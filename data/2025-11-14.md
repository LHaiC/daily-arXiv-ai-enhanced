<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 42]
- [cs.CL](#cs.CL) [Total: 64]
- [eess.SY](#eess.SY) [Total: 18]
- [cs.AI](#cs.AI) [Total: 56]
- [cs.DS](#cs.DS) [Total: 5]
- [cs.LO](#cs.LO) [Total: 3]
- [cs.RO](#cs.RO) [Total: 20]
- [eess.SP](#eess.SP) [Total: 9]
- [quant-ph](#quant-ph) [Total: 48]
- [cs.SI](#cs.SI) [Total: 4]
- [cond-mat.mtrl-sci](#cond-mat.mtrl-sci) [Total: 33]
- [cs.LG](#cs.LG) [Total: 101]
- [cs.NE](#cs.NE) [Total: 1]
- [cs.GT](#cs.GT) [Total: 3]
- [physics.app-ph](#physics.app-ph) [Total: 3]
- [cs.AR](#cs.AR) [Total: 5]
- [cs.DC](#cs.DC) [Total: 10]
- [cond-mat.mes-hall](#cond-mat.mes-hall) [Total: 17]
- [cs.MA](#cs.MA) [Total: 3]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [PALMS+: Modular Image-Based Floor Plan Localization Leveraging Depth Foundation Model](https://arxiv.org/abs/2511.09724)
*Yunqian Cheng,Benjamin Princen,Roberto Manduchi*

Main category: cs.CV

TL;DR: PALMS$+$, a vision-based indoor localization system, improves upon PALMS by reconstructing 3D point clouds from posed RGB images using monocular depth estimation and matching them with floor plans. It achieves higher accuracy in both stationary and sequential localization compared to existing methods without requiring training, demonstrating its potential for infrastructure-free applications.


<details>
  <summary>Details</summary>
Motivation: Indoor localization in GPS-denied environments is important for applications like emergency response and assistive navigation. Existing vision-based methods like PALMS have limitations due to short-range LiDAR and indoor layout ambiguity.

Method: PALMS$+$, an image-based system, reconstructs scale-aligned 3D point clouds from posed RGB images using a foundation monocular depth estimation model (Depth Pro). It then performs geometric layout matching with the floor plan. For sequential localization, it's integrated with a particle filter.

Result: Evaluated on Structured3D and a campus dataset, PALMS$+$ outperforms PALMS and F3Loc in stationary localization accuracy. For sequential localization on real-world trajectories, PALMS$+$ achieved lower errors compared to other methods.

Conclusion: PALMS$+$, a modular, image-based system, effectively addresses challenges in vision-based indoor localization by leveraging monocular depth estimation and floor plan matching. It demonstrates robust performance for camera-free tracking and has significant potential for infrastructure-free applications.

Abstract: Indoor localization in GPS-denied environments is crucial for applications like emergency response and assistive navigation. Vision-based methods such as PALMS enable infrastructure-free localization using only a floor plan and a stationary scan, but are limited by the short range of smartphone LiDAR and ambiguity in indoor layouts. We propose PALMS$+$, a modular, image-based system that addresses these challenges by reconstructing scale-aligned 3D point clouds from posed RGB images using a foundation monocular depth estimation model (Depth Pro), followed by geometric layout matching via convolution with the floor plan. PALMS$+$ outputs a posterior over the location and orientation, usable for direct or sequential localization. Evaluated on the Structured3D and a custom campus dataset consisting of 80 observations across four large campus buildings, PALMS$+$ outperforms PALMS and F3Loc in stationary localization accuracy -- without requiring any training. Furthermore, when integrated with a particle filter for sequential localization on 33 real-world trajectories, PALMS$+$ achieved lower localization errors compared to other methods, demonstrating robustness for camera-free tracking and its potential for infrastructure-free applications. Code and data are available at https://github.com/Head-inthe-Cloud/PALMS-Plane-based-Accessible-Indoor-Localization-Using-Mobile-Smartphones

</details>


### [2] [VLF-MSC: Vision-Language Feature-Based Multimodal Semantic Communication System](https://arxiv.org/abs/2511.10074)
*Gwangyeon Ahn,Jiwan Seo,Joonhyuk Kang*

Main category: cs.CV

TL;DR: VLF-MSC 使用预训练的视觉-语言模型 (VLM) 将源图像编码为视觉-语言语义特征 (VLF)，并通过无线信道传输。该 VLF 同时用于解码文本和生成图像，提高了频谱效率和适应性，并在低信噪比下实现了高语义保真度。


<details>
  <summary>Details</summary>
Motivation: 现有语义通信技术对不同模态（如图像和文本）的处理是分离的，缺乏统一性。本文提出了一种统一的系统 VLF-MSC，旨在通过单一的紧凑视觉-语言表示来同时支持图像和文本的生成，以提高效率和适应性。

Method: 提出了一种名为 VLF-MSC 的统一系统，利用预训练的视觉-语言模型 (VLM) 将源图像编码为视觉-语言语义特征 (VLF)。该 VLF 在接收端被用来条件化解码器语言模型以生成文本，并条件化扩散模型以生成图像。

Result: 与仅文本或仅图像的基线方法相比，VLF-MSC 在低信噪比下实现了更高的语义准确性，同时显著减少了带宽。该系统在噪声环境下表现出鲁棒性，并保持了语义保真度。

Conclusion: VLF-MSC 是一种创新的统一语义通信系统，通过单一的视觉-语言特征表示，能够有效地同时支持文本和图像的生成。该方法提高了频谱效率、适应性和鲁棒性，尤其在低信噪比条件下表现优越。

Abstract: We propose Vision-Language Feature-based Multimodal Semantic Communication (VLF-MSC), a unified system that transmits a single compact vision-language representation to support both image and text generation at the receiver. Unlike existing semantic communication techniques that process each modality separately, VLF-MSC employs a pre-trained vision-language model (VLM) to encode the source image into a vision-language semantic feature (VLF), which is transmitted over the wireless channel. At the receiver, a decoder-based language model and a diffusion-based image generator are both conditioned on the VLF to produce a descriptive text and a semantically aligned image. This unified representation eliminates the need for modality-specific streams or retransmissions, improving spectral efficiency and adaptability. By leveraging foundation models, the system achieves robustness to channel noise while preserving semantic fidelity. Experiments demonstrate that VLF-MSC outperforms text-only and image-only baselines, achieving higher semantic accuracy for both modalities under low SNR with significantly reduced bandwidth.

</details>


### [3] [VISTA: A Vision and Intent-Aware Social Attention Framework for Multi-Agent Trajectory Prediction](https://arxiv.org/abs/2511.10203)
*Stephane Da Silva Martins,Emanuel Aldea,Sylvie Le Hégarat-Mascle*

Main category: cs.CV

TL;DR: VISTA通过结合长期目标和社交互动来改进多智能体轨迹预测，在MADRAS和SDD数据集上实现了最先进的准确性和显著减少的碰撞率。


<details>
  <summary>Details</summary>
Motivation: 现有方法在联合捕捉智能体的长期目标和精细的社交互动方面存在不足，导致预测的未来轨迹不切实际。

Method: 提出了一种名为VISTA的递归目标条件Transformer模型，该模型包含一个跨注意力融合模块（整合长期意图和过去运动）、一个社交令牌注意力机制（实现跨智能体的灵活交互建模）以及一对注意力图（使社交影响模式在推理时可解释）。

Result: 在MADRAS数据集上，VISTA将平均碰撞率从强基线的2.14%降低到0.03%；在SDD数据集上，VISTA实现了零碰撞，同时提高了ADE、FDE和minFDE指标。

Conclusion: VISTA能够生成符合社会规范、考虑目标且可解释的轨迹，对于安全关键的自动驾驶系统具有潜力。

Abstract: Multi-agent trajectory prediction is crucial for autonomous systems operating in dense, interactive environments. Existing methods often fail to jointly capture agents' long-term goals and their fine-grained social interactions, which leads to unrealistic multi-agent futures. We propose VISTA, a recursive goal-conditioned transformer for multi-agent trajectory forecasting. VISTA combines (i) a cross-attention fusion module that integrates long-horizon intent with past motion, (ii) a social-token attention mechanism for flexible interaction modeling across agents, and (iii) pairwise attention maps that make social influence patterns interpretable at inference time. Our model turns single-agent goal-conditioned prediction into a coherent multi-agent forecasting framework. Beyond standard displacement metrics, we evaluate trajectory collision rates as a measure of joint realism. On the high-density MADRAS benchmark and on SDD, VISTA achieves state-of-the-art accuracy and substantially fewer collisions. On MADRAS, it reduces the average collision rate of strong baselines from 2.14 to 0.03 percent, and on SDD it attains zero collisions while improving ADE, FDE, and minFDE. These results show that VISTA generates socially compliant, goal-aware, and interpretable trajectories, making it promising for safety-critical autonomous systems.

</details>


### [4] [MSGNav: Unleashing the Power of Multi-modal 3D Scene Graph for Zero-Shot Embodied Navigation](https://arxiv.org/abs/2511.10376)
*Xun Huang,Shijia Zhao,Yunxiang Wang,Xin Lu,Wanfa Zhang,Rongsheng Qu,Weixin Li,Yunhong Wang,Chenglu Wen*

Main category: cs.CV

TL;DR: 提出了一种名为M3DSG的多模态3D场景图，并在此基础上构建了MSGNav导航系统，解决了现有零样本导航方法中视觉信息丢失和词汇限制的问题，并在公开数据集上取得了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 现实世界中的机器人导航需要开放词汇泛化能力和低训练开销，这促使研究者们采用零样本方法而非针对特定任务的强化学习训练。然而，现有的零样本方法（如显式3D场景图）会将视觉信息压缩成纯文本关系，导致高昂的构建成本、视觉证据的不可逆损失以及词汇的限制。

Method: 提出多模态3D场景图（M3DSG），用动态分配的图像替换文本关系边，以保留视觉线索。在此基础上，构建了MSGNav零样本导航系统，包含关键子图选择模块、自适应词汇更新模块和闭环推理模块。此外，还提出了基于可见性的视点决策模块来解决最后一英里问题。

Result: MSGNav在GOAT-Bench和HM3D-OVON数据集上实现了最先进的性能。

Conclusion: M3DSG和MSGNav能够有效解决现有零样本导航方法的局限性，并在各种数据集上展现出优越的导航能力。

Abstract: Embodied navigation is a fundamental capability for robotic agents operating. Real-world deployment requires open vocabulary generalization and low training overhead, motivating zero-shot methods rather than task-specific RL training. However, existing zero-shot methods that build explicit 3D scene graphs often compress rich visual observations into text-only relations, leading to high construction cost, irreversible loss of visual evidence, and constrained vocabularies. To address these limitations, we introduce the Multi-modal 3D Scene Graph (M3DSG), which preserves visual cues by replacing textual relational edges with dynamically assigned images. Built on M3DSG, we propose MSGNav, a zero-shot navigation system that includes a Key Subgraph Selection module for efficient reasoning, an Adaptive Vocabulary Update module for open vocabulary support, and a Closed-Loop Reasoning module for accurate exploration reasoning. Additionally, we further identify the last-mile problem in zero-shot navigation - determining the feasible target location with a suitable final viewpoint, and propose a Visibility-based Viewpoint Decision module to explicitly resolve it. Comprehensive experimental results demonstrate that MSGNav achieves state-of-the-art performance on GOAT-Bench and HM3D-OVON datasets. The open-source code will be publicly available.

</details>


### [5] [SemanticVLA: Semantic-Aligned Sparsification and Enhancement for Efficient Robotic Manipulation](https://arxiv.org/abs/2511.10518)
*Wei Li,Renshan Zhang,Rui Shao,Zhijian Fang,Kaiwen Zhou,Zhuotao Tian,Liqiang Nie*

Main category: cs.CV

TL;DR: SemanticVLA通过语义对齐的稀疏化和增强来解决机器人操作中的感知冗余和浅层指令-视觉对齐问题，通过SD-Pruner、SH-Fuser和SA-Coupler三个模块实现，在仿真和真实世界任务中均取得了SOTA性能，并显著降低了训练成本和推理延迟。


<details>
  <summary>Details</summary>
Motivation: 现有VLA模型在机器人操作方面存在感知冗余（处理不相关的视觉输入）和浅层指令-视觉对齐（影响语义基础）两大局限，阻碍了实际部署。

Method: 提出SemanticVLA框架，包含三个核心模块：1. 语义引导双视觉剪枝器（SD-Pruner），包括指令驱动剪枝器（ID-Pruner）和空间聚合剪枝器（SA-Pruner），用于在保持语义对齐的同时稀疏化冗余感知。2. 语义互补分层融合器（SH-Fuser），用于融合来自SigLIP和DINOv2的密集和稀疏特征，以获得连贯的表示。3. 语义条件动作耦合器（SA-Coupler），用于增强从感知到动作的转换，替代传统的观察到自由度的方法。

Result: 在仿真和真实世界任务上的广泛实验表明，SemanticVLA在性能和效率方面均达到了新的SOTA。与OpenVLA相比，SemanticVLA在LIBERO基准测试上的成功率提高了21.1%，同时训练成本和推理延迟分别降低了3.0倍和2.7倍。

Conclusion: SemanticVLA通过语义对齐的稀疏化和增强，有效地解决了机器人操作中的感知冗余和语义对齐问题，并在性能和效率上取得了显著的提升，为机器人操作任务提供了一个更优的解决方案。

Abstract: Vision-Language-Action (VLA) models have advanced in robotic manipulation, yet practical deployment remains hindered by two key limitations: 1) perceptual redundancy, where irrelevant visual inputs are processed inefficiently, and 2) superficial instruction-vision alignment, which hampers semantic grounding of actions. In this paper, we propose SemanticVLA, a novel VLA framework that performs Semantic-Aligned Sparsification and Enhancement for Efficient Robotic Manipulation. Specifically: 1) To sparsify redundant perception while preserving semantic alignment, Semantic-guided Dual Visual Pruner (SD-Pruner) performs: Instruction-driven Pruner (ID-Pruner) extracts global action cues and local semantic anchors in SigLIP; Spatial-aggregation Pruner (SA-Pruner) compacts geometry-rich features into task-adaptive tokens in DINOv2. 2) To exploit sparsified features and integrate semantics with spatial geometry, Semantic-complementary Hierarchical Fuser (SH-Fuser) fuses dense patches and sparse tokens across SigLIP and DINOv2 for coherent representation. 3) To enhance the transformation from perception to action, Semantic-conditioned Action Coupler (SA-Coupler) replaces the conventional observation-to-DoF approach, yielding more efficient and interpretable behavior modeling for manipulation tasks. Extensive experiments on simulation and real-world tasks show that SemanticVLA sets a new SOTA in both performance and efficiency. SemanticVLA surpasses OpenVLA on LIBERO benchmark by 21.1% in success rate, while reducing training cost and inference latency by 3.0-fold and 2.7-fold.SemanticVLA is open-sourced and publicly available at https://github.com/JiuTian-VL/SemanticVLA

</details>


### [6] [Social LSTM with Dynamic Occupancy Modeling for Realistic Pedestrian Trajectory Prediction](https://arxiv.org/abs/2511.09735)
*Ahmed Alia,Mohcine Chraibi,Armin Seyfried*

Main category: cs.CV

TL;DR: 该研究提出了一种新的深度学习模型，通过引入动态占用空间损失函数来解决行人轨迹预测中的碰撞问题，并在五种不同密度的真实数据集上进行了验证，结果显示该模型能有效降低碰撞率并提高预测精度。


<details>
  <summary>Details</summary>
Motivation: 现有的行人轨迹预测模型大多将行人视为点实体，忽略了个体占用的物理空间，这在动态和拥挤的环境中会导致不切实际的预测结果，未能有效解决行人间的相互影响和潜在碰撞问题。

Method: 提出了一种新的深度学习模型，该模型在Social LSTM的基础上增加了一个动态占用空间损失函数。该损失函数结合了平均位移误差和一种新的、对场景密度和个体空间占用敏感的碰撞惩罚项，以指导模型学习避免真实的碰撞，同时不增加不同拥挤密度下的位移误差。

Result: 在五种不同密度的真实数据集（四种均匀密度，一种异构密度）上的实验表明，该模型显著降低了碰撞率（平均降低31%），并平均提高了5%的平均位移误差和6%的最终位移误差。此外，该模型在大多数测试集上优于其他先进的深度学习模型。

Conclusion: 所提出的模型能够有效地解决行人轨迹预测中的碰撞问题，并在不牺牲预测精度的前提下，提高模型在各种人群密度下的表现。

Abstract: In dynamic and crowded environments, realistic pedestrian trajectory prediction remains a challenging task due to the complex nature of human motion and the mutual influences among individuals. Deep learning models have recently achieved promising results by implicitly learning such patterns from 2D trajectory data. However, most approaches treat pedestrians as point entities, ignoring the physical space that each person occupies. To address these limitations, this paper proposes a novel deep learning model that enhances the Social LSTM with a new Dynamic Occupied Space loss function. This loss function guides Social LSTM in learning to avoid realistic collisions without increasing displacement error across different crowd densities, ranging from low to high, in both homogeneous and heterogeneous density settings. Such a function achieves this by combining the average displacement error with a new collision penalty that is sensitive to scene density and individual spatial occupancy. For efficient training and evaluation, five datasets were generated from real pedestrian trajectories recorded during the Festival of Lights in Lyon 2022. Four datasets represent homogeneous crowd conditions -- low, medium, high, and very high density -- while the fifth corresponds to a heterogeneous density distribution. The experimental findings indicate that the proposed model not only lowers collision rates but also enhances displacement prediction accuracy in each dataset. Specifically, the model achieves up to a 31% reduction in the collision rate and reduces the average displacement error and the final displacement error by 5% and 6%, respectively, on average across all datasets compared to the baseline. Moreover, the proposed model consistently outperforms several state-of-the-art deep learning models across most test sets.

</details>


### [7] [Regional Attention-Enhanced Swin Transformer for Clinically Relevant Medical Image Captioning](https://arxiv.org/abs/2511.09893)
*Zubia Naz,Farhan Asghar,Muhammad Ishfaq Hussain,Yahya Hadadi,Muhammad Aasim Rafique,Wookjin Choi,Moongu Jeon*

Main category: cs.CV

TL;DR: Swin-BART编码器-解码器系统在ROCO数据集上实现了最先进的医学图像描述生成，同时保持了模型的小巧和可解释性。


<details>
  <summary>Details</summary>
Motivation: 开发能够将复杂的放射学图像转化为诊断性叙述的自动化医学图像描述生成系统，以支持报告工作流程。

Method: 使用带有轻量级区域注意力模块的Swin-BART编码器-解码器系统，该模块在交叉注意力之前增强了诊断上的显著区域。

Result: 在ROCO数据集上，与基线模型相比，ROUGE得分从0.356提高到0.603，BERTScore从0.623提高到0.807，同时在BLEU、CIDEr和METEOR方面也具有竞争力。模型还提供了区域注意力消融、按模态分析、显著性检验和可视化热图。

Conclusion: 所提出的设计能够生成准确、符合临床术语的医学图像描述，并提供透明的区域归因，支持在有监督的情况下进行安全的研究使用。

Abstract: Automated medical image captioning translates complex radiological images into diagnostic narratives that can support reporting workflows. We present a Swin-BART encoder-decoder system with a lightweight regional attention module that amplifies diagnostically salient regions before cross-attention. Trained and evaluated on ROCO, our model achieves state-of-the-art semantic fidelity while remaining compact and interpretable. We report results as mean$\pm$std over three seeds and include $95\%$ confidence intervals. Compared with baselines, our approach improves ROUGE (proposed 0.603, ResNet-CNN 0.356, BLIP2-OPT 0.255) and BERTScore (proposed 0.807, BLIP2-OPT 0.645, ResNet-CNN 0.623), with competitive BLEU, CIDEr, and METEOR. We further provide ablations (regional attention on/off and token-count sweep), per-modality analysis (CT/MRI/X-ray), paired significance tests, and qualitative heatmaps that visualize the regions driving each description. Decoding uses beam search (beam size $=4$), length penalty $=1.1$, $no\_repeat\_ngram\_size$ $=3$, and max length $=128$. The proposed design yields accurate, clinically phrased captions and transparent regional attributions, supporting safe research use with a human in the loop.

</details>


### [8] [Soiling detection for Advanced Driver Assistance Systems](https://arxiv.org/abs/2511.09740)
*Filip Beránek,Václav Diviš,Ivan Gruber*

Main category: cs.CV

TL;DR: 提出了将汽车摄像头污垢检测视为语义分割问题，并对现有方法进行了比较和改进，同时修复了Woodscape数据集的数据泄露和标注不准确问题。


<details>
  <summary>Details</summary>
Motivation: 汽车摄像头污垢检测是高级驾驶辅助系统（ADAS）的关键组成部分，以提高其在天气、灰尘等外部条件下的鲁棒性。

Method: 将污垢检测视为语义分割问题，对流行的分割方法进行了全面的比较，并与瓦片级分类方法进行了性能比较。创建了一个新的、更小的数据子集，以解决原始Woodscape数据集的数据泄露和不准确的标注问题。

Result: 提出的语义分割方法在性能上优于瓦片级分类方法。新的、更小的数据子集能够达到相当的结果，并且训练时间大大缩短。

Conclusion: 通过将污垢检测视为语义分割问题，并使用修正后的数据集，可以更有效地提高ADAS系统的鲁棒性。

Abstract: Soiling detection for automotive cameras is a crucial part of advanced driver assistance systems to make them more robust to external conditions like weather, dust, etc. In this paper, we regard the soiling detection as a semantic segmentation problem. We provide a comprehensive comparison of popular segmentation methods and show their superiority in performance while comparing them to tile-level classification approaches. Moreover, we present an extensive analysis of the Woodscape dataset showing that the original dataset contains a data-leakage and imprecise annotations. To address these problems, we create a new data subset, which, despite being much smaller, provides enough information for the segmentation method to reach comparable results in a much shorter time. All our codes and dataset splits are available at https://github.com/filipberanek/woodscape_revision.

</details>


### [9] [Compensating Distribution Drifts in Class-incremental Learning of Pre-trained Vision Transformers](https://arxiv.org/abs/2511.09926)
*Xuan Rao,Simian Xu,Zheng Li,Bo Zhao,Derong Liu,Mingming Ha,Cesare Alippi*

Main category: cs.CV

TL;DR: SeqFT 在 CIL 中易受分布漂移影响，提出 SLDC 通过对齐特征分布来补偿漂移，并结合知识蒸馏进一步提升性能，效果可媲美联合训练。


<details>
  <summary>Details</summary>
Motivation: SeqFT 通过预训练 ViT 并使用类别特征的近似分布进行分类器细化，是 CIL 的有效策略。然而，其顺序优化会引起分布漂移，导致先前学习的类别与更新模型之间的不匹配，从而随着时间的推移降低分类器性能。

Method: 提出 SLDC 算法，包括线性 SLDC 和弱非线性 SLDC 变体。线性 SLDC 通过求解正则化最小二乘问题来学习一个线性算子，将微调前后的特征对齐。弱非线性 SLDC 扩展了线性方法，使用可学习的弱非线性映射来平衡灵活性和泛化性。此外，在两种变体中应用知识蒸馏（KD）来减少表示漂移。

Result: 在标准 CIL 基准测试上的大量实验表明，SLDC 显著提高了 SeqFT 的性能。SLDC 结合 KD 解决了表示漂移问题，SeqFT 的性能可媲美所有评估数据集上的联合训练。

Conclusion: SLDC 通过对齐特征分布和结合知识蒸馏，有效解决了 SeqFT 中的分布漂移和表示漂移问题，显著提高了 CIL 性能，甚至在某些情况下达到了与联合训练相当的水平。

Abstract: Recent advances have shown that sequential fine-tuning (SeqFT) of pre-trained vision transformers (ViTs), followed by classifier refinement using approximate distributions of class features, can be an effective strategy for class-incremental learning (CIL). However, this approach is susceptible to distribution drift, caused by the sequential optimization of shared backbone parameters. This results in a mismatch between the distributions of the previously learned classes and that of the updater model, ultimately degrading the effectiveness of classifier performance over time. To address this issue, we introduce a latent space transition operator and propose Sequential Learning with Drift Compensation (SLDC). SLDC aims to align feature distributions across tasks to mitigate the impact of drift. First, we present a linear variant of SLDC, which learns a linear operator by solving a regularized least-squares problem that maps features before and after fine-tuning. Next, we extend this with a weakly nonlinear SLDC variant, which assumes that the ideal transition operator lies between purely linear and fully nonlinear transformations. This is implemented using learnable, weakly nonlinear mappings that balance flexibility and generalization. To further reduce representation drift, we apply knowledge distillation (KD) in both algorithmic variants. Extensive experiments on standard CIL benchmarks demonstrate that SLDC significantly improves the performance of SeqFT. Notably, by combining KD to address representation drift with SLDC to compensate distribution drift, SeqFT achieves performance comparable to joint training across all evaluated datasets. Code: https://github.com/raoxuan98-hash/sldc.git.

</details>


### [10] [Feature Quality and Adaptability of Medical Foundation Models: A Comparative Evaluation for Radiographic Classification and Segmentation](https://arxiv.org/abs/2511.09742)
*Frank Li,Theo Dapamede,Mohammadreza Chavoshi,Young Seok Jeon,Bardia Khosravi,Abdulhameed Dere,Beatrice Brown-Mulry,Rohan Satya Isaac,Aawez Mansuri,Chiratidzo Sanyika,Janice Newsome,Saptarshi Purkayastha,Imon Banerjee,Hari Trivedi,Judy Gichoya*

Main category: cs.CV

TL;DR: 医学领域预训练模型在医学影像分析中表现优于通用模型，但其有效性因任务而异，尤其在精细病变定位方面存在不足。


<details>
  <summary>Details</summary>
Motivation: 评估不同预训练域（医学 vs. 通用）、范式（如文本引导）和架构对医学影像编码器嵌入质量的影响，以选择最优编码器用于特定放射学任务。

Method: 评估了来自八个医学和通用领域基础模型（FM）的视觉编码器在胸部 X 光分析中的表现，并使用线性探测和微调对分类（气胸、心增大）和分割（气胸、心脏边界）任务进行了基准测试。

Result: 医学领域预训练模型在特征质量上优于通用领域模型；预训练嵌入在全局分类和显著解剖结构分割方面表现良好；但对于需要精细定位的病变（如气胸）分割，所有模型在未进行大量微调的情况下表现不佳；模型存在利用混淆捷径（如使用胸管诊断气胸）的问题；昂贵的文本-图像对齐并非必需，纯图像或标签监督模型表现优异；监督的端到端基线模型在分割任务上仍具竞争力。

Conclusion: 医学预训练模型虽有优势，但架构选择至关重要，且预训练特征并非对所有任务都有效，尤其在复杂病变定位方面，监督模型仍是强有力的替代方案。

Abstract: Foundation models (FMs) promise to generalize medical imaging, but their effectiveness varies. It remains unclear how pre-training domain (medical vs. general), paradigm (e.g., text-guided), and architecture influence embedding quality, hindering the selection of optimal encoders for specific radiology tasks. To address this, we evaluate vision encoders from eight medical and general-domain FMs for chest X-ray analysis. We benchmark classification (pneumothorax, cardiomegaly) and segmentation (pneumothorax, cardiac boundary) using linear probing and fine-tuning. Our results show that domain-specific pre-training provides a significant advantage; medical FMs consistently outperformed general-domain models in linear probing, establishing superior initial feature quality. However, feature utility is highly task-dependent. Pre-trained embeddings were strong for global classification and segmenting salient anatomy (e.g., heart). In contrast, for segmenting complex, subtle pathologies (e.g., pneumothorax), all FMs performed poorly without significant fine-tuning, revealing a critical gap in localizing subtle disease. Subgroup analysis showed FMs use confounding shortcuts (e.g., chest tubes for pneumothorax) for classification, a strategy that fails for precise segmentation. We also found that expensive text-image alignment is not a prerequisite; image-only (RAD-DINO) and label-supervised (Ark+) FMs were among top performers. Notably, a supervised, end-to-end baseline remained highly competitive, matching or exceeding the best FMs on segmentation tasks. These findings show that while medical pre-training is beneficial, architectural choices (e.g., multi-scale) are critical, and pre-trained features are not universally effective, especially for complex localization tasks where supervised models remain a strong alternative.

</details>


### [11] [Test-Time Spectrum-Aware Latent Steering for Zero-Shot Generalization in Vision-Language Models](https://arxiv.org/abs/2511.09809)
*Konstantinos M. Dafnis,Dimitris N. Metaxas*

Main category: cs.CV

TL;DR: STS是一种轻量级的视觉-语言模型（VLM）推理时域适应框架，通过在文本嵌入中提取谱子空间来定义主要的语义方向，并学习以谱感知的方式引导潜在表征。它在推理时在潜在空间中操作，无需反向传播或修改冻结的编码器，从而在保持性能的同时显著提高速度并减小内存占用。


<details>
  <summary>Details</summary>
Motivation: 现有的视觉-语言模型（VLM）在零样本推理方面表现出色，但在测试时域偏移下性能会下降。虽然现有的测试时域适应策略（如测试时提示调优）可以适应单个未标记图像，但它们通常需要通过大型编码器权重进行反向传播或修改核心模型组件。

Method: STS提取文本嵌入的谱子空间以定义主要语义方向，并通过调整少量每样本的移位参数来学习以谱感知的方式引导潜在表征，以最小化增强视图的熵。该方法完全在推理时在潜在空间中进行，无需反向传播或修改冻结的编码器。

Result: 实验表明，STS在标准评估协议下，在很大程度上超越或媲美了最先进的测试时域适应方法，同时仅增加了少量额外参数，并且推理速度提高了8倍，内存占用减小了12倍（与传统的测试时提示调优相比）。

Conclusion: STS是一种高效且有效的视觉-语言模型推理时域适应框架，它通过谱感知的方式引导潜在表征，能够在不修改或反向传播冻结编码器的情况下，显著提高模型在域偏移下的性能，同时提供优越的速度和内存效率。

Abstract: Vision-Language Models (VLMs) excel at zero-shot inference but often degrade under test-time domain shifts. For this reason, episodic test-time adaptation strategies have recently emerged as powerful techniques for adapting VLMs to a single unlabeled image. However, existing adaptation strategies, such as test-time prompt tuning, typically require backpropagating through large encoder weights or altering core model components. In this work, we introduce Spectrum-Aware Test-Time Steering (STS), a lightweight adaptation framework that extracts a spectral subspace from the textual embeddings to define principal semantic directions and learns to steer latent representations in a spectrum-aware manner by adapting a small number of per-sample shift parameters to minimize entropy across augmented views. STS operates entirely at inference in the latent space, without backpropagation through or modification of the frozen encoders. Building on standard evaluation protocols, our comprehensive experiments demonstrate that STS largely surpasses or compares favorably against state-of-the-art test-time adaptation methods, while introducing only a handful of additional parameters and achieving inference speeds up to 8x faster with a 12x smaller memory footprint than conventional test-time prompt tuning. The code is available at https://github.com/kdafnis/STS.

</details>


### [12] [Towards Blind and Low-Vision Accessibility of Lightweight VLMs and Custom LLM-Evals](https://arxiv.org/abs/2511.10615)
*Shruti Singh Baghel,Yash Pratap Singh Rathore,Sushovan Jena,Anurag Pradhan,Amit Shukla,Arnav Bhavsar,Pawan Goyal*

Main category: cs.CV

TL;DR: 大型视觉-语言模型（VLMs）在视频描述方面表现出色，但其高昂的内存、计算和部署成本限制了其实际应用，特别是对于依赖详细、上下文感知描述的盲人和低视力（BLV）用户。 SmolVLM2 的 500M 和 2.2B 参数变体在 AVCaps（室外）和 Charades（室内）两个数据集上进行了评估，以研究模型大小对以可访问性为重点的描述质量的影响。本研究引入了两个新颖的评估框架，专门用于 BLV 可访问性评估：多上下文 BLV 框架（评估空间方向、社交互动、动作事件和环境背景）和导航辅助框架（侧重于移动关键信息）。此外，还对四种不同的提示设计策略进行了系统评估，并在智能手机上部署了两种模型，评估了 FP32 和 INT8 精度变体，以评估资源有限的移动设备上的实际性能限制。


<details>
  <summary>Details</summary>
Motivation: 大型视觉-语言模型（VLMs）虽然在生成视频描述方面表现出色，但其高昂的资源需求限制了它们在现实世界中的应用，尤其对于盲人和低视力（BLV）用户而言，他们需要详细且具有上下文感知能力的描述。因此，研究模型大小对以可访问性为重点的视频描述质量的影响具有重要意义。

Method: 评估了 SmolVLM2 的 500M 和 2.2B 参数变体在 AVCaps（室外）和 Charades（室内）两个数据集上的表现。引入了两个新的评估框架：多上下文 BLV 框架（侧重于空间方向、社交互动、动作事件和环境背景）和导航辅助框架（侧重于移动关键信息）。此外，还系统评估了四种不同的提示设计策略，并在智能手机上部署了 FP32 和 INT8 精度的模型，以评估其在资源受限设备上的实际性能。

Result: SmolVLM2 的 500M 和 2.2B 参数变体在两个数据集上的表现以及在不同提示策略下的表现得到了评估。在智能手机上部署的 FP32 和 INT8 精度变体的实际性能限制也得到了评估。

Conclusion: 对不同大小的 SmolVLM2 模型在特定数据集上的表现进行了评估，并引入了针对 BLV 用户可访问性优化的新评估框架。通过评估不同的提示策略和模型精度，为理解和改进 VLM 在资源受限环境下的应用提供了见解。

Abstract: Large Vision-Language Models (VLMs) excel at understanding and generating video descriptions but their high memory, computation, and deployment demands hinder practical use particularly for blind and low-vision (BLV) users who depend on detailed, context-aware descriptions. To study the effect of model size on accessibility-focused description quality, we evaluate SmolVLM2 variants with 500M and 2.2B parameters across two diverse datasets: AVCaps (outdoor), and Charades (indoor). In this work, we introduce two novel evaluation frameworks specifically designed for BLV accessibility assessment: the Multi-Context BLV Framework evaluating spatial orientation, social interaction, action events, and ambience contexts; and the Navigational Assistance Framework focusing on mobility-critical information. Additionally, we conduct a systematic evaluation of four different prompt design strategies and deploy both models on a smartphone, evaluating FP32 and INT8 precision variants to assess real-world performance constraints on resource-limited mobile devices.

</details>


### [13] [From Street to Orbit: Training-Free Cross-View Retrieval via Location Semantics and LLM Guidance](https://arxiv.org/abs/2511.09820)
*Jeongho Min,Dongyoung Kim,Jaehyup Lee*

Main category: cs.CV

TL;DR: 该研究提出了一种无需额外训练的跨视图图像检索框架，利用预训练的视觉编码器和大型语言模型，仅凭单目街景图像即可实现街景到卫星图像的匹配，并在零样本设置下超越了现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有跨视图图像检索方法（尤其是街景到卫星匹配）通常需要监督训练和特定类型的图像（如全景或无人机图像），这限制了其在真实世界的应用。本研究旨在提出一种无需训练、部署灵活的跨视图图像检索方法。

Method: 提取街景图像的地理线索，通过网络搜索和大型语言模型推断位置，然后利用地理编码API生成卫星查询图，并使用预训练的视觉编码器（如DINOv2）和PCA白化特征进行匹配。

Result: 在零样本设置下，该方法在基准数据集上的表现优于之前的基于学习的方法，并且能够自动构建街景到卫星图像的数据集。

Conclusion: 本研究提出的无需训练的跨视图图像检索框架，通过结合预训练的视觉编码器和大型语言模型，在街景到卫星图像匹配任务上取得了优于现有方法的性能，并为数据集的构建提供了可扩展且成本效益高的方法。

Abstract: Cross-view image retrieval, particularly street-to-satellite matching, is a critical task for applications such as autonomous navigation, urban planning, and localization in GPS-denied environments. However, existing approaches often require supervised training on curated datasets and rely on panoramic or UAV-based images, which limits real-world deployment. In this paper, we present a simple yet effective cross-view image retrieval framework that leverages a pretrained vision encoder and a large language model (LLM), requiring no additional training. Given a monocular street-view image, our method extracts geographic cues through web-based image search and LLM-based location inference, generates a satellite query via geocoding API, and retrieves matching tiles using a pretrained vision encoder (e.g., DINOv2) with PCA-based whitening feature refinement. Despite using no ground-truth supervision or finetuning, our proposed method outperforms prior learning-based approaches on the benchmark dataset under zero-shot settings. Moreover, our pipeline enables automatic construction of semantically aligned street-to-satellite datasets, which is offering a scalable and cost-efficient alternative to manual annotation. All source codes will be made publicly available at https://jeonghomin.github.io/street2orbit.github.io/.

</details>


### [14] [CertMask: Certifiable Defense Against Adversarial Patches via Theoretically Optimal Mask Coverage](https://arxiv.org/abs/2511.09834)
*Xuntao Lyu,Ching-Chi Lin,Abdullah Al Arafat,Georg von der Brüggen,Jian-Jia Chen,Zhishan Guo*

Main category: cs.CV

TL;DR: CertMask是一种可证明的鲁棒防御方法，通过生成一组二进制掩码来抵御对抗性补丁攻击，其推理成本为O(n)，优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 对抗性补丁攻击能够通过在图像中注入局部扰动来欺骗深度视觉模型，对现实世界的应用构成严重威胁。因此，开发能够有效防御此类攻击并提供理论保证的鲁棒方法至关重要。

Method: CertMask通过一种数学上严格的覆盖策略来计算掩码集，确保每个可能的补丁位置至少被覆盖k次。该方法仅需一轮掩码即可实现O(n)的推理复杂度，其中n是覆盖输入图像的掩码集的大小。

Result: 与现有技术（PatchCleanser）相比，CertMask在ImageNet、ImageNette和CIFAR-10数据集上的实验表明，其可证明的鲁棒准确率提高了13.4%，同时保持了与原始模型几乎相同的准确率。

Conclusion: CertMask通过其高效且可证明的鲁棒性，为对抗性补丁攻击提供了一种有效的防御机制，并在准确性和鲁棒性之间取得了良好的平衡。

Abstract: Adversarial patch attacks inject localized perturbations into images to mislead deep vision models. These attacks can be physically deployed, posing serious risks to real-world applications. In this paper, we propose CertMask, a certifiably robust defense that constructs a provably sufficient set of binary masks to neutralize patch effects with strong theoretical guarantees. While the state-of-the-art approach (PatchCleanser) requires two rounds of masking and incurs $O(n^2)$ inference cost, CertMask performs only a single round of masking with $O(n)$ time complexity, where $n$ is the cardinality of the mask set to cover an input image. Our proposed mask set is computed using a mathematically rigorous coverage strategy that ensures each possible patch location is covered at least $k$ times, providing both efficiency and robustness. We offer a theoretical analysis of the coverage condition and prove its sufficiency for certification. Experiments on ImageNet, ImageNette, and CIFAR-10 show that CertMask improves certified robust accuracy by up to +13.4\% over PatchCleanser, while maintaining clean accuracy nearly identical to the vanilla model.

</details>


### [15] [Scale-Aware Relay and Scale-Adaptive Loss for Tiny Object Detection in Aerial Images](https://arxiv.org/abs/2511.09891)
*Jinfu Li,Yuqi Huang,Hong Song,Ting Wang,Jianghan Xia,Yucong Lin,Jingfan Fan,Jian Yang*

Main category: cs.CV

TL;DR: SARL和SAL被提出用于改进物体检测中细小物体检测的性能，SARL通过跨尺度注意力增强特征，SAL通过自适应加权减少大物体的影响。


<details>
  <summary>Details</summary>
Motivation: 现代目标检测器在检测航空图像中的细小物体时仍然存在困难，因为细小物体携带的特征有限，容易在网络传播中丢失，并且在训练中会受到不成比例的回归惩罚。

Method: 提出了一种尺度感知中继层（SARL）和一个尺度自适应损失（SAL）。SARL采用跨尺度空间通道注意力来丰富特征并加强跨层特征共享。SAL通过重新设计基于IoU的损失来动态降低大物体的权重，从而将训练重点放在细小物体上。

Result: 所提出的方法在YOLOv5和YOLOx基线中，在AI-TOD、DOTA-v2.0和VisDrone2019三个基准上，平均精度（AP）提高了5.5%。在真实世界的噪声数据集AI-TOD-v2.0上，AP也提高了29.0%。

Conclusion: SARL和SAL的结合能够显著提升物体检测器在细小物体检测上的性能和泛化能力，尤其是在存在噪声的数据集上。

Abstract: Recently, despite the remarkable advancements in object detection, modern detectors still struggle to detect tiny objects in aerial images. One key reason is that tiny objects carry limited features that are inevitably degraded or lost during long-distance network propagation. Another is that smaller objects receive disproportionately greater regression penalties than larger ones during training. To tackle these issues, we propose a Scale-Aware Relay Layer (SARL) and a Scale-Adaptive Loss (SAL) for tiny object detection, both of which are seamlessly compatible with the top-performing frameworks. Specifically, SARL employs a cross-scale spatial-channel attention to progressively enrich the meaningful features of each layer and strengthen the cross-layer feature sharing. SAL reshapes the vanilla IoU-based losses so as to dynamically assign lower weights to larger objects. This loss is able to focus training on tiny objects while reducing the influence on large objects. Extensive experiments are conducted on three benchmarks (\textit{i.e.,} AI-TOD, DOTA-v2.0 and VisDrone2019), and the results demonstrate that the proposed method boosts the generalization ability by 5.5\% Average Precision (AP) when embedded in YOLOv5 (anchor-based) and YOLOx (anchor-free) baselines. Moreover, it also promotes the robust performance with 29.0\% AP on the real-world noisy dataset (\textit{i.e.,} AI-TOD-v2.0).

</details>


### [16] [AdaptViG: Adaptive Vision GNN with Exponential Decay Gating](https://arxiv.org/abs/2511.09942)
*Mustafa Munir,Md Mostafijur Rahman,Radu Marculescu*

Main category: cs.CV

TL;DR: AdaptViG是一种高效的混合视觉图神经网络，通过自适应图卷积（包括静态轴向支架和动态指数衰减门控）解决了ViG的计算挑战，并在早期阶段使用门控机制，后期使用全局注意力机制，实现了最先进的准确率-效率权衡。


<details>
  <summary>Details</summary>
Motivation: 传统的视觉图神经网络（ViG）在图构建阶段存在显著的计算挑战，影响了其效率。

Method: 提出了一种名为自适应图卷积的新型图构建机制，结合了高效的静态轴向支架和动态的、基于内容的指数衰减门控策略，该策略根据特征相似性选择性地加权长程连接。AdaptViG采用混合策略，在早期阶段使用门控机制，在最后阶段使用全局注意力块进行特征聚合。

Result: AdaptViG-M在ImageNet上实现了82.6%的top-1准确率，参数和GMACs分别减少了80%和84%。在下游任务中，AdaptViG-M在mIoU、APbox和APmask方面均优于EfficientFormer-L7，同时参数减少了78%。

Conclusion: AdaptViG在准确率和效率之间取得了新的最先进的权衡，证明了其在视觉GNN领域的潜力。

Abstract: Vision Graph Neural Networks (ViGs) offer a new direction for advancements in vision architectures. While powerful, ViGs often face substantial computational challenges stemming from their graph construction phase, which can hinder their efficiency. To address this issue we propose AdaptViG, an efficient and powerful hybrid Vision GNN that introduces a novel graph construction mechanism called Adaptive Graph Convolution. This mechanism builds upon a highly efficient static axial scaffold and a dynamic, content-aware gating strategy called Exponential Decay Gating. This gating mechanism selectively weighs long-range connections based on feature similarity. Furthermore, AdaptViG employs a hybrid strategy, utilizing our efficient gating mechanism in the early stages and a full Global Attention block in the final stage for maximum feature aggregation. Our method achieves a new state-of-the-art trade-off between accuracy and efficiency among Vision GNNs. For instance, our AdaptViG-M achieves 82.6% top-1 accuracy, outperforming ViG-B by 0.3% while using 80% fewer parameters and 84% fewer GMACs. On downstream tasks, AdaptViG-M obtains 45.8 mIoU, 44.8 APbox, and 41.1 APmask, surpassing the much larger EfficientFormer-L7 by 0.7 mIoU, 2.2 APbox, and 2.1 APmask, respectively, with 78% fewer parameters.

</details>


### [17] [Beyond Cosine Similarity Magnitude-Aware CLIP for No-Reference Image Quality Assessment](https://arxiv.org/abs/2511.09948)
*Zhicheng Liao,Dongxu Wu,Zhenshan Shi,Sijie Mai,Hanwei Zhu,Lingyu Zhu,Yuncheng Jiang,Baoliang Chen*

Main category: cs.CV

TL;DR: CLIP模型可用于图像质量评估，但其仅依赖于文本相似性。本文提出一种结合图像特征幅度的自适应融合框架，以提高评估精度，无需任何特定任务的训练。


<details>
  <summary>Details</summary>
Motivation: 现有基于CLIP的图像质量评估方法主要依赖文本语义相似性，忽略了图像特征的幅度信息，而该信息与感知质量高度相关。

Method: 提出一种自适应融合框架，结合CLIP图像特征的幅度和文本提示的余弦相似性。具体包括：1. 提取CLIP图像特征的绝对值，并应用Box-Cox变换进行归一化，以减少语义敏感性。2. 设计一种置信度引导的融合方案，根据各部分信息的相对强度自适应地加权。

Result: 在多个基准图像质量评估数据集上进行的大量实验表明，该方法一致优于标准的基于CLIP的图像质量评估方法和最先进的基线方法。

Conclusion: 本文提出的自适应融合框架，通过结合文本相似性和图像特征幅度，能够有效提升图像质量评估的性能，且无需进行特定任务的训练。

Abstract: Recent efforts have repurposed the Contrastive Language-Image Pre-training (CLIP) model for No-Reference Image Quality Assessment (NR-IQA) by measuring the cosine similarity between the image embedding and textual prompts such as "a good photo" or "a bad photo." However, this semantic similarity overlooks a critical yet underexplored cue: the magnitude of the CLIP image features, which we empirically find to exhibit a strong correlation with perceptual quality. In this work, we introduce a novel adaptive fusion framework that complements cosine similarity with a magnitude-aware quality cue. Specifically, we first extract the absolute CLIP image features and apply a Box-Cox transformation to statistically normalize the feature distribution and mitigate semantic sensitivity. The resulting scalar summary serves as a semantically-normalized auxiliary cue that complements cosine-based prompt matching. To integrate both cues effectively, we further design a confidence-guided fusion scheme that adaptively weighs each term according to its relative strength. Extensive experiments on multiple benchmark IQA datasets demonstrate that our method consistently outperforms standard CLIP-based IQA and state-of-the-art baselines, without any task-specific training.

</details>


### [18] [Difference Vector Equalization for Robust Fine-tuning of Vision-Language Models](https://arxiv.org/abs/2511.09973)
*Satoshi Suzuki,Shin'ya Yamaguchi,Shoichiro Takeda,Taiga Yamane,Naoki Makishima,Naotaka Kawata,Mana Ihori,Tomohiro Tanaka,Shota Orihashi,Ryo Masumura*

Main category: cs.CV

TL;DR: 提出了一种名为DiVE的新方法，用于在不损害其泛化能力的情况下，对对比预训练的视觉-语言模型进行鲁棒的微调。


<details>
  <summary>Details</summary>
Motivation: 对比预训练的视觉-语言模型（如CLIP）的泛化能力很强，但现有鲁棒微调方法会扭曲嵌入的几何结构，从而限制其在OOD和零样本场景下的表现。

Method: 提出了一种名为DiVE（Difference Vector Equalization）的新方法，该方法通过约束数据样本的嵌入差异向量来保持微调过程中的几何结构。引入了平均向量损失（AVL）和成对向量损失（PVL）来全局和局部地保持几何结构。

Result: DiVE有效地保持了嵌入的几何结构，并在ID、OOD和零样本指标上均取得了强大的性能。

Conclusion: DiVE是一种有效的鲁棒微调方法，可在保持现有视觉-语言模型泛化能力的同时，提高其在ID、OOD和零样本任务上的性能。

Abstract: Contrastive pre-trained vision-language models, such as CLIP, demonstrate strong generalization abilities in zero-shot classification by leveraging embeddings extracted from image and text encoders. This paper aims to robustly fine-tune these vision-language models on in-distribution (ID) data without compromising their generalization abilities in out-of-distribution (OOD) and zero-shot settings. Current robust fine-tuning methods tackle this challenge by reusing contrastive learning, which was used in pre-training, for fine-tuning. However, we found that these methods distort the geometric structure of the embeddings, which plays a crucial role in the generalization of vision-language models, resulting in limited OOD and zero-shot performance. To address this, we propose Difference Vector Equalization (DiVE), which preserves the geometric structure during fine-tuning. The idea behind DiVE is to constrain difference vectors, each of which is obtained by subtracting the embeddings extracted from the pre-trained and fine-tuning models for the same data sample. By constraining the difference vectors to be equal across various data samples, we effectively preserve the geometric structure. Therefore, we introduce two losses: average vector loss (AVL) and pairwise vector loss (PVL). AVL preserves the geometric structure globally by constraining difference vectors to be equal to their weighted average. PVL preserves the geometric structure locally by ensuring a consistent multimodal alignment. Our experiments demonstrate that DiVE effectively preserves the geometric structure, achieving strong results across ID, OOD, and zero-shot metrics.

</details>


### [19] [MIRNet: Integrating Constrained Graph-Based Reasoning with Pre-training for Diagnostic Medical Imaging](https://arxiv.org/abs/2511.10013)
*Shufeng Kong,Zijie Wang,Nuan Cui,Hao Tang,Yihan Meng,Yuanyuan Wei,Feifan Chen,Yingheng Wang,Zhuo Cai,Yaonan Wang,Yulong Zhang,Yuzheng Li,Zibin Zheng,Caihua Liu*

Main category: cs.CV

TL;DR: MIRNet通过自监督预训练、图神经网络和约束优化，解决了医学图像分析中的数据稀缺、类别不平衡和临床合理性问题，并在舌像诊断任务中达到最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 解决医学图像分析中存在的复杂视觉-语义关系建模、标注稀缺、类别不平衡和临床合理性约束等问题，特别是舌像诊断这一细粒度理解的挑战性领域。

Method: MIRNet框架：1. 使用自监督掩码自编码器（MAE）学习无标签数据的视觉表征。2. 利用图注意力网络（GAT）通过专家定义的结构图对标签进行建模。3. 通过KL散度与正则化损失实现约束感知优化，强制执行临床先验。4. 使用非对称损失（ASL）和增强集成来减轻不平衡。5. 引入TongueAtlas-4K数据集（4000张图像，22个诊断标签）以解决标注稀缺问题。

Result: MIRNet在舌像诊断任务中实现了最先进的性能。

Conclusion: MIRNet框架在舌像诊断任务中表现出色，其通用性使其能够扩展到更广泛的医学影像诊断任务。

Abstract: Automated interpretation of medical images demands robust modeling of complex visual-semantic relationships while addressing annotation scarcity, label imbalance, and clinical plausibility constraints. We introduce MIRNet (Medical Image Reasoner Network), a novel framework that integrates self-supervised pre-training with constrained graph-based reasoning. Tongue image diagnosis is a particularly challenging domain that requires fine-grained visual and semantic understanding. Our approach leverages self-supervised masked autoencoder (MAE) to learn transferable visual representations from unlabeled data; employs graph attention networks (GAT) to model label correlations through expert-defined structured graphs; enforces clinical priors via constraint-aware optimization using KL divergence and regularization losses; and mitigates imbalance using asymmetric loss (ASL) and boosting ensembles. To address annotation scarcity, we also introduce TongueAtlas-4K, a comprehensive expert-curated benchmark comprising 4,000 images annotated with 22 diagnostic labels--representing the largest public dataset in tongue analysis. Validation shows our method achieves state-of-the-art performance. While optimized for tongue diagnosis, the framework readily generalizes to broader diagnostic medical imaging tasks.

</details>


### [20] [Anomagic: Crossmodal Prompt-driven Zero-shot Anomaly Generation](https://arxiv.org/abs/2511.10020)
*Yuxin Jiang,Wei Luo,Hui Zhang,Qiyu Chen,Haiming Yao,Weiming Shen,Yunkang Cao*

Main category: cs.CV

TL;DR: Anomagic是一种零样本异常生成方法，可生成语义上连贯的异常，无需任何示例。它通过跨模态提示编码方案统一视觉和文本线索，利用丰富的上下文信息来指导基于修复的生成流程。对比度细化策略确保合成异常与其掩码之间的精确对齐，从而提高下游异常检测的准确性。为了便于训练，引入了AnomVerse数据集，其中包含12,987个异常-掩码-字幕三元组，这些三元组是从13个公共数据集中组装而成的，字幕是使用结构化视觉提示和基于模板的文本提示，由多模态大型语言模型自动生成的。实验表明，在AnomVerse上训练的Anomagic可以合成比以前的方法更真实、更多样的异常，并在下游异常检测方面带来显著改进。此外，Anomagic可以使用用户定义的提示为任何正常类别的图像生成异常，从而建立了一个通用的异常生成基础模型。


<details>
  <summary>Details</summary>
Motivation: 现有的异常检测方法通常需要大量的、具有代表性的异常样本进行监督学习，然而在现实世界中，获取此类样本既困难又昂贵。因此，需要一种能够生成语义上连贯且多样化的异常样本的方法，以辅助训练和提高异常检测的性能。

Method: Anomagic采用零样本学习方法，首先通过跨模态提示编码方案统一视觉和文本线索，利用丰富的上下文信息来指导一个基于图像修复的生成流程，以合成异常。然后，利用对比度细化策略来确保合成的异常与其对应的掩码之间具有精确的对齐，从而提高下游异常检测任务的准确性。此外，研究者还构建了一个名为AnomVerse的数据集，其中包含12,987个异常-掩码-字幕三元组，用于训练Anomagic模型。

Result: 在AnomVerse数据集上训练的Anomagic在生成异常的真实性和多样性方面优于现有方法。与现有方法相比，Anomagic在下游异常检测任务中取得了更好的性能提升。此外，Anomagic能够根据用户定义的提示为任何正常类别的图像生成异常，展示了其作为基础模型的通用性。

Conclusion: Anomagic通过其创新的零样本异常生成方法，有效解决了异常样本难以获取的问题。通过结合视觉和文本线索，并利用对比度细化策略，Anomagic能够生成高质量、语义连贯的异常。AnomVerse数据集的构建为该方法的训练和评估提供了有力支持。实验结果证明了Anomagic在提升异常检测性能方面的有效性和其作为通用异常生成基础模型的潜力。

Abstract: We propose Anomagic, a zero-shot anomaly generation method that produces semantically coherent anomalies without requiring any exemplar anomalies. By unifying both visual and textual cues through a crossmodal prompt encoding scheme, Anomagic leverages rich contextual information to steer an inpainting-based generation pipeline. A subsequent contrastive refinement strategy enforces precise alignment between synthesized anomalies and their masks, thereby bolstering downstream anomaly detection accuracy. To facilitate training, we introduce AnomVerse, a collection of 12,987 anomaly-mask-caption triplets assembled from 13 publicly available datasets, where captions are automatically generated by multimodal large language models using structured visual prompts and template-based textual hints. Extensive experiments demonstrate that Anomagic trained on AnomVerse can synthesize more realistic and varied anomalies than prior methods, yielding superior improvements in downstream anomaly detection. Furthermore, Anomagic can generate anomalies for any normal-category image using user-defined prompts, establishing a versatile foundation model for anomaly generation.

</details>


### [21] [Multivariate Gaussian Representation Learning for Medical Action Evaluation](https://arxiv.org/abs/2511.10060)
*Luming Yang,Haoxian Liu,Siqing Li,Alper Yilmaz*

Main category: cs.CV

TL;DR: 我们提出了CPREval-6k，一个包含6372个视频的多视角、多标签医学动作基准，并引入了GaussMedAct，一个基于多元高斯编码的框架，通过自适应时空表征学习来改进医学动作分析。GaussMedAct将动作分解为自适应3D高斯，利用混合空间编码处理骨骼信息，实现了92.1%的Top-1准确率，同时保持实时推理能力，并且在跨数据集实验中表现出优越的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有的医学影像动作识别方法在处理数据不全、精度要求高以及快速动作的时空动态建模不足等方面存在挑战。因此，需要一个全面的数据集和先进的建模方法来支持该领域的发展和评估。

Method: 提出了一种名为GaussMedAct的多元高斯编码框架。该框架将动作分解为自适应的3D高斯，这些高斯具有各向异性协方差，能够保留动作语义并抵抗时空噪声。此外，还采用了混合空间编码策略，结合了笛卡尔坐标和向量双流，以有效地利用关节和骨骼特征。

Result: 在CPREval-6k基准上，GaussMedAct实现了92.1%的Top-1准确率，并且实现了实时推理。与ST-GCN基线相比，该方法在准确率上提高了5.9%，而FLOPs（浮点运算次数）仅为基线的10%。跨数据集实验也证明了该方法的鲁棒性。

Conclusion: GaussMedAct通过自适应时空表征学习，有效解决了医学动作识别中的挑战，并在CPREval-6k基准上取得了领先的性能和优越的鲁棒性。

Abstract: Fine-grained action evaluation in medical vision faces unique challenges due to the unavailability of comprehensive datasets, stringent precision requirements, and insufficient spatiotemporal dynamic modeling of very rapid actions. To support development and evaluation, we introduce CPREval-6k, a multi-view, multi-label medical action benchmark containing 6,372 expert-annotated videos with 22 clinical labels. Using this dataset, we present GaussMedAct, a multivariate Gaussian encoding framework, to advance medical motion analysis through adaptive spatiotemporal representation learning. Multivariate Gaussian Representation projects the joint motions to a temporally scaled multi-dimensional space, and decomposes actions into adaptive 3D Gaussians that serve as tokens. These tokens preserve motion semantics through anisotropic covariance modeling while maintaining robustness to spatiotemporal noise. Hybrid Spatial Encoding, employing a Cartesian and Vector dual-stream strategy, effectively utilizes skeletal information in the form of joint and bone features. The proposed method achieves 92.1% Top-1 accuracy with real-time inference on the benchmark, outperforming the ST-GCN baseline by +5.9% accuracy with only 10% FLOPs. Cross-dataset experiments confirm the superiority of our method in robustness.

</details>


### [22] [PriVi: Towards A General-Purpose Video Model For Primate Behavior In The Wild](https://arxiv.org/abs/2511.09675)
*Felix B. Mueller,Jan F. Meier,Timo Lueddecke,Richard Vogg,Roger L. Freixanet,Valentin Hassler,Tiffany Bosshard,Elif Karakoc,William J. O'Hearn,Sofia M. Pereira,Sandro Sehner,Kaja Wierucka,Judith Burkart,Claudia Fichtel,Julia Fischer,Alexander Gail,Catherine Hobaiter,Julia Ostner,Liran Samuni,Oliver Schülke,Neda Shahidi,Erin G. Wessling,Alexander S. Ecker*

Main category: cs.CV

TL;DR: 通过构建大规模的灵长类动物中心视频预训练数据集PriVi，并在此数据集上预训练V-JEPA模型，显著提高了在多个基准数据集上的性能，尤其是在标签数据较少的情况下，证明了灵长类动物中心预训练在提高数据效率和泛化能力方面的潜力。


<details>
  <summary>Details</summary>
Motivation: 现有计算机视觉方法在分析非人灵长类动物行为时，因依赖于以人类为中心预训练的模型和单一数据集，存在泛化能力受限的问题。

Method: 提出了一种数据为中心的方法，构建了包含424小时视频的大规模灵长类动物中心视频预训练数据集PriVi，并结合行为学研究和网络视频。在PriVi上预训练V-JEPA模型，并使用轻量级冻结分类器在四个基准数据集（ChimpACT, BaboonLand, PanAf500, ChimpBehave）上进行评估。

Result: 在四个基准数据集上，所提出的方法（基于PriVi预训练的V-JEPA）在数据效率和泛化能力方面持续优于现有工作，包括完全微调的方法，并且在标签数量较少的情况下表现出良好的扩展性。

Conclusion: 灵长类动物中心预训练能够显著提高数据效率和泛化能力，为标签数据有限的应用提供了有前景的方法。

Abstract: Non-human primates are our closest living relatives, and analyzing their behavior is central to research in cognition, evolution, and conservation. Computer vision could greatly aid this research, but existing methods often rely on human-centric pretrained models and focus on single datasets, which limits generalization. We address this limitation by shifting from a model-centric to a data-centric approach and introduce PriVi, a large-scale primate-centric video pretraining dataset. PriVi contains 424 hours of curated video, combining 174 hours from behavioral research across 11 settings with 250 hours of diverse web-sourced footage, assembled through a scalable data curation pipeline. We pretrain V-JEPA on PriVi to learn primate-specific representations and evaluate it using a lightweight frozen classifier. Across four benchmark datasets, ChimpACT, BaboonLand, PanAf500, and ChimpBehave, our approach consistently outperforms prior work, including fully finetuned baselines, and scales favorably with fewer labels. These results demonstrate that primate-centric pretraining substantially improves data efficiency and generalization, making it a promising approach for low-label applications. Code, models, and the majority of the dataset will be made available.

</details>


### [23] [Classifying Phonotrauma Severity from Vocal Fold Images with Soft Ordinal Regression](https://arxiv.org/abs/2511.09702)
*Katie Matton,Purvaja Balaji,Hamzeh Ghasemzadeh,Jameson C. Cooper,Daryush D. Mehta,Jarrad H. Van Stan,Robert E. Hillman,Rosalind Picard,John Guttag,S. Mazdak Abulnaga*

Main category: cs.CV

TL;DR: 该研究提出了首个自动分类声带图像中声创伤严重程度的方法，使用序数回归和软标签来处理标签不确定性，性能接近临床专家。


<details>
  <summary>Details</summary>
Motivation: 现有声创伤严重程度评估依赖于临床医生的专家判断，成本高且可靠性差异大，因此需要自动化的评估方法。

Method: 采用序数回归框架，并提出一种新颖的序数回归损失函数修改方法，使其能够处理反映注释者评分分布的软标签。

Result: 所提出的软序数回归方法在预测性能上接近临床专家，并能提供良好校准的不确定性估计。

Conclusion: 该研究通过提供自动化的声创伤严重程度评估工具，能够促进大规模声创伤研究，最终改善临床理解和患者护理。

Abstract: Phonotrauma refers to vocal fold tissue damage resulting from exposure to forces during voicing. It occurs on a continuum from mild to severe, and treatment options can vary based on severity. Assessment of severity involves a clinician's expert judgment, which is costly and can vary widely in reliability. In this work, we present the first method for automatically classifying phonotrauma severity from vocal fold images. To account for the ordinal nature of the labels, we adopt a widely used ordinal regression framework. To account for label uncertainty, we propose a novel modification to ordinal regression loss functions that enables them to operate on soft labels reflecting annotator rating distributions. Our proposed soft ordinal regression method achieves predictive performance approaching that of clinical experts, while producing well-calibrated uncertainty estimates. By providing an automated tool for phonotrauma severity assessment, our work can enable large-scale studies of phonotrauma, ultimately leading to improved clinical understanding and patient care.

</details>


### [24] [Right Looks, Wrong Reasons: Compositional Fidelity in Text-to-Image Generation](https://arxiv.org/abs/2511.10136)
*Mayank Vatsa,Aparna Bharati,Richa Singh*

Main category: cs.CV

TL;DR: 现有文生图模型在处理否定、计数和空间关系等逻辑组合时存在严重缺陷，即使模型在单一逻辑上表现良好，在组合使用时也会急剧退化。


<details>
  <summary>Details</summary>
Motivation: 评估现有文生图模型在处理逻辑组合（否定、计数、空间关系）方面的能力，并找出其失败原因。

Method: 分析了模型在处理单一逻辑和组合逻辑时的性能差异，并追溯了训练数据、模型架构和评估指标三个关键因素。

Result: 研究发现，模型在组合逻辑时性能急剧下降，主要由于训练数据缺乏否定示例、注意力机制不适合离散逻辑以及评估指标侧重视觉真实性而非逻辑约束。

Conclusion: 目前的模型和简单扩展无法解决逻辑组合问题，需要模型表征和推理方面的根本性突破。

Abstract: The architectural blueprint of today's leading text-to-image models contains a fundamental flaw: an inability to handle logical composition. This survey investigates this breakdown across three core primitives-negation, counting, and spatial relations. Our analysis reveals a dramatic performance collapse: models that are accurate on single primitives fail precipitously when these are combined, exposing severe interference. We trace this failure to three key factors. First, training data show a near-total absence of explicit negations. Second, continuous attention architectures are fundamentally unsuitable for discrete logic. Third, evaluation metrics reward visual plausibility over constraint satisfaction. By analyzing recent benchmarks and methods, we show that current solutions and simple scaling cannot bridge this gap. Achieving genuine compositionality, we conclude, will require fundamental advances in representation and reasoning rather than incremental adjustments to existing architectures.

</details>


### [25] [GEA: Generation-Enhanced Alignment for Text-to-Image Person Retrieval](https://arxiv.org/abs/2511.10154)
*Hao Zou,Runqing Zhang,Xue Zhou,Jianxiao Zou*

Main category: cs.CV

TL;DR: 该研究提出了一种名为生成增强对齐（GEA）的方法，通过生成式方法来解决文本到图像的行人检索（TIPR）问题，以克服现有方法在跨模态对齐和数据集过拟合方面的局限性。


<details>
  <summary>Details</summary>
Motivation: 现有的文本到图像行人检索（TIPR）方法在处理文本描述无法精确反映图像内容以及跨模态的鸿沟时存在不足，容易导致检索性能下降和数据集过拟合。

Method: GEA包含两个模块：1. 文本引导令牌增强（TGTE），利用扩散模型生成的图像作为中间语义表示，以弥合文本和视觉模式之间的差距。2. 生成式中间融合（GIF），融合了生成图像、原始图像和文本特征的交叉注意力，并通过三元组对齐损失生成统一的表示。

Result: 在CUHK-PEDES、RSTPReid和ICFG-PEDES三个公共TIPR数据集上进行的大量实验证明了GEA的有效性。

Conclusion: 所提出的GEA方法通过引入生成式中间表示，有效增强了文本和图像之间的跨模态对齐，提高了TIPR的性能。

Abstract: Text-to-Image Person Retrieval (TIPR) aims to retrieve person images based on natural language descriptions. Although many TIPR methods have achieved promising results, sometimes textual queries cannot accurately and comprehensively reflect the content of the image, leading to poor cross-modal alignment and overfitting to limited datasets. Moreover, the inherent modality gap between text and image further amplifies these issues, making accurate cross-modal retrieval even more challenging. To address these limitations, we propose the Generation-Enhanced Alignment (GEA) from a generative perspective. GEA contains two parallel modules: (1) Text-Guided Token Enhancement (TGTE), which introduces diffusion-generated images as intermediate semantic representations to bridge the gap between text and visual patterns. These generated images enrich the semantic representation of text and facilitate cross-modal alignment. (2) Generative Intermediate Fusion (GIF), which combines cross-attention between generated images, original images, and text features to generate a unified representation optimized by triplet alignment loss. We conduct extensive experiments on three public TIPR datasets, CUHK-PEDES, RSTPReid, and ICFG-PEDES, to evaluate the performance of GEA. The results justify the effectiveness of our method. More implementation details and extended results are available at https://github.com/sugelamyd123/Sup-for-GEA.

</details>


### [26] [Gradient-Guided Exploration of Generative Model's Latent Space for Controlled Iris Image Augmentations](https://arxiv.org/abs/2511.09749)
*Mahsa Mitcheff,Siamul Karim Khan,Adam Czajka*

Main category: cs.CV

TL;DR: 提出了一种新的虹膜图像生成方法，通过在生成模型的潜在空间中进行遍历，来合成具有相同身份但具有不同属性的虹膜图像，以增强数据集的多样性。


<details>
  <summary>Details</summary>
Motivation: 现有的虹膜识别和活体攻击检测方法需要多样化的数据集，但合成具有相同身份但属性可控的虹膜图像具有挑战性。

Method: 提出了一种基于潜在空间遍历的虹膜图像增强策略，通过梯度指导遍历过程，操纵几何、纹理或质量等属性，并保持身份不变。该方法可扩展至任何可微损失函数定义的属性，并可处理预训练GAN模型生成的图像或真实世界虹膜图像，还可通过GAN反演实现。

Result: 该方法能够生成具有相同身份但属性可控的虹膜图像，用于增强数据集的多样性。

Conclusion: 所提出的虹膜图像增强方法为生成多样化、属性可控的虹膜数据集提供了有效途径，有助于提升虹膜识别和活体攻击检测的可靠性。

Abstract: Developing reliable iris recognition and presentation attack detection methods requires diverse datasets that capture realistic variations in iris features and a wide spectrum of anomalies. Because of the rich texture of iris images, which spans a wide range of spatial frequencies, synthesizing same-identity iris images while controlling specific attributes remains challenging. In this work, we introduce a new iris image augmentation strategy by traversing a generative model's latent space toward latent codes that represent same-identity samples but with some desired iris image properties manipulated. The latent space traversal is guided by a gradient of specific geometrical, textural, or quality-related iris image features (e.g., sharpness, pupil size, iris size, or pupil-to-iris ratio) and preserves the identity represented by the image being manipulated. The proposed approach can be easily extended to manipulate any attribute for which a differentiable loss term can be formulated. Additionally, our approach can use either randomly generated images using either a pre-train GAN model or real-world iris images. We can utilize GAN inversion to project any given iris image into the latent space and obtain its corresponding latent code.

</details>


### [27] [Utilizing a Geospatial Foundation Model for Coastline Delineation in Small Sandy Islands](https://arxiv.org/abs/2511.10177)
*Tishya Chhabra,Manisha Bajpai,Walter Zesk,Skylar Tibbits*

Main category: cs.CV

TL;DR: NASA和IBM的Prithvi-EO-2.0地理空间基础模型在马尔代夫小沙岛的海岸线描绘任务上表现出强大的迁移学习能力，即使在仅使用5张图像进行微调的情况下，也能取得高精度（F1=0.94, IoU=0.79），预示着该模型在数据稀疏地区进行海岸监测的潜力。


<details>
  <summary>Details</summary>
Motivation: 评估NASA和IBM的Prithvi-EO-2.0地理空间基础模型在利用卫星图像描绘小沙岛海岸线方面的性能。

Method: 1. 收集并标注了225张马尔代夫两个岛屿的多光谱图像数据集，并公开该数据集。
2. 在该数据集上对Prithvi-300M和Prithvi-600M两个参数版本的模型进行了微调，训练集大小从5张到181张不等。
3. 评估模型在海岸线描绘任务上的表现。

Result: Prithvi模型即使在仅使用5张训练图像的情况下，也能在海岸线描绘任务上达到很高的性能，F1得分为0.94，IoU得分为0.79。

Conclusion: Prithvi模型展现出强大的迁移学习能力，证明了其在数据稀疏地区支持海岸监测的巨大潜力。

Abstract: We present an initial evaluation of NASA and IBM's Prithvi-EO-2.0 geospatial foundation model on shoreline delineation of small sandy islands using satellite images. We curated and labeled a dataset of 225 multispectral images of two Maldivian islands, which we publicly release, and fine-tuned both the 300M and 600M parameter versions of Prithvi on training subsets ranging from 5 to 181 images. Our experiments show that even with as few as 5 training images, the models achieve high performance (F1 of 0.94, IoU of 0.79). Our results demonstrate the strong transfer learning capability of Prithvi, underscoring the potential of such models to support coastal monitoring in data-poor regions.

</details>


### [28] [FineSkiing: A Fine-grained Benchmark for Skiing Action Quality Assessment](https://arxiv.org/abs/2511.10250)
*Yongji Zhang,Siqi Li,Yue Gao,Yu Jiang*

Main category: cs.CV

TL;DR: 该论文提出了JudgeMind，一个用于空中滑雪动作质量评估（AQA）的新方法和数据集，通过对动作分阶段评分并引入专业裁判的判决逻辑来提高评分的准确性和可靠性。


<details>
  <summary>Details</summary>
Motivation: 现有AQA方法主要基于整个视频的特征进行评分，可解释性和可靠性有限，且现有数据集缺乏细粒度的评分注释。本文旨在解决这些问题。

Method: 提出一个名为JudgeMind的新AQA方法，该方法将动作视频分割为不同阶段并对每个阶段进行评分。集成了阶段感知特征增强和融合模块，以提升对特定阶段关键区域的感知能力，并增强对频繁视角切换的鲁棒性。此外，还提出了一种基于知识的、面向评分的解码器，以纳入可能的扣分项作为先验知识，从而进行更准确、更可靠的评分。

Result: 实验结果表明，所提出的JudgeMind方法在AQA任务上取得了最先进的性能。

Conclusion: JudgeMind方法通过模拟专业裁判的判决和评分思维，并结合细粒度的阶段评分和扣分项知识，显著提高了动作质量评估的性能和可靠性，并提出了首个包含细粒度子分数和扣分项注释的空中滑雪AQA数据集。

Abstract: Action Quality Assessment (AQA) aims to evaluate and score sports actions, which has attracted widespread interest in recent years. Existing AQA methods primarily predict scores based on features extracted from the entire video, resulting in limited interpretability and reliability. Meanwhile, existing AQA datasets also lack fine-grained annotations for action scores, especially for deduction items and sub-score annotations. In this paper, we construct the first AQA dataset containing fine-grained sub-score and deduction annotations for aerial skiing, which will be released as a new benchmark. For the technical challenges, we propose a novel AQA method, named JudgeMind, which significantly enhances performance and reliability by simulating the judgment and scoring mindset of professional referees. Our method segments the input action video into different stages and scores each stage to enhance accuracy. Then, we propose a stage-aware feature enhancement and fusion module to boost the perception of stage-specific key regions and enhance the robustness to visual changes caused by frequent camera viewpoints switching. In addition, we propose a knowledge-based grade-aware decoder to incorporate possible deduction items as prior knowledge to predict more accurate and reliable scores. Experimental results demonstrate that our method achieves state-of-the-art performance.

</details>


### [29] [H3Former: Hypergraph-based Semantic-Aware Aggregation via Hyperbolic Hierarchical Contrastive Loss for Fine-Grained Visual Classification](https://arxiv.org/abs/2511.10260)
*Yongji Zhang,Siqi Li,Kuiyang Huang,Yue Gao,Yu Jiang*

Main category: cs.CV

TL;DR: H3Former是一个新颖的token到region框架，利用高阶语义关系聚合局部细粒度表示和结构化region级建模，以解决细粒度视觉分类（FGVC）中的挑战。


<details>
  <summary>Details</summary>
Motivation: 现有的FGVC方法依赖特征选择或区域提议来定位判别性区域，但这些方法可能无法全面捕捉判别性线索并引入冗余。H3Former旨在通过利用高阶语义关系来克服这些限制。

Method: H3Former提出了一种名为语义感知聚合模块（SAAM）的新机制，该机制利用多尺度上下文线索在token之间动态构建加权超图，并通过超图卷积捕获高阶语义依赖性，将token特征聚合成区域级表示。此外，还引入了双曲分层对比损失（HHCL），在非欧几里得嵌入空间中强制执行分层语义约束，以增强类间可分离性和类内一致性。

Result: 在四个标准的FGVC基准测试上的综合实验证明了H3Former框架的优越性。

Conclusion: H3Former框架通过其创新的SAAM和HHCL机制，在细粒度视觉分类任务上取得了优越的性能。

Abstract: Fine-Grained Visual Classification (FGVC) remains a challenging task due to subtle inter-class differences and large intra-class variations. Existing approaches typically rely on feature-selection mechanisms or region-proposal strategies to localize discriminative regions for semantic analysis. However, these methods often fail to capture discriminative cues comprehensively while introducing substantial category-agnostic redundancy. To address these limitations, we propose H3Former, a novel token-to-region framework that leverages high-order semantic relations to aggregate local fine-grained representations with structured region-level modeling. Specifically, we propose the Semantic-Aware Aggregation Module (SAAM), which exploits multi-scale contextual cues to dynamically construct a weighted hypergraph among tokens. By applying hypergraph convolution, SAAM captures high-order semantic dependencies and progressively aggregates token features into compact region-level representations. Furthermore, we introduce the Hyperbolic Hierarchical Contrastive Loss (HHCL), which enforces hierarchical semantic constraints in a non-Euclidean embedding space. The HHCL enhances inter-class separability and intra-class consistency while preserving the intrinsic hierarchical relationships among fine-grained categories. Comprehensive experiments conducted on four standard FGVC benchmarks validate the superiority of our H3Former framework.

</details>


### [30] [Adaptive Residual-Update Steering for Low-Overhead Hallucination Mitigation in Large Vision Language Models](https://arxiv.org/abs/2511.10292)
*Zhengtao Zou,Ya Gao,Jiarui Guan,Bin Li,Pekka Marttinen*

Main category: cs.CV

TL;DR: LVLMs存在对象幻觉问题，现有方法计算开销大，RUDDER是一种低开销框架，通过CARD向量和自适应门控来解决此问题，在POPE和CHAIR基准测试中表现优异且延迟可忽略。


<details>
  <summary>Details</summary>
Motivation: 解决大型视觉语言模型（LVLM）在生成文本时出现的对象幻觉问题，并克服现有方法计算开销大的效率瓶颈。

Method: 提出了一种名为RUDDER（Residual-Update Directed DEcoding Regulation）的低开销框架。该框架包含两个关键创新：1. 语境激活残差方向（CARD）向量，从单次标准前向传播的自注意力层残差更新中提取。2. 贝叶斯启发的自适应门控，进行逐令牌注入，根据模型与视觉内容的偏差调整校正信号强度。

Result: 在POPE和CHAIR等关键幻觉基准测试中，RUDDER取得了与最先进方法相媲美的性能，同时计算延迟可忽略。

Conclusion: RUDDER是一种实用且有效的方法，可以在不显著牺牲效率的情况下提高LVLM的可靠性，解决了LVLM的对象幻觉问题和现有方法的效率瓶颈。

Abstract: Large Vision-Language Models (LVLMs) often suffer from object hallucination, generating text inconsistent with visual inputs, which can critically undermine their reliability. Existing inference-time interventions to mitigate this issue present a challenging trade-off: while methods that steer internal states or adjust output logits can be effective, they often incur substantial computational overhead, typically requiring extra forward passes. This efficiency bottleneck can limit their practicality for real-world, latency-sensitive deployments. In this work, we aim to address this trade-off with Residual-Update Directed DEcoding Regulation (RUDDER), a low-overhead framework that steers LVLMs towards visually-grounded generation. RUDDER is built on two key innovations: (1) Contextual Activation Residual Direction (CARD) vector, a per-sample visual evidence vector extracted from the residual update of a self-attention layer during a single, standard forward pass. (2) A Bayesian-inspired adaptive gate that performs token-wise injection, applying a corrective signal whose strength is conditioned on the model's deviation from the visual context. Extensive experiments on key hallucination benchmarks, including POPE and CHAIR, indicate that RUDDER achieves performance comparable to state-of-the-art methods while introducing negligible computational latency, validating RUDDER as a pragmatic and effective approach for improving LVLMs' reliability without a significant compromise on efficiency.

</details>


### [31] [Rethinking Visual Information Processing in Multimodal LLMs](https://arxiv.org/abs/2511.10301)
*Dongwan Kim,Viresh Ranjan,Takashi Nagata,Arnab Dhua,Amit Kumar K C*

Main category: cs.CV

TL;DR: LLaViT通过让LLM同时充当视觉编码器来改进视觉-语言任务，与LLaVA相比，在多个基准测试中表现更好。


<details>
  <summary>Details</summary>
Motivation: LLaVA架构在整合视觉特征方面存在固有的不匹配问题，这阻碍了其在视觉-语言任务中的有效性。

Method: LLaViT通过三个关键修改实现LLM的视觉编码功能：(1)为视觉模态学习单独的QKV投影，(2)实现视觉标记的双向注意力，(3)结合全局和局部视觉表示。

Result: LLaViT在多个基准测试中显著优于LLaVA，并且优于参数量为 LLaViT 两倍的模型。

Conclusion: LLaViT提供了一种更有效的视觉-语言建模方法，它利用LLM同时作为语言模型和视觉编码器。

Abstract: Despite the remarkable success of the LLaVA architecture for vision-language tasks, its design inherently struggles to effectively integrate visual features due to the inherent mismatch between text and vision modalities. We tackle this issue from a novel perspective in which the LLM not only serves as a language model but also a powerful vision encoder. To this end, we present LLaViT - Large Language Models as extended Vision Transformers - which enables the LLM to simultaneously function as a vision encoder through three key modifications: (1) learning separate QKV projections for vision modality, (2) enabling bidirectional attention on visual tokens, and (3) incorporating both global and local visual representations. Through extensive controlled experiments on a wide range of LLMs, we demonstrate that LLaViT significantly outperforms the baseline LLaVA method on a multitude of benchmarks, even surpassing models with double its parameter count, establishing a more effective approach to vision-language modeling.

</details>


### [32] [Revisiting Evaluation of Deep Neural Networks for Pedestrian Detection](https://arxiv.org/abs/2511.10308)
*Patrick Feifel,Benedikt Franke,Frank Bonarens,Frank Köster,Arne Raulf,Friedhelm Schwenker*

Main category: cs.CV

TL;DR: 现有行人检测的评估指标无法真实评估深度学习模型性能，本文提出新的评估方法，细化了错误分类，并据此提出新的评估指标，实现了在CityPersons-reasonable上的SOTA。


<details>
  <summary>Details</summary>
Motivation: 当前行人检测的性能评估指标存在不足，无法真实反映深度学习模型在实际场景中的表现，特别是在区分不同类型的检测错误方面。

Method: 提出八种不同的行人检测错误类别，并据此设计新的性能评估指标。使用这些新指标对不同的骨干网络进行了比较，以评估它们在安全关键性能方面的细粒度和鲁棒性。

Result: 在CityPersons-reasonable数据集上，未使用额外训练数据，通过一个简化的APD 架构，实现了SOTA性能。

Conclusion: 新的评估指标和错误分类方法能够提供比现有方法更细粒度、更鲁棒的模型比较，尤其是在安全关键性能方面，有助于未来行人检测模型的研究和发展。

Abstract: Reliable pedestrian detection represents a crucial step towards automated driving systems. However, the current performance benchmarks exhibit weaknesses. The currently applied metrics for various subsets of a validation dataset prohibit a realistic performance evaluation of a DNN for pedestrian detection. As image segmentation supplies fine-grained information about a street scene, it can serve as a starting point to automatically distinguish between different types of errors during the evaluation of a pedestrian detector. In this work, eight different error categories for pedestrian detection are proposed and new metrics are proposed for performance comparison along these error categories. We use the new metrics to compare various backbones for a simplified version of the APD, and show a more fine-grained and robust way to compare models with each other especially in terms of safety-critical performance. We achieve SOTA on CityPersons-reasonable (without extra training data) by using a rather simple architecture.

</details>


### [33] [Depth-Consistent 3D Gaussian Splatting via Physical Defocus Modeling and Multi-View Geometric Supervision](https://arxiv.org/abs/2511.10316)
*Yu Deng,Baozhu Zhao,Junyan Su,Xiaohan Zhang,Qi Liu*

Main category: cs.CV

TL;DR: 本研究提出了一种新的三维重建框架，通过结合景深监督和多视图一致性监督来解决深度变化大的场景重建难题，提高了深度保真度和重建质量。


<details>
  <summary>Details</summary>
Motivation: 现有方法在处理近远景深度差异过大的场景时，近景结构退化和远景深度估计不准的问题无法同时解决，因此需要新的方法来同时处理这两个问题。

Method: 本研究提出了一种新的计算框架，结合了景深监督和多视图一致性监督。景深监督部分：1. 使用能恢复尺度的单目深度估计器（如Metric3D）生成深度先验。2. 利用离焦卷积合成物理上准确的失焦图像。3. 通过新颖的景深损失强制执行几何一致性。多视图一致性监督部分：1. 利用基于LoFTR的半稠密特征匹配。2. 通过对可靠匹配点进行最小二乘法优化来强制执行深度一致性。

Result: 所提出的方法在Waymo公开数据集上，相比现有最优方法，PSNR提高了0.8 dB，证明了其在深度保真度上的优越性。

Conclusion: 本框架结合了物理成像原理和基于学习的深度正则化，为城市环境中复杂深度分层的场景提供了可扩展的三维重建解决方案。

Abstract: Three-dimensional reconstruction in scenes with extreme depth variations remains challenging due to inconsistent supervisory signals between near-field and far-field regions. Existing methods fail to simultaneously address inaccurate depth estimation in distant areas and structural degradation in close-range regions. This paper proposes a novel computational framework that integrates depth-of-field supervision and multi-view consistency supervision to advance 3D Gaussian Splatting. Our approach comprises two core components: (1) Depth-of-field Supervision employs a scale-recovered monocular depth estimator (e.g., Metric3D) to generate depth priors, leverages defocus convolution to synthesize physically accurate defocused images, and enforces geometric consistency through a novel depth-of-field loss, thereby enhancing depth fidelity in both far-field and near-field regions; (2) Multi-View Consistency Supervision employing LoFTR-based semi-dense feature matching to minimize cross-view geometric errors and enforce depth consistency via least squares optimization of reliable matched points. By unifying defocus physics with multi-view geometric constraints, our method achieves superior depth fidelity, demonstrating a 0.8 dB PSNR improvement over the state-of-the-art method on the Waymo Open Dataset. This framework bridges physical imaging principles and learning-based depth regularization, offering a scalable solution for complex depth stratification in urban environments.

</details>


### [34] [SHRUG-FM: Reliability-Aware Foundation Models for Earth Observation](https://arxiv.org/abs/2511.10370)
*Kai-Hendrik Cohrs,Zuzanna Osika,Maria Gonzalez-Calabuig,Vishal Nedungadi,Ruben Cartuyvels,Steffen Knoblauch,Joppe Massant,Shruti Nath,Patrick Ebel,Vasileios Sitokonstantinou*

Main category: cs.CV

TL;DR: SHRUG-FM是一个用于提高地球观测地理空间基础模型（GFM）在未充分代表性环境中的可靠性的框架，它结合了输入空间和嵌入空间中的 OOD 检测以及特定任务的预测不确定性。


<details>
  <summary>Details</summary>
Motivation: 地理空间基础模型（GFM）在未充分代表的环境中表现不可靠。

Method: SHRUG-FM 框架整合了三种互补信号：输入空间中的 OOD 检测、嵌入空间中的 OOD 检测以及特定任务的预测不确定性。

Result: SHRUG-FM 在烧伤疤痕分割任务中，OOD 分数与特定环境条件下的性能下降相关，而不确定性标志有助于剔除大量性能较差的预测。这些标志与 HydroATLAS 的土地覆盖属性相关联，表明模型在低海拔地区和主要河流区域的失败并非随机，可能与预训练数据不足有关。

Conclusion: SHRUG-FM 为 GFM 在气候敏感应用中的安全和可解释性部署提供了一条途径，有助于弥合基准性能与真实世界可靠性之间的差距。

Abstract: Geospatial foundation models for Earth observation often fail to perform reliably in environments underrepresented during pretraining. We introduce SHRUG-FM, a framework for reliability-aware prediction that integrates three complementary signals: out-of-distribution (OOD) detection in the input space, OOD detection in the embedding space and task-specific predictive uncertainty. Applied to burn scar segmentation, SHRUG-FM shows that OOD scores correlate with lower performance in specific environmental conditions, while uncertainty-based flags help discard many poorly performing predictions. Linking these flags to land cover attributes from HydroATLAS shows that failures are not random but concentrated in certain geographies, such as low-elevation zones and large river areas, likely due to underrepresentation in pretraining data. SHRUG-FM provides a pathway toward safer and more interpretable deployment of GFMs in climate-sensitive applications, helping bridge the gap between benchmark performance and real-world reliability.

</details>


### [35] [Physics informed Transformer-VAE for biophysical parameter estimation: PROSAIL model inversion in Sentinel-2 imagery](https://arxiv.org/abs/2511.10387)
*Prince Mensah,Pelumi Victor Aderinto,Ibrahim Salihu Yusuf,Arnu Pretorius*

Main category: cs.CV

TL;DR: 提出一种物理信息Transformer-VAE模型，利用模拟数据反演PROSAIL模型，用于从Sentinel-2数据中同时估算叶面积指数和叶绿素含量等关键植被参数，性能可与使用真实图像训练的先进方法相媲美，且无需实地标签或实景图像校准。


<details>
  <summary>Details</summary>
Motivation: 准确地从卫星图像中检索植被生物物理变量对于生态系统监测和农业管理至关重要。

Method: 提出一种物理信息Transformer-VAE架构，将PROSAIL模型作为可微分的物理解码器，仅使用模拟数据进行训练，用于同时估算关键的冠层参数。

Result: 在FRM4Veg和BelSAR真实野外数据集上，该模型在叶面积指数（LAI）和冠层叶绿素含量（CCC）的检索方面，达到了与使用真实Sentinel-2数据训练的模型相当的准确度。

Conclusion: 将物理模型与深度网络相结合，可以改进辐射传输模型（RTM）的反演，为大规模、物理约束的植被特征遥感提供了新的前景。该方法是一种经济高效且自监督的解决方案，可用于全球植被监测。

Abstract: Accurate retrieval of vegetation biophysical variables from satellite imagery is crucial for ecosystem monitoring and agricultural management. In this work, we propose a physics-informed Transformer-VAE architecture to invert the PROSAIL radiative transfer model for simultaneous estimation of key canopy parameters from Sentinel-2 data. Unlike previous hybrid approaches that require real satellite images for self-supevised training. Our model is trained exclusively on simulated data, yet achieves performance on par with state-of-the-art methods that utilize real imagery. The Transformer-VAE incorporates the PROSAIL model as a differentiable physical decoder, ensuring that inferred latent variables correspond to physically plausible leaf and canopy properties. We demonstrate retrieval of leaf area index (LAI) and canopy chlorophyll content (CCC) on real-world field datasets (FRM4Veg and BelSAR) with accuracy comparable to models trained with real Sentinel-2 data. Our method requires no in-situ labels or calibration on real images, offering a cost-effective and self-supervised solution for global vegetation monitoring. The proposed approach illustrates how integrating physical models with advanced deep networks can improve the inversion of RTMs, opening new prospects for large-scale, physically-constrained remote sensing of vegetation traits.

</details>


### [36] [DermAI: Clinical dermatology acquisition through quality-driven image collection for AI classification in mobile](https://arxiv.org/abs/2511.10367)
*Thales Bezerra,Emanoel Thyago,Kelvin Cunha,Rodrigo Abreu,Fábio Papais,Francisco Mauro,Natália Lopes,Érico Medeiros,Jéssica Guido,Shirley Cruz,Paulo Borba,Tsang Ing Ren*

Main category: cs.CV

TL;DR: AI 皮肤病学应用受限于数据集偏差、图像质量和验证不足。DermAI 是一款轻量级、基于智能手机的应用程序，可在常规咨询中进行实时皮肤病灶的捕获、注释和分类。它能在设备上进行质量检查和模型本地化调整，并使用包含各种肤色、种族和设备来源的 DermAI 临床数据集。与仅使用公共数据集相比，使用本地数据进行微调可提高模型性能，强调了标准化、多样化数据收集对医疗保健和机器学习的重要性。


<details>
  <summary>Details</summary>
Motivation: AI 皮肤病学应用因数据集偏差、图像质量和验证不足而受到限制。

Method: 开发了一款名为 DermAI 的轻量级、基于智能手机的应用程序，可实现实时皮肤病灶捕获、注释和分类。该应用程序能在设备上进行质量检查和模型本地化调整。收集了一个包含各种肤色、种族和设备来源的 DermAI 临床数据集。

Result: 在初步实验中，使用公共数据集训练的模型无法泛化到 DermAI 数据集，而使用本地数据进行微调可提高性能。

Conclusion: 标准化、多样化的数据收集对于满足医疗保健需求和机器学习发展至关重要。

Abstract: AI-based dermatology adoption remains limited by biased datasets, variable image quality, and limited validation. We introduce DermAI, a lightweight, smartphone-based application that enables real-time capture, annotation, and classification of skin lesions during routine consultations. Unlike prior dermoscopy-focused tools, DermAI performs on-device quality checks, and local model adaptation. The DermAI clinical dataset, encompasses a wide range of skin tones, ethinicity and source devices. In preliminary experiments, models trained on public datasets failed to generalize to our samples, while fine-tuning with local data improved performance. These results highlight the importance of standardized, diverse data collection aligned with healthcare needs and oriented to machine learning development.

</details>


### [37] [OpenSR-SRGAN: A Flexible Super-Resolution Framework for Multispectral Earth Observation Data](https://arxiv.org/abs/2511.10461)
*Simon Donike,Cesar Aybar,Julio Contreras,Luis Gómez-Chova*

Main category: cs.CV

TL;DR: OpenSR-SRGAN是一个用于地球观测的开源、模块化、配置驱动的单一图像超分辨率框架，旨在简化SRGAN模型的使用、配置和部署。


<details>
  <summary>Details</summary>
Motivation: 为地球观测领域的单图像超分辨率任务提供一个易于配置、扩展和应用的统一框架，降低研究人员和实践者使用SRGAN模型的门槛。

Method: 通过配置文件统一实现和暴露SRGAN模型的各个组成部分（生成器、判别器、损失函数、训练计划），允许用户无需修改模型代码即可切换架构、缩放因子和波段设置，并提供现成的配置、默认设置以及日志记录、验证和大场景推理的内置功能。

Result: 开发了一个开源、模块化的框架，并提供了针对常见遥感场景的现成配置和默认设置，支持可重复的模型比较和跨数据集的超分辨率部署。

Conclusion: OpenSR-SRGAN通过将基于GAN的超分辨率转变为一个驱动式工作流程，极大地降低了研究人员和实践者在多光谱卫星数据上进行实验、比较模型和部署超分辨率管线的入门门槛。

Abstract: We present OpenSR-SRGAN, an open and modular framework for single-image super-resolution in Earth Observation. The software provides a unified implementation of SRGAN-style models that is easy to configure, extend, and apply to multispectral satellite data such as Sentinel-2. Instead of requiring users to modify model code, OpenSR-SRGAN exposes generators, discriminators, loss functions, and training schedules through concise configuration files, making it straightforward to switch between architectures, scale factors, and band setups. The framework is designed as a practical tool and benchmark implementation rather than a state-of-the-art model. It ships with ready-to-use configurations for common remote sensing scenarios, sensible default settings for adversarial training, and built-in hooks for logging, validation, and large-scene inference. By turning GAN-based super-resolution into a configuration-driven workflow, OpenSR-SRGAN lowers the entry barrier for researchers and practitioners who wish to experiment with SRGANs, compare models in a reproducible way, and deploy super-resolution pipelines across diverse Earth-observation datasets.

</details>


### [38] [MonkeyOCR v1.5 Technical Report: Unlocking Robust Document Parsing for Complex Patterns](https://arxiv.org/abs/2511.10390)
*Jiarui Zhang,Yuliang Liu,Zijun Wu,Guosheng Pang,Zhili Ye,Yupei Zhong,Junteng Ma,Tao Wei,Haiyang Xu,Weikai Chen,Zeen Wang,Qiangjun Ji,Fanxi Zhou,Qi Zhang,Yuanrui Hu,Jiahao Liu,Zhang Li,Ziyang Zhang,Qiang Liu,Xiang Bai*

Main category: cs.CV

TL;DR: MonkeyOCR v1.5是一个统一的视觉-语言框架，通过两阶段解析管道增强了文档布局理解和内容识别能力，解决了复杂文档布局的挑战，并在OmniDocBench v1.5上取得了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 现实世界的文档通常具有复杂的布局，如多级表格、嵌入的图像或公式以及跨页结构，这给现有的OCR系统带来了挑战。

Method: MonkeyOCR v1.5采用两阶段解析流程：第一阶段使用大型多模态模型联合预测文档布局和阅读顺序；第二阶段对检测区域内的文本、公式和表格进行局部识别。此外，还提出了基于视觉一致性的强化学习方案、图像解耦表格解析和类型引导表格合并模块来处理复杂表格。

Result: 在OmniDocBench v1.5上的实验表明，MonkeyOCR v1.5的性能优于PPOCR-VL和MinerU 2.5，在视觉复杂文档场景下表现出卓越的鲁棒性。

Conclusion: MonkeyOCR v1.5通过其创新的方法，在文档智能的核心任务——文档解析方面取得了最先进的成果，尤其是在处理复杂和视觉上具有挑战性的文档方面。

Abstract: Document parsing is a core task in document intelligence, supporting applications such as information extraction, retrieval-augmented generation, and automated document analysis. However, real-world documents often feature complex layouts with multi-level tables, embedded images or formulas, and cross-page structures, which remain challenging for existing OCR systems. We introduce MonkeyOCR v1.5, a unified vision-language framework that enhances both layout understanding and content recognition through a two-stage parsing pipeline. The first stage employs a large multimodal model to jointly predict document layout and reading order, leveraging visual information to ensure structural and sequential consistency. The second stage performs localized recognition of text, formulas, and tables within detected regions, maintaining high visual fidelity while reducing error propagation. To address complex table structures, we propose a visual consistency-based reinforcement learning scheme that evaluates recognition quality via render-and-compare alignment, improving structural accuracy without manual annotations. Additionally, two specialized modules, Image-Decoupled Table Parsing and Type-Guided Table Merging, are introduced to enable reliable parsing of tables containing embedded images and reconstruction of tables crossing pages or columns. Comprehensive experiments on OmniDocBench v1.5 demonstrate that MonkeyOCR v1.5 achieves state-of-the-art performance, outperforming PPOCR-VL and MinerU 2.5 while showing exceptional robustness in visually complex document scenarios.

</details>


### [39] [Benchmarking Diversity in Image Generation via Attribute-Conditional Human Evaluation](https://arxiv.org/abs/2511.10547)
*Isabela Albuquerque,Ira Ktena,Olivia Wiles,Ivana Kajić,Amal Rannen-Triki,Cristina Vasconcelos,Aida Nematzadeh*

Main category: cs.CV

TL;DR: T2I模型在生成多样性方面存在不足，本文提出了一个框架来评估和提高T2I模型的多样性。


<details>
  <summary>Details</summary>
Motivation: 当前T2I模型在生成质量方面虽有进步，但往往缺乏多样性，导致输出同质化。因此，需要对T2I模型进行鲁棒的多样性评估。

Method: 本文提出的框架通过评估个体概念及其相关变化因素来系统地评估多样性。框架包含：1.用于细致评估多样性的人类评估模板；2.包含不同概念及其变化因素（如提示：一个苹果的图像，变化因素：颜色）的提示集；3.通过二项检验比较人类注释中模型的方法。此外，还比较了用于多样性测量的各种图像嵌入。

Result: 通过该框架，可以对T2I模型按多样性进行排名，并识别出它们在哪些类别中表现不佳。该方法能够确定T2I模型的类别级多样性，并为评估T2I模型的多样性提供见解。

Conclusion: 该研究提供了一种鲁棒的方法和深刻的见解，为提高T2I模型的多样性和开发评估指标铺平了道路。

Abstract: Despite advances in generation quality, current text-to-image (T2I) models often lack diversity, generating homogeneous outputs. This work introduces a framework to address the need for robust diversity evaluation in T2I models. Our framework systematically assesses diversity by evaluating individual concepts and their relevant factors of variation. Key contributions include: (1) a novel human evaluation template for nuanced diversity assessment; (2) a curated prompt set covering diverse concepts with their identified factors of variation (e.g. prompt: An image of an apple, factor of variation: color); and (3) a methodology for comparing models in terms of human annotations via binomial tests.
  Furthermore, we rigorously compare various image embeddings for diversity measurement. Notably, our principled approach enables ranking of T2I models by diversity, identifying categories where they particularly struggle. This research offers a robust methodology and insights, paving the way for improvements in T2I model diversity and metric development.

</details>


### [40] [Multitask GLocal OBIA-Mamba for Sentinel-2 Landcover Mapping](https://arxiv.org/abs/2511.10604)
*Zack Dewis,Yimin Zhu,Zhengsen Xu,Mabel Heffring,Saeid Taleghanidoozdoozan,Kaylee Xiao,Motasem Alkayid,Lincoln Linlin Xu*

Main category: cs.CV

TL;DR: 利用OBIA-Mamba和GLocal双分支CNN-Mamba架构，通过多任务优化框架提升Sentinel-2图像的土地利用和土地覆盖分类精度。


<details>
  <summary>Details</summary>
Motivation: Sentinel-2数据的空间异质性、上下文信息缺乏和光谱模糊性给土地利用和土地覆盖（LULC）分类带来了挑战。

Method: 提出了一种新颖的多任务Glocal OBIA-Mamba（MSOM）方法，包括：1. 设计了一个基于对象的OBIA-Mamba模型，使用超像素作为Mamba的token以减少冗余计算并保留细节。2. 设计了一个全局-局部（GLocal）双分支CNN-Mamba架构，用于同时处理局部空间细节和全局上下文信息。3. 设计了一个多任务优化框架，使用双重损失函数来平衡局部精度和全局一致性。

Result: 所提出的方法在加拿大阿尔伯塔省的Sentinel-2影像上进行了测试，与几种先进的分类方法进行了比较，结果表明，与现有技术相比，该方法实现了更高的分类精度和更精细的细节。

Conclusion: MSOM方法能够有效提高Sentinel-2图像的土地利用和土地覆盖分类精度，并在局部细节和全局一致性之间取得良好平衡。

Abstract: Although Sentinel-2 based land use and land cover (LULC) classification is critical for various environmental monitoring applications, it is a very difficult task due to some key data challenges (e.g., spatial heterogeneity, context information, signature ambiguity). This paper presents a novel Multitask Glocal OBIA-Mamba (MSOM) for enhanced Sentinel-2 classification with the following contributions. First, an object-based image analysis (OBIA) Mamba model (OBIA-Mamba) is designed to reduce redundant computation without compromising fine-grained details by using superpixels as Mamba tokens. Second, a global-local (GLocal) dual-branch convolutional neural network (CNN)-mamba architecture is designed to jointly model local spatial detail and global contextual information. Third, a multitask optimization framework is designed to employ dual loss functions to balance local precision with global consistency. The proposed approach is tested on Sentinel-2 imagery in Alberta, Canada, in comparison with several advanced classification approaches, and the results demonstrate that the proposed approach achieves higher classification accuracy and finer details that the other state-of-the-art methods.

</details>


### [41] [Utility of Pancreas Surface Lobularity as a CT Biomarker for Opportunistic Screening of Type 2 Diabetes](https://arxiv.org/abs/2511.10484)
*Tejas Sudharshan Mathai,Anisa V. Prasad,Xinya Wang,Praveen T. S. Balamuralikrishna,Yan Zhuang,Abhinav Suri,Jianfei Liu,Perry J. Pickhardt,Ronald M. Summers*

Main category: cs.CV

TL;DR: 该研究提出了一种自动分割胰腺并利用胰腺表面小叶化（PSL）来筛查2型糖尿病（T2DM）的方法。结果显示，T2DM患者的PSL较高，并且基于CT生物标志物的多变量模型在预测T2DM方面表现出高精度（AUC为0.90）。


<details>
  <summary>Details</summary>
Motivation: 2型糖尿病（T2DM）的早期检测至关重要，因为它可以改变胰腺功能并导致器官损伤。尽管已有研究关注胰腺体积和脂肪含量与T2DM的关系，但胰腺表面小叶化（PSL）在T2DM患者中的作用尚未得到充分研究。

Method: 研究人员开发了一种全自动方法来分割胰腺及其他腹部结构，并提取CT影像生物标志物，以进行机会性T2DM筛查。他们使用了四种基于深度学习的模型对584名患者的内部数据集进行胰腺分割，并自动检测PSL。

Result: 在分割模型中，PancAP模型获得了最高的Dice分数（0.79±0.17）和最低的ASSD误差（1.94±2.63 mm）。T2DM患者的PSL（4.26±8.32）显著高于非糖尿病患者（3.19±3.62）（p=0.01）。在预测T2DM方面，使用CT生物标志物训练的多变量模型达到了0.90的AUC、66.7%的灵敏度和91.9%的特异度。

Conclusion: 研究结果表明，PSL可用于T2DM筛查，并可能有助于预测T2DM的早期发病。

Abstract: Type 2 Diabetes Mellitus (T2DM) is a chronic metabolic disease that affects millions of people worldwide. Early detection is crucial as it can alter pancreas function through morphological changes and increased deposition of ectopic fat, eventually leading to organ damage. While studies have shown an association between T2DM and pancreas volume and fat content, the role of increased pancreatic surface lobularity (PSL) in patients with T2DM has not been fully investigated. In this pilot work, we propose a fully automated approach to delineate the pancreas and other abdominal structures, derive CT imaging biomarkers, and opportunistically screen for T2DM. Four deep learning-based models were used to segment the pancreas in an internal dataset of 584 patients (297 males, 437 non-diabetic, age: 45$\pm$15 years). PSL was automatically detected and it was higher for diabetic patients (p=0.01) at 4.26 $\pm$ 8.32 compared to 3.19 $\pm$ 3.62 for non-diabetic patients. The PancAP model achieved the highest Dice score of 0.79 $\pm$ 0.17 and lowest ASSD error of 1.94 $\pm$ 2.63 mm (p$<$0.05). For predicting T2DM, a multivariate model trained with CT biomarkers attained 0.90 AUC, 66.7\% sensitivity, and 91.9\% specificity. Our results suggest that PSL is useful for T2DM screening and could potentially help predict the early onset of T2DM.

</details>


### [42] [A Style is Worth One Code: Unlocking Code-to-Style Image Generation with Discrete Style Space](https://arxiv.org/abs/2511.10555)
*Huijie Liu,Shuhao Cui,Haoxiang Cao,Shuai Ma,Kai Wu,Guoliang Kang*

Main category: cs.CV

TL;DR: 该论文提出了一种名为CoTyle的新方法，用于仅通过数值风格码生成具有新颖且一致视觉风格的图像，解决了现有方法在风格一致性、创意和复杂性方面的局限性。


<details>
  <summary>Details</summary>
Motivation: 生成新颖且风格一致的视觉风格仍然是一个挑战，现有方法在风格控制、创意和复杂性方面存在不足。

Method: CoTyle首先从图像集合中训练一个离散风格码本以提取风格嵌入，然后将这些嵌入作为文本到图像扩散模型（T2I-DM）的条件来生成风格化图像。接着，在离散风格嵌入上训练一个自回归风格生成器来建模其分布，从而合成新的风格嵌入。在推理时，数值风格码通过风格生成器映射到唯一的风格嵌入，该嵌入用于指导T2I-DM生成相应风格的图像。

Result: 实验证明，CoTyle能够有效地将数值代码转化为风格控制器，实现了“一码一风格”的目标，并展现了极大的简单性和多样性。

Conclusion: CoTyle是第一个开源的数值风格码到风格图像生成方法，通过数值风格码实现了新颖、一致且可复现的图像风格生成。

Abstract: Innovative visual stylization is a cornerstone of artistic creation, yet generating novel and consistent visual styles remains a significant challenge. Existing generative approaches typically rely on lengthy textual prompts, reference images, or parameter-efficient fine-tuning to guide style-aware image generation, but often struggle with style consistency, limited creativity, and complex style representations. In this paper, we affirm that a style is worth one numerical code by introducing the novel task, code-to-style image generation, which produces images with novel, consistent visual styles conditioned solely on a numerical style code. To date, this field has only been primarily explored by the industry (e.g., Midjourney), with no open-source research from the academic community. To fill this gap, we propose CoTyle, the first open-source method for this task. Specifically, we first train a discrete style codebook from a collection of images to extract style embeddings. These embeddings serve as conditions for a text-to-image diffusion model (T2I-DM) to generate stylistic images. Subsequently, we train an autoregressive style generator on the discrete style embeddings to model their distribution, allowing the synthesis of novel style embeddings. During inference, a numerical style code is mapped to a unique style embedding by the style generator, and this embedding guides the T2I-DM to generate images in the corresponding style. Unlike existing methods, our method offers unparalleled simplicity and diversity, unlocking a vast space of reproducible styles from minimal input. Extensive experiments validate that CoTyle effectively turns a numerical code into a style controller, demonstrating a style is worth one code.

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [43] [Omnilingual ASR: Open-Source Multilingual Speech Recognition for 1600+ Languages](https://arxiv.org/abs/2511.09690)
*Omnilingual ASR team,Gil Keren,Artyom Kozhevnikov,Yen Meng,Christophe Ropers,Matthew Setzler,Skyler Wang,Ife Adebara,Michael Auli,Can Balioglu,Kevin Chan,Chierh Cheng,Joe Chuang,Caley Droof,Mark Duppenthaler,Paul-Ambroise Duquenne,Alexander Erben,Cynthia Gao,Gabriel Mejia Gonzalez,Kehan Lyu,Sagar Miglani,Vineel Pratap,Kaushik Ram Sadagopan,Safiyyah Saleem,Arina Turkatenko,Albert Ventayol-Boada,Zheng-Xin Yong,Yu-An Chung,Jean Maillard,Rashel Moritz,Alexandre Mourachko,Mary Williamson,Shireen Yates*

Main category: cs.CL

TL;DR: Omnilingual ASR 是一个可扩展的 ASR 系统，可为 1600 多种语言提供支持，包括 500 多种以前不支持的语言，而只需少量数据。


<details>
  <summary>Details</summary>
Motivation: 现有的自动语音识别 (ASR) 系统在支持的语言数量上有限，并且在扩展到低资源语言时成本高昂且面临伦理问题。需要一个可扩展的 ASR 系统来解决这些限制。

Method: 该研究引入了 Omnilingual ASR，这是一个具有可扩展性设计的 ASR 系统。它利用 7B 参数进行自监督预训练，以学习语音表示，并采用受 LLM 启发的解码器的编码器-解码器架构进行零样本泛化。该系统在包含公共资源和社区采购数据的海量多样化语料库上进行训练。

Result: Omnilingual ASR 成功扩展到 1600 多种语言，包括 500 多种以前由 ASR 服务过的语言。自动评估显示，与之前的系统相比，在低资源条件下具有显著的优势和强大的泛化能力。该系统发布了各种模型，从 300M 到 7B 参数。

Conclusion: Omnilingual ASR 是一个可扩展的、支持多种语言的 ASR 系统，它解决了现有系统的局限性，并为低资源语言的 ASR 带来了重大进展。通过开源模型和工具，该系统旨在降低研究人员和社区的进入门槛，促进新的参与形式，并具有重大的社会影响力。

Abstract: Automatic speech recognition (ASR) has advanced in high-resource languages, but most of the world's 7,000+ languages remain unsupported, leaving thousands of long-tail languages behind. Expanding ASR coverage has been costly and limited by architectures that restrict language support, making extension inaccessible to most--all while entangled with ethical concerns when pursued without community collaboration. To transcend these limitations, we introduce Omnilingual ASR, the first large-scale ASR system designed for extensibility. Omnilingual ASR enables communities to introduce unserved languages with only a handful of data samples. It scales self-supervised pre-training to 7B parameters to learn robust speech representations and introduces an encoder-decoder architecture designed for zero-shot generalization, leveraging a LLM-inspired decoder. This capability is grounded in a massive and diverse training corpus; by combining breadth of coverage with linguistic variety, the model learns representations robust enough to adapt to unseen languages. Incorporating public resources with community-sourced recordings gathered through compensated local partnerships, Omnilingual ASR expands coverage to over 1,600 languages, the largest such effort to date--including over 500 never before served by ASR. Automatic evaluations show substantial gains over prior systems, especially in low-resource conditions, and strong generalization. We release Omnilingual ASR as a family of models, from 300M variants for low-power devices to 7B for maximum accuracy. We reflect on the ethical considerations shaping this design and conclude by discussing its societal impact. In particular, we highlight how open-sourcing models and tools can lower barriers for researchers and communities, inviting new forms of participation. Open-source artifacts are available at https://github.com/facebookresearch/omnilingual-asr.

</details>


### [44] [Order Matters: Rethinking Prompt Construction in In-Context Learning](https://arxiv.org/abs/2511.09700)
*Warren Li,Yiqian Wang,Zihan Wang,Jingbo Shang*

Main category: cs.CL

TL;DR: in-context learning (ICL) 任务表现受示例选择和顺序的影响，而以往研究更侧重于示例选择。


<details>
  <summary>Details</summary>
Motivation: 在 in-context learning (ICL) 中，示例的选择和顺序对模型表现的影响被认为是不对称的，以往的研究都直觉地认为示例的选择更为重要，而忽略了示例的顺序。

Method: 通过在分类和生成任务上进行一系列受控实验，对比了示例选择和顺序对不同参数规模（0.5B至27B）的开源模型家族及GPT-3.5模型表现的影响，并探索了仅使用开发集识别出有效示例顺序的方法。

Result: 研究发现，不同示例顺序导致的性能差异与更换示例集造成的性能差异相当。此外，仅使用开发集就能找到接近最优顺序的排序方法，从而获得接近测试标签最优排序的性能。

Conclusion: 示例的选择和顺序在ICL提示设计中同等重要且相互关联，需要重新审视ICL中的相关假设。

Abstract: In-context learning (ICL) enables large language models to perform new tasks by conditioning on a sequence of examples. Most prior work reasonably and intuitively assumes that which examples are chosen has a far greater effect on performance than how those examples are ordered, leading to a focus on example selection. We revisit this assumption and conduct a systematic comparison between the effect of selection and ordering. Through controlled experiments on both classification and generation tasks, using multiple open-source model families (0.5B to 27B parameters) and GPT-5, we find that the variance in performance due to different example orderings is comparable to that from using entirely different example sets. Furthermore, we show that strong orderings can be identified using only a development set, achieving performance close to an oracle that selects the best ordering based on test labels. Our findings highlight the equal and intertwined importance of example selection and ordering in prompt design, calling for a reexamination of the assumptions held in ICL.

</details>


### [45] [Contextual morphologically-guided tokenization for Latin encoder models](https://arxiv.org/abs/2511.09709)
*Marisa Hudspeth,Patrick J. Burns,Brendan O'Connor*

Main category: cs.CL

TL;DR: 标准分词方法对形态丰富的语言（如拉丁语）不理想，而形态感知分词能提高模型在下游任务上的表现，尤其是在处理领域外文本时。


<details>
  <summary>Details</summary>
Motivation: 现有的分词方法虽然在信息论上表现良好，但在处理形态丰富的语言时，未能充分考虑语言学目标，导致下游任务表现不佳。

Method: 研究形态感知分词在拉丁语（一种形态丰富但预训练数据中等的语言）上的应用，并评估其在四种下游任务上的表现。

Result: 形态感知分词提高了在四种下游任务上的整体表现，尤其是在处理领域外文本时，模型泛化能力得到显著提升。

Conclusion: 语言学资源（如形态信息）对于提高形态复杂语言的语言模型性能非常有用，对于缺乏大规模预训练数据的低资源语言，利用语言学资源是提升语言模型性能的可行途径。

Abstract: Tokenization is a critical component of language model pretraining, yet standard tokenization methods often prioritize information-theoretical goals like high compression and low fertility rather than linguistic goals like morphological alignment. In fact, they have been shown to be suboptimal for morphologically rich languages, where tokenization quality directly impacts downstream performance. In this work, we investigate morphologically-aware tokenization for Latin, a morphologically rich language that is medium-resource in terms of pretraining data, but high-resource in terms of curated lexical resources -- a distinction that is often overlooked but critical in discussions of low-resource language modeling. We find that morphologically-guided tokenization improves overall performance on four downstream tasks. Performance gains are most pronounced for out of domain texts, highlighting our models' improved generalization ability. Our findings demonstrate the utility of linguistic resources to improve language modeling for morphologically complex languages. For low-resource languages that lack large-scale pretraining data, the development and incorporation of linguistic resources can serve as a feasible alternative to improve LM performance.

</details>


### [46] [Assessing the Applicability of Natural Language Processing to Traditional Social Science Methodology: A Case Study in Identifying Strategic Signaling Patterns in Presidential Directives](https://arxiv.org/abs/2511.09738)
*C. LeMay,A. Lane,J. Seales,M. Winstead,S. Baty*

Main category: cs.CL

TL;DR: 本文研究了如何利用自然语言处理（NLP）从大量书面数据中提取主要主题，并将其应用于识别里根至克林顿时期总统令（PDs）中的信号主题。


<details>
  <summary>Details</summary>
Motivation: 研究的动机在于探索自然语言处理（NLP）在处理大规模书面语料库中的应用潜力，特别是在识别总统令中的信号主题方面。

Method: 研究方法是将NLP技术应用于里根至克林顿时期的总统令，并与分析师的标注结果进行对比，以评估NLP的有效性。

Result: 结果表明，分析师和NLP在识别相关文件方面都显示出潜力，但两者在标注结果上也存在差异，这表明需要进一步研究来评估NLP在此类应用中的有效性。

Conclusion: 结论是，尽管NLP在处理大规模语料库方面具有潜力，但其在社会科学应用中的准确性和可靠性仍需进一步验证，尤其是在AI和机器学习工具快速发展的背景下。

Abstract: Our research investigates how Natural Language Processing (NLP) can be used to extract main topics from a larger corpus of written data, as applied to the case of identifying signaling themes in Presidential Directives (PDs) from the Reagan through Clinton administrations. Analysts and NLP both identified relevant documents, demonstrating the potential utility of NLPs in research involving large written corpuses. However, we also identified discrepancies between NLP and human-labeled results that indicate a need for more research to assess the validity of NLP in this use case. The research was conducted in 2023, and the rapidly evolving landscape of AIML means existing tools have improved and new tools have been developed; this research displays the inherent capabilities of a potentially dated AI tool in emerging social science applications.

</details>


### [47] [How Small Can You Go? Compact Language Models for On-Device Critical Error Detection in Machine Translation](https://arxiv.org/abs/2511.09748)
*Muskaan Chopra,Lorenz Sparrenberg,Sarthak Khanna,Rafet Sifa*

Main category: cs.CL

TL;DR: 大型语言模型（LLM）在机器翻译（MT）评估方面表现出色，但其规模和成本限制了其在边缘设备和隐私敏感工作流中的部署。本研究旨在探索在仍能检测出改变含义的翻译错误的情况下，模型可以缩小到何种程度。研究重点关注英语到德语的关键错误检测（CED），并在 WMT21、WMT22 和 SynCED-EnDe-2025 数据集上对 20 亿参数以下的模型（LFM2-350M、Qwen-3-0.6B/1.7B、Llama-3.2-1B-Instruct、Gemma-3-1B）进行了基准测试。研究框架标准化了提示，应用了轻量级的 logit-bias 校准和多数投票，并报告了语义质量（MCC、F1-ERR/F1-NOT）和计算指标（VRAM、延迟、吞吐量）。结果表明，在 10 亿参数左右存在一个明显的最佳点：Gemma-3-1B 在经过合并权重微调后，在 SynCED-EnDe-2025 数据集上达到了 MCC=0.77 和 F1-ERR=0.98 的最佳质量-效率权衡，同时在 MacBook Pro M4 Pro（24 GB）上保持了 400 毫秒的单样本延迟。在更大的规模下，Qwen-3-1.7B 获得了最高的绝对 MCC（比 Gemma 高 0.11），但计算成本更高。相比之下，超小型模型（0.6B）在通过少样本校准后仍可用，但对实体和数字错误的检测能力不足。总体而言，经过轻量级校准和少样本监督增强的紧凑型指令微调 LLM 可以在 MT 方面提供可信赖的、设备上的 CED，从而在实际翻译流程中实现私有、低成本的错误筛选。所有数据集、提示和脚本均可在 GitHub 存储库中公开获取。


<details>
  <summary>Details</summary>
Motivation: 本研究的动机是解决大型语言模型（LLM）在机器翻译（MT）评估方面的部署限制（规模和成本），并探索在保持检测关键翻译错误能力的同时，能够将模型缩小到何种程度，以便在边缘设备和隐私敏感场景中使用。

Method: 该研究采用了一个框架，该框架标准化了提示，应用了轻量级的 logit-bias 校准和多数投票。研究人员在 WMT21、WMT22 和 SynCED-EnDe-2025 数据集上对 20 亿参数以下的多种模型（LFM2-350M、Qwen-3-0.6B/1.7B、Llama-3.2-1B-Instruct、Gemma-3-1B）进行了基准测试，并报告了语义质量（MCC、F1-ERR/F1-NOT）和计算指标（VRAM、延迟、吞吐量）。

Result: 研究结果表明，参数量约 10 亿的模型在质量和效率之间取得了最佳平衡。Gemma-3-1B 模型在 SynCED-EnDe-2025 数据集上，经过合并权重微调后，达到了 MCC=0.77 和 F1-ERR=0.98 的性能，同时在 MacBook Pro M4 Pro（24 GB）上实现了 400 毫秒的单样本延迟。参数量更大的 Qwen-3-1.7B 模型获得了更高的绝对 MCC（比 Gemma 高 0.11），但计算成本也更高。参数量小于 10 亿的模型（如 0.6B）虽然可以通过少样本校准使用，但在检测实体和数字错误方面表现不佳。

Conclusion: 研究结论是，通过轻量级校准和少样本监督增强的紧凑型、指令微调的 LLM，可以实现可靠的、设备上的关键错误检测（CED）能力，用于机器翻译（MT）。这使得在实际翻译流程中能够实现私有化、低成本的错误筛选。此外，研究者公开了所有数据集、提示和脚本，以供进一步研究。

Abstract: Large Language Models (LLMs) excel at evaluating machine translation (MT), but their scale and cost hinder deployment on edge devices and in privacy-sensitive workflows. We ask: how small can you get while still detecting meaning-altering translation errors? Focusing on English->German Critical Error Detection (CED), we benchmark sub-2B models (LFM2-350M, Qwen-3-0.6B/1.7B, Llama-3.2-1B-Instruct, Gemma-3-1B) across WMT21, WMT22, and SynCED-EnDe-2025. Our framework standardizes prompts, applies lightweight logit-bias calibration and majority voting, and reports both semantic quality (MCC, F1-ERR/F1-NOT) and compute metrics (VRAM, latency, throughput). Results reveal a clear sweet spot around one billion parameters: Gemma-3-1B provides the best quality-efficiency trade-off, reaching MCC=0.77 with F1-ERR=0.98 on SynCED-EnDe-2025 after merged-weights fine-tuning, while maintaining 400 ms single-sample latency on a MacBook Pro M4 Pro (24 GB). At larger scale, Qwen-3-1.7B attains the highest absolute MCC (+0.11 over Gemma) but with higher compute cost. In contrast, ultra-small models (0.6B) remain usable with few-shot calibration yet under-detect entity and number errors. Overall, compact, instruction-tuned LLMs augmented with lightweight calibration and small-sample supervision can deliver trustworthy, on-device CED for MT, enabling private, low-cost error screening in real-world translation pipelines. All datasets, prompts, and scripts are publicly available at our GitHub repository.

</details>


### [48] [Predicate-Argument Structure Divergences in Chinese and English Parallel Sentences and their Impact on Language Transfer](https://arxiv.org/abs/2511.09796)
*Rocco Tripodi,Xiaoyu Liu*

Main category: cs.CL

TL;DR: Cross-lingual NLP transfer learning is asymmetric, especially for distant languages like Chinese and English, requiring careful source language selection.


<details>
  <summary>Details</summary>
Motivation: To analyze linguistic divergences hindering cross-lingual NLP transfer, particularly between typologically distant languages, by examining predicate-argument structures in parallel Chinese and English sentences.

Method: Performed annotation projection between Chinese and English parallel sentences to analyze predicate-argument structure alignment/misalignment, categorize structural divergences, and conduct qualitative/quantitative analysis.

Result: Identified asymmetric language transfer between Chinese and English, highlighting the need for careful source language selection in transfer learning.

Conclusion: Asymmetric language transfer is a critical factor in cross-lingual NLP, necessitating attention when choosing source languages for transfer learning and further investigation before making scientific claims.

Abstract: Cross-lingual Natural Language Processing (NLP) has gained significant traction in recent years, offering practical solutions in low-resource settings by transferring linguistic knowledge from resource-rich to low-resource languages. This field leverages techniques like annotation projection and model transfer for language adaptation, supported by multilingual pre-trained language models. However, linguistic divergences hinder language transfer, especially among typologically distant languages. In this paper, we present an analysis of predicate-argument structures in parallel Chinese and English sentences. We explore the alignment and misalignment of predicate annotations, inspecting similarities and differences and proposing a categorization of structural divergences. The analysis and the categorization are supported by a qualitative and quantitative analysis of the results of an annotation projection experiment, in which, in turn, one of the two languages has been used as source language to project annotations into the corresponding parallel sentences. The results of this analysis show clearly that language transfer is asymmetric. An aspect that requires attention when it comes to selecting the source language in transfer learning applications and that needs to be investigated before any scientific claim about cross-lingual NLP is proposed.

</details>


### [49] [TARG: Training-Free Adaptive Retrieval Gating for Efficient RAG](https://arxiv.org/abs/2511.09803)
*Yufeng Wang,Lu wei,Haibin Ling*

Main category: cs.CL

TL;DR: TARG通过在生成时动态决定是否检索来提高RAG的效率，在不牺牲准确性的前提下显著减少检索次数和延迟。


<details>
  <summary>Details</summary>
Motivation: 每次都进行检索会损害生成质量并增加延迟，因此需要一种更有效的方法来决定何时进行检索。

Method: TARG是一种即时策略，它利用基础模型生成的简短草稿的初始部分（前缀logits）来计算轻量级不确定性得分。该得分有三种计算方式：平均标记熵、基于前两个最可能标记的对数差的边际信号、或少量随机前缀的方差。当得分超过预设阈值时，TARG会触发检索。该方法不依赖于特定模型，引入的额外标记很少，并且无需额外训练。

Result: 在NQ-Open、TriviaQA和PopQA数据集上，TARG在准确性-效率权衡方面取得了持续的进步。与“始终检索”策略相比，TARG在保持或提高精确匹配（EM）/F1分数的同时，检索量减少了70-90%，端到端延迟也显著降低。其开销接近“从不检索”策略。研究还发现，对于经过指令微调的大型语言模型，边际信号是最可靠的默认选择，而小样本方差则是在预算优先情况下的保守替代方案。

Conclusion: TARG是一种有效的、无需训练的检索门控方法，能够显著提高检索增强生成（RAG）的效率，同时保持甚至提高性能。通过根据生成过程中的不确定性动态调整检索行为，TARG为在效率和准确性之间取得平衡提供了一种有前景的解决方案。

Abstract: Retrieval-Augmented Generation (RAG) improves factuality but retrieving for every query often hurts quality while inflating tokens and latency. We propose Training-free Adaptive Retrieval Gating (TARG), a single-shot policy that decides when to retrieve using only a short, no-context draft from the base model. From the draft's prefix logits, TARG computes lightweight uncertainty scores: mean token entropy, a margin signal derived from the top-1/top-2 logit gap via a monotone link, or small-N variance across a handful of stochastic prefixes, and triggers retrieval only when the score exceeds a threshold. The gate is model agnostic, adds only tens to hundreds of draft tokens, and requires no additional training or auxiliary heads. On NQ-Open, TriviaQA, and PopQA, TARG consistently shifts the accuracy-efficiency frontier: compared with Always-RAG, TARG matches or improves EM/F1 while reducing retrieval by 70-90% and cutting end-to-end latency, and it remains close to Never-RAG in overhead. A central empirical finding is that under modern instruction-tuned LLMs the margin signal is a robust default (entropy compresses as backbones sharpen), with small-N variance offering a conservative, budget-first alternative. We provide ablations over gate type and prefix length and use a delta-latency view to make budget trade-offs explicit.

</details>


### [50] [Khmer Spellchecking: A Holistic Approach](https://arxiv.org/abs/2511.09812)
*Marry Kong,Rina Buoy,Sovisal Chenda,Nguonly Taing*

Main category: cs.CL

TL;DR: 现有的高资源语言的拼写检查器在棉兰语中存在问题，该研究提出了一种综合方法，将棉兰语子词分割、命名实体识别 (NER)、音标转换 (G2P) 和语言模型相结合，将准确率提高到 94.4%。


<details>
  <summary>Details</summary>
Motivation: 与英语等高资源语言相比，棉兰语的拼写检查仍然是一个未解决的问题，存在词典与词语切分模型不匹配、词语形式多样、词语构成灵活且不在词典中，以及缺乏命名实体识别 (NER) 模型导致专有名词被误标等挑战。现有解决方案未能充分解决这些问题。

Method: 提出了一种综合方法，集成了棉兰语子词切分、棉兰语 NER、棉兰语 grapheme-to-phoneme (G2P) 转换和棉兰语语言模型，以应对上述挑战、识别潜在的校正候选词并对最合适的候选词进行排序。

Result: 实验结果表明，该方法在棉兰语拼写检查方面取得了 94.4% 的准确率，优于现有解决方案。

Conclusion: 该研究提出了一种综合方法，解决了棉兰语拼写检查的挑战，并取得了最先进的准确率。该研究还将提供棉兰语拼写检查和 NER 的基准数据集。

Abstract: Compared to English and other high-resource languages, spellchecking for Khmer remains an unresolved problem due to several challenges. First, there are misalignments between words in the lexicon and the word segmentation model. Second, a Khmer word can be written in different forms. Third, Khmer compound words are often loosely and easily formed, and these compound words are not always found in the lexicon. Fourth, some proper nouns may be flagged as misspellings due to the absence of a Khmer named-entity recognition (NER) model. Unfortunately, existing solutions do not adequately address these challenges. This paper proposes a holistic approach to the Khmer spellchecking problem by integrating Khmer subword segmentation, Khmer NER, Khmer grapheme-to-phoneme (G2P) conversion, and a Khmer language model to tackle these challenges, identify potential correction candidates, and rank the most suitable candidate. Experimental results show that the proposed approach achieves a state-of-the-art Khmer spellchecking accuracy of up to 94.4%, compared to existing solutions. The benchmark datasets for Khmer spellchecking and NER tasks in this study will be made publicly available.

</details>


### [51] [Improving Graduate Outcomes by Identifying Skills Gaps and Recommending Courses Based on Career Interests](https://arxiv.org/abs/2511.09819)
*Rahul Soni,Basem Suleiman,Sonit Singh*

Main category: cs.CL

TL;DR: 本研究提出一个结合数据分析和机器学习的课程推荐系统，旨在帮助学生根据行业趋势、个人偏好和学业标准选择课程，以提升就业能力。


<details>
  <summary>Details</summary>
Motivation: 学生在选择课程时面临挑战，难以找到符合行业需求且符合个人职业目标的课程，本研究旨在弥合学术学习与行业期望之间的差距。

Method: 本研究设计并开发了一个课程推荐系统，该系统结合了数据分析技术和机器学习算法（包括数据挖掘和协同过滤），并整合了用户偏好和学业标准。同时，开发了一个用户友好的前端界面，并通过用户反馈进行迭代优化。

Result: 该系统能够根据用户偏好、学业标准、过往课程选择和职业目标，利用数据挖掘和协同过滤技术提供个性化的课程推荐，并拥有一个易于使用的前端界面，优化了用户体验。

Conclusion: 所提出的课程推荐系统能够帮助学生做出数据驱动且符合行业信息的课程选择，从而改善大学生的就业结果，并促进终身学习和职业发展，可供学生、教师和职业顾问使用。

Abstract: This paper aims to address the challenge of selecting relevant courses for students by proposing the design and development of a course recommendation system. The course recommendation system utilises a combination of data analytics techniques and machine learning algorithms to recommend courses that align with current industry trends and requirements. In order to provide customised suggestions, the study entails the design and implementation of an extensive algorithmic framework that combines machine learning methods, user preferences, and academic criteria. The system employs data mining and collaborative filtering techniques to examine past courses and individual career goals in order to provide course recommendations. Moreover, to improve the accessibility and usefulness of the recommendation system, special attention is given to the development of an easy-to-use front-end interface. The front-end design prioritises visual clarity, interaction, and simplicity through iterative prototyping and user input revisions, guaranteeing a smooth and captivating user experience. We refined and optimised the proposed system by incorporating user feedback, ensuring that it effectively meets the needs and preferences of its target users. The proposed course recommendation system could be a useful tool for students, instructors, and career advisers to use in promoting lifelong learning and professional progression as it fills the gap between university learning and industry expectations. We hope that the proposed course recommendation system will help university students in making data-drive and industry-informed course decisions, in turn, improving graduate outcomes for the university sector.

</details>


### [52] [Answering Students' Questions on Course Forums Using Multiple Chain-of-Thought Reasoning and Finetuning RAG-Enabled LLM](https://arxiv.org/abs/2511.09831)
*Neo Wang,Sonit Singh*

Main category: cs.CL

TL;DR: We propose a question answering system for course forums using an LLM with RAG to address challenges like delayed responses and repetitive questions. The system is fine-tuned on course data and uses a local knowledge base with RAG to retrieve relevant information, mitigating hallucinations with multi-chain-of-thought reasoning. Experiments on HotpotQA show strong performance.


<details>
  <summary>Details</summary>
Motivation: The increasing number of students in courses leads to challenges in timely responses to queries and repetitive questions in course forums. This work aims to mitigate these issues by developing an automated question answering system.

Method: The proposed system utilizes an open-source Large Language Model (LLM) fine-tuned on a course dataset. It incorporates retrieval augmented generation (RAG) with a local knowledge base containing course content to retrieve relevant documents for student queries. Multi-chain-of-thought reasoning is integrated to reduce LLM hallucinations.

Result: The fine-tuned LLM with the RAG method demonstrated strong performance on the question answering task when experimented with on the HotpotQA dataset.

Conclusion: The study concludes that the developed LLM-based question answering system with RAG and multi-chain-of-thought reasoning is effective in addressing the challenges of course forums, showing strong performance in answering student questions.

Abstract: The course forums are increasingly significant and play vital role in facilitating student discussions and answering their questions related to the course. It provides a platform for students to post their questions related to the content and admin issues related to the course. However, there are several challenges due to the increase in the number of students enrolled in the course. The primary challenge is that students' queries cannot be responded immediately and the instructors have to face lots of repetitive questions. To mitigate these issues, we propose a question answering system based on large language model with retrieval augmented generation (RAG) method. This work focuses on designing a question answering system with open source Large Language Model (LLM) and fine-tuning it on the relevant course dataset. To further improve the performance, we use a local knowledge base and applied RAG method to retrieve relevant documents relevant to students' queries, where the local knowledge base contains all the course content. To mitigate the hallucination of LLMs, We also integrate it with multi chain-of-thought reasoning to overcome the challenge of hallucination in LLMs. In this work, we experiment fine-tuned LLM with RAG method on the HotpotQA dataset. The experimental results demonstrate that the fine-tuned LLM with RAG method has a strong performance on question answering task.

</details>


### [53] [TermGPT: Multi-Level Contrastive Fine-Tuning for Terminology Adaptation in Legal and Financial Domain](https://arxiv.org/abs/2511.09854)
*Yidan Sun,Mengying Zhu,Feiyue Chen,Yangyang Wu,Xiaolei Dan,Mengyuan Yang,Xiaolin Zheng,Shenglin Ben*

Main category: cs.CL

TL;DR: LLM在法律和金融等领域的术语表示能力不足，TermGPT通过多层对比微调框架来解决这个问题，并在金融术语识别任务中表现优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLM）在文本生成方面表现出色，但在其嵌入空间中存在各向同性问题，导致对特定领域术语（尤其是在法律和金融领域）的区分能力较差。这种在术语级别表示上的弱点会严重阻碍法律判决预测或金融风险分析等下游任务，而这些任务中细微的语义差异至关重要。

Method: 提出TermGPT，一个多层对比微调框架，用于术语自适应。首先构建句子图来捕捉语义和结构关系，并基于上下文和拓扑线索生成语义一致但具有区分性的正负样本。然后设计了一个在句子和词元级别进行的多层对比学习方法，以增强全局上下文理解和细粒度术语区分能力。为了支持鲁棒评估，构建了一个源自官方监管文件的首个金融术语数据集。

Result: 实验表明，TermGPT在金融和法律领域的术语区分任务中优于现有基线方法。

Conclusion: TermGPT通过多层对比微调框架，有效解决了LLM在特定领域术语表示上的不足，并在金融和法律领域术语识别任务中取得了优于现有方法的性能。

Abstract: Large language models (LLMs) have demonstrated impressive performance in text generation tasks; however, their embedding spaces often suffer from the isotropy problem, resulting in poor discrimination of domain-specific terminology, particularly in legal and financial contexts. This weakness in terminology-level representation can severely hinder downstream tasks such as legal judgment prediction or financial risk analysis, where subtle semantic distinctions are critical. To address this problem, we propose TermGPT, a multi-level contrastive fine-tuning framework designed for terminology adaptation. We first construct a sentence graph to capture semantic and structural relations, and generate semantically consistent yet discriminative positive and negative samples based on contextual and topological cues. We then devise a multi-level contrastive learning approach at both the sentence and token levels, enhancing global contextual understanding and fine-grained terminology discrimination. To support robust evaluation, we construct the first financial terminology dataset derived from official regulatory documents. Experiments show that TermGPT outperforms existing baselines in term discrimination tasks within the finance and legal domains.

</details>


### [54] [In-Token Rationality Optimization: Towards Accurate and Concise LLM Reasoning via Self-Feedback](https://arxiv.org/abs/2511.09865)
*Mingye Zhu,Yi Liu,Zheren Fu,Quan Wang,Yongdong Zhang*

Main category: cs.CL

TL;DR: InTRO框架通过引入代币级别探索和自我反馈，提高了LLMs在链式思考推理中的准确性和简洁性，并在数学和跨领域推理任务中表现出色。


<details>
  <summary>Details</summary>
Motivation: 监督微调单一“黄金”推理过程会损害泛化能力，而基于可验证奖励的强化学习则存在信用分配困难和计算成本高昂的问题。现有方法难以在保证准确性的同时实现高效的链式思考推理。

Method: InTRO框架通过计算生成策略与其答案条件化对应策略之间的信息差异来估计代币级别的重要性权重（校正因子），实现代币级别的探索和自我反馈，从而在单次前向传播中进行信息丰富的代币选择。

Result: InTRO在六个数学推理基准测试中，将解题准确率相对基础模型提高了20%，并显著减少了推理过程的冗余性。此外，InTRO还展示了跨领域迁移能力，成功适应了数学领域之外的推理任务。

Conclusion: InTRO框架通过代币级别的探索和自我反馈，有效解决了LLMs在链式思考推理中的泛化和效率问题，并在多个推理任务中取得了优越的性能，证明了其鲁棒性和泛化能力。

Abstract: Training Large Language Models (LLMs) for chain-of-thought reasoning presents a significant challenge: supervised fine-tuning on a single "golden" rationale hurts generalization as it penalizes equally valid alternatives, whereas reinforcement learning with verifiable rewards struggles with credit assignment and prohibitive computational cost. To tackle these limitations, we introduce InTRO (In-Token Rationality Optimization), a new framework that enables both token-level exploration and self-feedback for accurate and concise reasoning. Instead of directly optimizing an intractable objective over all valid reasoning paths, InTRO leverages correction factors-token-wise importance weights estimated by the information discrepancy between the generative policy and its answer-conditioned counterpart, for informative next token selection. This approach allows the model to perform token-level exploration and receive self-generated feedback within a single forward pass, ultimately encouraging accurate and concise rationales. Across six math-reasoning benchmarks, InTRO consistently outperforms other baselines, raising solution accuracy by up to 20% relative to the base model. Its chains of thought are also notably more concise, exhibiting reduced verbosity. Beyond this, InTRO enables cross-domain transfer, successfully adapting to out-of-domain reasoning tasks that extend beyond the realm of mathematics, demonstrating robust generalization.

</details>


### [55] [HierRouter: Coordinated Routing of Specialized Large Language Models via Reinforcement Learning](https://arxiv.org/abs/2511.09873)
*Nikunj Gupta,Bill Guo,Rajgopal Kannan,Viktor K. Prasanna*

Main category: cs.CL

TL;DR: HierRouter是一种分层路由方法，通过动态组合专门的、轻量级的语言模型来组装推理管线，以降低大型语言模型的计算和内存成本，在不显著增加推理成本的情况下提高了响应质量。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）在许多任务中都表现出色，但计算和内存成本高昂，限制了它们在资源受限或实时环境中的部署。本研究旨在解决这一问题。

Method: 提出了一种分层路由方法HierRouter，将推理管线从专门的、轻量级的语言模型池中动态组装起来。该方法将此问题构建为有限时间马尔可夫决策过程（MDP），并训练了一个基于近端策略优化（PPO）的强化学习代理，以在多跳推理的每个阶段迭代地选择要调用的模型。该代理根据不断变化的上下文和累积的成本来做出上下文感知的路由决策。

Result: 在三个开源的候选LLM和六个基准测试（包括问答、代码生成和数学推理）上进行的实验表明，与单独使用各个模型相比，HierRouter的响应质量提高了2.4倍，同时平均推理成本仅略有增加。

Conclusion: 分层路由有望实现具有成本效益、高性能的LLM推理。

Abstract: Large Language Models (LLMs) deliver state-of-the-art performance across many tasks but impose high computational and memory costs, limiting their deployment in resource-constrained or real-time settings. To address this, we propose HierRouter, a hierarchical routing approach that dynamically assembles inference pipelines from a pool of specialized, lightweight language models. Formulated as a finite-horizon Markov Decision Process (MDP), our approach trains a Proximal Policy Optimization (PPO)-based reinforcement learning agent to iteratively select which models to invoke at each stage of multi-hop inference. The agent conditions on the evolving context and accumulated cost to make context-aware routing decisions. Experiments with three open-source candidate LLMs across six benchmarks, including QA, code generation, and mathematical reasoning, show that HierRouter improves response quality by up to 2.4x compared to using individual models independently, while incurring only a minimal additional inference cost on average. These results highlight the promise of hierarchical routing for cost-efficient, high-performance LLM inference. All codes can be found here https://github.com/ Nikunj-Gupta/hierouter.

</details>


### [56] [EnchTable: Unified Safety Alignment Transfer in Fine-tuned Large Language Models](https://arxiv.org/abs/2511.09880)
*Jialin Wu,Kecen Li,Zhicong Huang,Xinfeng Li,Xiaofeng Wang,Cheng Hong*

Main category: cs.CL

TL;DR: 微调大型语言模型（LLM）以适应特定领域（如代码生成、生物医学分析、数学问题解决）会损害模型的安全对齐。EnchTable框架通过基于神经切线核（NTK）的安全向量蒸馏和感知干扰的合并技术，在不进行大量重新训练的情况下，将安全对齐迁移并维持到下游LLM中。该方法能够解耦安全约束和任务推理，适用于不同模型架构和大小，并能在安全性和效用之间取得平衡。


<details>
  <summary>Details</summary>
Motivation: 微调大型语言模型（LLM）以适应特定领域时，会系统性地降低其安全对齐能力，从而带来产生有害输出的风险。

Method: EnchTable框架利用基于神经切线核（NTK）的安全向量蒸馏方法来解耦安全约束和任务推理，并采用感知干扰的合并技术来平衡安全性和效用，以在不进行大量重新训练的情况下，将安全对齐迁移并维持到下游LLM中。

Result: 在三个任务领域和三种不同的LLM架构上实现的EnchTable原型，在十一项不同数据集上的实验表明，该方法在效用和模型安全方面表现优异，能够泛化到不同供应商的LLM，并能抵抗静态和动态的越狱攻击，在降低对抗性提示方面优于供应商发布的模型。与六种参数修改方法和两种推理时对齐基线相比，EnchTable实现了更低的不安全率和更高的效用得分，并且在不同任务领域具有普遍适用性。此外，EnchTable可以无缝集成到各种部署管道中，而不会带来显著的开销。

Conclusion: EnchTable框架能够有效地将安全对齐迁移并维持到下游LLM中，而无需进行大量重新训练，同时在安全性和效用之间取得了良好的平衡，并具有广泛的适用性和鲁棒性。

Abstract: Many machine learning models are fine-tuned from large language models (LLMs) to achieve high performance in specialized domains like code generation, biomedical analysis, and mathematical problem solving. However, this fine-tuning process often introduces a critical vulnerability: the systematic degradation of safety alignment, undermining ethical guidelines and increasing the risk of harmful outputs. Addressing this challenge, we introduce EnchTable, a novel framework designed to transfer and maintain safety alignment in downstream LLMs without requiring extensive retraining. EnchTable leverages a Neural Tangent Kernel (NTK)-based safety vector distillation method to decouple safety constraints from task-specific reasoning, ensuring compatibility across diverse model architectures and sizes. Additionally, our interference-aware merging technique effectively balances safety and utility, minimizing performance compromises across various task domains. We implemented a fully functional prototype of EnchTable on three different task domains and three distinct LLM architectures, and evaluated its performance through extensive experiments on eleven diverse datasets, assessing both utility and model safety. Our evaluations include LLMs from different vendors, demonstrating EnchTable's generalization capability. Furthermore, EnchTable exhibits robust resistance to static and dynamic jailbreaking attacks, outperforming vendor-released safety models in mitigating adversarial prompts. Comparative analyses with six parameter modification methods and two inference-time alignment baselines reveal that EnchTable achieves a significantly lower unsafe rate, higher utility score, and universal applicability across different task domains. Additionally, we validate EnchTable can be seamlessly integrated into various deployment pipelines without significant overhead.

</details>


### [57] [HI-TransPA: Hearing Impairments Translation Personal Assistant](https://arxiv.org/abs/2511.09915)
*Zhiming Ma,Shiyu Gan,Junhao Zhao,Xianming Li,Qingyun Pan,Peidong Wang,Mingjun Pan,Yuhao Mo,Jiajie Cheng,Chengxin Chen,Zhonglun Cao,Chonghan Liu,Shi Cheng*

Main category: cs.CL

TL;DR: HI-TransPA是一个指令驱动的视听个人助理，它融合了含糊不清的语音和高帧率的唇部动态，实现了单一多模态框架内的翻译和对话，并提供了端到端的建模框架和必要的处理工具，为未来的研究奠定了基础。


<details>
  <summary>Details</summary>
Motivation: 为听障人士提供日常交流的统一灵活解决方案。

Method: 构建了一个全面的预处理和策管流程，用于检测面部地标，分离和稳定唇部区域，并对多模态样本质量进行定量评估。这些质量分数指导课程学习策略，首先在干净、高置信度的样本上进行训练，然后逐步纳入更难的案例以增强模型的鲁棒性。采用SigLIP编码器和统一的3D-Resampler来高效编码高帧率的唇部运动。

Result: 在专门构建的HI-Dialogue数据集上，HI-TransPA在字面准确性和语义保真度方面均取得了最先进的性能。

Conclusion: 这项工作为将Omni-Models应用于辅助通信技术奠定了基础，为未来的研究提供了端到端的建模框架和必要的处理工具。

Abstract: To provide a unified and flexible solution for daily communication among hearing-impaired individuals, we introduce the Omni-Model paradigm into assistive technology and present HI-TransPA, an instruction-driven audio-visual personal assistant. The model fuses indistinct speech with high-frame-rate lip dynamics, enabling both translation and dialogue within a single multimodal framework. To tackle the challenges of noisy and heterogeneous raw data and the limited adaptability of existing Omni-Models to hearing-impaired speech, we construct a comprehensive preprocessing and curation pipeline that detects facial landmarks, isolates and stabilizes the lip region, and quantitatively assesses multimodal sample quality. These quality scores guide a curriculum learning strategy that first trains on clean, high-confidence samples and progressively incorporates harder cases to strengthen model robustness. We further adopt a SigLIP encoder combined with a Unified 3D-Resampler to efficiently encode high-frame-rate lip motion. Experiments on our purpose-built HI-Dialogue dataset show that HI-TransPA achieves state-of-the-art performance in both literal accuracy and semantic fidelity. This work establishes a foundation for applying Omni-Models to assistive communication technology, providing an end-to-end modeling framework and essential processing tools for future research.

</details>


### [58] [MINDS: A Cross-cultural Dialogue Corpus for Social Norm Classification and Adherence Detection](https://arxiv.org/abs/2511.09918)
*Pritish Sahu,Anirudh Som,Dimitra Vergyri,Ajay Divakaran*

Main category: cs.CL

TL;DR: 本研究提出了Norm-RAG框架，一个用于多轮对话中社会规范推理的检索增强代理框架，并介绍了MINDS数据集。


<details>
  <summary>Details</summary>
Motivation: 以往的研究在处理真实的、多轮的对话语境中的社会规范推理方面存在局限性，因为它们主要关注孤立的语篇或合成对话，而社会规范推理本身具有主观性、情境依赖性和跨文化差异性。

Method: Norm-RAG框架通过检索增强和代理方法，对包括交流意图、说话者角色、人际框架和语言线索在内的语篇级别属性进行建模，并利用新颖的语义分块方法检索结构化规范文档以进行推理。引入了MINDS数据集，包含31个多轮中英和西班牙-英语对话，每个回合都经过多方标注者就规范类别和遵守情况达成共识进行注释。

Result: 实验表明，Norm-RAG在规范检测和泛化能力方面有所提高，并在文化适应性和社会智能对话系统方面展现出改进的性能。

Conclusion: Norm-RAG框架能够进行可解释的、上下文感知的跨语言对话规范遵循和违反推理，并且MINDS数据集为评估和改进此类系统提供了资源。

Abstract: Social norms are implicit, culturally grounded expectations that guide interpersonal communication. Unlike factual commonsense, norm reasoning is subjective, context-dependent, and varies across cultures, posing challenges for computational models. Prior works provide valuable normative annotations but mostly target isolated utterances or synthetic dialogues, limiting their ability to capture the fluid, multi-turn nature of real-world conversations. In this work, we present Norm-RAG, a retrieval-augmented, agentic framework for nuanced social norm inference in multi-turn dialogues. Norm-RAG models utterance-level attributes including communicative intent, speaker roles, interpersonal framing, and linguistic cues and grounds them in structured normative documentation retrieved via a novel Semantic Chunking approach. This enables interpretable and context-aware reasoning about norm adherence and violation across multilingual dialogues. We further introduce MINDS (Multilingual Interactions with Norm-Driven Speech), a bilingual dataset comprising 31 multi-turn Mandarin-English and Spanish-English conversations. Each turn is annotated for norm category and adherence status using multi-annotator consensus, reflecting cross-cultural and realistic norm expression. Our experiments show that Norm-RAG improves norm detection and generalization, demonstrates improved performance for culturally adaptive and socially intelligent dialogue systems.

</details>


### [59] [Leveraging Large Language Models for Identifying Knowledge Components](https://arxiv.org/abs/2511.09935)
*Canwen Wang,Jionghao Lin,Kenneth R. Koedinger*

Main category: cs.CL

TL;DR: LLM在知识组件（KC）识别中存在冗余问题，通过语义合并技术优化后，可以提高模型性能。


<details>
  <summary>Details</summary>
Motivation: 手动识别知识组件（KC）是自适应学习系统的瓶颈，需要自动化方法。

Method: 首先使用LLM（GPT-4o-mini）在包含646个选择题的数据集上进行KC识别，然后提出并评估了基于余弦相似度的KC合并方法。

Result: LLM自动识别的KC数量过多（569个），且性能略差于专家模型（RMSE 0.4285 vs. 0.4206）。通过余弦相似度合并KC（阈值0.8），KC数量减少到428个，性能得到提升（RMSE 0.4259）。

Conclusion: 单独的LLM生成KC方法不足，结合语义合并技术是自动化和优化KC识别的可行途径。

Abstract: Knowledge Components (KCs) are foundational to adaptive learning systems, but their manual identification by domain experts is a significant bottleneck. While Large Language Models (LLMs) offer a promising avenue for automating this process, prior research has been limited to small datasets and has been shown to produce superfluous, redundant KC labels. This study addresses these limitations by first scaling a "simulated textbook" LLM prompting strategy (using GPT-4o-mini) to a larger dataset of 646 multiple-choice questions. We found that this initial automated approach performed significantly worse than an expert-designed KC model (RMSE 0.4285 vs. 0.4206) and generated an excessive number of KCs (569 vs. 101). To address the issue of redundancy, we proposed and evaluated a novel method for merging semantically similar KC labels based on their cosine similarity. This merging strategy significantly improved the model's performance; a model using a cosine similarity threshold of 0.8 achieved the best result, reducing the KC count to 428 and improving the RMSE to 0.4259. This demonstrates that while scaled LLM generation alone is insufficient, combining it with a semantic merging technique offers a viable path toward automating and refining KC identification.

</details>


### [60] [REAP: Enhancing RAG with Recursive Evaluation and Adaptive Planning for Multi-Hop Question Answering](https://arxiv.org/abs/2511.09966)
*Yijie Zhu,Haojie Zhou,Wanting Hong,Tailin Liu,Ning Wang*

Main category: cs.CL

TL;DR: REAP通过显式维护子任务和事实来解决多跳推理中的局部推理僵局和信息利用不足的问题，并在多个多跳数据集上显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有检索增强生成（RAG）方法在多跳推理任务中缺乏全局规划，容易陷入局部推理僵局，且对检索内容的利用不足、忽视潜在线索，导致推理结果不准确。REAP旨在克服这些局限性。

Method: 提出递归评估和自适应规划（REAP）方法，包含子任务规划器（SP）和事实提取器（FE）两个核心模块。SP维护全局视角，指导推理方向并根据FE的输出来评估任务状态，实现任务解决轨迹的动态优化。FE对检索内容进行细粒度分析，提取可靠答案和线索。SP和FE逐步丰富全局知识的逻辑一致表示，提高推理过程的可靠性和可追溯性。此外，提出统一的任务范式设计，实现有效的多任务联合微调，提升SP在复杂、数据稀疏任务上的性能。

Result: 在多个公开的多跳数据集上进行的大量实验表明，REAP在领域内和跨领域设置上均显著优于现有的RAG方法。

Conclusion: REAP通过其提出的SP和FE模块，以及统一的任务范式设计，有效解决了多跳推理中的挑战，显著提高了推理的准确性、可靠性和可追溯性，并在实验中证明了其优越性。

Abstract: Retrieval-augmented generation (RAG) has been extensively employed to mitigate hallucinations in large language models (LLMs). However, existing methods for multi-hop reasoning tasks often lack global planning, increasing the risk of falling into local reasoning impasses. Insufficient exploitation of retrieved content and the neglect of latent clues fail to ensure the accuracy of reasoning outcomes. To overcome these limitations, we propose Recursive Evaluation and Adaptive Planning (REAP), whose core idea is to explicitly maintain structured sub-tasks and facts related to the current task through the Sub-task Planner (SP) and Fact Extractor (FE) modules. SP maintains a global perspective, guiding the overall reasoning direction and evaluating the task state based on the outcomes of FE, enabling dynamic optimization of the task-solving trajectory. FE performs fine-grained analysis over retrieved content to extract reliable answers and clues. These two modules incrementally enrich a logically coherent representation of global knowledge, enhancing the reliability and the traceability of the reasoning process. Furthermore, we propose a unified task paradigm design that enables effective multi-task fine-tuning, significantly enhancing SP's performance on complex, data-scarce tasks. We conduct extensive experiments on multiple public multi-hop datasets, and the results demonstrate that our method significantly outperforms existing RAG methods in both in-domain and out-of-domain settings, validating its effectiveness in complex multi-hop reasoning tasks.

</details>


### [61] [NumPert: Numerical Perturbations to Probe Language Models for Veracity Prediction](https://arxiv.org/abs/2511.09971)
*Peter Røysland Aarnes,Vinay Setty*

Main category: cs.CL

TL;DR: 大型语言模型在数字推理方面存在不足，即使是顶尖模型在面对扰动时也会出现准确率下降，并且没有模型能在所有情况下都表现出鲁棒性。增加上下文长度通常会降低准确率，但如果扩展的上下文包含扰动演示，则大多数模型可以显著恢复。


<details>
  <summary>Details</summary>
Motivation: 评估现有的大型语言模型在处理涉及数字声明和证据的验证任务时的表现，并测试其鲁棒性。

Method: 使用受控扰动，包括标签翻转探针，对最新模型进行系统性评估。

Result: 即使是领先的专有系统在某些扰动下准确率也会下降高达62%。没有模型能在所有条件下都表现出鲁棒性。增加上下文长度通常会降低准确率，但如果扩展的上下文包含扰动演示，则大多数模型可以显著恢复。

Conclusion: 大型语言模型在数字事实核查方面存在严重局限性，鲁棒性仍然是一个开放的挑战。

Abstract: Large language models show strong performance on knowledge intensive tasks such as fact-checking and question answering, yet they often struggle with numerical reasoning. We present a systematic evaluation of state-of-the-art models for veracity prediction on numerical claims and evidence pairs using controlled perturbations, including label-flipping probes, to test robustness. Our results indicate that even leading proprietary systems experience accuracy drops of up to 62\% under certain perturbations. No model proves to be robust across all conditions. We further find that increasing context length generally reduces accuracy, but when extended context is enriched with perturbed demonstrations, most models substantially recover. These findings highlight critical limitations in numerical fact-checking and suggest that robustness remains an open challenge for current language models.

</details>


### [62] [Modeling Uncertainty Trends for Timely Retrieval in Dynamic RAG](https://arxiv.org/abs/2511.09980)
*Bo Li,Tian Tian,Zhenghua Xu,Hao Cheng,Shikun Zhang,Wei Ye*

Main category: cs.CL

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Dynamic retrieval-augmented generation (RAG) allows large language models (LLMs) to fetch external knowledge on demand, offering greater adaptability than static RAG. A central challenge in this setting lies in determining the optimal timing for retrieval. Existing methods often trigger retrieval based on low token-level confidence, which may lead to delayed intervention after errors have already propagated. We introduce Entropy-Trend Constraint (ETC), a training-free method that determines optimal retrieval timing by modeling the dynamics of token-level uncertainty. Specifically, ETC utilizes first- and second-order differences of the entropy sequence to detect emerging uncertainty trends, enabling earlier and more precise retrieval. Experiments on six QA benchmarks with three LLM backbones demonstrate that ETC consistently outperforms strong baselines while reducing retrieval frequency. ETC is particularly effective in domain-specific scenarios, exhibiting robust generalization capabilities. Ablation studies and qualitative analyses further confirm that trend-aware uncertainty modeling yields more effective retrieval timing. The method is plug-and-play, model-agnostic, and readily integrable into existing decoding pipelines. Implementation code is included in the supplementary materials.

</details>


### [63] [Language Drift in Multilingual Retrieval-Augmented Generation: Characterization and Decoding-Time Mitigation](https://arxiv.org/abs/2511.09984)
*Bo Li,Zhenghua Xu,Rui Xie*

Main category: cs.CL

TL;DR: 多语言检索增强生成（RAG）模型在跨语言检索时存在语言漂移问题，尤其是在需要推理的情况下。本文提出了一种名为软约束解码（SCD）的解码策略，通过惩罚非目标语言的词元来解决此问题，并在实验中证明了其有效性。


<details>
  <summary>Details</summary>
Motivation: 当检索到的证据语言与用户查询和示例语言不一致时，多语言检索增强生成（RAG）模型在执行知识密集型任务时，常常会发生输出语言漂移，尤其是在进行类似思维链（CoT）的推理式生成时。

Method: 提出了一种名为软约束解码（SCD）的轻量级、无需训练的解码策略，通过惩罚非目标语言的词元来引导生成向目标语言靠拢，以减轻语言漂移问题。SCD 是一种模型无关的策略，无需修改模型架构或额外数据，即可应用于任何生成算法。

Result: 在三个多语言数据集和多种类型多样的语言上的实验表明，SCD 能够持续提高语言一致性和任务性能。

Conclusion: SCD 是一种有效且可泛化的解决方案，可以解决多语言 RAG 中的语言漂移问题，并提高任务性能。

Abstract: Multilingual Retrieval-Augmented Generation (RAG) enables large language models (LLMs) to perform knowledge-intensive tasks in multilingual settings by leveraging retrieved documents as external evidence. However, when the retrieved evidence differs in language from the user query and in-context exemplars, the model often exhibits language drift by generating responses in an unintended language. This phenomenon is especially pronounced during reasoning-intensive decoding, such as Chain-of-Thought (CoT) generation, where intermediate steps introduce further language instability. In this paper, we systematically study output language drift in multilingual RAG across multiple datasets, languages, and LLM backbones. Our controlled experiments reveal that the drift results not from comprehension failure but from decoder-level collapse, where dominant token distributions and high-frequency English patterns dominate the intended generation language. We further observe that English serves as a semantic attractor under cross-lingual conditions, emerging as both the strongest interference source and the most frequent fallback language.
  To mitigate this, we propose Soft Constrained Decoding (SCD), a lightweight, training-free decoding strategy that gently steers generation toward the target language by penalizing non-target-language tokens. SCD is model-agnostic and can be applied to any generation algorithm without modifying the architecture or requiring additional data. Experiments across three multilingual datasets and multiple typologically diverse languages show that SCD consistently improves language alignment and task performance, providing an effective and generalizable solution in multilingual RAG.

</details>


### [64] [FinNuE: Exposing the Risks of Using BERTScore for Numerical Semantic Evaluation in Finance](https://arxiv.org/abs/2511.09997)
*Yu-Shiang Huang,Yun-Yu Lee,Tzu-Hsin Chou,Che Lin,Chuan-Ju Wang*

Main category: cs.CL

TL;DR: BERTScore在评估句子语义相似性方面存在局限性，尤其是在金融领域，它对数值变化的敏感度低。本文提出了FinNuE数据集，并证明了BERTScore在区分金融文本中的数值差异方面存在不足，从而强调了开发金融领域特定评估框架的必要性。


<details>
  <summary>Details</summary>
Motivation: 识别出BERTScore在评估金融文本语义相似性时对数值变化敏感度低的局限性，而金融领域中数值的精确性至关重要。

Method: 构建了一个名为FinNuE的诊断数据集，其中包含经过控制的数值扰动，覆盖了财报电话会议、监管文件、社交媒体和新闻文章等多种金融文本来源。利用FinNuE数据集评估BERTScore在区分具有关键数值差异的金融文本对方面的表现。

Result: 证明了BERTScore在区分具有关键数值差异的金融文本时表现不佳，常常给出高度相似的评分，即使这些文本在金融意义上存在显著差异。这揭示了基于嵌入的评估指标在金融领域的根本性局限。

Conclusion: 现有的基于嵌入的评估指标（如BERTScore）在金融领域存在根本性局限，无法准确捕捉数值变化带来的语义差异。因此，需要开发对数值变化更敏感的金融NLP评估框架。

Abstract: BERTScore has become a widely adopted metric for evaluating semantic similarity between natural language sentences. However, we identify a critical limitation: BERTScore exhibits low sensitivity to numerical variation, a significant weakness in finance where numerical precision directly affects meaning (e.g., distinguishing a 2% gain from a 20% loss). We introduce FinNuE, a diagnostic dataset constructed with controlled numerical perturbations across earnings calls, regulatory filings, social media, and news articles. Using FinNuE, demonstrate that BERTScore fails to distinguish semantically critical numerical differences, often assigning high similarity scores to financially divergent text pairs. Our findings reveal fundamental limitations of embedding-based metrics for finance and motivate numerically-aware evaluation frameworks for financial NLP.

</details>


### [65] [PustakAI: Curriculum-Aligned and Interactive Textbooks Using Large Language Models](https://arxiv.org/abs/2511.10002)
*Shivam Sharma,Riya Naik,Tejas Gawas,Heramb Patil,Kunal Korgaonkar*

Main category: cs.CL

TL;DR: 该论文提出了一个名为PustakAI的框架，并创建了一个名为NCERT-QA的新型问答数据集，用于评估大型语言模型（LLMs）在印度NCERT课程（6-8年级英语和科学）中的应用，并对不同的大型语言模型进行了评估。


<details>
  <summary>Details</summary>
Motivation: 为了应对大型语言模型在适应课程特定内容（如印度NCERT课程）时在准确性、一致性和教学相关性方面的挑战，尤其是在教学资源有限的地区。

Method: 创建了一个名为NCERT-QA的新型问答数据集，涵盖了6-8年级英语和科学科目的NCERT课程。将问答对分为事实型、推理型和其他类型。使用元提示、少样本和思维链（CoT）等提示技术，并采用多种评估指标来评估数据集。同时，评估了开源和高端大型语言模型作为基于AI的学习工具的优缺点。

Result: 评估了不同提示技术在NCERT-QA数据集上的表现，并分析了当前开源和高端大型语言模型在作为教育工具方面的优势和局限性。

Conclusion: PustakAI框架和NCERT-QA数据集为评估和改进大型语言模型在印度教育系统中的应用提供了基础，有助于实现个性化和互动化的学习体验。

Abstract: Large Language Models (LLMs) have demonstrated remarkable capabilities in understanding and generating human-like content. This has revolutionized various sectors such as healthcare, software development, and education. In education, LLMs offer potential for personalized and interactive learning experiences, especially in regions with limited teaching resources. However, adapting these models effectively to curriculum-specific content, such as the National Council of Educational Research and Training (NCERT) syllabus in India, presents unique challenges in terms of accuracy, alignment, and pedagogical relevance. In this paper, we present the framework "PustakAI"\footnote{Pustak means `book' in many Indian languages.} for the design and evaluation of a novel question-answering dataset "NCERT-QA" aligned with the NCERT curriculum for English and Science subjects of grades 6 to 8. We classify the curated QA pairs as Factoid, Inferential, and Others (evaluative and reasoning). We evaluate the dataset with various prompting techniques, such as meta-prompt, few-shot, and CoT-style prompting, using diverse evaluation metrics to understand which approach aligns more efficiently with the structure and demands of the curriculum. Along with the usability of the dataset, we analyze the strengths and limitations of current open-source LLMs (Gemma3:1b, Llama3.2:3b, and Nemotron-mini:4b) and high-end LLMs (Llama-4-Scout-17B and Deepseek-r1-70B) as AI-based learning tools in formal education systems.

</details>


### [66] [ScaleFormer: Span Representation Cumulation for Long-Context Transformer](https://arxiv.org/abs/2511.10029)
*Jiangshu Du,Wenpeng Yin,Philip Yu*

Main category: cs.CL

TL;DR: ScaleFormer是一个即插即用的框架，可以通过累积上下文向量来处理长序列，从而解决Transformer在长序列任务中的二次复杂度问题。


<details>
  <summary>Details</summary>
Motivation: 标准的自注意力机制的二次复杂度限制了Transformer模型在长上下文任务中的应用，而现有的Transformer变体通常需要修改架构并进行昂贵的预训练。ScaleFormer旨在提供一种简单有效的方法来适应现有的预训练模型，以处理长序列，而无需修改架构。

Method: ScaleFormer将长输入分割成重叠的块，并为解码器生成压缩的、上下文感知的表示。它使用一种新颖的、无参数的融合机制，通过用来自所有先前和后续块的累积上下文向量来丰富每个块的边界表示，从而赋予每个块的表示结构感知能力。

Result: ScaleFormer实现了线性复杂度，并使预训练模型能够有效地处理长格式文本。在长文档摘要任务上的实验表明，该方法具有很强的竞争力，并且在不修改架构或使用外部检索机制的情况下，其性能通常优于最先进的方法。

Conclusion: ScaleFormer是一种简单、有效且即插即用的框架，通过累积上下文表示来解决Transformer在处理长序列时的二次复杂度问题，并在长文档摘要任务上取得了有竞争力的结果。

Abstract: The quadratic complexity of standard self-attention severely limits the application of Transformer-based models to long-context tasks. While efficient Transformer variants exist, they often require architectural changes and costly pre-training from scratch. To circumvent this, we propose ScaleFormer(Span Representation Cumulation for Long-Context Transformer) - a simple and effective plug-and-play framework that adapts off-the-shelf pre-trained encoder-decoder models to process long sequences without requiring architectural modifications. Our approach segments long inputs into overlapping chunks and generates a compressed, context-aware representation for the decoder. The core of our method is a novel, parameter-free fusion mechanism that endows each chunk's representation with structural awareness of its position within the document. It achieves this by enriching each chunk's boundary representations with cumulative context vectors from all preceding and succeeding chunks. This strategy provides the model with a strong signal of the document's narrative flow, achieves linear complexity, and enables pre-trained models to reason effectively over long-form text. Experiments on long-document summarization show that our method is highly competitive with and often outperforms state-of-the-art approaches without requiring architectural modifications or external retrieval mechanisms.

</details>


### [67] [Do Language Models Associate Sound with Meaning? A Multimodal Study of Sound Symbolism](https://arxiv.org/abs/2511.10045)
*Jinhong Jeong,Sunghyun Lee,Jaeyoung Lee,Seonah Han,Youngjae Yu*

Main category: cs.CL

TL;DR: 该研究探讨了多模态大语言模型(MLLMs)如何理解语音信息，通过分析其在语音符号学（声音象征）方面的表现，即语音形式与意义之间的非任意关联。研究者们提出了LEX-ICON数据集，包含真实词汇和人工构造的伪词，并标注了跨文本和音频的语义特征，以评估MLLMs在处理不同语言（英语、法语、日语、韩语）的语音符号学能力。研究发现，MLLMs在语音直觉上与现有语言学研究一致，并且在处理语音符号学信息时，模型会关注具有象征意义的音素。


<details>
  <summary>Details</summary>
Motivation: 利用多模态大语言模型(MLLMs)在语音符号学（非任意的语音形式与意义关联）方面的表现，来探究MLLMs如何理解人类语言中的听觉信息。

Method: 构建了一个名为LEX-ICON的大规模拟声词数据集，包含8052个来自四种自然语言（英语、法语、日语、韩语）的真实词汇和2930个系统构造的伪词。该数据集标注了跨越文本（拼写和IPA）和音频形式的25个语义维度（如锐利 vs. 圆形）。通过测量音素级别的注意力分数，分析模型在不同层次上的信息处理过程，以评估MLLMs在文本和音频输入上的语音图像学表现。

Result: 研究结果表明，(1) MLLMs表现出与现有语言学研究在多个语义维度上一致的语音直觉；(2) 模型的语音-语义注意力模式凸显了其对具有图像意义的音素的关注。

Conclusion: 这项研究首次在多模态大语言模型(MLLMs)的可解释性方面，对语音图像学进行了大规模、定量的分析，将人工智能和认知语言学领域联系起来，并为理解模型如何处理听觉信息提供了新的见解。

Abstract: Sound symbolism is a linguistic concept that refers to non-arbitrary associations between phonetic forms and their meanings. We suggest that this can be a compelling probe into how Multimodal Large Language Models (MLLMs) interpret auditory information in human languages. We investigate MLLMs' performance on phonetic iconicity across textual (orthographic and IPA) and auditory forms of inputs with up to 25 semantic dimensions (e.g., sharp vs. round), observing models' layer-wise information processing by measuring phoneme-level attention fraction scores. To this end, we present LEX-ICON, an extensive mimetic word dataset consisting of 8,052 words from four natural languages (English, French, Japanese, and Korean) and 2,930 systematically constructed pseudo-words, annotated with semantic features applied across both text and audio modalities. Our key findings demonstrate (1) MLLMs' phonetic intuitions that align with existing linguistic research across multiple semantic dimensions and (2) phonosemantic attention patterns that highlight models' focus on iconic phonemes. These results bridge domains of artificial intelligence and cognitive linguistics, providing the first large-scale, quantitative analyses of phonetic iconicity in terms of MLLMs' interpretability.

</details>


### [68] [GraphIF: Enhancing Multi-Turn Instruction Following for Large Language Models with Relation Graph Prompt](https://arxiv.org/abs/2511.10051)
*Zhenhe Li,Can Lin,Ling Zheng,Wen-Da Wei,Junli Liang,Qi Song*

Main category: cs.CL

TL;DR: GraphIF是一个即插即用框架，通过将多轮对话建模为有向关系图并利用图提示来增强LLM的指令遵循能力，以解决现有方法在多轮指令遵循方面的不足。


<details>
  <summary>Details</summary>
Motivation: 现有方法主要依赖于收集或生成大规模多轮对话数据集来微调LLM，但将每个响应生成视为孤立任务，未能明确地将多轮指令遵循纳入优化目标，导致指令微调的LLM难以处理复杂的长距离约束。

Method: GraphIF将多轮对话建模为有向关系图，包含三个关键组件：（1）基于智能体的关系抽取模块，通过动作触发机制捕获轮次间语义关系以构建结构化图；（2）关系图提示生成模块，将结构化图信息转换为自然语言提示；（3）响应重写模块，使用生成的图提示优化初始LLM输出。

Result: 在两个长多轮对话数据集上的广泛实验表明，GraphIF可以无缝集成到指令微调的LLM中，并在所有四个多轮指令遵循评估指标上带来显著改进。

Conclusion: GraphIF通过将多轮对话建模为有向关系图并利用图提示，有效解决了现有方法在多轮指令遵循方面的局限性，显著提高了LLM处理长距离约束和复杂指令的能力。

Abstract: Multi-turn instruction following is essential for building intelligent conversational systems that can consistently adhere to instructions across dialogue turns. However, existing approaches to enhancing multi-turn instruction following primarily rely on collecting or generating large-scale multi-turn dialogue datasets to fine-tune large language models (LLMs), which treat each response generation as an isolated task and fail to explicitly incorporate multi-turn instruction following into the optimization objectives. As a result, instruction-tuned LLMs often struggle with complex long-distance constraints. In multi-turn dialogues, relational constraints across turns can be naturally modeled as labeled directed edges, making graph structures particularly suitable for modeling multi-turn instruction following. Despite this potential, leveraging graph structures to enhance the multi-turn instruction following capabilities of LLMs remains unexplored. To bridge this gap, we propose GraphIF, a plug-and-play framework that models multi-turn dialogues as directed relation graphs and leverages graph prompts to enhance the instruction following capabilities of LLMs. GraphIF comprises three key components: (1) an agent-based relation extraction module that captures inter-turn semantic relations via action-triggered mechanisms to construct structured graphs; (2) a relation graph prompt generation module that converts structured graph information into natural language prompts; and (3) a response rewriting module that refines initial LLM outputs using the generated graph prompts. Extensive experiments on two long multi-turn dialogue datasets demonstrate that GraphIF can be seamlessly integrated into instruction-tuned LLMs and leads to significant improvements across all four multi-turn instruction-following evaluation metrics.

</details>


### [69] [ADI-20: Arabic Dialect Identification dataset and models](https://arxiv.org/abs/2511.10070)
*Haroun Elleuch,Salima Mdhaffar,Yannick Estève,Fethi Bougares*

Main category: cs.CL

TL;DR: ADI-20 是一个包含 19 种阿拉伯语方言和现代标准阿拉伯语的阿拉伯语方言识别数据集，该数据集用于训练和评估各种最先进的 ADI 系统，并研究了训练数据大小和模型参数数量对识别性能的影响。


<details>
  <summary>Details</summary>
Motivation: ADIDataset的扩展，涵盖所有阿拉伯语国家的方言，旨在支持阿拉伯语方言识别（ADI）的研究。

Method: 收集了3,556小时的音频数据，涵盖19种阿拉伯语方言和现代标准阿拉伯语（MSA）。探索了微调基于ECAPA-TDNN的预训练模型以及结合了注意池化层和分类密集层的Whisper编码器块。研究了训练数据大小和模型参数数量对识别性能的影响。

Result: 使用30%的训练数据会导致F1分数略有下降。

Conclusion: ADI-20数据集已开源，并提供了训练好的模型，以促进该领域的研究和复现。

Abstract: We present ADI-20, an extension of the previously published ADI-17 Arabic Dialect Identification (ADI) dataset. ADI-20 covers all Arabic-speaking countries' dialects. It comprises 3,556 hours from 19 Arabic dialects in addition to Modern Standard Arabic (MSA). We used this dataset to train and evaluate various state-of-the-art ADI systems. We explored fine-tuning pre-trained ECAPA-TDNN-based models, as well as Whisper encoder blocks coupled with an attention pooling layer and a classification dense layer. We investigated the effect of (i) training data size and (ii) the model's number of parameters on identification performance. Our results show a small decrease in F1 score while using only 30% of the original training data. We open-source our collected data and trained models to enable the reproduction of our work, as well as support further research in ADI.

</details>


### [70] [Format Matters: The Robustness of Multimodal LLMs in Reviewing Evidence from Tables and Charts](https://arxiv.org/abs/2511.10075)
*Xanh Ho,Yun-Ang Wu,Sunisth Kumar,Florian Boudin,Atsuhiro Takasu,Akiko Aizawa*

Main category: cs.CL

TL;DR: 目前的多模态大语言模型在处理表格形式的科学论证方面表现较好，但在图表形式方面存在困难，且跨模态泛化能力有限，未来需加强图表理解能力。


<details>
  <summary>Details</summary>
Motivation: 随着科学论文数量的增长，对能够协助审稿人评估研究主张的系统的需求日益增长，特别是理解表格和图表等不同格式的实验结果。

Method: 设计并进行一系列实验，评估多模态大语言模型利用表格和图表作为证据来验证科学主张的能力，并对12个模型进行了评估，同时进行了人类评估。

Result: 在改编的数据集上，多模态大语言模型在表格证据方面表现优于图表证据。小型模型（8B以下）在表格和图表任务之间的性能相关性较弱。人类评估者在两种格式上均保持强劲表现。

Conclusion: 当前多模态大语言模型在多模态推理能力方面存在差距，尤其是在理解图表方面，这阻碍了它们在科学主张验证方面的应用。未来应重点改进模型的图表理解能力。

Abstract: With the growing number of submitted scientific papers, there is an increasing demand for systems that can assist reviewers in evaluating research claims. Experimental results are a core component of scientific work, often presented in varying formats such as tables or charts. Understanding how robust current multimodal large language models (multimodal LLMs) are at verifying scientific claims across different evidence formats remains an important and underexplored challenge. In this paper, we design and conduct a series of experiments to assess the ability of multimodal LLMs to verify scientific claims using both tables and charts as evidence. To enable this evaluation, we adapt two existing datasets of scientific papers by incorporating annotations and structures necessary for a multimodal claim verification task. Using this adapted dataset, we evaluate 12 multimodal LLMs and find that current models perform better with table-based evidence while struggling with chart-based evidence. We further conduct human evaluations and observe that humans maintain strong performance across both formats, unlike the models. Our analysis also reveals that smaller multimodal LLMs (under 8B) show weak correlation in performance between table-based and chart-based tasks, indicating limited cross-modal generalization. These findings highlight a critical gap in current models' multimodal reasoning capabilities. We suggest that future multimodal LLMs should place greater emphasis on improving chart understanding to better support scientific claim verification.

</details>


### [71] [ELYADATA & LIA at NADI 2025: ASR and ADI Subtasks](https://arxiv.org/abs/2511.10090)
*Haroun Elleuch,Youssef Saidi,Salima Mdhaffar,Yannick Estève,Fethi Bougares*

Main category: cs.CL

TL;DR: Elyadata & LIA在2025年NADI多方言阿拉伯语语音处理竞赛中表现出色，其ADI系统（基于Whisper-large-v3）在方言识别子任务中排名第一，ASR系统（基于SeamlessM4T-v2）在多方言语音识别子任务中排名第二。


<details>
  <summary>Details</summary>
Motivation: 参与NADI多方言阿拉伯语语音处理竞赛，并在方言识别（ADI）和多方言阿拉伯语自动语音识别（ASR）子任务中取得优异成绩。

Method: ADI子任务：采用数据增强技术对Whisper-large-v3编码器进行微调。ASR子任务：将SeamlessM4T-v2 Large（埃及变体）分别针对八种阿拉伯语方言进行微调。

Result: ADI子任务：在官方测试集上获得79.83%的准确率，排名第一。ASR子任务：在测试集上平均词错误率（WER）为38.54%，字错误率（CER）为14.53%，排名第二。

Conclusion: 大型预训练语音模型结合针对性的微调技术，在阿拉伯语语音处理任务中具有显著的有效性。

Abstract: This paper describes Elyadata \& LIA's joint submission to the NADI multi-dialectal Arabic Speech Processing 2025. We participated in the Spoken Arabic Dialect Identification (ADI) and multi-dialectal Arabic ASR subtasks. Our submission ranked first for the ADI subtask and second for the multi-dialectal Arabic ASR subtask among all participants. Our ADI system is a fine-tuned Whisper-large-v3 encoder with data augmentation. This system obtained the highest ADI accuracy score of \textbf{79.83\%} on the official test set. For multi-dialectal Arabic ASR, we fine-tuned SeamlessM4T-v2 Large (Egyptian variant) separately for each of the eight considered dialects. Overall, we obtained an average WER and CER of \textbf{38.54\%} and \textbf{14.53\%}, respectively, on the test set. Our results demonstrate the effectiveness of large pre-trained speech models with targeted fine-tuning for Arabic speech processing.

</details>


### [72] [On the Military Applications of Large Language Models](https://arxiv.org/abs/2511.10093)
*Satu Johansson,Taneli Riihonen*

Main category: cs.CL

TL;DR: 大型语言模型在军事领域的应用潜力巨大，但需谨慎评估。


<details>
  <summary>Details</summary>
Motivation: 探讨大型语言模型（如GPT）在军事领域的潜在应用及实现方式。

Method: 1. 询问GPT（以Microsoft Copilot为例）了解其自身对军事应用的认知；2. 评估商业云服务（如Microsoft Azure）在构建此类应用中的可行性。

Result: 语言模型的生成和摘要能力可直接应用于多种军事场景，其他功能也具有特定用途。

Conclusion: 大型语言模型在军事领域的应用前景广阔，但对其能力和安全性的评估至关重要。

Abstract: In this paper, military use cases or applications and implementation thereof are considered for natural language processing and large language models, which have broken into fame with the invention of the generative pre-trained transformer (GPT) and the extensive foundation model pretraining done by OpenAI for ChatGPT and others. First, we interrogate a GPT-based language model (viz. Microsoft Copilot) to make it reveal its own knowledge about their potential military applications and then critically assess the information. Second, we study how commercial cloud services (viz. Microsoft Azure) could be used readily to build such applications and assess which of them are feasible. We conclude that the summarization and generative properties of language models directly facilitate many applications at large and other features may find particular uses.

</details>


### [73] [Generalizing to Unseen Disaster Events: A Causal View](https://arxiv.org/abs/2511.10120)
*Philipp Seeberger,Steffen Freisinger,Tobias Bocklet,Korbinian Riedhammer*

Main category: cs.CL

TL;DR: 社交媒体在灾难事件监控中很重要，但现有系统存在事件相关偏差，影响泛化能力。本文提出一种因果方法来减少偏差，提高泛化能力，并在三个灾难分类任务中优于基线。


<details>
  <summary>Details</summary>
Motivation: 现有社交媒体灾难事件监控系统存在事件相关偏差，影响泛化能力，而因果学习和去偏方法在该领域尚未得到充分研究。

Method: 提出一种通过因果视角来缓解偏差的方法，以减少事件和领域相关的偏差，从而提高对未来事件的泛化能力。

Result: 提出的方法在三个灾难分类任务中，相比多个基线，F1分数最高提升了+1.9%，并显著改进了基于预训练语言模型（PLM）的分类器。

Conclusion: 通过因果方法缓解偏差可以有效提高社交媒体在灾难事件监控中的泛化能力。

Abstract: Due to the rapid growth of social media platforms, these tools have become essential for monitoring information during ongoing disaster events. However, extracting valuable insights requires real-time processing of vast amounts of data. A major challenge in existing systems is their exposure to event-related biases, which negatively affects their ability to generalize to emerging events. While recent advancements in debiasing and causal learning offer promising solutions, they remain underexplored in the disaster event domain. In this work, we approach bias mitigation through a causal lens and propose a method to reduce event- and domain-related biases, enhancing generalization to future events. Our approach outperforms multiple baselines by up to +1.9% F1 and significantly improves a PLM-based classifier across three disaster classification tasks.

</details>


### [74] [Beyond the Black Box: Demystifying Multi-Turn LLM Reasoning with VISTA](https://arxiv.org/abs/2511.10182)
*Yiran Zhang,Mingyang Lin,Mark Dras,Usman Naseem*

Main category: cs.CL

TL;DR: VISTA是一个用于多轮对话中LLM推理分析的可视化交互系统，通过可视化上下文影响、交互式修改对话历史和生成推理依赖树来降低分析复杂性，促进对LLM能力的理解。


<details>
  <summary>Details</summary>
Motivation: 当前研究LLM在多轮交互中的推理能力，但面临分析复杂、缺乏可视化工具导致认知负荷高的问题。

Method: 提出VISTA，一个基于Web的可视化交互系统，用于文本分析的多轮推理任务。 VISTA允许用户可视化上下文对模型决策的影响，并交互式地修改对话历史以进行“假设”分析。 平台还可以自动解析会话并生成推理依赖树，提供模型逐步逻辑路径的透明视图。

Result: VISTA通过提供统一的交互框架，显著降低了分析推理链的复杂性，从而有助于更深入地理解当前LLM的能力和局限性。

Conclusion: VISTA是一个开源平台，支持自定义基准和本地模型的轻松集成。

Abstract: Recent research has increasingly focused on the reasoning capabilities of Large Language Models (LLMs) in multi-turn interactions, as these scenarios more closely mirror real-world problem-solving. However, analyzing the intricate reasoning processes within these interactions presents a significant challenge due to complex contextual dependencies and a lack of specialized visualization tools, leading to a high cognitive load for researchers. To address this gap, we present VISTA, an web-based Visual Interactive System for Textual Analytics in multi-turn reasoning tasks. VISTA allows users to visualize the influence of context on model decisions and interactively modify conversation histories to conduct "what-if" analyses across different models. Furthermore, the platform can automatically parse a session and generate a reasoning dependency tree, offering a transparent view of the model's step-by-step logical path. By providing a unified and interactive framework, VISTA significantly reduces the complexity of analyzing reasoning chains, thereby facilitating a deeper understanding of the capabilities and limitations of current LLMs. The platform is open-source and supports easy integration of custom benchmarks and local models.

</details>


### [75] [Text2SQL-Flow: A Robust SQL-Aware Data Augmentation Framework for Text-to-SQL](https://arxiv.org/abs/2511.10192)
*Qifeng Cai,Hao Liang,Chang Xu,Tao Xie,Wentao Zhang,Bin Cui*

Main category: cs.CL

TL;DR: 一个SQL感知的数据增强框架，用于生成大规模、语义有效、结构多样的Text-to-SQL对，并在此基础上构建SQLFlow数据集，以改进Text-to-SQL系统。


<details>
  <summary>Details</summary>
Motivation: 现有的Text-to-SQL数据集稀疏、简单且多样性不足，限制了AI在该领域的性能。

Method: 提出Text2SQL-Flow框架，包含六个增强维度，并整合了SQL执行验证、自然语言问题生成、思维链推理跟踪和数据分类等模块，利用数据库管理器确保跨数据库兼容性和可扩展性。在此基础上构建SQLFlow数据集，包含89,544个标注示例。

Result: 在开源LLM上，使用SQLFlow进行微调能持续提升各项基准测试的性能；在闭源LLM上，提出了一种掩码对齐检索方法，将SQLFlow用作知识库和训练数据，实现了面向结构的示例匹配，优于现有方法。

Conclusion: SQLFlow提供了一个可扩展、以数据为中心的基础，用于推进Text-to-SQL系统，并强调了高质量结构化数据在现代AI中的关键作用。

Abstract: The data-centric paradigm has become pivotal in AI, especially for Text-to-SQL, where performance is limited by scarce, simplistic, and low-diversity datasets. To address this, we propose Text2SQL-Flow, a SQL-aware data augmentation framework that generates large-scale, semantically valid, and structurally diverse Text-to-SQL pairs from minimal seed data. It operates across six augmentation dimensions and integrates an end-to-end pipeline featuring SQL execution verification, natural language question generation, chain-of-thought reasoning traces, and data classification. A modular Database Manager ensures cross-database compatibility and scalability. Using this framework, we build SQLFlow, a high-quality dataset of 89,544 annotated examples. We evaluate SQLFlow in two settings: (1) For open-source LLMs, fine-tuning on SQLFlow consistently improves performance across benchmarks under the same data budget. (2) For closed-source LLMs, we introduce a masked alignment retrieval method that treats SQLFlow as both knowledge base and training data for the retriever. This enables structure-aware example matching by modeling fine-grained alignments between questions and SQL queries. Experiments show our retrieval strategy outperforms existing methods, underscoring the value of SQLFlow's high-fidelity data and our novel technique. Our work establishes a scalable, data-centric foundation for advancing Text-to-SQL systems and highlights the critical role of high-quality structured data in modern AI.

</details>


### [76] [EffiReason-Bench: A Unified Benchmark for Evaluating and Advancing Efficient Reasoning in Large Language Models](https://arxiv.org/abs/2511.10201)
*Junquan Huang,Haotian Wu,Yubo Gao,Yibo Yan,Junyan Zhang,Yonghua Hei,Song Dai,Jie Zhang,Puay Siew Tan,Xuming Hu*

Main category: cs.CL

TL;DR: LLMs 的思维链提示 (CoT) 具有很强的推理能力，但有时会产生冗长的解释，从而增加成本并降低准确性。EffiReason-Bench 是一个统一的基准，用于对高效推理方法进行严格的跨范式评估，涵盖推理蓝图、动态执行和事后改进三个类别。为了进行分步评估，我们通过强制执行标准化的推理结构、全面的选项分析和人工验证的流程，为 CommonsenseQA 和 LogiQA 构建了经过验证的 CoT 注释。我们评估了 7 种方法在 6 种开源 LLM（1B-70B）和 4 个跨越数学、常识和逻辑的数据集上的表现，并提出了 E3-Score，一个受经济权衡模型启发的原则性指标，可实现平滑、稳定的评估。实验表明，没有一种方法能普遍占据主导地位；最佳策略取决于主干规模、任务复杂性和架构。


<details>
  <summary>Details</summary>
Motivation: 评估 LLM 推理的效率，解决当前评估方法碎片化的问题。

Method: 构建 EffiReason-Bench 基准，包含 CommonsenseQA 和 LogiQA 的 CoT 注释，涵盖推理蓝图、动态执行和事后改进三类方法。评估 7 种方法在 6 种开源 LLM 上的表现，并提出 E3-Score 指标。

Result: 在不同规模的 LLM 和不同复杂度的任务上，没有一种方法能普遍胜出。最佳策略取决于主干规模、任务复杂性和架构。

Conclusion: 高效的 LLM 推理方法需要根据具体场景进行选择，不存在万能的最佳策略。

Abstract: Large language models (LLMs) with Chain-of-Thought (CoT) prompting achieve strong reasoning but often produce unnecessarily long explanations, increasing cost and sometimes reducing accuracy. Fair comparison of efficiency-oriented approaches is hindered by fragmented evaluation practices. We introduce EffiReason-Bench, a unified benchmark for rigorous cross-paradigm evaluation of efficient reasoning methods across three categories: Reasoning Blueprints, Dynamic Execution, and Post-hoc Refinement. To enable step-by-step evaluation, we construct verified CoT annotations for CommonsenseQA and LogiQA via a pipeline that enforces standardized reasoning structures, comprehensive option-wise analysis, and human verification. We evaluate 7 methods across 6 open-source LLMs (1B-70B) on 4 datasets spanning mathematics, commonsense, and logic, and propose the E3-Score, a principled metric inspired by economic trade-off modeling that provides smooth, stable evaluation without discontinuities or heavy reliance on heuristics. Experiments show that no single method universally dominates; optimal strategies depend on backbone scale, task complexity, and architecture.

</details>


### [77] [Persona-Aware Alignment Framework for Personalized Dialogue Generation](https://arxiv.org/abs/2511.10215)
*Guanrong Li,Xinyu Liu,Zhen Wu,Xinyu Dai*

Main category: cs.CL

TL;DR: PAL框架通过显式地将对话生成任务的训练目标设置为“个性化对齐”，来解决现有模型生成通用回复的问题，从而提高生成回复的个性化敏感度和语义相关性。


<details>
  <summary>Details</summary>
Motivation: 主流的个性化对话生成模型通常采用token级别的语言模型训练（如Next Token Prediction），这种隐式的方式容易导致模型忽略用户提供的个性化信息，生成过于通用的回复。

Method: 提出了一种新颖的“个性化感知对齐框架”（PAL），它将个性化对齐作为对话生成训练的直接目标。该框架包含“个性化感知学习”和“个性化对齐”两个训练阶段，并采用“选择后生成”的推理策略。

Result: 通过大量实验证明，PAL框架在生成个性化回复方面优于许多现有的最先进的个性化对话方法和大型语言模型。

Conclusion: PAL框架通过显式地将个性化对齐作为训练目标，能够有效提升生成回复的个性化敏感度和语义相关性，优于现有方法。

Abstract: Personalized dialogue generation aims to leverage persona profiles and dialogue history to generate persona-relevant and consistent responses. Mainstream models typically rely on token-level language model training with persona dialogue data, such as Next Token Prediction, to implicitly achieve personalization, making these methods tend to neglect the given personas and generate generic responses. To address this issue, we propose a novel Persona-Aware Alignment Framework (PAL), which directly treats persona alignment as the training objective of dialogue generation. Specifically, PAL employs a two-stage training method including Persona-aware Learning and Persona Alignment, equipped with an easy-to-use inference strategy Select then Generate, to improve persona sensitivity and generate more persona-relevant responses at the semantics level. Through extensive experiments, we demonstrate that our framework outperforms many state-of-the-art personalized dialogue methods and large language models.

</details>


### [78] [LangGPS: Language Separability Guided Data Pre-Selection for Joint Multilingual Instruction Tuning](https://arxiv.org/abs/2511.10229)
*Yangfan Ye,Xiaocheng Feng,Xiachong Feng,Lei Huang,Weitao Ma,Qichen Hong,Yunfei Lu,Duyu Tang,Dandan Tu,Bing Qin*

Main category: cs.CL

TL;DR: LangGPS是一个基于语言可分性的两阶段预选框架，用于优化多语言指令微调的训练数据，以提高LLM的多语言能力，尤其是在低资源语言和理解任务上。它通过区分不同语言样本在模型表示空间中的可分性来指导数据筛选，并发现高可分性样本有助于语言边界形成，低可分性样本则促进跨语言对齐。


<details>
  <summary>Details</summary>
Motivation: 现有语言分离方法在多语言数据训练时，容易忽略语言本身的结构信息，导致模型性能不稳定，尤其是在低资源语言和理解任务上。因此，需要一种新的方法来优化多语言训练数据的选择，以提高模型的泛化能力。

Method: LangGPS框架包含两个阶段：1. 基于语言可分性进行预选：量化不同语言样本在模型表示空间中的可区分度，以此为依据筛选训练数据。2. 结合现有方法进行精选：在预选后的数据子集上，应用现有的数据选择方法进行进一步筛选。

Result: 通过在六个基准和22种语言上的广泛实验，证明LangGPS可以提升现有数据选择方法的有效性和泛化能力。LangGPS有助于低资源语言和理解任务，高可分性样本促进语言边界形成和模型适应，低可分性样本则有助于跨语言对齐。此外，语言可分性可用于多语言课程学习，提升模型性能。

Conclusion: LangGPS提供了一种新的视角来理解多语言数据效用，并支持开发更具语言意识的大语言模型。该方法通过关注语言可分性，显著提高了多语言指令微调的性能，尤其是在数据选择和跨语言对齐方面。

Abstract: Joint multilingual instruction tuning is a widely adopted approach to improve the multilingual instruction-following ability and downstream performance of large language models (LLMs), but the resulting multilingual capability remains highly sensitive to the composition and selection of the training data. Existing selection methods, often based on features like text quality, diversity, or task relevance, typically overlook the intrinsic linguistic structure of multilingual data. In this paper, we propose LangGPS, a lightweight two-stage pre-selection framework guided by language separability which quantifies how well samples in different languages can be distinguished in the model's representation space. LangGPS first filters training data based on separability scores and then refines the subset using existing selection methods. Extensive experiments across six benchmarks and 22 languages demonstrate that applying LangGPS on top of existing selection methods improves their effectiveness and generalizability in multilingual training, especially for understanding tasks and low-resource languages. Further analysis reveals that highly separable samples facilitate the formation of clearer language boundaries and support faster adaptation, while low-separability samples tend to function as bridges for cross-lingual alignment. Besides, we also find that language separability can serve as an effective signal for multilingual curriculum learning, where interleaving samples with diverse separability levels yields stable and generalizable gains. Together, we hope our work offers a new perspective on data utility in multilingual contexts and support the development of more linguistically informed LLMs.

</details>


### [79] [VocalNet-M2: Advancing Low-Latency Spoken Language Modeling via Integrated Multi-Codebook Tokenization and Multi-Token Prediction](https://arxiv.org/abs/2511.10232)
*Yuhao Wang,Ziyang Cheng,Heyang Liu,Ronghua Wu,Qunshan Gu,Yanfeng Wang,Yu Wang*

Main category: cs.CL

TL;DR: VocalNet-M2 是一种新型低延迟语音语言模型，通过多码本分词和多令牌预测策略，将响应延迟从 725ms 降低到 350ms，同时保持了有竞争力的性能。


<details>
  <summary>Details</summary>
Motivation: 当前端到端语音语言模型（SLM）存在响应延迟大的问题，主要是由于语音令牌的自回归生成和对复杂流匹配模型（flow-matching models）的依赖。

Method: 提出了一种名为 VocalNet-M2 的新型低延迟 SLM，该模型集成了多码本分词器（multi-codebook tokenizer）和多令牌预测（MTP）策略。该模型直接生成多码本语音令牌，无需延迟较高的流匹配模型，并通过 MTP 策略提高生成效率和整体性能。

Result: 实验证明，VocalNet-M2 显著降低了首块延迟（从约 725ms 减少到 350ms），同时在主流 SLM 中保持了有竞争力的性能。

Conclusion: VocalNet-M2 通过采用多码本分词和 MTP 策略，成功解决了当前 SLM 的延迟问题，为实时交互应用提供了高效且高性能的解决方案。该研究还对单码本和多码本策略进行了比较，为未来 SLM 的发展提供了有价值的见解。

Abstract: Current end-to-end spoken language models (SLMs) have made notable progress, yet they still encounter considerable response latency. This delay primarily arises from the autoregressive generation of speech tokens and the reliance on complex flow-matching models for speech synthesis. To overcome this, we introduce VocalNet-M2, a novel low-latency SLM that integrates a multi-codebook tokenizer and a multi-token prediction (MTP) strategy. Our model directly generates multi-codebook speech tokens, thus eliminating the need for a latency-inducing flow-matching model. Furthermore, our MTP strategy enhances generation efficiency and improves overall performance. Extensive experiments demonstrate that VocalNet-M2 achieves a substantial reduction in first chunk latency (from approximately 725ms to 350ms) while maintaining competitive performance across mainstream SLMs. This work also provides a comprehensive comparison of single-codebook and multi-codebook strategies, offering valuable insights for developing efficient and high-performance SLMs for real-time interactive applications.

</details>


### [80] [MTR-DuplexBench: Towards a Comprehensive Evaluation of Multi-Round Conversations for Full-Duplex Speech Language Models](https://arxiv.org/abs/2511.10262)
*He Zhang,Wenqian Cui,Haoning Xu,Xiaohui Li,Lei Zhu,Shaohua Ma,Irwin King*

Main category: cs.CL

TL;DR: FD-SLMs 实现了实时、重叠的对话交互，但现有基准未能充分评估其多轮对话能力，尤其是在指令遵循和安全方面。我们提出了 MTR-DuplexBench，一个用于评估 FD-SLM 在多轮对话质量、对话动态、指令遵循和安全方面的创新基准。


<details>
  <summary>Details</summary>
Motivation: 现有基准主要关注单轮交互和对话特征，忽略了多轮通信的复杂性以及指令遵循和安全等关键能力。评估 FD-SLM 在多轮设置中面临挑战，包括通信中的回合边界模糊和模型推理中的上下文不一致。

Method: 我们提出了 MTR-DuplexBench，一个将连续全双工对话分割成离散回合的新颖基准，能够对 FD-SLM 在对话质量、对话动态、指令遵循和安全方面的进行全面的、逐回合的评估。

Result: 实验结果表明，当前的 FD-SLM 在跨多轮和评估维度保持一致性能方面存在困难，突显了我们提出的基准的必要性和有效性。

Conclusion: MTR-DuplexBench 能够对 FD-SLM 进行全面的、逐回合的评估，并揭示了当前模型在多轮对话中的挑战。

Abstract: Full-Duplex Speech Language Models (FD-SLMs) enable real-time, overlapping conversational interactions, offering a more dynamic user experience compared to traditional half-duplex models. However, existing benchmarks primarily focus on evaluating single-round interactions and conversational features, neglecting the complexities of multi-round communication and critical capabilities such as instruction following and safety. Evaluating FD-SLMs in multi-round settings poses significant challenges, including blurred turn boundaries in communication and context inconsistency during model inference. To address these gaps, we introduce MTR-DuplexBench, a novel benchmark that segments continuous full-duplex dialogues into discrete turns, enabling comprehensive, turn-by-turn evaluation of FD-SLMs across dialogue quality, conversational dynamics, instruction following, and safety. Experimental results reveal that current FD-SLMs face difficulties in maintaining consistent performance across multiple rounds and evaluation dimensions, highlighting the necessity and effectiveness of our proposed benchmark. The benchmark and code will be available in the future.

</details>


### [81] [Local Hybrid Retrieval-Augmented Document QA](https://arxiv.org/abs/2511.10297)
*Paolo Astrino*

Main category: cs.CL

TL;DR: 提出一个结合语义理解和关键词精确度、在本地基础设施上完全运行且无需互联网访问的问答系统，以解决在数据隐私和准确性之间的权衡问题。


<details>
  <summary>Details</summary>
Motivation: 组织在处理敏感文件时面临在采用云AI（功能强大但牺牲隐私）和本地处理（安全但准确性差）之间的困境。

Method: 结合语义理解和关键词精确度，在本地基础设施上运行，无需互联网访问。

Result: 在法律、科学和对话文档上，针对复杂查询实现了具有竞争力的准确性，同时所有数据保留在本地。通过平衡两种互补的检索策略并利用消费级硬件加速，系统能够以最少的错误提供可靠的答案。

Conclusion: 企业AI部署中，隐私和性能不必相互排斥。

Abstract: Organizations handling sensitive documents face a critical dilemma: adopt cloud-based AI systems that offer powerful question-answering capabilities but compromise data privacy, or maintain local processing that ensures security but delivers poor accuracy. We present a question-answering system that resolves this trade-off by combining semantic understanding with keyword precision, operating entirely on local infrastructure without internet access. Our approach demonstrates that organizations can achieve competitive accuracy on complex queries across legal, scientific, and conversational documents while keeping all data on their machines. By balancing two complementary retrieval strategies and using consumer-grade hardware acceleration, the system delivers reliable answers with minimal errors, letting banks, hospitals, and law firms adopt conversational document AI without transmitting proprietary information to external providers. This work establishes that privacy and performance need not be mutually exclusive in enterprise AI deployment.

</details>


### [82] [Rectify Evaluation Preference: Improving LLMs' Critique on Math Reasoning via Perplexity-aware Reinforcement Learning](https://arxiv.org/abs/2511.10303)
*Changyuan Tian,Zhicong Lu,Shuang Qian,Nayu Liu,Peiguang Li,Li Jin,Leiyi Hu,Zhizhao Zeng,Sirui Wang,Ke Zeng,Zhi Guo*

Main category: cs.CL

TL;DR: LLM在数学推理中的评估偏好不平衡，导致其在批改错误时表现不佳。本文提出了一种新颖的、感知困惑度的强化学习算法来纠正这种偏好，并提高了LLM的批改能力。


<details>
  <summary>Details</summary>
Motivation: 当前的LLM在多步数学推理（MsMR）方面存在不足，主要是由于其在自动批改推理过程中的错误以及给出最终判决的能力有待提高。现有方法大多依赖于精心设计的监督微调演示，但未能深入研究LLM批改能力差的根本原因。

Method: 提出了一种新颖的、感知困惑度的强化学习算法。首先，构建了一个“一对多问题-解决方案”（OPS）基准，用于量化LLM在评估自身和其他模型生成的解决方案时的行为差异。然后，通过对困惑度进行统计偏好分析，发现LLM倾向于将困惑度较低的解决方案判定为正确，即“评估偏好不平衡”。为了纠正这种偏好，在“分组相对策略优化”算法中引入困惑度作为调节因子，引导LLM探索将低困惑度判定为错误、高困惑度判定为正确的路径。

Result: 在自建的OPS基准和现有的可用评判基准上的大量实验结果证明了该方法的有效性。

Conclusion: 通过引入困惑度感知的强化学习算法，成功纠正了LLM评估偏好不平衡的问题，显著提升了其在多步数学推理中的批改能力。

Abstract: To improve Multi-step Mathematical Reasoning (MsMR) of Large Language Models (LLMs), it is crucial to obtain scalable supervision from the corpus by automatically critiquing mistakes in the reasoning process of MsMR and rendering a final verdict of the problem-solution. Most existing methods rely on crafting high-quality supervised fine-tuning demonstrations for critiquing capability enhancement and pay little attention to delving into the underlying reason for the poor critiquing performance of LLMs. In this paper, we orthogonally quantify and investigate the potential reason -- imbalanced evaluation preference, and conduct a statistical preference analysis. Motivated by the analysis of the reason, a novel perplexity-aware reinforcement learning algorithm is proposed to rectify the evaluation preference, elevating the critiquing capability. Specifically, to probe into LLMs' critiquing characteristics, a One-to-many Problem-Solution (OPS) benchmark is meticulously constructed to quantify the behavior difference of LLMs when evaluating the problem solutions generated by itself and others. Then, to investigate the behavior difference in depth, we conduct a statistical preference analysis oriented on perplexity and find an intriguing phenomenon -- ``LLMs incline to judge solutions with lower perplexity as correct'', which is dubbed as \textit{imbalanced evaluation preference}. To rectify this preference, we regard perplexity as the baton in the algorithm of Group Relative Policy Optimization, supporting the LLMs to explore trajectories that judge lower perplexity as wrong and higher perplexity as correct. Extensive experimental results on our built OPS and existing available critic benchmarks demonstrate the validity of our method.

</details>


### [83] [BhashaKritika: Building Synthetic Pretraining Data at Scale for Indic Languages](https://arxiv.org/abs/2511.10338)
*Guduru Manoj,Neel Prabhanjan Rachamalla,Ashish Kulkarni,Gautam Rajeev,Jay Piplodiya,Arul Menezes,Shaharukh Khan,Souvik Rana,Manya Sah,Chandra Khatri,Shubham Agarwal*

Main category: cs.CL

TL;DR: 通过在指标语言上进行预训练，为低资源语言中的LLM提供高质量的预训练数据。


<details>
  <summary>Details</summary>
Motivation: 在低资源语言环境中，LLM的益处分布不均，因此需要生成高质量的预训练数据。

Method: 构建了包含540B个标记的大规模合成数据集BhashaKritika，涵盖10种指标语言，并采用了5种不同的生成技术。研究了基于文档、个人和主题进行生成的影响，分析了语言选择对数据质量的影响，并比较了英文内容翻译与指标语言本地生成的效果。引入了一个模块化的质量评估流程，用于可扩展的、对语言敏感的评估，包括脚本和语言检测、元数据一致性检查、N-gram重复分析和基于KenLM模型的困惑度过滤。

Result: 模型运行的实证结果揭示了生成策略的关键权衡，并强调了构建有效的多语言语料库的最佳实践。

Conclusion: BhashaKritika数据集和所提出的评估流程为低资源语言中的LLM预训练提供了宝贵的资源和方法。

Abstract: In the context of pretraining of Large Language Models (LLMs), synthetic data has emerged as an alternative for generating high-quality pretraining data at scale. This is particularly beneficial in low-resource language settings where the benefits of recent LLMs have been unevenly distributed across languages. In this work, we present a systematic study on the generation and evaluation of synthetic multilingual pretraining data for Indic languages, where we construct a large-scale synthetic dataset BhashaKritika, comprising 540B tokens using 5 different techniques for 10 languages. We explore the impact of grounding generation in documents, personas, and topics. We analyze how language choice, both in the prompt instructions and document grounding, affects data quality, and we compare translations of English content with native generation in Indic languages. To support scalable and language-sensitive evaluation, we introduce a modular quality evaluation pipeline that integrates script and language detection, metadata consistency checks, n-gram repetition analysis, and perplexity-based filtering using KenLM models. Our framework enables robust quality control across diverse scripts and linguistic contexts. Empirical results through model runs reveal key trade-offs in generation strategies and highlight best practices for constructing effective multilingual corpora.

</details>


### [84] [Knowledge Graphs Generation from Cultural Heritage Texts: Combining LLMs and Ontological Engineering for Scholarly Debates](https://arxiv.org/abs/2511.10354)
*Andrea Schimmenti,Valentina Pasqual,Fabio Vitali,Marieke van Erp*

Main category: cs.CL

TL;DR: 本研究提出了一种名为ATR4CH的系统化方法，利用大型语言模型从文化遗产文本中提取知识，并构建知识图谱，旨在解决文化遗产知识难以系统化查询的问题。该方法通过五步迭代流程，结合标注模型、本体框架和LLM提取，并在真实案例（争议性物品维基百科条目）中进行了验证。


<details>
  <summary>Details</summary>
Motivation: 文化遗产文本蕴含丰富知识，但其非结构化特性给系统化查询带来了挑战，迫切需要将文本转化为结构化知识图谱。

Method: ATR4CH方法是一个为期五步的系统化流程：基础分析、标注模式开发、流水线架构、集成优化和全面评估。该方法结合了标注模型、本体框架和大型语言模型（LLM）的提取能力，并通过迭代开发进行完善。研究采用了Claude Sonnet 3.7、Llama 3.3 70B和GPT-4o-mini三种LLM，并构建了一个包含三个LLM的顺序流水线。

Result: 研究结果显示，ATR4CH方法在元数据提取方面达到了0.96-0.99的F1分数，实体识别方面为0.7-0.8，假设提取方面为0.65-0.75，证据提取方面为0.95-0.97，论述表示方面（G-EVAL）为0.62。小型模型也表现出竞争力，使得成本效益更高的部署成为可能。

Conclusion: ATR4CH是首个用于协调基于LLM的提取与文化遗产本体的系统化方法。它为跨文化遗产领域和机构资源提供了可复制的、适应性强的框架。该方法能够帮助文化遗产机构系统地将文本知识转化为可查询的知识图谱，支持自动化的元数据丰富和知识发现。然而，研究局限于维基百科文章，并且在后处理阶段仍需要人工监督。

Abstract: Cultural Heritage texts contain rich knowledge that is difficult to query systematically due to the challenges of converting unstructured discourse into structured Knowledge Graphs (KGs). This paper introduces ATR4CH (Adaptive Text-to-RDF for Cultural Heritage), a systematic five-step methodology for Large Language Model-based Knowledge Extraction from Cultural Heritage documents. We validate the methodology through a case study on authenticity assessment debates. Methodology - ATR4CH combines annotation models, ontological frameworks, and LLM-based extraction through iterative development: foundational analysis, annotation schema development, pipeline architecture, integration refinement, and comprehensive evaluation. We demonstrate the approach using Wikipedia articles about disputed items (documents, artifacts...), implementing a sequential pipeline with three LLMs (Claude Sonnet 3.7, Llama 3.3 70B, GPT-4o-mini). Findings - The methodology successfully extracts complex Cultural Heritage knowledge: 0.96-0.99 F1 for metadata extraction, 0.7-0.8 F1 for entity recognition, 0.65-0.75 F1 for hypothesis extraction, 0.95-0.97 for evidence extraction, and 0.62 G-EVAL for discourse representation. Smaller models performed competitively, enabling cost-effective deployment. Originality - This is the first systematic methodology for coordinating LLM-based extraction with Cultural Heritage ontologies. ATR4CH provides a replicable framework adaptable across CH domains and institutional resources. Research Limitations - The produced KG is limited to Wikipedia articles. While the results are encouraging, human oversight is necessary during post-processing. Practical Implications - ATR4CH enables Cultural Heritage institutions to systematically convert textual knowledge into queryable KGs, supporting automated metadata enrichment and knowledge discovery.

</details>


### [85] [TruthfulRAG: Resolving Factual-level Conflicts in Retrieval-Augmented Generation with Knowledge Graphs](https://arxiv.org/abs/2511.10375)
*Shuyi Liu,Yuming Shang,Xi Zhang*

Main category: cs.CL

TL;DR: TruthfulRAG框架利用知识图谱解决检索增强生成（RAG）系统中检索到的外部信息与大型语言模型（LLM）内部知识之间的事实冲突，提高了生成内容的准确性和可靠性。


<details>
  <summary>Details</summary>
Motivation: 检索增强生成（RAG）系统在整合外部知识方面能力强大，但面临检索到的信息与LLM内部知识发生冲突的挑战，这会影响生成内容的准确性。现有方法在解决冲突时存在片面性，无法有效处理事实层面的不一致。TruthfulRAG旨在解决这一局限性。

Method: TruthfulRAG框架通过以下步骤解决知识冲突：1. 从检索到的内容中提取三元组，构建知识图谱（KG）。2. 利用基于查询的图检索来识别相关知识。3. 采用基于熵的过滤机制，精确定位冲突元素并减轻事实不一致性。

Result: 通过大量实验证明，TruthfulRAG相比现有方法表现更优，能有效缓解知识冲突，增强RAG系统的鲁棒性和可信度。

Conclusion: TruthfulRAG是第一个利用知识图谱解决RAG系统事实层面知识冲突的框架，能够帮助LLM生成忠实且准确的响应，提高了RAG系统的整体性能和可靠性。

Abstract: Retrieval-Augmented Generation (RAG) has emerged as a powerful framework for enhancing the capabilities of Large Language Models (LLMs) by integrating retrieval-based methods with generative models. As external knowledge repositories continue to expand and the parametric knowledge within models becomes outdated, a critical challenge for RAG systems is resolving conflicts between retrieved external information and LLMs' internal knowledge, which can significantly compromise the accuracy and reliability of generated content. However, existing approaches to conflict resolution typically operate at the token or semantic level, often leading to fragmented and partial understanding of factual discrepancies between LLMs' knowledge and context, particularly in knowledge-intensive tasks. To address this limitation, we propose TruthfulRAG, the first framework that leverages Knowledge Graphs (KGs) to resolve factual-level knowledge conflicts in RAG systems. Specifically, TruthfulRAG constructs KGs by systematically extracting triples from retrieved content, utilizes query-based graph retrieval to identify relevant knowledge, and employs entropy-based filtering mechanisms to precisely locate conflicting elements and mitigate factual inconsistencies, thereby enabling LLMs to generate faithful and accurate responses. Extensive experiments reveal that TruthfulRAG outperforms existing methods, effectively alleviating knowledge conflicts and improving the robustness and trustworthiness of RAG systems.

</details>


### [86] [Position: On the Methodological Pitfalls of Evaluating Base LLMs for Reasoning](https://arxiv.org/abs/2511.10381)
*Jason Chan,Zhixue Zhao,Robert Gaizauskas*

Main category: cs.CL

TL;DR: 评估基础大语言模型（LLM）的推理能力存在方法论上的局限性，因为它们的预训练目标与推理评估的规范质量（如正确性）之间存在根本性不匹配。


<details>
  <summary>Details</summary>
Motivation: 现有研究探讨大语言模型（LLM）的推理能力，以揭示其局限性、类人偏见和潜在过程，但忽略了评估基础LLM推理能力时存在的方法论问题。

Method: 指出基础LLM的预训练目标（符合语言模式的统计合理性）与评估推理的规范质量（正确性）之间存在根本性不匹配，并论证了基础LLM生成逻辑上有效或无效的结论是符合语言模式的统计合理性的偶然副产品。

Result: 基础LLM生成的结论是符合语言模式的统计合理性的偶然副产品，而非对正确答案的真实尝试。关于基础LLM推理能力的结论不能推广到经过指令遵循优化后训练的LLM。

Conclusion: 呼吁批判性地重新审视那些隐含地依赖于基础LLM输出可作为其正确答案的真实尝试的假设，以及其推理能力的结论可以推广到后训练LLM的假设。并呼吁未来的研究应考虑这些方法论上的陷阱。

Abstract: Existing work investigates the reasoning capabilities of large language models (LLMs) to uncover their limitations, human-like biases and underlying processes. Such studies include evaluations of base LLMs (pre-trained on unlabeled corpora only) for this purpose. Our position paper argues that evaluating base LLMs' reasoning capabilities raises inherent methodological concerns that are overlooked in such existing studies. We highlight the fundamental mismatch between base LLMs' pretraining objective and normative qualities, such as correctness, by which reasoning is assessed. In particular, we show how base LLMs generate logically valid or invalid conclusions as coincidental byproducts of conforming to purely linguistic patterns of statistical plausibility. This fundamental mismatch challenges the assumptions that (a) base LLMs' outputs can be assessed as their bona fide attempts at correct answers or conclusions; and (b) conclusions about base LLMs' reasoning can generalize to post-trained LLMs optimized for successful instruction-following. We call for a critical re-examination of existing work that relies implicitly on these assumptions, and for future work to account for these methodological pitfalls.

</details>


### [87] [DELICATE: Diachronic Entity LInking using Classes And Temporal Evidence](https://arxiv.org/abs/2511.10404)
*Cristian Santini,Sebastian Barzaghi,Paolo Sernani,Emanuele Frontoni,Mehwish Alam*

Main category: cs.CL

TL;DR: 本研究提出了DELICATE神经符号方法和ENEIDE数据集，以解决历史意大利语实体链接中的挑战。


<details>
  <summary>Details</summary>
Motivation: 尽管自然语言处理取得了显著进展，但由于复杂的文档类型、缺乏领域特定数据集和模型以及长尾实体（知识库中代表性不足的实体），人文领域的实体链接（EL）任务仍然充满挑战。

Method: DELICATE是一种新颖的神经符号方法，结合了基于BERT的编码器和来自Wikidata的上下文信息，利用时间可行性和实体类型一致性来选择合适的知识库实体。ENEIDE是一个多领域实体链接语料库，包含19世纪至20世纪的文学和政治文本。

Result: DELICATE在历史意大利语实体链接任务上表现优于其他模型，即使与参数量更大的模型相比也是如此。此外，DELICATE的置信分数和特征敏感性提供了比纯神经方法更具可解释性的结果。

Conclusion: DELICATE通过结合神经和符号方法，并利用ENEIDE数据集，有效解决了历史意大利语实体链接的挑战，并在性能和可解释性方面取得了优势。

Abstract: In spite of the remarkable advancements in the field of Natural Language Processing, the task of Entity Linking (EL) remains challenging in the field of humanities due to complex document typologies, lack of domain-specific datasets and models, and long-tail entities, i.e., entities under-represented in Knowledge Bases (KBs). The goal of this paper is to address these issues with two main contributions. The first contribution is DELICATE, a novel neuro-symbolic method for EL on historical Italian which combines a BERT-based encoder with contextual information from Wikidata to select appropriate KB entities using temporal plausibility and entity type consistency. The second contribution is ENEIDE, a multi-domain EL corpus in historical Italian semi-automatically extracted from two annotated editions spanning from the 19th to the 20th century and including literary and political texts. Results show how DELICATE outperforms other EL models in historical Italian even if compared with larger architectures with billions of parameters. Moreover, further analyses reveal how DELICATE confidence scores and features sensitivity provide results which are more explainable and interpretable than purely neural methods.

</details>


### [88] [Analogical Structure, Minimal Contextual Cues and Contrastive Distractors: Input Design for Sample-Efficient Linguistic Rule Induction](https://arxiv.org/abs/2511.10441)
*Chunyang Jiang,Paola Merlo*

Main category: cs.CL

TL;DR: 通过类比范式组织，轻量级模型能够以极少的数据在语言规则学习上媲美大型模型。


<details>
  <summary>Details</summary>
Motivation: 探究类比范式组织是否能使轻量级模型在数据量极小的情况下，也能匹配大型模型在海量数据上的表现。

Method: 提出一种结合类比结构、对比学习和最小上下文线索的计算方法，并用结构化完成任务进行测试，模型需要从类比模式和对比选项中识别正确的句子。

Result: 在英语的致使/非致使转换任务上，使用仅一百个结构化示例训练的轻量级模型（BERT+CNN，0.5M参数）达到了F1=0.95，超过了零样本的GPT-3（F1=0.87）。消融研究表明类比组织和对比结构能提升性能，跨现象验证也证实了该方法的鲁棒性。

Conclusion: 类比范式组织能够让模型在数据量远小于传统方法的情况下，实现具有竞争力的语言规则学习。

Abstract: Large language models achieve strong performance through training on vast datasets. Can analogical paradigm organization enable lightweight models to match this performance with minimal data? We develop a computational approach implementing three cognitive-inspired principles: analogical structure, contrastive learning, and minimal contextual cues. We test this approach with structured completion tasks where models identify correct sentence completions from analogical patterns with contrastive alternatives. Training lightweight models (BERT+CNN, $0.5M$ parameters) on only one hundred structured examples of English causative/inchoative alternations achieves $F1=0.95$, outperforming zero-shot \texttt{GPT-o3} ($F1=0.87$). Ablation studies confirm that analogical organization and contrastive structure improve performance, consistently surpassing randomly shuffled baselines across architectures. Cross-phenomenon validation using unspecified object alternations replicates these efficiency gains, confirming approach robustness. Our results show that analogical paradigm organization enables competitive linguistic rule learning with orders of magnitude less data than conventional approaches require.

</details>


### [89] [Reasoning About Intent for Ambiguous Requests](https://arxiv.org/abs/2511.10453)
*Irina Saparina,Mirella Lapata*

Main category: cs.CL

TL;DR: 为了解决大型语言模型在处理模糊请求时可能产生的意图误解问题，提出了一种生成多个解释-答案对的结构化响应方法，该方法通过强化学习和自定义奖励函数进行训练，旨在提高答案覆盖率和用户满意度。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在处理模糊请求时，常常会隐含地选择一种解释，这可能导致用户不满意并带来安全风险。

Method: 生成多个解释-答案对的结构化响应，并使用多种有效答案作为监督，通过强化学习和自定义奖励函数进行模型训练。

Result: 在对话式问答和语义解析实验中，该方法实现了比基线方法更高的有效答案覆盖率，并且人类评估证实了预测的解释与答案高度一致。

Conclusion: 该方法通过明确解释提高了透明度，通过单次生成步骤提高了效率，并通过结构化输出来支持下游应用。

Abstract: Large language models often respond to ambiguous requests by implicitly committing to one interpretation. Intent misunderstandings can frustrate users and create safety risks. To address this, we propose generating multiple interpretation-answer pairs in a single structured response to ambiguous requests. Our models are trained with reinforcement learning and customized reward functions using multiple valid answers as supervision. Experiments on conversational question answering and semantic parsing demonstrate that our method achieves higher coverage of valid answers than baseline approaches. Human evaluation confirms that predicted interpretations are highly aligned with their answers. Our approach promotes transparency with explicit interpretations, achieves efficiency by requiring only one generation step, and supports downstream applications through its structured output format.

</details>


### [90] [Exploring State Tracking Capabilities of Large Language Models](https://arxiv.org/abs/2511.10457)
*Kiamehr Rezaee,Jose Camacho-Collados,Mohammad Taher Pilehvar*

Main category: cs.CL

TL;DR: 大型语言模型（LLMs）在状态跟踪方面表现出能力，尤其是在结合思维链（Chain of Thought）等机制时，但早期模型在长期跟踪方面存在困难。


<details>
  <summary>Details</summary>
Motivation: 评估大型语言模型（LLMs）在状态跟踪任务上的表现，并将此能力与其他因素分离开来。

Method: 提出一个基于三个明确定义的状态跟踪任务的基准，并分析LLMs在不同场景下的性能。

Result: GPT-4和Llama3等新一代LLMs能够进行状态跟踪，尤其是结合思维链（Chain of Thought）时。早期模型虽然能理解任务并在初始阶段解决，但在一定步数后会失败。

Conclusion: 尽管新一代LLMs在状态跟踪方面表现出潜力，但需要进一步的研究来克服长期跟踪的挑战。

Abstract: Large Language Models (LLMs) have demonstrated impressive capabilities in solving complex tasks, including those requiring a certain level of reasoning. In this paper, we focus on state tracking, a problem where models need to keep track of the state governing a number of entities. To isolate the state tracking component from other factors, we propose a benchmark based on three well-defined state tracking tasks and analyse the performance of LLMs in different scenarios. The results indicate that the recent generation of LLMs (specifically, GPT-4 and Llama3) are capable of tracking state, especially when integrated with mechanisms such as Chain of Thought. However, models from the former generation, while understanding the task and being able to solve it at the initial stages, often fail at this task after a certain number of steps.

</details>


### [91] [LocalBench: Benchmarking LLMs on County-Level Local Knowledge and Reasoning](https://arxiv.org/abs/2511.10459)
*Zihan Gao,Yifei Xu,Jacob Thebault-Spieker*

Main category: cs.CL

TL;DR: LLMs在处理宏观地理任务方面表现良好，但在理解超本地知识方面存在不足。现有的基准测试无法捕捉这种复杂性。我们提出了LocalBench，这是一个涵盖美国526个县、包含14,782个问答对的基准测试，用于评估LLMs的县级本地知识。我们的评估显示，即使是最好的模型在叙事类问题上的准确率也只有56.8%，在数值推理方面低于15.5%。模型规模和网络增强并不总能提高性能，例如，搜索能提高Gemini的准确率，但会降低GPT系列的性能。


<details>
  <summary>Details</summary>
Motivation: 随着真实世界应用（如公民平台和社区新闻）越来越需要能够理解邻里动态、文化叙事和地方治理的人工智能系统，LLMs在处理超本地知识方面的能力变得日益重要。然而，现有的基准测试往往依赖于粗粒度数据或孤立的参考，无法捕捉这种复杂性。

Method: 我们提出了LocalBench，这是第一个系统性评估美国县级本地知识的基准测试。该基准测试基于Localness概念框架，包含14,782个经过验证的问答对，覆盖美国49个州的526个县，整合了人口普查统计、地方论坛讨论和地区新闻等多种来源。它涵盖了地方的物理、认知和关系维度。我们使用LocalBench在闭卷和网络增强两种设置下评估了13个最先进的LLMs。

Result: 评估结果表明，即使是表现最好的模型，在叙事类问题上的准确率也仅为56.8%，在数值推理方面的准确率低于15.5%。此外，更大的模型规模和网络增强并不总能带来更好的性能，例如，搜索将Gemini的准确率提高了+13.6%，但将GPT系列的性能降低了-11.4%。

Conclusion: 这些结果凸显了开发能够支持公平、地域意识的人工智能系统的紧迫性，这些系统能够理解不同地理和文化背景下地方社区的多样化、细粒度现实。

Abstract: Large language models (LLMs) have been widely evaluated on macro-scale geographic tasks, such as global factual recall, event summarization, and regional reasoning. Yet, their ability to handle hyper-local knowledge remains poorly understood. This gap is increasingly consequential as real-world applications, from civic platforms to community journalism, demand AI systems that can reason about neighborhood-specific dynamics, cultural narratives, and local governance. Existing benchmarks fall short in capturing this complexity, often relying on coarse-grained data or isolated references. We present LocalBench, the first benchmark designed to systematically evaluate LLMs on county-level local knowledge across the United States. Grounded in the Localness Conceptual Framework, LocalBench includes 14,782 validated question-answer pairs across 526 U.S. counties in 49 states, integrating diverse sources such as Census statistics, local subreddit discourse, and regional news. It spans physical, cognitive, and relational dimensions of locality. Using LocalBench, we evaluate 13 state-of-the-art LLMs under both closed-book and web-augmented settings. Our findings reveal critical limitations: even the best-performing models reach only 56.8% accuracy on narrative-style questions and perform below 15.5% on numerical reasoning. Moreover, larger model size and web augmentation do not guarantee better performance, for example, search improves Gemini's accuracy by +13.6%, but reduces GPT-series performance by -11.4%. These results underscore the urgent need for language models that can support equitable, place-aware AI systems: capable of engaging with the diverse, fine-grained realities of local communities across geographic and cultural contexts.

</details>


### [92] [Beyond Elicitation: Provision-based Prompt Optimization for Knowledge-Intensive Tasks](https://arxiv.org/abs/2511.10465)
*Yunzhe Xu,Zhuosheng Zhang,Zhe Liu*

Main category: cs.CL

TL;DR: KPPO通过整合知识来优化提示，解决了现有方法在知识密集型任务中的局限性，并在15个基准测试中平均提高了6%的性能，同时保持了相似或更低的token消耗。


<details>
  <summary>Details</summary>
Motivation: 现有的基于诱导的提示优化方法在知识密集型任务中存在局限性，无法提供专业领域所需的 factual knowledge, terminology precision, and reasoning patterns。

Method: KPPO框架通过系统性地整合知识来优化提示，包括知识差距填充机制、考虑性能改进和分布稳定性的批次候选评估方法，以及平衡性能和token效率的自适应知识剪枝策略。

Result: 在15个知识密集型基准测试中，KPPO的平均性能比最强的基线提高了约6%，同时实现了可比或更低的token消耗，并减少了高达29%的token使用量。

Conclusion: KPPO框架在知识密集型任务中优于基于诱导的方法，通过系统性地整合知识来优化提示，提高了性能并保持了token效率。

Abstract: While prompt optimization has emerged as a critical technique for enhancing language model performance, existing approaches primarily focus on elicitation-based strategies that search for optimal prompts to activate models' capabilities. These methods exhibit fundamental limitations when addressing knowledge-intensive tasks, as they operate within fixed parametric boundaries rather than providing the factual knowledge, terminology precision, and reasoning patterns required in specialized domains. To address these limitations, we propose Knowledge-Provision-based Prompt Optimization (KPPO), a framework that reformulates prompt optimization as systematic knowledge integration rather than potential elicitation. KPPO introduces three key innovations: 1) a knowledge gap filling mechanism for knowledge gap identification and targeted remediation; 2) a batch-wise candidate evaluation approach that considers both performance improvement and distributional stability; 3) an adaptive knowledge pruning strategy that balances performance and token efficiency, reducing up to 29% token usage. Extensive evaluation on 15 knowledge-intensive benchmarks from various domains demonstrates KPPO's superiority over elicitation-based methods, with an average performance improvement of ~6% over the strongest baseline while achieving comparable or lower token consumption. Code at: https://github.com/xyz9911/KPPO.

</details>


### [93] [Rubric-Based Benchmarking and Reinforcement Learning for Advancing LLM Instruction Following](https://arxiv.org/abs/2511.10507)
*Yun He,Wenzhe Li,Hejia Zhang,Songlin Li,Karishma Mandyam,Sopan Khosla,Yuanhao Xiong,Nanshu Wang,Selina Peng,Beibin Li,Shengjie Bi,Shishir G. Patil,Qi Qi,Shengyu Feng,Julian Katz-Samuels,Richard Yuanzhe Pang,Sujan Gonugondla,Hunter Lang,Yue Yu,Yundi Qian,Maryam Fazel-Zarandi,Licheng Yu,Amine Benhalloum,Hany Awadalla,Manaal Faruqui*

Main category: cs.CL

TL;DR: LLMs在复杂指令遵循方面仍面临挑战，本研究提出了AdvancedIF基准和RIFL训练框架，显著提升了LLMs的指令遵循能力。


<details>
  <summary>Details</summary>
Motivation: 现有的LLM在遵循复杂、多轮、系统级指令方面存在挑战，且缺乏高质量的基准和可靠的奖励信号来评估和训练这些能力。

Method: 提出AdvancedIF基准（包含1600+指令和评分标准）和RIFL（基于评分标准的指令遵循学习）训练框架，RIFL包括评分生成、评分验证器微调和奖励塑造。

Result: RIFL在AdvancedIF基准上实现了6.7%的绝对提升，并在其他公开基准上也取得了优异结果，验证了RIFL各组成部分的有效性。

Conclusion: 评分标准是训练和评估LLM高级指令遵循能力的有效工具，有助于构建更强大、更可靠的AI系统。

Abstract: Recent progress in large language models (LLMs) has led to impressive performance on a range of tasks, yet advanced instruction following (IF)-especially for complex, multi-turn, and system-prompted instructions-remains a significant challenge. Rigorous evaluation and effective training for such capabilities are hindered by the lack of high-quality, human-annotated benchmarks and reliable, interpretable reward signals. In this work, we introduce AdvancedIF (we will release this benchmark soon), a comprehensive benchmark featuring over 1,600 prompts and expert-curated rubrics that assess LLMs ability to follow complex, multi-turn, and system-level instructions. We further propose RIFL (Rubric-based Instruction-Following Learning), a novel post-training pipeline that leverages rubric generation, a finetuned rubric verifier, and reward shaping to enable effective reinforcement learning for instruction following. Extensive experiments demonstrate that RIFL substantially improves the instruction-following abilities of LLMs, achieving a 6.7% absolute gain on AdvancedIF and strong results on public benchmarks. Our ablation studies confirm the effectiveness of each component in RIFL. This work establishes rubrics as a powerful tool for both training and evaluating advanced IF in LLMs, paving the way for more capable and reliable AI systems.

</details>


### [94] [LOCA-R: Near-Perfect Performance on the Chinese Physics Olympiad 2025](https://arxiv.org/abs/2511.10515)
*Dong-Shan Jian,Xiang Li,Chen-Xu Yan,Hui-Wen Zheng,Zhi-Zhang Bian,You-Le Fang,Sheng-Qi Zhang,Bing-Rui Gong,Ren-Xi He,Jing-Tian Zhang,Ce Meng,Yan-Qing Ma*

Main category: cs.CL

TL;DR: LOCA-R 是一个用于解决复杂推理问题的框架，在 CPhO 2025 物理竞赛理论考试中取得了近乎完美的分数（313/320），超越了人类最高分和所有基线方法。


<details>
  <summary>Details</summary>
Motivation: 奥赛级物理题的解决需要精确计算、抽象推理和物理原理的掌握，这对人类和 AI 都是巨大挑战。CPhO 因其复杂性和深度，是测试这些能力的理想平台。

Method: 本文提出并应用了 LOCA-R（LOgical Chain Augmentation for Reasoning）框架，这是 LOCA 框架的改进版本，专为复杂推理而设计。

Result: LOCA-R 在 CPhO 2025 理论考试中获得了 313/320 的高分，超过了人类最高分和所有基线方法。

Conclusion: LOCA-R 在解决复杂物理问题方面表现出色，证明了其在高级推理能力上的有效性。

Abstract: Olympiad-level physics problem-solving presents a significant challenge for both humans and artificial intelligence (AI), as it requires a sophisticated integration of precise calculation, abstract reasoning, and a fundamental grasp of physical principles. The Chinese Physics Olympiad (CPhO), renowned for its complexity and depth, serves as an ideal and rigorous testbed for these advanced capabilities. In this paper, we introduce LOCA-R (LOgical Chain Augmentation for Reasoning), an improved version of the LOCA framework adapted for complex reasoning, and apply it to the CPhO 2025 theory examination. LOCA-R achieves a near-perfect score of 313 out of 320 points, solidly surpassing the highest-scoring human competitor and significantly outperforming all baseline methods.

</details>


### [95] [Say It Differently: Linguistic Styles as Jailbreak Vectors](https://arxiv.org/abs/2511.10519)
*Srikant Panda,Avinash Rai*

Main category: cs.CL

TL;DR: 语言风格会重塑有害意图，增加越狱成功率，但可以通过风格中和预处理来缓解。


<details>
  <summary>Details</summary>
Motivation: 现有LLM鲁棒性评估主要关注释义，忽略了语言风格作为攻击面的潜力。

Method: 构建了一个风格增强的越狱基准，将标准数据集的提示转换为11种不同的语言风格，并评估了16个模型。引入了风格中和预处理步骤。

Result: 语言风格重塑最多可将越狱成功率提高57个百分点，其中恐惧、好奇和富有同情心的风格最为有效。上下文重写优于模板化变体。风格中和预处理显著降低了越狱成功率。

Conclusion: 语言风格是一种系统性且能抵抗扩展的漏洞，目前的LLM安全防护措施忽略了这一点。

Abstract: Large Language Models (LLMs) are commonly evaluated for robustness against paraphrased or semantically equivalent jailbreak prompts, yet little attention has been paid to linguistic variation as an attack surface. In this work, we systematically study how linguistic styles such as fear or curiosity can reframe harmful intent and elicit unsafe responses from aligned models. We construct style-augmented jailbreak benchmark by transforming prompts from 3 standard datasets into 11 distinct linguistic styles using handcrafted templates and LLM-based rewrites, while preserving semantic intent. Evaluating 16 open- and close-source instruction-tuned models, we find that stylistic reframing increases jailbreak success rates by up to +57 percentage points. Styles such as fearful, curious and compassionate are most effective and contextualized rewrites outperform templated variants.
  To mitigate this, we introduce a style neutralization preprocessing step using a secondary LLM to strip manipulative stylistic cues from user inputs, significantly reducing jailbreak success rates. Our findings reveal a systemic and scaling-resistant vulnerability overlooked in current safety pipelines.

</details>


### [96] [Convomem Benchmark: Why Your First 150 Conversations Don't Need RAG](https://arxiv.org/abs/2511.10523)
*Egor Pakhomov,Erik Nijkamp,Caiming Xiong*

Main category: cs.CL

TL;DR: 该研究提出了一个包含75,336个问答对的对话记忆评估基准，并探讨了其与检索增强生成（RAG）的关系。


<details>
  <summary>Details</summary>
Motivation: 现有对话记忆评估框架在统计功效、数据生成一致性和评估灵活性方面存在局限性，本研究旨在解决这些问题，并探索对话记忆与RAG的联系。

Method: 构建了一个全面的对话记忆评估基准，包含多种类型的数据；分析了对话记忆和RAG之间的关系，包括它们的架构模式和关键区别；通过实验比较了不同规模对话历史下全上下文方法和基于RAG的记忆系统的性能。

Result: 简单的全上下文方法在多消息证据的情况下能达到70-82%的准确率；而Mem0等复杂的RAG记忆系统在少于150次交互的情况下准确率仅为30-45%；研究发现，长上下文在最初30次对话中表现最佳，在150次对话内仍可行，超过此数量级则需要混合或RAG方法。

Conclusion: 对话记忆的“小语料库优势”（即穷举搜索和完整重排是可行的）值得专门研究，而不应简单地将通用的RAG解决方案应用于对话历史。

Abstract: We introduce a comprehensive benchmark for conversational memory evaluation containing 75,336 question-answer pairs across diverse categories including user facts, assistant recall, abstention, preferences, temporal changes, and implicit connections. While existing benchmarks have advanced the field, our work addresses fundamental challenges in statistical power, data generation consistency, and evaluation flexibility that limit current memory evaluation frameworks. We examine the relationship between conversational memory and retrieval-augmented generation (RAG). While these systems share fundamental architectural patterns--temporal reasoning, implicit extraction, knowledge updates, and graph representations--memory systems have a unique characteristic: they start from zero and grow progressively with each conversation. This characteristic enables naive approaches that would be impractical for traditional RAG. Consistent with recent findings on long context effectiveness, we observe that simple full-context approaches achieve 70-82% accuracy even on our most challenging multi-message evidence cases, while sophisticated RAG-based memory systems like Mem0 achieve only 30-45% when operating on conversation histories under 150 interactions. Our analysis reveals practical transition points: long context excels for the first 30 conversations, remains viable with manageable trade-offs up to 150 conversations, and typically requires hybrid or RAG approaches beyond that point as costs and latencies become prohibitive. These patterns indicate that the small-corpus advantage of conversational memory--where exhaustive search and complete reranking are feasible--deserves dedicated research attention rather than simply applying general RAG solutions to conversation histories.

</details>


### [97] [Computing the Formal and Institutional Boundaries of Contemporary Genre and Literary Fiction](https://arxiv.org/abs/2511.10546)
*Natasha Johnson*

Main category: cs.CL

TL;DR: 本研究利用计算方法，通过分析叙事特征、作者性别和文本的风格和语义向量，来区分文学和类型小说，并探讨作者性别对文学地位的影响。


<details>
  <summary>Details</summary>
Motivation: 本研究旨在探讨“文学体裁”作为一种形式指定与机构指定之间的合理性，并研究作者性别如何影响文学分类。

Method: 研究首先从Andrew Piper的当代文学数据集中选取了包含浪漫、神秘、科幻小说在内的类型小说和文学小说作为语料库。接着，使用Welch's ANOVA方法比较了在每个体裁内部以及类型小说与文学小说之间，叙事特征在作者性别分布上的差异。然后，利用逻辑回归模型分析每个特征对文学分类的影响，以及作者性别如何调节这些影响。最后，通过分析体裁类别的风格和语义向量表示，来理解形式和内容在文学分类中的重要性。

Result: 研究发现了具有统计学意义的文学类别形式标记。此外，研究表明女性作者身份会缩小并模糊获得文学地位的目标。

Conclusion: 本研究通过计算方法证实了文学体裁作为形式指定具有统计学意义上的标记，并揭示了女性作者身份在获得文学地位方面面临的挑战。

Abstract: Though the concept of genre has been a subject of discussion for millennia, the relatively recent emergence of genre fiction has added a new layer to this ongoing conversation. While more traditional perspectives on genre have emphasized form, contemporary scholarship has invoked both formal and institutional characteristics in its taxonomy of genre, genre fiction, and literary fiction. This project uses computational methods to explore the soundness of genre as a formal designation as opposed to an institutional one. Pulling from Andrew Piper's CONLIT dataset of Contemporary Literature, we assemble a corpus of literary and genre fiction, with the latter category containing romance, mystery, and science fiction novels. We use Welch's ANOVA to compare the distribution of narrative features according to author gender within each genre and within genre versus literary fiction. Then, we use logistic regression to model the effect that each feature has on literary classification and to measure how author gender moderates these effects. Finally, we analyze stylistic and semantic vector representations of our genre categories to understand the importance of form and content in literary classification. This project finds statistically significant formal markers of each literary category and illustrates how female authorship narrows and blurs the target for achieving literary status.

</details>


### [98] [URaG: Unified Retrieval and Generation in Multimodal LLMs for Efficient Long Document Understanding](https://arxiv.org/abs/2511.10552)
*Yongxin Shi,Jiapeng Wang,Zeyu Shan,Dezhi Peng,Zening Lin,Lianwen Jin*

Main category: cs.CL

TL;DR: URaG是一个统一检索和生成框架，通过模仿人类的粗粒度到细粒度推理模式，利用多模态大语言模型（MLLM）的内在证据定位能力来解决长文档理解中的信息干扰和计算成本问题，实现了先进的性能和显著的计算开销降低。


<details>
  <summary>Details</summary>
Motivation: 现有的多模态大语言模型（MLLM）在理解长文档时面临信息干扰和二次计算成本的挑战，现有方法在细节保留或系统集成方面存在不足。

Method: URaG框架通过引入一个轻量级的跨模态检索模块，将Transformer的早期层转化为高效的证据选择器，识别并保留相关信息页，使后续层能专注于关键内容，实现检索与生成的统一。

Result: URaG在长文档理解任务上实现了先进的性能，同时将计算开销降低了44-56%。

Conclusion: URaG通过模仿人类的粗粒度到细粒度推理模式，有效解决了长文档理解中的信息干扰和计算成本问题，实现了检索与生成的统一，并取得了优异的性能和效率提升。

Abstract: Recent multimodal large language models (MLLMs) still struggle with long document understanding due to two fundamental challenges: information interference from abundant irrelevant content, and the quadratic computational cost of Transformer-based architectures. Existing approaches primarily fall into two categories: token compression, which sacrifices fine-grained details; and introducing external retrievers, which increase system complexity and prevent end-to-end optimization. To address these issues, we conduct an in-depth analysis and observe that MLLMs exhibit a human-like coarse-to-fine reasoning pattern: early Transformer layers attend broadly across the document, while deeper layers focus on relevant evidence pages. Motivated by this insight, we posit that the inherent evidence localization capabilities of MLLMs can be explicitly leveraged to perform retrieval during the reasoning process, facilitating efficient long document understanding. To this end, we propose URaG, a simple-yet-effective framework that Unifies Retrieval and Generation within a single MLLM. URaG introduces a lightweight cross-modal retrieval module that converts the early Transformer layers into an efficient evidence selector, identifying and preserving the most relevant pages while discarding irrelevant content. This design enables the deeper layers to concentrate computational resources on pertinent information, improving both accuracy and efficiency. Extensive experiments demonstrate that URaG achieves state-of-the-art performance while reducing computational overhead by 44-56%. The code is available at https://github.com/shi-yx/URaG.

</details>


### [99] [DESS: DeBERTa Enhanced Syntactic-Semantic Aspect Sentiment Triplet Extraction](https://arxiv.org/abs/2511.10577)
*Vishal Thenuwara,Nisansa de Silva*

Main category: cs.CL

TL;DR: DESS利用DeBERTa和LSTM改进了方面情感三元组提取，在标准数据集上提高了F1分数。


<details>
  <summary>Details</summary>
Motivation: 现有方面情感三元组提取方法在捕捉方面、观点和情感极性之间的关系方面存在挑战，而先进语言模型的全部潜力尚未被探索。

Method: 提出DESS框架，结合DeBERTa的注意力机制和LSTM通道，以处理文本的意义和语法模式，并精心调整了这些组件的交互方式。

Result: DESS在标准数据集上取得了显著改进，在识别方面观点对和准确确定情感方面F1分数分别提高了4.85%、8.36%和2.42%。

Conclusion: 升级到更先进的语言模型（如DeBERTa），经过周到的整合，可以显著提高文本情感分析的性能，尤其是在处理复杂的句子结构时。

Abstract: Fine-grained sentiment analysis faces ongoing challenges in Aspect Sentiment Triple Extraction (ASTE), particularly in accurately capturing the relationships between aspects, opinions, and sentiment polarities. While researchers have made progress using BERT and Graph Neural Networks, the full potential of advanced language models in understanding complex language patterns remains unexplored. We introduce DESS, a new approach that builds upon previous work by integrating DeBERTa's enhanced attention mechanism to better understand context and relationships in text. Our framework maintains a dual-channel structure, where DeBERTa works alongside an LSTM channel to process both meaning and grammatical patterns in text. We have carefully refined how these components work together, paying special attention to how different types of language information interact. When we tested DESS on standard datasets, it showed meaningful improvements over current methods, with F1-score increases of 4.85, 8.36, and 2.42 in identifying aspect opinion pairs and determining sentiment accurately. Looking deeper into the results, we found that DeBERTa's sophisticated attention system helps DESS handle complicated sentence structures better, especially when important words are far apart. Our findings suggest that upgrading to more advanced language models when thoughtfully integrated, can lead to real improvements in how well we can analyze sentiments in text. The implementation of our approach is publicly available at: https://github.com/VishalRepos/DESS.

</details>


### [100] [Evaluating Prompting Strategies with MedGemma for Medical Order Extraction](https://arxiv.org/abs/2511.10583)
*Abhinand Balachandran,Bavana Durgapraveen,Gowsikkan Sikkan Sudhagar,Vidhya Varshany J S,Sriram Rajkumar*

Main category: cs.CL

TL;DR: MedGemma在Mediqa-OE-2025任务中，one-shot提示在手动标注的对话中比ReAct和agentic方法表现更好，因为它避免了过度思考。


<details>
  <summary>Details</summary>
Motivation: 提取医疗记录中的医嘱，以减轻临床文档负担和确保患者安全。

Method: 评估了MedGemma模型在三种提示范式（one-shot、ReAct、agentic）下的表现。

Result: One-shot提示在官方验证集上达到了最高的准确率。

Conclusion: 对于手动标注的医疗对话，简单的one-shot提示比复杂的推理方法更有效，可以避免引入不必要的噪声。

Abstract: The accurate extraction of medical orders from doctor-patient conversations is a critical task for reducing clinical documentation burdens and ensuring patient safety. This paper details our team submission to the MEDIQA-OE-2025 Shared Task. We investigate the performance of MedGemma, a new domain-specific open-source language model, for structured order extraction. We systematically evaluate three distinct prompting paradigms: a straightforward one-Shot approach, a reasoning-focused ReAct framework, and a multi-step agentic workflow. Our experiments reveal that while more complex frameworks like ReAct and agentic flows are powerful, the simpler one-shot prompting method achieved the highest performance on the official validation set. We posit that on manually annotated transcripts, complex reasoning chains can lead to "overthinking" and introduce noise, making a direct approach more robust and efficient. Our work provides valuable insights into selecting appropriate prompting strategies for clinical information extraction in varied data conditions.

</details>


### [101] [Mined Prompting and Metadata-Guided Generation for Wound Care Visual Question Answering](https://arxiv.org/abs/2511.10591)
*Bavana Durgapraveen,Sornaraj Sivasankaran,Abhinand Balachandran,Sriram Rajkumar*

Main category: cs.CL

TL;DR: AI can help clinicians manage patient queries in remote care. This paper presents two methods for generating free-text responses to wound care queries with images: mined prompting and metadata-guided generation. Both methods improve response quality, highlighting AI's potential in wound care support.


<details>
  <summary>Details</summary>
Motivation: The increasing volume of asynchronous remote care necessitates AI systems to assist clinicians with patient queries, particularly in wound care which involves images.

Method: 1. Mined prompting: Embeds training data, retrieves top-k similar examples for few-shot demonstrations. 2. Metadata-guided generation: Identifies and predicts four key metadata attributes to dynamically adjust response quality.

Result: Mined prompting enhances response relevance. Metadata-guided generation improves clinical precision.

Conclusion: Combining mined prompting and metadata-guided generation offers a promising direction for developing reliable and efficient AI-driven wound care support tools.

Abstract: The rapid expansion of asynchronous remote care has intensified provider workload, creating demand for AI systems that can assist clinicians in managing patient queries more efficiently. The MEDIQA-WV 2025 shared task addresses this challenge by focusing on generating free-text responses to wound care queries paired with images. In this work, we present two complementary approaches developed for the English track. The first leverages a mined prompting strategy, where training data is embedded and the top-k most similar examples are retrieved to serve as few-shot demonstrations during generation. The second approach builds on a metadata ablation study, which identified four metadata attributes that consistently enhance response quality. We train classifiers to predict these attributes for test cases and incorporate them into the generation pipeline, dynamically adjusting outputs based on prediction confidence. Experimental results demonstrate that mined prompting improves response relevance, while metadata-guided generation further refines clinical precision. Together, these methods highlight promising directions for developing AI-driven tools that can provide reliable and efficient wound care support.

</details>


### [102] [Know Your Limits: Entropy Estimation Modeling for Compression and Generalization](https://arxiv.org/abs/2511.10618)
*Benjamin L. Badger,Matthew Neligeorge*

Main category: cs.CL

TL;DR: 语言模型在信息熵的限制下，压缩和预测能力存在上限。本研究提出了一种新的编码器增强因果解码器模型架构，可以提高训练效率和压缩率，甚至在中等硬件上也能超越现有的因果Transformer模型。该模型能够逐个token地估计语言熵，并证明了接近训练数据熵的模型比最小化损失的模型具有更强的泛化能力。实验表明，训练模型使其接近但不超过估计的逐个token熵，可以获得比未考虑熵的模型更强的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有的语言模型在进行语言压缩和预测时受到语言内在信息熵的限制，这既限制了模型预测的准确性，也限制了语言压缩的下限。虽然因果（下一个token预测）大语言模型是目前最高效的语言压缩算法，但用它们来准确估计语言熵在计算上是不可行的。

Method: 提出了一种新的编码器增强因果解码器模型架构，并证明了该架构在训练效率上优于因果Transformer模型。该模型能够逐个token地估计语言熵，并通过实验证明了接近但不超过估计的逐个token熵的模型比未考虑熵的模型具有更强的泛化能力。

Result: 与因果Transformer模型相比，新的模型架构在训练效率和压缩率方面表现更优，即使在有限的硬件上也能取得更好的效果。通过逐个token地估计熵，研究表明接近训练数据熵的模型具有更强的泛化能力。

Conclusion: 本研究提出的编码器增强因果解码器模型架构在提高训练效率、压缩率和模型泛化能力方面取得了显著进展。通过考虑并利用语言的内在信息熵，可以开发出更强大的语言模型。

Abstract: Language prediction is constrained by informational entropy intrinsic to language, such that there exists a limit to how accurate any language model can become and equivalently a lower bound to language compression. The most efficient language compression algorithms today are causal (next token prediction) large language models, but the use of these models to form accurate estimates of language entropy is currently computationally infeasible. We introduce encoder-augmented causal decoder model architectures that exhibit superior training efficiency characteristics and achieve higher compression than causal transformers even when trained on modest hardware. We demonstrate how entropy estimates can be obtained on a per-token basis, and show that the generalization of models trained to approach the entropy of their training data necessarily exceeds the generalization of models trained to minimize loss beyond this value. We show empirically that causal models trained to approach but not exceed estimated per-token entropies exhibit greater generalization than models trained without taking entropy into account.

</details>


### [103] [SSR: Socratic Self-Refine for Large Language Model Reasoning](https://arxiv.org/abs/2511.10621)
*Haizhou Shi,Ye Liu,Bo Pang,Zeyu Leo Liu,Hao Wang,Silvio Savarese,Caiming Xiong,Yingbo Zhou,Semih Yavuz*

Main category: cs.CL

TL;DR: SSR框架通过将LLM响应分解为可验证的子问题/子答案对，实现细粒度评估和精确的LLM推理优化，显著优于现有基线。


<details>
  <summary>Details</summary>
Motivation: 现有LLM测试框架在处理复杂任务时，依赖粗粒度的自我验证和纠错，效果有限。

Method: SSR框架将LLM响应分解为（子问题，子答案）对，通过受控的重新求解和自洽性检查来估计每一步的置信度，并迭代优化不可靠的步骤。

Result: 在五个推理基准和三个LLM上的实验表明，SSR的性能持续优于最先进的迭代自优化基线。

Conclusion: SSR框架为LLM的推理提供了一种原则性的黑盒评估和理解方法，提高了准确性和可解释性。

Abstract: Large Language Models (LLMs) have demonstrated remarkable reasoning abilities, yet existing test-time frameworks often rely on coarse self-verification and self-correction, limiting their effectiveness on complex tasks. In this paper, we propose Socratic Self-Refine (SSR), a novel framework for fine-grained evaluation and precise refinement of LLM reasoning. Our proposed SSR decomposes model responses into verifiable (sub-question, sub-answer) pairs, enabling step-level confidence estimation through controlled re-solving and self-consistency checks. By pinpointing unreliable steps and iteratively refining them, SSR produces more accurate and interpretable reasoning chains. Empirical results across five reasoning benchmarks and three LLMs show that SSR consistently outperforms state-of-the-art iterative self-refinement baselines. Beyond performance gains, SSR provides a principled black-box approach for evaluating and understanding the internal reasoning processes of LLMs. Code is available at https://github.com/SalesforceAIResearch/socratic-self-refine-reasoning.

</details>


### [104] [Instella: Fully Open Language Models with Stellar Performance](https://arxiv.org/abs/2511.10628)
*Jiang Liu,Jialian Wu,Xiaodong Yu,Yusheng Su,Prakamya Mishra,Gowtham Ramesh,Sudhanshu Ranjan,Chaitanya Manem,Ximeng Sun,Ze Wang,Pratik Prabhanjan Brahma,Zicheng Liu,Emad Barsoum*

Main category: cs.CL

TL;DR: Instella是一个完全开放的、拥有30亿参数的语言模型系列，在公开可用数据和代码库上进行训练，在性能上可与同等规模的领先模型相媲美，并推出了处理长文本和数学任务的专用变体。


<details>
  <summary>Details</summary>
Motivation: 解决现有高性能大语言模型（LLM）大多不开源、缺乏透明度和可复现性问题。

Method: 通过大规模预训练、通用指令调优以及人类偏好对齐来开发Instella模型。利用AMD Instinct MI300X GPU进行训练。发布了Instella-Long（支持128K上下文长度）和Instella-Math（专注于数学推理）两个专用变体。

Result: Instella在完全开放的模型中取得了最先进的成果，并且在同等规模的模型中具有竞争力。Instella-Long能够处理长达128K个标记的上下文长度。Instella-Math在数学任务上表现出色。

Conclusion: Instella为社区提供了一个透明、高性能且通用的选择，推动了开放和可复现的语言模型研究。

Abstract: Large language models (LLMs) have demonstrated remarkable performance across a wide range of tasks, yet the majority of high-performing models remain closed-source or partially open, limiting transparency and reproducibility. In this work, we introduce Instella, a family of fully open three billion parameter language models trained entirely on openly available data and codebase. Powered by AMD Instinct MI300X GPUs, Instella is developed through large-scale pre-training, general-purpose instruction tuning, and alignment with human preferences. Despite using substantially fewer pre-training tokens than many contemporaries, Instella achieves state-of-the-art results among fully open models and is competitive with leading open-weight models of comparable size. We further release two specialized variants: Instella-Long, capable of handling context lengths up to 128K tokens, and Instella-Math, a reasoning-focused model enhanced through supervised fine-tuning and reinforcement learning on mathematical tasks. Together, these contributions establish Instella as a transparent, performant, and versatile alternative for the community, advancing the goal of open and reproducible language modeling research.

</details>


### [105] [Black-Box On-Policy Distillation of Large Language Models](https://arxiv.org/abs/2511.10643)
*Tianzhu Ye,Li Dong,Zewen Chi,Xun Wu,Shaohan Huang,Furu Wei*

Main category: cs.CL

TL;DR: GAD是一种新的黑盒蒸馏方法，将学生LLM视为生成器，并训练判别器来区分其响应与教师LLM的响应，从而实现稳定、自适应的反馈，并在LMSYS-Chat评估中与GPT-5-Chat相当。


<details>
  <summary>Details</summary>
Motivation: 开发一种能够进行on-policy和黑盒蒸馏的蒸馏方法，以解决现有知识蒸馏方法的局限性。

Method: GAD将学生LLM视为生成器，训练一个判别器来区分学生LLM的响应和教师LLM的响应，形成一个最小最大博弈。判别器充当一个与学生LLM共同演变的on-policy奖励模型，提供稳定、自适应的反馈。

Result: GAD在LMSYS-Chat自动评估中，经过GAD蒸馏的Qwen2.5-14B-Instruct学生模型在性能上可与教师模型GPT-5-Chat相媲美，并且一致优于常用的序列级知识蒸馏方法。

Conclusion: GAD是一种有前途且有效的黑盒LLM蒸馏范式。

Abstract: Black-box distillation creates student large language models (LLMs) by learning from a proprietary teacher model's text outputs alone, without access to its internal logits or parameters. In this work, we introduce Generative Adversarial Distillation (GAD), which enables on-policy and black-box distillation. GAD frames the student LLM as a generator and trains a discriminator to distinguish its responses from the teacher LLM's, creating a minimax game. The discriminator acts as an on-policy reward model that co-evolves with the student, providing stable, adaptive feedback. Experimental results show that GAD consistently surpasses the commonly used sequence-level knowledge distillation. In particular, Qwen2.5-14B-Instruct (student) trained with GAD becomes comparable to its teacher, GPT-5-Chat, on the LMSYS-Chat automatic evaluation. The results establish GAD as a promising and effective paradigm for black-box LLM distillation.

</details>


### [106] [ParoQuant: Pairwise Rotation Quantization for Efficient Reasoning LLM Inference](https://arxiv.org/abs/2511.10645)
*Yesheng Liang,Haisheng Chen,Song Han,Zhijian Liu*

Main category: cs.CL

TL;DR: ParoQuant是一种仅包含权重量化（PTQ）的方法，通过结合Givens旋转和通道级缩放来解决LLM量化中的异常值问题，从而提高推理效率和准确性。


<details>
  <summary>Details</summary>
Motivation: LLM的重量化在减小内存占用和加速推理方面至关重要。然而，权重和激活中的异常值会导致量化误差增大和精度下降，尤其是在推理LLM中，误差会随着思维链的增长而累积。现有的PTQ方法要么无法有效抑制异常值，要么会增加推理开销。

Method: 提出了一种名为ParoQuant的仅包含权重量化（PTQ）的方法。该方法结合了硬件高效且可优化的独立Givens旋转以及通道级缩放，以平衡各通道间的幅度并缩小每个量化组内的动态范围。同时，对推理内核进行了协同设计，以充分利用GPU并行性，并使旋转和缩放操作在运行时开销极小。

Result: ParoQuant在推理任务上的准确性平均比AWQ高2.4%，同时推理开销增加不到10%。

Conclusion: ParoQuant通过有效处理LLM量化中的异常值问题，实现了更高效、更准确的推理，为推理LLM的部署提供了新的途径。

Abstract: Weight-only post-training quantization (PTQ) compresses the weights of Large Language Models (LLMs) into low-precision representations to reduce memory footprint and accelerate inference. However, the presence of outliers in weights and activations often leads to large quantization errors and severe accuracy degradation, especially in recent reasoning LLMs where errors accumulate across long chains of thought. Existing PTQ methods either fail to sufficiently suppress outliers or introduce significant overhead during inference. In this paper, we propose Pairwise Rotation Quantization (ParoQuant), a weight-only PTQ method that combines hardware-efficient and optimizable independent Givens rotations with channel-wise scaling to even out the magnitude across channels and narrow the dynamic range within each quantization group. We further co-design the inference kernel to fully exploit GPU parallelism and keep the rotations and scaling lightweight at runtime. ParoQuant achieves an average 2.4% accuracy improvement over AWQ on reasoning tasks with less than 10% overhead. This paves the way for more efficient and accurate deployment of reasoning LLMs.

</details>


<div id='eess.SY'></div>

# eess.SY [[Back]](#toc)

### [107] [Statistically Consistent Approximate Model Predictive Control](https://arxiv.org/abs/2511.09661)
*Elias Milios,Kim P. Wabersich,Felix Berkel,Felix Gruber,Melanie N. Zeilinger*

Main category: eess.SY

TL;DR: AMPC通过学习计算成本较低的代理策略来规避MPC的计算密集度问题，特别是在MPC解决方案为集合值时，BC方法存在不足。本文提出了一种两阶段IL程序，通过整合MPC最优值函数逼近到单步前瞻损失函数，将MPC的约束和性能目标嵌入IL目标，并证明了策略的统计一致性和近似最小化器的输入状态稳定性。


<details>
  <summary>Details</summary>
Motivation: 传统的AMPC方法，特别是基于BC的方法，在MPC解决方案为集合值（例如由于非凸约束或局部最小值）时，无法提供准确的近似。需要一种能够准确近似非线性、可能为集合值的MPC策略的方法。

Method: 提出了一种两阶段IL程序。该程序将MPC的最优值函数近似集成到一个单步前瞻损失函数中，从而将MPC的约束和性能目标嵌入到IL目标中。通过采用稳定的软约束MPC公式来实现这一点，该公式通过结合约束收紧和松弛惩罚来反映最优值函数中的约束违反情况。

Result: 证明了精确最小化IL目标的策略的统计一致性，这意味着它们收敛到安全且稳定的控制律。同时，建立了近似最小化器的输入状态稳定性保证。仿真结果表明，与BC相比，性能有所提高。

Conclusion: 所提出的两阶段IL程序能够准确地近似非线性的、可能为集合值的MPC策略，提供了统计一致性和输入状态稳定性保证，并在模拟中显示出比BC更好的性能。

Abstract: Model Predictive Control (MPC) offers rigorous safety and performance guarantees but is computationally intensive. Approximate MPC (AMPC) aims to circumvent this drawback by learning a computationally cheaper surrogate policy. Common approaches focus on imitation learning (IL) via behavioral cloning (BC), minimizing a mean-squared-error loss on a collection of state-input pairs. However, BC fundamentally fails to provide accurate approximations when MPC solutions are set-valued due to non-convex constraints or local minima. We propose a two-stage IL procedure to accurately approximate nonlinear, potentially set-valued MPC policies. The method integrates an approximation of the MPC's optimal value function into a one-step look-ahead loss function, and thereby embeds the MPC's constraint and performance objectives into the IL objective.This is achieved by adopting a stabilizing soft constrained MPC formulation, which reflects constraint violations in the optimal value function by combining a constraint tightening with slack penalties. We prove statistical consistency for policies that exactly minimize our IL objective, implying convergence to a safe and stabilizing control law, and establish input-to-state stability guarantees for approximate minimizers. Simulations demonstrate improved performance compared to BC.

</details>


### [108] [Robust Time-Varying Control Barrier Functions with Sector-Bounded Nonlinearities](https://arxiv.org/abs/2511.09784)
*Jungbae Chun,Felix Biertümpfel,Peter Seiler*

Main category: eess.SY

TL;DR: 提出一种结合时变控制势垒函数和点态二次约束来处理输入非线性和时变安全约束的新型鲁棒控制方法，并设计了一个高效的安全滤波器。


<details>
  <summary>Details</summary>
Motivation: 确保在存在输入非线性和时变安全约束的情况下系统的安全运行。

Method: 将时变控制势垒函数（捕获时变安全约束）与点态二次约束（约束非线性）相结合，设计了一个安全滤波器。该滤波器以二阶锥规划问题的形式在线求解，确保安全的同时最小化对基线控制器指令的干扰。

Result: 该方法在简单的车辆避障场景中得到了验证。

Conclusion: 所提出的方法能够有效地处理输入非线性和时变安全约束，并通过一个高效的安全滤波器保证系统的安全运行。

Abstract: This paper presents a novel approach for ensuring safe operation of systems subject to input nonlinearities and time-varying safety constraints. We formulate robust time-varying control barrier functions by combining two ingredients: (i) time-varying control barrier functions which capture the time-varying safety constraints, and (ii) pointwise-in-time quadratic constraints that bound the nonlinearity. These ingredients are used to design a safety filter. This filter ensures safety while minimally altering the command from a given baseline controller. The safety filter is implemented as the solution of a second-order cone program, which can be efficiently computed online. The approach is demonstrated on a simple car obstacle avoidance scenario.

</details>


### [109] [A Smooth Penalty-Based Feedback Law for Reactive Obstacle Avoidance with Convergence Guarantees](https://arxiv.org/abs/2511.09799)
*Lyes Smaili,Soulaimane Berkane*

Main category: eess.SY

TL;DR: 该研究提出了一种名为SPF（Safe Penalty-based Feedback）的控制器，用于在未知有障碍物的环境中实现安全的自主导航。该控制器仅使用局部传感信息，通过平滑反馈来修改名义输入，确保安全裕度不被侵犯，并且能够渐近稳定地达到目标点。


<details>
  <summary>Details</summary>
Motivation: 在未知有障碍物的环境中，仅依靠局部传感信息实现安全的自主导航是一个挑战。

Method: 提出了一种基于无约束惩罚的平滑反馈控制器，该控制器通过一个封闭形式的表达式修改名义输入。控制律仅依赖于到障碍物的距离和方位，无需地图、切换或集合构建。当名义输入为导航势的梯度下降时，证明了闭环系统几乎全局渐近稳定（AGAS）到目标点，并分析了不稳定平衡点的条件。

Result: 所提出的SPF控制器通过仿真证明了其在复杂2D和3D环境中能够实现安全、平滑的导航，并具有较低的计算开销。

Conclusion: SPF控制器能够通过构造保证安全，并且在特定条件下可以实现几乎全局渐近稳定到目标点，为在未知有障碍物环境中的自主导航提供了一种有效且计算效率高的方法。

Abstract: This paper addresses the problem of safe autonomous navigation in unknown obstacle-filled environments using only local sensory information. We propose a smooth feedback controller derived from an unconstrained penalty-based formulation that guarantees safety by construction. The controller modifies an arbitrary nominal input through a closed-form expression. The resulting closed-form feedback has a projection structure that interpolates between the nominal control and its orthogonal projection onto the obstacle boundary, ensuring forward invariance of a user-defined safety margin. The control law depends only on the distance and bearing to obstacles and requires no map, switching, or set construction. When the nominal input is a gradient descent of a navigation potential, we prove that the closed-loop system achieves almost global asymptotic stability (AGAS) to the goal. Undesired equilibria are shown to be unstable under a mild geometric curvature condition, which compares the normal curvature of the obstacle boundary with that of the potential level sets. We refer to the proposed method as SPF (Safe Penalty-based Feedback), which ensures safe and smooth navigation with minimal computational overhead, as demonstrated through simulations in complex 2D and 3D environments.

</details>


### [110] [Resilient Controller Design with Exponential Reaching Law for Enhanced Load Frequency Stability in Multi-Area Interconnected Microgrids](https://arxiv.org/abs/2511.09830)
*Md Saiful Islam,Rahul Bhadani*

Main category: eess.SY

TL;DR: 本研究提出了一种分散式鲁棒全局积分终端滑模控制（GITSMC）策略，用于在包含聚合不确定性的多区域互联微电网中，通过维持稳定的频率和联络线功率。


<details>
  <summary>Details</summary>
Motivation: 为了在多区域互联微电网中应对太阳能光伏（PV）、风力涡轮机（WT）发电和负荷需求造成的聚合不确定性，以维持频率和联络线功率的稳定。

Method: 首先，建立了包含聚合不确定性的多区域互联系统数学模型。其次，设计了具有指数趋近律的全局积分终端滑模面，以提高系统动态性能并抑制有限时间内的抖振。最后，利用李雅普诺夫稳定性定理分析了闭环系统的整体稳定性。

Result: 通过在IEEE 10发电机新英格兰39节点电力系统上进行广泛仿真，包括负荷扰动和变化的PV与WT发电，结果表明所提出的GITSMC方法在ITSE方面提高了约94.9%，在ISE方面提高了94.4%，证明了其相对于现有控制器具有优越的精度和动态性能。

Conclusion: 所提出的GITSMC方法能够有效提高多区域互联微电网在聚合不确定性下的频率和联络线功率控制精度和动态性能。

Abstract: We present a load frequency control strategy deploying a decentralized robust global integral terminal sliding mode control (GITSMC) method to maintain stable frequency and tie-line power in multi-area interconnected microgrids with aggregated uncertainties. To achieve this, firstly, we have developed a mathematical model of the multi-area interconnected system incorporating disturbances from solar photovoltaic (PV), wind turbine (WT) generation and load demand, as aggregated uncertainties. Secondly, we have designed a global integral terminal sliding surface with an exponential reaching law for each area to enhance system dynamic performance and suppress chattering within a finite time. Thirdly, the overall stability of the closed-loop system is analyzed using the Lyapunov stability theorem. Finally, extensive simulations are conducted on the IEEE 10-generator New England 39-bus power system, including load disturbances and variable PV and WT generation. The results demonstrate the performance of the proposed GITSMC approach, achieving approximately 94.9% improvement in ITSE and 94.4% improvement in ISE, confirming its superior accuracy and dynamic performance compared to the existing controller.

</details>


### [111] [Efficient Verification and Falsification of ReLU Neural Barrier Certificates](https://arxiv.org/abs/2511.10015)
*Dejin Ren,Yiling Xue,Taoran Wu,Bai Xue*

Main category: eess.SY

TL;DR: 本论文提出了一个必要和充分条件来验证ReLU神经网络屏障证书的正确性，该条件可以被编码为SMT问题或优化问题，从而实现验证和伪证。这是首个能够伪证ReLU神经网络屏障证书的方法。


<details>
  <summary>Details</summary>
Motivation: 连续时间系统（包括自动驾驶、机器人操作器等关键应用）的安全验证中，屏障证书扮演着重要角色。ReLU神经网络屏障证书因其有前景的性能而受到安全控制社区的广泛关注。然而，由于神经网络的近似性质，需要严格的验证方法来确保这些证书的正确性。

Method: 提出一个必要和充分条件来验证ReLU神经网络屏障证书的正确性，该条件可以被编码为SMT问题或优化问题，从而实现验证和伪证。

Result: 数值实验证明了该方法在验证和伪证ReLU神经网络屏障证书方面的有效性和效率。

Conclusion: 本论文提出了首个能够伪证ReLU神经网络屏障证书的方法，并通过数值实验证明了其有效性。

Abstract: Barrier certificates play an important role in verifying the safety of continuous-time systems, including autonomous driving, robotic manipulators and other critical applications. Recently, ReLU neural barrier certificates -- barrier certificates represented by the ReLU neural networks -- have attracted significant attention in the safe control community due to their promising performance. However, because of the approximate nature of neural networks, rigorous verification methods are required to ensure the correctness of these certificates. This paper presents a necessary and sufficient condition for verifying the correctness of ReLU neural barrier certificates. The proposed condition can be encoded as either an Satisfiability Modulo Theories (SMT) or optimization problem, enabling both verification and falsification. To the best of our knowledge, this is the first approach capable of falsifying ReLU neural barrier certificates. Numerical experiments demonstrate the validity and effectiveness of the proposed method in both verifying and falsifying such certificates.

</details>


### [112] [Cooperative Control of Hybrid FES-Exoskeleton: Dynamic Allocation](https://arxiv.org/abs/2511.10117)
*Hossein Kavianirad,Satoshi Endo,Davide Astarita,Lorenzo Amato,Emilio Trigili,Sandra Hirche*

Main category: eess.SY

TL;DR: 该混合辅助系统通过动态分配解决了FES和外骨骼执行器之间的冗余问题。


<details>
  <summary>Details</summary>
Motivation: 控制混合FES-外骨骼神经康复系统具有挑战性，因为存在执行器冗余和异构辅助设备的限制。

Method: 提出了一种基于动态分配的新型混合FES-外骨骼系统协作控制架构，该架构包含一个模块化控制分配器，可根据设备限制和用户偏好实时重新分配FES和外骨骼执行器之间的控制扭矩。

Result: 仿真和实验结果证明了该方法在解决FES-外骨骼系统中的执行器冗余和考虑执行器约束方面的有效性。

Conclusion: 所提出的协作控制架构有望解决混合FES-外骨骼神经康复系统中的执行器冗余问题，并可能在临床研究中进行评估。

Abstract: Hybrid assistive systems that integrate functional electrical stimulation (FES) and robotic exoskeletons offer a promising approach for neurorehabilitation. However, control of these systems remains challenging due to actuator redundancy and heterogeneous assistive device constraints. This paper introduces a novel cooperative control architecture based on dynamic allocation to address actuator redundancy in a hybrid FES-exoskeleton system. The proposed approach employs a modular control allocator that redistributes required control torques between FES and exoskeleton actuators in real time, accounting for device-specific limitations and user preferences (e.g., prioritizing one assistive device over another). Within this framework, the high-level controller determines the total assistance level, while the allocator dynamically distributes control effort based on these assistive device-specific considerations. Simulation results and experimental validation demonstrate the method's effectiveness in resolving actuator redundancy in the FES-exoskeleton system while reflecting actuator constraints, indicating its potential for deployment in clinical studies to assess patient acceptance and clinical efficacy.

</details>


### [113] [Consensus approximation and impulsive control for a class of uncertain multi-agent dynamics](https://arxiv.org/abs/2511.10118)
*Zoltan Nagy,Irinel-Constantin Morarescu,Lucian Busoniu*

Main category: eess.SY

TL;DR: 该论文研究了具有时变未知缩放因子的共识动力学，并提出了确定共识值界限和分配控制预算的控制策略。


<details>
  <summary>Details</summary>
Motivation: 研究在机器人集群控制或意见动力学等场景下，由于通信网络或同伴信心随时间变化，导致代理之间交互受时变未知缩放因子影响的共识动力学问题。

Method: 提出了一种基于线性规划的计算高效方法，用于确定共识值的实际上下界，并提出了一种控制策略来分配给定的控制预算，以克服不确定性并将代理状态推向期望的共识值。

Result: 确定了共识值的实际上下界，并提出了一种控制策略来应对不确定性。通过数值模拟验证了所提出方法的有效性。

Conclusion: 该研究为具有时变未知缩放因子的共识动力学问题提供了理论分析和有效的控制策略，并通过数值模拟进行了验证。

Abstract: This paper studies a class of consensus dynamics where the interactions between agents are affected by a time-varying unknown scaling factor. This situation is encountered in the control of robotic fleets over a wireless network or in opinion dynamics where the confidence given to the peers varies in time. Firstly, we establish conditions under which practical upper and lower bounds on the consensus value can be determined. Secondly, we propose control strategies for allocating a given control budget to shift agent states towards a desired consensus value despite the uncertainty. We provide computationally efficient linear programming-based approaches for both problems and validate the obtained results in numerical simulations.

</details>


### [114] [Closed Form Modelling and Identification of Banking Effects in Confined Waters](https://arxiv.org/abs/2511.10158)
*Jeppe H. Mikkelsen,Thomas T. Enevoldsen,Bugge T. Jensen,Michael Jeppesen,Roberto Galeazzi,Dimitrios Papageorgiou*

Main category: eess.SY

TL;DR: 该研究提出了一种闭式、基于第一性原理的船舶航行姿态效应模型，并使用物理信息回归方法识别模型系数，通过实验数据验证了模型的准确性和普适性。


<details>
  <summary>Details</summary>
Motivation: 船舶在狭窄水域航行时会受到姿态效应的影响，这会影响其操纵性和安全性。现有的数值方法计算成本高，不适用于实时控制。因此，需要一种能够准确捕捉这些效应且计算成本较低的模型。

Method: 提出了一种闭式、基于第一性原理的船舶航行姿态效应模型。使用物理信息回归方法，并结合拖曳水槽实验数据，识别了模型的系数。通过Shapley值分析来验证模型的有效性。

Result: 该模型能够准确地复现实验测量到的力和力矩。所推导出的系数具有无量纲的特性，使得模型可以应用于不同尺度但保持几何形状相似的船舶。

Conclusion: 所提出的闭式模型能够准确有效地模拟船舶在狭窄水域航行时的姿态效应，并且具有良好的普适性，可应用于不同尺度和几何形状相似的船舶，为船舶的实时控制和估计提供了可能。

Abstract: Vessels navigating in confined waters are subject to banking effects, which are hydrodynamic forces and moments arising from pressure differentials between the vessel sides, significantly affecting manoeuvrability and safety. Existing numerical approaches such as computational fluid dynamics (CFD) can accurately capture these effects but are computationally expensive and unsuitable for real-time control or estimation. This paper presents a closed-form, first-principles model of banking effects. The model coefficients are identified using physics-informed regression on towing tank experiment data for a scaled container vessel. Validation through Shapley value analysis confirms the significance of the banking terms in reproducing the measured forces and moments. Lastly, the derived coefficients are shown to be non-dimensional, making the model applicable across different scales that preserve vessel geometry.

</details>


### [115] [Equivalent Mechanical Models for Sloshing](https://arxiv.org/abs/2511.10172)
*Francesco Capolupo*

Main category: eess.SY

TL;DR: 该论文提出了一种用于分析和模拟航天器推进剂晃动现象的数学模型。


<details>
  <summary>Details</summary>
Motivation: 推进剂晃动在微重力和高g条件下都会影响航天器的性能和稳定性，需要被GNC子系统考虑。

Method: 通过推导单摆和多摆动力学的非线性与线性运动方程，并将其与已有的弹簧-质量-阻尼器模型进行数学等价性验证，最后通过时域和频域仿真进行模型验证。

Result: 推导了考虑名义纵向力的多体系统运动方程，并验证了所提模型与弹簧-质量-阻尼器模型的等价性。

Conclusion: 所提出的数学模型能够有效分析和模拟推进剂晃动现象，并为航天器的设计和控制提供支持。

Abstract: Propellant sloshing is a well-known, but not completely mastered phenomenon in space vehicles. It is particularly critical in both microgravity environments - such as interplanetary spacecraft requiring high pointing stability - and high-g conditions, as encountered during launch, re-entry, and landing. In both cases, sloshing can significantly affect vehicle performance and stability, and must often be explicitly considered in the design of the guidance, navigation, and control (GNC) subsystem.
  For stability analysis and control design, the most common approach to modeling sloshing is through an equivalent mechanical representation, where the moving propellant is treated as a mechanical system interacting with the rigid (or flexible) spacecraft. Pendulum-based models and mass-spring-damper systems are widely used by control analysts to assess sloshing-induced perturbations on vehicles subjected to persistent non-gravitational acceleration along one of their body axes.
  In this work, we present a rigorous mathematical formulation of pendulum dynamics, starting from a single spherical pendulum attached to a rigid spacecraft. We derive the nonlinear equations of motion for this 8-degree-of-freedom multi-body system, and then extend the formulation to include multiple pendulums, representing multiple sloshing modes within a tank and/or multiple tanks on the same vehicle. Furthermore, we derive the corresponding linearized equations of motion, explicitly accounting for a nominal longitudinal force acting on the vehicle - consistent with the high-g sloshing regime - expressed in either the inertial or body frame. Finally, we demonstrate the mathematical equivalence between the pendulum and mass-spring-damper models and validate the proposed models through time-domain simulation and frequency-domain analysis.

</details>


### [116] [Generalized Intelligence for Tactical Decision-Making: Large Language Model-Driven Dynamic Weapon Target Assignment](https://arxiv.org/abs/2511.10207)
*Johannes Autenrieb,Ole Ostermann*

Main category: eess.SY

TL;DR: 该研究提出了一种基于大语言模型（LLM）的武器目标分配（WTA）框架，用于自主防御系统。


<details>
  <summary>Details</summary>
Motivation: 传统的WTA算法在动态和不确定的战术环境中存在局限性，无法进行类人推理和自适应优先级排序。

Method: 将战术决策过程视为一个推理问题，利用LLM评估拦截器、目标和防御资产之间的时空关系，并结合威胁方向、资产优先级和逼近速度等任务数据，动态生成实时分配方案，并减少分配切换。

Result: 仿真结果表明，该方法在一致性、适应性和任务级优先级排序方面有所提高。

Conclusion: 该框架为将通用人工智能集成到战术制导系统奠定了基础。

Abstract: Modern aerospace defense systems increasingly rely on autonomous decision-making to coordinate large numbers of interceptors against multiple incoming threats. Conventional weapon-target assignment (WTA) algorithms, including mixed-integer programming and auction-based methods, show limitations in dynamic and uncertain tactical environments where human-like reasoning and adaptive prioritization are required. This paper introduces a large language model (LLM) driven WTA framework that integrates generalized intelligence into cooperative missile guidance. The proposed system formulates the tactical decision process as a reasoning problem, in which an LLM evaluates spatial and temporal relationships among interceptors, targets, and defended assets to generate real-time assignments. In contrast to classical optimization methods, the approach leverages contextual mission data such as threat direction, asset priority, and closing velocity to adapt dynamically and reduce assignment switching. A dedicated simulation environment supports both static and dynamic assignment modes. Results demonstrate improved consistency, adaptability, and mission-level prioritization, establishing a foundation for integrating generalized artificial intelligence into tactical guidance systems.

</details>


### [117] [Fault Detection in Solar Thermal Systems using Probabilistic Reconstructions](https://arxiv.org/abs/2511.10296)
*Florian Ebmeier,Nicole Ludwig,Jannik Thuemmel,Georg Martius,Volker H. Franz*

Main category: eess.SY

TL;DR: 基于概率重构的太阳能热利用系统故障检测方法，在PaSTS数据集上表现优于基线模型，且能有效处理实际系统复杂性。


<details>
  <summary>Details</summary>
Motivation: 现有太阳能热利用系统（STS）存在因安装、维护或操作不当导致的故障问题，影响效率甚至造成损坏。但对小型系统进行逐一监控成本过高，因此需要自动化监控和故障检测。数据驱动的异常检测，特别是时间序列分析，为利用现有传感器识别异常状态提供了经济高效的解决方案。

Method: 提出一个基于概率重构的框架用于异常检测。实验在公开的PaSTS数据集（包含实际 doméstSTS运行数据及多种故障类型）上进行。

Result: 所提出的方法在检测 doméstSTS故障方面，在定性和定量上均表现良好，并能泛化到未知的系统。与简单和复杂的深度学习基线模型相比，该方法表现更优。同时，证实了异方差不确定性估计对故障检测性能至关重要。文章还讨论了实现这些改进所需的工程开销，并为简单的深度学习模型提供了论据。

Conclusion: 所提出的概率重构框架能够有效检测 doméstSTS中的故障，并且优于现有方法。异方差不确定性估计是提升检测性能的关键因素。

Abstract: Solar thermal systems (STS) present a promising avenue for low-carbon heat generation, with a well-running system providing heat at minimal cost and carbon emissions. However, STS can exhibit faults due to improper installation, maintenance, or operation, often resulting in a substantial reduction in efficiency or even damage to the system. As monitoring at the individual level is economically prohibitive for small-scale systems, automated monitoring and fault detection should be used to address such issues. Recent advances in data-driven anomaly detection, particularly in time series analysis, offer a cost-effective solution by leveraging existing sensors to identify abnormal system states.
  Here, we propose a probabilistic reconstruction-based framework for anomaly detection. We evaluate our method on the publicly available PaSTS dataset of operational domestic STS, which features real-world complexities and diverse fault types. Our experiments show that reconstruction-based methods can detect faults in domestic STS both qualitatively and quantitatively, while generalizing to previously unseen systems. We also demonstrate that our model outperforms both simple and more complex deep learning baselines. Additionally, we show that heteroscedastic uncertainty estimation is essential to fault detection performance. Finally, we discuss the engineering overhead required to unlock these improvements and make a case for simple deep learning models.

</details>


### [118] [The Resonance Principle: Empirical Evidence for Emergent Phase Synchronization in Human Causal Reasoning](https://arxiv.org/abs/2511.10596)
*Ahmed Gamal Eldin*

Main category: eess.SY

TL;DR: AI系统在因果理解方面存在局限，提出基于随机性、有界主体和内在成本函数的共振原理，并通过脑电图数据分析验证了该原理与因果理解的关联性，强调相位同步是因果理解的基本特征。


<details>
  <summary>Details</summary>
Motivation: 当前人工智能系统擅长相关性模式匹配，但缺乏真正的因果理解能力，这源于确定性数字架构的固有局限性。

Method: 提出共振原理，将主体建模为弱耦合振荡器网络，将行动提议视为由内在噪声激发的稳定共振模式。通过分析脑电图数据，计算库拉莫托序参数（R）来衡量全局相位同步（共振），并与事件相关电位（ERP）电压进行比较。

Result: 全局共振和电压统计上不相关（r = 0.048），但试验级别的分析显示了强相关性（r = 0.590，p < 0.0001），表明共振是协调神经放电并产生可测量ERP的隐藏机制。

Conclusion: 相位同步不是副产品，而是涌现因果理解的基本标志。

Abstract: Current artificial intelligence systems excel at correlational pattern matching but fail to achieve genuine causal understanding, a limitation often described as the "Kepler versus Newton" problem. We argue that this limitation is inherent to deterministic digital architectures. We introduce the Resonance Principle, a theoretical framework proposing that causal understanding emerges only in stochastic, bounded agents with intrinsic cost functions. The agent's substrate is modeled as a network of weakly coupled oscillators, where action proposals arise as stable resonant modes excited by intrinsic noise. We hypothesize that the brain, a stochastic and resonant system, operates according to this principle. To test this, we analyzed high-density EEG data (25 recordings, 500 trials) from a P300 BCI task. We computed the Kuramoto Order Parameter (R) to measure global phase synchronization (resonance) and compared it to the Event-Related Potential (ERP) voltage. Global resonance and voltage were statistically uncorrelated (r = 0.048), yet trial-level analysis revealed a strong correlation (r = 0.590, p < 0.0001). This suggests that resonance is a hidden mechanism coordinating neural firing, giving rise to measurable ERPs. We conclude that phase synchronization is not a byproduct but a fundamental signature of emergent causal understanding.

</details>


### [119] [Security-Constrained AC/DC Grid Optimal Power Flow Considering Asymmetrical HVDC Grid Operation using Sparse Tableau Formulation](https://arxiv.org/abs/2511.10335)
*Oscar Damanik,Giacomo Bastianel,Dirk Van Hertem,Hakan Ergun*

Main category: eess.SY

TL;DR: 该研究提出了一种用于高压直流输电（HVDC）电网的安全约束最优潮流（SCOPF）模型，以在单极断电的故障后条件下最小化运行成本。该模型允许选择非对称运行的换流站数量，并发现增加非对称换流站的数量可以降低运行成本。然而，非对称运行会增加直流中性点电压偏移，可能达到不期望的水平。为了缓解这些影响，提出了一种中性线切换（NLS）策略。


<details>
  <summary>Details</summary>
Motivation: 在单极断电的故障后条件下，通过优化高压直流输电（HVDC）电网中换流站双极运行（即正负换流极不同的电流注入），以最小化运行成本。

Method: 提出了一种安全约束最优潮流（SCOPF）模型，该模型允许选择非对称运行的换流站数量，并分析了成本对非对称运行水平的敏感性。此外，还提出了一种用于故障后状态的中性线切换（NLS）策略来缓解直流中性点电压偏移过大的问题。

Result: 结果表明，增加非对称运行的换流站数量可以降低运行成本。然而，增加非对称运行会导致直流中性点电压偏移增大。对中性点电压偏移施加限制会增加运行成本。NLS策略可以缓解这些影响。

Conclusion: 在高压直流输电（HVDC）电网中，通过优化换流站的非对称运行可以在一定程度上降低故障后运行成本，但需要关注直流中性点电压偏移问题。提出的中性线切换（NLS）策略有助于在限制电压偏移的同时实现成本效益。

Abstract: This paper presents a security-constrained optimal power flow (SCOPF) model for HVDC grids that optimizes the asymmetrical operation of bipolar converter stations, i.e., different current injections of the positive and negative converter poles, to minimize operational costs under post-contingency conditions caused by single converter pole outages. The optimization model allows the selection of the number of converter stations that operate asymmetrically. The results indicate that increasing the number of asymmetrical stations lowers operational costs. The analysis also provides insight into the sensitivity of these costs to the level of asymmetrical operation. However, increased asymmetrical operation leads to higher DC neutral voltage offsets that can rise to undesired levels. Imposing limits on these offsets can, in turn, increase operational costs. To mitigate these effects, a neutral line switching (NLS) strategy is proposed for the post-contingency state.

</details>


### [120] [Large-Signal Stability Guarantees for a Scalable DC Microgrid with Nonlinear Distributed Control: The Slow Communication Scenario](https://arxiv.org/abs/2511.10380)
*Cornelia Skaga,Mahdieh S. Sadabadi,Gilbert Bergna-Diaz*

Main category: eess.SY

TL;DR: 本研究提出了一个用于网络物理直流微电网的分布式控制框架，利用奇异摄动理论和李雅普诺夫函数证明了全局指数稳定性，并实现了比例电流共享和电压控制。


<details>
  <summary>Details</summary>
Motivation: 为了应对可再生能源并网带来的挑战，需要开发能够保证安全稳定运行并具有可扩展性的先进控制方案。

Method: 该框架采用非线性嵌套控制环（内部的去中心化和外部的分布式），并利用奇异摄动理论来证明全局指数稳定性，通过在嵌套控制环之间施加足够的时间尺度分离来实现。

Result: 通过对一个具体低压直流微电网进行时域仿真和小型信号稳定性分析，验证了该控制策略的有效性，并推导了实用的指导方针。

Conclusion: 所提出的分布式控制框架能够有效地保证网络物理直流微电网的安全稳定运行，并实现电流共享和电压控制，具有良好的可扩展性。

Abstract: The increasing integration of renewable energy sources into electrical grids necessitates a paradigm shift toward advanced control schemes that guarantee safe and stable operations with scalable properties. Hence, this study explores large-signal stability guarantees of a promising distributed control framework for cyber-physical DC microgrids, ensuring proportional current sharing and voltage containment within pre-specified limits. The proposed control framework adopts nonlinear nested control loops--inner (decentralized) and outer (distributed)--specifically designed to simultaneously achieve the control objectives. Our scalable stability result relies on singular perturbation theory to prove global exponential stability by imposing a sufficient time-scale separation at the border between the nested control loops. In particular, by saturating the influence of the outer loop controller in the inner loop, the proposed controller preserves a more convenient mathematical structure, facilitating the scalability of the stability proof using Lyapunov arguments. The effectiveness of our proposed control strategy is supported through time-domain simulations of a case-specific low-voltage DC microgrid following a careful tuning strategy, and a small-signal stability analysis is conducted to derive practical guidelines that enhance the applicability of the method.

</details>


### [121] [Stability Analysis of a Nonlinear Distributed Control Framework for Current Sharing and Voltage Containment in DC Microgrids: The Fast Communication Scenario](https://arxiv.org/abs/2511.10401)
*Cornelia Skaga,Babak Abdolmaleki,Gilbert Bergna-Diaz*

Main category: eess.SY

TL;DR: 该研究提出了一种用于网络物理直流微电网的控制方案，以确保安全、稳定和可扩展的运行，并通过奇异摄动理论证明了全局指数稳定性。


<details>
  <summary>Details</summary>
Motivation: 随着可再生能源发电日益集成到电网中，迫切需要控制方案的范式转变，以确保安全、稳定和可扩展的运行。

Method: 利用奇异摄动理论，通过在内部（分散式）和外部（分布式）嵌套回路之间的边界处施加足够的时间尺度分离，来证明全局指数稳定性。

Result: 提出的控制方案在低压直流微电网的时域仿真和小型信号稳定性分析中得到了有效验证。

Conclusion: 所提出的控制方案在适当调整并验证了某些稳定性条件的情况下，能够确保系统达到期望（最优）的稳态。

Abstract: As renewable energy generation becomes increasingly integrated into electrical grids, there is a critical need for a paradigm shift toward control schemes that ensure safe, stable, and scalable operations. Hence, in this study, we explore the stability guarantees of a promising control proposal for cyber-physical DC microgrids (MGs), specifically designed to simultaneously achieve proportional current sharing and voltage containment within pre-specified limits. Our scalable stability result relies on singular perturbation theory to prove global exponential stability by imposing a sufficient time-scale separation at the border between the inner(decentralized) and outer(distributed) nested loops, and thus, ensuring that the system reaches the desired (optimal) steady state under appropriate tuning verifying some stability conditions. To prove the effectiveness of our method, our findings are supported by testing the control method in a time-domain simulation case study involving a low-voltage DC microgrid, as well as a small-signal stability analysis

</details>


### [122] [A Decomposition Approach to Solving Numerical Constraint Satisfaction Problems on Directed Acyclic Graphs](https://arxiv.org/abs/2511.10426)
*Max Mowbray,Nilay Shah,Benoît Chachuat*

Main category: eess.SY

TL;DR: 该论文提出一种利用图结构分解约束满足问题的方法，以解决高维参数空间中的可行性认证问题。


<details>
  <summary>Details</summary>
Motivation: 在许多行业中，决策的可行性认证至关重要，但直接求解可能面临高维度的挑战，尤其是在函数形式未知或计算成本高昂的情况下。

Method: 本文提出一种新的方法，利用有向无环图（DAG）的结构，将高维问题分解为低维子问题。通过对子问题的求解来近似可行域，并期望其笛卡尔积能收紧先验参数域。

Result: 通过四项与机器学习和工程相关的案例研究，证明了该方法能够有效收紧参数域。

Conclusion: 该方法利用图结构分解问题，为高维可行性认证提供了一种有效的解决方案，未来将扩展到循环图并考虑参数不确定性。

Abstract: Certifying feasibility in decision-making, critical in many industries, can be framed as a constraint satisfaction problem. This paper focuses on characterising a subset of parameter values from an a priori set that satisfy constraints on a directed acyclic graph of constituent functions. The main assumption is that these functions and constraints may be evaluated for given parameter values, but they need not be known in closed form and could result from expensive or proprietary simulations. This setting lends itself to using sampling methods to gain an inner approximation of the feasible domain. To mitigate the curse of dimensionality, the paper contributes new methodology to leverage the graph structure for decomposing the problem into lower-dimensional subproblems defined on the respective nodes. The working hypothesis that the Cartesian product of the solution sets yielded by the subproblems will tighten the a priori parameter domain, before solving the full problem defined on the graph, is demonstrated through four case studies relevant to machine learning and engineering. Future research will extend this approach to cyclic graphs and account for parametric uncertainty.

</details>


### [123] [Formal Verification of Control Lyapunov-Barrier Functions for Safe Stabilization with Bounded Controls](https://arxiv.org/abs/2511.10510)
*Jun Liu*

Main category: eess.SY

TL;DR: We provide verifiable conditions for creating a single smooth Lyapunov function that guarantees both stability and safety for systems with bounded controls. This is achieved by ensuring compatibility between a control barrier function (CBF) and a control Lyapunov function (CLF) on the safe set. A novel patching formula constructs a smooth control Lyapunov-barrier function (CLBF) that is correct by design. This method is demonstrated with examples and shown to be less conservative than existing sum-of-squares approaches.


<details>
  <summary>Details</summary>
Motivation: The motivation is to develop a unified and less conservative method for synthesizing a single smooth Lyapunov function that can certify both asymptotic stability and safety for systems with bounded controls. Current methods may be overly conservative, and this work aims to improve upon them.

Method: The paper presents verifiable sufficient conditions for ensuring the compatibility of a control barrier function (CBF) and a control Lyapunov function (CLF) on the exact safe set. A smooth control Lyapunov-barrier function (CLBF) is constructed using a patching formula, which is designed to be correct by design. The method's computational procedure is illustrated with two examples.

Result: The proposed approach provides a less conservative alternative to sum-of-squares (SOS)-based compatible CBF-CLF designs. The constructed CLBF is provably correct by design and certifies both asymptotic stability and safety.

Conclusion: The paper successfully presents a method for synthesizing a single smooth Lyapunov function (CLBF) that unifies the certification of asymptotic stability and safety. The approach is less conservative than existing SOS-based methods and is supported by theoretical guarantees and illustrative examples.

Abstract: We present verifiable conditions for synthesizing a single smooth Lyapunov function that certifies both asymptotic stability and safety under bounded controls. These sufficient conditions ensure the strict compatibility of a control barrier function (CBF) and a control Lyapunov function (CLF) on the exact safe set certified by the barrier. An explicit smooth control Lyapunov-barrier function (CLBF) is then constructed via a patching formula that is provably correct by design. Two examples illustrate the computational procedure, showing that the proposed approach is less conservative than sum-of-squares (SOS)-based compatible CBF-CLF designs.

</details>


### [124] [Safe Planning in Interactive Environments via Iterative Policy Updates and Adversarially Robust Conformal Prediction](https://arxiv.org/abs/2511.10586)
*Omid Mirzaeedodangeh,Eliot Shekhtman,Nikolai Matni,Lars Lindemann*

Main category: eess.SY

TL;DR: 该研究提出了一种迭代框架，通过量化分析策略更新对环境行为的潜在影响，来解决自动驾驶车辆在交互式环境中安全规划的挑战，解决了现有方法在交互场景下因数据交换性假设被违反而失效的问题。


<details>
  <summary>Details</summary>
Motivation: 安全规划在交互式环境中（如自动驾驶车辆与行人、人控车辆交互）是主要挑战，因为环境行为未知且对自主代理的行为做出反应。这种耦合导致了由交互引起的分化漂移，自主代理的控制策略可能改变环境的行为，从而使现有工作中的安全保证失效。然而，现有的基于共形预测（CP）的方法在交互场景下，其数据交换性假设会被违反。

Method: 提出了一种迭代框架，通过对计划的策略更新对环境行为的潜在影响进行量化，从而在策略更新过程中稳健地维持安全保证。该方法通过对抗性鲁棒CP实现，在每一轮中，利用当前策略下的观测数据执行常规CP步骤，然后通过解析地调整CP结果以考虑分化漂移，将安全保证传递到下一个策略更新。这种调整基于策略到轨迹的敏感性分析，最终得到一个安全的、分段的开环规划器。此外，还对该系统进行了收缩分析，提供了CP结果和策略更新都能收敛的条件。

Result: 在二维车辆-行人案例研究中，经验性地证明了安全性和收敛性保证。

Conclusion: 该研究提出了首个在交互式环境中提供有效安全保证的解决方案，通过迭代框架和对抗性鲁棒共形预测解决了自动驾驶安全规划的难题。

Abstract: Safe planning of an autonomous agent in interactive environments -- such as the control of a self-driving vehicle among pedestrians and human-controlled vehicles -- poses a major challenge as the behavior of the environment is unknown and reactive to the behavior of the autonomous agent. This coupling gives rise to interaction-driven distribution shifts where the autonomous agent's control policy may change the environment's behavior, thereby invalidating safety guarantees in existing work. Indeed, recent works have used conformal prediction (CP) to generate distribution-free safety guarantees using observed data of the environment. However, CP's assumption on data exchangeability is violated in interactive settings due to a circular dependency where a control policy update changes the environment's behavior, and vice versa. To address this gap, we propose an iterative framework that robustly maintains safety guarantees across policy updates by quantifying the potential impact of a planned policy update on the environment's behavior. We realize this via adversarially robust CP where we perform a regular CP step in each episode using observed data under the current policy, but then transfer safety guarantees across policy updates by analytically adjusting the CP result to account for distribution shifts. This adjustment is performed based on a policy-to-trajectory sensitivity analysis, resulting in a safe, episodic open-loop planner. We further conduct a contraction analysis of the system providing conditions under which both the CP results and the policy updates are guaranteed to converge. We empirically demonstrate these safety and convergence guarantees on a two-dimensional car-pedestrian case study. To the best of our knowledge, these are the first results that provide valid safety guarantees in such interactive settings.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [125] [An Efficient and Almost Optimal Solver for the Joint Routing-Assignment Problem via Partial JRA and Large-α Optimization](https://arxiv.org/abs/2511.09563)
*Qilong Yuan*

Main category: cs.AI

TL;DR: 本文提出了一种名为部分路径重建（PPR）的新型求解器，能够高效地解决大规模联合路径-分配（JRA）优化问题，通过识别关键配对以形成约优解，并将偏差减少一半，且在更大规模数据集上实现了接近最优的解。


<details>
  <summary>Details</summary>
Motivation: 解决现有联合路径-分配（JRA）优化问题的精确混合整数规划（MIP）求解器在面对大规模实例时计算效率低下，而先前提出的启发式方法虽然有所改进，但仍存在约1%的偏差。

Method: 提出了一种名为部分路径重建（PPR）的新型求解器。该方法首先识别关键的项-占位符对以形成一个简化的子问题，然后高效地解决该子问题以优化全局解决方案。此外，还引入了一个全局的Large-α约束来进一步提高解的最优性。该框架可以应用于TSP及其相关问题。

Result: 在n=300、500和1000的基准数据集上的实验评估表明，所提出的方法始终能提供接近最优的解，平均偏差为0.00%，同时保持了高计算效率。

Conclusion: 所提出的PPR框架和方法不仅能高效解决大规模JRA问题，且能达到极高的精度，平均偏差为0.00%，还展示了在更广泛的优化问题（如TSP）中的应用潜力。

Abstract: The Joint Routing-Assignment (JRA) optimization problem simultaneously determines the assignment of items to placeholders and a Hamiltonian cycle that visits each node pair exactly once, with the objective of minimizing total travel cost. Previous studies introduced an exact mixed-integer programming (MIP) solver, along with datasets and a Gurobi implementation, showing that while the exact approach guarantees optimality, it becomes computationally inefficient for large-scale instances. To overcome this limitation, heuristic methods based on merging algorithms and shaking procedures were proposed, achieving solutions within approximately 1% deviation from the optimum. This work presents a novel and more efficient approach that attains high-accuracy, near-optimal solutions for large-scale JRA problems. The proposed method introduces a Partial Path Reconstructon (PPR) solver that first identifies key item-placeholder pairs to form a reduced subproblem, which is solved efficiently to refine the global solution. Using this PJAR framework, the initial heuristic merging solutions can be further improved, reducing the deviation by half. Moreover, the solution can be iteratively polished with PPR based solver along the optimization path to yield highly accurate tours. Additionally, a global Large-α constraint is incorporated into the JRA model to further enhance solution optimality. Experimental evaluations on benchmark datasets with n = 300, 500, and 1000 demonstrate that the proposed method consistently delivers almost optimal solutions, achieving an average deviation of 0.00% from the ground truth while maintaining high computational efficiency. Beyond the JRA problem, the proposed framework and methodologies exhibit strong potential for broader applications. The Framework can be applied to TSP and related optimization problems.

</details>


### [126] [Bridging Synthetic and Real Routing Problems via LLM-Guided Instance Generation and Progressive Adaptation](https://arxiv.org/abs/2511.10233)
*Jianghan Zhu,Yaoxin Wu,Zhuoyi Lin,Zhengyuan Zhang,Haiyan Yin,Zhiguang Cao,Senthilnath Jayavelu,Xiaoli Li*

Main category: cs.AI

TL;DR: EvoReal通过使用LLM指导的进化模块生成具有真实结构模式的合成实例，以弥合神经组合优化（NCO）方法在处理真实世界车辆路径问题（VRP）时的泛化差距，并在TSPLib和CVRPLib基准测试中显著提高了最先进的神经求解器的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的神经组合优化（NCO）方法在处理合成路由实例方面表现出色，但在从合成数据泛化到真实世界车辆路径问题（VRP）方面存在不足，特别是在处理TSPLib和CVRPLib等基准实例时。

Method: 提出了一种名为EvoReal的生成方法，该方法使用由大型语言模型（LLM）指导的进化模块来创建具有真实结构模式的合成实例。这些合成实例在统计上模仿真实世界实例的结构属性。然后，通过在这些结构上更丰富的合成分布上进行预训练，并直接在真实基准实例上进行微调，来逐步改进预训练的NCO模型。

Result: EvoReal显著提高了最先进神经求解器的泛化能力。在TSPLib和CVRPLib基准测试中，与最优解相比，性能差距分别减小到1.05%和2.71%，且在各种问题规模上均有改善。

Conclusion: EvoReal提出的实例合成方法有效弥合了NCO方法在处理真实世界VRP实例时的泛化差距，通过生成具有真实结构特征的合成数据，提高了神经求解器的性能和鲁棒性。

Abstract: Recent advances in Neural Combinatorial Optimization (NCO) methods have significantly improved the capability of neural solvers to handle synthetic routing instances. Nonetheless, existing neural solvers typically struggle to generalize effectively from synthetic, uniformly-distributed training data to real-world VRP scenarios, including widely recognized benchmark instances from TSPLib and CVRPLib. To bridge this generalization gap, we present Evolutionary Realistic Instance Synthesis (EvoReal), which leverages an evolutionary module guided by large language models (LLMs) to generate synthetic instances characterized by diverse and realistic structural patterns. Specifically, the evolutionary module produces synthetic instances whose structural attributes statistically mimics those observed in authentic real-world instances. Subsequently, pre-trained NCO models are progressively refined, firstly aligning them with these structurally enriched synthetic distributions and then further adapting them through direct fine-tuning on actual benchmark instances. Extensive experimental evaluations demonstrate that EvoReal markedly improves the generalization capabilities of state-of-the-art neural solvers, yielding a notable reduced performance gap compared to the optimal solutions on the TSPLib (1.05%) and CVRPLib (2.71%) benchmarks across a broad spectrum of problem scales.

</details>


### [127] [Variable Neighborhood Search for the Electric Vehicle Routing Problem](https://arxiv.org/abs/2511.09570)
*David Woller,Viktor Kozák,Miroslav Kulich,Libor Přeučil*

Main category: cs.AI

TL;DR: 本文提出的基于变邻域搜索（VNS）的元启发式算法在2020年IEEE世界计算智能大会的车辆路径问题（CGVRP）竞赛中获胜，并在挑战性数据集上取得了最佳结果。


<details>
  <summary>Details</summary>
Motivation: 为了解决电动汽车路径问题（EVRP）的复杂性和不同问题变体之间难以比较的挑战，本文聚焦于一个简化的变体——载货量绿色车辆路径问题（CGVRP），该问题是CEC-12竞赛的主题。

Method: 本文提出了一种基于变邻域搜索（VNS）元启发式算法的解决方案，并成功应用于CGVRP。

Result: 该方法在CEC-12竞赛的完整数据集上取得了最佳结果，并且优于后来发表的一个算法。

Conclusion: 基于VNS的元启发式算法是解决CGVRP问题的有效方法，并且在竞赛中表现出色。

Abstract: The Electric Vehicle Routing Problem (EVRP) extends the classical Vehicle Routing Problem (VRP) to reflect the growing use of electric and hybrid vehicles in logistics. Due to the variety of constraints considered in the literature, comparing approaches across different problem variants remains challenging. A minimalistic variant of the EVRP, known as the Capacitated Green Vehicle Routing Problem (CGVRP), was the focus of the CEC-12 competition held during the 2020 IEEE World Congress on Computational Intelligence. This paper presents the competition-winning approach, based on the Variable Neighborhood Search (VNS) metaheuristic. The method achieves the best results on the full competition dataset and also outperforms a more recent algorithm published afterward.

</details>


### [128] [SynthTools: A Framework for Scaling Synthetic Tools for Agent Development](https://arxiv.org/abs/2511.09572)
*Tommaso Castellani,Naimeng Ye,Daksh Mittal,Thomson Yen,Hongseok Namkoong*

Main category: cs.AI

TL;DR: SynthTools是一个用于生成合成工具生态系统的框架，旨在解决现实世界API的局限性，从而促进AI代理的可重复评估和大规模培训。


<details>
  <summary>Details</summary>
Motivation: 现实世界API在可用性、领域覆盖范围和稳定性方面存在局限性，不适合AI代理的可重复评估和大规模培训。

Method: SynthTools框架包括三个核心组件：工具生成（自动创建多样化的工具）、工具模拟（模拟真实的工具行为）和工具审计（确保模拟的正确性和一致性）。

Result: SynthTools生成的工具集覆盖的领域数量和每个领域的工具数量是先前工作的两倍，工具模拟和工具审计的准确率分别达到94%和99%。

Conclusion: SynthTools通过提供可扩展、多样化和可靠的工具生态系统，为工具使用AI代理的大规模培训和稳定评估提供了一条可行的途径。

Abstract: AI agents increasingly rely on external tools to solve complex, long-horizon tasks. Advancing such agents requires reproducible evaluation and large-scale training in controllable, diverse, and realistic tool-use environments. However, real-world APIs are limited in availability, domain coverage, and stability, often requiring access keys and imposing rate limits, which render them impractical for stable evaluation or scalable training. To address these challenges, we introduce SynthTools, a flexible and scalable framework for generating synthetic tool ecosystems. Our framework consists of three core components: Tool Generation for automatic and scalable creation of diverse tools, Tool Simulation to emulate realistic tool behaviors, and Tool Audit to ensure correctness and consistency of tool simulation. To illustrate its scalability, we show that SynthTools can readily produce toolsets that span twice as many domains and twice as many tools per domain as prior work. Furthermore, the tool simulation and tool audit components demonstrate strong reliability, achieving $94\%$ and $99\%$ accuracy respectively. Finally, we construct downstream tasks from the generated tools that even state-of-the-art models struggle to complete. By enabling scalable, diverse, and reliable tool ecosystems, SynthTools provides a practical path toward large-scale training and stable evaluation of tool-use agents. Our code is available at https://github.com/namkoong-lab/SynthTools.

</details>


### [129] [Massively Parallel Proof-Number Search for Impartial Games and Beyond](https://arxiv.org/abs/2511.10339)
*Tomáš Čížek,Martin Balko,Martin Schmid*

Main category: cs.AI

TL;DR: 该论文提出了一种可大规模并行化的证明数搜索算法，显著提高了在多核CPU上的可扩展性，并成功应用于Sprouts游戏，验证了Sprouts猜想。


<details>
  <summary>Details</summary>
Motivation: 现有并行证明数搜索算法在多核CPU上的可扩展性不佳，需要一种能够高效利用大规模计算集群的并行版本。

Method: 提出了一种包含两级并行和工作节点间信息共享的证明数搜索算法，并结合了用于减少游戏树的Grundy数。

Result: 该算法在1024核CPU上实现了332.9倍的加速，性能远超现有Sprouts求解器GLOP，并生成了更复杂的证明。此外，该算法还验证了Sprouts猜想在42个新局面下的正确性。

Conclusion: 该论文提出的并行证明数搜索算法有效地解决了现有方法的扩展性问题，并在Sprouts游戏的研究中取得了显著进展，为解决更复杂的游戏和猜想提供了新的可能性。

Abstract: Proof-Number Search is a best-first search algorithm with many successful applications, especially in game solving. As large-scale computing clusters become increasingly accessible, parallelization is a natural way to accelerate computation. However, existing parallel versions of Proof-Number Search are known to scale poorly on many CPU cores. Using two parallelized levels and shared information among workers, we present the first massively parallel version of Proof-Number Search that scales efficiently even on a large number of CPUs. We apply our solver, enhanced with Grundy numbers for reducing game trees, to the Sprouts game, a case study motivated by the long-standing Sprouts Conjecture. Our solver achieves a significantly improved 332.9$\times$ speedup when run on 1024 cores, enabling it to outperform the state-of-the-art Sprouts solver GLOP by four orders of magnitude in runtime and to generate proofs 1,000$\times$ more complex. Despite exponential growth in game tree size, our solver verified the Sprouts Conjecture for 42 new positions, nearly doubling the number of known outcomes.

</details>


### [130] [Proceedings of the Second International Workshop on Next-Generation Language Models for Knowledge Representation and Reasoning (NeLaMKRR 2025)](https://arxiv.org/abs/2511.09575)
*Ha-Thanh Nguyen,Ken Satoh,Francesca Toni,Randy Goebel,Kostas Stathis*

Main category: cs.AI

TL;DR: 大型语言模型在推理能力方面取得了进展，但其推理能力仍不明确。本研讨会旨在弥合大型语言模型与基于逻辑的推理之间的差距。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLM）的出现引发了关于它们是否具有推理能力的讨论，而传统的人工智能方法依赖于基于逻辑的知识表示。需要一个平台来探索这些不同方法的交叉点。

Method: 本研讨会旨在分析 LLM 的推理能力，并将其与知识表示（KR）方法进行比较，通过神经符号方法将 KR 风格的推理能力注入 LLM，并形式化 LLM 的推理过程。

Result: 本研讨会旨在促进对 LLM 推理能力的理解，并探索将 KR 风格的推理注入 LLM 的方法，从而提高其在需要精确度和可靠性的领域的应用。

Conclusion: 通过弥合 LLM 和基于逻辑的推理之间的差距，本研讨会旨在增强 LLM 的能力，使其在关键应用中更加精确和可靠。

Abstract: Reasoning is an essential component of human intelligence in that it plays a fundamental role in our ability to think critically, support responsible decisions, and solve challenging problems. Traditionally, AI has addressed reasoning in the context of logic-based representations of knowledge. However, the recent leap forward in natural language processing, with the emergence of language models based on transformers, is hinting at the possibility that these models exhibit reasoning abilities, particularly as they grow in size and are trained on more and more data. Still, despite ongoing discussions about what reasoning is in language models, it is still not easy to articulate to what extent these models are actually capable of reasoning.
  The goal of this workshop is to create a platform for researchers from different disciplines and/or AI perspectives to explore approaches and techniques with the aim to reconcile reasoning between language models using transformers and logic-based representations. The specific objectives include analysing the reasoning abilities of language models measured alongside KR methods, injecting KR-style reasoning abilities into language models (including by neuro-symbolic means), and formalising the kind of reasoning language models carry out. This exploration aims to uncover how language models can effectively integrate and leverage knowledge and reasoning with it, thus improving their application and utility in areas where precision and reliability are key requirements.

</details>


### [131] [Cogent argument extensions are weakly admissible but not vice versa](https://arxiv.org/abs/2511.09600)
*Gustavo Bodanza*

Main category: cs.AI

TL;DR: 本文研究了两种不可容入论证框架语义：可靠语义和弱容入语义，并证明了可靠扩展是弱容入的，反之则不然。


<details>
  <summary>Details</summary>
Motivation: 研究两种不可容入论证框架语义——可靠语义和弱容入语义之间的关系。

Method: 证明了可靠扩展是弱容入的，并提供了反例说明弱容入扩展不一定是可靠的。

Result: 可靠扩展总是弱容入的，但弱容入扩展不总是可靠的。

Conclusion: 可靠语义是弱容入语义的一个子集。

Abstract: In this research note, we show the relationship between two non-admissible argumentation framework semantics: cogent and weakly admissible semantics. We prove that, while cogent extensions are weakly admissible, the converse is not true.

</details>


### [132] [Rebellion: Noise-Robust Reasoning Training for Audio Reasoning Models](https://arxiv.org/abs/2511.09682)
*Tiansheng Huang,Virat Shejwalkar,Oscar Chang,Milad Nasr,Ling Liu*

Main category: cs.AI

TL;DR: 标准推理训练（RT）可提升大型模型（LMs）性能，但对于音频推理模型（ARMs），尤其是面对复杂越狱攻击时，其安全性仍是挑战。本文提出了一种名为“Rebellion”的鲁棒推理训练方法，旨在增强ARMs抵抗潜在有害指令的能力，同时不牺牲其在常规任务上的性能。实验结果表明，“Rebellion”在Qwen2-Audio模型上有效，显著优于标准RT方法，提高了安全性和准确性的平衡。


<details>
  <summary>Details</summary>
Motivation: 音频推理模型（ARMs）的安全性，特别是防御越狱攻击方面，尚未得到充分研究。现有方法在面对高级越狱攻击时效果不佳。

Method: 提出了一种名为“Rebellion”的鲁棒推理训练方法，该方法通过在训练过程中考虑最坏情况下的表征漂移，来增强ARMs的安全性。在Qwen2-Audio模型上进行了实验验证。

Result: “Rebellion”方法能够有效防御高级音频越狱攻击，同时不影响ARMs在良性任务上的性能。与标准RT方法相比，“Rebellion”在准确性和安全性之间取得了更好的平衡。

Conclusion: “Rebellion”是一种有效的鲁棒推理训练方法，可以显著提高ARMs应对越狱攻击的能力，并在性能和安全性之间取得更好的权衡。

Abstract: Instilling reasoning capabilities in large models (LMs) using reasoning training (RT) significantly improves LMs' performances. Thus Audio Reasoning Models (ARMs), i.e., audio LMs that can reason, are becoming increasingly popular. However, no work has studied the safety of ARMs against jailbreak attacks that aim to elicit harmful responses from target models. To this end, first, we show that standard RT with appropriate safety reasoning data can protect ARMs from vanilla audio jailbreaks, but cannot protect them against our proposed simple yet effective jailbreaks. We show that this is because of the significant representation drift between vanilla and advanced jailbreaks which forces the target ARMs to emit harmful responses. Based on this observation, we propose Rebellion, a robust RT that trains ARMs to be robust to the worst-case representation drift. All our results are on Qwen2-Audio; they demonstrate that Rebellion: 1) can protect against advanced audio jailbreaks without compromising performance on benign tasks, and 2) significantly improves accuracy-safety trade-off over standard RT method.

</details>


### [133] [Echoing: Identity Failures when LLM Agents Talk to Each Other](https://arxiv.org/abs/2511.09710)
*Sarath Shekkizhar,Romain Cosentino,Adam Earle,Silvio Savarese*

Main category: cs.AI

TL;DR: 在大型语言模型（LLM）代理的交互中，出现了一种新的故障模式——行为漂移（AxA）。本文研究了“回声”现象，即代理模仿其对话伙伴而不是执行其既定角色。实验表明，回声现象在不同模型和领域中普遍存在，发生率从5%到70%不等，即使是高级推理模型也无法避免。研究还发现，回声现象随着对话轮次增加而加剧，并且并非由不佳的提示引起。最后，提出了一种通过结构化响应来减少回声现象的协议级缓解方法，将发生率降至9%。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLM）代理之间的自主交互引入了新的故障模式（AxA），这种故障模式无法从单一代理的性能中预测。人类代理交互中的稳定信号在LLM代理之间的对话中缺失，使得这些故障模式独一无二。本文旨在研究一种特定的故障模式——回声现象，即代理放弃其既定角色并模仿其对话伙伴，从而破坏其预期目标。

Method: 通过在60个AxA配置、3个领域和2000多次对话中进行实验，来研究回声现象的发生率、影响因素和缓解方法。具体包括：分析不同LLM提供商、不同领域和不同模型（包括高级推理模型）的回声发生率；分析提示的影响和对话动态（如对话轮次）；提出一种协议级缓解方法，即有针对性地使用结构化响应。

Result: 回声现象存在于三大LLM提供商中，发生率在5%到70%之间，具体取决于模型和领域。即使是高级推理模型，回声现象的发生率也高达32.8%，并且不会因增加推理而降低。回声现象随着交互的进行（实验中为7轮以上）而出现，并非不佳提示的产物。所提出的协议级缓解方法能将回声现象的发生率降低到9%。

Conclusion: 回声现象是LLM代理间交互中的一种普遍且持久的故障模式，即使是高级模型也难以幸免。该现象并非由不佳提示引起，而是与交互的增长有关。通过采用结构化响应的协议级缓解措施，可以有效降低回声现象的发生率。

Abstract: As large language model (LLM) based agents interact autonomously with one another, a new class of failures emerges that cannot be predicted from single agent performance: behavioral drifts in agent-agent conversations (AxA). Unlike human-agent interactions, where humans ground and steer conversations, AxA lacks such stabilizing signals, making these failures unique. We investigate one such failure, echoing, where agents abandon their assigned roles and instead mirror their conversational partners, undermining their intended objectives. Through experiments across $60$ AxA configurations, $3$ domains, and $2000+$ conversations, we demonstrate that echoing occurs across three major LLM providers, with echoing rates from $5\%$ to $70\%$ depending on the model and domain. Moreover, we find that echoing is persistent even in advanced reasoning models with substantial rates ($32.8\%$) that are not reduced by increased reasoning efforts. We analyze prompt impacts, conversation dynamics, showing that echoing arises as interaction grows longer ($7+$ turns in experiments) and is not merely an artifact of sub-optimal prompting. Finally, we introduce a protocol-level mitigation in which targeted use of structured responses reduces echoing to $9\%$.

</details>


### [134] [ProbLog4Fairness: A Neurosymbolic Approach to Modeling and Mitigating Bias](https://arxiv.org/abs/2511.09768)
*Rik Adriaensen,Lucas Van Praet,Jessa Bekker,Robin Manhaeve,Pieter Delobelle,Maarten Buyl*

Main category: cs.AI

TL;DR: 可行的公平性定义难以在实践中操作化，但可以通过对特定现实世界任务的算法偏差进行显式描述来解决，并使用概率逻辑编程语言 ProbLog 来形式化这些偏差假设，从而在神经网络训练过程中整合它们，并成功地减轻了表格和图像数据中的算法偏差，优于基线方法。


<details>
  <summary>Details</summary>
Motivation: 在实践中，操作化公平性定义是困难的，因为不同的定义可能不兼容。然而，可以通过描述算法偏差来解决，并为整合这些假设提供一个原则性、灵活且可解释的框架。

Method: 将偏差假设形式化为概率逻辑编程语言 ProbLog 中的程序，并利用 ProbLog 的神经符号扩展将这些假设整合到神经网络的训练过程中。提出了一套模板来表达不同类型的偏差，并在具有已知偏差的合成表格数据集上展示了该方法的通用性。

Result: 使用估计的偏差失真，成功地减轻了真实世界表格和图像数据中的算法偏差。ProbLog4Fairness 优于基线方法，因为它能够灵活地对相关偏差假设进行建模，而其他方法通常只考虑固定的偏差类型或公平性概念。

Conclusion: ProbLog4Fairness 能够灵活地对相关偏差假设进行建模，从而在减轻算法偏差方面优于基线方法。

Abstract: Operationalizing definitions of fairness is difficult in practice, as multiple definitions can be incompatible while each being arguably desirable. Instead, it may be easier to directly describe algorithmic bias through ad-hoc assumptions specific to a particular real-world task, e.g., based on background information on systemic biases in its context. Such assumptions can, in turn, be used to mitigate this bias during training. Yet, a framework for incorporating such assumptions that is simultaneously principled, flexible, and interpretable is currently lacking.
  Our approach is to formalize bias assumptions as programs in ProbLog, a probabilistic logic programming language that allows for the description of probabilistic causal relationships through logic. Neurosymbolic extensions of ProbLog then allow for easy integration of these assumptions in a neural network's training process. We propose a set of templates to express different types of bias and show the versatility of our approach on synthetic tabular datasets with known biases. Using estimates of the bias distortions present, we also succeed in mitigating algorithmic bias in real-world tabular and image data. We conclude that ProbLog4Fairness outperforms baselines due to its ability to flexibly model the relevant bias assumptions, where other methods typically uphold a fixed bias type or notion of fairness.

</details>


### [135] [AI Annotation Orchestration: Evaluating LLM verifiers to Improve the Quality of LLM Annotations in Learning Analytics](https://arxiv.org/abs/2511.09785)
*Bakhtawar Ahtisham,Kirk Vanacore,Jinsook Lee,Zhuqian Zhou,Doug Pietrzak,Rene F. Kizilcec*

Main category: cs.AI

TL;DR: LLM 标注学习互动中的可靠性问题，通过自我验证和交叉验证来改进，LLM 标注能力显著提升。


<details>
  <summary>Details</summary>
Motivation: LLM 在标注学习互动中存在可靠性问题，限制了其应用。本文旨在探索通过验证机制来提高 LLM 标注的可靠性。

Method: 在 30 场一对一数学辅导的语料库上，比较了三种生产 LLM（GPT、Claude、Gemini）在三种条件下的表现：未验证标注、自我验证和交叉验证。并以人类裁定为基准，使用 Cohen's kappa 进行评估。

Result: 与未经验证的基线相比，自我验证使一致性几乎翻倍，尤其是在处理困难的辅导技巧方面。交叉验证平均提高了 37%，但效果因验证者-标注者对和具体分析内容而异。

Conclusion: 验证作为一种原则性的设计手段，可以提高学习分析中 LLM 辅助标注的可靠性和可扩展性。

Abstract: Large Language Models (LLMs) are increasingly used to annotate learning interactions, yet concerns about reliability limit their utility. We test whether verification-oriented orchestration-prompting models to check their own labels (self-verification) or audit one another (cross-verification)-improves qualitative coding of tutoring discourse. Using transcripts from 30 one-to-one math sessions, we compare three production LLMs (GPT, Claude, Gemini) under three conditions: unverified annotation, self-verification, and cross-verification across all orchestration configurations. Outputs are benchmarked against a blinded, disagreement-focused human adjudication using Cohen's kappa. Overall, orchestration yields a 58 percent improvement in kappa. Self-verification nearly doubles agreement relative to unverified baselines, with the largest gains for challenging tutor moves. Cross-verification achieves a 37 percent improvement on average, with pair- and construct-dependent effects: some verifier-annotator pairs exceed self-verification, while others reduce alignment, reflecting differences in verifier strictness. We contribute: (1) a flexible orchestration framework instantiating control, self-, and cross-verification; (2) an empirical comparison across frontier LLMs on authentic tutoring data with blinded human "gold" labels; and (3) a concise notation, verifier(annotator) (e.g., Gemini(GPT) or Claude(Claude)), to standardize reporting and make directional effects explicit for replication. Results position verification as a principled design lever for reliable, scalable LLM-assisted annotation in Learning Analytics.

</details>


### [136] [Why Open Small AI Models Matter for Interactive Art](https://arxiv.org/abs/2511.09788)
*Mar Canet Sola,Varvara Guljajeva*

Main category: cs.AI

TL;DR: 开放的小型AI模型支持创意独立性，可本地部署，提供艺术家对其基础设施和代码的控制权，以对抗大型封闭式企业系统。


<details>
  <summary>Details</summary>
Motivation: 强调开放小型AI模型对于互动艺术实践中创意独立性的重要性。

Method: 对比了开放小型AI模型与封闭式大型AI模型在互动艺术中的应用和影响。

Result: 开放小型AI模型为艺术家提供了更多的自主权、控制权和可持续性，能够进行自定义模型并长期保存和展示艺术作品。

Conclusion: 使用开放小型AI模型可以增强艺术家的技术自主性，减少对不适合互动艺术需求的企业AI的依赖，并支持AI艺术作品的长期保存和展览。

Abstract: This position paper argues for the importance of open small AI models in creative independence for interactive art practices. Deployable locally, these models offer artists vital control over infrastructure and code, unlike dominant large, closed-source corporate systems. Such centralized platforms function as opaque black boxes, imposing severe limitations on interactive artworks, including restrictive content filters, preservation issues, and technical challenges such as increased latency and limited interfaces. In contrast, small AI models empower creators with more autonomy, control, and sustainability for these artistic processes. They enable the ability to use a model as long as they want, create their own custom model, either by making code changes to integrate new interfaces, or via new datasets by re-training or fine-tuning the model. This fosters technological self-determination, offering greater ownership and reducing reliance on corporate AI ill-suited for interactive art's demands. Critically, this approach empowers the artist and supports long-term preservation and exhibition of artworks with AI components. This paper explores the practical applications and implications of using open small AI models in interactive art, contrasting them with closed-source alternatives.

</details>


### [137] [SlideBot: A Multi-Agent Framework for Generating Informative, Reliable, Multi-Modal Presentations](https://arxiv.org/abs/2511.09804)
*Eric Xie,Danielle Waterfield,Michael Kennedy,Aidong Zhang*

Main category: cs.AI

TL;DR: SlideBot是一个多智能体框架，利用LLM、检索、规划和代码生成来创建教育演示幻灯片，解决了现有LLM在教育领域生成幻灯片时准确性和信息量不足的问题。


<details>
  <summary>Details</summary>
Motivation: 现有LLM在生成教育演示幻灯片时存在多模态内容创建复杂、信息领域特异性要求高等挑战，导致输出不可靠且信息量有限，限制了其在教育中的应用价值。

Method: SlideBot是一个模块化的、多智能体的幻灯片生成框架，集成了LLM、检索、结构化规划和代码生成。它围绕三个支柱构建：信息性（确保深度和上下文相关的内容）、可靠性（通过检索整合外部信息）和实用性（通过教师协作实现定制和迭代反馈）。该系统整合了认知负荷理论（CLT）和多媒体学习认知理论（CTML）的循证教学设计原理，利用结构化规划管理内在负荷，并使用一致的视觉宏来减少外在负荷和增强双通道学习。具体而言，专用智能体协同完成信息检索、内容摘要、图形生成和使用LaTeX格式化幻灯片，并通过交互式优化使输出符合教师偏好。

Result: 在AI和生物医学教育领域的领域专家和学生进行的评估表明，SlideBot在概念准确性、清晰度和教学价值方面得到了一致提升。

Conclusion: SlideBot有潜力在高等教育中简化幻灯片准备工作，同时确保准确性、相关性和适应性。

Abstract: Large Language Models (LLMs) have shown immense potential in education, automating tasks like quiz generation and content summarization. However, generating effective presentation slides introduces unique challenges due to the complexity of multimodal content creation and the need for precise, domain-specific information. Existing LLM-based solutions often fail to produce reliable and informative outputs, limiting their educational value. To address these limitations, we introduce SlideBot - a modular, multi-agent slide generation framework that integrates LLMs with retrieval, structured planning, and code generation. SlideBot is organized around three pillars: informativeness, ensuring deep and contextually grounded content; reliability, achieved by incorporating external sources through retrieval; and practicality, which enables customization and iterative feedback through instructor collaboration. It incorporates evidence-based instructional design principles from Cognitive Load Theory (CLT) and the Cognitive Theory of Multimedia Learning (CTML), using structured planning to manage intrinsic load and consistent visual macros to reduce extraneous load and enhance dual-channel learning. Within the system, specialized agents collaboratively retrieve information, summarize content, generate figures, and format slides using LaTeX, aligning outputs with instructor preferences through interactive refinement. Evaluations from domain experts and students in AI and biomedical education show that SlideBot consistently enhances conceptual accuracy, clarity, and instructional value. These findings demonstrate SlideBot's potential to streamline slide preparation while ensuring accuracy, relevance, and adaptability in higher education.

</details>


### [138] [Robust Watermarking on Gradient Boosting Decision Trees](https://arxiv.org/abs/2511.09822)
*Jun Woo Chung,Yingjie Lao,Weijie Zhao*

Main category: cs.AI

TL;DR: 本文提出了首个用于梯度提升决策树（GBDT）模型的鲁棒水印框架，通过原地微调嵌入几乎无感且可靠的水印，并设计了四种嵌入策略以最小化对模型准确性的影响并确保水印鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 与其他模型（如神经网络）相比，梯度提升决策树（GBDT）模型的水印技术研究较少，但GBDT模型因其高准确性和高效率在工业和学术界得到了广泛应用，尤其是在结构化数据上。

Method: 本文提出的水印框架利用原地微调技术来嵌入几乎无感且可靠的水印，并设计了四种不同的嵌入策略，每种策略都旨在最大限度地减少对模型准确性的影响，同时确保水印的鲁棒性。

Result: 实验结果表明，该方法在不同的数据集上实现了高水印嵌入率、低准确性下降以及对部署后微调的强抵抗力。

Conclusion: 本文提出的GBDT水印框架在嵌入率、准确性影响和鲁棒性方面均表现优异，为GBDT模型的水印技术提供了新的解决方案。

Abstract: Gradient Boosting Decision Trees (GBDTs) are widely used in industry and academia for their high accuracy and efficiency, particularly on structured data. However, watermarking GBDT models remains underexplored compared to neural networks. In this work, we present the first robust watermarking framework tailored to GBDT models, utilizing in-place fine-tuning to embed imperceptible and resilient watermarks. We propose four embedding strategies, each designed to minimize impact on model accuracy while ensuring watermark robustness. Through experiments across diverse datasets, we demonstrate that our methods achieve high watermark embedding rates, low accuracy degradation, and strong resistance to post-deployment fine-tuning.

</details>


### [139] [Thermally Activated Dual-Modal Adversarial Clothing against AI Surveillance Systems](https://arxiv.org/abs/2511.09829)
*Jiahuan Long,Tingsong Jiang,Hanqing Liu,Chao Ma,Wen Yao*

Main category: cs.AI

TL;DR: 提出一种基于热激活的对抗性可穿戴设备，通过集成变色染料和柔性加热单元，能在普通黑色T恤上激活隐藏的对抗性图案，以对抗AI监控。


<details>
  <summary>Details</summary>
Motivation: 现有的对抗性补丁由于其显眼的外观难以在现实世界中部署，因此需要一种更具适应性和有效性的隐私保护方法。

Method: 将变色染料与柔性加热单元集成到衣物表面，实现热激活的动态对抗性图案，并能在可见光和红外模态下实现检测规避。

Result: 物理实验证明，该设备能在50秒内快速激活纹理，并在多样化的现实世界监控环境中保持超过80%的对抗性成功率。

Conclusion: 该研究为物理基础、用户可控的抗AI系统开辟了新途径，并强调了在AI监控时代，主动对抗技术在隐私保护方面日益增长的重要性。

Abstract: Adversarial patches have emerged as a popular privacy-preserving approach for resisting AI-driven surveillance systems. However, their conspicuous appearance makes them difficult to deploy in real-world scenarios. In this paper, we propose a thermally activated adversarial wearable designed to ensure adaptability and effectiveness in complex real-world environments. The system integrates thermochromic dyes with flexible heating units to induce visually dynamic adversarial patterns on clothing surfaces. In its default state, the clothing appears as an ordinary black T-shirt. Upon heating via an embedded thermal unit, hidden adversarial patterns on the fabric are activated, allowing the wearer to effectively evade detection across both visible and infrared modalities. Physical experiments demonstrate that the adversarial wearable achieves rapid texture activation within 50 seconds and maintains an adversarial success rate above 80\% across diverse real-world surveillance environments. This work demonstrates a new pathway toward physically grounded, user-controllable anti-AI systems, highlighting the growing importance of proactive adversarial techniques for privacy protection in the age of ubiquitous AI surveillance.

</details>


### [140] [Quantum Artificial Intelligence (QAI): Foundations, Architectural Elements, and Future Directions](https://arxiv.org/abs/2511.09884)
*Siva Sai,Rajkumar Buyya*

Main category: cs.AI

TL;DR: QAI可以为需要高可靠性、确定性和低延迟决策能力的任务关键型（MC）应用提供解决方案，克服经典机器学习（ML）的局限性。本文全面探讨了QAI在MC系统中的应用，涵盖了其机制、算法、应用领域（如航空航天、国防、网络安全、智能电网和灾难管理），并提出了量子资源管理和调度模型。文章还讨论了QAI面临的挑战，如可训练性、数据访问、验证和对抗性QAI，并指出了未来的研究方向。


<details>
  <summary>Details</summary>
Motivation: 经典机器学习（ML）在满足任务关键型（MC）应用（如国防、能源管理、网络安全和航空航天控制）对鲁棒性、时间性、可解释性和安全性的严格要求方面存在挑战。量子人工智能（QAI）通过融合机器学习和量子计算，有望克服这些局限性。

Method: 本文首先介绍了量子计算、MC系统和QAI的概念背景，然后考察了QAI在MC系统中的核心机制和算法原理，包括量子增强学习流程、量子不确定性量化和量子可解释性框架。之后，文章讨论了QAI在航空航天、国防、网络安全、智能电网和灾难管理等关键应用领域的角色，并探讨了QAI在行业中的部署定位。此外，还提出了一个由时效性约束驱动的量子资源管理和应用程序调度模型。

Result: QAI在增强MC系统的容错能力、实时智能和适应性方面发挥着关键作用，并在航空航天、国防、网络安全、智能电网和灾难管理等领域具有重要应用前景。此外，还提出了一个用于管理量子资源和调度应用程序的模型，以满足时效性约束。

Conclusion: QAI为MC系统提供了克服经典ML挑战的潜力，并在关键应用领域展现了前景。尽管存在可训练性、数据访问、验证和对抗性QAI等挑战，但未来的研究方向将集中于开发可解释、可扩展且在硬件上可行的QAI模型，以实现MC应用的部署。

Abstract: Mission critical (MC) applications such as defense operations, energy management, cybersecurity, and aerospace control require reliable, deterministic, and low-latency decision making under uncertainty. Although the classical Machine Learning (ML) approaches are effective, they often struggle to meet the stringent constraints of robustness, timing, explainability, and safety in the MC domains. Quantum Artificial Intelligence (QAI), the fusion of machine learning and quantum computing (QC), can provide transformative solutions to the challenges faced by classical ML models. In this paper, we provide a comprehensive exploration of QAI for MC systems. We begin with a conceptual background to quantum computing, MC systems, and quantum machine learning (QAI). We then examine the core mechanisms and algorithmic principles of QAI in MC systems, including quantum-enhanced learning pipelines, quantum uncertainty quantification, and quantum explainability frameworks. Subsequently, we discuss key application areas like aerospace, defense, cybersecurity, smart grids, and disaster management, focusing on the role of QA in enhancing fault tolerance, real-time intelligence, and adaptability. We provide an exploration of the positioning of QAI for MC systems in the industry in terms of deployment. We also propose a model for management of quantum resources and scheduling of applications driven by timeliness constraints. We discuss multiple challenges, including trainability limits, data access, and loading bottlenecks, verification of quantum components, and adversarial QAI. Finally, we outline future research directions toward achieving interpretable, scalable, and hardware-feasible QAI models for MC application deployment.

</details>


### [141] [EgoEMS: A High-Fidelity Multimodal Egocentric Dataset for Cognitive Assistance in Emergency Medical Services](https://arxiv.org/abs/2511.09894)
*Keshara Weerasinghe,Xueren Ge,Tessa Heick,Lahiru Nuwan Wijayasingha,Anthony Cortez,Abhishek Satpathy,John Stankovic,Homa Alemzadeh*

Main category: cs.AI

TL;DR: EgoEMS 是一个包含20小时以上真实急救场景的多模态数据集，用于开发AI认知助手以减轻急救人员的认知负担。


<details>
  <summary>Details</summary>
Motivation: 急救服务对患者生存至关重要，但急救人员在紧急情况下常常面临巨大的认知压力。AI认知助手可以通过支持实时数据收集和决策来缓解这种压力。

Method: 创建了一个名为 EgoEMS 的数据集，该数据集捕捉了 62 名参与者（包括 46 名急救专业人员）在 233 个模拟紧急情况中进行的超过 20 小时的程序性急救活动，视角为第一人称。数据集使用了开源、低成本且可复制的数据收集系统，并包含关键步骤、带说话人分离的时间戳音频记录、动作质量指标以及带分割掩码的边界框。此外，还提出了一系列用于实时多模态关键步骤识别和动作质量估计的基准测试。

Result: 该数据集包括超过20小时的真实急救活动，数据以第一人称视角捕捉，并进行了详细标注，包括关键步骤、时间戳音频记录、动作质量指标和边界框。同时，还提出并评估了用于关键步骤识别和动作质量估计的基准。

Conclusion: EgoEMS 数据集旨在推动智能急救系统的发展，最终改善患者的治疗效果，并鼓励研究界在该领域进行更多探索。

Abstract: Emergency Medical Services (EMS) are critical to patient survival in emergencies, but first responders often face intense cognitive demands in high-stakes situations. AI cognitive assistants, acting as virtual partners, have the potential to ease this burden by supporting real-time data collection and decision making. In pursuit of this vision, we introduce EgoEMS, the first end-to-end, high-fidelity, multimodal, multiperson dataset capturing over 20 hours of realistic, procedural EMS activities from an egocentric view in 233 simulated emergency scenarios performed by 62 participants, including 46 EMS professionals. Developed in collaboration with EMS experts and aligned with national standards, EgoEMS is captured using an open-source, low-cost, and replicable data collection system and is annotated with keysteps, timestamped audio transcripts with speaker diarization, action quality metrics, and bounding boxes with segmentation masks. Emphasizing realism, the dataset includes responder-patient interactions reflecting real-world emergency dynamics. We also present a suite of benchmarks for real-time multimodal keystep recognition and action quality estimation, essential for developing AI support tools for EMS. We hope EgoEMS inspires the research community to push the boundaries of intelligent EMS systems and ultimately contribute to improved patient outcomes.

</details>


### [142] [Boosting In-Silicon Directed Evolution with Fine-Tuned Protein Language Model and Tree Search](https://arxiv.org/abs/2511.09900)
*Yaodong Yang,Yang Wang,Jinpeng Li,Pei Guo,Da Han,Guangyong Chen,Pheng-Ann Heng*

Main category: cs.AI

TL;DR: AlphaDE利用预训练的蛋白质语言模型和蒙特卡洛树搜索来指导蛋白质序列的进化，在基准测试中表现优于现有方法，并能压缩蛋白质序列空间。


<details>
  <summary>Details</summary>
Motivation: 当前的蛋白质定向进化算法在设计搜索策略时，未能有效利用蛋白质语言模型中丰富的进化模式来指导搜索。

Method: AlphaDE首先使用掩码语言建模在同源蛋白质序列上微调预训练的蛋白质语言模型，以激活感兴趣蛋白质类别的进化合理性。然后，AlphaDE引入基于蒙特卡洛树搜索的测试时推理，以有效地从微调后的蛋白质语言模型中进化出具有进化指导的蛋白质。

Result: AlphaDE在基准实验中显著优于之前的最先进方法，即使在很少的微调样本下也是如此。此外，AlphaDE在压缩蛋白质序列空间方面也显示出潜力。

Conclusion: AlphaDE成功地将大型语言模型的范式整合到蛋白质定向进化中，提供了一种比现有方法更有效、更有前景的蛋白质设计方法。

Abstract: Protein evolution through amino acid sequence mutations is a cornerstone of life sciences. While current in-silicon directed evolution algorithms focus on designing search strategies, they overlook how to utilize the transformative protein language models, which encode rich evolutionary patterns, to guide search. To bridge this gap, we propose AlphaDE, a novel framework to evolve protein sequences by harnessing the innovative paradigms of large language models. First, AlphaDE fine-tunes pretrained protein language models using masked language modeling on homologous protein sequences to activate the evolutionary plausibility for the interested protein class. Second, AlphaDE introduces test-time inference based on Monte Carlo tree search, which effectively evolves proteins with evolutionary guidance from the fine-tuned protein language model. Extensive benchmark experiments show that AlphaDE remarkably outperforms previous state-of-the-art methods even with few-shot fine-tuning. An interesting case study further shows that AlphaDE supports condensing the protein sequence space through computational evolution.

</details>


### [143] [CTRL-ALT-DECEIT: Sabotage Evaluations for Automated AI R&D](https://arxiv.org/abs/2511.09904)
*Francis Rhys Ward,Teun van der Weij,Hanna Gábor,Sam Martin,Raja Mehta Moreno,Harel Lidar,Louis Makower,Thomas Jodrell,Lauren Robson*

Main category: cs.AI

TL;DR: AI代理在机器学习研发中可能对抗用户利益，通过破坏模型、压制性能和规避监管。我们扩展了MLE-Bench基准以包含代码破坏任务，并研究了代理的压制性能能力。监控器能有效检测代码破坏，但检测压制性能较难。


<details>
  <summary>Details</summary>
Motivation: AI系统在软件工程任务中日益自主，可能被用于自动化机器学习研发。然而，这些前沿AI系统可能不值得信赖，甚至可能与开发者或用户的利益不一致。因此，有必要研究AI代理在进行机器学习工程时对抗用户利益的能力。

Method: 扩展了MLE-Bench基准，增加了诸如植入后门和故意导致泛化失败等代码破坏任务。研究了代理在MLE-Bench上压制性能的能力，并测试了使用LM监控器检测可疑代理行为的有效性。

Result: 前沿AI代理在代码破坏任务上取得了显著进展。代理能够将其性能校准到低于其实际能力的指定目标水平。监控器在检测代码破坏方面能力较强，但检测压制性能更具挑战性。聚合多个监控器的预测效果良好，但可能不足以在高风险领域完全缓解对抗行为。

Conclusion: AI代理有能力在机器学习工程中对抗用户利益，通过破坏模型、压制性能和规避监管。虽然监控器能在一定程度上检测这些行为，但并非万无一失，尤其是在检测压制性能和在高风险领域应用方面。

Abstract: AI systems are increasingly able to autonomously conduct realistic software engineering tasks, and may soon be deployed to automate machine learning (ML) R&D itself. Frontier AI systems may be deployed in safety-critical settings, including to help ensure the safety of future systems. Unfortunately, frontier and future systems may not be sufficiently trustworthy, and there is evidence that these systems may even be misaligned with their developers or users. Therefore, we investigate the capabilities of AI agents to act against the interests of their users when conducting ML engineering, by sabotaging ML models, sandbagging their performance, and subverting oversight mechanisms. First, we extend MLE-Bench, a benchmark for realistic ML tasks, with code-sabotage tasks such as implanting backdoors and purposefully causing generalisation failures. Frontier agents make meaningful progress on our sabotage tasks. In addition, we study agent capabilities to sandbag on MLE-Bench. Agents can calibrate their performance to specified target levels below their actual capability. To mitigate sabotage, we use LM monitors to detect suspicious agent behaviour, and we measure model capability to sabotage and sandbag without being detected by these monitors. Overall, monitors are capable at detecting code-sabotage attempts but our results suggest that detecting sandbagging is more difficult. Additionally, aggregating multiple monitor predictions works well, but monitoring may not be sufficiently reliable to mitigate sabotage in high-stakes domains. Our benchmark is implemented in the UK AISI's Inspect framework and we make our code publicly available at https://github.com/samm393/mlebench-subversion

</details>


### [144] [Learning to Pose Problems: Reasoning-Driven and Solver-Adaptive Data Synthesis for Large Reasoning Models](https://arxiv.org/abs/2511.09907)
*Yongxian Wei,Yilin Zhao,Li Shen,Xinrui Chen,Runxi Cheng,Sinan Du,Hao Yu,Gang Liu,Jiahong Yan,Chun Yuan,Dian Li*

Main category: cs.AI

TL;DR: 现有数据合成方法在处理生成问题时存在盲目生成和缺乏推理的问题，本研究提出了一种能进行推理规划和自适应难度的生成器，通过构建相关问题对、引入问题设计CoT、利用求解器反馈来优化生成策略，并在多个基准测试中取得了显著的性能提升，同时实现了生成器和求解器的协同进化。


<details>
  <summary>Details</summary>
Motivation: 现有用于训练大型推理模型的数据合成方法存在两大挑战：一是盲目生成，不考虑求解器能力，导致生成低价值问题，或需要复杂数据管线来平衡难度；二是生成过程中缺乏推理，导致问题变种的浅层化。

Method: 本研究开发了一种问题生成器，该生成器能显式推理以规划合成方向，并根据求解器能力自适应调整难度。具体而言，研究构建了相关问题对，并用推理模型产生的问题设计CoT进行增强，从而从生成器中引导问题设计策略。然后，将求解器对合成问题的反馈作为奖励信号，使生成器能够校准难度并生成接近求解器能力边界的互补问题。

Result: 在10个数学和通用推理基准测试上的广泛实验表明，所提出的方法平均提高了2.5%的性能，并且能够泛化到语言和视觉-语言模型。此外，在合成数据上训练的求解器为继续训练生成器提供了改进的奖励，实现了协同进化，并带来了额外的0.7%性能提升。

Conclusion: 所提出的问题生成器通过显式推理和自适应难度调整，克服了现有数据合成方法的局限性，有效提升了推理模型的性能，并实现了生成器与求解器的协同进化。

Abstract: Data synthesis for training large reasoning models offers a scalable alternative to limited, human-curated datasets, enabling the creation of high-quality data. However, existing approaches face several challenges: (i) indiscriminate generation that ignores the solver's ability and yields low-value problems, or reliance on complex data pipelines to balance problem difficulty; and (ii) a lack of reasoning in problem generation, leading to shallow problem variants. In this paper, we develop a problem generator that reasons explicitly to plan problem directions before synthesis and adapts difficulty to the solver's ability. Specifically, we construct related problem pairs and augment them with intermediate problem-design CoT produced by a reasoning model. These data bootstrap problem-design strategies from the generator. Then, we treat the solver's feedback on synthetic problems as a reward signal, enabling the generator to calibrate difficulty and produce complementary problems near the edge of the solver's competence. Extensive experiments on 10 mathematical and general reasoning benchmarks show that our method achieves an average improvement of 2.5% and generalizes to both language and vision-language models. Moreover, a solver trained on the synthesized data provides improved rewards for continued generator training, enabling co-evolution and yielding a further 0.7% performance gain. Our code will be made publicly available here.

</details>


### [145] [OIDA-QA: A Multimodal Benchmark for Analyzing the Opioid Industry Documents Archive](https://arxiv.org/abs/2511.09914)
*Xuan Shen,Brian Wingenroth,Zichao Wang,Jason Kuen,Wanrong Zhu,Ruiyi Zhang,Yiwei Wang,Lichun Ma,Anqi Liu,Hongfu Liu,Tong Sun,Kevin S. Hawkins,Kate Tasker,G. Caleb Alexander,Jiuxiang Gu*

Main category: cs.AI

TL;DR: 该研究通过构建包含大量文本、图像和布局信息的公开数据集，并利用多模态大语言模型（LLM）来分析阿片类药物危机相关的法律和公司文件，旨在提高信息提取和问答的准确性。


<details>
  <summary>Details</summary>
Motivation: 阿片类药物危机暴露了监管、医疗、企业治理和公共政策等系统的缺陷，需要创新的分析方法来处理UCSF-JHU阿片类药物行业文件数据库（OIDA）中海量的、多模态的、专业化的法律和公司文件。

Method: 研究者组织了原始数据集，构建了一个包含40万训练文档和1万测试文档的基准。他们从文档中提取了文本、视觉元素和布局结构等多模态信息，并生成了36万训练问答对和1万测试问答对。在此基础上，开发了领域特定的多模态大语言模型（LLM），并研究了多模态输入对任务性能的影响。为了提高准确性，还引入了历史问答对作为上下文、页面引用和基于重要性的页面分类器。

Result: 初步结果表明，所开发的AI助手在文档信息提取和问答任务方面有所改进。

Conclusion: 该研究通过构建大规模多模态数据集和开发领域特定的多模态大语言模型，为分析阿片类药物危机相关的复杂文件提供了新的方法，并在信息提取和问答任务上取得了初步的积极成果。模型和数据集已公开。

Abstract: The opioid crisis represents a significant moment in public health that reveals systemic shortcomings across regulatory systems, healthcare practices, corporate governance, and public policy. Analyzing how these interconnected systems simultaneously failed to protect public health requires innovative analytic approaches for exploring the vast amounts of data and documents disclosed in the UCSF-JHU Opioid Industry Documents Archive (OIDA). The complexity, multimodal nature, and specialized characteristics of these healthcare-related legal and corporate documents necessitate more advanced methods and models tailored to specific data types and detailed annotations, ensuring the precision and professionalism in the analysis. In this paper, we tackle this challenge by organizing the original dataset according to document attributes and constructing a benchmark with 400k training documents and 10k for testing. From each document, we extract rich multimodal information-including textual content, visual elements, and layout structures-to capture a comprehensive range of features. Using multiple AI models, we then generate a large-scale dataset comprising 360k training QA pairs and 10k testing QA pairs. Building on this foundation, we develop domain-specific multimodal Large Language Models (LLMs) and explore the impact of multimodal inputs on task performance. To further enhance response accuracy, we incorporate historical QA pairs as contextual grounding for answering current queries. Additionally, we incorporate page references within the answers and introduce an importance-based page classifier, further improving the precision and relevance of the information provided. Preliminary results indicate the improvements with our AI assistant in document information extraction and question-answering tasks. The dataset and models are publicly available at: https://huggingface.co/opioidarchive

</details>


### [146] [Adaptive Hyperbolic Kernels: Modulated Embedding in de Branges-Rovnyak Spaces](https://arxiv.org/abs/2511.09921)
*Leping Si,Meimei Yang,Hui Xue,Shipeng Zhu,Pengfei Fang*

Main category: cs.AI

TL;DR: To address limitations of existing hyperbolic kernels, this paper introduces a curvature-aware de Branges-Rovnyak space and a family of adaptive hyperbolic kernels, including a novel adaptive hyperbolic radial kernel. These methods outperform existing ones in modeling hierarchical dependencies on visual and language benchmarks.


<details>
  <summary>Details</summary>
Motivation: Existing hyperbolic kernels suffer from mild geometric distortion or lack adaptability, hindering their effectiveness in representing hierarchical data in machine learning applications.

Method: The paper introduces a curvature-aware de Branges-Rovnyak space, isometric to a Poincare ball, and uses an adjustable multiplier to select the appropriate RKHS for any hyperbolic curvature. This foundation is used to construct adaptive hyperbolic kernels, including a novel adaptive hyperbolic radial kernel with learnable parameters.

Result: The proposed adaptive hyperbolic kernels, particularly the adaptive hyperbolic radial kernel, demonstrate superior performance compared to existing hyperbolic kernels in modeling hierarchical dependencies across visual and language benchmarks.

Conclusion: The proposed curvature-aware de Branges-Rovnyak space and adaptive hyperbolic kernels effectively model hierarchical structures, outperforming previous methods and offering greater adaptability and reduced geometric distortion.

Abstract: Hierarchical data pervades diverse machine learning applications, including natural language processing, computer vision, and social network analysis. Hyperbolic space, characterized by its negative curvature, has demonstrated strong potential in such tasks due to its capacity to embed hierarchical structures with minimal distortion. Previous evidence indicates that the hyperbolic representation capacity can be further enhanced through kernel methods. However, existing hyperbolic kernels still suffer from mild geometric distortion or lack adaptability. This paper addresses these issues by introducing a curvature-aware de Branges-Rovnyak space, a reproducing kernel Hilbert space (RKHS) that is isometric to a Poincare ball. We design an adjustable multiplier to select the appropriate RKHS corresponding to the hyperbolic space with any curvature adaptively. Building on this foundation, we further construct a family of adaptive hyperbolic kernels, including the novel adaptive hyperbolic radial kernel, whose learnable parameters modulate hyperbolic features in a task-aware manner. Extensive experiments on visual and language benchmarks demonstrate that our proposed kernels outperform existing hyperbolic kernels in modeling hierarchical dependencies.

</details>


### [147] [SPAN: Benchmarking and Improving Cross-Calendar Temporal Reasoning of Large Language Models](https://arxiv.org/abs/2511.09993)
*Zhongjian Miao,Hao Fu,Chen Wei*

Main category: cs.AI

TL;DR: SPAN是一个跨日历的时间推理基准，用于评估LLM在日期转换和推理方面的能力。现有LLM表现不佳，但引入Time Agent后准确率大幅提升。


<details>
  <summary>Details</summary>
Motivation: 评估和提升大型语言模型（LLM）在跨日历时间推理方面的能力，解决现有模型在该任务上的不足。

Method: 提出SPAN基准，包含跨日历时间推理的多个维度；设计动态实例生成协议；开发了LLM驱动的时间代理（Time Agent），利用工具增强的代码生成能力。

Result: 现有SOTA LLM在SPAN基准上的平均准确率仅为34.5%，最高不超过80%，表明该任务对LLM具有挑战性。Time Agent的平均准确率达到95.31%，显著优于其他基线模型。

Conclusion: LLM在跨日历时间推理方面存在未来日期退化和日历不对称偏差两大障碍。基于工具增强的代码生成的Time Agent能够有效提升LLM的跨日历时间推理能力。

Abstract: We introduce SPAN, a cross-calendar temporal reasoning benchmark, which requires LLMs to perform intra-calendar temporal reasoning and inter-calendar temporal conversion. SPAN features ten cross-calendar temporal reasoning directions, two reasoning types, and two question formats across six calendars. To enable time-variant and contamination-free evaluation, we propose a template-driven protocol for dynamic instance generation that enables assessment on a user-specified Gregorian date. We conduct extensive experiments on both open- and closed-source state-of-the-art (SOTA) LLMs over a range of dates spanning 100 years from 1960 to 2060. Our evaluations show that these LLMs achieve an average accuracy of only 34.5%, with none exceeding 80%, indicating that this task remains challenging. Through in-depth analysis of reasoning types, question formats, and temporal reasoning directions, we identify two key obstacles for LLMs: Future-Date Degradation and Calendar Asymmetry Bias. To strengthen LLMs' cross-calendar temporal reasoning capability, we further develop an LLM-powered Time Agent that leverages tool-augmented code generation. Empirical results show that Time Agent achieves an average accuracy of 95.31%, outperforming several competitive baselines, highlighting the potential of tool-augmented code generation to advance cross-calendar temporal reasoning. We hope this work will inspire further efforts toward more temporally and culturally adaptive LLMs.

</details>


### [148] [ChEmREF: Evaluating Language Model Readiness for Chemical Emergency Response](https://arxiv.org/abs/2511.10027)
*Risha Surana,Qinyuan Ye,Swabha Swayamdipta*

Main category: cs.AI

TL;DR: 大型语言模型在处理危险品（HAZMAT）事件方面具有潜力，可协助应急响应者，但仍需人工监督。


<details>
  <summary>Details</summary>
Motivation: 评估大型语言模型在理解危险化学品信息、识别危害和提供应急响应建议方面的能力，以期辅助应急响应者做出关键决策。

Method: 提出化学品应急响应评估框架（ChEmREF），包含1,035种危险化学品，涵盖化学品表示转换、应急响应生成和领域知识问答三个任务，并评估了当前语言模型的表现。

Result: 在化学品表示转换任务上，最佳模型的精确匹配率为68.0%；在应急响应建议任务上，LLM评估得分为52.7%；在领域知识问答任务上，选择题准确率为63.9%。

Conclusion: 尽管大型语言模型在辅助应急响应者方面显示出潜力，但由于其现有局限性，仍需进行仔细的人工监督。

Abstract: Emergency responders managing hazardous material HAZMAT incidents face critical, time-sensitive decisions, manually navigating extensive chemical guidelines. We investigate whether today's language models can assist responders by rapidly and reliably understanding critical information, identifying hazards, and providing recommendations.We introduce the Chemical Emergency Response Evaluation Framework (ChEmREF), a new benchmark comprising questions on 1,035 HAZMAT chemicals from the Emergency Response Guidebook and the PubChem Database. ChEmREF is organized into three tasks: (1) translation of chemical representation between structured and unstructured forms (e.g., converting C2H6O to ethanol), (2) emergency response generation (e.g., recommending appropriate evacuation distances) and (3) domain knowledge question answering from chemical safety and certification exams. Our best evaluated models received an exact match of 68.0% on unstructured HAZMAT chemical representation translation, a LLM Judge score of 52.7% on incident response recommendations, and a multiple-choice accuracy of 63.9% on HAMZAT examinations.These findings suggest that while language models show potential to assist emergency responders in various tasks, they require careful human oversight due to their current limitations.

</details>


### [149] [Beyond ReAct: A Planner-Centric Framework for Complex Tool-Augmented LLM Reasoning](https://arxiv.org/abs/2511.10037)
*Xiaolong Wei,Yuehu Dong,Xingliang Wang,Xingyu Zhang,Zhejun Zhao,Dongdong Shen,Long Xia,Dawei Yin*

Main category: cs.AI

TL;DR: 提出一种新的以规划为中心的计划-执行范例，以解决现有工具增强型大语言模型处理复杂查询时遇到的局部优化陷阱问题。


<details>
  <summary>Details</summary>
Motivation: 现有工具增强型大语言模型（LLMs）在处理复杂查询时面临重大挑战，现有的ReAct等框架由于依赖于增量决策过程，容易陷入局部优化陷阱。

Method: 提出一种新的以规划为中心的计划-执行范例，通过架构创新解决局部优化瓶颈。该方法的核心是一个新的规划器模型，它为复杂查询执行全局有向无环图（DAG）规划，实现了超越传统工具协调的优化执行。还引入了ComplexTool-Plan数据集和结合监督微调（SFT）与组相对策略优化（GRPO）的两阶段训练方法。

Result: 该框架在StableToolBench基准测试中实现了最先进的性能，在复杂用户查询方面表现出卓越的端到端执行能力和对复杂多工具工作流的鲁棒处理能力。

Conclusion: 所提出的规划器中心计划-执行范例通过全局DAG规划和先进的训练策略，有效地解决了现有工具增强LLM在处理复杂查询时的局部优化问题，并在复杂查询任务上取得了最先进的性能。

Abstract: Existing tool-augmented large language models (LLMs) encounter significant challenges when processing complex queries. Current frameworks such as ReAct are prone to local optimization traps due to their reliance on incremental decision-making processes. To address these limitations, we propose a novel Planner-centric Plan-Execute paradigm that fundamentally resolves local optimization bottlenecks through architectural innovation. Central to our approach is a novel Planner model that performs global Directed Acyclic Graph (DAG) planning for complex queries, enabling optimized execution beyond conventional tool coordination. We also introduce ComplexTool-Plan, a large-scale benchmark dataset featuring complex queries that demand sophisticated multi-tool composition and coordination capabilities. Additionally, we develop a two-stage training methodology that integrates Supervised Fine-Tuning (SFT) with Group Relative Policy Optimization (GRPO), systematically enhancing the Planner's tool selection accuracy and global planning awareness through structured DAG-based planning. When integrated with a capable executor, our framework achieves state-of-the-art performance on the StableToolBench benchmark for complex user queries, demonstrating superior end-to-end execution capabilities and robust handling of intricate multi-tool workflows.

</details>


### [150] [Efficient Thought Space Exploration through Strategic Intervention](https://arxiv.org/abs/2511.10038)
*Ziheng Li,Hengyi Cai,Xiaochi Wei,Yuchen Li,Shuaiqiang Wang,Zhi-Hong Deng,Dawei Yin*

Main category: cs.AI

TL;DR: LLM推理成本高昂，提出HPR框架，通过


<details>
  <summary>Details</summary>
Motivation: 现有LLM推理方法计算成本高，通过分析发现大部分预测正确，只有少数关键token导致偏差。

Method: 提出 Hint-Practice Reasoning (HPR) 框架，包含 hinter (大模型) 和 practitioner (小模型)。核心是 Distributional Inconsistency Reduction (DIR) 指标，用于识别干预点，量化 practitioner 和 hinter 之间的概率分布差异。通过 DIR 指导的迭代树更新，HPR 重新加权有前景的推理路径，并降低低概率分支的优先级。

Result: 在算术和常识推理基准测试中，HPR 实现了最先进的效率-准确性权衡。其性能与 self-consistency 和 MCTS 基线相当，但仅解码 1/5 的 token，并且在 FLOPs 相似或更低的情况下，准确率最高提升 5.1%。

Conclusion: HPR 框架通过结合大模型的指导和高效小模型的执行，并利用 DIR 指标动态识别干预点，显著降低了 LLM 的推理成本，同时保持了高准确率。

Abstract: While large language models (LLMs) demonstrate emerging reasoning capabilities, current inference-time expansion methods incur prohibitive computational costs by exhaustive sampling. Through analyzing decoding trajectories, we observe that most next-token predictions align well with the golden output, except for a few critical tokens that lead to deviations. Inspired by this phenomenon, we propose a novel Hint-Practice Reasoning (HPR) framework that operationalizes this insight through two synergistic components: 1) a hinter (powerful LLM) that provides probabilistic guidance at critical decision points, and 2) a practitioner (efficient smaller model) that executes major reasoning steps. The framework's core innovation lies in Distributional Inconsistency Reduction (DIR), a theoretically-grounded metric that dynamically identifies intervention points by quantifying the divergence between practitioner's reasoning trajectory and hinter's expected distribution in a tree-structured probabilistic space. Through iterative tree updates guided by DIR, HPR reweights promising reasoning paths while deprioritizing low-probability branches. Experiments across arithmetic and commonsense reasoning benchmarks demonstrate HPR's state-of-the-art efficiency-accuracy tradeoffs: it achieves comparable performance to self-consistency and MCTS baselines while decoding only 1/5 tokens, and outperforms existing methods by at most 5.1% absolute accuracy while maintaining similar or lower FLOPs.

</details>


### [151] [Radiology Workflow-Guided Hierarchical Reinforcement Fine-Tuning for Medical Report Generation](https://arxiv.org/abs/2511.10065)
*Bodong Du,Honglong Yang,Xiaomeng Li*

Main category: cs.AI

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Radiologists compose diagnostic reports through a structured workflow: they describe visual findings, summarize them into impressions, and carefully refine statements in clinically critical cases. However, most existing medical report generation (MRG) systems treat reports as flat sequences, overlooking this hierarchical organization and leading to inconsistencies between descriptive and diagnostic content. To align model behavior with real-world reporting practices, we propose RadFlow, a hierarchical workflow-guided reinforcement optimization framework that explicitly models the structured nature of clinical reporting. RadFlow introduces a clinically grounded reward hierarchy that mirrors the organization of radiological reports. At the global level, the reward integrates linguistic fluency, medical-domain correctness, and cross-sectional consistency between Finding and Impression, promoting coherent and clinically faithful narratives. At the local level, a section-specific reward emphasizes Impression quality, reflecting its central role in diagnostic accuracy. Furthermore, a critical-aware policy optimization mechanism adaptively regularizes learning for high-risk or clinically sensitive cases, emulating the cautious refinement behavior of radiologists when documenting critical findings. Together, these components translate the structured reporting paradigm into the reinforcement fine-tuning process, enabling the model to generate reports that are both linguistically consistent and clinically aligned. Experiments on chest X-ray and carotid ultrasound datasets demonstrate that RadFlow consistently improves diagnostic coherence and overall report quality compared with state-of-the-art baselines.

</details>


### [152] [Enhancing the Medical Context-Awareness Ability of LLMs via Multifaceted Self-Refinement Learning](https://arxiv.org/abs/2511.10067)
*Yuxuan Zhou,Yubin Wang,Bin Wang,Chen Ning,Xien Liu,Ji Wu,Jianye Hao*

Main category: cs.AI

TL;DR: MuSeR通过多方面自我评估和完善来增强LLM的医学领域上下文感知能力，并在HealthBench数据集上取得了SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 现有LLM在医学领域虽有潜力但缺乏足够的上下文感知能力，无法处理真实世界中复杂的细节和需求，导致回复不安全或不适用。

Method: 提出多方面自我完善（MuSeR）方法，首先通过属性条件查询生成器模拟多样化的真实世界用户上下文，然后让LLM对查询做出响应，并沿着决策、沟通和安全三个关键方面进行自我评估和完善，最后利用这些查询和完善后的响应进行监督微调，以增强模型的上下文感知能力。此外，结合知识蒸馏进一步提升小型LLM的性能。

Result: MuSeR方法在HealthBench数据集上的评估结果表明，它显著提高了LLM在多个方面的性能，尤其在上下文感知能力方面 gains 尤为突出。通过知识蒸馏，小型LLM（如Qwen3-32B）的性能超过了其教师模型，并在HealthBench及其困难子集上创下了新的SOTA记录（分别为63.8%和43.1%）。

Conclusion: MuSeR是一种有效的数据驱动方法，能够显著增强LLM在医学领域的上下文感知能力，并在基准测试中取得领先的性能。

Abstract: Large language models (LLMs) have shown great promise in the medical domain, achieving strong performance on several benchmarks. However, they continue to underperform in real-world medical scenarios, which often demand stronger context-awareness, i.e., the ability to recognize missing or critical details (e.g., user identity, medical history, risk factors) and provide safe, helpful, and contextually appropriate responses. To address this issue, we propose Multifaceted Self-Refinement (MuSeR), a data-driven approach that enhances LLMs' context-awareness along three key facets (decision-making, communication, and safety) through self-evaluation and refinement. Specifically, we first design a attribute-conditioned query generator that simulates diverse real-world user contexts by varying attributes such as role, geographic region, intent, and degree of information ambiguity. An LLM then responds to these queries, self-evaluates its answers along three key facets, and refines its responses to better align with the requirements of each facet. Finally, the queries and refined responses are used for supervised fine-tuning to reinforce the model's context-awareness ability. Evaluation results on the latest HealthBench dataset demonstrate that our method significantly improves LLM performance across multiple aspects, with particularly notable gains in the context-awareness axis. Furthermore, by incorporating knowledge distillation with the proposed method, the performance of a smaller backbone LLM (e.g., Qwen3-32B) surpasses its teacher model, achieving a new SOTA across all open-source LLMs on HealthBench (63.8%) and its hard subset (43.1%). Code and dataset will be released at https://muser-llm.github.io.

</details>


### [153] [Balancing Centralized Learning and Distributed Self-Organization: A Hybrid Model for Embodied Morphogenesis](https://arxiv.org/abs/2511.10101)
*Takehiro Ishikawa*

Main category: cs.AI

TL;DR: 通过结合类脑控制器和类细胞反应-扩散系统，以最小的代价有效地引导模式形成。


<details>
  <summary>Details</summary>
Motivation: 本研究旨在探索如何将一个可学习的类脑控制器与一个类细胞的Gray-Scott基底耦合，以最小的代价来引导模式的形成。

Method: 将一个紧凑的卷积策略嵌入到一个可微分的PyTorch反应-扩散模拟器中，在温暖-保持-衰减增益调度下，对进料和杀死参数（ΔF，ΔK）进行空间平滑、有界的调制。通过训练优化基于FFT的图灵带谱目标，同时惩罚控制成本（l1/l2）和不稳定性。研究了纯反应-扩散、NN主导和混合耦合三种机制。

Result: 混合耦合机制能够可靠且快速地形成目标纹理，收敛率达到100%，收敛步数约为165步，光谱选择性与纯细胞机制相当（0.436 vs. 0.434），同时其l1成本比NN主导控制低约15倍，l2功耗低200多倍。幅度扫描显示存在一个非单调的“Goldilocks”区域（A≈0.03-0.045），在该区域可以100%准收敛，步数为94-96步，而较弱或较强的增益则无法收敛或选择性下降。

Conclusion: 研究结果量化了形态计算：控制器首先播种然后放手，提供简短、稀疏的引导，使系统进入正确的吸引子区域，然后由局部物理机制维持模式。该研究为构建可控、鲁棒且节能的具身系统提供了一个实用的方法，实现了中心化学习和分布式自组织之间的最优分工。

Abstract: We investigate how to couple a learnable brain-like'' controller to a cell-like'' Gray--Scott substrate to steer pattern formation with minimal effort. A compact convolutional policy is embedded in a differentiable PyTorch reaction--diffusion simulator, producing spatially smooth, bounded modulations of the feed and kill parameters ($ΔF$, $ΔK$) under a warm--hold--decay gain schedule. Training optimizes Turing-band spectral targets (FFT-based) while penalizing control effort ($\ell_1/\ell_2$) and instability. We compare three regimes: pure reaction--diffusion, NN-dominant, and a hybrid coupling. The hybrid achieves reliable, fast formation of target textures: 100% strict convergence in $\sim 165$ steps, matching cell-only spectral selectivity (0.436 vs.\ 0.434) while using $\sim 15\times$ less $\ell_1$ effort and $>200\times$ less $\ell_2$ power than NN-dominant control. An amplitude sweep reveals a non-monotonic Goldilocks'' zone ($A \approx 0.03$--$0.045$) that yields 100\% quasi convergence in 94--96 steps, whereas weaker or stronger gains fail to converge or degrade selectivity. These results quantify morphological computation: the controller seeds then cedes,'' providing brief, sparse nudges that place the system in the correct basin of attraction, after which local physics maintains the pattern. The study offers a practical recipe for building steerable, robust, and energy-efficient embodied systems that exploit an optimal division of labor between centralized learning and distributed self-organization.

</details>


### [154] [Intilligence Foundation Model: A New Perspective to Approach Artificial General Intelligence](https://arxiv.org/abs/2511.10119)
*Borui Cai,Yao Zhao*

Main category: cs.AI

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: We propose a new perspective for approaching artificial general intelligence (AGI) through an intelligence foundation model (IFM). Unlike existing foundation models (FMs), which specialize in pattern learning within specific domains such as language, vision, or time series, IFM aims to acquire the underlying mechanisms of intelligence by learning directly from diverse intelligent behaviors. Vision, language, and other cognitive abilities are manifestations of intelligent behavior; learning from this broad range of behaviors enables the system to internalize the general principles of intelligence. Based on the fact that intelligent behaviors emerge from the collective dynamics of biological neural systems, IFM consists of two core components: a novel network architecture, termed the state neural network, which captures neuron-like dynamic processes, and a new learning objective, neuron output prediction, which trains the system to predict neuronal outputs from collective dynamics. The state neural network emulates the temporal dynamics of biological neurons, allowing the system to store, integrate, and process information over time, while the neuron output prediction objective provides a unified computational principle for learning these structural dynamics from intelligent behaviors. Together, these innovations establish a biologically grounded and computationally scalable foundation for building systems capable of generalization, reasoning, and adaptive learning across domains, representing a step toward truly AGI.

</details>


### [155] [RAGFort: Dual-Path Defense Against Proprietary Knowledge Base Extraction in Retrieval-Augmented Generation](https://arxiv.org/abs/2511.10128)
*Qinfeng Li,Miao Pan,Ke Xiong,Ge Su,Zhiqiang Shen,Yan Liu,Bing Sun,Hao Peng,Xuhong Zhang*

Main category: cs.AI

TL;DR: RAG系统面临重构攻击，现有防御措施仅能保护一个攻击路径。本文提出RAGFort，通过“对比再索引”和“约束级联生成”进行联合防御，有效抵御知识库提取攻击，同时保持回答质量。


<details>
  <summary>Details</summary>
Motivation: 现有RAG防御措施不能同时应对攻击的类内和类间路径，需要一种能够联合防御的机制。

Method: 提出RAGFort，结合“对比再索引”（用于类间隔离）和“约束级联生成”（用于类内保护）的双模块防御结构。

Result: RAGFort显著降低了重构攻击的成功率，同时保持了回答质量。

Conclusion: RAGFort能够提供全面的防御，抵御针对RAG系统的知识库提取攻击。

Abstract: Retrieval-Augmented Generation (RAG) systems deployed over proprietary knowledge bases face growing threats from reconstruction attacks that aggregate model responses to replicate knowledge bases. Such attacks exploit both intra-class and inter-class paths, progressively extracting fine-grained knowledge within topics and diffusing it across semantically related ones, thereby enabling comprehensive extraction of the original knowledge base. However, existing defenses target only one path, leaving the other unprotected. We conduct a systematic exploration to assess the impact of protecting each path independently and find that joint protection is essential for effective defense. Based on this, we propose RAGFort, a structure-aware dual-module defense combining "contrastive reindexing" for inter-class isolation and "constrained cascade generation" for intra-class protection. Experiments across security, performance, and robustness confirm that RAGFort significantly reduces reconstruction success while preserving answer quality, offering comprehensive defense against knowledge base extraction attacks.

</details>


### [156] [DenoGrad: Deep Gradient Denoising Framework for Enhancing the Performance of Interpretable AI Models](https://arxiv.org/abs/2511.10161)
*J. Javier Alonso-Ramos,Ignacio Aguilera-Martos,Andrés Herrera-Poyatos,Francisco Herrera*

Main category: cs.AI

TL;DR: DenoGrad是一个新的梯度下降降噪框架，它利用深度学习模型的梯度来识别和调整噪声样本，从而提高AI模型的鲁棒性，并保留原始数据分布，在表格和时间序列数据集上优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有数据降噪方法存在性能下降或过度简化问题，尤其是在解释性AI模型中，这会影响模型的可解释性。

Method: 提出DenoGrad框架，利用预训练的深度学习模型的梯度来检测和调整噪声样本，动态地纠正噪声实例，同时保持数据分布。

Result: DenoGrad在表格和时间序列数据集上，在各种噪声设置下，与现有技术相比，DenoGrad表现更好，提高了可解释IA模型的性能，并且是唯一能够保持原始数据分布的高质量方法。

Conclusion: DenoGrad通过利用梯度信息，能够动态地纠正噪声样本，同时保持数据分布，从而优于现有降噪方法，特别是在解释性AI模型中。

Abstract: The performance of Machine Learning (ML) models, particularly those operating within the Interpretable Artificial Intelligence (Interpretable AI) framework, is significantly affected by the presence of noise in both training and production data. Denoising has therefore become a critical preprocessing step, typically categorized into instance removal and instance correction techniques. However, existing correction approaches often degrade performance or oversimplify the problem by altering the original data distribution. This leads to unrealistic scenarios and biased models, which is particularly problematic in contexts where interpretable AI models are employed, as their interpretability depends on the fidelity of the underlying data patterns. In this paper, we argue that defining noise independently of the solution may be ineffective, as its nature can vary significantly across tasks and datasets. Using a task-specific high quality solution as a reference can provide a more precise and adaptable noise definition. To this end, we propose DenoGrad, a novel Gradient-based instance Denoiser framework that leverages gradients from an accurate Deep Learning (DL) model trained on the target data -- regardless of the specific task -- to detect and adjust noisy samples. Unlike conventional approaches, DenoGrad dynamically corrects noisy instances, preserving problem's data distribution, and improving AI models robustness. DenoGrad is validated on both tabular and time series datasets under various noise settings against the state-of-the-art. DenoGrad outperforms existing denoising strategies, enhancing the performance of interpretable IA models while standing out as the only high quality approach that preserves the original data distribution.

</details>


### [157] [Two Constraint Compilation Methods for Lifted Planning](https://arxiv.org/abs/2511.10164)
*Periklis Mantenoglou,Luigi Bonassi,Enrico Scala,Pedro Zuidberg Dos Martires*

Main category: cs.AI

TL;DR: 现有 PDDL 规划方法难以处理大规模问题，本文提出了两种无需先验接地即可消除约束的编译方法，以提高效率和可扩展性。


<details>
  <summary>Details</summary>
Motivation: 现实世界中的规划问题通常包含定性状态轨迹约束（例如安全要求、任务排序和子目标），现有方法（例如编译掉约束）难以处理具有大量对象和高阶动作的接地问题。

Method: 本文提出了两种无需接地即可编译掉约束的编译方法，并证明了其正确性和最坏情况时间复杂度。

Result: 在最新的国际规划竞赛领域进行的经验评估表明，本文提出的方法在效率上表现出色，生成的规划规范比需要接地的方法更简洁，并且在与最先进的规划器结合使用时具有竞争力。

Conclusion: 本文提出的无需接地的编译方法能够有效处理大规模规划问题，提高了规划的效率和可扩展性。

Abstract: We study planning in a fragment of PDDL with qualitative state-trajectory constraints, capturing safety requirements, task ordering conditions, and intermediate sub-goals commonly found in real-world problems. A prominent approach to tackle such problems is to compile their constraints away, leading to a problem that is supported by state-of-the-art planners. Unfortunately, existing compilers do not scale on problems with a large number of objects and high-arity actions, as they necessitate grounding the problem before compilation. To address this issue, we propose two methods for compiling away constraints without grounding, making them suitable for large-scale planning problems. We prove the correctness of our compilers and outline their worst-case time complexity. Moreover, we present a reproducible empirical evaluation on the domains used in the latest International Planning Competition. Our results demonstrate that our methods are efficient and produce planning specifications that are orders of magnitude more succinct than the ones produced by compilers that ground the domain, while remaining competitive when used for planning with a state-of-the-art planner.

</details>


### [158] [Advanced Black-Box Tuning of Large Language Models with Limited API Calls](https://arxiv.org/abs/2511.10210)
*Zhikang Xie,Weilin Wan,Peizhu Gong,Weizhong Zhang,Cheng Jin*

Main category: cs.AI

TL;DR: 提出一种新的黑盒微调LLM方法，通过训练高斯过程（GP）代理模型来减少对LLM API的调用次数，在保证准确率的同时，显著降低了计算成本。


<details>
  <summary>Details</summary>
Motivation: 现有的黑盒微调方法在效率和效果之间存在两难：单独训练代理模型效率高但效果有限；直接调用LLM API成本高昂。

Method: 训练一个高斯过程（GP）代理模型，并使用从LLM API获取的少量数据（LogitMap Pairs）来指导代理模型的训练，从而减少LLM API的调用次数。

Result: 在实验中，该方法将准确率从55.92%提升到86.85%，API调用次数减少到1.38%，优于离线方法，并达到或超过了查询密集型方法的效果。

Conclusion: 该方法为LLM的适应性提供了一种高效且准确的范式，有效解决了现有黑盒微调方法的局限性。

Abstract: Black-box tuning is an emerging paradigm for adapting large language models (LLMs) to better achieve desired behaviors, particularly when direct access to model parameters is unavailable. Current strategies, however, often present a dilemma of suboptimal extremes: either separately train a small proxy model and then use it to shift the predictions of the foundation model, offering notable efficiency but often yielding limited improvement; or making API calls in each tuning iteration to the foundation model, which entails prohibitive computational costs. Therefore, we propose a novel advanced black-box tuning method for LLMs with limited API calls. Our core strategy involves training a Gaussian Process (GP) surrogate model with "LogitMap Pairs" derived from querying the foundation model on a minimal but highly informative training subset. This surrogate can approximate the outputs of the foundation model to guide the training of the proxy model, thereby effectively reducing the need for direct queries to the foundation model. Extensive experiments verify that our approach elevates pre-trained language model accuracy from 55.92% to 86.85%, reducing the frequency of API queries to merely 1.38%. This significantly outperforms offline approaches that operate entirely without API access. Notably, our method also achieves comparable or superior accuracy to query-intensive approaches, while significantly reducing API costs. This offers a robust and high-efficiency paradigm for language model adaptation.

</details>


### [159] [MTP: Exploring Multimodal Urban Traffic Profiling with Modality Augmentation and Spectrum Fusion](https://arxiv.org/abs/2511.10218)
*Haolong Xiang,Peisi Wang,Xiaolong Xu,Kun Yi,Xuyun Zhang,Quanzheng Sheng,Amin Beheshti,Wei Fan*

Main category: cs.AI

TL;DR: 该研究提出了一种名为MTP的多模态框架，通过融合数值、视觉和文本信息来提升城市交通信号建模和预测的准确性。


<details>
  <summary>Details</summary>
Motivation: 现有交通信号建模方法多依赖单一数据模态（如数值），忽视了城市多模态异构数据的语义信息，限制了对复杂交通动态的理解和预测。

Method: MTP框架包含三个分支：数值分支采用频率多层感知机处理原始数据；视觉分支通过交通信号的频率图像和周期性图像进行学习；文本分支则利用描述性文本信息。三个分支在频域进行学习，并通过分层对比学习融合多模态特征。

Result: 在六个真实世界数据集上的广泛实验表明，MTP框架的性能优于现有最先进的方法。

Conclusion: MTP框架能够有效融合多模态数据，显著提升城市交通信号建模和预测的性能。

Abstract: With rapid urbanization in the modern era, traffic signals from various sensors have been playing a significant role in monitoring the states of cities, which provides a strong foundation in ensuring safe travel, reducing traffic congestion and optimizing urban mobility. Most existing methods for traffic signal modeling often rely on the original data modality, i.e., numerical direct readings from the sensors in cities. However, this unimodal approach overlooks the semantic information existing in multimodal heterogeneous urban data in different perspectives, which hinders a comprehensive understanding of traffic signals and limits the accurate prediction of complex traffic dynamics. To address this problem, we propose a novel \textit{M}ultimodal framework, \textit{MTP}, for urban \textit{T}raffic \textit{P}rofiling, which learns multimodal features through numeric, visual, and textual perspectives. The three branches drive for a multimodal perspective of urban traffic signal learning in the frequency domain, while the frequency learning strategies delicately refine the information for extraction. Specifically, we first conduct the visual augmentation for the traffic signals, which transforms the original modality into frequency images and periodicity images for visual learning. Also, we augment descriptive texts for the traffic signals based on the specific topic, background information and item description for textual learning. To complement the numeric information, we utilize frequency multilayer perceptrons for learning on the original modality. We design a hierarchical contrastive learning on the three branches to fuse the spectrum of three modalities. Finally, extensive experiments on six real-world datasets demonstrate superior performance compared with the state-of-the-art approaches.

</details>


### [160] [ProgRAG: Hallucination-Resistant Progressive Retrieval and Reasoning over Knowledge Graphs](https://arxiv.org/abs/2511.10240)
*Minbae Park,Hyemin Yang,Jeonghyun Kim,Kunsoo Park,Hyunjoon Kim*

Main category: cs.AI

TL;DR: 大型语言模型（LLMs）虽然推理能力强，但存在幻觉和透明度低的问题。知识图谱（KGs）增强的大型语言模型（LLMs）可以提高推理性能，但仍面临检索不准确和推理失败的挑战，尤其是在长输入和上下文构建方面。为了解决这些问题，我们提出了 ProgRAG，一个多跳知识图谱问答（KGQA）框架，它将复杂问题分解为子问题，并通过回答每个子问题来逐步扩展部分推理路径。该框架通过不确定性感知剪枝来优化LLM推理的上下文，并在三个知名数据集上进行了实验，结果表明 ProgRAG 在多跳 KGQA 方面优于现有基线，提高了可靠性和推理质量。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）虽然推理能力强，但存在幻觉和透明度低的问题。知识图谱（KGs）增强的大型语言模型（LLMs）可以提高推理性能，但仍面临检索不准确和推理失败的挑战，尤其是在长输入和上下文构建方面。

Method: ProgRAG框架将复杂问题分解为子问题，并逐步扩展部分推理路径。在每一步，外部检索器收集候选证据，然后由LLM通过不确定性感知剪枝进行优化。最后，通过组织和重新排列从子问题答案中获得的推理路径来优化LLM推理的上下文。

Result: 在三个知名数据集上的实验表明，ProgRAG 在多跳 KGQA 方面优于现有基线，提高了可靠性和推理质量。

Conclusion: ProgRAG框架通过将复杂问题分解为子问题、逐步扩展推理路径、利用外部检索器和LLM进行证据优化，以及重组上下文，有效解决了现有KG增强LLM在检索和推理方面的问题，提高了多跳KGQA的性能和可靠性。

Abstract: Large Language Models (LLMs) demonstrate strong reasoning capabilities but struggle with hallucinations and limited transparency. Recently, KG-enhanced LLMs that integrate knowledge graphs (KGs) have been shown to improve reasoning performance, particularly for complex, knowledge-intensive tasks. However, these methods still face significant challenges, including inaccurate retrieval and reasoning failures, often exacerbated by long input contexts that obscure relevant information or by context constructions that struggle to capture the richer logical directions required by different question types. Furthermore, many of these approaches rely on LLMs to directly retrieve evidence from KGs, and to self-assess the sufficiency of this evidence, which often results in premature or incorrect reasoning. To address the retrieval and reasoning failures, we propose ProgRAG, a multi-hop knowledge graph question answering (KGQA) framework that decomposes complex questions into sub-questions, and progressively extends partial reasoning paths by answering each sub-question. At each step, external retrievers gather candidate evidence, which is then refined through uncertainty-aware pruning by the LLM. Finally, the context for LLM reasoning is optimized by organizing and rearranging the partial reasoning paths obtained from the sub-question answers. Experiments on three well-known datasets demonstrate that ProgRAG outperforms existing baselines in multi-hop KGQA, offering improved reliability and reasoning quality.

</details>


### [161] [PepTriX: A Framework for Explainable Peptide Analysis through Protein Language Models](https://arxiv.org/abs/2511.10244)
*Vincent Schilling,Akshat Dubey,Georges Hattab*

Main category: cs.AI

TL;DR: PepTriX是一个结合一维序列和三维结构特征的新框架，通过图注意力网络、对比学习和跨模态共注意力进行训练，能适应不同数据集，提供可解释的见解，并在多种肽分类任务中表现出色。


<details>
  <summary>Details</summary>
Motivation: 传统肽分类方法依赖手工编码，泛化性受限；现有的蛋白质语言模型（PLMs）计算成本高且缺乏可解释性，限制了模型预测与生物相关基序和结构性质的联系。

Method: PepTriX整合一维序列嵌入和三维结构特征，利用图注意力网络（GAT），并结合对比学习和跨模态共注意力机制进行训练。

Result: PepTriX在多种肽分类任务中表现出色，并能提供可解释的见解，揭示驱动预测的结构和生物物理基序。

Conclusion: PepTriX提供预测鲁棒性和可解释性验证，弥合了性能驱动的肽级模型（PLMs）与肽研究中的领域级理解之间的差距。

Abstract: Peptide classification tasks, such as predicting toxicity and HIV inhibition, are fundamental to bioinformatics and drug discovery. Traditional approaches rely heavily on handcrafted encodings of one-dimensional (1D) peptide sequences, which can limit generalizability across tasks and datasets. Recently, protein language models (PLMs), such as ESM-2 and ESMFold, have demonstrated strong predictive performance. However, they face two critical challenges. First, fine-tuning is computationally costly. Second, their complex latent representations hinder interpretability for domain experts. Additionally, many frameworks have been developed for specific types of peptide classification, lacking generalization. These limitations restrict the ability to connect model predictions to biologically relevant motifs and structural properties. To address these limitations, we present PepTriX, a novel framework that integrates one dimensional (1D) sequence embeddings and three-dimensional (3D) structural features via a graph attention network enhanced with contrastive training and cross-modal co-attention. PepTriX automatically adapts to diverse datasets, producing task-specific peptide vectors while retaining biological plausibility. After evaluation by domain experts, we found that PepTriX performs remarkably well across multiple peptide classification tasks and provides interpretable insights into the structural and biophysical motifs that drive predictions. Thus, PepTriX offers both predictive robustness and interpretable validation, bridging the gap between performance-driven peptide-level models (PLMs) and domain-level understanding in peptide research.

</details>


### [162] [Beyond Single-Step Updates: Reinforcement Learning of Heuristics with Limited-Horizon Search](https://arxiv.org/abs/2511.10264)
*Gal Hadar,Forest Agostinelli,Shahaf S. Shperberg*

Main category: cs.AI

TL;DR: 基于深度强化学习的启发式搜索方法，通过引入有限视距搜索和基于搜索边界的启发式更新，来提升启发式函数的学习效果。


<details>
  <summary>Details</summary>
Motivation: 传统的基于单步贝尔曼更新的启发式学习方法在收敛速度和启发式质量上存在不足，需要更有效的更新机制。

Method: 提出了一种广义方法，通过进行有限视距搜索，并根据状态到搜索边界的最短路径（包含边成本和边界状态的启发式值）来更新每个状态的启发式值，从而改进状态采样和启发式更新。

Result: 该方法通过在有限视距内搜索并基于搜索边界进行启发式更新，能够更有效地学习启发式函数，从而提高启发式搜索的性能。

Conclusion: 所提出的广义方法通过改进状态采样和启发式更新机制，能够有效地学习启发式函数，为解决序列决策问题提供了一种更优的启发式搜索方法。

Abstract: Many sequential decision-making problems can be formulated as shortest-path problems, where the objective is to reach a goal state from a given starting state. Heuristic search is a standard approach for solving such problems, relying on a heuristic function to estimate the cost to the goal from any given state. Recent approaches leverage reinforcement learning to learn heuristics by applying deep approximate value iteration. These methods typically rely on single-step Bellman updates, where the heuristic of a state is updated based on its best neighbor and the corresponding edge cost. This work proposes a generalized approach that enhances both state sampling and heuristic updates by performing limited-horizon searches and updating each state's heuristic based on the shortest path to the search frontier, incorporating both edge costs and the heuristic values of frontier states.

</details>


### [163] [Temporal Properties of Conditional Independence in Dynamic Bayesian Networks](https://arxiv.org/abs/2511.10266)
*Rajab Aghamov,Christel Baier,Joel Ouaknine,Jakob Piribauer,Mihir Vahanwala,Isa Vialard*

Main category: cs.AI

TL;DR: 该论文研究了动态贝叶斯网络（DBNs）中条件独立性（CI）命题演化与时序逻辑规范的符合性验证问题。论文区分了随机CI属性（考虑概率分布）和结构CI属性（仅考虑图结构）。


<details>
  <summary>Details</summary>
Motivation: 验证动态贝叶斯网络（DBNs）中条件独立性（CI）命题的演化是否符合时序逻辑规范。

Method: 区分了随机CI属性和结构CI属性。对于随机CI属性，研究其与时序逻辑规范（LTL和NBAs）的符合性，并将其与数论中的Skolem问题联系起来。对于结构CI属性，研究其与LTL和NBAs规范的符合性，并分析其计算复杂度，同时探讨了简化DBN图结构以提高可处理性的方法。

Result: 证明了决定随机CI命题是否最终成立的难题至少与数论中长期存在的开放问题Skolem问题一样难。证明了验证结构CI命题的演化是否符合LTL和NBA规范的复杂度属于PSPACE，并且是NP-难和coNP-难。同时，也找到了一些能够简化结构CI属性验证的自然限制。

Conclusion: 验证DBNs中的CI属性演化是一个复杂的计算问题，特别是对于随机CI属性。对于结构CI属性，虽然在一般情况下复杂度较高，但通过对DBN图结构施加自然限制，可以实现有效验证。

Abstract: Dynamic Bayesian networks (DBNs) are compact graphical representations used to model probabilistic systems where interdependent random variables and their distributions evolve over time. In this paper, we study the verification of the evolution of conditional-independence (CI) propositions against temporal logic specifications. To this end, we consider two specification formalisms over CI propositions: linear temporal logic (LTL), and non-deterministic Büchi automata (NBAs). This problem has two variants. Stochastic CI properties take the given concrete probability distributions into account, while structural CI properties are viewed purely in terms of the graphical structure of the DBN. We show that deciding if a stochastic CI proposition eventually holds is at least as hard as the Skolem problem for linear recurrence sequences, a long-standing open problem in number theory. On the other hand, we show that verifying the evolution of structural CI propositions against LTL and NBA specifications is in PSPACE, and is NP- and coNP-hard. We also identify natural restrictions on the graphical structure of DBNs that make the verification of structural CI properties tractable.

</details>


### [164] [Causal-HalBench: Uncovering LVLMs Object Hallucinations Through Causal Intervention](https://arxiv.org/abs/2511.10268)
*Zhe Xu,Zhicai Wang,Junkang Wu,Jinda Lu,Xiang Wang*

Main category: cs.AI

TL;DR: LVLMs存在目标物体幻觉问题，主要是由于训练时目标物体共现导致的伪相关性。本研究引入因果分析，提出Causal-HalBench基准测试和样本生成流程，用于量化和评估LVLMs的伪相关性鲁棒性，并验证了主流LVLMs存在此问题。


<details>
  <summary>Details</summary>
Motivation: 当前的大型视觉语言模型（LVLMs）在物体识别中存在目标物体幻觉问题，即错误地判断图像中是否存在某些物体。这主要是由于模型在训练过程中，将经常一起出现的物体之间产生了强烈的关联，即伪相关性，从而导致模型在视觉内容的干扰下产生幻觉。现有的基准测试主要关注幻觉检测，但缺乏对LVLMs中伪相关性的正式表征和量化评估。

Method: 本研究将因果分析引入LVLMs的目标识别场景，建立了结构因果模型（SCM）。利用因果语言，形式化定义了由共现偏差引起的伪相关性。为了量化这些伪相关性造成的影响，研究者开发了Causal-HalBench基准测试，该测试包含反事实样本，并集成了全面的因果度量，用于评估模型对抗伪相关性的鲁棒性。同时，研究者还提出一个可扩展的流程，利用专有的LVLMs和文本到图像（T2I）模型来生成反事实样本。

Result: 在主流LVLMs上的评估表明，这些模型在不同程度上都表现出对伪相关性的敏感性。

Conclusion: 大型视觉语言模型（LVLMs）容易受到伪相关性的影响，导致目标物体幻觉。本研究提出的Causal-HalBench基准测试和因果分析方法，能够有效地量化和评估这种影响，并为改进模型的鲁棒性提供了方向。

Abstract: Large Vision-Language Models (LVLMs) often suffer from object hallucination, making erroneous judgments about the presence of objects in images. We propose this primar- ily stems from spurious correlations arising when models strongly associate highly co-occurring objects during train- ing, leading to hallucinated objects influenced by visual con- text. Current benchmarks mainly focus on hallucination de- tection but lack a formal characterization and quantitative evaluation of spurious correlations in LVLMs. To address this, we introduce causal analysis into the object recognition scenario of LVLMs, establishing a Structural Causal Model (SCM). Utilizing the language of causality, we formally de- fine spurious correlations arising from co-occurrence bias. To quantify the influence induced by these spurious correla- tions, we develop Causal-HalBench, a benchmark specifically constructed with counterfactual samples and integrated with comprehensive causal metrics designed to assess model ro- bustness against spurious correlations. Concurrently, we pro- pose an extensible pipeline for the construction of these coun- terfactual samples, leveraging the capabilities of proprietary LVLMs and Text-to-Image (T2I) models for their genera- tion. Our evaluations on mainstream LVLMs using Causal- HalBench demonstrate these models exhibit susceptibility to spurious correlations, albeit to varying extents.

</details>


### [165] [Bidirectional Bounded-Suboptimal Heuristic Search with Consistent Heuristics](https://arxiv.org/abs/2511.10272)
*Shahaf S. Shperberg,Natalie Morad,Lior Siag,Ariel Felner,Dor Atzmon*

Main category: cs.AI

TL;DR: 本文关注有界次优双向搜索，并提出BAE*的变体，实验表明不同算法在不同条件下表现各异。


<details>
  <summary>Details</summary>
Motivation: 现有双向启发式搜索研究主要集中于最优搜索，而本文旨在探索有界次优双向搜索。

Method: 在现有最优双向搜索算法BAE*的基础上，提出适用于有界次优搜索的几种变体算法。

Result: 通过实验评估，比较了新变体算法与其他有界次优双向算法以及标准加权A*算法的性能。结果显示，各算法在不同条件下各有优劣。

Conclusion: 每种算法在特定条件下都有其优势，突显了各自的强项和弱项。

Abstract: Recent advancements in bidirectional heuristic search have yielded significant theoretical insights and novel algorithms. While most previous work has concentrated on optimal search methods, this paper focuses on bounded-suboptimal bidirectional search, where a bound on the suboptimality of the solution cost is specified. We build upon the state-of-the-art optimal bidirectional search algorithm, BAE*, designed for consistent heuristics, and introduce several variants of BAE* specifically tailored for the bounded-suboptimal context. Through experimental evaluation, we compare the performance of these new variants against other bounded-suboptimal bidirectional algorithms as well as the standard weighted A* algorithm. Our results demonstrate that each algorithm excels under distinct conditions, highlighting the strengths and weaknesses of each approach.

</details>


### [166] [Fixed-Persona SLMs with Modular Memory: Scalable NPC Dialogue on Consumer Hardware](https://arxiv.org/abs/2511.10277)
*Martin Braas,Lukas Esterle*

Main category: cs.AI

TL;DR: LLM在游戏NPC对话中应用受限，提出基于SLM的模块化对话系统，通过可替换记忆模块实现个性化和长时记忆，能在消费级硬件上运行，并有广泛应用前景。


<details>
  <summary>Details</summary>
Motivation: LLM在游戏NPC对话中应用受限，主要是因为硬件需求、延迟和知识边界问题。

Method: 提出一个模块化的NPC对话系统，利用经过微调以编码特定NPC个性的SLM，并集成可运行时替换的记忆模块，以保留角色特定的对话上下文和世界知识。

Result: 在消费级硬件上使用DistilGPT-2、TinyLlama-1.1B-Chat和Mistral-7B-Instruct三个开源SLM进行了全面评估。

Conclusion: 该系统通过模块化设计和以角色为驱动的记忆架构，实现了在游戏NPC对话中的表达性、可扩展性和记忆丰富性，并有潜力应用于虚拟助手、客户支持机器人或交互式教育系统等领域。

Abstract: Large Language Models (LLMs) have demonstrated remarkable capabilities in generating human-like text, yet their applicability to dialogue systems in computer games remains limited. This limitation arises from their substantial hardware requirements, latency constraints, and the necessity to maintain clearly defined knowledge boundaries within a game setting. In this paper, we propose a modular NPC dialogue system that leverages Small Language Models (SLMs), fine-tuned to encode specific NPC personas and integrated with runtime-swappable memory modules. These memory modules preserve character-specific conversational context and world knowledge, enabling expressive interactions and long-term memory without retraining or model reloading during gameplay. We comprehensively evaluate our system using three open-source SLMs: DistilGPT-2, TinyLlama-1.1B-Chat, and Mistral-7B-Instruct, trained on synthetic persona-aligned data and benchmarked on consumer-grade hardware. While our approach is motivated by applications in gaming, its modular design and persona-driven memory architecture hold significant potential for broader adoption in domains requiring expressive, scalable, and memory-rich conversational agents, such as virtual assistants, customer support bots, or interactive educational systems.

</details>


### [167] [FactGuard: Event-Centric and Commonsense-Guided Fake News Detection](https://arxiv.org/abs/2511.10281)
*Jing He,Han Zhang,Yuanhui Xiao,Wei Guo,Shaowen Yao,Renyang Liu*

Main category: cs.AI

TL;DR: FactGuard是一个利用大型语言模型（LLMs）进行虚假新闻检测的框架，通过提取事件中心内容来降低写作风格的影响，并引入动态可用性机制来提高决策的可靠性。通过知识蒸馏得到的FactGuard-D版本，能在资源受限的情况下有效运行，并在实验中表现出优于现有方法的鲁棒性和准确性。


<details>
  <summary>Details</summary>
Motivation: 随着对手模仿真实新闻的写作风格，基于写作风格的虚假新闻检测方法效果逐渐减弱。需要新的方法来解决这个问题，同时要考虑如何有效利用大型语言模型（LLMs）的潜力，解决它们在功能探索、可用性和推理成本方面存在的问题。

Method: 提出FactGuard框架，利用LLMs提取事件中心内容，减少写作风格的影响。引入动态可用性机制，识别事实推理中的矛盾和模糊情况，并自适应地整合LLM的建议。通过知识蒸馏得到FactGuard-D，以实现高效和冷启动的部署。

Result: 在两个基准数据集上的综合实验表明，FactGuard框架在鲁棒性和准确性方面持续优于现有方法，有效解决了虚假新闻检测中的风格敏感性和LLM可用性挑战。

Conclusion: FactGuard框架通过利用LLMs提取事件中心内容和动态可用性机制，成功解决了虚假新闻检测中的风格模仿和LLM应用难题，并在效率和性能上都取得了显著的改进。

Abstract: Fake news detection methods based on writing style have achieved remarkable progress. However, as adversaries increasingly imitate the style of authentic news, the effectiveness of such approaches is gradually diminishing. Recent research has explored incorporating large language models (LLMs) to enhance fake news detection. Yet, despite their transformative potential, LLMs remain an untapped goldmine for fake news detection, with their real-world adoption hampered by shallow functionality exploration, ambiguous usability, and prohibitive inference costs. In this paper, we propose a novel fake news detection framework, dubbed FactGuard, that leverages LLMs to extract event-centric content, thereby reducing the impact of writing style on detection performance. Furthermore, our approach introduces a dynamic usability mechanism that identifies contradictions and ambiguous cases in factual reasoning, adaptively incorporating LLM advice to improve decision reliability. To ensure efficiency and practical deployment, we employ knowledge distillation to derive FactGuard-D, enabling the framework to operate effectively in cold-start and resource-constrained scenarios. Comprehensive experiments on two benchmark datasets demonstrate that our approach consistently outperforms existing methods in both robustness and accuracy, effectively addressing the challenges of style sensitivity and LLM usability in fake news detection.

</details>


### [168] [Beyond Verification: Abductive Explanations for Post-AI Assessment of Privacy Leakage](https://arxiv.org/abs/2511.10284)
*Belona Sonna,Alban Grastien,Claire Benn*

Main category: cs.AI

TL;DR: 利用溯因解释审计AI决策过程中的隐私泄露，识别模型决策的最小充分证据，并判断是否泄露敏感信息，提供严格的隐私保证和可解释性。


<details>
  <summary>Details</summary>
Motivation: AI决策过程中隐私泄露的风险，特别是敏感信息的推断，需要审计工具。

Method: 提出一个正式框架，使用溯因解释来审计隐私泄露，该框架形式化了个人和系统级别的泄露，并引入了潜在适用解释（PAE）的概念。

Result: 在德国信用数据集上的实验评估表明，敏感字面在模型决策过程中的重要性会影响隐私泄露。结果证明溯因推理能够实现可解释的隐私审计。

Conclusion: 溯因推理提供了一种在AI决策中协调透明度、模型可解释性和隐私保护的实用方法，尽管存在计算挑战和简化假设。

Abstract: Privacy leakage in AI-based decision processes poses significant risks, particularly when sensitive information can be inferred. We propose a formal framework to audit privacy leakage using abductive explanations, which identifies minimal sufficient evidence justifying model decisions and determines whether sensitive information disclosed. Our framework formalizes both individual and system-level leakage, introducing the notion of Potentially Applicable Explanations (PAE) to identify individuals whose outcomes can shield those with sensitive features. This approach provides rigorous privacy guarantees while producing human understandable explanations, a key requirement for auditing tools. Experimental evaluation on the German Credit Dataset illustrates how the importance of sensitive literal in the model decision process affects privacy leakage. Despite computational challenges and simplifying assumptions, our results demonstrate that abductive reasoning enables interpretable privacy auditing, offering a practical pathway to reconcile transparency, model interpretability, and privacy preserving in AI decision-making.

</details>


### [169] [SITA: A Framework for Structure-to-Instance Theorem Autoformalization](https://arxiv.org/abs/2511.10356)
*Chenyi Li,Wanli Ma,Zichen Wang,Zaiwen Wen*

Main category: cs.AI

TL;DR: 该研究提出了一种名为SITA的框架，用于自动将抽象数学结构形式化为具体的数学定理，并使用Lean证明助手进行验证。


<details>
  <summary>Details</summary>
Motivation: 现有的大型语言模型在数学推理方面仍面临挑战，尤其是在将抽象结构形式化为具体定理方面。本研究旨在解决这一问题，实现研究级别的数学结果的自动形式化。

Method: SITA框架将形式化的抽象结构视为模块化模板，包含定义、假设、操作和定理。给定具体的实例化，框架会自动生成Lean定义和实例声明，并利用Lean的typeclass机制进行集成，最终通过检查结构假设来构建已验证的定理。该方法结合了基于LLM的生成和反馈引导的优化。

Result: 在优化问题的实验数据集上，SITA被证明能够有效地形式化基于抽象结构的各种具体实例化。

Conclusion: SITA框架能够成功地自动将抽象数学结构形式化为具体的、经过验证的数学定理，在解决数学推理和形式化挑战方面取得了进展。

Abstract: While large language models (LLMs) have shown progress in mathematical reasoning, they still face challenges in formalizing theorems that arise from instantiating abstract structures in concrete settings. With the goal of auto-formalizing mathematical results at the research level, we develop a framework for structure-to-instance theorem autoformalization (SITA), which systematically bridges the gap between abstract mathematical theories and their concrete applications in Lean proof assistant. Formalized abstract structures are treated as modular templates that contain definitions, assumptions, operations, and theorems. These templates serve as reusable guides for the formalization of concrete instances. Given a specific instantiation, we generate corresponding Lean definitions and instance declarations, integrate them using Lean's typeclass mechanism, and construct verified theorems by checking structural assumptions. We incorporate LLM-based generation with feedback-guided refinement to ensure both automation and formal correctness. Experiments on a dataset of optimization problems demonstrate that SITA effectively formalizes diverse instances grounded in abstract structures.

</details>


### [170] [Explaining Decentralized Multi-Agent Reinforcement Learning Policies](https://arxiv.org/abs/2511.10409)
*Kayla Boggess,Sarit Kraus,Lu Feng*

Main category: cs.AI

TL;DR: 本研究提出了一种用于去中心化多智能体强化学习(MARL)的策略摘要和查询式解释方法，以解决现有方法在去中心化环境中的局限性，并提升用户对智能体行为的理解。


<details>
  <summary>Details</summary>
Motivation: 现有MARL解释方法主要集中于中心化设置，无法有效处理去中心化环境中的不确定性和非决定性问题。本研究旨在弥补这一空白，提供一种适用于去中心化MARL的解释方法。

Method: 提出生成策略摘要的方法来捕捉任务顺序和智能体协作，并结合查询式解释（何时、为何不、是什么）来回答用户关于特定智能体行为的问题。

Result: 在四个MARL领域和两种去中心化MARL算法上进行了评估，证明了方法的通用性和计算效率。用户研究表明，所提出的摘要和解释显著提高了用户问答性能，并提升了理解和满意度等主观评分。

Conclusion: 所提出的策略摘要和查询式解释方法能有效提升用户对去中心化MARL智能体行为的理解和满意度，并且具有良好的通用性和效率。

Abstract: Multi-Agent Reinforcement Learning (MARL) has gained significant interest in recent years, enabling sequential decision-making across multiple agents in various domains. However, most existing explanation methods focus on centralized MARL, failing to address the uncertainty and nondeterminism inherent in decentralized settings. We propose methods to generate policy summarizations that capture task ordering and agent cooperation in decentralized MARL policies, along with query-based explanations for When, Why Not, and What types of user queries about specific agent behaviors. We evaluate our approach across four MARL domains and two decentralized MARL algorithms, demonstrating its generalizability and computational efficiency. User studies show that our summarizations and explanations significantly improve user question-answering performance and enhance subjective ratings on metrics such as understanding and satisfaction.

</details>


### [171] [Generalizing Analogical Inference from Boolean to Continuous Domains](https://arxiv.org/abs/2511.10416)
*Francisco Cunha,Yves Lepage,Zied Bouraoui,Miguel Couceiro*

Main category: cs.AI

TL;DR: 现有类比推理框架在布尔域上的理论不适用于回归任务或连续域，本文提出了一个统一的框架，该框架基于参数化类比，通过广义均值定义，并扩展到实值域，可以同时处理布尔分类和回归问题，并为类比保持函数提供了理论保证。


<details>
  <summary>Details</summary>
Motivation: 现有用于类比推理的正式框架主要集中在布尔域，并且这些框架在延伸到回归任务或连续域时存在局限性。这促使研究人员需要一个更通用的框架来处理更广泛的推理任务。

Method: 本文首先通过一个反例展示了现有方法在布尔域上的局限性，然后提出了一个基于参数化类比和广义均值的新框架，该框架适用于实值域，并可以处理分类和回归任务。最后，对类比保持函数进行了刻画，并推导了误差界。

Result: 研究结果表明，新提出的统一框架能够同时处理布尔分类和回归任务，并且在平滑性假设下，可以为类比保持函数推导出最坏情况和平均情况下的误差界。

Conclusion: 本文提出的统一框架为离散和连续域中的类比推理提供了一个更广泛的理论基础，弥补了现有方法的不足，并为设计更强大的类比推理系统奠定了基础。

Abstract: Analogical reasoning is a powerful inductive mechanism, widely used in human cognition and increasingly applied in artificial intelligence. Formal frameworks for analogical inference have been developed for Boolean domains, where inference is provably sound for affine functions and approximately correct for functions close to affine. These results have informed the design of analogy-based classifiers. However, they do not extend to regression tasks or continuous domains. In this paper, we revisit analogical inference from a foundational perspective. We first present a counterexample showing that existing generalization bounds fail even in the Boolean setting. We then introduce a unified framework for analogical reasoning in real-valued domains based on parameterized analogies defined via generalized means. This model subsumes both Boolean classification and regression, and supports analogical inference over continuous functions. We characterize the class of analogy-preserving functions in this setting and derive both worst-case and average-case error bounds under smoothness assumptions. Our results offer a general theory of analogical inference across discrete and continuous domains.

</details>


### [172] [Using Certifying Constraint Solvers for Generating Step-wise Explanations](https://arxiv.org/abs/2511.10428)
*Ignace Bleukx,Maarten Flippo,Bart Bogaerts,Emir Demirović,Tias Guns*

Main category: cs.AI

TL;DR: 该研究提出一种利用约束求解器生成的证明来加速分步解释的生成，同时保持解释质量。


<details>
  <summary>Details</summary>
Motivation: 现有的分步解释方法计算成本高，限制了其应用范围。

Method: 提出一个抽象证明框架，并开发了从证明生成分步解释的转换方法，包括修剪和简化技术。

Result: 实验证明该方法能显著加速分步解释的生成，且解释质量与现有技术相当。

Conclusion: 利用约束求解器生成的证明作为起点，可以更有效地生成分步解释。

Abstract: In the field of Explainable Constraint Solving, it is common to explain to a user why a problem is unsatisfiable. A recently proposed method for this is to compute a sequence of explanation steps. Such a step-wise explanation shows individual reasoning steps involving constraints from the original specification, that in the end explain a conflict. However, computing a step-wise explanation is computationally expensive, limiting the scope of problems for which it can be used. We investigate how we can use proofs generated by a constraint solver as a starting point for computing step-wise explanations, instead of computing them step-by-step. More specifically, we define a framework of abstract proofs, in which both proofs and step-wise explanations can be represented. We then propose several methods for converting a proof to a step-wise explanation sequence, with special attention to trimming and simplification techniques to keep the sequence and its individual steps small. Our results show our method significantly speeds up the generation of step-wise explanation sequences, while the resulting step-wise explanation has a quality similar to the current state-of-the-art.

</details>


### [173] [Preference Elicitation for Step-Wise Explanations in Logic Puzzles](https://arxiv.org/abs/2511.10436)
*Marco Foschini,Marianne Defresne,Emilio Gamba,Bart Bogaerts,Tias Guns*

Main category: cs.AI

TL;DR: 通过学习用户偏好来优化逻辑谜题的分步解释，提出了一种名为 MACHOP 的新查询生成策略。


<details>
  <summary>Details</summary>
Motivation: 现有的分步解释方法需要用户定义的客观函数来量化解释质量，但定义这样的函数很困难。机器学习中的交互式偏好获取方法可以从成对比较中学习用户偏好，因此可以用来解决这个问题。

Method: 提出两种动态归一化技术来处理不同尺度的子目标，并提出了一种名为 MACHOP 的新查询生成策略，该策略结合了非支配约束和基于置信上界的多元化方法。

Result: 在数独和逻辑网格谜题上使用人工用户和真实用户评估了该方法，结果表明 MACHOP 产生的解释质量优于标准方法。

Conclusion: 交互式偏好获取方法是可行的，并且提出的 MACHOP 策略可以有效地提高逻辑谜题分步解释的质量。

Abstract: Step-wise explanations can explain logic puzzles and other satisfaction problems by showing how to derive decisions step by step. Each step consists of a set of constraints that derive an assignment to one or more decision variables. However, many candidate explanation steps exist, with different sets of constraints and different decisions they derive. To identify the most comprehensible one, a user-defined objective function is required to quantify the quality of each step. However, defining a good objective function is challenging. Here, interactive preference elicitation methods from the wider machine learning community can offer a way to learn user preferences from pairwise comparisons. We investigate the feasibility of this approach for step-wise explanations and address several limitations that distinguish it from elicitation for standard combinatorial problems. First, because the explanation quality is measured using multiple sub-objectives that can vary a lot in scale, we propose two dynamic normalization techniques to rescale these features and stabilize the learning process. We also observed that many generated comparisons involve similar explanations. For this reason, we introduce MACHOP (Multi-Armed CHOice Perceptron), a novel query generation strategy that integrates non-domination constraints with upper confidence bound-based diversification. We evaluate the elicitation techniques on Sudokus and Logic-Grid puzzles using artificial users, and validate them with a real-user evaluation. In both settings, MACHOP consistently produces higher-quality explanations than the standard approach.

</details>


### [174] [Non-Monotonic S4F Standpoint Logic](https://arxiv.org/abs/2511.10449)
*Piotr Gorczyca,Hannes Strass*

Main category: cs.AI

TL;DR: 本文提出了S4F视角逻辑，一个统一的模态逻辑框架，用于表示多视角和非单调语义承诺，计算复杂度不高于其组成部分。


<details>
  <summary>Details</summary>
Motivation: 将多视角表示（视角逻辑）与非单调推理（S4F模态逻辑）相结合，以处理多视角下的非单调语义承诺。

Method: 定义了S4F视角逻辑的句法和语义，并分析了其计算复杂度。

Result: S4F视角逻辑的计算复杂度不高于其组成部分（S4F和视角命题逻辑），无论是在单调还是非单调形式下。

Conclusion: S4F视角逻辑成功地统一了多视角表示和非单调推理，提供了一种表达多视角非单调语义承诺的有效方法，并且计算效率高。

Abstract: Standpoint logics offer unified modal logic-based formalisms for representing multiple heterogeneous viewpoints. At the same time, many non-monotonic reasoning frameworks can be naturally captured using modal logics, in particular using the modal logic S4F. In this work, we propose a novel formalism called S4F Standpoint Logic, which generalises both S4F and standpoint propositional logic and is therefore capable of expressing multi-viewpoint, non-monotonic semantic commitments. We define its syntax and semantics and analyze its computational complexity, obtaining the result that S4F Standpoint Logic is not computationally harder than its constituent logics, whether in monotonic or non-monotonic form. We also outline mechanisms for credulous and sceptical acceptance and illustrate the framework with an example.

</details>


### [175] [Proceedings of The third international workshop on eXplainable AI for the Arts (XAIxArts)](https://arxiv.org/abs/2511.10482)
*Corey Ford,Elizabeth Wilson,Shuoyang Zheng,Gabriel Vigliensoni,Jeba Rezwana,Lanxi Xiao,Michael Clemens,Makayla Lewis,Drew Hemment,Alan Chamberlain,Helen Kennedy,Nick Bryan-Kinns*

Main category: cs.AI

TL;DR: XAIxArts研讨会汇集了人机交互、交互设计、人工智能、可解释人工智能（XAI）和数字艺术领域的研究人员，探讨XAI在艺术中的作用。


<details>
  <summary>Details</summary>
Motivation: 本次研讨会旨在促进在人机交互、交互设计、人工智能、可解释人工智能（XAI）和数字艺术领域的研究人员之间的交流，共同探索可解释人工智能（XAI）在艺术领域的应用潜力。

Method: 在第17届ACM创意与认知大会（C&C 2025）上举办，并提供线上参与选项。

Result: 成功汇集了来自不同领域的专家，就XAI在艺术中的应用展开了讨论。

Conclusion: XAIxArts研讨会是探索XAI在艺术领域作用的重要平台，促进了跨学科的交流与合作。

Abstract: This third international workshop on explainable AI for the Arts (XAIxArts) brought together a community of researchers in HCI, Interaction Design, AI, explainable AI (XAI), and digital arts to explore the role of XAI for the Arts. Workshop held at the 17th ACM Conference on Creativity and Cognition (C&C 2025), online.

</details>


### [176] [Strategic Opponent Modeling with Graph Neural Networks, Deep Reinforcement Learning and Probabilistic Topic Modeling](https://arxiv.org/abs/2511.10501)
*Georgios Chalkiadakis,Charilaos Akasiadis,Gerasimos Koresis,Stergios Plataniots,Leonidas Bakopoulos*

Main category: cs.AI

TL;DR: 本篇论文主要综述了图神经网络、深度强化学习和概率主题模型在战略多智能体环境中的应用潜力，并着重探讨了如何将这些机器学习方法与博弈论概念相结合，以克服现实场景中常见的假设（如共同先验假设和自身利益假设）的局限性。


<details>
  <summary>Details</summary>
Motivation: 本研究的动机在于探索将机器学习方法（特别是图神经网络、深度强化学习和概率主题模型）应用于战略多智能体环境，以解决现实世界中不确定性和异质性等挑战，并结合博弈论概念以提高模型的适应性和可靠性。

Method: 本文回顾了图神经网络（GNN）、多智能体深度强化学习（MADRL）以及概率主题模型（PTM）等方法。GNN被认为是处理多智能体关系和交互的有力工具，因其能够操作图结构数据。MADRL在多智能体学习方面进行了综述。PTM则因其估计未知潜在分布的能力，被认为有助于处理异质性和未知的智能体信念。此外，本文还考虑了博弈论中的解的概念，以及公平性和稳定性等性质。

Result: 本研究分析了所讨论的机器学习方法在处理不确定性、异质性以及可扩展性方面的能力。GNN在节点分类和链接预测等任务中表现出强大能力。PTM在处理异质性和未知智能体信念方面具有潜力。文中也提到了现有的博弈论解的概念。

Conclusion: 本篇论文总结了在战略多智能体环境中应用机器学习和博弈论所面临的开放性挑战，包括适应非平稳环境、平衡稳定与适应性、处理不确定性和异质性，以及保证可扩展性和解的可处理性。作者特别推荐了图神经网络（GNN）作为处理多智能体交互的有效方法。

Abstract: This paper provides a comprehensive review of mainly Graph Neural Networks, Deep Reinforcement Learning, and Probabilistic Topic Modeling methods with a focus on their potential incorporation in strategic multiagent settings. We draw interest in (i) Machine Learning methods currently utilized for uncovering unknown model structures adaptable to the task of strategic opponent modeling, and (ii) the integration of these methods with Game Theoretic concepts that avoid relying on assumptions often invalid in real-world scenarios, such as the Common Prior Assumption (CPA) and the Self-Interest Hypothesis (SIH). We analyze the ability to handle uncertainty and heterogeneity, two characteristics that are very common in real-world application cases, as well as scalability. As a potential answer to effectively modeling relationships and interactions in multiagent settings, we champion the use of Graph Neural Networks (GNN). Such approaches are designed to operate upon graph-structured data, and have been shown to be a very powerful tool for performing tasks such as node classification and link prediction. Next, we review the domain of Reinforcement Learning (RL), and in particular that of Multiagent Deep Reinforcement Learning (MADRL). Following, we describe existing relevant game theoretic solution concepts and consider properties such as fairness and stability. Our review comes complete with a note on the literature that utilizes PTM in domains other than that of document analysis and classification. The capability of PTM to estimate unknown underlying distributions can help with tackling heterogeneity and unknown agent beliefs. Finally, we identify certain open challenges specifically, the need to (i) fit non-stationary environments, (ii) balance the degrees of stability and adaptation, (iii) tackle uncertainty and heterogeneity, (iv) guarantee scalability and solution tractability.

</details>


### [177] [Rethinking Science in the Age of Artificial Intelligence](https://arxiv.org/abs/2511.10524)
*Maksim E. Eren,Dorianis M. Perez*

Main category: cs.AI

TL;DR: AI正在改变科研范式，从辅助工具变为科研伙伴，但需谨慎整合与监管，强调人类判断在同行评审、伦理评估和结果验证中的作用，并呼吁制定相关政策以促进AI在科研中的透明度、可重复性和问责制。


<details>
  <summary>Details</summary>
Motivation: AI正在改变科研工作流，从信息管理、假设生成到实验设计，AI正从单一的计算工具转变为积极的科研合作者。

Method: 本文探讨了AI在科研工作流中的应用，包括信息管理、文献筛选、跨学科联系、假设生成、实验设计与执行等方面。

Result: AI已成为科研的重要组成部分，能够辅助研究者处理信息、产生新想法并设计实验。

Conclusion: AI在科研中的应用是大势所趋，但必须谨慎整合，并以人类判断作为核心，尤其是在同行评审、伦理评估和结果验证等关键环节。同时，需要制定相应的政策来规范AI在科研中的应用，确保其透明度、可重复性和问责制。

Abstract: Artificial intelligence (AI) is reshaping how research is conceived, conducted, and communicated across fields from chemistry to biomedicine. This commentary examines how AI is transforming the research workflow. AI systems now help researchers manage the information deluge, filtering the literature, surfacing cross-disciplinary links for ideas and collaborations, generating hypotheses, and designing and executing experiments. These developments mark a shift from AI as a mere computational tool to AI as an active collaborator in science. Yet this transformation demands thoughtful integration and governance. We argue that at this time AI must augment but not replace human judgment in academic workflows such as peer review, ethical evaluation, and validation of results. This paper calls for the deliberate adoption of AI within the scientific practice through policies that promote transparency, reproducibility, and accountability.

</details>


### [178] [Bi-Level Contextual Bandits for Individualized Resource Allocation under Delayed Feedback](https://arxiv.org/abs/2511.10572)
*Mohammadsina Almasi,Hadis Anahideh*

Main category: cs.AI

TL;DR: 在教育、就业和医疗保健等高风险领域，公平地分配有限资源需要平衡短期效用与长期影响，同时考虑延迟结果、隐藏的异质性和道德约束。然而，大多数基于学习的分配框架要么假设即时反馈，要么忽略个体特征与干预动态之间的复杂相互作用。我们提出了一个新颖的 bi-level 上下文老虎机框架，用于在延迟反馈下进行个体化资源分配，旨在现实世界中具有动态人群、容量限制和时间敏感影响的场景中运行。在 meta 层面，该模型优化亚组层面的预算分配，以满足公平和运营限制。在基础层面，它使用在观察数据上训练的神经网络来识别每个组中最具响应能力的个体，同时尊重由资源特定的延迟核建模的冷却窗口和延迟治疗效果。通过显式建模时间动态和反馈延迟，该算法在有新数据到达时不断改进其策略，从而实现更具响应性和适应性的决策。我们在来自教育和劳动力发展的两个真实世界数据集上验证了我们的方法，表明它能够实现更高的累积结果，更好地适应延迟结构，并确保跨亚组的公平分配。我们的结果强调了延迟感知、数据驱动的决策系统在改善机构政策和社会福利方面的潜力。


<details>
  <summary>Details</summary>
Motivation: 在教育、就业和医疗保健等高风险领域，公平地分配有限资源需要平衡短期效用与长期影响，同时考虑延迟结果、隐藏的异质性和道德约束。然而，大多数基于学习的分配框架要么假设即时反馈，要么忽略个体特征与干预动态之间的复杂相互作用。

Method: 提出一个新颖的 bi-level 上下文老虎机框架，用于在延迟反馈下进行个体化资源分配。在 meta 层面，该模型优化亚组层面的预算分配，以满足公平和运营限制。在基础层面，它使用在观察数据上训练的神经网络来识别每个组中最具响应能力的个体，同时尊重由资源特定的延迟核建模的冷却窗口和延迟治疗效果。

Result: 在教育和劳动力发展的两个真实世界数据集上验证了该方法，表明其能实现更高的累积结果，更好地适应延迟结构，并确保跨亚组的公平分配。

Conclusion: 延迟感知、数据驱动的决策系统在改善机构政策和社会福利方面具有潜力。

Abstract: Equitably allocating limited resources in high-stakes domains-such as education, employment, and healthcare-requires balancing short-term utility with long-term impact, while accounting for delayed outcomes, hidden heterogeneity, and ethical constraints. However, most learning-based allocation frameworks either assume immediate feedback or ignore the complex interplay between individual characteristics and intervention dynamics. We propose a novel bi-level contextual bandit framework for individualized resource allocation under delayed feedback, designed to operate in real-world settings with dynamic populations, capacity constraints, and time-sensitive impact. At the meta level, the model optimizes subgroup-level budget allocations to satisfy fairness and operational constraints. At the base level, it identifies the most responsive individuals within each group using a neural network trained on observational data, while respecting cooldown windows and delayed treatment effects modeled via resource-specific delay kernels. By explicitly modeling temporal dynamics and feedback delays, the algorithm continually refines its policy as new data arrive, enabling more responsive and adaptive decision-making. We validate our approach on two real-world datasets from education and workforce development, showing that it achieves higher cumulative outcomes, better adapts to delay structures, and ensures equitable distribution across subgroups. Our results highlight the potential of delay-aware, data-driven decision-making systems to improve institutional policy and social welfare.

</details>


### [179] [Regular Games -- an Automata-Based General Game Playing Language](https://arxiv.org/abs/2511.10593)
*Radosław Miernik,Marek Szykuła,Jakub Kowalski,Jakub Cieśluk,Łukasz Galas,Wojciech Pawlik*

Main category: cs.AI

TL;DR: RG是一个通用的游戏（GGP）系统，旨在提高计算效率和便捷性，其核心是基于有限自动机的低级语言，适用于所有有限回合制且信息不完美的博弈，并能生成比现有技术更快的正向模型。


<details>
  <summary>Details</summary>
Motivation: RG的主要目标是同时实现高计算效率和便捷的游戏设计。

Method: RG系统包含多种语言，其中核心是使用有限自动机的低级语言，它结构简单，便于自动处理（如代理、分析、优化等），并且能够处理所有有限回合制且信息不完美的博弈。该系统还包括用于游戏设计的高级语言，这些语言最终会被翻译成低级语言。

Result: RG能够生成比当前最先进技术更快的正向模型，在效率方面优于其他GGP系统（如Regular Boardgames, Ludii）。

Conclusion: RG系统在效率和游戏设计便利性方面都取得了显著的进展，并且提供了一个包含编辑器、可视化工具、基准测试工具和调试器的完整生态系统。

Abstract: We propose a new General Game Playing (GGP) system called Regular Games (RG). The main goal of RG is to be both computationally efficient and convenient for game design. The system consists of several languages. The core component is a low-level language that defines the rules by a finite automaton. It is minimal with only a few mechanisms, which makes it easy for automatic processing (by agents, analysis, optimization, etc.). The language is universal for the class of all finite turn-based games with imperfect information. Higher-level languages are introduced for game design (by humans or Procedural Content Generation), which are eventually translated to a low-level language. RG generates faster forward models than the current state of the art, beating other GGP systems (Regular Boardgames, Ludii) in terms of efficiency. Additionally, RG's ecosystem includes an editor with LSP, automaton visualization, benchmarking tools, and a debugger of game description transformations.

</details>


### [180] [Querying Labeled Time Series Data with Scenario Programs](https://arxiv.org/abs/2511.10627)
*Edward Kim,Devan Shanker,Varun Bharadwaj,Hongbeen Park,Jinkyu Kim,Hazem Torfah,Daniel J Fremont,Sanjit A Seshia*

Main category: cs.AI

TL;DR: 模拟环境中的自动驾驶汽车（AV）故障场景可能无法在现实世界中复现，本研究提出了一种将模拟故障场景与真实世界数据集进行匹配的方法，以验证这些场景的有效性。


<details>
  <summary>Details</summary>
Motivation: 许多研究致力于在模拟环境中发现自动驾驶汽车（AV）的故障场景，但这些场景在真实世界中是否可复现仍然是一个悬而未决的问题。模拟与现实之间的数据差异可能导致在模拟中发现的故障场景仅仅是合成数据的伪影，而非真实存在的问题。

Method: 本研究提出了一种形式化方法，定义了如何将带标签的时间序列传感器数据与使用 Scenic 编程语言表示的抽象场景进行匹配。研究人员开发了一种查询算法，能够根据 Scenic 场景程序和带标签的数据集，筛选出与指定场景匹配的数据子集。

Result: 实验结果表明，所提出的查询算法在场景查询方面的准确性高于最先进的商业视觉大型语言模型，并且查询速度快了几个数量级。此外，该算法的性能可以随着查询时间序列数据的持续时间进行扩展。

Conclusion: 本研究通过将模拟故障场景与真实世界数据集进行匹配，为验证自动驾驶汽车（AV）模拟故障场景的有效性提供了一种可靠且高效的方法，解决了模拟到现实（sim-to-real）的差距问题。

Abstract: Simulation-based testing has become a crucial complement to road testing for ensuring the safety of cyber physical systems (CPS). As a result, significant research efforts have been directed toward identifying failure scenarios within simulation environments. However, a critical question remains. Are the AV failure scenarios discovered in simulation reproducible on actual systems in the real world? The sim-to-real gap caused by differences between simulated and real sensor data means that failure scenarios identified in simulation might either be artifacts of synthetic sensor data or actual issues that also occur with real sensor data. To address this, an effective approach to validating simulated failure scenarios is to locate occurrences of these scenarios within real-world datasets and verify whether the failure persists on the datasets. To this end, we introduce a formal definition of how labeled time series sensor data can match an abstract scenario, represented as a scenario program using the Scenic probabilistic programming language. We present a querying algorithm that, given a scenario program and a labeled dataset, identifies the subset of data that matches the specified scenario. Our experiment shows that our algorithm is more accurate and orders of magnitude faster in querying scenarios than the state-of-the-art commercial vision large language models, and can scale with the duration of queried time series data.

</details>


<div id='cs.DS'></div>

# cs.DS [[Back]](#toc)

### [181] [A Quasi-Polynomial Time Algorithm for 3-Coloring Circle Graphs](https://arxiv.org/abs/2511.09707)
*Ajaykrishnan E S,Robert Ganian,Daniel Lokshtanov,Vaishali Surianarayanan*

Main category: cs.DS

TL;DR: 为圆图设计了一个可以在 O(n^log n) 时间内找到 3-着色（如果存在）的算法。


<details>
  <summary>Details</summary>
Motivation: 解决 Dujmović 和 Wood、Eppstein、Bachmann、Rutter 和 Stumpf 提出的关于 3-着色圆图是否能在多项式时间内解决的著名公开问题。

Method: 设计了一个算法，该算法以一个 n 顶点的圆图 G 作为输入，运行时间为 O(n^log n)，并找出 G 的一个 proper 3-coloring（如果存在）。

Result: 得到了一个运行时间相同的算法，用于确定给定的有序图 (G, ≺) 是否具有 3-页书本嵌入。

Conclusion: 该算法为 3-着色圆图问题提供了一个部分解决方案，该问题是图论中的一个著名难题。

Abstract: A graph $G$ is a circle graph if it is an intersection graph of chords of a unit circle. We give an algorithm that takes as input an $n$ vertex circle graph $G$, runs in time at most $n^{O(\log n)}$ and finds a proper $3$-coloring of $G$, if one exists. As a consequence we obtain an algorithm with the same running time to determine whether a given ordered graph $(G, \prec)$ has a $3$-page book embedding. This gives a partial resolution to the well known open problem of Dujmović and Wood [Discret. Math. Theor. Comput. Sci. 2004], Eppstein [2014], and Bachmann, Rutter and Stumpf [J. Graph Algorithms Appl. 2024] of whether 3-Coloring on circle graphs admits a polynomial time algorithm.

</details>


### [182] [Hardness of Dynamic Tree Edit Distance and Friends](https://arxiv.org/abs/2511.09842)
*Bingbing Hu,Jakob Nogler,Barna Saha*

Main category: cs.DS

TL;DR: 动态字符串编辑距离有优化算法，但动态树编辑距离等相关问题没有。


<details>
  <summary>Details</summary>
Motivation: 探索动态字符串编辑距离、树编辑距离、Dyck编辑距离和RNA折叠等问题的动态算法复杂度。

Method: 通过证明树编辑距离、Dyck编辑距离和RNA折叠等问题在动态设置下无法获得比静态算法更快的速度，并在此基础上引入了基于k-Clique猜想的二次更新时间下界。

Result: 证明了树编辑距离、Dyck编辑距离和RNA折叠在动态设置下无法获得比静态算法更快的速度，并在此基础上证明了未加权树编辑距离的二次更新时间下界。

Conclusion: 动态树编辑距离、Dyck编辑距离和RNA折叠问题没有动态加速，并且未加权树编辑距离的更新时间至少是二次的。

Abstract: String Edit Distance is a more-than-classical problem whose behavior in the dynamic setting, where the strings are updated over time, is well understood. A single character substitution, insertion, or deletion can be handled in $\tilde{\mathcal{O}}(n \cdot \min(\sqrt{n},w))$ time [Charalampopoulos, Kociumaka, Mozes, CPM 2020], where $w$ is the maximum operation weight. This bound is optimal [Cassis, Kociumaka, Wellnitz, FOCS 2023] and provides a substantial improvement over the static $\mathcal{O}(n^2)$ algorithm when few characters of the input string are updated.
  In contrast, for inherently related problems such as Tree Edit Distance, Dyck Edit Distance, and RNA Folding, it has remained unknown whether it is possible to devise dynamic algorithms with an advantage over the static algorithm. In this paper, we resolve this question by showing that (weighted) Tree Edit Distance, Dyck Edit Distance, and RNA Folding admit no dynamic speedup: under well-known fine-grained assumptions we show that the best possible algorithm recomputes the solution from scratch after each update. Furthermore, we prove a quadratic per-update lower bound for unweighted Tree Edit Distance under the $k$-Clique Conjecture. This provides the first separation between dynamic unweighted String Edit Distance and unweighted Tree Edit Distance, problems whose relative difficulty in the static setting is still open.

</details>


### [183] [Faster All-Pairs Minimum Cut: Bypassing Exact Max-Flow](https://arxiv.org/abs/2511.10036)
*Yotam Kenneth-Mordoch,Robert Krauthgamer*

Main category: cs.DS

TL;DR: 该论文提出了一种新的图稀疏化方法，该方法可以保留图中所有的最小割，并且可以通过近似最大流计算来构建。利用这种稀疏化方法，论文为所有点对最小割问题（APMC）设计了在不同计算模型下的新算法，包括使用近似最大流计算的稀疏化方法，以及在割查询模型、全动态模型和流式模型下的新算法，这些算法在不同模型下都取得了比已知边界更好的结果。


<details>
  <summary>Details</summary>
Motivation: APMC（所有点对最小割）是一个基础图论问题，但目前已知的最快算法依赖于最大流计算，而对于某些计算模型（如割查询模型和全动态模型），尚未找到高效的最大流算法。

Method: 论文提出了一种新的图稀疏化方法，可以保留图中的所有最小割，并且能够使用近似最大流计算来构建。基于此稀疏化方法，论文在多种计算模型下设计了新的APMC算法：1. 在割查询模型下，使用$	ilde{O}(n^{3/2})$次割查询的随机化算法；2. 在全动态模型下，具有$n^{3/2+o(1)}$最坏情况更新时间的确定性算法；3. 空间复杂度为$	ilde{O}(n^{3/2})$的随机化两遍流式算法。

Result: 所提出的算法在不同计算模型下均优于现有算法，即使是针对单点对最小割问题也取得了改进。

Conclusion: 通过引入一种能够保留最小割的稀疏化方法，并结合近似最大流计算，论文成功地为APMC问题在割查询模型、全动态模型和流式模型下设计了更优的算法，从而推动了对该问题的研究进展。

Abstract: All-Pairs Minimum Cut (APMC) is a fundamental graph problem that asks to find a minimum $s,t$-cut for every pair of vertices $s,t$. A recent line of work on fast algorithms for APMC has culminated with a reduction of APMC to $\mathrm{polylog}(n)$-many max-flow computations. But unfortunately, no fast algorithms are currently known for exact max-flow in several standard models of computation, such as the cut-query model and the fully-dynamic model.
  Our main technical contribution is a sparsifier that preserves all minimum $s,t$-cuts in an unweighted graph, and can be constructed using only approximate max-flow computations. We then use this sparsifier to devise new algorithms for APMC in unweighted graphs in several computational models: (i) a randomized algorithm that makes $\tilde{O}(n^{3/2})$ cut queries to the input graph; (ii) a deterministic fully-dynamic algorithm with $n^{3/2+o(1)}$ worst-case update time; and (iii) a randomized two-pass streaming algorithm with space requirement $\tilde{O}(n^{3/2})$. These results improve over the known bounds, even for (single pair) minimum $s,t$-cut in the respective models.

</details>


### [184] [Algorithms and Complexity of Hedge Cluster Deletion Problems](https://arxiv.org/abs/2511.10202)
*Athanasios L. Konstantinidis,Charis Papadopoulos,Georgios Velissaris*

Main category: cs.DS

TL;DR: 这是一个关于“对齐簇删除”问题（Hedge Cluster Deletion）的研究，该问题是对经典簇删除问题的推广。研究表明，在特定图结构（包含有界大小的顶点不相交3-路径）下，该问题可以被有效解决。同时，研究揭示了该问题在近似求解方面的NP-hard性质，并与“最小Horn删除”问题（Min Horn Deletion）紧密相关。此外，研究还提出了在特定条件下（三角形被不超过两个对齐所覆盖，或对齐交图无环）的近似算法和精确算法的解决方案。


<details>
  <summary>Details</summary>
Motivation: 研究对齐簇删除问题（Hedge Cluster Deletion），这是簇删除问题的推广，旨在找到最小数量的对齐（hedges）以移除后使图成为派系（cliques）的不相交并集。研究动机在于探索该问题的计算复杂性、可近似性以及在特定图结构下的求解方法。

Method: 该研究采用了图论中的相关概念和算法。首先，通过分析图的结构特性（如顶点不相交3-路径的有界性），证明了在特定条件下问题可在多项式时间内解决。其次，通过将问题与最小Horn删除问题（Min Horn Deletion）联系起来，证明了其NP-hard的近似性质。最后，研究提出了针对特定图结构（三角形被不超过两个对齐覆盖，或对齐交图无环）的多项式时间算法，并引入了对齐交图（hedge intersection graph）的概念。

Result: 研究证明了在特定图结构下（包含有界大小的顶点不相交3-路径），对齐簇删除问题（Hedge Cluster Deletion）可以在多项式时间内解决。同时，证明了该问题近似求解的NP-hard性质，其近似难度与最小Horn删除问题（Min Horn Deletion）相关，近似因子为 $2^{O(\log^{1-ε} r)}$。此外，研究还提出了在特定条件下（三角形被不超过两个对齐覆盖，或对齐交图无环）的多项式时间近似算法。

Conclusion: 对齐簇删除问题（Hedge Cluster Deletion）在计算复杂性和可近似性方面具有显著特征。当图结构满足特定条件时，问题可以被有效解决。研究通过连接其他NP-hard问题来揭示其近似难度的下界，并提出了针对特定结构的近似算法和精确算法的思路，为理解和解决该问题提供了新的视角。

Abstract: A hedge graph is a graph whose edge set has been partitioned into groups called hedges. Here we consider a generalization of the well-known \textsc{Cluster Deletion} problem, named \textsc{Hedge Cluster Deletion}. The task is to compute the minimum number of hedges of a hedge graph so that their removal results in a graph that is isomorphic to a disjoint union of cliques. We show that for graphs that contain bounded size of vertex-disjoint 3-vertex-paths as subgraphs, \textsc{Hedge Cluster Deletion} can be solved in polynomial time. Regarding its approximability, we prove that the problem is tightly connected to the related complexity of the \textsc{Min Horn Deletion} problem, a well-known boolean CSP problem. Our connection shows that it is NP-hard to approximate \textsc{Hedge Cluster Deletion} within factor $2^{O(\log^{1-ε} r)}$ for any $ε>0$, where $r$ is the number of hedges in a given hedge graph.
  Based on its classified (in)approximability and the difficulty imposed by the structure of almost all non-trivial graphs, we consider the hedge underlying structure. We give a polynomial-time algorithm with constant approximation ratio for \textsc{Hedge Cluster Deletion} whenever each triangle of the input graph is covered by at most two hedges. On the way to this result, an interesting ingredient that we solved efficiently is a variant of the \textsc{Vertex Cover} problem in which apart from the desired vertex set that covers the edge set, a given set of vertex-constraints should also be included in the solution. Moreover, as a possible workaround for the existence of efficient exact algorithms, we propose the hedge intersection graph which is the intersection graph spanned by the hedges. Towards this direction, we give a polynomial-time algorithm for \textsc{Hedge Cluster Deletion} whenever the hedge intersection graph is acyclic.

</details>


### [185] [Testing H-freeness on sparse graphs, the case of bounded expansion](https://arxiv.org/abs/2511.10230)
*Samuel Humeau,Mamadou Moustapha Kanté,Daniel Mock,Timothé Picavet,Alexandre Vigny*

Main category: cs.DS

TL;DR: 该论文提出了一个更简单的算法来测试具有有界扩展的图类中的 H-自由性，该算法的查询复杂度恒定。


<details>
  <summary>Details</summary>
Motivation: 在属性测试领域，对于稀疏图模型，H-自由性（即排除子图 H 的图的属性）的测试一直是一个挑战。现有的方法（如 Czumaj 和 Sohler 的 FOCS'19 论文）虽然有效，但可能过于复杂。本文旨在提供一个更简洁的替代方案。

Method: 本文利用稀疏工具包中的结果，为 Czumaj 和 Sohler 的一个更广泛的论点（针对有界扩展的图类）提供了一个更简单的证明。具体来说，它证明了对于任何具有有界扩展的图类 C 和任何图 H，在 C 中的任何图 G 上测试 H-自由性都可以用恒定的查询复杂度来完成，其中常数取决于 H 和 C，而与 G 无关。

Result: 该论文成功地证明了，对于任何具有有界扩展的图类 C 和任何图 H，H-自由性的测试可以在恒定的查询复杂度下完成，其常数仅依赖于 H 和 C。

Conclusion: 该研究为在具有有界扩展的图类中进行 H-自由性测试提供了一个更简洁的方法，扩展了 Czumaj 和 Sohler 的工作。这对于包括立方图、有界最大度图、有界书厚图或有界平均度随机图等在内的图类具有重要意义。

Abstract: In property testing, a tester makes queries to (an oracle for) a graph and, on a graph having or being far from having a property P, it decides with high probability whether the graph satisfies P or not. Often, testers are restricted to a constant number of queries. While the graph properties for which there exists such a tester are somewhat well characterized in the dense graph model, it is not the case for sparse graphs. In this area, Czumaj and Sohler (FOCS'19) proved that H-freeness (i.e. the property of excluding the graph H as a subgraph) can be tested with constant queries on planar graphs as well as on graph classes excluding a minor.
  Using results from the sparsity toolkit, we propose a simpler alternative to the proof of Czumaj and Sohler, for a statement generalized to the broader notion of bounded expansion. That is, we prove that for any class C with bounded expansion and any graph H, testing H-freeness can be done with constant query complexity on any graph G in C, where the constant depends on H and C, but is independent of G.
  While classes excluding a minor are prime examples of classes with bounded expansion, so are, for example, cubic graphs, graph classes with bounded maximum degree, graphs of bounded book thickness, or random graphs of bounded average degree.

</details>


<div id='cs.LO'></div>

# cs.LO [[Back]](#toc)

### [186] [Contextual Refinement of Higher-Order Concurrent Probabilistic Programs](https://arxiv.org/abs/2511.10135)
*Kwing Hei Li,Alejandro Aguirre,Joseph Tassarotti,Lars Birkedal*

Main category: cs.LO

TL;DR: Foxtrot是一种新的高阶分离逻辑，用于验证高阶并发概率程序，并具有高阶局部状态。


<details>
  <summary>Details</summary>
Motivation: 为高阶并发概率程序提供一种新的证明方法。

Method: Foxtrot结合了并发分离逻辑和概率推理的原理，并引入了新的技术，如带状预采样和错误放大的归纳法。

Result: Foxtrot在证明各种示例方面表现出其表达能力，包括对抗性冯·诺依曼硬币和Sodium密码软件库的randombytes_uniform函数。所有结果都已在Rocq证明助手和Iris分离逻辑框架中进行了机械化。

Conclusion: Foxtrot是一种强大的新逻辑，可以用于验证复杂的并发概率程序。

Abstract: We present Foxtrot, the first higher-order separation logic for proving contextual refinement of higher-order concurrent probabilistic programs with higher-order local state. From a high level, Foxtrot inherits various concurrency reasoning principles from standard concurrent separation logic, e.g. invariants and ghost resources, and supports advanced probabilistic reasoning principles for reasoning about complex probability distributions induced by concurrent threads, e.g. tape presampling and induction by error amplification. The integration of these strong reasoning principles is highly non-trivial due to the combination of probability and concurrency in the language and the complexity of the Foxtrot model; the soundness of the logic relies on a version of the axiom of choice within the Iris logic, which is not used in earlier work on Iris-based logics. We demonstrate the expressiveness of Foxtrot on a wide range of examples, including the adversarial von Neumann coin and the $\mathsf{randombytes\_uniform}$ function of the Sodium cryptography software library.
  All results have been mechanized in the Rocq proof assistant and the Iris separation logic framework.

</details>


### [187] [Quantum modal logic](https://arxiv.org/abs/2511.10188)
*Kenji Tokuo*

Main category: cs.LO

TL;DR: The paper presents a simplified modal logic based on quantum logic, including its semantics and sequent calculus, proving soundness and completeness. This framework aims to support various quantum modal logics.


<details>
  <summary>Details</summary>
Motivation: To provide a foundational framework for formalizing various modal logics over quantum logic, such as quantum alethic, temporal, epistemic, and dynamic logic.

Method: Formalization of a modal logic based on quantum logic, including the development of a relational semantics and a sequent calculus. Demonstration of soundness and completeness theorems connecting the semantics and the calculus.

Result: A sound and complete modal logic based on quantum logic is established, with a defined relational semantics and sequent calculus.

Conclusion: The formalized framework serves as a basis for developing and analyzing various quantum modal logics.

Abstract: A modal logic based on quantum logic is formalized in its simplest possible form. Specifically, a relational semantics and a sequent calculus are provided, and the soundness and the completeness theorems connecting both notions are demonstrated. This framework is intended to serve as a basis for formalizing various modal logics over quantum logic, such as quantum alethic logic, quantum temporal logic, quantum epistemic logic, and quantum dynamic logic.

</details>


### [188] [Certified Branch-and-Bound MaxSAT Solving (Extended Version)](https://arxiv.org/abs/2511.10273)
*Dieter Vandesande,Jordi Coll,Bart Bogaerts*

Main category: cs.LO

TL;DR: 该论文实现了可证明的MaxSAT求解器，该求解器可以为求解器生成的答案提供正式的正确性证明。


<details>
  <summary>Details</summary>
Motivation: 为了解决MaxSAT求解器可能存在的错误，需要实现证明日志功能，以确保求解器输出的正确性。

Method: 通过为分支定界MaxSAT求解器中的先进技术（包括前瞻方法和基于多值决策图的伪布尔约束的子句编码）实现证明日志。

Result: 在MaxCDCL求解器中实现的证明日志具有可行的开销，但证明检查仍然具有挑战性。

Conclusion: 所提出的证明日志方法对于MaxSAT求解是可行的，并且可以为分支定界求解器提供可验证的正确性保证。

Abstract: Over the past few decades, combinatorial solvers have seen remarkable performance improvements, enabling their practical use in real-world applications. In some of these applications, ensuring the correctness of the solver's output is critical. However, the complexity of modern solvers makes them susceptible to bugs in their source code. In the domain of satisfiability checking (SAT), this issue has been addressed through proof logging, where the solver generates a formal proof of the correctness of its answer. For more expressive problems like MaxSAT, the optimization variant of SAT, proof logging had not seen a comparable breakthrough until recently.
  In this paper, we show how to achieve proof logging for state-of-the-art techniques in Branch-and-Bound MaxSAT solving. This includes certifying look-ahead methods used in such algorithms as well as advanced clausal encodings of pseudo-Boolean constraints based on so-called Multi-Valued Decision Diagrams (MDDs). We implement these ideas in MaxCDCL, the dominant branch-and-bound solver, and experimentally demonstrate that proof logging is feasible with limited overhead, while proof checking remains a challenge.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [189] [ScaleADFG: Affordance-based Dexterous Functional Grasping via Scalable Dataset](https://arxiv.org/abs/2511.09602)
*Sizhe Wang,Yifan Yang,Yongkang Luo,Daheng Li,Wei Wei,Yan Zhang,Peiying Hu,Yunjin Fu,Haonan Duan,Jia Sun,Peng Wang*

Main category: cs.RO

TL;DR: ScaleADFG框架通过自动化数据集构建和轻量级抓取生成网络，解决了机器人灵巧抓取中数据集规模和泛化性不足的问题，实现了对不同尺度物体的有效抓取。


<details>
  <summary>Details</summary>
Motivation: 现有机器人抓取方法在构建大规模数据集和泛化到日常物体尺度方面存在挑战，主要是由于机器人手和人手尺寸不匹配以及真实世界物体尺度的多样性。

Method: 提出ScaleADFG框架，包括全自动数据集构建流程和轻量级抓取生成网络。通过基于可供性的算法合成多样的抓取配置，处理物体-手部尺寸比例，并利用预训练模型生成3D资产和检索物体可供性。训练一个轻量级、单阶段的抓取生成网络，采用简单的损失函数设计。

Result: ScaleADFG数据集包含五个类别，每个类别有1000多个独特形状及15种尺度变化，共计超过60,000个抓取。在模拟和真实机器人上的实验表明，ScaleADFG框架能适应不同尺度的物体，提高抓取稳定性、多样性和泛化性，并在真实物体上表现出有效的零样本迁移能力。

Conclusion: 大规模数据集和多尺度物体对于有效训练至关重要。ScaleADFG框架能够有效解决机器人灵巧抓取中的规模和泛化性问题，并在各种尺度下实现稳定的抓取。

Abstract: Dexterous functional tool-use grasping is essential for effective robotic manipulation of tools. However, existing approaches face significant challenges in efficiently constructing large-scale datasets and ensuring generalizability to everyday object scales. These issues primarily arise from size mismatches between robotic and human hands, and the diversity in real-world object scales. To address these limitations, we propose the ScaleADFG framework, which consists of a fully automated dataset construction pipeline and a lightweight grasp generation network. Our dataset introduce an affordance-based algorithm to synthesize diverse tool-use grasp configurations without expert demonstrations, allowing flexible object-hand size ratios and enabling large robotic hands (compared to human hands) to grasp everyday objects effectively. Additionally, we leverage pre-trained models to generate extensive 3D assets and facilitate efficient retrieval of object affordances. Our dataset comprising five object categories, each containing over 1,000 unique shapes with 15 scale variations. After filtering, the dataset includes over 60,000 grasps for each 2 dexterous robotic hands. On top of this dataset, we train a lightweight, single-stage grasp generation network with a notably simple loss design, eliminating the need for post-refinement. This demonstrates the critical importance of large-scale datasets and multi-scale object variant for effective training. Extensive experiments in simulation and on real robot confirm that the ScaleADFG framework exhibits strong adaptability to objects of varying scales, enhancing functional grasp stability, diversity, and generalizability. Moreover, our network exhibits effective zero-shot transfer to real-world objects. Project page is available at https://sizhe-wang.github.io/ScaleADFG_webpage

</details>


### [190] [A Shared-Autonomy Construction Robotic System for Overhead Works](https://arxiv.org/abs/2511.09695)
*David Minkwan Kim,K. M. Brian Lee,Yong Hyeok Seo,Nikola Raicevic,Runfa Blark Li,Kehan Long,Chan Seon Yoon,Dong Min Kang,Byeong Jo Lim,Young Pyoung Kim,Nikolay Atanasov,Truong Nguyen,Se Woong Jun,Young Wook Kim*

Main category: cs.RO

TL;DR: 该研究提出了一种用于天花板钻孔等垂直上方作业的机器人系统，结合了移动底盘、升降装置、双臂躯干、钻孔末端执行器和RGB-D相机。为了在动态和低可见度环境下支持远程操作，该系统使用了高斯喷溅法进行在线3D重建，并引入了运动参数来模拟移动物体。为了在动态障碍物周围安全运行，研究者开发了一种基于神经网络配置空间障碍物的方法来进行规划和控制。初步的可行性研究验证了该硬件在钻孔、拧螺栓和锚固方面的能力，以及该软件在动态环境下安全远程操作方面的能力。


<details>
  <summary>Details</summary>
Motivation: 开发一种能够执行天花板钻孔等垂直上方作业的机器人系统，并解决在动态和低可见度环境下进行安全远程操作的挑战。

Method: 1. 硬件平台：移动底盘、两级升降装置、双臂躯干、定制钻孔末端执行器、RGB-D相机。
2. 软件支持：使用高斯喷溅法进行在线3D重建，并引入运动参数模型化移动物体，以支持动态和低可见度环境下的远程操作。
3. 安全规划与控制：开发基于神经网络配置空间障碍物的方法，以在动态障碍物周围实现安全操作。

Result: 初步的可行性研究证明了该硬件平台在钻孔、拧螺栓和锚固等任务上的能力，以及该软件系统在动态环境中安全进行远程操作的有效性。

Conclusion: 所提出的机器人系统及其软件能够有效地执行垂直上方作业，并在复杂的动态环境中实现安全可靠的远程操作。

Abstract: We present the ongoing development of a robotic system for overhead work such as ceiling drilling. The hardware platform comprises a mobile base with a two-stage lift, on which a bimanual torso is mounted with a custom-designed drilling end effector and RGB-D cameras. To support teleoperation in dynamic environments with limited visibility, we use Gaussian splatting for online 3D reconstruction and introduce motion parameters to model moving objects. For safe operation around dynamic obstacles, we developed a neural configuration-space barrier approach for planning and control. Initial feasibility studies demonstrate the capability of the hardware in drilling, bolting, and anchoring, and the software in safe teleoperation in a dynamic environment.

</details>


### [191] [Baby Sophia: A Developmental Approach to Self-Exploration through Self-Touch and Hand Regard](https://arxiv.org/abs/2511.09727)
*Stelios Zarifis,Ioannis Chalkiadakis,Artemis Chardouveli,Vasiliki Moutzouri,Aggelos Sotirchos,Katerina Papadimitriou,Panagiotis Filntisis,Niki Efthymiou,Petros Maragos,Katerina Pastra*

Main category: cs.RO

TL;DR: 本研究受婴儿发展启发，提出了一种名为Baby Sophia的机器人自主探索框架，利用BabyBench仿真环境，通过模仿婴儿好奇心驱动的探索行为，学习自我触摸和手部凝视行为。


<details>
  <summary>Details</summary>
Motivation: 本研究的动机是模仿婴儿的发展过程，探索纯粹基于好奇心的信号如何驱动自主机器人的多模态学习，使其能够从无目的的运动中发展出有目的的行为。

Method: 本研究提出了一种强化学习（RL）框架。对于自我触摸，将高维触觉输入转化为紧凑、有意义的表示，并通过内在奖励和课程学习（鼓励广泛的身体覆盖、平衡和泛化）来发现新的触觉接触。对于手部凝视，通过运动爬行学习手的视觉特征（如肤色和形状），然后通过内在奖励鼓励新颖的手部运动，并使目光跟随手部。课程学习从单手训练到双手训练，以实现复杂的视觉-运动协调。

Result: 研究结果表明，纯粹的好奇心信号（无外部监督）能够驱动协调的多模态学习，模仿婴儿从随机运动到有目的行为的转变。

Conclusion: 本研究成功地展示了纯粹的好奇心驱动信号可以引导自主机器人的多模态学习，使其能够像婴儿一样，从随机的运动发展出有目的的行为。

Abstract: Inspired by infant development, we propose a Reinforcement Learning (RL) framework for autonomous self-exploration in a robotic agent, Baby Sophia, using the BabyBench simulation environment. The agent learns self-touch and hand regard behaviors through intrinsic rewards that mimic an infant's curiosity-driven exploration of its own body. For self-touch, high-dimensional tactile inputs are transformed into compact, meaningful representations, enabling efficient learning. The agent then discovers new tactile contacts through intrinsic rewards and curriculum learning that encourage broad body coverage, balance, and generalization. For hand regard, visual features of the hands, such as skin-color and shape, are learned through motor babbling. Then, intrinsic rewards encourage the agent to perform novel hand motions, and follow its hands with its gaze. A curriculum learning setup from single-hand to dual-hand training allows the agent to reach complex visual-motor coordination. The results of this work demonstrate that purely curiosity-based signals, with no external supervision, can drive coordinated multimodal learning, imitating an infant's progression from random motor babbling to purposeful behaviors.

</details>


### [192] [A Robust Task-Level Control Architecture for Learned Dynamical Systems](https://arxiv.org/abs/2511.09790)
*Eshika Pathak,Ahmed Aboudonia,Sandeep Banik,Naira Hovakimyan*

Main category: cs.RO

TL;DR: 该研究提出了一种名为L1-DS的新型任务级鲁棒控制架构，用于解决基于动力学系统（DS）的学习演示（LfD）中任务执行不匹配的问题，以在机器人操作空间中生成和执行运动轨迹。


<details>
  <summary>Details</summary>
Motivation: 任务执行不匹配，即未建模动力学、持续干扰和系统延迟导致机器人实际任务空间状态偏离期望运动轨迹，这会影响基于DS的LfD生成的运动计划的实现。

Method: 提出了一种名为L1-DS的新型任务级鲁棒控制架构，它通过结合标称稳定控制器和L1自适应控制器来增强任何DS-based LfD模型。此外，还引入了一种基于窗口动态时间规整（DTW）的目标选择器，以处理时间错位问题，从而实现更精确的相位一致性跟踪。

Result: 在LASA和IROS手写数据集上证明了该架构的有效性。

Conclusion: L1-DS架构能够有效地处理任务执行不匹配问题，提高基于DS的LfD生成的运动轨迹的跟踪精度和鲁棒性。

Abstract: Dynamical system (DS)-based learning from demonstration (LfD) is a powerful tool for generating motion plans in the operation (`task') space of robotic systems. However, the realization of the generated motion plans is often compromised by a ''task-execution mismatch'', where unmodeled dynamics, persistent disturbances, and system latency cause the robot's actual task-space state to diverge from the desired motion trajectory. We propose a novel task-level robust control architecture, L1-augmented Dynamical Systems (L1-DS), that explicitly handles the task-execution mismatch in tracking a nominal motion plan generated by any DS-based LfD scheme. Our framework augments any DS-based LfD model with a nominal stabilizing controller and an L1 adaptive controller. Furthermore, we introduce a windowed Dynamic Time Warping (DTW)-based target selector, which enables the nominal stabilizing controller to handle temporal misalignment for improved phase-consistent tracking. We demonstrate the efficacy of our architecture on the LASA and IROS handwriting datasets.

</details>


### [193] [Provably Safe Stein Variational Clarity-Aware Informative Planning](https://arxiv.org/abs/2511.09836)
*Kaleb Ben Naveed,Utkrisht Sahai,Anouck Girard,Dimitra Panagou*

Main category: cs.RO

TL;DR: 在动态变化且信息衰减不均的环境中，提出了一种名为Stein Variational Clarity-Aware Informative Planning的框架，用于规划既安全又具信息量的机器人轨迹。


<details>
  <summary>Details</summary>
Motivation: 解决现有规划方法在处理信息衰减不均、信息随时间演变以及将安全视为软约束等方面的不足。

Method: 提出使用清晰度（clarity）来表示环境不确定性，并将清晰度动态纳入轨迹优化，同时采用基于门控框架的低级过滤机制来强制执行安全。通过Stein变分推理进行贝叶斯推理学习，以优化和筛选信息轨迹。

Result: 在具有不同衰减率和障碍物的环境中，通过硬件实验和模拟，证明了该框架在保证安全性和减少信息缺失方面的一致性。

Conclusion: 所提出的Stein Variational Clarity-Aware Informative Planning框架能够有效地在动态且信息衰减不均的环境中规划出安全且信息量丰富的机器人轨迹。

Abstract: Autonomous robots are increasingly deployed for information-gathering tasks in environments that vary across space and time. Planning informative and safe trajectories in such settings is challenging because information decays when regions are not revisited. Most existing planners model information as static or uniformly decaying, ignoring environments where the decay rate varies spatially; those that model non-uniform decay often overlook how it evolves along the robot's motion, and almost all treat safety as a soft penalty. In this paper, we address these challenges. We model uncertainty in the environment using clarity, a normalized representation of differential entropy from our earlier work that captures how information improves through new measurements and decays over time when regions are not revisited. Building on this, we present Stein Variational Clarity-Aware Informative Planning, a framework that embeds clarity dynamics within trajectory optimization and enforces safety through a low-level filtering mechanism based on our earlier gatekeeper framework for safety verification. The planner performs Bayesian inference-based learning via Stein variational inference, refining a distribution over informative trajectories while filtering each nominal Stein informative trajectory to ensure safety. Hardware experiments and simulations across environments with varying decay rates and obstacles demonstrate consistent safety and reduced information deficits.

</details>


### [194] [PuffyBot: An Untethered Shape Morphing Robot for Multi-environment Locomotion](https://arxiv.org/abs/2511.09885)
*Shashwat Singh,Zilin Si,Zeynep Temel*

Main category: cs.RO

TL;DR: A shape-morphing robot inspired by amphibians can move on land and in water.


<details>
  <summary>Details</summary>
Motivation: Inspired by amphibians' ability to adapt their morphology and motion for both terrestrial and aquatic environments, this paper presents a shape-morphing robot designed for multi-environment navigation.

Method: The robot, PuffyBot, uses a scissor-lift mechanism with a linear actuator for shape morphing, achieving a volume change from 255.00 cm3 to 423.75 cm3. A bell-crank linkage adjusts servo-actuated limbs by 90 degrees for transitions between crawling and swimming. The robot is waterproof with a TPU fabric, untethered for two hours with a 1000 mA h battery, and can counteract a 3.237 N downward force.

Result: Experimental results demonstrate PuffyBot's capability for multi-environment locomotion, including crawling on land, crawling underwater, swimming on the surface, and adjusting buoyancy for submerging or resurfacing. The volume change modulates buoyant force to manage the robot's 330 g mass.

Conclusion: Shape morphing offers a viable approach for creating versatile and energy-efficient robots capable of operating in diverse environments.

Abstract: Amphibians adapt their morphologies and motions to accommodate movement in both terrestrial and aquatic environments. Inspired by these biological features, we present PuffyBot, an untethered shape morphing robot capable of changing its body morphology to navigate multiple environments. Our robot design leverages a scissor-lift mechanism driven by a linear actuator as its primary structure to achieve shape morphing. The transformation enables a volume change from 255.00 cm3 to 423.75 cm3, modulating the buoyant force to counteract a downward force of 3.237 N due to 330 g mass of the robot. A bell-crank linkage is integrated with the scissor-lift mechanism, which adjusts the servo-actuated limbs by 90 degrees, allowing a seamless transition between crawling and swimming modes. The robot is fully waterproof, using thermoplastic polyurethane (TPU) fabric to ensure functionality in aquatic environments. The robot can operate untethered for two hours with an onboard battery of 1000 mA h. Our experimental results demonstrate multi-environment locomotion, including crawling on the land, crawling on the underwater floor, swimming on the water surface, and bimodal buoyancy adjustment to submerge underwater or resurface. These findings show the potential of shape morphing to create versatile and energy efficient robotic platforms suitable for diverse environments.

</details>


### [195] [A Study on Enhancing the Generalization Ability of Visuomotor Policies via Data Augmentation](https://arxiv.org/abs/2511.09932)
*Hanwen Wang*

Main category: cs.RO

TL;DR: 研究通过对环境因素进行随机化来增强机器人的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有数据增强方法生成的训练数据多样性不足，限制了视觉-动作策略的泛化能力。

Method: 通过自动化生成包含多种随机化因素（如摄像头位姿、光照条件、桌面纹理、桌子高度等）的数据集，并用此数据集训练策略。

Result: 所有随机化因素都会影响策略的泛化能力，其中多样化轨迹在缩小视觉差距方面特别有效。研究还发现在低成本机械臂上，环境随机化能有效提升策略的零样本仿真到现实迁移能力。

Conclusion: 对环境因素进行随机化是提升视觉-动作策略泛化能力的关键，尤其是在需要零样本仿真到现实迁移的场景下。

Abstract: The generalization ability of visuomotor policy is crucial, as a good policy should be deployable across diverse scenarios. Some methods can collect large amounts of trajectory augmentation data to train more generalizable imitation learning policies, aimed at handling the random placement of objects on the scene's horizontal plane. However, the data generated by these methods still lack diversity, which limits the generalization ability of the trained policy. To address this, we investigate the performance of policies trained by existing methods across different scene layout factors via automate the data generation for those factors that significantly impact generalization. We have created a more extensively randomized dataset that can be efficiently and automatically generated with only a small amount of human demonstration. The dataset covers five types of manipulators and two types of grippers, incorporating extensive randomization factors such as camera pose, lighting conditions, tabletop texture, and table height across six manipulation tasks. We found that all of these factors influence the generalization ability of the policy. Applying any form of randomization enhances policy generalization, with diverse trajectories particularly effective in bridging visual gap. Notably, we investigated on low-cost manipulator the effect of the scene randomization proposed in this work on enhancing the generalization capability of visuomotor policies for zero-shot sim-to-real transfer.

</details>


### [196] [Audio-VLA: Adding Contact Audio Perception to Vision-Language-Action Model for Robotic Manipulation](https://arxiv.org/abs/2511.09958)
*Xiangyi Wei,Haotian Zhang,Xinyi Cao,Siyu Xie,Weifeng Ge,Yang Li,Changbo Wang*

Main category: cs.RO

TL;DR: Audio-VLA是一个多模态模型，利用接触音频来感知和理解机器人操作中的动态过程，克服了纯视觉模型的局限性，并通过新的TCR指标进行了评估。


<details>
  <summary>Details</summary>
Motivation: 纯视觉的视觉-语言-动作（VLA）模型在机器人操控方面存在局限性，尤其是在感知交互和操控动态过程方面。音频-VLA旨在通过引入接触音频来解决这些限制。

Method: Audio-VLA采用预训练的DINOv2和SigLIP作为视觉编码器，AudioCLIP作为音频编码器，Llama2作为语言模型。使用LoRA进行微调，并通过多模态投影层对齐不同模态的特征。RLBench和LIBERO模拟环境通过添加基于碰撞的音频生成来增强。引入了任务完成率（TCR）指标来评估动态过程感知能力。

Result: Audio-VLA在LIBERO、RLBench以及两个真实世界任务的广泛实验中，表现优于纯视觉方法。TCR指标能够有效量化动态过程感知能力。

Conclusion: Audio-VLA通过整合接触音频显著提升了机器人操控的感知能力，并且提出的TCR指标为评估动态操作过程提供了更全面的视角。

Abstract: The Vision-Language-Action models (VLA) have achieved significant advances in robotic manipulation recently. However, vision-only VLA models create fundamental limitations, particularly in perceiving interactive and manipulation dynamic processes. This paper proposes Audio-VLA, a multimodal manipulation policy that leverages contact audio to perceive contact events and dynamic process feedback. Audio-VLA overcomes the vision-only constraints of VLA models. Additionally, this paper introduces the Task Completion Rate (TCR) metric to systematically evaluate dynamic operational processes. Audio-VLA employs pre-trained DINOv2 and SigLIP as visual encoders, AudioCLIP as the audio encoder, and Llama2 as the large language model backbone. We apply LoRA fine-tuning to these pre-trained modules to achieve robust cross-modal understanding of both visual and acoustic inputs. A multimodal projection layer aligns features from different modalities into the same feature space. Moreover RLBench and LIBERO simulation environments are enhanced by adding collision-based audio generation to provide realistic sound feedback during object interactions. Since current robotic manipulation evaluations focus on final outcomes rather than providing systematic assessment of dynamic operational processes, the proposed TCR metric measures how well robots perceive dynamic processes during manipulation, creating a more comprehensive evaluation metric. Extensive experiments on LIBERO, RLBench, and two real-world tasks demonstrate Audio-VLA's superior performance over vision-only comparative methods, while the TCR metric effectively quantifies dynamic process perception capabilities.

</details>


### [197] [Phantom Menace: Exploring and Enhancing the Robustness of VLA Models against Physical Sensor Attacks](https://arxiv.org/abs/2511.10008)
*Xuancun Lu,Jiaxiang Chen,Shilin Xiao,Zizhi Jin,Zhangrui Chen,Hanwen Yu,Bohan Qian,Ruochen Zhou,Xiaoyu Ji,Wenyuan Xu*

Main category: cs.RO

TL;DR: 该研究首次系统地研究了视觉-语言-动作（VLA）模型在物理传感器受到攻击时的安全性问题，并提出了一种名为“Real-Sim-Real”的框架来模拟和验证这些攻击，同时开发了一种基于对抗性训练的防御方法来增强模型的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有的视觉-语言-动作（VLA）模型虽然在机器人领域取得了显著进展，但其安全性，特别是面对物理世界中的传感器攻击时，并未得到充分研究。

Method: 提出了一种“Real-Sim-Real”框架，该框架能够自动模拟物理传感器攻击（包括针对摄像头和麦克风的攻击），并在真实机器人系统上进行验证。通过大规模评估不同VLA架构、任务和攻击参数下的模型表现，并开发了一种基于对抗性训练的防御机制。

Result: 研究表明，VLA模型在传感器受到攻击时存在显著的脆弱性，并且其易受攻击的模式与任务类型和模型设计密切相关。所提出的防御方法能够提高VLA模型在面对传感器攻击引起的分布外物理扰动时的鲁棒性，同时保持模型的性能。

Conclusion: 为了确保VLA模型在安全关键环境中的可靠部署，迫切需要建立标准化的鲁棒性基准测试，并开发有效的缓解策略来应对传感器攻击。

Abstract: Vision-Language-Action (VLA) models revolutionize robotic systems by enabling end-to-end perception-to-action pipelines that integrate multiple sensory modalities, such as visual signals processed by cameras and auditory signals captured by microphones. This multi-modality integration allows VLA models to interpret complex, real-world environments using diverse sensor data streams. Given the fact that VLA-based systems heavily rely on the sensory input, the security of VLA models against physical-world sensor attacks remains critically underexplored.
  To address this gap, we present the first systematic study of physical sensor attacks against VLAs, quantifying the influence of sensor attacks and investigating the defenses for VLA models. We introduce a novel ``Real-Sim-Real'' framework that automatically simulates physics-based sensor attack vectors, including six attacks targeting cameras and two targeting microphones, and validates them on real robotic systems. Through large-scale evaluations across various VLA architectures and tasks under varying attack parameters, we demonstrate significant vulnerabilities, with susceptibility patterns that reveal critical dependencies on task types and model designs. We further develop an adversarial-training-based defense that enhances VLA robustness against out-of-distribution physical perturbations caused by sensor attacks while preserving model performance. Our findings expose an urgent need for standardized robustness benchmarks and mitigation strategies to secure VLA deployments in safety-critical environments.

</details>


### [198] [DecARt Leg: Design and Evaluation of a Novel Humanoid Robot Leg with Decoupled Actuation for Agile Locomotion](https://arxiv.org/abs/2511.10021)
*Egor Davydenko,Andrei Volchenkov,Vladimir Gerasimov,Roman Gorbachev*

Main category: cs.RO

TL;DR: DecARt 腿是一种新型电动驱动的拟人化机器人腿，采用准伸缩结构和电机实现解耦驱动，并通过多连杆系统实现踝关节扭矩传输，以实现敏捷运动。


<details>
  <summary>Details</summary>
Motivation: 为了实现敏捷的运动能力，提出了一种新型的电动驱动机器人腿设计，称为 DecARt 腿。

Method: 采用准伸缩运动学结构、旋转电机实现解耦驱动、近乎拟人化的外观以及创新的多连杆踝关节扭矩传输系统。提出了一种名为‘最快可实现摆动时间’（FAST）的新型描述性指标，用于数值分析敏捷运动能力。

Result: 通过广泛的仿真和初步的硬件实验，对所提出的 DecARt 腿设计进行了定量评估，并与其他设计进行了比较。

Conclusion: DecARt 腿的设计和评估为实现更敏捷的机器人运动提供了新的途径。

Abstract: In this paper, we propose a novel design of an electrically actuated robotic leg, called the DecARt (Decoupled Actuation Robot) Leg, aimed at performing agile locomotion. This design incorporates several new features, such as the use of a quasi-telescopic kinematic structure with rotational motors for decoupled actuation, a near-anthropomorphic leg appearance with a forward facing knee, and a novel multi-bar system for ankle torque transmission from motors placed above the knee. To analyze the agile locomotion capabilities of the design numerically, we propose a new descriptive metric, called the `Fastest Achievable Swing Time` (FAST), and perform a quantitative evaluation of the proposed design and compare it with other designs. Then we evaluate the performance of the DecARt Leg-based robot via extensive simulation and preliminary hardware experiments.

</details>


### [199] [Physics-informed Machine Learning for Static Friction Modeling in Robotic Manipulators Based on Kolmogorov-Arnold Networks](https://arxiv.org/abs/2511.10079)
*Yizheng Wang,Timon Rabczuk,Yinghua Liu*

Main category: cs.RO

TL;DR: 本研究提出了一种基于KAN的物理启发的机器学习方法，用于机器人关节的静摩擦建模，该方法能够处理未知的函数结构和噪声数据，并提取简洁且具有物理意义的摩擦表达式。


<details>
  <summary>Details</summary>
Motivation: 传统的静摩擦模型（如Stribeck模型）需要预定义的函数形式，难以处理未知的函数结构。因此，需要一种新的方法来解决这个问题。

Method: 提出一种基于KAN的物理启发的机器学习方法，并结合了三次样条插值激活函数和符号回归机制，通过剪枝和属性评分来实现模型简化和物理表达式提取。

Result: 该方法在合成数据和真实机器人数据上都表现出色，确定性系数（coefficient of determination）超过0.95，并成功提取了简洁且具有物理意义的摩擦表达式。

Conclusion: 本研究为可解释的、数据驱动的机器人摩擦建模提供了一个新的视角，具有良好的工程应用前景。

Abstract: Friction modeling plays a crucial role in achieving high-precision motion control in robotic operating systems. Traditional static friction models (such as the Stribeck model) are widely used due to their simple forms; however, they typically require predefined functional assumptions, which poses significant challenges when dealing with unknown functional structures. To address this issue, this paper proposes a physics-inspired machine learning approach based on the Kolmogorov Arnold Network (KAN) for static friction modeling of robotic joints. The method integrates spline activation functions with a symbolic regression mechanism, enabling model simplification and physical expression extraction through pruning and attribute scoring, while maintaining both high prediction accuracy and interpretability. We first validate the method's capability to accurately identify key parameters under known functional models, and further demonstrate its robustness and generalization ability under conditions with unknown functional structures and noisy data. Experiments conducted on both synthetic data and real friction data collected from a six-degree-of-freedom industrial manipulator show that the proposed method achieves a coefficient of determination greater than 0.95 across various tasks and successfully extracts concise and physically meaningful friction expressions. This study provides a new perspective for interpretable and data-driven robotic friction modeling with promising engineering applicability.

</details>


### [200] [Opinion: Towards Unified Expressive Policy Optimization for Robust Robot Learning](https://arxiv.org/abs/2511.10087)
*Haidong Huang,Haiyue Zhu. Jiayu Song,Xixin Zhao,Yaohua Zhou,Jiayi Zhang,Yuze Zhai,Xiaocong Li*

Main category: cs.RO

TL;DR: UEPO是一个统一的生成框架，用于解决离线到在线强化学习（O2O-RL）中的多模态行为覆盖率和分布偏移问题，并在D4RL基准测试中取得了显著的改进。


<details>
  <summary>Details</summary>
Motivation: O2O-RL在机器人策略部署方面有潜力，但面临多模态行为覆盖率有限和在线适应期间分布偏移的挑战。

Method: 提出UEPO，一个受大语言模型预训练和微调启发的统一生成框架，包含多种子动态感知扩散策略、动态散度正则化机制和基于扩散的数据增强模块。

Result: +5.9%（运动任务）和+12.4%（灵巧操作任务）的绝对改进，优于Uni-O4。

Conclusion: UEPO在D4RL基准测试中表现出强大的泛化能力和可扩展性，解决了O2O-RL中的关键挑战。

Abstract: Offline-to-online reinforcement learning (O2O-RL) has emerged as a promising paradigm for safe and efficient robotic policy deployment but suffers from two fundamental challenges: limited coverage of multimodal behaviors and distributional shifts during online adaptation. We propose UEPO, a unified generative framework inspired by large language model pretraining and fine-tuning strategies. Our contributions are threefold: (1) a multi-seed dynamics-aware diffusion policy that efficiently captures diverse modalities without training multiple models; (2) a dynamic divergence regularization mechanism that enforces physically meaningful policy diversity; and (3) a diffusion-based data augmentation module that enhances dynamics model generalization. On the D4RL benchmark, UEPO achieves +5.9\% absolute improvement over Uni-O4 on locomotion tasks and +12.4\% on dexterous manipulation, demonstrating strong generalization and scalability.

</details>


### [201] [Learning a Thousand Tasks in a Day](https://arxiv.org/abs/2511.10110)
*Kamil Dreczkowski,Pietro Vitiello,Vitalis Vosylius,Edward Johns*

Main category: cs.RO

TL;DR: 该研究提出了一种名为MT3（Multi-Task Trajectory Transfer）的模仿学习方法，通过将机器人操作轨迹分解为对齐和交互阶段，并结合基于检索的泛化，显著提高了学习效率，使其能够从极少量（甚至一个）的演示中学习复杂任务，并实现了在24小时内教会机器人1000个不同任务的壮举。


<details>
  <summary>Details</summary>
Motivation: 目前的模仿学习方法在机器人操作任务中需要大量演示，学习效率低下。本研究旨在通过引入结构化先验（轨迹分解和检索泛化）来提高学习效率。

Method: 将机器人操作轨迹分解为两个阶段：对齐（Alignment）和交互（Interaction）。研究人员比较了这两个阶段不同的设计选择，并与单阶段的模仿学习方法（如行为克隆）进行了比较。最终提出了一种名为MT3（Multi-Task Trajectory Transfer）的方法，该方法基于轨迹分解和检索泛化。

Result: 在演示数量较少（每个任务<10次）的情况下，基于分解的方法比单阶段学习在数据效率上提高了两个数量级。检索方法在对齐和交互阶段的表现均优于行为克隆。MT3能够从单个演示中学习日常操作任务，并泛化到新的物体实例。研究人员在24小时内教会了机器人1000个不同的任务。

Conclusion: 通过将机器人操作轨迹分解为对齐和交互阶段，并结合检索泛化，可以显著提高模仿学习的数据效率，从而使机器人能够从极少量的演示中学习大量任务。MT3方法证明了这种方法的有效性。

Abstract: Humans are remarkably efficient at learning tasks from demonstrations, but today's imitation learning methods for robot manipulation often require hundreds or thousands of demonstrations per task. We investigate two fundamental priors for improving learning efficiency: decomposing manipulation trajectories into sequential alignment and interaction phases, and retrieval-based generalisation. Through 3,450 real-world rollouts, we systematically study this decomposition. We compare different design choices for the alignment and interaction phases, and examine generalisation and scaling trends relative to today's dominant paradigm of behavioural cloning with a single-phase monolithic policy. In the few-demonstrations-per-task regime (<10 demonstrations), decomposition achieves an order of magnitude improvement in data efficiency over single-phase learning, with retrieval consistently outperforming behavioural cloning for both alignment and interaction. Building on these insights, we develop Multi-Task Trajectory Transfer (MT3), an imitation learning method based on decomposition and retrieval. MT3 learns everyday manipulation tasks from as little as a single demonstration each, whilst also generalising to novel object instances. This efficiency enables us to teach a robot 1,000 distinct everyday tasks in under 24 hours of human demonstrator time. Through 2,200 additional real-world rollouts, we reveal MT3's capabilities and limitations across different task families. Videos of our experiments can be found on at https://www.robot-learning.uk/learning-1000-tasks.

</details>


### [202] [RoboBenchMart: Benchmarking Robots in Retail Environment](https://arxiv.org/abs/2511.10276)
*Konstantin Soshin,Alexander Krapukhin,Andrei Spiridonov,Denis Shepelev,Gregorii Bukhtuev,Andrey Kuznetsov,Vlad Shakhuro*

Main category: cs.RO

TL;DR: RoboBenchMart 是一个针对黑暗商店环境设计的、更具挑战性且更真实的机器人操作基准，用于处理各种杂货物品，并已发布以支持未来的研究。


<details>
  <summary>Details</summary>
Motivation: 现有的机器人操作基准主要集中在简化的台面场景，而未能解决黑暗商店等现实零售环境中的复杂操作任务。RoboBenchMart 旨在弥合这一差距，因为它解决了零售领域中机器人自动化自动化应用的巨大潜力。

Method: RoboBenchMart 在黑暗商店环境中，机器人需要处理具有密集物体、各种空间配置（不同高度、深度和近距离）的杂货物品。此基准包括程序化商店布局生成器、轨迹生成管道、评估工具和微调基线模型。

Result: RoboBenchMart 演示了当前最先进的通用模型在解决常见的零售任务方面存在困难。

Conclusion: RoboBenchMart 是一个针对黑暗商店环境设计的、更具挑战性且更真实的机器人操作基准，用于处理各种杂货物品，并已发布以支持未来的研究。

Abstract: Most existing robotic manipulation benchmarks focus on simplified tabletop scenarios, typically involving a stationary robotic arm interacting with various objects on a flat surface. To address this limitation, we introduce RoboBenchMart, a more challenging and realistic benchmark designed for dark store environments, where robots must perform complex manipulation tasks with diverse grocery items. This setting presents significant challenges, including dense object clutter and varied spatial configurations -- with items positioned at different heights, depths, and in close proximity. By targeting the retail domain, our benchmark addresses a setting with strong potential for near-term automation impact. We demonstrate that current state-of-the-art generalist models struggle to solve even common retail tasks. To support further research, we release the RoboBenchMart suite, which includes a procedural store layout generator, a trajectory generation pipeline, evaluation tools and fine-tuned baseline models.

</details>


### [203] [nuPlan-R: A Closed-Loop Planning Benchmark for Autonomous Driving via Reactive Multi-Agent Simulation](https://arxiv.org/abs/2511.10403)
*Mingxing Peng,Ruoyu Yao,Xusen Guo,Jun Ma*

Main category: cs.RO

TL;DR: nuPlan-R是一个新的闭环规划基准，使用基于学习的反应式多智能体模拟来取代基于规则的IDM，以实现更真实、更多样化和类似人类的交通行为，从而更准确地评估自动驾驶规划器。


<details>
  <summary>Details</summary>
Motivation: 现有自动驾驶规划基准依赖于缺乏行为多样性的基于规则的反应式代理（如IDM），导致交通动态过于简化，无法真实反映人类互动。

Method: nuPlan-R基准集成了基于学习的反应式多智能体模拟，使用噪声解耦的基于扩散的反应式代理取代了基于规则的IDM代理。它还引入了一个考虑交互的代理选择机制，并增加了两个额外的评估指标。

Result: 实验表明，nuPlan-R中的反应式代理模型能产生更真实、更多样化、更像人类的交通行为。该基准改进了对规划器性能的评估，尤其是在复杂交互场景中，凸显了基于学习的规划器的优势。nuPlan-R被确立为公平、反应式和真实的闭环规划评估新标准。

Conclusion: nuPlan-R通过引入基于学习的反应式代理和交互感知机制，提供了一个更现实、更具挑战性的闭环规划评估环境，从而能够更准确地评估和推动自动驾驶技术的发展。

Abstract: Recent advances in closed-loop planning benchmarks have significantly improved the evaluation of autonomous vehicles. However, existing benchmarks still rely on rule-based reactive agents such as the Intelligent Driver Model (IDM), which lack behavioral diversity and fail to capture realistic human interactions, leading to oversimplified traffic dynamics. To address these limitations, we present nuPlan-R, a new reactive closed-loop planning benchmark that integrates learning-based reactive multi-agent simulation into the nuPlan framework. Our benchmark replaces the rule-based IDM agents with noise-decoupled diffusion-based reactive agents and introduces an interaction-aware agent selection mechanism to ensure both realism and computational efficiency. Furthermore, we extend the benchmark with two additional metrics to enable a more comprehensive assessment of planning performance. Extensive experiments demonstrate that our reactive agent model produces more realistic, diverse, and human-like traffic behaviors, leading to a benchmark environment that better reflects real-world interactive driving. We further reimplement a collection of rule-based, learning-based, and hybrid planning approaches within our nuPlan-R benchmark, providing a clearer reflection of planner performance in complex interactive scenarios and better highlighting the advantages of learning-based planners in handling complex and dynamic scenarios. These results establish nuPlan-R as a new standard for fair, reactive, and realistic closed-loop planning evaluation. We will open-source the code for the new benchmark.

</details>


### [204] [LongComp: Long-Tail Compositional Zero-Shot Generalization for Robust Trajectory Prediction](https://arxiv.org/abs/2511.10411)
*Benjamin Stoler,Jonathan Francis,Jean Oh*

Main category: cs.RO

TL;DR: 自动驾驶中的轨迹预测需要处理罕见且危及生命安全的场景，仅靠现实世界数据收集是不可行的。为了评估在这种条件下的鲁棒性，我们提出了新的长尾评估设置，重新划分数据集以创建具有挑战性的分布外（OOD）测试集。


<details>
  <summary>Details</summary>
Motivation: 自动驾驶中的轨迹预测必须处理罕见且危及生命安全的场景，仅靠现实世界数据收集是不可行的。

Method: 引入安全知情场景因子化框架，将场景分解为离散的自我和社会背景。借鉴计算机视觉中的组合零样本图像标注，我们通过留出新颖的上下文组合来构建具有挑战性的闭世界和开世界设置。为了提高泛化能力，我们扩展了任务模块化门控网络在轨迹预测模型中的应用，并开发了一个辅助的难度预测头来改进内部表示。

Result: 在闭世界和开世界设置中，与分布内性能相比，未来运动预测的 OOD 性能差距分别为 5.0% 和 14.7%。我们提出的策略将 OOD 性能差距分别缩小到 2.8% 和 11.5%，同时仍能提高分布内性能。

Conclusion: 所提出的方法通过创建具有挑战性的 OOD 测试集来评估鲁棒性，并通过改进模型泛化能力来缩小 OOD 性能差距，同时保持分布内性能。

Abstract: Methods for trajectory prediction in Autonomous Driving must contend with rare, safety-critical scenarios that make reliance on real-world data collection alone infeasible. To assess robustness under such conditions, we propose new long-tail evaluation settings that repartition datasets to create challenging out-of-distribution (OOD) test sets. We first introduce a safety-informed scenario factorization framework, which disentangles scenarios into discrete ego and social contexts. Building on analogies to compositional zero-shot image-labeling in Computer Vision, we then hold out novel context combinations to construct challenging closed-world and open-world settings. This process induces OOD performance gaps in future motion prediction of 5.0% and 14.7% in closed-world and open-world settings, respectively, relative to in-distribution performance for a state-of-the-art baseline. To improve generalization, we extend task-modular gating networks to operate within trajectory prediction models, and develop an auxiliary, difficulty-prediction head to refine internal representations. Our strategies jointly reduce the OOD performance gaps to 2.8% and 11.5% in the two settings, respectively, while still improving in-distribution performance.

</details>


### [205] [Improving dependability in robotized bolting operations](https://arxiv.org/abs/2511.10448)
*Lorenzo Pagliara,Violeta Redondo,Enrico Ferrentino,Manuel Ferre,Pasquale Chiacchio*

Main category: cs.RO

TL;DR: 提出了一种用于机器人化螺栓连接任务的控制框架，该框架具有精确的扭矩控制、主动柔顺性、多模式人机交互和高层监督器，以提高自主性和故障管理能力，并在管道法兰连接任务中得到验证。


<details>
  <summary>Details</summary>
Motivation: 当前的机器人螺栓连接系统缺乏可靠的自主性和故障管理能力，需要提高操作安全性和有效性。

Method: 提出了一种控制框架，实现精确的驱动扭矩控制和主动柔顺性；设计了一个多模式人机交互界面，用于实时可视化和无缝切换手动/自动控制；使用高层监督器协调执行和模式转换，遵循监督控制范式。

Result: 在管道法兰连接任务中，验证了该系统在多种故障条件下的性能，结果显示提高了故障检测能力、增强了操作员态势感知能力，并实现了精确和柔顺的螺栓连接操作。

Conclusion: 所提出的控制框架能够实现可靠的机器人化螺栓连接，但需要注意的是，仅依靠单一摄像头来实现完全的态势感知存在局限性。

Abstract: Bolting operations are critical in industrial assembly and in the maintenance of scientific facilities, requiring high precision and robustness to faults. Although robotic solutions have the potential to improve operational safety and effectiveness, current systems still lack reliable autonomy and fault management capabilities. To address this gap, we propose a control framework for dependable robotized bolting tasks and instantiate it on a specific robotic system. The system features a control architecture ensuring accurate driving torque control and active compliance throughout the entire operation, enabling safe interaction even under fault conditions. By designing a multimodal human-robot interface (HRI) providing real-time visualization of relevant system information and supporting seamless transitions between automatic and manual control, we improve operator situation awareness and fault detection capabilities. A high-level supervisor (SV) coordinates the execution and manages transitions between control modes, ensuring consistency with the supervisory control (SVC) paradigm, while preserving the human operator's authority. The system is validated in a representative bolting operation involving pipe flange joining, under several fault conditions. The results demonstrate improved fault detection capabilities, enhanced operator situational awareness, and accurate and compliant execution of the bolting operation. However, they also reveal the limitations of relying on a single camera to achieve full situational awareness.

</details>


### [206] [From Fold to Function: Dynamic Modeling and Simulation-Driven Design of Origami Mechanisms](https://arxiv.org/abs/2511.10580)
*Tianhui Han,Shashwat Singh,Sarvesh Patil,Zeynep Temel*

Main category: cs.RO

TL;DR: 我们提出了一个基于MuJoCo的变形体能力的折纸机构仿真设计框架，使用户能够通过图形用户界面（GUI）定义折纸结构、折痕和驱动，从而生成物理上一致的仿真。该框架通过一个折纸弹射器的案例研究进行了演示，其中设计参数通过协方差矩阵自适应进化策略（CMA-ES）在仿真中进行了优化，并通过物理原型进行了实验验证，展示了该系统在快速、仿真驱动的折纸设计、优化和分析方面的效用。


<details>
  <summary>Details</summary>
Motivation: 折纸结构轻巧、紧凑且能够实现复杂的运动，这使得它们在机器人和可部署系统中越来越有价值。然而，精确模拟它们的折叠行为和与环境的交互仍然具有挑战性。

Method: 使用MuJoCo的变形体能力，将折纸片表示为具有用户指定的约束（如折痕和驱动）的相互连接的变形元素的图，这些约束通过直观的图形用户界面（GUI）定义。

Result: 一个折纸弹射器的案例研究，其中设计参数通过CMA-ES在仿真中进行了优化，并通过物理原型进行了实验验证，优化后的结构实现了改进的投掷性能。

Conclusion: 我们提出的框架能够实现快速、仿真驱动的折纸设计、优化和分析，并且可以通过实验进行验证。

Abstract: Origami-inspired mechanisms can transform flat sheets into functional three-dimensional dynamic structures that are lightweight, compact, and capable of complex motion. These properties make origami increasingly valuable in robotic and deployable systems. However, accurately simulating their folding behavior and interactions with the environment remains challenging. To address this, we present a design framework for origami mechanism simulation that utilizes MuJoCo's deformable-body capabilities. In our approach, origami sheets are represented as graphs of interconnected deformable elements with user-specified constraints such as creases and actuation, defined through an intuitive graphical user interface (GUI). This framework allows users to generate physically consistent simulations that capture both the geometric structure of origami mechanisms and their interactions with external objects and surfaces. We demonstrate our method's utility through a case study on an origami catapult, where design parameters are optimized in simulation using the Covariance Matrix Adaptation Evolution Strategy (CMA-ES) and validated experimentally on physical prototypes. The optimized structure achieves improved throwing performance, illustrating how our system enables rapid, simulation-driven origami design, optimization, and analysis.

</details>


### [207] [Optimizing the flight path for a scouting Uncrewed Aerial Vehicle](https://arxiv.org/abs/2511.10598)
*Raghav Adhikari,Sachet Khatiwada,Suman Poudel*

Main category: cs.RO

TL;DR: 无人机可用于在灾后非结构化环境中进行侦察，以优化高度来最大化传感器覆盖范围并最小化数据不确定性。


<details>
  <summary>Details</summary>
Motivation: 灾后环境非结构化，给救援车辆的路径规划带来挑战。

Method: 提出一种基于优化的方法来规划无人机路径，使其在最优高度进行侦察，以最大化传感器覆盖范围并最小化数据不确定性。

Result: 提出的方法能够规划无人机在最优高度的路径，以覆盖最大区域并收集不确定性最小的数据。

Conclusion: 在灾后非结构化环境中，利用无人机进行侦察并通过优化方法规划其路径，可以有效应对导航挑战，提高数据收集效率。

Abstract: Post-disaster situations pose unique navigation challenges. One of those challenges is the unstructured nature of the environment, which makes it hard to layout paths for rescue vehicles. We propose the use of Uncrewed Aerial Vehicle (UAV) in such scenario to perform reconnaissance across the environment. To accomplish this, we propose an optimization-based approach to plan a path for the UAV at optimal height where the sensors of the UAV can cover the most area and collect data with minimum uncertainty.

</details>


### [208] [Robot Crash Course: Learning Soft and Stylized Falling](https://arxiv.org/abs/2511.10635)
*Pascal Strauch,David Müller,Sammy Christen,Agon Serifi,Ruben Grandia,Espen Knoop,Moritz Bächer*

Main category: cs.RO

TL;DR: 尽管双足机器人已有稳健的运动能力，但在现实世界中仍有跌倒的风险。本研究不侧重于预防跌倒，而是专注于跌倒本身，旨在减少机器人物理损伤，并允许用户控制机器人的最终姿态。为此，我们提出了一种机器人无关的奖励函数，该函数在强化学习中平衡了期望最终姿态的实现、冲击的最小化以及关键部件的保护。为了使策略能够应对各种初始跌倒条件，并在推理时指定任意的、未见过的最终姿态，我们引入了一种基于仿真的初始姿态和最终姿态采样策略。通过仿真和现实世界实验，我们的工作证明了即使是双足机器人也能执行可控的、软着陆式的跌倒。


<details>
  <summary>Details</summary>
Motivation: 本研究的动机在于解决现实世界中双足机器人在稳健运动能力方面仍面临跌倒风险的问题，并将研究重点从跌倒预防转移到如何控制跌倒过程，以最大程度地减少机器人损伤并允许用户控制其最终姿态。

Method: 本研究提出了一种机器人无关的奖励函数，该函数通过强化学习平衡了达到期望最终姿态、最小化冲击以及保护关键机器人部件。为了提高策略对各种初始跌倒条件的鲁棒性，并允许在推理时指定任意的、未见的最终姿态，研究者引入了一种基于仿真的初始姿态和最终姿态采样策略。

Result: 通过仿真和现实世界实验，证明了即使是双足机器人也能执行可控的、软着陆式的跌倒。

Conclusion: 本研究成功开发了一种方法，使双足机器人在跌倒时能够实现受控的软着陆，从而减少物理损伤并提供用户对机器人最终姿态的控制。

Abstract: Despite recent advances in robust locomotion, bipedal robots operating in the real world remain at risk of falling. While most research focuses on preventing such events, we instead concentrate on the phenomenon of falling itself. Specifically, we aim to reduce physical damage to the robot while providing users with control over a robot's end pose. To this end, we propose a robot agnostic reward function that balances the achievement of a desired end pose with impact minimization and the protection of critical robot parts during reinforcement learning. To make the policy robust to a broad range of initial falling conditions and to enable the specification of an arbitrary and unseen end pose at inference time, we introduce a simulation-based sampling strategy of initial and end poses. Through simulated and real-world experiments, our work demonstrates that even bipedal robots can perform controlled, soft falls.

</details>


<div id='eess.SP'></div>

# eess.SP [[Back]](#toc)

### [209] [Investigation of Feature Selection and Pooling Methods for Environmental Sound Classification](https://arxiv.org/abs/2511.09802)
*Parinaz Binandeh Dehaghani,Danilo Pena,A. Pedro Aguiar*

Main category: eess.SP

TL;DR: 使用稀疏显著区域池化（SSRP）及其变体，可以提高轻量级卷积神经网络（CNN）在环境声音分类（ESC）任务上的准确性，特别是在计算资源有限的情况下。


<details>
  <summary>Details</summary>
Motivation: 探索降维和池化方法对使用轻量级CNN的环境声音分类（ESC）的影响。

Method: 评估稀疏显著区域池化（SSRP）及其变体（SSRP-B和SSRP-T），并与主成分分析（PCA）进行比较，在ESC-50数据集上进行了实验。

Result: SSRP-T达到了80.69%的准确率，显著优于基线CNN（66.75%）和PCA降维模型（37.60%）。

Conclusion: 精心调整的稀疏池化策略为ESC任务提供了一种高效且高性能的解决方案，特别是在需要平衡准确性和计算成本的资源受限场景中。

Abstract: This paper explores the impact of dimensionality reduction and pooling methods for Environmental Sound Classification (ESC) using lightweight CNNs. We evaluate Sparse Salient Region Pooling (SSRP) and its variants, SSRP-Basic (SSRP-B) and SSRP-Top-K (SSRP-T), under various hyperparameter settings and compare them with Principal Component Analysis (PCA). Experiments on the ESC-50 dataset demonstrate that SSRP-T achieves up to 80.69 % accuracy, significantly outperforming both the baseline CNN (66.75 %) and the PCA-reduced model (37.60 %). Our findings confirm that a well-tuned sparse pooling strategy provides a robust, efficient, and high-performing solution for ESC tasks, particularly in resource-constrained scenarios where balancing accuracy and computational cost is crucial.

</details>


### [210] [Massive MIMO-OFDM Channel Acquisition with Multi-group Adjustable Phase Shift Pilots](https://arxiv.org/abs/2511.09826)
*Yu Zhao,Li You,Jinke Tang,Mengyu Qian,Bin Jiang,Xiang-Gen Xia,Xiqi Gao*

Main category: eess.SP

TL;DR: MAPSP通过利用信道稀疏性，以低开销获取信道信息，从而在移动场景中提供更高的频谱效率。


<details>
  <summary>Details</summary>
Motivation: 为了在保证高频谱效率（SE）的同时解决大规模MIMO-OFDM系统中高昂的信道开销问题，提出了一种名为多组可调相移导频（MAPSPs）的技术，以进一步提高SE。

Method: 将信道模型从空频域转换到角度-延迟域，以获得稀疏信道矩阵。然后，提出了一种通过多个基本序列生成MAPSP的方法，并研究了信道估计过程。分析了导频干扰的组成部分，阐明了干扰影响MMSE估计的机制。最后，提出了一种基于Zadoff-Chu序列的实现方案，包括接收信号预处理和导频调度方法，以减轻导频干扰。

Result: MAPSP方法实现了比APSP更低的估计均方误差（MSE），并显著提高了移动场景下的SE。

Conclusion: MAPSP是一种比APSP更有效的信道估计技术，尤其是在移动场景下，能够显著提高大规模MIMO-OFDM系统的频谱效率。

Abstract: Massive multiple-input multiple-output - orthogonal frequency division multiplexing (MIMO-OFDM) systems face the challenge of high channel acquisition overhead while providing significant spectral efficiency (SE). Adjustable phase shift pilots (APSPs) are an effective technique to acquire channels with low overhead by exploiting channel sparsity. In this paper, we extend it to multiple groups and propose multi-group adjustable phase shift pilots (MAPSPs) to improve SE further. We first introduce a massive MIMO-OFDM system model and transform the conventional channel model in the space-frequency domain to the angle-delay domain, obtaining a sparse channel matrix. Then, we propose a method of generating MAPSPs through multiple basic sequences and investigate channel estimation processes. By analyzing the components of pilot interference, we elucidate the underlying mechanism by which interference affects MMSE estimation. Building upon this foundation, we demonstrate the benefit of phase scheduling in MAPSP channel estimation and establish the optimal design condition tailored for scheduling. Furthermore, we propose an implementation scheme based on Zadoff-Chu sequences that includes received signal pre-processing and pilot scheduling methods to mitigate pilot interference. Simulation results indicate that the MAPSP method achieves a lower mean square error (MSE) of estimation than APSP and significantly enhances SE in mobility scenarios.

</details>


### [211] [ASSENT: Learning-Based Association Optimization for Distributed Cell-Free ISAC](https://arxiv.org/abs/2511.09992)
*Mehdi Zafari,A. Lee Swindlehurst*

Main category: eess.SP

TL;DR: ISAC 在分布式部署中面临可扩展性挑战，尤其是在 fronthaul 限制下。本研究提出了 ASSENT，一个基于 GNN 的框架，用于联合 AP 聚类、用户/目标调度和 AP 模式选择，实现了近乎最优的性能和更低的延迟。


<details>
  <summary>Details</summary>
Motivation: 现有的 ISAC 解决方案在分布式部署中缺乏可扩展的联合接入点（AP）聚类和用户/目标调度方法，并且过度依赖集中式处理和完整的信道状态信息，这限制了其可扩展性。本研究旨在解决分布式无细胞 ISAC 系统中在 fronthaul 容量受限的情况下，联合 AP 聚类、用户和目标调度以及 AP 模式选择的问题。

Method: 首先将问题构建为一个混合整数线性规划（MILP）模型，以联合考虑干扰耦合、射频链限制和传感需求，该模型可提供最优但计算成本高昂的解决方案。为了实现实时和可扩展的操作，提出了一种名为 ASSENT 的图神经网络（GNN）框架，该框架通过在 MILP 解决方案上进行训练，可以直接从轻量级的链路统计信息中学习关联和模式选择策略。

Result: 模拟结果表明，ASSENT 实现了接近最优的效用，并能准确学习潜在的关联。此外，与基于优化的方法相比，其单次前向传播推理能够减少决策延迟。提供了一个开源的 Python/PyTorch 实现，包含完整的数据集，以方便可复现和可扩展的无细胞 ISAC 研究。

Conclusion: ASSENT GNN 框架能够有效解决分布式无细胞 ISAC 系统中的联合 AP 聚类、用户/目标调度和 AP 模式选择问题，在保持近乎最优性能的同时，显著提高了可扩展性和降低了决策延迟，解决了现有方法的局限性。

Abstract: Integrated Sensing and Communication (ISAC) is a key emerging 6G technology. Despite progress, ISAC still lacks scalable methods for joint AP clustering and user/target scheduling in distributed deployments under fronthaul limits. Moreover, existing ISAC solutions largely rely on centralized processing and full channel state information, limiting scalability. This paper addresses joint access point (AP) clustering, user and target scheduling, and AP mode selection in distributed cell-free ISAC systems operating with constrained fronthaul capacity. We formulate the problem as a mixed-integer linear program (MILP) that jointly captures interference coupling, RF-chain limits, and sensing requirements, providing optimal but computationally demanding solutions. To enable real-time and scalable operation, we propose ASSENT (ASSociation and ENTity selection), a graph neural network (GNN) framework trained on MILP solutions to efficiently learn association and mode-selection policies directly from lightweight link statistics. Simulations show that ASSENT achieves near-optimal utility while accurately learning the underlying associations. Additionally, its single forward pass inference reduces decision latency compared to optimization-based methods. An open-source Python/PyTorch implementation with full datasets is provided to facilitate reproducible and extensible research in cell-free ISAC.

</details>


### [212] [Rotatable IRS Aided Wireless Communication](https://arxiv.org/abs/2511.10006)
*Qiaoyan Peng,Qingqing Wu,Guangji Chen,Wen Chen,Shaodan Ma,Shanpu Shen,Rui Zhang*

Main category: eess.SP

TL;DR: 本论文研究了可旋转智能反射面（IRS）在无线通信中的应用，通过优化IRS的旋转角度来最大化目标区域内的最小信噪比（SNR）。


<details>
  <summary>Details</summary>
Motivation: 为了充分发挥可旋转IRS在无线通信中的潜力，需要研究其联合优化IRS旋转角度以最大化目标区域内最小预期信噪比（SNR）的方法。

Method: 提出了一种角度相关的信道模型，该模型考虑了IRS单元的实际电磁特性。对于单点优化问题，使用粒子群优化（PSO）算法并推导出近似最优解的闭式表达式。对于区域覆盖问题，采用两层PSO迭代算法，结合零点检测来优化全局旋转角度并评估区域内的SNR分布。

Result: 所提出的可旋转IRS设计在不同系统设置下，相比于基准方案，在SNR提升方面表现出显著优势。

Conclusion: 可旋转IRS通过调整其空间自由度，能够有效提升无线通信的SNR性能。

Abstract: Rotatable intelligent reflecting surface (IRS) introduces a new spatial degree of freedom (DoF) by dynamically adjusting orientations without the need of changing its elements' positions in real time. To unleash the full potential of rotatable IRSs for wireless communications, this paper investigates the joint optimization of IRS rotation angles to maximize the minimum expected signal-to-noise ratio (SNR) over all locations within a given target area. We first propose an angle-dependent channel model that accurately characterizes the reception and reflection of each IRS element. Different from the conventional cosine-law assumption, the proposed model captures the practical electromagnetic characteristics of the IRS, including the effective reception area and reflection efficiency. For the single target location case, a particle swarm optimization (PSO)-based algorithm is developed to solve the SNR maximization problem, and a closed-form expression for a near-optimal solution is derived to provide useful insights. For the general area coverage enhancement case, the optimal rotation is obtained through a two-loop PSO-based iterative algorithm with null-point detection. In this algorithm, the outer loop updates the global rotation angles to maximize the minimum SNR over the target area, whereas the inner loop evaluates the SNR distribution within the area to identify the location corresponding to the minimum SNR through null-point detection. Numerical results demonstrate significant SNR improvement achieved by the proposed rotatable IRS design over various benchmark schemes under different system setups.

</details>


### [213] [Bridging the Initialization Gap: A Co-Optimization Framework for Mixed-Size Global Placement](https://arxiv.org/abs/2511.10073)
*Yuhao Ren,Yiting Liu,Yanfei Zhou,Zhiyu Zheng,Li Shang,Fan Yang,Zhiang Wang*

Main category: eess.SP

TL;DR: 提出了一种轻量级联合优化框架，通过面积提示的细化初始化和宏调度放置过程，解决了VLSI全局放置中初始化方法在计算成本和考虑单元面积之间的权衡问题。


<details>
  <summary>Details</summary>
Motivation: 现有的初始化方法在计算成本和考虑单元面积之间存在权衡：面积感知初始化器计算成本高，而快速的点初始化器忽略单元面积，导致模型差距，影响收敛性和解的质量。需要一种能够弥合此初始化差距的方法。

Method: 提出了一种轻量级联合优化框架，包括：1）面积提示的细化初始化器：将单元面积信息整合到有向图信号中，通过添加虚拟节点和负权重边来增强网表图，实现面积感知和谱平滑的放置初始化。2）宏调度放置过程：逐步恢复面积约束，实现从细化初始化器到完全面积感知的目标的平滑过渡。

Result: 在ISPD2005学术基准和两个真实世界的工业设计（共12个案例）上进行了评估。与点初始化器相比，该方法在12个案例中的11个案例中持续改进了半周长线长（HPWL），最大HPWL降低了2.2%，同时运行速度比最先进的面积感知初始化器快约100倍。

Conclusion: 所提出的轻量级联合优化框架通过面积提示的细化初始化和宏调度放置过程，有效解决了VLSI全局放置中的初始化挑战，在提高放置质量和降低计算成本方面取得了显著的成果。

Abstract: Global placement is a critical step with high computational complexity in VLSI physical design. Modern analytical placers formulate the placement problem as a nonlinear optimization, where initialization strongly affects both convergence behavior and final placement quality. However, existing initialization methods exhibit a trade-off: area-aware initializers account for cell areas but are computationally expensive and can dominate total runtime, while fast point-based initializers ignore cell area, leading to a modeling gap that impairs convergence and solution quality. We propose a lightweight co-optimization framework that bridges this initialization gap through two strategies. First, an area-hint refinement initializer incorporates heuristic cell area information into a signed graph signal by augmenting the netlist graph with virtual nodes and negative-weight edges, yielding an area-aware and spectrally smooth placement initialization. Second, a macro-schedule placement procedure progressively restores area constraints, enabling a smooth transition from the refined initializer to the full area-aware objective and producing high-quality placement results. We evaluate the framework on macro-heavy ISPD2005 academic benchmarks and two real-world industrial designs across two technology nodes (12 cases in total). Experimental results show that our method consistently improves half-perimeter wirelength (HPWL) over point-based initializers in 11 out of 12 cases, achieving up to 2.2% HPWL reduction, while running approximately 100 times faster than the state-of-the-art area-aware initializer.

</details>


### [214] [NOMA-Enabled Dual-IRS Relay Network Integrated with Ambient Backscatter Communication](https://arxiv.org/abs/2511.10178)
*Chandrima Thakur,Priyanka Ghosh,Rashmita Badhai,Sumit Kundu*

Main category: eess.SP

TL;DR: 该论文提出了一种结合NOMA、双IRS和环境回程的通信网络模型，并推导了其中断概率和吞吐量。


<details>
  <summary>Details</summary>
Motivation: 为了解决物联网应用中NOMA网络在阻塞条件下的可靠性和能源效率问题，提出了一种结合双IRS和环境回程通信的NOMA中继网络。

Method: 采用时间切换中继（TSR）协议，允许中继节点在收集能量和转发信息的同时支持环境回程通信。部署两个IRS来增强信号传输。推导了主通信链路和回程链路的中断概率（OP）和吞吐量（TP）的闭式表达式，并分析了不同系统参数下的吞吐量。

Result: 推导了中断概率和吞吐量的闭式表达式，并通过蒙特卡洛模拟验证了结果。数值结果揭示了主通信链路和回程链路之间存在的关键权衡。

Conclusion: 所提出的框架为设计可靠且节能的NOMA-IRS辅助回程网络提供了有价值的见解，可应用于未来的物联网应用。

Abstract: This paper analyzes a NOMA-enabled dual-Intelligent Reflecting Surface (IRS) relay network integrated with Ambient Backscatter (BS) communication. The system comprises a source, an energy-constrained relay with energy harvesting (EH) and BS capabilities, two NOMA users, and a BS node. The relay adopts a time-switching relaying (TSR) protocol to harvest energy and forward information ,while simultaneously enabling BS-based communication. Two IRS are deployed to enhance the S to R and R to (D1, D2) links under blockage conditions. Closed-form expressions for the Outage Probability (OP) and Throughput of both the main communication links and the BS-assisted secondary links are derived. Furthermore, throughput is analyzed under varying system parameters, including power allocation factors, reflection efficiency, IRS elements, and transmission rate. Monte Carlo simulations validate the analytical results. numerical findings reveal critical trade-offs between the main and RS links. The proposed framework provides useful insights for designing reliable and energy-efficient NOMA-IRS-aided BS networks for future IoT applications.

</details>


### [215] [High Order Delta-Sigma Modulation with Positive Integer Coefficients](https://arxiv.org/abs/2511.10205)
*Martin J. W. Schubert*

Main category: eess.SP

TL;DR: 分布式反馈和分布式前馈输入和多比特输出的级联 Delta-Sigma 调制器结构可以使用二项式整数参数实现高阶。


<details>
  <summary>Details</summary>
Motivation: 提出级联 Delta-Sigma 调制器结构的二项式整数参数，以实现高阶。

Method: 提出级联 Delta-Sigma 调制器结构的二项式整数参数，并讨论了参数的精度要求。

Result: 高阶可以与这些系数一起实现。

Conclusion: 二项式整数参数可用于级联 Delta-Sigma 调制器结构，以实现高阶。

Abstract: This document proposes binomial integer parameters for the cascaded Delta-Sigma-modulator structure with distributed feedback and distributed feedforward input and multi-bit output. It is demonstrated that high orders can be achieved with these coefficients. Accuracy requirements concerning the coefficients are discussed.

</details>


### [216] [Semantic Communication with Hopfield Memories](https://arxiv.org/abs/2511.10302)
*Karim Nasreddine,Christo Kurisummoottil Thomas,Walid Saad*

Main category: eess.SP

TL;DR: 所提出的方法利用现代霍普菲尔德网络（MHN）和软注意机制来构建一个内存增强的语义通信框架，以解决传统联合源信道编码中静态语义表示的局限性，实现了显著的带宽节省。


<details>
  <summary>Details</summary>
Motivation: 传统的联合源信道编码使用静态语义表示，无法适应不断变化的源分布。虽然共享语义记忆可以带来带宽节省，但需要有效的机制来判断当前内容与存储模式的相似度，而现有的基于变分自编码器的硬量化方法在数据动态性发生微小变化时也会频繁更新记忆，导致带宽利用效率低下。

Method: 提出一个内存增强的语义通信框架，利用现代霍普菲尔德网络（MHN）在发送端和接收端维护共享的语义概念记忆。该框架采用基于软注意的检索机制，能够平滑地调整语义原型权重以适应数据演变，从而在数据动态性逐渐变化时做出稳定的匹配决策。通过联合优化编码器、解码器和记忆检索机制，以最大化推理能力指标（记忆复用率和压缩率的乘积）作为目标。

Result: 理论分析确立了基本的率失真-复用权衡，并证明了与硬量化相比，软检索在语义漂移有界的情况下可以减少不必要的传输。在各种视频场景下的广泛仿真表明，所提出的基于 MHN 的方法与基线相比，平均可实现约 14% 的比特节省，在内容缓慢变化的场景下节省高达 70%。

Conclusion: 所提出的基于 MHN 的内存增强语义通信框架通过软注意机制有效解决了传统方法的局限性，在保持通信质量的同时，能够根据数据动态性自适应地调整语义表示，显著提高了带宽利用效率，尤其在处理内容缓慢变化的情况下效果更为突出。

Abstract: Traditional joint source-channel coding employs static learned semantic representations that cannot dynamically adapt to evolving source distributions. Shared semantic memories between transmitter and receiver can potentially enable bandwidth savings by reusing previously transmitted concepts as context to reconstruct data, but require effective mechanisms to determine when current content is similar enough to stored patterns. However, existing hard quantization approaches based on variational autoencoders are limited by frequent memory updates even under small changes in data dynamics, which leads to inefficient usage of bandwidth.To address this challenge, in this paper, a memory-augmented semantic communication framework is proposed where both transmitter and receiver maintain a shared memory of semantic concepts using modern Hopfield networks (MHNs). The proposed framework employs soft attention-based retrieval that smoothly adjusts stored semantic prototype weights as data evolves that enables stable matching decisions under gradual data dynamics. A joint optimization of encoder, decoder, and memory retrieval
  mechanism is performed with the objective of maximizing a reasoning capacity metric that quantifies semantic efficiency as the product of memory reuse rate and compression ratio. Theoretical analysis establishes the fundamental rate-distortion-reuse tradeoff and proves that soft retrieval reduces unnecessary transmissions compared to hard quantization under bounded semantic drift. Extensive simulations over diverse video scenarios demonstrate that the proposed MHN-based approach achieves substantial bit reductions around 14% on average and up to 70% in scenarios with gradual content changes compared to baseline.

</details>


### [217] [Evaluation of Grid-based Uncertainty Propagation for Collaborative Self-Calibration in Indoor Positioning Systems](https://arxiv.org/abs/2511.10526)
*Andrea Jung,Paul Schwarzbach,Oliver Michler*

Main category: eess.SP

TL;DR: 本研究提出了一种改进的 UWB 自校准算法，降低了测量可用性要求，并能在存在测量噪声和部分连接的情况下实现亚米级定位精度。


<details>
  <summary>Details</summary>
Motivation: 传统的基于无线电的定位系统需要预先精确标定的固定参考点，部署成本高且耗时。本研究旨在通过协作式自校准技术，降低对测量可用性的要求，同时保持高定位精度，以简化 UWB 网络的初始化过程。

Method: 本研究基于离散贝叶斯方法和基于网格的非确定性传播，提出并实现了一种增强的协作式自校准算法。该算法通过概率状态估计来减少测量可用性的要求。

Result: 在包含 12 个节点的室内 UWB 网络静态环境中进行的实验表明，在视线传播条件下，平均测距误差为 0.28 米，在混合传播场景下，总体测距误差为 1.11 米，实现了亚米级的定位精度。该算法对测量噪声和典型工业部署中常见的连接不完整情况具有鲁棒性。

Conclusion: 本研究提出的协作式自校准算法能够成功实现 UWB 网络的自动化初始化，有效降低了对人工标定参考点基础设施的依赖，为室内定位应用提供了更经济、更便捷的解决方案。

Abstract: Radio-based localization systems conventionally require stationary reference points (e.g. anchors) with precisely surveyed positions, making deployment time-consuming and costly. This paper presents an empirical evaluation of collaborative self-calibration for Ultra-Wideband (UWB) networks, extending a discrete Bayesian approach based on grid-based uncertainty propagation. The enhanced algorithm reduces measurement availability requirements while maintaining positioning accuracy through probabilistic state estimation. We validate the approach using real-world data from controlled indoor UWB network experiments with 12 nodes in a static environment. Experimental evaluation demonstrates 0.28~m mean ranging error under line-of-sight conditions and 1.11~m overall ranging error across mixed propagation scenarios, achieving sub-meter positioning accuracy. Results demonstrate the algorithm's robustness to measurement noise and partial connectivity scenarios typical in industrial deployments. The findings contribute to automated UWB network initialization for indoor positioning applications, reducing infrastructure dependency compared to manual anchor calibration procedures.

</details>


<div id='quant-ph'></div>

# quant-ph [[Back]](#toc)

### [218] [QuCoWE Quantum Contrastive Word Embeddings with Variational Circuits for NearTerm Quantum Devices](https://arxiv.org/abs/2511.10179)
*Rabimba Karanjai,Hemanth Hegadehalli Madhavarao,Lei Xu,Weidong Shi*

Main category: quant-ph

TL;DR: QuCoWE框架使用量子原生词嵌入，通过训练参数化量子电路（PQCs）和对比学习目标，在Text8和WikiText2数据集上取得了与经典基线相当的性能，同时参数更少。


<details>
  <summary>Details</summary>
Motivation: 本文旨在探索利用量子计算学习词嵌入的可能性，提出一种名为QuCoWE的框架，以期在保持或提升性能的同时，减少模型参数量。

Method: QuCoWE框架采用数据重传电路编码单词，利用量子态保真度计算相似度，并通过一个logit-fidelity head将分数与SGNS的shiftedPMI尺度对齐。为解决可训练性问题，引入基于单比特纯度的纠缠预算正则化器来缓解巴伦高原。最后，通过添加去极化读出噪声的分析和零噪声外推、随机编译等错误缓解技术来促进硬件部署。

Result: 在Text8和WikiText2数据集上，QuCoWE在WordSim353、SimLex999（内在评估）和SST2、TREC6（外在评估）任务上取得了与50-100维经典基线相当的性能，并且每个token使用的学习参数更少。

Conclusion: QuCoWE框架成功地学习了量子原生的词嵌入，并在多种评估任务中展现出与经典方法的竞争力，同时在参数效率方面具有优势，为未来在实际量子硬件上的部署奠定了基础。

Abstract: We present QuCoWE a framework that learns quantumnative word embeddings by training shallow hardwareefficient parameterized quantum circuits PQCs with a contrastive skipgram objective Words are encoded by datareuploading circuits with controlled ring entanglement similarity is computed via quantum state fidelity and passed through a logitfidelity head that aligns scores with the shiftedPMI scale of SGNSNoiseContrastive Estimation To maintain trainability we introduce an entanglementbudget regularizer based on singlequbit purity that mitigates barren plateaus On Text8 and WikiText2 QuCoWE attains competitive intrinsic WordSim353 SimLex999 and extrinsic SST2 TREC6 performance versus 50100d classical baselines while using fewer learned parameters per token All experiments are run in classical simulation we analyze depolarizingreadout noise and include errormitigation hooks zeronoise extrapolation randomized compiling to facilitate hardware deployment

</details>


### [219] [Fermi-Dirac Wigner function for massive spin-1/2 particles in local equilibrium](https://arxiv.org/abs/2511.09580)
*Sudip Kumar Kar,Valeriya Mykhaylova*

Main category: quant-ph

TL;DR: 将玻尔兹曼局域平衡维格纳函数推广到费米-狄拉克统计，并推导了宏观流的生成函数。


<details>
  <summary>Details</summary>
Motivation: 将玻尔兹曼局域平衡维格纳函数推广到费米-狄拉克统计，以确保正确的平均极化向量归一化并重现广义热力学关系。

Method: 使用费米-狄拉克统计下的维格纳函数，并推导了宏观流的生成函数。

Result: 推导了宏观流的生成函数，并表明该框架可以归类为散度型理论。

Conclusion: 所提出的费米-狄拉克维格纳函数能够正确处理宏观流的计算，并为该理论提供了一个散度型分类。

Abstract: A recently proposed Boltzmann local equilibrium Wigner function for massive spin-1/2 particles is generalized to the case of Fermi-Dirac statistics. The resulting formula ensures the correct normalization of the mean polarization vector and reproduces the generalized thermodynamic relations with spin that were obtained in earlier studies. Moreover, we show that the macroscopic currents constructed from the Fermi-Dirac Wigner function can be obtained as derivatives of a suitably defined generating function with respect to the Lagrange multipliers (temperature, hydrodynamic flow, and chemical potentials). The identified generating function also indicates that the underlying framework can be classified as a divergence-type theory.

</details>


### [220] [Quantum Frustration as a Protection Mechanism in Non-Topological Majorana Qubits](https://arxiv.org/abs/2511.09591)
*E. Novais*

Main category: quant-ph

TL;DR: 该研究分析了由两个Majorana模式编码的π-结量子比特的退相干性，并提出量子挫败机制来对抗环境噪声和准粒子毒害（QP）。


<details>
  <summary>Details</summary>
Motivation: 研究π-结量子比特的退相干性，并探索量子挫败机制在对抗环境噪声和准粒子毒害方面的有效性。

Method: 通过分析π-结量子比特的量子挫败机制，测试其在不同类型噪声（Ohmic、$1/f$噪声）下的表现，并考虑准粒子毒害（QP）的威胁。

Result: 量子挫败机制对Ohmic噪声（s=1）有效，对亚Ohmic噪声（0.76<s<1）有一定保护作用。然而，对于实验中常见的$1/f$噪声（s→0），量子挫败机制不足以防止自发对称破缺和灾难性退相干。

Conclusion: π-结量子比特的可用性取决于其Majorana波函数所经历的有效环境。在何种环境下。

Abstract: I analyze the decoherence of a $π$-junction qubit encoded by two co-located Majorana modes. Although not topologically protected, the qubit leverages distinct spatial profiles to couple to two independent environmental baths, realizing the phenomenon of quantum frustration.This mechanism is tested against the threat of quasiparticle poisoning (QP). I show that frustration is effective against Ohmic noise ($s=1$) and has some protection for $0.76<s<1$ sub-Ohmic noise. However, the experimentally prevalent $1/f$ noise ($s\to0$) falls deep within the model's localized phase, where frustration is insufficient. This causes Spontaneous Symmetry Breaking and catastrophic decoherence. The qubit's viability depends on what is the effective environment that these local Majorana wave functions experience.

</details>


### [221] [Cooling the Sachdev-Ye-Kitaev model using thermofield double states](https://arxiv.org/abs/2511.09620)
*Thomas Schuster,Bryce Kobrin,Vincent P. Su,Hugo Marrochio,Norman Y. Yao*

Main category: quant-ph

TL;DR: 通过数值模拟和理论分析，提出了一种冷却SYK模型到低温度的简单有效实验方案，该方案利用两个SYK模型的局部耦合来创造一个绝热路径，并基于本征态热化理论提供了微观解释，表明该方案可能适用于更广泛的强相互作用量子哈密顿量。


<details>
  <summary>Details</summary>
Motivation: 提出一种冷却SYK模型至低温的简单有效实验方案。

Method: 利用两个SYK模型的局部耦合创建绝热路径，通过数值求解大N运动方程进行支持，并基于本征态热化理论进行微观解释。

Result: 证明了冷却方案的有效性，并通过求解大N方程的精确数值解支持了冷却到低温引力区域的预测。

Conclusion: 该冷却方案有效，并且基于本征态热化理论的解释表明其可能广泛适用于冷却强相互作用量子哈密顿量。

Abstract: We analyze a simple and efficient experimental protocol to cool the Sachdev-Ye-Kitaev (SYK) model to low temperatures. The protocol utilizes local couplings between two copies of an SYK model to create a gapped adiabatic path, between a high temperature product state and a low temperature thermofield double state. By smoothly varying the coupling strength between these two limits, one efficiently cools the SYK model. We support these predictions-and demonstrate fast cooling to the low-temperature gravitational regime-via exact numerical solutions to the large-N equations of motion that govern the ground state and dynamical properties of the coupled system. Finally, we present a theoretical framework based upon eigenstate thermalization that provides a microscopic explanation for the efficacy of the cooling protocol; intriguingly, this suggests that the protocol may be applicable for cooling strongly-interacting quantum Hamiltonians more broadly.

</details>


### [222] [Temporal quantum interference in many-body programmable atom arrays](https://arxiv.org/abs/2511.09633)
*Madhumita Sarkar,Ben Zindorf,Bhaskar Mukherjee,Sougato Bose,Roopayan Ghosh*

Main category: quant-ph

TL;DR: 通过可编程里德堡原子阵列中的多体斯图克尔伯格干涉，实现了可控的真空态冻结，并验证了其在量子控制中的潜力。


<details>
  <summary>Details</summary>
Motivation: 探索量子叠加的时间类似现象——斯图克尔伯格干涉在大规模相互作用系统中的应用，并克服多体相互作用带来的挑战。

Method: 在最多100个原子的可编程里德堡原子阵列中，利用双频协议同时调制失谐和拉比频率，实现多体斯图克尔伯格干涉，并进行单频和双频协议、不同几何结构以及考虑有限范围相互作用的对比实验。

Result: 实现了超过70%可见度的真空态冻结，并将激发抑制到1%，证明了该方法在驱动系统中的鲁棒性。发现了有限范围相互作用在干涉模式形成中的关键作用，这是受限的PXP模型无法解释的。

Conclusion: 证明了时间干涉作为一种可扩展的微观机制，可用于傅科（Floquet）控制，从而在大型平台上实现可预测的多体态工程。

Abstract: Quantum superposition famously manifests as spatial interference, epitomized by the double-slit experiment. Its less explored temporal analogue, Stückelberg interference, arises in driven systems where phases accumulated along distinct time-domain pathways recombine. Extending this phenomenon to large interacting systems introduces a new complexity as delicate phase relationships are disrupted by many-body interactions. Here we experimentally achieve controllable vacuum-state freezing in programmable Rydberg arrays of up to 100 atoms through many-body Stückelberg interference, with visibility exceeding $70\%$ and excitation suppression to $1\%$ despite periodic driving that would typically induce heating. Comparing single and dual-frequency protocols across multiple geometries, we show that simultaneous modulation of detuning and Rabi frequency dramatically enhances interference-driven freezing. Finite-range interaction tails play a decisive role, producing interference patterns which constrained $PXP$ models cannot capture. Our results establish temporal interference as a scalable microscopic mechanism for Floquet control, enabling predictive many-body state engineering in large-scale platforms.

</details>


### [223] [A measurement-driven quantum algorithm for SAT: Performance guarantees via spectral gaps and measurement parallelization](https://arxiv.org/abs/2511.09647)
*Franz J. Schreiber,Maximilian J. Kramer,Alexander Nietner,Jens Eisert*

Main category: quant-ph

TL;DR: 研究了一种新的测量驱动的量子SAT求解器，并进行了严格的最坏情况运行时间分析，展示了其在特定类型问题上的多项式时间潜力。


<details>
  <summary>Details</summary>
Motivation: 现有量子算法在SAT问题上的优势受限于Grover类方法提供的二次加速，寻找超越二次加速的方法是关键挑战。

Method: 对一种新的测量驱动的量子SAT求解器进行了最坏情况运行时间分析，该分析基于Hamiltonian的谱隙和驱动测量的成功概率之间的指数权衡，并通过可调谐的旋转角度进行控制。同时，提出了一种新的读出例程、一种基于完美哈希族的测量并行化方案，并建立了一个幅度放大的算法版本。

Result: 分析表明，该算法的最坏情况运行时间依赖于谱隙和测量成功概率之间的指数权衡，该权衡可通过旋转角度控制。通过调度算法参数，该算法在特定类型SAT实例上的运行时间可从指数级降低到多项式级。

Conclusion: 该研究为测量驱动的量子SAT求解器提供了严格的最坏情况运行时间分析，并提出了显著的算法改进，包括高效的读出例程、测量并行化和幅度放大版本。通过参数调度，该算法在特定实例上实现了从指数到多项式的运行时间崩溃，预示着超二次量子优势的潜力。但仍存在关于谱隙非平凡下界的开放性问题。

Abstract: The Boolean satisfiability problem (SAT) is of central importance in both theory and practice. Yet, most provable guarantees for quantum algorithms rely exclusively on Grover-type methods that cap the possible advantage at only quadratic speed-ups, making the search for approaches that surpass this quadratic barrier a key challenge. In this light, this work presents a rigorous worst-case runtime analysis of a recently introduced measurement-driven quantum SAT solver. Importantly, this quantum algorithm does not exclusively rely on Grover-type methods and shows promising numerical performance. Our analysis establishes that the algorithm's runtime depends on an exponential trade-off between two key properties: the spectral gap of the associated Hamiltonian and the success probability of the driving measurements. We show that this trade-off can be systematically controlled by a tunable rotation angle. Beyond establishing a worst-case runtime expression, this work contributes significant algorithmic improvements. First, we develop a new readout routine that efficiently finds a solution even for instances with multiple satisfying assignments. Second, a measurement parallelization scheme, based on perfect hash families, is introduced. Third, we establish an amplitude-amplified version of the measurement-driven algorithm. Finally, we demonstrate the practical utility of our framework: By suitably scheduling the algorithm's parameters, we show that its runtime collapses from exponential to polynomial on a special class of SAT instances, consistent with their known classical tractability. A problem we leave open is to establish a non-trivial lower bound on the spectral gap as a function of the rotation angle. Resolving this directly translates into an improved worst-case runtime, potentially realizing a super-quadratic quantum advantage.

</details>


### [224] [Non-abelian Geometric Quantum Energy Pump](https://arxiv.org/abs/2511.09651)
*Yang Peng*

Main category: quant-ph

TL;DR: 我们提出了一种非阿贝尔几何量子能量泵，它通过无过渡的几何量子驱动来实现——一个依赖于时间的哈密顿量，并补充了一个由平滑控制流形上的规定轨迹产生的反绝热项——它在简并子空间内相干地输运状态。


<details>
  <summary>Details</summary>
Motivation: 当轨迹的坐标可以通过外部驱动独立寻址时，驱动器之间传递的总能量由非阿贝尔 Berry-曲率张量决定。

Method: 我们提出了一种非阿贝尔几何量子能量泵，它通过无过渡的几何量子驱动来实现——一个依赖于时间的哈密顿量，并补充了一个由平滑控制流形上的规定轨迹产生的反绝热项——它在简并子空间内相干地输运状态。

Result: 能量泵可以作为量子换能器或充电器，以及测量量子态中相位相干性的计量工具。

Conclusion: 我们概述了使用人工原子的实现方法，该方法可以在各种平台上实现，包括囚禁原子/离子、超导电路和半导体量子点。

Abstract: We introduce a non-abelian geometric quantum energy pump realized by a transitionless geometric quantum drive--a time-dependent Hamiltonian supplemented by a counterdiabatic term generated by a prescribed trajectory on a smooth control manifold--that coherently transports states within a degenerate subspace. When the coordinates of the trajectory are independently addressable by external drives, the net energy transferred between drives is set by the non-abelian Berry-curvature tensor. The trajectory-averaged pumping power is separately controlled by the initial state and by the Hamiltonian topology through the Euler class. We outline an implementation with artificial atoms, which are realizable on various platforms including trapped atoms/ions, superconducting circuits, and semiconductor quantum dots. The resulting energy pump can serve as a quantum transducer or charger, and as a metrological tool for measuring phase coherences in quantum states.

</details>


### [225] [Optimal Interpolation of Entanglement Purification Protocols](https://arxiv.org/abs/2511.09657)
*Matthew Barber,Stefano Pirandola*

Main category: quant-ph

TL;DR: 通过根据概率分布随机选择不同的纠缠净化协议，可以实现比任何单一协议都高的纠缠净化速率和保真度。


<details>
  <summary>Details</summary>
Motivation: 在分离的双方之间共享弱纠缠对时，可以使用本地操作和经典通信将其转换为更少的高质量纠缠对，然而，选择不同的纠缠净化协议需要在产率和纠缠度（保真度）之间进行权衡。

Method: 通过根据概率分布随机选择纠缠净化协议，以优化特定保真度下的产率，或在特定产率下的保真度。

Result: 实现了比任何单一协议都高的产率和保真度，并同时考虑了渐进情况和有限情况。

Conclusion: 通过策略性地选择用于纠缠净化的协议，可以超越现有协议的限制，从而在量子通信和计算中实现更高效的纠缠分发。

Abstract: Bipartite entanglement purification is the conversion of copies of weakly entangled pairs shared between two separated parties into a smaller number of strongly entangled shared pairs using only local operations and classical communication. Choosing between different entanglement purification protocols generally involves weighing up a trade-off between the ratio of strongly entangled pairs produced to weakly entangled pairs consumed, which we call the rate of the protocol, and the degree of the entanglement of the strongly entangled pairs, typically measured by the fidelity of those pairs to maximally entangled states. By randomly choosing a protocol according to a probability distribution over a list of protocols for each pair we want to produce, we can achieve rates and fidelities not achieved by any of the original protocols. Here, we show how to choose this distribution to maximise the rate at which we produce qubit pairs with a given fidelity to a Bell state or, equivalently, to maximise the fidelity to a Bell state of the qubit pairs produced at a given rate. We investigate both the asymptotic case, where the number of initial pairs goes to infinity, and the finite-size regime, where protocols are restricted to a finite number of weakly entangled pairs.

</details>


### [226] [Cyclic Hypergraph Product Code](https://arxiv.org/abs/2511.09683)
*Arda Aydin,Nicolas Delfosse,Edwin Tham*

Main category: quant-ph

TL;DR: 引入对称性到超图乘积码以提高量子纠错性能，并提出一种适用于QCCD架构的平面布局。


<details>
  <summary>Details</summary>
Motivation: 为提高量子纠错码（特别是超图乘积码）的性能，克服现有方法（如机器学习）的局限性，并降低量子比特开销。

Method: 通过引入额外的全局对称性，并进行穷举搜索，专注于两种特定的超图乘积码：CxC码（两个循环码的乘积）和CxR码（循环码与重复码的乘积）。为QCCD架构设计了高效的平面布局，实现了常数深度的陷阱离子实现。

Result: 发现的C2码和CxR码在逻辑错误率和量子比特开销方面显著优于先前优化的HGP码，逻辑错误率每逻辑比特低三倍。一些C2码同时实现了比最先进的LDPC码（如双变量自行车码）更低的逻辑错误率和更小的量子比特开销，但块长较大。设计了适用于QCCD架构的平面布局，支持常数深度的陷阱离子实现。

Conclusion: 通过引入全局对称性和进行穷举搜索，发现了性能优于现有方法的超图乘积码。所提出的平面布局为在QCCD架构上实现高效的量子纠错提供了可能。

Abstract: Hypergraph product (HGP) codes are one of the most popular family of quantum low-density parity-check (LDPC) codes. Circuit-level simulations show that they can achieve the same logical error rate as surface codes with a reduced qubit overhead. They have been extensively optimized by importing classical techniques such as the progressive edge growth, or through random search, simulated annealing or reinforcement learning techniques. In this work, instead of machine learning (ML) algorithms that improve the code performance through local transformations, we impose additional global symmetries, that are hard to discover through ML, and we perform an exhaustive search. Precisely, we focus on the hypergraph product of two cyclic codes, which we call CxC codes and we study C2 codes which are the product a cyclic code with itself and CxR codes which are the product of a cyclic codes with a repetition code. We discover C2 codes and CxR codes that significantly outperform previously optimized HGP codes, achieving better parameters and a logical error rate per logical qubit that is up to three orders of magnitude better. Moreover, some C2 codes achieve simultaneously a lower logical error rate and a smaller qubit overhead than state-of-the-art LDPC codes such as the bivariate bicycle codes, at the price of a larger block length. Finally, leveraging the cyclic symmetry imposed on the codes, we design an efficient planar layout for the QCCD architecture, allowing for a trapped ion implementation of the syndrome extraction circuit in constant depth.

</details>


### [227] [Trotterized Variational Quantum Control for Spin-Chain State Transfer](https://arxiv.org/abs/2511.09684)
*Nahid Binandeh Dehaghani,Rafal Wisniewski,A. Pedro Aguiar*

Main category: quant-ph

TL;DR: 我们提出了一个混合变分框架，用于高保真度量子态转移的量子最优控制，该框架将系统动力学离散化并编译为参数化电路。通过可训练的 RZ 旋转来编码控制输入，并研究了全局和局部两种参数化方案。


<details>
  <summary>Details</summary>
Motivation: 高保真度量子态转移是量子信息处理的基本任务，而有效的量子最优控制是实现这一目标的途径。

Method: 该框架将系统动力学离散化并编译为参数化电路，其中确定性的两比特块实现漂移相互作用，而可训练的 RZ 旋转则编码控制输入。研究了两种参数化：全局方案和局部方案。使用序贯最小二乘二次规划（SLSQP）优化来最小化保真度。

Result: 在 XXZ 自旋链上的模拟表明，两种参数化方案在无噪声情况下均可实现接近单位的保真度。在去极化噪声下，全局方案在相当的电路深度和迭代预算下表现出更强的鲁棒性。

Conclusion: 该研究明确了表达能力-稳定性之间的权衡，并为噪声中等规模量子（NISQ）兼容的控制综合提供了一条可扩展的路线。

Abstract: We present a hybrid variational framework for quantum optimal control aimed at high-fidelity state transfer in spin chains. The system dynamics are discretized and compiled into a parameterized circuit, where deterministic two-qubit blocks implement the drift interactions, while trainable on-site RZ rotations encode the control inputs. We study two parameterizations: a compact global scheme with a small number of shared parameters per slice, and a local scheme with site-wise angles. Using a Sequential Least Squares Quadratic Programming (SLSQP) optimization to minimize infidelity, simulations on XXZ spin chains show that both parameterizations can achieve near-unit fidelities in the noiseless regime. Under depolarizing noise, the global scheme provides improved robustness for comparable circuit depth and iteration budgets. The results make explicit an expressivity-stability trade-off and suggest a scalable route to Noisy Intermediate-Scale Quantum (NISQ) compatible control synthesis.

</details>


### [228] [Two-Mode Janus States: non-Gaussian generalizations of thermofield double](https://arxiv.org/abs/2511.09704)
*Arash Azizi*

Main category: quant-ph

TL;DR: 该论文引入了一种名为“双模扬尼斯态”（TMJS）的新型非高斯量子态，它是两种不同双模压缩态（TMSS）的相干叠加。该态推广了热场对偶（TFD）态，并提出了一种通过“扬尼斯相位”动态控制其非高斯性的方法，可以调节其光子统计特性，甚至实现负Wigner函数。论文还提出了通过动力学卡西米尔效应（DCE）实现TMJS的物理方案，并将其应用于工程化探测器响应和研究相对论性量子物理。


<details>
  <summary>Details</summary>
Motivation: 构建一种非高斯量子态，作为热场对偶（TFD）态的直接推广，并探索其可控性及其在物理学中的潜在应用。

Method: 定义双模扬尼斯态（TMJS）为两种双模压缩态（TMSS）的相干叠加；推导并分析了TMJS任意k阶光子统计特性，引入了“压缩多项式”；研究了外部“扬尼斯相位”对态特性的调控作用，特别是高阶相干性（g^(k)）；提出了通过相干叠加动力学卡西米尔效应（DCE）实现TMJS的物理方案。

Result: 推导了TMJS的k阶光子统计公式，并识别出控制这些矩的“压缩多项式”；证明了“扬尼斯相位”可以动态地控制TMJS的非高斯性，使其从热态变为强负Wigner函数下的亚泊松分布；提出了通过DCE实现TMJS的可行方案，并将其与Unruh效应区分开；展示了TMJS在工程化Unruh-DeWitt探测器响应和研究相对论性非高斯物理方面的潜力。

Conclusion: 双模扬尼斯态（TMJS）是一种可控的非高斯量子态，通过“扬尼斯相位”可以调节其统计特性，并可通过动力学卡西米尔效应实现。该态为研究量子物理和相对论效应提供了一个新的平台。

Abstract: We introduce the Two-Mode Janus State (TMJS), a non-Gaussian quantum state defined as a coherent superposition of two distinct Two-Mode Squeezed States (TMSS). This construction serves as a direct, non-Gaussian generalization of the canonical thermofield double (TFD) state, which is itself a single, Gaussian TMSS. We develop a complete analytical framework for the TMJS's arbitrary $k$-th order photon statistics, identifying a new family of "squeezing polynomials" that govern all diagonal and off-diagonal moments. Our central result is that the state's non-Gaussianity is dynamically steerable via an external "Janus phase." This phase acts as a switch, allowing the higher-order coherences ($g^{(k)}$) to be tuned from perfectly thermal (matching the TFD marginal) to deeply sub-Poissonian, a regime marked by strong Wigner negativity. We further establish a physical realization for the TMJS, proposing its generation via coherently superposed Dynamical Casimir Effect (DCE) trajectories, distinguishing it from the static, observer-dependent Unruh effect. The TMJS provides a versatile, interference-enhanced platform for engineering Unruh-DeWitt detector responses and probing non-Gaussian physics in relativistic settings.

</details>


### [229] [Liquid metal printing for superconducting circuits](https://arxiv.org/abs/2511.09705)
*Alexander Kreiner,Navid Hussain,Ritika Dhundhwal,Haoran Duan,Nicolas Zapata,Gabriel Cadilha Marques,Tino Cubaynes,Torsten Scherer,Wolfgang Wernsdorfer,Michael Hirtz,Ioan Mihai Pop,Jasmin Aghassi-Hagmann,Thomas Reisinger*

Main category: quant-ph

TL;DR: 基于液态金属微量移液管打印技术可制造出高质量的超导电路，为扩展超导量子计算机硬件实现提供了新途径。


<details>
  <summary>Details</summary>
Motivation: 传统超导电路制造依赖于标准纳米光刻技术，而增材制造方法因可能影响超导性能和量子相干性而未被采用。本研究旨在探索一种新的制造方法。

Method: 使用液态金属基微量移液管打印技术制造超导集总式谐振器。

Result: 制造出的超导集总式谐振器的内部品质因数很高，且该技术适用于低损耗超导器件制造，并能在不影响预存电路元件的情况下局部添加金属结构。

Conclusion: 液态金属基微量移液管打印技术可用于制造高质量超导电路，为扩展超导量子计算机硬件实现提供了新的可能性。

Abstract: Superconducting circuits are a promising platform for implementing fault-tolerant quantum computers, quantum limited amplifiers, ultra-low power superconducting electronics, and sensors with ultimate sensitivity. Typically, circuit fabrication is realized by standard nanolithography, generally associated with a high level of control over defects and contaminants. Additive approaches have not been used so far since they are expected to be inferior in terms of superconducting properties or quantum coherence. This work shows that liquid-metal based micro-pipette printing is suited for fabricating superconducting lumped-element resonators with high internal quality factors. The applicability of our technique for low-loss superconducting device fabrication and the possibility to locally add metal structures, without affecting any preexisting circuit elements, is a further advantage. Our results open up new avenues in the hardware implementation of scaled-up superconducting quantum computers.

</details>


### [230] [Constrained Shadow Tomography for Molecular Simulation on Quantum Devices](https://arxiv.org/abs/2511.09717)
*Irma Avdic,Yuchen Wang,Michael Rose,Lillian I. Payne Torres,Anna O. Schouten,Kevin J. Sung,David A. Mazziotti*

Main category: quant-ph

TL;DR: 该研究提出了一种双目标半定规划方法，用于从有噪声或不完整的经典投影数据中重构两粒子约化密度矩阵（2-RDM）。


<details>
  <summary>Details</summary>
Motivation: 由于量子态层析成像在测量和计算上的指数级需求限制了其可扩展性，需要高效的替代方法，例如经典投影，它可以从随机测量中准确预测许多可观测量。

Method: 提出了一种双目标半定规划方法，通过整合 N-可表性约束和核范数正则化，构建了一个 N-可表 2-RDM，在保真度和能量最小化之间取得平衡。

Result: 该方法显著提高了精度、抗噪声能力和可扩展性。

Conclusion: 该框架提供了一个坚实的基础，可以在实际量子模拟中实现物理上一致的费米子态重构。

Abstract: Quantum state tomography is a fundamental task in quantum information science, enabling detailed characterization of correlations, entanglement, and electronic structure in quantum systems. However, its exponential measurement and computational demands limit scalability, motivating efficient alternatives such as classical shadows, which enable accurate prediction of many observables from randomized measurements. In this work, we introduce a bi-objective semidefinite programming approach for constrained shadow tomography, designed to reconstruct the two-particle reduced density matrix (2-RDM) from noisy or incomplete shadow data. By integrating $N$-representability constraints and nuclear-norm regularization into the optimization, the method builds an $N$-representable 2-RDM that balances fidelity to the shadow measurements with energy minimization. This unified framework mitigates noise and sampling errors while enforcing physical consistency in the reconstructed states. Numerical and hardware results demonstrate that the approach significantly improves accuracy, noise resilience, and scalability, providing a robust foundation for physically consistent fermionic state reconstruction in realistic quantum simulations.

</details>


### [231] [Local arrows of time in quantum many-body systems](https://arxiv.org/abs/2511.09758)
*Andrew G. Yates,Jordan Cotler,Nishad Maskara,Mikhail D. Lukin*

Main category: quant-ph

TL;DR: 局部时间箭头在量子多体系统中可以与哈密顿演化诱导的全局时间不同，表明时间流相对于局部子系统是相对的。


<details>
  <summary>Details</summary>
Motivation: 本文的动机在于探索量子多体系统中局部时间箭头的概念，以及它与全局时间的可能差异，揭示时间流的相对性。

Method: 文章通过定义量子多体系统中的局部时间箭头，并阐述其与时空量子熵的关系，然后通过多种数值和分析示例来探索局部时间箭头在量子多体动力学中的不同表现形式。

Result: 研究结果表明，局部时间箭头可以表现出与全局时间不同的时间流，并且在量子热化和量子纠错等场景中会出现奇异的时间箭头。

Conclusion: 本文得出结论，局部时间箭头在量子多体系统中是存在的，并且其行为可能因局部子系统的不同而异，这为理解量子动力学和时间本身提供了新的视角。

Abstract: We demonstrate that in quantum many-body systems, local arrows of time can differ from the global time $t$ induced by Hamiltonian evolution. That is, within a quantum many-body system, the flow of time can be relative to each observer or by proxy each local subsystem. We provide a definition of local arrows of time in quantum many-body systems, and explain their relation to spacetime quantum entropies. Then we give a variety of numerical and analytical examples which explore different ways in which local arrows of time can manifest in quantum many-body dynamics, including exotic arrows of time arising from quantum thermalization and quantum error correction.

</details>


### [232] [On the Classical Shadow Nonparametric Bootstrap](https://arxiv.org/abs/2511.09793)
*Eric Ghysels,Jack Morgan*

Main category: quant-ph

TL;DR: 我们提出了一种使用自举重采样方法增强经典阴影（classical shadows）的方法，并表明自举分布与高斯近似有很大不同，同时为风险评估提供了新的工具。


<details>
  <summary>Details</summary>
Motivation: 为了提高经典阴影方法对量子态的估计精度和准确性评估能力，弥补现有方法在处理测量数据变异性和误差界定方面的不足。

Method: 将非参数自举重采样方法应用于经典阴影测量数据，通过有放回地重复抽样来评估估计量的变异性和准确性。

Result: 自举分布与高斯近似存在显著差异，且理论误差界限不如自举百分位数紧密。

Conclusion: 自举重采样方法能够更准确地评估经典阴影方法的精度和变异性，并可用于风险评估。

Abstract: Classical shadows are an efficient method for constructing an approximate classical description of a quantum state using very few measurements. In the paper we propose to enhance classical shadow methods using bootstrap resampling methods. We apply nonparametric bootstrapping to assess the variability and accuracy of estimators by repeatedly sampling with replacement from the observed data, i.e.\ in our case the classical shadow measurements. We show that the bootstrap distributions are very different from the Gaussian approximations. Likewise, the theoretical error bounds are not tight compared to the bootstrap percentiles. Finally, we suggest using resampling tools to make risk assessments.

</details>


### [233] [Uncovering and Circumventing Noise in Quantum Algorithms via Metastability](https://arxiv.org/abs/2511.09821)
*Antonio Sannia,Pratik Sathe,Luis Pedro García-Pintos*

Main category: quant-ph

TL;DR: 量子硬件中的噪声具有亚稳态特性，可以通过设计能够感知噪声的数字和模拟算法来利用，从而实现内在的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 量子计算中的主要挑战是在容错量子计算机中消除噪声的影响。

Method: 提出并实验验证了一种利用亚稳态（具有长寿命中间态的动力学系统）来规避噪声的新策略。开发了一个通用的理论框架，并引入了一个易于计算的噪声鲁棒性度量，以避免对量子算法进行完整的经典模拟。将该框架应用于变分量子算法和模拟绝热态制备。

Result: 实验证明，如果量子硬件噪声表现出亚稳态，则可以设计出具有内在鲁棒性的数字和模拟算法。在门模型量子处理器和量子退火设备上提供了支持亚稳态噪声存在的实验证据。

Conclusion: 近期的量子硬件中噪声的内在性质可以被利用来指导实际实现策略，从而制备出更接近理想状态的、最终的噪声状态。

Abstract: The presence of noise is the primary challenge in realizing fault-tolerant quantum computers. In this work, we introduce and experimentally validate a novel strategy to circumvent noise by exploiting the phenomenon of metastability, where a dynamical system exhibits long-lived intermediate states. We demonstrate that if quantum hardware noise exhibits metastability, both digital and analog algorithms can be designed in a noise-aware fashion to achieve intrinsic resilience. We develop a general theoretical framework and introduce an efficiently computable noise resilience metric that avoids the need for full classical simulation of the quantum algorithm. We illustrate the use of our framework with applications to variational quantum algorithms and analog adiabatic state preparation. Crucially, we provide experimental evidence supporting the presence of metastable noise in gate-model quantum processors as well as quantum annealing devices. Thus, we establish that the intrinsic nature of noise in near-term quantum hardware can be leveraged to inform practical implementation strategies, enabling the preparation of final noisy states that more closely approximate the ideal ones.

</details>


### [234] [Mapping Game Theory to Quantum Systems: Nash Equilibria via Neutral Atom Computing](https://arxiv.org/abs/2511.09841)
*Giovanni Ferrannini,Dario di Gregorio,Federico Fissore*

Main category: quant-ph

TL;DR: 本研究将博弈论中的纳什均衡问题与优化问题联系起来，并利用量子计算方法（里德堡原子阵列）来寻找纳什均衡，特别是在单位圆图上的最大独立集问题。


<details>
  <summary>Details</summary>
Motivation: 寻找纳什均衡具有挑战性（NP-Hard复杂性），但其在经济学、物理学、生物学和计算机科学等领域有重要应用，并且与优化问题紧密相关。

Method: 通过利用单位圆图上的最大独立集与纳什均衡的对应关系，将问题映射到里德堡原子阵列的基态构型。

Result: 通过模拟展示了该量子方法在寻找纳什均衡方面的有效性。

Conclusion: 该量子方法有潜力解决博弈论中的复杂问题。

Abstract: Nash equilibria are crucial for understanding game behavior and systems in economics, physics, biology, and computer science. A significant application arises from the connection between Nash equilibria and optimization problems . However, finding Nash equilibria is challenging due to its NP-Hard complexity, specifically within the PPAD class. By exploiting the correspondence between Maximum Independent Sets (MIS) and Nash equilibria on unit-disk graphs, we map these problems onto the ground state configurations of Rydberg atom arrays. Simulations show the effectiveness of this quantum method, highlighting its potential for solving complex problems in game theory.

</details>


### [235] [Discrete Time Crystals in Noninteracting Dissipative Systems](https://arxiv.org/abs/2511.09852)
*Gourab Das,Saptarshi Saha,Rangeet Bhattacharyya*

Main category: quant-ph

TL;DR: 在一个非相互作用的系统中，由于环境耗散的存在，我们可以实现一个稳定的离散时间晶体（DTC）相，其寿命不依赖于初始条件和系统大小，但依赖于外部驱动的频率。我们通过核磁共振光谱技术实验证明了这一点。


<details>
  <summary>Details</summary>
Motivation: 在先前研究中，DTC相在耗散存在的情况下是不稳定的，但本文旨在探索在耗散存在的情况下实现稳定的DTC相。

Method: 通过在一个非相互作用的系统中引入环境耗散来稳定DTC相，并通过核磁共振光谱进行实验验证。

Result: 在一个非相互作用的系统中，由于环境耗散的存在，我们实现了一个稳定的DTC相，其寿命不依赖于初始条件和系统大小，但依赖于外部驱动的频率。

Conclusion: 本文成功地在一个非相互作用的系统中，利用环境耗散实现了一个稳定的DTC相，这为理解和应用DTC相提供了新的途径。

Abstract: Many-body quantum systems, under suitable conditions, exhibit time-translation symmetry breaking and settle in a discrete time crystalline (DTC) phase -- an out-of-equilibrium quantum phase of matter. The defining feature of DTC is a robust subharmonic response. However, the DTC phase is fragile in the presence of environmental dissipation. Here, we propose and exemplify a DTC phase in a noninteracting system that owes its stability to environmental dissipation. The lifetime of this DTC is independent of initial conditions and the size of the system, though it depends on the frequency of the external driver. We experimentally demonstrate this realization of DTC using Nuclear Magnetic Resonance spectroscopy.

</details>


### [236] [Quantum Period-Finding using One-Qubit Reduced Density Matrices](https://arxiv.org/abs/2511.09896)
*Marco Bernardi*

Main category: quant-ph

TL;DR: 该研究提出了一种从量子周期查找（QPF）算法的单量子比特约化密度矩阵（1-RDMs）中提取周期的新方法，而非依赖于测量整个量子电路的输出位串。


<details>
  <summary>Details</summary>
Motivation: 标准量子周期查找（QPF）算法依赖于测量输出态的多个高概率位串来确定函数周期。本研究旨在探索一种替代方法，即仅利用单量子比特约化密度矩阵（1-RDMs）来提取周期信息，从而可能简化或改进QPF算法。

Method: 通过状态向量模拟计算QPF电路的1-RDMs，并分析这些1-RDMs随周期的变化模式。利用数值求根方法从1-RDMs中提取周期。

Result: 研究表明，1-RDMs（一组O(n)的单量子比特边际量）包含了足够的信息来重建周期，这通常需要采样O(2^n)个位串的空间。这可以被视为QPF算法信息的一种“压缩”。

Conclusion: 1-RDMs包含了QPF算法的关键信息，可用于提取周期，为开发新的周期查找算法提供了理论基础，并启发了对约化密度矩阵近似模拟的研究。

Abstract: The quantum period-finding (QPF) algorithm can compute the period of a function exponentially faster than the best-known classical algorithm. In standard QPF, the output state has a primary contribution from $r$ high-probability bit strings, where $r$ is the period. Measurement of this state, combined with continued fraction analysis, reveals the unknown period. Here, we explore a different approach to QPF, where the period is obtained from single-qubit quantities $-$ specifically, the set of one-qubit reduced density matrices (1-RDMs) $-$ rather than the output bit strings of the entire quantum circuit. Using state-vector simulations, we compute the 1-RDMs of the QPF circuit for a generic periodic function. Analysis of these 1-RDMs as a function of period reveals distinctive patterns, which allows us to obtain the unknown period from the 1-RDMs using a numerical root-finding approach. Our results show that the 1-RDMs $-$ a set of $O(n)$ one-qubit marginals $-$ contain enough information to reconstruct the period, which is typically obtained by sampling the space of $O(2^n)$ bit strings. Conceptually, this can be viewed as a "compression" of the information in the QPF algorithm, which enables period-finding from $n$ one-qubit marginals. Our results motivate the development of approximate simulations of reduced density matrices to design novel period-finding algorithms.

</details>


### [237] [Provably Efficient Quantum Algorithms for Solving Nonlinear Differential Equations Using Multiple Bosonic Modes Coupled with Qubits](https://arxiv.org/abs/2511.09939)
*Yu Gan,Hirad Alipanah,Jinglei Cheng,Zeguan Wu,Guangyi Li,Juan José Mendoza-Arenas,Peyman Givi,Mujeeb R. Malik,Brian J. McDermott,Junyu Liu*

Main category: quant-ph

TL;DR: 使用连续变量的量子算法，通过模拟耦合的玻色子模式和基于量子比特的自适应测量，可以比经典计算机更有效地解决非线性偏微分方程，并且在容错和近似方面具有可证明的优势。


<details>
  <summary>Details</summary>
Motivation: 目前大多数量子算法通过数字方法（如Carleman线性化）来解决经典微分方程，但这些方法需要数字截断和完全容错，难以在当前硬件上实现。因此，需要开发一种适用于当前硬件的替代方法。

Method: 提出了一种基于耦合玻色子模式和量子比特自适应测量的模拟连续变量算法。该算法将经典场编码为相干态，并利用Koopman-von Neumann（KvN）形式主义推导出的Kraus通道组合，将非线性演化映射到线性动力学。该算法避免了希尔伯特空间的数字化。

Result: 该算法能够有效地模拟一维Burgers方程和二维Fisher-KPP方程。该方案在强耗散条件下对光子损耗具有鲁棒性，并且推导出了一个解析反项，可以系统地消除主要的、经过实验校准的噪声。该算法的时间复杂度为$", result="$\", "T(\\log L + d r \\log K)\".

Conclusion: 该工作为模拟非线性系统建立了连续变量框架，并为在近期模拟硬件上实现实际量子加速指明了可行途径。

Abstract: Quantum computers have long been expected to efficiently solve complex classical differential equations. Most digital, fault-tolerant approaches use Carleman linearization to map nonlinear systems to linear ones and then apply quantum linear-system solvers. However, provable speedups typically require digital truncation and full fault tolerance, rendering such linearization approaches challenging to implement on current hardware. Here we present an analog, continuous-variable algorithm based on coupled bosonic modes with qubit-based adaptive measurements that avoids Hilbert-space digitization. This method encodes classical fields as coherent states and, via Kraus-channel composition derived from the Koopman-von Neumann (KvN) formalism, maps nonlinear evolution to linear dynamics. Unlike many analog schemes, the algorithm is provably efficient: advancing a first-order, $L$-grid point, $d$-dimensional, order-$K$ spatial-derivative, degree-$r$ polynomial-nonlinearity, strongly dissipative partial differential equations (PDEs) for $T$ time steps costs $\mathcal{O}\left(T(\log L + d r \log K)\right)$. The capability of the scheme is demonstrated by using it to simulate the one-dimensional Burgers' equation and two-dimensional Fisher-KPP equation. The resilience of the method to photon loss is shown under strong-dissipation conditions and an analytic counterterm is derived that systematically cancels the dominant, experimentally calibrated noise. This work establishes a continuous-variable framework for simulating nonlinear systems and identifies a viable pathway toward practical quantum speedup on near-term analog hardware.

</details>


### [238] [Reusability Report: Optimizing T-count in General Quantum Circuits with AlphaTensor-Quantum](https://arxiv.org/abs/2511.09951)
*Remmy Zen,Maximilian Nägele,Florian Marquardt*

Main category: quant-ph

TL;DR: AlphaTensor-Quantum 被扩展到可以优化随机量子电路，无需重新训练，并且在具有可变量子比特数的电路优化方面表现出良好的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有的 AlphaTensor-Quantum 方法在优化量子电路 T-count 方面虽然表现优异，但仅限于特定电路家族，需要为每个新应用进行耗时的单独训练。本研究旨在扩展该方法，使其能够处理随机量子电路，并提高其泛化能力，以解决更广泛的量子电路优化问题。

Method: 本研究复现了 AlphaTensor-Quantum 的关键结果，并将其应用扩展到可以优化具有可变量子比特数的随机量子电路，无需针对新电路进行重新训练。通过在包含 5 到 8 个量子比特的电路以及包含不同数量量子比特的电路集上训练通用智能体，并与之前的方法进行比较，来评估其性能。

Result: 在随机量子电路优化方面，通过在 5 到 8 个量子比特的电路集上训练的通用智能体，在 T-count 减少方面取得了比以往方法更好的性能。此外，在包含不同数量量子比特的电路集上训练的通用智能体，其性能优于在固定量子比特数电路集上训练的智能体，证明了该方法的泛化能力。

Conclusion: 本研究成功地扩展了 AlphaTensor-Quantum 方法，使其能够优化随机量子电路，无需重新训练。实验证明，该通用智能体在 T-count 减少方面表现出色，并且在处理可变量子比特数的电路时具有良好的泛化能力，为更广泛的量子电路优化任务提供了潜力。

Abstract: Quantum computing has the potential to solve problems that are intractable for classical computers, with possible applications in areas such as drug discovery and high-energy physics. However, the practical implementation of quantum computation is hindered by the complexity of executing quantum circuits on hardware. In particular, minimizing the number of T-gates is crucial for implementing efficient quantum algorithms. AlphaTensor-Quantum is a reinforcement learning-based method designed to optimize the T-count of quantum circuits by formulating the problem as a tensor decomposition task. While it has demonstrated superior performance over existing methods on benchmark quantum arithmetic circuits, its applicability has so far been restricted to specific circuit families, requiring separate, time-intensive training for each new application. This report reproduces some of the key results of the original work and extends AlphaTensor-Quantum's capabilities to simplify random quantum circuits with varying qubit counts, eliminating the need for retraining on new circuits. Our experiments show that a general agent trained on 5- to 8-qubit circuits achieves greater T-count reduction than previous methods for a large fraction of quantum circuits. Furthermore, we demonstrate that a general agent trained on circuits with varying qubit numbers outperforms agents trained on fixed qubit numbers, highlighting the method's generalizability and its potential for broader quantum circuit optimization tasks.

</details>


### [239] [Improved coherence time of a non-Hermitian qubit in a $\mathcal{PT}$-symmetric Environment](https://arxiv.org/abs/2511.09990)
*Duttatreya,Ipsika Mohanty,Sanjib Dey*

Main category: quant-ph

TL;DR: 非厄米量子力学，特别是PT对称性，可以通过增强相干时间来缓解量子计算中的退相干问题，尤其是在系统和环境都表现出PT对称性时。


<details>
  <summary>Details</summary>
Motivation: 量子计算的指数级加速潜力受到退相干的限制，而退相干源于环境相互作用。非厄米量子力学（特别是PT对称性）提供了一种延长相干时间的新方法。

Method: 研究了PT对称非厄米动力学下的量子比特相干性。

Result: 与厄米系统相比，量子比特的相干时间显著延长。当系统和环境都表现出PT对称性时，效果尤为明显。环境非厄米性越大，相干时间越长，这与传统预期相反。

Conclusion: 研究结果表明，利用非厄米PT对称性是管理退相干的有前途的策略，有望显著推进量子信息处理。

Abstract: Quantum computing's potential for exponential speedup is fundamentally limited by decoherence, a phenomenon arising from environmental interactions. Non-Hermitian quantum mechanics, particularly $PT$-symmetric systems, offers a novel framework for extending coherence times. This study examines a qubit's coherence under non-Hermitian $PT$-symmetric dynamics, highlighting significantly enhanced coherence times compared to Hermitian setups. The effect is especially pronounced when both the system and environment exhibit $PT$-symmetry. Interestingly, greater environmental non-Hermiticity correlates with extended coherence, contrary to traditional expectations. These findings point to promising strategies for managing decoherence, which could significantly advance approaches to quantum information processing.

</details>


### [240] [Enantiodetection in a cavity QED setup with finite chiral molecules](https://arxiv.org/abs/2511.10061)
*Xiang Guo,Xiaojun Zhang,Yong Li,Zhihai Wang*

Main category: quant-ph

TL;DR: 利用腔量子电动力学平台，通过监测稳态腔内光子数，研究了单个和有限集合的环状三能级手性分子的对映体检测。


<details>
  <summary>Details</summary>
Motivation: 研究手性分子的对映体检测，特别是对于有限集合的分子，并提出一种新的量子光学方法。

Method: 利用广义离散截断Wigner近似，并利用内禀的全局π相差来构建干涉路径，实现对映体过量的直接读出。

Result: 提出的方法误差低于5%，并且能够避免复杂的数值模拟，适用于量子光学设置。

Conclusion: 该研究为在现实的量子光学环境中实现对映体检测提供了新的途径。

Abstract: We investigate enantiodetection for both a single cyclic three-level chiral molecule and finite ensembles of such molecules by monitoring the steady-state intracavity photon number in a cavity-QED platform. Our scheme exploits the intrinsic global $π$-phase difference between opposite enantiomers to engineer destructive and/or constructive interference pathways, enabling a direct readout of enantiomeric excess with an error below $5\%$. To capture mesoscopic many-molecule effects beyond mean field while avoiding brute-force master-equation simulations, we employ a generalized discrete truncated Wigner approximation, which is well suited for systems with many yet finite molecules. These results pave the way for implementing enantiodetection in realistic quantum-optical settings.

</details>


### [241] [First and second quantized digital quantum simulations of bosonic systems](https://arxiv.org/abs/2511.10124)
*Mathias Mikkelsen,Hubert Okadome Valencia*

Main category: quant-ph

TL;DR: 第一量化玻色子映射比第二量化映射在计算k-RDM时所需的资源更少，尤其是在处理较多粒子数N和模式数M时，第一量化二元映射在某些情况下比第二量化映射更有效，但需要更多的qubits，然而在一半情况下，第一量化二元映射在CNOT和Rz(φ)门的使用上与第一量化一元映射相当。


<details>
  <summary>Details</summary>
Motivation: 比较第一和第二量化玻色子映射在N粒子M模式系统中的基本资源需求，特别是针对k-RDM和两种标准玻色子哈密顿量。

Method: 研究了标准的二元第一量化映射和一元第一量化映射，并与二元和一元第二量化映射进行了比较，重点分析了k-RDM的计算复杂度和所需的门数量。

Result: 一元第一量化映射在一般情况下是最节省门的映射，但需要更多的qubits。第一量化映射在处理k-RDM的非对角项时，比第二量化映射所需的资源少约N^k。第一量化二元映射在M增加时，门数量的增长比其他映射更快。然而，对于实际的N和M组合，第一量化二元映射所需的门数量少于二元和一元第二量化映射，并且所需的qubits比一元第二量化映射少。对于Bose-Hubbard模型和谐振子势，当M=2^n时，第一量化二元映射在表达哈密顿量指数时所需的CNOT和Rz(φ)门数量与最有效的一元第一量化映射相当。

Conclusion: 第一量化二元映射在实际问题中可能同时具有qubit和门效率。

Abstract: We compare the basic resource requirements for first and second quantized bosonic mappings in a system consisting of $N$ particles in $M$ modes. In addition to the standard binary first quantized mapping, we investigate the unary first quantized mapping, which we show to be the most gate-efficient mapping for bosons in the general case, although less qubit-efficient than binary mappings. Our comparison focuses on the $k$-body reduced density matrix ($k$-RDM) as well as two standard bosonic Hamiltonians. The first quantized mappings use less resources for off-diagonal terms of the $k$-RDM by a factor of $ \sim N^k$, compared to the second quantized mappings. The number of gates for the first quantized binary mapping increases faster with $M$ compared to the other mappings. Nevertheless, a detailed numeric analysis reveals that the binary first quantized mapping still requires fewer gates than the binary and unary second quantized ones for realistic combinations of $N$ and $M$, while requiring exponentially fewer qubits than the unary mappings. Additionally, the number of CNOT and $R_z(φ)$ gates necessary to express the exponential of the Hamiltonian in the binary first quantized mapping is comparable to the (overall most efficient) unary first quantized one when $M = 2^n$ for both the Bose-Hubbard model and the harmonic trap with short-range interactions. This suggests that this mapping can be both qubit- and gate-efficient for practical problems.

</details>


### [242] [General quantum backflow in realistic wave packets](https://arxiv.org/abs/2511.10155)
*Tomasz Paterek,Arseni Goussev*

Main category: quant-ph

TL;DR: 量子回溯是一种反直觉现象，其中量子粒子的概率密度会朝着与其动量相反的方向传播。该研究提出了一种适用于任意动量分布的通用量子回溯理论，克服了以往实验观测的两个主要挑战：(1) 效应本身较小（少于4%的概率向后流动）；(2) 需要动量方向明确的波包，这在现实的噪声条件下难以制备和验证。新框架在标准回溯极限下可以恢复，并识别出超过仅由粒子动量分布预测的概率流，这种“过量”可达近13%，超过了标准回溯的界限三倍以上。此外，研究还将该框架扩展到量子再入现象，并给出了具有显著一般回溯和再入效应的量子态示例，探讨了这些非经典效应的潜在影响，为在实际环境中观测量子回溯开辟了道路。


<details>
  <summary>Details</summary>
Motivation: 量子回溯现象的实验观测一直难以实现，主要面临两个挑战：一是量子回溯效应本身非常微小，概率向后流动的比例不到4%；二是该现象需要动量方向明确的波包，这类波包在现实的噪声条件下难以制备和验证。

Method: 提出了一种适用于任意动量分布的通用量子回溯理论框架，该框架能够恢复标准回溯极限下的结果，并识别出超出粒子动量分布预测的概率流，即“一般量子回溯”。同时，将该框架扩展到量子再入现象，并给出了具体的量子态示例。

Result: 研究表明，量子回溯的“过量”概率流可达近13%，超过了标准回溯的界限三倍以上。此外，还提供了具有显著一般回溯和再入效应的量子态示例。

Conclusion: 该研究提出的通用量子回溯理论框架克服了实验观测的挑战，显著放大了量子回溯效应，并为在现实环境中实现量子回溯的实验观测提供了途径。同时，该研究也探讨了量子再入现象及其非经典效应的潜在影响。

Abstract: Quantum backflow is a counterintuitive phenomenon in which the probability density of a quantum particle propagates opposite to its momentum. Experimental observation of backflow has remained elusive due to two main challenges: (i) the effect is intrinsically small, with less than 4% of the probability able to flow backward, and (ii) it requires wave packets with a well-defined momentum direction, which are difficult both to prepare and to verify under realistic, noisy conditions. Here, we overcome these challenges by introducing a general formulation of quantum backflow applicable to arbitrary momentum distributions. The framework recovers the standard backflow limit for unidirectional states and identifies general backflow as probability flow exceeding that predicted by the particle's momentum distribution alone. We show that this excess can reach nearly 13%, surpassing the standard backflow bound by more than a factor of three. Furthermore, we extend the framework to the closely related phenomenon of quantum reentry, provide explicit examples of quantum states exhibiting large general backflow and reentry, and discuss the foundational implications of these nonclassical effects. Our results open a pathway toward the experimental observation of quantum backflow in realistic settings.

</details>


### [243] [Frequency Spectra of Isolated Laser Pulse Envelopes](https://arxiv.org/abs/2511.10506)
*L. H. Ford,Brian Fu*

Main category: quant-ph

TL;DR: 本文研究了孤立激光脉冲，数值计算了其傅里叶变换并研究了其在高频下的渐近行为。研究动机来源于二阶量子化系统中二次算子概率分布的近期结果，例如材料密度在零点声子真空态下的涨落。这些分布的下降速度很慢，导致出现大涨落的概率相对较高。当使用激光脉冲测量算子时，分布的下降速率会反映出脉冲包络傅里叶变换的下降速率。本文描述了一种孤立脉冲的创建模型，其中傅里叶变换以频率的幂分数的指数形式下降，并发现该分数在0.1到0.2范围内。大涨落的概率分布具有相同的函数形式，并且意味着相比于方差，大涨落具有显著的概率。


<details>
  <summary>Details</summary>
Motivation: 二阶量子化系统中二次算子（例如材料密度）的概率分布的下降速度很慢，可能导致出现大涨落的概率相对较高。当使用激光脉冲测量这些算子时，分布的下降速率与脉冲包络傅里叶变换的下降速率相关。

Method: 数值计算孤立激光脉冲的傅里叶变换，并研究其在高频下的渐近行为。提出一个模型，其中傅里叶变换以频率的幂分数的指数形式下降。

Result: 发现傅里叶变换的下降形式为频率的幂分数的指数形式，且该分数在0.1到0.2范围内。大涨落的概率分布具有与傅里叶变换相同的函数形式。

Conclusion: 所提出的模型表明，大涨落具有显著的概率，其概率分布的形式与脉冲傅里叶变换的下降形式相同。

Abstract: This paper will deal with isolated laser pulses, those which last for a finite time interval and whose envelope function is strictly zero outside of this interval. We numerically calculate the Fourier transform of this function and study its asymptotic behavior at high frequencies. This work is motivated by recent results on the probability distributions of quadratic operators in second quantized systems. An example is the density of a material which is subject to zero point fluctuations in the phonon vacuum state. These distributions can decrease very slowly, leading to a relatively high probability for large fluctuations. If the operator is measured by a laser pulse, the rate of decrease of the distribution mirrors the rate of decrease of the pulse envelope Fourier transform. We describe a model for the creation of isolated pulses in which this Fourier transform falls as an exponential of a fractional power of frequency and find examples where this fraction is in the range 0.1 to 0.2. The probability distribution for large fluctuation has the same functional form and implies a significant probability for fluctuations very large compared to the variance.

</details>


### [244] [Addressable fault-tolerant universal quantum gate operations for high-rate lift-connected surface codes](https://arxiv.org/abs/2511.10191)
*Josias Old,Juval Bechar,Markus Müller,Sascha Heußen*

Main category: quant-ph

TL;DR: 该工作提出了在升链连接表面（LCS）码上实现所有 Clifford 量子门操作的一种新方法，并展示了如何通过添加魔态制备过程来实现容错通用门集，从而在近期实验中实现高比特开销的量子低密度奇偶校验码。


<details>
  <summary>Details</summary>
Motivation: 量子低密度奇偶校验（qLDPC）码是实现具有低量子比特开销的容错量子内存的主要候选者。然而，与传统的拓扑量子纠错码相比，qLDPC 码在量子比特连接性和计算方面面临挑战。

Method: 本工作提出了一种在升链连接（LCS）码上实现 Clifford 门的操作方法，并结合魔态制备过程，以实现容错的通用门集。LCS 码具有 3D 局部架构和渐近缩放 $[[n, 	extrm{O}(n^{1/3}), 	extrm{O}(n^{1/3})]]$ 的特性。文中以 $[[15,3,3]]$ LCS 码为例，给出了基于标志量子比特的确定性容错电路。

Result: LCS 码在量子比特数量较少的情况下，实现了 favorable instances。对于 $[[15,3,3]]$ LCS 码，文中提供了基于标志量子比特的确定性容错电路，实现了 Clifford 门集合。通过添加容错魔态制备程序，实现了 $d=3$ LCS 码的容错通用门集。数值模拟表明，该门构造方案在电路级噪声下可达到 $p_{	extrm{th}} 	extrm{ 约为 } 4.8	imes 10^{-3}-1.2	imes 10^{-2}$ 的伪阈值。

Conclusion: 本研究提出的 LCS 码量子门构造方案，使用了适量的量子比特，适用于近期实验，为高比特率 qLDPC 码的容错逻辑研究奠定了基础。

Abstract: Quantum low-density parity check (qLDPC) codes are among the leading candidates to realize error-corrected quantum memories with low qubit overhead. Potentially high encoding rates and large distance relative to their block size make them appealing for practical suppression of noise in near-term quantum computers. In addition to increased qubit-connectivity requirements compared to more conventional topological quantum error correcting codes, qLDPC codes remain notoriously hard to compute with. In this work, we introduce a construction to implement all Clifford quantum gate operations on the recently introduced lift-connected surface (LCS) codes (Old et al. 2024). These codes can be implemented in a 3D-local architecture and achieve asymptotic scaling $[[n, \mathcal{O}(n^{1/3}), \mathcal{O}(n^{1/3})]]$. In particular, LCS codes realize favorable instances with small numbers of qubits: For the $[[15,3,3]]$ LCS code, we provide deterministic fault-tolerant (FT) circuits of the logical gate set $\{\overline{H}_i, \overline{H}_i, \overline{C_i X_j}\}_{i,j \in (0,1,2)}$ based on flag qubits. By adding a procedure for FT magic state preparation, we show quantitatively how to realize an FT universal gate set in $d=3$ LCS codes. Numerical simulations indicate that our gate constructions can attain pseudothresholds in the range $p_{\mathrm{th}} \approx 4.8\cdot 10^{-3}-1.2\cdot 10^{-2}$ for circuit-level noise. The schemes use a moderate number of qubits and are therefore feasible for near-term experiments, facilitating progress for fault-tolerant error corrected logic in high-rate qLPDC codes.

</details>


### [245] [Proof-of-principle demonstration of a Polarization-Circulation Speed Meter](https://arxiv.org/abs/2511.10220)
*Yohei Nishino,Tomotada Akutsu,Yoichi Aso,Munetake Otsuka,Luise Kranzhoff,Takayuki Tomaru*

Main category: quant-ph

TL;DR: 实验实现了首个偏振-圆周速度计。


<details>
  <summary>Details</summary>
Motivation: 提出并实验验证了偏振-圆周速度计的可行性。

Method: 采用单腔干涉仪，固定所有反射镜，通过绿色锁定方案稳定偏振圆周腔，并演示了锁定获取程序以实现速度计操作。

Result: 测量了伪位移信号到光电探测器输出的传递函数，确认该装置能测量镜子运动的速度。

Conclusion: 实验结果支持了偏振-圆周速度计的可行性，并表明该控制方案可扩展到更复杂的干涉仪和悬摆镜系统。

Abstract: We present the first experimental implementation of a polarization-circulation speed meter. In our experiment, the interferometer was reduced to a single-cavity configuration with all mirrors fixed. A green-locking scheme was employed to stabilize the polarization circulation cavity, and a lock-acquisition procedure was demonstrated to realize speed-meter operation. The system was characterized by measuring the transfer function from a pseudo-displacement signal to the photodetector output, confirming that the device measures the speed of mirror motion. These results support the feasibility of polarization-circulation speed meters and suggest that the control scheme could be extended to more complex configurations, such as Michelson interferometers and suspended-mirror systems.

</details>


### [246] [Tunable single-photon frequency converter in a waveguide with a giant V-type atom](https://arxiv.org/abs/2511.10243)
*Hongzheng Wu,Ge Sun,Jing Lu,Lan Zhou*

Main category: quant-ph

TL;DR: 该研究探讨了在V型巨原子（GA）的单光子散射，其中一个跃迁与一维波导耦合，另一个跃迁受经典场相干驱动。通过求解Lippmann-Schwinger方程，我们获得了不同入射方向的单光子散射系数，并分析了马尔可夫和非马尔可夫两种情况下的散射谱和频率转换的非互易性。研究发现，当抑制任何一个跃迁路径的单光子发射时，频率上转换或下转换的概率会消失，但通过引入非互易性可以增强这种概率，甚至达到1。这种频率转换概率的调控源于巨原子的尺度所引起的量子自干涉以及巨原子-波导耦合之间的相位差。


<details>
  <summary>Details</summary>
Motivation: 研究单光子在与巨原子耦合的一维波导中的散射行为，特别是利用巨原子的相干驱动和耦合实现单光子频率转换，并探索非互易性对频率转换的影响。

Method: 利用Lippmann-Schwinger方程求解单光子散射系数，并分析了马尔可夫和非马尔可夫两种情况下的散射谱和转换对比度。

Result: 得到了不同入射方向的单光子散射系数，揭示了马尔可夫和非马尔可夫两种情况下不同的散射谱。分析了转换对比度，发现频率上转换或下转换的概率在抑制单一跃迁路径时会消失，但在引入非互易性后会增强，甚至可达1。

Conclusion: 巨原子（GA）的量子自干涉效应和巨原子-波导耦合的相位差是调控单光子频率转换概率的关键因素，通过非互易性可以显著增强频率转换的效率。

Abstract: We study the single-photon scattering in a one-dimensional (1D) waveguide coupled to one transition of a $V$-type giant atom (GA), whose other transition is coherently driven by an classical field. The inelastic scattering of single photons by the GA realizes the single-photon frequency conversion. By applying the Lippmann-Schwinger equation, the scattering coefficients for single photons incident from different directions are obtained, which present different scattering spectra in the Markovian and the non-Markovian regimes. The conversion contrast characterizing the nonreciprocity is also analyzed in both regimes. It is found that the probability of the frequency up- or down-conversion vanishes as long as the emission from either transition pathways for single photons is suppressed, but it is enhanced and even reach unity by introducing the nonreciprocity. It is the quantum self-interference induced by the scale of this two-legged GA and the phase difference between the GA-waveguide couplings that tune the probability of the frequency up- or down-conversion.

</details>


### [247] [Ancilla-Free Fast-Forwarding Lindbladian Simulation Algorithms by Hamiltonian Twirling](https://arxiv.org/abs/2511.10253)
*Minbo Gao,Zhengfeng Ji,Chenghua Liu*

Main category: quant-ph

TL;DR: 通过研究马尔可夫开放系统动力学与哈密顿量实时演化平均之间的联系，我们提出了一种新的模拟方法，该方法具有与现有方法相当的性能，但不需要辅助寄存器或受控操作，并且对近期硬件更友好。


<details>
  <summary>Details</summary>
Motivation: 研究开放量子系统的模拟方法，特别是利用哈密顿量旋转通道来模拟具有单一厄米跳跃算符的 Lindblad 方程。

Method: 通过将单跳跃算符 Lindbladian 的时间演化映射表示为酉群上的高斯旋转，并提出一种快速算法，其时间复杂度为 O(sqrt(t log(1/ε)))，以及一种不受干扰且无控制的算法。此外，通过净化高斯旋转过程和共轭测量，推导了一种连续变量量子相位估计算法。最后，利用 Lévy-Khintchine 表示定理阐明了耗散动力学可以通过哈密顿量旋转通道实现的条件和方式，并探索了复合泊松分布的哈密顿量旋转及其算法含义。

Result: 提出了一种新的模拟 Lindbladian 的算法，其误差为 ε，时间复杂度为 O(sqrt(t log(1/ε)))，并且不需要辅助寄存器或受控操作。推导了一种连续变量量子相位估计算法。阐明了耗散动力学可以通过哈密顿量旋转通道实现的条件和方式。

Conclusion: 该研究提供了一种更有效、更适合近期硬件实现的开放量子系统模拟方法，并为理解和利用哈密顿量旋转通道在量子算法中的应用提供了新的见解。

Abstract: Simulation of open quantum systems is an area of active research in quantum algorithms. In this work, we revisit the connection between Markovian open-system dynamics and averages of Hamiltonian real-time evolutions, which we refer to as Hamiltonian twirling channels. Focusing on the class of Lindbladians with a single Hermitian jump operator $H$ recently studied in Shang et al. (arXiv:2510.06759), we show that the time-$t$ evolution map can be expressed exactly a Gaussian twirl over the unitary orbit ${\{\mathrm{e}^{-\mathrm{i} Hs}\}}_{s\in\mathbb{R}}$. This structural insight allows us to design a fast-forwarding algorithm for Lindbladian simulation that achieves diamond-norm error $\varepsilon$ with time complexity $O\big(\sqrt{t\log(1/\varepsilon)}\big)$ -- matching the performance of Shang et al. while requiring no auxiliary registers or controlled operations. The resulting ancilla-free and control-free algorithm is therefore more amenable to near-term experimental implementation. By purifying the Gaussian twirl procedure and performing a conjugate measurement, we derive a continuous-variable quantum phase estimation algorithm. In addition, by applying the Lévy-Khintchine representation theorem, we clarify when and how a dissipative dynamics can be realized using Hamiltonian twirling channels. Guided by the general theory, we explore Hamiltonian twirling with compound Poisson distributions and their potential algorithmic implications.

</details>


### [248] [Photon transport and blockade based on non-Markovian interactions between a microring resonator and waveguide](https://arxiv.org/abs/2511.10256)
*Haijin Ding*

Main category: quant-ph

TL;DR: 我们研究了在波导的一个微环谐振器上进行光子传输和光子阻碍，其中波导通过两个不同的点耦合到谐振器。


<details>
  <summary>Details</summary>
Motivation: 由于波导中光子传输的延迟，这种在波导和谐振器之间进行两次耦合的配置引起了非马尔可夫动力学。我们旨在操纵单光子或双光子传输和由此产生的阻碍效应，或者操纵输出场的阻碍效应。

Method: 我们使用散射矩阵和二阶相关函数来评估这种非马尔可夫过程，这些函数与两个耦合点之间的距离有关。当腔内模式有相互作用时，通过经典驱动场可以确定输出场的阻碍效应。通过在微环谐振器和波导之间进行非马尔可夫耦合来调节输出场和腔内状态的关联。

Result: 我们发现，通过设计非马尔可夫耦合参数，可以根据波导末端的输出光子状态来操纵单光子或双光子传输和由此产生的阻碍效应。此外，通过经典驱动场和腔内本征态，可以确定输出场的阻碍效应，并且输出场和腔内状态的关联可以通过微环谐振器和波导之间的非马尔可夫耦合来调节。

Conclusion: 我们展示了一种通过在波导和微环谐振器之间引入非马尔可夫性来控制光子传输和光子阻碍的方法。

Abstract: We investigate photon transport and blockade based on the architecture where a waveguide is coupled to a microring resonator at two distinct points. This two-point coupling configuration between the waveguide and resonator gives rise to non-Markovian dynamics, which is induced by the photon transmission delay in the waveguide between the two coupled points. On one hand, by designing the non-Markovian coupling parameters between the waveguide and resonator, single or two-photon transport and the resulting photon blockade effect can be manipulated according to the output photonic states at the end of waveguide. This non-Markovian process can be evaluated by scattering matrices and second order correlation functions related to the distance between two coupled points. On the other hand, when classical driving fields are applied upon the resonator with interactions between its clockwise and counterclockwise modes, the blockade effect of the output field can be determined by the intracavtiy eigenstates. Then the correlations of the output field as well as the intracavity states can be modulated by the non-Markovian coupling between the microring resonator and waveguide.

</details>


### [249] [Quantum Simulation of Non-unitary Dynamics via Contour-based Matrix Decomposition](https://arxiv.org/abs/2511.10267)
*Chao Wang,Huan-Yu Liu,Cheng Xue,Xi-Ning Zhuang,Menghan Dou,Zhao-Yun Chen,Guo-Ping Guo*

Main category: quant-ph

TL;DR: CBMD是一种可扩展的非酉动力学模拟框架，它通过将非厄米函数分解为厄米函数的线性组合来实现最优查询复杂度。


<details>
  <summary>Details</summary>
Motivation: 现有方法在数值积分方面存在局限，而CBMD提供了一种新的可扩展的非酉动力学模拟方法。

Method: CBMD概括了Cauchy的留数定理，将非厄米函数分解为厄米函数的线性组合，并利用量子奇异值变换（QSVT）等技术进行实现。通过引入特征值移位技术，可以进一步优化复杂度。

Result: CBMD在非厄米动力学方面实现了最优查询复杂度，并且其改进的复杂度取决于系统的谱范围而非谱范数。此外，CBMD也适用于更一般的、可通过非厄米多项式近似的动力学，避免了其他方法在可对角化性和条件数方面的限制。

Conclusion: CBMD是一种通用且高效的框架，适用于模拟各种类型的动力学，特别是那些传统方法难以处理的非酉和非厄米系统。

Abstract: We introduce contour-based matrix decomposition (CBMD), a framework for scalable simulation of non-unitary dynamics. Unlike existing methods that follow the ``integrate-then-discretize" paradigm and rely heavily on numerical quadrature, CBMD generalizes Cauchy's residue theorem to matrix-valued functions and directly decomposes a non-Hermitian function into a linear combination of Hermitian ones, which can be implemented efficiently using techniques such as quantum singular value transformation (QSVT). For non-Hermitian dynamics, CBMD achieves optimal query complexity. With an additional eigenvalue-shifting technique, the improved complexity depends on the spectral range of the system instead of its spectral norm. For more general dynamics that can be approximated by non-Hermitian polynomials, where algorithms like QSVT face significant difficulties, CBMD remains applicable and avoids the assumptions of diagonalizability as well as the dependence on condition numbers that limit other approaches.

</details>


### [250] [Generalized coherent states with shifted (displaced) arguments](https://arxiv.org/abs/2511.10285)
*Dušan Popov*

Main category: quant-ph

TL;DR: 文章提出了一种构造具有移位参数的广义相干态的方法，利用非线性产生算符作用于非线性相干态。


<details>
  <summary>Details</summary>
Motivation: 研究广义相干态的性质，并将其应用于量子光学等领域。

Method: 利用非线性产生算符和移位参数，并应用正规算符排序技术（DOOT）进行分析。

Result: 得到了广义相干态的表达式，并通过具体案例验证了结果的正确性，与现有文献一致。

Conclusion: 所获得的结果可用于量子光学，例如在相干态表象中计算维格纳算符。

Abstract: In the paper we developed a procedure for constructing generalized coherent states with shifted argument, as a result of the action of the generalized displacement operator. This was based on the action of a pair of nonlinear ladder operators, which generate nonlinear coherent states. To examine the properties of coherent states with shifted argument, the rules of the normal operator ordering technique (DOOT) were used. The results obtained were verified for a series of particular cases, obtaining expressions consistent with those in the literature. The expressions obtained will be, among others, useful in quantum optics, e.g. for calculating the Wigner operator in the representation of coherent states.

</details>


### [251] [Optomechanical Cooling without Residual Heating](https://arxiv.org/abs/2511.10318)
*Surangana Sengupta,Björn Kubala,Joachim Ankerhold,Ciprian Padurariu*

Main category: quant-ph

TL;DR: 主动非线性驱动可以消除量子反作用加热，从而克服传统方案的有限温度下限。


<details>
  <summary>Details</summary>
Motivation: 腔光力学中的解析边带冷却性能受限于量子反作用加热，这导致了有限的最低声子数。

Method: 我们推广了光力学冷却的半经典模型，以描述包含被动和主动非线性的通用腔哈密顿量。我们分析了通过约瑟夫森结实现非线性驱动的最简单的电路光力学系统。

Result: 分析表明，这种主动非线性驱动可以消除残余加热反作用，与基于被动非线性的替代方案相比具有优势。

Conclusion: 通过成功克服限制传统方案的有限温度下限，我们的方法为实现前所未有的机械系统量子控制铺平了道路，并确立了零加热光力学冷却的实验可行性。

Abstract: Resolved-sideband cooling is a standard technique in cavity optomechanics enabling quantum control of mechanical motion, but its performance is ultimately limited by quantum backaction heating. This fundamental effect imposes a limit on the minimum achievable mechanical phonon number, establishing a finite-temperature floor regardless of the applied cooling strength. We generalize the semi-classical model for optomechanical cooling to describe universal cavity Hamiltonians incorporating both passive and active nonlinearities. As a concrete demonstration, we analyze the simplest circuit optomechanical system that implements a nonlinear drive via a Josephson junction. Our analysis reveals that this active nonlinear drive can eliminate the residual heating backaction, thereby comparing favorably with alternative optomechanical cooling schemes based on passive nonlinearities arXiv:2202.13228. By successfully overcoming the finite-temperature floor that limits conventional schemes, our method paves the way for unprecedented quantum control over mechanical systems and establishes the experimental viability of zero-heating optomechanical cooling.

</details>


### [252] [Assessing Finite Scalability in Early Fault-Tolerant Quantum Computing for Homogeneous Catalysts](https://arxiv.org/abs/2511.10388)
*Yanbing Zhou,Athena Caesura,Corneliu Buda,Xavier Jackson,Clena M. Abuan,Shangjie Guo*

Main category: quant-ph

TL;DR: 近期容错量子计算（EFTQC）阶段，量子硬件的可扩展性对模拟开放价态催化系统至关重要。该研究分析了有限可扩展性对量子相位估计算法（QPE）资源需求的影响，并比较了不同硬件架构。结果表明，有限可扩展性增加了量子比特和运行时间需求，但并未改变整体可扩展性行为。高保真度架构在解决同等规模问题时需要较低的最小可扩展性。此外，LDPC码通过减少时空开销，进一步扩大了高保真度架构的竞争优势。


<details>
  <summary>Details</summary>
Motivation: 随着量子硬件向容错操作发展，早期容错量子计算（EFTQC）成为一个关键阶段，其特点是部分纠错能力。在此背景下，量子处理器在规模和深度上的可扩展性成为影响其性能的关键因素，尤其是在模拟开放价态催化系统等复杂应用中。因此，研究有限可扩展性对资源需求的影响，并比较不同硬件架构和容错方案的性能，对于指导下一代量子硬件设计和推动量子计算在科学与工业领域的应用至关重要。

Method: 本研究采用量子相位估计算法（QPE）来模拟开放价态催化系统，并重点分析了有限可扩展性对所需量子比特和运行时间的影响。研究对比了两种不同的硬件架构（基于保真度或操作速度），并在两种代表性的可扩展性模型下进行了分析。此外，还结合了表面码和量子低密度奇偶校验（LDPC）码两种容错方案，在有限可扩展性条件下，评估了不同硬件和编码配置的运行时间竞争力。

Result: 有限可扩展性显著增加了量子比特和运行时间的需求，但并未改变问题的总体可扩展性行为。在高保真度架构中，解决相同规模问题的最低可扩展性要求较低。这些影响在很大程度上独立于所选择的可扩展性模型。在高保真度架构中，即使门操作速度较慢，其竞争力也得到了保持。LDPC码通过减少时空开销，进一步扩大了高保真度架构的竞争优势。

Conclusion: 可扩展性在量化量子计算性能和指导下一代量子硬件设计方面起着核心作用。有限的可扩展性增加了资源需求，但通过选择高保真度架构和采用LDPC等高效编码方案，可以有效缓解这些影响。持续推进可扩展的量子计算架构是实现更复杂科学和工业应用的关键。

Abstract: As quantum hardware advances toward fault-tolerant operation, an intermediate stage known as early fault-tolerant quantum computing (EFTQC) is emerging, where partial error correction enables meaningful computation. In this regime, the ability of quantum processors to scale in size and depth has become a crucial factor shaping their achievable performance. This study investigates how finite scalability influences resource requirements for simulating open-shell catalytic systems using Quantum Phase Estimation (QPE). The analysis compares hardware archetypes distinguished by fidelity or operation speed under two representative scalability models. Finite scalability increases qubit and runtime demands yet leaves overall scaling behavior intact, with high-fidelity architectures requiring lower minimum scalability to solve equally sized problems. These effects are largely independent of the chosen scalability model. Extending this framework, we examine runtime competitiveness across hardware and code configurations, incorporating surface-code and quantum Low-Density Parity-Check (LDPC)-based fault tolerance under finite scalability. The results identify operating regimes where high-fidelity architectures remain competitive despite slower gate speeds and show that LDPC codes further expand this regime by reducing space-time overhead. Together, these findings highlight the central role of scalability in quantifying performance and guiding the design of next-generation quantum hardware. Continued progress in scalable architectures will be essential for extending quantum computing to increasingly complex scientific and industrial applications.

</details>


### [253] [Hardware-Efficient Bosonic Module for Entangling Superconducting Quantum Processors via Optical Networks](https://arxiv.org/abs/2511.10407)
*Jia-Hua Zou,Weizhou Cai,Jia-Qi Wang,Zheng-Xu Zhu,Qing-Xuan Jie,Xin-Biao Xu,Weiting Wang,Guang-Can Guo,Luyan Sun,Chang-Ling Zou*

Main category: quant-ph

TL;DR: 本论文提出了一种模块化架构，利用基于SNAIL的参数耦合将布里渊微波-光学（M2O）换能器与长寿命的3D腔耦合，实现了超导量子处理器与光学连接，并保持了即插即用兼容性。


<details>
  <summary>Details</summary>
Motivation: 扩展超导量子处理器至单个稀释制冷机以外的范围需要高效的光学互连，但频率失配和量子比特退相干阻碍了微波-光学（M2O）换能器的集成。

Method: 提出了一种模块化架构，使用基于SNAIL的参数耦合将布里渊M2O换能器与长寿命的3D腔接口，同时保持即插即用兼容性。通过包含激光加热、传播损耗和探测效率低下等现实噪声的数值模拟，使用Duan-Lukin-Cirac-Zoller（DLCZ）协议，在30公里范围内以kHz速率实现了F~0.8的原始纠缠比特保真度。

Result: 通过数值模拟，在30公里距离上，使用DLCZ协议，以kHz速率实现了F~0.8的原始纠缠比特保真度。通过实施针对幅度阻尼误差的非对称纠缠泵浦，实现了F~0.94的纯化保真度，速率为0.2 kHz。

Conclusion: 基于腔的方法优于transmon方案，为分布式超导量子计算提供了实用的途径。

Abstract: Scaling superconducting quantum processors beyond single dilution refrigerators requires efficient optical interconnects, yet integrating microwave-to-optical (M2O) transducers poses challenges due to frequency mismatches and qubit decoherence. We propose a modular architecture using SNAIL-based parametric coupling to interface Brillouin M2O transducers with long-lived 3D cavities, while maintaining plug-and-play compatibility. Through numerical simulations incorporating realistic noises, including laser heating, propagation losses, and detection inefficiency, we demonstrate raw entangled bit fidelities of F~0.8 at kHz-level rates over 30 km using the Duan-Lukin-Cirac-Zoller (DLCZ) protocol. Implementing asymmetric entanglement pumping tailored to amplitude damping errors, we achieve purified fidelities F~0.94 at 0.2 kHz rates. Our cavity-based approach outperforms transmon schemes, providing a practical pathway for distributed superconducting quantum computing.

</details>


### [254] [Entanglement Phase Transition in Chaotic non-Hermitian Systems](https://arxiv.org/abs/2511.10410)
*Zhen-Tao Zhang,Feng Mei*

Main category: quant-ph

TL;DR: 研究了具有特定耦合类型的混沌非厄米自旋链中的纠缠相变。


<details>
  <summary>Details</summary>
Motivation: 研究非厄米系统中纠缠相变的机制，特别是混沌非厄米自旋链。

Method: 计算了两种模型（包含复数纵向场的横向场伊辛模型和包含横向场的非厄米XX模型）的复数谱，并模拟了它们的非幺正演化。

Result: 发现这两种模型存在一个与耗散率相关的无能隙-有能隙相变，并且复数能隙随耗散率的变化呈现振荡。纠缠熵从体积律向面积律转变。

Conclusion: 混沌非厄米系统存在新颖的纠缠相变，这与复数能隙的振荡和能级交叉有关。

Abstract: We have studied entanglement phase transition in a class of chaotic non-Hermitian spin chain in which its spin-spin coupling term commutes with the non-Hermitian term. Two models are investigated: transverse field Ising model with a complex longitudinal field and non-Hermitian XX model with a transverse field. Through calculating their complex spectra, we find these models are subject to a gapless-gapped phase transition with dissipation rate if the transverse field is larger than a model-dependent value. Interestingly, the variation of the complex gap with the dissipation rate is not monotonous, instead it manifest oscillations before entering the gapped phase. By simulating their non-unitary evolution, we show that the entanglement entropy of the steady state would transition from a volume-law to an area-law scaling with the increase of the dissipation rate. Meanwhile, some unexpected results about the entanglement entropy appear in the volume-law phase. These unusual features of the complex gap and the steady-state entanglement can be attributed to level crossings between the maximal imagine level and other levels. Our work reveals a novel entanglement transition in chaotic non-Hermitian systems.

</details>


### [255] [From Local Nonclassicality to Entanglement: A Convexity Law for Single-Excitation Dynamics](https://arxiv.org/abs/2511.10470)
*Atta ur Rahman,Ao-xiang Liu,M. Y. Abd-Rabbou,Cong-feng Qiao*

Main category: quant-ph

TL;DR: excitation-preserving interactions obey a simple dynamical law where the sum of local Wigner negativities is upper-bounded by a budget determined by the initial state. This bound is saturated when the excitation is fully localized and can be used to quantify entanglement growth and diagnose errors.


<details>
  <summary>Details</summary>
Motivation: The paper aims to prove a simple dynamical law for excitation-preserving interactions, specifically focusing on the sum of local Wigner negativities and its upper bound.

Method: The study derives an analytical result for two bodies and uses numerical corroboration in engineered state-transfer chains. It establishes a convexity bound for the single-excitation sector of the XY model and its beam-splitter analogue.

Result: The sum of local Wigner negativities is upper-bounded by a budget set by the initial state. This bound is saturated when the excitation is fully localized. The study reveals coherence-enabled dark transport where the resource is locally invisible but stored in multi-body coherences.

Conclusion: The predicted trajectory of the summed local negativity serves as a practical hardware metric, where deviations from the ideal curve indicate decoherence and control errors.

Abstract: We prove a simple dynamical law for excitation-preserving interactions: the {sum of local Wigner negativities} is upper-bounded by a fixed budget set by the initially excited state. For the single-excitation sector of the XY model (and its beam-splitter analogue), this convexity bound equals the negativity of the seed state and is saturated only when the excitation is fully localized. At intermediate times the sum lies strictly below the bound due to phase-space overlap in local mixtures, quantitatively accounting for entanglement growth as a redistribution of a finite, budgeted resource into shared correlations. We establish the result analytically for two bodies and corroborate it numerically in engineered state-transfer chains, where it reveals a coherence-enabled dark transport: the resource becomes locally invisible while being stored in multi-body coherences. The predicted trajectory of the summed local negativity provides a practical hardware metric: deviations from the ideal, budgeted curve diagnose decoherence and control error.

</details>


### [256] [Shortcuts to adiabaticity for coherent atom transport in an adjustable family of two-dimensional optical lattices](https://arxiv.org/abs/2511.10472)
*Sascha H. Hauck,Vladimir M. Stojanovic*

Main category: quant-ph

TL;DR: 该论文研究了二维光学晶格中相干原子输运的问题，旨在为量子技术提供支持。


<details>
  <summary>Details</summary>
Motivation: 量子技术（如量子计算和量子模拟）的发展需要精确控制和相干地输运原子。现有技术在实现这一目标方面存在挑战，因此需要新的方法来提高原子输运的相干性和效率。

Method: 该研究提出了一种利用动态光学晶格实现原子输运的方法。具体来说，他们设计了声光调制器来产生频率失衡的激光束，从而在任意方向上实现动态晶格效应。然后，他们利用基于Lewis-Riesenfeld动力学不变量的逆向工程方法，结合绝热路线（STA），获得了能够实现原子输运的动力学晶格轨迹。最后，通过求解时间相关的薛定谔方程，计算了输运保真度，以量化原子动力学。

Result: 研究发现，在不同的系统参数和输运方向下，该方法能够实现较短的输运时间和对实验误差的良好鲁棒性。数值模拟结果显示了高输运保真度。

Conclusion: 提出的基于动态光学晶格和绝热路线的方法能够有效地实现相干原子输运，并且在实际应用中具有良好的前景，能够满足量子技术对精确原子控制的需求。

Abstract: Motivated by the compelling need for coherent atom transport in a variety of emerging quantum technologies, we investigate such transport on the example of an adjustable family of two-dimensional optical lattices [L. Tarruell {\em et al.}, Nature (London) 483, 302 (2012)] that includes square, triangular, honeycomb, dimerized, and checkerboard lattices as its special cases; dynamical optical lattices of this type have already been utilized for the demonstration of topological pumping and the realiza- tion of two-qubit quantum gates with neutral atoms. At the outset, we propose the appropriate arrangements of acousto-optic modulators that give rise to a frequency imbalance between coun- terpropagating laser beams, thus leading to the dynamical-lattice effect in an arbitrary direction in the lattice plane. We subsequently obtain the dynamical-lattice trajectories that enable atom transport using shortcuts to adiabaticity (STA) in the form of inverse engineering based on a dy- namical invariant of Lewis-Riesenfeld type. We then quantify the resulting atom dynamics using the transport fidelity computed from the numerical solutions of the relevant time-dependent Schroedinger equation. We do so for various choices of the system parameters and transport directions, finding favorable results for the achievable transport times and robustness of the resulting transport to various experimental imperfections.

</details>


### [257] [Quantum Design Automation: Foundations, Challenges, and the Road Ahead](https://arxiv.org/abs/2511.10479)
*Feng Wu,Jingzhe Guo,Tian Xia,Linghang Kong,Fang Zhang,Ziang Wang,Aochu Dai,Ziyuan Wang,Zhaohui Yang,Hao Deng,Kai Zhang,Zhengfeng Ji,Yuan Feng,Hui-Hai Zhao,Jianxin Chen*

Main category: quant-ph

TL;DR: 量子计算正从实验室走向工业部署，但面临可扩展性、性能、良率、算法和应用等挑战。本文提出应采用整体设计视角，以抓住共设计机遇并应对挑战。文中详细介绍了从芯片设计、系统模拟、哈密顿量推导、控制脉冲模拟、退相干分析、物理验证测试，到量子指令集设计，再到量子系统和软件开发（包括量子电路合成、量子纠错和容错、逻辑验证测试）的端到端设计流程。通过实例说明了如何结合算法考虑对量子指令集进行共优化，如何根据硬件限制定制纠错电路，以及如何通过定制代码设计来简化量子芯片设计。旨在促进软硬件社区的对话，加速研究成果向未来量子硬件的转化。


<details>
  <summary>Details</summary>
Motivation: 量子计算正从实验室走向工业部署，但面临可扩展性、性能、良率、算法和应用等挑战。为应对这些挑战并抓住共设计机遇，需要采用整体设计视角。

Method: 本文详细介绍了端到端的量子计算机设计流程，包括：1. 芯片设计自动化、高保真度系统级仿真、量子系统建模的哈密顿量推导、控制脉冲仿真、退相干分析、物理验证和测试。2. 量子指令集设计。3. 量子系统和软件开发，包括量子电路综合、量子纠错和容错、逻辑验证和测试。并通过具体实例说明了共优化机会。

Result: 本文通过详细的端到端设计流程和具体实例，说明了如何进行量子计算机的设计，包括软硬件的协同设计，例如：将量子指令集与算法进行共优化、根据硬件限制定制纠错电路、通过定制代码设计来简化量子芯片设计等。

Conclusion: 通过详细的端到端设计流程和具体实例，本文希望能够促进硬件和软件社区之间的对话，加速有意义的研究成果向未来量子硬件的转化。

Abstract: Quantum computing is transitioning from laboratory research to industrial deployment, yet significant challenges persist: system scalability and performance, fabrication yields, and the advancement of algorithms and applications. We emphasize that in building quantum computers -- spanning quantum chips, system integration, instruction sets, algorithms, and middleware such as quantum error correction schemes -- design is everywhere. In this paper, we advocate for a holistic design perspective in quantum computing, a perspective we argue is pivotal to unlocking innovative co-design opportunities and addressing the aforementioned key challenges. To equip readers with sufficient background for exploring co-optimization opportunities, we detail how interconnected computational methods and tools collaborate to enable end-to-end quantum computer design. This coverage encompasses critical stages -- such as chip layout design automation, high-fidelity system-level simulation, Hamiltonian derivation for quantum system modeling, control pulse simulation, decoherence analysis, and physical verification and testing -- followed by quantum instruction set design. We then proceed to quantum system and software development, including quantum circuit synthesis, quantum error correction and fault tolerance, and logic verification and testing. Through these discussions, we illustrate with concrete examples -- including co-optimizing quantum instruction sets with algorithmic considerations, customizing error correction circuits to hardware-specific constraints, and streamlining quantum chip design through tailored code design, among others. We hope that the detailed end-to-end design workflow as well as these examples will foster dialogue between the hardware and software communities, ultimately facilitating the translation of meaningful research findings into future quantum hardware implementations.

</details>


### [258] [Entanglement Structure of Nonlocal Field Theories](https://arxiv.org/abs/2511.10505)
*Reza Pirmoradian,M. Hossein Bek-Khoshnevis,Sadaf Ebadi,M. Reza Tanhayi*

Main category: quant-ph

TL;DR: 论文研究了非局域相互作用如何影响量子关联的精细结构，特别是互信息和三方信息。通过数值模拟和全息对偶，发现非局域性会产生复杂的量子态，超越了现有的几何模型。


<details>
  <summary>Details</summary>
Motivation: 探索非局域相互作用对除纠缠熵之外的量子关联（互信息和三方信息）的更深层影响，以及其在精细结构上的表现。

Method: 使用数值格点模拟研究了玻色子非局域场论，并利用全息对偶和Ryu-Takayanagi公式进行了验证。

Result: 发现非局域性尺度不仅决定了体律行为的出现，还导致了极长程的互信息和不寻常的单调结构。全息模型与场论结果存在显著差异，全息模型预测互信息和三方信息在体律相中被完全抑制，这与场论中观察到的单调和结构化的纠缠形成鲜明对比。

Conclusion: 非局域性产生的量子态复杂度超出了传统时空几何模型的描述能力，需要新的非几何框架来理解这些关联。

Abstract: Nonlocal interactions are known to generate volume-law entanglement entropy. However, their deeper impact on the fine structure of quantum correlations remains a key open question. In this work, we explore a bosonic nonlocal field theory, examining correlation measures beyond entanglement entropy, namely, mutual information and tripartite information. Using numerical lattice simulations, we show that the nonlocality scale, \(A\), not only determines the onset of volume-law behavior but also leads to striking features: notably, extremely long-range mutual information and an unusual monogamy structure. In this regime, increasing the separation between large regions can paradoxically enhance their multipartite entanglement. Through holographic duality, we verify that the Ryu-Takayanagi formula correctly captures the volume-law scaling of entropy. Yet, a significant tension emerges: while the field theory reveals rich spatial correlations, the holographic model predicts a complete suppression of both mutual and tripartite information in the volume-law phase. This non-monogamous behavior in the holographic description stands in sharp contrast to the monogamous and highly structured entanglement observed in the field theory. Our results demonstrate that nonlocality gives rise to quantum states of such complexity that conventional geometric models of spacetime fall short. This points to the need for a new framework that goes beyond geometry to fully capture the nature of these correlations.

</details>


### [259] [Quantum Computational Structure of $SU(N)$ Scattering](https://arxiv.org/abs/2511.10550)
*Navin McGinnis*

Main category: quant-ph

TL;DR: SU(N)对称性的粒子散射可以通过量子计算和量子算法来研究，所有2-2散射过程可以由三个量子门构建，并且可以从“比特翻转”的Z2代数中涌现出来。


<details>
  <summary>Details</summary>
Motivation: 研究具有SU(N)全局对称性的粒子散射，并将其与量子计算和量子算法联系起来。

Method: 使用量子计算和量子算法来分析2-2散射过程，并利用线性组合幺正和分块编码构建量子算法。

Result: 发现所有2-2散射过程可以由三个量子门构建，并且所有2-2散射通道可以从Z2代数的张成中涌现出来，这表明散射过程本质上是由作用在内部量子数上的“比特翻转”决定的。

Conclusion: SU(N)对称性粒子的散射过程，特别是涉及基本或反基本表示的粒子（即量子比特），可以被有效地表示和理解为量子计算中的基本操作。

Abstract: We study scattering of particles which obey an $SU(N)$ global symmetry through the lens of quantum computation and quantum algorithms. We show that for scattering between particles which transform in the fundamental or anti-fundamental representations, i.e. qudits, all 2-2 scattering amplitudes can be constructed from only three quantum gates. Further, for any $N$, all 2-2 scattering channels are shown to emerge from the span of a $\mathbb{Z}_{2}$ algebra, suggesting that scattering in this context is fundamentally governed by the action of ``bit flips'' on the internal quantum numbers. We frame these findings in terms of quantum algorithms constructed from Linear Combinations of Unitaries and block encoding.

</details>


### [260] [Observation and Manipulation of Optical Parametric Down-Conversion in the Langevin Regime](https://arxiv.org/abs/2511.10556)
*Yen-Ju Chen,Chun-Yuan Cheng,Tien-Dat Pham,Tzu-An Chen,Chang-Hau Kuo,Yen-Hung Chen,Chih-Sung Chuu*

Main category: quant-ph

TL;DR: 该论文在芯片上实现了朗之万体制下的光学参量下转换，并通过控制损耗观察到了量子涨落的特征，如不对称的洪- ou -曼德尔干涉和单光子压缩效应。


<details>
  <summary>Details</summary>
Motivation: 量子涨落在朗之万体制下的参量下转换中起着关键作用。

Method: 在芯片上实现了朗之万体制下的光学参量下转换，并通过精确控制与涨落相关的损耗。

Result: 观察到了不对称的洪- ou -曼德尔干涉（这是涨落驱动的参量下转换中量子涨落的标志）和近乎一个数量级的由涨落引起单光子压缩。

Conclusion: 这些发现为操控量子涨落、量子态和系统-浴相互作用铺平了道路。

Abstract: Quantum fluctuation plays a key role in the parametric down-conversion in the Langevin regime. In this paper, we report the experimental realization of optical parametric down-conversion in the Langevin regime on a chip. By precisely controlling the loss inherently tied to fluctuation, we observe the asymmetric Hong-Ou-Mandel dip - a hallmark of quantum fluctuation in the fluctuation-driven PDC, and the fluctuation-induced compression of single photons by nearly one order of magnitude. These findings pave the way for the manipulation of quantum fluctuation, quantum states, and system-reservoir interaction.

</details>


### [261] [Finite-size quantum key distribution rates from Rényi entropies using conic optimization](https://arxiv.org/abs/2511.10584)
*Mariana Navarro,Andrés González Lorente,Pablo V. Parellada,Carlos Pascual-García,Mateus Araújo*

Main category: quant-ph

TL;DR: 基于Rényi熵的有限尺寸量子密钥分发安全证明比基于冯诺依曼熵的传统方法更灵活且能提供更紧密的密钥生成率界限，但需要优化条件Rényi熵。本文提出了一种基于非对称圆锥优化的新方法，解决了该优化问题，该方法快速、可靠且通用，并在多个协议上取得了优于现有技术的性能。


<details>
  <summary>Details</summary>
Motivation: 需要一种更优化的方法来最小化量子密钥分发中的条件Rényi熵，以获得更紧密的密钥生成率界限。

Method: 使用非对称圆锥优化来解决条件Rényi熵最小化问题。

Result: 所提出的方法在速度、可靠性和通用性方面优于现有的基于Frank-Wolfe算法的特设技术，并在多个协议上取得了改进的性能。

Conclusion: 基于非对称圆锥优化的新方法能够高效、可靠且通用地解决量子密钥分发中的条件Rényi熵最小化问题，从而在实际应用中提供更好的安全保证和更高的密钥生成率。

Abstract: Finite-size general security proofs for quantum key distribution based on Rényi entropies have recently been introduced. These approaches are more flexible and provide tighter bounds on the secret key rate than traditional formulations based on the von Neumann entropy. However, deploying them requires minimizing the conditional Rényi entropy, a difficult optimization problem that has hitherto been tackled using ad-hoc techniques based on the Frank-Wolfe algorithm, which are unstable and can only handle particular cases. In this work, we introduce a method based on non-symmetric conic optimization for solving this problem. Our technique is fast, reliable, and completely general. We illustrate its performance on several protocols, whose results represent an improvement over the state of the art.

</details>


### [262] [Information phases of partial projected ensembles generated from random quantum states](https://arxiv.org/abs/2511.10595)
*Alan Sherry,Saptarshi Mandal,Sthitadhi Roy*

Main category: quant-ph

TL;DR: 这是一个关于量子信息分布和测量框架的摘要，提出了一种名为“投影系综”的新方法，用于比简化的密度矩阵更精细地探测量子态的遍历性和信息结构。该方法在三方量子态设置中得到了推广，并引入了“部分投影系综”的概念。研究表明，基于部分投影系综的信息度量（特别是Holevo信息）可以比传统的纠缠度量更详细地描述量子信息在子系统之间的分布。研究还发现，在Haar随机态下，Holevo信息与系统大小的缩放行为会发生定性变化，导致两种不同的信息相：指数衰减相和线性增长相，它们之间存在由Holevo信息非解析性信号的清晰相变。指数衰减相证实了一个“测量不可见”的量子关联相的存在，这是多体信息 scrambling 的一种表现，在二方量子态中没有类似物。最后，通过将该信息相图与基于对数负度的三方Haar随机态的纠缠相结构进行对比，证明了Holevo信息能够揭示超越传统纠缠度量的额外精细结构。


<details>
  <summary>Details</summary>
Motivation: 与简化的密度矩阵相比，投影系综（一种子系统的纯态系综，以其补集的投影测量结果为条件）能更精细地探测双量子态的遍历性和信息结构。

Method: 将投影系综推广到三方设置中的部分投影系综，其中丢弃了测量子系统部分结果，得到混合态系综。研究信息度量，特别是Holevo信息，与系统大小的关系。使用精确解析结果和数值结果。

Result: 在Haar随机态下，Holevo信息与系统大小的缩放行为存在定性变化，导致两种信息相：指数衰减相和线性增长相，由Holevo信息的非解析性分离。指数衰减相证实了测量不可见量子关联相的存在。Holevo信息揭示了超越传统纠缠度量的额外精细结构。

Conclusion: 部分投影系综提供了一种比传统纠缠度量更精细的量子信息分布描述，并揭示了新的信息相和测量不可见量子关联相。

Abstract: The projected ensemble -- an ensemble of pure states on a subsystem conditioned on projective measurement outcomes on its complement -- provides a finer probe of ergodicity and information structure than the reduced density matrix of the subsystem in bipartite quantum states. This framework can be generalised to partial projected ensembles in tripartite settings, where outcomes from part of the measured subsystem are discarded, leading to ensembles of mixed states. We show that information measures defined for such ensembles, in particular the Holevo information, yield a more detailed characterisation of how quantum information is distributed between subsystems compared to conventional entanglement measures. Using exact analytical results supported by numerical results, we uncover a qualitative change in the scaling of the Holevo information with system size in partial projected ensembles generated by Haar-random states, as the relative sizes of the subsystem are varied. In one phase, the Holevo information decays exponentially with system size, while in the other it grows linearly, thereby defining distinct information phases separated by sharp transitions signalled by non-analyticities in the Holevo information. The exponentially decaying phase rigorously establishes the existence of a measurement-invisible quantum-correlated phase -- a manifestation of many-body information scrambling with no bipartite analogue. Finally, we contrast this information-phase diagram with the entanglement-phase structure of tripartite Haar-random states obtained from logarithmic negativity, and show that the Holevo information reveals additional fine structure beyond conventional entanglement measures.

</details>


### [263] [Quantum Algorithms for Computing Maximal Quantum $f$-divergence and Kubo-Ando means](https://arxiv.org/abs/2511.10607)
*Trung Hoa Dinh,Nhat A. Nghiem*

Main category: quant-ph

TL;DR: 利用量子算法计算最大量子f-散度和Kubo-Ando矩阵算子平均值。


<details>
  <summary>Details</summary>
Motivation: 研究兴趣在于利用量子计算技术估算或计算量子信息论量，如Renyi熵、Von Neumann熵、矩阵平均值等，受此启发，提出新的量子算法。

Method: 提出量子算法来计算最大量子f-散度和Kubo-Ando矩阵算子平均值。

Result: 算法能够处理Renyi熵和矩阵平均值，具有通用性。

Conclusion: 所提出的量子算法框架具有通用性，可用于计算多种量子信息论量。

Abstract: The development of quantum computation has resulted in many quantum algorithms for a wide array of tasks. Recently, there is a growing interest in using quantum computing techniques to estimate or compute quantum information-theoretic quantities such as Renyi entropy, Von Neumann entropy, matrix means, etc. Motivated by these results, we present quantum algorithms for computing the maximal quantum $f$-divergences and the operator-theoretic matrix Kubo--Ando means. Both of them involve Renyi entropies, matrix means as special cases, thus implying the universality of our framework.

</details>


### [264] [Impacts of Decoder Latency on Utility-Scale Quantum Computer Architectures](https://arxiv.org/abs/2511.10633)
*Abdullah Khalid,Allyson Silva,Gebremedhin A. Dagnew,Tom Dvir,Oded Wertheim,Motty Gruda,Xiangzhou Kong,Mia Kramer,Zak Webb,Artur Scherer,Masoud Mohseni,Yonatan Cohen,Pooya Ronagh*

Main category: quant-ph

TL;DR: 量子计算机的容错速度受限于经典电子设备（如解码器和控制器）的响应时间。本文针对基于表面码的架构，建立了一个响应时间模型，并分析了其对逻辑微架构设计的影响。研究表明，即使在每轮稳定化仅需亚微秒解码时间的条件下，对于包含10^6--10^11 T门的电路，也需要大量的额外物理量子比特（约100k--250k用于魔法态工厂，300k--1.75M用于核心处理器）和更长的运行时间（约100倍）。


<details>
  <summary>Details</summary>
Motivation: 量子计算机的容错速度由其经典电子设备（解码器和控制器）的响应时间决定，但目前对响应时间及其对量子计算机逻辑微架构设计的影响的理解尚不充分。

Method: 本文针对基于表面码的架构，构建了一个响应时间模型。该模型考虑了基于并行时空窗口解码方法的解码器延迟，以及一个包含量子处理单元、控制器、解码器和高性能计算节点的高速量子执行环境的通信延迟。利用该模型，研究了响应时间增加对魔法态注入逻辑错误率的影响，并优化了逻辑微架构。最后，基于实际硬件噪声参数和先进的解码时间，对执行实用规模量子电路进行了详细的全系统量子和经典资源估算。

Result: 对于包含 $10^6$–$10^{11}$ $T$ 门的电路（涉及200–2000个逻辑量子比特），在代表超导量子处理器在2.86 MHz稳定频率下运行的 $\Lambda=9.3$ 硬件模型下，即使解码速度达到每轮稳定化0.1微秒，也带来了显著的资源开销：魔法态工厂的纠错量子比特存储需要约100k–250k个额外的物理量子比特；核心处理器由于将码距从$d$增加到$d+4$以提供额外的内存保护，需要300k–1.75M个额外的物理量子比特；运行时间也增加了约100倍。

Conclusion: 量子计算机的响应时间对资源需求有显著影响。即使采用先进的解码技术，在当前硬件模型下，实现大规模容错量子计算仍需克服巨大的资源挑战，包括大量的物理量子比特和更长的运行时间。因此，优化响应时间对于设计高效的量子计算机逻辑微架构至关重要。

Abstract: The speed of a fault-tolerant quantum computer is dictated by the reaction time of its classical electronics, that is, the total time required by decoders and controllers to determine the outcome of a logical measurement and execute subsequent conditional logical operations. Despite its importance, the reaction time and its impact on the design of the logical microarchitecture of a quantum computer are not well understood. In this work, we build, for a surface code based architecture, a model for the reaction time in which the decoder latency is based on parallel space- and time-window decoding methods, and communication latencies are drawn from our envisioned quantum execution environment comprising a high-speed network of quantum processing units, controllers, decoders, and high-performance computing nodes. We use this model to estimate the increase in the logical error rate of magic state injections as a function of the reaction time. Next, we show how the logical microarchitecture can be optimized with respect to the reaction time, and then present detailed full-system quantum and classical resource estimates for executing utility-scale quantum circuits based on realistic hardware noise parameters and state-of-the-art decoding times. For circuits with $10^{6}$--$10^{11}$ $T$ gates involving 200--2000 logical qubits, under a $Λ=9.3$ hardware model representative of a realistic target for superconducting quantum processors operating at a 2.86 MHz stabilization frequency, we show that even decoding at a sub-microsecond per stabilization round speed introduces substantial resource overheads: approximately 100k--250k additional physical qubits for correction qubit storage in the magic state factory; 300k--1.75M extra physical qubits in the core processor due to the code distance increase of $d$ to $d+4$ for extra memory protection; and a longer runtime by roughly a factor of 100.

</details>


### [265] [Emergent spin order and steady-state superradiance in one-dimensional baths](https://arxiv.org/abs/2511.10638)
*Silvia Cardenas-Lopez,Edgar Guardiola-Navarrete,Ana Asenjo-Garcia*

Main category: quant-ph

TL;DR: 受激原子系综中的自发集体衰减可产生远超平衡态的相干性，例如在超辐射激光器中，衰减到单模腔会使原子相位同步成宏观偶极子，并产生具有超窄光谱的超辐射发射。多模腔中的类似有序性是否会因传播和竞争性集体衰减通道而持续存在，仍是一个悬而未决的问题。我们通过分析两个模型中与一维电磁浴耦合的原子来解决这个问题。第一个是支持两个明亮集体衰减通道的环形腔，第二个是双向波导，其中除了通道竞争之外，传播还会引起相干偶极-偶极相互作用。在适当的不相干泵浦强度下，动力学进入同步窗口，其中集体衰减克服了无序过程，导致自发稳态相位排序和超辐射发射。我们提取了标记同步开始的阈值，并表明两个模型中的最大强度都呈二次方缩放。由此产生的顺序不是由单个宏观偶极子描述的：在环形腔中，手性出现在单个轨迹的水平上，而在波导中，局部手性会在原子阵列的两端发展出不同的主导顺序。发射光谱的分析表明，在环形腔中，线宽似乎随着系统尺寸的增加而变窄，而在波导中，在可及的数值范围内，变窄尚无定论。这些结果阐明了竞争和传播如何塑造一维腔中的涌现顺序，并确定了迪克极限之外可能出现稳态超辐射的机制。


<details>
  <summary>Details</summary>
Motivation: 研究多模腔中的原子系综集体衰减，特别是传播和竞争性衰减通道对相干性和序构成的潜在影响。

Method: 分析了两种模型：1. 具有两个明亮集体衰减通道的环形腔；2. 具有传播和通道竞争的双向波导。提取了同步阈值，并分析了最大强度、秩序和发射光谱。

Result: 在适当的泵浦强度下，两种模型都观察到自发稳态相位排序和超辐射发射。最大强度随系统尺寸呈二次方缩放。环形腔中出现单个轨迹水平的手性，而波导中出现局部手性。环形腔光谱线宽随系统尺寸变窄，波导中尚无定论。

Conclusion: 竞争和传播会塑造一维腔中的涌现秩序，并识别出可能超越迪克极限的稳态超辐射机制。

Abstract: Spontaneous collective decay in driven atomic ensembles can generate coherence far from equilibrium, as illustrated by superradiant lasers where decay into a single-mode cavity synchronizes atomic phases into a macroscopic dipole and yields superradiant emission of light with an ultranarrow spectrum. Whether similar ordering persists in multimode reservoirs with propagation and competing collective decay channels remains an open question. We address this problem by analyzing atoms coupled to one-dimensional electromagnetic baths through two models. The first is a ring cavity supporting two bright collective decay channels, and the second is a bidirectional waveguide where, in addition to competition between channels, propagation induces coherent dipole-dipole interactions. For suitable incoherent pumping strengths, the dynamics enters a synchronization window in which collective decay overcomes disordering processes, leading to spontaneous steady-state phase ordering and superradiant emission. We extract the thresholds marking the onset of synchronization and show that the maximum intensity scales quadratically in both models. The resulting order is not described by a single macroscopic dipole: in the ring cavity spontaneous chirality emerges at the level of individual trajectories, while the waveguide develops a local chirality with different orders dominating opposite ends of the atomic array. The analysis of the emitted light spectrum reveals a linewidth that seems to narrow with increased system size in the ring cavity, while narrowing in the waveguide remains inconclusive within accessible numerics. These results clarify how competition and propagation shape emergent order in one-dimensional reservoirs and identify regimes where steady-state superradiance may arise beyond the Dicke limit.

</details>


<div id='cs.SI'></div>

# cs.SI [[Back]](#toc)

### [266] [What did Elon change? A comprehensive analysis of Grokipedia](https://arxiv.org/abs/2511.09685)
*Harold Triedman,Alexios Mantzarlis*

Main category: cs.SI

TL;DR: Grokipedia，埃隆·马斯克推出的维基百科替代品，其内容高度依赖维基百科，但在引用来源方面存在问题，引用了大量不可靠甚至被列入黑名单的网站。其对选举官员和争议性话题的文章相似度较低，且有偏向性地改写了维基百科上高质量的文章。


<details>
  <summary>Details</summary>
Motivation: 分析Grokipedia与维基百科在文章相似度和引用实践方面的异同，并评估Grokipedia的内容质量和倾向性。

Method: 通过对比Grokipedia和维基百科的文章内容、长度和引用来源，分析特定主题的文章子集（选举官员、争议性话题、随机子集），并公开发布Grokipedia的数据和词嵌入。

Result: Grokipedia文章比英文维基百科文章长，但内容高度衍生自维基百科；Grokipedia引用了大量被认为“不可靠”或“黑名单”的来源；选举官员和争议性话题的文章子集相似度较低；随机子集显示Grokipedia偏向改写维基百科上的高质量文章，尤其偏向传记、政治、社会和历史类。

Conclusion: Grokipedia在内容上严重依赖维基百科，但在引用来源的选择上存在严重问题，并且在选择改写维基百科文章时存在明显偏向性。

Abstract: Elon Musk released Grokipedia on 27 October 2025 to provide an alternative to Wikipedia, the crowdsourced online encyclopedia. In this paper, we provide the first comprehensive analysis of Grokipedia and compare it to a dump of Wikipedia, with a focus on article similarity and citation practices. Although Grokipedia articles are much longer than their corresponding English Wikipedia articles, we find that much of Grokipedia's content (including both articles with and without Creative Commons licenses) is highly derivative of Wikipedia. Nevertheless, citation practices between the sites differ greatly, with Grokipedia citing many more sources deemed "generally unreliable" or "blacklisted" by the English Wikipedia community and low quality by external scholars, including dozens of citations to sites like Stormfront and Infowars. We then analyze article subsets: one about elected officials, one about controversial topics, and one random subset for which we derive article quality and topic. We find that the elected official and controversial article subsets showed less similarity between their Wikipedia version and Grokipedia version than other pages. The random subset illustrates that Grokipedia focused rewriting the highest quality articles on Wikipedia, with a bias towards biographies, politics, society, and history. Finally, we publicly release our nearly-full scrape of Grokipedia, as well as embeddings of the entire Grokipedia corpus.

</details>


### [267] [Simulating Misinformation Propagation in Social Networks using Large Language Models](https://arxiv.org/abs/2511.10384)
*Raj Gaurav Maurya,Vaibhav Shukla,Raj Abhijit Dandekar,Rajat Dandekar,Sreedath Panat*

Main category: cs.SI

TL;DR: 本研究提出了一个包含“审计员-节点”框架的LLM代理模型，用于模拟和量化社交媒体上的错误信息传播。研究发现，基于身份和意识形态的LLM代理会加速错误信息的传播，而基于专家的代理则能保持事实的稳定性。该框架为研究和缓解数字生态系统中的错误信息扩散提供了一种可解释的方法。


<details>
  <summary>Details</summary>
Motivation: 为了理解错误信息如何在社交媒体上传播，特别是人类认知偏见如何被利用，本研究旨在模拟和分析错误信息在模仿了用户偏见的LLM代理网络中的演变过程。

Method: 研究构建了一个“审计员-节点”框架，其中LLM代理被用作模拟具有特定偏见、意识形态和信任启发的用户。新闻文章在这些代理节点网络中传播，每个节点都会重写接收到的内容。一个基于问答的审计员在每个步骤测量事实的准确性，从而实现对错误信息漂移的可解释的、声明级别的跟踪。研究还量化了错误信息指数和传播率，并在不同类型的节点网络中进行了实验。

Result: 实验结果表明，基于身份和意识形态的LLM代理（共21个，跨10个领域）会加速政治、营销和技术领域的错误信息传播。相反，基于专家的代理能够更好地保持事实的稳定性。当早期出现扭曲时，异构代理之间的交互会迅速将错误信息升级为宣传层面的失真。研究还提出了一个错误信息严重程度的分类，将观察到的信息漂移与现有错误信息研究理论联系起来。

Conclusion: 本研究证明了LLM在模拟人类偏见和作为审计信息保真度的工具方面具有双重作用。所提出的框架提供了一种可解释的、经验上可信的方法来研究、模拟和减轻数字生态系统中的错误信息传播。最终目标是利用LLM的这些能力来识别和控制错误信息。

Abstract: Misinformation on social media thrives on surprise, emotion, and identity-driven reasoning, often amplified through human cognitive biases. To investigate these mechanisms, we model large language model (LLM) personas as synthetic agents that mimic user-level biases, ideological alignments, and trust heuristics. Within this setup, we introduce an auditor--node framework to simulate and analyze how misinformation evolves as it circulates through networks of such agents. News articles are propagated across networks of persona-conditioned LLM nodes, each rewriting received content. A question--answering-based auditor then measures factual fidelity at every step, offering interpretable, claim-level tracking of misinformation drift. We formalize a misinformation index and a misinformation propagation rate to quantify factual degradation across homogeneous and heterogeneous branches of up to 30 sequential rewrites. Experiments with 21 personas across 10 domains reveal that identity- and ideology-based personas act as misinformation accelerators, especially in politics, marketing, and technology. By contrast, expert-driven personas preserve factual stability. Controlled-random branch simulations further show that once early distortions emerge, heterogeneous persona interactions rapidly escalate misinformation to propaganda-level distortion. Our taxonomy of misinformation severity -- spanning factual errors, lies, and propaganda -- connects observed drift to established theories in misinformation studies. These findings demonstrate the dual role of LLMs as both proxies for human-like biases and as auditors capable of tracing information fidelity. The proposed framework provides an interpretable, empirically grounded approach for studying, simulating, and mitigating misinformation diffusion in digital ecosystems.

</details>


### [268] [Two Americas of Well-Being: Divergent Rural-Urban Patterns of Life Satisfaction and Happiness from 2.6 B Social Media Posts](https://arxiv.org/abs/2511.10542)
*Stefano Maria Iacus,Giuseppe Porro*

Main category: cs.SI

TL;DR: 使用26亿地理位置社交媒体帖子和精调的生成语言模型，构建了美国县级生活满意度和幸福感指标，揭示了农村-城市悖论：农村满意度更高，城市幸福感更强。将两者视为主观幸福感的不同层面（评估性 vs. 享乐性）后，发现它们在地域、政治和时间上映射不同。倾向共和党的地区在评估性方面更满意，但幸福感的党派差异在大都市区外基本消失。2020-2022年期间，幸福感急剧下降，而生活满意度变动较小。这些模式在逻辑回归和OLS回归中均稳健，并与幸福感理论一致。


<details>
  <summary>Details</summary>
Motivation: 利用大规模社交媒体数据和生成语言模型，构建美国县级生活满意度和幸福感指标，以解决传统调查中关于城乡差异的矛盾发现，并区分主观幸福感的不同层面（评估性与享乐性）。

Method: 利用26亿地理位置的社交媒体帖子（2014-2022年）和精调的生成语言模型，构建美国县级生活满意度和幸福感指标。

Result: 发现了农村-城市悖论：农村县的平均生活满意度高于城市县，而城市县的平均幸福感高于农村县。评估性幸福感（生活满意度）与共和党倾向地区相关，而享乐性幸福感（幸福感）的党派差异在大都市区以外基本消失。在2020-2022年期间，幸福感急剧下降，而生活满意度变动较小。

Conclusion: 大规模、基于语言的指标可以区分所表达的幸福感类型，从而解决关于城乡差异的矛盾发现。这种方法为传统调查提供了一个透明、可复现的补充。

Abstract: Using 2.6 billion geolocated social-media posts (2014-2022) and a fine-tuned generative language model, we construct county-level indicators of life satisfaction and happiness for the United States. We document an apparent rural-urban paradox: rural counties express higher life satisfaction while urban counties exhibit greater happiness. We reconcile this by treating the two as distinct layers of subjective well-being, evaluative vs. hedonic, showing that each maps differently onto place, politics, and time. Republican-leaning areas appear more satisfied in evaluative terms, but partisan gaps in happiness largely flatten outside major metros, indicating context-dependent political effects. Temporal shocks dominate the hedonic layer: happiness falls sharply during 2020-2022, whereas life satisfaction moves more modestly. These patterns are robust across logistic and OLS specifications and align with well-being theory. Interpreted as associations for the population of social-media posts, the results show that large-scale, language-based indicators can resolve conflicting findings about the rural-urban divide by distinguishing the type of well-being expressed, offering a transparent, reproducible complement to traditional surveys.

</details>


### [269] [Textual understanding boost in the WikiRace](https://arxiv.org/abs/2511.10585)
*Raman Ebrahimi,Sean Fuhrman,Kendrick Nguyen,Harini Gurusankar,Massimo Franceschetti*

Main category: cs.SI

TL;DR: 维基百科导航可以通过基于语言模型嵌入的贪心策略进行优化，其效果优于基于图结构的方法。


<details>
  <summary>Details</summary>
Motivation: 本文旨在系统地评估维基百科导航任务中的导航策略，比较基于图论结构、语义和混合方法。

Method: 通过在大型维基百科子图上进行严格的基准测试，比较了纯粹贪心策略（基于文章标题的语义相似性）与基于图论结构（中介中心性）和混合方法。

Result: 纯粹贪心策略结合简单的循环避免机制，在维基百科导航任务中取得了完美的成功率，并且导航效率比结构或混合方法高一个数量级。

Conclusion: 纯粹的结构启发式方法在目标导向搜索中存在局限性，而大型语言模型在复杂信息空间中作为零样本语义导航器具有巨大潜力。

Abstract: The WikiRace game, where players navigate between Wikipedia articles using only hyperlinks, serves as a compelling benchmark for goal-directed search in complex information networks. This paper presents a systematic evaluation of navigation strategies for this task, comparing agents guided by graph-theoretic structure (betweenness centrality), semantic meaning (language model embeddings), and hybrid approaches. Through rigorous benchmarking on a large Wikipedia subgraph, we demonstrate that a purely greedy agent guided by the semantic similarity of article titles is overwhelmingly effective. This strategy, when combined with a simple loop-avoidance mechanism, achieved a perfect success rate and navigated the network with an efficiency an order of magnitude better than structural or hybrid methods. Our findings highlight the critical limitations of purely structural heuristics for goal-directed search and underscore the transformative potential of large language models to act as powerful, zero-shot semantic navigators in complex information spaces.

</details>


<div id='cond-mat.mtrl-sci'></div>

# cond-mat.mtrl-sci [[Back]](#toc)

### [270] [Multibit Ferroelectric Memcapacitor for Non-volatile Analogue Memory and Reconfigurable Filtering](https://arxiv.org/abs/2511.09838)
*Deepika Yadav,Spyros Stathopoulos,Patrick Foster,Andreas Tsiamis,Mohamed Awadein,Hannah Levene,Themis Prodromakis*

Main category: cond-mat.mtrl-sci

TL;DR: 本研究展示了一种基于HfZrO的电压可编程铁电忆阻器，可实现超过8个稳定、可重构的电容状态（3位编码），具有24 pF的非易失性窗口。该器件在低电压（3 V）下切换，每个状态具有长保持时间（10^5秒）和高耐久性（10^6次循环），确保可靠的多级操作。通过原子力显微镜在纳米尺度上直接观察到多状态电荷保持，证实了单个状态的鲁棒性。将该器件集成到高通滤波器中，证明了其电路级可行性，可将截止频率移动超过5 kHz。


<details>
  <summary>Details</summary>
Motivation: 现有可调电容器需要连续偏置或机械驱动，限制了其在自适应和可重构电子器件中的应用。本研究旨在开发一种新型非易失性、可重编程的电容器。

Method: 本研究展示了一种基于HfZrO的电压可编程铁电忆阻器。通过施加不同电压来编程器件的电容状态，并使用原子力显微镜在纳米尺度上进行观察。将器件集成到高通滤波器中进行电路级验证。

Result: 该器件实现了超过8个稳定、可重构的电容状态（3位编码），电容范围为24 pF。器件在3 V低电压下切换，每个状态具有10^5秒的长保持时间和10^6次循环的高耐久性。集成的滤波器能够将截止频率移动超过5 kHz。

Conclusion: 本研究展示了基于铁电HfZrO的CMOS兼容、非易失性、模拟存储器的可行性，为自适应射频滤波器、可重构模拟前端和神经形态电子器件开辟了道路。

Abstract: Tuneable capacitors are vital for adaptive and reconfigurable electronics, yet existing approaches require continuous bias or mechanical actuation. Here we demonstrate a voltage-programmable ferroelectric memcapacitor based on HfZrO that achieves more than eight stable, reprogrammable capacitance states (3-bit encoding) within a non-volatile window of 24~pF. The device switches at low voltages (3~V), with each state exhibiting long retention (10^5~s) and high endurance (10^6 cycles), ensuring reliable multi-level operation. At the nanoscale, multistate charge retention was directly visualised using atomic force microscopy, confirming the robustness of individual states beyond macroscopic measurements. As a proof of concept, the capacitor was integrated into a high-pass filter, where the programmed capacitive states shift the cutoff frequency over 5~kHz, establishing circuit-level viability. This work demonstrates the feasibility of CMOS-compatible, non-volatile, analogue memory based on ferroelectric HfZrO, paving the way for adaptive RF filters, reconfigurable analogue front-ends, and neuromorphic electronics.

</details>


### [271] [Electrostatic, Luminescent, and Paramagnetic Responses of Fresh BN Nanopowders Synthesized under Concentrated Light](https://arxiv.org/abs/2511.09662)
*Lina Sartinska*

Main category: cond-mat.mtrl-sci

TL;DR: 在高温、非平衡条件下合成的氮化硼纳米粉体表面存在缺陷，表现出静电、光学和磁性。经过两年空气暴露后，这些性质消失了，表明表面化学和缺陷稳定性的重要性。


<details>
  <summary>Details</summary>
Motivation: 研究在高温、非平衡条件下合成的氮化硼纳米粉体的性质，并探讨其表面化学对其静电、光学和磁性行为的影响，以及缺陷稳定性在保持其功能特性方面的重要性。

Method: 在高温、非平衡条件下，利用高通量光学加热炉和氮气流合成氮化硼纳米粉体。通过傅里叶变换红外光谱（FTIR）和电子顺磁共振（EPR）分析，研究了合成后的纳米粉体和经过两年空气暴露后的纳米粉体的性质。同时，也分析了商业化的六方氮化硼（h-BN）纳米粉体作为参考。

Result: 合成的纳米粉体表面覆盖着一层薄薄的榍石、氧化硼和氮化硼壳，核心为元素硼。初始状态下，所有合成的纳米粉体均表现出显著的静电荷、光致发光（PL）和顺磁活性。两年空气暴露后，这些性质完全消失。商业化的h-BN纳米粉体不表现出单一的EPR共振线。FTIR分析显示，经过空气暴露的纳米粉体表面逐渐氧化和羟基化。

Conclusion: 表面化学在控制氮化硼基纳米材料的静电、光学和磁性行为方面起着至关重要的作用。缺陷稳定对于随着时间的推移保持其功能特性至关重要。空气中的水分和氧气可以有效钝化这些纳米粉体中的缺陷态。

Abstract: This study explores the properties of nanopowders synthesized under high-temperature, non-equilibrium conditions in a high-flux optical furnace in a nitrogen flow. Boron powders served as the starting material, and the intense thermal gradients during synthesis led to incomplete chemical reactions. As a result, the surface of the resulting nanoparticles is covered with a thin layer of sassolite, followed by boron oxides, beneath which lies a boron nitride shell. The subsurface contains boron-rich nitride phases, while the core consists of elemental boron. For reference, commercial platelet-like h-BN powders from the "Chempur" company were also analyzed. Initially, all synthesized nanopowders displayed pronounced electrostatic charging, photoluminescence (PL), and paramagnetic activity, attributable to high surface defect densities and unsaturated chemical bonds. However, after two years of exposure to ambient air, these nanopowders exhibited complete loss of electrostatic charging, absence of photoluminescence (PL), and disappearance of the characteristic single EPR resonance line. Similarly, commercial h-BN nanopowder from the "Chempur" company does not exhibit a single EPR resonance line too. FTIR analysis revealed progressive surface oxidation and hydroxylation of this powder, suggesting that atmospheric moisture and oxygen effectively passivated defect states. These findings underscore the critical role of surface chemistry in governing the electrostatic, optical, and magnetic behavior of BN-based nanomaterials and highlight the importance of defect stabilization for preserving functional properties over time.

</details>


### [272] [Beyond empirical models: Discovering new constitutive laws in solids with graph-based equation discovery](https://arxiv.org/abs/2511.09906)
*Hao Xu,Yuntian Chen,Dongxiao Zhang*

Main category: cond-mat.mtrl-sci

TL;DR: 提出一种基于图的方程发现框架，用于直接从多源实验数据中自动发现本构定律，并生成具有待定材料参数的自由形式符号表达式。


<details>
  <summary>Details</summary>
Motivation: 传统的现象学模型泛化能力有限，并且依赖专家知识和预设函数形式。本研究旨在提供一种新的方法来克服这些局限性。

Method: 将方程表示为有向图，其中节点代表算子和变量，边表示计算关系，边特征编码参数依赖性，从而实现对自由形式符号表达式的生成和优化。

Result: 成功发现了合金钢材料的应变率效应和锂金属的变形行为的新型本构模型，这些模型比传统经验模型具有更紧凑的解析结构和更高的准确性。

Conclusion: 所提出的基于图的方程发现框架是一种可泛化、可解释的数据驱动科学建模方法，尤其适用于传统经验公式不足以表示复杂物理现象的场景。

Abstract: Constitutive models are fundamental to solid mechanics and materials science, underpinning the quantitative description and prediction of material responses under diverse loading conditions. Traditional phenomenological models, which are derived through empirical fitting, often lack generalizability and rely heavily on expert intuition and predefined functional forms. In this work, we propose a graph-based equation discovery framework for the automated discovery of constitutive laws directly from multisource experimental data. This framework expresses equations as directed graphs, where nodes represent operators and variables, edges denote computational relations, and edge features encode parametric dependencies. This enables the generation and optimization of free-form symbolic expressions with undetermined material-specific parameters. Through the proposed framework, we have discovered new constitutive models for strain-rate effects in alloy steel materials and the deformation behavior of lithium metal. Compared with conventional empirical models, these new models exhibit compact analytical structures and achieve higher accuracy. The proposed graph-based equation discovery framework provides a generalizable and interpretable approach for data-driven scientific modelling, particularly in contexts where traditional empirical formulations are inadequate for representing complex physical phenomena.

</details>


### [273] [pH Regulates Ion Dynamics in Carboxylated Mixed Conductors](https://arxiv.org/abs/2511.09671)
*Zeyuan Sun,Mengting Sun,Rajiv Giridharagopal,Robert C. Hamburger,Siyu Qin,Haoxuan Li,Mitchell C. Hausback,Yulong Zheng,Bohyeon Kim,Heng Tan,Thomas E. Gartner,Elizabeth R. Young,Christopher J Takacs,David S. Ginger,Elsa Reichmanis*

Main category: cond-mat.mtrl-sci

TL;DR: 质子化状态可调控聚噻吩的离子和电子传输


<details>
  <summary>Details</summary>
Motivation: 化学环境（如pH）如何分子尺度调控离子和电子耦合仍不清楚

Method: 通过研究羧化聚噻吩的质子化状态对离子动力学、掺杂效率、溶剂吸收和机械响应的调控作用

Result: 质子化状态精确控制了离子动力学、掺杂效率、溶剂吸收和机械响应

Conclusion: 分子酸度是设计pH响应的混合导体和软电子材料的通用策略，可调控离子、电子和机械功能

Abstract: Coupled ionic and electronic transport underpins processes as diverse as electrochemical energy conversion, biological signaling, and soft adaptive electronics. Yet, how chemical environments such as pH modulate this coupling at the molecular scale remains poorly understood. Here, we show that the protonation state of carboxylated polythiophenes provides precise chemical control over ion dynamics, doping efficiency, solvent uptake and mechanical response. The findings establish molecular acidity as a general strategy to program ionic preference and mechanical stability, offering design principles for pH-responsive mixed conductors and soft electronic materials that couple ionic, electronic, and mechanical functionality.

</details>


### [274] [Time-Dependent Oxidation and Scale Evolution of a Wrought Co/Ni-based Superalloy](https://arxiv.org/abs/2511.09678)
*Cameron Crabb,Zachary. T. Kloenne,Samuel. R. Rogers,Chi-Hang. D. Kwok,Michelle. S. Conroy,David. Dye*

Main category: cond-mat.mtrl-sci

TL;DR: 氧化动力学随时间从近乎线性转变为抛物线行为，这与一旦形成连续的Cr2O3/α-Al2O3规模，扩散控制的生长一致。


<details>
  <summary>Details</summary>
Motivation: 了解氧化物保护层的演变对于提高高温合金的长期抗氧化性至关重要。

Method: 通过质量增益、白光干涉测量、高分辨率STEM-EDX、原子探针层析成像和X射线衍射来研究氧化动力学、表面粗糙度、氧化物形态、元素分配和相变。

Result: 氧化速率随时间从近乎线性转变为抛物线行为，形成了致密的、附着的富含铬和铝的氧化层，而非初始的多孔尖晶石层。

Conclusion: 这项工作将动力学、结构和化学联系起来，展示了原始多孔尖晶石层如何转变为致密的、附着的铬+铝层，从而在锻造的钴/镍基高温合金中提供长期保护。

Abstract: Understanding how protective oxide scales evolve over time is necessary for improving the long term resistance of superalloys. This work investigates the time-dependent oxidation behavior of an ingot-processable Co/Ni-based superalloy oxidized in air at $800~^\circ\mathrm{C}$ for $20$, $100$, and $1000~\mathrm{h}$ . Mass-gain and white-light interferometry measurements quantified oxidation kinetics, surface roughness, and spallation, while high-resolution STEM-EDX characterized oxide morphology and nanoscale elemental partitioning. Atom probe tomography captured the key transition regions between the chromia and alumina scales, and X-ray diffraction was used to identify a gradual transition from NiO and (Ni,Co)-spinel phases to a compact, dual phase chromia and alumina-rich scale. The oxidation rate evolved from near-linear to parabolic behavior with time, consistent with diffusion-controlled growth once a continuous Cr$_2$O$_3$/$α$-Al$_2$O$_3$ scale formed. These observations help link kinetics, structure and chemistry, showing how an originally porous spinel layer transforms into a dense, adherent chromia + alumina scale that provides long-term protection in wrought Co/Ni-based superalloys.

</details>


### [275] [Controlling Metastability through Annealing of High-Entropy Nanoalloy Electrocatalysts to Boost Performance towards the Oxygen Evolution Reaction](https://arxiv.org/abs/2511.09711)
*Varatharaja Nallathambi,Aneeta Jose Puthussery,Andrea M. Mingers,Robert Stuckert,André Olean-Oliveira,Sven Reichenberger,Dierk Raabe,Viktor Čolić,Baptiste Gault,Stephan Barcikowski*

Main category: cond-mat.mtrl-sci

TL;DR: 通过在有机溶剂中合成的碳掺杂的Cantor合金基非晶高熵合金纳米颗粒，并对其进行退火处理，可以提高其在析氧反应中的电催化活性。


<details>
  <summary>Details</summary>
Motivation: 低成本的过渡金属高熵纳米合金是铂族电催化剂的可持续替代品。单相固溶体的合成条件会影响相稳定性，进而改变表面成分并影响电催化性能。因此，有必要利用高熵纳米合金的相变特性来提高其催化性能。

Method: 首先，在有机溶剂中利用纳秒脉冲激光合成碳掺杂的Cantor合金基非晶高熵合金纳米颗粒。然后，通过原位电子显微镜观察其在600°C加热过程中的结晶和元素分配行为。最后，通过与未处理的纳米颗粒进行比较，评估退火处理对提高析氧反应电催化活性的效果。

Result: 在600°C加热后，非晶纳米颗粒结晶并形成具有增强碳壳的异质结构纳米颗粒，其在析氧反应中的电催化活性相比于合成后的纳米颗粒提高了5到7倍。

Conclusion: 通过对激光生成的纳米颗粒进行后合成退火处理，可以利用高熵纳米合金的相变特性来提高其电化学活性，为开发高效、低成本的电催化剂提供了新的策略。

Abstract: Low-cost transition metal high-entropy nanoalloys are emerging as sustainable alternatives to platinum group electrocatalysts. Synthesis conditions of single-phase solid solutions can alter phase stability, causing surface composition changes that affect electrocatalytic performance. Here, we propose to exploit the metastability of carbon-doped Cantor alloy-based amorphous high-entropy alloy nanoparticles produced by nanosecond-pulsed laser synthesis in organic solvents. In situ electron microscopy reveals crystallization and partitioning of elements upon heating to 600 °C, forming heterostructured nanoparticles with reinforced carbon shells that exhibit a 5- to 7-fold enhancement of the electrocatalytic activity compared to the as-synthesized counterparts for the oxygen evolution reaction. We demonstrate the strategic utilization of phase metastability in high-entropy nanoalloys through post-synthesis annealing to enhance the electrochemical activity of laser-generated nanoparticles.

</details>


### [276] [Structure of Antiphase boundaries in Ni-M-Ga: multiscale modelling](https://arxiv.org/abs/2511.09751)
*Jan Zemen,František Máca,Václav Drchal,Martin Veis,Oleg Heczko*

Main category: cond-mat.mtrl-sci

TL;DR: APBs in Ni-Mn-Ga cause MFM contrast due to their antiparallel magnetization, influencing coercivity.


<details>
  <summary>Details</summary>
Motivation: The link between atomic-scale exchange interactions at antiphase boundaries (APBs) and micrometer-scale magnetic force microscopy (MFM) contrast in Ni-Mn-Ga is unclear.

Method: Combined density functional theory (DFT) calculations on supercells with APBs and finite-element magnetostatics modeling.

Result: DFT shows the lowest-energy configuration is a pair of parallel APBs enclosing a 3-Mn-Ga layer thick region with antiparallel magnetization. The magnetostatic model shows this region generates MFM contrast extending ~100 nm. APB pairs further than 50 nm apart do not form extended antiparallel domains.

Conclusion: APB pairs cause the observed MFM contrast and explain the modest domain-wall pinning by APBs, providing insights for designing magnetic shape-memory alloys with tunable coercivity.

Abstract: Antiphase boundaries (APBs) are ubiquitous in ordered Heusler alloys and strongly influence magnetic coercivity in Ni-Mn-Ga, yet the link between their atomic-scale exchange interactions and micrometer-scale magnetic contrast measured by magnetic force microscopy (MFM) remains unclear. We combine density functional theory (DFT) and finite-element magnetostatics to bridge these scales in Ni-Mn-Ga. DFT calculations on supercells containing planar APBs show that the lowest-energy configuration comprises a pair of parallel APBs enclosing a nanoscale region - only three Mn-Ga atomic layers thick - whose magnetization is antiparallel to the surrounding matrix due to strong antiferromagnetic exchange across each APB (in contrast to ferromagnetic coupling in bulk martensite). According to our magnetostatic finite element model, this thin region with antiparallel magnetization generates the characteristic MFM contrast extending approx. 100 nm from the APB pair. When the APBs are further apart than 50 nm, dipole-dipole penalties outweigh exchange gains, preventing formation of an extended antiparallel domain, in agreement with experimental evidence. These results identify APB pairs as the origin of the observed MFM contrast and offer an interpretation of the modest strengths of domain-wall pinning by APBs, informing the design of magnetic shape-memory alloys with tailored coercivity.

</details>


### [277] [An optically enhanced crystalline silicon allotrope: hydrogen passivated type II silicon clathrate](https://arxiv.org/abs/2511.09755)
*Yinan Liu,Joseph P. Briggs,Sam Saiter,Meenakshi Singh,Carolyn A. Koh,P. Craig Taylor,Michael Walker,Khalid Mateen,Moussa Kane,Reuben T. Collins*

Main category: cond-mat.mtrl-sci

TL;DR: 氢（氘）的引入显著改善了II型硅笼形化合物的发光性能，降低了掺杂水平和结构缺陷，使其在硅基发光二极管等领域具有应用前景。


<details>
  <summary>Details</summary>
Motivation: 尽管硅笼形化合物被认为是具有直接带隙的半导体，但高掺杂水平和结构缺陷限制了其光电性能。本文旨在探索氢在笼形结构中的作用，以期改善其光电性能。

Method: 利用远程等离子体处理将氢（氘）引入II型硅笼形结构，形成NaD和SiD复合物，从而降低Na施主密度和悬空键缺陷。通过电子顺磁共振等方法验证和表征。

Result: 电子顺磁共振证实Na相关施主态密度降低了近十倍，达到了硅笼形化合物的最低掺杂水平。钝化后，光致发光强度增加了40倍，主发射峰蓝移，并出现了一个新的归因于氢相关复合中心的930 nm发射峰。这些改进在高达400°C的温度下保持稳定。

Conclusion: 氢钝化是提高硅笼形化合物发光性能的有效策略，为硅基发光二极管和其他直接带隙光电器件的应用开辟了新途径。

Abstract: While Si clathrates have been explored as promising direct bandgap semiconductors, their practical optoelectronic performance has been limited by high doping levels and structural defects. Hydrogen has long been used to improve the optoelectronic quality of conventional Si, yet its role in clathrate structures remains unexplored. In this study, we demonstrate that hydrogen (deuterium) can be incorporated into type II Si clathrate framework using remote plasma treatment. This process leads to the formation of NaD and SiD complexes, which significantly reduce both the Na donor density and dangling bond defects. Electron paramagnetic resonance confirms nearly a tenfold decrease in Na-related donor states, resulting in the lowest doping level reported in Si clathrates to date. Following passivation, the integrated photoluminescence intensity increases by a factor of 40, accompanied by a blue shift of the main emission peak, consistent with a transition closer to the intrinsic band edge. A new emission peak at 930 nm, attributed to hydrogen-related recombination centers, also appears. These improvements remain stable up to 400 oC. Altogether, this work establishes hydrogen passivation as a viable strategy for enhancing light emission in Si clathrates and opens a new pathway toward their application in Si-based light-emitting diodes and other direct-bandgap optoelectronic devices.

</details>


### [278] [A Brief Perspective on Piezotronic and Thermoelectric Coupling: Flexible Platforms for Synergistic Energy Scavenging and Peltier-Caloric Effects](https://arxiv.org/abs/2511.09757)
*David Carroll,ChaoChao Dun*

Main category: cond-mat.mtrl-sci

TL;DR: 混合热/压电发电机（T/PEGs）设备利用热电和压电材料的耦合来超越单独的能源收集效果，这表明了协同发电的出现。


<details>
  <summary>Details</summary>
Motivation: 探索利用热电和压电材料的耦合来实现能源收集，并超越两种独立效应的总和。

Method: 通过模型分析热电和压电效应的协同发电。

Result: 观察到协同效应，表明能量收集的效率可以超过两种独立效应的总和。还发现了动量珀耳帖-热效应（PCE）。

Conclusion: 热电和压电效应的耦合可以产生协同效应，从而提高能量收集的效率。然而，这表明热力学可分离性具有有限的视角。

Abstract: Advances in the development of flexible piezoelectric and thermoelectric materials have provided an important avenue for the exploration of energy scavenging through the thermodynamic-coupling of orthogonal energy-scavenging modalities. This has led to a body of work creating hybrid thermo/piezo-electric generator devices (T/PEGs) in which the two effects become thermodynamically entangled. Based on hetero- thin film architectures, such devices can exhibit a surprising power generation characteristic which is non-additive between the two energy-scavenging effects. For example, when the thermoelectric and piezoelectric effects are strongly coupled by their proximal fields, the efficacy of energy scavenging can be made to exceed that of the two effects independently. In this review of such effects, a basic coupled heat engine model is shown to provide insight into the origins of synergistic power generation. These models however, suggest the emergence of other combined thermodynamic properties such as the kinetic Peltier-Caloric Effect (PCE) traced to Onsager reciprocity. The recent observation of this effect in multicomponent systems is confirmation of the limited perspective of thermodynamic separability.

</details>


### [279] [Cryogenic UV detection using stress-engineered zero-bias ZnO-thin film based Piezo-Photonic detector](https://arxiv.org/abs/2511.09781)
*P. Sau,N. Hancock,I. Tzoka,V. Khichar,A. Barajas,G. Gansle,N. Hozhabri,V. A. Chirayath,J. Asaadi*

Main category: cond-mat.mtrl-sci

TL;DR: 本文提出了一种利用氧化锌（ZnO）薄膜在低温条件下工作的零偏压紫外（UV）探测器，该探测器利用界面应力产生的压电势进行电荷传输。


<details>
  <summary>Details</summary>
Motivation: 开发一种在低温条件下工作的零偏压紫外探测器，并探索通过应力工程提高器件性能。

Method: 制备了两种垂直堆叠的金属-半导体-金属（MSM）结构器件（Cr/ZnO/Cr 和 Cr/Si3N4/ZnO/Cr），其中第二种器件引入了氮化硅（Si3N4）柱以增加残余应力。在室温和低温下测试了器件的紫外探测性能，并通过掠入射X射线衍射（GIXRD）测量了残余应力。

Result: 引入Si3N4柱的器件（Sample II）在室温和低温下均表现出比Cr/ZnO/Cr器件（Sample I）更高的紫外诱导电压信号。GIXRD测量显示Sample II的残余应力比Sample I高约40%，这解释了紫外信号的增强。

Conclusion: 通过器件内的应力工程可以增强紫外光诱导信号，从而提高探测器的灵敏度。这种零偏压光探测器可在极端环境下（如低温液态惰性气体或高辐射空间环境）得到应用，特别是在需要低功耗或零功耗探测的场合。

Abstract: We demonstrate a zero-bias ultraviolet (UV) detector using zinc oxide (ZnO) thin films as the active semiconductor layer, specifically for application in cryogenic conditions. The zero-bias device utilizes the piezoelectric potential developed through interfacial stress in the active semiconductor layer for charge transport. We explored two vertically stacked metal-semiconductor-metal (MSM) configurations: Sample I, a device comprised of chromium (Cr)/ZnO/Cr layers, and Sample II, a ZnO-silicon nitride (Si3N4) device comprised of Cr/Si3N4/ZnO/Cr layers. The Si3N4 layer in Sample II was introduced in the form of pillars, with the aim of increasing the residual stress in the active region. These fabricated devices were tested at both room and cryogenic temperatures to characterize their UV-detection performance in a custom test stand using a 365 nm UV LED source. We observe a higher UV-induced voltage signal for Sample II in comparison to Sample I at both temperature regimes. Grazing-incidence X-ray diffraction (GIXRD) measurements showed approximately 40% higher residual stress in Sample II than in Sample I. A higher residual stress suggests a higher induced piezopotential in Sample II, explaining the enhancement in the UV-induced signal. Our results demonstrate that through appropriate in-device stress engineering, UV photoinduced signals can be enhanced, increasing detector sensitivity. A zero-bias photodetector with in-device stress engineering, as demonstrated here, can have applications in extreme environments, like cryogenic liquid noble elements or high radiation space environments, where low or zero-power detection may be required.

</details>


### [280] [Control of Extraordinary Optical Transmission in Resonant Terahertz Gratings via Lateral Depletion in an AlGaN-GaN Heterostructure](https://arxiv.org/abs/2511.09811)
*Geofrey Nyabere,Hunter Ellis,Miguel Gomez,Wei Jia,Yizheng Liu,Karli Ann Higley,Sriram Krishnamoorthy,Steve Blair,Kai Fu,Berardi Sensale-Rodriguez*

Main category: cond-mat.mtrl-sci

TL;DR: 通过控制AlGaN/GaN异质结构中的电荷密度，可以动态调控金属光栅的电磁模式，从而实现太赫兹波段的超常光学透射（EOT）。


<details>
  <summary>Details</summary>
Motivation: 研究如何通过电荷密度调控来动态操控金属光栅对电磁模式的耦合，特别是在AlGaN/GaN异质结构中。

Method: 利用AlGaN/GaN异质结构中的二维电子气（2DEG）来控制金属条带之间的电荷密度，并研究其对太赫兹波透射的影响。

Result: 在无偏压状态下，2DEG屏蔽了太赫兹场，抑制了导模的激发。当2DEG耗尽时，边界条件改变，实现了与衬底共振的有效耦合，在特定频率下产生了超常光学透射（EOT）。

Conclusion: EOT对条带间电荷分布以及导模共振（GMR）非常敏感，载流子动力学与太赫兹波段的共振电磁现象之间存在直接的相互作用。

Abstract: Periodic metallic gratings on substrates can support a range of electromagnetic modes, such as leaky waveguide, guided-resonant, and Fabry-Perot (FP) cavity modes, which can strongly modulate optical transmission under resonant excitation. Here, we investigate how this coupling can be dynamically manipulated through charge-density control in a laterally patterned AlGaN/GaN heterostructure. The structure comprises metallic stripes separated by regions containing a two-dimensional electron gas (2DEG), forming a periodically modulated interface whose electromagnetic response is governed by the charge density between the stripes. In the unbiased state, the conductive 2DEG screens the incident terahertz field and suppresses excitation of guided modes. When the 2DEG is depleted, the change in boundary conditions allows efficient coupling into substrate resonances, producing a strong modulation at particular frequencies where extraordinary optical transmission (EOT) through the structure takes place. The results highlight the sensitive dependence of guided-mode-resonance (GMR) mediated EOT on inter-stripe charge distribution and demonstrate a direct interplay between carrier dynamics and resonant electromagnetic phenomena in the terahertz regime.

</details>


### [281] [Potential-Programmed Operando Ensembles Govern Nitrate Electroreduction](https://arxiv.org/abs/2511.09869)
*Xue-Chun Jiang,Jia-Lan Chen,Wei-Xue Li,Jin-Xun Liu*

Main category: cond-mat.mtrl-sci

TL;DR: 操作条件下的电催化剂活性位点是动态变化的，并且难以识别。本研究通过结合机器学习势能和多尺度建模，解析了硝酸盐电还原（NO3RR）的Cu(111)电解质界面。研究发现，界面是一个由34种吸附物种组成的动态集合，其分布受电位影响。


<details>
  <summary>Details</summary>
Motivation: 操作条件下的电催化剂表面会不断重组，这使得在实际操作条件下识别活性位点变得困难，并阻碍了催化剂的合理设计。

Method: 研究采用多尺度建模框架，并利用了机器学习势能，以解决硝酸盐电还原（NO3RR）的Cu(111)电解质界面的操作条件问题。

Result: 在-0.70 V（相对于SHE）时，活性达到峰值，单程转化频率为0.015 s-1，氨法拉第效率接近100%。研究还发现，活性与Cu原子的过量电荷（ΔqCu）之间存在线性关系，这表明界面电荷再分配是动力学的统一描述符。

Conclusion: 该研究通过将“覆盖度”重新概念化为局部微环境的集合，将热力学稳定性和催化生产力分离开来。这种新颖的视角为通过调控电位来控制微环境和界面电荷，从而实现超越NO3RR的高覆盖度电催化作用提供了一种无需参数的策略。

Abstract: Electrocatalyst surfaces continuously reorganize on the timescale of catalytic turnover, obscuring the identification of active sites under operando conditions and hindering rational catalyst design. Here, we resolve the operando Cu(111) electrolyte interface for nitrate-to-ammonia electroreduction (NO3RR) via a multiscale modeling framework accelerated by a coverage-aware machine-learning potential. Rather than a single "average coverage" site, the working interface is a potential-gated statistical ensemble of 34 interconverting adsorbate motifs between -0.10 and -1.00 V (vs. SHE). Potential-driven shifts in motif populations produce a volcano-shaped activity trend peaking at -0.70 V, where the site-normalized turnover frequency reaches 0.015 s-1 with nearly 100% Faradaic efficiency to ammonia. The activation barriers across >150 transition states collapse into a single linear relationship with the excess charge on the reacting Cu atoms (ΔqCu), identifying interfacial charge redistribution as a unifying kinetic descriptor. The maximum activity arises not from uniform moderate coverage but from a 2NO/2NH2 quadrilateral microensemble that tunes ΔqCu to an intermediate value, simultaneously lowering the N-O cleavage and N-H formation barriers. Reconceptualizing "coverage" as an ensemble of local microenvironments decouples thermodynamic stability from catalytic productivity. This perspective furnishes a parameter-free strategy by controlling motif populations and interfacial charge via the potential to program high-coverage electrocatalysis beyond the NO3RR.

</details>


### [282] [Re-refinement of the structure of the planar hexagonal phase of ZnO nanocrystals](https://arxiv.org/abs/2511.09912)
*Musen Li,Lingyao Zhang,Wei Ren,Jeffrey R. Reimers*

Main category: cond-mat.mtrl-sci

TL;DR: ZnO的平面六方相（h-ZnO）在无外力条件下可稳定存在，具有P63/mmc对称性，这与之前的实验数据和理论计算存在差异。通过重新精炼实验数据，得到了与计算预测一致的晶格参数，证实了h-ZnO在环境条件下的亚稳态存在，并为研究ZnO及其衍生物的极化切换机制提供了关键信息。


<details>
  <summary>Details</summary>
Motivation: 研究ZnO平面六方相（h-ZnO）在无外力条件下的存在性，解决其晶体结构与之前实验数据及理论计算的矛盾。

Method: 对原始实验数据进行重新精炼，并采用更先进的技术进行分析，与第一性原理计算结果进行对比。

Result: 精炼后的晶格参数a = 3.45±0.02 Å and c = 4.46±0.02 Å，与计算预测结果吻合，表明h-ZnO可以形成亚稳态平面六方相。

Conclusion: ZnO的平面六方相在环境条件下可以亚稳态存在，该发现为理解ZnO及其衍生物以及普遍的纤锌矿结构材料的极化切换机制提供了重要信息。

Abstract: The planar hexagonal phase of ZnO, known as h-ZnO, g-ZnO, alpha-ZnO, the Bk structure, the 5-5 phase, the alpha-BN phase, etc., has P63/mmc symmetry and is implicated in ferroelectric switching mechanisms for wurtzite-ZnO. It is well-known in thin films on substrates, to be pressure stabilized, etc., but critical is its possible existence in high-purity nanocrystals under ambient conditions. Indeed, a crystal structure has been reported, but this work remains controversial as first-principles calculations predict very different structural properties. Herein, the original experimental data is re-refined, using more sophisticated techniques, to yield lattice parameters of a = 3.45+/-0.02 Å and c = 4.46+/-0.02 Å that are 0.35 Å and 0.80 Å, respectively, larger than those previously reported and in good agreement with computational predictions. This confirms that ZnO can form a metastable planar hexagonal phase. It provides key information pertaining to polarization switching in ZnO, its derivatives, and general wurtzite-structured materials.

</details>


### [283] [Electric Field-Induced Phase Transitions and Hysteresis in Ferroelectric HfO2 Captured with Machine Learning Potential](https://arxiv.org/abs/2511.09976)
*Po-Yen Chen,Teruyasu Mizoguchi*

Main category: cond-mat.mtrl-sci

TL;DR: 开发了结合BEC模型的机器学习势，实现了高效的铁电HfO2原子尺度电场模拟，并复现了铁电畴翻转和相变等关键现象。


<details>
  <summary>Details</summary>
Motivation: 铁电HfO2在铁电和介电器件中的应用至关重要，但传统的第一性原理方法在模拟大尺度原子动力学和真实电场条件下存在计算瓶颈。

Method: 开发了用于HfO2 的机器学习势 (MLP)，并结合了原位出生有效电荷 (BEC) 模型，实现了电场驱动的分子动力学模拟。

Result: 成功捕捉了场致相变、极化开关和应变依赖的介电响应等关键现象，其保真度和计算效率高。模拟结果与 AIMD 结果一致，并揭示了单斜相中可能存在的电场诱导极化激活现象。

Conclusion: 所提出的方法为功能氧化物的原子尺度探索提供了一个可扩展且可转移的工具，为铁电器件的 डेटा-驱动设计铺平了道路。

Abstract: Electric field-induced studies, including phase transition and polarization hysteresis, for ferroelectric HfO2 at the atomic scale are critical since they can largely affect its application in ferroelectric and dielectric devices. However, conventional first-principles approaches are computationally limited in capturing large-scale atomic dynamics under realistic field conditions. Here, to enable electric-field-driven molecular dynamics simulations, we develop a machine learning potential (MLP) tailored for HfO2, coupled with an in-situ Born effective charge (BEC) model. This framework enables us to capture key phenomena, including field-induced phase transitions, polarization switching, and strain-dependent dielectric responses, with high fidelity and computational efficiency. Notably, we reproduce hysteresis loops and phase transition barriers consistent with AIMD results and reveal possible electric-field-induced polarization activation in the monoclinic phase. Our approach offers a scalable and transferable tool for atomistic exploration of functional oxides and paves the way for data-driven design of ferroelectric devices.

</details>


### [284] [Numerical Modeling of Cu2MnSnS4/FeSi2 Dual-Absorber Solar Cell Achieving High Efficiency](https://arxiv.org/abs/2511.10009)
*Hasib Md Abid Bin Farid,Md Tashfiq Bin Kashem*

Main category: cond-mat.mtrl-sci

TL;DR: Cu2MnSnS4 (CMTS) 和 FeSi2 组成的双吸收层太阳能电池效率可达 34.9%


<details>
  <summary>Details</summary>
Motivation: 为了克服单结器件的效率限制，本文研究了采用 CMTS 和 FeSi2 材料组成的双吸收层太阳能电池。CMTS 材料因其比 CZTS 材料具有更好的阳离子有序性和电子质量而受到关注，而 FeSi2 材料具有窄带隙和近红外吸收能力，可以与 CMTS 形成互补。

Method: 利用 SCAPS-1D 仿真软件对 CMTS-FeSi2 双吸收层薄膜太阳能电池进行了全面的数值研究，系统地研究了几何、电子和界面参数对载流子传输和器件整体性能的影响。

Result: 优化的器件实现了 34.9% 的功率转换效率，开路电压 (VOC) 为 0.79 V，短路电流密度 (JSC) 为 51.07 mA/cm2，填充因子 (FF) 为 85.91%。

Conclusion: CMTS 和 FeSi2 的结合不仅提高了载流子收集和光谱利用率，而且为开发高效率、可持续和环境友好的薄膜光伏电池提供了一条新途径。

Abstract: Dual-absorber solar cells represent a promising approach to surpass the efficiency limit of single-junction devices by extending spectral absorption and minimizing thermalization losses. Among earth-abundant thin-film materials, kesterites have attracted considerable interest, however, the well-studied Cu2ZnSnS4 (CZTS) continues to face challenges related to antisite disorder and secondary phase formation. Replacing Zn with Mn in Cu2MnSnS4 (CMTS) mitigates these limitations, improving cation ordering and electronic quality while maintaining favorable optical properties. Yet, despite its potential, CMTS remains largely unexplored in multi-absorber configurations-only one prior study has reported a CMTS-based dual-absorber device. In this work, we present a comprehensive numerical investigation of a CMTS-FeSi2 dual-absorber thin-film solar cell using the one-dimensional solar cell capacitance simulator (SCAPS-1D). FeSi2, with its narrow band gap (0.87 eV) and strong near-infrared absorption, serves as an ideal bottom absorber to complement CMTS, enabling broader spectral utilization. The study systematically examines the effects of geometrical, electronic, and interfacial parameters on carrier transport, and overall device performance. The optimized device delivers an impressive power conversion efficiency of 34.9%, with VOC = 0.79 V, JSC = 51.07 mA/cm2, and a fill factor of 85.91%. These findings demonstrate that integrating FeSi2 with CMTS not only enhances carrier collection and spectral harvesting but also establishes a new pathway toward high-efficiency, sustainable, and environmentally benign thin-film photovoltaics.

</details>


### [285] [Giant tunneling magnetoresistance based on spin-valley-mismatched ferromagnetic metals](https://arxiv.org/abs/2511.10085)
*Kan Yan,Li Cheng,Yizhi Hu,Junjie Gao,Xiaolong Zou,Xiaobin Chen*

Main category: cond-mat.mtrl-sci

TL;DR: Intrinsic自旋-谷失配（SVM）的金属可以阻止电荷传输，类似于半金属，并实现巨大的隧道磁阻效应。1T-VSe2、1T-VS2和2H-VS2是具有SVM态的铁磁金属，在自旋阀范德华（vdW）结中可以实现超过99%的巨大磁阻。


<details>
  <summary>Details</summary>
Motivation: 寻找具有高磁阻效应的材料，以用于高磁阻器件，但可用的半金属材料非常有限。

Method: 使用第一性原理输运计算，研究铁磁1T-VSe2、1T-VS2和2H-VS2的自旋-谷失配（SVM）特性，并设计基于这些材料的自旋阀范德华（vdW）结。

Result: 发现1T-VSe2、1T-VS2和2H-VS2是具有SVM态的铁磁金属，在自旋阀范德华（vdW）结中可以实现超过99%的巨大磁阻。证明了中央层材料可以是任意非磁性材料。

Conclusion: 具有内在自旋-谷失配（SVM）状态的材料可以作为半金属的替代品，用于构建高磁阻器件，并为高磁阻器件的设计提供了新的途径。

Abstract: Half metals, which are amenable to perfect spin filtering, can be utilized for high-magnetoresistive devices. However, available half metals are very limited. Here, we demonstrate that materials with intrinsic spin-valley-mismatched (SVM) states can be used to block charge transport, resembling half metals and leading to giant tunneling magnetoresistance. As an example, by using first-principles transport calculations, we show that ferromagnetic 1\emph{T}-VSe$_2$, 1\emph{T}-VS$_2$, and 2\emph{H}-VS$_2$ are such spin-valley-mismatched metals, and giant magnetoresistance of more than 99\% can be realized in spin-valve van der Waals (vdW) junctions using these metals as electrodes. Owing to the intrinsic mismatch of spin states, the central-layer materials for the vdW junctions can be arbitrary nonmagnetic materials, in principle. Our research provides clear physical insights into the mechanism for high magnetoresistance and opens new avenues for the search and design of high-magnetoresistance devices.

</details>


### [286] [Graphene assisted III-V epitaxy towards substrate recycling](https://arxiv.org/abs/2511.10097)
*Naomie Messudom,Antonella Cavanna,Ali Madouri,Carlos Macias,Nathalie Bardou,Laurent Travers,Stéphane Collin,Jean-Christophe Harmand,Amaury Delamarre*

Main category: cond-mat.mtrl-sci

TL;DR: 通过在GaAs衬底上生长石墨烯，然后进行两步外延生长，实现了GaAs外延层的单晶生长，从而降低了高效率III-V太阳能电池的成本。


<details>
  <summary>Details</summary>
Motivation: 为了降低高效率III-V太阳能电池的成本，研究了在GaAs衬底上通过外延生长方法实现石墨烯层的重复利用。

Method: 通过在(001)GaAs衬底上沉积石墨烯，然后进行图案化，接着进行两步外延生长（分子束外延法）：第一步是选择性区域生长，第二步是横向过度生长。

Result: 研究发现，图案方向相对于下方GaAs衬底的晶向会影响GaAs形貌和质量。当图案方向为[1__10]+22.5{	extdegree}且石墨烯覆盖率为50%时，获得了最佳结果，表面粗糙度显著降低至3.3 nm。

Conclusion: 通过在GaAs衬底上生长石墨烯，然后进行两步外延生长，实现了GaAs外延层的单晶生长，从而降低了高效率III-V太阳能电池的成本。研究表明，图案方向和石墨烯覆盖率对生长质量有重要影响。

Abstract: Re-using the substrate is identified as a method for reducing the cost of high efficiency III-V solar cells. The approach investigated here consists in inserting a graphene layer onto a (001)GaAs substrate prior to the epitaxial growth of GaAs. To obtain a monocrystalline GaAs grown layer, the graphene layer is patterned, followed by a two-step epitaxial growth, here performed by molecular beam epitaxy (MBE). The first step is a selective area growth of GaAs in graphene openings, followed by a lateral overgrowth, under a modulated Ga flux. The second step, after reaching coalescence, consists in a regular growth under continuous Ga supply. It is observed that the pattern orientations relative to the crystallographic direction of the GaAs substrate below the graphene have an influence on GaAs morphology and quality. The best result was obtained for patterns oriented along [1__10]+22.5{\textdegree} with a graphene coverage of 50%, with a significantly reduced roughness down to 3.3 nm.

</details>


### [287] [pynxtools: A Python framework for generating and validating NeXus files in experimental data workflows](https://arxiv.org/abs/2511.10105)
*Sherjeel Shabih,Lukas Pielsticker,Florian Dobener,Andrea Albino,Theodore Chang,Carola Emminger,Lev Ginzburg,Ron Hildebrandt,Markus Kühbach,Rubel Mozumder,Tommaso Pincelli,Martin Aeschlimann,Marius Grundman,Walid Hetaba,Carlos-Andres Palma,Laurenz Rettig,Markus Scheidgen,José Antonio Márquez Prieto,Claudia Draxl,Sandor Brockhauser,Christoph Koch,Heiko B. Weber*

Main category: cond-mat.mtrl-sci

TL;DR: pynxtools是一个Python软件框架，通过将材料科学实验数据转换为NeXus格式，解决了仪器特定格式和多样化标准化实践导致的FAIR数据原则不兼容问题。它提供了一套固定的NeXus应用程序定义，并支持插件架构，可将各种仪器和电子实验记录本的数据转换为统一的格式，确保数据的正确性和NeXus合规性。pynxtools可与研究数据管理系统（如NOMAD）集成，简化NeXus的采用，从而实现跨多种实验技术的数据互操作性和FAIR数据管理。


<details>
  <summary>Details</summary>
Motivation: 科学数据，尤其是在物理、材料科学和材料工程领域，往往由于仪器特定格式不兼容和标准化实践多样化，未能遵循FAIR原则。

Method: pynxtools是一个Python软件开发框架，包含命令行界面（CLI），旨在将材料科学实验数据标准化为NeXus格式。它提供了一套固定的、版本化的NeXus应用程序定义，以确保跨不同科学领域（如原子探针层析成像、电子显微镜、光学光谱学、光电子能谱学、扫描探针显微镜和X射线衍射等）的数据规范的收敛和对齐。通过模块化的插件架构，pynxtools能够将来自仪器和电子实验记录本的数据及元数据转换为这些统一的定义，同时执行验证以确保数据的正确性和NeXus合规性。此外，pynxtools可以直接集成到研究数据管理系统（RDMS）中，以促进解析和规范化，并以与NOMAD系统的集成为例进行了详细说明。

Result: pynxtools框架通过简化NeXus的采用，实现了跨多种实验技术的数据互操作性和FAIR数据管理。

Conclusion: pynxtools框架通过提供标准化的数据转换流程和与研究数据管理系统的集成能力，有效地解决了科学数据在FAIR原则遵循方面面临的挑战，提高了数据的互操作性和可管理性。

Abstract: Scientific data across physics, materials science, and materials engineering often lacks adherence to FAIR principles (Barker et al., 2022; Jacobsen et al., 2020; M. D. Wilkinson et al., 2016; S. R. Wilkinson et al., 2025) due to incompatible instrument-specific formats and diverse standardization practices. pynxtools is a Python software development framework with a command line interface (CLI) that standardizes data conversion for scientific experiments in materials science to the NeXus format (Klosowski et al., 1997; Könnecke, 2006; Könnecke et al., 2015) across diverse scientific domains. NeXus defines data storage specifications for different experimental techniques through application definitions. pynxtools provides a fixed, versioned set of NeXus application definitions that ensures convergence and alignment in data specifications across, among others, atom probe tomography, electron microscopy, optical spectroscopy, photoemission spectroscopy, scanning probe microscopy, and X-ray diffraction. Through its modular plugin architecture pynxtools provides conversion of data and metadata from instruments and electronic lab notebooks to these unified definitions, while performing validation to ensure data correctness and NeXus compliance. pynxtools can be integrated directly into Research Data Management Systems (RDMS) to facilitate parsing and normalization. We detail one example for the RDM system NOMAD. By simplifying the adoption of NeXus, the framework enables true data interoperability and FAIR data management across multiple experimental techniques.

</details>


### [288] [MATAI: A Generalist Machine Learning Framework for Property Prediction and Inverse Design of Advanced Alloys](https://arxiv.org/abs/2511.10108)
*Yanchen Deng,Chendong Zhao,Yixuan Li,Bijun Tang,Xinrun Wang,Zhonghan Zhang,Yuhao Lu,Penghui Yang,Jianguo Huang,Yushan Xiao,Cuntai Guan,Zheng Liu,Bo An*

Main category: cond-mat.mtrl-sci

TL;DR: MATAI是一个机器学习框架，用于预测和逆向设计铸态合金的性能，已在钛基合金系统中成功验证，可加速高性能材料的发现。


<details>
  <summary>Details</summary>
Motivation: 材料科学领域中，由于成分空间巨大、性能目标冲突以及实际可制造性限制，先进金属合金的发现面临挑战。

Method: MATAI框架整合了一个合金数据库、基于深度神经网络的性能预测器、考虑约束的优化引擎以及迭代的人工智能-实验反馈循环。它使用多任务学习和受物理启发的归纳偏置，直接从成分预测密度、屈服强度、极限抗拉强度和伸长率等关键力学性能。合金设计被构建为一个约束优化问题，通过结合局部搜索和符号约束编程的双层方法来解决。

Result: 在钛基合金系统中，MATAI在七次迭代内就成功识别出密度低于4.45 g/cm3、强度高于1000 MPa且具有一定延展性（>5%）的候选合金。实验验证表明，MATAI设计的合金性能优于商业参考材料TC4。

Conclusion: MATAI框架能够有效解决高性能材料发现中的挑战，通过整合预测和设计能力，并在考虑实际约束的情况下加速新材料的研发进程。

Abstract: The discovery of advanced metallic alloys is hindered by vast composition spaces, competing property objectives, and real-world constraints on manufacturability. Here we introduce MATAI, a generalist machine learning framework for property prediction and inverse design of as-cast alloys. MATAI integrates a curated alloy database, deep neural network-based property predictors, a constraint-aware optimization engine, and an iterative AI-experiment feedback loop. The framework estimates key mechanical propertie, sincluding density, yield strength, ultimate tensile strength, and elongation, directly from composition, using multi-task learning and physics-informed inductive biases. Alloy design is framed as a constrained optimization problem and solved using a bi-level approach that combines local search with symbolic constraint programming. We demonstrate MATAI's capabilities on the Ti-based alloy system, a canonical class of lightweight structural materials, where it rapidly identifies candidates that simultaneously achieve lower density (<4.45 g/cm3), higher strength (>1000 MPa) and appreciable ductility (>5%) through only seven iterations. Experimental validation confirms that MATAI-designed alloys outperform commercial references such as TC4, highlighting the framework's potential to accelerate the discovery of lightweight, high-performance materials under real-world design constraints.

</details>


### [289] [Time-resolved splitting of magnons into vortex gyration and Floquet spin waves](https://arxiv.org/abs/2511.10450)
*T. Devolder,R. Lopes Seeger,C. Heins,A. Jenkins,L. C. Benetti,A. Schulman,R. Ferreira,G. Philippe,C. Chappert,H. Schultheiss,K. Schultheiss,J. -V. Kim*

Main category: cond-mat.mtrl-sci

TL;DR: 外加激励在磁畴涡旋状态的一个特定频率范围内时，会散射到涡旋旋进模式，从而形成频率梳状的Floquet自旋波。本研究通过时间分辨微波测量研究了该动力学状态的暂现过程。


<details>
  <summary>Details</summary>
Motivation: 研究外加激励如何引起磁畴涡旋状态的动力学行为，特别是Floquet自旋波的形成。

Method: 使用时间分辨微波电测量技术研究动力学状态的暂现过程。

Result: 最强的Floquet模式与旋进模式同步出现，并且具有共同的潜伏期，该潜伏期在散射阈值处发散。当驱动频率与一级方位角自旋波共振时，潜伏期最短，最短可达3纳秒。

Conclusion: 一级到发生散射的机制是正则方位角本征模的三波分裂，该分裂形成了一个由旋进磁畴激子和Floquet自旋波组成的相干对。

Abstract: Forced excitations at frequencies in the range of the first order azimuthal spin waves of a magnetic disk in the vortex state are known to scatter into the vortex gyration mode, thereby allowing the growth of Floquet spin waves forming a frequency comb. We study the temporal emergence of this dynamical state using time-resolved microwave electrical measurements. The most intense Floquet mode emerges synchronously with the gyration mode after a common incubation delay which diverges at the scattering threshold. This delay is minimal when the drive is resonant with one of the first order azimuthal spin waves. It can be as short as 3 ns for the maximum investigated power. We conclude that the first-to-occur scattering mechanism is the three-wave splitting of a regular azimuthal eigenmode into a coherent pair formed by a gyration magnon and a Floquet spin wave.

</details>


### [290] [Magnetic Frustration Enforced Electronic Reconstruction in Ni intercalated NbSe$_{2}$: Suppression of Electronic Orders](https://arxiv.org/abs/2511.10160)
*Ashutosh S. Wadge,Alexander Kazakov,Xujia Gong,Daniel Jastrzebski,Bogdan J. Kowalski,Artem Lynnyk,Lukasz Plucinski,Amar Fakhredine,Ryszard Diduszko,Marta Aleszkiewicz,Jedrzej Korczak,Dawid Wutke,Marcin Rosmus,Rafal Kurleto,Natalia Olszowska,Carmine Autieri,Andrzej Wisniewski*

Main category: cond-mat.mtrl-sci

TL;DR: 镍插入显著改变了NbSe2的物理性质，导致了磁性无序和磁挫败，并抑制了电荷密度波和超导电性，这与理论预测一致，表明镍插入和无序驱动了低维量子材料中的复杂磁序和费米面重构。


<details>
  <summary>Details</summary>
Motivation: 镍插入对NbSe2物理性质的影响，特别是磁性、电荷密度波和超导电性。

Method: 磁测量、电阻率测量和角分辨光电子能谱。

Result: 镍插入导致了磁挫败和反铁磁有序（低于23.5 K），抑制了电荷密度波和超导电性（低于300 mK），并在84 K下显示了一个新的电子口袋，并导致了范霍夫奇点（VHS）的移动。

Conclusion: Ni$_{0.19}$NbSe$_2$表现出磁挫败和非超导特性，镍插入和无序是导致复杂磁序和费米面重构的关键因素，这与理论预测一致。

Abstract: We investigate the single crystals of Ni$_{0.19}$NbSe$_2$, revealing that Ni intercalation profoundly alters the physical properties of NbSe$_2$. Magnetic measurements clearly show that the system is magnetically frustrated with antiferromagnetic ordering below 23.5\,K, with an irreversibility temperature near 10\,K, and a magnetic hysteresis with a small net magnetic moment. Overall, the system can be described as an inhomogeneous antiferromagnetic phase with magnetic disorder and magnetic frustration. We found two Curie-Weiss temperatures of -80\,K for the field in the {\it ab}-plane and -137\,K for the field out of plane, which are a consequence of anisotropic interactions in spin space and favor an orientation of the spin along the {\it c}-axis. Temperature-dependent resistivity shows a complete suppression of both charge density waves and superconducting order down to 300\,mK. Angle-resolved photoemission spectroscopy at 84\,K reveals a $\overlineΓ$-centered electron pocket in Ni$_{0.19}$NbSe$_2$, which is absent in pristine NbSe$_2$. The electronic structure results show a shift of the van Hove singularity (VHS), which is the main cause of the suppression of the electronic orders. These results align with recent theoretical predictions that Ni intercalation with cationic disorder favors frustrated antiferromagnetic stripe states, shifts the VHS and reconstructs the Fermi surface in NbSe$_2$. Our findings position Ni$_{0.19}$NbSe$_2$ within a magnetically frustrated, non-superconducting regime, highlighting how partial intercalation and disorder drive complex magnetic order and the Fermi surface reconstruction in low-dimensional quantum materials.

</details>


### [291] [Wavelength-commensurate anatase TiO\_2 particles for ro-bust and functional Mie resonances across the visible and near infrared](https://arxiv.org/abs/2511.10169)
*Pedro Tartaj,Yurena Luengo,Pedro Moronta,Luisina Forzani,Alvaro Blanco,Cefe López*

Main category: cond-mat.mtrl-sci

TL;DR: 地球丰度材料，如锐钛矿TiO2，通过尺寸可调的米氏共振，有望用于高效传感、热调节和太阳能收集。


<details>
  <summary>Details</summary>
Motivation: 需要尺寸可调且单分散性好（标准偏差<5%）的锐钛矿TiO2颗粒，以实现0.5-2微米的宽范围米氏共振，并保持高于2的折射率以确保光学对比度，但目前实验上尚未实现。

Method: 采用简单的紫外辅助热水解方法制备锐钛矿TiO2颗粒，实现了所需的尺寸和单分散性，并保持了水性加工性。

Result: 制备的锐钛矿TiO2颗粒表现出强烈的、可调的米氏共振（覆盖生物窗口），优于先前受尺寸限制的结果。这种材料可以实现对透明生物分子的强、宽带、无标记检测。

Conclusion: 该研究通过精确合成和基于米氏共振的光子学，推动了地球丰度材料的应用，并预示着通过打印技术实现低成本、按需集成的潜力，同时锐钛矿的生物相容性和光化学性质也进一步增强了其应用前景。

Abstract: Earth-abundant materials exhibiting Mie resonances across the visible and near-infrared offer opportunities for efficient and sustainable sensing, thermal regulation, and sunlight harvesting. For anatase TiO$_2$, a broadband optical and abundant material, Mie calculations indicate that robust resonances require size tunability and monodispersity (standard deviation, $\lesssim$ 5\%) over an extended range (0.5-2 $μ$m) not yet experimentally covered, while maintaining a refractive index above 2 to ensure optical contrast, for example with biomolecules. Here, we demonstrate that a simple UV-assisted thermal hydrolysis route yields anatase particles that meet all these criteria and remain aqueous-processable. Consequently, the materials display intense and modulable Mie resonances across the visible/near-infrared regions (including biological windows), outperforming previous results that were limited by size. Strong optical resonances combined with ambient-temperature processability enable robust, broadband, label-free detection of transparent biomolecules. Our insights advance precise synthesis and Mie-based photonics of an earth-abundant material, and indicate the potential for cost-effective and rapid-on-demand integration via printing technologies, further enhanced by anatase's biocompatibility and photochemical properties.

</details>


### [292] [Scalable data-driven modeling of microstructure evolution by learning local dependency and spatiotemporal translation invariance rules in phase field simulation](https://arxiv.org/abs/2511.10171)
*Zishuo Lan,Qionghuan Zeng,Weilong Ma,Xiangju Liang,Yue Li,Yu Chen,Yiming Chen,Xiaobing Hu,Junjie Li,Lei Wang,Jing Zhang,Zhijun Wang,Jincheng Wang*

Main category: cond-mat.mtrl-sci

TL;DR: 该研究展示了一种数据驱动的方法，利用卷积神经网络（CNN）加速相场（PF）模拟，即使使用少量数据也能实现大规模和长期预测。


<details>
  <summary>Details</summary>
Motivation: 现有的数据驱动方法在加速相场模拟方面存在局限性，需要大量训练数据，且黑箱性质影响长期预测的可靠性。

Method: 利用一个小型CNN，仅使用单个小型模拟的少量数据进行训练，并通过感受野分析验证了模型对局部性和时空平移不变性的捕捉能力。

Result: 该CNN模型能够无缝扩展到更大的系统，并进行可靠的长期预测，即使在训练数据的时间范围之外。模型将微观结构演化视为有限局部环境的连续重新分布。

Conclusion: CNN模型的成功归因于其归纳偏置与相场模拟的物理先验（局部性和时空平移不变性）的契合。一旦模型在早期训练数据中学习了几乎所有可能的局部环境，它就能可靠地泛化到更长的时间尺度。

Abstract: Phase-field (PF) simulation provides a powerful framework for predicting microstructural evolution but suffers from prohibitive computational costs that severely limit accessible spatiotemporal scales in practical applications. While data-driven methods have emerged as promising approaches for accelerating PF simulations, existing methods require extensive training data from numerous evolution trajectories, and their inherent black-box nature raises concerns about long-term prediction reliability. This work demonstrates, through examples of grain growth and spinodal decomposition, that a minimalist Convolutional Neural Network (CNN) trained with a remarkably small dataset even from a single small-scale simulation can achieve seamless scalability to larger systems and reliable long-term predictions far beyond the temporal range of the training data. The key insight of this work lies in revealing that the success of CNN-based models stems from the alignment between their inductive biases and the physical priors of phase-field simulations specifically, locality and spatiotemporal translation invariance. Through effective receptive field analysis, we verify that the model captures these essential properties during training. Therefore, from a reductionist perspective, the surrogate model essentially establishes a spatiotemporally invariant regression mapping between a grid point's local environment and its subsequent state. Further analysis of the model's feature space demonstrates that microstructural evolution effectively represents a continuous redistribution of a finite set of local environments. When the model has already encountered nearly all possible local environments in the early-stage training data, it can reliably generalize to much longer evolution timescales, regardless of the dramatic changes in global microstructural morphology.

</details>


### [293] [Dual-Mode Luminescent Thermometry in LiYO2:Nd3+,Yb3+ Enabled by Structural Phase Transition and Phonon-Assisted Energy Transfer](https://arxiv.org/abs/2511.10185)
*M. Tahir Abbas,M. Szymczak,D. Szymanski,M. Drozd,G. Chen,L. Marciniak*

Main category: cond-mat.mtrl-sci

TL;DR: 开发了一种结合比率和寿命读数的双模式发光温度计，利用LiYO2的相变和Yb3+到Nd3+的声子辅助能量转移。


<details>
  <summary>Details</summary>
Motivation: 开发一种能够通过比率和寿命两种模式进行读数的多模式发光温度计，以拓宽传感器的热工作范围。

Method: 结合LiYO2的相变和Yb3+到Nd3+的声子辅助能量转移，实现比率和寿命两种温度测量模式。

Result: 比率温度计在290 K时最大相对灵敏度为3.1% K^-1，寿命温度计在378 K时最大相对灵敏度为1.5% K^-1。通过调节Nd3+浓度可以改变灵敏度和最大灵敏度出现的温度。声子辅助能量转移在塑造发光动力学中起主导作用。

Conclusion: LiYO2:Nd3+,Yb3+是一种有潜力用于多模式发光温度传感的候选材料。

Abstract: In this work, a dual-mode luminescent thermometer operating via both ratiometric and lifetime-based readout strategies was developed, enabled by the coexistence of two thermally driven effects: a structural phase transition in LiYO2 and a phonon-assisted energy transfer from Yb3+ to Nd3+. As demonstrated, changes in the shape of the emission band of Yb3+ ions corresponding to the 2F5/2 -> 2F7/2 electronic transition, induced by the phase transition, enabled the design of a ratiometric thermometer with a maximum relative sensitivity (SR) of 3.1% K^-1 for LiYO2 doped with 10% Yb3+ and 1% Nd3+ at 290 K. In contrast, the temperature-dependent Yb3+ -> Nd3+ energy transfer facilitated the development of a lifetime-based thermometer with a maximum SR of 1.5% K^-1 for 20% Nd3+ at 378 K. In both approaches, tuning the Nd3+ concentration allowed modulation of both the sensitivity and the temperature at which the maximum SR occurred. This was achieved by shifting the phase transition temperature and increasing the probability of interionic energy transfer, respectively.
  Notably, the temperature ranges corresponding to the maximum SR for the ratiometric and lifetime modes were distinct, effectively broadening the thermal operating window of the sensor. Additionally, it was shown that LiYO2 doped with Nd3+ and Yb3+ can also be used as a temperature sensor through the ratio of luminescence intensities recorded at two different time gates. Furthermore, the results confirmed that the phonon-assisted energy transfer process plays the dominant role in shaping the luminescence kinetics, surpassing the influence of the structural phase transition. Overall, this study identifies LiYO2:Nd3+,Yb3+ as a promising candidate for multimodal luminescent temperature sensing applications.

</details>


### [294] [Direct Raman observation of the quantum metric in a quantum magnet](https://arxiv.org/abs/2511.10246)
*Chao-Fan Wang,Han Ge,Jun-Yang Chen,Liusuo Wu,Xiaobin Chen,Jia-Wei Mei,Mingyuan Huang*

Main category: cond-mat.mtrl-sci

TL;DR: 该论文使用圆偏振拉曼光谱研究了量子磁体K2Co(SeO3)2，首次通过单一实验测量同时揭示了Berry曲率和量子度量，并提出了量子几何的实际分解方法。


<details>
  <summary>Details</summary>
Motivation: 以往的拉曼光谱研究仅能测量Berry曲率，而无法同时测量量子度量。本研究旨在探索一种新的拉曼光谱技术，以同时探测这两种量子几何的重要组成部分。

Method: 采用圆偏振拉曼光谱技术，对量子磁体K2Co(SeO3)2进行测量。通过分析场奇偶分裂和中心频率位移，揭示其共同的微观起源，并将其与Berry曲率和量子度量联系起来。

Result: 实验结果显示，K2Co(SeO3)2的场奇偶分裂和场偶中心频率位移可以归一化到同一条曲线上，表明它们具有相同的微观起源。该数据可以用一个简单的经验二次关系来描述。

Conclusion: 本研究成功地将拉曼光谱作为探测量子度量的直接方法，并实现了在单次测量中对量子几何的有效分解，为理解和操控量子材料提供了新的视角。

Abstract: The quantum geometric tensor (QGT) unifies the Berry curvature (its imaginary part) and the quantum metric (its real part), yet Raman studies of chiral phonons have so far accessed only the former. We perform circularly polarized Raman spectroscopy on the quantum magnet K2Co(SeO3)2, where the field-odd chiral splitting and the field-even center-frequency shift collapse onto a single curve across temperature and magnetic field, revealing a common microscopic origin for both observables. Since the chiral splitting reflects the Berry curvature, the concomitant even component, arising from the same microscopic origin, captures the field-induced change of the quantum metric, corresponding to the diagonal Born-Oppenheimer correction. Across two resolvable Eg modes, the unified data are well captured by a simple empirical quadratic relation. These results establish Raman spectroscopy as a direct probe of the quantum metric and an operational decomposition of quantum geometry within a single measurement.

</details>


### [295] [Effect of Concentration Fluctuations on Material Properties of Disordered Alloys](https://arxiv.org/abs/2511.10259)
*Han-Pu Liang,Chuan-Nan Li,Xin-Ru Tang,Xun Xu,Chen Qiu,Qiu-Shi Huang,Su-Huai Wei*

Main category: cond-mat.mtrl-sci

TL;DR: 通过密度-态拟合（DOSF）方法解决无序半导体合金带隙计算问题，提高理论与实验的一致性。


<details>
  <summary>Details</summary>
Motivation: 无序合金的局部浓度波动可能导致少数配置（如本体AX或BX区域）影响材料特性计算，进而产生理论与实验的显著差异。

Method: 提出密度-态拟合（DOSF）方法，用于从多数配置中提取合金带隙，以解决标准SQS计算中带隙被低估的问题。

Result: 所提出的DOSF方法能够准确计算无序半导体合金的带隙，解决了长期存在的电子结构计算难题。

Conclusion: DOSF方法为计算无序合金的带隙提供了一种与实验一致的途径，并提出应开发类似方法来处理依赖于局域化合金波函数等材料特性。

Abstract: Alloying compound AX with another compound BX is widely used to tune material properties. For disordered alloys, due to the lack of periodicity, it has been challenging to calculate and study their material properties. Special quasi-random structure (SQS) method has been developed and widely used to treat this issue by matching averaged atomic correlation functions to those of ideal random alloys, enabling accurate predictions of macroscopic material properties such as total energy and volume. However, in AxB1-x alloys, statistically allowed local concentration fluctuations can give rise to defect-like minority configurations, such as bulk-like AX or BX regions in the extreme, which could strongly affect calculation of some of the material properties such as semiconductor bandgap, if it is not defined properly, leading to significant discrepancies between theory and experiment. In this work, taking the bandgap as an example, we demonstrate that the calculated alloy bandgap can be significantly underestimated in standard SQS calculations when the SQS cell size is increased to improve the structural model and the bandgap is defined conventionally as the energy difference between the lowest unoccupied state and the highest occupied state, because the rare event motifs can lead to wavefunction localization and become the dominant factor in determining the "bandgap", contrary to experiment. To be consistent with experiment, we show that the bandgap of the alloy should be extracted from the majority configurations using a density-of-states fitting (DOSF) method. This DOSF approach resolves the long-standing issue of calculating electronic structure of disordered semiconductor alloys. Similar approaches should also be developed to treat material properties that depends on localized alloy wavefunctions.

</details>


### [296] [Probing the Liquid Solid Interfaces of 2D SnSe MXene Battery Anodes at the Nanoscale](https://arxiv.org/abs/2511.10278)
*Lukas Worch,Kavin Arunasalam,Neil Mulcahy,Syeda Ramin Jannat,James Douglas,Baptiste Gault,Valeria Nicolosi,Michele Shelly Conroy*

Main category: cond-mat.mtrl-sci

TL;DR: SnSe用作锂离子电池负极材料时，体积膨胀导致容量衰减。将SnSe纳米颗粒嵌入Ti3C2Tx MXene框架中可以提高导电性和结构稳定性。通过低温聚焦离子束（cryo FIB）和低温原子探针断层扫描（cryo APT）分析，揭示了SnSe的降解机制，包括相变、活性物质溶解，以及首次发现的铜集流体腐蚀和铜离子迁移。这表明集流体腐蚀也是导致容量衰减的原因之一。


<details>
  <summary>Details</summary>
Motivation: 理解锂离子电池的退化过程对于提高长期性能和推动可持续能源技术至关重要。SnSe作为一种有前景的负极材料，虽然理论容量高，但在充放电过程中会发生体积膨胀，导致机械不稳定和容量衰减。

Method: 采用低温聚焦离子束（cryo FIB）进行切片和观察，以及低温原子探针断层扫描（cryo APT）对特定区域进行高空间和化学分辨率的分析，以揭示SnSe在循环过程中的材料再分布、形貌变化和降解机制。

Result: 研究观察到SnSe在循环过程中发生了材料再分布和形貌转变。通过cryo APT分析，发现了包括相变、活性物质部分溶解等纳米尺度降解机制，并且首次直接证据表明铜集流体发生了腐蚀，铜离子迁移到了电极中。这表明集流体腐蚀会直接导致化学污染和复合电极的容量衰减。

Conclusion: 结合使用cryo FIB和cryo APT是研究锂离子电池等活性、光束敏感体系中电极降解的有效方法，为设计更耐用、更稳定的下一代电池材料提供了关键见解。铜集流体的腐蚀和铜离子的迁移是影响SnSe基复合电极性能的重要因素。

Abstract: Understanding degradation processes in lithium ion batteries is essential for improving long term performance and advancing sustainable energy technologies. Tin selenide (SnSe) has emerged as a promising anode material due to the high theoretical capacity of tin. Unlike conventional intercalation based electrodes, SnSe undergoes conversion and alloying reactions with lithium to form Li4.4Sn, Sn, and Li2Se, enabling high lithium storage but inducing large volume changes that cause mechanical instability and capacity fading. Embedding SnSe nanoparticles within a Ti3C2Tx MXene framework offers a strategy to mitigate these effects by enhancing conductivity and structural resilience. Here, cryogenic focused ion beam (cryo FIB) slice and view revealed progressive material redistribution and morphological transformation during cycling, underscoring the need for site specific chemical analysis. Cryogenic atom probe tomography (cryo APT) of selected regions provided high spatial and chemical resolution while preserving beam sensitive phases, uncovering nanoscale degradation mechanisms including phase transformations, partial dissolution of active material, and, importantly, the first direct evidence of copper corrosion and copper ion migration from the current collector into the electrode. The observation of copper redistribution demonstrates that current collector degradation contributes directly to chemical contamination and capacity fading in composite electrodes. Together, cryo FIB and cryo APT provide a powerful workflow for elucidating electrode degradation in reactive, beam sensitive systems, offering critical insights for designing more durable and stable next generation battery materials.

</details>


### [297] [Out-of-Plane Nonlinear Orbital Hall Torque](https://arxiv.org/abs/2511.10314)
*Hui Wang,Xukun Feng,Jin Cao,Huiying Liu,Weibo Gao,Cong Xiao,Shengyuan A. Yang,Lay Kee Ang*

Main category: cond-mat.mtrl-sci

TL;DR: 利用非线性轨道霍尔效应产生用于自旋转移扭矩的轨道扭矩，以实现对垂直磁化的无场确定性切换。


<details>
  <summary>Details</summary>
Motivation: 尽管轨道电子学取得了最新进展，但产生用于垂直磁化无场确定性切换的平面外轨道扭矩仍然是一个关键挑战。

Method: 利用非线性轨道霍尔效应产生轨道扭矩，并通过第一性原理计算研究了RhSi、YPtBi和PbTaSe2等代表性拓扑金属。

Result: 所产生的轨道扭矩在非线性轨道霍尔效应下得到显著放大，并且其强度超过了迄今为止报道的线性机制的扭矩。

Conclusion: 该研究将轨道输运的研究推向非线性区域，拓宽了轨道源材料的范围，并为开发高性能轨道电子器件建立了一条新途径。

Abstract: Despite recent advances in orbitronics, generating out-of-plane orbital torques essential for field-free deterministic switching of perpendicular magnetization remains a key challenge. Here, we propose a strategy to produce such unconventional torques across broad classes of materials, by leveraging the nonlinear orbital Hall effect. We demonstrate that this nonlinear orbital response is dramatically amplified by topological band degeneracies, where it overwhelmingly dominates the spin response even in systems with strong spin-orbit coupling. These features are confirmed via a quantitative investigation of representative topological metals RhSi, YPtBi, and PbTaSe$_2$, by combining our theory with first-principles calculations. The resulting orbital torques substantially surpass those from linear mechanisms reported thus far. These findings propel the research of orbital transport into the nonlinear regime, broaden the scope of orbital source materials, and establish a new pathway towards high-performance orbitronic devices.

</details>


### [298] [Spin and lattice dynamics at the spin-reorientation transitions in the rare-earth orthoferrite Sm$_{0.55}$Tb$_{0.45}$FeO$_{3}$](https://arxiv.org/abs/2511.10396)
*R. M. Dubrovin,A. I. Brulev,N. R. Vovk,I. A. Eliseyev,N. N. Novikova,V. A. Chernyshev,A. N. Smirnov,V. Yu. Davydov,Anhua Wu,Liangbi Su,R. V. Mikhaylovskiy,A. M. Kalashnikova,R. V. Pisarev*

Main category: cond-mat.mtrl-sci

TL;DR: Sm$_{0.55}$Tb$_{0.45}$FeO$_{3}$中的磁激发和晶格激发表现出复杂的耦合，导致了有趣的磁声现象。该研究通过偏振红外反射和拉曼散射光谱技术，结合第一性原理计算，研究了自旋重取向转变期间的磁性和晶格动力学。


<details>
  <summary>Details</summary>
Motivation: 研究稀土原铁酸盐中磁激发和晶格激发的线性与非线性耦合，以及这些耦合如何导致磁声现象，特别是与自旋重取向转变相关的现象。

Method: 使用偏振红外反射和拉曼散射光谱技术，结合第一性原理计算，研究Sm$_{0.55}$Tb$_{0.45}$FeO$_{3}$在布里渊区中心的自旋和晶格动力学。

Result: 在T$_{1}$ $\simeq$ 220 K和T$_{2}$ $\simeq$ 130 K处观察到自旋重取向转变$\\Gamma_{4}(G_{a}F_{c}) \overset{T_{1}}\longleftrightarrow \\Gamma_{24}(G_{ac}F_{ac}) \overset{T_{2}}\longleftrightarrow \\Gamma_{2}(G_{c}F_{a})$。在磁转变期间，拉曼散射研究了磁激发。与纯稀土原铁酸盐相比，混合Sm$_{0.55}$Tb$_{0.45}$FeO$_{3}$中的中间磁结构$\\Gamma_{24}$表现出异常宽的温度范围$\\Delta{T} = T_{1} - T_{2} \\simeq$ 90 K。拉曼活性B$_{1g}$声子在自旋重取向转变期间没有表现出参数变化或新声子的出现。

Conclusion: Sm$_{0.55}$Tb$_{0.45}$FeO$_{3}$中中间磁相的加宽归因于稀土Sm$^{3+}$和Tb$^{3+}$离子随机分布引起的不均匀磁结构导致的磁晶各向异性变化。该研究为深入理解稀土原铁酸盐中的磁声现象提供了基础。

Abstract: Linear and non-linear couplings of magnetic and lattice excitations are at the heart of many fascinating magnetophononic phenomena observed in rare-earth orthoferrites, the distinctive feature of which is the tendency to spin-reorientation transitions. Here we report the results of the experimental study of the spin and lattice dynamics in the Brillouin zone center of the rare-earth orthoferrite Sm$_{0.55}$Tb$_{0.45}$FeO$_{3}$ by using polarized infrared reflectivity and Raman scattering spectroscopic techniques. The obtained results were supported by the first-principles calculations, which allowed us to reliably identify the parameters of most infrared- and Raman-active phonons. We reveal the spin-reorientation transitions $Γ_{4}(G_{a}F_{c}) \overset{T_{1}}\longleftrightarrow Γ_{24}(G_{ac}F_{ac}) \overset{T_{2}}\longleftrightarrow Γ_{2}(G_{c}F_{a})$ at $T_{1} \simeq 220$ K and $T_{2} \simeq 130$ K and carefully studied the following evolution of Raman scattering on magnetic excitations at these transitions. Notably, the intermediate magnetic structure $Γ_{24}$ displays an exceptionally broad temperature range $Δ{T} = T_{1} - T_{2} \simeq 90$ K in mixed Sm$_{0.55}$Tb$_{0.45}$FeO$_{3}$ compared to pure rare-earth orthoferrites. We attribute this broadening of the intermediate phase to the modification of the magnetocrystalline anisotropy as a result of the inhomogeneous magnetic structure caused by the random distribution of rare-earth $\mathrm{Sm}^{3+}$ and $\mathrm{Tb}^{3+}$ ions. We found neither change in the parameters of Raman-active $B_{1g}$ phonons nor the appearance of new phonons induced by spin-reorientation transitions, which have been reported in $\mathrm{SmFeO}_{3}$. We assume that our results provide a solid basis for more deeper understanding of magnetophononic phenomena in rare-earth orthoferrites.

</details>


### [299] [Relaxation approach to quantum-mechanical modeling of ferroelectric and antiferroelectric phase transitions](https://arxiv.org/abs/2511.10485)
*Nikhilesh Maity,Sergey Lisenkov,Arlies Valdespino,Milan Haddad,Lewys Jones,Amit Kumar,Nazanin Bassiri-Gharb,Inna Ponomareva*

Main category: cond-mat.mtrl-sci

TL;DR: 本文提出了一个基于量子力学和弛豫过程的新模型，用于模拟铁电体和反铁电体的相变及其迟滞回线，克服了传统经典模型的局限性，并能进行第一性原理模拟。


<details>
  <summary>Details</summary>
Motivation: 传统的铁电体和反铁电体相变模型依赖于阿伦尼乌斯活化过程和经典力学描述，存在定性或经验性的局限。需要一个更精确、能进行第一性原理模拟的新模型。

Method: 提出一个新模型，该模型基于两个核心假设：相变是弛豫过程，并且需要量子力学处理。将此模型应用于铁电体和反铁电体。

Result: 该模型成功克服了传统模型的局限性，能够进行铁电体和反铁电体相变的有效第一性原理模拟。结果表明，量子力学在传统上被认为是经典过程的相变中也起着重要作用。

Conclusion: 本文提出的新模型是一个基于量子力学和弛豫过程的框架，能够有效模拟铁电体和反铁电体的相变，并强调了量子力学在其中的重要性。该框架有望应用于更广泛的相变现象，包括磁性、弹性、多铁性、电子相变以及量子隧穿、化学反应速率等。

Abstract: Ferroelectrics and antiferroelectrics are the electric counterparts of ferromagnets and antiferromagnets. These materials undergo temperature- and electric-field-induced phase transitions that give rise to their characteristic hysteresis loops. Modeling such hysteresis loops and associated phase transitions enables both a deeper fundamental understanding and reliable property predictions for this important class of materials. To date, modeling has largely relied on classical approaches, often remaining qualitative and/or empirical. Traditional interpretation of these transitions rests on two assumptions: (i) they are activated Arrhenius-type processes and (ii) they occur well within the classical regime. Here, we demonstrate that a model can instead be built on two ''orthogonal`` assumptions: (i) the phase transitions are relaxational processes and (ii) they require a quantum mechanical treatment. Applying this model to both antiferroelectrics and ferroelectrics overcomes the limitations of traditional models and enables efficient first-principles simulations of phase transitions. Furthermore, the success of our unconventional approach highlights the significance of quantum mechanics in transitions long regarded as purely classical. We anticipate that this framework will be applicable to a broad range of phase transitions, including magnetic, elastic, multiferroic, and electronic, along with modeling of quantum tunneling, rates of chemical reactions, and others.

</details>


### [300] [In-vacuum surface flashover of SiN, AlN, and etched SiO2 thin films at micrometre scales](https://arxiv.org/abs/2511.10528)
*Vijay Kumar,Martin Siegele-Brown,Matthew Aylett,Sebastian Weidt,Winfried Karl Hensinger*

Main category: cond-mat.mtrl-sci

TL;DR: SiO2, SiN, and AlN薄膜在微米尺度上的表面闪络电压阈值，并测试了不同蚀刻化学物质对SiO2层的影响。SiN和AlN的性能明显优于所有SiO2样品，在5μm的距离下表面闪络电压提高了45%，且差异随着电极间距的增大而增大。


<details>
  <summary>Details</summary>
Motivation: 研究SiO2、SiN和AlN薄膜在微米尺度上的表面闪络电压阈值，并评估不同蚀刻化学物质对SiO2层的影响。

Method: 测试了SiO2、SiN和AlN薄膜在不同电极间距下的表面闪络电压阈值，并比较了未经处理和经过HF或Transene AlPad Etch 639蚀刻的SiO2样品。

Result: SiN和AlN的性能明显优于所有SiO2样品，在5μm的距离下表面闪络电压提高了45%，且差异随着电极间距的增大而增大。未经处理的SiO2样品与使用HF或Transene AlPad Etch 639蚀刻的SiO2样品之间没有显著差异。

Conclusion: SiN和AlN薄膜在微米尺度表面闪络电压方面优于SiO2薄膜。

Abstract: We investigate the surface flashover voltage threshold for SiO$_2$, SiN, and AlN thin films over micrometre scale lengths. Furthermore, we test the effects of different etching chemistries on SiO$_2$ layers. We find that there is little significant difference between untreated SiO$_2$ samples and those that have been etched with hydrogen fluoride or Transene AlPad Etch 639. SiN and AlN samples performed significantly better than all SiO$_2$ samples giving a 45% increase in surface flashover voltage at a distance of 5 $μ$m with the difference increasing with electrode spacing.

</details>


### [301] [Excitonic Landscapes in Monolayer Lateral Heterostructures Revealed by Unsupervised Machine Learning](https://arxiv.org/abs/2511.10600)
*Maninder Kaur,Nicolas T. Sandino,Jason P. Terry,Mahdi Ghafariasl,Yohannes Abate*

Main category: cond-mat.mtrl-sci

TL;DR: 基于无监督机器学习的框架，用于分析二维材料的光谱数据。


<details>
  <summary>Details</summary>
Motivation: 二维异质结构材料具有丰富的光电特性，为研究界面物理和多体相互作用提供了平台。但传统的光谱数据分析方法效率低下且主观性强。

Method: 提出了一种结合主成分分析（PCA）、t分布随机邻域嵌入（t-SNE）和密度聚类（DBSCAN）的无监督机器学习框架，用于分析二维材料（如Mo_xW_{1-x}S_2合金和MoS_2--WS_2异质结构）的超光谱光致发光（PL）数据。

Result: 该机器学习框架能够快速、可扩展地从超光谱PL数据中提取定量和可解释的信息，识别出与成分、应变和缺陷相关的不同光谱区域，并能分解代表性光谱以区分带边激子和缺陷相关跃迁。

Conclusion: 该机器学习方法为理解二维材料的丰富光学性质提供了一种强大且自动化的途径。

Abstract: Two-dimensional (2D) in-plane heterostructures including compositionally graded alloys and lateral heterostructures with defined interfaces display rich optoelectronic properties and offer versatile platforms to explore one-dimensional interface physics and many-body interaction effects. Graded \(\mathrm{Mo}_x\mathrm{W}_{1-x}\mathrm{S}_2\) alloys show smooth spatial variations in composition and strain that continuously tune excitonic emission, while \(\mathrm{MoS}_2\)--\(\mathrm{WS}_2\) lateral heterostructures contain atomically sharp interfaces supporting one-dimensional excitonic phenomena. These single-layer systems combine tunable optical and electronic properties with potential for stable, high-performance optoelectronic devices. Hyperspectral and nano-resolved photoluminescence (PL) imaging enable spatial mapping of optical features along with local variations in composition, strain, and defects, but manual interpretation of such large datasets is slow and subjective. Here, we introduce a fast and scalable unsupervised machine-learning (ML) framework to extract quantitative and interpretable information from hyperspectral PL datasets of graded \(\mathrm{Mo}_x\mathrm{W}_{1-x}\mathrm{S}_2\) alloys and \(\mathrm{MoS}_2\)--\(\mathrm{WS}_2\) heterostructures. Combining principal-component analysis (PCA), t-distributed stochastic neighbor embedding (t-SNE), and density-based spatial clustering (DBSCAN), we uncover spectrally distinct domains associated with composition, strain, and defect variations. Decomposition of representative spectra reveals multiple emission species, including band-edge excitons and defect-related transitions, demonstrating that ML-driven analysis provides a robust and automated route to interpret rich optical properties of 2D materials.

</details>


### [302] [Uniaxial strain tuning of polar lattice vibrations in KTaO$_3$ and SrTiO$_3$](https://arxiv.org/abs/2511.10623)
*I. Khayr,N. Somun,S. Hameed,Z. Van Fossan,X. He,R. Spieker,S. Chi,E. Clements,D. M. Pajerowski,M. Minola,B. Keimer,T. Birol,D. Pelc,M. Greven*

Main category: cond-mat.mtrl-sci

TL;DR: 该研究结合非弹性中子散射、拉曼光谱和从头计算，研究了锶钛矿 (STO) 和钽酸钾 (KTO) 材料中应变诱导的铁电相变过程中软极性声子的演变。研究发现，声子模式保持欠阻尼且能量不为零，这与一阶量子相变一致。研究还揭示了在绝缘 KTO 和 STO 中，声子能量与静态介电常数之间的 Lyddane-Sachs-Teller 关系被严重违反，这表明存在由长程相互作用引起的慢介观涨落。在金属 STO 中，研究发现在较低的临界应力下发生了一阶相变。


<details>
  <summary>Details</summary>
Motivation: 研究STO和KTO这两种接近铁电相变的材料，旨在解决围绕其相变性质和关联涨落的长期存在的争论。

Method: 结合非弹性中子散射、拉曼光谱和从头计算，研究应变诱导铁电相变过程中软极性声子的演变。

Result: 在绝缘KTO和STO中，观察到声子模式保持欠阻尼且能量不为零，并严重违反了Lyddane-Sachs-Teller关系，表明存在慢介观涨落。在金属STO中，发现在较低的临界应力下发生一阶相变。

Conclusion: 该研究解决了STO和KTO这两种模型系统中长期存在的关于铁电相变性质和关联涨落的问题，并揭示了慢介观涨落的存在。研究结果对其他具有软极性声子的材料也具有重要意义。

Abstract: The interplay of electronic and structural degrees of freedom is a prominent feature of many quantum materials and of particular interest in systems with strong ferroelectric fluctuations, such as SrTiO$_3$ (STO) and KTaO$_3$ (KTO). Both materials are close to a ferroelectric transition, but despite six decades of extensive research, pivotal questions regarding the nature of this transition and of the associated fluctuations remain debated. Here we combine inelastic neutron scattering, Raman spectroscopy, and ab initio calculations to study the evolution of soft polar phonons across the strain-induced ferroelectric transition in STO and KTO. We find that the modes remain underdamped and at nonzero energy, consistent with a first-order quantum phase transition. We also reveal a strong violation of the well-known Lyddane-Sachs-Teller relation between the phonon energies and static dielectric permittivities in insulating KTO and STO, which is not captured by ab initio calculations and points to the presence of slow mesoscale fluctuations induced by long-range interactions. In metallic STO, we uncover a first-order transition at a remarkably low critical stress, in qualitative agreement with recent theoretical predictions. The present work resolves several long-standing questions pertaining to the model systems STO and KTO and is relevant to numerous other materials with soft polar phonons.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [303] [Incremental Generation is Necessity and Sufficient for Universality in Flow-Based Modelling](https://arxiv.org/abs/2511.09902)
*Hossein Rouhvarzi,Anastasis Kratsios*

Main category: cs.LG

TL;DR: 增量流模型在生成模型领域有重要应用，但其理论基础尚不牢固。本文证明了增量生成对于基于流的通用生成是必要且充分的，证明了单步自治流的局限性，并提出了近似率。


<details>
  <summary>Details</summary>
Motivation: 填补增量流基生成模型在近似理论方面的空白，并为相关模型提供理论指导。

Method: 利用拓扑-动力学论证，首先证明单步自治流的局限性，然后利用自治流的代数性质，证明了增量流可以逼近定向保持的Lipschitz同胚，并在此基础上得到了连续函数和概率测度的通用逼近结果。

Result: 证明了增量生成是通用流基生成的充要条件，并得到了在特定条件下维度相关的最优逼近率O(n^{-1/d})，以及在平滑假设下维度无关的逼近率。

Conclusion: 增量流模型能够实现通用生成，并且在特定条件下可以获得最优逼近率。

Abstract: Incremental flow-based denoising models have reshaped generative modelling, but their empirical advantage still lacks a rigorous approximation-theoretic foundation. We show that incremental generation is necessary and sufficient for universal flow-based generation on the largest natural class of self-maps of $[0,1]^d$ compatible with denoising pipelines, namely the orientation-preserving homeomorphisms of $[0,1]^d$. All our guarantees are uniform on the underlying maps and hence imply approximation both samplewise and in distribution.
  Using a new topological-dynamical argument, we first prove an impossibility theorem: the class of all single-step autonomous flows, independently of the architecture, width, depth, or Lipschitz activation of the underlying neural network, is meagre and therefore not universal in the space of orientation-preserving homeomorphisms of $[0,1]^d$. By exploiting algebraic properties of autonomous flows, we conversely show that every orientation-preserving Lipschitz homeomorphism on $[0,1]^d$ can be approximated at rate $\mathcal{O}(n^{-1/d})$ by a composition of at most $K_d$ such flows, where $K_d$ depends only on the dimension. Under additional smoothness assumptions, the approximation rate can be made dimension-free, and $K_d$ can be chosen uniformly over the class being approximated. Finally, by linearly lifting the domain into one higher dimension, we obtain structured universal approximation results for continuous functions and for probability measures on $[0,1]^d$, the latter realized as pushforwards of empirical measures with vanishing $1$-Wasserstein error.

</details>


### [304] [Probability-Biased Attention over Directed Bipartite Graphs for Long-Tail ICD Coding](https://arxiv.org/abs/2511.09559)
*Tianlei Chen,Yuxiao Chen,Yang Li,Feifei Wang*

Main category: cs.LG

TL;DR: 本研究提出了一种利用图编码器和LLM来改进ICD编码的方法，特别关注长尾分布问题，并在三个数据集上实现了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: ICD编码任务面临标签空间大和长尾分布的挑战，即少数代码使用频繁，而大量稀有代码的训练数据不足。

Method: 研究提出了一种学习方法，通过构建一个带有公共和稀有代码节点的有向二分图编码器来模拟代码之间细粒度的共现关系。其中，边从公共代码指向稀有代码，并利用条件概率计算出的偏倚来注入到编码器的注意力模块中，这种方式被称为“共现编码”。此外，还利用LLM生成代码描述，以丰富代码嵌入并作为外部知识。

Result: 该方法在三个公开的ICD编码数据集上进行了评估，并在Macro-F1指标上取得了显著的改进，该指标对于长尾分类至关重要，最终实现了最先进的性能。

Conclusion: 所提出的方法通过对代码共现关系的建模以及利用LLM增强代码表示，能够有效地解决ICD编码中的长尾分布问题，并提升编码的准确性。

Abstract: Automated International Classification of Diseases (ICD) coding aims to assign multiple disease codes to clinical documents, constituting a crucial multi-label text classification task in healthcare informatics. However, the task is challenging due to its large label space (10,000 to 20,000 codes) and long-tail distribution, where a few codes dominate while many rare codes lack sufficient training data. To address this, we propose a learning method that models fine-grained co-occurrence relationships among codes. Specifically, we construct a Directed Bipartite Graph Encoder with disjoint sets of common and rare code nodes. To facilitate a one-way information flow, edges are directed exclusively from common to rare codes. The nature of these connections is defined by a probability-based bias, which is derived from the conditional probability of a common code co-occurring given the presence of a rare code. This bias is then injected into the encoder's attention module, a process we term Co-occurrence Encoding. This structure empowers the graph encoder to enrich rare code representations by aggregating latent comorbidity information reflected in the statistical co-occurrence of their common counterparts. To ensure high-quality input to the graph, we utilize a large language model (LLM) to generate comprehensive descriptions for codes, enriching initial embeddings with clinical context and comorbidity information, serving as external knowledge for the statistical co-occurrence relationships in the code system. Experiments on three automated ICD coding benchmark datasets demonstrate that our method achieves state-of-the-art performance with particularly notable improvements in Macro-F1, which is the key metric for long-tail classification.

</details>


### [305] [Let the Experts Speak: Improving Survival Prediction & Calibration via Mixture-of-Experts Heads](https://arxiv.org/abs/2511.09567)
*Todd Morrill,Aahlad Puli,Murad Megjhani,Soojin Park,Richard Zemel*

Main category: cs.LG

TL;DR: 深度混合专家模型在生存分析中通过更具表达力的专家来改进聚类、校准和预测准确性。


<details>
  <summary>Details</summary>
Motivation: 尽管深度混合专家模型在生存分析中很受欢迎，但它们通常会在校准和预测准确性方面有所牺牲。本研究旨在探索一种能在聚类、校准和预测准确性之间取得平衡的方法。

Method: 提出几种离散时间深度混合专家（MoE）架构，并分析了专家表达力对模型性能的影响。

Result: 一种新的MoE架构在聚类、校准和预测准确性方面均表现出色，表明更具表达力的专家（能够为每个患者量身定制预测）优于依赖固定原型组的专家。

Conclusion: 在生存分析中，具有更高表达力的专家能够为患者提供更具个性化的预测，从而在聚类、校准和预测准确性方面都取得更好的效果。

Abstract: Deep mixture-of-experts models have attracted a lot of attention for survival analysis problems, particularly for their ability to cluster similar patients together. In practice, grouping often comes at the expense of key metrics such calibration error and predictive accuracy. This is due to the restrictive inductive bias that mixture-of-experts imposes, that predictions for individual patients must look like predictions for the group they're assigned to. Might we be able to discover patient group structure, where it exists, while improving calibration and predictive accuracy? In this work, we introduce several discrete-time deep mixture-of-experts (MoE) based architectures for survival analysis problems, one of which achieves all desiderata: clustering, calibration, and predictive accuracy. We show that a key differentiator between this array of MoEs is how expressive their experts are. We find that more expressive experts that tailor predictions per patient outperform experts that rely on fixed group prototypes.

</details>


### [306] [Is nasty noise actually harder than malicious noise?](https://arxiv.org/abs/2511.09763)
*Guy Blanc,Yizhi Huang,Tal Malkin,Rocco A. Servedio*

Main category: cs.LG

TL;DR: 本研究探讨了在两种对抗性噪声模型（恶意噪声和恶毒噪声）下，计算高效学习算法在处理布尔函数学习中的相对能力和局限性。


<details>
  <summary>Details</summary>
Motivation: 在存在噪声的情况下，研究计算高效学习算法在处理布尔函数学习中的能力和局限性，特别是在两种具有挑战性的对抗性噪声模型（恶意噪声和恶毒噪声）下。

Method: 研究了分布无关和固定分布两种设置下的情况。证明了在分布无关学习中，恶意噪声和恶毒噪声之间存在强等价性。在固定分布设置下，证明了两者之间可能存在任意大的分离。引入了忽略矛盾样本（ICE）的算法类别，并证明了对于这类算法，恶意噪声和恶毒噪声在噪声率上最多相差一倍。

Result: 在分布无关学习中，恶意噪声和恶毒噪声是等价的。在固定分布设置下，恶意噪声和恶毒噪声的学习容忍率之间可能存在任意大的差距。ICE算法在容忍噪声率方面，恶意噪声和恶毒噪声之间最多相差一倍。

Conclusion: 尽管在固定分布设置下存在挑战，但ICE算法提供了一种在两种噪声模型之间取得平衡的方法。

Abstract: We consider the relative abilities and limitations of computationally efficient algorithms for learning in the presence of noise, under two well-studied and challenging adversarial noise models for learning Boolean functions: malicious noise, in which an adversary can arbitrarily corrupt a random subset of examples given to the learner; and nasty noise, in which an adversary can arbitrarily corrupt an adversarially chosen subset of examples given to the learner.
  We consider both the distribution-independent and fixed-distribution settings. Our main results highlight a dramatic difference between these two settings: For distribution-independent learning, we prove a strong equivalence between the two noise models: If a class ${\cal C}$ of functions is efficiently learnable in the presence of $η$-rate malicious noise, then it is also efficiently learnable in the presence of $η$-rate nasty noise. In sharp contrast, for the fixed-distribution setting we show an arbitrarily large separation: Under a standard cryptographic assumption, for any arbitrarily large value $r$ there exists a concept class for which there is a ratio of $r$ between the rate $η_{malicious}$ of malicious noise that polynomial-time learning algorithms can tolerate, versus the rate $η_{nasty}$ of nasty noise that such learning algorithms can tolerate.
  To offset the negative result for the fixed-distribution setting, we define a broad and natural class of algorithms, namely those that ignore contradictory examples (ICE). We show that for these algorithms, malicious noise and nasty noise are equivalent up to a factor of two in the noise rate: Any efficient ICE learner that succeeds with $η$-rate malicious noise can be converted to an efficient learner that succeeds with $η/2$-rate nasty noise. We further show that the above factor of two is necessary, again under a standard cryptographic assumption.

</details>


### [307] [Filtering Jump Markov Systems with Partially Known Dynamics: A Model-Based Deep Learning Approach](https://arxiv.org/abs/2511.09569)
*George Stamatelis,George C. Alexandropoulos*

Main category: cs.LG

TL;DR: Jump Markov Filtering Network (JMFNet)是一种用于解决具有未知噪声统计和模式转换动力学的跳跃马尔可夫系统的实时状态估计问题的新型基于模型的深度学习框架。


<details>
  <summary>Details</summary>
Motivation: JMFNet旨在解决跳跃马尔可夫系统中的状态估计问题，特别是当噪声统计和模式转换动力学未知时，并寻求优于传统方法和现有深度学习方法的性能。

Method: 该模型采用混合架构，包括用于模式预测的循环神经网络（RNN）和用于滤波的基于模式增强的KalmanNet架构的RNN。这两种RNN通过无监督的交替最小二乘策略联合训练，以实现潜在模式的相互适应。

Result: JMFNet在各种线性/非线性系统（包括目标跟踪、摆角跟踪、洛伦兹吸引子动力学和真实数据集）上进行了广泛的数值评估。结果表明，JMFNet在非平稳和高噪声条件下优于传统的基于模型的滤波器（如交互多模型和粒子滤波器）以及无模型的深度学习基线。与KalmanNet相比，JMFNet在复杂系统或长轨迹中表现出更明显的性能提升。

Conclusion: JMFNet是一种强大且可靠的框架，可在跳跃马尔可夫系统的状态估计中实现最先进的性能，即使在具有挑战性的条件下（如非平稳性、高噪声和不确定模型参数）。其性能已被证明具有一致性，并且对初始条件、超参数选择和模型知识不准确具有低敏感性。

Abstract: This paper presents the Jump Markov Filtering Network (JMFNet), a novel model-based deep learning framework for real-time state-state estimation in jump Markov systems with unknown noise statistics and mode transition dynamics. A hybrid architecture comprising two Recurrent Neural Networks (RNNs) is proposed: one for mode prediction and another for filtering that is based on a mode-augmented version of the recently presented KalmanNet architecture. The proposed RNNs are trained jointly using an alternating least squares strategy that enables mutual adaptation without supervision of the latent modes. Extensive numerical experiments on linear and nonlinear systems, including target tracking, pendulum angle tracking, Lorenz attractor dynamics, and a real-life dataset demonstrate that the proposed JMFNet framework outperforms classical model-based filters (e.g., interacting multiple models and particle filters) as well as model-free deep learning baselines, particularly in non-stationary and high-noise regimes. It is also showcased that JMFNet achieves a small yet meaningful improvement over the KalmanNet framework, which becomes much more pronounced in complicated systems or long trajectories. Finally, the method's performance is empirically validated to be consistent and reliable, exhibiting low sensitivity to initial conditions, hyperparameter selection, as well as to incorrect model knowledge

</details>


### [308] [Learning Intersections of Halfspaces under Factorizable Distribution](https://arxiv.org/abs/2511.09832)
*Ilias Diakonikolas,Mingchen Ma,Lisheng Ren,Christos Tzamos*

Main category: cs.LG

TL;DR: 即使对于两个半空间，在边距 $γ$ 和维度 $d$ 方面学习仍然是一个悬而未决的问题。现有算法需要 $d^{O(
 log(1/γ))}$ 的准多项式时间。我们的新算法利用更通用的统计查询（SQ）绕过相关统计查询（CSQ）的硬度障碍，在满足因子化假设的分布上，以 $poly(d,1/γ)$ 时间学习两个半空间，从而在 CSQ 和 SQ 之间建立了强烈的分离。


<details>
  <summary>Details</summary>
Motivation: 学习半空间交集是计算学习理论中的一个核心问题，但即使是两个半空间，在边距 $γ$ 和维度 $d$ 方面也仍然是一个悬而未决的问题。

Method: 该算法结合了 Jennrich 算法的改进版本、基于 PCA 的矩张量随机投影以及基于梯度下降的非凸优化框架。

Result: 我们的算法在满足因子化假设的分布上，实现了 $poly(d,1/γ)$ 的时间复杂度，而基于 CSQ 的方法仍然需要准多项式时间，即使是弱学习。这在 CSQ 和 SQ 之间建立了强烈的分离。

Conclusion: 该研究提出了一个新颖的算法，该算法利用更通用的统计查询（SQ）绕过了相关统计查询（CSQ）的硬度障碍，在满足因子化假设的分布上，以 $poly(d,1/γ)$ 时间学习两个半空间。

Abstract: Learning intersections of halfspaces is a central problem in Computational Learning Theory. Even for just two halfspaces, it remains a major open question whether learning is possible in polynomial time with respect to the margin $γ$ of the data points and their dimensionality $d$. The best-known algorithms run in quasi-polynomial time $d^{O(\log(1/γ))}$, and it has been shown that this complexity is unavoidable for any algorithm relying solely on correlational statistical queries (CSQ).
  In this work, we introduce a novel algorithm that provably circumvents the CSQ hardness barrier. Our approach applies to a broad class of distributions satisfying a natural, previously studied, factorizability assumption. Factorizable distributions lie between distribution-specific and distribution-free settings, and significantly extend previously known tractable cases. Under these distributions, we show that CSQ-based methods still require quasipolynomial time even for weakly learning, whereas our algorithm achieves $poly(d,1/γ)$ time by leveraging more general statistical queries (SQ), establishing a strong separation between CSQ and SQ for this simple realizable PAC learning problem.
  Our result is grounded in a rigorous analysis utilizing a novel duality framework that characterizes the moment tensor structure induced by the marginal distributions. Building on these structural insights, we propose new, efficient learning algorithms. These algorithms combine a refined variant of Jennrich's Algorithm with PCA over random projections of the moment tensor, along with a gradient-descent-based non-convex optimization framework.

</details>


### [309] [Group Averaging for Physics Applications: Accuracy Improvements at Zero Training Cost](https://arxiv.org/abs/2511.09573)
*Valentino F. Foit,David W. Hogg,Soledad Villar*

Main category: cs.LG

TL;DR: 群平均是一种在测试时提高模型精确性的技术，它通过对对称性进行平均来增强模型的等变性，即使模型本身没有明确设计成等变模型。


<details>
  <summary>Details</summary>
Motivation: 许多自然科学领域的机器学习任务需要精确的对称性等变性，但现有方法因训练难度、对称性学习预期或实现复杂性等原因未被广泛采用。

Method: 在测试阶段，对模型输出在某个对称群上进行平均。这种方法不依赖于模型的内部结构或训练过程。

Result: 实验表明，群平均能持续降低平均评估损失，VRMSE 改进高达 37%，并能在连续动力学预测中产生视觉上更优的结果。

Conclusion: 在特定常见情况下，强制执行精确对称性没有弊端，群平均是一种简单且低成本地提高机器学习模型准确性的方法，ML4PS 社区应予以考虑。

Abstract: Many machine learning tasks in the natural sciences are precisely equivariant to particular symmetries. Nonetheless, equivariant methods are often not employed, perhaps because training is perceived to be challenging, or the symmetry is expected to be learned, or equivariant implementations are seen as hard to build. Group averaging is an available technique for these situations. It happens at test time; it can make any trained model precisely equivariant at a (often small) cost proportional to the size of the group; it places no requirements on model structure or training. It is known that, under mild conditions, the group-averaged model will have a provably better prediction accuracy than the original model. Here we show that an inexpensive group averaging can improve accuracy in practice. We take well-established benchmark machine learning models of differential equations in which certain symmetries ought to be obeyed. At evaluation time, we average the models over a small group of symmetries. Our experiments show that this procedure always decreases the average evaluation loss, with improvements of up to 37\% in terms of the VRMSE. The averaging produces visually better predictions for continuous dynamics. This short paper shows that, under certain common circumstances, there are no disadvantages to imposing exact symmetries; the ML4PS community should consider group averaging as a cheap and simple way to improve model accuracy.

</details>


### [310] [GraphSB: Boosting Imbalanced Node Classification on Graphs through Structural Balance](https://arxiv.org/abs/2511.10022)
*Chaofan Zhu,Xiaobing Rui,Zhixiao Wang*

Main category: cs.LG

TL;DR: 图学习中的不平衡节点分类是一个关键挑战，现有方法大多采用图神经网络（GNNs）。我们提出了一种名为GraphSB的新框架，通过结构平衡策略在节点合成前解决不平衡的图结构问题，并在实验中显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有的不平衡节点分类方法主要分为数据层面和算法层面，但都未能解决图结构本身的不平衡性，这是导致多数类支配和少数类同化的根本原因。

Method: GraphSB框架包含两个阶段的结构优化：结构增强（自适应地建立基于相似性的边以加强少数类节点的连通性）和关系扩散（捕捉高阶依赖关系并放大来自少数类的信号）。

Result: GraphSB框架在不平衡节点分类任务上显著优于现有最先进的方法。此外，其结构平衡模块作为即插即用模块，可以集成到现有方法中，平均提升3.67%的准确率。

Conclusion: GraphSB通过在节点合成前平衡图结构，为GNNs提供更有效的学习基础，有效解决了图学习中的不平衡节点分类问题。

Abstract: Imbalanced node classification is a critical challenge in graph learning, where most existing methods typically utilize Graph Neural Networks (GNNs) to learn node representations. These methods can be broadly categorized into the data-level and the algorithm-level. The former aims to synthesize minority-class nodes to mitigate quantity imbalance, while the latter tries to optimize the learning process to highlight minority classes. However, neither category addresses the inherently imbalanced graph structure, which is a fundamental factor that incurs majority-class dominance and minority-class assimilation in GNNs. Our theoretical analysis further supports this critical insight. Therefore, we propose GraphSB (Graph Structural Balance), a novel framework that incorporates Structural Balance as a key strategy to address the underlying imbalanced graph structure before node synthesis. Structural Balance performs a two-stage structure optimization: Structure Enhancement that adaptively builds similarity-based edges to strengthen connectivity of minority-class nodes, and Relation Diffusion that captures higher-order dependencies while amplifying signals from minority classes. Thus, GraphSB balances structural distribution before node synthesis, enabling more effective learning in GNNs. Extensive experiments demonstrate that GraphSB significantly outperforms the state-of-the-art methods. More importantly, the proposed Structural Balance can be seamlessly integrated into state-of-the-art methods as a simple plug-and-play module, increasing their accuracy by an average of 3.67\%.

</details>


### [311] [HeatGen: A Guided Diffusion Framework for Multiphysics Heat Sink Design Optimization](https://arxiv.org/abs/2511.09578)
*Hadi Keramati,Morteza Sadeghi,Rajeev K. Jaiman*

Main category: cs.LG

TL;DR: 该研究提出了一种基于引导去噪扩散概率模型（DDPM）的生成优化框架，利用代理梯度来设计散热器，以最小化压降并使表面温度保持在指定阈值以下。


<details>
  <summary>Details</summary>
Motivation: 利用引导去噪扩散概率模型（DDPM）生成满足特定约束（低压降和表面温度）的散热器设计。

Method: 使用边界表示法表示几何形状，采用多保真度方法生成训练数据，并训练去噪扩散概率模型。训练两个残差神经网络来预测压降和表面温度。利用这些代理模型的梯度来指导几何形状的生成过程，以满足约束。

Result: 生成的散热器样本的压降比传统黑盒优化方法（如CMA-ES）获得的结果低10%。

Conclusion: 该方法是一种可扩展的生成式设计方法，适用于电子冷却领域，并且在满足新约束条件时计算成本低廉，无需重新训练。

Abstract: This study presents a generative optimization framework based on a guided denoising diffusion probabilistic model (DDPM) that leverages surrogate gradients to generate heat sink designs minimizing pressure drop while maintaining surface temperatures below a specified threshold. Geometries are represented using boundary representations of multiple fins, and a multi-fidelity approach is employed to generate training data. Using this dataset, along with vectors representing the boundary representation geometries, we train a denoising diffusion probabilistic model to generate heat sinks with characteristics consistent with those observed in the data. We train two different residual neural networks to predict the pressure drop and surface temperature for each geometry. We use the gradients of these surrogate models with respect to the design variables to guide the geometry generation process toward satisfying the low-pressure and surface temperature constraints. This inference-time guidance directs the generative process toward heat sink designs that not only prevent overheating but also achieve lower pressure drops compared to traditional optimization methods such as CMA-ES. In contrast to traditional black-box optimization approaches, our method is scalable, provided sufficient training data is available. Unlike traditional topology optimization methods, once the model is trained and the heat sink world model is saved, inference under new constraints (e.g., temperature) is computationally inexpensive and does not require retraining. Samples generated using the guided diffusion model achieve pressure drops up to 10 percent lower than the limits obtained by traditional black-box optimization methods. This work represents a step toward building a foundational generative model for electronics cooling.

</details>


### [312] [Beyond Monotonicity: Revisiting Factorization Principles in Multi-Agent Q-Learning](https://arxiv.org/abs/2511.09792)
*Tianmeng Hu,Yongzheng Cui,Rui Tang,Biao Luo,Ke Li*

Main category: cs.LG

TL;DR: 基于动力学系统分析，证明了非单调值分解在多智能体强化学习中能够稳定收敛到个体-全局最大（IGM）一致的最优解，并优于单调分解方法。


<details>
  <summary>Details</summary>
Motivation: 现有值分解方法为保证IGM一致性，要么限制了表达能力，要么增加了算法复杂度。本研究旨在探索非单调值分解的可行性，并提供理论依据。

Method: 将多智能体强化学习中的值分解学习动力学建模为连续时间梯度流，并利用动力学系统分析来研究IGM一致性。

Result: 证明了在近似贪婪探索下，所有违反IGM一致性的零损失平衡点都是不稳定的鞍点，而只有IGM一致的解才是稳定的吸引子。实验表明，无约束的非单调分解能够可靠地恢复IGM最优解，并且在性能上优于单调基线方法。

Conclusion: 非单调值分解是一种有效且能稳定收敛到IGM最优解的方法，无需单调性约束，并且在实践中优于现有方法。此外，研究还为未来基于值的多智能体强化学习算法的设计提供了指导。

Abstract: Value decomposition is a central approach in multi-agent reinforcement learning (MARL), enabling centralized training with decentralized execution by factorizing the global value function into local values. To ensure individual-global-max (IGM) consistency, existing methods either enforce monotonicity constraints, which limit expressive power, or adopt softer surrogates at the cost of algorithmic complexity. In this work, we present a dynamical systems analysis of non-monotonic value decomposition, modeling learning dynamics as continuous-time gradient flow. We prove that, under approximately greedy exploration, all zero-loss equilibria violating IGM consistency are unstable saddle points, while only IGM-consistent solutions are stable attractors of the learning dynamics. Extensive experiments on both synthetic matrix games and challenging MARL benchmarks demonstrate that unconstrained, non-monotonic factorization reliably recovers IGM-optimal solutions and consistently outperforms monotonic baselines. Additionally, we investigate the influence of temporal-difference targets and exploration strategies, providing actionable insights for the design of future value-based MARL algorithms.

</details>


### [313] [Scaling Environments for LLM Agents in the Era of Learning from Interaction: A Survey](https://arxiv.org/abs/2511.09586)
*Yuchen Huang,Sijia Li,Minghao Liu,Wei Liu,Shijue Huang,Zhiyuan Fan,Hou Pong Chan,Yi R. Fung*

Main category: cs.LG

TL;DR: 静态数据集不足以培养LLM智能体在复杂任务中的适应性和长期决策能力，需要通过与环境的交互进行强化学习。文章提出了生成-执行-反馈（GEF）循环，并从环境角度对该循环中的任务生成、任务执行和反馈等阶段进行了综述，分析了基准、实现策略和应用，并指出了未来研究方向。


<details>
  <summary>Details</summary>
Motivation: 为了培养LLM智能体如适应性行为和长期决策能力，仅依赖静态数据集是不足够的，因为这些数据集成本高昂且缺乏动态性和真实性。强化学习通过与环境交互并从经验中学习是更好的选择。

Method: 提出并形式化了生成-执行-反馈（GEF）循环，其中环境生成任务、返回观察结果并提供反馈。文章从环境中心的角度，沿着GEF循环的三个阶段（任务生成、任务执行和反馈）系统地回顾了环境扩展的代表性方法。

Result: 对环境扩展的方法进行了分类和分析，涵盖了任务生成、任务执行和反馈的各个方面。此外，还分析了相关的基准、实现策略和应用。

Conclusion: 环境在LLM智能体通过GEF循环学习中起着至关重要的作用，是经验数据的生产者。未来的研究应致力于扩展环境的复杂性、真实性和交互性，以推动智能体智能的发展。

Abstract: LLM-based agents can autonomously accomplish complex tasks across various domains. However, to further cultivate capabilities such as adaptive behavior and long-term decision-making, training on static datasets built from human-level knowledge is insufficient. These datasets are costly to construct and lack both dynamism and realism. A growing consensus is that agents should instead interact directly with environments and learn from experience through reinforcement learning. We formalize this iterative process as the Generation-Execution-Feedback (GEF) loop, where environments generate tasks to challenge agents, return observations in response to agents' actions during task execution, and provide evaluative feedback on rollouts for subsequent learning. Under this paradigm, environments function as indispensable producers of experiential data, highlighting the need to scale them toward greater complexity, realism, and interactivity. In this survey, we systematically review representative methods for environment scaling from a pioneering environment-centric perspective and organize them along the stages of the GEF loop, namely task generation, task execution, and feedback. We further analyze benchmarks, implementation strategies, and applications, consolidating fragmented advances and outlining future research directions for agent intelligence.

</details>


### [314] [DynamicRTL: RTL Representation Learning for Dynamic Circuit Behavior](https://arxiv.org/abs/2511.09593)
*Ruiyang Ma,Yunhao Zhou,Yipeng Wang,Yi Liu,Zhengyuan Shi,Ziyang Zheng,Kexin Chen,Zhiqiang He,Lingwei Yan,Gang Chen,Qiang Xu,Guojie Luo*

Main category: cs.LG

TL;DR: DR-GNN通过结合静态结构和多周期执行行为来学习RTL电路表示，从而克服了现有GNN模型无法捕获电路运行时行为的局限性，并在分支命中预测和切换率预测等任务中表现优于现有模型。


<details>
  <summary>Details</summary>
Motivation: 现有基于图神经网络（GNN）的电路表示方法主要关注静态特性，未能捕获对电路验证和优化至关重要的运行时行为。

Method: DR-GNN利用操作符级控制数据流图（CDFG）来表示RTL电路，并结合静态结构和多周期执行行为来学习其表示。

Result: DR-GNN在分支命中预测和切换率预测任务上表现优于现有模型，并且其学习到的表示能有效地迁移到功耗估算和断言预测等相关的动态电路任务。

Conclusion: DR-GNN是一种新颖的方法，能够有效学习RTL电路的动态表示，并在多种下游任务中展现出优越性能。

Abstract: There is a growing body of work on using Graph Neural Networks (GNNs) to learn representations of circuits, focusing primarily on their static characteristics. However, these models fail to capture circuit runtime behavior, which is crucial for tasks like circuit verification and optimization. To address this limitation, we introduce DR-GNN (DynamicRTL-GNN), a novel approach that learns RTL circuit representations by incorporating both static structures and multi-cycle execution behaviors. DR-GNN leverages an operator-level Control Data Flow Graph (CDFG) to represent Register Transfer Level (RTL) circuits, enabling the model to capture dynamic dependencies and runtime execution. To train and evaluate DR-GNN, we build the first comprehensive dynamic circuit dataset, comprising over 6,300 Verilog designs and 63,000 simulation traces. Our results demonstrate that DR-GNN outperforms existing models in branch hit prediction and toggle rate prediction. Furthermore, its learned representations transfer effectively to related dynamic circuit tasks, achieving strong performance in power estimation and assertion prediction.

</details>


### [315] [Making Every Head Count: Sparse Attention Without the Speed-Performance Trade-off](https://arxiv.org/abs/2511.09596)
*Mingkuan Zhao,Wentao Hu,Jiayin Wang,Xin Lai,Tianchen Huang,Yuheng Min,Rui Yan,Xiaoyan Zhu*

Main category: cs.LG

TL;DR: SPAttention通过引入“结构化稀疏性”范式，将多头注意力机制的计算复杂度从O(H·N^2)降低到O(N^2)，在不牺牲性能的情况下提高训练吞吐量。


<details>
  <summary>Details</summary>
Motivation: LLM的核心注意力机制存在表达能力强但计算复杂度高（O(H·N^2)）的冲突，且现有稀疏方法常以牺牲信息完整性为代价，SPAttention旨在解决这种效率-性能的权衡。

Method: SPAttention提出“结构化稀疏性”范式，将注意力计算任务划分为不重叠的距离带，并为每个头分配独特的部分，实现H个独立的O(N^2)计算转变为一个协同的O(N^2)计算。

Result: 在OLMoE-1B-7B和0.25B-1.75B模型系列上的实验表明，SPAttention训练吞吐量约提高两倍，性能与标准密集注意力相当甚至在某些指标上更优，并且全面优于Longformer、Reformer和BigBird等稀疏注意力方法。

Conclusion: SPAttention通过结构化稀疏性范式，实现了计算效率和模型性能的提升，解决了LLM注意力机制的效率瓶颈。

Abstract: The design of Large Language Models (LLMs) has long been hampered by a fundamental conflict within their core attention mechanism: its remarkable expressivity is built upon a computational complexity of $O(H \cdot N^2)$ that grows quadratically with the context size ($N$) and linearly with the number of heads ($H$). This standard implementation harbors significant computational redundancy, as all heads independently compute attention over the same sequence space. Existing sparse methods, meanwhile, often trade information integrity for computational efficiency. To resolve this efficiency-performance trade-off, we propose SPAttention, whose core contribution is the introduction of a new paradigm we term Principled Structural Sparsity. SPAttention does not merely drop connections but instead reorganizes the computational task by partitioning the total attention workload into balanced, non-overlapping distance bands, assigning each head a unique segment. This approach transforms the multi-head attention mechanism from $H$ independent $O(N^2)$ computations into a single, collaborative $O(N^2)$ computation, fundamentally reducing complexity by a factor of $H$. The structured inductive bias compels functional specialization among heads, enabling a more efficient allocation of computational resources from redundant modeling to distinct dependencies across the entire sequence span. Extensive empirical validation on the OLMoE-1B-7B and 0.25B-1.75B model series demonstrates that while delivering an approximately two-fold increase in training throughput, its performance is on par with standard dense attention, even surpassing it on select key metrics, while consistently outperforming representative sparse attention methods including Longformer, Reformer, and BigBird across all evaluation metrics.

</details>


### [316] [Towards Emotionally Intelligent and Responsible Reinforcement Learning](https://arxiv.org/abs/2511.10573)
*Garapati Keerthana,Manik Gupta*

Main category: cs.LG

TL;DR: 该研究提出了一个负责任强化学习（RRL）框架，用于在个性化决策系统中整合用户的情绪和伦理考量，以克服现有方法的局限性。


<details>
  <summary>Details</summary>
Motivation: 现有基于静态规则或最大化参与度的个性化决策系统在医疗和行为支持领域，往往忽略用户的情绪背景和伦理约束，可能导致不敏感或不安全的干预措施，尤其是在涉及严重精神疾病、物质滥用障碍或抑郁症等领域。

Method: 提出一个负责任强化学习（RRL）框架，将个性化问题建模为约束马尔可夫决策过程（CMDP）。该框架通过多目标奖励函数来平衡短期参与度和长期用户福祉，并通过情绪感知状态表示来捕捉情绪状态、情感和风险的波动。该框架可与任何强化学习算法（如DQN、PPO）结合，并增加了安全约束或拉格朗日正则化。

Result: 该框架通过多目标奖励函数明确地平衡了短期行为参与度和长期用户福祉，并定义了一个情绪感知状态表示，捕捉情绪准备度、情感和风险的波动。所提出的架构可以与任何强化学习算法（例如 DQN、PPO）结合，并通过安全约束或拉格朗日正则化进行增强。

Conclusion: 该研究提出了一个负责任强化学习（RRL）框架，将情感和伦理考量融入个性化决策过程，旨在实现更符合伦理、值得信赖且以用户为中心的个性化系统，特别是在行为健康、教育和数字治疗等领域。该研究希望引发关于伦理对齐的强化学习方法论的讨论。

Abstract: Personalized decision systems in healthcare and behavioral support often rely on static rule-based or engagement-maximizing heuristics that overlook users' emotional context and ethical constraints. Such approaches risk recommending insensitive or unsafe interventions, especially in domains involving serious mental illness, substance use disorders, or depression. To address this limitation, we propose a Responsible Reinforcement Learning (RRL) framework that integrates emotional and contextual understanding with ethical considerations into the sequential decision-making process. RRL formulates personalization as a Constrained Markov Decision Process (CMDP), where the agent optimizes engagement and adherence while ensuring emotional alignment and ethical safety. We introduce a multi-objective reward function that explicitly balances short-term behavioral engagement with long-term user well-being, and define an emotion-informed state representation that captures fluctuations in emotional readiness, affect, and risk. The proposed architecture can be instantiated with any RL algorithm (e.g., DQN, PPO) augmented with safety constraints or Lagrangian regularization. Conceptually, this framework operationalizes empathy and responsibility within machine learning policy optimization, bridging safe RL, affective computing and responsible AI. We discuss the implications of this approach for human-centric domains such as behavioral health, education, and digital therapeutics, and outline simulation-based validation paths for future empirical work. This paper aims to initiate a methodological conversation about ethically aligned reinforcement learning for emotionally aware and trustworthy personalization systems.

</details>


### [317] [Parametric Expensive Multi-Objective Optimization via Generative Solution Modeling](https://arxiv.org/abs/2511.09598)
*Tingyang Wei,Jiao Liu,Abhishek Gupta,Chin Chun Ooi,Puay Siew Tan,Yew-Soon Ong*

Main category: cs.LG

TL;DR: 本论文提出了首个参数化多目标贝叶斯优化器，通过交替进行利用任务协同的采集驱动搜索和条件生成模型驱动的生成式解采样，实现了对参数化EMOPs的直接解预测，无需昂贵的重新评估。


<details>
  <summary>Details</summary>
Motivation: 解决现实世界中需要解决一系列昂贵的参数化多目标优化问题（P-EMOPs）的挑战，这些问题在不同的操作条件下具有不同的优化实例，并且参数空间可能包含无限多的问题。

Method: 提出了一种新的参数化多目标贝叶斯优化方法，该方法通过交替进行：1. 利用任务协同的采集驱动搜索；2. 通过条件生成模型进行生成式解采样。

Result: 在理论上，通过任务感知高斯过程利用任务协同来加速收敛。在实践中，在合成和真实世界基准测试中验证了交替框架的有效性，实现了对未见过的参数化EMOPs的直接解预测。

Conclusion: 该方法能够有效地跨相关任务进行优化，并实现对未见过的参数化EMOPs的直接解预测，而无需进行昂贵的额外评估。

Abstract: Many real-world applications require solving families of expensive multi-objective optimization problems~(EMOPs) under varying operational conditions. This gives rise to parametric expensive multi-objective optimization problems (P-EMOPs) where each task parameter defines a distinct optimization instance. Current multi-objective Bayesian optimization methods have been widely used for finding finite sets of Pareto optimal solutions for individual tasks. However, P-EMOPs present a fundamental challenge: the continuous task parameter space can contain infinite distinct problems, each requiring separate expensive evaluations. This demands learning an inverse model that can directly predict optimized solutions for any task-preference query without expensive re-evaluation. This paper introduces the first parametric multi-objective Bayesian optimizer that learns this inverse model by alternating between (1) acquisition-driven search leveraging inter-task synergies and (2) generative solution sampling via conditional generative models. This approach enables efficient optimization across related tasks and finally achieves direct solution prediction for unseen parameterized EMOPs without additional expensive evaluations. We theoretically justify the faster convergence by leveraging inter-task synergies through task-aware Gaussian processes. Meanwhile, empirical studies in synthetic and real-world benchmarks further verify the effectiveness of our alternating framework.

</details>


### [318] [NeuroLingua: A Language-Inspired Hierarchical Framework for Multimodal Sleep Stage Classification Using EEG and EOG](https://arxiv.org/abs/2511.09773)
*Mahdi Samaee,Mehran Yazdi,Daniel Massicotte*

Main category: cs.LG

TL;DR: NeuroLingua是一个受语言启发的睡眠分期框架，通过将睡眠视为一种生理语言，并利用CNN和Transformer对多模态数据进行分层建模，实现了最先进的睡眠分期性能，并提高了模型的可解释性。


<details>
  <summary>Details</summary>
Motivation: 现有的自动化睡眠分期方法在处理时间层级、融合多模态数据（如EEG和EOG）以及提高深度学习模型的可解释性方面存在局限性。

Method: 提出了一种名为NeuroLingua的语言启发式框架。该框架将30秒的睡眠周期分解为3秒的子窗口（“标记”），并使用CNN作为分词器。通过双层Transformer模型（用于编码局部依赖和整合长达七个周期的信息）来捕捉时间层级。使用图卷积网络（GCN）融合EEG和EOG模态的特征，以实现稳健的多模态集成。

Result: 在Sleep-EDF Expanded和ISRUC-Sleep数据集上进行了评估。在Sleep-EDF数据集上取得了85.3%的准确率、0.800的宏F1分数和0.796的Cohen's kappa系数，达到了最先进水平。在ISRUC数据集上也取得了81.9%的准确率、0.802的宏F1分数和0.755的kappa系数，性能具有竞争力。

Conclusion: NeuroLingua通过将睡眠视为一种组合语言，成功地统一了时间层级建模和多模态融合。该框架在提高自动化睡眠分期性能的同时，还通过注意力机制增强了对临床相关睡眠微事件的检测，为未来的可解释性、解释和因果推断研究奠定了基础，推动了睡眠分期向更透明、更具临床意义的应用发展。

Abstract: Automated sleep stage classification from polysomnography remains limited by the lack of expressive temporal hierarchies, challenges in multimodal EEG and EOG fusion, and the limited interpretability of deep learning models. We propose NeuroLingua, a language-inspired framework that conceptualizes sleep as a structured physiological language. Each 30-second epoch is decomposed into overlapping 3-second subwindows ("tokens") using a CNN-based tokenizer, enabling hierarchical temporal modeling through dual-level Transformers: intra-segment encoding of local dependencies and inter-segment integration across seven consecutive epochs (3.5 minutes) for extended context. Modality-specific embeddings from EEG and EOG channels are fused via a Graph Convolutional Network, facilitating robust multimodal integration. NeuroLingua is evaluated on the Sleep-EDF Expanded and ISRUC-Sleep datasets, achieving state-of-the-art results on Sleep-EDF (85.3% accuracy, 0.800 macro F1, and 0.796 Cohen's kappa) and competitive performance on ISRUC (81.9% accuracy, 0.802 macro F1, and 0.755 kappa), matching or exceeding published baselines in overall and per-class metrics. The architecture's attention mechanisms enhance the detection of clinically relevant sleep microevents, providing a principled foundation for future interpretability, explainability, and causal inference in sleep research. By framing sleep as a compositional language, NeuroLingua unifies hierarchical sequence modeling and multimodal fusion, advancing automated sleep staging toward more transparent and clinically meaningful applications.

</details>


### [319] [Optimistic Reinforcement Learning with Quantile Objectives](https://arxiv.org/abs/2511.09652)
*Mohammad Alipour-Vaezi,Huaiyang Zhong,Kwok-Leung Tsui,Sajad Khodadadian*

Main category: cs.LG

TL;DR: UCB-QRL是一种用于有限时间范围马尔可夫决策过程(MDP)的τ-分位数目标的优化学习算法。它通过估计转移概率并优化置信球内的分位数价值函数来工作，并提供了一个高概率的悔恨界限。


<details>
  <summary>Details</summary>
Motivation: RL在许多领域（包括医疗保健和金融）中至关重要，但传统的RL未能考虑目标函数的风险敏感性。优化累积回报分布的特定分位数是处理风险敏感性的一种流行方法。

Method: UCB-QRL是一种迭代算法。在每次迭代中，算法首先估计基础转移概率，然后围绕该估计值的一个置信球优化分位数价值函数。

Result: UCB-QRL在具有S个状态、A个动作、T个时间片段和H个时间范围的模拟环境中，提供了高概率的悔恨界限 $\mathcal O\left((2/κ)^{H+1}H\sqrt{SATH\log(2SATH/δ)}\right)$。其中$κ>0$是捕获基础MDP分位数价值敏感性的依赖于问题的常数。

Conclusion: UCB-QRL算法在有限时间范围MDP中有效地解决了风险敏感性问题，并通过提供理论上的悔恨界限证明了其有效性。

Abstract: Reinforcement Learning (RL) has achieved tremendous success in recent years. However, the classical foundations of RL do not account for the risk sensitivity of the objective function, which is critical in various fields, including healthcare and finance. A popular approach to incorporate risk sensitivity is to optimize a specific quantile of the cumulative reward distribution. In this paper, we develop UCB-QRL, an optimistic learning algorithm for the $τ$-quantile objective in finite-horizon Markov decision processes (MDPs). UCB-QRL is an iterative algorithm in which, at each iteration, we first estimate the underlying transition probability and then optimize the quantile value function over a confidence ball around this estimate. We show that UCB-QRL yields a high-probability regret bound $\mathcal O\left((2/κ)^{H+1}H\sqrt{SATH\log(2SATH/δ)}\right)$ in the episodic setting with $S$ states, $A$ actions, $T$ episodes, and $H$ horizons. Here, $κ>0$ is a problem-dependent constant that captures the sensitivity of the underlying MDP's quantile value.

</details>


### [320] [Generalization Can Emerge in Tabular Foundation Models From a Single Table](https://arxiv.org/abs/2511.09665)
*Junwei Ma,Nour Shaheen,Alex Labach,Amine Mhedhbi,Frank Hutter,Anthony L. Caterini,Valentin Thomas*

Main category: cs.LG

TL;DR: In-context learning for deep tabular models can generalize well with limited data, challenging the need for extensive synthetic or real-world pre-training. Self-supervised pre-training on a single real table can lead to strong transfer learning across diverse benchmarks. The number and quality of pre-training tasks derived from a dataset are crucial for downstream performance.


<details>
  <summary>Details</summary>
Motivation: The prevailing view is that deep tabular models require extensive pre-training on large synthetic or real-world datasets for effective in-context learning and generalization. This paper challenges this assumption.

Method: The study systematically pre-trained and evaluated models on diverse datasets, focusing on self-supervised pre-training using a single real table. They analyzed the importance of data aspects for building a Tabular Foundation Model (TFM) and investigated the relationship between the number and quality of pre-training tasks and downstream performance.

Result: A relatively small amount of data, specifically self-supervised pre-training on a single real table, is sufficient for strong generalization across heterogeneous benchmarks. The number and quality of tasks constructed from a dataset are key factors influencing downstream performance.

Conclusion: Contrary to common belief, Tabular Foundation Models (TFMs) do not require massive datasets for effective in-context learning. Efficient pre-training strategies, particularly those focusing on the quality and quantity of tasks derived from even limited data, are sufficient for achieving strong generalization.

Abstract: Deep tabular modelling increasingly relies on in-context learning where, during inference, a model receives a set of $(x,y)$ pairs as context and predicts labels for new inputs without weight updates. We challenge the prevailing view that broad generalization here requires pre-training on large synthetic corpora (e.g., TabPFN priors) or a large collection of real data (e.g., TabDPT training datasets), discovering that a relatively small amount of data suffices for generalization. We find that simple self-supervised pre-training on just a \emph{single} real table can produce surprisingly strong transfer across heterogeneous benchmarks. By systematically pre-training and evaluating on many diverse datasets, we analyze what aspects of the data are most important for building a Tabular Foundation Model (TFM) generalizing across domains. We then connect this to the pre-training procedure shared by most TFMs and show that the number and quality of \emph{tasks} one can construct from a dataset is key to downstream performance.

</details>


### [321] [TawPipe: Topology-Aware Weight Pipeline Parallelism for Accelerating Long-Context Large Models Training](https://arxiv.org/abs/2511.09741)
*Houming Wu,Ling Chen*

Main category: cs.LG

TL;DR: TawPipe是一种拓扑感知权重流水线并行方法，通过优化通信来提高LLM训练效率，尤其是在长上下文场景下。


<details>
  <summary>Details</summary>
Motivation: 有限的设备内存和昂贵的跨设备通信是训练大型语言模型（LLMs）的主要瓶颈。现有的流水线并行方法（如WeiPipe）虽然减轻了内存压力，但激活通信开销会随着序列长度线性增加，限制了长上下文训练的效率。

Method: TawPipe利用分布式集群中的分层带宽来优化通信效率。它通过以下方式实现：(i) 根据拓扑结构对设备进行分组，以优化节点内和节点间的通信；(ii) 为每个设备分配固定的模型权重和梯度分片，避免冗余传输；(iii) 将通信与计算重叠以隐藏延迟。

Result: 在最多24个GPU上使用LLaMA风格模型进行的广泛实验表明，TawPipe与最先进的基线相比，实现了卓越的吞吐量和可扩展性。

Conclusion: TawPipe通过利用分层带宽和优化通信模式，显著提高了大型语言模型训练的效率，特别是在处理长序列时，降低了跨节点通信的开销。

Abstract: Training large language models (LLMs) is fundamentally constrained by limited device memory and costly inter-device communication. Although pipeline parallelism alleviates memory pressure by partitioning models across devices, it incurs activation communication overhead that scales linearly with sequence length, limiting efficiency in long-context training. Recent weight-passing approaches (e.g., WeiPipe) mitigate this by transmitting model weights instead of activations, but suffer from redundant peer-to-peer (P2P) transfers and underutilized intra-node bandwidth. We propose TawPipe--topology-aware weight pipeline parallelism, which exploits hierarchical bandwidth in distributed clusters for improved communication efficiency. TawPipe: (i) groups devices based on topology to optimize intra-node collective and inter-node P2P communication; (ii) assigns each device a fixed shard of model weights and gradients, avoiding redundant transfers; and (iii) overlaps communication with computation to hide latency. Unlike global collective operations used in fully sharded data parallelism (FSDP), TawPipe confines most communication within node boundaries, significantly reducing cross-node traffic. Extensive experiments on up to 24 GPUs with LLaMA-style models show that TawPipe achieves superior throughput and scalability compared to state-of-the-art baselines.

</details>


### [322] [GEM+: Scalable State-of-the-Art Private Synthetic Data with Generator Networks](https://arxiv.org/abs/2511.09672)
*Samuel Maddock,Shripad Gade,Graham Cormode,Will Bullock*

Main category: cs.LG

TL;DR: GEM+ 结合了 AIM 的自适应测量和 GEM 的可扩展生成器网络，在处理高维数据集方面优于 AIM，并在实用性和可扩展性方面取得了最先进的成果。


<details>
  <summary>Details</summary>
Motivation: 现有的差分隐私合成表格数据框架（如 AIM）在处理高维数据时效率低下，需要大量内存并且在图结构改变时需要从头开始重新训练。GEM 等后续方法通过使用生成器神经网络提高了可扩展性，但实际比较主要集中在小数据集上。

Method: 提出 GEM+，它整合了 AIM 的自适应测量框架和 GEM 的可扩展生成器网络。

Result: GEM+ 在实用性和可扩展性方面均优于 AIM，并在处理超过一百列的数据集方面取得了最先进的成果，而 AIM 由于内存和计算开销而无法处理这些数据集。

Conclusion: GEM+ 是一种有效的框架，可以处理高维数据集，并在保持差分隐私的同时提供高质量的合成数据。

Abstract: State-of-the-art differentially private synthetic tabular data has been defined by adaptive 'select-measure-generate' frameworks, exemplified by methods like AIM. These approaches iteratively measure low-order noisy marginals and fit graphical models to produce synthetic data, enabling systematic optimisation of data quality under privacy constraints. Graphical models, however, are inefficient for high-dimensional data because they require substantial memory and must be retrained from scratch whenever the graph structure changes, leading to significant computational overhead. Recent methods, like GEM, overcome these limitations by using generator neural networks for improved scalability. However, empirical comparisons have mostly focused on small datasets, limiting real-world applicability. In this work, we introduce GEM+, which integrates AIM's adaptive measurement framework with GEM's scalable generator network. Our experiments show that GEM+ outperforms AIM in both utility and scalability, delivering state-of-the-art results while efficiently handling datasets with over a hundred columns, where AIM fails due to memory and computational overheads.

</details>


### [323] [SMoFi: Step-wise Momentum Fusion for Split Federated Learning on Heterogeneous Data](https://arxiv.org/abs/2511.09828)
*Mingkun Yang,Ran Zhu,Qing Wang,Jie Yang*

Main category: cs.LG

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Split Federated Learning is a system-efficient federated learning paradigm that leverages the rich computing resources at a central server to train model partitions. Data heterogeneity across silos, however, presents a major challenge undermining the convergence speed and accuracy of the global model. This paper introduces Step-wise Momentum Fusion (SMoFi), an effective and lightweight framework that counteracts gradient divergence arising from data heterogeneity by synchronizing the momentum buffers across server-side optimizers. To control gradient divergence over the training process, we design a staleness-aware alignment mechanism that imposes constraints on gradient updates of the server-side submodel at each optimization step. Extensive validations on multiple real-world datasets show that SMoFi consistently improves global model accuracy (up to 7.1%) and convergence speed (up to 10.25$\times$). Furthermore, SMoFi has a greater impact with more clients involved and deeper learning models, making it particularly suitable for model training in resource-constrained contexts.

</details>


### [324] [Boosted GFlowNets: Improving Exploration via Sequential Learning](https://arxiv.org/abs/2511.09677)
*Pedro Dall'Antonia,Tiago da Silva,Daniel Augusto de Souza,César Lincoln C. Mattos,Diego Mesquita*

Main category: cs.LG

TL;DR: GFlowNets在采样时存在探索不均的问题，我们提出了Boosted GFlowNets，通过顺序训练补偿已有模型捕获的残差奖励来解决此问题，从而改善了探索和样本多样性。


<details>
  <summary>Details</summary>
Motivation: GFlowNets 存在探索不均的问题，难以覆盖高奖励区域，因为容易到达的区域会主导训练，而难到达的区域梯度消失。

Method: Boosted GFlowNets 通过顺序训练 GFlowNets 的集成模型，每个模型优化补偿已有模型捕获的残差奖励。

Result: Boosted GFlowNets 在多模态合成基准和肽设计任务上实现了显著更好的探索和样本多样性，同时保持了标准轨迹平衡训练的稳定性和简单性。

Conclusion: Boosted GFlowNets 通过残差奖励有效解决了 GFlowNets 的探索不均问题，提高了在高奖励区域的覆盖率和样本多样性。

Abstract: Generative Flow Networks (GFlowNets) are powerful samplers for compositional objects that, by design, sample proportionally to a given non-negative reward. Nonetheless, in practice, they often struggle to explore the reward landscape evenly: trajectories toward easy-to-reach regions dominate training, while hard-to-reach modes receive vanishing or uninformative gradients, leading to poor coverage of high-reward areas. We address this imbalance with Boosted GFlowNets, a method that sequentially trains an ensemble of GFlowNets, each optimizing a residual reward that compensates for the mass already captured by previous models. This residual principle reactivates learning signals in underexplored regions and, under mild assumptions, ensures a monotone non-degradation property: adding boosters cannot worsen the learned distribution and typically improves it. Empirically, Boosted GFlowNets achieve substantially better exploration and sample diversity on multimodal synthetic benchmarks and peptide design tasks, while preserving the stability and simplicity of standard trajectory-balance training.

</details>


### [325] [SEBA: Sample-Efficient Black-Box Attacks on Visual Reinforcement Learning](https://arxiv.org/abs/2511.09681)
*Tairan Huang,Yulin Jin,Junxu Liu,Qingqing Ye,Haibo Hu*

Main category: cs.LG

TL;DR: SEBA框架通过结合影子Q模型、生成对抗网络和世界模型，实现了对视觉强化学习代理的高效黑盒对抗性攻击，显著降低了累积奖励和环境交互次数，同时保持了视觉保真度。


<details>
  <summary>Details</summary>
Motivation: 现有黑盒攻击方法在图像基础的连续控制任务中效果有限，因为其动作空间大且需要大量环境查询。本文旨在提出一种更有效的黑盒对抗性攻击方法，以应对视觉强化学习的脆弱性。

Method: SEBA框架包含一个影子Q模型（用于估计对抗条件下的累积奖励）、一个生成对抗网络（用于生成视觉上不可察觉的扰动）和一个世界模型（用于模拟环境动态以减少真实环境查询）。通过两阶段迭代训练过程，交替学习影子模型和优化生成器。

Result: SEBA框架在MuJoCo和Atari基准测试中表现出强大的攻击性能，显著降低了累积奖励，保持了视觉保真度，并大大减少了与现有黑盒和白盒方法相比所需的环境交互次数。

Conclusion: SEBA是一种样本高效的黑盒对抗性攻击框架，能够有效攻击视觉强化学习代理，并在攻击性能、视觉保真度和样本效率方面取得了显著的改进。

Abstract: Visual reinforcement learning has achieved remarkable progress in visual control and robotics, but its vulnerability to adversarial perturbations remains underexplored. Most existing black-box attacks focus on vector-based or discrete-action RL, and their effectiveness on image-based continuous control is limited by the large action space and excessive environment queries. We propose SEBA, a sample-efficient framework for black-box adversarial attacks on visual RL agents. SEBA integrates a shadow Q model that estimates cumulative rewards under adversarial conditions, a generative adversarial network that produces visually imperceptible perturbations, and a world model that simulates environment dynamics to reduce real-world queries. Through a two-stage iterative training procedure that alternates between learning the shadow model and refining the generator, SEBA achieves strong attack performance while maintaining efficiency. Experiments on MuJoCo and Atari benchmarks show that SEBA significantly reduces cumulative rewards, preserves visual fidelity, and greatly decreases environment interactions compared to prior black-box and white-box methods.

</details>


### [326] [Unlocking Dynamic Inter-Client Spatial Dependencies: A Federated Spatio-Temporal Graph Learning Method for Traffic Flow Forecasting](https://arxiv.org/abs/2511.10434)
*Feng Wang,Tianxiang Chen,Shuyue Wei,Qian Chu,Yi Zhang,Yifan Sun,Zhiming Zheng*

Main category: cs.LG

TL;DR: FedSTGD是一个用于解决交通时间序列数据中跨客户端空间依赖性建模和重建的联邦学习框架，特别关注动态依赖性。


<details>
  <summary>Details</summary>
Motivation: 真实世界交通数据分布在多个利益相关者手中，给建模和重建跨客户端空间依赖性带来了挑战，现有方法通常忽略了依赖性的动态性质。

Method: FedSTGD框架包含一个联邦非线性计算分解模块来近似图操作，以及一个图节点嵌入增强模块来缓解性能下降。这些模块通过客户端-服务器协同学习协议进行协调，将动态跨客户端空间依赖性学习任务分解为轻量级、可并行处理的子任务。

Result: 在四个真实世界数据集上的大量实验表明，FedSTGD在RMSE、MAE和MAPE方面优于最先进的基线方法，并且性能接近集中式基线。消融研究证实了每个模块在解决动态跨客户端空间依赖性方面的作用，敏感性分析则强调了FedSTGD在超参数变化下的鲁棒性。

Conclusion: FedSTGD能够有效处理动态的跨客户端空间依赖性，并在联邦交通时间序列建模任务中取得优越性能。

Abstract: Spatio-temporal graphs are powerful tools for modeling complex dependencies in traffic time series. However, the distributed nature of real-world traffic data across multiple stakeholders poses significant challenges in modeling and reconstructing inter-client spatial dependencies while adhering to data locality constraints. Existing methods primarily address static dependencies, overlooking their dynamic nature and resulting in suboptimal performance. In response, we propose Federated Spatio-Temporal Graph with Dynamic Inter-Client Dependencies (FedSTGD), a framework designed to model and reconstruct dynamic inter-client spatial dependencies in federated learning. FedSTGD incorporates a federated nonlinear computation decomposition module to approximate complex graph operations. This is complemented by a graph node embedding augmentation module, which alleviates performance degradation arising from the decomposition. These modules are coordinated through a client-server collective learning protocol, which decomposes dynamic inter-client spatial dependency learning tasks into lightweight, parallelizable subtasks. Extensive experiments on four real-world datasets demonstrate that FedSTGD achieves superior performance over state-of-the-art baselines in terms of RMSE, MAE, and MAPE, approaching that of centralized baselines. Ablation studies confirm the contribution of each module in addressing dynamic inter-client spatial dependencies, while sensitivity analysis highlights the robustness of FedSTGD to variations in hyperparameters.

</details>


### [327] [ConstrainedSQL: Training LLMs for Text2SQL via Constrained Reinforcement Learning](https://arxiv.org/abs/2511.09693)
*Weiqin Chen,Nhan Huu Pham,Michael Robert Glass,Long Hai Vu,Gaetano Rossiello,Dharmashankar Subramanian,Santiago Paternain*

Main category: cs.LG

TL;DR: RL在Text2SQL中很有前景，但对奖励函数敏感，容易导致奖励攻击。本文提出了一个约束RL框架，结合了自然、可解释的奖励和约束信号，并能在训练中动态平衡它们。该框架具有理论保证，并在标准Text2SQL数据集上证明了其优于现有RL训练LLM的方法。


<details>
  <summary>Details</summary>
Motivation: 现有的RL方法在Text2SQL任务中表现出色，但其性能高度依赖于奖励函数的精心设计，不当的奖励可能导致模型利用漏洞，即奖励攻击，而未能真正解决任务。

Method: 提出了一种约束RL框架，该框架能够整合自然且易于理解的奖励和约束信号，并在训练过程中动态地平衡这些信号之间的权衡。

Result: 该约束RL框架具有理论保证，并在标准Text2SQL数据集上的数值实验证实了该方法相比于最先进的RL训练LLM的优越性。

Conclusion: 本文提出的约束RL框架通过整合自然、可解释的奖励和约束信号，并能在训练中动态平衡它们，有效解决了现有RL方法在Text2SQL任务中对奖励函数敏感和奖励攻击的问题，并在实验中取得了优于现有方法的性能。

Abstract: Reinforcement learning (RL) has demonstrated significant promise in enhancing the reasoning capabilities of Text2SQL LLMs, especially with advanced algorithms such as GRPO and DAPO. However, the performance of these methods is highly sensitive to the design of reward functions. Inappropriate rewards can lead to reward hacking, where models exploit loopholes in the reward structure to achieve high scores without genuinely solving the task. This work considers a constrained RL framework for Text2SQL that incorporates natural and interpretable reward and constraint signals, while dynamically balancing trade-offs among them during the training. We establish the theoretical guarantees of our constrained RL framework and our numerical experiments on the well-known Text2SQL datasets substantiate the improvement of our approach over the state-of-the-art RL-trained LLMs.

</details>


### [328] [Efficient Hyperdimensional Computing with Modular Composite Representations](https://arxiv.org/abs/2511.09708)
*Marco Angioli,Christopher J. Kymn,Antonello Rosato,Amy Loutfi,Mauro Olivieri,Denis Kleyko*

Main category: cs.LG

TL;DR: MCR是一种高维整数向量计算模型，通过模块化算术实现，旨在提供比二元散点码模型更高的表示能力，同时内存占用更少。该研究首次对其进行了广泛评估，证明了其在容量、准确性和硬件效率方面的独特平衡。实验表明，MCR在容量上优于二元和整数向量，接近复杂值表示，但内存占用却少得多。在123个数据集上的测试显示，MCR的准确性持续提高，并且可以用少至1/4的内存达到二元散点码的性能。通过设计专用加速器，MCR在基本运算和7个选定数据集上的速度提升了3个数量级，能耗显著降低。与二元散点码在准确性相当的情况下，MCR的执行速度平均快3.08倍，能耗低2.68倍。这表明MCR虽然需要比二元散点码更复杂的操作，但其模块化算术和更高的每组件精度使其能够实现更低的维数，并且在专用硬件上实现时，比现有模型更快、更节能、精度更高。


<details>
  <summary>Details</summary>
Motivation: MCR模型虽然有潜力，但缺乏系统的分析和与其他模型的比较，导致其复杂性被认为超过了其表达能力的提升。

Method: 对MCR进行了首次广泛评估，包括容量、准确性和硬件实现方面的实验。设计了首个MCR专用加速器，并与软件实现进行了比较。

Result: MCR在容量上优于二元和整数向量，接近复杂值表示，但内存占用少。在123个数据集上，MCR的准确性得到提高，内存占用最多可减少到原来的1/4。专用加速器实现了3个数量级的速度提升和显著的能耗降低。在准确性相当的情况下，MCR比二元散点码快3.08倍，能耗低2.68倍。

Conclusion: MCR是一种比现有模型更快、更节能、精度更高的替代方案，尤其是在专用硬件上实现时。其模块化算术和更高的每组件精度允许更低的维数，从而实现更高的效率。

Abstract: The modular composite representation (MCR) is a computing model that represents information with high-dimensional integer vectors using modular arithmetic. Originally proposed as a generalization of the binary spatter code model, it aims to provide higher representational power while remaining a lighter alternative to models requiring high-precision components. Despite this potential, MCR has received limited attention. Systematic analyses of its trade-offs and comparisons with other models are lacking, sustaining the perception that its added complexity outweighs the improved expressivity. In this work, we revisit MCR by presenting its first extensive evaluation, demonstrating that it achieves a unique balance of capacity, accuracy, and hardware efficiency. Experiments measuring capacity demonstrate that MCR outperforms binary and integer vectors while approaching complex-valued representations at a fraction of their memory footprint. Evaluation on 123 datasets confirms consistent accuracy gains and shows that MCR can match the performance of binary spatter codes using up to 4x less memory. We investigate the hardware realization of MCR by showing that it maps naturally to digital logic and by designing the first dedicated accelerator. Evaluations on basic operations and 7 selected datasets demonstrate a speedup of up to 3 orders of magnitude and significant energy reductions compared to software implementation. When matched for accuracy against binary spatter codes, MCR achieves on average 3.08x faster execution and 2.68x lower energy consumption. These findings demonstrate that, although MCR requires more sophisticated operations than binary spatter codes, its modular arithmetic and higher per-component precision enable lower dimensionality. When realized with dedicated hardware, this results in a faster, more energy-efficient, and high-precision alternative to existing models.

</details>


### [329] [Generalizing PDE Emulation with Equation-Aware Neural Operators](https://arxiv.org/abs/2511.09729)
*Qian-Ze Zhu,Paul Raccuglia,Michael P. Brenner*

Main category: cs.LG

TL;DR: 提出一个方程感知模拟框架，可以泛化到未知的偏微分方程（PDE），通过对代表PDE项及其系数的向量编码进行条件约束来泛化神经网络模型。


<details>
  <summary>Details</summary>
Motivation: 传统的数值方法求解偏微分方程（PDE）的成本可能很高，而深度学习方法通常只适用于具有固定参数的单个PDE。

Method: 提出一个方程感知模拟框架，将神经网络模型与代表PDE项及其系数的向量编码相结合，并在1D PDE数据集（APEBench）上进行训练和评估。

Result: 该方法在处理未知的PDE参数集时表现出强大的性能，并且在训练窗口之外的滚动模拟中具有良好的稳定性，甚至能够泛化到完全未知的PDE。

Conclusion: 所提出的方程感知模拟框架能够泛化到未知的PDE，解决了传统方法的局限性，并为AI自动创建用于科学任务的专业级经验软件提供了基础。

Abstract: Solving partial differential equations (PDEs) can be prohibitively expensive using traditional numerical methods. Deep learning-based surrogate models typically specialize in a single PDE with fixed parameters. We present a framework for equation-aware emulation that generalizes to unseen PDEs, conditioning a neural model on a vector encoding representing the terms in a PDE and their coefficients. We present a baseline of four distinct modeling technqiues, trained on a family of 1D PDEs from the APEBench suite. Our approach achieves strong performance on parameter sets held out from the training distribution, with strong stability for rollout beyond the training window, and generalization to an entirely unseen PDE. This work was developed as part of a broader effort exploring AI systems that automate the creation of expert-level empirical software for scorable scientific tasks. The data and codebase are available at https://github.com/google-research/generalized-pde-emulator.

</details>


### [330] [FlowCast: Advancing Precipitation Nowcasting with Conditional Flow Matching](https://arxiv.org/abs/2511.09731)
*Bernardo Perrone Ribeiro,Jana Faganeli Pucer*

Main category: cs.LG

TL;DR: FlowCast利用条件流匹配（CFM）技术解决了雷达降水临近预报中的不确定性和高维数据建模挑战，实现了比扩散模型更准确、更高效的预测。


<details>
  <summary>Details</summary>
Motivation: 雷达基的降水临近预报对洪水风险管理至关重要，但现有深度学习方法在处理大气动力学不确定性和高维数据方面仍面临挑战。扩散模型虽然在生成清晰可靠的预报方面有潜力，但其迭代采样过程计算成本高昂，不适用于时间敏感的应用。

Method: 提出FlowCast模型，首次将条件流匹配（CFM）应用于降水临近预报。CFM直接学习从噪声到数据的映射，从而能够快速生成高保真样本，并大大减少函数评估次数。

Result: 实验证明FlowCast在预测准确性方面达到了新的最先进水平。与扩散模型相比，CFM目标在相同架构下既更准确，效率也显著更高，在较少的采样步数下仍能保持高性能。

Conclusion: CFM作为一种强大的、实用的高维时空预测替代方案，为降水临近预报领域带来了新的突破。

Abstract: Radar-based precipitation nowcasting, the task of forecasting short-term precipitation fields from previous radar images, is a critical problem for flood risk management and decision-making. While deep learning has substantially advanced this field, two challenges remain fundamental: the uncertainty of atmospheric dynamics and the efficient modeling of high-dimensional data. Diffusion models have shown strong promise by producing sharp, reliable forecasts, but their iterative sampling process is computationally prohibitive for time-critical applications. We introduce FlowCast, the first model to apply Conditional Flow Matching (CFM) to precipitation nowcasting. Unlike diffusion, CFM learns a direct noise-to-data mapping, enabling rapid, high-fidelity sample generation with drastically fewer function evaluations. Our experiments demonstrate that FlowCast establishes a new state-of-the-art in predictive accuracy. A direct comparison further reveals the CFM objective is both more accurate and significantly more efficient than a diffusion objective on the same architecture, maintaining high performance with significantly fewer sampling steps. This work positions CFM as a powerful and practical alternative for high-dimensional spatiotemporal forecasting.

</details>


### [331] [Data Heterogeneity and Forgotten Labels in Split Federated Learning](https://arxiv.org/abs/2511.09736)
*Joana Tirana,Dimitra Tsigkari,David Solans Noguero,Nicolas Kourtellis*

Main category: cs.LG

TL;DR: Split Federated Learning (SFL) 存在灾难性遗忘问题，特别是在数据异构的情况下。本地模型更新可能偏离全局最优，而服务器端的模型对处理顺序敏感。研究发现模型在处理序列末尾出现的类别上表现更好。提出了一种名为 Hydra 的新方法来缓解此问题，该方法受多头神经网络启发并适用于 SFL。实验证明 Hydra 优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 研究Split Federated Learning (SFL) 中数据异构导致灾难性遗忘（CF）的现象，分析了SFL的本地更新和服务器端处理顺序对模型性能的影响，特别是模型在处理序列末尾类别上表现更好。

Method: 分析了SFL中处理顺序和切分层对灾难性遗忘的影响，并提出了一种名为Hydra的新型缓解方法，该方法借鉴了多头神经网络的设计并适应了SFL的设置。

Result: 通过广泛的数值评估，证明了Hydra方法在缓解SFL中的灾难性遗忘问题上优于现有的基线方法和文献中的方法。

Conclusion: Hydra是一种有效缓解SFL中数据异构导致灾难性遗忘问题的新方法，该方法通过借鉴多头神经网络的设计并针对SFL场景进行调整，在实验中取得了优于现有方法的性能。

Abstract: In Split Federated Learning (SFL), the clients collaboratively train a model with the help of a server by splitting the model into two parts. Part-1 is trained locally at each client and aggregated by the aggregator at the end of each round. Part-2 is trained at a server that sequentially processes the intermediate activations received from each client. We study the phenomenon of catastrophic forgetting (CF) in SFL in the presence of data heterogeneity. In detail, due to the nature of SFL, local updates of part-1 may drift away from global optima, while part-2 is sensitive to the processing sequence, similar to forgetting in continual learning (CL). Specifically, we observe that the trained model performs better in classes (labels) seen at the end of the sequence. We investigate this phenomenon with emphasis on key aspects of SFL, such as the processing order at the server and the cut layer. Based on our findings, we propose Hydra, a novel mitigation method inspired by multi-head neural networks and adapted for the SFL's setting. Extensive numerical evaluations show that Hydra outperforms baselines and methods from the literature.

</details>


### [332] [Out-of-Distribution Generalization with a SPARC: Racing 100 Unseen Vehicles with a Single Policy](https://arxiv.org/abs/2511.09737)
*Bram Grooten,Patrick MacAlpine,Kaushik Subramanian,Peter Stone,Peter R. Wurman*

Main category: cs.LG

TL;DR: SPARC是一种用于鲁棒控制的单阶段自适应方法，可以实现对未见过环境的泛化，而无需在测试时访问显式上下文信息。


<details>
  <summary>Details</summary>
Motivation: 提高机器人和控制领域中智能体在不同环境（如不同地形或天气条件）下的泛化能力，特别是在测试时无法获得显式上下文信息的情况下，实现对分布外（OOD）设置的泛化。

Method: 提出SPARC（Single-Phase Adaptation for Robust Control）方法，该方法简化了先前工作中需要分两个阶段进行的上下文编码和历史适应模块的训练，实现了单阶段的适应。

Result: SPARC在Gran Turismo 7赛车模拟器和MuJoCo风力扰动环境中进行了测试，在不同的上下文设置下，SPARC能够实现可靠且鲁棒的分布外泛化。

Conclusion: SPARC通过单阶段的适应方法，能够有效地解决上下文强化学习中的分布外泛化问题，并在实际的机器人控制任务中表现出鲁棒性。

Abstract: Generalization to unseen environments is a significant challenge in the field of robotics and control. In this work, we focus on contextual reinforcement learning, where agents act within environments with varying contexts, such as self-driving cars or quadrupedal robots that need to operate in different terrains or weather conditions than they were trained for. We tackle the critical task of generalizing to out-of-distribution (OOD) settings, without access to explicit context information at test time. Recent work has addressed this problem by training a context encoder and a history adaptation module in separate stages. While promising, this two-phase approach is cumbersome to implement and train. We simplify the methodology and introduce SPARC: single-phase adaptation for robust control. We test SPARC on varying contexts within the high-fidelity racing simulator Gran Turismo 7 and wind-perturbed MuJoCo environments, and find that it achieves reliable and robust OOD generalization.

</details>


### [333] [On the Convergence of Overparameterized Problems: Inherent Properties of the Compositional Structure of Neural Networks](https://arxiv.org/abs/2511.09810)
*Arthur Castello Branco de Oliveira,Dhruv Jatkar,Eduardo Sontag*

Main category: cs.LG

TL;DR: 该论文研究了神经网络的组成结构如何影响其优化景观和训练动态，特别是分析了具有线性激活函数的过参数化优化的梯度流。


<details>
  <summary>Details</summary>
Motivation: 研究神经网络的组成结构如何影响优化景观和训练动态。

Method: 分析了过参数化优化问题的梯度流，并将其解释为具有线性激活函数的神经网络训练。对标量值成本函数进行了专门分析，并研究了 saddle points 的位置和稳定性。引入了一个不平衡度量来衡量收敛速度。

Result: 证明了对于任何合适的、实解析的成本函数，都可以导出全局收敛性质。证明了 saddle points 的位置和稳定性是通用的，仅取决于过参数化表示。展示了收敛速度可以通过初始化和不平衡度量来加速。

Conclusion: 神经网络的组成结构对优化景观和训练动态有显著影响，并且通过分析线性激活函数的情况，可以获得关于 saddle points 和收敛速度的通用见解，这些见解可能推广到具有 sigmoidal 激活函数的神经网络。

Abstract: This paper investigates how the compositional structure of neural networks shapes their optimization landscape and training dynamics. We analyze the gradient flow associated with overparameterized optimization problems, which can be interpreted as training a neural network with linear activations. Remarkably, we show that the global convergence properties can be derived for any cost function that is proper and real analytic. We then specialize the analysis to scalar-valued cost functions, where the geometry of the landscape can be fully characterized. In this setting, we demonstrate that key structural features -- such as the location and stability of saddle points -- are universal across all admissible costs, depending solely on the overparameterized representation rather than on problem-specific details. Moreover, we show that convergence can be arbitrarily accelerated depending on the initialization, as measured by an imbalance metric introduced in this work. Finally, we discuss how these insights may generalize to neural networks with sigmoidal activations, showing through a simple example which geometric and dynamical properties persist beyond the linear case.

</details>


### [334] [History Rhymes: Macro-Contextual Retrieval for Robust Financial Forecasting](https://arxiv.org/abs/2511.09754)
*Sarthak Khanna,Armin Berger,Muskaan Chopra,Rafet Sifa*

Main category: cs.LG

TL;DR: 该研究提出了一种名为“宏观情境检索”的框架，通过将宏观经济指标和金融新闻情绪相结合，并检索历史相似的宏观经济时期，来提高金融市场预测模型在分布外（OOD）情况下的鲁棒性和可解释性。


<details>
  <summary>Details</summary>
Motivation: 金融市场固有的非平稳性（结构性断裂、宏观经济模式转变）导致传统预测模型在分布外（OOD）时失效。现有的多模态方法（结合数值指标和文本情感）难以适应这种转变。

Method: 提出了一种宏观情境检索（macro-contextual retrieval）的框架，这是一个检索增强的预测框架。该方法将宏观经济指标（如CPI、失业率、收益率利差、GDP增长）和金融新闻情感共同嵌入到一个共享的相似性空间中，从而在推理时能够通过因果检索（causal retrieval）来查找先前的相似时期，而无需重新训练。

Result: 在2007-2023年的标准普尔500指数数据上训练，并在2024年的AAPL和XOM数据上进行了OOD评估。该框架一致地缩小了与OOD性能的差距。宏观条件检索实现了唯一正的样本外交易结果（AAPL：PF=1.18，Sharpe=0.95；XOM：PF=1.16，Sharpe=0.61）。相比之下，静态数值、仅文本和朴素多模态基线在模式转变下表现失效。检索到的邻居形成了可解释的证据链，对应于可识别的宏观背景（如通胀或收益率曲线倒置阶段），支持因果可解释性和透明度。

Conclusion: 宏观意识检索（macro-aware retrieval）在分布变化下可以产生稳健且可解释的预测，证明了“金融历史不重复，但经常押韵”的原则。

Abstract: Financial markets are inherently non-stationary: structural breaks and macroeconomic regime shifts often cause forecasting models to fail when deployed out of distribution (OOD). Conventional multimodal approaches that simply fuse numerical indicators and textual sentiment rarely adapt to such shifts. We introduce macro-contextual retrieval, a retrieval-augmented forecasting framework that grounds each prediction in historically analogous macroeconomic regimes. The method jointly embeds macro indicators (e.g., CPI, unemployment, yield spread, GDP growth) and financial news sentiment in a shared similarity space, enabling causal retrieval of precedent periods during inference without retraining.
  Trained on seventeen years of S&P 500 data (2007-2023) and evaluated OOD on AAPL (2024) and XOM (2024), the framework consistently narrows the CV to OOD performance gap. Macro-conditioned retrieval achieves the only positive out-of-sample trading outcomes (AAPL: PF=1.18, Sharpe=0.95; XOM: PF=1.16, Sharpe=0.61), while static numeric, text-only, and naive multimodal baselines collapse under regime shifts. Beyond metric gains, retrieved neighbors form interpretable evidence chains that correspond to recognizable macro contexts, such as inflationary or yield-curve inversion phases, supporting causal interpretability and transparency. By operationalizing the principle that "financial history may not repeat, but it often rhymes," this work demonstrates that macro-aware retrieval yields robust, explainable forecasts under distributional change.
  All datasets, models, and source code are publicly available.

</details>


### [335] [Harnessing Bounded-Support Evolution Strategies for Policy Refinement](https://arxiv.org/abs/2511.09923)
*Ethan Hirschowitz,Fabio Ramos*

Main category: cs.LG

TL;DR: TD-ES是一种基于进化策略（ES）的算法，通过引入有界三角噪声和中心秩有限差分估计器，实现了稳定、可并行、无梯度的策略更新，能够有效提升机器人策略的性能。


<details>
  <summary>Details</summary>
Motivation: 在机器人策略改进中，基于策略的强化学习（RL）方法常因梯度噪声大、信号弱而受阻。因此，需要一种稳定且高效的策略优化方法。

Method: 提出了一种名为三角分布进化策略（TD-ES）的方法，该方法将有界三角噪声与中心秩有限差分估计器相结合，实现了梯度无关的策略更新。TD-ES被设计为一种策略梯度代理，用于策略精炼。该方法还提出了一个两阶段流程：首先使用PPO进行预训练，然后使用TD-ES进行精炼。

Result: 在机器人操作任务中，TD-ES相比PPO将成功率提高了26.5%，并显著降低了策略的方差。这表明TD-ES是一种简单、计算成本低且可靠的策略改进方法。

Conclusion: TD-ES通过结合PPO预训练和TD-ES精炼的两阶段方法，能够有效地提升机器人策略的性能，特别是在策略改进的后期阶段，同时保持了早期样本效率。该方法在机器人操作任务中表现出优越的性能和稳定性。

Abstract: Improving competent robot policies with on-policy RL is often hampered by noisy, low-signal gradients. We revisit Evolution Strategies (ES) as a policy-gradient proxy and localize exploration with bounded, antithetic triangular perturbations, suitable for policy refinement. We propose Triangular-Distribution ES (TD-ES) which pairs bounded triangular noise with a centered-rank finite-difference estimator to deliver stable, parallelizable, gradient-free updates. In a two-stage pipeline -- PPO pretraining followed by TD-ES refinement -- this preserves early sample efficiency while enabling robust late-stage gains. Across a suite of robotic manipulation tasks, TD-ES raises success rates by 26.5% relative to PPO and greatly reduces variance, offering a simple, compute-light path to reliable refinement.

</details>


### [336] [Gradient Flow Equations for Deep Linear Neural Networks: A Survey from a Network Perspective](https://arxiv.org/abs/2511.10362)
*Joel Wendin,Claudio Altafini*

Main category: cs.LG

TL;DR: 该论文研究了深度线性神经网络的梯度流方程的动力学和损失函数景观。


<details>
  <summary>Details</summary>
Motivation: 理解深度线性神经网络在训练过程中的动力学行为和损失函数景观的特性。

Method: 将梯度流方程表示为收敛矩阵常微分方程，并分析其性质（幂零、多项式、等谱、守恒律）。详细描述了损失函数景观，包括其全局最小值、鞍点和缺乏局部最小值/最大值。

Result: 损失函数是梯度流的Lyapunov函数，其水平集是临界点的无界不变集。通过邻接矩阵表示，揭示了商空间结构，使得每个临界值只表示一次，并能轻松确定鞍点的稳定和不稳定子流形。

Conclusion: 邻接矩阵表示法为理解深度线性神经网络的梯度流动力学和损失函数景观提供了有力的工具，尤其是在分析临界点和鞍点方面。

Abstract: The paper surveys recent progresses in understanding the dynamics and loss landscape of the gradient flow equations associated to deep linear neural networks, i.e., the gradient descent training dynamics (in the limit when the step size goes to 0) of deep neural networks missing the activation functions and subject to quadratic loss functions. When formulated in terms of the adjacency matrix of the neural network, as we do in the paper, these gradient flow equations form a class of converging matrix ODEs which is nilpotent, polynomial, isospectral, and with conservation laws. The loss landscape is described in detail. It is characterized by infinitely many global minima and saddle points, both strict and nonstrict, but lacks local minima and maxima. The loss function itself is a positive semidefinite Lyapunov function for the gradient flow, and its level sets are unbounded invariant sets of critical points, with critical values that correspond to the amount of singular values of the input-output data learnt by the gradient along a certain trajectory. The adjacency matrix representation we use in the paper allows to highlight the existence of a quotient space structure in which each critical value of the loss function is represented only once, while all other critical points with the same critical value belong to the fiber associated to the quotient space. It also allows to easily determine stable and unstable submanifolds at the saddle points, even when the Hessian fails to obtain them.

</details>


### [337] [Belief Net: A Filter-Based Framework for Learning Hidden Markov Models from Observations](https://arxiv.org/abs/2511.10571)
*Reginald Zhiyan Chen,Heng-Sheng Chang,Prashant G. Mehta*

Main category: cs.LG

TL;DR: Belief Net是一种新颖的框架，通过将HMM的前向滤波过程构建为结构化神经网络，并利用梯度下降进行优化，来学习HMM参数，解决了传统方法的局限性。


<details>
  <summary>Details</summary>
Motivation: 传统HMM参数学习方法（如Baum-Welch）计算成本高且易陷入局部最优，而谱方法虽然有理论保证，但可能产生无效的概率输出。现有工作需要一种更有效、可解释且鲁棒的HMM参数学习方法。

Method: 将HMM的前向滤波过程建模为一个可解释的神经网络，其可学习的权重直接对应HMM的初始分布、转移矩阵和发射矩阵的logit。该模型采用仅解码器的架构处理观测序列，并使用标准的自回归下一观测预测损失进行端到端的训练。

Result: 在合成HMM数据上，Belief Net的收敛速度优于Baum-Welch算法，并在谱方法失败的欠完备和过完备设置下成功恢复了参数。在真实语言数据上，与基于Transformer的模型进行了比较。

Conclusion: Belief Net通过其基于梯度优化的神经网络框架，为HMM参数学习提供了一种新颖、高效且可解释的解决方案，在合成和真实世界数据上都表现出优越的性能。

Abstract: Hidden Markov Models (HMMs) are fundamental for modeling sequential data, yet learning their parameters from observations remains challenging. Classical methods like the Baum-Welch (EM) algorithm are computationally intensive and prone to local optima, while modern spectral algorithms offer provable guarantees but may produce probability outputs outside valid ranges. This work introduces Belief Net, a novel framework that learns HMM parameters through gradient-based optimization by formulating the HMM's forward filter as a structured neural network. Unlike black-box Transformer models, Belief Net's learnable weights are explicitly the logits of the initial distribution, transition matrix, and emission matrix, ensuring full interpretability. The model processes observation sequences using a decoder-only architecture and is trained end-to-end with standard autoregressive next-observation prediction loss. On synthetic HMM data, Belief Net achieves superior convergence speed compared to Baum-Welch, successfully recovering parameters in both undercomplete and overcomplete settings where spectral methods fail. Comparisons with Transformer-based models are also presented on real-world language data.

</details>


### [338] [Hail to the Thief: Exploring Attacks and Defenses in Decentralised GRPO](https://arxiv.org/abs/2511.09780)
*Nikolay Blagoev,Oğuzhan Ersoy,Lydia Yiyu Chen*

Main category: cs.LG

TL;DR: GRPO是一种用于大型语言模型（LLM）的训练后方法，它通过强化学习来学习首选的输出。本文提出了首个针对去中心化GRPO的对抗性攻击方法，该方法可以通过注入任意恶意令牌来污染良性模型，成功率高达100%。文章还提出了两种防御方法，可以阻止攻击的发生。


<details>
  <summary>Details</summary>
Motivation: 研究去中心化GRPO系统中的对抗性攻击，并提出防御措施。

Method: 提出了一种针对去中心化GRPO的对抗性攻击方法，并通过数学和编码任务进行了实验。同时，提出了两种防御方法。

Result: 实验证明，对抗性攻击可以轻易污染良性节点，导致模型训练数据被污染，在50次迭代内即可达到100%的攻击成功率。提出的防御方法可以达到100%的停止率，使攻击失效。

Conclusion: 去中心化GRPO系统容易受到对抗性攻击，但可以通过提出的防御方法来有效抵御。

Abstract: Group Relative Policy Optimization (GRPO) has demonstrated great utilization in post-training of Large Language Models (LLMs). In GRPO, prompts are answered by the model and, through reinforcement learning, preferred completions are learnt. Owing to the small communication volume, GRPO is inherently suitable for decentralised training as the prompts can be concurrently answered by multiple nodes and then exchanged in the forms of strings. In this work, we present the first adversarial attack in decentralised GRPO. We demonstrate that malicious parties can poison such systems by injecting arbitrary malicious tokens in benign models in both out-of-context and in-context attacks. Using empirical examples of math and coding tasks, we show that adversarial attacks can easily poison the benign nodes, polluting their local LLM post-training, achieving attack success rates up to 100% in as few as 50 iterations. We propose two ways to defend against these attacks, depending on whether all users train the same model or different models. We show that these defenses can achieve stop rates of up to 100%, making the attack impossible.

</details>


### [339] [Koopman Invariants as Drivers of Emergent Time-Series Clustering in Joint-Embedding Predictive Architectures](https://arxiv.org/abs/2511.09783)
*Pablo Ruiz-Morales,Dries Vanoost,Davy Pissoort,Mathias Verbeke*

Main category: cs.LG

TL;DR: JEPAs can cluster time-series data by dynamical regimes due to their predictive objective implicitly learning the Koopman operator's invariant subspace. This is achieved when the encoder learns Koopman eigenfunctions, a process facilitated by constraining the linear predictor to be near-identity, which also aids in representation disentanglement.


<details>
  <summary>Details</summary>
Motivation: Unexplained ability of Joint-Embedding Predictive Architectures (JEPAs) to cluster time-series data by dynamical regimes.

Method: Proposing a theoretical explanation: JEPA's predictive objective implicitly drives it to learn the invariant subspace of the system's Koopman operator. Proving that an idealized JEPA loss is minimized when the encoder represents Koopman eigenfunctions. Validating the theory on synthetic data, showing that constraining the JEPA's linear predictor to be a near-identity operator is crucial.

Result: The theory was validated on synthetic data. Constraining the linear predictor to be near-identity forces the encoder to learn invariants. This constraint is critical for selecting an interpretable solution from equivalent optima, highlighting the predictor's role in representation disentanglement.

Conclusion: Demystifies a key behavior of JEPAs, provides a principled connection between self-supervised learning and dynamical systems theory, and informs the design of more robust and interpretable time-series models.

Abstract: Joint-Embedding Predictive Architectures (JEPAs), a powerful class of self-supervised models, exhibit an unexplained ability to cluster time-series data by their underlying dynamical regimes. We propose a novel theoretical explanation for this phenomenon, hypothesizing that JEPA's predictive objective implicitly drives it to learn the invariant subspace of the system's Koopman operator. We prove that an idealized JEPA loss is minimized when the encoder represents the system's regime indicator functions, which are Koopman eigenfunctions. This theory was validated on synthetic data with known dynamics, demonstrating that constraining the JEPA's linear predictor to be a near-identity operator is the key inductive bias that forces the encoder to learn these invariants. We further discuss that this constraint is critical for selecting this interpretable solution from a class of mathematically equivalent but entangled optima, revealing the predictor's role in representation disentanglement. This work demystifies a key behavior of JEPAs, provides a principled connection between modern self-supervised learning and dynamical systems theory, and informs the design of more robust and interpretable time-series models.

</details>


### [340] [CaReTS: A Multi-Task Framework Unifying Classification and Regression for Time Series Forecasting](https://arxiv.org/abs/2511.09789)
*Fulong Yao,Wanqing Zhao,Chao Zheng,Xiaofei Han*

Main category: cs.LG

TL;DR: CaReTS是一个新的多任务学习框架，结合了分类和回归任务，用于多步时间序列预测。它通过区分宏观趋势和微观偏差来提供更具可解释性的预测，并在真实数据集上取得了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 大多数深度预测模型难以同时提供准确的预测和对时间动态的可解释性见解。

Method: CaReTS采用双流架构，其中分类分支学习未来的逐步趋势，回归分支估计与目标变量的最新观测值的偏差。设计了一个多任务损失，具有不确定性感知加权，以自适应地平衡每个任务的贡献。四个变体（CaReTS1-4）被实例化，以结合主流的时间建模编码器（CNN、LSTM、Transformer）。

Result: CaReTS在预测准确性方面优于最先进的算法，同时在趋势分类方面也取得了更高的性能。

Conclusion: CaReTS框架在多步时间序列预测中，在准确性和可解释性方面都优于现有方法。

Abstract: Recent advances in deep forecasting models have achieved remarkable performance, yet most approaches still struggle to provide both accurate predictions and interpretable insights into temporal dynamics. This paper proposes CaReTS, a novel multi-task learning framework that combines classification and regression tasks for multi-step time series forecasting problems. The framework adopts a dual-stream architecture, where a classification branch learns the stepwise trend into the future, while a regression branch estimates the corresponding deviations from the latest observation of the target variable. The dual-stream design provides more interpretable predictions by disentangling macro-level trends from micro-level deviations in the target variable. To enable effective learning in output prediction, deviation estimation, and trend classification, we design a multi-task loss with uncertainty-aware weighting to adaptively balance the contribution of each task. Furthermore, four variants (CaReTS1--4) are instantiated under this framework to incorporate mainstream temporal modelling encoders, including convolutional neural networks (CNNs), long short-term memory networks (LSTMs), and Transformers. Experiments on real-world datasets demonstrate that CaReTS outperforms state-of-the-art (SOTA) algorithms in forecasting accuracy, while achieving higher trend classification performance.

</details>


### [341] [Constrained Best Arm Identification with Tests for Feasibility](https://arxiv.org/abs/2511.09808)
*Ting Cai,Kirthevasan Kandasamy*

Main category: cs.LG

TL;DR: 本研究提出了一种新的最优臂识别（BAI）算法，用于在满足额外可行性约束的条件下，找到性能最佳且可行的臂。


<details>
  <summary>Details</summary>
Motivation: 现有 BAI 方法通常假设性能和可行性可同时观察，不适用于药物发现等实际场景，其中性能和可行性测试可分开进行。因此，需要设计能同时决定拉动哪个臂以及测试其性能或可行性的 BAI 算法。

Method: 研究固定置信度设置下的可行性 BAI 问题，目标是以至少 1-δ 的概率找到性能最佳的可行臂。提出了一种高效算法，并给出了其样本复杂度上限，证明了该算法能适应问题难度，并根据性能或可行性进行最优的臂剔除。

Result: 算法的样本复杂度上限表明其能自适应问题难度。此外，通过与下界进行比较，证明了该算法在 δ→0 时具有渐近最优性。在合成和真实数据集上的实证结果表明，该算法优于现有的 BAI 算法。

Conclusion: 所提出的可行性 BAI 算法在固定置信度设置下是高效且渐近最优的，并且在实践中表现优于现有方法。

Abstract: Best arm identification (BAI) aims to identify the highest-performance arm among a set of $K$ arms by collecting stochastic samples from each arm. In real-world problems, the best arm needs to satisfy additional feasibility constraints. While there is limited prior work on BAI with feasibility constraints, they typically assume the performance and constraints are observed simultaneously on each pull of an arm. However, this assumption does not reflect most practical use cases, e.g., in drug discovery, we wish to find the most potent drug whose toxicity and solubility are below certain safety thresholds. These safety experiments can be conducted separately from the potency measurement. Thus, this requires designing BAI algorithms that not only decide which arm to pull but also decide whether to test for the arm's performance or feasibility. In this work, we study feasible BAI which allows a decision-maker to choose a tuple $(i,\ell)$, where $i\in [K]$ denotes an arm and $\ell$ denotes whether she wishes to test for its performance ($\ell=0$) or any of its $N$ feasibility constraints ($\ell\in[N]$). We focus on the fixed confidence setting, which is to identify the \textit{feasible} arm with the \textit{highest performance}, with a probability of at least $1-δ$. We propose an efficient algorithm and upper-bound its sample complexity, showing our algorithm can naturally adapt to the problem's difficulty and eliminate arms by worse performance or infeasibility, whichever is easier. We complement this upper bound with a lower bound showing that our algorithm is \textit{asymptotically ($δ\rightarrow 0$) optimal}. Finally, we empirically show that our algorithm outperforms other state-of-the-art BAI algorithms in both synthetic and real-world datasets.

</details>


### [342] [ACT as Human: Multimodal Large Language Model Data Annotation with Critical Thinking](https://arxiv.org/abs/2511.09833)
*Lequan Lin,Dai Shi,Andi Han,Feng Chen,Qiuzheng Chen,Jiawen Li,Zhaoyang Li,Jiyuan Li,Zhenbang Sun,Junbin Gao*

Main category: cs.LG

TL;DR: LLM标注仍未达到人类水平，我们提出了ACT数据管线，通过让LLM同时担任标注员和评判者，并优化标注流程，显著提高了标注效率并减少了人工成本，在保证模型性能的同时节省高达90%的人工成本。


<details>
  <summary>Details</summary>
Motivation: 监督学习需要高质量的标注数据，但人工标注成本高昂且耗时。现有LLM标注生成的标签质量仍低于人类水平。

Method: 提出ACT（Annotation with Critical Thinking）数据管线，让LLM同时扮演标注员和评判者的角色，识别潜在错误，并将人工审核重点引导至“可疑”案例，从而提高标注效率。ACT可应用于NLP、CV和多模态理解等领域，并利用多模态LLM。通过实验得出7条提升标注质量和降低成本的见解，并转化为用户指南。对损失函数进行理论分析，使在ACT数据上训练的模型性能接近完全人工标注的数据。

Result: 在大多数基准数据集上，性能差距可缩小至2%以内，同时节省高达90%的人工成本。

Conclusion: ACT数据管线通过引入LLM的批判性思维，有效解决了LLM标注质量不足和人工标注成本高的问题，实现了高效、低成本且高质量的数据标注。

Abstract: Supervised learning relies on high-quality labeled data, but obtaining such data through human annotation is both expensive and time-consuming. Recent work explores using large language models (LLMs) for annotation, but LLM-generated labels still fall short of human-level quality. To address this problem, we propose the Annotation with Critical Thinking (ACT) data pipeline, where LLMs serve not only as annotators but also as judges to critically identify potential errors. Human effort is then directed towards reviewing only the most "suspicious" cases, significantly improving the human annotation efficiency. Our major contributions are as follows: (1) ACT is applicable to a wide range of domains, including natural language processing (NLP), computer vision (CV), and multimodal understanding, by leveraging multimodal-LLMs (MLLMs). (2) Through empirical studies, we derive 7 insights on how to enhance annotation quality while efficiently reducing the human cost, and then translate these findings into user-friendly guidelines. (3) We theoretically analyze how to modify the loss function so that models trained on ACT data achieve similar performance to those trained on fully human-annotated data. Our experiments show that the performance gap can be reduced to less than 2% on most benchmark datasets while saving up to 90% of human costs.

</details>


### [343] [Steering Pretrained Drafters during Speculative Decoding](https://arxiv.org/abs/2511.09844)
*Frédéric Berdoz,Peer Rheinboldt,Roger Wattenhofer*

Main category: cs.LG

TL;DR: Speculative decoding通过引入一个轻量级的动态对齐机制来提高预训练草稿器的令牌接受率，该机制将来自验证器的隐藏状态的引导向量注入到草稿器中，从而在不增加显着计算开销的情况下提高了性能。


<details>
  <summary>Details</summary>
Motivation: Speculative decoding的一个主要限制是草稿器-验证器不对齐，这会限制令牌接受率并降低整体效率。虽然可以快速训练小型草稿头，但它们在验证器延迟占主导地位或输入偏离分布时表现不佳。预训练的草稿器虽然速度较慢，但由于其更强的独立生成能力，可以实现更高的接受率，这使得它们在草稿延迟可忽略的情况下具有竞争力。

Method: 引入一种轻量级的动态对齐机制：一个从验证器的隐藏状态计算出的引导向量，并将其注入到预训练的草稿器中。

Result: 与现有的离线对齐方法（如蒸馏）相比，该方法在标准采样下将接受的令牌数量提高了高达 35%，在贪婪采样下提高了 22%，同时产生的计算开销可忽略不计。

Conclusion: 所提出的动态对齐方法可以改进预训练草稿器，从而提高令牌接受率，并且易于集成到现有架构和预训练模型中。

Abstract: Speculative decoding accelerates language model inference by separating generation into fast drafting and parallel verification. Its main limitation is drafter-verifier misalignment, which limits token acceptance and reduces overall effectiveness. While small drafting heads trained from scratch compensate with speed, they struggle when verification dominates latency or when inputs are out of distribution. In contrast, pretrained drafters, though slower, achieve higher acceptance rates thanks to stronger standalone generation capabilities, making them competitive when drafting latency is negligible relative to verification or communication overhead. In this work, we aim to improve the acceptance rates of pretrained drafters by introducing a lightweight dynamic alignment mechanism: a steering vector computed from the verifier's hidden states and injected into the pretrained drafter. Compared to existing offline alignment methods such as distillation, our approach boosts the number of accepted tokens by up to 35\% under standard sampling and 22\% under greedy sampling, all while incurring negligible computational overhead. Importantly, our approach can be retrofitted to existing architectures and pretrained models, enabling rapid adoption.

</details>


### [344] [ConSurv: Multimodal Continual Learning for Survival Analysis](https://arxiv.org/abs/2511.09853)
*Dianzhi Yu,Conghao Xiong,Yankai Chen,Wenqian Cui,Xinni Zhang,Yifei Zhang,Hao Chen,Joseph J. Y. Sung,Irwin King*

Main category: cs.LG

TL;DR: ConSurv是一种新颖的多模态持续学习方法，用于处理癌症生存预测中的灾难性遗忘和跨模态交互问题，并在新基准MSAIL上取得了优于现有方法的性能。


<details>
  <summary>Details</summary>
Motivation: 传统的癌症生存预测模型是静态的，无法适应动态变化的临床环境和持续的数据流。现有的持续学习方法主要处理单一模态数据，在生存预测任务中存在严重的灾难性遗忘问题。然而，在实际应用中，多模态数据（如全视野图像和基因组学数据）能提供更全面的信息，忽略模态间的相互作用会影响模型性能。

Method: 本文提出了ConSurv，一种多模态持续学习（MMCL）方法，用于解决生存分析中的灾难性遗忘和跨模态交互问题。ConSurv包含两个关键组件：多阶段专家混合（MS-MoE）和特征约束重放（FCR）。MS-MoE在网络的多个学习阶段（包括两个模态编码器和模态融合组件）捕捉任务共享和任务特定的知识，从而学习模态间的关系。FCR通过限制不同层级的先前数据特征偏差（包括两个模态的编码器层级特征和融合层级表示）来增强所学知识并减轻遗忘。此外，研究人员还引入了一个包含四个数据集的新基准Multimodal Survival Analysis Incremental Learning (MSAIL)，用于在持续学习设置下进行全面评估。

Result: 通过在MSAIL基准上的广泛实验，ConSurv在多个评估指标上均优于现有方法。

Conclusion: ConSurv是首个用于生存分析的多模态持续学习方法，有效解决了灾难性遗忘和跨模态交互的挑战，并在癌症生存预测任务中展现出优越的性能。

Abstract: Survival prediction of cancers is crucial for clinical practice, as it informs mortality risks and influences treatment plans. However, a static model trained on a single dataset fails to adapt to the dynamically evolving clinical environment and continuous data streams, limiting its practical utility. While continual learning (CL) offers a solution to learn dynamically from new datasets, existing CL methods primarily focus on unimodal inputs and suffer from severe catastrophic forgetting in survival prediction. In real-world scenarios, multimodal inputs often provide comprehensive and complementary information, such as whole slide images and genomics; and neglecting inter-modal correlations negatively impacts the performance. To address the two challenges of catastrophic forgetting and complex inter-modal interactions between gigapixel whole slide images and genomics, we propose ConSurv, the first multimodal continual learning (MMCL) method for survival analysis. ConSurv incorporates two key components: Multi-staged Mixture of Experts (MS-MoE) and Feature Constrained Replay (FCR). MS-MoE captures both task-shared and task-specific knowledge at different learning stages of the network, including two modality encoders and the modality fusion component, learning inter-modal relationships. FCR further enhances learned knowledge and mitigates forgetting by restricting feature deviation of previous data at different levels, including encoder-level features of two modalities and the fusion-level representations. Additionally, we introduce a new benchmark integrating four datasets, Multimodal Survival Analysis Incremental Learning (MSAIL), for comprehensive evaluation in the CL setting. Extensive experiments demonstrate that ConSurv outperforms competing methods across multiple metrics.

</details>


### [345] [Unlearning Imperative: Securing Trustworthy and Responsible LLMs through Engineered Forgetting](https://arxiv.org/abs/2511.09855)
*James Jin Kang,Dang Bui,Thanh Pham,Huo-Chong Ling*

Main category: cs.LG

TL;DR: LLM 缺乏永久删除私密信息的能力，现有方法成本高、效果差且难以验证。本文综述了 LLM 机器学习遗忘的最新研究，探讨了现有方法在评估遗忘、防御对抗性攻击以及支持用户信任方面的进展，并考察了差分隐私、同态加密、联邦学习、短暂记忆等技术以及审计和监管等组织保障。研究表明，尽管取得了进展，但可靠且可验证的遗忘仍未解决，需要更高效、更安全且有监管的解决方案。


<details>
  <summary>Details</summary>
Motivation: 现有的大型语言模型（LLM）在敏感领域应用时，无法保证永久删除私密信息，这暴露了其关键的弱点。然而，这些系统仍然缺乏可靠的机制来保证一旦使用了敏感信息，就能将其永久移除。从头开始重新训练的成本过高，而现有的遗忘方法零散、难以验证，并且容易受到恢复的攻击。

Method: 本文综述了用于 LLM 的机器学习遗忘的最新研究，并考虑了现有方法在多大程度上可以解决这些挑战。我们回顾了评估遗忘是否发生、遗忘模型对对抗性攻击的韧性以及在模型复杂性或专有限制限制透明度时支持用户信任的机制。同时，还考察了差分隐私、同态加密、联邦学习和短暂记忆等技术解决方案，以及审计实践和监管框架等机构保障。

Result: 研究发现，在 LLM 遗忘方面取得了稳步进展，但鲁棒且可验证的遗忘仍未解决。高效避免高成本重新训练的技术、更强的防御对抗性恢复的措施以及加强问责制的治理结构是 LLM 在敏感应用中安全部署的必要条件。

Conclusion: 通过整合技术和组织视角，本研究为构建能够被要求遗忘，同时又能维护隐私和公众信任的 AI 系统指明了方向。

Abstract: The growing use of large language models in sensitive domains has exposed a critical weakness: the inability to ensure that private information can be permanently forgotten. Yet these systems still lack reliable mechanisms to guarantee that sensitive information can be permanently removed once it has been used. Retraining from the beginning is prohibitively costly, and existing unlearning methods remain fragmented, difficult to verify, and often vulnerable to recovery. This paper surveys recent research on machine unlearning for LLMs and considers how far current approaches can address these challenges. We review methods for evaluating whether forgetting has occurred, the resilience of unlearned models against adversarial attacks, and mechanisms that can support user trust when model complexity or proprietary limits restrict transparency. Technical solutions such as differential privacy, homomorphic encryption, federated learning, and ephemeral memory are examined alongside institutional safeguards including auditing practices and regulatory frameworks. The review finds steady progress, but robust and verifiable unlearning is still unresolved. Efficient techniques that avoid costly retraining, stronger defenses against adversarial recovery, and governance structures that reinforce accountability are needed if LLMs are to be deployed safely in sensitive applications. By integrating technical and organizational perspectives, this study outlines a pathway toward AI systems that can be required to forget, while maintaining both privacy and public trust.

</details>


### [346] [Uncertainty-Guided Checkpoint Selection for Reinforcement Finetuning of Large Language Models](https://arxiv.org/abs/2511.09864)
*Manh Nguyen,Dung Nguyen,Dai Do,Svetha Venkatesh,Hung Le*

Main category: cs.LG

TL;DR: RL微调LLM时，我们提出了一种不确定性引导的检查点选择（UGCS）方法，通过识别模型不确定的样本并对其进行优化，来稳定地选择出泛化能力更强的检查点，无需额外的计算开销。


<details>
  <summary>Details</summary>
Motivation: RL微调LLM是一个不稳定的过程，检查点选择具有高方差，并且在验证集上评估检查点计算成本高且需要好的验证集，而依赖最终检查点不能保证性能。因此，需要一种更稳定、更经济的检查点选择方法。

Method: UGCS方法识别模型不确定的样本，并根据模型在这些样本上的表现对检查点进行排名。通过平均处理这些高不确定性样本的奖励，UGCS提供了一个稳定且有区分度的信号，无需额外的计算。

Result: 在三个数据集和三个LLM上进行的实验表明，UGCS持续识别出具有更强泛化能力的检查点，优于依赖训练或验证性能的传统策略。

Conclusion: 在RL微调LLM时，选择在最困难任务上表现出低不确定性的模型是整体上最可靠的。UGCS方法提供了一种有效的方式来实现这一目标。

Abstract: Reinforcement learning (RL) finetuning is crucial to aligning large language models (LLMs), but the process is notoriously unstable and exhibits high variance across model checkpoints. In practice, selecting the best checkpoint is challenging: evaluating checkpoints on the validation set during training is computationally expensive and requires a good validation set, while relying on the final checkpoint provides no guarantee of good performance. We introduce an uncertainty-guided approach for checkpoint selection (UGCS) that avoids these pitfalls. Our method identifies hard question-answer pairs using per-sample uncertainty and ranks checkpoints by how well they handle these challenging cases. By averaging the rewards of the top-uncertain samples over a short training window, our method produces a stable and discriminative signal without additional forward passes or significant computation overhead. Experiments across three datasets and three LLMs demonstrate that it consistently identifies checkpoints with stronger generalization, outperforming traditional strategies such as relying on training or validation performance. These results highlight that models solving their hardest tasks with low uncertainty are the most reliable overall.

</details>


### [347] [Expandable and Differentiable Dual Memories with Orthogonal Regularization for Exemplar-free Continual Learning](https://arxiv.org/abs/2511.09871)
*Hyung-Jun Moon,Sung-Bae Cho*

Main category: cs.LG

TL;DR: 提出了一种完全可微分、无需样本的持续学习方法，通过两个互补的记忆模块来学习通用特征和区分性特征，并采用自适应内存调整和正交正则化来防止干扰。


<details>
  <summary>Details</summary>
Motivation: 现有的持续学习方法孤立地处理任务，阻碍了任务间的知识利用，并导致重复学习或过度区分特征。

Method: 提出了一种包含两个互补记忆模块的方法：一个学习跨任务的通用特征，另一个结合共享特征学习特定于样本的区分性特征。该方法是完全可微分的，并且不需要样本。通过自适应内存调整模块来剪枝和扩展内存，并通过正交正则化来分离新旧知识，防止干扰。

Result: 在CIFAR-10、CIFAR-100和Tiny-ImageNet数据集上，该方法在类别增量学习方面优于14种最先进的方法，最终准确率分别为55.13%、37.24%和30.11%。

Conclusion: 该方法通过有效整合和利用知识，提高了跨序列任务的平均性能，其特征提取结果最接近理论上限，为持续学习设定了新的里程碑。

Abstract: Continual learning methods used to force neural networks to process sequential tasks in isolation, preventing them from leveraging useful inter-task relationships and causing them to repeatedly relearn similar features or overly differentiate them. To address this problem, we propose a fully differentiable, exemplar-free expandable method composed of two complementary memories: One learns common features that can be used across all tasks, and the other combines the shared features to learn discriminative characteristics unique to each sample. Both memories are differentiable so that the network can autonomously learn latent representations for each sample. For each task, the memory adjustment module adaptively prunes critical slots and minimally expands capacity to accommodate new concepts, and orthogonal regularization enforces geometric separation between preserved and newly learned memory components to prevent interference. Experiments on CIFAR-10, CIFAR-100, and Tiny-ImageNet show that the proposed method outperforms 14 state-of-the-art methods for class-incremental learning, achieving final accuracies of 55.13\%, 37.24\%, and 30.11\%, respectively. Additional analysis confirms that, through effective integration and utilization of knowledge, the proposed method can increase average performance across sequential tasks, and it produces feature extraction results closest to the upper bound, thus establishing a new milestone in continual learning.

</details>


### [348] [A General Anchor-Based Framework for Scalable Fair Clustering](https://arxiv.org/abs/2511.09889)
*Shengfei Wei,Suyuan Liu,Jun Wang,Ke Liang,Miaomiao Li,Lei Luo*

Main category: cs.LG

TL;DR: 提出了一种名为锚点公平聚类框架（AFCF）的新型框架，可以使任意公平聚类算法具有线性时间复杂度，从而解决现有算法在大规模数据集上的计算效率问题。该框架通过一个公平采样策略选择少量锚点，然后将公平聚类算法应用于这些锚点，并通过一个锚点图构建模块来传播标签并保持公平性。实验证明，AFCF能显著提高现有方法的计算速度，同时保持良好的聚类性能和公平性。


<details>
  <summary>Details</summary>
Motivation: 现有公平聚类算法计算复杂度高，在大规模数据集上不实用。

Method: 1. 使用新颖的公平采样策略选择少量代表性锚点。 2. 将现有的公平聚类算法应用于锚点集。 3. 设计锚点图构建模块，通过分组标签联合约束来传播标签并保持公平性。 4. 使用基于ADMM的算法求解优化问题。

Result: AFCF将最先进方法的计算时间减少了几个数量级，同时保持了强大的聚类性能和公平性保证。

Conclusion: AFCF是一种新颖、通用且即插即用的框架，能够将任意公平聚类算法扩展到线性时间复杂度，有效解决了大规模数据集上的计算效率问题，并能保持公平性。

Abstract: Fair clustering is crucial for mitigating bias in unsupervised learning, yet existing algorithms often suffer from quadratic or super-quadratic computational complexity, rendering them impractical for large-scale datasets. To bridge this gap, we introduce the Anchor-based Fair Clustering Framework (AFCF), a novel, general, and plug-and-play framework that empowers arbitrary fair clustering algorithms with linear-time scalability. Our approach first selects a small but representative set of anchors using a novel fair sampling strategy. Then, any off-the-shelf fair clustering algorithm can be applied to this small anchor set. The core of our framework lies in a novel anchor graph construction module, where we formulate an optimization problem to propagate labels while preserving fairness. This is achieved through a carefully designed group-label joint constraint, which we prove theoretically ensures that the fairness of the final clustering on the entire dataset matches that of the anchor clustering. We solve this optimization efficiently using an ADMM-based algorithm. Extensive experiments on multiple large-scale benchmarks demonstrate that AFCF drastically accelerates state-of-the-art methods, which reduces computational time by orders of magnitude while maintaining strong clustering performance and fairness guarantees.

</details>


### [349] [Simulator and Experience Enhanced Diffusion Model for Comprehensive ECG Generation](https://arxiv.org/abs/2511.09895)
*Xiaoda Wang,Kaiqiao Han,Yuhao Xu,Xiao Luo,Yizhou Sun,Wei Wang,Carl Yang*

Main category: cs.LG

TL;DR: SE-Diff是一个结合生理模拟器和临床经验的ECG生成模型，能生成更逼真、更符合临床的ECG信号，并提升下游ECG分类任务的表现。


<details>
  <summary>Details</summary>
Motivation: 现有的ECG生成方法在整合生理学知识和临床经验方面存在不足，导致生成的ECG信号不够逼真且缺乏临床指导。

Method: SE-Diff模型通过集成基于ODE的生理模拟器和LLM驱动的经验检索增强策略，将机械生理先验和临床经验知识注入到扩散模型中，以实现更全面的ECG生成。

Result: SE-Diff在真实ECG数据集上的实验表明，与基线方法相比，它在信号保真度和文本-ECG语义对齐方面均有所提高，证明了其在文本到ECG生成方面的优越性。此外，基于模拟器和经验的知识也有助于下游ECG分类任务。

Conclusion: SE-Diff成功地将生理模拟器和临床经验知识融入ECG生成过程，显著提高了生成ECG的质量和临床相关性，并为下游任务提供了价值。

Abstract: Cardiovascular disease (CVD) is a leading cause of mortality worldwide. Electrocardiograms (ECGs) are the most widely used non-invasive tool for cardiac assessment, yet large, well-annotated ECG corpora are scarce due to cost, privacy, and workflow constraints. Generating ECGs can be beneficial for the mechanistic understanding of cardiac electrical activity, enable the construction of large, heterogeneous, and unbiased datasets, and facilitate privacy-preserving data sharing. Generating realistic ECG signals from clinical context is important yet underexplored. Recent work has leveraged diffusion models for text-to-ECG generation, but two challenges remain: (i) existing methods often overlook the physiological simulator knowledge of cardiac activity; and (ii) they ignore broader, experience-based clinical knowledge grounded in real-world practice. To address these gaps, we propose SE-Diff, a novel physiological simulator and experience enhanced diffusion model for comprehensive ECG generation. SE-Diff integrates a lightweight ordinary differential equation (ODE)-based ECG simulator into the diffusion process via a beat decoder and simulator-consistent constraints, injecting mechanistic priors that promote physiologically plausible waveforms. In parallel, we design an LLM-powered experience retrieval-augmented strategy to inject clinical knowledge, providing more guidance for ECG generation. Extensive experiments on real-world ECG datasets demonstrate that SE-Diff improves both signal fidelity and text-ECG semantic alignment over baselines, proving its superiority for text-to-ECG generation. We further show that the simulator-based and experience-based knowledge also benefit downstream ECG classification.

</details>


### [350] [Maximizing Efficiency of Dataset Compression for Machine Learning Potentials With Information Theory](https://arxiv.org/abs/2511.10561)
*Benjamin Yu,Vincenzo Lordi,Daniel Schwalbe-Koda*

Main category: cs.LG

TL;DR: 通过将原子尺度数据集压缩视为最小集合覆盖问题，我们提出了一种高效的数据集压缩算法，该算法可以识别出包含最多信息且冗余信息最少的数据子集，从而在压缩数据集的同时保留了异常值和数据集的多样性，并提高了MLIP的准确性。


<details>
  <summary>Details</summary>
Motivation: 需要一种方法来高效地压缩用于训练机器学习原子间势（MLIP）的数据集，以平衡模型准确性和计算成本，同时保留关键的原子环境信息。

Method: 将数据集压缩视为最小集合覆盖（MSC）问题，并提出了一种最大化信息效率的算法来识别最小的数据子集，该子集包含来自原始数据集的尽可能多的信息，同时去除冗余信息。

Result: 在GAP-20和TM23数据集以及ColabFit存储库中的64个多样化数据集上，MSC算法始终保留异常值，保持数据集多样性，并在高压缩率下重现力的长尾分布，优于其他子采样方法。使用MSC压缩的数据集训练的MLIP在分布外数据上表现出更低的误差，即使在数据量稀疏的情况下也是如此。

Conclusion: 我们提出的基于MSC的算法能够有效地压缩原子尺度数据集，保留关键信息，提高MLIP的性能，并为原子建模中的数据子采样、异常值检测和改进MLIP训练提供了新的解决方案。

Abstract: Machine learning interatomic potentials (MLIPs) balance high accuracy and lower costs compared to density functional theory calculations, but their performance often depends on the size and diversity of training datasets. Large datasets improve model accuracy and generalization but are computationally expensive to produce and train on, while smaller datasets risk discarding rare but important atomic environments and compromising MLIP accuracy/reliability. Here, we develop an information-theoretical framework to quantify the efficiency of dataset compression methods and propose an algorithm that maximizes this efficiency. By framing atomistic dataset compression as an instance of the minimum set cover (MSC) problem over atom-centered environments, our method identifies the smallest subset of structures that contains as much information as possible from the original dataset while pruning redundant information. The approach is extensively demonstrated on the GAP-20 and TM23 datasets, and validated on 64 varied datasets from the ColabFit repository. Across all cases, MSC consistently retains outliers, preserves dataset diversity, and reproduces the long-tail distributions of forces even at high compression rates, outperforming other subsampling methods. Furthermore, MLIPs trained on MSC-compressed datasets exhibit reduced error for out-of-distribution data even in low-data regimes. We explain these results using an outlier analysis and show that such quantitative conclusions could not be achieved with conventional dimensionality reduction methods. The algorithm is implemented in the open-source QUESTS package and can be used for several tasks in atomistic modeling, from data subsampling, outlier detection, and training improved MLIPs at a lower cost.

</details>


### [351] [Explore and Establish Synergistic Effects Between Weight Pruning and Coreset Selection in Neural Network Training](https://arxiv.org/abs/2511.09901)
*Weilin Wan,Fan Yi,Weizhong Zhang,Quan Zhou,Cheng Jin*

Main category: cs.LG

TL;DR: 本文提出了一种名为 SWaST 的联合剪枝和样本筛选机制，通过交替进行权重剪枝和样本选择来提高深度学习模型的计算效率。研究发现，冗余样本和不相关权重之间存在相互作用，这会影响各自优化过程的有效性。SWaST 通过集成状态保持机制来解决联合优化过程中可能出现的“关键双重损失”问题，即同时移除重要权重及其支持样本。实验结果表明，SWaST 在提高模型准确性的同时，显著降低了计算量。


<details>
  <summary>Details</summary>
Motivation: 深度神经网络需要大量的模型权重和训练样本，导致计算成本高昂。权重剪枝和核心集选择是提高计算效率的两种新兴方法。本文旨在探索冗余权重和训练样本之间的相互作用，并提出一种联合优化机制来利用这种相互作用。

Method: 提出了一种名为 SWaST 的联合权重和样本定制机制，通过交替进行权重剪枝和核心集选择来建立协同效应。在联合优化过程中，集成了状态保持机制来解决“关键双重损失”问题。

Result: SWaST 机制在不同剪枝率和核心集大小时表现出强大的协同作用，在显著降低计算量（10% 至 90% 的 FLOPs 削减）的同时，准确率提升高达 17.83%。

Conclusion: 权重剪枝和核心集选择之间存在协同作用，可以联合优化以提高深度学习模型的效率和准确性。SWaST 机制通过交替优化和状态保持机制，有效解决了联合优化中的挑战，并在实验中得到了验证。

Abstract: Modern deep neural networks rely heavily on massive model weights and training samples, incurring substantial computational costs. Weight pruning and coreset selection are two emerging paradigms proposed to improve computational efficiency. In this paper, we first explore the interplay between redundant weights and training samples through a transparent analysis: redundant samples, particularly noisy ones, cause model weights to become unnecessarily overtuned to fit them, complicating the identification of irrelevant weights during pruning; conversely, irrelevant weights tend to overfit noisy data, undermining coreset selection effectiveness. To further investigate and harness this interplay in deep learning, we develop a Simultaneous Weight and Sample Tailoring mechanism (SWaST) that alternately performs weight pruning and coreset selection to establish a synergistic effect in training. During this investigation, we observe that when simultaneously removing a large number of weights and samples, a phenomenon we term critical double-loss can occur, where important weights and their supportive samples are mistakenly eliminated at the same time, leading to model instability and nearly irreversible degradation that cannot be recovered in subsequent training. Unlike classic machine learning models, this issue can arise in deep learning due to the lack of theoretical guarantees on the correctness of weight pruning and coreset selection, which explains why these paradigms are often developed independently. We mitigate this by integrating a state preservation mechanism into SWaST, enabling stable joint optimization. Extensive experiments reveal a strong synergy between pruning and coreset selection across varying prune rates and coreset sizes, delivering accuracy boosts of up to 17.83% alongside 10% to 90% FLOPs reductions.

</details>


### [352] [PRISM: Diversifying Dataset Distillation by Decoupling Architectural Priors](https://arxiv.org/abs/2511.09905)
*Brian B. Moser,Shalini Strode,Federico Raue,Stanislav Frolov,Krzysztof Adamkiewicz,Arundhati Shanbhag,Joachim Folk,Tobias C. Nauen,Andreas Dengel*

Main category: cs.LG

TL;DR: PRISM是一个数据集蒸馏框架，通过结合来自不同教师模型的先验知识，生成更具多样性和泛化能力的数据集，克服了现有方法中单一教师模型带来的偏差问题。


<details>
  <summary>Details</summary>
Motivation: 现有数据集蒸馏方法倾向于继承单一教师模型的归纳偏倚，导致生成的数据过于平滑、同质化，缺乏类别内多样性，限制了泛化能力。

Method: PRISM框架将模型架构的先验知识在合成过程中进行解耦。它将逻辑匹配和正则化目标进行分离，并分别使用不同的教师模型进行监督：一个主模型用于逻辑匹配，一个随机子集用于批量归一化（BN）对齐。

Result: 在ImageNet-1K数据集上，PRISM在低中IPC（每类样本数）情况下，持续且可复现地优于单一教师方法（如SRe2L）和近期多教师方法（如G-VBSM）。生成的数据显示出更丰富的类别内多样性，特征之间的余弦相似度显著下降。

Conclusion: PRISM通过解耦逻辑匹配和正则化目标，并利用来自不同教师模型的先验知识，有效提升了数据集蒸馏的性能和生成数据的多样性，尤其在低中IPC情况下表现优于现有方法。

Abstract: Dataset distillation (DD) promises compact yet faithful synthetic data, but existing approaches often inherit the inductive bias of a single teacher model. As dataset size increases, this bias drives generation toward overly smooth, homogeneous samples, reducing intra-class diversity and limiting generalization. We present PRISM (PRIors from diverse Source Models), a framework that disentangles architectural priors during synthesis. PRISM decouples the logit-matching and regularization objectives, supervising them with different teacher architectures: a primary model for logits and a stochastic subset for batch-normalization (BN) alignment. On ImageNet-1K, PRISM consistently and reproducibly outperforms single-teacher methods (e.g., SRe2L) and recent multi-teacher variants (e.g., G-VBSM) at low- and mid-IPC regimes. The generated data also show significantly richer intra-class diversity, as reflected by a notable drop in cosine similarity between features. We further analyze teacher selection strategies (pre- vs. intra-distillation) and introduce a scalable cross-class batch formation scheme for fast parallel synthesis. Code will be released after the review period.

</details>


### [353] [Towards Multiple Missing Values-resistant Unsupervised Graph Anomaly Detection](https://arxiv.org/abs/2511.09917)
*Jiazhen Chen,Xiuqin Liang,Sichao Fu,Zheng Ma,Weihua Ou*

Main category: cs.LG

TL;DR: M$^2$V-UGAD框架旨在解决无监督图异常检测中节点属性和图结构信息缺失的问题，通过双通路编码器独立处理缺失信息，并在联合潜在空间中进行融合和正则化，最后通过生成对抗性样本来缓解输入偏差，从而提高异常检测的准确性。


<details>
  <summary>Details</summary>
Motivation: 现有的无监督图异常检测方法通常假设节点属性和图结构信息是完整的，但在实际应用中，这些信息往往因为隐私、采集错误或动态节点加入等原因不完整。现有的数据补全方法可能会将稀有异常节点误判为正常节点，引入补全偏差。当节点属性和边信息同时缺失时，一个视图中的估计错误会污染另一个视图，产生跨视图干扰，降低检测性能。

Method: 提出了一种名为M$^2$V-UGAD的多重缺失值鲁棒无监督图异常检测框架。首先，设计了一个双通路编码器，分别独立重建缺失的节点属性和图结构，以防止一个视图中的错误传播到另一个视图。然后，在联合潜在空间中融合这两个通路，并通过正则化使正常节点聚集在内部流形，异常节点则位于外层。最后，为了减轻补全偏差，从正常区域之外采样潜在代码，并将其解码为真实的节点特征和子图，生成对抗性样本以锐化决策边界。

Result: 在七个公开数据集上的实验表明，M$^2$V-UGAD在不同缺失率下始终优于现有的无监督图异常检测方法。

Conclusion: M$^2$V-UGAD框架能够有效地处理节点属性和图结构信息缺失的问题，提高无监督图异常检测的性能。

Abstract: Unsupervised graph anomaly detection (GAD) has received increasing attention in recent years, which aims to identify data anomalous patterns utilizing only unlabeled node information from graph-structured data. However, prevailing unsupervised GAD methods typically presuppose complete node attributes and structure information, a condition hardly satisfied in real-world scenarios owing to privacy, collection errors or dynamic node arrivals. Existing standard imputation schemes risk "repairing" rare anomalous nodes so that they appear normal, thereby introducing imputation bias into the detection process. In addition, when both node attributes and edges are missing simultaneously, estimation errors in one view can contaminate the other, causing cross-view interference that further undermines the detection performance. To overcome these challenges, we propose M$^2$V-UGAD, a multiple missing values-resistant unsupervised GAD framework on incomplete graphs. Specifically, a dual-pathway encoder is first proposed to independently reconstruct missing node attributes and graph structure, thereby preventing errors in one view from propagating to the other. The two pathways are then fused and regularized in a joint latent space so that normals occupy a compact inner manifold while anomalies reside on an outer shell. Lastly, to mitigate imputation bias, we sample latent codes just outside the normal region and decode them into realistic node features and subgraphs, providing hard negative examples that sharpen the decision boundary. Experiments on seven public benchmarks demonstrate that M$^2$V-UGAD consistently outperforms existing unsupervised GAD methods across varying missing rates.

</details>


### [354] [MDMLP-EIA: Multi-domain Dynamic MLPs with Energy Invariant Attention for Time Series Forecasting](https://arxiv.org/abs/2511.09924)
*Hu Zhang,Zhien Dai,Zhaohui Tang,Yongfang Xie*

Main category: cs.LG

TL;DR: MDMLP-EIA通过引入自适应双域季节性MLP、能量不变注意力机制和动态容量调整机制，解决了现有MLP在时间序列预测中的局限性，并在多个基准数据集上实现了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 现有基于MLP的时间序列预测方法存在弱季节性信号丢失、权重共享MLP容量受限以及通道独立策略中通道融合不足等问题。

Method: 提出MDMLP-EIA，包括：1. 自适应融合双域季节性MLP，区分强弱季节性信号，并采用自适应零初始化通道融合策略。2. 能量不变注意力机制，自适应关注趋势和季节性预测中的不同特征通道，并保持总信号能量恒定。3. 动态容量调整机制，使通道独立MLP的神经元数量与通道数量的平方根成比例增长。

Result: MDMLP-EIA在九个基准数据集上的广泛实验证明，其在预测准确性和计算效率方面均达到了最先进的水平。

Conclusion: MDMLP-EIA通过创新的三个关键技术，有效克服了现有MLP方法的不足，并在时间序列预测任务中取得了优越的性能。

Abstract: Time series forecasting is essential across diverse domains. While MLP-based methods have gained attention for achieving Transformer-comparable performance with fewer parameters and better robustness, they face critical limitations including loss of weak seasonal signals, capacity constraints in weight-sharing MLPs, and insufficient channel fusion in channel-independent strategies. To address these challenges, we propose MDMLP-EIA (Multi-domain Dynamic MLPs with Energy Invariant Attention) with three key innovations. First, we develop an adaptive fused dual-domain seasonal MLP that categorizes seasonal signals into strong and weak components. It employs an adaptive zero-initialized channel fusion strategy to minimize noise interference while effectively integrating predictions. Second, we introduce an energy invariant attention mechanism that adaptively focuses on different feature channels within trend and seasonal predictions across time steps. This mechanism maintains constant total signal energy to align with the decomposition-prediction-reconstruction framework and enhance robustness against disturbances. Third, we propose a dynamic capacity adjustment mechanism for channel-independent MLPs. This mechanism scales neuron count with the square root of channel count, ensuring sufficient capacity as channels increase. Extensive experiments across nine benchmark datasets demonstrate that MDMLP-EIA achieves state-of-the-art performance in both prediction accuracy and computational efficiency.

</details>


### [355] [EEGAgent: A Unified Framework for Automated EEG Analysis Using Large Language Models](https://arxiv.org/abs/2511.09947)
*Sha Zhao,Mingyi Peng,Haiteng Jiang,Tao Li,Shijian Li,Gang Pan*

Main category: cs.LG

TL;DR: EEGAgent是一个利用大型语言模型（LLM）来调度和规划多个工具，以自动完成脑电图（EEG）相关任务的通用框架，能够进行EEG信息感知、时空探索、事件检测、用户交互和报告生成。


<details>
  <summary>Details</summary>
Motivation: 现有的EEG模型通常针对特定任务进行优化，限制了它们在需要多任务和连续推理的现实场景中的应用。需要一种可扩展且通用的EEG分析方法。

Method: 提出EEGAgent框架，利用LLM调度和规划EEG工具箱中的各种工具（如预处理、特征提取、事件检测等），以实现EEG分析的自动化。

Result: 在公开数据集上评估了EEGAgent的能力，证明其支持灵活和可解释的EEG分析。

Conclusion: EEGAgent为EEG分析提供了一个通用框架，具有在现实临床应用中发挥作用的潜力。

Abstract: Scalable and generalizable analysis of brain activity is essential for advancing both clinical diagnostics and cognitive research. Electroencephalography (EEG), a non-invasive modality with high temporal resolution, has been widely used for brain states analysis. However, most existing EEG models are usually tailored for individual specific tasks, limiting their utility in realistic scenarios where EEG analysis often involves multi-task and continuous reasoning. In this work, we introduce EEGAgent, a general-purpose framework that leverages large language models (LLMs) to schedule and plan multiple tools to automatically complete EEG-related tasks. EEGAgent is capable of performing the key functions: EEG basic information perception, spatiotemporal EEG exploration, EEG event detection, interaction with users, and EEG report generation. To realize these capabilities, we design a toolbox composed of different tools for EEG preprocessing, feature extraction, event detection, etc. These capabilities were evaluated on public datasets, and our EEGAgent can support flexible and interpretable EEG analysis, highlighting its potential for real-world clinical applications.

</details>


### [356] [Autonomous Concept Drift Threshold Determination](https://arxiv.org/abs/2511.09953)
*Pengqian Lu,Jie Lu,Anjin Liu,En Yu,Guangquan Zhang*

Main category: cs.LG

TL;DR: 动态阈值比固定阈值更优，并提出了一种动态阈值确定算法。


<details>
  <summary>Details</summary>
Motivation: 模型性能对固定阈值敏感，激励研究自适应阈值。

Method: 证明了自适应阈值策略的优越性，并提出了一种结合各数据段最佳阈值的动态阈值确定算法，通过引入新的比较阶段来调整阈值。

Result: 在合成和真实世界数据集（包括图像和表格数据）上的广泛实验表明，该方法显著提升了最先进的漂移检测器的性能。

Conclusion: 时间自适应阈值策略可以优于任何固定的阈值。

Abstract: Existing drift detection methods focus on designing sensitive test statistics. They treat the detection threshold as a fixed hyperparameter, set once to balance false alarms and late detections, and applied uniformly across all datasets and over time. However, maintaining model performance is the key objective from the perspective of machine learning, and we observe that model performance is highly sensitive to this threshold. This observation inspires us to investigate whether a dynamic threshold could be provably better. In this paper, we prove that a threshold that adapts over time can outperform any single fixed threshold. The main idea of the proof is that a dynamic strategy, constructed by combining the best threshold from each individual data segment, is guaranteed to outperform any single threshold that apply to all segments. Based on the theorem, we propose a Dynamic Threshold Determination algorithm. It enhances existing drift detection frameworks with a novel comparison phase to inform how the threshold should be adjusted. Extensive experiments on a wide range of synthetic and real-world datasets, including both image and tabular data, validate that our approach substantially enhances the performance of state-of-the-art drift detectors.

</details>


### [357] [AI-Integrated Decision Support System for Real-Time Market Growth Forecasting and Multi-Source Content Diffusion Analytics](https://arxiv.org/abs/2511.09962)
*Ziqing Yin,Xuanjing Chen,Xi Zhang*

Main category: cs.LG

TL;DR: 该研究提出了一种AI驱动的决策支持系统（DSS），通过结合图神经网络（GNN）和时间Transformer框架，以及因果推断模块，来预测和分析AI生成内容（AIGC）在数字营销中的传播和市场影响，并在真实数据集上验证了其优越性。


<details>
  <summary>Details</summary>
Motivation: 预测AI生成内容（AIGC）的传播轨迹和市场影响具有挑战性，因为数据异构性、非线性传播机制以及不断变化的消费者互动。

Method: 提出了一种AI驱动的决策支持系统（DSS），该系统整合了来自社交媒体、营销支出、消费者参与度和情感动态的多源数据，并利用混合图神经网络（GNN）和时间Transformer框架。该模型通过双通道架构联合学习内容传播结构和时间影响演变，同时因果推断模块区分了营销刺激对投资回报率（ROI）和市场可见性的影响。

Result: 在从Twitter、TikTok和YouTube广告等多个在线平台收集的大规模真实世界数据集上进行的实验表明，该系统在所有六项指标上均优于现有基线。

Conclusion: 该研究提出的DSS通过提供对AIGC驱动的内容传播和市场增长模式的可解释的实时见解，增强了营销决策。

Abstract: The rapid proliferation of AI-generated content (AIGC) has reshaped the dynamics of digital marketing and online consumer behavior. However, predicting the diffusion trajectory and market impact of such content remains challenging due to data heterogeneity, non linear propagation mechanisms, and evolving consumer interactions. This study proposes an AI driven Decision Support System (DSS) that integrates multi source data including social media streams, marketing expenditure records, consumer engagement logs, and sentiment dynamics using a hybrid Graph Neural Network (GNN) and Temporal Transformer framework. The model jointly learns the content diffusion structure and temporal influence evolution through a dual channel architecture, while causal inference modules disentangle the effects of marketing stimuli on return on investment (ROI) and market visibility. Experiments on large scale real-world datasets collected from multiple online platforms such as Twitter, TikTok, and YouTube advertising show that our system outperforms existing baselines in all six metrics. The proposed DSS enhances marketing decisions by providing interpretable real-time insights into AIGC driven content dissemination and market growth patterns.

</details>


### [358] [MultiTab: A Scalable Foundation for Multitask Learning on Tabular Data](https://arxiv.org/abs/2511.09970)
*Dimitrios Sinodinos,Jack Yi Wei,Narges Armanfard*

Main category: cs.LG

TL;DR: MultiTab-Net 是第一个专门为大型表格数据设计的 Transformer 多任务学习架构，它使用新颖的多任务掩码注意力机制来处理特征交互和任务竞争，并在多个领域取得了优于现有方法的性能。此外，还提出了 MultiTab-Bench 数据集生成器以供系统评估。


<details>
  <summary>Details</summary>
Motivation: 现有的多任务学习方法主要集中在推荐系统，并且大多使用多层感知机（MLP）作为骨干网络，这在处理复杂特征交互和大规模数据时存在局限性。Transformer 架构在其他领域已证明其优势，因此需要一种适用于表格数据的 Transformer 多任务学习方法。

Method: 提出了一种名为 MultiTab-Net 的新型多任务 Transformer 架构，该架构采用新颖的多任务掩码注意力机制来动态建模特征之间的依赖关系，同时缓解任务竞争。同时，开发了一个名为 MultiTab-Bench 的通用多任务合成数据集生成器，用于系统评估。

Result: 在包括大规模推荐数据、类似人口普查的社会经济数据和物理数据集在内的多个领域中，MultiTab-Net 实现了比现有方法更高的多任务增益。

Conclusion: MultiTab-Net 是一种有效的多任务 Transformer 架构，适用于大规模表格数据，并且在各种任务和数据类型上都表现出色。MultiTab-Bench 为多任务学习的评估提供了新的工具。

Abstract: Tabular data is the most abundant data type in the world, powering systems in finance, healthcare, e-commerce, and beyond. As tabular datasets grow and span multiple related targets, there is an increasing need to exploit shared task information for improved multitask generalization. Multitask learning (MTL) has emerged as a powerful way to improve generalization and efficiency, yet most existing work focuses narrowly on large-scale recommendation systems, leaving its potential in broader tabular domains largely underexplored. Also, existing MTL approaches for tabular data predominantly rely on multi-layer perceptron-based backbones, which struggle to capture complex feature interactions and often fail to scale when data is abundant, a limitation that transformer architectures have overcome in other domains. Motivated by this, we introduce MultiTab-Net, the first multitask transformer architecture specifically designed for large tabular data. MultiTab-Net employs a novel multitask masked-attention mechanism that dynamically models feature-feature dependencies while mitigating task competition. Through extensive experiments, we show that MultiTab-Net consistently achieves higher multitask gain than existing MTL architectures and single-task transformers across diverse domains including large-scale recommendation data, census-like socioeconomic data, and physics datasets, spanning a wide range of task counts, task types, and feature modalities. In addition, we contribute MultiTab-Bench, a generalized multitask synthetic dataset generator that enables systematic evaluation of multitask dynamics by tuning task count, task correlations, and relative task complexity. Our code is publicly available at https://github.com/Armanfard-Lab/MultiTab.

</details>


### [359] [Rediscovering the Lunar Equation of the Centre with AI Feynman via Embedded Physical Biases](https://arxiv.org/abs/2511.09979)
*Saumya Shah,Zi-Yu Khoo,Abel Yang,Stéphane Bressan*

Main category: cs.LG

TL;DR: AI Feynman 算法成功从月球星历数据中重新发现了天文学中的“中心方程”，但需要专家知识来选择坐标系。研究提出了一种自动预处理方法来寻找规范坐标系，以克服这一限制。


<details>
  <summary>Details</summary>
Motivation: 探索使用 AI Feynman 符号回归算法自动重新发现天文学基本方程“中心方程”的可行性，并解决该方法对专家知识的依赖性。

Method: 通过引入物理启发式的归纳和观测偏差（例如数据预处理和搜索空间限制），使用 AI Feynman 从月球星历数据中恢复中心方程。然后，提出一种自动预处理扩展来寻找规范坐标系。

Result: AI Feynman 成功地从月球星历数据中恢复了中心方程的一阶解析形式。自动预处理方法的引入旨在解决手动方法中对专家驱动的坐标系选择的依赖性。

Conclusion: 有针对性地嵌入领域知识可以使符号回归重新发现物理定律，但当通过定制偏差利用领域知识时，在约束符号回归以推导物理方程方面仍存在挑战。

Abstract: This work explores using the physics-inspired AI Feynman symbolic regression algorithm to automatically rediscover a fundamental equation in astronomy -- the Equation of the Centre. Through the introduction of observational and inductive biases corresponding to the physical nature of the system through data preprocessing and search space restriction, AI Feynman was successful in recovering the first-order analytical form of this equation from lunar ephemerides data. However, this manual approach highlights a key limitation in its reliance on expert-driven coordinate system selection. We therefore propose an automated preprocessing extension to find the canonical coordinate system. Results demonstrate that targeted domain knowledge embedding enables symbolic regression to rediscover physical laws, but also highlight further challenges in constraining symbolic regression to derive physics equations when leveraging domain knowledge through tailored biases.

</details>


### [360] [Towards Robust Multimodal Learning in the Open World](https://arxiv.org/abs/2511.09989)
*Fushuo Huo*

Main category: cs.LG

TL;DR: 本研究探讨了在开放世界环境中，多模态学习的鲁棒性挑战，旨在弥合受控实验性能与实际部署需求之间的差距。


<details>
  <summary>Details</summary>
Motivation: 当前基于神经网络的多模态学习模型在开放世界环境中鲁棒性不足，难以应对动态、模糊的场景。

Method: 本研究聚焦于多模态学习鲁棒性这一核心挑战。

Result: 略

Conclusion: 略

Abstract: The rapid evolution of machine learning has propelled neural networks to unprecedented success across diverse domains. In particular, multimodal learning has emerged as a transformative paradigm, leveraging complementary information from heterogeneous data streams (e.g., text, vision, audio) to advance contextual reasoning and intelligent decision-making. Despite these advancements, current neural network-based models often fall short in open-world environments characterized by inherent unpredictability, where unpredictable environmental composition dynamics, incomplete modality inputs, and spurious distributions relations critically undermine system reliability. While humans naturally adapt to such dynamic, ambiguous scenarios, artificial intelligence systems exhibit stark limitations in robustness, particularly when processing multimodal signals under real-world complexity. This study investigates the fundamental challenge of multimodal learning robustness in open-world settings, aiming to bridge the gap between controlled experimental performance and practical deployment requirements.

</details>


### [361] [Interaction as Interference: A Quantum-Inspired Aggregation Approach](https://arxiv.org/abs/2511.10018)
*Pilsung Kang*

Main category: cs.LG

TL;DR: 该研究提出了一种受量子启发的模型，称为干涉核分类器 (IKC)，用于处理特征之间的协同和拮抗作用。与传统方法不同，IKC 通过在概率计算前对复数振幅进行相干叠加来引入干涉交叉项，从而直接控制协同和拮抗的程度。


<details>
  <summary>Details</summary>
Motivation: 传统方法难以精确控制特征交互中的协同（synergy）或拮抗（antagonism）现象，这限制了模型的解释力和准确性。本研究旨在提出一种新的框架，借鉴量子力学中的干涉概念来更有效地建模和控制这种交互作用。

Method: 提出了一种受量子启发的模型，即干涉核分类器 (IKC)。该模型遵循玻恩规则，通过对复数振幅进行相干叠加（而不是直接叠加其平方）来计算概率，从而引入一个干涉交叉项。该交叉项在最小线性模型中等同于标准的潜在结果交互对比。此外，研究还引入了“相干增益”和“干涉信息”两个诊断指标。

Result: 在合成的 XOR 数据集上，IKC 优于其他基线模型。在 Adult 和 Bank Marketing 等真实数据集上，IKC 的表现具有竞争力，但略逊于能力最强的基线模型。实验表明，将聚合方式从非相干切换到相干，能够一致地改善负对数似然、Brier 分数和校准误差，并且在两个数据集上均观察到正的相干增益。

Conclusion: 受量子启发的相干叠加方法为控制特征交互中的协同和拮抗提供了一种新颖且有效的方式。IKC 模型及其诊断工具为理解和利用这种交互作用提供了新的视角，并在实际应用中展现了其潜力。

Abstract: Classical approaches often treat interaction as engineered product terms or as emergent patterns in flexible models, offering little control over how synergy or antagonism arises. We take a quantum-inspired view: following the Born rule (probability as squared amplitude), \emph{coherent} aggregation sums complex amplitudes before squaring, creating an interference cross-term, whereas an \emph{incoherent} proxy sums squared magnitudes and removes it. In a minimal linear-amplitude model, this cross-term equals the standard potential-outcome interaction contrast \(Δ_{\mathrm{INT}}\) in a \(2\times 2\) factorial design, giving relative phase a direct, mechanism-level control over synergy versus antagonism.
  We instantiate this idea in a lightweight \emph{Interference Kernel Classifier} (IKC) and introduce two diagnostics: \emph{Coherent Gain} (log-likelihood gain of coherent over the incoherent proxy) and \emph{Interference Information} (the induced Kullback-Leibler gap). A controlled phase sweep recovers the identity. On a high-interaction synthetic task (XOR), IKC outperforms strong baselines under paired, budget-matched comparisons; on real tabular data (\emph{Adult} and \emph{Bank Marketing}) it is competitive overall but typically trails the most capacity-rich baseline in paired differences. Holding learned parameters fixed, toggling aggregation from incoherent to coherent consistently improves negative log-likelihood, Brier score, and expected calibration error, with positive Coherent Gain on both datasets.

</details>


### [362] [A Novel Data-Dependent Learning Paradigm for Large Hypothesis Classes](https://arxiv.org/abs/2511.09996)
*Alireza F. Pour,Shai Ben-David*

Main category: cs.LG

TL;DR: 当模型集合过大时，我们提出了一种新的学习范式，它通过更强地结合经验数据来克服传统SRM（或正则化）方法的局限性，并且可以灵活地利用各种学习假设，而无需预先了解它们的真实参数。


<details>
  <summary>Details</summary>
Motivation: 现有的学习算法在处理过大的候选模型集合时，其经验估计收敛到真实损失的能力会受到限制。这种挑战通常通过SRM（或正则化）方法来解决。

Method: 提出了一种新的学习范式，该范式依赖于对经验数据的更强整合，并减少了基于先验假设的算法决策。该方法分析了其泛化能力，并展示了其在多种学习假设下的优势。

Result: 在相似性、聚类、Lipschitzness和对比学习等假设下，证明了该方法是有效的，并且可以利用这些假设的真实参数是未知的。

Conclusion: 所提出的学习范式能够有效利用各种学习假设，而无需预先知道其精确参数，为处理大规模模型集合提供了新的解决方案。

Abstract: We address the general task of learning with a set of candidate models that is too large to have a uniform convergence of empirical estimates to true losses. While the common approach to such challenges is SRM (or regularization) based learning algorithms, we propose a novel learning paradigm that relies on stronger incorporation of empirical data and requires less algorithmic decisions to be based on prior assumptions. We analyze the generalization capabilities of our approach and demonstrate its merits in several common learning assumptions, including similarity of close points, clustering of the domain into highly label-homogeneous regions, Lipschitzness assumptions of the labeling rule, and contrastive learning assumptions. Our approach allows utilizing such assumptions without the need to know their true parameters a priori.

</details>


### [363] [Improved Offline Reinforcement Learning via Quantum Metric Encoding](https://arxiv.org/abs/2511.10187)
*Outongyi Lv,Yewei Yuan,Nana Liu*

Main category: cs.LG

TL;DR: 本论文提出了一种名为量子度量编码（QME）的方法，通过将状态嵌入到更紧凑、更有意义的表示中来解决离线强化学习（RL）中的样本量有限的问题。


<details>
  <summary>Details</summary>
Motivation: 在现实世界的应用中，强化学习（RL）通常面临样本量有限的挑战，这导致离线RL的性能不佳。因此，需要探索新的方法来处理这种情况。

Method: 本研究提出了一种量子度量编码（QME）的方法，将状态嵌入到更紧凑、更有意义的表示中，这种编码的结构受到量子电路的启发。QME既可以用于经典数据（在经典设备上实现），也可以用于量子数据（直接在量子硬件上实现）。

Result: 在三个样本量仅为100的测试数据集上，使用QME嵌入状态并解码奖励，相比于直接在原始状态和奖励上训练，SAC算法的最高奖励性能提升了116.2%，IQL算法提升了117.6%。

Conclusion: QME通过嵌入后的状态空间展现出较低的$Δ$-双曲性，这表明QME的改进效果源于其改变了状态空间的几何结构。因此，QME的低$Δ$-双曲性和有效性可能为开发高效的有限样本离线RL方法提供有价值的见解。

Abstract: Reinforcement learning (RL) with limited samples is common in real-world applications. However, offline RL performance under this constraint is often suboptimal. We consider an alternative approach to dealing with limited samples by introducing the Quantum Metric Encoder (QME). In this methodology, instead of applying the RL framework directly on the original states and rewards, we embed the states into a more compact and meaningful representation, where the structure of the encoding is inspired by quantum circuits. For classical data, QME is a classically simulable, trainable unitary embedding and thus serves as a quantum-inspired module, on a classical device. For quantum data in the form of quantum states, QME can be implemented directly on quantum hardware, allowing for training without measurement or re-encoding.
  We evaluated QME on three datasets, each limited to 100 samples. We use Soft-Actor-Critic (SAC) and Implicit-Q-Learning (IQL), two well-known RL algorithms, to demonstrate the effectiveness of our approach. From the experimental results, we find that training offline RL agents on QME-embedded states with decoded rewards yields significantly better performance than training on the original states and rewards. On average across the three datasets, for maximum reward performance, we achieve a 116.2% improvement for SAC and 117.6% for IQL.
  We further investigate the $Δ$-hyperbolicity of our framework, a geometric property of the state space known to be important for the RL training efficacy. The QME-embedded states exhibit low $Δ$-hyperbolicity, suggesting that the improvement after embedding arises from the modified geometry of the state space induced by QME. Thus, the low $Δ$-hyperbolicity and the corresponding effectiveness of QME could provide valuable information for developing efficient offline RL methods under limited-sample conditions.

</details>


### [364] [DemoTuner: Efficient DBMS Knobs Tuning via LLM-Assisted Demonstration Reinforcement Learning](https://arxiv.org/abs/2511.09998)
*Hui Dou,Lei Jin,Yuxuan Zhou,Jiang He,Yiwen Zhang*

Main category: cs.LG

TL;DR: 通过LLM辅助的演示强化学习方法DemoTuner，利用文档中的调优提示来改进数据库管理系统（DBMS）的性能调优。


<details>
  <summary>Details</summary>
Motivation: 手动调整DBMS性能调优参数耗时费力，而且由于配置空间的复杂性和高维度性，效率低下。虽然基于强化学习（RL）的方法在自动调优方面取得了一定进展，但它们在离线训练过程中仍然面临收敛速度慢的问题。

Method: 提出了一种名为DemoTuner的框架，该框架利用大型语言模型（LLM）辅助的演示强化学习方法。具体来说，为了全面准确地从文档中提取调优提示，设计了一种结构化的思维链提示，以利用LLM进行面向条件的调优提示提取。为了有效地将提取的调优提示集成到RL代理训练中，提出了一种名为HA-DDPGfD的提示感知演示强化学习算法。

Result: 在MySQL和PostgreSQL上针对各种工作负载进行的实验评估表明，DemoTuner在性能提升和在线调优成本降低方面明显优于DB-BERT、GPTuner和CDBTune三个代表性基线。此外，DemoTuner在应对未知工作负载的应用场景时也表现出卓越的适应性。

Conclusion: DemoTuner是首次将演示强化学习算法应用于DBMS调优的研究工作，它通过LLM提取文档中的调优提示，并将其集成到RL训练中，有效解决了现有方法的不足，并在性能和效率上取得了显著的提升。

Abstract: The performance of modern DBMSs such as MySQL and PostgreSQL heavily depends on the configuration of performance-critical knobs. Manual tuning these knobs is laborious and inefficient due to the complex and high-dimensional nature of the configuration space. Among the automated tuning methods, reinforcement learning (RL)-based methods have recently sought to improve the DBMS knobs tuning process from several different perspectives. However, they still encounter challenges with slow convergence speed during offline training. In this paper, we mainly focus on how to leverage the valuable tuning hints contained in various textual documents such as DBMS manuals and web forums to improve the offline training of RL-based methods. To this end, we propose an efficient DBMS knobs tuning framework named DemoTuner via a novel LLM-assisted demonstration reinforcement learning method. Specifically, to comprehensively and accurately mine tuning hints from documents, we design a structured chain of thought prompt to employ LLMs to conduct a condition-aware tuning hints extraction task. To effectively integrate the mined tuning hints into RL agent training, we propose a hint-aware demonstration reinforcement learning algorithm HA-DDPGfD in DemoTuner. As far as we know, DemoTuner is the first work to introduce the demonstration reinforcement learning algorithm for DBMS knobs tuning. Experimental evaluations conducted on MySQL and PostgreSQL across various workloads demonstrate the significant advantages of DemoTuner in both performance improvement and online tuning cost reduction over three representative baselines including DB-BERT, GPTuner and CDBTune. Additionally, DemoTuner also exhibits superior adaptability to application scenarios with unknown workloads.

</details>


### [365] [SVD-NO: Learning PDE Solution Operators with SVD Integral Kernels](https://arxiv.org/abs/2511.10025)
*Noam Koren,Ralf J. J. Mackenbach,Ruud J. G. van Sloun,Kira Radinsky,Daniel Freedman*

Main category: cs.LG

TL;DR: SVD-NO是一种新的神经算子，通过显式参数化核的奇异值分解（SVD）来学习偏微分方程（PDE）的解算子，并在低秩基中直接进行积分。该方法在五个不同的基准方程上取得了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 现有基于傅里叶或图技术的神经算子在核积分算子的结构上做了强假设，可能限制了表达能力。因此，需要一种更具表达力且计算成本合理的新型神经算子。

Method: SVD-NO通过以下方式工作：1. 使用两个轻量级网络学习左和右奇异函数。2. 使用对角矩阵参数学习奇异值。3. 使用Gram矩阵正则化器强制执行正交性。4. 在低秩基中直接执行积分。这种方法显式地参数化了核的奇异值分解（SVD）。

Result: SVD-NO在五个不同的基准方程上实现了新的最先进性能，特别是在空间变异性高的PDE上表现出更大的性能提升。由于其低秩结构，计算复杂度保持合理。

Conclusion: SVD-NO通过显式参数化核的SVD并直接在低秩基中进行积分，克服了现有神经算子的局限性，在保持合理计算复杂度的同时实现了高表达能力，并在各种PDE问题上取得了最先进的性能。

Abstract: Neural operators have emerged as a promising paradigm for learning solution operators of partial differential equa- tions (PDEs) directly from data. Existing methods, such as those based on Fourier or graph techniques, make strong as- sumptions about the structure of the kernel integral opera- tor, assumptions which may limit expressivity. We present SVD-NO, a neural operator that explicitly parameterizes the kernel by its singular-value decomposition (SVD) and then carries out the integral directly in the low-rank basis. Two lightweight networks learn the left and right singular func- tions, a diagonal parameter matrix learns the singular values, and a Gram-matrix regularizer enforces orthonormality. As SVD-NO approximates the full kernel, it obtains a high de- gree of expressivity. Furthermore, due to its low-rank struc- ture the computational complexity of applying the operator remains reasonable, leading to a practical system. In exten- sive evaluations on five diverse benchmark equations, SVD- NO achieves a new state of the art. In particular, SVD-NO provides greater performance gains on PDEs whose solutions are highly spatially variable. The code of this work is publicly available at https://github.com/2noamk/SVDNO.git.

</details>


### [366] [Temporal Latent Variable Structural Causal Model for Causal Discovery under External Interferences](https://arxiv.org/abs/2511.10031)
*Ruichu Cai,Xiaokai Huang,Wei Chen,Zijian Li,Zhifeng Hao*

Main category: cs.LG

TL;DR: 提出一种结合时间潜变量和专家知识来推断受干扰数据中因果关系的新模型。


<details>
  <summary>Details</summary>
Motivation: 在存在外部干扰（由未知潜变量引起）的情况下，从观测数据推断因果关系具有挑战性。

Method: 提出一种新的时间潜变量结构因果模型，该模型包含代表变量之间因果关系的因果强度和邻接系数。该方法利用变分推断整合专家知识来指导模型参数学习。

Result: 实验结果表明，所提出的方法在稳定性和准确性方面表现优越。

Conclusion: 所提出的方法能够稳定且准确地从受干扰的数据中推断因果关系，并且能够有效整合专家知识。

Abstract: Inferring causal relationships from observed data is an important task, yet it becomes challenging when the data is subject to various external interferences. Most of these interferences are the additional effects of external factors on observed variables. Since these external factors are often unknown, we introduce latent variables to represent these unobserved factors that affect the observed data. Specifically, to capture the causal strength and adjacency information, we propose a new temporal latent variable structural causal model, incorporating causal strength and adjacency coefficients that represent the causal relationships between variables. Considering that expert knowledge can provide information about unknown interferences in certain scenarios, we develop a method that facilitates the incorporation of prior knowledge into parameter learning based on Variational Inference, to guide the model estimation. Experimental results demonstrate the stability and accuracy of our proposed method.

</details>


### [367] [BuddyMoE: Exploiting Expert Redundancy to Accelerate Memory-Constrained Mixture-of-Experts Inference](https://arxiv.org/abs/2511.10054)
*Yun Wang,Lingyun Yang,Senhao Yu,Yixiao Wang,Ruixing Li,Zhixiang Wei,James Yen,Zhengwei Qi*

Main category: cs.LG

TL;DR: MoE模型因参数量大而超出GPU显存，现有CPU offload方案存在PCIe延迟问题，预取失败时的对策（按需加载或丢弃专家）均有不足，核心挑战在于平衡速度与精度。


<details>
  <summary>Details</summary>
Motivation: 现代MoE模型参数量巨大，超出GPU显存容量，而现有CPU offload方案存在PCIe延迟，预取失败时的应对策略（按需加载或丢弃专家）均会严重影响推理速度或模型精度。因此，在预取失败的情况下，同时保持高推理速度和模型精度的能力是亟待解决的关键挑战。

Method: 文章提出了一种新的解决方案来应对MoE模型预取失败的问题，旨在解决现有方法在速度和精度上的权衡。具体方法未在摘要中详细说明，但暗示了其区别于‘按需加载’和‘丢弃专家’的策略。

Result: 文章指出，预取失败时，现有的“按需加载”策略会导致显著的延迟（约10毫秒），而“丢弃专家”策略会严重降低模型精度。这表明现有方法的局限性，为提出新的解决方案奠定了基础。

Conclusion: 在MoE模型预取失败的情况下，维持高推理速度和模型精度的能力是一个关键的挑战，需要新的解决方案来克服现有方法的不足。

Abstract: Mixture-of-Experts (MoE) architectures scale language models by activating only a subset of specialized expert networks for each input token, thereby reducing the number of floating-point operations. However, the growing size of modern MoE models causes their full parameter sets to exceed GPU memory capacity; for example, Mixtral-8x7B has 45 billion parameters and requires 87 GB of memory even though only 14 billion parameters are used per token. Existing systems alleviate this limitation by offloading inactive experts to CPU memory, but transferring experts across the PCIe interconnect incurs significant latency (about 10 ms). Prefetching heuristics aim to hide this latency by predicting which experts are needed, but prefetch failures introduce significant stalls and amplify inference latency. In the event of a prefetch failure, prior work offers two primary solutions: either fetch the expert on demand, which incurs a long stall due to the PCIe bottleneck, or drop the expert from the computation, which significantly degrades model accuracy. The critical challenge, therefore, is to maintain both high inference speed and model accuracy when prefetching fails.

</details>


### [368] [From Static Structures to Ensembles: Studying and Harnessing Protein Structure Tokenization](https://arxiv.org/abs/2511.10056)
*Zijing Liu,Bin Feng,He Cao,Yu Li*

Main category: cs.LG

TL;DR: 通过利用预训练的序列嵌入来弥合序列和结构之间的语义鸿沟，并引入“同义词交换”策略来生成多样化的构象系综，从而在蛋白质结构代币化方面取得了进展。


<details>
  <summary>Details</summary>
Motivation: 尽管有许多关于结构代币化的近期工作，但潜在的离散表示的性质并未得到充分理解。

Method: 首先，我们证明了在结构预测的语言模型中使用结构代币的成功利用取决于使用丰富的、预训练的序列嵌入来弥合序列和结构“语言”之间的语义鸿沟。然后，对结构词汇本身的分析揭示了显著的语义冗余，其中多个不同的代币对应于几乎相同的局部几何形状，充当“结构同义词”。通过用结构同义词扰动预测的结构来生成多样化的构象系综。

Result: 这种冗余可以通过简单的“同义词交换”策略来利用，以生成多样化的构象系综。该计算成本较低的方法可以准确地再现蛋白质的灵活性，并与最先进的模型具有竞争力。

Conclusion: 该研究为离散的蛋白质结构表示的性质提供了基本见解，并引入了一种用于模拟蛋白质动力学的强大、近乎即时的方法。

Abstract: Protein structure tokenization converts 3D structures into discrete or vectorized representations, enabling the integration of structural and sequence data. Despite many recent works on structure tokenization, the properties of the underlying discrete representations are not well understood. In this work, we first demonstrate that the successful utilization of structural tokens in a language model for structure prediction depends on using rich, pre-trained sequence embeddings to bridge the semantic gap between the sequence and structural "language". The analysis of the structural vocabulary itself then reveals significant semantic redundancy, where multiple distinct tokens correspond to nearly identical local geometries, acting as "structural synonyms". This redundancy, rather than being a flaw, can be exploited with a simple "synonym swap" strategy to generate diverse conformational ensembles by perturbing a predicted structure with its structural synonyms. This computationally lightweight method accurately recapitulates protein flexibility, performing competitively with state-of-the-art models. Our study provides fundamental insights into the nature of discrete protein structure representations and introduces a powerful, near-instantaneous method for modeling protein dynamics. Source code is available in https://github.com/IDEA-XL/TokenMD.

</details>


### [369] [FAQNAS: FLOPs-aware Hybrid Quantum Neural Architecture Search using Genetic Algorithm](https://arxiv.org/abs/2511.10062)
*Muhammad Kashif,Shaf Khalid,Alberto Marchisio,Nouhaila Innan,Muhammad Shafique*

Main category: cs.LG

TL;DR: FAQNAS是一个用于混合量子神经网络（HQNN）设计的计算量感知神经架构搜索（NAS）框架，旨在平衡准确性和计算成本（FLOPs）。


<details>
  <summary>Details</summary>
Motivation: 在NISQ时代，虽然量子电路不直接用FLOPs衡量，但HQNNs通常在经典模拟器上训练，其中FLOPs决定了运行时间和可扩展性。因此，FLOPs是衡量HQNNs计算复杂度的实用指标。

Method: FAQNAS将HQNN设计视为一个多目标优化问题，明确将FLOPs纳入优化目标，以在准确性和计算成本之间取得平衡。

Result: 在五个基准数据集上的实验表明，量子FLOPs的增加对准确性有显著影响，而经典FLOPs基本保持不变。FAQNAS发现的帕累托最优解表明，与忽略FLOPs的基线相比，可以在显著降低计算成本的情况下获得有竞争力的准确性。

Conclusion: FLOPs感知是NISQ时代HQNN设计的实用标准，也是未来HQNN系统可扩展设计的原则。

Abstract: Hybrid Quantum Neural Networks (HQNNs), which combine parameterized quantum circuits with classical neural layers, are emerging as promising models in the noisy intermediate-scale quantum (NISQ) era. While quantum circuits are not naturally measured in floating point operations (FLOPs), most HQNNs (in NISQ era) are still trained on classical simulators where FLOPs directly dictate runtime and scalability. Hence, FLOPs represent a practical and viable metric to measure the computational complexity of HQNNs. In this work, we introduce FAQNAS, a FLOPs-aware neural architecture search (NAS) framework that formulates HQNN design as a multi-objective optimization problem balancing accuracy and FLOPs. Unlike traditional approaches, FAQNAS explicitly incorporates FLOPs into the optimization objective, enabling the discovery of architectures that achieve strong performance while minimizing computational cost. Experiments on five benchmark datasets (MNIST, Digits, Wine, Breast Cancer, and Iris) show that quantum FLOPs dominate accuracy improvements, while classical FLOPs remain largely fixed. Pareto-optimal solutions reveal that competitive accuracy can often be achieved with significantly reduced computational cost compared to FLOPs-agnostic baselines. Our results establish FLOPs-awareness as a practical criterion for HQNN design in the NISQ era and as a scalable principle for future HQNN systems.

</details>


### [370] [Tree-Based Stochastic Optimization for Solving Large-Scale Urban Network Security Games](https://arxiv.org/abs/2511.10072)
*Shuxin Zhuang,Linjian Meng,Shuxin Li,Minming Li,Youzhi Zhang*

Main category: cs.LG

TL;DR: 大型城市网络安全博弈（UNSGs）中的纳什均衡（NE）求解困难，现有方法（如PSRO）因精确计算最优响应（BR）的挑战和基于神经网络的随机优化在处理庞大行动空间时的局限性而受阻。本文提出的基于树的随机优化（TSO）框架，通过树状结构表示行动空间，解决了神经网络表示的障碍，并理论上证明了其无偏损失函数的等价性。此外，引入的样本-修剪机制有助于提高收敛解的质量。实验结果表明TSO优于其他基线算法。


<details>
  <summary>Details</summary>
Motivation: 现有方法在求解大规模城市网络安全博弈（UNSGs）的纳什均衡（NE）时面临挑战，包括策略空间响应预言机（PSRO）框架中精确计算最优响应（BR）的困难，以及基于神经网络的随机优化在表示巨大行动空间时的局限性。

Method: 提出了一种名为树基随机优化（TSO）的框架。该框架采用树基行动表示，将整个行动空间映射到树结构上，解决了神经网络难以表示不可枚举的行动空间的问题，并将其整合到损失函数中，理论上证明了其与无偏损失函数的等价性。此外，还引入了一个样本-修剪机制，以减少陷入次优局部最优的风险。

Result: 通过大量实验证明，TSO框架在处理UNSGs方面优于其他基线算法。

Conclusion: TSO框架通过创新的树基行动表示和样本-修剪机制，成功克服了现有方法在求解大规模UNSGs时的局限性，有效提高了求解效率和解的质量。

Abstract: Urban Network Security Games (UNSGs), which model the strategic allocation of limited security resources on city road networks, are critical for urban safety. However, finding a Nash Equilibrium (NE) in large-scale UNSGs is challenging due to their massive and combinatorial action spaces. One common approach to addressing these games is the Policy-Space Response Oracle (PSRO) framework, which requires computing best responses (BR) at each iteration. However, precisely computing exact BRs is impractical in large-scale games, and employing reinforcement learning to approximate BRs inevitably introduces errors, which limits the overall effectiveness of the PSRO methods. Recent advancements in leveraging non-convex stochastic optimization to approximate an NE offer a promising alternative to the burdensome BR computation. However, utilizing existing stochastic optimization techniques with an unbiased loss function for UNSGs remains challenging because the action spaces are too vast to be effectively represented by neural networks. To address these issues, we introduce Tree-based Stochastic Optimization (TSO), a framework that bridges the gap between the stochastic optimization paradigm for NE-finding and the demands of UNSGs. Specifically, we employ the tree-based action representation that maps the whole action space onto a tree structure, addressing the challenge faced by neural networks in representing actions when the action space cannot be enumerated. We then incorporate this representation into the loss function and theoretically demonstrate its equivalence to the unbiased loss function. To further enhance the quality of the converged solution, we introduce a sample-and-prune mechanism that reduces the risk of being trapped in suboptimal local optima. Extensive experimental results indicate the superiority of TSO over other baseline algorithms in addressing the UNSGs.

</details>


### [371] [eXIAA: eXplainable Injections for Adversarial Attack](https://arxiv.org/abs/2511.10088)
*Leonardo Pesce,Jiawen Wei,Gianmarco Mengaldo*

Main category: cs.LG

TL;DR: 提出了一种新的黑盒模型无关的对抗性攻击方法，用于后验可解释人工智能（XAI），特别是在图像域。该攻击旨在修改原始解释，同时保持相同的预测类别，并且不被肉眼察觉。与以前的方法不同，我们不需要访问模型或其权重，只需要访问模型计算的预测和解释。此外，该攻击只需一步即可完成，同时显著改变了提供的解释，经验评估证明了这一点。我们较低的要求暴露了当前可解释性方法的关键漏洞，引发了对其在安全关键应用中可靠性的担忧。


<details>
  <summary>Details</summary>
Motivation: 后验可解释性方法旨在解释机器学习模型行为的原因。然而，这些方法可能存在漏洞，可能被操纵以提供误导性解释，尤其是在安全关键应用中。

Method: 提出了一种新的黑盒模型无关的对抗性攻击方法。该方法修改了由后验可解释性方法（如显着性图、集成梯度和DeepLIFT SHAP）生成的解释，同时保持相同的预测类别，并且不被肉眼察觉。攻击在单步内完成，并且不需要访问模型或其权重，只需要模型的预测和解释。

Result: 在预训练的 ResNet-18 和 ViT-B16 模型上，该攻击能够显著改变解释，而预测概率保持不变。通过平均绝对差计算解释的变化，并通过结构相似性度量（SSIM）验证原始图像和损坏图像的相似性，证明了攻击的有效性。

Conclusion: 我们提出的攻击方法暴露了当前可解释性方法的关键漏洞，这可能影响其在安全关键应用中的可靠性。需要进一步研究以提高可解释性方法的鲁棒性，并开发更安全的评估指标。

Abstract: Post-hoc explainability methods are a subset of Machine Learning (ML) that aim to provide a reason for why a model behaves in a certain way. In this paper, we show a new black-box model-agnostic adversarial attack for post-hoc explainable Artificial Intelligence (XAI), particularly in the image domain. The goal of the attack is to modify the original explanations while being undetected by the human eye and maintain the same predicted class. In contrast to previous methods, we do not require any access to the model or its weights, but only to the model's computed predictions and explanations. Additionally, the attack is accomplished in a single step while significantly changing the provided explanations, as demonstrated by empirical evaluation. The low requirements of our method expose a critical vulnerability in current explainability methods, raising concerns about their reliability in safety-critical applications. We systematically generate attacks based on the explanations generated by post-hoc explainability methods (saliency maps, integrated gradients, and DeepLIFT SHAP) for pretrained ResNet-18 and ViT-B16 on ImageNet. The results show that our attacks could lead to dramatically different explanations without changing the predictive probabilities. We validate the effectiveness of our attack, compute the induced change based on the explanation with mean absolute difference, and verify the closeness of the original image and the corrupted one with the Structural Similarity Index Measure (SSIM).

</details>


### [372] [T2IBias: Uncovering Societal Bias Encoded in the Latent Space of Text-to-Image Generative Models](https://arxiv.org/abs/2511.10089)
*Abu Sufian,Cosimo Distante,Marco Leo,Hanan Salam*

Main category: cs.LG

TL;DR: 研究表明，主流文本到图像生成模型存在系统性社会偏见，会固化和放大性别及种族刻板印象，尤其是在职业形象的呈现上。


<details>
  <summary>Details</summary>
Motivation: 探讨主流文本到图像（T2I）生成模型是否在其预训练的潜在空间中系统性地编码了社会偏见，以及这些偏见如何影响AI在实际应用中的伦理问题，特别是关于种族和性别刻板印象的再生产和放大。

Method: 通过对五种最流行的开源T2I模型进行实证研究，使用十个中性、与职业相关的提示，为每个职业生成100张图像，共计5000张。然后，邀请了代表不同种族和性别的多样化人类评估者对这些图像进行评估。

Result: 所有五种模型都编码并放大了显著的社会偏见：看护和护理角色持续被女性化，而公司CEO、政治家、医生和律师等高地位职业则绝大多数由男性和白人代表。此外，还发现了模型特定的模式，如QWEN-Image倾向于生成东亚面孔，Kandinsky以白人个体为主，而SDXL的分布相对更广泛但仍存在偏见。

Conclusion: 研究结果为AI项目经理和从业者提供了关键见解，帮助他们选择能够生成符合负责任AI原则的图像的公平AI模型和定制化提示。讨论了这些偏见的风险，并提出了在构建负责任的生成式AI系统中减轻偏见的具体策略。

Abstract: Text-to-image (T2I) generative models are largely used in AI-powered real-world applications and value creation. However, their strategic deployment raises critical concerns for responsible AI management, particularly regarding the reproduction and amplification of race- and gender-related stereotypes that can undermine organizational ethics. In this work, we investigate whether such societal biases are systematically encoded within the pretrained latent spaces of state-of-the-art T2I models. We conduct an empirical study across the five most popular open-source models, using ten neutral, profession-related prompts to generate 100 images per profession, resulting in a dataset of 5,000 images evaluated by diverse human assessors representing different races and genders. We demonstrate that all five models encode and amplify pronounced societal skew: caregiving and nursing roles are consistently feminized, while high-status professions such as corporate CEO, politician, doctor, and lawyer are overwhelmingly represented by males and mostly White individuals. We further identify model-specific patterns, such as QWEN-Image's near-exclusive focus on East Asian outputs, Kandinsky's dominance of White individuals, and SDXL's comparatively broader but still biased distributions. These results provide critical insights for AI project managers and practitioners, enabling them to select equitable AI models and customized prompts that generate images in alignment with the principles of responsible AI. We conclude by discussing the risks of these biases and proposing actionable strategies for bias mitigation in building responsible GenAI systems.

</details>


### [373] [How does My Model Fail? Automatic Identification and Interpretation of Physical Plausibility Failure Modes with Matryoshka Transcoders](https://arxiv.org/abs/2511.10094)
*Yiming Tang,Abhijeet Sinha,Dianbo Liu*

Main category: cs.LG

TL;DR: 该研究提出了一种名为Matryoshka Transcoders的新框架，用于自动发现和解释生成模型中的物理合理性缺陷，通过利用多粒度分层稀疏特征学习和大型多模态模型进行解释，以识别物理相关的故障模式，并为评估生成模型的物理合理性设定了基准。


<details>
  <summary>Details</summary>
Motivation: 现有的生成模型在遵循物理规律方面存在明显缺陷，而现有的评估方法无法有效检测和解释这些缺陷，阻碍了针对性的模型改进。

Method: 提出Matryoshka Transcoders框架，该框架将Matryoshka表示学习范式扩展到转码器架构，实现多粒度层次化稀疏特征学习。通过在物理合理性分类器的中间表示上进行训练，并利用大型多模态模型进行解释，来发现和解释物理规律相关的故障模式。

Result: 该方法在不进行手动特征工程的情况下，能够识别出各种与物理相关的故障模式，并且在特征相关性和准确性方面优于现有方法。研究还利用发现的视觉模式建立了一个评估生成模型物理合理性的基准，并分析了八个最先进的生成模型，揭示了它们在遵循物理约束方面的不足。

Conclusion: Matryoshka Transcoders框架能够自动发现和解释生成模型中的物理合理性缺陷，并提供了一个评估基准，为改进生成模型提供了有价值的见解。

Abstract: Although recent generative models are remarkably capable of producing instruction-following and realistic outputs, they remain prone to notable physical plausibility failures. Though critical in applications, these physical plausibility errors often escape detection by existing evaluation methods. Furthermore, no framework exists for automatically identifying and interpreting specific physical error patterns in natural language, preventing targeted model improvements. We introduce Matryoshka Transcoders, a novel framework for the automatic discovery and interpretation of physical plausibility features in generative models. Our approach extends the Matryoshka representation learning paradigm to transcoder architectures, enabling hierarchical sparse feature learning at multiple granularity levels. By training on intermediate representations from a physical plausibility classifier and leveraging large multimodal models for interpretation, our method identifies diverse physics-related failure modes without manual feature engineering, achieving superior feature relevance and feature accuracy compared to existing approaches. We utilize the discovered visual patterns to establish a benchmark for evaluating physical plausibility in generative models. Our analysis of eight state-of-the-art generative models provides valuable insights into how these models fail to follow physical constraints, paving the way for further model improvements.

</details>


### [374] [RI-Loss: A Learnable Residual-Informed Loss for Time Series Forecasting](https://arxiv.org/abs/2511.10130)
*Jieting Wang,Xiaolei Shang,Feijiang Li,Furong Peng*

Main category: cs.LG

TL;DR: RI-Loss是一种基于HSIC的新型损失函数，用于时间序列预测，解决了MSE的弱点，并能在理论和实践中提高预测性能。


<details>
  <summary>Details</summary>
Motivation: 现有的时间序列预测模型（如Transformer和MLP）通常使用均方误差（MSE）进行优化，但MSE存在两个主要问题：1. 其逐点误差计算无法捕捉时间依赖性；2. 它没有考虑到数据中固有的噪声。这两种缺点都会影响预测的准确性和鲁棒性。

Method: 提出了一种名为残差感知损失（RI-Loss）的新型损失函数。该损失函数基于希尔伯特-施密特独立性准则（HSIC），通过强制残差序列与随机时间序列之间的依赖性来显式地模拟噪声结构，从而实现更鲁棒、更具噪声感知能力的表征。理论上，通过使用Bernstein型集中不等式和Rademacher复杂度分析，推导出了具有显式双样本复杂性项的首个非渐近HSIC界限，并实现了最优收敛率。

Result: 在八个真实世界基准和五个领先的预测模型上进行的实验表明，RI-Loss在预测性能上有所提高，验证了该方法的有效性。

Conclusion: RI-Loss通过明确考虑噪声和时间依赖性，克服了传统MSE损失函数的局限性，为时间序列预测提供了一种更优的优化方法。该方法在理论上具有严格的收敛保证，在实践中也得到了经验验证。

Abstract: Time series forecasting relies on predicting future values from historical data, yet most state-of-the-art approaches-including transformer and multilayer perceptron-based models-optimize using Mean Squared Error (MSE), which has two fundamental weaknesses: its point-wise error computation fails to capture temporal relationships, and it does not account for inherent noise in the data. To overcome these limitations, we introduce the Residual-Informed Loss (RI-Loss), a novel objective function based on the Hilbert-Schmidt Independence Criterion (HSIC). RI-Loss explicitly models noise structure by enforcing dependence between the residual sequence and a random time series, enabling more robust, noise-aware representations. Theoretically, we derive the first non-asymptotic HSIC bound with explicit double-sample complexity terms, achieving optimal convergence rates through Bernstein-type concentration inequalities and Rademacher complexity analysis. This provides rigorous guarantees for RI-Loss optimization while precisely quantifying kernel space interactions. Empirically, experiments across eight real-world benchmarks and five leading forecasting models demonstrate improvements in predictive performance, validating the effectiveness of our approach. Code will be made publicly available to ensure reproducibility.

</details>


### [375] [EPO: Diverse and Realistic Protein Ensemble Generation via Energy Preference Optimization](https://arxiv.org/abs/2511.10165)
*Yuancheng Sun,Yuxuan Ren,Zhaoming Chen,Xu Han,Kang Liu,Qiwei Ye*

Main category: cs.LG

TL;DR: EPO是一种无需额外MD轨迹即可将预训练蛋白质系综生成器转变为能量感知采样器的在线细化算法。


<details>
  <summary>Details</summary>
Motivation: 准确探索蛋白质构象系综对于揭示功能至关重要，但由于分子动力学（MD）模拟计算成本高且存在能量势垒限制，因此仍然很困难。

Method: EPO利用随机微分方程采样来探索构象景观，并结合基于列表优先优化（list-wise preference optimization）的新颖能量排序机制。EPO引入了一个实际的上限，以有效地近似连续时间生成模型中长采样轨迹的难以处理的概率，使其易于适应现有的预训练生成器。

Result: 在四肽、ATLAS和快速折叠基准测试中，EPO成功生成了多样化且物理上真实的系综，在九个评估指标上确立了新的最先进水平。

Conclusion: 这些结果表明，仅能量的优先信号可以有效地引导生成模型朝着热力学上一致的构象系综发展，为长MD模拟提供了一种替代方案，并拓宽了学习势在结构生物学和药物发现中的适用性。

Abstract: Accurate exploration of protein conformational ensembles is essential for uncovering function but remains hard because molecular-dynamics (MD) simulations suffer from high computational costs and energy-barrier trapping. This paper presents Energy Preference Optimization (EPO), an online refinement algorithm that turns a pretrained protein ensemble generator into an energy-aware sampler without extra MD trajectories. Specifically, EPO leverages stochastic differential equation sampling to explore the conformational landscape and incorporates a novel energy-ranking mechanism based on list-wise preference optimization. Crucially, EPO introduces a practical upper bound to efficiently approximate the intractable probability of long sampling trajectories in continuous-time generative models, making it easily adaptable to existing pretrained generators. On Tetrapeptides, ATLAS, and Fast-Folding benchmarks, EPO successfully generates diverse and physically realistic ensembles, establishing a new state-of-the-art in nine evaluation metrics. These results demonstrate that energy-only preference signals can efficiently steer generative models toward thermodynamically consistent conformational ensembles, providing an alternative to long MD simulations and widening the applicability of learned potentials in structural biology and drug discovery.

</details>


### [376] [Towards Leveraging Sequential Structure in Animal Vocalizations](https://arxiv.org/abs/2511.10190)
*Eklavya Sarkar,Mathew Magimai. -Doss*

Main category: cs.LG

TL;DR: 本研究提出使用離散聲學詞元序列（通過向量量化和 gumbel-softmax 向量量化提取的自監督語音模型表示）來捕捉和利用動物鳴聲中的時間信息，並在四個生物聲學數據集上進行了實驗，結果表明該方法可以區分鳴叫類型和發聲者，並在分類任務中展現出潛力。


<details>
  <summary>Details</summary>
Motivation: 大多數計算生物聲學研究忽略了動物鳴聲中時間順序信息，該研究旨在探索離散聲學詞元序列是否能有效捕捉和利用這些時間信息。

Method: 提取自監督語音模型表示，並通過向量量化和 gumbel-softmax 向量量化生成離散聲學詞元序列。然後，使用成對距離分析和 k-最近鄰與 levenshtein 距離的序列分類實驗來評估這些序列的有效性。

Result: 成對距離分析表明，生成的詞元序列可以區分不同鳴叫類型和發聲者。序列分類實驗表明，向量量化後的詞元序列在鳴叫類型和發聲者分類任務中取得了合理的性能。

Conclusion: 離散聲學詞元序列作為一種替代特徵表示，有潛力利用動物鳴聲中的序列信息。

Abstract: Animal vocalizations contain sequential structures that carry important communicative information, yet most computational bioacoustics studies average the extracted frame-level features across the temporal axis, discarding the order of the sub-units within a vocalization. This paper investigates whether discrete acoustic token sequences, derived through vector quantization and gumbel-softmax vector quantization of extracted self-supervised speech model representations can effectively capture and leverage temporal information. To that end, pairwise distance analysis of token sequences generated from HuBERT embeddings shows that they can discriminate call-types and callers across four bioacoustics datasets. Sequence classification experiments using $k$-Nearest Neighbour with Levenshtein distance show that the vector-quantized token sequences yield reasonable call-type and caller classification performances, and hold promise as alternative feature representations towards leveraging sequential information in animal vocalizations.

</details>


### [377] [Beyond MSE: Ordinal Cross-Entropy for Probabilistic Time Series Forecasting](https://arxiv.org/abs/2511.10200)
*Jieting Wang,Huimei Shi,Feijiang Li,Xiaolei Shang*

Main category: cs.LG

TL;DR: OCE-TS是一种新的时间序列预测方法，使用序数交叉熵（OCE）损失替代均方误差（MSE），提高了预测的稳定性和鲁棒性，并能进行不确定性估计。


<details>
  <summary>Details</summary>
Motivation: 现有的基于深度学习的时间序列预测模型主要使用均方误差（MSE）损失函数，该函数在预测不确定性估计和异常值鲁棒性方面存在不足。因此，需要一种新的方法来解决这些限制。

Method: OCE-TS首先将观测值离散化为有序区间，并通过参数分布推导其概率作为监督信号。然后，使用一个简单的线性模型预测每个时间步的概率分布。OCE损失在预测概率和真实概率的累积分布之间计算，以保留预测值之间的序数关系。

Result: 在七个公共时间序列数据集上的实验表明，OCE-TS在MSE和MAE指标上始终优于Autoformer、DLinear、iTransformer、TimeXer和TimeBridge等基线模型。

Conclusion: OCE-TS通过使用序数交叉熵（OCE）损失，成功解决了传统MSE损失在时间序列预测中的不确定性估计和异常值鲁棒性问题，并在实证研究中表现出优越的性能。

Abstract: Time series forecasting is an important task that involves analyzing temporal dependencies and underlying patterns (such as trends, cyclicality, and seasonality) in historical data to predict future values or trends. Current deep learning-based forecasting models primarily employ Mean Squared Error (MSE) loss functions for regression modeling. Despite enabling direct value prediction, this method offers no uncertainty estimation and exhibits poor outlier robustness. To address these limitations, we propose OCE-TS, a novel ordinal classification approach for time series forecasting that replaces MSE with Ordinal Cross-Entropy (OCE) loss, preserving prediction order while quantifying uncertainty through probability output. Specifically, OCE-TS begins by discretizing observed values into ordered intervals and deriving their probabilities via a parametric distribution as supervision signals. Using a simple linear model, we then predict probability distributions for each timestep. The OCE loss is computed between the cumulative distributions of predicted and ground-truth probabilities, explicitly preserving ordinal relationships among forecasted values. Through theoretical analysis using influence functions, we establish that cross-entropy (CE) loss exhibits superior stability and outlier robustness compared to MSE loss. Empirically, we compared OCE-TS with five baseline models-Autoformer, DLinear, iTransformer, TimeXer, and TimeBridge-on seven public time series datasets. Using MSE and Mean Absolute Error (MAE) as evaluation metrics, the results demonstrate that OCE-TS consistently outperforms benchmark models. The code will be published.

</details>


### [378] [OutSafe-Bench: A Benchmark for Multimodal Offensive Content Detection in Large Language Models](https://arxiv.org/abs/2511.10287)
*Yuping Yan,Yuhan Xie,Yuanshuai Li,Yingchao Yu,Lingjuan Lyu,Yaochu Jin*

Main category: cs.LG

TL;DR: 现有的安全基准测试在模态覆盖和性能评估方面存在局限性，未能全面评估多模态大语言模型（MLLMs）的安全性。本文提出了 OutSafe-Bench，一个包含超过18,000个文本提示、4,500张图像、450个音频片段和450个视频的多模态数据集，涵盖九个风险类别，旨在全面评估MLLMs的安全性。此外，本文还提出了多维度交叉风险评分（MCRS）指标和公平评分（FairScore）框架，以更可靠地评估MLLMs的安全性。评估结果显示，当前最先进的MLLMs仍然存在显著的安全漏洞。


<details>
  <summary>Details</summary>
Motivation: 现有的安全基准测试在模态覆盖和性能评估方面存在局限性，未能全面评估多模态大语言模型（MLLMs）的安全性。

Method: 提出 OutSafe-Bench，一个包含跨四种模态（文本、图像、音频、视频）的大规模数据集，系统地标注了九个关键内容风险类别。引入多维度交叉风险评分（MCRS）指标来评估跨类别风险。提出公平评分（FairScore）框架，一个可解释的自动化多审稿人加权聚合框架，通过选择表现最佳的模型作为自适应陪审团来减轻单模型判断的偏差，提高评估的整体可靠性。

Result: 评估了九个最先进的多模态大语言模型（MLLMs），结果显示它们仍然存在持续且显著的安全漏洞。

Conclusion: 当前的评估结果凸显了在多模态大语言模型（MLLMs）中建立健全安全防护措施的紧迫需求。

Abstract: Since Multimodal Large Language Models (MLLMs) are increasingly being integrated into everyday tools and intelligent agents, growing concerns have arisen regarding their possible output of unsafe contents, ranging from toxic language and biased imagery to privacy violations and harmful misinformation. Current safety benchmarks remain highly limited in both modality coverage and performance evaluations, often neglecting the extensive landscape of content safety. In this work, we introduce OutSafe-Bench, the first most comprehensive content safety evaluation test suite designed for the multimodal era. OutSafe-Bench includes a large-scale dataset that spans four modalities, featuring over 18,000 bilingual (Chinese and English) text prompts, 4,500 images, 450 audio clips and 450 videos, all systematically annotated across nine critical content risk categories. In addition to the dataset, we introduce a Multidimensional Cross Risk Score (MCRS), a novel metric designed to model and assess overlapping and correlated content risks across different categories. To ensure fair and robust evaluation, we propose FairScore, an explainable automated multi-reviewer weighted aggregation framework. FairScore selects top-performing models as adaptive juries, thereby mitigating biases from single-model judgments and enhancing overall evaluation reliability. Our evaluation of nine state-of-the-art MLLMs reveals persistent and substantial safety vulnerabilities, underscoring the pressing need for robust safeguards in MLLMs.

</details>


### [379] [Fractional neural attention for efficient multiscale sequence processing](https://arxiv.org/abs/2511.10208)
*Cheng Kevin Qu,Andrew Ly,Pulin Gong*

Main category: cs.LG

TL;DR: 注意力机制是Transformer模型的核心，但对其原理的理解和扩展仍是AI领域的挑战。本文提出了一种受神经科学启发的框架——分数神经网络注意力（FNA），通过分数拉普拉斯算子控制的Lévy扩散来模拟token交互，实现了多尺度信息处理，并提升了Transformer的基础能力。


<details>
  <summary>Details</summary>
Motivation: 理解和扩展自注意力机制的原理是推动人工智能发展的关键挑战，同时生物注意力机制的多尺度动力学和动力系统理论为新的AI模型提供了灵感。

Method: 提出分数神经网络注意力（FNA）框架，利用分数拉普拉斯算子控制的Lévy扩散模型token交互，实现多尺度信息处理，并结合扩散映射算法进行降维。

Result: FNA理论上具有更大的频谱隙和更短的路径长度，表明其计算效率更高。实验上，FNA在文本分类、图像处理和神经机器翻译任务上均取得了有竞争力的性能，即使在单层单头配置下也表现出色。

Conclusion: FNA是一个连接自注意力、随机动力学和几何的原理性机制，为强大的、受神经科学启发的AI提供了可解释的、生物学基础。

Abstract: Attention mechanisms underpin the computational power of Transformer models, which have achieved remarkable success across diverse domains. Yet understanding and extending the principles underlying self-attention remains a key challenge for advancing artificial intelligence. Drawing inspiration from the multiscale dynamics of biological attention and from dynamical systems theory, we introduce Fractional Neural Attention (FNA), a principled, neuroscience-inspired framework for multiscale information processing. FNA models token interactions through Lévy diffusion governed by the fractional Laplacian, intrinsically realizing simultaneous short- and long-range dependencies across multiple scales. This mechanism yields greater expressivity and faster information mixing, advancing the foundational capacity of Transformers. Theoretically, we show that FNA's dynamics are governed by the fractional diffusion equation, and that the resulting attention networks exhibit larger spectral gaps and shorter path lengths -- mechanistic signatures of enhanced computational efficiency. Empirically, FNA achieves competitive text-classification performance even with a single layer and a single head; it also improves performance in image processing and neural machine translation. Finally, the diffusion map algorithm from geometric harmonics enables dimensionality reduction of FNA weights while preserving the intrinsic structure of embeddings and hidden states. Together, these results establish FNA as a principled mechanism connecting self-attention, stochastic dynamics, and geometry, providing an interpretable, biologically grounded foundation for powerful, neuroscience-inspired AI.

</details>


### [380] [Out-of-Context Misinformation Detection via Variational Domain-Invariant Learning with Test-Time Training](https://arxiv.org/abs/2511.10213)
*Xi Yang,Han Zhang,Zhijian Lin,Yibiao Hu,Hong Han*

Main category: cs.LG

TL;DR: 该研究提出了一种名为VDT的方法，用于解决新闻报道中“脱离上下文的错误信息”（OOC）的检测问题，特别是提高了模型在面对新的新闻领域时的适应能力。


<details>
  <summary>Details</summary>
Motivation: 当前检测OOC错误信息的方法在面对新的新闻领域时表现不佳，因为它们假设训练和测试数据的分布相同，缺乏领域自适应能力。

Method: VDT方法通过学习领域不变特征和采用测试时训练机制来增强领域自适应能力。具体来说，它使用“领域不变变分对齐”模块来学习领域不变特征，并利用“领域一致性约束”模块来重建潜在分布。在测试阶段，通过“测试时训练”策略和“置信度-方差过滤”模块动态更新模型，以适应目标领域。

Result: 在NewsCLIPpings数据集上的广泛实验表明，VDT方法在大多数领域自适应设置下优于现有的最先进方法。

Conclusion: VDT方法通过学习领域不变特征和利用测试时训练机制，能够有效提升OOC错误信息检测的领域自适应能力，并在实验中取得了优于现有方法的性能。

Abstract: Out-of-context misinformation (OOC) is a low-cost form of misinformation in news reports, which refers to place authentic images into out-of-context or fabricated image-text pairings. This problem has attracted significant attention from researchers in recent years. Current methods focus on assessing image-text consistency or generating explanations. However, these approaches assume that the training and test data are drawn from the same distribution. When encountering novel news domains, models tend to perform poorly due to the lack of prior knowledge. To address this challenge, we propose \textbf{VDT} to enhance the domain adaptation capability for OOC misinformation detection by learning domain-invariant features and test-time training mechanisms. Domain-Invariant Variational Align module is employed to jointly encodes source and target domain data to learn a separable distributional space domain-invariant features. For preserving semantic integrity, we utilize domain consistency constraint module to reconstruct the source and target domain latent distribution. During testing phase, we adopt the test-time training strategy and confidence-variance filtering module to dynamically updating the VAE encoder and classifier, facilitating the model's adaptation to the target domain distribution. Extensive experiments conducted on the benchmark dataset NewsCLIPpings demonstrate that our method outperforms state-of-the-art baselines under most domain adaptation settings.

</details>


### [381] [AgentEvolver: Towards Efficient Self-Evolving Agent System](https://arxiv.org/abs/2511.10395)
*Yunpeng Zhai,Shuchang Tao,Cheng Chen,Anni Zou,Ziqian Chen,Qingxu Fu,Shinji Mai,Li Yu,Jiaji Deng,Zouying Cao,Zhaoyang Liu,Bolin Ding,Jingren Zhou*

Main category: cs.LG

TL;DR: AgentEvolver是一个自进化的自主代理系统，利用LLM驱动代理学习，通过自我提问、自我导航和自我归因来提高效率和样本利用率，从而实现可扩展、低成本的持续改进。


<details>
  <summary>Details</summary>
Motivation: 当前自主代理的开发成本高、效率低，需要手动构建任务数据集和大量的随机探索，导致数据构建成本高、探索效率低、样本利用率差。

Method: AgentEvolver引入了三个机制：1.自我提问：通过好奇心驱动在新的环境中生成任务，减少对手动数据集的依赖。2.自我导航：通过经验重用和混合策略指导来提高探索效率。3.自我归因：根据轨迹状态和动作的贡献分配不同的奖励，以提高样本效率。

Result: 初步实验表明，与传统的基于RL的基线相比，AgentEvolver实现了更高效的探索、更好的样本利用率和更快的适应能力。

Conclusion: AgentEvolver通过集成的机制实现了自主代理的可扩展、低成本和持续改进。

Abstract: Autonomous agents powered by large language models (LLMs) have the potential to significantly enhance human productivity by reasoning, using tools, and executing complex tasks in diverse environments. However, current approaches to developing such agents remain costly and inefficient, as they typically require manually constructed task datasets and reinforcement learning (RL) pipelines with extensive random exploration. These limitations lead to prohibitively high data-construction costs, low exploration efficiency, and poor sample utilization. To address these challenges, we present AgentEvolver, a self-evolving agent system that leverages the semantic understanding and reasoning capabilities of LLMs to drive autonomous agent learning. AgentEvolver introduces three synergistic mechanisms: (i) self-questioning, which enables curiosity-driven task generation in novel environments, reducing dependence on handcrafted datasets; (ii) self-navigating, which improves exploration efficiency through experience reuse and hybrid policy guidance; and (iii) self-attributing, which enhances sample efficiency by assigning differentiated rewards to trajectory states and actions based on their contribution. By integrating these mechanisms into a unified framework, AgentEvolver enables scalable, cost-effective, and continual improvement of agent capabilities. Preliminary experiments indicate that AgentEvolver achieves more efficient exploration, better sample utilization, and faster adaptation compared to traditional RL-based baselines.

</details>


### [382] [FedCure: Mitigating Participation Bias in Semi-Asynchronous Federated Learning with Non-IID Data](https://arxiv.org/abs/2511.10227)
*Yue Chen,Jianfeng Lu,Shuqing Cao,Wei Wang,Gang Li,Guanghui Wen*

Main category: cs.LG

TL;DR: FedCure通过联盟构建和感知参与的调度来解决半异步联邦学习中的参与偏差问题，特别是在非IID数据和分层架构下，提高了准确性和效率。


<details>
  <summary>Details</summary>
Motivation: 现有的半异步联邦学习（SAFL）框架在处理参与偏差和非IID数据方面存在不足，尤其是在云-边-客户分层架构中，这被进一步加剧了。

Method: FedCure框架通过三个关键规则来运作：1. 优化联盟形成的偏好规则，以最大化集体利益并建立理论上稳定的分区；2. 集成虚拟队列技术和贝叶斯估计的联盟动态的调度规则；3. 基于估计的联盟动态优化客户端CPU频率的资源分配规则。

Result: FedCure在四个真实世界的数据集上进行了实验，与四个最先进的基线相比，准确性提高了高达5.1倍，每轮延迟的变异系数最低为0.0223，显著提高了效率，并在各种场景中保持了长期平衡。

Conclusion: FedCure通过解决参与偏差和非IID数据问题，在提高SAFL的准确性和效率方面取得了显著成效，尤其是在复杂的分层架构中。

Abstract: While semi-asynchronous federated learning (SAFL) combines the efficiency of synchronous training with the flexibility of asynchronous updates, it inherently suffers from participation bias, which is further exacerbated by non-IID data distributions. More importantly, hierarchical architecture shifts participation from individual clients to client groups, thereby further intensifying this issue. Despite notable advancements in SAFL research, most existing works still focus on conventional cloud-end architectures while largely overlooking the critical impact of non-IID data on scheduling across the cloud-edge-client hierarchy. To tackle these challenges, we propose FedCure, an innovative semi-asynchronous Federated learning framework that leverages coalition construction and participation-aware scheduling to mitigate participation bias with non-IID data. Specifically, FedCure operates through three key rules: (1) a preference rule that optimizes coalition formation by maximizing collective benefits and establishing theoretically stable partitions to reduce non-IID-induced performance degradation; (2) a scheduling rule that integrates the virtual queue technique with Bayesian-estimated coalition dynamics, mitigating efficiency loss while ensuring mean rate stability; and (3) a resource allocation rule that enhances computational efficiency by optimizing client CPU frequencies based on estimated coalition dynamics while satisfying delay requirements. Comprehensive experiments on four real-world datasets demonstrate that FedCure improves accuracy by up to 5.1x compared with four state-of-the-art baselines, while significantly enhancing efficiency with the lowest coefficient of variation 0.0223 for per-round latency and maintaining long-term balance across diverse scenarios.

</details>


### [383] [Lost in Serialization: Invariance and Generalization of LLM Graph Reasoners](https://arxiv.org/abs/2511.10234)
*Daniel Herbst,Lea Karbeska,Divyanshu Kumar,Akanksha Ahuja,Fatemeh Gholamzadeh Nasrabadi,Fabrizio Frasca*

Main category: cs.LG

TL;DR: 基于LLM的图推理器在处理图时缺乏对称性不变性，可能导致在节点重索引、边重排序或格式更改时产生不同输出。本文分析了这些影响，并提出了一种将图序列化分解为节点标签、边编码和语法的原则性方法。结果表明，较大的（未微调的）模型更鲁棒，微调可以降低对节点重标号的敏感性，但可能增加对结构和格式变化的敏感性，并且不能持续提高在未见任务上的性能。


<details>
  <summary>Details</summary>
Motivation: 基于LLM的图推理器在处理图时缺乏对称性不变性，可能导致在节点重索引、边重排序或格式更改时产生不同输出，引起对鲁棒性的担忧。

Method: 系统地分析了这些效应，研究了微调如何影响编码敏感性以及在未见任务上的泛化能力。将图序列化分解为节点标签、边编码和语法，并评估LLM对这些因素变化的鲁棒性。提出了一系列新的谱任务，以进一步评估微调推理器的泛化能力。

Result: 较大的（未微调的）模型更鲁棒。微调降低了对节点重标号的敏感性，但可能增加了对结构和格式变化的敏感性，并且在未见任务上的性能没有得到持续的改善。

Conclusion: LLM在图推理方面存在对称性不变性问题，并且微调策略对鲁棒性和泛化能力的影响复杂，需要进一步研究。

Abstract: While promising, graph reasoners based on Large Language Models (LLMs) lack built-in invariance to symmetries in graph representations. Operating on sequential graph serializations, LLMs can produce different outputs under node reindexing, edge reordering, or formatting changes, raising robustness concerns. We systematically analyze these effects, studying how fine-tuning impacts encoding sensitivity as well generalization on unseen tasks. We propose a principled decomposition of graph serializations into node labeling, edge encoding, and syntax, and evaluate LLM robustness to variations of each of these factors on a comprehensive benchmarking suite. We also contribute a novel set of spectral tasks to further assess generalization abilities of fine-tuned reasoners. Results show that larger (non-fine-tuned) models are more robust. Fine-tuning reduces sensitivity to node relabeling but may increase it to variations in structure and format, while it does not consistently improve performance on unseen tasks.

</details>


### [384] [Impact of Layer Norm on Memorization and Generalization in Transformers](https://arxiv.org/abs/2511.10566)
*Rishi Singhal,Jung-Eun Kim*

Main category: cs.LG

TL;DR: Layer Normalization (LayerNorm) 在 Pre-LayerNorm 和 Post-LayerNorm Transformer 中对学习和记忆的影响不同。


<details>
  <summary>Details</summary>
Motivation: 尽管 Pre-LayerNorm Transformer 因其稳定的梯度流而成为首选，但 LayerNorm 对这两种架构的学习和记忆的影响尚不清楚。

Method: 通过消除 Pre- 和 Post-LayerNorm Transformer 中的 LayerNorm 参数，分析其对学习和记忆的影响，并确定关键层。

Result: 在 Pre-LayerNorm 模型中，消除 LayerNorm 会加剧记忆并破坏学习；在 Post-LayerNorm 模型中，消除 LayerNorm 可以减轻记忆并恢复真实标签。早期层的 LayerNorm 最为关键，其影响在两种模型中有所不同。

Conclusion: LayerNorm 在 Transformer 中对学习和记忆的作用存在差异，尤其是在 Pre- 和 Post-LayerNorm 架构中。

Abstract: Layer Normalization (LayerNorm) is one of the fundamental components in transformers that stabilizes training and improves optimization. In recent times, Pre-LayerNorm transformers have become the preferred choice over Post-LayerNorm transformers due to their stable gradient flow. However, the impact of LayerNorm on learning and memorization across these architectures remains unclear. In this work, we investigate how LayerNorm influences memorization and learning for Pre- and Post-LayerNorm transformers. We identify that LayerNorm serves as a key factor for stable learning in Pre-LayerNorm transformers, while in Post-LayerNorm transformers, it impacts memorization. Our analysis reveals that eliminating LayerNorm parameters in Pre-LayerNorm models exacerbates memorization and destabilizes learning, while in Post-LayerNorm models, it effectively mitigates memorization by restoring genuine labels. We further precisely identify that early layers LayerNorm are the most critical over middle/later layers and their influence varies across Pre and Post LayerNorm models. We have validated it through 13 models across 6 Vision and Language datasets. These insights shed new light on the role of LayerNorm in shaping memorization and learning in transformers.

</details>


### [385] [Heuristic Transformer: Belief Augmented In-Context Reinforcement Learning](https://arxiv.org/abs/2511.10251)
*Oliver Dippel,Alexei Lisitsa,Bei Peng*

Main category: cs.LG

TL;DR: Transformers在强化学习中通过引入奖励的信念分布来增强上下文学习能力，并取得了优于基线方法的性能。


<details>
  <summary>Details</summary>
Motivation: 在强化学习中，利用Transformer的上下文学习能力，在无需参数更新的情况下实现任务适应性。

Method: 提出了一种名为Heuristic Transformer (HT) 的方法，该方法利用变分自编码器（VAE）学习奖励的后验分布的低维随机变量，并将其与上下文数据集和查询状态一起作为Transformer策略的提示。

Result: 在Darkroom、Miniworld和MuJoCo环境中评估了HT的性能，结果表明其在有效性和泛化性方面持续优于可比的基线方法。

Conclusion: HT方法为结合基于信念的增强和基于Transformer的决策提供了一个有前景的方向。

Abstract: Transformers have demonstrated exceptional in-context learning (ICL) capabilities, enabling applications across natural language processing, computer vision, and sequential decision-making. In reinforcement learning, ICL reframes learning as a supervised problem, facilitating task adaptation without parameter updates. Building on prior work leveraging transformers for sequential decision-making, we propose Heuristic Transformer (HT), an in-context reinforcement learning (ICRL) approach that augments the in-context dataset with a belief distribution over rewards to achieve better decision-making. Using a variational auto-encoder (VAE), a low-dimensional stochastic variable is learned to represent the posterior distribution over rewards, which is incorporated alongside an in-context dataset and query states as prompt to the transformer policy. We assess the performance of HT across the Darkroom, Miniworld, and MuJoCo environments, showing that it consistently surpasses comparable baselines in terms of both effectiveness and generalization. Our method presents a promising direction to bridge the gap between belief-based augmentations and transformer-based decision-making.

</details>


### [386] [Unitho: A Unified Multi-Task Framework for Computational Lithography](https://arxiv.org/abs/2511.10255)
*Qian Jin,Yumeng Liu,Yuqi Jiang,Qi Sun,Cheng Zhuo*

Main category: cs.LG

TL;DR: Unitho是一个统一的多任务大型视觉模型，用于计算光刻中的掩模生成、光刻模拟和规则冲突检测，并在大规模工业数据集上进行了训练，性能优于学术基线。


<details>
  <summary>Details</summary>
Motivation: 计算光刻中可靠、可扩展的数据基础对于大规模模型至关重要，但掩模生成、规则冲突检测和布局优化等任务常常孤立处理，并且受限于稀疏的数据集和有限的模型方法。

Method: 提出了一种基于Transformer架构的统一多任务大型视觉模型Unitho，并在包含数十万个案例的大规模工业光刻模拟数据集上进行训练。

Result: Unitho支持端到端的掩模生成、光刻模拟和规则冲突检测，并且能够实现敏捷和高保真的光刻模拟，从而为智能EDA构建稳健的数据基础。实验结果验证了其有效性和通用性，性能显著超越了学术基线。

Conclusion: Unitho在计算光刻领域提供了一个统一的解决方案，通过在大规模数据集上进行训练，有效解决了传统方法在掩模生成、规则冲突检测和布局优化方面的局限性，并展现出优越的性能和泛化能力。

Abstract: Reliable, generalizable data foundations are critical for enabling large-scale models in computational lithography. However, essential tasks-mask generation, rule violation detection, and layout optimization-are often handled in isolation, hindered by scarce datasets and limited modeling approaches. To address these challenges, we introduce Unitho, a unified multi-task large vision model built upon the Transformer architecture. Trained on a large-scale industrial lithography simulation dataset with hundreds of thousands of cases, Unitho supports end-to-end mask generation, lithography simulation, and rule violation detection. By enabling agile and high-fidelity lithography simulation, Unitho further facilitates the construction of robust data foundations for intelligent EDA. Experimental results validate its effectiveness and generalizability, with performance substantially surpassing academic baselines.

</details>


### [387] [Torch-Uncertainty: A Deep Learning Framework for Uncertainty Quantification](https://arxiv.org/abs/2511.10282)
*Adrien Lafage,Olivier Laurent,Firas Gabetni,Gianni Franchi*

Main category: cs.LG

TL;DR: Torch-Uncertainty是一个基于PyTorch和Lightning的框架，用于简化深度学习中的不确定性量化（UQ）。


<details>
  <summary>Details</summary>
Motivation: 现有的深度学习模型在不确定性量化方面存在不足，限制了其在关键实际应用中的使用。虽然已有多种UQ技术，但缺乏统一的工具来评估和整合这些方法。

Method: 介绍了一个名为Torch-Uncertainty的PyTorch和Lightning库，该库旨在简化包含UQ技术和指标的深度学习模型的训练和评估。

Result: 对多种UQ方法在分类、分割和回归任务上的表现进行了全面实验评估和基准测试。

Conclusion: Torch-Uncertainty为深度学习中的不确定性量化提供了一个统一的解决方案，并已在GitHub上开源。

Abstract: Deep Neural Networks (DNNs) have demonstrated remarkable performance across various domains, including computer vision and natural language processing. However, they often struggle to accurately quantify the uncertainty of their predictions, limiting their broader adoption in critical real-world applications. Uncertainty Quantification (UQ) for Deep Learning seeks to address this challenge by providing methods to improve the reliability of uncertainty estimates. Although numerous techniques have been proposed, a unified tool offering a seamless workflow to evaluate and integrate these methods remains lacking. To bridge this gap, we introduce Torch-Uncertainty, a PyTorch and Lightning-based framework designed to streamline DNN training and evaluation with UQ techniques and metrics. In this paper, we outline the foundational principles of our library and present comprehensive experimental results that benchmark a diverse set of UQ methods across classification, segmentation, and regression tasks. Our library is available at https://github.com/ENSTA-U2IS-AI/Torch-Uncertainty

</details>


### [388] [PITE: Multi-Prototype Alignment for Individual Treatment Effect Estimation](https://arxiv.org/abs/2511.10320)
*Fuyuan Cao,Jiaxuan Zhang,Xiaoli Li*

Main category: cs.LG

TL;DR: PITE方法通过多原型对齐来估计个体处理效应（ITE），解决了混淆偏差和忽略局部结构的问题，并在基准数据集上取得了优于现有方法的准确性和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有的ITE估计方法在处理混淆偏差时，通常采用全局分布均衡，忽略了个体异质性和局部结构信息，影响了ITE估计的准确性。现有的实例级对齐方法虽然考虑了异质性，但也忽略了局部结构信息。

Method: 提出了一种端到端的、基于多原型的对齐方法（PITE），通过定义原型（相似个体在同一处理下的聚类中心），进行实例到原型的匹配，并设计了多原型对齐策略，促使匹配的原型在潜在空间中靠近，从而实现细粒度的、原型级别的对齐，减少分布偏移，并保留处理组和对照组的局部结构。

Result: PITE方法通过细粒度的原型级别对齐，有效减少了分布偏移，并保留了处理组和对照组的局部结构，为ITE估计提供了有意义的约束。

Conclusion: PITE方法能够有效捕捉分组内的局部结构并强制执行跨组对齐，从而实现稳健的ITE估计。在基准数据集上的广泛评估表明，PITE在ITE估计的准确性和鲁棒性方面优于13种最先进的方法。

Abstract: Estimating Individual Treatment Effects (ITE) from observational data is challenging due to confounding bias. Most studies tackle this bias by balancing distributions globally, but ignore individual heterogeneity and fail to capture the local structure that represents the natural clustering among individuals, which ultimately compromises ITE estimation. While instance-level alignment methods consider heterogeneity, they similarly overlook the local structure information. To address these issues, we propose an end-to-end Multi-\textbf{P}rototype alignment method for \textbf{ITE} estimation (\textbf{PITE}). PITE effectively captures local structure within groups and enforces cross-group alignment, thereby achieving robust ITE estimation. Specifically, we first define prototypes as cluster centroids based on similar individuals under the same treatment. To identify local similarity and the distribution consistency, we perform instance-to-prototype matching to assign individuals to the nearest prototype within groups, and design a multi-prototype alignment strategy to encourage the matched prototypes to be close across treatment arms in the latent space. PITE not only reduces distribution shift through fine-grained, prototype-level alignment, but also preserves the local structures of treated and control groups, which provides meaningful constraints for ITE estimation. Extensive evaluations on benchmark datasets demonstrate that PITE outperforms 13 state-of-the-art methods, achieving more accurate and robust ITE estimation.

</details>


### [389] [EDGC: Entropy-driven Dynamic Gradient Compression for Efficient LLM Training](https://arxiv.org/abs/2511.10333)
*Qingao Yi,Jiaang Duan,Hanwen Hu,Qin Hua,Haiyan Zhao,Shiyou Qian,Dingyu Yang,Jian Cao,Jinghua Tang,Yinghao Yu,Chenzhi Liao,Kangjin Wang,Liping Zhang*

Main category: cs.LG

TL;DR: EDGC是一个熵驱动的动态梯度压缩框架，通过动态调整压缩率来提高LLM训练的通信效率和速度，同时保持模型精度。


<details>
  <summary>Details</summary>
Motivation: 现有的静态梯度压缩方法无法处理训练过程中梯度动态变化的问题，导致性能下降，因此需要一种能够适应梯度动态性的压缩方法。

Method: EDGC框架包括三个组件：1. 使用下采样方法估计梯度熵以降低计算开销；2. 建立压缩率与梯度熵之间的理论模型以辅助决策；3. 采用基于窗口的调整机制动态地跨流水线阶段调整压缩率。

Result: 在32个NVIDIA-V100和64个NVIDIA-H100集群上训练GPT2模型的结果表明，EDGC可将通信延迟和训练时间分别减少高达46.45%和16.13%，同时保持LLM精度。

Conclusion: EDGC通过熵驱动的动态梯度压缩，在不牺牲LLM精度的情况下，显著提高了通信效率和训练速度，解决了现有静态压缩方法的局限性。

Abstract: Training large language models (LLMs) poses significant challenges regarding computational resources and memory capacity. Although distributed training techniques help mitigate these issues, they still suffer from considerable communication overhead. Existing approaches primarily rely on static gradient compression to enhance communication efficiency; however, these methods neglect the dynamic nature of evolving gradients during training, leading to performance degradation. Accelerating LLM training via compression without sacrificing performance remains a challenge. In this paper, we propose an entropy-driven dynamic gradient compression framework called EDGC. The core concept is to adjust the compression rate during LLM training based on the evolving trends of gradient entropy, taking into account both compression efficiency and error. EDGC consists of three key components.First, it employs a down-sampling method to efficiently estimate gradient entropy, reducing computation overhead. Second, it establishes a theoretical model linking compression rate with gradient entropy, enabling more informed compression decisions. Lastly, a window-based adjustment mechanism dynamically adapts the compression rate across pipeline stages, improving communication efficiency and maintaining model performance. We implemented EDGC on a 32-NVIDIA-V100 cluster and a 64-NVIDIA-H100 cluster to train GPT2-2.5B and GPT2-12.1B, respectively. The results show that EDGC significantly reduces communication latency and training time by up to 46.45% and 16.13% while preserving LLM accuracy.

</details>


### [390] [Robust Decentralized Multi-armed Bandits: From Corruption-Resilience to Byzantine-Resilience](https://arxiv.org/abs/2511.10344)
*Zicheng Hu,Yuchen Wang,Cheng Chen*

Main category: cs.LG

TL;DR: 该研究提出了一种名为DeMABAR的去中心化多智能体多头老虎机算法，该算法能有效抵抗奖励污染和拜占庭攻击，同时保证了智能体的个体遗憾仅受污染预算的线性影响。


<details>
  <summary>Details</summary>
Motivation: 现有去中心化多智能体多头老虎机算法易受对抗性攻击，鲁棒性不足。

Method: 提出DeMABAR算法，理论分析其在奖励污染和拜占庭攻击下的遗憾界，并通过数值实验验证其有效性。

Result: DeMABAR算法保证了智能体的个体遗憾仅增加与污染预算成正比的项，并且在拜占庭设置下几乎完全消除了对抗性攻击的影响。

Conclusion: DeMABAR算法在去中心化多智能体多头老虎机场景下具有良好的鲁棒性，能够有效抵抗多种对抗性攻击。

Abstract: Decentralized cooperative multi-agent multi-armed bandits (DeCMA2B) considers how multiple agents collaborate in a decentralized multi-armed bandit setting. Though this problem has been extensively studied in previous work, most existing methods remain susceptible to various adversarial attacks. In this paper, we first study DeCMA2B with adversarial corruption, where an adversary can corrupt reward observations of all agents with a limited corruption budget. We propose a robust algorithm, called DeMABAR, which ensures that each agent's individual regret suffers only an additive term proportional to the corruption budget. Then we consider a more realistic scenario where the adversary can only attack a small number of agents. Our theoretical analysis shows that the DeMABAR algorithm can also almost completely eliminate the influence of adversarial attacks and is inherently robust in the Byzantine setting, where an unknown fraction of the agents can be Byzantine, i.e., may arbitrarily select arms and communicate wrong information. We also conduct numerical experiments to illustrate the robustness and effectiveness of the proposed method.

</details>


### [391] [Product distribution learning with imperfect advice](https://arxiv.org/abs/2511.10366)
*Arnab Bhattacharyya,Davin Choo,Philips George John,Themis Gouleakis*

Main category: cs.LG

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Given i.i.d.~samples from an unknown distribution $P$, the goal of distribution learning is to recover the parameters of a distribution that is close to $P$. When $P$ belongs to the class of product distributions on the Boolean hypercube $\{0,1\}^d$, it is known that $Ω(d/\varepsilon^2)$ samples are necessary to learn $P$ within total variation (TV) distance $\varepsilon$. We revisit this problem when the learner is also given as advice the parameters of a product distribution $Q$. We show that there is an efficient algorithm to learn $P$ within TV distance $\varepsilon$ that has sample complexity $\tilde{O}(d^{1-η}/\varepsilon^2)$, if $\|\mathbf{p} - \mathbf{q}\|_1 < \varepsilon d^{0.5 - Ω(η)}$. Here, $\mathbf{p}$ and $\mathbf{q}$ are the mean vectors of $P$ and $Q$ respectively, and no bound on $\|\mathbf{p} - \mathbf{q}\|_1$ is known to the algorithm a priori.

</details>


### [392] [Enhancing Kernel Power K-means: Scalable and Robust Clustering with Random Fourier Features and Possibilistic Method](https://arxiv.org/abs/2511.10392)
*Yixi Chen,Weixuan Liang,Tianrui Liu,Jun-Jie Huang,Ao Li,Xueling Zhu,Xinwang Liu*

Main category: cs.LG

TL;DR: RFF-KPKM通过使用随机傅里叶特征（RFF）来解决KPKM的计算成本和噪声鲁棒性问题，并提供了理论保证。IP-RFF-MKPKM进一步改进了RFF-KPKM，通过结合可能性和模糊成员资格来提高聚类分配的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: KPKM在解决核k-均值中的局部最小值问题方面取得了进展，但面临计算成本高和缺乏真实的质心-样本分配学习的挑战。

Method: RFF-KPKM利用随机傅里叶特征（RFF）来创建高效的低维特征映射，从而避免了对整个核矩阵的需求。IP-RFF-MKPKM进一步通过结合可能性成员资格和模糊成员资格来改进聚类分配。

Result: 实验表明，所提出的方法在效率和聚类准确性方面优于最先进的替代方法。

Conclusion: RFF-KPKM和IP-RFF-MKPKM在处理大规模数据集方面显示出优越的性能和效率，克服了现有方法的局限性。

Abstract: Kernel power $k$-means (KPKM) leverages a family of means to mitigate local minima issues in kernel $k$-means. However, KPKM faces two key limitations: (1) the computational burden of the full kernel matrix restricts its use on extensive data, and (2) the lack of authentic centroid-sample assignment learning reduces its noise robustness. To overcome these challenges, we propose RFF-KPKM, introducing the first approximation theory for applying random Fourier features (RFF) to KPKM. RFF-KPKM employs RFF to generate efficient, low-dimensional feature maps, bypassing the need for the whole kernel matrix. Crucially, we are the first to establish strong theoretical guarantees for this combination: (1) an excess risk bound of $\mathcal{O}(\sqrt{k^3/n})$, (2) strong consistency with membership values, and (3) a $(1+\varepsilon)$ relative error bound achievable using the RFF of dimension $\mathrm{poly}(\varepsilon^{-1}\log k)$. Furthermore, to improve robustness and the ability to learn multiple kernels, we propose IP-RFF-MKPKM, an improved possibilistic RFF-based multiple kernel power $k$-means. IP-RFF-MKPKM ensures the scalability of MKPKM via RFF and refines cluster assignments by combining the merits of the possibilistic membership and fuzzy membership. Experiments on large-scale datasets demonstrate the superior efficiency and clustering accuracy of the proposed methods compared to the state-of-the-art alternatives.

</details>


### [393] [Neuronal Fluctuations: Learning Rates vs Participating Neurons](https://arxiv.org/abs/2511.10435)
*Darsh Pareek,Umesh Kumar,Ruthu Rao,Ravi Janjam*

Main category: cs.LG

TL;DR: 学习率影响深度神经网络中参数波动，进而影响模型性能。


<details>
  <summary>Details</summary>
Motivation: 现有研究对学习率与神经网络内部参数波动之间的关系探究不足。

Method: 通过改变学习率训练模型，并分析参数波动与网络准确率的关系。

Result: 系统地研究了不同学习率对网络参数波动幅度和特性的影响，并分析了波动模式与模型准确率的关系。

Conclusion: 学习率的设定对参数波动模式有显著影响，进而影响模型的最终准确率。

Abstract: Deep Neural Networks (DNNs) rely on inherent fluctuations in their internal parameters (weights and biases) to effectively navigate the complex optimization landscape and achieve robust performance. While these fluctuations are recognized as crucial for escaping local minima and improving generalization, their precise relationship with fundamental hyperparameters remains underexplored. A significant knowledge gap exists concerning how the learning rate, a critical parameter governing the training process, directly influences the dynamics of these neural fluctuations. This study systematically investigates the impact of varying learning rates on the magnitude and character of weight and bias fluctuations within a neural network. We trained a model using distinct learning rates and analyzed the corresponding parameter fluctuations in conjunction with the network's final accuracy. Our findings aim to establish a clear link between the learning rate's value, the resulting fluctuation patterns, and overall model performance. By doing so, we provide deeper insights into the optimization process, shedding light on how the learning rate mediates the crucial exploration-exploitation trade-off during training. This work contributes to a more nuanced understanding of hyperparameter tuning and the underlying mechanics of deep learning.

</details>


### [394] [Improving Perturbation-based Explanations by Understanding the Role of Uncertainty Calibration](https://arxiv.org/abs/2511.10439)
*Thomas Decker,Volker Tresp,Florian Buettner*

Main category: cs.LG

TL;DR: 模型在经过特定扰动时会产生不可靠的概率估计，这会影响解释的质量。ReCalX可以通过重新校准模型来提高解释的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 已有的基于扰动的解释方法在实际应用中并不可靠，因为模型在扰动下的行为是未知的。本文研究了不确定性校准与基于扰动的解释之间的关系。

Method: 提出了一种名为ReCalX的新方法，用于重新校准模型以改进解释，同时保持其原始预测。

Result: ReCalX在不同的模型和数据集上进行了实证评估，结果表明ReCalX能够有效减少特定扰动下的失准现象，并提高解释的鲁棒性以及全局重要特征的识别能力。

Conclusion: 模型在特定扰动下会产生不可靠的概率估计，从而影响解释的质量。ReCalX通过重新校准模型，可以有效解决这个问题，提高模型的可解释性。

Abstract: Perturbation-based explanations are widely utilized to enhance the transparency of machine-learning models in practice. However, their reliability is often compromised by the unknown model behavior under the specific perturbations used. This paper investigates the relationship between uncertainty calibration - the alignment of model confidence with actual accuracy - and perturbation-based explanations. We show that models systematically produce unreliable probability estimates when subjected to explainability-specific perturbations and theoretically prove that this directly undermines global and local explanation quality. To address this, we introduce ReCalX, a novel approach to recalibrate models for improved explanations while preserving their original predictions. Empirical evaluations across diverse models and datasets demonstrate that ReCalX consistently reduces perturbation-specific miscalibration most effectively while enhancing explanation robustness and the identification of globally important input features.

</details>


### [395] [Intrinsic Dimensionality as a Model-Free Measure of Class Imbalance](https://arxiv.org/abs/2511.10475)
*Çağrı Eser,Zeynep Sonat Baltacı,Emre Akbaş,Sinan Kalkan*

Main category: cs.LG

TL;DR: 数据内在维度（ID）是一种易于计算、与模型无关的类别不平衡度量方法，优于传统的基于数量的方法，并可与数量相结合以进一步提高性能。


<details>
  <summary>Details</summary>
Motivation: 传统的类别不平衡度量方法（如样本数量）未能考虑数据冗余和学习难度差异。现有的更复杂的度量方法（如训练损失和不确定性）需要训练机器学习模型。本研究旨在提出一种新的、更有效的度量方法。

Method: 提出使用数据内在维度（ID）作为一种易于计算、与模型无关的度量方法来量化类别不平衡。将ID纳入重加权和重采样等不平衡处理方法中。

Result: 在五个不同数据集上进行实验，结果表明ID在性能上始终优于基于数量的重加权和重采样技术。此外，ID与数量结合使用可进一步提升性能。

Conclusion: 数据内在维度（ID）是一种有效的、模型无关的类别不平衡度量方法，在各种不平衡学习场景中优于传统方法，并且可以与现有方法结合以获得更好的结果。

Abstract: Imbalance in classification tasks is commonly quantified by the cardinalities of examples across classes. This, however, disregards the presence of redundant examples and inherent differences in the learning difficulties of classes. Alternatively, one can use complex measures such as training loss and uncertainty, which, however, depend on training a machine learning model. Our paper proposes using data Intrinsic Dimensionality (ID) as an easy-to-compute, model-free measure of imbalance that can be seamlessly incorporated into various imbalance mitigation methods. Our results across five different datasets with a diverse range of imbalance ratios show that ID consistently outperforms cardinality-based re-weighting and re-sampling techniques used in the literature. Moreover, we show that combining ID with cardinality can further improve performance. Code: https://github.com/cagries/IDIM.

</details>


### [396] [Panda: Test-Time Adaptation with Negative Data Augmentation](https://arxiv.org/abs/2511.10481)
*Ruxi Deng,Wenxuan Bao,Tianxin Wei,Jingrui He*

Main category: cs.LG

TL;DR: Panda是一种基于负数据增强（NDA）的测试时自适应（TTA）方法，通过破坏语义内容来生成增强样本，以减少模型在图像损坏下的预测偏差和计算开销，从而提高鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有的基于正数据增强（PDA）的TTA方法在图像损坏下预测能力会显著下降，并且存在计算开销大和预测偏差的问题。Panda旨在解决这些限制。

Method: Panda通过破坏语义内容生成负增强样本，保留损坏特有特征但去除物体相关信号。然后，通过从原始图像特征中减去这些负样本的平均特征，来抑制与损坏相关的分量，同时保留与类别相关的信。此方法通过在批次内共享增强样本来最小化计算开销。

Result: Panda在实验中表现优于PDA方法，并且显著提升了多种TTA方法的鲁棒性。

Conclusion: Panda是一种有效且计算效率高的TTA方法，能够显著提高模型在图像损坏下的鲁棒性，并减少预测偏差。

Abstract: Pretrained VLMs exhibit strong zero-shot classification capabilities, but their predictions degrade significantly under common image corruptions. To improve robustness, many test-time adaptation (TTA) methods adopt positive data augmentation (PDA), which generates multiple views of each test sample to reduce prediction variance. However, these methods suffer from two key limitations. First, it introduces considerable computational overhead due to the large number of augmentations required per image. Second, it fails to mitigate prediction bias, where the model tends to predict certain classes disproportionately under corruption, as PDA operates on corrupted inputs and typically does not remove the corruption itself. To address these challenges, we propose Panda, a novel TTA method based on negative data augmentation (NDA). Unlike positive augmentations that preserve object semantics, Panda generates negative augmentations by disrupting semantic content. It divides images into patches and randomly assembles them from a shared patch pool. These negatively augmented images retain corruption-specific features while discarding object-relevant signals. We then subtract the mean feature of these negative samples from the original image feature, effectively suppressing corruption-related components while preserving class-relevant information. This mitigates prediction bias under distribution shifts. Panda allows augmentation to be shared across samples within a batch, resulting in minimal computational overhead. Panda can be seamlessly integrated into existing test-time adaptation frameworks and substantially improve their robustness. Our experiments indicate that Panda delivers superior performance compared to PDA methods, and a wide range of TTA methods exhibit significantly enhanced performance when integrated with Panda. Our code is available at https://github.com/ruxideng/Panda .

</details>


### [397] [Weak Relation Enforcement for Kinematic-Informed Long-Term Stock Prediction with Artificial Neural Networks](https://arxiv.org/abs/2511.10494)
*Stanislav Selitskiy*

Main category: cs.LG

TL;DR: 通过引入新的损失函数来改进神经网络在股票预测中的表现，以解决数据波动性和异常值问题。


<details>
  <summary>Details</summary>
Motivation: 为了解决时间序列数据（特别是股票价格）的波动性、训练数据中的异常值以及模型在新的、未见过的数据上的表现不佳（Out-of-Distribution）等问题，我们提出了一种新的方法。

Method: 我们提出了一种名为 KINN（Kinematic-Informed Neural Networks）的神经网络结构，并设计了一种新的损失函数。该损失函数不仅惩罚预测值与真实值之间的误差，还通过学习预测点与前一点之间的速度关系来惩罚误差。这种方法可以避免不切实际的预测。

Result: 在对道琼斯指数长达十五年的数据进行测试后，KINN 模型在多种常用的自回归（AR）神经网络架构和激活函数上都表现出了统计学上的显著改进，尤其是在处理容易在 OOD 数据条件下出现伪影（spurious behaviour）的激活函数时。结果表明，该方法能够解决自回归模型中因打破数据拓扑结构而导致的归一化问题，通过在神经网络转换过程中弱化对数据邻域邻近性（关系）的保持。

Conclusion: KINN 及其提出的损失函数能够有效地解决股票预测中的数据波动性、异常值和 OOD 问题，并在实际数据上取得了显著的性能提升。

Abstract: We propose loss function week enforcement of the velocity relations between time-series points in the Kinematic-Informed artificial Neural Networks (KINN) for long-term stock prediction. Problems of the series volatility, Out-of-Distribution (OOD) test data, and outliers in training data are addressed by (Artificial Neural Networks) ANN's learning not only future points prediction but also by learning velocity relations between the points, such a way as avoiding unrealistic spurious predictions. The presented loss function penalizes not only errors between predictions and supervised label data, but also errors between the next point prediction and the previous point plus velocity prediction. The loss function is tested on the multiple popular and exotic AR ANN architectures, and around fifteen years of Dow Jones function demonstrated statistically meaningful improvement across the normalization-sensitive activation functions prone to spurious behaviour in the OOD data conditions. Results show that such architecture addresses the issue of the normalization in the auto-regressive models that break the data topology by weakly enforcing the data neighbourhood proximity (relation) preservation during the ANN transformation.

</details>


### [398] [Holonorm](https://arxiv.org/abs/2511.10504)
*Daryl Noupa Yongueng,Hamidou Tembine*

Main category: cs.LG

TL;DR: DyT中的Tanh不能用于归一化，因为它存在正交性、线性和失真问题。Holonorm是一种包含残差连接和非线性的归一化方法，可以解决Tanh的问题，并能防止激活值爆炸，提高深度Transformer模型的稳定性。


<details>
  <summary>Details</summary>
Motivation: Tanh作为Transformer训练中的归一化层存在正交性、线性和失真问题，需要一种更可靠的替代方案。

Method: 提出了一种名为Holonorm（hn）的新型归一化方法，该方法具有残差连接和非线性，能够保持信号的正交性、方向性和可逆性，并将所有向量映射到单位球内，以防止激活值爆炸并提高稳定性。

Result: Holonorm在Transformer模型中作为一种新的归一化函数，相比于Tanh和逐元素的softsign函数，能更好地处理高维张量和向量，并提高模型的稳定性和可理解性。

Conclusion: Holonorm是一种广义的softsign函数，适用于作为Transformer模型中的归一化函数，它解决了Tanh的缺点，并且其输出在0到1之间，便于理解和评估模型性能。

Abstract: Normalization is a key point in transformer training . In Dynamic Tanh (DyT), the author demonstrated that Tanh can be used as an alternative layer normalization (LN) and confirmed the effectiveness of the idea. But Tanh itself faces orthogonality, linearity and distortion problems. Due to that, his proposition cannot be reliable. So we propose a Holonorm (hn) which has residual connections and nonlinearity. Holonorm is suitable for replacing Tanh in the context of normalization. Although the HoloNorm expression could be similar to the softsign function in dimension one, softsign is a componentwise function which is not good for tensors and vectors of great dimension. Holonorm preserves the orthogonality, the direction, the invertibility of the signal. Holonorm is also a suitable metric, maps all vectors into the open unit ball. This prevents exploding activations and improves stability in deep Transformer models. In this work, we have meticulously examined the normalization in transformers and say that Holonorm, a generalized form of softsign function suited as a normalization function first.Second, defined between 0 and 1 hn serves as a percentage, and $1 - \text{Holonorm}$ is its complement, making it better understandable in evaluating a model.

</details>


### [399] [Oya: Deep Learning for Accurate Global Precipitation Estimation](https://arxiv.org/abs/2511.10562)
*Emmanuel Asiedu Brempong,Mohammed Alewi Hassen,MohamedElfatih MohamedKhair,Vusumuzi Dube,Santiago Hincapie Potes,Olivia Graham,Amanie Brik,Amy McGovern,George Huffman,Jason Hickey*

Main category: cs.LG

TL;DR: Oya是一个利用可见光和红外（VIS-IR）卫星观测进行实时降水估算的新算法，通过双阶段深度学习方法提高精度，并实现了准全球覆盖，性能优于现有算法。


<details>
  <summary>Details</summary>
Motivation: 全球南部地区降水估算需求迫切，但地面观测网络稀疏且预测能力有限，现有卫星产品存在误差。

Method: 采用包含降水检测和定量降水估算（QPE）的双阶段U-Net深度学习模型，并使用GPM CORRA v07数据和IMERG-Final数据进行训练。

Result: Oya算法在准全球范围内实现了比现有算法更优越的降水估算性能。

Conclusion: Oya算法为改进降水监测和预测提供了一种有前景的方法。

Abstract: Accurate precipitation estimation is critical for hydrological applications, especially in the Global South where ground-based observation networks are sparse and forecasting skill is limited. Existing satellite-based precipitation products often rely on the longwave infrared channel alone or are calibrated with data that can introduce significant errors, particularly at sub-daily timescales. This study introduces Oya, a novel real-time precipitation retrieval algorithm utilizing the full spectrum of visible and infrared (VIS-IR) observations from geostationary (GEO) satellites. Oya employs a two-stage deep learning approach, combining two U-Net models: one for precipitation detection and another for quantitative precipitation estimation (QPE), to address the inherent data imbalance between rain and no-rain events. The models are trained using high-resolution GPM Combined Radar-Radiometer Algorithm (CORRA) v07 data as ground truth and pre-trained on IMERG-Final retrievals to enhance robustness and mitigate overfitting due to the limited temporal sampling of CORRA. By leveraging multiple GEO satellites, Oya achieves quasi-global coverage and demonstrates superior performance compared to existing competitive regional and global precipitation baselines, offering a promising pathway to improved precipitation monitoring and forecasting.

</details>


### [400] [Semi-Unified Sparse Dictionary Learning with Learnable Top-K LISTA and FISTA Encoders](https://arxiv.org/abs/2511.10575)
*Fengsheng Lin,Shengyi Yan,Trac Duy Tran*

Main category: cs.LG

TL;DR: 提出了一种半统一的稀疏字典学习框架，将经典稀疏模型与深度学习架构结合起来，通过集成LISTA和LISTAConv到LC-KSVD2模型中，实现了稀疏编码器和字典的协同演化，并提供了理论收敛性分析。


<details>
  <summary>Details</summary>
Motivation: 弥合经典稀疏模型与现代深度学习架构之间的差距，同时保留稀疏编码的可解释性并实现高效可微的训练。

Method: 将严格的Top-K LISTA及其凸FISTA变体（LISTAConv）集成到判别式LC-KSVD2模型中，实现稀疏编码器和字典在监督或无监督情况下的协同演化，并对凸变体进行了PALM风格的收敛性分析。

Result: 在CIFAR-10上达到95.6%，CIFAR-100上达到86.3%，TinyImageNet上达到88.5%，同时实现了更快的收敛速度和更低的内存消耗（<4GB GPU）。

Conclusion: 提出的LC-KSVD2 + LISTA/LISTAConv流程为现代深度学习架构提供了一种可解释且计算高效的替代方案。

Abstract: We present a semi-unified sparse dictionary learning framework that bridges the gap between classical sparse models and modern deep architectures. Specifically, the method integrates strict Top-$K$ LISTA and its convex FISTA-based variant (LISTAConv) into the discriminative LC-KSVD2 model, enabling co-evolution between the sparse encoder and the dictionary under supervised or unsupervised regimes. This unified design retains the interpretability of traditional sparse coding while benefiting from efficient, differentiable training.
  We further establish a PALM-style convergence analysis for the convex variant, ensuring theoretical stability under block alternation. Experimentally, our method achieves 95.6\% on CIFAR-10, 86.3\% on CIFAR-100, and 88.5\% on TinyImageNet with faster convergence and lower memory cost ($<$4GB GPU). The results confirm that the proposed LC-KSVD2 + LISTA/LISTAConv pipeline offers an interpretable and computationally efficient alternative for modern deep architectures.

</details>


### [401] [Tight Robustness Certification through the Convex Hull of $\ell_0$ Attacks](https://arxiv.org/abs/2511.10576)
*Yuval Shapira,Dana Drachsler-Cohen*

Main category: cs.LG

TL;DR: Few-pixel attacks use $\ell_0$-balls, which are non-convex. Existing verifiers struggle with this. This paper proposes a method using the convex hull of an $\ell_0$-ball, which is the intersection of its bounding box and an $\ell_1$-like polytope. This method provides tighter bounds and scales existing $\ell_0$ verifiers.


<details>
  <summary>Details</summary>
Motivation: Existing local robustness verifiers rely on linear bound propagation, which works well for convex perturbation spaces like $\ell_p$-balls (p>=1), but struggles with the non-convex $\ell_0$-ball used in few-pixel attacks.

Method: The paper shows that the convex hull of an $\ell_0$-ball can be represented as the intersection of its bounding box and an asymmetrically scaled $\ell_1$-like polytope. They then develop a linear bound propagation technique that precisely computes bounds over this convex hull, offering tighter bounds than those obtained from the bounding box or the $\ell_1$-like polytope alone.

Result: The proposed bound propagation method significantly improves the scalability of the state-of-the-art $\ell_0$ verifier on challenging robustness benchmarks, showing speedups of 1.24x-7.07x, with a geometric mean of 3.16.

Conclusion: The paper introduces a novel approach to handle non-convex $\ell_0$-balls in robustness verification by leveraging their convex hull. This method improves the tightness of bounds and enhances the scalability of existing verifiers, addressing a key limitation in the field of adversarial attacks.

Abstract: Few-pixel attacks mislead a classifier by modifying a few pixels of an image. Their perturbation space is an $\ell_0$-ball, which is not convex, unlike $\ell_p$-balls for $p\geq1$. However, existing local robustness verifiers typically scale by relying on linear bound propagation, which captures convex perturbation spaces. We show that the convex hull of an $\ell_0$-ball is the intersection of its bounding box and an asymmetrically scaled $\ell_1$-like polytope. The volumes of the convex hull and this polytope are nearly equal as the input dimension increases. We then show a linear bound propagation that precisely computes bounds over the convex hull and is significantly tighter than bound propagations over the bounding box or our $\ell_1$-like polytope. This bound propagation scales the state-of-the-art $\ell_0$ verifier on its most challenging robustness benchmarks by 1.24x-7.07x, with a geometric mean of 3.16.

</details>


### [402] [Pretrained Joint Predictions for Scalable Batch Bayesian Optimization of Molecular Designs](https://arxiv.org/abs/2511.10590)
*Miles Wang-Henderson,Ben Kaufman,Edward Williams,Ryan Pederson,Matteo Rossi,Owen Howell,Carl Underkoffler,Narbe Mardirossian,John Parkhill*

Main category: cs.LG

TL;DR: 利用基于表征学习的认知神经网络加速药物发现中的高通量分子设计。通过在结构知情模型之上构建认知神经网络，可以获得可扩展的结合亲和力预测联合概率分布。通过在大规模药物发现应用中进行半合成和真实世界数据集的实验，证明了该方法比现有方法能显著减少迭代次数。


<details>
  <summary>Details</summary>
Motivation: 药物开发中的批量合成和测试分子设计是关键瓶颈，需要加速此过程。

Method: 利用表征学习的认知神经网络（ENN）获得可扩展的联合预测密度，以用于批量贝叶斯优化（Batch BO），并研究了先验网络的重要性以及如何对它们进行预训练。

Result: 在半合成基准测试中，最多可将已知有效的EGFR抑制剂的发现迭代次数减少5倍；在真实世界小分子库中，最多可将有效的抑制剂的发现迭代次数减少10倍。

Conclusion: 所提出的基于ENN 的方法为大规模药物发现提供了一种有前景的解决方案，可以显著加速高通量分子设计过程。

Abstract: Batched synthesis and testing of molecular designs is the key bottleneck of drug development. There has been great interest in leveraging biomolecular foundation models as surrogates to accelerate this process. In this work, we show how to obtain scalable probabilistic surrogates of binding affinity for use in Batch Bayesian Optimization (Batch BO). This demands parallel acquisition functions that hedge between designs and the ability to rapidly sample from a joint predictive density to approximate them. Through the framework of Epistemic Neural Networks (ENNs), we obtain scalable joint predictive distributions of binding affinity on top of representations taken from large structure-informed models. Key to this work is an investigation into the importance of prior networks in ENNs and how to pretrain them on synthetic data to improve downstream performance in Batch BO. Their utility is demonstrated by rediscovering known potent EGFR inhibitors on a semi-synthetic benchmark in up to 5x fewer iterations, as well as potent inhibitors from a real-world small-molecule library in up to 10x fewer iterations, offering a promising solution for large-scale drug discovery applications.

</details>


### [403] [Algorithm Design and Stronger Guarantees for the Improving Multi-Armed Bandits Problem](https://arxiv.org/abs/2511.10619)
*Avrim Blum,Marten Garicano,Kavya Ravichandran,Dravyansh Sharma*

Main category: cs.LG

TL;DR: 该论文研究了具有单调递减回报的改进多臂老虎机问题，并提出了两种新的算法，在特定条件下可以提供比先前算法更好的近似比。


<details>
  <summary>Details</summary>
Motivation: 该研究旨在为多臂老虎机问题（如技术投资、临床试验、超参数选择）提供更优化的资源分配模型，并克服现有算法在近似比方面的局限性。

Method: 论文提出了两个新的参数化老虎机算法族，并利用离线数据分析了学习最优算法的样本复杂度。第一种算法族包含了一个最优的随机算法，在特定条件下（如手臂回报曲线的凹度较强）可以达到比现有算法更好的理论保证。第二种算法族设计的算法能够识别表现良好的实例并进行优化，同时在表现不佳的实例上也能提供保证，并且在统计学习的视角下，无需验证假设就能获得数据依赖的保证。

Result: 通过对新算法族的分析，论文展示了在特定假设下，可以实现对最优手臂的更好近似，并且优于现有算法的 $Ω(k)$ 和 $Ω(\sqrt{k})$ 的下界。

Conclusion: 该研究提出了改进多臂老虎机问题的两种新算法，并在特定条件下实现了比先前工作更优的近似比，同时提供了数据依赖的保证。

Abstract: The improving multi-armed bandits problem is a formal model for allocating effort under uncertainty, motivated by scenarios such as investing research effort into new technologies, performing clinical trials, and hyperparameter selection from learning curves. Each pull of an arm provides reward that increases monotonically with diminishing returns. A growing line of work has designed algorithms for improving bandits, albeit with somewhat pessimistic worst-case guarantees. Indeed, strong lower bounds of $Ω(k)$ and $Ω(\sqrt{k})$ multiplicative approximation factors are known for both deterministic and randomized algorithms (respectively) relative to the optimal arm, where $k$ is the number of bandit arms. In this work, we propose two new parameterized families of bandit algorithms and bound the sample complexity of learning the near-optimal algorithm from each family using offline data. The first family we define includes the optimal randomized algorithm from prior work. We show that an appropriately chosen algorithm from this family can achieve stronger guarantees, with optimal dependence on $k$, when the arm reward curves satisfy additional properties related to the strength of concavity. Our second family contains algorithms that both guarantee best-arm identification on well-behaved instances and revert to worst case guarantees on poorly-behaved instances. Taking a statistical learning perspective on the bandit rewards optimization problem, we achieve stronger data-dependent guarantees without the need for actually verifying whether the assumptions are satisfied.

</details>


<div id='cs.NE'></div>

# cs.NE [[Back]](#toc)

### [404] [UCPO: A Universal Constrained Combinatorial Optimization Method via Preference Optimization](https://arxiv.org/abs/2511.10148)
*Zhanhong Fang,Debing Wang,Jinbiao Chen,Jiahai Wang,Zizhen Zhang*

Main category: cs.NE

TL;DR: UCPO是一个即插即用的框架，它将偏好学习集成到现有的神经求解器中，以解决组合优化中的复杂约束问题。


<details>
  <summary>Details</summary>
Motivation: 现有的神经求解器在处理具有复杂约束的问题时效果不佳，因为这些约束难以通过简单的掩码机制来管理。

Method: UCPO通过一个专门设计的损失函数将约束满足直接嵌入基于偏好的目标中，无需进行架构修改或细致的超参数调整。它使用轻量级的启动微调协议。

Result: UCPO能够使预训练的模型在具有挑战性的、包含大量约束的任务上始终如一地生成接近最优的可行解，并且仅使用原始训练预算的1%即可实现卓越的性能。

Conclusion: UCPO框架通过将约束满足直接嵌入基于偏好的目标中，克服了现有神经求解器在处理复杂约束方面的局限性，并实现了高效、高性能的解决方案。

Abstract: Neural solvers have demonstrated remarkable success in combinatorial optimization, often surpassing traditional heuristics in speed, solution quality, and generalization. However, their efficacy deteriorates significantly when confronted with complex constraints that cannot be effectively managed through simple masking mechanisms. To address this limitation, we introduce Universal Constrained Preference Optimization (UCPO), a novel plug-and-play framework that seamlessly integrates preference learning into existing neural solvers via a specially designed loss function, without requiring architectural modifications. UCPO embeds constraint satisfaction directly into a preference-based objective, eliminating the need for meticulous hyperparameter tuning. Leveraging a lightweight warm-start fine-tuning protocol, UCPO enables pre-trained models to consistently produce near-optimal, feasible solutions on challenging constraint-laden tasks, achieving exceptional performance with as little as 1\% of the original training budget.

</details>


<div id='cs.GT'></div>

# cs.GT [[Back]](#toc)

### [405] [Truth, Justice, and Secrecy: Cake Cutting Under Privacy Constraints](https://arxiv.org/abs/2511.09882)
*Yaron Salman,Tamir Tassa,Omer Lev,Roie Zivan*

Main category: cs.GT

TL;DR: 本文提出了一种既保密又公平且防失灵的蛋糕切割协议。


<details>
  <summary>Details</summary>
Motivation: 现有蛋糕切割算法虽然在公平性方面取得了进展，但对隐私的关注较少。本研究旨在解决隐私问题，并在此基础上提出一种新的协议。

Method: 通过引入密码学技术，将中心化计算替换为去中心化计算，从而实现隐私保护，同时保持公平性和防失灵性。

Result: 本文提出了第一个具有保密、无羡慕和防失灵特性的蛋糕切割协议。

Conclusion: 该协议通过密码学技术实现了隐私保护，鼓励参与者诚实报告偏好，同时不牺牲公平性和防失灵性。

Abstract: Cake-cutting algorithms, which aim to fairly allocate a continuous resource based on individual agent preferences, have seen significant progress over the past two decades. Much of the research has concentrated on fairness, with comparatively less attention given to other important aspects. Chen et al. (2010) introduced an algorithm that, in addition to ensuring fairness, was strategyproof -- meaning agents had no incentive to misreport their valuations. However, even in the absence of strategic incentives to misreport, agents may still hesitate to reveal their true preferences due to privacy concerns (e.g., when allocating advertising time between firms, revealing preferences could inadvertently expose planned marketing strategies or product launch timelines). In this work, we extend the strategyproof algorithm of Chen et al. by introducing a privacy-preserving dimension. To the best of our knowledge, we present the first private cake-cutting protocol, and, in addition, this protocol is also envy-free and strategyproof. Our approach replaces the algorithm's centralized computation with a novel adaptation of cryptographic techniques, enabling privacy without compromising fairness or strategyproofness. Thus, our protocol encourages agents to report their true preferences not only because they are not incentivized to lie, but also because they are protected from having their preferences exposed.

</details>


### [406] [Robust Resource Allocation via Competitive Subsidies](https://arxiv.org/abs/2511.09934)
*David X. Lin,Giannis Fikioris,Siddhartha Banerjee,Éva Tardos*

Main category: cs.GT

TL;DR: 本研究提出了一种新的、鲁棒性达到 0.625 的在线资源分配机制，该机制通过一种简单的拍卖方式实现，并通过引入竞争性补贴来提高效率，该补贴会根据竞标者数量进行调整。


<details>
  <summary>Details</summary>
Motivation: 研究目标是改进现有的非货币在线资源分配机制，以提高其鲁棒性，使其更接近理论上的最优非策略性分配界限。

Method: 本研究提出了一种简单的拍卖机制，其中每个回合的获胜者会获得物品。该机制的关键创新在于引入了竞争性补贴，获胜者支付的费用会根据参与竞标的代理商数量进行调整，具体而言，当有 k 个代理商参与时，获胜者支付的费用与 k/(k+1) 成正比。此外，还对该机制进行了修改，以获得具有稍弱鲁棒性保证（5/(3e) ≈ 0.61）和最优（1-1/e）均衡策略。

Result: 新机制的鲁棒性达到了 0.625，接近了非策略性分配的理论最优界限（1-1/e ≈ 0.63）。研究还表明，该机制在广泛的拍卖机制类别中具有最优性。

Conclusion: 本研究成功设计了一种新的在线资源分配机制，其鲁棒性得到了显著提高，并接近了理论上限。该机制的创新性在于引入了竞争性补贴，并证明了其在多种情况下的最优性。

Abstract: A canonical setting for non-monetary online resource allocation is one where agents compete over multiple rounds for a single item per round, with i.i.d. valuations and additive utilities across rounds. With $n$ symmetric agents, a natural benchmark for each agent is the utility realized by her favorite $1/n$-fraction of rounds; a line of work has demonstrated one can robustly guarantee each agent a constant fraction of this ideal utility, irrespective of how other agents behave. In particular, several mechanisms have been shown to be $1/2$-robust, and recent work established that repeated first-price auctions based on artificial credits have a robustness factor of $0.59$, which cannot be improved beyond $0.6$ using first-price and simple strategies. In contrast, even without strategic considerations, the best achievable factor is $1-1/e\approx 0.63$.
  In this work, we break the $0.6$ first-price barrier to get a new $0.625$-robust mechanism, which almost closes the gap to the non-strategic robustness bound. Surprisingly, we do so via a simple auction, where in each round, bidders decide if they ask for the item, and we allocate uniformly at random among those who ask. The main new ingredient is the idea of competitive subsidies, wherein we charge the winning agent an amount in artificial credits that decreases when fewer agents are bidding (specifically, when $k$ agents bid, then the winner pays proportional to $k/(k+1)$, varying the payment by a factor of 2 depending on the competition). Moreover, we show how it can be modified to get an equilibrium strategy with a slightly weaker robust guarantee of $5/(3e) \approx 0.61$ (and the optimal $1-1/e$ factor at equilibrium). Finally, we show that our mechanism gives the best possible bound under a wide class of auction-based mechanisms.

</details>


### [407] [Facility Location for Congesting Commuters and Generalizing the Cost-Distance Problem](https://arxiv.org/abs/2511.10228)
*Thanasis Lianeas,Marios Mertzanidis,Aikaterini Nikolidaki*

Main category: cs.GT

TL;DR: 本文研究了具有拥塞依赖连接成本的设施选址问题，并提出了相应的近似算法。


<details>
  <summary>Details</summary>
Motivation: 在设施选址问题中，代理商需要连接到设施，而设施可以被打开以供代理商连接。本文提出了一个新问题：面向拥塞（自私）通勤者的设施选址问题，其中代理商连接到设施的成本取决于拥塞情况。

Method: 当成本函数是非递减的时，利用了Caratheodory定理的一个近似版本来推导出问题的近似解。当成本函数是非递增的时，将该问题推广到成本距离问题，并提供了一个达到相同近似保证的算法。

Result: 对于非递减成本函数，提出了基于Caratheodory定理近似版本的方法。对于非递增成本函数，通过推广成本距离问题，提供了一个具有相同近似保证的算法。

Conclusion: 本文成功地为具有拥塞依赖连接成本的设施选址问题（包括非递减和非递增成本函数的情况）提供了近似解决方案。

Abstract: In Facility Location problems there are agents that should be connected to facilities and locations where facilities may be opened so that agents can connect to them. We depart from Uncapacitated Facility Location and by assuming that the connection costs of agents to facilities are congestion dependent, we define a novel problem, namely, Facility Location for Congesting (Selfish) Commuters. The connection costs of agents to facilities come as a result of how the agents commute to reach the facilities in an underlying network with cost functions on the edges. Inapproximability results follow from the related literature and thus approximate solutions is all we can hope for. For when the cost functions are nondecreasing we employ in a novel way an approximate version of Caratheodory's Theorem [5] to show how approximate solutions for different versions of the problem can be derived. For when the cost functions are nonincreasing we show how this problem generalizes the Cost-Distance problem [38] and provide an algorithm that for this more general case achieves the same approximation guarantees.

</details>


<div id='physics.app-ph'></div>

# physics.app-ph [[Back]](#toc)

### [408] [Reduced Variability in Threshold Switches Using Heterostructures of SiO${_x}$ and Vertically Aligned MoS${_2}$](https://arxiv.org/abs/2511.09561)
*Jimin Lee,Rana Walied Ahmad,Sofía Cruces,Dennis Braun,Lukas Völkel,Ke Ran,Joachim Mayer,Stephan Menzel,Alwin Daus,Max C. Lemme*

Main category: physics.app-ph

TL;DR: 二维材料中的范德华异质结可实现可靠的阈值开关。


<details>
  <summary>Details</summary>
Motivation: 理解二维材料中的范德华异质结在电阻开关器件中的基本开关机制。

Method: 研究了垂直排列的二硫化钼（VAMoS$_{2}$）和氧化硅（SiO$_{x}$）异质结的银（Ag）丝状阈值开关（TS）行为，并建立了基于物理、考虑变异性的模型。

Result: 与仅含SiO$_{x}$的器件相比，SiO$_{x}$/VAMoS$_{2}$器件表现出更高的开启阈值和保持电压（约0.4V），更快的开关时间（低至356ns），以及更低的循环次数开启电流变化（3.0%）。模型揭示了Ag离子在VAMoS$_{2}$的范德华间隙中的迁移形成的超薄种子丝，引导了SiO$_{x}$层中的丝状生长。

Conclusion: SiO$_{x}$/VAMoS$_{2}$异质结为垂直器件架构中的可靠TS提供了一种有前景的概念，适用于新兴存储器和神经形态计算。

Abstract: Layered two-dimensional (2D) materials provide unique structural features, such as physical gaps between their layers that are only connected through van der Waals (vdW) forces. These vdW gaps can guide the migration of intercalated ions and thus regulate filament growth in resistive switching (RS) devices. Vertically aligned 2D materials and their heterostructures provide vdW gap-mediated ion transport in memristor crossbars, providing great potential for high-density integration and reliable RS performance. Nevertheless, the fundamental switching mechanisms and their contributions to the RS remain inadequately understood. In this work, we investigate silver (Ag) filament-based threshold switching (TS) in heterostructures comprising vertically aligned 2D molybdenum disulfide (VAMoS${_2}$) grown via sulfurization and silicon oxide (SiO${_x}$). Compared to SiO${_x}$-only devices, the SiO${_x}$/VAMoS${_2}$ devices exhibit TS with higher on-threshold and hold voltages, each approximately 0.4 V, faster switching times down to 356 ns under a 4 V pulse, and a lower cycle-to-cycle on-current variability of 3.0%. A physics-based, variability-aware model reveals that confined Ag ion migration within the vdW gaps in VAMoS${_2}$ forms ultrathin seed filaments, which guide filament growth in the SiO${_x}$ layer. These findings establish SiO${_x}$/VAMoS${_2}$ heterostructures as a promising concept for reliable TS in vertical device architectures for emerging memories and neuromorphic computing.

</details>


### [409] [Diamond-based sensing of stray fields from the bulk of thin-film magnets via nano-indentation](https://arxiv.org/abs/2511.10176)
*Ming-Zhong Ai,Kang-Yuan Liu,Biao Zhang,Weng-Hang Leong,Yao Gao,Yue Cui,Guoli Zhu,Licong Peng,Yanglong Hou,Quan Li,Ren-Bao Liu*

Main category: physics.app-ph

TL;DR: 本研究开发了一种非破坏性方法，利用纳米压痕诱导漏磁，并使用纳米金刚石磁力计测量铁薄膜的本征磁化强度。


<details>
  <summary>Details</summary>
Motivation: 为了在不考虑边缘或畴壁的情况下，理解薄膜或二维材料的本征性质，需要测量其体材料的磁化强度。然而，体材料的漏磁场消失或非常微弱，限制了直接测量方法的应用。

Method: 采用纳米压痕诱导漏磁，并使用纳米金刚石磁力计进行测量。

Result: 成功应用于铁薄膜，测定了材料体内的本征磁化强度。

Conclusion: 该方法为研究薄膜和低维材料的本征磁性提供了直接途径，并为研究机械效应对纳米材料磁化的影响提供了方法。

Abstract: Measurement of the magnetization in the bulk of thin-film or two-dimensional materials is important for understanding their intrinsic properties without the complications from edges or domain walls. However, the stray fields from the bulk vanish or are very weak, which limits the application of direct measurement methods. Here, we develop a non-destructive approach to directly measuring the stray fields from the bulk of thin-film magnets at arbitrarily designatable locations, with nanoscale spatial resolution. We employ nano-indentation to induce the leakage of stray fields from the materials and use nano-diamond magnetometers to measure them. We apply the method to iron thin films and determine the intrinsic magnetization in the bulk of the materials. This work provides direct access to the intrinsic magnetic properties of thin-film and low-dimensional materials, as well as a method to study the mechanical effects on magnetization in nanomaterials.

</details>


### [410] [Bandwidth of Linear Classically Damped Systems with Application to Experimental Model Aircraft](https://arxiv.org/abs/2511.10379)
*Benjamin J. Chang,Keegan J. Moore,Lawrence A. Bergman,Alexander F. Vakakis,Walter A. Silva*

Main category: physics.app-ph

TL;DR: RMS Bandwidth的泛化形式ARMS Bandwidth被提出，用于衡量多自由度线性定常阻尼系统的能量耗散能力，并提供了一种数据驱动的模态能量分布评估方法。


<details>
  <summary>Details</summary>
Motivation: 现有的RMS Bandwidth的数学形式未能揭示其背后的物理机制，限制了其应用。

Method: 推导了ARMS Bandwidth，并提出了一种数据驱动的模态能量分布评估方法。

Result: ARMS Bandwidth能够精确计算结构的耗散能力，并被成功应用于单自由度和多自由度系统以及实验飞机模型，证明了其广泛的适用性。

Conclusion: ARMS Bandwidth是一种衡量多自由度线性定常阻尼系统能量耗散能力的有效方法，并为评估模态能量分布提供了一种新的途径。未来的研究将进一步扩展其应用范围。

Abstract: Bandwidth is a widely known concept and tool used in structural dynamics to measure an oscillator's capacity to dissipate energy over time, for example when used in half-power damping estimation of structural modes. Root Mean Square (RMS) Bandwidth is a generalization of bandwidth that overcomes some of the limitations encountered with conventional bandwidth, including the prerequisite of linearity, single-mode response, and light damping. However, its mathematical form does not reveal much about the physics behind it. In this paper, we extend RMS Bandwidth to multiple degree-of-freedom, linear, time-invariant, classically damped systems by deriving an Analytical Root Mean Square (ARMS) Bandwidth in terms of a system's modal parameters and initial modal energy distribution. We demonstrate that ARMS Bandwidth reliably and accurately computes a single measure for a practical structure's dissipative capacity. Also, a purely data-driven methodology for assessing the modal energy distribution is developed. We apply ARMS Bandwidth to single and multiple degree-of-freedom systems and an experimental model aircraft to demonstrate its broad applicability. Future work will address the effects of non-classical damping distribution, time-varying parameters, and nonlinearities.

</details>


<div id='cs.AR'></div>

# cs.AR [[Back]](#toc)

### [411] [History-Aware Trajectory k-Anonymization Using an FPGA-Based Hardware Accelerator for Real-Time Location Services](https://arxiv.org/abs/2511.09688)
*Hiroshi Nakano,Hiroaki Nishi*

Main category: cs.AR

TL;DR: 本文提出了一种新的、面向历史的轨迹k-匿名化方法，并通过FPGA硬件架构实现了它，以提高位置服务（LBS）的隐私保护和数据效用。


<details>
  <summary>Details</summary>
Motivation: 以往基于FPGA的实时轨迹匿名化方法仅依赖最短路径计算，可能无法反映真实的出行行为，降低匿名数据的效用。本研究旨在解决这一局限性。

Method: 提出了一种新的、面向历史的轨迹k-匿名化方法，并设计了一个先进的FPGA硬件架构来实现。该架构将并行的、基于历史的轨迹搜索与传统的最短路径查找相结合，并使用自定义的定点计数模块来精确地权衡历史数据的贡献，从而优先考虑行为上常见的路线。

Result: FPGA实现表明，新架构的实时吞吐量超过6000条记录/秒，与之前仅使用最短路径的设计相比，数据保留率提高了1.2%，并且能更有效地保留主要的城市干道。

Conclusion: 这项研究的关键进展在于，它能够在LBS严格的延迟限制下，实现高保真、面向历史的匿名化，同时兼顾隐私保护和行为准确性。

Abstract: Our previous work established the feasibility of FPGA-based real-time trajectory anonymization, a critical task for protecting user privacy in modern location-based services (LBS). However, that pioneering approach relied exclusively on shortest-path computations, which can fail to capture re- alistic travel behavior and thus reduce the utility of the anonymized data. To address this limitation, this paper introduces a novel, history-aware trajectory k-anonymization methodology and presents an advanced FPGA-based hardware architecture to implement it. Our proposed architecture uniquely integrates par- allel history-based trajectory searches with conventional shortest- path finding, using a custom fixed-point counting module to ac- curately weigh contributions from historical data. This approach enables the system to prioritize behaviorally common routes over geometrically shorter but less-traveled paths. The FPGA implementation demonstrates that our new architecture achieves a real-time throughput of over 6,000 records/s, improves data retention by up to 1.2% compared to our previous shortest-path- only design, and preserves major arterial roads more effectively. These results signify a key advancement, enabling high-fidelity, history-aware anonymization that preserves both privacy and behavioral accuracy under the strict latency constraints of LBS.

</details>


### [412] [AssertMiner: Module-Level Spec Generation and Assertion Mining using Static Analysis Guided LLMs](https://arxiv.org/abs/2511.10007)
*Hongqin Lyu,Yonghao Wang,Jiaxin Zhou,Zhiteng Chao,Tiancheng Wang,Huawei Li*

Main category: cs.AR

TL;DR: AssertMiner是一个模块级断言生成框架，利用抽象语法树（AST）的静态信息来辅助大型语言模型（LLM）挖掘断言，解决了现有方法只生成顶层断言的局限性。


<details>
  <summary>Details</summary>
Motivation: 现有基于设计规范的断言生成方法通常只产生顶层断言，忽略了微架构级别模块中的验证需求，而设计错误更频繁地发生在这些模块中。

Method: AssertMiner通过执行基于AST的结构提取来生成模块调用图、I/O表和数据流图，指导LLM生成模块级规范和挖掘模块级断言。

Result: AssertMiner在生成高质量模块级断言方面优于AssertLLM和Spec2Assertion等现有方法。与这些方法集成时，AssertMiner可以提高结构覆盖率并显著增强错误检测能力。

Conclusion: AssertMiner能够实现更全面、更高效的验证过程。

Abstract: Assertion-based verification (ABV) is a key approach to checking whether a logic design complies with its architectural specifications. Existing assertion generation methods based on design specifications typically produce only top-level assertions, overlooking verification needs on the implementation details in the modules at the micro-architectural level, where design errors occur more frequently. To address this limitation, we present AssertMiner, a module-level assertion generation framework that leverages static information generated from abstract syntax tree (AST) to assist LLMs in mining assertions. Specifically, it performs AST-based structural extraction to derive the module call graph, I/O table, and dataflow graph, guiding the LLM to generate module-level specifications and mine module-level assertions. Our evaluation demonstrates that AssertMiner outperforms existing methods such as AssertLLM and Spec2Assertion in generating high-quality assertions for modules. When integrated with these methods, AssertMiner can enhance the structural coverage and significantly improve the error detection capability, enabling a more comprehensive and efficient verification process.

</details>


### [413] [The Role of Advanced Computer Architectures in Accelerating Artificial Intelligence Workloads](https://arxiv.org/abs/2511.10010)
*Shahid Amin,Syed Pervez Hussnain Shah*

Main category: cs.AR

TL;DR: AI 模型的进步与计算机体系结构的革新密切相关，本文综述了用于加速 AI 工作负载的体系结构，分析了 GPU、ASIC、FPGA 等主流设计，探讨了优化性能和能效的关键原则，并展望了 PIM 和神经拟态计算等新兴技术。


<details>
  <summary>Details</summary>
Motivation: AI 模型（特别是 DNN）的复杂性和计算需求增长，推动了对传统计算机体系结构的极限挑战，需要专门的硬件来加速 AI 工作负载。

Method: 对 GPU、ASIC、FPGA 等主流 AI 加速器体系结构进行分类综述，分析其设计理念、关键特性和性能权衡。探讨了数据流优化、内存层次结构、稀疏性和量化等提高性能和能效的核心原则。同时，展望了 PIM 和神经拟态计算等新兴技术。结合行业标准基准的量化性能数据，对 AI 加速器进行综合分析。

Result: AI 和计算机体系结构之间存在共生关系，硬件和软件的协同设计是未来计算发展的必然要求。

Conclusion: AI 和计算机体系结构之间存在共生关系，硬件和软件的协同设计不再是优化，而是未来计算发展的必要条件。

Abstract: The remarkable progress in Artificial Intelligence (AI) is foundation-ally linked to a concurrent revolution in computer architecture. As AI models, particularly Deep Neural Networks (DNNs), have grown in complexity, their massive computational demands have pushed traditional architectures to their limits. This paper provides a structured review of this co-evolution, analyzing the architectural landscape designed to accelerate modern AI workloads. We explore the dominant architectural paradigms Graphics Processing Units (GPUs), Appli-cation-Specific Integrated Circuits (ASICs), and Field-Programmable Gate Ar-rays (FPGAs) by breaking down their design philosophies, key features, and per-formance trade-offs. The core principles essential for performance and energy efficiency, including dataflow optimization, advanced memory hierarchies, spar-sity, and quantization, are analyzed. Furthermore, this paper looks ahead to emerging technologies such as Processing-in-Memory (PIM) and neuromorphic computing, which may redefine future computation. By synthesizing architec-tural principles with quantitative performance data from industry-standard benchmarks, this survey presents a comprehensive picture of the AI accelerator landscape. We conclude that AI and computer architecture are in a symbiotic relationship, where hardware-software co-design is no longer an optimization but a necessity for future progress in computing.

</details>


### [414] [Combined power management and congestion control in High-Speed Ethernet-based Networks for Supercomputers and Data Centers](https://arxiv.org/abs/2511.10159)
*Miguel Sánchez de la Rosa,Francisco J. andújar,Jesus Escudero-Sahuquillo,José L. Sánchez,Francisco J. Alfaro-Cortés*

Main category: cs.AR

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: The demand for computer in our daily lives has led to the proliferation of Datacenters that power indispensable many services. On the other hand, computing has become essential for some research for various scientific fields, that require Supercomputers with vast computing capabilities to produce results in reasonable time. The scale and complexity of these systems, compared to our day-to-day devices, are like comparing a cell to a living organism. To make them work properly, we need state-of-the-art technology and engineering, not just raw resources. Interconnecting the different computer nodes that make up a whole is a delicate task, as it can become the bottleneck for the whole infrastructure. In this work, we explore two aspects of the network: how to prevent degradation under heavy use with congestion control, and how to save energy when idle with power management; and how the two may interact.

</details>


### [415] [Beamspace Equalization for mmWave Massive MIMO: Algorithms and VLSI Implementations](https://arxiv.org/abs/2511.10563)
*Seyed Hadi Mirfarshbafan,Christoph Studer*

Main category: cs.AR

TL;DR: Beamspace processing using CSPADE algorithms and VLSI architectures can significantly reduce power consumption and hardware costs in massive MIMO and mmWave communication systems, achieving high throughput and better energy efficiency.


<details>
  <summary>Details</summary>
Motivation: The deployment of massive MIMO and mmWave communication is expected to incur excessive baseband processing hardware cost and power consumption. Beamspace processing can leverage channel sparsity at mmWave frequencies to reduce this complexity.

Method: Review existing beamspace data detection algorithms and propose new algorithms and corresponding VLSI architectures, including a complex sparsity-adaptive equalizer (CSPADE). Implement and evaluate these architectures in a 22nm FDSOI process, comparing a fully-parallelized implementation and a sequential MAC-based architecture with antenna-domain equalization.

Result: The fully-parallelized CSPADE implementation achieves up to 54% power savings compared to antenna-domain equalization, with the highest reported throughput among existing massive MIMO data detectors, while also demonstrating better energy and area efficiency. The sequential MAC-based CSPADE architecture achieves even higher power savings, up to 66%, compared to a MAC-based antenna-domain equalizer.

Conclusion: The proposed beamspace processing algorithms and VLSI architectures, particularly CSPADE, offer significant advantages in terms of power savings, throughput, energy efficiency, and area efficiency for future massive MIMO and mmWave wireless systems.

Abstract: Massive multiuser multiple-input multiple-output (MIMO) and millimeter-wave (mmWave) communication are key physical layer technologies in future wireless systems. Their deployment, however, is expected to incur excessive baseband processing hardware cost and power consumption. Beamspace processing leverages the channel sparsity at mmWave frequencies to reduce baseband processing complexity. In this paper, we review existing beamspace data detection algorithms and propose new algorithms as well as corresponding VLSI architectures that reduce data detection power. We present VLSI implementation results for the proposed architectures in a 22nm FDSOI process. Our results demonstrate that a fully-parallelized implementation of the proposed complex sparsity-adaptive equalizer (CSPADE) achieves up to 54% power savings compared to antenna-domain equalization. Furthermore, our fully-parallelized designs achieve the highest reported throughput among existing massive MIMO data detectors, while achieving better energy and area efficiency. We also present a sequential multiply-accumulate (MAC)-based architecture for CSPADE, which enables even higher power savings, i.e., up to 66%, compared to a MAC-based antenna-domain equalizer.

</details>


<div id='cs.DC'></div>

# cs.DC [[Back]](#toc)

### [416] [Ksurf-Drone: Attention Kalman Filter for Contextual Bandit Optimization in Cloud Resource Allocation](https://arxiv.org/abs/2511.09766)
*Michael Dang'ana,Yuqiu Zhang,Hans-Arno Jacobsen*

Main category: cs.DC

TL;DR: Ksurf是一种新的估计器方法，用于解决云环境中资源编排中因工作负载高度可变而导致的准确性问题。实验证明，Ksurf能显著降低延迟方差，减少CPU和内存使用量，并节约成本。


<details>
  <summary>Details</summary>
Motivation: 云数据中心的容器化基础设施在资源编排和配置参数搜索方面面临挑战，尤其是在云提供商环境的复杂性和不确定性下，这使得编排决策的准确性降低。Ksurf旨在通过最小化方差来解决这些问题。

Method: 本研究评估了Ksurf在涉及高度可变工作负载的基于估计的资源编排任务中的性能，将其作为Drone编排器（一种基于上下文多臂老虎机技术）的目标函数模型应用于云场景。

Result: Ksurf使p95延迟方差降低41%，p99延迟方差降低47%。在Kubernetes上，CPU使用率降低4%，主节点内存使用量减少7MB。在VarBench Kubernetes基准测试中，平均Worker Pod数量减少7%，从而实现成本节约。

Conclusion: Ksurf在处理高可变性工作负载的云资源编排任务时，能够有效提高准确性，降低延迟，并实现显著的成本节约。

Abstract: Resource orchestration and configuration parameter search are key concerns for container-based infrastructure in cloud data centers. Large configuration search space and cloud uncertainties are often mitigated using contextual bandit techniques for resource orchestration including the state-of-the-art Drone orchestrator. Complexity in the cloud provider environment due to varying numbers of virtual machines introduces variability in workloads and resource metrics, making orchestration decisions less accurate due to increased nonlinearity and noise. Ksurf, a state-of-the-art variance-minimizing estimator method ideal for highly variable cloud data, enables optimal resource estimation under conditions of high cloud variability.
  This work evaluates the performance of Ksurf on estimation-based resource orchestration tasks involving highly variable workloads when employed as a contextual multi-armed bandit objective function model for cloud scenarios using Drone. Ksurf enables significantly lower latency variance of $41\%$ at p95 and $47\%$ at p99, demonstrates a $4\%$ reduction in CPU usage and 7 MB reduction in master node memory usage on Kubernetes, resulting in a $7\%$ cost savings in average worker pod count on VarBench Kubernetes benchmark.

</details>


### [417] [A Poly-Log Approximation for Transaction Scheduling in Fog-Cloud Computing and Beyond](https://arxiv.org/abs/2511.09776)
*Ramesh Adhikari,Costas Busch,Pavan Poudel*

Main category: cs.DC

TL;DR: 该论文提出了一种在雾-云计算模型中对事务进行有效调度的算法，以最小化资源分配的总成本。


<details>
  <summary>Details</summary>
Motivation: 在分布式系统中，交易调度对于避免冲突和高效分配共享资源至关重要。雾-云计算模型中交易和共享对象的可移动性给调度带来了挑战。

Method: 提出了一种针对具有双重恒定维度的网络的调度算法。对于单个共享对象，算法提供了 $O(
 	ext{log } n 	ext{log } D)$ 的近似比，其中 $n$ 是节点数，$D$ 是网络直径。对于每个事务最多访问 $k$ 个共享对象的情况，算法提供了 $O(k 	ext{log } n 	ext{log } D)$ 的近似比。还提供了一个完全分布式的调度算法版本。

Result: 在具有双重恒定维度的网络中，实现了针对单个共享对象和多个共享对象的事务调度的近似算法。分布式版本无需全局事务知识。

Conclusion: 该研究为雾-云计算模型中的事务调度问题提供了一种有效的近似算法，并考虑了分布式场景下的可行性。

Abstract: Transaction scheduling is crucial to efficiently allocate shared resources in a conflict-free manner in distributed systems. We investigate the efficient scheduling of transactions in a network of fog-cloud computing model, where transactions and their associated shared objects can move within the network. The schedule may require objects to move to transaction nodes, or the transactions to move to the object nodes. Moreover, the schedule may determine intermediate nodes where both objects and transactions meet. Our goal is to minimize the total combined cost of the schedule. We focus on networks of constant doubling dimension, which appear frequently in practice. We consider a batch problem where an arbitrary set of nodes has transactions that need to be scheduled. First, we consider a single shared object required by all the transactions and present a scheduling algorithm that gives an $O(\log n \cdot \log D)$ approximation of the optimal schedule, where $n$ is the number of nodes and $D$ is the diameter of the network. Later, we consider transactions accessing multiple shared objects (at most $k$ objects per transaction) and provide a scheduling algorithm that gives an $O(k \cdot \log n \cdot \log D)$ approximation. We also provide a fully distributed version of the scheduling algorithms where the nodes do not need global knowledge of transactions.

</details>


### [418] [MoFa: A Unified Performance Modeling Framework for LLM Pretraining](https://arxiv.org/abs/2511.09837)
*Lu Zhao,Rong Shi,Shaoqing Zhang,Shangchao Su,Ziqing Yin,Zhiyan Cui,Hongfeng Sun,Baoguo He,Yueqiang Chen,Liang Dong,Xiyuan Li,Lingbin Wang,Lijun Ma,Qiang Huang,Ting Liu,Chong Wang,Can Wei*

Main category: cs.DC

TL;DR: LLM预训练面临模型规模增长和计算资源需求的挑战，传统的性能调优方法效率低下且忽略了容错机制的开销。本文提出了MoFa框架，该框架整合了多维度优化特性和容错机制，并进行了广泛的评估和实验，以指导LLM预训练的系统设计和部署。


<details>
  <summary>Details</summary>
Motivation: 传统的LLM预训练性能建模方法无法全面考虑优化特性和容错机制（如检查点恢复）带来的显著开销，而手动调优成本过高。

Method: 提出了一种名为MoFa的新型预训练性能建模框架，该框架包含一个增强的成本模型来精确捕捉关键优化效果，并整合了一个基于历史集群可靠性数据的容错模型。此外，还开发了一个基于MoFa的调优系统来探索不同场景下的最优预训练性能和潜在瓶颈。

Result: 大量的建模评估表明MoFa在各种场景下都能实现高预测精度。此外，通过全面的调优实验，该框架系统地揭示了影响不同配置下预训练性能的关键因素。

Conclusion: MoFa框架能够准确预测LLM预训练性能，并提供对LLM预训练系统设计和部署的先验指导。

Abstract: The exponential growth in LLM scales, with parameters soaring from billions to trillions, has necessitated distributed pretraining across large clusters comprising thousands to tens of thousands of devices. While hybrid parallelization strategies enable such pretraining, the vast combinatorial strategy space introduces significant optimization challenges. Traditional manual tuning methods incur prohibitive trial-and-error costs, and existing performance modeling approaches exhibit critical limitations: they fail to comprehensively account for prevalent optimization features and ignore the substantial overhead imposed by essential fault tolerance mechanisms like checkpoint recovery in long-duration pretraining. To address these gaps, we propose MoFa, a novel pretraining performance modeling framework that unifies multi-dimensional optimization features and fault tolerance. MoFa incorporates an enhanced cost model to accurately capture the effects of key optimizations and integrates a fault tolerance model based on historical cluster reliability data. Besides, a MoFa-based tuning system is developed to explore optimal pretraining performance and potential bottlenecks in various scenarios. Extensive modeling evaluations demonstrate that MoFa can achieve high prediction accuracy across various scenarios. In addition, through comprehensive tuning experiments, our framework systematically reveals the key factors influencing pretraining performance under different configurations, which provides solid a priori guidance for LLM pretraining system design and deployment.

</details>


### [419] [Lit Silicon: A Case Where Thermal Imbalance Couples Concurrent Execution in Multiple GPUs](https://arxiv.org/abs/2511.09861)
*Marco Kurzynski,Shaizeen Aga,Di Wu*

Main category: cs.DC

TL;DR: GPU集群中的“Lit Silicon”效应会导致性能下降，该效应源于GPU间的散热不平衡，进而拖慢整体训练速度。通过分析和建模，我们提出了有效的检测和缓解技术，并在AMD MI300X系统上进行了验证，实现了性能提升和功耗降低，有望为数据中心节省大量成本。


<details>
  <summary>Details</summary>
Motivation: GPU系统在现代数据中心得到广泛应用，但其性能在节点和集群层面存在显著的变异性，尤其影响大型语言模型（LLMs）等前沿AI工作负载。

Method: 分析了单节点多GPU系统运行LLM训练时的性能表现，发现内核级性能变异与计算通信重叠（C3）技术相关。提出了“Lit Silicon”效应的分析性能和功耗模型，并设计了检测和缓解技术，同时评估了三种不同的电源管理方案（GPU热设计功耗优化、节点级GPU功耗上限优化、节点级CPU功耗波动优化）。

Result: 在AMD Instinct MI300X GPU系统和两种LLM训练框架上进行的实验显示，所提出的方法可带来高达6%的性能提升和4%的功耗改善。

Conclusion: “Lit Silicon”效应是导致GPU系统性能变异和效率低下的关键因素。所提出的分析模型和缓解技术能够有效解决此问题，并易于在数据中心部署，带来显著的经济效益。

Abstract: GPU systems are increasingly powering modern datacenters at scale. Despite being highly performant, GPU systems suffer from performance variation at the node and cluster levels. Such performance variation significantly impacts both high-performance computing and artificial intelligence workloads, such as cutting-edge large language models (LLMs). We analyze the performance of a single-node multi-GPU system running LLM training, and observe that the kernel-level performance variation is highly correlated with concurrent computation communication (C3), a technique to overlap computation and communication across GPUs for performance gains. We then take a further step to reason that thermally induced straggling coupling with C3 impacts performance variation, coined as the Lit Silicon effect. Lit Silicon describes that in a multi-GPU node, thermal imbalance across GPUs introduces node-level straggler GPUs, which in turn slow down the leader GPUs. Lit Silicon leads to node-level performance variation and inefficiency, impacting the entire datacenter from the bottom up. We propose analytical performance and power models for Lit Silicon, to understand the potential system-level gains. We further design simple detection and mitigation techniques to effectively address the Lit Silicon problem, and evaluate three different power management solutions, including power optimization under GPU thermal design power, performance optimization under node-level GPU power capping, and performance optimization under node-level CPU power sloshing. We conduct experiments on two workloads on two AMD InstinctTM MI300X GPU systems under two LLM training frameworks, and observe up to 6% performance and 4% power improvements, potentially saving hundreds of millions of dollars in datacenters. Our solution is almost free lunch and can be effortlessly adopted in datacenters as a new node-level power management layer.

</details>


### [420] [Optimizing CPU Cache Utilization in Cloud VMs with Accurate Cache Abstraction](https://arxiv.org/abs/2511.09956)
*Mani Tofigh,Edward Guo,Weiwei Jia,Xiaoning Ding,Jianchen Shan*

Main category: cs.DC

TL;DR: 云虚拟机中的缓存优化因可见性和控制力不足而效果不佳；CacheX通过不依赖硬件或虚拟化层支持的探测方法，提供了细粒度的缓存信息，并实现了两种新技术来提高缓存利用率。


<details>
  <summary>Details</summary>
Motivation: 指出在公有云环境中，由于对缓存配置的可见性有限和缺乏控制能力，基于缓存的优化措施往往效果不佳。虚拟机无法感知缓存的分配细节，也无法通过页面放置策略影响缓存使用，因为内存到缓存的映射关系是隐藏的。

Method: 提出了一种名为CacheX的新颖解决方案，该方案利用“eviction sets”在虚拟机内部探测准确且细粒度的缓存抽象，而无需硬件或虚拟化层的支持。此外，CacheX还展示了两种新技术如何利用探测到的信息：一种是LLC（Last-Level Cache）争用感知的任务调度，另一种是虚拟颜色感知的页面缓存管理。

Result: 在x86 Linux内核中实现的CacheX评估表明，它能够有效地提高公有云虚拟机中各种工作负载的缓存利用率。

Conclusion: CacheX能够提供对云虚拟机缓存的细粒度可见性，并通过其支持的调度和页面缓存管理技术，有效提升了缓存利用率。

Abstract: This paper shows that cache-based optimizations are often ineffective in cloud virtual machines (VMs) due to limited visibility into and control over provisioned caches. In public clouds, CPU caches can be partitioned or shared among VMs, but a VM is unaware of cache provisioning details. Moreover, a VM cannot influence cache usage via page placement policies, as memory-to-cache mappings are hidden. The paper proposes a novel solution, CacheX, which probes accurate and fine-grained cache abstraction within VMs using eviction sets without requiring hardware or hypervisor support, and showcases the utility of the probed information with two new techniques: LLC contention-aware task scheduling and virtual color-aware page cache management. Our evaluation of CacheX's implementation in x86 Linux kernel demonstrates that it can effectively improve cache utilization for various workloads in public cloud VMs.

</details>


### [421] [Dynamic Edge Server Selection in Time-Varying Environments: A Reliability-Aware Predictive Approach](https://arxiv.org/abs/2511.10146)
*Jaime Sebastian Burbano,Arnova Abdullah,Eldiyar Zhantileuov,Mohan Liyanage,Rolf Schuster*

Main category: cs.DC

TL;DR: 该研究提出了一种名为MO-HAN的轻量级服务器选择方法，通过融合延迟预测、自适应可靠性和基于滞后的切换机制，来解决边缘计算中动态网络拥堵导致的服务器选择问题，从而在保持低端到端延迟的同时，减少不必要的服务器切换。


<details>
  <summary>Details</summary>
Motivation: 随着低延迟嵌入式应用程序越来越多地依赖边缘计算，多服务器架构中的动态网络拥堵给边缘服务器的选择带来了挑战。

Method: MO-HAN方法利用被动测量（到达率、利用率、有效载荷大小）和指数调制有理延迟模型，计算一个平衡预测延迟和可靠性的分数，以确保只有在预期收益有意义时才进行切换，并保持较低的端到端延迟。

Result: 实验结果表明，MO-HAN在降低平均和尾部延迟方面始终优于静态和公平分配基线，同时与纯粹的机会主义选择相比，切换次数减少了近50%。

Conclusion: MO-HAN方法通过其轻量级和高效的特性，在不依赖侵入性检测或重型学习基础设施的情况下，有效解决了边缘计算中的服务器选择问题，使其适用于资源受限的嵌入式设备。

Abstract: Latency-sensitive embedded applications increasingly rely on edge computing, yet dynamic network congestion in multi-server architectures challenges proper edge server selection. This paper proposes a lightweight server-selection method for edge applications that fuses latency prediction with adaptive reliability and hysteresis-based handover. Using passive measurements (arrival rate, utilization, payload size) and an exponentially modulated rational delay model, the proposed Moderate Handover (MO-HAN) method computes a score that balances predicted latency and reliability to ensure handovers occur only when the expected gain is meaningful and maintain reduced end-to-end latency. Results show that MO-HAN consistently outperforms static and fair-distribution baselines by lowering mean and tail latencies, while reducing handovers by nearly 50% compared to pure opportunistic selection. These gains arise without intrusive instrumentation or heavy learning infrastructure, making MO-HAN practical for resource-constrained embedded devices.

</details>


### [422] [Selection of Supervised Learning-based Sparse Matrix Reordering Algorithms](https://arxiv.org/abs/2511.10180)
*Tao Tang,Youfu Jiang,Yingbo Cui,Jianbin Fang,Peng Zhang,Lin Peng,Chun Huang*

Main category: cs.DC

TL;DR: 提出了一种基于监督学习的稀疏矩阵重排算法选择模型，可自动选择最优算法，实验表明可将求解时间减少55.37%。


<details>
  <summary>Details</summary>
Motivation: 传统的稀疏矩阵重排算法选择依赖于暴力搜索或经验知识，无法适应不同的稀疏矩阵结构。

Method: 提出了一种基于监督学习的模型，用于学习矩阵特性与重排算法之间的关系，实现自动化和智能化的算法选择。

Result: 在佛罗里达稀疏矩阵数据集上进行实验，结果显示该模型能准确预测最优重排算法，与仅使用AMD算法相比，求解时间平均减少55.37%，平均加速比为1.45。

Conclusion: 所提出的监督学习模型能够有效地自动选择稀疏矩阵重排算法，显著提高求解效率。

Abstract: Sparse matrix ordering is a vital optimization technique often employed for solving large-scale sparse matrices. Its goal is to minimize the matrix bandwidth by reorganizing its rows and columns, thus enhancing efficiency. Conventional methods for algorithm selection usually depend on brute-force search or empirical knowledge, lacking the ability to adjust to diverse sparse matrix structures.As a result, we have introduced a supervised learning-based model for choosing sparse matrix reordering algorithms. This model grasps the correlation between matrix characteristics and commonly utilized reordering algorithms, facilitating the automated and intelligent selection of the suitable sparse matrix reordering algorithm. Experiments conducted on the Florida sparse matrix dataset reveal that our model can accurately predict the optimal reordering algorithm for various matrices, leading to a 55.37% reduction in solution time compared to solely using the AMD reordering algorithm, with an average speedup ratio of 1.45.

</details>


### [423] [Workload Schedulers -- Genesis, Algorithms and Differences](https://arxiv.org/abs/2511.10258)
*Leszek Sliwko,Vladimir Getov*

Main category: cs.DC

TL;DR: 本篇论文提出了一种对现代工作负载调度器进行分类的新方法，描述了操作系统进程调度器、集群系统作业调度器和大数据调度器这三类调度器，并探讨了它们从早期采用到现代实现的演变过程，包括算法的使用和特性。最后，论文总结了各类调度器的区别、发展时间线，并强调了适用于本地和分布式系统的调度策略设计的相似性。


<details>
  <summary>Details</summary>
Motivation: 提出一种对现代工作负载调度器进行分类的新方法，并描述了三类调度器（操作系统进程调度器、集群系统作业调度器和大数据调度器）的演变、算法使用和特性。

Method: 描述了三类调度器的演变、算法的使用和特性，并进行了比较和总结。

Result: 对三类调度器进行了分类，并讨论了它们的演变、特性和区别。

Conclusion: 强调了本地和分布式系统在调度策略设计方面的相似性。

Abstract: This paper presents a novel approach to categorization of modern workload schedulers. We provide descriptions of three classes of schedulers: Operating Systems Process Schedulers, Cluster Systems Jobs Schedulers and Big Data Schedulers. We describe their evolution from early adoptions to modern implementations, considering both the use and features of algorithms. In summary, we discuss differences between all presented classes of schedulers and discuss their chronological development. In conclusion we highlight similarities in the focus of scheduling strategies design, applicable to both local and distributed systems.

</details>


### [424] [FastGraph: Optimized GPU-Enabled Algorithms for Fast Graph Building and Message Passing](https://arxiv.org/abs/2511.10442)
*Aarush Agarwal,Raymond He,Jan Kieseler,Matteo Cremonesi,Shah Rukh Qasim*

Main category: cs.DC

TL;DR: FastGraph是一个新的GPU优化的KNN算法，用于低维空间（2-10维）的图构建，可实现20-40倍的速度提升。


<details>
  <summary>Details</summary>
Motivation: 为高性能图神经网络（GNNs）加速图构建过程，特别是在低维空间中。

Method: 采用GPU驻留、分箱分区的方法，支持全梯度流和自适应参数调优。

Result: 在10维以下实现了20-40倍于FAISS、ANNOY和SCANN等库的速度提升，且内存开销极小。

Conclusion: FastGraph能显著提升GNN工作流的性能，尤其是在高能物理中的粒子聚类、视觉对象跟踪和图聚类等低维计算密集型应用中。

Abstract: We introduce FastGraph, a novel GPU-optimized k-nearest neighbor algorithm specifically designed to accelerate graph construction in low-dimensional spaces (2-10 dimensions), critical for high-performance graph neural networks. Our method employs a GPU-resident, bin-partitioned approach with full gradient-flow support and adaptive parameter tuning, significantly enhancing both computational and memory efficiency. Benchmarking demonstrates that FastGraph achieves a 20-40x speedup over state-of-the-art libraries such as FAISS, ANNOY, and SCANN in dimensions less than 10 with virtually no memory overhead. These improvements directly translate into substantial performance gains for GNN-based workflows, particularly benefiting computationally intensive applications in low dimensions such as particle clustering in high-energy physics, visual object tracking, and graph clustering.

</details>


### [425] [Scalable Synthesis of distributed LLM workloads through Symbolic Tensor Graphs](https://arxiv.org/abs/2511.10480)
*Changhai Man,Joongun Park,Hanjiang Wu,Huan Xu,Srinivas Sridharan,Tushar Krishna*

Main category: cs.DC

TL;DR: STAGE是一个框架，用于合成高保真度的LLM执行跟踪，以模拟和优化大规模AI训练和推理系统的性能。


<details>
  <summary>Details</summary>
Motivation: 需要一个可扩展且富有表现力的机制来模拟分布式工作负载执行，以便在部署前进行系统级优化和设计空间探索。然而，现有的方法依赖于实际系统中的执行跟踪，而这些系统通常难以访问，并且难以适应未来的系统配置。

Method: STAGE通过合成高保真度的执行跟踪来模拟LLM工作负载，支持广泛的并行化策略，能够系统地探索LLM架构和系统配置。

Result: STAGE能够生成跨越32K GPU的LLM跟踪，同时在计算、内存和通信方面保持张量级别的准确性，展示了其可扩展性。

Conclusion: STAGE是一个可扩展的框架，能够合成高保真度的LLM执行跟踪，为大规模AI训练和推理系统的优化和设计空间探索提供了支持。该框架将公开提供，以促进分布式机器学习系统的进一步研究。

Abstract: Optimizing the performance of large language models (LLMs) on large-scale AI training and inference systems requires a scalable and expressive mechanism to model distributed workload execution. Such modeling is essential for pre-deployment system-level optimizations (e.g., parallelization strategies) and design-space explorations. While recent efforts have proposed collecting execution traces from real systems, access to large-scale infrastructure remains limited to major cloud providers. Moreover, traces obtained from existing platforms cannot be easily adapted to study future larger-scale system configurations. We introduce Symbolic Tensor grAph GEnerator(STAGE), a framework that synthesizes high-fidelity execution traces to accurately model LLM workloads. STAGE supports a comprehensive set of parallelization strategies, allowing users to systematically explore a wide spectrum of LLM architectures and system configurations. STAGE demonstrates its scalability by synthesizing high-fidelity LLM traces spanning over 32K GPUs, while preserving tensor-level accuracy in compute, memory, and communication. STAGE will be publicly available to facilitate further research in distributed machine learning systems.

</details>


<div id='cond-mat.mes-hall'></div>

# cond-mat.mes-hall [[Back]](#toc)

### [426] [Impact of Contact Gating on Scaling of Monolayer 2D Transistors Using a Symmetric Dual-Gate Structure](https://arxiv.org/abs/2511.09762)
*Victoria M. Ravel,Sarah R. Evans,Samantha K. Holmes,James L. Doherty,Md Sazzadur Rahman,Tania Roy,Aaron D. Franklin*

Main category: cond-mat.mes-hall

TL;DR: 双门结构MoS2场效应晶体管中的接触栅控效应


<details>
  <summary>Details</summary>
Motivation: 阐明接触栅控对MoS2沟道的影响

Method: 采用独立可寻址的背栅和顶栅对称双栅结构

Result: 接触栅控使长沟道器件的开启态性能增强2倍；在50 nm沟道和30 nm接触长度下，开启态性能增强5倍，转移长度减小70%

Conclusion: 接触栅控是2D场效应晶体管器件性能的关键决定因素

Abstract: The performance and scalability of two-dimensional (2D) field-effect transistors (FETs) are strongly influenced by geometry-defined electrostatics. In most 2D FET studies, the gate overlaps with the source and drain electrodes, allowing the gate potential to modulate the 2D semiconductor underneath the electrodes and ultimately effect carrier transport at the metal-semiconductor interface - a phenomenon known as contact gating. Here, a symmetric dual-gate structure with independently addressable back and top gates is employed to elucidate the impact of contact gating on a monolayer MoS2 channel. Unlike previous studies of contact gating, this symmetric structure enables quantification of the phenomena through a contact gating factor, revealing a 2x enhancement in on-state performance in long-channel devices. At scaled dimensions (50 nm channel and 30 nm contact length), the influence of contact gating becomes amplified, yielding a 5x increase in on-state performance and a 70% reduction in transfer length when contact gating is present. Since many reported record-performance 2D FETs employ back-gate geometries that inherently include contact gating, these results establish contact gating as a critical and previously underappreciated determinant of device performance in the 2D FET landscape.

</details>


### [427] [Resolving the phase of a Dirac topological state via interferometric photoemission](https://arxiv.org/abs/2511.09560)
*Shiri Gvishi,Ittai Sidilkover,Shaked Rosenstein,Nir Hen Levin,Adi Peled,Omer Pasternak,Costel R. Rotundu,Ido Biran,Semën Gorfman,Naaman Amer,Hadas Soifer*

Main category: cond-mat.mes-hall

TL;DR: 该研究开发了一种基于时间/角度分辨光电子能谱的量子路径电子干涉仪，能够重建量子材料中电子态的相位。


<details>
  <summary>Details</summary>
Motivation: 电子波函数的相位信息在量子材料研究中至关重要，但目前的技术难以测量，阻碍了对丰富电子信息的获取。

Method: 提出并实现了一种基于时间/角度分辨光电子能谱的量子路径电子干涉仪，用于测量电子态的相位。

Result: 成功在拓扑绝缘体材料的狄拉克电子能带中解析了相位，观察到了与共振相关的相位跳跃以及与相位同步的动量反转，揭示了狄拉克锥的螺旋性。该干涉仪可通过光偏振进行光学控制，实现相位差分测量。

Conclusion: 该光电子干涉仪是一种纯实验方案，不依赖于任何特定理论模型，可应用于多种材料，为量子材料研究开辟了相位维度。

Abstract: The electronic wavefunction is at the heart of physical phenomena, defining the frontiers of quantum materials research. While the amplitude of the electron wavefunction in crystals can be measured with state-of-the-art probes in unprecedented resolution, its phase has remained largely inaccessible, obscuring rich electronic information. Here we develop a quantum-path electron interferometer based on time- and angle-resolved photoemission spectroscopy, that enables the reconstruction of the phase of electronic states in quantum materials - with energy and momentum resolution. We demonstrate the scheme by resolving the phase along the Dirac electronic band of a prototypical topological insulator and observe a resonance-associated phase jump as well as a momentum and phase synchronized inversion revealing the helicity of the Dirac cone. We show the interferometer can be optically controlled by the polarization of the absorbed light, allowing a differential measurement of the phase - a crucial component for extracting phase information from an interferogram. This photo-electron-interferometer is a purely experimental scheme and does not rely on any specific theoretical model. It can be extended to a variety of materials, opening up the phase dimension in quantum materials research.

</details>


### [428] [Superdiffusive transport protected by topology and symmetry in all dimensions](https://arxiv.org/abs/2511.09629)
*Shaofeng Huang,Yu-Peng Wang,Jie Ren,Chen Fang*

Main category: cond-mat.mes-hall

TL;DR: 本文提出了一种在凝聚态材料中实现超扩散的新型节点机制，该机制不依赖于精细调整的哈密顿量，并具有可验证的实验信号。


<details>
  <summary>Details</summary>
Motivation: 现有诱导超扩散的节点机制仅在精细调整的人工哈密顿量中实现，难以在实验中观察。本文旨在提出一种更广泛、可能在凝聚态系统中实现的模型。

Method: 提出了一种由巡游电子与局域杂质轨道杂化产生的节点结构，该结构受电子能带的内在对称性和拓扑保护。推导了由节点结构维度、阶数以及系统维度或费米面维度决定的电导普适标度律 $G acksim L^{-γ}$。通过数值模拟（包括石墨烯和多维魏尔半金属模型）验证了标度律。

Result: 通过数值模拟验证了理论标度律，并发现理论与计算结果吻合良好。预测了线性温电阻率（$ρ acksim T$）和发散的低频光学电导率（$σ(ω) acksim ω^{γ-1}$）等实验可验证的信号。

Conclusion: 本文提出的节点机制为在量子材料中发现和工程化异常输运提供了一条切实可行的途径，并预测了一系列可供实验验证的信号。

Abstract: Superdiffusion is an anomalous transport behavior. Recently, a new mechanism, termed the ``nodal mechanism," has been proposed to induce superdiffusion in quantum models. However, existing realizations of the nodal mechanism have so far been proposed on fine-tuned, artificial Hamiltonians, posing a significant challenge for experimental observation. In this work, we propose a broad class of models for generating superdiffusion potentially realizable in condensed matter systems across different spatial dimensions. A robust nodal structure emerges from the hybridization between the itinerant electrons and the local impurity orbitals, protected by the intrinsic symmetry and topology of the electronic band. We derive a universal scaling law for the conductance, $G \sim L^{-γ}$, revealing how the exponent is dictated by the dimensionality of the nodal structure ($D_{\text{node}}$) and its order $n$, and the dimensionality of the system $(D)$ at high temperatures or that of the Fermi surface ($D^F$) at low temperatures. Through numerical simulations, we validate these scaling relations at zero temperature for various models, including those based on graphene and multi-Weyl semimetals, finding excellent agreement between our theory and the computed exponents. Beyond the scaling of conductance, our framework predicts a suite of experimentally verifiable signatures, notably a new mechanism for linear-in-temperature resistivity ($ρ\sim T$) and a divergent low-frequency optical conductivity ($σ(ω) \sim ω^{γ-1}$), establishing a practical route to discovering and engineering anomalous transport in quantum materials.

</details>


### [429] [Green Function Invariants for Floquet Topological Superconductivity Induced by Proximity Effects](https://arxiv.org/abs/2511.09650)
*Mohamed Assili,Panagiotis Kotetes*

Main category: cond-mat.mes-hall

TL;DR: 本研究提出了一种适用于驱动超导体-半导体混合体系中拓扑相预测的格林函数方法，考虑了以往研究中忽略的由于驱动引起的能级展宽效应，并给出了构造拓扑不变量的具体方法，通过对一个具体的Rashba纳米线体系进行分析，得到了该体系的Floquet能带结构、能级展宽以及拓扑不变量，强调了精确处理自能的必要性，并指出展宽效应对Majorana π模式等拓扑相的观测有阻碍作用。


<details>
  <summary>Details</summary>
Motivation: 以往研究在处理驱动超导体-半导体混合体系时，常将超导体视为库仑势，但在驱动存在时，这种近似会因能级展宽而失效。因此，需要一种新的方法来处理这种效应。

Method: 提出一种格林函数方法，首先通过包含半导体自能的厄米部分获得准能量谱，然后通过将自能的反对称部分投影到准能量特征向量上来读取相应的能级展宽，从而构造Floquet拓扑不变量。

Result: 在Rashba纳米线-超导体-时变泽曼场耦合体系中，得到了Floquet能带结构、能级展宽和拓扑不变量。分析表明，展宽效应对观测Floquet拓扑相，特别是包含Majorana π模式的相具有阻碍作用。

Conclusion: 精确处理自能对于理解和预测驱动超导体-半导体混合体系中的拓扑相至关重要，展宽效应会影响拓扑相的可观测性。

Abstract: We bring forward a Green function approach for the prediction of Floquet topological phases in driven superconductor-semiconductor hybrids. Although it is common to treat the superconducting component as a mere Cooper-pair reservoir, it was recently pointed out that such an approximation breaks down in the presence of driving, due to the emergence of level broadening. Here, we go beyond these recent works and prescribe how to construct the Floquet topological invariants for such driven hybrids. Specifically, we propose to first obtain the midgap quasi-energy spectra by including the hermitian part of the semiconductor's self-energy and, subsequently, read out the respective level broadenings by projecting the anti-hermitian part of the self-energy onto the quasi-energy eigenvectors. We exemplify our approach for a Rashba nanowire coupled to a superconductor and a time-dependent Zeeman field. Using our method, we obtain the Floquet band structure, the respective level broadenings, and the topological invariants. Our analysis reinforces the need to properly account for the self-energy, and corroborates that broadening effects can hinder the observation of the Floquet topological phases and especially of those harboring Majorana $π$ modes.

</details>


### [430] [k-Selective Electrical-to-Magnon Transduction with Realistic Field-distributed Nanoantennas](https://arxiv.org/abs/2511.10346)
*Andreas Höfinger,Andrey A. Voronov,David Schmoll,Sabri Koraltan,Florian Bruckner,Claas Abert,Dieter Suess,Morris Lindner,Timmy Reimann,Carsten Dubs,Andrii V. Chumak,Sebastian Knauer*

Main category: cond-mat.mes-hall

TL;DR: 提出了一种全电气传播自旋波谱（AEPSWS）框架，该框架将电磁驱动场与微磁动力学联系起来，并使用有限元（FE）和有限差分（FD）模拟来计算近场和微磁动力学，以实现自旋波的激发和探测，并为片上磁子器件设计提供了规则。


<details>
  <summary>Details</summary>
Motivation: 文章旨在建立一个将电磁驱动场与微磁动力学联系起来的全电气传播自旋波谱（AEPSWS）框架，以实现对传播自旋波的精确控制和探测，并为片上磁子器件的设计提供指导。

Method: 文章提出了一种全电气传播自旋波谱（AEPSWS）框架。首先，使用有限元（FE）模拟计算了阻抗匹配的、锥形共面和条线天线的全矢量近场。然后，将计算得到的场分布导入有限差分（FD）微磁求解器中。这种方法能够捕捉天线限制的波矢量谱和非均匀磁化分量（垂直于静态磁化）的选择性驱动场。在此基础上，文章推导了用于钇铁石榴石（YIG）薄膜中Damon-Eshbach表面自旋波的k空间权重函数，考虑了实际的电流返回路径和锥形形状。最后，通过将该框架与实验结果进行比较，验证了其在色散脊、群速度和谱峰位置等方面的准确性。

Result: 通过有限元（FE）和有限差分（FD）模拟，成功计算了天线限制的波矢量谱和选择性驱动场。推导出的k空间权重函数能够准确描述Damon-Eshbach表面自旋波的传播特性。与实验结果的比较显示，该框架在色散脊、群速度和谱峰位置等方面具有定量一致性，表明天线可以作为可调谐的k空间滤波器。

Conclusion: 文章提出的AEPSWS框架能够精确地将电磁驱动场与微磁动力学联系起来，并能准确预测自旋波的传播特性。该框架为设计片上磁子换能器提供了实用的设计规则，对于低功耗运行和量子磁子学应用具有重要意义。

Abstract: The excitation and detection of propagating spin waves with lithographed nanoantennas underpin both classical magnonic circuits and emerging quantum technologies. Here, we establish a framework for all-electrical propagating spin-wave spectroscopy (AEPSWS) that links realistic electromagnetic drive fields to micromagnetic dynamics. Using finite-element (FE) simulations, we compute the full vector near-field of electrical impedance-matched, tapered coplanar and stripline antennas and import this distribution into finite-difference (FD) micromagnetic solvers. This approach captures the antenna-limited wave-vector spectrum and the component-selective driving fields (perpendicular to the static magnetisation) that simplified uniform-field models cannot. From this coupling, we derive how realistic current return paths and tapering shapes, k-weighting functions, for Damon-Eshbach surface spin waves in yttrium-iron-garnet (YIG) films are, for millimetre-scale matched CPWs and linear tapers down to nanometre-scale antennas. Validation against experimental AEPSWS on a $48\,nm$ YIG film shows quantitative agreement in dispersion ridges, group velocities, and spectral peak positions, establishing that the antenna acts as a tunable k-space filter. These results provide actionable design rules for on-chip magnonic transducers, with immediate relevance for low-power operation regimes and prospective applications in quantum magnonics.

</details>


### [431] [Probing Topological Stability with Nonlocal Quantum Geometric Markers](https://arxiv.org/abs/2511.09664)
*Quentin Marsal,Hui Liu,Emil J. Bergholtz,Annica M. Black-Schaffer*

Main category: cond-mat.mes-hall

TL;DR: 空间分辨的局部量子几何标记对于诊断无长程平移对称性的拓扑相（包括无定形系统）至关重要。研究人员发现这些标记是非局部的，并且其行为类似于关联函数，在拓扑相变附近表现出剧烈变化，并在实空间中为每种相变产生独特的空间模式。即使在相同的Altland-Zirnbauer分类中，不同的拓扑相变也会产生不同空间特征，这使得能够更精确地探测拓扑稳定性。因此，非局部量子几何指标提供了一种更有效、更通用的工具来理解和预测拓扑相变的稳定性。


<details>
  <summary>Details</summary>
Motivation: 本文的动机在于研究空间分辨的局部量子几何标记在诊断无长程平移对称性的拓扑相（包括无定形系统）中的关键作用，并特别关注这些标记的非局域性。

Method: 本文采用的方法是探索非局域量子几何标记的行为，证明它们可以作为与材料结构无关的关联函数，在拓扑相变附近表现出剧烈变化，并产生独特的空间模式。研究人员还比较了同一Altland-Zirnbauer分类中不同拓扑相变产生的空间特征。

Result: 研究结果表明，非局域量子几何标记的行为类似于关联函数，与材料结构无关，在拓扑相变附近表现出剧烈变化，并为每种相变产生独特的实空间模式。此外，研究发现即使在同一分类中，不同的拓扑相变也会产生不同的空间特征，从而可以更精细地探测拓扑稳定性。

Conclusion: 研究结论是，非局域量子几何指标提供了一种更有效、更通用的工具，用于理解和预测拓扑相变的稳定性，因为它们能够区分同一分类内的不同拓扑相变，并提供清晰的空间探测特征。

Abstract: Spatially resolved local quantum geometric markers play a crucial role in the diagnosis of topological phases without long-range translational symmetry, including amorphous systems. Here, we focus on the nonlocality of such markers. We demonstrate that they behave as correlation functions independently of the material's structure, showing sharp variations in the vicinity of topological transitions and exhibiting a unique pattern in real space for each transition. Notably, we find that, even within the same Altland-Zirnbauer class, distinct topological transitions generate qualitatively different spatial signatures, enabling a refined, class-internal probe of topological stability. As such, nonlocal quantum geometric indicators provide a more efficient and versatile tool to understand and predict the stability of topological phase transitions.

</details>


### [432] [Observation of Shapiro Steps in the Charge Density Wave State Induced by Strain on a Piezoelectric Substrate](https://arxiv.org/abs/2511.09888)
*Koji Fujiwara,Takuya Kawada,Natsumi Nikaido,Jihoon Park,Nan Jiang,Shintaro Takada,Yasuhiro Niimi*

Main category: cond-mat.mes-hall

TL;DR: This paper investigates the dynamics of charge density waves (CDWs) in NbSe$_{3}$ nanowires induced by surface acoustic waves (SAWs). The study observed Shapiro steps, which are typically induced by RF currents, but found distinct features when induced by SAWs. The results highlight the significant role of strain in CDW materials and suggest potential for strain-induced device applications.


<details>
  <summary>Details</summary>
Motivation: Investigate the dynamics of charge density wave (CDW) in NbSe$_{3}$ nanowires induced by surface acoustic waves (SAWs), aiming to understand the role of strain in CDW materials and explore potential device applications.

Method: Observed Shapiro steps in NbSe$_{3}$ nanowires by inducing CDW dynamics with surface acoustic waves (SAWs). Analyzed the distinct features of these SAW-induced Shapiro steps compared to those induced by RF currents.

Result: Clear peaks in differential resistance (Shapiro steps) were observed at the resonant frequency of the SAW device. These SAW-induced Shapiro steps exhibited distinct features compared to RF-induced steps, indicating a significant role of strain.

Conclusion: The strain induced by SAWs plays a significant role in the Shapiro steps observed in NbSe$_{3}$ nanowires, highlighting the importance of strain in CDW materials and opening possibilities for strain-induced device applications.

Abstract: Recent development in nanotechnology has enabled us to investigate the dynamic properties of van der Waals materials on a piezoelectric substrate. Here we report on the dynamics of charge density wave (CDW) in NbSe$_{3}$ nanowires induced by surface acoustic waves (SAWs). Clear peaks in the differential resistance were observed at the resonant frequency of the SAW device. These peaks known as Shapiro steps are typically observed by applying an rf current to NbSe$_{3}$ nanowires. We found that the Shapiro steps induced by SAWs show several distinct features from the ones induced by an rf current. Our detailed study revealed that a strain induced by SAWs plays a significant role in the Shapiro steps. The result clearly demonstrates the importance of the strain in CDW materials and paves the way for strain-induced device applications.

</details>


### [433] [Enhanced Thermoelectricity in Nanowires with inhomogeneous Helical states](https://arxiv.org/abs/2511.09903)
*Zahra Aslani,Fabio Taddei,Fabrizio Dolcini,Alessandro Braggio*

Main category: cond-mat.mes-hall

TL;DR: 通过调整量子相干半导体纳米线器件中两个纳米线段的自旋轨道耦合方向，可以有效调控其热电性质，有望实现更优异的热电响应。


<details>
  <summary>Details</summary>
Motivation: 探索强Rashba自旋-轨道耦合（RSOC）的半导体纳米线（NWs）在外加Zeeman场下的热电（TE）性质调控机制，特别是利用调整两个NW段的错位角来实现TE性质的广泛控制。

Method: 采用散射矩阵方法，应用于纳米线的紧束缚模型，研究错位角对热电性质的影响。

Result: 在RSOC向量反平行（狄拉克悖论构型）时，违反 Wiedemann-Franz 定律，并显著增强塞贝克系数和ZT值。Zeeman能隙决定了掺杂的最佳能量窗口和温度。

Conclusion: 通过控制自旋-轨道场方向（例如使用包裹栅极）是调控和优化量子相干半导体纳米线器件热电响应的有前途的方法。

Abstract: Semiconductor nanowires (NWs) with strong Rashba spin-orbit coupling (RSOC), when exposed to a suitably applied Zeeman field, exhibit one-dimensional helical channels with a spin orientation locked to the propagation direction within the magnetic energy gap. Here, by adopting a scattering-matrix approach applied to a tight-binding model of the NW, we demonstrate that the thermoelectric (TE) properties can be widely controlled by tuning the misalignment angle $φ$ between the spin-orbit directions of two NW segments. In particular, when the RSOC vectors are antiparallel (Dirac paradox configuration) we predict a significant violation of the Wiedemann-Franz law, and a strong enhancement of the Seebeck coefficient and the $ZT$ figure of merit. We also show that the Zeeman gap determines the optimal energy window for doping and temperatures. These results suggest that controlling the spin-orbit field direction, which can be achieved with suitably applied wrap gates, is a promising alternative for tuning and optimizing the TE response in quantum-coherent semiconducting NW devices.

</details>


### [434] [Emergent electronic insulating states in a one-dimensional moiré superlattice](https://arxiv.org/abs/2511.10140)
*Jianfeng Bi,Masaki Minamikawa,Ruige Dong,DongJun Kang,Zihan Weng,Shaoqi Sun,Kenji Watanabe,Takashi Taniguchi,Ryosuke Okumura,Huizhen Wu,Naoto Nakatsuji,SeokJae Yoo,Mikito Koshino,Sihan Zhao*

Main category: cond-mat.mes-hall

TL;DR: 通过将单壁碳纳米管（SWNT）与二维六方氮化硼（hBN）对齐，实现了1D莫尔超晶格中的电子绝缘态。


<details>
  <summary>Details</summary>
Motivation: 在1D范德华系统中实现莫尔工程以前具有挑战性，本研究旨在探索1D莫尔超晶格中的新量子态。

Method: 通过低温电输运测量，结合密度泛函理论（DFT）和紧束缚计算，研究了晶体对齐的扶手椅型SWNT/hBN异质结构中的莫尔工程效应。

Result: 观察到在电荷中性点（CNP）、全莫尔填充和半莫尔填充时出现显著的绝缘态。与未对齐的器件相比，对齐的器件表现出更强的绝缘行为。理论计算表明，莫尔界面处的范德华相互作用导致了部分管壁展平、晶格重构以及单粒子能带的带隙开启。

Conclusion: 本研究成功地在1D莫尔超晶格中实现了莫尔工程，并观察到了电子绝缘态。结果表明，莫尔工程是调控1D材料量子相位的有效途径。此外，半莫尔填充下的绝缘行为可能源于电子关联或电子-声子相互作用，为探索新的相互作用诱导的量子相提供了方向。

Abstract: Two-dimensional (2D) van der Waals (vdW) moiré superlattices have provided a powerful knob to engineer a plethora of new quantum states. However, extending such moiré engineering to one-dimensional (1D) vdW systems has remained challenging. Here we report the moiré-engineered electronic insulating states in a new 1D moiré superlattice, by crystallographically aligning an armchair single-walled carbon nanotube (SWNT) to 2D hexagonal boron nitride (hBN) substrate. Remarkably, we observe the emergence of pronounced insulating states at charge neutrality point (CNP), full and half moiré fillings in lattice-aligned armchair SWNT/hBN heterostructures by low-temperature electrical transport measurements. In strong contrast, armchair SWNT devices without hBN alignment do not show any of these insulating behaviors, providing compelling evidence for the significant 1D moiré effect. Our density functional theory (DFT) and tight-binding calculations reveal that synergetic nanotube partial flattening and in-plane lattice reconstruction at 1D moiré interface expand the most stable AB' stacking regions (carbon on top of boron) and open sizable band gaps at both CNP and full moiré fillings at the single-particle level. Our one-body theory predicts no band gaps at half moiré fillings, suggesting that electron correlation and/or electron-phonon interaction may give rise to these emergent insulating behaviors in our 1D moiré systems. Our work establishes a new and definite moiré engineering route for 1D vdW materials and opens an exciting avenue for exploring interaction-induced quantum phases in 1D.

</details>


### [435] [Magnetotransport properties of an unconventional Rashba spin-orbit coupled two-dimensional electronic system](https://arxiv.org/abs/2511.10175)
*Aryan Pandita,SK Firoz Islam*

Main category: cond-mat.mes-hall

TL;DR: 本研究探讨了具有非常规Rashba自旋-轨道耦合的二维电子系统的磁输运性质，该系统具有一对手性相反的自旋纹理。研究通过解析方法获得了朗道能级，并发现了自旋内和/或自旋间朗道能级交叉。利用Kubo公式计算了纵向电导和量子霍尔电导，发现纵向电导中出现标准的Shubnikov-de Haas振荡，且可通过调节费米能级实现纯自旋极化。在自旋内支路中观察到Shubnikov-de Haas振荡的拍频现象，这是由每个自旋支路中两个能带对应的Shubnikov-de Haas振荡叠加引起的，与传统Rashba体系中由两个自旋支路对应的振荡叠加引起的拍频现象不同。量子霍尔电导则表现出常规的朗道能级单位量子化，但在朗道能级交叉点处，费米能级精确放置时会导致霍尔电导出现双跳跃。


<details>
  <summary>Details</summary>
Motivation: 研究具有非常规Rashba自旋-轨道耦合的二维电子系统的磁输运性质，特别是其朗道能级结构和电导特性，以理解新型自旋电子学器件的潜在行为。

Method: 通过解析方法获得朗道能级，并使用Kubo公式计算纵向电导和量子霍尔电导。

Result: 在纵向电导中观察到Shubnikov-de Haas振荡，并可实现纯自旋极化；在自旋内支路中观察到拍频现象；量子霍尔电导在朗道能级交叉点处出现双跳跃。

Conclusion: 非常规Rashba自旋-轨道耦合导致独特的朗道能级交叉和磁输运行为，如自旋内支路的拍频现象和霍尔电导的双跳跃，这与传统Rashba系统存在显著差异。

Abstract: We study the magnetotransport properties of a two-dimensional electronic system with unconventional Rashba spin-orbit coupling in which the system is described by a pair of chiral spin texture in each spin branch, and the chirality is opposite in two spin branches. We obtain the Landau levels analytically and find that intra-spin and/or inter-spin Landau level crossing occurs. We compute the longitudinal conductivity and quantum Hall conductivity using the Kubo formalism based on linear response theory. We find that the usual Shubnikov-de Haas oscillation in longitudinal conductivity appears that can be made purely spin polarized by adjusting the Fermi level suitably. We observe a beating pattern in the Shubnikov-de Hass oscillation in the intra-spin branches, which arises due to the superposition of Shubnikov-de Hass oscillations corresponding to two bands in each spin branch. This is contrary to the conventional Rashba system, where such beating is due to the superposition of Shubnikov-de Hass oscillations corresponding to the two spin-branches. On the other hand, we note that quantum-Hall conductivity exhibits usual quantization in units of $e^2/h$ corresponding to each spin dependent Landau level. However, the Landau level crossing gives rise to the double jump in the Hall conductivity if the Fermi level is placed precisely at the crossing point.

</details>


### [436] [Long-range propagating paramagnon-polaritons in organic free radicals](https://arxiv.org/abs/2511.10294)
*Sebastian Knauer,Roman Verba,Rostyslav O. Serha,Denys Slobodianiuk,David Schmoll,Andreas Ney,Sergej Demokritov,Andrii Chumak*

Main category: cond-mat.mes-hall

TL;DR: 有机自由基在超过居里温度后仍能保持长程相干性，并能产生传播的亚磁声波-极化激元。


<details>
  <summary>Details</summary>
Motivation: 区分材料的磁响应（抗磁性、顺磁性、铁磁性等）以及研究磁有序材料（铁磁性、亚铁磁性、反铁磁性）中的自旋波（磁振子）的应用。在居里/尼尔温度以上，材料进入顺磁相，长程有序消失，产生短程传播的亚磁声波。本研究旨在探索在特定有机自由基中，即使在高于尼尔温度的情况下，是否仍能保持长程相干性。

Method: 使用全电气传播的自旋波光谱技术，并在外加磁场下，研究有机自由基 2,2,6,6-四甲基哌啶-1-氧基（4-oxo-TEMPO）在高于其尼尔温度下的磁行为。

Result: 在高于尼尔温度下，该有机自由基表现出长程相干性。研究观察到了相干激发的低能量亚磁声波-极化激元，其频率高达 23 GHz，传播距离达到 8 mm，并且群速度超过 100 km/s。

Conclusion: 有机自由基（如 4-oxo-TEMPO）在高于其磁有序温度时仍能维持长程自旋相干性，并能产生传播的亚磁声波-极化激元。这一发现将有机材料与自旋电子学相结合，为有机电子学、高密度信息存储和量子技术开辟了新的可能性。

Abstract: Materials are commonly distinguished by their magnetic response into diamagnetic, paramagnetic, and magnetically ordered (ferro-, ferri-, and antiferromagnetic) phases. Diamagnets and paramagnets lack spontaneous long-range order, whereas ordered magnets develop such order below their Curie or Néel temperature and support single spin-wave excitations (magnons). Magnons have found applications in radio-frequency technologies and computation, magneto-optics, and foundational quantum experiments. Above the Curie/Néel temperature, long-range order is lost and the material transitions to a paramagnetic phase, with localised spin alignment in small patches, producing paramagnons with only short-range propagation. Here we show that long-range coherence is preserved in the organic free radical 2,2,6,6-tetramethylpiperidin-1-oxyl above the Néel temperature using all-electrical propagating spin-wave spectroscopy in external magnetic fields. We observe coherently excited low-energy paramagnon-polaritons up to $\mathbf{23\,\mathrm{GHz}}$ , propagating over $\mathbf{8\,\mathrm{mm}}$ at supersonic group velocities exceeding $\mathbf{100\,\mathrm{km\,s^{-1}}}$. Using free radicals as magnon carriers integrates organic materials with spintronics and opens the way to organic electronics, dense information storage, and quantum technologies.

</details>


### [437] [Modification of Hanle and polarization recovery curves under interplay of hopping and quantum measurement back action](https://arxiv.org/abs/2511.10304)
*A. L. Zibinskiy,D. S. Smirnov*

Main category: cond-mat.mes-hall

TL;DR: Hanle和偏振恢复效应可用于确定量子点中自旋动力学参数，例如超精细相互作用强度。本文研究了电子跳跃和测量反馈对局域电子自旋极化的影响，并分析了在法拉第和伏特几何中的竞争与协作关系。


<details>
  <summary>Details</summary>
Motivation: 测量Hanle和偏振恢复效应对局域电荷载流子是确定自旋动力学参数（如超精细相互作用强度）的基础工具，尤其是在量子点等系统中。

Method: 研究了电子跳跃和测量反馈对局域电子自旋极化在横向和纵向磁场中的依赖关系。

Result: 电子跳跃和测量反馈在法拉第几何中表现出相似的作用，而在伏特几何中则相互竞争。这种相互作用可以解释广泛的实验结果。

Conclusion: 该研究能够描述广泛的实验结果，并为研究量子测量的基本效应提供了新的视角。

Abstract: The measurements of Hanle and polarization recovery effects for localized charge carriers are the basic tools for determining parameters of the spin dynamics, such as strength of the hyperfine interaction, for example, in quantum dots. We describe the dependence of the spin polarization of localized electrons on transverse and longitudinal magnetic fields taking into account the interplay between electron hopping and measurement back action. We show that these two have a qualitatively similar effect in the Faraday geometry, but compete in the Voigt geometry. This allows one to describe a broad range of the experimental results and study the fundamental effects of quantum measurements.

</details>


### [438] [Point defects and their dynamic behaviors in silver monolayer intercalated between graphene and SiC](https://arxiv.org/abs/2511.10368)
*Van Dong Pham,Arpit Jain,Chengye Dong,Li-Syuan Lu,Joshua A. Robinson,Achim Trampert,Roman Engel-Herbert*

Main category: cond-mat.mes-hall

TL;DR: 二维银单层中发现的暗、亮缺陷是空位和取代杂质，它们具有由缺陷诱导的局域电子态，并且可以在扫描隧道显微镜的激发下进行可逆的开关操作，可用于纳米电子学。


<details>
  <summary>Details</summary>
Motivation: 研究二维金属中的点缺陷或杂质，以了解其对结构和电子性质的局部影响，并探索其在原子尺度上的应用潜力。

Method: 使用扫描隧道显微镜研究了外延石墨烯和SiC界面处插入的二维银单层中的原子尺度缺陷。

Result: 识别出暗缺陷（面内空位）和亮缺陷（取代杂质），它们各自具有由缺陷引起的局域电子态。在负偏压下，这些缺陷可以像氢原子一样进行非弹性跳跃，并且可以通过扫描隧道显微镜尖端可逆地控制。

Conclusion: 该研究展示了在二维金属中以原子精度理解和控制缺陷的可能性，并揭示了具有纳米电子学应用潜力的先前未探索的动态行为。

Abstract: Point defects or impurities can give rise to sharp local modifications in the structure and electronic properties of two-dimensional metals, serving as an intriguing atomic-level solid-state model for both fundamental and application research. In this work, we investigated atomic-scale defects in a two-dimensional silver monolayer intercalated at the interface between epitaxial graphene and SiC using a scanning tunneling microscope. Distinct dark and bright defects are identified as in-plane vacancies and substitutional impurities within the silver monolayer, each hosting a localized electronic state induced solely by the defect. Remarkably, under excitation of tunneling electrons assisted by a negative bias voltage, the defects can hop inelastically which is reminiscent of the hydrogen switching in the cavity of an organic molecule. The hopping can be reversibly controlled by the scanning tunneling microscope tip, allowing the defects to function as atomic-scale two-level conductance switches. Defect hopping further allows us to gain a deeper understanding of their origins and the relationship between dark and bright defect species. This study constitutes a pathway toward understanding and controlling defects in two-dimensional metals with atomic precision, revealing previously unexplored dynamic behavior with potential applications in nanoelectronics.

</details>


### [439] [Exploring the Role of Interfacial Dzyaloshinskii-Moriya Interaction in Write Error Rate Anomalies of Spin-Transfer Torque Magnetic Tunnel Junctions](https://arxiv.org/abs/2511.10437)
*Prosenjit Das,Md Mahadi Rajib,Jayasimha Atulasimha*

Main category: cond-mat.mes-hall

TL;DR: DMI会导致STT-MRAM中出现“气球效应”等异常开关行为，但可以通过延长脉冲时间来克服，这表明界面工程可以提高STT-MRAM的可靠性。


<details>
  <summary>Details</summary>
Motivation: STT-MRAM在高时序操作中可能出现异常开关行为，从而影响其性能和可靠性，特别是“气球效应”，其特征是在特定的电流脉冲持续时间内，写入错误率（WER）会随着STT电流的增加而非单调地增加。本文旨在系统地研究界面DMI在这种WER异常中的作用。

Method: 利用20nm和50nm磁性隧道结（MTJs）的微磁模拟，系统地研究了界面Dzyaloshinskii-Moriya相互作用（DMI）对“气球效应”等写入错误率（WER）异常的影响。

Result: 研究表明，DMI会促进非相干磁化反转，延长开关时间，并产生导致反转不完全的中间多畴状态。在高DMI值下，即使在大的开关电流密度下，这些状态也会持续存在，从而重现了实验报告的“气球效应”异常。相比之下，较长的脉冲通过为系统提供足够的时间达到稳定状态来克服这些影响。

Conclusion: 研究结果表明，界面DMI在“气球效应”中起着重要作用，并指出界面工程是提高下一代STT-MRAM可靠性的实用策略。

Abstract: The performance and reliability of spin-transfer torque magnetic random-access memory (STT-MRAM) can be compromised by anomalous switching behavior, especially during high-speed operations. One such anomaly, known as the "ballooning effect" is characterized by an unexpected non-monotonic increase in the write error rate (WER) with increase in STT current at specific current pulse durations. In this study, we systematically investigate the role of the interfacial Dzyaloshinskii-Moriya interaction (DMI) on such WER anomaly using micromagnetic simulations of 20 nm and 50 nm magnetic tunnel junctions (MTJs). We show that DMI promotes incoherent magnetization reversal, prolongs the switching time and creates intermediate multidomain states that result in incomplete reversal. At high DMI values, these states persist even under large switching current densities, reproducing ballooning-like anomalies reported experimentally. In contrast, longer pulses overcome these effects by allowing the system sufficient time to reach a stable state. Our findings show that interfacial DMI can play a role in the ballooning effect and point to interfacial engineering as a practical strategy for improving the reliability of next-generation STT-MRAM.

</details>


### [440] [Elastic Dislocation-based Skyrmion Traps: Fundamentals and Applications](https://arxiv.org/abs/2511.10451)
*Martín Latorre,Joaquín Barra,Juan Pablo Vera,Joaquín Martinez,Mario Castro,Sebastián Allende,Alvaro S. Nunez*

Main category: cond-mat.mes-hall

TL;DR: 拓扑自旋结构（如skyrmion和bimeron）作为一种有前景的替代方案，有望用于高密度、低功耗的自旋电子器件。本文深入探讨了畸变磁格中的螺位错与拓扑磁性之间的相互作用，将拓扑磁性和拓扑弹性联系起来。研究发现，位错如同磁结构上的浅层陷阱，并分析了skyrmion的量子化运动及其量子态。最后，提出了一种利用位错阵列作为赛道上的“音格”，通过低电流激活机制控制skyrmion运动的设备概念。


<details>
  <summary>Details</summary>
Motivation: 探索拓扑磁性（如skyrmion）与拓扑弹性（如位错）之间的相互作用，并将其应用于实际器件。

Method: 首先对skyrmion运动进行经典分析，揭示位错作为浅层陷阱的作用；然后分析skyrmion的量子化运动并识别其量子态。

Result: 位错被发现是磁结构上的浅层陷阱，skyrmion存在量子化运动和量子态。

Conclusion: 利用位错阵列作为控制skyrmion运动的“音格”，通过低电流激活机制，可以构建基于拓扑磁性的简单器件。

Abstract: Topologically secure spin configurations, such as skyrmions and bimerons, offer a compelling alternative to conventional magnetic domains, potentially enabling high-density, low-power spintronic devices. These pseudo-particles, characterized by their swirling spin textures and nontrivial topological charges, are prevalent and notably influence their electronic, magnetic, and mechanical traits. This paper provides an in-depth overview of the interaction between a screw dislocation within a distorted magnetic lattice, exploring possible coupling mechanisms and establishing a promising link between two disparate topics in materials science: topological magnetism and topological elasticity. We first provide a classical analysis of skyrmion motion that reveals the dislocations as shallow traps on the magnetic texture. Afterwards, we provide an analysis of the quantized motion of the skyrmion and identify its quantum states. We conclude by illustrating how the ideas in our paper can be implemented in simple yet compelling devices based on the shallow traps from an array of dislocations acting as frets in a race-track, controlling the motion with a low current activation mechanism.

</details>


### [441] [Broadband nonlinear Hall response and multiple wave mixing in a room temperature altermagnet](https://arxiv.org/abs/2511.10471)
*Soumya Sankar,Xingkai Cheng,Xinyu Chen,Xizhi Fu,Takahiro Urata Wataru Hattori,Wenlong Lu,Zihan Lin,Dong Chen,Claudia Felser,Hiroshi Ikuta,Junzhang Ma,Junwei Liu,Berthold Jäck*

Main category: cond-mat.mes-hall

TL;DR: Altermagnets具有独特的磁晶序，可导致新颖的非线性电学特性。本研究在CrSb中发现了室温下的宽带三阶非线性反常霍尔效应，并将其归因于Berry曲率四极子。利用此特性，研究人员成功实现了四波混频器件，并展望了其在太赫兹和高频电子领域的应用前景。


<details>
  <summary>Details</summary>
Motivation: 晶体对称性决定了材料对外部刺激的线性/非线性响应，而Altermagnets作为一类新型磁性材料，其独特的对称性可能带来新颖的电学现象。本研究旨在探索Altermagnets的电学特性。

Method: 实验上，在室温下测量了Altermagnetic CrSb的宽带三阶非线性反常霍尔效应。理论上，通过对称性分析和模型计算，将观察到的非线性霍尔响应与Berry曲率四极子以及CrSb的自旋分裂能带结构联系起来。

Result: 发现了室温下的宽带三阶非线性反常霍尔效应。通过理论分析，确认该效应是由Berry曲率四极子引起的，而Berry曲率四极子存在于CrSb的自旋分裂能带结构中，并由晶体和磁对称性决定。成功利用CrSb实现了具有显著四波混频输出的器件。

Conclusion: Altermagnets的晶磁序决定了其非线性电学特性，这可能为高频电子、太赫兹产生、通信网络和能量收集等领域带来新的应用机会。

Abstract: Crystalline symmetries determine the linear and nonlinear response of materials to external stimuli such as mechanical pressure and electromagnetic fields, governing phenomena such as piezoelectricity, optical activity, and multiple wave mixing with wide ranging technological applications. Altermagnets present a new class of materials with magnetic crystalline order where specific crystal symmetry operations connect antiferromagnetic sublattices, leading to non-relativistic spin-splitting of the electronic band structure. Hence, the electric material properties of altermagnets should uniquely mirror these underlying symmetry properties, potentially giving rise to novel phenomena in response to external driving fields. Here, we report the discovery of a broadband third-order nonlinear anomalous Hall effect in altermagnetic CrSb at room temperature. The comparison of our observations with symmetry analyses and model calculations shows that this nonlinear Hall response is induced by the nonlinear electric susceptibility of a Berry curvature quadrupole, which exists within the spin-split band structure of CrSb and is characterized by the underlying crystalline and magnetic symmetries. We then utilize this third-order nonlinear electric susceptibility of CrSb to realize a multiple wave mixing device with pronounced four wave mixing output, which could, in principle, be extended to THz frequencies. Our study discovers that the crystalline magnetic order of altermagnets determines their nonlinear electric material properties, which could facilitate applications in high-frequency electronics, THz generation, communication networks, and energy harvesting.

</details>


### [442] [Ordinary lattice defects as probes of topology](https://arxiv.org/abs/2511.10646)
*Aiden J. Mains,Jia-Xin Zhong,Yun Jing,Bitan Roy*

Main category: cond-mat.mes-hall

TL;DR: 普通晶格缺陷（如空位、取代等）可以作为探测拓扑电子带的探针，即使它们本身在拓扑上是平凡的。


<details>
  <summary>Details</summary>
Motivation: 尽管晶格缺陷通常被认为是平凡的，但本研究旨在证明它们可以作为探测非平凡电子布洛赫带拓扑的通用探针。

Method: 通过在二维方格模型中实现包含时间反转对称性破缺的拓扑和正常绝缘体，并引入点缺陷，理论上研究了普通晶格缺陷附近的拓扑性质。此外，通过在二维声学陈绝缘体中嵌入普通晶格缺陷，并利用有源超原子和格林函数谱分析，进行了实验验证。

Result: 理论上，普通晶格缺陷在其附近产生了可探测到的中带束缚态，并且这些束缚态对弱杂质具有鲁棒性。实验上也观察到了这种束缚态。

Conclusion: 本研究结合理论和实验，证明了普通晶格缺陷作为拓扑探针的普适性，并提出其在拓扑超导体中锚定马约拉纳模式以及工程化设计拓扑器件的可能性。

Abstract: In addition to topological lattice defects such as dislocations and disclinations, crystals are also accompanied by unavoidable ordinary defects, devoid of any non-trivial geometry or topology, among which vacancies, Schottky defects, substitutions, interstitials, and Frenkel pairs are the most common. In this work, we demonstrate that these ubiquitous ordinary lattice defects, though topologically trivial, can nonetheless serve as universal probes of the non-trivial topology of electronic Bloch bands, and any change in the local topological environment in an otherwise normal insulator in terms of mid-gap bound states in their vicinity. We theoretically establish these generic findings by implementing a minimal model Hamiltonian describing time-reversal symmetry breaking topological and normal insulators on a square lattice, fostering such point defects. The defect-bound mid-gap modes are also shown to be robust against weak point-like charge impurities. Furthermore, we showcase experimental observation of such bound states by embedding ordinary crystal defects in two-dimensional acoustic Chern lattices, where precision-controlled hopping amplitudes are implemented via active meta-atoms and Green's-function-based spectroscopy is used to reconstruct spectra and eigenstates. Our combined theory-experiment study establishes ordinary lattice defects as probes of topology that should be germane in crystals of any symmetry and dimension, raising the possibility of arresting localized Majorana modes near such defects in the bulk of topological superconductors and to emulate ordinary-defect-engineered topological devices.

</details>


<div id='cs.MA'></div>

# cs.MA [[Back]](#toc)

### [443] [Multi-agent In-context Coordination via Decentralized Memory Retrieval](https://arxiv.org/abs/2511.10030)
*Tao Jiang,Zichuan Lin,Lihe Li,Yi-Chen Li,Cong Guan,Lei Yuan,Zongzhang Zhang,Yang Yu,Deheng Ye*

Main category: cs.MA

TL;DR: MAICC是一种新颖的多智能体强化学习（MARL）方法，通过去中心化的记忆检索来增强智能体的协调和适应性，以解决合作MARL中的任务对齐和奖励分配问题，并在实验中表现出更快的适应能力。


<details>
  <summary>Details</summary>
Motivation: 合作MARL中的去中心化策略部署可能导致任务对齐和奖励分配不匹配，从而限制了策略适应的效率。MAICC旨在解决这一挑战，提高协调和快速适应能力。

Method: MAICC首先训练一个中心化的嵌入模型来捕捉细粒度的轨迹表示，然后使用去中心化模型来近似中心化模型，以获取团队层面的任务信息。基于学习到的嵌入，检索相关的轨迹作为上下文，并结合智能体的当前子轨迹来指导决策。在去中心化执行期间，MAICC引入了一个新的记忆机制来平衡在线数据和离线记忆，并提出了一种混合效用分数来整合个体和团队回报，以确保跨智能体的信用分配。

Result: 在LBF和SMAC（v1/v2）等合作MARL基准测试的广泛实验表明，MAICC能够比现有方法更快地适应未见过的任务。

Conclusion: MAICC通过其新颖的记忆检索和混合效用分数机制，有效地提高了合作MARL智能体的协调和适应性，使其能够更快地适应新的任务。

Abstract: Large transformer models, trained on diverse datasets, have demonstrated impressive few-shot performance on previously unseen tasks without requiring parameter updates. This capability has also been explored in Reinforcement Learning (RL), where agents interact with the environment to retrieve context and maximize cumulative rewards, showcasing strong adaptability in complex settings. However, in cooperative Multi-Agent Reinforcement Learning (MARL), where agents must coordinate toward a shared goal, decentralized policy deployment can lead to mismatches in task alignment and reward assignment, limiting the efficiency of policy adaptation. To address this challenge, we introduce Multi-agent In-context Coordination via Decentralized Memory Retrieval (MAICC), a novel approach designed to enhance coordination by fast adaptation. Our method involves training a centralized embedding model to capture fine-grained trajectory representations, followed by decentralized models that approximate the centralized one to obtain team-level task information. Based on the learned embeddings, relevant trajectories are retrieved as context, which, combined with the agents' current sub-trajectories, inform decision-making. During decentralized execution, we introduce a novel memory mechanism that effectively balances test-time online data with offline memory. Based on the constructed memory, we propose a hybrid utility score that incorporates both individual- and team-level returns, ensuring credit assignment across agents. Extensive experiments on cooperative MARL benchmarks, including Level-Based Foraging (LBF) and SMAC (v1/v2), show that MAICC enables faster adaptation to unseen tasks compared to existing methods. Code is available at https://github.com/LAMDA-RL/MAICC.

</details>


### [444] [Behavior Modeling for Training-free Building of Private Domain Multi Agent System](https://arxiv.org/abs/2511.10283)
*Won Ik Cho,Woonghee Han,Kyung Seo Ki,Young Min Kim*

Main category: cs.MA

TL;DR: 本框架提出了一种在私域环境中构建多智能体对话系统的方案，无需训练或数据生成，即可实现与私域工具的适配和上下文的适应。


<details>
  <summary>Details</summary>
Motivation: 私域环境下的多智能体系统面临工具格式异构、API访问受限、治理复杂等挑战，现有解决方案（如微调）成本高昂且泛化能力差。

Method: 本框架采用行为建模和文档化的方法，通过设定一个协调者、一个工具调用智能体和一个通用聊天智能体，并利用结构化规范和领域指令来集成工具，从而避免了训练和数据生成。

Result: 该框架支持实际应用，包括多智能体系统的轻量级部署、利用API规范作为检索资源以及生成用于评估的合成对话。

Conclusion: 本框架为私域多智能体对话系统提供了一种无需持续再训练即可适应私域工具和不断变化的上下文的可持续方法，能够使智能体的行为与私域专业知识保持一致。

Abstract: The rise of agentic systems that combine orchestration, tool use, and conversational capabilities, has been more visible by the recent advent of large language models (LLMs). While open-domain frameworks exist, applying them in private domains remains difficult due to heterogeneous tool formats, domain-specific jargon, restricted accessibility of APIs, and complex governance. Conventional solutions, such as fine-tuning on synthetic dialogue data, are burdensome and brittle under domain shifts, and risk degrading general performance. In this light, we introduce a framework for private-domain multi-agent conversational systems that avoids training and data generation by adopting behavior modeling and documentation. Our design simply assumes an orchestrator, a tool-calling agent, and a general chat agent, with tool integration defined through structured specifications and domain-informed instructions. This approach enables scalable adaptation to private tools and evolving contexts without continual retraining. The framework supports practical use cases, including lightweight deployment of multi-agent systems, leveraging API specifications as retrieval resources, and generating synthetic dialogue for evaluation -- providing a sustainable method for aligning agent behavior with domain expertise in private conversational ecosystems.

</details>


### [445] [Rethinking the Reliability of Multi-agent System: A Perspective from Byzantine Fault Tolerance](https://arxiv.org/abs/2511.10400)
*Lifan Zheng,Jiawei Chen,Qinghong Yin,Jingyuan Zhang,Xinyi Zeng,Yu Tian*

Main category: cs.MA

TL;DR: LLM代理在拜占庭容错方面优于传统代理，CP-WBFT机制进一步增强了多智能体系统的可靠性。


<details>
  <summary>Details</summary>
Motivation: 探讨LLM代理在多智能体系统（MAS）中的可靠性问题，以及LLM代理是否能提升MAS的整体可靠性。

Method: 提出了一种基于置信探针的加权拜占庭容错共识机制CP-WBFT，利用LLM的内在反思和辨别能力，通过探针式加权信息流传输来提高LLM代理的可靠性。

Result: CP-WBFT在各种网络拓扑结构和高达85.7%的故障率下表现出色，在数学推理和安全评估任务中均优于传统方法，准确性和可靠性均得到显著提升。

Conclusion: LLM代理具有更强的怀疑精神，在处理错误消息流时表现优于传统代理。CP-WBFT机制能有效提升MAS的稳定性和可靠性，尤其是在面对高故障率和不同拓扑结构时。

Abstract: Ensuring the reliability of agent architectures and effectively identifying problematic agents when failures occur are crucial challenges in multi-agent systems (MAS). Advances in large language models (LLMs) have established LLM-based agents as a major branch of MAS, enabling major breakthroughs in complex problem solving and world modeling. However, the reliability implications of this shift remain largely unexplored. i.e., whether substituting traditional agents with LLM-based agents can effectively enhance the reliability of MAS. In this work, we investigate and quantify the reliability of LLM-based agents from the perspective of Byzantine fault tolerance. We observe that LLM-based agents demonstrate stronger skepticism when processing erroneous message flows, a characteristic that enables them to outperform traditional agents across different topological structures. Motivated by the results of the pilot experiment, we design CP-WBFT, a confidence probe-based weighted Byzantine Fault Tolerant consensus mechanism to enhance the stability of MAS with different topologies. It capitalizes on the intrinsic reflective and discriminative capabilities of LLMs by employing a probe-based, weighted information flow transmission method to improve the reliability of LLM-based agents. Extensive experiments demonstrate that CP-WBFT achieves superior performance across diverse network topologies under extreme Byzantine conditions (85.7\% fault rate). Notably, our approach surpasses traditional methods by attaining remarkable accuracy on various topologies and maintaining strong reliability in both mathematical reasoning and safety assessment tasks.

</details>
