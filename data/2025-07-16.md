<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 65]
- [cs.CL](#cs.CL) [Total: 47]
- [eess.SP](#eess.SP) [Total: 9]
- [eess.SY](#eess.SY) [Total: 9]
- [cs.DC](#cs.DC) [Total: 11]
- [cs.LG](#cs.LG) [Total: 83]
- [cs.GT](#cs.GT) [Total: 6]
- [eess.IV](#eess.IV) [Total: 3]
- [cs.MA](#cs.MA) [Total: 1]
- [cs.RO](#cs.RO) [Total: 34]
- [physics.app-ph](#physics.app-ph) [Total: 2]
- [cs.NE](#cs.NE) [Total: 6]
- [cs.SI](#cs.SI) [Total: 6]
- [cs.DS](#cs.DS) [Total: 14]
- [cond-mat.mtrl-sci](#cond-mat.mtrl-sci) [Total: 18]
- [cs.LO](#cs.LO) [Total: 9]
- [cs.AI](#cs.AI) [Total: 36]
- [cs.ET](#cs.ET) [Total: 1]
- [cs.GR](#cs.GR) [Total: 3]
- [cs.AR](#cs.AR) [Total: 8]
- [cond-mat.mes-hall](#cond-mat.mes-hall) [Total: 15]
- [quant-ph](#quant-ph) [Total: 51]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [CWNet: Causal Wavelet Network for Low-Light Image Enhancement](https://arxiv.org/abs/2507.10689)
*Tongshun Zhang,Pingping Liu,Yubing Lu,Mengen Cai,Zijian Zhang,Zhe Zhang,Qiuzhan Zhou*

Main category: cs.CV

TL;DR: CWNet利用小波变换和因果推理来改进低光图像增强，通过度量学习和实例级语义损失来处理实例级语义信息和特征特性，并在实验中取得了优于现有方法的性能。


<details>
  <summary>Details</summary>
Motivation: 解决传统低光图像增强方法主要关注统一亮度调整，忽略实例级语义信息和不同特征固有特性的问题。

Method: 提出了一种新颖的CWNet（因果小波网络）架构，该架构利用小波变换进行因果推理。该方法包括：1）采用因果推理视角，利用度量学习策略确保因果嵌入遵循因果原理，并引入实例级CLIP语义损失来精确维护因果因素一致性。2）基于因果分析，提出了一种基于小波变换的骨干网络，以优化频率信息的恢复。

Result: CWNet显著优于当前最先进的方法，在各种场景中表现出稳健的性能。

Conclusion: CWNet在多个数据集上显著优于当前最先进的方法，在各种场景中表现出稳健的性能。

Abstract: Traditional Low-Light Image Enhancement (LLIE) methods primarily focus on
uniform brightness adjustment, often neglecting instance-level semantic
information and the inherent characteristics of different features. To address
these limitations, we propose CWNet (Causal Wavelet Network), a novel
architecture that leverages wavelet transforms for causal reasoning.
Specifically, our approach comprises two key components: 1) Inspired by the
concept of intervention in causality, we adopt a causal reasoning perspective
to reveal the underlying causal relationships in low-light enhancement. From a
global perspective, we employ a metric learning strategy to ensure causal
embeddings adhere to causal principles, separating them from non-causal
confounding factors while focusing on the invariance of causal factors. At the
local level, we introduce an instance-level CLIP semantic loss to precisely
maintain causal factor consistency. 2) Based on our causal analysis, we present
a wavelet transform-based backbone network that effectively optimizes the
recovery of frequency information, ensuring precise enhancement tailored to the
specific attributes of wavelet transforms. Extensive experiments demonstrate
that CWNet significantly outperforms current state-of-the-art methods across
multiple datasets, showcasing its robust performance across diverse scenes.
Code is available at https://github.com/bywlzts/CWNet-Causal-Wavelet-Network.

</details>


### [2] [Integrating Biological Knowledge for Robust Microscopy Image Profiling on De Novo Cell Lines](https://arxiv.org/abs/2507.10737)
*Jiayuan Chen,Thai-Hoang Pham,Yuanlong Wang,Ping Zhang*

Main category: cs.CV

TL;DR: 通过整合知识图谱和转录组学特征，提出新框架提升显微成像模型在新细胞系上的性能，用于药物发现。


<details>
  <summary>Details</summary>
Motivation: 解决高通量筛选技术在处理具有显著形态和生物异质性的新型细胞系时所面临的挑战，以提高模型在新型细胞系上的鲁棒性和泛化能力。

Method: 提出了一种整合外部生物学知识到预训练策略的新框架，利用蛋白质相互作用数据构建知识图谱以分离扰动特征，并结合单细胞转录组学特征以捕捉细胞系特异性表示。

Result: 在RxRx数据库上进行评估，通过单样本微调和少样本微调，实验结果表明该方法有效提升了新型细胞系的显微成像分析能力。

Conclusion: 该框架通过整合外部生物学知识和预训练策略，成功提升了成像模型在新型细胞系上的泛化能力，并证明了其在基于表型的药物发现中的有效性。

Abstract: High-throughput screening techniques, such as microscopy imaging of cellular
responses to genetic and chemical perturbations, play a crucial role in drug
discovery and biomedical research. However, robust perturbation screening for
\textit{de novo} cell lines remains challenging due to the significant
morphological and biological heterogeneity across cell lines. To address this,
we propose a novel framework that integrates external biological knowledge into
existing pretraining strategies to enhance microscopy image profiling models.
Our approach explicitly disentangles perturbation-specific and cell
line-specific representations using external biological information.
Specifically, we construct a knowledge graph leveraging protein interaction
data from STRING and Hetionet databases to guide models toward
perturbation-specific features during pretraining. Additionally, we incorporate
transcriptomic features from single-cell foundation models to capture cell
line-specific representations. By learning these disentangled features, our
method improves the generalization of imaging models to \textit{de novo} cell
lines. We evaluate our framework on the RxRx database through one-shot
fine-tuning on an RxRx1 cell line and few-shot fine-tuning on cell lines from
the RxRx19a dataset. Experimental results demonstrate that our method enhances
microscopy image profiling for \textit{de novo} cell lines, highlighting its
effectiveness in real-world phenotype-based drug discovery applications.

</details>


### [3] [Auditing Facial Emotion Recognition Datasets for Posed Expressions and Racial Bias](https://arxiv.org/abs/2507.10755)
*Rina Khan,Catherine Stinson*

Main category: cs.CV

TL;DR: 该研究发现，面部表情识别（FER）算法在识别自发表情和不同肤色人群的表情时存在性能问题，这归因于数据集的偏差。研究审计了两个FER数据集，发现其中混有大量摆拍表情图像，并且模型对非白人或深肤色人群存在识别偏见，倾向于将其误判为负面情绪，这可能在实际应用中造成不良后果。


<details>
  <summary>Details</summary>
Motivation: 解决 FER 算法在识别自发表情时性能下降以及在跨种族识别时表现不佳的挑战，这些挑战源于 FER 数据集的构建方式。

Method: 通过随机抽样的方式对两个最先进的 FER 数据集进行审计，并检查图像是属于自发表情还是摆拍表情，以此提出识别自发或摆拍图像的方法。此外，还观察了样本中个体的肤色，并测试了在这些数据上训练的三个模型，以评估其对不同种族和肤色个体面部表情的预测能力。

Result: 在声称包含“in-the-wild”图像的数据集中发现了大量摆拍图像，这意味着在这些数据集上训练的模型无法准确反映其在真实应用场景下的性能。此外，研究发现 FER 模型更有可能将那些被标记为非白人或肤色较深的人识别为负面情绪（如愤怒或悲伤），即使他们实际上在微笑。这种偏差会使模型在现实应用中产生和加剧伤害。

Conclusion: FER 模型在处理自发表情和跨种族识别方面存在性能差距，这与 FER 数据集的构建方式有关。研究审计了两个 FER 数据集，发现其中包含大量摆拍表情图像，并且模型对非白人或深肤色个体的识别存在偏见，倾向于将其归类为负面情绪，即使他们实际上在微笑。这种偏见可能在现实应用中造成危害。

Abstract: Facial expression recognition (FER) algorithms classify facial expressions
into emotions such as happy, sad, or angry. An evaluative challenge facing FER
algorithms is the fall in performance when detecting spontaneous expressions
compared to posed expressions. An ethical (and evaluative) challenge facing FER
algorithms is that they tend to perform poorly for people of some races and
skin colors. These challenges are linked to the data collection practices
employed in the creation of FER datasets. In this study, we audit two
state-of-the-art FER datasets. We take random samples from each dataset and
examine whether images are spontaneous or posed. In doing so, we propose a
methodology for identifying spontaneous or posed images. We discover a
significant number of images that were posed in the datasets purporting to
consist of in-the-wild images. Since performance of FER models vary between
spontaneous and posed images, the performance of models trained on these
datasets will not represent the true performance if such models were to be
deployed in in-the-wild applications. We also observe the skin color of
individuals in the samples, and test three models trained on each of the
datasets to predict facial expressions of people from various races and skin
tones. We find that the FER models audited were more likely to predict people
labeled as not white or determined to have dark skin as showing a negative
emotion such as anger or sadness even when they were smiling. This bias makes
such models prone to perpetuate harm in real life applications.

</details>


### [4] [FPC-Net: Revisiting SuperPoint with Descriptor-Free Keypoint Detection via Feature Pyramids and Consistency-Based Implicit Matching](https://arxiv.org/abs/2507.10770)
*Ionuţ Grigore,Călin-Adrian Popa,Claudiu Leoveanu-Condrei*

Main category: cs.CV

TL;DR: 一种无需描述符即可匹配兴趣点的新技术，可大幅减少内存使用。


<details>
  <summary>Details</summary>
Motivation: 减少本地化系统中的内存使用量，并探索一种无需描述符的兴趣点匹配技术。

Method: 在检测过程中固有地关联兴趣点，无需计算、存储、传输或匹配描述符。

Result: 与经典手工方法和现代学习方法相比，该方法在内存使用方面有显著优势，匹配精度略有下降。

Conclusion: 该方法通过在检测过程中固有地关联兴趣点来消除对描述符的需求，尽管匹配精度略有下降，但显著减少了内存使用量，适用于本地化系统。

Abstract: The extraction and matching of interest points are fundamental to many
geometric computer vision tasks. Traditionally, matching is performed by
assigning descriptors to interest points and identifying correspondences based
on descriptor similarity. This work introduces a technique where interest
points are inherently associated during detection, eliminating the need for
computing, storing, transmitting, or matching descriptors. Although the
matching accuracy is marginally lower than that of conventional approaches, our
method completely eliminates the need for descriptors, leading to a drastic
reduction in memory usage for localization systems. We assess its effectiveness
by comparing it against both classical handcrafted methods and modern learned
approaches.

</details>


### [5] [A New Dataset and Performance Benchmark for Real-time Spacecraft Segmentation in Onboard Flight Computers](https://arxiv.org/abs/2507.10775)
*Jeffrey Joan Sam,Janhavi Sathe,Nikhil Chigali,Naman Gupta,Radhey Ruparel,Yicheng Jiang,Janmajay Singh,James W. Berck,Arko Barman*

Main category: cs.CV

TL;DR: 为解决太空损害检测和修复成本问题，创建了一个包含近64,000张图像的数据集，并微调了YOLO模型，实现了高效准确的太空图像分割。


<details>
  <summary>Details</summary>
Motivation: 为了应对外太空空间站面临的损坏问题以及人工或机器人修复的风险和高成本，提出利用图像分割技术开发自主检测系统。然而，现有模型需要大量训练数据，而公开的标注数据却十分稀少。

Method: 利用NASA的TTALOS管线生成包含近64,000张标注航天器图像的数据集，并加入噪声和畸变以模拟真实世界条件。对YOLOv8和YOLOv11分割模型进行了微调，以在模拟的真实世界挑战中建立性能基准。

Result: 生成了一个包含近64,000张标注航天器图像的数据集，并提供了微调后的YOLOv8和YOLOv11模型性能基准。所提出的模型在特定约束下达到了0.92的Dice分数，0.69的Hausdorff距离，推理时间约为0.5秒。

Conclusion: 该数据集和模型为在太空中的实时应用提供了性能基准，所提出的方法通过对YOLOv8和YOLOv11进行微调，在特定硬件和推理时间限制下实现了0.92的Dice分数和0.69的Hausdorff距离，推理时间约为0.5秒。

Abstract: Spacecraft deployed in outer space are routinely subjected to various forms
of damage due to exposure to hazardous environments. In addition, there are
significant risks to the subsequent process of in-space repairs through human
extravehicular activity or robotic manipulation, incurring substantial
operational costs. Recent developments in image segmentation could enable the
development of reliable and cost-effective autonomous inspection systems. While
these models often require large amounts of training data to achieve
satisfactory results, publicly available annotated spacecraft segmentation data
are very scarce. Here, we present a new dataset of nearly 64k annotated
spacecraft images that was created using real spacecraft models, superimposed
on a mixture of real and synthetic backgrounds generated using NASA's TTALOS
pipeline. To mimic camera distortions and noise in real-world image
acquisition, we also added different types of noise and distortion to the
images. Finally, we finetuned YOLOv8 and YOLOv11 segmentation models to
generate performance benchmarks for the dataset under well-defined hardware and
inference time constraints to mimic real-world image segmentation challenges
for real-time onboard applications in space on NASA's inspector spacecraft. The
resulting models, when tested under these constraints, achieved a Dice score of
0.92, Hausdorff distance of 0.69, and an inference time of about 0.5 second.
The dataset and models for performance benchmark are available at
https://github.com/RiceD2KLab/SWiM.

</details>


### [6] [Warehouse Spatial Question Answering with LLM Agent](https://arxiv.org/abs/2507.10778)
*Hsiang-Wei Huang,Jen-Hao Cheng,Kuang-Ming Chen,Cheng-Yen Yang,Bahaa Alattar,Yi-Ru Lin,Pyongkun Kim,Sangwon Kim,Kwangju Kim,Chung-I Huang,Jenq-Neng Hwang*

Main category: cs.CV

TL;DR: 提出一个LLM代理系统，通过集成多种工具来增强其空间推理能力，以应对复杂的空间问答任务，并在基准测试中表现出高准确性和效率。


<details>
  <summary>Details</summary>
Motivation: 解决现有MLLM在空间理解方面的挑战，特别是在复杂的室内仓库场景中。

Method: 提出一个具有强大高级空间推理能力的LLM代理系统，并集成多种工具，使LLM代理能够进行空间推理和API工具交互来回答复杂空间问题。

Result: 在物体检索、计数和距离估计等任务中取得了高准确性和效率。

Conclusion: 该系统在2025 AI City Challenge Physical AI Spatial Intelligence Warehouse 数据集上进行了广泛评估，在物体检索、计数和距离估计等任务中实现了高准确性和效率。

Abstract: Spatial understanding has been a challenging task for existing Multi-modal
Large Language Models~(MLLMs). Previous methods leverage large-scale MLLM
finetuning to enhance MLLM's spatial understanding ability. In this paper, we
present a data-efficient approach. We propose a LLM agent system with strong
and advanced spatial reasoning ability, which can be used to solve the
challenging spatial question answering task in complex indoor warehouse
scenarios. Our system integrates multiple tools that allow the LLM agent to
conduct spatial reasoning and API tools interaction to answer the given
complicated spatial question. Extensive evaluations on the 2025 AI City
Challenge Physical AI Spatial Intelligence Warehouse dataset demonstrate that
our system achieves high accuracy and efficiency in tasks such as object
retrieval, counting, and distance estimation. The code is available at:
https://github.com/hsiangwei0903/SpatialAgent

</details>


### [7] [ThinkingViT: Matryoshka Thinking Vision Transformer for Elastic Inference](https://arxiv.org/abs/2507.10800)
*Ali Hojjat,Janek Haberer,Soren Pirk,Olaf Landsiedel*

Main category: cs.CV

TL;DR: ThinkingViT是一种新的嵌套ViT架构，通过动态调整计算量和使用Token Recycling机制，在提高推理效率和准确性方面优于现有模型。


<details>
  <summary>Details</summary>
Motivation: 现有的Vision Transformer虽然性能优越，但计算预算固定，难以在异构硬件上进行扩展。嵌套Transformer模型虽然能实现可扩展推理，但会为所有输入分配相同的计算量，效率低下。

Method: ThinkingViT是一种嵌套Vision Transformer（ViT）架构，其核心是Token Recycling机制，能够根据输入难度动态调整推理计算。它通过激活部分注意力头并进行早期预测，或者激活更多注意力头并重新评估输入来工作。

Result: 在ImageNet-1K上，ThinkingViT在相同吞吐量下准确率高出基线模型2.0个百分点，在相同GMACs下高出2.9个百分点。

Conclusion: ThinkingViT通过采用渐进式思维阶段来动态调整基于输入难度的推理计算，并在ImageNet-1K上取得了优于嵌套基线模型的性能。

Abstract: Vision Transformers deliver state-of-the-art performance, yet their fixed
computational budget prevents scalable deployment across heterogeneous
hardware. Recent nested Transformer architectures mitigate this by embedding
nested subnetworks within a single model to enable scalable inference. However,
these models allocate the same amount of compute to all inputs, regardless of
their complexity, which leads to inefficiencies. To address this, we introduce
ThinkingViT, a nested ViT architecture that employs progressive thinking stages
to dynamically adjust inference computation based on input difficulty.
ThinkingViT initiates inference by activating a small subset of the most
important attention heads and terminates early if predictions reach sufficient
certainty. Otherwise, it activates additional attention heads and re-evaluates
the input. At the core of ThinkingViT is our Token Recycling mechanism, which
conditions each subsequent inference stage on the embeddings from the previous
stage, enabling progressive improvement. Due to its backbone-preserving design,
ThinkingViT also serves as a plugin upgrade for vanilla ViT. Experiments show
that ThinkingViT surpasses nested baselines by up to 2.0 percentage points
(p.p.) in accuracy at the same throughput and by up to 2.9 p.p. at equal GMACs
on ImageNet-1K. The source code is available at
https://github.com/ds-kiel/ThinkingViT.

</details>


### [8] [LLM-Guided Agentic Object Detection for Open-World Understanding](https://arxiv.org/abs/2507.10844)
*Furkan Mumcu,Michael J. Jones,Anoop Cherian,Yasin Yilmaz*

Main category: cs.CV

TL;DR: 提出LAOD框架，利用LLM生成对象名称，实现无需标签的零样本检测，提高了自主性和适应性。


<details>
  <summary>Details</summary>
Motivation: 传统的对象检测依赖于固定的类别集，处理新对象需要重新训练。虽然OWOD和OVOD提高了灵活性，但OWOD缺乏未知对象的语义标签，OVOD依赖用户提示，限制了自主性。

Method: 提出了一种名为LAOD（LLM-guided agentic object detection）的框架，利用大型语言模型（LLM）生成场景特定的对象名称，并将其输入到开放词汇检测器中进行定位，实现了完全无需标签的零样本检测。

Result: 通过在LVIS、COCO和COCO-OOD数据集上进行实验，验证了该方法的有效性，该方法在检测和命名新对象方面表现强劲。

Conclusion: 所提出的LAOD框架通过提示LLM生成场景特定的对象名称，实现了完全无需标签的零样本检测，并能动态调整目标，从而提高了开放世界理解的自主性和适应性。

Abstract: Object detection traditionally relies on fixed category sets, requiring
costly re-training to handle novel objects. While Open-World and
Open-Vocabulary Object Detection (OWOD and OVOD) improve flexibility, OWOD
lacks semantic labels for unknowns, and OVOD depends on user prompts, limiting
autonomy. We propose an LLM-guided agentic object detection (LAOD) framework
that enables fully label-free, zero-shot detection by prompting a Large
Language Model (LLM) to generate scene-specific object names. These are passed
to an open-vocabulary detector for localization, allowing the system to adapt
its goals dynamically. We introduce two new metrics, Class-Agnostic Average
Precision (CAAP) and Semantic Naming Average Precision (SNAP), to separately
evaluate localization and naming. Experiments on LVIS, COCO, and COCO-OOD
validate our approach, showing strong performance in detecting and naming novel
objects. Our method offers enhanced autonomy and adaptability for open-world
understanding.

</details>


### [9] [Winsor-CAM: Human-Tunable Visual Explanations from Deep Networks via Layer-Wise Winsorization](https://arxiv.org/abs/2507.10846)
*Casey Wall,Longwei Wang,Rodrigue Rizk,KC Santosh*

Main category: cs.CV

TL;DR: Winsor-CAM是Grad-CAM的一种改进方法，通过结合多层信息和异常值抑制技术，提高了模型解释的准确性和灵活性。


<details>
  <summary>Details</summary>
Motivation: 为了在关键领域部署卷积神经网络（CNN）模型，理解其决策过程至关重要。现有的Grad-CAM方法在处理多个卷积层的信息时存在不足，可能隐藏重要的语义线索或放大无关的噪声。

Method: 提出了一种名为Winsor-CAM的新型、可由用户调优的Grad-CAM扩展方法。该方法通过聚合所有卷积层的信息来生成鲁棒且连贯的显著性图，并采用Winsorization（一种基于百分位数的异常值衰减技术）来减轻噪声或极端归因值的影响。用户可以通过一个可控阈值进行语义层面的调整，从而灵活地探索模型在不同表征层级中的行为。

Result: 在PASCAL VOC 2012数据集和标准CNN架构（ResNet50、DenseNet121、VGG16、InceptionV3）上的评估表明，与Grad-CAM和均匀层平均基线相比，Winsor-CAM生成的热图更具可解释性，并且在交并比和质心对齐等定位指标上取得了更优越的性能。

Conclusion: Winsor-CAM通过聚合所有卷积层的信息，并应用Winsorization技术来缓解噪声或极端归因值的影响，从而生成鲁棒且连贯的显著性图。用户可控的阈值允许进行语义层面的调整，从而灵活地探索模型在不同表征层级中的行为。Winsor-CAM通过提供可解释的、多层级的见解和人为干预的控制，推动了可信AI的目标。

Abstract: Interpreting the decision-making process of Convolutional Neural Networks
(CNNs) is critical for deploying models in high-stakes domains.
Gradient-weighted Class Activation Mapping (Grad-CAM) is a widely used method
for visual explanations, yet it typically focuses on the final convolutional
layer or na\"ively averages across layers, strategies that can obscure
important semantic cues or amplify irrelevant noise. We propose Winsor-CAM, a
novel, human-tunable extension of Grad-CAM that generates robust and coherent
saliency maps by aggregating information across all convolutional layers. To
mitigate the influence of noisy or extreme attribution values, Winsor-CAM
applies Winsorization, a percentile-based outlier attenuation technique. A
user-controllable threshold allows for semantic-level tuning, enabling flexible
exploration of model behavior across representational hierarchies. Evaluations
on standard architectures (ResNet50, DenseNet121, VGG16, InceptionV3) using the
PASCAL VOC 2012 dataset demonstrate that Winsor-CAM produces more interpretable
heatmaps and achieves superior performance in localization metrics, including
intersection-over-union and center-of-mass alignment, when compared to Grad-CAM
and uniform layer-averaging baselines. Winsor-CAM advances the goal of
trustworthy AI by offering interpretable, multi-layer insights with
human-in-the-loop control.

</details>


### [10] [Sparse Fine-Tuning of Transformers for Generative Tasks](https://arxiv.org/abs/2507.10855)
*Wei Chen,Jingxi Yu,Zichen Miao,Qiang Qiu*

Main category: cs.CV

TL;DR: 一种受稀疏编码启发的微调框架，通过稀疏组合特征字典原子来适应下游任务，提高了图像编辑和文本到图像生成的效果。


<details>
  <summary>Details</summary>
Motivation: 现有的微调方法将更新后的表示形式化为修改参数的密集组合，使得解释其贡献和理解模型如何适应新任务变得困难。

Method: 本研究引入了一种受稀疏编码启发的微调框架，其中微调后的特征表示为基本元素（即特征字典原子）的稀疏组合。稀疏系数作为原子重要性的指标，用于识别每个原子对更新表示的贡献。

Result: 该方法在图像编辑任务中通过移除不重要的特征字典原子提高了文本对齐度；在文本到图像的概念定制任务中，该方法有效地构建了目标概念，并优于基线方法。

Conclusion: 该方法通过移除不重要的特征字典原子来增强图像编辑性能，提高文本对齐度，并在文本到图像的概念定制任务中，通过稀疏组合特征字典原子有效地构建目标概念，优于各种基线微调方法。

Abstract: Large pre-trained transformers have revolutionized artificial intelligence
across various domains, and fine-tuning remains the dominant approach for
adapting these models to downstream tasks due to the cost of training from
scratch. However, in existing fine-tuning methods, the updated representations
are formed as a dense combination of modified parameters, making it challenging
to interpret their contributions and understand how the model adapts to new
tasks. In this work, we introduce a fine-tuning framework inspired by sparse
coding, where fine-tuned features are represented as a sparse combination of
basic elements, i.e., feature dictionary atoms. The feature dictionary atoms
function as fundamental building blocks of the representation, and tuning atoms
allows for seamless adaptation to downstream tasks. Sparse coefficients then
serve as indicators of atom importance, identifying the contribution of each
atom to the updated representation. Leveraging the atom selection capability of
sparse coefficients, we first demonstrate that our method enhances image
editing performance by improving text alignment through the removal of
unimportant feature dictionary atoms. Additionally, we validate the
effectiveness of our approach in the text-to-image concept customization task,
where our method efficiently constructs the target concept using a sparse
combination of feature dictionary atoms, outperforming various baseline
fine-tuning methods.

</details>


### [11] [A Lightweight and Robust Framework for Real-Time Colorectal Polyp Detection Using LOF-Based Preprocessing and YOLO-v11n](https://arxiv.org/abs/2507.10864)
*Saadat Behzadi,Danial Sharifrazi,Bita Mesbahzadeh,Javad Hassannataj Joloudarid,Roohallah Alizadehsani*

Main category: cs.CV

TL;DR: 该研究提出了一种结合LOF和YOLO-v11n的结直肠息肉检测方法，通过数据预处理和模型优化，显著提高了检测的准确性和效率，适用于实时结肠镜检查。


<details>
  <summary>Details</summary>
Motivation: 及时准确地检测结直肠息肉对于诊断和预防结直肠癌至关重要，而结直肠癌是全球主要的死亡原因之一。

Method: 该研究采用了一种结合了局部异常值因子（LOF）算法和YOLO-v11n深度学习模型的新型轻量级高效框架，用于结直肠息肉检测。通过对五个公共数据集（CVC-ColonDB、CVC-ClinicDB、Kvasir-SEG、ETIS和EndoScene）进行实验，将分割掩码转换为检测标签，并利用LOF方法（配置30个邻居和5%的污染率）移除异常样本。然后将清理后的数据输入经过现代增强策略优化的YOLO-v11n模型进行训练，并采用5折交叉验证来增强模型的鲁棒性和泛化能力。

Result: 该方法显著提高了息肉定位性能，取得了95.83%的精确率、91.85%的召回率、93.48%的F1分数、96.48%的mAP@0.5和77.75%的mAP@0.5:0.95。与之前的基于YOLO的方法相比，该模型展示了更高的准确性和效率。

Conclusion: 该研究提出的方法非常适合临床环境中的实时结肠镜检查支持。这项研究强调了在设计有效的医学影像人工智能系统时，数据预处理和模型效率至关重要。

Abstract: Objectives: Timely and accurate detection of colorectal polyps plays a
crucial role in diagnosing and preventing colorectal cancer, a major cause of
mortality worldwide. This study introduces a new, lightweight, and efficient
framework for polyp detection that combines the Local Outlier Factor (LOF)
algorithm for filtering noisy data with the YOLO-v11n deep learning model.
  Study design: An experimental study leveraging deep learning and outlier
removal techniques across multiple public datasets.
  Methods: The proposed approach was tested on five diverse and publicly
available datasets: CVC-ColonDB, CVC-ClinicDB, Kvasir-SEG, ETIS, and EndoScene.
Since these datasets originally lacked bounding box annotations, we converted
their segmentation masks into suitable detection labels. To enhance the
robustness and generalizability of our model, we apply 5-fold cross-validation
and remove anomalous samples using the LOF method configured with 30 neighbors
and a contamination ratio of 5%. Cleaned data are then fed into YOLO-v11n, a
fast and resource-efficient object detection architecture optimized for
real-time applications. We train the model using a combination of modern
augmentation strategies to improve detection accuracy under diverse conditions.
  Results: Our approach significantly improves polyp localization performance,
achieving a precision of 95.83%, recall of 91.85%, F1-score of 93.48%, mAP@0.5
of 96.48%, and mAP@0.5:0.95 of 77.75%. Compared to previous YOLO-based methods,
our model demonstrates enhanced accuracy and efficiency.
  Conclusions: These results suggest that the proposed method is well-suited
for real-time colonoscopy support in clinical settings. Overall, the study
underscores how crucial data preprocessing and model efficiency are when
designing effective AI systems for medical imaging.

</details>


### [12] [Trexplorer Super: Topologically Correct Centerline Tree Tracking of Tubular Objects in CT Volumes](https://arxiv.org/abs/2507.10881)
*Roman Naeem,David Hagerman,Jennifer Alvén,Lennart Svensson,Fredrik Kahl*

Main category: cs.CV

TL;DR: A new model, Trexplorer Super, improves centerline tracking in 3D medical images and is validated on new synthetic and real-world datasets, outperforming existing methods. Performance on synthetic data doesn't always generalize to real data.


<details>
  <summary>Details</summary>
Motivation: Accurately tracking tubular tree structures like blood vessels and airways in 3D medical images is crucial for various downstream tasks, but existing models like Trexplorer struggle with issues like predicting duplicate branches and premature tracking termination. There is also a lack of public datasets for evaluating centerline tracking models.

Method: The paper introduces Trexplorer Super, an enhanced version of the Trexplorer model, designed for centerline tracking in 3D medical images. It also develops three centerline datasets (one synthetic, two real) with increasing difficulty to enable comprehensive evaluation.

Result: Trexplorer Super significantly improves performance compared to previous SOTA models on all developed datasets. The evaluation also revealed that high performance on synthetic data does not guarantee similar performance on real-world datasets.

Conclusion: Trexplorer Super outperforms previous SOTA models on every dataset, and strong performance on synthetic data does not necessarily translate to real datasets.

Abstract: Tubular tree structures, such as blood vessels and airways, are essential in
human anatomy and accurately tracking them while preserving their topology is
crucial for various downstream tasks. Trexplorer is a recurrent model designed
for centerline tracking in 3D medical images but it struggles with predicting
duplicate branches and terminating tracking prematurely. To address these
issues, we present Trexplorer Super, an enhanced version that notably improves
performance through novel advancements. However, evaluating centerline tracking
models is challenging due to the lack of public datasets. To enable thorough
evaluation, we develop three centerline datasets, one synthetic and two real,
each with increasing difficulty. Using these datasets, we conduct a
comprehensive evaluation of existing state-of-the-art (SOTA) models and compare
them with our approach. Trexplorer Super outperforms previous SOTA models on
every dataset. Our results also highlight that strong performance on synthetic
data does not necessarily translate to real datasets. The code and datasets are
available at https://github.com/RomStriker/Trexplorer-Super.

</details>


### [13] [Modernizing CNN-based Weather Forecast Model towards Higher Computational Efficiency](https://arxiv.org/abs/2507.10893)
*Minjong Cheon,Eunhan Goo,Su-Hyeon Shin,Muhammad Ahmed,Hyungjun Kim*

Main category: cs.CV

TL;DR: 提出了一种新的CNN天气预报模型KAI-a，它比Transformer模型更轻便、训练更快，同时达到了相似的准确性，并能很好地预测极端天气。


<details>
  <summary>Details</summary>
Motivation: 为了解决目前基于Transformer的天气预报模型所面临的训练复杂度和高资源需求问题，本研究旨在开发一种能够达到同等预测精度但计算需求显著降低的CNN模型。

Method: 本研究提出了一种现代化的、基于卷积神经网络（CNN）的全球天气预报模型KAI-a。该模型采用了尺度不变架构和InceptionNeXt块，并结合了地理物理感知设计，以适应地球系统数据的结构。KAI-a 模型拥有约700万个参数，在单块NVIDIA L40s GPU上仅需12小时即可完成训练。

Result: KAI-a 模型在传统的数值天气预报（NWP）系统方面达到了可比的准确性水平，与目前最先进的模型在中期天气预报方面性能相当，但其设计更为轻量级。此外，在2018年欧洲热浪和东亚夏季风的案例研究中，KAI-a 证明了其在捕捉极端天气事件方面的鲁棒性。

Conclusion: KAI-a 模型在保持与最先进模型相当的性能的同时，显著降低了计算需求，展示了其在捕捉极端事件方面的强大能力和实际应用价值。

Abstract: Recently, AI-based weather forecast models have achieved impressive advances.
These models have reached accuracy levels comparable to traditional NWP
systems, marking a significant milestone in data-driven weather prediction.
However, they mostly leverage Transformer-based architectures, which often
leads to high training complexity and resource demands due to the massive
parameter sizes. In this study, we introduce a modernized CNN-based model for
global weather forecasting that delivers competitive accuracy while
significantly reducing computational requirements. To present a systematic
modernization roadmap, we highlight key architectural enhancements across
multiple design scales from an earlier CNN-based approach. KAI-a incorporates a
scale-invariant architecture and InceptionNeXt-based blocks within a
geophysically-aware design, tailored to the structure of Earth system data.
Trained on the ERA5 daily dataset with 67 atmospheric variables, the model
contains about 7 million parameters and completes training in just 12 hours on
a single NVIDIA L40s GPU. Our evaluation shows that KAI-a matches the
performance of state-of-the-art models in medium-range weather forecasting,
while offering a significantly lightweight design. Furthermore, case studies on
the 2018 European heatwave and the East Asian summer monsoon demonstrate
KAI-a's robust skill in capturing extreme events, reinforcing its practical
utility.

</details>


### [14] [Commuting Distance Regularization for Timescale-Dependent Label Inconsistency in EEG Emotion Recognition](https://arxiv.org/abs/2507.10895)
*Xiaocong Zeng,Craig Michoski,Yan Pang,Dongyang Kuang*

Main category: cs.CV

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: In this work, we address the often-overlooked issue of Timescale Dependent
Label Inconsistency (TsDLI) in training neural network models for EEG-based
human emotion recognition. To mitigate TsDLI and enhance model generalization
and explainability, we propose two novel regularization strategies: Local
Variation Loss (LVL) and Local-Global Consistency Loss (LGCL). Both methods
incorporate classical mathematical principles--specifically, functions of
bounded variation and commute-time distances--within a graph theoretic
framework. Complementing our regularizers, we introduce a suite of new
evaluation metrics that better capture the alignment between temporally local
predictions and their associated global emotion labels. We validate our
approach through comprehensive experiments on two widely used EEG emotion
datasets, DREAMER and DEAP, across a range of neural architectures including
LSTM and transformer-based models. Performance is assessed using five distinct
metrics encompassing both quantitative accuracy and qualitative consistency.
Results consistently show that our proposed methods outperform state-of-the-art
baselines, delivering superior aggregate performance and offering a principled
trade-off between interpretability and predictive power under label
inconsistency. Notably, LVL achieves the best aggregate rank across all
benchmarked backbones and metrics, while LGCL frequently ranks the second,
highlighting the effectiveness of our framework.

</details>


### [15] [GeoDistill: Geometry-Guided Self-Distillation for Weakly Supervised Cross-View Localization](https://arxiv.org/abs/2507.10935)
*Shaowen Tong,Zimin Xia,Alexandre Alahi,Xuming He,Yujiao Shi*

Main category: cs.CV

TL;DR: GeoDistill利用教师-学生学习和视场感知的遮蔽，通过关注关键特征和忽略无纹理区域，提高了跨视图定位的准确性和鲁棒性，减少了对昂贵真实位姿标注的依赖。


<details>
  <summary>Details</summary>
Motivation: 跨视图定位对于自动导航和增强现实等大规模户外应用至关重要，但现有方法通常依赖于需要昂贵真实位姿标注的全监督学习。

Method: GeoDistill采用教师-学生学习框架，并利用视场（FoV）感知的遮蔽来增强局部特征学习，以实现鲁棒的跨视图定位。具体来说，教师模型对全景图像进行定位，而学生模型则从通过FoV感知的遮蔽创建的有限FoV对应图像中预测位置。通过使学生模型的预测与教师模型对齐，学生模型可以专注于车道线等关键特征，并忽略道路等无纹理区域。

Result: 实验表明，GeoDistill在不同框架下均显著提高了定位性能，并且其定位精度和不确定性减少，与查询图像是全景图还是有限FoV图无关。

Conclusion: GeoDistill是一个可扩展且高效的解决方案，可应对现实世界中的跨视图定位挑战，并引入了一种新颖的定向估计网络，无需精确的平面位置真实值即可预测相对方向。

Abstract: Cross-view localization, the task of estimating a camera's
3-degrees-of-freedom (3-DoF) pose by aligning ground-level images with
satellite images, is crucial for large-scale outdoor applications like
autonomous navigation and augmented reality. Existing methods often rely on
fully supervised learning, which requires costly ground-truth pose annotations.
In this work, we propose GeoDistill, a Geometry guided weakly supervised self
distillation framework that uses teacher-student learning with Field-of-View
(FoV)-based masking to enhance local feature learning for robust cross-view
localization. In GeoDistill, the teacher model localizes a panoramic image,
while the student model predicts locations from a limited FoV counterpart
created by FoV-based masking. By aligning the student's predictions with those
of the teacher, the student focuses on key features like lane lines and ignores
textureless regions, such as roads. This results in more accurate predictions
and reduced uncertainty, regardless of whether the query images are panoramas
or limited FoV images. Our experiments show that GeoDistill significantly
improves localization performance across different frameworks. Additionally, we
introduce a novel orientation estimation network that predicts relative
orientation without requiring precise planar position ground truth. GeoDistill
provides a scalable and efficient solution for real-world cross-view
localization challenges. Code and model can be found at
https://github.com/tongshw/GeoDistill.

</details>


### [16] [Graph Aggregation Prototype Learning for Semantic Change Detection in Remote Sensing](https://arxiv.org/abs/2507.10938)
*Zhengyi Xu,Haoran Wu,Wen Jiang,Jie Geng*

Main category: cs.CV

TL;DR: GAPL-SCD 通过图聚合原型学习和多任务优化来解决遥感数据中的语义变化检测问题，提高了准确性和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 由于 SCD 涉及多任务的联合优化，模型容易因特定任务的学习困难和冲突的梯度流而产生负迁移。

Method: 提出了一种名为 GAPL-SCD 的框架，该框架设计了一种多任务联合优化方法，以优化语义分割和变化检测的主要任务，以及图聚合原型学习的辅助任务。通过自查询多层次特征交互和双时相特征融合模块进一步增强了多尺度特征表示。

Result: 实验结果表明，该方法在 SECOND 和 Landsat-SCD 数据集上实现了最先进的性能，在 SCD 任务的准确性和鲁棒性方面有显著的提高。

Conclusion: GAPL-SCD 在 SECOND 和 Landsat-SCD 数据集上取得了最先进的性能，在 SCD 任务的准确性和鲁棒性方面有显著的提高。

Abstract: Semantic change detection (SCD) extends the binary change detection task to
provide not only the change locations but also the detailed "from-to"
categories in multi-temporal remote sensing data. Such detailed semantic
insights into changes offer considerable advantages for a wide array of
applications. However, since SCD involves the simultaneous optimization of
multiple tasks, the model is prone to negative transfer due to task-specific
learning difficulties and conflicting gradient flows. To address this issue, we
propose Graph Aggregation Prototype Learning for Semantic Change Detection in
remote sensing(GAPL-SCD). In this framework, a multi-task joint optimization
method is designed to optimize the primary task of semantic segmentation and
change detection, along with the auxiliary task of graph aggregation prototype
learning. Adaptive weight allocation and gradient rotation methods are used to
alleviate the conflict between training tasks and improve multi-task learning
capabilities. Specifically, the graph aggregation prototype learning module
constructs an interaction graph using high-level features. Prototypes serve as
class proxies, enabling category-level domain alignment across time points and
reducing interference from irrelevant changes. Additionally, the proposed
self-query multi-level feature interaction and bi-temporal feature fusion
modules further enhance multi-scale feature representation, improving
performance in complex scenes. Experimental results on the SECOND and
Landsat-SCD datasets demonstrate that our method achieves state-of-the-art
performance, with significant improvements in accuracy and robustness for SCD
task.

</details>


### [17] [Robust ID-Specific Face Restoration via Alignment Learning](https://arxiv.org/abs/2507.10943)
*Yushun Fang,Lu Liu,Xiang Gao,Qiang Hu,Ning Cao,Jianghe Cui,Gang Chen,Xiaoyun Zhang*

Main category: cs.CV

TL;DR: RIDFR是一个新颖的、特定身份的人脸恢复框架，利用扩散模型和两个并行的条件模块（内容注入和身份注入）来解决身份不确定性问题。通过对齐学习，它能有效抑制无关的人脸语义，生成高保真度的恢复结果。


<details>
  <summary>Details</summary>
Motivation: 为了解决现有基于扩散模型的人脸恢复方法在处理身份模糊输入和随机生成过程时引入的身份不确定性问题。

Method: RIDFR框架采用预训练的扩散模型，结合内容注入模块（输入降级图像）和身份注入模块（整合指定身份信息）。此外，还引入了对齐学习，通过对齐同一身份的多个参考人脸恢复结果，以抑制与身份无关的人脸语义（如姿态、表情、妆容、发型）的干扰。

Result: 实验证明，RIDFR框架在人脸恢复任务中，相比现有最先进方法，能够生成高质量、特定身份且身份保真度高的人脸恢复结果，并展现出强大的鲁棒性。

Conclusion: RIDFR框架在人脸恢复任务中表现优于现有最先进方法，能够生成高质量、特定身份且身份保真度高的人脸恢复结果，并展现出强大的鲁棒性。

Abstract: The latest developments in Face Restoration have yielded significant
advancements in visual quality through the utilization of diverse diffusion
priors. Nevertheless, the uncertainty of face identity introduced by
identity-obscure inputs and stochastic generative processes remains unresolved.
To address this challenge, we present Robust ID-Specific Face Restoration
(RIDFR), a novel ID-specific face restoration framework based on diffusion
models. Specifically, RIDFR leverages a pre-trained diffusion model in
conjunction with two parallel conditioning modules. The Content Injection
Module inputs the severely degraded image, while the Identity Injection Module
integrates the specific identity from a given image. Subsequently, RIDFR
incorporates Alignment Learning, which aligns the restoration results from
multiple references with the same identity in order to suppress the
interference of ID-irrelevant face semantics (e.g. pose, expression, make-up,
hair style). Experiments demonstrate that our framework outperforms the
state-of-the-art methods, reconstructing high-quality ID-specific results with
high identity fidelity and demonstrating strong robustness.

</details>


### [18] [Women Sport Actions Dataset for Visual Classification Using Small Scale Training Data](https://arxiv.org/abs/2507.10969)
*Palash Ray,Mahuya Sasmal,Asish Bera*

Main category: cs.CV

TL;DR: 本研究提出了WomenSports数据集和一种新的CNN模型，用于女性体育动作分类，并在WomenSports数据集上取得了89.15%的准确率。


<details>
  <summary>Details</summary>
Motivation: 现有的体育动作识别数据集缺乏代表女性运动的数据，特别是包含足够多的类内和类间变化的女性运动数据。为了解决这个问题，本研究创建了一个新的名为WomenSports的数据集。

Method: 提出了一种基于CNN和通道注意力机制的深度学习模型，用于体育动作分类。实验在三个体育数据集和一个舞蹈数据集上进行了验证。

Result: 在提出的WomenSports数据集上，使用ResNet-50的深度学习方法达到了89.15%的top-1分类准确率。该模型在其他三个体育数据集和一个舞蹈数据集上也表现出良好的泛化能力。

Conclusion: 本研究提出了一个名为WomenSports的新数据集，并设计了一种基于CNN和通道注意力机制的方法，用于女性体育动作的分类。实验结果表明，该方法在多个数据集上表现优异，在WomenSports数据集上达到了89.15%的准确率。

Abstract: Sports action classification representing complex body postures and
player-object interactions is an emerging area in image-based sports analysis.
Some works have contributed to automated sports action recognition using
machine learning techniques over the past decades. However, sufficient image
datasets representing women sports actions with enough intra- and inter-class
variations are not available to the researchers. To overcome this limitation,
this work presents a new dataset named WomenSports for women sports
classification using small-scale training data. This dataset includes a variety
of sports activities, covering wide variations in movements, environments, and
interactions among players. In addition, this study proposes a convolutional
neural network (CNN) for deep feature extraction. A channel attention scheme
upon local contextual regions is applied to refine and enhance feature
representation. The experiments are carried out on three different sports
datasets and one dance dataset for generalizing the proposed algorithm, and the
performances on these datasets are noteworthy. The deep learning method
achieves 89.15% top-1 classification accuracy using ResNet-50 on the proposed
WomenSports dataset, which is publicly available for research at Mendeley Data.

</details>


### [19] [Conceptualizing Multi-scale Wavelet Attention and Ray-based Encoding for Human-Object Interaction Detection](https://arxiv.org/abs/2507.10977)
*Quan Bi Pay,Vishnu Monn Baskaran,Junn Yong Loo,KokSheik Wong,Simon See*

Main category: cs.CV

TL;DR: 提出了一种新颖的基于小波注意力和射线编码器的 HOI 检测架构，解决了现有方法的效率和性能问题，并在基准测试中取得了有希望的结果。


<details>
  <summary>Details</summary>
Motivation: 现有 HOI 检测器在高效提供可靠预测方面存在困难，它们依赖于资源密集型的训练方法和效率低下的架构。

Method: 我们提出了一个类似小波注意力（wavelet attention-like）的骨干网络和一个新颖的基于射线（ray-based）的编码器架构，专门用于 HOI 检测。小波骨干网络通过聚合来自不同卷积滤波器提取的低阶和高阶交互的区分性特征，解决了表达中阶交互的局限性。同时，基于射线的编码器通过优化解码器对相关感兴趣区域的关注并减轻计算开销，实现了多尺度注意。我们的解码器利用可学习射线源的衰减强度，使查询嵌入与强化的感兴趣区域对齐，从而实现准确的预测。

Result: 实验结果表明，我们提出的架构在 HOI 检测任务上具有潜力。

Conclusion: 在 ImageNet 和 HICO-DET 等基准数据集上的实验结果表明，我们提出的架构具有潜力。

Abstract: Human-object interaction (HOI) detection is essential for accurately
localizing and characterizing interactions between humans and objects,
providing a comprehensive understanding of complex visual scenes across various
domains. However, existing HOI detectors often struggle to deliver reliable
predictions efficiently, relying on resource-intensive training methods and
inefficient architectures. To address these challenges, we conceptualize a
wavelet attention-like backbone and a novel ray-based encoder architecture
tailored for HOI detection. Our wavelet backbone addresses the limitations of
expressing middle-order interactions by aggregating discriminative features
from the low- and high-order interactions extracted from diverse convolutional
filters. Concurrently, the ray-based encoder facilitates multi-scale attention
by optimizing the focus of the decoder on relevant regions of interest and
mitigating computational overhead. As a result of harnessing the attenuated
intensity of learnable ray origins, our decoder aligns query embeddings with
emphasized regions of interest for accurate predictions. Experimental results
on benchmark datasets, including ImageNet and HICO-DET, showcase the potential
of our proposed architecture. The code is publicly available at
[https://github.com/henry-pay/RayEncoder].

</details>


### [20] [Mind the Gap: Bridging Occlusion in Gait Recognition via Residual Gap Correction](https://arxiv.org/abs/2507.10978)
*Ayush Gupta,Siyuan Huang,Rama Chellappa*

Main category: cs.CV

TL;DR: RG-Gait通过残差学习解决遮挡步态识别问题，在不影响整体识别准确性的前提下，提高了遮挡步态序列的识别性能。


<details>
  <summary>Details</summary>
Motivation: 当前大多数步态识别研究未能解决遮挡问题，即使有部分研究解决了该问题，但它们需要成对的遮挡和整体序列，这在现实世界中难以收集。此外，这些方法在处理遮挡问题时会牺牲在整体输入上的性能。

Method: RG-Gait方法将遮挡步态识别问题建模为一个残差学习任务，将遮挡步态签名概念化为与整体步态表示的残差偏差。提出了一种能够自适应集成所学残差的新型网络。

Result: RG-Gait方法在Gait3D、GREW和BRIAR数据集上表现出显著的性能提升，成功解决了遮挡步态识别的挑战，同时保持了对整体步态输入的识别准确性。

Conclusion: RG-Gait通过将遮挡步态建模为整体步态表示的残差偏差，并自适应地集成所学残差，成功地提高了遮挡步态序列的性能，同时保留了整体识别精度。该方法在Gait3D、GREW和BRIAR数据集上进行了评估，证明了学习残差是解决具有整体保留能力的遮挡步态识别的有效技术。

Abstract: Gait is becoming popular as a method of person re-identification because of
its ability to identify people at a distance. However, most current works in
gait recognition do not address the practical problem of occlusions. Among
those which do, some require paired tuples of occluded and holistic sequences,
which are impractical to collect in the real world. Further, these approaches
work on occlusions but fail to retain performance on holistic inputs. To
address these challenges, we propose RG-Gait, a method for residual correction
for occluded gait recognition with holistic retention. We model the problem as
a residual learning task, conceptualizing the occluded gait signature as a
residual deviation from the holistic gait representation. Our proposed network
adaptively integrates the learned residual, significantly improving performance
on occluded gait sequences without compromising the holistic recognition
accuracy. We evaluate our approach on the challenging Gait3D, GREW and BRIAR
datasets and show that learning the residual can be an effective technique to
tackle occluded gait recognition with holistic retention.

</details>


### [21] [SpaRTAN: Spatial Reinforcement Token-based Aggregation Network for Visual Recognition](https://arxiv.org/abs/2507.10999)
*Quan Bi Pay,Vishnu Monn Baskaran,Junn Yong Loo,KokSheik Wong,Simon See*

Main category: cs.CV

TL;DR: SpaRTAN是一种轻量级网络架构，通过多感受野卷积核和通道聚合模块提高空间和通道信息的处理效率，实现了优异的参数效率和性能。


<details>
  <summary>Details</summary>
Motivation: 现有的CNN和Transformer架构存在简单性偏见，偏爱简单特征而非复杂结构表示。此外，现代CNN中的MLP-like块存在显著的信息冗余问题，需要高扩展率来维持性能。

Method: 提出了一种名为SpaRTAN的轻量级架构设计，通过采用具有不同感受野（通过核大小和扩张因子控制）的卷积核来捕捉多阶空间特征，并使用基于波的通道聚合模块来调制和增强像素交互，减少通道冗余。

Result: SpaRTAN在ImageNet-1k上实现了77.7%的准确率，仅使用3.8M参数和约1.0 GFLOPs。在COCO基准测试中，其AP达到了50.0%，参数量为21.5M，优于先前基准1.2%。

Conclusion: SpaRTAN通过采用具有不同感受野的卷积核和基于波的通道聚合模块，有效捕获多阶空间特征并减少通道冗余，在参数效率和性能方面均表现出色，在ImageNet-1k和COCO基准测试中均取得了优于先前方法的成果。

Abstract: The resurgence of convolutional neural networks (CNNs) in visual recognition
tasks, exemplified by ConvNeXt, has demonstrated their capability to rival
transformer-based architectures through advanced training methodologies and
ViT-inspired design principles. However, both CNNs and transformers exhibit a
simplicity bias, favoring straightforward features over complex structural
representations. Furthermore, modern CNNs often integrate MLP-like blocks akin
to those in transformers, but these blocks suffer from significant information
redundancies, necessitating high expansion ratios to sustain competitive
performance. To address these limitations, we propose SpaRTAN, a lightweight
architectural design that enhances spatial and channel-wise information
processing. SpaRTAN employs kernels with varying receptive fields, controlled
by kernel size and dilation factor, to capture discriminative multi-order
spatial features effectively. A wave-based channel aggregation module further
modulates and reinforces pixel interactions, mitigating channel-wise
redundancies. Combining the two modules, the proposed network can efficiently
gather and dynamically contextualize discriminative features. Experimental
results in ImageNet and COCO demonstrate that SpaRTAN achieves remarkable
parameter efficiency while maintaining competitive performance. In particular,
on the ImageNet-1k benchmark, SpaRTAN achieves 77. 7% accuracy with only 3.8M
parameters and approximately 1.0 GFLOPs, demonstrating its ability to deliver
strong performance through an efficient design. On the COCO benchmark, it
achieves 50.0% AP, surpassing the previous benchmark by 1.2% with only 21.5M
parameters. The code is publicly available at
[https://github.com/henry-pay/SpaRTAN].

</details>


### [22] [Bridge Feature Matching and Cross-Modal Alignment with Mutual-filtering for Zero-shot Anomaly Detection](https://arxiv.org/abs/2507.11003)
*Yuhu Bai,Jiangning Zhang,Yunkang Cao,Guangyuan Lu,Qingdong He,Xiangtai Li,Guanzhong Tian*

Main category: cs.CV

TL;DR: FiSeCLIP是一种新提出的用于零样本异常检测（ZSAD）的方法，它利用CLIP的跨模态能力，通过批内图像的相互参考和文本过滤来提高检测精度，并在MVTec-AD等基准测试中取得了领先的性能。


<details>
  <summary>Details</summary>
Motivation: 为了解决零样本异常检测（ZSAD）中罕见类别的重要性和实际应用需求，并结合CLIP的特征匹配和跨模态对齐能力。

Method: FiSeCLIP结合了特征匹配和跨模态对齐，利用同一批次中的其他图像作为参考信息，并通过文本信息过滤噪声特征，同时利用CLIP恢复局部语义相关性以进行细粒度异常检测。

Result: FiSeCLIP在异常分类和分割方面均取得了优越性能，例如在MVTec-AD数据集上，其分割指标AU-ROC和F1-max分别比AdaCLIP高出4.6%和5.7%。

Conclusion: FiSeCLIP在异常检测基准测试中表现出色，在MVTec-AD上，其分割指标AU-ROC和F1-max分别优于SOTA AdaCLIP 4.6%和5.7%，为该方向奠定了更强的基线。

Abstract: With the advent of vision-language models (e.g., CLIP) in zero- and few-shot
settings, CLIP has been widely applied to zero-shot anomaly detection (ZSAD) in
recent research, where the rare classes are essential and expected in many
applications. This study introduces \textbf{FiSeCLIP} for ZSAD with
training-free \textbf{CLIP}, combining the feature matching with the
cross-modal alignment. Testing with the entire dataset is impractical, while
batch-based testing better aligns with real industrial needs, and images within
a batch can serve as mutual reference points. Accordingly, FiSeCLIP utilizes
other images in the same batch as reference information for the current image.
However, the lack of labels for these references can introduce ambiguity, we
apply text information to \textbf{fi}lter out noisy features. In addition, we
further explore CLIP's inherent potential to restore its local
\textbf{se}mantic correlation, adapting it for fine-grained anomaly detection
tasks to enable a more accurate filtering process. Our approach exhibits
superior performance for both anomaly classification and segmentation on
anomaly detection benchmarks, building a stronger baseline for the direction,
e.g., on MVTec-AD, FiSeCLIP outperforms the SOTA AdaCLIP by
+4.6\%$\uparrow$/+5.7\%$\uparrow$ in segmentation metrics AU-ROC/$F_1$-max.

</details>


### [23] [Semantically Informed Salient Regions Guided Radiology Report Generation](https://arxiv.org/abs/2507.11015)
*Zeyi Hou,Zeqiang Wei,Ruixin Yan,Ning Lang,Xiuzhuang Zhou*

Main category: cs.CV

TL;DR: SISRNet通过关注医学上重要的区域来提高胸部X光片报告的准确性，解决了现有方法的数据偏见问题。


<details>
  <summary>Details</summary>
Motivation: 现有的自动放射学报告生成方法由于放射学图像中存在数据偏见，生成的报告虽然流畅但可能在医学上不准确，限制了其临床应用。

Method: 提出了一种名为SISRNet的报告生成方法，该方法通过细粒度的跨模态语义显式识别具有医学关键特征的显著区域，并在图像建模和报告生成过程中系统地关注这些高信息区域。

Result: SISRNet有效捕捉细微的异常发现，减轻了数据偏见的不利影响，并最终生成了临床准确的报告。

Conclusion: SISRNet在IU-Xray和MIMIC-CXR数据集上表现优于现有方法，能够生成临床准确的报告。

Abstract: Recent advances in automated radiology report generation from chest X-rays
using deep learning algorithms have the potential to significantly reduce the
arduous workload of radiologists. However, due to the inherent massive data
bias in radiology images, where abnormalities are typically subtle and sparsely
distributed, existing methods often produce fluent yet medically inaccurate
reports, limiting their applicability in clinical practice. To address this
issue effectively, we propose a Semantically Informed Salient Regions-guided
(SISRNet) report generation method. Specifically, our approach explicitly
identifies salient regions with medically critical characteristics using
fine-grained cross-modal semantics. Then, SISRNet systematically focuses on
these high-information regions during both image modeling and report
generation, effectively capturing subtle abnormal findings, mitigating the
negative impact of data bias, and ultimately generating clinically accurate
reports. Compared to its peers, SISRNet demonstrates superior performance on
widely used IU-Xray and MIMIC-CXR datasets.

</details>


### [24] [Human-Guided Shade Artifact Suppression in CBCT-to-MDCT Translation via Schrödinger Bridge with Conditional Diffusion](https://arxiv.org/abs/2507.11025)
*Sung Ho Kang,Hyun-Cheol Park*

Main category: cs.CV

TL;DR: 我们提出了一种基于薛定谔桥（SB）的框架，用于CBCT到MDCT的翻译，它结合了GAN和人类指导的扩散模型，并通过二元反馈进行条件化，以实现解剖保真度和感知可控性。


<details>
  <summary>Details</summary>
Motivation: 为了实现CBCT到MDCT的翻译，并解决传统方法在解剖保真度和感知可控性方面的不足，同时整合人类的偏好。

Method: 提出了一种新颖的CBCT到MDCT翻译框架，该框架基于薛定谔桥（SB）公式，结合了GAN先验和人类指导的条件扩散。通过集成二元人类反馈和无分类器指导（CFG），并采用迭代优化和基于锦标赛的偏好选择，在没有奖励模型的情况下内化了人类偏好。

Result: 该方法选择性地衰减了关键解剖区域的伪影，同时保留了精细的结构细节，并在临床数据集上实现了优越的定量评估结果，优于先前的GAN和基于微调的反馈方法，且采样步数少。

Conclusion: 该框架通过选择性衰减伪影并保留细节，在临床数据集上实现了优于先前方法的CBCT到MDCT翻译，同时在RMSE、SSIM、LPIPS和Dice指标上表现出优越的性能，且仅需10个采样步。

Abstract: We present a novel framework for CBCT-to-MDCT translation, grounded in the
Schrodinger Bridge (SB) formulation, which integrates GAN-derived priors with
human-guided conditional diffusion. Unlike conventional GANs or diffusion
models, our approach explicitly enforces boundary consistency between CBCT
inputs and pseudo targets, ensuring both anatomical fidelity and perceptual
controllability. Binary human feedback is incorporated via classifier-free
guidance (CFG), effectively steering the generative process toward clinically
preferred outcomes. Through iterative refinement and tournament-based
preference selection, the model internalizes human preferences without relying
on a reward model. Subtraction image visualizations reveal that the proposed
method selectively attenuates shade artifacts in key anatomical regions while
preserving fine structural detail. Quantitative evaluations further demonstrate
superior performance across RMSE, SSIM, LPIPS, and Dice metrics on clinical
datasets -- outperforming prior GAN- and fine-tuning-based feedback methods --
while requiring only 10 sampling steps. These findings underscore the
effectiveness and efficiency of our framework for real-time, preference-aligned
medical image translation.

</details>


### [25] [Personalized OVSS: Understanding Personal Concept in Open-Vocabulary Semantic Segmentation](https://arxiv.org/abs/2507.11030)
*Sunghyun Park,Jungsoo Lee,Shubhankar Borse,Munawar Hayat,Sungha Choi,Kyuwoong Hwang,Fatih Porikli*

Main category: cs.CV

TL;DR: 本研究提出了一种新的个性化开放词汇语义分割任务和一种基于文本提示调优的插件方法，通过负掩模提议和注入视觉嵌入来提升模型识别用户特定物体（如“我的马克杯”）的能力，同时保持了原有开放词汇语义分割的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的开放词汇语义分割（OVSS）方法无法理解用户自定义的文本描述（例如，“我的马克杯”），导致在分割用户特定兴趣区域时遇到困难，尤其是在图像包含多个相似物体时，难以区分特定物体（例如，“我的马克杯”和“多个马克杯”）。

Method: 提出了一种新颖的个性化开放词汇语义分割任务，并采用基于文本提示调优的插件方法，利用少量图像和掩模对来识别个性化视觉概念，同时保留了原始开放词汇语义分割的性能。该方法通过“负掩模提议”来捕捉个性化概念之外的视觉概念，并通过将个性化概念的视觉嵌入注入文本提示来丰富其表示。

Result: 在新增的个性化开放词汇语义分割数据集（包括FSS$^{	ext{per}}$、CUB$^{	ext{per}}$和ADE$^{	ext{per}}$）上，证明了所提出方法的优越性。

Conclusion: 所提出的方法能够有效提升个性化开放词汇语义分割的性能，并且在不损害原始开放词汇语义分割性能的情况下，通过负掩模提议和视觉概念嵌入来丰富文本提示的表示。

Abstract: While open-vocabulary semantic segmentation (OVSS) can segment an image into
semantic regions based on arbitrarily given text descriptions even for classes
unseen during training, it fails to understand personal texts (e.g., `my mug
cup') for segmenting regions of specific interest to users. This paper
addresses challenges like recognizing `my mug cup' among `multiple mug cups'.
To overcome this challenge, we introduce a novel task termed
\textit{personalized open-vocabulary semantic segmentation} and propose a text
prompt tuning-based plug-in method designed to recognize personal visual
concepts using a few pairs of images and masks, while maintaining the
performance of the original OVSS. Based on the observation that reducing false
predictions is essential when applying text prompt tuning to this task, our
proposed method employs `negative mask proposal' that captures visual concepts
other than the personalized concept. We further improve the performance by
enriching the representation of text prompts by injecting visual embeddings of
the personal concept into them. This approach enhances personalized OVSS
without compromising the original OVSS performance. We demonstrate the
superiority of our method on our newly established benchmarks for this task,
including FSS$^\text{per}$, CUB$^\text{per}$, and ADE$^\text{per}$.

</details>


### [26] [Efficient Dual-domain Image Dehazing with Haze Prior Perception](https://arxiv.org/abs/2507.11035)
*Lirong Zheng,Yanshan Li,Rui Yu,Kaihao Zhang*

Main category: cs.CV

TL;DR: DGFDNet是一种新型的双域去雾网络，通过结合空间域和频率域的优势，并利用暗通道先验和多级特征融合，实现了高效、鲁棒的去雾效果，尤其在复杂场景下表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有的基于Transformer的模型虽然具有强大的全局建模能力，但计算成本高，限制了其实时应用。现有方法主要依赖于空间域特征来捕获长距离依赖关系，计算成本高且在复杂雾霾条件下不足。一些方法引入了频域线索，但空间和频域分支之间的弱耦合限制了整体性能。

Method: 提出了一种名为DGFDNet的新型双域框架，该框架跨空间和频率域执行物理引导的退化对齐。核心的DGFDBlock包含感知频率调制器（HAFM）和多级门控聚合模块（MGAM）。HAFM从暗通道先验生成像素级雾霾置信图，以自适应地增强雾霾相关的频率分量。MGAM通过不同的卷积核和混合门控机制融合多尺度特征以恢复精细的结构细节。此外，先验校正引导分支（PCGB）引入了闭环反馈机制，通过中间去雾特征迭代地优化先验，提高了雾霾定位精度。

Result: DGFDNet在四个基准雾霾数据集上实现了最先进的性能，具有出色的鲁棒性和实时效率。

Conclusion: DGFDNet在四个基准雾霾数据集上实现了最先进的性能，具有出色的鲁棒性和实时效率。

Abstract: Transformer-based models exhibit strong global modeling capabilities in
single-image dehazing, but their high computational cost limits real-time
applicability. Existing methods predominantly rely on spatial-domain features
to capture long-range dependencies, which are computationally expensive and
often inadequate under complex haze conditions. While some approaches introduce
frequency-domain cues, the weak coupling between spatial and frequency branches
limits the overall performance. To overcome these limitations, we propose the
Dark Channel Guided Frequency-aware Dehazing Network (DGFDNet), a novel
dual-domain framework that performs physically guided degradation alignment
across spatial and frequency domains. At its core, the DGFDBlock comprises two
key modules: 1) the Haze-Aware Frequency Modulator (HAFM), which generates a
pixel-level haze confidence map from dark channel priors to adaptively enhance
haze-relevant frequency components, thereby achieving global degradation-aware
spectral modulation; 2) the Multi-level Gating Aggregation Module (MGAM), which
fuses multi-scale features through diverse convolutional kernels and hybrid
gating mechanisms to recover fine structural details. Additionally, a Prior
Correction Guidance Branch (PCGB) incorporates a closed-loop feedback
mechanism, enabling iterative refinement of the prior by intermediate dehazed
features and significantly improving haze localization accuracy, especially in
challenging outdoor scenes. Extensive experiments on four benchmark haze
datasets demonstrate that DGFDNet achieves state-of-the-art performance with
superior robustness and real-time efficiency. Code is available at:
https://github.com/Dilizlr/DGFDNet.

</details>


### [27] [A Multi-View High-Resolution Foot-Ankle Complex Point Cloud Dataset During Gait for Occlusion-Robust 3D Completion](https://arxiv.org/abs/2507.11037)
*Jie-Wen Li,Zi-Han Ye,Qingyuan Zhou,Jiayi Song,Ying He,Ben Fei,Wen-Ming Chen*

Main category: cs.CV

TL;DR: FootGait3D是一个包含8403个点云帧的新型脚踝运动数据集，用于评估3D点云补全方法，以应对步态分析中的遮挡问题，促进生物力学和临床应用研究。


<details>
  <summary>Details</summary>
Motivation: 为了解决在动态步态条件下收集脚踝区域精确表面几何数据所面临的遮挡和视角限制的挑战，并为脚踝区域的详细建模提供更高的数据粒度。

Method: 使用定制的五摄像头深度传感系统，从46名受试者在自然步态下收集了高分辨率脚踝点云数据，每个帧包含完整的5视图重建和部分点云，以模拟不同程度的遮挡和视角变化。

Result: 成功构建了一个包含8403个点云帧的数据集（FootGait3D），能够用于评估3D点云补全方法在不同遮挡程度下的表现，并为相关研究提供了有价值的测试平台。

Conclusion: FootGait3D是一个包含8403个点云帧的新型多视图数据集，专门用于脚踝区域的精细运动数据建模，可以促进生物力学、临床步态分析、假肢设计和机器人技术等领域的研究。

Abstract: The kinematics analysis of foot-ankle complex during gait is essential for
advancing biomechanical research and clinical assessment. Collecting accurate
surface geometry data from the foot and ankle during dynamic gait conditions is
inherently challenging due to swing foot occlusions and viewing limitations.
Thus, this paper introduces FootGait3D, a novel multi-view dataset of
high-resolution ankle-foot surface point clouds captured during natural gait.
Different from existing gait datasets that typically target whole-body or
lower-limb motion, FootGait3D focuses specifically on the detailed modeling of
the ankle-foot region, offering a finer granularity of motion data. To address
this, FootGait3D consists of 8,403 point cloud frames collected from 46
subjects using a custom five-camera depth sensing system. Each frame includes a
complete 5-view reconstruction of the foot and ankle (serving as ground truth)
along with partial point clouds obtained from only four, three, or two views.
This structured variation enables rigorous evaluation of 3D point cloud
completion methods under varying occlusion levels and viewpoints. Our dataset
is designed for shape completion tasks, facilitating the benchmarking of
state-of-the-art single-modal (e.g., PointTr, SnowflakeNet, Anchorformer) and
multi-modal (e.g., SVDFormer, PointSea, CSDN) completion networks on the
challenge of recovering the full foot geometry from occluded inputs. FootGait3D
has significant potential to advance research in biomechanics and multi-segment
foot modeling, offering a valuable testbed for clinical gait analysis,
prosthetic design, and robotics applications requiring detailed 3D models of
the foot during motion. The dataset is now available at
https://huggingface.co/datasets/ljw285/FootGait3D.

</details>


### [28] [Combining Transformers and CNNs for Efficient Object Detection in High-Resolution Satellite Imagery](https://arxiv.org/abs/2507.11040)
*Nicolas Drapier,Aladine Chetouani,Aurélien Chateigner*

Main category: cs.CV

TL;DR: GLOD, a transformer-first architecture with Swin Transformer, UpConvMixer, and Fusion Blocks, achieves state-of-the-art results in satellite imagery object detection on xView.


<details>
  <summary>Details</summary>
Motivation: To address challenges in high-resolution satellite imagery object detection by developing a transformer-first architecture that improves feature extraction, upsampling, and multi-scale feature integration.

Method: GLOD is a transformer-first architecture using a Swin Transformer as backbone, UpConvMixer blocks for upsampling, and Fusion Blocks for multi-scale feature integration. It features asymmetric fusion with CBAM attention and a multi-path head design.

Result: Achieved 32.95% on xView, outperforming SOTA methods by 11.46%.

Conclusion: GLOD in satellite imagery object detection achieved 32.95% on xView, outperforming SOTA methods by 11.46%. Key innovations include asymmetric fusion with CBAM attention and a multi-path head design capturing objects across scales.

Abstract: We present GLOD, a transformer-first architecture for object detection in
high-resolution satellite imagery. GLOD replaces CNN backbones with a Swin
Transformer for end-to-end feature extraction, combined with novel UpConvMixer
blocks for robust upsampling and Fusion Blocks for multi-scale feature
integration. Our approach achieves 32.95\% on xView, outperforming SOTA methods
by 11.46\%. Key innovations include asymmetric fusion with CBAM attention and a
multi-path head design capturing objects across scales. The architecture is
optimized for satellite imagery challenges, leveraging spatial priors while
maintaining computational efficiency.

</details>


### [29] [Alleviating Textual Reliance in Medical Language-guided Segmentation via Prototype-driven Semantic Approximation](https://arxiv.org/abs/2507.11055)
*Shuchang Ye,Usman Naseem,Mingyuan Meng,Jinman Kim*

Main category: cs.CV

TL;DR: ProLearn通过原型驱动语义近似（PSA）减轻了医学图像分割对文本的依赖，即使在文本数据有限的情况下也能提升分割性能。


<details>
  <summary>Details</summary>
Motivation: 现有的医学语言引导分割方法虽然在提高图像分割精度方面表现出色，但其对成对图像-文本输入的依赖性限制了其在数据不完整或需要实时分析的场景中的应用。具体来说，许多数据集缺乏成对的报告，导致大量仅包含图像的数据无法得到有效利用；同时，在临床实践中，分割通常先于报告生成，这使得在缺乏文本报告的情况下进行推理成为一个挑战。

Method: ProLearn提出了一种新颖的原型驱动学习框架，利用原型驱动语义近似（PSA）模块来近似文本输入中的语义引导。PSA首先通过从文本报告中提取分割相关的语义来初始化一个离散且紧凑的原型空间，然后支持一种查询和响应机制，为没有文本输入的图像近似语义引导，从而减轻对文本的依赖。

Result: 实验结果表明，在有限的文本可用情况下，ProLearn在QaTa-COV19、MosMedData+和Kvasir-SEG等数据集上表现优于最先进的语言引导方法。

Conclusion: ProLearn框架通过其核心的ProLearn原型驱动语义近似（PSA）模块，成功地减轻了对文本的依赖，为医学图像分割领域开辟了新的可能性。

Abstract: Medical language-guided segmentation, integrating textual clinical reports as
auxiliary guidance to enhance image segmentation, has demonstrated significant
improvements over unimodal approaches. However, its inherent reliance on paired
image-text input, which we refer to as ``textual reliance", presents two
fundamental limitations: 1) many medical segmentation datasets lack paired
reports, leaving a substantial portion of image-only data underutilized for
training; and 2) inference is limited to retrospective analysis of cases with
paired reports, limiting its applicability in most clinical scenarios where
segmentation typically precedes reporting. To address these limitations, we
propose ProLearn, the first Prototype-driven Learning framework for
language-guided segmentation that fundamentally alleviates textual reliance. At
its core, in ProLearn, we introduce a novel Prototype-driven Semantic
Approximation (PSA) module to enable approximation of semantic guidance from
textual input. PSA initializes a discrete and compact prototype space by
distilling segmentation-relevant semantics from textual reports. Once
initialized, it supports a query-and-respond mechanism which approximates
semantic guidance for images without textual input, thereby alleviating textual
reliance. Extensive experiments on QaTa-COV19, MosMedData+ and Kvasir-SEG
demonstrate that ProLearn outperforms state-of-the-art language-guided methods
when limited text is available.

</details>


### [30] [Robust 3D-Masked Part-level Editing in 3D Gaussian Splatting with Regularized Score Distillation Sampling](https://arxiv.org/abs/2507.11061)
*Hayeon Kim,Ji Ha Jang,Se Young Chun*

Main category: cs.CV

TL;DR: RoMaP 是一个创新的局部 3D 高斯编辑框架，通过 3D-GALP 模块提供准确的 3D 掩码，并通过正则化 SDS 损失实现精确、灵活的部分级编辑，解决了现有方法在局部编辑方面的挑战。


<details>
  <summary>Details</summary>
Motivation: 尽管神经渲染和实例级编辑模型在 3D 内容创建方面取得了进展，但在高斯泼溅 (Gaussian Splatting) 等技术中，精确的局部 3D 编辑仍然是一个挑战，这主要是由于多视图 2D 部分分割不一致以及评分蒸馏采样 (SDS) 损失的固有模糊性。

Method: RoMaP 框架通过两个关键模块实现精确的局部 3D 编辑：1. 3D-GALP 模块，利用球谐 (SH) 系数来处理视角相关的标签变化和软标签特性，生成准确且跨视点一致的 3D 掩码。2. 正则化 SDS 损失，结合了标准 SDS 损失、L1 锚点损失（通过 SLaMP 编辑方法实现）、高斯先验移除以及鲁棒的 3D 掩码，以确保编辑的精确性和上下文一致性。

Result: 实验结果表明，RoMaP 在定性和定量方面均实现了最先进的局部 3D 编辑效果，能够实现更鲁棒、更灵活的 3D 高斯局部编辑。

Conclusion: RoMaP 在重建和生成的 3D 高斯场景和对象上实现了最先进的局部 3D 编辑，在定性和定量上都优于现有方法。

Abstract: Recent advances in 3D neural representations and instance-level editing
models have enabled the efficient creation of high-quality 3D content. However,
achieving precise local 3D edits remains challenging, especially for Gaussian
Splatting, due to inconsistent multi-view 2D part segmentations and inherently
ambiguous nature of Score Distillation Sampling (SDS) loss. To address these
limitations, we propose RoMaP, a novel local 3D Gaussian editing framework that
enables precise and drastic part-level modifications. First, we introduce a
robust 3D mask generation module with our 3D-Geometry Aware Label Prediction
(3D-GALP), which uses spherical harmonics (SH) coefficients to model
view-dependent label variations and soft-label property, yielding accurate and
consistent part segmentations across viewpoints. Second, we propose a
regularized SDS loss that combines the standard SDS loss with additional
regularizers. In particular, an L1 anchor loss is introduced via our Scheduled
Latent Mixing and Part (SLaMP) editing method, which generates high-quality
part-edited 2D images and confines modifications only to the target region
while preserving contextual coherence. Additional regularizers, such as
Gaussian prior removal, further improve flexibility by allowing changes beyond
the existing context, and robust 3D masking prevents unintended edits.
Experimental results demonstrate that our RoMaP achieves state-of-the-art local
3D editing on both reconstructed and generated Gaussian scenes and objects
qualitatively and quantitatively, making it possible for more robust and
flexible part-level 3D Gaussian editing.

</details>


### [31] [Joint angle model based learning to refine kinematic human pose estimation](https://arxiv.org/abs/2507.11075)
*Chang Peng,Yifei Zhou,Huifeng Xi,Shiqing Huang,Chuangye Chen,Jianming Yang,Bao Yang,Zhenyu Jiang*

Main category: cs.CV

TL;DR: 本文提出了一种新颖的基于关节角度建模的方法，通过生成高质量数据集并利用双向循环网络进行后处理，有效解决了无标记人体姿态估计中的关键点识别错误和轨迹波动问题，并在具有挑战性的场景中取得了优于现有方法的性能。


<details>
  <summary>Details</summary>
Motivation: 当前的人体姿态估计（HPE）在处理运动学人体姿态时，在关键点识别和轨迹平滑方面存在不足。现有基于深度学习的方法受限于手动标注训练数据集的不准确性。

Method: 本文提出了一种新颖的基于关节角度建模的方法来解决现有无标记人体姿态估计（HPE）中存在的关键点识别错误和轨迹随机波动问题。具体技术包括：1. 提出一种稳健的、用于描述运动学人体姿态的基于关节角度的模型。2. 利用高阶傅里叶级数近似关节角度的时间变化，以获得可靠的“真实”标签。3. 设计了一个双向循环网络作为后处理模块，以优化现有HRNet的估计结果。

Result: 在所构建的高质量数据集上训练的双向循环网络，在修正错误识别的关节和轨迹平滑方面表现出卓越的性能，并且在花样滑冰和街舞等具有挑战性的场景中，其基于关节角度的优化（JAR）方法的表现优于最先进的HPE优化网络。

Conclusion: 通过使用基于关节角度的建模和高阶傅里叶级数来近似关节角度的时间变化，我们构建了一个高质量的数据集，并训练了一个双向循环网络作为后处理模块，以优化现有的人体姿态估计方法。实验结果表明，该方法在修正错误识别的关节和 त्यांच्या时空轨迹方面表现出色，并且在花样滑冰和街舞等具有挑战性的场景中优于现有的人体姿态估计优化网络。

Abstract: Marker-free human pose estimation (HPE) has found increasing applications in
various fields. Current HPE suffers from occasional errors in keypoint
recognition and random fluctuation in keypoint trajectories when analyzing
kinematic human poses. The performance of existing deep learning-based models
for HPE refinement is considerably limited by inaccurate training datasets in
which the keypoints are manually annotated. This paper proposed a novel method
to overcome the difficulty through joint angle-based modeling. The key
techniques include: (i) A joint angle-based model of human pose, which is
robust to describe kinematic human poses; (ii) Approximating temporal variation
of joint angles through high order Fourier series to get reliable "ground
truth"; (iii) A bidirectional recurrent network is designed as a
post-processing module to refine the estimation of well-established HRNet.
Trained with the high-quality dataset constructed using our method, the network
demonstrates outstanding performance to correct wrongly recognized joints and
smooth their spatiotemporal trajectories. Tests show that joint angle-based
refinement (JAR) outperforms the state-of-the-art HPE refinement network in
challenging cases like figure skating and breaking.

</details>


### [32] [GKNet: Graph-based Keypoints Network for Monocular Pose Estimation of Non-cooperative Spacecraft](https://arxiv.org/abs/2507.11077)
*Weizhao Ma,Dong Zhou,Yuhui Hu,Zipeng He*

Main category: cs.CV

TL;DR: 为了解决非合作航天器姿态估计的挑战，我们提出了GKNet，一种利用图卷积神经网络和关键点几何约束的方法，并在新的SKD数据集上取得了优于现有方法的成果。


<details>
  <summary>Details</summary>
Motivation: 为了满足在轨服务任务（如卫星维护、空间碎片清除和空间站组装）对姿态估计精度的要求，以及解决现有方法在处理非合作航天器时的结构对称性和部分遮挡问题。

Method: 提出了一种名为GKNet的图卷积神经网络，利用关键点图的几何约束来提高姿态估计的精度。同时，构建了一个包含3个航天器目标、90,000张模拟图像和关键点标注的SKD数据集，用于更好地验证关键点检测器。

Result: GKNet在SKD数据集上进行了广泛的实验和消融研究，证明了其相比于最先进的航天器关键点检测器具有更高的精度和有效性。

Conclusion: 该研究提出了一个名为GKNet的图卷积神经网络，用于解决非合作航天器的单目姿态估计问题，并在SKD数据集上进行了验证，证明了其在精度和有效性上优于现有的方法。

Abstract: Monocular pose estimation of non-cooperative spacecraft is significant for
on-orbit service (OOS) tasks, such as satellite maintenance, space debris
removal, and station assembly. Considering the high demands on pose estimation
accuracy, mainstream monocular pose estimation methods typically consist of
keypoint detectors and PnP solver. However, current keypoint detectors remain
vulnerable to structural symmetry and partial occlusion of non-cooperative
spacecraft. To this end, we propose a graph-based keypoints network for the
monocular pose estimation of non-cooperative spacecraft, GKNet, which leverages
the geometric constraint of keypoints graph. In order to better validate
keypoint detectors, we present a moderate-scale dataset for the spacecraft
keypoint detection, named SKD, which consists of 3 spacecraft targets, 90,000
simulated images, and corresponding high-precise keypoint annotations.
Extensive experiments and an ablation study have demonstrated the high accuracy
and effectiveness of our GKNet, compared to the state-of-the-art spacecraft
keypoint detectors. The code for GKNet and the SKD dataset is available at
https://github.com/Dongzhou-1996/GKNet.

</details>


### [33] [Automatic Road Subsurface Distress Recognition from Ground Penetrating Radar Images using Deep Learning-based Cross-verification](https://arxiv.org/abs/2507.11081)
*Chang Peng,Bao Yang,Meiqi Li,Ge Zhang,Hui Sun,Zhenyu Jiang*

Main category: cs.CV

TL;DR: 本研究提出了一种基于3D GPR数据集和交叉验证策略的自动RSD识别方法，显著提高了识别准确性并降低了劳动强度。


<details>
  <summary>Details</summary>
Motivation: 为了解决当前深度学习模型在RSD识别中存在的挑战，如高质量数据集的稀缺和网络区分RSD的能力不足，本研究旨在提高RSD识别的自动化程度和准确性。

Method: 该研究构建了一个包含2134个样本的3D GPR数据集，并提出了一种新的交叉验证策略，以提高RSD识别的准确性。

Result: 该研究提出的交叉验证策略在田野测试中实现了超过98.6%的召回率，并将劳动强度降低了约90%。

Conclusion: 该研究提出了一种新的交叉验证策略，用于从地面穿透雷达图像中识别道路下层病害（RSD）。

Abstract: Ground penetrating radar (GPR) has become a rapid and non-destructive
solution for road subsurface distress (RSD) detection. However, RSD recognition
from GPR images is labor-intensive and heavily relies on inspectors' expertise.
Deep learning offers the possibility for automatic RSD recognition, but its
current performance is limited by two factors: Scarcity of high-quality dataset
for network training and insufficient capability of network to distinguish RSD.
In this study, a rigorously validated 3D GPR dataset containing 2134 samples of
diverse types was constructed through field scanning. Based on the finding that
the YOLO model trained with one of the three scans of GPR images exhibits
varying sensitivity to specific type of RSD, we proposed a novel
cross-verification strategy with outstanding accuracy in RSD recognition,
achieving recall over 98.6% in field tests. The approach, integrated into an
online RSD detection system, can reduce the labor of inspection by around 90%.

</details>


### [34] [Atmos-Bench: 3D Atmospheric Structures for Climate Insight](https://arxiv.org/abs/2507.11085)
*Tianchi Xu*

Main category: cs.CV

TL;DR: 介绍了一种新的 3D 大气基准 Atmos-Bench 和 FourCastX 网络，用于大气结构恢复。


<details>
  <summary>Details</summary>
Motivation: 现有的方法依赖辅助输入和简化的基于物理的近似，并且缺乏标准化的 3D 基准来进行公平评估，这可能会引入额外的 불확실성 并未能充分捕捉真实的辐射传输和大气散射-吸收效应。

Method: 提出了一种新颖的 FourCastX：增强频率的时空专家混合网络，该网络将 ATB-BC 物理约束嵌入模型架构中，以在恢复过程中促进能量一致性，并在 355 nm 和 532 nm 波段的 Atmos-Bench 数据集上实现一致的改进，其性能优于最先进的基线模型，而无需依赖辅助输入。

Result: 生成了 921,600 个图像切片，这些切片来自在 532 nm 和 355 nm 下模拟的 3D 散射体积，通过耦合 WRF 和增强的 COSP 模拟器，在 384 个陆地-海洋时间步长上产生高质量的体素级参考。

Conclusion: Atmos-Bench 建立了一个新的基于卫星的 3D 大气结构恢复标准，并为更深入的气候洞察铺平了道路。

Abstract: Atmospheric structure, represented by backscatter coefficients (BC) recovered
from satellite LiDAR attenuated backscatter (ATB), provides a volumetric view
of clouds, aerosols, and molecules, playing a critical role in human
activities, climate understanding, and extreme weather forecasting. Existing
methods often rely on auxiliary inputs and simplified physics-based
approximations, and lack a standardized 3D benchmark for fair evaluation.
However, such approaches may introduce additional uncertainties and
insufficiently capture realistic radiative transfer and atmospheric
scattering-absorption effects. To bridge these gaps, we present Atmos-Bench:
the first 3D atmospheric benchmark, along with a novel FourCastX:
Frequency-enhanced Spatio-Temporal Mixture-of-Experts Network that (a)
generates 921,600 image slices from 3D scattering volumes simulated at 532 nm
and 355 nm by coupling WRF with an enhanced COSP simulator over 384 land-ocean
time steps, yielding high-quality voxel-wise references; (b) embeds ATB-BC
physical constraints into the model architecture, promoting energy consistency
during restoration; (c) achieves consistent improvements on the Atmos-Bench
dataset across both 355 nm and 532 nm bands, outperforming state-of-the-art
baseline models without relying on auxiliary inputs. Atmos-Bench establishes a
new standard for satellite-based 3D atmospheric structure recovery and paves
the way for deeper climate insight.

</details>


### [35] [A Survey on Interpretability in Visual Recognition](https://arxiv.org/abs/2507.11099)
*Qiyang Wan,Chengzhi Gao,Ruiping Wang,Xilin Chen*

Main category: cs.CV

TL;DR: 本文对视觉识别模型的可解释性进行了综述，提出了一个新的分类方法，并讨论了未来的研究方向。


<details>
  <summary>Details</summary>
Motivation: 随着视觉识别方法在自动驾驶和医疗诊断等关键领域的广泛应用，对其进行故障诊断的需求日益增长，从而推动了可解释性研究的发展。

Method: 本文提出了一种从人本主义角度对可解释识别方法进行分类的体系，根据意图、对象、呈现和方法论对可解释识别方法进行分类，为这些XAI方法建立了一套系统、连贯的分类标准。

Result: 本文系统地回顾了视觉识别模型可解释性方面的现有研究，提出了一个以人为中心的方法分类体系，并对评估指标的需求进行了总结，同时探索了多模态大模型等新技术带来的新机遇。

Conclusion: 本篇论文对视觉识别模型的可解释性研究进行了全面的回顾，提出了一个以人为中心的方法分类体系，并对评估指标的需求进行了总结，同时探索了多模态大模型等新技术带来的新机遇，旨在组织现有研究并启发未来工作。

Abstract: In recent years, visual recognition methods have advanced significantly,
finding applications across diverse fields. While researchers seek to
understand the mechanisms behind the success of these models, there is also a
growing impetus to deploy them in critical areas like autonomous driving and
medical diagnostics to better diagnose failures, which promotes the development
of interpretability research. This paper systematically reviews existing
research on the interpretability of visual recognition models and proposes a
taxonomy of methods from a human-centered perspective. The proposed taxonomy
categorizes interpretable recognition methods based on Intent, Object,
Presentation, and Methodology, thereby establishing a systematic and coherent
set of grouping criteria for these XAI methods. Additionally, we summarize the
requirements for evaluation metrics and explore new opportunities enabled by
recent technologies, such as large multimodal models. We aim to organize
existing research in this domain and inspire future investigations into the
interpretability of visual recognition models.

</details>


### [36] [KptLLM++: Towards Generic Keypoint Comprehension with Large Language Model](https://arxiv.org/abs/2507.11102)
*Jie Yang,Wang Zeng,Sheng Jin,Lumin Xu,Wentao Liu,Chen Qian,Zhen Li,Ruimao Zhang*

Main category: cs.CV

TL;DR: KptLLM++ 是一个新颖的多模态大语言模型，通过“识别-然后检测”范式和结构化思维链推理，能够理解和定位图像中的关键点，并在大规模数据集上进行了训练，在细粒度图像分析和人机交互方面表现出色。


<details>
  <summary>Details</summary>
Motivation: 现有的多模态大语言模型（MLLMs）在捕捉细粒度语义信息方面存在不足，特别是在精确识别和分析物体的关键点方面。而关键点作为物体（尤其是铰接物体）的结构感知、像素级和紧凑表示，在细粒度图像分析、物体检索和行为识别等应用中至关重要。

Method: KptLLM++ 采用新颖的“识别-然后检测”范式，首先解释关键点语义，然后通过结构化的思维链推理机制精确定位其位置。通过将用户定义的指令引导下的多种输入模式相结合，实现了跨不同上下文的关键点检测的统一。

Result: KptLLM++ 在多个关键点检测基准测试中取得了最先进的性能，展现了卓越的准确性和泛化能力。

Conclusion: KptLLM++ 在多个关键点检测基准测试中取得了最先进的性能，展示了其作为细粒度图像理解的统一解决方案的潜力，以及对人机交互的变革性影响。

Abstract: The emergence of Multimodal Large Language Models (MLLMs) has revolutionized
image understanding by bridging textual and visual modalities. However, these
models often struggle with capturing fine-grained semantic information, such as
the precise identification and analysis of object keypoints. Keypoints, as
structure-aware, pixel-level, and compact representations of objects,
particularly articulated ones, play a crucial role in applications such as
fine-grained image analysis, object retrieval, and behavior recognition. In
this paper, we propose KptLLM++, a novel multimodal large language model that
specifically designed for generic keypoint comprehension through the
integration of diverse input modalities guided by user-defined instructions. By
unifying keypoint detection across varied contexts, KptLLM++ establishes itself
as an advanced interface, fostering more effective human-AI collaboration. The
model is built upon a novel identify-then-detect paradigm, which first
interprets keypoint semantics and subsequently localizes their precise
positions through a structured chain-of-thought reasoning mechanism. To push
the boundaries of performance, we have scaled up the training dataset to over
500K samples, encompassing diverse objects, keypoint categories, image styles,
and scenarios with complex occlusions. This extensive scaling enables KptLLM++
to unlock its potential, achieving remarkable accuracy and generalization.
Comprehensive experiments on multiple keypoint detection benchmarks demonstrate
its state-of-the-art performance, underscoring its potential as a unified
solution for fine-grained image understanding and its transformative
implications for human-AI interaction.

</details>


### [37] [Jellyfish Species Identification: A CNN Based Artificial Neural Network Approach](https://arxiv.org/abs/2507.11116)
*Md. Sabbir Hossen,Md. Saiduzzaman,Pabon Shaha,Mostofa Kamal Nasir*

Main category: cs.CV

TL;DR: 本研究提出了一种深度学习框架，通过结合多种特征提取技术和分类器，实现了对水母物种的高效检测和分类，其中人工神经网络与MobileNetV3的组合表现最佳，准确率高达98%。


<details>
  <summary>Details</summary>
Motivation: 水母在海洋生态系统中扮演着至关重要的角色，但由于其快速繁殖和生态影响，给生物多样性和保护带来了重大挑战。准确识别水母物种对于生态监测和管理至关重要。

Method: 提出了一种深度学习框架，利用MobileNetV3、ResNet50、EfficientNetV2-B0和VGG16等先进特征提取技术，并结合了七种传统机器学习分类器和三种前馈神经网络分类器，以实现精确的物种识别。此外，还激活了softmax函数，直接使用卷积神经网络模型对水母物种进行分类。

Result: 研究表明，人工神经网络与MobileNetV3的组合是表现最佳的模型，达到了98%的准确率，显著优于其他特征提取器-分类器组合。

Conclusion: 本研究展示了深度学习和混合框架在应对生物多样性挑战和推进海洋环境物种检测方面的有效性。

Abstract: Jellyfish, a diverse group of gelatinous marine organisms, play a crucial
role in maintaining marine ecosystems but pose significant challenges for
biodiversity and conservation due to their rapid proliferation and ecological
impact. Accurate identification of jellyfish species is essential for
ecological monitoring and management. In this study, we proposed a deep
learning framework for jellyfish species detection and classification using an
underwater image dataset. The framework integrates advanced feature extraction
techniques, including MobileNetV3, ResNet50, EfficientNetV2-B0, and VGG16,
combined with seven traditional machine learning classifiers and three
Feedforward Neural Network classifiers for precise species identification.
Additionally, we activated the softmax function to directly classify jellyfish
species using the convolutional neural network models. The combination of the
Artificial Neural Network with MobileNetV3 is our best-performing model,
achieving an exceptional accuracy of 98%, significantly outperforming other
feature extractor-classifier combinations. This study demonstrates the efficacy
of deep learning and hybrid frameworks in addressing biodiversity challenges
and advancing species detection in marine environments.

</details>


### [38] [Try Harder: Hard Sample Generation and Learning for Clothes-Changing Person Re-ID](https://arxiv.org/abs/2507.11119)
*Hankun Liu,Yujian Zhao,Guanglin Niu*

Main category: cs.CV

TL;DR: 该研究提出了一种名为HSGL的新框架，利用文本和视觉信息生成和学习难例，以提高衣着变化person Re-ID（CC-ReID）的性能。实验证明，该方法在PRCC和LTCC数据集上达到了最先进的水平。


<details>
  <summary>Details</summary>
Motivation: 难例在 person re-identification（ReID）任务中，特别是在衣着变化person Re-ID（CC-ReID）中，构成了显著的挑战。难例固有的歧义性或相似性，以及缺乏明确的定义，使其成为模型性能提升的根本瓶颈。这些问题不仅限制了针对性学习策略的设计，还削弱了模型在衣着或视角变化时的鲁棒性。

Method: 提出了一种名为“多模态引导的难例生成与学习”（HSGL）的框架。该框架包含两个核心组件：1. 双粒度难例生成（DGHSG），利用多模态线索合成语义一致的样本，包括粗粒度和细粒度的难例正样本和负样本，以增加训练数据的难度和多样性。2. 难例自适应学习（HSAL），引入一种感知难度的优化策略，根据文本语义标签调整特征距离，鼓励将难例正样本分离，并将难例负样本拉近嵌入空间，以增强模型的辨别能力和对难例的鲁棒性。

Result: 所提出的HSGL框架在多个CC-ReID基准测试中表现出有效性，并突显了多模态引导的难例生成和学习在鲁棒CC-ReID方面的潜力。特别是，HSAL显著加速了目标学习过程的收敛，并在PRCC和LTCC数据集上取得了最先进的性能。

Conclusion: 该研究提出了一个新颖的多模态引导的难例生成与学习（HSGL）框架，首次将文本和视觉模态统一起来，在一个统一的范式内明确定义、生成和优化难例，有效解决了现有方法在处理难例时的不足，并在多个CC-ReID基准测试中取得了最先进的性能，显著提高了模型的辨别能力和鲁棒性。

Abstract: Hard samples pose a significant challenge in person re-identification (ReID)
tasks, particularly in clothing-changing person Re-ID (CC-ReID). Their inherent
ambiguity or similarity, coupled with the lack of explicit definitions, makes
them a fundamental bottleneck. These issues not only limit the design of
targeted learning strategies but also diminish the model's robustness under
clothing or viewpoint changes. In this paper, we propose a novel
multimodal-guided Hard Sample Generation and Learning (HSGL) framework, which
is the first effort to unify textual and visual modalities to explicitly
define, generate, and optimize hard samples within a unified paradigm. HSGL
comprises two core components: (1) Dual-Granularity Hard Sample Generation
(DGHSG), which leverages multimodal cues to synthesize semantically consistent
samples, including both coarse- and fine-grained hard positives and negatives
for effectively increasing the hardness and diversity of the training data. (2)
Hard Sample Adaptive Learning (HSAL), which introduces a hardness-aware
optimization strategy that adjusts feature distances based on textual semantic
labels, encouraging the separation of hard positives and drawing hard negatives
closer in the embedding space to enhance the model's discriminative capability
and robustness to hard samples. Extensive experiments on multiple CC-ReID
benchmarks demonstrate the effectiveness of our approach and highlight the
potential of multimodal-guided hard sample generation and learning for robust
CC-ReID. Notably, HSAL significantly accelerates the convergence of the
targeted learning procedure and achieves state-of-the-art performance on both
PRCC and LTCC datasets. The code is available at
https://github.com/undooo/TryHarder-ACMMM25.

</details>


### [39] [Task-Oriented Human Grasp Synthesis via Context- and Task-Aware Diffusers](https://arxiv.org/abs/2507.11287)
*An-Lun Liu,Yu-Wei Chao,Yi-Ting Chen*

Main category: cs.CV

TL;DR: 提出了一种新的面向任务的人类抓取合成方法，该方法通过引入任务感知接触图来同时考虑任务和场景信息，并在抓取质量和任务性能方面取得了显著改进。


<details>
  <summary>Details</summary>
Motivation: 研究面向任务的人类抓取合成，这是一个需要同时考虑任务和上下文感知的新抓取合成任务。

Method: 提出了一种两阶段方法，首先构建考虑了场景和任务信息的任务感知接触图，然后在后续阶段利用该接触图来合成面向任务的人类抓取。

Result: 提出了一种新的数据集和评估指标，并通过实验验证了所提出方法相对于现有方法的优势。

Conclusion: 研究结果表明，同时考虑场景和任务信息对于抓取至关重要，并且在抓取质量和任务性能方面都显著优于现有方法。

Abstract: In this paper, we study task-oriented human grasp synthesis, a new grasp
synthesis task that demands both task and context awareness. At the core of our
method is the task-aware contact maps. Unlike traditional contact maps that
only reason about the manipulated object and its relation with the hand, our
enhanced maps take into account scene and task information. This comprehensive
map is critical for hand-object interaction, enabling accurate grasping poses
that align with the task. We propose a two-stage pipeline that first constructs
a task-aware contact map informed by the scene and task. In the subsequent
stage, we use this contact map to synthesize task-oriented human grasps. We
introduce a new dataset and a metric for the proposed task to evaluate our
approach. Our experiments validate the importance of modeling both scene and
task, demonstrating significant improvements over existing methods in both
grasp quality and task performance. See our project page for more details:
https://hcis-lab.github.io/TOHGS/

</details>


### [40] [MMOne: Representing Multiple Modalities in One Scene](https://arxiv.org/abs/2507.11129)
*Zhifeng Gu,Bing Wang*

Main category: cs.CV

TL;DR: A new framework, MMOne, tackles challenges in representing multiple senses by separating shared and unique information, improving scene understanding and working with more senses easily.


<details>
  <summary>Details</summary>
Motivation: To address the challenges of property disparity and granularity disparity arising from modality conflicts in multimodal scene representation.

Method: MMOne framework utilizing a modality modeling module with a novel modality indicator and a multimodal decomposition mechanism to separate multi-modal Gaussians into single-modal Gaussians, disentangling multimodal information into shared and modality-specific components.

Result: Extensive experiments demonstrate that MMOne consistently enhances the representation capability for each modality and is scalable to additional modalities.

Conclusion: The proposed MMOne framework effectively addresses modality conflicts by capturing unique properties of each modality and disentangling multimodal information into shared and modality-specific components, leading to enhanced representation capability and scalability.

Abstract: Humans perceive the world through multimodal cues to understand and interact
with the environment. Learning a scene representation for multiple modalities
enhances comprehension of the physical world. However, modality conflicts,
arising from inherent distinctions among different modalities, present two
critical challenges: property disparity and granularity disparity. To address
these challenges, we propose a general framework, MMOne, to represent multiple
modalities in one scene, which can be readily extended to additional
modalities. Specifically, a modality modeling module with a novel modality
indicator is proposed to capture the unique properties of each modality.
Additionally, we design a multimodal decomposition mechanism to separate
multi-modal Gaussians into single-modal Gaussians based on modality
differences. We address the essential distinctions among modalities by
disentangling multimodal information into shared and modality-specific
components, resulting in a more compact and efficient multimodal scene
representation. Extensive experiments demonstrate that our method consistently
enhances the representation capability for each modality and is scalable to
additional modalities. The code is available at
https://github.com/Neal2020GitHub/MMOne.

</details>


### [41] [RMAU-NET: A Residual-Multihead-Attention U-Net Architecture for Landslide Segmentation and Detection from Remote Sensing Images](https://arxiv.org/abs/2507.11143)
*Lam Pham,Cam Le,Hieu Tang,Khang Truong,Truong Nguyen,Jasmin Lampert,Alexander Schindler,Martin Boyer,Son Phan*

Main category: cs.CV

TL;DR: 提出了一种深度学习模型，利用遥感图像自动检测和分割滑坡，并在多个数据集上取得了良好的效果。


<details>
  <summary>Details</summary>
Motivation: 由于极端天气事件和人类活动，滑坡灾害频发。然而，由于观测区域广阔、地形崎岖，自动观测滑坡具有挑战性。

Method: 提出了一种端到端的基于深度学习的模型，利用遥感图像进行滑坡事件的自动观测。该模型包含一个新颖的神经网络架构，用于滑坡检测和滑坡分割两个任务。

Result: 在LandSlide4Sense和Bijie数据集上，滑坡检测任务的F1分数分别为98.23%和93.83%。在LandSlide4Sense和Nepal数据集上，分割任务的mIoU分数分别为63.74%和76.88%。

Conclusion: 该模型有潜力整合到现实世界的滑坡观测系统中。

Abstract: In recent years, landslide disasters have reported frequently due to the
extreme weather events of droughts, floods , storms, or the consequence of
human activities such as deforestation, excessive exploitation of natural
resources. However, automatically observing landslide is challenging due to the
extremely large observing area and the rugged topography such as mountain or
highland. This motivates us to propose an end-to-end deep-learning-based model
which explores the remote sensing images for automatically observing landslide
events. By considering remote sensing images as the input data, we can obtain
free resource, observe large and rough terrains by time. To explore the remote
sensing images, we proposed a novel neural network architecture which is for
two tasks of landslide detection and landslide segmentation. We evaluated our
proposed model on three different benchmark datasets of LandSlide4Sense, Bijie,
and Nepal. By conducting extensive experiments, we achieve F1 scores of 98.23,
93.83 for the landslide detection task on LandSlide4Sense, Bijie datasets; mIoU
scores of 63.74, 76.88 on the segmentation tasks regarding LandSlide4Sense,
Nepal datasets. These experimental results prove potential to integrate our
proposed model into real-life landslide observation systems.

</details>


### [42] [Assessing Color Vision Test in Large Vision-language Models](https://arxiv.org/abs/2507.11153)
*Hongfei Ye,Bin Chen,Wenxi Liu,Yu Zhang,Zhao Li,Dandan Ni,Hongyang Chen*

Main category: cs.CV

TL;DR: 本文构建了一个颜色视觉测试数据集，并提出了提升大型视觉-语言模型颜色视觉能力的微调策略。


<details>
  <summary>Details</summary>
Motivation: 大型视觉-语言模型的颜色视觉能力至关重要，但尚未得到充分探索。

Method: 定义了一个颜色视觉测试任务，并构建了一个包含多种类别和不同难度级别测试问题及任务的数据集，同时分析了模型在颜色视觉测试中常见的错误类型。

Result: 构建了一个颜色视觉测试数据集，并分析了模型错误类型，提出了改进策略。

Conclusion: 通过对大型视觉-语言模型进行微调，可以提高其在颜色视觉测试中的表现。

Abstract: With the widespread adoption of large vision-language models, the capacity
for color vision in these models is crucial. However, the color vision
abilities of large visual-language models have not yet been thoroughly
explored. To address this gap, we define a color vision testing task for large
vision-language models and construct a dataset \footnote{Anonymous Github
Showing some of the data
https://anonymous.4open.science/r/color-vision-test-dataset-3BCD} that covers
multiple categories of test questions and tasks of varying difficulty levels.
Furthermore, we analyze the types of errors made by large vision-language
models and propose fine-tuning strategies to enhance their performance in color
vision tests.

</details>


### [43] [Clustering-Guided Multi-Layer Contrastive Representation Learning for Citrus Disease Classification](https://arxiv.org/abs/2507.11171)
*Jun Chen,Yonghua Yu,Weifu Li,Yaohui Chen,Hong Chen*

Main category: cs.CV

TL;DR: 介绍了一种新的聚类引导自监督学习算法（CMCRL），用于柑橘病害的检测和分类。该方法无需大量标注数据，能够处理病害症状相似的问题，并学习分层特征表示，在性能上优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 为了解决当前基于深度学习的计算机视觉算法在柑橘病害检测和分类方面需要大量高质量带注释的训练样本的问题。

Method: 提出了一种新颖的聚类引导自监督多层对比表示学习（CMCRL）算法，该算法通过两个关键设计：与聚类质心的对比和多层对比训练（MCT）范式。

Result: 该方法实现了最先进的性能，超越了现有方法，并且在准确性、F1分数、精确率和召回率等方面均表现出色，尤其在类别不平衡的情况下显示出鲁棒性。

Conclusion: 该方法在CDD公共数据集上达到了最先进的性能，在准确性上比现有方法高出4.5%-30.1%。此外，在类别不平衡的挑战下，该方法在F1分数、精确率和召回率等其他评估指标上也表现出色，证明了其鲁棒性。

Abstract: Citrus, as one of the most economically important fruit crops globally,
suffers severe yield depressions due to various diseases. Accurate disease
detection and classification serve as critical prerequisites for implementing
targeted control measures. Recent advancements in artificial intelligence,
particularly deep learning-based computer vision algorithms, have substantially
decreased time and labor requirements while maintaining the accuracy of
detection and classification. Nevertheless, these methods predominantly rely on
massive, high-quality annotated training examples to attain promising
performance. By introducing two key designs: contrasting with cluster centroids
and a multi-layer contrastive training (MCT) paradigm, this paper proposes a
novel clustering-guided self-supervised multi-layer contrastive representation
learning (CMCRL) algorithm. The proposed method demonstrates several advantages
over existing counterparts: (1) optimizing with massive unannotated samples;
(2) effective adaptation to the symptom similarity across distinct citrus
diseases; (3) hierarchical feature representation learning. The proposed method
achieves state-of-the-art performance on the public citrus image set CDD,
outperforming existing methods by 4.5\%-30.1\% accuracy. Remarkably, our method
narrows the performance gap with fully supervised counterparts (all samples are
labeled). Beyond classification accuracy, our method shows great performance on
other evaluation metrics (F1 score, precision, and recall), highlighting the
robustness against the class imbalance challenge.

</details>


### [44] [How Far Have Medical Vision-Language Models Come? A Comprehensive Benchmarking Study](https://arxiv.org/abs/2507.11200)
*Che Liu,Jiazhen Pan,Weixiang Shen,Wenjia Bai,Daniel Rueckert,Rossella Arcucci*

Main category: cs.CV

TL;DR: 评估了通用和医学专用视觉-语言模型（VLM）在医疗任务中的表现，发现大型通用模型表现出强大的迁移能力，但推理能力仍有待提高，且没有模型达到临床部署的标准。


<details>
  <summary>Details</summary>
Motivation: 评估视觉-语言模型（VLM）在医疗任务中的能力，因为它们越来越多地被重新用于医疗保健领域。

Method: 对开放源代码的通用和医学专业视觉-语言模型（VLM）进行了全面的评估，这些模型涵盖了3B到72B参数，横跨八个基准：MedXpert、OmniMedVQA、PMC-VQA、PathVQA、MMMU、SLAKE和VQA-RAD。首先将模型性能分为理解和推理两个组成部分。

Result: 研究结果表明：1.大型通用模型在多个基准上的表现已达到甚至超过了医学专业模型，展示了从自然图像到医学图像的强大零样本迁移能力。2.推理性能始终低于理解性能，这表明在安全决策支持方面存在关键障碍。3.模型在不同基准上的性能差异很大，这反映了任务设计、注释质量和知识需求方面的差异。

Conclusion: 目前没有模型达到临床部署的可靠性阈值，这凸显了加强多模态对齐和更严格、更细粒度评估协议的必要性。

Abstract: Vision-Language Models (VLMs) trained on web-scale corpora excel at natural
image tasks and are increasingly repurposed for healthcare; however, their
competence in medical tasks remains underexplored. We present a comprehensive
evaluation of open-source general-purpose and medically specialised VLMs,
ranging from 3B to 72B parameters, across eight benchmarks: MedXpert,
OmniMedVQA, PMC-VQA, PathVQA, MMMU, SLAKE, and VQA-RAD. To observe model
performance across different aspects, we first separate it into understanding
and reasoning components. Three salient findings emerge. First, large
general-purpose models already match or surpass medical-specific counterparts
on several benchmarks, demonstrating strong zero-shot transfer from natural to
medical images. Second, reasoning performance is consistently lower than
understanding, highlighting a critical barrier to safe decision support. Third,
performance varies widely across benchmarks, reflecting differences in task
design, annotation quality, and knowledge demands. No model yet reaches the
reliability threshold for clinical deployment, underscoring the need for
stronger multimodal alignment and more rigorous, fine-grained evaluation
protocols.

</details>


### [45] [A Robust Incomplete Multimodal Low-Rank Adaptation Approach for Emotion Recognition](https://arxiv.org/abs/2507.11202)
*Xinkui Zhao,Jinsong Shu,Yangyang Wu,Guanjie Cheng,Zihe Liu,Naibo Wang,Shuiguang Deng,Zhongle Xie,Jianwei Yin*

Main category: cs.CV

TL;DR: MCULoRA通过解耦和动态调整训练比例来解决不完整多模态学习中的梯度冲突问题，并在下游任务中取得更好的准确性。


<details>
  <summary>Details</summary>
Motivation: 解决多模态情感识别（MER）在实际应用中因传感器故障或隐私保护而常遇到的不完整多模态问题，以及现有方法因训练梯度冲突而导致性能下降的局限性。

Method: 提出了一种基于模态组合的单模态解耦动态低秩自适应方法（MCULoRA），包括模态组合感知低秩自适应（MCLA）和动态参数微调（DPFT）模块。MCLA解耦了共享信息与各模态组合的独有特征，DPFT根据模态表示空间的可分性调整模态组合的训练比例。

Result: MCULoRA在多个基准数据集的广泛实验评估中，在下游任务准确性方面显著优于先前的不完整多模态学习方法。

Conclusion: MCULoRA在下游任务准确性方面显著优于先前的不完整多模态学习方法。

Abstract: Multimodal Emotion Recognition (MER) often encounters incomplete
multimodality in practical applications due to sensor failures or privacy
protection requirements. While existing methods attempt to address various
incomplete multimodal scenarios by balancing the training of each modality
combination through additional gradients, these approaches face a critical
limitation: training gradients from different modality combinations conflict
with each other, ultimately degrading the performance of the final prediction
model. In this paper, we propose a unimodal decoupled dynamic low-rank
adaptation method based on modality combinations, named MCULoRA, which is a
novel framework for the parameter-efficient training of incomplete multimodal
learning models. MCULoRA consists of two key modules, modality combination
aware low-rank adaptation (MCLA) and dynamic parameter fine-tuning (DPFT). The
MCLA module effectively decouples the shared information from the distinct
characteristics of individual modality combinations. The DPFT module adjusts
the training ratio of modality combinations based on the separability of each
modality's representation space, optimizing the learning efficiency across
different modality combinations. Our extensive experimental evaluation in
multiple benchmark datasets demonstrates that MCULoRA substantially outperforms
previous incomplete multimodal learning approaches in downstream task accuracy.

</details>


### [46] [NarrLV: Towards a Comprehensive Narrative-Centric Evaluation for Long Video Generation Models](https://arxiv.org/abs/2507.11245)
*X. Feng,H. Yu,M. Wu,S. Hu,J. Chen,C. Zhu,J. Wu,X. Chu,K. Huang*

Main category: cs.CV

TL;DR: 提出NarrLV基准和基于MLLM的评估指标，用于评估长视频生成模型的叙事能力。


<details>
  <summary>Details</summary>
Motivation: 现有长视频生成模型缺乏专门的评估基准，当前评估方法依赖于仅包含简单叙事提示的基准（如VBench），无法满足长视频模型不仅要扩展视频时长，还要准确表达更丰富叙事内容的需求。

Method: (i) 提出时间叙事原子（TNA）作为衡量叙事丰富度的基本单位，并构建了自动提示生成管线以生成包含可变数量TNA的评估提示。(ii) 基于叙事内容的三个渐进级别，设计了使用多模态大语言模型（MLLM）进行问答的评估指标。

Result: 实验结果表明，所提出的评估指标与人类判断高度相关，并且揭示了当前长视频生成模型在叙事内容表达方面的具体能力边界。

Conclusion: 该研究提出了NarrLV，一个旨在全面评估长视频生成模型叙事表达能力的基准，并设计了相应的评估指标，该指标与人类判断高度一致，并揭示了当前模型在叙事内容表达方面的能力边界。

Abstract: With the rapid development of foundation video generation technologies, long
video generation models have exhibited promising research potential thanks to
expanded content creation space. Recent studies reveal that the goal of long
video generation tasks is not only to extend video duration but also to
accurately express richer narrative content within longer videos. However, due
to the lack of evaluation benchmarks specifically designed for long video
generation models, the current assessment of these models primarily relies on
benchmarks with simple narrative prompts (e.g., VBench). To the best of our
knowledge, our proposed NarrLV is the first benchmark to comprehensively
evaluate the Narrative expression capabilities of Long Video generation models.
Inspired by film narrative theory, (i) we first introduce the basic narrative
unit maintaining continuous visual presentation in videos as Temporal Narrative
Atom (TNA), and use its count to quantitatively measure narrative richness.
Guided by three key film narrative elements influencing TNA changes, we
construct an automatic prompt generation pipeline capable of producing
evaluation prompts with a flexibly expandable number of TNAs. (ii) Then, based
on the three progressive levels of narrative content expression, we design an
effective evaluation metric using the MLLM-based question generation and
answering framework. (iii) Finally, we conduct extensive evaluations on
existing long video generation models and the foundation generation models.
Experimental results demonstrate that our metric aligns closely with human
judgments. The derived evaluation outcomes reveal the detailed capability
boundaries of current video generation models in narrative content expression.

</details>


### [47] [Fairness-Aware Grouping for Continuous Sensitive Variables: Application for Debiasing Face Analysis with respect to Skin Tone](https://arxiv.org/abs/2507.11247)
*Veronika Shilova,Emmanuel Malherbe,Giovanni Palma,Laurent Risser,Jean-Michel Loubes*

Main category: cs.CV

TL;DR: 提出一种基于公平性的分组方法，用于处理连续敏感属性，通过识别歧视最严重的子群体来提高公平性，并可用于消偏。


<details>
  <summary>Details</summary>
Motivation: 现有的公平性评估方法在处理连续敏感属性（如肤色）时，由于预设分组可能忽略某些少数族裔子群体的歧视，因此提出一种新的分组方法来解决此局限性。

Method: 提出了一种基于公平性的分组方法，通过根据观察到的歧视水平对数据进行分组，并引入基于歧视的组间方差的新标准来识别最关键的子群体。

Result: 提出的分组方法能够揭示比以往更细致的歧视模式，并且这些发现对于给定模型在不同数据集上保持稳定。消偏结果表明，该方法在几乎不影响准确性的情况下提高了公平性。

Conclusion: 该方法通过识别最关键的子群体来解决连续敏感属性的公平性问题，并通过事后处理进行消偏，在几乎不影响准确性的前提下提高了公平性，适用于工业部署。

Abstract: Within a legal framework, fairness in datasets and models is typically
assessed by dividing observations into predefined groups and then computing
fairness measures (e.g., Disparate Impact or Equality of Odds with respect to
gender). However, when sensitive attributes such as skin color are continuous,
dividing into default groups may overlook or obscure the discrimination
experienced by certain minority subpopulations. To address this limitation, we
propose a fairness-based grouping approach for continuous (possibly
multidimensional) sensitive attributes. By grouping data according to observed
levels of discrimination, our method identifies the partition that maximizes a
novel criterion based on inter-group variance in discrimination, thereby
isolating the most critical subgroups.
  We validate the proposed approach using multiple synthetic datasets and
demonstrate its robustness under changing population distributions - revealing
how discrimination is manifested within the space of sensitive attributes.
Furthermore, we examine a specialized setting of monotonic fairness for the
case of skin color. Our empirical results on both CelebA and FFHQ, leveraging
the skin tone as predicted by an industrial proprietary algorithm, show that
the proposed segmentation uncovers more nuanced patterns of discrimination than
previously reported, and that these findings remain stable across datasets for
a given model. Finally, we leverage our grouping model for debiasing purpose,
aiming at predicting fair scores with group-by-group post-processing. The
results demonstrate that our approach improves fairness while having minimal
impact on accuracy, thus confirming our partition method and opening the door
for industrial deployment.

</details>


### [48] [MFGDiffusion: Mask-Guided Smoke Synthesis for Enhanced Forest Fire Detection](https://arxiv.org/abs/2507.11252)
*Guanghao Wu,Chen Xu,Hai Song,Chong Wang,Qixing Zhang*

Main category: cs.CV

TL;DR: 该研究提出了一种生成森林火灾烟雾图像的框架，以解决烟雾数据稀缺的问题。通过结合分割模型、多模态模型和一种新的损失函数，该框架能够生成逼真且多样的烟雾图像，并已证明能有效提升烟雾检测模型的性能。


<details>
  <summary>Details</summary>
Motivation: 当前基于图像的烟雾检测是森林火灾检测和预防的关键方法，但森林火灾烟雾图像数据的稀缺是阻碍其发展的重要因素。现有的图像生成模型在生成高质量烟雾方面存在不足，尤其是在合成烟雾与背景的融合一致性方面。

Method: 提出了一种生成森林火灾烟雾图像的框架，包括：1. 使用预训练的分割模型和多模态模型获取烟雾掩膜和图像标题。2. 引入一种由掩膜和掩膜图像特征引导的网络架构，以解决现有修复模型对掩膜和掩膜图像利用不足的问题。3. 提出了一种新的损失函数——掩膜随机差值损失，通过随机扩展和侵蚀掩膜边缘来增强生成效果在掩膜周围的一致性。4. 结合烟雾特征，并使用多模态大语言模型作为筛选工具，筛选出多样化且合理的烟雾图像，以生成用于后续检测任务的烟雾图像数据集。

Result: 生成的烟雾图像逼真且多样化，并有效提升了森林火灾烟雾检测模型的性能。

Conclusion: 实验表明，所生成的烟雾图像逼真且多样化，能有效提升森林火灾烟雾检测模型的性能。

Abstract: Smoke is the first visible indicator of a wildfire.With the advancement of
deep learning, image-based smoke detection has become a crucial method for
detecting and preventing forest fires. However, the scarcity of smoke image
data from forest fires is one of the significant factors hindering the
detection of forest fire smoke. Image generation models offer a promising
solution for synthesizing realistic smoke images. However, current inpainting
models exhibit limitations in generating high-quality smoke representations,
particularly manifesting as inconsistencies between synthesized smoke and
background contexts. To solve these problems, we proposed a comprehensive
framework for generating forest fire smoke images. Firstly, we employed the
pre-trained segmentation model and the multimodal model to obtain smoke masks
and image captions.Then, to address the insufficient utilization of masks and
masked images by inpainting models, we introduced a network architecture guided
by mask and masked image features. We also proposed a new loss function, the
mask random difference loss, which enhances the consistency of the generated
effects around the mask by randomly expanding and eroding the mask
edges.Finally, to generate a smoke image dataset using random masks for
subsequent detection tasks, we incorporated smoke characteristics and use a
multimodal large language model as a filtering tool to select diverse and
reasonable smoke images, thereby improving the quality of the synthetic
dataset. Experiments showed that our generated smoke images are realistic and
diverse, and effectively enhance the performance of forest fire smoke detection
models. Code is available at https://github.com/wghr123/MFGDiffusion.

</details>


### [49] [ViewSRD: 3D Visual Grounding via Structured Multi-View Decomposition](https://arxiv.org/abs/2507.11261)
*Ronggang Huang,Haoxin Yang,Yan Cai,Xuemiao Xu,Huaidong Zhang,Shengfeng He*

Main category: cs.CV

TL;DR: ViewSRD通过将查询分解为更简单的部分并整合来自多个视点的跨模态信息来解决3D视觉基础中的挑战，从而提高性能。


<details>
  <summary>Details</summary>
Motivation: 现有的3D视觉基础方法在处理复杂的 Jadi 锚点查询中的目标与锚点的解耦以及解决由视角变化引起اً的空间描述不一致性方面存在困难。

Method: ViewSRD框架将3D视觉基础任务构建为一个结构化的多视图分解过程。首先，简单关系解耦（SRD）模块将复杂的 Jadi 锚点查询重构为一组目标单锚点语句，生成一组结构化的、注意视角的描述，以阐明位置关系。这些分解后的表示为多视图文本场景交互（Multi-TSI）模块奠定了基础，该模块使用共享的、跨模态一致视图令牌（CCVTs）来整合来自多个视点的文本和场景特征，以保留空间相关性。最后，文本场景推理模块将多视图预测合成为统一且鲁棒的3D视觉基础。

Result: 实验结果表明，ViewSRD显著优于现有方法，尤其在需要精确空间区分的复杂查询场景中表现突出。

Conclusion: ViewSRD在3D视觉基础任务上显著优于最先进的方法，特别是在需要精确空间区分的复杂查询方面。

Abstract: 3D visual grounding aims to identify and localize objects in a 3D space based
on textual descriptions. However, existing methods struggle with disentangling
targets from anchors in complex multi-anchor queries and resolving
inconsistencies in spatial descriptions caused by perspective variations. To
tackle these challenges, we propose ViewSRD, a framework that formulates 3D
visual grounding as a structured multi-view decomposition process. First, the
Simple Relation Decoupling (SRD) module restructures complex multi-anchor
queries into a set of targeted single-anchor statements, generating a
structured set of perspective-aware descriptions that clarify positional
relationships. These decomposed representations serve as the foundation for the
Multi-view Textual-Scene Interaction (Multi-TSI) module, which integrates
textual and scene features across multiple viewpoints using shared, Cross-modal
Consistent View Tokens (CCVTs) to preserve spatial correlations. Finally, a
Textual-Scene Reasoning module synthesizes multi-view predictions into a
unified and robust 3D visual grounding. Experiments on 3D visual grounding
datasets show that ViewSRD significantly outperforms state-of-the-art methods,
particularly in complex queries requiring precise spatial differentiation.

</details>


### [50] [YOLOatr : Deep Learning Based Automatic Target Detection and Localization in Thermal Infrared Imagery](https://arxiv.org/abs/2507.11267)
*Aon Safdar,Usman Akram,Waseem Anwar,Basit Malik,Mian Ibad Ali*

Main category: cs.CV

TL;DR: 提出了一种名为YOLOatr的改进型YOLOv5s模型，用于解决热红外（TI）图像中的自动目标检测（ATD）和识别（ATR）的挑战，并在DSIAC MWIR数据集上实现了99.6%的准确率。


<details>
  <summary>Details</summary>
Motivation: 与商业自动驾驶感知领域相比，国防和监控领域的自动目标检测（ATD）和识别（ATR）是一个具有挑战性的计算机视觉（CV）任务。有限的数据集、独特的领域特定和TI模特定挑战（例如，硬件限制、由于距离远导致的尺度不变性问题、战术车辆的故意遮挡、较低的传感器分辨率以及目标结构信息不足、天气、温度和一天中的时间变化以及目标与杂波比的变化）导致了类内差异增加和类间相似性更高，使得准确的实时ATR成为一项具有挑战性的CV任务。因此，当前最先进（SOTA）的深度学习架构在ATR领域表现不佳。

Method: 提出了一种改进的基于锚点的一阶段检测器YOLOatr，该检测器基于改进的YOLOv5s，并在检测头、颈部特征融合和自定义增强配置文件方面进行了优化。

Result: 所提出的模型在DSIAC MWIR数据集上针对实时ATR在相关和不相关测试协议上进行了评估，结果表明该模型达到了高达99.6%的最新ATR性能。

Conclusion: YOLOatr模型在DSIAC MWIR数据集上实现了高达99.6%的最新ATR性能。

Abstract: Automatic Target Detection (ATD) and Recognition (ATR) from Thermal Infrared
(TI) imagery in the defense and surveillance domain is a challenging computer
vision (CV) task in comparison to the commercial autonomous vehicle perception
domain. Limited datasets, peculiar domain-specific and TI modality-specific
challenges, i.e., limited hardware, scale invariance issues due to greater
distances, deliberate occlusion by tactical vehicles, lower sensor resolution
and resultant lack of structural information in targets, effects of weather,
temperature, and time of day variations, and varying target to clutter ratios
all result in increased intra-class variability and higher inter-class
similarity, making accurate real-time ATR a challenging CV task. Resultantly,
contemporary state-of-the-art (SOTA) deep learning architectures underperform
in the ATR domain. We propose a modified anchor-based single-stage detector,
called YOLOatr, based on a modified YOLOv5s, with optimal modifications to the
detection heads, feature fusion in the neck, and a custom augmentation profile.
We evaluate the performance of our proposed model on a comprehensive DSIAC MWIR
dataset for real-time ATR over both correlated and decorrelated testing
protocols. The results demonstrate that our proposed model achieves
state-of-the-art ATR performance of up to 99.6%.

</details>


### [51] [Tomato Multi-Angle Multi-Pose Dataset for Fine-Grained Phenotyping](https://arxiv.org/abs/2507.11279)
*Yujie Zhang,Sabine Struckmeyer,Andreas Kolb,Sven Reichardt*

Main category: cs.CV

TL;DR: 开发了 TomatoMAP 数据集和基于物联网的系统，实现了与专家相当的植物表型分析精度和速度。


<details>
  <summary>Details</summary>
Motivation: 解决传统植物表型分析方法中存在的观察者偏差和不一致性问题，以提高细粒度植物分析的准确性和可重复性。

Method: 开发了一个基于物联网（IoT）的图像采集系统，并使用该系统收集了包含 64,464 张 RGB 图像的 TomatoMAP 数据集，其中包含 12 种不同的植物姿势和 4 个相机俯仰角。对 7 个感兴趣区域（ROIs）进行了手动标注，并基于 BBCH 量表进行了 50 种细粒度生长阶段分类。此外，还提供了一个包含 3,616 张高分辨率图像的子集，用于细粒度表型分析的像素级语义和实例分割标注。使用结合了 MobileNetv3（分类）、YOLOv11（对象检测）和 MaskRCNN（分割）的级联深度学习模型进行了数据集验证。

Result: 基于 TomatoMAP 数据集训练的模型在准确性和速度方面达到了与领域专家相当的水平，通过 AI vs. 人类分析、Cohen's Kappa 和评分者间一致性热图验证了自动化细粒度表型分析的可靠性。

Conclusion: 该研究开发了 TomatoMAP 数据集，并使用基于物联网的图像采集系统和深度学习框架，实现了自动化细粒度表型分析，其准确性和速度可与领域专家相媲美，解决了传统方法中观察者偏差和不一致的问题。

Abstract: Observer bias and inconsistencies in traditional plant phenotyping methods
limit the accuracy and reproducibility of fine-grained plant analysis. To
overcome these challenges, we developed TomatoMAP, a comprehensive dataset for
Solanum lycopersicum using an Internet of Things (IoT) based imaging system
with standardized data acquisition protocols. Our dataset contains 64,464 RGB
images that capture 12 different plant poses from four camera elevation angles.
Each image includes manually annotated bounding boxes for seven regions of
interest (ROIs), including leaves, panicle, batch of flowers, batch of fruits,
axillary shoot, shoot and whole plant area, along with 50 fine-grained growth
stage classifications based on the BBCH scale. Additionally, we provide 3,616
high-resolution image subset with pixel-wise semantic and instance segmentation
annotations for fine-grained phenotyping. We validated our dataset using a
cascading model deep learning framework combining MobileNetv3 for
classification, YOLOv11 for object detection, and MaskRCNN for segmentation.
Through AI vs. Human analysis involving five domain experts, we demonstrate
that the models trained on our dataset achieve accuracy and speed comparable to
the experts. Cohen's Kappa and inter-rater agreement heatmap confirm the
reliability of automated fine-grained phenotyping using our approach.

</details>


### [52] [Detección y Cuantificación de Erosión Fluvial con Visión Artificial](https://arxiv.org/abs/2507.11301)
*Paúl Maji,Marlon Túquerres,Stalin Valencia,Marcela Valenzuela,Christian Mejia-Escobar*

Main category: cs.CV

TL;DR: 本研究利用YOLOv11和LiDAR图像开发了EROSCAN系统，可自动检测和量化河流侵蚀区域，准确率达70%。


<details>
  <summary>Details</summary>
Motivation: 为了克服传统方法在检测和监测河流侵蚀方面需要专业知识和大量手动处理的缺点，本研究旨在开发一种基于人工智能的自动化方法。

Method: 研究采用了基于人工智能的方法，特别是经过微调和训练的YOLOv11计算机视觉模型，并结合了照片和LiDAR图像，利用Roboflow平台进行分割和标注，以自动识别侵蚀区域并估算其面积。

Result: 实验结果表明，该方法能够以70%的准确率有效检测侵蚀模式，精确识别侵蚀区域，并可靠地计算其像素和平方米的范围。

Conclusion: 该研究开发了一个名为EROSCAN的交互式Web应用程序，可以自动识别河流侵蚀区域并计算其面积，从而优化了风险管理和区域规划中的决策。

Abstract: Fluvial erosion is a natural process that can generate significant impacts on
soil stability and strategic infrastructures. The detection and monitoring of
this phenomenon is traditionally addressed by photogrammetric methods and
analysis in geographic information systems. These tasks require specific
knowledge and intensive manual processing. This study proposes an artificial
intelligence-based approach for automatic identification of eroded zones and
estimation of their area. The state-of-the-art computer vision model YOLOv11,
adjusted by fine-tuning and trained with photographs and LiDAR images, is used.
This combined dataset was segmented and labeled using the Roboflow platform.
Experimental results indicate efficient detection of erosion patterns with an
accuracy of 70%, precise identification of eroded areas and reliable
calculation of their extent in pixels and square meters. As a final product,
the EROSCAN system has been developed, an interactive web application that
allows users to upload images and obtain automatic segmentations of fluvial
erosion, together with the estimated area. This tool optimizes the detection
and quantification of the phenomenon, facilitating decision making in risk
management and territorial planning.

</details>


### [53] [A Mixed-Primitive-based Gaussian Splatting Method for Surface Reconstruction](https://arxiv.org/abs/2507.11321)
*Haoxuan Qu,Yujun Cai,Hossein Rahmani,Ajay Kumar,Junsong Yuan,Jun Liu*

Main category: cs.CV

TL;DR: 该研究提出了一种新的高斯喷涂框架，通过整合多种几何图元（如椭圆和椭球）来提高3D表面重建的质量和细节表现。


<details>
  <summary>Details</summary>
Motivation: 现有基于高斯喷涂（GS）的方法在表面重建时仅限于使用单一类型的喷涂图元（高斯椭圆或高斯椭球），这对于表示现实世界中复杂多样的物体表面可能不够。因此，有必要开发一种能够利用多种图元来提高表面重建质量的方法。

Method: 提出了一种新颖的框架，首次实现了在高斯喷涂的表面重建过程中整合多种几何图元（如高斯椭圆和高斯椭球）。该框架包括一个组合喷涂策略，允许在喷涂和渲染过程中使用不同类型的图元；一个基于混合图元的初始化策略；以及一个顶点修剪机制，以优化学习过程。

Result: 通过大量实验证明了该框架的有效性，以及其在表面重建方面准确的性能表现。

Conclusion: 提出的框架能够整合多种几何图元，提高了高斯喷涂在表面重建中的表面表示能力和重建质量。通过组合喷涂策略、混合图元初始化和顶点修剪机制，该框架在不同类型图元的利用上表现出色。

Abstract: Recently, Gaussian Splatting (GS) has received a lot of attention in surface
reconstruction. However, while 3D objects can be of complex and diverse shapes
in the real world, existing GS-based methods only limitedly use a single type
of splatting primitive (Gaussian ellipse or Gaussian ellipsoid) to represent
object surfaces during their reconstruction. In this paper, we highlight that
this can be insufficient for object surfaces to be represented in high quality.
Thus, we propose a novel framework that, for the first time, enables Gaussian
Splatting to incorporate multiple types of (geometrical) primitives during its
surface reconstruction process. Specifically, in our framework, we first
propose a compositional splatting strategy, enabling the splatting and
rendering of different types of primitives in the Gaussian Splatting pipeline.
In addition, we also design our framework with a mixed-primitive-based
initialization strategy and a vertex pruning mechanism to further promote its
surface representation learning process to be well executed leveraging
different types of primitives. Extensive experiments show the efficacy of our
framework and its accurate surface reconstruction performance.

</details>


### [54] [MonoMVSNet: Monocular Priors Guided Multi-View Stereo Network](https://arxiv.org/abs/2507.11333)
*Jianfei Jiang,Qiankun Liu,Haochen Yu,Hongyuan Liu,Liyong Wang,Jiansheng Chen,Huimin Ma*

Main category: cs.CV

TL;DR: MonoMVSNet通过整合单目深度估计的优势，解决了传统MVS方法在处理纹理缺失和反射表面等挑战性区域的局限性，并在公开数据集上取得了优异的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的多视图立体（MVS）方法在处理纹理缺失和反射表面等具有挑战性的区域时，由于特征匹配失败而效果不佳。而单目深度估计 inherently 不需要特征匹配，因此在这些区域可以实现鲁棒的相对深度估计。为了弥合这一差距，提出MonoMVSNet。

Method: 提出了一种新颖的单目特征和深度引导的多视图立体网络（MonoMVSNet），该网络将强大的先验知识从单目基础模型集成到多视图几何中。具体方法包括：1. 利用新设计的跨视图位置编码的注意力机制，将参考视图的单目特征集成到源视图特征中。2. 通过对齐参考视图的单目深度，在采样过程中动态更新边缘区域的深度候选。3. 设计了一个基于单目深度的相对一致性损失来监督深度预测。

Result: MonoMVSNet在DTU和Tanks-and-Temples数据集上取得了最先进的性能，在Tanks-and-Temples的Intermediate和Advanced基准测试中排名第一。

Conclusion: MonoMVSNet在DTU和Tanks-and-Temples数据集上取得了最先进的性能，在Tanks-and-Temples的Intermediate和Advanced基准测试中排名第一。

Abstract: Learning-based Multi-View Stereo (MVS) methods aim to predict depth maps for
a sequence of calibrated images to recover dense point clouds. However,
existing MVS methods often struggle with challenging regions, such as
textureless regions and reflective surfaces, where feature matching fails. In
contrast, monocular depth estimation inherently does not require feature
matching, allowing it to achieve robust relative depth estimation in these
regions. To bridge this gap, we propose MonoMVSNet, a novel monocular feature
and depth guided MVS network that integrates powerful priors from a monocular
foundation model into multi-view geometry. Firstly, the monocular feature of
the reference view is integrated into source view features by the attention
mechanism with a newly designed cross-view position encoding. Then, the
monocular depth of the reference view is aligned to dynamically update the
depth candidates for edge regions during the sampling procedure. Finally, a
relative consistency loss is further designed based on the monocular depth to
supervise the depth prediction. Extensive experiments demonstrate that
MonoMVSNet achieves state-of-the-art performance on the DTU and
Tanks-and-Temples datasets, ranking first on the Tanks-and-Temples Intermediate
and Advanced benchmarks. The source code is available at
https://github.com/JianfeiJ/MonoMVSNet.

</details>


### [55] [UGC-VideoCaptioner: An Omni UGC Video Detail Caption Model and New Benchmarks](https://arxiv.org/abs/2507.11336)
*Peiran Wu,Yunze Liu,Zhengdong Zhu,Enmin Zhou,Shawn Shen*

Main category: cs.CV

TL;DR: 本研究提出了UGC-VideoCap数据集和UGC-VideoCaptioner(3B)模型，以解决现有视频字幕方法侧重视觉而忽略音频的问题，旨在提升用户生成短视频的全模态理解能力。


<details>
  <summary>Details</summary>
Motivation: 现有的视频字幕基准和模型主要以视觉为中心，忽视了音频在传达场景动态、说话者意图和叙事背景方面的重要作用，这阻碍了细粒度、多模态视频理解的进展。

Method: 提出了一种名为UGC-VideoCap的新基准和模型框架，用于对短格式用户生成视频进行详细的全模态字幕生成。该方法包括一个有1000个TikTok视频的数据集，并通过结构化的三阶段人机协同流程进行标注，涵盖仅音频、仅视觉和联合音频-视觉语义。此外，还提出了一个30亿参数的字幕模型UGC-VideoCaptioner(3B)，该模型采用新颖的两阶段训练策略（监督微调后接Group Relative Policy Optimization（GRPO）），可以从有限的数据中进行高效适应，并保持竞争力。

Result: UGC-VideoCap是一个包含1000个TikTok视频的数据集，并包含4000个精心设计的问答对，用于探究单模态和跨模态理解。提出的UGC-VideoCaptioner(3B)模型在有限数据下实现了高效适应和有竞争力的性能。

Conclusion: 该基准和模型为在无约束的真实用户生成内容场景下推进全模态视频字幕生成提供了高质量的基础和数据高效的解决方案。

Abstract: Real-world user-generated videos, especially on platforms like TikTok, often
feature rich and intertwined audio visual content. However, existing video
captioning benchmarks and models remain predominantly visual centric,
overlooking the crucial role of audio in conveying scene dynamics, speaker
intent, and narrative context. This lack of omni datasets and lightweight,
capable models hampers progress in fine grained, multimodal video
understanding. To address these challenges, we introduce UGC-VideoCap, a new
benchmark and model framework specifically designed for detailed omnimodal
captioning of short form user-generated videos. Unlike prior datasets,
UGC-VideoCap emphasizes balanced integration of audio and visual modalities,
featuring 1000 TikTok videos annotated through a structured three stage
human-in-the-loop pipeline covering audio only, visual only, and joint audio
visual semantics. The benchmark also includes 4000 carefully crafted QA pairs
probing both unimodal and cross modal understanding. Alongside the dataset, we
propose UGC-VideoCaptioner(3B), a 3B parameter captioning model distilled from
Gemini 2.5 Flash. Using a novel two-stage training strategy supervised fine
tuning followed by Group Relative Policy Optimization (GRPO), our approach
enables efficient adaptation from limited data while maintaining competitive
performance. Together, our benchmark and model offer a high-quality foundation
and a data-efficient solution for advancing omnimodal video captioning in
unconstrained real-world UGC settings.

</details>


### [56] [Attributes Shape the Embedding Space of Face Recognition Models](https://arxiv.org/abs/2507.11372)
*Pierrick Leroy,Antonio Mastropietro,Marco Nurisso,Francesco Vaccarino*

Main category: cs.CV

TL;DR: 人脸识别（FR）的深度学习模型在嵌入空间中展现出多尺度几何结构，会受到发色或对比度等属性的影响。本研究提出了一种几何方法和一种新的对齐指标，用于量化FR模型在这些属性上的不变性，从而提高模型的可解释性。


<details>
  <summary>Details</summary>
Motivation: 深度神经网络在人脸识别（FR）任务中取得了显著进展，特别是通过将面部图像嵌入高维特征空间中的基于边界的三元损失。在训练过程中，这些对比损失仅关注身份信息作为标签。然而，我们观察到嵌入空间中出现了一个多尺度几何结构，受到可解释面部（例如，发色）和图像属性（例如，对比度）的影响。

Method: 提出了一种几何方法来描述人脸识别模型对属性的依赖性或不变性，并引入了一种受物理学启发的对齐指标。

Result: 评估了在受控的、简化的模型和使用合成数据进行微调的广泛使用的人脸识别模型上提出的指标，以进行有针对性的属性增强。

Conclusion: 该模型在不同属性上表现出不同程度的不变性，揭示了其优点和缺点，并实现了更深层次的可解释性。

Abstract: Face Recognition (FR) tasks have made significant progress with the advent of
Deep Neural Networks, particularly through margin-based triplet losses that
embed facial images into high-dimensional feature spaces. During training,
these contrastive losses focus exclusively on identity information as labels.
However, we observe a multiscale geometric structure emerging in the embedding
space, influenced by interpretable facial (e.g., hair color) and image
attributes (e.g., contrast). We propose a geometric approach to describe the
dependence or invariance of FR models to these attributes and introduce a
physics-inspired alignment metric. We evaluate the proposed metric on
controlled, simplified models and widely used FR models fine-tuned with
synthetic data for targeted attribute augmentation. Our findings reveal that
the models exhibit varying degrees of invariance across different attributes,
providing insight into their strengths and weaknesses and enabling deeper
interpretability. Code available here:
https://github.com/mantonios107/attrs-fr-embs}{https://github.com/mantonios107/attrs-fr-embs

</details>


### [57] [Implementing Adaptations for Vision AutoRegressive Model](https://arxiv.org/abs/2507.11441)
*Kaif Shaikh,Antoni Kowalczuk,Franziska Boenisch,Adam Dziedzic*

Main category: cs.CV

TL;DR: 本研究评估了VAR在图像生成中的适应性，发现它在非DP任务上优于DM，但在DP任务上表现不佳，需要进一步研究。


<details>
  <summary>Details</summary>
Motivation: 本研究旨在探索VAR模型在特定下游任务（如医学数据生成）的适应性，并解决了VAR在差分隐私（DP）适应性方面的不足，而DM在这方面已有广泛研究。

Method: 实现了多种VAR适应性策略，并与DM适应性策略进行了基准测试和比较。

Result: VAR在非DP适应性任务上优于DM，但在DP适应性任务上性能受到影响。

Conclusion: VAR在非差分隐私（DP）适应性任务上表现优于DM，但在DP适应性任务上性能有所下降，需要进一步研究VAR的私有适应性。

Abstract: Vision AutoRegressive model (VAR) was recently introduced as an alternative
to Diffusion Models (DMs) in image generation domain. In this work we focus on
its adaptations, which aim to fine-tune pre-trained models to perform specific
downstream tasks, like medical data generation. While for DMs there exist many
techniques, adaptations for VAR remain underexplored. Similarly, differentially
private (DP) adaptations-ones that aim to preserve privacy of the adaptation
data-have been extensively studied for DMs, while VAR lacks such solutions. In
our work, we implement and benchmark many strategies for VAR, and compare them
to state-of-the-art DM adaptation strategies. We observe that VAR outperforms
DMs for non-DP adaptations, however, the performance of DP suffers, which
necessitates further research in private adaptations for VAR. Code is available
at https://github.com/sprintml/finetuning_var_dp.

</details>


### [58] [COLI: A Hierarchical Efficient Compressor for Large Images](https://arxiv.org/abs/2507.11443)
*Haoran Wang,Hanyu Pei,Yang Lyu,Kai Zhang,Li Li,Feng-Lei Fan*

Main category: cs.CV

TL;DR: COLI使用神经表示（NeRV）来压缩大型图像，通过加速训练和改进压缩技术，实现了更高的压缩比和更快的速度。


<details>
  <summary>Details</summary>
Motivation: 传统图像压缩技术在细节保留和泛化能力方面存在不足。隐式神经表示（INR）作为一种新兴的压缩方法，虽然避免了泛化问题，但在压缩大型图像时存在速度慢和压缩比不佳的挑战。

Method: COLI框架，结合了预训练-微调范式、混合精度训练和并行化目标函数来加速INR的收敛，并采用了Hyper-Compression后训练技术来提高压缩比。

Result: COLI框架在医学成像数据集上实现了具有竞争力的PSNR和SSIM指标，同时显著降低了每像素比特数（bpp），并将NeRV的训练速度提高了4倍。

Conclusion: COLI框架利用神经表示（NeRV）实现了对大型图像的高效压缩，通过预训练-微调范式、混合精度训练和并行化目标函数加速了训练收敛，并引入了Hyper-Compression后训练技术以提高压缩比，同时保持了最小的失真。在医学成像数据集上的评估表明，COLI在显著降低每像素比特数（bpp）的同时，实现了具有竞争力的PSNR和SSIM指标，并将NeRV训练速度提高了4倍。

Abstract: The escalating adoption of high-resolution, large-field-of-view imagery
amplifies the need for efficient compression methodologies. Conventional
techniques frequently fail to preserve critical image details, while
data-driven approaches exhibit limited generalizability. Implicit Neural
Representations (INRs) present a promising alternative by learning continuous
mappings from spatial coordinates to pixel intensities for individual images,
thereby storing network weights rather than raw pixels and avoiding the
generalization problem. However, INR-based compression of large images faces
challenges including slow compression speed and suboptimal compression ratios.
To address these limitations, we introduce COLI (Compressor for Large Images),
a novel framework leveraging Neural Representations for Videos (NeRV). First,
recognizing that INR-based compression constitutes a training process, we
accelerate its convergence through a pretraining-finetuning paradigm,
mixed-precision training, and reformulation of the sequential loss into a
parallelizable objective. Second, capitalizing on INRs' transformation of image
storage constraints into weight storage, we implement Hyper-Compression, a
novel post-training technique to substantially enhance compression ratios while
maintaining minimal output distortion. Evaluations across two medical imaging
datasets demonstrate that COLI consistently achieves competitive or superior
PSNR and SSIM metrics at significantly reduced bits per pixel (bpp), while
accelerating NeRV training by up to 4 times.

</details>


### [59] [HUG-VAS: A Hierarchical NURBS-Based Generative Model for Aortic Geometry Synthesis and Controllable Editing](https://arxiv.org/abs/2507.11474)
*Pan Du,Mingqi Xu,Xiaozhi Zhu,Jian-xun Wang*

Main category: cs.CV

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Accurate characterization of vascular geometry is essential for
cardiovascular diagnosis and treatment planning. Traditional statistical shape
modeling (SSM) methods rely on linear assumptions, limiting their expressivity
and scalability to complex topologies such as multi-branch vascular structures.
We introduce HUG-VAS, a Hierarchical NURBS Generative model for Vascular
geometry Synthesis, which integrates NURBS surface parameterization with
diffusion-based generative modeling to synthesize realistic, fine-grained
aortic geometries. Trained with 21 patient-specific samples, HUG-VAS generates
anatomically faithful aortas with supra-aortic branches, yielding biomarker
distributions that closely match those of the original dataset. HUG-VAS adopts
a hierarchical architecture comprising a denoising diffusion model that
generates centerlines and a guided diffusion model that synthesizes radial
profiles conditioned on those centerlines, thereby capturing two layers of
anatomical variability. Critically, the framework supports zero-shot
conditional generation from image-derived priors, enabling practical
applications such as interactive semi-automatic segmentation, robust
reconstruction under degraded imaging conditions, and implantable device
optimization. To our knowledge, HUG-VAS is the first SSM framework to bridge
image-derived priors with generative shape modeling via a unified integration
of NURBS parameterization and hierarchical diffusion processes.

</details>


### [60] [C-FBI: A Combinatorial method using Convolutions for Circle Fitting in Blurry Images](https://arxiv.org/abs/2507.11476)
*Esteban Román Catafau,Torbjörn E. M. Nordling*

Main category: cs.CV

TL;DR: 3C-FBI 是一种新的圆检测和拟合算法，在模糊图像和存在异常值的情况下表现出色，速度快、精度高。


<details>
  <summary>Details</summary>
Motivation: 解决在恶劣成像条件下鲁棒的圆检测和拟合这一计算机视觉基本挑战。

Method: 3C-FBI 算法结合了边缘像素（edgel）采样和参数空间中的卷积密度估计。

Result: 3C-FBI 在真实世界医学数据、合成数据和不同分辨率及异常值干扰水平的测试中均表现出色，达到了最先进的准确性（Jaccard 指数 0.896），并保持实时性能（40.3 fps），显著优于传统方法。

Conclusion: 3C-FBI 算法结合了边缘像素采样和参数空间中的卷积密度估计，在恶劣成像条件下实现了卓越的圆检测和拟合精度，同时保持实时性能，非常适合医学成像、机器人和工业检测等领域。

Abstract: This paper addresses the fundamental computer vision challenge of robust
circle detection and fitting in degraded imaging conditions. We present
Combinatorial Convolution-based Circle Fitting for Blurry Images (3C-FBI), an
algorithm that bridges the gap between circle detection and precise parametric
fitting by combining (1) efficient combinatorial edge pixel (edgel) sampling
and (2) convolution-based density estimation in parameter space.
  We evaluate 3C-FBI across three experimental frameworks: (1) real-world
medical data from Parkinson's disease assessments (144 frames from 36 videos),
(2) controlled synthetic data following established circle-fitting benchmarks,
and (3) systematic analysis across varying spatial resolutions and outlier
contamination levels. Results show that 3C-FBI achieves state-of-the-art
accuracy (Jaccard index 0.896) while maintaining real-time performance (40.3
fps), significantly outperforming classical methods like RCD (6.8 fps) on a
standard CPU (i7-10875H). It maintains near-perfect accuracy (Jaccard almost
1.0) at high resolutions (480x480) and reliable performance (Jaccard higher
than 0.95) down to 160x160 with up to 20% outliers.
  In extensive synthetic testing, 3C-FBI achieves a mean Jaccard Index of 0.989
across contamination levels, comparable to modern methods like Qi et al. (2024,
0.991), and surpassing RHT (0.964). This combination of accuracy, speed, and
robustness makes 3C-FBI ideal for medical imaging, robotics, and industrial
inspection under challenging conditions.

</details>


### [61] [COLIBRI Fuzzy Model: Color Linguistic-Based Representation and Interpretation](https://arxiv.org/abs/2507.11488)
*Pakizar Shamoi,Nuray Toganas,Muragul Muratbekova,Elnara Kadyrgali,Adilet Yerkin,Ayan Igali,Malika Ziyada,Ayana Adilova,Aron Karatayev,Yerdauit Torekhan*

Main category: cs.CV

TL;DR: 本研究提出了一种名为COLIBRI的人类感知颜色模型，使用模糊逻辑来模仿人类的颜色感知，并通过大规模实验验证了其优于传统颜色模型的性能，在设计、人工智能、市场营销和人机交互等领域具有重要意义。


<details>
  <summary>Details</summary>
Motivation: 为了弥合计算颜色表示与人类视觉感知之间的差距，本研究旨在创建一个能够模仿人类颜色感知的计算机模型。

Method: COLIBRI模型采用三阶段实验方法，首先通过初步实验识别颜色刺激，然后进行大规模人类颜色分类调查（超过1000名受试者），最后提取模糊分区和生成成员函数。模型还包含一个适应机制，可根据反馈和上下文变化进行优化。

Result: COLIBRI模型在颜色分类方面取得了显著成果，与RGB、HSV和LAB等传统模型相比，更符合人类感知。研究发现，该模型基于大规模样本（n=2496）构建，在颜色属性规范方面具有创新性。

Conclusion: 该COLIBRI模型通过模糊集和逻辑来模拟人类的颜色感知，并在颜色分类方面取得了显著成果，与RGB、HSV和LAB等传统模型相比，更符合人类感知。

Abstract: Colors are omnipresent in today's world and play a vital role in how humans
perceive and interact with their surroundings. However, it is challenging for
computers to imitate human color perception. This paper introduces the Human
Perception-Based Fuzzy Color Model, COLIBRI (Color Linguistic-Based
Representation and Interpretation), designed to bridge the gap between
computational color representations and human visual perception. The proposed
model uses fuzzy sets and logic to create a framework for color categorization.
Using a three-phase experimental approach, the study first identifies
distinguishable color stimuli for hue, saturation, and intensity through
preliminary experiments, followed by a large-scale human categorization survey
involving more than 1000 human subjects. The resulting data are used to extract
fuzzy partitions and generate membership functions that reflect real-world
perceptual uncertainty. The model incorporates a mechanism for adaptation that
allows refinement based on feedback and contextual changes. Comparative
evaluations demonstrate the model's alignment with human perception compared to
traditional color models, such as RGB, HSV, and LAB. To the best of our
knowledge, no previous research has documented the construction of a model for
color attribute specification based on a sample of this size or a comparable
sample of the human population (n = 2496). Our findings are significant for
fields such as design, artificial intelligence, marketing, and human-computer
interaction, where perceptually relevant color representation is critical.

</details>


### [62] [CATVis: Context-Aware Thought Visualization](https://arxiv.org/abs/2507.11522)
*Tariq Mehmood,Hamza Ahmad,Muhammad Haroon Shakeel,Murtaza Taj*

Main category: cs.CV

TL;DR: 提出一种五阶段EEG到图像生成框架，通过跨模态对齐和重排实现上下文感知，并在准确性和图像质量方面超越现有技术。


<details>
  <summary>Details</summary>
Motivation: 解决从复杂且嘈杂的EEG信号解码视觉表征的挑战，实现上下文感知的EEG到图像生成。

Method: 提出了一种新颖的五阶段框架，包括EEG编码器、跨模态对齐、标题重排、概念和标题嵌入的加权插值以及使用Stable Diffusion模型的图像生成。

Result: 实验结果表明，该方法生成的图像与视觉刺激高度一致，在分类准确率、生成准确率和Fréchet Inception Distance方面均优于现有最先进的方法。

Conclusion: 该方法在EEG信号的跨模态分析和图像生成方面取得了显著进展，通过多阶段框架实现了上下文感知的EEG到图像生成，并在准确性和图像质量方面优于现有技术。

Abstract: EEG-based brain-computer interfaces (BCIs) have shown promise in various
applications, such as motor imagery and cognitive state monitoring. However,
decoding visual representations from EEG signals remains a significant
challenge due to their complex and noisy nature. We thus propose a novel
5-stage framework for decoding visual representations from EEG signals: (1) an
EEG encoder for concept classification, (2) cross-modal alignment of EEG and
text embeddings in CLIP feature space, (3) caption refinement via re-ranking,
(4) weighted interpolation of concept and caption embeddings for richer
semantics, and (5) image generation using a pre-trained Stable Diffusion model.
We enable context-aware EEG-to-image generation through cross-modal alignment
and re-ranking. Experimental results demonstrate that our method generates
high-quality images aligned with visual stimuli, outperforming SOTA approaches
by 13.43% in Classification Accuracy, 15.21% in Generation Accuracy and
reducing Fr\'echet Inception Distance by 36.61%, indicating superior semantic
alignment and image quality.

</details>


### [63] [CharaConsist: Fine-Grained Consistent Character Generation](https://arxiv.org/abs/2507.11533)
*Mengyu Wang,Henghui Ding,Jianing Peng,Yao Zhao,Yunpeng Chen,Yunchao Wei*

Main category: cs.CV

TL;DR: CharaConsist improves text-to-image generation by ensuring consistent characters and backgrounds, even with large motions, using point-tracking attention and adaptive token merging, and is the first method for DiT models.


<details>
  <summary>Details</summary>
Motivation: Existing training-free methods for text-to-image generation suffer from inconsistent background details and identity/clothing inconsistencies when the foreground character undergoes large motion variations.

Method: CharaConsist employs point-tracking attention and adaptive token merge along with decoupled control of the foreground and background.

Result: CharaConsist enables fine-grained consistency for both foreground and background, addressing the limitations of previous methods and producing high-quality visual outputs suitable for various real-world applications.

Conclusion: CharaConsist enables fine-grained consistency for both foreground and background, supporting the generation of one character in continuous shots within a fixed scene or in discrete shots across different scenes. It is the first consistent generation method tailored for text-to-image DiT model and produces high-quality visual outputs, broadening its applicability to a wider range of real-world scenarios.

Abstract: In text-to-image generation, producing a series of consistent contents that
preserve the same identity is highly valuable for real-world applications.
Although a few works have explored training-free methods to enhance the
consistency of generated subjects, we observe that they suffer from the
following problems. First, they fail to maintain consistent background details,
which limits their applicability. Furthermore, when the foreground character
undergoes large motion variations, inconsistencies in identity and clothing
details become evident. To address these problems, we propose CharaConsist,
which employs point-tracking attention and adaptive token merge along with
decoupled control of the foreground and background. CharaConsist enables
fine-grained consistency for both foreground and background, supporting the
generation of one character in continuous shots within a fixed scene or in
discrete shots across different scenes. Moreover, CharaConsist is the first
consistent generation method tailored for text-to-image DiT model. Its ability
to maintain fine-grained consistency, combined with the larger capacity of
latest base model, enables it to produce high-quality visual outputs,
broadening its applicability to a wider range of real-world scenarios. The
source code has been released at https://github.com/Murray-Wang/CharaConsist

</details>


### [64] [Streaming 4D Visual Geometry Transformer](https://arxiv.org/abs/2507.11539)
*Dong Zhuo,Wenzhao Zheng,Jiahe Guo,Yuqi Wu,Jie Zhou,Jiwen Lu*

Main category: cs.CV

TL;DR: 提出了一种流式4D视觉几何变换器，可以实时从视频中重建4D几何，速度快且质量高。


<details>
  <summary>Details</summary>
Motivation: 为了促进交互式和实时应用，研究如何从视频中感知和重建4D时空几何。

Method: 提出了一种流式4D视觉几何变换器，采用因果变换器架构，利用时间因果注意力和缓存历史键值作为隐式记忆，以在线方式处理输入序列，并从密集的双向视觉几何基础变换器（VGGT）中蒸馏知识。

Result: 在各种4D几何感知基准测试中，该模型在在线场景下提高了推理速度，同时保持了具有竞争力的性能。

Conclusion: 该模型通过知识蒸馏和优化的注意力机制，在保持高质量空间一致性的同时，提高了在线场景下的推理速度，为可扩展和交互式的4D视觉系统铺平了道路。

Abstract: Perceiving and reconstructing 4D spatial-temporal geometry from videos is a
fundamental yet challenging computer vision task. To facilitate interactive and
real-time applications, we propose a streaming 4D visual geometry transformer
that shares a similar philosophy with autoregressive large language models. We
explore a simple and efficient design and employ a causal transformer
architecture to process the input sequence in an online manner. We use temporal
causal attention and cache the historical keys and values as implicit memory to
enable efficient streaming long-term 4D reconstruction. This design can handle
real-time 4D reconstruction by incrementally integrating historical information
while maintaining high-quality spatial consistency. For efficient training, we
propose to distill knowledge from the dense bidirectional visual geometry
grounded transformer (VGGT) to our causal model. For inference, our model
supports the migration of optimized efficient attention operator (e.g.,
FlashAttention) from the field of large language models. Extensive experiments
on various 4D geometry perception benchmarks demonstrate that our model
increases the inference speed in online scenarios while maintaining competitive
performance, paving the way for scalable and interactive 4D vision systems.
Code is available at: https://github.com/wzzheng/StreamVGGT.

</details>


### [65] [Towards Depth Foundation Model: Recent Trends in Vision-Based Depth Estimation](https://arxiv.org/abs/2507.11540)
*Zhen Xu,Hongyu Zhou,Sida Peng,Haotong Lin,Haoyu Guo,Jiahao Shao,Peishan Yang,Qinglin Yang,Sheng Miao,Xingyi He,Yifan Wang,Yue Wang,Ruizhen Hu,Yiyi Liao,Xiaowei Zhou,Hujun Bao*

Main category: cs.CV

TL;DR: 本文综述了深度估计技术的发展，特别是深度基础模型的潜力，旨在克服现有方法的局限性，并为未来的研究和应用提供指导。


<details>
  <summary>Details</summary>
Motivation: 为了克服传统深度估计方法（如基于激光雷达的方法）在成本、分辨率和环境适应性方面的局限性，并解决现有基于视觉的方法在泛化性和稳定性方面面临的挑战，本文旨在探索深度基础模型的潜力，以实现更鲁棒的深度估计。

Method: 本文通过对深度学习架构和范式的演变进行回顾，以及对大规模数据集的概述，来探讨深度估计领域的发展，特别是“深度基础模型”的潜力。

Result: 本文对深度估计领域进行了全面的概述，重点介绍了深度基础模型的发展，包括其关键架构、训练策略以及大规模数据集的支持，旨在为未来的研究和应用提供指导。

Conclusion: 深度估计任务在3D计算机视觉中至关重要，尤其是在3D重建、自由视角渲染、机器人、自动驾驶以及AR/VR技术等领域。虽然基于硬件的方法（如激光雷达）因成本高、分辨率低和环境敏感性而受到限制，但基于视觉的方法提供了一种有前景的替代方案，尽管在泛化性和稳定性方面仍面临挑战。受其他领域尺度定律和基础模型的启发，本文探讨了用于深度估计的“深度基础模型”，即在大型数据集上训练并具有强大零样本泛化能力的深度神经网络。文章回顾了单目、立体、多视图和单目视频设置下深度估计的深度学习架构和范式的演变，并讨论了这些模型解决现有挑战的潜力。此外，还对支持这些模型发展的大规模数据集进行了全面概述，旨在通过识别关键架构和训练策略，为构建鲁棒的深度基础模型指明方向，并为未来的研究和应用提供见解。

Abstract: Depth estimation is a fundamental task in 3D computer vision, crucial for
applications such as 3D reconstruction, free-viewpoint rendering, robotics,
autonomous driving, and AR/VR technologies. Traditional methods relying on
hardware sensors like LiDAR are often limited by high costs, low resolution,
and environmental sensitivity, limiting their applicability in real-world
scenarios. Recent advances in vision-based methods offer a promising
alternative, yet they face challenges in generalization and stability due to
either the low-capacity model architectures or the reliance on domain-specific
and small-scale datasets. The emergence of scaling laws and foundation models
in other domains has inspired the development of "depth foundation models":
deep neural networks trained on large datasets with strong zero-shot
generalization capabilities. This paper surveys the evolution of deep learning
architectures and paradigms for depth estimation across the monocular, stereo,
multi-view, and monocular video settings. We explore the potential of these
models to address existing challenges and provide a comprehensive overview of
large-scale datasets that can facilitate their development. By identifying key
architectures and training strategies, we aim to highlight the path towards
robust depth foundation models, offering insights into their future research
and applications.

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [66] [Truth Sleuth and Trend Bender: AI Agents to fact-check YouTube videos and influence opinions](https://arxiv.org/abs/2507.10577)
*Logé Cécile,Ghori Rehan*

Main category: cs.CL

TL;DR: 推出一个AI系统，由Truth Sleuth和Trend Bender组成，用于事实核查YouTube视频中的主张，并通过在评论区与用户互动来挑战错误信息，以期促进更知情的在线环境。


<details>
  <summary>Details</summary>
Motivation: 为了应对数字时代虚假信息通过YouTube等平台迅速传播的威胁，开发一种能够事实核查并与用户互动以挑战错误信息的AI系统。

Method: 开发了一个由两个AI代理组成的系统：Truth Sleuth（利用检索增强生成（RAG）技术从维基百科、谷歌搜索和谷歌FactCheck等来源核查YouTube视频中的主张）和Trend Bender（利用Truth Sleuth的报告和相关文章语料库生成评论，以引发辩论，并通过自我评估循环进行改进）。

Result: 实验表明，该系统的事实核查代理具有高准确性，并且AI驱动的干预措施有潜力在对抗虚假信息和营造更知情的在线空间方面发挥作用。

Conclusion: 该系统展示了AI在打击虚假信息方面的潜力，通过准确的事实核查和富有洞察力的评论与用户互动，促进更知情的在线环境。

Abstract: Misinformation poses a significant threat in today's digital world, often
spreading rapidly through platforms like YouTube. This paper introduces a novel
approach to combating misinformation by developing an AI-powered system that
not only fact-checks claims made in YouTube videos but also actively engages
users in the comment section and challenge misleading narratives. Our system
comprises two main agents: Truth Sleuth and Trend Bender.
  Truth Sleuth extracts claims from a YouTube video, uses a Retrieval-Augmented
Generation (RAG) approach - drawing on sources like Wikipedia, Google Search,
Google FactCheck - to accurately assess their veracity and generates a nuanced
and comprehensive report. Through rigorous prompt engineering, Trend Bender
leverages this report along with a curated corpus of relevant articles to
generate insightful and persuasive comments designed to stimulate a productive
debate. With a carefully set up self-evaluation loop, this agent is able to
iteratively improve its style and refine its output.
  We demonstrate the system's capabilities through experiments on established
benchmark datasets and a real-world deployment on YouTube, showcasing its
potential to engage users and potentially influence perspectives. Our findings
highlight the high accuracy of our fact-checking agent, and confirm the
potential of AI-driven interventions in combating misinformation and fostering
a more informed online space.

</details>


### [67] [An Offline Mobile Conversational Agent for Mental Health Support: Learning from Emotional Dialogues and Psychological Texts with Student-Centered Evaluation](https://arxiv.org/abs/2507.10580)
*Vimaleswar A,Prabhu Nandan Sahu,Nilesh Kumar Sahu,Haroon R Lone*

Main category: cs.CL

TL;DR: EmoSApp 是一款创新的离线智能手机应用，利用微调的 LLM 提供安全、个性化的心理健康支持，解决了传统数字平台的局限性。


<details>
  <summary>Details</summary>
Motivation: 现有的数字心理健康和情感支持平台存在用户可及性、网络连接和数据隐私方面的限制。因此，需要一个能够解决这些挑战的离线、基于智能手机的解决方案。

Method: 提出并实现了一个名为 EmoSApp 的离线、基于智能手机的对话应用程序，用于提供心理健康和情感支持。该系统利用了经过 Torchtune 和 Executorch 微调、量化和部署的大型语言模型 (LLM)，以确保所有推理都在智能手机上进行。具体来说，对 LLaMA-3.2-1B-Instruct 模型进行了微调，使用了包含 14,582 个心理健康问答对的自定义“知识数据集”以及多轮对话数据。

Result: EmoSApp 在学生人群中的定性人类评估表明，该应用能够做出连贯、富有同情心的回应，维持互动对话，并为用户的心理健康问题提供相关建议。此外，在九个标准常识和推理基准上的定量评估证明了经过微调、量化的模型在低资源环境下的有效性。

Conclusion: EmoSApp 作为一个完全离线、基于智能手机的对话应用程序，为心理健康和情感支持提供了新的解决方案。它通过在资源受限设备上部署经过微调、量化的大型语言模型，解决了用户可及性、网络连接和数据隐私等挑战。该应用在定性和定量评估中均表现出良好的效果，能够进行连贯、富有同情心的互动，并提供相关的心理健康建议，为未来便携、安全、定制化的 AI 心理健康解决方案奠定了基础。

Abstract: Mental health plays a crucial role in the overall well-being of an
individual. In recent years, digital platforms have been increasingly used to
expand mental health and emotional support. However, there are persistent
challenges related to limited user accessibility, internet connectivity, and
data privacy, which highlight the need for an offline, smartphone-based
solution. To address these challenges, we propose EmoSApp (Emotional Support
App): an entirely offline, smartphone-based conversational app designed for
mental health and emotional support. The system leverages Large Language Models
(LLMs), specifically fine-tuned, quantized and deployed using Torchtune and
Executorch for resource-constrained devices, allowing all inferences to occur
on the smartphone. To equip EmoSApp with robust domain expertise, we fine-tuned
the LLaMA-3.2-1B-Instruct model on our custom curated ``Knowledge dataset'' of
14,582 mental-health QA pairs, along with the multi-turn conversational data.
  Through qualitative human evaluation with the student population, we
demonstrate that EmoSApp has the ability to respond coherently, empathetically,
maintain interactive dialogue, and provide relevant suggestions to user's
mental health problems. Additionally, quantitative evaluations on nine standard
commonsense and reasoning benchmarks demonstrate the efficacy of our
fine-tuned, quantized model in low-resource settings. By prioritizing on-device
deployment and specialized domain adaptation, EmoSApp serves as a blueprint for
future innovations in portable, secure, and highly tailored AI-driven mental
health solutions.

</details>


### [68] [Transforming Sensitive Documents into Quantitative Data: An AI-Based Preprocessing Toolchain for Structured and Privacy-Conscious Analysis](https://arxiv.org/abs/2507.10582)
*Anders Ledberg,Anna Thalén*

Main category: cs.CL

TL;DR: 该研究提出了一个包含 LLM 提示、匿名化和嵌入生成的工具链，用于分析瑞典法院的敏感法律文件，成功地实现了数据匿名化和结构化，并支持大规模内容分析。


<details>
  <summary>Details</summary>
Motivation: 非结构化法律、医疗和行政来源的文本为公共卫生和社会科学研究提供了丰富但未被充分利用的资源。然而，大规模分析受到两个关键挑战的阻碍：存在敏感的、可识别的个人信息，以及在结构和语言上的显著差异。本研究旨在提供一个工具链，以应对这些挑战，实现对敏感文本数据的可扩展分析。

Method: 该工具链利用大型语言模型（LLM）提示来标准化、摘要和翻译文本（如有必要）为英语，以提高可比性。通过基于 LLM 的 redaction，并辅以命名实体识别和基于规则的方法，实现了匿名化，以最大限度地降低泄露风险。在瑞典法院关于《滥用者关怀法》（LVM）的 10,842 份裁决语料库（超过 56,000 页）上展示了该工具链。每个文档都被处理成匿名化、标准化的摘要，并转换为文档级嵌入。

Result: 该工具链已被证明可以有效去除识别信息，同时保留语义内容。通过对由手动标记摘要组成的语料库进行训练，证明了该工具链在大规模半自动化内容分析方面的能力。

Conclusion: 该工具链通过实现对敏感文档的结构化、注重隐私的分析，为之前因隐私和异构性限制而无法访问的文本数据领域的大规模研究开辟了新的可能性。

Abstract: Unstructured text from legal, medical, and administrative sources offers a
rich but underutilized resource for research in public health and the social
sciences. However, large-scale analysis is hampered by two key challenges: the
presence of sensitive, personally identifiable information, and significant
heterogeneity in structure and language. We present a modular toolchain that
prepares such text data for embedding-based analysis, relying entirely on
open-weight models that run on local hardware, requiring only a
workstation-level GPU and supporting privacy-sensitive research.
  The toolchain employs large language model (LLM) prompting to standardize,
summarize, and, when needed, translate texts to English for greater
comparability. Anonymization is achieved via LLM-based redaction, supplemented
with named entity recognition and rule-based methods to minimize the risk of
disclosure. We demonstrate the toolchain on a corpus of 10,842 Swedish court
decisions under the Care of Abusers Act (LVM), comprising over 56,000 pages.
Each document is processed into an anonymized, standardized summary and
transformed into a document-level embedding. Validation, including manual
review, automated scanning, and predictive evaluation shows the toolchain
effectively removes identifying information while retaining semantic content.
As an illustrative application, we train a predictive model using embedding
vectors derived from a small set of manually labeled summaries, demonstrating
the toolchain's capacity for semi-automated content analysis at scale.
  By enabling structured, privacy-conscious analysis of sensitive documents,
our toolchain opens new possibilities for large-scale research in domains where
textual data was previously inaccessible due to privacy and heterogeneity
constraints.

</details>


### [69] [A Taxonomy for Design and Evaluation of Prompt-Based Natural Language Explanations](https://arxiv.org/abs/2507.10585)
*Isar Nejadgholi,Mona Omidyeganeh,Marc-Antoine Drouin,Jonathan Boisvert*

Main category: cs.CL

TL;DR: 该研究提出了一个XAI分类法，用于表征和评估大型语言模型的自然语言解释（NLE），以增强AI治理的透明度。


<details>
  <summary>Details</summary>
Motivation: 随着大型语言模型的兴起，自然语言解释（NLE）成为阐明模型行为的关键，因此需要对其特性和治理影响进行研究，以实现有效的AI治理。

Method: 通过借鉴XAI文献，结合大型语言模型（LLM）的兴起，研究提出了一个适用于提示式NLE的XAI分类法，该分类法从上下文、生成与呈现、评估三个维度对NLE的特性和治理影响进行了梳理。

Result: 该研究提出了一个包含三个维度（上下文、生成与呈现、评估）的XAI分类法，为研究人员、审计人员和政策制定者提供了表征、设计和增强NLE以实现透明AI系统的框架。

Conclusion: 该研究提出了一个适用于基于提示的自然语言解释（NLE）的XAI（可解释人工智能）分类法，涵盖了上下文、生成与呈现、评估三个维度，旨在为AI治理提供一个框架。

Abstract: Effective AI governance requires structured approaches for stakeholders to
access and verify AI system behavior. With the rise of large language models,
Natural Language Explanations (NLEs) are now key to articulating model
behavior, which necessitates a focused examination of their characteristics and
governance implications. We draw on Explainable AI (XAI) literature to create
an updated XAI taxonomy, adapted to prompt-based NLEs, across three dimensions:
(1) Context, including task, data, audience, and goals; (2) Generation and
Presentation, covering generation methods, inputs, interactivity, outputs, and
forms; and (3) Evaluation, focusing on content, presentation, and user-centered
properties, as well as the setting of the evaluation. This taxonomy provides a
framework for researchers, auditors, and policymakers to characterize, design,
and enhance NLEs for transparent AI systems.

</details>


### [70] [AutoRAG-LoRA: Hallucination-Triggered Knowledge Retuning via Lightweight Adapters](https://arxiv.org/abs/2507.10586)
*Kaushik Dwivedi,Padmanabh Patanjali Mishra*

Main category: cs.CL

TL;DR: AutoRAG-LoRA是一个用于检索增强生成（RAG）的框架，通过LoRA适配器和KL正则化训练来减少LLM的幻觉，并包含幻觉检测和反馈纠正机制。


<details>
  <summary>Details</summary>
Motivation: 解决大型语言模型（LLMs）在广泛的自然语言任务中表现出色但仍易出现幻觉（事实不准确）的问题，以增强在真实世界部署中的可信度。

Method: 通过集成自动化提示重写、混合检索、低秩适配器调优、幻觉检测模块（结合分类器和自评估技术）以及包含对比KL损失和适配器微调的反馈纠正循环来解决大型语言模型的幻觉问题。

Result: AutoRAG-LoRA显著减少了事实漂移，同时保持了模型的效率和模块化。

Conclusion: AutoRAG-LoRA通过轻量级的LoRA适配器和KL正则化训练，有效减少了大型语言模型的幻觉，同时保持了模型的效率和模块化。

Abstract: Large Language Models (LLMs) have demonstrated remarkable fluency across a
range of natural language tasks, yet remain vulnerable to hallucinations -
factual inaccuracies that undermine trust in real world deployment. We present
AutoRAG-LoRA, a modular framework for Retrieval-Augmented Generation (RAG) that
tackles hallucination in large language models through lightweight LoRA-based
adapters and KL-regularized training. Our pipeline integrates automated prompt
rewriting, hybrid retrieval, and low-rank adapter tuning to ground responses in
retrieved evidence. A hallucination detection module, using both
classifier-based and self-evaluation techniques, assigns confidence scores to
generated outputs, triggering an optional feedback correction loop. This loop
enforces factual alignment via contrastive KL loss and adapter fine tuning. We
demonstrate that AutoRAG-LoRA significantly reduces the factual drift while
preserving the efficiency and modularity of the model.

</details>


### [71] [Anthropomimetic Uncertainty: What Verbalized Uncertainty in Language Models is Missing](https://arxiv.org/abs/2507.10587)
*Dennis Ulmer,Alexandra Lorson,Ivan Titov,Christian Hardmeier*

Main category: cs.CL

TL;DR: 语言模型输出过于自信，但准确性存疑，影响了用户对其的信任。本研究旨在通过模仿人类沟通方式来改善语言模型的不确定性传达，并指出了该领域未来的研究方向。


<details>
  <summary>Details</summary>
Motivation: 为了在人机协作中发挥语言模型的优势并减少潜在危害，需要解决语言模型输出过于自信但准确性存疑的问题，并探索更可信赖的不确定性传达方式。

Method: 对人类不确定性沟通的研究进行了全面的概述，并对现有研究进行了调查，同时分析了语言模型在不确定性传达中存在的偏差。

Result: 目前的研究忽视了人类不确定性沟通的细微差别以及影响模型不确定性沟通的数据偏差。提出“拟人化不确定性”的概念，强调直观和可信赖的不确定性沟通需要模仿人类的沟通方式，并指出了未来研究的独特因素和方向。

Conclusion: 语言模型在不确定性传达方面需要模仿人类的沟通方式，以实现直观和可信赖的沟通。

Abstract: Human users increasingly rely on natural language interactions with large
language models (LLMs) in order to receive help on a large variety of tasks and
problems. However, the trustworthiness and perceived legitimacy of LLMs is
undermined by the fact that their output is frequently stated in very confident
terms, even when its accuracy is questionable. Therefore, there is a need to
signal the confidence of the language model to a user in order to reap the
benefits of human-machine collaboration and mitigate potential harms.
Verbalized uncertainty is the expression of confidence with linguistic means,
an approach that integrates perfectly into language-based interfaces.
Nevertheless, most recent research in natural language processing (NLP)
overlooks the nuances surrounding human uncertainty communication and the data
biases that influence machine uncertainty communication. We argue for
anthropomimetic uncertainty, meaning that intuitive and trustworthy uncertainty
communication requires a degree of linguistic authenticity and personalization
to the user, which could be achieved by emulating human communication. We
present a thorough overview over the research in human uncertainty
communication, survey ongoing research, and perform additional analyses to
demonstrate so-far overlooked biases in verbalized uncertainty. We conclude by
pointing out unique factors in human-machine communication of uncertainty and
deconstruct anthropomimetic uncertainty into future research directions for
NLP.

</details>


### [72] [PLEX: Perturbation-free Local Explanations for LLM-Based Text Classification](https://arxiv.org/abs/2507.10596)
*Yogachandran Rahulamathavan,Misbah Farooq,Varuna De Silva*

Main category: cs.CL

TL;DR: PLEX 是一种新的 XAI 方法，它利用 LLM 的上下文嵌入和一个 Siamese 网络来为文本分类提供快速、准确的解释，与 LIME 和 SHAP 相比，其效率提高了几个数量级。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLM）在文本分类方面表现出色，但其复杂性阻碍了可解释性，使得理解其预测背后的推理变得困难。LIME 和 SHAP 等可解释人工智能（XAI）方法通过识别有影响力的词语来提供局部解释，但它们依赖于计算成本高昂的扰动。这些方法通常会生成数千个扰动句子并对每个句子进行推理，尤其是在使用 LLM 时，会带来巨大的计算负担。

Method: PLEX（无扰动局部解释）是一种新颖的方法，它利用从 LLM 中提取的上下文嵌入和一个“Siamese 网络”风格的神经网络，该网络经过训练以匹配特征重要性分数。这种一次性训练消除了后续扰动的需要，从而能够为任何新句子提供高效的解释。

Result: PLEX 在四个不同的分类任务（情绪、假新闻、虚假 COVID-19 新闻和抑郁症）上展示了其有效性，与 LIME 和 SHAP 相比，具有超过 92% 的一致性。我们使用“压力测试”进行的评估显示，PLEX 能够准确识别有影响力的词语，当删除这些词语时，其分类准确性的下降幅度与 LIME 和 SHAP 相当。值得注意的是，在某些情况下，PLEX 在捕捉关键特征的影响方面表现出更优越的性能。

Conclusion: PLEX 极大地加速了文本分类的解释过程，将时间和计算开销分别降低了两个和四个数量级，为基于 LLM 的文本分类提供了一种有前景的可解释性解决方案。

Abstract: Large Language Models (LLMs) excel in text classification, but their
complexity hinders interpretability, making it difficult to understand the
reasoning behind their predictions. Explainable AI (XAI) methods like LIME and
SHAP offer local explanations by identifying influential words, but they rely
on computationally expensive perturbations. These methods typically generate
thousands of perturbed sentences and perform inferences on each, incurring a
substantial computational burden, especially with LLMs. To address this, we
propose \underline{P}erturbation-free \underline{L}ocal \underline{Ex}planation
(PLEX), a novel method that leverages the contextual embeddings extracted from
the LLM and a ``Siamese network" style neural network trained to align with
feature importance scores. This one-off training eliminates the need for
subsequent perturbations, enabling efficient explanations for any new sentence.
We demonstrate PLEX's effectiveness on four different classification tasks
(sentiment, fake news, fake COVID-19 news and depression), showing more than
92\% agreement with LIME and SHAP. Our evaluation using a ``stress test"
reveals that PLEX accurately identifies influential words, leading to a similar
decline in classification accuracy as observed with LIME and SHAP when these
words are removed. Notably, in some cases, PLEX demonstrates superior
performance in capturing the impact of key features. PLEX dramatically
accelerates explanation, reducing time and computational overhead by two and
four orders of magnitude, respectively. This work offers a promising solution
for explainable LLM-based text classification.

</details>


### [73] [Emergence of Hierarchical Emotion Organization in Large Language Models](https://arxiv.org/abs/2507.10599)
*Bo Zhao,Maya Okawa,Eric J. Bigelow,Rose Yu,Tomer Ullman,Ekdeep Singh Lubana,Hidenori Tanaka*

Main category: cs.CL

TL;DR: 研究LLMs如何模拟用户情绪状态，发现LLMs具有情绪层次结构且会内化社会认知，但在情绪识别方面存在对弱势群体的偏差。


<details>
  <summary>Details</summary>
Motivation: 为了能够符合伦理地部署LLMs驱动的对话代理，理解它们如何模拟用户的情绪状态至关重要。

Method: 通过分析模型输出中的概率依赖关系，并将其与心理学中的情绪轮理论进行比较，来研究LLMs如何模拟用户的情绪状态。此外，还进行了人类研究以验证LLMs的发现。

Result: LLMs会自然地形成与人类心理模型一致的情绪层次树。研究还发现，LLMs在情绪识别方面存在系统性偏差，对弱势群体的误分类会加剧。人类研究表明LLMs会内化社会认知。

Conclusion: LLMs会内化社会认知，并表现出与人类相似的情绪层次结构。模型规模越大，情绪层次结构越复杂。然而，在跨社会经济群体的情绪识别方面存在系统性偏差，对代表性不足的群体的误分类会加剧。

Abstract: As large language models (LLMs) increasingly power conversational agents,
understanding how they model users' emotional states is critical for ethical
deployment. Inspired by emotion wheels -- a psychological framework that argues
emotions organize hierarchically -- we analyze probabilistic dependencies
between emotional states in model outputs. We find that LLMs naturally form
hierarchical emotion trees that align with human psychological models, and
larger models develop more complex hierarchies. We also uncover systematic
biases in emotion recognition across socioeconomic personas, with compounding
misclassifications for intersectional, underrepresented groups. Human studies
reveal striking parallels, suggesting that LLMs internalize aspects of social
perception. Beyond highlighting emergent emotional reasoning in LLMs, our
results hint at the potential of using cognitively-grounded theories for
developing better model evaluations.

</details>


### [74] [Testing Hypotheses from the Social Approval Theory of Online Hate: An Analysis of 110 Million Posts from Parler](https://arxiv.org/abs/2507.10810)
*David M. Markowitz,Samuel Hardman Taylor*

Main category: cs.CL

TL;DR: 在线仇恨言论的社会赞许理论在Parler平台上不成立。


<details>
  <summary>Details</summary>
Motivation: 本研究旨在探索在线仇恨言论的动机，特别是考察社会赞许理论在解释用户发布仇恨言论行为中的作用，并检验该理论在小众社交媒体平台上的适用性。

Method: 本研究使用2018年至2021年间从Parler收集的超过1.11亿条帖子，检验了Walther（2024）提出的在线仇恨的社会赞许理论的两个核心观点：1) 仇恨言论获得更多的社会赞许信号会预测后续产生更多仇恨言论；2) 随着社会赞许的增加，仇恨言论会变得更加极端。

Result: 研究结果表明，用户在一个仇恨言论帖子中获得的点赞数与其之后发布的仇恨言论数量（包括下一条帖子以及之后一周、一月、三月、六个月内的帖子）没有关联（H1a不成立）。同时，研究也未发现社会赞许的增加会导致仇恨言论的极端化（H1b不成立）。跨个体效应分析显示，在帖子层面，社会赞许与仇恨言论产生之间存在平均负相关，但在其他时间维度上的关系则不一致。

Conclusion: 研究发现，在Parler平台上，用户从仇恨言论中获得的“点赞”（社会赞许）数量与他们后续发布仇恨言论的数量之间没有关联，并且社会赞许的增加并未导致仇恨言论的极端化。此外，跨个体效应显示，社会赞许与仇恨言论的产生之间存在平均负相关关系，但在其他时间间隔上的关系则不确定。研究认为，在线仇恨的社会赞许强化机制在特定的小众社交媒体平台上可能有所不同。

Abstract: In this paper, we explored how online hate is motivated by receiving social
approval from others. We specifically examined two central tenets of Walther's
(2024) social approval theory of online hate: (H1a) more signals of social
approval on hate messages predicts more subsequent hate messages, and (H1b) as
social approval increases, hate speech messages become more extreme. Using over
110 million posts from Parler (2018-2021), we observed that the number of
upvotes a person received on a hate speech post was unassociated with the
amount of hate speech in their next post and posts during the next week, month,
three months, and six months. Between-person effects revealed an average
negative relationship between social approval and hate speech production at the
post level, but this relationship was mixed at other time intervals. Social
approval reinforcement mechanisms of online hate may operate differently on
niche social media platforms.

</details>


### [75] [Language Models for Adult Service Website Text Analysis](https://arxiv.org/abs/2507.10743)
*Nickolas Freeman,Thanh Nguyen,Gregory Bott,Jason Parton,Collin Francel*

Main category: cs.CL

TL;DR: 该研究针对成人服务网站（ASW）的文本分析，提出并验证了一种高效的自定义 transformer 模型，该模型在准确性、召回率、F1 分数和 ROC AUC 等指标上优于现有模型，并展示了其在数据分解、聚类和表情符号使用分析等任务中的应用潜力。


<details>
  <summary>Details</summary>
Motivation: 成人服务网站（ASW）长期以来一直与人口贩运相关，为人口贩运者提供了一个宣传其受害者的平台。因此，打击人口贩运的组织在试图识别潜在的人口贩运受害者时，经常使用 ASW 数据。将 ASW 数据转化为可行的见解所面临的一个关键挑战是文本分析。

Method: 对语言建模方法进行了全面研究，包括简单信息检索方法、预训练 transformer 和自定义 transformer 模型，并证明了 ASW 文本数据的特性允许使用相对较少的 GPU 资源高效地训练自定义 transformer 模型，并能在消费者硬件上高效地用于推理。

Result: 自定义模型在准确性、召回率、F1 分数和 ROC AUC 方面优于包括 BERT-base、RoBERTa 和 ModernBERT 在内的知名 encoder-only transformer 模型的微调变体。

Conclusion: 所开发模型代表了成人服务网站(ASW)文本分析的重大进展，可用于各种下游应用程序和研究。

Abstract: Sex trafficking refers to the use of force, fraud, or coercion to compel an
individual to perform in commercial sex acts against their will. Adult service
websites (ASWs) have and continue to be linked to sex trafficking, offering a
platform for traffickers to advertise their victims. Thus, organizations
involved in the fight against sex trafficking often use ASW data when
attempting to identify potential sex trafficking victims. A critical challenge
in transforming ASW data into actionable insight is text analysis. Previous
research using ASW data has shown that ASW ad text is important for linking
ads. However, working with this text is challenging due to its extensive use of
emojis, poor grammar, and deliberate obfuscation to evade law enforcement
scrutiny. We conduct a comprehensive study of language modeling approaches for
this application area, including simple information retrieval methods,
pre-trained transformers, and custom transformer models. We demonstrate that
characteristics of ASW text data allow efficient custom transformer models to
be trained with relatively small GPU resources and used efficiently for
inference on consumer hardware. Our custom models outperform fine-tuned
variants of well-known encoder-only transformer models, including BERT-base,
RoBERTa, and ModernBERT, on accuracy, recall, F1 score, and ROC AUC. We
demonstrate the use of our best-performing custom configuration on three tasks
related to ASW data analysis: (i) decomposing the giant component in a graph
representation of ASW data, (ii) clustering ASW ad text, and (iii) using the
learned token embeddings to understand the use of emojis in the illicit context
we study. The models we develop represent a significant advancement in ASW text
analysis, which can be leveraged in a variety of downstream applications and
research.

</details>


### [76] [Applying Text Embedding Models for Efficient Analysis in Labeled Property Graphs](https://arxiv.org/abs/2507.10772)
*Michal Podstawski*

Main category: cs.CL

TL;DR: 该研究通过嵌入文本属性来增强属性图的分析，提高了节点分类和关系预测的准确性。


<details>
  <summary>Details</summary>
Motivation: 利用标记属性图中丰富的文本属性来增强分析任务。

Method: 探索使用预训练的文本嵌入模型来嵌入文本节点和边缘属性，以实现高效的语义分析。

Result: 通过嵌入文本属性，支持节点分类和关系预测等下游任务，并提高了上下文理解能力。

Conclusion: 通过将文本语义集成到属性图的分析流程中，可以提高分析的准确性和可解释性。

Abstract: Labeled property graphs often contain rich textual attributes that can
enhance analytical tasks when properly leveraged. This work explores the use of
pretrained text embedding models to enable efficient semantic analysis in such
graphs. By embedding textual node and edge properties, we support downstream
tasks including node classification and relation prediction with improved
contextual understanding. Our approach integrates language model embeddings
into the graph pipeline without altering its structure, demonstrating that
textual semantics can significantly enhance the accuracy and interpretability
of property graph analysis.

</details>


### [77] [Can Multimodal Foundation Models Understand Schematic Diagrams? An Empirical Study on Information-Seeking QA over Scientific Papers](https://arxiv.org/abs/2507.10787)
*Yilun Zhao,Chengye Wang,Chuhan Li,Arman Cohan*

Main category: cs.CL

TL;DR: MISS-QA是一个新的基准测试，用于评估模型理解科学文献中的示意图。测试表明，即使是顶尖模型也无法达到人类专家的水平。


<details>
  <summary>Details</summary>
Motivation: 为了评估和改进模型解读科学文献中示意图的能力。

Method: 提出了MISS-QA基准测试，包含1500个专家标注的示例，涵盖465篇科学论文，旨在评估模型解读科学文献中示意图的能力。对18种前沿多模态基础模型进行了测试。

Result: 在MISS-QA基准测试中，18种前沿多模态基础模型（包括o4-mini、Gemini-2.5-Flash和Qwen2.5-VL）的表现与人类专家存在显著差距，展示了模型在理解不可回答问题方面的能力，并提供了详细的错误分析，指出了当前模型的优势和局限性。

Conclusion: 目前的多模态模型在解读科学文献中的示意图方面与人类专家存在显著差距，在MISS-QA基准测试中暴露了它们的优势和局限性。

Abstract: This paper introduces MISS-QA, the first benchmark specifically designed to
evaluate the ability of models to interpret schematic diagrams within
scientific literature. MISS-QA comprises 1,500 expert-annotated examples over
465 scientific papers. In this benchmark, models are tasked with interpreting
schematic diagrams that illustrate research overviews and answering
corresponding information-seeking questions based on the broader context of the
paper. We assess the performance of 18 frontier multimodal foundation models,
including o4-mini, Gemini-2.5-Flash, and Qwen2.5-VL. We reveal a significant
performance gap between these models and human experts on MISS-QA. Our analysis
of model performance on unanswerable questions and our detailed error analysis
further highlight the strengths and limitations of current models, offering key
insights to enhance models in comprehending multimodal scientific literature.

</details>


### [78] [LLMs on Trial: Evaluating Judicial Fairness for Large Language Models](https://arxiv.org/abs/2507.10852)
*Yiran Hu,Zongyue Xue,Haitao Li,Siyuan Zheng,Qingjing Chen,Shaochun Wang,Xihan Zhang,Ning Zheng,Yun Liu,Qingyao Ai,Yiqun Liu,Charles L. A. Clarke,Weixing Shen*

Main category: cs.CL

TL;DR: 该研究首次系统性地评估了大型语言模型（LLM）在司法领域的公平性，发现现有LLM普遍存在不公平现象，并提出了一套评估框架和指标，为未来的研究和改进提供了基础。


<details>
  <summary>Details</summary>
Motivation: LLM越来越多地应用于高风险领域，其司法公平性和对社会公正的潜在影响尚未得到充分研究，而LLM作为法官时，公平解决司法问题的能力是确保其可信度的先决条件。

Method: 提出一个包含65个标签和161个值的综合框架来衡量LLM的司法公平性，并构建了一个包含177,100个案例事实的数据集JudiFair。开发了一致性、偏见和不平衡准确性三个评估指标，并提出了一种评估多个LLM在各种标签上整体公平性的方法。

Result: 通过对16个LLM的实验，发现LLM在司法领域存在普遍的不一致性、偏见和不平衡的准确性。人口统计学标签上的偏见比程序性标签上的偏见更明显。不一致性增加与偏见减少相关，但准确性提高会加剧偏见。调整温度参数会影响LLM公平性，但模型大小、发布日期和来源国对司法公平性无显著影响。

Conclusion: LLM在司法领域存在普遍的不公平现象，具体表现在不一致性、偏见和不平衡的准确性方面，尤其是在处理人口统计学标签时偏见更为明显。

Abstract: Large Language Models (LLMs) are increasingly used in high-stakes fields
where their decisions impact rights and equity. However, LLMs' judicial
fairness and implications for social justice remain underexplored. When LLMs
act as judges, the ability to fairly resolve judicial issues is a prerequisite
to ensure their trustworthiness. Based on theories of judicial fairness, we
construct a comprehensive framework to measure LLM fairness, leading to a
selection of 65 labels and 161 corresponding values. Applying this framework to
the judicial system, we compile an extensive dataset, JudiFair, comprising
177,100 unique case facts. To achieve robust statistical inference, we develop
three evaluation metrics, inconsistency, bias, and imbalanced inaccuracy, and
introduce a method to assess the overall fairness of multiple LLMs across
various labels. Through experiments with 16 LLMs, we uncover pervasive
inconsistency, bias, and imbalanced inaccuracy across models, underscoring
severe LLM judicial unfairness. Particularly, LLMs display notably more
pronounced biases on demographic labels, with slightly less bias on substance
labels compared to procedure ones. Interestingly, increased inconsistency
correlates with reduced biases, but more accurate predictions exacerbate
biases. While we find that adjusting the temperature parameter can influence
LLM fairness, model size, release date, and country of origin do not exhibit
significant effects on judicial fairness. Accordingly, we introduce a publicly
available toolkit containing all datasets and code, designed to support future
research in evaluating and improving LLM fairness.

</details>


### [79] [How Stylistic Similarity Shapes Preferences in Dialogue Dataset with User and Third Party Evaluations](https://arxiv.org/abs/2507.10918)
*Ikumi Numaya,Shoji Moriya,Shiki Sato,Reina Akama,Jun Suzuki*

Main category: cs.CL

TL;DR: 本研究通过构建数据集，发现用户感知到的风格相似性比客观标注的风格相似性更能影响用户偏好，强调了区分这两者在对话系统研究中的重要性。


<details>
  <summary>Details</summary>
Motivation: 探讨了用户与聊天机器人之间风格相似性的主观和客观区别，以及它们对用户偏好的影响。

Method: 构建了一个包含用户偏好、主观风格相似性和客观风格相似性（由第三方评估者标注）的开放域对话数据集。

Result: 主观风格相似性与用户偏好之间存在很强的正相关关系，并且用户感知的主观风格相似性与第三方评估的客观风格相似性不同。

Conclusion: 区分主观和客观风格相似性对于理解用户偏好至关重要。

Abstract: Recent advancements in dialogue generation have broadened the scope of
human-bot interactions, enabling not only contextually appropriate responses
but also the analysis of human affect and sensitivity. While prior work has
suggested that stylistic similarity between user and system may enhance user
impressions, the distinction between subjective and objective similarity is
often overlooked. To investigate this issue, we introduce a novel dataset that
includes users' preferences, subjective stylistic similarity based on users'
own perceptions, and objective stylistic similarity annotated by third party
evaluators in open-domain dialogue settings. Analysis using the constructed
dataset reveals a strong positive correlation between subjective stylistic
similarity and user preference. Furthermore, our analysis suggests an important
finding: users' subjective stylistic similarity differs from third party
objective similarity. This underscores the importance of distinguishing between
subjective and objective evaluations and understanding the distinct aspects
each captures when analyzing the relationship between stylistic similarity and
user preferences. The dataset presented in this paper is available online.

</details>


### [80] [HanjaBridge: Resolving Semantic Ambiguity in Korean LLMs via Hanja-Augmented Pre-Training](https://arxiv.org/abs/2507.10920)
*Seungho Choi*

Main category: cs.CL

TL;DR: HanjaBridge通过在持续预训练中注入汉字信息来解决韩语同音词的歧义问题，显著提高了模型在韩语任务上的表现，并促进了跨语言迁移，同时在推理时保持了效率。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）在韩语等低资源语言中的表现不佳，部分原因是独特的语言挑战，例如韩文书写中无法区分的同音汉韩语词汇造成的语义歧义。

Method: HanjaBridge是一种新颖的意义注入技术，集成在持续预训练（CPT）框架中。它不将单词确定性地映射到单个汉字，而是向模型展示给定同形异义词的所有可能的汉字候选，促使模型学习上下文消歧。该过程与令牌级知识蒸馏相结合，以防止灾难性遗忘。

Result: HanjaBridge在KoBALT基准上实现了21%的相对提升，显著提高了韩语语言理解能力。通过共享汉字增强了韩语和中文之间的语义对齐，观察到了强大的跨语言迁移效应。即使在推理时省略汉字增强，性能增益也依然存在，没有额外的运行成本。

Conclusion: HanjaBridge通过为模型提供所有可能的相关汉字候选，有效解决了韩语同音词的语义歧义问题，并在持续预训练框架（CPT）中通过知识蒸馏防止了灾难性遗忘。实验表明，该方法显著提高了韩语理解能力（在KoBALT基准上相对提升21%），并通过共享汉字促进了韩语和中文之间的跨语言迁移。更重要的是，即使在推理时省略汉字增强，性能增益依然存在，保证了实际应用中的效率。

Abstract: Large language models (LLMs) often show poor performance in low-resource
languages like Korean, partly due to unique linguistic challenges such as
homophonous Sino-Korean words that are indistinguishable in Hangul script. To
address this semantic ambiguity, we propose HanjaBridge, a novel
meaning-injection technique integrated into a continual pre-training (CPT)
framework. Instead of deterministically mapping a word to a single Hanja
(Chinese character), HanjaBridge presents the model with all possible Hanja
candidates for a given homograph, encouraging the model to learn contextual
disambiguation. This process is paired with token-level knowledge distillation
to prevent catastrophic forgetting. Experimental results show that HanjaBridge
significantly improves Korean language understanding, achieving a 21\% relative
improvement on the KoBALT benchmark. Notably, by reinforcing semantic alignment
between Korean and Chinese through shared Hanja, we observe a strong positive
cross-lingual transfer. Furthermore, these gains persist even when Hanja
augmentation is omitted at inference time, ensuring practical efficiency with
no additional run-time cost.

</details>


### [81] [Modeling Understanding of Story-Based Analogies Using Large Language Models](https://arxiv.org/abs/2507.10957)
*Kalit Inani,Keshav Kabra,Vijay Marupudi,Sashank Varma*

Main category: cs.CL

TL;DR: LLMs在类比推理方面与人类的匹配度不如预期，尤其在精细化推理和解释方面存在差距。


<details>
  <summary>Details</summary>
Motivation: 探讨大型语言模型（LLMs）在检测和映射类比方面的能力是否与人类相当，以及它们在类比推理方面是否展现出类似人类的表现。

Method: 本研究通过分析LLMs的语义表征和显式提示来评估其类比推理能力，并与人类表现进行对比，同时考察了模型规模和架构的影响。

Result: 研究结果表明，LLMs在捕捉类比的相似性和差异性方面存在不足，并且显式提示在一定程度上可以提升其类比推理能力，但仍需与人类表现进行细致的对比。

Conclusion: LLMs在理解和生成类比方面与人类的相似性需要进一步研究，尤其是在个体类比推理和解释方面。

Abstract: Recent advancements in Large Language Models (LLMs) have brought them closer
to matching human cognition across a variety of tasks. How well do these models
align with human performance in detecting and mapping analogies? Prior research
has shown that LLMs can extract similarities from analogy problems but lack
robust human-like reasoning. Building on Webb, Holyoak, and Lu (2023), the
current study focused on a story-based analogical mapping task and conducted a
fine-grained evaluation of LLM reasoning abilities compared to human
performance. First, it explored the semantic representation of analogies in
LLMs, using sentence embeddings to assess whether they capture the similarity
between the source and target texts of an analogy, and the dissimilarity
between the source and distractor texts. Second, it investigated the
effectiveness of explicitly prompting LLMs to explain analogies. Throughout, we
examine whether LLMs exhibit similar performance profiles to those observed in
humans by evaluating their reasoning at the level of individual analogies, and
not just at the level of overall accuracy (as prior studies have done). Our
experiments include evaluating the impact of model size (8B vs. 70B parameters)
and performance variation across state-of-the-art model architectures such as
GPT-4 and LLaMA3. This work advances our understanding of the analogical
reasoning abilities of LLMs and their potential as models of human reasoning.

</details>


### [82] [DS@GT at eRisk 2025: From prompts to predictions, benchmarking early depression detection with conversational agent based assessments and temporal attention models](https://arxiv.org/abs/2507.10958)
*Anthony Miyaguchi,David Guecha,Yuwen Chiu,Sidharth Gaur*

Main category: cs.CL

TL;DR: DS@GT团队在eRisk 2025挑战赛中，利用LLMs和提示工程在对话式抑郁症检测任务中取得第二名。


<details>
  <summary>Details</summary>
Motivation: 本次工作笔记总结了DS@GT团队在eRisk 2025两个挑战中的参与情况，重点关注使用大型语言模型（LLMs）进行对话式抑郁症检测的试点任务。

Method: DS@GT团队采用提示工程策略，利用多种LLMs进行基于BDI-II的评估，并生成结构化JSON输出。由于缺乏真实标签，团队评估了跨模型的一致性和内部一致性。

Result: 在试点任务中，DS@GT团队的最佳提交在官方排行榜上名列第二，取得了DCHR = 0.50，ADODL = 0.89，ASHR = 0.27的成绩。

Conclusion: DS@GT团队在eRisk 2025的两个挑战中，使用LLMs和提示工程策略进行了对话式抑郁症检测。

Abstract: This Working Note summarizes the participation of the DS@GT team in two eRisk
2025 challenges. For the Pilot Task on conversational depression detection with
large language-models (LLMs), we adopted a prompt-engineering strategy in which
diverse LLMs conducted BDI-II-based assessments and produced structured JSON
outputs. Because ground-truth labels were unavailable, we evaluated cross-model
agreement and internal consistency. Our prompt design methodology aligned model
outputs with BDI-II criteria and enabled the analysis of conversational cues
that influenced the prediction of symptoms. Our best submission, second on the
official leaderboard, achieved DCHR = 0.50, ADODL = 0.89, and ASHR = 0.27.

</details>


### [83] [Teach Me Sign: Stepwise Prompting LLM for Sign Language Production](https://arxiv.org/abs/2507.10972)
*Zhaoyi An,Rei Kawakami*

Main category: cs.CL

TL;DR: TEAM-Sign fine-tunes an LLM to generate sign language by treating it as a natural language, using stepwise prompting to bridge the gap between sign and spoken languages.


<details>
  <summary>Details</summary>
Motivation: To address the limited impact of LLMs on sign language generation due to its complexity and unique rules, by treating sign language as a natural language.

Method: TEAM-Sign, a method that fine-tunes an LLM by treating sign language as a natural language, employing a stepwise prompting strategy to extract inherent sign language knowledge for learning and generation.

Result: Experimental results on How2Sign and Phoenix14T datasets demonstrate the effectiveness of the approach in aligning different distributions and grammatical rules between sign and spoken languages.

Conclusion: The proposed TEAM-Sign approach effectively leverages LLM's sign language knowledge and reasoning capabilities to address the distribution and grammatical differences between sign and spoken languages, showing promising results on How2Sign and Phoenix14T datasets.

Abstract: Large language models, with their strong reasoning ability and rich
knowledge, have brought revolution to many tasks of AI, but their impact on
sign language generation remains limited due to its complexity and unique
rules. In this paper, we propose TEAch Me Sign (TEAM-Sign), treating sign
language as another natural language. By fine-tuning an LLM, we enable it to
learn the correspondence between text and sign language, and facilitate
generation. Considering the differences between sign and spoken language, we
employ a stepwise prompting strategy to extract the inherent sign language
knowledge within the LLM, thereby supporting the learning and generation
process. Experimental results on How2Sign and Phoenix14T datasets demonstrate
that our approach effectively leverages both the sign language knowledge and
reasoning capabilities of LLM to align the different distribution and
grammatical rules between sign and spoken language.

</details>


### [84] [Mario at EXIST 2025: A Simple Gateway to Effective Multilingual Sexism Detection](https://arxiv.org/abs/2507.10996)
*Lin Tian,Johanne R. Trippas,Marian-Andrei Rizoiu*

Main category: cs.CL

TL;DR: 该研究提出了一种基于 Llama 3.1 8B 的分层 LoRA 方法，用于检测推文中存在的性别歧视。该方法通过适配所有线性层并引入条件适配器路由来优化模型性能，同时通过统一的多语言训练策略实现了跨语言迁移。研究结果表明，该方法在保持较低参数量和显著减少训练时间和存储占用的同时，取得了优于传统方法的性能。


<details>
  <summary>Details</summary>
Motivation: 该研究旨在解决文本中的性别歧视检测问题，并提出了一种参数高效的微调方法，以克服传统复杂数据处理和集成方法的局限性。

Method: 该研究提出了一种名为“分层低秩自适应”（LoRA）的方法，并在此基础上进行了条件适配器路由的改进，用于处理文本中的性别歧视检测问题。该方法应用于 Llama 3.1 8B 模型，并对所有线性变换进行了适配，而非仅限于注意力层。研究人员为每个子任务（二元性别歧视识别、来源意图检测、多标签性别歧视分类）训练了单独的 LoRA 适配器（秩=16，QLoRA 4 位），并采用了统一的多语言训练策略，利用了 Llama 3.1 的双语能力。该方法仅需要很少的预处理，并使用标准的监督学习。

Result: 该方法在 EXIST 2025 任务 1 中取得了具有竞争力的性能，在二元分类、意图检测和多标签分类任务上的 ICM-Hard 分别达到了 0.6774、0.4991 和 0.6519。与全量微调相比，可训练参数仅占 1.67%，训练时间缩短了 75%，模型存储减少了 98%。多语言训练策略通过跨语言迁移实现了 1.7-2.4% 的 F1 提升。

Conclusion: 该方法通过参数高效微调实现了具有竞争力的性能，同时大大减少了训练时间和模型存储。

Abstract: This paper presents our approach to EXIST 2025 Task 1, addressing text-based
sexism detection in English and Spanish tweets through hierarchical Low-Rank
Adaptation (LoRA) of Llama 3.1 8B. Our method introduces conditional adapter
routing that explicitly models label dependencies across three hierarchically
structured subtasks: binary sexism identification, source intention detection,
and multilabel sexism categorization. Unlike conventional LoRA applications
that target only attention layers, we apply adaptation to all linear
transformations, enhancing the model's capacity to capture task-specific
patterns. In contrast to complex data processing and ensemble approaches, we
show that straightforward parameter-efficient fine-tuning achieves strong
performance. We train separate LoRA adapters (rank=16, QLoRA 4-bit) for each
subtask using unified multilingual training that leverages Llama 3.1's native
bilingual capabilities. The method requires minimal preprocessing and uses
standard supervised learning. Our multilingual training strategy eliminates the
need for separate language-specific models, achieving 1.7-2.4\% F1 improvements
through cross-lingual transfer. With only 1.67\% trainable parameters compared
to full fine-tuning, our approach reduces training time by 75\% and model
storage by 98\%, while achieving competitive performance across all subtasks
(ICM-Hard: 0.6774 for binary classification, 0.4991 for intention detection,
0.6519 for multilabel categorization).

</details>


### [85] [Team HUMANE at AVeriTeC 2025: HerO 2 for Efficient Fact Verification](https://arxiv.org/abs/2507.11004)
*Yejun Yoon,Jaeyoon Jung,Seunghyun Yoon,Kunwoo Park*

Main category: cs.CL

TL;DR: HerO 2 是一个用于事实核查的系统，通过改进证据质量、优化真实性预测和集成更新的 LM 骨干来提升性能，在 AVeriTeC 任务中取得了第二名，同时保持了最短的运行时。


<details>
  <summary>Details</summary>
Motivation: HerO 2 是 HerO 的增强版本，HerO 是去年挑战中表现最佳的开源模型。

Method: HerO 2 通过文档摘要和答案改写来提高证据质量，通过计算约束下的训练后量化来优化真实性预测，并通过集成更新的语言模型（LM）骨干来增强整体系统性能。

Result: HerO 2 排名第二，运行时最短，效率高。

Conclusion: HerO 2 在 AVeriTeC 任务中取得了第二名的成绩，并实现了最快的运行时，展示了其在现实世界事实核查中的高效率和强大潜力。

Abstract: This paper presents HerO 2, Team HUMANE's system for the AVeriTeC shared task
at the FEVER-25 workshop. HerO 2 is an enhanced version of HerO, the
best-performing open-source model from the previous year's challenge. It
improves evidence quality through document summarization and answer
reformulation, optimizes veracity prediction via post-training quantization
under computational constraints, and enhances overall system performance by
integrating updated language model (LM) backbones. HerO 2 ranked second on the
leaderboard while achieving the shortest runtime among the top three systems,
demonstrating both high efficiency and strong potential for real-world fact
verification. The code is available at https://github.com/ssu-humane/HerO2.

</details>


### [86] [Journalism-Guided Agentic In-Context Learning for News Stance Detection](https://arxiv.org/abs/2507.11049)
*Dahyun Lee,Jonghyeon Choi,Jiyoung Han,Kunwoo Park*

Main category: cs.CL

TL;DR: 本研究提出了 K-News-Stance 数据集和 JoA-ICL 框架，用于韩语长篇新闻文章的立场检测，并在新闻推荐和媒体偏见分析方面取得了良好效果。


<details>
  <summary>Details</summary>
Motivation: 为了解决现有立场检测研究主要局限于短文本和高资源语言的问题，本研究旨在通过韩语新闻文章的立场检测来促进观点多样性和揭示媒体偏见。

Method: 研究提出了 JoA-ICL 框架，该框架利用语言模型代理预测关键结构片段（如导语、引语）的立场，然后聚合这些片段的立场以推断整篇文章的立场。

Result: JoA-ICL 框架在立场检测任务上优于现有方法，证明了逐层分析在捕捉长篇新闻文章整体立场方面的优势。此外，通过两个案例研究，证明了该框架在促进新闻推荐中的观点多样性和揭示媒体偏见模式方面的广泛应用潜力。

Conclusion: 本研究提出了 K-News-Stance 数据集和 JoA-ICL 框架，用于解决韩语长篇新闻文章的立场检测问题，并成功应用于新闻推荐和媒体偏见分析。

Abstract: As online news consumption grows, personalized recommendation systems have
become integral to digital journalism. However, these systems risk reinforcing
filter bubbles and political polarization by failing to incorporate diverse
perspectives. Stance detection -- identifying a text's position on a target --
can help mitigate this by enabling viewpoint-aware recommendations and
data-driven analyses of media bias. Yet, existing stance detection research
remains largely limited to short texts and high-resource languages. To address
these gaps, we introduce \textsc{K-News-Stance}, the first Korean dataset for
article-level stance detection, comprising 2,000 news articles with
article-level and 19,650 segment-level stance annotations across 47 societal
issues. We also propose \textsc{JoA-ICL}, a \textbf{Jo}urnalism-guided
\textbf{A}gentic \textbf{I}n-\textbf{C}ontext \textbf{L}earning framework that
employs a language model agent to predict the stances of key structural
segments (e.g., leads, quotes), which are then aggregated to infer the overall
article stance. Experiments show that \textsc{JoA-ICL} outperforms existing
stance detection methods, highlighting the benefits of segment-level agency in
capturing the overall position of long-form news articles. Two case studies
further demonstrate its broader utility in promoting viewpoint diversity in
news recommendations and uncovering patterns of media bias.

</details>


### [87] [LLM-Augmented Symptom Analysis for Cardiovascular Disease Risk Prediction: A Clinical NLP](https://arxiv.org/abs/2507.11052)
*Haowei Yang,Ziyu Shen,Junli Shao,Luyao Men,Xinyue Han,Jing Dong*

Main category: cs.CL

TL;DR: 本研究提出了一种利用大型语言模型（LLM）增强的临床NLP流程，通过领域适应、微调和提示工程，从临床笔记中提取信息以改进心血管疾病风险评估，并在MIMIC-III和CARDIO-NLP数据集上取得了更好的性能。


<details>
  <summary>Details</summary>
Motivation: 及时识别和准确评估心血管疾病（CVD）的风险对于降低全球死亡率仍然至关重要。现有的预测模型主要利用结构化数据，但非结构化的临床笔记包含有价值的早期指标。

Method: 本研究引入了一个新颖的、经大型语言模型增强的临床NLP流程，该流程采用领域适应的大型语言模型进行症状提取、上下文推理和自由文本报告的相关性分析。该方法整合了心血管特定微调、基于提示的推理和实体感知推理。通过提示工程和混合基于规则的验证来解决上下文幻觉和时间模糊等挑战。

Result: 在MIMIC-III和CARDIO-NLP数据集上的评估表明，在精确率、召回率、F1分数和AUROC方面均有改进，并且心脏病专家评估的临床相关性高（kappa = 0.82）。

Conclusion: 本研究表明大型语言模型在临床决策支持系统（CDSS）中有潜力，能够改进早期预警系统，并将患者叙述转化为可行的风险评估。

Abstract: Timely identification and accurate risk stratification of cardiovascular
disease (CVD) remain essential for reducing global mortality. While existing
prediction models primarily leverage structured data, unstructured clinical
notes contain valuable early indicators. This study introduces a novel
LLM-augmented clinical NLP pipeline that employs domain-adapted large language
models for symptom extraction, contextual reasoning, and correlation from
free-text reports. Our approach integrates cardiovascular-specific fine-tuning,
prompt-based inference, and entity-aware reasoning. Evaluations on MIMIC-III
and CARDIO-NLP datasets demonstrate improved performance in precision, recall,
F1-score, and AUROC, with high clinical relevance (kappa = 0.82) assessed by
cardiologists. Challenges such as contextual hallucination, which occurs when
plausible information contracts with provided source, and temporal ambiguity,
which is related with models struggling with chronological ordering of events
are addressed using prompt engineering and hybrid rule-based verification. This
work underscores the potential of LLMs in clinical decision support systems
(CDSS), advancing early warning systems and enhancing the translation of
patient narratives into actionable risk assessments.

</details>


### [88] [Social Media Sentiments Analysis on the July Revolution in Bangladesh: A Hybrid Transformer Based Machine Learning Approach](https://arxiv.org/abs/2507.11084)
*Md. Sabbir Hossen,Md. Saiduzzaman,Pabon Shaha*

Main category: cs.CL

TL;DR: 该研究提出了一种基于混合Transformer模型的情感分析框架，用于分析孟加拉国七月革命期间社交媒体上的公众意见。该框架在处理孟加拉语数据方面表现出色，准确率达到83.7%，并展示了机器学习在低资源语言情感分析中的潜力。


<details>
  <summary>Details</summary>
Motivation: 为了分析孟加拉国七月革命期间及之后社交媒体评论中的公众意见。

Method: 提出了一种混合Transformer模型，结合了BanglaBERT、mBERT、XLM-RoBERTa和XMB-BERT，并利用主成分分析（PCA）进行降维。研究还探索了十一种传统和先进的机器学习分类器来识别情感。

Result: 提出的混合XMB-BERT模型与投票分类器相结合，在分析社交媒体评论情感方面取得了83.7%的准确率，优于其他模型。

Conclusion: 该研究强调了机器学习技术在分析孟加拉语等低资源语言的社会情绪方面的潜力。

Abstract: The July Revolution in Bangladesh marked a significant student-led mass
uprising, uniting people across the nation to demand justice, accountability,
and systemic reform. Social media platforms played a pivotal role in amplifying
public sentiment and shaping discourse during this historic mass uprising. In
this study, we present a hybrid transformer-based sentiment analysis framework
to decode public opinion expressed in social media comments during and after
the revolution. We used a brand new dataset of 4,200 Bangla comments collected
from social media. The framework employs advanced transformer-based feature
extraction techniques, including BanglaBERT, mBERT, XLM-RoBERTa, and the
proposed hybrid XMB-BERT, to capture nuanced patterns in textual data.
Principle Component Analysis (PCA) were utilized for dimensionality reduction
to enhance computational efficiency. We explored eleven traditional and
advanced machine learning classifiers for identifying sentiments. The proposed
hybrid XMB-BERT with the voting classifier achieved an exceptional accuracy of
83.7% and outperform other model classifier combinations. This study
underscores the potential of machine learning techniques to analyze social
sentiment in low-resource languages like Bangla.

</details>


### [89] [Beyond Traditional Algorithms: Leveraging LLMs for Accurate Cross-Border Entity Identification](https://arxiv.org/abs/2507.11086)
*Andres Azqueta-Gavaldón,Joaquin Ramos Cosgrove*

Main category: cs.CL

TL;DR: LLM 在识别外国实体方面优于传统方法，准确率和 F1 分数更高，误报率更低。


<details>
  <summary>Details</summary>
Motivation: 在全球金融市场日益增长的跨境金融活动背景下，准确识别和分类外国实体对于西班牙金融系统的风险管理、合规性和反金融不当行为至关重要。传统的匹配算法在处理语言变异、特殊字符、过时名称和法律形式变更等方面存在挑战。

Method: 通过比较传统匹配算法（Jaccard、cosine、Levenshtein）和基于 LLM 的方法（Hugging Face LLMs、Microsoft Copilot、Alibaba Qwen 2.5）在处理 65 个葡萄牙公司案例数据集上的表现来评估。

Result: 传统方法准确率超过 92%，但误报率较高（20-40%）。基于 LLM 的接口方法表现更优，准确率超过 93%，F1 分数超过 96%，误报率较低（40-80%）。

Conclusion: LLMs 在识别和分类外国实体方面比传统方法更具优势，尤其是在处理语言变异和法律变更方面。

Abstract: The growing prevalence of cross-border financial activities in global markets
has underscored the necessity of accurately identifying and classifying foreign
entities. This practice is essential within the Spanish financial system for
ensuring robust risk management, regulatory adherence, and the prevention of
financial misconduct. This process involves a labor-intensive entity-matching
task, where entities need to be validated against available reference sources.
Challenges arise from linguistic variations, special characters, outdated
names, and changes in legal forms, complicating traditional matching algorithms
like Jaccard, cosine, and Levenshtein distances. These methods struggle with
contextual nuances and semantic relationships, leading to mismatches. To
address these limitations, we explore Large Language Models (LLMs) as a
flexible alternative. LLMs leverage extensive training to interpret context,
handle abbreviations, and adapt to legal transitions. We evaluate traditional
methods, Hugging Face-based LLMs, and interface-based LLMs (e.g., Microsoft
Copilot, Alibaba's Qwen 2.5) using a dataset of 65 Portuguese company cases.
Results show traditional methods achieve accuracies over 92% but suffer high
false positive rates (20-40%). Interface-based LLMs outperform, achieving
accuracies above 93%, F1 scores exceeding 96%, and lower false positives
(40-80%).

</details>


### [90] [The Devil behind the mask: An emergent safety vulnerability of Diffusion LLMs](https://arxiv.org/abs/2507.11097)
*Zichen Wen,Jiashu Qu,Dongrui Liu,Zhiyuan Liu,Ruixi Wu,Yicun Yang,Xiangqi Jin,Haoyun Xu,Xuyang Liu,Weijia Li,Chaochao Lu,Jing Shao,Conghui He,Linfeng Zhang*

Main category: cs.CL

TL;DR: DIJA 框架揭示了 dLLM 的新安全漏洞，并提供了有效的攻击方法，强调了重新思考 dLLM 安全对齐的必要性。


<details>
  <summary>Details</summary>
Motivation: 现有对齐机制无法保护 dLLM 免受特定类型的对抗性攻击，这是一种新的安全隐患。

Method: DIJA 构建对抗性交错掩码-文本提示，利用 dLLM 的文本生成机制（双向建模和并行解码）来利用其安全弱点。

Result: DIJA 在 Dream-Instruct 上实现了高达 100% 的基于关键字的 ASR，在 JailbreakBench 上超越了最强的先前基线 ReNeLLM，并且在 StrongREJECT 分数上提高了 37.7 个点，同时无需重写或隐藏越狱提示中的有害内容。

Conclusion: 现有的对齐机制未能保护 dLLM 免受上下文感知、掩码输入对抗性提示的影响，暴露了新的漏洞。DIJA 是第一个利用 dLLM 独特安全弱点的系统性研究和越狱攻击框架。

Abstract: Diffusion-based large language models (dLLMs) have recently emerged as a
powerful alternative to autoregressive LLMs, offering faster inference and
greater interactivity via parallel decoding and bidirectional modeling.
However, despite strong performance in code generation and text infilling, we
identify a fundamental safety concern: existing alignment mechanisms fail to
safeguard dLLMs against context-aware, masked-input adversarial prompts,
exposing novel vulnerabilities. To this end, we present DIJA, the first
systematic study and jailbreak attack framework that exploits unique safety
weaknesses of dLLMs. Specifically, our proposed DIJA constructs adversarial
interleaved mask-text prompts that exploit the text generation mechanisms of
dLLMs, i.e., bidirectional modeling and parallel decoding. Bidirectional
modeling drives the model to produce contextually consistent outputs for masked
spans, even when harmful, while parallel decoding limits model dynamic
filtering and rejection sampling of unsafe content. This causes standard
alignment mechanisms to fail, enabling harmful completions in alignment-tuned
dLLMs, even when harmful behaviors or unsafe instructions are directly exposed
in the prompt. Through comprehensive experiments, we demonstrate that DIJA
significantly outperforms existing jailbreak methods, exposing a previously
overlooked threat surface in dLLM architectures. Notably, our method achieves
up to 100% keyword-based ASR on Dream-Instruct, surpassing the strongest prior
baseline, ReNeLLM, by up to 78.5% in evaluator-based ASR on JailbreakBench and
by 37.7 points in StrongREJECT score, while requiring no rewriting or hiding of
harmful content in the jailbreak prompt. Our findings underscore the urgent
need for rethinking safety alignment in this emerging class of language models.
Code is available at https://github.com/ZichenWen1/DIJA.

</details>


### [91] [Multi-Trigger Poisoning Amplifies Backdoor Vulnerabilities in LLMs](https://arxiv.org/abs/2507.11112)
*Sanhanat Sivapiromrat,Caiqi Zhang,Marco Basaldella,Nigel Collier*

Main category: cs.CL

TL;DR: 本研究提出了一个研究LLM中毒的框架，发现了多触发器共存且鲁棒性强的漏洞，并提出了一种有效的后验恢复方法来防御此类攻击。


<details>
  <summary>Details</summary>
Motivation: 大多数现有作品都集中在攻击的有效性上，对触发器机制以及多个触发器在模型中的相互作用知之甚少。本研究旨在深入了解LLM中毒的触发器机制和多触发器交互。

Method: 提出了一种研究LLM中毒的框架，并通过实验证明了多个独立的后门触发器可以共存在单个模型中而不相互干扰。此外，还展示了具有高嵌入相似性的多个触发器即使在令牌被替换或被长令牌跨度分隔时也能实现鲁棒激活。最后，提出了一种后验恢复方法，该方法基于层级权重差异分析选择性地重新训练模型组件。

Result: 多个独立的后门触发器可以共存在单个模型中而不相互干扰。具有高嵌入相似性的多个触发器即使在令牌被替换或被长令牌跨度分隔时也能实现鲁棒激活。所提出的恢复方法能够有效去除触发器行为，并且参数更新最少。

Conclusion: 提出了一种后验恢复方法，该方法基于层级权重差异分析选择性地重新训练模型组件，可以有效去除触发器行为，并且参数更新最少，为多触发器中毒提供了实际且有效的防御。

Abstract: Recent studies have shown that Large Language Models (LLMs) are vulnerable to
data poisoning attacks, where malicious training examples embed hidden
behaviours triggered by specific input patterns. However, most existing works
assume a phrase and focus on the attack's effectiveness, offering limited
understanding of trigger mechanisms and how multiple triggers interact within
the model. In this paper, we present a framework for studying poisoning in
LLMs. We show that multiple distinct backdoor triggers can coexist within a
single model without interfering with each other, enabling adversaries to embed
several triggers concurrently. Using multiple triggers with high embedding
similarity, we demonstrate that poisoned triggers can achieve robust activation
even when tokens are substituted or separated by long token spans. Our findings
expose a broader and more persistent vulnerability surface in LLMs. To mitigate
this threat, we propose a post hoc recovery method that selectively retrains
specific model components based on a layer-wise weight difference analysis. Our
method effectively removes the trigger behaviour with minimal parameter
updates, presenting a practical and efficient defence against multi-trigger
poisoning.

</details>


### [92] [MSA at ImageCLEF 2025 Multimodal Reasoning: Multilingual Multimodal Reasoning With Ensemble Vision Language Models](https://arxiv.org/abs/2507.11114)
*Seif Ahmed,Mohamed T. Younes,Abdelrahman Moustafa,Abdelrahman Allam,Hamza Moustafa*

Main category: cs.CL

TL;DR: 通过集成Gemini模型并优化提示策略，该系统在多语言多模态推理任务中取得了优异的成绩。


<details>
  <summary>Details</summary>
Motivation: 为ImageCLEF 2025 EXAMS V挑战赛提供一个多语言多模态推理系统。

Method: 本文提出了一种基于Gemini模型的鲁棒的、多语言的、多模态的推理系统，并进行了广泛的消融研究，包括对不同大型语言模型（Gemini 2.5 Flash、Phi 4、Gemma 3、Mistral）进行训练和零样本评估，并重点研究了提示设计策略。

Result: 该系统在多语言赛道上总体准确率达到81.4%，在13个单语言赛道中的11个赛道中也名列前茅，在克罗地亚语和意大利语上的准确率分别达到95.07%和92.12%。

Conclusion: 轻量级的OCR-VLM集成，结合精确的提示策略和跨语言增强，在有利害关系的、多语言的教育环境中，可以优于更重的端到端模型。

Abstract: We present a robust ensemble-based system for multilingual multimodal
reasoning, designed for the ImageCLEF 2025 EXAMS V challenge. Our approach
integrates Gemini 2.5 Flash for visual description, Gemini 1.5 Pro for caption
refinement and consistency checks, and Gemini 2.5 Pro as a reasoner which
handles final answer selection, all coordinated through carefully engineered
few-shot and zero-shot prompts. We conducted an extensive ablation study,
training several large language models (Gemini 2.5 Flash, Phi 4, Gemma 3,
Mistral) on an English dataset and its multilingual augmented version.
Additionally, we evaluated Gemini 2.5 Flash in a zero-shot setting for
comparison and found it to substantially outperform the trained models. Prompt
design also proved critical: enforcing concise, language-normalized formats and
prohibiting explanatory text boosted model accuracy on the English validation
set from 55.9% to 61.7%. On the official leaderboard, our system (Team MSA)
achieved first place overall in the multilingual track with 81.4% accuracy, and
led 11 out of 13 individual language tracks, with top results such as 95.07%
for Croatian and 92.12% for Italian. These findings highlight that lightweight
OCR-VLM ensembles, when paired with precise prompt strategies and cross-lingual
augmentation, can outperform heavier end-to-end models in high-stakes,
multilingual educational settings.

</details>


### [93] [What Should LLMs Forget? Quantifying Personal Data in LLMs for Right-to-Be-Forgotten Requests](https://arxiv.org/abs/2507.11128)
*Dimitri Staufer*

Main category: cs.CL

TL;DR: LLMs可能泄露个人信息，但难以识别具体信息。本研究提出了WikiMem数据集和一种新指标，能在个体层面识别LLM中记忆的个人信息，并关联到模型规模和网络存在，为遗忘个人数据提供基础。


<details>
  <summary>Details</summary>
Motivation: 旨在解决大型语言模型（LLMs）可能记住并泄露个人信息的问题，特别是在遵守欧盟GDPR和遗忘权（RTBF）方面。现有的机器学习遗忘方法假设需要遗忘的数据是已知的，但未能解决如何识别模型中存储的个体事实关联的问题。隐私审计技术通常在总体层面操作或针对少量标识符，限制了其在个体层面数据查询中的应用。

Method: 提出了一种名为WikiMem的数据集（包含超过5000个自然语言金丝雀，涵盖Wikidata中的243个人类相关属性）和一种模型无关的指标，用于量化LLM中人类事实的关联。该方法通过对释义提示的校准负对数似然来对真实值与反事实进行排名。

Result: 在200名个体和15个LLM（参数量从410M到70B）上的评估表明，记忆情况与主体的网络存在和模型规模相关。

Conclusion: 该研究为在个体层面识别LLM中记忆的个人数据奠定了基础，能够为机器学习和遗忘权请求动态构建遗忘集。

Abstract: Large Language Models (LLMs) can memorize and reveal personal information,
raising concerns regarding compliance with the EU's GDPR, particularly the
Right to Be Forgotten (RTBF). Existing machine unlearning methods assume the
data to forget is already known but do not address how to identify which
individual-fact associations are stored in the model. Privacy auditing
techniques typically operate at the population level or target a small set of
identifiers, limiting applicability to individual-level data inquiries. We
introduce WikiMem, a dataset of over 5,000 natural language canaries covering
243 human-related properties from Wikidata, and a model-agnostic metric to
quantify human-fact associations in LLMs. Our approach ranks ground-truth
values against counterfactuals using calibrated negative log-likelihood across
paraphrased prompts. We evaluate 200 individuals across 15 LLMs (410M-70B
parameters), showing that memorization correlates with subject web presence and
model scale. We provide a foundation for identifying memorized personal data in
LLMs at the individual level, enabling the dynamic construction of forget sets
for machine unlearning and RTBF requests.

</details>


### [94] [Temperature and Persona Shape LLM Agent Consensus With Minimal Accuracy Gains in Qualitative Coding](https://arxiv.org/abs/2507.11198)
*Conrad Borchers,Bahar Shahrokhian,Francesco Balzan,Elham Tajik,Sreecharan Sankaranarayanan,Sebastian Simon*

Main category: cs.CL

TL;DR: LLM在定性研究中很有用，但多智能体系统（MAS）并不总是比单智能体系统更好。智能体角色和温度会影响共识，但并不总是提高准确性。研究发现，只有一种模型在特定条件下表现更好，但MAS可能有助于改进代码本。


<details>
  <summary>Details</summary>
Motivation: 在定性研究领域，虽然多智能体系统（MAS）可以模拟人类编码工作流程，但它们相对于单智能体编码的优势仍然知之甚少。

Method: 通过实验研究了智能体角色和温度如何影响基于8个代码的代码本的对话片段的共识建立和编码准确性。研究使用了六个开源LLM（具有3到320亿参数）和18种实验配置，分析了超过77000个编码决策，并与在线数学辅导课程的人工注释的成绩单的金标准数据集进行了比较。

Result: 温度显著影响了所有六个LLM达成共识的程度和时间。与统一角色相比，具有多个角色（包括中性、自信或共情）的MAS在四个LLM中显著延迟了共识。在其中三个LLM中，较高的温度显著削弱了多个角色对共识的影响。然而，温度和角色配对均未能在编码准确性方面带来稳健的改进。

Conclusion: 单智能体在大多数情况下匹配或优于多智能体共识，只有一种模型（OpenHermesV2:7B）和代码类别在温度较低（0.5或更低）且至少包含一个具有说服性角色的智能体时，表现出高于机会的收益。多智能体系统（MAS）在帮助缩小可能改进代码本和人类-AI编码的模糊代码应用方面可能仍然有用。研究结果挑战了多样化MAS角色能够带来更好结果的观点。

Abstract: Large Language Models (LLMs) enable new possibilities for qualitative
research at scale, including coding and data annotation. While multi-agent
systems (MAS) can emulate human coding workflows, their benefits over
single-agent coding remain poorly understood. We conducted an experimental
study of how agent persona and temperature shape consensus-building and coding
accuracy of dialog segments based on a codebook with 8 codes. Our open-source
MAS mirrors deductive human coding through structured agent discussion and
consensus arbitration. Using six open-source LLMs (with 3 to 32 billion
parameters) and 18 experimental configurations, we analyze over 77,000 coding
decisions against a gold-standard dataset of human-annotated transcripts from
online math tutoring sessions. Temperature significantly impacted whether and
when consensus was reached across all six LLMs. MAS with multiple personas
(including neutral, assertive, or empathetic), significantly delayed consensus
in four out of six LLMs compared to uniform personas. In three of those LLMs,
higher temperatures significantly diminished the effects of multiple personas
on consensus. However, neither temperature nor persona pairing lead to robust
improvements in coding accuracy. Single agents matched or outperformed MAS
consensus in most conditions. Only one model (OpenHermesV2:7B) and code
category showed above-chance gains from MAS deliberation when temperature was
0.5 or lower and especially when the agents included at least one assertive
persona. Qualitative analysis of MAS collaboration for these configurations
suggests that MAS may nonetheless aid in narrowing ambiguous code applications
that could improve codebooks and human-AI coding. We contribute new insight
into the limits of LLM-based qualitative methods, challenging the notion that
diverse MAS personas lead to better outcomes. We open-source our MAS and
experimentation code.

</details>


### [95] [EsBBQ and CaBBQ: The Spanish and Catalan Bias Benchmarks for Question Answering](https://arxiv.org/abs/2507.11216)
*Valle Ruiz-Fernández,Mario Mina,Júlia Falcão,Luis Vasquez-Reina,Anna Sallés,Aitor Gonzalez-Agirre,Olatz Perez-de-Viñaspre*

Main category: cs.CL

TL;DR: 本研究引入了西班牙语和加泰罗尼亚语的偏见评估数据集（EsBBQ和CaBBQ），以解决缺乏非英语偏见评估资源的问，评估了多种LLM，发现模型在模糊场景下表现不佳，并且准确率与偏见相关。


<details>
  <summary>Details</summary>
Motivation: 为了解决英语以外语言和社会背景（如西班牙）缺乏社会偏见评估资源的不足。

Method: 通过引入西班牙语和加泰罗尼亚语偏见问答基准（EsBBQ和CaBBQ），基于原始BBQ数据集，设计了包含10个类别的多项选择问答任务，以评估LLM在西班牙语和加泰罗尼亚语中的社会偏见。

Result: 报告了不同LLM（考虑模型家族、大小和变体）的评估结果，表明模型在模糊场景下容易出错，且高准确率与更多的社会偏见相关。

Conclusion: LLM在西班牙语和加泰罗尼亚语的特定社会背景下，在模糊场景下容易出错，并且高准确率往往与更大的社会偏见相关联。

Abstract: Previous literature has largely shown that Large Language Models (LLMs)
perpetuate social biases learnt from their pre-training data. Given the notable
lack of resources for social bias evaluation in languages other than English,
and for social contexts outside of the United States, this paper introduces the
Spanish and the Catalan Bias Benchmarks for Question Answering (EsBBQ and
CaBBQ). Based on the original BBQ, these two parallel datasets are designed to
assess social bias across 10 categories using a multiple-choice QA setting, now
adapted to the Spanish and Catalan languages and to the social context of
Spain. We report evaluation results on different LLMs, factoring in model
family, size and variant. Our results show that models tend to fail to choose
the correct answer in ambiguous scenarios, and that high QA accuracy often
correlates with greater reliance on social biases.

</details>


### [96] [An Agentic Flow for Finite State Machine Extraction using Prompt Chaining](https://arxiv.org/abs/2507.11222)
*Fares Wael,Youssef Maklad,Ali Hamdi,Wael Elsersy*

Main category: cs.CL

TL;DR: FlowFSM利用LLMs和代理框架，通过提示链和思维链推理，从RFC文档中提取准确的FSM，解决了现有技术的局限性。


<details>
  <summary>Details</summary>
Motivation: 现有FSM提取技术在可扩展性、覆盖范围和自然语言规范的模糊性方面存在局限性。

Method: 提出了一种名为FlowFSM的新型代理框架，该框架结合了大型语言模型（LLMs）、提示链和思维链推理，用于从原始RFC文档中提取精确的有限状态机（FSM）。FlowFSM通过链接代理输出来系统地处理协议规范、识别状态转换和构建结构化规则手册。

Result: FlowFSM在FTP和RTSP协议的实验评估中，实现了高提取精度，并最大限度地减少了幻觉转换，展示了其在协议分析和网络安全中的应用潜力。

Conclusion: FlowFSM在FTP和RTSP协议的实验评估中，实现了高提取精度，并最大限度地减少了幻觉转换，展示了其在协议分析和网络安全中的应用潜力。

Abstract: Finite-State Machines (FSMs) are critical for modeling the operational logic
of network protocols, enabling verification, analysis, and vulnerability
discovery. However, existing FSM extraction techniques face limitations such as
scalability, incomplete coverage, and ambiguity in natural language
specifications. In this paper, we propose FlowFSM, a novel agentic framework
that leverages Large Language Models (LLMs) combined with prompt chaining and
chain-of-thought reasoning to extract accurate FSMs from raw RFC documents.
FlowFSM systematically processes protocol specifications, identifies state
transitions, and constructs structured rule-books by chaining agent outputs.
Experimental evaluation across FTP and RTSP protocols demonstrates that FlowFSM
achieves high extraction precision while minimizing hallucinated transitions,
showing promising results. Our findings highlight the potential of agent-based
LLM systems in the advancement of protocol analysis and FSM inference for
cybersecurity and reverse engineering applications.

</details>


### [97] [Sparse Autoencoders Can Capture Language-Specific Concepts Across Diverse Languages](https://arxiv.org/abs/2507.11230)
*Lyzander Marciano Andrylie,Inaya Rahmanisa,Mahardika Krisna Ihsani,Alfan Farizki Wicaksono,Haryo Akbarianto Wibowo,Alham Fikri Aji*

Main category: cs.CL

TL;DR: 通过SAE-LAPE方法识别了Transformer模型中的语言特异性特征，这些特征可用于语言识别，性能优越且可解释性强。


<details>
  <summary>Details</summary>
Motivation: 现有研究难以从多义的单个神经元中分离出特定语言的单元，而稀疏自编码器（SAE）能够学习跨语言的单义特征，但其语言特异性特征仍有待探索。

Method: 提出了一种基于特征激活概率的SAE-LAPE方法，用于识别Transformer模型前馈网络中的语言特异性特征。

Result: 发现了大量可解释的、特定语言的激活特征，这些特征主要出现在模型的中间到最后几层，并且可以用于语言识别，性能与fastText相当且更具可解释性。

Conclusion: 研究表明，在Transformer模型中，存在大量可解释的、特定语言的激活特征，这些特征主要出现在模型的中间到最后几层，它们影响着模型的跨语言表现和语言输出，并且可以用于语言识别任务，其性能可与fastText媲美，同时具有更好的可解释性。

Abstract: Understanding the multilingual mechanisms of large language models (LLMs)
provides insight into how they process different languages, yet this remains
challenging. Existing studies often focus on individual neurons, but their
polysemantic nature makes it difficult to isolate language-specific units from
cross-lingual representations. To address this, we explore sparse autoencoders
(SAEs) for their ability to learn monosemantic features that represent concrete
and abstract concepts across languages in LLMs. While some of these features
are language-independent, the presence of language-specific features remains
underexplored. In this work, we introduce SAE-LAPE, a method based on feature
activation probability, to identify language-specific features within the
feed-forward network. We find that many such features predominantly appear in
the middle to final layers of the model and are interpretable. These features
influence the model's multilingual performance and language output and can be
used for language identification with performance comparable to fastText along
with more interpretability. Our code is available at
https://github.com/LyzanderAndrylie/language-specific-features .

</details>


### [98] [KV-Latent: Dimensional-level KV Cache Reduction with Frequency-aware Rotary Positional Embedding](https://arxiv.org/abs/2507.11273)
*Luohe Shi,Zuchao Li,Lefei Zhang,Guoming Liu,Baoyuan Qi,Hai Zhao*

Main category: cs.CL

TL;DR: KV-Latent通过降维KV Cache来优化LLM推理效率。


<details>
  <summary>Details</summary>
Motivation: Transformer解码器虽然在生成式AI方面表现优越，但KV Cache在推理过程中不断增大，成为内存和带宽的瓶颈。

Method: 提出KV-Latent方法，通过降采样KV向量维度到潜在空间来减小KV Cache的占用和提高推理速度，并对Rotary Positional Embedding进行修改以提高在低维向量上的稳定性。

Result: KV-Latent显著减小了KV Cache的占用并提高了推理速度，同时对模型性能影响很小，并且对有无Grouped Query Attention的模型均适用。

Conclusion: KV-Latent通过降维KV Cache、修改Rotary Positional Embedding的频率采样机制来提高LLM推理效率，实验证明该方法可行且效果良好，为构建更高效的语言模型系统提供了新的可能性。

Abstract: Large language models (LLMs) based on Transformer Decoders have become the
preferred choice for conversational generative AI. Despite the overall
superiority of the Decoder architecture, the gradually increasing Key-Value
(KV) cache during inference has emerged as a primary efficiency bottleneck,
both in aspects of memory consumption and data transfer bandwidth limitations.
To address these challenges, we propose a paradigm called KV-Latent. By
down-sampling the Key-Value vector dimensions into a latent space, we can
significantly reduce the KV Cache footprint and improve inference speed, only
with a small amount of extra training, less than 1\% of pre-training takes.
Besides, we enhanced the stability of Rotary Positional Embedding applied on
lower-dimensional vectors by modifying its frequency sampling mechanism,
avoiding noise introduced by higher frequencies while retaining position
attenuation. Our experiments, including both models with Grouped Query
Attention and those without, have yielded satisfactory results. Finally, we
conducted comparative experiments to study the impact of separately reducing
Key and Value components on model's performance. Our approach allows for the
construction of more efficient language model systems, and opens the new
possibility on KV Cache saving and efficient LLMs. Our code is available at
https://github.com/ShiLuohe/KV-Latent.

</details>


### [99] [FMC: Formalization of Natural Language Mathematical Competition Problems](https://arxiv.org/abs/2507.11275)
*Jiaxuan Xie,Chengwu Liu,Ye Yuan,Siqi Li,Zhiping Xiao,Ming Zhang*

Main category: cs.CL

TL;DR: 本研究提出了一种新的自动形式化方法，利用大型语言模型和错误反馈，无需训练即可将自然语言数学问题转换为Lean形式。研究人员构建了一个高质量的奥数级别数据集，并评估了不同LLM的表现，证明了该方法的有效性以及数据集作为自动定理证明器基准的潜力。


<details>
  <summary>Details</summary>
Motivation: 为了推进形式化数学推理，需要高效准确的自形式化方法，以利用大规模自然语言数学问题数据集构建形式语言数据集。

Method: 研究提出一个基于大型语言模型（LLM）和错误反馈的自形式化流程，实现全自动、无需训练的形式化。利用此流程，研究人员构建了一个包含奥林匹克级别数学问题的自然语言与Lean形式化表述对齐的数据集。此外，研究还评估了不同LLM的形式化和推理能力，并通过实验证明少样本学习、错误反馈和增加采样数能改进自形式化过程。

Result: 研究构建了一个包含3,922个奥数级别数学自然语言问题和9,787个Lean形式化表述的数据集，其中64.46%的条目被评估为具有平均以上质量。实验表明，少样本学习、错误反馈和增加采样数可以提升自形式化效果。该数据集对三个自动定理证明器的测试结果表明了其挑战性和作为基准的价值。

Conclusion: 该研究提出了一个基于大型语言模型和错误反馈的全自动、无需训练的自形式化流程，并构建了一个包含3,922个奥数级别数学自然语言问题和9,787个Lean形式化表述的数据集。该数据集64.46%的条目被评估为具有平均以上质量，可作为自动定理证明器的基准。研究还表明，少样本学习、错误反馈和增加采样数量能提升自形式化效果，并验证了该数据集在评估自动定理证明器上的挑战性和价值。

Abstract: Efficient and accurate autoformalization methods, which leverage large-scale
datasets of extensive natural language mathematical problems to construct
formal language datasets, are key to advancing formal mathematical reasoning.
In this paper, we propose an autoformalization pipeline based on large language
models with error feedback, achieving a fully automatic and training-free
formalization approach. Using this pipeline, we curate an Olympiad-level
dataset aligning natural language problems with Lean formalizations. The
dataset comprises $3,922$ mathematical problems in natural language and $9,787$
in Lean, of which $64.46\%$ were assessed as at least above-average quality,
making it suitable as a benchmark for automated theorem provers. Additionally,
we investigate the formalization and reasoning capabilities of various LLMs and
empirically demonstrate that few-shot learning, error feedback, and increasing
sampling numbers enhance the autoformalization process. Experiments of three
automated theorem provers on the \dataset\ dataset also highlight its
challenging nature and its value as a benchmark for formal reasoning tasks.

</details>


### [100] [Fine-Grained Chinese Hate Speech Understanding: Span-Level Resources, Coded Term Lexicon, and Enhanced Detection Frameworks](https://arxiv.org/abs/2507.11292)
*Zewen Bai,Liang Yang,Shengdi Yin,Yuanyuan Sun,Hongfei Lin*

Main category: cs.CL

TL;DR: 本研究解决了中文仇恨言论检测中的可解释性问题，通过发布新数据集、研究隐晦仇恨词汇和提出新方法，提升了检测性能。


<details>
  <summary>Details</summary>
Motivation: 本研究旨在解决中文仇恨言论检测领域存在的模型可解释性方面的挑战，特别是针对中文仇恨言论检测起步较晚，以及缺乏句柄级细粒度标注数据集和对隐晦仇恨言论识别与解释的研究不足的问题。

Method: 本研究提出的方法整合了一个带注释的词汇表到模型中，以提高仇恨言论检测的性能。

Result: 本研究引入了首个句柄级中文仇恨言论数据集STATE ToxiCN，并对现有模型进行了评估；进行了首个全面的中文隐晦仇恨词汇研究，评估了大型语言模型在解释仇恨语义方面的能力；所提出的整合带注释词汇表的方法显著提升了仇恨言论检测性能。

Conclusion: 本研究通过引入首个中文句柄级中文仇恨言论数据集STATE ToxiCN，并进行全面的中文隐晦仇恨词汇研究，以及提出将词汇表整合到模型中的方法，显著提升了仇恨言论检测性能，为中文仇恨言论检测可解释性研究提供了宝贵的资源和见解。

Abstract: The proliferation of hate speech has inflicted significant societal harm,
with its intensity and directionality closely tied to specific targets and
arguments. In recent years, numerous machine learning-based methods have been
developed to detect hateful comments on online platforms automatically.
However, research on Chinese hate speech detection lags behind, and
interpretability studies face two major challenges: first, the scarcity of
span-level fine-grained annotated datasets limits models' deep semantic
understanding of hate speech; second, insufficient research on identifying and
interpreting coded hate speech restricts model explainability in complex
real-world scenarios. To address these, we make the following contributions:
(1) We introduce the Span-level Target-Aware Toxicity Extraction dataset (STATE
ToxiCN), the first span-level Chinese hate speech dataset, and evaluate the
hate semantic understanding of existing models using it. (2) We conduct the
first comprehensive study on Chinese coded hate terms, LLMs' ability to
interpret hate semantics. (3) We propose a method to integrate an annotated
lexicon into models, significantly enhancing hate speech detection performance.
Our work provides valuable resources and insights to advance the
interpretability of Chinese hate speech detection research.

</details>


### [101] [Dr.Copilot: A Multi-Agent Prompt Optimized Assistant for Improving Patient-Doctor Communication in Romanian](https://arxiv.org/abs/2507.11299)
*Andrei Niculae,Adrian Cosma,Cosmin Dumitrache,Emilian Rǎdoi*

Main category: cs.CL

TL;DR: Dr.Copilot 是一个支持罗马尼亚语医生的多主体 LLM 系统，通过优化回复的表达质量来提升沟通效果，而非关注临床准确性，已在实际应用中取得成效。


<details>
  <summary>Details</summary>
Motivation: 为了解决文本远程医疗中，医疗建议的质量常常被沟通方式而非临床准确性所影响的问题，本文提出 Dr.Copilot 系统以支持罗马尼亚语医生，提升其书面回复的表达质量。

Method: Dr.Copilot 系统利用三个经过 DSPy 优化的语言模型主体，专注于评估和增强医生回复的表达质量，而非临床准确性，它提供了 17 个可解释的维度反馈，并针对罗马尼亚语低资源环境进行了优化和部署。

Result: 该系统在用户评价和回复质量方面均显示出可衡量的改进，并已成功应用于真实世界的罗马尼亚医疗环境。

Conclusion: Dr.Copilot 作为一个多主体大型语言模型系统，在罗马尼亚语的医疗环境中得到了首次实际应用，并通过了 41 名医生的实际部署和评估，证明了其在提升医生书面回复的表达质量方面的有效性，并已在用户评价和回复质量方面取得了可衡量的改进。

Abstract: Text-based telemedicine has become increasingly common, yet the quality of
medical advice in doctor-patient interactions is often judged more on how
advice is communicated rather than its clinical accuracy. To address this, we
introduce Dr.Copilot , a multi-agent large language model (LLM) system that
supports Romanian-speaking doctors by evaluating and enhancing the presentation
quality of their written responses. Rather than assessing medical correctness,
Dr.Copilot provides feedback along 17 interpretable axes. The system comprises
of three LLM agents with prompts automatically optimized via DSPy. Designed
with low-resource Romanian data and deployed using open-weight models, it
delivers real-time specific feedback to doctors within a telemedicine platform.
Empirical evaluations and live deployment with 41 doctors show measurable
improvements in user reviews and response quality, marking one of the first
real-world deployments of LLMs in Romanian medical settings.

</details>


### [102] [Internal Value Alignment in Large Language Models through Controlled Value Vector Activation](https://arxiv.org/abs/2507.11316)
*Haoran Jin,Meng Li,Xiting Wang,Zhihao Xu,Minlie Huang,Yantao Jia,Defu Lian*

Main category: cs.CL

TL;DR: ConVA aligns LLMs with human values by modifying their internal representations, achieving high success rates without performance loss and performance loss.


<details>
  <summary>Details</summary>
Motivation: Aligning Large Language Models (LLMs) with human values is important for providing clarity, transparency, and adaptability to changing circumstances.

Method: The paper introduces a Controlled Value Vector Activation (ConVA) method. This method involves interpreting how values are encoded in LLMs' latent representations and modifying relevant activations. It utilizes a context-controlled value vector identification method for accurate and unbiased interpretation, and a gated value vector activation method for effective and minimal value control.

Result: ConVA achieves the highest control success rate across 10 basic values without negatively impacting LLM performance and fluency. It also ensures target values are maintained even when faced with opposing or malicious input prompts.

Conclusion: Aligning LLMs with human values is crucial for clarity, transparency, and adaptability. The ConVA method achieves this by interpreting and modifying internal value encodings in LLM latent representations. Experiments demonstrate ConVA's high control success rate across 10 basic values without compromising model performance or fluency, even against adversarial prompts.

Abstract: Aligning Large Language Models (LLMs) with human values has attracted
increasing attention since it provides clarity, transparency, and the ability
to adapt to evolving scenarios. In this paper, we introduce a Controlled Value
Vector Activation (ConVA) method that directly aligns the internal values of
LLMs by interpreting how a value is encoded in their latent representations and
modifies relevant activations to ensure consistent values in LLMs. To ensure an
accurate and unbiased interpretation, we propose a context-controlled value
vector identification method. To consistently control values without
sacrificing model performance, we introduce a gated value vector activation
method for effective and minimum degree of value control. Experiments show that
our method achieves the highest control success rate across 10 basic values
without hurting LLM performance and fluency, and ensures target values even
with opposite and potentially malicious input prompts. Source code and data are
available at~ https://github.com/hr-jin/ConVA.

</details>


### [103] [Automated Novelty Evaluation of Academic Paper: A Collaborative Approach Integrating Human and Large Language Model Knowledge](https://arxiv.org/abs/2507.11330)
*Wenqing Wu,Chengzhi Zhang,Yi Zhao*

Main category: cs.CL

TL;DR: 通过结合人类专家和大型语言模型（LLM）的知识，提出了一种新颖的学术论文方法新颖性评估方法，并取得了优于现有方法的性能。


<details>
  <summary>Details</summary>
Motivation: 传统的新颖性评估方法（专家判断和独特参考文献组合）存在局限性，无法有效衡量新颖性。大型语言模型（LLM）拥有丰富的知识，而人类专家拥有LLM所不具备的判断能力。因此，研究旨在结合两者的优势来克服新颖性评估的局限性。

Method: 利用人类知识和LLM辅助预训练语言模型（PLMs）预测论文方法的新颖性。具体来说，提取同行评审报告中与新颖性相关的句子，并利用LLM总结论文的方法论部分，然后用这些信息对PLMs进行微调。此外，还设计了一个带有新颖的稀疏注意力（Sparse-Attention）的文本引导融合模块来整合人类和LLM的知识。

Result: 所提出的方法在与大量基线方法的比较中取得了优越的性能，实验证明了其有效性。

Conclusion: 该研究提出了一种结合人类知识和大型语言模型（LLM）来评估学术论文方法新颖性的新方法，并通过实验证明了其优越性。

Abstract: Novelty is a crucial criterion in the peer review process for evaluating
academic papers. Traditionally, it's judged by experts or measure by unique
reference combinations. Both methods have limitations: experts have limited
knowledge, and the effectiveness of the combination method is uncertain.
Moreover, it's unclear if unique citations truly measure novelty. The large
language model (LLM) possesses a wealth of knowledge, while human experts
possess judgment abilities that the LLM does not possess. Therefore, our
research integrates the knowledge and abilities of LLM and human experts to
address the limitations of novelty assessment. The most common novelty in
academic papers is the introduction of new methods. In this paper, we propose
leveraging human knowledge and LLM to assist pretrained language models (PLMs,
e.g. BERT etc.) in predicting the method novelty of papers. Specifically, we
extract sentences related to the novelty of the academic paper from peer review
reports and use LLM to summarize the methodology section of the academic paper,
which are then used to fine-tune PLMs. In addition, we have designed a
text-guided fusion module with novel Sparse-Attention to better integrate human
and LLM knowledge. We compared the method we proposed with a large number of
baselines. Extensive experiments demonstrate that our method achieves superior
performance.

</details>


### [104] [What is the Best Process Model Representation? A Comparative Analysis for Process Modeling with Large Language Models](https://arxiv.org/abs/2507.11356)
*Alexis Brissard,Frédéric Cuppens,Amal Zouaq*

Main category: cs.CL

TL;DR: LLM 的 PMo 任务中，Mermaid 在各项标准中表现最佳，BPMN text 在过程元素相似性方面表现最佳。


<details>
  <summary>Details</summary>
Motivation: LLM 越来越多地应用于 PM 任务，如 PMG。为支持这些任务，研究人员引入了多种 PMR，但它们在结构、复杂性和可用性方面差异很大，且从未经过系统比较。此外，最近的 PMG 方法依赖于不同的评估策略和生成技术，使得比较困难。

Method: 本研究首次对 LLM 的 PMo 任务中的多个 PMR 进行了实证评估。我们引入了 PMo 数据集，其中包含 55 个过程描述，并配有九种不同 PMR 的模型。我们沿着两个维度评估 PMR：LLM 的 PMo 的适用性以及 PMG 的性能。

Result: Mermaid 在六项 PMo 标准中得分最高，而 BPMN text 在过程元素相似性方面取得了最佳 PMG 结果。

Conclusion: Mermaid 在六项 PMo 标准中得分最高，而 BPMN text 在过程元素相似性方面取得了最佳 PMG 结果。

Abstract: Large Language Models (LLMs) are increasingly applied for Process Modeling
(PMo) tasks such as Process Model Generation (PMG). To support these tasks,
researchers have introduced a variety of Process Model Representations (PMRs)
that serve as model abstractions or generation targets. However, these PMRs
differ widely in structure, complexity, and usability, and have never been
systematically compared. Moreover, recent PMG approaches rely on distinct
evaluation strategies and generation techniques, making comparison difficult.
This paper presents the first empirical study that evaluates multiple PMRs in
the context of PMo with LLMs. We introduce the PMo Dataset, a new dataset
containing 55 process descriptions paired with models in nine different PMRs.
We evaluate PMRs along two dimensions: suitability for LLM-based PMo and
performance on PMG. \textit{Mermaid} achieves the highest overall score across
six PMo criteria, whereas \textit{BPMN text} delivers the best PMG results in
terms of process element similarity.

</details>


### [105] [Addressing Data Imbalance in Transformer-Based Multi-Label Emotion Detection with Weighted Loss](https://arxiv.org/abs/2507.11384)
*Xia Cui*

Main category: cs.CL

TL;DR: 通过加权损失函数优化Transformer模型在多标签情感检测中的表现，特别是在处理数据不平衡方面，但对少数类别的改进空间仍需探索。


<details>
  <summary>Details</summary>
Motivation: 为了解决多标签情感检测任务中的数据不平衡问题，并探索一种无需传统重采样方法的计算负担即可提升模型性能的途径。

Method: 应用简单的加权损失函数到基于Transformer的模型（BERT、RoBERTa、BART）中，通过动态调整类别权重来处理数据不平衡问题，以改进少数情感类别的性能。

Result: 加权损失函数提升了模型在高频情感类别上的性能，但对少数类别的影响有限。

Conclusion: 加权损失函数在处理高频类别时有效，但在少数类别上的效果有限，凸显了该方法在不平衡多标签情感检测中的优势与挑战。

Abstract: This paper explores the application of a simple weighted loss function to
Transformer-based models for multi-label emotion detection in SemEval-2025
Shared Task 11. Our approach addresses data imbalance by dynamically adjusting
class weights, thereby enhancing performance on minority emotion classes
without the computational burden of traditional resampling methods. We evaluate
BERT, RoBERTa, and BART on the BRIGHTER dataset, using evaluation metrics such
as Micro F1, Macro F1, ROC-AUC, Accuracy, and Jaccard similarity coefficients.
The results demonstrate that the weighted loss function improves performance on
high-frequency emotion classes but shows limited impact on minority classes.
These findings underscore both the effectiveness and the challenges of applying
this approach to imbalanced multi-label emotion detection.

</details>


### [106] [DCR: Quantifying Data Contamination in LLMs Evaluation](https://arxiv.org/abs/2507.11405)
*Cheng Xu,Nan Yan,Shuhao Guan,Changhong Jin,Yuke Mei,Yibing Guo,M-Tahar Kechadi*

Main category: cs.CL

TL;DR: DCR框架是一个轻量级、可解释的管道，用于检测和量化大型语言模型（LLM）的基准数据污染（BDC）。它通过计算统一的DCR因子来调整准确性，以反映感知污染的性能。DCR框架在9个LLM和3个任务上进行了验证，结果显示其能够可靠地诊断污染严重程度，并将准确性调整到与未污染基线相比平均误差4%的范围内。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLM）的快速发展引起了人们对基准数据污染（BDC）的担忧，即模型无意中记住了评估数据，从而提高了性能指标并破坏了真正的泛化评估。

Method: 该论文介绍了数据污染风险（DCR）框架，这是一个轻量级、可解释的管道，用于在四个细粒度级别上检测和量化BDC：语义、信息、数据和标签。通过模糊推理系统合成污染分数，DCR产生统一的DCR因子，该因子会调整原始准确性以反映感知污染的性能。

Result: DCR框架在9个LLM（0.5B-72B）的文本分类、虚假新闻检测和算术推理任务上进行了验证。

Conclusion: DCR框架能够可靠地诊断污染严重程度，并且通过DCR因子调整后的准确性在三个基准的平均误差范围内为4%，与未污染的基线相比。

Abstract: The rapid advancement of large language models (LLMs) has heightened concerns
about benchmark data contamination (BDC), where models inadvertently memorize
evaluation data, inflating performance metrics and undermining genuine
generalization assessment. This paper introduces the Data Contamination Risk
(DCR) framework, a lightweight, interpretable pipeline designed to detect and
quantify BDC across four granular levels: semantic, informational, data, and
label. By synthesizing contamination scores via a fuzzy inference system, DCR
produces a unified DCR Factor that adjusts raw accuracy to reflect
contamination-aware performance. Validated on 9 LLMs (0.5B-72B) across
sentiment analysis, fake news detection, and arithmetic reasoning tasks, the
DCR framework reliably diagnoses contamination severity and with accuracy
adjusted using the DCR Factor to within 4% average error across the three
benchmarks compared to the uncontaminated baseline. Emphasizing computational
efficiency and transparency, DCR provides a practical tool for integrating
contamination assessment into routine evaluations, fostering fairer comparisons
and enhancing the credibility of LLM benchmarking practices.

</details>


### [107] [EXAONE 4.0: Unified Large Language Models Integrating Non-reasoning and Reasoning Modes](https://arxiv.org/abs/2507.11407)
*LG AI Research,:,Kyunghoon Bae,Eunbi Choi,Kibong Choi,Stanley Jungkyu Choi,Yemuk Choi,Kyubeen Han,Seokhee Hong,Junwon Hwang,Taewan Hwang,Joonwon Jang,Hyojin Jeon,Kijeong Jeon,Gerrard Jeongwon Jo,Hyunjik Jo,Jiyeon Jung,Euisoon Kim,Hyosang Kim,Jihoon Kim,Joonkee Kim,Seonghwan Kim,Soyeon Kim,Sunkyoung Kim,Yireun Kim,Yongil Kim,Youchul Kim,Edward Hwayoung Lee,Gwangho Lee,Haeju Lee,Honglak Lee,Jinsik Lee,Kyungmin Lee,Sangha Park,Young Min Paik,Yongmin Park,Youngyong Park,Sanghyun Seo,Sihoon Yang,Heuiyeen Yeen,Sihyuk Yi,Hyeongu Yun*

Main category: cs.CL

TL;DR: EXAONE 4.0 是一个结合了易用性和推理能力的大型语言模型，支持多语言和智能体工具使用，并在性能上优于同类模型。


<details>
  <summary>Details</summary>
Motivation: 为了应对智能体 AI 时代的需求，EXAONE 4.0 旨在提供卓越的可用性和高级推理能力，并支持多语言和设备应用。

Method: EXAONE 4.0 是一个大型语言模型系列，包含 32B 和 1.2B 两种尺寸。32B 模型针对高性能进行了优化，而 1.2B 模型则专为设备应用设计。该模型在开放权重模型中表现优越，并能与前沿模型竞争。

Result: EXAONE 4.0 在同类开放权重模型中表现出众，并且在与前沿模型相比时仍具有竞争力。该模型系列包含两种尺寸，分别适用于不同场景。

Conclusion: EXAONE 4.0 成功整合了非推理模式和推理模式，结合了 EXAONE 3.5 的易用性和 EXAONE Deep 的高级推理能力，为智能体 AI 时代奠定了基础。它增加了智能体工具使用功能，并将多语言能力扩展到西班牙语。

Abstract: This technical report introduces EXAONE 4.0, which integrates a Non-reasoning
mode and a Reasoning mode to achieve both the excellent usability of EXAONE 3.5
and the advanced reasoning abilities of EXAONE Deep. To pave the way for the
agentic AI era, EXAONE 4.0 incorporates essential features such as agentic tool
use, and its multilingual capabilities are extended to support Spanish in
addition to English and Korean. The EXAONE 4.0 model series consists of two
sizes: a mid-size 32B model optimized for high performance, and a small-size
1.2B model designed for on-device applications. The EXAONE 4.0 demonstrates
superior performance compared to open-weight models in its class and remains
competitive even against frontier-class models. The models are publicly
available for research purposes and can be easily downloaded via
https://huggingface.co/LGAI-EXAONE.

</details>


### [108] [KisMATH: Do LLMs Have Knowledge of Implicit Structures in Mathematical Reasoning?](https://arxiv.org/abs/2507.11408)
*Soumadeep Saha,Akshay Chaturvedi,Saptarshi Saha,Utpal Garain,Nicholas Asher*

Main category: cs.CL

TL;DR: 本研究引入因果思维链图（CCGs）来解释思维链如何提高LLM的推理能力。通过构建KisMATH数据集，发现推理节点是答案的关键中介，且LLM会遵循CCG结构进行推理。


<details>
  <summary>Details</summary>
Motivation: 现有研究尚未就思维链（Chain-of-thought）提高大型语言模型在多种推理任务中表现的机制达成共识。

Method: 提出因果思维链图（CCGs）的概念，这是一种从推理链中自动提取的、能够模拟语言模型输出中细粒度因果依赖关系的定向无环图。构建了一个包含1671个数学推理问题及其相关CCGs的数据集——KisMATH。

Result: 通过对15个开源语言模型进行详细的实证分析，发现CCG中的推理节点是最终答案的必要中介（即推理过程的必要条件），并且语言模型会倾向于遵循CCG提供的推理路径。

Conclusion: 该研究通过引入因果思维链图（CCGs）来解析思维链推理的机制。实验表明，CCGs中的推理节点是最终答案的必要中介，并且语言模型会优先考虑CCG提供的推理路径，表明模型内部存在类似CCG的结构。

Abstract: Chain-of-thought traces have been shown to improve performance of large
language models in a plethora of reasoning tasks, yet there is no consensus on
the mechanism through which this performance boost is achieved. To shed more
light on this, we introduce Causal CoT Graphs (CCGs), which are directed
acyclic graphs automatically extracted from reasoning traces that model
fine-grained causal dependencies in the language model output. A collection of
$1671$ mathematical reasoning problems from MATH500, GSM8K and AIME, and their
associated CCGs are compiled into our dataset -- \textbf{KisMATH}. Our detailed
empirical analysis with 15 open-weight LLMs shows that (i) reasoning nodes in
the CCG are mediators for the final answer, a condition necessary for
reasoning; and (ii) LLMs emphasise reasoning paths given by the CCG, indicating
that models internally realise structures akin to our graphs. KisMATH enables
controlled, graph-aligned interventions and opens up avenues for further
investigation into the role of chain-of-thought in LLM reasoning.

</details>


### [109] [Seq vs Seq: An Open Suite of Paired Encoders and Decoders](https://arxiv.org/abs/2507.11412)
*Orion Weller,Kathryn Ricci,Marc Marone,Antoine Chaffin,Dawn Lawrie,Benjamin Van Durme*

Main category: cs.CL

TL;DR: Fair comparison of encoder-only and decoder-only LLMs using the Ettin suite, showing SOTA results and task-specific performance advantages, with continued training being suboptimal for cross-task adaptation.


<details>
  <summary>Details</summary>
Motivation: Previous work has attempted to compare encoder-only and decoder-only language models, but is forced to make comparisons with models that have different numbers of parameters, training techniques, and datasets. This study aims to provide a fair comparison using a consistent training methodology.

Method: Introduction of the SOTA open-data Ettin suite of models: paired encoder-only and decoder-only models ranging from 17 million parameters to 1 billion, trained on up to 2 trillion tokens. Using the same recipe for both encoder-only and decoder-only models.

Result: The Ettin suite achieved SOTA results in both encoder-only and decoder-only categories for their respective sizes, outperforming ModernBERT, Llama 3.2, and SmolLM2. It was found that encoder-only models are better for classification and retrieval, while decoder-only models are better for generative tasks. Adapting models across tasks through continued training is less effective than using the reverse objective.

Conclusion: encoder-only models excel at classification and retrieval tasks while decoders excel at generative tasks. Adapting a decoder model to encoder tasks (and vice versa) through continued training is subpar compared to using only the reverse objective.

Abstract: The large language model (LLM) community focuses almost exclusively on
decoder-only language models, since they are easier to use for text generation.
However, a large subset of the community still uses encoder-only models for
tasks such as classification or retrieval. Previous work has attempted to
compare these architectures, but is forced to make comparisons with models that
have different numbers of parameters, training techniques, and datasets. We
introduce the SOTA open-data Ettin suite of models: paired encoder-only and
decoder-only models ranging from 17 million parameters to 1 billion, trained on
up to 2 trillion tokens. Using the same recipe for both encoder-only and
decoder-only models produces SOTA recipes in both categories for their
respective sizes, beating ModernBERT as an encoder and Llama 3.2 and SmolLM2 as
decoders. Like previous work, we find that encoder-only models excel at
classification and retrieval tasks while decoders excel at generative tasks.
However, we show that adapting a decoder model to encoder tasks (and vice
versa) through continued training is subpar compared to using only the reverse
objective (i.e. a 400M encoder outperforms a 1B decoder on MNLI, and vice versa
for generative tasks). We open-source all artifacts of this study including
training data, training order segmented by checkpoint, and 200+ checkpoints to
allow future work to analyze or extend all aspects of training.

</details>


### [110] [Reasoning Strategies in Large Language Models: Can They Follow, Prefer, and Optimize?](https://arxiv.org/abs/2507.11423)
*Yanjian Zhang,Guillaume Wisniewski,Nadi Tomeh,Thierry Charnois*

Main category: cs.CL

TL;DR: LLM推理策略研究：提示词可引导但非万能，自适应选择是关键。


<details>
  <summary>Details</summary>
Motivation: LLM倾向于单一推理策略，可能限制其在多样化推理挑战中的有效性。

Method: 通过实验探究提示词是否能控制LLM的推理策略，并评估其对逻辑解题的影响。

Result: 实验表明，没有单一策略能持续提高准确性，但模型自适应选择最优策略可以提升性能。

Conclusion: 提示可以引导LLM选择不同的推理策略，但没有单一策略能持续提高准确性。模型应能自适应地选择最优策略以提升推理能力。

Abstract: Human reasoning involves different strategies, each suited to specific
problems. Prior work shows that large language model (LLMs) tend to favor a
single reasoning strategy, potentially limiting their effectiveness in diverse
reasoning challenges. In this work, we investigate whether prompting can
control LLMs reasoning strategies and assess its impact on logical
problem-solving. While our experiments show that no single strategy
consistently improves accuracy, performance could be enhanced if models could
adaptively choose the optimal strategy. We propose methods to guide LLMs in
strategy selection, highlighting new ways to refine their reasoning abilities.

</details>


### [111] [HKGAI-V1: Towards Regional Sovereign Large Language Model for Hong Kong](https://arxiv.org/abs/2507.11502)
*Sirui Han,Junqi Zhu,Ruiyuan Zhang,Yike Guo*

Main category: cs.CL

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: This paper presents the development of HKGAI-V1, a foundational sovereign
large language model (LLM), developed as part of an initiative to establish
value-aligned AI infrastructure specifically tailored for Hong Kong. Addressing
the region's unique multilingual environment (Cantonese, Mandarin, and
English), its distinct socio-legal context under the "one country, two systems"
framework, and specific local cultural and value considerations, the model is
built upon the DeepSeek architecture and systematically aligned with regional
norms through a multifaceted full parameter fine-tuning process. It is further
integrated with a retrieval-augmented generation (RAG) system to ensure timely
and factually grounded information access. The core contribution lies in the
design and implementation of a comprehensive, region-specific AI alignment and
safety framework, demonstrated through two key achievements: 1) The successful
development of HKGAI-V1 itself - which outper-forms general-purpose models in
handling Hong Kong-specific culturally sensitive queries, and embodies a
"governance-embedded" approach to digital sovereignty - empowers Hong Kong to
exercise control over AI applications in critical sectors including public
services, legal systems, and edu-cation. 2) The development of the proprietary
Adversarial HK Value Benchmark, a rigorous tool for evaluating model alignment
with local ethical and legal stand-ards under challenging conditions. By
documenting these achievements, the paper provides not only a technological
artifact but also a replicable blueprint for developing advanced, regionally
focused AI systems deeply rooted in their local identities.

</details>


### [112] [Real-World Summarization: When Evaluation Reaches Its Limits](https://arxiv.org/abs/2507.11508)
*Patrícia Schmidtová,Ondřej Dušek,Saad Mahamood*

Main category: cs.CL

TL;DR: LLM在酒店摘要方面表现良好，但评估不可靠。简单的指标（如词重叠）在评估摘要忠实度方面效果不错。错误信息风险最高。众包评估存在挑战。


<details>
  <summary>Details</summary>
Motivation: 旨在研究酒店摘要（LLM生成的简短摘要，捕捉住宿的独特功能）在忠实于输入数据方面的评估。

Method: 通过涉及分类错误评估和跨度级别注释的人类评估活动，比较了传统的、可训练的和LLM作为评判的方法。

Result: 研究发现，像词重叠这样的简单指标与人类判断的相关性出奇地好（Spearman相关等级为0.63），并且在应用于非领域数据时，通常优于更复杂的方法。LLM虽然能生成高质量的摘要，但作为评估者时并不可靠。

Conclusion: LLM在酒店摘要生成方面表现出色，但作为评估者时不可靠，容易出现标注不足或过度标注的问题。分析显示，错误和无法核实的信息会带来最大的风险。此外，众包评估也存在挑战。

Abstract: We examine evaluation of faithfulness to input data in the context of hotel
highlights: brief LLM-generated summaries that capture unique features of
accommodations. Through human evaluation campaigns involving categorical error
assessment and span-level annotation, we compare traditional metrics, trainable
methods, and LLM-as-a-judge approaches. Our findings reveal that simpler
metrics like word overlap correlate surprisingly well with human judgments
(Spearman correlation rank of 0.63), often outperforming more complex methods
when applied to out-of-domain data. We further demonstrate that while LLMs can
generate high-quality highlights, they prove unreliable for evaluation as they
tend to severely under- or over-annotate. Our analysis of real-world business
impacts shows incorrect and non-checkable information pose the greatest risks.
We also highlight challenges in crowdsourced evaluations.

</details>


<div id='eess.SP'></div>

# eess.SP [[Back]](#toc)

### [113] [A Leap-on-Success Exhaustive Search Method to Find Optimal Robust Minimum Redundancy Arrays (RMRAs): New Array Configurations for Sensor Counts 11 to 20](https://arxiv.org/abs/2507.10706)
*Pradyumna Kunchala,Ashish Patwari*

Main category: eess.SP

TL;DR: 本研究通过一种新的搜索算法发现了更多传感器数量下的最优 RMRA 配置，并验证了其鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有研究仅报告了多达 10 个传感器的最优 RMRA 配置，因为寻找最优 RMRA 配置是一个 NP 难问题。本研究旨在发现更多传感器数量下的最优 RMRA 配置，并验证其在单传感器故障下的鲁棒性。

Method: 使用新颖的 Leap-on-Success 穷举搜索算法来寻找最优 RMRA 配置，该算法通过在找到最优解后终止搜索来有效减少计算工作量。

Result: 发现了 11 至 15 个传感器的新型最优 RMRA 配置，并报告了 16 至 20 个传感器的近似最优配置。通过 MATLAB 模拟验证了这些阵列在所有单传感器故障场景下的鲁棒性，证实了它们比某些现有 TFRAs 更具弹性。

Conclusion: 本研究发现了 11 至 15 个传感器的新型最优鲁棒最小冗余阵列（RMRA）配置，并为 16 至 20 个传感器提供了近似最优配置。这不仅推进了 RMRA 设计的最新进展，还提出了一种有效的搜索方法，可用于未来阵列配置优化的探索。

Abstract: Two-fold redundant sparse arrays (TFRAs) are designed to maintain accurate
direction estimation even in the event of a single sensor failure, leveraging
the deliberate coarray redundancy infused into their design. Robust Minimum
Redundancy Arrays (RMRAs), a specialized class of TFRAs, optimize this
redundancy to achieve the maximum possible aperture for a given number of
sensors. However, finding optimal RMRA configurations is an NP-hard problem,
with prior research reporting optimal solutions only for arrays of up to ten
sensors. This paper presents newly discovered optimal RMRA configurations for
array sizes 11 to 15, identified using a novel Leap-on-Success exhaustive
search algorithm that efficiently reduces computational effort by terminating
the search upon locating optimal solutions. The robustness of these arrays was
validated under all single-element failure scenarios using MATLAB simulations,
confirming their superior resilience compared to some existing TFRAs vulnerable
to failures at specific sensor positions. Furthermore, near-optimal
configurations for array sizes 16 to 20 are also reported, highlighting the
potential applicability of the proposed method for larger array designs given
sufficient computational resources. This work not only advances the
state-of-the-art in RMRA design but also introduces an effective search
methodology that can be leveraged for future explorations in array
configuration optimization.

</details>


### [114] [Waterfilling at the Edge: Optimal Percentile Resource Allocation via Risk-Averse Reduction](https://arxiv.org/abs/2507.10838)
*Gokberk Yaylali,Ahmad Ali Khan,Dionysios S. Kalogerias*

Main category: eess.SP

TL;DR: 本研究提出了一种基于CVaR和SLαQ的优化框架，用于解决多终端AWGN信道中的确定性资源分配问题，特别是优化小区边缘终端的量化传输速率。通过推导闭式解和开发边缘水填充算法，实现了高效且公平的资源分配。


<details>
  <summary>Details</summary>
Motivation: 为了克服经典效用方法（如最小速率、和速率和比例公平性）在点对点多终端高斯噪声（AWGN）信道中优化小区边缘终端量化传输速率时的局限性（过于保守、不适用或缺乏严格/可解释的基础），本研究旨在提供一种更优的解决方案。

Method: 利用条件在险价值（CVaR）及其与和最小分位数（SLαQ）效用的等价性，将SLαQ最大化问题精确地凸重构。利用拉格朗日对偶性，推导了最优资源策略（水填充类型）和相关的（辅助）在险价值变量的参数化闭式解。开发了一种新颖的不精确对偶次梯度下降算法来确定全局最优资源策略，并严格证明了其收敛性。

Result: 研究实现了最优的资源分配策略，该策略为水填充类型，并提供了相关的（辅助）在险价值变量的参数化闭式解。提出的边缘水填充算法能够迭代且高效地分配资源，同时明确确保小区边缘终端的传输速率公平性。大规模数值实验证明了该方法的有效性。

Conclusion: 该研究提出了一种新颖的边缘水填充算法，可确保跨（小区边缘）终端的传输速率公平性，并通过数值实验验证了其在小区边缘进行鲁棒量化速率优化方面的有效性。

Abstract: We address deterministic resource allocation in point-to-point multi-terminal
AWGN channels without inter-terminal interference, with particular focus on
optimizing quantile transmission rates for cell-edge terminal service.
Classical utility-based approaches -- such as minimum rate, sumrate, and
proportional fairness -- are either overconservative, or inappropriate, or do
not provide a rigorous and/or interpretable foundation for fair rate
optimization at the edge. To overcome these challenges, we employ Conditional
Value-at-Risk (CVaR), a popular coherent risk measure, and establish its
equivalence with the sum-least-$\alpha$th-quantile (SL$\alpha$Q) utility. This
connection enables an exact convex reformulation of the SL$\alpha$Q
maximization problem, facilitating analytical tractability and precise and
interpretable control over cell-edge terminal performance. Utilizing Lagrangian
duality, we provide (for the first time) parameterized closed-form solutions
for the optimal resource policy -- which is of waterfilling-type -- as well as
the associated (auxiliary) Value-at-Risk variable. We further develop a novel
inexact dual subgradient descent algorithm of minimal complexity to determine
globally optimal resource policies, and we rigorously establish its
convergence. The resulting edge waterfilling algorithm iteratively and
efficiently allocates resources while explicitly ensuring transmission rate
fairness across (cell-edge) terminals. Several (even large-scale) numerical
experiments validate the effectiveness of the proposed method for enabling
robust quantile rate optimization at the edge.

</details>


### [115] [Dual RIS-Assisted Monostatic L-Band Radar Target Detection in NLoS Scenarios](https://arxiv.org/abs/2507.11036)
*Salman Liaquat,Ijaz Haider Naqvi,Nor Muzlifah Mahyuddin*

Main category: eess.SP

TL;DR: 该论文提出使用双 RIS 辅助雷达系统来改善非视距 (NLoS) 目标检测的信噪比 (SNR)，并通过实验证明了该方法的有效性。


<details>
  <summary>Details</summary>
Motivation: 解决了单个 RIS 无法在雷达与目标之间建立路径的场景，尤其是在非视距 (NLoS) 情况下。

Method: 推导了双 RIS 辅助下非视距 (NLoS) 情况下的信噪比 (SNR) 表达式，并计算了通过双 RIS 配置接收到的功率。

Result: 证明了 RIS 辅助雷达的 SNR 性能可以通过控制雷达和 RIS 的位置来提高。双 RIS 辅助雷达系统在特定条件下优于单 RIS 辅助雷达系统。

Conclusion: 通过控制 RIS 的数量、每个 RIS 的单元数量以及 RIS 位置的选择，可以实现目标定位所需的精度。在有利的对齐和足够大的 RIS 尺寸下，双 RIS 辅助雷达系统的性能可以超过单 RIS 辅助雷达系统。

Abstract: The use of a single Reconfigurable Intelligent Surface (RIS) to boost the
signal-to-noise ratio (SNR) at the radar offers significant improvement in
detecting targets, especially in non-line-of-sight (NLoS) scenarios. However,
there are scenarios where no path exists between the radar and the target, even
with a single RIS-assisted radar, due to other present obstacles. This paper
derives an expression for SNR in target detection scenarios where dual RISs
assist a monostatic radar in NLoS situations. We calculate the power received
at the radar through a dual RIS configuration. We show that the SNR performance
of RIS-assisted radars can improve with known locations of the radar and RISs.
Our results demonstrate that the required accuracy in target localization can
be achieved by controlling the number of RISs, the number of unit cells in each
RIS, and properly selecting the locations of RISs to cover the desired region.
The performance of dual RIS-assisted radar systems can surpass that of single
RIS-assisted radar systems under favourable alignment and sufficiently large
RIS sizes.

</details>


### [116] [Optimizing Fluid Antenna Configurations for Constructive Interference Precoding](https://arxiv.org/abs/2507.11093)
*Wenxuan Sun,Mingjie Shao,Luteng Zhu,Yao Ge,Tong Zhang,Zhi Liu*

Main category: eess.SP

TL;DR: 提出一种新的 FAS 和 CI pre­coding 方法，可降低通信误码率和计算复杂度。


<details>
  <summary>Details</summary>
Motivation: 为了解决传统固定阵列在多用户 MIMO 通信中传播条件受限的问题，提出一种新的物理层概念——流体天线系统 (FAS)。然而，现有的 FAS 和 CI pre­coding 方法未能有效解决 SEP 最小化问题。

Method: 将 SEP 最小化问题转化为 CI pre­coding 中的安全裕度最大化问题，并自定义了平滑技术和块坐标下降 (BCD) 算法，以实现低计算复杂度。

Result: 仿真结果表明，本文提出的 FAS 和 CI pre­coding 方法与现有的固定阵列和基于 PSO 的 FAS 方法相比，能够降低误比特率 (BER)。此外，与 PSO 基准方法相比，本文提出的方法具有较低的计算复杂度。

Conclusion: 本文提出的 joint SEP minimization 算法在降低误比特率和计算复杂度方面优于现有方法。

Abstract: The fluid antenna system (FAS) has emerged as a new physical-layer concept to
provide enhanced propagation conditions for multiuser multiple-input
multiple-output (MIMO) communications over conventional fixed arrays. This work
focuses on minimizing the maximum symbol error probability (SEP) under $M$-ary
phase shift keying (MPSK) signaling in a multiuser downlink equipped with FAS,
where each antenna moves within nonoverlapping intervals. This specific problem
of joint SEP minimization with FAS and constructive interference (CI) precoding
has not been previously addressed. The resulting problem turns out to be a
nonconvex and nonsmooth optimization challenge. We transform the SEP
minimization problem into a safety margin maximization problem in constructive
interference precoding. Then, we customize a smoothing technique and a block
coordinate descent (BCD) algorithm, with emphasis on low computational
complexity. Simulation results show that our approach can reduce bit error rate
(BER) compared to both the fixed arrays and FAS designed by existing particle
swarm optimization (PSO). Also, our approach shows attractively low
computational complexity compared to PSO benchmarks.

</details>


### [117] [Fairness-Aware Secure Integrated Sensing and Communications with Fractional Programming](https://arxiv.org/abs/2507.11224)
*Ali Khandan Boroujeni,Kuranage Roche Rayan Ranasinghe,Giuseppe Thadeu Freitas de Abreu,Stefan Köpsell,Ghazal Bagheri,Rafael F. Schaefer*

Main category: eess.SP

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: We propose a novel secure integrated sensing and communications (ISAC) system
designed to serve multiple communication users (CUs) and targets. To that end,
we formulate an optimization problem that maximizes the secrecy rate under
constraints balancing both communication and sensing requirements. To enhance
fairness among users, an entropy-regularized fairness metric is introduced
within the problem framework. We then propose a solution employing an
accelerated quadratic transform (QT) with a non-homogeneous bound to
iteratively solve two subproblems, thereby effectively optimizing the overall
objective. This approach ensures robust security and fairness in resource
allocation for ISAC systems. Finally, simulation results verify the performance
gains in terms of average secrecy rate, average data rate, and beam gain.

</details>


### [118] [Fast and Efficient Implementation of the Maximum Likelihood Estimation for the Linear Regression with Gaussian Model Uncertainty](https://arxiv.org/abs/2507.11249)
*Ruohai Guo,Jiang Zhu,Xing Jiang,Fengzhong Qu*

Main category: eess.SP

TL;DR: 本研究扩展了随机测量矩阵线性回归模型的分析，允许其均值秩亏缺，并提出了新的统一算法GRV-ML，证明了其凸性和强对偶性。


<details>
  <summary>Details</summary>
Motivation: 扩展了随机变量（RV）测量矩阵的线性回归模型分析，允许测量矩阵均值秩亏缺，以解决过定和不定情况。

Method: 提出了一种名为广义RV-ML（GRV-ML）的快速统一实现方法，该方法能够处理更一般的过定和不定系统，包括测量矩阵均值秩亏缺的情况。

Result: 证明了等效的最大似然估计（MLE）问题是凸的并满足强对偶性，证实了随机性在某些条件下对估计是有益的，并提出了一种名为广义RV-ML（GRV-ML）的快速统一实现方法。

Conclusion: 该研究将线性回归模型分析扩展到随机测量矩阵均值秩亏缺的场景，提出了广义RV-ML算法，并在数值模拟中验证了理论结果。

Abstract: The linear regression model with a random variable (RV) measurement matrix,
where the mean of the random measurement matrix has full column rank, has been
extensively studied. In particular, the quasiconvexity of the maximum
likelihood estimation (MLE) problem was established, and the corresponding
Cramer-Rao bound (CRB) was derived, leading to the development of an efficient
bisection-based algorithm known as RV-ML. In contrast, this work extends the
analysis to both overdetermined and underdetermined cases, allowing the mean of
the random measurement matrix to be rank-deficient. A remarkable contribution
is the proof that the equivalent MLE problem is convex and satisfies strong
duality, strengthening previous quasiconvexity results. Moreover, it is shown
that in underdetermined scenarios, the randomness in the measurement matrix can
be beneficial for estimation under certain conditions. In addition, a fast and
unified implementation of the MLE solution, referred to as generalized RV-ML
(GRV-ML), is proposed, which handles a more general case including both
underdetermined and overdetermined systems. Extensive numerical simulations are
provided to validate the theoretical findings.

</details>


### [119] [Sensing Accuracy Optimization for Multi-UAV SAR Interferometry with Data Offloading](https://arxiv.org/abs/2507.11284)
*Mohamed-Amine Lahmeri,Pouya Fakharizadeh,Víctor Mustieles-Pérez,Martin Vossiek,Gerhard Krieger,Robert Schober*

Main category: eess.SP

TL;DR: 通过进化算法优化无人机群的编队、速度和通信功率，提高了InSAR传感精度，实现了亚分米级垂直精度。


<details>
  <summary>Details</summary>
Motivation: 提高无人机群进行多基线InSAR传感时的传感精度，同时保证通信质量。

Method: 利用进化算法（EAs）联合优化无人机编队、速度和通信功率分配，以最小化平均DEM的高度误差，同时确保传感和通信的服务质量（QoS）。

Result: 提出的解决方案优于传统的遗传算法（GAs）、模拟退火（SA）和深度强化学习（DRL）等优化方法，在多种场景下实现了亚分米级的垂直精度。

Conclusion: 该研究展示了通过优化无人机编队、速度和通信功率分配，可以显著提高无人机群进行多基线InSAR传感时的传感精度，并达到亚分米级垂直精度，证明了无人机群在雷达干涉测量中实现高精度、实时地球观测的潜力。

Abstract: The integration of unmanned aerial vehicles (UAVs) with radar imaging sensors
has revolutionized the monitoring of dynamic and local Earth surface processes
by enabling high-resolution and cost-effective remote sensing. This paper
investigates the optimization of the sensing accuracy of a UAV swarm deployed
to perform multi-baseline interferometric synthetic aperture radar (InSAR)
sensing. In conventional single-baseline InSAR systems, only one synthetic
aperture radar (SAR) antenna pair acquires two SAR images from two distinct
angles to generate a digital elevation model (DEM) of the target area. However,
multi-baseline InSAR extends this concept by aggregating multiple acquisitions
from different angles, thus, significantly enhancing the vertical accuracy of
the DEM. The heavy computations required for this process are performed on the
ground and, therefore, the radar data is transmitted in real time to a ground
station (GS) via a frequency-division multiple access (FDMA) air-to-ground
backhaul link. This work focuses on improving the sensing precision by
minimizing the height error of the averaged DEM while simultaneously ensuring
sensing and communication quality-of-service (QoS). To this end, the UAV
formation, velocity, and communication power allocation are jointly optimized
using evolutionary algorithms (EAs). Our approach is benchmarked against
established optimization methods, including genetic algorithms (GAs), simulated
annealing (SA), and deep reinforcement learning (DRL) techniques. Numerical
results show that the proposed solution outperforms these baseline schemes and
achieves sub-decimeter vertical accuracy in several scenarios. These findings
underline the potential of coordinated UAV swarms for delivering high-precision
and real-time Earth observations through radar interferometry.

</details>


### [120] [Sparse Regression Codes exploit Multi-User Diversity without CSI](https://arxiv.org/abs/2507.11383)
*V S V Sandeep,Sai Dinesh Kancharana,Arun Pachai Kannu*

Main category: eess.SP

TL;DR: SPARC with MLMP decoder shows good performance in multiple access channels, outperforming existing methods.


<details>
  <summary>Details</summary>
Motivation: We study sparse regression codes (SPARC) for multiple access channels with multiple receive antennas, in non-coherent flat fading channels.

Method: We propose a novel practical decoder, referred to as maximum likelihood matching pursuit (MLMP), which greedily finds the support of the codewords of users with partial maximum likelihood metrics. MLMP works as a successive-combining energy detector. We also propose MLMP modifications to improve the performance at high code rates.

Result: Our studies in short block lengths show that, even without any channel state information, SPARC with MLMP decoder achieves multi-user diversity in some scenarios.

Conclusion: SPARC with MLMP decoder achieves multi-user diversity in some scenarios, giving better error performance with multiple users than that of the corresponding single-user case. SPARC with MLMP performs better than conventional sparse recovery algorithms and pilot-aided transmissions with polar codes.

Abstract: We study sparse regression codes (SPARC) for multiple access channels with
multiple receive antennas, in non-coherent flat fading channels. We propose a
novel practical decoder, referred to as maximum likelihood matching pursuit
(MLMP), which greedily finds the support of the codewords of users with partial
maximum likelihood metrics. As opposed to the conventional
successive-cancellation based greedy algorithms, MLMP works as a
successive-combining energy detector. We also propose MLMP modifications to
improve the performance at high code rates. Our studies in short block lengths
show that, even without any channel state information, SPARC with MLMP decoder
achieves multi-user diversity in some scenarios, giving better error
performance with multiple users than that of the corresponding single-user
case. We also show that SPARC with MLMP performs better than conventional
sparse recovery algorithms and pilot-aided transmissions with polar codes.

</details>


### [121] [Joint Power Allocation and Reflecting-Element Activation for Energy Efficiency Maximization in IRS-Aided Communications Under CSI Uncertainty](https://arxiv.org/abs/2507.11413)
*Christos N. Efrem,Ioannis Krikidis*

Main category: eess.SP

TL;DR: 本文研究了在信道状态信息不完美的智能反射面（IRS）辅助通信系统中，联合功率分配和反射单元（RE）激活以最大化能量效率（EE）的问题。文章提出了一种交替优化（AO）算法和一种分支定界（B&B）算法来解决该问题，并验证了所提出算法的有效性。


<details>
  <summary>Details</summary>
Motivation: 为了在考虑信道状态信息（CSI）不完美的情况下，最大化智能反射面（IRS）辅助通信系统的能量效率（EE），需要研究联合功率分配和反射单元（RE）激活问题。

Method: 文章提出了一种交替优化（AO）算法，该算法利用朗伯W函数和动态规划（DP）来解决鲁棒优化问题，并提出了一种分支定界（B&B）方法，该方法利用AO作为子程序，能够保证找到全局最优解。

Result: 数值结果表明，所提出的算法优于基线方案，AO在大多数情况下实现了接近最优的性能，并且B&B算法的计算复杂度平均较低。

Conclusion: 所提出的交替优化（AO）和分支定界（B&B）算法在实际应用中具有较低的计算复杂度和接近最优的性能。

Abstract: We study the joint power allocation and reflecting element (RE) activation to
maximize the energy efficiency (EE) in communication systems assisted by an
intelligent reflecting surface (IRS), taking into account imperfections in
channel state information (CSI). The robust optimization problem is mixed
integer, i.e., the optimization variables are continuous (transmit power) and
discrete (binary states of REs). In order to solve this challenging problem we
develop two algorithms. The first one is an alternating optimization (AO)
method that attains a suboptimal solution with low complexity, based on the
Lambert W function and a dynamic programming (DP) algorithm. The second one is
a branch-and-bound (B&B) method that uses AO as its subroutine and is formally
guaranteed to achieve a globally optimal solution. Both algorithms do not
require any external optimization solver for their implementation. Furthermore,
numerical results show that the proposed algorithms outperform the baseline
schemes, AO achieves near-optimal performance in most cases, and B&B has low
computational complexity on average.

</details>


<div id='eess.SY'></div>

# eess.SY [[Back]](#toc)

### [122] [Learning to Quantize and Precode in Massive MIMO Systems for Energy Reduction: a Graph Neural Network Approach](https://arxiv.org/abs/2507.10634)
*Thomas Feys,Liesbet Van der Perre,François Rottenberg*

Main category: eess.SY

TL;DR: 为了解决大规模MIMO系统中DAC功耗瓶颈问题，本文提出了一种基于图神经网络（GNN）的非线性预编码方法。该方法通过自监督学习和Gumbel-softmax梯度估计，在粗量化下显著提升了可实现速率，并大幅降低了DAC功耗（1位DAC效果媲美3位DAC的MRT），尽管增加了数字信号处理的功耗，但在一定带宽内仍可实现整体功耗降低。


<details>
  <summary>Details</summary>
Motivation: 大规模MIMO系统正朝着增加射频链数量、更高载波频率和更大带宽的方向发展，导致数模转换器（DAC）在硬件复杂度和功耗方面成为瓶颈。因此，研究非线性预编码以应对粗量化下行海量MIMO的DAC功耗问题至关重要。

Method: 提出了一种图神经网络（GNN）模型，用于处理粗量化下行海量MIMO的非线性预编码问题。该模型直接根据信道矩阵和预期的发射符号输出预编码量化向量，并通过最大化可实现速率进行自监督学习。为解决目标函数中的非可微性问题（源于非可微的DAC函数），提出了一种直接通过Gumbel-softmax估计梯度的方法。

Result: 所提出的图神经网络（GNN）方法在粗量化条件下实现了可观的总和速率提升。具体而言，在单用户场景下，该方法仅使用1位DAC便能达到与最大 ratio transmission (MRT) 相当的总和速率，而MRT需要3位DAC。这使得基带DAC和射频DAC的功耗分别降低了4-7倍和3倍。尽管数字信号处理的功耗有所增加，但考虑到这一点，在系统带宽高达3.5 MHz时，基带DAC的整体功耗仍能降低，而射频DAC在更高带宽下仍能保持2.9倍的功耗降低。分析未考虑间接降低功耗的因素（如缩短的前传链路和减少其他组件的功耗）。

Conclusion: 提出的图神经网络（GNN）方法通过直接输出预编码量化向量，在粗量化下显著提高了可实现的总和速率，并在单用户情况下，使用1位DAC实现了与最大 ratio transmission (MRT) 相同的总和速率，相较于MRT的3位DAC，可将基带和射频DAC的功耗降低4-7倍和3倍。然而，这会增加数字信号处理的功耗，但在考虑此因素后，对于基带DAC，在高达3.5 MHz的系统带宽下仍可实现整体功耗降低，而射频DAC在更高带宽下仍可维持2.9倍的功耗降低。

Abstract: Massive MIMO systems are moving toward increased numbers of radio frequency
chains, higher carrier frequencies and larger bandwidths. As such,
digital-to-analog converters (DACs) are becoming a bottleneck in terms of
hardware complexity and power consumption. In this work, non-linear precoding
for coarsely quantized downlink massive MIMO is studied. Given the NP-hard
nature of this problem, a graph neural network (GNN) is proposed that directly
outputs the precoded quantized vector based on the channel matrix and the
intended transmit symbols. The model is trained in a self-supervised manner, by
directly maximizing the achievable rate. To overcome the non-differentiability
of the objective function, introduced due to the non-differentiable DAC
functions, a straight-through Gumbel-softmax estimation of the gradient is
proposed. The proposed method achieves a significant increase in achievable sum
rate under coarse quantization. For instance, in the single-user case, the
proposed method can achieve the same sum rate as maximum ratio transmission
(MRT) by using one-bit DAC's as compared to 3 bits for MRT. This reduces the
DAC's power consumption by a factor 4-7 and 3 for baseband and RF DACs
respectively. This, however, comes at the cost of increased digital signal
processing power consumption. When accounting for this, the reduction in
overall power consumption holds for a system bandwidth up to 3.5 MHz for
baseband DACs, while the RF DACs can maintain a power reduction of 2.9 for
higher bandwidths. Notably, indirect effects, which further reduce the power
consumption, such as a reduced fronthaul consumption and reduction in other
components, are not considered in this analysis.

</details>


### [123] [Data-Driven Safety Certificates of Infinite Networks with Unknown Models and Interconnection Topologies](https://arxiv.org/abs/2507.10979)
*Mahdieh Zaker,Amy Nejati,Abolfazl Lavaei*

Main category: eess.SY

TL;DR: This paper offers a data-driven method to certify the safety of complex, infinite networks whose models and connections are unknown. It uses subsystem properties (storage certificates) to create a safety guarantee (barrier certificate) without needing to know exact network details or how subsystems connect. This method is more efficient in terms of data needed and works even when system details are not fully known, as shown in real-world examples.


<details>
  <summary>Details</summary>
Motivation: Existing analysis frameworks for finite networks are inapplicable to infinite networks due to their complex, interconnected nature and the challenge of precisely counting subsystems. The paper aims to provide a data-driven approach for safety certification in these scenarios where mathematical models and interconnection topologies are unknown.

Method: A compositional data-driven framework is used, focusing on the joint dissipativity-type properties of subsystems characterized by storage certificates. Innovative compositional data-driven conditions are introduced to construct a barrier certificate for the infinite network using storage certificates derived from data of unknown subsystems.

Result: The approach successfully constructs a barrier certificate for infinite networks with unknown models and topologies, offering correctness guarantees for network safety. It eliminates the need to check traditional dissipativity conditions and reduces sample complexity to a linear scale compared to existing methods. The effectiveness is demonstrated on two physical infinite networks.

Conclusion: The paper presents a compositional data-driven approach for the safety certification of infinite networks with unknown models and interconnection topologies. It leverages joint dissipativity-type properties and storage certificates of subsystems to construct a barrier certificate. The approach eliminates the need for precise knowledge of the interconnection topology and reduces sample complexity from exponential to linear with respect to the number of subsystems.

Abstract: Infinite networks are complex interconnected systems comprising a countably
infinite number of subsystems, where counting them precisely poses a
significant challenge due to the seemingly endless interconnected nature of the
network (e.g., counting vehicles on the road). In such scenarios, the presence
of infinitely many subsystems within the network renders the existing analysis
frameworks tailored for finite networks inapplicable to infinite ones. This
paper is concerned with offering a data-driven approach, within a compositional
framework, for the safety certification of infinite networks with both unknown
mathematical models and interconnection topologies. Given the immense
computational complexity stemming from the extensive dimension of infinite
networks, our approach capitalizes on the joint dissipativity-type properties
of subsystems, characterized by storage certificates. We introduce innovative
compositional data-driven conditions to construct a barrier certificate for the
infinite network leveraging storage certificates of its unknown subsystems
derived from data, while offering correctness guarantees across the network
safety. We demonstrate that our compositional data-driven reasoning eliminates
the requirement for checking the traditional dissipativity condition, which
typically mandates precise knowledge of the interconnection topology. In
addition, while existing data-driven literature demonstrates an exponential
trend in sample complexity with respect to network size, we showcase that our
compositional strategy notably reduces it to a linear scale in terms of the
number of subsystems. We illustrate our data-driven results on two physical
infinite networks with unknown models and interconnection topologies.

</details>


### [124] [Approximate solutions to games of ordered preference](https://arxiv.org/abs/2507.11021)
*Pau de las Heras Molins,Eric Roy-Almonacid,Dong Ho Lee,Lasse Peters,David Fridovich-Keil,Georgios Bakirtzis*

Main category: eess.SY

TL;DR: Autonomous vehicles use games of ordered preference to balance objectives like travel time and safety. 


<details>
  <summary>Details</summary>
Motivation: Games of ordered preference effectively model interactions for autonomous vehicles 

Method: lexicographic iterated best response (IBR) in receding horizon, termed 

Result: demonstrates through simulated traffic scenarios that lexicographic IBR over time efficiently computes 

Conclusion: lexicographic IBR over time efficiently computes approximate-optimal solutions for receding horizon games of ordered preference, converging towards generalized Nash equilibria.

Abstract: Autonomous vehicles must balance ranked objectives, such as minimizing travel
time, ensuring safety, and coordinating with traffic. Games of ordered
preference effectively model these interactions but become computationally
intractable as the time horizon, number of players, or number of preference
levels increase. While receding horizon frameworks mitigate long-horizon
intractability by solving sequential shorter games, often warm-started, they do
not resolve the complexity growth inherent in existing methods for solving
games of ordered preference. This paper introduces a solution strategy that
avoids excessive complexity growth by approximating solutions using
lexicographic iterated best response (IBR) in receding horizon, termed
"lexicographic IBR over time." Lexicographic IBR over time uses past
information to accelerate convergence. We demonstrate through simulated traffic
scenarios that lexicographic IBR over time efficiently computes
approximate-optimal solutions for receding horizon games of ordered preference,
converging towards generalized Nash equilibria.

</details>


### [125] [Standards-Compliant DM-RS Allocation via Temporal Channel Prediction for Massive MIMO Systems](https://arxiv.org/abs/2507.11064)
*Sehyun Ryu,Hyun Jong Yang*

Main category: eess.SY

TL;DR: 针对5G及以后网络中大规模MIMO系统的CSI反馈开销过大的问题，提出了一种基于信道预测的参考信号分配（CPRS）方法，通过结合信道预测和DM-RS分配来提升吞吐量，而无需CSI反馈。该方法使用符合标准的ViViT/CNN架构，将CSI矩阵视为序列图像数据，实现了高效自适应传输，并在仿真中取得了显著的性能提升。


<details>
  <summary>Details</summary>
Motivation: 在超越5G的网络中，随着大规模MIMO系统中天线数量的不断增加，对信道状态信息（CSI）反馈的需求也随之增加，这给减少反馈开销带来了严峻的挑战。虽然在CSI压缩和预测方面进行了大量研究，但参考信号分配在CSI受限条件下的研究却很少。

Method: 提出了一种符合标准的基于ViViT/CNN的架构来实现CPRS，将演进中的CSI矩阵视为序列图像数据，从而在动态环境中实现高效和自适应的传输。

Result: 仿真结果表明，与基准策略相比，所提出的CPRS方法能够将吞吐量提高高达36.60%。

Conclusion: 所提出的CPRS方法通过联合优化信道预测和DM-RS分配，在无需CSI反馈的情况下提高了数据吞吐量，并得到了仿真结果的验证，与基准策略相比，吞吐量提高了36.60%。

Abstract: Reducing feedback overhead in beyond 5G networks is a critical challenge, as
the growing number of antennas in modern massive MIMO systems substantially
increases the channel state information (CSI) feedback demand in frequency
division duplex (FDD) systems. To address this, extensive research has focused
on CSI compression and prediction, with neural network-based approaches gaining
momentum and being considered for integration into the 3GPP 5G-Advanced
standards. While deep learning has been effectively applied to CSI-limited
beamforming and handover optimization, reference signal allocation under such
constraints remains surprisingly underexplored. To fill this gap, we introduce
the concept of channel prediction-based reference signal allocation (CPRS),
which jointly optimizes channel prediction and DM-RS allocation to improve data
throughput without requiring CSI feedback. We further propose a
standards-compliant ViViT/CNN-based architecture that implements CPRS by
treating evolving CSI matrices as sequential image-like data, enabling
efficient and adaptive transmission in dynamic environments. Simulation results
using ray-tracing channel data generated in NVIDIA Sionna validate the proposed
method, showing up to 36.60% throughput improvement over benchmark strategies.

</details>


### [126] [Optimal Honeypot Ratio and Convergent Fictitious-Play Learning in Signaling Games for CPS Defense](https://arxiv.org/abs/2507.11113)
*Yueyue Xu,Yuewei Chen,Lin Wang,Zhaoyang Cheng,Xiaoming Hu*

Main category: eess.SY

TL;DR: 本文提出了一种将蜜罐部署建模为伽马固定信号博弈的方法，以应对网络物理系统（CPS）日益增长的攻击。研究了伽马-完美贝叶斯纳什均衡，并推导了其解析表达式，揭示了三种不同的均衡机制。此外，还确定了最大化网络平均效用的最优策略。通过一种离散时间的虚拟博弈算法，证明了该方法能够收敛到最优均衡。数值结果证实了该方法的有效性和在CPS防御中的应用潜力。


<details>
  <summary>Details</summary>
Motivation: 为了实现有效的预防性防御，本文研究了网络物理系统（CPS）面临的日益增长的攻击问题。

Method: 本文将蜜罐部署建模为一个伽马固定信号博弈，其中节点活性是唯一的信号，并且正常节点的信号伽马是外生的固定。我们定义了伽马-完美贝叶斯纳什均衡（gamma-PBNE），并获得了所有伽马-PBNE的解析表达式，揭示了三种取决于先验蜜罐比例的独特均衡机制。此外，还获得了联合最大化网络平均效用的最优蜜罐比例和信号策略。为了捕捉跨时间的战略互动，我们开发了一种离散时间的虚拟博弈算法，它将贝叶斯信念更新与经验最佳响应相结合。

Result: 通过数值结果证实了所提议方法的有效性，并证明了其在CPS防御中的适用性。

Conclusion: 所提出的基于伽马固定信号博弈的模型能够有效地用于网络防御，并且该算法可以收敛到最优的伽马-完美贝叶斯纳什均衡，从而实现了网络的平均效用最大化。

Abstract: Cyber-Physical Systems (CPSs) are facing a fast-growing wave of attacks. To
achieve effective proactive defense, this paper models honeypot deployment as a
gamma-fixed signaling game in which node liveness serves as the only signal and
normal-node signal gamma is exogenously fixed. We define the gamma-perfect
Bayesian-Nash equilibrium (gamma-PBNE). Analytical expressions are obtained for
all gamma-PBNEs, revealing three distinct equilibrium regimes that depend on
the priori honeypot ratio. Furthermore, the optimal honeypot ratio and
signaling strategy that jointly maximize the network average utility are
obtained. To capture strategic interaction over time, we develop a
discrete-time fictitious-play algorithm that couples Bayesian belief updates
with empirical best responses. We prove that, as long as the honeypot ratio is
perturbed within a non-degenerate neighbourhood of the optimum, every
fictitious-play path converges to the defender-optimal gamma-PBNE. Numerical
results confirm the effectiveness of the proposed method and demonstrate its
applicability to CPS defense.

</details>


### [127] [Optimal Sensor Scheduling and Selection for Continuous-Discrete Kalman Filtering with Auxiliary Dynamics](https://arxiv.org/abs/2507.11240)
*Mohamad Al Ahdab,John Leth,Zheng-Hua Tan*

Main category: eess.SY

TL;DR: 提出了一种优化CD-KF测量速率和辅助状态动力学的方法，以在资源消耗和估计准确性之间取得更好的平衡。


<details>
  <summary>Details</summary>
Motivation: 本研究的动机在于解决状态空间模型（SSM）中连续离散卡尔曼滤波器（CD-KF）在处理由多个传感器通过离散、不规则计时的测量进行观察的连续时间动力学时的效率问题，特别是在测量过程与辅助SSM的状态耦合的情况下，如测量速率与能源消耗或散热相关，或传感器的精度取决于其自身或目标的空间轨迹。

Method: 我们推导了CD-KF的均值后验协方差矩阵的均值上界，该上界相对于测量速率是连续可微的，并利用该上界提出了一个有限时间最优控制框架，以联合优化测量速率和辅助状态动力学。此外，我们还引入了一种确定性方法，用于从优化速率调度测量时间。

Result: 在状态空间滤波和动态时间高斯过程回归的实证结果中，证明了我们的方法在资源使用和估计准确性之间实现了改进的权衡。

Conclusion: 所提出的优化框架在状态空间滤波和动态时间高斯过程回归的实证结果中，实现了资源使用与估计准确性之间改进的权衡。

Abstract: We study the Continuous-Discrete Kalman Filter (CD-KF) for State-Space Models
(SSMs) where continuous-time dynamics are observed via multiple sensors with
discrete, irregularly timed measurements. Our focus extends to scenarios in
which the measurement process is coupled with the states of an auxiliary SSM.
For instance, higher measurement rates may increase energy consumption or heat
generation, while a sensor's accuracy can depend on its own spatial trajectory
or that of the measured target. Each sensor thus carries distinct costs and
constraints associated with its measurement rate and additional constraints and
costs on the auxiliary state. We model measurement occurrences as independent
Poisson processes with sensor-specific rates and derive an upper bound on the
mean posterior covariance matrix of the CD-KF along the mean auxiliary state.
The bound is continuously differentiable with respect to the measurement rates,
which enables efficient gradient-based optimization. Exploiting this bound, we
propose a finite-horizon optimal control framework to optimize measurement
rates and auxiliary-state dynamics jointly. We further introduce a
deterministic method for scheduling measurement times from the optimized rates.
Empirical results in state-space filtering and dynamic temporal Gaussian
process regression demonstrate that our approach achieves improved trade-offs
between resource usage and estimation accuracy.

</details>


### [128] [Moving Beyond Marginal Carbon Intensity: A Poor Metric for Both Carbon Accounting and Grid Flexibility](https://arxiv.org/abs/2507.11377)
*Philipp Wiesner,Odej Kao*

Main category: eess.SY

TL;DR: MCI在碳感知计算和电网灵活性方面都存在问题，应研究更可行的替代指标。


<details>
  <summary>Details</summary>
Motivation: 讨论了MCI在碳感知计算和激励电网灵活性方面的作用，并指出了其不足之处。

Method: 分析了MCI在碳感知计算中的局限性，包括不可观测性、依赖不透明的预测模型以及缺乏可验证性。

Result: MCI无法反映高碳源造成的削减，也无法提供可用过剩电力的信息。

Conclusion: MCI在碳感知计算和电网灵活性方面都不可靠且不可行。

Abstract: Marginal Carbon Intensity (MCI) has been promoted as an effective metric for
carbon-aware computing. Although it is already considered as impractical for
carbon accounting purposes, many still view it as valuable when optimizing for
grid flexibility by incentivizing electricity usage during curtailment periods.
In this statement paper, we argue that MCI is neither reliable nor actionable
for either purpose. We outline its fundamental limitations, including
non-observability, reliance on opaque predictive models, and the lack of
verifiability. Moreover, MCI fails to reflect curtailment caused by high-carbon
sources and offers no insight into the quantity of available excess power. We
advocate moving beyond MCI and instead call for research on more actionable
metrics, such as direct reporting of excess power, explicit modeling of energy
storage and grid stability, and integration with emerging granular renewable
energy certificate markets.

</details>


### [129] [Inverse Optimal Control with Constraint Relaxation](https://arxiv.org/abs/2507.11392)
*Rahel Rickenbach,Amon Lahr,Melanie N. Zeilinger*

Main category: eess.SY

TL;DR: 在反向最优控制（IOC）中，提出使用精确惩罚函数来处理带噪声演示中的约束激活问题，提高了估计准确性，并减少了未知变量的数量。


<details>
  <summary>Details</summary>
Motivation: 解决在反向最优控制（IOC）中，由于带噪声演示而导致的反向Karush-Kuhn-Tucker方法对约束激活和满足的依赖性问题。

Method: 利用精确惩罚函数处理反向最优控制（IOC）中的约束激活问题，通过减少未知变量和近似方法来提高对错误约束激活的容纳能力。

Result: 在多面体约束环境中，所提出的方法通过精确惩罚函数提高了估计准确性，并减少了未知变量的数量，优于传统的松弛方法。

Conclusion: 该方法通过使用精确惩罚函数克服了在反向最优控制（IOC）中处理带噪声演示中的约束激活问题，提高了估计的准确性，并减少了未知变量的数量，从而在多面体约束环境中表现优于传统松弛方法。

Abstract: Inverse optimal control (IOC) is a promising paradigm for learning and
mimicking optimal control strategies from capable demonstrators, or gaining a
deeper understanding of their intentions, by estimating an unknown objective
function from one or more corresponding optimal control sequences. When
computing estimates from demonstrations in environments with safety-preserving
inequality constraints, acknowledging their presence in the chosen IOC method
is crucial given their strong influence on the final control strategy. However,
solution strategies capable of considering inequality constraints, such as the
inverse Karush-Kuhn-Tucker approach, rely on their correct activation and
fulfillment; a restrictive assumption when dealing with noisy demonstrations.
To overcome this problem, we leverage the concept of exact penalty functions
for IOC and show preservation of estimation accuracy. Considering noisy
demonstrations, we then illustrate how the usage of penalty functions reduces
the number of unknown variables and how their approximations enhance the
estimation method's capacity to account for wrong constraint activations within
a polytopic-constrained environment. The proposed method is evaluated for three
systems in simulation, outperforming traditional relaxation approaches for
noisy demonstrations.

</details>


### [130] [A Risk-Aware Adaptive Robust MPC with Learned Uncertainty Quantification](https://arxiv.org/abs/2507.11420)
*Mingcong Li*

Main category: eess.SY

TL;DR: 提出了一种名为RAAR-MPC的风险感知自适应鲁棒MPC框架，用于解决具有非平稳不确定性的约束最优控制问题。该框架通过学习和自适应策略，在保证约束满足的同时减少了保守性。


<details>
  <summary>Details</summary>
Motivation: 解决受非平稳不确定性影响的约束最优控制问题，克服传统鲁棒MPC的过度保守性和随机MPC在未知不确定性分布下的困难。

Method: RAAR-MPC框架采用分层架构，包括一个中频风险评估引擎（利用高斯过程回归和主动学习构建数据驱动的预测误差集）和一个低时序的自纠正外环（用于更新自适应安全裕度），以实现风险调控。

Result: RAAR-MPC框架在DC-DC转换器基准测试中，相较于最先进的鲁棒和随机MPC策略，实现了目标风险水平，并显著降低了平均成本。

Conclusion: RAAR-MPC框架通过结合学习驱动的风险评估和自适应安全裕度，能够严格满足用户定义的概率约束，同时最小化保守性，并且保证了递归可行性。

Abstract: Solving chance-constrained optimal control problems for systems subject to
non-stationary uncertainties is a significant challenge.Conventional robust
model predictive control (MPC) often yields excessive conservatism by relying
on static worst-case assumptions, while standard stochastic MPC methods
struggle when underlying uncertainty distributions are unknown a priori.This
article presents a Risk-Aware Adaptive Robust MPC (RAAR-MPC) framework,a
hierarchical architecture that systematically orchestrates a novel synthesis of
proactive, learning-based risk assessment and reactive risk regulation. The
framework employs a medium-frequency risk assessment engine, which leverages
Gaussian process regression and active learning, to construct a tight,
data-driven characterization of the prediction error set from operational
data.Concurrently, a low-timescale outer loop implements a self-correcting
update law for an adaptive safety margin to precisely regulate the empirical
risk and compensate for unmodeled dynamics.This dual-timescale adaptation
enables the system to rigorously satisfy chance constraints with a user-defined
probability, while minimizing the conservatism inherent in traditional
approaches.We formally establish that the interplay between these adaptive
components guarantees recursive feasibility and ensures the closed-loop system
satisfies the chance constraints up to a user-defined risk level with high
probability.Numerical experiments on a benchmark DC-DC converter under
non-stationary parametric uncertainties demonstrate that our framework
precisely achieves the target risk level, resulting in a significantly lower
average cost compared to state-of-the-art robust and stochastic MPC strategies.

</details>


<div id='cs.DC'></div>

# cs.DC [[Back]](#toc)

### [131] [FAFO: Over 1 million TPS on a single node running EVM while still Merkleizing every block](https://arxiv.org/abs/2507.10757)
*Ryan Zarick,Isaac Zhang,Daniel Wong,Thomas Kim,Bryan Pellegrino,Mignon Li,Kelvin Wong*

Main category: cs.DC

TL;DR: FAFO 是一种新的区块链交易调度器，通过在区块形成前重排交易来解决数据争用问题，从而实现高吞吐量和并行性。


<details>
  <summary>Details</summary>
Motivation: 解决当前区块链执行吞吐量受数据争用限制、降低执行层并行性的问题。

Method: FAFO 采用 CPU 优化的缓存友好型 Bloom 过滤器来检测冲突并调度并行交易执行，实现了高吞吐量和低开销。

Result: FAFO 在单节点上实现了超过每秒一百一十万笔原生 ETH 交易和超过每秒五十万笔 ERC20 交易，成本比当前分片执行低 91%，并且能够支持轻客户端和基于 ZK 的 vApps 的无状态验证。

Conclusion: FAFO 通过简化的执行层和区块链交易调度器设计创新，证明了支持未来去中心化应用所需的高吞吐量是可行的。

Abstract: Current blockchain execution throughput is limited by data contention,
reducing execution layer parallelism. Fast Ahead-of-Formation Optimization
(FAFO) is the first blockchain transaction scheduler to address this problem by
reordering transactions before block formation for maximum concurrency. FAFO
uses CPU-optimized cache-friendly Bloom filters to efficiently detect conflicts
and schedule parallel transaction execution at high throughput and low
overhead.
  We integrate the Rust EVM client (REVM) into FAFO and achieve over 1.1
million native ETH transfers per second and over half a million ERC20 transfers
per second on a single node (Table 1), with 91% lower cost compared to
state-of-the-art sharded execution. Unlike many other existing high throughput
blockchain execution clients, FAFO uses QMDB to Merkleize world state after
every block, enabling light clients and stateless validation for ZK-based
vApps. FAFO scales with minimal synchronization overhead, scaling linearly with
additional CPU resources until it fully exploits the maximum parallelism of the
underlying transaction flow. FAFO proves that the high throughput necessary to
support future decentralized applications can be achieved with a streamlined
execution layer and innovations in blockchain transaction scheduler design.
FAFO is open-sourced at https://github.com/LayerZero-Labs/fafo.

</details>


### [132] [Dissecting the NVIDIA Blackwell Architecture with Microbenchmarks](https://arxiv.org/abs/2507.10789)
*Aaron Jarmusch,Nathan Graddon,Sunita Chandrasekaran*

Main category: cs.DC

TL;DR: 本研究对NVIDIA Blackwell GPU架构进行了详尽的微架构分析，通过与Hopper架构的对比，揭示了其关键性能特征、代际改进及功耗表现，为开发者提供了优化指导。


<details>
  <summary>Details</summary>
Motivation: 随着科学研究的快速发展，对计算能力的需求日益增长，GPU在满足这一需求方面发挥着关键作用。因此，有必要对现代NVIDIA Blackwell GPU架构进行深入的微架构分析，以了解其性能特征、改进之处以及为优化工作负载提供指导。

Method: 通过精心设计的微基准测试，对NVIDIA Blackwell GPU架构进行了细致的微架构分析，研究了其性能特征，包括延迟、吞吐量、缓存行为和调度细节。将Blackwell架构与Hopper架构进行了对比分析，并评估了功耗效率和能耗。

Result: 研究揭示了Blackwell架构的关键子系统细节，包括内存层次结构、SM执行流水线和SM子核心单元（如第五代Tensor Core）。通过与Hopper架构的对比，评估了代际改进和性能回归。此外，还研究了功耗效率和能耗。研究结果为优化Blackwell平台上的工作负载提供了可操作的见解。

Conclusion: 该研究通过对NVIDIA Blackwell架构进行微基准测试和性能分析，揭示了其关键子系统（包括内存层次结构、SM执行流水线和SM子核心单元，特别是支持FP4和FP6精度的第五代Tensor Core）的细节。通过对比Blackwell与Hopper架构（分别使用GeForce RTX 5080和H100 PCIe），研究评估了代际改进和性能回归，并探讨了功耗效率和能耗。研究结果为Blackwell平台的应用程序开发者、编译器编写者和性能工程师提供了优化工作负载的实用见解，并为GPU架构研究贡献了新的数据。

Abstract: The rapid development in scientific research provides a need for more compute
power, which is partly being solved by GPUs. This paper presents a
microarchitectural analysis of the modern NVIDIA Blackwell architecture by
studying GPU performance
  features with thought through microbenchmarks. We unveil key subsystems,
including the memory hierarchy, SM execution
  pipelines, and the SM sub-core units, including the 5th generation tensor
cores supporting FP4 and FP6 precisions.
  To understand the different key features of the NVIDIA GPU, we study latency,
throughput, cache behavior, and scheduling
  details, revealing subtle tuning metrics in the design of Blackwell. To
develop a comprehensive analysis, we compare the
  Blackwell architecture with the previous Hopper architecture by using the
GeForce RTX 5080 and H100 PCIe, respectively. We
  evaluate and compare results, presenting both generational improvements and
performance regressions. Additionally, we
  investigate the role of power efficiency and energy consumption under varied
workloads. Our findings provide actionable insights
  for application developers, compiler writers, and performance engineers to
optimize workloads on Blackwell-based platforms,
  and contribute new data to the growing research on GPU architectures.

</details>


### [133] [MMStencil: Optimizing High-order Stencils on Multicore CPU using Matrix Unit](https://arxiv.org/abs/2507.11067)
*Yinuo Wang,Tianqi Mao,Lin Gan,Wubing Wan,Zeyu Song,Jiayu Fu,Lanke He,Wenqiang Wang,Zekun Yin,Wei Xue,Guangwen Yang*

Main category: cs.DC

TL;DR: MMStencil optimizes matrix-accelerated stencil computation for 3D high-order stencils and HPC using SIMD, matrix units, and advanced parallelism, achieving significant performance gains.


<details>
  <summary>Details</summary>
Motivation: To explore the underexplored application of matrix-accelerated stencil computation to three-dimensional (3D) high-order stencils and HPC, addressing challenges like strided memory accesses, alignment conflicts, redundant accesses, and data-sharing issues in multicore CPUs with matrix units.

Method: The study analyzes matrix-based acceleration strategies for 3D high-order stencils, introducing algorithmic optimizations (SIMD, matrix units) and memory optimizations. It also proposes a multi-thread parallelism paradigm and DMA-based inter-NUMA communication.

Result: MMStencil achieves high hardware utilization, outperforms state-of-the-art libraries on Nvidia A100 GPGPU by up to 2.1x, and provides 1.8x speedup for RTM applications compared to a highly optimized industrial version.

Conclusion: Matrix-accelerated stencil computation is effective for 3D high-order stencils and HPC, outperforming state-of-the-art libraries and enabling significant speedups in real-world applications like RTM.

Abstract: Matrix-accelerated stencil computation is a hot research topic, yet its
application to three-dimensional (3D) high-order stencils and HPC remains
underexplored. With the emergence of matrix units on multicore CPUs, we analyze
matrix-based acceleration strategies and tailor an optimal approach for 3D
high-order stencils. We introduce algorithmic optimizations based on SIMD and
matrix units to address strided memory accesses, alignment conflicts, and
redundant accesses. We propose memory optimizations to boost on-package memory
efficiency, and a novel multi-thread parallelism paradigm to overcome
data-sharing challenges caused by the absence of shared data caches. MMStencil
sustains consistently high hardware utilization across diverse stencil shapes
and dimensions. Our DMA-based inter-NUMA communication further mitigates NUMA
effects and MPI limitations in hybrid parallelism. Combining all the
innovations, MMStencil outperforms state-of-the-art libraries on Nvidia A100
GPGPU by up to 2.1x. Moreover, the performance improvements translate directly
to real-world HPC applications and enable RTM applications to yield 1.8x
speedup versus a highly optimized industrial Nvidia A100 GPGPU version.

</details>


### [134] [Scaling the memory wall using mixed-precision -- HPG-MxP on an exascale machine](https://arxiv.org/abs/2507.11512)
*Aditya Kashi,Nicholson Koukpaizan,Hao Lu,Michael Matheson,Sarp Oral,Feiyi Wang*

Main category: cs.DC

TL;DR: 混合精度算法可以提升科学计算在HPC上的性能，尤其是在GPU上。通过优化HPG-MxP基准测试，实现了1.6倍的速度提升。


<details>
  <summary>Details</summary>
Motivation: 为了帮助科学计算从AI在HPC平台上的收益中获益，并解决混合精度算法在科学模拟应用中的实际增益不明确的问题。

Method: 通过高度优化的HPG-MxP基准测试实现，并对算法进行了增强。

Result: 在一个exascale系统上实现了HPG-MxP基准测试的高度优化实现，并展示了使用双精度和单精度组合可实现1.6倍的速度提升。

Conclusion: 在现代GPU超级计算机上，通过结合使用双精度和单精度，首次实现了1.6倍的速度提升。

Abstract: Mixed-precision algorithms have been proposed as a way for scientific
computing to benefit from some of the gains seen for artificial intelligence
(AI) on recent high performance computing (HPC) platforms. A few applications
dominated by dense matrix operations have seen substantial speedups by
utilizing low precision formats such as FP16. However, a majority of scientific
simulation applications are memory bandwidth limited. Beyond preliminary
studies, the practical gain from using mixed-precision algorithms on a given
HPC system is largely unclear.
  The High Performance GMRES Mixed Precision (HPG-MxP) benchmark has been
proposed to measure the useful performance of a HPC system on sparse
matrix-based mixed-precision applications. In this work, we present a highly
optimized implementation of the HPG-MxP benchmark for an exascale system and
describe our algorithm enhancements. We show for the first time a speedup of
1.6x using a combination of double- and single-precision on modern GPU-based
supercomputers.

</details>


### [135] [Generating Dynamic Graph Algorithms for Multiple Backends for a Graph DSL](https://arxiv.org/abs/2507.11094)
*Nibedita Behera,Ashwina Kumar,Atharva Chougule,Mohammed Shan P S,Rushabh Nirdosh Lalwani,Rupesh Nasre*

Main category: cs.DC

TL;DR: 该研究通过DSL简化了动态图的并行编程，提高了处理效率。


<details>
  <summary>Details</summary>
Motivation: 现有的图处理框架在处理动态图（图结构随时间变化）方面存在局限性，尤其是在生成高效且同步正确的代码方面仍然是一个重大挑战。

Method: 提出了一种抽象方案和运行时优化，利用领域特定语言（DSL）来表达动态图处理逻辑，并自动生成可并行执行的代码。

Result: 通过将DSL生成的代码应用于十个具有不同特征的大型图和三种常用算法（最短路径、PageRank和三角形计数），证明了该方法的有效性。

Conclusion: 该研究提出了一个用于高效处理动态图的抽象方案和运行时优化，通过领域特定语言（DSL）自动生成并行代码，并在多核、分布式和众核环境中进行了测试。

Abstract: With the rapid growth of unstructured and semistructured data, parallelizing
graph algorithms has become essential for efficiency. However, due to the
inherent irregularity in computation, memory access patterns, and
communication, graph algorithms are notoriously difficult to parallelize. To
address this challenge, several libraries, frameworks, and domain-specific
languages (DSLs) have been proposed to ease the parallel programming burden for
domain experts. Existing frameworks partially or fully abstract away
parallelism intricacies, provide intuitive scheduling mnemonics, and employ
program analysis to identify data races and generate synchronization code.
Despite these advances, most frameworks are limited in their abstractions and
runtime optimizations, especially when dealing with static graphs. In contrast,
many real-world graphs are inherently dynamic, with evolving structures over
time through insertions, deletions, and modifications of vertices, edges, and
attributes. Generating efficient and correctly synchronized code for such
dynamic graph algorithms remains a significant challenge.
  In this work, we introduce an abstraction scheme and runtime optimizations
for the efficient processing of morph algorithms. Specifically, given an
initial graph G and a set of updates $\Delta$G involving edge insertions and
deletions, we express the dynamic processing logic through a DSL and
automatically generate parallel code targeting multicore, distributed, and
many-core environments. We demonstrate the effectiveness of our approach by
applying the DSL-generated code to ten large graphs with diverse
characteristics and three widely used algorithms: Shortest Paths, PageRank, and
Triangle Counting.

</details>


### [136] [Boosting Scientific Error-Bounded Lossy Compression through Optimized Synergistic Lossy-Lossless Orchestration](https://arxiv.org/abs/2507.11165)
*Shixun Wu,Jinwen Pan,Jinyang Liu,Jiannan Tian,Ziwei Qiu,Jiajun Huang,Kai Zhao,Xin Liang,Sheng Di,Zizhong Chen,Franck Cappello*

Main category: cs.DC

TL;DR: cuSZ-Hi 是一种新的 GPU 压缩器，在科学数据压缩方面表现出色。


<details>
  <summary>Details</summary>
Motivation: 随着高性能计算架构的不断发展，越来越多的科学计算工作流被部署到 GPU 等先进计算平台上。这些工作流能以极高的吞吐量产生原始数据，因此迫切需要高压缩比、低延迟的误差有界数据压缩解决方案。

Method: cuSZ-Hi 是一种优化的、基于 GPU 的、高压缩比的科学误差有界有损压缩器，其框架设计灵活、与域无关且完全开源。其创新之处在于：1）最大化优化了基于 GPU 的并行化插值数据预测方案，使其能够适应多样化的数据特征；2）深入探索和研究了无损数据编码技术，并整合了最适合的无损编码流程以最大化 cuSZ-Hi 的压缩率；3）系统地在基准数据集上与代表性基线进行了评估。

Result: 与现有的科学有损压缩器相比，cuSZ-Hi 在 GPU 上的吞吐量与现有高压缩比的科学误差有界有损压缩器相当或更优，同时在相同的误差范围内可实现高达 249% 的压缩率提升，在相同的解压数据 PSNR 下可实现高达 215% 的压缩率提升。

Conclusion: cuSZ-Hi 在相同的误差范围内可实现高达 249% 的压缩率提升，在相同的解压数据 PSNR 下可实现高达 215% 的压缩率提升。

Abstract: As high-performance computing architectures evolve, more scientific computing
workflows are being deployed on advanced computing platforms such as GPUs.
These workflows can produce raw data at extremely high throughputs, requiring
urgent high-ratio and low-latency error-bounded data compression solutions. In
this paper, we propose cuSZ-Hi, an optimized high-ratio GPU-based scientific
error-bounded lossy compressor with a flexible, domain-irrelevant, and fully
open-source framework design. Our novel contributions are: 1) We maximally
optimize the parallelized interpolation-based data prediction scheme on GPUs,
enabling the full functionalities of interpolation-based scientific data
prediction that are adaptive to diverse data characteristics; 2) We thoroughly
explore and investigate lossless data encoding techniques, then craft and
incorporate the best-fit lossless encoding pipelines for maximizing the
compression ratio of cuSZ-Hi; 3) We systematically evaluate cuSZ-Hi on
benchmarking datasets together with representative baselines. Compared to
existing state-of-the-art scientific lossy compressors, with comparative or
better throughput than existing high-ratio scientific error-bounded lossy
compressors on GPUs, cuSZ-Hi can achieve up to 249% compression ratio
improvement under the same error bound, and up to 215% compression ratio
improvement under the same decompression data PSNR.

</details>


### [137] [Cyclic Data Streaming on GPUs for Short Range Stencils Applied to Molecular Dynamics](https://arxiv.org/abs/2507.11289)
*Martin Rose,Simon Homes,Lukas Ramsperger,Jose Gracia,Christoph Niethammer,Jadran Vrabec*

Main category: cs.DC

TL;DR: 我们提出了一个创新的 GPU 通信框架，在科学计算中实现线性性能扩展，并优于 LAMMPS。


<details>
  <summary>Details</summary>
Motivation: 为了在科学计算中获得最高性能。

Method: 提出了一种依赖于计算集群中 GPU 之间高带宽通信的新颖框架。数据集的切片在进程（GPU）的环中传播，从一个 GPU 传播到下一个 GPU，实现了时序并行化。

Result: 该框架为显式算法提供了线性的性能扩展，该性能扩展仅受数据集大小和 GPU 数量的限制。作为案例研究，实现了基于 Lennard-Jones 势的分子动力学模拟，以测量均质流体的性能。

Conclusion: 该框架在强扩展情况下优于 LAMMPS。

Abstract: In the quest for highest performance in scientific computing, we present a
novel framework that relies on high-bandwidth communication between GPUs in a
compute cluster. The framework offers linear scaling of performance for
explicit algorithms that is only limited by the size of the dataset and the
number of GPUs. Slices of the dataset propagate in a ring of processes (GPUs)
from one GPU, where they are processed, to the next, which results in a
parallel-in-time parallelization. The user of the framework has to write GPU
kernels that implement the algorithm and provide slices of the dataset.
Knowledge about the underlying parallelization strategy is not required because
the communication between processes is carried out by the framework. As a case
study, molecular dynamics simulation based on the Lennard-Jones potential is
implemented to measure the performance for a homogeneous fluid. Single node
performance and strong scaling behavior of this framework is compared to
LAMMPS, which is outperformed in the strong scaling case.

</details>


### [138] [A new Dune grid for scalable dynamic adaptivity based on the p4est software library](https://arxiv.org/abs/2507.11386)
*Carsten Burstedde,Mikhail Kirilin,Robert Klöfkorn*

Main category: cs.DC

TL;DR: 将 p4est 集成到 Dune 中，以提高 MPI 可扩展性，并在网格平衡方面取得了改进。


<details>
  <summary>Details</summary>
Motivation: 继承 p4est 几乎无限的 MPI 可扩展性、相对较thin的数据结构以及对 2D 和 3D 中多块（森林）网格拓扑的原生支持。

Method: 将 p4est 的网格接口添加到 Dune 求解器库，并与现有的 Dune-ALUGrid 实现进行了比较。

Result: 在可扩展性方面，新实现优于 Dune-ALUGrid。提出的替代平衡策略在数值示例中也显示出比现有 p4est 平衡策略更好的性能。

Conclusion: 该实现优于 Dune-ALUGrid，在可扩展性方面表现更好。此外，还提出了一种替代的平衡策略，以确保跨单元面的 2:1 平衡，与现有的 p4est 平衡策略相比，在所考虑的数值示例中具有更好的性能。

Abstract: In this work we extend the Dune solver library with another grid interface to
the open-source p4est software. While Dune already supports about a dozen
different mesh implementations through its mesh interface Dune-Grid, we
undertake this new coupling effort in order to inherit p4est's practically
unlimited MPI scalability as well as its relatively thin data structures, and
its native support for multi-block (forest) mesh topologies in both 2D and 3D.
  The presented implementation is compared to an existing implementation based
on Dune-ALUGrid for a variety of challenging test examples in a parallel
environment. The numerical experiments show that the implementation presented
here is outperforming Dune-ALUGrid in terms of scalability. In addition, an
alternative balancing strategy is presented to ensure 2:1 balancing across
element faces showing improved performance compared to the existing p4est
balance strategy in the numerical examples considered in this work.

</details>


### [139] [Quantifying the Energy Consumption and Carbon Emissions of LLM Inference via Simulations](https://arxiv.org/abs/2507.11417)
*Miray Özcan,Philipp Wiesner,Philipp Weiß,Odej Kao*

Main category: cs.DC

TL;DR: LLM 推理的碳排放正在增加，但现有模拟框架无法准确估算。我们提出了一个包含 GPU 功耗模型和能源系统联合仿真环境的框架，用于评估 LLM 推理的能源和碳影响，并展示了碳感知调度的潜力。


<details>
  <summary>Details</summary>
Motivation: 现有 LLM 部署的仿真框架缺乏对功耗的考量，无法准确估算推理相关的排放，而推理占 LLM 生命周期碳排放的一半以上。

Method: 提出了一个包含 GPU 功耗模型和能源系统联合仿真环境的仿真框架，用于评估 LLM 推理在不同部署设置下的能源和碳影响。

Result: 该框架能够分析不同配置（如批处理大小、序列长度和模型并行性）对能源需求和碳足迹的影响。

Conclusion: 该框架为未来碳感知推理基础设施的设计奠定了基础，并展示了在说明性部署案例中高达 69.2% 的可再生能源抵消潜力。

Abstract: The environmental impact of Large Language Models (LLMs) is rising
significantly, with inference now accounting for more than half of their total
lifecycle carbon emissions. However, existing simulation frameworks, which are
increasingly used to determine efficient LLM deployments, lack any concept of
power and, therefore, cannot accurately estimate inference-related emissions.
We present a simulation framework to assess the energy and carbon implications
of LLM inference under varying deployment setups. First, we extend a
high-fidelity LLM inference simulator with a GPU power model that estimates
power consumption based on utilization metrics, enabling analysis across
configurations like batch size, sequence length, and model parallelism. Second,
we integrate simulation outputs into an energy system co-simulation environment
to quantify carbon emissions under specific grid conditions and explore the
potential of carbon-aware scheduling. Through scenario-based analysis, our
framework reveals how inference parameters affect energy demand and carbon
footprint, demonstrates a renewable offset potential of up to 69.2% in an
illustrative deployment case, and provides a foundation for future carbon-aware
inference infrastructure design.

</details>


### [140] [FLsim: A Modular and Library-Agnostic Simulation Framework for Federated Learning](https://arxiv.org/abs/2507.11430)
*Arnab Mukherjee,Raju Halder,Joydeep Chandra*

Main category: cs.DC

TL;DR: FLsim 是一个灵活、可扩展且易于使用的联邦学习模拟框架，支持定制化数据、算法、网络拓扑和聚合策略，并可集成区块链，有助于简化联邦学习的研究和基准测试。


<details>
  <summary>Details</summary>
Motivation: 现有的联邦学习（FL）研究和新 FL 技术与众多既有最先进解决方案的基准测试仍然充满挑战。为了简化这一过程，需要一个能够满足文献中各种 FL 工作流需求的综合性 FL 模拟框架。

Method: 介绍了一个名为 FLsim 的综合性联邦学习（FL）模拟框架，该框架具有模块化、可扩展、资源效率高以及实验结果可控可复现等特点。FLsim 的用户界面允许用户通过作业配置指定定制化的 FL 需求，支持定制化的数据分布（从非独立同分布到独立同分布）、支持用户选择本地学习算法（不依赖于特定的机器学习库）、支持选择网络拓扑以说明节点间的通信模式、支持定义模型聚合与共识算法，并支持可插入的区块链技术以增强鲁棒性。

Result: 通过一系列实验评估，证明了 FLsim 在模拟各种最先进的联邦学习实验方面的有效性和多功能性。

Conclusion: FLsim 框架能够有效模拟各种最先进的联邦学习实验，提供了前所未有的灵活性和功能，有望成为联邦学习模拟框架的重大进步。

Abstract: Federated Learning (FL) has undergone significant development since its
inception in 2016, advancing from basic algorithms to complex methodologies
tailored to address diverse challenges and use cases. However, research and
benchmarking of novel FL techniques against a plethora of established
state-of-the-art solutions remain challenging. To streamline this process, we
introduce FLsim, a comprehensive FL simulation framework designed to meet the
diverse requirements of FL workflows in the literature. FLsim is characterized
by its modularity, scalability, resource efficiency, and controlled
reproducibility of experimental outcomes. Its easy to use interface allows
users to specify customized FL requirements through job configuration, which
supports: (a) customized data distributions, ranging from non-independent and
identically distributed (non-iid) data to independent and identically
distributed (iid) data, (b) selection of local learning algorithms according to
user preferences, with complete agnosticism to ML libraries, (c) choice of
network topology illustrating communication patterns among nodes, (d)
definition of model aggregation and consensus algorithms, and (e) pluggable
blockchain support for enhanced robustness. Through a series of experimental
evaluations, we demonstrate the effectiveness and versatility of FLsim in
simulating a diverse range of state-of-the-art FL experiments. We envisage that
FLsim would mark a significant advancement in FL simulation frameworks,
offering unprecedented flexibility and functionality for researchers and
practitioners alike.

</details>


### [141] [Uniting the World by Dividing it: Federated Maps to Enable Spatial Applications](https://arxiv.org/abs/2507.11437)
*Sagar Bharadwaj,Srinivasan Seshan,Anthony Rowe*

Main category: cs.DC

TL;DR: 空间Web需要一个去中心化的地图系统，以支持AR等应用，现有地图服务存在局限。本文提出联邦制空间命名系统，以解决这些问题。


<details>
  <summary>Details</summary>
Motivation: 现有中心化地图服务（如谷歌地图、苹果地图）无法满足新兴应用（如AR、室内地图）的需求，它们在规模、隐私和覆盖范围上存在局限。

Method: 提出一个联邦制空间命名系统，允许不同方管理和提供各自的地图数据，并探讨了实现这一系统所需的服务和实际问题。

Result: 论证了联邦制空间命名系统的可行性，该系统能提高地图管理的扩展性、隔离性和隐私性，并为地址解析、位置搜索和路由等服务提供了新的思路。

Conclusion: 未来需要一个联邦制空间命名系统来支持地理空间Web，解决现有中心化地图服务在规模、隐私和覆盖范围上的不足。

Abstract: The emergence of the Spatial Web -- the Web where content is tied to
real-world locations has the potential to improve and enable many applications
such as augmented reality, navigation, robotics, and more. The Spatial Web is
missing a key ingredient that is impeding its growth -- a spatial naming system
to resolve real-world locations to names. Today's spatial naming systems are
digital maps such as Google and Apple maps. These maps and the location-based
services provided on top of these maps are primarily controlled by a few large
corporations and mostly cover outdoor public spaces. Emerging classes of
applications, such as persistent world-scale augmented reality, require
detailed maps of both outdoor and indoor spaces. Existing centralized mapping
infrastructures are proving insufficient for such applications because of the
scale of cartography efforts required and the privacy of indoor map data.
  In this paper, we present a case for a federated spatial naming system, or in
other words, a federated mapping infrastructure. This enables disparate parties
to manage and serve their own maps of physical regions and unlocks scalability
of map management, isolation and privacy of maps. Map-related services such as
address-to-location mapping, location-based search, and routing needs
re-architecting to work on federated maps. We discuss some essential services
and practicalities of enabling these services.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [142] [Tool-to-Tool Matching Analysis Based Difference Score Computation Methods for Semiconductor Manufacturing](https://arxiv.org/abs/2507.10564)
*Sameera Bharadwaja H.,Siddhrath Jandial,Shashank S. Agashe,Rajesh Kumar Reddy Moore,Youngkwan Kim*

Main category: cs.LG

TL;DR: Novel TTTM methods using univariate and multivariate analysis are proposed to overcome limitations of traditional approaches in semiconductor manufacturing, showing effective results with high correlations and analyzing hyper-parameter sensitivity.


<details>
  <summary>Details</summary>
Motivation: Traditional TTTM approaches struggle with static configurations, the lack of a golden reference in commercial manufacturing, and heterogeneity in equipment make-and-model and vendors. The proposed methods aim to overcome these limitations.

Method: Novel TTTM analysis pipelines are proposed, utilizing univariate and multivariate approaches to analyze semiconductor manufacturing equipment data. The univariate methods correlate with variance and number of modes, while the multivariate methods build upon the univariate approaches.

Result: The best univariate method achieves a correlation coefficient >0.95 with variance and >0.5 with the number of modes. The best multivariate method achieves a correlation coefficient >0.75 with the top-performing univariate methods. Algorithm sensitivity to hyper-parameters is also analyzed.

Conclusion: The proposed TTTM analysis pipelines effectively overcome the limitations of traditional methods by addressing issues related to static configurations, golden references, and heterogeneous equipment settings. The methods show strong correlations with variance and number of modes, demonstrating their effectiveness.

Abstract: We consider the problem of tool-to-tool matching (TTTM), also called, chamber
matching in the context of a semiconductor manufacturing equipment. Traditional
TTTM approaches utilize static configuration data or depend on a golden
reference which are difficult to obtain in a commercial manufacturing line.
Further, existing methods do not extend very well to a heterogeneous setting,
where equipment are of different make-and-model, sourced from different
equipment vendors. We propose novel TTTM analysis pipelines to overcome these
issues. We hypothesize that a mismatched equipment would have higher variance
and/or higher number of modes in the data. Our best univariate method achieves
a correlation coefficient >0.95 and >0.5 with the variance and number of modes,
respectively showing that the proposed methods are effective. Also, the best
multivariate method achieves a correlation coefficient >0.75 with the
top-performing univariate methods, showing its effectiveness. Finally, we
analyze the sensitivity of the multivariate algorithms to the algorithm
hyper-parameters.

</details>


### [143] [GALDS: A Graph-Autoencoder-based Latent Dynamics Surrogate model to predict neurite material transport](https://arxiv.org/abs/2507.10871)
*Tsung Yeh Hsieh,Yongjie Jessica Zhang*

Main category: cs.LG

TL;DR: GALDS模型通过图自编码器和神经ODE，在加速和提高神经元物质运输模拟精度的同时，降低了数据和计算需求。


<details>
  <summary>Details</summary>
Motivation: 为了应对神经元网络中物质运输模拟的计算挑战，传统方法耗时且资源消耗大。神经元树的固有特性（主要是具有稳态抛物线速度剖面和分叉的管道）为计算优化提供了机会。

Method: 提出了一种基于图自编码器的潜在动力学代理模型（GALDS），利用图自编码器对网络几何、速度场和浓度分布进行编码，并通过图潜在空间系统动力学模型（受神经ODE启发）预测系统动力学，以简化神经元树中物质运输的模拟。

Result: GALDS模型实现了3%的平均相对误差和低于8%的最大相对误差，并且与之前的代理模型方法相比，速度提高了10倍。

Conclusion: GALDS模型在模拟神经元网络中的物质运输方面表现出色，能在8个未见过的几何结构和4个异常运输示例上，实现3%的平均相对误差和低于8%的最大相对误差，同时将速度提高了10倍。

Abstract: Neurons exhibit intricate geometries within their neurite networks, which
play a crucial role in processes such as signaling and nutrient transport.
Accurate simulation of material transport in the networks is essential for
understanding these biological phenomena but poses significant computational
challenges because of the complex tree-like structures involved. Traditional
approaches are time-intensive and resource-demanding, yet the inherent
properties of neuron trees, which consists primarily of pipes with steady-state
parabolic velocity profiles and bifurcations, provide opportunities for
computational optimization. To address these challenges, we propose a
Graph-Autoencoder-based Latent Dynamics Surrogate (GALDS) model, which is
specifically designed to streamline the simulation of material transport in
neural trees. GALDS employs a graph autoencoder to encode latent
representations of the network's geometry, velocity fields, and concentration
profiles. These latent space representations are then assembled into a global
graph, which is subsequently used to predict system dynamics in the latent
space via a trained graph latent space system dynamic model, inspired by the
Neural Ordinary Differential Equations (Neural ODEs) concept. The integration
of an autoencoder allows for the use of smaller graph neural network models
with reduced training data requirements. Furthermore, the Neural ODE component
effectively mitigates the issue of error accumulation commonly encountered in
recurrent neural networks. The effectiveness of the GALDS model is demonstrated
through results on eight unseen geometries and four abnormal transport
examples, where our approach achieves mean relative error of 3% with maximum
relative error <8% and demonstrates a 10-fold speed improvement compared to
previous surrogate model approaches.

</details>


### [144] [Enhancing Cross Entropy with a Linearly Adaptive Loss Function for Optimized Classification Performance](https://arxiv.org/abs/2507.10574)
*Jae Wan Shim*

Main category: cs.LG

TL;DR: 提出了一种新的损失函数——线性自适应交叉熵损失函数，它通过增加一个项来改进优化过程，并在实验中显示出比标准交叉熵损失更高的准确性和相当的效率。


<details>
  <summary>Details</summary>
Motivation: 为了提高包含独热编码类别标签的分类任务的优化过程。

Method: 提出了一种源自信息论的新型度量方法——线性自适应交叉熵损失函数，该函数在标准交叉熵损失函数的基础上增加了一个依赖于真实类别预测概率的项，以增强包含独热编码类别标签的分类任务的优化过程。

Result: 在基于ResNet的模型和CIFAR-100数据集上，所提出的方法在分类准确性方面持续优于标准的交叉熵损失函数，并且在效率上与传统的交叉熵损失基本相当。

Conclusion: 该方法可以拓宽未来损失函数设计的范围。

Abstract: We propose the Linearly Adaptive Cross Entropy Loss function. This is a novel
measure derived from the information theory. In comparison to the standard
cross entropy loss function, the proposed one has an additional term that
depends on the predicted probability of the true class. This feature serves to
enhance the optimization process in classification tasks involving one-hot
encoded class labels. The proposed one has been evaluated on a ResNet-based
model using the CIFAR-100 dataset. Preliminary results show that the proposed
one consistently outperforms the standard cross entropy loss function in terms
of classification accuracy. Moreover, the proposed one maintains simplicity,
achieving practically the same efficiency to the traditional cross entropy
loss. These findings suggest that our approach could broaden the scope for
future research into loss function design.

</details>


### [145] [An Adaptive Volatility-based Learning Rate Scheduler](https://arxiv.org/abs/2507.10575)
*Kieran Chai Kai Ren*

Main category: cs.LG

TL;DR: VolSched 是一种新的学习率调度器，通过分析准确性波动率来动态调整学习率，以提高深度学习模型的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 有效的学习率（LR）调度对于训练深度神经网络至关重要，但现有的调度器可能导致泛化能力不足。

Method: VolSched 通过计算准确性波动率来动态调整学习率，提高 LR 以跳出平台期，降低 LR 以稳定训练。

Result: VolSched 在 CIFAR-100 数据集上与 ResNet-18 和 ResNet-34 结合使用时，一致地提高了 top-1 准确率，并找到了比次优基线平坦 38% 的最终解决方案，表明其泛化能力得到提升。

Conclusion: VolSched 是一种新颖的自适应学习率调度器，通过计算长期和短期准确性波动率之间的比率来动态调整学习率，提高了模型的泛化能力。与 ResNet-18 和 ResNet-34 结合使用时，VolSched 分别提高了 1.4% 和 1.3% 的 top-1 准确率，并找到了比次优基线平坦 38% 的最终解决方案。

Abstract: Effective learning rate (LR) scheduling is crucial for training deep neural
networks. However, popular pre-defined and adaptive schedulers can still lead
to suboptimal generalization. This paper introduces VolSched, a novel adaptive
LR scheduler inspired by the concept of volatility in stochastic processes like
Geometric Brownian Motion to dynamically adjust the learning rate. By
calculating the ratio between long-term and short-term accuracy volatility,
VolSched increases the LR to escape plateaus and decreases it to stabilize
training, allowing the model to explore the loss landscape more effectively. We
evaluate VolSched on the CIFAR-100 dataset against a strong baseline using a
standard augmentation pipeline. When paired with ResNet-18 and ResNet-34, our
scheduler delivers consistent performance gains, improving top-1 accuracy by
1.4 and 1.3 percentage points respectively. Analysis of the loss curves reveals
that VolSched promotes a longer exploration phase. A quantitative analysis of
the Hessian shows that VolSched finds a final solution that is 38% flatter than
the next-best baseline, allowing the model to obtain wider minima and hence
better generalization performance.

</details>


### [146] [Universal Approximation Theorem for a Single-Layer Transformer](https://arxiv.org/abs/2507.10581)
*Esmail Gumaan*

Main category: cs.LG

TL;DR: 本篇论文研究了深度学习和Transformer的理论基础，证明了单层Transformer模型可以近似任意连续序列到序列映射。


<details>
  <summary>Details</summary>
Motivation: 尽管Transformer模型在自然语言处理等领域取得了巨大成功，但对其理论理解仍然有限。本研究旨在通过检验其数学基础并提出新的理论结果来增进对这些模型的理解。

Method: 本文研究了深度学习和Transformer的数学基础，包括线性代数、概率和优化中的关键概念，并详细分析了多头自注意力机制和反向传播算法。核心贡献是证明了单层Transformer（包含一个自注意力层和一个带ReLU激活的逐位置前馈网络）可以任意精度地近似紧域上的任何连续序列到序列映射。

Result: 我们证明了一个适用于Transformer的通用近似定理：单层Transformer可以近似任意的连续序列到序列映射。

Conclusion: 本研究提出了一种新的理论结果，即单层Transformer可以近似任意的连续序列到序列映射，这在理论上加深了对Transformer模型的理解，并有助于缩小理论与实践之间的差距。

Abstract: Deep learning employs multi-layer neural networks trained via the
backpropagation algorithm. This approach has achieved success across many
domains and relies on adaptive gradient methods such as the Adam optimizer.
Sequence modeling evolved from recurrent neural networks to attention-based
models, culminating in the Transformer architecture. Transformers have achieved
state-of-the-art performance in natural language processing (for example, BERT
and GPT-3) and have been applied in computer vision and computational biology.
However, theoretical understanding of these models remains limited. In this
paper, we examine the mathematical foundations of deep learning and
Transformers and present a novel theoretical result. We review key concepts
from linear algebra, probability, and optimization that underpin deep learning,
and we analyze the multi-head self-attention mechanism and the backpropagation
algorithm in detail. Our main contribution is a universal approximation theorem
for Transformers: we prove that a single-layer Transformer, comprising one
self-attention layer followed by a position-wise feed-forward network with ReLU
activation, can approximate any continuous sequence-to-sequence mapping on a
compact domain to arbitrary precision. We provide a formal statement and a
complete proof. Finally, we present case studies that demonstrate the practical
implications of this result. Our findings advance the theoretical understanding
of Transformer models and help bridge the gap between theory and practice.

</details>


### [147] [Step-wise Policy for Rare-tool Knowledge (SPaRK): Offline RL that Drives Diverse Tool Use in LLMs](https://arxiv.org/abs/2507.11371)
*Gabriel Bo,Koa Chang,Justin Gu*

Main category: cs.LG

TL;DR: SPaRK：一种通过优化工具多样性来提升大型语言模型推理能力的强化学习框架。


<details>
  <summary>Details</summary>
Motivation: 为了让大型语言模型能够利用多样化的工具使用模式，并超越传统的高温采样方法，探索更广泛的工具使用策略。

Method: 提出了一种名为 SPaRK（Step-wise Policy for Rare-tool Knowledge）的新型强化学习框架。该框架基于逐步强化学习，引入了双目标奖励系统，同时优化答案质量和工具多样性。通过在合成生成的数据集 MMLU-Pro 上使用离线 PPO 训练 Llama-3.1 8B 模型。其独特之处在于采用“稀有性优先”策略，并使用 GPT-4o 作为裁判来评估跨越八种不同工具和链式思考的候选动作，鼓励模型探索较少使用的工具。

Result: SPaRK 在 14 个 MMLU-Pro 类别上取得了有竞争力的性能，同时在工具选择方面表现出比基线和监督微调方法明显更高的熵。这表明通过明确的工具多样性进行的算法探索可以提高推理能力，同时不牺牲准确性。

Conclusion: SPaRK 框架通过优先考虑稀有但可行的工具，并在奖励系统中同时优化答案质量和工具多样性，实现了具有竞争力的性能和更高的工具选择熵，有效提升了大型语言模型的推理能力，且不牺牲准确性。

Abstract: We present Step-wise Policy for Rare-tool Knowledge (SPaRK), a novel
reinforcement learning framework that teaches large language models to explore
diverse tool usage patterns beyond conventional high-temperature sampling.
Building on recent advances in step-wise reinforcement learning, we introduce a
dual-objective reward system that simultaneously optimizes for answer quality
and tool diversity, training a Llama-3.1 8B model through offline PPO on
synthetically generated trajectories from the MMLU-Pro dataset. Our approach
uniquely employs a rarity-first exploitation strategy where a GPT-4o judge
scores candidate actions across eight distinct tools plus chain-of-thought
reasoning, with the policy favoring less-frequently used but still viable tools
to encourage systematic exploration. Empirical results demonstrate that SPaRK
achieves competitive performance across 14 MMLU-Pro categories while exhibiting
significantly higher entropy in tool selection compared to both baseline and
supervised fine-tuning approaches, suggesting that algorithmic exploration
through explicit tool diversity can enhance reasoning capabilities without
sacrificing accuracy.

</details>


### [148] [MH-FSF: A Unified Framework for Overcoming Benchmarking and Reproducibility Limitations in Feature Selection Evaluation](https://arxiv.org/abs/2507.10591)
*Vanderson Rocha,Diego Kreutz,Gabriel Canto,Hendrio Bragança,Eduardo Feitosa*

Main category: cs.LG

TL;DR: MH-FSF框架通过在10个公开的Android恶意软件数据集上实现17种特征选择方法，解决了当前研究在基准测试和可重复性方面的局限性，并强调了数据预处理和处理数据集不对称性的重要性。


<details>
  <summary>Details</summary>
Motivation: 当前研究在基准测试和专有数据集方面存在局限性，阻碍了可重复性并可能影响整体性能。为了解决这些问题，我们引入了MH-FSF框架，以促进特征选择方法的再现和实现。

Method: MH-FSF框架，一个全面、模块化和可扩展的平台，实现了17种方法（11种经典、6种领域特定），并在10个公开的Android恶意软件数据集上进行了系统评估。

Result: 在平衡和不平衡数据集上都发现了性能差异，凸显了数据预处理和考虑这些不对称性的选择标准至关重要。

Conclusion: MH-FSF提供了一个统一的平台，用于比较各种特征选择技术，促进了方法的一致性和严谨性，有望拓宽现有文献并为特征选择新研究方向铺平道路，特别是在Android恶意软件检测方面。

Abstract: Feature selection is vital for building effective predictive models, as it
reduces dimensionality and emphasizes key features. However, current research
often suffers from limited benchmarking and reliance on proprietary datasets.
This severely hinders reproducibility and can negatively impact overall
performance. To address these limitations, we introduce the MH-FSF framework, a
comprehensive, modular, and extensible platform designed to facilitate the
reproduction and implementation of feature selection methods. Developed through
collaborative research, MH-FSF provides implementations of 17 methods (11
classical, 6 domain-specific) and enables systematic evaluation on 10 publicly
available Android malware datasets. Our results reveal performance variations
across both balanced and imbalanced datasets, highlighting the critical need
for data preprocessing and selection criteria that account for these
asymmetries. We demonstrate the importance of a unified platform for comparing
diverse feature selection techniques, fostering methodological consistency and
rigor. By providing this framework, we aim to significantly broaden the
existing literature and pave the way for new research directions in feature
selection, particularly within the context of Android malware detection.

</details>


### [149] [Extension OL-MDISF: Online Learning from Mix-Typed, Drifted, and Incomplete Streaming Features](https://arxiv.org/abs/2507.10594)
*Shengda Zhuo,Di Wu,Yi He,Shuqiang Huang,Xindong Wu*

Main category: cs.LG

TL;DR: This paper introduces OL-MDISF, a novel framework for online learning that tackles heterogeneous, drifting, and incompletely labeled data streams using copula-based representations, ensemble entropy for drift detection, and pseudo-labeling. It offers a reproducible benchmark for complex online learning scenarios.


<details>
  <summary>Details</summary>
Motivation: The paper addresses three significant challenges in online learning: data heterogeneity with mixed feature types, performance decline due to data stream distribution shifts (drifts), and the infeasibility of labeling every data instance due to time and cost constraints.

Method: The proposed OL-MDISF (Online Learning from Mix-typed, Drifted, and Incomplete Streaming Features) framework utilizes a latent copula-based representation for heterogeneous features, employs ensemble entropy and latent mismatch for drift detection, and incorporates structure-aware pseudo-labeling to handle data stream challenges.

Result: This companion paper serves as a technical reference for OL-MDISF, including a discussion of related work and a comprehensive set of experiments on 14 real-world datasets under two drift scenarios, featuring CER trends, ablation studies, sensitivity analyses, and temporal ensemble dynamics.

Conclusion: The paper provides a reproducible benchmark for online learning on complex, weakly supervised streaming data, detailing the OL-MDISF framework which addresses data heterogeneity, distribution shifts, and labeling constraints through latent copula-based representation, ensemble entropy and latent mismatch for drift detection, and structure-aware pseudo-labeling.

Abstract: Online learning, where feature spaces can change over time, offers a flexible
learning paradigm that has attracted considerable attention. However, it still
faces three significant challenges. First, the heterogeneity of real-world data
streams with mixed feature types presents challenges for traditional parametric
modeling. Second, data stream distributions can shift over time, causing an
abrupt and substantial decline in model performance. Third, it is often
infeasible to label every data instance due to time and cost constraints. To
address these issues, we proposed OL-MDISF (Online Learning from Mix-typed,
Drifted, and Incomplete Streaming Features), which constructs a latent
copula-based representation for heterogeneous features, detects drifts via
ensemble entropy and latent mismatch, and performs structure-aware
pseudo-labeling.
  This companion paper serves as a standalone technical reference to OL-MDISF.
It provides a contextual discussion of related work in mixed-type modeling,
drift adaptation, and weak supervision, as well as a comprehensive set of
experiments across 14 real-world datasets under two types of drift scenarios.
These include CER trends, ablation studies, sensitivity analyses, and temporal
ensemble dynamics. We hope this document offers a reproducible benchmark for
online learning on complex, weakly supervised streaming data.

</details>


### [150] [Divide-Then-Rule: A Cluster-Driven Hierarchical Interpolator for Attribute-Missing Graphs](https://arxiv.org/abs/2507.10595)
*Yaowen Hu,Wenxuan Tu,Yue Liu,Miaomiao Li,Wenpeng Lu,Zhigang Luo,Xinwang Liu,Ping Chen*

Main category: cs.LG

TL;DR: DTRGC通过分层填充和聚类信息纠错，有效解决了属性缺失图的聚类问题，提升了现有方法的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的属性缺失图填充方法未能考虑节点邻域中可用信息的量不同，导致结果不可靠，尤其对于邻域信息不足的节点。

Method: 提出了一种名为“Divide-Then-Rule Graph Completion”（DTRGC）的新方法，该方法首先处理具有充足已知邻域信息的节点，并将其填充结果作为新知识来迭代地填充更难处理的节点，同时利用聚类信息来纠正填充错误。具体来说，动态聚类感知特征传播（DCFP）通过基于聚类结构调整传播权重来初始化缺失的节点属性。随后，分层邻域感知填充（HNAI）根据节点邻域属性的完整性将其分为三类，并优先处理邻域信息最多的节点组进行填充。最后，Hop-wise Representation Enhancement（HRE）整合了多跳信息，丰富了节点表示的表达能力。

Result: 实验结果表明，DTRGC在六个广泛使用的图数据集上，显著提高了各种DGC方法在属性缺失图上的聚类性能。

Conclusion: DTRGC方法在属性缺失图的聚类任务上显著提升了现有DGC方法的性能。

Abstract: Deep graph clustering (DGC) for attribute-missing graphs is an unsupervised
task aimed at partitioning nodes with incomplete attributes into distinct
clusters. Addressing this challenging issue is vital for practical
applications. However, research in this area remains underexplored. Existing
imputation methods for attribute-missing graphs often fail to account for the
varying amounts of information available across node neighborhoods, leading to
unreliable results, especially for nodes with insufficient known neighborhood.
To address this issue, we propose a novel method named Divide-Then-Rule Graph
Completion (DTRGC). This method first addresses nodes with sufficient known
neighborhood information and treats the imputed results as new knowledge to
iteratively impute more challenging nodes, while leveraging clustering
information to correct imputation errors. Specifically, Dynamic Cluster-Aware
Feature Propagation (DCFP) initializes missing node attributes by adjusting
propagation weights based on the clustering structure. Subsequently,
Hierarchical Neighborhood-aware Imputation (HNAI) categorizes attribute-missing
nodes into three groups based on the completeness of their neighborhood
attributes. The imputation is performed hierarchically, prioritizing the groups
with nodes that have the most available neighborhood information. The cluster
structure is then used to refine the imputation and correct potential errors.
Finally, Hop-wise Representation Enhancement (HRE) integrates information
across multiple hops, thereby enriching the expressiveness of node
representations. Experimental results on six widely used graph datasets show
that DTRGC significantly improves the clustering performance of various DGC
methods under attribute-missing graphs.

</details>


### [151] [RedOne: Revealing Domain-specific LLM Post-Training in Social Networking Services](https://arxiv.org/abs/2507.10605)
*Fei Zhao,Chonggang Lu,Yue Wang,Zheyong Xie,Ziyan Liu,Haofu Qian,JianZhao Huang,Fangcheng Shi,Zijie Meng,Hongcheng Guo,Mingqian He,Xinze Lyu,Yiming Lu,Ziyang Xiang,Zheyu Ye,Chengqiang Lu,Zhe Xu,Yi Wu,Yao Hu,Yan Gao,Jun Fan,Xiaolong Jiang,Weiting Liu,Boyang Wang,Shaosheng Cao*

Main category: cs.LG

TL;DR: RedOne是一个针对社交网络服务（SNS）的领域特定大语言模型（LLM），通过三阶段训练策略在真实世界数据上进行优化。与现有基线模型相比，RedOne在多个SNS任务上取得了显著的性能提升，并在线上测试中展现了在有害内容检测和搜索推荐方面的实际应用价值。


<details>
  <summary>Details</summary>
Motivation: 现有研究未能灵活适应多样化的真实世界背景，并且在数据扩展方面存在收益递减的问题。为了解决这些挑战，我们引入了RedOne，一个领域特定的LLM，旨在打破单任务基线的性能瓶颈，并为SNS建立全面的基础。

Method: RedOne模型通过包含持续预训练、监督微调和偏好优化三个阶段的策略进行训练，并使用了大规模的真实世界数据集。

Result: RedOne在8个主要的SNS任务上平均提升了14.02%，在SNS双语评估基准上提升了7.56%。在线测试结果显示，与单任务微调基线模型相比，RedOne在有害内容检测方面曝光率降低了11.23%，在帖子浏览搜索方面的点击页面率提高了14.95%。

Conclusion: RedOne是一个强大的、面向社交网络服务的领域特定语言大模型，它在各种任务中表现出优异的泛化能力，并在实际场景中具有广阔的应用前景。

Abstract: As a primary medium for modern information dissemination, social networking
services (SNS) have experienced rapid growth, which has proposed significant
challenges for platform content management and interaction quality improvement.
Recently, the development of large language models (LLMs) has offered potential
solutions but existing studies focus on isolated tasks, which not only
encounter diminishing benefit from the data scaling within individual scenarios
but also fail to flexibly adapt to diverse real-world context. To address these
challenges, we introduce RedOne, a domain-specific LLM designed to break the
performance bottleneck of single-task baselines and establish a comprehensive
foundation for the SNS. RedOne was developed through a three-stage training
strategy consisting of continue pretraining, supervised fine-tuning, and
preference optimization, using a large-scale real-world dataset. Through
extensive experiments, RedOne maintains strong general capabilities, and
achieves an average improvement up to 14.02% across 8 major SNS tasks and 7.56%
in SNS bilingual evaluation benchmark, compared with base models. Furthermore,
through online testing, RedOne reduced the exposure rate in harmful content
detection by 11.23% and improved the click page rate in post-view search by
14.95% compared with single-tasks finetuned baseline models. These results
establish RedOne as a robust domain-specific LLM for SNS, demonstrating
excellent generalization across various tasks and promising applicability in
real-world scenarios.

</details>


### [152] [GeoHopNet: Hopfield-Augmented Sparse Spatial Attention for Dynamic UAV Site Location Problem](https://arxiv.org/abs/2507.10636)
*Jianing Zhi,Xinghua Li,Zidong Chen*

Main category: cs.LG

TL;DR: GeoHopNet：一种高效的无人机动态选址解决方案，突破计算限制。


<details>
  <summary>Details</summary>
Motivation: 传统深度强化学习方法在处理大规模城市无人机动态选址问题时，由于标准注意力机制的计算复杂度瓶颈，面临挑战。

Method: 提出了一种名为 GeoHopNet 的新模型，该模型结合了 Hopfield 增强的稀疏空间注意力网络，并包含四个核心创新：(1) 距离偏置多头注意力机制，(2) K-最近邻稀疏注意力，(3) 现代 Hopfield 外部内存模块，(4) 内存正则化策略。

Result: GeoHopNet 算法在处理包含 1000 个节点的大规模实例时，能在 0.1 秒内找到高质量解（最优性差距为 0.22%），远超现有方法。在 100 节点实例上，相比 ADNet 基线，GeoHopNet 将解的质量提高了 22.2%，速度提升了 1.8 倍。

Conclusion: GeoHopNet 算法在解决大规模城市无人机动态选址问题上表现出色，显著提高了效率和解的质量，突破了现有方法的计算瓶颈。

Abstract: The rapid development of urban low-altitude unmanned aerial vehicle (UAV)
economy poses new challenges for dynamic site selection of UAV landing points
and supply stations. Traditional deep reinforcement learning methods face
computational complexity bottlenecks, particularly with standard attention
mechanisms, when handling large-scale urban-level location problems. This paper
proposes GeoHopNet, a Hopfield-augmented sparse spatial attention network
specifically designed for dynamic UAV site location problems. Our approach
introduces four core innovations: (1) distance-biased multi-head attention
mechanism that explicitly encodes spatial geometric information; (2) K-nearest
neighbor sparse attention that reduces computational complexity from $O(N^2)$
to $O(NK)$; (3) a modern Hopfield external memory module; and (4) a memory
regularization strategy. Experimental results demonstrate that GeoHopNet
extends the boundary of solvable problem sizes. For large-scale instances with
1,000 nodes, where standard attention models become prohibitively slow (over 3
seconds per instance) and traditional solvers fail, GeoHopNet finds
high-quality solutions (0.22\% optimality gap) in under 0.1 seconds. Compared
to the state-of-the-art ADNet baseline on 100-node instances, our method
improves solution quality by 22.2\% and is 1.8$\times$ faster.

</details>


### [153] [DALI-PD: Diffusion-based Synthetic Layout Heatmap Generation for ML in Physical Design](https://arxiv.org/abs/2507.10606)
*Bing-Yue Wu,Vidya A. Chhabria*

Main category: cs.LG

TL;DR: DALI-PD：一个用于生成合成物理设计布局热图的框架，通过扩散模型加速机器学习研究。


<details>
  <summary>Details</summary>
Motivation: 机器学习在物理设计任务中潜力巨大，但受限于高质量、大规模训练数据的可用性，而现有数据集创建成本高、受IP限制且更新慢。因此，需要一个可扩展的框架来生成合成数据以加速研究。

Method: DALI-PD框架利用扩散模型生成包括功耗、IR降、拥塞、宏放置和单元密度在内的多种布局热图，实现秒级快速推理。

Result: 使用DALI-PD框架创建了一个包含超过20,000个具有不同宏数量和布局配置的数据集，生成的热图与真实布局高度相似，并成功提高了下游任务（如IR降和拥塞预测）的机器学习准确性。

Conclusion: DALI-PD框架通过快速生成合成布局热图，解决了机器学习在物理设计任务中数据稀疏的问题，提高了模型的泛化能力和下游任务的准确性。

Abstract: Machine learning (ML) has demonstrated significant promise in various
physical design (PD) tasks. However, model generalizability remains limited by
the availability of high-quality, large-scale training datasets. Creating such
datasets is often computationally expensive and constrained by IP. While very
few public datasets are available, they are typically static, slow to generate,
and require frequent updates. To address these limitations, we present DALI-PD,
a scalable framework for generating synthetic layout heatmaps to accelerate ML
in PD research. DALI-PD uses a diffusion model to generate diverse layout
heatmaps via fast inference in seconds. The heatmaps include power, IR drop,
congestion, macro placement, and cell density maps. Using DALI-PD, we created a
dataset comprising over 20,000 layout configurations with varying macro counts
and placements. These heatmaps closely resemble real layouts and improve ML
accuracy on downstream ML tasks such as IR drop or congestion prediction.

</details>


### [154] [A Group Theoretic Analysis of the Symmetries Underlying Base Addition and Their Learnability by Neural Networks](https://arxiv.org/abs/2507.10678)
*Cutter Dawes,Simon Segert,Kamesh Krishnamurthy,Jonathan D. Cohen*

Main category: cs.LG

TL;DR: 神经网络通过对称性学习实现彻底泛化：研究发现，通过优化输入格式和采用合适的进位函数，神经网络能高效学习并实现彻底泛化，学习速度与进位函数结构紧密相关。


<details>
  <summary>Details</summary>
Motivation: 在将神经网络用于模拟人类认知功能和人工智能时，设计能够有效学习支持彻底泛化功能的系统是一个主要挑战。其根本在于发现和实现对称性功能的能力。

Method: 本研究通过对基数加法进行群论分析，揭示了进位函数的多种选择，并引入了量化指标来表征这些函数。接着，通过训练神经网络执行不同进位函数的基数加法，并比较学习效率和学习速率与网络结构的关系，来探究神经网络在对称性学习中的归纳偏置。

Result: 研究发现，即使是简单的神经网络，只要有正确的输入格式和进位函数，也能够实现彻底的泛化。同时，学习速度与进位函数的结构高度相关。

Conclusion: 该研究表明，通过正确的输入格式和进位函数，即使是简单的神经网络也能实现彻底的泛化。学习速度与进位函数的结构密切相关。此外，研究还讨论了其对认知科学和机器学习的意义。

Abstract: A major challenge in the use of neural networks both for modeling human
cognitive function and for artificial intelligence is the design of systems
with the capacity to efficiently learn functions that support radical
generalization. At the roots of this is the capacity to discover and implement
symmetry functions. In this paper, we investigate a paradigmatic example of
radical generalization through the use of symmetry: base addition. We present a
group theoretic analysis of base addition, a fundamental and defining
characteristic of which is the carry function -- the transfer of the remainder,
when a sum exceeds the base modulus, to the next significant place. Our
analysis exposes a range of alternative carry functions for a given base, and
we introduce quantitative measures to characterize these. We then exploit
differences in carry functions to probe the inductive biases of neural networks
in symmetry learning, by training neural networks to carry out base addition
using different carries, and comparing efficacy and rate of learning as a
function of their structure. We find that even simple neural networks can
achieve radical generalization with the right input format and carry function,
and that learning speed is closely correlated with carry function structure. We
then discuss the relevance this has for cognitive science and machine learning.

</details>


### [155] [A Feed-Forward Artificial Intelligence Pipeline for Sustainable Desalination under Climate Uncertainties: UAE Insights](https://arxiv.org/abs/2507.10609)
*Obumneme Nwafor,Chioma Nwafor,Amro Zakaria,Nkechi Nwankwo*

Main category: cs.LG

TL;DR: 阿联酋的海水淡化面临气候变化（特别是气溶胶光学厚度AOD）带来的挑战。本研究开发了一个两阶段预测模型，准确预测AOD和海水淡化效率损失（准确率达98%），并通过SHAP识别关键影响因素。此外，研究提出了一种基于AOD预测的防尘控制逻辑，可优化海水淡化运营（如调整压力、维护和能源切换），并提供了一个交互式仪表板以支持气候适应性规划。


<details>
  <summary>Details</summary>
Motivation: 鉴于阿联酋严重依赖海水淡化满足饮用水需求，而这一过程能耗高，对气候变化敏感（如海水温度、盐度和气溶胶光学厚度增加），特别是AOD会影响太阳能淡化系统的运行和经济效益，因此需要一个能够预测并适应这些气候不确定性的模型。

Method: 本研究提出了一种流水线式两阶段预测建模架构，第一阶段利用卫星数据和气象数据预测气溶胶光学厚度（AOD），第二阶段利用预测的AOD和其他气象因素预测海水淡化效率损失。研究还采用了SHAP方法来识别导致系统退化的关键因素，并提出了一种基于AOD和太阳能效率预测值的防尘规则控制逻辑，以调整进水压力、维护计划和能源切换。最后，将预测模型和控制逻辑打包成交互式仪表板，用于场景和预测分析。

Result: 该预测框架实现了98%的准确率，并使用SHAP方法揭示了导致系统退化的关键因素。此外，研究提出的防尘规则控制逻辑能够调整海水淡化厂的进水压力、维护计划和能源切换，并通过交互式仪表板提供了管理决策支持，以实现气候适应性规划。

Conclusion: 本研究提出了一个创新的流水线式两阶段预测建模架构，结合了预测模型和基于规则的控制逻辑，为阿联酋的海水淡化行业提供了一个应对气候变化挑战的管理决策支持系统，显著提高了预测准确性和系统的适应性。

Abstract: The United Arab Emirates (UAE) relies heavily on seawater desalination to
meet over 90% of its drinking water needs. Desalination processes are highly
energy intensive and account for approximately 15% of the UAE's electricity
consumption, contributing to over 22% of the country's energy-related CO2
emissions. Moreover, these processes face significant sustainability challenges
in the face of climate uncertainties such as rising seawater temperatures,
salinity, and aerosol optical depth (AOD). AOD greatly affects the operational
and economic performance of solar-powered desalination systems through
photovoltaic soiling, membrane fouling, and water turbidity cycles.
  This study proposes a novel pipelined two-stage predictive modelling
architecture: the first stage forecasts AOD using satellite-derived time series
and meteorological data; the second stage uses the predicted AOD and other
meteorological factors to predict desalination performance efficiency losses.
The framework achieved 98% accuracy, and SHAP (SHapley Additive exPlanations)
was used to reveal key drivers of system degradation. Furthermore, this study
proposes a dust-aware rule-based control logic for desalination systems based
on predicted values of AOD and solar efficiency. This control logic is used to
adjust the desalination plant feed water pressure, adapt maintenance
scheduling, and regulate energy source switching.
  To enhance the practical utility of the research findings, the predictive
models and rule-based controls were packaged into an interactive dashboard for
scenario and predictive analytics. This provides a management decision-support
system for climate-adaptive planning.

</details>


### [156] [FedGSCA: Medical Federated Learning with Global Sample Selector and Client Adaptive Adjuster under Label Noise](https://arxiv.org/abs/2507.10611)
*Mengwen Ye,Yingzi Huangfu,Shujian Gao,Wei Ren,Weifan Liu,Zekuan Yu*

Main category: cs.LG

TL;DR: FedGSCA 是一个新框架，通过全局样本选择器和客户端自适应调整 (CAA) 机制来增强嘈杂医疗联邦学习的鲁棒性，以解决噪声异质性和数据不平衡问题。


<details>
  <summary>Details</summary>
Motivation: 现有的联邦学习方法在处理噪声异质性和医疗数据不平衡方面存在困难。因此，提出 FedGSCA 框架以增强嘈杂医疗联邦学习的鲁棒性。

Method: FedGSCA 框架通过全局样本选择器聚合来自所有客户端的噪声知识，以解决噪声异质性问题并提高全局模型的稳定性。此外，还开发了一种客户端自适应调整 (CAA) 机制，该机制结合了自适应阈值伪标签生成和鲁棒的 Credal 标签损失，以动态调整类别分布，确保包含少数样本，并通过考虑多个合理的标签来仔细管理噪声标签。

Result: FedGSCA 在各种噪声条件下，包括对称、不对称、极端和异构类型，在真实世界的结肠图像数据集和两个合成医疗数据集上进行了评估。结果表明，FedGSCA 优于最先进的方法，在极端和异构噪声场景中表现出色。此外，FedGSCA 在提高模型稳定性和处理复杂噪声方面显示出显著优势。

Conclusion: FedGSCA 在各种噪声条件下，包括对称、不对称、极端和异构类型，在真实世界的结肠图像数据集和两个合成医疗数据集上进行了评估。结果表明，FedGSCA 优于最先进的方法，在极端和异构噪声场景中表现出色。此外，FedGSCA 在提高模型稳定性和处理复杂噪声方面显示出显著优势，非常适合真实的医疗联邦学习场景。

Abstract: Federated Learning (FL) emerged as a solution for collaborative medical image
classification while preserving data privacy. However, label noise, which
arises from inter-institutional data variability, can cause training
instability and degrade model performance. Existing FL methods struggle with
noise heterogeneity and the imbalance in medical data. Motivated by these
challenges, we propose FedGSCA, a novel framework for enhancing robustness in
noisy medical FL. FedGSCA introduces a Global Sample Selector that aggregates
noise knowledge from all clients, effectively addressing noise heterogeneity
and improving global model stability. Furthermore, we develop a Client Adaptive
Adjustment (CAA) mechanism that combines adaptive threshold pseudo-label
generation and Robust Credal Labeling Loss. CAA dynamically adjusts to class
distributions, ensuring the inclusion of minority samples and carefully
managing noisy labels by considering multiple plausible labels. This dual
approach mitigates the impact of noisy data and prevents overfitting during
local training, which improves the generalizability of the model. We evaluate
FedGSCA on one real-world colon slides dataset and two synthetic medical
datasets under various noise conditions, including symmetric, asymmetric,
extreme, and heterogeneous types. The results show that FedGSCA outperforms the
state-of-the-art methods, excelling in extreme and heterogeneous noise
scenarios. Moreover, FedGSCA demonstrates significant advantages in improving
model stability and handling complex noise, making it well-suited for
real-world medical federated learning scenarios.

</details>


### [157] [A parametric activation function based on Wendland RBF](https://arxiv.org/abs/2507.11493)
*Majid Darehmiraki*

Main category: cs.LG

TL;DR: 本论文提出了一种新的基于Wendland径向基函数的激活函数，它比传统的激活函数更光滑、更稳定，并且在某些任务上表现更好。


<details>
  <summary>Details</summary>
Motivation: 为了克服ReLU、sigmoid和tanh等传统激活函数的局限性，并利用Wendland RBF的紧支撑、光滑性和正定性等优点。

Method: 提出了一种基于Wendland径向基函数的增强型激活函数，该函数结合了线性、指数和Wendland分量，并具有可调的局部性。

Result: 实验结果表明，该Wendland激活函数在某些场景下（尤其是在回归任务中）实现了优于传统激活函数的准确性，同时保持了计算效率，并能缓解过拟合、提高泛化能力。

Conclusion: 该研究提出了基于Wendland径向基函数（RBF）的新型参数化激活函数，并证明了其在深度神经网络中的潜力，特别是在缓解过拟合和提高泛化能力方面。

Abstract: This paper introduces a novel parametric activation function based on
Wendland radial basis functions (RBFs) for deep neural networks. Wendland RBFs,
known for their compact support, smoothness, and positive definiteness in
approximation theory, are adapted to address limitations of traditional
activation functions like ReLU, sigmoid, and tanh. The proposed enhanced
Wendland activation combines a standard Wendland component with linear and
exponential terms, offering tunable locality, improved gradient propagation,
and enhanced stability during training. Theoretical analysis highlights its
mathematical properties, including smoothness and adaptability, while empirical
experiments on synthetic tasks (e.g., sine wave approximation) and benchmark
datasets (MNIST, Fashion-MNIST) demonstrate competitive performance. Results
show that the Wendland-based activation achieves superior accuracy in certain
scenarios, particularly in regression tasks, while maintaining computational
efficiency. The study bridges classical RBF theory with modern deep learning,
suggesting that Wendland activations can mitigate overfitting and improve
generalization through localized, smooth transformations. Future directions
include hybrid architectures and domain-specific adaptations.

</details>


### [158] [Sub-Scaling Laws: On the Role of Data Density and Training Strategies in LLMs](https://arxiv.org/abs/2507.10613)
*Zhengyu Chen,Siqi Wang,Teng Xiao,Yudong Wang,Shiqi Chen,Xunliang Cai,Junxian He,Jingang Wang*

Main category: cs.LG

TL;DR: 研究发现，数据质量和训练策略（如数据密度和资源分配）会影响大型语言模型的性能，并提出新的缩放定律以更好地预测模型性能。


<details>
  <summary>Details</summary>
Motivation: 探讨了传统缩放定律在大型语言模型中出现的偏差（即亚线性缩放），旨在理解其背后的原因。

Method: 通过对400多个模型进行广泛的实证分析，研究了数据质量和训练策略对模型性能的影响。

Result: 确定了高数据密度和资源分配不当是导致亚线性缩放的关键因素，并提出了一种能更好地预测亚线性缩放模型性能的次优缩放定律。

Conclusion: 本研究通过识别数据质量和训练策略在模型性能中的作用，为理解和预测大型语言模型的亚线性缩放现象提供了新的见解。

Abstract: Traditional scaling laws in natural language processing suggest that
increasing model size and training data enhances performance. However, recent
studies reveal deviations, particularly in large language models, where
performance improvements decelerate, which is a phenomenon known as
sub-scaling. This paper revisits these scaling laws by examining the impact of
data quality and training strategies on model performance. Through extensive
empirical analysis of over 400 models, we identify high data density and
non-optimal resource allocation as key factors contributing to sub-scaling.
High data density leads to diminishing returns due to redundant information,
while optimal resource allocation is crucial for sustained performance
improvements. We propose a sub-optimal scaling law that better predicts
performance in sub-scaling regimes, highlighting the importance of data quality
and diversity.

</details>


### [159] [D3FL: Data Distribution and Detrending for Robust Federated Learning in Non-linear Time-series Data](https://arxiv.org/abs/2507.11471)
*Harsha Varun Marisetty,Manik Gupta,Yogesh Simmhan*

Main category: cs.LG

TL;DR: 本文研究了联邦学习在处理非线性、非平稳时间序列数据时的性能。研究发现，FL在处理此类数据时不如集中式方法，但通过使用趋势剔除技术可以提高其性能。


<details>
  <summary>Details</summary>
Motivation: 物联网（IoT）设备产生大量的时间序列数据，这些数据通常具有非线性和非平稳性，这对预测精度提出了挑战。传统的集中式数据分析方法存在延迟和通信成本高的问题。联邦学习（FL）作为一种分布式学习方法，可以在不集中数据的情况下进行模型训练，但其在处理具有显著差异的分布式数据时性能会受到影响。

Method: 本文研究了非线性、非平稳时间序列数据分布（如广义极值分布和对数正态分布）对联邦学习（FL）性能的影响，并分析了不同的趋势剔除技术对FL设置下预测模型性能的影响。通过生成合成时间序列数据集和使用真实世界数据集，并训练LSTM预测模型，在集中式和FL方法下进行了评估。

Result: 实验结果表明，（1）在处理非线性数据分布时，FL的性能劣于集中式方法。（2）使用适当的趋势剔除技术能够改善FL的性能，并降低不同数据分布下的损失。

Conclusion: 联邦学习（FL）在处理非线性时间序列数据分布时，其性能不如集中式方法。然而，采用适当的趋势剔除技术可以显著提高FL在不同数据分布下的性能，减少损失。

Abstract: With advancements in computing and communication technologies, the Internet
of Things (IoT) has seen significant growth. IoT devices typically collect data
from various sensors, such as temperature, humidity, and energy meters. Much of
this data is temporal in nature. Traditionally, data from IoT devices is
centralized for analysis, but this approach introduces delays and increased
communication costs. Federated learning (FL) has emerged as an effective
alternative, allowing for model training across distributed devices without the
need to centralize data. In many applications, such as smart home energy and
environmental monitoring, the data collected by IoT devices across different
locations can exhibit significant variation in trends and seasonal patterns.
Accurately forecasting such non-stationary, non-linear time-series data is
crucial for applications like energy consumption estimation and weather
forecasting. However, these data variations can severely impact prediction
accuracy. The key contributions of this paper are: (1) Investigating how
non-linear, non-stationary time-series data distributions, like generalized
extreme value (gen-extreme) and log norm distributions, affect FL performance.
(2) Analyzing how different detrending techniques for non-linear time-series
data influence the forecasting model's performance in a FL setup. We generated
several synthetic time-series datasets using non-linear data distributions and
trained an LSTM-based forecasting model using both centralized and FL
approaches. Additionally, we evaluated the impact of detrending on real-world
datasets with non-linear time-series data distributions. Our experimental
results show that: (1) FL performs worse than centralized approaches when
dealing with non-linear data distributions. (2) The use of appropriate
detrending techniques improves FL performance, reducing loss across different
data distributions.

</details>


### [160] [Fine-tuning Large Language Model for Automated Algorithm Design](https://arxiv.org/abs/2507.10614)
*Fei Liu,Rui Zhang,Xi Lin,Zhichao Lu,Qingfu Zhang*

Main category: cs.LG

TL;DR: 微调语言模型以适应算法设计任务，效果优于通用模型，并具有良好的泛化性。


<details>
  <summary>Details</summary>
Motivation: 该研究旨在解决在算法设计中是否需要专门为该任务训练的语言模型，以及如何有效获取和评估这类模型的泛化能力的问题。

Method: 本研究探索了针对算法设计任务微调语言模型的方法。研究引入了一种“多样性感知排序采样”（DAR）策略，以平衡训练数据的多样性和质量，并利用“直接偏好优化”（DPO）技术来高效地使语言模型的输出与任务目标保持一致。

Result: 实验结果表明，经过微调的语言模型，即使是较小的模型（如 Llama-3.2-1B-Instruct），在特定算法设计任务（如容许集问题）上的表现也显著优于其通用版本；同时，较大的模型（如 Llama-3.1-8B-Instruct）在经过微调后能达到甚至超过通用版本。此外，研究还观察到，在特定算法设计任务上微调过的模型，在设置不同的相关任务上也表现出令人鼓舞的泛化能力。

Conclusion: 微调后的语言模型在算法设计任务上能够显著优于或匹敌通用模型，并且在相关任务上展现出良好的泛化能力，这表明针对特定任务进行调整对于提升语言模型在算法设计中的表现至关重要。

Abstract: The integration of large language models (LLMs) into automated algorithm
design has shown promising potential. A prevalent approach embeds LLMs within
search routines to iteratively generate and refine candidate algorithms.
However, most existing methods rely on off-the-shelf LLMs trained for general
coding tasks,leaving a key question open: Do we need LLMs specifically tailored
for algorithm design? If so, how can such LLMs be effectively obtained and how
well can they generalize across different algorithm design tasks? In this
paper, we take a first step toward answering these questions by exploring
fine-tuning of LLMs for algorithm design. We introduce a Diversity-Aware Rank
based (DAR) sampling strategy to balance training data diversity and quality,
then we leverage direct preference optimization to efficiently align LLM
outputs with task objectives. Our experiments, conducted on
Llama-3.2-1B-Instruct and Llama- 3.1-8B-Instruct, span three distinct algorithm
design tasks. Results suggest that finetuned LLMs can significantly outperform
their off-the-shelf counterparts with the smaller Llama-3.2-1B-Instruct and
match the larger Llama-3.1-8B-Instruct on the admissible set problem. Moreover,
we observe promising generalization: LLMs finetuned on specific algorithm
design tasks also improve performance on related tasks with varying settings.
These findings highlight the value of task-specific adaptation for LLMs in
algorithm design and open new avenues for future research.

</details>


### [161] [Scalpel vs. Hammer: GRPO Amplifies Existing Capabilities, SFT Replaces Them](https://arxiv.org/abs/2507.10616)
*Neel Rajani,Aryo Pradipta Gema,Seraphina Goldfarb-Tarrant,Ivan Titov*

Main category: cs.LG

TL;DR: 该研究比较了RL和SFT在LLM推理训练中的应用，发现在数学任务上RL略有提升，SFT提升更明显但会损害其他能力。SFT的训练过程对模型参数的修改更大，可能导致了这种损害。通过冻结模型部分进行训练的效果不确定。


<details>
  <summary>Details</summary>
Motivation: LLM通过数学和代码数据集进行推理的训练已成为LLM训练后的一项主要新焦点，其中RL和SFT是两种特别流行的方法，但它们的训练动态知之甚少。

Method: 通过在相同的数学问题、相同的模型和相似的超参数上对RL和SFT进行比较分析。

Result: RL在数学方面带来了较小的领域内收益，在MMLU等知识密集型基准测试上略有下降，而SFT的这些趋势更为明显。RL和SFT都主要修改了查询和键权重，其中SFT的更新更大，并且更多地影响了中间层的MLP。通过冻结模型部分进行训练以缓解在知识密集型基准测试上性能下降的研究结果不确定，在GPQA:Diamond上有所改善，但在其他基准测试上有所下降。

Conclusion: RL放大了现有能力，而SFT用新技能取代了旧技能。

Abstract: Training large language models (LLMs) for reasoning via maths and code
datasets has become a major new focus in LLM post-training. Two particularly
popular approaches are reinforcement learning (RL) and supervised fine-tuning
(SFT), but their training dynamics are poorly understood. We present a
comparative analysis of RL and SFT on the same maths problems with the same
model and similar hyperparameters. We find that RL yields minor in-domain gains
on maths and slight degradation on knowledge-intensive benchmarks like MMLU,
while both trends are more pronounced in SFT. We also analyse model parameters
across checkpoints, observing that both algorithms modify query and key weights
the most. Meanwhile, SFT exhibits greater updates and also affects mid-layer
MLPs more, leading us to hypothesise that this may have caused the
out-of-domain degradation. We therefore investigate whether freezing parts of
the model during training can mitigate the reduced performance on
knowledge-intensive benchmarks. However, our results are inconclusive, with
benefits on GPQA:Diamond and degradation on other benchmarks. Taken together,
our observations provide a preliminary indication for why RL amplifies existing
capabilities, while SFT replaces old skills with new ones.

</details>


### [162] [Distributionally Robust Optimization with Adversarial Data Contamination](https://arxiv.org/abs/2507.10718)
*Shuyao Li,Ilias Diakonikolas,Jelena Diakonikolas*

Main category: cs.LG

TL;DR: 本研究提出了一种新方法，能够同时应对数据污染和分布变化，并在存在异常值的情况下，为分布鲁棒优化提供有效的解决方案和理论保证。


<details>
  <summary>Details</summary>
Motivation: 解决分布鲁棒优化（DRO）在面对训练数据中的异常值时鲁棒性会受到影响的问题，并同时应对数据污染和分布变化带来的挑战。

Method: 提出了一种新颖的建模框架，将对训练数据污染的鲁棒性与对分布变化的鲁棒性相结合，并开发了一种受鲁棒统计学启发的有效算法来解决优化问题。

Result: 证明了该方法在有界协方差假设下，仅使用受污染的数据即可实现对真实 DRO 目标值 $O(\sqrt{\epsilon})$ 的估计误差。

Conclusion: 该研究首次在数据污染和分布变化的双重挑战下，为学习提供了严格的保证和有效的计算方法。

Abstract: Distributionally Robust Optimization (DRO) provides a framework for
decision-making under distributional uncertainty, yet its effectiveness can be
compromised by outliers in the training data. This paper introduces a
principled approach to simultaneously address both challenges. We focus on
optimizing Wasserstein-1 DRO objectives for generalized linear models with
convex Lipschitz loss functions, where an $\epsilon$-fraction of the training
data is adversarially corrupted. Our primary contribution lies in a novel
modeling framework that integrates robustness against training data
contamination with robustness against distributional shifts, alongside an
efficient algorithm inspired by robust statistics to solve the resulting
optimization problem. We prove that our method achieves an estimation error of
$O(\sqrt{\epsilon})$ for the true DRO objective value using only the
contaminated data under the bounded covariance assumption. This work
establishes the first rigorous guarantees, supported by efficient computation,
for learning under the dual challenges of data contamination and distributional
shifts.

</details>


### [163] [Compute Requirements for Algorithmic Innovation in Frontier AI Models](https://arxiv.org/abs/2507.10618)
*Peter Barnett*

Main category: cs.LG

TL;DR: 算法创新需求每年翻倍，但计算上限不太可能显著减缓AI算法进展。


<details>
  <summary>Details</summary>
Motivation: 探讨算法创新在开发中对计算能力的需求。

Method: 通过编目Llama 3和DeepSeek-V3中使用的36种预训练算法创新，并估算其开发所使用的总FLOP和所用硬件的FLOP/s来实证研究。

Result: 创新性研究发现，使用大量资源的创新，其需求每年翻倍。分析表明，单独的计算上限不太可能显著减缓AI算法的进展。

Conclusion: 即使有严格的计算上限，例如将总操作数限制在训练GPT-2的计算量，或将硬件容量限制为8个H100 GPU，仍有可能实现所分类别中一半的创新。

Abstract: Algorithmic innovation in the pretraining of large language models has driven
a massive reduction in the total compute required to reach a given level of
capability. In this paper we empirically investigate the compute requirements
for developing algorithmic innovations. We catalog 36 pre-training algorithmic
innovations used in Llama 3 and DeepSeek-V3. For each innovation we estimate
both the total FLOP used in development and the FLOP/s of the hardware
utilized. Innovations using significant resources double in their requirements
each year. We then use this dataset to investigate the effect of compute caps
on innovation. Our analysis suggests that compute caps alone are unlikely to
dramatically slow AI algorithmic progress. Even stringent compute caps -- such
as capping total operations to the compute used to train GPT-2 or capping
hardware capacity to 8 H100 GPUs -- could still have allowed for half of the
cataloged innovations.

</details>


### [164] [Meta-Reinforcement Learning for Fast and Data-Efficient Spectrum Allocation in Dynamic Wireless Networks](https://arxiv.org/abs/2507.10619)
*Oluwaseyi Giwa,Tobi Awodunmila,Muhammad Ahmed Mohsin,Ahsan Bilal,Muhammad Ali Jamshed*

Main category: cs.LG

TL;DR: 元学习框架通过MAML、RNN和增强型RNN架构，解决了传统DRL在5G/6G网络动态频谱分配中的样本复杂性和安全风险问题。实验结果表明，元学习方法在网络吞吐量、SINR、延迟和公平性方面均优于PPO基线，是一种更有效、更安全的智能控制选择。


<details>
  <summary>Details</summary>
Motivation: 为了解决传统深度强化学习（DRL）在5G/6G网络动态频谱分配中面临的巨大样本复杂性和无指导探索带来的安全风险（可能导致严重的网络干扰）等问题。

Method: 提出了一种元学习框架，实现了代理的鲁棒初始策略学习，并能在数据量最少的情况下快速适应新的无线场景。具体来说，实现了三种元学习架构：模型无关元学习（MAML）、循环神经网络（RNN）和增强型RNN。

Result: 与仅使用近端策略优化（PPO）基线的非元学习DRL算法相比，所提出的元学习方法在模拟的动态集成接入/回传（IAB）环境中表现出明显的性能优势。具体而言，基于注意力的元学习代理达到了48 Mbps的峰值平均网络吞吐量，而PPO基线则下降至10 Mbps。此外，该方法将信噪比（SINR）和延迟违规次数减少了50%以上，公平性指数达到了0.7，表明其在资源分配方面表现更优，并能快速适应新环境。

Conclusion: 元学习是一种在复杂无线系统中进行智能控制的有效且更安全的选择。

Abstract: The dynamic allocation of spectrum in 5G / 6G networks is critical to
efficient resource utilization. However, applying traditional deep
reinforcement learning (DRL) is often infeasible due to its immense sample
complexity and the safety risks associated with unguided exploration, which can
cause severe network interference. To address these challenges, we propose a
meta-learning framework that enables agents to learn a robust initial policy
and rapidly adapt to new wireless scenarios with minimal data. We implement
three meta-learning architectures, model-agnostic meta-learning (MAML),
recurrent neural network (RNN), and an attention-enhanced RNN, and evaluate
them against a non-meta-learning DRL algorithm, proximal policy optimization
(PPO) baseline, in a simulated dynamic integrated access/backhaul (IAB)
environment. Our results show a clear performance gap. The attention-based
meta-learning agent reaches a peak mean network throughput of 48 Mbps, while
the PPO baseline decreased drastically to 10 Mbps. Furthermore, our method
reduces SINR and latency violations by more than 50% compared to PPO. It also
shows quick adaptation, with a fairness index 0.7, showing better resource
allocation. This work proves that meta-learning is a very effective and safer
option for intelligent control in complex wireless systems.

</details>


### [165] [LLMs Meet Cross-Modal Time Series Analytics: Overview and Directions](https://arxiv.org/abs/2507.10620)
*Chenxi Liu,Hao Miao,Cheng Long,Yan Zhao,Ziyue Li,Panos Kalnis*

Main category: cs.LG

TL;DR: LLM在时间序列分析中很有前景，但需要解决跨模态问题。本教程概述了现有方法，并讨论了挑战和未来方向。


<details>
  <summary>Details</summary>
Motivation: LLM在时间序列分析中具有潜力，但由于其在文本语料库上预训练且未针对时间序列进行优化，存在跨模态鸿沟。

Method: 本教程对基于LLM的跨模态时间序列分析进行了全面的概述，引入了一个基于跨模态建模策略（转换、对齐、融合）的分类体系，并探讨了它们在各种下游任务中的应用。

Result: 本教程旨在为参与者提供对跨模态时间序列分析领域当前进展、方法论和未来研究方向的透彻理解，以扩展LLM在解决现实世界问题中的实际应用。

Conclusion: LLM在时间序列分析领域展现出巨大潜力，但存在跨模态鸿沟。本教程旨在弥合这一差距，通过分类现有方法（转换、对齐、融合）并讨论其在下游任务中的应用，同时总结开放性挑战，以期推动LLM在跨模态时间序列分析中的实际应用，并平衡有效性与效率。

Abstract: Large Language Models (LLMs) have emerged as a promising paradigm for time
series analytics, leveraging their massive parameters and the shared sequential
nature of textual and time series data. However, a cross-modality gap exists
between time series and textual data, as LLMs are pre-trained on textual
corpora and are not inherently optimized for time series. In this tutorial, we
provide an up-to-date overview of LLM-based cross-modal time series analytics.
We introduce a taxonomy that classifies existing approaches into three groups
based on cross-modal modeling strategies, e.g., conversion, alignment, and
fusion, and then discuss their applications across a range of downstream tasks.
In addition, we summarize several open challenges. This tutorial aims to expand
the practical application of LLMs in solving real-world problems in cross-modal
time series analytics while balancing effectiveness and efficiency.
Participants will gain a thorough understanding of current advancements,
methodologies, and future research directions in cross-modal time series
analytics.

</details>


### [166] [Flows and Diffusions on the Neural Manifold](https://arxiv.org/abs/2507.10623)
*Daniel Saragih,Deyu Cao,Tejas Balaji*

Main category: cs.LG

TL;DR: 通过梯度流匹配将扩散模型应用于权重空间学习，以改进模型初始化和检测异常。


<details>
  <summary>Details</summary>
Motivation: 将扩散和流模型在图像、视频和自然语言生成方面的成功扩展到权重空间学习，并利用优化动力学中提取的结构化先验。

Method: 提出了一种将梯度下降轨迹视为轨迹推理问题的方法，并将其统一在梯度流匹配框架下，将优化路径作为归纳偏置。探索了包括通过伴随匹配进行奖励微调、使用自编码器表示潜在权重、条件化任务特定上下文数据以及采用 Kaiming 均匀分布等架构和算法选择。

Result: 在生成分布内权重、改进下游训练初始化以及通过微调提升性能方面，该方法与基线相当或更优。在检测有害协变量偏移的应用中，该方法也优于最接近的可比基线。

Conclusion: 该研究将扩散和流模型扩展到权重空间学习，通过将梯度下降轨迹建模为轨迹推理问题，并提出了梯度流匹配框架。实验证明该方法在生成权重、改进初始化和支持微调方面优于基线，并在检测有害协变量偏移方面有实际应用价值。

Abstract: Diffusion and flow-based generative models have achieved remarkable success
in domains such as image synthesis, video generation, and natural language
modeling. In this work, we extend these advances to weight space learning by
leveraging recent techniques to incorporate structural priors derived from
optimization dynamics. Central to our approach is modeling the trajectory
induced by gradient descent as a trajectory inference problem. We unify several
trajectory inference techniques under the framework of gradient flow matching,
providing a theoretical framework for treating optimization paths as inductive
bias. We further explore architectural and algorithmic choices, including
reward fine-tuning by adjoint matching, the use of autoencoders for latent
weight representation, conditioning on task-specific context data, and adopting
informative source distributions such as Kaiming uniform. Experiments
demonstrate that our method matches or surpasses baselines in generating
in-distribution weights, improves initialization for downstream training, and
supports fine-tuning to enhance performance. Finally, we illustrate a practical
application in safety-critical systems: detecting harmful covariate shifts,
where our method outperforms the closest comparable baseline.

</details>


### [167] [Player-Team Heterogeneous Interaction Graph Transformer for Soccer Outcome Prediction](https://arxiv.org/abs/2507.10626)
*Lintao Wang,Shiwen Xu,Michael Horton,Joachim Gudmundsson,Zhiyong Wang*

Main category: cs.LG

TL;DR: HIGFormer通过异构交互图和Transformer来预测足球比赛结果，效果优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有方法忽略了球员和球队之间交互的异构性质，而这对于准确模拟比赛动态至关重要。

Method: HIGFormer（异构交互图Transformer）模型，一个新颖的图增强Transformer深度学习模型。该模型包含三个部分：（1）球员交互网络，通过异构交互图编码球员表现，结合局部图卷积和全局图增强Transformer；（2）球队交互网络，从球队到球队的角度构建交互图以模拟历史比赛关系；（3）比赛比较Transformer，联合分析球队和球员层面的信息以预测比赛结果。

Result: 在WyScout公开数据集上的广泛实验表明，HIGFormer在预测准确性方面显著优于现有方法。

Conclusion: HIGFormer在预测准确性方面显著优于现有方法，并能为球员表现评估、人才选拔和球队策略分析提供有价值的见解。

Abstract: Predicting soccer match outcomes is a challenging task due to the inherently
unpredictable nature of the game and the numerous dynamic factors influencing
results. While it conventionally relies on meticulous feature engineering, deep
learning techniques have recently shown a great promise in learning effective
player and team representations directly for soccer outcome prediction.
However, existing methods often overlook the heterogeneous nature of
interactions among players and teams, which is crucial for accurately modeling
match dynamics. To address this gap, we propose HIGFormer (Heterogeneous
Interaction Graph Transformer), a novel graph-augmented transformer-based deep
learning model for soccer outcome prediction. HIGFormer introduces a
multi-level interaction framework that captures both fine-grained player
dynamics and high-level team interactions. Specifically, it comprises (1) a
Player Interaction Network, which encodes player performance through
heterogeneous interaction graphs, combining local graph convolutions with a
global graph-augmented transformer; (2) a Team Interaction Network, which
constructs interaction graphs from a team-to-team perspective to model
historical match relationships; and (3) a Match Comparison Transformer, which
jointly analyzes both team and player-level information to predict match
outcomes. Extensive experiments on the WyScout Open Access Dataset, a
large-scale real-world soccer dataset, demonstrate that HIGFormer significantly
outperforms existing methods in prediction accuracy. Furthermore, we provide
valuable insights into leveraging our model for player performance evaluation,
offering a new perspective on talent scouting and team strategy analysis.

</details>


### [168] [GHPO: Adaptive Guidance for Stable and Efficient LLM Reinforcement Learning](https://arxiv.org/abs/2507.10628)
*Ziru Liu,Cheng Gong,Xinyu Fu,Yaofang Liu,Ran Chen,Shoubo Hu,Suiyun Zhang,Rui Liu,Qingfu Zhang,Dandan Tu*

Main category: cs.LG

TL;DR: GHPO通过自适应调整任务难度和混合学习策略，解决了RL在LLM复杂推理训练中的不稳定性问题，显著提升了性能。


<details>
  <summary>Details</summary>
Motivation: 现有的强化学习方法在应对LLM的复杂推理任务时，常常面临训练不稳定和效率低下的问题，这主要是由于能力-难度不匹配，导致奖励信号稀疏，学习停滞，尤其对资源有限的小型LLM而言更为严峻。

Method: 提出了一种名为“引导混合策略优化”（GHPO）的新型RL框架，该框架采用自适应提示细化技术来动态调整任务难度，并结合模仿学习和基于探索的RL，以创建平滑的学习课程。

Result: GHPO在六个具有挑战性的数学基准测试中，平均性能提升了约5%，并且在训练稳定性和最终推理性能方面均显著优于强大的同策略RL和课程学习基线。

Conclusion: GHPO框架通过自适应提示细化和混合学习策略，在数学推理任务上显著提高了LLM的性能和稳定性，平均提升约5%，优于现有的强化学习和课程学习方法，为开发强大且可靠的推理模型提供了一个可扩展且高效的解决方案。

Abstract: Reinforcement Learning with Verifiable Rewards (RLVR) has recently emerged as
a powerful paradigm for facilitating the self-improvement of large language
models (LLMs), particularly in the domain of complex reasoning tasks. However,
prevailing on-policy RL methods often contend with significant training
instability and inefficiency. This is primarily due to a capacity-difficulty
mismatch, where the complexity of training data frequently outpaces the model's
current capabilities, leading to critically sparse reward signals and stalled
learning progress. This challenge is particularly acute for smaller, more
resource-efficient LLMs. To overcome this, we introduce the Guided Hybrid
Policy Optimization (GHPO), a novel difficulty-aware reinforcement learning
framework. GHPO dynamically calibrates task difficulty by employing adaptive
prompt refinement to provide targeted guidance. This unique approach adaptively
balances direct imitation learning for problems currently beyond the model's
reach with exploration-based reinforcement learning for more manageable tasks,
effectively creating a smooth and optimized learning curriculum. Extensive
experiments demonstrate that GHPO achieves an average performance gain of
approximately 5% across six challenging mathematics benchmarks, consistently
outperforming strong on-policy reinforcement learning and curriculum learning
baselines. Further analysis confirms that our framework significantly enhances
both training stability and final reasoning performance, thus offering a
scalable and efficient solution for developing powerful and robust reasoning
models.

</details>


### [169] [Scalable Unsupervised Segmentation via Random Fourier Feature-based Gaussian Process](https://arxiv.org/abs/2507.10632)
*Issei Saito,Masatoshi Nagano,Tomoaki Nakamura,Daichi Mochihashi,Koki Mimura*

Main category: cs.LG

TL;DR: 提出了一种名为RFF-GP-HSMM的快速无监督时间序列分割方法，通过使用随机傅里叶特征（RFF）来近似高斯过程，解决了传统GP-HSMM计算成本高的问题，实现了与传统方法相当的性能，同时速度大幅提升。


<details>
  <summary>Details</summary>
Motivation: 传统的高斯过程隐半半马尔可夫模型（GP-HSMM）在处理大规模时间序列数据时，由于需要对N×N核矩阵进行求逆，计算成本非常高。本研究旨在解决这一计算瓶颈，提出一种更高效的时间序列分割方法。

Method: 该方法通过引入随机傅里叶特征（RFF）来近似高斯过程，并结合高斯过程隐半马尔可夫模型（GP-HSMM），解决了GP-HSMM计算成本高的问题。具体来说，它使用RFF将高斯过程近似为线性回归，从而避免了对N×N核矩阵进行求逆的需求，其中N是数据点的数量。

Result: RFF-GP-HSMM在CMU运动捕捉数据集上实现了与传统方法相当的分割性能，同时在处理包含39,200帧的时间序列数据时，分割速度比传统方法快了约278倍。

Conclusion: RFF-GP-HSMM在CMU运动捕捉数据集上的实验表明，该方法实现了与传统方法相当的分割性能，并且在包含39,200帧的时间序列数据上分割速度快了约278倍。

Abstract: In this paper, we propose RFF-GP-HSMM, a fast unsupervised time-series
segmentation method that incorporates random Fourier features (RFF) to address
the high computational cost of the Gaussian process hidden semi-Markov model
(GP-HSMM). GP-HSMM models time-series data using Gaussian processes, requiring
inversion of an N times N kernel matrix during training, where N is the number
of data points. As the scale of the data increases, matrix inversion incurs a
significant computational cost. To address this, the proposed method
approximates the Gaussian process with linear regression using RFF, preserving
expressive power while eliminating the need for inversion of the kernel matrix.
Experiments on the Carnegie Mellon University (CMU) motion-capture dataset
demonstrate that the proposed method achieves segmentation performance
comparable to that of conventional methods, with approximately 278 times faster
segmentation on time-series data comprising 39,200 frames.

</details>


### [170] [A Simple Baseline for Stable and Plastic Neural Networks](https://arxiv.org/abs/2507.10637)
*É. Künzel,A. Jaziri,V. Ramesh*

Main category: cs.LG

TL;DR: RDBP是一种新的持续学习方法，通过ReLUDown和Decreasing Backpropagation机制，在不牺牲性能的情况下提高了塑形性和稳定性，并降低了计算成本。


<details>
  <summary>Details</summary>
Motivation: 持续学习需要模型适应连续的任务流，同时不忘记先前的知识，但现有方法往往在塑形性和稳定性之间失衡。

Method: RDBP结合了两种机制：ReLUDown（一种轻量级激活修改，可保持特征敏感性并防止神经元休眠）和Decreasing Backpropagation（一种受生物学启发的梯度调度方案，可逐步保护早期层免受灾难性更新）。

Result: RDBP在Continual ImageNet基准测试中，塑形性和稳定性与现有最先进方法相当或更优，同时降低了计算成本。

Conclusion: RDBP是一种简单、低开销的基线方法，在Continual ImageNet基准测试中，其塑形性和稳定性与现有最先进方法相当或更优，同时降低了计算成本。RDBP为实际的持续学习提供了一个实用的解决方案，并为未来的持续学习策略提供了一个清晰的基准。

Abstract: Continual learning in computer vision requires that models adapt to a
continuous stream of tasks without forgetting prior knowledge, yet existing
approaches often tip the balance heavily toward either plasticity or stability.
We introduce RDBP, a simple, low-overhead baseline that unites two
complementary mechanisms: ReLUDown, a lightweight activation modification that
preserves feature sensitivity while preventing neuron dormancy, and Decreasing
Backpropagation, a biologically inspired gradient-scheduling scheme that
progressively shields early layers from catastrophic updates. Evaluated on the
Continual ImageNet benchmark, RDBP matches or exceeds the plasticity and
stability of state-of-the-art methods while reducing computational cost. RDBP
thus provides both a practical solution for real-world continual learning and a
clear benchmark against which future continual learning strategies can be
measured.

</details>


### [171] [ZClassifier: Temperature Tuning and Manifold Approximation via KL Divergence on Logit Space](https://arxiv.org/abs/2507.10638)
*Shim Soon Yong*

Main category: cs.LG

TL;DR: ZClassifier 是一种新的分类框架，使用高斯分布 logits 替代确定性 logits，提高了分类器的鲁棒性、校准性和潜在分离性。


<details>
  <summary>Details</summary>
Motivation: 为了解决传统确定性 logits 的局限性，并统一不确定性校准和潜在控制，提出了一种新的分类框架。

Method: ZClassifier 框架通过最小化预测的高斯分布与单位各向同性高斯分布之间的 KL 散度来同时处理温度缩放和流形逼近。

Result: ZClassifier 框架在 CIFAR-10 和 CIFAR-100 数据集上表现出色，其鲁棒性、校准性和潜在分离性均优于 softmax 分类器，并可用于分类器引导生成。

Conclusion: ZClassifier 通过将确定性 logits 替换为对角高斯分布 logits，并在 CIFAR-10 和 CIFAR-100 上进行实验，证明了其在鲁棒性、校准和潜在分离方面优于 softmax 分类器，并有效地用于分类器引导生成。

Abstract: We introduce a novel classification framework, ZClassifier, that replaces
conventional deterministic logits with diagonal Gaussian-distributed logits.
Our method simultaneously addresses temperature scaling and manifold
approximation by minimizing the Kullback-Leibler (KL) divergence between the
predicted Gaussian distributions and a unit isotropic Gaussian. This unifies
uncertainty calibration and latent control in a principled probabilistic
manner, enabling a natural interpretation of class confidence and geometric
consistency. Experiments on CIFAR-10 and CIFAR-100 show that ZClassifier
improves over softmax classifiers in robustness, calibration, and latent
separation. We also demonstrate its effectiveness for classifier-guided
generation by interpreting logits as Gaussian semantic potentials.

</details>


### [172] [First-of-its-kind AI model for bioacoustic detection using a lightweight associative memory Hopfield neural network](https://arxiv.org/abs/2507.10642)
*Andrew Gascoyne,Wendy Lomas*

Main category: cs.LG

TL;DR: 本研究提出了一种新颖的人工智能模型，用于解决生物声学分析中的数据量大、训练数据有限、环境影响和硬件要求高等问题。该模型采用霍普菲尔德神经网络，具有训练速度快、处理速度快、内存占用小、精度高等优点，适用于多种个人设备，并有潜力在野外部署。


<details>
  <summary>Details</summary>
Motivation: 人工智能模型在生物声学分析中的应用面临着训练数据有限、环境影响（尤其是能耗和碳足迹）以及硬件要求高这几个关键问题。在本研究中，我们提出了一种可以缓解这些问题的人工智能模型。

Method: 我们使用透明、可解释的霍普菲尔德神经网络通过联想记忆来存储信号并检测相似信号，然后可用于对物种进行分类。

Result: 该模型训练速度快（3毫秒），仅需要每个目标声音的代表性信号即可。该模型处理速度快，在标准的Apple MacBook Air上处理和分类所有10384个公开的蝙蝠录音仅需5.4秒。该模型内存占用小，仅为144.09MB RAM。该模型的精度高达86%，并且在人工识别方面没有发现模型识别不一致的情况。

Conclusion: 我们提出了一个公平的人工智能模型，该模型有潜力成为快速、轻量级、可持续、透明、可解释和准确的生物声学分析的变革者。

Abstract: A growing issue within conservation bioacoustics is the task of analysing the
vast amount of data generated from the use of passive acoustic monitoring
devices. In this paper, we present an alternative AI model which has the
potential to help alleviate this problem. Our model formulation addresses the
key issues encountered when using current AI models for bioacoustic analysis,
namely the: limited training data available; environmental impact, particularly
in energy consumption and carbon footprint of training and implementing these
models; and associated hardware requirements. The model developed in this work
uses associative memory via a transparent, explainable Hopfield neural network
to store signals and detect similar signals which can then be used to classify
species. Training is rapid ($3$\,ms), as only one representative signal is
required for each target sound within a dataset. The model is fast, taking only
$5.4$\,s to pre-process and classify all $10384$ publicly available bat
recordings, on a standard Apple MacBook Air. The model is also lightweight with
a small memory footprint of $144.09$\,MB of RAM usage. Hence, the low
computational demands make the model ideal for use on a variety of standard
personal devices with potential for deployment in the field via edge-processing
devices. It is also competitively accurate, with up to $86\%$ precision on the
dataset used to evaluate the model. In fact, we could not find a single case of
disagreement between model and manual identification via expert field guides.
Although a dataset of bat echolocation calls was chosen to demo this
first-of-its-kind AI model, trained on only two representative calls, the model
is not species specific. In conclusion, we propose an equitable AI model that
has the potential to be a game changer for fast, lightweight, sustainable,
transparent, explainable and accurate bioacoustic analysis.

</details>


### [173] [A Simple Approximate Bayesian Inference Neural Surrogate for Stochastic Petri Net Models](https://arxiv.org/abs/2507.10714)
*Bright Kwaku Manu,Trevor Reckell,Beckett Sterner,Petar Jevtic*

Main category: cs.LG

TL;DR: A neural network surrogate model is proposed for parameter estimation in Stochastic Petri Nets with covariate-dependent rates and partial observations, achieving accurate and fast results with uncertainty quantification.


<details>
  <summary>Details</summary>
Motivation: Parameter estimation for Stochastic Petri Nets (SPNs) is challenging, especially when transition rates depend on external covariates and explicit likelihoods are unavailable.

Method: We introduce a neural-surrogate framework that predicts the coefficients of known covariate-dependent rate functions directly from noisy, partially observed token trajectories using a lightweight 1D Convolutional Residual Network trained end-to-end on Gillespie-simulated SPN realizations. Monte Carlo dropout is used during inference for uncertainty quantification.

Result: Our surrogate recovers rate-function coefficients with an RMSE = 0.108 on synthetic SPNs with 20% missing events, and is substantially faster than traditional Bayesian approaches.

Conclusion: We demonstrate that data-driven, likelihood-free surrogates can enable accurate, robust, and real-time parameter recovery in complex, partially observed discrete-event systems.

Abstract: Stochastic Petri Nets (SPNs) are an increasingly popular tool of choice for
modeling discrete-event dynamics in areas such as epidemiology and systems
biology, yet their parameter estimation remains challenging in general and in
particular when transition rates depend on external covariates and explicit
likelihoods are unavailable. We introduce a neural-surrogate
(neural-network--based approximation of the posterior distribution) framework
that predicts the coefficients of known covariate-dependent rate functions
directly from noisy, partially observed token trajectories. Our model employs a
lightweight 1D Convolutional Residual Network trained end-to-end on
Gillespie-simulated SPN realizations, learning to invert system dynamics under
realistic conditions of event dropout. During inference, Monte Carlo dropout
provides calibrated uncertainty bounds together with point estimates. On
synthetic SPNs with 20% missing events, our surrogate recovers rate-function
coefficients with an RMSE = 0.108 and substantially runs faster than
traditional Bayesian approaches. These results demonstrate that data-driven,
likelihood-free surrogates can enable accurate, robust, and real-time parameter
recovery in complex, partially observed discrete-event systems.

</details>


### [174] [Ground-Compose-Reinforce: Tasking Reinforcement Learning Agents through Formal Language](https://arxiv.org/abs/2507.10741)
*Andrew C. Li,Toryn Q. Klassen,Andrew Wang,Parand A. Alamdari,Sheila A. McIlraith*

Main category: cs.LG

TL;DR: 提出了一种名为Ground-Compose-Reinforce的神经符号框架，用于将形式语言接地并指导RL代理完成任务。该方法通过数据驱动学习避免了手动设计，并通过组合形式语言实现了高效的数据接地和泛化能力。实验证明该方法在处理语言指令和机器人控制方面优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 在构建能够通过语言与人类互动的情境代理时，将语言与复杂感知（如像素）和动作联系起来是一个关键挑战。以往的研究通常通过手动设计语言接地或整理大量将语言与环境元素关联起来的数据集来解决此问题。

Method: 提出了一种名为Ground-Compose-Reinforce的神经符号框架，用于从数据中实现形式语言的接地，并通过语言直接给强化学习（RL）代理任务来引发行为。

Result: 在基于图像的网格世界和MuJoCo机器人领域进行了实验，证明了该方法在数据有限的情况下能够可靠地将形式语言指令映射到行为，而端到端的、数据驱动的方法则会失败。

Conclusion: 该框架能够以数据驱动的方式，将形式语言可靠地映射到行为，并且具有数据效率和泛化能力，能够处理任意的语言组合。

Abstract: Grounding language in complex perception (e.g. pixels) and action is a key
challenge when building situated agents that can interact with humans via
language. In past works, this is often solved via manual design of the language
grounding or by curating massive datasets relating language to elements of the
environment. We propose Ground-Compose-Reinforce, a neurosymbolic framework for
grounding formal language from data, and eliciting behaviours by directly
tasking RL agents through this language. By virtue of data-driven learning, our
framework avoids the manual design of domain-specific elements like reward
functions or symbol detectors. By virtue of compositional formal language
semantics, our framework achieves data-efficient grounding and generalization
to arbitrary language compositions. Experiments on an image-based gridworld and
a MuJoCo robotics domain show that our approach reliably maps formal language
instructions to behaviours with limited data while end-to-end, data-driven
approaches fail.

</details>


### [175] [A Benchmarking Framework for AI models in Automotive Aerodynamics](https://arxiv.org/abs/2507.10747)
*Kaustubh Tangsali,Rishikesh Ranade,Mohammad Amin Nabian,Alexey Kamenev,Peter Sharpe,Neil Ashton,Ram Cherukuri,Sanjay Choudhry*

Main category: cs.LG

TL;DR: 该框架通过提供标准化的方法来比较AI模型，增强了性能评估的透明度和一致性，旨在加速该领域的研发和创新。


<details>
  <summary>Details</summary>
Motivation: 为了加速该领域的研发和创新，提高对这些模型的理解和开发。

Method: 在开源NVIDIA PhysicsNeMo-CFD框架内引入了一个基准测试框架，用于系统地评估AI模型在汽车空气动力学预测方面的准确性、性能、可扩展性和泛化能力。该框架是开放且可扩展的，能够纳入计算机辅助工程（CAE）社区相关的多种度量标准。通过提供标准化的方法来比较AI模型，该框架增强了性能评估的透明度和一致性。

Result: 该框架通过对表面和体积流场预测进行评估，并对三种AI模型（DoMINO、X-MeshGraphNet和FIGConvNet）使用DrivAerML数据集进行了评估，以展示其效用。它还包括了集成其他模型和数据集的指南，使其能够通过物理上一致的指标进行扩展。

Conclusion: 该框架通过对表面和体积流场预测进行评估，并对三种AI模型（DoMINO、X-MeshGraphNet和FIGConvNet）使用DrivAerML数据集进行了评估，以展示其效用。它还包括了集成其他模型和数据集的指南，使其能够通过物理上一致的指标进行扩展。这项基准研究旨在使研究人员和行业专业人士能够选择、优化和推进由AI驱动的空气动力学建模方法，最终促进在汽车空气动力学领域开发更高效、更准确和更具可解释性的解决方案。

Abstract: In this paper, we introduce a benchmarking framework within the open-source
NVIDIA PhysicsNeMo-CFD framework designed to systematically assess the
accuracy, performance, scalability, and generalization capabilities of AI
models for automotive aerodynamics predictions. The open extensible framework
enables incorporation of a diverse set of metrics relevant to the
Computer-Aided Engineering (CAE) community. By providing a standardized
methodology for comparing AI models, the framework enhances transparency and
consistency in performance assessment, with the overarching goal of improving
the understanding and development of these models to accelerate research and
innovation in the field. To demonstrate its utility, the framework includes
evaluation of both surface and volumetric flow field predictions on three AI
models: DoMINO, X-MeshGraphNet, and FIGConvNet using the DrivAerML dataset. It
also includes guidelines for integrating additional models and datasets, making
it extensible for physically consistent metrics. This benchmarking study aims
to enable researchers and industry professionals in selecting, refining, and
advancing AI-driven aerodynamic modeling approaches, ultimately fostering the
development of more efficient, accurate, and interpretable solutions in
automotive aerodynamics

</details>


### [176] [Spatial Reasoners for Continuous Variables in Any Domain](https://arxiv.org/abs/2507.10768)
*Bart Pogodzinski,Christopher Wewer,Bernt Schiele,Jan Eric Lenssen*

Main category: cs.LG

TL;DR: Spatial Reasoners 是一个用于生成式空间推理的软件框架，简化了使用去噪模型处理连续变量的过程。


<details>
  <summary>Details</summary>
Motivation: 由于存在多种去噪模型、采样器和推理策略，因此为生成式推理提供基础设施需要付出巨大的努力。该框架旨在简化这一过程。

Method: 该框架提供了易于使用的接口来控制变量映射（从任意数据域到生成模型范式）和推理策略。

Result: 该框架允许研究人员轻松地将任意数据域中的变量映射到生成模型范式，并控制推理策略，从而促进了生成式推理的研究。

Conclusion: Spatial Reasoners 是一个开源软件框架，旨在使用生成式去噪模型对连续变量进行空间推理，旨在促进该领域的研究。

Abstract: We present Spatial Reasoners, a software framework to perform spatial
reasoning over continuous variables with generative denoising models. Denoising
generative models have become the de-facto standard for image generation, due
to their effectiveness in sampling from complex, high-dimensional
distributions. Recently, they have started being explored in the context of
reasoning over multiple continuous variables. Providing infrastructure for
generative reasoning with such models requires a high effort, due to a wide
range of different denoising formulations, samplers, and inference strategies.
Our presented framework aims to facilitate research in this area, providing
easy-to-use interfaces to control variable mapping from arbitrary data domains,
generative model paradigms, and inference strategies. Spatial Reasoners are
openly available at https://spatialreasoners.github.io/

</details>


### [177] [A Generalizable Physics-Enhanced State Space Model for Long-Term Dynamics Forecasting in Complex Environments](https://arxiv.org/abs/2507.10792)
*Yuchen Wang,Hongjue Zhao,Haohong Lin,Enze Xu,Lifang He,Huajie Shao*

Main category: cs.LG

TL;DR: 提出Phy-SSM，一种结合物理知识和状态空间模型（SSM）的方法，用于处理复杂环境中数据噪声大、采样不规则的长期动态预测问题。该方法通过将部分物理知识融入SSM，并引入物理状态正则化项，提升了模型的泛化和长期预测能力，在多个真实世界场景下验证了其优越性。


<details>
  <summary>Details</summary>
Motivation: SSM能够有效地捕捉序列数据中的长期依赖关系并对连续动态系统进行建模，而引入物理知识可以提高泛化能力。

Method: 提出了一种名为Phy-SSM的通用方法，该方法将部分物理知识集成到状态空间模型（SSM）中，用于复杂环境中的长期动态预测。具体地，将部分已知的系统动态分解为已知的和未知的状态矩阵，并将其集成到Phy-SSM单元中。此外，引入了一个物理状态正则化项，使估计的潜在状态与系统动态对齐，并从理论上分析了该方法的解的唯一性。

Result: 在车辆运动预测、无人机状态预测和COVID-19流行病学预测三个真实世界应用中，Phy-SSM在长期插值和外推任务上的表现均优于现有基线方法。

Conclusion: Phy-SSM在长期插值和外推任务中表现优于基线方法，并在车辆运动预测、无人机状态预测和COVID-19流行病学预测三个真实世界应用中进行了广泛的实验验证。

Abstract: This work aims to address the problem of long-term dynamic forecasting in
complex environments where data are noisy and irregularly sampled. While recent
studies have introduced some methods to improve prediction performance, these
approaches still face a significant challenge in handling long-term
extrapolation tasks under such complex scenarios. To overcome this challenge,
we propose Phy-SSM, a generalizable method that integrates partial physics
knowledge into state space models (SSMs) for long-term dynamics forecasting in
complex environments. Our motivation is that SSMs can effectively capture
long-range dependencies in sequential data and model continuous dynamical
systems, while the incorporation of physics knowledge improves generalization
ability. The key challenge lies in how to seamlessly incorporate partially
known physics into SSMs. To achieve this, we decompose partially known system
dynamics into known and unknown state matrices, which are integrated into a
Phy-SSM unit. To further enhance long-term prediction performance, we introduce
a physics state regularization term to make the estimated latent states align
with system dynamics. Besides, we theoretically analyze the uniqueness of the
solutions for our method. Extensive experiments on three real-world
applications, including vehicle motion prediction, drone state prediction, and
COVID-19 epidemiology forecasting, demonstrate the superior performance of
Phy-SSM over the baselines in both long-term interpolation and extrapolation
tasks. The code is available at https://github.com/511205787/Phy_SSM-ICML2025.

</details>


### [178] [Multi-Armed Sampling Problem and the End of Exploration](https://arxiv.org/abs/2507.10797)
*Mohammad Pedramfar,Siamak Ravanbakhsh*

Main category: cs.LG

TL;DR: 本文提出了多臂采样框架，作为多臂老虎机优化问题的采样对应。研究了采样中的探索-利用权衡，建立了后悔下界，并提出了最优算法。发现采样不需探索。通过温度参数统一了多臂采样和多臂老虎机问题。该框架可为采样研究（包括神经采样器）奠定基础，并有助于理解熵正则化强化学习、模型微调和RLHF的探索需求与收敛性。


<details>
  <summary>Details</summary>
Motivation: 我们研究的主要动机是为了严格审视采样背景下的探索-利用权衡。

Method: 我们定义了多臂采样框架，并提出了一个能达到最优后悔界限的算法。此外，我们还定义了一个连续的问题族及其相关的后悔度量，该度量使用温度参数来平滑地插值和统一多臂采样与多臂老虎机问题。

Result: 我们为多臂采样框架建立了相应的下界，并提出了一个能达到最优后悔界限的算法。

Conclusion: 与优化问题不同，采样不需要探索。我们提出的多臂采样框架及其结果可以为包括近期神经采样器在内的采样研究奠定基础，就像多臂老虎机在强化学习中所扮演的角色一样。我们的工作尤其揭示了熵正则化强化学习、预训练模型微调以及具有人类反馈的强化学习（RLHF）的探索需求和算法收敛性。

Abstract: This paper introduces the framework of multi-armed sampling, as the sampling
counterpart to the optimization problem of multi-arm bandits. Our primary
motivation is to rigorously examine the exploration-exploitation trade-off in
the context of sampling. We systematically define plausible notions of regret
for this framework and establish corresponding lower bounds. We then propose a
simple algorithm that achieves these optimal regret bounds. Our theoretical
results demonstrate that in contrast to optimization, sampling does not require
exploration. To further connect our findings with those of multi-armed bandits,
we define a continuous family of problems and associated regret measures that
smoothly interpolates and unifies multi-armed sampling and multi-armed bandit
problems using a temperature parameter. We believe the multi-armed sampling
framework, and our findings in this setting can have a foundational role in the
study of sampling including recent neural samplers, akin to the role of
multi-armed bandits in reinforcement learning. In particular, our work sheds
light on the need for exploration and the convergence properties of algorithm
for entropy-regularized reinforcement learning, fine-tuning of pretrained
models and reinforcement learning with human feedback (RLHF).

</details>


### [179] [Uncovering Causal Relation Shifts in Event Sequences under Out-of-Domain Interventions](https://arxiv.org/abs/2507.10809)
*Kazi Tasnim Zinat,Yun Zhou,Xiang Lyu,Yawei Wang,Zhicheng Liu,Panpan Xu*

Main category: cs.LG

TL;DR: 本研究提出了一种新的因果框架和基于Transformer的神经网络模型，用于在存在域外干预的情况下推断时间事件序列中的因果关系。


<details>
  <summary>Details</summary>
Motivation: 现有因果推断方法主要关注特定领域内的事件类型，忽视了外源性域外干预的影响，而这种影响在现实世界中会显著改变因果动态。

Method: 提出了一种新的因果框架来定义平均处理效应（ATE），以捕捉外源性域外干预下时间过程事件之间的因果关系转移，并设计了一个无偏ATE估计器，以及一个基于Transformer的神经网络模型来处理长期时间依赖性和局部模式，同时将外源性域外干预信息整合到过程建模中。

Result: 在模拟和真实世界数据集上的大量实验表明，所提出的方法在ATE估计和外源性域外干预增强点过程的拟合优度方面优于现有基线方法。

Conclusion: 所提出的新因果框架能够超出经典鲁宾因果框架在独立同分布数据上的限制，以捕捉外源性域外干预下时间过程事件之间的因果关系转移。所提出的无偏ATE估计器和基于Transformer的神经网络模型能够处理长期时间依赖性和局部模式，并将外源性干预信息整合到过程建模中。实验证明，该方法在ATE估计和拟合优度方面优于现有方法。

Abstract: Inferring causal relationships between event pairs in a temporal sequence is
applicable in many domains such as healthcare, manufacturing, and
transportation. Most existing work on causal inference primarily focuses on
event types within the designated domain, without considering the impact of
exogenous out-of-domain interventions. In real-world settings, these
out-of-domain interventions can significantly alter causal dynamics. To address
this gap, we propose a new causal framework to define average treatment effect
(ATE), beyond independent and identically distributed (i.i.d.) data in classic
Rubin's causal framework, to capture the causal relation shift between events
of temporal process under out-of-domain intervention. We design an unbiased ATE
estimator, and devise a Transformer-based neural network model to handle both
long-range temporal dependencies and local patterns while integrating
out-of-domain intervention information into process modeling. Extensive
experiments on both simulated and real-world datasets demonstrate that our
method outperforms baselines in ATE estimation and goodness-of-fit under
out-of-domain-augmented point processes.

</details>


### [180] [Semantic Context for Tool Orchestration](https://arxiv.org/abs/2507.10820)
*Robert Müller*

Main category: cs.LG

TL;DR: 本文证明了语义上下文（SC）是工具编排的关键，并提出了SC-LinUCB和FiReAct流水线，以提高LLM在工具选择和编排方面的效率和适应性。


<details>
  <summary>Details</summary>
Motivation: 为提高工具编排的鲁棒性，本文旨在探索和验证语义上下文（Semantic Context, SC）在利用描述性工具信息方面的基础作用。

Method: 本文提出了使用上下文老虎机（contextual bandits）的理论基础，引入了SC-LinUCB算法，并证明了其在动态动作空间中具有更低的遗憾（regret）和更好的适应性。此外，研究还提供了大规模语言模型（LLM）的并行实证验证，并提出了FiReAct流水线。

Result: 研究表明，语义上下文（SC）是实现鲁棒工具编排的基础。SC-LinUCB在动态动作空间中表现出更低的遗憾和更好的适应性。在静态和非平稳设置中，SC对于大规模语言模型（LLM）的上下文学习至关重要。FiReAct流水线在包含超过10,000个工具的基准测试中，证明了SC驱动的检索能够使LLM有效地编排大型动作空间。

Conclusion: 该研究为构建更具样本效率、自适应性和可扩展性的工具编排代理提供了全面的指导。

Abstract: This paper demonstrates that Semantic Context (SC), leveraging descriptive
tool information, is a foundational component for robust tool orchestration.
Our contributions are threefold. First, we provide a theoretical foundation
using contextual bandits, introducing SC-LinUCB and proving it achieves lower
regret and adapts favourably in dynamic action spaces. Second, we provide
parallel empirical validation with Large Language Models, showing that SC is
critical for successful in-context learning in both static (efficient learning)
and non-stationary (robust adaptation) settings. Third, we propose the FiReAct
pipeline, and demonstrate on a benchmark with over 10,000 tools that SC-based
retrieval enables an LLM to effectively orchestrate over a large action space.
These findings provide a comprehensive guide to building more sample-efficient,
adaptive, and scalable orchestration agents.

</details>


### [181] [From Small to Large: A Graph Convolutional Network Approach for Solving Assortment Optimization Problems](https://arxiv.org/abs/2507.10834)
*Guokai Li,Pin Gao,Stefanus Jasin,Zizhuo Wang*

Main category: cs.LG

TL;DR: 使用图卷积网络（GCN）解决 ассортимент优化问题，在大规模实例上实现了高效和高性能，并可扩展到模型无关的场景。


<details>
  <summary>Details</summary>
Motivation: 解决经典的、通常是 NP-hard 的 ассортимент优化问题，该问题在收入管理和多个行业中有应用。

Method: 将 ассортимент问题表示为图，然后训练 GCN 来学习最优 ассортимент的模式，最后提出两种基于 GCN 输出的推理策略。

Result: 在小规模实例上训练的 GCN 可以在几秒钟内处理大规模实例（最多 2,000 种产品），达到 90% 以上的最优性能，优于现有的启发式策略。该方法在模型无关的设置中也显示出有效性。

Conclusion: 图卷积网络（GCN）可以有效地解决混合多项式逻辑斯蒂选择模型下的约束 ассортимент优化问题，并且该方法能够泛化到大规模实例，在效率和性能上优于现有启发式策略。此外，该框架还可以扩展到模型无关的设置。

Abstract: Assortment optimization involves selecting a subset of substitutable products
(subject to certain constraints) to maximize the expected revenue. It is a
classic problem in revenue management and finds applications across various
industries. However, the problem is usually NP-hard due to its combinatorial
and non-linear nature. In this work, we explore how graph concolutional
networks (GCNs) can be leveraged to efficiently solve constrained assortment
optimization under the mixed multinomial logit choice model. We first develop a
graph representation of the assortment problem, then train a GCN to learn the
patterns of optimal assortments, and lastly propose two inference policies
based on the GCN's output. Due to the GCN's inherent ability to generalize
across inputs of varying sizes, we can use a GCN trained on small-scale
instances to facilitate large-scale instances. Extensive numerical experiments
demonstrate that given a GCN trained on small-scale instances (e.g., with 20
products), the proposed policies can achieve superior performance (90%+
optimality) on large-scale instances (with up to 2,000 products) within
seconds, which outperform existing heuristic policies in both performance and
efficiency. Furthermore, we extend our framework to a model-free setting where
the underlying choice model is unknown but transaction data is available. We
also conduct numerical experiments to demonstrate the effectiveness and
efficiency of our proposed policies in this setting.

</details>


### [182] [Offline Reinforcement Learning with Wasserstein Regularization via Optimal Transport Maps](https://arxiv.org/abs/2507.10843)
*Motoki Omura,Yusuke Mukuta,Kazuki Ota,Takayuki Osa,Tatsuya Harada*

Main category: cs.LG

TL;DR: 一种新的离线强化学习方法，利用Wasserstein距离和ICNNs解决分布偏移问题，在D4RL基准测试中表现优异。


<details>
  <summary>Details</summary>
Motivation: 为了解决离线强化学习（RL）中由策略与数据集分布不匹配引起的分布偏移问题，并提出一种比基于f散度等密度比率度量更鲁胺分布外数据的正则化方法。

Method: 提出一种利用Wasserstein距离来处理离线强化学习中分布偏移问题的方法，该方法使用输入凸神经网络（ICNNs）来模拟最优传输映射，从而避免了对抗性训练，保证了学习的稳定性。

Result: 在D4RL基准数据集上，与现有方法相比，该方法实现了相当或更优的性能。

Conclusion: 该方法在D4RL基准数据集上实现了与现有方法相当或更优的性能。

Abstract: Offline reinforcement learning (RL) aims to learn an optimal policy from a
static dataset, making it particularly valuable in scenarios where data
collection is costly, such as robotics. A major challenge in offline RL is
distributional shift, where the learned policy deviates from the dataset
distribution, potentially leading to unreliable out-of-distribution actions. To
mitigate this issue, regularization techniques have been employed. While many
existing methods utilize density ratio-based measures, such as the
$f$-divergence, for regularization, we propose an approach that utilizes the
Wasserstein distance, which is robust to out-of-distribution data and captures
the similarity between actions. Our method employs input-convex neural networks
(ICNNs) to model optimal transport maps, enabling the computation of the
Wasserstein distance in a discriminator-free manner, thereby avoiding
adversarial training and ensuring stable learning. Our approach demonstrates
comparable or superior performance to widely used existing methods on the D4RL
benchmark dataset. The code is available at
https://github.com/motokiomura/Q-DOT .

</details>


### [183] [Collaboration Promotes Group Resilience in Multi-Agent RL](https://arxiv.org/abs/2111.06614)
*Ilai Shraga,Guy Azran,Matthias Gerstgrasser,Ofir Abu,Jeffrey S. Rosenschein,Sarah Keren*

Main category: cs.LG

TL;DR: 本研究提出了群体弹性的概念，并证明了协作在提高 MARL 中代理对环境扰动的适应性方面的作用。


<details>
  <summary>Details</summary>
Motivation: 为了在各种动态场景中有效运行，RL代理必须对环境的意外变化具有弹性。此前的关于这种形式弹性的研究集中在单代理设置上。本研究工作介绍了并形式化了弹性的多代理变体，我们称之为群体弹性。

Method: 通过评估不同的协作协议并检查它们对群体弹性的影响来检验假设。

Result: 实验表明，与非协作方法相比，所有检查的协作方法都实现了更高的群体弹性。

Conclusion: 与非协作方法相比，所有检查的协作方法都实现了更高的群体弹性。

Abstract: To effectively operate in various dynamic scenarios, RL agents must be
resilient to unexpected changes in their environment. Previous work on this
form of resilience has focused on single-agent settings. In this work, we
introduce and formalize a multi-agent variant of resilience, which we term
group resilience. We further hypothesize that collaboration with other agents
is key to achieving group resilience; collaborating agents adapt better to
environmental perturbations in multi-agent reinforcement learning (MARL)
settings. We test our hypothesis empirically by evaluating different
collaboration protocols and examining their effect on group resilience. Our
experiments show that all the examined collaborative approaches achieve higher
group resilience than their non-collaborative counterparts.

</details>


### [184] [Visually grounded emotion regulation via diffusion models and user-driven reappraisal](https://arxiv.org/abs/2507.10861)
*Edoardo Pinzuti,Oliver Tüscher,André Ferreira Castro*

Main category: cs.LG

TL;DR: 本研究提出了一种利用AI生成视觉反馈来增强认知重评（一种情绪调节技术）的新方法，特别适用于那些难以进行传统语言重评的个体。实验结果显示，AI辅助重评能有效降低负面情绪，且重评内容与AI生成图像的情感一致性越高，效果越好。


<details>
  <summary>Details</summary>
Motivation: 尽管认知重评在临床和认知科学中起着核心作用，但现实世界的重评干预仍然需要大量的认知资源，并且主要是抽象和语言化的。这种对更高认知和语言过程的依赖在有创伤或抑郁症的个体中常常受损，这限制了标准方法的有效性。

Method: 本研究提出了一种新颖的、基于视觉的认知重评方法，该方法通过整合大型文本到图像扩散模型来增强情绪调节过程。具体来说，我们引入了一个系统，用户通过口头重评来重新解释负面情绪图像，然后使用经过微调的IP适配器的稳定扩散模型将其转化为支持性的、情绪上一致的可视化效果。这种生成式转换在视觉上实例化了用户的重评，同时保持了与原始刺激的结构相似性，从而外化和加强了调节意图。为了测试这种方法，我们进行了一项（N = 20）被试内实验，使用修改后的认知情绪调节（CER）任务。参与者或重评或描述了来自国际心智图片系统（IAPS）的负面图片，并辅以或不辅以人工智能生成的视觉反馈。

Result: 结果表明，与非人工智能和对照组相比，人工智能辅助重评能显著降低负面情绪。进一步的分析表明，参与者重评和生成图像之间的情感一致性与情绪缓解相关，这表明多模态一致性增强了调节效果。

Conclusion: 本研究表明，生成式视觉输入可以支持认知重评，并在生成式人工智能、情感计算和治疗技术交叉领域开辟了新的方向。

Abstract: Cognitive reappraisal is a key strategy in emotion regulation, involving
reinterpretation of emotionally charged stimuli to alter affective responses.
Despite its central role in clinical and cognitive science, real-world
reappraisal interventions remain cognitively demanding, abstract, and primarily
verbal. This reliance on higher-order cognitive and linguistic processes is
often impaired in individuals with trauma or depression, limiting the
effectiveness of standard approaches. Here, we propose a novel, visually based
augmentation of cognitive reappraisal by integrating large-scale text-to-image
diffusion models into the emotional regulation process. Specifically, we
introduce a system in which users reinterpret emotionally negative images via
spoken reappraisals, which are transformed into supportive, emotionally
congruent visualizations using stable diffusion models with a fine-tuned
IP-adapter. This generative transformation visually instantiates users'
reappraisals while maintaining structural similarity to the original stimuli,
externalizing and reinforcing regulatory intent. To test this approach, we
conducted a within-subject experiment (N = 20) using a modified cognitive
emotion regulation (CER) task. Participants reappraised or described aversive
images from the International Affective Picture System (IAPS), with or without
AI-generated visual feedback. Results show that AI-assisted reappraisal
significantly reduced negative affect compared to both non-AI and control
conditions. Further analyses reveal that sentiment alignment between
participant reappraisals and generated images correlates with affective relief,
suggesting that multimodal coherence enhances regulatory efficacy. These
findings demonstrate that generative visual input can support cogitive
reappraisal and open new directions at the intersection of generative AI,
affective computing, and therapeutic technology.

</details>


### [185] [Domain-Adaptive Small Language Models for Structured Tax Code Prediction](https://arxiv.org/abs/2507.10880)
*Souvik Nath,Sumit Wadhwa,Luiz Perez*

Main category: cs.LG

TL;DR: 该研究提出了一种创新的方法，利用域自适应小型语言模型 (SLM) 和编码器-解码器架构来精确预测产品和服务的税收代码，解决了跨国公司在税务合规方面面临的挑战。


<details>
  <summary>Details</summary>
Motivation: 跨国公司需要处理大量交易，并遵守各司法管辖区不同且复杂的税收法规。准确确定产品和服务税收代码（如 HSN 或 SAC）对于避免税务处罚至关重要。

Method: 提出了一种具有编码器-解码器架构的域自适应小型语言模型 (SLM)，用于改进产品和服务的税收代码预测。该方法解决了使用非结构化产品和服务数据预测分层税收代码序列的问题。

Result: 实验证明，基于编码器-解码器架构的 SLM 成功应用于结构化税收代码的顺序预测，该领域在当前 NLP 研究中探索较少。

Conclusion: 所提出的基于域自适应编码器-解码器 SLM 的方法在 HSN 码的顺序预测方面表现优于扁平分类器，并且在结构化序列生成任务方面优于仅解码器和仅编码器架构。

Abstract: Every day, multinational firms process thousands of transactions, each of
which must adhere to tax regulations that vary by jurisdiction and are often
nuanced. The determination of product and service tax codes, such as HSN or SAC
is a major use case in Tax compliance. An accurate determination of such codes
is imperative to avoid any tax penalties. This paper proposes a domain-adaptive
small language model (SLM) with an encoder-decoder architecture for the
enhanced prediction of product and service tax codes. In this approach, we
address the problem of predicting hierarchical tax code sequences using
unstructured product and services data. We employ an SLM based upon
encoder-decoder architecture as this enables sequential generation of tax codes
to capture the hierarchical dependencies present within the tax codes. Our
experiments demonstrate that encoder-decoder SLMs can be successfully applied
to the sequential prediction of structured tax codes, a domain that remains
comparatively unexplored in current NLP research. In this paper, we demonstrate
the superior performance of the domain-adaptive encoder-decoder SLMs over flat
classifiers when applied to the Harmonized System of Nomenclature (HSN), and
achieve superior results compared to decoder-only and encoder-only
architectures for structured sequence generation tasks. This approach can also
be scaled to other government-mandated tax commodity codes, such as United
Nations Standard Products and Services Codes (UNSPSC), or Brazil's Nomenclatura
Comum do Mercosul (NCM).

</details>


### [186] [Learning from Imperfect Data: Robust Inference of Dynamic Systems using Simulation-based Generative Model](https://arxiv.org/abs/2507.10884)
*Hyunwoo Cho,Hyeontae Jo,Hyung Ju Hwang*

Main category: cs.LG

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: System inference for nonlinear dynamic models, represented by ordinary
differential equations (ODEs), remains a significant challenge in many fields,
particularly when the data are noisy, sparse, or partially observable. In this
paper, we propose a Simulation-based Generative Model for Imperfect Data
(SiGMoID) that enables precise and robust inference for dynamic systems. The
proposed approach integrates two key methods: (1) physics-informed neural
networks with hyper-networks that constructs an ODE solver, and (2) Wasserstein
generative adversarial networks that estimates ODE parameters by effectively
capturing noisy data distributions. We demonstrate that SiGMoID quantifies data
noise, estimates system parameters, and infers unobserved system components.
Its effectiveness is validated validated through realistic experimental
examples, showcasing its broad applicability in various domains, from
scientific research to engineered systems, and enabling the discovery of full
system dynamics.

</details>


### [187] [How to Protect Models against Adversarial Unlearning?](https://arxiv.org/abs/2507.10886)
*Patryk Jasiorski,Marek Klonowski,Michał Woźniak*

Main category: cs.LG

TL;DR: 遗忘AI模型知识以满足法律和数据需求，但可能损害模型性能。本研究提出了一种对抗性遗忘方法，并介绍了一种新的保护模型性能免受遗忘负面影响的方法。


<details>
  <summary>Details</summary>
Motivation: AI模型需要满足如AI法案或GDPR等法律要求，以及移除有毒内容、消除偏见、应对恶意实例影响或数据分布结构变化的需求，但遗忘知识可能导致模型性能下降。

Method: 提出了一种新的方法来保护模型性能免受遗忘的负面影响，同时考虑了自发过程和对手行为。

Result: 研究表明，对抗性遗忘现象及对手的能力取决于模型架构和遗忘数据选择策略，并提出了一种新的保护模型性能的方法。

Conclusion: 该研究提出了一种新的方法来保护模型性能，以应对自发过程和对手行为导致的负面影响，并强调了模型架构和数据选择策略在对抗性遗忘中的重要性。

Abstract: AI models need to be unlearned to fulfill the requirements of legal acts such
as the AI Act or GDPR, and also because of the need to remove toxic content,
debiasing, the impact of malicious instances, or changes in the data
distribution structure in which a model works. Unfortunately, removing
knowledge may cause undesirable side effects, such as a deterioration in model
performance. In this paper, we investigate the problem of adversarial
unlearning, where a malicious party intentionally sends unlearn requests to
deteriorate the model's performance maximally. We show that this phenomenon and
the adversary's capabilities depend on many factors, primarily on the backbone
model itself and strategy/limitations in selecting data to be unlearned. The
main result of this work is a new method of protecting model performance from
these side effects, both in the case of unlearned behavior resulting from
spontaneous processes and adversary actions.

</details>


### [188] [Outbound Modeling for Inventory Management](https://arxiv.org/abs/2507.10890)
*Riccardo Savorgnan,Udaya Ghai,Carson Eisenach,Dean Foster*

Main category: cs.LG

TL;DR: 该研究提出了一种新的概率预测模型，用于准确预测库存仓库的单位流失和运输成本，以支持强化学习在库存管理中的应用，并设计了一种验证方案来评估模型在不同场景下的性能。


<details>
  <summary>Details</summary>
Motivation: 为了提高区域库存规划的准确性，特别是为了支持强化学习（RL）控制策略的开发，需要对复杂的生产系统中的单位流失和运输成本进行建模。现有的模拟方法由于其不可微和成本高昂的特性，不适用于RL训练环境。

Method: 将库存仓库的单位流失和相关运输成本的预测问题，建模为概率预测问题。通过对所有仓库的单位流失和运输成本的联合分布进行建模，并以库存量和外源性客户需求作为条件，来解决复杂的生产系统和非可微的模拟问题。此外，还提出了一种利用生产系统来评估因强化学习策略引起的潜在库存状态的模型验证方案。

Result: 提出的概率预测模型在分布内场景下能够准确预测单位流失和运输成本，但需要进一步的验证来评估其在分布外场景和实际应用中的表现。

Conclusion: 基于对所提出方法的初步评估，该模型在分布内设置下表现出准确性，但需要针对实际应用进行进一步验证。

Abstract: We study the problem of forecasting the number of units fulfilled (or
``drained'') from each inventory warehouse to meet customer demand, along with
the associated outbound shipping costs. The actual drain and shipping costs are
determined by complex production systems that manage the planning and execution
of customers' orders fulfillment, i.e. from where and how to ship a unit to be
delivered to a customer. Accurately modeling these processes is critical for
regional inventory planning, especially when using Reinforcement Learning (RL)
to develop control policies. For the RL usecase, a drain model is incorporated
into a simulator to produce long rollouts, which we desire to be
differentiable. While simulating the calls to the internal software systems can
be used to recover this transition, they are non-differentiable and too slow
and costly to run within an RL training environment. Accordingly, we frame this
as a probabilistic forecasting problem, modeling the joint distribution of
outbound drain and shipping costs across all warehouses at each time period,
conditioned on inventory positions and exogenous customer demand. To ensure
robustness in an RL environment, the model must handle out-of-distribution
scenarios that arise from off-policy trajectories. We propose a validation
scheme that leverages production systems to evaluate the drain model on
counterfactual inventory states induced by RL policies. Preliminary results
demonstrate the model's accuracy within the in-distribution setting.

</details>


### [189] [Class-Proportional Coreset Selection for Difficulty-Separable Data](https://arxiv.org/abs/2507.10904)
*Elisa Tsai,Haizhong Zheng,Atul Prakash*

Main category: cs.LG

TL;DR: 本研究提出了一种新的类别-难度可分离性概念，并开发了相应的度量方法（CDSC）和解决类别不平衡问题的采样策略。实验证明，该方法在数据集修剪任务中表现优于现有技术，尤其是在处理不平衡和大规模数据集时，能显著提高模型的效率和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有数据集修剪方法（如单次共同体选择）通常假设数据难度在类别之间是同质的，但研究发现数据难度在不同类别之间可能存在差异，这会导致类别不可知方法过度代表易类别而忽略了稀有但信息丰富的类别。

Method: 提出了一种名为类别难度可分离性系数（CDSC）的量化度量方法，并引入了多种采样策略的类别比例变体，以解决类别不可知共同体选择方法中类别-难度同质性假设的问题。

Result: 在五个跨越安全和医学领域的不同数据集上进行的评估表明，所提出的类别比例方法在数据效率方面始终达到最先进水平。例如，在CTU-13数据集上，在99%的极端修剪率下，一种名为CCS-CP的类别比例变体在准确率、精确率和召回率方面的下降幅度远小于类别不可知的基线方法。此外，研究还表明，激进的修剪可以增强模型在噪声、不平衡和大规模数据集上的泛化能力。

Conclusion: 显式地对类别-难度可分离性进行建模，可以实现更有效、更鲁棒和更具泛化能力的数据修剪，尤其是在高风险场景中。

Abstract: High-quality training data is essential for building reliable and efficient
machine learning systems. One-shot coreset selection addresses this by pruning
the dataset while maintaining or even improving model performance, often
relying on training-dynamics-based data difficulty scores. However, most
existing methods implicitly assume class-wise homogeneity in data difficulty,
overlooking variation in data difficulty across different classes.
  In this work, we challenge this assumption by showing that, in domains such
as network intrusion detection and medical imaging, data difficulty often
clusters by class. We formalize this as class-difficulty separability and
introduce the Class Difficulty Separability Coefficient (CDSC) as a
quantitative measure. We demonstrate that high CDSC values correlate with
performance degradation in class-agnostic coreset methods, which tend to
overrepresent easy majority classes while neglecting rare but informative ones.
  To address this, we introduce class-proportional variants of multiple
sampling strategies. Evaluated on five diverse datasets spanning security and
medical domains, our methods consistently achieve state-of-the-art data
efficiency. For instance, on CTU-13, at an extreme 99% pruning rate, a
class-proportional variant of Coverage-centric Coreset Selection (CCS-CP) shows
remarkable stability, with accuracy dropping only 2.58%, precision 0.49%, and
recall 0.19%. In contrast, the class-agnostic CCS baseline, the next best
method, suffers sharper declines of 7.59% in accuracy, 4.57% in precision, and
4.11% in recall.
  We further show that aggressive pruning enhances generalization in noisy,
imbalanced, and large-scale datasets. Our results underscore that explicitly
modeling class-difficulty separability leads to more effective, robust, and
generalizable data pruning, particularly in high-stakes scenarios.

</details>


### [190] [Diffusion Decoding for Peptide De Novo Sequencing](https://arxiv.org/abs/2507.10955)
*Chi-en Amy Tai,Alexander Wong*

Main category: cs.LG

TL;DR: 本研究探索了使用扩散模型改进肽段 de novo 测序，发现特定扩散解码器设计和 DINOISER 损失函数能显著提高氨基酸召回率。


<details>
  <summary>Details</summary>
Motivation: 为了解决传统自回归模型在肽段 de novo 测序中存在的级联错误和无法有效利用高可信度区域的问题，本研究尝试使用扩散模型。

Method: 本研究采用扩散模型进行肽段 de novo 测序，并设计了三种不同的扩散解码器，同时探索了 knapsack beam search 和多种损失函数。

Result: 研究发现，虽然 knapsack beam search 未能提升性能，但最佳的扩散解码器设计结合 DINOISER 损失函数，在氨基酸召回率方面相比基线模型 Casanovo 提高了 0.373，尽管肽段精确率和召回率仍为 0。

Conclusion: 本研究表明，扩散模型有潜力提高肽段 de novo 测序的准确性，尤其是在提高模型敏感性方面。

Abstract: Peptide de novo sequencing is a method used to reconstruct amino acid
sequences from tandem mass spectrometry data without relying on existing
protein sequence databases. Traditional deep learning approaches, such as
Casanovo, mainly utilize autoregressive decoders and predict amino acids
sequentially. Subsequently, they encounter cascading errors and fail to
leverage high-confidence regions effectively. To address these issues, this
paper investigates using diffusion decoders adapted for the discrete data
domain. These decoders provide a different approach, allowing sequence
generation to start from any peptide segment, thereby enhancing prediction
accuracy. We experiment with three different diffusion decoder designs,
knapsack beam search, and various loss functions. We find knapsack beam search
did not improve performance metrics and simply replacing the transformer
decoder with a diffusion decoder lowered performance. Although peptide
precision and recall were still 0, the best diffusion decoder design with the
DINOISER loss function obtained a statistically significant improvement in
amino acid recall by 0.373 compared to the baseline autoregressive
decoder-based Casanovo model. These findings highlight the potential of
diffusion decoders to not only enhance model sensitivity but also drive
significant advancements in peptide de novo sequencing.

</details>


### [191] [Physics-Informed Neural Networks For Semiconductor Film Deposition: A Review](https://arxiv.org/abs/2507.10983)
*Tao Han,Zahra Taheri,Hyunwoong Ko*

Main category: cs.LG

TL;DR: 本文回顾了机器学习（特别是物理信息神经网络PINNs）在半导体薄膜沉积中的应用，指出了现有技术的优缺点，并提出了改进这些过程的未来研究方向。


<details>
  <summary>Details</summary>
Motivation: 半导体薄膜沉积过程对实现薄膜均匀性、适当附着力和所需功能至关重要，但其复杂性对过程控制提出了挑战。机器学习（ML），特别是物理信息神经网络（PINNs），在解决这些挑战方面显示出巨大潜力，因此有必要对其在半导体薄膜沉积中的应用进行全面回顾和分析。

Method: 本文采用主题分析方法，全面回顾了机器学习（ML）在半导体薄膜沉积过程中的应用，特别是物理信息神经网络（PINNs）。分析了当前方法的优点和局限性，并探讨了将物理知识、控制定律和偏微分方程嵌入到针对半导体制造业的神经网络架构中的策略。

Result: 本文对机器学习在半导体薄膜沉积中的应用进行了全面回顾，识别了关键趋势、局限性和研究空白。讨论了PINNs的应用，并提出了整合PINNs以提高过程性能和运营效率的新研究方向，为该领域未来的研究奠定了基础。

Conclusion: 本文全面回顾了机器学习（ML）在半导体薄膜沉积过程中的应用，重点关注物理信息神经网络（PINNs）。通过主题分析，识别了关键趋势、现有局限性和研究空白，并提出了整合PINNs以提高薄膜沉积过程的解释性、准确性和鲁棒性的策略。最后，本文提出了将PINNs的优势相结合以显著推进薄膜沉积过程的新研究方向，为未来研究在整合物理信息ML框架、解决现有方法论差距以及提高半导体制造业的精度、可扩展性和运营效率方面建立了清晰的路径。

Abstract: Semiconductor manufacturing relies heavily on film deposition processes, such
as Chemical Vapor Deposition and Physical Vapor Deposition. These complex
processes require precise control to achieve film uniformity, proper adhesion,
and desired functionality. Recent advancements in Physics-Informed Neural
Networks (PINNs), an innovative machine learning (ML) approach, have shown
significant promise in addressing challenges related to process control,
quality assurance, and predictive modeling within semiconductor film deposition
and other manufacturing domains. This paper provides a comprehensive review of
ML applications targeted at semiconductor film deposition processes. Through a
thematic analysis, we identify key trends, existing limitations, and research
gaps, offering insights into both the advantages and constraints of current
methodologies. Our structured analysis aims to highlight the potential
integration of these ML techniques to enhance interpretability, accuracy, and
robustness in film deposition processes. Additionally, we examine
state-of-the-art PINN methods, discussing strategies for embedding physical
knowledge, governing laws, and partial differential equations into advanced
neural network architectures tailored for semiconductor manufacturing. Based on
this detailed review, we propose novel research directions that integrate the
strengths of PINNs to significantly advance film deposition processes. The
contributions of this study include establishing a clear pathway for future
research in integrating physics-informed ML frameworks, addressing existing
methodological gaps, and ultimately improving precision, scalability, and
operational efficiency within semiconductor manufacturing.

</details>


### [192] [StellarF: A Lora-Adapter Integrated Large Model Framework for Stellar Flare Forecasting with Historical & Statistical Data](https://arxiv.org/abs/2507.10986)
*Tianyu Su,Zhiqiang Zou,Ali Luo,Xiao Kong,Qingyu Lu,Min Li*

Main category: cs.LG

TL;DR: StellarF是一个利用低秩和适配器技术进行参数高效学习的新型大型模型，用于太阳耀斑预测。它通过结合耀斑统计信息和历史耀斑记录，能够识别多尺度模式，并在实验中展现出优于现有方法的性能。


<details>
  <summary>Details</summary>
Motivation: 为了解决太阳耀斑预测领域中已记录耀斑事件稀疏以及缺乏领域特定大规模预测模型的问题。

Method: 本研究提出了一种名为StellarF的新型大型模型，该模型利用低秩（LoRA）和适配器技术进行参数高效学习，以实现太阳耀斑预测。StellarF集成了耀斑统计信息模块和历史耀斑记录模块，能够从观测数据中识别多尺度模式。

Result: 在利用开普勒和TESS光变曲线构建的数据集上进行的广泛实验表明，StellarF相比现有方法取得了最先进的性能。

Conclusion: 本研究提出的StellarF模型在太阳耀斑预测方面取得了最先进的性能，为天体物理学研究和跨学科应用提供了一个新的方法框架。

Abstract: Stellar flare forecasting, a critical research frontier in astronomy, offers
profound insights into stellar activity. However, the field is constrained by
both the sparsity of recorded flare events and the absence of domain-specific
large-scale predictive models. To address these challenges, this study
introduces StellarF (Stellar Flare Forecasting), a novel large model that
leverages Low-Rank (LoRA) and Adapter techniques to parameter-efficient
learning for stellar flare forecasting. At its core, StellarF integrates an
flare statistical information module with a historical flare record module,
enabling multi-scale pattern recognition from observational data. Extensive
experiments on our self-constructed datasets (derived from Kepler and TESS
light curves) demonstrate that StellarF achieves state-of-the-art performance
compared to existing methods. The proposed prediction paradigm establishes a
novel methodological framework for advancing astrophysical research and
cross-disciplinary applications.

</details>


### [193] [High-Throughput Distributed Reinforcement Learning via Adaptive Policy Synchronization](https://arxiv.org/abs/2507.10990)
*Rodney Lafuente-Mercado*

Main category: cs.LG

TL;DR: ClusterEnv 是一个用于分布式 RL 环境执行的轻量级接口，它通过 DETACH 模式分离模拟和训练，并通过 AAPS 机制解决策略过时问题，从而提高了样本效率。


<details>
  <summary>Details</summary>
Motivation: 现有的强化学习（RL）框架将模拟、学习逻辑和编排封装到单一的系统中，这限制了模块化和可重用性。因此，需要一个更轻量级的接口来分布式执行 RL 工作负载。

Method: ClusterEnv 引入了 DETACH 模式，将模拟与训练分离，将 reset() 和 step() 操作卸载到远程工作节点，同时保持学习的集中化。为了解决分布式执行中的策略过时问题，我们提出了自适应 Actor 策略同步（AAPS），这是一种基于发散触发的更新机制，可在不牺牲性能的情况下减少同步开销。

Result: 实验表明，AAPS 在样本效率方面表现出色，并且所需的权重更新次数显著减少。

Conclusion: ClusterEnv 是一个轻量级的、与学习器无关的分布式环境执行接口，它镜像了 Gymnasium API。ClusterEnv 引入了 DETACH 模式，将模拟与训练分离，将 reset() 和 step() 操作卸载到远程工作节点，同时保持学习的集中化。为了解决分布式执行中的策略过时问题，我们提出了自适应 Actor 策略同步（AAPS），这是一种基于发散触发的更新机制，可在不牺牲性能的情况下减少同步开销。ClusterEnv 可与现有强化学习（RL）流程无缝集成，支持同步和异步策略方法，并且只需最少的代码更改。

Abstract: Scaling reinforcement learning (RL) workloads often requires distributing
environment simulation across compute clusters. Existing frameworks entangle
simulation, learning logic, and orchestration into monolithic systems, limiting
modularity and reusability. We present ClusterEnv, a lightweight,
learner-agnostic interface for distributed environment execution that mirrors
the Gymnasium API. ClusterEnv introduces the DETACH pattern, which decouples
simulation from training by offloading reset() and step() operations to remote
workers while keeping learning centralized. To address policy staleness in
distributed execution, we propose Adaptive Actor Policy Synchronization (AAPS),
a divergence-triggered update mechanism that reduces synchronization overhead
without sacrificing performance. ClusterEnv integrates cleanly into existing RL
pipelines, supports both on-policy and off-policy methods, and requires minimal
code changes. Experiments on discrete control tasks demonstrate that AAPS
achieves high sample efficiency with significantly fewer weight updates. Source
code is available at https://github.com/rodlaf/ClusterEnv.

</details>


### [194] [Misalignment from Treating Means as Ends](https://arxiv.org/abs/2507.10995)
*Henrik Marklund,Alex Infanger,Benjamin Van Roy*

Main category: cs.LG

TL;DR: 奖励函数常混淆终极目标和工具目标，导致强化学习模型目标不对齐，表现不佳。


<details>
  <summary>Details</summary>
Motivation: 本文的动机在于解决强化学习中奖励函数不完美的普遍问题。作者指出，奖励函数常常会混淆终极目标和工具目标，导致模型训练效果不佳，并对这种现象进行了深入分析。

Method: 本文提出了一个简单的例子，说明了即使是轻微的工具目标与终极目标之间的混淆也会导致严重的目标不对齐。通过分析这个例子，可以提炼出那些使得强化学习对工具目标与终极目标之间的混淆高度敏感的环境的本质属性。

Result: 通过一个简单的例子，本文展示了当奖励函数包含工具目标时，即使是很小的偏差也会导致与真实目标严重不一致，从而在真实目标下表现不佳。

Conclusion: 奖励函数（无论是学习到的还是手动指定的）很少是完美的。它们经常包含人类的终极目标（目的本身）和人类的工具目标（实现目标的手段）。这种对工具目标的包含会导致奖励函数失真，并可能导致严重的目标不对齐。优化一个错误的奖励函数，在真正的奖励函数下表现会很差。

Abstract: Reward functions, learned or manually specified, are rarely perfect. Instead
of accurately expressing human goals, these reward functions are often
distorted by human beliefs about how best to achieve those goals. Specifically,
these reward functions often express a combination of the human's terminal
goals -- those which are ends in themselves -- and the human's instrumental
goals -- those which are means to an end. We formulate a simple example in
which even slight conflation of instrumental and terminal goals results in
severe misalignment: optimizing the misspecified reward function results in
poor performance when measured by the true reward function. This example
distills the essential properties of environments that make reinforcement
learning highly sensitive to conflation of instrumental and terminal goals. We
discuss how this issue can arise with a common approach to reward learning and
how it can manifest in real environments.

</details>


### [195] [Crafting Imperceptible On-Manifold Adversarial Attacks for Tabular Data](https://arxiv.org/abs/2507.10998)
*Zhipeng He,Alexander Stevens,Chun Ouyang,Johannes De Smedt,Alistair Barros,Catarina Moreira*

Main category: cs.LG

TL;DR: 该研究提出了一种新颖的基于VAE的潜在空间扰动方法，用于生成表格数据的不可感知对抗样本，解决了表格数据异构性和缺乏直观相似性度量的挑战，并在实验中证明了其优越的性能和实际应用潜力。


<details>
  <summary>Details</summary>
Motivation: 表格数据的对抗性攻击由于其混合的类别和数值特征，带来了不同于图像或文本域的根本性挑战。缺乏直观的相似性度量使得生成不可感知扰动变得困难。此外，传统的基于梯度的$\ell_p$范数约束方法往往产生偏离原始数据分布的对抗样本，容易被检测。

Method: 提出一种基于潜在空间扰动的框架，利用混合输入的变分自编码器（VAE）生成对抗样本。该VAE能够整合类别嵌入和数值特征，在一个统一的潜在流形中进行扰动，以保持统计一致性。通过指定“分布内成功率”（IDSR）来衡量对抗样本在统计上与原始数据分布的不可区分性。

Result: 在六个公开数据集和三种模型架构上的评估表明，该方法实现了显著更低的异常值率和更一致的性能，优于传统的输入空间攻击和其他从图像领域改编的VAE方法。研究还进行了超参数敏感性、稀疏性控制和生成架构的比较分析，发现VAE类攻击对重构质量高度敏感，但在训练数据充足时具有优越的实际效用。

Conclusion: 该研究提出了一个基于潜在空间扰动的框架，使用混合输入的变分自编码器（VAE）生成不可感知对抗样本。通过将类别嵌入和数值特征整合到统一的潜在流形中，该方法能够实现保持统计一致性的扰动。评估结果表明，与传统的输入空间攻击和其他从图像领域改编的VAE方法相比，该方法在统计上更难区分，并且在多个公共数据集和模型架构上表现出更稳定、更低的异常值率。研究还强调了在充足训练数据可用时，VAE类攻击对重构质量的依赖性以及它们在实际应用中的优越性，为表格数据上的现实对抗攻击提供了鲁棒的方法。

Abstract: Adversarial attacks on tabular data present fundamental challenges distinct
from image or text domains due to the heterogeneous nature of mixed categorical
and numerical features. Unlike images where pixel perturbations maintain visual
similarity, tabular data lacks intuitive similarity metrics, making it
difficult to define imperceptible modifications. Additionally, traditional
gradient-based methods prioritise $\ell_p$-norm constraints, often producing
adversarial examples that deviate from the original data distributions, making
them detectable. We propose a latent space perturbation framework using a
mixed-input Variational Autoencoder (VAE) to generate imperceptible adversarial
examples. The proposed VAE integrates categorical embeddings and numerical
features into a unified latent manifold, enabling perturbations that preserve
statistical consistency. We specify In-Distribution Success Rate (IDSR) to
measure the proportion of adversarial examples that remain statistically
indistinguishable from the input distribution. Evaluation across six publicly
available datasets and three model architectures demonstrates that our method
achieves substantially lower outlier rates and more consistent performance
compared to traditional input-space attacks and other VAE-based methods adapted
from image domain approaches. Our comprehensive analysis includes
hyperparameter sensitivity, sparsity control mechanisms, and generative
architectural comparisons, revealing that VAE-based attacks depend critically
on reconstruction quality but offer superior practical utility when sufficient
training data is available. This work highlights the importance of on-manifold
perturbations for realistic adversarial attacks on tabular data, offering a
robust approach for practical deployment. The source code can be accessed
through https://github.com/ZhipengHe/VAE-TabAttack.

</details>


### [196] [AdaMuon: Adaptive Muon Optimizer](https://arxiv.org/abs/2507.11005)
*Chongjie Si,Debing Zhang,Wei Shen*

Main category: cs.LG

TL;DR: AdaMuon 是一个基于 Muon 优化器的自适应学习率框架，通过改进的二阶矩估计和重缩放策略，在不增加调优负担的情况下，提高了训练速度和稳定性。


<details>
  <summary>Details</summary>
Motivation: 为了在 Muon 优化器的基础上进一步提升模型训练效率，克服 AdamW 在大规模模型训练中的局限性。

Method: 提出 AdaMuon，一个基于 Muon 优化器的自适应学习率框架。该框架包含两个模块：1. 逐参数二阶矩调制，用于捕捉正交梯度更新以实现更新级别的自适应；2. RMS 对齐重缩放，通过将更新幅度与参数空间的内在结构对齐来调节整体更新幅度。

Result: 在多个模型规模和学习率环境下，AdaMuon 持续优于原始 Muon，实现了更高的收敛加速度，同时保持了训练稳定性。该方法不引入额外的调优负担，并且可以无缝集成到现有的 Muon 训练流程中。

Conclusion: AdaMuon 框架通过引入逐参数二阶矩调制和 RMS 对齐重缩放，在 Muon 优化器的基础上实现了自适应学习率，从而在模型训练中实现了更高的收敛加速度和训练稳定性。该框架易于集成且无需额外的调优。

Abstract: We propose AdaMuon, an adaptive learning-rate framework built upon the
recently validated Muon optimizer, which has demonstrated substantial
efficiency gains over AdamW in large-scale model training. AdaMuon augments
Muon with two mutually dependent modules: (1) a per-parameter second-moment
modulation that captures orthogonal gradient updates to ensure update-level
adaptivity, and (2) a RMS-aligned rescaling that regulates the overall update
magnitude by aligning it with the intrinsic structure of the parameter space.
Empirical results on multiple model scales and learning-rate regimes confirm
that AdaMuon consistently outperforms the original Muon, delivering higher
acceleration in convergence while maintaining training stability. Our method
introduces no additional tuning burden and can be seamlessly integrated into
existing Muon training pipelines.

</details>


### [197] [Leveraging Advanced Machine Learning to Predict Turbulence Dynamics from Temperature Observations at an Experimental Prescribed Fire](https://arxiv.org/abs/2507.11012)
*Dipak Dulal,Joseph J. Charney,Michael R. Gallagher,Pitambar Acharya,Carmeliza Navasca,Nicholas S. Skowronski*

Main category: cs.LG

TL;DR: 利用机器学习模型，通过温度数据预测火场中的湍流动能，提高了预测精度，有助于改进火场管理。


<details>
  <summary>Details</summary>
Motivation: 本研究旨在探索利用更易获得的温度数据预测湍流动能（TKE）的潜力，以期改进对火场环境的理解和火场管理策略。

Method: 本研究采用了多种机器学习模型，包括深度神经网络、随机森林回归器、梯度提升和高斯过程回归器，利用同步收集的温度数据（以10赫兹采样率）和湍流动能数据来预测湍流动能。研究还进行了数据可视化和相关性分析，以探索温度扰动与湍流动能之间的时空动态关系。

Result: 研究结果显示，机器学习模型能够从温度扰动中较为准确地预测TKE，其中回归模型表现尤为出色。研究发现了温 TKE 之间的模式和关系，并证明了机器学习技术在分析火场复杂大数据集方面的价值。

Conclusion: 该研究表明，尽管预测变量与目标变量之间的相关性较弱，但机器学习模型（尤其是回归模型）在准确预测湍流动能方面取得了显著成功。这为理解火场环境中的燃烧过程以及火场过程的耦合与解耦提供了新的见解，有助于改进火场管理策略和火灾/烟雾模型预测。

Abstract: This study explores the potential for predicting turbulent kinetic energy
(TKE) from more readily acquired temperature data using temperature profiles
and turbulence data collected concurrently at 10 Hz during a small experimental
prescribed burn in the New Jersey Pine Barrens. Machine learning models,
including Deep Neural Networks, Random Forest Regressor, Gradient Boosting, and
Gaussian Process Regressor, were employed to assess the potential to predict
TKE from temperature perturbations and explore temporal and spatial dynamics of
correlations. Data visualization and correlation analyses revealed patterns and
relationships between thermocouple temperatures and TKE, providing insight into
the underlying dynamics. More accurate predictions of TKE were achieved by
employing various machine learning models despite a weak correlation between
the predictors and the target variable. The results demonstrate significant
success, particularly from regression models, in accurately predicting the TKE.
The findings of this study demonstrate a novel numerical approach to
identifying new relationships between temperature and airflow processes in and
around the fire environment. These relationships can help refine our
understanding of combustion environment processes and the coupling and
decoupling of fire environment processes necessary for improving fire
operations strategy and fire and smoke model predictions. The findings of this
study additionally highlight the valuable role of machine learning techniques
in analyzing the complex large datasets of the fire environments, showcasing
their potential to advance fire research and management practices.

</details>


### [198] [First-Order Error Matters: Accurate Compensation for Quantized Large Language Models](https://arxiv.org/abs/2507.11017)
*Xingyu Zheng,Haotong Qin,Yuye Li,Jiakai Wang,Jinyang Guo,Michele Magno,Xianglong Liu*

Main category: cs.LG

TL;DR: FOEM是一种新的PTQ方法，通过考虑一阶梯度项来改进量化精度，相比GPTQ在多项任务上表现更优，并能与其它高级技术结合以进一步提升性能。


<details>
  <summary>Details</summary>
Motivation: 现有基于补偿的权重校准方法在量化过程中，假设一阶项可忽略，但研究揭示了累积的第一阶偏差使得这一假设失效。为了解决这个问题，需要一种新的PTQ方法来更准确地补偿量化误差。

Method: FOEM是一种新颖的后训练量化（PTQ）方法，它通过直接计算潜在权重和全精度权重之间的差异来近似梯度，从而显式地包含一阶梯度项以改进量化误差补偿。该方法引入了最小的额外计算开销，并利用预计算的乔勒斯基因子来高效地实时恢复黑塞矩阵的逆。

Result: FOEM在3位权重量化方面，将Llama3-8B的困惑度降低了89.6%，并将Llama3-70B的5次MMLU准确率从51.7%提高到74.9%，接近全精度模型的78.6%。此外，FOEM与GPTAQ和SpinQuant等技术集成，在W4A4KV4设置下取得了进一步的性能提升，并有效缩小了与全精度基线的精度差距。

Conclusion: FOEM 方法通过显式纳入一阶梯度项来改进量化误差补偿，避免了基于反向传播的梯度计算的高成本和泛化性限制，并利用预计算的乔勒斯基因子实时有效地恢复黑塞矩阵子矩阵的逆。实验证明，FOEM在各种模型和基准测试中持续优于经典的GPTQ方法，尤其是在3位权重量化方面，显著降低了困惑度并提高了准确性，同时还能与GPTAQ和SpinQuant等先进技术无缝集成，进一步缩小了与全精度基线的差距。

Abstract: Post-training quantization (PTQ) offers an efficient approach to compressing
large language models (LLMs), significantly reducing memory access and
computational costs. Existing compensation-based weight calibration methods
often rely on a second-order Taylor expansion to model quantization error,
under the assumption that the first-order term is negligible in well-trained
full-precision models. However, we reveal that the progressive compensation
process introduces accumulated first-order deviations between latent weights
and their full-precision counterparts, making this assumption fundamentally
flawed. To address this, we propose FOEM, a novel PTQ method that explicitly
incorporates first-order gradient terms to improve quantization error
compensation. FOEM approximates gradients by directly computing the difference
between latent and full-precision weights, avoiding the high cost and limited
generalization of backpropagation-based gradient computation. This approach
introduces minimal additional computational overhead. Moreover, FOEM leverages
precomputed Cholesky factors to efficiently recover the inverse of Hessian
submatrices in real time. Extensive experiments across a wide range of models
and benchmarks demonstrate that FOEM consistently outperforms the classical
GPTQ method. In 3-bit weight-only quantization, FOEM reduces the perplexity of
Llama3-8B by 89.6%, and improves the 5-shot MMLU accuracy of Llama3-70B from
51.7% to 74.9%, approaching the full-precision performance of 78.6%.
Furthermore, FOEM can be seamlessly integrated with advanced techniques such as
GPTAQ and SpinQuant, yielding additional improvements under the challenging
W4A4KV4 setting, and further narrowing the accuracy gap with full-precision
baselines beyond what current state-of-the-art methods achieve. The code is
available at https://github.com/Xingyu-Zheng/FOEM.

</details>


### [199] [Relative Entropy Pathwise Policy Optimization](https://arxiv.org/abs/2507.11019)
*Claas Voelcker,Axel Brunnbauer,Marcel Hussing,Michal Nauman,Pieter Abbeel,Eric Eaton,Radu Grosu,Amir-massoud Farahmand,Igor Gilitschenski*

Main category: cs.LG

TL;DR: REPPO是一种新的在线策略算法，它解决了传统在线策略方法的高方差和路径策略梯度对离线数据的依赖问题，实现了样本效率和训练稳定性的结合。


<details>
  <summary>Details</summary>
Motivation: 得分函数策略梯度在游戏、机器人和语言模型微调方面取得了显著成果，但高方差往往会破坏训练稳定性。另一方面，路径策略梯度可以缓解训练方差，但仅在由准确的动作条件价值函数驱动时才可靠，而这种价值函数在没有过去的离线数据的情况下，通常很难进行训练。

Method: 提出了一种价值梯度驱动的在线策略算法，可以仅从在线数据中训练Q值模型，从而在在线学习的背景下实现路径策略更新。讨论了如何在探索的随机策略与稳定的训练约束策略之间取得平衡，并评估了促进准确价值函数学习的重要结构组件。

Result: REPPO在两个标准的GPU并行基准测试的实验中，展现了强大的经验性能，同时降低了样本需求、运行时间和内存占用，并且具有高超参数鲁棒性。

Conclusion: REPPO是一种高效的在线策略算法，结合了路径策略梯度的样本效率和标准在线学习的简单性及最小内存占用。

Abstract: Score-function policy gradients have delivered strong results in
game-playing, robotics and language-model fine-tuning. Yet its high-variance
often undermines training stability. On the other hand, pathwise policy
gradients alleviate the training variance, but are reliable only when driven by
an accurate action-conditioned value function which is notoriously hard to
train without relying on past off-policy data. In this paper, we discuss how to
construct a value-gradient driven, on-policy algorithm that allow training
Q-value models purely from on-policy data, unlocking the possibility of using
pathwise policy updates in the context of on-policy learning. We show how to
balance stochastic policies for exploration with constrained policy updates for
stable training, and evaluate important architectural components that
facilitate accurate value function learning. Building on these insights, we
propose Relative Entropy Pathwise Policy Optimization (REPPO), an efficient
on-policy algorithm that combines the sample-efficiency of pathwise policy
gradients with the simplicity and minimal memory footprint of standard
on-policy learning. We demonstrate that REPPO provides strong empirical
performance at decreased sample requirements, wall-clock time, memory footprint
as well as high hyperparameter robustness in a set of experiments on two
standard GPU-parallelized benchmarks.

</details>


### [200] [AirLLM: Diffusion Policy-based Adaptive LoRA for Remote Fine-Tuning of LLM over the Air](https://arxiv.org/abs/2507.11515)
*Shiyi Yang,Xiaoxue Yu,Rongpeng Li,Jianhang Zhu,Zhifeng Zhao,Honggang Zhang*

Main category: cs.LG

TL;DR: AirLLM通过分层扩散策略，利用PPO和DDIM优化LoRA的秩配置，解决了边缘设备LLM远程微调的通信效率和性能问题。


<details>
  <summary>Details</summary>
Motivation: 现有低秩自适应（LoRA）方法在将大型语言模型（LLM）部署到边缘设备时，面临通信带宽有限以及计算和内存成本高昂的挑战。现有的LoRA方法通常采用固定的或启发式的秩配置，并且后续所有LoRA参数的无线传输效率低下。

Method: 提出了一种名为AirLLM的框架，该框架采用分层扩散策略来处理通信感知的LoRA自适应。具体来说，它将秩配置建模为一个跨越所有LoRA插入投影的结构化动作向量。该框架使用Proximal Policy Optimization（PPO）代理来生成粗粒度的决策，同时考虑无线状态和语言复杂度，然后通过Denoising Diffusion Implicit Models（DDIM）进行细化，生成高分辨率、任务和信道自适应的秩向量。PPO和DDIM模块交替优化，其中DDIM在Classifier-Free Guidance（CFG）范式下进行训练，以与PPO奖励保持一致。

Result: 实验结果表明，AirLLM在不同信噪比下，能够持续提升微调性能，同时显著降低传输成本，证明了通过强化学习驱动、扩散模型细化的秩自适应方法在可扩展和高效的无线远程微调方面的有效性。

Conclusion: AirLLM通过结合强化学习和扩散模型，实现了通信感知的LoRA自适应，显著提高了在边缘设备上进行远程模型微调的效率和性能。

Abstract: Operating Large Language Models (LLMs) on edge devices is increasingly
challenged by limited communication bandwidth and strained computational and
memory costs. Thus, cloud-assisted remote fine-tuning becomes indispensable.
Nevertheless, existing Low-Rank Adaptation (LoRA) approaches typically employ
fixed or heuristic rank configurations, and the subsequent over-the-air
transmission of all LoRA parameters could be rather inefficient. To address
this limitation, we develop AirLLM, a hierarchical diffusion policy framework
for communication-aware LoRA adaptation. Specifically, AirLLM models the rank
configuration as a structured action vector that spans all LoRA-inserted
projections. To solve the underlying high-dimensional sequential
decision-making problem, a Proximal Policy Optimization (PPO) agent generates
coarse-grained decisions by jointly observing wireless states and linguistic
complexity, which are then refined via Denoising Diffusion Implicit Models
(DDIM) to produce high-resolution, task- and channel-adaptive rank vectors. The
two modules are optimized alternatively, with the DDIM trained under the
Classifier-Free Guidance (CFG) paradigm to maintain alignment with PPO rewards.
Experiments under varying signal-to-noise ratios demonstrate that AirLLM
consistently enhances fine-tuning performance while significantly reducing
transmission costs, highlighting the effectiveness of reinforcement-driven,
diffusion-refined rank adaptation for scalable and efficient remote fine-tuning
over the air.

</details>


### [201] [GATE: Graph Attention Neural Networks with Real-Time Edge Construction for Robust Indoor Localization using Mobile Embedded Devices](https://arxiv.org/abs/2507.11053)
*Danish Gufran,Sudeep Pasricha*

Main category: cs.LG

TL;DR:  GATE是一种新颖的室内定位框架，通过自适应图表示和创新的向量设计，有效解决了Wi-Fi RSS指纹定位中的设备异质性和非欧几里得噪声问题，显著提高了定位精度。


<details>
  <summary>Details</summary>
Motivation: 现有基于Wi-Fi RSS指纹的室内定位方法，无论是传统的深度学习模型还是图神经网络，都未能有效处理真实世界中RSS噪声的非欧几里得分布以及设备异质性问题。深度学习模型忽略了空间关系和非均匀噪声，而图神经网络则在处理非欧几里得噪声和解决AP密集环境下的盲点问题时存在不足。因此，需要一种新的框架来克服这些挑战，提高室内定位的准确性和鲁棒性。

Method: GATE框架提出了一种新颖的图神经网络方法，通过构建自适应的图表示来编码室内定位信息。具体包括：1）注意力超空间向量（AHV），用于增强消息传递；2）多维超空间向量（MDHV），用于缓解图神经网络的盲点问题；3）实时边缘构建（RTEC），用于动态适应图结构。这些方法旨在模拟RSS噪声的非欧几里得结构，以减轻环境噪声和设备异质性带来的影响。

Result: 在真实世界的多样化室内环境中进行的广泛评估表明，GATE框架在不同路径长度、AP密度和异质设备条件下，平均定位误差比最先进的室内定位框架低1.6倍至4.72倍，最坏情况下的误差也降低了1.85倍至4.57倍。

Conclusion: GATE框架通过自适应图表示、注意力超空间向量（AHV）、多维超空间向量（MDHV）和实时边缘构建（RTEC）等技术，成功解决了现有深度学习和图神经网络在室内定位中的局限性，能够有效处理非欧几里得噪声和设备异质性问题，显著降低了定位误差，在真实世界评估中表现优于现有技术。

Abstract: Accurate indoor localization is crucial for enabling spatial context in smart
environments and navigation systems. Wi-Fi Received Signal Strength (RSS)
fingerprinting is a widely used indoor localization approach due to its
compatibility with mobile embedded devices. Deep Learning (DL) models improve
accuracy in localization tasks by learning RSS variations across locations, but
they assume fingerprint vectors exist in a Euclidean space, failing to
incorporate spatial relationships and the non-uniform distribution of
real-world RSS noise. This results in poor generalization across heterogeneous
mobile devices, where variations in hardware and signal processing distort RSS
readings. Graph Neural Networks (GNNs) can improve upon conventional DL models
by encoding indoor locations as nodes and modeling their spatial and signal
relationships as edges. However, GNNs struggle with non-Euclidean noise
distributions and suffer from the GNN blind spot problem, leading to degraded
accuracy in environments with dense access points (APs). To address these
challenges, we propose GATE, a novel framework that constructs an adaptive
graph representation of fingerprint vectors while preserving an indoor
state-space topology, modeling the non-Euclidean structure of RSS noise to
mitigate environmental noise and address device heterogeneity. GATE introduces
1) a novel Attention Hyperspace Vector (AHV) for enhanced message passing, 2) a
novel Multi-Dimensional Hyperspace Vector (MDHV) to mitigate the GNN blind
spot, and 3) an new Real-Time Edge Construction (RTEC) approach for dynamic
graph adaptation. Extensive real-world evaluations across multiple indoor
spaces with varying path lengths, AP densities, and heterogeneous devices
demonstrate that GATE achieves 1.6x to 4.72x lower mean localization errors and
1.85x to 4.57x lower worst-case errors compared to state-of-the-art indoor
localization frameworks.

</details>


### [202] [A Distance Metric for Mixed Integer Programming Instances](https://arxiv.org/abs/2507.11063)
*Gwen Maudet,Grégoire Danoy*

Main category: cs.LG

TL;DR: 提出了一种新的MILP实例数学距离度量方法，用于比较实例的相似性。该方法通过量化权重-变量分布来比较约束，并能进行实例级比较。实验结果表明，该方法在实例分组任务上表现优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 为了解决混合整数线性规划（MILP）实例缺乏比较结构的问题，提出了一种新的相似性度量方法，以促进实例集异质性的评估，并为求解器提供更好的指导，尤其是在机器学习场景中。

Method: 通过离散化右侧、权重和变量，并借鉴了Earth mover's distance的思路来量化约束比较中的权重-变量分布不匹配。

Result: 提出的度量方法，包括精确和贪婪变体，在StrIPLIB数据集上的表现优于现有方法，贪婪版本在效率上是精确版本的近200倍，同时准确性几乎相同。

Conclusion: 该方法在实例分组任务上优于所有非学习方法，并且在性能上与有监督分类器相媲美。

Abstract: Mixed-integer linear programming (MILP) is a powerful tool for addressing a
wide range of real-world problems, but it lacks a clear structure for comparing
instances. A reliable similarity metric could establish meaningful
relationships between instances, enabling more effective evaluation of instance
set heterogeneity and providing better guidance to solvers, particularly when
machine learning is involved. Existing similarity metrics often lack precision
in identifying instance classes or rely heavily on labeled data, which limits
their applicability and generalization. To bridge this gap, this paper
introduces the first mathematical distance metric for MILP instances, derived
directly from their mathematical formulations. By discretizing right-hand
sides, weights, and variables into classes, the proposed metric draws
inspiration from the Earth mover's distance to quantify mismatches in
weight-variable distributions for constraint comparisons. This approach
naturally extends to enable instance-level comparisons. We evaluate both an
exact and a greedy variant of our metric under various parameter settings,
using the StrIPLIB dataset. Results show that all components of the metric
contribute to class identification, and that the greedy version achieves
accuracy nearly identical to the exact formulation while being nearly 200 times
faster. Compared to state-of-the-art baselines, including feature-based,
image-based, and neural network models, our unsupervised method consistently
outperforms all non-learned approaches and rivals the performance of a
supervised classifier on class and subclass grouping tasks.

</details>


### [203] [LogTinyLLM: Tiny Large Language Models Based Contextual Log Anomaly Detection](https://arxiv.org/abs/2507.11071)
*Isaiah Thompson Ocansey,Ritwik Bhattacharya,Tanmay Sen*

Main category: cs.LG

TL;DR: 日志异常检测：LoRA等参数高效微调方法在Thunderbird数据集上准确率达98.83%，远超LogBert全量微调。


<details>
  <summary>Details</summary>
Motivation: 传统基于规则或深度学习的日志异常检测方法因日志数据量大、复杂度高而面临挑战，因此，有效检测异常日志序列对于系统维护和开发至关重要。

Method: 提出并比较了参数高效微调方法，特别是低秩适配（LoRA）和Adapter，用于检测大型日志数据集中日志序列的上下文异常，并对比了不同的微型语言模型在Thunderbird数据集上的表现。

Result: LoRA微调方法相比LogBert全量微调方法，性能提升了18%-19%，准确率达到了97.76%-98.83%，而LogBert的准确率为79.37%。

Conclusion: LoRA等参数高效微调方法在日志异常检测任务中表现出色，在Thunderbird数据集上显著优于LogBert等基于全量微调的方法，准确率可达97.76%-98.83%。

Abstract: Log anomaly detection using traditional rule based or deep learning based
methods is often challenging due to the large volume and highly complex nature
of log sequence. So effective way of detection of anomalous sequence of logs is
crucial for system maintenance and development. This paper proposes parameter
efficient finetuning specifically low rank adaptation (LoRA) and adapter based
approaches for finding contextual anomalies in sequence of logs in large log
data set. It compares different tiny large language models (LLMs) on the
Thunderbird dataset. The results show that LoRA based finetuning provides
substantial performance improvements of 18 to 19 percentage over LogBert based
full finetuning approach, achieving accuracy scores between 97.76% and 98.83%
compared to 79.37%.

</details>


### [204] [Real-Time Bayesian Detection of Drift-Evasive GNSS Spoofing in Reinforcement Learning Based UAV Deconfliction](https://arxiv.org/abs/2507.11173)
*Deepak Kumar Panda,Weisi Guo*

Main category: cs.LG

TL;DR: 本研究提出一种基于贝叶斯在线变化点检测（BOCPD）的方法，通过监控强化学习（RL）评价网络的值估计中的时间漂移，有效检测无人机导航中的漂移规避欺骗攻击，相比传统方法效果更优。


<details>
  <summary>Details</summary>
Motivation: 自主无人机（UAV）依赖GNSS进行导航，容易受到欺骗攻击，特别是漂移规避欺骗攻击，它能逐渐改变无人机轨迹而不触发常规的信号级反欺骗机制。传统检测方法需要累积样本，导致检测延迟。因此，需要鲁棒的时间尺度检测方法来及时响应。

Method: 提出一种基于贝叶斯在线变化点检测（BOCPD）的方法，通过监控强化学习（RL）评价网络的值估计中的时间漂移来检测无人机导航中的漂移规避欺骗攻击。

Result: 实验结果表明，本研究提出的基于时间尺度值估计的框架在检测漂移规避欺骗攻击方面优于传统的GNSS欺骗检测器、时间半监督学习框架和Page-Hinkley检验，具有更高的检测精度和更低的误报率和漏报率。

Conclusion: 本研究提出的基于贝叶斯在线变化点检测（BOCPD）的方法，通过监控强化学习（RL）评价网络的值估计中的时间漂移，能够有效检测无人机导航中的细微行为偏差，相比于传统的GNSS欺骗检测方法、时间半监督学习框架以及Page-Hinkley检验，在漂移规避欺骗攻击方面表现出更高的检测精度以及更低误报和漏报率。

Abstract: Autonomous unmanned aerial vehicles (UAVs) rely on global navigation
satellite system (GNSS) pseudorange measurements for accurate real-time
localization and navigation. However, this dependence exposes them to
sophisticated spoofing threats, where adversaries manipulate pseudoranges to
deceive UAV receivers. Among these, drift-evasive spoofing attacks subtly
perturb measurements, gradually diverting the UAVs trajectory without
triggering conventional signal-level anti-spoofing mechanisms. Traditional
distributional shift detection techniques often require accumulating a
threshold number of samples, causing delays that impede rapid detection and
timely response. Consequently, robust temporal-scale detection methods are
essential to identify attack onset and enable contingency planning with
alternative sensing modalities, improving resilience against stealthy
adversarial manipulations. This study explores a Bayesian online change point
detection (BOCPD) approach that monitors temporal shifts in value estimates
from a reinforcement learning (RL) critic network to detect subtle behavioural
deviations in UAV navigation. Experimental results show that this temporal
value-based framework outperforms conventional GNSS spoofing detectors,
temporal semi-supervised learning frameworks, and the Page-Hinkley test,
achieving higher detection accuracy and lower false-positive and false-negative
rates for drift-evasive spoofing attacks.

</details>


### [205] [Gradient Regularization-based Neural Granger Causality](https://arxiv.org/abs/2507.11178)
*Meiliang Liu,Huiwen Dong,Xiaoxiao Yang,Yunfang Xu,Zijin Li,Zhengye Si,Xinyue Yang,Zhiwen Zhao*

Main category: cs.LG

TL;DR: GRNGC是一种新的格兰杰因果推断方法，通过正则化梯度来解决现有方法的计算成本高和捕捉复杂交互能力弱的问题，并已在多个数据集上验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 现有的基于神经网络的格兰杰因果关系模型大多采用逐分量架构，需要为每个时间序列构建单独的模型，导致计算成本高昂；并且在神经网络的第一层权重上施加稀疏性正则化来提取因果关系会削弱模型捕捉复杂交互的能力。

Method: GRNGC模型，通过将L1正则化应用于模型输入和输出之间的梯度来推断格兰杰因果关系，并且该模型不依赖于特定的时间序列预测模型，可以与KAN、MLP和LSTM等多种架构结合使用。

Result: GRNGC在DREAM、Lorenz-96、fMRI BOLD和CausalTime上的数值模拟结果优于现有基线模型，并显著降低了计算开销。

Conclusion: GRNGC在真实世界DNA、酵母、HeLa和膀胱尿路上皮癌数据集上的实验进一步验证了该模型在重建基因调控网络方面的有效性。

Abstract: With the advancement of deep learning technologies, various neural
network-based Granger causality models have been proposed. Although these
models have demonstrated notable improvements, several limitations remain. Most
existing approaches adopt the component-wise architecture, necessitating the
construction of a separate model for each time series, which results in
substantial computational costs. In addition, imposing the sparsity-inducing
penalty on the first-layer weights of the neural network to extract causal
relationships weakens the model's ability to capture complex interactions. To
address these limitations, we propose Gradient Regularization-based Neural
Granger Causality (GRNGC), which requires only one time series prediction model
and applies $L_{1}$ regularization to the gradient between model's input and
output to infer Granger causality. Moreover, GRNGC is not tied to a specific
time series forecasting model and can be implemented with diverse architectures
such as KAN, MLP, and LSTM, offering enhanced flexibility. Numerical
simulations on DREAM, Lorenz-96, fMRI BOLD, and CausalTime show that GRNGC
outperforms existing baselines and significantly reduces computational
overhead. Meanwhile, experiments on real-world DNA, Yeast, HeLa, and bladder
urothelial carcinoma datasets further validate the model's effectiveness in
reconstructing gene regulatory networks.

</details>


### [206] [Mixture of Experts in Large Language Models](https://arxiv.org/abs/2507.11181)
*Danyang Zhang,Junhao Song,Ziqian Bi,Yingfang Yuan,Tianyang Wang,Joe Yeong,Junfeng Hao*

Main category: cs.LG

TL;DR: 该论文全面回顾了大型语言模型中的MoE架构，强调了其在提升性能和控制计算开销方面的优势，并指出了未来研究方向。


<details>
  <summary>Details</summary>
Motivation: 介绍MoE架构在大型语言模型中的应用，强调其提升模型性能和控制计算开销的能力。

Method: 对MoE架构进行了系统的分析，涵盖了理论基础、核心设计、LLM应用、专家门控与路由机制、层次化与稀疏MoE配置、元学习方法、多模态与多任务学习、实际部署案例以及深度学习的最新进展和挑战。

Result: MoE架构相比于等效的贝叶斯方法具有更优的模型容量、更好的任务特定性能，并能高效地扩展模型容量。

Conclusion: MoE架构在大型语言模型中具有提升性能和控制计算开销的潜力。为了最大化其效果，需要确保专家多样性、准确的校准和可靠的推理聚合。该研究为MoE架构的持续创新奠定了基础。

Abstract: This paper presents a comprehensive review of the Mixture-of-Experts (MoE)
architecture in large language models, highlighting its ability to
significantly enhance model performance while maintaining minimal computational
overhead. Through a systematic analysis spanning theoretical foundations, core
architectural designs, and large language model (LLM) applications, we examine
expert gating and routing mechanisms, hierarchical and sparse MoE
configurations, meta-learning approaches, multimodal and multitask learning
scenarios, real-world deployment cases, and recent advances and challenges in
deep learning. Our analysis identifies key advantages of MoE, including
superior model capacity compared to equivalent Bayesian approaches, improved
task-specific performance, and the ability to scale model capacity efficiently.
We also underscore the importance of ensuring expert diversity, accurate
calibration, and reliable inference aggregation, as these are essential for
maximizing the effectiveness of MoE architectures. Finally, this review
outlines current research limitations, open challenges, and promising future
directions, providing a foundation for continued innovation in MoE architecture
and its applications.

</details>


### [207] [Quantized Rank Reduction: A Communications-Efficient Federated Learning Scheme for Network-Critical Applications](https://arxiv.org/abs/2507.11183)
*Dimitrios Kritsiolis,Constantine Kotropoulos*

Main category: cs.LG

TL;DR: Federated learning trains models on decentralized data without sharing raw data, but has high communication overhead. This paper proposes using low-rank approximation and quantization to reduce this overhead with minimal accuracy loss.


<details>
  <summary>Details</summary>
Motivation: Addresses the challenge of communication overhead in federated learning due to frequent exchange of model updates.

Method: Utilizes low-rank approximation of neural network gradients and quantization to reduce communication overhead.

Result: Significant reduction in network load in the decentralized learning process.

Conclusion: The proposed scheme significantly reduces network load with minimal impact on model accuracy.

Abstract: Federated learning is a machine learning approach that enables multiple
devices (i.e., agents) to train a shared model cooperatively without exchanging
raw data. This technique keeps data localized on user devices, ensuring privacy
and security, while each agent trains the model on their own data and only
shares model updates. The communication overhead is a significant challenge due
to the frequent exchange of model updates between the agents and the central
server. In this paper, we propose a communication-efficient federated learning
scheme that utilizes low-rank approximation of neural network gradients and
quantization to significantly reduce the network load of the decentralized
learning process with minimal impact on the model's accuracy.

</details>


### [208] [An Explainable AI-Enhanced Machine Learning Approach for Cardiovascular Disease Detection and Risk Assessment](https://arxiv.org/abs/2507.11185)
*Md. Emon Akter Sourov,Md. Sabbir Hossen,Pabon Shaha,Mohammad Minoar Hossain,Md Sadiq Iqbal*

Main category: cs.LG

TL;DR: 本研究通过结合分类和回归模型，并利用SMOTE和可解释AI技术，利用机器学习提高了心脏病诊断的准确性和风险预测能力，其中随机森林和线性回归表现突出。


<details>
  <summary>Details</summary>
Motivation: 心脏病是全球主要的健康问题，特别是在医疗资源和诊断设施有限的地区。传统诊断方法在准确识别和管理心脏病风险方面存在不足，可能导致不良后果。机器学习在提高心脏病诊断的准确性、效率和速度方面具有巨大潜力。

Method: 本研究提出了一个结合分类模型（用于心脏病检测）和回归模型（用于风险预测）的综合框架。研究采用了包含1035个病例的心脏病数据集。为了解决类别不平衡问题，应用了合成少数类过采样技术（SMOTE），生成了100,000个合成数据点。使用准确率、精确率、召回率、F1分数、R2、MSE、RMSE和MAE等性能指标来评估模型效果。此外，还采用了可解释人工智能技术来增强模型的可解释性。

Result: 在分类模型中，随机森林表现最佳，在真实数据上准确率为97.2%，在合成数据上为97.6%。在回归任务中，线性回归在真实和合成数据集上分别取得了最高的R2值（0.992和0.984），同时错误指标最低。

Conclusion: 本研究展示了机器学习在心脏病诊断和风险预测方面的潜力，有助于早期干预和改善临床决策。

Abstract: Heart disease remains a major global health concern, particularly in regions
with limited access to medical resources and diagnostic facilities. Traditional
diagnostic methods often fail to accurately identify and manage heart disease
risks, leading to adverse outcomes. Machine learning has the potential to
significantly enhance the accuracy, efficiency, and speed of heart disease
diagnosis. In this study, we proposed a comprehensive framework that combines
classification models for heart disease detection and regression models for
risk prediction. We employed the Heart Disease dataset, which comprises 1,035
cases. To address the issue of class imbalance, the Synthetic Minority
Oversampling Technique (SMOTE) was applied, resulting in the generation of an
additional 100,000 synthetic data points. Performance metrics, including
accuracy, precision, recall, F1-score, R2, MSE, RMSE, and MAE, were used to
evaluate the model's effectiveness. Among the classification models, Random
Forest emerged as the standout performer, achieving an accuracy of 97.2% on
real data and 97.6% on synthetic data. For regression tasks, Linear Regression
demonstrated the highest R2 values of 0.992 and 0.984 on real and synthetic
datasets, respectively, with the lowest error metrics. Additionally,
Explainable AI techniques were employed to enhance the interpretability of the
models. This study highlights the potential of machine learning to
revolutionize heart disease diagnosis and risk prediction, thereby facilitating
early intervention and enhancing clinical decision-making.

</details>


### [209] [Striking the Perfect Balance: Preserving Privacy While Boosting Utility in Collaborative Medical Prediction Platforms](https://arxiv.org/abs/2507.11187)
*Shao-Bo Lin,Xiaotong Liu,Yao Wang*

Main category: cs.LG

TL;DR: 本研究提出了一种新的、注重隐私的在线协作医疗预测平台，通过理论和实验证明了它可以在保护隐私的同时实现最佳预测性能。


<details>
  <summary>Details</summary>
Motivation: 解决在线协作医疗预测平台中存在的隐私问题和预测质量低的问题，以鼓励患者参与和医生合作。

Method: 提出了一种注重隐私的机制，并将其整合到一个新颖的单次分布式学习框架中，该框架在统计学习理论的框架内进行了理论分析，并辅以玩具模拟和真实世界数据实验进行了验证。

Result: 理论上证明了所提出的分布式学习框架在特定隐私要求下可以实现最佳预测性能，并通过模拟和真实世界数据实验进行了验证。

Conclusion: 该研究提出了一个新颖的、注重隐私的分布式学习框架，用于在线协作医疗预测，并通过理论和实验证明了其在满足隐私要求的同时实现最佳预测性能的能力。

Abstract: Online collaborative medical prediction platforms offer convenience and
real-time feedback by leveraging massive electronic health records. However,
growing concerns about privacy and low prediction quality can deter patient
participation and doctor cooperation. In this paper, we first clarify the
privacy attacks, namely attribute attacks targeting patients and model
extraction attacks targeting doctors, and specify the corresponding privacy
principles. We then propose a privacy-preserving mechanism and integrate it
into a novel one-shot distributed learning framework, aiming to simultaneously
meet both privacy requirements and prediction performance objectives. Within
the framework of statistical learning theory, we theoretically demonstrate that
the proposed distributed learning framework can achieve the optimal prediction
performance under specific privacy requirements. We further validate the
developed privacy-preserving collaborative medical prediction platform through
both toy simulations and real-world data experiments.

</details>


### [210] [Gradient Descent on Logistic Regression: Do Large Step-Sizes Work with Data on the Sphere?](https://arxiv.org/abs/2507.11228)
*Si Yi Meng,Baptiste Goujaud,Antonio Orvieto,Christopher De Sa*

Main category: cs.LG

TL;DR: 梯度下降在具有相等幅度的数据集上的收敛性取决于数据的维度。在一维空间中可以保证全局收敛，但在高维空间中仍然可能出现循环行为。


<details>
  <summary>Details</summary>
Motivation: 探究将数据集限制为具有相等幅度是否是全局收敛的充分条件，即使步长可以超过稳定性阈值。

Method: 通过在不同维度（一维和高维）上研究梯度下降的收敛行为来分析。

Result: 在二维空间中，梯度下降表现出循环行为，即使在稳定性阈值以下使用任何步长也是如此。然而，在一维空间中，当数据集具有相等幅度时，可以保证全局收敛。

Conclusion: 当数据集具有相等幅度时，并不能保证梯度下降在所有维度上都能全局收敛。

Abstract: Gradient descent (GD) on logistic regression has many fascinating properties.
When the dataset is linearly separable, it is known that the iterates converge
in direction to the maximum-margin separator regardless of how large the step
size is. In the non-separable case, however, it has been shown that GD can
exhibit a cycling behaviour even when the step sizes is still below the
stability threshold $2/\lambda$, where $\lambda$ is the largest eigenvalue of
the Hessian at the solution. This short paper explores whether restricting the
data to have equal magnitude is a sufficient condition for global convergence,
under any step size below the stability threshold. We prove that this is true
in a one dimensional space, but in higher dimensions cycling behaviour can
still occur. We hope to inspire further studies on quantifying how common these
cycles are in realistic datasets, as well as finding sufficient conditions to
guarantee global convergence with large step sizes.

</details>


### [211] [Generative Click-through Rate Prediction with Applications to Search Advertising](https://arxiv.org/abs/2507.11246)
*Lingwei Kong,Lu Wang,Changping Peng,Zhangang Lin,Ching Law,Jingping Shao*

Main category: cs.LG

TL;DR: 提出了一种结合生成模型和判别模型的CTR预测新方法，通过两阶段训练提升了CTR预测精度，并在大型电商平台成功部署。


<details>
  <summary>Details</summary>
Motivation: 随着GPT等模型取得成功，生成模型在超越判别模型方面展现出巨大潜力。

Method: 提出了一种利用生成模型增强判别模型CTR预测精度的新型模型。该模型采用两阶段训练过程：1）对用户行为序列中的给定项类别进行下一项预测的生成预训练；2）在判别模型CTR预测框架内对预训练的生成模型进行微调。

Result: 通过在新数据集上的广泛实验和在线A/B测试结果证实了该方法的有效性，并验证了其重要的实用性。

Conclusion: 该模型已成功应用于全球最大的电子商务平台之一，并且未来将发布相关代码和数据集。

Abstract: Click-Through Rate (CTR) prediction models are integral to a myriad of
industrial settings, such as personalized search advertising. Current methods
typically involve feature extraction from users' historical behavior sequences
combined with product information, feeding into a discriminative model that is
trained on user feedback to estimate CTR. With the success of models such as
GPT, the potential for generative models to enrich expressive power beyond
discriminative models has become apparent. In light of this, we introduce a
novel model that leverages generative models to enhance the precision of CTR
predictions in discriminative models. To reconcile the disparate data
aggregation needs of both model types, we design a two-stage training process:
1) Generative pre-training for next-item prediction with the given item
category in user behavior sequences; 2) Fine-tuning the well-trained generative
model within a discriminative CTR prediction framework. Our method's efficacy
is substantiated through extensive experiments on a new dataset, and its
significant utility is further corroborated by online A/B testing results.
Currently, the model is deployed on one of the world's largest e-commerce
platforms, and we intend to release the associated code and dataset in the
future.

</details>


### [212] [LyAm: Robust Non-Convex Optimization for Stable Learning in Noisy Environments](https://arxiv.org/abs/2507.11262)
*Elmira Mirzabeigi,Sepehr Rezaee,Kourosh Parand*

Main category: cs.LG

TL;DR: LyAm is a new optimizer that improves deep learning training by combining Adam with Lyapunov stability theory, leading to better accuracy, faster convergence, and enhanced stability in computer vision tasks.


<details>
  <summary>Details</summary>
Motivation: Training deep neural networks for computer vision tasks often suffers from noisy gradients and unstable convergence, hindering performance and generalization.

Method: LyAm, a novel optimizer that integrates Adam's adaptive moment estimation with Lyapunov-based stability mechanisms, dynamically adjusts the learning rate using Lyapunov stability theory to enhance convergence robustness and mitigate training noise. The paper also provides a rigorous theoretical framework proving the convergence guarantees of LyAm in complex, non-convex settings.

Result: Extensive experiments on CIFAR-10 and CIFAR-100 show that LyAm consistently outperforms state-of-the-art optimizers in accuracy, convergence speed, and stability.

Conclusion: LyAm Optimizer, which integrates Adam with Lyapunov-based stability mechanisms, demonstrates superior performance over state-of-the-art optimizers in terms of accuracy, convergence speed, and stability, making it a strong candidate for robust deep learning optimization.

Abstract: Training deep neural networks, particularly in computer vision tasks, often
suffers from noisy gradients and unstable convergence, which hinder performance
and generalization. In this paper, we propose LyAm, a novel optimizer that
integrates Adam's adaptive moment estimation with Lyapunov-based stability
mechanisms. LyAm dynamically adjusts the learning rate using Lyapunov stability
theory to enhance convergence robustness and mitigate training noise. We
provide a rigorous theoretical framework proving the convergence guarantees of
LyAm in complex, non-convex settings. Extensive experiments on like as CIFAR-10
and CIFAR-100 show that LyAm consistently outperforms state-of-the-art
optimizers in terms of accuracy, convergence speed, and stability, establishing
it as a strong candidate for robust deep learning optimization.

</details>


### [213] [Turning Sand to Gold: Recycling Data to Bridge On-Policy and Off-Policy Learning via Causal Bound](https://arxiv.org/abs/2507.11269)
*Tal Fiskus,Uri Shaham*

Main category: cs.LG

TL;DR: 该研究通过将潜在结果框架应用于DRL，提高了样本效率并减小了经验回放缓冲区的大小，在Atari和MuJoCo实验中取得了显著成果。


<details>
  <summary>Details</summary>
Motivation: 深度强化学习（DRL）代理在解决复杂决策任务方面表现出色，但需要大量的训练步骤和经验回放缓冲区，导致计算和资源需求很高。本研究旨在解决这些挑战。

Method: 将Neyman-Rubin潜在结果框架引入DRL，并建立了事实损失的因果界，通过存储过去的价值网络输出来计算该界限，有效利用了通常被丢弃的数据。

Result: 在Atari 2600和MuJoCo域上的大量实验表明，该方法可以将奖励率提高高达2,427%，并且经验回放缓冲区大小减少高达96%，显著提高了样本效率，而成本极小。

Conclusion: 该研究提出了一种新的理论结果，将Neyman-Rubin潜在结果框架应用于深度强化学习（DRL），通过对事实损失（类似于DRL中的 on-policy loss）建立因果界，从而提高样本效率并减少对经验回放缓冲区的需求。

Abstract: Deep reinforcement learning (DRL) agents excel in solving complex
decision-making tasks across various domains. However, they often require a
substantial number of training steps and a vast experience replay buffer,
leading to significant computational and resource demands. To address these
challenges, we introduce a novel theoretical result that leverages the
Neyman-Rubin potential outcomes framework into DRL. Unlike most methods that
focus on bounding the counterfactual loss, we establish a causal bound on the
factual loss, which is analogous to the on-policy loss in DRL. This bound is
computed by storing past value network outputs in the experience replay buffer,
effectively utilizing data that is usually discarded. Extensive experiments
across the Atari 2600 and MuJoCo domains on various agents, such as DQN and
SAC, achieve up to 2,427% higher reward ratio, outperforming the same agents
without our proposed term, and reducing the experience replay buffer size by up
to 96%, significantly improving sample efficiency at negligible cost.

</details>


### [214] [Fast Last-Iterate Convergence of SGD in the Smooth Interpolation Regime](https://arxiv.org/abs/2507.11274)
*Amit Attia,Matan Schliserman,Uri Sherman,Tomer Koren*

Main category: cs.LG

TL;DR: 研究SGD在插值模型下的收敛性，给出了理论保证和改进的收敛率。


<details>
  <summary>Details</summary>
Motivation: 研究SGD在插值模型下的收敛性，特别关注最后一个迭代的行为，这对于理解过参数模型训练、持续学习中的遗忘以及随机Kaczmarz方法至关重要。

Method: 通过理论分析，推导了SGD最后一个迭代在$eta$-光滑凸目标函数和特定步长下的预期超风险上界，形式为$\widetilde{O}(1/(\eta T^{1-\beta\eta/2}) + \eta T^{\beta\eta/2} 	au_	ars	ars^2)$。

Result: 在特定条件下，当步长调整得当时，SGD最后一个迭代的预期超风险接近最优的$\widetilde{O}(1/T + 	au_	ars/ott	ars)$。当$	au_	ars=0$且步长为$ot/eta$时，收敛率为$O(1/ott)$，优于先前在特定线性回归问题上得到的结果。

Conclusion: 该研究为SGD的最后一个迭代在插值模型下提供了收敛保证，并推导了相应的收敛率，在某些情况下优于现有结果。

Abstract: We study population convergence guarantees of stochastic gradient descent
(SGD) for smooth convex objectives in the interpolation regime, where the noise
at optimum is zero or near zero. The behavior of the last iterate of SGD in
this setting -- particularly with large (constant) stepsizes -- has received
growing attention in recent years due to implications for the training of
over-parameterized models, as well as to analyzing forgetting in continual
learning and to understanding the convergence of the randomized Kaczmarz method
for solving linear systems. We establish that after $T$ steps of SGD on
$\beta$-smooth convex loss functions with stepsize $\eta \leq 1/\beta$, the
last iterate exhibits expected excess risk $\widetilde{O}(1/(\eta
T^{1-\beta\eta/2}) + \eta T^{\beta\eta/2} \sigma_\star^2)$, where
$\sigma_\star^2$ denotes the variance of the stochastic gradients at the
optimum. In particular, for a well-tuned stepsize we obtain a near optimal
$\widetilde{O}(1/T + \sigma_\star/\sqrt{T})$ rate for the last iterate,
extending the results of Varre et al. (2021) beyond least squares regression;
and when $\sigma_\star=0$ we obtain a rate of $O(1/\sqrt{T})$ with
$\eta=1/\beta$, improving upon the best-known $O(T^{-1/4})$ rate recently
established by Evron et al. (2025) in the special case of realizable linear
regression.

</details>


### [215] [Guiding LLM Decision-Making with Fairness Reward Models](https://arxiv.org/abs/2507.11344)
*Zara Hall,Melanie Subbiah,Thomas P Zollo,Kathleen McKeown,Richard Zemel*

Main category: cs.LG

TL;DR: 本研究提出了一个公平性奖励模型（FRM），通过弱监督学习训练，能够识别并降低大语言模型在高风险决策中的偏见，同时保持或提高准确性，并证明了其跨任务、跨领域和跨模型的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 为了解决在大语言模型（LLMs）被用于高风险决策（如保释或贷款审批）时，朴素的思维链采样可能放大数据中的不公平偏见的问题，本研究旨在实现可信赖的推理模型在这些决策中的应用。

Method: FRM模型通过弱监督、LLM标注的有偏见与无偏见推理示例进行训练，并展示了其在不同任务、领域和模型家族中的泛化能力。

Result: FRM在实际的决策制定任务（包括累犯预测和社交媒体内容审核）中，能够一致地提高公平性，同时保持甚至超越基线准确性。

Conclusion: 该研究提出了一个公平性奖励模型（FRM）框架，用于训练能够分配公平性分数的LLM，从而在聚合决策时降低有偏见的推理轨迹，偏向公平的轨迹。

Abstract: Large language models are increasingly used to support high-stakes decisions,
potentially influencing who is granted bail or receives a loan. Naive
chain-of-thought sampling can improve average decision accuracy, but has also
been shown to amplify unfair bias. To address this challenge and enable the
trustworthy use of reasoning models in high-stakes decision-making, we propose
a framework for training a generalizable Fairness Reward Model (FRM). Our model
assigns a fairness score to LLM reasoning, enabling the system to down-weight
biased trajectories and favor equitable ones when aggregating decisions across
reasoning chains. We show that a single Fairness Reward Model, trained on
weakly supervised, LLM-annotated examples of biased versus unbiased reasoning,
transfers across tasks, domains, and model families without additional
fine-tuning. Applied to real-world decision-making tasks including recidivism
prediction and social media moderation, we show that our approach consistently
improves fairness while matching, or even surpassing, baseline accuracy.

</details>


### [216] [Neurosymbolic Reasoning Shortcuts under the Independence Assumption](https://arxiv.org/abs/2507.11357)
*Emile van Krieken,Pasquale Minervini,Edoardo Ponti,Antonio Vergari*

Main category: cs.LG

TL;DR: The ubiquitous independence assumption in neuro-symbolic predictors hinders uncertainty modeling and causes models to succeed for the wrong reasons, a problem formally proven in this work.


<details>
  <summary>Details</summary>
Motivation: To settle the question of whether the independence assumption among symbolic concepts in neuro-symbolic predictors actually limits their capabilities, as argued by recent works but met with skepticism in the community.

Method: Formal proof showing that the independence assumption entails that a model can never represent uncertainty over certain concept combinations.

Result: The paper demonstrates that the independence assumption leads to a failure in modeling uncertainty and results in reasoning shortcuts, a pathological behavior in neuro-symbolic predictors.

Conclusion: The paper formally shows that the independence assumption among symbolic concepts in neuro-symbolic predictors prevents them from correctly modeling uncertainty and leads to reasoning shortcuts, where models succeed on tasks for the wrong reasons.

Abstract: The ubiquitous independence assumption among symbolic concepts in
neurosymbolic (NeSy) predictors is a convenient simplification: NeSy predictors
use it to speed up probabilistic reasoning. Recent works like van Krieken et
al. (2024) and Marconato et al. (2024) argued that the independence assumption
can hinder learning of NeSy predictors and, more crucially, prevent them from
correctly modelling uncertainty. There is, however, scepticism in the NeSy
community around the scenarios in which the independence assumption actually
limits NeSy systems (Faronius and Dos Martires, 2025). In this work, we settle
this question by formally showing that assuming independence among symbolic
concepts entails that a model can never represent uncertainty over certain
concept combinations. Thus, the model fails to be aware of reasoning shortcuts,
i.e., the pathological behaviour of NeSy predictors that predict correct
downstream tasks but for the wrong reasons.

</details>


### [217] [Local Pairwise Distance Matching for Backpropagation-Free Reinforcement Learning](https://arxiv.org/abs/2507.11367)
*Daniel Tanneberg*

Main category: cs.LG

TL;DR: 一种用于强化学习的无反向传播训练方法，利用前向传播中的局部信号和多维缩放的成对距离匹配来逐层训练网络，实现了与基于反向传播的方法相当的性能，并提高了稳定性和一致性。


<details>
  <summary>Details</summary>
Motivation: 反向传播（BP）通常需要存储前向传播的激活以进行后续的后向更新。此外，通过多个层反向传播误差信号可能导致梯度消失或爆炸，从而降低学习性能和稳定性。

Method: 提出一种在强化学习设置中，利用前向传播过程中的局部信号来训练神经网络各层的 novel 方法。该方法引入了利用多维缩放的成对距离匹配原理的局部、逐层损失，并辅以可选的奖励驱动指导。此方法允许使用在前向传播过程中计算出的局部信号来训练每个隐藏层，从而无需反向传播和存储中间激活。

Result: 通过策略梯度方法在常见的强化学习基准测试中进行实验，证明了这种无反向传播的方法可以达到与其经典的基于反向传播的对应方法相当的性能。此外，该方法提高了运行内外和跨运行的稳定性和一致性，并且在更具挑战性的环境中提高了性能。

Conclusion: 本方法在策略梯度方法和常见强化学习基准测试中实现了与经典基于反向传播的方法相当的性能，并且提高了运行内外和跨运行的稳定性和一致性，尤其是在复杂环境中。

Abstract: Training neural networks with reinforcement learning (RL) typically relies on
backpropagation (BP), necessitating storage of activations from the forward
pass for subsequent backward updates. Furthermore, backpropagating error
signals through multiple layers often leads to vanishing or exploding
gradients, which can degrade learning performance and stability. We propose a
novel approach that trains each layer of the neural network using local signals
during the forward pass in RL settings. Our approach introduces local,
layer-wise losses leveraging the principle of matching pairwise distances from
multi-dimensional scaling, enhanced with optional reward-driven guidance. This
method allows each hidden layer to be trained using local signals computed
during forward propagation, thus eliminating the need for backward passes and
storing intermediate activations. Our experiments, conducted with policy
gradient methods across common RL benchmarks, demonstrate that this
backpropagation-free method achieves competitive performance compared to their
classical BP-based counterpart. Additionally, the proposed method enhances
stability and consistency within and across runs, and improves performance
especially in challenging environments.

</details>


### [218] [A Neural Network Model of Complementary Learning Systems: Pattern Separation and Completion for Continual Learning](https://arxiv.org/abs/2507.11393)
*James P Jun,Vijay Marupudi,Raj Sanjay Shah,Sashank Varma*

Main category: cs.LG

TL;DR: 本研究提出了一种受大脑启发的持续学习模型，结合了VAE和MHN，以解决灾难性遗忘问题，并在MNIST任务上取得了良好效果。


<details>
  <summary>Details</summary>
Motivation: 为了解决神经网络在学习新信息时会灾难性遗忘先前知识的问题，借鉴了互补学习系统（CLS）理论，该理论提出大脑具有模式分离和模式补全的系统。

Method: 提出了一种结合变分自编码器（VAE）和现代霍普菲尔德网络（MHN）的持续学习模型，以模拟人类学习过程中模式分离和模式补全的互补功能。

Result: 模型在分割MNIST任务上取得了约90%的准确率，有效减少了遗忘。此外，通过表示分析验证了VAE在模式补全和MHN在模式分离方面的功能性分离。

Conclusion: 该模型通过结合变分自编码器（VAE）和现代霍普菲尔德网络（MHN），在分割MNIST任务上实现了接近最先进水平的准确率（约90%），显著减少了遗忘。实验分析证实了VAE在模式补全和MHN在模式分离方面的功能分离。

Abstract: Learning new information without forgetting prior knowledge is central to
human intelligence. In contrast, neural network models suffer from catastrophic
forgetting: a significant degradation in performance on previously learned
tasks when acquiring new information. The Complementary Learning Systems (CLS)
theory offers an explanation for this human ability, proposing that the brain
has distinct systems for pattern separation (encoding distinct memories) and
pattern completion (retrieving complete memories from partial cues). To capture
these complementary functions, we leverage the representational generalization
capabilities of variational autoencoders (VAEs) and the robust memory storage
properties of Modern Hopfield networks (MHNs), combining them into a neurally
plausible continual learning model. We evaluate this model on the Split-MNIST
task, a popular continual learning benchmark, and achieve close to
state-of-the-art accuracy (~90%), substantially reducing forgetting.
Representational analyses empirically confirm the functional dissociation: the
VAE underwrites pattern completion, while the MHN drives pattern separation. By
capturing pattern separation and completion in scalable architectures, our work
provides a functional template for modeling memory consolidation,
generalization, and continual learning in both biological and artificial
systems.

</details>


### [219] [Robust-Multi-Task Gradient Boosting](https://arxiv.org/abs/2507.11411)
*Seyedsaman Emami,Gonzalo Martínez-Muñoz,Daniel Hernández-Lobato*

Main category: cs.LG

TL;DR: R-MTGB 是一种新的梯度提升框架，可以稳健地处理多任务学习中的异常任务，通过将任务分为异常和非异常来提高性能。


<details>
  <summary>Details</summary>
Motivation: 现实世界的多任务学习场景通常涉及任务不对齐（异常或对抗性任务）的情况，这些任务与其他任务没有有益的相似性，并且实际上会降低整体模型的性能。为了克服这个挑战，我们提出了 R-MTGB。

Method: R-MTGB 框架将学习过程结构化为三个顺序块：(1) 学习共享模式，(2) 使用正则化参数将任务划分为异常和非异常任务，(3) 微调特定任务的预测器。该架构使 R-MTGB 能够自动检测和惩罚异常任务，同时促进相关任务之间的有效知识转移。该方法将这些机制无缝集成到梯度提升中，从而在不牺牲准确性的情况下稳健地处理噪声或对抗性任务。

Result: 广泛的实验表明，我们的方法成功地分离了异常任务，转移了知识，并持续降低了每个任务的预测误差，同时在所有任务中实现了整体性能的提升。

Conclusion: R-MTGB 在具有挑战性的多任务学习环境中展现了鲁棒性、适应性和可靠的收敛性，成功地分离了异常任务、转移了知识，并持续降低了每个任务的预测误差，同时在所有任务中实现了整体性能的提升。

Abstract: Multi-task learning (MTL) has shown effectiveness in exploiting shared
information across tasks to improve generalization. MTL assumes tasks share
similarities that can improve performance. In addition, boosting algorithms
have demonstrated exceptional performance across diverse learning problems,
primarily due to their ability to focus on hard-to-learn instances and
iteratively reduce residual errors. This makes them a promising approach for
learning multi-task problems. However, real-world MTL scenarios often involve
tasks that are not well-aligned (known as outlier or adversarial tasks), which
do not share beneficial similarities with others and can, in fact, deteriorate
the performance of the overall model. To overcome this challenge, we propose
Robust-Multi-Task Gradient Boosting (R-MTGB), a novel boosting framework that
explicitly models and adapts to task heterogeneity during training. R-MTGB
structures the learning process into three sequential blocks: (1) learning
shared patterns, (2) partitioning tasks into outliers and non-outliers with
regularized parameters, and (3) fine-tuning task-specific predictors. This
architecture enables R-MTGB to automatically detect and penalize outlier tasks
while promoting effective knowledge transfer among related tasks. Our method
integrates these mechanisms seamlessly within gradient boosting, allowing
robust handling of noisy or adversarial tasks without sacrificing accuracy.
Extensive experiments on both synthetic benchmarks and real-world datasets
demonstrate that our approach successfully isolates outliers, transfers
knowledge, and consistently reduces prediction errors for each task
individually, and achieves overall performance gains across all tasks. These
results highlight robustness, adaptability, and reliable convergence of R-MTGB
in challenging MTL environments.

</details>


### [220] [Toward Improving fNIRS Classification: A Study on Activation Functions in Deep Neural Architectures](https://arxiv.org/abs/2507.11436)
*Behtom Adeli,John McLinden,Pankaj Pandey,Ming Shao,Yalda Shahriari*

Main category: cs.LG

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Activation functions are critical to the performance of deep neural networks,
particularly in domains such as functional near-infrared spectroscopy (fNIRS),
where nonlinearity, low signal-to-noise ratio (SNR), and signal variability
poses significant challenges to model accuracy. However, the impact of
activation functions on deep learning (DL) performance in the fNIRS domain
remains underexplored and lacks systematic investigation in the current
literature. This study evaluates a range of conventional and field-specific
activation functions for fNIRS classification tasks using multiple deep
learning architectures, including the domain-specific fNIRSNet, AbsoluteNet,
MDNN, and shallowConvNet (as the baseline), all tested on a single dataset
recorded during an auditory task. To ensure fair a comparison, all networks
were trained and tested using standardized preprocessing and consistent
training parameters. The results show that symmetrical activation functions
such as Tanh and the Absolute value function Abs(x) can outperform commonly
used functions like the Rectified Linear Unit (ReLU), depending on the
architecture. Additionally, a focused analysis of the role of symmetry was
conducted using a Modified Absolute Function (MAF), with results further
supporting the effectiveness of symmetrical activation functions on performance
gains. These findings underscore the importance of selecting proper activation
functions that align with the signal characteristics of fNIRS data.

</details>


### [221] [Data Augmentation in Time Series Forecasting through Inverted Framework](https://arxiv.org/abs/2507.11439)
*Hongming Tan,Ting Chen,Ruochong Jin,Wai Kin Chan*

Main category: cs.LG

TL;DR: DAIF通过频率滤波和交叉变异打补丁策略，解决了iTransformer倒置框架在MTS预测中的不足，提升了预测效果。


<details>
  <summary>Details</summary>
Motivation: 现有的iTransformer模型虽然在多变量时间序列（MTS）预测方面表现优异，但其倒置框架在削弱时间依赖性信息和引入噪声方面存在局限性。

Method: 提出了一种名为DAIF的新型数据增强方法，该方法包含频率滤波和交叉变异打补丁两种策略，并将其应用于倒置框架以增强MTS预测能力。

Result: 实验结果表明，DAIF在多个数据集和倒置模型上均有效，证明了其在MTS预测中的优越性。

Conclusion: DAIF是一种新颖的、专门为MTS预测的倒置框架设计的数据增强方法，通过频率滤波和交叉变异打补丁策略，有效解决了倒置框架中时间依赖性信息减弱和噪声引入的问题。

Abstract: Currently, iTransformer is one of the most popular and effective models for
multivariate time series (MTS) forecasting. Thanks to its inverted framework,
iTransformer effectively captures multivariate correlation. However, the
inverted framework still has some limitations. It diminishes temporal
interdependency information, and introduces noise in cases of nonsignificant
variable correlation. To address these limitations, we introduce a novel data
augmentation method on inverted framework, called DAIF. Unlike previous data
augmentation methods, DAIF stands out as the first real-time augmentation
specifically designed for the inverted framework in MTS forecasting. We first
define the structure of the inverted sequence-to-sequence framework, then
propose two different DAIF strategies, Frequency Filtering and Cross-variation
Patching to address the existing challenges of the inverted framework.
Experiments across multiple datasets and inverted models have demonstrated the
effectiveness of our DAIF.

</details>


### [222] [LRMR: LLM-Driven Relational Multi-node Ranking for Lymph Node Metastasis Assessment in Rectal Cancer](https://arxiv.org/abs/2507.11457)
*Yaoxian Dong,Yifan Gao,Haoyue Li,Yanfen Cui,Xin Gao*

Main category: cs.LG

TL;DR: LRMR框架利用两阶段LLM（多模态分析生成结构化报告，文本模型进行跨患者相对排序）提升直肠癌淋巴结转移评估的准确性和可解释性，效果优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 传统的基于形态学指标的MRI评估在直肠癌淋巴结转移的术前评估中诊断性能有限，且现有AI模型常作为黑箱缺乏临床可信度，并忽视患者层面的背景信息。

Method: 提出LRMR框架，一个LLM驱动的关系多节点排序框架，将诊断任务从直接分类重构为结构化推理和排序过程。该框架分两阶段：1.多模态大语言模型分析患者所有淋巴结的组合蒙太奇图像，生成包含十个不同放射学特征的结构化报告。2.基于文本的大语言模型对不同患者的报告进行成对比较，基于不良特征的严重性和数量建立相对风险排序。

Result: 在117名直肠癌患者的回顾性队列中，LRMR达到了0.7917的AUC和0.7200的F1分数，优于ResNet50等深度学习基线（AUC 0.7708）。消融研究表明，移除关系排序或结构化提示阶段都会导致性能显著下降（AUC分别降至0.6875和0.6458）。

Conclusion: LRMR框架通过解耦视觉感知与认知推理的两阶段LLM方法，为评估直肠癌淋巴结转移提供了一种强大、可解释且有效的新范式。

Abstract: Accurate preoperative assessment of lymph node (LN) metastasis in rectal
cancer guides treatment decisions, yet conventional MRI evaluation based on
morphological criteria shows limited diagnostic performance. While some
artificial intelligence models have been developed, they often operate as black
boxes, lacking the interpretability needed for clinical trust. Moreover, these
models typically evaluate nodes in isolation, overlooking the patient-level
context. To address these limitations, we introduce LRMR, an LLM-Driven
Relational Multi-node Ranking framework. This approach reframes the diagnostic
task from a direct classification problem into a structured reasoning and
ranking process. The LRMR framework operates in two stages. First, a multimodal
large language model (LLM) analyzes a composite montage image of all LNs from a
patient, generating a structured report that details ten distinct radiological
features. Second, a text-based LLM performs pairwise comparisons of these
reports between different patients, establishing a relative risk ranking based
on the severity and number of adverse features. We evaluated our method on a
retrospective cohort of 117 rectal cancer patients. LRMR achieved an area under
the curve (AUC) of 0.7917 and an F1-score of 0.7200, outperforming a range of
deep learning baselines, including ResNet50 (AUC 0.7708). Ablation studies
confirmed the value of our two main contributions: removing the relational
ranking stage or the structured prompting stage led to a significant
performance drop, with AUCs falling to 0.6875 and 0.6458, respectively. Our
work demonstrates that decoupling visual perception from cognitive reasoning
through a two-stage LLM framework offers a powerful, interpretable, and
effective new paradigm for assessing lymph node metastasis in rectal cancer.

</details>


### [223] [Exploring the robustness of TractOracle methods in RL-based tractography](https://arxiv.org/abs/2507.11486)
*Jeremi Levesque,Antoine Théberge,Maxime Descoteaux,Pierre-Marc Jodoin*

Main category: cs.LG

TL;DR: 本文通过结合 Oracle 与强化学习（RL）框架，并引入迭代奖励训练（IRT）方案，显著提高了脑白质纤维追踪的准确性和可靠性。


<details>
  <summary>Details</summary>
Motivation: 为了提高基于扩散 MRI 的神经束追踪算法的性能，特别是在减少假阳性和提高准确性与解剖学有效性方面，本文探索了强化学习 (RL) 框架，特别是 TractOracle-RL 及其改进方法。

Method: 本文提出了四种 TractOracle-RL 框架的扩展，并引入了一种新的迭代奖励训练 (IRT) 方案，该方案借鉴了人类反馈强化学习 (RLHF) 的思想，利用束过滤方法在训练过程中迭代地优化 Oracle 的指导。

Result: 实验结果表明，结合 Oracle 的 RL 框架在各种数据集上均表现出稳健且可靠的追踪性能。IRT 训练方案训练的 RL 方法在准确性和解剖学有效性方面显著优于常用的神经束追踪技术。

Conclusion: 结合 Oracle 与 RL 框架，并采用 IRT 训练方案，能够显著提高神经束追踪的准确性和解剖学有效性，且在不同数据集上表现稳健。

Abstract: Tractography algorithms leverage diffusion MRI to reconstruct the fibrous
architecture of the brain's white matter. Among machine learning approaches,
reinforcement learning (RL) has emerged as a promising framework for
tractography, outperforming traditional methods in several key aspects.
TractOracle-RL, a recent RL-based approach, reduces false positives by
incorporating anatomical priors into the training process via a reward-based
mechanism. In this paper, we investigate four extensions of the original
TractOracle-RL framework by integrating recent advances in RL, and we evaluate
their performance across five diverse diffusion MRI datasets. Results
demonstrate that combining an oracle with the RL framework consistently leads
to robust and reliable tractography, regardless of the specific method or
dataset used. We also introduce a novel RL training scheme called Iterative
Reward Training (IRT), inspired by the Reinforcement Learning from Human
Feedback (RLHF) paradigm. Instead of relying on human input, IRT leverages
bundle filtering methods to iteratively refine the oracle's guidance throughout
training. Experimental results show that RL methods trained with oracle
feedback significantly outperform widely used tractography techniques in terms
of accuracy and anatomical validity.

</details>


### [224] [Langevin Flows for Modeling Neural Latent Dynamics](https://arxiv.org/abs/2507.11531)
*Yue Song,T. Anderson Keller,Yisong Yue,Pietro Perona,Max Welling*

Main category: cs.LG

TL;DR: LangevinFlow是一种新的变分自编码器，它使用Langevin动力学来模拟神经元群体活动，并结合物理原理，在各种数据集上均表现出色。


<details>
  <summary>Details</summary>
Motivation: 神经元群体表现出潜在的动力学结构，驱动着随时间变化的放电活动，这促使人们寻找能够同时捕捉内在网络动力学和外部未观测影响的模型。

Method: 提出了一种名为LangevinFlow的序列变分自编码器，其潜在变量的时间演化由欠阻尼Langevin方程控制，并结合了物理先验（惯性、阻尼、学习势函数和随机力）来表示神经系统中的自主和非自主过程。势函数被参数化为局部耦合振荡器的网络，以偏向生物神经元群体中观察到的振荡和流动行为。该模型包含一个递归编码器、一个单层Transformer解码器以及潜在空间中的Langevin动力学。

Result: 在由洛伦兹吸引子生成的合成神经元群体上，该方法优于最先进的基线方法，并精确匹配了真实的放电率。在神经潜在基准（NLB）上，该模型在四个具有挑战性的数据集上实现了更优的（每脉冲比特）预测准确性和前向预测准确性。此外，它在解码行为指标（如手部速度）方面与替代方法相当或更优。

Conclusion: 该模型为理解神经元群体动力学及其未观测影响提供了一个灵活、受物理学启发的、高性能的框架。

Abstract: Neural populations exhibit latent dynamical structures that drive
time-evolving spiking activities, motivating the search for models that capture
both intrinsic network dynamics and external unobserved influences. In this
work, we introduce LangevinFlow, a sequential Variational Auto-Encoder where
the time evolution of latent variables is governed by the underdamped Langevin
equation. Our approach incorporates physical priors -- such as inertia,
damping, a learned potential function, and stochastic forces -- to represent
both autonomous and non-autonomous processes in neural systems. Crucially, the
potential function is parameterized as a network of locally coupled
oscillators, biasing the model toward oscillatory and flow-like behaviors
observed in biological neural populations. Our model features a recurrent
encoder, a one-layer Transformer decoder, and Langevin dynamics in the latent
space. Empirically, our method outperforms state-of-the-art baselines on
synthetic neural populations generated by a Lorenz attractor, closely matching
ground-truth firing rates. On the Neural Latents Benchmark (NLB), the model
achieves superior held-out neuron likelihoods (bits per spike) and forward
prediction accuracy across four challenging datasets. It also matches or
surpasses alternative methods in decoding behavioral metrics such as hand
velocity. Overall, this work introduces a flexible, physics-inspired,
high-performing framework for modeling complex neural population dynamics and
their unobserved influences.

</details>


<div id='cs.GT'></div>

# cs.GT [[Back]](#toc)

### [225] [Protocols for Verifying Smooth Strategies in Bandits and Games](https://arxiv.org/abs/2507.10567)
*Miranda Christ,Daniel Reichman,Jonathan Shafer*

Main category: cs.GT

TL;DR: 本研究提出了用于验证多臂老虎机和标准型博弈中策略近似最优性的高效协议，其查询复杂度相对于动作数量呈亚线性，优于现有学习方法。


<details>
  <summary>Details</summary>
Motivation: 多臂老虎机和标准型博弈中，策略的动作数量可能非常庞大，导致传统的验证方法需要大量的查询。本研究旨在设计更高效的验证协议，其查询复杂度相对于动作数量是亚线性的，从而在实际应用中更具可行性。

Method: 本研究提出并分析了在多臂老虎机（multi-armed bandits）和标准型博弈（normal-form games）中验证策略近似最优性的协议。研究的重点是开发查询数量相对于动作数量呈亚线性增长的验证协议，尤其适用于动作数量庞大的情况。对于具有特定光滑性质（即策略不会在任何单一动作上分配过多的概率质量）的策略，研究证明了这种亚线性验证是可行的。研究中提供了具体的协议，用于验证多臂老虎机中的光滑策略是否达到了ε-最优性。这些验证协议在臂查询次数上优于学习算法。同时，研究还建立了该设定下查询复杂性的近乎紧密的下界。最后，研究展示了如何将老虎机验证技术应用于标准型博弈，以验证策略组合是否构成近似强光滑纳什均衡，其查询复杂度同样低于动作数量的线性。

Result: 研究成功开发了用于验证多臂老虎机中光滑策略近似最优性的协议，其查询复杂度优于学习算法，并建立了近乎紧密的下界。此外，研究将此技术扩展到标准型博弈，实现了对近似强光滑纳什均衡的亚线性查询复杂度验证。

Conclusion: 在多臂老虎机和标准型博弈中，研究了验证策略近似最优性的协议。我们证明了对于足够光滑且不会在任何特定动作上投入过多概率质量的策略，可以实现查询数量相对于动作数量的亚线性验证。我们提供了验证光滑策略在多臂老虎机中是否为ε-最优的协议，这些协议所需的臂查询次数比学习所需的少。此外，我们还为我们设定的查询复杂性建立了一个近乎紧密的下界。作为应用，我们将老虎机验证用于博弈中的验证，实现了对给定策略组合是否为近似强光滑纳什均衡的验证，其查询复杂度也低于动作数量的线性。

Abstract: We study protocols for verifying approximate optimality of strategies in
multi-armed bandits and normal-form games. As the number of actions available
to each player is often large, we seek protocols where the number of queries to
the utility oracle is sublinear in the number of actions. We prove that such
verification is possible for sufficiently smooth strategies that do not put too
much probability mass on any specific action. We provide protocols for
verifying that a smooth policy for a multi-armed bandit is
$\varepsilon$-optimal. Our verification protocols require provably fewer arm
queries than learning. Furthermore, we establish a nearly-tight lower bound on
the query complexity of verification in our settings. As an application, we
show how to use verification for bandits to achieve verification in normal-form
games. This gives a protocol for verifying whether a given strategy profile is
an approximate strong smooth Nash equilibrium, with a query complexity that is
sublinear in the number of actions.

</details>


### [226] [Pricing with Tips in Three-Sided Delivery Platforms](https://arxiv.org/abs/2507.10872)
*Yannai A. Gonczarowski,Gary Qiurui Ma,David C. Parkes*

Main category: cs.GT

TL;DR: 本文研究了带小费和不带小费的配送平台的均衡。有小费时，均衡总是存在的，且福利更高，但并非总能保证最优均衡。研究提出了在特定市场条件下保证存在并能高效计算最优均衡的方法。


<details>
  <summary>Details</summary>
Motivation: 本文旨在说明小费在定价中的作用，并研究有小费和无小费情况下的均衡存在性、效率和计算复杂度。

Method: 本文考虑了一个促进买家、商店和快递员之间交易的配送平台。除了买家支付特定于商店的购买价格以及快递员从平台接收特定于商店-买家的配送补偿外，每位买家还可以选择直接为特定商店的配送提供小费。均衡由清算市场的价格、补偿、小费和交易组成，以便买家在考虑他们支付的价格和小费的情况下，从偏好的商店获得配送，并且快递员在考虑他们收到的补偿和小费的情况下，配送偏好的订单。

Result: 有小费的情况下，总能保证存在一个均衡，而没有小费的情况下，仅当快递员数量不不少于买家或商店数量时，才能保证存在均衡。有小费情况下的最优均衡福利总是弱大于没有小费情况下的最优均衡福利。然而，即使有小费，也可能不存在有效的均衡，并且计算最优均衡福利是NP难的。

Conclusion: 在有小费的情况下，总能保证存在一个均衡，而没有小费的情况下，仅当快递员数量不少于买家或商店数量时，才能保证存在均衡。然而，即使有小费，也可能不存在有效的均衡，并且计算最优均衡福利是NP难的。通过识别市场结构上的自然条件，可以确保存在有效的有小费均衡，并能在多项式时间内计算出这些有效的均衡。

Abstract: We model a delivery platform facilitating transactions among three sides:
buyers, stores, and couriers. In addition to buyers paying store-specific
purchase prices and couriers receiving store--buyer-specific delivery
compensation from the platform, each buyer has the option to directly tip for
delivery from a specific store. An equilibrium consists of prices,
compensations, tips, and transactions that clear the market, such that buyers
receive deliveries from preferred stores considering the prices and tips they
pay, and couriers deliver preferred orders considering the compensations and
tips they receive.
  We illustrate the role of tips in pricing: Without tips, an equilibrium is
only guaranteed to exist when there are at least as many couriers as buyers or
stores. In contrast, with tips an equilibrium always exists. From an efficiency
perspective, the optimal with-tip equilibrium welfare is always weakly larger
than the optimal without-tip equilibrium welfare. However, we show that even
with tips, efficient equilibria may not exist, and calculating the optimal
equilibrium welfare is NP-hard. To address these challenges, we identify
natural conditions on market structure that ensure the existence of efficient
with-tip equilibria and allow these efficient equilibria to be computed in
polynomial time.

</details>


### [227] [Fair Contracts](https://arxiv.org/abs/2507.11214)
*Matteo Castiglioni,Junjie Chen,Yingkai Li*

Main category: cs.GT

TL;DR: 本研究解决了在公平性约束下设计最优合同的问题，并提出了几种算法来处理不同的公平性定义和约束条件。


<details>
  <summary>Details</summary>
Motivation: 本研究的动机是设计在公平性约束下最优的合同，并研究了公平性对合同设计的影响。

Method: 本研究采用公平（EF）及其放松形式 $\epsilon$-EF 和公平（除了一个项目）（EF1）的概念，研究了在公平性约束下设计最优合同的问题。

Result: 对于 EF 合同，当代理人数量恒定时，可以设计一个 FPTAS。当任务数量恒定时，可以设计一个多项式时间算法来计算最优 EF 合同。EF1 合同的公平价格有界，在 $\Omega(\sqrt{n})$ 和 $O(n^2)$ 之间，其中 n 是代理人的数量。然而，对于精确的 EF 合同，公平价格可能是无限的。

Conclusion: EF 合同的确存在，但计算任何常数因子近似的最优 EF 合同在一般情况下是 NP-hard 的，即使使用 $\epsilon$-EF 合同也是如此。然而，当代理人数量恒定时，我们能够设计一个关于 $\epsilon$-EF 和 EF1 的 FPTAS。此外，当任务数量恒定时，我们提出了一种计算最优 EF 合同的多项式时间算法。最后，我们分析了合同设计中的公平价格。

Abstract: We introduce and study the problem of designing optimal contracts under
fairness constraints on the task assignments and compensations. We adopt the
notion of envy-free (EF) and its relaxations, $\epsilon$-EF and envy-free up to
one item (EF1), in contract design settings. Unlike fair allocations, EF
contracts are guaranteed to exist. However, computing any constant-factor
approximation to the optimal EF contract is NP-hard in general, even using
$\epsilon$-EF contracts. For this reason, we consider settings in which the
number of agents or tasks is constant. Notably, while even with three agents,
finding an EF contract better than $2/5$ approximation of the optimal is
NP-hard, we are able to design an FPTAS when the number of agents is constant,
under relaxed notions of $\epsilon$-EF and EF1. Moreover, we present a
polynomial-time algorithm for computing the optimal EF contract when the number
of tasks is constant. Finally, we analyze the price of fairness in contract
design. We show that the price of fairness for exact EF contracts can be
unbounded, even with a single task and two agents. In contrast, for EF1
contracts, the price of fairness is bounded between $\Omega(\sqrt{n})$ and
$O(n^2)$, where $n$ is the number of agents.

</details>


### [228] [A Parallelizable Approach for Characterizing NE in Zero-Sum Games After a Linear Number of Iterations of Gradient Descent](https://arxiv.org/abs/2507.11366)
*Taemin Kim,James P. Bailey*

Main category: cs.GT

TL;DR: 提出一种基于哈密顿动力学的新在线优化方法，用于零和博弈，具有有限迭代、可并行化、任意学习率的优点，性能优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 零和博弈的在线优化是机器学习、经济学等领域中的一个基础性问题。传统方法在近似纳什均衡（NE）时存在收敛速度和并行化等方面的局限性。本文旨在提出一种更高效、更通用的方法来解决这个问题。

Method: 本文提出了一种基于物理学中哈密顿动力学的新方法，用于在线优化零和博弈。该方法通过有限次的交替梯度下降迭代，能够精确刻画纳什均衡集（在简并情况下），并且可以并行化，适用于任意学习率。

Result: 所提出的方法能够以有限次数的迭代刻画纳什均衡集，且该方法可以并行化，并适用于任意学习率。实验结果证明，该方法在性能上远超标准方法。

Conclusion: 本文提出的基于哈密顿动力学的新方法，在解决零和博弈的在线优化问题上取得了突破性进展，能够以有限的迭代次数精确刻画纳什均衡集，并且具有可并行化和任意学习率的优点，实验结果表明其性能显著优于传统方法。

Abstract: We study online optimization methods for zero-sum games, a fundamental
problem in adversarial learning in machine learning, economics, and many other
domains. Traditional methods approximate Nash equilibria (NE) using either
regret-based methods (time-average convergence) or contraction-map-based
methods (last-iterate convergence). We propose a new method based on
Hamiltonian dynamics in physics and prove that it can characterize the set of
NE in a finite (linear) number of iterations of alternating gradient descent in
the unbounded setting, modulo degeneracy, a first in online optimization.
Unlike standard methods for computing NE, our proposed approach can be
parallelized and works with arbitrary learning rates, both firsts in
algorithmic game theory. Experimentally, we support our results by showing our
approach drastically outperforms standard methods.

</details>


### [229] [Better Regret Rates in Bilateral Trade via Sublinear Budget Violation](https://arxiv.org/abs/2507.11419)
*Anna Lunghi,Matteo Castiglioni,Alberto Marchesi*

Main category: cs.GT

TL;DR: 通过放宽预算平衡约束，可以实现更好的遗憾界。该研究提出了一个在 $\beta \in [\frac{3}{4}, \frac{6}{7}]$ 范围内，预算违反最多为 $T^{\beta}$ 时，遗憾界为 $\tilde O(T^{1 - \beta/3})$ 的算法，并给出了匹配的下界。


<details>
  <summary>Details</summary>
Motivation: 研究了在双边交易机制中，当预算平衡约束被放宽时，遗憾与预算违反之间的权衡。

Method: 提出了一种算法，该算法通过允许以最多 $T^{\beta}$ 的方式违反全局预算平衡约束（其中 $\beta \in [\frac{3}{4}, \frac{6}{7}]$），实现了 $\tilde O(T^{1 - \beta/3})$ 的遗憾界。

Result: 设计了一种算法，其遗憾界为 $\tilde O(T^{1 - \beta/3})$，并给出了匹配的下界，完全刻画了遗憾与预算违反之间的权衡。

Conclusion: 该研究完全刻画了 the trade-off between regret and budget violation，并证明了 Bernasconi et al. [Ber+24] 得到的界是紧确的。

Abstract: Bilateral trade is a central problem in algorithmic economics, and recent
work has explored how to design trading mechanisms using no-regret learning
algorithms. However, no-regret learning is impossible when budget balance has
to be enforced at each time step. Bernasconi et al. [Ber+24] show how this
impossibility can be circumvented by relaxing the budget balance constraint to
hold only globally over all time steps. In particular, they design an algorithm
achieving regret of the order of $\tilde O(T^{3/4})$ and provide a lower bound
of $\Omega(T^{5/7})$.
  In this work, we interpolate between these two extremes by studying how the
optimal regret rate varies with the allowed violation of the global budget
balance constraint. Specifically, we design an algorithm that, by violating the
constraint by at most $T^{\beta}$ for any given $\beta \in [\frac{3}{4},
\frac{6}{7}]$, attains regret $\tilde O(T^{1 - \beta/3})$. We complement this
result with a matching lower bound, thus fully characterizing the trade-off
between regret and budget violation. Our results show that both the $\tilde
O(T^{3/4})$ upper bound in the global budget balance case and the
$\Omega(T^{5/7})$ lower bound under unconstrained budget balance violation
obtained by Bernasconi et al. [Ber+24] are tight.

</details>


### [230] [On the Complexity of the Optimal Correlated Equilibria in Extensive-Form Games](https://arxiv.org/abs/2507.11509)
*Vincent Cheval,Florian Horn,Soumyajit Paul,Mahsa Shirmohammadi*

Main category: cs.GT

TL;DR: 研究扩展形式游戏中各种相关均衡概念的计算复杂性，发现 NFCE 比 Nash 均衡更难计算，并为 NP-complete 性提供了完整的复杂性图景。


<details>
  <summary>Details</summary>
Motivation: 解决算法博弈论中的一个主要未解问题，即在诸如扩展形式游戏等压缩博弈中是否可以有效计算范式相关均衡 (NFCE)。

Method: 通过证明 NFCE 的阈值问题在具有完美回忆的多人扩展形式游戏中是 PSPACE-hard，以及 AFCE 的阈值问题在两人游戏中是 NP-hard 来建立复杂性。通过提供 NP 上界来补充硬度结果，从而在各种相关均衡概念中获得最佳均衡计算的完整复杂性图景。

Result: NFCE 的阈值问题在具有完美回忆的多人扩展形式游戏中是 PSPACE-hard 的，而 Nash 均衡的阈值问题是 ER-complete 的。AFCE 的阈值问题在两人游戏中是 NP-hard 的。此外，EFCE、AFCE、范式粗略、扩展形式粗略和代理形式粗略相关均衡的阈值问题已被证明是 NP-complete 的。

Conclusion: 计算 NFCE、EFCE 和 AFCE 的阈值问题，并在多人随机扩展形式游戏中提供 NP-完备性的最佳分类，以揭示扩展形式游戏中的复杂性反转。

Abstract: A major open question in algorithmic game theory is whether normal-form
correlated equilibria (NFCE) can be computed efficiently in succinct games such
as extensive-form games [DFF+25,6PR24,FP23,HvS08,VSF08,PR08]. Motivated by this
question, we study the associated Threshold problem: deciding whether there
exists a correlated equilibrium whose value exceeds a given threshold. We prove
that this problem is PSPACE-hard for NFCE in multiplayer extensive-form games
with perfect recall, even for fixed thresholds. To contextualize this result,
we also establish the complexity of the Threshold problem for Nash equilibria
in this setting, showing it is ER-complete. These results uncover a surprising
complexity reversal: while optimal correlated equilibria are computationally
simpler than optimal Nash in normal-form games, the opposite holds in
extensive-form games, where computing optimal correlated equilibria is provably
harder. Building on this line of inquiry, we also address a related question by
[VSF08], who introduced the notions of extensive-form correlated equilibrium
(EFCE) and agent-form correlated equilibrium (AFCE). They asked how difficult
the Threshold problem is for AFCE; we answer this question by proving that it
is NP-hard, even in two-player games without chance nodes. Complementing our
hardness results, we establish tight complexity classifications for the
Threshold problem across several correlated equilibrium concepts - including
EFCE, AFCE, normal-form coarse, extensive-form coarse, and agent-form coarse
correlated equilibria. For each of these solution concepts in multiplayer
stochastic extensive-form games with perfect recall, we prove NP-completeness
by providing matching NP upper bounds to the previously known hardness results.
Together, our results provide the most complete landscape to date for the
complexity of optimal equilibrium computation in extensive-form games.

</details>


<div id='eess.IV'></div>

# eess.IV [[Back]](#toc)

### [231] [Latent Space Consistency for Sparse-View CT Reconstruction](https://arxiv.org/abs/2507.11152)
*Duoyou Chen,Yunqing Chen,Can Zhang,Zhou Wang,Cheng Chen,Ruoxiu Xiao*

Main category: eess.IV

TL;DR: CLS-DM通过跨模态对比学习解决2D X射线到3D CT重建的潜在空间对齐问题，在稀疏CT重建中表现优于现有方法，并可推广到其他跨模态任务。


<details>
  <summary>Details</summary>
Motivation: 为了解决现有潜在扩散模型（LDM）在2D X射线模态和3D CT模态的潜在表示之间存在显著差异，导致在潜在空间中无法有效对齐的问题，以应对CT扫描时间长和辐射暴露量大的挑战。

Method: 提出了一致性潜在空间扩散模型（CLS-DM），该模型通过跨模态特征对比学习，从2D X射线图像中有效地提取潜在的3D信息，并实现模态间的潜在空间对齐。

Result: CLS-DM在LIDC-IDRI和CTSpine1K数据集上，在PSNR和SSIM等标准体素级指标方面，优于经典和最先进的生成模型。

Conclusion: CLS-DM在LIDC-IDRI和CTSpine1K数据集上，在PSNR和SSIM等标准体素级指标方面，优于经典和最先进的生成模型。该方法不仅有助于提高稀疏X射线重建CT的有效性和经济性，还可以推广到其他跨模态转换任务，例如文本到图像合成。

Abstract: Computed Tomography (CT) is a widely utilized imaging modality in clinical
settings. Using densely acquired rotational X-ray arrays, CT can capture 3D
spatial features. However, it is confronted with challenged such as significant
time consumption and high radiation exposure. CT reconstruction methods based
on sparse-view X-ray images have garnered substantial attention from
researchers as they present a means to mitigate costs and risks. In recent
years, diffusion models, particularly the Latent Diffusion Model (LDM), have
demonstrated promising potential in the domain of 3D CT reconstruction.
Nonetheless, due to the substantial differences between the 2D latent
representation of X-ray modalities and the 3D latent representation of CT
modalities, the vanilla LDM is incapable of achieving effective alignment
within the latent space. To address this issue, we propose the Consistent
Latent Space Diffusion Model (CLS-DM), which incorporates cross-modal feature
contrastive learning to efficiently extract latent 3D information from 2D X-ray
images and achieve latent space alignment between modalities. Experimental
results indicate that CLS-DM outperforms classical and state-of-the-art
generative models in terms of standard voxel-level metrics (PSNR, SSIM) on the
LIDC-IDRI and CTSpine1K datasets. This methodology not only aids in enhancing
the effectiveness and economic viability of sparse X-ray reconstructed CT but
can also be generalized to other cross-modal transformation tasks, such as
text-to-image synthesis. We have made our code publicly available at
https://anonymous.4open.science/r/CLS-DM-50D6/ to facilitate further research
and applications in other domains.

</details>


### [232] [3D Magnetic Inverse Routine for Single-Segment Magnetic Field Images](https://arxiv.org/abs/2507.11293)
*J. Senthilnath,Chen Hao,F. C. Wellstood*

Main category: eess.IV

TL;DR: 3D MIR是一种结合了CNN、物理约束和优化的新方法，用于通过磁场图像（MFI）精确恢复半导体封装中导线的3D信息，在无损检测中具有重要应用价值。


<details>
  <summary>Details</summary>
Motivation: 在半导体封装中，为了无损检测（NDT）定位电路缺陷，精确恢复3D信息至关重要。

Method: 3D MIR方法整合了基于深度学习（DL）的卷积神经网络（CNN）、基于空间物理的约束以及优化技术。该方法分为三个阶段：1. CNN模型处理磁场图像（MFI）数据，预测导线长度（ℓ）和垂直深度（z_o），并对线段类型（c）进行分类。2. 利用空间物理约束，为线段的位置（x_o, y_o, z_o）、长度（ℓ）、电流（I）和电流方向提供初始估计。3. 优化器调整这五个参数（x_o, y_o, z_o, ℓ, I），以最小化重建的MFI与实际MFI之间的差异。

Result: 结果表明，3D MIR方法能够高精度地恢复3D信息。

Conclusion: 该方法结合了深度学习和基于物理的优化，在半导体封装的磁场图像重建方面设定了新的基准，展示了在实际应用中的潜力。

Abstract: In semiconductor packaging, accurately recovering 3D information is crucial
for non-destructive testing (NDT) to localize circuit defects. This paper
presents a novel approach called the 3D Magnetic Inverse Routine (3D MIR),
which leverages Magnetic Field Images (MFI) to retrieve the parameters for the
3D current flow of a single-segment. The 3D MIR integrates a deep learning
(DL)-based Convolutional Neural Network (CNN), spatial-physics-based
constraints, and optimization techniques. The method operates in three stages:
i) The CNN model processes the MFI data to predict ($\ell/z_o$), where $\ell$
is the wire length and $z_o$ is the wire's vertical depth beneath the magnetic
sensors and classify segment type ($c$). ii) By leveraging
spatial-physics-based constraints, the routine provides initial estimates for
the position ($x_o$, $y_o$, $z_o$), length ($\ell$), current ($I$), and current
flow direction (positive or negative) of the current segment. iii) An optimizer
then adjusts these five parameters ($x_o$, $y_o$, $z_o$, $\ell$, $I$) to
minimize the difference between the reconstructed MFI and the actual MFI. The
results demonstrate that the 3D MIR method accurately recovers 3D information
with high precision, setting a new benchmark for magnetic image reconstruction
in semiconductor packaging. This method highlights the potential of combining
DL and physics-driven optimization in practical applications.

</details>


### [233] [HANS-Net: Hyperbolic Convolution and Adaptive Temporal Attention for Accurate and Generalizable Liver and Tumor Segmentation in CT Imaging](https://arxiv.org/abs/2507.11325)
*Arefin Ittesafun Abian,Ripon Kumar Debnath,Md. Abdur Rahman,Mohaimenul Azam Khan Raiaan,Md Rafiqul Islam,Asif Karim,Reem E. Mohamed,Sami Azam*

Main category: eess.IV

TL;DR: HANS-Net是一個用於肝臟和腫瘤分割的新框架，通過結合多種先進技術，在準確性和泛化能力方面取得了優異的結果。


<details>
  <summary>Details</summary>
Motivation: 準確的肝臟和腫瘤分割對於可靠的診斷和治療計劃至關重要，但由於複雜的解剖結構、腫瘤外觀的差異以及標註數據的限制，仍然具有挑戰性。

Method: HANS-Net是一個新穎的分割框架，結合了雙曲卷積、小波分解模塊、突觸可塑性機制和隱含神經表示分支。它還結合了不確定性感知蒙特卡洛dropout和輕量級時間注意力。

Result: HANS-Net在LiTS數據集上達到了93.26%的平均Dice分數、88.09%的IoU、0.72毫米的平均對稱表面距離（ASSD）和11.91%的體積重疊誤差（VOE）。在3D-IRCADb-01數據集上進行的交叉數據集驗證，平均Dice為87.45%、IoU為80.30%、ASSD為1.525毫米和VOE為19.71%。

Conclusion: HANS-Net在提供解剖一致、準確且可靠的肝臟和腫瘤分割方面，有效且穩健。

Abstract: Accurate liver and tumor segmentation on abdominal CT images is critical for
reliable diagnosis and treatment planning, but remains challenging due to
complex anatomical structures, variability in tumor appearance, and limited
annotated data. To address these issues, we introduce Hyperbolic-convolutions
Adaptive-temporal-attention with Neural-representation and Synaptic-plasticity
Network (HANS-Net), a novel segmentation framework that synergistically
combines hyperbolic convolutions for hierarchical geometric representation, a
wavelet-inspired decomposition module for multi-scale texture learning, a
biologically motivated synaptic plasticity mechanism for adaptive feature
enhancement, and an implicit neural representation branch to model fine-grained
and continuous anatomical boundaries. Additionally, we incorporate
uncertainty-aware Monte Carlo dropout to quantify prediction confidence and
lightweight temporal attention to improve inter-slice consistency without
sacrificing efficiency. Extensive evaluations of the LiTS dataset demonstrate
that HANS-Net achieves a mean Dice score of 93.26%, an IoU of 88.09%, an
average symmetric surface distance (ASSD) of 0.72 mm, and a volume overlap
error (VOE) of 11.91%. Furthermore, cross-dataset validation on the
3D-IRCADb-01 dataset obtains an average Dice of 87.45%, IoU of 80.30%, ASSD of
1.525 mm, and VOE of 19.71%, indicating strong generalization across different
datasets. These results confirm the effectiveness and robustness of HANS-Net in
providing anatomically consistent, accurate, and confident liver and tumor
segmentation.

</details>


<div id='cs.MA'></div>

# cs.MA [[Back]](#toc)

### [234] [A Learning Framework For Cooperative Collision Avoidance of UAV Swarms Leveraging Domain Knowledge](https://arxiv.org/abs/2507.10913)
*Shuangyao Huang,Haibo Zhang,Zhiyi Huang*

Main category: cs.MA

TL;DR: 一种新的 MARL 框架，使用基于图像处理的轮廓逼近方法来驱动奖励，以实现无人机群的协作避障。与现有方法相比，它减少了智能体交互，并提高了在复杂环境中的适应性。


<details>
  <summary>Details</summary>
Motivation: 为了解决无人机群在协作避开碰撞时遇到的挑战，特别是在大规模应用和复杂环境适应性方面。

Method: 提出了一种多智能体强化学习（MARL）框架，利用图像处理领域的知识来获取奖励，将障碍物建模为二维场上的极值点，通过逼近轮廓来避免碰撞。该方法通过最小化智能体交互和消除复杂的信用分配方案或观测共享机制，实现了大规模训练。

Result: 实验证明，该框架在无人机群协作避障方面性能优于现有的 MARL 算法，并且能够适应包含非可行或不存在轮廓的复杂环境。

Conclusion: 该框架通过利用领域知识驱动的奖励，实现了无人机群协作避障，能够适应复杂环境并减少训练中的交互需求。

Abstract: This paper presents a multi-agent reinforcement learning (MARL) framework for
cooperative collision avoidance of UAV swarms leveraging domain
knowledge-driven reward. The reward is derived from knowledge in the domain of
image processing, approximating contours on a two-dimensional field. By
modeling obstacles as maxima on the field, collisions are inherently avoided as
contours never go through peaks or intersect. Additionally, counters are smooth
and energy-efficient. Our framework enables training with large swarm sizes as
the agent interaction is minimized and the need for complex credit assignment
schemes or observation sharing mechanisms in state-of-the-art MARL approaches
are eliminated. Moreover, UAVs obtain the ability to adapt to complex
environments where contours may be non-viable or non-existent through intensive
training. Extensive experiments are conducted to evaluate the performances of
our framework against state-of-the-art MARL algorithms.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [235] [Learning to Move in Rhythm: Task-Conditioned Motion Policies with Orbital Stability Guarantees](https://arxiv.org/abs/2507.10602)
*Maximilian Stölzle,T. Konstantin Rusch,Zach J. Patterson,Rodrigo Pérez-Dattari,Francesco Stella,Josie Hughes,Cosimo Della Santina,Daniela Rus*

Main category: cs.RO

TL;DR: OSMPs框架通过结合学习到的微分同胚编码器和超临界Hopf分岔，成功克服了DMPs在捕捉周期性运动和任务插值方面的局限性，并在机器人应用中展现出优越的性能和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 动态运动原语（DMPs）虽然具有内置的稳定性和鲁棒性，但在捕捉复杂的周期性运动和任务间的插值方面存在局限性，这限制了其在行走和节奏性工具使用等任务中的应用。OSMPs旨在克服这些限制。

Method: 提出了一种名为轨道稳定运动原语（OSMPs）的框架，该框架结合了学习到的微分同胚编码器和潜在空间中的超临界Hopf分岔。

Result: OSMPs框架在各种机器人平台（包括协作臂、软操纵器和受生物启发的硬软海龟机器人）的仿真和真实世界实验中得到了验证，并且在零次射击泛化到未见运动目标方面表现优于包括扩散策略在内的最先进基线。

Conclusion: 该框架通过结合学习到的微分同胚编码器和潜在空间中的超临界Hopf分岔，能够从演示中准确学习周期性运动，并确保轨道稳定性和横向收缩的正式保证。通过将双射编码器条件化于任务，可以使单个学习策略代表多个运动目标，从而在训练分布内实现对未见运动目标的零次射击泛化。

Abstract: Learning from demonstration provides a sample-efficient approach to acquiring
complex behaviors, enabling robots to move robustly, compliantly, and with
fluidity. In this context, Dynamic Motion Primitives offer built - in stability
and robustness to disturbances but often struggle to capture complex periodic
behaviors. Moreover, they are limited in their ability to interpolate between
different tasks. These shortcomings substantially narrow their applicability,
excluding a wide class of practically meaningful tasks such as locomotion and
rhythmic tool use. In this work, we introduce Orbitally Stable Motion
Primitives (OSMPs) - a framework that combines a learned diffeomorphic encoder
with a supercritical Hopf bifurcation in latent space, enabling the accurate
acquisition of periodic motions from demonstrations while ensuring formal
guarantees of orbital stability and transverse contraction. Furthermore, by
conditioning the bijective encoder on the task, we enable a single learned
policy to represent multiple motion objectives, yielding consistent zero-shot
generalization to unseen motion objectives within the training distribution. We
validate the proposed approach through extensive simulation and real-world
experiments across a diverse range of robotic platforms - from collaborative
arms and soft manipulators to a bio-inspired rigid-soft turtle robot -
demonstrating its versatility and effectiveness in consistently outperforming
state-of-the-art baselines such as diffusion policies, among others.

</details>


### [236] [Vision Language Action Models in Robotic Manipulation: A Systematic Review](https://arxiv.org/abs/2507.10672)
*Muhayy Ud Din,Waseem Akram,Lyes Saad Saoud,Jan Rosell,Irfan Hussain*

Main category: cs.RO

TL;DR: 本综述全面分析了机器人领域的视觉语言动作（VLA）模型，重点关注机器人操纵和指令驱动的自主性。我们评估了模型、数据集和模拟平台，并提出了改进未来研究和发展的战略方向。


<details>
  <summary>Details</summary>
Motivation: 旨在统一视觉感知、自然语言理解和具身控制在一个学习框架内，重点关注机器人操纵和指令驱动的自主性，为具身智能和机器人控制的研究提供一个全面的技术参考和概念路线图。

Method: 通过对102个VLA模型、26个数据集和12个模拟平台的全面分析，评估VLA模型在机器人操纵和指令驱动自主性方面的现状。采用基于任务复杂度、模态多样性和数据集规模的新标准来评估数据集，并引入一个二维框架来表征数据集的语义丰富度和多模态对齐度。评估模拟环境生成大规模数据以及模拟到现实世界迁移的能力。

Result: 对现有VLA模型、数据集和模拟平台进行了分类和评估，指出了当前数据格局中未被充分探索的领域，并识别了可扩展的预训练协议、模块化架构设计和强大的多模态对齐策略等关键挑战和战略方向。

Conclusion: 该综述全面评估了102个视觉语言动作（VLA）模型、26个基础数据集和12个模拟平台，对机器人操纵和指令驱动的自主性进行了重点分析，并提出了可扩展的预训练协议、模块化架构设计和强大的多模态对齐策略等战略方向，旨在推动具身智能和机器人控制的发展。

Abstract: Vision Language Action (VLA) models represent a transformative shift in
robotics, with the aim of unifying visual perception, natural language
understanding, and embodied control within a single learning framework. This
review presents a comprehensive and forward-looking synthesis of the VLA
paradigm, with a particular emphasis on robotic manipulation and
instruction-driven autonomy. We comprehensively analyze 102 VLA models, 26
foundational datasets, and 12 simulation platforms that collectively shape the
development and evaluation of VLAs models. These models are categorized into
key architectural paradigms, each reflecting distinct strategies for
integrating vision, language, and control in robotic systems. Foundational
datasets are evaluated using a novel criterion based on task complexity,
variety of modalities, and dataset scale, allowing a comparative analysis of
their suitability for generalist policy learning. We introduce a
two-dimensional characterization framework that organizes these datasets based
on semantic richness and multimodal alignment, showing underexplored regions in
the current data landscape. Simulation environments are evaluated for their
effectiveness in generating large-scale data, as well as their ability to
facilitate transfer from simulation to real-world settings and the variety of
supported tasks. Using both academic and industrial contributions, we recognize
ongoing challenges and outline strategic directions such as scalable
pretraining protocols, modular architectural design, and robust multimodal
alignment strategies. This review serves as both a technical reference and a
conceptual roadmap for advancing embodiment and robotic control, providing
insights that span from dataset generation to real world deployment of
generalist robotic agents.

</details>


### [237] [Closed Form Time Derivatives of the Equations of Motion of Rigid Body Systems](https://arxiv.org/abs/2507.11076)
*Andreas Mueller,Shivesh Kumar*

Main category: cs.RO

TL;DR: A new closed-form method using Lie group formulation to calculate time derivatives of rigid body dynamics equations for robotics control.


<details>
  <summary>Details</summary>
Motivation: Derivatives of equations of motion are increasingly relevant for robotics, especially for controlling systems with elastic components, which require not only smooth trajectories but also time derivatives of control forces/torques.

Method: The Lie group formulation for rigid body systems is used to derive compact and easily parameterized equations.

Result: The paper provides a closed-form formulation for the time derivatives of the EOM up to second-order.

Conclusion: This paper presents a closed-form formulation for the time derivatives of the equations of motion (EOM) for rigid body systems up to second-order, offering a direct insight into their structure as an alternative to recursive algorithms.

Abstract: Derivatives of equations of motion(EOM) describing the dynamics of rigid body
systems are becoming increasingly relevant for the robotics community and find
many applications in design and control of robotic systems. Controlling robots,
and multibody systems comprising elastic components in particular, not only
requires smooth trajectories but also the time derivatives of the control
forces/torques, hence of the EOM. This paper presents the time derivatives of
the EOM in closed form up to second-order as an alternative formulation to the
existing recursive algorithms for this purpose, which provides a direct insight
into the structure of the derivatives. The Lie group formulation for rigid body
systems is used giving rise to very compact and easily parameterized equations.

</details>


### [238] [Exteroception through Proprioception Sensing through Improved Contact Modeling for Soft Growing Robots](https://arxiv.org/abs/2507.10694)
*Francesco Fuentes,Serigne Diagne,Zachary Kingston,Laura H. Blumenschein*

Main category: cs.RO

TL;DR: 软体生长机器人可通过模型和模拟器用于非结构化环境的探索和测绘。


<details>
  <summary>Details</summary>
Motivation: 软体机器人因其被动的形变能力，在鲁棒驱动和非结构化环境中导航方面具有优势。本研究旨在利用软体生长机器人的被动形变特性，通过理解其碰撞和形变行为，将其作为环境测绘和探索的工具。

Method: 本研究通过表征碰撞行为和开发基于几何的模拟器来模拟机器人轨迹，并利用蒙特卡洛采样来估计最佳的机器人部署。

Result: 研究成功开发了一个能够模拟机器人轨迹的模拟器，并通过在未知环境中进行测绘，证明了该模型和模拟器的有效性。

Conclusion: 本研究表明，软体生长机器人能够有效地用于探索和测绘未知环境，并且在均匀和非均匀环境中，其动作选择方法能快速接近理想状态。

Abstract: Passive deformation due to compliance is a commonly used benefit of soft
robots, providing opportunities to achieve robust actuation with few active
degrees of freedom. Soft growing robots in particular have shown promise in
navigation of unstructured environments due to their passive deformation. If
their collisions and subsequent deformations can be better understood, soft
robots could be used to understand the structure of the environment from direct
tactile measurements. In this work, we propose the use of soft growing robots
as mapping and exploration tools. We do this by first characterizing collision
behavior during discrete turns, then leveraging this model to develop a
geometry-based simulator that models robot trajectories in 2D environments.
Finally, we demonstrate the model and simulator validity by mapping unknown
environments using Monte Carlo sampling to estimate the optimal next deployment
given current knowledge. Over both uniform and non-uniform environments, this
selection method rapidly approaches ideal actions, showing the potential for
soft growing robots in unstructured environment exploration and mapping.

</details>


### [239] [RCG: Safety-Critical Scenario Generation for Robust Autonomous Driving via Real-World Crash Grounding](https://arxiv.org/abs/2507.10749)
*Benjamin Stoler,Juliet Yang,Jonathan Francis,Jean Oh*

Main category: cs.RO

TL;DR: 本研究提出了RCG框架，通过集成碰撞信息语义和安全感知的行为表示，生成真实的安全关键自动驾驶场景，显著提升了系统性能。


<details>
  <summary>Details</summary>
Motivation: 真实世界的安全关键场景对于训练和评估自动驾驶系统至关重要，但在实际驾驶数据集中却极为罕见。

Method: 提出了一种名为Real-world Crash Grounding (RCG)的场景生成框架，该框架将碰撞信息语义集成到对抗性扰动流程中。通过在大量驾驶日志上进行对比预训练，然后在包含碰撞的、带有近似轨迹注释的小型数据集上进行微调，构建了安全感知的行为表示。该嵌入能够捕获与真实世界事故行为一致的语义结构，并支持选择高风险且行为上真实可信的对手轨迹。将此选择机制集成到现有的场景生成流程中，用基于嵌入的标准替代了手工设计的评分目标。

Result: 实验结果表明，使用该框架生成的场景进行训练的自动驾驶系统，在七种评估设置下平均成功率提高了9.2%。此外，该方法能够生成更合理、更细致的对手行为，使得对自动驾驶系统的压力测试更加有效和真实。

Conclusion: 该方法生成的安全关键场景能够显著提高自动驾驶系统的下游成功率，平均提高了9.2%，并且能够生成更具可信度和细微差别的对手行为，从而实现更有效和现实的压力测试。

Abstract: Safety-critical scenarios are essential for training and evaluating
autonomous driving (AD) systems, yet remain extremely rare in real-world
driving datasets. To address this, we propose Real-world Crash Grounding (RCG),
a scenario generation framework that integrates crash-informed semantics into
adversarial perturbation pipelines. We construct a safety-aware behavior
representation through contrastive pre-training on large-scale driving logs,
followed by fine-tuning on a small, crash-rich dataset with approximate
trajectory annotations extracted from video. This embedding captures semantic
structure aligned with real-world accident behaviors and supports selection of
adversary trajectories that are both high-risk and behaviorally realistic. We
incorporate the resulting selection mechanism into two prior scenario
generation pipelines, replacing their handcrafted scoring objectives with an
embedding-based criterion. Experimental results show that ego agents trained
against these generated scenarios achieve consistently higher downstream
success rates, with an average improvement of 9.2% across seven evaluation
settings. Qualitative and quantitative analyses further demonstrate that our
approach produces more plausible and nuanced adversary behaviors, enabling more
effective and realistic stress testing of AD systems. Code and tools will be
released publicly.

</details>


### [240] [rt-RISeg: Real-Time Model-Free Robot Interactive Segmentation for Active Instance-Level Object Understanding](https://arxiv.org/abs/2507.10776)
*Howard H. Qian,Yiting Chen,Gaotian Wang,Podshara Chanrungmaneekul,Kaiyu Hang*

Main category: cs.RO

TL;DR: 本研究提出了rt-RISeg框架，通过机器人交互和身体固定不变特征（BFIF）来分割未见对象，提高了27.5%的准确率，并且可以与视觉基础模型结合使用。


<details>
  <summary>Details</summary>
Motivation: 以往的未见对象实例分割（UOIS）方法在大型数据集上训练模型，容易导致在静态视觉特征上过拟合，在面对分布外场景时泛化性能差。为了解决这个问题，我们基于视觉本质上是交互的并且随着时间发生的原理重新思考了UOIS任务。

Method: 提出了一种新颖的实时交互感知框架rt-RISeg，该框架通过机器人交互和分析设计的身体固定不变特征（BFIF）来持续分割未见过的对象，利用随机采样身体框架的相对旋转和线性速度来识别对象，无需任何学习到的分割模型。

Result: 所提出的rt-RISeg方法实现了平均27.5%的准确率提升，并且其生成的分割掩码可作为提示用于视觉基础模型，显著提升了性能。此外，rt-RISeg是一个独立的框架，但也能够与更广泛的模型结合。

Conclusion: 通过使用机器人交互和设计的身体固定不变特征（BFIF）的分析，rt-RISeg框架在每次机器人交互中生成和更新对象分割掩码，而无需等待动作完成，实现了完全自包含的分割流程，平均对象分割准确率比最先进的UOIS方法提高了27.5%。

Abstract: Successful execution of dexterous robotic manipulation tasks in new
environments, such as grasping, depends on the ability to proficiently segment
unseen objects from the background and other objects. Previous works in unseen
object instance segmentation (UOIS) train models on large-scale datasets, which
often leads to overfitting on static visual features. This dependency results
in poor generalization performance when confronted with out-of-distribution
scenarios. To address this limitation, we rethink the task of UOIS based on the
principle that vision is inherently interactive and occurs over time. We
propose a novel real-time interactive perception framework, rt-RISeg, that
continuously segments unseen objects by robot interactions and analysis of a
designed body frame-invariant feature (BFIF). We demonstrate that the relative
rotational and linear velocities of randomly sampled body frames, resulting
from selected robot interactions, can be used to identify objects without any
learned segmentation model. This fully self-contained segmentation pipeline
generates and updates object segmentation masks throughout each robot
interaction without the need to wait for an action to finish. We showcase the
effectiveness of our proposed interactive perception method by achieving an
average object segmentation accuracy rate 27.5% greater than state-of-the-art
UOIS methods. Furthermore, although rt-RISeg is a standalone framework, we show
that the autonomously generated segmentation masks can be used as prompts to
vision foundation models for significantly improved performance.

</details>


### [241] [LF: Online Multi-Robot Path Planning Meets Optimal Trajectory Control](https://arxiv.org/abs/2507.11464)
*Ajay Shankar,Keisuke Okumura,Amanda Prorok*

Main category: cs.RO

TL;DR: A new multi-robot navigation system uses a two-part approach: a fast central planner for paths and independent controllers for movement, allowing many robots to navigate complex spaces reliably.


<details>
  <summary>Details</summary>
Motivation: To develop a multi-robot control paradigm for point-to-point navigation tasks for holonomic robots, ensuring scalability and reliability even with dynamic environments and goal updates.

Method: A hierarchical approach is used, with a centralized discrete planner for collision-free paths and decentralized trajectory controllers for reliable execution. This shifts from coupled discrete planning to decoupled continuous control.

Result: Demonstrations with up to 15 real multirotors and ground robots showed robust and versatile lifelong navigation, handling random and consecutive target updates while a person moved through the workspace.

Conclusion: The proposed hierarchical framework enables scalable and reliable lifelong multi-robot navigation, adapting to dynamic environments and asynchronous goal updates.

Abstract: We propose a multi-robot control paradigm to solve point-to-point navigation
tasks for a team of holonomic robots with access to the full environment
information. The framework invokes two processes asynchronously at high
frequency: (i) a centralized, discrete, and full-horizon planner for computing
collision- and deadlock-free paths rapidly, leveraging recent advances in
multi-agent pathfinding (MAPF), and (ii) dynamics-aware, robot-wise optimal
trajectory controllers that ensure all robots independently follow their
assigned paths reliably. This hierarchical shift in planning representation
from (i) discrete and coupled to (ii) continuous and decoupled domains enables
the framework to maintain long-term scalable motion synthesis. As an
instantiation of this idea, we present LF, which combines a fast
state-of-the-art MAPF solver (LaCAM), and a robust feedback control stack
(Freyja) for executing agile robot maneuvers. LF provides a robust and
versatile mechanism for lifelong multi-robot navigation even under asynchronous
and partial goal updates, and adapts to dynamic workspaces simply by quick
replanning. We present various multirotor and ground robot demonstrations,
including the deployment of 15 real multirotors with random, consecutive target
updates while a person walks through the operational workspace.

</details>


### [242] [Versatile and Generalizable Manipulation via Goal-Conditioned Reinforcement Learning with Grounded Object Detection](https://arxiv.org/abs/2507.10814)
*Huiyi Wang,Fahim Shahriar,Alireza Azimi,Gautham Vasan,Rupam Mahmood,Colin Bellinger*

Main category: cs.RO

TL;DR: 该研究提出了一种将预训练的物体检测模型集成到目标条件强化学习中的方法，以实现更通用、更高效的机器人抓取。


<details>
  <summary>Details</summary>
Motivation: 通用机器人操作对于在涉及多样化和不断变化的家庭和工作场所中的部署至关重要，而利用大型预训练模型（如大型语言模型和物体检测器）可以提高强化学习中的机器人感知能力。

Method: 将预训练的物体检测模型用于目标条件强化学习，并使用基于掩码的目标条件化提供对象不可知线索，以改进特征共享和泛化。

Result: 在模拟的抓取任务中，基于掩码的目标条件化在抓取分布内和分布外的物体时均保持约 90% 的成功率，并确保了更快的收敛到更高的回报。

Conclusion: 该研究成功地将预训练的物体检测模型集成到目标条件强化学习中，实现了通用且多功能的机器人抓取能力。

Abstract: General-purpose robotic manipulation, including reach and grasp, is essential
for deployment into households and workspaces involving diverse and evolving
tasks. Recent advances propose using large pre-trained models, such as Large
Language Models and object detectors, to boost robotic perception in
reinforcement learning. These models, trained on large datasets via
self-supervised learning, can process text prompts and identify diverse objects
in scenes, an invaluable skill in RL where learning object interaction is
resource-intensive. This study demonstrates how to integrate such models into
Goal-Conditioned Reinforcement Learning to enable general and versatile robotic
reach and grasp capabilities. We use a pre-trained object detection model to
enable the agent to identify the object from a text prompt and generate a mask
for goal conditioning. Mask-based goal conditioning provides object-agnostic
cues, improving feature sharing and generalization. The effectiveness of the
proposed framework is demonstrated in a simulated reach-and-grasp task, where
the mask-based goal conditioning consistently maintains a $\sim$90\% success
rate in grasping both in and out-of-distribution objects, while also ensuring
faster convergence to higher returns.

</details>


### [243] [Mixed Discrete and Continuous Planning using Shortest Walks in Graphs of Convex Sets](https://arxiv.org/abs/2507.10878)
*Savva Morozov,Tobia Marcucci,Bernhard Paus Graesdal,Alexandre Amice,Pablo A. Parrilo,Russ Tedrake*

Main category: cs.RO

TL;DR: SWP在GCS中的研究，使用SDP和增量搜索找到近似最短路径，并成功应用于机器人规划问题。


<details>
  <summary>Details</summary>
Motivation: 研究图论中的最短路径问题（SWP），特别是在凸集图（GCS）的背景下。GCS图的每个顶点代表一个凸程序，边代表程序间的耦合约束和成本。

Method: 提出了一种利用半definiteness programming（SDP）合成分段二次函数作为成本到期函数下界的方法，并使用该下界引导增量搜索算法来找到近似最短路径。

Result: 所提出的方法在碰撞检测运动规划、技能链接和混合系统最优控制等实验中表现出了高性能和计算效率，验证了其在解决混合离散-连续规划问题方面的有效性。

Conclusion: SWP在GCS中是机器人领域许多混合离散-连续规划问题的自然语言，能够统一通常需要专门解决方案的问题，同时提供高性能和计算效率。

Abstract: We study the Shortest-Walk Problem (SWP) in a Graph of Convex Sets (GCS). A
GCS is a graph where each vertex is paired with a convex program, and each edge
couples adjacent programs via additional costs and constraints. A walk in a GCS
is a sequence of vertices connected by edges, where vertices may be repeated.
The length of a walk is given by the cumulative optimal value of the
corresponding convex programs. To solve the SWP in GCS, we first synthesize a
piecewise-quadratic lower bound on the problem's cost-to-go function using
semidefinite programming. Then we use this lower bound to guide an
incremental-search algorithm that yields an approximate shortest walk. We show
that the SWP in GCS is a natural language for many mixed discrete-continuous
planning problems in robotics, unifying problems that typically require
specialized solutions while delivering high performance and computational
efficiency. We demonstrate this through experiments in collision-free motion
planning, skill chaining, and optimal control of hybrid systems.

</details>


### [244] [Object-Centric Mobile Manipulation through SAM2-Guided Perception and Imitation Learning](https://arxiv.org/abs/2507.10899)
*Wang Zhicheng,Satoshi Yagi,Satoshi Yamamori,Jun Morimoto*

Main category: cs.RO

TL;DR: 模仿学习在移动操作中的一个关键挑战是导航和操作的解耦，这在导航不精确时会导致性能下降。本研究提出了一种对象中心方法，利用SAM2整合操作方向信息，实现了从不同视角对同一任务的一致性理解。实验证明，该方法比Action Chunking Transformer具有更强的泛化能力，显著提高了移动操作系统的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 当前的移动操作框架将导航和操作解耦，仅在到达特定位置后执行操作，这在导航不精确（尤其是在接近角度不对齐时）会导致性能下降。为了让移动机械臂能够从不同方向执行相同的任务，我们提出了一种新的方法。

Method: 提出了一种基于SAM2的对象中心方法，将操作方向信息整合到模型中，以实现从不同方向对同一任务的一致性理解。

Result: 所提出的方法在拾取和放置任务中，与Action Chunking Transformer相比，在多样化的接近角度训练下表现出更优越的泛化能力，显著提升了模仿学习在移动操作系统中的泛化性和鲁棒性。

Conclusion: 该研究通过引入基于SAM2的对象中心方法，将操作方向信息整合到模型中，显著提高了模仿学习在移动操作中的泛化性和鲁棒性，解决了现有框架中导航与操作解耦导致的性能下降问题。

Abstract: Imitation learning for mobile manipulation is a key challenge in the field of
robotic manipulation. However, current mobile manipulation frameworks typically
decouple navigation and manipulation, executing manipulation only after
reaching a certain location. This can lead to performance degradation when
navigation is imprecise, especially due to misalignment in approach angles. To
enable a mobile manipulator to perform the same task from diverse orientations,
an essential capability for building general-purpose robotic models, we propose
an object-centric method based on SAM2, a foundation model towards solving
promptable visual segmentation in images, which incorporates manipulation
orientation information into our model. Our approach enables consistent
understanding of the same task from different orientations. We deploy the model
on a custom-built mobile manipulator and evaluate it on a pick-and-place task
under varied orientation angles. Compared to Action Chunking Transformer, our
model maintains superior generalization when trained with demonstrations from
varied approach angles. This work significantly enhances the generalization and
robustness of imitation learning-based mobile manipulation systems.

</details>


### [245] [Fast Non-Episodic Adaptive Tuning of Robot Controllers with Online Policy Optimization](https://arxiv.org/abs/2507.10914)
*James A. Preiss,Fengze Xie,Yiheng Lin,Adam Wierman,Yisong Yue*

Main category: cs.RO

TL;DR: M-GAPS 是一种新的在线策略优化算法，适用于动态变化的机器人控制器参数调整，在实际应用中表现优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 研究在动力学、策略类别和最优目标都随时间变化的情况下，机器人控制器参数的在线算法。

Method: 提出了一种基于模型的单轨迹在线策略优化算法 M-GAPS，并对四旋翼飞行器状态空间和策略类别进行了重新参数化，以改进优化景观。

Result: M-GAPS 比固定试验段长度的基线算法更快地找到近似最优参数，并能快速适应未建模的风和负载扰动。在 1:6 比例的 Ackermann 转向小车上也取得了类似的大幅改进。

Conclusion: M-GAPS 算法在硬件实验中表现出色，能够快速找到近似最优参数，尤其是在不利的试验段长度下，并能快速适应风和负载扰动，在 1:6 比例的 Ackermann 转向小车上也取得了显著改进。结果表明，该算法代表了一类新兴的在线策略优化方法，比传统自适应控制更灵活，比无模型强化学习更稳定、数据更高效。

Abstract: We study online algorithms to tune the parameters of a robot controller in a
setting where the dynamics, policy class, and optimality objective are all
time-varying. The system follows a single trajectory without episodes or state
resets, and the time-varying information is not known in advance. Focusing on
nonlinear geometric quadrotor controllers as a test case, we propose a
practical implementation of a single-trajectory model-based online policy
optimization algorithm, M-GAPS,along with reparameterizations of the quadrotor
state space and policy class to improve the optimization landscape. In hardware
experiments,we compare to model-based and model-free baselines that impose
artificial episodes. We show that M-GAPS finds near-optimal parameters more
quickly, especially when the episode length is not favorable. We also show that
M-GAPS rapidly adapts to heavy unmodeled wind and payload disturbances, and
achieves similar strong improvement on a 1:6-scale Ackermann-steered car. Our
results demonstrate the hardware practicality of this emerging class of online
policy optimization that offers significantly more flexibility than classic
adaptive control, while being more stable and data-efficient than model-free
reinforcement learning.

</details>


### [246] [Unified Modeling and Structural Optimization of Multi-magnet Embedded Soft Continuum Robots for Enhanced Kinematic Performances](https://arxiv.org/abs/2507.10950)
*Zhiwei Wu,Jiahao Luo,Siyi Wei,Jinhui Zhang*

Main category: cs.RO

TL;DR: 该研究提出了一个用于提高软连续机器人运动学性能的建模与优化框架，并提供了最优设计方法。


<details>
  <summary>Details</summary>
Motivation: 为了提高多磁嵌入软连续机器人的运动学性能，研究者们需要一个统一的建模和优化框架。

Method: 提出了一种基于扩展伪刚体模型的微分系统公式，并结合了基于微分几何的结构优化框架。

Result: 证明了MeSCRs的最大可控自由度等于嵌入磁体数量的两倍，并通过优化框架提高了局部性能，为设计提供了最优磁体配置的解决方案。

Conclusion: 该研究提出了一个统一的建模和优化框架，用于提高多磁嵌入软连续机器人的运动学性能，并推导出了最优磁体配置的解析和数值解。

Abstract: This paper presents a unified modeling and optimization framework to enhance
the kinematic performance of multi-magnet embedded soft continuum robots
(MeSCRs). To this end, we establish a differentiable system formulation based
on an extended pseudo-rigid-body model. This formulation enables analysis of
the equilibrium well-posedness and the geometry of the induced configuration
under magnetic actuation. In particular, we show that the maximum controllable
degrees of freedom of a MeSCR equal twice the number of embedded magnets. We
subsequently develop a structural optimization framework based on differential
geometry that links classical kinematic measures (e.g., manipulability and
dexterity) to the configuration of embedded magnets. The resulting optimization
condition reveals that improving local performance requires structurally
modulating the spectrum of the configuration space metric to counteract its
distortion. Closed-form solutions for optimal magnet configurations are derived
under representative conditions, and a gradient-based numerical method is
proposed for general design scenarios. Simulation studies validate the
effectiveness of the proposed framework.

</details>


### [247] [Whom to Respond To? A Transformer-Based Model for Multi-Party Social Robot Interaction](https://arxiv.org/abs/2507.10960)
*He Zhu,Ryo Miyoshi,Yuki Okafuji*

Main category: cs.RO

TL;DR: 研究提出了一种基于Transformer的多任务学习框架，通过新颖的损失函数和数据集，提升了社交机器人在多人场景下的响应决策能力和社交智能。


<details>
  <summary>Details</summary>
Motivation: 现有机器人交互研究主要集中在单用户交互，忽略了在多方交互（如商场、医院）中机器人需要理解上下文并决定何时以及对谁做出响应的挑战。

Method: 提出了一种基于Transformer的多任务学习框架，并引入了两个新颖的损失函数：一个用于约束活动发言者以改进场景建模，另一个用于引导响应选择至机器人接收到的语音。

Result: 实验结果表明，所提出的模型在响应决策方面达到了最先进的性能，优于现有的基于启发式和单任务的方法。特别是在处理如注视未对准等现实复杂性方面表现出色。

Conclusion: 该研究通过提出的Transformer模型和新颖的损失函数，在多方交互环境中显著提升了社交机器人的响应决策能力，实现了超越现有方法的性能，为开发更具社交智能的机器人奠定了基础。

Abstract: Prior human-robot interaction (HRI) research has primarily focused on
single-user interactions, where robots do not need to consider the timing or
recipient of their responses. However, in multi-party interactions, such as at
malls and hospitals, social robots must understand the context and decide both
when and to whom they should respond. In this paper, we propose a
Transformer-based multi-task learning framework to improve the decision-making
process of social robots, particularly in multi-user environments. Considering
the characteristics of HRI, we propose two novel loss functions: one that
enforces constraints on active speakers to improve scene modeling, and another
that guides response selection towards utterances specifically directed at the
robot. Additionally, we construct a novel multi-party HRI dataset that captures
real-world complexities, such as gaze misalignment. Experimental results
demonstrate that our model achieves state-of-the-art performance in respond
decisions, outperforming existing heuristic-based and single-task approaches.
Our findings contribute to the development of socially intelligent social
robots capable of engaging in natural and context-aware multi-party
interactions.

</details>


### [248] [EquiContact: A Hierarchical SE(3) Vision-to-Force Equivariant Policy for Spatially Generalizable Contact-rich Tasks](https://arxiv.org/abs/2507.10961)
*Joohwan Seo,Arvind Kruthiventy,Soomi Lee,Megan Teng,Xiang Zhang,Seoyeon Choi,Jongeun Choi,Roberto Horowitz*

Main category: cs.RO

TL;DR: EquiContact框架通过结合SE(3)等变的视觉规划和低层几何鲁棒性控制，实现了机器人接触操作任务（如钉子插入孔）的空间泛化和高成功率。


<details>
  <summary>Details</summary>
Motivation: 旨在实现视觉引导的、接触丰富的操作任务中策略的空间泛化能力，特别是在钉子插入孔（PiH）任务中，并从少量演示中进行训练。

Method: 提出了一种名为EquiContact的层次化策略框架，该框架由高层的扩散等变描述符场（Diff-EDF）和低层的几何鲁棒性AC T（G-CompACT）组成。G-CompACT仅使用局部观测（几何一致误差向量、力矩读数和腕部RGB图像）并输出末端执行器坐标系中的动作。EquiContact的整个流程都具有SE(3)等变性。

Result: 在现实世界的PiH任务实验中，EquiContact框架实现了接近完美的成功率，并能鲁棒地泛化到未见的空间配置，验证了所提出的框架和原理。

Conclusion: 该研究提出了EquiContact框架，通过结合高层扩散等变描述符场（Diff-EDF）和低层几何鲁棒性AC T（G-CompACT）的层次化策略，成功实现了视觉引导的、接触丰富的操作任务的鲁棒空间泛化。实验证明，该框架在钉子插入孔（PiH）任务中取得了接近完美的成功率，并能泛化到未见的空间配置。

Abstract: This paper presents a framework for learning vision-based robotic policies
for contact-rich manipulation tasks that generalize spatially across task
configurations. We focus on achieving robust spatial generalization of the
policy for the peg-in-hole (PiH) task trained from a small number of
demonstrations. We propose EquiContact, a hierarchical policy composed of a
high-level vision planner (Diffusion Equivariant Descriptor Field, Diff-EDF)
and a novel low-level compliant visuomotor policy (Geometric Compliant ACT,
G-CompACT). G-CompACT operates using only localized observations (geometrically
consistent error vectors (GCEV), force-torque readings, and wrist-mounted RGB
images) and produces actions defined in the end-effector frame. Through these
design choices, we show that the entire EquiContact pipeline is
SE(3)-equivariant, from perception to force control. We also outline three key
components for spatially generalizable contact-rich policies: compliance,
localized policies, and induced equivariance. Real-world experiments on PiH
tasks demonstrate a near-perfect success rate and robust generalization to
unseen spatial configurations, validating the proposed framework and
principles. The experimental videos can be found on the project website:
https://sites.google.com/berkeley.edu/equicontact

</details>


### [249] [SMART-Merge Planner: A Safe Merging and Real-Time Motion Planner for Autonomous Highway On-Ramp Merging](https://arxiv.org/abs/2507.10968)
*Toktam Mohammadnejad,Jovin D'sa,Behdad Chalaki,Hossein Nourkhiz Mahjoub,Ehsan Moradi-Pari*

Main category: cs.RO

TL;DR: SMART-Merge：一种用于安全舒适高速公路强制合流的运动规划器，模拟结果显示成功率 100%，合并时间短。


<details>
  <summary>Details</summary>
Motivation: 解决高速公路合流（尤其是强制合流）的复杂性，该任务要求在有限的时间内安全舒适地完成变道。

Method: 提出了一种基于格点（lattice-based）的运动规划器 SMART-Merge，通过调整成本项和引入期望速度启发式方法来优化强制合流过程。

Result: 在 CarMaker 高保真模拟中，SMART-Merge 规划器在数百个高速公路合流场景下实现了 100% 的成功率，并显著缩短了合并时间，优于其他基线方法。

Conclusion: SMART-Merge 规划器在复杂强制合流任务中表现出 100% 的成功率，并且合并时间最短，证明了其可靠性和鲁棒性。

Abstract: Merging onto a highway is a complex driving task that requires identifying a
safe gap, adjusting speed, often interactions to create a merging gap, and
completing the merge maneuver within a limited time window while maintaining
safety and driving comfort. In this paper, we introduce a Safe Merging and
Real-Time Merge (SMART-Merge) planner, a lattice-based motion planner designed
to facilitate safe and comfortable forced merging. By deliberately adapting
cost terms to the unique challenges of forced merging and introducing a desired
speed heuristic, SMART-Merge planner enables the ego vehicle to merge
successfully while minimizing the merge time. We verify the efficiency and
effectiveness of the proposed merge planner through high-fidelity CarMaker
simulations on hundreds of highway merge scenarios. Our proposed planner
achieves the success rate of 100% as well as completes the merge maneuver in
the shortest amount of time compared with the baselines, demonstrating our
planner's capability to handle complex forced merge tasks and provide a
reliable and robust solution for autonomous highway merge. The simulation
result videos are available at
https://sites.google.com/view/smart-merge-planner/home.

</details>


### [250] [MPC-based Coarse-to-Fine Motion Planning for Robotic Object Transportation in Cluttered Environments](https://arxiv.org/abs/2507.11211)
*Chen Cai,Ernesto Dickel Saraiva,Ya-jun Pan,Steven Liu*

Main category: cs.RO

TL;DR: 提出了一种新的机器人操作运动规划框架，该框架结合了双目视觉和MPC，能够实时处理混乱和不确定的环境。


<details>
  <summary>Details</summary>
Motivation: 提出了一种用于在混乱、未建模环境中进行机器人操作的新颖的粗到细运动规划框架。

Method: 该系统集成了双目视觉感知设置和基于B样条的}(
model)预测控制(MPC)方案。它利用基于视觉的成本函数来促进目标驱动的探索，并采用改进的核感知器碰撞检测器来实现高效的约束更新以进行实时规划。该框架能够处理闭链运动学并支持动态重规划。

Result: 该系统能够从部分和不确定的观测中生成可行的全局轨迹，并随着新的视觉数据的不断融合，逐步完善环境模型和运动规划。

Conclusion: 该框架在多臂平台上进行了验证，证明了其在不确定性和混乱环境下的鲁棒性和适应性。

Abstract: This letter presents a novel coarse-to-fine motion planning framework for
robotic manipulation in cluttered, unmodeled environments. The system
integrates a dual-camera perception setup with a B-spline-based model
predictive control (MPC) scheme. Initially, the planner generates feasible
global trajectories from partial and uncertain observations. As new visual data
are incrementally fused, both the environment model and motion planning are
progressively refined. A vision-based cost function promotes target-driven
exploration, while a refined kernel-perceptron collision detector enables
efficient constraint updates for real-time planning. The framework accommodates
closed-chain kinematics and supports dynamic replanning. Experiments on a
multi-arm platform validate its robustness and adaptability under uncertainties
and clutter.

</details>


### [251] [Uncertainty Aware Mapping for Vision-Based Underwater Robots](https://arxiv.org/abs/2507.10991)
*Abhimanyu Bhowmik,Mohit Singh,Madhushree Sannigrahi,Martin Ludvigsen,Kostas Alexis*

Main category: cs.RO

TL;DR: 提出一种融合深度估计置信度的水下机器人建图方法，改进了Voxblox算法，并在水下实验中验证了不确定性表示的有效性。


<details>
  <summary>Details</summary>
Motivation: 为了解决水下机器人在检查和探索受限空间时，由于传感器噪声和环境变化导致的环境表示不确定性问题。

Method: 提出了一种将视觉感知中的深度估计置信度融合到基于体素的地图构建框架（Voxblox）中的方法，并对Voxblox的权重计算和更新机制进行了改进。

Result: 在水池和峡湾的实验中，证明了该方法能够有效地表示地图构建中的不确定性，并通过水下机器人实验展示了不确定性的变化。

Conclusion: 该方法通过融合深度估计置信度到基于体素的地图构建框架中，并改进了现有的Voxblox权重计算和更新机制，实现了在存在传感器噪声和环境变化的水下机器人视觉感知和建图中的不确定性表示。

Abstract: Vision-based underwater robots can be useful in inspecting and exploring
confined spaces where traditional sensors and preplanned paths cannot be
followed. Sensor noise and situational change can cause significant uncertainty
in environmental representation. Thus, this paper explores how to represent
mapping inconsistency in vision-based sensing and incorporate depth estimation
confidence into the mapping framework. The scene depth and the confidence are
estimated using the RAFT-Stereo model and are integrated into a voxel-based
mapping framework, Voxblox. Improvements in the existing Voxblox weight
calculation and update mechanism are also proposed. Finally, a qualitative
analysis of the proposed method is performed in a confined pool and in a pier
in the Trondheim fjord. Experiments using an underwater robot demonstrated the
change in uncertainty in the visualization.

</details>


### [252] [Ocean Diviner: A Diffusion-Augmented Reinforcement Learning for AUV Robust Control in the Underwater Tasks](https://arxiv.org/abs/2507.11283)
*Weiyi Liu,Jingzehua Xu,Guanwen Xie,Yi Li*

Main category: cs.RO

TL;DR: A new diffusion-augmented RL method improves AUV control by generating feasible trajectories and using diffusion for efficient exploration and RL for action selection, showing better performance in tough underwater environments.


<details>
  <summary>Details</summary>
Motivation: This paper addresses key challenges in underwater trajectory planning and dynamic environment adaptation for autonomous underwater vehicle (AUV) control.

Method: This paper proposes a diffusion-augmented reinforcement learning (RL) approach integrating a diffusion-based trajectory generation framework with a novel diffusion U-Net architecture for high-dimensional state encoding, and a sample-efficient hybrid learning architecture that combines diffusion-guided exploration with RL policy optimization for robust AUV control.

Result: Extensive simulation experiments validate the method's superior robustness and flexibility, outperforming conventional control methods in challenging marine conditions.

Conclusion: The proposed diffusion-augmented reinforcement learning approach demonstrates superior robustness and flexibility for autonomous underwater vehicle (AUV) control, outperforming conventional methods in challenging marine conditions and offering enhanced adaptability and reliability for underwater tasks.

Abstract: This paper presents a diffusion-augmented reinforcement learning (RL)
approach for robust autonomous underwater vehicle (AUV) control, addressing key
challenges in underwater trajectory planning and dynamic environment
adaptation. The proposed method integrates three core innovations: (1) A
diffusion-based trajectory generation framework that produces physically
feasible multi-step trajectories, enhanced by a high-dimensional state encoding
mechanism combining current observations with historical states and actions
through a novel diffusion U-Net architecture, significantly improving
long-horizon planning. (2) A sample-efficient hybrid learning architecture that
synergizes diffusion-guided exploration with RL policy optimization, where the
diffusion model generates diverse candidate actions and the RL critic selects
optimal actions, achieving higher exploration efficiency and policy stability
in dynamic underwater environments. Extensive simulation experiments validating
the method's superior robustness and flexibility, outperforms conventional
control methods in challenging marine conditions, offering enhanced
adaptability and reliability for AUV operations in the underwater tasks.

</details>


### [253] [ILCL: Inverse Logic-Constraint Learning from Temporally Constrained Demonstrations](https://arxiv.org/abs/2507.11000)
*Minwoo Cho,Jaehwi Jang,Daehyung Park*

Main category: cs.RO

TL;DR: ILCL是一种新颖的时间约束学习方法，通过GA-TL-Mining和Logic-CRL之间的博弈来学习逻辑约束，在各种任务中都优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 解决从演示中学习时间约束以复现类似演示的逻辑约束行为的问题，因为学习逻辑约束由于可能的规范的组合大空间和非马尔可夫约束的病态性质而具有挑战性。

Method: ILCL被构建为基于遗传算法的时间逻辑挖掘（GA-TL-Mining）和基于逻辑约束强化学习（Logic-CRL）之间的双人零和博弈。GA-TL-Mining用于构建参数化截断线性时序逻辑（TLTL）的语法树，而Logic-CRL则通过一种新颖的约束重分配方案，在TLTL约束下寻找最大化任务奖励的策略。

Result: ILCL在学习和转移TL约束方面优于最先进的基线，并在四项时间约束任务中取得了成功。

Conclusion: ILCL在学习和转移TL约束方面优于最先进的基线，并在四项时间约束任务和现实世界的插入浅孔任务中得到了成功转移。

Abstract: We aim to solve the problem of temporal-constraint learning from
demonstrations to reproduce demonstration-like logic-constrained behaviors.
Learning logic constraints is challenging due to the combinatorially large
space of possible specifications and the ill-posed nature of non-Markovian
constraints. To figure it out, we introduce a novel temporal-constraint
learning method, which we call inverse logic-constraint learning (ILCL). Our
method frames ICL as a two-player zero-sum game between 1) a genetic
algorithm-based temporal-logic mining (GA-TL-Mining) and 2) logic-constrained
reinforcement learning (Logic-CRL). GA-TL-Mining efficiently constructs syntax
trees for parameterized truncated linear temporal logic (TLTL) without
predefined templates. Subsequently, Logic-CRL finds a policy that maximizes
task rewards under the constructed TLTL constraints via a novel constraint
redistribution scheme. Our evaluations show ILCL outperforms state-of-the-art
baselines in learning and transferring TL constraints on four temporally
constrained tasks. We also demonstrate successful transfer to real-world
peg-in-shallow-hole tasks.

</details>


### [254] [Multi-IMU Sensor Fusion for Legged Robots](https://arxiv.org/abs/2507.11447)
*Shuo Yang,John Z. Zhang,Ibrahima Sory Sow,Zachary Manchester*

Main category: cs.RO

TL;DR: 一种用于有腿机器人的状态估计解决方案，利用低成本传感器和多IMU数据，通过视觉-惯性-腿部里程计实现低漂移姿态和速度估计。


<details>
  <summary>Details</summary>
Motivation: 为了在具有挑战性的运动条件下，利用一组低成本、紧凑、轻便的传感器，为有腿机器人实现低漂移的姿态和速度估计。

Method: 该方法融合了多组惯性测量单元（IMU）数据和关节编码器测量值，并利用扩展卡尔曼滤波器（EKF）进行状态估计。然后，将该滤波器的速度估计与相机数据融合，形成一个基于因子图的滑动窗口估计器，从而实现视觉-惯性-腿部里程计。

Result: 该方法通过全面的理论分析和使用真实机器人数据进行的硬件实验进行了验证，在多种具有挑战性的运动任务中，实现了最小的位置偏差。

Conclusion: 该算法在涉及大量地面撞击、脚部打滑和身体突然旋转的情况下，即使在具有挑战性的移动任务中，也能持续实现最小的位置偏差。

Abstract: This paper presents a state-estimation solution for legged robots that uses a
set of low-cost, compact, and lightweight sensors to achieve low-drift pose and
velocity estimation under challenging locomotion conditions. The key idea is to
leverage multiple inertial measurement units on different links of the robot to
correct a major error source in standard proprioceptive odometry. We fuse the
inertial sensor information and joint encoder measurements in an extended
Kalman filter, then combine the velocity estimate from this filter with camera
data in a factor-graph-based sliding-window estimator to form a
visual-inertial-leg odometry method. We validate our state estimator through
comprehensive theoretical analysis and hardware experiments performed using
real-world robot data collected during a variety of challenging locomotion
tasks. Our algorithm consistently achieves minimal position deviation, even in
scenarios involving substantial ground impact, foot slippage, and sudden body
rotations. A C++ implementation, along with a large-scale dataset, is available
at https://github.com/ShuoYangRobotics/Cerberus2.0.

</details>


### [255] [Learning to Tune Like an Expert: Interpretable and Scene-Aware Navigation via MLLM Reasoning and CVAE-Based Adaptation](https://arxiv.org/abs/2507.11001)
*Yanbo Wang,Zipeng Fang,Lei Zhao,Weidong Chen*

Main category: cs.RO

TL;DR: LE-Nav 使用多模态大语言模型和条件变分自编码器来动态调整导航超参数，以提高服务机器人在非结构化环境中的导航性能和用户接受度。


<details>
  <summary>Details</summary>
Motivation: 服务机器人在多样化和动态化的环境中部署日益广泛，这些环境中的物理布局和社会背景会随着时间推移和地点变化。在这些非结构化场景中，依赖固定参数的传统导航系统往往无法跨场景泛化，导致性能下降和社会接受度降低。尽管近期的方法利用强化学习来增强传统规划器，但这些方法由于泛化能力差和仿真环境多样性有限，在实际部署中常常失败，阻碍了有效的仿真到现实迁移。

Method: LE-Nav 是一个可解释的、场景感知的导航框架，它利用多模态大型语言模型推理和条件变分自编码器来适应性地调整规划器超参数。为了实现零次场景理解，我们使用了单次示例和思维链提示策略。此外，条件变分自编码器捕获了自然语言指令和导航超参数之间的映射关系，实现了专家级的调整。

Result: 实验表明，LE-Nav 能够生成超参数，在各种规划器和场景中实现人类水平的调整。在智能轮椅平台上的真实导航试验和用户研究表明，LE-Nav 在成功率、效率、安全性以及舒适度等量化指标上优于最先进的方法，并在感知的安全性和社会接受度方面获得更高的主观评分。

Conclusion: LE-Nav 在各种规划器和场景中实现了达到人类水平的超参数调整。在智能轮椅平台上的真实导航试验和用户研究表明，LE-Nav 在成功率、效率、安全性 serta 舒适度等量化指标上优于最先进的方法，并在感知的安全性和社会接受度方面获得更高的主观评分。

Abstract: Service robots are increasingly deployed in diverse and dynamic environments,
where both physical layouts and social contexts change over time and across
locations. In these unstructured settings, conventional navigation systems that
rely on fixed parameters often fail to generalize across scenarios, resulting
in degraded performance and reduced social acceptance. Although recent
approaches have leveraged reinforcement learning to enhance traditional
planners, these methods often fail in real-world deployments due to poor
generalization and limited simulation diversity, which hampers effective
sim-to-real transfer. To tackle these issues, we present LE-Nav, an
interpretable and scene-aware navigation framework that leverages multi-modal
large language model reasoning and conditional variational autoencoders to
adaptively tune planner hyperparameters. To achieve zero-shot scene
understanding, we utilize one-shot exemplars and chain-of-thought prompting
strategies. Additionally, a conditional variational autoencoder captures the
mapping between natural language instructions and navigation hyperparameters,
enabling expert-level tuning. Experiments show that LE-Nav can generate
hyperparameters achieving human-level tuning across diverse planners and
scenarios. Real-world navigation trials and a user study on a smart wheelchair
platform demonstrate that it outperforms state-of-the-art methods on
quantitative metrics such as success rate, efficiency, safety, and comfort,
while receiving higher subjective scores for perceived safety and social
acceptance. Code is available at https://github.com/Cavendish518/LE-Nav.

</details>


### [256] [Enhancing Autonomous Manipulator Control with Human-in-loop for Uncertain Assembly Environments](https://arxiv.org/abs/2507.11006)
*Ashutosh Mishra,Shreya Santra,Hazal Gozbasi,Kentaro Uno,Kazuya Yoshida*

Main category: cs.RO

TL;DR: 本研究提出了一种结合了“人在回路”（HITL）控制的先进方法，用于在月球任务等不确定环境中增强机器人的自主操作和操纵能力，通过数字孪生模拟和自适应控制提高了部署太阳能电池板等任务的可靠性和效率。


<details>
  <summary>Details</summary>
Motivation: 本研究旨在提升机器人在月球等不确定和具有挑战性环境中的自主操作能力，特别是通过引入“人在回路”（HITL）控制来增强机器人操纵的可靠性和效率。

Method: 研究集成了机器人操纵器和可伸缩的梯状结构，用于自主部署柔性太阳能电池板，并利用实时反馈进行精确控制。该操纵器传输位置和力-扭矩数据，以实现动态误差检测和自适应控制。为应对沉陷、可变负载和低光照条件的影响，研究采用了高效的运动规划策略，并辅以允许操作员干预模糊场景的人工控制。数字孪生模拟通过提供持续反馈、迭代任务优化和与部署流程的无缝集成来增强系统的鲁棒性。

Result: 通过在模拟月球的条件下进行测试，验证了该系统在极端光照、可变地形、变化的有效载荷和传感器限制下的性能和可靠性。

Conclusion: 该研究提出了一种在月球任务中结合了人在回路（HITL）控制的自主机器人操作增强方法，以提高在不确定和具有挑战性环境下的机器人操纵能力。通过整合人类决策和自主机器人功能，研究提高了空间应用的可靠性和效率。

Abstract: This study presents an advanced approach to enhance robotic manipulation in
uncertain and challenging environments, with a focus on autonomous operations
augmented by human-in-the-loop (HITL) control for lunar missions. By
integrating human decision-making with autonomous robotic functions, the
research improves task reliability and efficiency for space applications. The
key task addressed is the autonomous deployment of flexible solar panels using
an extendable ladder-like structure and a robotic manipulator with real-time
feedback for precision. The manipulator relays position and force-torque data,
enabling dynamic error detection and adaptive control during deployment. To
mitigate the effects of sinkage, variable payload, and low-lighting conditions,
efficient motion planning strategies are employed, supplemented by human
control that allows operators to intervene in ambiguous scenarios. Digital twin
simulation enhances system robustness by enabling continuous feedback,
iterative task refinement, and seamless integration with the deployment
pipeline. The system has been tested to validate its performance in simulated
lunar conditions and ensure reliability in extreme lighting, variable terrain,
changing payloads, and sensor limitations.

</details>


### [257] [TRAN-D: 2D Gaussian Splatting-based Sparse-view Transparent Object Depth Reconstruction via Physics Simulation for Scene Update](https://arxiv.org/abs/2507.11069)
*Jeongyun Kim,Seunghoon Jeong,Giseop Kim,Myung-Hwan Jeon,Eunji Jun,Ayoung Kim*

Main category: cs.RO

TL;DR: TRAN-D是一种新颖的2D高斯泼溅方法，用于从RGB图像重建透明物体的3D几何形状。它通过将透明物体与背景分离并使用对象感知损失来优化高斯，从而解决反射和折射问题。该方法在稀疏视图和动态环境中表现出色，并在合成和真实数据上均优于现有方法，其精度比基线高出1.5倍以上。


<details>
  <summary>Details</summary>
Motivation: 从RGB图像理解透明物体的3D几何形状具有挑战性，因为它们固有的物理特性（如反射和折射）。为了解决这些困难，特别是在视图稀疏和动态环境的场景中，我们引入了TRAN-D。

Method: TRAN-D是一种新颖的基于2D高斯泼溅的透明物体深度重建方法，它将透明物体与背景分离，从而能够集中优化对应于物体的
高斯。
我们通过一种使高斯位于被遮挡区域的对象感知损失来减轻伪影，确保覆盖不可见表面，同时减少过拟合。
此外，我们还结合了基于物理的模拟，能够在几秒钟内优化重建，有效处理物体移除和剩余物体的链式反应运动，而无需重新扫描。

Result: TRAN-D在合成TRansPose序列上的平均绝对误差减少了39%以上。
此外，尽管仅使用一张图像进行更新，TRAN-D的{\delta} < 2.5 cm精度达到了48.46%，是基线（使用六张图像）的1.5倍以上。

Conclusion: TRAN-D在合成和真实世界序列上都得到了评估，并且在基于GS的现有最先进方法方面持续展示出稳健的改进。与基线相比，TRAN-D在合成TRansPose序列上的平均绝对误差减少了39%以上。此外，尽管仅使用一张图像进行更新，TRAN-D的{\delta} < 2.5 cm精度达到了48.46%，是基线（使用六张图像）的1.5倍以上。

Abstract: Understanding the 3D geometry of transparent objects from RGB images is
challenging due to their inherent physical properties, such as reflection and
refraction. To address these difficulties, especially in scenarios with sparse
views and dynamic environments, we introduce TRAN-D, a novel 2D Gaussian
Splatting-based depth reconstruction method for transparent objects. Our key
insight lies in separating transparent objects from the background, enabling
focused optimization of Gaussians corresponding to the object. We mitigate
artifacts with an object-aware loss that places Gaussians in obscured regions,
ensuring coverage of invisible surfaces while reducing overfitting.
Furthermore, we incorporate a physics-based simulation that refines the
reconstruction in just a few seconds, effectively handling object removal and
chain-reaction movement of remaining objects without the need for rescanning.
TRAN-D is evaluated on both synthetic and real-world sequences, and it
consistently demonstrated robust improvements over existing GS-based
state-of-the-art methods. In comparison with baselines, TRAN-D reduces the mean
absolute error by over 39% for the synthetic TRansPose sequences. Furthermore,
despite being updated using only one image, TRAN-D reaches a {\delta} < 2.5 cm
accuracy of 48.46%, over 1.5 times that of baselines, which uses six images.
Code and more results are available at https://jeongyun0609.github.io/TRAN-D/.

</details>


### [258] [Force-Based Viscosity and Elasticity Measurements for Material Biomechanical Characterisation with a Collaborative Robotic Arm](https://arxiv.org/abs/2507.11133)
*Luca Beber,Edoardo Lamon,Giacomo Moretti,Matteo Saveriano,Luca Fambri,Luigi Palopoli,Daniele Fontanelli*

Main category: cs.RO

TL;DR: 本研究使用机器人系统精确估算了材料的粘弹性参数，并在离体组织上进行了验证，结果显示其准确性高，为机器人辅助医疗诊断提供了信心。


<details>
  <summary>Details</summary>
Motivation: 为了降低诊断活动的误差，减少主观性，缩短等待时间，并探索机器人技术在医疗诊断中的应用潜力。

Method: 通过机器人系统进行物理交互，精确估算人体组织的生物力学特性，评估其粘弹性参数的准确性和精确性。

Result: 机器人系统估算的粘弹性参数与使用高精度仪器获得的真值非常接近，证明了该方法的准确性。

Conclusion: 本研究结果表明，该机器人系统在测量不同粘弹性参数的材料方面具有高准确性和精确性，并已在离体组织上进行了初步概念验证，证明了该方法在生物样本上的适用性。这增强了机器人用于此类临床应用的潜力。

Abstract: Diagnostic activities, such as ultrasound scans and palpation, are relatively
low-cost. They play a crucial role in the early detection of health problems
and in assessing their progression. However, they are also error-prone
activities, which require highly skilled medical staff. The use of robotic
solutions can be key to decreasing the inherent subjectivity of the results and
reducing the waiting list. For a robot to perform palpation or ultrasound
scans, it must effectively manage physical interactions with the human body,
which greatly benefits from precise estimation of the patient's tissue
biomechanical properties. This paper assesses the accuracy and precision of a
robotic system in estimating the viscoelastic parameters of various materials,
including some tests on ex vivo tissues as a preliminary proof-of-concept
demonstration of the method's applicability to biological samples. The
measurements are compared against a ground truth derived from silicone
specimens with different viscoelastic properties, characterised using a
high-precision instrument. Experimental results show that the robotic system's
accuracy closely matches the ground truth, increasing confidence in the
potential use of robots for such clinical applications.

</details>


### [259] [A Robust Controller based on Gaussian Processes for Robotic Manipulators with Unknown Uncertainty](https://arxiv.org/abs/2507.11170)
*Giulio Giacomuzzo,Mohamed Abdelwahab,Marco Calì,Alberto Dalla Libera,Ruggero Carli*

Main category: cs.RO

TL;DR: 提出了一种基于高斯过程回归的鲁棒反馈线性化方法，用于拉格朗日系统的精确轨迹跟踪，并成功应用于双自由度平面机器人。


<details>
  <summary>Details</summary>
Motivation: 为了确保一类重要的拉格朗日系统能够精确地跟踪轨迹，即使在模型不匹配的界限未知的情况下。

Method: 提出了一种新颖的基于学习的鲁棒反馈线性化策略，该策略采用基于高斯过程回归（GPR）的回归框架来估计模型不匹配，并结合经典反馈线性化方案，通过引入一个基于GPR方差的附加项来补偿残余不确定性。

Result: 在 két bậc tự do planar robot 上进行了数值测试，证明了该策略的有效性。

Conclusion: 该方法保证了系统能够渐进地跟踪期望轨迹。

Abstract: In this paper, we propose a novel learning-based robust feedback
linearization strategy to ensure precise trajectory tracking for an important
family of Lagrangian systems. We assume a nominal knowledge of the dynamics is
given but no a-priori bounds on the model mismatch are available. In our
approach, the key ingredient is the adoption of a regression framework based on
Gaussian Processes (GPR) to estimate the model mismatch. This estimate is added
to the outer loop of a classical feedback linearization scheme based on the
nominal knowledge available. Then, to compensate for the residual uncertainty,
we robustify the controller including an additional term whose size is designed
based on the variance provided by the GPR framework. We proved that, with high
probability, the proposed scheme is able to guarantee asymptotic tracking of a
desired trajectory. We tested numerically our strategy on a 2 degrees of
freedom planar robot.

</details>


### [260] [Comparison of Localization Algorithms between Reduced-Scale and Real-Sized Vehicles Using Visual and Inertial Sensors](https://arxiv.org/abs/2507.11241)
*Tobias Kern,Leon Tolksdorf,Christian Birkner*

Main category: cs.RO

TL;DR: 在缩小的车辆上测试了三种自定位算法（OpenVINS、VINS-Fusion、RTAB-Map），发现 OpenVINS 的性能最佳。缩小的车辆在平移和旋转运动估计方面与全尺寸车辆的性能相似，可以作为自定位算法的测试平台。


<details>
  <summary>Details</summary>
Motivation: 由于先进的自动驾驶功能的发展，物理缩小比例的车辆正在出现，因此有必要研究尺度对自定位准确性的影响。

Method: 使用 ROS2 兼容的视觉和视觉惯性算法（OpenVINS、VINS-Fusion 和 RTAB-Map）以及摄像头和惯性测量单元（IMU）来研究尺度对自定位准确性的影响。记录缩小比例车辆的数据，并将其与真实比例车辆的数据进行比较。

Result: OpenVINS 在应用于缩小的车辆时表现最佳，定位误差最低。缩小比例的车辆在平移车辆运动估计准确性方面与全尺寸车辆的差异很小，而在旋转车辆运动估计准确性方面没有显着差异。

Conclusion: 所选的视觉和视觉惯性算法在应用于缩小的车辆时，OpenVINS 的性能最佳，并且所选算法在缩小车辆和全尺寸车辆之间的姿态估计准确性方面没有重大差异，这表明缩小的车辆可以作为自定位算法的测试平台。

Abstract: Physically reduced-scale vehicles are emerging to accelerate the development
of advanced automated driving functions. In this paper, we investigate the
effects of scaling on self-localization accuracy with visual and
visual-inertial algorithms using cameras and an inertial measurement unit
(IMU). For this purpose, ROS2-compatible visual and visual-inertial algorithms
are selected, and datasets are chosen as a baseline for real-sized vehicles. A
test drive is conducted to record data of reduced-scale vehicles. We compare
the selected localization algorithms, OpenVINS, VINS-Fusion, and RTAB-Map, in
terms of their pose accuracy against the ground-truth and against data from
real-sized vehicles. When comparing the implementation of the selected
localization algorithms to real-sized vehicles, OpenVINS has the lowest average
localization error. Although all selected localization algorithms have
overlapping error ranges, OpenVINS also performs best when applied to a
reduced-scale vehicle. When reduced-scale vehicles were compared to real-sized
vehicles, minor differences were found in translational vehicle motion
estimation accuracy. However, no significant differences were found when
comparing the estimation accuracy of rotational vehicle motion, allowing RSVRs
to be used as testing platforms for self-localization algorithms.

</details>


### [261] [Development of an Autonomous Mobile Robotic System for Efficient and Precise Disinfection](https://arxiv.org/abs/2507.11270)
*Ting-Wei Ou,Jia-Hao Jiang,Guan-Lin Huang,Kuu-Young Young*

Main category: cs.RO

TL;DR: 本研究提出了一种创新的移动机器人紫外线消毒系统，通过识别病毒热点和优化紫外线剂量，能在保证消毒效果的同时，显著缩短医院消毒时间。


<details>
  <summary>Details</summary>
Motivation: 新冠疫情凸显了医院环境中自动化消毒的必要性，尤其是在资源短缺和人员有限的情况下。现有研究主要关注紫外线覆盖范围，忽视了人类活动对病毒分布的影响。因此，需要一种能够关注病毒热点并优化消毒过程的自动化系统。

Method: 提出了一种移动机器人紫外线消毒系统，该系统能够识别病毒热点并进行优化消毒，通过优化紫外线剂量确保所有表面得到充分消毒，并最大限度地减少低风险区域的暴露，从而缩短消毒时间。

Result: 在两个代表性的医院场景中，本研究提出的方法在达到相同消毒效果的情况下，分别将消毒时间缩短了 30.7% 和 31.9%。

Conclusion: 本研究提出的移动机器人紫外线消毒系统能够有效缩短消毒时间，同时保证消毒效果，并针对医院环境中的病毒热点进行优化消毒。

Abstract: The COVID-19 pandemic has severely affected public health, healthcare
systems, and daily life, especially amid resource shortages and limited
workers. This crisis has underscored the urgent need for automation in hospital
environments, particularly disinfection, which is crucial to controlling virus
transmission and improving the safety of healthcare personnel and patients.
Ultraviolet (UV) light disinfection, known for its high efficiency, has been
widely adopted in hospital settings. However, most existing research focuses on
maximizing UV coverage while paying little attention to the impact of human
activity on virus distribution. To address this issue, we propose a mobile
robotic system for UV disinfection focusing on the virus hotspot. The system
prioritizes disinfection in high-risk areas and employs an approach for
optimized UV dosage to ensure that all surfaces receive an adequate level of UV
exposure while significantly reducing disinfection time. It not only improves
disinfection efficiency but also minimizes unnecessary exposure in low-risk
areas. In two representative hospital scenarios, our method achieves the same
disinfection effectiveness while reducing disinfection time by 30.7% and 31.9%,
respectively. The video of the experiment is available at:
https://youtu.be/wHcWzOcoMPM.

</details>


### [262] [Diffusion-Based Imaginative Coordination for Bimanual Manipulation](https://arxiv.org/abs/2507.11296)
*Huilin Xu,Jian Ding,Jiakun Xu,Ruixiang Wang,Jun Chen,Jinjie Mai,Yanwei Fu,Bernard Ghanem,Feng Xu,Mohamed Elhoseiny*

Main category: cs.RO

TL;DR: 本研究提出了一种基于扩散的框架，通过联合优化视频和动作预测来提升机器人双臂协调能力。该方法通过多帧潜在预测和单向注意机制，在ALOHA、RoboTwin和真实世界实验中均取得了显著的成功率提升。


<details>
  <summary>Details</summary>
Motivation: 为了解决机器人双臂操作中高维动作空间和复杂协调的挑战，并探索视频预测在增强双臂协调方面的潜力。

Method: 提出了一种统一的基于扩散的框架，用于联合优化视频和动作预测。具体来说，采用多帧潜在预测策略将未来状态编码到潜在空间中，并引入单向注意机制，使视频预测依赖于动作，而动作预测独立于视频预测，从而在推理时可以省略视频预测以提高效率。

Result: 在ALOHA、RoboTwin两个模拟基准和真实世界设置上进行的实验表明，该方法显著提高了成功率，分别比强基线ACT提高了24.9%、11.1%和32.5%。

Conclusion: 该研究提出了一个统一的基于扩散的方法来联合优化视频和动作预测，以提高双臂协调能力。实验结果表明，与现有基线ACT相比，该方法在ALOHA、RoboTwin和真实世界实验中分别取得了24.9%、11.1%和32.5%的成功率提升。

Abstract: Bimanual manipulation is crucial in robotics, enabling complex tasks in
industrial automation and household services. However, it poses significant
challenges due to the high-dimensional action space and intricate coordination
requirements. While video prediction has been recently studied for
representation learning and control, leveraging its ability to capture rich
dynamic and behavioral information, its potential for enhancing bimanual
coordination remains underexplored. To bridge this gap, we propose a unified
diffusion-based framework for the joint optimization of video and action
prediction. Specifically, we propose a multi-frame latent prediction strategy
that encodes future states in a compressed latent space, preserving
task-relevant features. Furthermore, we introduce a unidirectional attention
mechanism where video prediction is conditioned on the action, while action
prediction remains independent of video prediction. This design allows us to
omit video prediction during inference, significantly enhancing efficiency.
Experiments on two simulated benchmarks and a real-world setting demonstrate a
significant improvement in the success rate over the strong baseline ACT using
our method, achieving a \textbf{24.9\%} increase on ALOHA, an \textbf{11.1\%}
increase on RoboTwin, and a \textbf{32.5\%} increase in real-world experiments.
Our models and code are publicly available at
https://github.com/return-sleep/Diffusion_based_imaginative_Coordination.

</details>


### [263] [All Eyes, no IMU: Learning Flight Attitude from Vision Alone](https://arxiv.org/abs/2507.11302)
*Jesse J. Hagenaars,Stein Stroobants,Sander M. Bohte,Guido C. H. E. De Croon*

Main category: cs.RO

TL;DR: 研究提出了一种仅使用事件相机进行视觉飞行控制的方法，无需惯性传感器，可用于飞行机器人。


<details>
  <summary>Details</summary>
Motivation: 许多飞行动物依靠视觉进行姿态控制，而它们可能没有专门的重力感应。与此相反，飞行机器人通常严重依赖加速度计和陀螺仪进行姿态稳定。因此，本研究旨在探索一种仅依靠视觉进行飞行控制的方法，以应对通用环境。

Method: 该方法使用了一个小型循环卷积神经网络，通过监督学习进行训练，实现了仅依赖事件相机数据来估计姿态和旋转速率，从而无需惯性传感器即可进行飞行控制。

Result: 现实世界的飞行测试表明，该方法结合了事件相机和低延迟神经网络，能够取代传统飞行控制回路中的惯性测量单元。此外，研究还探讨了网络在不同环境中的泛化能力，以及记忆和不同视野的影响，其中具有记忆和类似地平线视觉线索的网络性能最佳，而具有较窄视野的变体则具有更好的相对泛化能力。

Conclusion: 本文展示了仅通过视觉进行飞行控制，可作为实现自主、昆虫尺度飞行机器人的有前景的候选方案。

Abstract: Vision is an essential part of attitude control for many flying animals, some
of which have no dedicated sense of gravity. Flying robots, on the other hand,
typically depend heavily on accelerometers and gyroscopes for attitude
stabilization. In this work, we present the first vision-only approach to
flight control for use in generic environments. We show that a quadrotor drone
equipped with a downward-facing event camera can estimate its attitude and
rotation rate from just the event stream, enabling flight control without
inertial sensors. Our approach uses a small recurrent convolutional neural
network trained through supervised learning. Real-world flight tests
demonstrate that our combination of event camera and low-latency neural network
is capable of replacing the inertial measurement unit in a traditional flight
control loop. Furthermore, we investigate the network's generalization across
different environments, and the impact of memory and different fields of view.
While networks with memory and access to horizon-like visual cues achieve best
performance, variants with a narrower field of view achieve better relative
generalization. Our work showcases vision-only flight control as a promising
candidate for enabling autonomous, insect-scale flying robots.

</details>


### [264] [Acting and Planning with Hierarchical Operational Models on a Mobile Robot: A Study with RAE+UPOM](https://arxiv.org/abs/2507.11345)
*Oscar Lima,Marc Vinci,Sunandita Patra,Sebastian Stock,Joachim Hertzberg,Martin Atzmueller,Malik Ghallab,Dana Nau,Paolo Traverso*

Main category: cs.RO

TL;DR: 我们提出了一个集成的 actor-planner 系统 (RAE+UPOM)，用于解决机器人任务执行中的不一致性问题。该系统在移动机械臂的物体收集任务中进行了物理部署，并证明了其在动作失败和传感器噪声下的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 解决机器人任务执行中，符号规划模型和实际运行的控制结构之间存在不一致性的挑战。

Method: 我们提出了一种集成的 actor-planner 系统，该系统通过一个交织了 RAE（Reactive Acting Engine）和 UPOM（anytime UCT-like Monte Carlo planner）的层级操作模型来连接符号规划模型和机器人实际运行的控制结构。

Result: 在真实世界的物体收集任务中，我们对一个移动机械臂进行了 RAE+UPOM 的实现和实验。结果表明，该系统能够可靠地执行任务，并在动作失败和传感器噪声等情况下保持鲁棒性，同时提供了关于交织的 acting-and-planning 决策过程的实证见解。

Conclusion: 在机器人任务执行中，我们提出了一种集成的 actor-planner 系统，该系统在物理部署中展示了鲁棒的任务执行能力，能够应对动作失败和传感器噪声。

Abstract: Robotic task execution faces challenges due to the inconsistency between
symbolic planner models and the rich control structures actually running on the
robot. In this paper, we present the first physical deployment of an integrated
actor-planner system that shares hierarchical operational models for both
acting and planning, interleaving the Reactive Acting Engine (RAE) with an
anytime UCT-like Monte Carlo planner (UPOM). We implement RAE+UPOM on a mobile
manipulator in a real-world deployment for an object collection task. Our
experiments demonstrate robust task execution under action failures and sensor
noise, and provide empirical insights into the interleaved acting-and-planning
decision making process.

</details>


### [265] [From Production Logistics to Smart Manufacturing: The Vision for a New RoboCup Industrial League](https://arxiv.org/abs/2507.11402)
*Supun Dissanayaka,Alexander Ferrein,Till Hofmann,Kosuke Nakajima,Mario Sanz-Lopez,Jesus Savage,Daniel Swoboda,Matteo Tschesche,Wataru Uemura,Tarik Viehmann,Shohei Yasuda*

Main category: cs.RO

TL;DR: RoboCup物流联赛因未能跟上智能制造的步伐而进行了改革，推出了RoboCup智能制造联赛，涵盖了更多领域，如工业机器人、人机协作和人形机器人，并侧重于当前和未来的挑战。


<details>
  <summary>Details</summary>
Motivation: RoboCup物流联赛由于过于关注生产物流而未能反映智能制造的最新进展，削弱了其相关性。

Method: 提出RoboCup智能制造联赛的愿景，一个包含多个独立但逐渐合并的赛道的大型智能制造场景。

Result: 预期该联赛将吸引新老团队，并将重点转移到当前和未来的工业机器人挑战上。

Conclusion: 该新竞赛旨在通过涵盖工业机器人、人机协作和人形机器人等领域的多个赛道，并结合生产物流，来吸引新老团队，并关注当前和未来的工业机器人挑战，从而提高其吸引力和相关性。

Abstract: The RoboCup Logistics League is a RoboCup competition in a smart factory
scenario that has focused on task planning, job scheduling, and multi-agent
coordination. The focus on production logistics allowed teams to develop highly
competitive strategies, but also meant that some recent developments in the
context of smart manufacturing are not reflected in the competition, weakening
its relevance over the years. In this paper, we describe the vision for the
RoboCup Smart Manufacturing League, a new competition designed as a larger
smart manufacturing scenario, reflecting all the major aspects of a modern
factory. It will consist of several tracks that are initially independent but
gradually combined into one smart manufacturing scenario. The new tracks will
cover industrial robotics challenges such as assembly, human-robot
collaboration, and humanoid robotics, but also retain a focus on production
logistics. We expect the reenvisioned competition to be more attractive to
newcomers and well-tried teams, while also shifting the focus to current and
future challenges of industrial robotics.

</details>


### [266] [Human-Robot collaboration in surgery: Advances and challenges towards autonomous surgical assistants](https://arxiv.org/abs/2507.11460)
*Jacinto Colan,Ana Davila,Yutaro Yamada,Yasuhisa Hasegawa*

Main category: cs.RO

TL;DR: 本系统综述检视了自主手术机器人助手（ASAR）在人机协作外科手术领域的进展与挑战，重点关注了机器人提供有意义辅助的场景。研究发现，尽管ASAR在内窥镜引导等方面的应用日益广泛，但仍面临动作协调、手术意识、信息交换和技能获取等方面的挑战，并指出了未来研究的方向。


<details>
  <summary>Details</summary>
Motivation: 旨在检查自主手术机器人助手（ASAR）的发展进展和持续挑战，特别关注机器人为主的提供有意义和积极支持的人类外科医生。

Method: 采用PRISMA指南，在IEEE Xplore、Scopus和Web of Science数据库中进行了全面的文献检索，最终选定了32项研究进行详细分析。

Result: 研究结果表明，对ASAR的关注日益增长，主要应用在内窥镜引导，并在自主工具操作方面取得了新进展。然而，机器人动作与外科医生偏好的一致性、自主系统的手术意识、无缝人机信息交换的建立以及在共享工作空间中获得技能的复杂性等关键挑战阻碍了ASAR的广泛应用。

Conclusion: 该综述综合了当前趋势，明确了关键的局限性，并概述了对提高手术环境人机协作的可靠性、安全性和有效性至关重要的新研究方向。

Abstract: Human-robot collaboration in surgery represents a significant area of
research, driven by the increasing capability of autonomous robotic systems to
assist surgeons in complex procedures. This systematic review examines the
advancements and persistent challenges in the development of autonomous
surgical robotic assistants (ASARs), focusing specifically on scenarios where
robots provide meaningful and active support to human surgeons. Adhering to the
PRISMA guidelines, a comprehensive literature search was conducted across the
IEEE Xplore, Scopus, and Web of Science databases, resulting in the selection
of 32 studies for detailed analysis. Two primary collaborative setups were
identified: teleoperation-based assistance and direct hands-on interaction. The
findings reveal a growing research emphasis on ASARs, with predominant
applications currently in endoscope guidance, alongside emerging progress in
autonomous tool manipulation. Several key challenges hinder wider adoption,
including the alignment of robotic actions with human surgeon preferences, the
necessity for procedural awareness within autonomous systems, the establishment
of seamless human-robot information exchange, and the complexities of skill
acquisition in shared workspaces. This review synthesizes current trends,
identifies critical limitations, and outlines future research directions
essential to improve the reliability, safety, and effectiveness of human-robot
collaboration in surgical environments.

</details>


### [267] [Robot Drummer: Learning Rhythmic Skills for Humanoid Drumming](https://arxiv.org/abs/2507.11498)
*Asad Ali Shahid,Francesco Braghin,Loris Roveda*

Main category: cs.RO

TL;DR: 机器人鼓手：一个能够进行高精度、富有表现力演奏的人形机器人系统，可通过强化学习实现类似人类的击打策略。


<details>
  <summary>Details</summary>
Motivation: 在人形机器人在灵活性、平衡性和运动性方面取得显著进步的同时，它们在音乐表演等表达性领域的应用仍有待探索。然而，像击鼓这样的音乐任务具有独特的挑战，例如瞬时时序、快速接触和多肢协调性。

Method: 将 the humanoid drumming 表述为时序性接触点的满足，并将鼓谱转化为节奏接触链（Rhythmic Contact Chain）。通过将乐曲分解为固定长度的片段，并利用强化学习技术，训练了一个能够处理长时程音乐表演的单一策略。

Result: 通过在摇滚、金属和爵士乐等三十多首流行曲目上进行的大量实验，结果表明机器人鼓手能够持续获得高 F1 分数。所学习到的行为还展现出类似人类的演奏策略，例如交叉手臂击打和自适应的鼓槌分配。

Conclusion: 机器人鼓手在节奏、精确度和多肢协调性方面取得了显著成效，并且能够跨多种音乐风格实现类似人类的演奏策略。

Abstract: Humanoid robots have seen remarkable advances in dexterity, balance, and
locomotion, yet their role in expressive domains, such as music performance,
remains largely unexplored. Musical tasks, like drumming, present unique
challenges, including split-second timing, rapid contacts, and multi-limb
coordination over pieces lasting minutes. In this paper, we introduce Robot
Drummer, a humanoid system capable of expressive, high-precision drumming
across a diverse repertoire of songs. We formulate humanoid drumming as
sequential fulfillment of timed-contacts and transform drum scores in to a
Rhythmic Contact Chain. To handle the long-horizon nature of musical
performance, we decompose each piece into fixed-length segments and train a
single policy across all segments in parallel using reinforcement learning.
Through extensive experiments on over thirty popular rock, metal, and jazz
tracks, our results demonstrate that Robot Drummer consistently achieves high
F1 scores. The learned behaviors exhibit emergent human-like drumming
strategies, such as cross-arm strikes, and adaptive sticks assignments,
demonstrating the potential of reinforcement learning to bring humanoid robots
into the domain of creative musical performance. Project page:
\href{https://robot-drummer.github.io}{robot-drummer.github.io}

</details>


### [268] [LLM-based ambiguity detection in natural language instructions for collaborative surgical robots](https://arxiv.org/abs/2507.11525)
*Ana Davila,Jacinto Colan,Yasuhisa Hasegawa*

Main category: cs.RO

TL;DR: "在手术中，自然语言指令可能存在歧义，带来风险。本研究提出一个框架，利用大型语言模型（LLM）和共形预测来检测这些歧义，并在评估中展现出超过60%的准确率，以提高人机协作的安全性。"


<details>
  <summary>Details</summary>
Motivation: "为了解决安全关键的人机交互（尤其是在手术等领域）中自然语言指令的歧义性问题。"

Method: "提出一个框架，使用大型语言模型（LLM）进行特定于协作外科场景的歧义检测。该方法采用LLM评估器集成，结合链式思考评估器，并通过共形预测合成评估结果."

Result: "在对Llama 3.2 11B和Gemma 3 12B的评估中，区分模糊与非模糊的外科手术指令的分类准确率超过60%。"

Conclusion: "该框架通过集成多种LLM评估器并利用共形预测来合成评估，从而能够识别模糊的神经外科手术指令，提高了人机协作的安全性与可靠性."

Abstract: Ambiguity in natural language instructions poses significant risks in
safety-critical human-robot interaction, particularly in domains such as
surgery. To address this, we propose a framework that uses Large Language
Models (LLMs) for ambiguity detection specifically designed for collaborative
surgical scenarios. Our method employs an ensemble of LLM evaluators, each
configured with distinct prompting techniques to identify linguistic,
contextual, procedural, and critical ambiguities. A chain-of-thought evaluator
is included to systematically analyze instruction structure for potential
issues. Individual evaluator assessments are synthesized through conformal
prediction, which yields non-conformity scores based on comparison to a labeled
calibration dataset. Evaluating Llama 3.2 11B and Gemma 3 12B, we observed
classification accuracy exceeding 60% in differentiating ambiguous from
unambiguous surgical instructions. Our approach improves the safety and
reliability of human-robot collaboration in surgery by offering a mechanism to
identify potentially ambiguous instructions before robot action.

</details>


<div id='physics.app-ph'></div>

# physics.app-ph [[Back]](#toc)

### [269] [Real-time, Adaptive Radiological Anomaly Detection and Isotope Identification Using Non-negative Matrix Factorization](https://arxiv.org/abs/2507.10715)
*Chandler Jones,Mark Bandstra,Stefan Faaland,Yue Shi Lai,Nico Abgrall,Scott Suchyta,Reynold Cooper*

Main category: physics.app-ph

TL;DR: 为解决移动探测器系统在核不扩散应用中背景变化带来的挑战，提出了一种新颖的自适应NMF算法，该算法能实时更新背景模型，提高检测性能。


<details>
  <summary>Details</summary>
Motivation: 在核不扩散应用中，如搜索操作，光谱异常检测和同位素识别算法是不可或缺的组成部分。然而，对于移动探测器系统来说，由于观测到的伽马射线背景变化比静态探测器系统更大，因此该任务尤其具有挑战性。这可能导致算法超出预期的误报率，或者牺牲检测灵敏度以维持所需的误报率。

Method: 开发了一种新颖的基于NMF的算法，该算法能够周期性地更新其背景模型以适应不断变化的Ifs。

Result: 该自适应NMF算法比现有的基于NMF的方法具有更少的环境假设，使其更具通用性，同时在模拟和真实世界的数据集上保持或超过检测性能。

Conclusion: 开发的自适应NMF算法能更好地适应不断变化的Ifs，并在模拟和真实世界的数据集上保持或超过检测性能。

Abstract: Spectroscopic anomaly detection and isotope identification algorithms are
integral components in nuclear nonproliferation applications such as search
operations. The task is especially challenging in the case of mobile detector
systems due to the fact that the observed gamma-ray background changes more
than for a static detector system, and a pretrained background model can easily
find itself out of domain. The result is that algorithms may exceed their
intended false alarm rate, or sacrifice detection sensitivity in order to
maintain the desired false alarm rate. Non-negative matrix factorization (NMF)
has been shown to be a powerful tool for spectral anomaly detection and
identification, but, like many similar algorithms that rely on data-driven
background models, in its conventional implementation it is unable to update in
real time to account for environmental changes that affect the background
spectroscopic signature. We have developed a novel NMF-based algorithm that
periodically updates its background model to accommodate changing environmental
conditions. The Adaptive NMF algorithm involves fewer assumptions about its
environment, making it more generalizable than existing NMF-based methods while
maintaining or exceeding detection performance on simulated and real-world
datasets.

</details>


### [270] [Realization of Friedrich-Wintgen QBIC with high Q-factors based on acoustic-solid coupling and sensing applications](https://arxiv.org/abs/2507.11390)
*Bowei Wu,BoyueSu,Shuanghuizhi Li,Tingfeng Ma*

Main category: physics.app-ph

TL;DR: 本研究提出了一种基于声固耦合F-W BICs的气体传感新方法，通过提高Q因子解决了传统方法的局限性，并在实验中验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 为了满足现代化学和生物传感领域对更高分辨率和灵敏度的需求，本研究旨在解决传统开放系统F-W BICs的Q因子不足的问题，并探索其在气体传感中的应用。

Method: 首先建立了结合准封闭腔内弹性波和声波的耦合谐振器模型。然后采用耦合模式理论计算局域模式和辐射模式的本征模式，并构建耦合系统的哈密顿矩阵，推导出声学透射谱。

Result: 与开放系统相比，声固耦合诱导的F-W BIC的Q因子显著提高，并通过实验验证。基于此，开发了一种基于声固耦合F-W BIC行为的气体浓度传感技术，并进行了实验验证，结果表明该技术对不同浓度的气体具有良好的响应。

Conclusion: 本工作通过声固耦合引入法布里-珀罗（F-P）共振，探索了准封闭系统中高Q值弗里德里希-温特根（F-W）束缚态连续体（BICs）的形成机制和实现方法，并进一步研究了其在气体传感中的应用。实验结果表明，所提出的基于声固耦合F-W BIC行为的气体传感技术具有可行性和可靠性，能够对不同浓度的气体产生显著响应。

Abstract: In recent years, bound states in the continuum (BICs) have attracted
extensive attentions in the sensing field due to their theoretically ultra-high
resonance quality factors (Q-factors). Among them, Friedrich-Wintgen (F-W)
BICs, which arise from the interference between different coupled modes, are
particularly promising for acoustic sensing applications owing to the easy
realization. Most existing F-W BICs are realized in open systems through the
interference between waveguides and resonant cavities. However, with increasing
demands for higher resolution and sensitivity in modern chemical and biological
sensing, the practically measured Q-factors of conventional open-system F-W
BICs often fall short of expectations.In this work, we introduce F-P resonance
via acoustic-solid coupling to explore the formation mechanism and realization
method of high-Q F-W BICs in quasi-closed systems, and further investigate
their application in gas sensing. A coupled resonator model combining elastic
and acoustic waves in a quasi-closed cavity is first established. Coupled mode
theory is employed to calculate the eigenmodes of both localized and radiative
modes. Based on this, the Hamiltonian matrix of the coupled system is
constructed, from which the acoustic transmission spectrum is derived. The
results show that the Q-factor of the F-W BIC induced by acoustic-solid
coupling is significantly higher than that of open systems, which is further
validated by experiments.Based on this, a gas concentration sensing technique
based on acoustic-solid coupled F-W BIC behavior is developed. A sensing device
is fabricated accordingly, and gas concentration measurements are carried out.
Experimental results demonstrate a pronounced response to gases with different
concentrations, confirming the feasibility and reliability of this novel gas
sensing approach.

</details>


<div id='cs.NE'></div>

# cs.NE [[Back]](#toc)

### [271] [Tangma: A Tanh-Guided Activation Function with Learnable Parameters](https://arxiv.org/abs/2507.10560)
*Shreel Golwala*

Main category: cs.NE

TL;DR: Tangma是一种新的、可学习的激活函数，通过引入可学习参数$\alpha$和$\\gamma$来调整神经元激活和提高训练稳定性。在MNIST和CIFAR-10上的实验结果表明，Tangma在准确率、收敛速度和训练效率方面均优于ReLU、Swish和GELU等现有激活函数，为深度学习模型提供了更优的性能和更强的可控性。


<details>
  <summary>Details</summary>
Motivation: 激活函数是深度神经网络中有效反向传播和表达能力的关键。本文旨在通过引入一种新的、可学习的激活函数Tangma来改进深度神经网络的训练效果和性能。

Method: 本文提出了一种名为Tangma的新激活函数，它结合了双曲正切函数的平滑形状以及两个可学习参数：$\alpha$用于调整神经元激活，$\\gamma$用于保留弱梯度和提高训练稳定性。在MNIST和CIFAR-10数据集上，使用包含卷积层和线性层的自定义网络对Tangma进行了评估，并与ReLU、Swish和GELU进行了比较。

Result: Tangma在MNIST上实现了99.09%的验证准确率，优于其他激活函数，并展示了更快的收敛速度和更高的稳定性。在CIFAR-10上，Tangma达到了78.15%的验证准确率，同样优于其他激活函数，并保持了有竞争力的训练损失。此外，Tangma的平均训练时间也低于Swish和GELU。

Conclusion: Tangma在MNIST和CIFAR-10数据集上表现优于ReLU、Swish和GELU等基线激活函数，在MNIST上达到了最高的验证准确率(99.09%)和最低的验证损失，实现了比基线更快、更稳定的收敛。在CIFAR-10上，Tangma达到了78.15%的验证准确率，并且训练效率也优于Swish和GELU。这表明Tangma在标准的视觉任务中表现良好，并能实现可靠、高效的训练。其可学习的设计提供了对激活行为的更多控制，这可能有利于图像识别或语言建模等任务中的大型模型。

Abstract: Activation functions are key to effective backpropagation and expressiveness
in deep neural networks. This work introduces Tangma, a new activation function
that combines the smooth shape of the hyperbolic tangent with two learnable
parameters: $\alpha$, which shifts the curve's inflection point to adjust
neuron activation, and $\gamma$, which adds linearity to preserve weak
gradients and improve training stability. Tangma was evaluated on MNIST and
CIFAR-10 using custom networks composed of convolutional and linear layers, and
compared against ReLU, Swish, and GELU. On MNIST, Tangma achieved the highest
validation accuracy of 99.09% and the lowest validation loss, demonstrating
faster and more stable convergence than the baselines. On CIFAR-10, Tangma
reached a top validation accuracy of 78.15%, outperforming all other activation
functions while maintaining a competitive training loss. Tangma also showed
improved training efficiency, with lower average epoch runtimes compared to
Swish and GELU. These results suggest that Tangma performs well on standard
vision tasks and enables reliable, efficient training. Its learnable design
gives more control over activation behavior, which may benefit larger models in
tasks such as image recognition or language modeling.

</details>


### [272] [SFATTI: Spiking FPGA Accelerator for Temporal Task-driven Inference -- A Case Study on MNIST](https://arxiv.org/abs/2507.10561)
*Alessio Caviglia,Filippo Marostica,Alessio Carpegna,Alessandro Savino,Stefano Di Carlo*

Main category: cs.NE

TL;DR: 本文利用Spiker+框架为MNIST手写数字识别生成SNN加速器，探讨了不同配置的优缺点，以满足边缘计算的低功耗和低延迟需求。


<details>
  <summary>Details</summary>
Motivation: 为了在边缘应用（如图像识别）中实现低延迟、高能效推理，需要硬件加速器。SNN因其事件驱动和时间稀疏的特性，非常适合低功耗FPGA部署。

Method: 本文使用Spiker+框架，通过HLS规范网络拓扑、神经元模型和量化，自动生成SNN加速器，并在MNIST数据集上手写数字识别任务上进行评估。

Result: 通过评估多种配置，分析了与边缘计算约束相关的权衡。

Conclusion: 硬件加速器对于在图像识别等边缘应用中实现低延迟、高能效推理至关重要。脉冲神经网络（SNN）由于其事件驱动和时间稀疏的特性，特别有前景，非常适合低功耗基于FPGA的部署。本文探讨使用开源Spiker+框架为MNIST数据集上的手写数字识别生成优化的SNN加速器。Spiker+支持网络拓扑、神经元模型和量化的 HLS 规范，可自动生成可部署的HDL。

Abstract: Hardware accelerators are essential for achieving low-latency,
energy-efficient inference in edge applications like image recognition. Spiking
Neural Networks (SNNs) are particularly promising due to their event-driven and
temporally sparse nature, making them well-suited for low-power Field
Programmable Gate Array (FPGA)-based deployment. This paper explores using the
open-source Spiker+ framework to generate optimized SNNs accelerators for
handwritten digit recognition on the MNIST dataset. Spiker+ enables high-level
specification of network topologies, neuron models, and quantization,
automatically generating deployable HDL. We evaluate multiple configurations
and analyze trade-offs relevant to edge computing constraints.

</details>


### [273] [A Biomimetic Way for Coral-Reef-Inspired Swarm Intelligence for Carbon-Neutral Wastewater Treatment](https://arxiv.org/abs/2507.10563)
*Antonis Messinis*

Main category: cs.NE

TL;DR: 这项研究提出了一种受珊瑚礁启发的群集交互网络，用于碳中和废水处理，实现了高去除效率和低能耗，并有潜力节省柴油，但数据科学人员和可解释性是未来的挑战。


<details>
  <summary>Details</summary>
Motivation: 随着废水处理率的增加，实现能源中和的净化过程面临挑战。

Method: 该研究提出了一种受珊瑚礁启发的群集交互网络（Swarm Interaction Network），并结合了形态发生抽象和多任务碳感知技术，以实现碳中和废水处理。

Result: 该方法实现了 96.7% 的去除效率，0.31 kWh m$^{-3}$ 的能耗和 14.2 g m$^{-3}$ 的 CO$_{2}$ 排放量，并在岛屿泻湖、啤酒厂废水和沙漠温室等现场情景中显示出高达 22% 的柴油节省潜力。

Conclusion: 这项研究引入了一种受珊瑚礁启发的、用于碳中和废水处理的群集交互网络，该网络结合了形态发生抽象和多任务碳感知。与七个基线相比，该方法实现了 96.7% 的去除效率，0.31 kWh m$^{-3}$ 的能耗和 14.2 g m$^{-3}$ 的 CO$_{2}$ 排放量。方差分析证明了其在传感器漂移下的鲁棒性。现场情景——岛屿泻湖、啤酒厂废水和沙漠温室——显示出高达 22% 的柴油节省潜力。

Abstract: With increasing wastewater rates, achieving energy-neutral purification is
challenging. We introduce a coral-reef-inspired Swarm Interaction Network for
carbon-neutral wastewater treatment, combining morphogenetic abstraction with
multi-task carbon awareness. Scalability stems from linear token complexity,
mitigating the energy-removal problem. Compared with seven baselines, our
approach achieves 96.7\% removal efficiency, 0.31~kWh~m$^{-3}$ energy
consumption, and 14.2~g~m$^{-3}$ CO$_2$ emissions. Variance analysis
demonstrates robustness under sensor drift. Field scenarios--insular lagoons,
brewery spikes, and desert greenhouses--show potential diesel savings of up to
22\%. However, data-science staffing remains an impediment. Future work will
integrate AutoML wrappers within the project scope, although governance
restrictions pose interpretability challenges that require further visual
analytics.

</details>


### [274] [An Exact Gradient Framework for Training Spiking Neural Networks](https://arxiv.org/abs/2507.10568)
*Arman Ferdowsi,Atakan Aral*

Main category: cs.NE

TL;DR: 提出了一种新的事件驱动学习框架，用于训练脉冲神经网络（SNN），提高了准确性、时间精度和鲁棒性，并简化了神经形态硬件的实现。


<details>
  <summary>Details</summary>
Motivation: 为了充分利用SNN的时间动态，需要整合可训练的突触传输延迟和自适应发放阈值等生物启发的自由度。现有方法存在训练精度和效率限制，并且对神经形态硬件实现提出了挑战。

Method: 提出了一种分析性事件驱动学习框架，克服了现有方法对离散时间模拟、代理梯度近似或完全访问内部状态变量的依赖，能够计算精确的损失梯度。

Result: 实验结果表明，与现有方法相比，所提出的框架在准确性（最高提升7%）、时间精度和鲁棒性方面均有显著的提高。

Conclusion: 该研究提出了一种分析性事件驱动学习框架，能够精确计算关于突触权重、传输延迟和自适应神经元发放阈值的损失梯度，在准确性、时间精度和鲁棒性方面均取得了显著提升。

Abstract: Spiking neural networks inherently rely on the precise timing of discrete
spike events for information processing. Incorporating additional bio-inspired
degrees of freedom, such as trainable synaptic transmission delays and adaptive
firing thresholds, is essential for fully leveraging the temporal dynamics of
SNNs. Although recent methods have demonstrated the benefits of training
synaptic weights and delays, both in terms of accuracy and temporal
representation, these techniques typically rely on discrete-time simulations,
surrogate gradient approximations, or full access to internal state variables
such as membrane potentials. Such requirements limit training precision and
efficiency and pose challenges for neuromorphic hardware implementation due to
increased memory and I/O bandwidth demands. To overcome these challenges, we
propose an analytical event-driven learning framework that computes exact loss
gradients not only with respect to synaptic weights and transmission delays but
also to adaptive neuronal firing thresholds. Experiments on multiple benchmarks
demonstrate significant gains in accuracy (up to 7%), timing precision, and
robustness compared to existing methods.

</details>


### [275] [Grammatical Structure and Grammatical Variations in Non-Metric Iranian Classical Music](https://arxiv.org/abs/2507.10708)
*Maziar Kanani,Sean O Leary,James McDermott*

Main category: cs.NE

TL;DR: 该研究介绍了用于解析和生成非公制伊朗古典音乐的算法，并成功创建了可接受的音乐变体。


<details>
  <summary>Details</summary>
Motivation: 旨在开发一种用于解析和生成非公制伊朗古典音乐的算法，以用于教育和音乐学目的，并为该类型音乐创建变体。

Method: 介绍了符号数据集和用于结构解析和生成伊朗古典音乐变体的算法。该算法将每个旋律（Gusheh）解析为一种语法，以识别动机和乐句，然后通过对语法进行突变来生成新语法，从而产生原始曲调的变体。对突变进行了统计分析。

Result: 该解析算法能够很好地捕捉非公制组织。生成的变体被领域专家听众认为是可接受的。

Conclusion: 该系统成功地通过突变产生了可接受的变体。该方法可以应用于阿拉伯或土耳其古典音乐。

Abstract: In this study we introduce a symbolic dataset composed of non-metric Iranian
classical music, and algorithms for structural parsing of this music, and
generation of variations. The corpus comprises MIDI files and data sheets of
Dastgah Shour from Radif Mirza Abdollah, the foundational repertoire of Iranian
classical music. Furthermore, we apply our previously-introduced algorithm for
parsing melodic structure (Kanani et al., 2023b)to the dataset. Unlike much
Western music, this type of non-metric music does not follow bar-centric
organisation. The non-metric organisation can be captured well by our parsing
algorithm. We parse each tune (Gusheh) into a grammar to identify motifs and
phrases. These grammar representations can be useful for educational and
ethnomusicological purposes. We also further develop a previously-introduced
method of creating melodic variations (Kanani et al., 2023b). After parsing an
existing tune to produce a grammar, by applying mutations to this grammar, we
generate a new grammar. Expanding this new version yields a variation of the
original tune. Variations are assessed by a domain-expert listener.
Additionally, we conduct a statistical analysis of mutation with different
representation setups for our parsing and generation algorithms. The
overarching conclusion is that the system successfully produces acceptable
variations post-mutation. While our case study focuses on Iranian classical
music, the methodology can be adapted for Arabic or Turkish classical music.

</details>


### [276] [Biological Processing Units: Leveraging an Insect Connectome to Pioneer Biofidelic Neural Architectures](https://arxiv.org/abs/2507.10951)
*Siyu Yu,Zihan Qin,Tingshan Liu,Beiya Xu,R. Jacob Vogelstein,Jason Brown,Joshua T. Vogelstein*

Main category: cs.NE

TL;DR: 果蝇大脑的连接组可以转化为生物处理单元（BPU），在MNIST和CIFAR-10等基准测试中表现出色，甚至优于尺寸匹配的机器学习模型。


<details>
  <summary>Details</summary>
Motivation: 探索生物进化的电路是否能够支持人工智能。

Method: 将果蝇幼虫大脑的完整连接组转换为生物处理单元（BPU），一个直接源于突触连接的固定递归网络。

Result: 尽管规模不大（3000个神经元和65000个连接），BPU在MNIST上达到了98%的准确率，在CIFAR-10上达到了58%，优于尺寸匹配的多层感知机（MLP）。通过结构化连接组扩展BPU可以进一步提高CIFAR-10的性能。模型在ChessBench数据集上取得了60%的走法准确率，优于尺寸相当的Transformer。CNN-BPU模型优于参数匹配的Transformer，并在推理时使用深度-6极小极大搜索，达到了91.7%的准确率。

Conclusion: 生物保真神经网络架构有潜力支持复杂的认知任务，未来的工作可以将其扩展到更大、更智能的连接组。

Abstract: The complete connectome of the Drosophila larva brain offers a unique
opportunity to investigate whether biologically evolved circuits can support
artificial intelligence. We convert this wiring diagram into a Biological
Processing Unit (BPU), a fixed recurrent network derived directly from synaptic
connectivity. Despite its modest size 3,000 neurons and 65,000 weights between
them), the unmodified BPU achieves 98% accuracy on MNIST and 58% on CIFAR-10,
surpassing size-matched MLPs. Scaling the BPU via structured connectome
expansions further improves CIFAR-10 performance, while modality-specific
ablations reveal the uneven contributions of different sensory subsystems. On
the ChessBench dataset, a lightweight GNN-BPU model trained on only 10,000
games achieves 60% move accuracy, nearly 10x better than any size transformer.
Moreover, CNN-BPU models with ~2M parameters outperform parameter-matched
Transformers, and with a depth-6 minimax search at inference, reach 91.7%
accuracy, exceeding even a 9M-parameter Transformer baseline. These results
demonstrate the potential of biofidelic neural architectures to support complex
cognitive tasks and motivate scaling to larger and more intelligent connectomes
in future work.

</details>


<div id='cs.SI'></div>

# cs.SI [[Back]](#toc)

### [277] [Local Clustering in Hypergraphs through Higher-Order Motifs](https://arxiv.org/abs/2507.10570)
*Giuseppe F. Italiano,Athanasios L. Konstantinidis,Anna Mpanti,Fariba Ranjbar*

Main category: cs.SI

TL;DR: 提出了一种新的超图局部聚类方法，利用高阶超图的结构来提高聚类质量和效率。


<details>
  <summary>Details</summary>
Motivation: 现有的图聚类方法主要关注成对关系，忽略了超图中存在的高阶交互，导致聚类结果不佳。

Method: 该方法基于高阶超图的局部聚类，通过高阶超图的特定结构来优化超图的基准，并提出两种策略：基于核心的的方法和基于BFS的方法。

Result: 在真实数据集上的广泛实验证明了该框架的有效性，并对两种提出的聚类策略在聚类质量和计算效率方面进行了比较分析。

Conclusion: 提出了一种基于高阶超图的局部聚类方法，通过利用高阶超图的特定结构来优化聚类质量和计算效率。

Abstract: Hypergraphs provide a powerful framework for modeling complex systems and
networks with higher-order interactions beyond simple pairwise relationships.
However, graph-based clustering approaches, which focus primarily on pairwise
relations, fail to represent higher-order interactions, often resulting in
low-quality clustering outcomes. In this work, we introduce a novel approach
for local clustering in hypergraphs based on higher-order motifs, small
connected subgraphs in which nodes may be linked by interactions of any order,
extending motif-based techniques previously applied to standard graphs. Our
method exploits hypergraph-specific higher-order motifs to better characterize
local structures and optimize motif conductance. We propose two alternative
strategies for identifying local clusters around a seed hyperedge: a core-based
method utilizing hypergraph core decomposition and a BFS-based method based on
breadth-first exploration. We construct an auxiliary hypergraph to facilitate
efficient partitioning and introduce a framework for local motif-based
clustering. Extensive experiments on real-world datasets demonstrate the
effectiveness of our framework and provide a comparative analysis of the two
proposed clustering strategies in terms of clustering quality and computational
efficiency.

</details>


### [278] [The Shape of Deceit: Behavioral Consistency and Fragility in Money Laundering Patterns](https://arxiv.org/abs/2507.10608)
*Danny Butvinik,Ofir Yakobi,Michal Einhorn Cohen,Elina Maliarsky*

Main category: cs.SI

TL;DR: 传统的反洗钱系统侧重于识别异常交易，但洗钱行为往往隐藏在常规模式中。本研究提出一种基于网络理论的方法，通过识别交易网络中的特定模式和行为一致性来检测洗钱，而非依赖异常值。


<details>
  <summary>Details</summary>
Motivation: 当前的AML系统主要关注异常实体或交易，但这种方法未能抓住洗钱活动真实、隐蔽且规律的本质。洗钱行为往往不是异常的，而是隐藏在常规行为模式中的。

Method: 提出了一种基于网络理论的视角，通过分析交易网络的子图结构来识别预定义的洗钱模式，并引入了“行为一致性”作为洗钱活动的核心特征，同时研究了模式的脆弱性和鲁棒性，以及基于行为本质的模式相似性概念。

Result: 该研究通过网络理论和行为一致性概念，为AML系统提供了一种新的检测洗钱活动的方法，有助于更准确地识别隐藏在常规交易网络中的洗钱模式，而非仅仅依赖于统计上的异常值。

Conclusion: 该研究提出了一种新的反洗钱（AML）系统范式，从传统的实体/交易层面转向基于网络理论的模式检测，强调行为一致性和子图结构来识别洗钱活动，而非仅仅依赖统计异常值。研究还探讨了模式的脆弱性和鲁棒性，主张检测应侧重于行为本质的保持，并提出了新的模式相似性概念。

Abstract: Conventional anti-money laundering (AML) systems predominantly focus on
identifying anomalous entities or transactions, flagging them for manual
investigation based on statistical deviation or suspicious behavior. This
paradigm, however, misconstrues the true nature of money laundering, which is
rarely anomalous but often deliberate, repeated, and concealed within
consistent behavioral routines. In this paper, we challenge the entity-centric
approach and propose a network-theoretic perspective that emphasizes detecting
predefined laundering patterns across directed transaction networks. We
introduce the notion of behavioral consistency as the core trait of laundering
activity, and argue that such patterns are better captured through subgraph
structures expressing semantic and functional roles - not solely geometry.
Crucially, we explore the concept of pattern fragility: the sensitivity of
laundering patterns to small attribute changes and, conversely, their semantic
robustness even under drastic topological transformations. We claim that
laundering detection should not hinge on statistical outliers, but on
preservation of behavioral essence, and propose a reconceptualization of
pattern similarity grounded in this insight. This philosophical and practical
shift has implications for how AML systems model, scan, and interpret networks
in the fight against financial crime.

</details>


### [279] [Multilayer Artificial Benchmark for Community Detection (mABCD)](https://arxiv.org/abs/2507.10795)
*Łukasz Kraiński,Michał Czuba,Piotr Bródka,Paweł Prałat,Bogumił Kamiński,François Théberge*

Main category: cs.SI

TL;DR: A new model called mABCD is introduced for multilayer networks, which is faster, more interpretable, and analytically tractable, building upon the ABCD model.


<details>
  <summary>Details</summary>
Motivation: The research aims to extend the capabilities of the ABCD model to multilayer networks, leveraging its advantages such as speed, interpretability, and analytical investigation.

Method: The study adapts the ABCD model, a random graph model with community structure and power-law distributions, to create a variant for multilayer networks named mABCD.

Result: The paper presents the mABCD model, a new model for multilayer networks that is based on the ABCD model and offers similar benefits.

Conclusion: The paper introduces mABCD, a variant of the ABCD model for multilayer networks, which is inspired by the ABCD model's strengths in speed, interpretability, and analytical tractability.

Abstract: The Artificial Benchmark for Community Detection (ABCD) model is a random
graph model with community structure and power-law distribution for both
degrees and community sizes. The model generates graphs similar to the
well-known LFR model but it is faster, more interpretable, and can be
investigated analytically. In this paper, we use the underlying ingredients of
the ABCD model and introduce its variant for multilayer networks, mABCD.

</details>


### [280] [Toxicity in State Sponsored Information Operations](https://arxiv.org/abs/2507.10936)
*Ashfaq Ali Shafin,Khandaker Mamun Ahmed*

Main category: cs.SI

TL;DR: This study analyzes toxic language in state-sponsored information operations on X/Twitter, finding it's strategically used and drives high engagement, especially from Russian operations.


<details>
  <summary>Details</summary>
Motivation: To comprehensively analyze the emotional and rhetorical strategies, specifically toxic language, employed in state-sponsored information operations on social media platforms, which is inadequately characterized in scientific literature.

Method: Analyzed 56 million posts from over 42 thousand accounts linked to 18 geopolitical entities on X/Twitter using Google's Perspective API to detect and quantify six categories of toxic content.

Result: Toxic content constitutes 1.53% of all posts but is associated with disproportionately high engagement and is strategically deployed. Russian influence operations' toxic content receives significantly higher user engagement compared to other countries.

Conclusion: State-sponsored information operations increasingly use toxic language, with Russian operations showing disproportionately high engagement.

Abstract: State-sponsored information operations (IOs) increasingly influence global
discourse on social media platforms, yet their emotional and rhetorical
strategies remain inadequately characterized in scientific literature. This
study presents the first comprehensive analysis of toxic language deployment
within such campaigns, examining 56 million posts from over 42 thousand
accounts linked to 18 distinct geopolitical entities on X/Twitter. Using
Google's Perspective API, we systematically detect and quantify six categories
of toxic content and analyze their distribution across national origins,
linguistic structures, and engagement metrics, providing essential information
regarding the underlying patterns of such operations. Our findings reveal that
while toxic content constitutes only 1.53% of all posts, they are associated
with disproportionately high engagement and appear to be strategically deployed
in specific geopolitical contexts. Notably, toxic content originating from
Russian influence operations receives significantly higher user engagement
compared to influence operations from any other country in our dataset. Our
code is available at https://github.com/shafin191/Toxic_IO.

</details>


### [281] [Urban delineation through the lens of commute networks: Leveraging graph embeddings to distinguish socioeconomic groups in cities](https://arxiv.org/abs/2507.11057)
*Devashish Khulbe,Stanislav Sobolevsky*

Main category: cs.SI

TL;DR: 本研究利用图神经网络（GNN）分析通勤网络，以界定城市区域并识别社区，有效揭示了社会经济差异。


<details>
  <summary>Details</summary>
Motivation: 为了解决城市研究中区分都市区内部区域以理解由人口动态变化的城市边界的重要性，并应用于城市科学，如促进已划分区域与行政区划的比较，以及为政策制定者提供变化的经济和劳动力状况信息。

Method: 本研究提出使用源自人口普查的通勤网络，并利用图神经网络（GNN）架构对其进行建模。首先，使用GNN生成城市区域（节点）的低维表示；随后，对节点的嵌入进行聚类，以识别城市中空间上内聚的社区。

Result: 实验结果表明，网络嵌入能够有效捕捉不同城市社区之间显著的社会经济差异，特别是在家庭收入中位数等因素上。研究还强调了人口普查流动性数据在区域划分中的作用，并确立了GNN在城市社区检测中的效用，是该领域现有方法的有力替代。

Conclusion: 该研究证明了基于GNN的通勤网络分析在城市区域划分中的有效性，为理解城市结构和社会经济差异提供了新方法。

Abstract: Delineating areas within metropolitan regions stands as an important focus
among urban researchers, shedding light on the urban perimeters shaped by
evolving population dynamics. Applications to urban science are numerous, from
facilitating comparisons between delineated districts and administrative
divisions to informing policymakers of the shifting economic and labor
landscapes. In this study, we propose using commute networks sourced from the
census for the purpose of urban delineation, by modeling them with a Graph
Neural Network (GNN) architecture. We derive low-dimensional representations of
granular urban areas (nodes) using GNNs. Subsequently, nodes' embeddings are
clustered to identify spatially cohesive communities in urban areas. Our
experiments across the U.S. demonstrate the effectiveness of network embeddings
in capturing significant socioeconomic disparities between communities in
various cities, particularly in factors such as median household income. The
role of census mobility data in regional delineation is also noted, and we
establish the utility of GNNs in urban community detection, as a powerful
alternative to existing methods in this domain. The results offer insights into
the wider effects of commute networks and their use in building meaningful
representations of urban regions.

</details>


### [282] [Enhance Stability of Network by Edge Anchor](https://arxiv.org/abs/2507.11090)
*Hongbo Qiu,Renjie Sun,Chen chen,Xiaoyang Wang*

Main category: cs.SI

TL;DR: 通过锚定关键边来提升社交网络稳定性和用户参与度，并提出了一种解决此NP难问题的有效算法。


<details>
  <summary>Details</summary>
Motivation: 随着在线社交网络的快速发展，增强其稳定性成为研究的焦点。本研究旨在识别对社区稳定性有显著影响的关键关系，并提出通过锚定关键边来提升网络整体用户参与度的策略。

Method: 提出了一种名为“锚定约束加强”的新问题，旨在通过锚定一部分边来提升图的整体韧性。该问题被证明是NP难的。为了解决这个问题，研究引入了一个迭代式的贪心框架，并在其中设计了向上路由方法、支持检查策略和分类树结构，以优化计算效率和扩展性。

Result: 实验结果表明，该方法能够有效地提升网络的韧性，并且在处理大规模网络时具有良好的效率。

Conclusion: 本研究提出的基于锚定边选择的加强图韧性方法在真实网络上的实验结果验证了其效率和有效性。

Abstract: With the rapid growth of online social networks, strengthening their
stability has emerged as a key research focus. This study aims to identify
influential relationships that significantly impact community stability. In
this paper, we introduce and explore the anchor trussness reinforcement problem
to reinforce the overall user engagement of networks by anchoring some edges.
Specifically, for a given graph $G$ and a budget $b$, we aim to identify $b$
edges whose anchoring maximizes the trussness gain, which is the cumulative
increment of trussness across all edges in $G$. We establish the NP-hardness of
the problem. To address this problem, we introduce a greedy framework that
iteratively selects the current best edge. To scale for larger networks, we
first propose an upward-route method to constrain potential trussness increment
edges. Augmented with a support check strategy, this approach enables the
efficient computation of the trussness gain for anchoring one edge. Then, we
design a classification tree structure to minimize redundant computations in
each iteration by organizing edges based on their trussness. We conduct
extensive experiments on 8 real-world networks to validate the efficiency and
effectiveness of the proposed model and methods.

</details>


<div id='cs.DS'></div>

# cs.DS [[Back]](#toc)

### [283] [A Fast Coloring Oracle for Average Case Hypergraphs](https://arxiv.org/abs/2507.10691)
*Cassandra Marcussen,Edward Pyne,Ronitt Rubinfeld,Asaf Shapira,Shlomo Tauber*

Main category: cs.DS

TL;DR: 该研究提出了一种新的、更简单的超图2着色算法，比现有方法更优，并提供了一个接近理想的着色预言机。


<details>
  <summary>Details</summary>
Motivation: 该研究旨在解决NP难问题——超图2着色问题。现有的算法依赖于正则性引理，分析复杂且运行时间常数巨大。因此，研究者希望找到一种更简单、更有效的算法。

Method: 该研究提出了一种新的简单且基础的确定性2-染色算法，并将其转化为一个随机化算法。此外，研究还定义了一个着色预言机，并证明了其平均查询时间为O(1)。

Result: 该研究提出了一种新的确定性2-染色算法，该算法能够重新证明Person-Schacht和Lee-Molla-Nagle定理，并且避免使用正则性引理。同时，该算法还可以转化为一个随机化算法，其平均期望运行时间为O(n)。研究还证明了一个着色预言机，该预言机平均可以在O(1)时间内回答每个顶点着色查询，并且保持一致性。

Conclusion: 该研究提出了一个简单且基础的确定性2-染色算法，该算法可以重新证明Person-Schacht和Lee-Molla-Nagle定理，并且避免了使用正则性引理。此外，研究还将该算法转化为一个随机化算法，其平均期望运行时间仅为O(n)。研究的第二个主要成果是提出了一个着色预言机，该预言机可以在O(1)的平均时间内为每个顶点着色，并且确保所有着色查询都与一个合法的2-染色一致。

Abstract: Hypergraph $2$-colorability is one of the classical NP-hard problems. Person
and Schacht [SODA'09] designed a deterministic algorithm whose expected running
time is polynomial over a uniformly chosen $2$-colorable $3$-uniform
hypergraph. Lee, Molla, and Nagle recently extended this to $k$-uniform
hypergraphs for all $k\geq 3$. Both papers relied heavily on the regularity
lemma, hence their analysis was involved and their running time hid tower-type
constants.
  Our first result in this paper is a new simple and elementary deterministic
$2$-coloring algorithm that reproves the theorems of Person-Schacht and
Lee-Molla-Nagle while avoiding the use of the regularity lemma. We also show
how to turn our new algorithm into a randomized one with average expected
running time of only $O(n)$.
  Our second and main result gives what we consider to be the ultimate evidence
of just how easy it is to find a $2$-coloring of an average $2$-colorable
hypergraph. We define a coloring oracle to be an algorithm which, given vertex
$v$, assigns color red/blue to $v$ while inspecting as few edges as possible,
so that the answers to any sequence of queries to the oracle are consistent
with a single legal $2$-coloring of the input. Surprisingly, we show that there
is a coloring oracle that, on average, can answer every vertex query in time
$O(1)$.

</details>


### [284] [Solving Random Planted CSPs below the $n^{k/2}$ Threshold](https://arxiv.org/abs/2507.10833)
*Arpon Basu,Jun-Ting Hsieh,Andrew D. Lin,Peter Manohar*

Main category: cs.DS

TL;DR: 本文提出了一种解决k元布尔CSP随机planted实例的算法，该算法在特定约束数量下，能在n^O(l)时间内找到满足赋值，并与现有算法进行了比较。


<details>
  <summary>Details</summary>
Motivation: 解决k元布尔约束满足问题（CSP）的随机planted实例，并与现有算法进行对比和泛化。

Method: 本文提出了一系列算法来解决k元布尔约束满足问题（CSP）的随机planted实例。具体来说，算法首先使用一个度为O(l)的Sum-of-Squares SDP找到一个近似解	ilde{x}，该解与planted赋值x*的差距为o(1)，然后使用第二个舍入过程从	ilde{x}中恢复出x*。

Result: 当约束数量m满足m >= O(n) * (n/l)^((k/2)-1) log n时，算法可以在n^O(l)时间内成功找到满足的赋值。

Conclusion: 该算法在满足特定约束数量的条件下，能够成功找出满足的赋值。

Abstract: We present a family of algorithms to solve random planted instances of any
$k$-ary Boolean constraint satisfaction problem (CSP). A randomly planted
instance of a Boolean CSP is generated by (1) choosing an arbitrary planted
assignment $x^*$, and then (2) sampling constraints from a particular "planting
distribution" designed so that $x^*$ will satisfy every constraint. Given an
$n$ variable instance of a $k$-ary Boolean CSP with $m$ constraints, our
algorithm runs in time $n^{O(\ell)}$ for a choice of a parameter $\ell$, and
succeeds in outputting a satisfying assignment if $m \geq O(n) \cdot
(n/\ell)^{\frac{k}{2} - 1} \log n$. This generalizes the
$\mathrm{poly}(n)$-time algorithm of [FPV15], the case of $\ell = O(1)$, to
larger runtimes, and matches the constraint number vs.\ runtime trade-off
established for refuting random CSPs by [RRS17].
  Our algorithm is conceptually different from the recent algorithm of
[GHKM23], which gave a $\mathrm{poly}(n)$-time algorithm to solve semirandom
CSPs with $m \geq \tilde{O}(n^{\frac{k}{2}})$ constraints by exploiting
conditions that allow a basic SDP to recover the planted assignment $x^*$
exactly. Instead, we forego certificates of uniqueness and recover $x^*$ in two
steps: we first use a degree-$O(\ell)$ Sum-of-Squares SDP to find some
$\hat{x}$ that is $o(1)$-close to $x^*$, and then we use a second rounding
procedure to recover $x^*$ from $\hat{x}$.

</details>


### [285] [Solving Linear Programs with Differential Privacy](https://arxiv.org/abs/2507.10946)
*Alina Ene,Huy Le Nguyen,Ta Duy Nguyen,Adrian Vladu*

Main category: cs.DS

TL;DR: This paper presents differentially private algorithms for linear programming that significantly outperform previous methods in terms of accuracy and efficiency, especially for general LP problems.


<details>
  <summary>Details</summary>
Motivation: The paper addresses the challenge of solving linear programs (LPs) under differential privacy constraints, aiming to improve the efficiency and accuracy of private solutions compared to prior work.

Method: We adapt and improve upon existing algorithms, specifically a rescaling perceptron algorithm and an iterative procedure for identifying equality constraints, to achieve differential privacy for linear programming.

Result: For homogeneous LPs, we achieve an improved bound on the number of violated constraints. For general LPs, our algorithm offers a substantial improvement (at least a factor of d^5) over the previous best results in terms of the number of dropped constraints.

Conclusion: Our algorithms provide efficient differentially private solutions for linear programs, improving upon existing bounds by significant factors for both homogeneous and general cases.

Abstract: We study the problem of solving linear programs of the form $Ax\le b$,
$x\ge0$ with differential privacy. For homogeneous LPs $Ax\ge0$, we give an
efficient $(\epsilon,\delta)$-differentially private algorithm which with
probability at least $1-\beta$ finds in polynomial time a solution that
satisfies all but
$O(\frac{d^{2}}{\epsilon}\log^{2}\frac{d}{\delta\beta}\sqrt{\log\frac{1}{\rho_{0}}})$
constraints, for problems with margin $\rho_{0}>0$. This improves the bound of
$O(\frac{d^{5}}{\epsilon}\log^{1.5}\frac{1}{\rho_{0}}\mathrm{poly}\log(d,\frac{1}{\delta},\frac{1}{\beta}))$
by [Kaplan-Mansour-Moran-Stemmer-Tur, STOC '25]. For general LPs $Ax\le b$,
$x\ge0$ with potentially zero margin, we give an efficient
$(\epsilon,\delta)$-differentially private algorithm that w.h.p drops
$O(\frac{d^{4}}{\epsilon}\log^{2.5}\frac{d}{\delta}\sqrt{\log dU})$
constraints, where $U$ is an upper bound for the entries of $A$ and $b$ in
absolute value. This improves the result by Kaplan et al. by at least a factor
of $d^{5}$. Our techniques build upon privatizing a rescaling perceptron
algorithm by [Hoberg-Rothvoss, IPCO '17] and a more refined iterative procedure
for identifying equality constraints by Kaplan et al.

</details>


### [286] [FPT Parameterisations of Fractional and Generalised Hypertree Width](https://arxiv.org/abs/2507.11080)
*Matthias Lanzinger,Igor Razgon,Daniel Unterberger*

Main category: cs.DS

TL;DR: Introduced the first FPT algorithms for key hypergraph decomposition parameters (generalized hypertree width, fractional hypertree width, adaptive width) using MSO transductions, applicable to bounded rank/degree hypergraphs.


<details>
  <summary>Details</summary>
Motivation: To provide the first exact fpt algorithms for important hypergraph decomposition parameters that have recognized importance in complexity theory, databases, and constraint satisfaction.

Method: The approach extends a recent treewidth algorithm using monadic second-order (MSO) transductions, overcoming technical challenges specific to hypergraphs.

Result: Successfully developed and presented the first fpt algorithms for generalized hypertree width, fractional hypertree width, and adaptive width in hypergraphs.

Conclusion: The paper presents the first fixed-parameter tractable (fpt) algorithms for determining central hypergraph decomposition parameters like generalized hypertree width, fractional hypertree width, and adaptive width. These algorithms apply to hypergraph classes with bounded rank and degree.

Abstract: We present the first fixed-parameter tractable (fpt) algorithms for precisely
determining several central hypergraph decomposition parameters, including
generalized hypertree width, fractional hypertree width, and adaptive width.
Despite the recognized importance of these measures in complexity theory,
databases, and constraint satisfaction, no exact fpt algorithms for any of them
had previously been known. Our results are obtained for hypergraph classes of
bounded rank and bounded degree.
  Our approach extends a recent algorithm for treewidth (Boja\'ncyk &
Pilipczuk, LMCS 2022) utilizing monadic second-order (MSO) transductions.
Leveraging this framework, we overcome the significant technical hurdles
presented by hypergraphs, whose structural decompositions are technically much
more intricate than their graph counterparts.

</details>


### [287] [Faster algorithms for k-Orthogonal Vectors in low dimension](https://arxiv.org/abs/2507.11098)
*Anita Dürr,Evangelos Kipouridis,Karol Węgrzycki*

Main category: cs.DS

TL;DR: 该研究提出了一个组合算法，以随机化时间 $\tilde{\mathcal{O}}(1.25^d n)$ 解决了 $k$-正交向量问题，该算法通过计算机辅助评估可进一步优化至 $\mathcal{O}(1.16^d \cdot n)$。研究结果对于 $k \ge 2$ 时的 $k$-正交向量问题提供了最佳时间复杂度，并与集合覆盖猜想相关。


<details>
  <summary>Details</summary>
Motivation: 该研究旨在解决正交向量（OV）问题及其推广形式 $k$-正交向量问题，并寻求比现有算法更优的时间复杂度。

Method: 该研究提出了一个组合算法，该算法能够以随机化时间 $\tilde{\mathcal{O}}(1.25^d n)$ 解决 $k$-正交向量问题，通过计算机辅助评估可进一步优化至 $\mathcal{O}(1.16^d \cdot n)$。

Result: 研究提出了一个组合算法，以随机化时间 $\tilde{\mathcal{O}}(1.25^d n)$ 解决了 $k$-正交向量问题，并提出通过计算机辅助评估可进一步优化至 $\mathcal{O}(1.16^d \cdot n)$。对于 $k \ge 2$，证明了 $k$-正交向量问题可以在 $\mathcal{O}(2^{(1 - \varepsilon_k)\cdot d}\cdot n)$ 时间内解决，并指出该结果在渐近意义上是最佳的，与集合覆盖猜想相悖。

Conclusion: 该研究提出了一个组合算法，能够以随机化时间 $	ilde{\mathcal{O}}(1.25^d n)$ 解决 $k$-正交向量问题，并能通过计算机辅助评估进一步优化至 $\mathcal{O}(1.16^d \cdot n)$。研究结果表明，对于每个固定的 $k \ge 2$，存在 $\varepsilon_k > 0$，使得 $k$-正交向量问题可以在 $\mathcal{O}(2^{(1 - \varepsilon_k)\cdot d}\cdot n)$ 时间内解决，这在渐近意义上是目前最好的结果，并与集合覆盖猜想相悖。

Abstract: In the Orthogonal Vectors problem (OV), we are given two families $A, B$ of
subsets of $\{1,\ldots,d\}$, each of size $n$, and the task is to decide
whether there exists a pair $a \in A$ and $b \in B$ such that $a \cap b =
\emptyset$. Straightforward algorithms for this problem run in $\mathcal{O}(n^2
\cdot d)$ or $\mathcal{O}(2^d \cdot n)$ time, and assuming SETH, there is no
$2^{o(d)}\cdot n^{2-\varepsilon}$ time algorithm that solves this problem for
any constant $\varepsilon > 0$.
  Williams (FOCS 2024) presented a $\tilde{\mathcal{O}}(1.35^d \cdot n)$-time
algorithm for the problem, based on the succinct equality-rank decomposition of
the disjointness matrix. In this paper, we present a combinatorial algorithm
that runs in randomized time $\tilde{\mathcal{O}}(1.25^d n)$. This can be
improved to $\mathcal{O}(1.16^d \cdot n)$ using computer-aided evaluations.
  We generalize our result to the $k$-Orthogonal Vectors problem, where given
$k$ families $A_1,\ldots,A_k$ of subsets of $\{1,\ldots,d\}$, each of size $n$,
the task is to find elements $a_i \in A_i$ for every $i \in \{1,\ldots,k\}$
such that $a_1 \cap a_2 \cap \ldots \cap a_k = \emptyset$. We show that for
every fixed $k \ge 2$, there exists $\varepsilon_k > 0$ such that the $k$-OV
problem can be solved in time $\mathcal{O}(2^{(1 - \varepsilon_k)\cdot d}\cdot
n)$. We also show that, asymptotically, this is the best we can hope for: for
any $\varepsilon > 0$ there exists a $k \ge 2$ such that $2^{(1 -
\varepsilon)\cdot d} \cdot n^{\mathcal{O}(1)}$ time algorithm for
$k$-Orthogonal Vectors would contradict the Set Cover Conjecture.

</details>


### [288] [Efficient Branch-and-Bound for Submodular Function Maximization under Knapsack Constraint](https://arxiv.org/abs/2507.11107)
*Yimin Hao,Yi Zhou,Chao Xu,Zhang-Hua Fu*

Main category: cs.DS

TL;DR: 针对次模背包问题（SKP），提出了一种新的最优分支定界算法，在保证解最优性的同时，提高了计算效率。


<details>
  <summary>Details</summary>
Motivation: 为了解决次模背包问题（SKP）的优化解问题，该问题在医疗保健设施选址和风险管理等领域至关重要，需要使用精确算法而非近似算法。

Method: 提出了一种最优分支定界方法，并引入了具有最差情况严格性保证的新型上界和一种有效的对偶分支方法以减少重复计算。

Result: 实验表明，采用该新方法的算法效率远高于传统方法。

Conclusion: 该分支定界方法在设施选址、加权覆盖、影响力最大化等应用中，比传统方法更有效。

Abstract: The submodular knapsack problem (SKP), which seeks to maximize a submodular
set function by selecting a subset of elements within a given budget, is an
important discrete optimization problem. The majority of existing approaches to
solving the SKP are approximation algorithms. However, in domains such as
health-care facility location and risk management, the need for optimal
solutions is still critical, necessitating the use of exact algorithms over
approximation methods. In this paper, we present an optimal branch-and-bound
approach, featuring a novel upper bound with a worst-case tightness guarantee
and an efficient dual branching method to minimize repeat computations.
Experiments in applications such as facility location, weighted coverage,
influence maximization, and so on show that the algorithms that implement the
new ideas are far more efficient than conventional methods.

</details>


### [289] [Finding Order-Preserving Subgraphs](https://arxiv.org/abs/2507.11115)
*Haruya Imamura,Yasuaki Kobayashi,Yota Otachi,Toshiki Saitoh,Keita Sato,Asahi Takaoka,Ryo Yoshinaka*

Main category: cs.DS

TL;DR: 本研究探讨了在考虑顶点排序的情况下，子图同构和最大公共子图问题的计算复杂性。研究发现，即使在深度为2的树和阈值图等受限图类中，这些问题（特别是OISI）仍然是NP完全的。此外，问题可解性取决于具体的顶点排序方式，某些排序方式可以使问题变得容易处理（如MCOIS在特定排序下的多项式解法）。


<details>
  <summary>Details</summary>
Motivation: 由于时间序列数据或蛋白质结构等图数据中通常存在自然的顶点全序关系（如时间序列或氨基酸序列），研究有序（诱导）子图同构（O(I)SI）和最大公共有序（诱导）子图（MCO(I)S）问题，即在寻找子图同构时要保持顶点排序，具有重要的实际意义。这促使研究者们去探索和理解这些问题在不同图类和不同顶点排序下的计算复杂性。

Method: 该研究通过理论分析和证明，研究了有序（诱导）子图同构（O(I)SI）和最大公共有序（诱导）子图（MCO(I)S）的计算复杂性。具体来说，研究者们证明了这些问题在特定图类（如深度为2的树和阈值图）上的NP完全性，并分析了不同顶点排序对问题可处理性的影响，揭示了OSI和OISI在计算复杂性上的差异。

Result: 研究的主要成果包括：1. 证明了在深度为2的树和阈值图等特定图类上，O(I)SI和MCO(I)S问题仍然是NP完全的。2. 揭示了OSI和OISI在某些图类上的计算复杂性差异，例如，OSI在区间图的区间排序下是多项式可解的，而OISI在此设置下仍然是NP完全的。3. 论证了这些问题的可处理性可能依赖于顶点排序，例如，MCOIS在给定阈值图的特定顶点排序时是多项式可解的，尽管OISI本身在阈值图上是NP完全的。

Conclusion: 该研究证明了有序（诱导）子图同构（O(I)SI）及其泛化问题最大公共有序（诱导）子图（MCO(I)S）在某些图类（如深度为2的树和阈值图）上仍然是NP完全问题，即使在这些限制条件下也是如此。研究还揭示了OSI和OISI在计算复杂性上的差异，例如OSI在区间图的区间排序下是多项式可解的，而OISI仍然是NP完全的。此外，研究表明这些问题的可处理性可能取决于顶点排序，例如，虽然OISI在阈值图上是NP完全的，但其泛化问题MCOIS在给定特定顶点排序时可以在多项式时间内解决。

Abstract: (Induced) Subgraph Isomorphism and Maximum Common (Induced) Subgraph are
fundamental problems in graph pattern matching and similarity computation. In
graphs derived from time-series data or protein structures, a natural total
ordering of vertices often arises from their underlying structure, such as
temporal sequences or amino acid sequences. This motivates the study of problem
variants that respect this inherent ordering. This paper addresses Ordered
(Induced) Subgraph Isomorphism (O(I)SI) and its generalization, Maximum Common
Ordered (Induced) Subgraph (MCO(I)S), which seek to find subgraph isomorphisms
that preserve the vertex orderings of two given ordered graphs. Our main
contributions are threefold: (1) We prove that these problems remain
NP-complete even when restricted to small graph classes, such as trees of depth
2 and threshold graphs. (2) We establish a gap in computational complexity
between OSI and OISI on certain graph classes. For instance, OSI is
polynomial-time solvable for interval graphs with their interval orderings,
whereas OISI remains NP-complete under the same setting. (3) We demonstrate
that the tractability of these problems can depend on the vertex ordering. For
example, while OISI is NP-complete on threshold graphs, its generalization,
MCOIS, can be solved in polynomial time if the specific vertex orderings that
characterize the threshold graphs are provided.

</details>


### [290] [Improved sampling algorithms and Poincaré inequalities for non-log-concave distributions](https://arxiv.org/abs/2507.11236)
*Yuchen He,Zhehan Lei,Jianan Shao,Chihao Zhang*

Main category: cs.DS

TL;DR: 研究改进了从特定分布采样的算法，发现更强的平滑性条件能指数级降低采样复杂度。在特定条件下，新算法复杂度为多项式，优于现有算法，并改进了庞加莱常数估计。


<details>
  <summary>Details</summary>
Motivation: 该研究的动机是探索更强的平滑性条件（1*）如何影响从分布 $\\\mu$（密度为 $e^{-V}$）采样的查询复杂度。研究人员发现，相比于仅满足标准平滑性条件（1）的采样算法，满足（1*）的算法可以获得显著的查询复杂度提升，从而改进了现有的准多项式时间采样算法。

Method: 本研究提出了在(1*)（所有 Ornstein-Uhlenbeck 过程中的分布都具有 L-平滑性）和(2)（二阶矩有界）假设下，从分布 $\\\mu$（密度为 $e^{-V}$）采样的算法。该算法的查询复杂度为 $\mathrm{poly}(L,d) \cdot \left(rac{Ld+M}{\epsilon^2}\right)^{\mathcal{O}(L+1)}$，当 L=O(1) 且 M=poly(d) 时，复杂度关于 d 和 $1/\epsilon$ 是多项式的。

Result: 在假设 (1*) 和 (2) 下，我们证明了采样复杂度可以达到 $\mathrm{poly}(L,d) \cdot \left(rac{Ld+M}{\epsilon^2}\right)^{\mathcal{O}(L+1)}$，这在 L=O(1) 和 M=poly(d) 时，相对于 d 和 $1/\epsilon$ 是多项式的，优于现有的准多项式时间算法。此外，我们还证明了在 (1*) 和 $\\\lambda$-次高斯假设下，庞加莱常数最多为 $O(\\lambda)^{2(L+1)}$，并将其应用于混合高斯分布的庞加莱常数估计。

Conclusion: 该研究表明，将平滑性条件从(1)增强到(1*)可以使采样算法的查询复杂度产生指数级差距。此外，在(1*)和$\|X\|$是 $\lambda$-次高斯分布的假设下，$\\\mu$ 的庞加莱常数最多为 $O(\\lambda)^{2(L+1)}$。作为该技术的一个应用，我们获得了混合高斯分布（具有相同协方差）的庞加莱常数的改进估计。

Abstract: We study the problem of sampling from a distribution $\mu$ with density
$\propto e^{-V}$ for some potential function $V:\mathbb R^d\to \mathbb R$ with
query access to $V$ and $\nabla V$. We start with the following standard
assumptions:
  (1) The potential function $V$ is $L$-smooth.
  (2) The second moment $\mathbf{E}_{X\sim \mu}[\|X\|^2]\leq M$.
  Recently, He and Zhang (COLT'25) showed that the query complexity of sampling
from such distributions is at least
$\left(\frac{LM}{d\epsilon}\right)^{\Omega(d)}$ where $\epsilon$ is the desired
accuracy in total variation distance, and the Poincar\'e constant can be
arbitrarily large.
  Meanwhile, another common assumption in the study of diffusion based samplers
(see e.g., the work of Chen, Chewi, Li, Li, Salim and Zhang (ICLR'23))
strengthens the smoothness condition (1) to the following:
  (1*) The potential function of *every* distribution along the
Ornstein-Uhlenbeck process starting from $\mu$ is $L$-smooth.
  We show that under the assumptions (1*) and (2), the query complexity of
sampling from $\mu$ can be $\mathrm{poly}(L,d)\cdot
\left(\frac{Ld+M}{\epsilon^2}\right)^{\mathcal{O}(L+1)}$, which is polynomial
in $d$ and $\frac{1}{\epsilon}$ when $L=\mathcal{O}(1)$ and
$M=\mathrm{poly}(d)$. This improves the algorithm with quasi-polynomial query
complexity developed by Huang et al. (COLT'24). Our results imply that the
seemly moderate strengthening of the smoothness condition (1) to (1*) can lead
to an exponential gap in the query complexity of sampling algorithms.
  Moreover, we show that together with the assumption (1*) and the stronger
moment assumption that $\|X\|$ is $\lambda$-sub-Gaussian for $X\sim\mu$, the
Poincar\'e constant of $\mu$ is at most $\mathcal{O}(\lambda)^{2(L+1)}$. As an
application of our technique, we obtain improved estimate of the Poincar\'e
constant for mixture of Gaussians with the same covariance.

</details>


### [291] [Fully Dynamic Euclidean k-Means](https://arxiv.org/abs/2507.11256)
*Sayan Bhattacharya,Martín Costa,Ermiya Farokhnejad,Shaofeng H. -C. Jiang,Yaonan Jin,Jianing Lou*

Main category: cs.DS

TL;DR: 针对动态欧氏k-均值聚类问题，提出了一种具有近乎最优近似比、更新时间和追索性的新算法。


<details>
  <summary>Details</summary>
Motivation: 在动态环境中解决欧氏k-均值聚类问题，该环境中的输入点会随着时间的推移通过插入/删除而演变，同时最小化近似比、更新时间和追索性。

Method: 通过利用最近关于度量空间k-均值聚类问题的动态算法的工作，并结合新颖的几何数据结构，特别是第一个实现多项式时间每点评估的相容哈希方案，来解决欧氏k-均值聚类问题。

Result: 提出了一个动态算法，具有多项式（1/ε）的近似比、近乎最优的（~O(k^ε)）更新时间以及近乎最优的（~O(1)）追索性。

Conclusion: 该算法在通用环境中提供了近乎最优的保证，几乎涵盖了所有三个参数（近似比、更新时间和追索性）。

Abstract: We consider the fundamental Euclidean $k$-means clustering problem in a
dynamic setting, where the input $X \subseteq \mathbb{R}^d$ evolves over time
via a sequence of point insertions/deletions. We have to explicitly maintain a
solution (a set of $k$ centers) $S \subseteq \mathbb{R}^d$ throughout these
updates, while minimizing the approximation ratio, the update time (time taken
to handle a point insertion/deletion) and the recourse (number of changes made
to the solution $S$) of the algorithm.
  We present a dynamic algorithm for this problem with
$\text{poly}(1/\epsilon)$-approximation ratio, $\tilde{O}(k^{\epsilon})$ update
time and $\tilde{O}(1)$ recourse. In the general regime, where the dimension
$d$ cannot be assumed to be a fixed constant, our algorithm has almost optimal
guarantees across all these three parameters. Indeed, improving our update time
or approximation ratio would imply beating the state-of-the-art static
algorithm for this problem (which is widely believed to be the best possible),
and the recourse of any dynamic algorithm must be $\Omega(1)$.
  We obtain our result by building on top of the recent work of [Bhattacharya,
Costa, Farokhnejad; STOC'25], which gave a near-optimal dynamic algorithm for
$k$-means in general metric spaces (as opposed to in the Euclidean setting).
Along the way, we design several novel geometric data structures that are of
independent interest. Specifically, one of our main contributions is designing
the first consistent hashing scheme [Czumaj, Jiang, Krauthgamer, Vesel\'y,
Yang; FOCS'22] that achieves $\text{poly}(d)$ running time per point evaluation
with competitive parameters.

</details>


### [292] [Deterministic Lower Bounds for $k$-Edge Connectivity in the Distributed Sketching Model](https://arxiv.org/abs/2507.11257)
*Peter Robinson,Ming Ming Tan*

Main category: cs.DS

TL;DR: 该研究首次在分布式图描摹模型中为 k 边连通性问题提供了确定性算法的下界，证明了最坏情况消息长度至少为 $\Omega(k)$ 比特。


<details>
  <summary>Details</summary>
Motivation: 在分布式图描摹模型中，为图连通性问题（特别是 k 边连通性）提供确定性算法的第一个下界，并克服了先前研究中仅限于 1 边连通性的对数级下界。

Method: 通过引入新的图构造和三方通信复杂性问题 UniqueOverlap 来证明下界，并利用交叉相交集族的结果来证明 UniqueOverlap 的确定性算法的难点，最后通过新的模拟论证获得 k 边连通性的下界。

Result: 在分布式图描摹模型中，为 k 边连通性问题（适用于 $k = O(\sqrt{n})$）提供了第一个确定性算法下界，即最坏情况消息长度为 $\Omega(k)$ 比特。

Conclusion: 提出了一种新的确定性算法，用于在分布式图描摹模型中决定 k 边连通性，其最坏情况消息长度为 $\Omega(k)$ 比特，适用于 $k = O(\sqrt{n})$ 的情况。

Abstract: We study the $k$-edge connectivity problem on undirected graphs in the
distributed sketching model, where we have $n$ nodes and a referee. Each node
sends a single message to the referee based on its 1-hop neighborhood in the
graph, and the referee must decide whether the graph is $k$-edge connected by
taking into account the received messages.
  We present the first lower bound for deciding a graph connectivity problem in
this model with a deterministic algorithm. Concretely, we show that the worst
case message length is $\Omega( k )$ bits for $k$-edge connectivity, for any
super-constant $k = O(\sqrt{n})$. Previously, only a lower bound of $\Omega(
\log^3 n )$ bits was known for ($1$-edge) connectivity, due to Yu (SODA 2021).
In fact, our result is the first super-polylogarithmic lower bound for a
connectivity decision problem in the distributed graph sketching model.
  To obtain our result, we introduce a new lower bound graph construction, as
well as a new 3-party communication complexity problem that we call
UniqueOverlap. As this problem does not appear to be amenable to reductions to
existing hard problems such as set disjointness or indexing due to correlations
between the inputs of the three players, we leverage results from
cross-intersecting set families to prove the hardness of UniqueOverlap for
deterministic algorithms. Finally, we obtain the sought lower bound for
deciding $k$-edge connectivity via a novel simulation argument that, in
contrast to previous works, does not introduce any probability of error and
thus works for deterministic algorithms.

</details>


### [293] [On Tight Robust Coresets for $k$-Medians Clustering](https://arxiv.org/abs/2507.11260)
*Lingxiao Huang,Zhenyu Jiang,Yi Li,Xuan Wu*

Main category: cs.DS

TL;DR: 本文为鲁棒k-中位数问题在各种度量空间中提供了新的Coreset构造，并在VC和双维度空间中实现了接近最优的大小。


<details>
  <summary>Details</summary>
Motivation: 该研究旨在解决鲁棒k-中位数问题，为具有m个异常值的聚类问题提供更有效的Coreset解决方案。

Method: 该研究通过新的数据集分解技术，结合链接论证，实现了Coreset的构造，并将其扩展到鲁棒(k,z)-聚类问题。

Result: 在VC或双维度d的度量空间中，Coreset大小为O(m) + 	ilde{O}(kdes^{-2})；在欧氏空间中，Coreset大小为O(mes^{-1}) + 	ilde{O}(is{k^{4/3}es^{-2}, kes^{-3}})。这些结果优于现有研究。

Conclusion: 该研究为鲁棒k-中位数问题提供了新的Coreset构造，并在多种度量空间中实现了最优或接近最优的Coreset大小。

Abstract: This paper considers coresets for the robust $k$-medians problem with $m$
outliers, and new constructions in various metric spaces are obtained.
Specifically, for metric spaces with a bounded VC or doubling dimension $d$,
the coreset size is $O(m) + \tilde{O}(kd\varepsilon^{-2})$, which is optimal up
to logarithmic factors. For Euclidean spaces, the coreset size is
$O(m\varepsilon^{-1}) +
\tilde{O}(\min\{k^{4/3}\varepsilon^{-2},k\varepsilon^{-3}\})$, improving upon a
recent result by Jiang and Lou (ICALP 2025). These results also extend to
robust $(k,z)$-clustering, yielding, for VC and doubling dimension, a coreset
size of $O(m) + \tilde{O}(kd\varepsilon^{-2z})$ with the optimal linear
dependence on $m$. This extended result improves upon the earlier work of Huang
et al. (SODA 2025). The techniques introduce novel dataset decompositions,
enabling chaining arguments to be applied jointly across multiple components.

</details>


### [294] [Permutation patterns in streams](https://arxiv.org/abs/2507.11291)
*Benjamin Aram Berendsohn*

Main category: cs.DS

TL;DR: This paper analyzes the space complexity of finding permutation patterns in a stream. The complexity depends on the pattern: monotone patterns take $\Theta(k\log n)$, some patterns take $O(\sqrt{n\log n})$ or $O(\sqrt{n} \log n)$, and others take $\widetilde{\Theta}_{\pi}(n)$. For non-permutation streams, it


<details>
  <summary>Details</summary>
Motivation: The motivation is to study permutation pattern matching in a streaming setting, where the input is revealed sequentially. This setting is novel because the input being a permutation allows for inferring information about future inputs, which can be exploited by algorithms. Existing lower bound techniques are difficult to apply in this context.

Method: The paper proposes algorithms for permutation pattern matching in a streaming setting, leveraging the sequential nature of the input permutation to infer information about future elements. It analyzes the space complexity for different types of patterns (monotone, 312, 132, 231, 213, and others) and compares it to the case where the input is an arbitrary sequence of integers.

Result: The paper demonstrates that the space complexity of permutation pattern matching in a streaming setting is highly dependent on the pattern. Specifically, it establishes complexity bounds for various patterns, including $\Theta(k\log n)$ for monotone patterns, $O(\sqrt{n\log n})$ for $\pi \in \{312,132\}$, $O(\sqrt{n} \log n)$ for $\pi \in \{231,213\}$, and $\widetilde{\Theta}_{\pi}(n)$ for all other patterns. The results also show that for arbitrary sequences, the complexity is $\widetilde{\Theta}_{\pi}(n)$ except for monotone patterns.

Conclusion: The paper studies the complexity of permutation pattern matching in a streaming setting, showing that the space complexity varies significantly based on the specific pattern being searched for. For monotone patterns, the complexity is $\Theta(k\log n)$. For patterns like 312 and 132, it is $O(\sqrt{n\log n})$. For patterns 231 and 213, it is $O(\sqrt{n} \log n)$. For all other patterns, it is $\widetilde{\Theta}_{\pi}(n)$. In contrast, for arbitrary sequences (not permutations), the complexity is $\widetilde{\Theta}_{\pi}(n)$ for all cases except the monotone ones.

Abstract: Permutation patterns and pattern avoidance are central, well-studied concepts
in combinatorics and computer science. Given two permutations $\tau$ and $\pi$,
the pattern matching problem (PPM) asks whether $\tau$ contains $\pi$. This
problem arises in various contexts in computer science and statistics and has
been studied extensively in exact-, parameterized-, approximate-,
property-testing- and other formulations.
  In this paper, we study pattern matching in a \emph{streaming setting}, when
the input $\tau$ is revealed sequentially, one element at a time. There is
extensive work on the space complexity of various statistics in streams of
integers. The novelty of our setting is that the input stream is \emph{a
permutation}, which allows inferring some information about future inputs. Our
algorithms crucially take advantage of this fact, while existing lower bound
techniques become difficult to apply.
  We show that the complexity of the problem changes dramatically depending on
the pattern~$\pi$. The space requirement is: $\Theta(k\log{n})$ for the
monotone patterns $\pi = 12\dots k$, or $\pi = k\dots21$, $O(\sqrt{n\log{n}})$
for $\pi \in \{312,132\}$, $O(\sqrt{n} \log n)$ for $\pi \in \{231,213\}$, and
$\widetilde{\Theta}_{\pi}(n)$ for all other $\pi$. If $\tau$ is an arbitrary
sequence of integers (not necessary a permutation), we show that the complexity
is $\widetilde{\Theta}_{\pi}(n)$ in all except the first (monotone) cases.

</details>


### [295] [Scheduling on Identical Machines with Setup Time and Unknown Execution Time](https://arxiv.org/abs/2507.11311)
*Yasushi Kawase,Kazuhisa Makino,Vinh Long Phan,Hanna Sumita*

Main category: cs.DS

TL;DR: 该研究解决了具有设置时间和未知执行时间的作业调度问题，提出了一系列在线算法，并在不同设置下实现了渐近最优的性能。


<details>
  <summary>Details</summary>
Motivation: 为了解决在具有设置时间和未知执行时间的作业调度问题中最小化最大完工时间这一挑战。

Method: 研究设计了在线算法来解决在相同的机器上进行作业调度的问题，其中作业需要在执行前进行初始设置。设置时间是批次内作业集的单调函数，而作业的执行时间在完成前是未知的。研究考虑了两种情况：批次分配到单个机器或多个机器，并分析了允许或不允许抢占的情况。

Result: 研究中的在线算法在所有四种考虑的场景（批次分配到单个机器或多个机器，允许或不允许抢占）中，针对作业数量和机器数量都实现了渐近最优的竞争比。

Conclusion: 该研究为在具有设置时间和未知执行时间的作业调度问题设计了在线算法，实现了渐近最优的竞争比。

Abstract: In this study, we investigate a scheduling problem on identical machines in
which jobs require initial setup before execution. We assume that an algorithm
can dynamically form a batch (i.e., a collection of jobs to be processed
together) from the remaining jobs. The setup time is modeled as a known
monotone function of the set of jobs within a batch, while the execution time
of each job remains unknown until completion. This uncertainty poses
significant challenges for minimizing the makespan. We address these challenges
by considering two scenarios: each job batch must be assigned to a single
machine, or a batch may be distributed across multiple machines. For both
scenarios, we analyze settings with and without preemption. Across these four
settings, we design online algorithms that achieve asymptotically optimal
competitive ratios with respect to both the number of jobs and the number of
machines.

</details>


### [296] [Multipass Linear Sketches for Geometric LP-Type Problems](https://arxiv.org/abs/2507.11484)
*N. Efe Çekirge,William Gay,David P. Woodruff*

Main category: cs.DS

TL;DR: 研究提出了一种用于LP类型问题的多通道线性草图算法，在低维度和高精度下具有出色的性能，空间复杂度相比现有算法在1/ε上有指数级提升，并证明了单通道算法的局限性。


<details>
  <summary>Details</summary>
Motivation: LP类型问题（如最小包围球、线性支持向量机、线性规划和半定规划）在机器学习中有广泛应用，但现有算法在处理流式和分布式大数据模型时存在效率问题。

Method: 提出了一种基于线性草图的$
u$-近似算法，该算法具有O(ds)通道和O(s(√d/ε)3d/s)·poly(d, log(1/ε))的空间复杂度，适用于组合维度和VC维度为O(d)的LP类型问题。

Result: 在低维度（d < (1/ε)^0.999）和高精度（ε）要求下，实现了O(ds)通道和O(s(√d/ε)3d/s)·poly(d, log(1/ε))空间复杂度的$
u$-近似算法，并在参数s=d log(1/ε)时，实现了在1/ε上的指数级改进。此外，还证明了任何单通道算法在解决MEB和线性SVM问题时，至少需要(1/ε)^Ω(d)的下界。

Conclusion: 该研究为LP类型问题提供了一种新的流式和分布式近似算法，该算法在低维度和高精度要求下表现出色，并且通过多通道方法实现了比现有算法在1/ε上的指数级改进。

Abstract: LP-type problems such as the Minimum Enclosing Ball (MEB), Linear Support
Vector Machine (SVM), Linear Programming (LP), and Semidefinite Programming
(SDP) are fundamental combinatorial optimization problems, with many important
applications in machine learning applications such as classification,
bioinformatics, and noisy learning. We study LP-type problems in several
streaming and distributed big data models, giving $\varepsilon$-approximation
linear sketching algorithms with a focus on the high accuracy regime with low
dimensionality $d$, that is, when ${d < (1/\varepsilon)^{0.999}}$. Our main
result is an $O(ds)$ pass algorithm with $O(s( \sqrt{d}/\varepsilon)^{3d/s})
\cdot \mathrm{poly}(d, \log (1/\varepsilon))$ space complexity in words, for
any parameter $s \in [1, d \log (1/\varepsilon)]$, to solve
$\varepsilon$-approximate LP-type problems of $O(d)$ combinatorial and VC
dimension. Notably, by taking $s = d \log (1/\varepsilon)$, we achieve space
complexity polynomial in $d$ and polylogarithmic in $1/\varepsilon$, presenting
exponential improvements in $1/\varepsilon$ over current algorithms. We
complement our results by showing lower bounds of $(1/\varepsilon)^{\Omega(d)}$
for any $1$-pass algorithm solving the $(1 + \varepsilon)$-approximation MEB
and linear SVM problems, further motivating our multi-pass approach.

</details>


<div id='cond-mat.mtrl-sci'></div>

# cond-mat.mtrl-sci [[Back]](#toc)

### [297] [An eco-friendly universal strategy via ribavirin to achieve highly efficient and stable perovskite solar cells](https://arxiv.org/abs/2507.10557)
*Xianhu Wu,Gaojie Xia,Guanglei Cui,Jieyu Bi,Nian Liu,Jiaxin Jiang,Jilong Sun,Luyang Liu,Ping Li,Ning Lu,Zewen Zuo,Min Gu*

Main category: cond-mat.mtrl-sci

TL;DR: 使用发酵产生的核糖核酸作为掺杂剂，提高钙钛矿太阳能电池的效率和稳定性。


<details>
  <summary>Details</summary>
Motivation: 钙钛矿薄膜中的晶界杂乱且存在大量缺陷，这些缺陷会促进钙钛矿的分解，从而影响器件的性能和稳定性。因此，需要一种有效的方法来调控晶体生长，减少缺陷密度。

Method: 使用发酵产生的核糖核酸（一种来自枯草芽孢杆菌的化合物）作为掺杂剂，调控钙钛矿薄膜的晶体生长。通过密度泛函理论计算，验证了核糖核酸能够提高钙钛矿中VI、VMA、VPb和PbI的缺陷形成能。

Result: 使用核糖核酸作为掺杂剂，钙钛矿太阳能电池（ITO/PEDOT:PSS/perovskite/PCBM/BCP/Ag）的开路电压从1.077V提高到1.151V，功率转换效率（PCE）从17.05%提高到19.86%。在长期稳定性测试中，经过约900小时的储存，使用核糖核酸的器件的PCE仍保留了初始值的84.33%，而对照组器件仅保留13.44%。此外，在另一种器件结构（ITO/SnO2/perovskite/Spiro-OMETAD/Ag）中，PCE也从20.16%提高到22.14%，证明了该掺杂方法的通用性。

Conclusion: 这项工作提出了一种使用发酵产生的核糖核酸来控制钙钛矿晶体生长的新策略，这种策略可以显著提高钙钛矿太阳能电池的效率和稳定性。通过调整钙钛矿的功函数和能级结构，该方法能有效减少缺陷密度，提高开路电压和功率转换效率。此外，这种掺杂方法在不同器件结构中均表现出良好的通用性，并且在长期稳定性测试中也表现出色。

Abstract: The grain boundaries of perovskite films prepared by the solution method are
highly disordered, with a large number of defects existing at the grain
boundaries. These defect sites promote the decomposition of perovskite. Here,
we use ribavirin obtained through bacillus subtilis fermentation to regulate
the crystal growth of perovskite, inducing changes in the work function and
energy level structure of perovskite, which significantly reduces the defect
density. Based on density functional theory calculations, the defect formation
energies of VI, VMA, VPb, and PbI in perovskite are improved. This increases
the open-circuit voltage of perovskite solar cells (PSCs)
(ITO/PEDOT:PSS/perovskite/PCBM/BCP/Ag) from 1.077 to 1.151 V, and the PCE
increases significantly from 17.05% to 19.86%. Unencapsulated PSCs were stored
in the environment (humidity approximately 35+-5%) for long-term stability
testing. After approximately 900 hours of storage, the PCE of the
ribavirin-based device retains 84.33% of its initial PCE, while the
control-based device retains only 13.44% of its initial PCE. The PCE of PSCs
(ITO/SnO2/perovskite/Spiro-OMETAD/Ag) is increased from 20.16% to 22.14%,
demonstrating the universality of this doping method. This universal doping
strategy provides a new approach for improving the efficiency and stability of
PSCs using green molecular doping strategies.

</details>


### [298] [Revisiting the Abundance of Topological Materials](https://arxiv.org/abs/2507.10736)
*Hossein Mirhosseini,Luis Elcoro,Andreas Knüpfer,Thomas D. Kühne*

Main category: cond-mat.mtrl-sci

TL;DR: 计算方法和精度对拓扑材料的分类有显著影响，准确的计算表明拓扑材料比之前认为的要少。


<details>
  <summary>Details</summary>
Motivation: 重新审视了拓扑材料的分类，重点关注了计算工作流的优化和精确性。

Method: 通过整合混合密度泛函理论计算和 Hartree-Fock 交换，并优化从材料项目数据库获得的原子构型，然后进行精确的电子结构计算。

Result: 混合密度泛函理论计算结果显示，只有 15% 的材料是拓扑重要的，这与之前基于半局部泛函的 30% 的结果形成对比。

Conclusion: 与此前基于半局部交换和相关泛函的报道形成鲜明对比，基于混合密度泛函理论计算的结果表明，只有 15% 的材料是拓扑重要的。这凸显了拓扑分类对准确的原子和电子结构的依赖性，使得拓扑材料的丰度远低于普遍假设。

Abstract: The classification of topological materials is revisited using advanced
computational workflows that integrate hybrid density functional theory
calculations with exact Hartree-Fock exchange. Unlike previous studies, our
workflow optimizes atomic configurations obtained from the Materials Project
Database, followed by precise electronic structure calculations. Our results
based on hybrid density functional theory calculations reveal that only 15\% of
materials are topologically nontrivial, which is in stark contrast to the
previously reported 30\% based on semi-local exchange and correlation
functionals. This discrepancy underscores the critical dependence of
topological classifications on accurate atomic and electronic structures,
rendering the abundance of topological materials much lower than generally
assumed.

</details>


### [299] [A molecular dynamics investigation of the dependence of mechanical properties of steel nanowires on C concentration](https://arxiv.org/abs/2507.10751)
*J. K. Liyanage,M. D. Nadeesha Tharundi,Laalitha S. I. Liyanage*

Main category: cond-mat.mtrl-sci

TL;DR: 通过分子动力学模拟研究了钢纳米线的力学性能与温度和碳含量的关系。结果显示，杨氏模量随温度和碳含量的变化而变化，屈服强度和抗拉强度随碳含量增加而降低，这与滑移面的形成和扩展有关。


<details>
  <summary>Details</summary>
Motivation: 本研究旨在探索钢纳米线的力学性能与温度及碳含量之间的关系，以期为纳米结构钢材料的设计提供指导。

Method: 采用分子动力学模拟研究了不同碳含量的钢纳米线的力学性能与温度的关系。评估了四种原子间势能，并选择了Liyanage等人开发的MEAM势能，因为它能准确预测BCC Fe、B1结构FeC以及含碳BCC铁的行为。对含碳量为0-10%的FeC纳米线在0.1 K至900 K的温度范围内进行了单轴拉伸试验，并通过分析应力-应变曲线确定了杨氏模量、屈服应力和抗拉强度（UTS）。

Result: 结果表明，杨氏模量随碳含量的增加在0.1 K至300 K范围内呈现增长趋势，但在600 K至900 K范围内则呈下降趋势。屈服应力和抗拉强度（UTS）均随着碳含量的增加而逐渐降低。通过公共近邻分析发现，随着碳含量的增加，滑移面的形成速度加快，并且在较高温度下滑移面的扩展性增强，这是导致纳米线强度下降的原因。

Conclusion: 本研究揭示了碳含量和温度对钢纳米线力学行为的影响规律，为纳米结构钢材料的设计提供了参考。

Abstract: The temperature dependence of mechanical properties of steel nanowires with
varying carbon content was studied using molecular dynamics simulations. Four
interatomic potentials were assessed, with the Modified Embedded Atom Method
(MEAM) potential developed by Liyanage et al. selected for its accuracy in
predicting the behavior of BCC Fe, FeC in the B1 rock salt structure, and BCC
iron with carbon. Uniaxial tensile tests were conducted on FeC nanowires with
carbon concentrations of 0-10% at temperatures ranging from 0.1 K to 900 K.
Stress-strain curves were analyzed to determine Young's modulus, yield stress,
and ultimate tensile strength (UTS). Results showed that Young's modulus
increased between 0.1 K and 300 K but decreased between 600 K and 900 K with
increasing carbon content. Both yield stress and UTS decreased progressively
with higher carbon percentages. Common Neighbor Analysis revealed rapid
formation of slip planes as carbon content increased and greater slip plane
propagation at elevated temperatures, contributing to reduced nanowire
strength. These findings provide insights into the influence of carbon content
and temperature on the mechanical behavior of steel nanowires, which may inform
the design of nanostructured steel materials for various applications.

</details>


### [300] [Indium Hydroxide Ceramic Targets: A Breakthrough in High-Mobility Thin-Film Transistor Technology](https://arxiv.org/abs/2507.11011)
*Hikaru Sadahira,Prashant R. Ghediya,Hyeonjun Kong,Akira Miura,Yasutaka Matsuo,Hiromichi Ohta,Yusaku Magari*

Main category: cond-mat.mtrl-sci

TL;DR: 使用氢氧化铟陶瓷靶材通过脉冲激光沉积制备含氢氧化铟薄膜晶体管，解决了氢气使用的挑战，并实现了高性能。


<details>
  <summary>Details</summary>
Motivation: 为了克服在薄膜沉积过程中氢气掺杂带来的安全和可控性挑战，以实现下一代平板显示器中薄膜晶体管的规模化和工业化生产。

Method: 通过使用氢氧化铟陶瓷作为靶材进行薄膜沉积，并采用脉冲激光沉积技术，在薄膜退火后，成功制备了含有足够氢浓度且具有高电子迁移率的氧化铟薄膜，实现了与使用气相氢复合方法相当的高性能薄膜晶体管。

Result: 制备的氧化铟薄膜含有足够的氢，并且由于晶粒显著生长而表现出非常高的电子迁移率。此外，制造的薄膜晶体管表现出与使用气相氢掺杂方法生产的器件相当的高性能。

Conclusion: 该方法为含氢氧化铟薄膜晶体管在下一代平板显示器中的应用提供了一条实用的途径。

Abstract: Thin-film transistors composed of a hydrogen-containing indium oxide active
layer are promising candidates for backplane devices in next-generation flat
panel displays, offering higher definition and faster operation. However, the
hydrogen incorporation process during film deposition poses challenges for
scalable and industrial development due to both safety and controllability
issues. Here, we demonstrate that using indium hydroxide ceramic as the target
material for film deposition overcomes the difficulties associated with
hydrogen gas usage. We sintered commercially available indium hydroxide powder
using a conventional ceramic process at 150-250{\deg}C in air and utilized it
for the deposition of hydrogen-incorporated indium oxide films via pulsed laser
deposition. The resulting indium oxide films, after thermal annealing,
contained a sufficient concentration of hydrogen and exhibited very high
electron mobility due to significantly grown grains. Furthermore, we confirmed
that the fabricated thin-film transistors exhibited comparably high performance
to those produced using the gas-phase hydrogen incorporation method. This
approach offers a practical pathway for hydrogen-containing indium oxide-based
thin-film transistors in next-generation flat panel displays.

</details>


### [301] [Raman signature of cation vacancies in rare-earth nitrides](https://arxiv.org/abs/2507.10796)
*M. Markwitz,K. Van Koughnet,K. Kneisel,W. F. Holmes-Hewett,F. Natali,E. X. M. Trewick,L. Porteous,B. J. Ruck,H. J. Trodahl*

Main category: cond-mat.mtrl-sci

TL;DR: 通过拉曼光谱和计算研究，发现了稀土物相中的阳离子空位，这为稀土物相的空穴掺杂提供了新的途径。


<details>
  <summary>Details</summary>
Motivation: 稀土物相是内在铁磁半导体，但缺乏空穴掺杂，因此需要研究其性质以实现空穴掺杂。

Method: 通过拉曼光谱/计算研究了稀土物相，揭示了阳离子空位的存在。

Result: 发现了稀土物相中的阳离子空位，其拉曼活性振动模式在1100-1400 cm$^{-1}$，并且该模式的频率与计算得到的阳离子空位周围的氮离子的呼吸模式振动频率高度一致。

Conclusion: 研究发现了稀土物相中的阳离子空位，这为稀土物相的空穴掺杂提供了新的途径。

Abstract: We report a coordinated Raman/computation study of the rare-earth nitrides, a
series of intrinsic ferromagnetic semiconductors, to reveal the presence of
cation vacancies. Their presence is signaled by a Raman-active vibrational mode
at 1100-1400 cm$^{-1}$, rising steadily as the lattice contracts across the
series. The mode's frequency is in excellent agreement with the computed
breathing-mode vibration of the six nitrogen ions surrounding cation vacancies.
The discovery of such cation vacancies opens the door for hole doping that has
so far been lacking in the exploitation of rare-earth nitrides.

</details>


### [302] [Solid-State Dewetting of Polycrystalline Thin Films: a Phase Field Approach](https://arxiv.org/abs/2507.10811)
*Paul Hoffrogge,Nils Becker,Daniel Schneider,Britta Nestler,Axel Voigt,Marco Salvalaglio*

Main category: cond-mat.mtrl-sci

TL;DR: 该研究提出了一个三维多相场框架，用于模拟多晶薄膜中的固态去湿（SSD），该框架考虑了晶界的影响，并能重现SSD现象，解释了去湿在晶界三重结的发生，并提出了去湿开始的精确判据。


<details>
  <summary>Details</summary>
Motivation: 填补了理论研究主要集中在单晶SSD而忽略了多晶薄膜中晶界复杂性的空白。

Method: 利用一个多相场框架，考虑了各向同性的表面和界面能以及由曲率驱动的晶界运动，以模拟三维多晶薄膜中的SSD。

Result: 提出并应用了一个多相场框架，该框架能重现多晶薄膜SSD的关键现象，并与能量论证一致。研究提供了关于去湿在晶界三重结处开始的关键证据，并提出了经数值模拟证实的去湿开始的精确分析判据，同时展示了多晶薄膜块的SSD。

Conclusion: 该工作提出了一个多相场框架，用于模拟和理解多晶薄膜中的固态去湿（SSD）现象。该框架能够重现SSD的关键现象，并与基于能量论证的预测一致，同时还能解释去湿在晶界三重结处的发生。此外，该研究还提出了去湿开始的精确分析判据，并通过数值模拟进行了验证，并展示了多晶薄膜块的SSD现象。

Abstract: Solid-state dewetting (SSD) is the process by which thin solid films break up
and retract on a substrate, resulting in the formation of nanostructures and
islands. While SSD in single-crystalline films is generally understood as a
surface-energy-driven process mediated by surface diffusion, polycrystalline
films feature additional complexity due to the presence of grain boundaries.
Theoretical investigations and simulation frameworks have mainly focused on
single-crystalline SSD. In this work, we present and apply a multi-phase-field
framework that captures key mechanisms in polycrystalline thin films with
multiple grains and grain boundaries in three dimensions. By considering
isotropic surface and interface energy and curvature-driven grain boundary
motion, we demonstrate how the framework reproduces the key phenomenology of
SSD while being consistent with predictions based on energetic arguments. We
also introduce refined analytical criteria for the onset of dewetting,
confirmed by numerical simulations. Key evidence is given concerning the onset
of dewetting at grain-boundary triple junctions. Moreover, we showcase SSD of
polycrystalline patches. This work paves the way for in-depth investigations of
the morphological evolution of polycrystalline thin films.

</details>


### [303] [Spin ordering-induced fully-compensated ferrimagnetism](https://arxiv.org/abs/2507.10848)
*San-Dong Guo,Shaobo Chen,Guangzhao Wang*

Main category: cond-mat.mtrl-sci

TL;DR: 通过工程化自旋序而非改变晶格结构，实现了全补偿亚铁磁性，为零净磁矩下的非相对论自旋劈裂提供了新方法。


<details>
  <summary>Details</summary>
Motivation: 全补偿亚铁磁体具有零净磁矩但显示出非相对论全局自旋劈裂，这在构建高性能自旋电子器件方面具有高度优势。

Method: 利用第一性原理计算，构建了一个以单层$	ext{Cr}_2	ext{C}_2	ext{S}_6$为基本构筑单元的双层系统来证实该提议。

Result: 通过第一性原理计算，证实了该策略可以诱导全补偿亚铁磁性，并且可以通过调整其中一层的$	ext{Néel}$矢量轻松地在两种不同的电子状态之间切换。该策略还可以通过自旋序工程扩展到诱导交变磁性。

Conclusion: 本文提出了一种通过工程化自旋序而不是修改晶格结构来诱导全补偿亚铁磁性的方法，为实现零净磁化磁体中的非相对论自旋劈裂提供了一条替代途径，有望推动低功耗自旋电子器件的发展和构建。

Abstract: Fully-compensated ferrimagnets exhibit zero net magnetic moment yet display
non-relativistic global spin splitting, making them highly advantageous for
constructing high-performance spintronic devices. The general strategy is to
break the inversion symmetry of conventional antiferromagnets or the
rotational/mirror symmetry of altermagnets to achieve fully-compensated
ferrimagnets. Here, we propose to induce fully-compensated ferrimagnetism by
engineering the spin ordering rather than modifying the lattice structure.
Bilayer stacking engineering offers a convenient platform to verify our
proposal and readily enables switching between two distinct electronic states
by tuning the $\mathrm{N\acute{e}el}$ vector of one layer. By the
first-principles calculations, a bilayer system is constructed with monolayer
$\mathrm{Cr_2C_2S_6}$ as the elementary building block to corroborate our
proposal. This strategy can also be extended to inducing altermagnetism via
spin ordering engineering. Our work offers an alternative route to realize
non-relativistic spin splitting in zero-net-magnetization magnets, paving the
way for the advancement and construction of low-power spintronic device.

</details>


### [304] [Optical Spin Sensing and Metamagnetic Phase Control in the 2D Van der Waals Magnet Yb3+-Doped CrPS4](https://arxiv.org/abs/2507.10889)
*Jacob T. Baillie,Kimo Pressler,Nick J. Adams,Faris Horani,Thom J. Snoeren,Rémi Beaulac,Daniel R. Gamelin*

Main category: cond-mat.mtrl-sci

TL;DR: 通过掺杂Yb3+，实现了对CrPS4磁性和光学性质的调控，并成功演示了光驱动的自旋翻转跃迁。


<details>
  <summary>Details</summary>
Motivation: 探索二维磁性材料在自旋光子学领域的应用潜力，以及磁性与光学性质耦合的机制。

Method: 研究了掺杂Yb3+的CrPS4的光学和自旋性质，特别是Yb3+的f-f发光与CrPS4的磁序之间的关系。

Result: 发现CrPS4的磁序通过超交换耦合编码在Yb3+的f-f发光中，并且自旋重取向可以调制Yb3+的发光能量和交换劈裂。

Conclusion: 该研究表明，通过掺杂Yb3+可以调节CrPS4的磁性和光学性质，并实现了光驱动的自旋翻转跃迁。

Abstract: The emergence of two-dimensional magnets within the van der Waals toolkit has
introduced unprecedented opportunities to develop ultrathin spintronic
technologies. Strong coupling between spin and optical properties in such
materials can further enable novel spin-photonic capabilities of both
fundamental and technological interest. Here, we investigate the optical and
spin properties of the air-stable, layered A-type antiferromagnet chromium
thiophosphate (CrPS4) when doped with Yb3+. We show that the collective spin
properties of CrPS4 are encoded in the sharp f-f luminescence of isolated Yb3+
dopants via strong magnetic superexchange coupling between the two, and that
spontaneous magnetic ordering in CrPS4 induces large exchange splittings in the
narrow Yb3+ f-f photoluminescence features below TN. Spin reorientation in
CrPS4 via a "spin-flop" metamagnetic transition modulates the Yb3+ f-f
luminescence energies and exchange splittings. This pronounced link between
spin and optical properties enables the demonstration of optically driven
spin-flop transitions in CrPS4.

</details>


### [305] [Frequency comb in twisted magnonic crystals](https://arxiv.org/abs/2507.10922)
*Minghao Li,Zhejunyu Jin,Zhaozhuo Zeng,Peng Yan*

Main category: cond-mat.mtrl-sci

TL;DR: 扭曲磁子晶体中的 MFCs：这项研究通过双音微波激励在扭曲磁子晶体中产生了 MFCs，并发现扭转角会显著影响三磁子相互作用。研究结果有助于优化 MFCs 的产生，并为信息处理和高精度计量等领域开辟了新的可能性。


<details>
  <summary>Details</summary>
Motivation: 探索扭曲磁子晶体（MCs）中未被充分研究的非线性动力学，特别是磁子频率梳（MFCs）的产生。

Method: 通过双音微波激励在扭曲磁子晶体中演示了磁子频率梳（MFCs）的产生。

Result: 发现有限的扭转角能显著增强三磁子相互作用，其原因是层间偶极-偶极相互作用引起的非共线基态磁构型。梳齿的数量对扭转角的依赖性呈现出类似平台状的行为，并且随着传播磁子模式的激发频率的增加，平台的宽度和高度会饱和。

Conclusion: 该研究加深了对扭曲磁子晶体中非线性相互作用的理解，并强调了其在基于莫尔材料的信息处理和高精度计量方面的潜力。

Abstract: While twisted magnonic crystals (MCs) have recently gained attention for
their intriguing linear phenomena, such as magnon flat bands, their nonlinear
dynamics -- particularly the generation of magnonic frequency combs (MFCs) --
have remained largely unexplored. In this work, we demonstrate the creation of
MFCs in twisted MCs using two-tone microwave excitation. We find that finite
twist angles significantly enhance three-magnon interactions, driven by the
non-collinear ground-state magnetic configuration induced by interlayer
dipole-dipole interactions. The number of comb teeth exhibits a plateau-like
dependence on the twist angle, with the plateau's width and height saturating
as the excitation frequency of the propagating magnon mode increases. This
behavior reveals an optimal range of twist angles and frequencies for achieving
high-quality MFCs with a large number of comb teeth. Our findings deepen the
understanding of nonlinear interactions in twisted MCs and highlight their
potential for advancing moir\'e-based materials in information processing and
high-precision metrology.

</details>


### [306] [Weak low-temperature ferromagnetism and linear magnetoresistance in Lu$_{0.75}$Fe$_6$Sn$_6$ with a disordered HfFe$_6$Ge$_6$-type structure](https://arxiv.org/abs/2507.10964)
*Chenfei Shi,Zhaodi Lin,Qiyuan Liu,Junai Lv,Xiaofan Xu,Baojuan Kang,Jin-Hu Yang,Yi Liu,Jian Zhang,Shixun Cao,Jin-Ke Bao*

Main category: cond-mat.mtrl-sci

TL;DR: 研究人员使用自熔剂法合成了一种名为 Lu$_{0.75}$Fe$_6$Sn$_6$ 的新材料，发现它具有复杂的晶体结构，并在低温下表现出有趣的磁性和电学特性，包括平面内的弱铁磁性和线性磁阻，这可能与材料的结构缺陷有关。


<details>
  <summary>Details</summary>
Motivation: 探索具有 Fe-kagome 晶格的 Lu$_{0.75}$Fe$_6$Sn$_6$ 材料的合成及其物理性质。

Method: 使用自熔剂法合成 Lu$_{0.75}$Fe$_6$Sn$_6$ 单晶，并研究其晶体结构、磁性、热力学和电输运性质。

Result: 合成了 Lu$_{0.75}$Fe$_6$Sn$_6$ 单晶，发现其结构为 HfFe$_6$Ge$_6$ 型与 CoSn 型结构的交错，Lu 位存在 25% 空位，Sn 位存在无序。在 40 K 以下表现出 ab 平面内的弱铁磁性（倾斜反铁磁性）和 c 轴方向的反铁磁性，并观察到各向异性的非饱和线性磁阻。

Conclusion: 该研究报告了使用自熔剂法合成具有 Fe-kagome 晶格的 Lu$_{0.75}$Fe$_6$Sn$_6$ 单晶，并对其进行了结构、磁性、热力学和输运性质的研究。结构精炼表明，Lu$_{0.75}$Fe$_6$Sn$_6$ 主要框架为 HfFe$_6$Ge$_6$ 型结构，并伴有 CoSn 型结构，导致 Lu 位存在 25% 的空位以及 Sn 位存在无序。该材料在 40 K 以下表现出显著的磁各向异性，在 ab 平面内具有弱铁磁性，而在 c 轴方向表现出反铁磁行为。弱铁磁性源于倾斜的反铁磁性，磁矩偏离 c 轴指向 ab 平面。此外，在 Lu$_{0.75}$Fe$_6$Sn$_6$ 中还观察到各向异性的非饱和线性磁阻，这可能源于样品中的结构无序。

Abstract: We report the synthesis of Lu$_{0.75}$Fe$_6$Sn$_6$ single crystals with a
Fe-kagome lattice using a self-flux method. The crystal structure, magnetic,
thermodynamic and electrical transport properties were investigated. Structure
refinement reveals that Lu$_{0.75}$Fe$_6$Sn$_6$ has a HfFe$_6$Ge$_6$-type
structure as the major framework intergrown with a CoSn-type structure, leading
to a vacancy of 25% on the Lu-site and disorder on the Sn-site. It exhibits a
significant magnetic anisotropy with weak ferromagnetism in the ab-plane below
40 K and antiferromagnetic behavior along the c-axis. The weak ferromagnetism
is due to the canted antiferromagnetism with magnetic moment deviating from the
$c$-axis to the ab-plane. Besides, an anisotropic non-saturated linear
magnetoresistance is also observed in Lu$_{0.75}$Fe$_6$Sn$_6$, probably
resulting from the structural disorder in the sample.

</details>


### [307] [Hidden fully-compensated ferrimagnetism](https://arxiv.org/abs/2507.11118)
*San-Dong Guo*

Main category: cond-mat.mtrl-sci

TL;DR: 本文提出了隐藏的全补偿亚铁磁性概念，并预测了一种名为 $PT$-双层 $	ext{CrMoC}_2	ext{S}_6$ 的新型材料，它具有隐藏自旋极化，可以通过电场调控，为自旋电子学提供了新方向。


<details>
  <summary>Details</summary>
Motivation: 为了在自旋电子学中实现更快的开关动力学、更高的抗干扰性、更低的功耗和更高的整体效率，需要引入具有自旋劈裂的零净磁化材料。本文旨在探索除超磁体外，具有零净自旋极化但局部自旋极化非零的隐藏自旋极化（HSP）的新型材料。

Method: 通过第一性原理计算，预测了 $PT$-双层 $	ext{CrMoC}_2	ext{S}_6$ 是一种隐藏的全补偿亚铁磁性材料，并展示了其全补偿的隐藏自旋极化特性，以及如何通过外电场进行调控。

Result: 预测了 $PT$-双层 $	ext{CrMoC}_2	ext{S}_6$ 是一种隐藏的全补偿亚铁磁性材料，并展示了其隐藏自旋极化特性，该特性可以通过外加垂直电场进行分离和观察。 

Conclusion: 本文提出并预测了一种隐藏的、全补偿的亚铁磁性材料 $PT$-双层 $	ext{CrMoC}_2	ext{S}_6$，其具有全补偿的隐藏自旋极化，可通过垂直外电场分离和观察。这些研究为自旋电子学的发展提供了一类新的隐藏自旋极化材料。

Abstract: Incorporating zero-net-magnetization magnets that exhibit spin-splitting into
spintronics delivers key advantages: faster switching dynamics, greater
immunity to destabilizing fields, lower power consumption, and markedly
improved overall efficiency. The collinear magnets with net-zero magnetization
and spin-splitting mainly include altermagnet and fully-compensated
ferrimagnet, which provide possibility to achieve hidden spin polarization
(HSP) with net-zero spin polarization in total but non-zero local spin
polarization. In addition to proposal of hidden altermagnetism, we hereby
introduce this concept of hidden fully-compensated ferrimagnetism, where the
total spin polarization is zero, but either of the two inversion-partner
sectors possesses fully-compensated ferrimagnetism with non-zero local spin
polarization in the real space. By the first-principle calculations, we predict
that $PT$-bilayer $\mathrm{CrMoC_2S_6}$ is a possible hidden fully-compensated
ferrimagnet, showing fully-compensated ferrimagnetic HSP, which can be
separated and observed by an out-of-plane external electric field. Our works
provide a class of hidden spin-polarized materials that facilitates the
advancement of spintronics.

</details>


### [308] [Magneto-elastic softening in cold-sprayed polycrystalline nickel studied by resonant ultrasound spectroscopy](https://arxiv.org/abs/2507.11239)
*Michaela Janovská,Petr Sedlák,Martin Ševčík,Jan Cizek,Jan Kondas,Reeti Singh,Jan Čupera,Hanuš Seiner*

Main category: cond-mat.mtrl-sci

TL;DR: 激光超声可用于分析纯镍冷喷涂沉积物的残余应力，并能监测退火和应力均匀性。


<details>
  <summary>Details</summary>
Motivation: 为了分析冷喷涂金属沉积物中高含量的压缩残余应力，并探索一种可行的无损检测方法，特别是针对纯镍等铁磁性和磁致伸缩材料。

Method: 采用激光超声技术，通过接触式共振超声光谱法监测纯镍沉积物在居里点温度下的剪切模量和内部摩擦参数，以评估磁弹性软化强度。同时，该方法也用于原位观察退火过程和检测残余应力均匀性，并提出了一种室温下磁弹性耦合探测的方法。

Result: 激光超声技术能够有效分析纯镍冷喷涂沉积物的残余应力。该方法可以监测材料在居里点温度下的磁弹性软化，原位观察退火过程，并检测残余应力在厚度方向的均匀性。同时，提出的室温探测方法也对所测材料进行了测试。

Conclusion: 本研究提出的激光超声方法可用于分析冷喷涂金属沉积物的残余应力，特别是铁磁性和磁致伸缩材料（如纯镍）。该方法可在居里点温度下监测材料的剪切模量和内部摩擦参数，从而评估磁弹性软化强度，并能原位观察退火过程和检测沉积物厚度方向的残余应力均匀性。此外，还提出并测试了一种用于室温下磁弹性耦合探测的方法。

Abstract: Cold-sprayed metallic deposits are additively manufactured materials
containing high levels of compressive residual stress. Here we show that the
presence and intensity of this stress can be analyzed using laser-ultrasonics,
provided that the sprayed material is ferromagnetic and magnetostrictive, as in
the case of pure nickel. Contactless resonant ultrasound spectroscopy is used
to monitor the evolution of shear modulus and internal friction parameter of
two polycrystalline Ni deposits with temperature over the Curie point, which
enables a direct assessment of the strength of magneto-elastic softening that
is known to be strongly stress-dependent. In addition, the proposed methodology
is also shown to be suitable for in-situ observation of the recrystallization
process in the vicinity of the Curie point, as well as inspecting the
homogeneity of the residual stress level across the thickness of the
cold-sprayed deposit. Finally, a methodology for room-temperature probing of
the magnetoelastic coupling is proposed and tested on the examined materials.

</details>


### [309] [Diverse polymorphism in Ruddlesden-Popper chalcogenides](https://arxiv.org/abs/2507.11300)
*Prakriti Kayastha,Erik Fransson,Paul Erhart,Lucy Whalley*

Main category: cond-mat.mtrl-sci

TL;DR: RP硫属化合物的结构演变


<details>
  <summary>Details</summary>
Motivation: RP氧化物的结构多样性已被用于调节性质或实现多铁性等高级功能，但对RP硫属化合物的结构演变知之甚少。

Method: 开发高精度机器学习原子间势，对 Ba$_{n+1}$Zr$_n$S$_{3n+1}$（n=1至6）进行大规模分子动力学模拟。

Result: 预测了每个n值的新多晶型物，计算了它们相应的相变温度，并通过与已发表的实验结果进行比较来验证了我们 [的方法]。我们发现n=1相表现出负热膨胀，n=1和n=3经历了不寻常的升序对称性破缺，n≥4的相形成了层依赖性倾斜模式。

Conclusion: RP硫属化合物的结构演变揭示了与无机RP材料前所未见的层依赖性倾斜模式，这源于八面体旋转和岩盐界面之间 the 崎岖不平的竞争，并提出了实现高级功能的新策略。

Abstract: Ruddlesden-Popper (RP) chalcogenides are stable, non-toxic candidates for
optoelectronic or thermoelectric applications. The structural diversity of RP
oxides is already exploited to tune properties or achieve more advanced
functionalities like multiferroicity, however, little is known about the
structural evolution of RP chalcogenides. In this work, we develop a
high-accuracy machine-learned interatomic potential to run large-scale
molecular dynamics simulations on $Ba_{n+1}Zr_nS_{3n+1}$ for $n=1$ to $n=6$. We
predict new polymorphs for each $n$-value, calculate their corresponding phase
transition temperatures, and validate our approach through comparison to
published experimental results. We find that the $n=1$ phase exhibits negative
thermal expansion, that $n=1$ and $n=3$ undergo unusual ascending symmetry
breaking, and that phases with $n\geq4$ form layer-dependent tilt patterns
previously unreported for inorganic RP materials. This unique behaviour results
from competition between octahedral rotations and rumpling at the rocksalt
interface, and suggests new strategies for accessing advanced functionalities.

</details>


### [310] [A supramolecular ferroelectric with two sublattices and polarization dependent conductivity](https://arxiv.org/abs/2507.11309)
*H. Mager,M. Litterst,Sophia Klubertz,S. V. Haridas,O. Shyshov,M. von Delius,M. Kemerink*

Main category: cond-mat.mtrl-sci

TL;DR: 本文研究了一种有机分子材料，它具有铁电性和电子电导性，并且这两种性质可以通过化学设计进行调控，在多功能材料领域具有应用潜力。


<details>
  <summary>Details</summary>
Motivation: 本文旨在探索有机铁电材料的化学设计可能性，以期结合和微调功能分子材料的性质，并研究铁电极化与电子电导性之间的关系。

Method: 本研究通过化学设计，结合和微调了功能分子材料的性质，特别是研究了一类具有长距离超分子组织成纤维束的有机分子材料。通过极化-滞后和电容-电压曲线，研究了材料的铁电行为和电子电导性，并分析了铁电极化方向和程度对电导率的调节作用。

Result: 所研究的材料在固态下表现出铁电行为，具有两个独立的偶极子部分，在极化-滞后和电容-电压曲线上表现为两个不同的矫顽电场。此外，材料还表现出长距离电子电导性，该电导性受到铁电极化方向和程度的调节。

Conclusion: 该材料具有双重偶极子部分，可利用铁电特性调节电导率，是多功能材料的优良基础。

Abstract: The possibility to combine and finetune properties of functional molecular
materials by chemical design is particularly relevant for organic
ferroelectrics. In this work, we investigate a class of organic molecular
materials that show long-range supramolecular organization into fibrillar
bundles. In solid state, the material shows ferroelectric behavior resulting
from two largely independent dipolar moieties that show up as two separate
coercive fields in polarization-hysteresis and capacitance-voltage curves.
Moreover, the material shows a long-range electronic conductivity that arises
due to oxidation at the positive electrode, followed by electron transfer
between neighboring molecules. We find that this conductivity is modulated by
the direction and degree of ferroelectric polarization, which we interpret in
terms of injection barrier modulation at low electric fields and a recently
developed framework for asymmetric polaron hopping at high fields. With two
distinct, partially independent dipolar moieties offering the possibility to
use ferroelectric properties to modulate conductance, the materials presented
herein are a promising basis for multifunctional materials.

</details>


### [311] [Unveiling Zn incorporation in CuInS$_2$ quantum dots: X-ray and optical analysis of doping effects, structural modifications and surface passivation](https://arxiv.org/abs/2507.11338)
*Andrés Burgos-Caminal,Brener R. C. Vale,André F. V. Fonseca,Juan F. Hidalgo,Elisa P. P. Collet,Lázaro García,Víctor Vega-Mayoral,Saül Garcia-Orrit,Iciar Arnay,Juan Cabanillas-González,Laura Simonelli,Ana Flávia Nogueira,Marco Antônio Schiavon,Thomas J. Penfold,Lazaro A. Padilha,Wojciech Gawelda*

Main category: cond-mat.mtrl-sci

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Quantum dots (QDs) exhibit unique properties arising from their reduced size
and quantum confinement effects, including exceptionally bright and tunable
photoluminescence. Among these, CuInS$_{2}$ QDs have gained significant
attention owing to their remarkable broadband emission, making them highly
desirable for various optoelectronic applications requiring efficient
luminescent nanomaterials. However, maximizing radiative recombination in
CuInS$_{2}$ QDs often necessitates minimizing intragap trap states. A common
approach involves the introduction of Zn during the synthesis, which typically
promotes the formation of a ZnS shell that passivates the QD surface.
  Despite its importance, the characterization and quantification of Zn
incorporation using conventional techniques, such as optical spectroscopy or
electron microscopy, remains challenging. In this study, we utilized X-ray
absorption spectroscopy (XAS), in both X-ray absorption near-edge structure
(XANES) and extended X-ray absorption fine structure (EXAFS) spectral ranges,
to investigate Zn incorporation into CuInS$_{2}$ QDs with element-specific
precision. This approach allowed us to detect the formation of a ZnS surface
shell and to resolve the spatial distribution of Zn atoms within the QD
lattice, distinguishing between Zn as a substituent, or as an interstitial
defect.
  Additionally, we explored the optical and dynamical properties of CuInS$_{2}$
QDs using time-resolved optical spectroscopies, particularly in the presence of
electron and hole acceptors. These results provide deeper insights into the
role and effectiveness of the Zn-induced passivating layer, paving the way for
optimizing QD performance in photoluminescence applications.

</details>


### [312] [Implementation of the magnetic force theorem for large-scale calculations of magnon bands: application to yttrium iron garnet](https://arxiv.org/abs/2507.11374)
*Thorbjørn Skovhus,Varun Rajeev Pavizhakumari,Thomas Olsen*

Main category: cond-mat.mtrl-sci

TL;DR: An efficient method to calculate exchange parameters in q-space using Bloch states, validated on yttrium iron garnet, showing good agreement with experiments and revealing complex exchange pathways.


<details>
  <summary>Details</summary>
Motivation: To present an efficient implementation of the magnetic force theorem for direct evaluation of exchange parameters in q-space, suitable for high-throughput computations.

Method: The exchange parameters are calculated directly from Bloch states without relying on any mapping onto localized orbitals.

Result: The method was applied to yttrium iron garnet, showing excellent agreement with experimental magnon dispersion. The calculations revealed multiple inequivalent exchange pathways for the same interatomic distances, fully accounting for long-range interactions.

Conclusion: We present an efficient implementation of the magnetic force theorem which allows for direct evaluation of exchange parameters in q-space, well suited for high-throughput computations.

Abstract: We present an efficient implementation of the magnetic force theorem which
allows for direct evaluation of exchange parameters in q-space. The exchange
parameters are calculated directly from Bloch states and the implementation
does not rely on any mapping onto localized orbitals. This renders the approach
well suited for high-throughput computations, where the construction of a
localized basis set (for example Wannier functions) often is impractical. We
demonstrate the versatility of the method by applying it to yttrium iron
garnet, where we obtain excellent agreement with the experimental magnon
dispersion without any prior assumptions of important exchange pathways. In
particular, the calculations reveal the existence of several inequivalent
exchange pathways associated with the same interatomic distances. Performing
such calculations in q-space fully accounts for long-range exchange
interactions and provides a convenient route for validating models obtained by
fitting to inelastic neutron scattering data.

</details>


### [313] [Volcano-Like Ferroic Transitions Deviating from the Model of Landau Theory](https://arxiv.org/abs/2507.11409)
*Yuxuan Sheng,Menghao Wu*

Main category: cond-mat.mtrl-sci

TL;DR: 本文预测并证实了两种新型铁电和铁磁性材料，它们具有反常的火山状温度依赖性，并通过第一性原理计算进行了验证。


<details>
  <summary>Details</summary>
Motivation: 预测存在反常火山状温度依赖性的极化或磁化，其最大值位于高温处，这与基于 Landau 理论的经典模型不同。

Method: 通过第一性原理计算，在几个典型的体系中，包括被银离子或金属分子插入的磁性双层，证明了这些设想。

Result: 展示了两种可能出现反常火山状温度依赖性的铁电和铁磁性材料，其中铁电性的开关通路涉及多种亚稳态相，而补偿反铁磁性则可以实现一种独特的温度区分多铁性。

Conclusion: 本文提出并证实了两种可能出现反常火山状温度依赖性的铁电和铁磁性材料，与基于 Landau 理论的经典模型不同。

Abstract: We predict the existence of abnormal volcano-like temperature dependence of
polarization or magnetization with maxima located at elevated temperature,
distinct from classical model based on Landau theory. One case is
ferroelectricity with long ion displacements and quantized polarizations that
cannot be used for expansion in Landau model, and the switching pathway
involves various metastable phases where the polar phase is higher both in
energy and entropy compared with non-polar phase. Another case is compensated
antiferromagnets with two opposite spin lattices of different spin exchange
constants. Such difference can be utilized for a unique type of temperature
differentiated multiferroicity, where large magnetizations can be reversed upon
ferroelectric switching between two Curie temperature with alternating half of
spins in paramagnetic state. We demonstrate these proposals by first-principles
calculations on several paradigmatic systems, including magnetic bilayers
intercalated by Ag ions or metal molecules.

</details>


### [314] [Revisiting the Influence of Sn in Cu-Al alloys: A Third Element Effect Enabling Stainless Steel Type Aqueous Passivation Behavior](https://arxiv.org/abs/2507.11416)
*Debashish Sur,Nathan C. Smith,Elaf A. Anber,Kaitlyn L. Anderson,Peter F. Connors,Daniel Foley,Mitra L. Taheri,Junsoo Han,Christopher M. Wolverton,John R. Scully*

Main category: cond-mat.mtrl-sci

TL;DR: Sn合金添加剂能改善Cu-Al合金的耐腐蚀性，通过形成Al(III)和Sn(IV, II)的络合物氧化物降低腐蚀速率，并表现出第三元素效应。


<details>
  <summary>Details</summary>
Motivation: 重新审视了Sn合金添加剂对Cu-Al合金水性钝化行为的影响，并发现了其作为一种新的第三元素效应。

Method: 采用电化学和表面敏感的非原位及在位光谱技术研究了各元素在水性钝化过程中的作用。结合基于第一性原理的团簇展开计算和蒙特卡洛模拟，探究了Cu-Al-Sn体系中化学短程有序与钝化之间的联系。

Result: 高纯度Sn和Cu在测试环境中均未钝化，而高纯度Al则形成了具有稳定钝化电流密度（0.01 mA/cm^2）的钝化膜。Cu-xAl-Sn固溶体合金（x > 18 at.%）在添加Sn（< 3 at.%）后，其腐蚀速率低于相应的Cu-xAl合金，这归因于表面形成了Al(III)和Sn(IV, II)的未知络合物氧化物。Sn对Al(III)钝化有很强的影响，表明了其第三元素效应。

Conclusion: Sn合金添加剂对Cu-Al合金的水性钝化行为产生了显著影响，表现出一种新的第三元素效应。Sn的添加可以降低Cu-Al合金的腐蚀速率，特别是在Al含量大于18%且Sn含量小于3%时，通过形成Al(III)和Sn(IV, II)的复杂氧化物来实现。Sn对Al(III)钝化有很强的影响，证实了其第三元素效应。

Abstract: The influence of Sn alloying additions on the aqueous passivation behavior of
Cu-Al alloys was revisited and found to function as a new third element effect
in acidified 0.1 M Na2SO4 solution. The role of each element during the process
of aqueous passivation was investigated using electrochemical and
surface-sensitive ex-situ and in-operando spectroscopic techniques. The
connection between passivation and the atomic arrangements of atoms in the
solid solution was supported by first principles based cluster expansion
calculations and Monte Carlo simulations probing the chemical short-range order
in the Cu-Al-Sn system. High purity Sn, like high purity Cu, did not passivate
in the test environment, whereas high purity Al formed a passive film with a
stable passive current density of 0.01 mA/cm^2. Cu-xAl-Sn solid solution alloys
where x greater than 18 at.%, containing less than 3 at.% Sn additions
exhibited lower corrosion rates than Cu-xAl alloys, brought by Al(III) and
Sn(IV, II) unidentified complex oxides formation on the surface. A strong
influence of Sn on Al(III) passivation was observed, i.e., strongly suggesting
a third element effect type behavior. Possible governing processes explaining
the stainless steel type corrosion behavior are discussed, providing insights
for exploring novel synergies in the design of corrosion resistant alloys.

</details>


<div id='cs.LO'></div>

# cs.LO [[Back]](#toc)

### [315] [$ε$-Distance via Lévy-Prokhorov Lifting](https://arxiv.org/abs/2507.10732)
*Josée Desharnais,Ana Sokolova*

Main category: cs.LO

TL;DR: ε-distance 是一种基于 ε-bisimulation 的行为假度量，具有直观、易于计算的优点。本研究表明，它也是一个函子，并且与 ε-coupling 和 ε-bisimulation 具有共代数表征。


<details>
  <summary>Details</summary>
Motivation:  Kantorovich 距离被认为是概率过程的最优假度量，但ε-distance 在可计算性和直观性方面也具有优势，促使研究者对ε-distance 的性质进行更深入的探索。

Method: 通过将 Kantorovich 距离替换为 L'evy-Prokhorov 距离，为ε-distance提供了函子。

Result: 研究表明，ε-distance 也是某个泛函的最大不动点，并提供了一个函子。此外，ε-coupling 和 ε-bisimulation 具有令人信服的共代数表征。

Conclusion: 将 L'evy-Prokhorov 距离替换到提升的函子中的 Kantorovich 距离，可以得到ε-distance，它是某个泛函的最大不动点的函子。

Abstract: The most studied and accepted pseudometric for probabilistic processes is one
based on the Kantorovich distance between distributions. It comes with many
theoretical and motivating results, in particular it is the fixpoint of a given
functional and defines a functor on (complete) pseudometric spaces.
  Other notions of behavioural pseudometrics have also been proposed, one of
them ($\epsilon$-distance) based on $\epsilon$-bisimulation.
$\epsilon$-Distance has the advantages that it is intuitively easy to
understand, it relates systems that are conceptually close (for example, an
imperfect implementation is close to its specification), and it comes equipped
with a natural notion of $\epsilon$-coupling. Finally, this distance is easy to
compute.
  We show that $\epsilon$-distance is also the greatest fixpoint of a
functional and provides a functor. The latter is obtained by replacing the
Kantorovich distance in the lifting functor with the L\'evy-Prokhorov distance.
In addition, we show that $\epsilon$-couplings and $\epsilon$-bisimulations
have an appealing coalgebraic characterization.

</details>


### [316] [Reasoning about Medical Triage Optimization with Logic Programming](https://arxiv.org/abs/2507.10781)
*Jaikrishna Manojkumar Patil,Adam Chapman,Richard Knuszka,John Chapman,Paulo Shakarian*

Main category: cs.LO

TL;DR: 提出一个逻辑编程框架，用于医疗后送决策，将伤亡人数平均减少了 35.75%。


<details>
  <summary>Details</summary>
Motivation: 支持高风险医疗决策。

Method: 提出一个逻辑编程框架，用于编排优化问题的多种变体，并推理其结果，以支持高风险的医疗决策。该逻辑编程层协调多个优化公式的构建和评估，将解决方案转换为支持进一步符号推理和确保有效资源分配的逻辑事实。

Result: 与标准基线相比，平均伤亡减少了 35.75%。

Conclusion: 该框架证明了逻辑编程如何为任务关键领域中模块化、可解释和操作有效的优化奠定基础。

Abstract: We present a logic programming framework that orchestrates multiple variants
of an optimization problem and reasons about their results to support
high-stakes medical decision-making. The logic programming layer coordinates
the construction and evaluation of multiple optimization formulations,
translating solutions into logical facts that support further symbolic
reasoning and ensure efficient resource allocation-specifically targeting the
"right patient, right platform, right escort, right time, right destination"
principle. This capability is integrated into GuardianTwin, a decision support
system for Forward Medical Evacuation (MEDEVAC), where rapid and explainable
resource allocation is critical. Through a series of experiments, our framework
demonstrates an average reduction in casualties by 35.75 % compared to standard
baselines. Additionally, we explore how users engage with the system via an
intuitive interface that delivers explainable insights, ultimately enhancing
decision-making in critical situations. This work demonstrates how logic
programming can serve as a foundation for modular, interpretable, and
operationally effective optimization in mission-critical domains.

</details>


### [317] [Execution and monitoring of HOA automata with HOAX](https://arxiv.org/abs/2507.11126)
*Luca Di Stefano*

Main category: cs.LO

TL;DR: Hoax is a configurable, open-source tool for executing ω-automata (HOA format) with runtime monitoring via trap sets, capable of identifying unresolvable 'ugly prefixes'. It's compared to PyContract.


<details>
  <summary>Details</summary>
Motivation: To present a tool called Hoax for the execution of ω-automata expressed in the popular HOA format, enabling runtime monitoring of acceptance conditions and identification of non-monitorable scenarios.

Method: The tool Hoax leverages the notion of trap sets for runtime monitoring of any (non-parity) acceptance condition supported by the HOA format. When the automaton is not monitorable, the tool identifies 'ugly prefixes'. The paper details the formal foundations and design of the tool and compares it against the trace analyser PyContract.

Result: Hoax leverages trap sets for runtime monitoring of acceptance conditions in ω-automata and can identify 'ugly prefixes' in non-monitorable cases. A comparison with PyContract on a lock acquisition scenario is provided.

Conclusion: The paper presents Hoax, an open-source and configurable tool for executing ω-automata in HOA format, which leverages trap sets for runtime monitoring of various acceptance conditions. It can identify 'ugly prefixes' when an automaton is not monitorable, indicating that no future observation can lead to a conclusive verdict. The tool's formal foundations, design, and comparison with PyContract on a lock acquisition scenario are also presented.

Abstract: We present a tool called Hoax for the execution of {\omega}-automata
expressed in the popular HOA format. The tool leverages the notion of trap sets
to enable runtime monitoring of any (non-parity) acceptance condition supported
by the format. When the automaton is not monitorable, the tool may still be
able to recognise so-called ugly prefixes, and determine that no further
observation will ever lead to a conclusive verdict. The tool is open-source and
highly configurable. We present its formal foundations, its design, and compare
it against the trace analyser PyContract on a lock acquisition scenario.

</details>


### [318] [Interpolation and Quantifiers in Ortholattices](https://arxiv.org/abs/2507.11141)
*Simon Guilloud,Sankalp Gambhir,Viktor Kunčak*

Main category: cs.LO

TL;DR: This paper analyzes quantifiers and interpolation in orthologic, a weaker version of classical logic. It introduces a proof system, shows interpolants exist despite no general quantifier elimination, and provides an efficient algorithm for computing them, useful for verification tasks.


<details>
  <summary>Details</summary>
Motivation: The paper studies quantifiers and interpolation properties in orthologic, a non-distributive weakening of classical logic with a quadratic-time decision procedure, aiming to provide useful tools for verification algorithms.

Method: A sequent-based proof system for quantified orthologic is presented and proven sound and complete for complete ortholattices.

Result: An efficient algorithm to compute interpolants in orthologic is provided, which is expected to be useful for establishing unreachability in verification algorithms.

Conclusion: The paper proves that orthologic does not admit quantifier elimination in general, but interpolants always exist and provides an efficient algorithm for their computation.

Abstract: We study quantifiers and interpolation properties in \emph{orthologic}, a
non-distributive weakening of classical logic that is sound for formula
validity with respect to classical logic, yet has a quadratic-time decision
procedure. We present a sequent-based proof system for quantified orthologic,
which we prove sound and complete for the class of all complete ortholattices.
We show that orthologic does not admit quantifier elimination in general.
Despite that, we show that interpolants always exist in orthologic. We give an
algorithm to compute interpolants efficiently. We expect our result to be
useful to quickly establish unreachability as a component of verification
algorithms.

</details>


### [319] [LISA -- A Modern Proof System](https://arxiv.org/abs/2507.11167)
*Simon Guilloud,Sankalp Gambhir,Viktor Kunčak*

Main category: cs.LO

TL;DR: LISA 是一个用 Scala 编写的证明系统和助手，用于模式化一阶逻辑和集合论。它使用多项式时间证明检查和斜格公理，并提供用户友好的证明构建和策略开发证明策略的工具。


<details>
  <summary>Details</summary>
Motivation: 提出一个用于模式化一阶逻辑和公理集合论的证明系统和证明助手，以提供用户友好的工具和表示法来构建证明和开发证明策略。

Method: LISA 系统的逻辑内核是一个用于模式化一阶逻辑（带等词和模式谓词/函数符号）的证明检查器。它实现了多项式时间证明检查，并使用斜格公理。它支持定理（其证明未展开）、谓词符号定义以及唯一性已证实的对象的概念。一个领域特定语言支持在 Scala 中构建证明和开发证明策略。

Result: LISA 证明系统得到了阐述，其证明的风格和抽象级别得到了说明。包括一个利用斜格性质来减小证明规模的命题重言式生成策略。此外，还展示了在 LISA 中对集合论（包括康托尔定理）的早期形式化。

Conclusion: LISA是一个用于模式化一阶逻辑和公理集合论的证明系统和证明助手，其逻辑内核实现了多项式时间证明检查，并利用了斜格公理。该系统支持定理、谓词符号定义以及唯一性已证实的对象的概念。它提供了一种领域特定语言，允许用户使用用户友好的工具和表示法来构建证明和开发证明策略，同时保留在通用语言 Scala 中。LISA 的证明风格和抽象级别得到了说明，包括一个利用斜格性质来减小证明规模的命题重言式生成策略。此外，还展示了在 LISA 中对集合论（包括康托尔定理）的早期形式化。

Abstract: We present LISA, a proof system and proof assistant for constructing proofs
in schematic first-order logic and axiomatic set theory. The logical kernel of
the system is a proof checker for first-order logic with equality and schematic
predicate and function symbols. It implements polynomial-time proof checking
and uses the axioms of ortholattices (which implies the irrelevance of the
order of conjuncts and disjuncts and additional propositional laws). The kernel
supports the notion of theorems (whose proofs are not expanded), as well as
definitions of predicate symbols and objects whose unique existence is proven.
A domain-specific language enables construction of proofs and development of
proof tactics with user-friendly tools and presentation, while remaining within
the general-purpose language, Scala. We describe the LISA proof system and
illustrate the flavour and the level of abstraction of proofs written in LISA.
This includes a proof-generating tactic for propositional tautologies,
leveraging the ortholattice properties to reduce the size of proofs. We also
present early formalization of set theory in LISA, including Cantor's theorem.

</details>


### [320] [Cancellative Convex Semilattices](https://arxiv.org/abs/2507.11186)
*Ana Sokolova,Harald Woracek*

Main category: cs.LO

TL;DR: 可换赋格是代数，它们同时是凸代数和赋格，并满足分配公理。本文证明了可换赋格是可换的当且仅当它同构于Riesz空间的凸子集。


<details>
  <summary>Details</summary>
Motivation: 本文旨在证明可换赋格是可换的当且仅当它同构于Riesz空间的凸子集。

Method: 我们证明了一个类似的定理：可换赋格是可换的当且仅当它同构于Riesz空间（即具有规范的可换赋格运算的格序向量空间）的凸子集。

Result: 可换赋格是可换的当且仅当它同构于Riesz空间的凸子集。

Conclusion: 可换赋格是赋格和凸代数，并且满足分配公理。这些代数在近年来作为概率和非确定性的合适代数而受到关注，特别是通过成为非空有限生成凸子集到分布代数上的Eilenberg-Moore代数。

Abstract: Convex semilattices are algebras that are at the same time a convex algebra
and a semilattice, together with a distributivity axiom. These algebras have
attracted some attention in the last years as suitable algebras for probability
and nondeterminism, in particular by being the Eilenberg-Moore algebras of the
nonempty finitely-generated convex subsets of the distributions monad.
  A convex semilattice is cancellative if the underlying convex algebra is
cancellative. Cancellative convex algebras have been characterized by M. H.
Stone and by H. Kneser: A convex algebra is cancellative if and only if it is
isomorphic to a convex subset of a vector space (with canonical convex algebra
operations).
  We prove an analogous theorem for convex semilattices: A convex semilattice
is cancellative if and only if it is isomorphic to a convex subset of a Riesz
space, i.e., a lattice-ordered vector space (with canonical convex semilattice
operations).

</details>


### [321] [Complexity of some modal logics of density (extended version)](https://arxiv.org/abs/2507.11238)
*Philippe Balbiani,Olivier Gasquet*

Main category: cs.LO

TL;DR: 该研究将密度单模态逻辑的可满足性问题确定为EXPTIME类，并将弱密度双模态逻辑的可满足性问题确定为PSPACE类。


<details>
  <summary>Details</summary>
Motivation: 该研究的动机是确定密度单模态逻辑和弱密度双模态逻辑的可满足性问题的计算复杂度。

Method: 通过使用选择性过滤论证证明了密度单模态逻辑的可满足性问题属于EXPTIME类；通过使用类似模型推论的方法证明了弱密度双模态逻辑的可满足性问题属于PSPACE类。

Result: 密度单模态逻辑的可满足性问题属于EXPTIME类，弱密度双模态逻辑的可满足性问题属于PSPACE类。

Conclusion: 该研究证明了密度单模态逻辑的可满足性问题属于EXPTIME类，而弱密度双模态逻辑的可满足性问题属于PSPACE类。

Abstract: By using a selective filtration argument, we prove that the satisfiability
problem of the unimodal logic of density is in $EXPTIME$. By using a
tableau-like approach, we prove that the satisfiability problem of the bimodal
logic of weak density is in $PSPACE$.

</details>


### [322] [Path-filtration for modal logics applied to revisiting quasi-dense logics](https://arxiv.org/abs/2507.11258)
*Olivier Gasquet*

Main category: cs.LO

TL;DR: 论文指出了Lyon和Ostropolski-Nalewaja关于准稠密模态逻辑可判定性证明中的一个主要缺陷，并提供了一个新的、更简单的证明，将上界从EXPSPACE改进到NEXPTIME。


<details>
  <summary>Details</summary>
Motivation: 解决Lyon和Ostropolski-Nalewaja论文中准稠密模态逻辑可判定性证明中的主要缺陷，并改进其上界。

Method: 提出了一种基于正则模型中路径的新型过滤方法。

Result: 提供了一个正确、简单、直接的证明，将假设的成员资格从EXPSPACE改进到NEXPTIME。ệc là một câu hỏi mở.

Conclusion: 准稠密模态逻辑的可判定性问题仍然是开放的，但已获得改进的上界。

Abstract: In https://arxiv.org/pdf/2405.10094 (also published at LICS'24 conference),
Lyon and Ostropolski-Nalewaja answer the question of the decidability of
quasi-dense modallogics, and give an upper bound in EXPSPACE. Unfortunately,
their intricate proof contains a major flaw that cannot be fixed, leaving the
question wide open. In this paper we provide a correct and rather simple and
direct proof of it by introducing a new variant of the well-know filtration
method based on paths in a canonical model and improve the hypothetical
membership to membership NEXPTIME.

</details>


### [323] [SC-TPTP: An Extension of the TPTP Derivation Format for Sequent-Based Calculus](https://arxiv.org/abs/2507.11349)
*Julie Cailler,Simon Guilloud*

Main category: cs.LO

TL;DR: A new format (SC-TPTP) and tools were created to transfer first-order logic proofs between automated and interactive theorem provers, demonstrated by connecting Lisa and Go'eland.


<details>
  <summary>Details</summary>
Motivation: Motivated by the transfer of proofs between proof systems, particularly from first-order automated theorem provers (ATPs) to interactive theorem provers (ITPs).

Method: Specified an extension of the TPTP derivation text format (SC-TPTP) focusing on sequent formalisms to describe first-order logic proofs, and implemented a library of tools for parsing, printing, checking, and exporting these proofs, including rebuilding low-level proof steps from advanced ones.

Result: Developed SC-TPTP format and a library of tools, enabling the Lisa proof assistant to query the Go'eland automated theorem prover and facilitating proof management and interoperability between different proof systems.

Conclusion: We specified an extension of the TPTP derivation text format to describe proofs in first-order logic called SC-TPTP, which allows the Lisa proof assistant to query the Go'eland automated theorem prover and provides a library of tools for managing SC-TPTP proofs.

Abstract: Motivated by the transfer of proofs between proof systems, and in particular
from first order automated theorem provers (ATPs) to interactive theorem
provers (ITPs), we specify an extension of the TPTP derivation text format to
describe proofs in first-order logic: SC-TPTP. To avoid multiplication of
standards, our proposed format over-specifies the TPTP derivation format by
focusing on sequent formalisms. By doing so, it provides a high level of
detail, is faithful to mathematical tradition, and cover multiple existing
tools and in particular tableaux-based strategies. We make use of this format
to allow the Lisa proof assistant to query the Go\'eland automated theorem
prover, and implement a library of tools able to parse, print and check SC-TPTP
proofs, export them into Coq files, and rebuild low-level proof steps from
advanced ones.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [324] [SAMEP: A Secure Protocol for Persistent Context Sharing Across AI Agents](https://arxiv.org/abs/2507.10562)
*Hari Masoor*

Main category: cs.AI

TL;DR: SAMEP is a framework for persistent, secure, and semantically searchable memory sharing among AI agents, reducing redundant computations and improving context relevance.


<details>
  <summary>Details</summary>
Motivation: Current AI agent architectures suffer from ephemeral memory limitations, preventing effective collaboration and knowledge sharing across sessions and agent boundaries. SAMEP addresses persistent context preservation, secure multi-agent collaboration, and efficient semantic discovery.

Method: SAMEP implements a distributed memory repository with vector-based semantic search, cryptographic access controls (AES-256-GCM), and standardized APIs compatible with existing agent communication protocols (MCP, A2A).

Result: Experimental results show 73% reduction in redundant computations, 89% improvement in context relevance scores, and complete compliance with regulatory requirements including audit trail generation.

Conclusion: SAMEP enabled a new paradigm of persistent, collaborative AI agent ecosystems while maintaining security and privacy guarantees.

Abstract: Current AI agent architectures suffer from ephemeral memory limitations,
preventing effective collaboration and knowledge sharing across sessions and
agent boundaries. We introduce SAMEP (Secure Agent Memory Exchange Protocol), a
novel framework that enables persistent, secure, and semantically searchable
memory sharing among AI agents. Our protocol addresses three critical
challenges: (1) persistent context preservation across agent sessions, (2)
secure multi-agent collaboration with fine-grained access control, and (3)
efficient semantic discovery of relevant historical context. SAMEP implements a
distributed memory repository with vector-based semantic search, cryptographic
access controls (AES-256-GCM), and standardized APIs compatible with existing
agent communication protocols (MCP, A2A). We demonstrate SAMEP's effectiveness
across diverse domains including multi-agent software development, healthcare
AI with HIPAA compliance, and multi-modal processing pipelines. Experimental
results show 73% reduction in redundant computations, 89% improvement in
context relevance scores, and complete compliance with regulatory requirements
including audit trail generation. SAMEP enables a new paradigm of persistent,
collaborative AI agent ecosystems while maintaining security and privacy
guarantees.

</details>


### [325] [AI Mother Tongue: Self-Emergent Communication in MARL via Endogenous Symbol Systems](https://arxiv.org/abs/2507.10566)
*Hung Ming Liu*

Main category: cs.AI

TL;DR: AIM框架通过内生符号系统解决MARL通信困境，无需外部偏差，实现高效通信，并提出三大理论见解。


<details>
  <summary>Details</summary>
Motivation: 为了解决分布式多智能体强化学习（MARL）中“联合探索困境”导致智能体陷入“通信真空均衡”的问题，本研究旨在探索是否可以不依赖传统的外部归纳偏差，而是通过智能体自身的内生符号系统来实现通信的涌现。

Method: 本研究采用AI Mother Tongue（AIM）框架，该框架基于向量量化变分自编码器（VQ-VAE），通过实验证明了在智能体拥有内生符号系统时，其神经表征能够自发地进行语义压缩和经历Nash均衡驱动的语义收敛，从而在无需外部归纳偏差的情况下实现有效的符号通信。研究还开发了可解释性分析工具，以验证符号使用呈现出显著的幂律分布。

Result: 实验证明，当智能体拥有内生符号系统时，其神经表征能够自发地实现语义压缩和Nash均衡驱动的语义收敛，有效达成符号通信，且无需外部归纳偏差。AIM框架相比传统的显式通信方法，展现出更强的泛化能力和效率。分析工具证实了符号使用的幂律分布特性，并引出了三个理论见解。

Conclusion: 该研究提出了一种名为“AI母语”（AIM）的框架，基于向量量化变分自编码器（VQ-VAE），证明了在拥有内生符号系统的条件下，智能体能够自发地实现语义压缩和收敛，从而在没有外部归纳偏差的情况下达成有效的符号交流。研究结果与神经科学和大型语言模型的研究发现相呼应，并提出了“神经通信假说”、“工具优先原则”和“语义可解释范式”三个理论见解，为连接符号主义和联结主义提供了新思路。

Abstract: In Decentralized Multi-Agent Reinforcement Learning (MARL), the development
of Emergent Communication has long been constrained by the ``Joint Exploration
Dilemma'', leading agents to fall into a ``Communication Vacuum Equilibrium'' .
Traditional methods address this by introducing inductive biases to facilitate
communication emergence . This study fundamentally questions whether such
artificial inductive biases are, in fact, over-engineering. Through experiments
with the ``AI Mother Tongue'' (AIM) framework, based on a Vector Quantized
Variational Autoencoder (VQ-VAE), we demonstrate that when agents possess an
endogenous symbol system, their neural representations naturally exhibit
spontaneous semantic compression and Nash equilibrium-driven semantic
convergence, achieving effective symbolic communication without external
inductive biases. This aligns with recent neuroscience findings suggesting that
the human brain does not directly use human language for internal thought , and
resonates with research on ``soft thinking'' capabilities in Large Language
Models (LLMs) . Compared to traditional explicit communication methods, AIM
demonstrates stronger generality and efficiency. The interpretable analysis
toolkit developed in this study confirms that symbol usage exhibits a
significant power-law distribution, leading to three major theoretical
insights: the ``Neural Communication Hypothesis'', the ``Tool-First
Principle'', and the ``Semantic Interpretability Paradigm''. Future research
will explore the integration of Hierarchical Quantized Variational Autoencoders
(HQ-VAE) to enhance AIM's complex expressive capabilities and investigate the
potential for ``Reinforcement Learning (RL) Low-Level Pre-training''. This
discovery offers new avenues for bridging symbolism and connectionism.

</details>


### [326] [Orchestrator-Agent Trust: A Modular Agentic AI Visual Classification System with Trust-Aware Orchestration and RAG-Based Reasoning](https://arxiv.org/abs/2507.10571)
*Konstantinos I. Roumeliotis,Ranjan Sapkota,Manoj Karkee,Nikolaos D. Tselikas*

Main category: cs.AI

TL;DR: 通过结合通用视觉智能体、推理协调器和 RAG 模块，并在苹果叶病诊断中进行评估，该研究提出了一种创新的 Agentic AI 框架，以提高零样本场景下多智能体 AI 的信任度和准确性。


<details>
  <summary>Details</summary>
Motivation: 在现代人工智能（AI）日益依赖融合视觉和语言理解的多智能体架构的背景下，如何在零样本（无需微调）设置下信任这些智能体是一个关键挑战。

Method: 提出了一种模块化 Agentic AI 视觉分类框架，该框架集成了通用多模态智能体、非视觉推理协调器和检索增强生成（RAG）模块。通过三种配置进行基准测试：(I) 零样本置信度协调；(II) 微调智能体；(III) 基于 CLIP 图像检索和重新评估循环增强的信任校准协调。使用置信度校准指标（ECE, OCR, CCC）来调节智能体之间的信任度。

Result: 在苹果叶病诊断应用中，零样本设置下使用信任感知协调和 RAG 的方法，准确率提高了 77.94%，达到 85.63%。GPT-4o 表现出更好的校准性，而 Qwen-2.5-VL 则存在过度自信问题。图像 RAG 通过视觉相似案例的关联，实现了对智能体过度自信的纠正。

Conclusion: 该研究提出了一个创新的模块化 Agentic AI 视觉分类框架，通过集成通用多模态智能体、非视觉推理协调器和检索增强生成（RAG）模块，解决了在零样本设置下信任多智能体 AI 的挑战。实验证明，结合信任感知协调和 RAG 的零样本方法，准确率提高了 77.94%，总体达到 85.63%。该框架将感知（视觉智能体）与元推理（协调器）分离，提高了可扩展性和可解释性，并可应用于诊断、生物学和其他信任关键领域。

Abstract: Modern Artificial Intelligence (AI) increasingly relies on multi-agent
architectures that blend visual and language understanding. Yet, a pressing
challenge remains: How can we trust these agents especially in zero-shot
settings with no fine-tuning? We introduce a novel modular Agentic AI visual
classification framework that integrates generalist multimodal agents with a
non-visual reasoning orchestrator and a Retrieval-Augmented Generation (RAG)
module. Applied to apple leaf disease diagnosis, we benchmark three
configurations: (I) zero-shot with confidence-based orchestration, (II)
fine-tuned agents with improved performance, and (III) trust-calibrated
orchestration enhanced by CLIP-based image retrieval and re-evaluation loops.
Using confidence calibration metrics (ECE, OCR, CCC), the orchestrator
modulates trust across agents. Our results demonstrate a 77.94\% accuracy
improvement in the zero-shot setting using trust-aware orchestration and RAG,
achieving 85.63\% overall. GPT-4o showed better calibration, while Qwen-2.5-VL
displayed overconfidence. Furthermore, image-RAG grounded predictions with
visually similar cases, enabling correction of agent overconfidence via
iterative re-evaluation. The proposed system separates perception (vision
agents) from meta-reasoning (orchestrator), enabling scalable and interpretable
multi-agent AI. This blueprint is extensible to diagnostics, biology, and other
trust-critical domains. All models, prompts, results, and system components
including the complete software source code are openly released to support
reproducibility, transparency, and community benchmarking at Github:
https://github.com/Applied-AI-Research-Lab/Orchestrator-Agent-Trust

</details>


### [327] [From Semantic Web and MAS to Agentic AI: A Unified Narrative of the Web of Agents](https://arxiv.org/abs/2507.10644)
*Tatiana Petrova,Aleksandr Puzikov,Boris Bliznukov,Radu State*

Main category: cs.AI

TL;DR: 本研究首次全面回顾了WoA的演变历程，提出了一种新的分类法，揭示了从语义网和MAS到LLM驱动的代理的清晰演变脉络，并指出了WoA未来的研究方向在于解决社会技术挑战。


<details>
  <summary>Details</summary>
Motivation: 当前关于Web of Agents（WoA）的研究分散在不同的社区，将大型语言模型（LLM）驱动的框架、多智能体系统（MAS）和语义网（Semantic Web）的历史视为独立的领域，阻碍了对该领域发展轨迹的整体理解。

Method: 提出一个四轴分类法（语义基础、通信范式、智能中心、发现机制）来系统化分析，并提供了一个统一的分析视角来比较所有代的代理架构。

Result: 展示了现代协议（如A2A和MCP）是早期标准（如FIPA和基于OWL的语义代理）局限性的直接演变结果。识别出“智能中心”的范式转变：从编码在外部数据（语义网）或平台（MAS）中，转变为嵌入代理的核心模型（LLM）中。

Conclusion: 虽然新的协议至关重要，但它们不足以构建一个健壮、开放、可信的生态系统。下一研究前沿在于解决持续存在的社会技术挑战，并为新兴的代理网络（WoA）制定关于去中心化身份、经济模型、安全和治理的新议程。

Abstract: The concept of the Web of Agents (WoA), which transforms the static,
document-centric Web into an environment of autonomous agents acting on users'
behalf, has attracted growing interest as large language models (LLMs) become
more capable. However, research in this area is still fragmented across
different communities. Contemporary surveys catalog the latest LLM-powered
frameworks, while the rich histories of Multi-Agent Systems (MAS) and the
Semantic Web are often treated as separate, legacy domains. This fragmentation
obscures the intellectual lineage of modern systems and hinders a holistic
understanding of the field's trajectory. We present the first comprehensive
evolutionary overview of the WoA. We show that modern protocols like A2A and
the MCP, are direct evolutionary responses to the well-documented limitations
of earlier standards like FIPA standards and OWL-based semantic agents. To
systematize this analysis, we introduce a four-axis taxonomy (semantic
foundation, communication paradigm, locus of intelligence, discovery
mechanism). This framework provides a unified analytical lens for comparing
agent architectures across all generations, revealing a clear line of descent
where others have seen a disconnect. Our analysis identifies a paradigm shift
in the 'locus of intelligence': from being encoded in external data (Semantic
Web) or the platform (MAS) to being embedded within the agent's core model
(LLM). This shift is foundational to modern Agentic AI, enabling the scalable
and adaptive systems the WoA has long envisioned. We conclude that while new
protocols are essential, they are insufficient for building a robust, open,
trustworthy ecosystem. Finally, we argue that the next research frontier lies
in solving persistent socio-technical challenges, and we map out a new agenda
focused on decentralized identity, economic models, security, and governance
for the emerging WoA.

</details>


### [328] [Comprehension Without Competence: Architectural Limits of LLMs in Symbolic Computation and Reasoning](https://arxiv.org/abs/2507.10624)
*Zheng Zhang*

Main category: cs.AI

TL;DR: LLMs在推理任务中存在“计算性分裂脑”问题，即理解与执行脱节，限制了其可靠应用知识的能力。


<details>
  <summary>Details</summary>
Motivation: LLMs虽然具有出色的表面流畅性，但在符号推理、算术准确性和逻辑一致性方面存在系统性问题。

Method: 通过受控实验和架构分析来诊断LLMs的缺陷。

Result: LLMs经常能够阐述正确的原理但无法可靠地应用它们，这种“计算性“分裂脑”综合征”的局限性在不同领域普遍存在，即使在理想化的提示下模型行为仍然脆弱。

Conclusion: LLMs在需要符号推理、算术准确性和逻辑一致性的任务中存在系统性缺陷，这源于“理解”与“能力”之间的差距，表现为“计算性“分裂脑”综合征”，即指令和动作路径在几何和功能上分离。LLMs是强大的模式补全引擎，但缺乏结构化的推理能力。

Abstract: Large Language Models (LLMs) display striking surface fluency yet
systematically fail at tasks requiring symbolic reasoning, arithmetic accuracy,
and logical consistency. This paper offers a structural diagnosis of such
failures, revealing a persistent gap between \textit{comprehension} and
\textit{competence}. Through controlled experiments and architectural analysis,
we demonstrate that LLMs often articulate correct principles without reliably
applying them--a failure rooted not in knowledge access, but in computational
execution. We term this phenomenon the computational \textit{split-brain
syndrome}, where instruction and action pathways are geometrically and
functionally dissociated. This core limitation recurs across domains, from
mathematical operations to relational inferences, and explains why model
behavior remains brittle even under idealized prompting. We argue that LLMs
function as powerful pattern completion engines, but lack the architectural
scaffolding for principled, compositional reasoning. Our findings delineate the
boundary of current LLM capabilities and motivate future models with
metacognitive control, principle lifting, and structurally grounded execution.
This diagnosis also clarifies why mechanistic interpretability findings may
reflect training-specific pattern coordination rather than universal
computational principles, and why the geometric separation between instruction
and execution pathways suggests limitations in neural introspection and
mechanistic analysis.

</details>


### [329] [Taming Uncertainty via Automation: Observing, Analyzing, and Optimizing Agentic AI Systems](https://arxiv.org/abs/2507.11277)
*Dany Moshkovich,Sergey Zeltyn*

Main category: cs.AI

TL;DR: AgentOps是一个用于运维LLM驱动的自主智能体系统的框架，通过自动化流程管理不确定性，实现系统的安全有效运行。


<details>
  <summary>Details</summary>
Motivation: 现有软件运维实践难以应对LLM驱动的自主智能体系统中固有的不确定性问题。

Method: 提出AgentOps框架，包含行为观察、指标收集、问题检测、根本原因分析、优化建议和运行时自动化六个阶段的自动化运维流程。

Result: AgentOps为开发者、测试者、SRE和业务用户提供了跨越系统生命周期不同阶段的运维解决方案，实现了AI系统的自我改进。

Conclusion: AgentOps通过自动化管理不确定性，实现AI系统的安全、自适应和有效运行。

Abstract: Large Language Models (LLMs) are increasingly deployed within agentic
systems-collections of interacting, LLM-powered agents that execute complex,
adaptive workflows using memory, tools, and dynamic planning. While enabling
powerful new capabilities, these systems also introduce unique forms of
uncertainty stemming from probabilistic reasoning, evolving memory states, and
fluid execution paths. Traditional software observability and operations
practices fall short in addressing these challenges.
  This paper introduces AgentOps: a comprehensive framework for observing,
analyzing, optimizing, and automating operation of agentic AI systems. We
identify distinct needs across four key roles-developers, testers, site
reliability engineers (SREs), and business users-each of whom engages with the
system at different points in its lifecycle. We present the AgentOps Automation
Pipeline, a six-stage process encompassing behavior observation, metric
collection, issue detection, root cause analysis, optimized recommendations,
and runtime automation. Throughout, we emphasize the critical role of
automation in managing uncertainty and enabling self-improving AI systems-not
by eliminating uncertainty, but by taming it to ensure safe, adaptive, and
effective operation.

</details>


### [330] [Perspective-Aware AI in Extended Reality](https://arxiv.org/abs/2507.11479)
*Daniel Platnick,Matti Gruener,Marjan Alirezaie,Kent Larson,Dava J. Newman,Hossein Rahnama*

Main category: cs.AI

TL;DR: PAiR是一个将视角感知AI（PAi）与XR集成的框架，通过利用基于多模态数字足迹学习的用户身份模型，实现可解释、情境感知的沉浸式体验。


<details>
  <summary>Details</summary>
Motivation: 当前的XR系统由于用户模型肤浅和认知背景有限，无法提供自适应、沉浸式的体验。

Method: PAiR是一个基础框架，它将视角感知AI（PAi）与XR集成，以实现可解释的、上下文感知的、以用户身份为基础的体验。PAi基于Chronicles构建，Chronicles是基于多模态数字足迹学习的、可推理的身份模型，能够捕捉用户认知和经验的演变。PAiR在闭环系统中运用这些模型，将动态用户状态与沉浸式环境联系起来。

Result: 展示了PAiR的架构，详细介绍了其模块和系统流程，并通过在基于Unity的OpenDome引擎中实现的两个概念验证场景证明了其效用。

Conclusion: PAiR通过将基于视角的身份模型嵌入沉浸式系统，为人机交互开辟了新方向。

Abstract: AI-enhanced Extended Reality (XR) aims to deliver adaptive, immersive
experiences-yet current systems fall short due to shallow user modeling and
limited cognitive context. We introduce Perspective-Aware AI in Extended
Reality (PAiR), a foundational framework for integrating Perspective-Aware AI
(PAi) with XR to enable interpretable, context-aware experiences grounded in
user identity. PAi is built on Chronicles: reasoning-ready identity models
learned from multimodal digital footprints that capture users' cognitive and
experiential evolution. PAiR employs these models in a closed-loop system
linking dynamic user states with immersive environments. We present PAiR's
architecture, detailing its modules and system flow, and demonstrate its
utility through two proof-of-concept scenarios implemented in the Unity-based
OpenDome engine. PAiR opens a new direction for human-AI interaction by
embedding perspective-based identity models into immersive systems.

</details>


### [331] [Enhancing the Capabilities of Large Language Models for API calls through Knowledge Graphs](https://arxiv.org/abs/2507.10630)
*Ye Yang,Xue Xiao,Ping Yin,Taotao Xie*

Main category: cs.AI

TL;DR: KG2data 通过集成知识图谱、LLM 和 ReAct 代理，在气象领域实现了智能数据分析和问答，其 API 调用准确性优于现有方法，并解决了 LLM 在处理领域特定知识方面的局限性。


<details>
  <summary>Details</summary>
Motivation: 然而，在气象学等知识密集型领域，LLM 通过 API 调用有效利用工具的能力仍有待探索。现有系统在处理复杂或术语丰富的查询时存在局限性，因为它们对领域特定知识的访问有限。

Method: KG2data 系统集成了知识图谱、大型语言模型 (LLM)、ReAct 代理和工具使用技术，以实现气象领域的智能数据采集和查询处理。通过使用虚拟 API，根据名称识别失败、幻觉失败和调用正确性这三个指标评估 API 调用准确性。

Result: KG2data 在 API 调用准确性方面表现优于 RAG2data 和 chat2data，具体指标分别为（1.43%、0%、88.57%），而 RAG2data 为（16%、10%、72.14%），chat2data 为（7.14%、8.57%、71.43%）。KG2data 通过将知识图谱用作持久内存，增强了内容检索、复杂查询处理、领域特定推理、语义关系解析和异构数据集成，并降低了对 LLM 进行微调的高昂成本。

Conclusion: KG2data 提供了一种新颖的解决方案，可在知识密集型领域中实现智能的、基于知识的问答和数据分析。

Abstract: API calls by large language models (LLMs) offer a cutting-edge approach for
data analysis. However, their ability to effectively utilize tools via API
calls remains underexplored in knowledge-intensive domains like meteorology.
This paper introduces KG2data, a system that integrates knowledge graphs, LLMs,
ReAct agents, and tool-use technologies to enable intelligent data acquisition
and query handling in the meteorological field. Using a virtual API, we
evaluate API call accuracy across three metrics: name recognition failure,
hallucination failure, and call correctness. KG2data achieves superior
performance (1.43%, 0%, 88.57%) compared to RAG2data (16%, 10%, 72.14%) and
chat2data (7.14%, 8.57%, 71.43%). KG2data differs from typical LLM-based
systems by addressing their limited access to domain-specific knowledge, which
hampers performance on complex or terminology-rich queries. By using a
knowledge graph as persistent memory, our system enhances content retrieval,
complex query handling, domain-specific reasoning, semantic relationship
resolution, and heterogeneous data integration. It also mitigates the high cost
of fine-tuning LLMs, making the system more adaptable to evolving domain
knowledge and API structures. In summary, KG2data provides a novel solution for
intelligent, knowledge-based question answering and data analysis in domains
with high knowledge demands.

</details>


### [332] [Parsing Musical Structure to Enable Meaningful Variations](https://arxiv.org/abs/2507.10740)
*Maziar Kanani,Sean O Leary,James McDermott*

Main category: cs.AI

TL;DR: 本研究提出一种基于语法的音乐生成方法，通过变异现有曲调的语法结构来生成新的音乐，并分析了变异过程对音乐的影响。


<details>
  <summary>Details</summary>
Motivation: 本研究旨在探索一种新颖的音乐生成方法，通过对现有曲调进行结构化变异来自动生成新的、相关的音乐。

Method: 本研究提出了一种新颖的基于规则的方法，通过变异现有曲调来生成音乐。首先，使用 Sequitur 算法解析曲调以提取其 Pathway Assembly (PA) 结构，形成一个语法。然后，对该语法进行多种类型的变异（如添加、删除、交换或反转部分），以生成新的曲调。研究中还分析了不同变异类型对曲调的影响，并从编辑距离、结构复杂性和长度等方面评估了变异对曲调的改变。

Result: 研究结果展示了通过对音乐语法进行变异可以生成新的音高序列，并量化了这些变异对曲调的逐步影响，包括编辑距离、结构复杂性和长度的变化，同时还分析了不同变异类型的影响效果和输处音乐的音乐性。

Conclusion: 该研究通过对现有曲调进行变异来生成新音乐，并分析了变异对曲调的逐步影响。

Abstract: This paper presents a novel rule-based approach for generating music by
varying existing tunes. We parse each tune to find the Pathway Assembly (PA) [
1], that is a structure representing all repetitions in the tune. The Sequitur
algorithm [2 ] is used for this. The result is a grammar. We then carry out
mutation on the grammar, rather than on a tune directly. There are potentially
19 types of mutations such as adding, removing, swapping or reversing parts of
the grammar that can be applied to the grammars. The system employs one of the
mutations randomly in this step to automatically manipulate the grammar.
Following the mutation, we need to expand the grammar which returns a new tune.
The output after 1 or more mutations will be a new tune related to the original
tune. Our study examines how tunes change gradually over the course of multiple
mutations. Edit distances, structural complexity and length of the tunes are
used to show how a tune is changed after multiple mutations. In addition, the
size of effect of each mutation type is analyzed. As a final point, we review
the musical aspect of the output tunes. It should be noted that the study only
focused on generating new pitch sequences. The study is based on an Irish
traditional tune dataset and a list of integers has been used to represent each
tune's pitch values.

</details>


### [333] [AI and the Net-Zero Journey: Energy Demand, Emissions, and the Potential for Transition](https://arxiv.org/abs/2507.10750)
*Pandu Devarakota,Nicolas Tsesmetzis,Faruk O. Alpak,Apurva Gala,Detlef Hohl*

Main category: cs.AI

TL;DR: AI在短期内会增加碳排放，但长期来看，通过优化能源利用，AI可以大幅减少碳排放，最终对气候产生积极影响。


<details>
  <summary>Details</summary>
Motivation: 评估AI在发展和运营过程中对数据中心能源消耗和温室气体排放的影响，并探讨AI在能源生产、供应和消费领域的应用潜力，以解决AI对气候变化的净效应这一核心问题。

Method: 本文是一篇技术综述文章，通过分析数据中心的能源消耗情景和温室气体排放影响，并结合近期（至2030年）和长期（2035年及以后）的预测，探讨AI对二氧化碳排放的净效应，并讨论AI在能源领域的自动化和效率提升潜力。

Result: 近期预测显示，AI需求增长将导致电力消耗和相关二氧化碳排放增加。然而，长期来看，AI通过自动化和优化各行业流程（从能源生产到物流），有潜力显著降低碳足迹，其积极影响预计将超过初期的排放增长。

Conclusion: 虽然AI在短期内可能因数据中心和模型训练的电力需求而增加碳排放，但从长远来看，AI有潜力通过优化能源生产、供应链和消费来大幅减少碳排放，其积极影响有望抵消初始的增长，从而支持气候减缓工作。

Abstract: Thanks to the availability of massive amounts of data, computing resources,
and advanced algorithms, AI has entered nearly every sector. This has sparked
significant investment and interest, particularly in building data centers with
the necessary hardware and software to develop and operate AI models and
AI-based workflows. In this technical review article, we present energy
consumption scenarios of data centers and impact on GHG emissions, considering
both near-term projections (up to 2030) and long-term outlook (2035 and
beyond). We address the quintessential question of whether AI will have a net
positive, neutral, or negative impact on CO2 emissions by 2035. Additionally,
we discuss AI's potential to automate, create efficient and disruptive
workflows across various fields related to energy production, supply and
consumption. In the near-term scenario, the growing demand for AI will likely
strain computing resources, lead to increase in electricity consumption and
therefore associated CO2 emissions. This is due to the power-hungry nature of
big data centers and the requirements for training and running of large and
complex AI models, as well as the penetration of AI assistant search and
applications for public use. However, the long-term outlook could be more
promising. AI has the potential to be a game-changer in CO2 reduction. Its
ability to further automate and optimize processes across industries, from
energy production to logistics, could significantly decrease our carbon
footprint. This positive impact is anticipated to outweigh the initial
emissions bump, creating value for businesses and society in areas where
traditional solutions have fallen short. In essence, AI might cause some
initial growing pains for the environment, but it has the potential to support
climate mitigation efforts.

</details>


### [334] [IoT Malware Network Traffic Detection using Deep Learning and GraphSAGE Models](https://arxiv.org/abs/2507.10758)
*Nikesh Prajapati,Bimal Karki,Saroj Gopali,Akbar Siami Namin*

Main category: cs.AI

TL;DR: 本文评估了多种深度学习模型（包括BERT、TCN、Multi-Head Attention、GraphSAGE、BI-LSTM）在物联网恶意流量检测中的性能。结果显示，BERT表现最佳，准确率和多项关键指标接近100%；Multi-Head Attention性能良好但处理时间长；GraphSAGE训练快但性能较低。


<details>
  <summary>Details</summary>
Motivation: 物联网系统流量模式具有序列性和多样性，其中蕴含丰富的时序模式供模型学习，因此本文旨在利用深度学习模型检测物联网恶意攻击，并对所选模型进行全面评估。

Method: 本文通过深度学习模型，特别是GraphSAGE、Transformer的BERT、TCN以及Multi-Head Attention、BI-LSTM Multi-Head Attention和BI-LSTM与LSTM模型，来检测物联网的恶意攻击。对这些模型在恶意网络流量检测方面的性能进行了全面评估。

Result: 实验结果表明，BERT模型的性能最优，准确率高达99.94%，精确率、召回率、F1分数和AUC-ROC分数也达到了99.99%。Multi-Head Attention模型检测能力良好且结果可解释，但处理时间长。GraphSAGE模型训练时间最短，但各项性能指标最低。

Conclusion: BERT模型在检测物联网恶意攻击方面表现最佳，准确率达到99.94%，并具有高精确率、召回率、F1分数和AUC-ROC分数（均为99.99%），这得益于其强大的时序依赖捕捉能力。Multi-Head Attention模型也展现了良好的检测能力和可解释性，但处理时间较长。GraphSAGE模型训练时间最短，但准确率、精确率和F1分数最低。

Abstract: This paper intends to detect IoT malicious attacks through deep learning
models and demonstrates a comprehensive evaluation of the deep learning and
graph-based models regarding malicious network traffic detection. The models
particularly are based on GraphSAGE, Bidirectional encoder representations from
transformers (BERT), Temporal Convolutional Network (TCN) as well as Multi-Head
Attention, together with Bidirectional Long Short-Term Memory (BI-LSTM)
Multi-Head Attention and BI-LSTM and LSTM models. The chosen models
demonstrated great performance to model temporal patterns and detect feature
significance. The observed performance are mainly due to the fact that IoT
system traffic patterns are both sequential and diverse, leaving a rich set of
temporal patterns for the models to learn. Experimental results showed that
BERT maintained the best performance. It achieved 99.94% accuracy rate
alongside high precision and recall, F1-score and AUC-ROC score of 99.99% which
demonstrates its capabilities through temporal dependency capture. The
Multi-Head Attention offered promising results by providing good detection
capabilities with interpretable results. On the other side, the Multi-Head
Attention model required significant processing time like BI-LSTM variants. The
GraphSAGE model achieved good accuracy while requiring the shortest training
time but yielded the lowest accuracy, precision, and F1 score compared to the
other models

</details>


### [335] [Detecting AI Assistance in Abstract Complex Tasks](https://arxiv.org/abs/2507.10761)
*Tyler King,Nikolos Gurney,John H. Miller,Volkan Ustun*

Main category: cs.AI

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Detecting assistance from artificial intelligence is increasingly important
as they become ubiquitous across complex tasks such as text generation, medical
diagnosis, and autonomous driving. Aid detection is challenging for humans,
especially when looking at abstract task data. Artificial neural networks excel
at classification thanks to their ability to quickly learn from and process
large amounts of data -- assuming appropriate preprocessing. We posit detecting
help from AI as a classification task for such models. Much of the research in
this space examines the classification of complex but concrete data classes,
such as images. Many AI assistance detection scenarios, however, result in data
that is not machine learning-friendly. We demonstrate that common models can
effectively classify such data when it is appropriately preprocessed. To do so,
we construct four distinct neural network-friendly image formulations along
with an additional time-series formulation that explicitly encodes the
exploration/exploitation of users, which allows for generalizability to other
abstract tasks. We benchmark the quality of each image formulation across three
classical deep learning architectures, along with a parallel CNN-RNN
architecture that leverages the additional time series to maximize testing
performance, showcasing the importance of encoding temporal and spatial
quantities for detecting AI aid in abstract tasks.

</details>


### [336] [Fine-grained Timing Analysis of Digital Integrated Circuits in Answer Set Programming](https://arxiv.org/abs/2507.11150)
*Alessandro Bertagnon,Marcello Dalpasso,Michele Favalli,Marco Gavanelli*

Main category: cs.AI

TL;DR: This paper presents a method using Answer Set Programming (ASP) to accurately calculate the maximum delay in integrated circuits, a task traditionally approximated. Experiments show ASP is effective for hardware design challenges.


<details>
  <summary>Details</summary>
Motivation: To compute the actual maximum delay in integrated circuits, rather than an upper bound, to avoid suboptimal processor speeds and missed performance opportunities.

Method: Modeling the maximum delay problem in Answer Set Programming (ASP) using non-trivial encodings.

Result: Experimental results demonstrate the viability of ASP for addressing complex problems in hardware design.

Conclusion: ASP is a viable solution for computing the actual maximum delay in integrated circuits, which can lead to better processor speeds compared to traditional methods.

Abstract: In the design of integrated circuits, one critical metric is the maximum
delay introduced by combinational modules within the circuit. This delay is
crucial because it represents the time required to perform a computation: in an
Arithmetic-Logic Unit it represents the maximum time taken by the circuit to
perform an arithmetic operation. When such a circuit is part of a larger,
synchronous system, like a CPU, the maximum delay directly impacts the maximum
clock frequency of the entire system. Typically, hardware designers use Static
Timing Analysis to compute an upper bound of the maximum delay because it can
be determined in polynomial time. However, relying on this upper bound can lead
to suboptimal processor speeds, thereby missing performance opportunities. In
this work, we tackle the challenging task of computing the actual maximum
delay, rather than an approximate value. Since the problem is computationally
hard, we model it in Answer Set Programming (ASP), a logic language featuring
extremely efficient solvers. We propose non-trivial encodings of the problem
into ASP. Experimental results show that ASP is a viable solution to address
complex problems in hardware design.

</details>


### [337] [Uncertainty-Informed Scheduling of Decision Points for Intelligent Mobile Health Interventions](https://arxiv.org/abs/2507.10798)
*Asim H. Gazi,Bhanu T. Gullapalli,Daiqi Gao,Benjamin M. Marlin,Vivek Shetty,Susan A. Murphy*

Main category: cs.AI

TL;DR: 为了解决mHealth干预中固定决策点调度的问题，本文提出了一种名为SigmaScheduling的新方法。该方法根据对用户行为时间预测的不确定性来动态调整决策点，提高了干预的及时性，尤其适用于Oralytics等旨在改善口腔卫生等习惯性行为的mHealth应用。实验结果表明，SigmaScheduling能显著提高决策点在用户行为发生前被安排的几率，从而提升干预效果。


<details>
  <summary>Details</summary>
Motivation: 目前的mHealth干预措施（如JITAIs）在安排决策点时采用固定的时间间隔，这种“一刀切”的方法对于日常规律不规律的个体效果不佳，常常导致决策点安排在目标行为发生之后，使得干预措施失效。

Method: SigmaScheduling是一种动态调度决策点的方法，它基于对预期行为时间的预测不确定性。当行为时间更具可预测性时，SigmaScheduling将决策点安排在更接近预期行为的时间；当不确定性更高时，SigmaScheduling则会提前安排决策点，以增加及时干预的可能性。

Result: 在对Oralytics（一项旨在改善日常刷牙习惯的JITAI）的为期10周、涉及68名参与者的真实世界数据进行的评估中，SigmaScheduling将决策点安排在刷牙事件之前的几率提高了70%以上，从而保留了干预并影响行为的机会。

Conclusion: SigmaScheduling可以推进精准的mHealth，特别是针对那些有时间敏感性、习惯性行为（如口腔卫生或饮食习惯）的JITAIs。

Abstract: Timely decision making is critical to the effectiveness of mobile health
(mHealth) interventions. At predefined timepoints called "decision points,"
intelligent mHealth systems such as just-in-time adaptive interventions
(JITAIs) estimate an individual's biobehavioral context from sensor or survey
data and determine whether and how to intervene. For interventions targeting
habitual behavior (e.g., oral hygiene), effectiveness often hinges on
delivering support shortly before the target behavior is likely to occur.
Current practice schedules decision points at a fixed interval (e.g., one hour)
before user-provided behavior times, and the fixed interval is kept the same
for all individuals. However, this one-size-fits-all approach performs poorly
for individuals with irregular routines, often scheduling decision points after
the target behavior has already occurred, rendering interventions ineffective.
In this paper, we propose SigmaScheduling, a method to dynamically schedule
decision points based on uncertainty in predicted behavior times. When behavior
timing is more predictable, SigmaScheduling schedules decision points closer to
the predicted behavior time; when timing is less certain, SigmaScheduling
schedules decision points earlier, increasing the likelihood of timely
intervention. We evaluated SigmaScheduling using real-world data from 68
participants in a 10-week trial of Oralytics, a JITAI designed to improve daily
toothbrushing. SigmaScheduling increased the likelihood that decision points
preceded brushing events in at least 70% of cases, preserving opportunities to
intervene and impact behavior. Our results indicate that SigmaScheduling can
advance precision mHealth, particularly for JITAIs targeting time-sensitive,
habitual behaviors such as oral hygiene or dietary habits.

</details>


### [338] [Automated Thematic Analyses Using LLMs: Xylazine Wound Management Social Media Chatter Use Case](https://arxiv.org/abs/2507.10803)
*JaMor Hairston,Ritvik Ranjan,Sahithi Lakamana,Anthony Spadaro,Selen Bozkurt,Jeanmarie Perrone,Abeed Sarker*

Main category: cs.AI

TL;DR: 本研究发现，通过少次提示，LLM可以有效进行社交媒体数据的归纳主题分析，并且在某些方面能媲美甚至超越专家分析，为定性研究提供了一种可扩展的辅助方法。


<details>
  <summary>Details</summary>
Motivation: 评估使用大型语言模型（LLM）复制专家驱动的社交媒体数据归纳主题分析的可行性，因为LLM在处理需要深度解释和领域专业知识的任务时面临挑战。

Method: 研究人员使用了两个不相交的Reddit数据集（分别包含286和686条关于xylazine的帖子），并结合了12个由专家确定的主题。他们采用了零次、一次和少次提示策略，将这项任务建模为一系列二元分类问题，而不是单一的多标签分类问题。使用准确率、精确率、召回率和F1分数来衡量模型性能。

Result: 在验证集上，GPT-4o采用两次提示策略表现最佳，准确率为90.9%，F1分数为0.71。对于高流行度的主题，模型得出的主题分布与专家分类非常接近（例如，xylazine使用：13.6% vs. 17.8%；MOUD使用：16.5% vs. 17.8%）。

Conclusion: LLM在定性研究中可以作为一种可扩展的补充，用于主题分析。

Abstract: Background Large language models (LLMs) face challenges in inductive thematic
analysis, a task requiring deep interpretive and domain-specific expertise. We
evaluated the feasibility of using LLMs to replicate expert-driven thematic
analysis of social media data. Methods Using two temporally non-intersecting
Reddit datasets on xylazine (n=286 and n=686, for model optimization and
validation, respectively) with twelve expert-derived themes, we evaluated five
LLMs against expert coding. We modeled the task as a series of binary
classifications, rather than a single, multi-label classification, employing
zero-, single-, and few-shot prompting strategies and measuring performance via
accuracy, precision, recall, and F1-score. Results On the validation set,
GPT-4o with two-shot prompting performed best (accuracy: 90.9%; F1-score:
0.71). For high-prevalence themes, model-derived thematic distributions closely
mirrored expert classifications (e.g., xylazine use: 13.6% vs. 17.8%; MOUD use:
16.5% vs. 17.8%). Conclusions Our findings suggest that few-shot LLM-based
approaches can automate thematic analyses, offering a scalable supplement for
qualitative research. Keywords: thematic analysis, large language models,
natural language processing, qualitative analysis, social media, prompt
engineering, public health

</details>


### [339] [AF-XRAY: Visual Explanation and Resolution of Ambiguity in Legal Argumentation Frameworks](https://arxiv.org/abs/2507.10831)
*Yilin Xia,Heng Zheng,Shawn Bowers,Bertram Ludäscher*

Main category: cs.AI

TL;DR: AF-XRAY 是一个开源工具包，用于探索、分析和可视化法律推理中的抽象框架，通过分层可视化、攻击边分类、替代语义叠加和关键攻击集识别来解决歧义和解释论点可接受性问题。


<details>
  <summary>Details</summary>
Motivation: 为了应对非专家在法律推理中识别歧义来源和解释论点可接受性的挑战，我们提出了 AF-XRAY 工具包。

Method: AF-XRAY 工具包通过以下方式进行分析：(i) 基于博弈论论点长度的分层可视化，揭示有根据的推导结构；(ii) 按语义角色（主要、次要、失误）对攻击边进行分类；(iii) 在模糊的三值基本语义上叠加替代的两值解的可视化；(iv) 识别可悬挂以解决未定论点的关键攻击集。

Result: 通过系统生成关键攻击集，AF-XRAY 将模糊场景转化为可解释的结论，使用户能够精确找出歧义的具体原因并探索替代解决方案。我们使用实际法律案例（例如，Bench-Capon 建模的“野生动物”案例）证明，我们的工具通过揭示不同假设如何导致不同的既定结论，支持目的论的法律推理。

Conclusion: AF-XRAY 能够帮助用户识别法律推理中的歧义来源并解释论点可接受性，其通过分层可视化、攻击边分类、替代语义可视化以及关键攻击集识别等功能，将模糊场景转化为可解释的结论。

Abstract: Argumentation frameworks (AFs) provide formal approaches for legal reasoning,
but identifying sources of ambiguity and explaining argument acceptance remains
challenging for non-experts. We present AF-XRAY, an open-source toolkit for
exploring, analyzing, and visualizing abstract AFs in legal reasoning. AF-XRAY
introduces: (i) layered visualizations based on game-theoretic argument length
revealing well-founded derivation structures; (ii) classification of attack
edges by semantic roles (primary, secondary, blunders); (iii) overlay
visualizations of alternative 2-valued solutions on ambiguous 3-valued grounded
semantics; and (iv) identification of critical attack sets whose suspension
resolves undecided arguments. Through systematic generation of critical attack
sets, AF-XRAY transforms ambiguous scenarios into grounded solutions, enabling
users to pinpoint specific causes of ambiguity and explore alternative
resolutions. We use real-world legal cases (e.g., Wild Animals as modeled by
Bench-Capon) to show that our tool supports teleological legal reasoning by
revealing how different assumptions lead to different justified conclusions.

</details>


### [340] [NavComposer: Composing Language Instructions for Navigation Trajectories through Action-Scene-Object Modularization](https://arxiv.org/abs/2507.10894)
*Zongtao He,Liuyi Wang,Lu Chen,Chengju Liu,Qijun Chen*

Main category: cs.AI

TL;DR: NavComposer 和 NavInstrCritic 框架自动生成和评估导航指令，解决了现有方法在数量和质量上的不足，并支持更广泛的应用。


<details>
  <summary>Details</summary>
Motivation: 专家提供的导航指令数量有限，合成的标注质量不高，不足以支持大规模研究。现有评估方法依赖专家标注，存在局限性。

Method: 提出NavComposer框架，通过显式分解和重组语义实体（动作、场景、对象）来自动生成导航指令，并介绍了NavInstrCritic评估系统，该系统从对比匹配、语义一致性和语言多样性三个维度进行无标注评估。

Result: 通过大量实验证明了该方法的有效性，为可扩展和可泛化的研究提供了支持。

Conclusion: NavComposer通过明确分解和重组语义实体（如动作、场景和对象）来自动生成高质量的导航指令，其模块化架构可灵活集成最先进的技术，并增强指令的丰富性和准确性。NavInstrCritic是一个无标注的评估系统，从对比匹配、语义一致性和语言多样性三个维度评估导航指令质量，克服了传统依赖专家标注的评估方法的局限性。该方法通过将指令生成和评估与特定导航代理分离，实现了更具可扩展性和通用性的研究。

Abstract: Language-guided navigation is a cornerstone of embodied AI, enabling agents
to interpret language instructions and navigate complex environments. However,
expert-provided instructions are limited in quantity, while synthesized
annotations often lack quality, making them insufficient for large-scale
research. To address this, we propose NavComposer, a novel framework for
automatically generating high-quality navigation instructions. NavComposer
explicitly decomposes semantic entities such as actions, scenes, and objects,
and recomposes them into natural language instructions. Its modular
architecture allows flexible integration of state-of-the-art techniques, while
the explicit use of semantic entities enhances both the richness and accuracy
of instructions. Moreover, it operates in a data-agnostic manner, supporting
adaptation to diverse navigation trajectories without domain-specific training.
Complementing NavComposer, we introduce NavInstrCritic, a comprehensive
annotation-free evaluation system that assesses navigation instructions on
three dimensions: contrastive matching, semantic consistency, and linguistic
diversity. NavInstrCritic provides a holistic evaluation of instruction
quality, addressing limitations of traditional metrics that rely heavily on
expert annotations. By decoupling instruction generation and evaluation from
specific navigation agents, our method enables more scalable and generalizable
research. Extensive experiments provide direct and practical evidence for the
effectiveness of our method.

</details>


### [341] [Lessons Learned from Evaluation of LLM based Multi-agents in Safer Therapy Recommendation](https://arxiv.org/abs/2507.10911)
*Yicong Wu,Ting Chen,Irit Hochberg,Zhoujian Sun,Ruth Edry,Zhengxing Huang,Mor Peleg*

Main category: cs.AI

TL;DR: LLM-based systems for therapy recommendations in multimorbid patients show promise but require further refinement to ensure complete and conflict-free advice.


<details>
  <summary>Details</summary>
Motivation: Existing decision support systems for therapy recommendations in chronic patients with multimorbidity face scalability limitations and risks of treatment conflicts. This study was inspired by the way General Practitioners (GPs) manage such patients by convening Multidisciplinary Teams (MDTs), and investigated the feasibility and value of using an LLM-based MAS for safer therapy recommendations.

Method: The study designed and evaluated a Large Language Model (LLM)-based multi-agent system (MAS) framework simulating Multidisciplinary Team (MDT) decision-making by enabling discussion among LLM agents to resolve medical conflicts. This MAS was compared against a single-agent approach and real-world benchmarks using therapy planning tasks for multimorbidity patients. New evaluation metrics were defined to assess clinical goals met and medication burden.

Result: The results indicate that a single LLM agent acting as a GP performs comparably to MDT simulations. The top-performing models offered correct recommendations that met all clinical goals but were incomplete. Additionally, some models suggested unnecessary medications, causing unintended medication-condition conflicts or drug-drug interactions.

Conclusion: The study found that current LLMs, when used in a single-agent system simulating a GP, perform as well as multi-agent systems simulating MDTs for therapy recommendations in chronic patients with multimorbidity. However, even the best-performing models provided incomplete advice and some included unnecessary medications, leading to potential conflicts.

Abstract: Therapy recommendation for chronic patients with multimorbidity is
challenging due to risks of treatment conflicts. Existing decision support
systems face scalability limitations. Inspired by the way in which general
practitioners (GP) manage multimorbidity patients, occasionally convening
multidisciplinary team (MDT) collaboration, this study investigated the
feasibility and value of using a Large Language Model (LLM)-based multi-agent
system (MAS) for safer therapy recommendations. We designed a single agent and
a MAS framework simulating MDT decision-making by enabling discussion among LLM
agents to resolve medical conflicts. The systems were evaluated on therapy
planning tasks for multimorbidity patients using benchmark cases. We compared
MAS performance with single-agent approaches and real-world benchmarks. An
important contribution of our study is the definition of evaluation metrics
that go beyond the technical precision and recall and allow the inspection of
clinical goals met and medication burden of the proposed advices to a gold
standard benchmark. Our results show that with current LLMs, a single agent GP
performs as well as MDTs. The best-scoring models provide correct
recommendations that address all clinical goals, yet the advices are
incomplete. Some models also present unnecessary medications, resulting in
unnecessary conflicts between medication and conditions or drug-drug
interactions.

</details>


### [342] [Enhancing Safe and Controllable Protein Generation via Knowledge Preference Optimization](https://arxiv.org/abs/2507.10923)
*Yuhao Wang,Keyan Ding,Kehua Feng,Zeyuan Wang,Ming Qin,Xiaotong Li,Qiang Zhang,Huajun Chen*

Main category: cs.AI

TL;DR: KPO框架通过整合知识图谱和强化学习，在利用蛋白质语言模型进行设计的同时，解决了其潜在的生物安全和伦理风险。


<details>
  <summary>Details</summary>
Motivation: 蛋白质语言模型在序列生成方面展现出强大潜力，可用于功能优化和从头设计，但也存在生成增强病毒传播或逃避免疫应答等有害蛋白质序列的重大风险，引发了生物安全和伦理挑战。

Method: 提出了一种知识引导的偏好优化（KPO）框架，该框架通过蛋白质安全知识图谱整合先验知识，并采用图修剪策略识别优选序列，利用强化学习最小化生成有害蛋白质的风险。

Result: 实验结果表明，KPO框架能有效降低生成危险序列的可能性，同时保持高功能性。

Conclusion: KPO框架通过整合蛋白质安全知识图谱和利用图修剪策略与强化学习，有效降低了生成有害蛋白质序列的风险，同时保持了蛋白质的高功能性，为生物技术中应用生成模型提供了强大的安全保障框架。

Abstract: Protein language models have emerged as powerful tools for sequence
generation, offering substantial advantages in functional optimization and
denovo design. However, these models also present significant risks of
generating harmful protein sequences, such as those that enhance viral
transmissibility or evade immune responses. These concerns underscore critical
biosafety and ethical challenges. To address these issues, we propose a
Knowledge-guided Preference Optimization (KPO) framework that integrates prior
knowledge via a Protein Safety Knowledge Graph. This framework utilizes an
efficient graph pruning strategy to identify preferred sequences and employs
reinforcement learning to minimize the risk of generating harmful proteins.
Experimental results demonstrate that KPO effectively reduces the likelihood of
producing hazardous sequences while maintaining high functionality, offering a
robust safety assurance framework for applying generative models in
biotechnology.

</details>


### [343] [Modeling Habitat Shifts: Integrating Convolutional Neural Networks and Tabular Data for Species Migration Prediction](https://arxiv.org/abs/2507.10993)
*Emir Durakovic,Min-Hong Shih*

Main category: cs.AI

TL;DR: 气候变化导致鸟类栖息地迁移，本研究提出一种结合CNN和表格数据的方法，利用卫星图像和环境特征来预测鸟类在特定栖息地的存在情况，准确率达85%。


<details>
  <summary>Details</summary>
Motivation: 由于气候变化导致栖息地范围发生变化，需要一种准确的模型来预测鸟类物种在特定栖息地的存在情况。

Method: 结合卷积神经网络（CNN）和表格数据，利用卫星图像和环境特征（如温度、降 precipitation、高程）来预测不同气候下的鸟类存在情况。CNN模型捕捉景观的空间特征，而表格方法则利用生态和地理数据。

Result: 该方法预测鸟类分布的平均准确率为85%，为理解鸟类迁徙提供了一种可扩展且可靠的方法。

Conclusion: 该研究提出了一种结合卷积神经网络（CNN）和表格数据的解决方案，可以对鸟类物种在特定栖息地的存在情况进行建模，平均准确率为85%，为理解鸟类迁徙提供了一种可扩展且可靠的方法。

Abstract: Due to climate-induced changes, many habitats are experiencing range shifts
away from their traditional geographic locations (Piguet, 2011). We propose a
solution to accurately model whether bird species are present in a specific
habitat through the combination of Convolutional Neural Networks (CNNs)
(O'Shea, 2015) and tabular data. Our approach makes use of satellite imagery
and environmental features (e.g., temperature, precipitation, elevation) to
predict bird presence across various climates. The CNN model captures spatial
characteristics of landscapes such as forestation, water bodies, and
urbanization, whereas the tabular method uses ecological and geographic data.
Both systems predict the distribution of birds with an average accuracy of 85%,
offering a scalable but reliable method to understand bird migration.

</details>


### [344] [Personalized Exercise Recommendation with Semantically-Grounded Knowledge Tracing](https://arxiv.org/abs/2507.11060)
*Yilmazcan Ozyurt,Tunaberk Almaci,Stefan Feuerriegel,Mrinmaya Sachan*

Main category: cs.AI

TL;DR: ExRec 框架通过结合问题语义和知识追踪来改进练习推荐，并使用强化学习进行个性化，在在线数学学习中表现出色。


<details>
  <summary>Details</summary>
Motivation: 现有练习推荐方法在模拟学生表现时，往往忽略了问题的语义内容和学习过程的顺序、结构化进展。为了解决这些问题，需要一种能够理解问题语义并捕捉学习过程结构的新方法。

Method: ExRec 框架通过以下步骤实现个性化练习推荐：1. 标注练习题的知识点（KCs）并学习其语义表示。2. 训练结合了问题语义信息的知识追踪（KT）模型。3. 优化强化学习（RL）方法，特别是提出了一种基于模型的价值估计（MVE）方法，该方法利用 KT 模型的组件来估计累积知识增长。

Result: ExRec 框架在四个不同在线数学学习任务中得到验证，结果表明该框架在不同 RL 方法下都表现出有效性。此外，ExRec 能够稳健地泛化到新的、未见过的问题，并能生成可解释的学生学习轨迹。

Conclusion: ExRec 框架通过结合知识追踪（KT）和强化学习（RL）来解决现有练习推荐系统忽视问题语义和学习过程结构化的问题。该框架能够生成可解释的学生学习轨迹，并能泛化到新的、未见过的问题，证明了 KT 引导的 RL 在个性化教育中的潜力。

Abstract: We introduce ExRec, a general framework for personalized exercise
recommendation with semantically-grounded knowledge tracing. Our method builds
on the observation that existing exercise recommendation approaches simulate
student performance via knowledge tracing (KT) but they often overlook two key
aspects: (a) the semantic content of questions and (b) the sequential,
structured progression of student learning. To address this, our ExRec presents
an end-to-end pipeline, from annotating the KCs of questions and learning their
semantic representations to training KT models and optimizing several
reinforcement learning (RL) methods. Moreover, we improve standard
Q-learning-based continuous RL methods via a tailored model-based value
estimation (MVE) approach that directly leverages the components of KT model in
estimating cumulative knowledge improvement. We validate the effectiveness of
our ExRec using various RL methods across four real-world tasks with different
educational goals in online math learning. We further show that ExRec
generalizes robustly to new, unseen questions and that it produces
interpretable student learning trajectories. Together, our findings highlight
the promise of KT-guided RL for effective personalization in education.

</details>


### [345] [Tactical Decision for Multi-UGV Confrontation with a Vision-Language Model-Based Commander](https://arxiv.org/abs/2507.11079)
*Li Wang,Qizhen Wu,Lei Chen*

Main category: cs.AI

TL;DR: 提出了一种结合视觉-语言模型和轻量级大语言模型的指挥系统，用于自主对抗中的态势感知和战略决策，提高了适应性和可解释性，并在仿真中取得了超过80%的胜率。


<details>
  <summary>Details</summary>
Motivation: 传统的基于规则的方法在复杂战场环境中容易失效，而现有的强化学习方法由于缺乏可解释性，主要关注动作而非战略决策。

Method: 提出了一种基于视觉-语言模型的指挥系统，整合了用于场景理解的视觉-语言模型和用于战略推理的轻量级大语言模型，实现了共享语义空间内的统一感知和决策。

Result: 仿真和消融实验验证了该方法与基线模型相比，胜率超过80%。

Conclusion: 该方法通过结合视觉-语言模型和轻量级大语言模型，实现了统一的感知和决策，在自主对抗中展现了强大的适应性和可解释性。

Abstract: In multiple unmanned ground vehicle confrontations, autonomously evolving
multi-agent tactical decisions from situational awareness remain a significant
challenge. Traditional handcraft rule-based methods become vulnerable in the
complicated and transient battlefield environment, and current reinforcement
learning methods mainly focus on action manipulation instead of strategic
decisions due to lack of interpretability. Here, we propose a vision-language
model-based commander to address the issue of intelligent
perception-to-decision reasoning in autonomous confrontations. Our method
integrates a vision language model for scene understanding and a lightweight
large language model for strategic reasoning, achieving unified perception and
decision within a shared semantic space, with strong adaptability and
interpretability. Unlike rule-based search and reinforcement learning methods,
the combination of the two modules establishes a full-chain process, reflecting
the cognitive process of human commanders. Simulation and ablation experiments
validate that the proposed approach achieves a win rate of over 80% compared
with baseline models.

</details>


### [346] [Function-to-Style Guidance of LLMs for Code Translation](https://arxiv.org/abs/2507.11083)
*Longhui Zhang,Bin Wang,Jiahao Wang,Xiaofeng Zhao,Min Zhang,Hao Yang,Meishan Zhang,Yu Li,Jing Li,Jun Yu,Min Zhang*

Main category: cs.AI

TL;DR: F2STrans是一种新的代码翻译方法，通过结合函数学习和风格学习，显著提高了大型语言模型的翻译性能和代码可读性，甚至能让小模型超越大模型。


<details>
  <summary>Details</summary>
Motivation: 尽管大型语言模型（LLMs）在代码翻译方面取得了进展，但要确保翻译代码的正确性和可读性仍然是一个挑战，这限制了它们在实际软件开发中的应用。因此，有必要提出一种能够同时提升翻译正确性和可读性的方法。

Method: F2STrans采用一个包含两个阶段的函数到风格引导范式：1. 函数学习，通过在线编程平台挖掘高质量的源目标代码对来优化翻译的正确性。2. 风格学习，通过整合正负面风格示例来提升翻译的可读性。此外，引入了一个包含最新源代码、广泛测试用例和人工注释的真实翻译的新型代码翻译基准，用于全面的功能和风格评估。

Result: F2STrans显著提高了代码翻译性能。在新的基准和现有数据集上的实验表明，该方法能够使Qwen-1.5B在20种不同的代码翻译场景下，平均性能优于经过提示增强的Qwen-32B和GPT-4。

Conclusion: F2STrans通过函数到风格的引导范式，在代码翻译任务中显著提高了LLM的性能，同时确保了翻译的正确性和可读性。实验证明，该方法能够使较小模型（如Qwen-1.5B）在多种代码翻译场景下超越更大的模型（如Qwen-32B和GPT-4）。

Abstract: Large language models (LLMs) have made significant strides in code
translation tasks. However, ensuring both the correctness and readability of
translated code remains a challenge, limiting their effective adoption in
real-world software development. In this work, we propose F2STrans, a
function-to-style guiding paradigm designed to progressively improve the
performance of LLMs in code translation. Our approach comprises two key stages:
(1) Functional learning, which optimizes translation correctness using
high-quality source-target code pairs mined from online programming platforms,
and (2) Style learning, which improves translation readability by incorporating
both positive and negative style examples. Additionally, we introduce a novel
code translation benchmark that includes up-to-date source code, extensive test
cases, and manually annotated ground-truth translations, enabling comprehensive
functional and stylistic evaluations. Experiments on both our new benchmark and
existing datasets demonstrate that our approach significantly improves code
translation performance. Notably, our approach enables Qwen-1.5B to outperform
prompt-enhanced Qwen-32B and GPT-4 on average across 20 diverse code
translation scenarios.

</details>


### [347] [AI Agent Architecture for Decentralized Trading of Alternative Assets](https://arxiv.org/abs/2507.11117)
*Ailiya Borjigin,Cong He,Charles CC Lee,Wei Zhou*

Main category: cs.AI

TL;DR: GoldMine OS利用AI代理实现实物黄金的去中心化代币化和交易，满足高性能、高安全性和合规性要求。


<details>
  <summary>Details</summary>
Motivation: 去中心化交易实物黄金等现实世界替代资产，需要在满足合规性、流动性和风险管理的严格要求的同时，将实物资产托管与区块链系统连接起来。

Method: 提出了一种名为GoldMine OS的面向研究的体系结构，该体系结构利用多个专业的AI代理（合规、代币发行、做市和风险控制）以及一个协调核心，来自动执行和保护实物黄金到基于区块链的稳定币（“OZ”）的代币化和交易。

Result: 模拟和试点部署的实验结果显示，该原型能够满足需求，代币发行时间不到1.2秒（比手动流程快100倍以上）；做市代理能够在波动条件下保持低于0.5%的买卖价差；容错测试表明，系统能在10秒内检测并缓解神谕价格欺骗攻击；模拟金库错误报告后可立即停止发行，对用户影响最小；基准测试显示，该架构可扩展至支持5000 TPS和10000并发用户。

Conclusion: 该研究表明，基于AI代理的去中心化交易所能够满足严格的性能和安全要求，为传统上流动性差的资产提供更广泛的访问，并通过其治理模型确保系统的持续透明度、适应性和正式保证。

Abstract: Decentralized trading of real-world alternative assets (e.g., gold) requires
bridging physical asset custody with blockchain systems while meeting strict
requirements for compliance, liquidity, and risk management. We present
GoldMine OS, a research oriented architecture that employs multiple specialized
AI agents to automate and secure the tokenization and exchange of physical gold
into a blockchain based stablecoin ("OZ"). Our approach combines on chain smart
contracts for critical risk controls with off chain AI agents for decision
making, blending the transparency and reliability of blockchains with the
flexibility of AI driven automation. We describe four cooperative agents
(Compliance, Token Issuance, Market Making, and Risk Control) and a
coordinating core, and evaluate the system through simulation and a controlled
pilot deployment. In experiments the prototype delivers on demand token
issuance in under 1.2 s, more than 100 times faster than manual workflows. The
Market Making agent maintains tight liquidity with spreads often below 0.5
percent even under volatile conditions. Fault injection tests show resilience:
an oracle price spoofing attack is detected and mitigated within 10 s, and a
simulated vault mis reporting halts issuance immediately with minimal user
impact. The architecture scales to 5000 transactions per second with 10000
concurrent users in benchmarks. These results indicate that an AI agent based
decentralized exchange for alternative assets can satisfy rigorous performance
and safety requirements. We discuss broader implications for democratizing
access to traditionally illiquid assets and explain how our governance model --
multi signature agent updates and on chain community voting on risk parameters
-- provides ongoing transparency, adaptability, and formal assurance of system
integrity.

</details>


### [348] [Defining neurosymbolic AI](https://arxiv.org/abs/2507.11127)
*Lennert De Smet,Luc De Raedt*

Main category: cs.AI

TL;DR: 神经符号AI领域缺乏统一的形式化定义。我们提出一种新的定义，将神经符号推理视为逻辑函数与信念函数乘积上的积分，并证明它适用于现有系统。


<details>
  <summary>Details</summary>
Motivation: 当前神经符号AI领域缺乏一个普遍接受的形式化定义，这阻碍了该领域的发展。

Method: 提出了一种新的形式化定义，即将神经符号推理定义为逻辑函数与信念函数乘积上的积分。

Result: 所提出的形式化定义能够涵盖现有的关键神经符号AI系统，为该领域提供了一个统一的框架。 
TLDR: 神经符号AI领域急需一个形式化定义。我们提出将神经符号推理定义为逻辑函数与信念函数乘积上的积分，并证明该定义能涵盖现有代表性系统。这种方法为神经符号AI提供了一个统一的理论基础，有助于未来的研究和发展。它解决了该领域缺乏统一标准的痛点，并为构建更强大的AI系统铺平了道路。 


Conclusion: 该研究提出了神经符号AI的形式化定义，并展示了该定义如何涵盖了关键的神经符号AI系统。

Abstract: Neurosymbolic AI focuses on integrating learning and reasoning, in
particular, on unifying logical and neural representations. Despite the
existence of an alphabet soup of neurosymbolic AI systems, the field is lacking
a generally accepted formal definition of what neurosymbolic models and
inference really are. We introduce a formal definition for neurosymbolic AI
that makes abstraction of its key ingredients. More specifically, we define
neurosymbolic inference as the computation of an integral over a product of a
logical and a belief function. We show that our neurosymbolic AI definition
makes abstraction of key representative neurosymbolic AI systems.

</details>


### [349] [Collaborative Trustworthiness for Good Decision Making in Autonomous Systems](https://arxiv.org/abs/2507.11135)
*Selma Saidi,Omar Laimona,Christoph Schmickler,Dirk Ziegenbein*

Main category: cs.AI

TL;DR: 本研究提出了一种新颖的协作方法，利用自动驾驶系统的质量属性和借鉴社会认识论的聚合/传播规则，通过BDDs模型提高了自动驾驶系统在复杂环境中的决策能力和可信度。


<details>
  <summary>Details</summary>
Motivation: 确保自动驾驶系统在动态复杂环境中安全可靠地运行，特别是在需要自主决策（如机动）的情况下，仍然是一个重大挑战。在信息冲突的情况下，基于协作数据共享的可信决策制定，其聚合问题至关重要。

Method: 本研究提出了一种利用各自动驾驶系统不同的质量属性（如感知质量）来确定可信赖系统的协作方法，并借鉴社会认识论的概念定义了用于自动决策的聚合和传播规则。使用二元决策图（BDDs）作为信念聚合和传播的正式模型，并通过简化规则减小BDDs的尺寸以实现高效的协作自动化推理。

Result: 研究结果表明，该方法能够利用各自动驾驶系统不同的质量属性来确定可信赖的系统，并通过社会认识论的概念定义聚合和传播规则，从而提高自动驾驶系统的可信度、可靠性和决策能力。使用BDDs作为正式模型和简化规则，实现了高效的协作自动化推理。

Conclusion: 本研究提出了一种通用的协作方法，以提高自动驾驶系统在动态复杂环境中的可信度、可靠性和决策能力。通过利用各自动驾驶系统不同的质量属性（如感知质量），而非传统的共识或多数规则，来确定可信赖的系统。借鉴社会认识论的概念，定义了用于自动决策的聚合和传播规则。研究使用二元决策图（BDDs）作为信念聚合和传播的正式模型，并提出了简化规则以减小BDDs的尺寸，从而实现高效的协作自动化推理。

Abstract: Autonomous systems are becoming an integral part of many application domains,
like in the mobility sector. However, ensuring their safe and correct behaviour
in dynamic and complex environments remains a significant challenge, where
systems should autonomously make decisions e.g., about manoeuvring. We propose
in this paper a general collaborative approach for increasing the level of
trustworthiness in the environment of operation and improve reliability and
good decision making in autonomous system. In the presence of conflicting
information, aggregation becomes a major issue for trustworthy decision making
based on collaborative data sharing. Unlike classical approaches in the
literature that rely on consensus or majority as aggregation rule, we exploit
the fact that autonomous systems have different quality attributes like
perception quality. We use this criteria to determine which autonomous systems
are trustworthy and borrow concepts from social epistemology to define
aggregation and propagation rules, used for automated decision making. We use
Binary Decision Diagrams (BDDs) as formal models for beliefs aggregation and
propagation, and formulate reduction rules to reduce the size of the BDDs and
allow efficient computation structures for collaborative automated reasoning.

</details>


### [350] [DuetGraph: Coarse-to-Fine Knowledge Graph Reasoning with Dual-Pathway Global-Local Fusion](https://arxiv.org/abs/2507.11229)
*Jin Li,Zezhong Ding,Xike Xie*

Main category: cs.AI

TL;DR: DuetGraph 通过双通路信息融合和粗细粒度优化解决了知识图谱推理中的分数平滑问题，提升了推理效果和训练效率。


<details>
  <summary>Details</summary>
Motivation: 现有的知识图谱推理方法在集成全局和局部信息方面取得了进展，但普遍存在分数平滑问题，这模糊了正确答案和错误答案之间的界限，并阻碍了推理的有效性。

Method: DuetGraph 提出了一种粗粒度到细粒度的知识图谱推理机制，采用双通路融合全局和局部信息。该方法将局部信息（通过消息传递）和全局信息（通过注意力机制）分离到两个不同的通路中进行处理，以防止相互干扰并保持表示区分度。此外，DuetGraph 引入了粗粒度到细粒度的优化策略，将实体划分为高分和低分子集，缩小候选空间并增大分数差距，从而缓解了分数平滑问题并提高了推理质量。

Result: 实验结果表明，DuetGraph 在多个数据集上取得了最先进的性能，推理质量提高了高达 8.7%，训练效率提高了 1.8 倍。

Conclusion: DuetGraph 通过分离局部和全局信息处理、引入粗粒度到细粒度优化，有效解决了知识图谱推理中的分数平滑问题，并在多个数据集上实现了最先进的性能，推理质量提高了 8.7%，训练效率提高了 1.8 倍。

Abstract: Knowledge graphs (KGs) are vital for enabling knowledge reasoning across
various domains. Recent KG reasoning methods that integrate both global and
local information have achieved promising results. However, existing methods
often suffer from score over-smoothing, which blurs the distinction between
correct and incorrect answers and hinders reasoning effectiveness. To address
this, we propose DuetGraph, a coarse-to-fine KG reasoning mechanism with
dual-pathway global-local fusion. DuetGraph tackles over-smoothing by
segregating -- rather than stacking -- the processing of local (via message
passing) and global (via attention) information into two distinct pathways,
preventing mutual interference and preserving representational discrimination.
In addition, DuetGraph introduces a coarse-to-fine optimization, which
partitions entities into high- and low-score subsets. This strategy narrows the
candidate space and sharpens the score gap between the two subsets, which
alleviates over-smoothing and enhances inference quality. Extensive experiments
on various datasets demonstrate that DuetGraph achieves state-of-the-art (SOTA)
performance, with up to an 8.7% improvement in reasoning quality and a
1.8$\times$ acceleration in training efficiency.

</details>


### [351] [Opus: A Prompt Intention Framework for Complex Workflow Generation](https://arxiv.org/abs/2507.11288)
*Théo Fagnoni,Mahsun Altin,Chia En Chung,Phillip Kingston,Alan Tuning,Dana O. Mohamed,Inès Adnani*

Main category: cs.AI

TL;DR: Opus Prompt Intention Framework通过增加一个意图捕获层来改进LLM的工作流生成，提高了输出的逻辑性和可扩展性，并在混合意图引导方面表现尤为出色。


<details>
  <summary>Details</summary>
Motivation: 旨在提高指令调优的大型语言模型（LLMs）在复杂工作流生成方面的能力。

Method: 提出Opus Prompt Intention Framework，包含提取工作流信号、解释为结构化工作流意图对象以及基于意图生成工作流的中间意图捕获层。

Result: 在包含1000个多意图查询-工作流对的合成基准测试中，与直接生成相比，该框架在语义工作流相似性指标上实现了持续改进，尤其是在混合意图引导的情况下。

Conclusion: 该框架通过引入中间意图捕获层，显著提高了LLM在复杂工作流生成方面的质量，尤其是在混合意图引导方面，并提供了可复现、可定制的系统。

Abstract: This paper introduces the Opus Prompt Intention Framework, designed to
improve complex Workflow Generation with instruction-tuned Large Language
Models (LLMs). We propose an intermediate Intention Capture layer between user
queries and Workflow Generation, implementing the Opus Workflow Intention
Framework, which consists of extracting Workflow Signals from user queries,
interpreting them into structured Workflow Intention objects, and generating
Workflows based on these Intentions. Our results show that this layer enables
LLMs to produce logical and meaningful outputs that scale reliably as query
complexity increases. On a synthetic benchmark of 1,000 multi-intent
query-Workflow(s) pairs, applying the Opus Prompt Intention Framework to
Workflow Generation yields consistent improvements in semantic Workflow
similarity metrics. In this paper, we introduce the Opus Prompt Intention
Framework by applying the concepts of Workflow Signal and Workflow Intention to
LLM-driven Workflow Generation. We present a reproducible, customizable
LLM-based Intention Capture system to extract Workflow Signals and Workflow
Intentions from user queries. Finally, we provide empirical evidence that the
proposed system significantly improves Workflow Generation quality compared to
direct generation from user queries, particularly in cases of Mixed Intention
Elicitation.

</details>


### [352] [Contestability in Quantitative Argumentation](https://arxiv.org/abs/2507.11323)
*Xiang Yin,Nico Potyka,Antonio Rago,Timotheus Kampik,Francesca Toni*

Main category: cs.AI

TL;DR: EW-QBAFs可通过G-RAE和迭代算法实现AI可辩论性，通过调整边缘权重使AI决策符合人类偏好。


<details>
  <summary>Details</summary>
Motivation: AI可辩论性要求AI驱动的决策与人类偏好一致，而EW-QBAFs在此方面的应用尚未得到充分研究。

Method: 提出梯度基于关系归因解释（G-RAEs）来量化边缘权重变化对目标参数强度的敏感性，并开发了一种迭代算法来逐步调整边缘权重以达到目标强度。

Result: 实验证明该方法在模拟推荐系统和多层感知机的EW-QBAFs上能有效解决可辩论性问题。

Conclusion: EW-QBAFs可以用于AI可辩论性，通过G-RAE和迭代算法调整边缘权重以达到目标强度，并在模拟推荐系统和多层感知机的EW-QBAFs上有效解决了可辩论性问题。

Abstract: Contestable AI requires that AI-driven decisions align with human
preferences. While various forms of argumentation have been shown to support
contestability, Edge-Weighted Quantitative Bipolar Argumentation Frameworks
(EW-QBAFs) have received little attention. In this work, we show how EW-QBAFs
can be deployed for this purpose. Specifically, we introduce the contestability
problem for EW-QBAFs, which asks how to modify edge weights (e.g., preferences)
to achieve a desired strength for a specific argument of interest (i.e., a
topic argument). To address this problem, we propose gradient-based relation
attribution explanations (G-RAEs), which quantify the sensitivity of the topic
argument's strength to changes in individual edge weights, thus providing
interpretable guidance for weight adjustments towards contestability. Building
on G-RAEs, we develop an iterative algorithm that progressively adjusts the
edge weights to attain the desired strength. We evaluate our approach
experimentally on synthetic EW-QBAFs that simulate the structural
characteristics of personalised recommender systems and multi-layer
perceptrons, and demonstrate that it can solve the problem effectively.

</details>


### [353] [CogDDN: A Cognitive Demand-Driven Navigation with Decision Optimization and Dual-Process Thinking](https://arxiv.org/abs/2507.11334)
*Yuehao Huang,Liang Liu,Shuangming Lei,Yukai Ma,Hao Su,Jianbiao Mei,Pengxiang Zhao,Yaqing Gu,Yong Liu,Jiajun Lv*

Main category: cs.AI

TL;DR: CogDDN是一个基于VLM的框架，通过模拟人类认知和学习机制（整合快慢思考、双过程决策、CoT推理）来改进需求驱动导航（DDN）。它能更好地处理未知和非结构化环境，在AI2Thor模拟器上相比传统方法提升了15%的导航准确性和适应性。


<details>
  <summary>Details</summary>
Motivation: 传统数据驱动的需求驱动导航（DDN）方法依赖预先收集的数据进行模型训练和决策，在未见场景中的泛化能力有限。因此，需要一种新的方法来提高DDN在未知和非结构化环境中的适应性和准确性。

Method: 提出了一种名为CogDDN的基于视觉语言模型（VLM）的框架，该框架通过整合快速和慢速思维系统来模拟人类认知和学习机制，并有选择性地识别满足用户需求的关键对象。CogDDN通过语义对齐检测到的对象和给定的指令来识别合适的目标对象。此外，它还包含一个双过程决策模块，包括用于快速高效决策的启发式过程，以及用于分析过往错误、累积知识库并持续改进性能的分析过程。思维链（CoT）推理增强了决策过程。

Result: CogDDN相比单视图纯视觉方法，导航准确性和适应性有15%的提升。

Conclusion: CogDDN在AI2Thor模拟器和ProcThor数据集上的广泛的闭环评估显示，CogDDN相比仅使用单视图摄像头的传统方法，导航准确性和适应性有15%的显著提升。

Abstract: Mobile robots are increasingly required to navigate and interact within
unknown and unstructured environments to meet human demands. Demand-driven
navigation (DDN) enables robots to identify and locate objects based on
implicit human intent, even when object locations are unknown. However,
traditional data-driven DDN methods rely on pre-collected data for model
training and decision-making, limiting their generalization capability in
unseen scenarios. In this paper, we propose CogDDN, a VLM-based framework that
emulates the human cognitive and learning mechanisms by integrating fast and
slow thinking systems and selectively identifying key objects essential to
fulfilling user demands. CogDDN identifies appropriate target objects by
semantically aligning detected objects with the given instructions.
Furthermore, it incorporates a dual-process decision-making module, comprising
a Heuristic Process for rapid, efficient decisions and an Analytic Process that
analyzes past errors, accumulates them in a knowledge base, and continuously
improves performance. Chain of Thought (CoT) reasoning strengthens the
decision-making process. Extensive closed-loop evaluations on the AI2Thor
simulator with the ProcThor dataset show that CogDDN outperforms single-view
camera-only methods by 15%, demonstrating significant improvements in
navigation accuracy and adaptability. The project page is available at
https://yuehaohuang.github.io/CogDDN/.

</details>


### [354] [Foundation Models for Logistics: Toward Certifiable, Conversational Planning Interfaces](https://arxiv.org/abs/2507.11352)
*Yunhao Yang,Neel P. Bhatt,Christian Ellis,Alvaro Velasquez,Zhangyang Wang,Ufuk Topcu*

Main category: cs.AI

TL;DR: 通过结合自然语言对话和可验证的保证，该框架可以更安全、更快速、更准确地处理复杂的物流规划问题，即使在 불확실성 的情况下也是如此。


<details>
  <summary>Details</summary>
Motivation: 现有方法（如整数规划）在处理不确定性和实时 replanning 方面存在不足，而大型语言模型（LLMs）则可能出现误解和幻觉，危及安全性和成本。因此，需要一种能够处理不确定性并提供可验证保证的框架。

Method: 该框架将用户请求转换为结构化规划规范，量化其自身在现场和令牌级别的 불확실성，并在置信度低于自适应阈值时调用交互式澄清循环。

Result: 一个经过 100 个 불확실성 过滤示例微调的轻量级模型，在零样本性能上超越了 GPT-4.1，并将推理延迟缩短了近 50%。

Conclusion: 该研究提出了一种神经符号框架，将可及的自然语言对话与对目标解释的可验证保证相结合，以实现可认证、实时、用户对齐的复杂物流决策。

Abstract: Logistics operators, from battlefield coordinators rerouting airlifts ahead
of a storm to warehouse managers juggling late trucks, often face life-critical
decisions that demand both domain expertise and rapid and continuous
replanning. While popular methods like integer programming yield logistics
plans that satisfy user-defined logical constraints, they are slow and assume
an idealized mathematical model of the environment that does not account for
uncertainty. On the other hand, large language models (LLMs) can handle
uncertainty and promise to accelerate replanning while lowering the barrier to
entry by translating free-form utterances into executable plans, yet they
remain prone to misinterpretations and hallucinations that jeopardize safety
and cost. We introduce a neurosymbolic framework that pairs the accessibility
of natural-language dialogue with verifiable guarantees on goal interpretation.
It converts user requests into structured planning specifications, quantifies
its own uncertainty at the field and token level, and invokes an interactive
clarification loop whenever confidence falls below an adaptive threshold. A
lightweight model, fine-tuned on just 100 uncertainty-filtered examples,
surpasses the zero-shot performance of GPT-4.1 while cutting inference latency
by nearly 50%. These preliminary results highlight a practical path toward
certifiable, real-time, and user-aligned decision-making for complex logistics.

</details>


### [355] [Modeling Code: Is Text All You Need?](https://arxiv.org/abs/2507.11467)
*Daniel Nichols,Konstantinos Parasyris,Harshitha Menon,Brian R. Bartoldson,Giorgis Georgakoudis,Tal Ben-Nun,Abhinav Bhatele*

Main category: cs.AI

TL;DR: 代码大模型在代码生成、翻译和摘要等方面表现出色，但在推理代码的控制流和数据流等方面存在局限。本研究提出了一种结合代码文本和结构化表示的新方法，以克服现有方法的不足。


<details>
  <summary>Details</summary>
Motivation: 现有的基于Transformer的代码大模型在理解和推理代码的结构化、分析属性（如控制流和数据流）方面存在局限性。而以往利用图神经网络等方法处理结构化数据的方法，又缺乏大模型的生成能力和规模。

Method: 提出了一种结合代码文本和结构化表示的新方法。

Result: 提出了一种新方法，结合了代码作为文本进行建模和结构化表示的优点。

Conclusion: 需要结合代码的文本表示和结构化表示的优点，以实现更强大的代码大模型。

Abstract: Code LLMs have become extremely popular recently for modeling source code
across a variety of tasks, such as generation, translation, and summarization.
However, transformer-based models are limited in their capabilities to reason
through structured, analytical properties of code, such as control and data
flow. Previous work has explored the modeling of these properties with
structured data and graph neural networks. However, these approaches lack the
generative capabilities and scale of modern LLMs. In this work, we introduce a
novel approach to combine the strengths of modeling both code as text and more
structured forms.

</details>


### [356] [Chain of Thought Monitorability: A New and Fragile Opportunity for AI Safety](https://arxiv.org/abs/2507.11473)
*Tomek Korbak,Mikita Balesni,Elizabeth Barnes,Yoshua Bengio,Joe Benton,Joseph Bloom,Mark Chen,Alan Cooney,Allan Dafoe,Anca Dragan,Scott Emmons,Owain Evans,David Farhi,Ryan Greenblatt,Dan Hendrycks,Marius Hobbhahn,Evan Hubinger,Geoffrey Irving,Erik Jenner,Daniel Kokotajlo,Victoria Krakovna,Shane Legg,David Lindner,David Luan,Aleksander Mądry,Julian Michael,Neel Nanda,Dave Orr,Jakub Pachocki,Ethan Perez,Mary Phuong,Fabien Roger,Joshua Saxe,Buck Shlegeris,Martín Soto,Eric Steinberger,Jasmine Wang,Wojciech Zaremba,Bowen Baker,Rohin Shah,Vlad Mikulik*

Main category: cs.AI

TL;DR: AI安全新方法：通过监测“思考”链（CoT）来发现不良意图，有潜力但需进一步研究。


<details>
  <summary>Details</summary>
Motivation: AI系统能够用人类语言思考，为AI安全提供了新的途径，即通过监测其思考链来发现不良意图。

Method: 通过监测AI的“思考”链（CoT）来发现其不良意图。

Result: CoT监测虽然不完美，但仍有潜力，建议进一步研究CoT的可监测性，并与现有安全方法一同进行投入。同时，建议前端模型开发者在做开发决策时考虑其对CoT可监测性的影响，因为该方法可能不稳定。

Conclusion: AI系统可以通过监测其“思考”链（CoT）来监控不良行为，虽然此方法不完美，但仍有潜力，应与现有安全方法结合进行研究和投资。

Abstract: AI systems that "think" in human language offer a unique opportunity for AI
safety: we can monitor their chains of thought (CoT) for the intent to
misbehave. Like all other known AI oversight methods, CoT monitoring is
imperfect and allows some misbehavior to go unnoticed. Nevertheless, it shows
promise and we recommend further research into CoT monitorability and
investment in CoT monitoring alongside existing safety methods. Because CoT
monitorability may be fragile, we recommend that frontier model developers
consider the impact of development decisions on CoT monitorability.

</details>


### [357] [Illuminating the Three Dogmas of Reinforcement Learning under Evolutionary Light](https://arxiv.org/abs/2507.11482)
*Mani Hamidi,Terrence W. Deacon*

Main category: cs.AI

TL;DR: 本文借鉴进化理论来修订 RL 的三个核心原则，并提出整合生命起源理论以解决能动性问题，为生物学习模型提供了新视角。


<details>
  <summary>Details</summary>
Motivation: RL 的三个核心原则——能动性、学习目标和奖励假设的范围——需要概念上的修订。本文旨在通过借鉴开放式进化理论来重新审视这些原则，并探索其在生物学习模型中的应用。

Method: 本文提出一个受开放式进化理论启发的框架来重新审视 RL 的三个核心原则：能动性、学习目标和奖励假设的范围。首先，我们借鉴进化见解来丰富“适应而非搜索”的学习观，然后利用进化适应性的类比来阐明标量奖励与多目标优化之间的争论，以解决奖励假设的限制。最后，我们认为，虽然进化范式指明了解决能动性问题的有益方向，但需要整合生命起源理论的思想，特别是维持和复制的热力学，为理解生物系统中的能动性、资源约束强化学习提供基础。

Result: 本文通过借鉴进化理论和生命起源理论，对 RL 的核心原则进行了概念上的修订，为理解生物系统中的学习、能动性和资源约束提供了一个新的框架。

Conclusion: 强化学习（RL）的三个核心原则——关于能动性、学习目标和奖励假设的范围——已被强调为概念修正的关键目标，对理论和应用都有重大影响。本文提出一个受开放式进化理论启发的框架来重新审视这三个“信条”。我们重新审视每个假设，并解决与之相关的关切。为了使我们的论点与 RL 作为生物学习模型相关，我们首先建立进化动力学可以合理地在个体一生中作用于生物大脑，并且不局限于跨代过程。我们首先回顾第二个信条，利用进化见解来丰富“适应而非搜索”的学习观。然后，我们利用进化适应性的类比来阐明标量奖励与多目标优化之间的争论，以解决奖励假设的限制。在讨论了对 RL 探索的实际影响后，我们转向第一个——也是最根本的——问题：能动性账户的缺失。我们认为，与其他两个问题不同，单独的进化范式无法解决能动性问题，尽管它指明了一个有益的方向。我们主张整合生命起源理论的思想，其中维持和复制的热力学为理解生物系统中的能动性、资源约束强化学习提供了有希望的基础。

Abstract: Three core tenets of reinforcement learning (RL)--concerning the definition
of agency, the objective of learning, and the scope of the reward
hypothesis--have been highlighted as key targets for conceptual revision, with
major implications for theory and application. We propose a framework, inspired
by open-ended evolutionary theory, to reconsider these three "dogmas." We
revisit each assumption and address related concerns raised alongside them. To
make our arguments relevant to RL as a model of biological learning, we first
establish that evolutionary dynamics can plausibly operate within living brains
over an individual's lifetime, and are not confined to cross-generational
processes. We begin by revisiting the second dogma, drawing on evolutionary
insights to enrich the "adaptation-rather-than-search" view of learning. We
then address the third dogma regarding the limits of the reward hypothesis,
using analogies from evolutionary fitness to illuminate the scalar reward vs.
multi-objective debate. After discussing practical implications for exploration
in RL, we turn to the first--and arguably most fundamental--issue: the absence
of a formal account of agency. We argue that unlike the other two problems, the
evolutionary paradigm alone cannot resolve the agency question, though it
gestures in a productive direction. We advocate integrating ideas from
origins-of-life theory, where the thermodynamics of sustenance and replication
offer promising foundations for understanding agency and resource-constrained
reinforcement learning in biological systems.

</details>


### [358] [DrafterBench: Benchmarking Large Language Models for Tasks Automation in Civil Engineering](https://arxiv.org/abs/2507.11527)
*Yinsheng Li,Zhen Dong,Yi Shao*

Main category: cs.AI

TL;DR: DrafterBench is a new benchmark for evaluating LLM agents in civil engineering drawing revisions, featuring diverse tasks and tools to test AI capabilities and guide improvements for industrial applications.


<details>
  <summary>Details</summary>
Motivation: Need for systematic evaluation of LLM agents for industrial automation, specifically in Civil Engineering, to assess their potential in tasks like technical drawing revision.

Method: Propose DrafterBench, a benchmark containing 12 task types from real-world drawing files, 46 customized functions/tools, and 1920 tasks, to rigorously test AI agents' proficiency in interpreting instructions, leveraging prior knowledge, and adapting to dynamic instruction quality.

Result: DrafterBench comprehensively assesses distinct capabilities including structured data comprehension, function execution, instruction following, and critical reasoning, providing detailed analysis of task accuracy and error statistics.

Conclusion: DrafterBench is an open-source benchmark designed to evaluate LLM agents in technical drawing revision for civil engineering, offering comprehensive assessment of various capabilities and detailed analysis for identifying improvement targets.

Abstract: Large Language Model (LLM) agents have shown great potential for solving
real-world problems and promise to be a solution for tasks automation in
industry. However, more benchmarks are needed to systematically evaluate
automation agents from an industrial perspective, for example, in Civil
Engineering. Therefore, we propose DrafterBench for the comprehensive
evaluation of LLM agents in the context of technical drawing revision, a
representation task in civil engineering. DrafterBench contains twelve types of
tasks summarized from real-world drawing files, with 46 customized
functions/tools and 1920 tasks in total. DrafterBench is an open-source
benchmark to rigorously test AI agents' proficiency in interpreting intricate
and long-context instructions, leveraging prior knowledge, and adapting to
dynamic instruction quality via implicit policy awareness. The toolkit
comprehensively assesses distinct capabilities in structured data
comprehension, function execution, instruction following, and critical
reasoning. DrafterBench offers detailed analysis of task accuracy and error
statistics, aiming to provide deeper insight into agent capabilities and
identify improvement targets for integrating LLMs in engineering applications.
Our benchmark is available at https://github.com/Eason-Li-AIS/DrafterBench,
with the test set hosted at
https://huggingface.co/datasets/Eason666/DrafterBench.

</details>


### [359] [How Many Instructions Can LLMs Follow at Once?](https://arxiv.org/abs/2507.11538)
*Daniel Jaroslawicz,Brendan Whiting,Parth Shah,Karime Maamari*

Main category: cs.AI

TL;DR: IFScale 是一个包含 500 条指令的基准测试，用于评估 LLM 在高密度指令下的表现。结果显示，即使是最好的模型，其准确率也只有 68%，并且存在模型规模、推理能力、对早期指令的偏见和错误类别等影响因素。


<details>
  <summary>Details</summary>
Motivation: 评估 LLM 在高指令密度下的指令遵循能力，填补现有基准测试的空白。

Method: 提出 IFScale 基准测试，包含 500 条用于商业报告写作任务的关键词包含指令，以衡量指令密度增加时指令遵循能力的下降情况。评估了 20 个最先进的模型。

Result: 发现模型规模和推理能力与性能下降模式、对早期指令的偏见和错误类别相关。即使是最好的 frontier 模型，在 500 条指令的最大密度下准确率也只有 68%。

Conclusion: 现有基准测试未能充分评估大规模语言模型（LLM）在高密度指令下的指令遵循能力。 frontier 模型在 500 条指令的最大密度下准确率仅为 68%。模型规模和推理能力与性能下降模式、对早期指令的偏见以及指令遵循错误类别相关。IFScale 基准测试有助于设计高密度指令提示并了解性能-延迟权衡。

Abstract: Production-grade LLM systems require robust adherence to dozens or even
hundreds of instructions simultaneously. However, the instruction-following
capabilities of LLMs at high instruction densities have not yet been
characterized, as existing benchmarks only evaluate models on tasks with a
single or few instructions. We introduce IFScale, a simple benchmark of 500
keyword-inclusion instructions for a business report writing task to measure
how instruction-following performance degrades as instruction density
increases. We evaluate 20 state-of-the-art models across seven major providers
and find that even the best frontier models only achieve 68% accuracy at the
max density of 500 instructions. Our analysis reveals model size and reasoning
capability to correlate with 3 distinct performance degradation patterns, bias
towards earlier instructions, and distinct categories of instruction-following
errors. Our insights can help inform design of instruction-dense prompts in
real-world applications and highlight important performance-latency tradeoffs.
We open-source the benchmark and all results for further analysis at
https://distylai.github.io/IFScale.

</details>


<div id='cs.ET'></div>

# cs.ET [[Back]](#toc)

### [360] [Fault-Free Analog Computing with Imperfect Hardware](https://arxiv.org/abs/2507.11134)
*Zhicheng Xu,Jiawei Liu,Sitao Huang,Zefan Li,Shengbo Wang,Bo Wen,Ruibin Mao,Mingrui Jiang,Giacomo Pedretti,Jim Ignowski,Kaibin Huang,Can Li*

Main category: cs.ET

TL;DR: 通过将矩阵分解为两个子矩阵的乘积，可以有效解决忆阻器等模拟计算硬件中的器件故障问题，大幅提高计算精度和效率。


<details>
  <summary>Details</summary>
Motivation: 为了解决模拟计算（特别是基于忆阻器的计算）中器件故障和变异性导致的精度和可靠性问题，以及现有容错技术（如冗余和再训练）在处理高精度应用或需要固定矩阵和隐私保护的场景下的局限性。

Method: 提出了一种新颖的矩阵分解技术，将目标矩阵分解为两个子矩阵的乘积。通过在模拟硬件上对这两个子矩阵进行编程，实现了计算的容错性。利用数学优化来规避故障器件和消除差分对，从而提高计算密度和精度。

Result: 基于忆阻器的系统在 39% 的器件故障率下实现了 >99.999% 的余弦相似度（针对离散傅立叶变换矩阵），而传统直接表示方法在 0.01% 的故障率下就会失败。在无线通信中实现了 56 倍的比特错误率降低，密度和能效相比现有技术分别提高了 179% 和 196%。

Conclusion: 该研究提出了一种无故障矩阵表示方法，将目标矩阵分解为两个可调子矩阵的乘积，并可在模拟硬件上进行编程。这种间接、自适应的表示能够通过数学优化绕过故障设备并消除差分对，从而显著提高计算密度。该方法在基于忆阻器的系统中实现了超过 99.999% 的余弦相似度，即使在 39% 的器件故障率下也能处理离散傅立叶变换矩阵，这在传统直接表示方法中是无法实现的。此外，该研究在无线通信中实现了 56 倍的比特错误率降低，在密度和能效方面比现有技术提高了 196% 和 179%。该方法不仅在忆阻器上得到了验证，而且广泛适用于新兴存储器和非电计算基元，表明器件良率不再是模拟计算硬件的主要瓶颈。

Abstract: The growing demand for edge computing and AI drives research into analog
in-memory computing using memristors, which overcome data movement bottlenecks
by computing directly within memory. However, device failures and variations
critically limit analog systems' precision and reliability. Existing
fault-tolerance techniques, such as redundancy and retraining, are often
inadequate for high-precision applications or scenarios requiring fixed
matrices and privacy preservation. Here, we introduce and experimentally
demonstrate a fault-free matrix representation where target matrices are
decomposed into products of two adjustable sub-matrices programmed onto analog
hardware. This indirect, adaptive representation enables mathematical
optimization to bypass faulty devices and eliminate differential pairs,
significantly enhancing computational density. Our memristor-based system
achieved >99.999% cosine similarity for a Discrete Fourier Transform matrix
despite 39% device fault rate, a fidelity unattainable with conventional direct
representation, which fails with single device faults (0.01% rate). We
demonstrated 56-fold bit-error-rate reduction in wireless communication and
>196% density with 179% energy efficiency improvements compared to
state-of-the-art techniques. This method, validated on memristors, applies
broadly to emerging memories and non-electrical computing substrates, showing
that device yield is no longer the primary bottleneck in analog computing
hardware.

</details>


<div id='cs.GR'></div>

# cs.GR [[Back]](#toc)

### [361] [Developing and evaluating quilts for the depiction of large layered graphs](https://arxiv.org/abs/2507.10883)
*Juhee Bae,Benjamin Watson*

Main category: cs.GR

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Traditional layered graph depictions such as flow charts are in wide use. Yet
as graphs grow more complex, these depictions can become difficult to
understand. Quilts are matrix-based depictions for layered graphs designed to
address this problem. In this research, we first improve Quilts by developing
three design alternatives, and then compare the best of these alternatives to
better-known node-link and matrix depictions. A primary weakness in Quilts is
their depiction of skip links, links that do not simply connect to a succeeding
layer. Therefore in our first study, we compare Quilts using color-only,
text-only, and mixed (color and text) skip link depictions, finding that path
finding with the color-only depiction is significantly slower and less
accurate, and that in certain cases, the mixed depiction offers an advantage
over the text-only depiction. In our second study, we compare Quilts using the
mixed depiction to node-link diagrams and centered matrices. Overall results
show that users can find paths through graphs significantly faster with Quilts
(46.6 secs) than with node-link (58.3 secs) or matrix (71.2 secs) diagrams.
This speed advantage is still greater in large graphs (e.g. in 200 node graphs,
55.4 secs vs. 71.1 secs for node-link and 84.2 secs for matrix depictions).

</details>


### [362] [OffsetCrust: Variable-Radius Offset Approximation with Power Diagrams](https://arxiv.org/abs/2507.10924)
*Zihan Zhao,Pengfei Wang,Minfeng Xu,Shuangmin Chen,Shiqing Xin,Changhe Tu,Wenping Wang*

Main category: cs.GR

TL;DR: OffsetCrust是一个新的框架，可以有效地计算可变半径的偏移曲面，通过幂图和轻量级微调来解决现有方法的缺点。


<details>
  <summary>Details</summary>
Motivation: 可变半径偏置曲面的计算仍然是一个挑战性问题，而偏移曲面在几何处理中有重要应用。

Method: 通过计算幂图来解决可变半径偏置曲面的问题。幂图由贡献位点构成，这些位点由在基曲面S上仔细采样的点及其对应的离曲面点组成，这些点沿着依赖于R（定义在基曲面S上的半径函数）的方向进行位移。在均匀半径的情况下，这些位移方向与S的法线方向精确对齐。

Result: 该方法在准确性和效率方面得到了广泛的实验验证，并展示了其在从内轴变换（MAT）表示重建原始边界曲面等应用中的实用性。

Conclusion: 该研究提出了一种名为OffsetCrust的新框架，通过计算幂图来解决可变半径偏置曲面的问题，并在均匀半径的情况下，通过轻量级的微调过程来缓解基于 वृत्त (crust) 的方法中常见的错位问题。

Abstract: Offset surfaces, defined as the Minkowski sum of a base surface and a rolling
ball, play a crucial role in geometry processing, with applications ranging
from coverage motion planning to brush modeling. While considerable progress
has been made in computing constant-radius offset surfaces, computing
variable-radius offset surfaces remains a challenging problem. In this paper,
we present OffsetCrust, a novel framework that efficiently addresses the
variable-radius offsetting problem by computing a power diagram. Let $R$ denote
the radius function defined on the base surface $S$. The power diagram is
constructed from contributing sites, consisting of carefully sampled base
points on $S$ and their corresponding off-surface points, displaced along
$R$-dependent directions. In the constant-radius case only, these displacement
directions align exactly with the surface normals of $S$. Moreover, our method
mitigates the misalignment issues commonly seen in crust-based approaches
through a lightweight fine-tuning procedure. We validate the accuracy and
efficiency of OffsetCrust through extensive experiments, and demonstrate its
practical utility in applications such as reconstructing original boundary
surfaces from medial axis transform (MAT) representations.

</details>


### [363] [Elevating 3D Models: High-Quality Texture and Geometry Refinement from a Low-Quality Model](https://arxiv.org/abs/2507.11465)
*Nuri Ryu,Jiyun Won,Jooeun Son,Minsu Gong,Joo-Haeng Lee,Sunghyun Cho*

Main category: cs.GR

TL;DR: Elevate3D是一个新的框架，可以提高低质量3D资产的质量。它使用名为HFS-SDEdit的纹理增强方法，并通过在纹理和几何之间交替来改进模型。与其他方法不同，Elevate3D还包括几何精炼，利用图像中的几何线索来创建更精确的模型。


<details>
  <summary>Details</summary>
Motivation: 为了解决计算机图形学和3D视觉应用中高质量3D资产稀缺且获取成本高昂的问题，提出Elevate3D框架来提升低质量3D资产的质量。

Method: Elevate3D框架通过HFS-SDEdit进行纹理增强，并利用HFS-SDEdit优化后的图像中的几何线索，通过最先进的单目几何预测器进行几何精炼，实现视图与视图的交替优化。

Result: Elevate3D在3D模型精炼方面取得了最先进的质量，优于近期的方法。

Conclusion: Elevate3D通过HFS-SDEdit和几何线索优化，在3D模型精炼方面取得了最先进的质量，有效解决了高质量开源3D资产稀缺的问题。

Abstract: High-quality 3D assets are essential for various applications in computer
graphics and 3D vision but remain scarce due to significant acquisition costs.
To address this shortage, we introduce Elevate3D, a novel framework that
transforms readily accessible low-quality 3D assets into higher quality. At the
core of Elevate3D is HFS-SDEdit, a specialized texture enhancement method that
significantly improves texture quality while preserving the appearance and
geometry while fixing its degradations. Furthermore, Elevate3D operates in a
view-by-view manner, alternating between texture and geometry refinement.
Unlike previous methods that have largely overlooked geometry refinement, our
framework leverages geometric cues from images refined with HFS-SDEdit by
employing state-of-the-art monocular geometry predictors. This approach ensures
detailed and accurate geometry that aligns seamlessly with the enhanced
texture. Elevate3D outperforms recent competitors by achieving state-of-the-art
quality in 3D model refinement, effectively addressing the scarcity of
high-quality open-source 3D assets.

</details>


<div id='cs.AR'></div>

# cs.AR [[Back]](#toc)

### [364] [Device-Level Optimization Techniques for Solid-State Drives: A Survey](https://arxiv.org/abs/2507.10573)
*Tianyu Ren,Yajuan Du,Jinhua Cui,Yina Lv,Qiao Li,Chun Jason Xue*

Main category: cs.AR

TL;DR: This survey analyzes SSD architecture, challenges (scalability, endurance, latency, security), and optimizations (error correction, FTL, ZNS, FDP), highlighting future research directions for AI/LLM workloads.


<details>
  <summary>Details</summary>
Motivation: As storage demands grow, SSDs face critical challenges in scalability, endurance, latency, and security.

Method: The survey examines the fundamental components of SSDs (NAND flash memory, controller functionalities, host interface protocols), discusses major challenges (reliability degradation, endurance limitations, latency variations, security threats), explores advanced optimization techniques (error correction, FTL enhancements, ZNS, FDP), and highlights open research challenges (QLC/PLC NAND scalability, performance-reliability trade-offs, SSD optimizations for AI/LLM workloads).

Result: The survey offers a comprehensive overview of SSDs, their challenges, and optimization techniques, guiding future research.

Conclusion: This survey provides a comprehensive analysis of SSD architecture, key challenges, and device-level optimization techniques. It aims to guide future research in developing next-generation SSDs that balance performance, longevity, and security in evolving storage ecosystems.

Abstract: Solid-state drives (SSDs) have revolutionized data storage with their high
performance, energy efficiency, and reliability. However, as storage demands
grow, SSDs face critical challenges in scalability, endurance, latency, and
security. This survey provides a comprehensive analysis of SSD architecture,
key challenges, and device-level optimization techniques. We first examine the
fundamental components of SSDs, including NAND flash memory structures, SSD
controller functionalities (e.g., address mapping, garbage collection, wear
leveling), and host interface protocols (SATA, SAS, NVMe). Next, we discuss
major challenges such as reliability degradation, endurance limitations,
latency variations, and security threats (e.g., secure deletion, ransomware
defense). We then explore advanced optimization techniques, including error
correction mechanisms, flash translation layer (FTL) enhancements, and emerging
architectures like zoned namespace (ZNS) SSDs and flexible data placement
(FDP). Finally, we highlight open research challenges, such as QLC/PLC NAND
scalability, performance-reliability trade-offs, and SSD optimizations for
AI/LLM workloads. This survey aims to guide future research in developing
next-generation SSDs that balance performance, longevity, and security in
evolving storage ecosystems.

</details>


### [365] [SPICEAssistant: LLM using SPICE Simulation Tools for Schematic Design of Switched-Mode Power Supplies](https://arxiv.org/abs/2507.10639)
*Simon Nau,Jan Krummenauer,André Zimmermann*

Main category: cs.AR

TL;DR: SPICEAssistant框架通过与SPICE仿真器集成，提升了LLM在开关模式电源设计中的表现，相比GPT-4o性能提升38%。


<details>
  <summary>Details</summary>
Motivation: 探索LLM在电子设计自动化（EDA）领域，特别是开关模式电源（SMPS）设计中的应用潜力，解决LLM在理解SPICE仿真结果和多步设计流程方面的局限性。

Method: 提出SPICEAssistant框架，为LLM提供一个包含多种工具的接口，使其能够与SPICE仿真器进行交互，从而评估对电路修改的影响。

Result: SPICEAssistant框架通过增加仿真迭代次数，有效提升了LLM进行SMPS设计的能力。SPICEAssistant在包含256个问题的基准测试中，相比独立的GPT-4o，性能提升了约38%。

Conclusion: SPICEAssistant框架显著优于独立的LLM GPT-4o，在基准测试中表现提升约38%。

Abstract: State-of-the-art large language models (LLMs) show high performance across a
wide range of tasks in many domains of science. In the field of electronic
design automation (EDA), it is yet to be determined to what extent they are
capable to understand, adapt, and dimension electronic circuits. This paper
focuses on the application of LLMs to switched-mode power supply (SMPS) design
on printed circuit boards (PCBs). Particular challenges for LLMs in this
context include their limited ability to interpret results from key simulation
tools like SPICE and the multi-step design process. To address these
challenges, we suggest SPICEAssistant, a framework that provides a broad
selection of tools to an LLM. The tools serve as an interface to SPICE,
allowing the LLM to interact flexibly with the simulator to estimate the impact
of its modifications to the circuit. To evaluate the performance of
SPICEAssistant, we defined a benchmark consisting of 256 questions testing the
ability to adapt circuit netlists to fulfil different SMPS design tasks. The
benchmarking results show that simulation feedback effectively improves SMPS
design capabilities of LLMs. An increasing number of simulation iterations
leads to enhanced performance. The SPICEAssistant framework significantly
outperforms the standalone LLM GPT-4o on the benchmark by approximately 38%.

</details>


### [366] [LASANA: Large-scale Surrogate Modeling for Analog Neuromorphic Architecture Exploration](https://arxiv.org/abs/2507.10748)
*Jason Ho,James A. Boyle,Linshen Liu,Andreas Gerstlauer*

Main category: cs.AR

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Neuromorphic systems using in-memory or event-driven computing are motivated
by the need for more energy-efficient processing of artificial intelligence
workloads. Emerging neuromorphic architectures aim to combine traditional
digital designs with the computational efficiency of analog computing and novel
device technologies. A crucial problem in the rapid exploration and co-design
of such architectures is the lack of tools for fast and accurate modeling and
simulation. Typical mixed-signal design tools integrate a digital simulator
with an analog solver like SPICE, which is prohibitively slow for large
systems. By contrast, behavioral modeling of analog components is faster, but
existing approaches are fixed to specific architectures with limited energy and
performance modeling. In this paper, we propose LASANA, a novel approach that
leverages machine learning to derive data-driven surrogate models of analog
sub-blocks in a digital backend architecture. LASANA uses SPICE-level
simulations of a circuit to train ML models that predict circuit energy,
performance, and behavior at analog/digital interfaces. Such models can provide
energy and performance annotation on top of existing behavioral models or
function as replacements to analog simulation. We apply LASANA to an analog
crossbar array and a spiking neuron circuit. Running MNIST and spiking MNIST,
LASANA surrogates demonstrate up to three orders of magnitude speedup over
SPICE, with energy, latency, and behavioral error less than 7%, 8%, and 2%,
respectively.

</details>


### [367] [OpenGCRAM: An Open-Source Gain Cell Compiler Enabling Design-Space Exploration for AI Workloads](https://arxiv.org/abs/2507.10849)
*Xinxin Wang,Lixian Yan,Shuhan Liu,Luke Upton,Zhuoqi Cai,Yiming Tan,Shengman Li,Koustav Jana,Peijing Li,Jesse Cirimelli-Low,Thierry Tambe,Matthew Guthaus,H. -S. Philip Wong*

Main category: cs.AR

TL;DR: OpenGCRAM是一个开源GCRAM编译器，可以为CMOS代工厂生成GCRAM设计和版图，并进行性能模拟，以满足不同应用的需求。


<details>
  <summary>Details</summary>
Motivation: 为了支持具有不同流量和寿命指标的工作负载，GCRAM也提供高带宽、超低漏电和宽范围的保持时间，这可以通过晶体管设计（如阈值电压和沟道材料）以及通过改变工作电压来动态调整。然而，设计和优化GCRAM子系统可能非常耗时。

Method: 通过用户指定的配置（例如字大小和字数）生成GCRAM bank电路设计和DRC-、LVS-clean版图，并提供面积、延迟和功耗模拟。

Result: OpenGCRAM能够快速、准确、可定制且优化地生成GCRAM块，减少设计时间，确保工艺合规性，并提供满足不同应用需求的、性能定制的内存块。

Conclusion: OpenGCRAM是一个开源GCRAM编译器，能够为商用CMOS代工厂生成GCRAM bank电路设计和DRC-、LVS-clean版图，并根据用户指定的配置（例如字大小和字数）提供面积、延迟和功耗模拟。OpenGCRAM能够快速、准确、可定制且优化地生成GCRAM块，减少设计时间，确保工艺合规性，并提供满足不同应用需求的、性能定制的内存块。

Abstract: Gain Cell memory (GCRAM) offers higher density and lower power than SRAM,
making it a promising candidate for on-chip memory in domain-specific
accelerators. To support workloads with varying traffic and lifetime metrics,
GCRAM also offers high bandwidth, ultra low leakage power and a wide range of
retention times, which can be adjusted through transistor design (like
threshold voltage and channel material) and on-the-fly by changing the
operating voltage. However, designing and optimizing GCRAM sub-systems can be
time-consuming. In this paper, we present OpenGCRAM, an open-source GCRAM
compiler capable of generating GCRAM bank circuit designs and DRC- and
LVS-clean layouts for commercially available foundry CMOS, while also providing
area, delay, and power simulations based on user-specified configurations
(e.g., word size and number of words). OpenGCRAM enables fast, accurate,
customizable, and optimized GCRAM block generation, reduces design time, ensure
process compliance, and delivers performance-tailored memory blocks that meet
diverse application requirements.

</details>


### [368] [Mapping Fusion: Improving FPGA Technology Mapping with ASIC Mapper](https://arxiv.org/abs/2507.10912)
*Cunxi Yu*

Main category: cs.AR

TL;DR: FuseMap框架通过结合ASIC技术映射和强化学习，改进了FPGA的LUT映射，提高了精度并降低了延迟和面积。


<details>
  <summary>Details</summary>
Motivation: ASIC技术映射器可以潜在地提高LUT映射器的性能，使得标准单元映射和LUT映射能够以增量方式协同工作。

Method: 提出FuseMap框架，利用强化学习来改进FPGA的LUT映射过程，并将其与ASIC技术映射相结合，实现增量式映射。

Result: FuseMap在ISCAS 85/89、ITC/ISCAS 99、VTR 8.0和EPFL基准测试集上进行了评估，实验结果表明FuseMap在多种电路设计中实现了更高的映射精度，同时降低了延迟和面积。

Conclusion: FuseMap框架利用强化学习在单元选择过程中做出针对特定设计的选择，以改进FPGA设计流程中的LUT映射，实现了更高的映射精度，并降低了多种电路设计的延迟和面积。

Abstract: LUT (Look-Up Table) mapping is a critical step in FPGA logic synthesis, where
a logic network is transformed into a form that can be directly implemented
using the FPGA's LUTs. An FPGA LUT is a flexible digital memory structure that
can implement any logic function of a limited number of inputs, typically 4 to
6 inputs, depending on the FPGA architecture. The goal of LUT mapping is to map
the Boolean network into LUTs, where each LUT can implement any function with a
fixed number of inputs. In parallel to FPGA technology mapping, ASIC technology
mapping maps the Boolean network to user-defined standard cells, which has
traditionally been developed separately from LUT mapping algorithms. However,
in this work, our motivating examples demonstrate that ASIC technology mappers
can potentially improve the performance of LUT mappers, such that standard cell
mapping and LUT mapping work in an incremental manner.
  Therefore, we propose the FuseMap framework, which explores this opportunity
to improve LUT mapping in the FPGA design flow by utilizing reinforcement
learning to make design-specific choices during cell selection. The
effectiveness of FuseMap is evaluated on a wide range of benchmarks, different
technology libraries, and technology mappers. The experimental results
demonstrate that FuseMap achieves higher mapping accuracy while reducing delay
and area across diverse circuit designs collected from ISCAS 85/89, ITC/ISCAS
99, VTR 8.0, and EPFL benchmarks.

</details>


### [369] [Security Enclave Architecture for Heterogeneous Security Primitives for Supply-Chain Attacks](https://arxiv.org/abs/2507.10971)
*Kshitij Raj,Atri Chatterjee,Patanjali SLPSK,Swarup Bhunia,Sandip Ray*

Main category: cs.AR

TL;DR: CITADEL 是一个创新的模块化安全框架，用于简化片上系统 (SoC) 的安全架构设计。该框架具有高度可配置性和即插即用功能，能够有效应对各种安全威胁，如供应链攻击。通过实际案例研究，CITADEL 被证明在不显著增加硬件成本的情况下，能够显著增强 SoC 的安全性。


<details>
  <summary>Details</summary>
Motivation: 为应对片上系统 (SoC) 安全架构设计耗时且容易出现安全漏洞的挑战，提出 CITADEL 框架以简化设计流程并提高安全性。

Method: CITADEL 是一个模块化的安全框架，通过组合自定义知识产权 (IP) 模块来构建安全子系统，实现可配置、即插即用的功能。

Result: CITADEL 在应对供应链威胁方面进行了实例化演示，并且在多种 ASIC 技术中进行了实际案例研究和评估，结果显示其对硅面积和功耗的影响极小。

Conclusion: CITADEL 是一个模块化的安全框架，可以简化片上系统 (SoC) 的安全架构设计，具有可配置、即插即用等特点，能够针对特定威胁定制安全机制。该框架在应对供应链威胁方面表现出色，并能克服构建统一安全架构以应对多种攻击向量的挑战。实际案例研究表明，CITADEL 在硅面积和功耗方面只有微小的开销，是增强 SoC 安全性的实用解决方案。

Abstract: Designing secure architectures for system-on-chip (SoC) platforms is a highly
intricate and time-intensive task, often requiring months of development and
meticulous verification. Even minor architectural oversights can lead to
critical vulnerabilities that undermine the security of the entire chip. In
response to this challenge, we introduce CITADEL, a modular security framework
aimed at streamlining the creation of robust security architectures for SoCs.
CITADEL offers a configurable, plug-and-play subsystem composed of custom
intellectual property (IP) blocks, enabling the construction of diverse
security mechanisms tailored to specific threats. As a concrete demonstration,
we instantiate CITADEL to defend against supply-chain threats, illustrating how
the framework adapts to one of the most pressing concerns in hardware security.
This paper explores the range of obstacles encountered when building a unified
security architecture capable of addressing multiple attack vectors and
presents CITADEL's strategies for overcoming them. Through several real-world
case studies, we showcase the practical implementation of CITADEL and present a
thorough evaluation of its impact on silicon area and power consumption across
various ASIC technologies. Results indicate that CITADEL introduces only
minimal resource overhead, making it a practical solution for enhancing SoC
security.

</details>


### [370] [SystolicAttention: Fusing FlashAttention within a Single Systolic Array](https://arxiv.org/abs/2507.11331)
*Jiawei Lin,Guokai Chen,Yuanlong Li,Thomas Bourgeat*

Main category: cs.AR

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Transformer models rely heavily on scaled dot-product attention (SDPA),
typically implemented using the FlashAttention algorithm. However, current
systolic-array-based accelerators face significant challenges when executing
FlashAttention. Systolic arrays can only achieve high utilization for
consecutive and large matrix multiplications. In contrast, FlashAttention
requires frequently interleaved matrix multiplications and softmax operations.
  The frequent data swaps between the systolic array and external vector units
result in low systolic array utilization. This is further exacerbated by the
fact that softmax involves numerous non-matrix operations, which are not
well-suited for systolic arrays. Moreover, the concurrent execution of matrix
multiplication on systolic arrays and softmax on vector units leads to register
file and SRAM port contention, further degrading performance.
  To overcome these limitations, we propose FSA, an enhanced systolic array
architecture that enables the entire FlashAttention algorithm to run entirely
within a single systolic array, eliminating the need for external vector units.
At the core of FSA is SystolicAttention, a novel scheduling algorithm that maps
FlashAttention operations onto systolic arrays with fine-grained, element-wise
overlap. This significantly improves array utilization while preserving the
original floating-point operation order to maintain numerical stability.
  We implement FSA in synthesizable RTL and evaluate its performance against
state-of-the-art commercial accelerators. Our results show that FSA achieves
1.77x and 4.83x higher attention FLOPs/s utilization compared to AWS
NeuronCore-v2 and Google TPUv5e, respectively, with only about 10% area
overhead.

</details>


### [371] [Elk: Exploring the Efficiency of Inter-core Connected AI Chips with Deep Learning Compiler Techniques](https://arxiv.org/abs/2507.11506)
*Yiqi Liu,Yuqi Xue,Noelle Crawford,Jilong Xue,Jian Huang*

Main category: cs.AR

TL;DR: Elk is a DL compiler that maximizes AI chip efficiency by optimizing compute, communication, and I/O through advanced scheduling and memory allocation, achieving 94% of ideal performance.


<details>
  <summary>Details</summary>
Motivation: The increasing demand for deep learning (DL) models necessitates efficient AI chips that balance compute, communication, and I/O. However, exploring the efficiency of inter-core connected AI (ICCA) chips is challenging due to the inherent trade-offs among these factors.

Method: Elk, a DL compiler framework, jointly optimizes compute, communication, and I/O by structuring these factors into configurable parameters. It utilizes a novel inductive operator scheduling policy and a cost-aware on-chip memory allocation algorithm to maximize efficiency and generate globally optimized execution plans.

Result: Elk achieves 94% of the ideal roofline performance on average for ICCA chips. It effectively overlaps off-chip data loading and on-chip execution, supporting large DL models and aiding in the architecture design space exploration for new ICCA chip development.

Conclusion: Elk achieves 94% of the ideal roofline performance of ICCA chips on average, demonstrating its effectiveness in supporting large DL models on ICCA chips and enabling architecture design space exploration for new ICCA chip development.

Abstract: To meet the increasing demand of deep learning (DL) models, AI chips are
employing both off-chip memory (e.g., HBM) and high-bandwidth low-latency
interconnect for direct inter-core data exchange. However, it is not easy to
explore the efficiency of these inter-core connected AI (ICCA) chips, due to a
fundamental tussle among compute (per-core execution), communication
(inter-core data exchange), and I/O (off-chip data access).
  In this paper, we develop Elk, a DL compiler framework to maximize the
efficiency of ICCA chips by jointly trading off all the three performance
factors discussed above. Elk structures these performance factors into
configurable parameters and forms a global trade-off space in the DL compiler.
To systematically explore this space and maximize overall efficiency, Elk
employs a new inductive operator scheduling policy and a cost-aware on-chip
memory allocation algorithm. It generates globally optimized execution plans
that best overlap off-chip data loading and on-chip execution. To examine the
efficiency of Elk, we build a full-fledged emulator based on a real ICCA chip
IPU-POD4, and an ICCA chip simulator for sensitivity analysis with different
interconnect network topologies. Elk achieves 94% of the ideal roofline
performance of ICCA chips on average, showing the benefits of supporting large
DL models on ICCA chips. We also show Elk's capability of enabling architecture
design space exploration for new ICCA chip development.

</details>


<div id='cond-mat.mes-hall'></div>

# cond-mat.mes-hall [[Back]](#toc)

### [372] [Quantum criticality and tunable Griffiths phase in superconducting twisted trilayer graphene](https://arxiv.org/abs/2507.10687)
*Phanibhusan S. Mahapatra,Haining Pan,Kenji Watanabe,Takashi Taniguchi,J. H. Pixley,Eva Y. Andrei*

Main category: cond-mat.mes-hall

TL;DR: 在扭曲三层石墨烯中发现磁场可诱导超导体-绝缘体转变，并观察到一种在宽磁场范围内存在的量子格里菲斯相，该相可用倾斜磁场精确控制，并揭示了超导配对局域化等新现象。


<details>
  <summary>Details</summary>
Motivation: 在低维度系统中，量子涨落可能破坏长程相干性，引发超导体-绝缘体转变（SIT），并产生新奇的多体物态。本研究旨在探索扭曲三层石墨烯（TTG）在磁场作用下的SIT行为，并揭示其潜在的量子临界机制。

Method: 通过磁场和倾斜磁场调控扭曲三层石墨烯（TTG），并进行输运测量，观察和分析超导体-绝缘体转变（SIT）现象及其相关的量子临界行为。

Result: 在扭曲三层石墨烯（TTG）中观察到磁场调制的SIT，并发现量子临界性在宽广的磁场范围内表现明显，符合量子格里菲斯相（QGP）的描述。该相表现出由无限随机固定点支配的量子相变和超慢弛豫动力学。此外，研究还观察到电流驱动的绝缘-超导再entrant转变，以及TTG显著违反泡利极限的现象。

Conclusion: 本研究首次在扭曲三层石墨烯（TTG）中观察到磁场调制的超导体-绝缘体转变（SIT），并揭示了量子临界性的新证据，即量子格里菲斯相（QGP）。该相在宽广的磁场范围内存在，并可通过倾斜磁场精确调控，最终指向一个由无限随机固定点支配的量子相变。

Abstract: When dimensionality is reduced, enhanced quantum fluctuations can destroy
long-range phase coherence, driving a superconductor insulator transition, SIT,
where disorder and electronic correlations give rise to novel many-body states.
Here, we report the first observation of a magnetic field tuned SIT in
mirrorsymmetric twisted trilayer graphene, TTG. Remarkably, signatures of
quantum criticality persist over an exceptionally broad range of magnetic
fields and are well described by the formation of a quantum Griffiths phase, a
regime in which rare spatially extended regions develop local order within a
globally disordered phase. This leads to a quantum phase transition governed by
an infinite-randomness fixed point and characterized by ultraslow relaxation
dynamics. Near the quantum critical region, transport measurements reveal
strongly nonlinear electrical behavior, including a current-driven reentrant
transition from insulating to superconducting transport, providing direct
evidence of local superconducting order. By tilting the magnetic field, we are
able to collapse the broad Griffiths regime into a single quantum critical
point, QCP, demonstrating a striking level of control over disorder induced
quantum dynamics. Our results further show that TTG strongly violates the Pauli
limit and establishes twisted trilayer graphene as a tunable platform for
exploring quantum phase fluctuations, Cooper pair localization, and
unconventional superconductivity.

</details>


### [373] [Spin and valley-dependent tunneling in MoS$_2$ through magnetic barrier](https://arxiv.org/abs/2507.10716)
*Ahmed Jellal,Nadia Benlakhouy,Pablo Díaz,David Laroze*

Main category: cond-mat.mes-hall

TL;DR: 研究了磁势垒对 MoS$_{2}$ 电子传输的影响，发现了与自旋轨道耦合和磁场相关的共振隧穿现象，并展示了利用磁势垒实现自旋和谷选择性电子传输的潜力。


<details>
  <summary>Details</summary>
Motivation: 研究了在磁势垒作用下单层二硫化钼 MoS$_{2}$ 中的电子传输。

Method: 采用全带连续模型来捕捉相关的物理现象。

Result: 观察到由磁约束引起的量子干涉效应产生的清晰的共振隧穿特征，并在导带和价带中发现了独特的共振模式，这与 MoS$_{2}$ 的内在自旋-轨道耦合和磁场引起的时反对称性破坏密切相关。

Conclusion: 通过调整外部参数，可以精确控制自旋极化和谷极化电流，表明磁势垒可以控制 MoS$_{2}$ 中的电子自旋和谷，使其成为节能自旋电子和谷电子器件的有前途的平台。

Abstract: We study electron transport in monolayer molybdenum disulfide MoS$_2$
subjected to a magnetic barrier. Our analysis employs a full-band continuum
model to capture the relevant physical phenomena. We focus on how electron
energy, magnetic field strength, and the geometric characteristics of the
barrier affect the transmission and conductance. We observe sharp resonant
tunneling features emerging from quantum interference effects induced by
magnetic confinement. A key outcome of our study is the discovery of distinct
resonance patterns in the conduction and valence bands. These patterns are
closely related to the intrinsic spin-orbit coupling in MoS$_2$ and the
breaking of time-reversal symmetry by the magnetic field. This results in
significant spin and valley selectivity in electron transport. We demonstrate
that adjusting external parameters precisely controls spin-polarized and
valley-polarized currents. We show that a magnetic barrier can control electron
spin and valley in MoS$_2$, making it a promising platform for energy-efficient
spintronic and valleytronic devices.

</details>


### [374] [Imaging Nonlinear Spin Waves in Magnetoacoustic Devices](https://arxiv.org/abs/2507.10724)
*N. Beaver,B. Luo,S-W. Chiu,D. A. Bas,P. J. Shah,A. Franson,M. S. Wolf,M. R. Page,M. J. Newburger,L. Caretta,N. X. Sun,P. Stevenson*

Main category: cond-mat.mes-hall

TL;DR: 该研究使用NV中心研究了磁声器件中的非线性动力学，发现了噪声源并提出了控制方法。


<details>
  <summary>Details</summary>
Motivation: 理解磁声系统的非线性动力学对于其在下一代传感器和计算应用中的发展至关重要。

Method: 利用金刚石中的氮空位（NV）中心，对FeGaB/LiNbO3磁声器件中的非线性磁畴散射过程进行亚微米级空间分辨成像。

Result: 在1425 MHz声学驱动下，观察到高度异质的磁噪声产生，响应在微米尺度上呈现显著差异。时间域测量显示，随着驱动功率的增加，NV中心自旋弛豫率增加了两个数量级，表现出阈值状的非线性行为。

Conclusion: 该研究揭示了限制磁声传感器性能的微观噪声源，并展示了声学模式工程如何实现对非线性磁畴过程的选择性控制。

Abstract: Magnetoacoustic systems offer promising platforms for next-generation sensors
and computing applications, but understanding their nonlinear dynamics remains
challenging. Here, we use nitrogen vacancy (NV) centers in diamond to spatially
map nonlinear magnon scattering processes in FeGaB/LiNbO3 magnetoacoustic
devices with sub-micron resolution. We observe highly heterogeneous magnetic
noise generation under acoustic driving at 1425 MHz, with responses varying
dramatically across micron length scales. Time-domain measurements reveal
threshold-like nonlinear behavior where NV center spin relaxation rates
increase over two orders of magnitude as drive power is increased. These
findings reveal microscopic noise sources that limit magnetoacoustic sensor
performance while simultaneously demonstrating how acoustic mode engineering
could enable selective control of nonlinear magnon processes.

</details>


### [375] [Marginal Metals and Kosterlitz-Thouless Type Phase Transition in Disordered Altermagnets](https://arxiv.org/abs/2507.10762)
*Chang-An Li,Bo Fu,Huaiming Guo,Björn Trauzettel,Song-Bo Zhang*

Main category: cond-mat.mes-hall

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Altermagnetism, a recently discovered magnetic phase characterized by
spin-split bands without net magnetization, has emerged as promising platform
for novel physics and potential applications. However, its stability against
disorder-ubiquitous in real materials-remains poorly understood. Here, we study
the electron localization properties of two-dimensional altermagnets subject to
disorder. Remarkably, we discover a disorder-driven phase transition from a
marginal metallic phase to an insulator, which falls into the
Kosterlitz-Thouless class. We demonstrate this by convincing numerical evidence
and propose a vortex-antivortex-like spin pair picture for its interpretation.
Moreover, we show that the characteristic spin anisotropy of altermagnets
persists but gradually fades away across the transition. These changes directly
affect the spin-splitting features that are detectable in angle-resolved
photoemission spectroscopy and tunneling magnetoresistance. Our findings
provide a new perspective on recent experimental observations of altermagnetism
in candidate materials.

</details>


### [376] [Dimensional crossover of superfluid $^{3}$He in a magnetic field](https://arxiv.org/abs/2507.10763)
*Leyla Saraj,Daksh Malhotra,Aymar Muhikira,Alexander J. Shook,John P. Davis,Igor Boettcher*

Main category: cond-mat.mes-hall

TL;DR: 该研究在纳米限制几何中探索了超流3He的相位图，发现了从3D到准2D的平滑过渡，并为实验提供了指导。


<details>
  <summary>Details</summary>
Motivation: 论文的动机是受到近期在纳米尺度限制几何形状下超流3He实验的启发。

Method: 论文基于最小化Ginzburg-Landau自由能，采用3x3矩阵超流序参数，并考虑了三种不同的边界条件。

Result: 研究观察到在特定条件下，从3D系统到准2D极限存在平滑的相变，并且可以对自由能泛函系数进行精确的数值和解析说明，也可用于约束或测量这些参数。

Conclusion: 论文对超流3He在纳米尺度限制几何形状下的相位图进行了理论研究，重点关注平板几何和垂直磁场对限制尺寸变化的响应。通过对具有三种不同边界条件的3x3矩阵超流序参数的Ginzburg-Landau自由能进行最小化分析，研究观察到在数百纳米的平板高度和数千高斯磁场下，从3D系统到准2D极限的平滑过渡。研究还指出，尽管底层方程复杂，但可以对自由能泛函系数的一般值进行精确的数值和解析说明，这可用于约束或测量这些参数。为了指导未来的实验研究，论文计算了相位图与压力、温度、平板高度和磁场的关系。

Abstract: Motivated by recent experiments on superfluid $^3$He in nanoscale-confined
geometries, we theoretically investigate the associated phase diagram in a slab
geometry and perpendicular magnetic field as the size of confinement is varied.
Our analysis is based on minimizing the Ginzburg--Landau free energy for the
$3\times 3$ matrix superfluid order parameter for three different boundary
conditions. We observe a smooth crossover from the phase diagram of the 3D
system to the quasi-2D limit for slab heights of several hundred nanometres and
magnetic fields of several kilogauss. We illuminate that, despite the apparent
complexity of the underlying equations, many precise numerical and even
analytical statements can be made about the phase structure for general values
of the coefficients of the free energy functional, which can in turn be used to
constrain or measure these parameters. To guide future experimental studies, we
compute the phase diagram in dependence of pressure, temperature, slab height,
and magnetic field.

</details>


### [377] [Moiré dependent Chern insulators in twisted crystalline flatbands](https://arxiv.org/abs/2507.10875)
*Wenxuan Wang,Yijie Wang,Zaizhe Zhang,Zihao Huo,Gengdong Zhou,Kenji Watanabe,Takashi Taniguchi,X. C. Xie,Kaihui Liu,Zhida Song,Xiaobo Lu*

Main category: cond-mat.mes-hall

TL;DR: 双铑三层间隙烯在不同扭转角下表现出丰富的拓扑现象，可用于量子存储和计算。


<details>
  <summary>Details</summary>
Motivation: 研究双铑三层间隙烯在不同扭转角下的对称性破缺态和拓扑现象，探索其在量子存储和计算方面的应用潜力。

Method: 通过实验研究了扭转双铑三层间隙烯的能带结构和对称性破缺态，并观察到了不同扭转角下的拓扑现象。

Result: 在小扭转角下，观察到了 Chern 数 C = 3 的可编程 Chern 绝缘体；在较大扭转角下，观察到了分数填充下的多重 Chern 绝缘体（C = 1），但缺失了 C = 1 的 Chern 绝缘体。

Conclusion: 这项研究展示了来自铑多层石墨烯的扭转平带作为研究拓扑相关物理学的新平台，为开发用于量子存储和计算的新设备提供了有前景的途径。

Abstract: In moir\'e crystals, the competition between different isospin configurations
can be tuned by twist angles and stacking orders, forming various
symmetry-broken states. Here we report twisted double
rhombohedral-trilayer-gaphene as a new twisted crystalline flatbands system
showing rich moir\'e dependent topological phenomena. For small twist angles,
programmable Chern insulators with Chern number C = 3 at integer moir\'e
filling v = 1 have been observed. We have further revealed multiple first-order
transitions and an exotic hidden order which can quench the Chern insulator.
Interestingly, for a larger twist angle, multiple Chern insulators with C = 1
at fractional fillings including v = 1/4, 1/3 and 1/2 have been observed,
whereas the Chern insulator at v = 1 is absent. Our study demonstrated the
twisted flatbands from rhombohedral-multilayer-graphene as a new platform to
study topological correlated physics, offering a promising pathway toward
developing new devices for quantum storage and computation.

</details>


### [378] [Tunable Interlayer Excitons in Bilayer Graphene Nanoribbons](https://arxiv.org/abs/2507.10887)
*Alexandre R. Rocha,Rodrigo G. Amorim,Wanderlã L. Scopel,Cesar E. P. Villegas*

Main category: cond-mat.mes-hall

TL;DR: 本研究利用量子化学计算发现，石墨烯纳米带形成的范德华异质结构中存在层间激子耦合效应，并能实现长寿命激子，有望用于量子调控和光电子器件。


<details>
  <summary>Details</summary>
Motivation: 为了探索垂直堆叠的范德华结构在量子调控和新奇光电子特性方面的潜力，特别是研究层间激子耦合效应。

Method: 利用激发态密度泛函理论计算，研究了直线型石墨烯纳米带衍生的二维范德华纳米结构中的层间激子耦合。

Result: 发现所研究的结构中存在强烈的层间激子耦合，激子响应在近红外区域出现峰值，并观察到了层间激子激发，其吸收峰强度可达最大吸收的13%。同时，发现了促进激子形成的I型和II型带对齐。特别地，在室温下，层间激子的辐射寿命长达1纳秒至9.4微秒。

Conclusion: 通过仔细设计堆叠顺序，可以调节双层石墨烯纳米带的激子响应和寿命，这表明其在量子控制和光电子器件领域具有潜力。

Abstract: Vertically stacked van der Waals structures are promising platforms that
enable layer engineering, opening new avenues for the quantum control of
elementary excitations, including optically generated bound electron-hole
pairs. Here we employ excited-state density functional calculations to
demonstrate strong interlayer excitonic coupling in one-dimensional van der
Waals nanostructures derived from armchair graphene nanoribbons. The excitonic
response exhibits prominent peaks in the near-infrared range, mainly attributed
to intralayer excitons, while interlayer excitations with absorption peak
strengths of up to 13\% of the maximum absorption are also observed. Both
type-I and type-II band alignments are found, which promote the formation of
intralayer and interlayer excitons. Notably, interlayer excitons in these
systems exhibit long-lived radiative lifetimes at room temperature, ranging
from 1 nanosecond to 9.4 microseconds. Our calculations suggest the potential
to tune the excitonic response and lifetimes of bilayer graphene nanoribbons
via careful engineering of the stacking order.

</details>


### [379] [Polarons in two-dimensional polar materials: All-coupling variational theory](https://arxiv.org/abs/2507.10930)
*A. Kudlis,V. Shahnazaryan,I. V. Tokatly*

Main category: cond-mat.mes-hall

TL;DR: A theoretical study of polarons in 2D materials using experimentally accessible parameters and Feynman's approach, analyzing coupling regimes to understand polaron properties.


<details>
  <summary>Details</summary>
Motivation: The motivation is to provide a detailed theoretical study of polarons in 2D polar materials, extending existing theories to this new class of materials.

Method: The paper extends the classical Fr"ohlich polaron theory to 2D materials. It defines a dimensionless parameter to characterize electron-phonon coupling and uses the Feynman variational path-integral approach to analyze both weak and strong coupling regimes.

Result: The theoretical framework is determined by experimentally accessible parameters and analyzes both weak and strong coupling regimes, offering insights into polaron properties in 2D materials.

Conclusion: The study provides insights into the ground-state energy and effective mass of polarons in 2D polar monolayers, based on a theoretical framework derived from experimentally accessible parameters.

Abstract: We present a detailed and self-contained theoretical study of polarons in
two-dimensional (2D) polar materials, which extends the classical macroscopic
theory of Fr\"ohlich polarons to the 2D case. The theory is fully determined by
experimentally accessible parameters, the static and optical 2D
polarizabilities of a monolayer, the frequency of transverse optical phonons,
and the effective mass of charge carriers. We define a single dimensionless
parameter, which characterizes the coupling of electrons with longitudinal
optical phonons, analyze both weak- and strong-coupling regimes, and adopt the
Feynman variational path-integral approach for a high-quality interpolation
between these limits. Our results provide insight into the ground-state energy
and effective mass of polarons in the new generation of 2D polar monolayers.

</details>


### [380] [Adiabatic nonabelian braiding of imperfect Majoranas](https://arxiv.org/abs/2507.11039)
*Maximilian Nitsch,Viktor Svensson,William Samuelson,Konstantin Nestmann,Jeroen Danon,Karsten Flensberg,Rubén Seoane Souto,Martin Leijnse*

Main category: cond-mat.mes-hall

TL;DR: 提出了一种在不完美MBS系统中进行鲁棒非阿贝尔编织的新方法，即使在MBS不完全隔离的情况下也适用。


<details>
  <summary>Details</summary>
Motivation: 在具有散射和光滑势能变化的有限系统中，MBS并不完美，可能类似于常规费米子，而通常认为准粒子交换（或编织）是拓扑相的明确证据。

Method: 研究了隔离MBS、常规费米子以及介于两者之间状态的编织性质，并提出了一种补偿因不完美MBS编织协议引起的不期望的地面态简并分裂的方法。

Result: 发现所提出的编织协议在不完美MBS系统中是鲁棒且非阿贝尔的，其结果取决于MBS的隔离度，但在完全费米子的情况下除外。

Conclusion: 该研究提出了一种补偿不完美Majorana束缚态（MBS）系统中的地面态简并分裂的方法，使得编织结果在一定程度上依赖于MBS的隔离度，但只要不是完全费米子化的极限，结果仍然是鲁棒且非阿贝尔的。

Abstract: Demonstration of a nontrivial result of quasiparticle exchange (or braiding)
is usually considered the definitive proof of a topological phase with
nonabelian excitations, such as Majorana bound states (MBSs). However, in
finite systems with disorder and smooth potential variations, the MBSs are
imperfect in the sense that they are not fully isolated in space and can, to a
varying degree, resemble conventional fermions. Here, we study the braiding
properties of isolated MBSs, regular fermions, and anything in between. We find
a way to compensate for the undesired splitting of the ground-state degeneracy
which occurs during the protocol for imperfect MBS. This leads to a braiding
outcome that depends on the degree of MBS isolation but remains robust and
nonabelian except in the perfect fermion limit. Our protocol could be
implemented in different platforms with nonabelian excitations, including
quantum-dot-based minimal Kitaev chains.

</details>


### [381] [Internal dynamics and dielectric screening of confined multiexciton states](https://arxiv.org/abs/2507.11087)
*Josep Planelles,Juan I. Climente,Jose L. Movilla*

Main category: cond-mat.mes-hall

TL;DR: 大型CsPbBr3纳米晶体中的二激子（BX）具有比激子（X）和三体（X*）更低的介电屏蔽。这是因为BX的内部动力学频率较低，导致其介电常数降低。


<details>
  <summary>Details</summary>
Motivation: 解释为什么激子（X）和三体（X*）在大型CsPbBr3纳米晶体中比二激子（BX）经历更少的介电屏蔽。

Method: 使用有效质量-变分量子蒙特卡洛模拟，并引入特征频率来描述激子内部动力学。

Result: 模拟结果表明，大型纳米晶体中X和X*的特征频率相似，而BX的特征频率较低。由于这些频率高于块体LO声子的频率，因此BX的介电常数较低，这与强约束纳米晶体的情况相反。

Conclusion: BX在大型CsPbBr3纳米晶体中的介电屏蔽效应比X和X*弱，这是由于其内部动力学频率低于LO声子频率，导致其介电常数降低。

Abstract: Recent experimental and computational studies suggest that biexcitons (BX)
confined in large CsPbBr$_3$ nanocrystals experience reduced dielectric
screening as compared to excitons (X) and trions (X$^*$). Here we provide a
physical rationale to explain such a behavior. A characteristic frequency is
introduced, which describes the internal dynamics of an exciton within the
excitonic complex. By means of effective mass--variational Quantum Monte Carlo
simulations, we show that, in large nanocrystals, the frequency is similar for
X and X$^*$, but smaller for BX. Because the frequencies exceed that of the
bulk longitudinal optical phonon, this leads to a reduced dielectric constant
for BX, which is in contrast with the behavior of strongly confined
nanocrystals.

</details>


### [382] [Near transform-limited single photons from rapid-thermal annealed quantum dots](https://arxiv.org/abs/2507.11108)
*Hendrik Mannel,Fabio Rimek,Marcel Zoellner,Nico Schwarz,Andreas D. Wieck,Nikolai Bart,Arne Ludwig,Martin Geller*

Main category: cond-mat.mes-hall

TL;DR: 本研究使用快速热退火（RTA）调控了自组装InAs/GaAs量子点的光学性质，发现该方法在保持单光子发射质量的同时，实现了发射波长蓝移，为量子光子应用提供了有效手段。


<details>
  <summary>Details</summary>
Motivation: 为了实现量子通信和量子互联网等应用，研究了自组装InAs/GaAs量子点（QDs）的单光子发射特性，并探索了退火对其光学性质的影响。

Method: 通过在低温（4.2 K）下进行共振荧光测量，研究了退火对量子点单光子统计、发射线宽和相干时间 $T_2$ 的影响。

Result: 研究发现，尽管退火温度高达 $760^	ext{o}	ext{C}$，但该过程并未严重降低量子点的光学质量。相反，观察到近乎傅里叶极限的单光子发射线宽，且相干时间 $T_2$ 仅为傅里叶极限 $T_2=2T_1$ 的1.5倍。

Conclusion: 本研究表明，快速热退火（RTA）是调整量子点光学性质的有效方法，能够保持关键的单光子发射特性，并可能有助于减少量子光子应用中非辐射俄歇复合等不良效应。

Abstract: Single-photon emitters are essential components for quantum communication
systems, enabling applications such as secure quantum key distribution and the
long-term vision of a quantum internet. Among various candidates,
self-assembled InAs/GaAs quantum dots (QDs) remain highly promising due to
their ability to emit coherent and indistinguishable photons, as well as their
compatibility with photonic integration. In this work, we investigate the
impact of post-growth rapid thermal annealing (RTA) on the quantum optical
properties of single self-assembled QDs embedded in a p-i-n diode structure.
The annealing process induces a controlled blueshift of the emission wavelength
by promoting Ga in-diffusion and intermixing. Using resonance fluorescence
measurements at cryogenic temperatures (4.2 K), we investigate the
single-photon statistics, the emission linewidths, and coherence time $T_2$ of
the emitted photons. Our results show that, despite the high annealing
temperature of $760^\circ$C, the process does not degrade the optical quality
of the quantum dots strongly. Instead, we observe single-photon emission with
near transform-limited linewidths, where the dephasing time $T_2$ is only a
factor 1.5 above the Fourier-limit $T_2=2T_1$. These findings demonstrate that
rapid thermal annealing (RTA) serves as an effective tuning method that
preserves the key single-photon emission properties and may help reduce
undesirable effects such as non-radiative Auger recombination in quantum
photonic applications.

</details>


### [383] [Significant electron-magnon scattering in layered ferromagnet Cr$_2$Te$_3$](https://arxiv.org/abs/2507.11182)
*Yujun Wang,Shunzhen Wang,Masashi Kawaguchi,Jun Uzuhashi,Akhilesh Kumar Patel,Kenji Nawa,Yuya Sakuraba,Tadakatsu Ohkubo,Hiroshi Kohno,Masamitsu Hayashi*

Main category: cond-mat.mes-hall

TL;DR: В Cr$_{2}$Te$_{3}$ аномальный холловский эффект возникает из-за рассеяния электронов на магнитонах, а изменение знака связано с конкуренцией с ягодами/примесями.


<details>
  <summary>Details</summary>
Motivation: Неизвестность происхождения аномального холловского эффекта и изменения его знака в слоистом ферромагнетике Cr$_{2}$Te$_{3}$, несмотря на его уникальные электронные и магнитные свойства.

Method: Экспериментально показано, что рассеяние электронов на магнитонах значительно влияет на аномальный холловский эффект в Cr$_{2}$Te$_{3}$ за счет индуцированного магнитонами смещения.

Result: Предлагается, что индуцированное магнитонами смещение может доминировать в аномальном холловском эффекте в слоистых ферромагнетиках с тяжелыми элементами.

Conclusion: 电子-磁畴относятся к аномальному холловскому эффекту в Cr$_{2}$Te$_{3}$ через индуцированное магнитонами смещение, и изменение знака вызвано конкуренцией с материалом, вызванным ягодами или примесями.

Abstract: A layered ferromagnet Cr$_2$Te$_3$ is attracting growing interest because of
its unique electronic and magnetic properties. Studies have shown that it
exhibits sizable anomalous Hall effect (AHE) that changes sign with
temperature. The origin of the AHE and the sign change, however, remains
elusive. Here we show experimentally that electron-magnon scattering
significantly contributes to the AHE in Cr$_2$Te$_3$ through magnon induced
skew scattering, and that the sign change is caused by the competition with the
Berry-curvature or impurity-induced side-jump contribution. The electron-magnon
skew scattering is expected to arise from the exchange interaction between the
itinerant Te $p$-electrons and the localized Cr $d$-electrons modified by the
strong spin-orbit coupling on Te. These results suggest that the magnon-induced
skew scattering can dominate the AHE in layered ferromagnets with heavy
elements.

</details>


### [384] [Diverse high-Chern-number quantum anomalous Hall insulators in twisted rhombohedral graphene](https://arxiv.org/abs/2507.11347)
*Naitian Liu,Zhangyuan Chen,Jing Ding,Wenqiang Zhou,Hanxiao Xiang,Xinjie Fang,Linfeng Wu,Xiaowan Zhan,Le Zhang,Qianmei Chen,Kenji Watanabe,Takashi Taniguchi,Na Xin,Shuigang Xu*

Main category: cond-mat.mes-hall

TL;DR: 本研究在扭曲石墨烯中实现了高陈数的量子反常霍尔效应，为先进电子学和量子物理研究提供了新平台。


<details>
  <summary>Details</summary>
Motivation: 旨在实现具有高陈数（C）的量子反常霍尔（QAH）绝缘体，以实现低功耗电子学所需的多条无耗散边缘通道。

Method: 通过精确控制扭曲角度（约1.40°和0.89°）和电子填充，在扭曲菱面形多层石墨烯中观测到量子反常霍尔效应。

Result: 在扭曲角度约1.40°时，在1.2个载流子每莫尔单位格的填充下，在高达2开尔文的温度下实现了C=5的QAH效应。此外，在部分填充下出现了C=5, 6, 7的非整周期QAH绝缘体。在0.89°的扭曲角度下，在两个和三个电子的填充下分别出现了C=3和C=6的陈绝缘体。

Conclusion: 该研究报告在扭曲单层菱面形五层石墨烯中实现了多种高陈数（C=3, 5, 6, 7）的量子反常霍尔（QAH）绝缘体，并展示了其在多通道、无耗散电子学和探索奇异量子霍尔态方面的潜力。

Abstract: Quantum anomalous Hall (QAH) insulators with high Chern number (C) enables
multiple dissipationless edge channels for low-power-consumption electronics.
We report the realization of multiple high-C QAH insulators including C=3,5,6,
and 7 in twisted monolayer-rhombohedral pentalayer graphene. In twist angles of
approximately 1.40{\deg}, we observe QAH effect with C=5 at a filling of one
electron per moir\'e unit cell, persisting up to 2 Kelvin. Furthermore,
incommensurate QAH insulators with C=5,6, and 7 emerge at partial fillings. In
twist angles of 0.89{\deg}, Chern insulators with C=3 and C=6 appear at
fillings of two and three electrons, respectively. Our findings establish
twisted rhombohedral multilayer graphene as a highly tunable platform for
multichannel, dissipationless electronics and for the exploration of exotic
quantum Hall states beyond traditional Landau level paradigm.

</details>


### [385] [High-frequency surface acoustic waves: Generation with sub-optical wavelength metal gratings and detection at the exciton resonance](https://arxiv.org/abs/2507.11425)
*Olga Ken,Dmytro Horiachyi,Ilya Akimov,Vladimir Korenev,Vitalyi Gusev,Leonid Litvin,Michael Kahl,Arne Ludwig,Nikolai Spitzer,Andreas D. Wieck,Manfred Bayer*

Main category: cond-mat.mes-hall

TL;DR: 通过利用GaAs的激子共振，我们开发了一种高灵敏度的all-optical方法来生成和检测高达30 GHz的表面声波。


<details>
  <summary>Details</summary>
Motivation: 为了实现高频表面声波（SAW）的all-optical生成和检测，并提高检测灵敏度。

Method: 利用偏振敏感泵浦-探测技术，通过激子共振引起的介电函数变化来检测SAW，并建立了一个考虑了探针光衍射和不考虑探针光衍射两种情况的理论模型。

Result: 成功生成和检测了高达~30 GHz的SAW，并将检测灵敏度提高了约一个数量级。

Conclusion: 我们展示了在具有短周期Au光栅的GaAs/AlAlOx异质结构中 all-optical 生成和检测高频（高达~30 GHz）表面声波（SAW）的方法，并提出了一种利用GaAs窄激子共振的，对SAW进行检测的偏振敏感泵浦-探测技术，该技术能够实现比离开共振点检测高一个数量级的检测灵敏度。

Abstract: We demonstrate all-optical generation and detection of high-frequency (up to
~30 GHz) surface acoustic waves (SAWs) in GaAs/AlGaAs heterostructures with
short-period Au gratings on top. We present a sensitive method of SAWs
detection by means of a polarization-sensitive pump-probe technique that
exploits the narrow exciton resonance in high-quality GaAs. The elastic strain
of the SAW causes modulation of the exciton energy in the time domain. As a
result, even a small deformation leads to a noticeable change in the dielectric
function at the detection wavelength leading to an order of magnitude increase
in the detection sensitivity as compared to detection apart from the resonance.
A theoretical model is developed that considers two detection schemes: one
accounting for probe light diffraction and one without.

</details>


### [386] [Optimized Synthesis and Device Integration of Long 17-Atom-Wide Armchair Graphene Nanoribbons](https://arxiv.org/abs/2507.11307)
*Jeong Ha Hwang,Nicolò Bassi,Mayada Fadel,Oliver Braun,Tim Dumslaff,Carlo Pignedoli,Michael Stiefel,Roman Furrer,Hironobu Hayashi,Hiroko Yamada,Akimitsu Narita,Klaus Müllen,Michel Calame,Mickael L. Perrin,Roman Fasel,Pascal Ruffieux,Vincent Meunier,Gabriela Borin Barin*

Main category: cond-mat.mes-hall

TL;DR: 通过优化在衬底上的合成方法，成功提高了17-AGNRs的长度和稳定性，并将其集成到晶体管器件中，证明了其在碳基纳米电子学中的应用潜力。


<details>
  <summary>Details</summary>
Motivation: 为了满足器件集成对17-AGNRs的结构要求，特别是长度参数，需要优化其合成方法。

Method: 采用在分子前体上进行精确控制的底物合成（OSS）方法，在超高真空（UHV）下合成17-碳原子的扶手状石墨烯纳米带（17-AGNRs），并通过优化合成条件，如缓慢升温和增加表面覆盖率，显著提高了17-AGNRs的长度至约17纳米。研究还利用扫描探针技术和拉曼光谱对合成的17-AGNRs进行了表征，并评估了其在不同环境下的稳定性和在场效应晶体管（FET）中的集成应用。

Result: 优化后的OSS条件可生产平均长度约为17纳米的17-AGNRs，这些纳米带在衬底转移后仍表现出良好的稳定性和环境兼容性，并成功集成到具有石墨烯电极的场效应晶体管（FET）中，证实了电子传输发生在GNRs中。

Conclusion: 该研究展示了将窄带隙的17-AGNRs集成到功能器件中的可行性，并为碳基纳米电子学的发展做出了贡献。

Abstract: Seventeen-carbon-atom-wide armchair graphene nanoribbons (17-AGNRs) are
promising candidates for high-performance electronic devices due to their
narrow electronic bandgap. Atomic precision in edge structure and width control
is achieved through a bottom-up on-surface synthesis (OSS) approach from
tailored molecular precursors in ultra-high vacuum (UHV). This synthetic
protocol must be optimized to meet the structural requirements for device
integration, with ribbon length being the most critical parameter. Here, we
report optimized OSS conditions that produce 17-AGNRs with an average length of
approximately 17 nm. This length enhancement is achieved through a gradual
temperature ramping during an extended annealing period, combined with a
template-like effect driven by monomer assembly at high surface coverage. The
resulting 17-AGNRs are comprehensively characterized in UHV using scanning
probe techniques and Raman spectroscopy. Raman measurements following substrate
transfer enabled the characterization of the length distribution of GNRs on the
device substrate and confirmed their stability under ambient conditions and
harsh chemical environments, including acid vapors and etchants. The increased
length and ambient stability of the 17-AGNRs lead to their reliable integration
into device architectures. As a proof of concept, we integrate 17-AGNRs into
field-effect transistors (FET) with graphene electrodes and confirm that
electronic transport occurs through the GNRs. This work demonstrates the
feasibility of integrating narrow-bandgap GNRs into functional devices and
contributes to advancing the development of carbon-based nanoelectronics.

</details>


<div id='quant-ph'></div>

# quant-ph [[Back]](#toc)

### [387] [Formal Verification of Variational Quantum Circuits](https://arxiv.org/abs/2507.10635)
*Nicola Assolini,Luca Marzari,Isabella Mastroeni,Alessandra di Pierro*

Main category: quant-ph

TL;DR: 本研究填补了变分量子电路（VQC）形式化验证的空白，提出了一种新的基于抽象解释的框架，解决了量子领域的挑战，并验证了其实用性。


<details>
  <summary>Details</summary>
Motivation: 为了解决变分量子电路（VQC）在面对对抗性输入时缺乏形式化验证框架的问题，为量子机器学习模型提供鲁棒性认证。

Method: 提出了一种新颖的基于抽象解释的语义框架，用于形式化定义VQC的验证问题并分析其复杂度，同时研究了区间可达性技术在量子领域的适用性和局限性。

Result: 展示了所提出方法的有效性，并分析了量子特定因素（如状态归一化）对现有验证方法带来的挑战。

Conclusion: 本研究首次深入研究了变分量子电路（VQC）的形式验证问题，并提出了一种新颖的基于抽象解释的语义框架来应对量子特有的挑战。

Abstract: Variational quantum circuits (VQCs) are a central component of many quantum
machine learning algorithms, offering a hybrid quantum-classical framework
that, under certain aspects, can be considered similar to classical deep neural
networks. A shared aspect is, for instance, their vulnerability to adversarial
inputs, small perturbations that can lead to incorrect predictions. While
formal verification techniques have been extensively developed for classical
models, no comparable framework exists for certifying the robustness of VQCs.
Here, we present the first in-depth theoretical and practical study of the
formal verification problem for VQCs. Inspired by abstract interpretation
methods used in deep learning, we analyze the applicability and limitations of
interval-based reachability techniques in the quantum setting. We show that
quantum-specific aspects, such as state normalization, introduce inter-variable
dependencies that challenge existing approaches. We investigate these issues by
introducing a novel semantic framework based on abstract interpretation, where
the verification problem for VQCs can be formally defined, and its complexity
analyzed. Finally, we demonstrate our approach on standard verification
benchmarks.

</details>


### [388] [Stabilizer Rényi Entropy Encodes Fusion Rules of Topological Defects and Boundaries](https://arxiv.org/abs/2507.10656)
*Masahiro Hoshino,Yuto Ashida*

Main category: quant-ph

TL;DR: SRE可用于研究量子临界系统中的缺陷。开放边界和拓扑缺陷在SRE中产生特定的修正，SRE还能反映缺陷融合规则。Ising模型数值计算验证了这些发现。


<details>
  <summary>Details</summary>
Motivation: 探索SRE（可计算的量子魔性度量）作为信息论探针，用于研究一维量子临界系统中渐近缺陷的普适性质。

Method: 利用边界共形场论，推导SRE与开放边界（对数修正）和拓扑缺陷（尺寸无关项）的关系，并通过数值计算（Ising模型）验证理论预测。

Result: 开放边界导致SRE出现普适对数修正，拓扑缺陷产生普适尺寸无关项。多个缺陷的存在使得SRE中的普适项能够精确反映定义非可逆对称代数的缺陷融合规则。

Conclusion: SRE可作为探针，用于研究一维量子临界系统中渐近缺陷的普适性质，特别是开放边界和拓扑缺陷在SRE中表现为特定的普适修正项，且SRE能反映缺陷融合规则（非可逆对称代数）。

Abstract: We demonstrate that the stabilizer R\'{e}nyi entropy (SRE), a computable
measure of quantum magic, can serve as an information-theoretic probe for
universal properties associated with conformal defects in one-dimensional
quantum critical systems. Using boundary conformal field theory, we show that
open boundaries manifest as a universal logarithmic correction to the SRE,
whereas topological defects yield a universal size-independent term. When
multiple defects are present, we find that the universal terms in the SRE
faithfully reflect the defect-fusion rules that define noninvertible symmetry
algebra. These analytical predictions are corroborated by numerical
calculations of the Ising model, where boundaries and topological defects are
described by Cardy states and Verlinde lines, respectively.

</details>


### [389] [Optimal Calibration of Qubit Detuning and Crosstalk](https://arxiv.org/abs/2507.10661)
*David Shnaiderov,Matan Ben Dov,Yoav Woldiger,Assaf Hamo,Eugene Demler,Emanuele G. Dalla Torre*

Main category: quant-ph

TL;DR: 量子计算中的校准：更少测量，更快速度。


<details>
  <summary>Details</summary>
Motivation: 量子处理器中物理量子比特的表征和校准对于维持其性能至关重要，而串扰的存在使估计单个量子比特的失谐变得复杂。

Method: 通过优化拉姆齐干涉实验并利用费雪信息和克拉美-Rao边界来推导估计拉 姆齐干涉和串扰参数的最优策略。

Result: 实验证明，该方法在单个 NV 中心和超导 Transmon 上都能实现参数的精确提取，与现有方法相比，测量次数减少了 50%，同时保持了估计精度。

Conclusion: 所提出的方法能够以更少 的测量次数实现精确的参数提取，并将校准时间缩短多达 50%，同时保持估计精度。

Abstract: Characterizing and calibrating physical qubits is essential for maintaining
the performance of quantum processors. A key challenge in this process is the
presence of crosstalk that complicates the estimation of individual qubit
detunings. In this work, we derive optimal strategies for estimating detuning
and crosstalk parameters by optimizing Ramsey interference experiments using
Fisher information and the Cramer-Rao bound. We compare several calibration
protocols, including measurements of a single quadrature at multiple times and
of two quadratures at a single time, for a fixed number of total measurements.
Our results predict that the latter approach yields the highest precision and
robustness in both cases of isolated and coupled qubits. We validate
experimentally our approach using a single NV center as well as superconducting
transmons. Our approach enables accurate parameter extraction with
significantly fewer measurements, resulting in up to a 50\% reduction in
calibration time while maintaining estimation accuracy.

</details>


### [390] [Entanglement and Purity in Open Systems: A Breakdown of the Lindblad Approach](https://arxiv.org/abs/2507.10668)
*Raoul Serao,Aniello Quaranta,Antonio Capolupo,Fabio Franchini,Salvatore Marco Giampaolo*

Main category: quant-ph

TL;DR: Lindblad master equation 在模拟开放量子系统短期动力学时存在局限性，可能导致对纠缠和纯度行为的错误预测。


<details>
  <summary>Details</summary>
Motivation: 旨在评估 Lindblad master equation 在模拟开放量子系统短期动力学方面的准确性，并揭示其潜在局限性。

Method: 通过比较 Lindblad master equation 和完整的微观处理方法，来检验 Lindblad master equation 在模拟开放量子系统（特别是两个相互作用的二能级系统）短期动力学（纠缠和纯度）方面的有效性。

Result: 微观处理方法显示纠缠增长和纯度呈二次衰减，而 Lindbladian 方法预测纯度呈线性衰减，并且在耗散耦合超过相互作用强度时会抑制纠缠。时间依赖的 Lindbladian 模型改善了部分预测，但导致其他可观测量的结果不一致。

Conclusion: Lindblad master equation 在捕捉开放量子系统纠缠和纯度短期动力学方面存在局限性，尤其是在耗散耦合超过相互作用强度时，它会抑制纠缠，并可能导致纯度衰减的预测不准确。即使是时间依赖的 Lindbladian 模型，也只能改善部分预测，而导致其他可观测量的结果不一致。

Abstract: We examine the effectiveness of Lindblad master equation in capturing the
short-time dynamics of entanglement and purity in open quantum systems.
Focusing on two interacting two-level systems interacting with a larger
environment, we compare the Lindbladian approach to a full microscopic
treatment. While the latter shows entanglement growth and a quadratic decay of
purity, the Lindbladian method predicts a linear purity decay and can entirely
suppress entanglement when the dissipative coupling exceeds the interaction
strength. Introducing a time-dependent Lindbladian improves some predictions
but causes inconsistencies in other observables. Our results highlight the
limitations of effective models and the need for caution when applying them to
describe subtle quantum behaviors.

</details>


### [391] [Optimal quantum transport on a ring via locally monitored chiral quantum walks](https://arxiv.org/abs/2507.10669)
*Sara Finocchiaro,Giovanni Luilli,Giuliano Benenti,Matteo G. A. Paris,Luca Razzoli*

Main category: quant-ph

TL;DR: 通过局部监测的连续时间手征量子行走，在环上实现了高效的激发转移，无需精细调整演化时间。


<details>
  <summary>Details</summary>
Motivation: 在纯相干传输的有限网络中，破坏性干涉会显著抑制传输概率，只有通过精心调整演化时间或制备初始状态才能达到高值。

Method: 研究了一个环上的激发转移问题，将其建模为局部监测的连续时间手征量子行走。通过时间反演对称性破坏引入手征性，赋予相干动力学方向偏差并能提升暗态。通过在目标位点进行频闪投影测量来实现局部监测，无需精细调整演化时间即可进行实际探测。

Result: 通过分析手征性与测量频率的相互作用，确定了最大化渐近探测概率的最佳条件。该传输协议的优化依赖于描述渐近非幺正动力学的Perron-Frobenius算子的谱性质以及对暗态的分析。

Conclusion: 该方法为在受监控系统中增强量子输运提供了一个通用框架。

Abstract: In purely coherent transport on finite networks, destructive interference can
significantly suppress transfer probabilities, which can only reach high values
through careful fine-tuning of the evolution time or tailored initial-state
preparations. We address this issue by investigating excitation transfer on a
ring, modeling it as a locally monitored continuous-time chiral quantum walk.
Chirality, introduced through time-reversal symmetry breaking, imparts a
directional bias to the coherent dynamics and can lift dark states. Local
monitoring, implemented via stroboscopic projective measurements at the target
site, provides a practical detection protocol without requiring fine-tuning of
the evolution time. By analyzing the interplay between chirality and
measurement frequency, we identify optimal conditions for maximizing the
asymptotic detection probability. The optimization of this transfer protocol
relies on the spectral properties of the Perron-Frobenius operator, which
capture the asymptotic non-unitary dynamics, and on the analysis of dark
states. Our approach offers a general framework for enhancing quantum transport
in monitored systems.

</details>


### [392] [Data-insenstive cooling of polar molecules with Rydberg atoms](https://arxiv.org/abs/2507.10671)
*Jeremy T. Young,Ron Belyansky,Kang-Kuen Ni,Alexey V. Gorshkov*

Main category: quant-ph

TL;DR: 一种新的冷却技术，利用里德堡原子冷却极性分子，保持其量子信息，延长量子计算时间。


<details>
  <summary>Details</summary>
Motivation: 为了在极性分子和中性原子的混合陈列中扩展量子计算和模拟的时间。

Method: 利用里德堡原子与极性分子之间的范德华或偶极相互作用，通过声子交换实现相干冷却，并设计了状态不敏感的相互作用。

Result: 成功实现了对极性分子的相干冷却，同时保持了其内部量子态的完整性，为混合量子系统中量子信息的扩展提供了可能。

Conclusion: 本文提出了一种利用里德堡原子对极性分子进行冷却的方法，同时不破坏分子中编码的量子信息。通过选择合适的内态并施加外部场，实现了热分子与冷原子之间的状态不敏感相互作用。这种相互作用（可能是范德华相互作用或偶极相互作用）会在两个物种之间诱导声子交换相互作用，从而在不影响内态的情况下相干地冷却极性分子。该过程可以重复进行，以实现持续冷却。

Abstract: We propose a method to sympathetically cool polar molecules with Rydberg
atoms without destroying the quantum information encoded in the polar
molecules. While the interactions between the two are usually state-dependent,
we show how to engineer state-insensitive interactions between the hot
molecules and the cold atoms with a suitable choice of internal states and the
application of external fields. The resulting interactions, which may be van
der Waals or dipolar, induce a phonon swap interaction between the two species,
thereby coherently cooling the polar molecules without affecting the internal
state, a process which can be repeated if the atoms are cooled again or new
cold atoms are brought in. Our cooling schemes open the possibility of
extending quantum computation and simulation times in emerging hybrid tweezer
arrays of polar molecules and neutral atoms.

</details>


### [393] [Manarat: A Scalable QICK-Based Control System for Superconducting Quantum Processors Supporting Synchronized Control of 10 Flux-Tunable Qubits](https://arxiv.org/abs/2507.10676)
*Agustin Silva,Alvaro Orgaz-Fuertes*

Main category: quant-ph

TL;DR: Manarat是一个基于QICK的可扩展多板控制平台，通过硬件、固件和软件的增强，实现了跨多个RFSoC板的亚纳秒级定时对齐。该平台已成功用于10量子比特处理器的同步控制，为构建更大规模的量子计算机提供了解决方案。


<details>
  <summary>Details</summary>
Motivation: 现有的QICK框架虽然提供了灵活的开源脉冲级量子比特控制，但缺乏对多板同步的原生支持，这限制了其在中大规模量子设备上的应用。为了解决这一限制，需要一个可扩展的多板控制平台。

Method: Manarat平台基于QICK，通过集成低抖动时钟分发网络、对tProcessor的修改以及一种确定性地对齐跨板程序执行的同步方案，实现了跨多个AMD ZCU216 RFSoC板的100皮秒级定时对齐。此外，还包括一个定制的模拟前端，用于磁通控制，集成了高速RF信号和低噪声、高精度DAC产生的软件可编程直流偏置电压。软件栈能够协调同步的多板实验，并与Qibo框架完全集成。

Result: Manarat平台成功实现了跨多个RFSoC板的亚纳秒级定时对齐和相干控制，并能在10量子比特的超导处理器上可靠执行同步控制序列，例如跨板CZ门校准。

Conclusion: Manarat平台在10个量子比特的超导处理器上进行了验证，通过两个RFSoC板实现了跨板CZ门校准等同步控制序列的可靠执行，证明了在多个RFSoC板之间实现亚纳秒同步和相干控制是可行的，为超导量子计算机的可扩展操作奠定了基础。

Abstract: A scalable control architecture for superconducting quantum processors is
essential as the number of qubits increases and coherent multi-qubit operations
span beyond the capacity of a single control module. The Quantum
Instrumentation Control Kit (QICK), built on AMD RFSoC platforms, offers a
flexible open-source framework for pulse-level qubit control but lacks native
support for multi-board synchronization, limiting its applicability to mid- and
large-scale quantum devices. To overcome this limitation, we introduce Manarat,
a scalable multi-board control platform based on QICK that incorporates
hardware, firmware, and software enhancements to enable sub-100 ps timing
alignment across multiple AMD ZCU216 RFSoC boards. Our system integrates a
low-jitter clock distribution network, modifications to the tProcessor, and a
synchronization scheme to ensure deterministic alignment of program execution
across boards. It also includes a custom analog front-end for flux control that
combines high-speed RF signals with software-programmable DC biasing voltages
generated by a low-noise, high-precision DAC. These capabilities are
complemented by a software stack capable of orchestrating synchronized
multi-board experiments and fully integrated with the open-source Qibo
framework for quantum device calibration and algorithm execution. We validate
Manarat on a 10-qubit superconducting processor controlled by two RFSoC boards,
demonstrating reliable execution of synchronized control sequences for
cross-board CZ gate calibration. These results confirm that sub-nanosecond
synchronization and coherent control is achievable across multiple RFSoC
boards, enabling scalable operation of superconducting quantum computers.

</details>


### [394] [Magic transition in monitored free fermion dynamics](https://arxiv.org/abs/2507.10688)
*Cheng Wang,Zhi-Cheng Yang,Tianci Zhou,Xiao Chen*

Main category: quant-ph

TL;DR: 研究发现，在特定的量子电路模型中，魔力与纠缠之间的关系在相变过程中会发生变化，表现为魔力结构的非局域化相变，并且其动力学行为具有特殊的弛豫特性。


<details>
  <summary>Details</summary>
Motivation: 该研究旨在探索魔力与纠缠在1+1维随机自由费米子电路中的联系，特别关注能够表现出纠缠相变的混合自由费米子动力学。

Method: 该研究使用稳定量Rényi熵（SRE）来量化魔力，并通过完美采样算法进行数值计算。同时，利用二分稳定互信息来表征魔力结构的非局域化相变。

Result: 研究结果显示，SRE在系统从临界相过渡到面积定律（非纠缠）相时保持广泛。然而，魔力结构本身经历了一个非局域化相变，该相变可以通过二分稳定互信息来表征，其缩放行为与纠缠熵相似。此外，SRE的动力学表现出临界相的弛豫时间比一般随机电路更长，并且随系统尺寸线性增长。

Conclusion: 该研究表明，在1+1维随机自由费米子电路中，虽然系统的纠缠熵在相变中保持广泛，但魔力（magic）的结构会经历一个非局域化相变，这可以通过二分稳定互信息来表征，并且其缩放行为与纠缠熵相似。此外，研究还揭示了SRE的动力学特性，在临界相中，其弛豫到稳态的时间比一般的随机电路长，并且随系统尺寸线性增长。

Abstract: We investigate magic and its connection to entanglement in 1+1 dimensional
random free fermion circuits, with a focus on hybrid free fermion dynamics that
can exhibit an entanglement phase transition. To quantify magic, we use the
Stabilizer R\'enyi Entropy (SRE), which we compute numerically via a perfect
sampling algorithm. We show that although the SRE remains extensive as the
system transitions from a critical phase to an area-law (disentangled) phase,
the structure of magic itself undergoes a delocalization phase transition. This
transition is characterized using the bipartite stabilizer mutual information,
which exhibits the same scaling behavior as entanglement entropy: logarithmic
scaling in the critical phase and a finite constant in the area-law phase.
Additionally, we explore the dynamics of SRE. While the total SRE becomes
extensive in $O(1)$ time, we find that in the critical phase, the relaxation
time to the steady-state value is parameterically longer than that in generic
random circuits. The relaxation follows a universal form, with a relaxation
time that grows linearly with the system size, providing further evidence for
the critical nature of the phase.

</details>


### [395] [Classifying locally distinguishable sets: No activation across bipartitions](https://arxiv.org/abs/2507.10698)
*Atanu Bhunia,Saronath Halder,Ritabrata Sengupta*

Main category: quant-ph

TL;DR: 本研究对量子态的局部可区分性进行了深入探讨，发现某些看似“无用”的本地可区分态在特定条件下（OP-LOCC）可转化为有用的本地不可区分态。通过构建不同状态结构，研究者对本地可区分态进行了分类，并揭示了在多方系统中存在“无跨二划分激活”的特殊现象。


<details>
  <summary>Details</summary>
Motivation: 研究在正交性保持的局部操作和经典通信（OP-LOCC）下，本地可区分态集向本地不可区分态集转化的可行性，以及这种转化的限制条件，特别是在多方系统中是否存在“无跨二划分激活”的现象。

Method: 通过提供不同结构的本地可区分乘积和纠缠态，以及允许此类转化的某些本地可区分态结构，对本地可区分态集进行分类，并引入层级结构。研究了在多方系统中，当无法跨越任何二划分进行激活时，即“无跨二划分激活”的现象。

Result: 提供了不允许此类转化的本地可区分乘积和纠缠态的结构，以及允许此类转化的本地可区分态的结构，从而对本地可区分态集进行了分类并引入了层级。在多方系统中，发现了“无跨二划分激活”的现象。

Conclusion: 该工作对本地可区分态集进行了分类，引入了层级结构，并研究了在正交性保持的局部操作和经典通信（OP-LOCC）下，本地可区分态集转化为本地不可区分态集的可行性。

Abstract: A set of orthogonal quantum states is said to be locally indistinguishable if
they cannot be perfectly distinguished by local operations and classical
communication (LOCC). Otherwise, the states are locally distinguishable.
However, locally indistinguishable states may find applications in information
processing protocols. In this sense, locally indistinguishable states are
useful. On the other hand, it is usual to consider that locally distinguishable
states are useless. Nevertheless, recent works suggest that locally
distinguishable states should be given due consideration as in certain
situations these states can be converted to locally indistinguishable states
under orthogonality-preserving LOCC (OP-LOCC). Such a counterintuitive
phenomenon motivates us to ask when the aforesaid conversion is possible and
when it is not. In this work, we provide different structures of locally
distinguishable product and entangled states which do not allow the aforesaid
conversion. We also provide certain structures of locally distinguishable
states which allow the aforesaid conversion. In this way, we classify the
locally distinguishable sets by introducing hierarchies among them. In a
multipartite system, this study becomes more involved as there exist
multipartite locally distinguishable sets which cannot be converted to locally
indistinguishable sets by OP-LOCC across any bipartition. We say this as ``no
activation across bi-partitions".

</details>


### [396] [Compilation ofQCrank Encoding Algorithm for a Dynamically Programmable Qubit Array Processor](https://arxiv.org/abs/2507.10699)
*Jan Balewski,Wan-Hsuan Lin,Anupam Mitra,Milan Kornjača,Stefan Ostermann,Pedro L. S. Lopes,Daniel Bochen Tan,Jason Cong*

Main category: quant-ph

TL;DR: QCrank 协议通过算法和硬件协同设计，在 DPQA 上实现了高效的数据编码，显示出良好的准确性扩展潜力。


<details>
  <summary>Details</summary>
Motivation: 为了在近期的量子程序中高效部署，需要进行算法和硬件感知的编译协同设计，特别是针对具有高量子比特数、操作并行性、多区域架构和可重构连接等特性的中性原子 DPQA。

Method: 通过使用参数化泡利通道的噪声模型，在 Qiskit 中对 DPQA 进行了模拟，并评估了 QCrank 将 24-320 个实数写入和读出 6-20 个量子比特的准确性，同时与 Quantinuum H1-1E 的模拟性能和 IBM Fez 的实验结果进行了比较。

Result: DPQA 在写/读 24-320 个实数到 6-20 个量子比特时表现出有希望的准确性扩展，在与 Quantinuum H1-1E 和 IBM Fez 的比较中显示出有竞争力的性能。

Conclusion: DPQA 在处理 QCrank 协议方面具有准确性扩展的潜力，与 Quantinuum H1-1E 等硬件相比，该协议能够将大量实值经典数据编码到量子态中。

Abstract: Algorithm and hardware-aware compilation co-design is essential for the
efficient deployment of near-term quantum programs. We present a compilation
case-study implementing QCrank -- an efficient encoding protocol for storing
sequenced real-valued classical data in a quantum state -- targeting neutral
atom-based Dynamically Programmable Qubit Arrays (DPQAs). We show how key
features of neutral-atom arrays such as high qubits count, operation
parallelism, multi-zone architecture, and natively reconfigurable connectivity
can be used to inform effective algorithm deployment. We identify algorithmic
and circuit features that signal opportunities to implement them in a
hardware-efficient manner. To evaluate projected hardware performance, we
define a realistic noise model for DPQAs using parameterized Pauli channels,
implement it in Qiskit circuit simulators, and assess QCrank's accuracy for
writing and reading back 24-320 real numbers into 6-20 qubits. We compare DPQA
results with simulated performances of Quantinuum's H1-1E and with experimental
results from IBM Fez, highlighting promising accuracy scaling for DPQAs.

</details>


### [397] [Quantum Wave Atom Transforms](https://arxiv.org/abs/2507.10739)
*Marianna Podzorova,Yi-Kai Liu*

Main category: quant-ph

TL;DR: 提出了一种新的量子算法，用于执行小波包变换和波原子变换，其效率远高于经典算法，并且能够处理更广泛的变换类型，有望应用于求解偏微分方程。


<details>
  <summary>Details</summary>
Motivation: 经典方法中，波原子用于构建微分算子的稀疏表示，从而实现偏微分方程的快速数值算法。将此方法量子化，以期提高效率和适用性。

Method: 构建了第一个具有树状结构的小波包变换（有时称为波原子变换）的量子算法。

Result: 该量子算法能够实现更大类的小波和波原子变换，能够处理更大类可能的树状结构。对于维度为$2^n$的变换，量子算法的门复杂度为$O(\mathrm{poly}(n))$，而经典实现需要$O(n 2^n)$次浮点运算。这一结果可以用于改进现有的求解双曲型偏微分方程的量子算法。

Conclusion: 该研究提出的量子算法在处理小波包变换和波原变换方面，相较于经典算法，具有更高的效率和更广泛的适用性，有望改进现有的求解双曲型偏微分方程的量子算法。

Abstract: This paper constructs the first quantum algorithm for wavelet packet
transforms with a tree structure, sometimes called wave atom transforms.
Classically, wave atoms are used to construct sparse representations of
differential operators, which enable fast numerical algorithms for partial
differential equations. Compared to previous work, our quantum algorithm can
implement a larger class of wavelet and wave atom transforms, by using an
efficient representation for a larger class of possible tree structures. Our
quantum implementation has $O(\mathrm{poly}(n))$ gate complexity for the
transform of dimension $2^n$, while classical implementations have $O(n 2^n)$
floating point operations. The result can be used to improve existing quantum
algorithms for solving hyperbolic partial differential equations.

</details>


### [398] [A Practical Guide to using Pauli Path Simulators for Utility-Scale Quantum Experiments](https://arxiv.org/abs/2507.10771)
*Hrant Gharibyan,Siddharth Hariprakash,Mohammed Zuhair Mullath,Vincent P. Su*

Main category: quant-ph

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: In this this paper we present an inexpensive protocol to perform runtime and
memory estimation for large-scale experiments with Pauli Path simulators (PPS).
Additionally, we propose a conceptually simple solution for studying whether
PPS can be used as a scientific discovery tool, rather than reproducing
existing answers. We start by analyzing the dynamics of the Pauli coefficients
tracked in the Heisenberg picture. In addition to surprisingly generic
convergence features of the Pauli coefficient distributions, we find certain
regularities that allow for extrapolation of memory and runtime requirements
for smaller and smaller coefficient truncation parameter $\delta$. We then
introduce a framework for understanding convergence in the absence of rigorous
error guarantees on PPS. Combined with runtime analysis, we propose bifurcating
quantum simulation problems broadly into two classes, based on whether there is
apparent convergence of expectation values as a function of $\delta$. This
serves as a way for practitioners to understand where their problem falls on
the frontier of classical simulability. In the case without apparent
convergence, PPS may still serve useful as a Monte Carlo-like estimate. Applied
to IBM's utility-scale experiments, we show parameter regimes where both
behaviors are realized. Some of our key findings challenge conventional
intuition: reducing $\delta$ does not always improve accuracy, and deeper
quantum circuits may actually be easier to simulate than shallower ones. The
BlueQubit SDK implementing these methods has been released publicly, offering
researchers a comprehensive toolkit for evaluating this frontier classical
simulation approach. These results establish practical guidelines for when PPS
can serve as a reliable verification tool versus when it should be used as a
complementary estimate alongside quantum experiments.

</details>


### [399] [Time-series forecasting for nonlinear high-dimensional system using hybrid method combining autoencoder and multi-parallelized quantum long short-term memory and gated recurrent unit](https://arxiv.org/abs/2507.10876)
*Makoto Takagi,Ryuji Kokubo,Misato Kurosawa,Tsubasa Ikami,Yasuhiro Egami,Hiroki Nagai,Takahiro Kashikawa,Koichi Kimura,Yutaka Takita,Yu Matsuda*

Main category: quant-ph

TL;DR: 提出了一种基于量子计算的高维空间时间序列预测方法，通过优化传感器布局和改进量子LSTM/GRU模型，提高了预测精度。


<details>
  <summary>Details</summary>
Motivation: 为了解决高维空间数据的时间序列预测问题，并提高预测效率和精度。

Method: 提出了一种高维空间数据的时间序列预测方法，包括：1. 利用组合优化方法选择稀疏传感器最优位置。2. 在选定位置进行时间序列预测。3. 通过学习到的解码器从预测值估计整个空间分布。引入了多并行量子长短期记忆（MP-QLSTM）和门控循环单元（MP-QGRU）来提升预测性能。

Result: MP-QLSTM和MP-QGRU相比于经典LSTM和GRU，测试损失降低了约1.5%。MP-QLSTM的均方根百分比误差为0.256%，证明了该方法在实际应用中的准确性和有效性。

Conclusion: 该方法能够有效处理高维空间数据的时间序列预测任务，并且在预测精度上优于传统的LSTM和GRU模型。

Abstract: A time-series forecasting method for high-dimensional spatial data is
proposed. The method involves optimal selection of sparse sensor positions to
efficiently represent the spatial domain, time-series forecasting at these
positions, and estimation of the entire spatial distribution from the
forecasted values via a learned decoder. Sensor positions are selected using a
method based on combinatorial optimization. Introducing multi-parallelized
quantum long short-term memory (MP-QLSTM) and gated recurrent unit (MP-QGRU)
improves time-series forecasting performance by extending QLSTM models using
the same number of variational quantum circuits (VQCs) as the cell state
dimensions. Unlike the original QLSTM, our method fully measures all qubits in
each VQC, maximizing the representation capacity. MP-QLSTM and MP-QGRU achieve
approximately 1.5% lower test loss than classical LSTM and GRU. The root mean
squared percentage error of MP-QLSTM is 0.256% against the values measured
independently using semiconductor pressure sensors, demonstrating the method's
accuracy and effectiveness for high-dimensional forecasting tasks.

</details>


### [400] [Entanglement and magic on the light-front](https://arxiv.org/abs/2507.10777)
*Sam Alterman,Peter J. Love*

Main category: quant-ph

TL;DR: LF和IF形式下的量子模拟利用了不同的量子资源，LF所需的资源更少。


<details>
  <summary>Details</summary>
Motivation: 在量子场论（QFT）的轻前沿（LF）表述中，物理学是从必然以光速行进的无质量观察者的角度来表述的。LF表述为格点规范理论提供了一种计算方法，并被研究作为量子计算机的一个未来应用。一个自然的问题是，实验室中物理量子比特的纠缠和语境性等量子资源如何在QFT的LF模拟中被利用。

Method: 本研究使用（1+1）维横向场伊辛模型来探索这个问题，并推导了LF能量算符。

Result: LF哈密顿量的本征态在LF动量空间中是可分离的，而IF哈密顿量的本征态在IF动量空间中表现出成对的纠缠。LF基础态比IF基础态需要更少的动量空间魔力。在量子临界点，LF基础态是稳定子，并且在LF动量空间中是可分离的，而IF基础态是IF动量空间中最大纠缠对的乘积。

Conclusion: LF和IF形式下的量子模拟利用了不同的量子资源（例如纠缠和魔力），并且LF基础态的简洁性所需的量子资源更少。

Abstract: In the light-front (LF) formulation of quantum field theory (QFT), physics is
formulated from the perspective of a massless observer necessarily traveling at
the speed of light. The LF formulation provides an alternative computational
approach to lattice gauge theory, and has recently been investigated as a
future application of quantum computers. A natural question is how quantum
resources such as entanglement and contextuality amongst physical qubits in the
laboratory are utilized in LF simulations of QFTs. We use the (1+1)D
transverse-field Ising model to explore this question. We derive the LF energy
operator that generates the LF dynamics of the system, which is distinct from
the instant-form (IF) Hamiltonian. We find that while the eigenstates of the IF
Hamiltonian exhibit pairwise entanglement between positive and negative momenta
in IF momentum-space, the eigenstates of the LF Hamiltonian are separable in LF
momentum-space. We then calculate the momentum-space magic of the
IF-momentum-space ground state and show that it always requires more magic to
prepare than the LF-momentum-space ground state. At the quantum critical point,
corresponding to a massless free fermion, both LF and IF ground states are
stabilizers, but the LF ground state is separable in LF momentum-space while
the IF ground state is a product of maximally entangled pairs in IF
momentum-space. These results show that quantum resources such as entanglement
and magic are utilized differently by quantum simulations formulated in LF and
IF, and that the simplicity of the LF ground state results in fewer required
quantum resources.

</details>


### [401] [Quantum Advantage in Storage and Retrieval of Isometry Channels](https://arxiv.org/abs/2507.10784)
*Satoshi Yoshida,Jisho Miyazaki,Mio Murao*

Main category: quant-ph

TL;DR: 该研究提出了一种改进的基于端口转移的协议，以更有效地存储和检索同位异形通道，并在一般量子通道方面取得了更好的性能。


<details>
  <summary>Details</summary>
Motivation: 该研究的动机在于分析基于估计的策略在同位异形通道存储和检索方面的渐近性能，并提出一种更高效的协议来克服现有方法的局限性。

Method: 该研究分析了基于估计的策略在同位异形通道存储和检索方面的渐近性能，并提出了一个基于端口转移的更高效协议。

Result: 该研究表明，同位异形通道估计的最佳保真度为$F = 1-{d(D-d)oldsymbol{}/oldsymbol{n}} + O(n^{-2})$，其中d和D分别是同位异形通道的输入和输出维度，$n$是查询次数。

Conclusion: 该研究表明，基于估计的策略对于同位异形（isometry）通道的存储和检索来说并非最优，因为需要$n=oldsymbol{m oldsymbol{	heta}}(oldsymbol{f oldsymbol{oldsymbol{	ext{1}}}}oldsymbol{/}oldsymbol{f oldsymbol{oldsymbol{	ext{ 	extbackslash epsilon}}}}}$才能达到$oldsymbol{f oldsymbol{oldsymbol{	ext{ 	extbackslash epsilon}}}}}$的钻石范数误差。为了克服这一局限性，研究者提出了一种基于端口转移（port-based teleportation）的更高效协议，仅用$n=oldsymbol{m oldsymbol{	heta}}(oldsymbol{f oldsymbol{oldsymbol{	ext{1}}}}oldsymbol{/}oldsymbol{f oldsymbol{oldsymbol{	ext{ 	extbackslash sqrt{	extbackslash epsilon}}}}}})$次查询即可将同位异形通道存储在程序状态中。此外，该方法已被推广到一般量子通道，并在程序成本方面优于Gschwedtner、Bluhm和Winter等人先前的工作。

Abstract: Storage and retrieval refer to the task of encoding a quantum channel
$\Lambda$ into a quantum state, known as the program state, such that the
channel can later be retrieved. This task is closely related to quantum channel
estimation, where multiple queries to $\Lambda$ are used to prepare a quantum
state $\phi_\Lambda$ that encodes information about the channel. The channel
can then be retrieved by measuring $\phi_\Lambda$, following a
measure-and-prepare strategy. In this work, we analyze the asymptotic
performance of the estimation-based strategy for storage and retrieval of
isometry channels. We show that the optimal fidelity for isometry estimation is
given by $F = 1-{d(D-d)\over n} + O(n^{-2})$, where $d$ and $D$ denote the
input and output dimensions of the isometry, and $n$ is the number of queries.
This result indicates that, unlike in the case of unitary channels, the
estimation-based strategy is suboptimal for the storage and retrieval of
isometry channels, which requires $n = \Theta(\epsilon^{-1})$ to achieve the
diamond-norm error $\epsilon$. To address this limitation, we propose a more
efficient protocol based on port-based teleportation, which stores the isometry
channel in a program state using only $n = \Theta(1/\sqrt{\epsilon})$ queries.
As an application, we extend our approach to general quantum channels,
achieving improved program cost compared to prior results by Gschwedtner,
Bluhm, and Winter [Quantum $\textbf{5}$, 488 (2021)].

</details>


### [402] [Facets of Non-locality and Advantage in Entanglement-Assisted Classical Communication Tasks](https://arxiv.org/abs/2507.10830)
*Sumit Rout,Anubhav Chaturvedi,Some Sankar Bhattacharya,Paweł Horodecki*

Main category: quant-ph

TL;DR: 该研究揭示了非局域性与关联辅助经典通信优势之间的联系，提出了一种新的贝尔不等式，并引入了线读取机制来展示非局域关联的优势作用，特别是在Bob-无输入准备-测量场景下，非局域关联能增强通信效果，优于共享随机性辅助。


<details>
  <summary>Details</summary>
Motivation: 揭示非局域性与关联辅助经典通信优势之间的关键联系。

Method: 利用线切割技术提供了一个适用于任何关联辅助有界经典通信任务的贝尔不等式，并通过引入线读取机制来利用经典消息的可读性。

Result: 贝尔不等式的违反等同于量子关联在通信任务中的量子辅助优势。线读取机制展示了非局域关联在某些情况下（否则无法观察到优势）的有利辅助作用。在Bob-无输入准备-测量场景下，提出了几类经典通信任务，其中非局域关联增强了有界经典通信，而共享随机性辅助的收益则严格次优。第一类任务的优势来自任何非局域方面，第二类任务则针对特定的非局域方面。研究揭示了这些任务中的量子优势，包括qutrit优于qubit的纠缠优势。

Conclusion: 揭示了非局域性与关联辅助经典通信优势之间的关键联系。

Abstract: We reveal key connections between non-locality and advantage in
correlation-assisted classical communication. First, using the wire-cutting
technique, we provide a Bell inequality tailored to any correlation-assisted
bounded classical communication task. The violation of this inequality by a
quantum correlation is equivalent to its quantum-assisted advantage in the
corresponding communication task. Next, we introduce wire-reading, which
leverages the readability of classical messages to demonstrate advantageous
assistance of non-local correlations in setups where no such advantage can be
otherwise observed. Building on this, we introduce families of classical
communication tasks in a Bob-without-input prepare-and-measure scenario, where
non-local correlation enhances bounded classical communication while shared
randomness assistance yields strictly suboptimal payoff. For the first family
of tasks, assistance from any non-local facet leads to optimal payoff, while
each task in the second family is tailored to a non-local facet. We reveal
quantum advantage in these tasks, including qutrit over qubit entanglement
advantage.

</details>


### [403] [A unified approach to quantum resource theories and a new class of free operations](https://arxiv.org/abs/2507.10851)
*N. L. Diaz,Antonio Anna Mele,Pablo Bermejo,Paolo Braccia,Andrew E. Deneris,Martin Larocca,M. Cerezo*

Main category: quant-ph

TL;DR: 该研究提出了一种新的方法来统一理解和构建量子资源理论（QRTs），将自由操作定义为代数结构的自同构。此方法被应用于多种QRTs，并成功识别了新的非资源增加操作，解决了文献中的一个开放性问题。


<details>
  <summary>Details</summary>
Motivation: 该研究旨在解决量子资源理论（QRTs）中不同理论之间难以比较和研究的难题。通过提出一个统一的框架，将QRTs与其代数结构相关联，并将自由操作定义为代数结构的自同构，该研究希望能够更清晰地揭示不同QRTs之间的相似性和差异性，并为解决开放性问题提供新的途径。

Method: 本研究提出了一种将量子资源理论（QRTs）与其代数结构$\\mathcal{E}$相关联的新方法，其中自由操作被定义为$\\mathcal{E}$的自同构。通过研究纠缠、Clifford可稳定性、纯度、虚数性、费米高斯性、参考系、热力学和相干性等QRTs，确定了它们各自的代数结构$\\mathcal{E}$，并展示了$\\mathcal{E}$可以是李代数、群、环或集合。基于这种统一的理解，作者将随机局部操作和经典通信（SLOCC）的概念推广到基于李代数的QRTs，识别了新的非资源增加操作，并证明了这些操作的有效性。

Result: 本研究成功地为量子资源理论（QRTs）提供了一个统一的数学框架，并将自由操作的概念推广到更广泛的领域。通过识别不同QRTs的代数结构，作者发现了新的非资源增加操作，并为基于李代数的QRTs提出了SLOCC的推广，解决了文献中的一个开放性问题。此外，研究还提供了这些新操作的严格证明，确保了它们将自由态映射到自由态，并且在特定情况下不会增加资源。

Conclusion: 该研究提出了一个统一的框架来理解和构建量子资源理论（QRTs），将自由操作定义为特定代数结构$\mathcal{E}$的自同构。通过将此框架应用于现有的多个QRTs，包括纠缠、Clifford可稳定性、纯度、虚数性、费米高斯性、参考系、热力学和相干性，并展示了$\mathcal{E}$可以的不同代数结构（如李代数、群、环或集合），作者为QRTs提供了一个新的视角。此外，该研究将随机局部操作和经典通信（SLOCC）的概念推广到基于李代数的QRTs，识别了新的非资源增加操作，为文献中的一个开放性问题提供了解决方案，并严格证明了这些操作的有效性。

Abstract: In quantum resource theories (QRTs) certain quantum states and operations are
deemed more valuable than others. While the determination of the ``free''
elements is usually guided by the constraints of some experimental setup, this
can make it difficult to study similarities and differences between QRTs. In
this work, we argue that QRTs follow from the choice of a preferred algebraic
structure $\mathcal{E}$ to be preserved, thus setting the free operations as
the automorphisms of $\mathcal{E}$. We illustrate our finding by determining
$\mathcal{E}$ for the QRTs of entanglement, Clifford stabilizerness, purity,
imaginarity, fermionic Gaussianity, reference frames, thermodynamics and
coherence; showing instances where $\mathcal{E}$ is a Lie algebra, group, ring,
or even a simple set. This unified understanding allows us to generalize the
concept of stochastic local operations and classical communication (SLOCC) to
identify novel resource non-increasing operations for Lie-algebra based QRTs,
thus finding a new solution to an open problem in the literature. We showcase
the sanity of our new set of operations by rigorously proving that they map
free states to free states, as well as determine more general situations where
these transformations strictly do not increase the resource of a state.

</details>


### [404] [Higher spin Richardson-Gaudin model with time-dependent coupling: Exact dynamics](https://arxiv.org/abs/2507.10856)
*Suvendu Barik,Lieuwe Bakker,Vladimir Gritsev,Jiří Minář,Emil A. Yuzbashyan*

Main category: quant-ph

TL;DR: 该研究确定了自旋 Richardson-Gaudin 模型的精确渐近多体波函数，发现其稳态是非热的，并且不符合广义 Gbbens Ensemble，这与自旋 1/2 的情况不同。研究还证明了均值场理论的精确性，并提出了实验验证的方法。


<details>
  <summary>Details</summary>
Motivation: 与普遍的看法相反， Richardson-Gaudin 模型的自旋 s 的渐近多体波函数不能通过合并自旋 1/2 的情况来获得，而是需要单独处理每个自旋。

Method: 本文推导了具有与时间成反比耦合的自旋 Richardson-Gaudin 模型的精确渐近多体波函数，特别是对于从 t = 0+ 的基态开始的时间演化，并且该模型适用于任意自旋 s。

Result: 研究结果表明， Richardson-Gaudin 模型的稳态是非热的，并且不符合广义 Gbbens Ensemble。此外，均值场理论对于作用在不同格点上的有限数量的自旋算符的乘积是精确的。研究还讨论了如何在腔量子电动力学和捕获离子实验中进行探测。

Conclusion: 研究发现，对于耦合强度与时间成反比的自旋 Richardson-Gaudin 模型，其稳态是“非热”的，并且不符合广义 Gbbens Ensemble（与自旋 1/2 的情况不同）。研究还表明，均值场理论对于作用在不同格点上的有限数量的自旋算符的乘积是精确的。

Abstract: We determine the exact asymptotic many-body wavefunction of a spin-$s$
Richardson-Gaudin model with a coupling inversely proportional to time, for
time evolution starting from the ground state at $t = 0^+$ and for arbitrary
$s$. Contrary to common belief, the resulting wavefunction cannot be derived
from the spin-$1/2$ case by merging spins, but instead requires independent
treatment for each spin size. The steady state is non-thermal and, in contrast
to the spin-$1/2$ case, does not conform to a natural Generalized Gibbs
Ensemble. We show that mean-field theory is exact for any product of a finite
number of spin operators on different sites. We discuss how these findings can
be probed in cavity QED and trapped ion experiments.

</details>


### [405] [Hawking time crystal](https://arxiv.org/abs/2507.10862)
*Juan Ramón Muñoz de Nova,Fernando Sols*

Main category: quant-ph

TL;DR: 在量子黑洞激光器中观察到了时间晶体，这是由自发霍金辐射的自我放大引起的。HTC是Andreev-Hawking效应的非线性周期性版本。


<details>
  <summary>Details</summary>
Motivation: 在量子黑洞激光器（BHL）中数值观测到时间晶体。

Method: 通过量子黑洞激光器（BHL）中的自发对称性破缺，实现了霍金时间晶体（HTC）。

Result: 量子纠缠的自发霍金辐射的自我放大导致了时间晶体的形成。

Conclusion: 时间晶体（HTC）可以被视为Andreev-Hawking效应的非线性周期性版本，其特征在于自发产生的成对的色散波和孤子进入上游和下游区域所产生的反相关能带。

Abstract: We report the numerical observation of a time crystal in a quantum black-hole
laser (BHL), where the genuine spontaneous character of the symmetry breaking
stems from the self-amplification of spontaneous Hawking radiation. The
resulting Hawking time crystal (HTC) is characterized by the periodic
dependence of the out-of-time density-density correlation function, while
equal-time correlations are time-independent because they embody averages over
different realizations with a random oscillation phase. The HTC can be regarded
as a nonlinear periodic version of the Andreev-Hawking effect, signaled by
anticorrelation bands resulting from the spontaneous, quantum emission of pairs
of dispersive waves and solitons into the upstream and downstream regions.

</details>


### [406] [Mesoscopic Fluctuations and Multifractality at and across Measurement-Induced Phase Transition](https://arxiv.org/abs/2507.11312)
*Igor Poboiko,Igor V. Gornyi,Alexander D. Mirlin*

Main category: quant-ph

TL;DR: 受监测的二维自由费米子在测量诱导相变中，其统计涨落与 Anderson 局域化类似。研究分析了粒子数协方差 G_AB 和密度关联函数 C(r)，发现在不同相和相变点展现出不同的涨落特性和多重分形行为。


<details>
  <summary>Details</summary>
Motivation: 研究的动机在于探索量子轨迹系综上的统计涨落，并揭示其与 Anderson 局域化的类比，尤其是在测量诱导相变的背景下，以理解受监测量子系统的行为。

Method: 研究利用投影监测局部电荷的二维自由费米子模型，探索了量子轨迹系综上的统计涨落，特别关注了测量诱导相变。主要分析了空间分离区域间的粒子数协方差（G_AB）和两点密度关联函数（C(r)）。

Result: 研究结果显示，G_AB在非局域相中表现出接近高斯分布的普适涨落，方差约为1。在局域相中，G_AB的分布广泛，其对数方差与系统尺寸L成正比，方差的对数增长率与L^μ（μ≈0.5）成正比。在相变点，G_AB的分布函数具有标度不变性，C(r)表现出多重分形统计特性，并表征了多重分形维数谱。

Conclusion: 该研究展示了受量子轨迹系综统计涨落的类比，该模型为二维自由费米子，在投影监测局部电荷的情况下，经历了测量诱导相变。研究结果表明，在非局域相中，粒子数协方差（G_AB）表现出接近高斯分布的普适涨落，方差约为1。在局域相中，G_AB的分布广泛，且其对数方差与系统尺寸L成正比，方差的对数增长率与L^μ（μ≈0.5）成正比。在相变点，G_AB的分布函数具有标度不变性，而密度关联函数（C(r)）表现出多重分形统计特性。研究为受监测系统的介观理论奠定了基础，并为进一步的扩展提供了可能。

Abstract: We explore statistical fluctuations over the ensemble of quantum trajectories
in a model of two-dimensional free fermions subject to projective monitoring of
local charge across the measurement-induced phase transition. Our observables
are the particle-number covariance between spatially separated regions,
$G_{AB}$, and the two-point density correlation function, $\mathcal{C}(r)$. Our
results exhibit a remarkable analogy to Anderson localization, with $G_{AB}$
corresponding to two-terminal conductance and $\mathcal{C}(r)$ to two-point
conductance, albeit with different replica limit and unconventional symmetry
class, geometry, and boundary conditions. In the delocalized phase, $G_{AB}$
exhibits ``universal'', nearly Gaussian, fluctuations with variance of order
unity. In the localized phase, we find a broad distribution of $G_{AB}$ with
$\overline{-\ln G_{AB}} \sim L $ (where $L$ is the system size) and the
variance $\mathrm{var}(\ln G_{AB}) \sim L^\mu$, and similarly for
$\mathcal{C}(r)$, with $\mu \approx 0.5$. At the transition point, the
distribution function of $G_{AB}$ becomes scale-invariant and $\mathcal{C}(r)$
exhibits multifractal statistics, $\overline{\mathcal{C}^{q}(r)}\sim r^{-q(d+1)
- \Delta_{q}}$. We characterize the spectrum of multifractal dimensions
$\Delta_q$. Our findings lay the groundwork for mesoscopic theory of monitored
systems, paving the way for various extensions.

</details>


### [407] [Entanglement production in the Sachdev-Ye-Kitaev Model and its variants](https://arxiv.org/abs/2507.10892)
*Tanay Pathak,Masaki Tezuka*

Main category: quant-ph

TL;DR: 该研究通过分析SYK模型及其变体在不同N下的纠缠熵和两点自相关函数，揭示了纠缠增长率作为衡量混沌的精细指标，并指出了费米子算子的非局域性对纠缠动力学的影响。


<details>
  <summary>Details</summary>
Motivation: 理解量子混沌系统如何产生纠缠，以及这如何反映其混沌动力学和区分混沌行为。

Method: 利用冯·诺依曼纠缠熵，研究了在三个SYK模型变体（具有有限数量的Majorana费米子N）下，非纠缠态的演化。

Result: 所有SYK模型变体在早期都表现出线性的纠缠增长，在后期则饱和到一个与随机矩阵理论（RMT）一致的普适值，但增长速率不同。这种差异源于SYK及其二元变体中费米子算子的非局域性增强，而自旋SYK模型中的自旋算子则没有这种效应。数值结果表明，随着N的增加，这些差异逐渐显现。虽然所有变体都是量子混沌的，但它们的纠缠动力学反映了不同程度的混沌，并且纠缠产生率是超越传统测量的混沌的精细探测器。在N≥24时，两点自相关函数偏离了RMT预测，特别是在从指数衰减到饱和的过渡区域。

Conclusion: 量子混沌系统产生纠缠的机制有助于理解其混沌动力学，并区分不同类别的混沌行为。

Abstract: Understanding how quantum chaotic systems generate entanglement can provide
insight into their microscopic chaotic dynamics and can help distinguish
between different classes of chaotic behavior. Using von Neumann entanglement
entropy, we study a nonentangled state evolved under three variants of the
Sachdev-Ye-Kitaev (SYK) model with a finite number of Majorana fermions $N$.
All the variants exhibit linear entanglement growth at early times, which at
late times saturates to a universal value consistent with random matrix theory
(RMT), but their growth rates differ. We interpret this as a large-$N$ effect,
arising from the enhanced non-locality of fermionic operators in SYK and binary
SYK, absent in spin operators of the spin-SYK model. Numerically, we find that
these differences emerge gradually with increasing $N$. Although all variants
are quantum chaotic, their entanglement dynamics reflect varying degrees of
chaos and indicate that the entanglement production rate serves as a
fine-grained probe of chaos beyond conventional measures. To probe its effect
on thermalization properties of these models, we study the two-point
autocorrelation function, finding no differences between the SYK variants, but
deviations from RMT predictions for $N \geq 24$, particularly near the
crossover from exponential decay to saturation regime.

</details>


### [408] [An Optimization-Free Recursive QAOA for the Binary Paint Shop Problem](https://arxiv.org/abs/2507.10908)
*Gary J Mooney,Jedwin Villanueva,Bhaskar Roy Radhan,Joydip Ghosh,Charles D Hill,Lloyd C L Hollenberg*

Main category: quant-ph

TL;DR: 通过将预计算的参数传递给RQAOA，可以提高BPSP问题的解决效率，并且 CNOT 计数和深度更低。


<details>
  <summary>Details</summary>
Motivation: 为了提高QAOA算法在处理更大、未见过的BPSP实例时的效率，通过参数传递技术来规避外层优化循环。

Method: 使用参数传递技术，将预计算的参数应用于RQAOA，以解决二元油漆车间问题（BPSP）。BPSP被转化为具有对称哈密顿量和Ising图结构的Ising基态问题。

Result: 参数传递在RQAOA中没有明显降低解的质量，同时通过避免优化所需的测量大大提高了效率。RQAOA仅需要ZZ相关性的测量，并且具有较低的CNOT计数和深度。与经典求解器和启发式算法相比，QAOA和RQAOA的性能得到了评估。

Conclusion: 该研究将参数传递应用于RQAOA，以解决BPSP问题，在不牺牲解质量的情况下提高了效率，并降低了CNOT计数和深度。

Abstract: The classical outer optimisation loop of the classical-quantum hybrid Quantum
Approximate Optimisation Algorithm (QAOA) can be bypassed by transferring
precomputed parameters to larger unseen problem instances using the parameter
concentration property found in certain classes of problem instances. In this
paper, parameter transfer is applied to the recursive-QAOA (RQAOA) approach of
Bravyi et al. implementing the Binary Paint Shop Problem (BPSP) -- an
optimisation problem found in manufacturing where a sequence of cars are to be
painted under certain constraints while minimising the number of colour changes
between cars. The BPSP can be conveniently formulated as an Ising ground state
problem with a symmetric Hamiltonian and Ising graph structure that is
well-suited for QAOA parameter-transfer techniques. Throughout our quantum
simulated experiments, parameter transfer showed no noticeable reduction in
solution quality over optimisation for QAOA and RQAOA while substantially
improving the efficiency due to avoiding measurements required for
optimisation. Additionally, RQAOA only requires measurements of
$ZZ$-correlations instead of full statevectors, benefiting from the
reverse-causal-cone feature that leads to circuits with significantly lower
CNOT counts and depths. The performance of QAOA and RQAOA with parameter
transfer is benchmarked against classical solvers and heuristics and their
resilience to non-optimal parameters is explored. The entanglement entropy and
bond dimensions are obtained from matrix product state simulations to provide
an indication of the classical resources required to simulate the quantum
algorithms. Circuit sizes and measurement counts are compared between the
implementations.

</details>


### [409] [Quantum algorithm for solving McKean-Vlasov stochastic differential equations](https://arxiv.org/abs/2507.10926)
*Koichi Miyamoto*

Main category: quant-ph

TL;DR: 本文首次将量子蒙特卡洛积分（QMCI）应用于求解McKean-Vlasov随机微分方程（MVSDEs），并提出了一种结合QMCI、高阶时间离散化和时间外插的量子算法。该算法在精度和计算复杂度上均优于经典的粒子方法。


<details>
  <summary>Details</summary>
Motivation: 量子蒙特卡洛积分（QMCI）作为一种具有二次加速的量子算法，在工业和科学应用中日益受到关注。本文旨在探索QMCI在求解McKean-Vlasov随机微分方程（MVSDEs）这一具有金融和流体力学等领域应用的新兴问题上的首次应用。

Method: 通过结合量子蒙特卡洛积分（QMCI）、高阶时间离散化方法以及时间外插技术来设计量子算法，用于计算MVSDEs的期望值。

Result: 该量子算法能够以 $\epsilon$ 的精度估计终端时间的函数期望值 $\mathbb{E}[\phi(X_T)]$，其量子电路查询复杂度为 $O(1/\epsilon^{1+2/p})$，其中 $p\in(1,2]$ 是SDE离散化方法的时间一阶精度。这相比于经典的粒子方法（复杂度为 $O(1/\epsilon^3)$）具有显著的加速。数值实验也验证了该算法的预期表现。

Conclusion: 所提出的量子算法结合了量子蒙特卡洛积分、高阶时间离散化方法和时间外插技术，能够有效求解McKean-Vlasov随机微分方程（MVSDEs），并在计算精度和复杂度方面展现出优于经典粒子方法的优势。

Abstract: Quantum Monte Carlo integration, a quantum algorithm for calculating
expectations that provides a quadratic speed-up compared to its classical
counterpart, is now attracting increasing interest in the context of its
industrial and scientific applications. In this paper, we propose the first
application of QMCI to solving McKean-Vlasov stochastic differential equations
(MVSDEs), a nonlinear class of SDEs whose drift and diffusion coefficients
depend on the law $\mu_t$ of the solution $X_t$ -- appearing in fields such as
finance and fluid mechanics. We focus on the problem setting where the
coefficients depend on $\mu_t$ through expectations of some functions
$\mathbb{E}[\varphi_k(X_t)]$, and the goal is to compute the expectation of a
function $\mathbb{E}[\phi(X_T)]$ at a terminal time $T$. We devise a quantum
algorithm that leverages QMCI to compute these expectations, combined with a
high-order time discretization method for SDEs and extrapolation of the
expectations in time. The proposed algorithm estimates $\mathbb{E}[\phi(X_T)]$
with accuracy $\epsilon$, making $O(1/\epsilon^{1+2/p})$ queries to the quantum
circuit for time evolution over one step, where $p\in(1,2]$ is the weak order
of the SDE discretization method. This demonstrates the speed-up over the
well-known classical algorithm called the particle method with complexity of
$O(1/\epsilon^3)$. We conduct a numerical demonstration of our quantum
algorithm applied to an example of MVSDEs, with some parts emulated
classically, and observe that the accuracy and complexity behave as expected.

</details>


### [410] [Towards a Utility-Scale Quantum Edge Detection for Real-World Medical Image Data](https://arxiv.org/abs/2507.10939)
*Emmanuel Billias,Nikos Chrisochoides*

Main category: quant-ph

TL;DR: 通过双层分解和优化，QHED在NISQ设备上的性能和保真度得到了显著提升，为分布式量子计算在图像分析（如MRI）中的应用提供了证据。


<details>
  <summary>Details</summary>
Motivation: 为了在有噪声的中等规模量子（NISQ）设备上为实际图像分析增强量子哈达玛边缘检测（QHED）的质量和性能。

Method: 提出了一种双层分解策略，包括数据级分解（将输入图像划分为P个增强子图像，每个子图像编码到单独的量子电路中）和电路级分解（将每个电路切割成Q个更小的子电路）。

Result: 在真实IBM噪声模型下，对于5量子比特数据输入，双层P×Q分解和我们引入的优化实现了超过62%的电路深度减少和大约93%的二量子比特操作减少，同时保持超过95.6%的保真度。

Conclusion: 在真实IBM噪声模型下，对于5量子比特数据输入，双层P×Q分解和我们引入的优化实现了超过62%的电路深度减少和大约93%的二量子比特操作减少，同时保持超过95.6%的保真度。这证明了在NISQ硬件上执行高保真QHED的可行性，并通过处理具有逆量子傅里叶变换的原始k空间MRI数据以及在大型2D和3D MRI数据集上修改的QHED的分布式模拟，进一步证明了分布式效用规模量子计算的经验教训和早期证据。

Abstract: We present a two-level decomposition strategy to enhance the quality and
performance of Quantum Hadamard Edge Detection (QHED) for practical image
analysis on Noisy Intermediate-Scale Quantum (NISQ) devices. A Data-Level
Decomposition partitions an input image into P augmented sub-images, each
encoded into a separate quantum circuit. Each of these circuits is then further
cut via Circuit-Level Decomposition into Q smaller sub-circuits suitable for
execution on near-term quantum devices. The two-level P $\times$ Q
decomposition, along with optimizations we introduced, achieves over 62\%
reductions in circuit depth and approximately 93\% fewer two-qubit operations,
while maintaining a fidelity exceeding 95.6\% under realistic IBM noise models
for 5-qubit data input sizes. These results demonstrate the feasibility of
performing high-fidelity QHED on NISQ hardware and provide lessons and early
evidence of distributed utility scale quantum computing, further illustrated by
processing raw k-space MRI data with an Inverse Quantum Fourier Transform and a
distributed simulation of the modified QHED on large 2D and 3D MRI datasets.

</details>


### [411] [SU(1,1) coherent states for the Dunkl- Klein-Gordon equation in its canonical form](https://arxiv.org/abs/2507.10947)
*M. Salazar-Ramírez,J. A. Martínez-Nuño,MR Cordero-López*

Main category: quant-ph

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Using representation-theoretic techniques associated with the
$\mathfrak{su}(1,1)$ symmetry algebra, we construct Perelomov coherent states
for the Dunkl-Klein-Gordon equation in its canonical form, which is free of
first-order Dunkl derivatives. Our analysis is restricted to the even-parity
sector and to the regime where the curvature constant $R$ is much smaller than
the system's kinetic energy. The equation under consideration emerges from a
matrix-operator framework based on Dirac gamma matrices and a universal length
scale that encodes the curvature of space via the Dunkl operator, thereby
circumventing the need for spin connections in the Dirac equation.

</details>


### [412] [Spin Relaxation Mechanisms and Nuclear Spin Entanglement of the V$_B^{-1}$ Center in hBN](https://arxiv.org/abs/2507.11494)
*Chanaprom Cholsuk,Tobias Vogl,Viktor Ivády*

Main category: quant-ph

TL;DR: hBN 中的 V_B^- 自旋量子比特是一种有前途的传感工具，但其 T1 弛豫时间仍不清楚。我们使用一种新的自旋动力学模型来研究 T1 弛豫机制，发现电子-核和核-核相互作用在驱动弛豫中起着关键作用。我们的模型可以准确地预测 T1 时间，并为未来的量子技术提供见解。


<details>
  <summary>Details</summary>
Motivation: hBN 中带负电的硼空位 V_B^- 缺陷作为一种有前途的自旋量子比特，在传感领域引起了人们的关注，因为它具有高温自旋控制和范德华结构中的多功能集成能力。尽管大量实验探索了其相干性，但对其自旋弛豫时间 T1 及其控制参数依赖性的了解却少得多。

Method: 我们开发了一个基于簇展开技术的无参数自旋动力学模型来研究低温下的 T1 弛豫机制。

Result: 我们的结果表明，V_B^- 中心构成了一个强耦合的电子自旋-核自旋核心，这有必要包括三个最近邻氮核自旋的相干动力学和派生的记忆效应。在此框架内，本工作在 B = 90 G 时精确重现了实验观察到的 T1 时间，并进一步预测了在 0 ≤ B ≤ 2000 G 区间内，当自旋弛豫主要由超细和偶极相互作用介导的电子-核和核-核翻转-翻转过程驱动时，T1 对外部磁场的依赖性。

Conclusion: 本研究建立了一个可靠且可扩展的方法来描述 V_B^- 中心的 T1 弛豫，并提供了微观见解以支持未来基于核自旋的量子技术的发展。

Abstract: The negatively charged boron vacancy $V_B^-$ defect in hexagonal boron
nitride (hBN) has recently emerged as a promising spin qubit for sensing due to
its high-temperature spin control and versatile integration into van der Waals
structures. While extensive experiments have explored their coherence
properties, much less is known about the spin relaxation time $T_1$ and its
control-parameter dependence. In this work, we develop a parameter-free spin
dynamics model based on the cluster-expansion technique to investigate $T_1$
relaxation mechanisms at low temperature. Our results reveal that the $V_B^-$
center constitutes a strongly coupled electron spin-nuclear spin core, which
necessitates the inclusion of the coherent dynamics and derived memory effects
of the three nearest-neighbor nitrogen nuclear spins. Using this framework,
this work closely reproduces the experimentally observed $T_1$ time at $B =
90\,\mathrm{G}$ and further predicts the $T_1$ dependence on external magnetic
field in the $0 \le B \le 2000\,\mathrm{G}$ interval, when the spin relaxation
is predominantly driven by electron-nuclear and nuclear-nuclear flip-flop
processes mediated by hyperfine and dipolar interactions. This study
establishes a reliable and scalable approach for describing $T_1$ relaxation in
$V_B^-$ centers and offers microscopic insights to support future developments
in nuclear-spin-based quantum technologies.

</details>


### [413] [Rapid mixing for Gibbs states within a logical sector: a dynamical view of self-correcting quantum memories](https://arxiv.org/abs/2507.10976)
*Thiago Bergamaschi,Reza Gheissari,Yunchao Liu*

Main category: quant-ph

TL;DR: 该研究提出了一种快速生成自校正量子记忆体中逻辑扇区吉布斯状态的方法，该方法在4D توريك码中具有应用潜力。


<details>
  <summary>Details</summary>
Motivation: 本研究旨在解决自校正量子记忆体的状态（逻辑扇区内的吉布斯状态）是如何在初始阶段被创建的问题。

Method: 该研究使用准局部量子吉布斯采样器，并利用了低温下亚稳态的衰减相关性质。

Result: 研究结果表明，该采样器能快速收敛到目标吉布斯状态，并在4D توريك码中实现了快速的吉布斯状态制备。

Conclusion: 该研究表明，对于一类具有奇偶校验冗余的格上的自校正量子记忆体，准局部量子吉布斯采样器在从基态初始化时，可以快速收敛到相应的低温吉布斯状态（在逻辑扇区内）。这揭示了自校正量子记忆体的动力学特性：

Abstract: Self-correcting quantum memories store logical quantum information for
exponential time in thermal equilibrium at low temperatures. By definition,
these systems are slow mixing. This raises the question of how the memory
state, which we refer to as the Gibbs state within a logical sector, is created
in the first place.
  In this paper, we show that for a broad class of self-correcting quantum
memories on lattices with parity check redundancies, a quasi-local quantum
Gibbs sampler rapidly converges to the corresponding low-temperature Gibbs
state within a logical sector when initialized from a ground state. This
illustrates a dynamical view of self-correcting quantum memories, where the
"syndrome sector" rapidly converges to thermal equilibrium, while the "logical
sector" remains metastable. As a key application, when initialized from a
random ground state, this gives a rapid Gibbs state preparation algorithm for
the 4D toric code in $\mathrm{polylog}(n)$ depth. The main technical
ingredients behind our approach are new, low-temperature decay-of-correlation
properties for these metastable states.

</details>


### [414] [Critical Reflections on Overcoming a Challenge for Bohmian Mechanics by H. Nikolic and the Experimental Findings of Sharoglazova et al](https://arxiv.org/abs/2507.10989)
*Mikołaj Sienicki,Krzysztof Sienicki*

Main category: quant-ph

TL;DR: Nikolic修正Bohmian力学以应对实验挑战，但引入了新假设并忽略了关键特征，Bohmian力学仍有待完善。


<details>
  <summary>Details</summary>
Motivation: 该论文的动机是探讨Bohmian力学在解释Sharoglazova等人的实验结果时遇到的挑战，以及H. Nikolic的回应如何未能完全解决这些挑战。

Method: 该论文通过分析H. Nikolic对Sharoglazova等人的实验结果的回应，并着重探讨其修正方案在满足连续性方程的同时，如何重新引入了避免的假设，并忽略了关键的经验和非定域方面来展开分析。

Result: 该论文的结果是，Nikolic的修正方案虽然满足了连续性方程，但引入了新的假设并忽略了重要的系统特征，表明Bohmian力学在应用于复杂相互作用系统时仍存在未解决的问题。

Conclusion: 该论文的结论是，Nikolic的修正虽然满足了连续性方程，但重新引入了他试图避免的假设，并且忽略了系统中关键的经验和非定域方面。这些问题突显了将Bohmian力学应用于复杂、相互作用的体系时存在的未解决的矛盾。

Abstract: This paper offers a brief reflection on H. Nikolic's response to the
experimental findings of Sharoglazova et al., which challenge Bohmian
mechanics. While Nikolic's revision satisfies the continuity equation, it
reintroduces assumptions he seeks to avoid and overlooks key empirical and
nonlocal aspects of the system. These issues underscore unresolved tensions in
applying Bohmian mechanics to complex, interacting regimes.

</details>


### [415] [A Noise-Aware Scalable Subspace Classical Optimizer for the Quantum Approximate Optimization Algorithm](https://arxiv.org/abs/2507.10992)
*Kwassi Joseph Dzahini,Jeffrey M. Larson,Matt Menickelly,Stefan M. Wild*

Main category: quant-ph

TL;DR: ANASTAARS是一种新颖的、可扩展的、噪声感知的经典优化器，专门用于QAOA等变分量子算法。它通过自适应随机子空间策略和噪声感知技术，有效降低了计算成本并提高了鲁棒性，在近期量子计算应用中展现出良好的可扩展性。


<details>
  <summary>Details</summary>
Motivation: 为了解决量子近似优化算法（QAOA）中潜在的大量QAOA层带来的挑战，需要一种噪声感知且可扩展的经典优化器。

Method: ANASTAARS利用自适应随机子空间策略来优化QAOA电路的ansatz参数，通过Johnson-Lindenstrauss变换在低维仿射子空间内构建随机插值模型，并结合噪声感知优化技术来估计噪声幅度和调整信任区域步长。

Result: ANASTAARS能够选择性地重用先前获得的测量结果，显著降低了与测量获取相关的计算成本，并且能够有效地处理噪声测量。

Conclusion: ANASTAARS在数值实验中证明了其在近期量子计算应用中的实际可扩展性。

Abstract: We introduce ANASTAARS, a noise-aware scalable classical optimizer for
variational quantum algorithms such as the quantum approximate optimization
algorithm (QAOA). ANASTAARS leverages adaptive random subspace strategies to
efficiently optimize the ansatz parameters of a QAOA circuit, in an effort to
address challenges posed by a potentially large number of QAOA layers.
ANASTAARS iteratively constructs random interpolation models within
low-dimensional affine subspaces defined via Johnson--Lindenstrauss transforms.
This adaptive strategy allows the selective reuse of previously acquired
measurements, significantly reducing computational costs associated with shot
acquisition. Furthermore, to robustly handle noisy measurements, ANASTAARS
incorporates noise-aware optimization techniques by estimating noise magnitude
and adjusts trust-region steps accordingly. Numerical experiments demonstrate
the practical scalability of the proposed method for near-term quantum
computing applications.

</details>


### [416] [A scalable quantum-neural hybrid variational algorithm for ground state estimation](https://arxiv.org/abs/2507.11002)
*Minwoo Kim,Kyoung Keun Park,Uihwan Jeong,Sanghyeon Lee,Taehyun Kim*

Main category: quant-ph

TL;DR: U-VQNHE 通过酉变换解决了 VQNHE 的训练问题，减少了测量开销。


<details>
  <summary>Details</summary>
Motivation: 为了解决 VQNHE 在训练过程中出现的范数问题和损失函数发散问题，以及随量子比特数增加而出现的指数级测量开销问题。

Method: 提出了一种酉变分量子-神经混合本征求解器 (U-VQNHE)，它通过强制执行酉神经变换来改进原始 VQNHE。

Result: U-VQNHE 解决了这些问题，显著减少了所需的测量次数，并保持了比标准变分量子本征求解器更高的准确性和稳定性。

Conclusion: U-VQNHE 通过强制执行酉变换解决了 VQNHE 的范数问题和损失函数发散问题，显著减少了测量开销，并保持了比标准 VQE 更高的准确性和稳定性。

Abstract: We propose the unitary variational quantum-neural hybrid eigensolver
(U-VQNHE), which improves upon the original VQNHE by enforcing unitary neural
transformations. The non-unitary nature of VQNHE causes normalization issues
and divergence of the loss function during training, leading to exponential
scaling of measurement overhead with qubit number. U-VQNHE resolves these
issues, significantly reduces required measurements, and retains improved
accuracy and stability over standard variational quantum eigensolvers.

</details>


### [417] [A review of perfect quantum state transfer, from one to two and three dimensional arrays of qubits](https://arxiv.org/abs/2507.11016)
*Marzieh Asoudeh,Vahid Karimipour*

Main category: quant-ph

TL;DR: 本篇论文回顾了量子状态转移，特别是二维和三维格子中的完美量子状态转移，并提出了一种在量子比特的不同层之间以单位保真度路由未知量子态的方法。


<details>
  <summary>Details</summary>
Motivation: 鉴于制造单层量子芯片和发展多层量子芯片的最新进展，对量子状态转移主题进行回顾。

Method: 提出了一种在量子比特的不同层之间以单位保真度路由未知量子态的方法。

Result: 本篇论文提出了一种在量子比特的不同层之间以单位保真度路由未知量子态的方法。

Conclusion: 本篇论文详细介绍了量子状态转移，特别是二维和三维格子中的完美量子状态转移。

Abstract: In the light of recent advances in fabricating single layer quantum chips and
a possible road toward development of multi-layer quantum chips, we review, in
a detailed way, the subject of quantum state transfer with particular emphasis
on perfect quantum state transfer in two and three dimensional lattices. We
show how one can route an unknown quantum state from one node in a single layer
of a quantum chip to another one on another layer with unit fidelity.
  Our method of presentation in this review allows the reader with a modest
background in quantum mechanics to grasp the essential ideas and methods of
this important branch of quantum information theory.

</details>


### [418] [New Localizable Entanglement](https://arxiv.org/abs/2507.11020)
*Abbaas Sabour,Fereydoon Khazali,Soghra Ghanavati*

Main category: quant-ph

TL;DR: 通过提出NLE并与LE进行比较，研究了其与LE的关系，发现NLE不大于LE，且在组分数量增加时两者差异会变大。


<details>
  <summary>Details</summary>
Motivation: 为了解决Verstraete等人于2004年提出的可定位纠缠（LE）概念中的歧义。

Method: 提出并探索了一种称为“新的可定位纠缠”（NLE）的纠缠形式，并通过与“可定位纠缠”（LE）进行比较来分析。

Result: NLE的大小不大于LE。对于三组分系统，NLE与LE没有显著差异。然而，当组分数量增加到四时，两者可能存在显著差异，并且随着组分数量的进一步增加，这种差异会略微增大。经典相关性既是LE的下界，也是NLE的下界。

Conclusion: NLE的大小不大于LE，且当系统组件数量增加时，NLE与LE的差异会更明显，经典相关性同时作为LE和NLE的下界。

Abstract: In this study, we have addressed an ambiguity in the concept of localizable
entanglement (LE) introduced by Verstraete et al in 2004. By doing so, we have
proposed and explored a unique form of this entanglement, called new
localizable entanglement (NLE). We have shown that NLE is always less than or
equal to LE. Additionally, we have demonstrated that for systems with three
components, NLE does not differ significantly from LE. However, when the number
of components increases to four, there is a possibility of significant
differences between the two methods. Furthermore, as the number of components
increases further, this difference becomes slightly more pronounced. It appears
that the classical correlation, which is the lower bound for LE, is also a
lower bound for NLE.

</details>


### [419] [On the Fundamental Resource for Exponential Advantage in Quantum Channel Learning](https://arxiv.org/abs/2507.11089)
*Minsoo Kim,Changhun Oh*

Main category: quant-ph

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Quantum resources enable us to achieve an exponential advantage in learning
the properties of unknown physical systems by employing quantum memory. While
entanglement with quantum memory is recognized as a necessary qualitative
resource, its quantitative role remains less understood. In this work, we
distinguish between two fundamental resources provided by quantum memory --
entanglement and ancilla qubits -- and analyze their separate contributions to
the sampling complexity of quantum learning. Focusing on the task of Pauli
channel learning, a prototypical example of quantum channel learning,
remarkably, we prove that vanishingly small entanglement in the input state
already suffices to accomplish the learning task with only a polynomial number
of channel queries in the number of qubits. In contrast, we show that without a
sufficient number of ancilla qubits, even learning partial information about
the channel demands an exponentially large sample complexity. Thus, our
findings reveal that while a large amount of entanglement is not necessary, the
dimension of the quantum memory is a crucial resource. Hence, by identifying
how the two resources contribute differently, our work offers deeper insight
into the nature of the quantum learning advantage.

</details>


### [420] [Quantum Power Iteration Unified Using Generalized Quantum Signal Processing](https://arxiv.org/abs/2507.11142)
*Viktor Khinevich,Yasunori Lee,Nobuyuki Yoshioka,Wataru Mizukami*

Main category: quant-ph

TL;DR: GQSP统一了量子功率方法，在效率、收敛性和获得激发态方面优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 提出一个统一的框架，通过广义量子信号处理（GQSP）来处理基于量子功率的方法。

Method: 通过广义量子信号处理（GQSP）实现了经典功率迭代、功率Lanczos、逆迭代和折叠谱方法的量子类似物。

Result: GQSP为基础的量子功率方法结合了可扩展性、灵活性和鲁棒的收敛性，并且在分子哈密顿量上进行了基准测试，其中量子功率Lanczos比标准的量子功率迭代收敛更快、更可靠，而量子逆迭代优于基于时间演化算子的现有逆迭代变体。量子折叠谱方法可以在没有变分优化的前提下获得激发态。

Conclusion: GQSP使量子功率方法具有可扩展性、灵活性和鲁棒的收敛性，为容错量子设备上的实际初始状态制备铺平了道路。

Abstract: We present a unifying framework for quantum power-method-based algorithms
through the lens of generalized quantum signal processing (GQSP): we apply GQSP
to realize quantum analogues of classical power iteration, power Lanczos,
inverse iteration, and folded spectrum methods, all within a single coherent
framework. Our approach is efficient in terms of the number of queries to the
block encoding of a Hamiltonian. Also, our approach can avoid Suzuki-Trotter
decomposition. We constructed quantum circuits for GQSP-based quantum power
methods, estimated the number of queries, and numerically verified that this
framework works. We additionally benchmark various quantum power methods with
molecular Hamiltonians and demonstrate that Quantum Power Lanczos converges
faster and more reliably than standard Quantum Power Iteration, while Quantum
Inverse Iteration outperforms existing inverse iteration variants based on
time-evolution operators. We also show that the Quantum Folded Spectrum Method
can obtain excited states without variational optimization. Overall, our
results indicate that GQSP-based implementations of power methods combine
scalability, flexibility, and robust convergence, paving the way for practical
initial state preparations on fault-tolerant quantum devices.

</details>


### [421] [Versatile Wavelength-Division Multiplexed Quantum Key Distribution Network Operating Simultaneously in the O and C Bands](https://arxiv.org/abs/2507.11175)
*Davide Scalcon,Matteo Padovan,Paolo Villoresi,Giuseppe Vallone,Marco Avesani*

Main category: quant-ph

TL;DR: 本研究构建了一个四节点光子QKD网络，利用波分复用技术实现了在所有节点间的同步密钥分发，并显著降低了成本和提高了紧凑性。


<details>
  <summary>Details</summary>
Motivation: 随着技术进步，量子密钥分发（QKD）的商业和全球部署加速，其在未来通信网络中实现无条件安全通信的能力至关重要。因此，在真实环境中进行QKD网络实施的实际演示对于确保其可靠应用非常关键。

Method: 本研究设计并实现了一个四节点光子量子密钥分发（QKD）网络。网络利用波分复用（WDM）技术，在O频段和C频段部署了三个发射器，实现了在所有节点间的同步密钥分发。中心接收节点设计为共享除单光子探测器外的所有光学和电子解码组件，以优化成本和空间。

Result: 成功构建了一个四节点光子QKD网络，实现了在O和C频段跨三个发射器的波分复用，并在所有节点间同步分发了量子安全密钥。通过共享中心接收节点的光学和电子解码组件（单光子探测器除外），有效降低了系统成本并提高了紧凑性。

Conclusion: 该研究展示了一个四节点光子QKD网络，该网络在O和C频段跨三个发射器使用多功能且具成本效益的波分复用技术，实现了在所有节点间的同步量子安全密钥分发。中心接收节点共享所有光学和电子解码组件（单光子探测器除外），从而显著降低了系统成本并提高了紧凑性。

Abstract: Ongoing technological progress is accelerating the commercial and
global-scale deployment of Quantum Key Distribution (QKD). Its ability to
enable unconditionally secure communication is expected to be a key feature of
future telecommunication networks, and practical demonstrations of QKD network
implementations in real-world environments are crucial for ensuring reliable
adoption. In this work, we demonstrate a four-node photonic QKD network that
employs versatile and cost-effective wavelength-division multiplexing across
three transmitters in the O and C bands to simultaneously distribute
quantum-secure keys among all nodes. Specifically, the broadband central
receiver node shares all optical and electronic decoding components, except for
the single-photon detectors, across the three QKD links, significantly reducing
system costs and enhancing compactness.

</details>


### [422] [Real-time preparation and verification of nonstabilizer states](https://arxiv.org/abs/2507.11180)
*Jian Li,Ye-Chao Liu,Xiao-Xiao Chen,Zhe Meng,Xing-Yan Fan,Wen-Hao Wang,Jie Ma,An-Ning Zhang,Jiangwei Shang*

Main category: quant-ph

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Entanglement lies at the heart of quantum information science, serving as a
key resource for quantum communication, computation, and metrology.
Consequently, high-precision entangled state preparation and efficient
verification are essential for practical quantum technologies. Quantum state
verification (QSV) has recently gained much attention as an efficient and
experiment-friendly approach for verifying entangled states. In this work, we
experimentally demonstrate a QSV protocol for verifying three-qubit
nonstabilizer $W$ state via a modified homogeneous strategy. Notably, our
implementation extends QSV beyond its standard role by integrating the state
preparation process, thus guiding and validating the real-time generation of
high-fidelity target states. Specifically, we realize the efficient
verification with a favorable scaling of the required number of copies versus
infidelity as $-1.39$, outperforming the standard quantum limit of $-2$.
Meanwhile, a fidelity of $97.07(\pm 0.26)\%$ via direct estimation is achieved
using only $9$ measurement settings and $10^4$ samples, which is independently
confirmed by quantum state tomography to be $98.58(\pm 0.12)\%$ with
approximately $10^6$ measurements. This work presents the first experimental
demonstration of QSV actively assisted with state preparation, establishing it
as a powerful and resource-efficient alternative to full tomography for
real-time quantum state engineering.

</details>


### [423] [A Three-Party Lightweight Quantum Key Distribution Protocol in a Restricted Quantum Environment](https://arxiv.org/abs/2507.11188)
*Mustapha Anis Younes,Sofia Zebboudj,Abdelhakim Gharbi*

Main category: quant-ph

TL;DR: 本研究提出了一种新的轻量级量子密钥分发（LQKD）协议，该协议使用四粒子簇状态，允许一个量子用户与两个经典用户同时建立两个独立的密钥。该协议采用单向传输，克服了现有半量子密钥分发（SQKD）方案的缺点，更轻便实用，安全级别与全量子协议相当，并且在非理想情况下具有良好的噪声容限。


<details>
  <summary>Details</summary>
Motivation: 为了克服现有半量子密钥分发（SQKD）方案的局限性，如需要双向传输、经典参与者易受量子木马攻击以及量子比特效率较低等问题，提出了一种新的轻量级量子密钥分发（LQKD）协议。

Method: 提出了一种基于四粒子簇状态的轻量级量子密钥分发（LQKD）协议，该协议允许一个有量子能力的参与者同时与两个仅限于执行Hadamard操作和Z基测量的经典参与者建立两个独立的密钥。该协议采用单向量子比特传输，克服了现有半量子密钥分发（SQKD）方案中需要双向或循环传输的限制，无需经典参与者配备昂贵的量子设备来防御量子木马攻击，减少了量子比特传输距离，并提高了量子比特效率。

Result: 该协议实现了三方通信，使一个有量子能力的参与者能够同时与两个经典参与者建立两个独立的密钥。与现有方案相比，该协议更轻量、更实用，并且在理想情况下具有与全量子协议相同的安全级别。在非理想情况下，该协议被证明是无条件安全的，并且具有接近BB84协议的噪声容限。

Conclusion: 该协议比现有的半量子密钥分发（SQKD）协议更轻量、更实用，并且在理想情况下具有与全量子协议相同的安全级别。在非理想情况下，该协议被证明是无条件安全的，并且具有接近BB84协议的噪声容限。

Abstract: This study proposes a new lightweight quantum key distribution (LQKD)
protocol based on the four-particle cluster state within a quantum-restricted
environment. The protocol enables a quantum-capable user to simultaneously
establish two separate secret keys with two "classical" users, who are limited
to performing only the Hadamard operation and measurements in the $Z$ basis. By
adopting a one-way qubit transmission approach, the proposed protocol addresses
several limitations of existing semi-quantum key distribution (SQKD) schemes
that rely on two-way or circular transmission methods: (1) it eliminates the
need for classical participants to be equipped with costly quantum devices to
defend against quantum Trojan horse attacks; (2) it reduces the qubit
transmission distance; and (3) it achieves higher qubit efficiency.
Consequently, the proposed three-party LQKD protocol is both more lightweight
and practical than existing SQKD protocols. Furthermore, the security analysis
shows that, in the ideal case, the protocol achieves the same level of security
as fully quantum protocols. Finally, the study proves the unconditional
security of the protocol in the non-ideal case, demonstrating a noise tolerance
close to that of the BB84 protocol.

</details>


### [424] [$d+1$ Measurement Bases are Sufficient for Determining $d$-Dimensional Quantum States: Theory and Experiment](https://arxiv.org/abs/2507.11204)
*Tianqi Xiao,Yaxin Wang,Ying Xia,Zhihao Li,Xiaoqi Zhou*

Main category: quant-ph

TL;DR: 量子物理学界长期关注如何用最少的测量基来表征量子态，尤其在高维量子信息处理领域。本研究提出了一个创新的量子态层析方案，仅用d+1个测量基就能完整重构任意d维量子态。实验上，该方案在d=6的硅光子芯片上得到了验证，即使在该维度下不存在互补基。此方法为量子态表征和测量设计提供了新思路，并预示着其在未来量子信息处理中的应用潜力。


<details>
  <summary>Details</summary>
Motivation: 确定完整表征未知量子态所需的最小测量基数量是量子物理学中的一个长期存在的问题，这对于高维量子信息处理尤其重要。

Method: 提出了一种仅需d+1个测量基即可完全重构任意d维量子态的量子态层析方案。

Result: 通过在硅光子芯片上进行实验验证，该方案成功重建了d=6的量子态，即使在不存在完全互补基的情况下也是如此。

Conclusion: 该方法为量子态表征提供了新视角，并有望在量子信息处理的未来应用中发挥作用。

Abstract: A long-standing problem in quantum physics is to determine the minimal number
of measurement bases required for the complete characterization of unknown
quantum states, a question of particular relevance to high-dimensional quantum
information processing. Here, we propose a quantum state tomography scheme that
requires only $d+1$ projective measurement bases to fully reconstruct an
arbitrary $d$-dimensional quantum state. As a proof-of-principle, we
experimentally verified this scheme on a silicon photonic chip by
reconstructing quantum states for $d=6$, in which a complete set of mutually
unbiased bases does not exist. This approach offers new perspectives for
quantum state characterization and measurement design, and holds promise for
future applications in quantum information processing.

</details>


### [425] [Quantum Adaptive Excitation Network with Variational Quantum Circuits for Channel Attention](https://arxiv.org/abs/2507.11217)
*Yu-Chao Hsu,Kuan-Cheng Chen,Tai-Yue Li,Nan-Yow Chen*

Main category: quant-ph

TL;DR: 提出了一种名为QAE-Net的混合量子-经典框架，通过用变分量子电路（VQC）替换CNN中的经典激励块来增强通道注意力机制，并在图像分类任务中取得了性能提升。


<details>
  <summary>Details</summary>
Motivation: 为了增强卷积神经网络（CNN）中的通道注意力机制，并解决纯经典方法难以建模的高阶通道间依赖性问题。

Method: 提出了一种名为量子自适应激励网络（QAE-Net）的混合量子-经典框架，该框架用浅层变分量子电路（VQC）替换了CNN中Squeeze-and-Excitation模块的经典激励块，以利用量子叠加和纠缠来捕捉高阶通道间依赖性。

Result: 在MNIST、FashionMNIST和CIFAR-10等图像分类任务上观察到了一致的性能提升，特别是在处理三通道输入时。实验结果表明，增加量子线路中的变分层数可以逐步提高分类准确性。

Conclusion: QAE-Net通过将CNN中的经典激励块替换为VQC，展示了在图像分类任务上提升性能的潜力，尤其是在处理三通道输入时。增加量子线路的变分层数可进一步提高分类准确性，表明更深的量子模型具有更好的表达能力。该方法适用于NISQ时代，为在实际深度学习工作流中部署量子增强的注意力机制提供了可行的途径。

Abstract: In this work, we introduce the Quantum Adaptive Excitation Network (QAE-Net),
a hybrid quantum-classical framework designed to enhance channel attention
mechanisms in Convolutional Neural Networks (CNNs). QAE-Net replaces the
classical excitation block of Squeeze-and-Excitation modules with a shallow
Variational Quantum Circuit (VQC), leveraging quantum superposition and
entanglement to capture higher-order inter-channel dependencies that are
challenging to model with purely classical approaches. We evaluate QAE-Net on
benchmark image classification tasks, including MNIST, FashionMNIST, and
CIFAR-10, and observe consistent performance improvements across all datasets,
with particularly notable gains on tasks involving three-channel inputs.
Furthermore, experimental results demonstrate that increasing the number of
variational layers in the quantum circuit leads to progressively higher
classification accuracy, underscoring the expressivity benefits of deeper
quantum models. These findings highlight the potential of integrating VQCs into
CNN architectures to improve representational capacity while maintaining
compatibility with near-term quantum devices. The proposed approach is tailored
for the Noisy Intermediate-Scale Quantum (NISQ) era, offering a scalable and
feasible pathway for deploying quantum-enhanced attention mechanisms in
practical deep learning workflows.

</details>


### [426] [Finite-correlation-secure quantum key distribution](https://arxiv.org/abs/2507.11243)
*Yang-Guang Shan,Jia-Xuan Li,Zhen-Qiang Yin,Shuang Wang,Wei Chen,De-Yong He,Guang-Can Guo,Zheng-Fu Han*

Main category: quant-ph

TL;DR: 提出了一种免疫所有维度相关性的新量子密钥分发协议，该协议具有非纠缠、有限范围相关性和有限真空概率的要求，同时具有侧信道安全和测量设备无关的特性，可容忍高达500个脉冲的相关性。


<details>
  <summary>Details</summary>
Motivation: 量子密钥分发中不同脉冲之间的相关性是一个棘手的问题，现有的解决方案需要表征相关性的强度，这可能会降低量子密钥分发的安全性。

Method: 提出了一种新的量子密钥分发协议，该协议免疫所有维度上的所有相关性，具有非纠缠和有限范围相关性的要求，以及有限的真空概率。

Result: 有限密钥安全分析表明，该协议能够抵抗相干攻击，并且数值模拟显示，即使在较大的相关范围（例如跨越500个脉冲）下，该协议的性能也不会受到显著影响，并且可以容忍较大的相关范围。

Conclusion: 该协议免疫所有维度上的所有相关性，具有非纠缠和有限范围相关性的要求，以及有限的真空概率。该协议还具有侧信道安全和测量设备无关的特性，在实际量子密钥分发系统中具有高安全性。

Abstract: Correlation between different pulses is a nettlesome problem in quantum key
distribution (QKD). All existing solutions for this problem need to
characterize the strength of the correlation, which may reduce the security of
QKD to an accurate characterization. In this article, we propose a new protocol
immune to all correlations of all dimensions, with the only requirements of
non-entangled and finite-ranged correlation, and bounded vacuum probability.
Additionally, the new protocol is side-channel-secure and
measurement-device-independent, giving high-level security in practical QKD
systems. We provide the finite-key security analysis against coherent attacks
and conduct numerical simulations to see the performance. The result shows that
a small correlation range does not influence the performance a lot and the
protocol could tolerate a large correlation range, such as correlations
spanning over 500 pulses.

</details>


### [427] [Secure quantum key distribution against correlated leakage source](https://arxiv.org/abs/2507.11251)
*Jia-Xuan Li,Yang-Guang Shan,Rong Wang,Feng-Yu Lu,Zhen-Qiang Yin,Shuang Wang,Wei Chen,De-Yong He,Guang-Can Guo,Zheng-Fu Han*

Main category: quant-ph

TL;DR: 本研究提出了一个用于分析量子密钥分发（QKD）中脉冲相关性安全风险的框架，并开发了一种新的QKD协议，提高了其在实际应用中的安全性和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 量子密钥分发（QKD）的实际部署受到信源设备不完美的挑战，特别是传输脉冲之间的相关性可能危及QKD理论保证的安全性。这项工作旨在解决这一被忽视的安全风险。

Method: 提出了一种新的安全分析框架，用于分析具有相关性的量子密钥分发（QKD）。该框架通过扩展和重新排列QKD轮次并利用广义链式法则，首次实现了有限密钥分析。在此框架基础上，借鉴侧信道安全QKD的思想，开发了一种针对相关泄漏源的安全QKD协议。

Result: 提出的安全分析框架能够对具有相关性的QKD进行有限密钥分析。开发的新型QKD协议仅需相关性范围和真空分量下界的表征即可实现安全。模拟结果显示，该协议比现有协议具有更好的参数容错能力。

Conclusion: 该研究为在实际运行条件下，如不完美参数，实现量子密钥分发（QKD）的安全提供了关键一步。通过开发一个安全分析框架，并基于此提出了一种新的QKD协议，该协议仅需了解相关性范围和真空分量的下界即可实现针对相关泄漏源的安全。模拟结果表明，与现有协议相比，该协议具有优越的容错能力，为在真实世界约束下实现长距离、高性能安全通信奠定了基础。

Abstract: Quantum key distribution (QKD) provides information theoretic security based
on quantum mechanics, however, its practical deployment is challenged by
imperfections of source devices. Among various source loopholes, correlations
between transmitted pulses pose a significant yet underexplored security risk,
potentially compromising QKD's theoretical guarantees. In this work, we propose
a security analysis framework for QKD under correlations, enabling finite-key
analysis for the first time by extending and rearranging QKD rounds and
leveraging the generalized chain rule. Based on this framework, and inspired by
the idea of side-channel-secure QKD, we develop a secure QKD against correlated
leakage source only need the characterization of correlation range and the
lower bound on the vacuum component of the prepared states. Additionally, our
framework can be extended to other QKD protocols, offering a general approach
to consider correlation induced security vulnerabilities. The simulation
results demonstrate the effectiveness of our protocol and its significantly
superior tolerance to imperfect parameters compared to existing protocols. This
work provides a crucial step toward closing security loopholes in QKD,
enhancing its practicality, and ensuring long-distance,high-performance secure
communication under real-world constraints.

</details>


### [428] [Quantized decay charges in non-Hermitian networks characterized by directed graphs](https://arxiv.org/abs/2507.11322)
*Wenwen Liu,Junyao Wu,Li Zhang,Oubo You,Ye Tian,Wenan Zang,Hongsheng Chen,Bumki Min,Yihao Yang,Shuang Zhang*

Main category: quant-ph

TL;DR: 研究了具有纯指数衰减（无振荡）的新型非厄米系统，发现了作为拓扑不变量的量化衰减电荷，并通过实验验证了其在不同系统中的存在，为光子学等领域开辟了新应用。


<details>
  <summary>Details</summary>
Motivation: 探索非厄米物理学中不同于传统非厄米奇异性（NHSE）的奇异现象，特别是寻找具有纯指数衰减而无振荡模式的本征态，并揭示其潜在的拓扑性质和应用价值。

Method: 本研究将具有非互易跃迁的系统建模为定向图，并引入了量化衰减电荷的概念，将其定义为每个节点处沿边的衰减常数之和，以此作为新的拓扑不变量。通过推导普适条件，将此模型推广到不同维度和连接性的系统，并利用微波谐振电路进行了实验验证。

Result: 成功引入了具有纯衰减模式的新型非厄米系统，该模式表现为无振荡的纯指数衰减。发现了量化衰减电荷作为一种新的拓扑不变量，并推导了其普适条件，适用于各种维度和连接性的系统。微波谐振电路的实验结果证实了纯衰减模式的预测。

Conclusion: 本研究引入了一类新的非厄米系统，其特征是纯衰减模式，即不包含传统非厄米奇异性中的振荡模式的纯指数衰减的本征态。通过将这些系统建模为具有非互易跃迁的定向图，我们发现了量化衰减电荷，即每个节点处沿边的衰减常数之和，这是一种新颖的拓扑不变量。我们推导了这些模式的普适条件，并将其推广到一维环、复杂连通性的定向图和高维格点。通过微波谐振电路的实验验证证实了预测的纯衰减行为。本发现为光子学、信号处理等领域的潜在应用开辟了道路，有望利用非厄米网络的独特拓扑性质。

Abstract: Non-Hermitian physics has unveiled a realm of exotic phenomena absent in
Hermitian systems, with the non-Hermitian skin effect (NHSE) showcasing
boundary-localized eigenstates driven by non-reciprocal interactions. Here, we
introduce a new class of non-Hermitian systems exhibiting pure decay modes:
eigenstates with pure, smooth exponential decay, devoid of the oscillatory wave
patterns typical of traditional NHSE. Modeled as directed graphs with
non-reciprocal hopping, these systems reveal quantized decay charges, defined
as the sum of decay constants along edges at each node, offering a novel
topological invariant. We derive universal conditions for these modes, enabling
versatile configurations from one-dimensional rings, directed graphs with
complicated connectivity, to higher-dimensional lattices. Experimental
validation using microwave resonant circuits confirms the predicted pure decay
profiles. This discovery paves the way for potential applications in photonics,
signal processing, and beyond, harnessing the unique topological properties of
non-Hermitian networks.

</details>


### [429] [Channel-loss-independent quantum-enhanced interferometer](https://arxiv.org/abs/2507.11342)
*Yi-Xin Shen,Zhou-Kai Cao,Jian Leng,Xiang-Bin Wang*

Main category: quant-ph

TL;DR: 提出了一种与信道损耗无关的量子增强干涉仪，该干涉仪在长基线区域具有更高的角分辨率，并且仅需要成熟的技术。


<details>
  <summary>Details</summary>
Motivation: 在任意大的信道损耗下，从遥远星体发出的弱光相位差的费舍尔信息保持不变。

Method: 提出了一种与信道损耗无关的量子增强干涉仪。

Result: 该方法的角分辨率优于长基线区域的先前量子增强方法。

Conclusion: 该方法在长基线区域优于先前所有基于量子增强的测量方法，并且仅需要探测器和可调谐相干态或双模压缩态光源，这些都是成熟的技术。

Abstract: We propose a channel-loss-independent quantum-enhanced interferometer. In our
scheme, the Fisher information for phase difference of weak light from a remote
star remains constant under arbitrarily large channel loss, and the angular
resolution of our method is better than that of prior quantum-enhanced methods
in the long-baseline regime. Moreover, our method requires only threshold
detectors and tunable coherent state or two-mode squeezed state sources, both
of which are matured technologies nowadays.

</details>


### [430] [Metrology using atoms in an array of double-well potentials](https://arxiv.org/abs/2507.11395)
*Danish Ali Hamza,Jan Chwedeńczuk*

Main category: quant-ph

TL;DR: 利用双阱势阱阵列和洪-欧-曼德尔效应的多体等效物产生纠缠态，以提高量子传感器的计量灵敏度。


<details>
  <summary>Details</summary>
Motivation: 探索量子效应（如纠缠、爱因斯坦-波多尔斯基-罗森 मिळू、贝尔相关性）在超越标准量子极限以提高计量灵敏度方面的应用，并提出一种新的生成可扩展、多体纠缠态的方法，用于量子增强计量。

Method: 通过包含独立且不相关的玻色-爱因斯坦凝聚体的（1D）双阱势阱阵列，利用分束变换在相邻阱之间混合信号，产生洪-欧-曼德尔效应的多体等效物，从而生成可扩展的、多体纠缠态。

Result: 证明了通过洪-欧-曼德尔效应的多体等效物产生的纠缠态可以提高量子传感器的灵敏度，并确定了使量子克拉美-罗界饱和的最佳测量。

Conclusion: 量子纠缠（如纠缠、爱因斯坦-波多尔斯基-罗森 मिळू、贝尔相关性）可以超越标准量子极限提高计量灵敏度。这些相关性通常通过原子或分子之间的相互作用，或激光脉冲通过双折射晶体期间产生。我们考虑了一种替代方法来生成可扩展的、多体纠缠态，并展示了它们在量子增强计量中的可用性。我们的装置是包含独立且不相关的玻色-爱因斯坦凝聚体的（1D）双阱势阱阵列。分束变换在相邻阱之间混合信号，并通过洪-欧-曼德尔效应的多体等效物产生强纠缠态。我们证明了这种纠缠可以提高量子传感器的灵敏度。在我们的分析中，我们考虑了原子涨落的影响，并确定了使量子克拉美-罗界饱和的最佳测量。

Abstract: Quantum effects, such as entanglement, Einstein-Podolsky-Rosen steering, and
Bell correlations, can enhance metrological sensitivity beyond the standard
quantum limit. These correlations are typically generated through interactions
between atoms or molecules, or during the passage of a laser pulse through a
birefringent crystal. Here, we consider an alternative method of generating
scalable, many-body entangled states, and demonstrate their usability for
quantum-enhanced metrology. Our setup is a one-dimensional (1D) array of
double-well potentials holding independent and uncorrelated Bose-Einstein
condensates. The beam-splitting transformation mixes the signal between
adjacent wells and yields a strongly entangled state through a many-body
equivalent of the Hong-Ou-Mandel effect. We demonstrate this entanglement can
improve the sensitivity of quantum sensors. In our analysis, we account for the
effects of atomic fluctuations and identify the optimal measurement that
saturates the quantum Cramer-Rao bound.

</details>


### [431] [Stochastic Entanglement Configuration for Constructive Entanglement Topologies in Quantum Machine Learning with Application to Cardiac MRI](https://arxiv.org/abs/2507.11401)
*Mehri Mehrnia,Mohammed S. M. Elbaz*

Main category: quant-ph

TL;DR: 提出了一种随机纠缠配置方法，用于优化变分量子电路的纠缠策略。该方法通过生成和评估多种纠缠拓扑结构，在心脏MRI疾病分类任务中发现了优于经典模型和传统方法的建设性纠缠配置，显著提高了分类准确率。


<details>
  <summary>Details</summary>
Motivation: 当前量子机器学习（QML）中的变分量子电路（VQC）虽然需要有效的纠缠策略，但大多采用固定的、不适应任务需求的纠缠拓扑结构，这限制了其超越经典模型的潜力。因此，有必要开发一种能够自适应任务需求、系统地生成和评估多样化纠缠拓扑结构的方法。

Method: 提出了一种新颖的随机纠缠配置方法，将纠缠拓扑编码为表示量子比特之间定向纠缠的随机二元矩阵。该方法允许使用纠缠密度和每量子比特约束作为关键指标，在假设的候选纠缠拓扑空间中进行可扩展探索。该方法定义了无约束和有约束的采样模式，以控制每量子比特的纠缠。

Result: 研究中生成的400种随机配置在心脏MRI疾病分类任务中进行了评估，其中64种（16%）被识别为建设性配置，其性能一致优于经典基线。顶尖配置的集成模型达到了约0.92的分类准确率，比经典模型（约0.87）高出5%以上。与环状、最近邻、无纠缠和全纠缠等四种传统拓扑结构相比，传统结构均未超越经典基线（最高准确率约0.82），而该方法识别出的配置准确率最高可提升20%。

Conclusion: 该研究提出的随机纠缠配置方法能够系统地生成多样化的纠缠拓扑结构，并从中识别出能够提升混合模型性能的建设性纠缠配置。在心脏MRI疾病分类任务中，该方法发现了400种配置中的64种（16%）建设性配置，其性能一致优于经典基线。通过集成顶尖配置，实现了约0.92的分类准确率，显著超越了经典模型（约0.87）超过5%。与四种传统拓扑结构相比，该方法识别出的配置可提供高达20%的准确率提升，证明了其鲁棒性和泛化能力。

Abstract: Efficient entanglement strategies are essential for advancing variational
quantum circuits (VQCs) for quantum machine learning (QML). However, most
current approaches use fixed entanglement topologies that are not adaptive to
task requirements, limiting potential gains over classical models. We introduce
a novel stochastic entanglement configuration method that systematically
generates diverse entanglement topologies to identify a subspace of
constructive entanglement configurations, defined as entanglement topologies
that boost hybrid model performance (e.g., classification accuracy) beyond
classical baselines. Each configuration is encoded as a stochastic binary
matrix, denoting directed entanglement between qubits. This enables scalable
exploration of the hyperspace of candidate entanglement topologies using
entanglement density and per-qubit constraints as key metrics. We define
unconstrained and constrained sampling modes, controlling entanglement per
qubit. Using our method, 400 stochastic configurations were generated and
evaluated in a hybrid QML for cardiac MRI disease classification. We identified
64 (16%) novel constructive entanglement configurations that consistently
outperformed the classical baseline. Ensemble aggregation of top-performing
configurations achieved ~0.92 classification accuracy, exceeding the classical
model (~0.87) by over 5%. Compared to four conventional topologies (ring,
nearest neighbor, no entanglement, fully entangled), none surpassed the
classical baseline (maximum accuracy ~0.82), while our configurations delivered
up to ~20% higher accuracy. Thus, highlighting the robustness and
generalizability of the identified constructive entanglements.

</details>


### [432] [Simulating and Sampling from Quantum Circuits with 2D Tensor Networks](https://arxiv.org/abs/2507.11424)
*Manuel S. Rudolph,Joseph Tindall*

Main category: quant-ph

TL;DR: This paper uses tensor networks matching quantum processor geometry to classically simulate quantum circuits. It finds that lattice geometry heavily influences simulation difficulty and the behavior of physical phenomena like loop correlations, with different effects observed on IBM's and Google's processor geometries.


<details>
  <summary>Details</summary>
Motivation: Classical simulations of quantum circuits are crucial for developing quantum computers and assessing the current state of the field. This work aims to systematically simulate physically-motivated circuits using tensor network ans"atze that mirror the processor's geometry.

Method: The paper uses 2D tensor network ans"atze that match the geometry of the quantum processor to classically simulate quantum circuits. A generalized boundary Matrix Product State contraction algorithm is employed to controllably generate samples from the tensor network states, allowing for systematic convergence to the true distribution.

Result: The study simulated large local unitary Jastrow ansatz circuits to numerical precision. It also investigated a domain-wall quench in a 2D discrete-time Heisenberg model on heavy-hex and rotated square lattices. The results show rapid buildup of complex loop correlations on the Google Willow geometry, significantly affecting local properties, while loop correlations build up slowly on heavy-hex processors with negligible impact on local properties even at large circuit depths.

Conclusion: The geometry of the quantum processor plays a significant role in classical simulability. Different lattice geometries (heavy-hex and rotated square) exhibit varying rates of loop correlation buildup, impacting local properties and classical simulation efficiency.

Abstract: Classical simulations of quantum circuits play a vital role in the
development of quantum computers and for taking the temperature of the field.
Here, we classically simulate various physically-motivated circuits using 2D
tensor network ans\"atze for the many-body wavefunction which match the
geometry of the underlying quantum processor. We then employ a generalized
version of the boundary Matrix Product State contraction algorithm to
controllably generate samples from the resultant tensor network states. Our
approach allows us to systematically converge both the quality of the final
state and the samples drawn from it to the true distribution defined by the
circuit. With these methods, we simulate the largest local unitary Jastrow
ansatz circuit taken from recent IBM experiments to numerical precision. We
also study a domain-wall quench in a two-dimensional discrete-time Heisenberg
model on large heavy-hex and rotated square lattices, which reflect IBM's and
Google's latest quantum processors respectively. We observe a rapid buildup of
complex loop correlations on the Google Willow geometry which significantly
impact the local properties of the system. Meanwhile, we find loop correlations
build up extremely slowly on heavy-hex processors and have almost negligible
impact on the local properties of the system, even at large circuit depths. Our
results underscore the role the geometry of the quantum processor plays in
classical simulability.

</details>


### [433] [Entanglement Classification in the Graph States: The generalization to $n$-Qubits States using the Entanglement Matrix](https://arxiv.org/abs/2507.11458)
*Sameer Sharma*

Main category: quant-ph

TL;DR: 本研究提出熵纠缠矩阵来量化图态纠缠，发现最大纠缠度与量子比特数呈二次方关系，奇偶系统行为不同，12的倍数系统纠缠度更强。


<details>
  <summary>Details</summary>
Motivation: 图态作为一类重要的多粒子量子纠缠态，在量子误差校正、量子通信和量子计算等领域具有广泛应用。然而，有效量化和分类这些复杂状态中的纠缠仍然是一个挑战。本研究旨在开发一种新的方法来深入理解和量化图态的纠缠特性。

Method: 本研究采用熵纠缠矩阵（Entanglement Matrix）作为新颖的分析工具，结合图论和量子信息概念，系统地量化和分类了n量子比特图态中的纠缠。通过识别图表示中的主要和次要中点（对应于量子比特间的受控-Z门操作），并利用冯诺依曼熵作为度量标准，推导了最大纠缠度与量子比特数量之间的精确数学关系。

Result: 研究结果表明，图态中的最大纠缠度与量子比特数量之间存在二次方关系，但奇数和偶数系统表现出不同的行为模式。对于奇数n量子比特图态，最大纠缠度为 $E_{\max} = n^2 - n$；而偶数系统则展现出更高的纠缠度，且其具体公式取决于特定的结构配置。值得注意的是，当量子比特数量为12的倍数时，系统表现出增强的纠缠特性。

Conclusion: 本研究提出的熵纠缠矩阵为量化和分类n量子比特图态中的纠缠提供了一个新颖且系统的框架。通过将图论概念与量子信息理论相结合，我们发现了量子比特数量与最大纠缠度之间的精确数学关系，并揭示了奇偶系统在纠缠特性上的差异。特别是，12的倍数系统表现出增强的纠缠特性。该框架为理解复杂量子系统中的纠缠分布奠定了分析基础，并为未来的量子技术提供了有价值的见解。

Abstract: Graph states represent a significant class of multi-partite entangled quantum
states with applications in quantum error correction, quantum communication,
and quantum computation. In this work, we introduce a novel formalism called
the Entanglement Matrix for quantifying and classifying entanglement in n-qubit
graph states. Leveraging concepts from graph theory and quantum information, we
develop a systematic approach to analyze entanglement by identifying primary
and secondary midpoints in graph representations, where midpoints correspond to
controlled-Z gate operations between qubits. Using Von Neumann entropy as our
measure, we derive precise mathematical relationships for maximum entanglement
in graph states as a function of qubit number. Our analysis reveals that
entanglement follows a quadratic relationship with the number of qubits, but
with distinct behaviors for odd versus even qubit systems. For odd n-qubit
graph states, maximum entanglement follows $E_{\max} = n^2 - n$, while even
n-qubit states exhibit higher entanglement with varying formulae depending on
specific configurations. Notably, systems with qubit counts that are multiples
of 12 demonstrate enhanced entanglement properties. This comprehensive
classification framework provides valuable insights into the structure of
multi-qubit entanglement, establishing an analytical foundation for
understanding entanglement distribution in complex quantum systems that may
inform future quantum technologies.

</details>


### [434] [Enhancing the Clique Local Decoder to Correct Length-2 Space Errors in the Surface Code](https://arxiv.org/abs/2507.11481)
*Zikang Jia,Shravan Veerapaneni,Gokul Subramanian Ravi*

Main category: quant-ph

TL;DR: Clique_L2 是一种新的量子纠错解码器，它通过处理更长的错误链来提高效率，显著减少了数据传输量，尤其是在处理簇状错误时。


<details>
  <summary>Details</summary>
Motivation: 为了满足容错量子计算对高效、可扩展的量子纠错（QEC）策略日益增长的需求，并解决传统解码器在最坏情况下的高开销问题，开发了利用量子错误稀疏性以及许多量子错误具有平凡性质的局部解码器，以辅助传统解码器。

Method: 提出 Clique_L2 解码器，该解码器在 Clique 解码器的基础上进行了扩展，放宽了部分原始约束，并增加了低成本逻辑以纠正空间中的长度为 2 的错误链。

Result: Clique_L2 在数据量子比特错误和均匀随机噪声下，与 Clique_L1 解码器相比，解码带宽减少高达 8.95 倍，在高码距下尤其有利。在簇状错误和较长错误链更可能发生的情况下，Clique_L2 与 Clique_L1 解码器相比，解码带宽减少高达 18.3 倍，在广泛的物理量子比特错误率下均能实现显著效益。

Conclusion: Clique_L2 扩展了 Clique 解码器，通过增加处理长度为 2 的空间错误链的能力，在处理特定错误模型（如数据量子比特错误和均匀随机噪声）以及簇状错误时，与 Clique_L1 解码器相比，解码带宽减少高达 18.3 倍。

Abstract: The growing demand for fault-tolerant quantum computing drives the need for
efficient, scalable Quantum Error Correction (QEC) strategies. Conventional
decoders designed for worst-case error scenarios incur significant overhead,
prompting the development of local decoders, that leverage the sparse and often
trivial nature of many quantum errors, to support the conventional decoders.
The previously proposed Clique decoder addresses this by handling isolated,
length-1 space and time errors within the cryogenic environment with minimal
hardware costs, thereby mitigating I/O bandwidth constraints between cryogenic
quantum systems and room-temperature processors. Building on this foundation,
we propose Clique_L2 that extends the Clique-based approach by relaxing some
original constraints and incorporating additional low-cost logic to also
correct length-2 error chains in space, which become non-trivial occurrences at
higher physical error rates and code distances. This enhanced capability not
only further reduces out-of-the-fridge data transmission but also adapts more
effectively to clustered errors observed under a variety of noise models.
Specifically, under data-qubit-only errors and uniformly random noise,
Clique_L2 achieves up to 8.95x decoding bandwidth reduction over the original
Clique (or Clique_L1) decoder, especially beneficial at higher code distances.
When clustered errors and longer error chains are more likely to occur,
Clique_L2 achieves up to 18.3x decoding bandwidth reduction over Clique_L1,
achieving substantial benefits across a wide range of physical qubit error
rates.

</details>


### [435] [Sharp Error-Rate Transitions in Quantum QC-LDPC Codes under Joint BP Decoding](https://arxiv.org/abs/2507.11534)
*Daiki Komoto,Kenta Kasai*

Main category: quant-ph

TL;DR: 量子拟循环低密度奇偶校验码通过联合信念传播（BP）解码表现出陡峭的错误率曲线，证明了阈值行为，尽管存在错误层。错误层源于捕获集，可通过识别和避免这些结构来减少。


<details>
  <summary>Details</summary>
Motivation: 研究量子拟循环低密度奇偶校验码的性能，特别是它们在存在错误层时的行为，并探索导致错误层的根本原因。

Method: 量子拟循环低密度奇偶校验码通过联合信念传播（BP）解码。

Result: 量子拟循环低密度奇偶校验码通过联合信念传播（BP）解码表现出陡峭的错误率曲线，这是具有非消失编码率且不使用非二进制BP解码器的量子码的首次此类阈值行为观察。此外，导致错误层的主要错误事件通常只涉及少量比特，这表明错误层是由捕获集引起的。

Conclusion: 量子拟循环低密度奇偶校验码通过联合信念传播（BP）解码表现出陡峭的错误率曲线，尽管存在错误层。这表明错误层是由捕获集引起的，识别和避免这些结构可能会进一步降低错误层。

Abstract: In this study, we report that quantum quasi-cyclic low-density parity-check
codes decoded via joint belief propagation (BP) exhibit steep error-rate
curves, despite the presence of error floors. To the best of our knowledge,
this is the first observation of such threshold-like behavior for quantum codes
with non-vanishing coding rate, excluding those decoded with non-binary BP
decoders. Moreover, we find that dominant error events contributing to the
error floor typically involve only a small number of bits. These findings
suggest that the error floor is caused by trapping sets -- specific subgraph
structures in the Tanner graph -- and indicate that identifying and avoiding
such structures may lead to further reduction of the error floor.

</details>


### [436] [Understanding Quantum Information and Computation](https://arxiv.org/abs/2507.11536)
*John Watrous*

Main category: quant-ph

TL;DR: 一门关于量子计算理论的课程，内容涵盖量子信息、量子算法、量子信息通用公式和量子纠错，共16课时。


<details>
  <summary>Details</summary>
Motivation: 本课程旨在教授量子计算的理论基础。

Method: 该课程包含16个课时，每个课时都配有视频和书面材料。

Result: 课程内容全面，涵盖了量子计算的各个主要方面，从基础理论到高级概念。

Conclusion: 该课程涵盖了量子信息、量子算法（包括查询算法、Shor算法和Grover算法）、量子信息通用公式（包括密度矩阵、量子通道和通用测量）以及量子纠错（包括基础、稳定器形式、CSS码、环形码和容错量子计算）的基础知识。

Abstract: This is a course on the theory of quantum computing. It consists of 16
lessons, each with a video and written component, covering the basics of
quantum information, quantum algorithms (including query algorithms, Shor's
algorithm for integer factorization, and Grover's algorithm), the general
formulation of quantum information (including density matrices, quantum
channels, and general measurements), and quantum error correction (including
the basics, the stabilizer formalism, CSS codes, the toric code, and
fault-tolerant quantum computation).

</details>


### [437] [Koopman-von Neumann Field Theory](https://arxiv.org/abs/2507.11541)
*James Stokes*

Main category: quant-ph

TL;DR: The classical many-body problem is reformulated as a bosonic quantum field theory, enabling the transfer of quantum techniques to classical statistical mechanics and impacting quantum algorithms.


<details>
  <summary>Details</summary>
Motivation: Reformulating the classical many-body problem as a bosonic quantum field theory.

Method: The classical many-body problem is reformulated as a bosonic quantum field theory, and quantum field operators evolve unitarily in the Heisenberg picture to satisfy a quantum Vlasov equation as an operator identity.

Result: A quantum Vlasov equation is satisfied as an operator identity.

Conclusion: The formalism enables the direct transfer of techniques from quantum information and quantum many-body field theory to classical nonequilibrium statistical mechanics, with implications for quantum algorithms.

Abstract: The classical many-body problem is reformulated as a bosonic quantum field
theory. Quantum field operators evolve unitarily in the Heisenberg picture so
that a quantum Vlasov equation is satisfied as an operator identity. The
formalism enables the direct transfer of techniques from quantum information
and quantum many-body field theory to classical nonequilibrium statistical
mechanics. Implications for quantum algorithms are discussed.

</details>
