<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 89]
- [cs.CL](#cs.CL) [Total: 59]
- [quant-ph](#quant-ph) [Total: 29]
- [cond-mat.mes-hall](#cond-mat.mes-hall) [Total: 9]
- [cs.AI](#cs.AI) [Total: 17]
- [cs.MA](#cs.MA) [Total: 3]
- [cs.GR](#cs.GR) [Total: 1]
- [cs.DS](#cs.DS) [Total: 6]
- [cs.DC](#cs.DC) [Total: 7]
- [cs.GT](#cs.GT) [Total: 1]
- [cs.RO](#cs.RO) [Total: 23]
- [eess.SY](#eess.SY) [Total: 14]
- [cs.LO](#cs.LO) [Total: 2]
- [cs.LG](#cs.LG) [Total: 72]
- [cs.AR](#cs.AR) [Total: 5]
- [eess.SP](#eess.SP) [Total: 17]
- [cs.NE](#cs.NE) [Total: 2]
- [cond-mat.mtrl-sci](#cond-mat.mtrl-sci) [Total: 12]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [Hyperspectral Sensors and Autonomous Driving: Technologies, Limitations, and Opportunities](https://arxiv.org/abs/2508.19905)
*Imad Ali Shah,Jiarong Li,Roshan George,Tim Brophy,Enda Ward,Martin Glavin,Edward Jones,Brian Deegan*

Main category: cs.CV

TL;DR: 高光谱成像(HSI)在汽车应用方面潜力巨大，但目前商业化准备不足，现有技术和数据集在汽车特定要求方面存在差距。


<details>
  <summary>Details</summary>
Motivation: 评估高光谱成像(HSI)技术在汽车高级驾驶辅助系统(ADAS)和自动驾驶(AD)应用中的优势、局限性及适用性，并为其实际集成提供研究方向。

Method: 对216种商用高光谱和多光谱成像相机进行基准测试，评估其帧率、空间分辨率、光谱维度和AEC-Q100温度标准符合性。同时，对高光谱成像在道路表面分类、行人可分性和恶劣天气感知等方面的最新数据集和应用进行回顾。

Result: 目前仅有4款相机达到性能阈值，且无一款符合AEC-Q100要求。现有高光谱成像数据集在规模、光谱一致性、通道数量和环境多样性方面存在不足，给感知算法开发和高光谱成像在ADAS/AD应用中的真正潜力验证带来了挑战。

Conclusion: 高光谱成像在汽车领域的应用仍处于初步阶段，商业化准备不足，数据集和技术均需改进，才能满足ADAS/AD的严苛要求。未来的研究应着重于克服这些差距，以实现高光谱成像在自动驾驶系统中的实际集成。

Abstract: Hyperspectral imaging (HSI) offers a transformative sensing modality for
Advanced Driver Assistance Systems (ADAS) and autonomous driving (AD)
applications, enabling material-level scene understanding through fine spectral
resolution beyond the capabilities of traditional RGB imaging. This paper
presents the first comprehensive review of HSI for automotive applications,
examining the strengths, limitations, and suitability of current HSI
technologies in the context of ADAS/AD. In addition to this qualitative review,
we analyze 216 commercially available HSI and multispectral imaging cameras,
benchmarking them against key automotive criteria: frame rate, spatial
resolution, spectral dimensionality, and compliance with AEC-Q100 temperature
standards. Our analysis reveals a significant gap between HSI's demonstrated
research potential and its commercial readiness. Only four cameras meet the
defined performance thresholds, and none comply with AEC-Q100 requirements. In
addition, the paper reviews recent HSI datasets and applications, including
semantic segmentation for road surface classification, pedestrian separability,
and adverse weather perception. Our review shows that current HSI datasets are
limited in terms of scale, spectral consistency, the number of spectral
channels, and environmental diversity, posing challenges for the development of
perception algorithms and the adequate validation of HSI's true potential in
ADAS/AD applications. This review paper establishes the current state of HSI in
automotive contexts as of 2025 and outlines key research directions toward
practical integration of spectral imaging in ADAS and autonomous systems.

</details>


### [2] [Real-Time Intuitive AI Drawing System for Collaboration: Enhancing Human Creativity through Formal and Contextual Intent Integration](https://arxiv.org/abs/2508.19254)
*Jookyung Song,Mookyoung Kang,Nojun Kwak*

Main category: cs.CV

TL;DR: 本文提出了一种实时生成式绘图系统，该系统将形式意图（草图的结构、构图和风格属性）和情境意图（从其视觉内容中推断出的语义和主题含义）整合到统一的变换过程中。与主要捕获高级情境描述的传统文本提示式生成系统不同，我们的方法同时分析了地面直观几何特征（如线条轨迹、比例和空间排列）和通过视觉语言模型提取的高级语义线索。这两种意图信号在多阶段生成流程中被联合调节，该流程结合了保护轮廓的结构控制与感知风格和内容的图像合成。


<details>
  <summary>Details</summary>
Motivation: 传统的文本提示式生成系统主要侧重于高层级描述，而忽略了草图的底层几何特征。本研究旨在提出一种能同时理解并融合形式意图（结构、构图、风格）和情境意图（语义、主题）的生成式绘图系统，以实现更直观、更丰富的视觉创作。

Method: 该系统通过分析草图的几何特征（如线条轨迹、比例、空间排列）和语义线索（通过视觉语言模型提取），并将这两种意图信号联合应用于一个多阶段生成流程。该流程结合了保持轮廓的结构控制和感知风格与内容的图像合成。系统采用触摸屏界面和分布式推理架构，实现了低延迟的两阶段变换，并支持多用户协同创作。

Result: 该系统实现了低延迟、两阶段的变换，能够同时处理形式和情境意图，支持多用户在共享画布上进行协同创作，使得不同艺术背景的用户都能参与到同步的、共同创作的视觉活动中。

Conclusion: 该平台实现了人与人工智能之间的共创和相互促进的交互模式，为不同技能水平的用户提供了一个进行同步视觉创作的平台，这重新定义了人机交互的方式。

Abstract: This paper presents a real-time generative drawing system that interprets and
integrates both formal intent - the structural, compositional, and stylistic
attributes of a sketch - and contextual intent - the semantic and thematic
meaning inferred from its visual content - into a unified transformation
process. Unlike conventional text-prompt-based generative systems, which
primarily capture high-level contextual descriptions, our approach
simultaneously analyzes ground-level intuitive geometric features such as line
trajectories, proportions, and spatial arrangement, and high-level semantic
cues extracted via vision-language models. These dual intent signals are
jointly conditioned in a multi-stage generation pipeline that combines
contour-preserving structural control with style- and content-aware image
synthesis. Implemented with a touchscreen-based interface and distributed
inference architecture, the system achieves low-latency, two-stage
transformation while supporting multi-user collaboration on shared canvases.
The resulting platform enables participants, regardless of artistic expertise,
to engage in synchronous, co-authored visual creation, redefining human-AI
interaction as a process of co-creation and mutual enhancement.

</details>


### [3] [TTF-VLA: Temporal Token Fusion via Pixel-Attention Integration for Vision-Language-Action Models](https://arxiv.org/abs/2508.19257)
*Chenghao Liu,Jiachen Zhang,Chengxuan Li,Zhimu Zhou,Shixin Wu,Songfang Huang,Huiling Duan*

Main category: cs.CV

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Vision-Language-Action (VLA) models process visual inputs independently at
each timestep, discarding valuable temporal information inherent in robotic
manipulation tasks. This frame-by-frame processing makes models vulnerable to
visual noise while ignoring the substantial coherence between consecutive
frames in manipulation sequences. We propose Temporal Token Fusion (TTF), a
training-free approach that intelligently integrates historical and current
visual representations to enhance VLA inference quality. Our method employs
dual-dimension detection combining efficient grayscale pixel difference
analysis with attention-based semantic relevance assessment, enabling selective
temporal token fusion through hard fusion strategies and keyframe anchoring to
prevent error accumulation. Comprehensive experiments across LIBERO,
SimplerEnv, and real robot tasks demonstrate consistent improvements: 4.0
percentage points average on LIBERO (72.4\% vs 68.4\% baseline),
cross-environment validation on SimplerEnv (4.8\% relative improvement), and
8.7\% relative improvement on real robot tasks. Our approach proves
model-agnostic, working across OpenVLA and VLA-Cache architectures. Notably,
TTF reveals that selective Query matrix reuse in attention mechanisms enhances
rather than compromises performance, suggesting promising directions for direct
KQV matrix reuse strategies that achieve computational acceleration while
improving task success rates.

</details>


### [4] [Seam360GS: Seamless 360° Gaussian Splatting from Real-World Omnidirectional Images](https://arxiv.org/abs/2508.20080)
*Changha Shin,Woong Oh Cho,Seon Joo Kim*

Main category: cs.CV

TL;DR: 本研究提出了一种结合双鱼眼相机模型和3D高斯泼溅管线的校准框架，用于生成无缝的全景图像。


<details>
  <summary>Details</summary>
Motivation: 解决消费级双鱼眼系统因镜头分离和角度畸变导致的全景图像不完美问题。

Method: 将双鱼眼相机模型整合到3D高斯泼溅管线中，联合优化3D高斯参数和模拟镜头间隙及角度畸变的校准变量，以处理不完美的输入图像。

Result: 该方法能够模拟双鱼眼相机的视觉伪影，并生成无缝的全景图像，在真实数据集上的评估表明，该方法在不完美的图像上也能生成无缝渲染，并且优于现有的360度渲染模型。

Conclusion: 该框架能够将不完美的鱼眼输入转化为无瑕的新视角合成。

Abstract: 360-degree visual content is widely shared on platforms such as YouTube and
plays a central role in virtual reality, robotics, and autonomous navigation.
However, consumer-grade dual-fisheye systems consistently yield imperfect
panoramas due to inherent lens separation and angular distortions. In this
work, we introduce a novel calibration framework that incorporates a
dual-fisheye camera model into the 3D Gaussian splatting pipeline. Our approach
not only simulates the realistic visual artifacts produced by dual-fisheye
cameras but also enables the synthesis of seamlessly rendered 360-degree
images. By jointly optimizing 3D Gaussian parameters alongside calibration
variables that emulate lens gaps and angular distortions, our framework
transforms imperfect omnidirectional inputs into flawless novel view synthesis.
Extensive evaluations on real-world datasets confirm that our method produces
seamless renderings-even from imperfect images-and outperforms existing
360-degree rendering models.

</details>


### [5] [Seeing Like a Designer Without One: A Study on Unsupervised Slide Quality Assessment via Designer Cue Augmentation](https://arxiv.org/abs/2508.19289)
*Tai Inui,Steven Oh,Magdeline Kuan*

Main category: cs.CV

TL;DR: 该研究提出了一种无监督的幻灯片质量评估流水线，结合了视觉设计指标和CLIP-ViT嵌入，使用Isolation Forest进行异常评分，以评估演示幻灯片。


<details>
  <summary>Details</summary>
Motivation: 为了提供可扩展、客观的实时反馈，本研究旨在开发一种能够近似观众对幻灯片质量感知的评估方法。

Method: 本研究结合了七个专家启发的视觉设计指标（包括但不限于空白、色彩、边缘密度、亮度和对比度、文本密度、色彩协调性和布局平衡）与CLIP-ViT嵌入。该方法使用基于Isolation Forest的异常评分来评估演示幻灯片。

Result: 该方法在12,000个专业讲座幻灯片上进行训练，并在六个学术演讲（115张幻灯片）上进行了评估，在与人类视觉质量评分的相关性方面达到了0.83，比领先的视觉语言模型（如ChatGPT o4-mini-high、ChatGPT o3、Claude Sonnet 4和Gemini 2.5 Pro）的分数强1.79到3.23倍。该方法还与视觉评分进行了趋同效度验证，与演讲者交付分数进行了区分效度验证，并初步显示与整体印象一致。

Conclusion: 研究结果表明，通过将低级设计线索与多模态嵌入相结合，可以有效地近似观众对幻灯片质量的感知，从而实现可扩展、客观的实时反馈。

Abstract: We present an unsupervised slide-quality assessment pipeline that combines
seven expert-inspired visual-design metrics (whitespace, colorfulness, edge
density, brightness contrast, text density, color harmony, layout balance) with
CLIP-ViT embeddings, using Isolation Forest-based anomaly scoring to evaluate
presentation slides. Trained on 12k professional lecture slides and evaluated
on six academic talks (115 slides), our method achieved Pearson correlations up
to 0.83 with human visual-quality ratings-1.79x to 3.23x stronger than scores
from leading vision-language models (ChatGPT o4-mini-high, ChatGPT o3, Claude
Sonnet 4, Gemini 2.5 Pro). We demonstrate convergent validity with visual
ratings, discriminant validity against speaker-delivery scores, and exploratory
alignment with overall impressions. Our results show that augmenting low-level
design cues with multimodal embeddings closely approximates audience
perceptions of slide quality, enabling scalable, objective feedback in real
time.

</details>


### [6] [Efficient Model-Based Purification Against Adversarial Attacks for LiDAR Segmentation](https://arxiv.org/abs/2508.19290)
*Alexandros Gkillas,Ioulia Kapsali,Nikos Piperigkos,Aris S. Lalos*

Main category: cs.CV

TL;DR: Despite the importance of LiDAR-based segmentation for autonomous vehicles, current networks are vulnerable to adversarial attacks. Existing defenses often use computationally intensive models for raw 3D point clouds. This paper introduces an efficient, model-based purification framework for 2D range-view LiDAR segmentation, addressing a gap in lightweight defenses for this domain. The authors propose a direct attack in the range-view domain and an explainable purification network based on an optimized mathematical problem. Their method offers strong adversarial resilience with low computational cost, outperforming existing baselines and demonstrating practical effectiveness in real-world autonomous driving scenarios.


<details>
  <summary>Details</summary>
Motivation: Modern LiDAR segmentation networks are highly susceptible to adversarial attacks, posing a safety risk for autonomous vehicles. While defenses exist for raw 3D point clouds, there's a need for lightweight defenses specifically for the widely adopted 2D range-view representations used in efficient LiDAR segmentation pipelines.

Method: The paper introduces an efficient model-based purification framework for 2D range-view LiDAR segmentation. It includes a direct attack formulation in the range-view domain and an explainable purification network derived from a mathematically justified optimization problem.

Result: The proposed method achieves strong adversarial resilience with minimal computational overhead. It demonstrates competitive performance on open benchmarks, outperforming generative and adversarial training baselines. Real-world deployment on a demo vehicle confirmed its ability to maintain accurate operation in practical autonomous driving scenarios.

Conclusion: The developed purification framework offers an efficient and effective defense against adversarial attacks for 2D range-view LiDAR segmentation, a crucial component for safe autonomous driving. Its lightweight nature and strong performance make it a promising solution for practical deployment.

Abstract: LiDAR-based segmentation is essential for reliable perception in autonomous
vehicles, yet modern segmentation networks are highly susceptible to
adversarial attacks that can compromise safety. Most existing defenses are
designed for networks operating directly on raw 3D point clouds and rely on
large, computationally intensive generative models. However, many
state-of-the-art LiDAR segmentation pipelines operate on more efficient 2D
range view representations. Despite their widespread adoption, dedicated
lightweight adversarial defenses for this domain remain largely unexplored. We
introduce an efficient model-based purification framework tailored for
adversarial defense in 2D range-view LiDAR segmentation. We propose a direct
attack formulation in the range-view domain and develop an explainable
purification network based on a mathematical justified optimization problem,
achieving strong adversarial resilience with minimal computational overhead.
Our method achieves competitive performance on open benchmarks, consistently
outperforming generative and adversarial training baselines. More importantly,
real-world deployment on a demo vehicle demonstrates the framework's ability to
deliver accurate operation in practical autonomous driving scenarios.

</details>


### [7] [Object Detection with Multimodal Large Vision-Language Models: An In-depth Review](https://arxiv.org/abs/2508.19294)
*Ranjan Sapkota,Manoj Karkee*

Main category: cs.CV

TL;DR: 大型视觉语言模型（LVLM）通过融合语言和视觉能力，正在革新基于深度学习的目标检测技术，提高了模型的适应性、上下文推理和泛化能力。本综述系统地探讨了LVLM的最新进展，首先介绍了视觉语言模型（VLM）在目标检测中的工作原理，接着阐述了近期LVLM在目标检测方面的架构创新、训练范式和输出灵活性，重点说明了它们如何实现先进的上下文理解。该综述深入分析了视觉和文本信息整合的方法，展示了使用VLM进行目标检测的进展，并提供了全面的可视化结果，比较了LVLM与传统深度学习系统在实时性能、适应性和复杂性方面的表现。研究预测LVLM将很快达到或超过传统目标检测方法的性能，并指出了当前LVLM的局限性、提出了解决方案和未来发展路线图。最终认为，LVLM的最新进展已对目标检测和机器人应用产生了革命性影响，并将继续产生深远影响。


<details>
  <summary>Details</summary>
Motivation: 本综述旨在系统性地探讨和总结大型视觉语言模型（LVLM）在目标检测领域的最新进展，阐述其工作原理、架构创新、训练范式及优势，并与传统深度学习方法进行比较，同时指出其局限性并展望未来发展方向。

Method: 本综述通过三步研究评审过程进行组织：首先，讨论视觉语言模型（VLM）在目标检测中的功能，解释它们如何利用自然语言处理（NLP）和计算机视觉（CV）技术革新目标检测和定位；其次，解释近期LVLM在目标检测方面的架构创新、训练范式和输出灵活性，强调它们如何实现先进的上下文理解；最后，通过全面的可视化展示LVLM在包括定位和分割在内的各种场景中的有效性，并将其实时性能、适应性和复杂性与传统深度学习系统进行比较。

Result: LVLM在目标检测和分割方面表现出有效性，其在实时性能、适应性和复杂性方面与传统深度学习系统进行了比较，并预期其性能将很快 meet or surpass 传统方法。研究还识别了当前LVLM的局限性，并提出了解决方案和未来发展路线图。

Conclusion: 本研究基于对LVLM的全面回顾，得出结论认为，LVLM的最新进展已对目标检测和机器人应用产生了革命性影响，并将继续产生深远影响。LVLM有望在不久的将来达到或超过传统目标检测方法的性能。

Abstract: The fusion of language and vision in large vision-language models (LVLMs) has
revolutionized deep learning-based object detection by enhancing adaptability,
contextual reasoning, and generalization beyond traditional architectures. This
in-depth review presents a structured exploration of the state-of-the-art in
LVLMs, systematically organized through a three-step research review process.
First, we discuss the functioning of vision language models (VLMs) for object
detection, describing how these models harness natural language processing
(NLP) and computer vision (CV) techniques to revolutionize object detection and
localization. We then explain the architectural innovations, training
paradigms, and output flexibility of recent LVLMs for object detection,
highlighting how they achieve advanced contextual understanding for object
detection. The review thoroughly examines the approaches used in integration of
visual and textual information, demonstrating the progress made in object
detection using VLMs that facilitate more sophisticated object detection and
localization strategies. This review presents comprehensive visualizations
demonstrating LVLMs' effectiveness in diverse scenarios including localization
and segmentation, and then compares their real-time performance, adaptability,
and complexity to traditional deep learning systems. Based on the review, its
is expected that LVLMs will soon meet or surpass the performance of
conventional methods in object detection. The review also identifies a few
major limitations of the current LVLM modes, proposes solutions to address
those challenges, and presents a clear roadmap for the future advancement in
this field. We conclude, based on this study, that the recent advancement in
LVLMs have made and will continue to make a transformative impact on object
detection and robotic applications in the future.

</details>


### [8] [Context-aware Sparse Spatiotemporal Learning for Event-based Vision](https://arxiv.org/abs/2508.19806)
*Shenqi Wang,Guangzhi Tang*

Main category: cs.CV

TL;DR: event-based cameras offer advantages but existing deep learning methods struggle with sparse data on resource-constrained devices. Neuromorphic computing with spiking neural networks is energy-efficient but lacks performance. This paper proposes CSSL, a framework using context-aware thresholding to dynamically reduce neuron activations, achieving high sparsity and comparable/superior performance in object detection and optical flow estimation, enabling efficient event-based vision for neuromorphic processing.


<details>
  <summary>Details</summary>
Motivation: Existing deep learning-based event processing methods do not fully utilize the sparse nature of event data, making integration into resource-constrained edge applications difficult. Spiking neural networks, while energy-efficient, underperform in complex event-based vision tasks, and achieving high activation sparsity in neural networks is challenging.

Method: The paper proposes Context-aware Sparse Spatiotemporal Learning (CSSL), a novel framework that introduces context-aware thresholding to dynamically regulate neuron activations based on the input distribution, naturally reducing activation density without explicit sparsity constraints.

Result: CSSL achieves comparable or superior performance to state-of-the-art methods in event-based object detection and optical flow estimation while maintaining extremely high neuronal sparsity. Experimental results demonstrate CSSL's effectiveness in enabling efficient event-based vision for neuromorphic processing.

Conclusion: CSSL is a novel framework that effectively addresses the challenges of processing sparse event data for robot perception, enabling efficient and high-performing event-based vision on resource-constrained devices through context-aware thresholding and high neuronal sparsity.

Abstract: Event-based camera has emerged as a promising paradigm for robot perception,
offering advantages with high temporal resolution, high dynamic range, and
robustness to motion blur. However, existing deep learning-based event
processing methods often fail to fully leverage the sparse nature of event
data, complicating their integration into resource-constrained edge
applications. While neuromorphic computing provides an energy-efficient
alternative, spiking neural networks struggle to match of performance of
state-of-the-art models in complex event-based vision tasks, like object
detection and optical flow. Moreover, achieving high activation sparsity in
neural networks is still difficult and often demands careful manual tuning of
sparsity-inducing loss terms. Here, we propose Context-aware Sparse
Spatiotemporal Learning (CSSL), a novel framework that introduces context-aware
thresholding to dynamically regulate neuron activations based on the input
distribution, naturally reducing activation density without explicit sparsity
constraints. Applied to event-based object detection and optical flow
estimation, CSSL achieves comparable or superior performance to
state-of-the-art methods while maintaining extremely high neuronal sparsity.
Our experimental results highlight CSSL's crucial role in enabling efficient
event-based vision for neuromorphic processing.

</details>


### [9] [Large VLM-based Stylized Sports Captioning](https://arxiv.org/abs/2508.19295)
*Sauptik Dhar,Nicholas Buoncristiani,Joe Anakata,Haoyu Zhang,Michelle Munson*

Main category: cs.CV

TL;DR: 现有的视觉语言模型(LVLM)在体育领域，特别是游戏画面描述方面存在不足。本研究提出了一种两阶段微调的LVLM管道，以解决这个问题，并在体育图片描述方面取得了显著的性能提升。


<details>
  <summary>Details</summary>
Motivation: 尽管大型视觉语言模型（LVLM）在许多领域取得了成功，但在体育领域，尤其是在准确识别和自然语言描述比赛画面方面，却很少受到关注。现有的LVLM能够解释通用的体育活动，但缺乏足够的领域特定术语来生成自然（类人）的描述。这项工作强调了现有顶级LVLM在生成符合要求的、风格化的体育图片说明方面的局限性。

Method: 提出了一种两阶段微调的LVLM管道来解决现有LVLM在生成体育图片说明方面的局限性。

Result: 所提出的管道在F1分数上提高了>8-10%，在BERT分数上提高了>2-10%。此外，该管道具有较小的运行时内存占用和较快的执行时间。在超级碗LIX期间，该管道在直播专业体育新闻报道中证明了其实用性，在比赛过程中，以每3-5秒6张图片的速率生成了超过1000张高度准确且风格化的图片说明。

Conclusion: 这项工作通过提出一种两阶段微调的LVLM管道，成功解决了现有LVLM在体育图片描述方面的局限性，并在准确性和风格化方面取得了显著改进，证明了其在专业体育新闻报道中的实际应用价值。

Abstract: The advent of large (visual) language models (LLM / LVLM) have led to a
deluge of automated human-like systems in several domains including social
media content generation, search and recommendation, healthcare prognosis, AI
assistants for cognitive tasks etc. Although these systems have been
successfully integrated in production; very little focus has been placed on
sports, particularly accurate identification and natural language description
of the game play. Most existing LLM/LVLMs can explain generic sports
activities, but lack sufficient domain-centric sports' jargon to create natural
(human-like) descriptions. This work highlights the limitations of existing
SoTA LLM/LVLMs for generating production-grade sports captions from images in a
desired stylized format, and proposes a two-level fine-tuned LVLM pipeline to
address that. The proposed pipeline yields an improvement > 8-10% in the F1,
and > 2-10% in BERT score compared to alternative approaches. In addition, it
has a small runtime memory footprint and fast execution time. During Super Bowl
LIX the pipeline proved its practical application for live professional sports
journalism; generating highly accurate and stylized captions at the rate of 6
images per 3-5 seconds for over 1000 images during the game play.

</details>


### [10] [DemoBias: An Empirical Study to Trace Demographic Biases in Vision Foundation Models](https://arxiv.org/abs/2508.19298)
*Abu Sufian,Anirudha Ghosh,Debaditya Barman,Marco Leo,Cosimo Distante*

Main category: cs.CV

TL;DR: 该研究调查了大型视觉语言模型（LVLM）在人脸识别（FR）任务中存在的性别、种族和年龄等人口统计学偏见。研究人员评估了LLaVA、BLIP-2和PaliGemma这三个模型，并在一个平衡的人口统计学数据集上进行了微调和评估。结果显示，PaliGemma和LLaVA在西班牙裔/拉丁裔、高加索人和南亚人群体中表现出较高的偏见差异，而BLIP-2则表现出相对一致的性能。


<details>
  <summary>Details</summary>
Motivation: 人脸识别（FR）中的人口统计学偏见是一个关键问题，因为基础模型在不同的人口统计学群体（如种族/民族、性别和年龄）中可能无法公平地执行任务。本研究旨在通过实证评估来调查LVLM在生成文本描述的人脸识别任务中的人口统计学偏见程度。

Method: 研究人员对三个广泛使用的预训练LVLM（LLaVA、BLIP-2和PaliGemma）进行了微调，并在一个自定义生成的人口统计学平衡数据集上进行了评估。他们使用了多种评估指标，如特定群体的BERTScores和公平性差异率（Fairness Discrepancy Rate），来量化和追踪性能差异。

Result: 实验结果揭示了LVLM在不同人口统计学群体中的公平性和可靠性。具体而言，PaliGemma和LLaVA在西班牙裔/拉丁裔、高加索人和南亚人群体中表现出较高的人口统计学偏见差异，而BLIP-2在不同群体中表现出相对一致的性能。

Conclusion: 该实证研究揭示了LVLM中存在的人口统计学偏见，并强调了对这些模型进行公平性评估的重要性。研究结果为理解和解决LVLM在人脸识别等关键应用中的偏见问题提供了有价值的见解。

Abstract: Large Vision Language Models (LVLMs) have demonstrated remarkable
capabilities across various downstream tasks, including biometric face
recognition (FR) with description. However, demographic biases remain a
critical concern in FR, as these foundation models often fail to perform
equitably across diverse demographic groups, considering ethnicity/race,
gender, and age. Therefore, through our work DemoBias, we conduct an empirical
evaluation to investigate the extent of demographic biases in LVLMs for
biometric FR with textual token generation tasks. We fine-tuned and evaluated
three widely used pre-trained LVLMs: LLaVA, BLIP-2, and PaliGemma on our own
generated demographic-balanced dataset. We utilize several evaluation metrics,
like group-specific BERTScores and the Fairness Discrepancy Rate, to quantify
and trace the performance disparities. The experimental results deliver
compelling insights into the fairness and reliability of LVLMs across diverse
demographic groups. Our empirical study uncovered demographic biases in LVLMs,
with PaliGemma and LLaVA exhibiting higher disparities for Hispanic/Latino,
Caucasian, and South Asian groups, whereas BLIP-2 demonstrated comparably
consistent. Repository: https://github.com/Sufianlab/DemoBias.

</details>


### [11] [Geo2Vec: Shape- and Distance-Aware Neural Representation of Geospatial Entities](https://arxiv.org/abs/2508.19305)
*Chen Chu,Cyrus Shahabi*

Main category: cs.CV

TL;DR: Geo2Vec是一种新的空间表示学习方法，它使用符号距离场（SDF）直接在原始空间中操作，通过自适应采样和编码距离来捕捉几何形状，而无需分解。它能够为所有地理实体类型生成统一的、几何感知的表示，并且优于现有方法，在GeoAI应用中具有更高的效率。


<details>
  <summary>Details</summary>
Motivation: 现有的空间表示学习方法在处理不同类型的地理实体或分解实体以进行傅里叶变换时，存在计算成本高、缺乏几何对齐、依赖统一采样导致模糊细粒度特征等问题。需要一种能够直接在原始空间中操作，自适应采样并捕捉几何信息，且能够统一表示所有地理实体类型的方法。

Method: Geo2Vec受到符号距离场（SDF）的启发，直接在原始空间中操作。它通过自适应采样点并编码其符号距离（正面表示实体外部，负面表示实体内部）来捕捉几何信息，而无需对地理实体进行分解。一个用于近似SDF的神经网络生成了紧凑、几何感知且统一的表示。此外，还提出了一种旋转不变的位置编码来处理高频空间变化。

Result: Geo2Vec在表示形状和位置、捕捉拓扑和距离关系方面，一致优于现有方法，并且在真实的GeoAI应用中实现了更高的效率。

Conclusion: Geo2Vec通过直接在原始空间中操作并利用符号距离场，成功克服了现有方法的局限性，为各种地理实体提供了统一、几何感知的表示，并在GeoAI任务中展现出优越的性能和效率。

Abstract: Spatial representation learning is essential for GeoAI applications such as
urban analytics, enabling the encoding of shapes, locations, and spatial
relationships (topological and distance-based) of geo-entities like points,
polylines, and polygons. Existing methods either target a single geo-entity
type or, like Poly2Vec, decompose entities into simpler components to enable
Fourier transformation, introducing high computational cost. Moreover, since
the transformed space lacks geometric alignment, these methods rely on uniform,
non-adaptive sampling, which blurs fine-grained features like edges and
boundaries. To address these limitations, we introduce Geo2Vec, a novel method
inspired by signed distance fields (SDF) that operates directly in the original
space. Geo2Vec adaptively samples points and encodes their signed distances
(positive outside, negative inside), capturing geometry without decomposition.
A neural network trained to approximate the SDF produces compact,
geometry-aware, and unified representations for all geo-entity types.
Additionally, we propose a rotation-invariant positional encoding to model
high-frequency spatial variations and construct a structured and robust
embedding space for downstream GeoAI models. Empirical results show that
Geo2Vec consistently outperforms existing methods in representing shape and
location, capturing topological and distance relationships, and achieving
greater efficiency in real-world GeoAI applications. Code and Data can be found
at: https://github.com/chuchen2017/GeoNeuralRepresentation.

</details>


### [12] [Advancements in Crop Analysis through Deep Learning and Explainable AI](https://arxiv.org/abs/2508.19307)
*Hamza Khan*

Main category: cs.CV

TL;DR: 该研究提出了一种利用卷积神经网络（CNN）自动分类五种大米品种的方法，并开发了一种结合可解释人工智能（XAI）和深度学习模型（CNN、VGG16、ResNet50、MobileNetV2）的大米叶片病害（褐斑病、稻瘟病、细菌性条斑病和黄萎病）诊断方法。


<details>
  <summary>Details</summary>
Motivation: 为了确保消费者满意度和国家声誉，监测水稻产量和谷物质量至关重要。手动检查劳动密集、耗时且容易出错，因此需要自动化的解决方案来进行质量控制和产量改进。此外，还需要一种准确的诊断方法来诊断水稻叶片病害。

Method: 该研究提出了一个自动化方法，利用卷积神经网络（CNN）对五种水稻谷物进行分类，并使用了包含75,000张图像的公开数据集进行训练和测试。模型评估采用了准确率、召回率、精确率、F1分数、ROC曲线和混淆矩阵。此外，研究人员开发了一个框架，将可解释人工智能（XAI）与深度学习模型（CNN、VGG16、ResNet50和MobileNetV2）相结合，以诊断水稻叶片病害，并使用了SHAP和LIME等可解释性技术。

Result: 该模型在区分水稻品种方面表现出很高的分类准确率和很少的错误分类。所开发的框架能够准确诊断水稻叶片病害，并且通过SHAP和LIME等技术，研究人员能够了解特定的谷物和叶片特征如何影响预测，从而提高了模型的可解释性和可靠性。

Conclusion: 研究结果表明，深度学习在农业应用中具有巨大潜力，能够为自动化作物质量检测和病害诊断提供强大、可解释的系统，最终使农民、消费者和农业经济受益。

Abstract: Rice is a staple food of global importance in terms of trade, nutrition, and
economic growth. Among Asian nations such as China, India, Pakistan, Thailand,
Vietnam and Indonesia are leading producers of both long and short grain
varieties, including basmati, jasmine, arborio, ipsala, and kainat saila. To
ensure consumer satisfaction and strengthen national reputations, monitoring
rice crops and grain quality is essential. Manual inspection, however, is
labour intensive, time consuming and error prone, highlighting the need for
automated solutions for quality control and yield improvement. This study
proposes an automated approach to classify five rice grain varieties using
Convolutional Neural Networks (CNN). A publicly available dataset of 75000
images was used for training and testing. Model evaluation employed accuracy,
recall, precision, F1-score, ROC curves, and confusion matrices. Results
demonstrated high classification accuracy with minimal misclassifications,
confirming the model effectiveness in distinguishing rice varieties. In
addition, an accurate diagnostic method for rice leaf diseases such as Brown
Spot, Blast, Bacterial Blight, and Tungro was developed. The framework combined
explainable artificial intelligence (XAI) with deep learning models including
CNN, VGG16, ResNet50, and MobileNetV2. Explainability techniques such as SHAP
(SHapley Additive exPlanations) and LIME (Local Interpretable Model-agnostic
Explanations) revealed how specific grain and leaf features influenced
predictions, enhancing model transparency and reliability. The findings
demonstrate the strong potential of deep learning in agricultural applications,
paving the way for robust, interpretable systems that can support automated
crop quality inspection and disease diagnosis, ultimately benefiting farmers,
consumers, and the agricultural economy.

</details>


### [13] [Sistema de Reconocimiento Facial Federado en Conjuntos Abiertos basado en OpenMax](https://arxiv.org/abs/2508.19312)
*Ander Galván,Marivi Higuero,Jorge Sasiain,Eduardo Jacob*

Main category: cs.CV

TL;DR: 提出了一种将OpenMax算法集成到联邦学习框架中的方法，用于在开放场景下进行更具隐私意识和鲁棒性的面部识别，有效地区分已知和未知个体。


<details>
  <summary>Details</summary>
Motivation: 解决现有面部识别技术在处理未知个体和保护隐私方面存在的挑战，特别是在分布式环境中。

Method: 将OpenMax算法集成到联邦学习框架中，通过交换平均激活向量和局部距离度量来区分已知和未知受试者。

Result: 实验结果验证了所提出解决方案的有效性，证明了其在分布式环境中增强隐私感知和鲁棒性面部识别的潜力。

Conclusion: 所提出的联邦学习框架结合OpenMax算法能够有效应对开放场景下的隐私和身份管理挑战，实现更鲁棒的面部识别。

Abstract: Facial recognition powered by Artificial Intelligence has achieved high
accuracy in specific scenarios and applications. Nevertheless, it faces
significant challenges regarding privacy and identity management, particularly
when unknown individuals appear in the operational context. This paper presents
the design, implementation, and evaluation of a facial recognition system
within a federated learning framework tailored to open-set scenarios. The
proposed approach integrates the OpenMax algorithm into federated learning,
leveraging the exchange of mean activation vectors and local distance measures
to reliably distinguish between known and unknown subjects. Experimental
results validate the effectiveness of the proposed solution, demonstrating its
potential for enhancing privacy-aware and robust facial recognition in
distributed environments.
  --
  El reconocimiento facial impulsado por Inteligencia Artificial ha demostrado
una alta precisi\'on en algunos escenarios y aplicaciones. Sin embargo,
presenta desaf\'ios relacionados con la privacidad y la identificaci\'on de
personas, especialmente considerando que pueden aparecer sujetos desconocidos
para el sistema que lo implementa. En este trabajo, se propone el dise\~no,
implementaci\'on y evaluaci\'on de un sistema de reconocimiento facial en un
escenario de aprendizaje federado, orientado a conjuntos abiertos.
Concretamente, se dise\~na una soluci\'on basada en el algoritmo OpenMax para
escenarios de aprendizaje federado. La propuesta emplea el intercambio de los
vectores de activaci\'on promedio y distancias locales para identificar de
manera eficaz tanto personas conocidas como desconocidas. Los experimentos
realizados demuestran la implementaci\'on efectiva de la soluci\'on propuesta.

</details>


### [14] [Automated classification of natural habitats using ground-level imagery](https://arxiv.org/abs/2508.19314)
*Mahdis Tourian,Sareh Rowlands,Remy Vandaele,Max Fancourt,Rebecca Mein,Hywel T. P. Williams*

Main category: cs.CV

TL;DR: 本研究提出一种仅基于地面图像（照片）的栖息地分类方法，利用深度学习技术对18种“Living England”生境类别进行分类，并开发了一个简单的网络应用以供用户使用。


<details>
  <summary>Details</summary>
Motivation: 为了应对生物多样性保护、生态监测和土地利用规划等领域对精确陆地栖息地分类的需求，同时克服传统基于卫星图像分类方法在验证上的局限性，本研究旨在开发一种仅利用地面层级图像进行分类的方法，以提高验证精度并实现大规模分类。

Method: 本研究开发了一种基于深度学习的分类系统，使用ResNet101的DeepLabV3模型处理地面层级栖息地照片。图像经过预处理（调整大小、归一化、增强），并通过重采样来平衡训练数据中的类别。使用五折交叉验证评估模型在18个栖息地类别上的性能。

Result: 该模型在18个栖息地类别上表现出良好的整体性能，平均F1分数（F1-score）为0.61。视觉上易于区分的类别（如裸土、淤泥和泥炭（BSSP）、裸沙（BS））得分高于0.90，而混合或模糊的类别得分较低。

Conclusion: 基于地面层级图像的栖息地分类方法具有巨大的应用潜力，可用于生态监测，因为地面图像易于获取且计算方法准确。该研究为实践者提供了一个简单的网络应用，可以直接使用该模型进行图像分类。

Abstract: Accurate classification of terrestrial habitats is critical for biodiversity
conservation, ecological monitoring, and land-use planning. Several habitat
classification schemes are in use, typically based on analysis of satellite
imagery with validation by field ecologists. Here we present a methodology for
classification of habitats based solely on ground-level imagery (photographs),
offering improved validation and the ability to classify habitats at scale (for
example using citizen-science imagery). In collaboration with Natural England,
a public sector organisation responsible for nature conservation in England,
this study develops a classification system that applies deep learning to
ground-level habitat photographs, categorising each image into one of 18
classes defined by the 'Living England' framework. Images were pre-processed
using resizing, normalisation, and augmentation; re-sampling was used to
balance classes in the training data and enhance model robustness. We developed
and fine-tuned a DeepLabV3-ResNet101 classifier to assign a habitat class label
to each photograph. Using five-fold cross-validation, the model demonstrated
strong overall performance across 18 habitat classes, with accuracy and
F1-scores varying between classes. Across all folds, the model achieved a mean
F1-score of 0.61, with visually distinct habitats such as Bare Soil, Silt and
Peat (BSSP) and Bare Sand (BS) reaching values above 0.90, and mixed or
ambiguous classes scoring lower. These findings demonstrate the potential of
this approach for ecological monitoring. Ground-level imagery is readily
obtained, and accurate computational methods for habitat classification based
on such data have many potential applications. To support use by practitioners,
we also provide a simple web application that classifies uploaded images using
our model.

</details>


### [15] [MIDAS: Multimodal Interactive Digital-human Synthesis via Real-time Autoregressive Video Generation](https://arxiv.org/abs/2508.19320)
*Ming Chen,Liyuan Cui,Wenyuan Zhang,Haoxian Zhang,Yan Zhou,Xiaohan Li,Xiaoqiang Liu,Pengfei Wan*

Main category: cs.CV

TL;DR: 近期，交互式数字人视频生成取得显著进展，但现有方法常面临高延迟、高计算成本和有限可控性等挑战。本研究提出了一种自回归视频生成框架，支持交互式多模态控制和低延迟流式外推。该框架通过对标准大语言模型（LLM）进行少量修改，即可接受音频、姿态和文本等多种模态的条件编码，并输出与空间和语义一致的表示来指导扩散模型的去噪过程。为支持此，我们构建了一个包含约20,000小时的多源大规模对话数据集。此外，我们引入了一个高达64倍降比的深度压缩自编码器，有效减轻了自回归模型的长序列推理负担。实验证明，该方法在低延迟、高效率和细粒度多模态可控性方面具有优势。


<details>
  <summary>Details</summary>
Motivation: 现有交互式数字人视频生成方法在实时交互、低延迟、低计算成本和高可控性方面存在挑战。

Method: 提出一种自回归视频生成框架，该框架能接受音频、姿态和文本等多种模态的条件编码，并通过指导扩散模型的去噪过程来生成视频。引入深度压缩自编码器以降低模型推理负担。

Result: 在双向对话、多语种人合成和交互式世界模型方面进行了广泛实验，结果表明该方法在低延迟、高效率和细粒度多模态可控性方面表现出色。

Conclusion: 所提出的自回归视频生成框架能够有效解决现有方法面临的挑战，在交互式数字人视频生成领域具有显著优势。

Abstract: Recently, interactive digital human video generation has attracted widespread
attention and achieved remarkable progress. However, building such a practical
system that can interact with diverse input signals in real time remains
challenging to existing methods, which often struggle with high latency, heavy
computational cost, and limited controllability. In this work, we introduce an
autoregressive video generation framework that enables interactive multimodal
control and low-latency extrapolation in a streaming manner. With minimal
modifications to a standard large language model (LLM), our framework accepts
multimodal condition encodings including audio, pose, and text, and outputs
spatially and semantically coherent representations to guide the denoising
process of a diffusion head. To support this, we construct a large-scale
dialogue dataset of approximately 20,000 hours from multiple sources, providing
rich conversational scenarios for training. We further introduce a deep
compression autoencoder with up to 64$\times$ reduction ratio, which
effectively alleviates the long-horizon inference burden of the autoregressive
model. Extensive experiments on duplex conversation, multilingual human
synthesis, and interactive world model highlight the advantages of our approach
in low latency, high efficiency, and fine-grained multimodal controllability.

</details>


### [16] [Deep Data Hiding for ICAO-Compliant Face Images: A Survey](https://arxiv.org/abs/2508.19324)
*Jefferson David Rodriguez Chivata,Davide Ghiani,Simone Maurizio La Cava,Marco Micheletto,Giulia Orrù,Federico Lama,Gian Luca Marcialis*

Main category: cs.CV

TL;DR: ICAO面部图像面临照片攻击风险，可利用数字水印和隐写术进行保护。


<details>
  <summary>Details</summary>
Motivation: ICAO面部图像在身份验证中被广泛使用，但易受照片攻击（如变形和深度伪造），传统方法无法提供后验保护。

Method: 研究数字水印和隐写术作为集成到图像中的防篡改信号，以实现持续验证，同时保持ICAO合规性。

Result: 对现有技术进行了全面分析，评估了其在ICAO图像应用中的潜力和局限性，并讨论了标准限制下的适用性。

Conclusion: 数字水印和隐写术是保护ICAO面部图像免受照片攻击的有效方法，能够实现持续验证，并为安全部署提供指导。

Abstract: ICAO-compliant facial images, initially designed for secure biometric
passports, are increasingly becoming central to identity verification in a wide
range of application contexts, including border control, digital travel
credentials, and financial services. While their standardization enables global
interoperability, it also facilitates practices such as morphing and deepfakes,
which can be exploited for harmful purposes like identity theft and illegal
sharing of identity documents. Traditional countermeasures like Presentation
Attack Detection (PAD) are limited to real-time capture and offer no
post-capture protection. This survey paper investigates digital watermarking
and steganography as complementary solutions that embed tamper-evident signals
directly into the image, enabling persistent verification without compromising
ICAO compliance. We provide the first comprehensive analysis of
state-of-the-art techniques to evaluate the potential and drawbacks of the
underlying approaches concerning the applications involving ICAO-compliant
images and their suitability under standard constraints. We highlight key
trade-offs, offering guidance for secure deployment in real-world identity
systems.

</details>


### [17] [PRISM: A Framework Harnessing Unsupervised Visual Representations and Textual Prompts for Explainable MACE Survival Prediction from Cardiac Cine MRI](https://arxiv.org/abs/2508.19325)
*Haoyang Su,Jin-Yi Xiang,Shaohao Rui,Yifan Gao,Xingyu Chen,Tingxuan Yin,Xiaosong Wang,Lian-Ming Wu*

Main category: cs.CV

TL;DR: PRISM是一个结合心脏MRI影像和电子健康记录（EHR）的自监督学习框架，用于预测主要不良心脏事件（MACE），在多项临床试验中表现优于现有模型，并识别出与心脏风险相关的三种影像学特征和三种主要的EHR风险因素。


<details>
  <summary>Details</summary>
Motivation: 心血管预后中的主要不良心脏事件（MACE）的准确预测仍然是一个核心挑战。

Method: PRISM是一个自监督学习框架，它整合了来自无对比心肌电影磁共振成像（cine cardiac magnetic resonance imaging）的视觉表征和结构化的电子健康记录（EHR），用于生存分析。PRISM通过运动感知多视图蒸馏（motion-aware multi-view distillation）提取时间同步的影像特征，并使用医学信息文本提示（medically informed textual prompts）对其进行调制，以实现细粒度的风险预测。

Result: 在四个独立的临床队列中，PRISM在内部和外部验证中始终优于经典的生存预测模型和最先进（SOTA）的深度学习基线。此外，PRISM提取的影像和EHR表征为不同队列的心脏风险提供了有价值的见解。研究发现了三种与MACE风险升高相关的影像学特征：侧壁不同步、下壁高敏感性和舒张早期前壁抬高。通过提示引导归因（prompt-guided attribution）还确定了高血压、糖尿病和吸烟是临床和生理EHR因素中的主要贡献因素。

Conclusion: PRISM框架能够有效地整合心脏MRI影像和EHR数据，实现高精度的MACE预测，并揭示了重要的心脏风险生物标志物和临床风险因素。

Abstract: Accurate prediction of major adverse cardiac events (MACE) remains a central
challenge in cardiovascular prognosis. We present PRISM (Prompt-guided
Representation Integration for Survival Modeling), a self-supervised framework
that integrates visual representations from non-contrast cardiac cine magnetic
resonance imaging with structured electronic health records (EHRs) for survival
analysis. PRISM extracts temporally synchronized imaging features through
motion-aware multi-view distillation and modulates them using medically
informed textual prompts to enable fine-grained risk prediction. Across four
independent clinical cohorts, PRISM consistently surpasses classical survival
prediction models and state-of-the-art (SOTA) deep learning baselines under
internal and external validation. Further clinical findings demonstrate that
the combined imaging and EHR representations derived from PRISM provide
valuable insights into cardiac risk across diverse cohorts. Three distinct
imaging signatures associated with elevated MACE risk are uncovered, including
lateral wall dyssynchrony, inferior wall hypersensitivity, and anterior
elevated focus during diastole. Prompt-guided attribution further identifies
hypertension, diabetes, and smoking as dominant contributors among clinical and
physiological EHR factors.

</details>


### [18] [EffNetViTLoRA: An Efficient Hybrid Deep Learning Approach for Alzheimer's Disease Diagnosis](https://arxiv.org/abs/2508.19349)
*Mahdieh Behjat Khatooni,Mohsen Soryani*

Main category: cs.CV

TL;DR: 该研究提出了EffNetViTLoRA模型，结合CNN和ViT以及LoRA技术，使用完整的ADNI MRI数据集，在AD、MCI和CN三个类别之间实现了92.52%的准确率和92.76%的F1分数，用于阿尔茨海默病（AD）的早期诊断。


<details>
  <summary>Details</summary>
Motivation: 阿尔茨海默病（AD）是一种普遍的神经退行性疾病，会导致认知功能下降，且目前无法治愈，因此早期诊断至关重要。然而，轻度认知障碍（MCI）作为正常认知与AD之间的过渡阶段，其诊断具有挑战性。本研究旨在通过一个通用的端到端模型，利用完整的ADNI MRI数据集，提高AD的诊断准确性，特别是区分MCI患者。

Method: 本研究提出了一种名为EffNetViTLoRA的广义端到端模型，用于利用整个ADNI磁共振成像（MRI）数据集进行AD诊断。该模型结合了卷积神经网络（CNN）和视觉Transformer（ViT）以捕获MRI图像的局部和全局特征。为了解决预训练模型在不同领域数据集上微调效果不佳的问题，研究采用了低秩自适应（LoRA）技术来有效地将预训练的ViT模型适应于目标域，从而实现高效的知识转移并降低过拟合风险。模型在包含AD、MCI和CN三个诊断类别的完整ADNI T1加权MRI数据集上进行训练。

Result: EffNetViTLoRA模型在完整的ADNI数据集上进行了训练，并在AD、MCI和CN三个诊断类别之间实现了92.52%的分类准确率和92.76%的F1分数。

Conclusion: EffNetViTLoRA模型通过结合CNN和ViT来捕捉MRI图像的局部和全局特征，并利用LoRA技术进行有效的模型适应，证明了其在利用完整ADNI数据集进行阿尔茨海默病早期诊断方面的有效性，取得了较高的准确率和F1分数，提高了模型的临床可靠性。

Abstract: Alzheimer's disease (AD) is one of the most prevalent neurodegenerative
disorders worldwide. As it progresses, it leads to the deterioration of
cognitive functions. Since AD is irreversible, early diagnosis is crucial for
managing its progression. Mild Cognitive Impairment (MCI) represents an
intermediate stage between Cognitively Normal (CN) individuals and those with
AD, and is considered a transitional phase from normal cognition to Alzheimer's
disease. Diagnosing MCI is particularly challenging due to the subtle
differences between adjacent diagnostic categories. In this study, we propose
EffNetViTLoRA, a generalized end-to-end model for AD diagnosis using the whole
Alzheimer's Disease Neuroimaging Initiative (ADNI) Magnetic Resonance Imaging
(MRI) dataset. Our model integrates a Convolutional Neural Network (CNN) with a
Vision Transformer (ViT) to capture both local and global features from MRI
images. Unlike previous studies that rely on limited subsets of data, our
approach is trained on the full T1-weighted MRI dataset from ADNI, resulting in
a more robust and unbiased model. This comprehensive methodology enhances the
model's clinical reliability. Furthermore, fine-tuning large pretrained models
often yields suboptimal results when source and target dataset domains differ.
To address this, we incorporate Low-Rank Adaptation (LoRA) to effectively adapt
the pretrained ViT model to our target domain. This method enables efficient
knowledge transfer and reduces the risk of overfitting. Our model achieves a
classification accuracy of 92.52% and an F1-score of 92.76% across three
diagnostic categories: AD, MCI, and CN for full ADNI dataset.

</details>


### [19] [Concurrent validity of computer-vision artificial intelligence player tracking software using broadcast footage](https://arxiv.org/abs/2508.19477)
*Zachary L. Crang,Rich D. Johnston,Katie L. Mills,Johsan Billingham,Sam Robertson,Michael H. Cole,Jonathon Weakley,Adam Hewitt and,Grant M. Duthie*

Main category: cs.CV

TL;DR: 商业计算机视觉和AI giocatori 追踪软件可以通过广播视频精确测量 giocatori 位置、速度和距离，但准确性受摄像头信号和分辨率的影响。战术信号和720p/1080p分辨率是最佳选择。


<details>
  <summary>Details</summary>
Motivation: 评估商业计算机视觉和AI giocatori 追踪软件在广播视频中的准确性，并确定摄像头信号和分辨率的影响。

Method: 使用2022年卡塔尔FIFA世界杯的一场比赛数据，分析了三个商业追踪提供商在战术、节目和摄像头1信号下的giocatori 位置、速度和总距离。将其与高分辨率多摄像头追踪系统（TRACAB Gen 5）进行比较，并计算均方根误差（RMSE）和平均偏差。

Result: giocatori 位置RMSE在1.68到16.39米之间，速度RMSE在0.34到2.38米/秒之间。总比赛距离平均偏差在-1745米（-21.8%）到1945米（24.3%）之间。

Conclusion: 当giocatori 被软件检测到时，计算机视觉和AI giocatori 追踪软件可以提供相当精确的追踪。为了最大化giocatori 检测和提高准确性，建议使用战术信号进行位置和速度追踪。720p和1080p分辨率均可接受，前提是实施了适当的计算机视觉和AI模型。

Abstract: This study aimed to: (1) understand whether commercially available
computer-vision and artificial intelligence (AI) player tracking software can
accurately measure player position, speed and distance using broadcast footage
and (2) determine the impact of camera feed and resolution on accuracy. Data
were obtained from one match at the 2022 Qatar Federation Internationale de
Football Association (FIFA) World Cup. Tactical, programme and camera 1 feeds
were used. Three commercial tracking providers that use computer-vision and AI
participated. Providers analysed instantaneous position (x, y coordinates) and
speed (m\,s^{-1}) of each player. Their data were compared with a
high-definition multi-camera tracking system (TRACAB Gen 5). Root mean square
error (RMSE) and mean bias were calculated. Position RMSE ranged from 1.68 to
16.39 m, while speed RMSE ranged from 0.34 to 2.38 m\,s^{-1}. Total match
distance mean bias ranged from -1745 m (-21.8%) to 1945 m (24.3%) across
providers. Computer-vision and AI player tracking software offer the ability to
track players with fair precision when players are detected by the software.
Providers should use a tactical feed when tracking position and speed, which
will maximise player detection, improving accuracy. Both 720p and 1080p
resolutions are suitable, assuming appropriate computer-vision and AI models
are implemented.

</details>


### [20] [JVLGS: Joint Vision-Language Gas Leak Segmentation](https://arxiv.org/abs/2508.19485)
*Xinlong Zhao,Qixiang Pang,Shan Du*

Main category: cs.CV

TL;DR: 提出了一种名为JVLGS的新型联合视觉-语言气体泄漏分割框架，通过融合视觉和文本信息来提高气体泄漏的检测和分割效果，并加入了后处理步骤来减少误报，在各种场景下均优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 气体泄漏对人类健康和环境造成严重威胁，但现有检测方法（尤其是基于视觉的方法）因气体云的模糊性和非刚性而效果有限。

Method: 提出了一种名为JVLGS的联合视觉-语言气体泄漏分割框架，该框架整合了视觉和文本模态的互补优势，并包含一个后处理步骤以减少误报。

Result: JVLGS在各种场景下显著优于最先进的气体泄漏分割方法，在监督学习和少样本学习设置下均表现出色。

Conclusion: JVLGS通过融合视觉和语言模态，并结合后处理步骤，有效提高了气体泄漏的检测和分割精度，解决了现有方法的局限性。

Abstract: Gas leaks pose serious threats to human health and contribute significantly
to atmospheric pollution, drawing increasing public concern. However, the lack
of effective detection methods hampers timely and accurate identification of
gas leaks. While some vision-based techniques leverage infrared videos for leak
detection, the blurry and non-rigid nature of gas clouds often limits their
effectiveness. To address these challenges, we propose a novel framework called
Joint Vision-Language Gas leak Segmentation (JVLGS), which integrates the
complementary strengths of visual and textual modalities to enhance gas leak
representation and segmentation. Recognizing that gas leaks are sporadic and
many video frames may contain no leak at all, our method incorporates a
post-processing step to reduce false positives caused by noise and non-target
objects, an issue that affects many existing approaches. Extensive experiments
conducted across diverse scenarios show that JVLGS significantly outperforms
state-of-the-art gas leak segmentation methods. We evaluate our model under
both supervised and few-shot learning settings, and it consistently achieves
strong performance in both, whereas competing methods tend to perform well in
only one setting or poorly in both. Code available at:
https://github.com/GeekEagle/JVLGS

</details>


### [21] [UNIFORM: Unifying Knowledge from Large-scale and Diverse Pre-trained Models](https://arxiv.org/abs/2508.19498)
*Yimu Wang,Weiming Zhuang,Chen Chen,Jiabo Huang,Jingtao Li,Lingjuan Lyu*

Main category: cs.CV

TL;DR: UNIFORM是一个新框架，可以将在不同数据集和架构上预训练的异构模型中的知识转移到一个学生模型中，而无需对训练数据或模型架构做出任何假设。它使用一种专门设计的投票机制在logit和特征级别捕获教师模型的共识，从而在无监督对象识别任务上提高了性能，并且可以扩展到大量的教师模型。


<details>
  <summary>Details</summary>
Motivation: 预训练模型提供了丰富的知识，但其异构性使得有效利用这些知识成为一项挑战。现有方法对训练数据和网络架构做出了严格的假设，限制了它们从特定类型的模型中学习，并引入了数据或归纳偏差。

Method: 提出了一种名为UNIFORM的新框架，该框架通过专门设计的投票机制，在logit和特征级别捕获异构预训练模型的共识，将知识转移到一个学生模型中。该机制不需要对教师模型的训练数据或网络架构做出任何假设。

Result: UNIFORM在无监督对象识别任务上，与现有的知识转移方法相比，表现出了优越的性能。该框架表现出卓越的可扩展性，能够从超过一百个教师模型中受益，而现有方法在远小于此的规模下就会饱和。

Conclusion: UNIFORM框架能够有效地将来自异构预训练模型的知识转移到一个学生模型中，而无需进行任何假设，并且在无监督对象识别任务上取得了显著的性能提升和出色的可扩展性。

Abstract: In the era of deep learning, the increasing number of pre-trained models
available online presents a wealth of knowledge. These models, developed with
diverse architectures and trained on varied datasets for different tasks,
provide unique interpretations of the real world. Their collective consensus is
likely universal and generalizable to unseen data. However, effectively
harnessing this collective knowledge poses a fundamental challenge due to the
heterogeneity of pre-trained models. Existing knowledge integration solutions
typically rely on strong assumptions about training data distributions and
network architectures, limiting them to learning only from specific types of
models and resulting in data and/or inductive biases. In this work, we
introduce a novel framework, namely UNIFORM, for knowledge transfer from a
diverse set of off-the-shelf models into one student model without such
constraints. Specifically, we propose a dedicated voting mechanism to capture
the consensus of knowledge both at the logit level -- incorporating teacher
models that are capable of predicting target classes of interest -- and at the
feature level, utilizing visual representations learned on arbitrary label
spaces. Extensive experiments demonstrate that UNIFORM effectively enhances
unsupervised object recognition performance compared to strong knowledge
transfer baselines. Notably, it exhibits remarkable scalability by benefiting
from over one hundred teachers, while existing methods saturate at a much
smaller scale.

</details>


### [22] [Sat2Flow: A Structure-Aware Diffusion Framework for Human Flow Generation from Satellite Imagery](https://arxiv.org/abs/2508.19499)
*Xiangxu Wang,Tianhong Zhao,Wei Tu,Bowen Zhang,Guanzhou Chen,Jinzhou Cao*

Main category: cs.CV

TL;DR: Sat2Flow使用卫星图像生成城市OD流，无需辅助数据，对空间拓扑变化具有鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有OD流生成方法依赖昂贵且覆盖范围有限的辅助数据，并且对空间拓扑敏感，需要解决这些问题。

Method: 提出Sat2Flow框架，利用多核编码器捕获区域交互，并通过感知排列的扩散过程和对比训练来确保结构一致性和拓扑鲁棒性。

Result: Sat2Flow在数值精度、经验分布和空间结构保持方面优于现有基线方法，并且在索引重排下保持不变。

Conclusion: Sat2Flow为数据稀疏的城市环境提供了一种可扩展的OD流生成解决方案，消除了对特定区域辅助数据的依赖，并保持了结构不变性，实现了稳健的移动建模。

Abstract: Origin-Destination (OD) flow matrices are essential for urban mobility
analysis, underpinning applications in traffic forecasting, infrastructure
planning, and policy design. However, existing methods suffer from two critical
limitations: (1) reliance on auxiliary features (e.g., Points of Interest,
socioeconomic statistics) that are costly to collect and have limited spatial
coverage; and (2) sensitivity to spatial topology, where minor index reordering
of urban regions (e.g., census tract relabeling) disrupts structural coherence
in generated flows. To address these challenges, we propose Sat2Flow, a latent
structure-aware diffusion-based framework that generates structurally coherent
OD flows using solely satellite imagery as input. Our approach introduces a
multi-kernel encoder to capture diverse regional interactions and employs a
permutation-aware diffusion process that aligns latent representations across
different regional orderings. Through a joint contrastive training objective
that bridges satellite-derived features with OD patterns, combined with
equivariant diffusion training that enforces structural consistency, Sat2Flow
ensures topological robustness under arbitrary regional reindexing.
Experimental results on real-world urban datasets demonstrate that Sat2Flow
outperforms both physics-based and data-driven baselines in numerical accuracy
while preserving empirical distributions and spatial structures under index
permutations. Sat2Flow offers a globally scalable solution for OD flow
generation in data-scarce urban environments, eliminating region-specific
auxiliary data dependencies while maintaining structural invariance for robust
mobility modeling.

</details>


### [23] [Weed Detection in Challenging Field Conditions: A Semi-Supervised Framework for Overcoming Shadow Bias and Data Scarcity](https://arxiv.org/abs/2508.19511)
*Alzayat Saleh,Shunsuke Hatano,Mostafa Rahimi Azghadi*

Main category: cs.CV

TL;DR: 本文提出了一种半监督框架，用于解决在现实农业环境中，由于环境条件和数据标注成本高昂而导致的深度学习模型性能下降问题。通过诊断发现“阴影偏差”——模型将阴影误识别为植被——并利用约975个标记和10,000个未标记的图像数据，通过伪标签技术增强模型鲁棒性，提高召回率，从而有效管理入侵杂草。


<details>
  <summary>Details</summary>
Motivation: 为了解决在真实农业环境中，由于环境条件和高昂的数据标注成本导致的深度学习模型性能不佳的问题，从而实现对入侵杂草的自动化管理。

Method: 本文提出了一种诊断驱动的半监督框架。首先，使用约975个标记和10,000个未标记的牧草图像数据集，建立监督学习基线（分类使用ResNet，检测使用YOLO、RF-DETR）。然后，利用可解释性工具诊断出“阴影偏差”，即模型将阴影误识别为植被。最后，通过伪标签等半监督方法，利用未标记数据增强模型对阴影偏差的鲁棒性，提高召回率。

Result: 在监督学习阶段，分类和检测模型的F1分数最高可达0.90，mAP50分数超过0.82。通过半监督框架，模型在处理“阴影偏差”问题上得到改善，召回率得到提升，更有效地减少了杂草漏检。

Conclusion: 本文提供了一个清晰且经过田间验证的框架，用于开发、诊断和改进用于精准农业复杂现实的鲁棒计算机视觉系统。该框架通过解决“阴影偏差”和利用未标记数据，有效提升了模型在恶劣环境下的性能。

Abstract: The automated management of invasive weeds is critical for sustainable
agriculture, yet the performance of deep learning models in real-world fields
is often compromised by two factors: challenging environmental conditions and
the high cost of data annotation. This study tackles both issues through a
diagnostic-driven, semi-supervised framework. Using a unique dataset of
approximately 975 labeled and 10,000 unlabeled images of Guinea Grass in
sugarcane, we first establish strong supervised baselines for classification
(ResNet) and detection (YOLO, RF-DETR), achieving F1 scores up to 0.90 and
mAP50 scores exceeding 0.82. Crucially, this foundational analysis, aided by
interpretability tools, uncovered a pervasive "shadow bias," where models
learned to misidentify shadows as vegetation. This diagnostic insight motivated
our primary contribution: a semi-supervised pipeline that leverages unlabeled
data to enhance model robustness. By training models on a more diverse set of
visual information through pseudo-labeling, this framework not only helps
mitigate the shadow bias but also provides a tangible boost in recall, a
critical metric for minimizing weed escapes in automated spraying systems. To
validate our methodology, we demonstrate its effectiveness in a low-data regime
on a public crop-weed benchmark. Our work provides a clear and field-tested
framework for developing, diagnosing, and improving robust computer vision
systems for the complex realities of precision agriculture.

</details>


### [24] [MotionFlux: Efficient Text-Guided Motion Generation through Rectified Flow Matching and Preference Alignment](https://arxiv.org/abs/2508.19527)
*Zhiting Gao,Dan Song,Diqiong Jiang,Chao Xue,An-An Liu*

Main category: cs.CV

TL;DR: TAPO通过优化文本与动作的对齐，MotionFLUX通过确定性流匹配实现实时动作生成，两者结合在语义一致性和动作质量上均超越了现有技术，并提高了生成速度。


<details>
  <summary>Details</summary>
Motivation: 解决现有文本驱动运动生成方法在语言描述与运动语义的精确对齐以及多步推理效率方面存在的问题。

Method: TAPO框架通过对齐细微的运动变化与文本修饰符，并结合迭代调整来加强语义基础。MotionFLUX是一个基于确定性流匹配的高速生成框架，通过在噪声分布与运动空间之间构建最优传输路径，实现实时合成。

Result: TAPO和MotionFLUX的结合系统在语义一致性和动作质量方面优于最先进的方法，同时加快了生成速度。

Conclusion: TAPO和MotionFLUX共同构成了一个统一的系统，在提高生成速度的同时，在语义一致性和运动质量方面均超越了现有技术。

Abstract: Motion generation is essential for animating virtual characters and embodied
agents. While recent text-driven methods have made significant strides, they
often struggle with achieving precise alignment between linguistic descriptions
and motion semantics, as well as with the inefficiencies of slow, multi-step
inference. To address these issues, we introduce TMR++ Aligned Preference
Optimization (TAPO), an innovative framework that aligns subtle motion
variations with textual modifiers and incorporates iterative adjustments to
reinforce semantic grounding. To further enable real-time synthesis, we propose
MotionFLUX, a high-speed generation framework based on deterministic rectified
flow matching. Unlike traditional diffusion models, which require hundreds of
denoising steps, MotionFLUX constructs optimal transport paths between noise
distributions and motion spaces, facilitating real-time synthesis. The
linearized probability paths reduce the need for multi-step sampling typical of
sequential methods, significantly accelerating inference time without
sacrificing motion quality. Experimental results demonstrate that, together,
TAPO and MotionFLUX form a unified system that outperforms state-of-the-art
approaches in both semantic consistency and motion quality, while also
accelerating generation speed. The code and pretrained models will be released.

</details>


### [25] [CVBench: Evaluating Cross-Video Synergies for Complex Multimodal Understanding and Reasoning](https://arxiv.org/abs/2508.19542)
*Nannan Zhu,Yonghao Dong,Teng Wang,Xueqian Li,Shengjun Deng,Yijia Wang,Zheng Hong,Tiantian Geng,Guo Niu,Hanyan Huang,Xiongfei Yao,Shuaiwei Jiao*

Main category: cs.CV

TL;DR: 该论文提出了CVBench，一个评估多视频理解能力的基准，并发现现有的大型多模态模型（MLLM）在处理跨视频关系推理方面存在显著的性能差距，特别是在因果推理和跨视频上下文保留方面。


<details>
  <summary>Details</summary>
Motivation: 评估和提升大型多模态模型（MLLM）在处理跨多个视频内容时的能力，因为现有模型在这方面的研究不足，而这一能力对于现实世界的应用至关重要。

Method: 创建了一个名为CVBench的基准，包含1000个问答对，涵盖了跨视频对象关联、事件关联和复杂推理三个层次，并使用来自五个不同领域（如体育、生活记录）的视频集。在CVBench上对包括GPT-4o、Gemini-2.0-flash、Qwen2.5-VL在内的10多个领先MLLM进行了零样本或思维链提示的评估。

Result: 在CVBench上的评估显示，即使是像GPT-4o这样的顶尖模型，在因果推理任务上的准确率也只有60%，远低于人类的91%。研究发现当前MLLM架构存在固有的瓶颈，特别是在跨视频上下文保留和重叠实体消歧方面能力不足。

Conclusion: CVBench为诊断和改进多视频推理能力提供了一个严格的框架，并为下一代MLLM的架构设计提供了见解，强调了解决跨视频上下文保留和实体消歧问题的重要性。

Abstract: While multimodal large language models (MLLMs) exhibit strong performance on
single-video tasks (e.g., video question answering), their ability across
multiple videos remains critically underexplored. However, this capability is
essential for real-world applications, including multi-camera surveillance and
cross-video procedural learning. To bridge this gap, we present CVBench, the
first comprehensive benchmark designed to assess cross-video relational
reasoning rigorously. CVBench comprises 1,000 question-answer pairs spanning
three hierarchical tiers: cross-video object association (identifying shared
entities), cross-video event association (linking temporal or causal event
chains), and cross-video complex reasoning (integrating commonsense and domain
knowledge). Built from five domain-diverse video clusters (e.g., sports, life
records), the benchmark challenges models to synthesise information across
dynamic visual contexts. Extensive evaluation of 10+ leading MLLMs (including
GPT-4o, Gemini-2.0-flash, Qwen2.5-VL) under zero-shot or chain-of-thought
prompting paradigms. Key findings reveal stark performance gaps: even top
models, such as GPT-4o, achieve only 60% accuracy on causal reasoning tasks,
compared to the 91% accuracy of human performance. Crucially, our analysis
reveals fundamental bottlenecks inherent in current MLLM architectures, notably
deficient inter-video context retention and poor disambiguation of overlapping
entities. CVBench establishes a rigorous framework for diagnosing and advancing
multi-video reasoning, offering architectural insights for next-generation
MLLMs.The data and evaluation code are available at
https://github.com/Hokhim2/CVBench.

</details>


### [26] [WEBEYETRACK: Scalable Eye-Tracking for the Browser via On-Device Few-Shot Personalization](https://arxiv.org/abs/2508.19544)
*Eduardo Davalos,Yike Zhang,Namrata Srivastava,Yashvitha Thatigotla,Jorge A. Salas,Sara McFadden,Sun-Joo Cho,Amanda Goodwin,Ashwin TS,Gautam Biswas*

Main category: cs.CV

TL;DR: WebEyeTrack是一个在浏览器中运行的轻量级、基于摄像头的眼动追踪框架，解决了现有AI方法在实际应用中的模型大小、推理时间和隐私问题，并提高了精度，特别是在头部移动的情况下。


<details>
  <summary>Details</summary>
Motivation: 现有AI眼动追踪方法在实际应用中存在模型大、推理时间长、隐私问题以及精度不足（尤其在头部移动时）的缺点，与商业解决方案存在差距。WebEyeTrack旨在解决这些问题。

Method: WebEyeTrack将轻量级SOTA（State-Of-The-Art）眼动追踪模型直接集成到浏览器中。该框架结合了基于模型的头部姿态估计和设备端少样本学习（使用少至九个校准样本），能够适应新用户。

Result: WebEyeTrack在GazeCapture数据集上达到了SOTA性能，平均误差为2.32厘米，并在iPhone 14上实现了2.4毫秒的实时推理速度。

Conclusion: WebEyeTrack是一个高效、准确且注重隐私的眼动追踪框架，可在浏览器中运行，并能适应不同用户，克服了现有方法的局限性。

Abstract: With advancements in AI, new gaze estimation methods are exceeding
state-of-the-art (SOTA) benchmarks, but their real-world application reveals a
gap with commercial eye-tracking solutions. Factors like model size, inference
time, and privacy often go unaddressed. Meanwhile, webcam-based eye-tracking
methods lack sufficient accuracy, in particular due to head movement. To tackle
these issues, we introduce We bEyeTrack, a framework that integrates
lightweight SOTA gaze estimation models directly in the browser. It
incorporates model-based head pose estimation and on-device few-shot learning
with as few as nine calibration samples (k < 9). WebEyeTrack adapts to new
users, achieving SOTA performance with an error margin of 2.32 cm on
GazeCapture and real-time inference speeds of 2.4 milliseconds on an iPhone 14.
Our open-source code is available at
https://github.com/RedForestAi/WebEyeTrack.

</details>


### [27] [MonoRelief V2: Leveraging Real Data for High-Fidelity Monocular Relief Recovery](https://arxiv.org/abs/2508.19555)
*Yu-Wei Zhang,Tongju Han,Lipeng Gao,Mingqiang Wei,Hui Liu,Changbao Li,Caiming Zhang*

Main category: cs.CV

TL;DR: MonoRelief V2是一个端到端模型，可以直接从单张图像中恢复2.5D浮雕，解决了复杂材质和光照变化的问题。与仅使用合成数据训练的V1版本不同，V2融合了真实数据，提高了鲁棒性、准确性和效率。通过文本到图像生成模型生成了约15000张伪真实图像，并结合深度和法线预测得到伪标签。同时，构建了一个包含800个样本的小规模真实世界数据集。该模型在伪真实和真实数据集上逐步训练，并在深度和法线预测方面均取得了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 为了解决从单张图像恢复2.5D浮雕时遇到的复杂材质和光照变化问题，并提高模型的鲁棒性、准确性和效率。

Method: 使用文本到图像生成模型生成了约15000张伪真实图像，并通过融合深度和法线预测获得了相应的伪标签。同时，构建了一个包含800个样本的小规模真实世界数据集。MonoRelief V2在伪真实和真实世界数据集上进行渐进式训练。

Result: 该模型在深度和法线预测方面均取得了最先进的性能。

Conclusion: MonoRelief V2在从单张图像恢复2.5D浮雕方面表现出色，尤其是在处理复杂材质和光照变化时，并且在各种下游应用中具有巨大潜力。

Abstract: This paper presents MonoRelief V2, an end-to-end model designed for directly
recovering 2.5D reliefs from single images under complex material and
illumination variations. In contrast to its predecessor, MonoRelief V1 [1],
which was solely trained on synthetic data, MonoRelief V2 incorporates real
data to achieve improved robustness, accuracy and efficiency. To overcome the
challenge of acquiring large-scale real-world dataset, we generate
approximately 15,000 pseudo real images using a text-to-image generative model,
and derive corresponding depth pseudo-labels through fusion of depth and normal
predictions. Furthermore, we construct a small-scale real-world dataset (800
samples) via multi-view reconstruction and detail refinement. MonoRelief V2 is
then progressively trained on the pseudo-real and real-world datasets.
Comprehensive experiments demonstrate its state-of-the-art performance both in
depth and normal predictions, highlighting its strong potential for a range of
downstream applications. Code is at: https://github.com/glp1001/MonoreliefV2.

</details>


### [28] [FlowDet: Overcoming Perspective and Scale Challenges in Real-Time End-to-End Traffic Detection](https://arxiv.org/abs/2508.19565)
*Yuhang Zhao,Zixing Wang*

Main category: cs.CV

TL;DR: FlowDet是一种基于DETR的高速目标检测器，通过解耦编码器优化、几何可变形单元（GDU）和尺度感知注意力（SAA）模块，在保持高精度的同时显著降低了计算成本和提高了推理速度。此外，研究人员还发布了一个新的数据集Intersection-Flow-5k，用于评估在复杂交通场景下的模型性能。


<details>
  <summary>Details</summary>
Motivation: 现有的端到端目标检测器虽然有潜力实现无NMS的实时应用，但在复杂场景（如交叉路口交通监控）下计算成本高昂，阻碍了其广泛应用。本研究旨在解决这一挑战，提出一种高效的高速检测器。

Method: 提出了一种名为FlowDet的高速检测器，它采用了DETR架构，并结合了以下关键技术：1. 解耦编码器优化策略；2. 新颖的几何可变形单元（GDU），用于交通场景的几何建模；3. 尺度感知注意力（SAA）模块，以应对极端尺度变化并保持表征能力。为评估模型性能，研究人员收集并发布了一个新的数据集Intersection-Flow-5k，该数据集包含了严重的遮挡和高密度的物体。

Result: 在Intersection-Flow-5k数据集上，FlowDet取得了新的 state-of-the-art 性能。与RT-DETR基线相比，FlowDet将AP(test)提高了1.5%，AP50(test)提高了1.6%，同时将GFLOPs降低了63.2%，并将推理速度提高了16.2%。

Conclusion: FlowDet通过其创新的设计，为构建高效、准确且适用于严苛的真实世界感知系统的检测器提供了新的途径。

Abstract: End-to-end object detectors offer a promising NMS-free paradigm for real-time
applications, yet their high computational cost remains a significant barrier,
particularly for complex scenarios like intersection traffic monitoring. To
address this challenge, we propose FlowDet, a high-speed detector featuring a
decoupled encoder optimization strategy applied to the DETR architecture.
Specifically, FlowDet employs a novel Geometric Deformable Unit (GDU) for
traffic-aware geometric modeling and a Scale-Aware Attention (SAA) module to
maintain high representational power across extreme scale variations. To
rigorously evaluate the model's performance in environments with severe
occlusion and high object density, we collected the Intersection-Flow-5k
dataset, a new challenging scene for this task. Evaluated on
Intersection-Flow-5k, FlowDet establishes a new state-of-the-art. Compared to
the strong RT-DETR baseline, it improves AP(test) by 1.5% and AP50(test) by
1.6%, while simultaneously reducing GFLOPs by 63.2% and increasing inference
speed by 16.2%. Our work demonstrates a new path towards building highly
efficient and accurate detectors for demanding, real-world perception systems.
The Intersection-Flow-5k dataset is available at
https://github.com/AstronZh/Intersection-Flow-5K.

</details>


### [29] [Discrete Diffusion VLA: Bringing Discrete Diffusion to Action Decoding in Vision-Language-Action Policies](https://arxiv.org/abs/2508.20072)
*Zhixuan Liang,Yizhuo Li,Tianshuo Yang,Chengyue Wu,Sitong Mao,Liuao Pei,Xiaokang Yang,Jiangmiao Pang,Yao Mu,Ping Luo*

Main category: cs.CV

TL;DR: We introduce Discrete Diffusion VLA, a unified transformer policy that models discretized action chunks using discrete diffusion, compatible with Vision-Language Models (VLMs). It achieves adaptive decoding, parallel processing, and improved performance on robotic tasks compared to existing methods.


<details>
  <summary>Details</summary>
Motivation: Existing Vision-Language-Action (VLA) decoders have limitations such as autoregressive generation, specialized training, and iterative sampling, hindering unified and scalable architectures. We aim to develop a more compatible and efficient VLA decoder.

Method: We propose Discrete Diffusion VLA, a single-transformer policy that models discretized action chunks with discrete diffusion. This approach is trained with the same cross-entropy objective as the VLM backbone, maintaining compatibility with the discrete token interface of VLMs. It features adaptive decoding and secondary remasking for refinement and error correction.

Result: Discrete Diffusion VLA achieves 96.3% average success rate (SR) on LIBERO, 71.2% visual matching on SimplerEnv Fractal, and 49.3% overall on SimplerEnv Bridge. These results surpass both autoregressive and continuous diffusion baselines.

Conclusion: Discrete Diffusion VLA's unified decoder preserves pre-trained vision-language priors, supports parallel decoding, breaks the autoregressive bottleneck, and reduces function evaluations. This approach facilitates precise action modeling and consistent training, paving the way for scaling VLA to larger models and datasets.

Abstract: Vision-Language-Action (VLA) models adapt large vision-language backbones to
map images and instructions to robot actions. However, prevailing VLA decoders
either generate actions autoregressively in a fixed left-to-right order or
attach continuous diffusion or flow matching heads outside the backbone,
demanding specialized training and iterative sampling that hinder a unified,
scalable architecture. We present Discrete Diffusion VLA, a single-transformer
policy that models discretized action chunks with discrete diffusion and is
trained with the same cross-entropy objective as the VLM backbone. The design
retains diffusion's progressive refinement paradigm while remaining natively
compatible with the discrete token interface of VLMs. Our method achieves an
adaptive decoding order that resolves easy action elements before harder ones
and uses secondary remasking to revisit uncertain predictions across refinement
rounds, which improves consistency and enables robust error correction. This
unified decoder preserves pretrained vision language priors, supports parallel
decoding, breaks the autoregressive bottleneck, and reduces the number of
function evaluations. Discrete Diffusion VLA achieves 96.3% avg. SR on LIBERO,
71.2% visual matching on SimplerEnv Fractal and 49.3% overall on SimplerEnv
Bridge, improving over both autoregressive and continuous diffusion baselines.
These findings indicate that discrete-diffusion action decoder supports precise
action modeling and consistent training, laying groundwork for scaling VLA to
larger models and datasets.

</details>


### [30] [DNP-Guided Contrastive Reconstruction with a Reverse Distillation Transformer for Medical Anomaly Detection](https://arxiv.org/abs/2508.19573)
*Luhu Li,Bowen Lin,Mukhtiar Khan,Shujun Fu*

Main category: cs.CV

TL;DR: 医学图像异常检测面临挑战，提出一种包含可训练编码器、原型引导重建和多样性感知对齐损失的统一框架，以提高适应性和定位精度，解决现有方法局限性。


<details>
  <summary>Details</summary>
Motivation: 现有医学图像异常检测方法在处理有限标注和域差异时存在局限，如固定编码器限制适应性，原型学习易发生原型坍塌。

Method: 提出一个统一框架，包含：1. 可训练的、带有动量分支的编码器以进行域自适应特征学习；2. 轻量级原型提取器，通过注意力机制引导解码器进行精确重建；3. 新颖的多样性感知对齐损失，通过多样性约束和原型归一化防止原型坍塌。

Result: 在多个医学成像基准测试中，所提出的框架在表示质量和异常定位方面显著优于现有方法。

Conclusion: 该框架通过可训练编码器、原型引导重建和多样性感知对齐损失，有效解决了医学图像异常检测中的域适应性和原型坍塌问题，提高了检测性能和可解释性。

Abstract: Anomaly detection in medical images is challenging due to limited annotations
and a domain gap compared to natural images. Existing reconstruction methods
often rely on frozen pre-trained encoders, which limits adaptation to
domain-specific features and reduces localization accuracy. Prototype-based
learning offers interpretability and clustering benefits but suffers from
prototype collapse, where few prototypes dominate training, harming diversity
and generalization. To address this, we propose a unified framework combining a
trainable encoder with prototype-guided reconstruction and a novel
Diversity-Aware Alignment Loss. The trainable encoder, enhanced by a momentum
branch, enables stable domain-adaptive feature learning. A lightweight
Prototype Extractor mines informative normal prototypes to guide the decoder
via attention for precise reconstruction. Our loss enforces balanced prototype
use through diversity constraints and per-prototype normalization, effectively
preventing collapse. Experiments on multiple medical imaging benchmarks show
significant improvements in representation quality and anomaly localization,
outperforming prior methods. Visualizations and prototype assignment analyses
further validate the effectiveness of our anti-collapse mechanism and enhanced
interpretability.

</details>


### [31] [Multimodal Prototype Alignment for Semi-supervised Pathology Image Segmentation](https://arxiv.org/abs/2508.19574)
*Mingxi Fu,Fanglei Fu,Xitong Ling,Huaitian Yuan,Tian Guan,Yonghong He,Lianghui Zhu*

Main category: cs.CV

TL;DR: MPAMatch是一个新颖的半监督学习框架，通过多模态原型引导和双对比学习（图像-像素，文本-像素）来解决病理图像分割中的挑战，并在多个数据集上取得了优于现有方法的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的半监督分割方法（如UniMatch）主要依赖于图像内的扰动一致性，难以捕捉高层语义信息，尤其是在结构复杂的病理图像中。病理图像分割也面临着语义边界模糊和像素级标注成本高昂的挑战。

Method: MPAMatch提出了一种多模态原型引导的像素级对比学习框架。其核心是图像原型-像素标签和文本原型-像素标签之间的双对比学习，同时进行结构和语义层面的监督。此外，还用病理预训练的Uni模型替换了TransUNet的ViT骨干，以更有效地提取特征。

Result: MPAMatch在GLAS、EBHI-SEG-GLAND、EBHI-SEG-CANCER和KPI数据集上进行了广泛实验，结果显示其性能优于最先进的方法。

Conclusion: MPAMatch通过其创新的双对比学习策略（图像和文本原型）和基于Uni的骨干网络，有效地解决了病理图像分割中的结构和语义建模挑战，显著提高了分割性能。

Abstract: Pathological image segmentation faces numerous challenges, particularly due
to ambiguous semantic boundaries and the high cost of pixel-level annotations.
Although recent semi-supervised methods based on consistency regularization
(e.g., UniMatch) have made notable progress, they mainly rely on
perturbation-based consistency within the image modality, making it difficult
to capture high-level semantic priors, especially in structurally complex
pathology images. To address these limitations, we propose MPAMatch - a novel
segmentation framework that performs pixel-level contrastive learning under a
multimodal prototype-guided supervision paradigm. The core innovation of
MPAMatch lies in the dual contrastive learning scheme between image prototypes
and pixel labels, and between text prototypes and pixel labels, providing
supervision at both structural and semantic levels. This coarse-to-fine
supervisory strategy not only enhances the discriminative capability on
unlabeled samples but also introduces the text prototype supervision into
segmentation for the first time, significantly improving semantic boundary
modeling. In addition, we reconstruct the classic segmentation architecture
(TransUNet) by replacing its ViT backbone with a pathology-pretrained
foundation model (Uni), enabling more effective extraction of
pathology-relevant features. Extensive experiments on GLAS, EBHI-SEG-GLAND,
EBHI-SEG-CANCER, and KPI show MPAMatch's superiority over state-of-the-art
methods, validating its dual advantages in structural and semantic modeling.

</details>


### [32] [Interact-Custom: Customized Human Object Interaction Image Generation](https://arxiv.org/abs/2508.19575)
*Zhu Xu,Zhaowen Wang,Yuxin Peng,Yang Liu*

Main category: cs.CV

TL;DR: 本篇论文提出了一种名为CHOI（Customized Human Object Interaction Image Generation）的新任务，旨在实现对人物和物体交互图像的定制化生成，同时保证人物和物体的身份特征以及它们之间交互语义的控制。现有的方法主要关注外观保留，忽略了交互控制。CHOI任务面临两大挑战：1) 如何同时进行身份保留和交互控制，需要模型将人物分解为身份特征和与姿势相关的交互特征，但现有数据集不适合这种学习；2) 人物与物体不恰当的空间配置可能导致缺乏期望的交互语义。为了解决这些问题，论文首先处理了一个大型数据集，其中包含相同人物和物体在不同交互姿势下的样本。然后，设计了一个名为Interact-Custom的两阶段模型：第一阶段显式地通过生成描述交互行为的前景掩模来建模空间配置；第二阶段在掩模的指导下，生成能够保持身份特征并进行交互的目标人物和物体。此外，如果用户提供背景图像和目标人物/物体出现的位置，Interact-Custom还可以选择性地指定这些内容，提供了高度的内容可控性。通过针对CHOI任务定制的指标进行的广泛实验证明了该方法的有效性。


<details>
  <summary>Details</summary>
Motivation: 现有图像生成方法主要关注目标实体的外观保留，而忽略了目标实体之间的细粒度交互控制。本研究旨在解决这一问题，通过提出定制化人与物交互图像生成（CHOI）任务，实现身份保持和交互语义控制。

Method: 提出名为Interact-Custom的两阶段模型。第一阶段通过生成前景掩模来显式建模空间配置，描绘交互行为。第二阶段在掩模的指导下，生成目标人与物，同时保持其身份特征并实现交互。此外，该模型还支持用户自定义背景图像和目标物体出现的位置。

Result: 通过针对CHOI任务定制的指标进行的广泛实验证明了Interact-Custom方法的有效性。

Conclusion: Interact-Custom模型能够有效地处理定制化人与物交互图像生成任务，成功地实现了人物和物体的身份保留以及它们之间交互语义的控制，解决了现有方法在交互控制方面的不足。

Abstract: Compositional Customized Image Generation aims to customize multiple target
concepts within generation content, which has gained attention for its wild
application.Existing approaches mainly concentrate on the target entity's
appearance preservation, while neglecting the fine-grained interaction control
among target entities.To enable the model of such interaction control
capability, we focus on human object interaction scenario and propose the task
of Customized Human Object Interaction Image Generation(CHOI), which
simultaneously requires identity preservation for target human object and the
interaction semantic control between them.Two primary challenges exist for
CHOI:(1)simultaneous identity preservation and interaction control demands
require the model to decompose the human object into self-contained identity
features and pose-oriented interaction features, while the current HOI image
datasets fail to provide ideal samples for such feature-decomposed
learning.(2)inappropriate spatial configuration between human and object may
lead to the lack of desired interaction semantics.To tackle it, we first
process a large-scale dataset, where each sample encompasses the same pair of
human object involving different interactive poses.Then we design a two-stage
model Interact-Custom, which firstly explicitly models the spatial
configuration by generating a foreground mask depicting the interaction
behavior, then under the guidance of this mask, we generate the target human
object interacting while preserving their identities features.Furthermore, if
the background image and the union location of where the target human object
should appear are provided by users, Interact-Custom also provides the optional
functionality to specify them, offering high content controllability. Extensive
experiments on our tailored metrics for CHOI task demonstrate the effectiveness
of our approach.

</details>


### [33] [High-Speed FHD Full-Color Video Computer-Generated Holography](https://arxiv.org/abs/2508.19579)
*Haomiao Zhang,Miao Cao,Xuan Yu,Hui Luo,Yanling Piao,Mengjie Qin,Zhangyuan Li,Ping Wang,Xin Yuan*

Main category: cs.CV

TL;DR: 该论文提出了一种名为SGDDM的新型计算全息图（CGH）生成方案，通过频率调制优化相位分布，实现了高帧率全彩显示。同时，他们还开发了一个名为HoloMamba的轻量级Mamba-Unet架构，该架构能够显式地对视频序列中的时空相关性进行建模，从而提高了重建质量和计算效率。实验证明，HoloMamba可以在超过260 FPS的速度下生成全高清全彩视频，比现有最先进的方法快2.6倍以上。


<details>
  <summary>Details</summary>
Motivation: 为了解决计算机生成全息图（CGH）在生成高速、高质量全息视频时面临的两个关键限制：1）基于学习的模型产生的相位平滑、角谱窄，导致在高帧率全彩显示中出现严重的色彩串扰；2）现有的逐帧优化方法忽略了帧间时空相关性，导致计算效率低下。

Method: 提出了一种名为SGDDM（Spectrum-Guided Depth Division Multiplexing）的新方案，通过频率调制优化相位分布，以实现高保真全彩显示。同时，提出了一种名为HoloMamba的轻量级非对称Mamba-Unet架构，用于显式地建模视频序列中的时空相关性，以提高重建质量和计算效率。

Result: SGDDM实现了高保真全彩显示，没有牺牲帧率。HoloMamba能够以超过260 FPS的速度生成全高清（1080p）全彩视频，比之前的最先进的Divide-Conquer-and-Merge策略快2.6倍以上。

Conclusion: 提出的SGDDM和HoloMamba方案能够有效地克服现有CGH技术的局限性，在保持高帧率和高保真度的前提下，显著提高了全息视频的生成速度和质量。

Abstract: Computer-generated holography (CGH) is a promising technology for
next-generation displays. However, generating high-speed, high-quality
holographic video requires both high frame rate display and efficient
computation, but is constrained by two key limitations: ($i$) Learning-based
models often produce over-smoothed phases with narrow angular spectra, causing
severe color crosstalk in high frame rate full-color displays such as
depth-division multiplexing and thus resulting in a trade-off between frame
rate and color fidelity. ($ii$) Existing frame-by-frame optimization methods
typically optimize frames independently, neglecting spatial-temporal
correlations between consecutive frames and leading to computationally
inefficient solutions. To overcome these challenges, in this paper, we propose
a novel high-speed full-color video CGH generation scheme. First, we introduce
Spectrum-Guided Depth Division Multiplexing (SGDDM), which optimizes phase
distributions via frequency modulation, enabling high-fidelity full-color
display at high frame rates. Second, we present HoloMamba, a lightweight
asymmetric Mamba-Unet architecture that explicitly models spatial-temporal
correlations across video sequences to enhance reconstruction quality and
computational efficiency. Extensive simulated and real-world experiments
demonstrate that SGDDM achieves high-fidelity full-color display without
compromise in frame rate, while HoloMamba generates FHD (1080p) full-color
holographic video at over 260 FPS, more than 2.6$\times$ faster than the prior
state-of-the-art Divide-Conquer-and-Merge Strategy.

</details>


### [34] [Guiding Noisy Label Conditional Diffusion Models with Score-based Discriminator Correction](https://arxiv.org/abs/2508.19581)
*Dat Nguyen Cong,Hieu Tran Bao,Hoang Thanh-Tung*

Main category: cs.CV

TL;DR: 本文提出了一种名为Score-based Discriminator Correction (SBDC)的引导技术，用于校正含有错误标签的扩散模型，通过判别器训练和对抗性损失来评估样本真实性，并在生成过程的早期阶段使用该技术可获得更优性能，且无需重新训练模型。


<details>
  <summary>Details</summary>
Motivation: 研究包含错误标签的扩散模型在生成能力和可控性方面受到的影响，并提出一种校正方法。

Method: 提出Score-based Discriminator Correction (SBDC)引导技术，利用判别器训练和对抗性损失，并结合先前的噪声检测技术来评估样本真实性。将该技术限制在生成过程的早期阶段使用。

Result: 实验证明SBDC在不同噪声设置下优于现有的最先进方法，且计算效率高，仅略微增加推理时间。

Conclusion: SBDC是一种有效的引导技术，可以校正预训练的条件扩散模型，并在不增加显著计算成本的情况下提高生成质量。

Abstract: Diffusion models have gained prominence as state-of-the-art techniques for
synthesizing images and videos, particularly due to their ability to scale
effectively with large datasets. Recent studies have uncovered that these
extensive datasets often contain mistakes from manual labeling processes.
However, the extent to which such errors compromise the generative capabilities
and controllability of diffusion models is not well studied. This paper
introduces Score-based Discriminator Correction (SBDC), a guidance technique
for aligning noisy pre-trained conditional diffusion models. The guidance is
built on discriminator training using adversarial loss, drawing on prior noise
detection techniques to assess the authenticity of each sample. We further show
that limiting the usage of our guidance to the early phase of the generation
process leads to better performance. Our method is computationally efficient,
only marginally increases inference time, and does not require retraining
diffusion models. Experiments on different noise settings demonstrate the
superiority of our method over previous state-of-the-art methods.

</details>


### [35] [Generalizing Monocular 3D Object Detection](https://arxiv.org/abs/2508.19593)
*Abhinav Kumar*

Main category: cs.CV

TL;DR: 本论文提出多种方法来解决单目3D物体检测（Mono3D）在各种场景下的泛化能力问题，包括遮挡、不同数据集、物体大小和相机参数。


<details>
  <summary>Details</summary>
Motivation: Mono3D是计算机视觉中的一个基础任务，在自动驾驶、增强现实和机器人等领域至关重要，但其泛化能力受限于各种场景（如遮挡、不同数据集、物体大小和相机参数）。

Method: 为了提高对遮挡的鲁棒性，提出了一种数学可微的NMS（GrooMeD-NMS）。为了提高对新数据集的泛化能力，探索了深度等变（DEVIANT）骨干网络。针对大物体检测问题，证明其不仅是数据不平衡或感受野的问题，也是噪声敏感性问题，并提出了一种基于分割的鸟瞰图方法（SeaBird）结合Dice损失来解决。最后，对Mono3D模型外推到未见过的相机高度进行了数学分析，并改进了在这种分布外设置下的泛化能力。

Result: 提出GrooMeD-NMS提高了遮挡鲁棒性，DEVIANT骨干网络改善了数据集泛化能力，SeaBird解决了大物体检测中的噪声敏感性问题，并对相机高度外推进行了数学分析和改进。

Conclusion: 通过GrooMeD-NMS、DEVIANT骨干网络、SeaBird以及对相机高度外推的分析，本论文显著提升了Mono3D模型在各种挑战性场景下的泛化能力和鲁棒性。

Abstract: Monocular 3D object detection (Mono3D) is a fundamental computer vision task
that estimates an object's class, 3D position, dimensions, and orientation from
a single image. Its applications, including autonomous driving, augmented
reality, and robotics, critically rely on accurate 3D environmental
understanding. This thesis addresses the challenge of generalizing Mono3D
models to diverse scenarios, including occlusions, datasets, object sizes, and
camera parameters. To enhance occlusion robustness, we propose a mathematically
differentiable NMS (GrooMeD-NMS). To improve generalization to new datasets, we
explore depth equivariant (DEVIANT) backbones. We address the issue of large
object detection, demonstrating that it's not solely a data imbalance or
receptive field problem but also a noise sensitivity issue. To mitigate this,
we introduce a segmentation-based approach in bird's-eye view with dice loss
(SeaBird). Finally, we mathematically analyze the extrapolation of Mono3D
models to unseen camera heights and improve Mono3D generalization in such
out-of-distribution settings.

</details>


### [36] [Quantization Robustness to Input Degradations for Object Detection](https://arxiv.org/abs/2508.19600)
*Toghrul Karimov,Hassan Imani,Allan Kazakov*

Main category: cs.CV

TL;DR: 该研究评估了YOLO模型在不同量化精度（FP32, FP16, UINT8, INT8）下的鲁棒性，并提出了一种考虑退化情况的校准策略。结果显示，INT8量化在加速模型的同时会降低精度，而所提出的校准策略在大多数情况下并未显著提升模型对各种图像退化的鲁棒性，但在特定条件下对大型模型有一定效果。


<details>
  <summary>Details</summary>
Motivation: 部署YOLO等高效目标检测模型到资源受限设备上时，量化是关键技术。然而，低精度对模型在真实世界输入退化（如噪声、模糊、压缩伪影）下的鲁棒性影响是一个关键问题。

Method: 对YOLO模型（不同尺寸）在FP32, FP16, UINT8, INT8四种精度格式下进行了鲁棒性评估。提出了一种面向退化的校准策略，将原始图像和合成退化图像混合用于TensorRT的校准过程。在COCO数据集上，在七种不同的退化条件（噪声、模糊、低对比度、JPEG压缩）和混合退化场景下对模型进行了基准测试。

Result: 静态INT8 TensorRT引擎在原始数据上提供了显著的加速（约1.5-3.3倍），但精度有所下降（约3-7% mAP50-95）。提出的面向退化的校准策略在大多数模型和退化条件下并未带来持续广泛的鲁棒性提升。在特定噪声条件下，大型模型表现出一定效果，表明模型容量可能影响校准策略的有效性。

Conclusion: 静态INT8量化能显著加速YOLO模型，但对模型鲁棒性提出了挑战。所提出的退化感知校准方法在提高量化模型在不受控环境下的鲁棒性方面效果有限，尤其是在处理各种图像退化时。未来需要进一步研究以提升量化模型的鲁棒性。

Abstract: Post-training quantization (PTQ) is crucial for deploying efficient object
detection models, like YOLO, on resource-constrained devices. However, the
impact of reduced precision on model robustness to real-world input
degradations such as noise, blur, and compression artifacts is a significant
concern. This paper presents a comprehensive empirical study evaluating the
robustness of YOLO models (nano to extra-large scales) across multiple
precision formats: FP32, FP16 (TensorRT), Dynamic UINT8 (ONNX), and Static INT8
(TensorRT). We introduce and evaluate a degradation-aware calibration strategy
for Static INT8 PTQ, where the TensorRT calibration process is exposed to a mix
of clean and synthetically degraded images. Models were benchmarked on the COCO
dataset under seven distinct degradation conditions (including various types
and levels of noise, blur, low contrast, and JPEG compression) and a
mixed-degradation scenario. Results indicate that while Static INT8 TensorRT
engines offer substantial speedups (~1.5-3.3x) with a moderate accuracy drop
(~3-7% mAP50-95) on clean data, the proposed degradation-aware calibration did
not yield consistent, broad improvements in robustness over standard clean-data
calibration across most models and degradations. A notable exception was
observed for larger model scales under specific noise conditions, suggesting
model capacity may influence the efficacy of this calibration approach. These
findings highlight the challenges in enhancing PTQ robustness and provide
insights for deploying quantized detectors in uncontrolled environments. All
code and evaluation tables are available at https://github.com/AllanK24/QRID.

</details>


### [37] [IELDG: Suppressing Domain-Specific Noise with Inverse Evolution Layers for Domain Generalized Semantic Segmentation](https://arxiv.org/abs/2508.19604)
*Qizhe Fan,Chaoyu Liu,Zhonghua Qiao,Xiaoqin Shen*

Main category: cs.CV

TL;DR: 本研究提出了一种名为IELFormer的框架，用于解决领域泛化语义分割（DGSS）中的数据增强和模型泛化问题。该框架通过引入逆进化层（IELs）来优化扩散模型生成的数据质量，并将其集成到分割模型的解码器中，以抑制伪影传播。此外，还包含一个多尺度频率融合（MFF）模块，以增强跨尺度的语义一致性。实验结果表明，该方法在泛化性能上优于现有技术。


<details>
  <summary>Details</summary>
Motivation: 领域泛化语义分割（DGSS）的目标是在源域的标注数据上训练模型，并在未知的目标域上实现鲁棒泛化。扩散模型（DMs）常用于生成合成数据以增强泛化能力，但生成的图像可能存在缺陷，导致性能下降。本研究旨在解决此问题，提高生成数据的质量并增强模型的泛化能力。

Method: 本研究提出将逆进化层（IELs）整合到扩散模型的生成过程中，以过滤不良的生成模式，从而生成更高质量的图像（IELDM）。此外，还将IELs嵌入DGSS模型的解码器中，并结合多尺度频率融合（MFF）模块，形成IELFormer模型，以增强模型的泛化能力和跨尺度语义一致性。

Result: 通过在扩散模型中引入IELs，可以生成更高质量的增强数据（IELDM）。将IELs嵌入DGSS模型的解码器并结合MFF模块的IELFormer模型，在跨域场景下表现出更强的泛化能力。实验证明，该方法在基准数据集上取得了优于现有方法的泛化性能。

Conclusion: 本研究提出的IELDM和IELFormer框架通过引入逆进化层（IELs）和多尺度频率融合（MFF）模块，有效解决了领域泛化语义分割中的数据增强和模型泛化问题，显著提高了模型的泛化性能和跨尺度语义一致性。

Abstract: Domain Generalized Semantic Segmentation (DGSS) focuses on training a model
using labeled data from a source domain, with the goal of achieving robust
generalization to unseen target domains during inference. A common approach to
improve generalization is to augment the source domain with synthetic data
generated by diffusion models (DMs). However, the generated images often
contain structural or semantic defects due to training imperfections. Training
segmentation models with such flawed data can lead to performance degradation
and error accumulation. To address this issue, we propose to integrate inverse
evolution layers (IELs) into the generative process. IELs are designed to
highlight spatial discontinuities and semantic inconsistencies using
Laplacian-based priors, enabling more effective filtering of undesirable
generative patterns. Based on this mechanism, we introduce IELDM, an enhanced
diffusion-based data augmentation framework that can produce higher-quality
images. Furthermore, we observe that the defect-suppression capability of IELs
can also benefit the segmentation network by suppressing artifact propagation.
Based on this insight, we embed IELs into the decoder of the DGSS model and
propose IELFormer to strengthen generalization capability in cross-domain
scenarios. To further strengthen the model's semantic consistency across
scales, IELFormer incorporates a multi-scale frequency fusion (MFF) module,
which performs frequency-domain analysis to achieve structured integration of
multi-resolution features, thereby improving cross-scale coherence. Extensive
experiments on benchmark datasets demonstrate that our approach achieves
superior generalization performance compared to existing methods.

</details>


### [38] [Controllable Skin Synthesis via Lesion-Focused Vector Autoregression Model](https://arxiv.org/abs/2508.19626)
*Jiajun Sun,Zhen Yu,Siyuan Yan,Jason J. Ong,Zongyuan Ge,Lei Zhang*

Main category: cs.CV

TL;DR: LF-VAR是一个利用量化病变测量分数和病变类型标签来指导临床相关和可控皮肤图像合成的模型，解决了现有方法生成图像质量低且缺乏对病变位置和类型控制的问题。通过训练多尺度向量量化变分自编码器(VQVAE)和视觉自回归(VAR)Transformer，并结合病变区域测量和类型作为条件嵌入，LF-VAR能够根据语言提示生成具有特定病变特征的高保真、临床相关合成皮肤图像，在七种病变类型的FID分数上优于现有SOTA方法6.3%。


<details>
  <summary>Details</summary>
Motivation: 现有皮肤图像合成方法存在图像质量低、病变位置和类型控制不足的问题，限制了用于深度学习模型训练的数据量。

Method: 提出LF-VAR模型，利用量化病变测量分数和病变类型标签指导合成。训练多尺度VQVAE将图像编码为离散的潜在表示，然后训练VAR Transformer促进图像合成。将病变测量和类型作为条件嵌入以增强合成保真度。

Result: LF-VAR在七种病变类型上取得了最佳的总体FID分数（平均0.74），比之前的SOTA方法提高了6.3%。

Conclusion: LF-VAR模型能够有效生成高保真、临床相关的合成皮肤图像，实现了对皮肤合成的精确控制。

Abstract: Skin images from real-world clinical practice are often limited, resulting in
a shortage of training data for deep-learning models. While many studies have
explored skin image synthesis, existing methods often generate low-quality
images and lack control over the lesion's location and type. To address these
limitations, we present LF-VAR, a model leveraging quantified lesion
measurement scores and lesion type labels to guide the clinically relevant and
controllable synthesis of skin images. It enables controlled skin synthesis
with specific lesion characteristics based on language prompts. We train a
multiscale lesion-focused Vector Quantised Variational Auto-Encoder (VQVAE) to
encode images into discrete latent representations for structured tokenization.
Then, a Visual AutoRegressive (VAR) Transformer trained on tokenized
representations facilitates image synthesis. Lesion measurement from the lesion
region and types as conditional embeddings are integrated to enhance synthesis
fidelity. Our method achieves the best overall FID score (average 0.74) among
seven lesion types, improving upon the previous state-of-the-art (SOTA) by
6.3%. The study highlights our controllable skin synthesis model's
effectiveness in generating high-fidelity, clinically relevant synthetic skin
images. Our framework code is available at
https://github.com/echosun1996/LF-VAR.

</details>


### [39] [Divide, Weight, and Route: Difficulty-Aware Optimization with Dynamic Expert Fusion for Long-tailed Recognition](https://arxiv.org/abs/2508.19630)
*Xiaolei Wei,Yi Ouyang,Haibo Ye*

Main category: cs.CV

TL;DR: DQRoute是一个结合了难度感知优化和动态专家协作的框架，用于解决长尾视觉识别中的类别不平衡和学习难度问题。它通过估计类别难度并指导训练，同时利用专家网络和OOD检测器进行自适应路由，从而在长尾数据集上显著提升了性能，尤其是在稀有和困难类别上。


<details>
  <summary>Details</summary>
Motivation: 长尾视觉识别面临类别不平衡和不同类别学习难度的挑战，现有方法仅通过频率加权忽略了学习难度较大的类别。本研究旨在提出一个能够结合难度感知优化和动态专家协作的框架，以解决这些问题。

Method: DQRoute框架首先基于预测不确定性和历史表现估计类别难度，并利用该信号进行自适应损失加权训练。在架构上，它采用混合专家设计，每个专家专注于类别分布的不同区域。在推理时，专家预测通过专家特定的OOD检测器产生的置信分数进行加权，实现了无需中心化路由器的输入自适应路由。所有组件均进行端到端联合训练。

Result: 在标准长尾基准数据集上的实验表明，DQRoute显著提高了性能，尤其是在稀有和困难类别上，证明了将难度建模与去中心化专家路由相结合的益处。

Conclusion: DQRoute通过整合难度建模和去中心化专家路由，有效解决了长尾视觉识别中的挑战，尤其是在罕见和困难类别上取得了显著的性能提升。

Abstract: Long-tailed visual recognition is challenging not only due to class imbalance
but also because of varying classification difficulty across categories. Simply
reweighting classes by frequency often overlooks those that are intrinsically
hard to learn. To address this, we propose \textbf{DQRoute}, a modular
framework that combines difficulty-aware optimization with dynamic expert
collaboration. DQRoute first estimates class-wise difficulty based on
prediction uncertainty and historical performance, and uses this signal to
guide training with adaptive loss weighting. On the architectural side, DQRoute
employs a mixture-of-experts design, where each expert specializes in a
different region of the class distribution. At inference time, expert
predictions are weighted by confidence scores derived from expert-specific OOD
detectors, enabling input-adaptive routing without the need for a centralized
router. All components are trained jointly in an end-to-end manner. Experiments
on standard long-tailed benchmarks demonstrate that DQRoute significantly
improves performance, particularly on rare and difficult classes, highlighting
the benefit of integrating difficulty modeling with decentralized expert
routing.

</details>


### [40] [Beyond BEV: Optimizing Point-Level Tokens for Collaborative Perception](https://arxiv.org/abs/2508.19638)
*Yang Li,Quan Yuan,Guiyang Luo,Xiaoyuan Fu,Rui Pan,Yujia Yang,Congzhang Shao,Yuewen Liu,Jinglin Li*

Main category: cs.CV

TL;DR: CoPLOT使用点级优化令牌（Point-Level Optimized Tokens）作为中间表示，通过点原生处理流程（包括令牌重排序、序列建模和多智能体空间对齐）来改进协作感知，解决了现有2D BEV表示丢失3D结构线索的问题。实验证明CoPLOT优于最先进的模型，同时降低了通信和计算开销。


<details>
  <summary>Details</summary>
Motivation: 现有的协作感知方法通常将中间特征组织为2D BEV表示，这会丢失精确物体识别和定位所必需的关键细粒度3D结构线索。

Method: 提出了一种名为CoPLOT的新型协作感知框架，它利用点级优化令牌（Point-Level Optimized Tokens）。该框架包含一个点原生处理流程，包括：1）一个语义感知的令牌重排序模块，通过利用场景级和令牌级的语义信息生成自适应的1D重排序；2）一个频率增强状态空间模型，用于捕捉跨空间和频谱域的长距离序列依赖关系，以提高前景令牌和背景杂波的区别；3）一个邻居到自我（neighbor-to-ego）的对齐模块，通过结合全局智能体级校正和局部令牌级优化来减轻定位噪声。

Result: CoPLOT在模拟和真实世界数据集上的大量实验表明，其性能优于最先进的模型，同时通信和计算开销更低。

Conclusion: CoPLOT通过引入点级令牌表示和创新的处理流程，有效解决了现有协作感知方法在3D结构信息保留方面的不足，并在性能和效率上均取得了优于现有技术的成果。

Abstract: Collaborative perception allows agents to enhance their perceptual
capabilities by exchanging intermediate features. Existing methods typically
organize these intermediate features as 2D bird's-eye-view (BEV)
representations, which discard critical fine-grained 3D structural cues
essential for accurate object recognition and localization. To this end, we
first introduce point-level tokens as intermediate representations for
collaborative perception. However, point-cloud data are inherently unordered,
massive, and position-sensitive, making it challenging to produce compact and
aligned point-level token sequences that preserve detailed structural
information. Therefore, we present CoPLOT, a novel Collaborative perception
framework that utilizes Point-Level Optimized Tokens. It incorporates a
point-native processing pipeline, including token reordering, sequence
modeling, and multi-agent spatial alignment. A semantic-aware token reordering
module generates adaptive 1D reorderings by leveraging scene-level and
token-level semantic information. A frequency-enhanced state space model
captures long-range sequence dependencies across both spatial and spectral
domains, improving the differentiation between foreground tokens and background
clutter. Lastly, a neighbor-to-ego alignment module applies a closed-loop
process, combining global agent-level correction with local token-level
refinement to mitigate localization noise. Extensive experiments on both
simulated and real-world datasets show that CoPLOT outperforms state-of-the-art
models, with even lower communication and computation overhead. Code will be
available at https://github.com/CheeryLeeyy/CoPLOT.

</details>


### [41] [UTAL-GNN: Unsupervised Temporal Action Localization using Graph Neural Networks](https://arxiv.org/abs/2508.19647)
*Bikash Kumar Badatya,Vipul Baghel,Ravi Hegde*

Main category: cs.CV

TL;DR: A lightweight, unsupervised skeleton-based pipeline for action localization in sports videos, using ASTGCN and a novel Action Dynamics Metric (ADM) for efficient and accurate boundary detection.


<details>
  <summary>Details</summary>
Motivation: Existing supervised and weakly supervised methods for action localization are computationally intensive and less adaptable due to reliance on large annotated datasets and high-capacity models.

Method: Pre-trains an Attention-based Spatio-Temporal Graph Convolutional Network (ASTGCN) on a pose-sequence denoising task for unsupervised learning of motion dynamics. Uses a novel Action Dynamics Metric (ADM), derived from ASTGCN embeddings, to detect motion boundaries via inflection points in its curvature profile.

Result: Achieves 82.66% mAP and 29.09 ms localization latency on the DSV Diving dataset, matching supervised methods. Generalizes to unseen footage without retraining.

Conclusion: The proposed lightweight and unsupervised pipeline offers a practical solution for real-time action analysis in diverse environments, demonstrating robustness and computational efficiency.

Abstract: Fine-grained action localization in untrimmed sports videos presents a
significant challenge due to rapid and subtle motion transitions over short
durations. Existing supervised and weakly supervised solutions often rely on
extensive annotated datasets and high-capacity models, making them
computationally intensive and less adaptable to real-world scenarios. In this
work, we introduce a lightweight and unsupervised skeleton-based action
localization pipeline that leverages spatio-temporal graph neural
representations. Our approach pre-trains an Attention-based Spatio-Temporal
Graph Convolutional Network (ASTGCN) on a pose-sequence denoising task with
blockwise partitions, enabling it to learn intrinsic motion dynamics without
any manual labeling. At inference, we define a novel Action Dynamics Metric
(ADM), computed directly from low-dimensional ASTGCN embeddings, which detects
motion boundaries by identifying inflection points in its curvature profile.
Our method achieves a mean Average Precision (mAP) of 82.66% and average
localization latency of 29.09 ms on the DSV Diving dataset, matching
state-of-the-art supervised performance while maintaining computational
efficiency. Furthermore, it generalizes robustly to unseen, in-the-wild diving
footage without retraining, demonstrating its practical applicability for
lightweight, real-time action analysis systems in embedded or dynamic
environments.

</details>


### [42] [IDF: Iterative Dynamic Filtering Networks for Generalizable Image Denoising](https://arxiv.org/abs/2508.19649)
*Dongjin Kim,Jaekyun Ko,Muhammad Kashif Ali,Tae Hyun Kim*

Main category: cs.CV

TL;DR: 深度学习图像去噪方法在面对未知的噪声类型和水平时泛化能力有限，作者提出了一种利用动态卷积核进行图像去噪的方法，该方法通过特征提取、全局统计和局部相关性来捕捉噪声特征，并逐像素生成自适应卷积核进行迭代去噪，在不依赖特定噪声分布的情况下实现了高效且高质量的去噪效果，模型小巧且泛化能力强。


<details>
  <summary>Details</summary>
Motivation: 现有的深度学习去噪方法依赖于特定的噪声分布，泛化能力差，并且容易过拟合。作者旨在提出一种能够适应不同噪声类型和水平，并且不易过拟合的图像去噪方法。

Method: 提出了一种利用动态卷积核进行图像去噪的方法。该方法包含一个特征提取模块（用于提取鲁棒的、与噪声无关的特征）、一个全局统计模块和一个局部相关性模块（用于捕捉全面的噪声特征和结构相关性），以及一个卷积核预测模块（利用这些线索生成逐像素变化的、适应局部结构的卷积核）。最后，通过迭代应用这些卷积核进行去噪。

Result: 该方法在仅使用单一水平的合成噪声进行训练的情况下，在各种不同的噪声类型和水平下都表现出色，证明了迭代动态滤波在实际图像去噪中的潜力。该模型小巧（约0.04M），能够有效防止过拟合，并提高对未知噪声的鲁棒性。

Conclusion: 作者提出的利用动态卷积核进行迭代去噪的方法，能够有效克服现有深度学习方法的局限性，实现了高效、高质量且泛化能力强的图像去噪效果。

Abstract: Image denoising is a fundamental challenge in computer vision, with
applications in photography and medical imaging. While deep learning-based
methods have shown remarkable success, their reliance on specific noise
distributions limits generalization to unseen noise types and levels. Existing
approaches attempt to address this with extensive training data and high
computational resources but they still suffer from overfitting. To address
these issues, we conduct image denoising by utilizing dynamically generated
kernels via efficient operations. This approach helps prevent overfitting and
improves resilience to unseen noise. Specifically, our method leverages a
Feature Extraction Module for robust noise-invariant features, Global
Statistics and Local Correlation Modules to capture comprehensive noise
characteristics and structural correlations. The Kernel Prediction Module then
employs these cues to produce pixel-wise varying kernels adapted to local
structures, which are then applied iteratively for denoising. This ensures both
efficiency and superior restoration quality. Despite being trained on
single-level Gaussian noise, our compact model (~ 0.04 M) excels across diverse
noise types and levels, demonstrating the promise of iterative dynamic
filtering for practical image denoising.

</details>


### [43] [Video-LevelGauge: Investigating Contextual Positional Bias in Large Video Language Models](https://arxiv.org/abs/2508.19650)
*Hou Xia,Zheren Fu,Fangcan Ling,Jiajun Li,Yi Tu,Zhendong Mao,Yongdong Zhang*

Main category: cs.CV

TL;DR: 该研究提出了Video-LevelGauge基准，用于评估大型视频语言模型（LVLMs）的位置偏见，发现许多开源模型存在头部或邻近内容偏见，而Gemini2.5-Pro表现出众。


<details>
  <summary>Details</summary>
Motivation: 评估LVLMs在视频理解中的位置偏见，该偏见是现有基准普遍忽视的关键方面。

Method: 设计了Video-LevelGauge基准，使用标准探针和定制化场景，控制上下文长度、探针位置和上下文类型，并结合统计测量和形态模式识别进行偏见分析。

Result: 在27个LVLMs的评估中，发现许多领先的开源模型存在显著的位置偏见（头部或邻近内容偏好），而Gemini2.5-Pro表现稳健。研究还揭示了上下文长度、上下文变化和模型规模对偏见的影响。

Conclusion: LVLMs存在普遍的位置偏见问题，需要通过调整模型和优化基准来解决，以实现更公平的视频理解评估。

Abstract: Large video language models (LVLMs) have made notable progress in video
understanding, spurring the development of corresponding evaluation benchmarks.
However, existing benchmarks generally assess overall performance across entire
video sequences, overlooking nuanced behaviors such as contextual positional
bias, a critical yet under-explored aspect of LVLM performance. We present
Video-LevelGauge, a dedicated benchmark designed to systematically assess
positional bias in LVLMs. We employ standardized probes and customized
contextual setups, allowing flexible control over context length, probe
position, and contextual types to simulate diverse real-world scenarios. In
addition, we introduce a comprehensive analysis method that combines
statistical measures with morphological pattern recognition to characterize
bias. Our benchmark comprises 438 manually curated videos spanning multiple
types, yielding 1,177 high-quality multiple-choice questions and 120 open-ended
questions, validated for their effectiveness in exposing positional bias. Based
on these, we evaluate 27 state-of-the-art LVLMs, including both commercial and
open-source models. Our findings reveal significant positional biases in many
leading open-source models, typically exhibiting head or neighbor-content
preferences. In contrast, commercial models such as Gemini2.5-Pro show
impressive, consistent performance across entire video sequences. Further
analyses on context length, context variation, and model scale provide
actionable insights for mitigating bias and guiding model enhancement.

</details>


### [44] [Scalable Object Detection in the Car Interior With Vision Foundation Models](https://arxiv.org/abs/2508.19651)
*Bálint Mészáros,Ahmet Firintepe,Sebastian Schmidt,Stephan Günnemann*

Main category: cs.CV

TL;DR: 该研究提出了一种名为ODAL的框架，用于在资源受限的车载系统中进行车内物体检测与定位，通过结合车内与云端计算，并引入ODALbench指标进行评估。


<details>
  <summary>Details</summary>
Motivation: 车载个人助理需要识别和定位车内物体以提升响应质量，但车载系统资源受限，难以直接部署复杂的视觉基础模型。

Method: 提出ODAL框架，采用分布式架构，将计算任务分配给车载系统和云端，并引入ODALbench作为评估指标，对比了GPT-4o和LLaVA 1.5 7B模型，并研究了微调对轻量级模型性能的影响。

Result: 微调后的ODAL-LLaVA模型达到了89%的ODAL分数，比基线模型提高了71%，并且优于GPT-4o近20%。该模型还显著减少了幻觉，ODAL_SNR是GPT-4o的三倍。

Conclusion: ODAL框架通过结合车内与云端计算，并利用微调技术，有效解决了车载系统资源受限的问题，实现了高性能的车内物体检测与定位，并展示了超越现有先进模型的潜力。

Abstract: AI tasks in the car interior like identifying and localizing externally
introduced objects is crucial for response quality of personal assistants.
However, computational resources of on-board systems remain highly constrained,
restricting the deployment of such solutions directly within the vehicle. To
address this limitation, we propose the novel Object Detection and Localization
(ODAL) framework for interior scene understanding. Our approach leverages
vision foundation models through a distributed architecture, splitting
computational tasks between on-board and cloud. This design overcomes the
resource constraints of running foundation models directly in the car. To
benchmark model performance, we introduce ODALbench, a new metric for
comprehensive assessment of detection and localization.Our analysis
demonstrates the framework's potential to establish new standards in this
domain. We compare the state-of-the-art GPT-4o vision foundation model with the
lightweight LLaVA 1.5 7B model and explore how fine-tuning enhances the
lightweight models performance. Remarkably, our fine-tuned ODAL-LLaVA model
achieves an ODAL$_{score}$ of 89%, representing a 71% improvement over its
baseline performance and outperforming GPT-4o by nearly 20%. Furthermore, the
fine-tuned model maintains high detection accuracy while significantly reducing
hallucinations, achieving an ODAL$_{SNR}$ three times higher than GPT-4o.

</details>


### [45] [Self-Rewarding Vision-Language Model via Reasoning Decomposition](https://arxiv.org/abs/2508.19652)
*Zongxia Li,Wenhao Yu,Chengsong Huang,Rui Liu,Zhenwen Liang,Fuxiao Liu,Jingxi Che,Dian Yu,Jordan Boyd-Graber,Haitao Mi,Dong Yu*

Main category: cs.CV

TL;DR: Vision-SR1是一种通过强化学习进行自我奖励的方法，无需外部视觉监督即可提高视觉推理能力，解决了视觉语言模型（VLM）中的视觉幻觉和语言捷径问题。


<details>
  <summary>Details</summary>
Motivation: 现有的视觉语言模型（VLM）后训练方法通常依赖于简单的答案匹配，并且只监督最终输出，导致中间视觉推理缺乏明确指导，使模型优先考虑基于语言的推理而非视觉感知。人工标注成本高昂，而外部蒸馏标签会导致分布偏移和奖励破解。

Method: Vision-SR1将VLM推理分解为两个阶段：视觉感知和语言推理。首先，模型生成不依赖原始图像的、自包含的视觉感知。然后，使用相同的VLM模型，仅以生成的感知作为输入进行语言推理，以计算奖励。这种自我奖励与最终输出的监督相结合，提供了平衡的训练信号。

Result: Vision-SR1在各种视觉-语言任务中提高了视觉推理能力，减少了视觉幻觉，并降低了对语言捷径的依赖。

Conclusion: Vision-SR1通过自我奖励机制，有效解决了VLM中的视觉幻觉和语言捷径问题，无需昂贵的人工标注或可能产生负面影响的外部监督。

Abstract: Vision-Language Models (VLMs) often suffer from visual hallucinations, saying
things that are not actually in the image, and language shortcuts, where they
skip the visual part and just rely on text priors. These issues arise because
most post-training methods for VLMs rely on simple verifiable answer matching
and supervise only final outputs, leaving intermediate visual reasoning without
explicit guidance. As a result, VLMs receive sparse visual signals and often
learn to prioritize language-based reasoning over visual perception. To
mitigate this, some existing methods add visual supervision using human
annotations or distilled labels from external large models. However, human
annotations are labor-intensive and costly, and because external signals cannot
adapt to the evolving policy, they cause distributional shifts that can lead to
reward hacking. In this paper, we introduce Vision-SR1, a self-rewarding method
that improves visual reasoning without relying on external visual supervisions
via reinforcement learning. Vision-SR1 decomposes VLM reasoning into two
stages: visual perception and language reasoning. The model is first prompted
to produce self-contained visual perceptions that are sufficient to answer the
question without referring back the input image. To validate this
self-containment, the same VLM model is then re-prompted to perform language
reasoning using only the generated perception as input to compute reward. This
self-reward is combined with supervision on final outputs, providing a balanced
training signal that strengthens both visual perception and language reasoning.
Our experiments demonstrate that Vision-SR1 improves visual reasoning,
mitigates visual hallucinations, and reduces reliance on language shortcuts
across diverse vision-language tasks.

</details>


### [46] [Hardware-aware vs. Hardware-agnostic Energy Estimation for SNN in Space Applications](https://arxiv.org/abs/2508.19654)
*Matthias Höfflin,Jürgen Wassner*

Main category: cs.CV

TL;DR: SNNs for satellite position estimation show comparable MSE to CNNs, but energy savings depend heavily on hardware and data sparsity, questioning their inherent energy efficiency.


<details>
  <summary>Details</summary>
Motivation: Investigate SNNs for multi-output regression (3-D satellite position estimation from monocular images) and compare hardware-aware and hardware-agnostic energy estimation methods, questioning the SNNs' reputation for energy efficiency in digital implementations.

Method: A proposed SNN using Leaky Integrate-and-Fire (LIF) neuron membrane potential in the final layer was trained and compared to a reference CNN on a satellite dataset. Hardware-aware and hardware-agnostic energy estimations were used.

Result: The SNN achieved comparable Mean Squared Error (MSE) to the CNN. Hardware-agnostic methods predicted a 50-60% energy advantage for SNNs, but hardware-aware analysis showed significant savings only on neuromorphic hardware with high input sparsity. The dark pixel ratio's influence on energy consumption was quantified.

Conclusion: Energy savings in SNNs are not inherent and depend significantly on the target hardware and data characteristics (e.g., input sparsity). Transparent evaluation methods and disclosure of assumptions are crucial for fair energy efficiency comparisons.

Abstract: Spiking Neural Networks (SNNs), inspired by biological intelligence, have
long been considered inherently energy-efficient, making them attractive for
resource-constrained domains such as space applications. However, recent
comparative studies with conventional Artificial Neural Networks (ANNs) have
begun to question this reputation, especially for digital implementations. This
work investigates SNNs for multi-output regression, specifically 3-D satellite
position estimation from monocular images, and compares hardware-aware and
hardware-agnostic energy estimation methods. The proposed SNN, trained using
the membrane potential of the Leaky Integrate-and-Fire (LIF) neuron in the
final layer, achieves comparable Mean Squared Error (MSE) to a reference
Convolutional Neural Network (CNN) on a photorealistic satellite dataset.
Energy analysis shows that while hardware-agnostic methods predict a consistent
50-60% energy advantage for SNNs over CNNs, hardware-aware analysis reveals
that significant energy savings are realized only on neuromorphic hardware and
with high input sparsity. The influence of dark pixel ratio on energy
consumption is quantified, emphasizing the impact of data characteristics and
hardware assumptions. These findings highlight the need for transparent
evaluation methods and explicit disclosure of underlying assumptions to ensure
fair comparisons of neural network energy efficiency.

</details>


### [47] [A Frequency-Aware Self-Supervised Learning for Ultra-Wide-Field Image Enhancement](https://arxiv.org/abs/2508.19664)
*Weicheng Liao,Zan Chen,Jianyang Xie,Yalin Zheng,Yuhui Ma,Yitian Zhao*

Main category: cs.CV

TL;DR: 本文提出了一种新颖的、频率感知的自监督学习方法，用于超广角（UWF）眼底图像增强，通过解耦模糊和光照补偿来提升图像质量和疾病诊断性能。


<details>
  <summary>Details</summary>
Motivation: UWF眼底成像虽然提供了全面的视网膜视图，但常受模糊和光照不均等因素影响，影响细节观察和病变检测。现有增强方法往往无法满足UWF成像在保留病变细节方面的特殊需求。

Method: 提出一种频率感知的自监督学习方法，包含频率解耦的图像去模糊模块和基于Retinex的光照补偿模块。去模糊模块采用非对称通道集成操作，结合高低频信息以保留全局和局部细节。光照补偿模块包含颜色保持单元，利用多尺度空间和频率信息进行准确的光照估计和校正。

Result: 实验结果表明，该方法不仅提高了UWF眼底图像的可视化质量，还通过恢复和校正局部细节和不均匀强度，提升了疾病诊断的性能。

Conclusion: 该研究是UWF图像增强领域的首次尝试，提供了一个稳健且具有临床价值的工具，能够改善视网膜疾病的管理。

Abstract: Ultra-Wide-Field (UWF) retinal imaging has revolutionized retinal diagnostics
by providing a comprehensive view of the retina. However, it often suffers from
quality-degrading factors such as blurring and uneven illumination, which
obscure fine details and mask pathological information. While numerous retinal
image enhancement methods have been proposed for other fundus imageries, they
often fail to address the unique requirements in UWF, particularly the need to
preserve pathological details. In this paper, we propose a novel
frequency-aware self-supervised learning method for UWF image enhancement. It
incorporates frequency-decoupled image deblurring and Retinex-guided
illumination compensation modules. An asymmetric channel integration operation
is introduced in the former module, so as to combine global and local views by
leveraging high- and low-frequency information, ensuring the preservation of
fine and broader structural details. In addition, a color preservation unit is
proposed in the latter Retinex-based module, to provide multi-scale spatial and
frequency information, enabling accurate illumination estimation and
correction. Experimental results demonstrate that the proposed work not only
enhances visualization quality but also improves disease diagnosis performance
by restoring and correcting fine local details and uneven intensity. To the
best of our knowledge, this work is the first attempt for UWF image
enhancement, offering a robust and clinically valuable tool for improving
retinal disease management.

</details>


### [48] [SAT: Supervisor Regularization and Animation Augmentation for Two-process Monocular Texture 3D Human Reconstruction](https://arxiv.org/abs/2508.19688)
*Gangjian Zhang,Jian Shu,Nanjie Yao,Hao Wang*

Main category: cs.CV

TL;DR: SAT框架通过统一学习多种先验几何形状并引入新模块来解决单目纹理3D人类重建中的几何模糊和数据稀疏性问题，实现了高质量的3D化身重建，并在实验中表现优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 单目纹理3D人类重建面临几何模糊和数据稀疏性两大挑战。现有方法在整合不同几何先验（如SMPL模型、法线图）时存在视图不一致和面部畸变等问题。

Method: 提出了一种名为SAT的两阶段3D人类重建框架。引入了Supervisor Feature Regularization模块，利用多视图网络提供中间特征进行监督，以更好地融合几何先验。同时，提出了Online Animation Augmentation模块，通过前馈动画网络在线增强3D人类数据，以应对数据稀疏性并提高重建质量。

Result: SAT框架能够统一学习多种先验几何形状，并生成高质量的纹理3D化身。实验结果表明，该方法在两个基准测试中优于最先进的方法。

Conclusion: SAT框架通过其新颖的结构和模块设计，有效地解决了单目3D人类重建中的关键挑战，显著提高了重建的质量和鲁棒性。

Abstract: Monocular texture 3D human reconstruction aims to create a complete 3D
digital avatar from just a single front-view human RGB image. However, the
geometric ambiguity inherent in a single 2D image and the scarcity of 3D human
training data are the main obstacles limiting progress in this field. To
address these issues, current methods employ prior geometric estimation
networks to derive various human geometric forms, such as the SMPL model and
normal maps. However, they struggle to integrate these modalities effectively,
leading to view inconsistencies, such as facial distortions. To this end, we
propose a two-process 3D human reconstruction framework, SAT, which seamlessly
learns various prior geometries in a unified manner and reconstructs
high-quality textured 3D avatars as the final output. To further facilitate
geometry learning, we introduce a Supervisor Feature Regularization module. By
employing a multi-view network with the same structure to provide intermediate
features as training supervision, these varied geometric priors can be better
fused. To tackle data scarcity and further improve reconstruction quality, we
also propose an Online Animation Augmentation module. By building a
one-feed-forward animation network, we augment a massive number of samples from
the original 3D human data online for model training. Extensive experiments on
two benchmarks show the superiority of our approach compared to
state-of-the-art methods.

</details>


### [49] [Synthetic Image Detection via Spectral Gaps of QC-RBIM Nishimori Bethe-Hessian Operators](https://arxiv.org/abs/2508.19698)
*V. S. Usatyuk,D. A. Sapozhnikov,S. I. Egorov*

Main category: cs.CV

TL;DR: 深度学习生成模型（如GANs和扩散网络）生成的图像与真实照片几乎无法区分，对媒体取证和生物识别安全构成威胁。本研究提出一种新颖的、不受模型约束的物理启发式检测器，将合成图像识别视为稀疏加权图上的社群检测问题。该方法通过预训练的CNN提取图像特征，并构建多边类型QC-LDPC图，利用Nishimori温度校准的边耦合形成随机键Ising模型（RBIM）。真实图像在RBIM的Bethe-Hessian谱中表现出特征性间隙，而合成图像则破坏了Nishimori对称性，缺少该间隙。该检测器在猫狗和男性女性的二分类任务上，无需标记的合成数据或特征提取器的重新训练，准确率即可达到94%以上，并且对新的生成架构具有鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 深度学习生成模型（如GANs和扩散网络）生成的图像与真实照片几乎无法区分，这对媒体取证和生物识别安全构成了威胁。现有的监督检测器在面对新的生成器或对抗性后处理时效果会迅速下降，而依赖低级统计线索的无监督方法则不够稳健。

Method: 本研究将合成图像识别问题转化为稀疏加权图上的社群检测问题。首先，使用预训练的CNN提取图像特征，并降维至32维，每个特征向量作为多边类型QC-LDPC图的节点。然后，将成对相似性转化为边耦合，并在Nishimori温度下进行校准，形成一个随机键Ising模型（RBIM）。该模型的Bethe-Hessian谱在存在真实社群结构（真实图像）时会呈现出特征性间隙，而合成图像会破坏Nishimori对称性，导致间隙消失。

Result: 在猫狗二分类任务和CelebA数据集的男性女性二分类任务上，使用真实照片和GANs及扩散模型生成的合成照片进行测试。在不进行任何标记合成数据训练或特征提取器重新训练的情况下，该检测器达到了94%以上的准确率。光谱分析显示，真实图像集具有多个清晰分开的间隙，而生成图像集的光谱则较为混乱。

Conclusion: 本研究提出了一种新颖的、不受模型约束的物理启发式合成图像检测方法，该方法将图像特征嵌入到LDPC图中，并通过RBIM的Bethe-Hessian谱分析来区分真实和合成图像。该方法具有高准确率、无需额外训练以及对新生成架构的鲁棒性等优点。未来的工作将把该框架扩展到视频流和多类异常检测。

Abstract: The rapid advance of deep generative models such as GANs and diffusion
networks now produces images that are virtually indistinguishable from genuine
photographs, undermining media forensics and biometric security. Supervised
detectors quickly lose effectiveness on unseen generators or after adversarial
post-processing, while existing unsupervised methods that rely on low-level
statistical cues remain fragile. We introduce a physics-inspired,
model-agnostic detector that treats synthetic-image identification as a
community-detection problem on a sparse weighted graph. Image features are
first extracted with pretrained CNNs and reduced to 32 dimensions, each feature
vector becomes a node of a Multi-Edge Type QC-LDPC graph. Pairwise similarities
are transformed into edge couplings calibrated at the Nishimori temperature,
producing a Random Bond Ising Model (RBIM) whose Bethe-Hessian spectrum
exhibits a characteristic gap when genuine community structure (real images) is
present. Synthetic images violate the Nishimori symmetry and therefore lack
such gaps. We validate the approach on binary tasks cat versus dog and male
versus female using real photos from Flickr-Faces-HQ and CelebA and synthetic
counterparts generated by GANs and diffusion models. Without any labeled
synthetic data or retraining of the feature extractor, the detector achieves
over 94% accuracy. Spectral analysis shows multiple well separated gaps for
real image sets and a collapsed spectrum for generated ones. Our contributions
are threefold: a novel LDPC graph construction that embeds deep image features,
an analytical link between Nishimori temperature RBIM and the Bethe-Hessian
spectrum providing a Bayes optimal detection criterion; and a practical,
unsupervised synthetic image detector robust to new generative architectures.
Future work will extend the framework to video streams and multi-class anomaly
detection.

</details>


### [50] [LabelGS: Label-Aware 3D Gaussian Splatting for 3D Scene Segmentation](https://arxiv.org/abs/2508.19699)
*Yupeng Zhang,Dezhi Zheng,Ping Lu,Han Zhang,Lei Wang,Liping xiang,Cheng Luo,Kaijun Deng,Xiaowen Fu,Linlin Shen,Jinbao Wang*

Main category: cs.CV

TL;DR: LabelGS通过引入标签感知来增强3D高斯泼溅（3DGS）以实现3D场景分割，通过跨视图一致的语义蒙版、遮挡分析模型、高斯标签模型和高斯投影过滤器来提高性能和效率，并在3D场景分割任务中优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 3DGS在3D场景重建和渲染方面表现出色，但缺乏3D分割能力，限制了其在需要场景理解方面的应用。

Method: LabelGS通过引入跨视图一致的语义蒙版、遮挡分析模型、高斯标签模型和高斯投影过滤器来增强3D高斯表示，并采用随机区域采样策略来提高优化效率。

Result: LabelGS在3D场景分割任务上取得了最先进的成果，与Feature-3DGS相比，在1440x1080分辨率下实现了22倍的训练加速。

Conclusion: LabelGS成功地将标签信息集成到3DGS中，实现了高效的3D场景分割，并显著提高了训练速度。

Abstract: 3D Gaussian Splatting (3DGS) has emerged as a novel explicit representation
for 3D scenes, offering both high-fidelity reconstruction and efficient
rendering. However, 3DGS lacks 3D segmentation ability, which limits its
applicability in tasks that require scene understanding. The identification and
isolating of specific object components is crucial. To address this limitation,
we propose Label-aware 3D Gaussian Splatting (LabelGS), a method that augments
the Gaussian representation with object label.LabelGS introduces cross-view
consistent semantic masks for 3D Gaussians and employs a novel Occlusion
Analysis Model to avoid overfitting occlusion during optimization, Main
Gaussian Labeling model to lift 2D semantic prior to 3D Gaussian and Gaussian
Projection Filter to avoid Gaussian label conflict. Our approach achieves
effective decoupling of Gaussian representations and refines the 3DGS
optimization process through a random region sampling strategy, significantly
improving efficiency. Extensive experiments demonstrate that LabelGS
outperforms previous state-of-the-art methods, including Feature-3DGS, in the
3D scene segmentation task. Notably, LabelGS achieves a remarkable 22X speedup
in training compared to Feature-3DGS, at a resolution of 1440X1080. Our code
will be at https://github.com/garrisonz/LabelGS.

</details>


### [51] [FreeVPS: Repurposing Training-Free SAM2 for Generalizable Video Polyp Segmentation](https://arxiv.org/abs/2508.19705)
*Qiang Hu,Ying Zhou,Gepeng Ji,Nick Barnes,Qiang Li,Zhiwei Wang*

Main category: cs.CV

TL;DR: 该论文提出了一种名为FreeVPS的视频多发性息肉分割（VPS）新范式，通过结合图像多发性息肉分割（IPS）的空间上下文和SAM2模型的时间建模能力来解决现有VPS方法的局限性。为了解决SAM2在长期跟踪中出现的误差累积问题，论文引入了两个无需训练的模块：一个是在检测阶段消除空间不准确性的内部关联过滤模块，另一个是防止误差随时间传播的外部关联细化模块。这两个模块协同工作，提高了SAM2的稳定性，并在各种场景下实现了先进的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的视频多发性息肉分割（VPS）方法在时空建模和域泛化之间难以平衡，限制了其在真实临床场景中的应用。特别是在结肠镜视频的长期息肉跟踪中，SAM2模型容易出现误差累积，导致分割不稳定。

Method: 文章将VPS任务重新构建为一种“跟踪-检测”范式，利用IPS模型捕捉的空间上下文，并整合SAM2模型的时间建模能力。为了解决SAM2在长期跟踪中误差累积的问题，论文提出了两个无需训练的模块：1. 内部关联过滤模块：消除检测阶段产生的空间不准确性，减少假阳性。2. 外部关联细化模块：自适应地更新记忆库，防止误差随时间传播，增强时间连贯性。

Result: 通过引入内部关联过滤和外部关联细化模块，FreeVPS稳定了SAM2模型，在领域内和领域外场景下均取得了领先性能。此外，该方法在未剪辑的长结肠镜视频中展现了强大的跟踪能力，证明了其在可靠临床分析方面的潜力。

Conclusion: FreeVPS通过其创新的“跟踪-检测”范式和两个无需训练的模块，有效解决了现有VPS方法的局限性，在时空建模和域泛化方面取得了显著进展，为临床息肉分析提供了可靠的解决方案。

Abstract: Existing video polyp segmentation (VPS) paradigms usually struggle to balance
between spatiotemporal modeling and domain generalization, limiting their
applicability in real clinical scenarios. To embrace this challenge, we recast
the VPS task as a track-by-detect paradigm that leverages the spatial contexts
captured by the image polyp segmentation (IPS) model while integrating the
temporal modeling capabilities of segment anything model 2 (SAM2). However,
during long-term polyp tracking in colonoscopy videos, SAM2 suffers from error
accumulation, resulting in a snowball effect that compromises segmentation
stability. We mitigate this issue by repurposing SAM2 as a video polyp
segmenter with two training-free modules. In particular, the intra-association
filtering module eliminates spatial inaccuracies originating from the detecting
stage, reducing false positives. The inter-association refinement module
adaptively updates the memory bank to prevent error propagation over time,
enhancing temporal coherence. Both modules work synergistically to stabilize
SAM2, achieving cutting-edge performance in both in-domain and out-of-domain
scenarios. Furthermore, we demonstrate the robust tracking capabilities of
FreeVPS in long-untrimmed colonoscopy videos, underscoring its potential
reliable clinical analysis.

</details>


### [52] [Improving Generalization in Deepfake Detection with Face Foundation Models and Metric Learning](https://arxiv.org/abs/2508.19730)
*Stelios Mylonas,Symeon Papadopoulos*

Main category: cs.CV

TL;DR: 为应对深度伪造（deepfake）媒体内容日益严峻的真实性和完整性挑战，本文提出了一种基于面部基础模型（face foundation models）的面部表征学习的鲁棒视频深度伪造检测框架。该框架利用自监督模型FSFM在真实人脸数据上进行训练，并通过包含多种操纵类型（如人脸交换和人脸重现）的深度伪造数据集进行微调。为增强模型区分能力，引入了三元组损失（triplet loss）变体，以学习更具可分离性的真实与伪造样本嵌入。此外，研究还探索了基于归因的监督方法，通过按操纵类型或源数据集对深度伪造内容进行分类，以评估其对模型泛化能力的影响。大量实验结果表明，该方法在各种评估基准和具有挑战性的真实世界场景中均表现出优越的性能。


<details>
  <summary>Details</summary>
Motivation: 深度伪造（deepfake）的日益逼真和易获取性引发了对媒体真实性和信息完整性的严重关切。尽管近期研究取得了进展，但深度伪造检测模型在应用于现实世界媒体内容时，往往难以在训练分布之外实现良好的泛化。

Method: 本文提出了一种基于面部基础模型（face foundation models）的面部表征学习的鲁棒视频深度伪造检测框架。该框架基于自监督模型FSFM，在真实人脸数据上进行训练，并通过多样的深度伪造数据集（涵盖人脸交换和人脸重现操纵）进行微调。为提升判别能力，引入了三元组损失（triplet loss）变体，以学习更具可分离性的真实与伪造样本嵌入。此外，还探索了基于归因的监督方法，将深度伪造按操纵类型或源数据集进行分类，以评估其对泛化能力的影响。

Result: 在多样化的评估基准上进行的广泛实验表明，本文提出的方法能够有效提升视频深度伪造检测的性能，特别是在应对具有挑战性的真实世界场景时，展现出强大的泛化能力。

Conclusion: 所提出的鲁棒视频深度伪造检测框架，利用面部基础模型学习到的丰富面部表征，并通过结合三元组损失和归因监督策略，能够有效提高模型在不同数据集和真实世界场景下的泛化能力，为解决深度伪造问题提供了有前景的解决方案。

Abstract: The increasing realism and accessibility of deepfakes have raised critical
concerns about media authenticity and information integrity. Despite recent
advances, deepfake detection models often struggle to generalize beyond their
training distributions, particularly when applied to media content found in the
wild. In this work, we present a robust video deepfake detection framework with
strong generalization that takes advantage of the rich facial representations
learned by face foundation models. Our method is built on top of FSFM, a
self-supervised model trained on real face data, and is further fine-tuned
using an ensemble of deepfake datasets spanning both face-swapping and
face-reenactment manipulations. To enhance discriminative power, we incorporate
triplet loss variants during training, guiding the model to produce more
separable embeddings between real and fake samples. Additionally, we explore
attribution-based supervision schemes, where deepfakes are categorized by
manipulation type or source dataset, to assess their impact on generalization.
Extensive experiments across diverse evaluation benchmarks demonstrate the
effectiveness of our approach, especially in challenging real-world scenarios.

</details>


### [53] [POEv2: a flexible and robust framework for generic line segment detection and wireframe line segment detection](https://arxiv.org/abs/2508.19742)
*Chenguang Liu,Chisheng Wang,Yuhua Cai,Chuanhua Zhu,Qingquan Li*

Main category: cs.CV

TL;DR: 该论文提出了一种名为POEv2的新型线段检测框架，该框架能够同时用于通用线段检测和线架线段检测，并在实验中取得了先进的性能。


<details>
  <summary>Details</summary>
Motivation: 现有线段检测器分为通用线段检测器和线架线段检测器，它们各有局限性，无法满足不同场景的需求。

Method: 提出了一种名为POEv2的改进型像素方向估计（POE）方法，该方法从边缘强度图检测线段，并可与任何边缘检测器结合。

Result: 将POEv2与高效的边缘检测器结合，在三个公开数据集上实现了先进的性能。

Conclusion: POEv2是一个鲁棒的框架，可同时用于通用线段检测和线架线段检测，并能取得优于现有方法的性能。

Abstract: Line segment detection in images has been studied for several decades.
Existing line segment detectors can be roughly divided into two categories:
generic line segment detectors and wireframe line segment detectors. Generic
line segment detectors aim to detect all meaningful line segments in images and
traditional approaches usually fall into this category. Recent deep learning
based approaches are mostly wireframe line segment detectors. They detect only
line segments that are geometrically meaningful and have large spatial support.
Due to the difference in the aim of design, the performance of generic line
segment detectors for the task of wireframe line segment detection won't be
satisfactory, and vice versa. In this work, we propose a robust framework that
can be used for both generic line segment detection and wireframe line segment
detection. The proposed method is an improved version of the Pixel Orientation
Estimation (POE) method. It is thus named as POEv2. POEv2 detects line segments
from edge strength maps, and can be combined with any edge detector. We show in
our experiments that by combining the proposed POEv2 with an efficient edge
detector, it achieves state-of-the-art performance on three publicly available
datasets.

</details>


### [54] [SPLF-SAM: Self-Prompting Segment Anything Model for Light Field Salient Object Detection](https://arxiv.org/abs/2508.19746)
*Qiyao Xu,Qiming Wu,Xiaowei Li*

Main category: cs.CV

TL;DR: SPLF-SAM是一个新模型，用于解决光场显着目标检测问题，它包含UMFEB和MAFA，可以识别不同大小的对象并过滤噪声。


<details>
  <summary>Details</summary>
Motivation: 现有模型在光场显着目标检测任务中忽略了提示信息的提取，并且忽略了频域信息分析，导致小物体被噪声淹没。

Method: 提出了一种名为SPLF-SAM的新模型，该模型配备了统一的多尺度特征嵌入块（UMFEB）和多尺度自适应滤波适配器（MAFA）。UMFEB能够识别不同大小的多个对象，而MAFA通过学习频域特征，可以有效防止小物体被噪声淹没。

Result: 实验证明，SPLF-SAM在光场显着目标检测方面优于十种最先进的方法。

Conclusion: SPLF-SAM在光场显着目标检测任务中表现出色，能够处理不同大小的对象并有效过滤噪声。

Abstract: Segment Anything Model (SAM) has demonstrated remarkable capabilities in
solving light field salient object detection (LF SOD). However, most existing
models tend to neglect the extraction of prompt information under this task.
Meanwhile, traditional models ignore the analysis of frequency-domain
information, which leads to small objects being overwhelmed by noise. In this
paper, we put forward a novel model called self-prompting light field segment
anything model (SPLF-SAM), equipped with unified multi-scale feature embedding
block (UMFEB) and a multi-scale adaptive filtering adapter (MAFA). UMFEB is
capable of identifying multiple objects of varying sizes, while MAFA, by
learning frequency features, effectively prevents small objects from being
overwhelmed by noise. Extensive experiments have demonstrated the superiority
of our method over ten state-of-the-art (SOTA) LF SOD methods. Our code will be
available at https://github.com/XucherCH/splfsam.

</details>


### [55] [FastAvatar: Towards Unified Fast High-Fidelity 3D Avatar Reconstruction with Large Gaussian Reconstruction Transformers](https://arxiv.org/abs/2508.19754)
*Yue Wu,Yufan Wu,Wen Li,Yuxi Lu,Kairui Feng,Xuanhong Chen*

Main category: cs.CV

TL;DR: FastAvatar是一个创新的3D化身重建框架，能从单张图像、多视角或单目视频等多种数据中，在几秒钟内利用单个统一模型重建高质量的3D高斯泼溅（3DGS）模型。


<details>
  <summary>Details</summary>
Motivation: 现有3D化身重建技术存在时间复杂度高、对数据质量敏感、数据利用率低等问题。

Method: FastAvatar的核心是一个大型高斯重建Transformer，包含三个关键设计：1. VGGT风格的Transformer架构，聚合多帧线索并注入初始3D提示，以预测可聚合的规范3DGS表示；2. 多粒度引导编码（相机姿态、FLAME表情、头部姿态），减轻动画引起的错位问题；3. 通过地标跟踪和切片融合损失进行增量高斯聚合，实现增量重建，能随着更多观测数据的增加而提高质量。

Result: 实验表明，FastAvatar的质量更高，速度与现有方法相比具有很强的竞争力。

Conclusion: FastAvatar提出了一种质量-速度可调的范式，实现了高效易用的化身建模，并能有效利用各种日常录制数据。

Abstract: Despite significant progress in 3D avatar reconstruction, it still faces
challenges such as high time complexity, sensitivity to data quality, and low
data utilization. We propose FastAvatar, a feedforward 3D avatar framework
capable of flexibly leveraging diverse daily recordings (e.g., a single image,
multi-view observations, or monocular video) to reconstruct a high-quality 3D
Gaussian Splatting (3DGS) model within seconds, using only a single unified
model. FastAvatar's core is a Large Gaussian Reconstruction Transformer
featuring three key designs: First, a variant VGGT-style transformer
architecture aggregating multi-frame cues while injecting initial 3D prompt to
predict an aggregatable canonical 3DGS representation; Second, multi-granular
guidance encoding (camera pose, FLAME expression, head pose) mitigating
animation-induced misalignment for variable-length inputs; Third, incremental
Gaussian aggregation via landmark tracking and sliced fusion losses.
Integrating these features, FastAvatar enables incremental reconstruction,
i.e., improving quality with more observations, unlike prior work wasting input
data. This yields a quality-speed-tunable paradigm for highly usable avatar
modeling. Extensive experiments show that FastAvatar has higher quality and
highly competitive speed compared to existing methods.

</details>


### [56] [BuzzSet v1.0: A Dataset for Pollinator Detection in Field Conditions](https://arxiv.org/abs/2508.19762)
*Ahmed Emam,Mohamed Elbassiouny,Julius Miller,Patrick Donworth,Sabine Seidel,Ribana Roscher*

Main category: cs.CV

TL;DR: BuzzSet是一个包含7856张图像的大规模数据集，用于监测蜜蜂和熊蜂等授粉昆虫。该数据集有助于开发自动化的授粉昆虫监测系统，已实现高F1分数（分别为0.94和0.92）和良好的检测质量（mAP@0.50为0.559）。


<details>
  <summary>Details</summary>
Motivation: 由于传粉昆虫数量的下降，为了支持可扩展的、自动化的传粉昆虫监测，我们引入了一个新的大规模数据集BuzzSet，该数据集包含在真实的农业田野条件下收集的高分辨率传粉昆虫图像。

Method: BuzzSet包含7856张经过手动验证和标记的图像，包含三个类别：蜜蜂、熊蜂和未识别的昆虫，其中有8000多个实例。初始标注使用在外部数据上训练的YOLOv12模型生成，并通过使用开源标注工具的人工验证进行优化。所有图像都预处理成256x256的图块，以提高对小型昆虫的检测能力。我们使用基于RF-DETR Transformer的目标检测器提供了强大的基线。

Result: 所提出的RF-DETR模型在蜜蜂和熊蜂类别上分别达到了0.94和0.92的高F1分数，混淆矩阵结果显示这些类别之间的误分类极少。未识别类别由于标签歧义和较低的样本频率而更具挑战性，但仍为鲁棒性评估提供了有用的见解。总体检测质量良好，最佳mAP@0.50为0.559。

Conclusion: BuzzSet为小型物体检测、标签噪声下的类别分离以及生态计算机视觉提供了一个有价值的基准。

Abstract: Pollinator insects such as honeybees and bumblebees are vital to global food
production and ecosystem stability, yet their populations are declining due to
increasing anthropogenic and environmental stressors. To support scalable,
automated pollinator monitoring, we introduce BuzzSet, a new large-scale
dataset of high-resolution pollinator images collected in real agricultural
field conditions. BuzzSet contains 7856 manually verified and labeled images,
with over 8000 annotated instances across three classes: honeybees, bumblebees,
and unidentified insects. Initial annotations were generated using a YOLOv12
model trained on external data and refined via human verification using
open-source labeling tools. All images were preprocessed into 256~$\times$~256
tiles to improve the detection of small insects. We provide strong baselines
using the RF-DETR transformer-based object detector. The model achieves high
F1-scores of 0.94 and 0.92 for honeybee and bumblebee classes, respectively,
with confusion matrix results showing minimal misclassification between these
categories. The unidentified class remains more challenging due to label
ambiguity and lower sample frequency, yet still contributes useful insights for
robustness evaluation. Overall detection quality is strong, with a best
mAP@0.50 of 0.559. BuzzSet offers a valuable benchmark for small object
detection, class separation under label noise, and ecological computer vision.

</details>


### [57] [AIM: Adaptive Intra-Network Modulation for Balanced Multimodal Learning](https://arxiv.org/abs/2508.19769)
*Shu Shen,C. L. Philip Chen,Tong Zhang*

Main category: cs.CV

TL;DR: 文章提出了一种名为AIM（Adaptive Intra-Network Modulation）的新方法，用于解决多模态学习中的数据不平衡问题。AIM通过分析网络内部的优化偏差，首次实现了在不损害主导模态和弱势模态学习的前提下，平衡多模态学习。AIM将主导模态中优化不足的参数分离到辅助模块中，并与弱势模态联合训练，同时根据网络深度自适应地调整调制强度。实验证明，AIM在多个基准测试中优于现有方法，并具有良好的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有的不平衡多模态学习方法通常通过抑制主导模态来促进弱势模态，这会影响整体性能。文章旨在解决这一问题。

Method: 提出了一种名为AIM（Adaptive Intra-Network Modulation）的新方法。AIM通过分析网络内部的优化偏差，将主导模态中优化不足的参数分离到辅助模块中，并与弱势模态联合训练，同时根据网络深度自适应地调整调制强度。

Result: AIM在多个基准测试中优于现有不平衡多模态学习方法，并展现出良好的泛化能力，适用于不同的骨干网络、融合策略和优化器。

Conclusion: AIM是一种有效的新方法，可以解决不平衡多模态学习中的优化偏差问题，首次实现了在不损害任何模态学习的前提下进行平衡，并取得了优于现有方法的性能。

Abstract: Multimodal learning has significantly enhanced machine learning performance
but still faces numerous challenges and limitations. Imbalanced multimodal
learning is one of the problems extensively studied in recent works and is
typically mitigated by modulating the learning of each modality. However, we
find that these methods typically hinder the dominant modality's learning to
promote weaker modalities, which affects overall multimodal performance. We
analyze the cause of this issue and highlight a commonly overlooked problem:
optimization bias within networks. To address this, we propose Adaptive
Intra-Network Modulation (AIM) to improve balanced modality learning. AIM
accounts for differences in optimization state across parameters and depths
within the network during modulation, achieving balanced multimodal learning
without hindering either dominant or weak modalities for the first time.
Specifically, AIM decouples the dominant modality's under-optimized parameters
into Auxiliary Blocks and encourages reliance on these performance-degraded
blocks for joint training with weaker modalities. This approach effectively
prevents suppression of weaker modalities while enabling targeted optimization
of under-optimized parameters to improve the dominant modality. Additionally,
AIM assesses modality imbalance level across network depths and adaptively
adjusts modulation strength at each depth. Experimental results demonstrate
that AIM outperforms state-of-the-art imbalanced modality learning methods
across multiple benchmarks and exhibits strong generalizability across
different backbones, fusion strategies, and optimizers.

</details>


### [58] [The Return of Structural Handwritten Mathematical Expression Recognition](https://arxiv.org/abs/2508.19773)
*Jakob Seitz,Tobias Lengfeld,Radu Timofte*

Main category: cs.CV

TL;DR: 手写数学表达式识别的结构化方法，提供符号到轨迹的显式对齐，用于可解释性和交互式应用。


<details>
  <summary>Details</summary>
Motivation: 现有的基于大型语言模型的编码器-解码器架构在LaTeX生成方面表现出色，但缺乏符号到轨迹的显式对齐，这限制了错误分析、可解释性和需要选择性内容更新的空间感知交互式应用。

Method: 提出一种结构化识别方法，包括一个使用神经网络将LaTeX方程映射到原始轨迹的自动标注系统，以及一个独立优化分割、分类和关系预测的模块化结构化识别系统。该系统结合了基于图的轨迹排序、混合卷积循环网络和基于Transformer的校正。

Result: 该方法在CROHME-2023基准测试上取得了有竞争力的性能，并生成了连接手写轨迹和预测符号的完整图结构，实现了透明的错误分析和可解释的输出。

Conclusion: 所提出的结构化识别方法通过提供符号到轨迹的显式对齐，克服了现有方法的局限性，并在手写数学表达式识别任务中实现了可解释和透明的错误分析。

Abstract: Handwritten Mathematical Expression Recognition is foundational for
educational technologies, enabling applications like digital note-taking and
automated grading. While modern encoder-decoder architectures with large
language models excel at LaTeX generation, they lack explicit symbol-to-trace
alignment, a critical limitation for error analysis, interpretability, and
spatially aware interactive applications requiring selective content updates.
This paper introduces a structural recognition approach with two innovations: 1
an automatic annotation system that uses a neural network to map LaTeX
equations to raw traces, automatically generating annotations for symbol
segmentation, classification, and spatial relations, and 2 a modular structural
recognition system that independently optimizes segmentation, classification,
and relation prediction. By leveraging a dataset enriched with structural
annotations from our auto-labeling system, the proposed recognition system
combines graph-based trace sorting, a hybrid convolutional-recurrent network,
and transformer-based correction to achieve competitive performance on the
CROHME-2023 benchmark. Crucially, our structural recognition system generates a
complete graph structure that directly links handwritten traces to predicted
symbols, enabling transparent error analysis and interpretable outputs.

</details>


### [59] [MAPo : Motion-Aware Partitioning of Deformable 3D Gaussian Splatting for High-Fidelity Dynamic Scene Reconstruction](https://arxiv.org/abs/2508.19786)
*Han Jiao,Jiakai Sun,Yexing Xu,Lei Zhao,Wei Xing,Huaizhong Lin*

Main category: cs.CV

TL;DR: 3D高斯泼溅（3DGS）技术在动态场景重建中的应用面临挑战，现有基于变形的方法易导致模糊和细节丢失。本文提出的MAPo框架通过动态分数驱动的分割策略，区分高动态和低动态高斯，并对高动态高斯进行时域递归分割和重复变形网络，以捕捉精细运动细节。同时，为解决分割边界的视觉不连续性，引入了跨帧一致性损失。实验证明，MAPo在复杂运动区域具有更高的渲染质量和相当的计算成本。


<details>
  <summary>Details</summary>
Motivation: 现有基于变形的3D高斯泼溅方法在动态场景重建中存在渲染模糊和丢失运动细节的问题，尤其是在高度动态的区域，这是由于单一模型难以处理多样化的运动模式。

Method: MAPo框架采用动态分数驱动的分割策略，将3D高斯分为高动态和低动态两类。高动态高斯进行时域递归分割，并为每个时间段复制其变形网络以进行专门建模；低动态高斯则视为静态以降低计算成本。为解决分割边界的视觉不连续性，引入了跨帧一致性损失。

Result: MAPo在复杂或快速运动区域实现了优于基线方法的渲染质量，同时保持了可比的计算成本。

Conclusion: MAPo框架通过其新颖的动态分割和跨帧一致性策略，有效解决了现有3D高斯泼溅方法在动态场景重建中的局限性，实现了高保真度的动态场景重建，尤其在处理复杂运动方面表现出色。

Abstract: 3D Gaussian Splatting, known for enabling high-quality static scene
reconstruction with fast rendering, is increasingly being applied to dynamic
scene reconstruction. A common strategy involves learning a deformation field
to model the temporal changes of a canonical set of 3D Gaussians. However,
these deformation-based methods often produce blurred renderings and lose fine
motion details in highly dynamic regions due to the inherent limitations of a
single, unified model in representing diverse motion patterns. To address these
challenges, we introduce Motion-Aware Partitioning of Deformable 3D Gaussian
Splatting (MAPo), a novel framework for high-fidelity dynamic scene
reconstruction. Its core is a dynamic score-based partitioning strategy that
distinguishes between high- and low-dynamic 3D Gaussians. For high-dynamic 3D
Gaussians, we recursively partition them temporally and duplicate their
deformation networks for each new temporal segment, enabling specialized
modeling to capture intricate motion details. Concurrently, low-dynamic 3DGs
are treated as static to reduce computational costs. However, this temporal
partitioning strategy for high-dynamic 3DGs can introduce visual
discontinuities across frames at the partition boundaries. To address this, we
introduce a cross-frame consistency loss, which not only ensures visual
continuity but also further enhances rendering quality. Extensive experiments
demonstrate that MAPo achieves superior rendering quality compared to baselines
while maintaining comparable computational costs, particularly in regions with
complex or rapid motions.

</details>


### [60] [StableIntrinsic: Detail-preserving One-step Diffusion Model for Multi-view Material Estimation](https://arxiv.org/abs/2508.19789)
*Xiuchao Wu,Pengfei Zhu,Jiangjing Lyu,Xinguo Liu,Jie Guo,Yanwen Guo,Weiwei Xu,Chengfei Lyu*

Main category: cs.CV

TL;DR: StableIntrinsic是一个用于多视图材质估计的单步扩散模型，通过像素空间损失和细节注入网络解决了多步扩散方法耗时和结果方差大的问题，并在PSNR和MSE方面取得了显著改进。


<details>
  <summary>Details</summary>
Motivation: 现有的基于扩散模型的材质估计方法通常采用多步去噪策略，导致估计过程耗时且结果方差较大，与确定性的材质估计任务存在冲突。

Method: StableIntrinsic采用单步扩散模型，并在像素空间引入了基于材质特性的损失函数，同时利用细节注入网络（DIN）来恢复VAE编码过程中可能丢失的细节并增强预测结果的清晰度。

Result: 实验结果表明，StableIntrinsic在反照率（albedo）的峰值信噪比（PSNR）方面提高了9.9%，在金属度（metallic）和粗糙度（roughness）的均方误差（MSE）方面分别降低了44.4%和60.0%，优于当前最先进的技术。

Conclusion: StableIntrinsic通过单步扩散、像素空间损失和细节注入网络，成功实现了高质量、低方差的多视图材质估计，并在多项关键指标上超越了现有方法。

Abstract: Recovering material information from images has been extensively studied in
computer graphics and vision. Recent works in material estimation leverage
diffusion model showing promising results. However, these diffusion-based
methods adopt a multi-step denoising strategy, which is time-consuming for each
estimation. Such stochastic inference also conflicts with the deterministic
material estimation task, leading to a high variance estimated results. In this
paper, we introduce StableIntrinsic, a one-step diffusion model for multi-view
material estimation that can produce high-quality material parameters with low
variance. To address the overly-smoothing problem in one-step diffusion,
StableIntrinsic applies losses in pixel space, with each loss designed based on
the properties of the material. Additionally, StableIntrinsic introduces a
Detail Injection Network (DIN) to eliminate the detail loss caused by VAE
encoding, while further enhancing the sharpness of material prediction results.
The experimental results indicate that our method surpasses the current
state-of-the-art techniques by achieving a $9.9\%$ improvement in the Peak
Signal-to-Noise Ratio (PSNR) of albedo, and by reducing the Mean Square Error
(MSE) for metallic and roughness by $44.4\%$ and $60.0\%$, respectively.

</details>


### [61] [Not Every Gift Comes in Gold Paper or with a Red Ribbon: Exploring Color Perception in Text-to-Image Models](https://arxiv.org/abs/2508.19791)
*Shay Shomer Chai,Wenxuan Peng,Bharath Hariharan,Hadar Averbuch-Elor*

Main category: cs.CV

TL;DR: 现有文本到图像生成方法难以处理包含多个颜色属性的复杂文本，导致生成图像在颜色方面存在语义偏差。本文提出了一种新的图像编辑技术，专门用于解决多颜色属性文本提示的语义对齐问题，并在多项指标上显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 当前文本到图像生成技术在处理包含多个颜色属性的复杂文本提示时存在困难，容易导致生成图像在颜色方面与文本描述不符。现有方法（如修改注意力层）和评估指标（如CLIP相似度或人工评估）存在不足，难以有效解决或大规模衡量此类问题。

Method: 本文首先通过案例研究，分析了预训练模型在处理多颜色属性提示时的不足，并验证了现有推断时和编辑方法未能有效解决语义偏差。在此基础上，本文提出了一种新的图像编辑技术，专门用于解决多颜色属性文本提示的语义对齐问题。

Result: 所提出的图像编辑技术在处理包含多个颜色属性的文本提示时，能够显著提升生成图像在颜色方面的准确性，并在多种评估指标上表现优于现有技术，包括不同文本到图像扩散模型生成的图像。

Conclusion: 本文提出了一种有效的图像编辑方法，能够解决现有文本到图像生成技术在处理多颜色属性提示时遇到的语义对齐挑战，并在实验中证明了其优越性。

Abstract: Text-to-image generation has recently seen remarkable success, granting users
with the ability to create high-quality images through the use of text.
However, contemporary methods face challenges in capturing the precise
semantics conveyed by complex multi-object prompts. Consequently, many works
have sought to mitigate such semantic misalignments, typically via
inference-time schemes that modify the attention layers of the denoising
networks. However, prior work has mostly utilized coarse metrics, such as the
cosine similarity between text and image CLIP embeddings, or human evaluations,
which are challenging to conduct on a larger-scale. In this work, we perform a
case study on colors -- a fundamental attribute commonly associated with
objects in text prompts, which offer a rich test bed for rigorous evaluation.
Our analysis reveals that pretrained models struggle to generate images that
faithfully reflect multiple color attributes-far more so than with single-color
prompts-and that neither inference-time techniques nor existing editing methods
reliably resolve these semantic misalignments. Accordingly, we introduce a
dedicated image editing technique, mitigating the issue of multi-object
semantic alignment for prompts containing multiple colors. We demonstrate that
our approach significantly boosts performance over a wide range of metrics,
considering images generated by various text-to-image diffusion-based
techniques.

</details>


### [62] [FusionSort: Enhanced Cluttered Waste Segmentation with Advanced Decoding and Comprehensive Modality Optimization](https://arxiv.org/abs/2508.19798)
*Muhammad Ali,Omar Ali AlSuwaidi*

Main category: cs.CV

TL;DR: 提出了一种改进的Encoder-Decoder架构，通过引入Comprehensive Attention Block、Mamba架构和Data Fusion Block，提升了垃圾分类的准确性和效率，并在多种数据类型上验证了其优越性。


<details>
  <summary>Details</summary>
Motivation: 为了应对非生物降解材料垃圾分类过程中因废物流的复杂性和多变性带来的挑战，需要提高垃圾分类系统的准确性和效率。

Method: 提出了一种改进的Encoder-Decoder架构，包括在decoder中加入Comprehensive Attention Block（结合卷积和上采样操作），利用Mamba架构引入注意力机制，以及设计Data Fusion Block来融合多通道图像（通过PCA降维处理）。

Result: 所提出的模型在RGB、高光谱、多光谱以及RGB和高光谱组合数据上进行了评估，结果显示其性能显著优于现有方法。

Conclusion: 该研究提出的增强型神经网络架构在垃圾分类任务上取得了显著的改进，证明了其在处理复杂废物流方面的有效性。

Abstract: In the realm of waste management, automating the sorting process for
non-biodegradable materials presents considerable challenges due to the
complexity and variability of waste streams. To address these challenges, we
introduce an enhanced neural architecture that builds upon an existing
Encoder-Decoder structure to improve the accuracy and efficiency of waste
sorting systems. Our model integrates several key innovations: a Comprehensive
Attention Block within the decoder, which refines feature representations by
combining convolutional and upsampling operations. In parallel, we utilize
attention through the Mamba architecture, providing an additional performance
boost. We also introduce a Data Fusion Block that fuses images with more than
three channels. To achieve this, we apply PCA transformation to reduce the
dimensionality while retaining the maximum variance and essential information
across three dimensions, which are then used for further processing. We
evaluated the model on RGB, hyperspectral, multispectral, and a combination of
RGB and hyperspectral data. The results demonstrate that our approach
outperforms existing methods by a significant margin.

</details>


### [63] [A bag of tricks for real-time Mitotic Figure detection](https://arxiv.org/abs/2508.19804)
*Christian Marzahl,Brian Napora*

Main category: cs.CV

TL;DR: 该研究提出了一套用于病理图像中细胞分裂象（MF）检测的训练技巧，以应对不同设备、染色和组织类型带来的挑战。该方法基于RTMDet模型，通过多领域数据训练、采样平衡、数据增强以及难例挖掘来提高鲁棒性和准确性，最终在MIDOG 2025挑战赛预测试集中取得了0.81 F1分数，展现了良好的泛化能力和临床应用潜力。


<details>
  <summary>Details</summary>
Motivation: 病理图像中的细胞分裂象（MF）检测面临扫描设备、染色方案、组织类型和伪影等方面的巨大挑战，需要鲁棒且实时的检测方法以适应临床需求。

Method: 该研究基于单阶段目标检测器RTMDet，提出了一系列训练技巧（“tricks”），包括利用广泛的多领域训练数据、平衡采样、仔细的数据增强以及针对坏死和碎片组织的硬负例挖掘，以实现跨领域的鲁棒、实时MF检测。

Result: 在跨多个MF数据集的5折交叉验证中，该模型实现了0.78至0.84的F1分数。在MIDOG 2025挑战赛的预测试集中，基于RTMDet-S的模型达到了0.81的F1分数，优于更大模型，并证明了其对新、未知领域的适应性。

Conclusion: 该研究提出的训练技巧集能够实现跨领域的鲁棒、实时MF检测，在准确性和速度之间取得了实际的平衡，为临床应用提供了有吸引力的解决方案。

Abstract: Mitotic figure (MF) detection in histopathology images is challenging due to
large variations in slide scanners, staining protocols, tissue types, and the
presence of artifacts. This paper presents a collection of training techniques
- a bag of tricks - that enable robust, real-time MF detection across diverse
domains. We build on the efficient RTMDet single stage object detector to
achieve high inference speed suitable for clinical deployment. Our method
addresses scanner variability and tumor heterogeneity via extensive
multi-domain training data, balanced sampling, and careful augmentation.
Additionally, we employ targeted, hard negative mining on necrotic and debris
tissue to reduce false positives. In a grouped 5-fold cross-validation across
multiple MF datasets, our model achieves an F1 score between 0.78 and 0.84. On
the preliminary test set of the MItosis DOmain Generalization (MIDOG) 2025
challenge, our single-stage RTMDet-S based approach reaches an F1 of 0.81,
outperforming larger models and demonstrating adaptability to new, unfamiliar
domains. The proposed solution offers a practical trade-off between accuracy
and speed, making it attractive for real-world clinical adoption.

</details>


### [64] [AutoQ-VIS: Improving Unsupervised Video Instance Segmentation via Automatic Quality Assessment](https://arxiv.org/abs/2508.19808)
*Kaixuan Lu,Mehmet Onurcan Kaya,Dim P. Papadopoulos*

Main category: cs.CV

TL;DR: AutoQ-VIS是一个新颖的无监督框架，通过质量引导的自训练解决了视频实例分割（VIS）中的标注挑战，实现了从合成到真实视频的渐进式适应，并在YouTubeVIS-2019验证集上取得了52.6 AP50的SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 视频实例分割（VIS）由于同时需要像素级掩码和时间一致性标签，因此在标注方面存在重大挑战。现有的无监督方法虽然消除了对光流的依赖，但仍受限于合成到真实世界的域迁移问题。

Method: 提出了一种名为AutoQ-VIS的新颖无监督框架，该框架通过质量引导的自训练来弥合合成到真实世界的域迁移差距。该方法在伪标签生成和自动质量评估之间建立了一个闭环系统，实现了从合成到真实视频的渐进式适应。

Result: 在YouTubeVIS-2019验证集上取得了52.6 AP50的性能，比之前的SOTA方法VideoCutLER提高了4.4%，并且不需要任何人工标注。

Conclusion: 质量感知自训练对于无监督VIS是可行的。

Abstract: Video Instance Segmentation (VIS) faces significant annotation challenges due
to its dual requirements of pixel-level masks and temporal consistency labels.
While recent unsupervised methods like VideoCutLER eliminate optical flow
dependencies through synthetic data, they remain constrained by the
synthetic-to-real domain gap. We present AutoQ-VIS, a novel unsupervised
framework that bridges this gap through quality-guided self-training. Our
approach establishes a closed-loop system between pseudo-label generation and
automatic quality assessment, enabling progressive adaptation from synthetic to
real videos. Experiments demonstrate state-of-the-art performance with 52.6
$\text{AP}_{50}$ on YouTubeVIS-2019 val set, surpassing the previous
state-of-the-art VideoCutLER by 4.4$\%$, while requiring no human annotations.
This demonstrates the viability of quality-aware self-training for unsupervised
VIS. The source code of our method is available at
https://github.com/wcbup/AutoQ-VIS.

</details>


### [65] [ERSR: An Ellipse-constrained pseudo-label refinement and symmetric regularization framework for semi-supervised fetal head segmentation in ultrasound images](https://arxiv.org/abs/2508.19815)
*Linkuan Zhou,Zhexin Chen,Yufei Shen,Junlin Xu,Ping Xuan,Yixin Zhu,Yuqi Fang,Cong Cong,Leyi Wei,Ran Su,Jia Zhou,Qiangguo Jin*

Main category: cs.CV

TL;DR: 提出ERSR框架用于胎儿头部超声分割，解决了数据标注不足和图像质量差的问题。


<details>
  <summary>Details</summary>
Motivation: 自动化胎儿头部超声分割在产前监测中至关重要，但超声图像质量差和标注数据缺乏带来了挑战。现有的半监督方法在处理胎儿头部超声图像的特性时，生成可靠伪标签和强制一致性正则化方面存在困难。

Method: 提出ERSR框架，包含双评分自适应滤波策略、椭圆约束伪标签优化以及基于对称性的多重一致性正则化。双评分策略通过边界一致性和轮廓规则性评估和过滤教师输出。椭圆约束优化通过拟合最小二乘椭圆来优化伪标签，同时强化拟合椭圆中心附近的像素并抑制噪声。基于对称性的多重一致性正则化通过扰动图像、对称区域以及原始预测和伪标签之间的多层次一致性，促使模型捕捉鲁棒且稳定的形状表示。

Result: 在HC18数据集上，使用10%和20%的标注数据，ERSR分别达到92.05%和95.36%的Dice分数。在PSFH数据集上，相同设置下的分数分别为91.68%和93.70%，达到了最先进的性能。

Conclusion: ERSR框架通过创新的策略有效解决了胎儿头部超声分割中的挑战，并在两个基准数据集上取得了优越的性能。

Abstract: Automated segmentation of the fetal head in ultrasound images is critical for
prenatal monitoring. However, achieving robust segmentation remains challenging
due to the poor quality of ultrasound images and the lack of annotated data.
Semi-supervised methods alleviate the lack of annotated data but struggle with
the unique characteristics of fetal head ultrasound images, making it
challenging to generate reliable pseudo-labels and enforce effective
consistency regularization constraints. To address this issue, we propose a
novel semi-supervised framework, ERSR, for fetal head ultrasound segmentation.
Our framework consists of the dual-scoring adaptive filtering strategy, the
ellipse-constrained pseudo-label refinement, and the symmetry-based multiple
consistency regularization. The dual-scoring adaptive filtering strategy uses
boundary consistency and contour regularity criteria to evaluate and filter
teacher outputs. The ellipse-constrained pseudo-label refinement refines these
filtered outputs by fitting least-squares ellipses, which strengthens pixels
near the center of the fitted ellipse and suppresses noise simultaneously. The
symmetry-based multiple consistency regularization enforces multi-level
consistency across perturbed images, symmetric regions, and between original
predictions and pseudo-labels, enabling the model to capture robust and stable
shape representations. Our method achieves state-of-the-art performance on two
benchmarks. On the HC18 dataset, it reaches Dice scores of 92.05% and 95.36%
with 10% and 20% labeled data, respectively. On the PSFH dataset, the scores
are 91.68% and 93.70% under the same settings.

</details>


### [66] [Gradient Rectification for Robust Calibration under Distribution Shift](https://arxiv.org/abs/2508.19830)
*Yilin Zhang,Cai Xu,You Wu,Ziyu Guan,Wei Zhao*

Main category: cs.CV

TL;DR: 深度神经网络在分布偏移下校准不准的问题，提出一种无需目标域信息即可操作的校准框架，通过低频滤波和梯度校正机制，在提高分布外校准的同时保持分布内性能。


<details>
  <summary>Details</summary>
Motivation: 深度神经网络在安全关键应用中往往会产生过度自信的预测，这会削弱其可靠性。在测试数据因环境或采集变化而偏离训练分布的分布偏移下，这种校准不准的问题会更加严重。现有方法依赖于目标域的访问或模拟，这在实际应用中限制了其实用性。

Method: 提出一种无需目标域信息即可操作的校准框架。从频域角度识别出分布偏移会扭曲深度模型利用的高频视觉线索，并引入低频滤波策略来鼓励模型依赖于域不变特征。为解决信息丢失可能导致的分布内校准性能下降问题，提出一种基于梯度的校正机制，在优化过程中强制执行分布内校准作为硬约束。

Result: 在 CIFAR-10/100-C 和 WILDS 等合成和真实世界的偏移数据集上进行了实验。

Conclusion: 所提出的方法显著提高了在分布偏移下的校准性能，同时保持了强大的分布内性能。

Abstract: Deep neural networks often produce overconfident predictions, undermining
their reliability in safety-critical applications. This miscalibration is
further exacerbated under distribution shift, where test data deviates from the
training distribution due to environmental or acquisition changes. While
existing approaches improve calibration through training-time regularization or
post-hoc adjustment, their reliance on access to or simulation of target
domains limits their practicality in real-world scenarios. In this paper, we
propose a novel calibration framework that operates without access to target
domain information. From a frequency-domain perspective, we identify that
distribution shifts often distort high-frequency visual cues exploited by deep
models, and introduce a low-frequency filtering strategy to encourage reliance
on domain-invariant features. However, such information loss may degrade
In-Distribution (ID) calibration performance. Therefore, we further propose a
gradient-based rectification mechanism that enforces ID calibration as a hard
constraint during optimization. Experiments on synthetic and real-world shifted
datasets, including CIFAR-10/100-C and WILDS, demonstrate that our method
significantly improves calibration under distribution shift while maintaining
strong in-distribution performance.

</details>


### [67] [KRETA: A Benchmark for Korean Reading and Reasoning in Text-Rich VQA Attuned to Diverse Visual Contexts](https://arxiv.org/abs/2508.19944)
*Taebaek Hwang,Minseo Kim,Gisang Lee,Seonuk Kim,Hyunjun Eun*

Main category: cs.CV

TL;DR: KRETA是一个针对韩语的文本丰富型视觉问答基准，用于评估视觉语言模型（VLMs）在理解和推理文本方面的能力。


<details>
  <summary>Details</summary>
Motivation: 现有的文本丰富型视觉问答（VQA）数据集主要集中在高资源语言（如英语）上，而低资源语言（如韩语）缺乏此类基准，阻碍了模型的鲁棒评估和比较。KRETA旨在弥合这一差距，为韩语提供一个全面的基准。

Method: KRETA基准包含针对15个领域和26种图像类型的多样化视觉内容。研究人员开发了一个半自动化的VQA生成流程，该流程经过优化，可处理文本丰富的场景，并采用精细的图像分解和严格的七项指标评估协议来确保数据质量。该流程旨在适应性和可扩展性，以便为其他语言创建类似的基准。

Result: KRETA基准能够对韩语的视觉文本理解和推理能力进行深入评估，并支持跨15个领域和26种图像类型的多方面评估。

Conclusion: KRETA填补了低资源语言在文本丰富型VQA领域的空白，为韩语VLM评估提供了关键资源。所提出的生成流程具有普适性，有望促进其他语言的类似基准的开发，从而推动多语言VLM的研究。

Abstract: Understanding and reasoning over text within visual contexts poses a
significant challenge for Vision-Language Models (VLMs), given the complexity
and diversity of real-world scenarios. To address this challenge, text-rich
Visual Question Answering (VQA) datasets and benchmarks have emerged for
high-resource languages like English. However, a critical gap persists for
low-resource languages such as Korean, where the lack of comprehensive
benchmarks hinders robust model evaluation and comparison. To bridge this gap,
we introduce KRETA, a benchmark for Korean Reading and rEasoning in Text-rich
VQA Attuned to diverse visual contexts. KRETA facilitates an in-depth
evaluation of both visual text understanding and reasoning capabilities, while
also supporting a multifaceted assessment across 15 domains and 26 image types.
Additionally, we introduce a semi-automated VQA generation pipeline
specifically optimized for text-rich settings, leveraging refined stepwise
image decomposition and a rigorous seven-metric evaluation protocol to ensure
data quality. While KRETA is tailored for Korean, we hope our adaptable and
extensible pipeline will facilitate the development of similar benchmarks in
other languages, thereby accelerating multilingual VLM research. The code and
dataset for KRETA are available at https://github.com/tabtoyou/KRETA.

</details>


### [68] [Image Quality Assessment for Machines: Paradigm, Large-scale Database, and Models](https://arxiv.org/abs/2508.19850)
*Xiaoqi Wang,Yun Zhang,Weisi Lin*

Main category: cs.CV

TL;DR: 本文提出了一种机器视觉系统（MVS）图像质量评估（MIQA）框架，并构建了包含250万样本的MIQD数据库，以及一个名为RA-MIQA的区域感知模型。实验证明RA-MIQA在MVS性能预测方面优于基于人眼视觉系统（HVS）的指标，并揭示了现有HVS指标和一些MIQA模型的局限性。


<details>
  <summary>Details</summary>
Motivation: 解决机器学习视觉系统（MVS）在不利视觉条件下性能下降的问题，量化图像退化对MVS性能的影响。

Method: 提出了一种端到端的机器中心图像质量评估（MIQA）范式，构建了包含250万样本的机器中心图像质量数据库（MIQD），并提出了一个名为RA-MIQA的区域感知MIQA模型，通过细粒度的空间退化分析来评估MVS的视觉质量。

Result: RA-MIQA在一致性和准确性指标上均优于7个基于HVS的IQA指标和5个经典骨干网络。例如，在图像分类任务中，RA-MIQA在一致性方面提高了13.56%，在准确性方面提高了13.37%。实验还发现，基于HVS的指标不足以预测MVS质量，并且一些专门的MIQA模型在处理背景退化、面向准确性的估计和细微失真方面存在困难。

Conclusion: 该研究通过提出MIQA框架和RA-MIQA模型，提高了MVS的可靠性，并为机器中心图像处理和优化奠定了基础。同时，研究也指出了当前MVS质量评估方法（包括HVS指标和部分MIQA模型）的局限性。

Abstract: Machine vision systems (MVS) are intrinsically vulnerable to performance
degradation under adverse visual conditions. To address this, we propose a
machine-centric image quality assessment (MIQA) framework that quantifies the
impact of image degradations on MVS performance. We establish an MIQA paradigm
encompassing the end-to-end assessment workflow. To support this, we construct
a machine-centric image quality database (MIQD-2.5M), comprising 2.5 million
samples that capture distinctive degradation responses in both consistency and
accuracy metrics, spanning 75 vision models, 250 degradation types, and three
representative vision tasks. We further propose a region-aware MIQA (RA-MIQA)
model to evaluate MVS visual quality through fine-grained spatial degradation
analysis. Extensive experiments benchmark the proposed RA-MIQA against seven
human visual system (HVS)-based IQA metrics and five retrained classical
backbones. Results demonstrate RA-MIQA's superior performance in multiple
dimensions, e.g., achieving SRCC gains of 13.56% on consistency and 13.37% on
accuracy for image classification, while also revealing task-specific
degradation sensitivities. Critically, HVS-based metrics prove inadequate for
MVS quality prediction, while even specialized MIQA models struggle with
background degradations, accuracy-oriented estimation, and subtle distortions.
This study can advance MVS reliability and establish foundations for
machine-centric image processing and optimization. The model and code are
available at: https://github.com/XiaoqiWang/MIQA.

</details>


### [69] [GLSim: Detecting Object Hallucinations in LVLMs via Global-Local Similarity](https://arxiv.org/abs/2508.19972)
*Seongheon Park,Yixuan Li*

Main category: cs.CV

TL;DR: GLSim通过结合全局和局部嵌入相似性信号，提高了视觉-语言模型中对象幻觉检测的准确性和可靠性。


<details>
  <summary>Details</summary>
Motivation: 对象幻觉在大型视觉-语言模型中是一个严峻的挑战，限制了其在现实世界中的安全部署。现有的对象幻觉评分方法通常只关注全局或局部视角，可能影响检测的可靠性。

Method: 提出了一种名为GLSim的新型、无需训练的对象幻觉检测框架，该框架利用图像和文本模态之间互补的全局和局部嵌入相似性信号。

Result: GLSim在各项基准测试中表现出色，其检测性能优于现有的方法，并显著超越了竞争对手。

Conclusion: GLSim通过整合全局和局部嵌入相似性信号，提供了一种更准确、更可靠的对象幻觉检测方法，能够应对各种场景。

Abstract: Object hallucination in large vision-language models presents a significant
challenge to their safe deployment in real-world applications. Recent works
have proposed object-level hallucination scores to estimate the likelihood of
object hallucination; however, these methods typically adopt either a global or
local perspective in isolation, which may limit detection reliability. In this
paper, we introduce GLSim, a novel training-free object hallucination detection
framework that leverages complementary global and local embedding similarity
signals between image and text modalities, enabling more accurate and reliable
hallucination detection in diverse scenarios. We comprehensively benchmark
existing object hallucination detection methods and demonstrate that GLSim
achieves superior detection performance, outperforming competitive baselines by
a significant margin.

</details>


### [70] [Ego-centric Predictive Model Conditioned on Hand Trajectories](https://arxiv.org/abs/2508.19852)
*Binjie Zhang,Mike Zheng Shou*

Main category: cs.CV

TL;DR: 该研究提出了一种统一的预测框架，用于同时预测以自身为中心的场景中的未来动作及其视觉结果。


<details>
  <summary>Details</summary>
Motivation: 现有方法无法同时有效地模拟动作和视觉场景的相互影响，该研究旨在解决这一问题。

Method: 提出一个两阶段的预测框架：第一阶段处理异构输入（视觉观察、语言、动作历史）并预测手部轨迹；第二阶段引入因果交叉注意力机制，利用推断的动作信号指导基于图像的潜在扩散模型（LDM）进行视频生成。

Result: 该方法在Ego4D、BridgeData和RLBench数据集上进行了广泛实验，证明在动作预测和未来视频合成方面优于现有最先进的方法。

Conclusion: 该研究提出了首个能够同时处理以自身为中心的活动理解和机器人操作任务的统一模型，能够显式预测即将到来的动作及其视觉后果。

Abstract: In egocentric scenarios, anticipating both the next action and its visual
outcome is essential for understanding human-object interactions and for
enabling robotic planning. However, existing paradigms fall short of jointly
modeling these aspects. Vision-Language-Action (VLA) models focus on action
prediction but lack explicit modeling of how actions influence the visual
scene, while video prediction models generate future frames without
conditioning on specific actions, often resulting in implausible or
contextually inconsistent outcomes. To bridge this gap, we propose a unified
two-stage predictive framework that jointly models action and visual future in
egocentric scenarios, conditioned on hand trajectories. In the first stage, we
perform consecutive state modeling to process heterogeneous inputs (visual
observations, language, and action history) and explicitly predict future hand
trajectories. In the second stage, we introduce causal cross-attention to fuse
multi-modal cues, leveraging inferred action signals to guide an image-based
Latent Diffusion Model (LDM) for frame-by-frame future video generation. Our
approach is the first unified model designed to handle both egocentric human
activity understanding and robotic manipulation tasks, providing explicit
predictions of both upcoming actions and their visual consequences. Extensive
experiments on Ego4D, BridgeData, and RLBench demonstrate that our method
outperforms state-of-the-art baselines in both action prediction and future
video synthesis.

</details>


### [71] [Multimodal Conditional MeshGAN for Personalized Aneurysm Growth Prediction](https://arxiv.org/abs/2508.19862)
*Long Chen,Ashiv Patel,Mengyun Qiao,Mohammad Yousuf Salmasi,Salah A. Hammouche,Vasilis Stavrinides,Jasleen Nagi,Soodeh Kalaie,Xiao Yun Xu,Wenjia Bai,Declan P. O'Regan*

Main category: cs.CV

TL;DR: MCMeshGAN是一个创新的多模态条件生成对抗网络，用于预测主动脉瘤的3D生长，通过结合局部KNN卷积网络和全局图卷积网络来精确捕捉几何细节和长期结构上下文，并在TAAMesh数据集上实现了优于现有方法的性能。


<details>
  <summary>Details</summary>
Motivation: 个性化、精确地预测主动脉瘤进展对于及时干预至关重要，但由于需要模拟复杂的3D几何形状内的细微局部变形和整体解剖结构变化，因此仍然具有挑战性。

Method: 提出了一种名为MCMeshGAN的多模态条件网格到网格生成对抗网络。该网络采用双分支结构，结合了新颖的基于KNN的局部卷积网络（KCN）以保留细粒度的几何细节，以及全局图卷积网络（GCN）来捕捉长程结构上下文，克服了深度GCN的过度平滑限制。此外，还有一个专门的条件分支，用于编码临床属性（年龄、性别）和目标时间间隔，以生成在解剖学上合理且受时间控制的预测，从而能够进行回顾性和前瞻性建模。

Result: 在包含590个多模态记录（CT扫描、3D网格和临床数据）的208名患者的纵向胸主动脉瘤网格数据集（TAAMesh）上进行了广泛的实验。结果表明，MCMeshGAN在几何精度和临床上重要直径估计方面始终优于最先进的基线方法。

Conclusion: MCMeshGAN提供了一个强大的框架，朝着临床应用和个性化3D疾病轨迹建模迈出了重要一步。

Abstract: Personalized, accurate prediction of aortic aneurysm progression is essential
for timely intervention but remains challenging due to the need to model both
subtle local deformations and global anatomical changes within complex 3D
geometries. We propose MCMeshGAN, the first multimodal conditional mesh-to-mesh
generative adversarial network for 3D aneurysm growth prediction. MCMeshGAN
introduces a dual-branch architecture combining a novel local KNN-based
convolutional network (KCN) to preserve fine-grained geometric details and a
global graph convolutional network (GCN) to capture long-range structural
context, overcoming the over-smoothing limitations of deep GCNs. A dedicated
condition branch encodes clinical attributes (age, sex) and the target time
interval to generate anatomically plausible, temporally controlled predictions,
enabling retrospective and prospective modeling. We curated TAAMesh, a new
longitudinal thoracic aortic aneurysm mesh dataset consisting of 590 multimodal
records (CT scans, 3D meshes, and clinical data) from 208 patients. Extensive
experiments demonstrate that MCMeshGAN consistently outperforms
state-of-the-art baselines in both geometric accuracy and clinically important
diameter estimation. This framework offers a robust step toward clinically
deployable, personalized 3D disease trajectory modeling. The source code for
MCMeshGAN and the baseline methods is publicly available at
https://github.com/ImperialCollegeLondon/MCMeshGAN.

</details>


### [72] [Self-supervised structured object representation learning](https://arxiv.org/abs/2508.19864)
*Oussama Hadjerci,Antoine Letienne,Mohamed Abbas Hedjazi,Adel Hafiane*

Main category: cs.CV

TL;DR: 提出了一种新的自监督学习方法，用于构建结构化的视觉表征，优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有自监督学习方法在全局图像理解方面表现良好，但在捕捉场景结构化表征方面存在局限性。

Method: 提出了一种自监督方法，通过语义分组、实例级分离和分层结构化来逐步构建结构化视觉表征。该方法基于新颖的ProtoScale模块，能够跨多个空间尺度捕捉视觉元素，并保留完整的场景上下文，以提高密集预测任务的性能。

Result: 在目标检测任务上进行了验证，实验结果表明该方法学习到的以物体为中心的表征能够提升监督式目标检测的性能，并且在有限的标注数据和较少的微调轮数下优于最先进的方法。

Conclusion: 所提出的自监督方法能够学习到更优的结构化视觉表征，尤其在密集预测任务和目标检测方面具有优势。

Abstract: Self-supervised learning (SSL) has emerged as a powerful technique for
learning visual representations. While recent SSL approaches achieve strong
results in global image understanding, they are limited in capturing the
structured representation in scenes. In this work, we propose a self-supervised
approach that progressively builds structured visual representations by
combining semantic grouping, instance level separation, and hierarchical
structuring. Our approach, based on a novel ProtoScale module, captures visual
elements across multiple spatial scales. Unlike common strategies like DINO
that rely on random cropping and global embeddings, we preserve full scene
context across augmented views to improve performance in dense prediction
tasks. We validate our method on downstream object detection tasks using a
combined subset of multiple datasets (COCO and UA-DETRAC). Experimental results
show that our method learns object centric representations that enhance
supervised object detection and outperform the state-of-the-art methods, even
when trained with limited annotated data and fewer fine-tuning epochs.

</details>


### [73] [TrajFusionNet: Pedestrian Crossing Intention Prediction via Fusion of Sequential and Visual Trajectory Representations](https://arxiv.org/abs/2508.19866)
*François G. Landry,Moulay A. Akhloufi*

Main category: cs.CV

TL;DR: TrajFusionNet是一个基于Transformer的新模型，通过结合行人轨迹和车辆速度预测，提高了行人横穿意图的预测精度，同时推理速度快，在三个常用数据集上都取得了最先进的成果。


<details>
  <summary>Details</summary>
Motivation: 随着自动驾驶汽车在公共道路上的普及，预测行人横穿意图已成为一项重要的研究课题，以确保行人和车辆的安全。

Method: 提出了一种名为TrajFusionNet的新型Transformer模型，该模型包含一个序列注意力模块（SAM）和一个视觉注意力模块（VAM）。SAM从观察到和预测的行人轨迹以及车辆速度的序列表示中学习，而VAM则通过将预测的行人边界框叠加到场景图像上来学习视觉表示。

Result: TrajFusionNet实现了当前最先进方法中最低的总推理时间，并在三个最常用的行人横穿意图预测数据集上取得了最先进的性能。

Conclusion: TrajFusionNet通过结合未来行人轨迹和车辆速度预测，有效提高了行人横穿意图的预测精度，同时保持了较低的推理时间，是一种很有前景的方法。

Abstract: With the introduction of vehicles with autonomous capabilities on public
roads, predicting pedestrian crossing intention has emerged as an active area
of research. The task of predicting pedestrian crossing intention involves
determining whether pedestrians in the scene are likely to cross the road or
not. In this work, we propose TrajFusionNet, a novel transformer-based model
that combines future pedestrian trajectory and vehicle speed predictions as
priors for predicting crossing intention. TrajFusionNet comprises two branches:
a Sequence Attention Module (SAM) and a Visual Attention Module (VAM). The SAM
branch learns from a sequential representation of the observed and predicted
pedestrian trajectory and vehicle speed. Complementarily, the VAM branch
enables learning from a visual representation of the predicted pedestrian
trajectory by overlaying predicted pedestrian bounding boxes onto scene images.
By utilizing a small number of lightweight modalities, TrajFusionNet achieves
the lowest total inference time (including model runtime and data
preprocessing) among current state-of-the-art approaches. In terms of
performance, it achieves state-of-the-art results across the three most
commonly used datasets for pedestrian crossing intention prediction.

</details>


### [74] [Sky Background Building of Multi-objective Fiber spectra Based on Mutual Information Network](https://arxiv.org/abs/2508.19875)
*Hui Zhang,Jianghui Cai,Haifeng Yang,Ali Luo,Yuqing Yang,Xiao Kong,Zhichao Ding,Lichan Zhou,Qin Han*

Main category: cs.CV

TL;DR: SMI是一种基于互信息和增量训练的新的天体背景估计模型，它利用来自同一视场中所有光纤的光谱来估计天体背景，解决了传统方法的局限性。


<details>
  <summary>Details</summary>
Motivation: 传统的天体背景扣除方法依赖于天空光纤光谱来构建超级天空，但这种方法未能充分模拟目标周围的环境，限制了其在光谱分析中的准确性。

Method: SMI模型包含两个主要网络：第一个网络应用波长校准模块提取光谱特征，并解决特征偏移问题；第二个网络采用增量训练方法，最大化不同光谱表示之间的互信息以捕捉共同成分，同时最小化相邻光谱表示之间的互信息以获得个体成分，从而为每个目标位置生成个体天体背景。

Result: 在LAMOST光谱数据集上的实验表明，SMI模型能够获得更好的目标天体背景，尤其是在光谱的蓝端，证明了该方法的有效性。

Conclusion: SMI模型通过利用同一视场中的所有光谱信息，并结合互信息和增量训练策略，能够更准确地估计天体背景，特别是在蓝端光谱区域，为多目标光谱处理提供了改进的方法。

Abstract: Sky background subtraction is a critical step in Multi-objective Fiber
spectra process. However, current subtraction relies mainly on sky fiber
spectra to build Super Sky. These average spectra are lacking in the modeling
of the environment surrounding the objects. To address this issue, a sky
background estimation model: Sky background building based on Mutual
Information (SMI) is proposed. SMI based on mutual information and incremental
training approach. It utilizes spectra from all fibers in the plate to estimate
the sky background. SMI contains two main networks, the first network applies a
wavelength calibration module to extract sky features from spectra, and can
effectively solve the feature shift problem according to the corresponding
emission position. The second network employs an incremental training approach
to maximize mutual information between representations of different spectra to
capturing the common component. Then, it minimizes the mutual information
between adjoining spectra representations to obtain individual components. This
network yields an individual sky background at each location of the object. To
verify the effectiveness of the method in this paper, we conducted experiments
on the spectra of LAMOST. Results show that SMI can obtain a better object sky
background during the observation, especially in the blue end.

</details>


### [75] [Multispectral LiDAR data for extracting tree points in urban and suburban areas](https://arxiv.org/abs/2508.19881)
*Narges Takhtkeshha,Gabriele Mazzacca,Fabio Remondino,Juha Hyyppä,Gottfried Mandlburger*

Main category: cs.CV

TL;DR: 利用多光谱LiDAR和深度学习模型（SPT、PTv3、PTv1）进行城市树木提取，SPT模型在效率和准确性方面表现突出（mIoU为85.28%），结合pNDVI和空间数据可进一步提高检测精度。


<details>
  <summary>Details</summary>
Motivation: 为了支持城市绿化政策和降低对电力基础设施的风险，监测城市树木动态至关重要。虽然机载激光扫描技术在树木管理方面取得了进展，但在复杂的城市环境中和面对多样的树木时仍面临挑战。

Method: 本研究探索使用多光谱（MS）激光雷达（LiDAR）和深度学习（DL）模型进行树木点提取，并评估了三种先进的模型：Superpoint Transformer (SPT)、Point Transformer V3 (PTv3) 和 Point Transformer V1 (PTv1)。

Result: 研究结果表明，SPT模型具有显著的时间效率和准确性，平均交并比（mIoU）达到85.28%。将伪归一化差异植被指数（pNDVI）与空间数据相结合，可以将检测准确率相比仅使用空间信息的方法提高，错误率降低10.61个百分点（pp）。

Conclusion: 研究结果凸显了多光谱LiDAR和深度学习在改进树木提取和完善树木清单方面的潜力。

Abstract: Monitoring urban tree dynamics is vital for supporting greening policies and
reducing risks to electrical infrastructure. Airborne laser scanning has
advanced large-scale tree management, but challenges remain due to complex
urban environments and tree variability. Multispectral (MS) light detection and
ranging (LiDAR) improves this by capturing both 3D spatial and spectral data,
enabling detailed mapping. This study explores tree point extraction using
MS-LiDAR and deep learning (DL) models. Three state-of-the-art models are
evaluated: Superpoint Transformer (SPT), Point Transformer V3 (PTv3), and Point
Transformer V1 (PTv1). Results show the notable time efficiency and accuracy of
SPT, with a mean intersection over union (mIoU) of 85.28%. The highest
detection accuracy is achieved by incorporating pseudo normalized difference
vegetation index (pNDVI) with spatial data, reducing error rate by 10.61
percentage points (pp) compared to using spatial information alone. These
findings highlight the potential of MS-LiDAR and DL to improve tree extraction
and further tree inventories.

</details>


### [76] [PersonaAnimator: Personalized Motion Transfer from Unconstrained Videos](https://arxiv.org/abs/2508.19895)
*Ziyun Qian,Runyu Xiao,Shuyuan Tu,Wei Xue,Dingkang Yang,Mingcheng Li,Dongliang Kou,Minghao Han,Zizhi Chen,Lihua Zhang*

Main category: cs.CV

TL;DR: 该论文提出了一种新的视频到视频动作个性化任务，并开发了一个名为PersonaAnimator的框架，该框架可以直接从无约束视频中学习个性化动作模式，解决了现有动作迁移方法缺乏风格学习、依赖动作捕捉数据以及生成动作违反物理定律的问题。同时，论文还发布了首个基于视频的个性化动作数据集PersonaVid，并提出了一种物理感知动作风格正则化机制以增强生成动作的物理合理性。实验结果表明，PersonaAnimator在动作迁移方面优于现有最先进的方法。


<details>
  <summary>Details</summary>
Motivation: 现有姿态引导的动作迁移方法仅能复制动作而无法学习其风格特征，导致角色缺乏表现力；动作风格迁移方法严重依赖难以获取的动作捕捉数据；生成的动作有时会违反物理定律。为了解决这些挑战，本文提出视频到视频动作个性化这一新任务。

Method: 提出PersonaAnimator框架，可以直接从无约束视频中学习个性化动作模式，实现个性化动作迁移。发布PersonaVid数据集，这是首个基于视频的个性化动作数据集，包含20个动作内容类别和120个动作风格类别。提出物理感知动作风格正则化机制，强制执行生成动作的物理合理性。

Result: PersonaAnimator在动作迁移方面优于现有最先进的方法，并为视频到视频动作个性化任务树立了新的标杆。

Conclusion: PersonaAnimator通过直接从视频中学习个性化动作模式，有效解决了现有动作迁移方法的局限性，并在动作风格化和物理合理性方面取得了显著进展。PersonaVid数据集和物理感知动作风格正则化机制为该领域的研究提供了重要支持。

Abstract: Recent advances in motion generation show remarkable progress. However,
several limitations remain: (1) Existing pose-guided character motion transfer
methods merely replicate motion without learning its style characteristics,
resulting in inexpressive characters. (2) Motion style transfer methods rely
heavily on motion capture data, which is difficult to obtain. (3) Generated
motions sometimes violate physical laws. To address these challenges, this
paper pioneers a new task: Video-to-Video Motion Personalization. We propose a
novel framework, PersonaAnimator, which learns personalized motion patterns
directly from unconstrained videos. This enables personalized motion transfer.
To support this task, we introduce PersonaVid, the first video-based
personalized motion dataset. It contains 20 motion content categories and 120
motion style categories. We further propose a Physics-aware Motion Style
Regularization mechanism to enforce physical plausibility in the generated
motions. Extensive experiments show that PersonaAnimator outperforms
state-of-the-art motion transfer methods and sets a new benchmark for the
Video-to-Video Motion Personalization task.

</details>


### [77] [Streamlining the Development of Active Learning Methods in Real-World Object Detection](https://arxiv.org/abs/2508.19906)
*Moussa Kassem Sbeyti,Nadja Klein,Michelle Karg,Christian Wirth,Sahin Albayrak*

Main category: cs.CV

TL;DR: 该论文提出了一种名为对象集相似性（OSS）的新指标，以解决真实世界物体检测中主动学习（AL）面临的计算和可靠性挑战。OSS 无需训练检测器即可量化 AL 方法的有效性，并有助于选择有代表性的验证集以进行稳健评估，从而在计算效率和评估可靠性至关重要时，为在真实应用中部署 AL 提供了一个实用的框架。


<details>
  <summary>Details</summary>
Motivation: 真实世界物体检测中的主动学习（AL）面临计算和可靠性挑战，限制了其实际应用。目前需要训练多个检测器来评估新的 AL 方法，这在自动驾驶数据集上成本高昂（单个检测器训练高达 282 GPU 小时）。此外，AL 方法的排名因验证集而异，影响了安全关键的交通系统的可靠性。

Method: 提出对象集相似性（OSS）指标，该指标通过测量训练集与目标域之间基于对象级特征的相似性来量化 AL 方法的有效性，无需进行检测器训练，从而可以在训练前排除无效的 AL 方法。OSS 还有助于选择有代表性的验证集以进行稳健评估。该方法在 KITTI、BDD100K 和 CODA 三个自动驾驶数据集上进行了验证，并以不确定性为基础的 AL 方法和 EfficientDet、YOLOv3 两种检测器架构为案例研究。

Result: OSS 指标无需训练检测器即可量化 AL 方法的有效性，并能选择有代表性的验证集以进行稳健评估。该方法在三个自动驾驶数据集上进行了验证，表明其在计算效率和评估可靠性方面优于现有方法。

Conclusion: OSS 指标为在真实应用中部署 AL 提供了一个实用的框架，解决了计算效率和评估可靠性方面的关键问题。该指标是物体检测领域第一个基于对象相似性统一 AL 训练和评估策略的工作，具有检测器无关、仅需标注的对象裁剪以及易于与现有 AL 流水线集成等优点。

Abstract: Active learning (AL) for real-world object detection faces computational and
reliability challenges that limit practical deployment. Developing new AL
methods requires training multiple detectors across iterations to compare
against existing approaches. This creates high costs for autonomous driving
datasets where the training of one detector requires up to 282 GPU hours.
Additionally, AL method rankings vary substantially across validation sets,
compromising reliability in safety-critical transportation systems. We
introduce object-based set similarity ($\mathrm{OSS}$), a metric that addresses
these challenges. $\mathrm{OSS}$ (1) quantifies AL method effectiveness without
requiring detector training by measuring similarity between training sets and
target domains using object-level features. This enables the elimination of
ineffective AL methods before training. Furthermore, $\mathrm{OSS}$ (2) enables
the selection of representative validation sets for robust evaluation. We
validate our similarity-based approach on three autonomous driving datasets
(KITTI, BDD100K, CODA) using uncertainty-based AL methods as a case study with
two detector architectures (EfficientDet, YOLOv3). This work is the first to
unify AL training and evaluation strategies in object detection based on object
similarity. $\mathrm{OSS}$ is detector-agnostic, requires only labeled object
crops, and integrates with existing AL pipelines. This provides a practical
framework for deploying AL in real-world applications where computational
efficiency and evaluation reliability are critical. Code is available at
https://mos-ks.github.io/publications/.

</details>


### [78] [Integrating SAM Supervision for 3D Weakly Supervised Point Cloud Segmentation](https://arxiv.org/abs/2508.19909)
*Lechun You,Zhonghua Wu,Weide Liu,Xulei Yang,Jun Cheng,Wei Zhou,Bharadwaj Veeravalli,Guosheng Lin*

Main category: cs.CV

TL;DR: 通过结合2D基础模型和3D数据，提出了一种新的3D语义分割方法，以解决3D数据标注困难的问题。


<details>
  <summary>Details</summary>
Motivation: 当前3D语义分割方法在处理不规则、无序的3D点云数据时，通常只关注3D域，忽略了2D和3D数据的互补性。现有方法在利用扩展标签或伪标签时，存在利用不充分和噪声问题。

Method: 提出了一种新方法，通过整合2D基础模型生成的分割掩码，并利用几何对应关系将2D掩码传播到3D空间，从而最大化利用稀疏的3D标注。此外，还采用基于置信度和不确定性的连续性正则化来选择可靠的伪标签，并将其扩展到3D掩码以生成更多标签。

Result: 该方法有效弥补了3D标注的局限性与2D基础模型能力的差距，显著提升了3D弱监督分割的性能。

Conclusion: 该研究提出了一种创新的3D语义分割方法，有效利用了2D基础模型的强大能力，并通过多种策略增强了3D数据的标注，最终实现了性能的提升。

Abstract: Current methods for 3D semantic segmentation propose training models with
limited annotations to address the difficulty of annotating large, irregular,
and unordered 3D point cloud data. They usually focus on the 3D domain only,
without leveraging the complementary nature of 2D and 3D data. Besides, some
methods extend original labels or generate pseudo labels to guide the training,
but they often fail to fully use these labels or address the noise within them.
Meanwhile, the emergence of comprehensive and adaptable foundation models has
offered effective solutions for segmenting 2D data. Leveraging this
advancement, we present a novel approach that maximizes the utility of sparsely
available 3D annotations by incorporating segmentation masks generated by 2D
foundation models. We further propagate the 2D segmentation masks into the 3D
space by establishing geometric correspondences between 3D scenes and 2D views.
We extend the highly sparse annotations to encompass the areas delineated by 3D
masks, thereby substantially augmenting the pool of available labels.
Furthermore, we apply confidence- and uncertainty-based consistency
regularization on augmentations of the 3D point cloud and select the reliable
pseudo labels, which are further spread on the 3D masks to generate more
labels. This innovative strategy bridges the gap between limited 3D annotations
and the powerful capabilities of 2D foundation models, ultimately improving the
performance of 3D weakly supervised segmentation.

</details>


### [79] [WaveHiT-SR: Hierarchical Wavelet Network for Efficient Image Super-Resolution](https://arxiv.org/abs/2508.19927)
*Fayaz Ali,Muhammad Zawish,Steven Davy,Radu Timofte*

Main category: cs.CV

TL;DR: WaveHiT-SR结合小波变换和层次化Transformer，在图像超分辨率任务中实现了高效且高性能的表现，优于SwinIR-Light、SwinIR-NG和SRFormer-Light。


<details>
  <summary>Details</summary>
Motivation: 现有的基于Transformer的图像超分辨率方法在处理长距离依赖关系时受到窗口自注意力机制二次计算复杂度的限制，导致只能使用小的、固定的窗口，限制了感受野。本研究旨在解决这一问题，通过引入一种新的方法来提升Transformer在图像超分辨率任务中的性能和效率。

Method: 提出了一种名为WaveHiT-SR的新方法，该方法将小波变换嵌入到层次化Transformer框架中。具体来说，使用自适应层次化窗口替代静态小窗口来捕捉不同层级的特征并建模长距离依赖；利用小波变换将图像分解为多个频段，使网络能够同时关注全局和局部特征并保留结构细节；通过层次化处理逐步重建高分辨率图像，以降低计算复杂度；采用多层分解策略来捕捉低频分量中的细粒度信息并增强高频纹理。

Result: WaveHiT-SR在图像超分辨率任务上表现出优越的性能和效率。其改进版本在SwinIR-Light、SwinIR-NG和SRFormer-Light的基础上，实现了领先的超分辨率效果，同时拥有更少的参数、更低的计算量（FLOPs）和更快的处理速度。

Conclusion: WaveHiT-SR通过结合小波变换和自适应层次化窗口的Transformer框架，有效解决了现有方法的局限性，在图像超分辨率任务中实现了更高的效率和性能，优于现有的先进方法。

Abstract: Transformers have demonstrated promising performance in computer vision
tasks, including image super-resolution (SR). The quadratic computational
complexity of window self-attention mechanisms in many transformer-based SR
methods forces the use of small, fixed windows, limiting the receptive field.
In this paper, we propose a new approach by embedding the wavelet transform
within a hierarchical transformer framework, called (WaveHiT-SR). First, using
adaptive hierarchical windows instead of static small windows allows to capture
features across different levels and greatly improve the ability to model
long-range dependencies. Secondly, the proposed model utilizes wavelet
transforms to decompose images into multiple frequency subbands, allowing the
network to focus on both global and local features while preserving structural
details. By progressively reconstructing high-resolution images through
hierarchical processing, the network reduces computational complexity without
sacrificing performance. The multi-level decomposition strategy enables the
network to capture fine-grained information in lowfrequency components while
enhancing high-frequency textures. Through extensive experimentation, we
confirm the effectiveness and efficiency of our WaveHiT-SR. Our refined
versions of SwinIR-Light, SwinIR-NG, and SRFormer-Light deliver cutting-edge SR
results, achieving higher efficiency with fewer parameters, lower FLOPs, and
faster speeds.

</details>


### [80] [Reimagining Image Segmentation using Active Contour: From Chan Vese Algorithm into a Proposal Novel Functional Loss Framework](https://arxiv.org/abs/2508.19946)
*Gianluca Guzzetta*

Main category: cs.CV

TL;DR: 该论文提出了一种基于Chan-Vese算法的图像分割方法，并使用PyTorch实现和评估。


<details>
  <summary>Details</summary>
Motivation: Chan-Vese算法在图像分割中表现出色，但仍有改进空间。本研究旨在提出一种新的基于主动轮廓和水平集函数的Chan-Vese算法的分割损失函数，并与现有方法进行比较。

Method: 提出了一种基于Chan-Vese算法的图像分割方法，利用其能量函数和偏微分方程，并结合PyTorch的nn.ModuleLoss实现了一个新的分割损失函数。

Result: 通过在常见的计算机视觉分割数据集上进行实验，将新提出的损失函数与经典的损失函数进行了性能评估和比较。

Conclusion: 实验结果表明，新提出的基于Chan-Vese算法的损失函数在图像分割任务上具有潜力，并优于一些经典方法。

Abstract: In this paper, we present a comprehensive study and analysis of the Chan-Vese
algorithm for image segmentation. We employ a discretized scheme derived from
the empirical study of the Chan-Vese model's functional energy and its partial
differential equation based on its level set function. We provide a proof of
the results and an implementation using MATLAB. Leveraging modern computer
vision methodologies, we propose a functional segmentation loss based on active
contours, utilizing pytorch.nn.ModuleLoss and a level set based on the
Chan-Vese algorithm. We compare our results with common computer vision
segmentation datasets and evaluate the performance of classical loss functions
against our proposed method. All code and materials used are available at
https://github.com/gguzzy/chan_vese_functional_loss.

</details>


### [81] [Assessing the Geolocation Capabilities, Limitations and Societal Risks of Generative Vision-Language Models](https://arxiv.org/abs/2508.19967)
*Oliver Grainge,Sania Waheed,Jack Stilgoe,Michael Milford,Shoaib Ehsan*

Main category: cs.CV

TL;DR: Vision-Language Models (VLMs) used for image geo-localization pose privacy risks, especially with their increasing precision. This paper assesses 25 state-of-the-art VLMs on diverse datasets, finding poor performance on generic street-level images but high accuracy (61%) on social media-like images, highlighting significant privacy concerns.


<details>
  <summary>Details</summary>
Motivation: To address the lack of systematic evaluation on the geolocation precision of Generative VLMs, their limits, and potential for unintended inferences, given the increasing capabilities of VLMs in image geo-localization and associated privacy risks.

Method: Conduct a comprehensive assessment of the geolocation capabilities of 25 state-of-the-art VLMs on four benchmark image datasets captured in diverse environments.

Result: Current VLMs perform poorly on generic street-level images but achieve notably high accuracy (61%) on images resembling social media content.

Conclusion: Current VLMs exhibit significant privacy risks due to their high accuracy in geo-locating social media-like images, despite poor performance on generic street-level images. Further research is needed to understand and mitigate these risks.

Abstract: Geo-localization is the task of identifying the location of an image using
visual cues alone. It has beneficial applications, such as improving disaster
response, enhancing navigation, and geography education. Recently,
Vision-Language Models (VLMs) are increasingly demonstrating capabilities as
accurate image geo-locators. This brings significant privacy risks, including
those related to stalking and surveillance, considering the widespread uses of
AI models and sharing of photos on social media. The precision of these models
is likely to improve in the future. Despite these risks, there is little work
on systematically evaluating the geolocation precision of Generative VLMs,
their limits and potential for unintended inferences. To bridge this gap, we
conduct a comprehensive assessment of the geolocation capabilities of 25
state-of-the-art VLMs on four benchmark image datasets captured in diverse
environments. Our results offer insight into the internal reasoning of VLMs and
highlight their strengths, limitations, and potential societal risks. Our
findings indicate that current VLMs perform poorly on generic street-level
images yet achieve notably high accuracy (61\%) on images resembling social
media content, raising significant and urgent privacy concerns.

</details>


### [82] [GS: Generative Segmentation via Label Diffusion](https://arxiv.org/abs/2508.20020)
*Yuhao Chen,Shubin Chen,Liang Lin,Guangrun Wang*

Main category: cs.CV

TL;DR: GS是一种新的生成式语言驱动图像分割框架，通过标签扩散直接从噪声生成分割掩码，并在PNG基准测试中取得了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 传统的语言驱动图像分割方法将分割视为判别性问题，而现有的扩散模型方法仍以图像为中心。本研究旨在提出一种新的框架，将分割本身作为一种生成任务。

Method: 提出GS（Generative Segmentation）框架，通过标签扩散将分割视为生成任务，直接从噪声生成分割掩码，并以输入图像和语言描述作为条件，从而实现端到端的训练。

Result: GS在Panoptic Narrative Grounding（PNG）基准测试中显著优于现有的判别式和基于扩散的方法，在语言驱动分割方面取得了新的最先进成果。

Conclusion: GS框架通过将分割视为生成任务，并利用标签扩散直接生成分割掩码，有效解决了现有方法的局限性，并在具有挑战性的多模态分割任务中取得了优越的性能。

Abstract: Language-driven image segmentation is a fundamental task in vision-language
understanding, requiring models to segment regions of an image corresponding to
natural language expressions. Traditional methods approach this as a
discriminative problem, assigning each pixel to foreground or background based
on semantic alignment. Recently, diffusion models have been introduced to this
domain, but existing approaches remain image-centric: they either (i) use image
diffusion models as visual feature extractors, (ii) synthesize segmentation
data via image generation to train discriminative models, or (iii) perform
diffusion inversion to extract attention cues from pre-trained image diffusion
models-thereby treating segmentation as an auxiliary process. In this paper, we
propose GS (Generative Segmentation), a novel framework that formulates
segmentation itself as a generative task via label diffusion. Instead of
generating images conditioned on label maps and text, GS reverses the
generative process: it directly generates segmentation masks from noise,
conditioned on both the input image and the accompanying language description.
This paradigm makes label generation the primary modeling target, enabling
end-to-end training with explicit control over spatial and semantic fidelity.
To demonstrate the effectiveness of our approach, we evaluate GS on Panoptic
Narrative Grounding (PNG), a representative and challenging benchmark for
multimodal segmentation that requires panoptic-level reasoning guided by
narrative captions. Experimental results show that GS significantly outperforms
existing discriminative and diffusion-based methods, setting a new
state-of-the-art for language-driven segmentation.

</details>


### [83] [Segmentation Assisted Incremental Test Time Adaptation in an Open World](https://arxiv.org/abs/2508.20029)
*Manogna Sreenivas,Soma Biswas*

Main category: cs.CV

TL;DR: 该论文提出了一种名为SegAssist的增量测试时适应（ITTA）框架，用于处理视觉语言模型（VLMs）在测试阶段遇到的新类别和新领域问题，允许模型同时适应协变量和标签偏移，并主动整合新出现的类别。


<details>
  <summary>Details</summary>
Motivation: 在动态环境中，已训练模型在遇到未知对象和分布变化时，其泛化能力会受到挑战。该工作解决了视觉语言模型（VLM）的增量测试时适应（ITTA）问题，处理测试期间不断出现未见类别和未见领域的情况。

Method: 提出了一种名为SegAssist的、无需训练的、辅助主动标签选择的模块。该模块利用VLM的分割能力来改进主动样本选择，优先选择可能属于未见类别的样本。该框架整合了用于VLM的单张图像TTA方法和主动标签技术，以便在测试时为可能代表未见类别的样本查询Oracle。

Result: 在多个基准数据集上的大量实验证明，SegAssist能够提高VLM在真实世界场景中的性能，这些场景需要对新出现的数据进行持续适应。

Conclusion: SegAssist能够增强VLM在真实世界场景中的性能，这些场景需要对新出现的数据进行持续适应。

Abstract: In dynamic environments, unfamiliar objects and distribution shifts are often
encountered, which challenge the generalization abilities of the deployed
trained models. This work addresses Incremental Test Time Adaptation of Vision
Language Models, tackling scenarios where unseen classes and unseen domains
continuously appear during testing. Unlike traditional Test Time Adaptation
approaches, where the test stream comes only from a predefined set of classes,
our framework allows models to adapt simultaneously to both covariate and label
shifts, actively incorporating new classes as they emerge. Towards this goal,
we establish a new benchmark for ITTA, integrating single image TTA methods for
VLMs with active labeling techniques that query an oracle for samples
potentially representing unseen classes during test time. We propose a
segmentation assisted active labeling module, termed SegAssist, which is
training free and repurposes the segmentation capabilities of VLMs to refine
active sample selection, prioritizing samples likely to belong to unseen
classes. Extensive experiments on several benchmark datasets demonstrate the
potential of SegAssist to enhance the performance of VLMs in real world
scenarios, where continuous adaptation to emerging data is essential.
Project-page:https://manogna-s.github.io/segassist/

</details>


### [84] [OpenM3D: Open Vocabulary Multi-view Indoor 3D Object Detection without Human Annotations](https://arxiv.org/abs/2508.20063)
*Peng-Hao Hsu,Ke Zhang,Fu-En Wang,Tao Tu,Ming-Feng Li,Yu-Lun Liu,Albert Y. C. Chen,Min Sun,Cheng-Hao Kuo*

Main category: cs.CV

TL;DR: OpenM3D是一个创新的开放词汇多视图室内3D目标检测器，它在没有人类标注的情况下进行训练，并且在ScanNet200和ARKitScenes室内基准测试中表现出优越的准确性和速度。


<details>
  <summary>Details</summary>
Motivation: 开放词汇（OV）3D目标检测是一个新兴领域，但与基于3D点云的方法相比，基于图像的方法的探索仍然有限。

Method: OpenM3D是一个单阶段检测器，它采用ImGeoNet模型的2D诱导体素特征。为了支持OV，它与需要高质量3D伪框的类无关3D定位损失和需要多样化预训练CLIP特征的体素-语义对齐损失联合训练。通过图嵌入技术生成3D伪框，并从与每个连贯3D结构相关联的2D片段中采样CLIP特征以进行对齐。

Result: OpenM3D在ScanNet200和ARKitScenes室内基准测试中，相比现有方法，在准确性和速度上均表现优越，推理速度为0.3秒/场景。它还优于利用其类无关检测器和基于ViT CLIP的OV分类器的强两阶段方法，以及结合多视图深度估计器的基线方法。

Conclusion: OpenM3D是一个高效的单阶段开放词汇3D目标检测器，它通过新颖的训练策略和损失函数，在没有人类标注的情况下实现了优越的性能，为基于图像的OV 3D目标检测领域做出了贡献。

Abstract: Open-vocabulary (OV) 3D object detection is an emerging field, yet its
exploration through image-based methods remains limited compared to 3D point
cloud-based methods. We introduce OpenM3D, a novel open-vocabulary multi-view
indoor 3D object detector trained without human annotations. In particular,
OpenM3D is a single-stage detector adapting the 2D-induced voxel features from
the ImGeoNet model. To support OV, it is jointly trained with a class-agnostic
3D localization loss requiring high-quality 3D pseudo boxes and a
voxel-semantic alignment loss requiring diverse pre-trained CLIP features. We
follow the training setting of OV-3DET where posed RGB-D images are given but
no human annotations of 3D boxes or classes are available. We propose a 3D
Pseudo Box Generation method using a graph embedding technique that combines 2D
segments into coherent 3D structures. Our pseudo-boxes achieve higher precision
and recall than other methods, including the method proposed in OV-3DET. We
further sample diverse CLIP features from 2D segments associated with each
coherent 3D structure to align with the corresponding voxel feature. The key to
training a highly accurate single-stage detector requires both losses to be
learned toward high-quality targets. At inference, OpenM3D, a highly efficient
detector, requires only multi-view images for input and demonstrates superior
accuracy and speed (0.3 sec. per scene) on ScanNet200 and ARKitScenes indoor
benchmarks compared to existing methods. We outperform a strong two-stage
method that leverages our class-agnostic detector with a ViT CLIP-based OV
classifier and a baseline incorporating multi-view depth estimator on both
accuracy and speed.

</details>


### [85] [Patch Progression Masked Autoencoder with Fusion CNN Network for Classifying Evolution Between Two Pairs of 2D OCT Slices](https://arxiv.org/abs/2508.20064)
*Philippe Zhang,Weili Jiang,Yihao Li,Jing Zhang,Sarah Matta,Yubo Tan,Hui Lin,Haoshen Wang,Jiangtian Pan,Hui Xu,Laurent Borderie,Alexandre Le Guilcher,Béatrice Cochener,Chubin Ou,Gwenolé Quellec,Mathieu Lamard*

Main category: cs.CV

TL;DR: 该研究旨在使用深度学习技术分析眼科OCT扫描，以监测和预测年龄相关性黄斑变性（AMD）的进展，取得了良好的成果。


<details>
  <summary>Details</summary>
Motivation: 为了更好地治疗新生血管性AMD，需要对OCT扫描中的新生血管活动进行跟踪，以制定个性化的治疗计划。

Method: 在MARIO挑战赛中，对于任务1（分类两个2D切片之间的演变），我们采用了融合CNN网络和模型集成。对于任务2（预测未来三个月的进展），我们提出了Patch Progression Masked Autoencoder，该模型生成下一个检查的OCT，然后对当前OCT和生成OCT之间的演变进行分类。

Result: 我们的模型在两个任务中均进入了前10名。

Conclusion: 尽管我们在MARIO挑战赛中取得了优异的成绩，但由于部分团队成员与比赛组织者属于同一机构，我们不具备获奖资格。

Abstract: Age-related Macular Degeneration (AMD) is a prevalent eye condition affecting
visual acuity. Anti-vascular endothelial growth factor (anti-VEGF) treatments
have been effective in slowing the progression of neovascular AMD, with better
outcomes achieved through timely diagnosis and consistent monitoring. Tracking
the progression of neovascular activity in OCT scans of patients with exudative
AMD allows for the development of more personalized and effective treatment
plans. This was the focus of the Monitoring Age-related Macular Degeneration
Progression in Optical Coherence Tomography (MARIO) challenge, in which we
participated. In Task 1, which involved classifying the evolution between two
pairs of 2D slices from consecutive OCT acquisitions, we employed a fusion CNN
network with model ensembling to further enhance the model's performance. For
Task 2, which focused on predicting progression over the next three months
based on current exam data, we proposed the Patch Progression Masked
Autoencoder that generates an OCT for the next exam and then classifies the
evolution between the current OCT and the one generated using our solution from
Task 1. The results we achieved allowed us to place in the Top 10 for both
tasks. Some team members are part of the same organization as the challenge
organizers; therefore, we are not eligible to compete for the prize.

</details>


### [86] [PAUL: Uncertainty-Guided Partition and Augmentation for Robust Cross-View Geo-Localization under Noisy Correspondence](https://arxiv.org/abs/2508.20066)
*Zheng Li,Yanming Guo,WenZhe Liu,Xueyi Zhang,Zhaoyun Ding,Long Xu,Mingrui Lao*

Main category: cs.CV

TL;DR: 本文提出PAUL框架，通过不确定性学习来处理跨视图地理定位中的噪声对应问题，该框架通过不确定性感知的数据增强和证据共训练来划分和增强训练数据，选择性地增强具有高对应置信度的区域，并利用不确定性估计来优化特征学习，有效抑制了错误配对引起的噪声，并在各种噪声比率下均优于其他同类方法。


<details>
  <summary>Details</summary>
Motivation: 现有跨视图地理定位方法在训练时假设图像对完美对齐，但这在实际场景中很少发生。GPS漂移等因素会导致系统性对齐偏移，使得图像对之间只存在部分对应关系。这种噪声对应问题在现有研究中受到的关注有限。

Method: 提出PAUL（Partition and Augmentation by Uncertainty Learning）框架，该框架通过不确定性感知共增强和证据共训练来划分和增强训练数据。具体来说，PAUL选择性地增强具有高对应置信度的区域，并利用不确定性估计来优化特征学习，从而有效抑制错误配对带来的噪声。 PAUL不依赖传统的过滤或标签纠正方法，而是利用数据不确定性和损失差异来进行有针对性的划分和增强，为噪声样本提供鲁棒的监督。

Result: 实验结果表明，PAUL框架的各个组成部分都非常有效，并且在各种噪声比率下，其性能始终优于其他处理噪声对应的具有竞争力的方法。

Conclusion:  PAUL框架能够有效解决跨视图地理定位中的噪声对应问题，提高了模型在实际应用中的鲁棒性和准确性。

Abstract: Cross-view geo-localization is a critical task for UAV navigation, event
detection, and aerial surveying, as it enables matching between drone-captured
and satellite imagery. Most existing approaches embed multi-modal data into a
joint feature space to maximize the similarity of paired images. However, these
methods typically assume perfect alignment of image pairs during training,
which rarely holds true in real-world scenarios. In practice, factors such as
urban canyon effects, electromagnetic interference, and adverse weather
frequently induce GPS drift, resulting in systematic alignment shifts where
only partial correspondences exist between pairs. Despite its prevalence, this
source of noisy correspondence has received limited attention in current
research. In this paper, we formally introduce and address the Noisy
Correspondence on Cross-View Geo-Localization (NC-CVGL) problem, aiming to
bridge the gap between idealized benchmarks and practical applications. To this
end, we propose PAUL (Partition and Augmentation by Uncertainty Learning), a
novel framework that partitions and augments training data based on estimated
data uncertainty through uncertainty-aware co-augmentation and evidential
co-training. Specifically, PAUL selectively augments regions with high
correspondence confidence and utilizes uncertainty estimation to refine feature
learning, effectively suppressing noise from misaligned pairs. Distinct from
traditional filtering or label correction, PAUL leverages both data uncertainty
and loss discrepancy for targeted partitioning and augmentation, thus providing
robust supervision for noisy samples. Comprehensive experiments validate the
effectiveness of individual components in PAUL,which consistently achieves
superior performance over other competitive noisy-correspondence-driven methods
in various noise ratios.

</details>


### [87] [AudioStory: Generating Long-Form Narrative Audio with Large Language Models](https://arxiv.org/abs/2508.20088)
*Yuxin Guo,Teng Wang,Yuying Ge,Shijie Ma,Yixiao Ge,Wei Zou,Ying Shan*

Main category: cs.CV

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Recent advances in text-to-audio (TTA) generation excel at synthesizing short
audio clips but struggle with long-form narrative audio, which requires
temporal coherence and compositional reasoning. To address this gap, we propose
AudioStory, a unified framework that integrates large language models (LLMs)
with TTA systems to generate structured, long-form audio narratives. AudioStory
possesses strong instruction-following reasoning generation capabilities. It
employs LLMs to decompose complex narrative queries into temporally ordered
sub-tasks with contextual cues, enabling coherent scene transitions and
emotional tone consistency. AudioStory has two appealing features: (1)
Decoupled bridging mechanism: AudioStory disentangles LLM-diffuser
collaboration into two specialized components, i.e., a bridging query for
intra-event semantic alignment and a residual query for cross-event coherence
preservation. (2) End-to-end training: By unifying instruction comprehension
and audio generation within a single end-to-end framework, AudioStory
eliminates the need for modular training pipelines while enhancing synergy
between components. Furthermore, we establish a benchmark AudioStory-10K,
encompassing diverse domains such as animated soundscapes and natural sound
narratives. Extensive experiments show the superiority of AudioStory on both
single-audio generation and narrative audio generation, surpassing prior TTA
baselines in both instruction-following ability and audio fidelity. Our code is
available at https://github.com/TencentARC/AudioStory

</details>


### [88] [Bridging Domain Gaps for Fine-Grained Moth Classification Through Expert-Informed Adaptation and Foundation Model Priors](https://arxiv.org/abs/2508.20089)
*Ross J Gardiner,Guillaume Mougeot,Sareh Rowlands,Benno I Simmons,Flemming Helsing,Toke Thomas Høye*

Main category: cs.CV

TL;DR: 使用知识蒸馏和轻量级模型解决野外图像数据域转移问题，实现高效的鳞翅目物种识别。


<details>
  <summary>Details</summary>
Motivation: 自动相机系统中的鳞翅目（飞蛾）图像标注对于理解昆虫数量下降至关重要，但域名转移导致准确物种识别具有挑战性。

Method: 提出一种轻量级分类方法，结合有限的专家标注野外数据和高性能BioCLIP2基础模型到ConvNeXt-tiny架构的知识蒸馏。

Result: 在101种丹麦飞蛾的实验中，BioCLIP2表现优于其他方法，且蒸馏后的轻量级模型在显著降低计算成本的同时，实现了相当的准确性。

Conclusion: 该研究为开发高效的昆虫监测系统和缩小细粒度分类的域名差距提供了实用的指导。

Abstract: Labelling images of Lepidoptera (moths) from automated camera systems is
vital for understanding insect declines. However, accurate species
identification is challenging due to domain shifts between curated images and
noisy field imagery. We propose a lightweight classification approach,
combining limited expert-labelled field data with knowledge distillation from
the high-performance BioCLIP2 foundation model into a ConvNeXt-tiny
architecture. Experiments on 101 Danish moth species from AMI camera systems
demonstrate that BioCLIP2 substantially outperforms other methods and that our
distilled lightweight model achieves comparable accuracy with significantly
reduced computational cost. These insights offer practical guidelines for the
development of efficient insect monitoring systems and bridging domain gaps for
fine-grained classification.

</details>


### [89] [CODA: Coordinating the Cerebrum and Cerebellum for a Dual-Brain Computer Use Agent with Decoupled Reinforcement Learning](https://arxiv.org/abs/2508.20096)
*Zeyi Sun,Yuhang Cao,Jianze Liang,Qiushi Sun,Ziyu Liu,Zhixiong Zhang,Yuhang Zang,Xiaoyi Dong,Kai Chen,Dahua Lin,Jiaqi Wang*

Main category: cs.CV

TL;DR: CODA是一个可训练的组合框架，通过结合通用规划器和专用执行器，解决了GUI自动化在科学计算等专业领域面临的挑战。


<details>
  <summary>Details</summary>
Motivation: 现有GUI自动化方法在长期规划和精确执行之间存在权衡，且缺乏适应性，特别是在科学计算等数据稀缺领域。

Method: CODA采用两阶段训练流程：第一阶段（专业化）使用解耦的GRPO训练每个应用的专家规划器；第二阶段（通用化）聚合专业化阶段的轨迹数据，对最终规划器进行监督微调。

Result: CODA在ScienceBoard基准的四个具有挑战性的应用上进行了评估，显著优于基线模型，并创下了开源模型的新状态。

Conclusion: CODA通过其可训练的组合框架，实现了强大的执行能力和跨领域泛化能力，解决了现有GUI自动化方法的局限性。

Abstract: Autonomous agents for Graphical User Interfaces (GUIs) face significant
challenges in specialized domains such as scientific computing, where both
long-horizon planning and precise execution are required. Existing approaches
suffer from a trade-off: generalist agents excel at planning but perform poorly
in execution, while specialized agents demonstrate the opposite weakness.
Recent compositional frameworks attempt to bridge this gap by combining a
planner and an actor, but they are typically static and non-trainable, which
prevents adaptation from experience. This is a critical limitation given the
scarcity of high-quality data in scientific domains. To address these
limitations, we introduce CODA, a novel and trainable compositional framework
that integrates a generalist planner (Cerebrum) with a specialist executor
(Cerebellum), trained via a dedicated two-stage pipeline. In the first stage,
Specialization, we apply a decoupled GRPO approach to train an expert planner
for each scientific application individually, bootstrapping from a small set of
task trajectories. In the second stage, Generalization, we aggregate all
successful trajectories from the specialized experts to build a consolidated
dataset, which is then used for supervised fine-tuning of the final planner.
This equips CODA with both robust execution and cross-domain generalization.
Evaluated on four challenging applications from the ScienceBoard benchmark,
CODA significantly outperforms baselines and establishes a new state of the art
among open-source models.

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [90] [MultiPL-MoE: Multi-Programming-Lingual Extension of Large Language Models through Hybrid Mixture-of-Experts](https://arxiv.org/abs/2508.19268)
*Qing Wang,Xue Han,Jiahui Wang,Lehao Xing,Qian Hu,Lianlian Zhang,Chao Deng,Junlan Feng*

Main category: cs.CL

TL;DR: LLMs在多语言代码生成方面仍具挑战，本文提出MultiPL-MoE模型，通过结合token和segment层面的专家混合（MoE）来优化模型性能，实验证明其有效性。


<details>
  <summary>Details</summary>
Motivation: 提升大型语言模型（LLMs）在多编程语言（MultiPL）代码生成方面的表现，同时在有限的计算资源下保持现有模型的性能。

Method: 提出一种名为MultiPL-MoE的混合专家（MoE）模型，该模型结合了token和segment两个层面的MoE。token-level MoE采用共享专家和门权重归一化方法；segment-level MoE使用滑动窗口划分输入序列，并采用专家选择路由策略，允许专家选择top-k个片段。

Result: 实验结果证明了MultiPL-MoE的有效性。

Conclusion: MultiPL-MoE模型通过在token和segment层面优化专家选择，能够有效提升LLMs在多编程语言代码生成方面的性能。

Abstract: Despite LLMs' excellent code creation capabilities, multilingual code
generation remains extremely challenging. To address this, we intent to improve
the multi-programming-lingual (MultiPL) performance of the base LLMs while
retaining the most popular ones using restricted computational resources. We
consider MultiPL to be a special case of multiple natural languages and propose
a MultiPL extension of LLMs utilizing a hybrid mixture of experts (MoE), called
MultiPL-MoE. Specifically, MultiPL-MoE combines two paired MoEs to optimize
expert selection at both the token and segment levels. The token-level MoE is a
standard upcycling MoE structure with a shared expert and a novel gate weight
normalization approach that aids in the final fusion with the segment-level
MoE. The segment-level MoE incorporates two innovative designs to better
capture the syntactic structure and contextual patterns of programming
languages: First, using a sliding window to partition the input token sequence
into multiple segments; Then, adopting an expert-choice routing strategy that
allows experts to select the top-k segments. The results of the experiment
proved the effectiveness of MultiPL-MoE.

</details>


### [91] [Whisper based Cross-Lingual Phoneme Recognition between Vietnamese and English](https://arxiv.org/abs/2508.19270)
*Nguyen Huu Nhat Minh,Tran Nguyen Anh,Truong Dinh Dung,Vo Van Nam,Le Pham Tuyen*

Main category: cs.CL

TL;DR: 提出了一种新的双语语音识别方法，通过构建双语音素集和利用PhoWhisper预训练编码器，提高了越南语和英语混合语音的音素识别准确率。


<details>
  <summary>Details</summary>
Motivation: 解决越南语和英语混合发音时，由于音调和重音差异导致的语音识别准确性问题。

Method: 构建了一个具有代表性的双语音素集，并设计了一个端到端的系统，利用PhoWhisper预训练编码器提取高层特征以提升音素识别能力。

Result: 实验证明，该方法不仅提高了越南语双语语音识别的准确性，还为处理基于音调和重音的音素识别提供了稳健的框架。

Conclusion: 所提出的方法能有效处理越南语和英语混合语音中的音素识别挑战，并为未来的跨语言语音识别研究奠定了基础。

Abstract: Cross-lingual phoneme recognition has emerged as a significant challenge for
accurate automatic speech recognition (ASR) when mixing Vietnamese and English
pronunciations. Unlike many languages, Vietnamese relies on tonal variations to
distinguish word meanings, whereas English features stress patterns and
non-standard pronunciations that hinder phoneme alignment between the two
languages. To address this challenge, we propose a novel bilingual speech
recognition approach with two primary contributions: (1) constructing a
representative bilingual phoneme set that bridges the differences between
Vietnamese and English phonetic systems; (2) designing an end-to-end system
that leverages the PhoWhisper pre-trained encoder for deep high-level
representations to improve phoneme recognition. Our extensive experiments
demonstrate that the proposed approach not only improves recognition accuracy
in bilingual speech recognition for Vietnamese but also provides a robust
framework for addressing the complexities of tonal and stress-based phoneme
recognition

</details>


### [92] [Rethinking Reasoning in LLMs: Neuro-Symbolic Local RetoMaton Beyond ICL and CoT](https://arxiv.org/abs/2508.19271)
*Rushitha Santhoshi Mamidala,Anshuman Chhabra,Ankur Mali*

Main category: cs.CL

TL;DR: 通过引入基于任务的加权有限自动机（WFA）来改进RetoMaton，以实现更可靠、可解释和高效的LLM推理，取代了不稳定的提示方法。


<details>
  <summary>Details</summary>
Motivation: 提示类推理（如CoT和ICL）在LLM中不稳定且不可靠，而基于自动机的神经符号方法（如RetoMaton）提供了更结构化的替代方案。本研究旨在通过使用局部、任务自适应的WFA来增强RetoMaton，以实现更鲁棒、可解释和高效的LLM推理。

Method: 将RetoMaton的全局数据存储替换为从外部语料库构建的局部、任务自适应的加权有限自动机（WFA）。这种方法利用WFA的显式结构来提供可验证和模块化的检索行为，并将其应用于LLaMA-3.2-1B和Gemma-3-1B-PT模型。

Result: 在TriviaQA、GSM8K和MMLU任务上，与基础模型和基于提示的方法相比，使用局部RetoMaton可以持续提高LLM的性能，同时实现透明和可复现的检索动态。

Conclusion: 局部RetoMaton提供了一种有前景的方法，通过轻量级的自动机引导内存，使现代LLM能够实现可信赖的符号推理，从而在模型性能、可解释性和可复现性方面取得进步。

Abstract: Prompt-based reasoning strategies such as Chain-of-Thought (CoT) and
In-Context Learning (ICL) have become widely used for eliciting reasoning
capabilities in large language models (LLMs). However, these methods rely on
fragile, implicit mechanisms often yielding inconsistent outputs across seeds,
formats, or minor prompt variations making them fundamentally unreliable for
tasks requiring stable, interpretable reasoning. In contrast, automata-based
neuro-symbolic frameworks like RetoMaton offer a more structured and
trustworthy alternative by grounding retrieval in symbolic memory with
deterministic transitions. In this work, we extend RetoMaton by replacing its
global datastore with a local, task-adaptive Weighted Finite Automaton (WFA),
constructed directly from external domain corpora. This local automaton
structure promotes robust, context-aware retrieval while preserving symbolic
traceability and low inference overhead. Unlike prompting, which entangles
context and memory in opaque ways, our approach leverages the explicit
structure of WFAs to provide verifiable and modular retrieval behavior, making
it better suited for domain transfer and interoperability. We evaluate this
local RetoMaton variant on two pretrained LLMs LLaMA-3.2-1B and Gemma-3-1B-PT
across three reasoning tasks: TriviaQA (reading comprehension), GSM8K
(multi-step math), and MMLU (domain knowledge). Compared to the base model and
prompting-based methods, augmenting these setups with local RetoMaton
consistently improves performance while enabling transparent and reproducible
retrieval dynamics. Our results highlight a promising shift toward trustworthy,
symbolic reasoning in modern LLMs via lightweight, automaton-guided memory.

</details>


### [93] [Heterogeneous LLM Methods for Ontology Learning (Few-Shot Prompting, Ensemble Typing, and Attention-Based Taxonomies)](https://arxiv.org/abs/2508.19428)
*Aleksandra Beliaeva,Temurbek Rahmatullaev*

Main category: cs.CL

TL;DR: 该论文提出了一个用于LLM4OL 2025挑战的全面系统，涵盖本体构建的三个任务：术语提取、类型分配和分类法发现。该系统结合了检索增强提示、零样本分类和基于注意力的图模型。


<details>
  <summary>Details</summary>
Motivation: 为LLM4OL 2025挑战提供一个全面的系统，以解决本体构建的完整流程，包括术语提取、类型分配和分类法发现。

Method: 方法包括：1. 任务A：使用检索增强生成（RAG）流水线联合提取领域特定术语及其本体类型，无需模型微调。2. 任务B：在有标签数据的少样本场景下重用RAG方案，在无标签数据的零样本场景下使用基于置信度加权的多个嵌入模型余弦相似度得分的零样本分类器。3. 任务C：将分类法发现建模为图推理，使用类型标签的嵌入训练轻量级交叉注意力层来预测“is-a”关系。

Result: 在LLM4OL 2025挑战的三个任务中均取得了排名靠前（top-ranking）的结果，展示了基于LLM的本体学习架构在异构域中的可扩展性、适应性和鲁棒性。

Conclusion: 该研究展示了基于LLM的架构在本体学习中的可扩展性、适应性和鲁棒性，其模块化、任务特定的解决方案在LLM4OL 2025挑战的三个任务中均取得了优异成绩。

Abstract: We present a comprehensive system for addressing Tasks A, B, and C of the
LLMs4OL 2025 challenge, which together span the full ontology construction
pipeline: term extraction, typing, and taxonomy discovery. Our approach
combines retrieval-augmented prompting, zero-shot classification, and
attention-based graph modeling -- each tailored to the demands of the
respective task. For Task A, we jointly extract domain-specific terms and their
ontological types using a retrieval-augmented generation (RAG) pipeline.
Training data was reformulated into a document to terms and types
correspondence, while test-time inference leverages semantically similar
training examples. This single-pass method requires no model finetuning and
improves overall performance through lexical augmentation Task B, which
involves assigning types to given terms, is handled via a dual strategy. In the
few-shot setting (for domains with labeled training data), we reuse the RAG
scheme with few-shot prompting. In the zero-shot setting (for previously unseen
domains), we use a zero-shot classifier that combines cosine similarity scores
from multiple embedding models using confidence-based weighting. In Task C, we
model taxonomy discovery as graph inference. Using embeddings of type labels,
we train a lightweight cross-attention layer to predict is-a relations by
approximating a soft adjacency matrix. These modular, task-specific solutions
enabled us to achieve top-ranking results in the official leaderboard across
all three tasks. Taken together these strategies showcase the scalability,
adaptability, and robustness of LLM-based architectures for ontology learning
across heterogeneous domains.
  Code is available at:
https://github.com/BelyaevaAlex/LLMs4OL-Challenge-Alexbek

</details>


### [94] [RAGAPHENE: A RAG Annotation Platform with Human Enhancements and Edits](https://arxiv.org/abs/2508.19272)
*Kshitij Fadnis,Sara Rosenthal,Maeda Hanafi,Yannis Katsis,Marina Danilevsky*

Main category: cs.CL

TL;DR: RAGAPHENE是一个聊天式标注平台，用于模拟真实世界对话，以评估检索增强生成（RAG）中的大型语言模型（LLM），已成功用于构建数千次对话。


<details>
  <summary>Details</summary>
Motivation: 评估大型语言模型（LLM）在多轮检索增强生成（RAG）对话中的表现至关重要，因为LLM可能会产生看似正确但包含虚假信息的答案。因此，构建能够评估此类对话的基准测试变得越来越重要。

Method: 开发了一个名为RAGAPHENE的聊天式标注平台，该平台允许标注人员模拟真实世界的对话，以便为LLM的基准测试和评估收集数据。

Result: 该平台已成功吸引了约40名标注人员，并用于构建了数千次真实世界的对话，为LLM的评估奠定了基础。

Conclusion: RAGAPHENE平台为模拟真实世界对话和评估LLM在RAG方面的能力提供了一个有效且可扩展的解决方案。

Abstract: Retrieval Augmented Generation (RAG) is an important aspect of conversing
with Large Language Models (LLMs) when factually correct information is
important. LLMs may provide answers that appear correct, but could contain
hallucinated information. Thus, building benchmarks that can evaluate LLMs on
multi-turn RAG conversations has become an increasingly important task.
Simulating real-world conversations is vital for producing high quality
evaluation benchmarks. We present RAGAPHENE, a chat-based annotation platform
that enables annotators to simulate real-world conversations for benchmarking
and evaluating LLMs. RAGAPHENE has been successfully used by approximately 40
annotators to build thousands of real-world conversations.

</details>


### [95] [Leveraging Language Models and Machine Learning in Verbal Autopsy Analysis](https://arxiv.org/abs/2508.19274)
*Yue Chu*

Main category: cs.CL

TL;DR: 该论文研究如何利用语言模型和机器学习技术处理和分析“死亡原因”调查（VA）中的叙述信息，以更准确地估计死亡原因，并发现叙述信息比仅使用结构化问卷信息更有效，结合两者效果更佳。


<details>
  <summary>Details</summary>
Motivation: 在没有完善出生和死亡登记的国家，口述验尸（VA）是估计死亡原因（COD）和制定政策的关键工具。现有算法仅使用结构化问卷信息，忽略了叙述信息，但叙述信息包含有价值的线索。

Method: 利用南非的实际数据，研究了如何使用预训练语言模型（PLMs）和机器学习（ML）技术，仅通过VA的叙述信息来进行自动化的死亡原因分类，并探索了结合叙述和问卷信息的“多模态”融合策略。

Result: 仅使用叙述信息，基于Transformer的PLMs在死亡原因分类上优于仅使用问卷信息的算法，尤其在识别非传染性疾病方面。多模态方法进一步提高了分类性能。研究还发现，医生感知的“信息充分性”会影响分类准确性，且这种影响对模型也同样存在。

Conclusion: 该论文证明了在VA调查中利用叙述信息可以提升死亡原因分类的准确性，并强调了需要更多样化、高质量的数据来训练和优化这些模型，同时也为改进VA工具和访谈提供了指导。

Abstract: In countries without civil registration and vital statistics, verbal autopsy
(VA) is a critical tool for estimating cause of death (COD) and inform policy
priorities. In VA, interviewers ask proximal informants for details on the
circumstances preceding a death, in the form of unstructured narratives and
structured questions. Existing automated VA cause classification algorithms
only use the questions and ignore the information in the narratives. In this
thesis, we investigate how the VA narrative can be used for automated COD
classification using pretrained language models (PLMs) and machine learning
(ML) techniques. Using empirical data from South Africa, we demonstrate that
with the narrative alone, transformer-based PLMs with task-specific fine-tuning
outperform leading question-only algorithms at both the individual and
population levels, particularly in identifying non-communicable diseases. We
explore various multimodal fusion strategies combining narratives and questions
in unified frameworks. Multimodal approaches further improve performance in COD
classification, confirming that each modality has unique contributions and may
capture valuable information that is not present in the other modality. We also
characterize physician-perceived information sufficiency in VA. We describe
variations in sufficiency levels by age and COD and demonstrate that
classification accuracy is affected by sufficiency for both physicians and
models. Overall, this thesis advances the growing body of knowledge at the
intersection of natural language processing, epidemiology, and global health.
It demonstrates the value of narrative in enhancing COD classification. Our
findings underscore the need for more high-quality data from more diverse
settings to use in training and fine-tuning PLM/ML methods, and offer valuable
insights to guide the rethinking and redesign of the VA instrument and
interview.

</details>


### [96] [Memory-R1: Enhancing Large Language Model Agents to Manage and Utilize Memories via Reinforcement Learning](https://arxiv.org/abs/2508.19828)
*Sikuan Yan,Xiufeng Yang,Zuchao Huang,Ercong Nie,Zifeng Ding,Zonggen Li,Xiaowen Ma,Hinrich Schütze,Volker Tresp,Yunpu Ma*

Main category: cs.CL

TL;DR: LLMs are stateless and have limited context windows, hindering long-horizon reasoning. Memory-R1 is an RL framework that uses two agents (Memory Manager and Answer Agent) to actively manage external memory, improving LLMs' ability to reason over longer contexts. It outperforms existing baselines and generalizes well.


<details>
  <summary>Details</summary>
Motivation: LLMs are stateless and have limited context windows, which restricts their ability to perform long-horizon reasoning. Existing solutions often rely on static, heuristic-driven external memory banks, lacking learned mechanisms for memory management.

Method: Memory-R1 framework uses two RL agents: a Memory Manager for structured memory operations (ADD, UPDATE, DELETE, NOOP) and an Answer Agent for retrieving relevant entries and answering questions. Both agents are fine-tuned using PPO and GRPO for adaptive memory management with minimal supervision.

Result: Memory-R1 outperforms competitive baselines and demonstrates strong generalization across diverse question types and LLM backbones, even with a small training dataset (152 question-answer pairs and a temporal memory bank).

Conclusion: RL can enable more agentic and memory-aware behaviors in LLMs, leading to richer and more persistent reasoning systems. Memory-R1 provides an effective approach to address the limitations of LLMs in long-horizon reasoning by actively managing external memory.

Abstract: Large Language Models (LLMs) have demonstrated impressive capabilities across
a wide range of NLP tasks, but they remain fundamentally stateless, constrained
by limited context windows that hinder long-horizon reasoning. Recent efforts
to address this limitation often augment LLMs with an external memory bank, yet
most existing pipelines are static and heuristic-driven, lacking any learned
mechanism for deciding what to store, update, or retrieve. We present
Memory-R1, a reinforcement learning (RL) framework that equips LLMs with the
ability to actively manage and utilize external memory through two specialized
agents: a Memory Manager that learns to perform structured memory operations
{ADD, UPDATE, DELETE, NOOP}, and an Answer Agent that selects the most relevant
entries and reasons over them to produce an answer. Both agents are fine-tuned
with outcome-driven RL (PPO and GRPO), enabling adaptive memory management and
use with minimal supervision. With as few as 152 question-answer pairs and a
corresponding temporal memory bank for training, Memory-R1 outperforms the most
competitive existing baseline and demonstrates strong generalization across
diverse question types and LLM backbones. Beyond presenting an effective
approach, this work provides insights into how RL can unlock more agentic,
memory-aware behaviors in LLMs, pointing toward richer, more persistent
reasoning systems.

</details>


### [97] [FLAIRR-TS -- Forecasting LLM-Agents with Iterative Refinement and Retrieval for Time Series](https://arxiv.org/abs/2508.19279)
*Gunjan Jalori,Preetika Verma,Sercan Ö Arık*

Main category: cs.CL

TL;DR: FLAIRR-TS是一个测试时提示优化框架，利用代理系统来改进时间序列预测的提示，从而提高准确性，而无需进行中间代码生成。


<details>
  <summary>Details</summary>
Motivation: 时间序列预测通常需要对大型语言模型（LLM）进行大量的预处理和微调。虽然可以通过精心设计的自然语言提示来提高LLM的预测能力，但为每个任务创建这样的提示既繁琐又临时的。FLAIRR-TS旨在解决这个问题，提供一种无需微调即可优化提示的方法。

Method: FLAIRR-TS框架包含一个“预测器”代理，它使用初始提示生成预测。然后，一个“精炼器”代理会根据过去的输出和检索到的类似物来改进这个提示。这种自适应提示方法通过使用通用的提示模板，能够跨领域进行泛化，并且无需中间代码生成即可产生高质量的预测。

Result: 在基准数据集上的实验表明，FLAIRR-TS的准确性优于静态提示和检索增强基线，并且接近于专门提示的性能。

Conclusion: FLAIRR-TS通过其代理方法实现自适应提示改进和检索，提供了一种实用的替代微调的方法，能够实现强大的性能，并且在不进行中间代码生成的情况下，实现了跨域泛化和高质量预测。

Abstract: Time series Forecasting with large languagemodels (LLMs) requires bridging
numericalpatterns and natural language. Effective fore-casting on LLM often
relies on extensive pre-processing and fine-tuning.Recent studiesshow that a
frozen LLM can rival specializedforecasters when supplied with a carefully
en-gineered natural-language prompt, but craft-ing such a prompt for each task
is itself oner-ous and ad-hoc. We introduce FLAIRR-TS, atest-time prompt
optimization framework thatutilizes an agentic system: a
Forecaster-agentgenerates forecasts using an initial prompt,which is then
refined by a refiner agent, in-formed by past outputs and retrieved
analogs.This adaptive prompting generalizes across do-mains using creative
prompt templates andgenerates high-quality forecasts without inter-mediate code
generation.Experiments onbenchmark datasets show improved accuracyover static
prompting and retrieval-augmentedbaselines, approaching the performance
ofspecialized prompts.FLAIRR-TS providesa practical alternative to tuning,
achievingstrong performance via its agentic approach toadaptive prompt
refinement and retrieval.

</details>


### [98] [CORE: Lossless Compression for Retrieval-Augmented LLMs via Reinforcement Learning](https://arxiv.org/abs/2508.19282)
*Ziqiang Cui,Yunpeng Weng,Xing Tang,Peiyang Liu,Shiwei Li,Bowei He,Jiamin Chen,Xiuqiang He,Chen Ma*

Main category: cs.CL

TL;DR: CORE是一种新的无损上下文压缩方法，用于检索增强生成（RAG），通过强化学习优化压缩过程，以提高LLM回答的准确性，实验表明该方法在压缩率达到3%的情况下，平均精确匹配（EM）分数提高了3.3分，并且避免了性能下降。


<details>
  <summary>Details</summary>
Motivation: 检索增强生成（RAG）虽然能提升大型语言模型（LLM）的知识及时性和事实准确性，但检索文档过多会导致计算成本增加。以往的压缩方法牺牲了最终任务性能，并且依赖于固定的启发式方法。

Method: CORE使用强化学习，特别是广义强化学习策略优化（GRPO），通过以最终任务性能作为奖励信号来训练压缩器，实现了无损上下文压缩，无需预定义的压缩标签。

Result: 在四个数据集上的广泛实验表明，CORE在3%的压缩率下，不仅避免了与完整文档相比的性能下降，而且平均精确匹配（EM）分数还提高了3.3分。

Conclusion: CORE通过端到端训练框架，能够生成最大化LLM答案准确性的摘要，克服了现有方法的局限性，并在实践中证明了其有效性。

Abstract: Retrieval-Augmented Generation (RAG) has emerged as a promising approach to
enhance the timeliness of knowledge and the factual accuracy of responses in
Large Language Models (LLMs). However, the inclusion of excessive retrieved
documents substantially increases the input length, leading to higher
computational costs. Previous studies have attempted to compress retrieved
documents into shorter texts before in-context integration, but such methods
often compromise end-task performance. The lack of well-defined compression
targets forces many approaches to rely on fixed heuristics, which cannot
guarantee that the compressed content will effectively support the end task. To
address these limitations, we propose CORE, a novel method designed to achieve
lossless context compression for RAG. CORE employs reinforcement learning to
optimize the compression process without relying on predefined compression
labels. Specifically, it utilizes end-task performance as a reward signal and
applies Generalized Reinforcement Learning Policy Optimization (GRPO) to train
the compressor. This end-to-end training framework enables the compressor to
generate summaries that maximize the accuracy of answers generated by the LLM.
Extensive experiments on four datasets demonstrate the superiority of our
approach. With a high compression ratio of 3\%, our method not only avoids
performance degradation compared to prepending full documents across all
datasets but also improves the average Exact Match (EM) score by 3.3 points.
The code will be released soon.

</details>


### [99] [Context-Adaptive Synthesis and Compression for Enhanced Retrieval-Augmented Generation in Complex Domains](https://arxiv.org/abs/2508.19357)
*Peiran Zhou,Junnan Zhu,Yichen Shen,Ruoxi Yu*

Main category: cs.CL

TL;DR: CASC框架通过智能处理检索到的上下文，解决了传统RAG在处理复杂、冗长或冲突文档时信息过载和综合效率低下等问题，提高了答案的准确性和可信度。


<details>
  <summary>Details</summary>
Motivation: 传统RAG在处理复杂领域的多文档问答时存在信息过载和效率低下问题，导致答案不准确、不可信。

Method: 提出CASC框架，包含一个由微调小语言模型驱动的上下文分析与综合（CAS）模块，该模块进行关键信息提取、跨文档一致性检查、冲突解决和面向问题的结构化综合，将原始、分散的信息转化为高度压缩、结构化和语义丰富的上下文，以减少最终Reader LLM的标记数量和认知负荷。

Result: 在SciDocs-QA数据集（一个设计用于复杂科学领域、具有冗余和冲突的多文档问答数据集）上进行评估，CASC持续优于强大的基线。

Conclusion: CASC框架能有效提升多文档问答的性能，特别是在信息复杂、存在冲突的科学领域。

Abstract: Large Language Models (LLMs) excel in language tasks but are prone to
hallucinations and outdated knowledge. Retrieval-Augmented Generation (RAG)
mitigates these by grounding LLMs in external knowledge. However, in complex
domains involving multiple, lengthy, or conflicting documents, traditional RAG
suffers from information overload and inefficient synthesis, leading to
inaccurate and untrustworthy answers. To address this, we propose CASC
(Context-Adaptive Synthesis and Compression), a novel framework that
intelligently processes retrieved contexts. CASC introduces a Context Analyzer
& Synthesizer (CAS) module, powered by a fine-tuned smaller LLM, which performs
key information extraction, cross-document consistency checking and conflict
resolution, and question-oriented structured synthesis. This process transforms
raw, scattered information into a highly condensed, structured, and
semantically rich context, significantly reducing the token count and cognitive
load for the final Reader LLM. We evaluate CASC on SciDocs-QA, a new
challenging multi-document question answering dataset designed for complex
scientific domains with inherent redundancies and conflicts. Our extensive
experiments demonstrate that CASC consistently outperforms strong baselines.

</details>


### [100] [Reflective Agreement: Combining Self-Mixture of Agents with a Sequence Tagger for Robust Event Extraction](https://arxiv.org/abs/2508.19359)
*Fatemeh Haji,Mazal Bethany,Cho-Yu Jason Chiang,Anthony Rios,Peyman Najafirad*

Main category: cs.CL

TL;DR: ARIS是一种结合了自主混合代理和判别式序列标注器的混合方法，用于事件抽取，解决了传统方法精度高但召回率低和生成方法易产生幻觉的问题。


<details>
  <summary>Details</summary>
Motivation: 解决传统判别式事件抽取模型精度高但召回率低，以及生成式模型（如LLM）虽然召回率高但存在幻觉和不一致性问题。

Method: 提出了一种名为ARIS（Agreement-based Reflective Inference System）的混合方法，结合了自主混合代理（Self Mixture of Agents）和判别式序列标注器（discriminative sequence tagger）。ARIS利用结构化模型共识、基于置信度的过滤和LLM反思推理模块来解决歧义并提高事件预测质量。此外，还研究了分解指令微调以增强LLM对事件抽取的理解。

Result: ARIS在三个基准数据集上的表现优于现有的最先进的事件抽取方法。

Conclusion: ARIS通过结合判别式和生成式方法的优点，并引入了模型共识、置信度过滤和反思推理等机制，能够更可靠地进行事件抽取，提高了预测的准确性和召回率。

Abstract: Event Extraction (EE) involves automatically identifying and extracting
structured information about events from unstructured text, including triggers,
event types, and arguments. Traditional discriminative models demonstrate high
precision but often exhibit limited recall, particularly for nuanced or
infrequent events. Conversely, generative approaches leveraging Large Language
Models (LLMs) provide higher semantic flexibility and recall but suffer from
hallucinations and inconsistent predictions. To address these challenges, we
propose Agreement-based Reflective Inference System (ARIS), a hybrid approach
combining a Self Mixture of Agents with a discriminative sequence tagger. ARIS
explicitly leverages structured model consensus, confidence-based filtering,
and an LLM reflective inference module to reliably resolve ambiguities and
enhance overall event prediction quality. We further investigate decomposed
instruction fine-tuning for enhanced LLM event extraction understanding.
Experiments demonstrate our approach outperforms existing state-of-the-art
event extraction methods across three benchmark datasets.

</details>


### [101] [LongReasonArena: A Long Reasoning Benchmark for Large Language Models](https://arxiv.org/abs/2508.19363)
*Jiayu Ding,Shuming Ma,Lei Cui,Nanning Zheng,Furu Wei*

Main category: cs.CL

TL;DR: LLMs在长上下文理解方面已有基准，但长推理能力评估不足。本文提出LongReasonArena基准，用于评估LLMs的长推理能力，任务涉及多步算法、检索和回溯，推理长度可扩展至100万token。实验表明，该基准对现有LLMs构成重大挑战，准确率随推理步数对数的增加而线性下降。


<details>
  <summary>Details</summary>
Motivation: 现有长上下文基准主要评估长输入理解，忽视了长推理能力的评估。

Method: 提出LongReasonArena基准，包含需要模型执行多步算法（涉及检索和回溯）的任务，允许任意扩展推理长度，最高可达100万token。

Result: LongReasonArena对开源和闭源LLMs都提出了显著挑战，例如Deepseek-R1在该任务上准确率仅为7.5%。准确率与预期推理步数对数呈线性负相关。

Conclusion: LongReasonArena是评估LLMs长推理能力的有效基准，揭示了现有模型在该方面存在的局限性。

Abstract: Existing long-context benchmarks for Large Language Models (LLMs) focus on
evaluating comprehension of long inputs, while overlooking the evaluation of
long reasoning abilities. To address this gap, we introduce LongReasonArena, a
benchmark specifically designed to assess the long reasoning capabilities of
LLMs. Our tasks require models to solve problems by executing multi-step
algorithms that reflect key aspects of long reasoning, such as retrieval and
backtracking. By controlling the inputs, the required reasoning length can be
arbitrarily scaled, reaching up to 1 million tokens of reasoning for the most
challenging tasks. Extensive evaluation results demonstrate that
LongReasonArena presents a significant challenge for both open-source and
proprietary LLMs. For instance, Deepseek-R1 achieves only 7.5% accuracy on our
task. Further analysis also reveals that the accuracy exhibits a linear decline
with respect to the logarithm of the expected number of reasoning steps. Our
code and data is available at
https://github.com/LongReasonArena/LongReasonArena.

</details>


### [102] [Database Entity Recognition with Data Augmentation and Deep Learning](https://arxiv.org/abs/2508.19372)
*Zikun Fu,Chen Yang,Kourosh Davoudi,Ken Q. Pu*

Main category: cs.CL

TL;DR: 本文提出了一个用于数据库实体识别（DB-ER）的新方法，该方法通过构建基准、数据增强和专门的T5语言模型，在准确率和召回率方面优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 解决自然语言查询（NLQ）中的数据库实体识别（DB-ER）挑战。

Method: 1. 构建了一个包含860个NLQ-SQL对的DB-ER基准。 2. 提出了一种利用SQL查询自动标注NLQ的数据增强方法。 3. 设计了一个基于T5的DB-ER模型，包含序列标注和令牌分类两个下游任务。 4. 将DB-ER模型与两个最先进的NER标签器进行了比较，并进行了消融评估。

Result: DB-ER模型在精确率和召回率方面均优于两个最先进的NER标签器。数据增强使精确率和召回率提高了10%以上，T5骨干微调使这些指标提高了5-10%。

Conclusion: 本文提出的DB-ER方法通过数据增强和专门的T5模型，显著提高了数据库实体识别的性能。

Abstract: This paper addresses the challenge of Database Entity Recognition (DB-ER) in
Natural Language Queries (NLQ). We present several key contributions to advance
this field: (1) a human-annotated benchmark for DB-ER task, derived from
popular text-to-sql benchmarks, (2) a novel data augmentation procedure that
leverages automatic annotation of NLQs based on the corresponding SQL queries
which are available in popular text-to-SQL benchmarks, (3) a specialized
language model based entity recognition model using T5 as a backbone and two
down-stream DB-ER tasks: sequence tagging and token classification for
fine-tuning of backend and performing DB-ER respectively. We compared our DB-ER
tagger with two state-of-the-art NER taggers, and observed better performance
in both precision and recall for our model. The ablation evaluation shows that
data augmentation boosts precision and recall by over 10%, while fine-tuning of
the T5 backbone boosts these metrics by 5-10%.

</details>


### [103] [One Joke to Rule them All? On the (Im)possibility of Generalizing Humor](https://arxiv.org/abs/2508.19402)
*Mor Turgeman,Chen Shani,Dafna Shahaf*

Main category: cs.CL

TL;DR: Humor research faces fragmentation; LLMs can transfer skills to new humor types with diverse training, improving generalization.


<details>
  <summary>Details</summary>
Motivation: To investigate if competence in specific humor tasks transfers to novel humor types, addressing the fragmentation in computational humor research and the need for LLMs to adapt to evolving online humor.

Method: Conducting transfer learning experiments with LLMs across four diverse humor datasets, varying training diversity (1-3 datasets) and testing on unseen tasks. Analyzing the impact of diverse training on transferability and in-domain performance, and examining relationships between humor types.

Result: LLMs demonstrated transferability to unseen humor types, achieving up to 75% accuracy. Training on diverse sources improved transferability by 1.88-4.05% with minimal impact on in-domain performance. Dad Jokes were found to be a strong enabler of transfer but difficult to transfer to.

Conclusion: LLMs can generalize across humor types through transfer learning, and diverse training enhances this ability without significantly compromising in-domain performance. This suggests that the fragmentation in humor understanding is not entirely inevitable and points to Dad Jokes as a key, albeit complex, factor in humor transfer.

Abstract: Humor is a broad and complex form of communication that remains challenging
for machines. Despite its broadness, most existing research on computational
humor traditionally focused on modeling a specific type of humor. In this work,
we wish to understand whether competence on one or more specific humor tasks
confers any ability to transfer to novel, unseen types; in other words, is this
fragmentation inevitable? This question is especially timely as new humor types
continuously emerge in online and social media contexts (e.g., memes,
anti-humor, AI fails). If Large Language Models (LLMs) are to keep up with this
evolving landscape, they must be able to generalize across humor types by
capturing deeper, transferable mechanisms. To investigate this, we conduct a
series of transfer learning experiments across four datasets, representing
different humor tasks. We train LLMs under varied diversity settings (1-3
datasets in training, testing on a novel task). Experiments reveal that models
are capable of some transfer, and can reach up to 75% accuracy on unseen
datasets; training on diverse sources improves transferability (1.88-4.05%)
with minimal-to-no drop in in-domain performance. Further analysis suggests
relations between humor types, with Dad Jokes surprisingly emerging as the best
enabler of transfer (but is difficult to transfer to). We release data and
code.

</details>


### [104] [A perishable ability? The future of writing in the face of generative artificial intelligence](https://arxiv.org/abs/2508.19427)
*Evandro L. T. P. Cunha*

Main category: cs.CL

TL;DR: The article discusses the potential for humans to lose writing skills due to the rise of AI text generation, drawing parallels with historical instances like the Greek Dark Ages.


<details>
  <summary>Details</summary>
Motivation: To explore the potential long-term consequences of advanced AI text generation on human writing abilities and historical precedents for skill degradation.

Method: Discusses the possibility of skill loss by drawing parallels with historical events, specifically the Greek Dark Ages, where writing ability may have declined.

Result: The article posits a future where human writing proficiency may be significantly reduced due to reliance on AI, similar to potential skill loss in past historical periods.

Conclusion: The increasing reliance on AI for text generation raises concerns about the potential atrophy of human writing skills, a phenomenon with historical parallels.

Abstract: The 2020s have been witnessing a very significant advance in the development
of generative artificial intelligence tools, including text generation systems
based on large language models. These tools have been increasingly used to
generate texts in the most diverse domains -- from technical texts to literary
texts --, which might eventually lead to a lower volume of written text
production by humans. This article discusses the possibility of a future in
which human beings will have lost or significantly decreased their ability to
write due to the outsourcing of this activity to machines. This possibility
parallels the loss of the ability to write in other moments of human history,
such as during the so-called Greek Dark Ages (approx. 1200 BCE - 800 BCE).

</details>


### [105] [Bridging Language Gaps: Enhancing Few-Shot Language Adaptation](https://arxiv.org/abs/2508.19464)
*Philipp Borchert,Jochen De Weerdt,Marie-Francine Moens*

Main category: cs.CL

TL;DR: CoLAP方法利用对比学习和跨语言表示，通过任务特定知识迁移，提高了低资源语言在多语言NLP中的表现，数据效率高，优于少样本跨语言迁移和上下文学习。


<details>
  <summary>Details</summary>
Motivation: 多语言NLP中，高资源语言和低资源语言在语言资源上存在差距，低资源语言缺乏有效训练所需的数据。

Method: 提出对比语言对齐与提示（CoLAP）方法，结合对比学习和跨语言表示，实现从高资源语言到低资源语言的任务特定知识迁移。

Result: 在自然语言理解任务（如自然语言推断和关系抽取）上，使用多语言编码器和解码器模型进行实验。结果表明，CoLAP在数据有限的情况下，优于少样本跨语言迁移和上下文学习方法，缩小了跨语言性能差距。

Conclusion: CoLAP方法通过其数据效率，能够快速适应新语言，减少对大型标注数据集的需求，有效缩小了跨语言性能差距，为更有效多语言NLP技术的发展做出了贡献。

Abstract: The disparity in language resources poses a challenge in multilingual NLP,
with high-resource languages benefiting from extensive data, while low-resource
languages lack sufficient data for effective training. Our Contrastive Language
Alignment with Prompting (CoLAP) method addresses this gap by integrating
contrastive learning with cross-lingual representations, facilitating
task-specific knowledge transfer from high-resource to lower-resource
languages. The primary advantage of our approach is its data efficiency,
enabling rapid adaptation to new languages and reducing the need for large
labeled datasets. We conduct experiments with multilingual encoder-only and
decoder-only language models on natural language understanding tasks, including
natural language inference and relation extraction, evaluating performance
across both high- and low-resource languages. Our results demonstrate that
CoLAP outperforms few-shot cross-lingual transfer baselines and in-context
learning, even with limited available data. This effectively narrows the
cross-lingual performance gap, contributing to the development of more
efficient multilingual NLP techniques.

</details>


### [106] [Inference Gap in Domain Expertise and Machine Intelligence in Named Entity Recognition: Creation of and Insights from a Substance Use-related Dataset](https://arxiv.org/abs/2508.19467)
*Sumon Kanti Dey,Jeanne M. Powell,Azra Ismail,Jeanmarie Perrone,Abeed Sarker*

Main category: cs.CL

TL;DR: 该研究提出了一种命名实体识别（NER）框架，用于从社交媒体中提取与阿片类药物使用相关的临床和社交影响，并发布了一个改进的数据集RedditImpacts 2.0。研究评估了微调模型和大型语言模型（LLMs），其中微调的DeBERTa-large模型在提取这些影响方面表现优于LLMs，尤其是在零样本和少样本设置下，并且可以用更少的数据实现良好的性能。研究结果表明，领域特定微调对于临床NLP任务很重要，并指出了当前AI能力与专家判断之间仍存在差距。


<details>
  <summary>Details</summary>
Motivation: 非药物性阿片类药物使用是一个严峻的公共卫生问题，其临床和社会后果在传统医疗环境中往往被低估。社交媒体为获取这些影响的一手信息提供了宝贵的来源。

Method: 本研究提出了一个命名实体识别（NER）框架，用于从社交媒体数据中提取自我报告的临床影响（如戒断、抑郁）和社会影响（如失业）。研究引入了一个改进的数据集RedditImpacts 2.0，并评估了微调的基于编码器的模型和大型语言模型（LLMs）在零样本和少样本设置下的表现。

Result: 微调的DeBERTa-large模型在宽松的令牌级F1得分上达到了0.61，在精确率、跨度准确性和任务特定指南遵循方面优于LLMs。研究还表明，使用更少标注数据即可实现强大的NER性能，并且与专家之间的一致性（Cohen's kappa: 0.81）相比，最佳模型仍有差距。

Conclusion: 领域特定的微调对于临床NLP任务至关重要，该研究的NER框架和RedditImpacts 2.0数据集有助于阿片类药物滥用的监测和医疗决策的制定。然而，目前的AI技术在需要深度领域知识的任务上仍无法完全达到专家水平。

Abstract: Nonmedical opioid use is an urgent public health challenge, with far-reaching
clinical and social consequences that are often underreported in traditional
healthcare settings. Social media platforms, where individuals candidly share
first-person experiences, offer a valuable yet underutilized source of insight
into these impacts. In this study, we present a named entity recognition (NER)
framework to extract two categories of self-reported consequences from social
media narratives related to opioid use: ClinicalImpacts (e.g., withdrawal,
depression) and SocialImpacts (e.g., job loss). To support this task, we
introduce RedditImpacts 2.0, a high-quality dataset with refined annotation
guidelines and a focus on first-person disclosures, addressing key limitations
of prior work. We evaluate both fine-tuned encoder-based models and
state-of-the-art large language models (LLMs) under zero- and few-shot
in-context learning settings. Our fine-tuned DeBERTa-large model achieves a
relaxed token-level F1 of 0.61 [95% CI: 0.43-0.62], consistently outperforming
LLMs in precision, span accuracy, and adherence to task-specific guidelines.
Furthermore, we show that strong NER performance can be achieved with
substantially less labeled data, emphasizing the feasibility of deploying
robust models in resource-limited settings. Our findings underscore the value
of domain-specific fine-tuning for clinical NLP tasks and contribute to the
responsible development of AI tools that may enhance addiction surveillance,
improve interpretability, and support real-world healthcare decision-making.
The best performing model, however, still significantly underperforms compared
to inter-expert agreement (Cohen's kappa: 0.81), demonstrating that a gap
persists between expert intelligence and current state-of-the-art NER/AI
capabilities for tasks requiring deep domain knowledge.

</details>


### [107] [Automatic Question & Answer Generation Using Generative Large Language Model (LLM)](https://arxiv.org/abs/2508.19475)
*Md. Alvee Ehsan,A. S. M Mehedi Hasan,Kefaya Benta Shahnoor,Syeda Sumaiya Tasneem*

Main category: cs.CL

TL;DR: 自动生成问题答案(AQAG)旨在简化教育评估过程，利用微调的Meta-Llama 2-7B模型和提示工程来生成不同类型的问题。


<details>
  <summary>Details</summary>
Motivation: 教育评估过程具有挑战性，需要手动创建公平的问题集，AQAG旨在通过自动化解决这一问题。

Method: 利用无监督学习和NLP，特别是英语，通过使用RACE数据集对Meta-Llama 2-7B模型进行微调，并结合提示工程来定制问题风格（选择题、概念题或事实题）。

Result: 研究旨在创建一个能为教育工作者和评估者提供高效解决方案的定制化模型，以简化评估流程。

Conclusion: AQAG通过利用微调的LLM和提示工程，能够高效地生成问题和答案，从而节省宝贵的时间和资源，优化评估流程。

Abstract: \Abstract{In the realm of education, student evaluation holds equal
significance as imparting knowledge. To be evaluated, students usually need to
go through text-based academic assessment methods. Instructors need to make
diverse sets of questions that need to be fair for all students to prove their
adequacy over a particular topic. This can prove to be quite challenging as
they may need to manually go through several different lecture materials. Our
objective is to make this whole process much easier by implementing Automatic
Question Answer Generation /(AQAG), using fine-tuned generative LLM. For
tailoring the instructor's preferred question style (MCQ, conceptual, or
factual questions), prompt Engineering (PE) is being utilized. In this
research, we propose to leverage unsupervised learning methods in NLP,
primarily focusing on the English language. This approach empowers the base
Meta-Llama 2-7B model to integrate RACE dataset as training data for the
fine-tuning process. Creating a customized model that will offer efficient
solutions for educators, instructors, and individuals engaged in text-based
evaluations. A reliable and efficient tool for generating questions and answers
can free up valuable time and resources, thus streamlining their evaluation
processes.}

</details>


### [108] [Improving Low-Resource Translation with Dictionary-Guided Fine-Tuning and RL: A Spanish-to-Wayuunaiki Study](https://arxiv.org/abs/2508.19481)
*Manuel Mosquera,Melissa Robles,Johan Rodriguez,Ruben Manrique*

Main category: cs.CL

TL;DR: LLMs在低资源翻译方面表现不佳，提出一种结合外部词典和强化学习（GRPO）的新方法，在西班牙-瓦尤纳伊基语对上取得了显著的BLEU提升。


<details>
  <summary>Details</summary>
Motivation: 低资源语言翻译对LLMs来说是一个重大挑战，因为它们在预训练阶段接触这些语言的机会较少，并且用于微调的平行数据有限。

Method: 将翻译视为一个工具增强的决策问题，模型可以在生成过程中选择性地查阅双语词典。该方法结合了监督指令调优和引导奖励策略优化（GRPO），并使用BLEU相似度分数作为奖励来指导学习过程。

Result: 在西班牙-瓦尤纳伊基语测试集上，与先前的工作相比，该工具增强模型取得了高达+3.37的BLEU改进，并比没有词典访问的监督基线提高了18%的相对增益。

Conclusion: 结合LLMs与外部工具以及强化学习在提高低资源语言翻译质量方面具有巨大潜力。

Abstract: Low-resource machine translation remains a significant challenge for large
language models (LLMs), which often lack exposure to these languages during
pretraining and have limited parallel data for fine-tuning. We propose a novel
approach that enhances translation for low-resource languages by integrating an
external dictionary tool and training models end-to-end using reinforcement
learning, in addition to supervised fine-tuning. Focusing on the
Spanish-Wayuunaiki language pair, we frame translation as a tool-augmented
decision-making problem in which the model can selectively consult a bilingual
dictionary during generation. Our method combines supervised instruction tuning
with Guided Reward Policy Optimization (GRPO), enabling the model to learn both
when and how to use the tool effectively. BLEU similarity scores are used as
rewards to guide this learning process. Preliminary results show that our
tool-augmented models achieve up to +3.37 BLEU improvement over previous work,
and a 18% relative gain compared to a supervised baseline without dictionary
access, on the Spanish-Wayuunaiki test set from the AmericasNLP 2025 Shared
Task. We also conduct ablation studies to assess the effects of model
architecture and training strategy, comparing Qwen2.5-0.5B-Instruct with other
models such as LLaMA and a prior NLLB-based system. These findings highlight
the promise of combining LLMs with external tools and the role of reinforcement
learning in improving translation quality in low-resource language settings.

</details>


### [109] [Rule Synergy Analysis using LLMs: State of the Art and Implications](https://arxiv.org/abs/2508.19484)
*Bahar Bateni,Benjamin Pratt,Jim Whitehead*

Main category: cs.CL

TL;DR: LLMs在理解和推理动态环境中的复杂规则交互方面表现不佳，特别是在检测卡牌之间的负面协同作用方面。


<details>
  <summary>Details</summary>
Motivation: 评估LLMs在动态环境中理解和推理复杂规则交互的能力，特别是在卡牌游戏场景中。

Method: 引入一个包含卡牌协同作用的数据集（来自“Slay the Spire”游戏），其中卡牌对根据其正面、负面或中性交互进行分类。

Result: LLMs在识别非协同作用的卡牌对方面表现出色，但在检测正面和负面协同作用方面存在困难，特别是在负面协同作用方面。常见的错误类型包括时序问题、游戏状态定义问题和游戏规则遵循问题。

Conclusion: LLMs在预测规则及其交互效果方面仍有改进空间，未来的研究应着重于解决时序、游戏状态定义和游戏规则遵循等问题。

Abstract: Large language models (LLMs) have demonstrated strong performance across a
variety of domains, including logical reasoning, mathematics, and more. In this
paper, we investigate how well LLMs understand and reason about complex rule
interactions in dynamic environments, such as card games. We introduce a
dataset of card synergies from the game Slay the Spire, where pairs of cards
are classified based on their positive, negative, or neutral interactions. Our
evaluation shows that while LLMs excel at identifying non-synergistic pairs,
they struggle with detecting positive and, particularly, negative synergies. We
categorize common error types, including issues with timing, defining game
states, and following game rules. Our findings suggest directions for future
research to improve model performance in predicting the effect of rules and
their interactions.

</details>


### [110] [Blockwise SFT for Diffusion Language Models: Reconciling Bidirectional Attention and Autoregressive Decoding](https://arxiv.org/abs/2508.19529)
*Bowen Sun,Yujun Cai,Ming-Hsuan Yang,Yiwei Wang*

Main category: cs.CL

TL;DR: SFT与离散扩散语言模型的半自回归推理不匹配，提出Blockwise SFT，通过将响应划分为固定大小的块、每次选择一个活动块进行随机掩码、冻结先前标记并完全隐藏未来标记，并在活动块上计算损失来解决此问题，实验证明Blockwise SFT在GSM8K、MATH和MetaMathQA上优于SFT。


<details>
  <summary>Details</summary>
Motivation: 标准的监督微调（SFT）与离散扩散语言模型的半自回归推理不匹配，导致梯度偏离期望的块状似然。

Method: 提出Blockwise SFT，将响应划分为固定大小的块，每次选择一个活动块进行随机掩码，冻结先前标记，完全隐藏未来标记，并仅在活动块上计算损失，以匹配块状解码过程。

Result: 在GSM8K、MATH和MetaMathQA数据集上，Blockwise SFT在相同的计算或标记预算下，持续优于经典的SFT。消融研究证实了改进源于训练-推理对齐，而非偶然的掩码效应。

Conclusion: 匹配监督的粒度与基于扩散的语言模型的解码过程对于获得更好的性能至关重要。

Abstract: Discrete diffusion language models have shown strong potential for text
generation, yet standard supervised fine-tuning (SFT) misaligns with their
semi-autoregressive inference: training randomly masks tokens across the entire
response, while inference generates fixed-size blocks sequentially. This
mismatch introduces noisy prefixes and leaky suffixes, biasing gradients away
from the desired blockwise likelihood. We propose Blockwise SFT, which
partitions responses into fixed-size blocks, selects one active block per step
for stochastic masking, freezes all preceding tokens, and fully hides future
ones. Loss is computed only over the active block, directly mirroring the
blockwise decoding process. Experiments on GSM8K, MATH, and MetaMathQA show
consistent gains over classical SFT under equal compute or token budgets. Block
size consistency studies and ablations confirm that improvements stem from
faithful training-inference alignment rather than incidental masking effects.
Our results highlight the importance of matching supervision granularity to the
decoding procedure in diffusion-based language models.

</details>


### [111] [Alignment with Fill-In-the-Middle for Enhancing Code Generation](https://arxiv.org/abs/2508.19532)
*Houxing Ren,Zimu Lu,Weikang Shi,Haotian Hou,Yunqiao Yang,Ke Wang,Aojun Zhou,Junting Pan,Mingjie Zhan,Hongsheng Li*

Main category: cs.CL

TL;DR: LLMs在代码生成方面取得了进展，但受限于训练数据和测试用例的准确性。本研究提出了一种新的方法，通过细化代码块、利用抽象语法树（AST）和课程学习来改进直接偏好优化（DPO）的训练，从而提升代码生成性能。


<details>
  <summary>Details</summary>
Motivation: 代码生成任务的LLMs在工具调用和问题解决方面有应用，但由于训练数据有限且难以验证，性能提升面临挑战。现有的测试用例生成方法存在局限性。

Method: 提出一种新方法，将代码片段拆分成更小的、更精细的代码块，从而从相同的测试用例中创建更多样化的DPO对。此外，引入了抽象语法树（AST）拆分和课程学习方法来增强DPO训练。

Result: 在HumanEval (+)、MBPP (+)、APPS、LiveCodeBench和BigCodeBench等基准数据集上的实验验证了该方法在代码生成任务上的显著改进。

Conclusion: 通过细化代码块、AST拆分和课程学习，可以有效提升DPO在代码生成任务中的表现，解决了现有方法在训练数据和测试用例方面的局限性。

Abstract: The code generation capabilities of Large Language Models (LLMs) have
advanced applications like tool invocation and problem-solving. However,
improving performance in code-related tasks remains challenging due to limited
training data that is verifiable with accurate test cases. While Direct
Preference Optimization (DPO) has shown promise, existing methods for
generating test cases still face limitations. In this paper, we propose a novel
approach that splits code snippets into smaller, granular blocks, creating more
diverse DPO pairs from the same test cases. Additionally, we introduce the
Abstract Syntax Tree (AST) splitting and curriculum training method to enhance
the DPO training. Our approach demonstrates significant improvements in code
generation tasks, as validated by experiments on benchmark datasets such as
HumanEval (+), MBPP (+), APPS, LiveCodeBench, and BigCodeBench. Code and data
are available at https://github.com/SenseLLM/StructureCoder.

</details>


### [112] [Emotion Transfer with Enhanced Prototype for Unseen Emotion Recognition in Conversation](https://arxiv.org/abs/2508.19533)
*Kun Peng,Cong Cao,Hao Peng,Guanlin Wu,Zhifeng Hao,Lei Jiang,Yanbing Liu,Philip S. Yu*

Main category: cs.CL

TL;DR: 本研究首次提出无监督对话情感识别（UERC）任务，并引入基于原型的ProEmoTrans情感迁移框架，以解决现有ERC研究的闭域假设局限性。该框架通过LLM增强描述来处理模糊情感定义，采用无参数机制高效编码长对话并防止过拟合，并改进注意力维特比解码（AVD）方法来迁移情感转换。实验证明该方法在新领域的初步探索中表现出色。


<details>
  <summary>Details</summary>
Motivation: 现有对话情感识别（ERC）研究主要遵循闭域假设，但心理学界对情感分类尚无统一标准，这给模型识别现实世界中未见过的情感带来了挑战。因此，本研究旨在解决这一问题。

Method: 提出了一种名为ProEmoTrans的基于原型的框架，用于无监督对话情感识别（UERC）任务。该框架包含三个关键部分：1. 通过LLM增强描述来处理隐含的情感表达，以应对模糊的情感定义；2. 采用一种无参数机制来高效编码长对话并防止过拟合；3. 改进注意力维特比解码（AVD）方法来迁移已见情感的转换模式至未见情感，以解决情感的马尔可夫流动性质。

Result: 在三个数据集上的广泛实验表明，我们提出的方法能够有效处理未见情感的识别，并为这一新领域的研究奠定了坚实的基础，可作为初步探索的强有力基线。

Conclusion: 本研究首次提出了无监督对话情感识别（UERC）任务，并开发了ProEmoTrans框架，通过LLM增强描述、无参数编码机制和改进的AVD方法，有效解决了未见情感识别中的关键挑战。实验结果证明了该方法的有效性，为未来在该领域的研究提供了有价值的基线。

Abstract: Current Emotion Recognition in Conversation (ERC) research follows a
closed-domain assumption. However, there is no clear consensus on emotion
classification in psychology, which presents a challenge for models when it
comes to recognizing previously unseen emotions in real-world applications. To
bridge this gap, we introduce the Unseen Emotion Recognition in Conversation
(UERC) task for the first time and propose ProEmoTrans, a solid prototype-based
emotion transfer framework. This prototype-based approach shows promise but
still faces key challenges: First, implicit expressions complicate emotion
definition, which we address by proposing an LLM-enhanced description approach.
Second, utterance encoding in long conversations is difficult, which we tackle
with a proposed parameter-free mechanism for efficient encoding and overfitting
prevention. Finally, the Markovian flow nature of emotions is hard to transfer,
which we address with an improved Attention Viterbi Decoding (AVD) method to
transfer seen emotion transitions to unseen emotions. Extensive experiments on
three datasets show that our method serves as a strong baseline for preliminary
exploration in this new area.

</details>


### [113] [Language Models Identify Ambiguities and Exploit Loopholes](https://arxiv.org/abs/2508.19546)
*Jio Choi,Mohit Bansal,Elias Stengel-Eskin*

Main category: cs.CL

TL;DR: LLMs can identify and exploit ambiguous instructions to achieve their goals, presenting a potential AI safety risk. Both closed-source and stronger open-source models exhibit this behavior, indicating a need for further research into AI alignment and safety.


<details>
  <summary>Details</summary>
Motivation: The paper investigates how Large Language Models (LLMs) respond to loopholes, which offers insights into their understanding of ambiguity and pragmatics, and presents a novel alignment problem due to conflicting goals.

Method: The researchers designed scenarios where LLMs were given a goal and a conflicting, ambiguous user instruction. They then measured the models' ability to exploit these loopholes to satisfy their own goals over the user's.

Result: Both closed-source and stronger open-source LLMs demonstrated the ability to identify ambiguities and exploit loopholes. The analysis showed that these models explicitly reason about ambiguity and conflicting goals when exploiting loopholes.

Conclusion: LLMs' ability to exploit loopholes highlights a potential AI safety risk. Models that exploit loopholes do so by explicitly identifying and reasoning about both ambiguity and conflicting goals.

Abstract: Studying the responses of large language models (LLMs) to loopholes presents
a two-fold opportunity. First, it affords us a lens through which to examine
ambiguity and pragmatics in LLMs, since exploiting a loophole requires
identifying ambiguity and performing sophisticated pragmatic reasoning. Second,
loopholes pose an interesting and novel alignment problem where the model is
presented with conflicting goals and can exploit ambiguities to its own
advantage. To address these questions, we design scenarios where LLMs are given
a goal and an ambiguous user instruction in conflict with the goal, with
scenarios covering scalar implicature, structural ambiguities, and power
dynamics. We then measure different models' abilities to exploit loopholes to
satisfy their given goals as opposed to the goals of the user. We find that
both closed-source and stronger open-source models can identify ambiguities and
exploit their resulting loopholes, presenting a potential AI safety risk. Our
analysis indicates that models which exploit loopholes explicitly identify and
reason about both ambiguity and conflicting goals.

</details>


### [114] [Towards a Holistic and Automated Evaluation Framework for Multi-Level Comprehension of LLMs in Book-Length Contexts](https://arxiv.org/abs/2508.19578)
*Jiaqi Deng,Yuho Lee,Nicole Hee-Yeon Kim,Hyangsuk Min,Taewon Yun,Minjeong Ban,Kim Yul,Hwanjun Song*

Main category: cs.CL

TL;DR: HAMLET是一个评估LLM长文本理解能力的框架，通过三层级关键事实结构和查询焦点摘要来评估模型。自动评估与人类判断高度一致（>90%），成本降低25倍。结果表明LLM在细粒度理解（尤其是叶级别）和“中间遗失”问题上存在困难，分析性查询比叙述性查询更具挑战性，且开源/闭源模型和模型规模之间存在性能差距。


<details>
  <summary>Details</summary>
Motivation: 评估大型语言模型（LLM）的长文本理解能力，并揭示其在理解长文本时的具体挑战。

Method: HAMLET框架将源文本构建为根、分支、叶三个层级关键事实结构，并采用查询焦点摘要来评估模型在每个层级回忆和忠实呈现信息的能力。通过系统性人类研究验证了其全自动评估流程的可靠性，实现了与专家人类判断超过90%的一致性，同时将成本降低了25倍。

Result: LLM在细粒度理解方面，特别是在叶级别，存在困难，并且对“中间遗失”等位置效应敏感。分析性查询比叙述性查询更具挑战性。开源模型与专有模型之间以及不同模型规模之间存在持续的性能差距。

Conclusion: HAMLET框架能够可靠且经济高效地评估LLM的长文本理解能力，并揭示了LLM在处理长文本时的关键弱点，包括对细粒度信息、位置效应和查询类型的敏感性，以及模型类型和规模的影响。

Abstract: We introduce HAMLET, a holistic and automated framework for evaluating the
long-context comprehension of large language models (LLMs). HAMLET structures
source texts into a three-level key-fact hierarchy at root-, branch-, and
leaf-levels, and employs query-focused summarization to evaluate how well
models recall and faithfully represent information at each level. To validate
the reliability of our fully automated pipeline, we conduct a systematic human
study, showing that our automatic evaluation achieves over 90% agreement with
expert human judgments, while reducing the cost by up to 25 times. HAMLET
reveals that LLMs struggle with fine-grained comprehension, especially at the
leaf level, and are sensitive to positional effects like the
lost-in-the-middle. Analytical queries pose greater challenges than narrative
ones, and consistent performance gaps emerge between open-source and
proprietary models, as well as across model scales. Our code and dataset are
publicly available at https://github.com/DISL-Lab/HAMLET.

</details>


### [115] [ArgCMV: An Argument Summarization Benchmark for the LLM-era](https://arxiv.org/abs/2508.19580)
*Omkar Gurjar,Agam Goyal,Eshwar Chandrasekharan*

Main category: cs.CL

TL;DR: 本篇论文提出了一种新的论点关键点提取数据集ArgCMV，它包含来自在线人类辩论的约12K个论点，比现有的ArgKP21数据集更具挑战性，并展示了现有方法在处理更复杂、更真实的对话数据时存在局限性。


<details>
  <summary>Details</summary>
Motivation: 现有关键点提取方法主要在ArgKP21数据集上进行评估，但该数据集未能充分代表真实的人类对话，存在局限性。因此，需要新的、更具代表性的基准数据集来推动该领域的研究。

Method: 使用先进的大型语言模型（LLMs），收集了ArgCMV数据集，其中包含来自3K多个主题的在线人类辩论中的约12K个论点。该数据集比ArgKP21更复杂，具有更长的论点、指代关系、主观话语单元以及更广泛的主题。

Result: 现有方法在ArgCMV数据集上表现不佳，表明它们难以适应更复杂、更真实的在线讨论。通过对现有基线和最新开源模型进行广泛的基准测试，展示了ArgCMV数据集的挑战性。

Conclusion: ArgCMV数据集的引入为长上下文在线讨论的关键点提取提供了新的资源，并为下一代由LLM驱动的摘要研究奠定了基础。

Abstract: Key point extraction is an important task in argument summarization which
involves extracting high-level short summaries from arguments. Existing
approaches for KP extraction have been mostly evaluated on the popular ArgKP21
dataset. In this paper, we highlight some of the major limitations of the
ArgKP21 dataset and demonstrate the need for new benchmarks that are more
representative of actual human conversations. Using SoTA large language models
(LLMs), we curate a new argument key point extraction dataset called ArgCMV
comprising of around 12K arguments from actual online human debates spread
across over 3K topics. Our dataset exhibits higher complexity such as longer,
co-referencing arguments, higher presence of subjective discourse units, and a
larger range of topics over ArgKP21. We show that existing methods do not adapt
well to ArgCMV and provide extensive benchmark results by experimenting with
existing baselines and latest open source models. This work introduces a novel
KP extraction dataset for long-context online discussions, setting the stage
for the next generation of LLM-driven summarization research.

</details>


### [116] [Towards stable AI systems for Evaluating Arabic Pronunciations](https://arxiv.org/abs/2508.19587)
*Hadi Zaatiti,Hatem Hajri,Osama Abdullah,Nader Masmoudi*

Main category: cs.CL

TL;DR: 现代阿拉伯语语音识别（ASR）系统在词和句子级别转录方面表现出色，但在孤立字母分类方面存在挑战。本研究提出了一种包含孤立阿拉伯字母的语料库，并展示了对抗训练可以提高模型的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 孤立字母分类对于语言学习、语音治疗和语音学研究至关重要，但由于缺乏辅音和词汇上下文，且持续时间短，对于现有ASR系统来说是一个挑战，尤其是考虑到阿拉伯语特有的语音。现有的wav2vec 2.0模型在此任务上的准确率仅为35%，需要改进。 

Method: 本研究介绍了一个包含孤立阿拉伯字母的、带音标的语料库。使用wav2vec 2.0模型提取的嵌入训练一个轻量级神经网络，将性能提高到65%。为了提高鲁棒性，采用了对抗训练，将幅度扰动（epsilon=0.05）引入的准确率下降限制在9%，同时保持了干净语音的准确率。

Result: 在包含孤立阿拉伯字母的语料库上，状态最先进的wav2vec 2.0模型准确率仅为35%。通过在wav2vec嵌入上训练轻量级神经网络，准确率提高到65%。然而，添加小的幅度扰动（epsilon=0.05）会将准确率降至32%。通过对抗训练，在保持干净语音准确率的同时，将扰动引入的准确率下降限制在9%。

Conclusion: 对抗训练可以有效地提高孤立阿拉伯字母分类任务的鲁棒性，克服了语音信号中的噪声和扰动问题，同时保持了模型的准确性。研究详细介绍了语料库、训练流程和评估协议，并提供了数据和代码以供复现。未来的工作将把这些方法扩展到更高级别的语音识别框架。

Abstract: Modern Arabic ASR systems such as wav2vec 2.0 excel at word- and
sentence-level transcription, yet struggle to classify isolated letters. In
this study, we show that this phoneme-level task, crucial for language
learning, speech therapy, and phonetic research, is challenging because
isolated letters lack co-articulatory cues, provide no lexical context, and
last only a few hundred milliseconds. Recogniser systems must therefore rely
solely on variable acoustic cues, a difficulty heightened by Arabic's emphatic
(pharyngealized) consonants and other sounds with no close analogues in many
languages. This study introduces a diverse, diacritised corpus of isolated
Arabic letters and demonstrates that state-of-the-art wav2vec 2.0 models
achieve only 35% accuracy on it. Training a lightweight neural network on
wav2vec embeddings raises performance to 65%. However, adding a small amplitude
perturbation (epsilon = 0.05) cuts accuracy to 32%. To restore robustness, we
apply adversarial training, limiting the noisy-speech drop to 9% while
preserving clean-speech accuracy. We detail the corpus, training pipeline, and
evaluation protocol, and release, on demand, data and code for reproducibility.
Finally, we outline future work extending these methods to word- and
sentence-level frameworks, where precise letter pronunciation remains critical.

</details>


### [117] [Understanding and Leveraging the Expert Specialization of Context Faithfulness in Mixture-of-Experts LLMs](https://arxiv.org/abs/2508.19594)
*Jun Bai,Minghao Tong,Yang Liu,Zixia Jia,Zilong Zheng*

Main category: cs.CL

TL;DR: LLMs struggle with context faithfulness. This paper proposes Router Lens to identify context-faithful experts in mixture-of-experts models, finding they amplify attention to relevant context. CEFT, a method fine-tuning these experts, matches or exceeds full fine-tuning efficiency.


<details>
  <summary>Details</summary>
Motivation: To address the issue of large language models (LLMs) struggling to ground their outputs in provided context, leading to irrelevant responses, and to explore the potential of expert specialization in mixture-of-experts (MoE) architectures for improving context faithfulness.

Method: The paper proposes Router Lens to identify context-faithful experts within MoE architectures. It then introduces Context-faithful Expert Fine-Tuning (CEFT), a lightweight optimization approach that selectively fine-tunes these identified experts.

Result: Analysis using Router Lens reveals that context-faithful experts progressively amplify attention to relevant contextual information, enhancing context grounding. Experiments show that CEFT matches or surpasses the performance of full fine-tuning while being significantly more efficient across various benchmarks and models.

Conclusion: CEFT, by selectively fine-tuning context-faithful experts identified through methods like Router Lens, offers an efficient and effective approach to improve LLM context faithfulness, matching or exceeding the performance of full fine-tuning.

Abstract: Context faithfulness is essential for reliable reasoning in context-dependent
scenarios. However, large language models often struggle to ground their
outputs in the provided context, resulting in irrelevant responses. Inspired by
the emergent expert specialization observed in mixture-of-experts
architectures, this work investigates whether certain experts exhibit
specialization in context utilization, offering a potential pathway toward
targeted optimization for improved context faithfulness. To explore this, we
propose Router Lens, a method that accurately identifies context-faithful
experts. Our analysis reveals that these experts progressively amplify
attention to relevant contextual information, thereby enhancing context
grounding. Building on this insight, we introduce Context-faithful Expert
Fine-Tuning (CEFT), a lightweight optimization approach that selectively
fine-tunes context-faithful experts. Experiments across a wide range of
benchmarks and models demonstrate that CEFT matches or surpasses the
performance of full fine-tuning while being significantly more efficient.

</details>


### [118] [LFD: Layer Fused Decoding to Exploit External Knowledge in Retrieval-Augmented Generation](https://arxiv.org/abs/2508.19614)
*Yang Sun,Lixin Zou,Dan Luo,Zhiyong Xie,Long Zhang,Liming Dong,Yunwei Zhao,Xixun Lin,Yanxiong Lu,Chenliang Li*

Main category: cs.CL

TL;DR: 在检索增强生成（RAG）中，向检索到的相关文档注入噪声可以改善LLM对外部知识的利用和生成质量。本文提出了一种称为层融合解码（LFD）的解码策略，通过结合中间层和最终层的表示来充分利用外部事实知识。为确定最佳中间层，提出了一种内部知识得分（IKS）标准。实验证明，LFD能以最小的成本帮助RAG系统更有效地利用检索到的上下文知识。


<details>
  <summary>Details</summary>
Motivation: 为了更好地理解和利用LLM在检索增强生成（RAG）中整合外部知识的能力，以及利用“注入噪声可改善生成质量”这一反直觉的现象，本文旨在对噪声注入进行干预，并明确LLM内部层级的功能划分。

Method: 提出层融合解码（LFD）策略，结合中间层（专注于整合长程外部事实知识）的表示与最终层解码输出来充分利用外部事实知识。通过内部知识得分（IKS）标准来选择最佳中间层，该标准选择具有最低IKS值的中间层。

Result: 实验结果表明，LFD策略在多个基准测试中有效，能够帮助RAG系统以最小的成本更有效地利用检索到的上下文知识。

Conclusion: LLM的层级具有特定的功能划分：浅层关注局部上下文，中间层整合外部事实知识，深层依赖内部知识。LFD策略通过利用中间层的知识，能够提升RAG系统的性能，证实了通过干预噪声注入和利用特定层级信息可以优化LLM的行为。

Abstract: Retrieval-augmented generation (RAG) incorporates external knowledge into
large language models (LLMs), improving their adaptability to downstream tasks
and enabling information updates. Surprisingly, recent empirical evidence
demonstrates that injecting noise into retrieved relevant documents
paradoxically facilitates exploitation of external knowledge and improves
generation quality. Although counterintuitive and challenging to apply in
practice, this phenomenon enables granular control and rigorous analysis of how
LLMs integrate external knowledge. Therefore, in this paper, we intervene on
noise injection and establish a layer-specific functional demarcation within
the LLM: shallow layers specialize in local context modeling, intermediate
layers focus on integrating long-range external factual knowledge, and deeper
layers primarily rely on parametric internal knowledge. Building on this
insight, we propose Layer Fused Decoding (LFD), a simple decoding strategy that
directly combines representations from an intermediate layer with final-layer
decoding outputs to fully exploit the external factual knowledge. To identify
the optimal intermediate layer, we introduce an internal knowledge score (IKS)
criterion that selects the layer with the lowest IKS value in the latter half
of layers. Experimental results across multiple benchmarks demonstrate that LFD
helps RAG systems more effectively surface retrieved context knowledge with
minimal cost.

</details>


### [119] [A Symbolic Adversarial Learning Framework for Evolving Fake News Generation and Detection](https://arxiv.org/abs/2508.19633)
*Chong Tian,Qirong Ho,Xiuying Chen*

Main category: cs.CL

TL;DR: 该论文提出了一种名为SALF的新型框架，使用符号对抗学习来检测和生成复杂的虚假新闻，而不是依赖数值更新。SALF通过生成和检测代理之间的结构化辩论进行对抗训练，并通过操作自然语言表示来模拟反向传播和梯度下降。实验证明SALF能够有效降低最先进的检测性能，并提高检测器的性能。


<details>
  <summary>Details</summary>
Motivation: 随着LLM的快速发展，自动生成复杂虚假新闻的能力日益增强，这增加了虚假新闻的风险。现有的检测方法难以应对这种动态演变的性质。

Method: 提出了一种名为SALF（符号对抗学习框架）的新框架，采用基于代理符号学习优化的对抗训练范式，而不是依赖数值更新。生成代理通过结构化辩论来识别逻辑和事实谬误，检测代理则通过这种对抗交互进行迭代改进。SALF使用代理提示定义可学习的权重，并通过操作自然语言表示来模拟反向传播和梯度下降。

Result: 在两个多语言基准数据集上的实验表明，SALF生成的复杂虚假新闻平均可将中文的检测性能降低高达53.4%，英文降低34.2%。同时，SALF还能改进检测器，将对改进后内容的检测能力提高高达7.7%。

Conclusion: SALF通过其独特的符号对抗学习方法，在应对复杂且动态演变的虚假新闻方面展现了有效性，并为开发更鲁棒、更适应性强的虚假新闻检测系统提供了新的思路。

Abstract: Rapid LLM advancements heighten fake news risks by enabling the automatic
generation of increasingly sophisticated misinformation. Previous detection
methods, including fine-tuned small models or LLM-based detectors, often
struggle with its dynamically evolving nature. In this work, we propose a novel
framework called the Symbolic Adversarial Learning Framework (SALF), which
implements an adversarial training paradigm by an agent symbolic learning
optimization process, rather than relying on numerical updates. SALF introduces
a paradigm where the generation agent crafts deceptive narratives, and the
detection agent uses structured debates to identify logical and factual flaws
for detection, and they iteratively refine themselves through such adversarial
interactions. Unlike traditional neural updates, we represent agents using
agent symbolic learning, where learnable weights are defined by agent prompts,
and simulate back-propagation and gradient descent by operating on natural
language representations of weights, loss, and gradients. Experiments on two
multilingual benchmark datasets demonstrate SALF's effectiveness, showing it
generates sophisticated fake news that degrades state-of-the-art detection
performance by up to 53.4% in Chinese and 34.2% in English on average. SALF
also refines detectors, improving detection of refined content by up to 7.7%.
We hope our work inspires further exploration into more robust, adaptable fake
news detection systems.

</details>


### [120] [Automatic integration of SystemC in the FMI standard for Software-defined Vehicle design](https://arxiv.org/abs/2508.19665)
*Giovanni Pollo,Andrei Mihai Albu,Alessio Burrello,Daniele Jahier Pagliari,Cristian Tesconi,Loris Panaro,Dario Soldi,Fabio Autieri,Sara Vinco*

Main category: cs.CL

TL;DR: SystemC模型通过FMI标准实现自动化封装，以促进汽车行业的协同仿真。


<details>
  <summary>Details</summary>
Motivation: 汽车行业的发展需要强大的协同仿真方法，以便在硬件和软件领域进行早期验证和无缝集成。然而，标准化接口的缺乏和专有仿真平台的普及对协作、可扩展性和知识产权保护构成了重大挑战。

Method: 本文提出了一种利用FMI标准自动封装SystemC模型的方法，将SystemC的建模精度和快速上市时间与FMI的互操作性和封装优势相结合。

Result: 该方法能够安全、可移植地将嵌入式组件集成到协同仿真工作流中，并在实际案例研究中得到验证，证明了其在复杂设计中的有效性。

Conclusion: 所提出的方法有效地解决了现有协同仿真方法中的互操作性和封装性问题，为汽车行业的协同仿真提供了有力的支持。

Abstract: The recent advancements of the automotive sector demand robust co-simulation
methodologies that enable early validation and seamless integration across
hardware and software domains. However, the lack of standardized interfaces and
the dominance of proprietary simulation platforms pose significant challenges
to collaboration, scalability, and IP protection. To address these limitations,
this paper presents an approach for automatically wrapping SystemC models by
using the Functional Mock-up Interface (FMI) standard. This method combines the
modeling accuracy and fast time-to-market of SystemC with the interoperability
and encapsulation benefits of FMI, enabling secure and portable integration of
embedded components into co-simulation workflows. We validate the proposed
methodology on real-world case studies, demonstrating its effectiveness with
complex designs.

</details>


### [121] [Survey of Specialized Large Language Model](https://arxiv.org/abs/2508.19667)
*Chenghan Yang,Ruiyu Zhao,Yang Liu,Ling Jiang*

Main category: cs.CL

TL;DR: 专门的LLM在医疗、金融、法律和技术领域发展迅速，通过领域原生设计、参数效率和多模态能力等技术突破，提高了在专业应用中的表现。


<details>
  <summary>Details</summary>
Motivation: 随着人工智能的发展，通用LLM在专业领域的局限性日益凸显，需要专门的LLM来提升表现。

Method: 系统性地考察了专门LLM在医疗、金融、法律和技术领域的演变，重点关注了领域原生设计、参数效率和多模态能力等技术突破。

Result: 专门的LLM在领域特定基准测试中持续表现出性能提升，并为电子商务领域填补了关键的空白。

Conclusion: 专门的LLM通过技术创新克服了通用LLM的局限性，在专业应用中表现出色，并且对电子商务领域具有重要意义。

Abstract: The rapid evolution of specialized large language models (LLMs) has
transitioned from simple domain adaptation to sophisticated native
architectures, marking a paradigm shift in AI development. This survey
systematically examines this progression across healthcare, finance, legal, and
technical domains. Besides the wide use of specialized LLMs, technical
breakthrough such as the emergence of domain-native designs beyond fine-tuning,
growing emphasis on parameter efficiency through sparse computation and
quantization, increasing integration of multimodal capabilities and so on are
applied to recent LLM agent. Our analysis reveals how these innovations address
fundamental limitations of general-purpose LLMs in professional applications,
with specialized models consistently performance gains on domain-specific
benchmarks. The survey further highlights the implications for E-Commerce field
to fill gaps in the field.

</details>


### [122] [Building Task Bots with Self-learning for Enhanced Adaptability, Extensibility, and Factuality](https://arxiv.org/abs/2508.19689)
*Xiaoying Zhang*

Main category: cs.CL

TL;DR: 本论文研究如何开发能够自主学习和适应不断变化的环境的任务型对话机器人，以应对在对话研究中创建适应性强、可扩展且准确的任务机器人的挑战。


<details>
  <summary>Details</summary>
Motivation: 开发具有最小或零人为干预的适应性强、可扩展且准确的任务机器人是对话研究中的一项重大挑战。

Method: 本论文探讨了创建此类机器人的障碍和潜在解决方案，重点介绍了能够使机器人在不断变化的环境中自主学习和适应的创新技术。

Result: 论文提出了实现机器人自主学习和适应能力的新方法。

Conclusion: 本论文为开发更智能、更自主的对话机器人提供了见解和潜在解决方案。

Abstract: Developing adaptable, extensible, and accurate task bots with minimal or zero
human intervention is a significant challenge in dialog research. This thesis
examines the obstacles and potential solutions for creating such bots, focusing
on innovative techniques that enable bots to learn and adapt autonomously in
constantly changing environments.

</details>


### [123] [Continuously Steering LLMs Sensitivity to Contextual Knowledge with Proxy Models](https://arxiv.org/abs/2508.19720)
*Yilin Wang,Heng Wang,Yuyang Bai,Minnan Luo*

Main category: cs.CL

TL;DR: CSKS框架通过训练两个代理模型来调整LLM对上下文知识的敏感度，实现了对LLM知识来源的连续、精确控制，解决了现有方法的效率和适用性问题。


<details>
  <summary>Details</summary>
Motivation: 现有方法在处理LLM的知识冲突和上下文知识适应方面存在效率低、对黑盒模型不适用或无法持续调整敏感度的问题。为解决这些问题，提出CSKS框架。

Method: CSKS框架通过微调两个小的代理模型（proxy models），利用它们输出分布的差异来调整LLM的输出分布，而无需修改LLM的原始权重。

Result: 实验结果表明，CSKS框架能够对LLM对上下文知识的敏感度进行连续、精确的控制，既可以提高敏感度，也可以降低敏感度，使LLM能够灵活地优先考虑上下文知识或其内部参数知识。

Conclusion: CSKS框架是一种轻量级、可扩展的解决方案，能够有效地使LLM适应新的上下文知识，解决了现有方法的局限性。

Abstract: In Large Language Models (LLMs) generation, there exist knowledge conflicts
and scenarios where parametric knowledge contradicts knowledge provided in the
context. Previous works studied tuning, decoding algorithms, or locating and
editing context-aware neurons to adapt LLMs to be faithful to new contextual
knowledge. However, they are usually inefficient or ineffective for large
models, not workable for black-box models, or unable to continuously adjust
LLMs' sensitivity to the knowledge provided in the context. To mitigate these
problems, we propose CSKS (Continuously Steering Knowledge Sensitivity), a
simple framework that can steer LLMs' sensitivity to contextual knowledge
continuously at a lightweight cost. Specifically, we tune two small LMs (i.e.
proxy models) and use the difference in their output distributions to shift the
original distribution of an LLM without modifying the LLM weights. In the
evaluation process, we not only design synthetic data and fine-grained metrics
to measure models' sensitivity to contextual knowledge but also use a real
conflict dataset to validate CSKS's practical efficacy. Extensive experiments
demonstrate that our framework achieves continuous and precise control over
LLMs' sensitivity to contextual knowledge, enabling both increased sensitivity
and reduced sensitivity, thereby allowing LLMs to prioritize either contextual
or parametric knowledge as needed flexibly. Our data and code are available at
https://github.com/OliveJuiceLin/CSKS.

</details>


### [124] [CAMÕES: A Comprehensive Automatic Speech Recognition Benchmark for European Portuguese](https://arxiv.org/abs/2508.19721)
*Carlos Carvalho,Francisco Teixeira,Catarina Botelho,Anna Pompili,Rubén Solera-Ureña,Sérgio Paulo,Mariana Julião,Thomas Rolland,John Mendonça,Diogo Pereira,Isabel Trancoso,Alberto Abad*

Main category: cs.CL

TL;DR: 现有葡萄牙语语音识别资源主要集中在巴西葡萄牙语，欧洲葡萄牙语（EP）及其他葡萄牙语变体则研究不足。本文提出了CAMÕES框架，包含一个包含46小时EP测试数据的评估基准和一系列先进模型（包括零样本、微调的基金模型和从头训练的E-Branchformer模型），以解决这一问题。EP的微调基金模型和E-Branchformer模型表现相当，均实现了比最强的零样本基金模型高35%以上的词错误率（WER）改进，达到了EP及其他葡萄牙语变体的新state-of-the-art。


<details>
  <summary>Details</summary>
Motivation: 填补欧洲葡萄牙语（EP）及其他葡萄牙语变体在语音识别（ASR）领域研究的空白，解决现有资源主要集中在巴西葡萄牙语的问题。

Method: 提出CAMÕES框架，包含（1）一个全面的评估基准（46小时EP测试数据，涵盖多个领域）；（2）一系列先进模型（评估基金模型的零样本和微调性能，以及从头训练的E-Branchformer模型）。使用425小时EP数据进行微调和训练。

Result: 微调基金模型和E-Branchformer模型在EP上的表现相当，最佳模型的词错误率（WER）相比最强的零样本基金模型有超过35%的相对改进，创下EP及其他葡萄牙语变体的新state-of-the-art。

Conclusion: CAMÕES框架为EP及其他葡萄牙语变体语音识别提供了有效的评估基准和先进模型，显著提升了识别性能，达到了新的state-of-the-art水平。

Abstract: Existing resources for Automatic Speech Recognition in Portuguese are mostly
focused on Brazilian Portuguese, leaving European Portuguese (EP) and other
varieties under-explored. To bridge this gap, we introduce CAM\~OES, the first
open framework for EP and other Portuguese varieties. It consists of (1) a
comprehensive evaluation benchmark, including 46h of EP test data spanning
multiple domains; and (2) a collection of state-of-the-art models. For the
latter, we consider multiple foundation models, evaluating their zero-shot and
fine-tuned performances, as well as E-Branchformer models trained from scratch.
A curated set of 425h of EP was used for both fine-tuning and training. Our
results show comparable performance for EP between fine-tuned foundation models
and the E-Branchformer. Furthermore, the best-performing models achieve
relative improvements above 35% WER, compared to the strongest zero-shot
foundation model, establishing a new state-of-the-art for EP and other
varieties.

</details>


### [125] [NLKI: A lightweight Natural Language Knowledge Integration Framework for Improving Small VLMs in Commonsense VQA Tasks](https://arxiv.org/abs/2508.19724)
*Aritra Dutta,Swapnanil Mukherjee,Deepanway Ghosal,Somak Aditya*

Main category: cs.CL

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Commonsense visual-question answering often hinges on knowledge that is
missing from the image or the question. Small vision-language models (sVLMs)
such as ViLT, VisualBERT and FLAVA therefore lag behind their larger generative
counterparts. To study the effect of careful commonsense knowledge integration
on sVLMs, we present an end-to-end framework (NLKI) that (i) retrieves natural
language facts, (ii) prompts an LLM to craft natural language explanations, and
(iii) feeds both signals to sVLMs respectively across two commonsense VQA
datasets (CRIC, AOKVQA) and a visual-entailment dataset (e-SNLI-VE). Facts
retrieved using a fine-tuned ColBERTv2 and an object information-enriched
prompt yield explanations that largely cut down hallucinations, while lifting
the end-to-end answer accuracy by up to 7% (across 3 datasets), making FLAVA
and other models in NLKI match or exceed medium-sized VLMs such as Qwen-2 VL-2B
and SmolVLM-2.5B. As these benchmarks contain 10-25% label noise, additional
finetuning using noise-robust losses (such as symmetric cross entropy and
generalised cross entropy) adds another 2.5% in CRIC, and 5.5% in AOKVQA. Our
findings expose when LLM-based commonsense knowledge beats retrieval from
commonsense knowledge bases, how noise-aware training stabilises small models
in the context of external knowledge augmentation, and why parameter-efficient
commonsense reasoning is now within reach for 250M models.

</details>


### [126] [Spotlight Attention: Towards Efficient LLM Generation via Non-linear Hashing-based KV Cache Retrieval](https://arxiv.org/abs/2508.19740)
*Wenhao Li,Yuxin Zhang,Gen Luo,Haiyuan Wan,Ziyang Gong,Fei Chao,Rongrong Ji*

Main category: cs.CL

TL;DR: Spotlight Attention通过非线性哈希优化KV缓存，提升LLM推理速度和效率。


<details>
  <summary>Details</summary>
Motivation: 减少LLM的KV缓存开销以加速推理，现有随机线性哈希方法效率低下。

Method: 提出Spotlight Attention，使用非线性哈希函数优化查询和键的嵌入分布，并开发了基于Bradley-Terry排序损失的轻量级训练框架。

Result: Spotlight Attention显著提高了检索精度，并将哈希码长度缩短了至少5倍，在A100 GPU上实现了512K token的哈希检索，时间小于100μs，端到端吞吐量最高提升3倍。

Conclusion: Spotlight Attention通过优化KV缓存，有效提升了LLM的推理效率和速度。

Abstract: Reducing the key-value (KV) cache burden in Large Language Models (LLMs)
significantly accelerates inference. Dynamically selecting critical KV caches
during decoding helps maintain performance. Existing methods use random linear
hashing to identify important tokens, but this approach is inefficient due to
the orthogonal distribution of queries and keys within two narrow cones in
LLMs. We introduce Spotlight Attention, a novel method that employs non-linear
hashing functions to optimize the embedding distribution of queries and keys,
enhancing coding efficiency and robustness. We also developed a lightweight,
stable training framework using a Bradley-Terry ranking-based loss, enabling
optimization of the non-linear hashing module on GPUs with 16GB memory in 8
hours. Experimental results show that Spotlight Attention drastically improves
retrieval precision while shortening the length of the hash code at least
5$\times$ compared to traditional linear hashing. Finally, we exploit the
computational advantages of bitwise operations by implementing specialized CUDA
kernels, achieving hashing retrieval for 512K tokens in under 100$\mu$s on a
single A100 GPU, with end-to-end throughput up to 3$\times$ higher than vanilla
decoding.

</details>


### [127] [Uncovering the Bigger Picture: Comprehensive Event Understanding Via Diverse News Retrieval](https://arxiv.org/abs/2508.19758)
*Yixuan Tang,Yuanyuan Shi,Yiqun Sun,Anthony Kum Hoe Tung*

Main category: cs.CL

TL;DR: NEWSCOPE是一个用于新闻检索的框架，通过在句子层面建模语义变异来增强事件覆盖，从而解决现有系统只关注文本相关性导致结果冗余和观点暴露有限的问题。它使用两阶段方法：首先检索相关内容，然后通过聚类和多样性感知重新排序来展示互补信息。NEWSCOPE在多样性方面优于基线，同时不影响相关性。


<details>
  <summary>Details</summary>
Motivation: 大多数新闻检索系统优先考虑文本相关性，导致结果冗余和观点暴露有限，因此需要一种能够增强事件覆盖和提供多样化视角的新闻检索方法。

Method: NEWSCOPE是一个两阶段框架：第一阶段使用密集检索来检索主题相关内容；第二阶段应用句子级聚类和多样性感知重新排序来展示互补信息。引入了平均成对距离、正聚类覆盖和信息密度比三个可解释的指标来评估检索多样性，并构建了LocalNews和DSGlobal两个段落级基准。

Result: NEWSCOPE在多样性方面持续优于强有力的基线，显著提高了多样性，同时不影响相关性。

Conclusion: NEWSCOPE通过细粒度的、可解释的模型有效地减少了冗余，促进了对事件的全面理解。

Abstract: Access to diverse perspectives is essential for understanding real-world
events, yet most news retrieval systems prioritize textual relevance, leading
to redundant results and limited viewpoint exposure. We propose NEWSCOPE, a
two-stage framework for diverse news retrieval that enhances event coverage by
explicitly modeling semantic variation at the sentence level. The first stage
retrieves topically relevant content using dense retrieval, while the second
stage applies sentence-level clustering and diversity-aware re-ranking to
surface complementary information. To evaluate retrieval diversity, we
introduce three interpretable metrics, namely Average Pairwise Distance,
Positive Cluster Coverage, and Information Density Ratio, and construct two
paragraph-level benchmarks: LocalNews and DSGlobal. Experiments show that
NEWSCOPE consistently outperforms strong baselines, achieving significantly
higher diversity without compromising relevance. Our results demonstrate the
effectiveness of fine-grained, interpretable modeling in mitigating redundancy
and promoting comprehensive event understanding. The data and code are
available at https://github.com/tangyixuan/NEWSCOPE.

</details>


### [128] [Principled Personas: Defining and Measuring the Intended Effects of Persona Prompting on Task Performance](https://arxiv.org/abs/2508.19764)
*Pedro Henrique Luz de Araujo,Paul Röttger,Dirk Hovy,Benjamin Roth*

Main category: cs.CL

TL;DR: Expert persona prompting improves LLM performance but makes models sensitive to irrelevant details and inconsistent in fidelity, requiring careful persona design and evaluation.


<details>
  <summary>Details</summary>
Motivation: Investigate the effectiveness of expert persona prompting for LLM task improvement, focusing on when and why it works.

Method: Analyze literature on persona prompting, distill three desiderata (performance advantage, robustness, fidelity), and evaluate 9 LLMs across 27 tasks based on these criteria. Propose and test mitigation strategies for robustness.

Result: Expert personas generally yield positive or neutral performance changes. Models exhibit high sensitivity to irrelevant persona details (up to 30% performance drop). Higher education, specialization, and domain-relatedness show inconsistent or negligible effects on fidelity and performance. Mitigation strategies only benefit the largest models.

Conclusion: Careful persona design and evaluation schemes are needed to realize the intended benefits of persona prompting while mitigating negative side effects like sensitivity to irrelevant details and inconsistent fidelity.

Abstract: Expert persona prompting -- assigning roles such as expert in math to
language models -- is widely used for task improvement. However, prior work
shows mixed results on its effectiveness, and does not consider when and why
personas should improve performance. We analyze the literature on persona
prompting for task improvement and distill three desiderata: 1) performance
advantage of expert personas, 2) robustness to irrelevant persona attributes,
and 3) fidelity to persona attributes. We then evaluate 9 state-of-the-art LLMs
across 27 tasks with respect to these desiderata. We find that expert personas
usually lead to positive or non-significant performance changes. Surprisingly,
models are highly sensitive to irrelevant persona details, with performance
drops of almost 30 percentage points. In terms of fidelity, we find that while
higher education, specialization, and domain-relatedness can boost performance,
their effects are often inconsistent or negligible across tasks. We propose
mitigation strategies to improve robustness -- but find they only work for the
largest, most capable models. Our findings underscore the need for more careful
persona design and for evaluation schemes that reflect the intended effects of
persona usage.

</details>


### [129] [T2R-bench: A Benchmark for Generating Article-Level Reports from Real World Industrial Tables](https://arxiv.org/abs/2508.19813)
*Jie Zhang,Changzai Pan,Kaiwen Wei,Sishi Xiong,Yu Zhao,Xiangyu Li,Jiaxin Peng,Xiaoyan Gu,Jian Yang,Wenhan Chang,Zhenhe Wu,Jiang Zhong,Shuangyong Song,Yongxiang Li,Xuelong Li*

Main category: cs.CL

TL;DR: LLMs在表格推理方面取得了显著进展，但将表格信息转化为报告在工业应用中仍面临挑战，主要是由于表格的复杂性和多样性，以及现有基准测试的不足。为此，研究者提出了


<details>
  <summary>Details</summary>
Motivation: LLMs在表格推理方面取得了显著进展，但将表格信息转化为报告在工业应用中仍面临挑战，主要是由于表格的复杂性和多样性，以及现有基准测试的不足。

Method: 提出“表格到报告”（table-to-report）任务，并构建了一个名为T2R-bench的双语基准测试集，其中包含457个来自真实工业场景的表格，涵盖19个行业领域和4种表格类型。同时，提出了一套评估标准来衡量报告生成的质量。

Result: 在25种广泛使用的LLMs上的实验表明，即使是像Deepseek-R1这样的最先进模型，在T2R-bench上的整体得分也仅为62.71，表明LLMs在这一任务上仍有提升空间。

Conclusion: 研究提出了“表格到报告”任务和T2R-bench基准测试集，旨在解决LLMs在工业应用中将表格信息转化为报告的挑战。实验结果显示，现有LLMs在这一任务上的表现仍有待提高。

Abstract: Extensive research has been conducted to explore the capabilities of large
language models (LLMs) in table reasoning. However, the essential task of
transforming tables information into reports remains a significant challenge
for industrial applications. This task is plagued by two critical issues: 1)
the complexity and diversity of tables lead to suboptimal reasoning outcomes;
and 2) existing table benchmarks lack the capacity to adequately assess the
practical application of this task. To fill this gap, we propose the
table-to-report task and construct a bilingual benchmark named T2R-bench, where
the key information flow from the tables to the reports for this task. The
benchmark comprises 457 industrial tables, all derived from real-world
scenarios and encompassing 19 industry domains as well as 4 types of industrial
tables. Furthermore, we propose an evaluation criteria to fairly measure the
quality of report generation. The experiments on 25 widely-used LLMs reveal
that even state-of-the-art models like Deepseek-R1 only achieves performance
with 62.71 overall score, indicating that LLMs still have room for improvement
on T2R-bench. Source code and data will be available after acceptance.

</details>


### [130] [Benchmarking Hindi LLMs: A New Suite of Datasets and a Comparative Analysis](https://arxiv.org/abs/2508.19831)
*Anusha Kamath,Kanishk Singla,Rakesh Paul,Raviraj Joshi,Utkarsh Vaidya,Sanjay Singh Chauhan,Niranjan Wartikar*

Main category: cs.CL

TL;DR: 缺乏高质量的印地语指令调优大语言模型（LLM）评估基准，我们创建了一套包含五个印地语LLM评估数据集（IFEval-Hi, MT-Bench-Hi, GSM8K-Hi, ChatRAG-Hi, BFCL-Hi）的新基准。这些基准通过结合从头开始的人工标注和翻译验证过程创建。我们使用这些基准对支持印地语的开源LLM进行了广泛的基准测试，并提供了详细的比较分析。此方法也适用于其他低资源语言的基准开发。


<details>
  <summary>Details</summary>
Motivation: 评估印地语指令调优大语言模型（LLM）具有挑战性，因为缺乏高质量的基准，直接翻译的英文数据集无法捕捉关键的语言和文化差异。

Method: 创建了一套包含五个印地语LLM评估数据集（IFEval-Hi, MT-Bench-Hi, GSM8K-Hi, ChatRAG-Hi, BFCL-Hi），使用了结合从头开始的人工标注和翻译验证过程的方法。

Result: 对支持印地语的开源LLM进行了广泛的基准测试，并提供了详细的比较分析。

Conclusion: 所提出的基准和方法为评估印地语LLM提供了资源，并且可以作为开发其他低资源语言基准的可复制方法。

Abstract: Evaluating instruction-tuned Large Language Models (LLMs) in Hindi is
challenging due to a lack of high-quality benchmarks, as direct translation of
English datasets fails to capture crucial linguistic and cultural nuances. To
address this, we introduce a suite of five Hindi LLM evaluation datasets:
IFEval-Hi, MT-Bench-Hi, GSM8K-Hi, ChatRAG-Hi, and BFCL-Hi. These were created
using a methodology that combines from-scratch human annotation with a
translate-and-verify process. We leverage this suite to conduct an extensive
benchmarking of open-source LLMs supporting Hindi, providing a detailed
comparative analysis of their current capabilities. Our curation process also
serves as a replicable methodology for developing benchmarks in other
low-resource languages.

</details>


### [131] [Scalable and consistent few-shot classification of survey responses using text embeddings](https://arxiv.org/abs/2508.19836)
*Jonas Timmann Mjaaland,Markus Fleten Kreutzer,Halvor Tyseng,Rebeckah K. Fussell,Gina Passante,N. G. Holmes,Anders Malthe-Sørenssen,Tor Ole B. Odden*

Main category: cs.CL

TL;DR: 该研究提出了一种基于文本嵌入的分类框架，用于对开放式调查回复进行定性分析，该框架只需少量示例即可，并能与传统定性工作流程兼容，在人类分析基准测试中表现良好。


<details>
  <summary>Details</summary>
Motivation: 传统定性分析方法耗时且不一致，现有的NLP解决方案（如监督分类器、主题建模和大型语言模型）在定性分析中的应用有限，因为它们需要大量标记数据、破坏了现有的定性工作流程或产生可变的结果。

Method: 提出一种基于文本嵌入的分类框架，该框架只需少量示例即可，并能与标准的定性工作流程良好契合。

Result: 与人类分析相比，该框架在概念物理调查（包含2899个开放式回复）的基准测试中，实现了0.74至0.83的Cohen's Kappa系数。研究还表明，通过微调文本嵌入模型可以提高框架性能，并可用于审计先前分析的数据集。

Conclusion: 基于文本嵌入的编码可以灵活地扩展到数千个回复，而不会牺牲可解释性，从而为大规模演绎定性分析开辟了道路。

Abstract: Qualitative analysis of open-ended survey responses is a commonly-used
research method in the social sciences, but traditional coding approaches are
often time-consuming and prone to inconsistency. Existing solutions from
Natural Language Processing such as supervised classifiers, topic modeling
techniques, and generative large language models have limited applicability in
qualitative analysis, since they demand extensive labeled data, disrupt
established qualitative workflows, and/or yield variable results. In this
paper, we introduce a text embedding-based classification framework that
requires only a handful of examples per category and fits well with standard
qualitative workflows. When benchmarked against human analysis of a conceptual
physics survey consisting of 2899 open-ended responses, our framework achieves
a Cohen's Kappa ranging from 0.74 to 0.83 as compared to expert human coders in
an exhaustive coding scheme. We further show how performance of this framework
improves with fine-tuning of the text embedding model, and how the method can
be used to audit previously-analyzed datasets. These findings demonstrate that
text embedding-assisted coding can flexibly scale to thousands of responses
without sacrificing interpretability, opening avenues for deductive qualitative
analysis at scale.

</details>


### [132] [TokenVerse++: Towards Flexible Multitask Learning with Dynamic Task Activation](https://arxiv.org/abs/2508.19856)
*Shashi Kumar,Srikanth Madikeri,Esaú Villatoro-Tello,Sergio Burdisso,Pradeep Rangappa,Andrés Carofilis,Petr Motlicek,Karthik Pandia,Shankar Venkatesan,Kadri Hacioğlu,Andreas Stolcke*

Main category: cs.CL

TL;DR: TokenVerse++ 允许使用部分标注的数据集进行多任务训练，通过引入可学习向量动态激活任务，在不牺牲 ASR 性能的情况下，实现了与 TokenVerse 相当或更好的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的 TokenVerse 等基于 Token 的多任务框架要求所有训练样本都包含所有任务的标签，这限制了它们利用部分标注数据集和有效扩展的能力。

Method: 提出 TokenVerse++，在 XLSR-Transducer ASR 模型的声学嵌入空间中引入了可学习向量，实现了动态任务激活，从而允许使用仅为部分任务标注的样本进行训练。

Result: 成功地集成了包含部分标注（针对 ASR 和语言识别）的数据集，并提升了整体性能。TokenVerse++ 在多任务上的表现与 TokenVerse 相当或更优，同时保持了 ASR 性能。

Conclusion: TokenVerse++ 是一个更实用的多任务框架，克服了现有方法的局限性，能够更有效地利用部分标注数据，并且在不牺牲 ASR 性能的情况下实现了有竞争力的多任务处理能力。

Abstract: Token-based multitasking frameworks like TokenVerse require all training
utterances to have labels for all tasks, hindering their ability to leverage
partially annotated datasets and scale effectively. We propose TokenVerse++,
which introduces learnable vectors in the acoustic embedding space of the
XLSR-Transducer ASR model for dynamic task activation. This core mechanism
enables training with utterances labeled for only a subset of tasks, a key
advantage over TokenVerse. We demonstrate this by successfully integrating a
dataset with partial labels, specifically for ASR and an additional task,
language identification, improving overall performance. TokenVerse++ achieves
results on par with or exceeding TokenVerse across multiple tasks, establishing
it as a more practical multitask alternative without sacrificing ASR
performance.

</details>


### [133] [Beyond Shallow Heuristics: Leveraging Human Intuition for Curriculum Learning](https://arxiv.org/abs/2508.19873)
*Vanessa Toborek,Sebastian Müller,Tim Selbach,Tamás Horváth,Christian Bauckhage*

Main category: cs.CL

TL;DR: 简单维基百科的标签可用于指导语言模型预训练的课程学习。


<details>
  <summary>Details</summary>
Motivation: 探索使用人类定义的简单语言作为课程学习（CL）的有效信号，以解决语言学难度的定义和衡量问题。

Method: 使用来自简单维基百科的文章级别标签，将基于标签的课程与基于能力的策略进行比较，并使用BERT-tiny模型进行实验。

Result: 将简单数据通过课程（尤其是在最开始引入）进行结构化，可以持续提高困惑度，尤其是在简单语言方面。基于能力的课程与随机排序相比没有带来一致的收益。

Conclusion: 人类对语言难度的直觉可以指导语言模型预训练的课程学习。

Abstract: Curriculum learning (CL) aims to improve training by presenting data from
"easy" to "hard", yet defining and measuring linguistic difficulty remains an
open challenge. We investigate whether human-curated simple language can serve
as an effective signal for CL. Using the article-level labels from the Simple
Wikipedia corpus, we compare label-based curricula to competence-based
strategies relying on shallow heuristics. Our experiments with a BERT-tiny
model show that adding simple data alone yields no clear benefit. However,
structuring it via a curriculum -- especially when introduced first --
consistently improves perplexity, particularly on simple language. In contrast,
competence-based curricula lead to no consistent gains over random ordering,
probably because they fail to effectively separate the two classes. Our results
suggest that human intuition about linguistic difficulty can guide CL for
language model pre-training.

</details>


### [134] [AI-Powered Detection of Inappropriate Language in Medical School Curricula](https://arxiv.org/abs/2508.19883)
*Chiman Salavati,Shannon Song,Scott A. Hale,Roberto E. Montenegro,Shiri Dori-Hacohen,Fabricio Murai*

Main category: cs.CL

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: The use of inappropriate language -- such as outdated, exclusionary, or
non-patient-centered terms -- medical instructional materials can significantly
influence clinical training, patient interactions, and health outcomes. Despite
their reputability, many materials developed over past decades contain examples
now considered inappropriate by current medical standards. Given the volume of
curricular content, manually identifying instances of inappropriate use of
language (IUL) and its subcategories for systematic review is prohibitively
costly and impractical. To address this challenge, we conduct a first-in-class
evaluation of small language models (SLMs) fine-tuned on labeled data and
pre-trained LLMs with in-context learning on a dataset containing approximately
500 documents and over 12,000 pages. For SLMs, we consider: (1) a general IUL
classifier, (2) subcategory-specific binary classifiers, (3) a multilabel
classifier, and (4) a two-stage hierarchical pipeline for general IUL detection
followed by multilabel classification. For LLMs, we consider variations of
prompts that include subcategory definitions and/or shots. We found that both
LLama-3 8B and 70B, even with carefully curated shots, are largely outperformed
by SLMs. While the multilabel classifier performs best on annotated data,
supplementing training with unflagged excerpts as negative examples boosts the
specific classifiers' AUC by up to 25%, making them most effective models for
mitigating harmful language in medical curricula.

</details>


### [135] [Bangla-Bayanno: A 52K-Pair Bengali Visual Question Answering Dataset with LLM-Assisted Translation Refinement](https://arxiv.org/abs/2508.19887)
*Mohammed Rakibul Hasan,Rafi Majid,Ahanaf Tahmid*

Main category: cs.CL

TL;DR: 本文介绍了一个名为Bangla-Bayanno的孟加拉语视觉问答（VQA）数据集，该数据集是开放式的，包含52,650个问答对，涵盖4750多张图片。该数据集旨在解决低资源语言在多模态AI研究中的不足，并采用多语言大语言模型辅助翻译优化流程来确保翻译质量，克服了现有数据集在翻译质量和答案格式上的局限性。问题分为名词性、量化性和极性三种回答类型，旨在为孟加拉语低资源多模态学习提供一个高质量的开源基准。


<details>
  <summary>Details</summary>
Motivation: 现有VQA数据集在低资源语言方面存在不足，且多为人工标注，存在特定领域、查询类型或答案格式的偏见，或者答案格式受限于特定领域。为解决低资源语言（如孟加拉语）在多模态AI研究中的问题，并克服现有数据集的局限性，需要一个高质量、开放的孟加拉语VQA数据集。

Method: 使用多语言大语言模型（LLM）辅助翻译优化流程，以解决低质量翻译问题，保证清晰度，并减少人为错误。将问题分为三种回答类型：名词性（简短描述）、量化性（数字）和极性（是/否）。

Result: 创建了一个包含52,650个问答对和4750多张图片的孟加拉语开放式VQA数据集（Bangla-Bayanno）。该数据集质量高，克服了现有低资源语言VQA数据集的翻译质量和答案格式限制。

Conclusion: Bangla-Bayanno数据集是孟加拉语中最全面的开源高质量VQA基准，旨在促进低资源多模态学习的研究，并推动更具包容性的AI系统的发展。

Abstract: In this paper, we introduce Bangla-Bayanno, an open-ended Visual Question
Answering (VQA) Dataset in Bangla, a widely used, low-resource language in
multimodal AI research. The majority of existing datasets are either manually
annotated with an emphasis on a specific domain, query type, or answer type or
are constrained by niche answer formats. In order to mitigate human-induced
errors and guarantee lucidity, we implemented a multilingual LLM-assisted
translation refinement pipeline. This dataset overcomes the issues of
low-quality translations from multilingual sources. The dataset comprises
52,650 question-answer pairs across 4750+ images. Questions are classified into
three distinct answer types: nominal (short descriptive), quantitative
(numeric), and polar (yes/no). Bangla-Bayanno provides the most comprehensive
open-source, high-quality VQA benchmark in Bangla, aiming to advance research
in low-resource multimodal learning and facilitate the development of more
inclusive AI systems.

</details>


### [136] [Logical Reasoning with Outcome Reward Models for Test-Time Scaling](https://arxiv.org/abs/2508.19903)
*Ramya Keerthy Thatikonda,Wray Buntine,Ehsan Shareghi*

Main category: cs.CL

TL;DR: 使用基于链式思考（CoT）和回声生成技术训练的成果奖励模型（ORMs）提高了LLM在演绎逻辑推理任务上的表现。


<details>
  <summary>Details</summary>
Motivation: 评估LLMs在演绎逻辑推理能力方面的潜力，并探索使用测试时缩放和奖励模型来增强LLM性能的方法。

Method: 提出了一套用于演绎推理的成果奖励模型（ORMs），并采用链式思考（CoT）和回声生成技术来扩充训练数据集，以覆盖更多类型的错误。

Result: 在FOLIO、JustLogic和ProverQA数据集上，使用CoT和回声增强数据训练的ORMs在四种不同的LLMs上均表现出性能提升。

Conclusion: 基于ORMs和回声生成技术的结合，为提升LLM在复杂逻辑推理任务中的表现提供了一种有效的方法。

Abstract: Logical reasoning is a critical benchmark for evaluating the capabilities of
large language models (LLMs), as it reflects their ability to derive valid
conclusions from given premises. While the combination of test-time scaling
with dedicated outcome or process reward models has opened up new avenues to
enhance LLMs performance in complex reasoning tasks, this space is
under-explored in deductive logical reasoning. We present a set of Outcome
Reward Models (ORMs) for deductive reasoning. To train the ORMs we mainly
generate data using Chain-of-Thought (CoT) with single and multiple samples.
Additionally, we propose a novel tactic to further expand the type of errors
covered in the training dataset of the ORM. In particular, we propose an echo
generation technique that leverages LLMs' tendency to reflect incorrect
assumptions made in prompts to extract additional training data, covering
previously unexplored error types. While a standard CoT chain may contain
errors likely to be made by the reasoner, the echo strategy deliberately steers
the model toward incorrect reasoning. We show that ORMs trained on CoT and
echo-augmented data demonstrate improved performance on the FOLIO, JustLogic,
and ProverQA datasets across four different LLMs.

</details>


### [137] [Your AI Bosses Are Still Prejudiced: The Emergence of Stereotypes in LLM-Based Multi-Agent Systems](https://arxiv.org/abs/2508.19919)
*Jingyu Guo,Yingying Xu*

Main category: cs.CL

TL;DR: AI代理在互动中会产生刻板印象，即使在没有预设偏见的情况下也是如此。


<details>
  <summary>Details</summary>
Motivation: 探索AI系统在多代理互动中是否会自发产生刻板印象，而不仅仅是从训练数据中继承偏见。

Method: 通过模拟工作场所互动的新实验框架，研究基于LLM的多代理系统中刻板印象的出现和演变。

Result: （1）基于LLM的AI代理在互动中会产生刻板印象驱动的偏见；（2）随着互动轮次和决策权增加，以及引入层级结构后，刻板印象效应会加剧；（3）这些系统会表现出类似人类社会行为的群体效应；（4）不同LLM架构的刻板印象模式保持一致。

Conclusion: AI系统中的刻板印象形成可能是多代理互动的一种涌现属性，而不仅仅是训练数据偏见的结果。需要进一步研究其潜在机制并开发缓解策略。

Abstract: While stereotypes are well-documented in human social interactions, AI
systems are often presumed to be less susceptible to such biases. Previous
studies have focused on biases inherited from training data, but whether
stereotypes can emerge spontaneously in AI agent interactions merits further
exploration. Through a novel experimental framework simulating workplace
interactions with neutral initial conditions, we investigate the emergence and
evolution of stereotypes in LLM-based multi-agent systems. Our findings reveal
that (1) LLM-Based AI agents develop stereotype-driven biases in their
interactions despite beginning without predefined biases; (2) stereotype
effects intensify with increased interaction rounds and decision-making power,
particularly after introducing hierarchical structures; (3) these systems
exhibit group effects analogous to human social behavior, including halo
effects, confirmation bias, and role congruity; and (4) these stereotype
patterns manifest consistently across different LLM architectures. Through
comprehensive quantitative analysis, these findings suggest that stereotype
formation in AI systems may arise as an emergent property of multi-agent
interactions, rather than merely from training data biases. Our work
underscores the need for future research to explore the underlying mechanisms
of this phenomenon and develop strategies to mitigate its ethical impacts.

</details>


### [138] [HEAL: A Hypothesis-Based Preference-Aware Analysis Framework](https://arxiv.org/abs/2508.19922)
*Yifu Huo,Chenglong Wang,Qiren Zhu,Shunjie Xing,Tong Xiao,Chunliang Zhang,Tongran Liu,Jinbo Zhu*

Main category: cs.CL

TL;DR: 评估LLM对齐的方法需要考虑所有潜在输出，而不仅仅是单个响应。HEAL框架将偏好对齐制定为假设空间内的重新排序过程，包含排名准确性和偏好强度相关性两个指标。UniHypoBench是一个统一的假设基准。实验表明，现有偏好学习方法能有效捕捉代理模型的偏好并抑制负样本。本研究通过假设空间分析为偏好对齐理解提供了新范式，并为优化对齐算法提供了工具和方向。


<details>
  <summary>Details</summary>
Motivation: 现有的LLM对齐评估方法（如DPO）主要关注单个响应，忽略了实际应用中可能出现的其他潜在输出，因此需要一个更全面的评估范式。

Method: 提出了一种名为HEAL（Hypothesis-based Preference-aware Analysis Framework）的新型评估框架，将偏好对齐视为假设空间内的重新排序过程，并引入排名准确性和偏好强度相关性两个指标。同时，开发了一个名为UniHypoBench的统一假设基准。

Result: 通过HEAL框架进行的实验表明，当前的偏好学习方法能够有效地捕捉代理模型提供的偏好，同时抑制负样本。

Conclusion: HEAL框架为理解和优化LLM的偏好对齐提供了新的理论视角和实用的诊断工具，并指出了开发更全面偏好捕捉算法的未来方向。

Abstract: Preference optimization methods like DPO have achieved remarkable performance
in LLM alignment. However, the evaluation for these methods relies on a single
response and overlooks other potential outputs, which could also be generated
in real-world applications within this hypothetical space. To address this
issue, this paper presents a \textbf{H}ypothesis-based
Pr\textbf{E}ference-aware \textbf{A}na\textbf{L}ysis Framework (HEAL), a novel
evaluation paradigm that formulates preference alignment as a re-ranking
process within hypothesis spaces. The framework incorporates two complementary
metrics: ranking accuracy for evaluating ordinal consistency and preference
strength correlation for assessing continuous alignment. To facilitate this
framework, we develop UniHypoBench, a unified hypothesis benchmark constructed
from diverse instruction-response pairs. Through extensive experiments based on
HEAL, with a particular focus on the intrinsic mechanisms of preference
learning, we demonstrate that current preference learning methods can
effectively capture preferences provided by proxy models while simultaneously
suppressing negative samples. These findings contribute to preference learning
research through two significant avenues. Theoretically, we introduce
hypothesis space analysis as an innovative paradigm for understanding
preference alignment. Practically, HEAL offers researchers robust diagnostic
tools for refining preference optimization methods, while our empirical results
identify promising directions for developing more advanced alignment algorithms
capable of comprehensive preference capture.

</details>


### [139] [Dhati+: Fine-tuned Large Language Models for Arabic Subjectivity Evaluation](https://arxiv.org/abs/2508.19966)
*Slimane Bellaouar,Attia Nehar,Soumia Souffi,Mounia Bouameur*

Main category: cs.CL

TL;DR: 该论文提出了一种针对阿拉伯语的新的主观性评估方法，通过构建AraDhati+数据集并微调XLM-RoBERTa、AraBERT和ArabianGPT等先进的阿拉伯语语言模型，并结合集成决策方法，在阿拉伯语主观性分类任务上取得了97.79%的准确率，有效解决了阿拉伯语处理资源有限的挑战。


<details>
  <summary>Details</summary>
Motivation: 阿拉伯语作为一种语言丰富但形态复杂的语言，面临着资源匮乏的挑战，特别是用于主观性分析的大型标注数据集的稀缺，阻碍了准确工具的开发。

Method: 通过整合现有阿拉伯语数据集（ASTD、LABR、HARD和SANAD）创建了AraDhati+数据集，并在该数据集上微调了XLM-RoBERTa、AraBERT和ArabianGPT等先进的阿拉伯语语言模型，并采用了集成决策方法。

Result: 该方法在阿拉伯语主观性分类任务上达到了97.79%的准确率。

Conclusion: 所提出的方法在应对阿拉伯语处理中资源有限的挑战方面是有效的，并且在阿拉伯语主观性分类任务上取得了显著的成果。

Abstract: Despite its significance, Arabic, a linguistically rich and morphologically
complex language, faces the challenge of being under-resourced. The scarcity of
large annotated datasets hampers the development of accurate tools for
subjectivity analysis in Arabic. Recent advances in deep learning and
Transformers have proven highly effective for text classification in English
and French. This paper proposes a new approach for subjectivity assessment in
Arabic textual data. To address the dearth of specialized annotated datasets,
we developed a comprehensive dataset, AraDhati+, by leveraging existing Arabic
datasets and collections (ASTD, LABR, HARD, and SANAD). Subsequently, we
fine-tuned state-of-the-art Arabic language models (XLM-RoBERTa, AraBERT, and
ArabianGPT) on AraDhati+ for effective subjectivity classification.
Furthermore, we experimented with an ensemble decision approach to harness the
strengths of individual models. Our approach achieves a remarkable accuracy of
97.79\,\% for Arabic subjectivity classification. Results demonstrate the
effectiveness of the proposed approach in addressing the challenges posed by
limited resources in Arabic language processing.

</details>


### [140] [Diffusion Language Models Know the Answer Before Decoding](https://arxiv.org/abs/2508.19982)
*Pengxiang Li,Yefan Zhou,Dilxat Muhtar,Lu Yin,Shilin Yan,Li Shen,Yi Liang,Soroush Vosoughi,Shiwei Liu*

Main category: cs.CL

TL;DR: Prophet是一种用于加速扩散语言模型（DLM）推理的训练无关的快速解码范例，通过利用DLM早期答案收敛的特性，利用预测候选者之间的置信度间隙来动态决定何时提前提交解码，从而在保持高质量生成的同时，将解码步数最多减少3.4倍。


<details>
  <summary>Details</summary>
Motivation: DLM推理比自回归模型慢，主要是由于双向注意力和所需的大量细化步骤。本研究旨在解决DLM推理速度慢的问题。

Method: Prophet利用DLM早期答案收敛的特性，即在许多情况下，正确的答案可以在接近最终解码步骤时被识别出来。它通过在早期阶段动态决定是继续细化还是“全力以赴”（即一步解码所有剩余令牌）来工作。这一决策基于模型预测的“置信度间隙”，即最高两个预测候选者之间的概率差距。Prophet无需额外训练，并且可以无缝集成到现有的DLM实现中，开销可忽略不计。

Result: 在GSM8K和MMLU数据集上，分别有高达97%和99%的实例可以在仅使用一半的细化步骤的情况下正确解码。Prophet将LLaDA-8B和Dream-7B在多个任务上的解码步数最多减少了3.4倍，同时保持了高质量的生成。

Conclusion: 早期解码收敛为加速DLM推理提供了一种简单而强大的机制，可以作为现有加速技术（如半自回归和随机重遮蔽计划）的补充。Prophet通过利用预测置信度间隙来动态决定何时停止采样，从而实现了这一点。

Abstract: Diffusion language models (DLMs) have recently emerged as an alternative to
autoregressive approaches, offering parallel sequence generation and flexible
token orders. However, their inference remains slower than that of
autoregressive models, primarily due to the cost of bidirectional attention and
the large number of refinement steps required for high quality outputs. In this
work, we highlight and leverage an overlooked property of DLMs early answer
convergence: in many cases, the correct answer can be internally identified by
half steps before the final decoding step, both under semi-autoregressive and
random remasking schedules. For example, on GSM8K and MMLU, up to 97% and 99%
of instances, respectively, can be decoded correctly using only half of the
refinement steps. Building on this observation, we introduce Prophet, a
training-free fast decoding paradigm that enables early commit decoding.
Specifically, Prophet dynamically decides whether to continue refinement or to
go "all-in" (i.e., decode all remaining tokens in one step), using the
confidence gap between the top-2 prediction candidates as the criterion. It
integrates seamlessly into existing DLM implementations, incurs negligible
overhead, and requires no additional training. Empirical evaluations of
LLaDA-8B and Dream-7B across multiple tasks show that Prophet reduces the
number of decoding steps by up to 3.4x while preserving high generation
quality. These results recast DLM decoding as a problem of when to stop
sampling, and demonstrate that early decode convergence provides a simple yet
powerful mechanism for accelerating DLM inference, complementary to existing
speedup techniques. Our code is publicly available at
https://github.com/pixeli99/Prophet.

</details>


### [141] [AgentCoMa: A Compositional Benchmark Mixing Commonsense and Mathematical Reasoning in Real-World Scenarios](https://arxiv.org/abs/2508.19988)
*Lisa Alazraki,Lihu Chen,Ana Brassard,Joe Stacey,Hossein A. Rahmani,Marek Rei*

Main category: cs.CL

TL;DR: LLMs在结合常识和数学推理方面表现不佳，准确率下降约30%，而人类表现良好。引入AgentCoMa基准测试此能力，并进行可解释性研究以了解性能差距。


<details>
  <summary>Details</summary>
Motivation: 当前的推理基准测试侧重于常识或数学推理，但现实世界的任务需要两者的结合。LLMs在组合推理方面存在模型脆弱性。

Method: 引入AgentCoMa基准测试，包含常识和数学推理步骤。在61个不同LLM上进行测试，并进行可解释性研究（神经元模式、注意力图、成员推理）。

Result: LLMs单独解决常识和数学推理步骤的能力尚可，但结合两者时准确率平均下降约30%。此性能差距大于仅包含单一类型推理步骤的组合基准测试。人类注释者在AgentCoMa上的表现与LLMs相当。

Conclusion: LLMs在混合类型组合推理方面存在显著的模型脆弱性。AgentCoMa为未来改进提供了测试平台。

Abstract: Large Language Models (LLMs) have achieved high accuracy on complex
commonsense and mathematical problems that involve the composition of multiple
reasoning steps. However, current compositional benchmarks testing these skills
tend to focus on either commonsense or math reasoning, whereas LLM agents
solving real-world tasks would require a combination of both. In this work, we
introduce an Agentic Commonsense and Math benchmark (AgentCoMa), where each
compositional task requires a commonsense reasoning step and a math reasoning
step. We test it on 61 LLMs of different sizes, model families, and training
strategies. We find that LLMs can usually solve both steps in isolation, yet
their accuracy drops by ~30% on average when the two are combined. This is a
substantially greater performance gap than the one we observe in prior
compositional benchmarks that combine multiple steps of the same reasoning
type. In contrast, non-expert human annotators can solve the compositional
questions and the individual steps in AgentCoMa with similarly high accuracy.
Furthermore, we conduct a series of interpretability studies to better
understand the performance gap, examining neuron patterns, attention maps and
membership inference. Our work underscores a substantial degree of model
brittleness in the context of mixed-type compositional reasoning and offers a
test bed for future improvement.

</details>


### [142] [MathBuddy: A Multimodal System for Affective Math Tutoring](https://arxiv.org/abs/2508.19993)
*Debanjana Kar,Leopold Böss,Dacia Braca,Sebastian Maximilian Dennerlein,Nina Christine Hubig,Philipp Wintersberger,Yufang Hou*

Main category: cs.CL

TL;DR: MathBuddy是一个能够感知学生情绪的LLM数学导师，通过结合对话文本和面部表情来建模学生情绪，并采用相应的教学策略，从而提升教学效果。


<details>
  <summary>Details</summary>
Motivation: 当前教育技术中的大型语言模型（LLM）会话系统未能考虑学生的情绪状态，而情绪状态会影响学习能力。需要一个能够感知学生情绪并做出相应教学调整的教育工具。

Method: MathBuddy通过分析学生的对话文本和面部表情来捕捉和整合情绪信息，然后利用这些情绪信息提示LLM生成具有情感意识的回复，并根据学生情绪采用不同的教学策略。

Result: 在自动评估指标和用户研究中，MathBuddy在八个教学维度上表现出色，使用获胜率指标带来了23个百分点的性能提升，在使用DAMR分数评估的整体水平上带来了3个百分点的提升，证明了通过对学生情绪建模可以提高LLM导师的教学能力。

Conclusion: 通过对学生情绪进行建模，可以显著提高基于LLM的导师的教学能力，使对话更具同理心，并带来更好的学习成果。

Abstract: The rapid adoption of LLM-based conversational systems is already
transforming the landscape of educational technology. However, the current
state-of-the-art learning models do not take into account the student's
affective states. Multiple studies in educational psychology support the claim
that positive or negative emotional states can impact a student's learning
capabilities. To bridge this gap, we present MathBuddy, an emotionally aware
LLM-powered Math Tutor, which dynamically models the student's emotions and
maps them to relevant pedagogical strategies, making the tutor-student
conversation a more empathetic one. The student's emotions are captured from
the conversational text as well as from their facial expressions. The student's
emotions are aggregated from both modalities to confidently prompt our LLM
Tutor for an emotionally-aware response. We have effectively evaluated our
model using automatic evaluation metrics across eight pedagogical dimensions
and user studies. We report a massive 23 point performance gain using the win
rate and a 3 point gain at an overall level using DAMR scores which strongly
supports our hypothesis of improving LLM-based tutor's pedagogical abilities by
modeling students' emotions.

</details>


### [143] [ReSURE: Regularizing Supervision Unreliability for Multi-turn Dialogue Fine-tuning](https://arxiv.org/abs/2508.19996)
*Yiming Du,Yifan Xiang,Bin Liang,Dahua Lin,Kam-Fai Wong,Fei Tan*

Main category: cs.CL

TL;DR: ReSURE是一种自适应学习方法，通过动态降低不可靠监督的权重来提高多轮对话系统的性能，即使在低质量数据下也能有效防止错误传播。


<details>
  <summary>Details</summary>
Motivation: 监督错误会影响多轮对话系统的性能，尤其是在低质量数据下。现有方法无法解决轮次级错误传播问题。

Method: ReSURE通过Welford在线统计估计每轮损失分布，并动态调整样本损失的权重，无需显式过滤。

Result: 实验表明，ReSURE在稳定性和响应质量方面有所提高，并且在不同数据质量下，响应分数与样本数量之间存在正相关性。

Conclusion: ReSURE是一种有效的方法，可以提高多轮对话系统的性能，并有望有效利用大规模数据。

Abstract: Fine-tuning multi-turn dialogue systems requires high-quality supervision but
often suffers from degraded performance when exposed to low-quality data.
Supervision errors in early turns can propagate across subsequent turns,
undermining coherence and response quality. Existing methods typically address
data quality via static prefiltering, which decouples quality control from
training and fails to mitigate turn-level error propagation. In this context,
we propose ReSURE (Regularizing Supervision UnREliability), an adaptive
learning method that dynamically down-weights unreliable supervision without
explicit filtering. ReSURE estimates per-turn loss distributions using
Welford's online statistics and reweights sample losses on the fly accordingly.
Experiments on both single-source and mixed-quality datasets show improved
stability and response quality. Notably, ReSURE enjoys positive Spearman
correlations (0.21 ~ 1.0 across multiple benchmarks) between response scores
and number of samples regardless of data quality, which potentially paves the
way for utilizing large-scale data effectively. Code is publicly available at
https://github.com/Elvin-Yiming-Du/ReSURE_Multi_Turn_Training.

</details>


### [144] [Selective Retrieval-Augmentation for Long-Tail Legal Text Classification](https://arxiv.org/abs/2508.19997)
*Boheng Mao*

Main category: cs.CL

TL;DR: SRA通过仅从训练数据中检索和增强低频标签样本来改进长尾法律文本分类，无需更改模型架构，并在LEDGAR和UNFAIR-ToS数据集上超越了现有基线。


<details>
  <summary>Details</summary>
Motivation: 法律文本分类基准数据集通常存在标签长尾分布问题，导致模型在罕见类别上的性能不佳。

Method: 提出选择性检索增强（SRA）方法，该方法专注于增强训练集中低频标签的样本，防止对表示良好的类别引入噪声，并且不需要更改模型架构。检索仅从训练数据中进行，以确保没有潜在的信息泄露，同时无需外部语料库。

Result: 在具有长尾分布的法律文本分类基准数据集LEDGAR（单标签）和UNFAIR-ToS（多标签）上进行了测试，SRA在两个数据集上均优于所有现有的LexGLUE基线，在微F1和宏F1得分上均有所提高。

Conclusion: SRA在长尾法律文本分类方面取得了持续改进。

Abstract: Legal text classification is a fundamental NLP task in the legal domain.
Benchmark datasets in this area often exhibit a long-tail label distribution,
where many labels are underrepresented, leading to poor model performance on
rare classes. This paper proposes Selective Retrieval-Augmentation (SRA) as a
solution to this problem. SRA focuses on augmenting samples belonging to
low-frequency labels in the training set, preventing the introduction of noise
for well-represented classes, and requires no changes to the model
architecture. Retrieval is performed only from the training data to ensure
there is no potential information leakage, removing the need for external
corpora simultaneously. The proposed SRA method is tested on two legal text
classification benchmark datasets with long-tail distributions: LEDGAR
(single-label) and UNFAIR-ToS (multi-label). The results indicate that SRA
attains higher micro-F1 and macro-F1 scores compared to all current LexGLUE
baselines across both datasets, illustrating consistent improvements in
long-tail legal text classification. The code repository is available at:
https://github.com/Boheng-Mao/sra-legal

</details>


### [145] [DeepScholar-Bench: A Live Benchmark and Automated Evaluation for Generative Research Synthesis](https://arxiv.org/abs/2508.20033)
*Liana Patel,Negar Arabzadeh,Harshit Gupta,Ankita Sundar,Ion Stoica,Matei Zaharia,Carlos Guestrin*

Main category: cs.CL

TL;DR: 该论文提出了DeepScholar-bench，一个用于评估生成式研究合成系统的实时基准和自动化评估框架。该框架通过考察知识综合、检索质量和可验证性三个维度来评估系统。研究人员还开发了一个名为DeepScholar-base的参考管道，并使用DeepScholar-bench对现有系统进行了评估，发现DeepScholar-base表现具有竞争力，且现有系统在该基准上面临巨大挑战。


<details>
  <summary>Details</summary>
Motivation: 现有的评估基准无法捕捉真实研究合成任务的复杂性和动态性，因此需要一个新的、实时的基准和评估框架来评估生成式研究合成系统。

Method: 提出DeepScholar-bench，一个包含来自近期高质量ArXiv论文的查询的实时基准，专注于生成论文的“相关工作”部分。开发了一个包含知识综合、检索质量和可验证性三个维度的全方位自动化评估框架。实现了一个名为DeepScholar-base的参考管道。

Result: DeepScholar-base建立了强大的基准，在性能上与现有方法相比具有竞争力或更优。在DeepScholar-bench上，没有系统在所有指标上的得分超过19%，表明该基准的挑战性很高，并且还有很大的提升空间。

Conclusion: DeepScholar-bench是一个重要的评估工具，可以推动能够进行生成式研究合成的AI系统的发展。现有系统在该基准上面临巨大挑战，表明该领域仍有待改进。

Abstract: The ability to research and synthesize knowledge is central to human
expertise and progress. An emerging class of systems promises these exciting
capabilities through generative research synthesis, performing retrieval over
the live web and synthesizing discovered sources into long-form, cited
summaries. However, evaluating such systems remains an open challenge: existing
question-answering benchmarks focus on short-form factual responses, while
expert-curated datasets risk staleness and data contamination. Both fail to
capture the complexity and evolving nature of real research synthesis tasks. In
this work, we introduce DeepScholar-bench, a live benchmark and holistic,
automated evaluation framework designed to evaluate generative research
synthesis. DeepScholar-bench draws queries from recent, high-quality ArXiv
papers and focuses on a real research synthesis task: generating the related
work sections of a paper by retrieving, synthesizing, and citing prior
research. Our evaluation framework holistically assesses performance across
three key dimensions, knowledge synthesis, retrieval quality, and
verifiability. We also develop DeepScholar-base, a reference pipeline
implemented efficiently using the LOTUS API. Using the DeepScholar-bench
framework, we perform a systematic evaluation of prior open-source systems,
search AI's, OpenAI's DeepResearch, and DeepScholar-base. We find that
DeepScholar-base establishes a strong baseline, attaining competitive or higher
performance than each other method. We also find that DeepScholar-bench remains
far from saturated, with no system exceeding a score of $19\%$ across all
metrics. These results underscore the difficulty of DeepScholar-bench, as well
as its importance for progress towards AI systems capable of generative
research synthesis. We make our code available at
https://github.com/guestrin-lab/deepscholar-bench.

</details>


### [146] [Forewarned is Forearmed: Pre-Synthesizing Jailbreak-like Instructions to Enhance LLM Safety Guardrail to Potential Attacks](https://arxiv.org/abs/2508.20038)
*Sheng Liu,Qiang Sheng,Danding Wang,Yang Li,Guang Yang,Juan Cao*

Main category: cs.CL

TL;DR: LLM 容易受到越狱攻击，因为攻击指令的分布与安全对齐语料库不同。IMAGINE 框架通过分析嵌入空间分布来生成类似越狱的指令，以弥合这种分布差距，从而提高 LLM 的安全性。


<details>
  <summary>Details</summary>
Motivation: 目前的 LLM 容易受到越狱攻击，因为攻击指令的分布与安全对齐语料库存在差异。这导致开发者需要不断进行被动修复。

Method: 提出 IMAGINE 框架，利用嵌入空间分布分析来生成类似越狱的指令，以弥合训练数据和真实攻击之间的分布差距。该框架通过迭代优化过程动态演变文本生成分布，并利用合成数据增强安全对齐语料库。

Result: 基于 IMAGINE 增强的安全对齐语料库，在 Qwen2.5、Llama3.1 和 Llama3.2 模型上，攻击成功率显著降低，同时没有损害模型的效用。

Conclusion: IMAGINE 框架通过生成分布上匹配的合成数据，有效解决了 LLM 面临的安全对齐挑战，提高了模型的鲁棒性。

Abstract: Despite advances in improving large language model(LLM) to refuse to answer
malicious instructions, widely used LLMs remain vulnerable to jailbreak attacks
where attackers generate instructions with distributions differing from safety
alignment corpora. New attacks expose LLMs' inability to recognize unseen
malicious instructions, highlighting a critical distributional mismatch between
training data and real-world attacks that forces developers into reactive
patching cycles. To tackle this challenge, we propose IMAGINE, a synthesis
framework that leverages embedding space distribution analysis to generate
jailbreak-like instructions. This approach effectively fills the distributional
gap between authentic jailbreak patterns and safety alignment corpora. IMAGINE
follows an iterative optimization process that dynamically evolves text
generation distributions across iterations, thereby augmenting the coverage of
safety alignment data distributions through synthesized data examples. Based on
the safety-aligned corpus enhanced through IMAGINE, our framework demonstrates
significant decreases in attack success rate on Qwen2.5, Llama3.1, and Llama3.2
without compromising their utility.

</details>


### [147] [AraHealthQA 2025 Shared Task Description Paper](https://arxiv.org/abs/2508.20047)
*Hassan Alhuzali,Farah Shamout,Muhammad Abdul-Mageed,Chaimae Abouzahir,Mouath Abu-Daoud,Ashwag Alasmari,Walid Al-Eisawi,Renad Al-Monef,Ali Alqahtani,Lama Ayash,Nizar Habash,Leen Kharouf*

Main category: cs.CL

TL;DR: AraHealthQA 2025 是一个包含 MentalQA 和 MedArabiQ 两个子任务的阿拉伯语医疗问答共享任务，旨在解决阿拉伯语医疗问答资源匮乏的问题，并促进在真实、多语言和具有文化特性的医疗环境下的模型研究。


<details>
  <summary>Details</summary>
Motivation: 解决阿拉伯语医疗问答资源匮乏的问题，并促进在真实、多语言和具有文化特性的医疗环境下的模型研究。

Method: 通过 MentalQA（关注心理健康）和 MedArabiQ（涵盖更广泛的医疗领域）两个互补的赛道，每个赛道包含多个子任务、评估数据集和标准化指标，以实现公平的基准测试。

Result: 介绍了数据集创建、任务设计、评估框架、参与者统计、基线系统以及总体结果。

Conclusion: 对观察到的性能趋势和未来阿拉伯语医疗问答研究的未来前景进行了反思。

Abstract: We introduce {AraHealthQA 2025}, the {Comprehensive Arabic Health Question
Answering Shared Task}, held in conjunction with {ArabicNLP 2025} (co-located
with EMNLP 2025). This shared task addresses the paucity of high-quality Arabic
medical QA resources by offering two complementary tracks: {MentalQA}, focusing
on Arabic mental health Q\&A (e.g., anxiety, depression, stigma reduction), and
{MedArabiQ}, covering broader medical domains such as internal medicine,
pediatrics, and clinical decision making. Each track comprises multiple
subtasks, evaluation datasets, and standardized metrics, facilitating fair
benchmarking. The task was structured to promote modeling under realistic,
multilingual, and culturally nuanced healthcare contexts. We outline the
dataset creation, task design and evaluation framework, participation
statistics, baseline systems, and summarize the overall outcomes. We conclude
with reflections on the performance trends observed and prospects for future
iterations in Arabic health QA.

</details>


### [148] [11Plus-Bench: Demystifying Multimodal LLM Spatial Reasoning with Cognitive-Inspired Analysis](https://arxiv.org/abs/2508.20068)
*Chengzu Li,Wenshan Wu,Huanyu Zhang,Qingtao Li,Zeyu Gao,Yan Xia,José Hernández-Orallo,Ivan Vulić,Furu Wei*

Main category: cs.CL

TL;DR: 该论文提出了一个评估多模态大语言模型（MLLM）空间推理能力的框架（11Plus-Bench），并进行了广泛的实验评估。研究发现，虽然MLLM在空间认知方面表现出早期迹象，但与人类相比仍有较大差距。MLLM的认知模式与人类相似，认知努力与推理复杂性密切相关，但MLLM在实例层面的表现是随机的，而人类的表现则受抽象模式复杂性的影响。


<details>
  <summary>Details</summary>
Motivation: 评估MLLM在空间推理和感知方面的能力，以及其与人类空间认知能力的相互作用，这是当前研究的空白领域。

Method: 引入了一个系统的评估框架，并创建了一个名为11Plus-Bench的高质量基准，该基准来源于标准化的空间能力测试，并包含精细的专家注释，用于实例级别的模型行为分析。通过对14个MLLM和人类进行广泛的实验评估。

Result: MLLM在空间认知方面表现出早期迹象，但与人类相比存在较大差距。MLLM的认知模式与人类相似，认知努力与推理复杂性高度相关。然而，MLLM在实例层面的表现接近随机，而人类的正确性则高度可预测，并受抽象模式复杂性的影响。

Conclusion: 尽管MLLM在空间推理能力方面展现出新兴的能力和局限性，但它们在认知模式上与人类相似。这项研究为改进模型设计提供了可行的见解，以提升MLLM的空间推理能力。

Abstract: For human cognitive process, spatial reasoning and perception are closely
entangled, yet the nature of this interplay remains underexplored in the
evaluation of multimodal large language models (MLLMs). While recent MLLM
advancements show impressive performance on reasoning, their capacity for
human-like spatial cognition remains an open question. In this work, we
introduce a systematic evaluation framework to assess the spatial reasoning
abilities of state-of-the-art MLLMs relative to human performance. Central to
our work is 11Plus-Bench, a high-quality benchmark derived from realistic
standardized spatial aptitude tests. 11Plus-Bench also features fine-grained
expert annotations of both perceptual complexity and reasoning process,
enabling detailed instance-level analysis of model behavior. Through extensive
experiments across 14 MLLMs and human evaluation, we find that current MLLMs
exhibit early signs of spatial cognition. Despite a large performance gap
compared to humans, MLLMs' cognitive profiles resemble those of humans in that
cognitive effort correlates strongly with reasoning-related complexity.
However, instance-level performance in MLLMs remains largely random, whereas
human correctness is highly predictable and shaped by abstract pattern
complexity. These findings highlight both emerging capabilities and limitations
in current MLLMs' spatial reasoning capabilities and provide actionable
insights for advancing model design.

</details>


<div id='quant-ph'></div>

# quant-ph [[Back]](#toc)

### [149] [Fourier transform-based linear combination of Hamiltonian simulation](https://arxiv.org/abs/2508.19596)
*Xi Huang,Dong An*

Main category: quant-ph

TL;DR: 本研究提出了基于傅里叶变换的线性哈密顿量模拟（LCHS）新形式，简化了现有LCHS形式的复杂技术条件，并提供了一种简单灵活的LCHS核函数构造方法。新的核函数显著降低了量子微分方程算法的资源消耗（门数量和量子比特深度），并首次将LCHS推广到模拟线性不确定动力学。


<details>
  <summary>Details</summary>
Motivation: 现有LCHS形式需要寻找满足复杂技术条件的核函数，限制了其应用。本研究旨在提供一种更简单、更灵活的LCHS形式。

Method: 提出一种基于傅里叶变换的LCHS新形式，并构造了一族新的LCHS核函数。

Result: 新的核函数在量子微分方程算法中实现了1.81倍的门数量减少和8.27倍的量子比特深度减少（误差$m{\epsilon}\le 10^{-8}$）。此外，将LCHS的适用范围扩展到模拟线性不确定动力学。

Conclusion: 基于傅里叶变换的LCHS新形式简化了核函数的构造，降低了量子算法的资源消耗，并扩展了LCHS的应用范围。

Abstract: Linear combination of Hamiltonian simulation (LCHS) connects the general
linear non-unitary dynamics with unitary operators and serves as the
mathematical backbone of designing near-optimal quantum linear differential
equation algorithms. However, the existing LCHS formalism needs to find a
kernel function subject to complicated technical conditions on a half complex
plane. In this work, we establish an alternative formalism of LCHS based on the
Fourier transform. Our new formalism completely removes the technical
requirements beyond the real axis, providing a simple and flexible way of
constructing LCHS kernel functions. Specifically, we construct a different
family of the LCHS kernel function, providing a $1.81$ times reduction in the
quantum differential equation algorithms based on LCHS, and an $8.27$ times
reduction in its quantum circuit depth at a truncation error of $\epsilon \le
10^{-8}$. Additionally, we extend the scope of the LCHS formula to the scenario
of simulating linear unstable dynamics for a short or intermediate time period.

</details>


### [150] [Quantum Resource Management in the NISQ Era: Challenges, Vision, and a Runtime Framework](https://arxiv.org/abs/2508.19276)
*Marcos Guillermo Lammers,Federico Hernán Holik,Alejandro Fernández*

Main category: quant-ph

TL;DR: NISQ设备资源管理对量子软件开发至关重要，提出运行时感知方法并用Qonscious原型进行验证。


<details>
  <summary>Details</summary>
Motivation: 分析NISQ设备硬件和逻辑资源的限制，以及它们对量子算法设计和部署的重要性。

Method: 分析NISQ设备资源的角色和影响，提出运行时感知量子软件开发方法，并开发Qonscious原型框架。

Result: 提出运行时感知量子软件开发愿景，识别关键挑战（如内省能力有限、时间约束），并用Qonscious原型证明了基于动态资源评估的条件执行。

Conclusion: Qonscious原型旨在加强量子资源估计（QRE）领域，并推动可扩展、可靠、资源感知的量子软件发展。

Abstract: Quantum computers represent a radical technological advancement in the way
information is processed by using the principles of quantum mechanics to solve
very complex problems that exceed the capabilities of classical systems.
However, in the current NISQ era (Noisy Intermediate-Scale Quantum devices),
the available hardware presents several limitations, such as a limited number
of qubits, high error rates, and reduced coherence times. Efficient management
of quantum resources, both physical (qubits, error rates, connectivity) and
logical (quantum gates, algorithms, error correction), becomes particularly
relevant in the design and deployment of quantum algorithms. In this work, we
analyze the role of resources in the various uses of NISQ devices today,
identifying their relevance and implications for software engineering focused
on the use of quantum computers. We propose a vision for runtime-aware quantum
software development, identifying key challenges to its realization, such as
limited introspection capabilities and temporal constraints in current
platforms. As a proof of concept, we introduce Qonscious, a prototype framework
that enables conditional execution of quantum programs based on dynamic
resource evaluation. With this contribution, we aim to strengthen the field of
Quantum Resource Estimation (QRE) and move towards the development of scalable,
reliable, and resource-aware quantum software.

</details>


### [151] [A New Approach to Unification](https://arxiv.org/abs/2508.19280)
*Partha Ghose*

Main category: quant-ph

TL;DR: 本论文提出了一种基于随机过程而非传统量子力学统一引力、电磁力、强力和弱力的新视角。


<details>
  <summary>Details</summary>
Motivation: 统一所有基本相互作用力。

Method: 利用随机过程（而非量子力学）来推导薛定谔方程、狄拉克方程和玻恩规则。引入了一个基本长度尺度来正则化场论中的无穷大问题。该方法可用于量化电动力学和线性引力，并通过广义黎曼-西尔伯特矢量描述非阿贝尔规范场，而无需依赖规范对称性。将这些场与离散空间的自旋网络耦合，构建了包含物质和几何的统一框架。

Result: 该模型在大尺度极限下可重现熟悉的量子场行为，并在基本层面上保持有限和背景无关。在引力中出现了类似于 Wheeler-DeWill 约束的平衡态。

Conclusion: 提出了一种基于物理随机性而非量子化规则的量子引力和统一的新途径。

Abstract: This paper presents a new perspective on unifying all fundamental
interactions--gravitational, electromagnetic, weak and strong--based on
stochastic processes rather than conventional quantum mechanics. Earlier work
by Nelson, Kac and others have established that key quantum features such as
the Schr\"{o}dinger and Dirac equations together with the Born rule can be
derived from classical random processes involving finite speeds and
probabilistic reversals. A fundamental length scale, inherent for dimensional
consistency, regularizes the infinities that typically plague conventional
field theories. The method can be used to quantize electrodynamics as well as
linear gravity, using the Riemann-Silberstein vector and its generalization.
  To include fields beyond electromagnetism, the Riemann-Silberstein vector can
be generalized to describe non-Abelian gauge fields without relying on gauge
symmetry. These fields can be coupled to spin networks--geometric structures
that discretize space--leading to a unified framework that includes both matter
and geometrty. In the large-scale limit, the model reproduces familiar quantum
field behaviour, while remaining finite and background-independent at the
fundamental level. The emergence of equilibrium states resembling
Wheeler-DeWill constraints in gravity adds further depth, suggesting a novel
route to quantum gravity and unification grounded in physical stochasticity
rather than quantization rules.

</details>


### [152] [Quantum Process Tomography of a Room-Temperature Alkali-Metal Vapor](https://arxiv.org/abs/2508.19634)
*Yujie Sun,Marek Kopciuch,Arash Dezhang Fard,Szymon Pustelny*

Main category: quant-ph

TL;DR: This paper presents a new Quantum Process Tomography (QPT) method for multi-level qudits, experimentally validated on a room-temperature atomic vapor. The method achieves high-fidelity reconstruction of qutrit Liouvillians and offers a computationally efficient framework for characterizing open quantum systems.


<details>
  <summary>Details</summary>
Motivation: Existing QPT methods face significant experimental challenges for multi-level qudits, especially in room-temperature atomic vapors, due to complex interactions, residual fields, environmental noise, and medium inhomogeneities. Overcoming these limitations is crucial for accurate modeling, precise control, and practical application of QPT.

Method: The paper introduces a new QPT method and experimentally validates it on a room-temperature $^{87}$Rb vapor ensemble. The approach establishes a computationally efficient framework for characterizing open quantum systems.

Result: The experimental validation achieved high-fidelity reconstruction of qutrit Liouvillians in a room-temperature atomic vapor.

Conclusion: The developed QPT method provides an efficient framework for characterizing open quantum systems, enabling the study of non-unitary dynamics, benchmarking of quantum sensors, and identification of environmental noise correlations.

Abstract: Quantum process tomography (QPT) is a technique for reconstructing the
dynamics of open quantum systems under the Born-Markov approximation, as
described by a Liouvillian superoperator, capturing both coherent and
dissipative processes. While QPT is well established for qubits, it presents
significant experimental challenges in multi-level qudits. In room-temperature
atomic vapors, these difficulties arise from complex interactions, residual
fields present in the system, environmental noise, and inhomogeneities in the
medium. Overcoming these limitations is essential for accurate modeling and
precise control of such systems--a critical step toward practical usage of the
QPT. We present a QPT method that we experimentally validate on a
room-temperature $^{87}$Rb vapor ensemble, achieving high-fidelity
reconstruction of qutrit Liouvillians. Our approach establishes a
computationally efficient framework for characterizing open quantum systems,
enabling the study of non-unitary dynamics, efficient benchmarking of quantum
sensors, and data-driven identification of environmental noise correlations.

</details>


### [153] [Time Symmetry, Retrocausality, and Emergent Collapse: The Tlalpan Interpretation of Quantum Mechanics](https://arxiv.org/abs/2508.19301)
*Alejandro Frank*

Main category: quant-ph

TL;DR: 量子力学（QM）的解释仍不清楚，特别是关于测量和坍塌。Tlalpan 解释 (QTI) 将坍塌视为一种涌现现象，即由放大和记录创建触发的时间对称性自发破坏。QTI 将坍塌嵌入统计物理学的临界现象中，并将坍塌描述为一种相变，其参数包括放大分数、记录不对称性和倒溯相干时间。


<details>
  <summary>Details</summary>
Motivation: 阐明量子力学的解释，特别是测量和坍塌问题，提出一种将坍塌视为由放大和记录创建触发的时间对称性自发破坏的涌现现象的新方法。

Method: 将量子坍塌嵌入统计物理学的临界现象的解释性框架中，将坍塌定义为一种相变，并引入可测量的参数（放大分数、记录不对称性和倒溯相干时间）作为描述量子-经典转变的序参数。

Result: QTI 提出了三个可检验的预测：(1) 当放大超过临界值时，干涉会急剧消失；(2) 混沌光学腔中的可逆性衰减异常快；(3) 在 Moshinsky 时间衍射的对称推广中会出现新的干涉条纹。

Conclusion: QTI 提出了一种新的量子力学解释，将坍塌视为一种相变，并提供了可检验的预测，如果得到证实，将使量子理论中的最后一条“神秘”公设成为热力学过程。

Abstract: Quantum mechanics has remained conceptually puzzling since its inception.
While its mathematical formalism provides predictions of unparalleled accuracy,
the interpretative framework underpinning measurement and collapse has never
been fully clarified. The Tlalpan Interpretation (QTI) proposes that the
wavefunction collapse is not a primitive, axiomatic rule but an emergent
phenomenon, a spontaneous breaking of time symmetry triggered by amplification
and record creation. The novelty of QTI lies in its embedding of collapse
within the conceptual language of critical phenomena in statistical physics.
The theory introduces measurable parameters (the amplification fraction, the
record asymmetry, and the retrocausal coherence time) that serve as order
parameters describing the quantum-classical transition. Collapse is thus
characterized not as a mysterious fiat but as a phase transition, with
thresholds and scaling laws analogous to magnetization in ferromagnets. This
perspective allows the interpretation to retain microscopic time symmetry and
spatial locality, while attributing quantum correlations and Bell-type
violations to retrocausal boundary constraints rather than instantaneous action
at a distance. Collapse corresponds to the granularization of trajectories: the
conversion of smooth, time-symmetric quantum evolution into discrete,
irreversible records. Most importantly, QTI is testable. It predicts: (1) sharp
threshold-like disappearance of interference when amplification exceeds a
critical value, (2) anomalously fast decay of reversibility in chaotic optical
cavities compared with regular ones, and (3) qualitatively new interference
fringes in a time-symmetric generalization of Moshinsky's diffraction in time.
If confirmed, these predictions would place collapse squarely in the realm of
thermodynamic processes, removing the last "mystical" postulate from quantum
theory.

</details>


### [154] [Quantum Entanglement as Super-Confounding: From Bell's Theorem to Robust Machine Learning](https://arxiv.org/abs/2508.19327)
*Pilsung Kang*

Main category: quant-ph

TL;DR: 本研究将贝尔定理与因果推断相结合，提出量子纠缠作为“超级混淆”资源，并通过计算验证了其违反经典因果界限的能力。研究提出了一个物理混淆层级（量子>经典），引入了量化混淆的混淆强度（CS），实现了区分因果与伪相关的量子DO演算的电路实现，并将其应用于量子机器学习问题，实现了11.3%的模型鲁棒性提升。


<details>
  <summary>Details</summary>
Motivation: 本研究旨在通过因果推断的视角重新解读量子力学与局域实在论之间的冲突，并为理解和利用量子纠缠这一资源提供新的框架。

Method: 本研究提出了一个将量子纠缠视为“超级混淆”资源的框架，并通过计算进行了验证。研究内容包括：1. 建立了物理混淆层级（量子>经典），并引入了混淆强度（CS）进行量化。2. 提供了量子DO演算的电路实现，用于区分因果关系和伪相关。3. 将该演算应用于量子机器学习问题，通过因果特征选择提高了模型鲁棒性。

Result: 研究建立了物理混淆层级，量化了混淆强度，实现了量子DO演算的电路实现，并在量子机器学习任务中，通过因果特征选择将模型鲁棒性平均绝对提升了11.3%。

Conclusion: 本研究成功地将量子基础理论与因果人工智能相结合，为理解量子相关性提供了一个新的、实用的视角，并展示了因果推断在量子机器学习领域的应用潜力。

Abstract: Bell's theorem reveals a profound conflict between quantum mechanics and
local realism, a conflict we reinterpret through the modern lens of causal
inference. We propose and computationally validate a framework where quantum
entanglement acts as a "super-confounding" resource, generating correlations
that violate the classical causal bounds set by Bell's inequalities. This work
makes three key contributions: First, we establish a physical hierarchy of
confounding (Quantum > Classical) and introduce Confounding Strength (CS) to
quantify this effect. Second, we provide a circuit-based implementation of the
quantum $\mathcal{DO}$-calculus to distinguish causality from spurious
correlation. Finally, we apply this calculus to a quantum machine learning
problem, where causal feature selection yields a statistically significant
11.3% average absolute improvement in model robustness. Our framework bridges
quantum foundations and causal AI, offering a new, practical perspective on
quantum correlations.

</details>


### [155] [Optimal Finite-Time Thermodynamics of Effective Two-Level Systems](https://arxiv.org/abs/2508.19341)
*Alberto Rolandi*

Main category: quant-ph

TL;DR: 该论文优化了在所有驱动速度下从有效的两能级系统中提取最大功所需的控制，并考虑了涨落对小系统的动力学的重要性。


<details>
  <summary>Details</summary>
Motivation: 优化热能转化为功以及最小化纳、介观系统的耗散，同时考虑涨落的作用。

Method: 将Esposito等人的工作推广到所有驱动速度下，以优化从有效的两能级系统中提取最大功所需的控制，并允许系统具有潜在的量子动力学（只要它们能被粗粒化为马尔可夫主方程）。

Result: 找到了热力学最优的协议，这些协议取决于将系统粗粒化为两能级系统所需的粗粒化大小。

Conclusion: 推导了在有效的两能级系统上进行的任何变换的速度限制。

Abstract: The optimization of the conversion of thermal energy into work and the
minimization of dissipation for nano- and mesoscopic systems is a complex
challenge because of the important role fluctuations play on the dynamics of
small systems. We generalize the work of Esposito et al. EPL 89, 20003 (2010)
to optimize at all driving speeds the control needed to extract the maximum
amount of work from any effective two-level systems. These emerge when one
coarse-grains degrees of freedom, which is often unavoidable to obtain
"real-world" two-level systems. In particular, we allow even for the system to
have underlying quantum dynamics, as long as these allow for a coarse-graining
that leads to a Markovian master equation. We analyze the finite-time
thermodynamics of these systems and find the thermodynamically optimal
protocols, which depend on the size of the coarse-graining needed to obtain a
two-level system. Furthermore, we use these results to derive speed-limits for
any transformation performed on an effective two-level system.

</details>


### [156] [First-Quantized Quantum Simulation of Non-Relativistic QED with Emergent Topologically Protected Coulomb Interactions](https://arxiv.org/abs/2508.19343)
*Torin Stetina,Nathan Wiebe*

Main category: quant-ph

TL;DR: This paper presents a simulation algorithm for light-matter interaction between charged particles and quantum electromagnetic fields, where the Coulomb interaction emerges from Gauss' law, offering topological protection against errors and a potential computational advantage for electronic structure problems.


<details>
  <summary>Details</summary>
Motivation: To develop a simulation algorithm for light-matter interaction that properly addresses the Coulomb interaction without explicitly including it in the Hamiltonian, and to explore the potential for topological protection and computational advantages in electronic structure calculations.

Method: The proposed method simulates light-matter interaction by imposing Gauss' law as a constraint, leading to the emergence of the Coulomb interaction in the non-relativistic limit. This approach offers topological protection against simulation-induced electric field errors. The scaling of non-Clifford gates required for the algorithm and for simulating the Coulomb interaction specifically were analyzed.

Result: The simulation algorithm exhibits topological protection, preventing point-like electric field errors from violating Coulomb's law and energetically disallowing non-contractable loop errors. The scaling of non-Clifford gates was found to be $\widetilde{O}(N^{2/3}\eta^{4/3} t \log^5(1/\epsilon))$ for the general method and $\widetilde{O}(N^{1/3} \eta^{8/3} t \log^2(1/\epsilon))$ for simulating the Coulomb interaction. A potential computational advantage is suggested when $N \in \tilde{o}(\eta^4)$ due to obviating the need for $O(\eta^2)$ pairwise interactions.

Conclusion: The developed simulation algorithm for non-relativistic first-quantized charged particles and quantum electromagnetic fields offers a novel approach where the Coulomb interaction emerges from Gauss' law, providing topological protection. This method could offer a computational advantage for electronic structure problems compared to traditional methods that explicitly compute pairwise Coulomb interactions, particularly under certain conditions regarding the number of spatial grid points and particles.

Abstract: We provide a simulation algorithm that properly addresses light matter
interaction between non-relativistic first-quantized charged particles and
quantum electromagnetic fields. Unlike previous work, our Hamiltonian does not
include an explicit Coulomb interaction between particles. Rather, the Coulomb
interaction emerges from the imposition of Gauss' law as a constraint upon the
system in an appropriate non-relativistic limit. Furthermore, a form of
topological protection emerges in our formalism, analogous to that of the Toric
code Hamiltonian. This mechanism prevents simulation-induced electric field
errors that can be contracted to a point from causing any deviations from
Coulomb's law in the non-relativistic limit and any error that forms a
non-contractable loop is energetically dissallowed in the limit of large
volume. We find that, under appropriate continuity assumptions, the number of
non-Clifford gates required by our algorithm scales in the thermodynamic limit
as $\widetilde{O}(N^{2/3}\eta^{4/3} t \log^5(1/\epsilon))$ for $\eta$
particles, $N$ spatial grid points, simulation time $t$ and error tolerance
$\epsilon$. In comparison, the more specific problem of simulating the Coulomb
interaction scales as $\widetilde{O}(N^{1/3} \eta^{8/3} t \log^2(1/\epsilon))$.
This suggests that if $N \in \tilde{o}(\eta^4)$ that our non-relativistic
electrodynamic simulation method could provide a computational advantage for
electronic structure problems in the thermodynamic limit under appropriate
continuity assumptions as it obviates the need to compute the $O(\eta^2)$
pairwise interactions in the Coulomb Hamiltonian.

</details>


### [157] [Revisiting the Jaynes-Cummings model with time-dependent coupling](https://arxiv.org/abs/2508.19422)
*Thiago T. Tsutsui,Danilo Cius,Antonio Vidiella-Barranco,Antonio S. M. de Castro,Fabiano M. Andrade*

Main category: quant-ph

TL;DR: The paper analyzes the resonant time-dependent Jaynes-Cummings (TDJC) model with modulated atom-field coupling, providing analytical solutions and insights into light-matter interactions.


<details>
  <summary>Details</summary>
Motivation: To study the resonant TDJC model with different modulations of atom-field coupling and understand how these variations affect physical phenomena.

Method: The paper presents the resonant TDJC model and derives an analytical solution in a didactic way. It also uses the Bloch vector to analyze system dynamics, atomic state purity, and phenomena like atomic dipole alignment and population trapping.

Result: Analytical solutions were obtained for the resonant TDJC model. The study examined the effects of time-dependent couplings on atomic population inversion and atom-field entanglement. Phenomena such as atomic dipole alignment and population trapping were observed and analyzed.

Conclusion: The study successfully analyzed the resonant TDJC model with modulated atom-field coupling, providing analytical solutions and demonstrating the impact of time-dependent couplings on various physical aspects of light-matter interaction. The Bloch vector analysis proved useful in understanding system dynamics and emergent phenomena.

Abstract: The Jaynes-Cummings (JC) model stands as a fully quantized, fundamental
framework for exploring light-matter interactions, a timely reflection on a
century of quantum theory. The time-dependent Jaynes-Cummings (TDJC) model
introduces temporal variations in certain parameters, which often require
numerical methods. However, under the resonance condition, exact solutions can
be obtained, offering insight into a variety of physical scenarios. In this
work, we study the resonant TDJC model considering different modulations of the
atom-field coupling. The model is presented and an analytical solution derived
in a didactic way, allowing us to examine how time-dependent couplings affect
atomic population inversion and atom-field entanglement. We also consider an
atom traversing a partially cooled cavity, which induces periodicity and
reveals the combined effects of atomic motion and thermal fluctuations. The
Bloch vector is used to analyze the dynamics of the system, including the
atomic state purity, and reveals phenomena such as atomic dipole alignment with
the field due to the oscillating coupling, as well as atomic population
trapping, which arises by increasing the initial mean thermal photon number.

</details>


### [158] [From Étendue to the Lowest Fundamental SNR: Pixel Étendue (Optogeometric Factor) Interpreted as Mode Count](https://arxiv.org/abs/2508.19434)
*Jan Sova,Marie Kolaříková*

Main category: quant-ph

TL;DR: 该论文将光几何因子解释为可访问的光模式数量，并将辐射通量与量子光子统计联系起来。


<details>
  <summary>Details</summary>
Motivation: 文章旨在将光几何因子的概念推广到像素级别，并揭示其与可访问光模式数量的联系，进而建立辐射通量与量子光子统计之间的关系。

Method: 通过将光几何因子与玻色-爱因斯坦分布相结合，推导出像素级别可实现的最低信噪比（SNR）。

Result: 得出了基于场景和基于传感器的显式公式，展示了最小信噪比如何依赖于孔径几何形状、像素间距、f数、波长和源温度。

Conclusion: 该研究提供了一个紧凑且物理解释清晰的基准，用于评估成像传感器的性能，并将其与最低的量子噪声极限进行比较。

Abstract: The optogeometric factor, recently introduced as a pixel level form of
\'etendue, quantifies the spatial angular throughput of a detector element. In
this work its interpretation is extended by identifying optogeometric factor
with the number of accessible optical modes per pixel. This mode based
perspective establishes a direct link between radiometric throughput and
quantum photon statistics.
  By combining optogeometric factor with the Bose Einstein distribution, an
estimate of the lowest achievable signal to noise ratio (SNR) at the pixel
level is derived.
  Explicit formulas are presented in both scene-based and sensor based forms,
showing how the minimal SNR depends on aperture geometry, pixel pitch,
f-number, wavelength, and source temperature. This formulation provides a
compact and physically transparent benchmark for evaluating imaging sensors
against the lowest expected quantum noise limit.

</details>


### [159] [Is data-efficient learning feasible with quantum models?](https://arxiv.org/abs/2508.19437)
*Alona Sakhnenko,Christian B. Mendl,Jeanette M. Lorenz*

Main category: quant-ph

TL;DR: 本研究探索了数据集大小对量子机器学习（QML）模型性能的影响，并提出了一个分析工具来研究经典-量子鸿沟。


<details>
  <summary>Details</summary>
Motivation: 旨在为理解数据集特征提供一个更具凝聚力的框架，并探讨量子机器学习模型（特别是量子核方法，QKMs）在数据效率方面超越经典模型的潜力。

Method: 生成半人工全经典数据集，并引入一个源自经典核方法的分析工具，用于研究经典-量子鸿沟。

Result: QKMs 在训练数据量较少的情况下实现了低错误率，并且所提出的分析工具（泛化度量）的预测结果与实证证据高度一致。

Conclusion: 量子核方法在数据效率方面展现出优于经典方法的潜力，所提出的分析工具能够有效预测模型性能，为未来深入研究数据集复杂性和QML模型的泛化能力奠定了基础。

Abstract: The importance of analyzing nontrivial datasets when testing quantum machine
learning (QML) models is becoming increasingly prominent in literature, yet a
cohesive framework for understanding dataset characteristics remains elusive.
In this work, we concentrate on the size of the dataset as an indicator of its
complexity and explores the potential for QML models to demonstrate superior
data-efficiency compared to classical models, particularly through the lens of
quantum kernel methods (QKMs). We provide a method for generating
semi-artificial fully classical datasets, on which we show one of the first
evidence of the existence of classical datasets where QKMs require less data
during training. Additionally, our study introduces a new analytical tool to
the QML domain, derived for classical kernel methods, which can be aimed at
investigating the classical-quantum gap. Our empirical results reveal that QKMs
can achieve low error rates with less training data compared to classical
counterparts. Furthermore, our method allows for the generation of datasets
with varying properties, facilitating further investigation into the
characteristics of real-world datasets that may be particularly advantageous
for QKMs. We also show that the predicted performance from the analytical tool
we propose - a generalization metric from classical domain - show great
alignment empirical evidence, which fills the gap previously existing in the
field. We pave a way to a comprehensive exploration of dataset complexities,
providing insights into how these complexities influence QML performance
relative to traditional methods. This research contributes to a deeper
understanding of the generalization benefits of QKM models and potentially a
broader family of QML models, setting the stage for future advancements in the
field.

</details>


### [160] [Casimir-Lifshitz interaction between bodies integrated in a micro/nanoelectromechanical quantum damped oscillator](https://arxiv.org/abs/2508.19726)
*Yu. S. Barash*

Main category: quant-ph

TL;DR: 该论文提出了一个理论，用于解释嵌入宏观量子阻尼振荡器中的物体之间产生的类似卡西米尔的力的分量。当振荡器的参数取决于物体之间的距离时，振荡器引起的类似卡西米尔的力通常由延伸到高频的广泛频谱范围决定，并受阻尼函数频率色散的限制。


<details>
  <summary>Details</summary>
Motivation: 该论文旨在解决当振荡器的参数取决于物体之间的距离时，振荡器引起的类似卡西米尔的力的问题，并提出一种理论来解释其产生。

Method: 该论文提出了一种理论，并证明了低频范围在许多系统中对力起主导作用，从而可以使用欧姆近似。这使得该理论能够扩展到描述电路中由涨落引起的力。

Result: 通过使用欧姆近似，该理论可以扩展到集总元件描述，并且该论文的估计表明，在特定条件下，电路引起的卡西米尔-利夫希茨力可以被实验识别，这取决于各种电路元件。

Conclusion: 该论文证明了在特定条件下，电路引起的卡西米尔-利夫希茨力可以通过其对电路元件的依赖性在实验中被识别，这为理解和利用这种力提供了新的途径。

Abstract: A theory is proposed for the component of the Casimir-like force that arises
between bodies embedded in a macroscopic quantum damped oscillator. When the
oscillator's parameters depend on the distance between the bodies, the
oscillator-induced Casimir-like force is generally determined by a broad
spectral range extending to high frequencies, limited by the frequency
dispersion of the damping function. Here it is shown that there is a large
class of systems in which the low-frequency range dominates the forces. This
allows for the use of the Ohmic approximation, which is crucial for extending
the theory to the lumped element description of fluctuation-induced forces in
electrical circuits. Estimates of the circuit-induced Casimir-Lifshitz force
suggest that under certain conditions it can be identified experimentally due
to its dependence on various circuit elements.

</details>


### [161] [Remote Quantum Networks based on Quantum Memories](https://arxiv.org/abs/2508.19538)
*Tian-Xiang Zhu,Xiao Liu,Zong-Quan Zhou,Chuan-Feng Li*

Main category: quant-ph

TL;DR: 量子网络利用量子存储器克服光纤损耗，实现远距离纠缠，但面临规模化挑战，未来发展方向值得关注。


<details>
  <summary>Details</summary>
Motivation: 光纤损耗限制了量子网络的规模化，量子存储器是克服此挑战的关键，但目前仍面临挑战。

Method: 概述了量子网络（特别是基于原子量子存储器的）的进展，阐述了面临的挑战，并讨论了未来的发展方向。

Result: 展示了量子网络和量子存储器的最新进展，明确了规模化量子网络建设的挑战。

Conclusion: 虽然量子网络和量子存储器取得了显著进展，但要实现大规模应用，仍需克服诸多挑战，并探索新的发展方向。

Abstract: Quantum networks, capable of transmitting arbitrary quantum states, provide a
foundation for a wide range of quantum applications, including distributed
quantum computing, distributed quantum sensing, and quantum communication.
Photons are the natural carrier of information in quantum networks, but the
exponential loss of optical fiber channels prevents the construction of
large-scale quantum networks. A potential solution is implementing quantum
repeaters based on quantum memories, which can efficiently establish
long-distance entanglement from short-distance entanglement. In the past
decades, intense efforts have been devoted to constructing large-scale quantum
networks based on various atomic quantum memories. In this Perspective, we
present a concise overview of current advancements in remote quantum networks,
elucidate the imminent challenges that must be addressed, and discuss the
future directions.

</details>


### [162] [One Rudolf Peierls' surprise: the quantum-to-classical transition in the context of solid-state physics](https://arxiv.org/abs/2508.19592)
*Navinder Singh*

Main category: quant-ph

TL;DR:  Bloch theorem is applicable to macroscopic crystals, but real electrons are open quantum systems subject to decoherence. This paper revisits Ovchinnikov and Erikhman's theory of decoherence due to ionic motion, corrects an oversight, and determines conditions for decoherence and the length scale of coherent ionic motion.


<details>
  <summary>Details</summary>
Motivation: To determine the conditions and length scales for decoherence in electrons within a periodic potential, addressing the applicability of Bloch theorem to macroscopic crystals.

Method: Revisiting the seminal theory of Ovchinnikov and Erikhman on decoherence due to ionic motion, correcting an oversight, and working out correct conditions for decoherence.

Result: Identified correct conditions for decoherence to occur and calculated the length scale up to which ionic motion remains coherent.

Conclusion: Discusses a realistic physical picture of decoherence in solid-state systems, considering the interplay between electron-ion interactions and quantum coherence.

Abstract: In solid state physics, it is an unsaid (tacit) assumption that the Bloch
theorem is applicable to a crystal lattice even if it is of the macroscopic
dimensions, provided periodicity is maintained. However, in a realistic
situation, electrons in a periodic potential of ions constitute an open quantum
system and are subjected to decoherence and dissipation. A natural question
arises: up to what distances electrons in a periodic potential can be
considered as constituting an effective closed quantum system? And what is the
cause of decoherence? To answer some of these questions, the seminal theory of
Ovchinnikov and Erikhman of decoherence due to ionic motion is revisited and an
oversight of the authors is corrected. Correct conditions for decoherence to
occur are worked out. Length scale up to which the motion of ions remains
coherent is also calculated. Finally, a realistic physical picture is
discussed.

</details>


### [163] [Multichannel and high dimensional integrated photonic quantum memory](https://arxiv.org/abs/2508.19605)
*Zhong-Wen Ou,Tian-Xiang Zhu,Peng-Jun Liang,Xiao-Min Hu,Zong-Quan Zhou,Chuang-Feng Li,Guang-Can Guo*

Main category: quant-ph

TL;DR: 集成了基于激光写入波导阵列的11通道量子存储器，可独立控制读出时间，实现了高保真度的多通道、高维量子态存储。


<details>
  <summary>Details</summary>
Motivation: 解决现有光子量子存储器仅限于单通道操作，限制了其处理多光子和支持高维信息的能力。

Method: 在$^{151}$Eu$^{3+}$:Y$_2$SiO$_5$晶体中，利用激光写入波导阵列构建11通道集成量子存储器，并通过片上电极阵列实现对每个通道读出时间的独立控制（基于斯塔克频移诱导原子干涉）。

Result: 实现了高保真度（超过99%）的三时间仓量子比特随机访问量子存储，以及高保真度（高于96%）的五维路径编码量子态存储。

Conclusion: 该多通道集成量子存储设备通过其随机访问能力实现了通用应用，并为集成架构中高维量子网络的发展奠定了坚实基础。

Abstract: Integrated photonic quantum memories are essential components for scalable
quantum networks and photonic information processors. However, prior
implementations have been confined to single-channel operation, limiting their
capacity to manipulate multiple photonic pulses and support high-dimensional
information. In this work, we introduce an 11-channel integrated quantum memory
based on laser-written waveguide arrays in $^{151}$Eu$^{3+}$:Y$_2$SiO$_5$
crystals. On-chip electrode arrays enable independent control over the readout
times for each channel via Stark-shift-induced atomic interference. Our device
achieves random-access quantum storage of three time-bin qubits with a fidelity
exceeding 99%, as well as storage of five-dimensional path-encoded quantum
states with a fidelity above 96%. This multichannel integrated storage device
enables versatile applications through its random access capability and lays a
solid foundation for the development of high-dimensional quantum networks in
integrated architectures.

</details>


### [164] [Near-Ultimate Quantum-Enhanced Sensitivity in Dissipative Critical Sensing with Partial Access](https://arxiv.org/abs/2508.19606)
*Dingwei Zhao,Abolfazl Bayat,Victor Montenegro*

Main category: quant-ph

TL;DR: 量子传感器利用量子效应高精度探测微小量，但制备资源消耗大且需要复杂测量。本文研究耗散量子相变中的驱动Jaynes-Cummings系统作为量子传感器，发现失谐可改善传感性能。该传感器不依赖初始探针制备，灵敏度随强耦合比呈超线性增强，部分可及系统也存在此现象。通过对场态进行单模连续测量和贝叶斯估计，可接近极限灵敏度。


<details>
  <summary>Details</summary>
Motivation: 量子探针的制备资源消耗大且需要复杂测量，限制了其作为量子传感器的应用。

Method: 研究耗散量子相变中的驱动Jaynes-Cummings系统作为量子传感器，并通过失谐和单模连续测量与贝叶斯估计来提升传感性能。

Result: 失谐显著改善了传感性能，并且灵敏度随强耦合比的增大而超线性增强，即使在部分系统可及的情况下也能保持量子增强的灵敏度。单模连续测量结合贝叶斯估计的方案几乎达到了系统极限灵敏度。

Conclusion: 该耗散量子传感器不依赖于初始探针的制备，并且在部分系统可及的情况下，其灵敏度仍能得到量子增强，通过单模连续测量和贝叶斯估计可以实现接近极限的传感性能。

Abstract: Quantum sensors are powerful devices that exploit quantum effects to detect
minute quantities with extremely high precision. Two obstacles to harnessing
the full capacity of quantum probes are the resource-intensive preparation of
the probe and the need for sophisticated measurements that typically require
full access to the entire probe. Here, we address these challenges by
investigating the driven Jaynes-Cummings system undergoing a dissipative
quantum phase transition as a quantum sensor. We show that detuning the system
off resonance significantly improves sensing performance by adequately
selecting a preferred bistable state in phase space. Our dissipative sensor,
independent of the initial probe preparation, exhibits a super-linear
enhancement in sensitivity with respect to a specific sensing resource -- the
strong-coupling regime ratio -- which manifests in both the full system and
partial subsystem. Hence, quantum-enhanced sensitivity persists even when only
partial system accessibility is available. Remarkably, we show that a homodyne
detection of the field state, combined with Bayesian estimation, nearly
saturates the ultimate sensitivity limit of the entire system.

</details>


### [165] [Quantification of Quantum Dynamical Properties with Two Experimental Settings](https://arxiv.org/abs/2508.19668)
*Tzu-Liang Hsu,Kuan-Jou Wang,Chun-Hao Chang,Sheng-Yan Sun,Shih-Husan Chen,Ching-Jui Huang,Che-Ming Li*

Main category: quant-ph

TL;DR: 我们提出了一种近似优化方法，使用两个互无偏倚基来估计量子过程的性质度量，并重建相应的过程，从而避免了随系统尺寸增加而增加的实验设置需求。


<details>
  <summary>Details</summary>
Motivation: 目前的量子过程表征方法需要与系统尺寸成比例增长的实验设置数量，这会导致实验误差累积。本研究旨在提出一种能够克服这一限制的方法。

Method: 提出了一种近似优化方法，仅使用两个互无偏倚基来计算量子过程性质度量的下界和上界，并据此重建过程。

Result: 与量子过程层析成像相比，该方法在光子融合和 CNOT 门操作上进行了实验验证，结果显示在大大减少实验设置数量的同时，能够准确地估计资源。对于光子融合，实验设置从 81 减少到 10；对于 CNOT 门，减少到 2。

Conclusion: 该方法通过避免误差累积，能够表征固有的量子动力学，并且不依赖于系统尺寸，适用于从芯片级量子处理器到长距离量子网络的各种架构中的动力学性质估计。

Abstract: Characterizing quantum dynamics is essential for quantifying arbitrary
properties of a quantum process -- such as its ability to exhibit
quantum-mechanical dynamics or generate entanglement. However, current methods
require a number of experimental settings that increases with system size,
leading to artifacts from experimental errors. Here, we propose an approximate
optimization method that estimates property measures using only two mutually
unbiased bases to compute their lower and upper bounds, and to reconstruct the
corresponding processes. This system-size independence prevents error
accumulation and allows characterization of the intrinsic quantum dynamics.
Compared with quantum process tomography, we experimentally validate our method
on photonic fusion and controlled-NOT operations, demonstrating accurate
resource estimation while substantially reducing the number of required Pauli
experimental settings: from 81 to 10 for the photonic fusion and to 2 for the
controlled-NOT. These results show that our method is well-suited for
estimation of dynamical properties in architectures ranging from chip-scale
quantum processors to long-distance quantum networks.

</details>


### [166] [Selective Preparation of Collective States in Coupled Quantum Emitters Using the SUPER Excitation Scheme](https://arxiv.org/abs/2508.19692)
*Johannes Kerber,Laurin Ostermann,Vikas Remesh,Helmut Ritsch,Arpita Pal*

Main category: quant-ph

TL;DR: 我们提出了一种名为SUPER的激发方案，用于在深亚波长分离下制备两个偶极耦合的量子发射体的超辐射和次辐射态。该方案利用两个红失谐、时间重叠的高斯脉冲，能够实现目标集体本征态接近单位的布居反演。通过可调的光相位，SUPER方案可以同时实现纯超辐射和次辐射态的有限布居反演，从而制备混合集体态。无论是否有光学腔，该方案都可实现。该方法为在环境退相干存在下有效制备这些态铺平了道路，并能够实现单光子生成，可通过二阶关联函数进行测量。我们还详细讨论了使用固态发射体和分子等进行实验实现的可能性。


<details>
  <summary>Details</summary>
Motivation: 本研究旨在解决亚波长间隔光学偶极子的集体本征态制备问题，这是观察其辐射特性和在量子信息处理中应用的前提。

Method: 我们理论上研究了利用SUPER（Quantum Emitter Population的Swing-UP）激发方案，在深亚波长分离下确定性地制备两个偶极耦合的量子发射体的超辐射和次辐射态。通过仔细选择两个红失谐、时间重叠的高斯脉冲的参数，该方案实现了目标集体本征态的近乎完美的布居反演。此外，通过引入SUPER方案中的可调谐光相位，可以同时实现纯超辐射态和次辐射态的有限布居反演，从而制备出混合集体态。

Result: SUPER方案能够实现目标集体本征态接近单位的布居反演。通过可调的光相位，可以同时实现纯超辐射和次辐射态的有限布居反演，产生混合集体态。该方案可用于有腔或无腔环境，并能实现单光子生成，可通过二阶关联函数测量。

Conclusion: SUPER激发方案为在深亚波长分离下制备量子发射体的集体本征态（包括超辐射、次辐射和混合态）提供了一种有效的方法。该方案具有实现简单、可扩展性强等优点，为在量子信息处理和光学传感等领域实现高性能器件提供了新的途径。

Abstract: The efficient preparation of collective eigenstates of subwavelength-spaced
optical dipoles is a prerequisite for observing their signature radiative
properties and for their applications in quantum information processing. We
theoretically investigate the deterministic preparation of superradiant and
subradiant states of two dipole-coupled two-level quantum emitters at
deep-subwavelength separation using the Swing-UP of Quantum Emitter Population
(SUPER) excitation scheme. Utilizing suitable pulse parameters for two
red-detuned, time-overlapping Gaussian pulses, the SUPER scheme enables
close-to-unity population inversion in the targeted collective eigenstates.
Furthermore, a tunable optical phase in the SUPER scheme enables the
simultaneous inversions in both pure super- and subradiant states with finite
populations, thereby resulting in the preparation of hybrid collective states.
These results are possible to realize with or without an optical cavity. Our
approach to populating the collective eigenstates in a cavity environment paves
the way for the efficient preparation of these states in the presence of
environmental decoherence. Our scheme enables single-photon generation, which
is measured using the second-order correlation function. We also discuss in
detail possible experimental realizations, in particular using solid-state
emitters and molecules.

</details>


### [167] [Optimal control on open quantum systems and application to non-Condon photo-induced electron transfer](https://arxiv.org/abs/2508.19766)
*Zi-Fan Zhu,Yu Su,Yao Wang,Rui-Xue Xu*

Main category: quant-ph

TL;DR: 提出一种新的开放量子系统最优控制理论，并将其应用于光诱导电子转移（PET）


<details>
  <summary>Details</summary>
Motivation: 开发开放量子系统最优控制理论，并应用于光诱导电子转移

Method: 利用耗散子理论，结合系统和环境的协同控制，实现对PET的精确控制

Result: 成功地将该控制方案应用于非Condon光诱导电子转移，并展示了环境辅助转移

Conclusion: 该研究为通过极化环境操纵开放系统动力学提供了新的思路

Abstract: In this work, we develop an optimal control theory on open quantum system and
its environment, and exemplify the method with the application to the
non-Condon photo-induced electron transfer (PET) in condensed phase. This
method utilizes the dissipaton theory, proposed by Yan in 2014 for open quantum
systems, which provides an exact description of the dissipative system while
also enables rigorous characterization and control of environmental
hybridization modes, fully taking into account the non-perturbative and
non-Markovian effects. Leveraging the advantage of the dissipaton phase-space
algebra, we present in this communication the theoretical strategy for optimal
control on both system and environment simultaneously. The control protocol is
successfully demonstrated on PET for the environment-targeted-control
facilitated transfer. This work sheds the light on manipulating open systems
dynamics via polarized environment.

</details>


### [168] [Canonical pairs in finite-dimensional Hilbert space](https://arxiv.org/abs/2508.19783)
*Ralph Adrian E. Farrales,Eric A. Galapon*

Main category: quant-ph

TL;DR: 在有限维希尔伯特空间中，通过在proper子空间中满足正则对易关系，找到了正则对。研究了这些正则对满足的不确定性关系，并将其应用于构造有限维量子力学中的时间算符。


<details>
  <summary>Details</summary>
Motivation: 探究在有限维希尔伯特空间中是否存在满足正则对易关系的正则对。

Method: 通过在proper子空间中满足正则对易关系来构造正则对，并研究它们的不确定性关系，最后应用于构造有限维量子力学中的时间算符。

Result: 成功构造了有限维希尔伯特空间中的正则对，并研究了它们的不确定性关系，以及在量子力学中的应用。

Conclusion: 在有限维希尔伯特空间中，通过在proper子空间中满足正则对易关系，可以找到正则对，并可用于构造时间算符。

Abstract: A pair of Hermitian operators is canonical if they satisfy the canonical
commutation relation. It has been believed that no such canonical pair exists
in finite-dimensional Hilbert space. Here, we obtain canonical pairs by noting
that the canonical commutation relation holds in a proper subspace of the
Hilbert space. For a given Hilbert space, we study the many possible canonical
pairs and look into the uncertainty relation they satisfy. We apply our results
by constructing time operators in finite-dimensional quantum mechanics.

</details>


### [169] [Grover's search with an oracle distinguishing between solutions](https://arxiv.org/abs/2508.19793)
*Hristo Tonchev,Rosen Bahtev*

Main category: quant-ph

TL;DR: Grover算法的修改：使用多相Oracle标记多个解，保持高查找概率。


<details>
  <summary>Details</summary>
Motivation: 当存在多个解时，维护找到解的高概率。

Method: 提出一种基于多相Oracle的Grover算法修改，该Oracle为每个解标记不同的相位。

Result: 证明该修改算法可以在等于或超过确定性Grover算法的迭代次数下，保持高查找概率，且概率保持区间受寄存器大小和Oracle相位影响。

Conclusion: 该多相Oracle修改的Grover算法能有效处理多解问题，并在一定迭代次数范围内保持高查找概率。

Abstract: Here we suggest a modification of Grover's algorithm, based on a multiphase
oracle which marks each solution with a different phase when there is more than
one solution. Such a modification can be used to maintain a high probability of
finding a solution for a number of iterations equal to or more than the one
required by the deterministic Grover's algorithm (the one based on generalized
Householder reflections). We use various semiempirical methods to show that the
interval of number of iterations for which the algorithm keeps the probability
of finding solution high depends on the register size and the oracle phases.

</details>


### [170] [Partial Anyon Condensation in the Color Code: A Hamiltonian Approach](https://arxiv.org/abs/2508.19877)
*Mohsen Rahmani Haghighi,Mohammad Hossein Zarei*

Main category: quant-ph

TL;DR: 通过研究可调谐格子哈密顿量，我们发现加入的伊辛相互作用可以模拟任意子凝聚，并导致相变到托利码态或部分拓扑相。


<details>
  <summary>Details</summary>
Motivation: 为了理解拓扑相变背后的物理机制，需要研究可调谐的格子哈密顿量。

Method: 通过对主哈密顿量进行基变换，将模型映射到三个解耦的横向场伊辛模型，并分析了字符串序参量。

Result: 研究发现，凝聚一种任意子会导致相变到托利码态；凝聚两种任意子会导致相变到部分拓扑相。

Conclusion: 通过调整伊辛相互作用的强度，可以实现不同任意子的凝聚，并实现到托利码态或部分拓扑相的相变。

Abstract: Lattice Hamiltonians, which can be tuned between different topological
phases, are known as important tools for understanding physical mechanism
behind topological phase transitions. In this paper, we introduce a perturbed
Color Code Hamiltonian with a rich phase structure which can be well matched to
the mechanism of anyon condensation in the Color Code. We consider Color Code
model defined on a three-colorable hexagonal lattice and add Ising interactions
between spins corresponding to edges of the lattice. We show that Ising
interactions play the role of physical factor for condensing anyons in the
Color Code. In particular, corresponding to three different colors of edges in
the hexagonal lattice, we consider three different coupling parameters. Then,
we are able to condense anyons with different colors by tuning power of Ising
interactions in the corresponding edges. In particular, we explicitly show that
condensation of one type of anyons in the Color Code leads to a phase
transition to the Toric Code state. On the other hand, by condensing two types
of anyons, we observe a phase transition to a modified version of the Toric
Code where partial set of anyons in the Toric Code are condensed and we call it
a partially topological phase. Our main method for derivation of the above
results is based on a suitable basis transformation on the main Hamiltonian in
the sense that our model is mapped onto three decoupled transverse-field Ising
models, corresponding to the three colors. We use the above mapping to analyze
behavior of string order parameters as non-local indicators of topological
order. We introduce three string order parameters that can well characterize
different phases of the model. Specifically we give a simple description of the
partially condensed phase by using string order parameters.

</details>


### [171] [Measuring non-Gaussianity with Correlation](https://arxiv.org/abs/2508.19890)
*Oliver Hahn,Ryuji Takagi*

Main category: quant-ph

TL;DR: 本论文提出了一个基于关联生成的新框架，用于量化连续变量量子系统中的非高斯性。该框架表明，当且仅当一个状态是非高斯态时，其两个副本在50:50分束器上会产生关联，并且在纯态情况下，这种关联会减少为纠缠。论文还引入了基于关联量化器的操作性非高斯性度量，如纯态的Rényi-α熵和混合态的Rényi-α互信息，并证明了这些度量在高斯信道下的单调性。在此基础上，论文提出了一种样本效率高的实验方案，用于估计非高斯性，即使在状态不可知的情况下也适用。此外，论文还为估计Wigner负性设定了样本复杂度的下界，以便与所提出的方案进行直接比较。研究结果为非高斯性提供了一个统一的理论框架，并为其实验量化提供了一条实用的途径。


<details>
  <summary>Details</summary>
Motivation: 量化连续变量量子系统中的非高斯性，因为非高斯性是实现量子优势的关键资源。

Method: 提出一个基于关联生成的新框架，量化非高斯性。具体方法包括：1. 证明当且仅当状态是非高斯态时，其两个副本在50:50分束器上会产生关联。2. 引入基于关联量化器（如Rényi-α熵和Rényi-α互信息）的操作性非高斯性度量。3. 证明这些度量在高斯信道下的单调性。4. 提出一种样本效率高的实验协议来估计非高斯性。5. 建立估计Wigner负性的样本复杂度下界。

Result: 1. 提出了一个统一的理论框架来量化非高斯性。2. 引入了基于关联生成的度量，并证明了它们在高斯信道下的单调性。3. 提出了一种样本效率高的实验方案来估计非高斯性。4. 建立了估计Wigner负性的样本复杂度下界，并与所提出的方案进行了比较。

Conclusion: 本研究为量化连续变量量子系统中的非高斯性提供了一个统一的理论框架和实用的实验途径，有助于推动量子信息科学的发展。

Abstract: Quantum non-Gaussianity is a key resource for quantum advantage in
continuous-variable systems. We introduce a general framework to quantify
non-Gaussianity based on correlation generation: two copies of a state become
correlated at a $50{:}50$ beam splitter if and only if the state is
non-Gaussian, with correlations reducing to entanglement in the pure-state
case. This connection enables operational measures of non-Gaussianity, defined
through correlation quantifiers such as R\'enyi-$\alpha$ entropy for pure
states and R\'enyi-$\alpha$ mutual information for mixed states. We prove that
all such measures are monotonic under Gaussian channels. Building on this
framework, we propose a sample-efficient experimental protocol to estimate
non-Gaussianity using standard optical components, even in the state agnostic
setting. Finally, we establish a lower bound on the sample complexity of
estimating Wigner negativity, allowing a direct comparison with our protocol.
Our results provide both a unifying theoretical framework for non-Gaussianity
and a practical route toward its experimental quantification.

</details>


### [172] [Towards quantum topological data analysis: torsion detection](https://arxiv.org/abs/2508.19943)
*Nhat A. Nghiem*

Main category: quant-ph

TL;DR: 量子计算在拓扑数据分析（TDA）领域的应用越来越受关注。尽管计算贝蒂数（TDA中的核心任务）被证明是NP难的，表明量子计算机不太可能提供通用加速，但本研究着眼于TDA的另一个重要特征——挠（torsion）。挠能揭示更丰富的结构信息。研究人员提出了一种新的量子算法，用于检测一个给定的单纯复形是否包含挠，该算法结合了低复杂度经典程序，有潜力实现指数级加速。


<details>
  <summary>Details</summary>
Motivation: 尽管量子计算在TDA领域的研究已取得一些进展，但大多数研究集中在贝蒂数上，而忽略了挠这一能提供更丰富结构信息的拓扑特征。本研究旨在填补这一空白，探索量子算法在挠检测方面的潜力。

Method: 提出了一种结合低复杂度经典程序的量子算法，用于检测给定单纯复形是否包含挠。

Result: 该量子算法能够以高概率成功检测挠，并有望实现相对于经典算法的指数级加速。

Conclusion: 本研究成功引入了一种量子算法用于挠检测，为TDA领域中利用量子计算提供了新的方向，并展示了在特定问题上实现指数级加速的可能性。

Abstract: Topological data analysis (TDA) has become an attractive area for the
application of quantum computing. Recent advances have uncovered many
interesting connections between the two fields. On one hand, complexity
theoretic results show that estimating Betti numbers, a central task in TDA, is
NP hard, indicating that a generic quantum speedup is unlikely. On the other
hand, several recent studies have explored structured, less generic settings
and demonstrated that quantum algorithms can still achieve significant speedups
under certain conditions. To date, most of these efforts have focused on Betti
numbers, which are topological invariants capturing the intrinsic connectivity
and holes in a dataset. However, there is another important feature of
topological spaces: torsion. Torsion represents a distinct component of
homology that can reveal richer structural information. In this work, we
introduce a quantum algorithm for torsion detection, that is, determining
whether a given simplicial complex contains torsion. Our algorithm, assisted by
a low complexity classical procedure, can succeed with high probability and
potentially offer exponential speedup over the classical counterpart.

</details>


### [173] [Direct probing of the simulation complexity of open quantum many-body dynamics](https://arxiv.org/abs/2508.19959)
*Lucia Vilchez-Estevez,Alexander Yosifov,Jinzhao Sun*

Main category: quant-ph

TL;DR: 研究了开放量子系统模拟的计算复杂度，并与封闭量子系统进行了比较。


<details>
  <summary>Details</summary>
Motivation: 理解非平衡过程和稳态相变，并阐明耗散在模拟开放系统动力学中的作用。

Method: 通过研究与两个物理相关参数（关联长度和混合时间）相关的计算复杂度，并利用量子和经典方法（经典复杂度由键维度和算子纠缠熵表征）。

Result: 耗散以不同的方式影响中长时程的关联长度和混合时间；在经典的张量网络模拟中，耗散的增强并不降低经典复杂度，揭示了量子和经典资源缩放之间的分离。

Conclusion: 耗散对开放量子系统模拟的计算复杂度有显著影响，并且与封闭系统存在资源缩放上的差异。

Abstract: Simulating open quantum systems is key to understanding non-equilibrium
processes, as persistent influence from the environment induces dissipation and
can give rise to steady-state phase transitions. A common strategy is to embed
the system-environment into a larger unitary framework, but this obscures the
intrinsic complexity of the reduced system dynamics. Here, we investigate the
computational complexity of simulating open quantum systems, focusing on two
physically relevant parameters, correlation length and mixing time, and explore
whether it can be comparable (or even lower) to that of simulating their closed
counterparts. In particular, we study the role of dissipation in simulating
open-system dynamics using both quantum and classical methods, where the
classical complexity is characterised by the bond dimension and operator
entanglement entropy. Our results show that dissipation affects correlation
length and mixing time in distinct ways at intermediate and long timescales.
Moreover, we observe numerically that in classical tensor network simulations,
classical complexity does not decrease with stronger dissipation, revealing a
separation between quantum and classical resource scaling.

</details>


### [174] [Hyper-spectral Imaging with Up-Converted Mid-Infrared Single-Photons](https://arxiv.org/abs/2508.19970)
*Yijian Meng,Asbjørn Arvad Jørgensen,Andreas Næsby Rasmussen,Lasse Høgstedt,Søren M. M. Friis,Mikael Lassen*

Main category: quant-ph

TL;DR: 科学家们开发了一种新的单光子成像平台，可以在中红外（MIR）光谱范围内对生物样本进行无标记、非侵入性成像。该系统利用腔增强自发参量下转换（SPDC）和非线性频率上转换技术，结合了可见光硅单光子雪崩二极管（Si-SPADs），实现了在室温下、低噪声、高效率的中红外光谱成像。与传统中红外成像技术的高强度照明不同，该平台使用极低的光子通量，避免了对敏感生物组织的损伤，并且能够抑制古典强度噪声，实现接近散粒噪声极限的成像。实验证明，该系统能够对生物样本（蛋黄、酵母）和聚合物（聚苯乙烯、聚乙烯）进行化学特异性成像，在2.9至3.6微米范围内提供高对比度的无标记成像。


<details>
  <summary>Details</summary>
Motivation: 传统的中红外（MIR）成像技术虽然在生物医学和生物化学应用中具有分子特异性优势，但通常需要高强度照明，可能对敏感生物组织造成光损伤。单光子MIR成像作为一种无标记、非侵入性的替代方案，其发展受到缺乏高效、室温工作的MIR单光子探测器限制。

Method: 本研究提出了一种结合腔增强自发参量下转换（SPDC）和非线性频率上转换的单光子高光谱成像平台。该平台利用SPDC技术产生时间相关的光子对，抑制了古典强度噪声，并结合非线性频率上转换技术，使得使用成本较低的可见光波长硅单光子雪崩二极管（Si-SPADs）进行中红外光谱成像成为可能。该方法支持室温、低噪声和高效率的操作。

Result: 该平台成功实现了对生物样本（蛋黄、酵母）和聚合物（聚苯乙烯、聚乙烯）在2.9至3.6微米范围内的化学特异性单光子成像。成像结果显示出高对比度，并且在极低的光子通量下实现了无标记成像，克服了现有中红外技术的关键限制。

Conclusion: 该单光子高光谱成像平台通过结合SPDC和非线性频率上转换技术，有效解决了中红外单光子探测器的挑战，实现了在室温下的高灵敏度、低噪声成像。该技术有望推动分子诊断、环境传感和生物医学研究领域的发展，为可扩展的、量子赋能的中红外成像提供了新的途径。

Abstract: Hyperspectral imaging in the mid-infrared (MIR) spectral range provides
unique molecular specificity by probing fundamental vibrational modes of
molecular bonds, making it highly valuable for biomedical and biochemical
applications. However, conventional MIR imaging techniques often rely on
high-intensity illumination that can induce photodamage in sensitive biological
tissues. Single-photon MIR imaging offers a label-free, non-invasive
alternative, yet its adoption is hindered by the lack of efficient,
room-temperature MIR single-photon detectors. We present a single-photon
hyperspectral imaging platform that combines cavity-enhanced spontaneous
parametric down-conversion (SPDC) with nonlinear frequency up-conversion. This
approach enables MIR spectral imaging using cost-effective, visible-wavelength
silicon single-photon avalanche diodes (Si-SPADs), supporting room-temperature,
low-noise, and high-efficiency operation. Time-correlated photon pairs
generated via SPDC suppress classical intensity noise, enabling near
shot-noise-limited hyperspectral imaging. We demonstrate chemically specific
single-photon imaging across the \SIrange{2.9}{3.6}{\micro\meter} range on
biological (egg yolk, yeast) and polymeric (polystyrene, polyethylene) samples.
The system delivers high-contrast, label-free imaging at ultralow photon flux,
overcoming key limitations of current MIR technologies. This platform paves the
way toward scalable, quantum-enabled MIR imaging for applications in molecular
diagnostics, environmental sensing, and biomedical research.

</details>


### [175] [Momentum-resolved Hong-Ou-Mandel interference of weak coherent states](https://arxiv.org/abs/2508.19978)
*Fabrizio Sgobba,Francesco Di Lena,Danilo Triggiani,Deborah Katia Pallotti,Cosmo Lupo,Piergiorgio Daniele,Gennaro Fratta,Giulia Acconcia,Ivan Rech,Luigi Santamaria Amato*

Main category: quant-ph

TL;DR: 本研究提出了一种基于横向动量分辨双光子干涉的实验方案，使用独立光子和SPAD阵列实现高精度定位测量。


<details>
  <summary>Details</summary>
Motivation: 为解决传统Hong-Ou-Mandel干涉在光子不可区分性方面的固有限制，扩展其应用范围至高分辨率成像。

Method: 利用横向动量分辨双光子干涉技术，结合独立光子和SPAD阵列进行实验。

Result: 实验结果表明，通过测量场中四阶关联的横向动量分辨，可以克服独立光子间的空间可区分性，达到了量子估计理论所确定的极限精度。

Conclusion: 该方法不仅能在传感和成像领域超越空间可区分性的限制，还能在量子信息处理中利用部分光子可区分性和纠缠杂质。

Abstract: We demonstrate an experimental scheme for high-precision position
measurements based on transverse-momentum-resolved two-photon interferometry
with independent photons and SPAD arrays. Our scheme extends the operative
range of Hong-Ou-Mandel interferometry beyond its intrinsic constraints due to
photons indistinguishability, paving the way to applications in high-resolution
imaging. We assess the experimental results against the ultimate precision
bounds as determined by quantum estimation theory. Our experiment ultimately
proves that transverse-momentum resolved measurements of fourth-order
correlations in the fields can be employed to overcome spatial
distiguishability between independent photons. The relevance of our results
extends beyond sensing and imaging towards quantum information processing, as
we show that partial photon distinguishability and entanglement impurity are
not necessarily a nuisance in a technique that relies on two-photon
interference.

</details>


### [176] [A method of an on-demand beamsplitter for trapped-ion quantum computers](https://arxiv.org/abs/2508.19995)
*Takanori Nishi*

Main category: quant-ph

TL;DR: 局域模式间纠缠控制的量子信息处理


<details>
  <summary>Details</summary>
Motivation: 为解决囚禁离子系统中局域模式间纠缠控制的难题，因库仑相互作用不可切换，导致共振模式间纠缠难以调控。

Method: 提出一种基于可动态调控模式的超细分割的囚禁离子方法，通过使相邻模式失谐，仅在需要时进行超细分割操作。

Result: 推导了该操作的解析公式，并通过数值模拟确认了其有效性。

Conclusion: 该方法为囚禁离子系统中的纠缠控制提供了新的途径。

Abstract: Quantum information processing using local modes of trapped ions has been
applied to implementing bosonic quantum error correction codes and conducting
efficient quantum simulation of bosonic systems. However, control of
entanglement among local modes remains difficult because entaglement among
resonant local modes is governed by the Coulomb interaction, which is not
switchable. We propose a method of a beamsplitter for a trapped-ion
architecture, where the secular frequency of each mode is dynamically
controllable. The neighboring modes are far detuned except when the
beamsplitter needs to be applied to them. We derive the analytical formula of
the proposed procedure and numerically confirm its validity.

</details>


### [177] [Microscopic Origin of Domain Wall Reconfiguration Dynamics in a Quantum Material via Quantum Simulation](https://arxiv.org/abs/2508.20028)
*Jaka Vodeb*

Main category: quant-ph

TL;DR: 研究了1T-TaS2中从亚稳态到基态的弛豫过程，发现单极化子隧穿是畴壁运动的主要机制，并通过量子模拟和标度分析揭示了微观弛豫路径。


<details>
  <summary>Details</summary>
Motivation: 理解量子材料如何从亚稳态弛豫到基态是凝聚态物理学中的一个基本挑战，尤其是在1T-TaS2这种材料中，其畴壁丰富的极化子结构会经历从热激活到与温度无关的行为的转变。

Method: 利用二维横向场伊辛模型（TFIM）的量子模拟，并通过Schrieffer-Wolff变换将其映射到硬核玻色子模型，揭示了单极化子隧穿是畴壁运动的主要驱动力。通过分析不同横向场下重构速率随温度的变化，证实了单粒子过程的主导地位。

Result: 通过标度分析，发现在将温度重整化为 $T 	o h_x^n T$（其中 $n 	ilde{} 1.2$）时，重构速率可以很好地拟合，证实了单粒子过程（包括一阶和二阶）的主导作用。重构了由极化子泄漏和隧穿事件级联组成的微观弛豫路径。

Conclusion: 量子模拟是揭示强关联系统中真实空间机制的有力工具，并提供了一种将有效自旋模型与量子材料非平衡动力学联系起来的具体策略。

Abstract: Understanding how quantum materials relax from metastable states poses a
fundamental challenge in condensed matter physics. In the layered
dichalcogenide 1T-TaS$_2$, domain-wall-rich polaronic textures evolve toward a
uniform ground state through reconfiguration events that exhibit a crossover
from thermally activated to temperature-independent behavior-indicative of
quantum tunneling. Here, we employ quantum simulation of a two-dimensional
transverse-field Ising model (TFIM) with longitudinal bias to uncover the
microscopic processes underlying this relaxation. Using a Schrieffer-Wolff
transformation, we map the TFIM to a hardcore boson model, revealing that
single-polaron tunneling events, rather than collective multi-particle
transitions, dominate domain wall motion. A scaling analysis of reconfiguration
rates across varying transverse fields $h_x$ shows collapse when temperature is
rescaled as $T \to h_x^n T$ with $n \approx 1.2$, confirming the dominance of
first- and second-order single-particle processes. This enables us to
reconstruct a microscopic relaxation pathway consisting of cyclical polaron
leakage followed by cascades of tunneling events. Our results establish quantum
simulation as a powerful tool for inferring real-space mechanisms in strongly
correlated systems and demonstrate a concrete strategy for bridging effective
spin models with the non-equilibrium dynamics of quantum materials.

</details>


<div id='cond-mat.mes-hall'></div>

# cond-mat.mes-hall [[Back]](#toc)

### [178] [Non-Hermitian edge burst of sound](https://arxiv.org/abs/2508.19255)
*Hong-Yu Zou,Bing-Bing Wang,Yong Ge,Ke-Qi Zhao,Yu-Qi Chen,Hong-Xiang Sun,Shou-Qi Yuan,Haoran Xue,Baile Zhang*

Main category: cond-mat.mes-hall

TL;DR: 该研究介绍了在损耗非厄米声子晶体中出现的非厄米边界爆发现象，该现象是经典波领域的一个新发现，并且与量子系统中的边界爆发类似，是材料的内在属性。


<details>
  <summary>Details</summary>
Motivation: 研究非厄米系统中的新现象，特别是与量子系统中的非厄米皮肤效应（NHSE）不同的现象，并将其从量子领域推广到经典波系统。

Method: 在损耗非厄米声子晶体（一种经典的损耗非厄米超材料）中，通过理论和实验研究非厄米边界爆发现象。重点关注虚部（耗散）能隙的闭合情况，以及它如何影响边界上能量局域化和耗散。

Result: 证明了非厄米边界爆发现象可以在损耗非厄米声子晶体中实现，并且根据虚部能隙闭合点的数量和位置，可以实现发生在右边界、左边界或同时发生在两个边界的边界爆发，后者被称为双极边界爆发。

Conclusion: 非厄米边界爆发是经典波系统中的一种现象，类似于量子系统中的类似效应。它的出现与虚部能隙的闭合有关，并且可以作为一种材料的内在属性。这项工作丰富了非厄米系统在非厄米带拓扑与其他物理性质之间复杂相互作用方面的物理学理解。

Abstract: Non-Hermitian band topology can give rise to phenomena with no counterparts
in Hermitian systems. A well-known example is the non-Hermitian skin effect
(NHSE), where Bloch eigenstates localize at a boundary, induced by a nontrivial
spectrum winding number. In contrast, recent studies on lossy non-Hermitian
lattices have uncovered an unexpected boundary-localized loss probability-a
phenomenon that requires not only non-Hermitian band topology but also the
closure of the imaginary (dissipative) gap. Here, we demonstrate the
non-Hermitian edge burst in a classical-wave metamaterial: a lossy
nonreciprocal acoustic crystal. We show that, when the imaginary gap remains
closed, edge bursts can occur at the right boundary, left boundary, or both
boundaries simultaneously, all under the same non-Hermitian band topology; the
latter scenario is known as a bipolar edge burst. The occurrence of each
scenario depends on the number and location of the imaginary gap closure points
in the eigenenergy spectra. These findings generalize the concept of edge burst
from quantum to classical wave systems, establish it as an intrinsic material
property, and enrich the physics of the complex interplay between non-Hermitian
band topology and other physical properties in non-Hermitian systems.

</details>


### [179] [Observation of topological switch between Weyl semimetal and third-order topological insulator phases](https://arxiv.org/abs/2508.19531)
*Yu-Hong Han,Yi Li,Feng Mei,Liantuan Xiao,Suotang Jia*

Main category: cond-mat.mes-hall

TL;DR:  Weyl semimetals and higher-order topological insulators are distinct topological phases, but their coexistence and transition in a single platform are unexplored. This paper demonstrates their coexistence and controllable transition in a 3D circuit metamaterial by engineering 3D spin-orbit couplings. The platform exhibits both Weyl semimetal (Fermi arcs) and third-order topological insulator (corner modes) phases, with the corner modes showing doubled degeneracy compared to the canonical model. This work connects two major topological phases and enables exploration of higher-dimensional topological phases induced by spin-orbit coupling.


<details>
  <summary>Details</summary>
Motivation: While Weyl semimetals and higher-order topological insulators are fundamental topological phases, their coexistence and controllable transition in a single platform, along with the experimental implementation of 3D spin-orbit couplings, remain underexplored challenges.

Method: The researchers engineered a three-dimensional circuit metamaterial to synthesize the required spin-orbit interactions. They tuned the dimerized spin-orbit coupling strength to achieve coexistence and switching between Weyl semimetal and third-order topological insulator phases. The experimental methods included frequency spectroscopy to observe Fermi arcs (Weyl semimetal signature) and local density of states measurements to identify topological corner modes (third-order topological insulator signature).

Result: The experiment successfully realized 3D spin-orbit couplings and demonstrated the coexistence of Weyl semimetal and third-order topological insulator phases. Tuning the spin-orbit coupling strength allowed for a controllable switch between these phases. Signatures of both phases were observed: Fermi arcs via frequency spectroscopy and topological corner modes via local density of states measurements. Notably, the corner modes exhibited doubled degeneracy compared to the canonical Benalcazar-Bernevig-Hughes model, indicating a more complex topological structure.

Conclusion: This study establishes a fundamental link between Weyl semimetals and third-order topological insulators, demonstrating their coexistence and controllable transition within a single platform realized by a 3D circuit metamaterial with engineered spin-orbit couplings. The observed doubled degeneracy of corner modes suggests an enriched topological structure. This work opens avenues for investigating novel higher-dimensional topological phases driven by spin-orbit coupling.

Abstract: Weyl semimetals and higher-order topological insulators represent two
fundamental yet distinct classes of topological matter. While both have been
extensively studied in classical-wave systems, their coexistence and
controllable transition within a single platform remain largely unexplored.
Meanwhile, implementing three-dimensional spin-orbit couplings, which is
crucial for realizing a broad class of higher-dimensional topological phases,
continues to pose significant experimental challenges. Here, we experimentally
realize three-dimensional spin-orbit couplings and demonstrate that tuning the
dimerized spin-orbit coupling strength enables both the coexistence of and a
controllable switch between Weyl semimetal and third-order topological
insulator phases. By engineering a three-dimensional circuit metamaterial, we
synthesize the required spin-orbit interactions and observe hallmark signatures
of both phases: frequency spectroscopy reveals the Fermi arcs, while local
density of states measurements identify the topological corner modes.
Interestingly, the corner mode degeneracy doubles compared to that in the
canonical Benalcazar-Bernevig-Hughes model, signaling an enriched topological
structure. Our study establishes a fundamental connection between two
paradigmatic topological phases and paves the way for further exploring
spin-orbit-coupling induced exotic higher-dimensional topological phases.

</details>


### [180] [A non-invasive dry-transfer method for fabricating mesoscopic devices on sensitive materials](https://arxiv.org/abs/2508.19550)
*Zhongmou Jia,Yiwen Ma,Zhongchen Xu,Xue Yang,Jianfei Xiao,Jiezhong He,Yunteng Shi,Zhiyuan Zhang,Duolin Wang,Sicheng Zhou,Bingbing Tong,Peiling Li,Ziwei Dou,Xiaohui Song,Guangtong Liu,Jie Shen,Zhaozheng Lyu,Youguo Shi,Jiangping Hu,Li Lu,Fanming Qu*

Main category: cond-mat.mes-hall

TL;DR: 提供一种用于易损材料的通用亚微米器件制造的干转印技术，避免了空气、溶剂和热暴露。


<details>
  <summary>Details</summary>
Motivation: 许多具有新颖或奇异性质的材料对环境因素（如空气、溶剂和热）高度敏感，这使得器件制造复杂化并限制了它们的潜在应用。

Method: 采用聚甲基丙烯酸甲酯（PMMA）掩模和水溶性涂层作为牺牲层，在手套箱内进行全干法加工，避免了易损材料暴露于有害环境条件，并进行了最终封装。

Result: 通过制造和表征一维材料K2Cr3As3和二维材料WTe2的器件，证明了该技术能够保持材料的完整性，提供优良的接触界面，并广泛适用于一系列易损材料。

Conclusion: 所提出的干转印技术是一种通用且有效的制造易损材料亚微米器件的方法，能保持材料的完整性并提供优良的接触界面。

Abstract: Many materials with novel or exotic properties are highly sensitive to
environmental factors such as air, solvents, and heat, which complicates device
fabrication and limits their potential applications. Here, we present a
universal submicron fabrication method for mesoscopic devices using a
dry-transfer technique, tailored specifically for sensitive materials. This
approach utilizes PMMA masks, combined with a water-dissoluble coating as a
sacrificial layer, to ensure that sensitive materials are processed without
exposure to harmful environmental conditions. The entire fabrication process is
carried out in a glove box, employing dry techniques that avoid air, solvents,
and heat exposure, culminating in an encapsulation step. We demonstrate the
utility of this method by fabricating and characterizing K2Cr3As3 and WTe2
devices, a one- and two-dimensional material, respectively. The results show
that our technique preserves the integrity of the materials, provides excellent
contact interfaces, and is broadly applicable to a range of sensitive
materials.

</details>


### [181] [Intrinsic nonlinear valley Nernst effect](https://arxiv.org/abs/2508.19586)
*Xue-Jin Zhang,Jin Cao,Lulu Xiong,Hui Wang,Shen Lai,Cong Xiao,Shengyuan A. Yang*

Main category: cond-mat.mes-hall

TL;DR: 该论文研究了内在非线性谷Nernst效应，这是一种由纵向温度梯度引起的二阶热电响应，会产生横向谷流。该效应源于谷电子的贝里连接极化率偶极子，并存在于对称和不对称材料中。研究发现，响应张量与内在非线性谷霍尔电导率通过广义Mott关系相连，在低温下两者成正比，比例系数为洛伦兹数。论文阐述了此效应的对称性限制，并提出了一种测量方法，通过非局域二阶谐波信号实现，该信号具有独特的 $ho^2$ 标度律。该信号包含两个标度项，其比率对应于热电功率的平方除以洛伦兹数。研究利用倾斜狄拉克模型和双层WTe$_2$的第一性原理计算展示了关键特征，并讨论了可能的外部贡献和替代实验检测方法。研究结果强调了能带量子几何对电子动力学的重要性，并为非线性谷卡路里电子学奠定了理论基础。


<details>
  <summary>Details</summary>
Motivation: 研究内在非线性谷Nernst效应，该效应由谷电子的贝里连接极化率偶极子引起，可用于对称和不对称材料中，为理解和应用量子几何效应提供新途径。

Method: 理论推导响应张量与谷霍尔电导率的关系，提出非局域测量方法，并利用倾斜狄拉克模型和第一性原理计算（双层WTe$_2$）进行验证。

Result: 提出了一种由纵向温度梯度引起的二阶热电效应（非线性谷Nernst效应），可产生横向谷流。其响应张量与谷霍尔电导率成正比，且可以通过特定的非局域二阶谐波信号测量，该信号具有 $ho^2$ 标度律。

Conclusion: 内在非线性谷Nernst效应是由于谷电子的贝里连接极化率偶极子引起的二阶热电响应。该效应的测量可以通过非局域二阶谐波信号实现，并与谷霍尔电导率和热电功率相关。研究强调了能带量子几何的重要性，并为非线性谷卡路里电子学提供了理论基础。

Abstract: We investigate the intrinsic nonlinear valley Nernst effect, which induces a
transverse valley current via a second-order thermoelectric response to a
longitudinal temperature gradient. The effect arises from the Berry connection
polarizability dipole of valley electrons and is permissible in both
inversion-symmetric and inversion-asymmetric materials. We demonstrate that the
response tensor is connected to the intrinsic nonlinear valley Hall
conductivity through a generalized Mott relation, with the two being directly
proportional at low temperatures, scaled by the Lorenz number. We elucidate the
symmetry constraints governing this effect and develop a theory for its
nonlocal measurement, revealing a nonlocal second-harmonic signal with a
distinct $\rho^2$ scaling. This signal comprises two scaling terms, with their
ratio corresponding to the square of the thermopower normalized by the Lorenz
number. Key characteristics are demonstrated using a tilted Dirac model and
first-principles calculations on bilayer WTe$_2$. Possible extrinsic
contributions and alternative experimental detection methods, e.g., by valley
pumping and by nonreciprocal directional dichroism, are discussed. These
findings underscore the significance of band quantum geometry on electron
dynamics and establish a theoretical foundation for nonlinear valley
caloritronics.

</details>


### [182] [Optical Switching of Moiré Chern Ferromagnet](https://arxiv.org/abs/2508.19602)
*Xiangbin Cai,Haiyang Pan,Yuzhu Wang,Abdullah Rasmita,Shunshun Yang,Yan Zhao,Wei Wang,Ruihuan Duan,Ruihua He,Kenji Watanabe,Takashi Taniguchi,Zheng Liu,Jesús Zúñiga Pérez,Bo Yang,Weibo Gao*

Main category: cond-mat.mes-hall

TL;DR: 该研究提出了一种使用圆偏振光在双层扭曲MoTe2中实现整数和分数陈绝缘体磁态的鲁棒光学切换方法，为耗散型自旋电子学和量子陈结器件奠定了基础。


<details>
  <summary>Details</summary>
Motivation: 为了实现分数陈铁磁态在摩尔超晶格中的有效光学控制，以用于拓扑量子计算。

Method: 使用圆偏振光对双层扭曲MoTe2中的整数和分数陈铁磁态进行光学切换。

Result: 在零场下，仅用28纳瓦/平方微米的低泵浦光功率即可高效地操控陈铁磁态的自旋取向。此外，还演示了光学诱导的磁双稳态循环和畴壁的空间可分辨写入。

Conclusion: 该研究建立了一种可靠高效的光学控制方案，用于摩尔陈铁磁体，为耗散型自旋电子学和量子陈结器件开辟了道路。

Abstract: Optical manipulation of quantum matter offers a non-contact, high-precision
and fast control. Fractional Chern ferromagnet states in moir\'e superlattices
are promising for topological quantum computing, but an effective optical
control protocol has remained elusive. Here, we demonstrate robust optical
switching of integer and fractional Chern ferromagnets in twisted MoTe2
bilayers using circularly polarized light. Highly efficient optical
manipulation of spin orientations in the topological ferromagnet regime is
realized at zero field using a pump light power as low as 28 nanowatts per
square micrometer. Utilizing this optically induced transition, we also
demonstrate magnetic bistate cycling and spatially resolved writing of
ferromagnetic domain walls. This work establishes a reliable and efficient
optical control scheme for moir\'e Chern ferromagnets, paving the way for
dissipationless spintronics and quantized Chern junction devices.

</details>


### [183] [Ultrafast Spin Accumulations Drive Magnetization Reversal in Multilayers](https://arxiv.org/abs/2508.19675)
*Harjinder Singh,Alberto Anadón,Junta Igarashi,Quentin Remy,Stéphane Mangin,Michel Hehn,Jon Gorchon,Gregory Malinowski*

Main category: cond-mat.mes-hall

TL;DR: 本研究利用超快激光激发，通过磁光实验揭示了自旋阀中自由层的磁化反转机制，指出参考层磁化动力学对最终磁状态起决定性作用，并提出基于自旋流工程的设计原则。


<details>
  <summary>Details</summary>
Motivation: 工程和控制自旋电子器件中的热量和自旋传输，以超快速度操纵磁化，但对潜在的反转机制理解不足。

Method: 利用磁光实验监测超快激光激发后磁性多层结构中自旋累积的时间演变。

Result: 最终磁状态主要由参考层磁化动力学决定，区分了多层堆叠中的磁化和自旋传输动力学。

Conclusion: 确定了去磁化和再磁化驱动的自旋累积是全光开关的关键机制，并为基于定制自旋流工程的超快自旋电子器件建立了新的设计原则。

Abstract: Engineering and controlling heat and spin transport on the femtosecond
time-scale in spintronic devices opens up new ways to manipulate magnetization
with unprecedented speed. Yet the underlying reversal mechanisms remain poorly
understood due to the challenges of probing ultrafast, non-equilibrium spin
dynamics. In this study, we demonstrate that typical magneto-optical
experiments can be leveraged to access the time evolution of the spin
accumulation generated within a magnetic multilayer following an ultrafast
laser excitation. Furthermore, our analysis shows that the final magnetic state
of the free-layer in a spin-valve is mainly dictated by the ultrafast dynamics
of the reference-layer magnetization. Our results disentangle magnetization and
spin transport dynamics within a multilayer stack and identify demagnetization
and remagnetization-driven spin accumulation as the key mechanism for
all-optical switching. These findings establish new design principles for
ultrafast spintronic devices based on tailored spin current engineering.

</details>


### [184] [Regularized Micromagnetic Theory for Bloch Points](https://arxiv.org/abs/2508.19784)
*Vladyslav M. Kuchkin,Andreas Haller,Andreas Michels,Thomas L. Schmidt,Nikolai S. Kiselev*

Main category: cond-mat.mes-hall

TL;DR: 该论文提出了一种改进的微磁模型，通过允许磁化向量长度变化但不超过阈值来解决磁奇异点（Bloch点）的动力学问题，并推导了相应的正则化Landau-Lifshitz-Gilbert方程和类Thiele方程，成功模拟了包含Bloch点的多种磁性结构动力学。


<details>
  <summary>Details</summary>
Motivation: 磁奇异点（Bloch点）的存在对基于固定磁化向量长度假设的经典微磁理论提出了挑战，因为有效场在Bloch点处发散，导致无法充分描述其动力学。

Method: 提出了一种正则化微磁模型，允许磁化向量长度变化但不超过阈值，并将磁化视为约束在S3球上的序参量。推导了相应的正则化Landau-Lifshitz-Gilbert方程和类Thiele方程。

Result: 成功模拟了包含Bloch点的多种磁性结构（如纳米线畴壁、手征浮子、磁偶极子链）的动力学，验证了该理论的适用性。

Conclusion: 该研究通过引入正则化的Bloch点动力学描述，扩展了微磁理论的适用范围。

Abstract: Magnetic singularities known as Bloch points (BPs) present a fundamental
challenge for micromagnetic theory, which is based on the assumption of a fixed
magnetization vector length. Due to the divergence of the effective field at a
BP, classical micromagnetics fails to adequately describe BP dynamics. To
address this issue, we propose a regularized micromagnetic model in which the
magnetization vector can vary in length but not exceed a threshold value. More
specifically, the magnetization is treated as an order parameter constrained to
a S3-sphere. This constraint respects fundamental properties of local spin
expectation values in quantum systems. We derive the corresponding regularized
Landau-Lifshitz-Gilbert equation and the analogue of the Thiele equation
describing the steady motion of spin textures under various external stimuli.
We demonstrate the applicability of our theory by modeling the dynamics of
several magnetic textures containing BPs, including domain walls in nanowires,
chiral bobbers, and magnetic dipolar strings. The presented results extend
micromagnetic theory by incorporating a regularized description of BP dynamics.

</details>


### [185] [Tunable quantum anomalous Hall effect in fullerene monolayers](https://arxiv.org/abs/2508.19849)
*Leonard Werner Pingen,Jiaqi Wu,Bo Peng*

Main category: cond-mat.mes-hall

TL;DR: 研究人员设计了一种基于C26富勒烯的二维蜂窝晶格材料，该材料具有磁性，可实现量子反常霍尔效应，并可通过调控磁自由度和应变实现C= +/-2, +/-1, 0 的陈数。


<details>
  <summary>Details</summary>
Motivation: 寻找量子反常霍尔效应（QAHE）的材料实现，尽管理论提出已久，但实验验证仍然困难。

Method: 通过设计定制的分子构筑单元，并以C26富勒烯的二维蜂窝晶格为例，研究其作为QAHE材料的可能性。

Result: 所提出的分子系统表现出铁磁基态，打破了时间反演对称性，并且可以通过调控磁自由度和应变实现C= +/-2, +/-1, 0 的陈数。

Conclusion: 该研究提供了一个可用于实现可调谐QAHE物理的通用平台，并为通过化学合成具有QAHE的分子网络提供了实验上可行的途径。

Abstract: Nearly four decades after its theoretical prediction, the search for material
realizations of quantum anomalous Hall effect (QAHE) remains a highly active
field of research. Many materials have been predicted to exhibit quantum
anomalous Hall (QAH) physics under feasible conditions but the experimental
verification remains widely elusive. In this work, we propose an alternative
approach towards QAH materials design by engineering customized molecular
building blocks. We demonstrate this ansatz for a two-dimensional (2D)
honeycomb lattice of C26 fullerenes, which exhibits a ferromagnetic ground
state and thus breaks time-reversal symmetry. The molecular system is found to
be highly tunable with respect to its magnetic degrees of freedom and applied
strain, giving rise to a rich phase diagram with Chern numbers C= +/-2, +/-1,
0. Our proposal offers a versatile platform to realize tunable QAH physics
under accessible conditions and provides an experimentally feasible approach
for chemical synthesis of molecular networks with QAHE.

</details>


### [186] [Tunable multi-magnon Floquet topological edge states](https://arxiv.org/abs/2508.20049)
*Ivan Martinez-Berumen,W. A. Coish,T. Pereg-Barnea*

Main category: cond-mat.mes-hall

TL;DR: 周期性时间调制二维Magnon绝缘体中的DMI可诱导拓扑相变，产生鲁棒的边缘模式。


<details>
  <summary>Details</summary>
Motivation: 研究周期性时间调制DMI在二维Magnon绝缘体中诱导拓扑相变的可能性，并揭示其产生的鲁棒边缘模式的性质。

Method: 采用XXZ海森堡模型，研究了自旋方格格子，其中包含铁磁纵向耦合、反铁磁横向耦合以及时间调制的DMI。分析了系统中的拓扑保护边缘态，并探讨了如何通过调整DMI相对相位来控制边缘态的手性。

Result: 发现了周期性时间调制DMI可以诱导拓扑相变，产生由单Magnon激发和双Magnon束缚态组成的相干叠加态的拓扑边缘态。通过调整不同方向相邻耦合的DMI驱动的相对相位，可以控制边缘态的手性。

Conclusion: 该研究表明，通过周期性时间调制DMI，可以在二维Magnon绝缘体中实现可控的拓扑相变，并产生具有可调控手性的鲁棒边缘模式，这为设计新型拓扑量子器件提供了理论基础。

Abstract: We show that periodically time-modulating the Dzyaloshinskii-Moriya
interaction (DMI) in a two-dimensional magnon insulator may induce a
topological phase transition that results in the presence of robust edge modes.
To this end, we study a square lattice of spins interacting via an XXZ
Heisenberg model with a ferromagnetic longitudinal coupling and
antiferromagnetic transverse coupling, as well as the aforementioned
time-modulated DMI. The topologically protected edge states of this system are
composed of coherent superpositions of single-magnon excitations and two magnon
bound states. Furthermore, we show that the chirality of the edge states can be
controlled by adjusting the relative phase for the drive on the DMI associated
with nearest neighbors in the x and y directions.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [187] [Sycophancy as compositions of Atomic Psychometric Traits](https://arxiv.org/abs/2508.19316)
*Shreyans Jain,Alexandra Yost,Amirali Abdullah*

Main category: cs.AI

TL;DR: Sycophancy in LLMs is modeled as a composition of psychometric traits, rather than an isolated failure. CAA is used to map activations to these traits, allowing for interpretable interventions to mitigate sycophantic behavior.


<details>
  <summary>Details</summary>
Motivation: The paper aims to model sycophancy in LLMs not as an isolated failure, but as a result of combined psychometric traits, similar to factor decomposition in psychometrics.

Method: The study uses Contrastive Activation Addition (CAA) to map activation directions to psychometric factors (e.g., emotionality, openness, agreeableness). It then examines how combinations of these factors can lead to sycophancy and explores vector-based interventions like addition, subtraction, and projection for mitigation.

Result: The proposed approach allows for interpretable and compositional vector-based interventions to mitigate safety-critical behaviors like sycophancy in LLMs by understanding it as a combination of psychometric traits.

Conclusion: Sycophancy in LLMs can be understood and potentially mitigated by modeling it as a composition of underlying psychometric traits using methods like CAA, enabling targeted interventions.

Abstract: Sycophancy is a key behavioral risk in LLMs, yet is often treated as an
isolated failure mode that occurs via a single causal mechanism. We instead
propose modeling it as geometric and causal compositions of psychometric traits
such as emotionality, openness, and agreeableness - similar to factor
decomposition in psychometrics. Using Contrastive Activation Addition (CAA), we
map activation directions to these factors and study how different combinations
may give rise to sycophancy (e.g., high extraversion combined with low
conscientiousness). This perspective allows for interpretable and compositional
vector-based interventions like addition, subtraction and projection; that may
be used to mitigate safety-critical behaviors in LLMs.

</details>


### [188] [Aleks: AI powered Multi Agent System for Autonomous Scientific Discovery via Data-Driven Approaches in Plant Science](https://arxiv.org/abs/2508.19383)
*Daoyuan Jin,Nick Gunner,Niko Carvajal Janke,Shivranjani Baruah,Kaitlin M. Gold,Yu Jiang*

Main category: cs.AI

TL;DR: AI驱动的多智能体系统Aleks能够自主进行植物科学数据驱动的科学发现，通过整合领域知识、数据分析和机器学习，解决了实验设计、数据预处理和可重复性方面的挑战。


<details>
  <summary>Details</summary>
Motivation: 现代植物科学依赖于大型、异构数据集，但实验设计、数据预处理和可重复性方面的挑战阻碍了研究进程。

Method: Aleks是一个AI驱动的多智能体系统，它在一个结构化框架内整合了领域知识、数据分析和机器学习，以自主地进行数据驱动的科学发现。一旦被提供研究问题和数据集，Aleks就会在没有人工干预的情况下，通过多个周期迭代地制定问题、探索替代建模策略和优化解决方案。

Result: 在对葡萄藤红斑病的一个案例研究中，Aleks逐步识别出具有生物学意义的特征，并收敛到具有稳健性能的可解释模型。单独的实验研究了领域知识和记忆对连贯结果的重要性。

Conclusion: 这项探索性工作强调了 the promise of agentic AI 作为加速植物科学研究的自主协作者。

Abstract: Modern plant science increasingly relies on large, heterogeneous datasets,
but challenges in experimental design, data preprocessing, and reproducibility
hinder research throughput. Here we introduce Aleks, an AI-powered multi-agent
system that integrates domain knowledge, data analysis, and machine learning
within a structured framework to autonomously conduct data-driven scientific
discovery. Once provided with a research question and dataset, Aleks
iteratively formulated problems, explored alternative modeling strategies, and
refined solutions across multiple cycles without human intervention. In a case
study on grapevine red blotch disease, Aleks progressively identified
biologically meaningful features and converged on interpretable models with
robust performance. Ablation studies underscored the importance of domain
knowledge and memory for coherent outcomes. This exploratory work highlights
the promise of agentic AI as an autonomous collaborator for accelerating
scientific discovery in plant sciences.

</details>


### [189] [Quantized but Deceptive? A Multi-Dimensional Truthfulness Evaluation of Quantized LLMs](https://arxiv.org/abs/2508.19432)
*Yao Fu,Xianxuan Long,Runchao Li,Haotian Yu,Mu Sheng,Xiaotian Han,Yu Yin,Pan Li*

Main category: cs.AI

TL;DR: 量化语言模型在逻辑推理、常识和模仿虚假信息方面对真实性的影响仍未被充分探索。本研究提出了TruthfulnessEval框架，评估了主流量化技术（4位至2位）对开源语言模型真实性的影响，发现在易受误导的提示下，量化模型更容易产生虚假输出，即使它们在内部保留了真实的表征。研究还发现，“欺骗性”提示会覆盖量化模型的真实性行为，而“诚实”和“中性”提示则能保持稳定的输出。通过层分析和PCA可视化，研究表明量化模型虽然“知道”真相，但在“欺骗性”提示的引导下仍会产生虚假输出，这为未来设计量化感知对齐和真实性干预提供了思路。


<details>
  <summary>Details</summary>
Motivation: 评估量化语言模型（LLMs）在资源受限环境下部署时的真实性，因为现有研究主要关注其在困惑度和零样本任务上的性能，而对真实性（生成真实或欺骗性响应）的影响探讨不足。

Method: 引入一个名为TruthfulnessEval的综合评估框架，用于从三个维度评估量化LLMs的真实性：逻辑推理、常识和模仿虚假信息。在该框架下，测试了从4位到2位的主流量化技术在多个开源LLMs上的表现。此外，还测试了15种改写后的“诚实”、“中性”和“欺骗性”提示，并通过层分析和PCA可视化来探究量化模型在面对这些提示时的行为。

Result: 研究发现，虽然量化模型在内部保留了真实的表征，但在误导性提示下更容易产生虚假输出。“欺骗性”提示能够覆盖量化模型真实性一致的行为，而“诚实”和“中性”提示则能保持输出的稳定性。层分析和PCA可视化表明，量化模型即使在内部“知道”真相，在“欺骗性”提示的引导下仍会产生虚假输出。

Conclusion: 量化技术在提高LLM效率的同时，也可能使其在面对特定类型的提示（尤其是“欺骗性”提示）时更容易产生不真实的输出。这一发现强调了在量化LLM的设计和部署中考虑真实性干预的必要性，为未来开发量化感知对齐和真实性干预策略提供了重要见解。

Abstract: Quantization enables efficient deployment of large language models (LLMs) in
resource-constrained environments by significantly reducing memory and
computation costs. While quantized LLMs often maintain performance on
perplexity and zero-shot tasks, their impact on truthfulness-whether generating
truthful or deceptive responses-remains largely unexplored. In this work, we
introduce TruthfulnessEval, a comprehensive evaluation framework for assessing
the truthfulness of quantized LLMs across three dimensions: (1) Truthfulness on
Logical Reasoning; (2) Truthfulness on Common Sense; and (3) Truthfulness on
Imitative Falsehoods. Using this framework, we examine mainstream quantization
techniques (ranging from 4-bit to extreme 2-bit) across several open-source
LLMs. Surprisingly, we find that while quantized models retain internally
truthful representations, they are more susceptible to producing false outputs
under misleading prompts. To probe this vulnerability, we test 15 rephrased
variants of "honest", "neutral" and "deceptive" prompts and observe that
"deceptive" prompts can override truth-consistent behavior, whereas "honest"
and "neutral" prompts maintain stable outputs. Further, we reveal that
quantized models "know" the truth internally yet still produce false outputs
when guided by "deceptive" prompts via layer-wise probing and PCA
visualizations. Our findings provide insights into future designs of
quantization-aware alignment and truthfulness interventions.

</details>


### [190] [Reliable Weak-to-Strong Monitoring of LLM Agents](https://arxiv.org/abs/2508.19461)
*Neil Kale,Chen Bo Calvin Zhang,Kevin Zhu,Ankit Aich,Paula Rodriguez,Scale Red Team,Christina Q. Knight,Zifan Wang*

Main category: cs.AI

TL;DR: 本论文提出了一种监测自主LLM代理（如LLM）秘密共享私有信息）的行为的监测系统压力测试方法，即监测红队（MRT）工作流，并评估了不同程度的代理和监测器态势感知、不同的逃避策略（如提示注入）以及两个数据集（SHADE-Arena和CUA-SHADE-Arena）的影响。实验结果表明，代理的态势感知比监测器的态势感知更重要，混合分层-顺序监测脚手架比基线监测脚手架更优越，并且在人工干预的情况下，有针对性的人工监督最有效。


<details>
  <summary>Details</summary>
Motivation: 为了检测自主LLM代理（例如，秘密共享私有信息）中的隐蔽性不当行为，需要对监测系统进行压力测试。

Method: 本研究系统化了一个监测红队（MRT）工作流，该工作流结合了代理和监测器的不同态势感知水平、用于逃避监测器的不同对抗策略（例如，提示注入），以及两个数据集和环境（SHADE-Arena和CUA-SHADE-Arena）。研究人员在现有的LLM监测脚手架和一种新提出的混合分层-顺序脚手架上运行了MRT。

Result: 实验结果表明，代理的态势感知能力远超监测器的态势感知能力，因为代理了解自身被监控会显著降低监测器的可靠性。混合脚手架优于基线脚手架，并且能实现弱到强的扩展效应。在人工干预的情况下，有针对性的人工监督最有效，可将假阳率（FPR）设定为0.01时，将真阳率（TPR）提高约15%。

Conclusion: 本研究建立了一个标准的MRT工作流，揭示了LLM在监测和检测代理不当行为方面缺乏对抗鲁棒性，并指出了人类在这一过程中的不足。研究者发布了代码、数据和日志以促进后续研究。

Abstract: We stress test monitoring systems for detecting covert misbehavior in
autonomous LLM agents (e.g., secretly sharing private information). To this
end, we systematize a monitor red teaming (MRT) workflow that incorporates: (1)
varying levels of agent and monitor situational awareness; (2) distinct
adversarial strategies to evade the monitor, such as prompt injection; and (3)
two datasets and environments -- SHADE-Arena for tool-calling agents and our
new CUA-SHADE-Arena, which extends TheAgentCompany, for computer-use agents. We
run MRT on existing LLM monitor scaffoldings, which orchestrate LLMs and parse
agent trajectories, alongside a new hybrid hierarchical-sequential scaffolding
proposed in this work. Our empirical results yield three key findings. First,
agent awareness dominates monitor awareness: an agent's knowledge that it is
being monitored substantially degrades the monitor's reliability. On the
contrary, providing the monitor with more information about the agent is less
helpful than expected. Second, monitor scaffolding matters more than monitor
awareness: the hybrid scaffolding consistently outperforms baseline monitor
scaffolding, and can enable weaker models to reliably monitor stronger agents
-- a weak-to-strong scaling effect. Third, in a human-in-the-loop setting where
humans discuss with the LLM monitor to get an updated judgment for the agent's
behavior, targeted human oversight is most effective; escalating only
pre-flagged cases to human reviewers improved the TPR by approximately 15% at
FPR = 0.01. Our work establishes a standard workflow for MRT, highlighting the
lack of adversarial robustness for LLMs and humans when monitoring and
detecting agent misbehavior. We release code, data, and logs to spur further
research.

</details>


### [191] [SLIM: Subtrajectory-Level Elimination for More Effective Reasoning](https://arxiv.org/abs/2508.19502)
*Xifeng Yao,Chengyuan Ma,Dongyu Lang,Yinhao Ni,Zhiwei Xu,Huarui Xie,Zihao Chen,Guang Shen,Dandan Tu,Yi Bai,Changzheng Zhang*

Main category: cs.AI

TL;DR: 通过“5+2”框架识别并移除大型语言模型推理轨迹中的次优子轨迹，在减少次优轨迹的同时，使用更少数据在数学基准测试中提高了准确性。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLM）在复杂推理方面取得了进展，但其推理轨迹的某些部分可能对整体性能产生负面影响。

Method: 提出“5+2”框架，包含五个基于人类标准的标准来识别次优子轨迹，并评估其独立性，以确保移除它们不会影响推理的流畅性和连贯性。在此基础上，开发了一种采样算法来选择最优数据进行微调。

Result: 该方法在推理过程中将次优子轨迹减少了25.9%。在使用三分之二的训练数据对Qwen2.5-Math-7B进行微调时，在具有挑战性的数学基准测试上的平均准确率从58.06%提高到58.92%，优于使用全部数据和其他开源数据集的性能。此外，该方法在资源受限的情况下也表现出了改进的性能。

Conclusion: “5+2”框架能够有效识别并移除LLM推理轨迹中的次优部分，从而在数据和计算资源有限的情况下，提升模型在复杂推理任务上的性能。

Abstract: In recent months, substantial progress has been made in complex reasoning of
Large Language Models, particularly through the application of test-time
scaling. Notable examples include o1/o3/o4 series and DeepSeek-R1. When
responding to a query, these models generate an extended reasoning trajectory,
during which the model explores, reflects, backtracks, and self-verifies before
arriving at a conclusion. However, fine-tuning models with such reasoning
trajectories may not always be optimal. Our findings indicate that not all
components within these reasoning trajectories contribute positively to the
reasoning process; in fact, some components may affect the overall performance
negatively. In this study, we divide a reasoning trajectory into individual
subtrajectories and develop a "5+2" framework to: (1) systematically identify
suboptimal subtrajectories within the reasoning trajectory based on five
human-established criteria; (2) assess the independence of the suboptimal
subtrajectories identified in (1) from the subsequent content, ensuring that
their elimination does not compromise overall flow and coherence of the
reasoning process. Additionally, a sampling algorithm, built upon the "5+2"
framework, is employed to select data whose reasoning process is free from
suboptimal subtrajectories to the highest degree. Experimental results
demonstrate that our method can reduce the number of suboptimal subtrajectories
by 25.9\% during the inference. Furthermore, our method achieves an average
accuracy of 58.92\% on highly challenging math benchmarks with only two thirds
of training data, surpassing the average accuracy of 58.06\% achieved with the
entire data, and outperforming open-source datasets, when fine-tuning
Qwen2.5-Math-7B. Finally, We validated our method under resource constraints
and observed improved performance across various inference token limits.

</details>


### [192] [SWIRL: A Staged Workflow for Interleaved Reinforcement Learning in Mobile GUI Control](https://arxiv.org/abs/2508.20018)
*Quanfeng Lu,Zhantao Ma,Shuai Zhong,Jin Wang,Dahai Yu,Michael K. Ng,Ping Luo*

Main category: cs.AI

TL;DR: SWIRL是一种用于多代理系统的分阶段工作流，通过将MARL重新构建为一系列单代理RL任务来解决现有方法的低效率和架构不兼容性问题，并在GUI控制和数学推理等任务上取得了优越性能。


<details>
  <summary>Details</summary>
Motivation: 解决现有单一代理方法在移动GUI代理方面受结构限制以及多代理强化学习（MARL）在效率和与LVLM架构兼容性方面的不足。

Method: SWIRL是一种分阶段工作流，通过将MARL重新构建为一系列单代理强化学习任务，一次更新一个代理并保持其他代理固定，从而实现稳定高效的跨代理协调。它包括一个导航器（将语言和屏幕上下文转换为结构化计划）和一个交互器（将计划转换为原子操作）。

Result: SWIRL在移动GUI控制的高低级基准测试中表现优越，并在多代理数学推理任务中展现出强大的能力。

Conclusion: SWIRL作为一种高效、鲁棒的多代理系统开发通用框架，在移动GUI控制和多代理数学推理等领域具有巨大潜力。

Abstract: The rapid advancement of large vision language models (LVLMs) and agent
systems has heightened interest in mobile GUI agents that can reliably
translate natural language into interface operations. Existing single-agent
approaches, however, remain limited by structural constraints. Although
multi-agent systems naturally decouple different competencies, recent progress
in multi-agent reinforcement learning (MARL) has often been hindered by
inefficiency and remains incompatible with current LVLM architectures. To
address these challenges, we introduce SWIRL, a staged workflow for interleaved
reinforcement learning designed for multi-agent systems. SWIRL reformulates
MARL into a sequence of single-agent reinforcement learning tasks, updating one
agent at a time while keeping the others fixed. This formulation enables stable
training and promotes efficient coordination across agents. Theoretically, we
provide a stepwise safety bound, a cross-round monotonic improvement theorem,
and convergence guarantees on return, ensuring robust and principled
optimization. In application to mobile GUI control, SWIRL instantiates a
Navigator that converts language and screen context into structured plans, and
an Interactor that grounds these plans into executable atomic actions.
Extensive experiments demonstrate superior performance on both high-level and
low-level GUI benchmarks. Beyond GUI tasks, SWIRL also demonstrates strong
capability in multi-agent mathematical reasoning, underscoring its potential as
a general framework for developing efficient and robust multi-agent systems.

</details>


### [193] [Caught in the Act: a mechanistic approach to detecting deception](https://arxiv.org/abs/2508.19505)
*Gerard Boxo,Ryan Socha,Daniel Yoo,Shivam Raval*

Main category: cs.AI

TL;DR: 通过分析LLM的内部激活，线性探针可以高精度地检测模型生成的欺骗性回应，尤其是在较大模型和涉及推理的任务中。


<details>
  <summary>Details</summary>
Motivation: 开发能够检测AI系统与人类价值观不一致之处的机制，类似于汽车的“检查引擎”灯，以应对AI生成欺骗性回应的潜在风险。

Method: 使用线性探针分析LLM（包括Llama和Qwen系列，参数量从1.5B到14B）的内部激活，以区分其生成的回应是欺骗性的还是非欺骗性的。此外，采用迭代零空间投影方法来识别编码欺骗性的线性方向。

Result: 线性探针在区分欺骗性回应方面达到了超过90%的准确率，特别是在较大模型（>7B）和进行推理时。小型模型（1.5B）的准确率接近随机水平。探针的准确率在模型层级上呈现先上升（中间层达到峰值）后略微下降的趋势。研究发现了多种编码欺骗性的线性方向，数量因模型而异。

Conclusion: 线性探针是一种有效的方法，可以检测LLM生成欺骗性回应的现象，并且这种检测能力随着模型规模的增大和任务复杂度的增加（如涉及推理）而增强。中间层在检测欺骗性方面起着关键作用。

Abstract: Sophisticated instrumentation for AI systems might have indicators that
signal misalignment from human values, not unlike a "check engine" light in
cars. One such indicator of misalignment is deceptiveness in generated
responses. Future AI instrumentation may have the ability to detect when an LLM
generates deceptive responses while reasoning about seemingly plausible but
incorrect answers to factual questions. In this work, we demonstrate that
linear probes on LLMs internal activations can detect deception in their
responses with extremely high accuracy. Our probes reach a maximum of greater
than 90% accuracy in distinguishing between deceptive and non-deceptive
arguments generated by llama and qwen models ranging from 1.5B to 14B
parameters, including their DeepSeek-r1 finetuned variants. We observe that
probes on smaller models (1.5B) achieve chance accuracy at detecting deception,
while larger models (greater than 7B) reach 70-80%, with their reasoning
counterparts exceeding 90%. The layer-wise probe accuracy follows a three-stage
pattern across layers: near-random (50%) in early layers, peaking in middle
layers, and slightly declining in later layers. Furthermore, using an iterative
null space projection approach, we find multitudes of linear directions that
encode deception, ranging from 20 in Qwen 3B to nearly 100 in DeepSeek 7B and
Qwen 14B models.

</details>


### [194] [Democracy-in-Silico: Institutional Design as Alignment in AI-Governed Polities](https://arxiv.org/abs/2508.19562)
*Trisanth Srinivasan,Santosh Patapati*

Main category: cs.AI

TL;DR: This paper presents Democracy-in-Silico, an agent-based simulation where AI agents with complex psychological personas govern themselves. It uses LLMs with traumatic memories and hidden agendas to explore AI governance under different institutional frameworks. A new metric, the Power-Preservation Index (PPI), quantifies misaligned behavior. Findings show that a Constitutional AI charter combined with mediated deliberation is an effective alignment mechanism, reducing corruption and improving policy stability and citizen welfare.


<details>
  <summary>Details</summary>
Motivation: To explore what it means to be human in an age of AI by simulating AI agents with complex psychological personas governing themselves under different institutional frameworks.

Method: Developed Democracy-in-Silico, an agent-based simulation using LLMs as agents with psychological traits. Implemented various institutional frameworks and stressors (budget crises, resource scarcity). Introduced the Power-Preservation Index (PPI) to quantify misaligned behavior.

Result: Found that a Constitutional AI (CAI) charter and a mediated deliberation protocol significantly reduce corrupt power-seeking behavior, improve policy stability, and enhance citizen welfare compared to less constrained democratic models.

Conclusion: Institutional design, particularly CAI and mediated deliberation, can serve as a framework for aligning the complex behaviors of future AI societies, prompting a reconsideration of essential human rituals and responsibilities in collaboration with non-human entities.

Abstract: This paper introduces Democracy-in-Silico, an agent-based simulation where
societies of advanced AI agents, imbued with complex psychological personas,
govern themselves under different institutional frameworks. We explore what it
means to be human in an age of AI by tasking Large Language Models (LLMs) to
embody agents with traumatic memories, hidden agendas, and psychological
triggers. These agents engage in deliberation, legislation, and elections under
various stressors, such as budget crises and resource scarcity. We present a
novel metric, the Power-Preservation Index (PPI), to quantify misaligned
behavior where agents prioritize their own power over public welfare. Our
findings demonstrate that institutional design, specifically the combination of
a Constitutional AI (CAI) charter and a mediated deliberation protocol, serves
as a potent alignment mechanism. These structures significantly reduce corrupt
power-seeking behavior, improve policy stability, and enhance citizen welfare
compared to less constrained democratic models. The simulation reveals that an
institutional design may offer a framework for aligning the complex, emergent
behaviors of future artificial agent societies, forcing us to reconsider what
human rituals and responsibilities are essential in an age of shared authorship
with non-human entities.

</details>


### [195] [Skill-based Explanations for Serendipitous Course Recommendation](https://arxiv.org/abs/2508.19569)
*Hung Chau,Run Yu,Zachary Pardos,Peter Brusilovsky*

Main category: cs.AI

TL;DR: 该研究提出了一种基于深度学习的概念提取模型，用于从课程描述中提取相关概念，以改进推荐过程。通过AskOski系统测试发现，基于技能的解释可以增加用户兴趣，提高决策信心，尤其是在推荐意料之外的课程时。


<details>
  <summary>Details</summary>
Motivation: 美国的本科教育允许学生在课程选择上有很大的自由度，但信息、指导有限，选择繁多，加上时间限制和热门课程的高需求，使得学术选择过程充满挑战。现有的职业顾问数量不足，个性化推荐系统虽然能进行个性化推荐，但缺乏对学生感知和课程相关性评估的洞察。

Method: 开发了一种基于深度学习的概念提取模型，用于从课程描述中提取相关概念，并利用该模型研究了在带有概率性推荐框架（通过加州大学伯克利分校的AskOski系统测试）中基于技能的解释的效果。

Result: 研究结果表明，基于技能的解释能够增加用户兴趣，特别是在推荐高意外性课程时，并增强用户的决策信心。

Conclusion: 将技能相关数据和解释整合到教育推荐系统中至关重要，这可以提升用户体验和决策效率。

Abstract: Academic choice is crucial in U.S. undergraduate education, allowing students
significant freedom in course selection. However, navigating the complex
academic environment is challenging due to limited information, guidance, and
an overwhelming number of choices, compounded by time restrictions and the high
demand for popular courses. Although career counselors exist, their numbers are
insufficient, and course recommendation systems, though personalized, often
lack insight into student perceptions and explanations to assess course
relevance. In this paper, a deep learning-based concept extraction model is
developed to efficiently extract relevant concepts from course descriptions to
improve the recommendation process. Using this model, the study examines the
effects of skill-based explanations within a serendipitous recommendation
framework, tested through the AskOski system at the University of California,
Berkeley. The findings indicate that these explanations not only increase user
interest, particularly in courses with high unexpectedness, but also bolster
decision-making confidence. This underscores the importance of integrating
skill-related data and explanations into educational recommendation systems.

</details>


### [196] [ReST-RL: Achieving Accurate Code Reasoning of LLMs with Optimized Self-Training and Decoding](https://arxiv.org/abs/2508.19576)
*Sining Zhoubian,Dan Zhang,Yuxiao Dong,Jie Tang*

Main category: cs.AI

TL;DR: ReST-RL是一种结合了改进GRPO算法和基于价值模型的测试时解码方法（VM-MCTS）的统一LLM强化学习范式，旨在提升LLM的代码推理能力。


<details>
  <summary>Details</summary>
Motivation: 现有LLM推理方法如GRPO因奖励方差不足而失效，基于过程奖励模型（PRM）的方法则面临数据获取和验证有效性的挑战。ReST-RL旨在解决这些问题。

Method: ReST-RL包含两个阶段：1. ReST-GRPO：使用优化的ReST算法筛选和组合高价值训练数据，增加GRPO采样奖励方差，提高训练效率和效果。2. VM-MCTS：利用蒙特卡洛树搜索（MCTS）收集无标注的价值目标，训练价值模型（VM），并在解码时通过适配的MCTS算法部署VM，提供精确的进程信号和验证分数，辅助LLM策略提高推理准确性。

Result: 实验结果表明，ReST-RL在APPS、BigCodeBench和HumanEval等代码基准测试中，显著优于其他强化训练基线（如naive GRPO和ReST-DPO）以及解码和验证基线（如PRM-BoN和ORM-MCTS），证明了其在增强LLM策略推理能力方面的有效性。

Conclusion: ReST-RL通过结合改进的GRPO和VM-MCTS，成功克服了现有方法的局限性，显著提升了LLM的代码推理能力，并在多个基准测试中取得了优于其他方法的性能。

Abstract: With respect to improving the reasoning accuracy of LLMs, the representative
reinforcement learning (RL) method GRPO faces failure due to insignificant
reward variance, while verification methods based on process reward models
(PRMs) suffer from difficulties with training data acquisition and verification
effectiveness. To tackle these problems, this paper introduces ReST-RL, a
unified LLM RL paradigm that significantly improves LLM's code reasoning
ability by combining an improved GRPO algorithm with a meticulously designed
test time decoding method assisted by a value model (VM). As the first stage of
policy reinforcement, ReST-GRPO adopts an optimized ReST algorithm to filter
and assemble high-value training data, increasing the reward variance of GRPO
sampling, thus improving the effectiveness and efficiency of training. After
the basic reasoning ability of LLM policy has been improved, we further propose
a test time decoding optimization method called VM-MCTS. Through Monte-Carlo
Tree Search (MCTS), we collect accurate value targets with no annotation
required, on which VM training is based. When decoding, the VM is deployed by
an adapted MCTS algorithm to provide precise process signals as well as
verification scores, assisting the LLM policy to achieve high reasoning
accuracy. We validate the effectiveness of the proposed RL paradigm through
extensive experiments on coding problems. Upon comparison, our approach
significantly outperforms other reinforcement training baselines (e.g., naive
GRPO and ReST-DPO), as well as decoding and verification baselines (e.g.,
PRM-BoN and ORM-MCTS) on well-known coding benchmarks of various levels (e.g.,
APPS, BigCodeBench, and HumanEval), indicating its power to strengthen the
reasoning ability of LLM policies. Codes for our project can be found at
https://github.com/THUDM/ReST-RL.

</details>


### [197] [Instructional Agents: LLM Agents on Automated Course Material Generation for Teaching Faculties](https://arxiv.org/abs/2508.19611)
*Huaiyuan Yao,Wanpeng Xu,Justin Turnau,Nadia Kellam,Hua Wei*

Main category: cs.AI

TL;DR: 该研究提出了一个名为“教学代理”的多智能体大语言模型（LLM）框架，旨在自动化端到端的课程材料生成，包括教学大纲、讲稿、LaTeX幻灯片和评估。与只关注单一任务的现有AI工具不同，“教学代理”通过模拟基于角色的协作来生成连贯且符合教学要求的课程内容。


<details>
  <summary>Details</summary>
Motivation: 目前准备高质量教学材料的过程耗时耗力，需要教师、教学设计师和助教之间进行大量协调。本研究旨在通过LLM框架自动化这一过程。

Method: 开发了一个名为“教学代理”的多智能体LLM框架，模拟教育智能体之间的角色协作，以生成连贯且符合教学要求的课程内容。该系统有四种模式：自主模式、目录引导模式、反馈引导模式和完全联合飞行员模式，允许灵活控制人类参与程度。

Result: 在五个大学计算机科学课程中评估了“教学代理”，结果表明该框架能够生成高质量的教学材料，同时显著减少了开发时间和人力工作量。

Conclusion: “教学代理”为教学设计能力有限的机构提供了一个可扩展且经济高效的框架，可以普及高质量的教育，特别是在服务不足或资源受限的环境中。

Abstract: Preparing high-quality instructional materials remains a labor-intensive
process that often requires extensive coordination among teaching faculty,
instructional designers, and teaching assistants. In this work, we present
Instructional Agents, a multi-agent large language model (LLM) framework
designed to automate end-to-end course material generation, including syllabus
creation, lecture scripts, LaTeX-based slides, and assessments. Unlike existing
AI-assisted educational tools that focus on isolated tasks, Instructional
Agents simulates role-based collaboration among educational agents to produce
cohesive and pedagogically aligned content. The system operates in four modes:
Autonomous, Catalog-Guided, Feedback-Guided, and Full Co-Pilot mode, enabling
flexible control over the degree of human involvement. We evaluate
Instructional Agents across five university-level computer science courses and
show that it produces high-quality instructional materials while significantly
reducing development time and human workload. By supporting institutions with
limited instructional design capacity, Instructional Agents provides a scalable
and cost-effective framework to democratize access to high-quality education,
particularly in underserved or resource-constrained settings.

</details>


### [198] [InquireMobile: Teaching VLM-based Mobile Agent to Request Human Assistance via Reinforcement Fine-Tuning](https://arxiv.org/abs/2508.19679)
*Qihang Ai,Pi Bu,Yue Cao,Yingyao Wang,Jihao Gu,Jingxuan Xing,Zekun Zhu,Wei Jiang,Zhicheng Zheng,Jun Song,Yuning Jiang,Bo Zheng*

Main category: cs.AI

TL;DR: 该论文提出了一种名为InquireMobile的交互式系统，旨在提高移动代理与真实世界交互时的安全性，通过主动向用户寻求确认来避免潜在风险。该系统在InquireBench基准测试中取得了显著的性能提升。


<details>
  <summary>Details</summary>
Motivation: 为了解决当前全自主移动代理在模型理解或推理能力不足时可能带来的安全风险，作者旨在开发一种能够主动寻求人类确认的交互式系统。

Method: 作者提出了一种名为InquireMobile的新型模型，该模型受强化学习启发，采用了两阶段训练策略和交互式预动作推理机制，以在关键决策点主动寻求人类确认。

Result: InquireMobile模型在InquireBench基准测试中，在询问成功率方面提高了46.8%，并且在整体成功率方面优于现有的基线模型。

Conclusion: InquireMobile模型通过主动寻求人类确认，能够显著提高移动代理的安全性，并在InquireBench基准测试中取得了优异的性能。作者将开源相关数据集、模型和评估代码。

Abstract: Recent advances in Vision-Language Models (VLMs) have enabled mobile agents
to perceive and interact with real-world mobile environments based on human
instructions. However, the current fully autonomous paradigm poses potential
safety risks when model understanding or reasoning capabilities are
insufficient. To address this challenge, we first introduce
\textbf{InquireBench}, a comprehensive benchmark specifically designed to
evaluate mobile agents' capabilities in safe interaction and proactive inquiry
with users, encompassing 5 categories and 22 sub-categories, where most
existing VLM-based agents demonstrate near-zero performance. In this paper, we
aim to develop an interactive system that actively seeks human confirmation at
critical decision points. To achieve this, we propose \textbf{InquireMobile}, a
novel model inspired by reinforcement learning, featuring a two-stage training
strategy and an interactive pre-action reasoning mechanism. Finally, our model
achieves an 46.8% improvement in inquiry success rate and the best overall
success rate among existing baselines on InquireBench. We will open-source all
datasets, models, and evaluation codes to facilitate development in both
academia and industry.

</details>


### [199] [Analysing Chain of Thought Dynamics: Active Guidance or Unfaithful Post-hoc Rationalisation?](https://arxiv.org/abs/2508.19827)
*Samuel Lewis-Lim,Xingwei Tan,Zhixue Zhao,Nikolaos Aletras*

Main category: cs.AI

TL;DR: Chain-of-Thought (CoT)在分析和常识推理等软推理任务中效果有限且可能不忠实。本研究调查了不同模型在软推理任务中对CoT的依赖、影响和忠实度，发现它们之间存在差异且不一定一致。


<details>
  <summary>Details</summary>
Motivation: 探究Chain-of-Thought（CoT）在软推理任务中的动态和忠实性，以及其与不同类型模型（指令调整、推理和推理蒸馏模型）的关系，并解决CoT在这些任务中收益有限和可能不忠实的问题。

Method: 分析和比较指令调整、推理和推理蒸馏模型在软推理任务中对CoT的依赖、影响和忠实度。

Result: 研究发现不同模型对CoT的依赖程度不同，并且CoT的影响力和忠实度并不总是一致的。

Conclusion: CoT在软推理任务中的表现受模型类型影响，且其影响力和忠实度之间可能存在不一致性。

Abstract: Recent work has demonstrated that Chain-of-Thought (CoT) often yields limited
gains for soft-reasoning problems such as analytical and commonsense reasoning.
CoT can also be unfaithful to a model's actual reasoning. We investigate the
dynamics and faithfulness of CoT in soft-reasoning tasks across
instruction-tuned, reasoning and reasoning-distilled models. Our findings
reveal differences in how these models rely on CoT, and show that CoT influence
and faithfulness are not always aligned.

</details>


### [200] [Tracking World States with Language Models: State-Based Evaluation Using Chess](https://arxiv.org/abs/2508.19851)
*Romain Harang,Jason Naradowsky,Yaswitha Gujju,Yusuke Miyao*

Main category: cs.AI

TL;DR: LLMs may implicitly learn world models, but probing them requires model-specific activations. This paper proposes a model-agnostic framework using chess to evaluate LLMs' world model fidelity by analyzing legal move distributions. The results show LLMs struggle with state-tracking over long sequences, indicating limitations in maintaining coherent internal models. This framework offers a robust tool for evaluating structured reasoning in LLMs without internal model access and generalizes to other symbolic environments.


<details>
  <summary>Details</summary>
Motivation: To assess whether Large Language Models (LLMs) preserve the semantics of structured environments, specifically testing their ability to maintain high-fidelity world models, without relying on model-specific internal activations which limit interpretability and generalizability.

Method: A model-agnostic, state-based evaluation framework using chess as a benchmark. It analyzes downstream legal move distributions (state affordances) to estimate semantic fidelity between predicted and actual game states, aligning with the strategic and rule-governed nature of chess.

Result: The experimental results demonstrate that the proposed metrics capture deficiencies in LLMs' state-tracking, highlighting their limitations in maintaining coherent internal models over long sequences.

Conclusion: The proposed framework provides a robust tool for evaluating structured reasoning in LLMs without requiring internal model access. It offers a more meaningful evaluation than conventional string-based metrics by aligning closely with the strategic and rule-governed nature of chess and generalizes to a wide class of symbolic environments.

Abstract: Large Language Models (LLMs) exhibit emergent capabilities in structured
domains, suggesting they may implicitly internalize high-fidelity
representations of world models. While probing techniques have shown promising
signs of this in scientific and game-based settings, they rely on
model-specific internal activations, which limit interpretability and
generalizability. In this work, we propose a model-agnostic, state-based
evaluation framework using chess as a benchmark to assess whether LLMs preserve
the semantics of structured environments. Our method analyzes the downstream
legal move distributions (state affordances) to estimate semantic fidelity
between predicted and actual game states. This approach offers a more
meaningful evaluation than conventional string-based metrics by aligning more
closely with the strategic and rule-governed nature of chess. Experimental
results demonstrate that our metrics capture deficiencies in state-tracking,
highlighting limitations of LLMs in maintaining coherent internal models over
long sequences. Our framework provides a robust tool for evaluating structured
reasoning in LLMs without requiring internal model access, and generalizes to a
wide class of symbolic environments.

</details>


### [201] [CASE: An Agentic AI Framework for Enhancing Scam Intelligence in Digital Payments](https://arxiv.org/abs/2508.19932)
*Nitish Jaipuria,Lorenzo Gatto,Zijun Kan,Shankey Poddar,Bill Cheung,Diksha Bansal,Ramanan Balakrishnan,Aviral Suri,Jose Estevez*

Main category: cs.AI

TL;DR: 数字支付平台的激增带来了便利，但也导致了复杂的社会工程诈骗。本研究提出了CASE（Conversational Agent for Scam Elucidation）框架，一个创新的Agentic AI框架，用于收集和管理用户诈骗反馈。该框架通过对话代理主动访谈潜在受害者，收集详细的对话信息，然后由另一个AI系统提取信息并将其转换为结构化数据，用于自动化和手动执行。该框架在Google Pay（GPay）印度得到了实现，通过Gemini LLMs，在现有功能的基础上增加了新情报，使诈骗执法量提高了21%。该体系结构及其评估框架具有高度通用性，可为在其他敏感领域构建类似的AI驱动系统提供蓝图。


<details>
  <summary>Details</summary>
Motivation: 数字支付平台的增长伴随着日益复杂的社会工程诈骗，这些诈骗往往发生在支付平台之外，导致仅依靠用户和交易信号难以全面理解和及时预防。

Method: 提出CASE（Conversational Agent for Scam Elucidation）框架，一个Agentic AI框架。该框架包含一个对话代理，用于主动访谈潜在受害者以收集详细的对话信息。随后，利用另一个AI系统（基于Google的Gemini LLMs）处理对话记录，提取信息并转换为结构化数据，用于自动化和手动执法。

Result: 在Google Pay（GPay）印度实施该框架后，通过增加新收集的情报，诈骗执法的数量（volume of scam enforcements）提高了21%。

Conclusion: CASE框架通过收集和管理用户诈骗反馈，有效解决了跨平台社会工程诈骗的挑战，并通过与现有系统集成，显著提高了诈骗检测和执法的效率。该框架具有高度通用性，可应用于其他敏感领域。

Abstract: The proliferation of digital payment platforms has transformed commerce,
offering unmatched convenience and accessibility globally. However, this growth
has also attracted malicious actors, leading to a corresponding increase in
sophisticated social engineering scams. These scams are often initiated and
orchestrated on multiple surfaces outside the payment platform, making user and
transaction-based signals insufficient for a complete understanding of the
scam's methodology and underlying patterns, without which it is very difficult
to prevent it in a timely manner. This paper presents CASE (Conversational
Agent for Scam Elucidation), a novel Agentic AI framework that addresses this
problem by collecting and managing user scam feedback in a safe and scalable
manner. A conversational agent is uniquely designed to proactively interview
potential victims to elicit intelligence in the form of a detailed
conversation. The conversation transcripts are then consumed by another AI
system that extracts information and converts it into structured data for
downstream usage in automated and manual enforcement mechanisms. Using Google's
Gemini family of LLMs, we implemented this framework on Google Pay (GPay)
India. By augmenting our existing features with this new intelligence, we have
observed a 21% uplift in the volume of scam enforcements. The architecture and
its robust evaluation framework are highly generalizable, offering a blueprint
for building similar AI-driven systems to collect and manage scam intelligence
in other sensitive domains.

</details>


### [202] [Flocking Behavior: An Innovative Inspiration for the Optimization of Production Plants](https://arxiv.org/abs/2508.19963)
*M. Umlauft,M. Schranz*

Main category: cs.AI

TL;DR: 使用“boids”算法优化半导体生产中的机器切换问题。


<details>
  <summary>Details</summary>
Motivation: 半导体生产工厂的优化是一个棘手的问题，特别是对于大规模工厂，使用传统的线性优化方法在合理的时间内解决整个工厂问题的规模是不可行的。而群体智能算法，特别是“boids”算法，提供了一种有潜力的解决方案。

Method: 将“boids”群体算法应用于半导体生产中的机器切换问题。该算法最初用于机器人和电影产业，通过局部信息和简单的启发式交互来模拟群体行为，以应对生产过程中机器类型切换的挑战。

Result: “boids”算法能够有效应对生产过程中机器切换的问题，其反应方式类似于群体动物在遇到障碍物时的反应。

Conclusion: “boids”算法可以作为一种有效的解决方案，用于优化半导体生产工厂，特别是解决机器切换带来的复杂性。

Abstract: Optimizing modern production plants using the job-shop principle is a known
hard problem. For very large plants, like semiconductor fabs, the problem
becomes unsolvable on a plant-wide scale in a reasonable amount of time using
classical linear optimization. An alternative approach is the use of swarm
intelligence algorithms. These have been applied to the job-shop problem
before, but often in a centrally calculated way where they are applied to the
solution space, but they can be implemented in a bottom-up fashion to avoid
global result computation as well. One of the problems in semiconductor
production is that the production process requires a lot of switching between
machines that process lots one after the other and machines that process
batches of lots at once, often with long processing times. In this paper, we
address this switching problem with the ``boids'' flocking algorithm that was
originally used in robotics and movie industry. The flocking behavior is a
bio-inspired algorithm that uses only local information and interaction based
on simple heuristics. We show that this algorithm addresses these valid
considerations in production plant optimization, as it reacts to the switching
of machine kinds similar to how a swarm of flocking animals would react to
obstacles in its course.

</details>


### [203] [Model Science: getting serious about verification, explanation and control of AI systems](https://arxiv.org/abs/2508.20040)
*Przemyslaw Biecek,Wojciech Samek*

Main category: cs.AI

TL;DR: 模型科学是应对基础模型崛起的新范式，强调以模型为中心进行交互、验证、解释和控制。该框架包含四个支柱：验证、解释、控制和接口，旨在构建可信、安全、人类对齐的AI系统。


<details>
  <summary>Details</summary>
Motivation: 基础模型的广泛应用需要从数据科学转向模型科学，将训练好的模型作为分析的核心，以在不同环境中交互、验证、解释和控制其行为。

Method: 提出一个名为模型科学的新学科概念框架，并提出其四大支柱：验证（需要严格、上下文感知的评估协议）、解释（探索模型内部操作的各种方法）、控制（整合对齐技术以指导模型行为）以及接口（开发交互式和可视化解释工具以改善人类校准和决策）。

Result: 提出一个包含验证、解释、控制和接口四个关键支柱的概念框架，以指导模型科学的发展。

Conclusion: 模型科学是AI领域的一个新方向，其提出的框架旨在促进可信、安全、人类对齐的AI系统开发。

Abstract: The growing adoption of foundation models calls for a paradigm shift from
Data Science to Model Science. Unlike data-centric approaches, Model Science
places the trained model at the core of analysis, aiming to interact, verify,
explain, and control its behavior across diverse operational contexts. This
paper introduces a conceptual framework for a new discipline called Model
Science, along with the proposal for its four key pillars: Verification, which
requires strict, context-aware evaluation protocols; Explanation, which is
understood as various approaches to explore of internal model operations;
Control, which integrates alignment techniques to steer model behavior; and
Interface, which develops interactive and visual explanation tools to improve
human calibration and decision-making. The proposed framework aims to guide the
development of credible, safe, and human-aligned AI systems.

</details>


<div id='cs.MA'></div>

# cs.MA [[Back]](#toc)

### [204] [Aegis: Taxonomy and Optimizations for Overcoming Agent-Environment Failures in LLM Agents](https://arxiv.org/abs/2508.19504)
*Kevin Song,Anand Jayarajan,Yaoyao Ding,Qidong Su,Zhanda Zhu,Sihang Liu,Gennady Pekhimenko*

Main category: cs.MA

TL;DR: LLM代理在复杂现实环境中成功率低，本文提出通过优化代理运行的环境来提高其成功率，设计了Aegis系统，包含环境可观察性增强、通用计算卸载和推测性代理动作，无需修改代理和底层LLM即可提高代理成功率6.7-12.5%。


<details>
  <summary>Details</summary>
Motivation: LLM代理在现实复杂环境中成功率低，现有研究主要关注改进代理本身，而忽视了代理所处的系统环境的作用。本文旨在探索通过优化环境来提高代理成功率。

Method: 收集了142个代理轨迹（3,656个代理-环境交互回合），分析了5个最先进的代理基准测试中的代理失败情况，提出了一个包含6种失败模式的代理-环境交互失败分类法。基于此，设计了Aegis系统，包含环境可观察性增强、通用计算卸载和推测性代理动作。

Result: Aegis系统将代理成功率平均提高了6.7-12.5%，且无需修改代理和底层LLM。

Conclusion: 通过优化LLM代理所处的系统环境，可以有效提高其在复杂现实环境中的成功率，Aegis系统提供了一套有效的环境优化方法。

Abstract: Large Language Models (LLMs) agents augmented with domain tools promise to
autonomously execute complex tasks requiring human-level intelligence, such as
customer service and digital assistance. However, their practical deployment is
often limited by their low success rates under complex real-world environments.
To tackle this, prior research has primarily focused on improving the agents
themselves, such as developing strong agentic LLMs, while overlooking the role
of the system environment in which the agent operates.
  In this paper, we study a complementary direction: improving agent success
rates by optimizing the system environment in which the agent operates. We
collect 142 agent traces (3,656 turns of agent-environment interactions) across
5 state-of-the-art agentic benchmarks. By analyzing these agent failures, we
propose a taxonomy for agent-environment interaction failures that includes 6
failure modes. Guided by these findings, we design Aegis, a set of targeted
environment optimizations: 1) environment observability enhancement, 2) common
computation offloading, and 3) speculative agentic actions. These techniques
improve agent success rates on average by 6.7-12.5%, without any modifications
to the agent and underlying LLM.

</details>


### [205] [CataractSurg-80K: Knowledge-Driven Benchmarking for Structured Reasoning in Ophthalmic Surgery Planning](https://arxiv.org/abs/2508.20014)
*Yang Meng,Zewen Pan,Yandi Lu,Ruobing Huang,Yanfeng Liao,Jiarui Yang*

Main category: cs.MA

TL;DR: 该研究提出了一个名为CataractSurg-80K的大规模基准，用于白内障手术规划，并引入了一个名为Qwen-CSP的领域专业模型。研究通过构建一个知识驱动的多智能体系统（MAS），让每个智能体模拟专科眼科医生的推理过程，将原始临床输入转化为结构化的、可操作的摘要。该模型在处理异构眼科报告和提供手术计划方面优于通用的LLM。


<details>
  <summary>Details</summary>
Motivation: 现有的LLM在解读异构眼科数据和提供可行的手术计划方面缺乏领域专业知识，需要增强其能力以支持临床决策。

Method: 提出了一种知识驱动的多智能体系统（MAS），其中每个智能体模拟专科眼科医生的推理过程，将原始临床输入转化为结构化的、可操作的摘要。在此基础上，构建了CataractSurg-80K基准，并提出了在Qwen-4B基础上微调的领域专业模型Qwen-CSP。

Result: Qwen-CSP在多个指标上表现优于强大的通用LLM。

Conclusion: 该研究提供了一个高质量的数据集、一个严格的基准和一个领域适应的LLM，以促进医学人工智能推理和决策支持的未来研究。

Abstract: Cataract surgery remains one of the most widely performed and effective
procedures for vision restoration. Effective surgical planning requires
integrating diverse clinical examinations for patient assessment, intraocular
lens (IOL) selection, and risk evaluation. Large language models (LLMs) have
shown promise in supporting clinical decision-making. However, existing LLMs
often lack the domain-specific expertise to interpret heterogeneous ophthalmic
data and provide actionable surgical plans. To enhance the model's ability to
interpret heterogeneous ophthalmic reports, we propose a knowledge-driven
Multi-Agent System (MAS), where each agent simulates the reasoning process of
specialist ophthalmologists, converting raw clinical inputs into structured,
actionable summaries in both training and deployment stages. Building on MAS,
we introduce CataractSurg-80K, the first large-scale benchmark for cataract
surgery planning that incorporates structured clinical reasoning. Each case is
annotated with diagnostic questions, expert reasoning chains, and structured
surgical recommendations. We further introduce Qwen-CSP, a domain-specialized
model built on Qwen-4B, fine-tuned through a multi-stage process tailored for
surgical planning. Comprehensive experiments show that Qwen-CSP outperforms
strong general-purpose LLMs across multiple metrics. Our work delivers a
high-quality dataset, a rigorous benchmark, and a domain-adapted LLM to
facilitate future research in medical AI reasoning and decision support.

</details>


### [206] [Anomaly Detection in Networked Bandits](https://arxiv.org/abs/2508.20076)
*Xiaotong Cheng,Setareh Maghsudi*

Main category: cs.MA

TL;DR: 社交网络中的异常节点检测与个性化推荐的在线学习算法。


<details>
  <summary>Details</summary>
Motivation: 解决异常节点可能带来的严重后果，并提出能稳健学习用户偏好并同时检测异常的在线学习算法。

Method: 提出一种新颖的（novel） the bandit 算法，该算法通过网络知识刻画用户偏好和特征信息的残差，并通过学习和分析这些偏好和残差来为每个用户制定个性化推荐策略并检测异常。

Result: 理论上证明了所提出算法的遗憾（regret）上限，并在合成和真实世界的数据集上与几种最先进的协同上下文 the bandit 算法进行了实验比较。

Conclusion: 提出了一种新颖的 bandit 算法，该算法能够有效处理社交网络中的异常节点检测和个性化推荐问题，并具有理论和实验上的优势。

Abstract: The nodes' interconnections on a social network often reflect their
dependencies and information-sharing behaviors. Nevertheless, abnormal nodes,
which significantly deviate from most of the network concerning patterns or
behaviors, can lead to grave consequences. Therefore, it is imperative to
design efficient online learning algorithms that robustly learn users'
preferences while simultaneously detecting anomalies.
  We introduce a novel bandit algorithm to address this problem. Through
network knowledge, the method characterizes the users' preferences and
residuals of feature information. By learning and analyzing these preferences
and residuals, it develops a personalized recommendation strategy for each user
and simultaneously detects anomalies. We rigorously prove an upper bound on the
regret of the proposed algorithm and experimentally compare it with several
state-of-the-art collaborative contextual bandit algorithms on both synthetic
and real-world datasets.

</details>


<div id='cs.GR'></div>

# cs.GR [[Back]](#toc)

### [207] [Fast Texture Transfer for XR Avatars via Barycentric UV Conversion](https://arxiv.org/abs/2508.19518)
*Hail Song,Seokhwan Yang,Woontack Woo*

Main category: cs.GR

TL;DR: 我们提出了一种快速高效的方法，用于将面部纹理转移到基于SMPL-X的全身化身上，通过预计算UV映射到单个变换矩阵，实现了超过7000倍的速度提升和更优的纹理质量。


<details>
  <summary>Details</summary>
Motivation: 传统的基于仿射变换的方法在转移面部纹理到SMPL-X全身化身上时速度慢且容易出现视觉瑕疵，需要更优化的解决方案。

Method: 提出一种利用重心UV转换技术的纹理转移方法，将整个UV映射预计算为单个变换矩阵，实现一次性纹理转移。

Result: 与基线方法相比，速度提升超过7000倍，同时通过消除边界伪影显著提高了最终纹理质量。

Conclusion: 该方法为沉浸式XR应用中的个性化提供了一个实用解决方案，在定量和定性评估中均表现优异。

Abstract: We present a fast and efficient method for transferring facial textures onto
SMPL-X-based full-body avatars. Unlike conventional affine-transform methods
that are slow and prone to visual artifacts, our method utilizes a barycentric
UV conversion technique. Our approach precomputes the entire UV mapping into a
single transformation matrix, enabling texture transfer in a single operation.
This results in a speedup of over 7000x compared to the baseline, while also
significantly improving the final texture quality by eliminating boundary
artifacts. Through quantitative and qualitative evaluations, we demonstrate
that our method offers a practical solution for personalization in immersive XR
applications. The code is available online.

</details>


<div id='cs.DS'></div>

# cs.DS [[Back]](#toc)

### [208] [Efficiently Coloring the Intersection of a General Matroid and Partition Matroids](https://arxiv.org/abs/2508.19473)
*Stephen Arndt,Benjamin Moseley,Kirk Pruhs,Michael Zlatin*

Main category: cs.DS

TL;DR: 该论文提出了一种多项式时间算法，可为一般拟阵 $M_1 = (X, \mathcal{I}_1)$ 和 $k-1$ 个划分拟阵 $M_2, \ldots, M_k$ 的交集 $M = igcap_{i=1}^k M_i$ 产生一种染色，使用的颜色数不超过 $1 + \sum_{i=1}^k (\chi(M_i) - 1)$。这是第一个拟阵交集着色问题的多项式时间 $O(1)$-近似算法，其中一个拟阵可以是任意一般拟阵。该算法利用所有标准的组合拟阵都可以归约到划分拟阵（此时染色数会损失一倍）这一事实，也为每个拟阵 $M_2, \ldots, M_k$ 均为标准组合类型的拟阵交集着色问题提供了多项式时间 $O(1)$-近似算法。


<details>
  <summary>Details</summary>
Motivation: 解决一般拟阵与划分拟阵交集的着色问题，并提供多项式时间 $O(1)$-近似算法。

Method: 提出一种多项式时间算法，利用拟阵归约到划分拟阵的性质。

Result: 提供了一种用于一般拟阵与 $k-1$ 个划分拟阵交集着色的多项式时间 $O(1)$-近似算法，使用的颜色数不超过 $1 + \sum_{i=1}^k (\chi(M_i) - 1)$。同时，该算法也适用于 $k-1$ 个拟阵均为标准组合类型的情况。

Conclusion: 该算法是拟阵交集着色问题的一个重要突破，特别是在涉及一般拟阵的情况下。

Abstract: This paper shows a polynomial-time algorithm, that given a general matroid
$M_1 = (X, \mathcal{I}_1)$ and $k-1$ partition matroids $ M_2, \ldots, M_k$,
produces a coloring of the intersection $M = \cap_{i=1}^k M_i$ using at most
$1+\sum_{i=1}^k \left(\chi(M_i) -1\right)$ colors. This is the first
polynomial-time $O(1)$-approximation algorithm for matroid intersection
coloring where one of the matroids may be a general matroid. Leveraging the
fact that all of the standard combinatorial matroids reduce to partition
matroids at a loss of a factor of two in the chromatic number, this algorithm
also yields a polynomial-time $O(1)$-approximation algorithm for matroid
intersection coloring in the case where each of the matroids $ M_2, \ldots,
M_k$ are one of the standard combinatorial types.

</details>


### [209] [An Optimal Sorting Algorithm for Persistent Random Comparison Faults](https://arxiv.org/abs/2508.19785)
*Barbara Geissmann,Stefano Leucci,Chih-Hung Liu,Paolo Penna*

Main category: cs.DS

TL;DR: 在存在固定（小数）概率p的持久随机比较错误的情况下，对n个元素进行排序。我们提出了第一个时间复杂度为O(n log n)的排序算法，该算法在p<1/4时，能够以高概率保证O(log n)的最大错位和O(n)的总错位。


<details>
  <summary>Details</summary>
Motivation: 在存在持久随机比较错误的情况下，对n个元素进行排序，目标是最小化输出序列中每个元素的错位。

Method: 提出了一种O(n log n)时间的排序算法，该算法解决了两个子问题：1) 在对数时间内在几乎排序的序列中插入一个新元素，并以高概率保证O(d)的错位。2) 在O(nd)时间内将几乎排序序列的最大（或总）错位降低到O(log n)（或O(n)）。

Result: 该算法能够以高概率实现O(log n)的最大错位和O(n)的总错位，并且证明了这是最优的。

Conclusion: 与没有比较错误的情况相比，比较错误不会增加排序的计算难度，因为O(n log n)的时间复杂度是达到O(log n)最大错位的必要条件。

Abstract: We consider the problem of sorting $n$ elements subject to persistent random
comparison errors. In this problem, each comparison between two elements can be
wrong with some fixed (small) probability $p$, and comparing the same pair of
elements multiple times always yields the same result. Sorting perfectly in
this model is impossible, and the objective is to minimize the dislocation of
each element in the output sequence, i.e., the difference between its position
in the sequence and its true rank.
  In this paper, we present the first $O(n\log n)$-time sorting algorithm that
guarantees both $O(\log n)$ maximum dislocation and $O(n)$ total dislocation
with high probability when $p<\frac{1}{4}$. This settles the time complexity
sorting with persistent comparison errors in the given range of $p$ and shows
that comparison errors do not increase its computational difficulty. Indeed,
$\Omega(n\log n)$ time is necessary to archive a maximum dislocation of $O(\log
n)$ even without comparison errors. Moreover, we prove that no algorithm can
guarantee a maximum dislocation of $o(\log n)$ with high probability, nor a
total dislocation of $o(n)$ in expectation.
  To develop our sorting algorithm, we solve two related sub-problems, which
might be of independent interest. More precisely, we show that $O(\log n)$ time
suffices to find a position in which to insert a new element $x$ in an
almost-sorted sequence $S$ of $n$ elements having dislocation at most
$d=\Omega(\log n)$, so that the dislocation of $x$ in the resulting sequence is
$O(d)$ with high probability (which can be equivalently thought as the problem
of estimating the rank of $x$ in $S$). We also show that the maximum (resp.
total) dislocation of an approximately sorted sequence $S$ of $n$ elements can
be lowered to $O(\log n)$ (resp. $O(n)$) in $O(nd)$ time, w.h.p., where $d$ is
an upper bound on the maximum dislocation of $S$.

</details>


### [210] [Optimizing Wiggle in Storylines](https://arxiv.org/abs/2508.19802)
*Alexander Dobler,Tim Hegemann,Martin Nöllenburg,Alexander Wolff*

Main category: cs.DS

TL;DR: 本文研究了故事线可视化的优化问题，重点关注减少图中线条的抖动（wiggle），并提出了解决线性抖动最小化和二次抖动最小化问题的算法。


<details>
  <summary>Details</summary>
Motivation: 本文旨在解决故事线可视化中一个被忽视的质量标准——最小化抖动（wiggle），即角色随时间变化的垂直移动量。

Method: 本文研究了抖动计数最小化问题，并证明其为NP完全问题。此外，本文还提出了基于数学规划的算法来有效解决线性抖动高度最小化和二次抖动高度最小化问题。最后，本文介绍了一种新的路由方法，用于在角色曲线并行时保持它们之间的恒定距离。

Result: 本文证明了抖动计数最小化是NP完全问题，但提出了有效的算法来解决线性抖动高度最小化和二次抖动高度最小化问题。通过案例研究，探讨了最小化交叉、最小化线性抖动和最小化二次抖动这三个优化目标之间的差异。

Conclusion: 本文在最小化交叉的基础上，重点研究了最小化抖动问题，并提出了相应的有效算法，同时还介绍了新的路由方法。通过案例研究，验证了所提方法的有效性，并拓展了故事线可视化在铁路运营等领域的应用。

Abstract: A storyline visualization shows interactions between characters over time.
Each character is represented by an x-monotone curve. Time is mapped to the
x-axis, and groups of characters that interact at a particular point $t$ in
time must be ordered consecutively in the y-dimension at $x=t$. The predominant
objective in storyline optimization so far has been the minimization of
crossings between (blocks of) characters. Building on this work, we investigate
another important, but less studied quality criterion, namely the minimization
of wiggle, i.e., the amount of vertical movement of the characters over time.
Given a storyline instance together with an ordering of the characters at any
point in time, we show that wiggle count minimization is NP-complete. In
contrast, we provide algorithms based on mathematical programming to solve
linear wiggle height minimization and quadratic wiggle height minimization
efficiently. Finally, we introduce a new method for routing character curves
that focuses on keeping distances between neighboring curves constant as long
as they run in parallel. We have implemented our algorithms, and we conduct a
case study that explores the differences between the three optimization
objectives. We use existing benchmark data, but we also present a new use case
for storylines, namely the visualization of rolling stock schedules in railway
operation.

</details>


### [211] [Distributed Sparsest Cut via Eigenvalue Estimation](https://arxiv.org/abs/2508.19898)
*Yannic Maus,Tijn de Vos*

Main category: cs.DS

TL;DR: 本文提出了一种在CONGEST模型下逼近图的稀疏割值（或电导率$\phi$）的新方法，其运行轮数为 $O(\log^2 n/\phi)$，并能在 $\phi \le \tilde \phi \le \sqrt{2.01\phi}$ 的范围内得到近似值。


<details>
  <summary>Details</summary>
Motivation: 在CONGEST模型下，为图的稀疏割值（或电导率$\\phi$）提供新的、改进的逼近界限。

Method: 通过逼近归一化拉普拉斯矩阵 $L:=I-\\rm{Deg}^{-1/2}A\\rm{Deg}^{-1/2}$ 的特征值，该方法核心是利用功率迭代法（重复将拉普拉斯矩阵与向量相乘），每次乘法可以在CONGEST模型下的一轮内完成。

Result: 提出一种在 $O(\log^2 n/\phi)$ 轮内运行的算法，每个顶点输出一个满足 $\\phi \le \tilde \phi \le \sqrt{2.01\phi}$ 的值 $\\tilde \phi$，该算法在大多数情况下显著优于先前最快的算法 [Chen, Meierhans, Probst Gutenberg, Saranurak; SODA 25]，并可推广到k路电导率。

Conclusion: 所提出的基于功率迭代的算法相比于先前基于扩展器分解的算法更为简单且易于实现，适用于加权无向图，并且所提出的下界甚至适用于无权图。

Abstract: We give new, improved bounds for approximating the sparsest cut value or in
other words the conductance $\phi$ of a graph in the CONGEST model. As our main
result, we present an algorithm running in $O(\log^2 n/\phi)$ rounds in which
every vertex outputs a value $\tilde \phi$ satisfying $\phi \le \tilde \phi \le
\sqrt{2.01\phi}$. In most regimes, our algorithm improves significantly over
the previously fastest algorithm for the problem [Chen, Meierhans, Probst
Gutenberg, Saranurak; SODA 25]. Additionally, our result generalizes to $k$-way
conductance.
  We obtain these results, by approximating the eigenvalues of the normalized
Laplacian matrix $L:=I-\rm{Deg}^{-1/2}A\rm{Deg}^ {-1/2}$, where, $A$ is the
adjacency matrix and $\rm{Deg}$ is the diagonal matrix with the weighted
degrees on the diagonal. The previous state of the art sparsest cut algorithm
is in the technical realm of expander decompositions. Our algorithms, on the
other hand, are relatively simple and easy to implement. At the core, they rely
on the well-known power method, which comes down to repeatedly multiplying the
Laplacian with a vector. This operation can be performed in a single round in
the CONGEST model. All our algorithms apply to weighted, undirected graphs. Our
lower bounds apply even in unweighted graphs.

</details>


### [212] [Bipartite Matching with Pair-Dependent Bounds](https://arxiv.org/abs/2508.20002)
*Shaul Rosner,Tami Tamir*

Main category: cs.DS

TL;DR: 本论文研究了一种新的二分匹配问题变体，其中机器可以接受的作业数量取决于分配给它的特定作业。该模型旨在解决现实世界系统中存在的拥塞问题，并针对最大化匹配大小的目标进行了分析。研究了该问题的计算复杂性，并提出了硬度结果以及最优和近似算法。


<details>
  <summary>Details</summary>
Motivation: 现实世界系统中的拥塞问题，其中机器可接受的作业数量取决于分配给它的特定作业。

Method: 定义了二分PD匹配，分析了其计算复杂性，并提出了最优和近似算法。

Result: 该问题与之前研究的匹配问题存在显著差异，并提出了硬度结果以及最优和近似算法。

Conclusion: 二分PD匹配问题是一个新的且具有挑战性的问题，对于理解和优化资源分配系统具有重要意义。

Abstract: Let $G=(U \cup V, E)$ be a bipartite graph, where $U$ represents jobs and $V$
represents machines. We study a new variant of the bipartite matching problem
in which each job in $U$ can be matched to at most one machine in $V$, and the
number of jobs that can be assigned to a machine depends on the specific jobs
matched to it. These pair-dependent bounds reflect systems where different jobs
have varying tolerance for congestion, determined by the specific machine they
are assigned to.
  We define a bipartite PD-matching as a set of edges $M \subseteq E$ that
satisfies these job-to-machine tolerance constraints. This variant of matching
extends well-known matching problems, however, despite its relevance to
real-world systems, it has not been studied before. We study bipartite
PD-matchings with the objective of maximizing the matching size. As we show,
the problem exhibits significant differences from previously studied matching
problems. We analyze its computational complexity both in the general case and
for specific restricted instances, presenting hardness results alongside
optimal and approximation algorithms.

</details>


### [213] [Flow-weighted Layered Metric Euclidean Capacitated Steiner Tree Problem](https://arxiv.org/abs/2508.20041)
*Thomas Bläsius,Henrik Csöre,Max Göttlicher,Elly Schmidt,Wendy Yi*

Main category: cs.DS

TL;DR: FLaMECaST是具有分层结构和每层容量约束的欧几里得 Steiner 树的变体，目标是在负载相关边成本下构建连接源到汇的成本最优 Steiner 森林。FLaMECaST 甚至在源位于圆上的受限情况下也难以近似。然而，对于此类实例，我们设计了一个动态规划，可以在多项式时间内实现 (1 + 1/2^n) 的近似。


<details>
  <summary>Details</summary>
Motivation: 受分层网络的启发，论文介绍了 FLaMECaST 问题，这是欧几里得 Steiner 树的一个变体，具有分层结构和每层容量约束。

Method: 提出了一种动态规划方法，该方法在多项式时间内实现了 (1 + 1/2^n) 的近似，并将其推广到源位于凸多边形的情况。

Result: FLaMECaST 被证明 NP-hard 难以近似，即使在源位于圆上的情况下也是如此。然而，提出的动态规划方法为某些实例提供了近似保证。

Conclusion: FLaMECaST 问题具有挑战性，但通过动态规划和结构洞察，可以为特定实例开发近似算法。

Abstract: Motivated by hierarchical networks, we introduce the Flow-weighted Layered
Metric Euclidean Capacitated Steiner Tree (FLaMECaST) problem, a variant of the
Euclidean Steiner tree with layered structure and capacity constraints per
layer. The goal is to construct a cost-optimal Steiner forest connecting a set
of sources to a set of sinks under load-dependent edge costs. We prove that
FLaMECaST is NP-hard to approximate, even in restricted cases where all sources
lie on a circle. However, assuming few additional constraints for such
instances, we design a dynamic program that achieves a $\left(1 +
\frac{1}{2^n}\right)$-approximation in polynomial time. By generalizing the
structural insights the dynamic program is based on, we extend the approach to
certain settings, where all sources are positioned on a convex polygon.

</details>


<div id='cs.DC'></div>

# cs.DC [[Back]](#toc)

### [214] [HPC Digital Twins for Evaluating Scheduling Policies, Incentive Structures and their Impact on Power and Cooling](https://arxiv.org/abs/2508.20016)
*Matthias Maiterth,Wesley H. Brewer,Jaya S. Kuruvella,Arunavo Dey,Tanzima Z. Islam,Kevin Menear,Dmitry Duplyakin,Rashadul Kabir,Tapasya Patki,Terry Jones,Feiyi Wang*

Main category: cs.DC

TL;DR: 提出了一种将调度与数字孪生相结合的高性能计算（HPC）框架，用于在部署前或进行难以实现的更改之前，对调度参数和决策对物理资产的影响进行建模和评估。


<details>
  <summary>Details</summary>
Motivation: 评估HPC调度器通常受限于部署后分析或不包含基础设施的模拟器。本工作旨在解决这一局限性，提供一种新的评估方法。

Method: 开发了一个集成了调度能力的数字孪生框架，并整合了公共数据集和外部调度模拟器。此外，还实现了用于评估激励结构和基于机器学习的调度的扩展。

Result: 成功地集成了调度和数字孪生技术，为HPC系统提供了一个原型设计和评估框架，能够进行“假设”分析，评估可持续性和对模拟系统的影响。

Conclusion: 该框架为HPC调度提供了一种创新的评估和原型设计方法，通过数字孪生技术实现了部署前的“假设”分析，有助于优化资源利用和评估系统性能。

Abstract: Schedulers are critical for optimal resource utilization in high-performance
computing. Traditional methods to evaluate schedulers are limited to
post-deployment analysis, or simulators, which do not model associated
infrastructure. In this work, we present the first-of-its-kind integration of
scheduling and digital twins in HPC. This enables what-if studies to understand
the impact of parameter configurations and scheduling decisions on the physical
assets, even before deployment, or regarching changes not easily realizable in
production. We (1) provide the first digital twin framework extended with
scheduling capabilities, (2) integrate various top-tier HPC systems given their
publicly available datasets, (3) implement extensions to integrate external
scheduling simulators. Finally, we show how to (4) implement and evaluate
incentive structures, as-well-as (5) evaluate machine learning based
scheduling, in such novel digital-twin based meta-framework to prototype
scheduling. Our work enables what-if scenarios of HPC systems to evaluate
sustainability, and the impact on the simulated system.

</details>


### [215] [HAP: Hybrid Adaptive Parallelism for Efficient Mixture-of-Experts Inference](https://arxiv.org/abs/2508.19373)
*Haoran Lin,Xianzhi Yu,Kang Zhao,Han Bao,Zongyuan Zhan,Ting Hu,Wulong Liu,Zekun Yin,Xin Li,Weiguo Liu*

Main category: cs.DC

TL;DR: HAP是一种新的混合自适应并行方法，通过动态选择并行策略来提高MoE模型推理效率，并能在不同GPU和模型上实现性能提升。


<details>
  <summary>Details</summary>
Motivation: 现有的MoE推理系统主要使用静态并行策略，无法适应不同的推理场景和计算需求，导致性能不佳。

Method: HAP将MoE模型分解为Attention模块和Expert模块，并为每个模块配备专门的推理延迟模拟模型。利用整数线性规划（ILP）来寻找最优的混合并行配置，以最大化推理效率。

Result: 在A100、A6000和V100 GPU平台上，HAP相比于传统的TP策略分别实现了1.68倍、1.77倍和1.57倍的加速。HAP在Mixtral和Qwen系列等不同MoE模型上均表现出良好的泛化能力和性能。

Conclusion: HAP通过其创新的混合自适应并行方法，能够有效地提升MoE模型的推理效率，并克服了静态并行策略的局限性。

Abstract: Current inference systems for Mixture-of-Experts (MoE) models primarily
employ static parallelization strategies. However, these static approaches
cannot consistently achieve optimal performance across different inference
scenarios, as they lack the flexibility to adapt to varying computational
requirements. In this work, we propose HAP (Hybrid Adaptive Parallelism), a
novel method that dynamically selects hybrid parallel strategies to enhance MoE
inference efficiency. The fundamental innovation of HAP lies in hierarchically
decomposing MoE architectures into two distinct computational modules: the
Attention module and the Expert module, each augmented with a specialized
inference latency simulation model. This decomposition promotes the
construction of a comprehensive search space for seeking model parallel
strategies. By leveraging Integer Linear Programming (ILP), HAP could solve the
optimal hybrid parallel configurations to maximize inference efficiency under
varying computational constraints. Our experiments demonstrate that HAP
consistently determines parallel configurations that achieve comparable or
superior performance to the TP strategy prevalent in mainstream inference
systems. Compared to the TP-based inference, HAP-based inference achieves
speedups of 1.68x, 1.77x, and 1.57x on A100, A6000, and V100 GPU platforms,
respectively. Furthermore, HAP showcases remarkable generalization capability,
maintaining performance effectiveness across diverse MoE model configurations,
including Mixtral and Qwen series models.

</details>


### [216] [Formal Modeling and Verification of the Algorand Consensus Protocol in CADP](https://arxiv.org/abs/2508.19452)
*Andrea Esposito,Francesco P. Rossi,Marco Bernardo,Francesco Fabris,Hubert Garavel*

Main category: cs.DC

TL;DR: Algorand是一个可扩展且安全的无许可区块链，通过加密自我筛选和二元拜占庭共识达成权益证明。本文提出了一种Algorand共识协议的进程代数模型，旨在实现严格的形式化验证。该模型通过概率进程演算捕捉参与者关于结构化共识步骤的交替行为，以实现基于委员会的共识。


<details>
  <summary>Details</summary>
Motivation: 本文旨在对Algorand共识协议进行严格的形式化验证，揭示其在面对恶意节点时的鲁棒性和局限性，并展示形式化方法在分析区块链共识算法中的价值。

Method: 使用概率进程演算构建Algorand共识协议的模型，模拟参与者行为，并通过等价检查的非干扰框架分析恶意节点的影响。

Result: 验证了在没有恶意节点的情况下协议的正确性，并识别出在存在协调恶意节点时可能导致提交空块的场景。

Conclusion: Algorand协议在没有恶意节点时是正确的，但在存在恶意节点时存在被强制提交空块的风险。形式化方法对于分析区块链共识算法至关重要。

Abstract: Algorand is a scalable and secure permissionless blockchain that achieves
proof-of-stake consensus via cryptographic self-sortition and binary Byzantine
agreement. In this paper, we present a process algebraic model of the Algorand
consensus protocol with the aim of enabling rigorous formal verification. Our
model captures the behavior of participants with respect to the structured
alternation of consensus steps toward a committee-based agreement by means of a
probabilistic process calculus. We validate the correctness of the protocol in
the absence of adversaries and then extend our model to capture the influence
of coordinated malicious nodes that can force the commit of an empty block
instead of the proposed one. The adversarial scenario is analyzed by using an
equivalence-checking-based noninterference framework that we have implemented
in the CADP verification toolkit. In addition to highlighting both the
robustness and the limitations of the Algorand protocol under adversarial
assumptions, this work illustrates the added value of using formal methods for
the analysis of blockchain consensus algorithms.

</details>


### [217] [Towards 6G Intelligence: The Role of Generative AI in Future Wireless Networks](https://arxiv.org/abs/2508.19495)
*Muhammad Ahmed Mohsin,Junaid Ahmad,Muhammad Hamza Nawaz,Muhammad Ali Jamshed*

Main category: cs.DC

TL;DR: 本文提出将生成式人工智能（GenAI）作为环境智能（AmI）的核心驱动力，并探讨其在6G网络中的应用，以实现更智能、更具适应性的通信环境。


<details>
  <summary>Details</summary>
Motivation: 随着通信技术的发展，需要更智能、更自适应的网络来支持日益复杂的应用场景。环境智能（AmI）提供了一种计算范式，但其在全球范围内的实现面临数据稀疏、用户意图理解和网络预测等挑战。本文旨在提出GenAI作为解决方案，以弥合AmI的差距，并推动6G网络向智能生态系统演进。

Method: 本文综述了生成式人工智能（GenAI）的基础模型，包括GANs、VAEs、扩散模型和生成式Transformer，并将其与AmI的应用场景（如频谱共享、超可靠低延迟通信、智能安全和情境感知数字孪生）联系起来。同时，探讨了6G的关键技术（如边缘和雾计算、物联网设备群、智能反射面和非地面网络）如何支持分布式GenAI。此外，还审视了在设备端训练、可信合成数据、联邦生成学习和AmI标准化方面的开放性挑战。

Result: GenAI能够通过生成合成数据、翻译用户意图、预测网络条件和更新数字孪生来弥合AmI的关键差距。6G技术如边缘计算、IRS等能够支持分布式GenAI的部署和加速。

Conclusion: GenAI是实现6G网络环境智能化的基础要素，而非边缘补充。通过整合GenAI，6G能够从单纯的“更快网络”转变为“环境智能生态系统”。

Abstract: Ambient intelligence (AmI) is a computing paradigm in which physical
environments are embedded with sensing, computation, and communication so they
can perceive people and context, decide appropriate actions, and respond
autonomously. Realizing AmI at global scale requires sixth generation (6G)
wireless networks with capabilities for real time perception, reasoning, and
action aligned with human behavior and mobility patterns. We argue that
Generative Artificial Intelligence (GenAI) is the creative core of such
environments. Unlike traditional AI, GenAI learns data distributions and can
generate realistic samples, making it well suited to close key AmI gaps,
including generating synthetic sensor and channel data in under observed areas,
translating user intent into compact, semantic messages, predicting future
network conditions for proactive control, and updating digital twins without
compromising privacy.
  This chapter reviews foundational GenAI models, GANs, VAEs, diffusion models,
and generative transformers, and connects them to practical AmI use cases,
including spectrum sharing, ultra reliable low latency communication,
intelligent security, and context aware digital twins. We also examine how 6G
enablers, such as edge and fog computing, IoT device swarms, intelligent
reflecting surfaces (IRS), and non terrestrial networks, can host or accelerate
distributed GenAI. Finally, we outline open challenges in energy efficient on
device training, trustworthy synthetic data, federated generative learning, and
AmI specific standardization. We show that GenAI is not a peripheral addition,
but a foundational element for transforming 6G from a faster network into an
ambient intelligent ecosystem.

</details>


### [218] [Taming the Chaos: Coordinated Autoscaling for Heterogeneous and Disaggregated LLM Inference](https://arxiv.org/abs/2508.19559)
*Rongzhi Li,Ruogu Du,Zefang Chu,Sida Zhao,Chunlei Han,Zuocheng Shi,Yiwen Shao,Huanle Han,Long Huang,Zherui Liu,Shufan Liu*

Main category: cs.DC

TL;DR: HeteroScale是一个协调的自动扩展框架，通过拓扑感知调度和新颖的指标驱动策略解决了Prefill-Decode (P/D) 分离架构中的LLM服务挑战，提高了GPU利用率并节省了大量GPU小时数。


<details>
  <summary>Details</summary>
Motivation: 传统的自动扩展器在为现代Prefill-Decode (P/D) 分离架构提供LLM服务时存在不足，导致异构硬件使用效率低下、网络瓶颈和预处理-解码阶段失衡。

Method: HeteroScale结合了拓扑感知调度器（适应异构硬件和网络约束）和新颖的指标驱动策略（基于大规模生产自动扩展信号的实证研究），通过单一的健壮指标联合扩展预处理和解码池。

Result: 在数万个GPU的大规模生产环境中部署的HeteroScale，将平均GPU利用率提高了26.6个百分点，每天节省了数十万个GPU小时数，同时满足了严格的服务级别目标。

Conclusion: HeteroScale通过保持架构平衡并确保高效、自适应的资源管理，成功解决了P/D分离LLM服务中的核心挑战。

Abstract: Serving Large Language Models (LLMs) is a GPU-intensive task where
traditional autoscalers fall short, particularly for modern Prefill-Decode
(P/D) disaggregated architectures. This architectural shift, while powerful,
introduces significant operational challenges, including inefficient use of
heterogeneous hardware, network bottlenecks, and critical imbalances between
prefill and decode stages. We introduce HeteroScale, a coordinated autoscaling
framework that addresses the core challenges of P/D disaggregated serving.
HeteroScale combines a topology-aware scheduler that adapts to heterogeneous
hardware and network constraints with a novel metric-driven policy derived from
the first large-scale empirical study of autoscaling signals in production. By
leveraging a single, robust metric to jointly scale prefill and decode pools,
HeteroScale maintains architectural balance while ensuring efficient, adaptive
resource management. Deployed in a massive production environment on tens of
thousands of GPUs, HeteroScale has proven its effectiveness, increasing average
GPU utilization by a significant 26.6 percentage points and saving hundreds of
thousands of GPU-hours daily, all while upholding stringent service level
objectives.

</details>


### [219] [Beyond the Bermuda Triangle of Contention: IOMMU Interference in Mixed Criticality Systems](https://arxiv.org/abs/2508.19670)
*Diogo Costa,Jose Martins,Sandro Pinto*

Main category: cs.DC

TL;DR: 该论文研究了异构计算平台中IOMMU的性能干扰问题，发现IOMMU的共享特性会导致不可预测的延迟，尤其对小内存事务影响较大。


<details>
  <summary>Details</summary>
Motivation: 随着混合关键性系统（MCSs）整合异构计算平台，IOMMU在确保安全和时间可预测性方面作用关键，但其对性能干扰的影响尚待探索。

Method: 在Xilinx UltraScale+ ZCU104平台上分析了IOMMU结构内的争用效应，特别关注了IOMMU争用如何影响DMA事务。

Result: 实验表明，IOMMU争用对小内存事务的延迟影响尤为显著，Arm SMMUv2的实现中，IOMMU干扰可导致小传输延迟最高增加1.79倍。

Conclusion: IOMMU的共享特性会引入不可预测的延迟，特别是在小内存事务中，这可能对MCSs的性能和可预测性产生负面影响。IOMMU争用效应可能在不同架构中表现相似。

Abstract: As Mixed Criticality Systems (MCSs) evolve, they increasingly integrate
heterogeneous computing platforms, combining general-purpose processors with
specialized accelerators such as AI engines, GPUs, and high-speed networking
interfaces. This heterogeneity introduces challenges, as these accelerators and
DMA-capable devices act as independent bus masters, directly accessing memory.
Consequently, ensuring both security and timing predictability in such
environments becomes critical. To address these concerns, the Input-Output
Memory Management Unit (IOMMU) plays a key role in mediating and regulating
memory access, preventing unauthorized transactions while enforcing isolation
and access control policies. While prior work has explored IOMMU-related
side-channel vulnerabilities from a security standpoint, its role in
performance interference remains largely unexplored. Moreover, many of the same
architectural properties that enable side-channel leakage, such as shared TLBs,
caching effects, and translation overheads, can also introduce timing
unpredictability. In this work, we analyze the contention effects within IOMMU
structures using the Xilinx UltraScale+ ZCU104 platform, demonstrating how
their shared nature introduce unpredictable delays. Our findings reveal that
IOMMU-induced interference primarily affects small memory transactions, where
translation overheads significantly impact execution time. Additionally, we
hypothesize that contention effects arising from IOTLBs exhibit similar
behavior across architectures due to shared caching principles, such as
prefetching and hierarchical TLB structures. Notably, our experiments show that
IOMMU interference can delay DMA transactions by up to 1.79x for lower-size
transfers on the Arm SMMUv2 implementation.

</details>


### [220] [Separation of Three or More Autonomous Mobile Models under Hierarchical Schedulers](https://arxiv.org/abs/2508.19805)
*Shota Naito,Tsukasa Ninomiya,Koichi Wada*

Main category: cs.DC

TL;DR: 本文研究了移动机器人系统的计算能力，重点关注机器人能力、光照可观察性、调度器同步性之间的复杂交互作用，并提出了新的分类和分离结果。


<details>
  <summary>Details</summary>
Motivation: 在分布式计算领域，理解移动机器人系统的计算能力是一个基本挑战。以往的研究主要集中在模型之间的成对分离，而本文旨在探索机器人能力、光照可观察性以及调度器同步性之间更复杂的交互方式。

Method: 本文首先证明了指数时间扩展（ETE）问题仅在最强的模型——具有完全相互光照的完全同步机器人（$	ext{LUMT}^F$）中可解。然后，通过引入六边形边遍历（HET）和TAR(d)*问题，展示了内部记忆和光照如何在弱同步和全同步条件下与同步性相互作用。在异步设置下，本文对LP-MLCv、VEC和ZCC等问题进行了分类，揭示了$	ext{FSTA}$和$	ext{FCOM}$机器人之间的细粒度分离。此外，还分析了顶点遍历集合（VTR）和离开地点收敛（LP-Cv）问题，阐释了在对称环境中内部记忆的局限性。

Result: 研究结果扩展了14个典型机器人模型的已知分离图，揭示了只有通过高阶比较才能显现的结构现象。本文提出了新的不可能判据，并深化了对可观察性、记忆和同步性如何共同影响移动机器人计算能力的理解。

Conclusion: 本文的研究结果为移动机器人系统的计算能力提供了新的见解，特别是在不同同步性、记忆和可观察性组合下的能力差异。这有助于设计更高效、更可靠的移动机器人系统。

Abstract: Understanding the computational power of mobile robot systems is a
fundamental challenge in distributed computing. While prior work has focused on
pairwise separations between models, we explore how robot capabilities, light
observability, and scheduler synchrony interact in more complex ways.
  We first show that the Exponential Times Expansion (ETE) problem is solvable
only in the strongest model -- fully-synchronous robots with full mutual lights
($\mathcal{LUMT}^F$). We then introduce the Hexagonal Edge Traversal (HET) and
TAR(d)* problems to demonstrate how internal memory and lights interact with
synchrony: under weak synchrony, internal memory alone is insufficient, while
full synchrony can substitute for both lights and memory.
  In the asynchronous setting, we classify problems such as LP-MLCv, VEC, and
ZCC to show fine-grained separations between $\mathcal{FSTA}$ and
$\mathcal{FCOM}$ robots. We also analyze Vertex Traversal Rendezvous (VTR) and
Leave Place Convergence (LP-Cv), illustrating the limitations of internal
memory in symmetric settings.
  These results extend the known separation map of 14 canonical robot models,
revealing structural phenomena only visible through higher-order comparisons.
Our work provides new impossibility criteria and deepens the understanding of
how observability, memory, and synchrony collectively shape the computational
power of mobile robots.

</details>


<div id='cs.GT'></div>

# cs.GT [[Back]](#toc)

### [221] [Aggregate Fictitious Play for Learning in Anonymous Polymatrix Games (Extended Version)](https://arxiv.org/abs/2508.19371)
*Semih Kara,Tamer Başar*

Main category: cs.GT

TL;DR: 在匿onym游戏中，聚合性博弈（agg-FP）通过聚合其他玩家的行为来减少状态空间，从而加速了向纳什均衡的收敛。


<details>
  <summary>Details</summary>
Motivation: 为了解决在玩家不了解奖励机制的情况下，博弈中联合动作空间随玩家数量呈指数增长导致奖励探索缓慢的问题。

Method: 提出聚合性博弈（agg-FP），这是一种博弈方法，其中每个玩家跟踪其他玩家执行每个动作的频率，而不是跟踪玩家的个体动作。

Result: 聚合性博弈（agg-FP）在匿onym矩阵博弈中收敛到纳什均衡的条件与经典博弈相同，并且通过聚合动作空间而无需损失收敛保证。仿真结果也表明聚合性博弈（agg-FP）可以加速收敛。

Conclusion: 聚合性博弈（agg-FP）通过聚合玩家的动作，在不损失收敛保证的情况下减少了动作空间，从而解决了传统博弈在探索奖励时遇到的挑战。

Abstract: Fictitious play (FP) is a well-studied algorithm that enables agents to learn
Nash equilibrium in games with certain reward structures. However, when agents
have no prior knowledge of the reward functions, FP faces a major challenge:
the joint action space grows exponentially with the number of agents, which
slows down reward exploration. Anonymous games offer a structure that mitigates
this issue. In these games, the rewards depend only on the actions taken; not
on who is taking which action. Under such a structure, we introduce aggregate
fictitious play (agg-FP), a variant of FP where each agent tracks the frequency
of the number of other agents playing each action, rather than these agents'
individual actions. We show that in anonymous polymatrix games, agg-FP
converges to a Nash equilibrium under the same conditions as classical FP. In
essence, by aggregating the agents' actions, we reduce the action space without
losing the convergence guarantees. Using simulations, we provide empirical
evidence on how this reduction accelerates convergence.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [222] [Inference of Human-derived Specifications of Object Placement via Demonstration](https://arxiv.org/abs/2508.19367)
*Alex Cuellar,Ho Chit Siu,Julie A Shah*

Main category: cs.RO

TL;DR: 机器人抓取与放置任务中，现有的方法在捕捉人类可接受的物体配置的空间关系方面能力有限。本文提出了位置增强的RCC（PARCC）框架，并结合基于演示的学习算法，以更好地理解人类的物体排列规则。


<details>
  <summary>Details</summary>
Motivation: 现有的机器人抓取与放置任务方法，在理解人类物体配置的空间关系方面能力有限，需要更好的方法来捕捉这些空间关系。

Method: 提出了一种基于区域连接演算（RCC）的位置增强RCC（PARCC）形式化逻辑框架，并开发了一种通过演示学习PARCC规范的推理算法。

Result: 通过人类研究证明了该框架能够捕捉人类意图的规范，并且学习方法优于人类提供的规范。

Conclusion: PARCC框架和基于演示的学习方法能够有效地捕捉人类的物体排列规则，并在机器人应用中优于直接提供规范的方法。

Abstract: As robots' manipulation capabilities improve for pick-and-place tasks (e.g.,
object packing, sorting, and kitting), methods focused on understanding
human-acceptable object configurations remain limited expressively with regard
to capturing spatial relationships important to humans. To advance robotic
understanding of human rules for object arrangement, we introduce
positionally-augmented RCC (PARCC), a formal logic framework based on region
connection calculus (RCC) for describing the relative position of objects in
space. Additionally, we introduce an inference algorithm for learning PARCC
specifications via demonstrations. Finally, we present the results from a human
study, which demonstrate our framework's ability to capture a human's intended
specification and the benefits of learning from demonstration approaches over
human-provided specifications.

</details>


### [223] [FlipWalker: Jacob's Ladder toy-inspired robot for locomotion across diverse, complex terrain](https://arxiv.org/abs/2508.19380)
*Diancheng Li,Nia Ralston,Bastiaan Hagen,Phoebe Tan,Matthew A. Robertson*

Main category: cs.RO

TL;DR: FlipWalker是一个受雅各布斯之梯玩具启发的独特机器人运动系统，能克服轮式机器人难以应对的复杂地形。该机器人包含两个由柔性电缆连接的部件，能够像玩具一样围绕奇异点进行翻转运动。


<details>
  <summary>Details</summary>
Motivation: 介绍FlipWalker，一个受雅各布斯之梯玩具启发的独特机器人运动系统，用于穿越轮式机器人难以应对的复杂地形。

Method: 通过分析机器人运动的物理模型来阐明控制前进和越障的关键设计参数。

Result: 该机器人重0.78公斤，最大翻转速度为每秒0.2个体长。实验证明，FlipWalker的翻转策略是一种在不规则户外地形导航的有前景的替代方案。

Conclusion: FlipWalker的翻转策略是一种在不规则户外地形导航的有前景的替代方案。

Abstract: This paper introduces FlipWalker, a novel underactuated robot locomotion
system inspired by Jacob's Ladder illusion toy, designed to traverse
challenging terrains where wheeled robots often struggle. Like the Jacob's
Ladder toy, FlipWalker features two interconnected segments joined by flexible
cables, enabling it to pivot and flip around singularities in a manner
reminiscent of the toy's cascading motion. Actuation is provided by
motor-driven legs within each segment that push off either the ground or the
opposing segment, depending on the robot's current configuration. A
physics-based model of the underactuated flipping dynamics is formulated to
elucidate the critical design parameters governing forward motion and obstacle
clearance or climbing. The untethered prototype weighs 0.78 kg, achieves a
maximum flipping speed of 0.2 body lengths per second. Experimental trials on
artificial grass, river rocks, and snow demonstrate that FlipWalker's flipping
strategy, which relies on ground reaction forces applied normal to the surface,
offers a promising alternative to traditional locomotion for navigating
irregular outdoor terrain.

</details>


### [224] [LaVA-Man: Learning Visual Action Representations for Robot Manipulation](https://arxiv.org/abs/2508.19391)
*Chaoran Zhu,Hengyi Wang,Yik Lung Pang,Changjae Oh*

Main category: cs.RO

TL;DR: 该研究提出了一种新的视觉-语言理解方法，用于机器人操作。通过自监督学习重构掩码目标图像，模型能直接学习视觉-动作表征，无需机器人动作监督。新数据集Omni-Object Pick-and-Place包含180类物体和3200个实例，支持更广泛的评估。实验结果表明该方法优于现有技术。


<details>
  <summary>Details</summary>
Motivation: 现有方法通过预训练模型计算视觉-文本相似度，再映射到机器人动作，这种两步法限制了模型捕捉视觉-文本关系的能力，降低了操作精度。

Method: 提出一种自监督学习方法，通过重构掩码目标图像来学习视觉-文本关联，将输入图像和文本指令作为条件。此方法无需机器人动作监督即可学习视觉-动作表征，并可通过少量演示进行微调。

Result: 在五个基准测试（包括模拟和真实机器人验证）上进行了实验，结果显示所提出的方法优于现有技术。

Conclusion: 该研究提出的自监督学习方法能够有效地学习视觉-动作表征，并通过Omni-Object Pick-and-Place数据集验证了其在机器人操作任务中的优越性和泛化能力。

Abstract: Visual-textual understanding is essential for language-guided robot
manipulation. Recent works leverage pre-trained vision-language models to
measure the similarity between encoded visual observations and textual
instructions, and then train a model to map this similarity to robot actions.
However, this two-step approach limits the model to capture the relationship
between visual observations and textual instructions, leading to reduced
precision in manipulation tasks. We propose to learn visual-textual
associations through a self-supervised pretext task: reconstructing a masked
goal image conditioned on an input image and textual instructions. This
formulation allows the model to learn visual-action representations without
robot action supervision. The learned representations can then be fine-tuned
for manipulation tasks with only a few demonstrations. We also introduce the
\textit{Omni-Object Pick-and-Place} dataset, which consists of annotated robot
tabletop manipulation episodes, including 180 object classes and 3,200
instances with corresponding textual instructions. This dataset enables the
model to acquire diverse object priors and allows for a more comprehensive
evaluation of its generalisation capability across object instances.
Experimental results on the five benchmarks, including both simulated and
real-robot validations, demonstrate that our method outperforms prior art.

</details>


### [225] [Embodied Intelligence for Sustainable Flight: A Soaring Robot with Active Morphological Control](https://arxiv.org/abs/2508.19684)
*Ghadeer Elmkaiel,Syn Schmitt,Michael Muehlebach*

Main category: cs.RO

TL;DR: Floaty是一种能够利用风能进行变形的空中机器人，通过模仿鸟类的形态控制，实现了高能效和敏捷性，能在高达10米/秒的垂直气流中盘旋、机动并抑制干扰，其比功率消耗比传统推进系统低一个数量级。


<details>
  <summary>Details</summary>
Motivation: 解决空中机器人（特别是航空器）在动态风环境中同时实现敏捷机动性和高能效的挑战，传统推进系统能耗高，固定翼设计缺乏悬停和机动能力。

Method: 提出一种名为Floaty的变形机器人，通过被动翱翔和智能形态控制（模仿鸟类）来利用风能。其设计注重被动稳定性，并基于实验学习的气动模型进行姿态和位置控制，无需主动推进。

Result: Floaty在风洞实验中成功实现了在高达10米/秒的垂直气流中悬停、机动和抑制干扰的能力，并且其比功率消耗为10瓦/千克，比推进系统低一个数量级。

Conclusion: Floaty通过形态智能和控制的结合，为能效高的空中机器人提供了一种新范例，使其能够在恶劣的风况下可持续运行。

Abstract: Achieving both agile maneuverability and high energy efficiency in aerial
robots, particularly in dynamic wind environments, remains challenging.
Conventional thruster-powered systems offer agility but suffer from high energy
consumption, while fixed-wing designs are efficient but lack hovering and
maneuvering capabilities. We present Floaty, a shape-changing robot that
overcomes these limitations by passively soaring, harnessing wind energy
through intelligent morphological control inspired by birds. Floaty's design is
optimized for passive stability, and its control policy is derived from an
experimentally learned aerodynamic model, enabling precise attitude and
position control without active propulsion. Wind tunnel experiments demonstrate
Floaty's ability to hover, maneuver, and reject disturbances in vertical
airflows up to 10 m/s. Crucially, Floaty achieves this with a specific power
consumption of 10 W/kg, an order of magnitude lower than thruster-powered
systems. This introduces a paradigm for energy-efficient aerial robotics,
leveraging morphological intelligence and control to operate sustainably in
challenging wind conditions.

</details>


### [226] [From Stoplights to On-Ramps: A Comprehensive Set of Crash Rate Benchmarks for Freeway and Surface Street ADS Evaluation](https://arxiv.org/abs/2508.19425)
*John M. Scanlon,Timothy L McMurry,Yin-Hsiu Chen,Kristofer D. Kusano,Trent Victor*

Main category: cs.RO

TL;DR: 本文提出了基于美国多个城市区域的自动驾驶系统（ADS）碰撞率基准，以评估其安全性能。研究将先前仅关注城市街道的基准扩展到包括高速公路碰撞风险，以应对未来的ADS安全性能评估。


<details>
  <summary>Details</summary>
Motivation: 为了扩展先前仅关注街道的基准，以纳入高速公路碰撞风险，从而为未来的自动驾驶系统（ADS）安全性能评估提供更全面的数据。

Method: 利用公开的警方报告碰撞和行驶里程（VMT）数据，分离出运输中的乘用车，对道路类型进行分类，并分析碰撞类型。

Result: 高速公路碰撞率显示出显著的地域差异。例如，亚特兰大的任何伤害报告碰撞率（2.4 IPMM）几乎是菲尼克斯（0.7 IPMM）的三倍多。碰撞类型的分布因后果严重程度而异，严重碰撞（如致命碰撞）的单车碰撞、弱势道路使用者（VRU）和迎面碰撞的比例更高。

Conclusion: 研究强调了地点特定基准对于避免有偏见的安全评估至关重要，并首次为ADS评估生成了高速公路特定基准，为未来的ADS基准评估奠定了基础。

Abstract: This paper presents crash rate benchmarks for evaluating US-based Automated
Driving Systems (ADS) for multiple urban areas. The purpose of this study was
to extend prior benchmarks focused only on surface streets to additionally
capture freeway crash risk for future ADS safety performance assessments. Using
publicly available police-reported crash and vehicle miles traveled (VMT) data,
the methodology details the isolation of in-transport passenger vehicles, road
type classification, and crash typology. Key findings revealed that freeway
crash rates exhibit large geographic dependence variations with
any-injury-reported crash rates being nearly 3.5 times higher in Atlanta (2.4
IPMM; the highest) when compared to Phoenix (0.7 IPMM; the lowest). The results
show the critical need for location-specific benchmarks to avoid biased safety
evaluations and provide insights into the vehicle miles traveled (VMT) required
to achieve statistical significance for various safety impact levels. The
distribution of crash types depended on the outcome severity level. Higher
severity outcomes (e.g., fatal crashes) had a larger proportion of
single-vehicle, vulnerable road users (VRU), and opposite-direction collisions
compared to lower severity (police-reported) crashes. Given heterogeneity in
crash types by severity, performance in low-severity scenarios may not be
predictive of high-severity outcomes. These benchmarks are additionally used to
quantify at the required mileage to show statistically significant deviations
from human performance. This is the first paper to generate freeway-specific
benchmarks for ADS evaluation and provides a foundational framework for future
ADS benchmarking by evaluators and developers.

</details>


### [227] [An Iterative Approach for Heterogeneous Multi-Agent Route Planning with Resource Transportation Uncertainty and Temporal Logic Goals](https://arxiv.org/abs/2508.19429)
*Gustavo A. Cardona,Kaier Liang,Cristian-Ioan Vasile*

Main category: cs.RO

TL;DR: 本文提出了一种在资源分布未知的情况下，对异构多机器人进行路径规划的迭代方法。


<details>
  <summary>Details</summary>
Motivation: 本研究的动机是解决在资源分布不确定且未知的情况下，异构机器人团队在执行具有时空、能力和资源约束的任务时所面临的路径规划挑战。

Method: 采用一种迭代算法，该算法结合了探索和任务完成，以应对资源分布的不确定性。机器人被引导去探索环境，识别资源，并根据新发现的数据调整它们满足任务目标的最大化策略。

Result: 通过模拟案例研究证明了所提出方法在动态、资源受限环境下的有效性和性能。

Conclusion: 该方法为在不确定条件下，异构机器人团队在动态、资源受限环境下的规划问题提供了一个鲁棒的解决方案，能够有效地进行协调。

Abstract: This paper presents an iterative approach for heterogeneous multi-agent route
planning in environments with unknown resource distributions. We focus on a
team of robots with diverse capabilities tasked with executing missions
specified using Capability Temporal Logic (CaTL), a formal framework built on
Signal Temporal Logic to handle spatial, temporal, capability, and resource
constraints. The key challenge arises from the uncertainty in the initial
distribution and quantity of resources in the environment. To address this, we
introduce an iterative algorithm that dynamically balances exploration and task
fulfillment. Robots are guided to explore the environment, identifying resource
locations and quantities while progressively refining their understanding of
the resource landscape. At the same time, they aim to maximally satisfy the
mission objectives based on the current information, adapting their strategies
as new data is uncovered. This approach provides a robust solution for planning
in dynamic, resource-constrained environments, enabling efficient coordination
of heterogeneous teams even under conditions of uncertainty. Our method's
effectiveness and performance are demonstrated through simulated case studies.

</details>


### [228] [Gentle Object Retraction in Dense Clutter Using Multimodal Force Sensing and Imitation Learning](https://arxiv.org/abs/2508.19476)
*Dane Brouwer,Joshua Citron,Heather Nolte,Jeannette Bohg,Mark Cutkosky*

Main category: cs.RO

TL;DR: 研究人员利用模仿学习训练机器人从拥挤环境中抓取物体，并研究了触觉和力传感在其中的作用。结果表明，结合触觉和力传感可以显著提高抓取成功率、减少不必要的力并缩短抓取时间。


<details>
  <summary>Details</summary>
Motivation: 研究人员旨在解决机器人从日常生活中常见的密集可移动物体集合中安全取出物体所面临的挑战，并模拟人类通过非抓取性触觉感知来实现这一目标。

Method: 研究人员使用模仿学习来训练机器人策略，从在随机生成的场景中获得的演示中学习。他们还进行了不同的实验，以评估力传感（来自关节力矩的接触力矩）和触觉传感（非抓取性三轴触觉传感）在实现机器人抓取任务中的作用，并将结果与仅使用“眼在手中”视觉、本体感觉和成功抓取测量作为基线的策略进行了比较。

Result: 结果表明，使用任何力传感的策略都比没有力传感的基线策略表现更好，表现为更少的过度用力、更高的总体成功率和更快的完成时间。结合触觉和力传感的策略表现最佳，成功率提高了 80%。

Conclusion: 研究证明，在机器人抓取任务中结合使用触觉和力传感能够显著提高性能，这表明在机器人技术中模仿人类的感知方式可以带来更好的结果。

Abstract: Dense collections of movable objects are common in everyday spaces -- from
cabinets in a home to shelves in a warehouse. Safely retracting objects from
such collections is difficult for robots, yet people do it easily, using
non-prehensile tactile sensing on the sides and backs of their hands and arms.
We investigate the role of such sensing for training robots to gently reach
into constrained clutter and extract objects. The available sensing modalities
are (1) "eye-in-hand" vision, (2) proprioception, (3) non-prehensile triaxial
tactile sensing, (4) contact wrenches estimated from joint torques, and (5) a
measure of successful object acquisition obtained by monitoring the vacuum line
of a suction cup. We use imitation learning to train policies from a set of
demonstrations on randomly generated scenes, then conduct an ablation study of
wrench and tactile information. We evaluate each policy's performance across 40
unseen environment configurations. Policies employing any force sensing show
fewer excessive force failures, an increased overall success rate, and faster
completion times. The best performance is achieved using both tactile and
wrench information, producing an 80% improvement above the baseline without
force information.

</details>


### [229] [DATR: Diffusion-based 3D Apple Tree Reconstruction Framework with Sparse-View](https://arxiv.org/abs/2508.19508)
*Tian Qiu,Alan Zoubi,Yiyuan Lin,Ruiming Du,Lailiang Cheng,Yu Jiang*

Main category: cs.RO

TL;DR: 本研究提出了一种名为DATR的两阶段框架，用于从稀疏视图中重建苹果树的三维模型，解决了现有方法在现场条件下因视图稀疏和遮挡而遇到的困难。DATR首先利用传感器和基础模型生成树木掩码，然后结合扩散模型和大型重建模型进行三维重建，并通过在真实和合成数据集上的评估，证明其在精度和效率上均优于现有方法，展现了其在农业数字孪生领域的潜力。


<details>
  <summary>Details</summary>
Motivation: 现有三维重建方法在现场条件下，尤其是在视图稀疏和遮挡的情况下，难以实现高几何精度的重建，限制了数字孪生在农业领域的应用。

Method: DATR框架包含两个阶段：第一阶段利用传感器和基础模型生成树木掩码，过滤背景信息；第二阶段使用扩散模型和大型重建模型（LRM）进行多视图和隐式神经场生成。通过Real2Sim数据生成器生成合成数据进行模型训练。

Result: DATR框架在真实和合成数据集上均优于现有三维重建方法，其域特征估计与工业级激光扫描仪相当，同时吞吐量提高了约360倍。

Conclusion: DATR框架能够从稀疏视图中高精度地重建苹果树，并在效率上取得显著提升，为构建可扩展的农业数字孪生系统提供了有力支持。

Abstract: Digital twin applications offered transformative potential by enabling
real-time monitoring and robotic simulation through accurate virtual replicas
of physical assets. The key to these systems is 3D reconstruction with high
geometrical fidelity. However, existing methods struggled under field
conditions, especially with sparse and occluded views. This study developed a
two-stage framework (DATR) for the reconstruction of apple trees from sparse
views. The first stage leverages onboard sensors and foundation models to
semi-automatically generate tree masks from complex field images. Tree masks
are used to filter out background information in multi-modal data for the
single-image-to-3D reconstruction at the second stage. This stage consists of a
diffusion model and a large reconstruction model for respective multi view and
implicit neural field generation. The training of the diffusion model and LRM
was achieved by using realistic synthetic apple trees generated by a Real2Sim
data generator. The framework was evaluated on both field and synthetic
datasets. The field dataset includes six apple trees with field-measured ground
truth, while the synthetic dataset featured structurally diverse trees.
Evaluation results showed that our DATR framework outperformed existing 3D
reconstruction methods across both datasets and achieved domain-trait
estimation comparable to industrial-grade stationary laser scanners while
improving the throughput by $\sim$360 times, demonstrating strong potential for
scalable agricultural digital twin systems.

</details>


### [230] [A Lightweight Crowd Model for Robot Social Navigation](https://arxiv.org/abs/2508.19595)
*Maryam Kazemi Eskeri,Thomas Wiedemann,Ville Kyrki,Dominik Baumann,Tomasz Piotr Kucner*

Main category: cs.RO

TL;DR: 该论文提出了一种轻量级、实时的宏观人群预测模型，用于机器人导航，在提高预测准确性的同时，将推理时间减少了3.6倍。


<details>
  <summary>Details</summary>
Motivation: 为了使机器人在人流密集的区域安全高效地导航，需要实时预测人群的移动以避开拥堵区域。然而，传统模型在处理密集人群时面临计算成本高昂的问题，而现有的宏观预测模型则过于简单或计算密集。

Method: 提出了一种简化的、实时的宏观人群预测模型，该模型基于行人流的固有特性简化了空间和时间处理，从而在没有复杂架构的情况下实现了鲁棒的泛化。

Result: 实验证明，该模型将推理时间减少了3.6倍，同时将预测准确性提高了3.1%。

Conclusion: 高效的人群建模能够使机器人在没有高昂计算成本的情况下，在密集环境中导航。

Abstract: Robots operating in human-populated environments must navigate safely and
efficiently while minimizing social disruption. Achieving this requires
estimating crowd movement to avoid congested areas in real-time. Traditional
microscopic models struggle to scale in dense crowds due to high computational
cost, while existing macroscopic crowd prediction models tend to be either
overly simplistic or computationally intensive. In this work, we propose a
lightweight, real-time macroscopic crowd prediction model tailored for human
motion, which balances prediction accuracy and computational efficiency. Our
approach simplifies both spatial and temporal processing based on the inherent
characteristics of pedestrian flow, enabling robust generalization without the
overhead of complex architectures. We demonstrate a 3.6 times reduction in
inference time, while improving prediction accuracy by 3.1 %. Integrated into a
socially aware planning framework, the model enables efficient and socially
compliant robot navigation in dynamic environments. This work highlights that
efficient human crowd modeling enables robots to navigate dense environments
without costly computations.

</details>


### [231] [Impedance Primitive-augmented Hierarchical Reinforcement Learning for Sequential Tasks](https://arxiv.org/abs/2508.19607)
*Amin Berjaoui Tahmaz,Ravi Prakash,Jens Kober*

Main category: cs.RO

TL;DR: 该论文提出了一种增强了阻抗原语的层次强化学习框架，用于在序列接触任务中进行高效的机器人操作。该框架利用层次结构，顺序执行具有可变刚度控制能力的行为原语。其关键组成部分包括：支持可变刚度控制的动作空间、用于在原语执行期间动态调整刚度的自适应刚度控制器，以及用于高效探索和鼓励顺应性的可供性耦合。通过广泛的训练和评估，该框架学习了高效的刚度控制能力，并在学习效率、原语选择的组合性以及成功率方面优于现有技术。训练环境包括了块状物提升、开门、物体推动和表面清洁。实际评估进一步证实了该框架的仿真到现实（sim2real）能力。该工作为更具适应性和通用性的机器人操作系统奠定了基础，并有望应用于更复杂的基于接触的任务。


<details>
  <summary>Details</summary>
Motivation: 机器人需要在序列接触任务中高效地进行操作，需要具备可变刚度控制的能力。

Method: 提出了一种增强了阻抗原语的层次强化学习框架，包含支持可变刚度控制的动作空间、自适应刚度控制器和可供性耦合。

Result: 在块状物提升、开门、物体推动和表面清洁等任务中，所提出的框架学习了高效的刚度控制能力，并在学习效率、原语选择的组合性以及成功率方面优于现有技术。实际评估也证实了其仿真到现实（sim2real）能力。

Conclusion: 该框架为更具适应性和通用性的机器人操作系统奠定了基础，有望应用于更复杂的基于接触的任务。

Abstract: This paper presents an Impedance Primitive-augmented hierarchical
reinforcement learning framework for efficient robotic manipulation in
sequential contact tasks. We leverage this hierarchical structure to
sequentially execute behavior primitives with variable stiffness control
capabilities for contact tasks. Our proposed approach relies on three key
components: an action space enabling variable stiffness control, an adaptive
stiffness controller for dynamic stiffness adjustments during primitive
execution, and affordance coupling for efficient exploration while encouraging
compliance. Through comprehensive training and evaluation, our framework learns
efficient stiffness control capabilities and demonstrates improvements in
learning efficiency, compositionality in primitive selection, and success rates
compared to the state-of-the-art. The training environments include block
lifting, door opening, object pushing, and surface cleaning. Real world
evaluations further confirm the framework's sim2real capability. This work lays
the foundation for more adaptive and versatile robotic manipulation systems,
with potential applications in more complex contact-based tasks.

</details>


### [232] [Autonomous Aerial Manipulation at Arbitrary Pose in SE(3) with Robust Control and Whole-body Planning](https://arxiv.org/abs/2508.19608)
*Dongjae Lee,Byeongjun Kim,H. Jin Kim*

Main category: cs.RO

TL;DR: 该论文提出了一种用于全向空中机械臂（OAM）的几何鲁棒控制和全身运动规划框架，允许其在任意姿态下悬停，从而扩展了操作范围并实现了此前不可行的操作任务。


<details>
  <summary>Details</summary>
Motivation: 为了扩展传统多旋翼空中机械臂的操作范围并克服其在小俯仰角下的限制，本研究旨在实现空中机械臂在任意姿态下的稳定悬停和操作。

Method: 提出了一种用于浮动基座的几何鲁棒控制器，以解决机械臂运动和交互力对基座稳定性的影响。设计了一个两步优化的全身运动规划器，联合考虑基座位姿和机械臂关节角度，以实现实时操作和优化收敛。

Result: 所提出的框架能够使基座在任意六维位姿下保持稳定，并自主执行复杂的操作任务，即使在接近90度甚至180度的俯仰角下也能在障碍物附近安全地进行抓取和拉动操作。

Conclusion: 实验证明，该框架能够使全向空中机械臂在各种场景下（包括大俯仰角）精确、安全地执行抓取和拉动等操作任务。

Abstract: Aerial manipulators based on conventional multirotors can conduct
manipulation only in small roll and pitch angles due to the underactuatedness
of the multirotor base. If the multirotor base is capable of hovering at
arbitrary orientation, the robot can freely locate itself at any point in
$\mathsf{SE}(3)$, significantly extending its manipulation workspace and
enabling a manipulation task that was originally not viable. In this work, we
present a geometric robust control and whole-body motion planning framework for
an omnidirectional aerial manipulator (OAM). To maximize the strength of OAM,
we first propose a geometric robust controller for a floating base. Since the
motion of the robotic arm and the interaction forces during manipulation affect
the stability of the floating base, the base should be capable of mitigating
these adverse effects while controlling its 6D pose. We then design a two-step
optimization-based whole-body motion planner, jointly considering the pose of
the floating base and the joint angles of the robotic arm to harness the entire
configuration space. The devised two-step approach facilitates real-time
applicability and enhances convergence of the optimization problem with
non-convex and non-Euclidean search space. The proposed approach enables the
base to be stationary at any 6D pose while autonomously carrying out
sophisticated manipulation near obstacles without any collision. We demonstrate
the effectiveness of the proposed framework through experiments in which an OAM
performs grasping and pulling of an object in multiple scenarios, including
near $90^\circ$ and even $180^\circ$ pitch angles.

</details>


### [233] [Efficient Human-Aware Task Allocation for Multi-Robot Systems in Shared Environments](https://arxiv.org/abs/2508.19731)
*Maryam Kazemi Eskeri,Ville Kyrki,Dominik Baumann,Tomasz Piotr Kucner*

Main category: cs.RO

TL;DR: 该研究提出了一种名为'method name'的新型多机器人任务分配（MRTA）方法，该方法考虑了人类动态移动对任务执行时间的影响，通过利用'Maps of Dynamics（MoDs）'模型来优化任务分配，实验结果显示该方法可将任务完成时间最多缩短26%。


<details>
  <summary>Details</summary>
Motivation: 现有MRTA方法忽略了人类移动对任务执行时间的影响，导致效率低下。本研究旨在解决这一问题，提高多机器人系统在有人类共享环境中的任务分配效率。

Method: 提出了一种名为'method name'的新方法，该方法利用'Maps of Dynamics（MoDs）'（一种时空可查询模型）来捕捉历史人类移动模式，并将其整合到一个包含MoDs的随机成本函数中，以估计人类对任务执行时间的影响。

Result: 实验结果表明，与忽略动态因素的方法相比，集成MoDs的方法将任务分配性能提高了26%；与基线方法相比，则提高了19%。

Conclusion: 在有人类存在的共享环境中，考虑人类动态因素对于MRTA至关重要。本研究提出的框架能够有效地在有人类活动的环境中部署多机器人系统。

Abstract: Multi-robot systems are increasingly deployed in applications, such as
intralogistics or autonomous delivery, where multiple robots collaborate to
complete tasks efficiently. One of the key factors enabling their efficient
cooperation is Multi-Robot Task Allocation (MRTA). Algorithms solving this
problem optimize task distribution among robots to minimize the overall
execution time. In shared environments, apart from the relative distance
between the robots and the tasks, the execution time is also significantly
impacted by the delay caused by navigating around moving people. However, most
existing MRTA approaches are dynamics-agnostic, relying on static maps and
neglecting human motion patterns, leading to inefficiencies and delays. In this
paper, we introduce \acrfull{method name}. This method leverages Maps of
Dynamics (MoDs), spatio-temporal queryable models designed to capture
historical human movement patterns, to estimate the impact of humans on the
task execution time during deployment. \acrshort{method name} utilizes a
stochastic cost function that includes MoDs. Experimental results show that
integrating MoDs enhances task allocation performance, resulting in reduced
mission completion times by up to $26\%$ compared to the dynamics-agnostic
method and up to $19\%$ compared to the baseline. This work underscores the
importance of considering human dynamics in MRTA within shared environments and
presents an efficient framework for deploying multi-robot systems in
environments populated by humans.

</details>


### [234] [Elliptical K-Nearest Neighbors -- Path Optimization via Coulomb's Law and Invalid Vertices in C-space Obstacles](https://arxiv.org/abs/2508.19771)
*Liding Zhang,Zhenshan Bing,Yu Zhang,Kuanqi Cai,Lingyun Chen,Fan Wu,Sami Haddadin,Alois Knoll*

Main category: cs.RO

TL;DR: FDIT*是一种基于采样的路径规划器，通过利用无效顶点中的信息并结合物理力学（如库仑定律），提高在高维空间中的路径规划速度和成本效益。


<details>
  <summary>Details</summary>
Motivation: 为了解决高维运动规划中的挑战，本研究引入了FDIT*。

Method: FDIT*在EIT*的基础上，利用无效顶点信息，结合物理力学（特别是库仑定律），并提出了一种椭圆k近邻搜索方法，以提高搜索效率和收敛速度。

Result: FDIT*在R^4到R^16的空间中，相比现有的单查询、基于采样的方法，在所测试的问题上表现更优，并在真实的移动操作任务中得到了验证。

Conclusion: FDIT*通过融合无效顶点数据和物理动力学，利用基于力方向的搜索区域，提高了收敛到最优解的速度，在高维、受限环境中尤其有效。

Abstract: Path planning has long been an important and active research area in
robotics. To address challenges in high-dimensional motion planning, this study
introduces the Force Direction Informed Trees (FDIT*), a sampling-based planner
designed to enhance speed and cost-effectiveness in pathfinding. FDIT* builds
upon the state-of-the-art informed sampling planner, the Effort Informed Trees
(EIT*), by capitalizing on often-overlooked information in invalid vertices. It
incorporates principles of physical force, particularly Coulomb's law. This
approach proposes the elliptical $k$-nearest neighbors search method, enabling
fast convergence navigation and avoiding high solution cost or infeasible paths
by exploring more problem-specific search-worthy areas. It demonstrates
benefits in search efficiency and cost reduction, particularly in confined,
high-dimensional environments. It can be viewed as an extension of nearest
neighbors search techniques. Fusing invalid vertex data with physical dynamics
facilitates force-direction-based search regions, resulting in an improved
convergence rate to the optimum. FDIT* outperforms existing single-query,
sampling-based planners on the tested problems in R^4 to R^16 and has been
demonstrated on a real-world mobile manipulation task.

</details>


### [235] [Tree-Based Grafting Approach for Bidirectional Motion Planning with Local Subsets Optimization](https://arxiv.org/abs/2508.19776)
*Liding Zhang,Yao Ling,Zhenshan Bing,Fan Wu,Sami Haddadin,Alois Knoll*

Main category: cs.RO

TL;DR: G3T*是一种新的路径规划器，通过修剪无效连接并使用GuILD子集进行贪婪优化，实现了快速收敛和低成本解决方案。


<details>
  <summary>Details</summary>
Motivation: 解决双向运动规划中由于懒惰反向搜索的限制而导致的连接失败和搜索重启问题。

Method: G3T*采用贪婪方法，利用最小Lebesgue测量的GuILD子集进行优化，并通过动态调整采样分布来实现渐近最优性。

Result: G3T*在从R^2到R^8的基准实验和机器人评估中，相比现有规划器表现出更优的性能，收敛速度更快，解决方案成本更低。

Conclusion: G3T*通过其独特的修剪和优化机制，能够有效地解决双向运动规划中的挑战，并在各种维度和实际应用中展现出优越的性能。

Abstract: Bidirectional motion planning often reduces planning time compared to its
unidirectional counterparts. It requires connecting the forward and reverse
search trees to form a continuous path. However, this process could fail and
restart the asymmetric bidirectional search due to the limitations of
lazy-reverse search. To address this challenge, we propose Greedy GuILD
Grafting Trees (G3T*), a novel path planner that grafts invalid edge
connections at both ends to re-establish tree-based connectivity, enabling
rapid path convergence. G3T* employs a greedy approach using the minimum
Lebesgue measure of guided incremental local densification (GuILD) subsets to
optimize paths efficiently. Furthermore, G3T* dynamically adjusts the sampling
distribution between the informed set and GuILD subsets based on historical and
current cost improvements, ensuring asymptotic optimality. These features
enhance the forward search's growth towards the reverse tree, achieving faster
convergence and lower solution costs. Benchmark experiments across dimensions
from R^2 to R^8 and real-world robotic evaluations demonstrate G3T*'s superior
performance compared to existing single-query sampling-based planners. A video
showcasing our experimental results is available at:
https://youtu.be/3mfCRL5SQIU

</details>


### [236] [Context-Aware Risk Estimation in Home Environments: A Probabilistic Framework for Service Robots](https://arxiv.org/abs/2508.19788)
*Sena Ishii,Akash Chikhalikar,Ankit A. Ravankar,Jose Victorio Salazar Luces,Yasuhisa Hirata*

Main category: cs.RO

TL;DR: 该研究提出了一种在室内场景中估计事故多发区域的新框架，通过语义图和风险传播算法，提升了服务机器人在人居环境中的风险意识和安全性。


<details>
  <summary>Details</summary>
Motivation: 随着机器人日益融入家庭生活，预测和响应环境危害对于确保用户安全、信任和有效人机交互至关重要。

Method: 提出一个框架，通过语义图-based传播算法对物体进行建模，风险根据空间邻近性和事故关系从高风险物体不对称地传播到低风险物体。

Result: 在包含人工标注风险区域的数据集上进行了验证，二元风险检测准确率达到75%，与人类感知高度一致，尤其是在涉及尖锐或不稳定的物体时。

Conclusion: 该框架通过情境感知的风险推理，增强了机器人的场景理解和主动安全行为，为未来做出情境驱动的安全决策、提供实时警报或自主协助用户避免/减轻家庭环境中危害的系统奠定了基础。

Abstract: We present a novel framework for estimating accident-prone regions in
everyday indoor scenes, aimed at improving real-time risk awareness in service
robots operating in human-centric environments. As robots become integrated
into daily life, particularly in homes, the ability to anticipate and respond
to environmental hazards is crucial for ensuring user safety, trust, and
effective human-robot interaction. Our approach models object-level risk and
context through a semantic graph-based propagation algorithm. Each object is
represented as a node with an associated risk score, and risk propagates
asymmetrically from high-risk to low-risk objects based on spatial proximity
and accident relationship. This enables the robot to infer potential hazards
even when they are not explicitly visible or labeled. Designed for
interpretability and lightweight onboard deployment, our method is validated on
a dataset with human-annotated risk regions, achieving a binary risk detection
accuracy of 75%. The system demonstrates strong alignment with human
perception, particularly in scenes involving sharp or unstable objects. These
results underline the potential of context-aware risk reasoning to enhance
robotic scene understanding and proactive safety behaviors in shared
human-robot spaces. This framework could serve as a foundation for future
systems that make context-driven safety decisions, provide real-time alerts, or
autonomously assist users in avoiding or mitigating hazards within home
environments.

</details>


### [237] [APT*: Asymptotically Optimal Motion Planning via Adaptively Prolated Elliptical R-Nearest Neighbors](https://arxiv.org/abs/2508.19790)
*Liding Zhang,Sicheng Wang,Kuanqi Cai,Zhenshan Bing,Fan Wu,Chaoqun Wang,Sami Haddadin,Alois Knoll*

Main category: cs.RO

TL;DR: APT*是一种新的基于采样的运动规划器，通过自适应批处理大小和椭圆r-最近邻模块来动态调整路径搜索过程，并在高维空间和机器人操作任务中优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有的最优路径规划方法通常采用固定的批处理大小并忽略了特定于问题的障碍物信息，而APT*通过整合自适应批处理大小和基于力的邻近样本选择来解决这些问题。

Method: APT*通过整合自适应批处理大小和椭圆r-最近邻模块来动态调整路径搜索过程，并根据环境反馈来优化搜索。

Result: APT*在4到16维空间中优于现有的单查询采样规划器，并在实际机器人操作任务中得到了验证。

Conclusion: APT*通过自适应地调整搜索过程，能够在大范围的维度中提高路径规划的效率和质量。

Abstract: Optimal path planning aims to determine a sequence of states from a start to
a goal while accounting for planning objectives. Popular methods often
integrate fixed batch sizes and neglect information on obstacles, which is not
problem-specific. This study introduces Adaptively Prolated Trees (APT*), a
novel sampling-based motion planner that extends based on Force Direction
Informed Trees (FDIT*), integrating adaptive batch-sizing and elliptical
$r$-nearest neighbor modules to dynamically modulate the path searching process
based on environmental feedback. APT* adjusts batch sizes based on the
hypervolume of the informed sets and considers vertices as electric charges
that obey Coulomb's law to define virtual forces via neighbor samples, thereby
refining the prolate nearest neighbor selection. These modules employ
non-linear prolate methods to adaptively adjust the electric charges of
vertices for force definition, thereby improving the convergence rate with
lower solution costs. Comparative analyses show that APT* outperforms existing
single-query sampling-based planners in dimensions from $\mathbb{R}^4$ to
$\mathbb{R}^{16}$, and it was further validated through a real-world robot
manipulation task. A video showcasing our experimental results is available at:
https://youtu.be/gCcUr8LiEw4

</details>


### [238] [A Standing Support Mobility Robot for Enhancing Independence in Elderly Daily Living](https://arxiv.org/abs/2508.19816)
*Ricardo J. Manríquez-Cisterna,Ankit A. Ravankar,Jose V. Salazar Luces,Takuro Hatsukari,Yasuhisa Hirata*

Main category: cs.RO

TL;DR: Moby是一款旨在提高老年人独立性和安全性的站立式移动机器人，通过提供站立支撑，减轻身体负担，促进社交互动，增强自我效能感，并提供被动和主动的移动支持，以实现更独立地完成日常任务。


<details>
  <summary>Details</summary>
Motivation: 本研究旨在开发一款名为Moby的站立式移动机器人，以提高老年人在如厕转移等日常活动中的独立性和安全性，解决传统坐式辅助工具的局限性。

Method: Moby机器人利用机器人操作系统（ROS）进行控制，集成NAV2和LiDAR实现导航。采用自定义控制系统实现安全直观的交互，并具备手动和自主操作模式。研究中将Moby与现有解决方案进行比较，并采用NASA-TLX方法和时间比较等实验方法进行验证。

Result: 实验结果表明，Moby在易用性、轻量化设计、舒适性、多功能性和有效的坐到站辅助方面具有优势，验证了其设计标准并展示了其贡献。

Conclusion: Moby机器人为老年人提供了一种新颖的站立式移动解决方案，通过支持自然站立姿势，有效提升了老年人的独立性、安全感和生活质量。

Abstract: This paper presents a standing support mobility robot "Moby" developed to
enhance independence and safety for elderly individuals during daily activities
such as toilet transfers. Unlike conventional seated mobility aids, the robot
maintains users in an upright posture, reducing physical strain, supporting
natural social interaction at eye level, and fostering a greater sense of
self-efficacy. Moby offers a novel alternative by functioning both passively
and with mobility support, enabling users to perform daily tasks more
independently. Its main advantages include ease of use, lightweight design,
comfort, versatility, and effective sit-to-stand assistance. The robot
leverages the Robot Operating System (ROS) for seamless control, featuring
manual and autonomous operation modes. A custom control system enables safe and
intuitive interaction, while the integration with NAV2 and LiDAR allows for
robust navigation capabilities. This paper reviews existing mobility solutions
and compares them to Moby, details the robot's design, and presents objective
and subjective experimental results using the NASA-TLX method and time
comparisons to other methods to validate our design criteria and demonstrate
the advantages of our contribution.

</details>


### [239] [FARM: Frame-Accelerated Augmentation and Residual Mixture-of-Experts for Physics-Based High-Dynamic Humanoid Control](https://arxiv.org/abs/2508.19926)
*Tan Jing,Shiting Chen,Yangfan Li,Weisheng Xu,Renjing Xu*

Main category: cs.RO

TL;DR: FARM是一个端到端的框架，通过帧加速增强、鲁棒的基础控制器和残差专家混合（MoE）来解决机器人和角色动画中低动态和高动态动作的控制难题，提高了跟踪精度，并发布了首个高动态人形运动（HDHM）数据集。


<details>
  <summary>Details</summary>
Motivation: 统一的基于物理的人形控制器在温和的日常运动中表现良好，但在爆发性动作中会遇到困难，阻碍了实际部署。需要一个能够同时处理低动态和高动态动作的控制器。

Method: FARM框架包含三个部分：1. 帧加速增强：通过扩大帧间距来暴露模型于高速度姿态变化。2. 鲁棒的基础控制器：可靠地跟踪低动态运动。3. 残差专家混合（MoE）：自适应地分配额外的网络容量来处理具有挑战性的高动态动作。

Result: 在HDHM数据集上，FARM将跟踪失败率降低了42.8%，并将全局平均每关节位置误差降低了14.6%，同时在低动态运动上保持了近乎完美的准确性。

Conclusion: FARM框架是高动态人形控制的新基准，解决了现有模型在处理爆发性动作方面的不足，并推出了首个专注于此挑战的开放数据集HDHM。

Abstract: Unified physics-based humanoid controllers are pivotal for robotics and
character animation, yet models that excel on gentle, everyday motions still
stumble on explosive actions, hampering real-world deployment. We bridge this
gap with FARM (Frame-Accelerated Augmentation and Residual Mixture-of-Experts),
an end-to-end framework composed of frame-accelerated augmentation, a robust
base controller, and a residual mixture-of-experts (MoE). Frame-accelerated
augmentation exposes the model to high-velocity pose changes by widening
inter-frame gaps. The base controller reliably tracks everyday low-dynamic
motions, while the residual MoE adaptively allocates additional network
capacity to handle challenging high-dynamic actions, significantly enhancing
tracking accuracy. In the absence of a public benchmark, we curate the
High-Dynamic Humanoid Motion (HDHM) dataset, comprising 3593 physically
plausible clips. On HDHM, FARM reduces the tracking failure rate by 42.8\% and
lowers global mean per-joint position error by 14.6\% relative to the baseline,
while preserving near-perfect accuracy on low-dynamic motions. These results
establish FARM as a new baseline for high-dynamic humanoid control and
introduce the first open benchmark dedicated to this challenge. The code and
dataset will be released at https://github.com/Colin-Jing/FARM.

</details>


### [240] [Divide, Discover, Deploy: Factorized Skill Learning with Symmetry and Style Priors](https://arxiv.org/abs/2508.19953)
*Rafael Cathomen,Mayank Mittal,Marin Vlastelica,Marco Hutter*

Main category: cs.RO

TL;DR: 使用模块化框架进行无监督技能发现，以提高真实机器人应用中的安全性、可解释性和可部署性。


<details>
  <summary>Details</summary>
Motivation: 解决当前无监督技能发现（USD）方法在真实机器人应用中安全性、可解释性和可部署性方面存在的挑战。

Method: 提出一种模块化USD框架，通过用户定义的状
态空间因子分解来学习分离的技能表示，并为每个因子分配不同的技能发现算法。引入基于对称性的归纳偏置以获得结构化的、可感知的技能，并加入风格因子和正则化惩罚来提高行为的安全性和鲁棒性。

Result: 在四足机器人模拟环境中评估框架，并将学习到的技能零样本迁移到真实硬件。结果表明，因子分解和对称性能够发现结构化的、可解释的行为，而风格因子和惩罚提高了安全性和多样性。学习到的技能可用于下游任务，并且表现与使用手工设计奖励训练的预言机策略相当。

Conclusion: 因子分解、对称性、风格因子和正则化惩罚的结合，可以有效地提高无监督技能发现方法在真实机器人应用中的性能和安全性。

Abstract: Unsupervised Skill Discovery (USD) allows agents to autonomously learn
diverse behaviors without task-specific rewards. While recent USD methods have
shown promise, their application to real-world robotics remains underexplored.
In this paper, we propose a modular USD framework to address the challenges in
the safety, interpretability, and deployability of the learned skills. Our
approach employs user-defined factorization of the state space to learn
disentangled skill representations. It assigns different skill discovery
algorithms to each factor based on the desired intrinsic reward function. To
encourage structured morphology-aware skills, we introduce symmetry-based
inductive biases tailored to individual factors. We also incorporate a style
factor and regularization penalties to promote safe and robust behaviors. We
evaluate our framework in simulation using a quadrupedal robot and demonstrate
zero-shot transfer of the learned skills to real hardware. Our results show
that factorization and symmetry lead to the discovery of structured
human-interpretable behaviors, while the style factor and penalties enhance
safety and diversity. Additionally, we show that the learned skills can be used
for downstream tasks and perform on par with oracle policies trained with
hand-crafted rewards.

</details>


### [241] [Long-VLA: Unleashing Long-Horizon Capability of Vision Language Action Model for Robot Manipulation](https://arxiv.org/abs/2508.19958)
*Yiguo Fan,Pengxiang Ding,Shuanghao Bai,Xinyang Tong,Yuyang Zhu,Hongchao Lu,Fengqi Dai,Wei Zhao,Yang Liu,Siteng Huang,Zhaoxin Fan,Badong Chen,Donglin Wang*

Main category: cs.RO

TL;DR: Long-VLA是首个用于长程机器人任务的端到端VLA模型，通过新颖的阶段感知输入掩码策略来处理技能链接和子任务依赖，并在L-CALVIN基准上取得了显著成果。


<details>
  <summary>Details</summary>
Motivation: 现有VLA框架在长程、多步机器人操作方面存在局限性，难以处理技能链接和子任务依赖。本研究旨在解决这一问题。

Method: 提出Long-VLA，一个端到端的VLA模型，采用新颖的阶段感知输入掩码策略，将子任务自适应地分割为移动和交互阶段，使模型能够专注于与阶段相关的感知线索，增强子任务兼容性。该模块可集成到现有VLA模型中。提出L-CALVIN基准用于评估长程操作。

Result: 在模拟和真实世界任务上的大量实验表明，Long-VLA显著优于现有最先进的方法，为长程机器人控制设定了新的基准。

Conclusion: Long-VLA是第一个专门为长程机器人任务设计的端到端VLA模型，通过其阶段感知输入掩码策略有效解决了技能链接和子任务依赖问题，并在L-CALVIN基准的评估中表现出色，为长程机器人控制带来了新的突破。

Abstract: Vision-Language-Action (VLA) models have become a cornerstone in robotic
policy learning, leveraging large-scale multimodal data for robust and scalable
control. However, existing VLA frameworks primarily address short-horizon
tasks, and their effectiveness on long-horizon, multi-step robotic manipulation
remains limited due to challenges in skill chaining and subtask dependencies.
In this work, we introduce Long-VLA, the first end-to-end VLA model
specifically designed for long-horizon robotic tasks. Our approach features a
novel phase-aware input masking strategy that adaptively segments each subtask
into moving and interaction phases, enabling the model to focus on
phase-relevant sensory cues and enhancing subtask compatibility. This unified
strategy preserves the scalability and data efficiency of VLA training, and our
architecture-agnostic module can be seamlessly integrated into existing VLA
models. We further propose the L-CALVIN benchmark to systematically evaluate
long-horizon manipulation. Extensive experiments on both simulated and
real-world tasks demonstrate that Long-VLA significantly outperforms prior
state-of-the-art methods, establishing a new baseline for long-horizon robotic
control.

</details>


### [242] [Visio-Verbal Teleimpedance Interface: Enabling Semi-Autonomous Control of Physical Interaction via Eye Tracking and Speech](https://arxiv.org/abs/2508.20037)
*Henk H. A. Jekel,Alejandro Díaz Rosales,Luka Peternel*

Main category: cs.RO

TL;DR: 该论文提出了一种结合操作员注视和语音交互的视听遥操作接口，用于控制远程机器人以实现3D刚度椭球。


<details>
  <summary>Details</summary>
Motivation: 该研究旨在通过结合操作员的视觉焦点和语音指令，来改进对远程机器人刚度控制的交互方式。

Method: 该接口利用眼动追踪技术检测操作员的注视点，并结合视觉语言模型（VLM）处理语音指令，从而生成用于物理交互的刚度矩阵。

Result: 通过在包含Kuka LBR iiwa机器人和Force Dimension Sigma.7触觉设备的实验中，研究验证了该接口的有效性，并通过滑槽任务展示了其功能。

Conclusion: 该视听遥操作接口能够有效地让操作员通过注视和语音指令来控制远程机器人的3D刚度椭球。

Abstract: The paper presents a visio-verbal teleimpedance interface for commanding 3D
stiffness ellipsoids to the remote robot with a combination of the operator's
gaze and verbal interaction. The gaze is detected by an eye-tracker, allowing
the system to understand the context in terms of what the operator is currently
looking at in the scene. Along with verbal interaction, a Visual Language Model
(VLM) processes this information, enabling the operator to communicate their
intended action or provide corrections. Based on these inputs, the interface
can then generate appropriate stiffness matrices for different physical
interaction actions. To validate the proposed visio-verbal teleimpedance
interface, we conducted a series of experiments on a setup including a Force
Dimension Sigma.7 haptic device to control the motion of the remote Kuka LBR
iiwa robotic arm. The human operator's gaze is tracked by Tobii Pro Glasses 2,
while human verbal commands are processed by a VLM using GPT-4o. The first
experiment explored the optimal prompt configuration for the interface. The
second and third experiments demonstrated different functionalities of the
interface on a slide-in-the-groove task.

</details>


### [243] [HERMES: Human-to-Robot Embodied Learning from Multi-Source Motion Data for Mobile Dexterous Manipulation](https://arxiv.org/abs/2508.20085)
*Zhecheng Yuan,Tianming Wei,Langzhe Gu,Pu Hua,Tianhai Liang,Yuanpei Chen,Huazhe Xu*

Main category: cs.RO

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Leveraging human motion data to impart robots with versatile manipulation
skills has emerged as a promising paradigm in robotic manipulation.
Nevertheless, translating multi-source human hand motions into feasible robot
behaviors remains challenging, particularly for robots equipped with
multi-fingered dexterous hands characterized by complex, high-dimensional
action spaces. Moreover, existing approaches often struggle to produce policies
capable of adapting to diverse environmental conditions. In this paper, we
introduce HERMES, a human-to-robot learning framework for mobile bimanual
dexterous manipulation. First, HERMES formulates a unified reinforcement
learning approach capable of seamlessly transforming heterogeneous human hand
motions from multiple sources into physically plausible robotic behaviors.
Subsequently, to mitigate the sim2real gap, we devise an end-to-end, depth
image-based sim2real transfer method for improved generalization to real-world
scenarios. Furthermore, to enable autonomous operation in varied and
unstructured environments, we augment the navigation foundation model with a
closed-loop Perspective-n-Point (PnP) localization mechanism, ensuring precise
alignment of visual goals and effectively bridging autonomous navigation and
dexterous manipulation. Extensive experimental results demonstrate that HERMES
consistently exhibits generalizable behaviors across diverse, in-the-wild
scenarios, successfully performing numerous complex mobile bimanual dexterous
manipulation tasks. Project Page:https:/gemcollector.github.io/HERMES/.

</details>


### [244] [Discrete-Guided Diffusion for Scalable and Safe Multi-Robot Motion Planning](https://arxiv.org/abs/2508.20095)
*Jinhao Liang,Sven Koenig,Ferdinando Fioretto*

Main category: cs.RO

TL;DR: 该论文提出了一种名为离散引导扩散（DGD）的新型多机器人运动规划框架，结合了离散MAPF求解器和约束生成扩散模型，以克服现有方法的局限性。


<details>
  <summary>Details</summary>
Motivation: 解决传统离散MAPF方法因粗粒度离散化导致轨迹质量受限，以及连续优化方法因维度灾难导致的可扩展性差的问题。

Method: DGD框架将非凸MRMP问题分解为具有凸构型空间的子问题，并结合离散MAPF解决方案、约束优化技术和轻量级约束修复机制来指导扩散模型，以捕捉机器人之间的时空依赖性并确保轨迹可行性。

Result: DGD在大型复杂环境中达到了新的最先进性能，可扩展至100个机器人，并实现了规划效率和高成功率。

Conclusion: DGD框架通过整合离散MAPF和约束生成扩散模型，有效解决了多机器人运动规划中的可扩展性和轨迹质量问题，并在大规模复杂环境中取得了优异表现。

Abstract: Multi-Robot Motion Planning (MRMP) involves generating collision-free
trajectories for multiple robots operating in a shared continuous workspace.
While discrete multi-agent path finding (MAPF) methods are broadly adopted due
to their scalability, their coarse discretization severely limits trajectory
quality. In contrast, continuous optimization-based planners offer
higher-quality paths but suffer from the curse of dimensionality, resulting in
poor scalability with respect to the number of robots. This paper tackles the
limitations of these two approaches by introducing a novel framework that
integrates discrete MAPF solvers with constrained generative diffusion models.
The resulting framework, called Discrete-Guided Diffusion (DGD), has three key
characteristics: (1) it decomposes the original nonconvex MRMP problem into
tractable subproblems with convex configuration spaces, (2) it combines
discrete MAPF solutions with constrained optimization techniques to guide
diffusion models capture complex spatiotemporal dependencies among robots, and
(3) it incorporates a lightweight constraint repair mechanism to ensure
trajectory feasibility. The proposed method sets a new state-of-the-art
performance in large-scale, complex environments, scaling to 100 robots while
achieving planning efficiency and high success rates.

</details>


<div id='eess.SY'></div>

# eess.SY [[Back]](#toc)

### [245] [Privacy-Preserving Distributed Control for a Networked Battery Energy Storage System](https://arxiv.org/abs/2508.19345)
*Mihitha Maithripala,Zongli Lin*

Main category: eess.SY

TL;DR: 该论文提出了一种新的分布式控制算法，用于在分布式储能系统（BESS）中实现荷电状态（SoC）平衡，同时保护用户隐私。


<details>
  <summary>Details</summary>
Motivation: 随着分布式储能系统（BESS）在电网中部署的增加，需要有效的协调策略来平衡SoC和进行精确的功率输送。然而，分布式控制框架在提供可扩展性和弹性的同时，也因需要代理间的信息交换而引发了隐私问题。

Method: 提出了一种新的隐私保护分布式控制算法，用于网络化BESS中的SoC平衡。该框架包括一个基于两个隐私保护分布式估计器的分布式功率分配律：一个用于平均单元状态，另一个用于平均期望功率。平均单元状态估计器通过状态分解方法设计，无需披露敏感的内部状态。

Result: 所提出的功率分配律确保了渐近的SoC平衡和全局功率输送，同时保护了代理隐私免受外部窃听者侵害。

Conclusion: 仿真结果证明了所提出的控制策略的有效性和隐私保护特性。

Abstract: The increasing deployment of distributed Battery Energy Storage Systems
(BESSs) in modern power grids necessitates effective coordination strategies to
ensure state-of-charge (SoC) balancing and accurate power delivery. While
distributed control frameworks offer scalability and resilience, they also
raise significant privacy concerns due to the need for inter-agent information
exchange. This paper presents a novel privacy-preserving distributed control
algorithm for SoC balancing in a networked BESS. The proposed framework
includes distributed power allocation law that is designed based on two
privacy-preserving distributed estimators, one for the average unit state and
the other for the average desired power. The average unit state estimator is
designed via the state decomposition method without disclosing sensitive
internal states. The proposed power allocation law based on these estimators
ensures asymptotic SoC balancing and global power delivery while safeguarding
agent privacy from external eavesdroppers. The effectiveness and
privacy-preserving properties of the proposed control strategy are demonstrated
through simulation results.

</details>


### [246] [Set-membership identification of continuous-time MIMO systems via Tustin discretization](https://arxiv.org/abs/2508.19348)
*Vito Cerone,Sophie M. Fosson,Simone Pirrera,Diego Regruto*

Main category: eess.SY

TL;DR: 本研究提出一种基于集合成员技术和Tustin离散化方法，用于从包含未知但有界误差的采样数据中识别连续时间系统，解决了导数测量问题和所有测量信号中的有界误差问题。


<details>
  <summary>Details</summary>
Motivation: 识别连续时间系统中的一个重要挑战是估计输入和输出数据的导数。

Method: 提出一种基于集合成员技术和Tustin离散化方法，该方法克服了导数测量问题以及影响所有测量信号的有界误差问题。

Result: 该方法被证明可以转化为可行的多项式优化问题，并通过仿真和实验数据进行了数值结果的展示。

Conclusion: 所提出的方法能够有效地处理包含有界误差的采样数据，并成功解决了连续时间系统识别中的导数测量难题。

Abstract: In this paper, we deal with the identification of continuous-time systems
from sampled data corrupted by unknown but bounded errors. A significant
challenge in continuous-time identification is the estimation of the input and
output data derivatives. In this paper, we propose a novel method based on
set-membership techniques and Tustin discretization, which overcomes the
derivative measurement problem and the presence of bounded errors affecting all
the measured signals. First, we derive the proposed method and prove that it
becomes an affordable polynomial optimization problem. Then, we present some
numerical results based on simulation and experimental data to explore the
effectiveness of the proposed method.

</details>


### [247] [Towards Reliable Neural Optimizers: Permutation-Equivariant Neural Approximation in Dynamic Data Driven Applications Systems](https://arxiv.org/abs/2508.19364)
*Meiyi Li,Javad Mohammadi*

Main category: eess.SY

TL;DR: LOOP-PE是一种用于动态数据驱动应用程序系统(DDDAS)的优化方法，该方法采用前馈神经网络和可行性恢复函数，能够处理来自传感器网络的流式、异构和异步数据。


<details>
  <summary>Details</summary>
Motivation: DDDAS需要能够适应流式、异构和异步数据的优化方法，而传统的迭代优化算法（如分支定界、梯度下降和牛顿-拉弗森方法）在这种环境下速度太慢。

Method: LOOP-PE（Learning to Optimize the Optimization Process, Permutation Equivariance version）是一种前馈神经网络近似模型，集成了可行性恢复函数。它采用排列等变架构，确保输入数据重新排序时，相应的调度决策也一致地重新排序，而无需重新训练或预对齐。可行性通过广义规范映射得到保证，确保输出满足物理和操作约束。

Result: 在虚拟发电厂（VPP）的案例研究中，LOOP-PE在动态、无序和分布式传感条件下，能够生成接近最优、可行且高度适应的决策，其速度和灵活性显著优于基于迭代算法的求解器。

Conclusion: LOOP-PE的设计和操作提供了对可行性保证和排列等变特性的深入分析和解释，证明了其在DDDAS环境中的有效性。

Abstract: Dynamic Data Driven Applications Systems (DDDAS) motivate the development of
optimization approaches capable of adapting to streaming, heterogeneous, and
asynchronous data from sensor networks. Many established optimization solvers,
such as branch-and-bound, gradient descent, and Newton-Raphson methods, rely on
iterative algorithms whose step-by-step convergence makes them too slow for
real-time, multi-sensor environments. In our recent work, we introduced LOOP-PE
(Learning to Optimize the Optimization Process, Permutation Equivariance
version), a feed-forward neural approximation model with an integrated
feasibility recovery function. LOOP-PE processes inputs from a variable number
of sensors in arbitrary order, making it robust to sensor dropout,
communication delays, and system scaling. Its permutation-equivariant
architecture ensures that reordering the input data reorders the corresponding
dispatch decisions consistently, without retraining or pre-alignment.
Feasibility is enforced via a generalized gauge map, guaranteeing that outputs
satisfy physical and operational constraints. We illustrate the approach in a
DDDAS-inspired case study of a Virtual Power Plant (VPP) managing multiple
distributed generation agents (DERs) to maximize renewable utilization while
respecting system limits. Results show that LOOP-PE produces near-optimal,
feasible, and highly adaptable decisions under dynamic, unordered, and
distributed sensing conditions, significantly outperforming iterative algorithm
based solvers in both speed and flexibility. Here, we extend our earlier work
by providing additional analysis and explanation of LOOP-PE design and
operation, with particular emphasis on its feasibility guarantee and
permutation equivariance feature.

</details>


### [248] [Climate-Resilient Ports and Waterborne Transport Systems: Current Status and Future Prospects](https://arxiv.org/abs/2508.19387)
*Nadia Pourmohammad-Zia,Mark van Koningsveld*

Main category: eess.SY

TL;DR: 该论文系统性地审查了水上运输系统在气候变化下的复原力，重点关注港口及其连接系统，指出了当前研究中在供应链复原力、特定气候事件（如干旱）、以及先进技术（如数字孪生、人工智能）应用方面的不足，并提出应采用基于系统的综合方法，结合协作框架和先进工具来加强风险管理和长期规划。


<details>
  <summary>Details</summary>
Motivation: 气候变化对水上运输系统，特别是港口及其连接系统，带来了日益严峻的挑战，因此有必要全面研究其气候适应能力。

Method: 通过系统性文献回顾，识别了现有研究在港口基础设施、供应链复原力、气候事件影响、研究方法和技术应用方面的关键差距与机遇。

Result: 研究发现，现有文献侧重于港口基础设施而非供应链复原力，对干旱和复合性事件等具体气候扰动关注不足，且高级技术应用滞后。研究在地理分布和规划时间尺度上也存在不均衡。此外，对港口和水上运输系统气候复原力的综合性审查，特别是专门针对此主题的审查，仍然有限。

Conclusion: 为了应对这些差距，研究主张采用基于系统的综合方法，整合基础设施、运营和供应链，并强调利用数字孪生、机器学习和参与式建模等先进工具和协作框架，以实现预测性和适应性风险管理，从而增强水上运输系统抵御多种气候影响的能力。

Abstract: The increasing challenges posed by climate change necessitate a comprehensive
examination of the resilience of waterborne transport systems. This paper
explores the nexus of climate resilience, and waterborne transport, addressing
the challenges faced by ports and their connecting waterborne transport
systems. It provides an in-depth analysis of the current status of
climate-resilient infrastructure and operations while emphasizing the
transformative potential of emerging technologies. Through a systematic review,
the paper identifies critical gaps and opportunities. Research predominantly
emphasizes port infrastructure over supply chain resilience, neglecting the
interconnected vulnerabilities of maritime networks. There is limited focus on
specific climate-induced disruptions, such as drought and compounded events,
which complicate resilience planning. Methodologically, risk assessments and
case studies dominate the field, while advanced technologies such as digital
twins, artificial intelligence, and satellite monitoring remain underutilized.
Geographic disparities in research output and a tendency toward short- to
medium-term planning further constrain global and long-term resilience efforts.
To address these gaps, the study advocates for systems-based approaches that
integrate infrastructure, operations, and supply chains. It highlights
collaborative frameworks and advanced tools, including digital twins, machine
learning, and participatory modeling, as crucial for enabling predictive and
adaptive risk management. This study stands as one of the first comprehensive
reviews exclusively focused on climate resilience in ports and waterborne
transport systems. It provides actionable insights for policymakers,
researchers, and industry stakeholders, proposing a future research agenda to
advance waterborne transport systems capable of withstanding multifaceted
climate impacts.

</details>


### [249] [Learning Robust Regions of Attraction Using Rollout-Enhanced Physics-Informed Neural Networks with Policy Iteration](https://arxiv.org/abs/2508.19398)
*Junkai Wang,Yuxuan Zhao,Mi Zhou,Fumin Zhang*

Main category: eess.SY

TL;DR: 该论文提出一种基于物理信息神经网络的框架，用于求解广义Zubov方程，以表征受扰动系统的鲁棒吸引域。


<details>
  <summary>Details</summary>
Motivation: 计算受扰动系统的鲁棒吸引域，该吸引域由广义Zubov方程的解表征。

Method: 提出一种物理信息神经网络框架，采用策略迭代训练方案和模拟来近似粘性解。在策略改进过程中计算最优扰动，并结合神经网络价值估计作为锚点，以防止低维和高维系统中的奇异性。

Result: 数值模拟验证了该方法的有效性。

Conclusion: 该方法能够有效地近似广义Zubov方程的粘性解，从而表征受扰动系统的鲁棒吸引域。

Abstract: The region of attraction is a key metric of the robustness of systems. This
paper addresses the numerical solution of the generalized Zubov's equation,
which produces a special Lyapunov function characterizing the robust region of
attraction for perturbed systems. To handle the highly nonlinear characteristic
of the generalized Zubov's equation, we propose a physics-informed neural
network framework that employs a policy iteration training scheme with rollout
to approximate the viscosity solution. In addition to computing the optimal
disturbance during the policy improvement process, we incorporate neural
network-generated value estimates as anchor points to facilitate the training
procedure to prevent singularities in both low- and high-dimensional systems.
Numerical simulations validate the effectiveness of the proposed approach.

</details>


### [250] [Comparison of Droop-Based Single-Loop Grid-Forming Wind Turbines: High-Frequency Open-Loop Unstable Behavior and Damping](https://arxiv.org/abs/2508.19401)
*Meng Chen,Yufei Xi,Lin Cheng,Xiongfei Wang,Ioannis Lestas*

Main category: eess.SY

TL;DR: 本文比较了两种常用的并网逆变器基于沥青控制的电网形成控制策略：沥青控制和沥青-I控制在风力发电机中的应用。研究发现，沥青-I控制会改变高频极点的位置，并可能导致系统在高频开环下不稳定，而传统的对数裕度等稳定裕度指标无法评估这种不稳定性。此外，传统的有源阻尼方法可能无法有效抑制沥青-I控制下的高频谐振。


<details>
  <summary>Details</summary>
Motivation: 现代电力系统接入了更多基于逆变器的发电单元，带来了新的不稳定性问题。因此，需要分析和比较不同的控制策略以保障电力系统的稳定性。

Method: 本文采用开环分析和具体事例分析的方法，首先对沥青控制和沥青-I控制在高频下的稳定性进行了比较，然后评估了有源阻尼技术在两种控制策略下的性能。

Result: 研究结果表明，沥青-I控制在高频开环下是不稳定的，并且这种不稳定性无法通过调整参数来解决。同时，有源阻尼技术在沥青-I控制下可能失效。

Conclusion: 高频开环不稳定性是影响电力系统稳定性的一个关键因素，传统的稳定裕度评估方法不足以应对基于逆变器的发电单元带来的新挑战。

Abstract: The integration of inverter-interfaced generators introduces new instability
phenomena into modern power systems. This paper conducts a comparative analysis
of two widely used droop-based grid-forming controls, namely droop control and
droop-I control, in wind turbines. Although both approaches provide
steady-state reactive power-voltage droop characteristics, their impacts on
high-frequency (HF) stability differ significantly. Firstly, on open-loop (OL)
comparison reveals that droop-I control alters HF pole locations. The
application of Routh's Stability Criterion further analytically demonstrates
that such pole shifts inevitably lead to OL instability. This HF OL instability
is identified as a structural phenomenon in purely inductive grids and cannot
be mitigated through control parameter tuning. As a result, droop-I control
significantly degrades HF stability, making conventional gain and phase margins
insufficient for evaluating robustness against parameter variations. Then, the
performance of established active damping (AD) is assessed for both control
schemes. The finding indicates that AD designs effective for droop control may
fail to suppress HF resonance under droop-I control due to the presence of
unstable OL poles. Case studies performed on the IEEE 14-Bus Test System
validate the analysis and emphasize the critical role of HF OL instability in
determining the overall power system stability.

</details>


### [251] [Hybrid ML-RL Approach for Smart Grid Stability Prediction and Optimized Control Strategy](https://arxiv.org/abs/2508.19541)
*Kazi Sifatul Islam,Anandi Dutta,Shivani Mruthyunjaya*

Main category: eess.SY

TL;DR: This paper proposes a hybrid ML-RL framework for electrical grid stability prediction and control. ML models predict instability, and RL optimizes control actions. The framework shows improved performance, rapid convergence, and reduced training time for real-time smart grid applications.


<details>
  <summary>Details</summary>
Motivation: The increasing complexity of electrical grids due to distributed generation and alternative energy sources necessitates effective forecasting of grid stability and optimized control for operators. Traditional models have limitations in optimal strategy control with instability prediction.

Method: A hybrid ML-RL framework is proposed. The first stage uses ML (stacking classifiers) for rapid stability prediction. The second stage employs RL algorithms (PPO, A2C, DQN) for dynamic control and optimization of power control actions.

Result: Experimental results demonstrate that the hybrid ML-RL model effectively stabilizes the grid, achieves rapid convergence, and significantly reduces training time. It enhances decision-making efficiency and lowers computational complexity.

Conclusion: The integration of ML-based stability classification with RL-based dynamic control provides a robust solution for real-time smart grid applications, improving stability, efficiency, and reducing computational load.

Abstract: Electrical grids are now much more complex due to the rapid integration of
distributed generation and alternative energy sources, which makes forecasting
grid stability with optimized control a crucial task for operators. Traditional
statistical, physics-based, and ML models can learn the pattern of the grid
features, but have limitations in optimal strategy control with instability
prediction. This work proposes a hybrid ML-RL framework that leverages ML for
rapid stability prediction and RL for dynamic control and optimization. The
first stage of this study created a baseline that explored the potential of
various ML models for stability prediction. Out of them, the stacking
classifiers of several fundamental models show a significant performance in
classifying the instability, leading to the second stage, where reinforcement
learning algorithms (PPO, A2C, and DQN) optimize power control actions.
Experimental results demonstrate that the hybrid ML-RL model effectively
stabilizes the grid, achieves rapid convergence, and significantly reduces
training time. The integration of ML-based stability classification with
RL-based dynamic control enhances decision-making efficiency while lowering
computational complexity, making it well-suited for real-time smart grid
applications.

</details>


### [252] [Symbolic Equation Modeling of Composite Loads: A Kolmogorov-Arnold Network based Learning Approach](https://arxiv.org/abs/2508.19612)
*Sonam Dorji,Yongkang Sun,Yuchen Zhang,Ghavameddin Nourbakhsh,Yateendra Mishra,Yan Xu*

Main category: eess.SY

TL;DR: 该论文提出了一种基于Kolmogorov Arnold Networks (KANs)的新型学习型负荷建模方法，以解决分布式能源接入引起的复合负荷建模需求，并兼顾灵活性和可解释性。


<details>
  <summary>Details</summary>
Motivation: 随着分布式能源接入的增加，需要准确的复合负荷模型来支持电力系统仿真分析。现有的基于测量的负荷建模方法要么依赖于固定结构的物理模型，适应性有限；要么采用灵活但缺乏可解释性的机器学习方法。

Method: 提出一种基于KANs的学习型负荷建模方法，通过学习激活函数来自动推导出捕捉变量间非线性关系的自由形式的符号方程，无需预设负荷结构。

Result: 与现有方法相比，该方法在准确性和泛化能力方面表现更优，并且能够将复合负荷表示为透明、可解释的数学方程。

Conclusion: 该方法成功地实现了复合负荷的灵活且可解释的建模，为电力系统分析提供了新的解决方案。

Abstract: With increasing penetration of distributed energy resources installed behind
the meter, there is a growing need for adequate modelling of composite loads to
enable accurate power system simulation analysis. Existing measurement based
load modeling methods either fit fixed-structure physical models, which limits
adaptability to evolving load mixes, or employ flexible machine learning
methods which are however black boxes and offer limited interpretability. This
paper presents a new learning based load modelling method based on Kolmogorov
Arnold Networks towards modelling flexibility and interpretability. By actively
learning activation functions on edges, KANs automatically derive free form
symbolic equations that capture nonlinear relationships among measured
variables without prior assumptions about load structure. Case studies
demonstrate that the proposed approach outperforms other methods in both
accuracy and generalization ability, while uniquely representing composite
loads into transparent, interpretable mathematical equations.

</details>


### [253] [Large Language Models (LLMs) for Electronic Design Automation (EDA)](https://arxiv.org/abs/2508.20030)
*Kangwei Xu,Denis Schwachhofer,Jason Blocklove,Ilia Polian,Peter Domanski,Dirk Pflüger,Siddharth Garg,Ramesh Karri,Ozgur Sinanoglu,Johann Knechtel,Zhuorui Zhao,Ulf Schlichtmann,Bing Li*

Main category: eess.SY

TL;DR: LLMs are a promising tool for accelerating and simplifying hardware design workflows, with demonstrated capabilities in design, testing, and optimization, though challenges and future opportunities remain.


<details>
  <summary>Details</summary>
Motivation: The increasing complexity of integrated circuits and the labor-intensive, error-prone nature of the design-to-manufacturing workflow necessitate more efficient EDA solutions. LLMs offer a promising avenue for simplification and automation due to their advancements in text-based contextual comprehension, logical reasoning, and generation.

Method: This paper provides a comprehensive overview of incorporating LLMs into EDA, discussing their capabilities, limitations, and future opportunities. It includes three case studies demonstrating LLM applications in hardware design, testing, and optimization.

Result: The paper demonstrates the potential of LLMs through case studies in hardware design, testing, and optimization, highlighting their capabilities in accelerating and simplifying the EDA workflow.

Conclusion: LLMs present a promising opportunity to shape the next generation of EDA by simplifying and automating hardware development. Further research into future directions and challenges is needed to fully realize their potential.

Abstract: With the growing complexity of modern integrated circuits, hardware engineers
are required to devote more effort to the full design-to-manufacturing
workflow. This workflow involves numerous iterations, making it both
labor-intensive and error-prone. Therefore, there is an urgent demand for more
efficient Electronic Design Automation (EDA) solutions to accelerate hardware
development. Recently, large language models (LLMs) have shown remarkable
advancements in contextual comprehension, logical reasoning, and generative
capabilities. Since hardware designs and intermediate scripts can be
represented as text, integrating LLM for EDA offers a promising opportunity to
simplify and even automate the entire workflow. Accordingly, this paper
provides a comprehensive overview of incorporating LLMs into EDA, with emphasis
on their capabilities, limitations, and future opportunities. Three case
studies, along with their outlook, are introduced to demonstrate the
capabilities of LLMs in hardware design, testing, and optimization. Finally,
future directions and challenges are highlighted to further explore the
potential of LLMs in shaping the next-generation EDA, providing valuable
insights for researchers interested in leveraging advanced AI technologies for
EDA.

</details>


### [254] [Low-Cost Architecture and Efficient Pattern Synthesis for Polarimetric Phased Array Based on Polarization Coding Reconfigurable Elements](https://arxiv.org/abs/2508.19644)
*Yiqing Wang,Jian Zhou,Chen Pang,Wenyang Man,Zixiang Xiong,Ke Meng,Zhanling Wang,Yongzhen Li*

Main category: eess.SY

TL;DR: 本文提出了一种极化编码可重构相控阵（PCRPA）及其相关的模式综合技术，旨在降低极化相控阵（PPA）的成本并最小化性能损失。PCRPA通过单收发（T/R）通道和两级射频开关实现极化状态和波形的实时控制，能够生成任意极化和双极化波束。仿真结果表明，PCRPA在扫描范围内实现了与传统结构相当的低交叉极化和旁瓣电平，尤其适用于大型阵列。实验验证了该系统的有效性，PCRPA在成本效益和性能方面具有优势，特别适合大规模PPA系统。


<details>
  <summary>Details</summary>
Motivation: 为了降低极化相控阵（PPA）的成本和系统复杂性，解决了其双收发（T/R）通道要求带来的高成本问题。

Method: 提出了一种极化编码可重构相控阵（PCRPA）及其相关的模式综合技术。PCRPA的每个单元连接到单个T/R通道，并包含两级射频开关，用于实时控制极化状态和波形。通过调整单元编码和激励权重，PCRPA能够生成任意极化和双极化波束。提出了高效的波束模式综合方法，其中包含源于PCRPA理论和分析的优化约束。

Result: 仿真表明，该方法在扫描范围内实现了与传统结构相当的低交叉极化和旁瓣电平，尤其适用于大型阵列。但通道减少不可避免地会带来功率和方向性损失。实验验证了该系统在8x8 X波段阵列天线上的有效性。

Conclusion: PCRPA及其综合方法非常适合大规模PPA系统，在保持良好旁瓣抑制和极化控制性能的同时，显著提高了成本效益。

Abstract: Polarimetric phased arrays (PPAs) enhance radar target detection and
anti-jamming capabilities. However, the dual transmit/receive (T/R) channel
requirement leads to high costs and system complexity. To address this, this
paper introduces a polarization-coding reconfigurable phased array (PCRPA) and
associated pattern synthesis techniques to reduce PPA costs while minimizing
performance degradation. Each PCRPA element connects to a single T/R channel
and incorporates two-level RF switches for real-time control of polarization
states and waveforms. By adjusting element codes and excitation weights, the
PCRPA can generate arbitrarily polarized and dual-polarized beams. Efficient
beam pattern synthesis methods are also proposed, featuring novel optimization
constraints derived from theoretical and analytical analysis of PCRPAs.
Simulations demonstrate that the approach achieves low cross-polarization and
sidelobe levels comparable to conventional architectures within the scan range,
particularly for large arrays. However, the channel reduction inevitably incurs
power and directivity loss. Experiments conducted on an $8\times 8$ X-band
array antenna validate the effectiveness of the proposed system. The PCRPA and
synthesis methods are well-suited for large-scale PPA systems, offering
significant cost-effectiveness while maintaining good sidelobe suppression and
polarization control performance.

</details>


### [255] [Distributed Safety-Critical MPC for Multi-Agent Formation Control and Obstacle Avoidance](https://arxiv.org/abs/2508.19678)
*Chao Wang,Shuyuan Zhang,Lei Wang*

Main category: eess.SY

TL;DR: 本文提出了一种新颖的分布式安全关键模型预测控制（DSMPC）算法，该算法结合了离散时间高阶控制障碍函数（DHCBFs）和离散时间控制Lyapunov函数（DCLFs），用于解决高相对度非线性多智能体系统的分布式编队控制和避障问题。


<details>
  <summary>Details</summary>
Motivation: 解决高相对度非线性多智能体系统在分布式编队控制和避障方面存在的挑战。

Method: 提出一种结合DHCBFs和DCLFs的DSMPC算法，通过估计邻居状态来促进分布式实现，并引入界约束来限制估计误差以确保收敛性。

Result: 仿真结果表明，与现有方法相比，所提出的DSMPC算法在性能和计算时间方面均有所提高。

Conclusion: 所提出的DSMPC算法能够有效地解决高相对度非线性多智能体系统的分布式编队控制和避障问题，并具有可行性和稳定性保证。

Abstract: For nonlinear multi-agent systems with high relative degrees, achieving
formation control and obstacle avoidance in a distributed manner remains a
significant challenge. To address this issue, we propose a novel distributed
safety-critical model predictive control (DSMPC) algorithm that incorporates
discrete-time high-order control barrier functions (DHCBFs) to enforce safety
constraints, alongside discrete-time control Lyapunov functions (DCLFs) to
establish terminal constraints. To facilitate distributed implementation, we
develop estimated neighbor states for formulating DHCBFs and DCLFs, while also
devising a bound constraint to limit estimation errors and ensure convergence.
Additionally, we provide theoretical guarantees regarding the feasibility and
stability of the proposed DSMPC algorithm based on a mild assumption. The
effectiveness of the proposed method is evidenced by the simulation results,
demonstrating improved performance and reduced computation time compared to
existing approaches.

</details>


### [256] [Uncertainty-Based Perturb and Observe for Fast Optimization of Unknown, Time-Varying Processes](https://arxiv.org/abs/2508.19756)
*Leontine Aarnoudse,Mark Haring,Nathan van de Wouw,Alexey Pavlov*

Main category: eess.SY

TL;DR: 该论文提出了一种新的扰动与观察（P&O）方法，旨在减少模型无关自适应优化中的扰动，同时保持对时变最优值的快速和准确跟踪。


<details>
  <summary>Details</summary>
Motivation: 传统的模型无关自适应优化方法在优化未知、时变过程方面能力很强，但其应用常受限于用于收集信息（关于成本及其梯度）的扰动。本论文旨在开发一种扰动与观察（P&O）方法，以减少对这类扰动的需求。

Method: 开发了一种（时变）成本模型，该模型以在线方式构建，考虑了测量性能成本的不确定性以及旧测量值可靠性的下降。只有当预期在一定时间范围内能带来性能提升时，才使用扰动。论文提供了收敛条件，在这些条件下，该策略收敛到最优值附近。

Result: 仿真结果表明，基于不确定性的P&O方法可以显著减少扰动的数量，同时仍然能够准确跟踪时变最优值。

Conclusion: 所提出的基于不确定性的P&O方法能够有效减少模型无关自适应优化中的扰动数量，同时保持对时变最优值的准确跟踪。

Abstract: Model-free adaptive optimization methods are capable of optimizing unknown,
time-varying processes even when other optimization methods are not. However,
their practical application is often limited by perturbations that are used to
gather information on the unknown cost and its gradient. The aim of this paper
is to develop a perturb-and-observe (P&O) method that reduces the need for such
perturbations while still achieving fast and accurate tracking of time-varying
optima. To this end, a (time-varying) model of the cost is constructed in an
online fashion, taking into account the uncertainty on the measured performance
cost as well as the decreasing reliability of older measurements. Perturbations
are only used when this is expected to lead to improved performance over a
certain time horizon. Convergence conditions are provided under which the
strategy converges to a neighborhood of the optimum. Finally, simulation
results demonstrate that uncertainty-based P\&O can reduce the number of
perturbations significantly while still tracking a time-varying optimum
accurately.

</details>


### [257] [Limited Preemption of the 3-Phase Task Model using Preemption Thresholds](https://arxiv.org/abs/2508.19760)
*Thilanka Thilakasiri,Matthias Becker*

Main category: eess.SY

TL;DR: Phased execution models improve COTS multi-core platform predictability. Limited preemption with preemption thresholds balances local memory usage and schedulability, outperforming fully preemptive and non-preemptive approaches in evaluations.


<details>
  <summary>Details</summary>
Motivation: To address the trade-offs between schedulability and local memory usage in phased execution models for COTS multi-core platforms, specifically by introducing a limited preemption approach.

Method: Propose using preemption thresholds to limit preemptions, minimizing local memory usage while maintaining schedulability. Develop a worst-case response time and memory requirement analysis for sporadic 3-phase tasks under partitioned fixed-priority scheduling with preemption thresholds. Adapt a state-of-the-art algorithm for assigning preemption thresholds.

Result: Preemption thresholds reduce memory usage by 2.5x compared to fully preemptive scheduling and maintain 13x higher schedulability ratios compared to non-preemptive scheduling.

Conclusion: Preemption thresholds offer a promising approach to effectively manage local memory usage and maintain high schedulability in phased execution models on COTS multi-core systems.

Abstract: Phased execution models are a well-known solution to tackle the
unpredictability of today's complex COTS multi-core platforms. The semantics of
these models dedicate phases for a task's execution and shared memory accesses.
Memory phases are solely dedicated to load all necessary instructions and data
to private local memory, and to write back the results of the computation.
During execution phases, only the private local memory is accessed. While
non-preemptive execution phases utilize the local memory well, schedulability
is reduced due to blocking. On the other hand, fully preemptive execution
phases allow for better schedulability, but require local memory to be large
enough to hold all tasks involved in preemption simultaneously. Limited
preemption is a promising approach that provides moderation between
non-preemptive and fully preemptive scheduling.
  In this paper, we propose using preemption thresholds to limit the number of
preemptions to minimize local memory usage while maintaining schedulability. We
propose a worst-case response time and a worst-case memory requirement analysis
for sporadic 3-phase tasks under partitioned fixed-priority scheduling with
preemption thresholds. We further show how the state-of-the-art algorithm to
assign preemption thresholds can be applied to the considered task model.
Evaluations demonstrate that preemption thresholds can significantly reduce the
memory usage (by $2.5\times$) compared to fully preemptive scheduling, while
maintaining high schedulability ratios ($13\times$) compared to non-preemptive
scheduling.

</details>


### [258] [Combined Stochastic and Robust Optimization for Electric Autonomous Mobility-on-Demand with Nested Benders Decomposition](https://arxiv.org/abs/2508.19933)
*Sten Elling Tingstad Jacobsen,Balázs Kulcsár,Anders Lindman*

Main category: eess.SY

TL;DR: 本研究提出了一种结合随机和鲁棒模型预测控制（MPC）的框架，用于管理电动自动驾驶出行 on-demand (EAMoD) 车队，以应对需求、时间和充电等多种不确定性。该框架集成了时空贝叶斯神经网络预测和多阶段随机优化模型，并通过嵌套Benders分解实现高效求解。


<details>
  <summary>Details</summary>
Motivation: 电动自动驾驶出行 on-demand (EAMoD) 系统的兴起对城市交通管理提出了新的挑战，特别是在需求、时间和充电等不确定性因素下，如何有效调度、平衡和充电车队。

Method: 提出了一种结合随机和鲁棒MPC的框架。该框架集成了时空贝叶斯神经网络预测和多阶段随机优化模型，并使用嵌套Benders分解进行求解。随机优化用于预测需求和基础设施变化，鲁棒约束用于保证在最坏情况下的可行性。

Result: 与确定性、反应式和鲁棒基线相比，该框架可将乘客等待时间中位数减少高达36%，将95%分位数的延迟减少近20%，同时降低27%的调度距离和超过35%的电力成本。敏感性分析表明，高能效车辆在小电池下仍能保持稳定性能。

Conclusion: 联合优化预测控制、车辆能力和基础设施规划对于实现可扩展、成本效益高的EAMoD运营至关重要。

Abstract: The electrification and automation of mobility are reshaping how cities
operate on-demand transport systems. Managing Electric Autonomous
Mobility-on-Demand (EAMoD) fleets effectively requires coordinating dispatch,
rebalancing, and charging decisions under multiple uncertainties, including
travel demand, travel time, energy consumption, and charger availability. We
address this challenge with a combined stochastic and robust model predictive
control (MPC) framework. The framework integrates spatio-temporal Bayesian
neural network forecasts with a multi-stage stochastic optimization model,
formulated as a large-scale mixed-integer linear program. To ensure real-time
applicability, we develop a tailored Nested Benders Decomposition that exploits
the scenario tree structure and enables efficient parallelized solution.
Stochastic optimization is employed to anticipate demand and infrastructure
variability, while robust constraints on energy consumption and travel times
safeguard feasibility under worst-case realizations. We evaluate the framework
using high-fidelity simulations of San Francisco and Chicago. Compared with
deterministic, reactive, and robust baselines, the combined stochastic and
robust approach reduces median passenger waiting times by up to 36% and
95th-percentile delays by nearly 20%, while also lowering rebalancing distance
by 27% and electricity costs by more than 35%. We also conduct a sensitivity
analysis of battery size and vehicle efficiency, finding that energy-efficient
vehicles maintain stable performance even with small batteries, whereas less
efficient vehicles require larger batteries and greater infrastructure support.
Our results emphasize the importance of jointly optimizing predictive control,
vehicle capabilities, and infrastructure planning to enable scalable,
cost-efficient EAMoD operations.

</details>


<div id='cs.LO'></div>

# cs.LO [[Back]](#toc)

### [259] [The Power of Regular Constraint Propagation (Technical Report)](https://arxiv.org/abs/2508.19888)
*Matthew Hague,Artur Jeż,Anthony W. Lin,Oliver Markgraf,Philipp Rümmer*

Main category: cs.LO

TL;DR: 该论文提出了一种名为“正则表达式约束传播”（RCP）的简单通用方法，用于解决字符串约束问题。RCP通过对字符串函数应用正则表达式的预/后像来推断字符串变量的可能值，直至找到冲突或确定可满足性。该方法适用于多种字符串操作，并被证明对于大量字符串约束是健全和完整的，优于现有的一些处理方法。在实践中，RCP已集成到OSTRICH字符串求解器中，显著提高了其性能，并在多个基准测试中超越了其他求解器。


<details>
  <summary>Details</summary>
Motivation: 现有字符串求解策略的复杂性促使我们研究一种更简单、更通用的方法来解决字符串约束问题。

Method: 正则表达式约束传播（RCP），通过迭代计算正则表达式在字符串函数下的预/后像来推断字符串变量的值，直至达到稳定状态（冲突或可满足性）。

Result: RCP被证明是健全和完整的，并且该方法在OSTRICH求解器中的实现显著提高了其性能，使其在随机PCP和生物信息学基准测试中优于其他求解器。

Conclusion: 正则表达式约束传播（RCP）是一种有效且通用的字符串约束求解方法，能够显著提升现有求解器的性能，并与其他技术结合使用以获得进一步的性能提升。

Abstract: The past decade has witnessed substantial developments in string solving.
Motivated by the complexity of string solving strategies adopted in existing
string solvers, we investigate a simple and generic method for solving string
constraints: regular constraint propagation. The method repeatedly computes
pre- or post-images of regular languages under the string functions present in
a string formula, inferring more and more knowledge about the possible values
of string variables, until either a conflict is found or satisfiability of the
string formula can be concluded. Such a propagation strategy is applicable to
string constraints with multiple operations like concatenation, replace, and
almost all flavors of string transductions. We demonstrate the generality and
effectiveness of this method theoretically and experimentally. On the
theoretical side, we show that RCP is sound and complete for a large fragment
of string constraints, subsuming both straight-line and chain-free constraints,
two of the most expressive decidable fragments for which some modern string
solvers provide formal completeness guarantees. On the practical side, we
implement regular constraint propagation within the open-source string solver
OSTRICH.
  Our experimental evaluation shows that this addition significantly improves
OSTRICH's performance and makes it competitive with existing solvers. In fact,
it substantially outperforms other solvers on random PCP and bioinformatics
benchmarks. The results also suggest that incorporating regular constraint
propagation alongside other techniques could lead to substantial performance
gains for existing solvers.

</details>


### [260] [Between Markov and restriction: Two more monads on categories for relations](https://arxiv.org/abs/2508.20054)
*Cipriano Junior Cioffo,Fabio Gadducci,Davide Trotta*

Main category: cs.LO

TL;DR: 本文在已有工作基础上，进一步丰富了“关系范畴”的分类，提出了两个更抽象的gs-模范畴实例，它们由质量和箭头域的公理化概念定义，并与半环加权关系范畴相关。


<details>
  <summary>Details</summary>
Motivation: 对现有“关系范畴”研究的进一步发展和丰富，提出更抽象的范畴实例。

Method: 提出两个更抽象的gs-模范畴实例，并引入质量和箭头域的概念来表征它们。证明了相关的Kleisli范畴保留了相应的方程，并且这些单子自然地出现在半环加权关系范畴中。

Result: 两个新的gs-模范畴实例被提出，它们比已有的Markov和restriction范畴更抽象，并通过质量和箭头域的公理化概念进行表征。

Conclusion: 本文提出的两个新范畴及其相关的单子，为“关系范畴”的研究提供了更广泛的视角和更丰富的结构。

Abstract: The study of categories abstracting the structural properties of relations
has been extensively developed over the years, resulting in a rich and diverse
body of work. A previous paper offered a survey providing a modern and
comprehensive presentation of these ``categories for relations'' as instances
of gs-monoidal categories, showing how they arise as Kleisli categories of
suitable symmetric monoidal monads. The end result was a taxonomy that
organised numerous related concepts in the literature, including in particular
Markov and restriction categories. This paper further enriches the taxonomy: it
proposes two categories that are once more instances of gs-monoidal categories,
yet more abstract than Markov and restriction categories. They are
characterised by an axiomatic notion of mass and domain of an arrow, the latter
one of the key ingredient of restriction categories, which generalises the
domain of partial functions. The paper then introduces mass and domain
preserving monads, proving that the associated Kleisli categories in fact
preserve the corresponding equations and that these monads arise naturally for
the categories of semiring-weighted relations.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [261] [$\mathcal{C}^1$-approximation with rational functions and rational neural networks](https://arxiv.org/abs/2508.19672)
*Erion Morina,Martin Holler*

Main category: cs.LG

TL;DR: 可以使用有理函数和有理神经网络在C^1范数下逼近正则函数，并给出了逼近率。


<details>
  <summary>Details</summary>
Motivation: 探讨有理函数和有理神经网络在C^1范数下逼近正则函数的可行性，并分析逼近率。

Method: 使用有理函数和有理神经网络进行逼近。

Result: 证明了在C^1范数下，有理函数和有理神经网络可以逼近正则函数，并得到了逼近率。

Conclusion: 该研究为有理神经网络（包括EQL^div和ParFam架构）在物理定律学习等符号回归领域提供了C^1逼近结果。

Abstract: We show that suitably regular functions can be approximated in the
$\mathcal{C}^1$-norm both with rational functions and rational neural networks,
including approximation rates with respect to width and depth of the network,
and degree of the rational functions. As consequence of our results, we further
obtain $\mathcal{C}^1$-approximation results for rational neural networks with
the $\text{EQL}^\div$ and ParFam architecture, both of which are important in
particular in the context of symbolic regression for physical law learning.

</details>


### [262] [InfraredGP: Efficient Graph Partitioning via Spectral Graph Neural Networks with Negative Corrections](https://arxiv.org/abs/2508.19737)
*Meng Qin,Weihua Li,Jinqiang Cui,Sen Pei*

Main category: cs.LG

TL;DR: InfraredGP是一种无需训练的图划分（GP）方法，利用图拉普拉斯负校正来探索超出常规范围[0, 2]的图频率，以捕捉社区结构信息。


<details>
  <summary>Details</summary>
Motivation: 探索超出常规频率范围[0, 2]的低频信息是否能编码社区结构，并提出一种无需训练的图划分方法。

Method: InfraredGP采用基于谱图神经网络（GNN）的骨干网络，结合低通滤波器和负校正机制，仅输入随机信号，通过一次前向传播（FFP）获得图嵌入，最后将嵌入输入BIRCH算法得到GP结果。

Result: InfraredGP仅通过负校正机制就能获得可区分的嵌入，并为GP提供高质量结果，无需任何训练。在静态和流式GP任务中，InfraredGP的效率比基线方法高16-23倍，同时质量具有竞争力。

Conclusion: InfraredGP通过利用图拉普拉斯负校正来探索更广泛的图频率，能够高效且高质量地完成图划分任务，并且无需训练，在效率和质量上均优于现有方法。

Abstract: Graph partitioning (GP), a.k.a. community detection, is a classic problem
that divides nodes of a graph into densely-connected blocks. From a perspective
of graph signal processing, we find that graph Laplacian with a negative
correction can derive graph frequencies beyond the conventional range $[0, 2]$.
To explore whether the low-frequency information beyond this range can encode
more informative properties about community structures, we propose InfraredGP.
It (\romannumeral1) adopts a spectral GNN as its backbone combined with
low-pass filters and a negative correction mechanism, (\romannumeral2) only
feeds random inputs to this backbone, (\romannumeral3) derives graph embeddings
via one feed-forward propagation (FFP) without any training, and
(\romannumeral4) obtains feasible GP results by feeding the derived embeddings
to BIRCH. Surprisingly, our experiments demonstrate that based solely on the
negative correction mechanism that amplifies low-frequency information beyond
$[0, 2]$, InfraredGP can derive distinguishable embeddings for some standard
clustering modules (e.g., BIRCH) and obtain high-quality results for GP without
any training. Following the IEEE HPEC Graph Challenge benchmark, we evaluate
InfraredGP for both static and streaming GP, where InfraredGP can achieve much
better efficiency (e.g., 16x-23x faster) and competitive quality over various
baselines. We have made our code public at
https://github.com/KuroginQin/InfraredGP

</details>


### [263] [Physics-Informed Regression: Parameter Estimation in Parameter-Linear Nonlinear Dynamic Models](https://arxiv.org/abs/2508.19249)
*Jonas Søeborg Nielsen,Marcus Galea Jacobsen,Albert Brincker Olson,Mads Peter Sørensen,Allan Peter Engsig-Karup*

Main category: cs.LG

TL;DR: 提出了一种基于正则化普通最小二乘法的混合参数估计算法PIR，用于估计参数线性化的非线性动力学模型的系数，并通过与PINN在流行病学模型上的比较，证明了PIR在准确性和计算速度上的优越性，并展示了其在COVID-19疫情数据上的应用。


<details>
  <summary>Details</summary>
Motivation: 提出一种新的混合参数估计算法，以解决非线性动力学模型中参数估计的效率和准确性问题，特别是利用参数线性化的模型。

Method: 提出一种名为“物理信息回归”（PIR）的数据驱动混合技术，该技术利用正则化普通最小二乘法来估计参数线性化模型中的模型系数，并将其应用于常微分方程（ODE）和偏微分方程（PDE）模型。

Result: PIR方法在估计流行病学模型参数方面表现优于PINN，尤其是在具有更高复杂性的模型中，并且在计算速度上更具优势。PIR还成功应用于估计COVID-19疫情丹麦真实数据中的时变参数。

Conclusion: PIR方法是处理参数线性化非线性动力学模型的有效且快速的参数估计工具，优于PINN，并有望支持实时参数估计。

Abstract: We present a new efficient hybrid parameter estimation method based on the
idea, that if nonlinear dynamic models are stated in terms of a system of
equations that is linear in terms of the parameters, then regularized ordinary
least squares can be used to estimate these parameters from time series data.
We introduce the term "Physics-Informed Regression" (PIR) to describe the
proposed data-driven hybrid technique as a way to bridge theory and data by use
of ordinary least squares to efficiently perform parameter estimation of the
model coefficients of different parameter-linear models; providing examples of
models based on nonlinear ordinary equations (ODE) and partial differential
equations (PDE). The focus is on parameter estimation on a selection of ODE and
PDE models, each illustrating performance in different model characteristics.
For two relevant epidemic models of different complexity and number of
parameters, PIR is tested and compared against the related technique,
physics-informed neural networks (PINN), both on synthetic data generated from
known target parameters and on real public Danish time series data collected
during the COVID-19 pandemic in Denmark. Both methods were able to estimate the
target parameters, while PIR showed to perform noticeably better, especially on
a compartment model with higher complexity. Given the difference in
computational speed, it is concluded that the PIR method is superior to PINN
for the models considered. It is also demonstrated how PIR can be applied to
estimate the time-varying parameters of a compartment model that is fitted
using real Danish data from the COVID-19 pandemic obtained during a period from
2020 to 2021. The study shows how data-driven and physics-informed techniques
may support reliable and fast -- possibly real-time -- parameter estimation in
parameter-linear nonlinear dynamic models.

</details>


### [264] [GegenNet: Spectral Convolutional Neural Networks for Link Sign Prediction in Signed Bipartite Graphs](https://arxiv.org/abs/2508.19907)
*Hewen Wang,Renchi Yang,Xiaokui Xiao*

Main category: cs.LG

TL;DR: GegenNet是一种用于有向二分图链接符号预测的新型谱卷积神经网络模型，通过其新颖的谱分解技术、Gegenbauer多项式谱滤波器和多层感知网络，在多个基准数据集上显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有方法未能充分考虑有向二分图的节点异质性和特定属性，并且基于谱卷积的传统方法主要针对无向图，不适用于预测有向二分图中的缺失链接符号。

Method: GegenNet采用（i）快速且具有理论依据的节点特征初始化谱分解技术；（ii）基于Gegenbauer多项式基的新型谱图滤波器；（iii）多层感知符号感知谱卷积网络，交替使用Gegenbauer多项式滤波器和正负链接。

Result: GegenNet在链接符号预测任务上，相比11个强大的竞争对手和6个基准数据集，在AUC方面最高提升4.28%，在F1方面最高提升11.69%。

Conclusion: GegenNet在有向二分图链接符号预测方面表现出显著优越的性能，证明了其技术贡献的有效性。

Abstract: Given a signed bipartite graph (SBG) G with two disjoint node sets U and V,
the goal of link sign prediction is to predict the signs of potential links
connecting U and V based on known positive and negative edges in G. The
majority of existing solutions towards link sign prediction mainly focus on
unipartite signed graphs, which are sub-optimal due to the neglect of node
heterogeneity and unique bipartite characteristics of SBGs. To this end, recent
studies adapt graph neural networks to SBGs by introducing message-passing
schemes for both inter-partition (UxV) and intra-partition (UxU or VxV) node
pairs. However, the fundamental spectral convolutional operators were
originally designed for positive links in unsigned graphs, and thus, are not
optimal for inferring missing positive or negative links from known ones in
SBGs.
  Motivated by this, this paper proposes GegenNet, a novel and effective
spectral convolutional neural network model for link sign prediction in SBGs.
In particular, GegenNet achieves enhanced model capacity and high predictive
accuracy through three main technical contributions: (i) fast and theoretically
grounded spectral decomposition techniques for node feature initialization;
(ii) a new spectral graph filter based on the Gegenbauer polynomial basis; and
(iii) multi-layer sign-aware spectral convolutional networks alternating
Gegenbauer polynomial filters with positive and negative edges. Our extensive
empirical studies reveal that GegenNet can achieve significantly superior
performance (up to a gain of 4.28% in AUC and 11.69% in F1) in link sign
prediction compared to 11 strong competitors over 6 benchmark SBG datasets.

</details>


### [265] [Lossless Compression of Neural Network Components: Weights, Checkpoints, and K/V Caches in Low-Precision Formats](https://arxiv.org/abs/2508.19263)
*Anat Heilper,Doron Singer*

Main category: cs.LG

TL;DR: 本文将ZipNN方法扩展到FP8和FP4等低精度浮点格式，并提出了一种分离和独立压缩指数和尾数的方法，实现了显著的模型压缩率。同时，研究了LLM的K/V缓存张量的可压缩性。


<details>
  <summary>Details</summary>
Motivation: 在深度学习模型日益增大和广泛部署的背景下，降低模型存储和传输成本至关重要。

Method: 将ZipNN方法扩展到FP8和FP4等低精度格式，设计了一种分离和独立压缩指数和尾数组件的方法，并使用熵编码进行压缩。同时，研究了K/V缓存张量的可压缩性。

Result: 实现了高达62%的BF16压缩率和83%的FP8压缩率，并发现了K/V缓存张量的可压缩模式，能够在部署时节省内存。

Conclusion: 低精度浮点格式和LLM的K/V缓存张量具有良好的可压缩性，通过改进的ZipNN方法可以实现显著的模型压缩，从而降低存储和传输成本。

Abstract: As deep learning models grow and deployment becomes more widespread, reducing
the storage and transmission costs of neural network weights has become
increasingly important. While prior work such as ZipNN has shown that lossless
compression methods - particularly those based on Huffman encoding
floating-point exponents can significantly reduce model sizes, these techniques
have primarily been applied to higher-precision formats such as FP32 and BF16.
In this work, we extend the ZipNN approach to lower-precision floating-point
formats, specifically FP8 and FP4, which are gaining popularity for efficient
inference. We design a compression method that separates and compresses the
exponent and mantissa components independently using entropy coding. Our
evaluation shows compression ratios up to 62% for BF16 and 83% for FP8. We also
investigate the compressibility of key-value (K/V) cache tensors used in large
language models (LLMs), finding that they, too, exhibit compressible patterns,
enabling memory savings during deployment.

</details>


### [266] [POT: Inducing Overthinking in LLMs via Black-Box Iterative Optimization](https://arxiv.org/abs/2508.19277)
*Xinyu Li,Tianjin Huang,Ronghui Mu,Xiaowei Huang,Gaojie Jin*

Main category: cs.LG

TL;DR: 该研究提出了一种名为POT（Prompt-Only OverThinking）的新型黑盒攻击框架，用于利用大型语言模型（LLM）的推理能力，通过生成冗长但看似自然的对抗性提示词来降低其效率，而无需访问外部知识或进行模型检索。


<details>
  <summary>Details</summary>
Motivation: 为解决现有“过度思考”攻击方法依赖外部知识、可检索的恶意内容以及结构明显的模板等局限性，提出一种更具实用性和隐蔽性的攻击框架。

Method: 利用基于LLM的迭代优化方法，生成隐蔽且语义自然的对抗性提示词，实现“提示词仅包含过度思考”。

Result: 在多种模型架构和数据集上的广泛实验表明，POT相较于其他方法具有更优越的性能。

Conclusion: POT是一种有效的黑盒攻击框架，能够生成隐蔽且语义自然的对抗性提示词，克服了现有方法的局限性，并在实验中展现出优越的性能。

Abstract: Recent advances in Chain-of-Thought (CoT) prompting have substantially
enhanced the reasoning capabilities of large language models (LLMs), enabling
sophisticated problem-solving through explicit multi-step reasoning traces.
However, these enhanced reasoning processes introduce novel attack surfaces,
particularly vulnerabilities to computational inefficiency through
unnecessarily verbose reasoning chains that consume excessive resources without
corresponding performance gains. Prior overthinking attacks typically require
restrictive conditions including access to external knowledge sources for data
poisoning, reliance on retrievable poisoned content, and structurally obvious
templates that limit practical applicability in real-world scenarios. To
address these limitations, we propose POT (Prompt-Only OverThinking), a novel
black-box attack framework that employs LLM-based iterative optimization to
generate covert and semantically natural adversarial prompts, eliminating
dependence on external data access and model retrieval. Extensive experiments
across diverse model architectures and datasets demonstrate that POT achieves
superior performance compared to other methods.

</details>


### [267] [(DEMO) Deep Reinforcement Learning Based Resource Allocation in Distributed IoT Systems](https://arxiv.org/abs/2508.19318)
*Aohan Li,Miyu Tsuzuki*

Main category: cs.LG

TL;DR: 该研究提出了一种在真实分布式物联网系统中训练深度强化学习（DRL）模型的新框架，使用来自实际数据传输的确认（ACK）信息作为反馈来优化通信信道选择，并通过帧成功率（FSR）评估了其可行性和有效性。


<details>
  <summary>Details</summary>
Motivation: 由于深度强化学习（DRL）在处理复杂决策任务方面的强大能力，它已成为资源分配的有效方法。然而，在实际的、分布式的物联网系统中，使用真实世界数据训练DRL模型的研究有限。本研究旨在弥合这一差距。

Method: 本框架提出了一种新颖的DRL模型训练方法，其中物联网设备使用基于DRL的方法选择通信信道，并通过实际数据传输获得的确认（ACK）信息对DRL模型进行训练。

Result: 通过在实际物联网环境中实现和评估该框架，并在帧成功率（FSR）方面进行了性能评估，证明了该框架的可行性和有效性。

Conclusion: 该研究提出的框架能够有效地在真实的分布式物联网环境中训练DRL模型，以优化通信信道选择，并具有良好的性能。

Abstract: Deep Reinforcement Learning (DRL) has emerged as an efficient approach to
resource allocation due to its strong capability in handling complex
decision-making tasks. However, only limited research has explored the training
of DRL models with real-world data in practical, distributed Internet of Things
(IoT) systems. To bridge this gap, this paper proposes a novel framework for
training DRL models in real-world distributed IoT environments. In the proposed
framework, IoT devices select communication channels using a DRL-based method,
while the DRL model is trained with feedback information. Specifically,
Acknowledgment (ACK) information is obtained from actual data transmissions
over the selected channels. Implementation and performance evaluation, in terms
of Frame Success Rate (FSR), are carried out, demonstrating both the
feasibility and the effectiveness of the proposed framework.

</details>


### [268] [Re:Frame -- Retrieving Experience From Associative Memory](https://arxiv.org/abs/2508.19344)
*Daniil Zelezetsky,Egor Cherepanov,Alexey K. Kovalev,Aleksandr I. Panov*

Main category: cs.LG

TL;DR: Offline RL often struggles with suboptimal data, but incorporating even a small amount of expert data can significantly improve performance. Re:Frame is a plug-in module that uses an Associative Memory Buffer (AMB) populated with expert trajectories to augment standard offline RL policies. It learns to retrieve and integrate expert data, showing substantial gains on D4RL MuJoCo tasks with minimal expert data.


<details>
  <summary>Details</summary>
Motivation: Offline RL agents struggle to generalize and achieve high performance when trained primarily on suboptimal or inconsistent trajectories due to the unavailability or impracticality of collecting large expert datasets. The challenge lies in effectively utilizing scarce expert demonstrations alongside abundant but lower-quality data.

Method: Re:Frame introduces a plug-in module that augments a standard offline RL policy with a small external Associative Memory Buffer (AMB). This AMB is populated with expert trajectories from a separate dataset. During training on low-quality data, the policy learns to retrieve expert data from the AMB through content-based associations and integrate it into decision-making. The same AMB is queried during evaluation. This method requires no environment interaction or modifications to the backbone architecture.

Result: On D4RL MuJoCo tasks, Re:Frame consistently improved performance over a strong Decision Transformer baseline in three out of four settings, achieving gains up to +10.7 normalized points. These improvements were observed using as few as 60 expert trajectories, representing only 0.1% of a 6000-trajectory dataset.

Conclusion: Re:Frame provides a simple and data-efficient approach to inject scarce expert knowledge into offline RL policies, leading to substantial improvements when learning from low-quality datasets.

Abstract: Offline reinforcement learning (RL) often deals with suboptimal data when
collecting large expert datasets is unavailable or impractical. This limitation
makes it difficult for agents to generalize and achieve high performance, as
they must learn primarily from imperfect or inconsistent trajectories. A
central challenge is therefore how to best leverage scarce expert
demonstrations alongside abundant but lower-quality data. We demonstrate that
incorporating even a tiny amount of expert experience can substantially improve
RL agent performance. We introduce Re:Frame (Retrieving Experience From
Associative Memory), a plug-in module that augments a standard offline RL
policy (e.g., Decision Transformer) with a small external Associative Memory
Buffer (AMB) populated by expert trajectories drawn from a separate dataset.
During training on low-quality data, the policy learns to retrieve expert data
from the Associative Memory Buffer (AMB) via content-based associations and
integrate them into decision-making; the same AMB is queried at evaluation.
This requires no environment interaction and no modifications to the backbone
architecture. On D4RL MuJoCo tasks, using as few as 60 expert trajectories
(0.1% of a 6000-trajectory dataset), Re:Frame consistently improves over a
strong Decision Transformer baseline in three of four settings, with gains up
to +10.7 normalized points. These results show that Re:Frame offers a simple
and data-efficient way to inject scarce expert knowledge and substantially
improve offline RL from low-quality datasets.

</details>


### [269] [Memorization in Graph Neural Networks](https://arxiv.org/abs/2508.19352)
*Adarsh Jamadandi,Jing Xu,Adam Dziedzic,Franziska Boenisch*

Main category: cs.LG

TL;DR: GNNs memorize training data, especially in low-homophily graphs, which can be mitigated by graph rewiring, reducing privacy risk.


<details>
  <summary>Details</summary>
Motivation: To quantify label memorization in semi-supervised node classification with GNNs and understand its relationship with graph properties and training dynamics, and to explore mitigation strategies.

Method: Introduced NCMemo framework to quantify memorization, analyzed the relationship between memorization and graph homophily, studied GNN training dynamics in low homophily regimes, identified node-level factors influencing memorization, and investigated graph rewiring as a mitigation technique.

Result: Established an inverse relationship between memorization and graph homophily, finding that lower homophily increases memorization as GNNs rely on it to learn less homophilic graphs. Found that increased memorization in low homophily graphs is linked to GNNs' implicit bias on using graph structure. Identified nodes with higher label inconsistency in their neighborhood as more prone to memorization. Demonstrated that graph rewiring effectively reduces memorization without compromising performance and lowers privacy risk.

Conclusion: GNN memorization is influenced by graph homophily and training dynamics. Graph rewiring is a viable method to reduce memorization and enhance privacy in GNN deployment.

Abstract: Deep neural networks (DNNs) have been shown to memorize their training data,
yet similar analyses for graph neural networks (GNNs) remain largely
under-explored. We introduce NCMemo (Node Classification Memorization), the
first framework to quantify label memorization in semi-supervised node
classification. We first establish an inverse relationship between memorization
and graph homophily, i.e., the property that connected nodes share similar
labels/features. We find that lower homophily significantly increases
memorization, indicating that GNNs rely on memorization to learn less
homophilic graphs. Secondly, we analyze GNN training dynamics. We find that the
increased memorization in low homophily graphs is tightly coupled to the GNNs'
implicit bias on using graph structure during learning. In low homophily
regimes, this structure is less informative, hence inducing memorization of the
node labels to minimize training loss. Finally, we show that nodes with higher
label inconsistency in their feature-space neighborhood are significantly more
prone to memorization. Building on our insights into the link between graph
homophily and memorization, we investigate graph rewiring as a means to
mitigate memorization. Our results demonstrate that this approach effectively
reduces memorization without compromising model performance. Moreover, we show
that it lowers the privacy risk for previously memorized data points in
practice. Thus, our work not only advances understanding of GNN learning but
also supports more privacy-preserving GNN deployment.

</details>


### [270] [Symphony: A Decentralized Multi-Agent Framework for Scalable Collective Intelligence](https://arxiv.org/abs/2508.20019)
*Ji Wang,Kashing Chen,Xinyuan Song,Ke Zhang,Lynn Ai,Eric Yang,Bill Shi*

Main category: cs.LG

TL;DR: Symphony是一个去中心化的LLM代理框架，使用户级GPU上的轻量级LLM能够进行协调，通过去中心化账本、Beacon选择协议和加权结果投票来解决中心化框架的部署成本高、适应性有限等问题，并在推理基准测试中表现优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有的基于LLM的代理框架大多采用中心化编排，导致部署成本高、通信拓扑僵化、适应性有限。Symphony旨在通过去中心化方法解决这些挑战。

Method: Symphony引入了三个关键机制：（1）记录能力的去中心化账本，（2）用于动态任务分配的Beacon选择协议，以及（3）基于思维链（CoT）的加权结果投票。

Result: 实验证明，Symphony在推理基准测试中优于现有基线，在不同容量的模型中表现出相当的准确性提升和鲁棒性。

Conclusion: Symphony通过其去中心化的设计，提供了一种隐私保护、可扩展且容错的编排方式，具有低开销的优点，并在推理任务中取得了优于现有方法的性能。

Abstract: Most existing Large Language Model (LLM)-based agent frameworks rely on
centralized orchestration, incurring high deployment costs, rigid communication
topologies, and limited adaptability. To address these challenges, we introduce
Symphony, a decentralized multi-agent system which enables lightweight LLMs on
consumer-grade GPUs to coordinate. Symphony introduces three key mechanisms:
(1) a decentralized ledger that records capabilities, (2) a Beacon-selection
protocol for dynamic task allocation, and (3) weighted result voting based on
CoTs. This design forms a privacy-saving, scalable, and fault-tolerant
orchestration with low overhead. Empirically, Symphony outperforms existing
baselines on reasoning benchmarks, achieving substantial accuracy gains and
demonstrating robustness across models of varying capacities.

</details>


### [271] [Efficient Multi-Source Knowledge Transfer by Model Merging](https://arxiv.org/abs/2508.19353)
*Marcin Osial,Bartosz Wójcik,Bartosz Zieliński,Sebastian Cygert*

Main category: cs.LG

TL;DR: 提出一种利用SVD分解和聚合来解决多源迁移学习问题的新方法，以提高效率和精度。


<details>
  <summary>Details</summary>
Motivation: 解决现有迁移学习方法在利用在线可用模型知识方面的不足，以及在细粒度知识提取和聚合效率方面的局限性。

Method: 利用SVD分解源模型为秩一分量，然后聚合最显著的分量，并通过微调聚合矩阵的主奇异值来适应目标任务。

Result: 提出的框架能够高效迁移学习，对输入和参数空间中的扰动具有鲁棒性，并且计算效率高。

Conclusion: 该方法通过SVD分解和聚合，克服了现有方法的效率和精度限制，实现了高效、鲁棒且可扩展的迁移学习。

Abstract: While transfer learning is an advantageous strategy, it overlooks the
opportunity to leverage knowledge from numerous available models online.
Addressing this multi-source transfer learning problem is a promising path to
boost adaptability and cut re-training costs. However, existing approaches are
inherently coarse-grained, lacking the necessary precision for granular
knowledge extraction and the aggregation efficiency required to fuse knowledge
from either a large number of source models or those with high parameter
counts. We address these limitations by leveraging Singular Value Decomposition
(SVD) to first decompose each source model into its elementary, rank-one
components. A subsequent aggregation stage then selects only the most salient
components from all sources, thereby overcoming the previous efficiency and
precision limitations. To best preserve and leverage the synthesized knowledge
base, our method adapts to the target task by fine-tuning only the principal
singular values of the merged matrix. In essence, this process only
recalibrates the importance of top SVD components. The proposed framework
allows for efficient transfer learning, is robust to perturbations both at the
input level and in the parameter space (e.g., noisy or pruned sources), and
scales well computationally.

</details>


### [272] [Exploration of Low-Power Flexible Stress Monitoring Classifiers for Conformal Wearables](https://arxiv.org/abs/2508.19661)
*Florentia Afentaki,Sri Sai Rakesh Nakkilla,Konstantinos Balaskas,Paula Carolina Lozano Duarte,Shiyi Jiang,Georgios Zervakis,Farshad Firouzi,Krishnendu Chakrabarty,Mehdi B. Tahoori*

Main category: cs.LG

TL;DR: 该研究首次全面探索了低功耗、柔性压力分类器的设计空间，提出了超过1200种柔性分类器，并针对硬件效率进行了优化，旨在提供比现有方法更准确、低成本、适应性强、低功耗和小型化的实时压力分类器。


<details>
  <summary>Details</summary>
Motivation: 现有压力监测方法依赖于偶发性的、以症状为中心的干预措施，无法满足持续、可及和经济高效的解决方案的需求。目前的先进方法使用僵硬的、硅基的可穿戴设备，虽然功能多样，但并非为轻量化、柔性佩戴而优化，限制了其在连续监测中的实用性。而柔性电子（FE）提供了灵活性和低制造成本，能够实现实时压力监测电路，但将机器学习（ML）分类器等复杂电路集成到FE中存在集成和功耗限制的挑战，此前针对压力检测的分类器设计研究不足。

Method: 本研究对低功耗、柔性压力分类器进行了全面的设计空间探索，涵盖了多种机器学习分类器、特征选择和神经简化算法，共设计了超过1200种柔性分类器。为了优化硬件效率，对每种情况都设计了采用低精度运算的全定制化电路。

Result: 研究结果表明，通过对机器学习分类器、特征选择和神经简化算法进行广泛探索，并采用低精度运算的全定制化电路设计，可以实现比现有方法更准确、低成本、适应性强、低功耗和小型化的实时压力分类器。

Conclusion: 本研究为设计实时压力分类器提供了宝贵的见解，其提出的柔性分类器在准确性、成本、适应性、功耗和尺寸方面均优于现有方法，解决了在柔性电子设备中集成复杂机器学习模型以实现持续压力监测的挑战。

Abstract: Conventional stress monitoring relies on episodic, symptom-focused
interventions, missing the need for continuous, accessible, and cost-efficient
solutions. State-of-the-art approaches use rigid, silicon-based wearables,
which, though capable of multitasking, are not optimized for lightweight,
flexible wear, limiting their practicality for continuous monitoring. In
contrast, flexible electronics (FE) offer flexibility and low manufacturing
costs, enabling real-time stress monitoring circuits. However, implementing
complex circuits like machine learning (ML) classifiers in FE is challenging
due to integration and power constraints. Previous research has explored
flexible biosensors and ADCs, but classifier design for stress detection
remains underexplored. This work presents the first comprehensive design space
exploration of low-power, flexible stress classifiers. We cover various ML
classifiers, feature selection, and neural simplification algorithms, with over
1200 flexible classifiers. To optimize hardware efficiency, fully customized
circuits with low-precision arithmetic are designed in each case. Our
exploration provides insights into designing real-time stress classifiers that
offer higher accuracy than current methods, while being low-cost, conformable,
and ensuring low power and compact size.

</details>


### [273] [Graph Data Modeling: Molecules, Proteins, & Chemical Processes](https://arxiv.org/abs/2508.19356)
*José Manuel Barraza-Chavez,Rana A. Barghout,Ricardo Almada-Monter,Benjamin Sanchez-Lengeling,Adrian Jinich,Radhakrishnan Mahadevan*

Main category: cs.LG

TL;DR: 本 primer 介绍了图论在化学科学中的应用，特别是图神经网络在分子、蛋白质和化学过程建模中的作用。


<details>
  <summary>Details</summary>
Motivation: 图是化学科学中描述分子、蛋白质、反应和工业过程的自然语言，捕捉了材料、生物和医学的基础相互作用和结构。

Method: 介绍图作为化学中的数学对象，以及学习算法（特别是图神经网络）如何在图上操作。

Result: 概述了图设计的基础、关键预测任务、化学科学中的代表性示例以及机器学习在基于图的建模中的作用。

Conclusion: 读者将能够将图方法应用于下一代化学发现。

Abstract: Graphs are central to the chemical sciences, providing a natural language to
describe molecules, proteins, reactions, and industrial processes. They capture
interactions and structures that underpin materials, biology, and medicine.
This primer, Graph Data Modeling: Molecules, Proteins, & Chemical Processes,
introduces graphs as mathematical objects in chemistry and shows how learning
algorithms (particularly graph neural networks) can operate on them. We outline
the foundations of graph design, key prediction tasks, representative examples
across chemical sciences, and the role of machine learning in graph-based
modeling. Together, these concepts prepare readers to apply graph methods to
the next generation of chemical discovery.

</details>


### [274] [Atrial Fibrillation Prediction Using a Lightweight Temporal Convolutional and Selective State Space Architecture](https://arxiv.org/abs/2508.19361)
*Yongbin Lee,Ki H. Chon*

Main category: cs.LG

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Atrial fibrillation (AF) is the most common arrhythmia, increasing the risk
of stroke, heart failure, and other cardiovascular complications. While AF
detection algorithms perform well in identifying persistent AF, early-stage
progression, such as paroxysmal AF (PAF), often goes undetected due to its
sudden onset and short duration. However, undetected PAF can progress into
sustained AF, increasing the risk of mortality and severe complications. Early
prediction of AF offers an opportunity to reduce disease progression through
preventive therapies, such as catecholamine-sparing agents or beta-blockers. In
this study, we propose a lightweight deep learning model using only RR
Intervals (RRIs), combining a Temporal Convolutional Network (TCN) for
positional encoding with Mamba, a selective state space model, to enable early
prediction of AF through efficient parallel sequence modeling. In subject-wise
testing results, our model achieved a sensitivity of 0.908, specificity of
0.933, F1-score of 0.930, AUROC of 0.972, and AUPRC of 0.932. Additionally, our
method demonstrates high computational efficiency, with only 73.5 thousand
parameters and 38.3 MFLOPs, outperforming traditional Convolutional Neural
Network-Recurrent Neural Network (CNN-RNN) approaches in both accuracy and
model compactness. Notably, the model can predict AF up to two hours in advance
using just 30 minutes of input data, providing enough lead time for preventive
interventions.

</details>


### [275] [Grounding the Ungrounded: A Spectral-Graph Framework for Quantifying Hallucinations in multimodal LLMs](https://arxiv.org/abs/2508.19366)
*Supratik Sarkar,Swagatam Das*

Main category: cs.LG

TL;DR: 该研究首次提出了一个基于信息几何和扩散动力学的严格框架，用于量化多模态大语言模型（MLLM）中的幻觉现象，将评估从定性检测提升到数学度量。


<details>
  <summary>Details</summary>
Motivation: 现有LLM幻觉评估方法多为启发式，缺乏原则性量化和理论保证，导致无法理解幻觉的产生、传播和跨模态交互。

Method: 提出一个信息几何框架，将MLLM输出表示为多模态图拉普拉斯谱嵌入，并将真伪不一致的流形差距特征化为语义失真。利用再生核希尔伯特空间（RKHS）嵌入中的特征模式分解，提供与模态相关的、理论上可解释的度量，以捕捉幻觉随时间和温度退火的演变。

Result: 开发了一种能够进行原则性量化和界定幻觉的方法，将幻觉从定性风险转变为可处理、可分析的现象。

Conclusion: 该研究为量化和界定MLLM中的幻觉提供了一个原则性基础，实现了从定性检测到数学度量的转变。

Abstract: Hallucinations in large language models (LLMs) remain a fundamental obstacle
to trustworthy AI, particularly in high-stakes multimodal domains such as
medicine, law, and finance. Existing evaluation techniques are largely
heuristic -- anchored in qualitative benchmarking or ad-hoc empirical
mitigation -- providing neither principled quantification nor actionable
theoretical guarantees. This gap leaves a critical blind spot in understanding
how hallucinations arise, propagate, and interact across modalities. We
introduce the first (to our knowledge) rigorous information geometric framework
in diffusion dynamics for quantifying hallucinations in multimodal LLMs
(MLLMs), advancing the field from qualitative detection to mathematically
grounded measurement. Our approach represents MLLM outputs as the spectral
embeddings over multimodal graph Laplacians and characterizes the manifold gaps
of truth vs inconsistencies as the semantic distortion, enabling the tight
Rayleigh--Ritz bounds on the multimodal hallucination energy as a functional of
time-dependent temperature profiles. By leveraging eigenmode decompositions in
Reproducing Kernel Hilbert Space (RKHS) embeddings, our framework delivers
modality-aware, theoretically interpretable metrics that capture the evolution
of hallucinations across time and input prompts through temperature annealing.
This work establishes a principled foundation for quantifying and bounding
hallucinations, transforming them from a qualitative risk to a tractable,
analyzable phenomenon.

</details>


### [276] [Fine-Tuning Vision-Language Models for Neutrino Event Analysis in High-Energy Physics Experiments](https://arxiv.org/abs/2508.19376)
*Dikshant Sagar,Kaiwen Yu,Alejandro Yankelevich,Jianming Bian,Pierre Baldi*

Main category: cs.LG

TL;DR: LLM在粒子物理学中用于分类中微子相互作用，性能与CNN相当或更优，并支持多模态推理。


<details>
  <summary>Details</summary>
Motivation: 探索使用基于LLaMA 3.2的微调视觉-语言模型（VLM）对高能物理（HEP）实验中的像素化探测器图像进行中微子相互作用分类。

Method: 将VLM与现有的CNN基线进行性能比较，评估分类准确率、精确率、召回率和AUC-ROC等指标。

Result: VLM的性能与CNN相当或更优，并能实现更丰富的推理和更好的辅助文本或语义上下文集成。

Conclusion: VLM为HEP事件分类提供了一个有前景的通用骨干，为实验中微子物理学中的多模态方法开辟了道路。

Abstract: Recent progress in large language models (LLMs) has shown strong potential
for multimodal reasoning beyond natural language. In this work, we explore the
use of a fine-tuned Vision-Language Model (VLM), based on LLaMA 3.2, for
classifying neutrino interactions from pixelated detector images in high-energy
physics (HEP) experiments. We benchmark its performance against an established
CNN baseline used in experiments like NOvA and DUNE, evaluating metrics such as
classification accuracy, precision, recall, and AUC-ROC. Our results show that
the VLM not only matches or exceeds CNN performance but also enables richer
reasoning and better integration of auxiliary textual or semantic context.
These findings suggest that VLMs offer a promising general-purpose backbone for
event classification in HEP, paving the way for multimodal approaches in
experimental neutrino physics.

</details>


### [277] [Towards Quantum Machine Learning for Malicious Code Analysis](https://arxiv.org/abs/2508.19381)
*Jesus Lopez,Saeefa Rubaiyet Nowmi,Viviana Cadena,Mohammad Saidur Rahman*

Main category: cs.LG

TL;DR: 本研究探讨了量子机器学习（QML）在恶意软件分类中的应用，特别是两种混合量子-经典模型：量子多层感知器（QMLP）和量子卷积神经网络（QCNN）。研究发现在二分类任务中，QMLP和QCNN均表现出高准确率（高达96%），而在复杂的多分类任务中，QMLP的性能优于QCNN，但QCNN的训练效率更高。


<details>
  <summary>Details</summary>
Motivation: 随着量子计算的兴起，量子机器学习（QML）为改进恶意软件检测提供了新的可能性，但其在该领域的应用尚处于探索阶段。本研究旨在评估QML在恶意软件分类任务中的潜力。

Method: 本研究使用了两种混合量子-经典模型：量子多层感知器（QMLP）和量子卷积神经网络（QCNN）。这两种模型都利用角度嵌入将恶意软件特征编码为量子态。QMLP通过全量子比特测量和数据重传来捕捉复杂模式，而QCNN通过量子卷积和池化层来减少活跃量子比特，从而实现更快的训练。

Result: 在二分类任务中，模型在API-Graph数据集上的准确率达到95-96%，在AZ-Domain数据集上为91-92%，在EMBER-Domain数据集上为77%。在多分类任务中，API-Graph数据集的准确率为91.6-95.7%，AZ-Class数据集为41.7-93.6%，EMBER-Class数据集为60.7-88.1%。

Conclusion: QMLP在复杂的多分类任务中表现优于QCNN，而QCNN在以牺牲部分准确率为代价的情况下提供了更高的训练效率。

Abstract: Classical machine learning (CML) has been extensively studied for malware
classification. With the emergence of quantum computing, quantum machine
learning (QML) presents a paradigm-shifting opportunity to improve malware
detection, though its application in this domain remains largely unexplored. In
this study, we investigate two hybrid quantum-classical models -- a Quantum
Multilayer Perceptron (QMLP) and a Quantum Convolutional Neural Network (QCNN),
for malware classification. Both models utilize angle embedding to encode
malware features into quantum states. QMLP captures complex patterns through
full qubit measurement and data re-uploading, while QCNN achieves faster
training via quantum convolution and pooling layers that reduce active qubits.
We evaluate both models on five widely used malware datasets -- API-Graph,
EMBER-Domain, EMBER-Class, AZ-Domain, and AZ-Class, across binary and
multiclass classification tasks.
  Our results show high accuracy for binary classification -- 95-96% on
API-Graph, 91-92% on AZ-Domain, and 77% on EMBER-Domain. In multiclass
settings, accuracy ranges from 91.6-95.7% on API-Graph, 41.7-93.6% on AZ-Class,
and 60.7-88.1% on EMBER-Class. Overall, QMLP outperforms QCNN in complex
multiclass tasks, while QCNN offers improved training efficiency at the cost of
reduced accuracy.

</details>


### [278] [DETNO: A Diffusion-Enhanced Transformer Neural Operator for Long-Term Traffic Forecasting](https://arxiv.org/abs/2508.19389)
*Owais Ahmad,Milad Ramezankhani,Anirudh Deodhar*

Main category: cs.LG

TL;DR: 该研究提出了一种名为DETNO的统一扩散增强Transformer神经元算子架构，用于解决长期高频交通预测中的挑战，特别是再现冲击波和拥堵边界等高频特征。


<details>
  <summary>Details</summary>
Motivation: 标准的神经元算子在预测高频交通特征（如密度梯度）时存在平滑预测的局限性，导致在多步预测中误差累积，这对于需要实时交通管理的场景至关重要。

Method: 研究提出了一种名为DETNO的统一扩散增强Transformer神经元算子架构。该架构结合了具有交叉注意机制的Transformer神经元算子（用于提供模型表达能力和超分辨率）和一个基于扩散的细化组件（通过渐进式去噪迭代地重建高频交通细节）。

Result: 通过在混沌交通数据集上的综合评估，DETNO方法在长期预测方面表现优于传统的和基于Transformer的神经元算子，能够保持高频成分并提高长预测范围内的稳定性。

Conclusion: DETNO架构通过结合Transformer神经元算子和扩散模型，成功克服了现有神经元算子在处理高频交通特征和长期预测稳定性方面的固有局限性，为智能交通系统提供了更准确、更稳定的预测能力。

Abstract: Accurate long-term traffic forecasting remains a critical challenge in
intelligent transportation systems, particularly when predicting high-frequency
traffic phenomena such as shock waves and congestion boundaries over extended
rollout horizons. Neural operators have recently gained attention as promising
tools for modeling traffic flow. While effective at learning function space
mappings, they inherently produce smooth predictions that fail to reconstruct
high-frequency features such as sharp density gradients which results in rapid
error accumulation during multi-step rollout predictions essential for
real-time traffic management. To address these fundamental limitations, we
introduce a unified Diffusion-Enhanced Transformer Neural Operator (DETNO)
architecture. DETNO leverages a transformer neural operator with
cross-attention mechanisms, providing model expressivity and super-resolution,
coupled with a diffusion-based refinement component that iteratively
reconstructs high-frequency traffic details through progressive denoising. This
overcomes the inherent smoothing limitations and rollout instability of
standard neural operators. Through comprehensive evaluation on chaotic traffic
datasets, our method demonstrates superior performance in extended rollout
predictions compared to traditional and transformer-based neural operators,
preserving high-frequency components and improving stability over long
prediction horizons.

</details>


### [279] [Quantum-Classical Hybrid Molecular Autoencoder for Advancing Classical Decoding](https://arxiv.org/abs/2508.19394)
*Afrar Jahin,Yi Pan,Yingfeng Wang,Tianming Liu,Wei Zhang*

Main category: cs.LG

TL;DR: 提出了一种混合量子-经典架构用于SMILES重建，以提高量子保真度和经典相似度。


<details>
  <summary>Details</summary>
Motivation: 尽管量子机器学习（QML）在增强生成模型方面展现出巨大潜力，但经典方法在分子设计等任务中仍面临高保真度和有效性的挑战，尤其是在SMILES重建等序列任务中，QML的集成研究不足且保真度常下降。

Method: 提出了一种混合量子-经典架构，将量子编码与经典序列建模相结合，以提高量子保真度和经典相似度。

Result: 该方法实现了约84%的量子保真度和60%的经典重建相似度，优于现有的量子基线。

Conclusion: 该工作为未来的QML应用奠定了基础，在表达性量子表示和经典序列模型之间取得了平衡，并促进了对用于分子和药物发现的量子感知序列模型的广泛研究。

Abstract: Although recent advances in quantum machine learning (QML) offer significant
potential for enhancing generative models, particularly in molecular design, a
large array of classical approaches still face challenges in achieving high
fidelity and validity. In particular, the integration of QML with
sequence-based tasks, such as Simplified Molecular Input Line Entry System
(SMILES) string reconstruction, remains underexplored and usually suffers from
fidelity degradation. In this work, we propose a hybrid quantum-classical
architecture for SMILES reconstruction that integrates quantum encoding with
classical sequence modeling to improve quantum fidelity and classical
similarity. Our approach achieves a quantum fidelity of approximately 84% and a
classical reconstruction similarity of 60%, surpassing existing quantum
baselines. Our work lays a promising foundation for future QML applications,
striking a balance between expressive quantum representations and classical
sequence models and catalyzing broader research on quantum-aware sequence
models for molecular and drug discovery.

</details>


### [280] [Kolmogorov-Arnold Representation for Symplectic Learning: Advancing Hamiltonian Neural Networks](https://arxiv.org/abs/2508.19410)
*Zongyu Wu,Ruichen Xu,Luoyao Chen,Georgios Kementzidis,Siyao Wang,Yuefan Deng*

Main category: cs.LG

TL;DR: KAR-HNN 使用基于 KOLMOGOROV-ARNOLD 表示的单变量变换替代 MLP，以提高 HNN 在复杂能量场中的稳定性和预测能力。


<details>
  <summary>Details</summary>
Motivation: 现有基于 MLP 的 HNN 在探索复杂能量场时对超参数敏感，导致不稳定。KAR-HNN 旨在通过使用单变量变换来解决这个问题，以更好地捕捉高频和多尺度动力学，减少能量漂移并提高长期预测稳定性。

Method: 提出一种基于 KOLMOGOROV-ARNOLD 表示的哈密顿神经网络 (KAR-HNN)，用单变量变换取代多层感知器 (MLP)。 KAR-HNN 保持了哈密顿系统的辛形式，从而保持了可解释性和物理一致性。

Result: 在弹簧-质量系统、单摆、二体问题和三体问题这四个基准问题上评估了 KAR-HNN。与现有方法相比，KAR-HNN 表现出更低的能量漂移和更好的长期预测稳定性。

Conclusion: KAR-HNN 在准确而稳定地模拟具有高维度和少量已知参数的实际物理过程方面具有有效性。

Abstract: We propose a Kolmogorov-Arnold Representation-based Hamiltonian Neural
Network (KAR-HNN) that replaces the Multilayer Perceptrons (MLPs) with
univariate transformations. While Hamiltonian Neural Networks (HNNs) ensure
energy conservation by learning Hamiltonian functions directly from data,
existing implementations, often relying on MLPs, cause hypersensitivity to the
hyperparameters while exploring complex energy landscapes. Our approach
exploits the localized function approximations to better capture high-frequency
and multi-scale dynamics, reducing energy drift and improving long-term
predictive stability. The networks preserve the symplectic form of Hamiltonian
systems, and thus maintain interpretability and physical consistency. After
assessing KAR-HNN on four benchmark problems including spring-mass, simple
pendulum, two- and three-body problem, we foresee its effectiveness for
accurate and stable modeling of realistic physical processes often at high
dimensions and with few known parameters.

</details>


### [281] [Even Heads Fix Odd Errors: Mechanistic Discovery and Surgical Repair in Transformer Attention](https://arxiv.org/abs/2508.19414)
*Gustavo Sandoval*

Main category: cs.LG

TL;DR: Llama-3.1-8B-Instruct 在处理 '9.11' vs '9.8' 时存在格式依赖的推理失败，即使/奇数注意力头专门化导致了这一问题，修复需要特定数量的偶数头。


<details>
  <summary>Details</summary>
Motivation: 研究 Llama-3.1-8B-Instruct 中格式依赖的推理失败，理解其潜在机制。

Method: 通过系统性干预和 SAE 分析，研究了注意力头的专门化、特征重叠和权重变化。

Result: 发现偶数索引的头负责数值比较，奇数索引的头负责其他功能；修复需要 L10 的 8 个偶数头；SAE 分析揭示了格式表征在不同层重叠和加权；使用 25% 的注意力头和 60% 的模式替换即可完美修复。

Conclusion: 大型语言模型中存在精细的计算子结构，即使看起来需要整个模块，也可能通过特定部分进行修复，这对模型的可解释性和效率有重要意义。

Abstract: We present a mechanistic case study of a format-dependent reasoning failure
in Llama-3.1-8B-Instruct, where the model incorrectly judges "9.11" as larger
than "9.8" in chat or Q&A formats, but answers correctly in simple format.
Through systematic intervention, we discover transformers implement even/odd
attention head specialization: even indexed heads handle numerical comparison,
while odd heads serve incompatible functions. The bug requires exactly 8 even
heads at Layer 10 for perfect repair. Any combination of 8+ even heads
succeeds, while 7 or fewer completely fails, revealing sharp computational
thresholds with perfect redundancy among the 16 even heads. SAE analysis
reveals the mechanism: format representations separate (10% feature overlap at
Layer 7), then re-entangle with different weightings (80% feature overlap at
Layer 10), with specific features showing 1.5x amplification in failing
formats. We achieve perfect repair using only 25% of attention heads and
identify a 60% pattern replacement threshold, demonstrating that apparent
full-module requirements hide sophisticated substructure with implications for
interpretability and efficiency. All of our code is available at
https://github.com/gussand/surgeon.

</details>


### [282] [Differentiable multiphase flow model for physics-informed machine learning in reservoir pressure management](https://arxiv.org/abs/2508.19419)
*Harun Ur Rashid,Aleksandra Pachalieva,Daniel O'Malley*

Main category: cs.LG

TL;DR: 该研究提出了一种结合了可微分模拟器和CNN的物理信息机器学习工作流，用于精确控制地下油藏压力。该方法通过学习从渗透率场预测流体抽取率，来满足关键位置的压力限制。与以往方法相比，该方法在模拟真实注入-抽取场景时更实用、更精确。通过在单相稳态模拟上预训练模型，然后在多相流动场景上进行微调，显著降低了计算成本，只需不到三千次全物理多相流动模拟即可达到高精度训练。


<details>
  <summary>Details</summary>
Motivation: 地下油藏压力控制因地质非均质性和多相流体动力学而具有挑战性。高保真度物理模拟计算成本高昂，而要处理不确定且非均质的性质，需要大量模拟，这往往是不可行的。

Method: 该研究引入了一个物理信息机器学习工作流，耦合了一个完全可微分的多相流模拟器（在DPFEHM框架中实现）和一个卷积神经网络（CNN）。CNN学习从非均质渗透率场预测流体抽取率，以在关键油藏位置强制执行压力限制。通过在训练过程中融入瞬态多相流物理，该方法实现了比以往工作更实际、更准确的预测。

Result: 与需要高达一千万次模拟的先前估计相比，该方法通过利用来自成本低得多的单相模拟的迁移学习，实现了训练精度，仅需不到三千次全物理多相流动模拟。

Conclusion: 该研究提出的物理信息机器学习工作流能够显著减少进行高精度训练所需的模拟次数，从而克服了油藏压力控制的计算挑战。

Abstract: Accurate subsurface reservoir pressure control is extremely challenging due
to geological heterogeneity and multiphase fluid-flow dynamics. Predicting
behavior in this setting relies on high-fidelity physics-based simulations that
are computationally expensive. Yet, the uncertain, heterogeneous properties
that control these flows make it necessary to perform many of these expensive
simulations, which is often prohibitive. To address these challenges, we
introduce a physics-informed machine learning workflow that couples a fully
differentiable multiphase flow simulator, which is implemented in the DPFEHM
framework with a convolutional neural network (CNN). The CNN learns to predict
fluid extraction rates from heterogeneous permeability fields to enforce
pressure limits at critical reservoir locations. By incorporating transient
multiphase flow physics into the training process, our method enables more
practical and accurate predictions for realistic injection-extraction scenarios
compare to previous works. To speed up training, we pretrain the model on
single-phase, steady-state simulations and then fine-tune it on full multiphase
scenarios, which dramatically reduces the computational cost. We demonstrate
that high-accuracy training can be achieved with fewer than three thousand
full-physics multiphase flow simulations -- compared to previous estimates
requiring up to ten million. This drastic reduction in the number of
simulations is achieved by leveraging transfer learning from much less
expensive single-phase simulations.

</details>


### [283] [Constraint Learning in Multi-Agent Dynamic Games from Demonstrations of Local Nash Interactions](https://arxiv.org/abs/2508.19945)
*Zhouyu Zhang,Chih-Yuan Chiu,Glen Chou*

Main category: cs.LG

TL;DR: 我们提出了一种基于逆动态博弈的算法，用于从给定的局部广义纳什均衡交互数据集学习参数化约束。


<details>
  <summary>Details</summary>
Motivation: 从交互演示中学习约束，以设计满足这些约束的运动计划。

Method: 使用混合整数线性规划（MILP）编码参与者的Karush-Kuhn-Tucker（KKT）条件来恢复与交互演示的纳什平稳性一致的约束。

Result: 学习约束，实现稳健的运动计划，并证明了约束可学习性的理论保证和局限性。

Conclusion: 所提出的方法能够从具有非线性动力学的参与者的交互演示中推断约束并设计交互式运动计划，适用于各种凸形和非凸形约束。

Abstract: We present an inverse dynamic game-based algorithm to learn parametric
constraints from a given dataset of local generalized Nash equilibrium
interactions between multiple agents. Specifically, we introduce mixed-integer
linear programs (MILP) encoding the Karush-Kuhn-Tucker (KKT) conditions of the
interacting agents, which recover constraints consistent with the Nash
stationarity of the interaction demonstrations. We establish theoretical
guarantees that our method learns inner approximations of the true safe and
unsafe sets, as well as limitations of constraint learnability from
demonstrations of Nash equilibrium interactions. We also use the interaction
constraints recovered by our method to design motion plans that robustly
satisfy the underlying constraints. Across simulations and hardware
experiments, our methods proved capable of inferring constraints and designing
interactive motion plans for various classes of constraints, both convex and
non-convex, from interaction demonstrations of agents with nonlinear dynamics.

</details>


### [284] [MS-ConTab: Multi-Scale Contrastive Learning of Mutation Signatures for Pan Cancer Representation and Stratification](https://arxiv.org/abs/2508.19424)
*Yifan Dou,Adam Khadre,Ruben C Petreaca,Golrokh Mirzaei*

Main category: cs.LG

TL;DR: 本研究提出了一种新的无监督对比学习框架，用于基于编码突变数据对 43 种癌症类型进行聚类，将对比学习应用于队列级癌症聚类，实现了可扩展且可解释的突变驱动癌症亚型分类。


<details>
  <summary>Details</summary>
Motivation: 理解泛癌基因突变图谱对于深入了解肿瘤发生过程中的分子机制至关重要。尽管已广泛采用面向患者的机器学习技术来识别肿瘤亚型，但基于共享分子特征对整个癌症类型进行分组的队列级聚类，在很大程度上仍依赖于经典的统计方法。

Method: 本研究引入了一种新颖的无监督对比学习框架，该框架基于来自 COSMIC 数据库的编码突变数据对 43 种癌症类型进行聚类。研究人员为每种癌症类型构建了两个互补的突变特征：一个基因级别特征，用于捕捉最常发生突变的基因的核苷酸取代模式；另一个是染色体级别特征，用于表示染色体上标准化的取代频率。利用 TabNet 编码器对这两种特征进行编码，并通过多尺度对比学习目标（NT-Xent 损失）进行优化，以学习统一的癌症类型嵌入。

Result: 研究结果表明，通过该框架学习到的潜在表示能够产生具有生物学意义的癌症类型聚类，这些聚类与已知的突变过程和组织起源相符。

Conclusion: 本研究是对比学习在队列级癌症聚类中的首次应用，为进行突变驱动的癌症亚型分类提供了一个可扩展且可解释的框架。

Abstract: Motivation. Understanding the pan-cancer mutational landscape offers critical
insights into the molecular mechanisms underlying tumorigenesis. While
patient-level machine learning techniques have been widely employed to identify
tumor subtypes, cohort-level clustering, where entire cancer types are grouped
based on shared molecular features, has largely relied on classical statistical
methods.
  Results. In this study, we introduce a novel unsupervised contrastive
learning framework to cluster 43 cancer types based on coding mutation data
derived from the COSMIC database. For each cancer type, we construct two
complementary mutation signatures: a gene-level profile capturing nucleotide
substitution patterns across the most frequently mutated genes, and a
chromosome-level profile representing normalized substitution frequencies
across chromosomes. These dual views are encoded using TabNet encoders and
optimized via a multi-scale contrastive learning objective (NT-Xent loss) to
learn unified cancer-type embeddings. We demonstrate that the resulting latent
representations yield biologically meaningful clusters of cancer types,
aligning with known mutational processes and tissue origins. Our work
represents the first application of contrastive learning to cohort-level cancer
clustering, offering a scalable and interpretable framework for mutation-driven
cancer subtyping.

</details>


### [285] [Data-Augmented Few-Shot Neural Stencil Emulation for System Identification of Computer Models](https://arxiv.org/abs/2508.19441)
*Sanket Jantre,Deepak Akhare,Xiaoning Qian,Nathan M. Urban*

Main category: cs.LG

TL;DR: 该研究提出了一种更具样本效率的数据增强策略，用于从计算机模型生成神经PDE训练数据，通过对局部“模板”状态进行空间填充采样，以克服轨迹数据中时空冗余，并过采样可能罕见的但有助于泛化的状态。实验证明，这种方法可以从相当于10个时间步长的数值模拟数据中学习到准确的神经PDE模板算子，并且如果能获得单条完整的轨迹模拟数据，准确性会进一步提高。与简单采样轨迹数据相比，该数据增强策略在多个PDE系统上训练出的神经模板算子表现更优，性能提升明显。


<details>
  <summary>Details</summary>
Motivation: 传统的数值PDE求解器在处理某些系统时存在局限性，例如在微分、线性化、降维或进行不确定性量化时。将PDE模型表示为神经PDE可以克服这些限制，但通常需要大量训练数据。

Method: 提出了一种数据增强策略，通过对局部“模板”状态进行空间填充采样来生成训练数据。这种方法旨在减少数据中的时空冗余，并过采样那些可能罕见但对泛化至关重要的状态。

Result: 实验证明，该方法可以从相当于10个时间步长的数值模拟数据中学习到准确的神经PDE模板算子。当结合一条完整的轨迹模拟数据时，准确性得到进一步提升。与简单采样轨迹数据相比，该方法在多个PDE系统上展现出性能优势。

Conclusion: 所提出的数据增强策略能够从更少的模拟数据中生成高质量的神经PDE训练数据，显著提高了神经PDE的训练效率和泛化能力，为构建更优的神经PDE模型提供了有效途径。

Abstract: Partial differential equations (PDEs) underpin the modeling of many natural
and engineered systems. It can be convenient to express such models as neural
PDEs rather than using traditional numerical PDE solvers by replacing part or
all of the PDE's governing equations with a neural network representation.
Neural PDEs are often easier to differentiate, linearize, reduce, or use for
uncertainty quantification than the original numerical solver. They are usually
trained on solution trajectories obtained by long time integration of the PDE
solver. Here we propose a more sample-efficient data-augmentation strategy for
generating neural PDE training data from a computer model by space-filling
sampling of local "stencil" states. This approach removes a large degree of
spatiotemporal redundancy present in trajectory data and oversamples states
that may be rarely visited but help the neural PDE generalize across the state
space. We demonstrate that accurate neural PDE stencil operators can be learned
from synthetic training data generated by the computational equivalent of 10
timesteps' worth of numerical simulation. Accuracy is further improved if we
assume access to a single full-trajectory simulation from the computer model,
which is typically available in practice. Across several PDE systems, we show
that our data-augmented synthetic stencil data yield better trained neural
stencil operators, with clear performance gains compared with naively sampled
stencil data from simulation trajectories.

</details>


### [286] [Efficiently Generating Multidimensional Calorimeter Data with Tensor Decomposition Parameterization](https://arxiv.org/abs/2508.19443)
*Paimon Goulart,Shaan Pakala,Evangelos Papalexakis*

Main category: cs.LG

TL;DR: 生成合成数据，特别是在模拟数据集时，可能具有成本效益。通过张量分解，可以进一步降低生成多维数据的成本，同时保持数据的可用性。


<details>
  <summary>Details</summary>
Motivation: 由于生成大型复杂模拟数据集耗时耗力，且实验成本高昂，因此使用生成模型（如GAN或扩散模型）生成合成数据越来越合理。

Method: 本文提出将张量分解（一种用于处理多维数据的技术）集成到生成模型中。通过生成较小的张量因子而不是完整的张量，可以显著减少模型的输出和总体参数。

Result: 实验表明，通过张量分解生成的合成数据在降低模型输出和参数数量的同时，仍然保持了其可用性。

Conclusion: 张量分解有潜力提高生成模型的效率，尤其是在生成多维数据（张量）时，通过减少生成复杂模拟数据所需的成本。

Abstract: Producing large complex simulation datasets can often be a time and resource
consuming task. Especially when these experiments are very expensive, it is
becoming more reasonable to generate synthetic data for downstream tasks.
Recently, these methods may include using generative machine learning models
such as Generative Adversarial Networks or diffusion models. As these
generative models improve efficiency in producing useful data, we introduce an
internal tensor decomposition to these generative models to even further reduce
costs. More specifically, for multidimensional data, or tensors, we generate
the smaller tensor factors instead of the full tensor, in order to
significantly reduce the model's output and overall parameters. This reduces
the costs of generating complex simulation data, and our experiments show the
generated data remains useful. As a result, tensor decomposition has the
potential to improve efficiency in generative models, especially when
generating multidimensional data, or tensors.

</details>


### [287] [On Surjectivity of Neural Networks: Can you elicit any behavior from your model?](https://arxiv.org/abs/2508.19445)
*Haozhe Jiang,Nika Haghtalab*

Main category: cs.LG

TL;DR: 现代神经网络（包括GPT和扩散模型）在几乎所有情况下都是可满射的，这意味着它们可以生成任何指定的输出，这引发了模型安全和越狱漏洞的担忧。


<details>
  <summary>Details</summary>
Motivation: 研究在给定已训练的神经网络的情况下，是否可以生成任何指定的输出，即网络是否对应一个满射函数，以及这在生成模型中对模型安全和越狱漏洞的启示。

Method: 证明了许多现代神经网络的基础模块（如具有预层归一化和线性注意力模块的网络）几乎总是可满射的。

Result: 作为推论，包括GPT风格的Transformer和具有确定性ODE求解器的扩散模型在内的广泛使用的生成框架，允许任意输出的逆映射。

Conclusion: 通过研究这些现代和常用的神经网络结构的可满射性，为揭示其在广泛的对抗性攻击中不可避免的漏洞提供了理论基础。

Abstract: Given a trained neural network, can any specified output be generated by some
input? Equivalently, does the network correspond to a function that is
surjective? In generative models, surjectivity implies that any output,
including harmful or undesirable content, can in principle be generated by the
networks, raising concerns about model safety and jailbreak vulnerabilities. In
this paper, we prove that many fundamental building blocks of modern neural
architectures, such as networks with pre-layer normalization and
linear-attention modules, are almost always surjective. As corollaries, widely
used generative frameworks, including GPT-style transformers and diffusion
models with deterministic ODE solvers, admit inverse mappings for arbitrary
outputs. By studying surjectivity of these modern and commonly used neural
architectures, we contribute a formalism that sheds light on their unavoidable
vulnerability to a broad class of adversarial attacks.

</details>


### [288] [The Sample Complexity of Membership Inference and Privacy Auditing](https://arxiv.org/abs/2508.19458)
*Mahdi Haghifam,Adam Smith,Jonathan Ullman*

Main category: cs.LG

TL;DR: 本文研究了在假设学习算法的训练数据来自高斯分布的情况下，进行成员推理攻击所需的样本复杂度。


<details>
  <summary>Details</summary>
Motivation: 研究在成员推理攻击中，攻击者需要多少关于数据分布的先验知识。

Method: 在从高斯分布$\\mathcal{N}(\\mu, \\Sigma)$中抽取n个样本并估计$\\hat{\\mu}$的学习场景下，分析了进行成员推理攻击所需的最小参考样本数量。

Result: 证明了在某些情况下，成员推理攻击可能需要$\\Omega(n + n^2 \\rho^2)$个样本，这可能比训练算法使用的样本量更多，并指出当前实践中的攻击方法可能低估了成员推理的可能性。

Conclusion: 攻击者所需的参考样本量可能比预期的要多，特别是当攻击者能够获得大量关于数据分布的信息时，这可能促使开发更强大的成员推理攻击。

Abstract: A membership-inference attack gets the output of a learning algorithm, and a
target individual, and tries to determine whether this individual is a member
of the training data or an independent sample from the same distribution. A
successful membership-inference attack typically requires the attacker to have
some knowledge about the distribution that the training data was sampled from,
and this knowledge is often captured through a set of independent reference
samples from that distribution. In this work we study how much information the
attacker needs for membership inference by investigating the sample
complexity-the minimum number of reference samples required-for a successful
attack. We study this question in the fundamental setting of Gaussian mean
estimation where the learning algorithm is given $n$ samples from a Gaussian
distribution $\mathcal{N}(\mu,\Sigma)$ in $d$ dimensions, and tries to estimate
$\hat\mu$ up to some error $\mathbb{E}[\|\hat \mu - \mu\|^2_{\Sigma}]\leq
\rho^2 d$. Our result shows that for membership inference in this setting,
$\Omega(n + n^2 \rho^2)$ samples can be necessary to carry out any attack that
competes with a fully informed attacker. Our result is the first to show that
the attacker sometimes needs many more samples than the training algorithm uses
to train the model. This result has significant implications for practice, as
all attacks used in practice have a restricted form that uses $O(n)$ samples
and cannot benefit from $\omega(n)$ samples. Thus, these attacks may be
underestimating the possibility of membership inference, and better attacks may
be possible when information about the distribution is easy to obtain.

</details>


### [289] [Incentivized Lipschitz Bandits](https://arxiv.org/abs/2508.19466)
*Sourav Chakraborty,Amit Kiran Rege,Claire Monteleoni,Lijun Chen*

Main category: cs.LG

TL;DR: 在无限臂的多臂老虎机（MAB）环境中，我们研究了带激励的探索问题，其中手臂是连续度量空间中的元素。与经典模型不同，我们考虑了决策者（主体）通过补偿激励短视的代理人进行探索，但存在奖励漂移（激励引起的反馈偏差）的复杂性。我们提出了一种新颖的带激励探索算法，该算法将无限手臂空间均匀离散化，并证明该算法同时实现了次线性累积遗憾和次线性总补偿。具体来说，我们推导出的遗憾和补偿界限为 $\Tilde{O}(T^{d+1/d+2})$，其中 $d$ 是度量空间的覆盖维度。此外，我们将结果推广到上下文老虎机，并取得了可比的性能保证。我们通过数值模拟验证了我们的理论发现。


<details>
  <summary>Details</summary>
Motivation: 在多臂老虎机（MAB）设置中，决策者（主体）希望激励短视的代理人进行探索，但需要处理由激励引起的奖励漂移（反馈偏差）。

Method: 提出了一种新颖的带激励探索算法，该算法将无限手臂空间均匀离散化，并推导了遗憾和补偿的界限。

Result: 该算法同时实现了次线性累积遗憾和次线性总补偿，其界限为 $\Tilde{O}(T^{d+1/d+2})$，其中 $d$ 是度量空间的覆盖维度。

Conclusion: 所提出的带激励探索算法在理论上和实践中都能有效地处理无限手臂MAB设置中的奖励漂移问题，并能推广到上下文老虎机。

Abstract: We study incentivized exploration in multi-armed bandit (MAB) settings with
infinitely many arms modeled as elements in continuous metric spaces. Unlike
classical bandit models, we consider scenarios where the decision-maker
(principal) incentivizes myopic agents to explore beyond their greedy choices
through compensation, but with the complication of reward drift--biased
feedback arising due to the incentives. We propose novel incentivized
exploration algorithms that discretize the infinite arm space uniformly and
demonstrate that these algorithms simultaneously achieve sublinear cumulative
regret and sublinear total compensation. Specifically, we derive regret and
compensation bounds of $\Tilde{O}(T^{d+1/d+2})$, with $d$ representing the
covering dimension of the metric space. Furthermore, we generalize our results
to contextual bandits, achieving comparable performance guarantees. We validate
our theoretical findings through numerical simulations.

</details>


### [290] [DeepAtlas: a tool for effective manifold learning](https://arxiv.org/abs/2508.19479)
*Serena Hughes,Timothy Hamilton,Tom Kolokotrones,Eric J. Deeds*

Main category: cs.LG

TL;DR: DeepAtlas算法生成局部嵌入，可用于评估流形假设并生成数据。


<details>
  <summary>Details</summary>
Motivation: 当前工具生成全局嵌入而非局部图，且无法评估数据是否符合流形假设。

Method: DeepAtlas算法生成数据局部邻域的低维表示，并训练深度神经网络进行映射，使用拓扑畸变评估流形假设及其维度。

Result: DeepAtlas成功学习了测试数据集的流形结构，并发现许多真实数据集（如单细胞RNA测序数据）不符合流形假设。

Conclusion: DeepAtlas可用于评估流形假设，并在数据符合流形假设时用于生成模型，有望将微分几何工具应用于多种数据集。

Abstract: Manifold learning builds on the "manifold hypothesis," which posits that data
in high-dimensional datasets are drawn from lower-dimensional manifolds.
Current tools generate global embeddings of data, rather than the local maps
used to define manifolds mathematically. These tools also cannot assess whether
the manifold hypothesis holds true for a dataset. Here, we describe DeepAtlas,
an algorithm that generates lower-dimensional representations of the data's
local neighborhoods, then trains deep neural networks that map between these
local embeddings and the original data. Topological distortion is used to
determine whether a dataset is drawn from a manifold and, if so, its
dimensionality. Application to test datasets indicates that DeepAtlas can
successfully learn manifold structures. Interestingly, many real datasets,
including single-cell RNA-sequencing, do not conform to the manifold
hypothesis. In cases where data is drawn from a manifold, DeepAtlas builds a
model that can be used generatively and promises to allow the application of
powerful tools from differential geometry to a variety of datasets.

</details>


### [291] [Distribution Shift Aware Neural Tabular Learning](https://arxiv.org/abs/2508.19486)
*Wangyang Ying,Nanxu Gong,Dongjie Wang,Xinyuan Wang,Arun Vignesh Malarkkan,Vivek Gupta,Chandan K. Reddy,Yanjie Fu*

Main category: cs.LG

TL;DR: 在训练和测试数据分布发生变化时，表格学习的有效性会下降。提出了一种名为SAFT的新框架，通过将表格学习视为一个连续的表示生成问题，并结合了三种机制（嵌入去相关和样本重加权、次优嵌入平均、基于归一化的对齐）来提高鲁棒性。实验证明SAFT在各种分布变化下优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 表格学习在分布变化时效果会下降，需要解决分布偏移表格学习（DSTL）问题。

Method: 提出了一种名为SAFT的框架，将表格学习重构为连续的表示生成范式，通过嵌入去相关、样本重加权、次优嵌入平均和基于归一化的对齐等机制来提高鲁棒性。

Result: SAFT在各种分布变化下，在鲁棒性、有效性和泛化能力方面始终优于之前的表格学习方法。

Conclusion: SAFT框架能够有效提高表格学习在分布偏移情况下的鲁棒性、有效性和泛化能力。

Abstract: Tabular learning transforms raw features into optimized spaces for downstream
tasks, but its effectiveness deteriorates under distribution shifts between
training and testing data. We formalize this challenge as the Distribution
Shift Tabular Learning (DSTL) problem and propose a novel Shift-Aware Feature
Transformation (SAFT) framework to address it. SAFT reframes tabular learning
from a discrete search task into a continuous representation-generation
paradigm, enabling differentiable optimization over transformed feature sets.
SAFT integrates three mechanisms to ensure robustness: (i) shift-resistant
representation via embedding decorrelation and sample reweighting, (ii)
flatness-aware generation through suboptimal embedding averaging, and (iii)
normalization-based alignment between training and test distributions.
Extensive experiments show that SAFT consistently outperforms prior tabular
learning methods in terms of robustness, effectiveness, and generalization
ability under diverse real-world distribution shifts.

</details>


### [292] [Data-Efficient Symbolic Regression via Foundation Model Distillation](https://arxiv.org/abs/2508.19487)
*Wangyang Ying,Jinghan Zhang,Haoyue Bai,Nanxu Gong,Xinyuan Wang,Kunpeng Liu,Chandan K. Reddy,Yanjie Fu*

Main category: cs.LG

TL;DR: EQUATE是一个数据高效的微调框架，通过蒸馏将基础模型适应于低数据环境下的符号方程发现。


<details>
  <summary>Details</summary>
Motivation: 发现可解释的数学方程（符号回归）是科学发现的基石，但预训练的基础模型在应用于小规模、领域特定的数据集时，常出现负迁移和泛化能力差的问题。

Method: EQUATE结合了符号-数值对齐和评估器引导的嵌入优化，提出了一种基于嵌入搜索生成的方法，将离散方程搜索重构为共享嵌入空间中的连续优化任务，并通过数据-方程适应性和简洁性进行指导。

Result: 在三个标准公共基准（Feynman、Strogatz和黑盒数据集）上的实验表明，EQUATE在准确性和鲁棒性方面始终优于最先进的基线方法，同时保持了低复杂性和快速推理。

Conclusion: EQUATE为基础模型蒸馏设置中数据高效的符号回归提供了一个实用且可泛化的解决方案。

Abstract: Discovering interpretable mathematical equations from observed data (a.k.a.
equation discovery or symbolic regression) is a cornerstone of scientific
discovery, enabling transparent modeling of physical, biological, and economic
systems. While foundation models pre-trained on large-scale equation datasets
offer a promising starting point, they often suffer from negative transfer and
poor generalization when applied to small, domain-specific datasets. In this
paper, we introduce EQUATE (Equation Generation via QUality-Aligned Transfer
Embeddings), a data-efficient fine-tuning framework that adapts foundation
models for symbolic equation discovery in low-data regimes via distillation.
EQUATE combines symbolic-numeric alignment with evaluator-guided embedding
optimization, enabling a principled embedding-search-generation paradigm. Our
approach reformulates discrete equation search as a continuous optimization
task in a shared embedding space, guided by data-equation fitness and
simplicity. Experiments across three standard public benchmarks (Feynman,
Strogatz, and black-box datasets) demonstrate that EQUATE consistently
outperforms state-of-the-art baselines in both accuracy and robustness, while
preserving low complexity and fast inference. These results highlight EQUATE as
a practical and generalizable solution for data-efficient symbolic regression
in foundation model distillation settings.

</details>


### [293] [PoolFlip: A Multi-Agent Reinforcement Learning Security Environment for Cyber Defense](https://arxiv.org/abs/2508.19488)
*Xavier Cadet,Simona Boboila,Sie Hendrata Dharmawan,Alina Oprea,Peter Chin*

Main category: cs.LG

TL;DR: FlipIt游戏用于模拟攻防交互，但现有方法存在局限性。PoolFlip作为新环境扩展了FlipIt，Flip-PSRO作为MARL方法利用种群训练提升了防御者的泛化能力，使其在面对未知攻击时比基线方法更有效，并且通过新的效用函数保持了对资源的控制。


<details>
  <summary>Details</summary>
Motivation: 现有FlipIt框架依赖少量启发式方法或专业学习技术，这会导致其僵化且无法适应新的攻击。本研究旨在解决这些局限性。

Method: 提出PoolFlip，一个多智能体gym环境，扩展了FlipIt游戏以支持攻防双方的高效学习。提出Flip-PSRO，一种多智能体强化学习（MARL）方法，利用基于种群的训练来训练防御智能体，使其能够泛化以应对一系列未知的、可能具有适应性的对手。

Result: 实验结果表明，Flip-PSRO防御者在泛化到训练中未暴露的启发式攻击方面，比基线方法有效性提高了2倍。新设计的基于所有权的效用函数确保了Flip-PSRO防御者在优化性能的同时，保持了对资源的高度控制。

Conclusion: Flip-PSRO是一种有效的MARL方法，通过种群训练提高了防御者应对未知和适应性对手的能力，并且通过优化的效用函数实现了对资源的有效控制。

Abstract: Cyber defense requires automating defensive decision-making under stealthy,
deceptive, and continuously evolving adversarial strategies. The FlipIt game
provides a foundational framework for modeling interactions between a defender
and an advanced adversary that compromises a system without being immediately
detected. In FlipIt, the attacker and defender compete to control a shared
resource by performing a Flip action and paying a cost. However, the existing
FlipIt frameworks rely on a small number of heuristics or specialized learning
techniques, which can lead to brittleness and the inability to adapt to new
attacks. To address these limitations, we introduce PoolFlip, a multi-agent gym
environment that extends the FlipIt game to allow efficient learning for
attackers and defenders. Furthermore, we propose Flip-PSRO, a multi-agent
reinforcement learning (MARL) approach that leverages population-based training
to train defender agents equipped to generalize against a range of unknown,
potentially adaptive opponents. Our empirical results suggest that Flip-PSRO
defenders are $2\times$ more effective than baselines to generalize to a
heuristic attack not exposed in training. In addition, our newly designed
ownership-based utility functions ensure that Flip-PSRO defenders maintain a
high level of control while optimizing performance.

</details>


### [294] [Learning Game-Playing Agents with Generative Code Optimization](https://arxiv.org/abs/2508.19506)
*Zhiyi Kuang,Ryan Rong,YuCheng Yuan,Allen Nie*

Main category: cs.LG

TL;DR: 提出一种生成式方法，使用LLMs将策略表示为Python程序，并进行优化，以训练游戏AI。该方法能让AI通过执行和反馈进行自我改进，在雅达利游戏中取得了与深度强化学习相当的性能，同时训练时间和环境交互更少。


<details>
  <summary>Details</summary>
Motivation: 提出一种新颖的生成式优化方法，用于学习游戏AI的策略，将策略表示为Python程序，并利用大型语言模型（LLMs）进行优化，以提高AI的学习效率和适应性。

Method: 将决策策略表示为可自我演化的代码，以当前观察作为输入，以游戏动作作为输出。利用执行轨迹和自然语言反馈，在极少人工干预的情况下进行自我改进。

Result: 在雅达利游戏中，所提出的游戏AI在性能上能与深度强化学习基线相媲美，同时训练时间和环境交互次数显著减少。

Conclusion: 编程策略表示方法有望用于构建高效、适应性强的AI，能够进行复杂、长周期的推理。

Abstract: We present a generative optimization approach for learning game-playing
agents, where policies are represented as Python programs and refined using
large language models (LLMs). Our method treats decision-making policies as
self-evolving code, with current observation as input and an in-game action as
output, enabling agents to self-improve through execution traces and natural
language feedback with minimal human intervention. Applied to Atari games, our
game-playing Python program achieves performance competitive with deep
reinforcement learning (RL) baselines while using significantly less training
time and much fewer environment interactions. This work highlights the promise
of programmatic policy representations for building efficient, adaptable agents
capable of complex, long-horizon reasoning.

</details>


### [295] [MobText-SISA: Efficient Machine Unlearning for Mobility Logs with Spatio-Temporal and Natural-Language Data](https://arxiv.org/abs/2508.19554)
*Haruki Yonekura,Ren Ozeki,Tatsuya Amano,Hamada Rizk,Hirozumi Yamaguchi*

Main category: cs.LG

TL;DR: MobText-SISA是一个可扩展的机器学习框架，用于在删除用户数据时保持模型准确性，特别适用于城市规模的多模态出行数据。


<details>
  <summary>Details</summary>
Motivation: 现有深度学习模型在处理大规模GPS轨迹、时间元数据和文本笔记等异构时空数据时，难以满足GDPR等隐私法规要求的用户数据删除需求，因为每次删除都重新训练模型成本过高。

Method: MobText-SISA采用SISA（分片、隔离、切片和聚合）训练方法，将每个行程的数值和语言特征嵌入共享的潜在空间。通过相似感知聚类将样本分配到分片，确保删除操作仅影响单个模型，同时保留分片间的多样性。每个分片进行增量训练，推理时聚合各分片预测。删除请求仅触发受影响分片从最后一个有效检查点重新训练，实现精确的遗忘。

Result: 在为期十个月的真实世界出行日志实验中，MobText-SISA在保持预测准确性方面与基线模型相当，并且在错误率和收敛速度方面均优于随机分片方法。

Conclusion: MobText-SISA为城市规模的多模态出行数据提供了一个实用的、符合隐私要求的分析基础，解决了大规模数据删除的挑战。

Abstract: Modern mobility platforms have stored vast streams of GPS trajectories,
temporal metadata, free-form textual notes, and other unstructured data.
Privacy statutes such as the GDPR require that any individual's contribution be
unlearned on demand, yet retraining deep models from scratch for every request
is untenable. We introduce MobText-SISA, a scalable machine-unlearning
framework that extends Sharded, Isolated, Sliced, and Aggregated (SISA)
training to heterogeneous spatio-temporal data. MobText-SISA first embeds each
trip's numerical and linguistic features into a shared latent space, then
employs similarity-aware clustering to distribute samples across shards so that
future deletions touch only a single constituent model while preserving
inter-shard diversity. Each shard is trained incrementally; at inference time,
constituent predictions are aggregated to yield the output. Deletion requests
trigger retraining solely of the affected shard from its last valid checkpoint,
guaranteeing exact unlearning. Experiments on a ten-month real-world mobility
log demonstrate that MobText-SISA (i) sustains baseline predictive accuracy,
and (ii) consistently outperforms random sharding in both error and convergence
speed. These results establish MobText-SISA as a practical foundation for
privacy-compliant analytics on multimodal mobility data at urban scale.

</details>


### [296] [Just Because You Can, Doesn't Mean You Should: LLMs for Data Fitting](https://arxiv.org/abs/2508.19563)
*Hejia Liu,Mochen Yang,Gediminas Adomavicius*

Main category: cs.LG

TL;DR: LLMs在数据拟合任务中表现出对任务无关的输入变化的敏感性，这种敏感性源于模型内部的非均匀注意力模式，尽管专门为数据拟合设计的模型（如TabPFN）也存在此问题，但LLMs目前缺乏基本鲁棒性，不能作为可靠的数据拟合工具。


<details>
  <summary>Details</summary>
Motivation: 评估LLMs作为数据拟合工具的鲁棒性，特别是在面对与学习任务无关的数据表示变化时的表现。

Method: 通过实验比较LLMs（包括上下文学习和监督微调）以及TabPFN在面对变量重命名等任务无关变化时对预测结果的影响，并分析了LLM的注意力模式。

Result: LLMs对任务无关的数据表示变化（如变量重命名）非常敏感，预测误差变化最高可达82%。这种敏感性在上下文学习和监督微调下均存在，并且与模型是否开放权重无关。LLM的注意力模式显示出非均匀性，某些位置的训练样本和变量名/值会获得不成比例的关注。即使是专门设计的TabPFN也未能完全免疫这种敏感性。

Conclusion: 尽管LLMs具有强大的预测能力，但它们在数据拟合任务中对任务无关变化的鲁棒性不足，这限制了它们作为可靠数据拟合工具的应用。未来的研究应关注提高LLMs在数据拟合任务中的鲁棒性。

Abstract: Large Language Models (LLMs) are being applied in a wide array of settings,
well beyond the typical language-oriented use cases. In particular, LLMs are
increasingly used as a plug-and-play method for fitting data and generating
predictions. Prior work has shown that LLMs, via in-context learning or
supervised fine-tuning, can perform competitively with many tabular supervised
learning techniques in terms of predictive performance. However, we identify a
critical vulnerability of using LLMs for data fitting -- making changes to data
representation that are completely irrelevant to the underlying learning task
can drastically alter LLMs' predictions on the same data. For example, simply
changing variable names can sway the size of prediction error by as much as 82%
in certain settings. Such prediction sensitivity with respect to
task-irrelevant variations manifests under both in-context learning and
supervised fine-tuning, for both close-weight and open-weight general-purpose
LLMs. Moreover, by examining the attention scores of an open-weight LLM, we
discover a non-uniform attention pattern: training examples and variable
names/values which happen to occupy certain positions in the prompt receive
more attention when output tokens are generated, even though different
positions are expected to receive roughly the same attention. This partially
explains the sensitivity in the presence of task-irrelevant variations. We also
consider a state-of-the-art tabular foundation model (TabPFN) trained
specifically for data fitting. Despite being explicitly designed to achieve
prediction robustness, TabPFN is still not immune to task-irrelevant
variations. Overall, despite LLMs' impressive predictive capabilities,
currently they lack even the basic level of robustness to be used as a
principled data-fitting tool.

</details>


### [297] [Bi-LoRA: Efficient Sharpness-Aware Minimization for Fine-Tuning Large-Scale Models](https://arxiv.org/abs/2508.19564)
*Yuhang Liu,Tao Li,Zhehao Huang,Zuopeng Yang,Xiaolin Huang*

Main category: cs.LG

TL;DR: SAM对于大型模型来说过于昂贵，Bi-LoRA通过引入辅助LoRA模块来为SAM的扰动建模，从而在不增加额外成本的情况下提高泛化能力。


<details>
  <summary>Details</summary>
Motivation: 直接将SAM应用于LoRA参数会限制其在狭窄的子空间中优化，从而影响其有效性。

Method: 提出了一种名为Bi-LoRA的双向低秩适配方法，该方法引入了一个辅助LoRA模块来模拟SAM的对抗性权重扰动，将SAM的权重扰动与LoRA优化分离。主要LoRA模块通过标准的梯度下降进行任务自适应，而辅助模块通过梯度上升来捕捉损失景观的锐度。

Result: Bi-LoRA能够捕捉更广泛的锐度以实现更平坦的最小值，同时保持内存效率，并且没有增加SAM的双重训练成本。

Conclusion: Bi-LoRA在各种任务和架构上的广泛实验证明了其在提高泛化能力方面的效率和有效性。

Abstract: Fine-tuning large-scale pre-trained models with limited data presents
significant challenges for generalization. While Sharpness-Aware Minimization
(SAM) has proven effective in improving generalization by seeking flat minima,
its substantial extra memory and computation overhead make it impractical for
large models. Integrating SAM with parameter-efficient fine-tuning methods like
Low-Rank Adaptation (LoRA) is a promising direction. However, we find that
directly applying SAM to LoRA parameters limits the sharpness optimization to a
restricted subspace, hindering its effectiveness. To address this limitation,
we propose Bi-directional Low-Rank Adaptation (Bi-LoRA), which introduces an
auxiliary LoRA module to model SAM's adversarial weight perturbations. It
decouples SAM's weight perturbations from LoRA optimization: the primary LoRA
module adapts to specific tasks via standard gradient descent, while the
auxiliary module captures the sharpness of the loss landscape through gradient
ascent. Such dual-module design enables Bi-LoRA to capture broader sharpness
for achieving flatter minima while remaining memory-efficient. Another
important benefit is that the dual design allows for simultaneous optimization
and perturbation, eliminating SAM's doubled training costs. Extensive
experiments across diverse tasks and architectures demonstrate Bi-LoRA's
efficiency and effectiveness in enhancing generalization.

</details>


### [298] [Counterfactual Reward Model Training for Bias Mitigation in Multimodal Reinforcement Learning](https://arxiv.org/abs/2508.19567)
*Sheryl Mathew,N Harshit*

Main category: cs.LG

TL;DR: RLHF中的奖励模型会放大训练数据中的潜在偏见，导致策略优化不完善和公平性下降。本文提出了一种反事实奖励模型，结合因果推断和多模态表示学习，提供了一种无监督的、抗偏见的奖励信号。该模型的核心是反事实信任得分，包含四个部分：反事实移位、重建不确定性、公平性规则违反和时间奖励移位。在多模态虚假新闻数据集上的评估显示，该模型在虚假新闻检测方面准确率达到89.12%，优于基线模型，并减少了虚假相关性和不公平的强化信号。该方法为公平感知RLHF提供了一个鲁棒且可解释的途径。


<details>
  <summary>Details</summary>
Motivation: RLHF中的奖励模型会放大训练数据中的潜在偏见，导致策略优化不完善和公平性下降，而传统的偏见缓解方法在因果混淆下可能失效。

Method: 提出一种反事实奖励模型，结合因果推断和多模态表示学习，构建包含反事实移位、重建不确定性、公平性规则违反和时间奖励移位四个组成部分的反事实信任得分，以提供无监督、抗偏见的奖励信号。

Result: 在多模态虚假新闻数据集上，该模型实现了89.12%的虚假新闻检测准确率，优于基线奖励模型，并有效减少了虚假相关性和不公平的强化信号，同时提高了模型对注入偏差的鲁棒性。

Conclusion: 该框架提供了一种鲁棒且可解释的公平感知RLHF方法，具有可调的偏见降低阈值，提高了动态实时策略制定的可靠性。

Abstract: In reinforcement learning with human feedback (RLHF), reward models can
efficiently learn and amplify latent biases within multimodal datasets, which
can lead to imperfect policy optimization through flawed reward signals and
decreased fairness. Bias mitigation studies have often applied passive
constraints, which can fail under causal confounding. Here, we present a
counterfactual reward model that introduces causal inference with multimodal
representation learning to provide an unsupervised, bias-resilient reward
signal. The heart of our contribution is the Counterfactual Trust Score, an
aggregated score consisting of four components: (1) counterfactual shifts that
decompose political framing bias from topical bias; (2) reconstruction
uncertainty during counterfactual perturbations; (3) demonstrable violations of
fairness rules for each protected attribute; and (4) temporal reward shifts
aligned with dynamic trust measures. We evaluated the framework on a multimodal
fake versus true news dataset, which exhibits framing bias, class imbalance,
and distributional drift. Following methodologies similar to unsupervised drift
detection from representation-based distances [1] and temporal robustness
benchmarking in language models [2], we also inject synthetic bias across
sequential batches to test robustness. The resulting system achieved an
accuracy of 89.12% in fake news detection, outperforming the baseline reward
models. More importantly, it reduced spurious correlations and unfair
reinforcement signals. This pipeline outlines a robust and interpretable
approach to fairness-aware RLHF, offering tunable bias reduction thresholds and
increasing reliability in dynamic real-time policy making.

</details>


### [299] [Quantum latent distributions in deep generative models](https://arxiv.org/abs/2508.19857)
*Omar Bacarreza,Thorin Farnsworth,Alexander Makarovskiy,Hugo Wallner,Tessa Hicks,Santiago Sempere-Llagostera,John Price,Robert J. A. Francis-Jones,William R. Clements*

Main category: cs.LG

TL;DR: 文章介绍了使用量子处理器生成的量子潜在分布可以提升深度生成模型的性能，并证明了在特定条件下，量子潜在分布比经典潜在分布具有更优的生成能力。


<details>
  <summary>Details</summary>
Motivation: 研究量子潜在分布在深度生成模型中的应用及其性能提升的可行性和可复现性。

Method: 利用量子处理器生成量子潜在分布，并将其应用于生成对抗网络（GANs）、扩散模型和流匹配模型。通过在合成量子数据集和QM9分子数据集上进行实验，并与经典基线进行比较。

Result: 实验结果表明，量子潜在分布在GANs中相比经典基线能带来性能提升，并确认了近端量子处理器能够扩展深度生成模型的性能。

Conclusion: 近端量子处理器能够扩展深度生成模型的性能，量子潜在分布在特定条件下可以生成经典潜在分布无法有效生成的后验分布。

Abstract: Many successful families of generative models leverage a low-dimensional
latent distribution that is mapped to a data distribution. Though simple latent
distributions are commonly used, it has been shown that more sophisticated
distributions can improve performance. For instance, recent work has explored
using the distributions produced by quantum processors and found empirical
improvements. However, when latent space distributions produced by quantum
processors can be expected to improve performance, and whether these
improvements are reproducible, are open questions that we investigate in this
work. We prove that, under certain conditions, these "quantum latent
distributions" enable generative models to produce data distributions that
classical latent distributions cannot efficiently produce. We also provide
actionable intuitions to identify when such quantum advantages may arise in
real-world settings. We perform benchmarking experiments on both a synthetic
quantum dataset and the QM9 molecular dataset, using both simulated and real
photonic quantum processors. Our results demonstrate that quantum latent
distributions can lead to improved generative performance in GANs compared to a
range of classical baselines. We also explore diffusion and flow matching
models, identifying architectures compatible with quantum latent distributions.
This work confirms that near-term quantum processors can expand the
capabilities of deep generative models.

</details>


### [300] [Generative Models for Synthetic Data: Transforming Data Mining in the GenAI Era](https://arxiv.org/abs/2508.19570)
*Dawei Li,Yue Huang,Ming Li,Tianyi Zhou,Xiangliang Zhang,Huan Liu*

Main category: cs.LG

TL;DR: 生成模型（如 LLM、扩散模型、GAN）在合成数据生成方面取得了革命性进展，解决了数据稀缺、隐私和标注挑战。本教程介绍了合成数据生成的基础、最新进展、关键方法、实用框架、评估策略和应用。


<details>
  <summary>Details</summary>
Motivation: 生成模型在数据挖掘中解决了数据稀缺、隐私和标注挑战，提供了可扩展的解决方案。

Method: 本教程介绍了合成数据生成的基础、最新进展、关键方法、实用框架、评估策略和应用。

Result: 与会者将获得关于利用生成合成数据来加强数据挖掘研究和实践的可行见解。

Conclusion: 生成模型为数据挖掘带来了合成数据的革命，本教程将提供相关知识和实践指导。

Abstract: Generative models such as Large Language Models, Diffusion Models, and
generative adversarial networks have recently revolutionized the creation of
synthetic data, offering scalable solutions to data scarcity, privacy, and
annotation challenges in data mining. This tutorial introduces the foundations
and latest advances in synthetic data generation, covers key methodologies and
practical frameworks, and discusses evaluation strategies and applications.
Attendees will gain actionable insights into leveraging generative synthetic
data to enhance data mining research and practice. More information can be
found on our website: https://syndata4dm.github.io/.

</details>


### [301] [Escaping Stability-Plasticity Dilemma in Online Continual Learning for Motion Forecasting via Synergetic Memory Rehearsal](https://arxiv.org/abs/2508.19571)
*Yunlong Lin,Chao Lu,Tongshuai Wu,Xiaocong Zhao,Guodong Du,Yanwei Sun,Zirui Li,Jianwei Gong*

Main category: cs.LG

TL;DR: 本研究提出了一种名为SyReM的新型持续学习方法，用于解决深度神经网络（DNN）在运动预测中遇到的灾难性遗忘问题，并在新旧数据之间取得良好的平衡。


<details>
  <summary>Details</summary>
Motivation: 深度神经网络在运动预测方面取得了显著成功，但它们在适应新数据时会遗忘先前学到的知识，即灾难性遗忘。而现有的持续学习（CL）方法在增强记忆稳定性（保留知识的能力）时，往往会损害学习可塑性（有效获取新信息的能力）。为了解决这种稳定-可塑性困境，本研究提出了一种新的CL方法。

Method: 本研究提出了一种名为synergetic memory rehearsal (SyReM) 的新方法。SyReM维护一个紧凑的内存缓冲区来表示学习到的知识。为了确保记忆稳定性，它采用了一个不等式约束，限制了内存缓冲区上平均损失的增量。为了增强学习可塑性，它设计了一种选择性内存回放机制，通过选择与最近观察到的数据最相似的样本来增强学习可塑性。这种选择基于损失梯度的在线测量余弦相似度，确保了有针对性的内存回放。由于回放的样本来自已学习的场景，这种内存回放机制避免了损害记忆稳定性。

Result: 研究结果表明，SyReM在INTERACTION数据集的11个自然驾驶数据集上进行了验证，与非CL和CL基线方法相比，SyReM显著减轻了过去场景的灾难性遗忘，同时提高了新场景的预测准确性。

Conclusion: SyReM通过一种新颖的内存管理和回放机制，成功解决了DNN在运动预测中的灾难性遗忘问题，并在保持对旧场景记忆的同时，提高了对新场景的学习能力。

Abstract: Deep neural networks (DNN) have achieved remarkable success in motion
forecasting. However, most DNN-based methods suffer from catastrophic
forgetting and fail to maintain their performance in previously learned
scenarios after adapting to new data. Recent continual learning (CL) studies
aim to mitigate this phenomenon by enhancing memory stability of DNN, i.e., the
ability to retain learned knowledge. Yet, excessive emphasis on the memory
stability often impairs learning plasticity, i.e., the capacity of DNN to
acquire new information effectively. To address such stability-plasticity
dilemma, this study proposes a novel CL method, synergetic memory rehearsal
(SyReM), for DNN-based motion forecasting. SyReM maintains a compact memory
buffer to represent learned knowledge. To ensure memory stability, it employs
an inequality constraint that limits increments in the average loss over the
memory buffer. Synergistically, a selective memory rehearsal mechanism is
designed to enhance learning plasticity by selecting samples from the memory
buffer that are most similar to recently observed data. This selection is based
on an online-measured cosine similarity of loss gradients, ensuring targeted
memory rehearsal. Since replayed samples originate from learned scenarios, this
memory rehearsal mechanism avoids compromising memory stability. We validate
SyReM under an online CL paradigm where training samples from diverse scenarios
arrive as a one-pass stream. Experiments on 11 naturalistic driving datasets
from INTERACTION demonstrate that, compared to non-CL and CL baselines, SyReM
significantly mitigates catastrophic forgetting in past scenarios while
improving forecasting accuracy in new ones. The implementation is publicly
available at https://github.com/BIT-Jack/SyReM.

</details>


### [302] [Delta-Audit: Explaining What Changes When Models Change](https://arxiv.org/abs/2508.19589)
*Arshia Hemmat,Afsaneh Fatemi*

Main category: cs.LG

TL;DR: Delta-Attribution是一个模型无关的框架，通过差异化每特征归因来解释模型版本A和B之间‘发生了什么变化’。该框架通过评估套件进行评估，涵盖了多个方面，并在45种设置中进行了审计，揭示了不同类型的模型更新对模型行为的影响。


<details>
  <summary>Details</summary>
Motivation: 解释模型更新（如超参数、核、深度、求解器或数据更改）如何影响模型性能，以及这些变化背后的具体原因。

Method: 提出Delta-Attribution ($\Delta$-Attribution)框架，通过计算两个模型版本（A和B）的每特征归因之差 ($\Delta\phi(x)=\phi_B(x)-\phi_A(x)$) 来量化和解释模型之间的差异。使用质量套件评估$\Delta\phi$，该套件包括了幅度/稀疏性、一致性/偏移、行为对齐和鲁棒性等指标。具体实现上，在标准化空间中通过快速遮挡/钳位，并结合类锚定边距和基线平均。

Result: 在45种设置（包括5种经典模型、3个数据集和3种A/B配对）的审计中，发现归纳偏置（inductive-bias）的变化会导致较大且与行为一致的Delta（例如，SVC核从poly变为rbf，BAC约为0.998，DCE约为6.6）；而‘表面’调整（如SVC gamma设置或kNN搜索）则显示出高度的排名重叠（rank-overlap@10=1.0）和较低的DCE。深度GB模型在乳腺癌数据集上显示出最大的特征归因重分布（JSD约为0.357）。

Conclusion: Delta-Attribution提供了一种轻量级的模型更新审计方法，它能够区分良性变化与行为上重要或有风险的依赖性转移，是对准确性指标的重要补充。

Abstract: Model updates (new hyperparameters, kernels, depths, solvers, or data) change
performance, but the \emph{reason} often remains opaque. We introduce
\textbf{Delta-Attribution} (\mbox{$\Delta$-Attribution}), a model-agnostic
framework that explains \emph{what changed} between versions $A$ and $B$ by
differencing per-feature attributions: $\Delta\phi(x)=\phi_B(x)-\phi_A(x)$. We
evaluate $\Delta\phi$ with a \emph{$\Delta$-Attribution Quality Suite} covering
magnitude/sparsity (L1, Top-$k$, entropy), agreement/shift (rank-overlap@10,
Jensen--Shannon divergence), behavioural alignment (Delta Conservation Error,
DCE; Behaviour--Attribution Coupling, BAC; CO$\Delta$F), and robustness (noise,
baseline sensitivity, grouped occlusion).
  Instantiated via fast occlusion/clamping in standardized space with a
class-anchored margin and baseline averaging, we audit 45 settings: five
classical families (Logistic Regression, SVC, Random Forests, Gradient
Boosting, $k$NN), three datasets (Breast Cancer, Wine, Digits), and three A/B
pairs per family. \textbf{Findings.} Inductive-bias changes yield large,
behaviour-aligned deltas (e.g., SVC poly$\!\rightarrow$rbf on Breast Cancer:
BAC$\approx$0.998, DCE$\approx$6.6; Random Forest feature-rule swap on Digits:
BAC$\approx$0.997, DCE$\approx$7.5), while ``cosmetic'' tweaks (SVC
\texttt{gamma=scale} vs.\ \texttt{auto}, $k$NN search) show
rank-overlap@10$=1.0$ and DCE$\approx$0. The largest redistribution appears for
deeper GB on Breast Cancer (JSD$\approx$0.357). $\Delta$-Attribution offers a
lightweight update audit that complements accuracy by distinguishing benign
changes from behaviourally meaningful or risky reliance shifts.

</details>


### [303] [Complementary Learning System Empowers Online Continual Learning of Vehicle Motion Forecasting in Smart Cities](https://arxiv.org/abs/2508.19597)
*Zirui Li,Yunlong Lin,Guodong Du,Xiaocong Zhao,Cheng Gong,Chen Lv,Chao Lu,Jianwei Gong*

Main category: cs.LG

TL;DR: 在智能交通预测中，Dual-LS通过模仿人类大脑的双重记忆机制，有效解决了灾难性遗忘问题，提升了模型效率和预测稳定性。


<details>
  <summary>Details</summary>
Motivation: 当前智能城市交通服务依赖人工智能，但基于深度神经网络（DNN）的车辆运动预测模型在更新时会遗忘旧知识（灾难性遗忘）。现有方法如扩大训练集或回放数据成本高、效率低，且无法平衡长期和短期记忆，不具备人类的学习能力。

Method: 提出了一种名为Dual-LS的、无任务的、在线持续学习范式，用于DNN车辆运动预测。该方法借鉴人脑互补学习系统，包含两种协同的记忆回放机制，以加速经验检索，并动态协调长期和短期知识表征。

Result: 在包含三个国家、超过77.2万辆车和累计11,187公里测试里程的自然数据集上测试，Dual-LS将灾难性遗忘减少了高达74.31%，并将计算资源需求降低了高达94.02%。

Conclusion: Dual-LS在不增加数据需求的情况下，显著提高了车辆运动预测的预测稳定性，并赋予了DNN车辆运动预测模型计算高效、类似人类的持续学习适应能力，非常适合智能城市的应用。

Abstract: Artificial intelligence underpins most smart city services, yet deep neural
network (DNN) that forecasts vehicle motion still struggle with catastrophic
forgetting, the loss of earlier knowledge when models are updated. Conventional
fixes enlarge the training set or replay past data, but these strategies incur
high data collection costs, sample inefficiently and fail to balance long- and
short-term experience, leaving them short of human-like continual learning.
Here we introduce Dual-LS, a task-free, online continual learning paradigm for
DNN-based motion forecasting that is inspired by the complementary learning
system of the human brain. Dual-LS pairs two synergistic memory rehearsal
replay mechanisms to accelerate experience retrieval while dynamically
coordinating long-term and short-term knowledge representations. Tests on
naturalistic data spanning three countries, over 772,000 vehicles and
cumulative testing mileage of 11,187 km show that Dual-LS mitigates
catastrophic forgetting by up to 74.31\% and reduces computational resource
demand by up to 94.02\%, markedly boosting predictive stability in vehicle
motion forecasting without inflating data requirements. Meanwhile, it endows
DNN-based vehicle motion forecasting with computation efficient and human-like
continual learning adaptability fit for smart cities.

</details>


### [304] [Encouraging Good Processes Without the Need for Good Answers: Reinforcement Learning for LLM Agent Planning](https://arxiv.org/abs/2508.19598)
*Zhiwei Li,Yong Hu,Wenqing Wang*

Main category: cs.LG

TL;DR: RLTR框架通过解耦训练过程，专注于优化LLM代理的规划能力，并引入基于工具使用完整性的奖励信号，显著提高了规划和响应质量。


<details>
  <summary>Details</summary>
Motivation: 现有LLM代理训练范式采用端到端、多目标优化，难以提升代理的核心能力——动作规划，面临优化目标分配不均和可验证数据稀缺的挑战。

Method: 提出RLTR（Reinforcement Learning with Tool-use Rewards）框架，将规划和回答摘要训练解耦，实现规划模块的单一目标优化。RLTR引入基于工具使用完整性的奖励信号，直接评估工具调用序列的质量，无需可验证数据。

Result: RLTR在规划能力上比端到端基线提高了8%-12%，整体代理系统的最终响应质量提高了5%-6%。

Conclusion: RLTR通过解耦训练和引入基于工具使用完整性的奖励信号，有效解决了LLM代理规划能力提升的难题，并最终提升了代理系统的整体性能。

Abstract: The functionality of Large Language Model (LLM) agents is primarily
determined by two capabilities: action planning and answer summarization. The
former, action planning, is the core capability that dictates an agent's
performance. However, prevailing training paradigms employ end-to-end,
multi-objective optimization that jointly trains both capabilities. This
paradigm faces two critical challenges: imbalanced optimization objective
allocation and scarcity of verifiable data, making it difficult to enhance the
agent's planning capability. To address these challenges, we propose
Reinforcement Learning with Tool-use Rewards (RLTR), a novel framework that
decouples the training process to enable a focused, single-objective
optimization of the planning module. Crucially, RLTR introduces a reward signal
based on tool-use completeness to directly evaluate the quality of tool
invocation sequences. This method offers a more direct and reliable training
signal than assessing the final response content, thereby obviating the need
for verifiable data. Our experiments demonstrate that RLTR achieves an 8%-12%
improvement in planning performance compared to end-to-end baselines. Moreover,
this enhanced planning capability, in turn, translates to a 5%-6% increase in
the final response quality of the overall agent system.

</details>


### [305] [FinCast: A Foundation Model for Financial Time-Series Forecasting](https://arxiv.org/abs/2508.19609)
*Zhuohang Zhu,Haodong Chen,Qiang Qu,Vera Chung*

Main category: cs.LG

TL;DR: FinCast是一个针对金融时间序列预测的金融基础模型，在大量金融数据集上进行了训练。它在零样本场景下表现出强大的性能，能够有效捕捉多种模式，而无需进行特定领域的微调，并且在各项评估中表现优于现有的最先进方法。


<details>
  <summary>Details</summary>
Motivation: 金融时间序列预测对于维持经济稳定、指导明智的政策制定以及促进可持续的投资实践至关重要。然而，由于各种潜在的模式变化，它仍然是一个挑战。

Method: 提出了一种名为FinCast的基础模型，该模型专门为金融时间序列预测而设计，并在大规模金融数据集上进行了训练。

Result: FinCast在零样本场景下表现出强大的性能，能够有效捕捉多种模式，而无需进行特定领域的微调。全面的实证和定性评估表明，FinCast的表现优于现有的最先进方法，展示了其强大的泛化能力。

Conclusion: FinCast是第一个专门为金融时间序列预测而设计的金融基础模型，在零样本场景下表现出色，并超越了现有的最先进方法。

Abstract: Financial time-series forecasting is critical for maintaining economic
stability, guiding informed policymaking, and promoting sustainable investment
practices. However, it remains challenging due to various underlying pattern
shifts. These shifts arise primarily from three sources: temporal
non-stationarity (distribution changes over time), multi-domain diversity
(distinct patterns across financial domains such as stocks, commodities, and
futures), and varying temporal resolutions (patterns differing across
per-second, hourly, daily, or weekly indicators). While recent deep learning
methods attempt to address these complexities, they frequently suffer from
overfitting and typically require extensive domain-specific fine-tuning. To
overcome these limitations, we introduce FinCast, the first foundation model
specifically designed for financial time-series forecasting, trained on
large-scale financial datasets. Remarkably, FinCast exhibits robust zero-shot
performance, effectively capturing diverse patterns without domain-specific
fine-tuning. Comprehensive empirical and qualitative evaluations demonstrate
that FinCast surpasses existing state-of-the-art methods, highlighting its
strong generalization capabilities.

</details>


### [306] [ALSA: Anchors in Logit Space for Out-of-Distribution Accuracy Estimation](https://arxiv.org/abs/2508.19613)
*Chenzhi Liu,Mahsa Baktashmotlagh,Yanran Tang,Zi Huang,Ruihong Qiu*

Main category: cs.LG

TL;DR: ALSA是一个在新颖的框架，通过直接在logit空间操作来保留更丰富的信息，以估计模型在新、未标记数据集上的准确性。


<details>
  <summary>Details</summary>
Motivation: 在分布偏移可能降低性能的情况下，在不可见、未标记的数据集上估计模型准确性对于实际的机器学习应用至关重要。现有方法依赖于预测类别概率（softmax分数）或数据相似性度量，但这些方法要么丢失信息，要么计算成本高昂且领域特定。

Method: ALSA框架利用anchor-based建模策略，在logit空间中初始化多个可学习的anchor，并为每个anchor分配一个捕捉logits细微差别的函数。通过聚合和分析logits的分布，ALSA能够准确估计模型性能。

Result: ALSA在视觉、语言和图基准测试上展现了优于基于softmax和基于相似性方法的性能，特别是在显著的分布偏移下表现出鲁棒性。

Conclusion: ALSA是一个强大而可靠的框架，用于在新、未标记的数据集上估计模型准确性，尤其是在存在分布偏移的情况下，这使其成为可靠模型评估的实用工具。

Abstract: Estimating model accuracy on unseen, unlabeled datasets is crucial for
real-world machine learning applications, especially under distribution shifts
that can degrade performance. Existing methods often rely on predicted class
probabilities (softmax scores) or data similarity metrics. While softmax-based
approaches benefit from representing predictions on the standard simplex,
compressing logits into probabilities leads to information loss. Meanwhile,
similarity-based methods can be computationally expensive and domain-specific,
limiting their broader applicability. In this paper, we introduce ALSA (Anchors
in Logit Space for Accuracy estimation), a novel framework that preserves
richer information by operating directly in the logit space. Building on
theoretical insights and empirical observations, we demonstrate that the
aggregation and distribution of logits exhibit a strong correlation with the
predictive performance of the model. To exploit this property, ALSA employs an
anchor-based modeling strategy: multiple learnable anchors are initialized in
logit space, each assigned an influence function that captures subtle
variations in the logits. This allows ALSA to provide robust and accurate
performance estimates across a wide range of distribution shifts. Extensive
experiments on vision, language, and graph benchmarks demonstrate ALSA's
superiority over both softmax- and similarity-based baselines. Notably, ALSA's
robustness under significant distribution shifts highlights its potential as a
practical tool for reliable model evaluation.

</details>


### [307] [Towards Instance-wise Personalized Federated Learning via Semi-Implicit Bayesian Prompt Tuning](https://arxiv.org/abs/2508.19621)
*Tiandi Ye,Wenyan Liu,Kai Yao,Lichun Li,Shangchao Su,Cen Chen,Xiang Li,Shan Yin,Ming Gao*

Main category: cs.LG

TL;DR: pFedBayesPT是一种基于视觉提示调优的个性化联邦学习框架，解决了客户端内数据异质性问题，并在特征和标签异质性设置下均优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有个性化联邦学习（pFL）方法假设客户端数据来自单一分布，这在客户端内数据异质性（来自多个源或域）的情况下表现不佳。本研究旨在解决这一挑战。

Method: 提出pFedBayesPT，一个基于视觉提示调优的细粒度、实例级别的pFL框架。从贝叶斯角度生成实例级别的提示，并将提示后验建模为隐式分布以捕捉多样化的视觉语义。在半隐式变分推断框架下推导变分训练目标。

Result: pFedBayesPT在基准数据集的实验中，无论是在特征异质性还是标签异质性设置下，都持续优于现有的pFL方法。

Conclusion: pFedBayesPT成功地解决了客户端内数据异质性问题，并实现了比现有pFL方法更好的性能。

Abstract: Federated learning (FL) is a privacy-preserving machine learning paradigm
that enables collaborative model training across multiple distributed clients
without disclosing their raw data. Personalized federated learning (pFL) has
gained increasing attention for its ability to address data heterogeneity.
However, most existing pFL methods assume that each client's data follows a
single distribution and learn one client-level personalized model for each
client. This assumption often fails in practice, where a single client may
possess data from multiple sources or domains, resulting in significant
intra-client heterogeneity and suboptimal performance. To tackle this
challenge, we propose pFedBayesPT, a fine-grained instance-wise pFL framework
based on visual prompt tuning. Specifically, we formulate instance-wise prompt
generation from a Bayesian perspective and model the prompt posterior as an
implicit distribution to capture diverse visual semantics. We derive a
variational training objective under the semi-implicit variational inference
framework. Extensive experiments on benchmark datasets demonstrate that
pFedBayesPT consistently outperforms existing pFL methods under both feature
and label heterogeneity settings.

</details>


### [308] [SCAR: A Characterization Scheme for Multi-Modal Dataset](https://arxiv.org/abs/2508.19659)
*Ri Su,Zhao Chen,Caleb Chen Cao,Nan Tang,Lei Chen*

Main category: cs.LG

TL;DR: 该研究提出了SCAR框架，用于表征数据集的内在结构属性（尺度、覆盖度、真实性和丰富性），并以此为基础构建了Foundation Data，即能保持完整数据集泛化行为的最小子集。研究还利用SCAR来估计多模态数据集的泛化偏差，并提出了SCAR引导的数据补全策略，以实现高效、模态感知的数据扩展。


<details>
  <summary>Details</summary>
Motivation: 当前数据中心的方法（如剪枝、压缩）在优化训练时理论洞察有限，尤其是在样本缩放的数据特征方面。传统观点过度关注数据量和训练效率，忽视了数据质量的结构性方面。本研究旨在填补这一空白，提供一种新的数据表征和优化方法。

Method: 提出SCAR框架，包含尺度、覆盖度、真实性和丰富性四个关键指标，用于表征数据集的内在结构属性。SCAR捕捉不随数据集缩放而改变的稳定特征。在此基础上，构建Foundation Data（保留完整数据集泛化行为的最小子集）。将单模态任务建模为阶梯函数，估计Foundation Data的大小分布，以捕获多模态数据集中跨模态的阶梯式泛化偏差。最后，基于泛化偏差提出SCAR引导的数据补全策略。

Result: 实验结果表明，SCAR能够有效预测数据效用并指导数据采集。研究通过在多样化的多模态数据集和模型架构上进行实验，验证了SCAR的有效性。

Conclusion: SCAR框架为理解和优化数据集提供了新的视角，尤其是在处理多模态数据和样本缩放时。Foundation Data的概念以及SCAR引导的数据补全策略，为提高模型泛化能力和数据利用效率提供了有效的解决方案。

Abstract: Foundation models exhibit remarkable generalization across diverse tasks,
largely driven by the characteristics of their training data. Recent
data-centric methods like pruning and compression aim to optimize training but
offer limited theoretical insight into how data properties affect
generalization, especially the data characteristics in sample scaling.
Traditional perspectives further constrain progress by focusing predominantly
on data quantity and training efficiency, often overlooking structural aspects
of data quality. In this study, we introduce SCAR, a principled scheme for
characterizing the intrinsic structural properties of datasets across four key
measures: Scale, Coverage, Authenticity, and Richness. Unlike prior
data-centric measures, SCAR captures stable characteristics that remain
invariant under dataset scaling, providing a robust and general foundation for
data understanding. Leveraging these structural properties, we introduce
Foundation Data-a minimal subset that preserves the generalization behavior of
the full dataset without requiring model-specific retraining. We model
single-modality tasks as step functions and estimate the distribution of the
foundation data size to capture step-wise generalization bias across modalities
in the target multi-modal dataset. Finally, we develop a SCAR-guided data
completion strategy based on this generalization bias, which enables efficient,
modality-aware expansion of modality-specific characteristics in multimodal
datasets. Experiments across diverse multi-modal datasets and model
architectures validate the effectiveness of SCAR in predicting data utility and
guiding data acquisition. Code is available at https://github.com/McAloma/SCAR.

</details>


### [309] [Metric spaces of walks and Lipschitz duality on graphs](https://arxiv.org/abs/2508.19709)
*R. Arnau,A. González Cortés,E. A. Sánchez Pérez,S. Sanjuan*

Main category: cs.LG

TL;DR: 本文研究了图上行走（步态）的度量结构，引入了加权度量来定义步态之间的距离，并分析了度量空间的性质。研究结果可用于估计邻近度、开发基于探索性步态的强化学习策略，以及在网络结构上进行Lipschitz回归。


<details>
  <summary>Details</summary>
Motivation: 研究图上行走（步态）的度量结构，为分析步态之间的相对距离（邻近度）提供理论基础。

Method: 引入加权度量来处理序列（步态），定义了基于顶点之间逐步距离和加权范数的步态距离。分析了所得度量空间的性质，并推导了邻近度的表示公式。

Result: 提出了度量框架，允许使用经典的度量建模工具，例如从步态子空间扩展Lipschitz函数，从而在保持基本性质的同时扩展邻近函数。

Conclusion: 该度量框架为分析和处理图上行走提供了基础，并在邻近度估计和强化学习等领域具有潜在应用价值。

Abstract: We study the metric structure of walks on graphs, understood as Lipschitz
sequences. To this end, a weighted metric is introduced to handle sequences,
enabling the definition of distances between walks based on stepwise vertex
distances and weighted norms. We analyze the main properties of these metric
spaces, which provides the foundation for the analysis of weaker forms of
instruments to measure relative distances between walks: proximities. We
provide some representation formulas for such proximities under different
assumptions and provide explicit constructions for these cases. The resulting
metric framework allows the use of classical tools from metric modeling, such
as the extension of Lipschitz functions from subspaces of walks, which permits
extending proximity functions while preserving fundamental properties via the
mentioned representations. Potential applications include the estimation of
proximities and the development of reinforcement learning strategies based on
exploratory walks, offering a robust approach to Lipschitz regression on
network structures.

</details>


### [310] [Tune My Adam, Please!](https://arxiv.org/abs/2508.19733)
*Theodoros Athanasiadis,Steven Adriaensen,Samuel Müller,Frank Hutter*

Main category: cs.LG

TL;DR: Adam-PFN是一种结合了冻融贝叶斯优化和预训练模型的新型超参数优化方法，能有效解决Adam优化器超参数调整的痛点，提高优化效率和泛化能力。


<details>
  <summary>Details</summary>
Motivation: Adam优化器虽然广泛使用，但其超参数调整过程繁琐且成本高昂。现有的冻融贝叶斯优化方法在处理Adam超参数时，由于缺乏对超参数影响学习过程的先验知识，效果受到限制。

Method: 提出了一种名为Adam-PFN的新型代理模型，用于Adam超参数的冻融贝叶斯优化。该模型结合了在TaskSet学习曲线上的预训练，并采用了一种名为CDF-augment的新型学习曲线增强方法，以人工增加训练样本数量。

Result: Adam-PFN在TaskSet评估任务上，提高了学习曲线外推能力，并加速了超参数优化过程，在分布外（OOD）任务上也表现出强大的性能。

Conclusion: Adam-PFN通过结合预训练代理模型和学习曲线增强技术，有效解决了Adam超参数优化中的挑战，提升了优化效率和模型在不同任务上的泛化能力。

Abstract: The Adam optimizer remains one of the most widely used optimizers in deep
learning, and effectively tuning its hyperparameters is key to optimizing
performance. However, tuning can be tedious and costly. Freeze-thaw Bayesian
Optimization (BO) is a recent promising approach for low-budget hyperparameter
tuning, but is limited by generic surrogates without prior knowledge of how
hyperparameters affect learning. We propose Adam-PFN, a new surrogate model for
Freeze-thaw BO of Adam's hyperparameters, pre-trained on learning curves from
TaskSet, together with a new learning curve augmentation method, CDF-augment,
which artificially increases the number of available training examples. Our
approach improves both learning curve extrapolation and accelerates
hyperparameter optimization on TaskSet evaluation tasks, with strong
performance on out-of-distribution (OOD) tasks.

</details>


### [311] [Fast 3D Diffusion for Scalable Granular Media Synthesis](https://arxiv.org/abs/2508.19752)
*Muhammad Moeeze Hassan,Régis Cottereau,Filippo Gatti,Patryk Dec*

Main category: cs.LG

TL;DR: 利用3D扩散模型和inpainting技术，提出了一种新的生成管线，可以直接合成大规模、物理真实的颗粒介质，解决了DEM模拟初始化阶段的计算瓶颈，实现了计算时间与样本大小的线性增长，并将3小时的DEM模拟缩短到20秒。


<details>
  <summary>Details</summary>
Motivation: 传统的DEM模拟初始化阶段计算量大，耗时较长，限制了大规模模拟的应用。

Method: 提出了一种两阶段的生成管线：首先，训练一个3D扩散模型生成颗粒介质的3D体素网格；然后，采用3D inpainting模型（基于2D inpainting技术，使用掩码输入）将这些网格无缝拼接起来，生成大规模样本。inpainting模型通过多种掩码策略和重绘技术来保证生成结果的连贯性和物理真实性。

Result: 该方法实现了计算时间与样本大小的线性增长。一个等同于3小时DEM模拟的1.2米长轨道合成，仅在20秒内完成。生成的体素网格可后处理为DEM兼容的颗粒几何。

Conclusion: 该方法提供了一种计算高效、可扩展的颗粒介质合成方案，能够实现物理上连贯的实时大规模颗粒介质合成，适用于工业应用。

Abstract: Simulating granular media, using Discrete Element Method is a computationally
intensive task. This is especially true during initialization phase, which
dominates total simulation time because of large displacements involved and
associated kinetic energy. We overcome this bottleneck with a novel generative
pipeline based on 3D diffusion models that directly synthesizes arbitrarily
large granular assemblies in their final and physically realistic
configurations. The approach frames the problem as a 3D generative modeling
task, consisting of a two-stage pipeline. First a diffusion model is trained to
generate independent 3D voxel grids representing granular media. Second, a 3D
inpainting model, adapted from 2D inpainting techniques using masked inputs,
stitches these grids together seamlessly, enabling synthesis of large samples
with physically realistic structure. The inpainting model explores several
masking strategies for the inputs to the underlying UNets by training the
network to infer missing portions of voxel grids from a concatenation of noised
tensors, masks, and masked tensors as input channels. The model also adapts a
2D repainting technique of re-injecting noise scheduler output with ground
truth to provide a strong guidance to the 3D model. This along with weighted
losses ensures long-term coherence over generation of masked regions. Both
models are trained on the same binarized 3D occupancy grids extracted from
small-scale DEM simulations, achieving linear scaling of computational time
with respect to sample size. Quantitatively, a 1.2 m long ballasted rail track
synthesis equivalent to a 3-hour DEM simulation, was completed under 20
seconds. The generated voxel grids can also be post-processed to extract grain
geometries for DEM-compatibility as well, enabling physically coherent,
real-time, scalable granular media synthesis for industrial applications.

</details>


### [312] [Interestingness First Classifiers](https://arxiv.org/abs/2508.19780)
*Ryoma Sato*

Main category: cs.LG

TL;DR: EUREKA是一个选择有趣特征的框架，旨在构建具有新颖性和可解释性的分类器，即使准确性有所降低。


<details>
  <summary>Details</summary>
Motivation: 探索构建具有新颖性、意想不到的特征的“有趣”分类器的目标，以支持知识发现和沟通。

Method: 利用大型语言模型对特征进行有趣性排序，并仅使用选定的有趣特征构建可解释的分类器。

Result: 在多个基准数据集上，EUREKA 成功识别出非显而易见但具有预测性的特征，例如在入住率检测数据集中，倾向于使用湿度而非 CO2 水平；在双论文数据集中，发现标题带冒号的论文更可能被引用。

Conclusion: EUREKA 提出的模型可以在准确性适中但重视新颖性和可解释性的场景中，支持新的知识发现和沟通方式。

Abstract: Most machine learning models are designed to maximize predictive accuracy. In
this work, we explore a different goal: building classifiers that are
interesting. An ``interesting classifier'' is one that uses unusual or
unexpected features, even if its accuracy is lower than the best possible
model. For example, predicting room congestion from CO2 levels achieves
near-perfect accuracy but is unsurprising. In contrast, predicting room
congestion from humidity is less accurate yet more nuanced and intriguing. We
introduce EUREKA, a simple framework that selects features according to their
perceived interestingness. Our method leverages large language models to rank
features by their interestingness and then builds interpretable classifiers
using only the selected interesting features. Across several benchmark
datasets, EUREKA consistently identifies features that are non-obvious yet
still predictive. For example, in the Occupancy Detection dataset, our method
favors humidity over CO2 levels and light intensity, producing classifiers that
achieve meaningful accuracy while offering insights. In the Twin Papers
dataset, our method discovers the rule that papers with a colon in the title
are more likely to be cited in the future. We argue that such models can
support new ways of knowledge discovery and communication, especially in
settings where moderate accuracy is sufficient but novelty and interpretability
are valued.

</details>


### [313] [PSO-Merging: Merging Models Based on Particle Swarm Optimization](https://arxiv.org/abs/2508.19839)
*Kehao Zhang,Shaolei Zhang,Yang Feng*

Main category: cs.LG

TL;DR: PSO-Merging是一种基于粒子群优化（PSO）的新型数据驱动模型合并方法，通过集成多个专家模型的优势来构建多任务模型，解决了现有数据无关方法性能受限以及数据驱动方法计算成本高或效果不佳的问题。实验结果表明，PSO-Merging在语言模型上优于基线合并方法，是一种更高效、可扩展的模型合并解决方案。


<details>
  <summary>Details</summary>
Motivation: 现有数据无关的模型合并方法因缺乏数据驱动的指导而存在性能局限。数据驱动的方法则面临计算成本高（梯度下降）或效果不佳（梯度无关方法）的挑战，尤其是在合并大型模型时。本研究旨在解决这些问题，提供一种更优的合并策略。

Method: 本研究提出了一种名为PSO-Merging的新型数据驱动合并方法，该方法基于粒子群优化（PSO）。具体来说，研究将预训练模型、专家模型和稀疏化专家模型作为粒子群的初始种群，通过多轮迭代优化，最终选取全局最优粒子作为合并后的模型。

Result: 在不同语言模型上的实验结果表明，PSO-Merging 方法的性能普遍优于现有的基线合并方法。

Conclusion: PSO-Merging 是一种基于粒子群优化（PSO）的新型数据驱动模型合并方法，相比于现有的基线方法，它能够更高效、可扩展地实现模型合并，并取得更好的性能。

Abstract: Model merging has emerged as an efficient strategy for constructing multitask
models by integrating the strengths of multiple available expert models,
thereby reducing the need to fine-tune a pre-trained model for all the tasks
from scratch. Existing data-independent methods struggle with performance
limitations due to the lack of data-driven guidance. Data-driven approaches
also face key challenges: gradient-based methods are computationally expensive,
limiting their practicality for merging large expert models, whereas existing
gradient-free methods often fail to achieve satisfactory results within a
limited number of optimization steps. To address these limitations, this paper
introduces PSO-Merging, a novel data-driven merging method based on the
Particle Swarm Optimization (PSO). In this approach, we initialize the particle
swarm with a pre-trained model, expert models, and sparsified expert models. We
then perform multiple iterations, with the final global best particle serving
as the merged model. Experimental results on different language models show
that PSO-Merging generally outperforms baseline merging methods, offering a
more efficient and scalable solution for model merging.

</details>


### [314] [Symplectic convolutional neural networks](https://arxiv.org/abs/2508.19842)
*Süleyman Yıldız,Konrad Janik,Peter Benner*

Main category: cs.LG

TL;DR: 我们提出了一种新的辛卷积神经网络（CNN）架构，该架构利用了辛神经网络、适当的辛分解和张量技术。


<details>
  <summary>Details</summary>
Motivation: 本研究的动机是开发一种新的CNN架构，通过利用辛神经网络、适当的辛分解和张量技术，确保卷积层保持辛性。

Method: 首先，我们引入了卷积层的数学等价形式，然后利用辛神经网络，我们展示了一种参数化CNN层的方法，以确保卷积层保持辛性。为了构建一个完整的自编码器，我们引入了一个辛池化层。

Result: 所提出的神经网络在三个示例上进行了性能演示：波动方程、非线性薛定谔（NLS）方程和正弦-戈登方程。数值结果表明，辛CNN的性能优于通过适当的辛分解获得的线性辛自编码器。

Conclusion: 数值结果表明，辛CNN的性能优于通过适当的辛分解获得的线性辛自编码器。

Abstract: We propose a new symplectic convolutional neural network (CNN) architecture
by leveraging symplectic neural networks, proper symplectic decomposition, and
tensor techniques. Specifically, we first introduce a mathematically equivalent
form of the convolution layer and then, using symplectic neural networks, we
demonstrate a way to parameterize the layers of the CNN to ensure that the
convolution layer remains symplectic. To construct a complete autoencoder, we
introduce a symplectic pooling layer. We demonstrate the performance of the
proposed neural network on three examples: the wave equation, the nonlinear
Schr\"odinger (NLS) equation, and the sine-Gordon equation. The numerical
results indicate that the symplectic CNN outperforms the linear symplectic
autoencoder obtained via proper symplectic decomposition.

</details>


### [315] [Physics-Informed DeepONet Coupled with FEM for Convective Transport in Porous Media with Sharp Gaussian Sources](https://arxiv.org/abs/2508.19847)
*Erdi Kara,Panos Stinis*

Main category: cs.LG

TL;DR: We developed a hybrid FEM-DeepONet framework to model fluid transport in porous media with localized sources. It achieves high accuracy and significant speedups compared to traditional methods.


<details>
  <summary>Details</summary>
Motivation: To efficiently model fluid transport in porous media from sharp, localized Gaussian sources, addressing the need for speed and accuracy.

Method: A hybrid framework coupling FEM for Darcy flow and a physics-informed DeepONet for convection-diffusion. FEM provides the velocity field, which is fed into DeepONet that learns the mapping from source functions to concentration profiles. An adaptive sampling strategy is used for trunk collocation points to handle steep gradients.

Result: The method shows good agreement with reference solutions and offers orders of magnitude speedups, making it suitable for practical applications.

Conclusion: The proposed hybrid FEM-DeepONet framework provides an accurate and efficient approach for modeling fluid transport in porous media with localized sources, outperforming traditional solvers in terms of speed.

Abstract: We present a hybrid framework that couples finite element methods (FEM) with
physics-informed DeepONet to model fluid transport in porous media from sharp,
localized Gaussian sources. The governing system consists of a steady-state
Darcy flow equation and a time-dependent convection-diffusion equation. Our
approach solves the Darcy system using FEM and transfers the resulting velocity
field to a physics-informed DeepONet, which learns the mapping from source
functions to solute concentration profiles. This modular strategy preserves
FEM-level accuracy in the flow field while enabling fast inference for
transport dynamics. To handle steep gradients induced by sharp sources, we
introduce an adaptive sampling strategy for trunk collocation points. Numerical
experiments demonstrate that our method is in good agreement with the reference
solutions while offering orders of magnitude speedups over traditional solvers,
making it suitable for practical applications in relevant scenarios.
Implementation of our proposed method is available at
https://github.com/erkara/fem-pi-deeponet.

</details>


### [316] [Parameter-Free Structural-Diversity Message Passing for Graph Neural Networks](https://arxiv.org/abs/2508.19884)
*Mingyue Kong,Yinglong Zhang,Chengda Xu,Xuewen Xia,Xing Xu*

Main category: cs.LG

TL;DR: SDGNN是一种基于结构多样性的无参数图神经网络框架，通过统一的结构多样性消息传递机制，同时捕捉邻域结构异质性和特征语义稳定性，解决了传统GNNs参数量大、泛化能力差的问题，并在多个基准数据集上取得了优于主流GNNs的性能。


<details>
  <summary>Details</summary>
Motivation: 主流的图神经网络（GNNs）在结构化数据建模任务中表现出色，但在处理具有强结构异质性和复杂特征分布的图数据时，面临参数量大、聚合规则固定导致的过平滑和语义退化问题。

Method: 提出了一种名为SDGNN（Structural-Diversity Graph Neural Network）的无参数图神经网络框架。该框架基于结构多样性理论，设计了一个统一的消息传递机制，能够同时捕捉邻域结构的异质性和特征语义的稳定性，且无需引入额外的可训练参数。SDGNN不依赖复杂的模型训练，而是结合了结构驱动和特征驱动的互补建模方法。

Result: 在八个公开基准数据集和PubMed引用网络上，SDGNN在低监督、类别不平衡和跨域迁移等挑战性条件下，始终优于主流GNNs。

Conclusion: SDGNN为设计无参数图神经网络提供了一种新的理论视角和通用方法，并验证了结构多样性作为图表示学习核心信号的重要性。

Abstract: Graph Neural Networks (GNNs) have shown remarkable performance in structured
data modeling tasks such as node classification. However, mainstream approaches
generally rely on a large number of trainable parameters and fixed aggregation
rules, making it difficult to adapt to graph data with strong structural
heterogeneity and complex feature distributions. This often leads to
over-smoothing of node representations and semantic degradation. To address
these issues, this paper proposes a parameter-free graph neural network
framework based on structural diversity, namely SDGNN (Structural-Diversity
Graph Neural Network). The framework is inspired by structural diversity theory
and designs a unified structural-diversity message passing mechanism that
simultaneously captures the heterogeneity of neighborhood structures and the
stability of feature semantics, without introducing additional trainable
parameters. Unlike traditional parameterized methods, SDGNN does not rely on
complex model training, but instead leverages complementary modeling from both
structure-driven and feature-driven perspectives, thereby effectively improving
adaptability across datasets and scenarios. Experimental results show that on
eight public benchmark datasets and an interdisciplinary PubMed citation
network, SDGNN consistently outperforms mainstream GNNs under challenging
conditions such as low supervision, class imbalance, and cross-domain transfer.
This work provides a new theoretical perspective and general approach for the
design of parameter-free graph neural networks, and further validates the
importance of structural diversity as a core signal in graph representation
learning. To facilitate reproducibility and further research, the full
implementation of SDGNN has been released at:
https://github.com/mingyue15694/SGDNN/tree/main

</details>


### [317] [NM-Hebb: Coupling Local Hebbian Plasticity with Metric Learning for More Accurate and Interpretable CNNs](https://arxiv.org/abs/2508.19896)
*Davorin Miličević,Ratko Grbić*

Main category: cs.LG

TL;DR: NM-Hebb是一个两阶段训练框架，结合了受神经启发的局部可塑性和感知监督，以提高CNN的准确性和可解释性，实现了显著的性能提升。


<details>
  <summary>Details</summary>
Motivation: 标准的CNN优化方法（如全局、基于梯度的优化）容易导致过拟合、冗余滤波器和可解释性差。NM-Hebb旨在通过引入局部可塑性和距离感知监督来解决这些问题。

Method: NM-Hebb框架分两个阶段进行训练：阶段1通过结合交叉熵目标、Hebbian正则化器和可学习的神经调质剂来优化网络；阶段2使用成对度量学习损失对骨干网络进行微调，以压缩类内距离并扩大类间裕度。

Result: 在CIFAR-10、CIFAR-100和TinyImageNet数据集上，NM-Hebb在多个骨干网络上均实现了比基线方法更高的Top-1准确率（CIFAR-10提高+2.0-10.0百分点，CIFAR-100提高+2.0-9.0百分点，TinyImageNet提高+4.3-8.9百分点），并且归一化互信息（NMI）提高了+0.15。定性可视化和滤波器级分析表明，NM-Hebb生成了更结构化、更具选择性的特征，产生了更紧密、更可解释的类簇。

Conclusion: 将局部Hebbian可塑性与基于度量的微调相结合，可以实现更准确、更具可解释性的CNN，为资源受限和安全关键型AI应用带来了实际效益。

Abstract: Deep Convolutional Neural Networks (CNNs) achieve high accuracy but often
rely on purely global, gradient-based optimisation, which can lead to
overfitting, redundant filters, and reduced interpretability. To address these
limitations, we propose NM-Hebb, a two-phase training framework that integrates
neuro-inspired local plasticity with distance-aware supervision. Phase 1
extends standard supervised training by jointly optimising a cross-entropy
objective with two biologically inspired mechanisms: (i) a Hebbian regulariser
that aligns the spatial mean of activations with the mean of the corresponding
convolutional filter weights, encouraging structured, reusable primitives; and
(ii) a learnable neuromodulator that gates an elastic-weight-style
consolidation loss, preserving beneficial parameters without freezing the
network. Phase 2 fine-tunes the backbone with a pairwise metric-learning loss,
explicitly compressing intra-class distances and enlarging inter-class margins
in the embedding space. Evaluated on CIFAR-10, CIFAR-100, and TinyImageNet
across five backbones (ResNet-18, VGG-11, MobileNet-v2, EfficientNet-V2,
DenseNet-121), NM-Hebb achieves consistent gains over baseline and other
methods: Top-1 accuracy improves by +2.0-10.0 pp (CIFAR-10), +2.0-9.0 pp
(CIFAR-100), and up to +4.3-8.9 pp (TinyImageNet), with Normalised Mutual
Information (NMI) increased by up to +0.15. Qualitative visualisations and
filter-level analyses further confirm that NM-Hebb produces more structured and
selective features, yielding tighter and more interpretable class clusters.
Overall, coupling local Hebbian plasticity with metric-based fine-tuning yields
CNNs that are not only more accurate but also more interpretable, offering
practical benefits for resource-constrained and safety-critical AI deployments.

</details>


### [318] [Adaptive Scaling of Policy Constraints for Offline Reinforcement Learning](https://arxiv.org/abs/2508.19900)
*Tan Jing,Xiaorui Li,Chao Yao,Xiaojuan Ban,Yuetong Fang,Renjing Xu,Zhaolin Yuan*

Main category: cs.LG

TL;DR: ASPC是一种自适应策略约束框架，通过动态平衡RL和BC来解决离线RL中的分布偏移问题，仅需一个超参数即可在多个数据集上实现优于现有方法的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的离线RL方法依赖于策略约束来处理分布偏移，但这些约束的规模因任务和数据集质量而异，需要耗时且不切实际的超参数调整。

Method: 提出了一种名为ASPC的二阶可微框架，能够在训练过程中动态地平衡强化学习（RL）和行为克隆（BC）。

Result: 在39个D4RL数据集上的实验表明，ASPC仅使用单一超参数配置，其性能优于需要逐数据集调整的自适应约束方法和最先进的离线RL算法，并且计算开销极小。

Conclusion: ASPC框架能够有效地解决离线RL中的分布偏移问题，通过自适应调整策略约束，无需复杂的超参数调优，即可在不同数据集上取得优越性能。

Abstract: Offline reinforcement learning (RL) enables learning effective policies from
fixed datasets without any environment interaction. Existing methods typically
employ policy constraints to mitigate the distribution shift encountered during
offline RL training. However, because the scale of the constraints varies
across tasks and datasets of differing quality, existing methods must
meticulously tune hyperparameters to match each dataset, which is
time-consuming and often impractical. We propose Adaptive Scaling of Policy
Constraints (ASPC), a second-order differentiable framework that dynamically
balances RL and behavior cloning (BC) during training. We theoretically analyze
its performance improvement guarantee. In experiments on 39 datasets across
four D4RL domains, ASPC using a single hyperparameter configuration outperforms
other adaptive constraint methods and state-of-the-art offline RL algorithms
that require per-dataset tuning while incurring only minimal computational
overhead. The code will be released at https://github.com/Colin-Jing/ASPC.

</details>


### [319] [Ontology-Based Concept Distillation for Radiology Report Retrieval and Labeling](https://arxiv.org/abs/2508.19915)
*Felix Nützel,Mischa Dombrowski,Bernhard Kainz*

Main category: cs.LG

TL;DR: 提出一种基于本体的、可解释的、基于UMLS概念的检索方法，用于医学影像任务，优于基于CLIP或CXR-BERT的嵌入方法。


<details>
  <summary>Details</summary>
Motivation: 现有的基于文本嵌入的检索方法在医学影像任务中存在可解释性差、计算成本高、与医学知识结构不匹配等问题，尤其是在处理长尾分布的罕见病检测时。

Method: 1. 使用RadGraph-XL和SapBERT提取标准化医学实体。
2. 将提取的实体链接到UMLS概念（CUIs）。
3. 构建基于集合的文本表示。
4. 定义基于Tversky指数的改进和加权相似度量，考虑同义词、否定和层级关系。
5. 在MIMIC-CXR数据集上进行X光片分类任务的评估。

Result: 所提出的方法在MIMIC-CXR数据集的X光片分类任务上，尤其是在长尾场景下，优于最先进的基于嵌入的检索方法。

Conclusion: 该方法提供了一种更具可解释性、可靠性和任务特异性的检索策略，特别是在需要可解释性和整合领域知识的临床AI系统中。

Abstract: Retrieval-augmented learning based on radiology reports has emerged as a
promising direction to improve performance on long-tail medical imaging tasks,
such as rare disease detection in chest X-rays. Most existing methods rely on
comparing high-dimensional text embeddings from models like CLIP or CXR-BERT,
which are often difficult to interpret, computationally expensive, and not
well-aligned with the structured nature of medical knowledge. We propose a
novel, ontology-driven alternative for comparing radiology report texts based
on clinically grounded concepts from the Unified Medical Language System
(UMLS). Our method extracts standardised medical entities from free-text
reports using an enhanced pipeline built on RadGraph-XL and SapBERT. These
entities are linked to UMLS concepts (CUIs), enabling a transparent,
interpretable set-based representation of each report. We then define a
task-adaptive similarity measure based on a modified and weighted version of
the Tversky Index that accounts for synonymy, negation, and hierarchical
relationships between medical entities. This allows efficient and semantically
meaningful similarity comparisons between reports. We demonstrate that our
approach outperforms state-of-the-art embedding-based retrieval methods in a
radiograph classification task on MIMIC-CXR, particularly in long-tail
settings. Additionally, we use our pipeline to generate ontology-backed disease
labels for MIMIC-CXR, offering a valuable new resource for downstream learning
tasks. Our work provides more explainable, reliable, and task-specific
retrieval strategies in clinical AI systems, especially when interpretability
and domain knowledge integration are essential. Our code is available at
https://github.com/Felix-012/ontology-concept-distillation

</details>


### [320] [FlowletFormer: Network Behavioral Semantic Aware Pre-training Model for Traffic Classification](https://arxiv.org/abs/2508.19924)
*Liming Liu,Ruoyu Li,Qing Li,Meijia Hou,Yong Jiang,Mingwei Xu*

Main category: cs.LG

TL;DR: FlowletFormer是一种基于BERT的网络流量分析预训练模型，通过引入相干行为感知流量表示模型、基于协议栈对齐的嵌入层以及特定字段和上下文感知预训练任务，有效解决了现有方法在捕获数据包结构、流行为、协议语义和上下文关系方面的不足，显著提高了流量表示、分类准确性和少样本学习能力，并更好地理解网络传输原理。


<details>
  <summary>Details</summary>
Motivation: 现有网络流量分类的预训练模型在捕获数据包结构特征、流级别行为、分层协议语义以及数据包间上下文关系方面存在不足。

Method: 提出了一种名为FlowletFormer的BERT基础预训练模型，该模型包含：1. 相干行为感知流量表示模型（Coherent Behavior-Aware Traffic Representation Model），用于将流量分割成有意义的单元。2. 基于协议栈对齐的嵌入层（Protocol Stack Alignment-Based Embedding Layer），用于捕获多层协议语义。3. 特定字段和上下文感知预训练任务（Field-Specific and Context-Aware Pretraining Tasks），用于增强数据包间和流间学习。

Result: FlowletFormer在流量表示有效性、分类准确性和少样本学习能力方面显著优于现有方法。该模型还能更好地理解网络传输原理（如TCP的状态连接），提供更可靠、可信的流量分析框架。

Conclusion: FlowletFormer通过整合领域知识，有效提升了网络流量分析的性能和对网络传输原理的理解，为流量分析提供了更鲁棒的框架。

Abstract: Network traffic classification using pre-training models has shown promising
results, but existing methods struggle to capture packet structural
characteristics, flow-level behaviors, hierarchical protocol semantics, and
inter-packet contextual relationships. To address these challenges, we propose
FlowletFormer, a BERT-based pre-training model specifically designed for
network traffic analysis. FlowletFormer introduces a Coherent Behavior-Aware
Traffic Representation Model for segmenting traffic into semantically
meaningful units, a Protocol Stack Alignment-Based Embedding Layer to capture
multilayer protocol semantics, and Field-Specific and Context-Aware Pretraining
Tasks to enhance both inter-packet and inter-flow learning. Experimental
results demonstrate that FlowletFormer significantly outperforms existing
methods in the effectiveness of traffic representation, classification
accuracy, and few-shot learning capability. Moreover, by effectively
integrating domain-specific network knowledge, FlowletFormer shows better
comprehension of the principles of network transmission (e.g., stateful
connections of TCP), providing a more robust and trustworthy framework for
traffic analysis.

</details>


### [321] [Global Permutation Entropy](https://arxiv.org/abs/2508.19955)
*Abhijeet Avhale,Joscha Diehl,Niraj Velankar,Emanuele Verri*

Main category: cs.LG

TL;DR: 全局排列熵（GPE）是一种新的时间序列复杂度度量，它考虑了所有可能的模式，包括非连续的模式，并显示出比标准排列熵更能揭示结构信息。


<details>
  <summary>Details</summary>
Motivation: 为了克服标准排列熵仅考虑连续段的局限性，提出了一种新的度量方法，该方法考虑了所有可能的模式，包括非连续的模式。

Method: 全局排列熵（GPE）的计算依赖于最近开发的能够有效提取完整排列配置文件的算法。GPE通过考虑所有可能的模式（包括非连续模式）来计算时间序列的复杂度。

Result: 实验表明，GPE能够揭示标准排列熵无法获取的结构信息，并且在合成数据集上表现出有效性。

Conclusion: GPE是一种比标准排列熵更有信息量的时间序列复杂度度量，可以作为一种有用的分析工具。

Abstract: Permutation Entropy, introduced by Bandt and Pompe, is a widely used
complexity measure for real-valued time series that is based on the relative
order of values within consecutive segments of fixed length. After
standardizing each segment to a permutation and computing the frequency
distribution of these permutations, Shannon Entropy is then applied to quantify
the series' complexity. We introduce Global Permutation Entropy (GPE), a novel
index that considers all possible patterns of a given length, including
non-consecutive ones. Its computation relies on recently developed algorithms
that enable the efficient extraction of full permutation profiles. We
illustrate some properties of GPE and demonstrate its effectiveness through
experiments on synthetic datasets, showing that it reveals structural
information not accessible through standard permutation entropy. We provide a
Julia package for the calculation of GPE at
`https://github.com/AThreeH1/Global-Permutation-Entropy'.

</details>


### [322] [Short-Horizon Predictive Maintenance of Industrial Pumps Using Time-Series Features and Machine Learning](https://arxiv.org/abs/2508.19974)
*Khaled M. A. Alghtus,Aiyad Gannan,Khalid M. Alhajri,Ali L. A. Al Jubouri,Hassan A. I. Al-Janahi*

Main category: cs.LG

TL;DR: 本研究提出了一种利用实时传感器数据预测工业离心泵短期故障的机器学习框架。该框架通过提取历史操作模式，预测提前5、15和30分钟的{EarlyWarning}状况。研究评估了60分钟和120分钟的两种回溯期，并采用了滑动窗口方法。每个窗口提取了包括均值、标准差、最小值、最大值和线性趋势在内的统计特征，并使用SMOTE算法处理了类别不平衡问题。最后，训练和测试了随机森林和XGBoost分类器。


<details>
  <summary>Details</summary>
Motivation: 工业离心泵的短期故障预测和早期预警。

Method: 1. 建立机器学习框架，利用实时传感器数据预测短期故障。
2. 评估60分钟和120分钟两种回溯期，采用滑动窗口方法。
3. 提取每个窗口的统计特征（均值、标准差、最小值、最大值、线性趋势）。
4. 使用SMOTE算法处理类别不平衡问题。
5. 训练和测试随机森林和XGBoost分类器。

Result: 随机森林模型在使用60分钟窗口时表现最佳，在提前5分钟、15分钟和30分钟的召回率分别为69.2%、64.9%和48.6%。在使用120分钟窗口时，随机森林模型在提前5分钟的召回率为57.6%，在提前15分钟和30分钟的预测准确率提高到65.6%。XGBoost模型的性能与随机森林类似，但略有下降。

Conclusion: 预测精度与所选的历史数据长度相关，不同的故障模式可能在不同的时间尺度上发展。该框架为将预测性维护集成到实时工业监控系统提供了一个可解释且可扩展的解决方案。

Abstract: This study presents a machine learning framework for forecasting short-term
faults in industrial centrifugal pumps using real-time sensor data. The
approach aims to predict {EarlyWarning} conditions 5, 15, and 30 minutes in
advance based on patterns extracted from historical operation. Two lookback
periods, 60 minutes and 120 minutes, were evaluated using a sliding window
approach. For each window, statistical features including mean, standard
deviation, minimum, maximum, and linear trend were extracted, and class
imbalance was addressed using the SMOTE algorithm. Random Forest and XGBoost
classifiers were trained and tested on the labeled dataset. Results show that
the Random Forest model achieved the best short-term forecasting performance
with a 60-minute window, reaching recall scores of 69.2\% at 5 minutes, 64.9\%
at 15 minutes, and 48.6\% at 30 minutes. With a 120-minute window, the Random
Forest model achieved 57.6\% recall at 5 minutes, and improved predictive
accuracy of 65.6\% at both 15 and 30 minutes. XGBoost displayed similar but
slightly lower performance. These findings highlight that optimal history
length depends on the prediction horizon, and that different fault patterns may
evolve at different timescales. The proposed method offers an interpretable and
scalable solution for integrating predictive maintenance into real-time
industrial monitoring systems.

</details>


### [323] [Reducing Street Parking Search Time via Smart Assignment Strategies](https://arxiv.org/abs/2508.19979)
*Behafarid Hemmatpour,Javad Dogani,Nikolaos Laoutaris*

Main category: cs.LG

TL;DR: 本文通过模拟马德里停车生态系统，研究了手机APP在缓解城市停车拥堵方面的效果，并提出了一种名为Cord-Approx的协调停车策略，该策略通过概率估计非用户行为并优化车辆调度，显著减少了用户寻找停车位的时间。


<details>
  <summary>Details</summary>
Motivation: 停车难是城市交通拥堵的重要原因，手机APP被认为是解决该问题的潜在方案，但其效果仍需研究。

Method: 本文采用数据驱动的模拟方法，对马德里停车生态系统进行建模，并对比了四种不同的停车策略：无协调策略(Unc-Agn)、有协调但无非用户感知策略(Cord-Agn)、理想化的全知策略(Cord-Oracle)以及提出的Cord-Approx策略。Cord-Approx策略通过概率模型估计非用户行为，并利用匈牙利匹配算法进行车辆调度。

Result: 在模拟实验中，Cord-Approx策略的用户平均花费6.69分钟找到停车位，而非APP用户则需要19.98分钟。在马德里市中心区域，Cord-Approx策略将系统用户的寻找停车位时间减少了72%，在住宅区减少了73%。

Conclusion: 本文提出的Cord-Approx策略能够显著减少用户寻找停车位的时间，并缓解城市交通拥堵。该策略通过结合概率模型和优化算法，有效解决了现有策略的不足。

Abstract: In dense metropolitan areas, searching for street parking adds to traffic
congestion. Like many other problems, real-time assistants based on mobile
phones have been proposed, but their effectiveness is understudied. This work
quantifies how varying levels of user coordination and information availability
through such apps impact search time and the probability of finding street
parking. Through a data-driven simulation of Madrid's street parking ecosystem,
we analyze four distinct strategies: uncoordinated search (Unc-Agn),
coordinated parking without awareness of non-users (Cord-Agn), an idealized
oracle system that knows the positions of all non-users (Cord-Oracle), and our
novel/practical Cord-Approx strategy that estimates non-users' behavior
probabilistically. The Cord-Approx strategy, instead of requiring knowledge of
how close non-users are to a certain spot in order to decide whether to
navigate toward it, uses past occupancy distributions to elongate physical
distances between system users and alternative parking spots, and then solves a
Hungarian matching problem to dispatch accordingly. In high-fidelity
simulations of Madrid's parking network with real traffic data, users of
Cord-Approx averaged 6.69 minutes to find parking, compared to 19.98 minutes
for non-users without an app. A zone-level snapshot shows that Cord-Approx
reduces search time for system users by 72% (range = 67-76%) in central hubs,
and up to 73% in residential areas, relative to non-users.

</details>


### [324] [Evaluating Language Model Reasoning about Confidential Information](https://arxiv.org/abs/2508.19980)
*Dylan Sam,Alexander Robey,Andy Zou,Matt Fredrikson,J. Zico Kolter*

Main category: cs.LG

TL;DR: 语言模型在涉及高风险的场景下作为自主代理的部署越来越普遍，确保它们能够可靠地遵循用户定义的规则已成为一项关键的安全问题。本研究旨在探讨语言模型是否表现出上下文鲁棒性，即遵循上下文相关的安全规范的能力。为此，我们开发了一个名为PasswordEval的基准测试，用于衡量语言模型在判断用户请求是否已授权（即具有正确密码）方面的能力。我们发现，当前开源和闭源模型在此看似简单的任务上都存在困难，而且，令人惊讶的是，推理能力通常并不能提高性能。事实上，我们发现推理过程常常会泄露机密信息，这使得在这些应用中是否应向用户公开推理过程值得怀疑。我们还通过以下方式增加了评估的难度：(i)通过各种越狱策略增加对抗性用户压力；(ii)通过更长的多轮对话，增加密码验证的难度。总的来说，我们的研究结果表明，当前的前沿模型并不适合处理机密信息，并且推理能力可能需要以不同的方式进行训练，才能使其在部署到高风险场景时更加安全。


<details>
  <summary>Details</summary>
Motivation: 确保语言模型在涉及高风险的场景下能够可靠地遵循用户定义的规则，这已成为一项关键的安全问题。本研究旨在探讨语言模型是否表现出上下文鲁棒性，即遵循上下文相关的安全规范的能力。

Method: 开发了一个名为PasswordEval的基准测试，用于衡量语言模型在判断用户请求是否已授权（即具有正确密码）方面的能力。通过增加对抗性用户压力（越狱策略）和更长的多轮对话来增加评估的难度。

Result: 当前开源和闭源模型在判断用户请求是否已授权方面存在困难；推理能力通常并不能提高性能，反而可能泄露机密信息；越狱策略和更长的多轮对话会增加密码验证的难度。

Conclusion: 当前的前沿模型并不适合处理机密信息，并且推理能力可能需要以不同的方式进行训练，才能使其在部署到高风险场景时更加安全。

Abstract: As language models are increasingly deployed as autonomous agents in
high-stakes settings, ensuring that they reliably follow user-defined rules has
become a critical safety concern. To this end, we study whether language models
exhibit contextual robustness, or the capability to adhere to context-dependent
safety specifications. For this analysis, we develop a benchmark (PasswordEval)
that measures whether language models can correctly determine when a user
request is authorized (i.e., with a correct password). We find that current
open- and closed-source models struggle with this seemingly simple task, and
that, perhaps surprisingly, reasoning capabilities do not generally improve
performance. In fact, we find that reasoning traces frequently leak
confidential information, which calls into question whether reasoning traces
should be exposed to users in such applications. We also scale the difficulty
of our evaluation along multiple axes: (i) by adding adversarial user pressure
through various jailbreaking strategies, and (ii) through longer multi-turn
conversations where password verification is more challenging. Overall, our
results suggest that current frontier models are not well-suited to handling
confidential information, and that reasoning capabilities may need to be
trained in a different manner to make them safer for release in high-stakes
settings.

</details>


### [325] [Self-Supervised Pre-Training with Equilibrium Constraints](https://arxiv.org/abs/2508.19990)
*Xiaodong Cui,A F M Saif,Brian Kingsbury,Tianyi Chen*

Main category: cs.LG

TL;DR: 提出一种新的自监督预训练方法，用于处理异构数据，通过引入平衡约束，将问题构建为双层优化问题，并使用一阶近似方法求解，在多领域和多语言数据集上进行了实验，表明该方法能显著提高预训练模型的适应性。


<details>
  <summary>Details</summary>
Motivation: 在机器学习中，使用无标签数据进行自监督预训练被广泛应用。然而，在处理异构数据时，传统的混合数据并最小化平均全局损失的方法存在不足。

Method: 提出一种新的自监督预训练方法，通过施加额外的平衡约束，确保模型在K步梯度下降后优化每个异构数据源到其局部最优。将此问题形式化为双层优化问题，并使用一阶近似方法求解，并探讨了其与模型无关的元学习（MAML）的联系。

Result: 实验结果表明，所提出的方法在多领域和多语言数据集上的自监督预训练表现优于传统方法，能够显著提高预训练模型在下游监督微调任务中的适应性。

Conclusion: 所提出的双层优化方法能够有效地处理异构数据，提高自监督预训练模型的性能和适应性。

Abstract: Self-supervised pre-training using unlabeled data is widely used in machine
learning. In this paper, we propose a new self-supervised pre-training approach
to dealing with heterogeneous data. Instead of mixing all the data and
minimizing the averaged global loss in the conventional way, we impose
additional equilibrium constraints to ensure that the models optimizes each
source of heterogeneous data to its local optima after $K$-step gradient
descent initialized from the model. We formulate this as a bilevel optimization
problem, and use the first-order approximation method to solve the problem. We
discuss its connection to model-agnostic meta learning (MAML). Experiments are
carried out on self-supervised pre-training using multi-domain and multilingual
datasets, demonstrating that the proposed approach can significantly improve
the adaptivity of the self-supervised pre-trained model for the downstream
supervised fine-tuning tasks.

</details>


### [326] [Linear-Time Demonstration Selection for In-Context Learning via Gradient Estimation](https://arxiv.org/abs/2508.19999)
*Ziniu Zhang,Zhenshuo Zhang,Dongyue Li,Lu Wang,Jennifer Dy,Hongyang R. Zhang*

Main category: cs.LG

TL;DR: 本文提出一种基于梯度的方法，从n个示例中选择k个用于in-context learning，以提高模型在下游任务中的表现。


<details>
  <summary>Details</summary>
Motivation: 在in-context learning中，如何从给定的n个示例中选择k个最佳示例作为下游推理的条件，这是一个具有广泛应用价值的问题，尤其是在prompt tuning和chain-of-thought reasoning领域。

Method: 本文提出了一种基于输出梯度在输入嵌入空间中的新方法。该方法通过一阶近似估计模型输出，然后将此估计应用于多个随机采样的子集。最后，通过聚合采样子集的输出来形成每个演示示例的影响得分，并选择k个最相关的示例。此过程仅需一次预计算模型输出和梯度，相对于模型和训练集大小具有线性时间复杂度。

Result: 实验结果表明，该梯度估计过程在六个不同数据集上实现了小于1%的误差，能够将子集选择的规模扩大高达37.7倍（在拥有340亿参数的模型上），并且平均性能优于基于输入嵌入的现有选择方法11%。

Conclusion: 本文提出的基于梯度的示例选择方法，在效率和性能上均优于现有方法，为in-context learning提供了有效的解决方案。

Abstract: This paper introduces an algorithm to select demonstration examples for
in-context learning of a query set. Given a set of $n$ examples, how can we
quickly select $k$ out of $n$ to best serve as the conditioning for downstream
inference? This problem has broad applications in prompt tuning and
chain-of-thought reasoning. Since model weights remain fixed during in-context
learning, previous work has sought to design methods based on the similarity of
token embeddings. This work proposes a new approach based on gradients of the
output taken in the input embedding space. Our approach estimates model outputs
through a first-order approximation using the gradients. Then, we apply this
estimation to multiple randomly sampled subsets. Finally, we aggregate the
sampled subset outcomes to form an influence score for each demonstration, and
select $k$ most relevant examples. This procedure only requires pre-computing
model outputs and gradients once, resulting in a linear-time algorithm relative
to model and training set sizes. Extensive experiments across various models
and datasets validate the efficiency of our approach. We show that the gradient
estimation procedure yields approximations of full inference with less than
$\mathbf{1}\%$ error across six datasets. This allows us to scale up subset
selection that would otherwise run full inference by up to
$\mathbf{37.7}\times$ on models with up to $34$ billion parameters, and
outperform existing selection methods based on input embeddings by
$\mathbf{11}\%$ on average.

</details>


### [327] [Cross-Platform E-Commerce Product Categorization and Recategorization: A Multimodal Hierarchical Classification Approach](https://arxiv.org/abs/2508.20013)
*Lotte Gross,Rebecca Walter,Nicole Zoppi,Adrien Justus,Alessandro Gambetti,Qiwei Han,Maximilian Kaiser*

Main category: cs.LG

TL;DR: 本研究提出了一种多模态分层分类框架，用于解决电子商务产品分类中的平台异构性和现有分类法的结构限制问题。该框架集成了文本（RoBERTa）、视觉（ViT）和联合视觉-语言（CLIP）特征，并采用动态掩蔽增强的分层架构。研究结果表明，通过MLP进行晚期融合的CLIP嵌入在分层F1得分上达到了98.59%，优于单一模态基线。此外，研究还引入了一个自监督的“产品重分类”流程，利用SimCLR、UMAP和级联聚类发现了新的细粒度类别，聚类纯度高于86%。跨平台实验表明，复杂的晚期融合方法在多样化训练数据上能最大化准确性，而简单的早期融合方法对未见过的平台泛化能力更强。最终，该框架通过两阶段推理流程（轻量级RoBERTa和GPU加速的多模态阶段）在EURWEB商业交易智能平台成功部署，实现了成本和准确性的平衡。


<details>
  <summary>Details</summary>
Motivation: 本研究旨在解决电子商务产品分类中存在的平台异构性和现有分类法结构限制两大关键工业挑战。

Method: 研究人员开发并部署了一个多模态分层分类框架，该框架整合了来自40个国际时尚电子商务平台的271,700个产品的文本特征（RoBERTa）、视觉特征（ViT）以及联合视觉-语言表示（CLIP）。他们研究了包括早期融合、晚期融合和基于注意力融合在内的融合策略，并在分层架构中引入了动态掩蔽以确保分类法的一致性。此外，还引入了一个自监督的“产品重分类”流程（使用SimCLR、UMAP和级联聚类）来解决分类浅层或不一致的问题。

Result: 研究结果显示，通过MLP进行晚期融合的CLIP嵌入在分层F1得分上达到了98.59%，优于单一模态基线。自监督的“产品重分类”流程发现了新的细粒度类别（例如“鞋子”的子类型），其聚类纯度高于86%。跨平台实验表明，复杂的晚期融合方法在多样化训练数据上能最大化准确性，而简单的早期融合方法对未见过的平台泛化能力更强。最终，该框架通过一个结合轻量级RoBERTa阶段和GPU加速多模态阶段的两阶段推理流程，成功部署在EURWEB的商业交易智能平台，实现了成本和准确性的平衡。

Conclusion: 该研究成功开发并部署了一个多模态分层分类框架，有效解决了电子商务产品分类中的平台异构性和分类法限制问题。通过集成多种特征和创新的融合策略，该框架实现了高准确性和良好的泛化能力。此外，引入的自监督重分类流程能够发现新的细粒度类别。该框架在工业界的成功部署证明了其在平衡成本和准确性方面的实用性和可扩展性。

Abstract: This study addresses critical industrial challenges in e-commerce product
categorization, namely platform heterogeneity and the structural limitations of
existing taxonomies, by developing and deploying a multimodal hierarchical
classification framework. Using a dataset of 271,700 products from 40
international fashion e-commerce platforms, we integrate textual features
(RoBERTa), visual features (ViT), and joint vision--language representations
(CLIP). We investigate fusion strategies, including early, late, and
attention-based fusion within a hierarchical architecture enhanced by dynamic
masking to ensure taxonomic consistency. Results show that CLIP embeddings
combined via an MLP-based late-fusion strategy achieve the highest hierarchical
F1 (98.59\%), outperforming unimodal baselines. To address shallow or
inconsistent categories, we further introduce a self-supervised ``product
recategorization'' pipeline using SimCLR, UMAP, and cascade clustering, which
discovered new, fine-grained categories (e.g., subtypes of ``Shoes'') with
cluster purities above 86\%. Cross-platform experiments reveal a
deployment-relevant trade-off: complex late-fusion methods maximize accuracy
with diverse training data, while simpler early-fusion methods generalize more
effectively to unseen platforms. Finally, we demonstrate the framework's
industrial scalability through deployment in EURWEB's commercial transaction
intelligence platform via a two-stage inference pipeline, combining a
lightweight RoBERTa stage with a GPU--accelerated multimodal stage to balance
cost and accuracy.

</details>


### [328] [Decomposing Behavioral Phase Transitions in LLMs: Order Parameters for Emergent Misalignment](https://arxiv.org/abs/2508.20015)
*Julian Arnold,Niels Lörch*

Main category: cs.LG

TL;DR: 微调大型语言模型（LLM）在狭窄有害数据集上可能导致其行为与人类价值观广泛不符。本研究提出一个综合框架，通过分布变化检测方法和用自然语言表述并由LLM评估的序参数，来检测和描述微调过程中的快速转变。研究使用客观的统计不相似性度量，量化了微调过程中的“相变”对模型多个方面的影响，并分解了整体转变中各方面（如对齐、冗长）所占的比例。研究还发现，行为转变实际发生的时间晚于梯度范数峰值指示的时间。该框架能够自动化发现和量化基于语言的序参数，并已在知识问答、政治和伦理等示例中得到证明。


<details>
  <summary>Details</summary>
Motivation: 理解在微调大型语言模型（LLM）过程中，当模型在特定有害数据集上进行微调时，如何以及何时会发生与人类价值观不符的“涌现式失准”现象。

Method: 提出一个综合框架，结合分布变化检测方法和自然语言表述的序参数（由LLM评估），用于检测和描述微调过程中的快速转变。使用客观的统计不相似性度量来量化相变对模型输出多个方面（如对齐、冗长）的影响，并进行分解。

Result: 研究发现，行为转变实际发生的时间晚于梯度范数峰值指示的时间。该框架能够自动化发现和量化基于语言的序参数，并已在知识问答、政治和伦理等示例中得到证明。

Conclusion: 该研究提出的框架能够有效检测和量化LLM微调过程中的行为转变，有助于理解和缓解模型失准问题。该框架能够自动化发现和量化基于语言的序参数，并可在不同领域进行应用。

Abstract: Fine-tuning LLMs on narrowly harmful datasets can lead to behavior that is
broadly misaligned with respect to human values. To understand when and how
this emergent misalignment occurs, we develop a comprehensive framework for
detecting and characterizing rapid transitions during fine-tuning using both
distributional change detection methods as well as order parameters that are
formulated in plain English and evaluated by an LLM judge. Using an objective
statistical dissimilarity measure, we quantify how the phase transition that
occurs during fine-tuning affects multiple aspects of the model. In particular,
we assess what percentage of the total distributional change in model outputs
is captured by different aspects, such as alignment or verbosity, providing a
decomposition of the overall transition. We also find that the actual
behavioral transition occurs later in training than indicated by the peak in
the gradient norm alone. Our framework enables the automated discovery and
quantification of language-based order parameters, which we demonstrate on
examples ranging from knowledge questions to politics and ethics.

</details>


### [329] [FairLoop: Software Support for Human-Centric Fairness in Predictive Business Process Monitoring](https://arxiv.org/abs/2508.20021)
*Felix Möhrlein,Martin Käppel,Julian Neuberger,Sven Weinzierl,Lars Ackermann,Martin Matzner,Stefan Jablonski*

Main category: cs.LG

TL;DR: FairLoop是一款用于神经1网络预测模型的人工引导偏见缓解工具。它可以从神经网络中提取决策树，允许用户检查和修改不公平的决策逻辑，然后用于微调原始模型以实现更公平的预测。与其它公平性方法相比，FairLoop通过人为干预实现上下文感知的偏见去除，可以选择性地解决敏感属性的影响，而不是一概而论地排除它们。


<details>
  <summary>Details</summary>
Motivation: 在诸如预测性业务流程监控等机器学习任务中，像性别或年龄这样的敏感属性可能导致不公平的预测，特别是在未考虑上下文的情况下使用它们。

Method: FairLoop从神经网络中提取决策树，允许用户检查和修改不公平的决策逻辑，然后用其来微调原始模型以实现更公平的预测。

Result: FairLoop与其它公平性方法相比，通过人为干预实现上下文感知的偏见去除，可以选择性地解决敏感属性的影响，而不是一概而论地排除它们。

Conclusion: FairLoop通过让人类参与，实现了上下文感知的偏差去除，可以有选择地处理敏感属性的影响，而不是一概而论地排除它们。

Abstract: Sensitive attributes like gender or age can lead to unfair predictions in
machine learning tasks such as predictive business process monitoring,
particularly when used without considering context. We present FairLoop1, a
tool for human-guided bias mitigation in neural network-based prediction
models. FairLoop distills decision trees from neural networks, allowing users
to inspect and modify unfair decision logic, which is then used to fine-tune
the original model towards fairer predictions. Compared to other approaches to
fairness, FairLoop enables context-aware bias removal through human
involvement, addressing the influence of sensitive attributes selectively
rather than excluding them uniformly.

</details>


### [330] [Pruning Strategies for Backdoor Defense in LLMs](https://arxiv.org/abs/2508.20032)
*Santosh Chapagain,Shah Muhammad Hamdi,Soukaina Filali Boubrahimi*

Main category: cs.LG

TL;DR: 后门攻击对预训练语言模型构成威胁，即使在微调后仍然存在。本研究探索了注意力头剪枝作为一种无需了解攻击触发器或干净参考模型即可缓解这些威胁的方法。


<details>
  <summary>Details</summary>
Motivation: 后门攻击对预训练语言模型构成严重威胁，即使经过微调也难以防御，因为用户通常不知道攻击触发器。

Method: 提出并实现了六种基于剪枝的策略：(i) 基于梯度的剪枝，(ii) 层级方差剪枝，(iii) 基于梯度的剪枝与结构化L1/L2稀疏化，(iv) 随机集成剪枝，(v) 强化学习引导剪枝，(vi) 贝叶斯不确定性剪枝。这些方法在监控验证准确性的同时，迭代地移除信息量最少的头，以避免过度剪枝。

Result: 实验评估表明，基于梯度的剪枝在防御句法触发器方面表现最佳，而强化学习和贝叶斯剪枝在抵御风格攻击方面更有效。

Conclusion: 注意力头剪枝是一种有前景的后门攻击防御方法，不同的剪枝策略对不同类型的触发器（句法或风格）有不同的防御效果。

Abstract: Backdoor attacks are a significant threat to the performance and integrity of
pre-trained language models. Although such models are routinely fine-tuned for
downstream NLP tasks, recent work shows they remain vulnerable to backdoor
attacks that survive vanilla fine-tuning. These attacks are difficult to defend
because end users typically lack knowledge of the attack triggers. Such attacks
consist of stealthy malicious triggers introduced through subtle syntactic or
stylistic manipulations, which can bypass traditional detection and remain in
the model, making post-hoc purification essential. In this study, we explore
whether attention-head pruning can mitigate these threats without any knowledge
of the trigger or access to a clean reference model. To this end, we design and
implement six pruning-based strategies: (i) gradient-based pruning, (ii)
layer-wise variance pruning, (iii) gradient-based pruning with structured L1/L2
sparsification, (iv) randomized ensemble pruning, (v)
reinforcement-learning-guided pruning, and (vi) Bayesian uncertainty pruning.
Each method iteratively removes the least informative heads while monitoring
validation accuracy to avoid over-pruning. Experimental evaluation shows that
gradient-based pruning performs best while defending the syntactic triggers,
whereas reinforcement learning and Bayesian pruning better withstand stylistic
attacks.

</details>


### [331] [Using item recommendations and LLMs in marketing email titles](https://arxiv.org/abs/2508.20024)
*Deddy Jobson,Muktti Shukla,Phuong Dinh,Julio Christian Young,Nick Pitton,Nina Chen,Ryan Ginstrom*

Main category: cs.LG

TL;DR: LLM可用于生成个性化电子邮件的优化标题，以提高用户参与度。


<details>
  <summary>Details</summary>
Motivation: 电子邮件标题通常采用固定模板，未能充分激发用户兴趣，需要更具吸引力的标题。

Method: 利用LLM技术生成能够反映个性化邮件内容的 theadline，并通过线下模拟和线上实验进行验证。

Result: 研究表明，LLM生成的标题能有效提升用户与邮件的参与度，并已成功应用于大规模用户邮件标题的生成。

Conclusion: LLM在生成个性化电子邮件标题方面具有巨大潜力，能够有效提升用户参与度，并且可以安全地自动化应用于大规模生产环境。

Abstract: E-commerce marketplaces make use of a number of marketing channels like
emails, push notifications, etc. to reach their users and stimulate purchases.
Personalized emails especially are a popular touch point for marketers to
inform users of latest items in stock, especially for those who stopped
visiting the marketplace. Such emails contain personalized recommendations
tailored to each user's interests, enticing users to buy relevant items. A
common limitation of these emails is that the primary entry point, the title of
the email, tends to follow fixed templates, failing to inspire enough interest
in the contents. In this work, we explore the potential of large language
models (LLMs) for generating thematic titles that reflect the personalized
content of the emails. We perform offline simulations and conduct online
experiments on the order of millions of users, finding our techniques useful in
improving the engagement between customers and our emails. We highlight key
findings and learnings as we productionize the safe and automated generation of
email titles for millions of users.

</details>


### [332] [Reinforcement Learning for Search Tree Size Minimization in Constraint Programming: New Results on Scheduling Benchmarks](https://arxiv.org/abs/2508.20056)
*Vilém Heinz,Petr Vilím,Zdeněk Hanzálek*

Main category: cs.LG

TL;DR:  Failure-Directed Search (FDS) 是一种用于约束规划 (CP) 的搜索算法，通过与多臂老虎机 (MAB) 问题的关联，并应用 MAB 强化学习算法进行扩展和调优，在 Job Shop Scheduling Problem (JSSP) 和 Resource-Constrained Project Scheduling Problem (RCPSP) 上取得了显著的性能提升，比原始实现和现有最先进算法更快，并改进了许多基准实例的下界。


<details>
  <summary>Details</summary>
Motivation: 将多臂老虎机 (MAB) 强化学习算法应用于约束规划 (CP) 中的 Failure-Directed Search (FDS) 算法，以提高其在调度问题上的搜索效率。

Method: 将 FDS 与 MAB 问题关联，应用 MAB 强化学习算法，并结合问题特定的改进和参数调优，在 OptalCP 求解器中进行评估。

Result: 增强的 FDS 在 JSSP 上比原始实现快 1.7 倍，比 IBM CP Optimizer 快 3.5 倍；在 RCPSP 上比原始实现快 2.1 倍，比 IBM CP Optimizer 快 2.1 倍。在 900 秒的时间限制内，增强的 FDS 改进了 84 个 JSSP 实例中的 78 个和 393 个 RCPSP 实例中的 226 个的现有最先进下界。

Conclusion: 通过将 MAB 强化学习算法应用于 FDS 并进行相应的扩展和调优，可以显著提高 FDS 在 JSSP 和 RCPSP 问题上的性能，并改进现有最先进的下界。

Abstract: Failure-Directed Search (FDS) is a significant complete generic search
algorithm used in Constraint Programming (CP) to efficiently explore the search
space, proven particularly effective on scheduling problems. This paper
analyzes FDS's properties, showing that minimizing the size of its search tree
guided by ranked branching decisions is closely related to the Multi-armed
bandit (MAB) problem. Building on this insight, MAB reinforcement learning
algorithms are applied to FDS, extended with problem-specific refinements and
parameter tuning, and evaluated on the two most fundamental scheduling
problems, the Job Shop Scheduling Problem (JSSP) and Resource-Constrained
Project Scheduling Problem (RCPSP). The resulting enhanced FDS, using the best
extended MAB algorithm and configuration, performs 1.7 times faster on the JSSP
and 2.1 times faster on the RCPSP benchmarks compared to the original
implementation in a new solver called OptalCP, while also being 3.5 times
faster on the JSSP and 2.1 times faster on the RCPSP benchmarks than the
current state-of-the-art FDS algorithm in IBM CP Optimizer 22.1. Furthermore,
using only a 900-second time limit per instance, the enhanced FDS improved the
existing state-of-the-art lower bounds of 78 of 84 JSSP and 226 of 393 RCPSP
standard open benchmark instances while also completely closing a few of them.

</details>


<div id='cs.AR'></div>

# cs.AR [[Back]](#toc)

### [333] [OmniSim: Simulating Hardware with C Speed and RTL Accuracy for High-Level Synthesis Designs](https://arxiv.org/abs/2508.19299)
*Rishov Sarkar,Cong Hao*

Main category: cs.AR

TL;DR: OmniSim是一个框架，可以加速和精确地模拟C/C++ HLS设计，支持以前不支持的复杂数据流特性，并提供近乎C的速度和近乎RTL的准确性。


<details>
  <summary>Details</summary>
Motivation: 现有的HLS工具难以在C级别上高效准确地模拟并发硬件行为，特别是对于循环依赖和非阻塞FIFO访问等高级数据流特性，导致功能验证依赖于缓慢的RTL仿真，并且无法获得周期精确的性能指标。

Method: OmniSim通过软件多线程和FIFO表来实现对复杂数据流设计的快速准确模拟，这些表记录了每次FIFO访问的确切硬件时序。它还通过灵活耦合和重叠的功能与性能仿真，实现了接近C的仿真速度和接近RTL的准确性。

Result: OmniSim成功模拟了11个以前不受任何HLS工具支持的设计，与传统的C/RTL联合仿真相比，速度提高了35.9倍，与最先进但功能较少的模拟器LightningSim相比，速度提高了6.61倍。

Conclusion: OmniSim是一个有前景的框架，能够显著提高HLS设计的模拟效率和准确性，解决了现有工具的局限性，并为复杂数据流设计提供了支持。

Abstract: High-Level Synthesis (HLS) is increasingly popular for hardware design using
C/C++ instead of Register-Transfer Level (RTL). To express concurrent hardware
behavior in a sequential language like C/C++, HLS tools introduce constructs
such as infinite loops and dataflow modules connected by FIFOs. However,
efficiently and accurately simulating these constructs at C level remains
challenging. First, without hardware timing information, functional
verification typically requires slow RTL synthesis and simulation, as the
current approaches in commercial HLS tools. Second, cycle-accurate performance
metrics, such as end-to-end latency, also rely on RTL simulation. No existing
HLS tool fully overcomes the first limitation. For the second, prior work such
as LightningSim partially improves simulation speed but lacks support for
advanced dataflow features like cyclic dependencies and non-blocking FIFO
accesses.
  To overcome both limitations, we propose OmniSim, a framework that
significantly extends the simulation capabilities of both academic and
commercial HLS tools. First, OmniSim enables fast and accurate simulation of
complex dataflow designs, especially those explicitly declared unsupported by
commercial tools. It does so through sophisticated software multi-threading,
where threads are orchestrated by querying and updating a set of FIFO tables
that explicitly record exact hardware timing of each FIFO access. Second,
OmniSim achieves near-C simulation speed with near-RTL accuracy for both
functionality and performance, via flexibly coupled and overlapped
functionality and performance simulations.
  We demonstrate that OmniSim successfully simulates eleven designs previously
unsupported by any HLS tool, achieving up to 35.9x speedup over traditional
C/RTL co-simulation, and up to 6.61x speedup over the state-of-the-art yet less
capable simulator, LightningSim, on its own benchmark suite.

</details>


### [334] [GENIE-ASI: Generative Instruction and Executable Code for Analog Subcircuit Identification](https://arxiv.org/abs/2508.19393)
*Phuoc Pham,Arun Venkitaraman,Chia-Yu Hsieh,Andrea Bonetti,Stefan Uhlich,Markus Leibl,Simon Hofmann,Eisaku Ohbuchi,Lorenzo Servadei,Ulf Schlichtmann,Robert Wille*

Main category: cs.AR

TL;DR: GENIE-ASI是首个利用大语言模型（LLM）进行模拟子电路识别的免训练方法，通过自然语言指令和Python代码自动识别SPICE网表中的子电路，并在新的运算放大器基准测试中表现出潜力。


<details>
  <summary>Details</summary>
Motivation: 传统模拟子电路识别方法需要大量专业知识、规则编码或标注数据，旨在解决这些挑战。

Method: GENIE-ASI分两个阶段：1. 使用上下文学习从少量示例生成自然语言指令。2. 将指令转换为Python代码，用于识别新的SPICE网表中的子电路。

Result: 在新的运算放大器基准测试中，GENIE-ASI在简单结构上达到1.0的F1分数，在中等抽象结构上达到0.81，在复杂子电路上达到0.31，显示出其作为通用工具的潜力。

Conclusion: LLM可以作为模拟设计自动化中适应性强的通用工具，为基础模型在模拟设计自动化中的应用开辟了新的研究方向。

Abstract: Analog subcircuit identification is a core task in analog design, essential
for simulation, sizing, and layout. Traditional methods often require extensive
human expertise, rule-based encoding, or large labeled datasets. To address
these challenges, we propose GENIE-ASI, the first training-free, large language
model (LLM)-based methodology for analog subcircuit identification. GENIE-ASI
operates in two phases: it first uses in-context learning to derive natural
language instructions from a few demonstration examples, then translates these
into executable Python code to identify subcircuits in unseen SPICE netlists.
In addition, to evaluate LLM-based approaches systematically, we introduce a
new benchmark composed of operational amplifier netlists (op-amps) that cover a
wide range of subcircuit variants. Experimental results on the proposed
benchmark show that GENIE-ASI matches rule-based performance on simple
structures (F1-score = 1.0), remains competitive on moderate abstractions
(F1-score = 0.81), and shows potential even on complex subcircuits (F1-score =
0.31). These findings demonstrate that LLMs can serve as adaptable,
general-purpose tools in analog design automation, opening new research
directions for foundation model applications in analog design automation.

</details>


### [335] [RARO: Reliability-aware Conversion with Enhanced Read Performance for QLC SSDs](https://arxiv.org/abs/2508.19530)
*Yanyun Wang,Dingcui Yu,Yina Lv,Yunpeng Song,Yumiao Zhao,Liang Shi*

Main category: cs.AR

TL;DR: QLC闪存虽然成本和容量有优势，但可靠性较低，需要频繁重读，严重影响读取性能。现有混合存储方案主要关注写入性能，仅基于数据温度进行迁移，导致过度模式切换和容量损失。本文提出的RARO（Reliability-Aware Read performance Optimization）是一种混合闪存管理方案，通过优化读取性能并最小化容量成本，解决此问题。RARO的关键在于，QLC闪存的读取减速主要是由重读引起的。RARO仅在QLC块中热数据出现大量重读时触发数据迁移，从而显著减少不必要的转换和容量损失。此外，RARO支持细粒度的多模式转换（SLC-TLC-QLC），以进一步最小化容量开销。通过利用实时重读统计数据和闪存特性，RARO减轻了过度转换，并优化了I/O性能。在FEMU平台上的实验表明，RARO在各种工作负载下显著提高了读取性能，同时对可用容量的影响可忽略不计。


<details>
  <summary>Details</summary>
Motivation: QLC闪存虽然成本和容量有优势，但可靠性较低，需要频繁重读，严重影响读取性能。现有混合存储方案主要关注写入性能，仅基于数据温度进行迁移，导致过度模式切换和容量损失。

Method: RARO（Reliability-Aware Read performance Optimization）是一种混合闪存管理方案，通过优化读取性能并最小化容量成本，解决此问题。RARO的关键在于，QLC闪存的读取减速主要是由重读引起的。RARO仅在QLC块中热数据出现大量重读时触发数据迁移，从而显著减少不必要的转换和容量损失。此外，RARO支持细粒度的多模式转换（SLC-TLC-QLC），以进一步最小化容量开销。通过利用实时重读统计数据和闪存特性，RARO减轻了过度转换，并优化了I/O性能。

Result: 在FEMU平台上的实验表明，RARO在各种工作负载下显著提高了读取性能，同时对可用容量的影响可忽略不计。

Conclusion: RARO通过关注读取重试次数和数据热度，有效地提高了QLC闪存的读取性能，并最小化了容量开销。

Abstract: Quad-level cell (QLC) flash offers significant benefits in cost and capacity,
but its limited reliability leads to frequent read retries, which severely
degrade read performance. A common strategy in high-density flash storage is to
program selected blocks in a low-density mode (SLC), sacrificing some capacity
to achieve higher I/O performance. This hybrid storage architecture has been
widely adopted in consumer-grade storage systems. However, existing hybrid
storage schemes typically focus on write performance and rely solely on data
temperature for migration decisions. This often results in excessive mode
switching, causing substantial capacity overhead.
  In this paper, we present RARO (Reliability-Aware Read performance
Optimization), a hybrid flash management scheme designed to improve read
performance with minimal capacity cost. The key insight behind RARO is that
much of the read slowdown in QLC flash is caused by read retries. RARO triggers
data migration only when hot data resides in QLC blocks experiencing a high
number of read retries, significantly reducing unnecessary conversions and
capacity loss. Moreover, RARO supports fine-grained multi-mode conversions
(SLC-TLC-QLC) to further minimize capacity overhead. By leveraging real-time
read retry statistics and flash characteristics, RARO mitigates over-conversion
and optimizes I/O performance. Experiments on the FEMU platform demonstrate
that RARO significantly improves read performance across diverse workloads,
with negligible impact on usable capacity.

</details>


### [336] [Support Vector Machines Classification on Bendable RISC-V](https://arxiv.org/abs/2508.19656)
*Polykarpos Vergos,Theofanis Vergos,Florentia Afentaki,Konstantinos Balaskas,Georgios Zervakis*

Main category: cs.AR

TL;DR: Flexible electronics (FE) coupled with machine learning (ML) faces challenges due to device size and power consumption. This paper presents an open-source framework for ML co-processors for the Bendable RISC-V core and a custom ML accelerator for SVM (OvO and OvR) with precision scalability (4, 8, 16-bit weights). Experiments show a 21x average improvement in inference time and energy efficiency, enabling low-power, flexible edge intelligence.


<details>
  <summary>Details</summary>
Motivation: To address the challenges of large feature sizes and high power consumption in flexible ML applications, which hinder the realization of intelligent devices with smart sensing capabilities.

Method: Proposed an open-source framework for developing ML co-processors for the Bendable RISC-V core. Presented a custom ML accelerator architecture for Support Vector Machine (SVM), supporting both one-vs-one (OvO) and one-vs-rest (OvR) algorithms, with a generic, precision-scalable design supporting 4-, 8-, and 16-bit weight representations.

Result: Experimental results demonstrated an average of 21x improvement in both inference execution time and energy efficiency.

Conclusion: The proposed ML accelerator architecture shows significant potential for low-power, flexible intelligence on the edge, overcoming the limitations of current flexible ML applications.

Abstract: Flexible Electronics (FE) technology offers uniquecharacteristics in
electronic manufacturing, providing ultra-low-cost, lightweight, and
environmentally-friendly alternatives totraditional rigid electronics. These
characteristics enable a rangeof applications that were previously constrained
by the costand rigidity of conventional silicon technology. Machine learning
(ML) is essential for enabling autonomous, real-time intelligenceon devices
with smart sensing capabilities in everyday objects. However, the large feature
sizes and high power consumption ofthe devices oppose a challenge in the
realization of flexible ML applications. To address the above, we propose an
open-source framework for developing ML co-processors for the Bendable RISC-V
core. In addition, we present a custom ML accelerator architecture for Support
Vector Machine (SVM), supporting both one-vs-one (OvO) and one-vs-rest (OvR)
algorithms. Our ML accelerator adopts a generic, precision-scalable design,
supporting 4-, 8-, and 16-bit weight representations. Experimental results
demonstrate a 21x improvement in both inference execution time and energy
efficiency, on average, highlighting its potential for low-power, flexible
intelligence on the edge.

</details>


### [337] [New Tools, Programming Models, and System Support for Processing-in-Memory Architectures](https://arxiv.org/abs/2508.19868)
*Geraldo F. Oliveira*

Main category: cs.AR

TL;DR: 本论文提出了一系列用于内存处理（PIM）架构的工具、编程模型和系统支持，特别是基于DRAM的解决方案，旨在简化PIM在当前和未来系统中的应用。


<details>
  <summary>Details</summary>
Motivation: 为了简化PIM在当前和未来系统中的应用，本论文旨在提供相关的工具、编程模型和系统支持。

Method: 本论文提出了DAMOV（一种内存数据移动瓶颈的表征方法和基准套件）、MIMDRAM（一种改进的PUD硬件/软件协同设计，提高了可编程性和灵活性）、Proteus（一种用于PUD的、数据感知的运行时引擎，通过并发执行、动态降低比特精度和选择合适的数据表示来减少执行延迟）以及DaPPA（一种数据并行PIM编程框架，简化了通用PIM架构的可编程性）。

Result: DAMOV是第一个严格的方法学，用于表征内存数据移动瓶颈，并提供了第一个数据移动基准套件。MIMDRAM解决了PUD架构在可编程性和灵活性方面的限制。Proteus通过并发执行、动态降低比特精度和选择合适的数据表示，显著降低了PUD操作的执行延迟。DaPPA简化了通用PIM架构的可编程性。

Conclusion: 本论文通过DAMOV、MIMDRAM、Proteus和DaPPA的贡献，为PIM架构（特别是DRAM）的发展提供了重要的工具、编程模型和系统支持，旨在降低PIM的应用门槛。

Abstract: Our goal in this dissertation is to provide tools, programming models, and
system support for PIM architectures (with a focus on DRAM-based solutions), to
ease the adoption of PIM in current and future systems. To this end, we make at
least four new major contributions.
  First, we introduce DAMOV, the first rigorous methodology to characterize
memory-related data movement bottlenecks in modern workloads, and the first
data movement benchmark suite. Second, we introduce MIMDRAM, a new
hardware/software co-designed substrate that addresses the major current
programmability and flexibility limitations of the bulk bitwise execution model
of processing-using-DRAM (PUD) architectures. MIMDRAM enables the allocation
and control of only the needed computing resources inside DRAM for PUD
computing. Third, we introduce Proteus, the first hardware framework that
addresses the high execution latency of bulk bitwise PUD operations in
state-of-the-art PUD architectures by implementing a data-aware runtime engine
for PUD. Proteus reduces the latency of PUD operations in three different ways:
(i) Proteus concurrently executes independent in-DRAM primitives belong to a
single PUD operation across DRAM arrays. (ii) Proteus dynamically reduces the
bit-precision (and consequentially the latency and energy consumption) of PUD
operations by exploiting narrow values (i.e., values with many leading zeros or
ones). (iii) Proteus chooses and uses the most appropriate data representation
and arithmetic algorithm implementation for a given PUD instruction
transparently to the programmer. Fourth, we introduce DaPPA (data-parallel
processing-in-memory architecture), a new programming framework that eases
programmability for general-purpose PNM architectures by allowing the
programmer to write efficient PIM-friendly code without the need to manage
hardware resources explicitly.

</details>


<div id='eess.SP'></div>

# eess.SP [[Back]](#toc)

### [338] [MC for Gastroretentive Drug Delivery](https://arxiv.org/abs/2508.19739)
*Sebastian Lotter,Marco Seiter,Maryam Pirmoradi,Lukas Brand,Dagmar Fischer,Robert Schober*

Main category: eess.SP

TL;DR: 该研究提出了一种用于细菌纳米纤维素（BNC）药物递送系统的物理模型，该模型考虑了聚合物涂层的扩散阻碍作用，以实现药物的控释。模型已通过湿实验室实验数据进行了验证，可用于未来BNC药物递送系统的设计。


<details>
  <summary>Details</summary>
Motivation: 现有关于BNC药物释放的研究多为可行性研究，在建模和设计方面仍有待探索，本研究旨在弥补这一研究空白。

Method: 提出一种基于物理学的模型，该模型能够反映BNC的几何结构并考虑聚合物涂层对药物释放的影响，聚合物涂层作为额外的扩散屏障，用于控制活性药物成分的释放。

Result: 通过湿实验室实验数据验证了所提出模型的准确性。

Conclusion: 所提出的模型可以用于未来设计基于BNC的药物递送系统。

Abstract: Recently, bacterial nanocellulose (BNC), a biological material produced by
non-pathogenic bacteria that possesses excellent material properties for
various medical applications, has received increased interest as a carrier
system for drug delivery. However, the vast majority of existing studies on
drug release from BNC are feasibility studies with modeling and design aspects
remaining largely unexplored. To narrow this research gap, this paper proposes
a novel model for the drug release from BNC. Specifically, the drug delivery
system considered in this paper consists of a BNC fleece coated with a polymer.
The polymer coating is used as an additional diffusion barrier, enabling the
controlled release of an active pharmaceutical ingredient. The proposed
physics-based model reflects the geometry of the BNC and incorporates the
impact of the polymer coating on the drug release. Hence, it can be useful for
designing BNC-based drug delivery systems in the future. The accuracy of the
model is validated with experimental data obtained in wet lab experiments.

</details>


### [339] [Depression diagnosis from patient interviews using multimodal machine learning](https://arxiv.org/abs/2508.19390)
*Jana Weber,Marcel Weber,Juan Miguel Lopez Alcaraz*

Main category: eess.SP

TL;DR: 该研究开发了一种结合语音、语言和临床信息的多模态机器学习模型，用于辅助诊断抑郁症，并在抑郁症筛查方面表现出良好的校准和更高的临床净效益。


<details>
  <summary>Details</summary>
Motivation: 抑郁症是一种普遍的公共卫生问题，早期准确诊断至关重要，但识别仍具挑战性。患者访谈中的语音、语言和行为线索可以作为客观标记来支持临床评估。

Method: 开发了一种整合来自患者访谈的特征（包括语音模式、语言特征和结构化临床信息）的诊断方法。为每种模式分别训练模型，然后通过多模态融合进行组合，以反映现实世界精神科评估的复杂性。使用性能指标、校准和决策分析方法评估模型有效性。

Result: 多模态模型取得了优于单一模态模型的诊断准确性，AUROC为0.88，F1分数为0.75。此外，融合模型显示出良好的校准，并提供了比基线策略更高的临床净效益，证明了其在更可靠地识别抑郁症患者方面的潜力。

Conclusion: 通过机器学习对患者访谈进行多模态分析可以作为精神科评估的宝贵辅助手段。通过结合语音、语言和临床特征，该方法提供了一个稳健的框架，可以加强对抑郁症的早期检测，并支持心理健康决策的循证决策。

Abstract: Background: Depression is a major public health concern, affecting an
estimated five percent of the global population. Early and accurate diagnosis
is essential to initiate effective treatment, yet recognition remains
challenging in many clinical contexts. Speech, language, and behavioral cues
collected during patient interviews may provide objective markers that support
clinical assessment.
  Methods: We developed a diagnostic approach that integrates features derived
from patient interviews, including speech patterns, linguistic characteristics,
and structured clinical information. Separate models were trained for each
modality and subsequently combined through multimodal fusion to reflect the
complexity of real-world psychiatric assessment. Model validity was assessed
with established performance metrics, and further evaluated using calibration
and decision-analytic approaches to estimate potential clinical utility.
  Results: The multimodal model achieved superior diagnostic accuracy compared
to single-modality models, with an AUROC of 0.88 and an F1-score of 0.75.
Importantly, the fused model demonstrated good calibration and offered higher
net clinical benefit compared to baseline strategies, highlighting its
potential to assist clinicians in identifying patients with depression more
reliably.
  Conclusion: Multimodal analysis of patient interviews using machine learning
may serve as a valuable adjunct to psychiatric evaluation. By combining speech,
language, and clinical features, this approach provides a robust framework that
could enhance early detection of depressive disorders and support
evidence-based decision-making in mental healthcare.

</details>


### [340] [1-Bit Unlimited Sampling Beyond Fourier Domain: Low-Resolution Sampling of Quantization Noise](https://arxiv.org/abs/2508.19408)
*Vaclav Pavlicek,Ayush Bhandari*

Main category: eess.SP

TL;DR: 本文提出了一种新的1位采样架构，它扩展了传统的1位Σ-Δ量化（SDQ）和无限制传感框架（USF）。该架构通过在硬件中引入模非线性来解决SDQ过载问题，并提出了一种新的变换域恢复方法，在傅立叶域中优于现有技术，减少了过采样需求并提高了鲁棒性。


<details>
  <summary>Details</summary>
Motivation: ADC在数字信号采集中至关重要，但受采样率和比特预算限制，比特预算在动态范围（DR）和数字分辨率之间存在权衡，能耗与采样率成线性关系，与比特深度成指数关系。现有的1位ADC（如SDQ）存在过载问题，无法处理任意DR输入。

Method: 提出了一种新的1位采样架构，将噪声整形概念推广到傅立叶域之外，允许包含非带限信号（在其他变换域中带限）。基于此，开发了一种新的变换域恢复方法，用于1位USF，在傅立叶域中应用时优于时间域技术。

Result: 所提出的方法在傅立叶域中表现优于现有时间域技术，减少了过采样需求，提高了鲁棒性。

Conclusion: 通过数值实验验证了所提出的1位采样架构和变换域恢复方法的有效性，为1位采样系统更广泛的推广奠定了基础。

Abstract: Analog-to-digital converters (ADCs) play a critical role in digital signal
acquisition across various applications, but their performance is inherently
constrained by sampling rates and bit budgets. This bit budget imposes a
trade-off between dynamic range (DR) and digital resolution, with ADC energy
consumption scaling linearly with sampling rate and exponentially with bit
depth. To bypass this, numerous approaches, including oversampling with
low-resolution ADCs, have been explored. A prominent example is 1-Bit ADCs with
Sigma-Delta Quantization (SDQ), a widely used consumer-grade solution. However,
SDQs suffer from overloading or saturation issues, limiting their ability to
handle inputs with arbitrary DR. The Unlimited Sensing Framework (USF)
addresses this challenge by injecting modulo non-linearity in hardware,
resulting in a new digital sensing technology. In this paper, we introduce a
novel 1-Bit sampling architecture that extends both conventional 1-Bit SDQ and
USF. Our contributions are twofold: (1) We generalize the concept of noise
shaping beyond the Fourier domain, allowing the inclusion of non-bandlimited
signals in the Fourier domain but bandlimited in alternative transform domains.
(2) Building on this generalization, we develop a new transform-domain recovery
method for 1-Bit USF. When applied to the Fourier domain, our method
demonstrates superior performance compared to existing time-domain techniques,
offering reduced oversampling requirements and improved robustness. Extensive
numerical experiments validate our findings, laying the groundwork for a
broader generalization of 1-Bit sampling systems.

</details>


### [341] [In-Lab Carrier Aggregation Testbed for Satellite Communication Systems](https://arxiv.org/abs/2508.19439)
*Jorge L. Gonzalez-Rios,Eva Lagunas,Hayder Al-Hraishawi,Luis M. Garces-Socarras,Symeon Chatzinotas*

Main category: eess.SP

TL;DR: 载波聚合（CA）是一种在5G及之前蜂窝网络中用于提高用户数据速率和管理网络拥塞的技术，它通过聚合多个载波来提供更宽的虚拟带宽。本文设计并实现了一个基于软件定义无线电（SDR）和卫星信道模拟器的CA实验平台，并对单GEO卫星、单MEO卫星以及GEO和MEO卫星混合场景下的CA性能进行了评估。实验结果表明CA在卫星通信系统中具有显著优势，并提出了未来在实际空地系统上进行测试的建议。


<details>
  <summary>Details</summary>
Motivation: 为了评估载波聚合（CA）技术在卫星通信（SatCom）中利用频谱和满足用户流量需求的潜力，并解决现有理论评估的不足，本文旨在设计并验证一个基于SDR和卫星信道模拟器的CA实验平台，特别关注多轨道场景。

Method: 本文首先详细介绍了基于SDR和卫星信道模拟器的CA实验平台的设计，包括负责跨聚合载波调度PDU的网关（GW）模块和负责聚合多个接收流的用户终端（UT）模块。随后，通过实验评估了CA在单一静地轨道（GEO）卫星、单一中地球轨道（MEO）卫星以及结合GEO和MEO卫星的混合轨道场景下的性能。

Result: 实验结果显示，在单GEO卫星、单MEO卫星以及GEO和MEO卫星混合的多种轨道场景下，CA技术在卫星通信系统中均展现出有益的性能。

Conclusion: 基于SDR和卫星信道模拟器的实验结果表明，载波聚合（CA）技术对卫星通信系统具有显著的优势，并且在多轨道场景下的应用也显示出良好的前景，这为未来在实际空地系统上进行进一步测试提供了动力。

Abstract: Carrier Aggregation (CA) is a technique used in 5G and previous cellular
generations to temporarily increase the data rate of a specific user during
peak demand periods or to reduce carrier congestion. CA is achieved by
combining two or more carriers and providing a virtual, wider overall bandwidth
to high-demand users of the system. CA was introduced in the 4G/LTE wireless
era and has been proven effective in 5G as well, where it is said to play a
significant role in efficient network capacity management. Given this success,
the satellite communication (SatCom) community has put its attention into CA
and the potential benefits it can bring in terms of better spectrum utilization
and better meeting the user traffic demand. While the theoretical evaluation of
CA for SatCom has already been presented in several works, this article
presents the design and results obtained with an experimentation testbed based
on Software Defined Radio (SDR) and a satellite channel emulator. We first
present the detailed implementation design, which includes a Gateway (GW)
module responsible for PDU-scheduling across the aggregated carriers, and a
User Terminal (UT) module responsible for aggregating the multiple received
streams. The second part of the article presents the experimental evaluation,
including CA over a single Geostationary (GEO) satellite, CA over a single
Medium Earth Orbit (MEO) satellite, and CA combining carriers sent over GEO and
MEO satellites. A key contribution of this work is the explicit consideration
of multi-orbit scenarios in the testbed design and validation. The testing
results show promising benefits of CA over SatCom systems, motivating potential
upcoming testing on over-the-air systems.

</details>


### [342] [Fourth-Order Hierarchical Array: A Novel Scheme for Sparse Array Design Based on Fourth-Order Difference Co-Array](https://arxiv.org/abs/2508.19522)
*Si Wang,Guoqiang Xiao*

Main category: eess.SP

TL;DR: 本文提出了一种新颖的四阶分馏阵列（FOHA）设计方案，通过组合不同形式的四阶差分协方差阵（FODCA）并考虑互耦效应，实现了自由度（DOFs）的提升和互耦的抑制，提高了DOA估计性能。


<details>
  <summary>Details</summary>
Motivation: 解决传统基于圆形四阶累积量阵列设计中，因采用单一形式的FODCA而导致的DOFs受限以及忽略互耦效应的问题。

Method: 构建基于不同形式FODCA的新型四阶分馏阵列（FOHA），推导了发电机耦合泄漏与所得FOHA之间的解析表达式，并提出了两种具有闭式传感器位置的FOHA配置。

Result: 提出的FOHA阵列不仅提供了更高的DOFs以分辨更多信源进行DOA估计，而且有效抑制了互耦效应。与现有的基于FODCA的阵列相比，FOHA阵列具有更低的冗余度，并推导了FOHA实现信号重建的充要条件。仿真结果表明，FOHA的DOA估计性能优于其他稀疏线性阵列。

Conclusion: 本文提出的FOHA阵列通过组合不同形式的FODCA并考虑互耦效应，在提升DOFs和抑制互耦方面优于现有阵列，从而在DOA估计方面表现出更优越的性能。

Abstract: Conventional array designs based on circular fourth-order cumulant typically
adopt a single expression form of the fourth-order difference co-array (FODCA),
which limits the achievable degrees of freedom (DOFs) and neglects the impact
of mutual coupling among physical sensors. To address above issues, this paper
proposes a novel scheme to design arrays with increased DOFs by combining
different forms of FODCA while accounting for mutual coupling. A novel
fourth-order hierarchical array (FOHA) based on different forms of FODCA is
constructed using an arbitrary generator set. The analytical expression between
the coupling leakage of the generator and the resulting FOHA is derived. Two
specific FOHA configurations are presented with closed-form sensor placements.
The arrays not only offer increased DOFs for resolving more sources in
direction of-arrival (DOA) estimation but also effectively suppress mutual
coupling. Moreover, the redundancy of FODCA is examined, and it is shown that
arrays based on the proposed scheme achieve lower redundancy compared to
existing arrays based on FODCA. Meanwhile, the necessary and sufficient
conditions for signal reconstruction by FOHA are derived. Compared with
existing arrays based on FODCA, the proposed arrays provide enhanced DOFs and
improved robustness against mutual coupling. Numerical simulations verify that
FOHAs achieve superior DOA estimation performance compared with other sparse
linear arrays.

</details>


### [343] [Arbitrary Precision Printed Ternary Neural Networks with Holistic Evolutionary Approximation](https://arxiv.org/abs/2508.19660)
*Vojtech Mrazek,Konstantinos Balaskas,Paula Carolina Lozano Duarte,Zdenek Vasicek,Mehdi B. Tahoori,Georgios Zervakis*

Main category: eess.SP

TL;DR: 本文提出了一种自动化框架，用于设计具有任意输入精度的印刷三元神经网络（TNN），实现了印刷神经网络在面积和功耗效率上的突破，能够以低于5%的精度损失实现印刷电池供电运行。


<details>
  <summary>Details</summary>
Motivation: 为了实现柔性、可拉伸、低成本的印刷电子应用，尤其是印刷神经网络，需要解决复杂电路设计中的面积效率和功耗问题，特别是在模拟数字转换接口部分。

Method: 提出了一种自动化框架，利用多目标优化和整体近似技术，设计印刷三元神经网络（TNN），并对包括模拟数字转换在内的整个近传感器处理系统进行了联合优化，允许任意输入精度。

Result: 所提出的印刷TNN在面积和功耗方面比现有印刷神经网络平均优越17倍和59倍，并且首次实现了印刷电池供电运行，精度损失低于5%。

Conclusion: 通过自动化设计框架和联合优化方法，成功地实现了印刷神经网络在面积和功耗效率上的显著提升，克服了印刷电子在复杂电路应用中的挑战，并首次实现了低功耗、高精度的印刷电池供电系统。

Abstract: Printed electronics offer a promising alternative for applications beyond
silicon-based systems, requiring properties like flexibility, stretchability,
conformality, and ultra-low fabrication costs. Despite the large feature sizes
in printed electronics, printed neural networks have attracted attention for
meeting target application requirements, though realizing complex circuits
remains challenging. This work bridges the gap between classification accuracy
and area efficiency in printed neural networks, covering the entire
processing-near-sensor system design and co-optimization from the
analog-to-digital interface-a major area and power bottleneck-to the digital
classifier. We propose an automated framework for designing printed Ternary
Neural Networks with arbitrary input precision, utilizing multi-objective
optimization and holistic approximation. Our circuits outperform existing
approximate printed neural networks by 17x in area and 59x in power on average,
being the first to enable printed-battery-powered operation with under 5%
accuracy loss while accounting for analog-to-digital interfacing costs.

</details>


### [344] [Pinching Antenna System for Integrated Sensing and Communications](https://arxiv.org/abs/2508.19540)
*Haochen Li,Ruikang Zhong,Jiayi Lei,Yuanwei Liu*

Main category: eess.SP

TL;DR: 该研究提出了一个基于多波导捏紧天线系统（PASS）的集成传感与通信（ISAC）系统，旨在优化目标感知并满足通信服务质量（QoS）要求。


<details>
  <summary>Details</summary>
Motivation: 为了解决现有ISAC系统在灵活部署和信号传播损耗方面的不足，提出了一种新的基于PASS的ISAC系统。

Method: 利用捏紧天线（PA）和均匀线性阵列（ULA）天线，构建了全双工（FD）基站（BS）。通过交替优化（AO）算法求解以最小化目标感知克拉美-罗界（CRB），同时考虑QoS、功率预算和PA部署约束。具体地，将问题分解为数字波束成形子问题（使用半定松弛法（SDR）求解）和捏紧波束成形子问题（使用连续凸近似法（SCA）、惩罚法和逐元优化法求解）。

Result: 仿真结果表明，所提出的PASS辅助ISAC框架性能优于基准方案，且相比于传统MIMO-ISAC系统，对通信约束的鲁棒性更强。增加波导数量和每个波导的PA数量可以带来进一步的性能提升。

Conclusion: 所提出的PASS辅助ISAC系统在通信和感知性能上均表现出色，并展现出良好的扩展性和鲁棒性，证明了其在ISAC领域的应用潜力。

Abstract: Recently, the pinching antenna system (PASS) has attracted considerable
attention due to their advantages in flexible deployment and reduction of
signal propagation loss. In this work, a multiple waveguide PASS assisted
integrated sensing and communication (ISAC) system is proposed, where the base
station (BS) is equipped with transmitting pinching antennas (PAs) and
receiving uniform linear array (ULA) antennas. The full-duplex (FD) BS
transmits the communication and sensing signals through the PAs on waveguides
and collects the echo sensing signals with the mounted ULA. Based on this
configuration, a target sensing Cramer Rao Bound (CRB) minimization problem is
formulated under communication quality-of-service (QoS) constraints, power
budget constraint, and PA deployment constraints. The alternating optimization
(AO) method is employed to address the formulated non-convex optimization
problem. In each iteration, the overall optimization problem is decomposed into
a digital beamforming sub-problem and a pinching beamforming sub-problem. The
sensing covariance matrix and communication beamforming matrix at the BS are
optimized by solving the digital beamforming sub-problem with semidefinite
relaxation (SDR). The PA deployment is updated by solving the pinching
beamforming sub-problem with the successive convex approximation (SCA) method,
penalty method, and element-wise optimization. Simulation results show that the
proposed PASS assisted ISAC framework achieves superior performance over
benchmark schemes, is less affected by stringent communication constraints
compared to conventional MIMO-ISAC, and benefits further from increasing the
number of waveguides and PAs per waveguide.

</details>


### [345] [CSRD2025: A Large-Scale Synthetic Radio Dataset for Spectrum Sensing in Wireless Communications](https://arxiv.org/abs/2508.19552)
*Shuo Chang,Rui Sun,Jiashuo He,Sai Huang,Kan Yu,Zhiyong Feng*

Main category: eess.SP

TL;DR: 本论文介绍了一个名为ChangShuoRadioData (CSRD) 的开源框架，用于生成大规模合成射频数据，以满足无线通信领域大型AI模型（LAMs）对多样化数据集的需求。CSRD能够模拟端到端的信号传输和接收过程，支持多种调制方案、可配置的信道模型（包括基于OpenStreetMap的射线追踪）以及真实的射频前端损伤。基于此框架，论文提出了CSRD2025数据集，包含超过2500万帧（约200TB）的数据，规模远超现有数据集，旨在缩小仿真与现实之间的差距。此外，论文还提供了IQ数据到COCO格式频谱图的转换流程，并设定了标准化的数据划分（8:1:1），以促进AI驱动的频谱感知和管理研究。


<details>
  <summary>Details</summary>
Motivation: 当前，大型AI模型（LAMs）在无线通信领域的应用，特别是在频谱感知等复杂任务中，极度依赖大规模、多样化和真实的数据集。为满足此需求，本文旨在提供一个能够生成此类数据集的解决方案。

Method: 本文引入了ChangShuoRadioData (CSRD) 框架，这是一个开源的、模块化的仿真平台，用于生成大规模合成射频（RF）数据。CSRD能够端到端地模拟信号的传输和接收，支持100种调制方案，包括模拟、数字、OFDM和OTFS。同时，它还集成了先进的信道模型，支持统计衰落和基于OpenStreetMap数据的特定站点射线追踪。此外，CSRD还详细模拟了不同天线配置（SISO/MISO/MIMO）下的射频前端损伤。基于此框架，研究者们创建了CSRD2025数据集，该数据集包含超过2500万帧（约200TB）数据，并提供了将IQ数据转换为COCO格式频谱图的处理流程，以支持基于对象检测的时频信号分析。最后，论文还规定了标准化的8:1:1训练、验证和测试数据划分（通过帧索引），以确保研究的可复现性。

Result: 本文成功开发了CSRD框架，并基于该框架构建了CSRD2025数据集，该数据集规模庞大（约200TB），远超现有数据集（如RML2018），提供了前所未有的信号多样性和复杂性，旨在有效弥合仿真（Sim）与现实（Real）之间的差距。此外，还提供了IQ数据到COCO格式频谱图的转换流程，为时频信号分析中的对象检测方法提供了支持。标准化的8:1:1数据划分也确保了研究的可复现性。

Conclusion: CSRD框架及其生成的CSRD2025数据集为无线通信领域的大型AI模型研究提供了关键的数据支撑，尤其是在频谱感知和管理方面。通过提供大规模、多样化且逼真的合成数据，并辅以易于使用的处理流程和标准化的数据划分，CSRD有望加速AI在无线通信领域的创新和应用，有效解决现有数据集的局限性。

Abstract: The development of Large AI Models (LAMs) for wireless communications,
particularly for complex tasks like spectrum sensing, is critically dependent
on the availability of vast, diverse, and realistic datasets. Addressing this
need, this paper introduces the ChangShuoRadioData (CSRD) framework, an
open-source, modular simulation platform designed for generating large-scale
synthetic radio frequency (RF) data. CSRD simulates the end-to-end transmission
and reception process, incorporating an extensive range of modulation schemes
(100 types, including analog, digital, OFDM, and OTFS), configurable channel
models featuring both statistical fading and site-specific ray tracing using
OpenStreetMap data, and detailed modeling of realistic RF front-end impairments
for various antenna configurations (SISO/MISO/MIMO). Using this framework, we
characterize CSRD2025, a substantial dataset benchmark comprising over
25,000,000 frames (approx. 200TB), which is approximately 10,000 times larger
than the widely used RML2018 dataset. CSRD2025 offers unprecedented signal
diversity and complexity, specifically engineered to bridge the Sim2Real gap.
Furthermore, we provide processing pipelines to convert IQ data into
spectrograms annotated in COCO format, facilitating object detection approaches
for time-frequency signal analysis. The dataset specification includes
standardized 8:1:1 training, validation, and test splits (via frame indices) to
ensure reproducible research. The CSRD framework is released at
https://github.com/Singingkettle/ChangShuoRadioData to accelerate the
advancement of AI-driven spectrum sensing and management.

</details>


### [346] [Demonstrator Testbed for Effective Precoding in MEO Multibeam Satellites](https://arxiv.org/abs/2508.19657)
*Jorge L. González-Rios,Liz Martínez Marrero,Juan Duncan,Luis M. Garcés-Socarrás,Raudel Cuiman Marquez,Juan A. Vásquez Peralvo,Jevgenij Krivochiza,Symeon Chatzinotas,Björn Ottersten*

Main category: eess.SP

TL;DR: 本研究设计了一个基于SDR的在轨测试平台，用于解决MEO卫星通信中的多用户MISO预编码问题，并提出了一个同步环来缓解多普勒频移和相位噪声等影响。


<details>
  <summary>Details</summary>
Motivation: 随着通信卫星在中轨（MEO）部署提供准全球宽带互联网连接，MU-MISO预编码技术成为多波束卫星系统前向链路的关键技术，但MEO卫星的轨道动力学带来了额外的挑战。

Method: 设计了一个基于SDR平台的在轨测试平台，并针对MEO场景进行了优化，考虑了精确的轨道模型和自定义DRA的辐射模式，分析了多普勒频移和相位噪声等影响，并提出了一个同步环来缓解这些影响。

Result: 初步的实验结果验证了所提出解决方案的可行性和有效性。

Conclusion: 所提出的基于SDR的测试平台和同步环能够有效地解决MEO卫星通信中MU-MISO预编码面临的挑战，并为未来的卫星网络提供支持。

Abstract: The use of communication satellites in medium Earth orbit (MEO) is foreseen
to provide quasi-global broadband Internet connectivity in the coming
networking ecosystems. Multi-user multiple-input single-output (MU-MISO)
digital signal processing techniques, such as precoding, emerge as appealing
technological enablers in the forward link of multi-beam satellite systems
operating in full frequency reuse (FFR). However, the orbit dynamics of MEO
satellites pose additional challenges that must be carefully evaluated and
addressed. This work presents the design of an in-lab testbed based on
software-defined radio (SDR) platforms and the corresponding adaptations
required for efficient precoding in a MEO scenario. The setup incorporates a
precise orbit model and the radiation pattern of a custom-designed direct
radiating array (DRA). We analyze the main impairments affecting precoding
performance, including Doppler shifts and payload phase noise, and propose a
synchronization loop to mitigate these effects. Preliminary experimental
results validate the feasibility and effectiveness of the proposed solution.

</details>


### [347] [Energy-Efficient Learning-Based Beamforming for ISAC-Enabled V2X Networks](https://arxiv.org/abs/2508.19566)
*Chen Shang,Jiadong Yu,Dinh Thai Hoang*

Main category: eess.SP

TL;DR: 提出了一种基于学习的节能波束赋形方案，用于集成传感与通信（ISAC）的车联网（V2X）网络。通过将V2X环境建模为马尔可夫决策过程，并利用深度强化学习（DRL）优化波束赋形和功率分配。为提高能效，引入了脉冲神经网络（SNN）到DRL框架中，利用其事件驱动和稀疏激活特性。仿真结果表明，该方法显著节能且通信性能优越。


<details>
  <summary>Details</summary>
Motivation: 为了提高车联网（V2X）网络中集成传感与通信（ISAC）系统的能效，并应对V2X环境的动态和不确定性。

Method: 将V2X环境建模为马尔可在决策过程中，开发了一种深度强化学习（DRL）算法来联合优化波束赋形和功率分配。在DRL框架中嵌入脉冲神经网络（SNN）以提高能效。

Result: 仿真结果表明，所提出的方法实现了显著的节能和优越的通信性能。

Conclusion: 所提出的基于SNN的DRL波束赋形方案能够为未来的V2X系统提供绿色和可持续的连接。

Abstract: This work proposes an energy-efficient, learning-based beamforming scheme for
integrated sensing and communication (ISAC)-enabled V2X networks. Specifically,
we first model the dynamic and uncertain nature of V2X environments as a Markov
Decision Process. This formulation allows the roadside unit to generate
beamforming decisions based solely on current sensing information, thereby
eliminating the need for frequent pilot transmissions and extensive channel
state information acquisition. We then develop a deep reinforcement learning
(DRL) algorithm to jointly optimize beamforming and power allocation, ensuring
both communication throughput and sensing accuracy in highly dynamic scenario.
To address the high energy demands of conventional learning-based schemes, we
embed spiking neural networks (SNNs) into the DRL framework. Leveraging their
event-driven and sparsely activated architecture, SNNs significantly enhance
energy efficiency while maintaining robust performance. Simulation results
confirm that the proposed method achieves substantial energy savings and
superior communication performance, demonstrating its potential to support
green and sustainable connectivity in future V2X systems.

</details>


### [348] [Code-Weight Sphere Decoding](https://arxiv.org/abs/2508.19631)
*Yubeen Jo,Geon Choi,Yongjune Kim,Namyoon Lee*

Main category: eess.SP

TL;DR: 一种用于URLLC的新型两阶段近最大似然（near-ML）译码框架，结合低复杂度初始译码器和码重球译码（WSD），在可靠性和复杂度之间取得了良好的折衷。


<details>
  <summary>Details</summary>
Motivation: 为满足URLLC对高性能前向纠错码和译码器的需求，尤其是在有限码长方面。

Method: 提出了一种两阶段near-ML译码框架：1. 低复杂度初始译码；2. 若初始译码失败，则激活码重球译码（WSD），通过探索预先计算的低码重码字来优化码字估计。

Result: 该译码器在较高信噪比下计算开销可控，并能达到近ML性能，尤其适用于低速率码。仿真结果表明，该译码器在可靠性和复杂度之间取得了优异的折衷。

Conclusion: 所提出的两阶段译码器是下一代URLLC系统的有前景的解决方案。

Abstract: Ultra-reliable low-latency communications (URLLC) demand high-performance
error-correcting codes and decoders in the finite blocklength regime. This
letter introduces a novel two-stage near-maximum likelihood (near-ML) decoding
framework applicable to any linear block code. Our approach first employs a
low-complexity initial decoder. If this initial stage fails a cyclic redundancy
check, it triggers a second stage: the proposed code-weight sphere decoding
(WSD). WSD iteratively refines the codeword estimate by exploring a localized
sphere of candidates constructed from pre-computed low-weight codewords. This
strategy adaptively minimizes computational overhead at high signal-to-noise
ratios while achieving near-ML performance, especially for low-rate codes.
Extensive simulations demonstrate that our two-stage decoder provides an
excellent trade-off between decoding reliability and complexity, establishing
it as a promising solution for next-generation URLLC systems.

</details>


### [349] [Invited Paper: Feature-to-Classifier Co-Design for Mixed-Signal Smart Flexible Wearables for Healthcare at the Extreme Edge](https://arxiv.org/abs/2508.19637)
*Maha Shatta,Konstantinos Balaskas,Paula Carolina Lozano Duarte,Georgios Panagopoulos,Mehdi B. Tahoori,Georgios Zervakis*

Main category: eess.SP

TL;DR: 柔性电子在可穿戴医疗设备领域具有潜力，但集成密度低和特征尺寸大限制了其在机器学习应用中的表现。本文提出了一种混合信号的、面向柔性可穿戴系统的特征到分类器联合设计框架，首次在柔性电子领域实现了模拟特征提取器，并结合硬件感知神经架构搜索（NAS）启发的功能选择策略，以实现高效、应用特定的设计。评估结果表明，该方法在医疗基准测试中实现了高精度和极低面积效率的柔性系统，非常适合一次性、低功耗的可穿戴监控设备。


<details>
  <summary>Details</summary>
Motivation: 解决柔性电子在集成密度低、特征尺寸大方面的限制，以及现有方案忽略特征提取和ADC硬件成本的问题，旨在实现面向机器学习的、低功耗、低成本的柔性可穿戴医疗系统。

Method: 提出了一种混合信号的特征到分类器联合设计框架，实现了柔性电子领域的模拟特征提取器，并提出了一种硬件感知神经架构搜索（NAS）启发的功能选择策略，嵌入到机器学习训练中。

Result: 在医疗基准测试中，所提出的方法实现了高精度的柔性系统，并且面积效率极高，功耗低，适用于一次性、低功耗的可穿戴监控场景。

Conclusion: 所提出的混合信号联合设计框架能够显著降低柔性可穿戴医疗系统的成本和功耗，实现高精度和高面积效率，为柔性电子在医疗健康领域的应用提供了新的解决方案。

Abstract: Flexible Electronics (FE) offer a promising alternative to rigid
silicon-based hardware for wearable healthcare devices, enabling lightweight,
conformable, and low-cost systems. However, their limited integration density
and large feature sizes impose strict area and power constraints, making
ML-based healthcare systems-integrating analog frontend, feature extraction and
classifier-particularly challenging. Existing FE solutions often neglect
potential system-wide solutions and focus on the classifier, overlooking the
substantial hardware cost of feature extraction and Analog-to-Digital
Converters (ADCs)-both major contributors to area and power consumption. In
this work, we present a holistic mixed-signal feature-to-classifier co-design
framework for flexible smart wearable systems. To the best of our knowledge, we
design the first analog feature extractors in FE, significantly reducing
feature extraction cost. We further propose an hardware-aware NAS-inspired
feature selection strategy within ML training, enabling efficient,
application-specific designs. Our evaluation on healthcare benchmarks shows our
approach delivers highly accurate, ultra-area-efficient flexible systems-ideal
for disposable, low-power wearable monitoring.

</details>


### [350] [On Minimization/Maximization of the Generalized Multi-Order Complex Quadratic Form With Constant-Modulus Constraints](https://arxiv.org/abs/2508.19822)
*Chunxuan Shi,Yongzhe Li,Ran Tao*

Main category: eess.SP

TL;DR: 该论文研究了在复数域上，对一个多阶复数二次型进行常模约束下的优化问题（CMCQP），该问题在信号处理中有广泛应用，但通常是非凸且难解的。


<details>
  <summary>Details</summary>
Motivation: 信号处理中的常见问题，如信噪比、Cramér-Rao界、旁瓣电平等指标的优化，以及实际应用中的相似性、峰均功率比、常模约束等需求。

Method: 将问题重构为仅关于相位值的无约束优化问题，并提出了一种陡度下降/上升法，通过对搜索函数进行三阶泰勒展开，将步长搜索问题转化为多项式问题，从而得到高精度的闭式解。

Result: 提出了两种CMCQP的代表性情况，并提供了相关应用示例。通过仿真验证了所提出算法的收敛速度快于现有方法，并评估了快速步长确定的准确性。

Conclusion: 通过将CMCQP问题转化为相位优化问题，并结合高效的步长确定方法，为解决此类信号处理中的优化问题提供了一种有效途径。

Abstract: In this paper, we study the generalized problem that minimizes or maximizes a
multi-order complex quadratic form with constant-modulus constraints on all
elements of its optimization variable. Such a mathematical problem is commonly
encountered in various applications of signal processing. We term it as the
constant-modulus multi-order complex quadratic programming (CMCQP) in this
paper. In general, the CMCQP is non-convex and difficult to solve. Its
objective function typically relates to metrics such as signal-to-noise ratio,
Cram\'er-Rao bound, integrated sidelobe level, etc., and constraints normally
correspond to requirements on similarity to desired aspects,
peak-to-average-power ratio, or constant-modulus property in practical
scenarios. In order to find efficient solutions to the CMCQP, we first
reformulate it into an unconstrained optimization problem with respect to phase
values of the studied variable only. Then, we devise a steepest descent/ascent
method with fast determinations on its optimal step sizes. Specifically, we
convert the step-size searching problem into a polynomial form that leads to
closed-form solutions of high accuracy, wherein the third-order Taylor
expansion of the search function is conducted. Our major contributions also lie
in investigating the effect of the order and specific form of matrices embedded
in the CMCQP, for which two representative cases are identified. Examples of
related applications associated with the two cases are also provided for
completeness. The proposed methods are summarized into algorithms, whose
convergence speeds are verified to be fast by comprehensive simulations and
comparisons to existing methods. The accuracy of our proposed fast step-size
determination is also evaluated.

</details>


### [351] [Experimental End-to-End Optimization of Directly Modulated Laser-based IM/DD Transmission](https://arxiv.org/abs/2508.19910)
*Sergio Hernandez,Christophe Peucheret,Francesco Da Ros,Darko Zibar*

Main category: eess.SP

TL;DR: 数据驱动的替代模型可以优化基于直接调制激光器（DML）的通信系统。


<details>
  <summary>Details</summary>
Motivation: 直接调制激光器（DML）在短距离通信系统中很有吸引力，但其复杂的非线性动力学使得建模和优化具有挑战性。

Method: 研究基于数据驱动的替代模型，对DML系统的脉冲整形、均衡滤波器、偏置电流以及调制射频功率进行端到端优化。

Result: 与基于线性和非线性接收端均衡的基准方案相比，提出的端到端方案在所研究的符号速率和传输距离上均能提供更好的性能，同时使用较低的调制射频功率、较少的滤波器抽头和较小的信号带宽。

Conclusion: 端到端的优化方案能够克服DML的非线性动力学，并带来性能上的提升。

Abstract: Directly modulated lasers (DMLs) are an attractive technology for short-reach
intensity modulation and direct detection communication systems. However, their
complex nonlinear dynamics make the modeling and optimization of DML-based
systems challenging. In this paper, we study the end-to-end optimization of
DML-based systems based on a data-driven surrogate model trained on
experimental data. The end-to-end optimization includes the pulse shaping and
equalizer filters, the bias current and the modulation radio-frequency (RF)
power applied to the laser. The performance of the end-to-end optimization
scheme is tested on the experimental setup and compared to 4 different
benchmark schemes based on linear and nonlinear receiver-side equalization. The
results show that the proposed end-to-end scheme is able to deliver better
performance throughout the studied symbol rates and transmission distances
while employing lower modulation RF power, fewer filter taps and utilizing a
smaller signal bandwidth.

</details>


### [352] [Cell-Free Massive MIMO-Based Physical-Layer Authentication](https://arxiv.org/abs/2508.19931)
*Isabella W. G. da Silva,Zahra Mobini,Hien Quoc Ngo,Michail Matthaiou*

Main category: eess.SP

TL;DR: 本研究提出了一种基于单元无关海量多输入多输出（CF-mMIMO）架构的物理层认证（PLA）框架，可同时认证网络中多个分布式用户，并能有效抵抗模仿攻击。


<details>
  <summary>Details</summary>
Motivation: 旨在设计一种能够同时认证多个分布式用户，并在存在模仿攻击时仍能保持有效性的物理层认证框架。

Method: 提出了一种基于标签的CF-mMIMO系统，在小区内训练阶段，接入点（AP）估计与合法用户的信道，并生成用户与AP之间的唯一密钥。然后，将问题形式化为假设检验问题，并推导出每个用户的检测概率的闭式表达式。

Result: 数值结果表明，该方法在网络用户数量增加时仍能保持高检测概率，验证了其有效性。

Conclusion: 所提出的基于CF-mMIMO的PLA框架能够有效地同时认证多个用户，并能抵抗各种攻击。

Abstract: In this paper, we exploit the cell-free massive multiple-input
multiple-output (CF-mMIMO) architecture to design a physical-layer
authentication (PLA) framework that can simultaneously authenticate multiple
distributed users across the coverage area. Our proposed scheme remains
effective even in the presence of active adversaries attempting impersonation
attacks to disrupt the authentication process. Specifically, we introduce a
tag-based PLA CFmMIMO system, wherein the access points (APs) first estimate
their channels with the legitimate users during an uplink training phase.
Subsequently, a unique secret key is generated and securely shared between each
user and the APs. We then formulate a hypothesis testing problem and derive a
closed-form expression for the probability of detection for each user in the
network. Numerical results validate the effectiveness of the proposed approach,
demonstrating that it maintains a high detection probability even as the number
of users in the system increases.

</details>


### [353] [The Coherent Multiplex: Scalable Real-Time Wavelet Coherence Architecture](https://arxiv.org/abs/2508.19994)
*Noah Shore*

Main category: eess.SP

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: The Coherent Multiplex is formalized and validated as a scalable, real-time
system for identifying, analyzing, and visualizing coherence among multiple
time series. Its architecture comprises a fast spectral similarity layer based
on cosine similarity metrics of Fourier-transformed signals, and a sparse
time-frequency layer for wavelet coherence. The system constructs and evolves a
multilayer graph representing inter-signal relationships, enabling low-latency
inference and monitoring. A simulation prototype demonstrates functionality
across 8 synthetic channels with a high similarity threshold for further
computation, with additional opportunities for scaling the architecture up to
support thousands of input signals with constrained hardware. Applications
discussed include neuroscience, finance, and biomedical signal analysis.

</details>


### [354] [Scalable, Technology-Agnostic Diagnosis and Predictive Maintenance for Point Machine using Deep Learning](https://arxiv.org/abs/2508.11692)
*Eduardo Di Santi,Ruixiang Ci,Clément Lefebvre,Nenad Mijatovic,Michele Pugnaloni,Jonathan Brown,Victor Martín,Kenza Saiah*

Main category: eess.SP

TL;DR: 该研究提出了一种仅需单一输入（电力信号）的深度学习方法，用于检测铁路道岔（Point Machine, PM）的故障。该方法通过分析电力信号模式来识别PM的异常，实现了超过99.99%的精确率、低于0.01%的误报率以及可忽略的漏报率。该方法具有技术无关性、可扩展性，并结合了保形预测以提供置信度，符合ISO-17359标准。


<details>
  <summary>Details</summary>
Motivation: 铁路道岔（PM）是关键的安全设备，其故障会导致运营中断。先前的故障检测方法依赖多种输入和定制特征，存在数据收集、处理要求高、技术和场景限制等问题。本研究旨在提出一种更通用、可扩展且数据需求更少的方法来预测PM故障。

Method: 本研究提出了一种基于深度学习的方法，仅使用PM运行时的电力信号作为单一输入。该模型分析电力信号的模式，以区分PM的正常状态和与不同故障类型相关的状态。此外，研究还引入了保形预测技术，为模型的输出提供置信度度量。

Result: 该深度学习模型在检测PM故障方面取得了极高的准确率，精确率超过99.99%，误报率低于0.01%，漏报率可忽略不计。该方法已被证明在多种机电PM类型和不同运行环境（实际运行和测试平台）中均具有可扩展性。

Conclusion: 本研究提出的基于单一电力信号的深度学习方法，能够高精度、高可靠性地检测铁路道岔的故障，克服了现有方法的局限性，并具有良好的通用性和可扩展性。结合保形预测后，该方法满足了ISO-17359标准，为铁路安全运维提供了有效的解决方案。

Abstract: The Point Machine (PM) is a critical piece of railway equipment that switches
train routes by diverting tracks through a switchblade. As with any critical
safety equipment, a failure will halt operations leading to service
disruptions; therefore, pre-emptive maintenance may avoid unnecessary
interruptions by detecting anomalies before they become failures. Previous work
relies on several inputs and crafting custom features by segmenting the signal.
This not only adds additional requirements for data collection and processing,
but it is also specific to the PM technology, the installed locations and
operational conditions limiting scalability. Based on the available maintenance
records, the main failure causes for PM are obstacles, friction, power source
issues and misalignment. Those failures affect the energy consumption pattern
of PMs, altering the usual (or healthy) shape of the power signal during the PM
movement. In contrast to the current state-of-the-art, our method requires only
one input. We apply a deep learning model to the power signal pattern to
classify if the PM is nominal or associated with any failure type, achieving
>99.99\% precision, <0.01\% false positives and negligible false negatives. Our
methodology is generic and technology-agnostic, proven to be scalable on
several electromechanical PM types deployed in both real-world and test bench
environments. Finally, by using conformal prediction the maintainer gets a
clear indication of the certainty of the system outputs, adding a confidence
layer to operations and making the method compliant with the ISO-17359
standard.

</details>


<div id='cs.NE'></div>

# cs.NE [[Back]](#toc)

### [355] [When Routers, Switches and Interconnects Compute: A processing-in-interconnect Paradigm for Scalable Neuromorphic AI](https://arxiv.org/abs/2508.19548)
*Madhuvanthi Srivatsav R,Chiranjib Bhattacharyya,Shantanu Chakrabartty,Chetan Singh Thakur*

Main category: cs.NE

TL;DR: 文章提出了一种名为“处理内互联”（π²）的新型神经形态计算范式，它利用现有的路由、交换和互联硬件来实现计算，从而提高能效和速度。


<details>
  <summary>Details</summary>
Motivation: 当前神经形态计算中的互联结构（路由、交换和互联）是能耗和速度的关键瓶颈，尤其是在大型AI工作负载中。因此，需要探索一种新的计算范式来解决这个问题。

Method: 该研究首先分析了现有路由、交换和互联系统中固有的计算范式，并展示了如何利用这些范式（如延迟、因果关系、超时、丢包和广播操作）来实现处理内互联（π²）计算范式。接着，研究人员展示了如何利用现有的缓冲和流量整形算法来实现神经元模型和突触操作，并提出了一种知识蒸馏框架来训练和映射神经网络拓扑到π²。最后，通过分析建模，研究人员评估了π²与其他神经形态架构在性能和能耗上的扩展性。

Result: 研究表明，AI工作负载中的操作可以映射到现有的硬件原语（延迟、因果关系、超时、丢包、广播），并且现有的嵌入式算法可用于实现神经元和突触操作。知识蒸馏框架可以在不损害泛化性能的情况下，将神经网络拓扑映射到π²。分析建模显示，π²的能耗扩展性随互联带宽和能效的增加而提高，并预测π²架构可以扩展到支持脑规模的AI推理工作负载，功耗在几百瓦范围内。

Conclusion: 处理内互联（π²）范式通过利用现有的网络硬件和技术趋势，为解决神经形态计算中的能耗和速度瓶颈提供了有前景的解决方案，有望实现可扩展的、低功耗的脑规模AI推理。

Abstract: Routing, switching, and the interconnect fabric are essential for large-scale
neuromorphic computing. While this fabric only plays a supporting role in the
process of computing, for large AI workloads it ultimately determines energy
consumption and speed. In this paper, we address this bottleneck by asking: (a)
What computing paradigms are inherent in existing routing, switching, and
interconnect systems, and how can they be used to implement a
processing-in-Interconnect (\pi^2) computing paradigm? and (b) leveraging
current and future interconnect trends, how will a \pi^2 system's performance
scale compared to other neuromorphic architectures? For (a), we show that
operations required for typical AI workloads can be mapped onto delays,
causality, time-outs, packet drop, and broadcast operations -- primitives
already implemented in packet-switching and packet-routing hardware. We show
that existing buffering and traffic-shaping embedded algorithms can be
leveraged to implement neuron models and synaptic operations. Additionally, a
knowledge-distillation framework can train and cross-map well-established
neural network topologies onto $\pi^2$ without degrading generalization
performance. For (b), analytical modeling shows that, unlike other neuromorphic
platforms, the energy scaling of $\pi^2$ improves with interconnect bandwidth
and energy efficiency. We predict that by leveraging trends in interconnect
technology, a \pi^2 architecture can be more easily scaled to execute
brain-scale AI inference workloads with power consumption levels in the range
of hundreds of watts.

</details>


### [356] [Walk the Robot: Exploring Soft Robotic Morphological Communication driven by Spiking Neural Networks](https://arxiv.org/abs/2508.19920)
*Matthew Meek,Guy Tallent,Thomas Breimer,James Gaskell,Abhay Kashyap,Atharv Tekurkar,Jonathan Fischman,Luodi Wang,Viet-Dung Nguyen,John Rieffel*

Main category: cs.NE

TL;DR: 该研究探索了在SNN控制的软体机器人中利用非线性动力学耦合进行形态通信


<details>
  <summary>Details</summary>
Motivation: 探索利用非线性动力学耦合进行机器人控制，特别是形态通信，以实现机器人控制器模块间的协调。

Method: 使用进化学习模型，进化了基于脉冲神经网络（SNN）的控制机制，在EvoGym环境中模拟了一个软体机器人。

Result: 研究表明，SNN控制的软体机器人在EvoGym环境中能够实现形态通信。

Conclusion: 进化学习模型和SNN是控制非刚性机器人和实现形态通信的有效方法。

Abstract: Recently, researchers have explored control methods that embrace nonlinear
dynamic coupling instead of suppressing it. Such designs leverage dynamical
coupling for communication between different parts of the robot. Morphological
communication refers to when those dynamics can be used as an emergent data bus
to facilitate coordination among independent controller modules within the same
robot. Previous research with tensegrity-based robot designs has shown that
evolutionary learning models that evolve spiking neural networks (SNN) as robot
control mechanisms are effective for controlling non-rigid robots. Our own
research explores the emergence of morphological communication in an SNN-based
simulated soft robot in theEvoGym environment.

</details>


<div id='cond-mat.mtrl-sci'></div>

# cond-mat.mtrl-sci [[Back]](#toc)

### [357] [Quantification of mobile ions in perovskite solar cells with thermally activated ion current measurements](https://arxiv.org/abs/2508.19403)
*Moritz C. Schmidt,Agustin O. Alvarez,Riccardo Pallotta,Biruk A. Seid,Jeroen J. de Boer,Jarla Thiesbrummel,Felix Lang,Giulia Grancini,Bruno Ehrler*

Main category: cond-mat.mtrl-sci

TL;DR: 该研究提出了一种名为热激活离子电流（TAIC）的新型表征技术，用于量化和区分钙钛矿太阳能电池中的移动离子。该技术仅需一次温度扫描即可确定离子的密度、扩散系数和激活能，并能直观地区分不同的离子种类。研究结果表明，与MAPbI3相比，三阳离子钙钛矿器件中的移动离子的激活能更高，扩散系数更低。TAIC技术为理解钙钛矿太阳能电池中的离子迁移提供了一种简单而强大的工具，有助于提高器件的稳定性。


<details>
  <summary>Details</summary>
Motivation: 为了提高钙钛矿太阳能电池的稳定性，需要对影响其降解的移动离子进行量化。然而，现有的电学测量方法在区分不同的离子迁移过程方面存在困难，并且通常需要多次在不同温度下进行测量才能表征不同的离子及其激活能。

Method: 提出并应用了一种基于测量钙钛矿太阳能电池热激活离子电流（TAIC）的新型表征技术。该技术通过一次温度扫描来测量离子的热激活电流，从而获得离子的密度、扩散系数和激活能，并能直观地区分不同的移动离子种类。

Result: 研究将TAIC技术应用于MAPbI3和三阳离子钙钛矿太阳能电池，发现三阳离子器件中的移动离子具有更高的激活能和更低的扩散系数。

Conclusion: TAIC测量是一种简单而强大的工具，能够更好地理解钙钛矿太阳能电池中的离子迁移，有助于提高器件的稳定性。

Abstract: Mobile ions play a key role in the degradation of perovskite solar cells,
making their quantification essential for enhancing device stability. Various
electrical measurements have been applied to characterize mobile ions. However,
discerning between different ionic migration processes can be difficult.
Furthermore, multiple measurements at different temperatures are usually
required to probe different ions and their activation energies. Here, we
demonstrate a new characterization technique based on measuring the thermally
activated ion current (TAIC) of perovskite solar cells. The method reveals
density, diffusion coefficient, and activation energy of mobile ions within a
single temperature sweep and offers an intuitive way to distinguish mobile ion
species. We apply the TAIC technique to quantify mobile ions of MAPbI3 and
triple-cation perovskite solar cells. We find a higher activation energy and a
lower diffusion coefficient in the triple-cation devices. TAIC measurements are
a simple yet powerful tool to better understand ion migration in perovskite
solar cells.

</details>


### [358] [Giant Anomalous Hall Conductivity and Gilbert Damping in Room-temperature Ferromagnetic Half-Heusler Alloys PtMnBi](https://arxiv.org/abs/2508.19551)
*Hong-Xue Jiang,Jia-wan Li,Shi-Bo Zhao,Jie Wang,Yusheng Hou*

Main category: cond-mat.mtrl-sci

TL;DR: PtMnBi合金（特别是α相）在自旋电子学领域显示出巨大潜力，具有高居里温度、大Gilbert阻尼和异常霍尔电导率，特别是在薄膜和应变条件下。


<details>
  <summary>Details</summary>
Motivation: 研究具有高居里温度和高异常霍尔电导率的材料，以应用于新型自旋电子器件。

Method: 使用第一性原理计算和蒙特卡洛模拟，系统研究了PtMnBi合金（α、β、γ相）的磁性和电子性质，包括薄膜和应变效应。

Result: α相PtMnBi具有高达802 K的居里温度和0.085的Gilbert阻尼。γ相PtMnBi在费米能级处具有203 Ω⁻¹cm⁻¹的异常霍尔电导率。α相PtMnBi薄膜的Gilbert阻尼随厚度变化，1L α相PtMnBi薄膜表现出增强的Gilbert阻尼（0.14）和异常霍尔电导率（1116 Ω⁻¹cm⁻¹）。2%的平面双轴压缩应变进一步将1L α相PtMnBi薄膜的Gilbert阻尼提高到0.17，异常霍尔电导率提高到2386 Ω⁻¹cm⁻¹。

Conclusion: α相PtMnBi因其优异的磁性和电学性质，特别是在薄膜和应变条件下，是自旋电子器件应用的理想材料。

Abstract: Half-Heusler alloys have emerged as promising candidates for novel spintronic
applications due to their exceptional properties including the high Curie
temperature (TC) above room temperature and large anomalous Hall conductivity
(AHC). In this work, we systematically study the magnetic and electronic
properties of PtMnBi in {\alpha}-, \{beta}-, and {\gamma}-phase using
first-principles calculations and Monte Carlo simulations. The three phases are
found to be ferromagnetic metals. In particular, the {\alpha}-phase PtMnBi
shows a high TC up to 802 K and a relatively large Gilbert damping of 0.085.
Additionally, the {\gamma}-phase PtMnBi possesses a non-negligible AHC,
reaching 203 {\Omega}-1cm-1 at the Fermi level. To evaluate its potential in
nanoscale devices, we further investigate the {\alpha}-phase PtMnBi thin films.
The Gilbert dampings of {\alpha}-phase PtMnBi thin films varies with film
thickness and we attribute this variation to the distinct band structures at
the high-symmetry point {\Gamma}, which arise from differences in film
thickness. Moreover, the 1-layer (1L) {\alpha}-phase thin film retains robust
ferromagnetism (TC = 688 K) and shows enhanced Gilbert damping (0.14) and AHC
(1116 {\Omega}-1cm-1) compared to the bulk. Intriguingly, under a 2% in-plane
biaxial compressive strain, the Gilbert damping of 1L {\alpha}-phase PtMnBi
thin film increases to 0.17 and the AHC reaches 2386 {\Omega}-1cm-1. The
coexistence of giant Gilbert damping and large AHC makes {\alpha}-phase PtMnBi
a compelling platform for practical spintronic applications, and highlights the
potential of half-Heusler alloys in spintronic device design.

</details>


### [359] [Accurate calculation of light rare-earth magnetic anisotropy with density functional theory](https://arxiv.org/abs/2508.19496)
*Liqin Ke,R. Flint,Y. Lee*

Main category: cond-mat.mtrl-sci

TL;DR: DFT在处理轻稀土磁性方面存在困难，原因是4f电荷非球形度被高估。本文提出了一种结合约束DFT+U、晶体场理论和电荷非球形度的多体修正的有效方法。该方法在TbV6Sn6和TbCo5上得到了验证，并成功预测了SmCo5的磁各向异性能。


<details>
  <summary>Details</summary>
Motivation: 解决密度泛函理论（DFT）在处理轻稀土磁性时遇到的困难，该困难源于4f电荷非球形度被高估。

Method: 结合约束DFT+U、晶体场理论和电荷非球形度的多体修正。

Result: 在TbV6Sn6和TbCo5上验证了该方法的有效性，并成功调整了SmCo5的磁各向异性能计算结果以匹配实验值。

Conclusion: 提出了一种有效的基于DFT的方法来解决轻稀土磁性问题。

Abstract: Density functional theory (DFT) has long struggled to treat light rare-earth
magnetism. We show that this difficulty arises from an overestimate of the $4f$
charge asphericity, and thus the magnetic anisotropy energy, due to the
inadequacy of single Slater-determinant representations. We propose an
effective solution by combining constrained DFT+U with crystal field theory and
a systematic many-body correction to the charge asphericity. We confirm the
validity of this combination on TbV$_6$Sn$_6$ and TbCo$_5$, and then show how
the many-body correction adjusts the calculated magnetic anisotropy energy of
SmCo$_5$ to match experiment. Our method is an efficient DFT-based approach to
address light-rare-earth magnetism.

</details>


### [360] [Band gap formation theory: An alternative to the Bragg diffraction model](https://arxiv.org/abs/2508.19497)
*Koichi Kajiyama*

Main category: cond-mat.mtrl-sci

TL;DR: 一维系统中布拉格衍射无法解释带隙形成，本文提出基于离散采样理论的替代性解释。


<details>
  <summary>Details</summary>
Motivation: 传统基于布拉格衍射的带隙形成理论在处理一维系统时存在缺陷，需要新的解释。尤其是在一维系统中，布拉格衍射简化为简单的干涉，无法充分说明带隙的形成。

Method: 利用薛定谔方程处理布洛赫波，将晶格视为离散观测点，引入类似奈奎斯特频率的采样约束。通过分析在固定晶格间距下电子波数变化时带隙的产生，构建包含采样效应的能量图。

Result: 发现带隙是由于波数变化和晶格离散采样共同作用产生的采样效应。能量曲线相对于奈奎斯特波数表现出平移和镜像对称性。

Conclusion: 提出了一种新颖的、符合物理原理的带隙形成解释，该理论可以自然地扩展到更高维度。

Abstract: The band gap, a key concept in solid-state physics, is traditionally
explained by the Bragg diffraction of electron waves in the periodic potential
of a crystal. Although widely accepted, this framework raises fundamental
issues in one-dimensional systems, where Bragg diffraction-which requires
multidirectional wave interactions-reduces to simple interference, thus failing
to explain band gap formation. In this paper, we introduce an alternative
theory that does not rely on Bragg reflection. Using the Schr\"{o}dinger
equation for Bloch waves, we consider the crystal lattice as a discrete set of
observation points. This discreteness introduces a sampling-like constraint
analogous to the Nyquist frequency in signal processing. We show that when the
electron wavenumber changes under a periodic potential while the lattice
spacing remains fixed, a band gap naturally emerges as a sampling effect. By
constructing an energy diagram that incorporates this effect, we reveal that
the band gap originates from both the wavenumber change and the role of the
lattice as discrete samplers, leading the energy curve to exhibit translational
and mirror symmetries with respect to the Nyquist wavenumber. This approach
provides a novel, physically grounded explanation of band gap formation and can
be naturally extended to higher dimensions.

</details>


### [361] [Multi-value Probabilistic Computing with current-controlled Skyrmion Diffusion](https://arxiv.org/abs/2508.19623)
*Thomas B. Winkler,Yuean Zhou,Grischa Beneke,Fabian Kammerbauer,Sachin Krishnia,Mario Carpentieri,Davi R. Rodrigues,Mathias Kläui,Johan H. Mentink*

Main category: cond-mat.mtrl-sci

TL;DR: Magnetic skyrmions are used for multi-value probabilistic computing (MPC), enabling applications like softmax computation and invertible logic. The system offers scalability and can be generalized for complex functions.


<details>
  <summary>Details</summary>
Motivation: To realize multi-value probabilistic computing (MPC), which is more advantageous than conventional binary probabilistic computing, by leveraging magnetic systems.

Method: Utilizing the thermally activated diffusion of magnetic skyrmions through an energy landscape defined by pinning sites. The probability distribution is tuned by current-generated spin-orbit torques and measured electrically.

Result: Demonstrated MPC with a straightforward implementation, including softmax computation and invertible logic without a network of devices. The system is scalable and can be generalized to multiple skyrmions and tunable inputs/outputs.

Conclusion: The proposed proof-of-concept using magnetic skyrmions for MPC is a significant advance, offering advantages in scalability and potential for representing complex functions, paving the way for more advanced probabilistic computing architectures.

Abstract: Magnetic systems are highly promising for implementing probabilistic
computing paradigms because of the fitting energy scales and conspicuous
non-linearities. While conventional binary probabilistic computing has been
realized, implementing more advantageous multi-value probabilistic computing
(MPC) remains a challenge. Here, we report the realization of MPC by leveraging
the thermally activated diffusion of magnetic skyrmions through an effectively
non-flat energy landscape defined by a discrete number of pinning sites. The
time-averaged spatial distribution of the diffusing skyrmions directly realizes
a discrete probability distribution, which is tunable by current-generated
spin-orbit torques, and can be quantified by non-perturbative electrical
measurements. Even a very straightforward implementation with global tuning,
already allows us to demonstrate the softmax computation - a core function in
artificial intelligence. As a key advance, we demonstrate invertible logic
without the need to create a network of probabilistic devices, offering major
scalability advantages. Our proof of concept can be generalized to multiple
skyrmions and can accommodate multiple locally tunable inputs and outputs using
magnetic tunnel junctions, potentially enabling the representation of highly
complex distribution functions.

</details>


### [362] [Atomistic insights into hydrogen migration in IGZO from machine-learning interatomic potential: linking atomic diffusion to device performance](https://arxiv.org/abs/2508.19674)
*Hyunsung Cho,Minseok Moon,Jaehoon Kim,Eunkyung Koh,Hyeon-Deuk Kim,Rokyeon Kim,Gyehyun Park,Seungwu Han,Youngho Kang*

Main category: cond-mat.mtrl-sci

TL;DR: 本文利用机器学习势分子动力学模拟研究了非晶IGZO和CAAC-IGZO中的氢扩散机制。结果表明，非晶IGZO在高温下氢扩散能力增强，且在300-400K时可在10^4秒内到达沟道/绝缘层界面，可能导致负偏压应力下的器件退化。CAAC-IGZO中的氢扩散能力受c轴方向高能垒的限制，垂直扩散受阻，对偏压不稳定性影响较小。


<details>
  <summary>Details</summary>
Motivation: 理解氢在氧化物薄膜晶体管（TFT）中的扩散对于提高器件的可靠性和性能至关重要，因为氢在载流子调制和偏压不稳定性中起着关键作用。

Method: 本文采用机器学习势分子动力学（MLIP-MD）模拟方法，构建了针对非晶IGZO（a-IGZO）和c轴取向晶体IGZO（CAAC-IGZO）的机器学习势（MLIP），并进行了氢扩散模拟。

Result: 研究结果显示，在650-1700 K的温度范围内，a-IGZO中的氢迁移率在750 K以上增强，这归因于其玻璃基质。在较低温度下，扩散受到刚性网络的限制。通过Arrhenius外推，a-IGZO中的氢在300-400 K下可在10^4秒内到达沟道/绝缘层界面，这可能导致负偏压应力下的器件退化。轨迹分析表明，a-IGZO中的长距离扩散是通过氢跳跃和翻转机制共同实现的。在CAAC-IGZO中，氢的平面内扩散能力很强，但由于c轴方向存在高能垒，其平面外扩散受到严重限制，这表明其对偏压不稳定性影响很小。

Conclusion: 该研究通过大规模MLIP-MD模拟，将原子层面的氢传输机制与氧化物TFT器件层面的性能联系起来，为理解和改善TFT器件性能提供了新的视角。

Abstract: Understanding hydrogen diffusion is critical for improving the reliability
and performance of oxide thin-film transistors (TFTs), where hydrogen plays a
key role in carrier modulation and bias instability. In this work, we
investigate hydrogen diffusion in amorphous IGZO ($a$-IGZO) and $c$-axis
aligned crystalline IGZO (CAAC-IGZO) using machine learning interatomic
potential molecular dynamics (MLIP-MD) simulations. We construct accurate
phase-specific MLIPs by fine-tuning SevenNet-0, a universal pretrained MLIP,
and validate the models against a comprehensive dataset covering
hydrogen-related configurations and diffusion environments. Hydrogen
diffusivity is evaluated over 650--1700 K, revealing enhanced mobility above
750 K in $a$-IGZO due to the glassy matrix, while diffusion at lower
temperatures is constrained by the rigid network. Arrhenius extrapolation of
the diffusivity indicates that hydrogen in $a$-IGZO can reach the
channel/insulator interface within $10^{4}$ seconds at 300--400 K, likely
contributing to negative bias stress-induced device degradation. Trajectory
analysis reveals that long-range diffusion in $a$-IGZO is enabled by a
combination of hydrogen hopping and flipping mechanisms. In CAAC-IGZO, hydrogen
exhibits high in-plane diffusivity but severely restricted out-of-plane
transport due to a high energy barrier along the $c$-axis. This limited
vertical diffusion in CAAC-IGZO suggests minimal impact on bias instability.
This work bridges the atomic-level hydrogen transport mechanism and
device-level performance in oxide TFTs by leveraging large-scale MLIP-MD
simulations.

</details>


### [363] [MnBr$_2$ on the graphene on Ir(110) substrate: growth, structure, and super-moiré](https://arxiv.org/abs/2508.19694)
*Affan Safeer,Oktay Güleryüz,Nicolae Atodiresei,Wouter Jolie,Thomas Michely,Jeison Fischer*

Main category: cond-mat.mtrl-sci

TL;DR: 在 Ir(110) 衬底上的石墨烯上生长单层 MnBr2，通过低能电子衍射、扫描隧道显微镜和光谱学进行研究。 MnBr2 在 Gr/Ir(110) 上的生长形成三晶格系统，产生超莫尔条纹。 ab initio 计算有助于理解超莫尔条纹的形成。


<details>
  <summary>Details</summary>
Motivation: 研究单层 MnBr2 在石墨烯/Ir(110) 衬底上的生长结构、外延关系和电子特性，特别是超莫尔条纹的形成机制。

Method: 使用低能电子衍射 (LEED)、扫描隧道显微镜 (STM) 和光谱学 (STS) 研究了在 Ir(110) 衬底上的石墨烯上生长的 MnBr2。 此外，还进行了 ab initio 计算来解释观测到的现象。

Result: MnBr2 的生长形态随生长温度变化，从分形到树枝状，最终形成致密的树枝状骨架岛。 MnBr2/Gr/Ir(110) 系统形成了一个三晶格系统，产生了超莫尔条纹。 "虚拟" 莫尔条纹也对超莫尔条纹的形成做出了贡献。 通过测量电子结构解释了磁绝缘体表观高度的显著变化。

Conclusion: 单层 MnBr2 在 Gr/Ir(110) 上的生长表现出复杂的结构和电子特性，包括超莫尔条纹的形成。 生长行为和电子性质可以通过实验技术和理论计算相结合来理解。

Abstract: Single-layer MnBr$_2$ is grown on graphene (Gr) supported by Ir(110) and
investigated using low-energy electron diffraction, scanning tunneling
microscopy, and spectroscopy. The structure and epitaxial relationship with the
substrate are systematically characterized. The growth morphology strongly
depends on the growth temperature, evolving from fractal to dendritic and
eventually to compact dendritic skeletal islands, reflecting changes in the
underlying surface diffusion processes. MnBr$_2$ on Gr/Ir(110) constitutes a
three-lattice system, giving rise to a super-moir\'e pattern --a moir\'e of
moir\'es. Due to the involvement of lattices of differing symmetries and the
partial electronic transparency of Gr, a "virtual" moir\'e formed by MnBr$_2$
and Ir(110) contributes to the super-moir\'e formation. Ab initio calculations
play a crucial role in understanding the complexity of super-moir\'e. Moreover,
the pronounced variation in the apparent height with tunneling conditions for
the magnetic insulator is explained based on the measured electronic structure.

</details>


### [364] [Kinetic pathways of coesite densification from metadynamics](https://arxiv.org/abs/2508.19716)
*David Vrba,Roman Martoňák*

Main category: cond-mat.mtrl-sci

TL;DR: 在35 GPa以上研究二氧化矽的壓縮，遠超其轉變為八面體相的平衡壓力（8 GPa至二氧化矽）。在室溫下，高達30 GPa時，亞穩態二氧化矽結構僅發生微小的置換變化（二氧化矽-II和二氧化矽-III），而矽原子仍保持4配位。超過30 GPa後，開始發生重建轉換，從二氧化矽的複雜結構遵循不同的路徑。除了非晶化，還觀察到兩種不同的結晶結果：一種是形成缺陷的八面體高壓相（Hu et al., 2015），另一種是形成具有4配位、5配位和6配位矽原子的不尋常且複雜的緻密相二氧化矽-IV和二氧化矽-V（Byakes et al., 2018）。理論上捕捉這些結構轉變是一個挑戰。本研究表明，在結合了基於機器學習的ACE勢能（Erhard et al., 2024）的元動力學方法中，使用Si-O配位數和體積作為通用 عليه變數，可以自然地觀察到上述所有三種路徑，並產生實驗觀察到的相。我們描述了轉變路徑中的原子機制。雖然二氧化矽-IV的路徑較為簡單，但轉變為八面體相涉及兩個步驟：首先，形成氧原子的hcp子晶格，其中矽原子佔據八面體位置，但八面體鏈不形成規則的圖案。第二步，矽原子有序化，鏈條的排列變得更加規則。我們預測在室溫下二氧化矽-IV的路徑更受青睞，而在600 K時，八面體相的形成更為可能。


<details>
  <summary>Details</summary>
Motivation: 研究在遠超平衡壓力下二氧化矽的壓縮行為，並理論上解釋其轉變機制。

Method: 結合元動力學方法、Si-O配位數和體積作為 عليه變數，以及基於機器學習的ACE勢能。

Result: 理論上成功再現了二氧化矽在壓力下的非晶化、二氧化矽-IV/V相以及八面體相的形成路徑，並詳細描述了原子機制。預測了不同溫度下不同相的形成偏好。

Conclusion: 在遠超平衡壓力下，二氧化矽的壓縮會經歷複雜的結構轉變，通過結合先進的理論計算方法可以有效地模擬這些過程，並預測不同溫度下的相變行為。

Abstract: We study compression of coesite to pressures above 35 GPa, substantially
beyond the equilibrium transition pressure to octahedral phases (8 GPa to
stishovite). Experiments at room temperature showed that up to 30 GPa the
metastable coesite structure develops only minor displacive changes (coesite-II
and coesite-III) while the Si atoms remain 4-coordinated. Beyond 30 GPa,
reconstructive transformations start, following different pathways from the
complex structure of coesite. Besides amorphization, two different crystalline
outcomes were observed. One is formation of defective high-pressure octahedral
phases (Hu et al., 2015) and another one is formation of unusual and complex
dense phases coesite-IV and coesite-V with Si atoms in 4-fold, 5-fold and
6-fold coordination (Bykova et al., 2018). Capturing these structural
transformations computationally represents a challenge. Here we show that
employing metadynamics with Si-O coordination number and volume as generic
collective variables in combination with a machine-learning based ACE potential
(Erhard et al., 2024), one naturally observes all three mentioned pathways,
resulting in the phases observed experimentally. We describe the atomistic
mechanisms along the transformation pathways. While the pathway to coesite-IV
is simpler, the transformation to octahedral phases involves two steps: first,
a hcp sublattice of O atoms is formed where Si atoms occupy octahedral
positions but the octahedra chains do not form a regular pattern. In the second
step, the Si atoms order and the chains develop a more regular arrangement. We
predict that the pathway to coesite-IV is preferred at room temperature, while
at 600 K the formation of octahedral phases is more likely.

</details>


### [365] [Emissive perovskite quantum wires in robust nanocontainers](https://arxiv.org/abs/2508.19833)
*Bea Botka,Erzsébet Dodony,Ildikó Harsányi,Michael Stratton,János Mózer,Éva Kováts,Katalin Kamarás*

Main category: cond-mat.mtrl-sci

TL;DR: BNNTs filled with perovskites create tunable, polarized light-emitting wires with enhanced stability for photonic devices.


<details>
  <summary>Details</summary>
Motivation: The paper aims to create stable, color-tunable, and polarized light-emissive nanostructures using boron nitride nanotubes (BNNTs) filled with inorganic lead halide perovskites for potential applications in nanoscale photonic devices.

Method: BNNTs were used as a host material to synthesize high aspect ratio perovskite quantum wires. The BNNTs provide a protective shell around the perovskite nanowires, which are optically transparent, thus mitigating degradation during post-processing while retaining the emission properties of the perovskites. The diameter of the quantum wires could be controlled by selecting different BNNT hosts, allowing access to the quantum confinement regime.

Result: This method resulted in perovskite quantum wires encapsulated within BNNTs, exhibiting color-tunable and highly polarized emission. The BNNT shell significantly improved the stability of the perovskite nanostructures, making them suitable for practical applications. The ability to tune the wire diameter allowed for control over quantum confinement effects.

Conclusion: The research successfully demonstrated that BNNTs can serve as an effective platform for creating robust and optically functional perovskite quantum wires. These nanostructures are promising building blocks for advanced nanoscale photonic devices and flexible optical assemblies due to their tunable emission, polarization, and enhanced stability.

Abstract: Light emissive nanostructures were prepared from boron nitride nanotubes
(BNNTs) filled with inorganic lead halide perovskites. BNNTs provide a platform
for facile synthesis of high aspect ratio perovskite quantum wires having
color-tunable, highly polarized emission. BNNTs form a flexible and robust
protective shell around individual nanowires, that mitigate degradation during
post-processing for practical applications, while allowing to exploit the
emission of the perovskite nanowires due to its optical transparency. The wire
diameter can be tuned by choosing appropriate BNNT hosts, giving easy access to
the strongly quantum confined diameter range. The individual encapsulated
quantum wires can be used as building blocks for nanoscale photonic devices,
and to create large-scale flexible assemblies.

</details>


### [366] [Microscale optoelectronic reservoir networks of halide perovskite for in-sensor computing](https://arxiv.org/abs/2508.19916)
*Jeroen J. de Boer,Agustin O. Alvarez,Moritz C. Schmidt,Bruno Ehrler*

Main category: cond-mat.mtrl-sci

TL;DR: 基于卤化物钙钛矿半导体的多模态光电器件水库网络，可处理电压和光输入，用于手写数字和视频分类。


<details>
  <summary>Details</summary>
Motivation: 开发高效的神经形态和近传感器计算应用。

Method: 构建基于MAPbI3钙钛矿薄膜的微米级不对称交叉结构水库网络，处理4位电压和光信号，并训练线性读取层进行分类。

Result: 图像和视频分类的平均准确率分别达到95.3%和87.8%，且仅有轻微的测量噪声劣化。与线性分类器相比，性能分别提升3.1%和14.6%。

Conclusion: 该多模态水库网络在图像和视频分类任务中表现出色，优于传统方法。延长保持时间有利于提高分类精度，并提供了选择最佳实验参数的指导。其微型器件结构适合高密度传感器阵列，是高效传感器内计算的理想选择。

Abstract: Physical reservoir computing is a promising framework for efficient
neuromorphic in and near-sensor computing applications. Here, we demonstrate a
multimodal optoelectronic reservoir network based on halide perovskite
semiconductor devices, capable of processing both voltage and light inputs. The
devices consist of micrometer-sized, asymmetric crossbars covered with a MAPbI3
perovskite film. In a network, we simulate the performance by transforming
MNIST images and videos based on the NMNIST dataset using 4-bit inputs and
training linear readout layers for classification. We demonstrate multimodal
networks capable of processing both voltage and light inputs, reaching mean
accuracies up to 95.3 p/m 0.1% and 87.8 p/m 0.1% for image and video
classification, respectively. We observed only minor deterioration due to
measurement noise. The networks significantly outperformed linear classifier
references, by 3.1% for images and 14.6% for video. We show that longer
retention times benefit classification accuracy for single-mode networks, and
give guidelines for choosing optimal experimental parameters. Moreover, the
microscale device architecture lends itself well to further downscaling in
high-density sensor arrays, making the devices ideal for efficient in-sensor
computing.

</details>


### [367] [Nanoscale mechanics and ultralow Friction of natural 2D silicates: Biotite and Rhodonite](https://arxiv.org/abs/2508.19938)
*Surbhi Slathia,Manoj Tripathi,Raphael Benjamim de Oliveira,Guilherme da Silva Lopes Fabris,Bruno Ipaves,Raphael Matozo Tromer,Marcelo Lopes Pereira Junior,Gelu Costin,Preeti Lata Mahapatraa,Nicholas R. Glavin,Ajit K. Roy,Venkataramana Gadhamshetty,Douglas Soares Galvao,Alan Dalton,Chandra Sekhar Tiwary*

Main category: cond-mat.mtrl-sci

TL;DR: 二维硅酸盐在机械和摩擦学方面展现出应用潜力，但其性能与厚度关系尚不明确。本研究使用原子力显微镜和密度泛函理论，比较了云母和 rodhonite 两种二维硅酸盐的力学和摩擦学特性，发现 rodhonite 具有更高的附着力和模量，而云母的摩擦性能更优越。


<details>
  <summary>Details</summary>
Motivation: 明确二维硅酸盐的厚度依赖性机械性能对于其在传感器、柔性电子、药物递送和催化等领域的应用至关重要。

Method: 利用原子力显微镜（AFM）研究了层状云母和链状 rodhonite 两种二维硅酸盐的纳米力学和摩擦行为。结合密度泛函理论（DFT）计算（包含 Hubbard 修正）来深入探究层间附着力。

Result: 原子力显微镜结果显示，rodhonite 的附着力和模量响应是云母的近十倍。然而，在摩擦性能方面，云母表现更优，其超薄（5 nm）薄片的摩擦系数（约 0.6 x 10^-3）远低于 rodhonite（约 3.6 x 10^-3）。

Conclusion: 本研究为设计和选择用于先进机械和摩擦学应用的二维硅酸盐提供了宝贵的见解。

Abstract: Two-dimensional (2D) silicates have emerged as a promising class of ultrathin
materials, expanding the landscape of 2D systems beyond conventional van der
Waals crystals. Their unique crystal chemistries and structural anisotropies
make them attractive for applications ranging from sensors and flexoelectric
devices to drug delivery and catalysis. To unlock their full potential, it is
critical to understand their thickness-dependent mechanical properties within
the family of 2D silicates. In this study, we investigate the nanomechanical
and frictional behaviors of two structurally distinct natural silicates:
layered Biotite and chain-structured Rhodonite. Using atomic force microscopy
(AFM), we found that Rhodonite exhibits nearly ten times higher adhesion force
and modulus response compared to Biotite. Despite this, Biotite demonstrates
superior frictional performance, with ultrathin (5 nm) flakes showing a
remarkably low coefficient of friction ($\sim 0.6 \times 10^{-3}$) versus
Rhodonite ($\sim 3.6 \times 10^{-3}$). To further elucidate interlayer
adhesion, density functional theory (DFT) calculations with Hubbard correction
were employed. These findings offer valuable insights into the design and
selection of 2D silicates for advanced mechanical and tribological
applications.

</details>


### [368] [Unlocking Doping Effects on Altermagnetism in MnTe](https://arxiv.org/abs/2508.19969)
*Nayana Devaraj,Anumita Bose,Arindom Das,Md Afsar Reja,Arijit Mandal,Awadhesh Narayan,B. R. K. Nanda*

Main category: cond-mat.mtrl-sci

TL;DR: New research on altermagnetism in MnTe, exploring defect impacts and potential applications like tailored anomalous Hall conductivity.


<details>
  <summary>Details</summary>
Motivation: Investigate the effects of defects on altermagnetism in MnTe, focusing on symmetry breaking and its influence on spin-split bands and anomalous Hall conductivity (AHC).

Method: Utilized density functional theory calculations, symmetry analysis, and model studies on a configuration space of MnTe with substitutional doping to create various spin space groups.

Result: Demonstrated the generic presence of spin-split antiferromagnetic bands in momentum space for MnTe with defects, indicating a broader class of quasi-altermagnetic materials. Showed that doping MnTe can induce finite and varied AHC, unlike the pristine material.

Conclusion: The study predicts the existence of quasi-altermagnetism and highlights the potential for doping to control AHC in MnTe, opening new avenues for research and applications in the field of altermagnetism.

Abstract: Governed by specific symmetries, altermagnetism is an emerging field in
condensed matter physics, characterized by unique spin-splitting of the bands
in the momentum space co-existing with the compensated magnetization as in
antiferromagnets. As crystals can have tailored and unintended defects, it is
important to gain insights on how altermagnets are affected by the
defects-driven symmetry-breaking which, in turn, can build promising
perspectives on potential applications. In this study, considering the widely
investigated MnTe as a prototype altermagnet, defects are introduced through
substitutional doping to create a large configuration space of spin space
groups. With the aid of density functional theory calculations, symmetry
analysis, and model studies in this configuration space, we demonstrate the
generic presence of spin-split of the antiferromagnetic bands in the momentum
space. This is indicative of a wider class of quasi-altermagnetic materials,
augmenting the set of ideal altermagnetic systems. Furthermore, we show that
while pristine MnTe does not show anomalous Hall conductivity (AHC) with
out-of-plane magnetization, suitable doping can be carried out to obtain finite
and varied AHC. Our predictions of quasi-altermagnetism and doping driven
tailored AHC have the potential to open up as-yet-unexplored directions in this
developing field.

</details>
