<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 141]
- [cs.CL](#cs.CL) [Total: 86]
- [cs.NE](#cs.NE) [Total: 5]
- [cond-mat.mes-hall](#cond-mat.mes-hall) [Total: 16]
- [cs.LG](#cs.LG) [Total: 128]
- [cs.ET](#cs.ET) [Total: 3]
- [cs.LO](#cs.LO) [Total: 9]
- [cs.RO](#cs.RO) [Total: 43]
- [cond-mat.mtrl-sci](#cond-mat.mtrl-sci) [Total: 36]
- [cs.AI](#cs.AI) [Total: 59]
- [cs.GT](#cs.GT) [Total: 6]
- [cs.AR](#cs.AR) [Total: 7]
- [eess.SP](#eess.SP) [Total: 58]
- [quant-ph](#quant-ph) [Total: 61]
- [cs.MA](#cs.MA) [Total: 4]
- [cs.GR](#cs.GR) [Total: 7]
- [eess.SY](#eess.SY) [Total: 31]
- [cs.DS](#cs.DS) [Total: 15]
- [cs.DC](#cs.DC) [Total: 10]
- [physics.app-ph](#physics.app-ph) [Total: 6]
- [cs.SI](#cs.SI) [Total: 6]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [Comparative Analysis of Algorithms for the Fitting of Tessellations to 3D Image Data](https://arxiv.org/abs/2507.14268)
*Andreas Alpers,Orkun Furat,Christian Jung,Matthias Neumann,Claudia Redenbach,Aigerim Saken,Volker Schmidt*

Main category: cs.CV

TL;DR: 本研究对用于材料三维图像数据的镶嵌模型算法进行了比较分析，评估了多种优化方法，并为选择合适方法提供了指导。


<details>
  <summary>Details</summary>
Motivation: 本研究旨在对用于拟合晶体和泡沫等材料的三维图像数据的镶嵌模型算法策略进行比较分析。

Method: 本研究回顾并评估了用于生成Voronoi、Laguerre和广义平衡幂图（GBPD）以近似基于体素的晶粒结构的优化方法，包括线性规划、非线性规划、通过交叉熵方法进行的随机优化和梯度下降。

Result: 本研究的结果强调了模型复杂性、优化例程复杂性和近似质量之间的权衡，并根据数据特性和应用需求为选择合适的方法提供了指导。

Conclusion: 本研究对用于拟合晶粒和泡沫等材料的3D图像数据的镶嵌模型的算法策略进行了比较分析。评估了包括线性规划、非线性规划、交叉熵方法随机优化和梯度下降等基于优化的方法，用于生成近似基于体素的晶粒结构的Voronoi、Laguerre和广义平衡幂图（GBPD）。在真实数据集上使用差异度量评估拟合质量，这些度量量化了晶粒体积、表面积和拓扑结构的差异。结果强调了模型复杂性、所涉及的优化例程复杂性以及近似质量之间的权衡，为根据数据特性和应用需求选择合适的方法提供了指导。

Abstract: This paper presents a comparative analysis of algorithmic strategies for
fitting tessellation models to 3D image data of materials such as polycrystals
and foams. In this steadily advancing field, we review and assess
optimization-based methods -- including linear and nonlinear programming,
stochastic optimization via the cross-entropy method, and gradient descent --
for generating Voronoi, Laguerre, and generalized balanced power diagrams
(GBPDs) that approximate voxelbased grain structures. The quality of fit is
evaluated on real-world datasets using discrepancy measures that quantify
differences in grain volume, surface area, and topology. Our results highlight
trade-offs between model complexity, the complexity of the optimization
routines involved, and the quality of approximation, providing guidance for
selecting appropriate methods based on data characteristics and application
needs.

</details>


### [2] [Semantic Segmentation based Scene Understanding in Autonomous Vehicles](https://arxiv.org/abs/2507.14303)
*Ehsan Rassekh*

Main category: cs.CV

TL;DR: 该研究提出并评估了几种用于自动驾驶车辆的语义分割模型，重点是骨干网络的选择，并取得了改进的性能指标。


<details>
  <summary>Details</summary>
Motivation: 随着人工智能（AI）和深度学习（DL）在解决复杂任务和在关键情况下做出正确决策方面的潜力日益显现，这项工作旨在通过语义分割来改进场景理解。

Method: 提出了几种有效的模型来通过语义分割研究场景理解，并使用 BDD100k 数据集进行研究。此外，还使用了几种骨干网络作为模型的编码器。

Result: 所提出的模型在 BDD100k 数据集上进行了评估，结果表明选择合适的骨干网络对模型的语义分割性能有很大影响，并且所提出的指标（准确性、平均 IoU 和损失函数）均得到改善。

Conclusion: 所提出的模型在准确性、平均 IoU 和损失函数方面得到了改进，提高了语义分割的性能，从而更好地理解场景和周围环境。

Abstract: In recent years, the concept of artificial intelligence (AI) has become a
prominent keyword because it is promising in solving complex tasks. The need
for human expertise in specific areas may no longer be needed because machines
have achieved successful results using artificial intelligence and can make the
right decisions in critical situations. This process is possible with the help
of deep learning (DL), one of the most popular artificial intelligence
technologies. One of the areas in which the use of DL is used is in the
development of self-driving cars, which is very effective and important. In
this work, we propose several efficient models to investigate scene
understanding through semantic segmentation. We use the BDD100k dataset to
investigate these models. Another contribution of this work is the usage of
several Backbones as encoders for models. The obtained results show that
choosing the appropriate backbone has a great effect on the performance of the
model for semantic segmentation. Better performance in semantic segmentation
allows us to understand better the scene and the environment around the agent.
In the end, we analyze and evaluate the proposed models in terms of accuracy,
mean IoU, and loss function, and the results show that these metrics are
improved.

</details>


### [3] [CLIPTTA: Robust Contrastive Vision-Language Test-Time Adaptation](https://arxiv.org/abs/2507.14312)
*Marc Lafon,Gustavo Adolfo Vargas Hakim,Clément Rambour,Christian Desrosier,Nicolas Thome*

Main category: cs.CV

TL;DR: CLIPTTA是一种用于视觉-语言模型的测试时自适应方法，它通过软对比损失克服了现有方法的局限性，并在各种分布变化下表现出优越且稳定的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的测试时自适应方法（如熵最小化）与视觉-语言模型的对比学习目标不一致，导致性能受限并出现伪标签漂移和类别坍塌等问题。

Method: CLIPTTA是一种新的基于梯度的测试时自适应方法，利用软对比损失来适应视觉-语言模型。它通过批次感知设计来缓解坍塌风险，并通过海洋损失扩展到开放集设置，以改进OOD检测。

Result: CLIPTTA在各种分布变化下表现出稳定的性能，并且在许多数据集上优于最先进的测试时自适应方法。

Conclusion: CLIPTTA在75个跨分布变化的数据集上进行评估，其性能持续优于基于熵的目标，并且与最先进的测试时自适应方法相比具有高度竞争力，在大量数据集上表现更优，并在跨多样化分布变化方面表现出更稳定的性能。

Abstract: Vision-language models (VLMs) like CLIP exhibit strong zero-shot capabilities
but often fail to generalize under distribution shifts. Test-time adaptation
(TTA) allows models to update at inference time without labeled data, typically
via entropy minimization. However, this objective is fundamentally misaligned
with the contrastive image-text training of VLMs, limiting adaptation
performance and introducing failure modes such as pseudo-label drift and class
collapse. We propose CLIPTTA, a new gradient-based TTA method for
vision-language models that leverages a soft contrastive loss aligned with
CLIP's pre-training objective. We provide a theoretical analysis of CLIPTTA's
gradients, showing how its batch-aware design mitigates the risk of collapse.
We further extend CLIPTTA to the open-set setting, where both in-distribution
(ID) and out-of-distribution (OOD) samples are encountered, using an Outlier
Contrastive Exposure (OCE) loss to improve OOD detection. Evaluated on 75
datasets spanning diverse distribution shifts, CLIPTTA consistently outperforms
entropy-based objectives and is highly competitive with state-of-the-art TTA
methods, outperforming them on a large number of datasets and exhibiting more
stable performance across diverse shifts.

</details>


### [4] [A Hidden Stumbling Block in Generalized Category Discovery: Distracted Attention](https://arxiv.org/abs/2507.14315)
*Qiyu Xu,Zhanxuan Hu,Yu Duan,Ercheng Pei,Yonghang Tai*

Main category: cs.CV

TL;DR: AF是一种新的注意力机制，通过剪枝非信息性令牌来解决GCD中的‘注意力分散’问题，能显著提升现有GCD方法的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的GCD方法在处理无标签数据时，模型倾向于关注任务无关的背景区域，导致特征提取不佳，即‘注意力分散’问题。为了解决这个问题，提出AF机制来提升模型注意力。

Method: AF包括两个组件：令牌重要性度量（TIME）和令牌自适应剪枝（TAP）。TIME在多个尺度上量化令牌的重要性，而TAP则利用TIME提供的多尺度重要性分数来剪枝非信息性令牌。

Result: AF在SimGCD上实现了高达15.4%的性能提升，计算开销极小。

Conclusion: AF是一个轻量级的、即插即用的模块，可以无缝集成到现有的GCD方法中，计算开销极小。与SimGCD结合使用时，AF在计算开销极小的情况下，性能比基线提高了15.4%。

Abstract: Generalized Category Discovery (GCD) aims to classify unlabeled data from
both known and unknown categories by leveraging knowledge from labeled known
categories. While existing methods have made notable progress, they often
overlook a hidden stumbling block in GCD: distracted attention. Specifically,
when processing unlabeled data, models tend to focus not only on key objects in
the image but also on task-irrelevant background regions, leading to suboptimal
feature extraction. To remove this stumbling block, we propose Attention
Focusing (AF), an adaptive mechanism designed to sharpen the model's focus by
pruning non-informative tokens. AF consists of two simple yet effective
components: Token Importance Measurement (TIME) and Token Adaptive Pruning
(TAP), working in a cascade. TIME quantifies token importance across multiple
scales, while TAP prunes non-informative tokens by utilizing the multi-scale
importance scores provided by TIME. AF is a lightweight, plug-and-play module
that integrates seamlessly into existing GCD methods with minimal computational
overhead. When incorporated into one prominent GCD method, SimGCD, AF achieves
up to 15.4% performance improvement over the baseline with minimal
computational overhead. The implementation code is provided in
https://github.com/Afleve/AFGCD.

</details>


### [5] [Hallucination Score: Towards Mitigating Hallucinations in Generative Image Super-Resolution](https://arxiv.org/abs/2507.14367)
*Weiming Ren,Raghav Goyal,Zhiming Hu,Tristan Ty Aumentado-Armstrong,Iqbal Mohomed,Alex Levinshtein*

Main category: cs.CV

TL;DR: 本研究提出了一种新的“幻觉评分”（HS）方法，使用大语言模型来评估超分辨率图像的生成细节是否与原始图像匹配，发现HS与人类评价一致，并提出用深度特征来优化模型以减少“幻觉”。


<details>
  <summary>Details</summary>
Motivation: 当前最先进的生成式超分辨率（GSR）模型虽然在感知图像质量上表现优异，但存在一个关键问题：生成的内容有时与低分辨率图像（LRI）或地面真实图像（GTI）在感知上不匹配，即“幻觉”现象。这种现象影响了模型的实际部署和用户体验。然而，现有的图像评估指标和质量模型无法有效捕捉或量化这种“幻觉”，因为它们与图像的保真度或无参考质量是正交的。因此，有必要开发新的方法来衡量、分析和减轻这种“幻觉”问题。

Method: 本研究提出了一种利用多模态大语言模型（MLLM）来评估和量化生成式超分辨率（GSR）“幻觉”问题的新方法。通过设计特定的提示（prompt），MLLM能够生成一个“幻觉评分”（HS），该评分能够准确反映人类对生成图像细节与原始图像（LRI或GTI）的感知匹配程度。此外，研究还探索了深度特征距离与HS之间的相关性，并提出了一种基于这些特征的、可微分的奖励函数，用于在模型训练过程中直接优化GSR模型，以减轻幻觉的产生。

Result: 研究结果表明，所提出的“幻觉评分”（HS）与人类评估结果高度吻合，并且能够提供比现有超分辨率（SR）模型评估指标更具互补性的见解。此外，研究发现特定的深度特征距离与HS之间存在很强的相关性。基于这一发现，研究提出了一种将GSR模型进行对齐的方法，利用这些深度特征作为可微分的奖励函数，从而有效减轻“幻觉”问题。

Conclusion: 虽然生成式超分辨率（GSR）在感知图像质量方面取得了最先进的成果，但其生成细节与低分辨率图像（LRI）或地面真实图像（GTI）在感知上不匹配的“幻觉”问题，限制了其在实际中的应用。本研究提出了一种基于多模态大语言模型（MLLM）的“幻觉评分”（HS）指标，该指标与人类评估高度一致，并能提供比现有图像指标更深入的洞察。此外，研究还发现某些深度特征距离与HS高度相关，可用于优化GSR模型以减轻幻觉。

Abstract: Generative super-resolution (GSR) currently sets the state-of-the-art in
terms of perceptual image quality, overcoming the "regression-to-the-mean" blur
of prior non-generative models. However, from a human perspective, such models
do not fully conform to the optimal balance between quality and fidelity.
Instead, a different class of artifacts, in which generated details fail to
perceptually match the low resolution image (LRI) or ground-truth image (GTI),
is a critical but under studied issue in GSR, limiting its practical
deployments. In this work, we focus on measuring, analyzing, and mitigating
these artifacts (i.e., "hallucinations"). We observe that hallucinations are
not well-characterized with existing image metrics or quality models, as they
are orthogonal to both exact fidelity and no-reference quality. Instead, we
take advantage of a multimodal large language model (MLLM) by constructing a
prompt that assesses hallucinatory visual elements and generates a
"Hallucination Score" (HS). We find that our HS is closely aligned with human
evaluations, and also provides complementary insights to prior image metrics
used for super-resolution (SR) models. In addition, we find certain deep
feature distances have strong correlations with HS. We therefore propose to
align the GSR models by using such features as differentiable reward functions
to mitigate hallucinations.

</details>


### [6] [DUSTrack: Semi-automated point tracking in ultrasound videos](https://arxiv.org/abs/2507.14368)
*Praneeth Namburi,Roger Pallarès-López,Jessica Rosendorf,Duarte Folgado,Brian W. Anthony*

Main category: cs.CV

TL;DR: DUSTrack是一个结合深度学习和光流法的超声追踪工具，能准确追踪组织运动，并提供易用的界面和优化的追踪性能。


<details>
  <summary>Details</summary>
Motivation: 准确追踪B模式超声图像中的组织运动具有挑战性，因为散斑噪声、低边缘对比度和平面外运动会影响解剖标志点的追踪，而这对于量化组织动态至关重要。

Method: DUSTrack结合了深度学习和光流法，并通过图形用户界面简化了训练数据的生成和模型的迭代优化，同时采用了一种新颖的光流法滤波技术来减少噪声并保留快速的组织运动。

Result: DUSTrack在零样本点追踪方面表现出优越的准确性，并且在特定方法方面表现相当，证明了其作为通用基础工具的潜力。

Conclusion: DUSTrack是一个强大而灵活的开源框架，用于从超声视频中追踪点和量化组织运动，在临床和生物力学研究中具有巨大潜力。

Abstract: Ultrasound technology enables safe, non-invasive imaging of dynamic tissue
behavior, making it a valuable tool in medicine, biomechanics, and sports
science. However, accurately tracking tissue motion in B-mode ultrasound
remains challenging due to speckle noise, low edge contrast, and out-of-plane
movement. These challenges complicate the task of tracking anatomical landmarks
over time, which is essential for quantifying tissue dynamics in many clinical
and research applications. This manuscript introduces DUSTrack (Deep learning
and optical flow-based toolkit for UltraSound Tracking), a semi-automated
framework for tracking arbitrary points in B-mode ultrasound videos. We combine
deep learning with optical flow to deliver high-quality and robust tracking
across diverse anatomical structures and motion patterns. The toolkit includes
a graphical user interface that streamlines the generation of high-quality
training data and supports iterative model refinement. It also implements a
novel optical-flow-based filtering technique that reduces high-frequency
frame-to-frame noise while preserving rapid tissue motion. DUSTrack
demonstrates superior accuracy compared to contemporary zero-shot point
trackers and performs on par with specialized methods, establishing its
potential as a general and foundational tool for clinical and biomechanical
research. We demonstrate DUSTrack's versatility through three use cases:
cardiac wall motion tracking in echocardiograms, muscle deformation analysis
during reaching tasks, and fascicle tracking during ankle plantarflexion. As an
open-source solution, DUSTrack offers a powerful, flexible framework for point
tracking to quantify tissue motion from ultrasound videos. DUSTrack is
available at https://github.com/praneethnamburi/DUSTrack.

</details>


### [7] [CRAFT: A Neuro-Symbolic Framework for Visual Functional Affordance Grounding](https://arxiv.org/abs/2507.14426)
*Zhou Chen,Joe Lin,Sathyanarayanan N. Aakur*

Main category: cs.CV

TL;DR: CRAFT is a neuro-symbolic framework for interpretable affordance grounding that uses commonsense priors and visual evidence with an energy-based reasoning loop to identify objects enabling actions, improving accuracy and interpretability in scene understanding.


<details>
  <summary>Details</summary>
Motivation: To introduce a neuro-symbolic framework for interpretable affordance grounding, which identifies the objects in a scene that enable a given action (e.g., "cut").

Method: CRAFT integrates structured commonsense priors from ConceptNet and language models with visual evidence from CLIP, using an energy-based reasoning loop to refine predictions iteratively.

Result: Experiments in multi-object, label-free settings demonstrate that CRAFT enhances accuracy while improving interpretability.

Conclusion: CRAFT enhances accuracy while improving interpretability, providing a step toward robust and trustworthy scene understanding.

Abstract: We introduce CRAFT, a neuro-symbolic framework for interpretable affordance
grounding, which identifies the objects in a scene that enable a given action
(e.g., "cut"). CRAFT integrates structured commonsense priors from ConceptNet
and language models with visual evidence from CLIP, using an energy-based
reasoning loop to refine predictions iteratively. This process yields
transparent, goal-driven decisions to ground symbolic and perceptual
structures. Experiments in multi-object, label-free settings demonstrate that
CRAFT enhances accuracy while improving interpretability, providing a step
toward robust and trustworthy scene understanding.

</details>


### [8] [Adaptive 3D Gaussian Splatting Video Streaming](https://arxiv.org/abs/2507.14432)
*Han Gong,Qiyue Li,Zhi Liu,Hao Zhou,Peng Yuan Zhou,Zhu Li,Jie Li*

Main category: cs.CV

TL;DR: 提出了一种新的3DGS视频流传输框架，通过基于高斯变形场的方法和混合显著性切片、差异化质量模型，实现了高效压缩和高质量传输，优于现有技术。


<details>
  <summary>Details</summary>
Motivation: 为了解决3DGS视频流传输面临的数据量大、压缩和传输复杂性高等挑战。

Method: 提出了一种基于高斯变形场的三维高斯喷溅（3DGS）视频构建方法，并结合混合显著性切片和差异化质量模型，实现了高效的数据压缩和带宽波动适应性。

Result: 实验评估验证了所提出方法的优越性，其在视频质量、压缩效率和传输速率方面均表现出色。

Conclusion: 该研究提出的3DGS视频流传输框架在视频质量、压缩效率和传输速率方面均优于现有方法。

Abstract: The advent of 3D Gaussian splatting (3DGS) has significantly enhanced the
quality of volumetric video representation. Meanwhile, in contrast to
conventional volumetric video, 3DGS video poses significant challenges for
streaming due to its substantially larger data volume and the heightened
complexity involved in compression and transmission. To address these issues,
we introduce an innovative framework for 3DGS volumetric video streaming.
Specifically, we design a 3DGS video construction method based on the Gaussian
deformation field. By employing hybrid saliency tiling and differentiated
quality modeling of 3DGS video, we achieve efficient data compression and
adaptation to bandwidth fluctuations while ensuring high transmission quality.
Then we build a complete 3DGS video streaming system and validate the
transmission performance. Through experimental evaluation, our method
demonstrated superiority over existing approaches in various aspects, including
video quality, compression effectiveness, and transmission rate.

</details>


### [9] [IRGPT: Understanding Real-world Infrared Image with Bi-cross-modal Curriculum on Large-scale Benchmark](https://arxiv.org/abs/2507.14449)
*Zhe Cao,Jin Zhang,Ruiheng Zhang*

Main category: cs.CV

TL;DR: IRGPT是第一个基于大规模真实红外文本数据集（IR-TD）构建的用于真实世界红外图像的多模态大型语言模型，它通过创新的双交叉模态课程迁移学习策略，在识别和基础等任务上取得了最先进的性能，克服了现有方法依赖合成数据的局限性。


<details>
  <summary>Details</summary>
Motivation: 真实世界的红外图像由于对齐文本数据的稀疏性和特定领域的特性，给视觉-语言模型带来了独特的挑战。现有的方法依赖于从可见图像进行风格转换生成的合成红外图像，这限制了它们捕捉红外模态独特特性的能力。

Method: 提出IRGPT，这是第一个用于真实世界红外图像的多模态大型语言模型，该模型建立在具有超过260K真实图像文本对的大型红外文本数据集（IR-TD）之上。提出了一种双交叉模态课程迁移学习策略，通过考虑红外-可见和红外-文本的难度分数，系统地将知识从可见域迁移到红外域。

Result: IRGPT在9项任务（例如识别、基础）的基准测试中，即使与更大规模的模型相比，也取得了最先进的性能。

Conclusion: IRGPT在9项任务的基准测试中取得了最先进的性能，即使与更大规模的模型相比也是如此。

Abstract: Real-world infrared imagery presents unique challenges for vision-language
models due to the scarcity of aligned text data and domain-specific
characteristics. Although existing methods have advanced the field, their
reliance on synthetic infrared images generated through style transfer from
visible images, which limits their ability to capture the unique
characteristics of the infrared modality. To address this, we propose IRGPT,
the first multi-modal large language model for real-world infrared images,
built upon a large-scale InfraRed-Text Dataset (IR-TD) comprising over 260K
authentic image-text pairs. The proposed IR-TD dataset contains real infrared
images paired with meticulously handcrafted texts, where the initial drafts
originated from two complementary processes: (1) LLM-generated descriptions of
visible images, and (2) rule-based descriptions of annotations. Furthermore, we
introduce a bi-cross-modal curriculum transfer learning strategy that
systematically transfers knowledge from visible to infrared domains by
considering the difficulty scores of both infrared-visible and infrared-text.
Evaluated on a benchmark of 9 tasks (e.g., recognition, grounding), IRGPT
achieves state-of-the-art performance even compared with larger-scale models.

</details>


### [10] [GPI-Net: Gestalt-Guided Parallel Interaction Network via Orthogonal Geometric Consistency for Robust Point Cloud Registration](https://arxiv.org/abs/2507.14452)
*Weikang Gu,Mingyue Han,Li Xue,Heng Dong,Changcai Yang,Riqing Chen,Lifang Wei*

Main category: cs.CV

TL;DR: 提出GPI-Net网络，利用格式塔原理和正交几何一致性，通过GFA和DMG块有效融合点云的局部和全局特征，提升配准精度。


<details>
  <summary>Details</summary>
Motivation: 为了解决点云配准中特征融合时特征冗余和复杂空间关系带来的挑战，提出利用格式塔原理来促进局部和全局信息之间的互补通信。

Method: 提出了一种名为GPI-Net的新型网络，该网络结合了格式塔原理和正交几何一致性。具体包括：1. 引入正交集成策略，减少冗余信息并生成更紧凑的全局结构。2. 设计了格式塔特征注意力（GFA）块，通过自注意力和交叉注意力机制捕捉对应点中的几何特征。3. 设计了双路径多粒度并行交互聚合（DMG）块，促进不同粒度间的特征信息交换。

Result: 在各种具有挑战性的任务上的广泛实验表明，GPI-Net相比现有方法具有优越的性能。

Conclusion: 该研究提出的GPI-Net在点云配准任务中表现出优越性能，能够有效处理局部和全局特征的融合，并在各种具有挑战性的任务上超越现有方法。

Abstract: The accurate identification of high-quality correspondences is a prerequisite
task in feature-based point cloud registration. However, it is extremely
challenging to handle the fusion of local and global features due to feature
redundancy and complex spatial relationships. Given that Gestalt principles
provide key advantages in analyzing local and global relationships, we propose
a novel Gestalt-guided Parallel Interaction Network via orthogonal geometric
consistency (GPI-Net) in this paper. It utilizes Gestalt principles to
facilitate complementary communication between local and global information.
Specifically, we introduce an orthogonal integration strategy to optimally
reduce redundant information and generate a more compact global structure for
high-quality correspondences. To capture geometric features in correspondences,
we leverage a Gestalt Feature Attention (GFA) block through a hybrid
utilization of self-attention and cross-attention mechanisms. Furthermore, to
facilitate the integration of local detail information into the global
structure, we design an innovative Dual-path Multi-Granularity parallel
interaction aggregation (DMG) block to promote information exchange across
different granularities. Extensive experiments on various challenging tasks
demonstrate the superior performance of our proposed GPI-Net in comparison to
existing methods. The code will be released at https://github.com/gwk/GPI-Net.

</details>


### [11] [Adaptive 3D Gaussian Splatting Video Streaming: Visual Saliency-Aware Tiling and Meta-Learning-Based Bitrate Adaptation](https://arxiv.org/abs/2507.14454)
*Han Gong,Qiyue Li,Jie Li,Zhi Liu*

Main category: cs.CV

TL;DR: 该论文解决了3DGS视频流式传输中的切片、质量评估和比特率适应挑战，提出了一种结合显著性分析的自适应切片技术、一种新的质量评估框架和一种基于元学习的比特率算法，并在实验中取得了优于现有方法的性能。


<details>
  <summary>Details</summary>
Motivation: 3DGS视频流式传输领域的研究仍处于早期阶段，在切片、质量评估和比特率适应等方面存在基本挑战。

Method: 通过显著性分析指导的自适应3DGS切片技术，结合空间和时间特征，为每个切片编码具有专用变形场和多级质量的版本；引入了一个联合评估3DGS表示中的空间域退化和2D渲染图像质量的新颖质量评估框架；开发了一种基于元学习的自适应比特率算法，以适应3DGS视频流式传输。

Result: 所提出的方法在切片、质量评估和比特率适应方面取得了显著的改进，并在大量实验中证明了其优越性。

Conclusion: 该研究提出了一种自适应3DGS切片技术，该技术由显著性分析指导，并结合了空间和时间特征。每个切片被编码为具有专用变形场和多个质量级别的版本，以实现自适应选择。此外，研究引入了一个新颖的3DGS视频质量评估框架，该框架在流式传输期间联合评估3DGS表示中的空间域退化以及生成的2D渲染图像的质量。研究还开发了一种专门针对3DGS视频流式传输的基于元学习的自适应比特率算法，该算法在不同的网络条件下均能实现最佳性能。实验证明，所提出的方法显著优于最先进的方法。

Abstract: 3D Gaussian splatting video (3DGS) streaming has recently emerged as a
research hotspot in both academia and industry, owing to its impressive ability
to deliver immersive 3D video experiences. However, research in this area is
still in its early stages, and several fundamental challenges, such as tiling,
quality assessment, and bitrate adaptation, require further investigation. In
this paper, we tackle these challenges by proposing a comprehensive set of
solutions. Specifically, we propose an adaptive 3DGS tiling technique guided by
saliency analysis, which integrates both spatial and temporal features. Each
tile is encoded into versions possessing dedicated deformation fields and
multiple quality levels for adaptive selection. We also introduce a novel
quality assessment framework for 3DGS video that jointly evaluates
spatial-domain degradation in 3DGS representations during streaming and the
quality of the resulting 2D rendered images. Additionally, we develop a
meta-learning-based adaptive bitrate algorithm specifically tailored for 3DGS
video streaming, achieving optimal performance across varying network
conditions. Extensive experiments demonstrate that our proposed approaches
significantly outperform state-of-the-art methods.

</details>


### [12] [GEMINUS: Dual-aware Global and Scene-Adaptive Mixture-of-Experts for End-to-End Autonomous Driving](https://arxiv.org/abs/2507.14456)
*Chi Wan,Yixin Cui,Jiatong Du,Shuo Yang,Yulong Bai,Yanjun Huang*

Main category: cs.CV

TL;DR: GEMINUS是一个混合专家自动驾驶框架，通过结合全局和场景自适应专家，并使用双感知路由器来提高在各种驾驶场景下的性能和鲁棒性，在Bench2Drive基准测试中取得了最先进的成果。


<details>
  <summary>Details</summary>
Motivation: 现有的单模态规划方法在处理多样化交通环境时难以学习到多样化的驾驶技能，因此需要一种能够适应不同场景的框架。

Method: 提出了一种名为GEMINUS的混合专家端到端自动驾驶框架，该框架包含一个全局专家、一个场景自适应专家组和一个双感知路由器。

Result: GEMINUS在Bench2Drive闭环基准测试中超越了现有方法，在仅使用单目视觉输入的情况下，在驾驶得分和成功率方面取得了最先进的性能。消融研究表明，与原始单专家基线相比，GEMINUS在驾驶得分、成功率和多能力平均分方面分别提高了7.67%、22.06%和19.41%。

Conclusion: GEMINUS框架通过结合全局专家和场景自适应专家组，并通过双感知路由器动态激活专家模块，实现了在多样化场景下的自适应和鲁棒性能。

Abstract: End-to-end autonomous driving requires adaptive and robust handling of
complex and diverse traffic environments. However, prevalent single-mode
planning methods attempt to learn an overall policy while struggling to acquire
diversified driving skills to handle diverse scenarios. Therefore, this paper
proposes GEMINUS, a Mixture-of-Experts end-to-end autonomous driving framework
featuring a Global Expert, a Scene-Adaptive Experts Group, and equipped with a
Dual-aware Router. Specifically, the Global Expert is trained on the overall
dataset, possessing robust performance. The Scene-Adaptive Experts are trained
on corresponding scene subsets, achieving adaptive performance. The Dual-aware
Router simultaneously considers scenario-level features and routing uncertainty
to dynamically activate expert modules. Through the effective coupling of the
Global Expert and the Scene-Adaptive Experts Group via the Dual-aware Router,
GEMINUS achieves adaptive and robust performance in diverse scenarios. GEMINUS
outperforms existing methods in the Bench2Drive closed-loop benchmark and
achieves state-of-the-art performance in Driving Score and Success Rate, even
with only monocular vision input. Furthermore, ablation studies demonstrate
significant improvements over the original single-expert baseline: 7.67% in
Driving Score, 22.06% in Success Rate, and 19.41% in MultiAbility-Mean. The
code will be available at https://github.com/newbrains1/GEMINUS.

</details>


### [13] [VisGuard: Securing Visualization Dissemination through Tamper-Resistant Data Retrieval](https://arxiv.org/abs/2507.14459)
*Huayuan Ye,Juntong Chen,Shenzhuo Zhang,Yipeng Zhang,Changbo Wang,Chenhui Li*

Main category: cs.CV

TL;DR: VisGuard is a robust framework that embeds recoverable metadata links into visualization images, protecting against tampering and enabling applications like interactive reconstruction and copyright protection.


<details>
  <summary>Details</summary>
Motivation: Existing methods for embedding metadata into visualization images for retrieval (VIDR) are often fragile to common image tampering (e.g., cropping, editing) during online distribution, leading to information loss.

Method: The proposed VisGuard framework embeds metadata links into visualization images using techniques like repetitive data tiling, invertible information broadcasting, and an anchor-based scheme for crop localization to ensure recoverability even after image tampering.

Result: VisGuard reliably embeds metadata links into visualization images, ensuring they remain recoverable even after substantial tampering, thereby facilitating and safeguarding visualization dissemination and information conveyance.

Conclusion: VisGuard enables various applications, including interactive chart reconstruction, tampering detection, and copyright protection, demonstrating superior performance in data retrieval accuracy, embedding capacity, and security against tampering and steganalysis.

Abstract: The dissemination of visualizations is primarily in the form of raster
images, which often results in the loss of critical information such as source
code, interactive features, and metadata. While previous methods have proposed
embedding metadata into images to facilitate Visualization Image Data Retrieval
(VIDR), most existing methods lack practicability since they are fragile to
common image tampering during online distribution such as cropping and editing.
To address this issue, we propose VisGuard, a tamper-resistant VIDR framework
that reliably embeds metadata link into visualization images. The embedded data
link remains recoverable even after substantial tampering upon images. We
propose several techniques to enhance robustness, including repetitive data
tiling, invertible information broadcasting, and an anchor-based scheme for
crop localization. VisGuard enables various applications, including interactive
chart reconstruction, tampering detection, and copyright protection. We conduct
comprehensive experiments on VisGuard's superior performance in data retrieval
accuracy, embedding capacity, and security against tampering and steganalysis,
demonstrating VisGuard's competence in facilitating and safeguarding
visualization dissemination and information conveyance.

</details>


### [14] [OptiCorNet: Optimizing Sequence-Based Context Correlation for Visual Place Recognition](https://arxiv.org/abs/2507.14477)
*Zhenyu Li,Tianyi Shang,Pengjie Xu,Ruirui Zhang,Fanchen Kong*

Main category: cs.CV

TL;DR: OptiCorNet是一个创新的序列建模框架，通过结合空间特征提取和时间差分（DSD模块）来改进视觉地点识别（VPR）。它使用1D卷积和LSTM来生成鲁棒的描述符，并通过四元组损失进行优化。该方法在处理季节和视角变化等挑战性场景时，优于现有技术。


<details>
  <summary>Details</summary>
Motivation: 现有的基于深度学习的视觉地点识别（VPR）解决方案主要关注单帧嵌入，忽略了图像序列中存在的时间相干性，而这在动态和感知混淆的环境中长期定位仍然是一个基本挑战。

Method: OptiCorNet是一个新颖的序列建模框架，它将空间特征提取和时间差分统一到一个可微分、可端到端训练的模块中。该方法的核心是一个轻量级的1D卷积编码器，结合一个可学习的微分时间算子（DSD），共同捕获短期空间上下文和长期时间转换。DSD模块通过一个固定的差分核对序列中的方向差异进行建模，然后进行基于LSTM的细化和可选的残差投影，产生紧凑、具有区分性的描述符，这些描述符对视角和外观的变化具有鲁棒性。此外，该方法还采用四元组损失来优化批次内的正对齐和多负发散，以进一步提高类间可分离性。

Result: 与先前将时间聚合视为后处理的方法不同，OptiCorNet直接学习序列级嵌入，从而实现更有效的端到端地点识别。

Conclusion: OptiCorNet通过学习序列级嵌入直接进行端到端地点识别，在具有挑战性的季节和视角变化的多项公开基准测试中，其性能优于最先进的方法。

Abstract: Visual Place Recognition (VPR) in dynamic and perceptually aliased
environments remains a fundamental challenge for long-term localization.
Existing deep learning-based solutions predominantly focus on single-frame
embeddings, neglecting the temporal coherence present in image sequences. This
paper presents OptiCorNet, a novel sequence modeling framework that unifies
spatial feature extraction and temporal differencing into a differentiable,
end-to-end trainable module. Central to our approach is a lightweight 1D
convolutional encoder combined with a learnable differential temporal operator,
termed Differentiable Sequence Delta (DSD), which jointly captures short-term
spatial context and long-range temporal transitions. The DSD module models
directional differences across sequences via a fixed-weight differencing
kernel, followed by an LSTM-based refinement and optional residual projection,
yielding compact, discriminative descriptors robust to viewpoint and appearance
shifts. To further enhance inter-class separability, we incorporate a
quadruplet loss that optimizes both positive alignment and multi-negative
divergence within each batch. Unlike prior VPR methods that treat temporal
aggregation as post-processing, OptiCorNet learns sequence-level embeddings
directly, enabling more effective end-to-end place recognition. Comprehensive
evaluations on multiple public benchmarks demonstrate that our approach
outperforms state-of-the-art baselines under challenging seasonal and viewpoint
variations.

</details>


### [15] [DFQ-ViT: Data-Free Quantization for Vision Transformers without Fine-tuning](https://arxiv.org/abs/2507.14481)
*Yujia Tong,Jingling Yuan,Tian Zhang,Jianquan Liu,Chuang Hu*

Main category: cs.CV

TL;DR: DFQ-ViT 通过改进合成样本生成和引入激活值校正，解决了数据无关量化视觉Transformer的性能问题，效果媲美真实数据量化，且无需微调，更绿色高效。


<details>
  <summary>Details</summary>
Motivation: 现有数据无关量化（DFQ）方法在为视觉Transformer（ViT）生成用于量化的合成样本时，未能充分捕捉和平衡样本中的全局与局部特征，导致合成数据质量不高。此外，量化后的模型在推理时，其中间层激活值的分布与全精度模型存在显著差异。这些问题共同导致了量化模型性能的严重下降。因此，需要一种新的方法来提升DFQ的质量和效率。

Method: DFQ-ViT 提出了一种新的数据无关量化（DFQ）流水线，主要包括两个关键部分：1. 合成样本生成：采用逐步增加难度的方式生成合成样本，以提高样本质量，更好地捕捉全局和局部特征。2. 激活值校正：在量化模型的校准和推理阶段，引入激活值校正矩阵，用于缩小量化模型与全精度模型之间中间层激活值分布的差距。

Result: DFQ-ViT 在各项实验中表现出相对于现有 DFQ 方法的显著优越性。具体而言，在 DeiT-T 模型进行 3 位权重量化时，DFQ-ViT 的性能比现有最优方法高出 4.29%。该方法无需微调，从而降低了计算开销，并为资源受限的边缘设备部署提供了便利，提高了能源效率，有利于实际应用。

Conclusion: DFQ-ViT 克服了现有数据无关量化方法在处理视觉Transformer（ViT）时合成样本质量不高以及量化后模型与全精度模型之间激活值分布差异的问题。通过逐步生成难度递增的合成样本和引入激活值校正矩阵，DFQ-ViT 显著提高了量化模型的性能，使其达到甚至优于使用真实数据进行量化的方法，同时无需微调，降低了计算开销和部署门槛，符合绿色学习的理念。

Abstract: Data-Free Quantization (DFQ) enables the quantization of Vision Transformers
(ViTs) without requiring access to data, allowing for the deployment of ViTs on
devices with limited resources. In DFQ, the quantization model must be
calibrated using synthetic samples, making the quality of these synthetic
samples crucial. Existing methods fail to fully capture and balance the global
and local features within the samples, resulting in limited synthetic data
quality. Moreover, we have found that during inference, there is a significant
difference in the distributions of intermediate layer activations between the
quantized and full-precision models. These issues lead to a severe performance
degradation of the quantized model. To address these problems, we propose a
pipeline for Data-Free Quantization for Vision Transformers (DFQ-ViT).
Specifically, we synthesize samples in order of increasing difficulty,
effectively enhancing the quality of synthetic data. During the calibration and
inference stage, we introduce the activation correction matrix for the
quantized model to align the intermediate layer activations with those of the
full-precision model. Extensive experiments demonstrate that DFQ-ViT achieves
remarkable superiority over existing DFQ methods and its performance is on par
with models quantized through real data. For example, the performance of DeiT-T
with 3-bit weights quantization is 4.29% higher than the state-of-the-art. Our
method eliminates the need for fine-tuning, which not only reduces
computational overhead but also lowers the deployment barriers for edge
devices. This characteristic aligns with the principles of Green Learning by
improving energy efficiency and facilitating real-world applications in
resource-constrained environments.

</details>


### [16] [Benefit from Reference: Retrieval-Augmented Cross-modal Point Cloud Completion](https://arxiv.org/abs/2507.14485)
*Hongye Hou,Liu Zhan,Yang Yang*

Main category: cs.CV

TL;DR: 提出了一种检索增强的点云补全框架，通过学习相似参考样本的结构先验信息来改进不完整点云的3D结构重建。该方法通过SSFE和PRAG模块，有效增强相关结构特征，抑制无关信息，并实现从全局到局部的特征融合，在处理稀疏和未见类别数据方面表现出色。


<details>
  <summary>Details</summary>
Motivation: 解决在不完整的点云中完成整个3D结构的任务，特别是在残差点云缺乏典型结构特征时。现有方法主要关注每个特定的输入类别，限制了其生成能力。

Method: 提出了一种新颖的检索增强点云补全框架，结合了跨模态检索来学习相似参考样本的结构先验信息。设计了结构共享特征编码器（SSFE）来联合提取跨模态特征和重建参考特征作为先验。通过编码器中的双通道控制门，增强参考样本中的相关结构特征并抑制无关信息干扰。提出了渐进式检索增强生成器（PRAG），采用分层特征融合机制，从全局到局部地将参考先验信息与输入特征相结合。

Result: 生成细粒度点云，并展示了处理稀疏数据和未见类别的泛化能力。

Conclusion: 该方法在多个数据集和真实场景的广泛评估中，证明了其在生成细粒度点云方面的有效性，以及在处理稀疏数据和未见类别方面的泛化能力。

Abstract: Completing the whole 3D structure based on an incomplete point cloud is a
challenging task, particularly when the residual point cloud lacks typical
structural characteristics. Recent methods based on cross-modal learning
attempt to introduce instance images to aid the structure feature learning.
However, they still focus on each particular input class, limiting their
generation abilities. In this work, we propose a novel retrieval-augmented
point cloud completion framework. The core idea is to incorporate cross-modal
retrieval into completion task to learn structural prior information from
similar reference samples. Specifically, we design a Structural Shared Feature
Encoder (SSFE) to jointly extract cross-modal features and reconstruct
reference features as priors. Benefiting from a dual-channel control gate in
the encoder, relevant structural features in the reference sample are enhanced
and irrelevant information interference is suppressed. In addition, we propose
a Progressive Retrieval-Augmented Generator (PRAG) that employs a hierarchical
feature fusion mechanism to integrate reference prior information with input
features from global to local. Through extensive evaluations on multiple
datasets and real-world scenes, our method shows its effectiveness in
generating fine-grained point clouds, as well as its generalization capability
in handling sparse data and unseen categories.

</details>


### [17] [Efficient Whole Slide Pathology VQA via Token Compression](https://arxiv.org/abs/2507.14497)
*Weimin Lyu,Qingqiao Hu,Kehan Qi,Zhan Shi,Wentao Huang,Saumya Gupta,Chao Chen*

Main category: cs.CV

TL;DR: TCP-LLaVA 透過 token 壓縮技術，有效解決了病理學全載玻片圖像分析的長上下文和計算需求問題，首次實現了 WSI 的 VQA，並在準確性和資源消耗方面均取得顯著成效。


<details>
  <summary>Details</summary>
Motivation: 解決了全載玻片圖像（WSIs）在病理學分析中，由於其巨大的尺寸（高達 10,000 x 10,000 像素）而對多模態大型語言模型（MLLM）造成的長上下文和高計算需求挑戰，以及現有方法在 VQA 方面的不足。

Method: 提出了一种名为 TCP-LLaVA 的新 MLLM 架构，利用可训练的压缩 token 聚合视觉和文本信息，并通过模态压缩模块（受 BERT 的 [CLS] token 机制启发）将压缩后的 token 输入 LLM 以生成答案。

Result: 在十種 TCGA 腫瘤亞型的實驗中，TCP-LLaVA 在 VQA 準確性方面優於現有的 MLLM 方法，並大幅減少了訓練資源的消耗。

Conclusion: TCP-LLaVA 透過 token 壓縮技術，成功實現了 WSI 的視覺問答（VQA），在準確性方面超越了現有 MLLM 方法，同時顯著降低了訓練資源消耗。

Abstract: Whole-slide images (WSIs) in pathology can reach up to 10,000 x 10,000
pixels, posing significant challenges for multimodal large language model
(MLLM) due to long context length and high computational demands. Previous
methods typically focus on patch-level analysis or slide-level classification
using CLIP-based models with multi-instance learning, but they lack the
generative capabilities needed for visual question answering (VQA). More recent
MLLM-based approaches address VQA by feeding thousands of patch tokens directly
into the language model, which leads to excessive resource consumption. To
address these limitations, we propose Token Compression Pathology LLaVA
(TCP-LLaVA), the first MLLM architecture to perform WSI VQA via token
compression. TCP-LLaVA introduces a set of trainable compression tokens that
aggregate visual and textual information through a modality compression module,
inspired by the [CLS] token mechanism in BERT. Only the compressed tokens are
forwarded to the LLM for answer generation, significantly reducing input length
and computational cost. Experiments on ten TCGA tumor subtypes show that
TCP-LLaVA outperforms existing MLLM baselines in VQA accuracy while reducing
training resource consumption by a substantial margin.

</details>


### [18] [Motion Segmentation and Egomotion Estimation from Event-Based Normal Flow](https://arxiv.org/abs/2507.14500)
*Zhiyuan Hua,Dehao Yuan,Cornelia Fermüller*

Main category: cs.CV

TL;DR: 提出一种利用事件数据和几何约束的鲁棒框架，用于运动分割和自我运动估计，无需计算光流。


<details>
  <summary>Details</summary>
Motivation: 为了解决传统依赖光流或显式深度估计的运动分割和自我运动估计方法的局限性，利用事件数据的稀疏性和高时间分辨率，并结合几何约束（法向流、场景结构、惯性测量）。

Method: 提出了一种基于优化的方法，通过迭代进行事件过分割、利用残差分析分离独立运动对象，并结合运动相似性和时间一致性信息进行分层聚类来优化分割。

Result: 在EVIMO2v2数据集上进行了验证，结果表明该方法能够进行准确的分割和轨迹运动估计，且无需计算全部光流。

Conclusion: 该方法在EVIMO2v2数据集上实现了准确的分割和轨迹运动估计，且无需计算光流，在物体边界处表现出显著优势，具有大规模、实时机器人和导航应用的巨大潜力。

Abstract: This paper introduces a robust framework for motion segmentation and
egomotion estimation using event-based normal flow, tailored specifically for
neuromorphic vision sensors. In contrast to traditional methods that rely
heavily on optical flow or explicit depth estimation, our approach exploits the
sparse, high-temporal-resolution event data and incorporates geometric
constraints between normal flow, scene structure, and inertial measurements.
The proposed optimization-based pipeline iteratively performs event
over-segmentation, isolates independently moving objects via residual analysis,
and refines segmentations using hierarchical clustering informed by motion
similarity and temporal consistency. Experimental results on the EVIMO2v2
dataset validate that our method achieves accurate segmentation and
translational motion estimation without requiring full optical flow
computation. This approach demonstrates significant advantages at object
boundaries and offers considerable potential for scalable, real-time robotic
and navigation applications.

</details>


### [19] [Advances in Feed-Forward 3D Reconstruction and View Synthesis: A Survey](https://arxiv.org/abs/2507.14501)
*Jiahui Zhang,Yuelei Li,Anpei Chen,Muyu Xu,Kunhao Liu,Jianyuan Wang,Xiao-Xiao Long,Hanxue Liang,Zexiang Xu,Hao Su,Christian Theobalt,Christian Rupprecht,Andrea Vedaldi,Hanspeter Pfister,Shijian Lu,Fangneng Zhan*

Main category: cs.CV

TL;DR: 3D重建和视图合成的进阶，重点是快速的前馈方法，如3DGS和NeRF，以及它们在AR/VR和数字人等领域的应用。


<details>
  <summary>Details</summary>
Motivation: 传统方法依赖于计算密集型迭代优化，在现实场景中的应用受到限制，而基于深度学习的前馈方法能够实现快速、可泛化的3D重建和视图合成。

Method: 对基于深度学习的前馈技术进行全面的调查，根据点云、3D高斯泼溅（3DGS）、神经辐射场（NeRF）等基础表示架构进行分类。

Result: 检查关键任务，如无姿态重建、动态3D重建以及3D感知图像和视频合成，并强调它们在数字人、SLAM、机器人等领域的应用。此外，还回顾了常用的数据集、详细统计数据和各种下游任务的评估协议。

Conclusion: 进阶的3D视觉和相关应用。

Abstract: 3D reconstruction and view synthesis are foundational problems in computer
vision, graphics, and immersive technologies such as augmented reality (AR),
virtual reality (VR), and digital twins. Traditional methods rely on
computationally intensive iterative optimization in a complex chain, limiting
their applicability in real-world scenarios. Recent advances in feed-forward
approaches, driven by deep learning, have revolutionized this field by enabling
fast and generalizable 3D reconstruction and view synthesis. This survey offers
a comprehensive review of feed-forward techniques for 3D reconstruction and
view synthesis, with a taxonomy according to the underlying representation
architectures including point cloud, 3D Gaussian Splatting (3DGS), Neural
Radiance Fields (NeRF), etc. We examine key tasks such as pose-free
reconstruction, dynamic 3D reconstruction, and 3D-aware image and video
synthesis, highlighting their applications in digital humans, SLAM, robotics,
and beyond. In addition, we review commonly used datasets with detailed
statistics, along with evaluation protocols for various downstream tasks. We
conclude by discussing open research challenges and promising directions for
future work, emphasizing the potential of feed-forward approaches to advance
the state of the art in 3D vision.

</details>


### [20] [DCHM: Depth-Consistent Human Modeling for Multiview Detection](https://arxiv.org/abs/2507.14505)
*Jiahao Ma,Tianyu Wang,Miaomiao Liu,David Ahmedt-Aristizabal,Chuong Nguyen*

Main category: cs.CV

TL;DR: 提出了一种名为DCHM的框架，通过超像素高斯溅射技术实现了多视角深度一致性，用于在稀疏视角、大规模和拥挤场景下精确地进行行人检测，且无需昂贵标注。


<details>
  <summary>Details</summary>
Motivation: 现有方法在行人检测中存在噪声多、精度低的问题，并且依赖昂贵的多视角3D标注，泛化能力差。为了解决这些问题，需要一种无需人工标注且能精确建模人类的方法。

Method: 提出了一种名为深度一致性人类建模（DCHM）的框架，该框架采用超像素高斯溅射技术，实现了稀疏视角、大规模和拥挤场景下的多视角深度一致性，生成精确的点云用于行人定位。

Result: DCHM框架显著减少了人类建模过程中的噪声，并在行人定位方面取得了优于现有最先进基线方法的性能。此外，DCHM是首个在如此具有挑战性的设置下重建行人并进行多视角分割的方法。

Conclusion: DCHM是一种新颖的框架，用于在稀疏视角、大规模和拥挤的场景中进行一致的深度估计和多视角融合，通过超像素高斯溅射实现了精确的点云，从而提高了行人定位的准确性，并且无需昂贵的多视角3D标注，在降噪和泛化能力方面优于现有方法。

Abstract: Multiview pedestrian detection typically involves two stages: human modeling
and pedestrian localization. Human modeling represents pedestrians in 3D space
by fusing multiview information, making its quality crucial for detection
accuracy. However, existing methods often introduce noise and have low
precision. While some approaches reduce noise by fitting on costly multiview 3D
annotations, they often struggle to generalize across diverse scenes. To
eliminate reliance on human-labeled annotations and accurately model humans, we
propose Depth-Consistent Human Modeling (DCHM), a framework designed for
consistent depth estimation and multiview fusion in global coordinates.
Specifically, our proposed pipeline with superpixel-wise Gaussian Splatting
achieves multiview depth consistency in sparse-view, large-scaled, and crowded
scenarios, producing precise point clouds for pedestrian localization.
Extensive validations demonstrate that our method significantly reduces noise
during human modeling, outperforming previous state-of-the-art baselines.
Additionally, to our knowledge, DCHM is the first to reconstruct pedestrians
and perform multiview segmentation in such a challenging setting. Code is
available on the \href{https://jiahao-ma.github.io/DCHM/}{project page}.

</details>


### [21] [ArtiMuse: Fine-Grained Image Aesthetics Assessment with Joint Scoring and Expert-Level Understanding](https://arxiv.org/abs/2507.14533)
*Shuo Cao,Nan Ma,Jiayang Li,Xiaohui Li,Lihao Shao,Kaiwen Zhu,Yu Zhou,Yuandong Pu,Jiarui Wu,Jiaquan Wang,Bo Qu,Wenhai Wang,Yu Qiao,Dajuin Yao,Yihao Liu*

Main category: cs.CV

TL;DR: 本研究提出了ArtiMuse，一个基于MLLM的IAA模型，以及ArtiMuse-10K，一个包含10,000张图像的专家标注数据集，旨在改进IAA的量化评分和专业理解能力。


<details>
  <summary>Details</summary>
Motivation: 为了满足教育应用、艺术创作和AIGC技术在图像美学评估（IAA）方面日益增长的需求，特别是需要能够提供量化评分和专业理解的方法。

Method: 提出了一种名为ArtiMuse 的基于多模态大语言模型（MLLM）的图像美学评估（IAA）方法，该方法能够进行联合评分和专家级理解。

Result: 所提出的ArtiMuse模型和ArtiMuse-10K数据集能够提供更强的感知和泛化能力，克服现有方法的模式偏差和缺乏细粒度属性分解的问题，从而支持更深入的美学评估。

Conclusion:  ArtiMuse-10K是一个包含10,000张图像的专家策划图像美学数据集，涵盖5个主要类别和15个子类别，并附有8维属性分析和整体评分。

Abstract: The rapid advancement of educational applications, artistic creation, and
AI-generated content (AIGC) technologies has substantially increased practical
requirements for comprehensive Image Aesthetics Assessment (IAA), particularly
demanding methods capable of delivering both quantitative scoring and
professional understanding. Multimodal Large Language Model (MLLM)-based IAA
methods demonstrate stronger perceptual and generalization capabilities
compared to traditional approaches, yet they suffer from modality bias
(score-only or text-only) and lack fine-grained attribute decomposition,
thereby failing to support further aesthetic assessment. In this paper, we
present:(1) ArtiMuse, an innovative MLLM-based IAA model with Joint Scoring and
Expert-Level Understanding capabilities; (2) ArtiMuse-10K, the first
expert-curated image aesthetic dataset comprising 10,000 images spanning 5 main
categories and 15 subcategories, each annotated by professional experts with
8-dimensional attributes analysis and a holistic score. Both the model and
dataset will be made public to advance the field.

</details>


### [22] [Real Time Captioning of Sign Language Gestures in Video Meetings](https://arxiv.org/abs/2507.14543)
*Sharanya Mukherjee,Md Hishaam Akhtar,Kannadasan R*

Main category: cs.CV

TL;DR: A browser extension that translates sign language to subtitles for video calls.


<details>
  <summary>Details</summary>
Motivation: To bridge the communication gap between people with and without hearing impairments, especially in the context of increasingly essential video meetings.

Method: Developing a browser extension for real-time sign language to subtitle translation.

Result: The system will translate sign language into subtitles using a dataset of over 2000 ASL videos performed by more than 100 signers.

Conclusion: We propose a browser extension that automatically translates sign language to subtitles during video calls, using a large-scale dataset of ASL videos.

Abstract: It has always been a rather tough task to communicate with someone possessing
a hearing impairment. One of the most tested ways to establish such a
communication is through the use of sign based languages. However, not many
people are aware of the smaller intricacies involved with sign language. Sign
language recognition using computer vision aims at eliminating the
communication barrier between deaf-mute and ordinary people so that they can
properly communicate with others. Recently the pandemic has left the whole
world shaken up and has transformed the way we communicate. Video meetings have
become essential for everyone, even people with a hearing disability. In recent
studies, it has been found that people with hearing disabilities prefer to sign
over typing during these video calls. In this paper, we are proposing a browser
extension that will automatically translate sign language to subtitles for
everyone else in the video call. The Large-scale dataset which contains more
than 2000 Word-Level ASL videos, which were performed by over 100 signers will
be used.

</details>


### [23] [Multimodal AI for Gastrointestinal Diagnostics: Tackling VQA in MEDVQA-GI 2025](https://arxiv.org/abs/2507.14544)
*Sujata Gaihre,Amir Thapa Magar,Prasuna Pokharel,Laxmi Tiwari*

Main category: cs.CV

TL;DR: 本文介绍了一种用于胃肠内窥镜检查医学VQA的Florence模型方法，通过微调和数据增强提高了准确性，并为未来研究提供了基础。


<details>
  <summary>Details</summary>
Motivation: 本次工作旨在解决图像密集型胃肠内窥镜检查的医学视觉问答（VQA）的子任务1，该任务是ImageCLEFmed MEDVQA 2025挑战的一部分。

Method: 采用Florence模型作为VQA流水线的骨干，结合强大的视觉编码器和文本编码器来解析内窥镜图像并生成临床相关的答案。为了提高泛化能力，采用了领域特定的数据增强技术，在增加训练多样性的同时保持了医学特征。

Result: 在KASVIR数据集上的实验表明，通过对Florence模型进行微调，可以获得在官方挑战指标上的准确响应。

Conclusion: 通过对Florence模型进行微调，可以在官方挑战指标上产生准确的响应，这表明大型多模态模型在医学VQA方面具有潜力，并为未来的可解释性、鲁棒性和临床整合工作提供了坚实的基础。

Abstract: This paper describes our approach to Subtask 1 of the ImageCLEFmed MEDVQA
2025 Challenge, which targets visual question answering (VQA) for
gastrointestinal endoscopy. We adopt the Florence model-a large-scale
multimodal foundation model-as the backbone of our VQA pipeline, pairing a
powerful vision encoder with a text encoder to interpret endoscopic images and
produce clinically relevant answers. To improve generalization, we apply
domain-specific augmentations that preserve medical features while increasing
training diversity. Experiments on the KASVIR dataset show that fine-tuning
Florence yields accurate responses on the official challenge metrics. Our
results highlight the potential of large multimodal models in medical VQA and
provide a strong baseline for future work on explainability, robustness, and
clinical integration. The code is publicly available at:
https://github.com/TiwariLaxuu/VQA-Florence.git

</details>


### [24] [Synthesizing Images on Perceptual Boundaries of ANNs for Uncovering Human Perceptual Variability on Facial Expressions](https://arxiv.org/abs/2507.14549)
*Haotian Deng,Chi Zhang,Chen Wei,Quanying Liu*

Main category: cs.CV

TL;DR: 本研究通过探索人工神经网络（ANN）决策边界与人类感知变异性之间的关联，证明了模糊的面部表情刺激会同时影响ANN和人类的感知，并提出通过行为数据微调ANN以实现个性化情感解读。


<details>
  <summary>Details</summary>
Motivation: 为了解决人工神经网络（ANN）在面部表情识别方面虽然准确但对个体感知差异的建模能力欠缺的问题，本研究旨在探索面部表情样本的模糊性与人类观察者之间感知判断分歧之间的关系。

Method: 本研究提出了一种新颖的感知边界采样方法，用于生成位于ANN决策边界上的人脸表情刺激。利用这些刺激构建了varEmotion数据集，并通过大规模人类行为实验进行分析。

Result: 研究结果表明，那些使ANN分类器感到困惑的刺激同样会引起人类参与者高度的感知不确定性，这揭示了情绪感知中存在的共享计算原理。通过行为数据微调ANN，能够使ANN预测与人类感知模式（包括群体和个体层面）保持一致。

Conclusion: 本研究成功建立了人工神经网络（ANN）决策边界与人类感知变异性之间的系统性联系，并通过使用行为数据对ANN表示进行微调，实现了ANN预测与群体及个体层面的人类感知模式的对齐，为情感解读的个性化建模提供了新的见解。

Abstract: A fundamental challenge in affective cognitive science is to develop models
that accurately capture the relationship between external emotional stimuli and
human internal experiences. While ANNs have demonstrated remarkable accuracy in
facial expression recognition, their ability to model inter-individual
differences in human perception remains underexplored. This study investigates
the phenomenon of high perceptual variability-where individuals exhibit
significant differences in emotion categorization even when viewing the same
stimulus. Inspired by the similarity between ANNs and human perception, we
hypothesize that facial expression samples that are ambiguous for ANN
classifiers also elicit divergent perceptual judgments among human observers.
To examine this hypothesis, we introduce a novel perceptual boundary sampling
method to generate facial expression stimuli that lie along ANN decision
boundaries. These ambiguous samples form the basis of the varEmotion dataset,
constructed through large-scale human behavioral experiments. Our analysis
reveals that these ANN-confusing stimuli also provoke heightened perceptual
uncertainty in human participants, highlighting shared computational principles
in emotion perception. Finally, by fine-tuning ANN representations using
behavioral data, we achieve alignment between ANN predictions and both
group-level and individual-level human perceptual patterns. Our findings
establish a systematic link between ANN decision boundaries and human
perceptual variability, offering new insights into personalized modeling of
emotional interpretation.

</details>


### [25] [Clutter Detection and Removal by Multi-Objective Analysis for Photographic Guidance](https://arxiv.org/abs/2507.14553)
*Xiaoran Wu*

Main category: cs.CV

TL;DR: 一个相机引导系统，帮助摄影爱好者识别和移除照片中的干扰物，以提高照片质量。


<details>
  <summary>Details</summary>
Motivation: 为了解决摄影爱好者因疏忽或缺乏经验而在照片中包含干扰物，阻碍情感和故事传达的问题。

Method: 开发了一个相机引导系统，通过估计和可视化对象对照片美感和内容的贡献来识别和移除混乱物。该系统包括一个具有美感评估的混乱区分算法和一个基于生成对抗网络的迭代图像修复算法。

Result: 用户研究表明，该系统提供了灵活的界面和准确的算法，用户可以更好地识别干扰物并拍出更高质量的图像。

Conclusion: 该系统能帮助用户在更少的时间内识别干扰物并拍出更高质量的图像。

Abstract: Clutter in photos is a distraction preventing photographers from conveying
the intended emotions or stories to the audience. Photography amateurs
frequently include clutter in their photos due to unconscious negligence or the
lack of experience in creating a decluttered, aesthetically appealing scene for
shooting. We are thus motivated to develop a camera guidance system that
provides solutions and guidance for clutter identification and removal. We
estimate and visualize the contribution of objects to the overall aesthetics
and content of a photo, based on which users can interactively identify
clutter. Suggestions on getting rid of clutter, as well as a tool that removes
cluttered objects computationally, are provided to guide users to deal with
different kinds of clutter and improve their photographic work. Two technical
novelties underpin interactions in our system: a clutter distinguishment
algorithm with aesthetics evaluations for objects and an iterative image
inpainting algorithm based on generative adversarial nets that reconstructs
missing regions of removed objects for high-resolution images. User studies
demonstrate that our system provides flexible interfaces and accurate
algorithms that allow users to better identify distractions and take higher
quality images within less time.

</details>


### [26] [Descrip3D: Enhancing Large Language Model-based 3D Scene Understanding with Object-Level Text Descriptions](https://arxiv.org/abs/2507.14555)
*Jintang Xue,Ganning Zhao,Jie-En Yao,Hong-En Chen,Yue Hu,Meida Chen,Suya You,C. -C. Jay Kuo*

Main category: cs.CV

TL;DR: Descrip3D uses text descriptions to represent object relationships in 3D scenes, improving understanding and performance on various tasks without needing extra supervision.


<details>
  <summary>Details</summary>
Motivation: Current 3D scene-language models struggle with relational understanding, particularly when visual embeddings alone do not adequately convey object roles and interactions.

Method: Descrip3D explicitly encodes object relationships using natural language. It enhances objects with textual descriptions capturing intrinsic attributes and contextual relationships, integrated through embedding fusion and prompt-level injection for unified reasoning across tasks like grounding, captioning, and question answering, without task-specific heads or additional supervision.

Result: Descrip3D enhances object representations with textual descriptions, improving relational understanding and achieving superior performance on benchmark datasets.

Conclusion: Descrip3D consistently outperforms strong baseline models across five benchmark datasets, demonstrating the effectiveness of language-guided relational representation for understanding complex indoor scenes.

Abstract: Understanding 3D scenes goes beyond simply recognizing objects; it requires
reasoning about the spatial and semantic relationships between them. Current 3D
scene-language models often struggle with this relational understanding,
particularly when visual embeddings alone do not adequately convey the roles
and interactions of objects. In this paper, we introduce Descrip3D, a novel and
powerful framework that explicitly encodes the relationships between objects
using natural language. Unlike previous methods that rely only on 2D and 3D
embeddings, Descrip3D enhances each object with a textual description that
captures both its intrinsic attributes and contextual relationships. These
relational cues are incorporated into the model through a dual-level
integration: embedding fusion and prompt-level injection. This allows for
unified reasoning across various tasks such as grounding, captioning, and
question answering, all without the need for task-specific heads or additional
supervision. When evaluated on five benchmark datasets, including ScanRefer,
Multi3DRefer, ScanQA, SQA3D, and Scan2Cap, Descrip3D consistently outperforms
strong baseline models, demonstrating the effectiveness of language-guided
relational representation for understanding complex indoor scenes.

</details>


### [27] [LEAD: Exploring Logit Space Evolution for Model Selection](https://arxiv.org/abs/2507.14559)
*Zixuan Hu,Xiaotong Li,Shixiang Tang,Jun Liu,Yichun Hu,Ling-Yu Duan*

Main category: cs.CV

TL;DR: LEAD是一种新的微调对齐方法，使用常微分方程（ODE）来模拟和预测预训练模型在下游任务中的迁移能力，解决了现有方法在捕捉优化非线性方面的不足。该方法通过分析网络输出（logits）的演化，并结合类别感知分解，能够一步预测迁移能力，无需实际微调，并在多项实验中表现出色。


<details>
  <summary>Details</summary>
Motivation: 预训练-微调范式在视觉任务中取得了巨大成功，导致了大量预训练模型的涌现。然而，如何在下游任务中高效地选择最合适的预训练模型，成了一个严峻的挑战。这个挑战的关键在于有效地预测模型的迁移能力，同时要考虑到潜在的微调动态。现有的方法通常在特征空间中用线性变换来模拟微调动态，但这与微调目标并不精确吻合，也无法捕捉优化过程中产生的非线性。

Method: LEAD提出了一种基于网络输出（logits）的、与微调对齐的方法。该方法提出了一个理论框架来模拟优化过程，并推导出一个常微分方程（ODE）来描绘向最终logit状态演化的非线性过程。此外，还设计了一种类别感知分解方法来考虑跨类别的不同演化动态，以确保其实际适用性。

Result: 在24个监督和自监督预训练模型以及10个下游数据集上的综合实验表明，LEAD具有出色的性能，并且即使在数据稀疏的情况下也展现出广泛的适应性。

Conclusion: LEAD通过整合与其优化目标紧密结合的非线性建模能力，提供了一个简洁的解决方案，能够有效地弥合优化鸿沟，并且可以一步完成，无需漫长的微调过程。

Abstract: The remarkable success of pretrain-then-finetune paradigm has led to a
proliferation of available pre-trained models for vision tasks. This surge
presents a significant challenge in efficiently choosing the most suitable
pre-trained models for downstream tasks. The critical aspect of this challenge
lies in effectively predicting the model transferability by considering the
underlying fine-tuning dynamics. Existing methods often model fine-tuning
dynamics in feature space with linear transformations, which do not precisely
align with the fine-tuning objective and fail to grasp the essential
nonlinearity from optimization. To this end, we present LEAD, a
finetuning-aligned approach based on the network output of logits. LEAD
proposes a theoretical framework to model the optimization process and derives
an ordinary differential equation (ODE) to depict the nonlinear evolution
toward the final logit state. Additionally, we design a class-aware
decomposition method to consider the varying evolution dynamics across classes
and further ensure practical applicability. Integrating the closely aligned
optimization objective and nonlinear modeling capabilities derived from the
differential equation, our method offers a concise solution to effectively
bridge the optimization gap in a single step, bypassing the lengthy fine-tuning
process. The comprehensive experiments on 24 supervised and self-supervised
pre-trained models across 10 downstream datasets demonstrate impressive
performances and showcase its broad adaptability even in low-data scenarios.

</details>


### [28] [Benchmarking GANs, Diffusion Models, and Flow Matching for T1w-to-T2w MRI Translation](https://arxiv.org/abs/2507.14575)
*Andrea Moschetto,Lemuel Puglisi,Alec Sargood,Pierluigi Dell'Acqua,Francesco Guarnera,Sebastiano Battiato,Daniele Ravì*

Main category: cs.CV

TL;DR: Pix2Pix在MRI跨模态合成中优于其他模型，但基于流的模型需要更多数据。


<details>
  <summary>Details</summary>
Motivation: 为了减少MRI扫描时间、成本和提高诊断质量，研究人员正在探索计算方法来进行跨模态合成，将已获得的MRI对比度（如T1w）转换为缺失的对比度（如T2w）。

Method: 本文对生成对抗网络（GAN）、扩散模型和流匹配（FM）技术进行了全面的基准测试，用于T1w到T2w的二维MRI图像转换。所有模型均在三个公开的健康成人MRI数据集上进行了公平设置和评估。

Result: 在对三个公开MRI数据集进行的定量和定性分析中，基于GAN的Pix2Pix模型在结构保真度、图像质量和计算效率方面均优于基于扩散和FM的模型。

Conclusion: Pix2Pix等生成模型在T1w到T2w的MRI图像转换任务中，在结构保真度、图像质量和计算效率方面优于扩散模型和流匹配模型。基于流的模型在小型数据集上容易过拟合，需要更多数据才能达到或超过GAN的性能。

Abstract: Magnetic Resonance Imaging (MRI) enables the acquisition of multiple image
contrasts, such as T1-weighted (T1w) and T2-weighted (T2w) scans, each offering
distinct diagnostic insights. However, acquiring all desired modalities
increases scan time and cost, motivating research into computational methods
for cross-modal synthesis. To address this, recent approaches aim to synthesize
missing MRI contrasts from those already acquired, reducing acquisition time
while preserving diagnostic quality. Image-to-image (I2I) translation provides
a promising framework for this task. In this paper, we present a comprehensive
benchmark of generative models$\unicode{x2013}$specifically, Generative
Adversarial Networks (GANs), diffusion models, and flow matching (FM)
techniques$\unicode{x2013}$for T1w-to-T2w 2D MRI I2I translation. All
frameworks are implemented with comparable settings and evaluated on three
publicly available MRI datasets of healthy adults. Our quantitative and
qualitative analyses show that the GAN-based Pix2Pix model outperforms
diffusion and FM-based methods in terms of structural fidelity, image quality,
and computational efficiency. Consistent with existing literature, these
results suggest that flow-based models are prone to overfitting on small
datasets and simpler tasks, and may require more data to match or surpass GAN
performance. These findings offer practical guidance for deploying I2I
translation techniques in real-world MRI workflows and highlight promising
directions for future research in cross-modal medical image synthesis. Code and
models are publicly available at
https://github.com/AndreaMoschetto/medical-I2I-benchmark.

</details>


### [29] [Performance comparison of medical image classification systems using TensorFlow Keras, PyTorch, and JAX](https://arxiv.org/abs/2507.14587)
*Merjem Bećirović,Amina Kurtović,Nordin Smajlović,Medina Kapo,Amila Akagić*

Main category: cs.CV

TL;DR: 本研究评估了TensorFlow、PyTorch和JAX在血细胞图像分类任务中的性能，发现在图像分辨率和框架优化等因素影响下，JAX和PyTorch的性能与现有基准相当，显示出其在医学图像分类中的效率。


<details>
  <summary>Details</summary>
Motivation: 尽管基于深度学习的自动分类系统在血细胞图像分析方面显示出巨大潜力，但缺乏对特定深度学习框架的详细性能分析。

Method: 本研究通过比较TensorFlow (Keras)、PyTorch和JAX这三种流行的深度学习框架在BloodMNIST数据集上的血细胞图像分类性能来评估它们。研究主要关注推理时间差异，同时也考察了不同图像尺寸下的分类性能。

Result: 研究结果表明，不同框架在性能上存在差异，这受到图像分辨率和框架特定优化等因素的影响。

Conclusion: JAX和PyTorch在血细胞图像分类方面达到了与当前基准相当的准确性，证明了这些框架在医学图像分类方面的效率。

Abstract: Medical imaging plays a vital role in early disease diagnosis and monitoring.
Specifically, blood microscopy offers valuable insights into blood cell
morphology and the detection of hematological disorders. In recent years, deep
learning-based automated classification systems have demonstrated high
potential in enhancing the accuracy and efficiency of blood image analysis.
However, a detailed performance analysis of specific deep learning frameworks
appears to be lacking. This paper compares the performance of three popular
deep learning frameworks, TensorFlow with Keras, PyTorch, and JAX, in
classifying blood cell images from the publicly available BloodMNIST dataset.
The study primarily focuses on inference time differences, but also
classification performance for different image sizes. The results reveal
variations in performance across frameworks, influenced by factors such as
image resolution and framework-specific optimizations. Classification accuracy
for JAX and PyTorch was comparable to current benchmarks, showcasing the
efficiency of these frameworks for medical image classification.

</details>


### [30] [DiSCO-3D : Discovering and segmenting Sub-Concepts from Open-vocabulary queries in NeRF](https://arxiv.org/abs/2507.14596)
*Doriand Petit,Steve Bourgeois,Vincent Gay-Bellile,Florian Chabot,Loïc Barthe*

Main category: cs.CV

TL;DR: DiSCO-3D是第一个解决3D开放词汇子概念发现问题的方法，它能同时适应场景和用户查询，并在各种分割任务中表现出色。


<details>
  <summary>Details</summary>
Motivation: 解决3D开放词汇子概念发现的更广泛问题，旨在同时适应场景和用户查询的3D语义分割。

Method: DiSCO-3D基于神经场表示，结合了无监督分割和弱开放词汇引导。

Result: DiSCO-3D在3D开放词汇子概念发现方面实现了有效性能，并在开放词汇和无监督分割的边缘情况下展现出最先进的结果。

Conclusion: DiSCO-3D在3D开放词汇子概念发现方面实现了有效性能，并在开放词汇和无监督分割的边缘情况下展现出最先进的结果。

Abstract: 3D semantic segmentation provides high-level scene understanding for
applications in robotics, autonomous systems, \textit{etc}. Traditional methods
adapt exclusively to either task-specific goals (open-vocabulary segmentation)
or scene content (unsupervised semantic segmentation). We propose DiSCO-3D, the
first method addressing the broader problem of 3D Open-Vocabulary Sub-concepts
Discovery, which aims to provide a 3D semantic segmentation that adapts to both
the scene and user queries. We build DiSCO-3D on Neural Fields representations,
combining unsupervised segmentation with weak open-vocabulary guidance. Our
evaluations demonstrate that DiSCO-3D achieves effective performance in
Open-Vocabulary Sub-concepts Discovery and exhibits state-of-the-art results in
the edge cases of both open-vocabulary and unsupervised segmentation.

</details>


### [31] [Exp-Graph: How Connections Learn Facial Attributes in Graph-based Expression Recognition](https://arxiv.org/abs/2507.14608)
*Nandani Sharma,Dinesh Singh*

Main category: cs.CV

TL;DR: Exp-Graph利用图神经网络对齐面部属性的结构关系，以提高面部表情识别的准确性，并在多个数据集上取得了领先的性能。


<details>
  <summary>Details</summary>
Motivation: 面部表情识别在人机交互应用中至关重要，但现有方法未能充分利用面部属性的结构信息。由于面部属性的结构随表情变化，将结构信息纳入面部属性对于提高识别精度至关重要。

Method: 提出了一种名为Exp-Graph的新框架，利用图神经网络对面部属性的结构关系进行建模，以实现面部表情识别。具体地，使用面部地标作为图的顶点，邻近性和视觉Transformer编码的局部外观相似性来确定边，并通过图卷积网络来捕获和整合这些结构依赖关系。

Result: Exp-Graph框架在三个基准数据集上取得了优异的识别准确率，表明其在不同环境下的有效性。

Conclusion: Exp-Graph框架在Oulu-CASIA、eNTERFACE05和AFEW三个基准数据集上取得了98.09%、79.01%和56.39%的识别准确率，证明了其在实验室和真实世界场景中都具有强大的泛化能力和有效性。

Abstract: Facial expression recognition is crucial for human-computer interaction
applications such as face animation, video surveillance, affective computing,
medical analysis, etc. Since the structure of facial attributes varies with
facial expressions, incorporating structural information into facial attributes
is essential for facial expression recognition. In this paper, we propose
Exp-Graph, a novel framework designed to represent the structural relationships
among facial attributes using graph-based modeling for facial expression
recognition. For facial attributes graph representation, facial landmarks are
used as the graph's vertices. At the same time, the edges are determined based
on the proximity of the facial landmark and the similarity of the local
appearance of the facial attributes encoded using the vision transformer.
Additionally, graph convolutional networks are utilized to capture and
integrate these structural dependencies into the encoding of facial attributes,
thereby enhancing the accuracy of expression recognition. Thus, Exp-Graph
learns from the facial attribute graphs highly expressive semantic
representations. On the other hand, the vision transformer and graph
convolutional blocks help the framework exploit the local and global
dependencies among the facial attributes that are essential for the recognition
of facial expressions. We conducted comprehensive evaluations of the proposed
Exp-Graph model on three benchmark datasets: Oulu-CASIA, eNTERFACE05, and AFEW.
The model achieved recognition accuracies of 98.09\%, 79.01\%, and 56.39\%,
respectively. These results indicate that Exp-Graph maintains strong
generalization capabilities across both controlled laboratory settings and
real-world, unconstrained environments, underscoring its effectiveness for
practical facial expression recognition applications.

</details>


### [32] [Depthwise-Dilated Convolutional Adapters for Medical Object Tracking and Segmentation Using the Segment Anything Model 2](https://arxiv.org/abs/2507.14613)
*Guoping Xu,Christopher Kabat,You Zhang*

Main category: cs.CV

TL;DR: DD-SAM2通过引入DD-Adapter增强SAM2在医疗视频分割和跟踪任务中的性能，以更少的计算资源和数据实现了优越效果。


<details>
  <summary>Details</summary>
Motivation: 解决现有医学图像分割方法在动态医学成像场景中适应性差、模态特异性设计限制以及SAM2模型在医疗视频应用中需要大规模数据集进行重新训练或迁移学习导致的高计算成本和灾难性遗忘风险的问题。

Method: 提出了一种名为DD-SAM2的高效适应框架，该框架引入了深度可分离适配器（DD-Adapter），以增强多尺度特征提取能力，并最小化参数开销。该方法利用SAM2的流式内存机制，专注于医疗视频对象跟踪和分割。

Result: 在TrackRad2025（肿瘤分割）和EchoNet-Dynamic（左心室跟踪）数据集上取得了优异的性能，Dice分数分别达到0.93和0.97。

Conclusion: DD-SAM2是一个高效的SAM2适应框架，通过引入深度可分离适配器（DD-Adapter）增强了多尺度特征提取能力，并以最小的参数开销实现了在有限医疗视频数据上的有效微调。该框架充分利用了SAM2的流式内存机制，实现了医疗视频对象跟踪和分割。实验结果表明，DD-SAM2在TrackRad2025和EchoNet-Dynamic数据集上分别取得了0.93和0.97的Dice分数，展现了其优越性能。

Abstract: Recent advances in medical image segmentation have been driven by deep
learning; however, most existing methods remain limited by modality-specific
designs and exhibit poor adaptability to dynamic medical imaging scenarios. The
Segment Anything Model 2 (SAM2) and its related variants, which introduce a
streaming memory mechanism for real-time video segmentation, present new
opportunities for prompt-based, generalizable solutions. Nevertheless, adapting
these models to medical video scenarios typically requires large-scale datasets
for retraining or transfer learning, leading to high computational costs and
the risk of catastrophic forgetting. To address these challenges, we propose
DD-SAM2, an efficient adaptation framework for SAM2 that incorporates a
Depthwise-Dilated Adapter (DD-Adapter) to enhance multi-scale feature
extraction with minimal parameter overhead. This design enables effective
fine-tuning of SAM2 on medical videos with limited training data. Unlike
existing adapter-based methods focused solely on static images, DD-SAM2 fully
exploits SAM2's streaming memory for medical video object tracking and
segmentation. Comprehensive evaluations on TrackRad2025 (tumor segmentation)
and EchoNet-Dynamic (left ventricle tracking) datasets demonstrate superior
performance, achieving Dice scores of 0.93 and 0.97, respectively. To the best
of our knowledge, this work provides an initial attempt at systematically
exploring adapter-based SAM2 fine-tuning for medical video segmentation and
tracking. Code, datasets, and models will be publicly available at
https://github.com/apple1986/DD-SAM2.

</details>


### [33] [BusterX++: Towards Unified Cross-Modal AI-Generated Content Detection and Explanation with MLLM](https://arxiv.org/abs/2507.14632)
*Haiquan Wen,Tianxiao Li,Zhenglin Huang,Yiwei He,Guangliang Cheng*

Main category: cs.CV

TL;DR: BusterX++ 框架通过跨模态检测和 RL 训练策略，有效解决了现有合成媒体检测方法的局限性，并在 GenBuster++ 基准测试中取得了优异成果。


<details>
  <summary>Details</summary>
Motivation: 当前的合成媒体检测方法在处理结合多种媒体格式的合成内容时效果不佳，因为它们主要基于单模态设计。为了应对这一挑战，需要一种能够进行跨模态检测和解释的框架。

Method: 提出了一种名为 BusterX++ 的新框架，该框架采用先进的强化学习 (RL) 训练策略，并通过多阶段训练、思维奖励和混合推理来实现性能提升，以解决现有单模态检测方法的局限性。

Result: BusterX++ 在 GenBuster++ 基准测试中取得了稳定的显著性能提升，该基准包含 4,000 个由人类专家精心策划的图像和视频剪辑，确保了高质量、多样性和实际应用性。

Conclusion: BusterX++ 框架在跨模态合成媒体检测方面表现出有效性和泛化能力。

Abstract: Recent advances in generative AI have dramatically improved image and video
synthesis capabilities, significantly increasing the risk of misinformation
through sophisticated fake content. In response, detection methods have evolved
from traditional approaches to multimodal large language models (MLLMs),
offering enhanced transparency and interpretability in identifying synthetic
media. However, current detection systems remain fundamentally limited by their
single-modality design. These approaches analyze images or videos separately,
making them ineffective against synthetic content that combines multiple media
formats. To address these challenges, we introduce \textbf{BusterX++}, a novel
framework designed specifically for cross-modal detection and explanation of
synthetic media. Our approach incorporates an advanced reinforcement learning
(RL) post-training strategy that eliminates cold-start. Through Multi-stage
Training, Thinking Reward, and Hybrid Reasoning, BusterX++ achieves stable and
substantial performance improvements. To enable comprehensive evaluation, we
also present \textbf{GenBuster++}, a cross-modal benchmark leveraging
state-of-the-art image and video generation techniques. This benchmark
comprises 4,000 images and video clips, meticulously curated by human experts
using a novel filtering methodology to ensure high quality, diversity, and
real-world applicability. Extensive experiments demonstrate the effectiveness
and generalizability of our approach.

</details>


### [34] [Multispectral State-Space Feature Fusion: Bridging Shared and Cross-Parametric Interactions for Object Detection](https://arxiv.org/abs/2507.14643)
*Jifeng Shen,Haibo Zhan,Shaohua Dong,Xin Zuo,Wankou Yang,Haibin Ling*

Main category: cs.CV

TL;DR: MS2Fusion框架利用狀態空間模型（SSM）通過雙路交互機制解決了多光譜目標檢測中的泛化性和計算瓶頸問題，在多個基準測試中取得了優越的性能，並對其他多光譜感知任務具有通用性。


<details>
  <summary>Details</summary>
Motivation: 現代多光譜特徵融合在目標檢測方面面臨兩個關鍵限制：1）過度偏好局部互補特徵而非跨模態共享語義，不利於泛化性能；2）感受野大小與計算複雜度之間的權衡，為可擴展的特徵建模帶來了關鍵瓶頸。

Method: 提出了一種新穎的多光譜狀態空間特徵融合框架（MS2Fusion），該框架基於狀態空間模型（SSM），通過雙路參數交互機制實現高效有效的融合。具體來說，第一條交叉參數交互分支繼承了交叉注意力在挖掘互補信息方面的優勢，並在SSM中進行了跨模態隱態解碼。第二條共享參數分支通過參數共享的SSM，利用聯合嵌入探索跨模態對齊，以獲得跨模態的相似語義特徵和結構。最後，這兩個路徑與SSM聯合優化，在統一的框架中融合多光譜特徵，使MS2Fusion能夠同時享受功能互補和共享語義空間。

Result: MS2Fusion顯著優於其他最先進的多光譜目標檢測方法，並且在RGB-T語義分割和RGBT顯著目標檢測上也取得了最先進的結果。

Conclusion: MS2Fusion在FLIR、M3FD和LLVIP等主流基準測試中顯著優於其他最先進的多光譜目標檢測方法，證明了其優越性。此外，MS2Fusion具有通用性，適用於其他多光譜感知任務，即使沒有特殊設計，在RGB-T語義分割和RGBT顯著目標檢測上也取得了最先進的結果，顯示了其通用性。

Abstract: Modern multispectral feature fusion for object detection faces two critical
limitations: (1) Excessive preference for local complementary features over
cross-modal shared semantics adversely affects generalization performance; and
(2) The trade-off between the receptive field size and computational complexity
present critical bottlenecks for scalable feature modeling. Addressing these
issues, a novel Multispectral State-Space Feature Fusion framework, dubbed
MS2Fusion, is proposed based on the state space model (SSM), achieving
efficient and effective fusion through a dual-path parametric interaction
mechanism. More specifically, the first cross-parameter interaction branch
inherits the advantage of cross-attention in mining complementary information
with cross-modal hidden state decoding in SSM. The second shared-parameter
branch explores cross-modal alignment with joint embedding to obtain
cross-modal similar semantic features and structures through parameter sharing
in SSM. Finally, these two paths are jointly optimized with SSM for fusing
multispectral features in a unified framework, allowing our MS2Fusion to enjoy
both functional complementarity and shared semantic space. In our extensive
experiments on mainstream benchmarks including FLIR, M3FD and LLVIP, our
MS2Fusion significantly outperforms other state-of-the-art multispectral object
detection methods, evidencing its superiority. Moreover, MS2Fusion is general
and applicable to other multispectral perception tasks. We show that, even
without specific design, MS2Fusion achieves state-of-the-art results on RGB-T
semantic segmentation and RGBT salient object detection, showing its
generality. The source code will be available at
https://github.com/61s61min/MS2Fusion.git.

</details>


### [35] [AI-Powered Precision in Sport Taekwondo: Enhancing Fairness, Speed, and Trust in Competition (FST.ai)](https://arxiv.org/abs/2507.14657)
*Keivan Shariatmadar,Ahmad Osman*

Main category: cs.CV

TL;DR: FST.ai是一个利用AI技术（计算机视觉、深度学习）的体育裁判框架，能实时准确地识别和评分跆拳道中的头踢动作，并将该技术推广到其他体育项目。


<details>
  <summary>Details</summary>
Motivation: 传统体育裁判系统存在延迟、主观性和不一致性问题，影响公平性和运动员信任度。

Method: 利用计算机视觉、深度学习和边缘推理技术，通过姿态估计、运动分类和冲击分析来实现自动化动作识别与分类。

Result: 将决策时间从几分钟缩短到几秒钟，同时提高了判罚的一致性和透明度。

Conclusion: FST.ai框架的鲁棒性、可扩展性以及跨运动的潜力得到了验证，有望提升多个项目的裁判标准。

Abstract: The integration of Artificial Intelligence (AI) into sports officiating
represents a paradigm shift in how decisions are made in competitive
environments. Traditional manual systems, even when supported by Instant Video
Replay (IVR), often suffer from latency, subjectivity, and inconsistent
enforcement, undermining fairness and athlete trust. This paper introduces
FST.ai, a novel AI-powered framework designed to enhance officiating in Sport
Taekwondo, particularly focusing on the complex task of real-time head kick
detection and scoring. Leveraging computer vision, deep learning, and edge
inference, the system automates the identification and classification of key
actions, significantly reducing decision time from minutes to seconds while
improving consistency and transparency. Importantly, the methodology is not
limited to Taekwondo. The underlying framework -- based on pose estimation,
motion classification, and impact analysis -- can be adapted to a wide range of
sports requiring action detection, such as judo, karate, fencing, or even team
sports like football and basketball, where foul recognition or performance
tracking is critical. By addressing one of Taekwondo's most challenging
scenarios -- head kick scoring -- we demonstrate the robustness, scalability,
and sport-agnostic potential of FST.ai to transform officiating standards
across multiple disciplines.

</details>


### [36] [Artificial Intelligence in the Food Industry: Food Waste Estimation based on Computer Vision, a Brief Case Study in a University Dining Hall](https://arxiv.org/abs/2507.14662)
*Shayan Rokhva,Babak Teimourpour*

Main category: cs.CV

TL;DR: 本研究提出了一种基于计算机视觉的食物浪费量化方法，通过分析餐前餐后图像的语义分割来估算餐盘食物浪费。该方法经济高效、可扩展且能实现实时监测，对干性食物效果尤佳，为餐饮业减少食物浪费提供了技术支持。


<details>
  <summary>Details</summary>
Motivation: 量化机构食堂的食物浪费对于支持数据驱动的可持续发展策略至关重要。本研究旨在开发一种经济高效的计算机视觉框架，以估算餐盘级别的食物浪费。

Method: 该研究采用计算机视觉技术，利用语义分割方法，对餐前餐后的RGB图像进行分析，以量化食物浪费。研究中训练了四种全监督模型（U-Net、U-Net++及其轻量级变体），并采用了有上限的动态逆频率损失和AdamW优化器。性能评估指标包括像素准确率、Dice、IoU以及一个自定义的像素一致性（DPA）指标。

Result: 所有模型均取得了令人满意的性能，在DPA指标上，至少有一个模型针对每种食物类型都达到了90%或更高，表明像素级比例估计具有很强的一致性。轻量级模型具有更少的参数，推理速度更快，在NVIDIA T4 GPU上实现了实时吞吐量。研究还发现，干性、硬性食物成分（如米饭和炸薯条）的分割效果优于复杂、碎片化或粘稠的菜肴（如炖菜），尤其是在餐后。

Conclusion: 该研究提出了一种经济高效的计算机视觉框架，用于估算餐盘级别的食物浪费。该框架利用了餐前餐后RGB图像的语义分割技术，并针对伊朗的五种菜肴进行了训练和评估。结果表明，所有模型均取得了令人满意的性能，其中至少有一个模型在DPA（像素级比例估计的一致性）上接近或超过了90%。轻量级模型在推理速度方面表现出色，能够实现实时吞吐量。研究还指出了干性、硬性食物成分的分割效果优于复杂、碎片化或粘稠的菜肴。尽管存在2D成像、食物种类有限和手动数据收集等限制，但该框架代表了一种可扩展、非接触式的食物消耗监测解决方案，为自动化、实时浪费跟踪系统奠定了基础，并为餐饮管理和政策制定者提供了可行的见解和未来方向。

Abstract: Quantifying post-consumer food waste in institutional dining settings is
essential for supporting data-driven sustainability strategies. This study
presents a cost-effective computer vision framework that estimates plate-level
food waste by utilizing semantic segmentation of RGB images taken before and
after meal consumption across five Iranian dishes. Four fully supervised models
(U-Net, U-Net++, and their lightweight variants) were trained using a capped
dynamic inverse-frequency loss and AdamW optimizer, then evaluated through a
comprehensive set of metrics, including Pixel Accuracy, Dice, IoU, and a
custom-defined Distributional Pixel Agreement (DPA) metric tailored to the
task. All models achieved satisfying performance, and for each food type, at
least one model approached or surpassed 90% DPA, demonstrating strong alignment
in pixel-wise proportion estimates. Lighter models with reduced parameter
counts offered faster inference, achieving real-time throughput on an NVIDIA T4
GPU. Further analysis showed superior segmentation performance for dry and more
rigid components (e.g., rice and fries), while more complex, fragmented, or
viscous dishes, such as stews, showed reduced performance, specifically
post-consumption. Despite limitations such as reliance on 2D imaging,
constrained food variety, and manual data collection, the proposed framework is
pioneering and represents a scalable, contactless solution for continuous
monitoring of food consumption. This research lays foundational groundwork for
automated, real-time waste tracking systems in large-scale food service
environments and offers actionable insights and outlines feasible future
directions for dining hall management and policymakers aiming to reduce
institutional food waste.

</details>


### [37] [Gene-DML: Dual-Pathway Multi-Level Discrimination for Gene Expression Prediction from Histopathology Images](https://arxiv.org/abs/2507.14670)
*Yaxuan Song,Jianan Fan,Hang Chang,Weidong Cai*

Main category: cs.CV

TL;DR: Gene-DML是一个新的框架，通过双通路多层次判别来更好地匹配病理图像和基因表达数据，提高了预测基因表达的准确性。


<details>
  <summary>Details</summary>
Motivation: 现有的基因表达预测方法未能充分利用组织病理学图像和基因表达谱在多层次表示之间进行跨模态表示对齐，限制了预测性能。该研究旨在解决此问题。

Method: 提出了一种名为 Gene-DML 的统一框架，该框架通过双通路多层次判别（Dual-pathway Multi-Level discrimination）来构建潜在空间，以增强形态学和转录组学之间的对应关系。具体包括：1. 多尺度实例级判别通路：对从局部、邻域和全局三个层级提取的组织病理学表示进行对齐，以捕捉与基因表达谱相关的、可感知尺度的形态-转录关系。2. 跨层级实例-组判别通路：强制单个实例（图像/基因）与跨模态的实例组（基因/图像）之间保持结构一致性，以加强跨模态的对齐。通过联合建模细粒度和结构层次的判别，Gene-DML 学习了鲁棒的跨模态表示。

Result: 通过双通路多层次判别，Gene-DML 能够学习鲁棒的跨模态表示，从而提高基因表达预测的准确性和泛化能力。在公开空间转录组学数据集上的广泛实验证明，Gene-DML 在基因表达预测方面取得了最先进的性能。

Conclusion: Gene-DML 框架通过其双通路多层次判别方法，有效提升了在组织病理学图像中预测基因表达的准确性和泛化能力，并在公开空间转录组学数据集上达到了最先进的性能。

Abstract: Accurately predicting gene expression from histopathology images offers a
scalable and non-invasive approach to molecular profiling, with significant
implications for precision medicine and computational pathology. However,
existing methods often underutilize the cross-modal representation alignment
between histopathology images and gene expression profiles across multiple
representational levels, thereby limiting their prediction performance. To
address this, we propose Gene-DML, a unified framework that structures latent
space through Dual-pathway Multi-Level discrimination to enhance correspondence
between morphological and transcriptional modalities. The multi-scale
instance-level discrimination pathway aligns hierarchical histopathology
representations extracted at local, neighbor, and global levels with gene
expression profiles, capturing scale-aware morphological-transcriptional
relationships. In parallel, the cross-level instance-group discrimination
pathway enforces structural consistency between individual (image/gene)
instances and modality-crossed (gene/image, respectively) groups, strengthening
the alignment across modalities. By jointly modelling fine-grained and
structural-level discrimination, Gene-DML is able to learn robust cross-modal
representations, enhancing both predictive accuracy and generalization across
diverse biological contexts. Extensive experiments on public spatial
transcriptomics datasets demonstrate that Gene-DML achieves state-of-the-art
performance in gene expression prediction. The code and checkpoints will be
released soon.

</details>


### [38] [Docopilot: Improving Multimodal Models for Document-Level Understanding](https://arxiv.org/abs/2507.14675)
*Yuchen Duan,Zhe Chen,Yusong Hu,Weiyun Wang,Shenglong Ye,Botian Shi,Lewei Lu,Qibin Hou,Tong Lu,Hongsheng Li,Jifeng Dai,Wenhai Wang*

Main category: cs.CV

TL;DR: 发布Doc-750K数据集和Docopilot模型，用于文档级多模态理解，解决了现有方法的局限性，并在实验中取得了更好的效果。


<details>
  <summary>Details</summary>
Motivation: 解决当前多模态大语言模型在复杂、多页文档理解方面的不足，以及现有RAG方法存在的碎片化检索上下文、多阶段错误累积和额外检索时间成本等问题。

Method: 提出Doc-750K数据集，构建Docopilot模型，该模型无需依赖RAG即可准确处理文档级依赖关系。

Result: Doc-750K数据集包含多样化的文档结构、广泛的跨页依赖关系以及源自原始文档的真实问答对。Docopilot在文档理解任务和多轮交互中表现优于现有方法。

Conclusion: Docopilot在文档理解任务和多轮交互中实现了卓越的连贯性、准确性和效率，为文档级多模态理解树立了新的基准。

Abstract: Despite significant progress in multimodal large language models (MLLMs),
their performance on complex, multi-page document comprehension remains
inadequate, largely due to the lack of high-quality, document-level datasets.
While current retrieval-augmented generation (RAG) methods offer partial
solutions, they suffer from issues, such as fragmented retrieval contexts,
multi-stage error accumulation, and extra time costs of retrieval. In this
work, we present a high-quality document-level dataset, Doc-750K, designed to
support in-depth understanding of multimodal documents. This dataset includes
diverse document structures, extensive cross-page dependencies, and real
question-answer pairs derived from the original documents. Building on the
dataset, we develop a native multimodal model, Docopilot, which can accurately
handle document-level dependencies without relying on RAG. Experiments
demonstrate that Docopilot achieves superior coherence, accuracy, and
efficiency in document understanding tasks and multi-turn interactions, setting
a new baseline for document-level multimodal understanding. Data, code, and
models are released at https://github.com/OpenGVLab/Docopilot

</details>


### [39] [WSI-Agents: A Collaborative Multi-Agent System for Multi-Modal Whole Slide Image Analysis](https://arxiv.org/abs/2507.14680)
*Xinheng Lyu,Yuci Liang,Wenting Chen,Meidan Ding,Jiaqi Yang,Guolin Huang,Daokun Zhang,Xiangjian He,Linlin Shen*

Main category: cs.CV

TL;DR: WSI-Agents 是一个协作多代理系统，通过整合专业代理和验证机制，提高了 WSI 分析的准确性和多任务处理能力。


<details>
  <summary>Details</summary>
Motivation: 为了解决多模态大语言模型（MLLMs）在 WSI 分析中表现不如特定任务模型以及协作多代理系统在病理学领域应用潜力未被充分探索的问题。

Method: 提出了一种名为 WSI-Agents 的新型协作多代理系统，该系统集成了专门的功能代理、任务分配和验证机制，并包含任务分配模块、验证机制和汇总模块。

Result: 在多模态 WSI 基准测试的广泛实验中，WSI-Agents 在各种任务上均显示出优于当前 WSI MLLMs 和医学代理框架的性能。

Conclusion: WSI-Agents 在多模态 WSI 分析任务中表现优于现有的 WSI MLLMs 和医学代理框架。

Abstract: Whole slide images (WSIs) are vital in digital pathology, enabling gigapixel
tissue analysis across various pathological tasks. While recent advancements in
multi-modal large language models (MLLMs) allow multi-task WSI analysis through
natural language, they often underperform compared to task-specific models.
Collaborative multi-agent systems have emerged as a promising solution to
balance versatility and accuracy in healthcare, yet their potential remains
underexplored in pathology-specific domains. To address these issues, we
propose WSI-Agents, a novel collaborative multi-agent system for multi-modal
WSI analysis. WSI-Agents integrates specialized functional agents with robust
task allocation and verification mechanisms to enhance both task-specific
accuracy and multi-task versatility through three components: (1) a task
allocation module assigning tasks to expert agents using a model zoo of patch
and WSI level MLLMs, (2) a verification mechanism ensuring accuracy through
internal consistency checks and external validation using pathology knowledge
bases and domain-specific models, and (3) a summary module synthesizing the
final summary with visual interpretation maps. Extensive experiments on
multi-modal WSI benchmarks show WSI-Agents's superiority to current WSI MLLMs
and medical agent frameworks across diverse tasks.

</details>


### [40] [From Semantics, Scene to Instance-awareness: Distilling Foundation Model for Open-vocabulary Situation Recognition](https://arxiv.org/abs/2507.14686)
*Chen Cai,Tianyi Liu,Jianjun Gao,Wenyang Liu,Kejun Wu,Ruoyu Wang,Yi Wang,Soo Chin Liew*

Main category: cs.CV

TL;DR: MIPD通过知识蒸馏增强了GSR模型的泛化和零样本能力，以识别未见和罕见的场景。


<details>
  <summary>Details</summary>
Motivation: 为了解决现有MLLM在复杂GSR任务上的不足以及它们在边缘设备部署上的资源密集性问题，并克服传统GSR模型泛化能力不足、难以识别未知和罕见场景的缺点。

Method: 提出了一种名为多模态交互提示蒸馏（MIPD）的新框架，该框架利用LLM驱动的判断性原理生成器（JRG）和负引导多模态提示对齐（NMPA）模块，将知识从教师MLLM转移到小型GSR模型，以增强其泛化能力和零样本能力。

Result: MIPD框架能够识别未见过的场景，并且更好地识别罕见的场景，最终的GSR模型具有更强的泛化能力，能够更好地理解场景，缩小已见与未见场景之间的差距，并减轻罕见情况下的预测偏差。

Conclusion: MIPD框架在Ov-SWiG数据集上取得了优于以往的性能，在已见、罕见和未见的情况下均表现出色，并在HICO-DET数据集上进一步证明了其在未见检测方面的改进。

Abstract: Recent Multimodal Large Language Models (MLLMs) exhibit strong zero-shot
abilities but struggle with complex Grounded Situation Recognition (GSR) and
are resource-intensive for edge device deployment. Meanwhile, conventional GSR
models often lack generalization ability, falling short in recognizing unseen
and rare situations. In this paper, we exploit transferring knowledge from a
teacher MLLM to a small GSR model to enhance its generalization and zero-shot
abilities, thereby introducing the task of Open-vocabulary Grounded Situation
Recognition (Ov-GSR). To achieve this, we propose Multimodal Interactive Prompt
Distillation (MIPD), a novel framework that distills enriched multimodal
knowledge from the foundation model, enabling the student Ov-GSR model to
recognize unseen situations and be better aware of rare situations.
Specifically, the MIPD framework first leverages the LLM-based Judgmental
Rationales Generator (JRG) to construct positive and negative glimpse and gaze
rationales enriched with contextual semantic information. The proposed
scene-aware and instance-perception prompts are then introduced to align
rationales with visual information from the MLLM teacher via the
Negative-Guided Multimodal Prompting Alignment (NMPA) module, effectively
capturing holistic and perceptual multimodal knowledge. Finally, the aligned
multimodal knowledge is distilled into the student Ov-GSR model, providing a
stronger foundation for generalization that enhances situation understanding,
bridges the gap between seen and unseen scenarios, and mitigates prediction
bias in rare cases. We evaluate MIPD on the refined Ov-SWiG dataset, achieving
superior performance on seen, rare, and unseen situations, and further
demonstrate improved unseen detection on the HICO-DET dataset.

</details>


### [41] [GTPBD: A Fine-Grained Global Terraced Parcel and Boundary Dataset](https://arxiv.org/abs/2507.14697)
*Zhiwei Zhang,Zi Ye,Yibin Wen,Shuai Yuan,Haohuan Fu,Jianxi Huang,Juepeng Zheng*

Main category: cs.CV

TL;DR: GTPBD是一个新的精细梯田地块数据集，包含超过20万个地块，用于解决现有数据集在复杂梯田地形表示方面的不足，并支持多种遥感任务。


<details>
  <summary>Details</summary>
Motivation: 现有的农业地块提取研究仅关注中等分辨率测绘或规则的平原农田，而缺乏对复杂梯田地形的表示，这与精准农业的需求不符。

Method: 提出了一种名为GTPBD（全球梯田地块和边界数据集）的数据集，该数据集是第一个涵盖全球主要梯田区域的精细数据集，包含超过20万个手工标注的复杂梯田地块。GTPBD包含47,537张高分辨率图像，具有三个级别的标签：像素级边界标签、掩码标签和地块标签。它涵盖了中国七个主要地理区域和全球大陆性气候区域。对GTPBD数据集进行了基准测试，包括八种语义分割方法、四种边缘提取方法、三种地块提取方法和五种无监督域适应（UDA）方法，并结合了整合像素级和对象级指标的多维度评估框架。

Result: GTPBD数据集包含超过20万个复杂梯田地块，具有像素级边界标签、掩码标签和地块标签，适用于语义分割、边缘检测、梯田地块提取和无监督域适应（UDA）任务，并进行了多种方法的基准测试。

Conclusion: GTPBD填补了梯田遥感研究的关键空白，为精细农业地形分析和跨场景知识转移提供了基础架构。

Abstract: Agricultural parcels serve as basic units for conducting agricultural
practices and applications, which is vital for land ownership registration,
food security assessment, soil erosion monitoring, etc. However, existing
agriculture parcel extraction studies only focus on mid-resolution mapping or
regular plain farmlands while lacking representation of complex terraced
terrains due to the demands of precision agriculture.In this paper, we
introduce a more fine-grained terraced parcel dataset named GTPBD (Global
Terraced Parcel and Boundary Dataset), which is the first fine-grained dataset
covering major worldwide terraced regions with more than 200,000 complex
terraced parcels with manual annotation. GTPBD comprises 47,537 high-resolution
images with three-level labels, including pixel-level boundary labels, mask
labels, and parcel labels. It covers seven major geographic zones in China and
transcontinental climatic regions around the world.Compared to the existing
datasets, the GTPBD dataset brings considerable challenges due to the: (1)
terrain diversity; (2) complex and irregular parcel objects; and (3) multiple
domain styles. Our proposed GTPBD dataset is suitable for four different tasks,
including semantic segmentation, edge detection, terraced parcel extraction,
and unsupervised domain adaptation (UDA) tasks.Accordingly, we benchmark the
GTPBD dataset on eight semantic segmentation methods, four edge extraction
methods, three parcel extraction methods, and five UDA methods, along with a
multi-dimensional evaluation framework integrating pixel-level and object-level
metrics. GTPBD fills a critical gap in terraced remote sensing research,
providing a basic infrastructure for fine-grained agricultural terrain analysis
and cross-scenario knowledge transfer.

</details>


### [42] [MultiRetNet: A Multimodal Vision Model and Deferral System for Staging Diabetic Retinopathy](https://arxiv.org/abs/2507.14738)
*Jeannie She,Katie Spivakovsky*

Main category: cs.CV

TL;DR: MultiRetNet 通过结合眼底图像、社会经济和合并症数据，提高糖尿病视网膜病变分期准确性，并通过对比学习和临床推迟系统改善服务欠缺群体的早期检测。


<details>
  <summary>Details</summary>
Motivation: 糖尿病视网膜病变（DR）是可预防失明的主要原因，尤其是在低收入社区，由于筛查机会有限，患者更有可能在诊断前发展到晚期阶段。本研究旨在通过整合多模态数据和临床推迟系统来提高 DR 的早期检测和分期准确性，特别关注服务欠缺的群体。

Method: 本研究提出了一种名为 MultiRetNet 的新颖流程，结合了三种多模态融合方法，并通过对比学习训练推迟系统，以识别需要临床医生审查的分布外样本。

Result: 通过对比学习训练的推迟系统，在欠佳图像上保持了诊断准确性，并整合了关键健康数据，有望降低医疗成本，提高早期检测率，促进医疗公平。

Conclusion: 该方法通过结合视网膜成像、社会经济因素和合并症信息，提高糖尿病视网膜病变分期准确性，并整合了临床推迟系统，以实现临床人类在循环实现。通过保持在欠佳图像上的诊断准确性并整合关键健康数据，该系统可以改善早期检测，尤其是在服务欠缺的地区，从而降低医疗成本，提高早期检测率，解决医疗公平性问题。

Abstract: Diabetic retinopathy (DR) is a leading cause of preventable blindness,
affecting over 100 million people worldwide. In the United States, individuals
from lower-income communities face a higher risk of progressing to advanced
stages before diagnosis, largely due to limited access to screening. Comorbid
conditions further accelerate disease progression. We propose MultiRetNet, a
novel pipeline combining retinal imaging, socioeconomic factors, and
comorbidity profiles to improve DR staging accuracy, integrated with a clinical
deferral system for a clinical human-in-the-loop implementation. We experiment
with three multimodal fusion methods and identify fusion through a fully
connected layer as the most versatile methodology. We synthesize adversarial,
low-quality images and use contrastive learning to train the deferral system,
guiding the model to identify out-of-distribution samples that warrant
clinician review. By maintaining diagnostic accuracy on suboptimal images and
integrating critical health data, our system can improve early detection,
particularly in underserved populations where advanced DR is often first
identified. This approach may reduce healthcare costs, increase early detection
rates, and address disparities in access to care, promoting healthcare equity.

</details>


### [43] [InterAct-Video: Reasoning-Rich Video QA for Urban Traffic](https://arxiv.org/abs/2507.14743)
*Joseph Raj Vishal,Rutuja Patil,Manas Srinivas Gowda,Katha Naik,Yezhou Yang,Bharatesh Chakravarthi*

Main category: cs.CV

TL;DR: 本研究提出了InterAct VideoQA数据集，以解决现有视频问答模型在处理复杂交通场景时的不足。实验表明，该数据集有助于提升模型性能，并为未来在智能交通系统中的视频问答研究提供了基准。


<details>
  <summary>Details</summary>
Motivation: 现有的视频问答模型在处理真实交通场景的复杂性方面存在困难，这些场景通常涉及跨越时空的多个并发事件。为了解决这些挑战并推动智能交通系统的视频问答研究，需要一个专门的数据集。

Method: 提出InterAct VideoQA数据集，包含8小时真实交通视频，分割成10秒片段，并提供超过25,000个问答对，涵盖时空动态、车辆交互、事件检测等交通属性。评估并微调了现有的视频问答模型。

Result: 在InterAct VideoQA数据集上，现有的视频问答模型在推理细粒度的时空依赖关系方面面临挑战。然而，通过在该数据集上进行微调，这些模型的性能得到了显著提升。

Conclusion: 该研究介绍了InterAct VideoQA数据集，并评估了现有视频问答模型在该数据集上的表现。结果表明，现有模型在处理复杂的交通场景时存在挑战，但通过在该数据集上进行微调，可以显著提升模型性能，证明了领域特定数据集对于视频问答的重要性。

Abstract: Traffic monitoring is crucial for urban mobility, road safety, and
intelligent transportation systems (ITS). Deep learning has advanced
video-based traffic monitoring through video question answering (VideoQA)
models, enabling structured insight extraction from traffic videos. However,
existing VideoQA models struggle with the complexity of real-world traffic
scenes, where multiple concurrent events unfold across spatiotemporal
dimensions. To address these challenges, this paper introduces \textbf{InterAct
VideoQA}, a curated dataset designed to benchmark and enhance VideoQA models
for traffic monitoring tasks. The InterAct VideoQA dataset comprises 8 hours of
real-world traffic footage collected from diverse intersections, segmented into
10-second video clips, with over 25,000 question-answer (QA) pairs covering
spatiotemporal dynamics, vehicle interactions, incident detection, and other
critical traffic attributes. State-of-the-art VideoQA models are evaluated on
InterAct VideoQA, exposing challenges in reasoning over fine-grained
spatiotemporal dependencies within complex traffic scenarios. Additionally,
fine-tuning these models on InterAct VideoQA yields notable performance
improvements, demonstrating the necessity of domain-specific datasets for
VideoQA. InterAct VideoQA is publicly available as a benchmark dataset to
facilitate future research in real-world deployable VideoQA models for
intelligent transportation systems. GitHub Repo:
https://github.com/joe-rabbit/InterAct_VideoQA

</details>


### [44] [LeAdQA: LLM-Driven Context-Aware Temporal Grounding for Video Question Answering](https://arxiv.org/abs/2507.14784)
*Xinxin Dong,Baoyun Peng,Haokai Ma,Yufei Wang,Zixuan Dong,Fei Hu,Xiaodong Wang*

Main category: cs.CV

TL;DR: LeAdQA 通过利用 LLM 细化视频问答中的问题，并结合精确的视觉基础来识别关键时刻，从而提高了回答复杂问题的准确性和效率。


<details>
  <summary>Details</summary>
Motivation: 解决当前视频问答方法在处理长视频中的稀疏关键时刻和推理其因果关系以回答复杂问题方面的局限性，这些方法受限于（1）任务无关的采样（处理所有帧，用无关内容压倒关键事件）和（2）启发式检索（捕获表面模式但忽略因果时间结构）。

Method: LeAdQA 方法首先利用 LLM 改革问题-选项对，解决因果模糊性并聚焦时间。然后，这些改进的查询指导时间基础模型精确检索最显著的片段，并辅以自适应融合机制以最大化相关性。最后，通过 MLLM 处理集成的视觉-文本线索来生成准确的、与上下文相关的答案。

Result: 在 NExT-QA、IntentQA 和 NExT-GQA 数据集上的实验表明，LeAdQA 的精确视觉基础显著增强了视频-问题关系的理解，在复杂推理任务上达到了 SOTA 性能，同时保持了计算效率。

Conclusion: LeAdQA 通过因果感知查询细化和细粒度视觉基础相结合，实现了视频问答的最新（SOTA）性能，特别是在复杂推理任务上，同时保持了计算效率。

Abstract: Video Question Answering (VideoQA) requires identifying sparse critical
moments in long videos and reasoning about their causal relationships to answer
semantically complex questions. While recent advances in multimodal learning
have improved alignment and fusion, current approaches remain limited by two
prevalent but fundamentally flawed strategies: (1) task-agnostic sampling
indiscriminately processes all frames, overwhelming key events with irrelevant
content; and (2) heuristic retrieval captures superficial patterns but misses
causal-temporal structures needed for complex reasoning. To address these
challenges, we introduce LeAdQA, an innovative approach that bridges these gaps
through synergizing causal-aware query refinement with fine-grained visual
grounding. Our method first leverages LLMs to reformulate question-option
pairs, resolving causal ambiguities and sharpening temporal focus. These
refined queries subsequently direct a temporal grounding model to precisely
retrieve the most salient segments, complemented by an adaptive fusion
mechanism dynamically integrating the evidence to maximize relevance. The
integrated visual-textual cues are then processed by an MLLM to generate
accurate, contextually-grounded answers. Experiments on NExT-QA, IntentQA, and
NExT-GQA demonstrate that our method's precise visual grounding substantially
enhances the understanding of video-question relationships, achieving
state-of-the-art (SOTA) performance on complex reasoning tasks while
maintaining computational efficiency.

</details>


### [45] [FOCUS: Fused Observation of Channels for Unveiling Spectra](https://arxiv.org/abs/2507.14787)
*Xi Xiao,Aristeidis Tsaris,Anika Tabassum,John Lagergren,Larry M. York,Tianyang Wang,Xiao Wang*

Main category: cs.CV

TL;DR: "FOCUS enables practical and accurate spatial-spectral interpretability for Vision Transformers in hyperspectral imaging by using spectral prompts and a learnable SINK token to guide attention, overcoming challenges of spectral cue interpretation and computational cost."


<details>
  <summary>Details</summary>
Motivation: "Interpreting Vision Transformers (ViTs) in hyperspectral imaging (HSI) is challenging due to: 1. Existing saliency methods failing to capture meaningful spectral cues, often focusing solely on the class token. 2. Full-spectrum ViTs being computationally expensive for interpretability given HSI's high-dimensional nature."

Method: "FOCUS utilizes two core components: 1. Class-specific spectral prompts: These guide the attention mechanism towards semantically meaningful wavelength groups within the hyperspectral data. 2. A learnable [SINK] token: This token is trained with an attraction loss to absorb noisy or redundant attention, effectively cleaning up the interpretability signals."

Result: "FOCUS achieves stable and interpretable 3D saliency maps and spectral importance curves in a single forward pass, without gradient backpropagation or backbone modification. It improves band-level IoU by 15%, reduces attention collapse by over 40%, and generates saliency results that closely align with expert annotations."

Conclusion: "FOCUS is the first framework enabling reliable and efficient spatial-spectral interpretability for frozen ViTs in hyperspectral imaging. It introduces class-specific spectral prompts and a learnable [SINK] token to guide attention, producing stable and interpretable 3D saliency maps and spectral importance curves. FOCUS improves band-level IoU by 15%, reduces attention collapse by over 40%, aligns with expert annotations, and has less than 1% parameter overhead, making high-resolution ViT interpretability practical for real-world hyperspectral applications."

Abstract: Hyperspectral imaging (HSI) captures hundreds of narrow, contiguous
wavelength bands, making it a powerful tool in biology, agriculture, and
environmental monitoring. However, interpreting Vision Transformers (ViTs) in
this setting remains largely unexplored due to two key challenges: (1) existing
saliency methods struggle to capture meaningful spectral cues, often collapsing
attention onto the class token, and (2) full-spectrum ViTs are computationally
prohibitive for interpretability, given the high-dimensional nature of HSI
data. We present FOCUS, the first framework that enables reliable and efficient
spatial-spectral interpretability for frozen ViTs. FOCUS introduces two core
components: class-specific spectral prompts that guide attention toward
semantically meaningful wavelength groups, and a learnable [SINK] token trained
with an attraction loss to absorb noisy or redundant attention. Together, these
designs make it possible to generate stable and interpretable 3D saliency maps
and spectral importance curves in a single forward pass, without any gradient
backpropagation or backbone modification. FOCUS improves band-level IoU by 15
percent, reduces attention collapse by over 40 percent, and produces saliency
results that align closely with expert annotations. With less than 1 percent
parameter overhead, our method makes high-resolution ViT interpretability
practical for real-world hyperspectral applications, bridging a long-standing
gap between black-box modeling and trustworthy HSI decision-making.

</details>


### [46] [A Novel Downsampling Strategy Based on Information Complementarity for Medical Image Segmentation](https://arxiv.org/abs/2507.14790)
*Wenbo Yue,Chang Li,Guoping Xu*

Main category: cs.CV

TL;DR: HPD是一种新的下采样方法，通过MinMaxPooling保留更多空间信息，在语义分割任务中提升了精度。


<details>
  <summary>Details</summary>
Motivation: 传统的下采样方法（如最大池化和跨行卷积）在特征聚合、感受野扩展和计算约简方面表现良好，但在语义分割任务中可能会丢失关键的空间信息，从而影响像素级预测精度。

Method: 提出了一种基于信息互补的下采样方法——混合池化下采样（HPD），并使用MinMaxPooling来替代传统方法，通过提取局部区域的最大值信息来有效保留图像的明暗对比度和细节特征。

Result: 在ACDC和Synapse数据集上的各种CNN架构上进行的实验表明，HPD在分割性能上优于传统方法，平均将DSC系数提高了0.5%。

Conclusion: HPD模块为语义分割任务提供了一个有效的解决方案，在DSC系数上平均提高了0.5%

Abstract: In convolutional neural networks (CNNs), downsampling operations are crucial
to model performance. Although traditional downsampling methods (such as
maximum pooling and cross-row convolution) perform well in feature aggregation,
receptive field expansion, and computational reduction, they may lead to the
loss of key spatial information in semantic segmentation tasks, thereby
affecting the pixel-by-pixel prediction accuracy.To this end, this study
proposes a downsampling method based on information complementarity - Hybrid
Pooling Downsampling (HPD). The core is to replace the traditional method with
MinMaxPooling, and effectively retain the light and dark contrast and detail
features of the image by extracting the maximum value information of the local
area.Experiment on various CNN architectures on the ACDC and Synapse datasets
show that HPD outperforms traditional methods in segmentation performance, and
increases the DSC coefficient by 0.5% on average. The results show that the HPD
module provides an efficient solution for semantic segmentation tasks.

</details>


### [47] [Light Future: Multimodal Action Frame Prediction via InstructPix2Pix](https://arxiv.org/abs/2507.14809)
*Zesen Zhong,Duomin Zhang,Yijia Li*

Main category: cs.CV

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Predicting future motion trajectories is a critical capability across domains
such as robotics, autonomous systems, and human activity forecasting, enabling
safer and more intelligent decision-making. This paper proposes a novel,
efficient, and lightweight approach for robot action prediction, offering
significantly reduced computational cost and inference latency compared to
conventional video prediction models. Importantly, it pioneers the adaptation
of the InstructPix2Pix model for forecasting future visual frames in robotic
tasks, extending its utility beyond static image editing. We implement a deep
learning-based visual prediction framework that forecasts what a robot will
observe 100 frames (10 seconds) into the future, given a current image and a
textual instruction. We repurpose and fine-tune the InstructPix2Pix model to
accept both visual and textual inputs, enabling multimodal future frame
prediction. Experiments on the RoboTWin dataset (generated based on real-world
scenarios) demonstrate that our method achieves superior SSIM and PSNR compared
to state-of-the-art baselines in robot action prediction tasks. Unlike
conventional video prediction models that require multiple input frames, heavy
computation, and slow inference latency, our approach only needs a single image
and a text prompt as input. This lightweight design enables faster inference,
reduced GPU demands, and flexible multimodal control, particularly valuable for
applications like robotics and sports motion trajectory analytics, where motion
trajectory precision is prioritized over visual fidelity.

</details>


### [48] [Distilling Parallel Gradients for Fast ODE Solvers of Diffusion Models](https://arxiv.org/abs/2507.14797)
*Beier Zhu,Ruoyu Wang,Tong Zhao,Hanwang Zhang,Chi Zhang*

Main category: cs.CV

TL;DR: EPD is a novel ODE solver that accelerates diffusion models by parallelizing gradient evaluations, achieving high-quality results with low latency and outperforming existing methods.


<details>
  <summary>Details</summary>
Motivation: Diffusion models suffer from high sampling latency due to their sequential denoising nature, and existing acceleration methods often degrade image quality under low-latency constraints.

Method: EPD incorporates multiple parallel gradient evaluations in each ODE step to mitigate truncation errors, allowing for fully parallelized additional gradient computations to preserve low-latency sampling. It optimizes a small set of learnable parameters in a distillation fashion.

Result: EPD achieves state-of-the-art performance in low-latency sampling, surpassing existing learning-based solvers. For instance, at 5 NFE, EPD achieves FID scores of 4.47 on CIFAR-10, 7.97 on FFHQ, 8.17 on ImageNet, and 8.26 on LSUN Bedroom.

Conclusion: Our method, Ensemble Parallel Direction solver (EPD), achieves high-quality and low-latency sampling by mitigating truncation errors through parallel gradient evaluations in each ODE step. It optimizes learnable parameters with minimal training overhead and can be used as a plugin for existing ODE samplers.

Abstract: Diffusion models (DMs) have achieved state-of-the-art generative performance
but suffer from high sampling latency due to their sequential denoising nature.
Existing solver-based acceleration methods often face image quality degradation
under a low-latency budget. In this paper, we propose the Ensemble Parallel
Direction solver (dubbed as \ours), a novel ODE solver that mitigates
truncation errors by incorporating multiple parallel gradient evaluations in
each ODE step. Importantly, since the additional gradient computations are
independent, they can be fully parallelized, preserving low-latency sampling.
  Our method optimizes a small set of learnable parameters in a distillation
fashion, ensuring minimal training overhead.
  In addition, our method can serve as a plugin to improve existing ODE
samplers. Extensive experiments on various image synthesis benchmarks
demonstrate the effectiveness of our \ours~in achieving high-quality and
low-latency sampling. For example, at the same latency level of 5 NFE, EPD
achieves an FID of 4.47 on CIFAR-10, 7.97 on FFHQ, 8.17 on ImageNet, and 8.26
on LSUN Bedroom, surpassing existing learning-based solvers by a significant
margin. Codes are available in https://github.com/BeierZhu/EPD.

</details>


### [49] [An Evaluation of DUSt3R/MASt3R/VGGT 3D Reconstruction on Photogrammetric Aerial Blocks](https://arxiv.org/abs/2507.14798)
*Xinyi Wu,Steven Landgraf,Markus Ulrich,Rongjun Qin*

Main category: cs.CV

TL;DR: DUSt3R/MASt3R/VGGT 等基于 Transformer 的 3D 重建方法在稀疏、低分辨率航空影像集上表现出色，但并非传统 SfM/MVS 方法的完全替代品。


<details>
  <summary>Details</summary>
Motivation: 评估 DUSt3R/MASt3R/VGGT 等先进的 3D 重建基础模型在航空影像集上的潜力，特别是在处理稀疏影像重叠、立体遮挡和纹理缺失等挑战性场景下的表现。

Method: 对预训练的 DUSt3R/MASt3R/VGGT 模型在 UseGeo 数据集的航空影像块上进行了全面的评估，重点关注位姿估计和密集 3D 重建。

Result: 与 COLMAP 相比，DUSt3R/MASt3R/VGGT 在非常稀疏的影像集（少于 10 张图像，分辨率高达 518 像素）上能够准确地重建密集点云，完整性提高高达 50%。VGGT 在计算效率、可扩展性和相机位姿估计的可靠性方面表现更优。然而，所有模型在高分辨率图像和大型数据集上面临局限性，随着图像数量的增加和几何复杂性的提高，位姿的可靠性会下降。

Conclusion:  transformer-based 方法（DUSt3R/MASt3R/VGGT）在低分辨率、稀疏的航空影像集上表现出有前景的性能，但在高分辨率和大规模数据集上面临挑战，不能完全取代传统的 SfM 和 MVS 方法，可作为其补充。

Abstract: State-of-the-art 3D computer vision algorithms continue to advance in
handling sparse, unordered image sets. Recently developed foundational models
for 3D reconstruction, such as Dense and Unconstrained Stereo 3D Reconstruction
(DUSt3R), Matching and Stereo 3D Reconstruction (MASt3R), and Visual Geometry
Grounded Transformer (VGGT), have attracted attention due to their ability to
handle very sparse image overlaps. Evaluating DUSt3R/MASt3R/VGGT on typical
aerial images matters, as these models may handle extremely low image overlaps,
stereo occlusions, and textureless regions. For redundant collections, they can
accelerate 3D reconstruction by using extremely sparsified image sets. Despite
tests on various computer vision benchmarks, their potential on photogrammetric
aerial blocks remains unexplored. This paper conducts a comprehensive
evaluation of the pre-trained DUSt3R/MASt3R/VGGT models on the aerial blocks of
the UseGeo dataset for pose estimation and dense 3D reconstruction. Results
show these methods can accurately reconstruct dense point clouds from very
sparse image sets (fewer than 10 images, up to 518 pixels resolution), with
completeness gains up to +50% over COLMAP. VGGT also demonstrates higher
computational efficiency, scalability, and more reliable camera pose
estimation. However, all exhibit limitations with high-resolution images and
large sets, as pose reliability declines with more images and geometric
complexity. These findings suggest transformer-based methods cannot fully
replace traditional SfM and MVS, but offer promise as complementary approaches,
especially in challenging, low-resolution, and sparse scenarios.

</details>


### [50] [EBA-AI: Ethics-Guided Bias-Aware AI for Efficient Underwater Image Enhancement and Coral Reef Monitoring](https://arxiv.org/abs/2507.15036)
*Lyes Saad Saoud,Irfan Hussain*

Main category: cs.CV

TL;DR: EBA-AI是一个AI框架，用于水下图像增强，它解决了数据集偏差、高计算成本和缺乏透明度的问题，同时实现了效率、公平性和可解释性的平衡。


<details>
  <summary>Details</summary>
Motivation: 水下图像增强对于海洋保护至关重要，特别是在珊瑚礁监测方面。然而，目前基于AI的增强模型常常面临数据集偏差、高计算成本和缺乏透明度等问题，这些问题可能导致错误的解读。

Method: EBA-AI框架利用CLIP嵌入来检测和减轻数据集偏差，确保跨不同水下环境的均衡表示。它还集成了自适应处理以优化能源效率，显著降低GPU使用率，同时保持具有竞争力的增强质量。

Result: 在LSUI400、Oceanex和UIEB100上的实验表明，虽然PSNR下降了1.0 dB，但计算节省使得大规模海洋监测的实时可行性成为可能。此外，不确定性估计和可解释性技术增强了对AI驱动的环境决策的信任。与CycleGAN、FunIEGAN、RAUNENet、WaterNet、UGAN、PUGAN和UTUIE的比较验证了EBA-AI在平衡水下图像处理中的效率、公平性和可解释性方面的有效性。

Conclusion: EBA-AI框架通过利用CLIP嵌入来检测和减轻数据集偏差，并集成自适应处理以优化能源效率，显著降低GPU使用率，同时保持具有竞争力的增强质量，解决了AI驱动的增强模型中存在的数据集偏差、高计算成本和缺乏透明度的问题。实验表明，虽然PSNR会受到1.0 dB的控制性下降，但计算节省使得大规模海洋监测的实时可行性成为可能。此外，不确定性估计和可解释性技术增强了对AI驱动的环境决策的信任。

Abstract: Underwater image enhancement is vital for marine conservation, particularly
coral reef monitoring. However, AI-based enhancement models often face dataset
bias, high computational costs, and lack of transparency, leading to potential
misinterpretations. This paper introduces EBA-AI, an ethics-guided bias-aware
AI framework to address these challenges. EBA-AI leverages CLIP embeddings to
detect and mitigate dataset bias, ensuring balanced representation across
varied underwater environments. It also integrates adaptive processing to
optimize energy efficiency, significantly reducing GPU usage while maintaining
competitive enhancement quality. Experiments on LSUI400, Oceanex, and UIEB100
show that while PSNR drops by a controlled 1.0 dB, computational savings enable
real-time feasibility for large-scale marine monitoring. Additionally,
uncertainty estimation and explainability techniques enhance trust in AI-driven
environmental decisions. Comparisons with CycleGAN, FunIEGAN, RAUNENet,
WaterNet, UGAN, PUGAN, and UTUIE validate EBA-AI's effectiveness in balancing
efficiency, fairness, and interpretability in underwater image processing. By
addressing key limitations of AI-driven enhancement, this work contributes to
sustainable, bias-aware, and computationally efficient marine conservation
efforts. For interactive visualizations, animations, source code, and access to
the preprint, visit: https://lyessaadsaoud.github.io/EBA-AI/

</details>


### [51] [Exploring Scalable Unified Modeling for General Low-Level Vision](https://arxiv.org/abs/2507.14801)
*Xiangyu Chen,Kaiwen Zhu,Yuandong Pu,Shuo Cao,Xiaohui Li,Wenlong Zhang,Yihao Liu,Yu Qiao,Jiantao Zhou,Chao Dong*

Main category: cs.CV

TL;DR: 提出了一种新的VPIP框架和GenLV模型，实现了统一的低级视觉任务处理，并在多任务、可扩展性和适应性方面取得了优异成果。


<details>
  <summary>Details</summary>
Motivation: 低级视觉任务（如图像恢复、增强、风格化和特征提取）在任务形式和输出域上存在显著差异，为实现跨这些多样化任务的统一建模带来了挑战。

Method: 提出了一种名为视觉任务提示图像处理（VPIP）的框架，该框架利用输入-目标图像对作为视觉提示来引导模型执行各种低级视觉任务。该框架包含一个端到端的图像处理骨干网络、一个提示编码器和一个提示交互模块。基于此框架，开发了一个统一的低级视觉模型GenLV，并在多个代表性任务上进行了评估。通过扩展模型容量和任务多样性，并在包含100多个低级视觉任务的大型基准上进行训练，验证了该方法的扩展性。

Result: 实验结果表明，所提出的方法在广泛的任务中取得了相当可观的性能。特别是，增加训练任务的数量可以提高泛化能力，对于数据有限的任务尤其如此。该模型在零样本泛化、少样本迁移和特定任务微调场景中的表现也证实了其强大的适应性。

Conclusion: 该研究提出的视觉任务提示图像处理（VPIP）框架及其统一模型GenLV在多种低级视觉任务中表现出强大的性能、可扩展性和适应性，证明了其作为通用低级视觉建模的有效基础的潜力。

Abstract: Low-level vision involves a wide spectrum of tasks, including image
restoration, enhancement, stylization, and feature extraction, which differ
significantly in both task formulation and output domains. To address the
challenge of unified modeling across such diverse tasks, we propose a Visual
task Prompt-based Image Processing (VPIP) framework that leverages input-target
image pairs as visual prompts to guide the model in performing a variety of
low-level vision tasks. The framework comprises an end-to-end image processing
backbone, a prompt encoder, and a prompt interaction module, enabling flexible
integration with various architectures and effective utilization of
task-specific visual representations. Based on this design, we develop a
unified low-level vision model, GenLV, and evaluate its performance across
multiple representative tasks. To explore the scalability of this approach, we
extend the framework along two dimensions: model capacity and task diversity.
We construct a large-scale benchmark consisting of over 100 low-level vision
tasks and train multiple versions of the model with varying scales.
Experimental results show that the proposed method achieves considerable
performance across a wide range of tasks. Notably, increasing the number of
training tasks enhances generalization, particularly for tasks with limited
data, indicating the model's ability to learn transferable representations
through joint training. Further evaluations in zero-shot generalization,
few-shot transfer, and task-specific fine-tuning scenarios demonstrate the
model's strong adaptability, confirming the effectiveness, scalability, and
potential of the proposed framework as a unified foundation for general
low-level vision modeling.

</details>


### [52] [Visual Place Recognition for Large-Scale UAV Applications](https://arxiv.org/abs/2507.15089)
*Ioannis Tsampikos Papapetros,Ioannis Kansizoglou,Antonios Gasteratos*

Main category: cs.CV

TL;DR: 提出LASED数据集和可定向CNN解决了航空视觉场所识别的挑战，提高了模型的鲁棒性和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 解决航空视觉场所识别（vPR）面临的挑战，包括大规模、高海拔数据集的可用性有限以及UAV图像固有的旋转歧义性。

Method: 提出了一种名为LASED的大规模航空数据集，包含约100万张图像，并集成了可定向卷积神经网络（CNN）以处理旋转不变性。

Result: 在LASED上训练的模型比在较小、多样性较低的数据集上训练的模型具有更高的召回率，并且可定向CNN在处理旋转歧义方面表现优于传统的卷积架构，平均召回率提高了12%。

Conclusion: 通过结合结构化、大规模数据集和旋转等变神经网络，该方法显著提高了航空视觉场所识别模型的鲁棒性和泛化能力。

Abstract: Visual Place Recognition (vPR) plays a crucial role in Unmanned Aerial
Vehicle (UAV) navigation, enabling robust localization across diverse
environments. Despite significant advancements, aerial vPR faces unique
challenges due to the limited availability of large-scale, high-altitude
datasets, which limits model generalization, along with the inherent rotational
ambiguity in UAV imagery. To address these challenges, we introduce LASED, a
large-scale aerial dataset with approximately one million images,
systematically sampled from 170,000 unique locations throughout Estonia over a
decade, offering extensive geographic and temporal diversity. Its structured
design ensures clear place separation significantly enhancing model training
for aerial scenarios. Furthermore, we propose the integration of steerable
Convolutional Neural Networks (CNNs) to explicitly handle rotational variance,
leveraging their inherent rotational equivariance to produce robust,
orientation-invariant feature representations. Our extensive benchmarking
demonstrates that models trained on LASED achieve significantly higher recall
compared to those trained on smaller, less diverse datasets, highlighting the
benefits of extensive geographic coverage and temporal diversity. Moreover,
steerable CNNs effectively address rotational ambiguity inherent in aerial
imagery, consistently outperforming conventional convolutional architectures,
achieving on average 12\% recall improvement over the best-performing
non-steerable network. By combining structured, large-scale datasets with
rotation-equivariant neural networks, our approach significantly enhances model
robustness and generalization for aerial vPR.

</details>


### [53] [Seeing Through Deepfakes: A Human-Inspired Framework for Multi-Face Detection](https://arxiv.org/abs/2507.14807)
*Juan Hu,Shaojing Fan,Terence Sim*

Main category: cs.CV

TL;DR: 本研究提出了一种名为 HICOM 的新颖框架，通过模仿人类的认知方式来检测多面深度伪造视频，提高了检测准确性和泛化能力，并提供了可解释性。


<details>
  <summary>Details</summary>
Motivation: 现有的深度伪造视频检测方法在单面检测上表现良好，但在多面场景下由于缺乏对关键情境线索的认知而表现不佳。因此，有必要开发一种能应对多面深度伪造视频的新方法。

Method: 通过人类研究系统地检查人们如何在社交环境中检测深度伪造面部，并量化分析人们依赖的关键线索：场景运动一致性、面部外观兼容性、人际目光对齐和面部-身体一致性。基于这些见解，提出了一种名为 HICOM 的新颖框架来检测多面深度伪造视频中的每一个假面部，并结合大型语言模型提供可解释性。

Result: HICOM 在基准数据集上的广泛实验表明，在数据集内检测方面，平均准确率提高了 3.3%；在真实世界扰动下，平均准确率提高了 2.8%。此外，在未见过的数据集上，HICOM 的表现比现有方法高出 5.8%，证明了人类启发式线索的泛化能力。HICOM 还通过整合大型语言模型来提供人类可读的解释，增强了可解释性。

Conclusion: 该研究提出了一种新颖的基于人类认知 的方法来检测多面深度伪造视频，通过识别场景运动一致性、面部外观兼容性、人际目光对齐和面部-身体一致性这四个关键线索，并利用大型语言模型提供可解释性，有效提高了检测准确率和泛化能力，为深度伪造防御提供了新思路。

Abstract: Multi-face deepfake videos are becoming increasingly prevalent, often
appearing in natural social settings that challenge existing detection methods.
Most current approaches excel at single-face detection but struggle in
multi-face scenarios, due to a lack of awareness of crucial contextual cues. In
this work, we develop a novel approach that leverages human cognition to
analyze and defend against multi-face deepfake videos. Through a series of
human studies, we systematically examine how people detect deepfake faces in
social settings. Our quantitative analysis reveals four key cues humans rely
on: scene-motion coherence, inter-face appearance compatibility, interpersonal
gaze alignment, and face-body consistency. Guided by these insights, we
introduce \textsf{HICOM}, a novel framework designed to detect every fake face
in multi-face scenarios. Extensive experiments on benchmark datasets show that
\textsf{HICOM} improves average accuracy by 3.3\% in in-dataset detection and
2.8\% under real-world perturbations. Moreover, it outperforms existing methods
by 5.8\% on unseen datasets, demonstrating the generalization of human-inspired
cues. \textsf{HICOM} further enhances interpretability by incorporating an LLM
to provide human-readable explanations, making detection results more
transparent and convincing. Our work sheds light on involving human factors to
enhance defense against deepfakes.

</details>


### [54] [Dense-depth map guided deep Lidar-Visual Odometry with Sparse Point Clouds and Images](https://arxiv.org/abs/2507.15496)
*JunYing Huang,Ao Xu,DongSun Yong,KeRen Li,YuanFeng Wang,Qi Qin*

Main category: cs.CV

TL;DR: 提出了一种融合LiDAR和视觉信息的新的里程计框架，通过深度补全、注意力机制和分层姿态优化，在KITTI数据集上实现了优于现有方法的准确性和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 为自主系统实现精确可靠的自我定位和导航。

Method: 提出了一种新的LiDAR-视觉里程计框架，通过深度补全从点云和图像中估计稠密深度图，并结合了具有注意力机制的多尺度特征提取网络，实现了自适应的深度感知表示。此外，利用稠密的深度信息改进了光流估计，并减少了遮挡区域的误差。所提出的分层姿态优化模块逐步优化运动估计，确保在动态环境和尺度模糊下的鲁棒性。

Result: 在KITTI Odometry基准测试中，与最先进的视觉和LiDAR里程计方法相比，实现了相似或更优的准确性和鲁棒性。

Conclusion: 该方法在KITTI Odometry基准测试中取得了与最先进的视觉和LiDAR里程计方法相当或更优的准确性和鲁棒性。

Abstract: Odometry is a critical task for autonomous systems for self-localization and
navigation. We propose a novel LiDAR-Visual odometry framework that integrates
LiDAR point clouds and images for accurate and robust pose estimation. Our
method utilizes a dense-depth map estimated from point clouds and images
through depth completion, and incorporates a multi-scale feature extraction
network with attention mechanisms, enabling adaptive depth-aware
representations. Furthermore, we leverage dense depth information to refine
flow estimation and mitigate errors in occlusion-prone regions. Our
hierarchical pose refinement module optimizes motion estimation progressively,
ensuring robust predictions against dynamic environments and scale ambiguities.
Comprehensive experiments on the KITTI odometry benchmark demonstrate that our
approach achieves similar or superior accuracy and robustness compared to
state-of-the-art visual and LiDAR odometry methods.

</details>


### [55] [SegQuant: A Semantics-Aware and Generalizable Quantization Framework for Diffusion Models](https://arxiv.org/abs/2507.14811)
*Jiaji Zhang,Ruichao Sun,Hailiang Zhao,Jiaju Wu,Peng Chen,Hao Li,Xinkui Zhao,Kingsum Chow,Gang Xiong,Lin Ye,Shuiguang Deng*

Main category: cs.CV

TL;DR: SegQuant通过结合SegLinear和DualScale技术，解决了扩散模型量化中的泛化性和集成性问题，实现了高效且保真的模型压缩。


<details>
  <summary>Details</summary>
Motivation: 现有的量化方法（PTQ）通常依赖于特定架构的启发式方法，这限制了它们的泛化能力，并阻碍了与工业部署管道的集成。

Method: SegQuant框架包含一个感知段的、基于图的量化策略（SegLinear）来捕捉结构语义和空间异质性，以及一个双尺度量化方案（DualScale）来保留极性不对称激活。

Result: SegQuant在保持生成输出视觉保真度的同时，能够实现强大的性能，并且与主流部署工具兼容，并且适用于Transformer以外的扩散模型。

Conclusion: SegQuant是一个统一的量化框架，通过自适应地结合互补技术来增强跨模型通用性。它包括一个感知段的、基于图的量化策略（SegLinear）和一种双尺度量化方案（DualScale），在保持生成输出视觉保真度的同时，能够实现强大的性能，并且与主流部署工具兼容。

Abstract: Diffusion models have demonstrated exceptional generative capabilities but
are computationally intensive, posing significant challenges for deployment in
resource-constrained or latency-sensitive environments. Quantization offers an
effective means to reduce model size and computational cost, with post-training
quantization (PTQ) being particularly appealing due to its compatibility with
pre-trained models without requiring retraining or training data. However,
existing PTQ methods for diffusion models often rely on architecture-specific
heuristics that limit their generalizability and hinder integration with
industrial deployment pipelines. To address these limitations, we propose
SegQuant, a unified quantization framework that adaptively combines
complementary techniques to enhance cross-model versatility. SegQuant consists
of a segment-aware, graph-based quantization strategy (SegLinear) that captures
structural semantics and spatial heterogeneity, along with a dual-scale
quantization scheme (DualScale) that preserves polarity-asymmetric activations,
which is crucial for maintaining visual fidelity in generated outputs. SegQuant
is broadly applicable beyond Transformer-based diffusion models, achieving
strong performance while ensuring seamless compatibility with mainstream
deployment tools.

</details>


### [56] [FinChart-Bench: Benchmarking Financial Chart Comprehension in Vision-Language Models](https://arxiv.org/abs/2507.14823)
*Dong Shu,Haoyang Yuan,Yuchen Wang,Yanguang Liu,Huopu Zhang,Haiyan Zhao,Mengnan Du*

Main category: cs.CV

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Large vision-language models (LVLMs) have made significant progress in chart
understanding. However, financial charts, characterized by complex temporal
structures and domain-specific terminology, remain notably underexplored. We
introduce FinChart-Bench, the first benchmark specifically focused on
real-world financial charts. FinChart-Bench comprises 1,200 financial chart
images collected from 2015 to 2024, each annotated with True/False (TF),
Multiple Choice (MC), and Question Answering (QA) questions, totaling 7,016
questions. We conduct a comprehensive evaluation of 25 state-of-the-art LVLMs
on FinChart-Bench. Our evaluation reveals critical insights: (1) the
performance gap between open-source and closed-source models is narrowing, (2)
performance degradation occurs in upgraded models within families, (3) many
models struggle with instruction following, (4) both advanced models show
significant limitations in spatial reasoning abilities, and (5) current LVLMs
are not reliable enough to serve as automated evaluators. These findings
highlight important limitations in current LVLM capabilities for financial
chart understanding. The FinChart-Bench dataset is available at
https://huggingface.co/datasets/Tizzzzy/FinChart-Bench.

</details>


### [57] [Being-H0: Vision-Language-Action Pretraining from Large-Scale Human Videos](https://arxiv.org/abs/2507.15597)
*Hao Luo,Yicheng Feng,Wanpeng Zhang,Sipeng Zheng,Ye Wang,Haoqi Yuan,Jiazheng Liu,Chaoyi Xu,Qin Jin,Zongqing Lu*

Main category: cs.CV

TL;DR: Being-H0是一个基于大规模人类视频训练的灵巧视觉-语言-动作模型，通过物理指令调优解决了现有模型的局限性，并在手部运动生成和机器人操作任务中取得了显著成果。


<details>
  <summary>Details</summary>
Motivation: 为了解决现有VLA模型在处理需要高灵巧性的复杂操作任务以及在新场景和任务上泛化能力不足的问题，该研究提出利用人类手部作为基础操纵器，以解决数据瓶颈问题。

Method: 提出了一种名为Being-H0的灵巧视觉-语言-动作（VLA）模型，该模型在包括运动捕捉、VR和纯RGB视频在内的大规模数据集上进行训练。该方法的核心是物理指令调优，包括大规模VLA预训练、物理空间对齐和机器人任务的后训练适应。此外，还引入了一种实现毫米级重建精度的部件级运动标记方法，用于精确的手部轨迹建模。

Result: Being-H0在手部运动生成和指令遵循方面展现出卓越的性能，并且模型和数据的规模化也带来了相应的性能提升。在将物理指令调优应用于现实世界的机器人操作时，也观察到了预期的收益。

Conclusion: Being-H0在手部运动生成和指令遵循方面表现出色，并且能够很好地随着模型和数据规模的扩展而扩展。在将物理指令调优应用于现实世界的机器人操作时，也观察到了预期的收益。

Abstract: We introduce Being-H0, a dexterous Vision-Language-Action model (VLA) trained
on large-scale human videos. Existing VLAs struggle with complex manipulation
tasks requiring high dexterity and generalize poorly to novel scenarios and
tasks, primarily due to their reliance on synthetic data with significant
sim-to-real gaps or teleoperated demonstrations lacking scale and diversity. To
address this data bottleneck, we propose leveraging human hands as a foundation
manipulator, capitalizing on the rich dexterity and scalability present in web
data. Our approach centers on physical instruction tuning, a novel training
paradigm that combines large-scale VLA pretraining from human videos, physical
space alignment for 3D reasoning, and post-training adaptation for robotic
tasks. Additionally, we introduce a part-level motion tokenization method which
achieves millimeter-level reconstruction accuracy to model precise hand
trajectories for action learning. To support our proposed paradigm, we further
develop a comprehensive data curation pipeline that integrates heterogeneous
sources -- including motion capture, VR, and RGB-only videos -- into a
large-scale dataset with millions of motion-based instructional instances. We
empirically show the excellence of Being-H0 in hand motion generation and
instruction following, and it also scales well with model and data sizes.
Importantly, we observe the expected gains of Being-H0 in real-world robotic
manipulation as physical instruction tuning is applied. More details are
available at https://beingbeyond.github.io/Being-H0.

</details>


### [58] [PHATNet: A Physics-guided Haze Transfer Network for Domain-adaptive Real-world Image Dehazing](https://arxiv.org/abs/2507.14826)
*Fu-Jen Tsai,Yan-Tsung Peng,Yen-Yu Lin,Chia-Wen Lin*

Main category: cs.CV

TL;DR: PHATNet 是一种新的域适应方法，它将 Haze 模式从看不见的域转移到无 Haze 的图像，以改进去雾模型。


<details>
  <summary>Details</summary>
Motivation: 现有去雾模型在处理看不见的真实世界 Haze 图像时，由于训练数据有限，性能会显着下降。这促使研究人员开发一种灵活的域适应方法，以提高测试期间的去雾性能。

Method: PHATNet 通过将无 Haze 的图像与来自看不见的域的 Haze 模式相结合，来生成特定领域的微调集，以更新去雾模型以实现有效的域适应。此外，还引入了 Haze-Transfer-Consistency 损失和 Content-Leakage 损失来增强 PHATNet 的分离能力。

Result: 实验结果表明，PHATNet 显着提高了最先进的去雾模型在基准真实世界图像去雾数据集上的性能。

Conclusion: PHATNet 显着提高了最先进的去雾模型在基准真实世界图像去雾数据集上的性能。

Abstract: Image dehazing aims to remove unwanted hazy artifacts in images. Although
previous research has collected paired real-world hazy and haze-free images to
improve dehazing models' performance in real-world scenarios, these models
often experience significant performance drops when handling unseen real-world
hazy images due to limited training data. This issue motivates us to develop a
flexible domain adaptation method to enhance dehazing performance during
testing. Observing that predicting haze patterns is generally easier than
recovering clean content, we propose the Physics-guided Haze Transfer Network
(PHATNet) which transfers haze patterns from unseen target domains to
source-domain haze-free images, creating domain-specific fine-tuning sets to
update dehazing models for effective domain adaptation. Additionally, we
introduce a Haze-Transfer-Consistency loss and a Content-Leakage Loss to
enhance PHATNet's disentanglement ability. Experimental results demonstrate
that PHATNet significantly boosts state-of-the-art dehazing models on benchmark
real-world image dehazing datasets.

</details>


### [59] [Paired Image Generation with Diffusion-Guided Diffusion Models](https://arxiv.org/abs/2507.14833)
*Haoxuan Zhang,Wenju Cui,Yuzhu Cao,Tao Tan,Jie Liu,Yunsong Peng,Jian Zheng*

Main category: cs.CV

TL;DR: 提出了一种无需外部条件的配对图像生成方法，用于解决数字乳房断层合成（DBT）图像中肿块分割的数据短缺问题。通过训练额外的引导器来生成配对的DBT图像和病灶掩模，并将其用于监督训练，能够提高生成质量并提升分割性能。


<details>
  <summary>Details</summary>
Motivation: 数字乳房断层合成（DBT）图像中肿块病灶的分割对于乳腺癌的早期筛查非常重要。然而，高密度乳腺组织导致病灶隐藏性高，手动标注困难且耗时，这造成了模型训练所需标注数据的缺乏。现有的扩散模型常用于数据增强，但面临生成病灶区域特征学习困难、生成图像质量低以及只能生成图像而无法生成对应标注的挑战。

Method: 提出了一种配对图像生成方法，通过训练额外的条件扩散模型引导器来实现配对图像的生成，无需外部条件。

Result: 生成的配对DBT切片和肿块区域掩模被纳入肿块区域分割任务的监督训练过程中。实验结果表明，该方法在无需外部条件的情况下可以提高生成质量，并有助于缓解标注数据短缺问题，提升下游任务的性能。

Conclusion: 该方法可以提高生成质量，同时在没有外部条件的情况下，有助于缓解标注数据短缺的问题，从而提高下游任务的性能。

Abstract: The segmentation of mass lesions in digital breast tomosynthesis (DBT) images
is very significant for the early screening of breast cancer. However, the
high-density breast tissue often leads to high concealment of the mass lesions,
which makes manual annotation difficult and time-consuming. As a result, there
is a lack of annotated data for model training. Diffusion models are commonly
used for data augmentation, but the existing methods face two challenges.
First, due to the high concealment of lesions, it is difficult for the model to
learn the features of the lesion area. This leads to the low generation quality
of the lesion areas, thus limiting the quality of the generated images. Second,
existing methods can only generate images and cannot generate corresponding
annotations, which restricts the usability of the generated images in
supervised training. In this work, we propose a paired image generation method.
The method does not require external conditions and can achieve the generation
of paired images by training an extra diffusion guider for the conditional
diffusion model. During the experimental phase, we generated paired DBT slices
and mass lesion masks. Then, we incorporated them into the supervised training
process of the mass lesion segmentation task. The experimental results show
that our method can improve the generation quality without external conditions.
Moreover, it contributes to alleviating the shortage of annotated data, thus
enhancing the performance of downstream tasks.

</details>


### [60] [Training Self-Supervised Depth Completion Using Sparse Measurements and a Single Image](https://arxiv.org/abs/2507.14845)
*Rizhao Fan,Zhigen Li,Heping Li,Ning An*

Main category: cs.CV

TL;DR: 一种新的自监督深度补全方法，仅需稀疏深度和图像即可训练，无需密集标签或多帧图像，通过深度分布损失和分割图提高了深度估计效果。


<details>
  <summary>Details</summary>
Motivation: 解决了现有监督学习方法依赖密集深度标签成本高，以及自监督方法需要图像序列强制几何约束和光度一致性的问题，这些方法在静态或单帧场景中适用性受限。

Method: 利用深度分布的特性，设计了新的损失函数，有效地将深度信息从观测点传播到未观测区域，并结合了视觉基础模型生成的分割图来进一步增强深度估计。

Result: 通过广泛的实验证明了所提出方法的有效性。

Conclusion: 提出了一种新颖的自监督深度补全范式，仅需要稀疏深度测量及其对应的图像进行训练，无需密集深度标签或额外的邻近视点图像。

Abstract: Depth completion is an important vision task, and many efforts have been made
to enhance the quality of depth maps from sparse depth measurements. Despite
significant advances, training these models to recover dense depth from sparse
measurements remains a challenging problem. Supervised learning methods rely on
dense depth labels to predict unobserved regions, while self-supervised
approaches require image sequences to enforce geometric constraints and
photometric consistency between frames. However, acquiring dense annotations is
costly, and multi-frame dependencies limit the applicability of self-supervised
methods in static or single-frame scenarios. To address these challenges, we
propose a novel self-supervised depth completion paradigm that requires only
sparse depth measurements and their corresponding image for training. Unlike
existing methods, our approach eliminates the need for dense depth labels or
additional images captured from neighboring viewpoints. By leveraging the
characteristics of depth distribution, we design novel loss functions that
effectively propagate depth information from observed points to unobserved
regions. Additionally, we incorporate segmentation maps generated by vision
foundation models to further enhance depth estimation. Extensive experiments
demonstrate the effectiveness of our proposed method.

</details>


### [61] [Grounding Degradations in Natural Language for All-In-One Video Restoration](https://arxiv.org/abs/2507.14851)
*Muhammad Kamran Janjua,Amirhosein Ghasemabadi,Kunlin Zhang,Mohammad Salameh,Chao Gao,Di Niu*

Main category: cs.CV

TL;DR: 提出了一种无需退化知识的全能视频恢复框架，利用基础模型和自然语言处理，并在新的基准上取得了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 视频恢复的挑战在于处理各种退化，而现有方法通常需要关于这些退化的先验知识。这项工作旨在通过利用基础模型和自然语言来提供一种更灵活、更通用的视频恢复方法，并解决了标准化基准测试的必要性。

Method: 提出了一种全能的视频恢复框架，通过基础模型将视频帧的退化感知语义上下文用自然语言进行基础化，提供可解释和灵活的指导。与现有技术不同，我们的方法在训练或测试时假定没有退化知识，并学习基础知识的近似值，以便在推理时可以安全地分离基础模型，而不会增加额外成本。

Result: 在多退化设置（3D和4D）和时间变化复合退化基准（包括模拟自然天气退化的数据集）上，与现有方法进行了比较，并报告了最先进的性能。

Conclusion: 我们的方法在所有基准上都取得了最先进的性能。

Abstract: In this work, we propose an all-in-one video restoration framework that
grounds degradation-aware semantic context of video frames in natural language
via foundation models, offering interpretable and flexible guidance. Unlike
prior art, our method assumes no degradation knowledge in train or test time
and learns an approximation to the grounded knowledge such that the foundation
model can be safely disentangled during inference adding no extra cost.
Further, we call for standardization of benchmarks in all-in-one video
restoration, and propose two benchmarks in multi-degradation setting,
three-task (3D) and four-task (4D), and two time-varying composite degradation
benchmarks; one of the latter being our proposed dataset with varying snow
intensity, simulating how weather degradations affect videos naturally. We
compare our method with prior works and report state-of-the-art performance on
all benchmarks.

</details>


### [62] [An Uncertainty-aware DETR Enhancement Framework for Object Detection](https://arxiv.org/abs/2507.14855)
*Xingshu Chen,Sicheng Yu,Chong Cheng,Hao Wang,Ting Tian*

Main category: cs.CV

TL;DR: This paper enhances object detection by modeling bounding box uncertainty using Gaussian distributions and Gromov-Wasserstein distance, improving accuracy and robustness. It achieves state-of-the-art results on COCO and medical imaging datasets.


<details>
  <summary>Details</summary>
Motivation: Conventional detectors ignore uncertainty in predictions, limiting model robustness. This paper aims to improve both localization accuracy and explicitly model prediction uncertainty in object detection.

Method: The paper proposes an uncertainty-aware enhancement framework for DETR-based object detectors by modeling bounding boxes as multivariate Gaussian distributions and incorporating the Gromov-Wasserstein distance into the loss function. A Bayes Risk formulation is derived to filter high-risk information, and a simple algorithm is proposed to quantify localization uncertainty via confidence intervals.

Result: Experiments on the COCO benchmark show enhanced performance when the method is integrated into existing DETR variants. The framework achieved state-of-the-art results on the LISC and WBCDD datasets for leukocyte detection.

Conclusion: The proposed uncertainty-aware framework can be effectively integrated into existing DETR variants, enhancing their performance and demonstrating scalability across general and domain-specific detection tasks. State-of-the-art results were achieved on the LISC and WBCDD datasets for leukocyte detection.

Abstract: This paper investigates the problem of object detection with a focus on
improving both the localization accuracy of bounding boxes and explicitly
modeling prediction uncertainty. Conventional detectors rely on deterministic
bounding box regression, ignoring uncertainty in predictions and limiting model
robustness. In this paper, we propose an uncertainty-aware enhancement
framework for DETR-based object detectors. We model bounding boxes as
multivariate Gaussian distributions and incorporate the Gromov-Wasserstein
distance into the loss function to better align the predicted and ground-truth
distributions. Building on this, we derive a Bayes Risk formulation to filter
high-risk information and improve detection reliability. We also propose a
simple algorithm to quantify localization uncertainty via confidence intervals.
Experiments on the COCO benchmark show that our method can be effectively
integrated into existing DETR variants, enhancing their performance. We further
extend our framework to leukocyte detection tasks, achieving state-of-the-art
results on the LISC and WBCDD datasets. These results confirm the scalability
of our framework across both general and domain-specific detection tasks. Code
page:
https://github.com/ParadiseforAndaChen/An-Uncertainty-aware-DETR-Enhancement-Framework-for-Object-Detection.

</details>


### [63] [Hybrid-supervised Hypergraph-enhanced Transformer for Micro-gesture Based Emotion Recognition](https://arxiv.org/abs/2507.14867)
*Zhaoqiang Xia,Hexiang Huang,Haoyu Chen,Xiaoyi Feng,Guoying Zhao*

Main category: cs.CV

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Micro-gestures are unconsciously performed body gestures that can convey the
emotion states of humans and start to attract more research attention in the
fields of human behavior understanding and affective computing as an emerging
topic. However, the modeling of human emotion based on micro-gestures has not
been explored sufficiently. In this work, we propose to recognize the emotion
states based on the micro-gestures by reconstructing the behavior patterns with
a hypergraph-enhanced Transformer in a hybrid-supervised framework. In the
framework, hypergraph Transformer based encoder and decoder are separately
designed by stacking the hypergraph-enhanced self-attention and multiscale
temporal convolution modules. Especially, to better capture the subtle motion
of micro-gestures, we construct a decoder with additional upsampling operations
for a reconstruction task in a self-supervised learning manner. We further
propose a hypergraph-enhanced self-attention module where the hyperedges
between skeleton joints are gradually updated to present the relationships of
body joints for modeling the subtle local motion. Lastly, for exploiting the
relationship between the emotion states and local motion of micro-gestures, an
emotion recognition head from the output of encoder is designed with a shallow
architecture and learned in a supervised way. The end-to-end framework is
jointly trained in a one-stage way by comprehensively utilizing
self-reconstruction and supervision information. The proposed method is
evaluated on two publicly available datasets, namely iMiGUE and SMG, and
achieves the best performance under multiple metrics, which is superior to the
existing methods.

</details>


### [64] [Region-aware Depth Scale Adaptation with Sparse Measurements](https://arxiv.org/abs/2507.14879)
*Rizhao Fan,Tianfang Ma,Zhigen Li,Ning An,Jian Cheng*

Main category: cs.CV

TL;DR: 提出一种无需训练或微调的非学习方法，利用稀疏深度测量将基础模型的相对深度预测转换为度量深度，保留泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有基础模型在零样本单目深度估计方面表现出色，但其输出通常是相对尺度而非度量尺度，这限制了其在实际应用中的部署。现有的尺度适应方法需要額外的训练，并且会损害模型的泛化能力。

Method: 提出了一种非学习方法，利用稀疏深度测量来将基础模型预测的相对深度转换为度量深度。

Result: 实验结果证明了该方法在将相对深度转换为度量深度方面的有效性，且没有额外的计算成本和泛化能力损失。

Conclusion: 该方法通过利用稀疏深度测量，实现了将基础模型预测的相对深度转换为度量深度，无需重新训练或微调，从而保留了基础模型的泛化能力，并在实验中证明了其有效性。

Abstract: In recent years, the emergence of foundation models for depth prediction has
led to remarkable progress, particularly in zero-shot monocular depth
estimation. These models generate impressive depth predictions; however, their
outputs are often in relative scale rather than metric scale. This limitation
poses challenges for direct deployment in real-world applications. To address
this, several scale adaptation methods have been proposed to enable foundation
models to produce metric depth. However, these methods are typically costly, as
they require additional training on new domains and datasets. Moreover,
fine-tuning these models often compromises their original generalization
capabilities, limiting their adaptability across diverse scenes. In this paper,
we introduce a non-learning-based approach that leverages sparse depth
measurements to adapt the relative-scale predictions of foundation models into
metric-scale depth. Our method requires neither retraining nor fine-tuning,
thereby preserving the strong generalization ability of the original foundation
models while enabling them to produce metric depth. Experimental results
demonstrate the effectiveness of our approach, high-lighting its potential to
bridge the gap between relative and metric depth without incurring additional
computational costs or sacrificing generalization ability.

</details>


### [65] [BeatFormer: Efficient motion-robust remote heart rate estimation through unsupervised spectral zoomed attention filters](https://arxiv.org/abs/2507.14885)
*Joaquim Comas,Federico Sukno*

Main category: cs.CV

TL;DR: BeatFormer是一种轻量级频谱注意力模型，通过频谱对比学习，无需标签即可高效准确地估计rPPG信号，尤其擅长处理运动场景。


<details>
  <summary>Details</summary>
Motivation: 目前的rPPG信号估计方法要么依赖大量标注数据，要么在复杂场景下性能受限。需要一种能够结合深度学习和传统方法优点，同时保持计算效率和泛化能力的混合方法。

Method: BeatFormer模型集成了缩放正交复数注意力和频域能量测量，并采用频谱对比学习（SCL）进行训练，无需PPG或HR标签。

Result: BeatFormer在PURE、UBFC-rPPG和MMPD数据集上进行了验证，证明了其鲁棒性和性能，特别是在运动场景下的跨数据集评估中表现突出。

Conclusion: BeatFormer通过结合频谱注意力模型和对比学习，在无需PPG或HR标签的情况下，实现了高效且鲁棒的rPPG信号估计，尤其在运动场景下的跨数据集评估中表现优异。

Abstract: Remote photoplethysmography (rPPG) captures cardiac signals from facial
videos and is gaining attention for its diverse applications. While deep
learning has advanced rPPG estimation, it relies on large, diverse datasets for
effective generalization. In contrast, handcrafted methods utilize
physiological priors for better generalization in unseen scenarios like motion
while maintaining computational efficiency. However, their linear assumptions
limit performance in complex conditions, where deep learning provides superior
pulsatile information extraction. This highlights the need for hybrid
approaches that combine the strengths of both methods. To address this, we
present BeatFormer, a lightweight spectral attention model for rPPG estimation,
which integrates zoomed orthonormal complex attention and frequency-domain
energy measurement, enabling a highly efficient model. Additionally, we
introduce Spectral Contrastive Learning (SCL), which allows BeatFormer to be
trained without any PPG or HR labels. We validate BeatFormer on the PURE,
UBFC-rPPG, and MMPD datasets, demonstrating its robustness and performance,
particularly in cross-dataset evaluations under motion scenarios.

</details>


### [66] [TriCLIP-3D: A Unified Parameter-Efficient Framework for Tri-Modal 3D Visual Grounding based on CLIP](https://arxiv.org/abs/2507.14904)
*Fan Li,Zanyi Wang,Zeyi Huang,Guang Dai,Jingdong Wang,Mengmeng Wang*

Main category: cs.CV

TL;DR: 提出了一种统一的2D预训练多模态网络，简化了3D视觉基础模型的架构，提高了效率和性能。通过GARF模块融合几何特征，并整合文本信息，实现了端到端的跨模态理解。


<details>
  <summary>Details</summary>
Motivation: 现有的3D视觉基础方法依赖于不同模态（如RGB图像、文本和3D点云）的独立编码器，导致模型庞大、复杂且训练效率低下。为了解决这个问题，旨在简化模型架构并提高训练效率。

Method: 提出了一种统一的2D预训练多模态网络来处理RGB图像、文本和点云三种模态，简化了模型架构。通过使用基于适配器的2D CLIP双模态模型进行微调，该框架能够适应三模态设置。提出了一种几何感知2D-3D特征恢复和融合（GARF）模块来融合点云和图像的几何多尺度特征，并整合文本特征进行最终的模态融合。最后，采用多模态解码器促进深层跨模态理解。

Result: 与基线方法相比，该方法将可训练参数量减少了约58%，在3D检测任务上提高了6.52%，在3D视觉基础任务上提高了6.25%。

Conclusion: 该方法实现了跨三种模态的统一特征提取和融合，能够构建端到端的3D视觉基础模型，在3D检测任务上提高了6.52%，在3D视觉基础任务上提高了6.25%，同时可训练参数量减少了约58%。

Abstract: 3D visual grounding allows an embodied agent to understand visual information
in real-world 3D environments based on human instructions, which is crucial for
embodied intelligence. Existing 3D visual grounding methods typically rely on
separate encoders for different modalities (e.g., RGB images, text, and 3D
point clouds), resulting in large and complex models that are inefficient to
train. While some approaches use pre-trained 2D multi-modal models like CLIP
for 3D tasks, they still struggle with aligning point cloud data to 2D
encoders. As a result, these methods continue to depend on 3D encoders for
feature extraction, further increasing model complexity and training
inefficiency. In this paper, we propose a unified 2D pre-trained multi-modal
network to process all three modalities (RGB images, text, and point clouds),
significantly simplifying the architecture. By leveraging a 2D CLIP bi-modal
model with adapter-based fine-tuning, this framework effectively adapts to the
tri-modal setting, improving both adaptability and performance across
modalities. Our Geometric-Aware 2D-3D Feature Recovery and Fusion (GARF) module
is designed to fuse geometric multi-scale features from point clouds and
images. We then integrate textual features for final modality fusion and
introduce a multi-modal decoder to facilitate deep cross-modal understanding.
Together, our method achieves unified feature extraction and fusion across the
three modalities, enabling an end-to-end 3D visual grounding model. Compared to
the baseline, our method reduces the number of trainable parameters by
approximately 58\%, while achieving a 6.52\% improvement in the 3D detection
task and a 6.25\% improvement in the 3D visual grounding task.

</details>


### [67] [Semantic-Aware Representation Learning for Multi-label Image Classification](https://arxiv.org/abs/2507.14918)
*Ren-Dong Xie,Zhi-Fen He,Bo Li,Bin Liu,Jin-Yan Hu*

Main category: cs.CV

TL;DR: 提出一种名为SARL（语义感知表示学习）的新方法，用于多标签图像分类，通过提取语义相关特征和使用基于最优传输的注意力机制来改进图像表示，实验证明其优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有的基于注意力机制或图卷积网络（GCN）的方法可能包含噪声且定位不精确，因此提出SARL来学习语义感知的表示。

Method: 首先，利用标签语义相关特征学习模块提取语义相关特征；然后，设计基于最优传输的注意力机制以获得语义对齐的图像表示；最后，使用区域得分聚合策略进行多标签预测。

Result: SARL在PASCAL VOC 2007和MS-COCO数据集上进行了实验，证明了其优越性。

Conclusion: SARL在PASCAL VOC 2007和MS-COCO数据集上优于现有方法

Abstract: Multi-label image classification, an important research area in computer
vision, focuses on identifying multiple labels or concepts within an image.
Existing approaches often employ attention mechanisms or graph convolutional
networks (GCNs) to learn image representation. However, this representation may
contain noise and may not locate objects precisely. Therefore, this paper
proposes a Semantic-Aware Representation Learning (SARL) for multi-label image
classification. First, a label semantic-related feature learning module is
utilized to extract semantic-related features. Then, an optimal transport-based
attention mechanism is designed to obtain semantically aligned image
representation. Finally, a regional score aggregation strategy is used for
multi-label prediction. Experimental results on two benchmark datasets, PASCAL
VOC 2007 and MS-COCO, demonstrate the superiority of SARL over existing
methods.

</details>


### [68] [Stereo-GS: Multi-View Stereo Vision Model for Generalizable 3D Gaussian Splatting Reconstruction](https://arxiv.org/abs/2507.14921)
*Xiufeng Huang,Ka Chun Cheung,Runmin Cong,Simon See,Renjie Wan*

Main category: cs.CV

TL;DR: 一种名为\method的新框架，可以高效地进行3D高斯重建，无需相机参数，即可从图像生成高质量的3D内容。


<details>
  <summary>Details</summary>
Motivation: 当前3D高斯重建方法在训练时需要大量计算资源和数据集，并且通常将3D高斯几何和外观的预测纠缠在一起，依赖于数据驱动的先验知识，导致回归速度缓慢。为了解决这些问题，需要一种更高效、更灵活的方法。

Method: 提出了一种名为\method的解耦框架，通过立体视觉骨干网络从局部图像对中提取特征，并通过全局注意力块进行融合。专门的点和高斯预测头生成多视图点图以用于几何，以及用于外观的高斯特征，组合成GS图来表示3DGS对象。一个改进网络增强这些GS图以实现高质量重建。该方法实现了姿态无关的3D重建。

Result: 该方法通过解耦3D高斯表示，并实现姿态无关的3D重建，显著提高了效率和鲁棒性，为现实世界的3D内容生成提供了一个可行的解决方案。

Conclusion: 该方法通过解耦3D高斯几何和外观预测，并采用姿态无关的3D重建，实现了高效、可扩展的3D内容生成，降低了资源需求，同时保持了高质量的输出。

Abstract: Generalizable 3D Gaussian Splatting reconstruction showcases advanced
Image-to-3D content creation but requires substantial computational resources
and large datasets, posing challenges to training models from scratch. Current
methods usually entangle the prediction of 3D Gaussian geometry and appearance,
which rely heavily on data-driven priors and result in slow regression speeds.
To address this, we propose \method, a disentangled framework for efficient 3D
Gaussian prediction. Our method extracts features from local image pairs using
a stereo vision backbone and fuses them via global attention blocks. Dedicated
point and Gaussian prediction heads generate multi-view point-maps for geometry
and Gaussian features for appearance, combined as GS-maps to represent the 3DGS
object. A refinement network enhances these GS-maps for high-quality
reconstruction. Unlike existing methods that depend on camera parameters, our
approach achieves pose-free 3D reconstruction, improving robustness and
practicality. By reducing resource demands while maintaining high-quality
outputs, \method provides an efficient, scalable solution for real-world 3D
content generation.

</details>


### [69] [3-Dimensional CryoEM Pose Estimation and Shift Correction Pipeline](https://arxiv.org/abs/2507.14924)
*Kaishva Chintan Shah,Virajith Boddapati,Karthik S. Gurumoorthy,Sandip Kaledhonkar,Ajit Rajwade*

Main category: cs.CV

TL;DR: 一种基于多维缩放（MDS）和稳健优化（L1 范数）的低温电子显微镜（cryo-EM）姿态估计和移位校正方法，可提高重建精度，尤其是在低信噪比（SNR）情况下。


<details>
  <summary>Details</summary>
Motivation: 低温电子显微镜（cryo-EM）中的精确姿态估计和移位校正是关键挑战，因为极低的信噪比（SNR）直接影响三维重建的保真度。

Method: 提出一种利用多维缩放（MDS）技术稳健地估计粒子三维旋转矩阵的方法，将旋转矩阵表示为旋转轴和垂直于该轴的平面内的单位向量。该技术利用了三维重建中公共线的概念。为解决低信噪比（SNR）问题，引入了两个组成部分：（1）基于 L1 范数或其他稳健范数的稳健联合优化框架，用于同时估计旋转轴和平面内向量，并通过投影坐标下降法精确强制执行单位范数和正交性约束；（2）通过全局最小二乘法估计一致的平面内平移的迭代移位校正算法。

Result: 与现有方法相比，该方法在 Euler 角精度和重建保真度方面均表现出优越的性能。

Conclusion: 该方法在 Euler 角精度和重建保真度方面持续优于现有方法，并通过傅立叶壳相关性（FSC）进行衡量。

Abstract: Accurate pose estimation and shift correction are key challenges in cryo-EM
due to the very low SNR, which directly impacts the fidelity of 3D
reconstructions. We present an approach for pose estimation in cryo-EM that
leverages multi-dimensional scaling (MDS) techniques in a robust manner to
estimate the 3D rotation matrix of each particle from pairs of dihedral angles.
We express the rotation matrix in the form of an axis of rotation and a unit
vector in the plane perpendicular to the axis. The technique leverages the
concept of common lines in 3D reconstruction from projections. However, common
line estimation is ridden with large errors due to the very low SNR of cryo-EM
projection images. To address this challenge, we introduce two complementary
components: (i) a robust joint optimization framework for pose estimation based
on an $\ell_1$-norm objective or a similar robust norm, which simultaneously
estimates rotation axes and in-plane vectors while exactly enforcing unit norm
and orthogonality constraints via projected coordinate descent; and (ii) an
iterative shift correction algorithm that estimates consistent in-plane
translations through a global least-squares formulation. While prior approaches
have leveraged such embeddings and common-line geometry for orientation
recovery, existing formulations typically rely on $\ell_2$-based objectives
that are sensitive to noise, and enforce geometric constraints only
approximately. These choices, combined with a sequential pipeline structure,
can lead to compounding errors and suboptimal reconstructions in low-SNR
regimes. Our pipeline consistently outperforms prior methods in both Euler
angle accuracy and reconstruction fidelity, as measured by the Fourier Shell
Correlation (FSC).

</details>


### [70] [Probabilistic smooth attention for deep multiple instance learning in medical imaging](https://arxiv.org/abs/2507.14932)
*Francisco M. Castro-Macías,Pablo Morales-Álvarez,Yunan Wu,Rafael Molina,Aggelos K. Katsaggelos*

Main category: cs.CV

TL;DR: 提出了一种新颖的概率框架，用于多示例学习，解决了现有方法在注意力值上确定性处理的问题，并在医疗成像分类任务中取得了领先的预测性能和可解释性结果。


<details>
  <summary>Details</summary>
Motivation: 现有的深度多示例学习方法将注意力值视为确定性的，这可能忽略了单个实例的贡献中的不确定性。

Method: 提出了一种新颖的概率框架，该框架可以估计注意力值上的概率分布，并同时考虑全局和局部交互。

Result: 在涉及十一种最先进的基线和三个医疗数据集的综合评估中，证明了该方法优于其他方法。

Conclusion: 所提出的概率框架在不同的指标上取得了顶尖的预测性能，并且所提出的概率性注意力处理方式能够提供关于疾病定位的可解释性不确定性图。

Abstract: The Multiple Instance Learning (MIL) paradigm is attracting plenty of
attention in medical imaging classification, where labeled data is scarce. MIL
methods cast medical images as bags of instances (e.g. patches in whole slide
images, or slices in CT scans), and only bag labels are required for training.
Deep MIL approaches have obtained promising results by aggregating
instance-level representations via an attention mechanism to compute the
bag-level prediction. These methods typically capture both local interactions
among adjacent instances and global, long-range dependencies through various
mechanisms. However, they treat attention values deterministically, potentially
overlooking uncertainty in the contribution of individual instances. In this
work we propose a novel probabilistic framework that estimates a probability
distribution over the attention values, and accounts for both global and local
interactions. In a comprehensive evaluation involving {\color{review} eleven}
state-of-the-art baselines and three medical datasets, we show that our
approach achieves top predictive performance in different metrics. Moreover,
the probabilistic treatment of the attention provides uncertainty maps that are
interpretable in terms of illness localization.

</details>


### [71] [Open-set Cross Modal Generalization via Multimodal Unified Representation](https://arxiv.org/abs/2507.14935)
*Hai Huang,Yan Xia,Shulei Wang,Hanting Wang,Minghui Fang,Shengpeng Ji,Sashuai Zhou,Tao Jin,Zhou Zhao*

Main category: cs.CV

TL;DR: 为解决跨模态泛化在开放集环境下的局限性，提出OSCMG任务和MICU模型（含FCMI、CUJP），用于评估和提升多模态统一表征在开放集场景下的性能。


<details>
  <summary>Details</summary>
Motivation: 现有跨模态泛化（CMG）的研究主要关注闭集环境，缺乏对开放集环境的考虑。然而，开放集场景（如OSCMG任务）在现实世界应用中更为常见，需要模型不仅能进行跨模态知识迁移，还能泛化到新模态的未见类别。因此，有必要研究开放集跨模态泛化。

Method: 提出了一种名为MICU（包含Fine-Coarse Masked multimodal InfoNCE (FCMI) 和 Cross modal Unified Jigsaw Puzzles (CUJP)）的模型。FCMI通过在整体语义和时间层面应用对比学习和掩码来增强多模态对齐和泛化能力。CUJP通过整合特定于模态的特征选择和自监督学习来增强特征多样性和模型不确定性，以处理开放集任务中的未知类别。

Result: 所提出的MICU模型在CMG和新提出的OSCMG任务上进行了广泛的实验，结果验证了该方法的有效性，表明其能够增强多模态统一表征在开放集环境下的鲁棒性和泛化能力。

Conclusion: 该研究提出了OSCMG任务，并设计了MICU模型（包含FCMI和CUJP），在CMG和OSCMG上进行了广泛的实验验证了方法的有效性。

Abstract: This paper extends Cross Modal Generalization (CMG) to open-set environments
by proposing the more challenging Open-set Cross Modal Generalization (OSCMG)
task. This task evaluates multimodal unified representations in open-set
conditions, addressing the limitations of prior closed-set cross-modal
evaluations. OSCMG requires not only cross-modal knowledge transfer but also
robust generalization to unseen classes within new modalities, a scenario
frequently encountered in real-world applications. Existing multimodal unified
representation work lacks consideration for open-set environments. To tackle
this, we propose MICU, comprising two key components: Fine-Coarse Masked
multimodal InfoNCE (FCMI) and Cross modal Unified Jigsaw Puzzles (CUJP). FCMI
enhances multimodal alignment by applying contrastive learning at both holistic
semantic and temporal levels, incorporating masking to enhance generalization.
CUJP enhances feature diversity and model uncertainty by integrating
modality-agnostic feature selection with self-supervised learning, thereby
strengthening the model's ability to handle unknown categories in open-set
tasks. Extensive experiments on CMG and the newly proposed OSCMG validate the
effectiveness of our approach. The code is available at
https://github.com/haihuangcode/CMG.

</details>


### [72] [DWTGS: Rethinking Frequency Regularization for Sparse-view 3D Gaussian Splatting](https://arxiv.org/abs/2507.15690)
*Hung Nguyen,Runfa Li,An Le,Truong Nguyen*

Main category: cs.CV

TL;DR: DWTGS通过小波域损失和自监督稀疏性，解决了稀疏视图3D高斯泼溅的过拟合问题，提高了重建质量。


<details>
  <summary>Details</summary>
Motivation: 解决稀疏视图3D高斯泼溅（3DGS）在重建高质量新视图时遇到的挑战，该挑战源于对稀疏训练视图中的高频（HF）细节过度拟合。现有的频率正则化方法依赖傅立叶变换，存在参数调整困难和不利的高频学习偏差等问题。

Method: 提出了一种名为DWTGS的框架，该框架利用小波域损失提供额外的空间监督。具体来说，它在多个离散小波变换（DWT）级别上仅监督低频（LF）LL子带，同时以自监督的方式强制执行高频（HF）HH子带的稀疏性。

Result: 实验表明，DWTGS的低频优先策略提高了泛化能力并减少了高频幻觉，在多个基准测试中始终优于基于傅立叶的对应方法。

Conclusion: DWTGS通过在多个DWT级别上仅监督低频(LF)LL子带，并在高频(HF)HH子带上以自监督方式强制执行稀疏性，从而在稀疏视图3D高斯泼溅中实现了更高质量的新视图重建，并优于基于傅立叶的传统方法。

Abstract: Sparse-view 3D Gaussian Splatting (3DGS) presents significant challenges in
reconstructing high-quality novel views, as it often overfits to the
widely-varying high-frequency (HF) details of the sparse training views. While
frequency regularization can be a promising approach, its typical reliance on
Fourier transforms causes difficult parameter tuning and biases towards
detrimental HF learning. We propose DWTGS, a framework that rethinks frequency
regularization by leveraging wavelet-space losses that provide additional
spatial supervision. Specifically, we supervise only the low-frequency (LF) LL
subbands at multiple DWT levels, while enforcing sparsity on the HF HH subband
in a self-supervised manner. Experiments across benchmarks show that DWTGS
consistently outperforms Fourier-based counterparts, as this LF-centric
strategy improves generalization and reduces HF hallucinations.

</details>


### [73] [Polymorph: Energy-Efficient Multi-Label Classification for Video Streams on Embedded Devices](https://arxiv.org/abs/2507.14959)
*Saeid Ghafouri,Mohsen Fayyaz,Xiangchen Li,Deepu John,Bo Ji,Dimitrios Nikolopoulos,Hans Vandierendonck*

Main category: cs.CV

TL;DR: Polymorph是一个上下文感知框架，通过激活一组最小化的低秩适配器（LoRA）来提高嵌入式设备上的实时多标签视频分类效率，从而降低延迟和能耗。


<details>
  <summary>Details</summary>
Motivation: 嵌入式设备上的实时多标签视频分类受到有限的计算和能源预算的限制。视频流具有标签稀疏性、时间连续性和标签共现等结构特性，可以用于更高效的推理。

Method: Polymorph是一个上下文感知框架，为每一帧激活一组最小化的轻量级低秩适配器（LoRA）。每个适配器专门处理由共现模式派生的子集类，并作为共享骨干的LoRA权重实现。运行时，Polymorph动态地选择和组合覆盖活动标签所需的适配器，避免了完整的模型切换和权重合并。

Result: Polymorph实现了40%的能耗降低，并将mAP提高了9个点。

Conclusion: Polymorph通过动态选择和组合所需的适配器来提高可扩展性，同时降低延迟和能源开销。在TAO数据集上，Polymorph实现了40%的能耗降低，并将mAP提高了9个点。

Abstract: Real-time multi-label video classification on embedded devices is constrained
by limited compute and energy budgets. Yet, video streams exhibit structural
properties such as label sparsity, temporal continuity, and label co-occurrence
that can be leveraged for more efficient inference. We introduce Polymorph, a
context-aware framework that activates a minimal set of lightweight Low Rank
Adapters (LoRA) per frame. Each adapter specializes in a subset of classes
derived from co-occurrence patterns and is implemented as a LoRA weight over a
shared backbone. At runtime, Polymorph dynamically selects and composes only
the adapters needed to cover the active labels, avoiding full-model switching
and weight merging. This modular strategy improves scalability while reducing
latency and energy overhead. Polymorph achieves 40% lower energy consumption
and improves mAP by 9 points over strong baselines on the TAO dataset.
Polymorph is open source at https://github.com/inference-serving/polymorph/.

</details>


### [74] [Decision PCR: Decision version of the Point Cloud Registration task](https://arxiv.org/abs/2507.14965)
*Yaojie Zhang,Tianlun Huang,Weijun Wang,Wei Feng*

Main category: cs.CV

TL;DR: 提出了一种新的数据驱动方法，使用深度学习分类器来评估点云配准质量，解决了低重叠点云配准的挑战，并提高了现有方法的性能。


<details>
  <summary>Details</summary>
Motivation: 低重叠点云配准（PCR）仍然是3D视觉中的一个重大挑战，传统的评估指标在极低的内点比例下会失效。

Method: 首先，构建了一个基于3DMatch数据集的相应数据集。然后，训练了一个基于深度学习的分类器来可靠地评估配准质量。

Result: 所提出的分类器克服了传统指标的局限性，并显著提高了现有PCR方法的配准性能。例如，将该框架与GeoTransformer结合在3DLoMatch基准测试中实现了86.97%的SOTA配准召回率，并在ETH数据集上展示了强大的泛化能力。

Conclusion: 数据驱动的方法通过训练基于深度学习的分类器来评估配准质量，克服了传统指标的局限性，并显著提高了现有配准方法的性能，在3DLoMatch基准测试中达到了新的SOTA配准召回率86.97%。

Abstract: Low-overlap point cloud registration (PCR) remains a significant challenge in
3D vision. Traditional evaluation metrics, such as Maximum Inlier Count, become
ineffective under extremely low inlier ratios. In this paper, we revisit the
registration result evaluation problem and identify the Decision version of the
PCR task as the fundamental problem. To address this Decision PCR task, we
propose a data-driven approach. First, we construct a corresponding dataset
based on the 3DMatch dataset. Then, a deep learning-based classifier is trained
to reliably assess registration quality, overcoming the limitations of
traditional metrics. To our knowledge, this is the first comprehensive study to
address this task through a deep learning framework. We incorporate this
classifier into standard PCR pipelines. When integrated with our approach,
existing state-of-the-art PCR methods exhibit significantly enhanced
registration performance. For example, combining our framework with
GeoTransformer achieves a new SOTA registration recall of 86.97\% on the
challenging 3DLoMatch benchmark. Our method also demonstrates strong
generalization capabilities on the unseen outdoor ETH dataset.

</details>


### [75] [Hierarchical Cross-modal Prompt Learning for Vision-Language Models](https://arxiv.org/abs/2507.14976)
*Hao Zheng,Shunzhi Yang,Zhuoxin He,Jinfeng Yang,Zhenhua Huang*

Main category: cs.CV

TL;DR: HiCroPL通过双向跨模态提示学习，解决了VLM在下游任务中的泛化能力限制，实现了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 预训练的视觉-语言模型（VLMs）虽然泛化能力强，但在适应下游任务时保持其泛化能力仍具挑战性。现有的提示学习方法存在模态隔离和层级语义衰减两大瓶颈，限制了其泛化能力。

Method: HiCroPL框架通过分层知识映射器，在早期层利用文本提示注入清晰的语义到视觉提示中，以增强低层视觉语义的表示。在后期层，视觉提示将与任务相关的对象信息反向传递给文本提示，以实现更深层次的对齐。此外，HiCroPL还引入了层级特定的知识代理，以实现高效的跨模态交互。

Result: HiCroPL在四个下游任务的广泛评估中取得了优越的性能，并在11个基准测试中达到了最先进的水平，显著提升了模型性能。

Conclusion: HiCroPL通过分层知识映射器和层级特定的知识代理，实现了跨模态知识的双向流动，有效解决了现有提示学习方法中的模态隔离和层级语义衰减问题，从而提升了模型的泛化能力。在四个下游任务的广泛评估中，HiCroPL取得了优于现有方法的性能，并在11个基准测试中达到了最先进的水平。

Abstract: Pre-trained Vision-Language Models (VLMs) such as CLIP have shown excellent
generalization abilities. However, adapting these large-scale models to
downstream tasks while preserving their generalization capabilities remains
challenging. Although prompt learning methods have shown promise, they suffer
from two fundamental bottlenecks that limit generalization: (a) modality
isolation, and (b) hierarchical semantic decay. To address these limitations,
we propose HiCroPL, a Hierarchical Cross-modal Prompt Learning framework that
establishes bidirectional knowledge flow between text and vision modalities,
enabling them to refine their semantics mutually. HiCroPL routes knowledge
flows by leveraging the complementary strengths of text and vision. In early
layers, text prompts inject relatively clear semantics into visual prompts
through a hierarchical knowledge mapper, enhancing the representation of
low-level visual semantics. In later layers, visual prompts encoding specific
task-relevant objects flow back to refine text prompts, enabling deeper
alignment. Crucially, our hierarchical knowledge mapper allows representations
at multi-scales to be fused, ensuring that deeper representations retain
transferable shallow semantics thereby enhancing generalization. We further
introduce a lightweight layer-specific knowledge proxy to enable efficient
cross-modal interactions. Extensive evaluations across four tasks demonstrate
HiCroPL's superior performance, achieving state-of-the-art results on 11
benchmarks with significant improvements. Code is available at:
https://github.com/zzeoZheng/HiCroPL.

</details>


### [76] [Language Integration in Fine-Tuning Multimodal Large Language Models for Image-Based Regression](https://arxiv.org/abs/2507.14997)
*Roy H. Jennings,Genady Paikin,Roy Shaul,Evgeny Soloveichik*

Main category: cs.CV

TL;DR: 使用包含特定图像语义的提示，可以提升多模态大语言模型在图像回归任务上的表现，RvTC方法通过基于区间的方法和数据驱动的提示，在图像回归任务上取得了最先进的成果。


<details>
  <summary>Details</summary>
Motivation: 现有的多模态大语言模型（MLLMs）在图像回归任务中存在局限性，如使用预设输出词汇表和通用任务提示，这未能充分利用文本语义信息，其效果与仅使用图像训练的模型相当。本研究旨在探索如何有效利用MLLMs的跨模态理解能力来改进图像回归任务。

Method: 提出了一种名为RvTC（Regression via Transformer-Based Classification）的新方法，该方法用灵活的基于区间（bin-based）的方法替代了受词汇表限制的分类，并通过增加区间来消除手动设计词汇表的需要。此外，研究表明使用包含特定图像语义信息的数据驱动型提示，可以显著提高MLLMs的表现，例如在AVA数据集上，加入挑战标题将相关性从0.83提高到0.90。

Result: RvTC方法在四个图像评估数据集上取得了最先进的性能，并且仅使用图像数据。通过在提示中加入数据特异性信息（如AVA数据集的挑战标题），可以显著提升MLLMs的表现，相关性从0.83提高到0.90，超过了仅使用图像的模型以及使用通用提示的MLLMs。

Conclusion: MLLMs在图像回归任务中通过数据驱动的提示，可以超越图像本身，实现最先进的性能，这表明在多模态回归任务中包含有意义的文本上下文至关重要。

Abstract: Multimodal Large Language Models (MLLMs) show promise for image-based
regression tasks, but current approaches face key limitations. Recent methods
fine-tune MLLMs using preset output vocabularies and generic task-level prompts
(e.g., "How would you rate this image?"), assuming this mimics human rating
behavior. Our analysis reveals these approaches provide no benefit over
image-only training. Models using preset vocabularies and generic prompts
perform equivalently to image-only models, failing to leverage semantic
understanding from textual input. We propose Regression via Transformer-Based
Classification (RvTC), which replaces vocabulary-constrained classification
with a flexible bin-based approach. Unlike approaches that address
discretization errors through complex distributional modeling, RvTC eliminates
manual vocabulary crafting through straightforward bin increase, achieving
state-of-the-art performance on four image assessment datasets using only
images. More importantly, we demonstrate that data-specific prompts
dramatically improve performance. Unlike generic task descriptions, prompts
containing semantic information about specific images enable MLLMs to leverage
cross-modal understanding. On the AVA dataset, adding challenge titles to
prompts improves correlations from 0.83 to 0.90, a new state-of-the-art. We
demonstrate through empirical evidence from the AVA and AGIQA-3k datasets that
MLLMs benefit from semantic prompt information surpassing mere statistical
biases. This underscores the importance of incorporating meaningful textual
context in multimodal regression tasks.

</details>


### [77] [Axis-Aligned Document Dewarping](https://arxiv.org/abs/2507.15000)
*Chaoyun Wang,I-Chao Shen,Takeo Igarashi,Nanning Zheng,Caigui Jiang*

Main category: cs.CV

TL;DR: This paper introduces a new approach to document dewarping by leveraging the geometric property of axis alignment. It includes a new training constraint, an inference preprocessing step, and a novel evaluation metric (AAD), achieving state-of-the-art results.


<details>
  <summary>Details</summary>
Motivation: Existing learning-based document dewarping methods do not fully leverage the geometric properties of physical documents. The key insight is that dewarped documents transform distorted feature lines into axis-aligned ones, reflecting the inherent grid geometry of planar documents.

Method: The method incorporates an axis-aligned geometric constraint during training and an axis-alignment preprocessing strategy during inference. A new metric, Axis-Aligned Distortion (AAD), is introduced for evaluation.

Result: Achieved state-of-the-art results on multiple existing benchmarks, with 18.2%~34.5% improvement on the AAD metric.

Conclusion: The proposed method achieves state-of-the-art results on multiple benchmarks and shows significant improvements on the new AAD metric.

Abstract: Document dewarping is crucial for many applications. However, existing
learning-based methods primarily rely on supervised regression with annotated
data without leveraging the inherent geometric properties in physical documents
to the dewarping process. Our key insight is that a well-dewarped document is
characterized by transforming distorted feature lines into axis-aligned ones.
This property aligns with the inherent axis-aligned nature of the discrete grid
geometry in planar documents. In the training phase, we propose an axis-aligned
geometric constraint to enhance document dewarping. In the inference phase, we
propose an axis alignment preprocessing strategy to reduce the dewarping
difficulty. In the evaluation phase, we introduce a new metric, Axis-Aligned
Distortion (AAD), that not only incorporates geometric meaning and aligns with
human visual perception but also demonstrates greater robustness. As a result,
our method achieves SOTA results on multiple existing benchmarks and achieves
18.2%~34.5% improvements on the AAD metric.

</details>


### [78] [FastSmoothSAM: A Fast Smooth Method For Segment Anything Model](https://arxiv.org/abs/2507.15008)
*Jiasheng Xu,Yewang Chen*

Main category: cs.CV

TL;DR: 本研究提出一种B样条曲线拟合方法，用于优化FastSAM模型的分割边缘，解决了其锯齿状边缘问题，在保持实时性的同时提高了精度。


<details>
  <summary>Details</summary>
Motivation: FastSAM在实现实时分割的同时，存在边缘锯齿、偏离真实物体形状的问题，限制了其在需要精确边缘识别的实际应用中的效率。

Method: 提出一种基于B样条曲线拟合的四阶段模型细化方法，通过两轮曲线拟合来平滑FastSAM生成的锯齿状边缘，以提升边缘质量和几何精度。

Result: 该方法成功改善了FastSAM的边缘质量，提高了分割精度，同时保持了实时处理能力，为FastSAM技术在实际应用中开辟了更广阔的前景。

Conclusion: 该方法通过B样条曲线拟合技术有效解决了FastSAM生成的边缘锯齿问题，在保持实时性的同时显著提高了分割边缘的质量和精度，增强了FastSAM在工业自动化、医学成像和自动驾驶等领域的实用性。

Abstract: Accurately identifying and representing object edges is a challenging task in
computer vision and image processing. The Segment Anything Model (SAM) has
significantly influenced the field of image segmentation, but suffers from high
memory consumption and long inference times, limiting its efficiency in
real-time applications. To address these limitations, Fast Segment Anything
(FastSAM) was proposed, achieving real-time segmentation. However, FastSAM
often generates jagged edges that deviate from the true object shapes.
Therefore, this paper introduces a novel refinement approach using B-Spline
curve fitting techniques to enhance the edge quality in FastSAM. Leveraging the
robust shape control and flexible geometric construction of B-Splines, a
four-stage refining process involving two rounds of curve fitting is employed
to effectively smooth jagged edges. This approach significantly improves the
visual quality and analytical accuracy of object edges without compromising
critical geometric information. The proposed method improves the practical
utility of FastSAM by improving segmentation accuracy while maintaining
real-time processing capabilities. This advancement unlocks greater potential
for FastSAM technology in various real-world scenarios, such as industrial
automation, medical imaging, and autonomous systems, where precise and
efficient edge recognition is crucial.

</details>


### [79] [Towards Video Thinking Test: A Holistic Benchmark for Advanced Video Reasoning and Understanding](https://arxiv.org/abs/2507.15028)
*Yuanhan Zhang,Yunice Chew,Yuhao Dong,Aria Leo,Bo Hu,Ziwei Liu*

Main category: cs.CV

TL;DR: 视频大型语言模型在理解视频内容方面，尤其是在处理复杂叙事和应对对抗性问题时，与人类相比存在较大差距。


<details>
  <summary>Details</summary>
Motivation: 现有视频大型语言模型基准未能充分反映其在保持视频理解的正确性和鲁棒性方面与人类智能的差距。

Method: 提出并评估了视频思维测试（Video-TT）基准，该基准包含1000个YouTube Shorts视频，每个视频都配有一个开放式问题和四个旨在探查视觉和叙事复杂性的对抗性问题。

Result: 评估结果显示，视频大型语言模型在Video-TT上的表现与人类相比存在显著差距。

Conclusion: 目前视频大型语言模型在理解视频内容方面与人类智能相比仍存在显著差距，尤其是在复杂视觉叙事和对抗性问题方面。

Abstract: Human intelligence requires correctness and robustness, with the former being
foundational for the latter. In video understanding, correctness ensures the
accurate interpretation of visual content, and robustness maintains consistent
performance in challenging conditions. Despite advances in video large language
models (video LLMs), existing benchmarks inadequately reflect the gap between
these models and human intelligence in maintaining correctness and robustness
in video interpretation. We introduce the Video Thinking Test (Video-TT), to
assess if video LLMs can interpret real-world videos as effectively as humans.
Video-TT reflects genuine gaps in understanding complex visual narratives, and
evaluates robustness against natural adversarial questions. Video-TT comprises
1,000 YouTube Shorts videos, each with one open-ended question and four
adversarial questions that probe visual and narrative complexity. Our
evaluation shows a significant gap between video LLMs and human performance.

</details>


### [80] [OpenBreastUS: Benchmarking Neural Operators for Wave Imaging Using Breast Ultrasound Computed Tomography](https://arxiv.org/abs/2507.15035)
*Zhijun Zeng,Youjia Zheng,Hao Hu,Zeyuan Dong,Yihang Zheng,Xinliang Liu,Jinzhuo Wang,Zuoqiang Shi,Linfeng Zhang,Yubing Li,He Sun*

Main category: cs.CV

TL;DR: OpenBreastUS 是一个大规模数据集，用于训练和评估神经算子在乳腺超声成像中的应用，解决了现有数据集过于简化的缺点，并首次实现了高效的原位成像。


<details>
  <summary>Details</summary>
Motivation: 传统的数值求解器计算成本高且不稳定，限制了其在准实时图像重建中的应用。现有的神经算子数据集过于简化，未能反映现实世界的复杂性。

Method: 提出 OpenBreastUS 数据集，包含 8,000 个解剖学上真实的乳腺模型和超过 1600 万个频域波模拟，用于基准测试神经算子在超声计算机断层扫描 (USCT) 中的性能。

Result: OpenBreastUS 数据集能够对流行的神经算子在正向模拟和逆向成像任务上的性能、可扩展性和泛化能力进行全面的基准测试，并首次实现了使用神经算子求解器对人体乳腺进行高效的原位成像。

Conclusion: OpenBreastUS 是一个大规模数据集，旨在弥合理论方程与实际成像应用之间的差距，并促进神经 PDE 求解器在现实世界医学成像问题中的应用。该数据集使研究人员能够对流行的神经算子在正向模拟和逆向成像任务上的性能、可扩展性和泛化能力进行全面的基准测试。该研究首次展示了使用神经算子求解器对人体乳腺进行高效的原位成像。

Abstract: Accurate and efficient simulation of wave equations is crucial in
computational wave imaging applications, such as ultrasound computed tomography
(USCT), which reconstructs tissue material properties from observed scattered
waves. Traditional numerical solvers for wave equations are computationally
intensive and often unstable, limiting their practical applications for
quasi-real-time image reconstruction. Neural operators offer an innovative
approach by accelerating PDE solving using neural networks; however, their
effectiveness in realistic imaging is limited because existing datasets
oversimplify real-world complexity. In this paper, we present OpenBreastUS, a
large-scale wave equation dataset designed to bridge the gap between
theoretical equations and practical imaging applications. OpenBreastUS includes
8,000 anatomically realistic human breast phantoms and over 16 million
frequency-domain wave simulations using real USCT configurations. It enables a
comprehensive benchmarking of popular neural operators for both forward
simulation and inverse imaging tasks, allowing analysis of their performance,
scalability, and generalization capabilities. By offering a realistic and
extensive dataset, OpenBreastUS not only serves as a platform for developing
innovative neural PDE solvers but also facilitates their deployment in
real-world medical imaging problems. For the first time, we demonstrate
efficient in vivo imaging of the human breast using neural operator solvers.

</details>


### [81] [OmniVTON: Training-Free Universal Virtual Try-On](https://arxiv.org/abs/2507.15037)
*Zhaotong Yang,Yuhui Li,Shengfeng He,Xinzhe Li,Yangyang Xu,Junyu Dong,Yong Du*

Main category: cs.CV

TL;DR: OmniVTON是一个无需训练的通用虚拟试穿框架，通过解耦服装和姿态信息，解决了现有方法的局限性，实现了高保真度和姿态一致性，并在多人类虚拟试穿方面取得了突破。


<details>
  <summary>Details</summary>
Motivation: 现有基于图像的虚拟试穿（VTON）技术在跨领域泛化和数据偏差方面存在挑战，且缺乏能够同时处理这两种情况的统一的、无需训练的解决方案。

Method: OmniVTON通过解耦服装和姿态约束，引入了服装先验生成机制和连续边界缝合法来保留服装细节，并利用DDIM反演来精确对齐姿态，从而解决了现有方法的局限性。

Result: 实验结果表明，OmniVTON在多样化的数据集、服装类型和应用场景中均表现出优越的性能，并且是首个能够实现多人类虚拟试穿的框架。

Conclusion: OmniVTON在多人类虚拟试穿方面取得了显著的进展，能够在同一场景中实现多个个体之间的逼真服装转移。

Abstract: Image-based Virtual Try-On (VTON) techniques rely on either supervised
in-shop approaches, which ensure high fidelity but struggle with cross-domain
generalization, or unsupervised in-the-wild methods, which improve adaptability
but remain constrained by data biases and limited universality. A unified,
training-free solution that works across both scenarios remains an open
challenge. We propose OmniVTON, the first training-free universal VTON
framework that decouples garment and pose conditioning to achieve both texture
fidelity and pose consistency across diverse settings. To preserve garment
details, we introduce a garment prior generation mechanism that aligns clothing
with the body, followed by continuous boundary stitching technique to achieve
fine-grained texture retention. For precise pose alignment, we utilize DDIM
inversion to capture structural cues while suppressing texture interference,
ensuring accurate body alignment independent of the original image textures. By
disentangling garment and pose constraints, OmniVTON eliminates the bias
inherent in diffusion models when handling multiple conditions simultaneously.
Experimental results demonstrate that OmniVTON achieves superior performance
across diverse datasets, garment types, and application scenarios. Notably, it
is the first framework capable of multi-human VTON, enabling realistic garment
transfer across multiple individuals in a single scene. Code is available at
https://github.com/Jerome-Young/OmniVTON

</details>


### [82] [Rethinking Pan-sharpening: Principled Design, Unified Training, and a Universal Loss Surpass Brute-Force Scaling](https://arxiv.org/abs/2507.15059)
*Ran Zhang,Xuanhua He,Li Xueheng,Ke Cao,Liu Liu,Wenbo Xu,Fang Jiabin,Yang Qize,Jie Zhang*

Main category: cs.CV

TL;DR: PanTiny是一个轻量级的超分辨率框架，通过多数据集联合训练和创新的损失函数，实现了高效率和强大的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 为了解决当前超分辨率成像领域模型规模大、计算开销高以及在全分辨率数据上泛化能力差的问题，提出PanTiny框架以实现高效和稳健的性能。

Method: 提出了一种名为PanTiny的轻量级、单步超分辨率成像框架，并引入了多合一训练范式，在三个不同的卫星数据集（WV2、WV3和GF2）上同时进行训练。此外，还提出了一种通用的复合损失函数，以提高超分辨率成像的性能。

Result: PanTiny模型实现了优越的性能-效率平衡，优于大多数更大、更专业的模型。多合一训练策略提高了模型在全分辨率数据上的泛化能力。复合损失函数能够提升几乎所有超分辨率成像模型的性能。

Conclusion: PanTiny通过其轻量级设计、多合一训练范式和强大的复合损失函数，在效率和性能之间取得了优越的平衡，超越了许多更大、更专业的模型，并提倡业界转向更高效、可泛化和数据感知模型。

Abstract: The field of pan-sharpening has recently seen a trend towards increasingly
large and complex models, often trained on single, specific satellite datasets.
This approach, however, leads to high computational overhead and poor
generalization on full resolution data, a paradigm we challenge in this paper.
In response to this issue, we propose PanTiny, a lightweight, single-step
pan-sharpening framework designed for both efficiency and robust performance.
More critically, we introduce multiple-in-one training paradigm, where a
single, compact model is trained simultaneously on three distinct satellite
datasets (WV2, WV3, and GF2) with different resolution and spectral
information. Our experiments show that this unified training strategy not only
simplifies deployment but also significantly boosts generalization on
full-resolution data. Further, we introduce a universally powerful composite
loss function that elevates the performance of almost all of models for
pan-sharpening, pushing state-of-the-art metrics into a new era. Our PanTiny
model, benefiting from these innovations, achieves a superior
performance-to-efficiency balance, outperforming most larger, specialized
models. Through extensive ablation studies, we validate that principled
engineering in model design, training paradigms, and loss functions can surpass
brute-force scaling. Our work advocates for a community-wide shift towards
creating efficient, generalizable, and data-conscious models for
pan-sharpening. The code is available at
https://github.com/Zirconium233/PanTiny .

</details>


### [83] [StableAnimator++: Overcoming Pose Misalignment and Face Distortion for Human Image Animation](https://arxiv.org/abs/2507.15064)
*Shuyuan Tu,Zhen Xing,Xintong Han,Zhi-Qi Cheng,Qi Dai,Chong Luo,Zuxuan Wu,Yu-Gang Jiang*

Main category: cs.CV

TL;DR: StableAnimator++ 是一个创新的 ID 保持视频扩散框架，通过可学习的姿态对齐、SVD 引导的对齐、人脸嵌入细化、分布感知 ID 适配器以及 HJB 驱动的面部优化，解决了当前模型在人物图像动画中 ID 一致性的难题，能够生成高质量且无需后处理的视频。


<details>
  <summary>Details</summary>
Motivation: 当前的生成模型在保持人物图像动画的身份（ID）一致性方面存在挑战，特别是在参考图像和驱动视频在身体大小或位置上存在显著差异时。

Method: StableAnimator++ 是一个包含可学习的姿态对齐功能的 ID 保持视频扩散框架。它首先使用可学习层通过奇异值分解（SVD）注入的引导来预测参考图像和驱动姿态之间的相似性变换矩阵，以对齐姿态。然后，它使用现成的编码器计算图像和人脸嵌入，并通过全局内容感知人脸编码器来细化人脸嵌入。为了进一步保持身份识别（ID），该模型引入了一个分布感知 ID 适配器来抵消时间层造成的干扰，并通过分布对齐来保持 ID。在推理阶段，提出了一种基于汉密尔顿-雅可比-贝尔曼（HJB）的人脸优化方法，并将其集成到去噪过程中，以增强面部保真度。

Result: StableAnimator++ 能够生成高质量的视频，这些视频以参考图像和姿态序列为条件，并且无需进行任何后处理。

Conclusion: StableAnimator++ 在基准测试中被证明在定性和定量上都是有效的。

Abstract: Current diffusion models for human image animation often struggle to maintain
identity (ID) consistency, especially when the reference image and driving
video differ significantly in body size or position. We introduce
StableAnimator++, the first ID-preserving video diffusion framework with
learnable pose alignment, capable of generating high-quality videos conditioned
on a reference image and a pose sequence without any post-processing. Building
upon a video diffusion model, StableAnimator++ contains carefully designed
modules for both training and inference, striving for identity consistency. In
particular, StableAnimator++ first uses learnable layers to predict the
similarity transformation matrices between the reference image and the driven
poses via injecting guidance from Singular Value Decomposition (SVD). These
matrices align the driven poses with the reference image, mitigating
misalignment to a great extent. StableAnimator++ then computes image and face
embeddings using off-the-shelf encoders, refining the face embeddings via a
global content-aware Face Encoder. To further maintain ID, we introduce a
distribution-aware ID Adapter that counteracts interference caused by temporal
layers while preserving ID via distribution alignment. During the inference
stage, we propose a novel Hamilton-Jacobi-Bellman (HJB) based face optimization
integrated into the denoising process, guiding the diffusion trajectory for
enhanced facial fidelity. Experiments on benchmarks show the effectiveness of
StableAnimator++ both qualitatively and quantitatively.

</details>


### [84] [Aesthetics is Cheap, Show me the Text: An Empirical Evaluation of State-of-the-Art Generative Models for OCR](https://arxiv.org/abs/2507.15085)
*Peirong Zhang,Haowei Xu,Jiaxin Zhang,Guitao Xu,Xuhan Zheng,Zhenhua Yang,Junle Liu,Yuyi Zhang,Lianwen Jin*

Main category: cs.CV

TL;DR: 评估了当前最先进的生成模型在文本图像生成和编辑方面的能力，特别是在OCR任务上，发现它们存在不足，并呼吁将这些能力内建到通用模型中。


<details>
  <summary>Details</summary>
Motivation: 现有的大型生成模型（如Flux系列和GPT-4o）在图像生成方面表现出色，引发了它们是否能掌握文本图像生成和编辑复杂性的疑问。

Method: 通过评估当前最先进的生成模型在文本图像生成和编辑方面的能力，并引入了典型的光学字符识别（OCR）任务。评估了33个代表性任务，涵盖文档、手写文本、场景文本、艺术文本和复杂/富文本布局五类。评估了6个模型（闭源和开源），使用了定制的高质量图像输入和提示。

Result: 识别出现有生成模型在OCR任务方面的弱点，并为社区提供实现照片级文本图像生成和编辑能力内建化的宝贵见解。

Conclusion: 应将照片级文本图像生成和编辑作为通用生成模型的内建基础技能，而非交给专门的解决方案。

Abstract: Text image is a unique and crucial information medium that integrates visual
aesthetics and linguistic semantics in modern e-society. Due to their subtlety
and complexity, the generation of text images represents a challenging and
evolving frontier in the image generation field. The recent surge of
specialized image generators (\emph{e.g.}, Flux-series) and unified generative
models (\emph{e.g.}, GPT-4o), which demonstrate exceptional fidelity, raises a
natural question: can they master the intricacies of text image generation and
editing? Motivated by this, we assess current state-of-the-art generative
models' capabilities in terms of text image generation and editing. We
incorporate various typical optical character recognition (OCR) tasks into our
evaluation and broaden the concept of text-based generation tasks into OCR
generative tasks. We select 33 representative tasks and categorize them into
five categories: document, handwritten text, scene text, artistic text, and
complex \& layout-rich text. For comprehensive evaluation, we examine six
models across both closed-source and open-source domains, using tailored,
high-quality image inputs and prompts. Through this evaluation, we draw crucial
observations and identify the weaknesses of current generative models for OCR
tasks. We argue that photorealistic text image generation and editing should be
internalized as foundational skills into general-domain generative models,
rather than being delegated to specialized solutions, and we hope this
empirical analysis can provide valuable insights for the community to achieve
this goal. This evaluation is online and will be continuously updated at our
GitHub repository.

</details>


### [85] [BleedOrigin: Dynamic Bleeding Source Localization in Endoscopic Submucosal Dissection via Dual-Stage Detection and Tracking](https://arxiv.org/abs/2507.15094)
*Mengya Xu,Rulin Zhou,An Wang,Chaoyang Lyu,Zhen Li,Ning Zhong,Hongliang Ren*

Main category: cs.CV

TL;DR: 本研究提出了BleedOrigin-Bench数据集和BleedOrigin-Net框架，用于解决ESD术中出血源的检测和跟踪问题，并在实验中取得了优异的成果。


<details>
  <summary>Details</summary>
Motivation: 内窥镜粘膜下剥离术（ESD）中的术中出血给患者带来显著风险，需要实时精确定位和持续监测出血源以进行有效的止血干预。然而，现有的AI方法主要关注出血区域分割，忽视了在ESD这种视觉障碍频繁、场景动态变化的挑战性环境中进行精确出血源检测和时间跟踪的关键需求。此外，缺乏专门的数据集也阻碍了强大的AI辅助引导系统的发展。

Method: 本研究提出了一种名为BleedOrigin-Net的新型双阶段检测-跟踪框架，用于在ESD过程中进行出血源定位。该框架解决了从出血起始检测到连续空间跟踪的完整工作流程。研究人员还构建了首个全面的ESD出血源数据集BleedOrigin-Bench，包含1771个专家标注的出血源，覆盖了8个解剖部位和6种临床场景，并与YOLOv11/v12、多模态大语言模型和点跟踪方法进行了比较。

Result: BleedOrigin-Net在出血起始检测方面达到了96.85%的帧级准确率（±≤8帧），在初始出血源检测方面达到了70.24%的像素级准确率（≤100像素），在点跟踪方面达到了96.11%的像素级准确率（≤100像素），表现优于现有方法。

Conclusion: 所提出的BleedOrigin-Net在ESD止血方面表现出最先进的性能，实现了高精度的出血点检测和跟踪，为AI辅助的内窥镜手术提供了有效的解决方案。

Abstract: Intraoperative bleeding during Endoscopic Submucosal Dissection (ESD) poses
significant risks, demanding precise, real-time localization and continuous
monitoring of the bleeding source for effective hemostatic intervention. In
particular, endoscopists have to repeatedly flush to clear blood, allowing only
milliseconds to identify bleeding sources, an inefficient process that prolongs
operations and elevates patient risks. However, current Artificial Intelligence
(AI) methods primarily focus on bleeding region segmentation, overlooking the
critical need for accurate bleeding source detection and temporal tracking in
the challenging ESD environment, which is marked by frequent visual
obstructions and dynamic scene changes. This gap is widened by the lack of
specialized datasets, hindering the development of robust AI-assisted guidance
systems. To address these challenges, we introduce BleedOrigin-Bench, the first
comprehensive ESD bleeding source dataset, featuring 1,771 expert-annotated
bleeding sources across 106,222 frames from 44 procedures, supplemented with
39,755 pseudo-labeled frames. This benchmark covers 8 anatomical sites and 6
challenging clinical scenarios. We also present BleedOrigin-Net, a novel
dual-stage detection-tracking framework for the bleeding source localization in
ESD procedures, addressing the complete workflow from bleeding onset detection
to continuous spatial tracking. We compare with widely-used object detection
models (YOLOv11/v12), multimodal large language models, and point tracking
methods. Extensive evaluation demonstrates state-of-the-art performance,
achieving 96.85% frame-level accuracy ($\pm\leq8$ frames) for bleeding onset
detection, 70.24% pixel-level accuracy ($\leq100$ px) for initial source
detection, and 96.11% pixel-level accuracy ($\leq100$ px) for point tracking.

</details>


### [86] [LoopNet: A Multitasking Few-Shot Learning Approach for Loop Closure in Large Scale SLAM](https://arxiv.org/abs/2507.15109)
*Mohammad-Maher Nakshbandi,Ziad Sharawy,Sorin Grigorescu*

Main category: cs.CV

TL;DR: LoopNet improves SLAM loop closure by using a specialized ResNet (LoopNet) with few-shot learning for real-time performance on embedded systems, outperforming older methods. A new dataset, LoopDB, is also released.


<details>
  <summary>Details</summary>
Motivation: The paper aims to solve two main problems in real-time SLAM systems: loop closure detection accuracy and real-time computation constraints on embedded hardware.

Method: LoopNet employs a multitasking ResNet architecture adapted for online retraining using few-shot learning and optimized for embedded devices. It leverages DISK (DIStinctive Keypoints) descriptors.

Result: LoopNet surpasses traditional methods and handcrafted features by offering better performance under varying conditions, effectively indexing visual datasets and measuring prediction quality. The paper also introduces a new benchmarking dataset, LoopDB.

Conclusion: LoopNet is a novel method that enhances loop closure detection accuracy and addresses real-time computation constraints in SLAM systems. It utilizes a multitasking ResNet architecture with few-shot learning for online retraining and incorporates DISK descriptors for improved performance.

Abstract: One of the main challenges in the Simultaneous Localization and Mapping
(SLAM) loop closure problem is the recognition of previously visited places. In
this work, we tackle the two main problems of real-time SLAM systems: 1) loop
closure detection accuracy and 2) real-time computation constraints on the
embedded hardware. Our LoopNet method is based on a multitasking variant of the
classical ResNet architecture, adapted for online retraining on a dynamic
visual dataset and optimized for embedded devices. The online retraining is
designed using a few-shot learning approach. The architecture provides both an
index into the queried visual dataset, and a measurement of the prediction
quality. Moreover, by leveraging DISK (DIStinctive Keypoints) descriptors,
LoopNet surpasses the limitations of handcrafted features and traditional deep
learning methods, offering better performance under varying conditions. Code is
available at https://github.com/RovisLab/LoopNet. Additinally, we introduce a
new loop closure benchmarking dataset, coined LoopDB, which is available at
https://github.com/RovisLab/LoopDB.

</details>


### [87] [Enhancing Visual Planning with Auxiliary Tasks and Multi-token Prediction](https://arxiv.org/abs/2507.15130)
*Ce Zhang,Yale Song,Ruta Desai,Michael Louis Iuzzolino,Joseph Tighe,Gedas Bertasius,Satwik Kottur*

Main category: cs.CV

TL;DR: 该研究提出了一种名为 VideoPlan 的方法，通过辅助任务增强和多令牌预测来解决视频规划中的数据稀缺性和结构化动作空间建模问题，并在多个基准测试中取得了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 为了解决在视频规划（VPA）任务中训练大型多模态语言模型（MLLMs）所面临的两个挑战：1. 程序性注释的稀缺性，限制了模型有效学习程序性任务动态的能力；2. 与自由形式的自然语言相比，下一个令牌预测目标在显式捕获视觉规划的结构化动作空间方面效率低下。

Method: 提出了一种名为 VideoPlan 的方法，该方法结合了辅助任务增强（Auxiliary Task Augmentation）和多令牌预测（Multi-token Prediction）。辅助任务增强通过在与长期视频规划相关的辅助任务（例如目标预测）上训练模型来解决数据稀疏性问题。多令牌预测通过使用多个预测头在训练期间预测多个未来令牌来扩展传统的下一个令牌预测，从而更明确地模拟了视觉规划特有的结构化动作空间。

Result: VideoPlan 在 COIN 和 CrossTask 数据集上实现了最先进的 VPA 性能，在预测 3 个未来动作时分别超越了先前方法 7.3% 和 3.4%。该方法在 Ego4D 长时动作预测任务上也表现出色，与现有方法相当。

Conclusion: VideoPlan 在 COIN 和 CrossTask 数据集上实现了最先进的 VPA 性能，在预测 3 个未来动作时分别超越了先前方法 7.3% 和 3.4%。此外，在 Ego4D 长时动作预测任务上，VideoPlan 的表现与最先进的方法相当，尽管它没有使用专门的以自我为中心的特征。

Abstract: Visual Planning for Assistance (VPA) aims to predict a sequence of user
actions required to achieve a specified goal based on a video showing the
user's progress. Although recent advances in multimodal large language models
(MLLMs) have shown promising results in video understanding, long-horizon
visual planning remains a challenging problem. We identify two challenges in
training large MLLMs for video-based planning tasks: (1) scarcity of procedural
annotations, limiting the model's ability to learn procedural task dynamics
effectively, and (2) inefficiency of next-token prediction objective to
explicitly capture the structured action space for visual planning when
compared to free-form, natural language. To tackle data scarcity, we introduce
Auxiliary Task Augmentation. We design and train our model on auxiliary tasks
relevant to long-horizon video-based planning (e.g., goal prediction) to
augment the model's planning ability. To more explicitly model the structured
action space unique to visual planning tasks, we leverage Multi-token
Prediction, extending traditional next-token prediction by using multiple heads
to predict multiple future tokens during training. Our approach, VideoPlan,
achieves state-of-the-art VPA performance on the COIN and CrossTask datasets,
surpassing prior methods by 7.3% and 3.4%, respectively, when predicting 3
future actions. We further extend our method to the challenging Ego4D Long-term
Action Anticipation task, and show that it is on par with the state-of-the-art
approaches despite not using specialized egocentric features. Code will be made
available.

</details>


### [88] [Event-based Graph Representation with Spatial and Motion Vectors for Asynchronous Object Detection](https://arxiv.org/abs/2507.15150)
*Aayush Atul Verma,Arpitsinh Vaghela,Bharatesh Chakravarthi,Kaustav Chanda,Yezhou Yang*

Main category: cs.CV

TL;DR: 通过新颖的时空多图表示，实现了比现有图方法更优的事件检测性能和更高的效率。


<details>
  <summary>Details</summary>
Motivation: 现有的基于图表示的方法虽然能保留事件数据的稀疏性和异步性，但在时空动态建模方面存在不足，限制了其在下游任务中的性能。因此，需要更好的方法来处理事件数据的时空特性。

Method: 提出了一种新颖的时空多图表示方法，通过解耦的空间图（利用B样条基函数）和时间图（利用基于运动矢量的注意力机制）来捕捉时空动态，从而允许使用高效的2D卷积核替代计算成本高的3D卷积核。

Result: 在Gen1汽车和eTraM数据集的事件对象检测任务上，相较于先前基于图的方法，在检测准确率上提升了超过6%，同时实现了5倍的加速，并减少了参数量，而计算成本并未增加。

Conclusion: 所提出的方法通过结构化图模型有效地处理异步视觉数据，在事件检测方面取得了显著的性能提升和效率改进。

Abstract: Event-based sensors offer high temporal resolution and low latency by
generating sparse, asynchronous data. However, converting this irregular data
into dense tensors for use in standard neural networks diminishes these
inherent advantages, motivating research into graph representations. While such
methods preserve sparsity and support asynchronous inference, their performance
on downstream tasks remains limited due to suboptimal modeling of
spatiotemporal dynamics. In this work, we propose a novel spatiotemporal
multigraph representation to better capture spatial structure and temporal
changes. Our approach constructs two decoupled graphs: a spatial graph
leveraging B-spline basis functions to model global structure, and a temporal
graph utilizing motion vector-based attention for local dynamic changes. This
design enables the use of efficient 2D kernels in place of computationally
expensive 3D kernels. We evaluate our method on the Gen1 automotive and eTraM
datasets for event-based object detection, achieving over a 6% improvement in
detection accuracy compared to previous graph-based works, with a 5x speedup,
reduced parameter count, and no increase in computational cost. These results
highlight the effectiveness of structured graph modeling for asynchronous
vision. Project page: eventbasedvision.github.io/eGSMV.

</details>


### [89] [MeshMamba: State Space Models for Articulated 3D Mesh Generation and Reconstruction](https://arxiv.org/abs/2507.15212)
*Yusuke Yoshiyasu,Leyuan Sun,Ryusuke Sagawa*

Main category: cs.CV

TL;DR: MeshMamba是一个基于Mamba-SSM的新型3D关节网格学习模型，能够高效处理大量顶点，并催生了用于3D网格生成（MambaDiff3D）和人体姿态恢复（Mamba-HMR）的先进模型。


<details>
  <summary>Details</summary>
Motivation: 为了学习3D关节网格模型，并提高生成和重建的效率和质量，特别是处理包含大量顶点（如服装和手部几何）的模型。

Method: MeshMamba模型，利用Mamba-SSM处理3D关节网格，通过基于身体部位注释或模板网格3D顶点位置对顶点进行排序，以尊重关节形状的结构。基于此，开发了MambaDiff3D（用于生成3D关节网格的去噪扩散模型）和Mamba-HMR（用于从单张图像重建3D人体形状和姿势的人体网格恢复模型）。

Result: MambaDiff3D能够生成包含服装和抓握手的密集3D人体网格，并在3D人体形状生成任务上优于先前方法。Mamba-HMR成功地将非参数人体网格恢复的能力扩展到全身（包括面部和手），并实现了有竞争力的（近）实时性能。

Conclusion: MeshMamba通过利用Mamba-SSM，可以高效、可扩展地处理大量输入标记，从而能够生成和重建具有超过10,000个顶点的身体网格模型，并捕捉服装和手部几何形状。基于MeshMamba设计的MambaDiff3D（用于生成3D关节网格的去噪扩散模型）和Mamba-HMR（用于从单张图像重建3D人体形状和姿势的人体网格恢复模型）在各自任务中均表现出色。MambaDiff3D生成的密集3D人体网格（包括服装和抓握的手）优于先前方法。Mamba-HMR则将非参数人体网格恢复的能力从仅处理身体姿势（约500个顶点标记）扩展到包含面部和手的全身设置，并在（近）实时性能上达到有竞争力水平。

Abstract: In this paper, we introduce MeshMamba, a neural network model for learning 3D
articulated mesh models by employing the recently proposed Mamba State Space
Models (Mamba-SSMs). MeshMamba is efficient and scalable in handling a large
number of input tokens, enabling the generation and reconstruction of body mesh
models with more than 10,000 vertices, capturing clothing and hand geometries.
The key to effectively learning MeshMamba is the serialization technique of
mesh vertices into orderings that are easily processed by Mamba. This is
achieved by sorting the vertices based on body part annotations or the 3D
vertex locations of a template mesh, such that the ordering respects the
structure of articulated shapes. Based on MeshMamba, we design 1) MambaDiff3D,
a denoising diffusion model for generating 3D articulated meshes and 2)
Mamba-HMR, a 3D human mesh recovery model that reconstructs a human body shape
and pose from a single image. Experimental results showed that MambaDiff3D can
generate dense 3D human meshes in clothes, with grasping hands, etc., and
outperforms previous approaches in the 3D human shape generation task.
Additionally, Mamba-HMR extends the capabilities of previous non-parametric
human mesh recovery approaches, which were limited to handling body-only poses
using around 500 vertex tokens, to the whole-body setting with face and hands,
while achieving competitive performance in (near) real-time.

</details>


### [90] [Improving Joint Embedding Predictive Architecture with Diffusion Noise](https://arxiv.org/abs/2507.15216)
*Yuping Qiu,Rui Zhu,Ying-cong Chen*

Main category: cs.CV

TL;DR: N-JEPA（基于噪声的JEPA）通过将扩散噪声整合到掩码图像建模（MIM）中，并结合多层次噪声调度，增强了自监督学习（SSL）在图像识别任务中的表现。


<details>
  <summary>Details</summary>
Motivation: 为了进一步增强自监督学习（SSL）的表示能力，特别是弥补其在图像生成和细节增强方面相对于生成模型的不足，研究者们试图找到SSL与生成模型之间的联系。生成模型通过近似数据分布来创建新样本，这暗示了它们能带来对原始视觉数据的语义理解，这对于识别任务至关重要。因此，本研究旨在将扩散模型的扩散噪声与SSL相结合，以学习一个具有竞争力的识别模型。

Method: 提出了一种名为N-JEPA（基于噪声的JEPA）的新模型，该模型将扩散模型的扩散噪声通过掩码令牌的位置嵌入融入掩码图像建模（MIM）。模型还采用了多层次噪声调度作为一系列特征增强，以进一步提高模型的鲁棒性。

Result: 通过综合研究，证明了N-JEPA在下游分类任务中的有效性。

Conclusion: 通过将扩散模型的扩散噪声结合到掩码图像建模（MIM）中，并利用位置嵌入来整合噪声，N-JEPA（基于噪声的JEPA）能够有效地增强SSL的表示能力，并在下游分类任务中取得了有竞争力的识别模型效果。

Abstract: Self-supervised learning has become an incredibly successful method for
feature learning, widely applied to many downstream tasks. It has proven
especially effective for discriminative tasks, surpassing the trending
generative models. However, generative models perform better in image
generation and detail enhancement. Thus, it is natural for us to find a
connection between SSL and generative models to further enhance the
representation capacity of SSL. As generative models can create new samples by
approximating the data distribution, such modeling should also lead to a
semantic understanding of the raw visual data, which is necessary for
recognition tasks. This enlightens us to combine the core principle of the
diffusion model: diffusion noise, with SSL to learn a competitive recognition
model. Specifically, diffusion noise can be viewed as a particular state of
mask that reveals a close relationship between masked image modeling (MIM) and
diffusion models. In this paper, we propose N-JEPA (Noise-based JEPA) to
incorporate diffusion noise into MIM by the position embedding of masked
tokens. The multi-level noise schedule is a series of feature augmentations to
further enhance the robustness of our model. We perform a comprehensive study
to confirm its effectiveness in the classification of downstream tasks. Codes
will be released soon in public.

</details>


### [91] [Hierarchical Part-based Generative Model for Realistic 3D Blood Vessel](https://arxiv.org/abs/2507.15223)
*Siqi Chen,Guoqing Zhang,Jiahao Lai,Bingzhi Shen,Sihong Zhang,Caixia Dong,Xuejin Chen,Yang Li*

Main category: cs.CV

TL;DR: 一项新的分块生成框架，用于三维血管建模，在处理复杂血管网络方面表现优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 为了解决三维血管建模中由于复杂的血管分支模式、曲率和不规则形状而导致的几何和拓扑表示的挑战。

Method: 本研究提出了一种分层分块框架，用于三维血管生成。该方法将全局二叉树拓扑与局部几何细节分离开来，分为三个阶段：关键图生成、基于几何属性的血管段生成以及通过整合局部血管段进行分层血管组装。

Result: 在真实数据集上验证了该框架，证明了其在血管网络建模方面优于现有方法。

Conclusion: 本研究提出的分块生成方法在三维血管建模方面取得了优于现有方法的性能，为血管数据的生成设定了新的基准。

Abstract: Advancements in 3D vision have increased the impact of blood vessel modeling
on medical applications. However, accurately representing the complex geometry
and topology of blood vessels remains a challenge due to their intricate
branching patterns, curvatures, and irregular shapes. In this study, we propose
a hierarchical part-based frame work for 3D vessel generation that separates
the global binary tree-like topology from local geometric details. Our approach
proceeds in three stages: (1) key graph generation to model the overall
hierarchical struc ture, (2) vessel segment generation conditioned on geometric
properties, and (3) hierarchical vessel assembly by integrating the local
segments according to the global key graph. We validate our framework on real
world datasets, demonstrating superior performance over existing methods in
modeling complex vascular networks. This work marks the first successful
application of a part-based generative approach for 3D vessel modeling, setting
a new benchmark for vascular data generation. The code is available at:
https://github.com/CybercatChen/PartVessel.git.

</details>


### [92] [Mammo-SAE: Interpreting Breast Cancer Concept Learning with Sparse Autoencoders](https://arxiv.org/abs/2507.15227)
*Krishna Kanth Nakka*

Main category: cs.CV

TL;DR: 本研究将稀疏自编码器 (SAE) 的可解释性应用于乳腺成像的 Mammo-CLIP 模型，识别与“肿块”和“可疑钙化”等临床概念相关的潜在特征，发现神经元与真实区域对齐，并揭示了模型决策中的混杂因素。


<details>
  <summary>Details</summary>
Motivation: 可解释性在高风险领域（如医学成像）至关重要，在这些领域，理解模型决策对于临床应用至关重要。

Method: 我们通过分析在大量乳腺X线照片图像-报告对上预训练的视觉-语言基础模型 Mammo-CLIP，将基于稀疏自编码器 (SAE) 的可解释性引入乳腺成像。我们针对 Mammo-CLIP 训练了一个补丁级别的 Mammo-SAE，以识别和探测与临床相关乳腺概念（如“肿块”和“可疑钙化”）相关的潜在特征。

Result: 我们的发现揭示了 SAE 潜在空间中顶部激活的类别级潜在神经元通常与地面真实区域对齐，并揭示了影响模型决策过程的几个混杂因素。此外，我们分析了模型在下游微调以改进乳腺概念预测时所依赖的潜在神经元。

Conclusion: 这项研究突显了可解释的 SAE 潜在表征在为乳腺成像的各种层面的基础模型提供更深入的洞察方面所展现出的前景。

Abstract: Interpretability is critical in high-stakes domains such as medical imaging,
where understanding model decisions is essential for clinical adoption. In this
work, we introduce Sparse Autoencoder (SAE)-based interpretability to breast
imaging by analyzing {Mammo-CLIP}, a vision--language foundation model
pretrained on large-scale mammogram image--report pairs. We train a patch-level
\texttt{Mammo-SAE} on Mammo-CLIP to identify and probe latent features
associated with clinically relevant breast concepts such as \textit{mass} and
\textit{suspicious calcification}. Our findings reveal that top activated class
level latent neurons in the SAE latent space often tend to align with ground
truth regions, and also uncover several confounding factors influencing the
model's decision-making process. Additionally, we analyze which latent neurons
the model relies on during downstream finetuning for improving the breast
concept prediction. This study highlights the promise of interpretable SAE
latent representations in providing deeper insight into the internal workings
of foundation models at every layer for breast imaging.

</details>


### [93] [Cross-Domain Few-Shot Learning with Coalescent Projections and Latent Space Reservation](https://arxiv.org/abs/2507.15243)
*Naeem Paeedeh,Mahardhika Pratama,Wolfgang Mayer,Jimmy Cao,Ryszard Kowlczyk*

Main category: cs.CV

TL;DR: A new method using Coalescent Projection and Self-Supervised Transformations improves Cross-Domain Few-Shot Learning by reducing overfitting and adapting to new domains using only base data, outperforming existing approaches.


<details>
  <summary>Details</summary>
Motivation: Existing Cross-Domain Few-Shot Learning (CD-FSL) methods, even those using DINO pre-training, struggle with overfitting when updating a large number of transformer parameters due to limited labeled samples. This limits their effectiveness in handling unseen data from different domains.

Method: The paper proposes Coalescent Projection (CP) as a replacement for soft prompts and introduces a novel pseudo-class generation method combined with Self-Supervised Transformations (SSTs). These methods are designed to prepare the network for unseen samples from different domains by updating fewer parameters and leveraging only base domain data to avoid overfitting.

Result: The proposed method, utilizing Coalescent Projection (CP) and Self-Supervised Transformations (SSTs), demonstrates effectiveness in comprehensive experiments, particularly in the extreme domain shift scenario of the BSCD-FSL benchmark. It outperforms current state-of-the-art methods.

Conclusion: Coalescent Projection (CP) and Self-Supervised Transformations (SSTs) effectively address overfitting in Cross-Domain Few-Shot Learning (CD-FSL) by enabling network adaptation using only base domain data, outperforming prior methods in extreme domain shift scenarios.

Abstract: Despite the progress in Cross-Domain Few-Shot Learning (CD-FSL), a model
pre-trained with DINO combined with a prototypical classifier outperforms the
latest SOTA methods. A crucial limitation that needs to be overcome is that
updating too many parameters of the transformers leads to overfitting due to
the scarcity of labeled samples. To address this challenge, we propose a new
concept, Coalescent Projection (CP), as an effective successor to soft prompts.
Additionally, we propose a novel pseudo-class generation method combined with
Self-Supervised Transformations (SSTs) that relies solely on the base domain to
prepare the network for encountering unseen samples from different domains. The
proposed method exhibits its effectiveness in comprehensive experiments on the
extreme domain shift scenario of the BSCD-FSL benchmark. Our code is published
at https://github.com/Naeem-Paeedeh/CPLSR.

</details>


### [94] [FreeCus: Free Lunch Subject-driven Customization in Diffusion Transformers](https://arxiv.org/abs/2507.15249)
*Yanbing Zhang,Zhe Wang,Qin Zhou,Mengping Yang*

Main category: cs.CV

TL;DR: FreeCus是一个无需训练的框架，通过注意力共享、改进的特征提取和多模态大语言模型，解锁了扩散Transformer（DiT）在主题驱动图像生成中的零样本能力，达到了先进水平。


<details>
  <summary>Details</summary>
Motivation: 现有文本到图像（T2I）生成技术，特别是基于扩散Transformer（DiT）的主题驱动技术，虽然能实现高保真定制化生产，但通常需要进行每主体优化或在大型数据集上训练专用编码器，这限制了其实际应用。此外，当前方法未能充分利用现代扩散Transformer（如Flux系列）固有的零样本潜力来实现真实的主题驱动合成。

Method: FreeCus框架通过三个关键创新激活DiT的能力：1）引入关键的注意力共享机制，以捕捉主体的布局完整性并保留编辑的灵活性。2）通过对DiT的动态移位进行分析，提出了一种改进的变体，以增强细粒度特征提取。3）集成先进的多模态大语言模型（MLLMs）以丰富跨模态语义表示。

Result: 实验结果表明，FreeCus框架能够实现跨多种场景下的一致性主体合成，并且与现有图像修复管线和控制模块兼容。

Conclusion: FreeCus框架成功解锁了DiT的零样本能力，实现了跨多种场景下的一致性主体合成，并取得了与需要额外训练的方法相当或更优的性能。此外，该框架与现有的图像修复管线和控制模块兼容，可用于创造更具吸引力的体验。

Abstract: In light of recent breakthroughs in text-to-image (T2I) generation,
particularly with diffusion transformers (DiT), subject-driven technologies are
increasingly being employed for high-fidelity customized production that
preserves subject identity from reference inputs, enabling thrilling design
workflows and engaging entertainment. Existing alternatives typically require
either per-subject optimization via trainable text embeddings or training
specialized encoders for subject feature extraction on large-scale datasets.
Such dependencies on training procedures fundamentally constrain their
practical applications. More importantly, current methodologies fail to fully
leverage the inherent zero-shot potential of modern diffusion transformers
(e.g., the Flux series) for authentic subject-driven synthesis. To bridge this
gap, we propose FreeCus, a genuinely training-free framework that activates
DiT's capabilities through three key innovations: 1) We introduce a pivotal
attention sharing mechanism that captures the subject's layout integrity while
preserving crucial editing flexibility. 2) Through a straightforward analysis
of DiT's dynamic shifting, we propose an upgraded variant that significantly
improves fine-grained feature extraction. 3) We further integrate advanced
Multimodal Large Language Models (MLLMs) to enrich cross-modal semantic
representations. Extensive experiments reflect that our method successfully
unlocks DiT's zero-shot ability for consistent subject synthesis across diverse
contexts, achieving state-of-the-art or comparable results compared to
approaches that require additional training. Notably, our framework
demonstrates seamless compatibility with existing inpainting pipelines and
control modules, facilitating more compelling experiences. Our code is
available at: https://github.com/Monalissaa/FreeCus.

</details>


### [95] [MinCD-PnP: Learning 2D-3D Correspondences with Approximate Blind PnP](https://arxiv.org/abs/2507.15257)
*Pei An,Jiaqi Yang,Muyao Peng,You Yang,Qiong Liu,Xiaolin Wu,Liangliang Nan*

Main category: cs.CV

TL;DR: 该研究提出了一种名为 MinCD-Net 的新方法，用于图像到点云配准，通过最小化 2D 和 3D 关键点之间的 Chamfer 距离来解决 PnP 的敏感性问题，并在多个数据集上取得了优于现有方法的性能。


<details>
  <summary>Details</summary>
Motivation: 为了解决差分 PnP 对预测的对应关系中的噪声和离群值敏感的问题，从而阻碍了对应关系学习的有效性。

Method: 提出了一种基于近似盲 PnP 的对应学习方法，通过最小化学习到的 2D 和 3D 关键点之间的 Chamfer 距离（MinCD-PnP）来解决，并设计了一个名为 MinCD-Net 的轻量级多任务学习模块。

Result: MinCD-Net 表现优于最先进的方法，在跨场景和跨数据集的设置中，在 7-Scenes、RGBD-V2、ScanNet 和自收集数据集上均实现了更高的内点率 (IR) 和配准召回率 (RR)。

Conclusion: MinCD-Net 在跨场景和跨数据集的设置中，在 7-Scenes、RGBD-V2、ScanNet 和自收集数据集上的实验证明，其性能优于最先进的方法，并实现了更高的内点率 (IR) 和配准召回率 (RR)。

Abstract: Image-to-point-cloud (I2P) registration is a fundamental problem in computer
vision, focusing on establishing 2D-3D correspondences between an image and a
point cloud. The differential perspective-n-point (PnP) has been widely used to
supervise I2P registration networks by enforcing the projective constraints on
2D-3D correspondences. However, differential PnP is highly sensitive to noise
and outliers in the predicted correspondences. This issue hinders the
effectiveness of correspondence learning. Inspired by the robustness of blind
PnP against noise and outliers in correspondences, we propose an approximated
blind PnP based correspondence learning approach. To mitigate the high
computational cost of blind PnP, we simplify blind PnP to an amenable task of
minimizing Chamfer distance between learned 2D and 3D keypoints, called
MinCD-PnP. To effectively solve MinCD-PnP, we design a lightweight multi-task
learning module, named as MinCD-Net, which can be easily integrated into the
existing I2P registration architectures. Extensive experiments on 7-Scenes,
RGBD-V2, ScanNet, and self-collected datasets demonstrate that MinCD-Net
outperforms state-of-the-art methods and achieves a higher inlier ratio (IR)
and registration recall (RR) in both cross-scene and cross-dataset settings.

</details>


### [96] [Conditional Video Generation for High-Efficiency Video Compression](https://arxiv.org/abs/2507.15269)
*Fangqiu Yi,Jingyu Xu,Jiawei Shao,Chi Zhang,Xuelong Li*

Main category: cs.CV

TL;DR: 提出一种基于条件扩散模型的视频压缩新框架，通过多粒度条件化、紧凑表示和多条件训练，提升了视频的感知重构质量，并在各项指标上超越现有编解码器。


<details>
  <summary>Details</summary>
Motivation: 基于条件扩散模型在视频重构方面表现出符合人类视觉感知的优势这一洞察，提出了一种利用条件扩散模型进行感知优化重构的视频压缩框架。

Method: 本研究将视频压缩重构为一个条件生成任务，利用条件扩散模型从稀疏但信息丰富的信号生成视频。引入了三个关键模块：1. 多粒度条件化，捕捉静态场景结构和动态时空线索；2. 紧凑表示，用于高效传输且不牺牲语义丰富性；3. 多条件训练，包含模态 dropout 和角色感知嵌入，以防止过度依赖单一模态并增强鲁棒性。

Result: 实验结果表明，该方法在感知质量方面表现出色，尤其在高压缩率下。

Conclusion: 本方法在感知质量指标（如 Fréchet Video Distance (FVD) 和 LPIPS）上显著优于传统和神经编解码器，尤其是在高压缩率下。

Abstract: Perceptual studies demonstrate that conditional diffusion models excel at
reconstructing video content aligned with human visual perception. Building on
this insight, we propose a video compression framework that leverages
conditional diffusion models for perceptually optimized reconstruction.
Specifically, we reframe video compression as a conditional generation task,
where a generative model synthesizes video from sparse, yet informative
signals. Our approach introduces three key modules: (1) Multi-granular
conditioning that captures both static scene structure and dynamic
spatio-temporal cues; (2) Compact representations designed for efficient
transmission without sacrificing semantic richness; (3) Multi-condition
training with modality dropout and role-aware embeddings, which prevent
over-reliance on any single modality and enhance robustness. Extensive
experiments show that our method significantly outperforms both traditional and
neural codecs on perceptual quality metrics such as Fr\'echet Video Distance
(FVD) and LPIPS, especially under high compression ratios.

</details>


### [97] [In-context Learning of Vision Language Models for Detection of Physical and Digital Attacks against Face Recognition Systems](https://arxiv.org/abs/2507.15285)
*Lazaro Janier Gonzalez-Soler,Maciej Salwowski,Christoph Busch*

Main category: cs.CV

TL;DR: 该研究提出了一种新的视觉语言模型（VLM）上下文学习框架，用于检测人脸识别系统中的物理和数字攻击，并在不进行大量训练的情况下取得了优于传统CNN的性能。


<details>
  <summary>Details</summary>
Motivation: 随着检测方法的改进，攻击技术变得越来越复杂。传统深度学习模型在不同类型的攻击或不同的环境条件下适应性较差，并且需要大量的训练数据，而生物识别数据收集面临隐私和现实世界的挑战。

Method: 本文研究了视觉语言模型（VLM）的应用，并提出了一种用于检测生物识别系统中物理呈现攻击和数字变形攻击的上下文学习框架。该研究首次建立了用于通过上下文学习技术在安全关键场景中量化评估 VLM 的系统框架。

Result: 实验评估表明，所提出的子系统在物理和数字攻击检测方面取得了具有竞争力的性能，优于一些传统的卷积神经网络（CNN）。

Conclusion: 该框架为提高攻击检测的泛化能力提供了一个有前景的工具，并且无需进行资源密集型训练即可实现高性能。

Abstract: Recent advances in biometric systems have significantly improved the
detection and prevention of fraudulent activities. However, as detection
methods improve, attack techniques become increasingly sophisticated. Attacks
on face recognition systems can be broadly divided into physical and digital
approaches. Traditionally, deep learning models have been the primary defence
against such attacks. While these models perform exceptionally well in
scenarios for which they have been trained, they often struggle to adapt to
different types of attacks or varying environmental conditions. These
subsystems require substantial amounts of training data to achieve reliable
performance, yet biometric data collection faces significant challenges,
including privacy concerns and the logistical difficulties of capturing diverse
attack scenarios under controlled conditions. This work investigates the
application of Vision Language Models (VLM) and proposes an in-context learning
framework for detecting physical presentation attacks and digital morphing
attacks in biometric systems. Focusing on open-source models, the first
systematic framework for the quantitative evaluation of VLMs in
security-critical scenarios through in-context learning techniques is
established. The experimental evaluation conducted on freely available
databases demonstrates that the proposed subsystem achieves competitive
performance for physical and digital attack detection, outperforming some of
the traditional CNNs without resource-intensive training. The experimental
results validate the proposed framework as a promising tool for improving
generalisation in attack detection.

</details>


### [98] [Minutiae-Anchored Local Dense Representation for Fingerprint Matching](https://arxiv.org/abs/2507.15297)
*Zhiyu Pan,Xiongjun Guan,Yongjie Duan,Jianjiang Feng,Jie Zhou*

Main category: cs.CV

TL;DR: 提出了一种名为 DMD 的新颖指纹匹配方法，该方法使用以细节点为锚点的局部密集表示，结合了脊线纹理和细节点特征。该方法通过利用空间对应关系和前景掩码来提高效率和鲁棒性，并在各种数据集上实现了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 指纹匹配在各种不同的采集条件下仍然是生物特征识别中的一个基本挑战。为了在这些场景中实现稳健和准确的性能。

Method: 提出了一种名为 DMD 的局部密集表示方法，该方法以细节点为锚点，可以同时捕获细粒度的脊线纹理和具有判别性的细节点特征，并以空间结构化的方式进行表示。具体来说，描述符是从以检测到的每个细节点为中心和方向的局部块中提取的，形成一个三维张量，其中两个维度代表指纹平面上的空间位置，第三个维度编码语义特征。这种表示显式地捕获了局部图像块的抽象特征，实现了多层次、细粒度的描述，并聚合了来自多个细节点及其周围脊线结构的信息。此外，由于 DMD 与块图像具有很强的空间对应关系，它允许使用前景分割掩码来识别有效的描述符区域。在匹配过程中，比较仅限于重叠的前景区域，从而提高了效率和鲁棒性。

Result: 与其他方法相比，DMD 在各种指纹数据集（包括滚印、平面、局部、非接触和潜在指纹）上进行了评估，并在多个基准测试中取得了最先进的准确性，同时保持了高计算效率。

Conclusion: DMD 方法在多个基准测试中实现了最先进的准确性，同时保持了高计算效率，在万规模指纹识别方面显示出巨大潜力。

Abstract: Fingerprint matching under diverse capture conditions remains a fundamental
challenge in biometric recognition. To achieve robust and accurate performance
in such scenarios, we propose DMD, a minutiae-anchored local dense
representation which captures both fine-grained ridge textures and
discriminative minutiae features in a spatially structured manner.
Specifically, descriptors are extracted from local patches centered and
oriented on each detected minutia, forming a three-dimensional tensor, where
two dimensions represent spatial locations on the fingerprint plane and the
third encodes semantic features. This representation explicitly captures
abstract features of local image patches, enabling a multi-level, fine-grained
description that aggregates information from multiple minutiae and their
surrounding ridge structures. Furthermore, thanks to its strong spatial
correspondence with the patch image, DMD allows for the use of foreground
segmentation masks to identify valid descriptor regions. During matching,
comparisons are then restricted to overlapping foreground areas, improving
efficiency and robustness. Extensive experiments on rolled, plain, parital,
contactless, and latent fingerprint datasets demonstrate the effectiveness and
generalizability of the proposed method. It achieves state-of-the-art accuracy
across multiple benchmarks while maintaining high computational efficiency,
showing strong potential for large-scale fingerprint recognition. Corresponding
code is available at https://github.com/Yu-Yy/DMD.

</details>


### [99] [Few-Shot Object Detection via Spatial-Channel State Space Model](https://arxiv.org/abs/2507.15308)
*Zhimeng Xin,Tianxu Wu,Yixiong Zou,Shiming Chen,Dingjie Fu,Xinge You*

Main category: cs.CV

TL;DR: 针对少数样本目标检测（FSOD）中特征提取的挑战，提出一种基于Mamba的空间-通道状态空间建模（SCSM）模块，通过建模通道间的相关性来优化特征表示，并在实验中取得了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 少数样本目标检测（FSOD）中，由于训练样本有限，现有方法可能难以从每个通道准确提取有效特征。具体来说，权重高的通道不一定有效，权重低的通道可能仍然有重要价值。

Method: 本文提出了一种空间-通道状态空间建模（SCSM）模块，该模块包含空间特征建模（SFM）和通道状态建模（CSM）两个子模块。CSM子模块基于Mamba，用于学习通道序列中的相关性。

Result: 在VOC和COCO数据集上的大量实验表明，SCSM模块能够提升所提出检测器的性能。

Conclusion: 提出的空间-通道状态空间建模（SCSM）模块能够提高通道中特征表示的质量，并实现最先进的性能。

Abstract: Due to the limited training samples in few-shot object detection (FSOD), we
observe that current methods may struggle to accurately extract effective
features from each channel. Specifically, this issue manifests in two aspects:
i) channels with high weights may not necessarily be effective, and ii)
channels with low weights may still hold significant value. To handle this
problem, we consider utilizing the inter-channel correlation to facilitate the
novel model's adaptation process to novel conditions, ensuring the model can
correctly highlight effective channels and rectify those incorrect ones. Since
the channel sequence is also 1-dimensional, its similarity with the temporal
sequence inspires us to take Mamba for modeling the correlation in the channel
sequence. Based on this concept, we propose a Spatial-Channel State Space
Modeling (SCSM) module for spatial-channel state modeling, which highlights the
effective patterns and rectifies those ineffective ones in feature channels. In
SCSM, we design the Spatial Feature Modeling (SFM) module to balance the
learning of spatial relationships and channel relationships, and then introduce
the Channel State Modeling (CSM) module based on Mamba to learn correlation in
channels. Extensive experiments on the VOC and COCO datasets show that the SCSM
module enables the novel detector to improve the quality of focused feature
representation in channels and achieve state-of-the-art performance.

</details>


### [100] [BenchDepth: Are We on the Right Way to Evaluate Depth Foundation Models?](https://arxiv.org/abs/2507.15321)
*Zhenyu Li,Haotong Lin,Jiashi Feng,Peter Wonka,Bingyi Kang*

Main category: cs.CV

TL;DR: BenchDepth 提出了一种评估深度基础模型 (DFM) 的新方法，通过五个下游任务（如深度补全、SLAM 等）来衡量其实际效用，而不是依赖于有问题的基于对齐的指标。


<details>
  <summary>Details</summary>
Motivation: 评估 DFM 具有挑战性，因为现有协议不一致、基于对齐的指标存在偏差，并且难以进行公平比较。本研究旨在通过一种基于实际效用的评估方法来解决这些问题。

Method: 提出了一种名为 BenchDepth 的新基准，该基准通过五个选定的下游代理任务（深度补全、立体匹配、单目前馈 3D 场景重建、SLAM 和视觉语言空间理解）来评估 DFM，而不是依赖于有偏差的基于对齐的指标。

Result: 评估了八个最先进的 DFM，并提供了关键发现和观察的深入分析，旨在为深度模型评估的最佳实践提供信息。

Conclusion: BenchDepth 通过评估深度基础模型 (DFM) 在五个下游代理任务中的实用性，提供了一种新的评估方法，旨在克服现有协议的局限性，并促进深度模型评估最佳实践的讨论。

Abstract: Depth estimation is a fundamental task in computer vision with diverse
applications. Recent advancements in deep learning have led to powerful depth
foundation models (DFMs), yet their evaluation remains challenging due to
inconsistencies in existing protocols. Traditional benchmarks rely on
alignment-based metrics that introduce biases, favor certain depth
representations, and complicate fair comparisons. In this work, we propose
BenchDepth, a new benchmark that evaluates DFMs through five carefully selected
downstream proxy tasks: depth completion, stereo matching, monocular
feed-forward 3D scene reconstruction, SLAM, and vision-language spatial
understanding. Unlike conventional evaluation protocols, our approach assesses
DFMs based on their practical utility in real-world applications, bypassing
problematic alignment procedures. We benchmark eight state-of-the-art DFMs and
provide an in-depth analysis of key findings and observations. We hope our work
sparks further discussion in the community on best practices for depth model
evaluation and paves the way for future research and advancements in depth
estimation.

</details>


### [101] [ExDD: Explicit Dual Distribution Learning for Surface Defect Detection via Diffusion Synthesis](https://arxiv.org/abs/2507.15335)
*Muhammad Aqeel,Federico Leonardi,Francesco Setti*

Main category: cs.CV

TL;DR: ExDD是一个新框架，通过显式建模双特征分布和使用潜在扩散模型生成合成数据来改进工业缺陷检测，解决了单类别异常检测的局限性，并在KSDD2数据集上取得了SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 传统的单类别异常检测范式在工业缺陷检测中存在局限性，尤其是在处理异常值分布不均匀和真实世界制造环境中数据稀缺的问题。本研究旨在提出一种能够克服这些限制的新框架。

Method: ExDD框架通过以下方式工作：1. 显式建模双特征分布：利用并行的内存库分别捕获正常和异常模式的统计特性，解决了均匀异常值假设的根本缺陷。2. 克服数据稀缺性：采用具有领域特定文本条件的潜在扩散模型，生成保留工业背景的原位合成缺陷。3. 邻域感知比率评分：通过融合互补距离度量来放大表现出偏离正常性和与已知缺陷模式相似性的区域的信号。

Result: 在KSDD2数据集上的实验验证显示，ExDD框架取得了优越的性能，I-AUROC为94.2%，P-AUROC为97.7%，并且在增加100个合成样本时性能达到最优。

Conclusion: ExDD框架通过显式建模双特征分布、利用具有领域特定文本条件的潜在扩散模型生成合成缺陷以及采用邻域感知比率评分机制，克服了工业缺陷检测中单类别异常检测范式的局限性，并在KSDD2数据集上取得了优越的性能。

Abstract: Industrial defect detection systems face critical limitations when confined
to one-class anomaly detection paradigms, which assume uniform outlier
distributions and struggle with data scarcity in realworld manufacturing
environments. We present ExDD (Explicit Dual Distribution), a novel framework
that transcends these limitations by explicitly modeling dual feature
distributions. Our approach leverages parallel memory banks that capture the
distinct statistical properties of both normality and anomalous patterns,
addressing the fundamental flaw of uniform outlier assumptions. To overcome
data scarcity, we employ latent diffusion models with domain-specific textual
conditioning, generating in-distribution synthetic defects that preserve
industrial context. Our neighborhood-aware ratio scoring mechanism elegantly
fuses complementary distance metrics, amplifying signals in regions exhibiting
both deviation from normality and similarity to known defect patterns.
Experimental validation on KSDD2 demonstrates superior performance (94.2%
I-AUROC, 97.7% P-AUROC), with optimal augmentation at 100 synthetic samples.

</details>


### [102] [RoadFusion: Latent Diffusion Model for Pavement Defect Detection](https://arxiv.org/abs/2507.15346)
*Muhammad Aqeel,Kidus Dagnaw Bellete,Francesco Setti*

Main category: cs.CV

TL;DR: RoadFusion 通过合成异常生成和双路径特征适应性解决了道路缺陷检测中的数据稀缺、域漂移和外观变异性问题，并在多个基准测试中取得了最先进的成果。


<details>
  <summary>Details</summary>
Motivation: 道路缺陷检测面临严峻的挑战，包括标注数据有限、训练和部署环境之间的域漂移以及不同道路条件下缺陷外观的高度变异性。

Method: 提出了一种名为 RoadFusion 的框架，该框架通过具有双路径特征适应性的合成异常生成来解决数据稀缺、域漂移和缺陷外观高变异性等挑战。具体而言，利用潜在扩散模型，以文本提示和空间掩码为条件，生成多样化且逼真的缺陷，从而在数据稀缺的情况下实现有效的训练。两个独立的特征适配器分别对正常和异常输入的表示进行专门化，以提高对域漂移和缺陷变异性的鲁棒性。最后，采用轻量级鉴别器在斑块级别学习区分细粒度的缺陷模式。

Result: 在六个基准数据集上进行了评估，RoadFusion 在分类和定位任务上均实现了始终如一的强大性能。

Conclusion: RoadFusion 在分类和定位任务中均表现出始终如一的强大性能，并在与实际道路检测相关的多个指标上创下新的最先进纪录。

Abstract: Pavement defect detection faces critical challenges including limited
annotated data, domain shift between training and deployment environments, and
high variability in defect appearances across different road conditions. We
propose RoadFusion, a framework that addresses these limitations through
synthetic anomaly generation with dual-path feature adaptation. A latent
diffusion model synthesizes diverse, realistic defects using text prompts and
spatial masks, enabling effective training under data scarcity. Two separate
feature adaptors specialize representations for normal and anomalous inputs,
improving robustness to domain shift and defect variability. A lightweight
discriminator learns to distinguish fine-grained defect patterns at the patch
level. Evaluated on six benchmark datasets, RoadFusion achieves consistently
strong performance across both classification and localization tasks, setting
new state-of-the-art in multiple metrics relevant to real-world road
inspection.

</details>


### [103] [DAViD: Data-efficient and Accurate Vision Models from Synthetic Data](https://arxiv.org/abs/2507.15365)
*Fatemeh Saleh,Sadegh Aliakbarian,Charlie Hewitt,Lohit Petikam,Xiao-Xian,Antonio Criminisi,Thomas J. Cashman,Tadas Baltrušaitis*

Main category: cs.CV

TL;DR: 使用成本更低、可控性更高的高保真度合成数据，可以训练出与使用大型真实数据集训练的同等人本计算机视觉模型，且在准确性上不打折扣，同时效率更高。


<details>
  <summary>Details</summary>
Motivation: 探索使用合成数据替代大型真实数据集进行人本计算机视觉模型训练的可行性，以提高效率并解决数据偏见问题。

Method: 在小型、高保真度的合成数据集上训练模型，并进行详细的定量评估。

Result: 在真实图像上进行了广泛的定量评估，证明了模型在深度估计、表面法线估计和软前景分割任务上的准确性。合成数据训练的模型在训练和推理成本上仅为同等精度的基础模型的几分之一。

Conclusion: 使用合成数据训练的模型在三种密集预测任务上达到了与基础模型相当的准确性，同时显著降低了训练和推理成本。

Abstract: The state of the art in human-centric computer vision achieves high accuracy
and robustness across a diverse range of tasks. The most effective models in
this domain have billions of parameters, thus requiring extremely large
datasets, expensive training regimes, and compute-intensive inference. In this
paper, we demonstrate that it is possible to train models on much smaller but
high-fidelity synthetic datasets, with no loss in accuracy and higher
efficiency. Using synthetic training data provides us with excellent levels of
detail and perfect labels, while providing strong guarantees for data
provenance, usage rights, and user consent. Procedural data synthesis also
provides us with explicit control on data diversity, that we can use to address
unfairness in the models we train. Extensive quantitative assessment on real
input images demonstrates accuracy of our models on three dense prediction
tasks: depth estimation, surface normal estimation, and soft foreground
segmentation. Our models require only a fraction of the cost of training and
inference when compared with foundational models of similar accuracy. Our
human-centric synthetic dataset and trained models are available at
https://aka.ms/DAViD.

</details>


### [104] [Rethinking Occlusion in FER: A Semantic-Aware Perspective and Go Beyond](https://arxiv.org/abs/2507.15401)
*Huiyu Zhai,Xingxing Yang,Yalan Ye,Chenyang Li,Bin Fan,Changze Li*

Main category: cs.CV

TL;DR: ORSANet通过结合语义分割图和面部关键点，并使用创新的模块和损失函数，有效解决了面部遮挡问题，提升了面部表情识别的准确率。


<details>
  <summary>Details</summary>
Motivation: 现有的面部表情识别模型在处理部分遮挡的面部信息时，难以提取有效的面部特征，导致分类不准确。

Method: ORSANet提出了一种新的面部表情识别方法，包含三个关键贡献：1.引入多模态语义引导（语义分割图和面部关键点）来处理面部遮挡问题，学习高层语义知识。2.设计了多尺度交叉交互模块（MCM）来融合多模态先验信息。3.提出了动态对抗排斥增强损失（DARELoss）来区分相似表情。

Result: ORSANet通过引入多模态语义引导、多尺度交叉交互模块和动态对抗排斥增强损失，在包含遮挡的面部表情识别任务上取得了先进的性能。

Conclusion: ORSANet在公开基准和Occlu-FER上实现了最先进的识别性能。

Abstract: Facial expression recognition (FER) is a challenging task due to pervasive
occlusion and dataset biases. Especially when facial information is partially
occluded, existing FER models struggle to extract effective facial features,
leading to inaccurate classifications. In response, we present ORSANet, which
introduces the following three key contributions: First, we introduce auxiliary
multi-modal semantic guidance to disambiguate facial occlusion and learn
high-level semantic knowledge, which is two-fold: 1) we introduce semantic
segmentation maps as dense semantics prior to generate semantics-enhanced
facial representations; 2) we introduce facial landmarks as sparse geometric
prior to mitigate intrinsic noises in FER, such as identity and gender biases.
Second, to facilitate the effective incorporation of these two multi-modal
priors, we customize a Multi-scale Cross-interaction Module (MCM) to adaptively
fuse the landmark feature and semantics-enhanced representations within
different scales. Third, we design a Dynamic Adversarial Repulsion Enhancement
Loss (DARELoss) that dynamically adjusts the margins of ambiguous classes,
further enhancing the model's ability to distinguish similar expressions. We
further construct the first occlusion-oriented FER dataset to facilitate
specialized robustness analysis on various real-world occlusion conditions,
dubbed Occlu-FER. Extensive experiments on both public benchmarks and Occlu-FER
demonstrate that our proposed ORSANet achieves SOTA recognition performance.
Code is publicly available at https://github.com/Wenyuzhy/ORSANet-master.

</details>


### [105] [SurgX: Neuron-Concept Association for Explainable Surgical Phase Recognition](https://arxiv.org/abs/2507.15418)
*Ka Young Kim,Hyeon Bae Kim,Seong Tae Kim*

Main category: cs.CV

TL;DR: SurgX通过概念关联提高手术阶段识别模型的可解释性，解决了深度学习模型的不透明性问题。


<details>
  <summary>Details</summary>
Motivation: 深度学习模型在手术阶段识别方面存在固有的不透明性，难以理解其决策过程，这阻碍了信任并使模型调试变得困难。

Method: 提出了一种名为SurgX的新型基于概念的解释框架，包括选择代表性示例序列、构建定制化概念集、将神经元与概念相关联以及识别对预测至关重要的神经元。

Result: 通过在两个手术阶段识别模型上进行的大量实验，验证了SurgX方法的有效性，并分析了其预测解释。

Conclusion: SurgX框架通过将神经元与相关概念相关联，增强了手术阶段识别模型的可解释性，并通过实验验证了其有效性。

Abstract: Surgical phase recognition plays a crucial role in surgical workflow
analysis, enabling various applications such as surgical monitoring, skill
assessment, and workflow optimization. Despite significant advancements in deep
learning-based surgical phase recognition, these models remain inherently
opaque, making it difficult to understand how they make decisions. This lack of
interpretability hinders trust and makes it challenging to debug the model. To
address this challenge, we propose SurgX, a novel concept-based explanation
framework that enhances the interpretability of surgical phase recognition
models by associating neurons with relevant concepts. In this paper, we
introduce the process of selecting representative example sequences for
neurons, constructing a concept set tailored to the surgical video dataset,
associating neurons with concepts and identifying neurons crucial for
predictions. Through extensive experiments on two surgical phase recognition
models, we validate our method and analyze the explanation for prediction. This
highlights the potential of our method in explaining surgical phase
recognition. The code is available at https://github.com/ailab-kyunghee/SurgX

</details>


### [106] [EgoPrune: Efficient Token Pruning for Egomotion Video Reasoning in Embodied Agent](https://arxiv.org/abs/2507.15428)
*Jiaao Li,Kaiyuan Li,Chen Gao,Yong Li,Xinlei Chen*

Main category: cs.CV

TL;DR: EgoPrune是一种创新的免训练方法，通过关键帧选择、视角感知冗余过滤和MMR选择器，显著提升了第一人称视频的推理效率，降低了计算成本，并成功应用于边缘设备。


<details>
  <summary>Details</summary>
Motivation: 为了提高第一人称视角（egomotion）视频推理的效率，以应对其在具身AI（embodied AI）代理中作为主要视觉输入的需求。现有的基于视觉-语言模型的方法计算成本高昂，不适用于长视频输入，而为第三人称视频设计的令牌剪除方法未能充分利用第一人称视频的时空连续性和运动约束。

Method: EgoPrune包含三个主要组件：1. 关键帧选择器：用于从视频中高效地抽取时间子集。2. 视角感知冗余过滤（PARF）：通过视角变换对齐视觉令牌并去除冗余信息。3. 最大边缘相关性（MMR）令牌选择器：综合考虑视觉-文本相关性和帧内多样性来选择令牌。

Result: EgoPrune在两个第一人称视频基准测试中，无论在何种剪除比例下，其性能始终优于之前的免训练方法。同时，它显著降低了计算量（FLOPs）、内存占用和延迟。该方法已成功部署在搭载Jetson Orin NX 16GB边缘设备的具身代理上，证明了其在边缘计算环境下的高效性和实用性。

Conclusion: EgoPrune是一种针对自主移动视频推理的免训练（training-free）的令牌剪除方法，它通过关键帧选择、视角感知冗余过滤（PARF）和最大边缘相关性（MMR）令牌选择，有效解决了现有方法在处理长视频输入时的计算成本问题。实验证明，EgoPrune在性能上优于先前免训练方法，并显著降低了计算量、内存使用和延迟。此外，该方法已成功部署在边缘设备上，展示了其在实际应用中的高效性和适用性。

Abstract: Egomotion videos are first-person recordings where the view changes
continuously due to the agent's movement. As they serve as the primary visual
input for embodied AI agents, making egomotion video reasoning more efficient
is therefore essential for real-world deployment. Recent advances in
vision-language models have enabled strong multimodal reasoning capabilities,
but their computational cost remains prohibitive for long, redundant video
inputs. Existing token pruning methods, typically designed for third-person
videos, fail to leverage the spatiotemporal continuity and motion constraints
inherent in egomotion settings. To address this, we propose EgoPrune, a
training-free token pruning method tailored for egomotion video reasoning.
EgoPrune comprises three components: a keyframe selector adapted from EmbodiedR
for temporally efficient sampling; Perspective-Aware Redundancy Filtering
(PARF), which aligns visual tokens using perspective transformations and
removes redundant tokens; and a Maximal Marginal Relevance (MMR)-based token
selector that jointly considers visual-text relevance and intra-frame
diversity. Experiments on two egomotion video benchmarks show that EgoPrune
consistently outperforms prior training-free methods across various pruning
ratios while significantly reducing FLOPs, memory usage, and latency. Moreover,
we deploy EgoPrune on an embodied agent equipped with a Jetson Orin NX 16GB
edge device, demonstrating its real-world efficiency and suitability for
on-device egomotion video reasoning.

</details>


### [107] [One Last Attention for Your Vision-Language Model](https://arxiv.org/abs/2507.15480)
*Liang Chen,Ghazi Shazan Ahmad,Tianjun Yao,Lingqiao Liu,Zhiqiang Shen*

Main category: cs.CV

TL;DR: RAda 是一种新的 VLM 微调方法，通过利用最终的融合表示来改进下游任务的性能。


<details>
  <summary>Details</summary>
Motivation: 大多数 VLM 微调方法通常侧重于从单独的模态（文本或视觉）中精炼表示，而忽略了它们在决策过程（即驱动最终预测的理性矩阵）中融合表示的关键作用。为了弥合这一差距，我们提出了一种简单而有效的理性适应 (RAda) 方法，在微调过程中显式地利用最终的融合表示。

Method: RAda 采用了一个在 VLM 末端附加的轻量级注意力层学习到的掩码，以动态校准理性矩阵中每个元素的贡献，从而在不产生高昂的中间特征修改成本的情况下，对最终的跨模态交互进行有针对性的调整。

Result: 实验表明，RAda 是一种多功能微调技术，能够改进基线并与当前最先进的技术相媲美。

Conclusion: RAda 是一种多功能微调技术，在大多数设置中都能以最少的代码改进基线并与当前技术相媲美。

Abstract: Pretrained vision-language models (VLMs), such as CLIP, achieve remarkable
zero-shot performance, yet their downstream potential hinges on effective
fine-tuning. Most adaptation methods typically focus on refining representation
from separate modalities (text or vision) but neglect the critical role of
their fused representations in the decision-making process, \emph{\ie} rational
matrix that drives the final prediction. To bridge the gap, we propose a simple
yet effective \textbf{R}ational \textbf{Ada}ptaion ({RAda}) to explicitly
exploit the final fused representation during fine-tuning. RAda employs a
learned mask, obtained from a lightweight attention layer attached at the end
of a VLM, to dynamically calibrate the contribution of each element in the
rational matrix, enabling targeted adjustments to the final cross-modal
interactions without incurring costly modifications to intermediate features.
Experiments in different settings (i.e., updating, or freezing pretrained
encoders in adaptation, and test-time training that can only access the
unlabeled test data) show that RAda serves as a versatile fine-tuning
technique, improving the baseline with minimal code and performing comparably
against current arts in most settings. Code is available at
\href{https://github.com/khufia/RAda/tree/main}{github.com/khufia/RAda}.

</details>


### [108] [An aerial color image anomaly dataset for search missions in complex forested terrain](https://arxiv.org/abs/2507.15492)
*Rakesh John Amala Arokia Nathan,Matthias Gessner,Nurullah Özkan,Marius Bock,Mohamed Youssef,Maximilian Mews,Björn Piltz,Ralf Berger,Oliver Bimber*

Main category: cs.CV

TL;DR: 由于森林茂密，搜寻失踪人员困难重重，因此创建了一个包含众包标注异常的数据集，以改进搜索技术。


<details>
  <summary>Details</summary>
Motivation: 在一次家庭谋杀案的搜捕行动中，由于植被茂密，自动化分析效果不佳，需要众包搜索来寻找线索。

Method: 通过众包搜索和标注真实世界条件下难以检测的异常来创建数据集。

Result: 创建了一个包含标注的、在遮挡条件下难以检测的异常的独特数据集，并进行了基准测试，表明现有方法的性能不佳。

Conclusion: 该数据集可作为在复杂的森林环境中改进异常检测方法的基准，以支持搜捕和救援行动。现有的方法表现不佳，凸显了上下文感知方法的需求。

Abstract: After a family murder in rural Germany, authorities failed to locate the
suspect in a vast forest despite a massive search. To aid the search, a
research aircraft captured high-resolution aerial imagery. Due to dense
vegetation obscuring small clues, automated analysis was ineffective, prompting
a crowd-search initiative. This effort produced a unique dataset of labeled,
hard-to-detect anomalies under occluded, real-world conditions. It can serve as
a benchmark for improving anomaly detection approaches in complex forest
environments, supporting manhunts and rescue operations. Initial benchmark
tests showed existing methods performed poorly, highlighting the need for
context-aware approaches. The dataset is openly accessible for offline
processing. An additional interactive web interface supports online viewing and
dynamic growth by allowing users to annotate and submit new findings.

</details>


### [109] [Quantifying and Narrowing the Unknown: Interactive Text-to-Video Retrieval via Uncertainty Minimization](https://arxiv.org/abs/2507.15504)
*Bingqing Zhang,Zhuo Cao,Heming Du,Yang Li,Xue Li,Jiajun Liu,Sen Wang*

Main category: cs.CV

TL;DR: UMIVR是一个创新的交互式文本到视频检索框架，通过量化和最小化文本模糊性、映射不确定性和帧不确定性来提高检索性能。


<details>
  <summary>Details</summary>
Motivation: 当前的文本到视频检索（TVR）系统在处理模糊的文本查询、不明确的文本-视频映射以及低质量的视频帧方面存在挑战。虽然交互式系统试图通过澄清问题来解决这些问题，但它们通常缺乏对不确定性的明确量化，限制了其有效性。

Method: UMIVR框架通过基于语义熵的文本模糊性评分（TAS）、基于Jensen-Shannon散度的映射不确定性评分（MUS）以及基于时间质量的帧采样器（TQFS）来量化文本模糊性、映射不确定性和帧不确定性，并利用这些度量来生成有针对性的澄清问题，以迭代地优化用户查询。

Result: 在MSR-VTT-1k数据集上，UMIVR在10轮交互后实现了69.2%的召回率@1，在多个基准测试上均取得了显著的性能提升，证明了其有效性。

Conclusion: UMIVR通过量化文本模糊性、映射不确定性和帧不确定性，并利用这些度量来指导交互式问题生成，从而有效减少检索歧义，在MSR-VTT-1k数据集上实现了显著的召回率提升，为交互式文本到视频检索奠定了基础。

Abstract: Despite recent advances, Text-to-video retrieval (TVR) is still hindered by
multiple inherent uncertainties, such as ambiguous textual queries, indistinct
text-video mappings, and low-quality video frames. Although interactive systems
have emerged to address these challenges by refining user intent through
clarifying questions, current methods typically rely on heuristic or ad-hoc
strategies without explicitly quantifying these uncertainties, limiting their
effectiveness. Motivated by this gap, we propose UMIVR, an
Uncertainty-Minimizing Interactive Text-to-Video Retrieval framework that
explicitly quantifies three critical uncertainties-text ambiguity, mapping
uncertainty, and frame uncertainty-via principled, training-free metrics:
semantic entropy-based Text Ambiguity Score (TAS), Jensen-Shannon
divergence-based Mapping Uncertainty Score (MUS), and a Temporal Quality-based
Frame Sampler (TQFS). By adaptively generating targeted clarifying questions
guided by these uncertainty measures, UMIVR iteratively refines user queries,
significantly reducing retrieval ambiguity. Extensive experiments on multiple
benchmarks validate UMIVR's effectiveness, achieving notable gains in Recall@1
(69.2\% after 10 interactive rounds) on the MSR-VTT-1k dataset, thereby
establishing an uncertainty-minimizing foundation for interactive TVR.

</details>


### [110] [SAIGFormer: A Spatially-Adaptive Illumination-Guided Network for Low-Light Image Enhancement](https://arxiv.org/abs/2507.15520)
*Hanting Li,Fei Zhou,Xin Sun,Yang Hua,Jungong Han,Liang-Jie Zhang*

Main category: cs.CV

TL;DR: SAIGFormer通过动态积分图像和光照引导自注意力机制，解决了低光照图像增强中的非均匀光照问题，并在实验中取得了优异的成果。


<details>
  <summary>Details</summary>
Motivation: 解决现有Transformer方法在非均匀光照（如背光和阴影）场景下出现曝光过度或亮度恢复不足的问题。

Method: 提出了一种空间自适应光照引导Transformer（SAIGFormer）框架，该框架包括动态积分图像表示、空间自适应积分光照估计器（SAI2E）和光照引导多头自注意力（IG-MSA）机制。

Result: SAIGFormer在五个标准低光数据集和一个跨域基准（LOL-Blur）上进行了广泛的实验，其在定量和定性指标上均显著优于最先进的方法。

Conclusion: SAIGFormer在非均匀光照增强方面表现出色，并具有强大的跨数据集泛化能力。

Abstract: Recent Transformer-based low-light enhancement methods have made promising
progress in recovering global illumination. However, they still struggle with
non-uniform lighting scenarios, such as backlit and shadow, appearing as
over-exposure or inadequate brightness restoration. To address this challenge,
we present a Spatially-Adaptive Illumination-Guided Transformer (SAIGFormer)
framework that enables accurate illumination restoration. Specifically, we
propose a dynamic integral image representation to model the spatially-varying
illumination, and further construct a novel Spatially-Adaptive Integral
Illumination Estimator ($\text{SAI}^2\text{E}$). Moreover, we introduce an
Illumination-Guided Multi-head Self-Attention (IG-MSA) mechanism, which
leverages the illumination to calibrate the lightness-relevant features toward
visual-pleased illumination enhancement. Extensive experiments on five standard
low-light datasets and a cross-domain benchmark (LOL-Blur) demonstrate that our
SAIGFormer significantly outperforms state-of-the-art methods in both
quantitative and qualitative metrics. In particular, our method achieves
superior performance in non-uniform illumination enhancement while exhibiting
strong generalization capabilities across multiple datasets. Code is available
at https://github.com/LHTcode/SAIGFormer.git.

</details>


### [111] [Procedure Learning via Regularized Gromov-Wasserstein Optimal Transport](https://arxiv.org/abs/2507.15540)
*Syed Ahmed Mahmood,Ali Shah Ali,Umer Ahmed,Fawad Javed Fateh,M. Zeeshan Zia,Quoc-Huy Tran*

Main category: cs.CV

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: We study the problem of self-supervised procedure learning, which discovers
key steps and establishes their order from a set of unlabeled procedural
videos. Previous procedure learning methods typically learn frame-to-frame
correspondences between videos before determining key steps and their order.
However, their performance often suffers from order variations,
background/redundant frames, and repeated actions. To overcome these
challenges, we propose a self-supervised procedure learning framework, which
utilizes a fused Gromov-Wasserstein optimal transport formulation with a
structural prior for computing frame-to-frame mapping between videos. However,
optimizing exclusively for the above temporal alignment term may lead to
degenerate solutions, where all frames are mapped to a small cluster in the
embedding space and hence every video is associated with only one key step. To
address that limitation, we further integrate a contrastive regularization
term, which maps different frames to different points in the embedding space,
avoiding the collapse to trivial solutions. Finally, we conduct extensive
experiments on large-scale egocentric (i.e., EgoProceL) and third-person (i.e.,
ProceL and CrossTask) benchmarks to demonstrate superior performance by our
approach against previous methods, including OPEL which relies on a traditional
Kantorovich optimal transport formulation with an optimality prior.

</details>


### [112] [Towards Holistic Surgical Scene Graph](https://arxiv.org/abs/2507.15541)
*Jongmin Shin,Enki Cho,Ka Yong Kim,Jung Yong Kim,Seong Tae Kim,Namkee Oh*

Main category: cs.CV

TL;DR: 提出Endoscapes-SG201数据集和SSG-Com方法，通过包含工具-动作-目标组合和手部身份信息，改进了手术场景图表示，并在下游任务中取得了更好的性能。


<details>
  <summary>Details</summary>
Motivation: 以往的手术场景图研究虽然可行，但在表示工具-动作-目标组合和手部身份等方面仍有不足，而这些方面对手术场景的理解至关重要。

Method: 提出Endoscapes-SG201数据集，其中包含工具-动作-目标组合和手部身份的注释。引入SSG-Com，这是一种基于图的方法，用于学习和表示这些关键要素。

Result: 所提出的SSG-Com方法在关键安全视角评估和动作三元组识别等下游任务中，通过集成工具-动作-目标组合和手部身份信息，显著提高了手术场景理解的性能。

Conclusion: 通过实验证明了集成这些关键场景图组件的重要性，凸显了它们对手术场景理解的重大贡献。

Abstract: Surgical scene understanding is crucial for computer-assisted intervention
systems, requiring visual comprehension of surgical scenes that involves
diverse elements such as surgical tools, anatomical structures, and their
interactions. To effectively represent the complex information in surgical
scenes, graph-based approaches have been explored to structurally model
surgical entities and their relationships. Previous surgical scene graph
studies have demonstrated the feasibility of representing surgical scenes using
graphs. However, certain aspects of surgical scenes-such as diverse
combinations of tool-action-target and the identity of the hand operating the
tool-remain underexplored in graph-based representations, despite their
importance. To incorporate these aspects into graph representations, we propose
Endoscapes-SG201 dataset, which includes annotations for tool-action-target
combinations and hand identity. We also introduce SSG-Com, a graph-based method
designed to learn and represent these critical elements. Through experiments on
downstream tasks such as critical view of safety assessment and action triplet
recognition, we demonstrated the importance of integrating these essential
scene graph components, highlighting their significant contribution to surgical
scene understanding. The code and dataset are available at
https://github.com/ailab-kyunghee/SSG-Com

</details>


### [113] [HOLa: Zero-Shot HOI Detection with Low-Rank Decomposed VLM Feature Adaptation](https://arxiv.org/abs/2507.15542)
*Qinqian Lei,Bo Wang,Robby T. Tan*

Main category: cs.CV

TL;DR: HOLa是一种新颖的零样本HOI检测方法，通过低秩分解VLM特征和LLM驱动的正则化，提高了对不可见类别的泛化能力和动作区分能力。


<details>
  <summary>Details</summary>
Motivation: 为了提高零样本HOI检测中对不可见动作的泛化能力和动作区分能力。

Method: HOLa首先通过低秩分解VLM文本特征，生成类别共享的基线特征和可适应的权重。然后，为每个HOI类别调整权重，并引入人-物标记以丰富视觉交互表示。最后，使用LLM派生的动作正则化来指导权重调整。

Result: HOLa在HICO-DET数据集的零样本HOI设置上达到了新的最先进水平，在不可见动词设置下实现了27.91的不可见类别mAP。

Conclusion: HOLa通过低秩分解VLM文本特征，生成类别共享的基线特征和可适应的权重，形成紧凑的HOI表示，以提高对不可见类别的泛化能力。此外，通过为每个HOI类别调整权重并引入人-物标记以丰富视觉交互表示来优化动作区分，并使用LLM派生的动作正则化来指导权重调整，以进一步区分不可见动作。

Abstract: Zero-shot human-object interaction (HOI) detection remains a challenging
task, particularly in generalizing to unseen actions. Existing methods address
this challenge by tapping Vision-Language Models (VLMs) to access knowledge
beyond the training data. However, they either struggle to distinguish actions
involving the same object or demonstrate limited generalization to unseen
classes. In this paper, we introduce HOLa (Zero-Shot HOI Detection with
Low-Rank Decomposed VLM Feature Adaptation), a novel approach that both
enhances generalization to unseen classes and improves action distinction. In
training, HOLa decomposes VLM text features for given HOI classes via low-rank
factorization, producing class-shared basis features and adaptable weights.
These features and weights form a compact HOI representation that preserves
shared information across classes, enhancing generalization to unseen classes.
Subsequently, we refine action distinction by adapting weights for each HOI
class and introducing human-object tokens to enrich visual interaction
representations. To further distinguish unseen actions, we guide the weight
adaptation with LLM-derived action regularization. Experimental results show
that our method sets a new state-of-the-art across zero-shot HOI settings on
HICO-DET, achieving an unseen-class mAP of 27.91 in the unseen-verb setting.
Our code is available at https://github.com/ChelsieLei/HOLa.

</details>


### [114] [DynImg: Key Frames with Visual Prompts are Good Representation for Multi-Modal Video Understanding](https://arxiv.org/abs/2507.15569)
*Xiaoyi Bao,Chenwei Xie,Hao Tang,Tingyu Weng,Xiaofeng Wang,Yun Zheng,Xingang Wang*

Main category: cs.CV

TL;DR: DynImg通过使用时间提示（非关键帧）来增强MLLMs在视频理解中的时空交互能力，尤其是在处理快速移动物体时，取得了显著的性能提升。


<details>
  <summary>Details</summary>
Motivation: 现有的多模态大语言模型（MLLMs）在视频理解任务中存在如何有效整合时间信息的问题。传统方法将空间和时间信息分开处理，由于运动模糊等问题，快速移动物体的空间信息难以准确表示，导致时间上重要的区域在空间特征提取中被忽视，从而阻碍了准确的时空交互和视频理解。

Method: 提出了一种名为动态图像（DynImg）的视频表示方法，该方法引入非关键帧作为时间提示，以突出包含快速移动物体的空间区域，并使用4D视频旋转位置嵌入来保持DynImg的正确顺序，保留其时空邻接性。

Result: 实验评估表明，DynImg在多个视频理解基准测试中的表现优于现有最先进的方法约2%。

Conclusion: DynImg 通过引入非关键帧作为时间提示，引导模型关注快速移动物体的空间区域，并结合4D视频旋转位置嵌入来保留时空邻接性，在多个视频理解基准测试中取得了约2%的提升，证明了其有效性。

Abstract: In recent years, the introduction of Multi-modal Large Language Models
(MLLMs) into video understanding tasks has become increasingly prevalent.
However, how to effectively integrate temporal information remains a critical
research focus. Traditional approaches treat spatial and temporal information
separately. Due to issues like motion blur, it is challenging to accurately
represent the spatial information of rapidly moving objects. This can lead to
temporally important regions being underemphasized during spatial feature
extraction, which in turn hinders accurate spatio-temporal interaction and
video understanding. To address this limitation, we propose an innovative video
representation method called Dynamic-Image (DynImg). Specifically, we introduce
a set of non-key frames as temporal prompts to highlight the spatial areas
containing fast-moving objects. During the process of visual feature
extraction, these prompts guide the model to pay additional attention to the
fine-grained spatial features corresponding to these regions. Moreover, to
maintain the correct sequence for DynImg, we employ a corresponding 4D video
Rotary Position Embedding. This retains both the temporal and spatial adjacency
of DynImg, helping MLLM understand the spatio-temporal order within this
combined format. Experimental evaluations reveal that DynImg surpasses the
state-of-the-art methods by approximately 2% across multiple video
understanding benchmarks, proving the effectiveness of our temporal prompts in
enhancing video comprehension.

</details>


### [115] [GeMix: Conditional GAN-Based Mixup for Improved Medical Image Augmentation](https://arxiv.org/abs/2507.15577)
*Hugo Carlesso,Maria Eliza Patulea,Moncef Garouani,Radu Tudor Ionescu,Josiane Mothe*

Main category: cs.CV

TL;DR: GeMix is a novel augmentation strategy that uses GANs to create more realistic interpolated images, improving performance in medical image classification tasks compared to traditional Mixup.


<details>
  <summary>Details</summary>
Motivation: Naive pixel-wise interpolation in Mixup produces unrealistic images that can hinder learning, particularly in high-stakes medical applications. GeMix aims to replace heuristic blending with a learned, label-aware interpolation powered by class-conditional GANs.

Method: GeMix is a two-stage framework that uses a StyleGAN2-ADA generator trained on the target dataset. It samples two label vectors from Dirichlet priors biased toward different classes and blends them via a Beta-distributed coefficient. The generator is then conditioned on this soft label to synthesize visually coherent images that lie along a continuous class manifold.

Result: GeMix increases macro-F1 over traditional mixup for all tested backbones (ResNet-50, ResNet-101, EfficientNet-B0) on the COVIDx-CT-3 dataset, reducing the false negative rate for COVID-19 detection.

Conclusion: GeMix is a drop-in replacement for pixel-space mixup, delivering stronger regularization and greater semantic fidelity, without disrupting existing training pipelines.

Abstract: Mixup has become a popular augmentation strategy for image classification,
yet its naive pixel-wise interpolation often produces unrealistic images that
can hinder learning, particularly in high-stakes medical applications. We
propose GeMix, a two-stage framework that replaces heuristic blending with a
learned, label-aware interpolation powered by class-conditional GANs. First, a
StyleGAN2-ADA generator is trained on the target dataset. During augmentation,
we sample two label vectors from Dirichlet priors biased toward different
classes and blend them via a Beta-distributed coefficient. Then, we condition
the generator on this soft label to synthesize visually coherent images that
lie along a continuous class manifold. We benchmark GeMix on the large-scale
COVIDx-CT-3 dataset using three backbones (ResNet-50, ResNet-101,
EfficientNet-B0). When combined with real data, our method increases macro-F1
over traditional mixup for all backbones, reducing the false negative rate for
COVID-19 detection. GeMix is thus a drop-in replacement for pixel-space mixup,
delivering stronger regularization and greater semantic fidelity, without
disrupting existing training pipelines. We publicly release our code at
https://github.com/hugocarlesso/GeMix to foster reproducibility and further
research.

</details>


### [116] [Compress-Align-Detect: onboard change detection from unregistered images](https://arxiv.org/abs/2507.15578)
*Gabriele Inzerillo,Diego Valsesia,Aniello Fiengo,Enrico Magli*

Main category: cs.CV

TL;DR: 该研究提出了一个创新的框架，将图像压缩、共配准和变更检测集成到卫星上，以实现实时变更检测，并达到了显著的性能。


<details>
  <summary>Details</summary>
Motivation: 卫星图像的变更检测通常会有几个小时到几天的延迟，因为获取的图像需要下行链路，并且地面站需要生成正射校正的图像产品；这可能会阻碍实时或近实时应用。

Method: 该研究提出了一个新颖高效的在轨变更检测框架，通过深度神经网络以端到端的方式解决了这些挑战，该网络由三个相互关联的子模块组成：(1) 图像压缩，旨在最大限度地减少机载数据存储资源；(2) 轻量级的、非正射校正的多时相图像对的共配准；(3) 一个新颖的、时间不变且计算高效的变更检测模型。

Result: 在压缩率方面的 F1 分数方面获得了有吸引力的变更检测结果，在 15W 加速器上能够维持 0.7 Mpixel/s 的吞吐量。

Conclusion: 该研究提出了首个将所有这些任务结合在一个端到端框架中，并满足在轨处理的限制。

Abstract: Change detection from satellite images typically incurs a delay ranging from
several hours up to days because of latency in downlinking the acquired images
and generating orthorectified image products at the ground stations; this may
preclude real- or near real-time applications. To overcome this limitation, we
propose shifting the entire change detection workflow onboard satellites. This
requires to simultaneously solve challenges in data storage, image registration
and change detection with a strict complexity constraint. In this paper, we
present a novel and efficient framework for onboard change detection that
addresses the aforementioned challenges in an end-to-end fashion with a deep
neural network composed of three interlinked submodules: (1) image compression,
tailored to minimize onboard data storage resources; (2) lightweight
co-registration of non-orthorectified multi-temporal image pairs; and (3) a
novel temporally-invariant and computationally efficient change detection
model. This is the first approach in the literature combining all these tasks
in a single end-to-end framework with the constraints dictated by onboard
processing. Experimental results compare each submodule with the current
state-of-the-art, and evaluate the performance of the overall integrated system
in realistic setting on low-power hardware. Compelling change detection results
are obtained in terms of F1 score as a function of compression rate, sustaining
a throughput of 0.7 Mpixel/s on a 15W accelerator.

</details>


### [117] [SegDT: A Diffusion Transformer-Based Segmentation Model for Medical Imaging](https://arxiv.org/abs/2507.15595)
*Salah Eddine Bekhouche,Gaby Maroun,Fadi Dornaika,Abdenour Hadid*

Main category: cs.CV

TL;DR: SegDT是一种基于扩散Transformer和Rectified Flow的新型皮肤病变分割模型，可在低成本硬件上运行，具有快速推理和最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 解决医疗图像分割，特别是皮肤病变分割的问题，以辅助疾病诊断和治疗规划。

Method: 提出了一种名为SegDT的新型分割模型，该模型基于扩散Transformer（DiT），并结合了Rectified Flow。

Result: SegDT在三个基准数据集上取得了最先进的结果，并且推理速度快。

Conclusion: SegDT在三个基准数据集上的表现优于现有方法，同时保持了快速的推理速度，使其在实际医疗应用中具有吸引力。

Abstract: Medical image segmentation is crucial for many healthcare tasks, including
disease diagnosis and treatment planning. One key area is the segmentation of
skin lesions, which is vital for diagnosing skin cancer and monitoring
patients. In this context, this paper introduces SegDT, a new segmentation
model based on diffusion transformer (DiT). SegDT is designed to work on
low-cost hardware and incorporates Rectified Flow, which improves the
generation quality at reduced inference steps and maintains the flexibility of
standard diffusion models. Our method is evaluated on three benchmarking
datasets and compared against several existing works, achieving
state-of-the-art results while maintaining fast inference speeds. This makes
the proposed model appealing for real-world medical applications. This work
advances the performance and capabilities of deep learning models in medical
image analysis, enabling faster, more accurate diagnostic tools for healthcare
professionals. The code is made publicly available at
\href{https://github.com/Bekhouche/SegDT}{GitHub}.

</details>


### [118] [SurfaceSplat: Connecting Surface Reconstruction and Gaussian Splatting](https://arxiv.org/abs/2507.15602)
*Zihui Gao,Jia-Wang Bian,Guosheng Lin,Hao Chen,Chunhua Shen*

Main category: cs.CV

TL;DR: 提出了一种结合SDF和3DGS优点的混合方法，以解决稀疏视图表面重建和新视图渲染的挑战，并在DTU和MobileBrick数据集上取得了SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 解决从稀疏视图图像进行表面重建和新视图渲染的挑战。SDF方法难以处理精细细节，而3DGS方法缺乏全局几何一致性。

Method: 提出了一种新颖的混合方法，结合了SDF和3D高斯泼溅（3DGS）的优点。SDF捕捉粗糙几何以增强3DGS渲染，而3DGS的新渲染图像则用于精炼SDF的细节以实现精确的表面重建。

Result: 所提出的混合方法在表面重建和新视图渲染方面取得了优于现有最先进方法的性能。

Conclusion: 该方法在DTU和MobileBrick数据集上超越了最先进的方法，在表面重建和新视角合成方面表现优异。

Abstract: Surface reconstruction and novel view rendering from sparse-view images are
challenging. Signed Distance Function (SDF)-based methods struggle with fine
details, while 3D Gaussian Splatting (3DGS)-based approaches lack global
geometry coherence. We propose a novel hybrid method that combines the
strengths of both approaches: SDF captures coarse geometry to enhance
3DGS-based rendering, while newly rendered images from 3DGS refine the details
of SDF for accurate surface reconstruction. As a result, our method surpasses
state-of-the-art approaches in surface reconstruction and novel view synthesis
on the DTU and MobileBrick datasets. Code will be released at
https://github.com/Gaozihui/SurfaceSplat.

</details>


### [119] [CylinderPlane: Nested Cylinder Representation for 3D-aware Image Generation](https://arxiv.org/abs/2507.15606)
*Ru Jia,Xiaozhuang Ma,Jianji Wang,Nanning Zheng*

Main category: cs.CV

TL;DR: CylinderPlane uses a cylindrical coordinate system to improve 360° image generation by avoiding artifacts common in Tri-plane methods, and it works well with different resolutions and rendering techniques.


<details>
  <summary>Details</summary>
Motivation: To address the limitations of Tri-plane representation in 3D-aware image generative models, specifically the multi-face artifacts caused by feature sharing in symmetric regions, which hinder the generation of consistent 360° view images.

Method: The proposed method utilizes a Cylindrical Coordinate System for feature representation, explicitly separating features at different angles to avoid the multi-face artifacts seen in Tri-plane representations. It also introduces a nested cylinder representation that composites multiple cylinders at different scales to handle complex geometry and varying resolutions, making it adaptable to different neural rendering pipelines.

Result: The CylinderPlane representation enables high-quality, artifacts-free 360° image synthesis by explicitly separating features at different angles. The nested cylinder representation further improves adaptability to complex geometry and varying resolutions, facilitating fine detail learning and robustness. Experiments show superior performance compared to existing methods on both synthetic and real-world images.

Conclusion: CylinderPlane, a novel implicit representation based on Cylindrical Coordinate System, eliminates feature ambiguity and ensures multi-view consistency for 360° image synthesis, achieving superior performance over previous methods.

Abstract: While the proposal of the Tri-plane representation has advanced the
development of the 3D-aware image generative models, problems rooted in its
inherent structure, such as multi-face artifacts caused by sharing the same
features in symmetric regions, limit its ability to generate 360$^\circ$ view
images. In this paper, we propose CylinderPlane, a novel implicit
representation based on Cylindrical Coordinate System, to eliminate the feature
ambiguity issue and ensure multi-view consistency in 360$^\circ$. Different
from the inevitable feature entanglement in Cartesian coordinate-based
Tri-plane representation, the cylindrical coordinate system explicitly
separates features at different angles, allowing our cylindrical representation
possible to achieve high-quality, artifacts-free 360$^\circ$ image synthesis.
We further introduce the nested cylinder representation that composites
multiple cylinders at different scales, thereby enabling the model more
adaptable to complex geometry and varying resolutions. The combination of
cylinders with different resolutions can effectively capture more critical
locations and multi-scale features, greatly facilitates fine detail learning
and robustness to different resolutions. Moreover, our representation is
agnostic to implicit rendering methods and can be easily integrated into any
neural rendering pipeline. Extensive experiments on both synthetic dataset and
unstructured in-the-wild images demonstrate that our proposed representation
achieves superior performance over previous methods.

</details>


### [120] [A Survey on Efficiency Optimization Techniques for DNN-based Video Analytics: Process Systems, Algorithms, and Applications](https://arxiv.org/abs/2507.15628)
*Shanjiang Tang,Rui Huang,Hsinyu Luo,Chunjiang Wang,Ce Yu,Yusen Li,Hao Fu,Chao Sun,and Jian Xiao*

Main category: cs.CV

TL;DR: 本调查专注于提高深度神经网络（DNN）在视频分析中效率的优化技术，涵盖硬件、数据处理和部署等方面，并讨论了现有方法的问题与挑战。


<details>
  <summary>Details</summary>
Motivation: 随着视频数据的爆炸式增长，对视频分析的需求不断增加，其中准确性和效率是两个主要关注点。尽管深度神经网络（DNN）已被广泛采用以确保准确性，但提高其在视频分析中的效率仍然是一个开放的挑战。

Method: 本调查旨在提供对 DNN 在视频分析中的效率优化技术的全面回顾，并按自下而上的方式组织现有方法，涵盖硬件支持、数据处理、操作部署等多个视角。

Result: 本调查全面回顾了 DNN 在视频分析中的效率优化技术，并分析了相关问题与挑战。

Conclusion: 深度神经网络（DNN）在视频分析中的效率优化仍然是一个开放的挑战。本调查全面回顾了 DNN 在视频分析中的效率优化技术，涵盖了硬件支持、数据处理、操作部署等多个视角，并分析了现有优化框架和工作中的问题与挑战。

Abstract: The explosive growth of video data in recent years has brought higher demands
for video analytics, where accuracy and efficiency remain the two primary
concerns. Deep neural networks (DNNs) have been widely adopted to ensure
accuracy; however, improving their efficiency in video analytics remains an
open challenge. Different from existing surveys that make summaries of
DNN-based video mainly from the accuracy optimization aspect, in this survey,
we aim to provide a thorough review of optimization techniques focusing on the
improvement of the efficiency of DNNs in video analytics. We organize existing
methods in a bottom-up manner, covering multiple perspectives such as hardware
support, data processing, operational deployment, etc. Finally, based on the
optimization framework and existing works, we analyze and discuss the problems
and challenges in the performance optimization of DNN-based video analytics.

</details>


### [121] [Experimenting active and sequential learning in a medieval music manuscript](https://arxiv.org/abs/2507.15633)
*Sachin Sharma,Federico Simonetta,Michele Flammini*

Main category: cs.CV

TL;DR: 该研究旨在探索主动学习（AL）和顺序学习（SL）在光学音乐识别（OMR）中的应用，以解决标注数据稀缺的问题。研究人员使用 YOLOv8 模型，通过选择不确定性最高的样本进行标注和训练，并在Medieval手稿上进行了实验。结果显示，与全监督学习相比，该方法在标注数据量大大减少的情况下，取得了相似的准确率。然而，研究也指出，在所用的手稿中，基于不确定性的AL效果不佳，并建议在数据稀缺的情况下探索更有效的方法。


<details>
  <summary>Details</summary>
Motivation: 光学音乐识别（OMR）是文化遗产中音乐数字化的基础，但其发展受到标注数据稀缺和历史手稿复杂性的限制。

Method: 利用 YOLOv8，该系统选择不确定性最高（预测置信度最低）的样本进行迭代标注和重新训练。

Result: 实验结果表明，用更少的标注样本可以达到与全监督训练相当的准确性。

Conclusion: 研究表明，在所用的手稿中，基于不确定性的主动学习（AL）效果不佳，并提倡在数据稀缺的情况下使用更有效的方法。

Abstract: Optical Music Recognition (OMR) is a cornerstone of music digitization
initiatives in cultural heritage, yet it remains limited by the scarcity of
annotated data and the complexity of historical manuscripts. In this paper, we
present a preliminary study of Active Learning (AL) and Sequential Learning
(SL) tailored for object detection and layout recognition in an old medieval
music manuscript. Leveraging YOLOv8, our system selects samples with the
highest uncertainty (lowest prediction confidence) for iterative labeling and
retraining. Our approach starts with a single annotated image and successfully
boosts performance while minimizing manual labeling. Experimental results
indicate that comparable accuracy to fully supervised training can be achieved
with significantly fewer labeled examples. We test the methodology as a
preliminary investigation on a novel dataset offered to the community by the
Anonymous project, which studies laude, a poetical-musical genre spread across
Italy during the 12th-16th Century. We show that in the manuscript at-hand,
uncertainty-based AL is not effective and advocates for more usable methods in
data-scarcity scenarios.

</details>


### [122] [Uncovering Critical Features for Deepfake Detection through the Lottery Ticket Hypothesis](https://arxiv.org/abs/2507.15636)
*Lisan Al Amin,Md. Ismail Hossain,Thanh Thi Nguyen,Tasnim Jahan,Mahbubul Islam,Faisal Quader*

Main category: cs.CV

TL;DR: 本研究将彩票假说应用于深度伪造检测，通过剪枝技术在保持高准确率的同时减小模型大小。研究发现，即使在80%稀疏度下，MesoNet也能保持约90%的准确率，并证明了所提方法的优越性和跨数据集的可迁移性，为开发高效的深度伪造检测系统提供了潜力。


<details>
  <summary>Details</summary>
Motivation: 深度伪造技术的进步带来了越来越逼真的合成媒体，对信息完整性和社会信任构成了重大挑战。现有的检测方法虽然有前景，但其底层机制理解不足，且模型庞大难以在资源受限的环境中部署。本研究旨在通过应用彩票假说（LTH）来解决这些问题，以识别对深度伪造检测至关重要的关键特征，并探索高效的剪枝方法。

Method: 本研究将彩票假说（LTH）应用于深度伪造检测，通过实验检查了神经网络如何在保持高检测准确率的同时进行有效剪枝。研究使用了MesoNet、CNN-5和ResNet-18架构，并在OpenForensic和FaceForensics++数据集上进行了广泛的实验。通过Grad-CAM可视化分析了剪枝网络如何保持对关键面部区域的关注。

Result: 研究发现，深度伪造检测网络包含“中奖彩票”，即子网络，可以在高稀疏度下保持性能。例如，MesoNet在OpenForensic数据集上，在80%的稀疏度下仍能保持56.2%的准确率，仅使用3000个参数，这接近其基线准确率（62.6%）。提出的基于LTH的迭代剪枝方法持续优于单次剪枝方法。可视化分析表明，剪枝网络能够关注关键面部区域。此外，“中奖彩票”在不同数据集之间表现出可转移性。

Conclusion: 该研究表明，深度伪造检测网络包含“中奖彩票”，即子网络，即使在高度稀疏的情况下也能保持性能。通过实验证明，基于LTH的迭代剪枝方法优于单次剪枝方法，并且所提出的剪枝网络能够关注关键面部区域进行深度伪造检测，同时展示了在不同数据集之间转移“中奖彩票”的潜力。

Abstract: Recent advances in deepfake technology have created increasingly convincing
synthetic media that poses significant challenges to information integrity and
social trust. While current detection methods show promise, their underlying
mechanisms remain poorly understood, and the large sizes of their models make
them challenging to deploy in resource-limited environments. This study
investigates the application of the Lottery Ticket Hypothesis (LTH) to deepfake
detection, aiming to identify the key features crucial for recognizing
deepfakes. We examine how neural networks can be efficiently pruned while
maintaining high detection accuracy. Through extensive experiments with
MesoNet, CNN-5, and ResNet-18 architectures on the OpenForensic and
FaceForensics++ datasets, we find that deepfake detection networks contain
winning tickets, i.e., subnetworks, that preserve performance even at
substantial sparsity levels. Our results indicate that MesoNet retains 56.2%
accuracy at 80% sparsity on the OpenForensic dataset, with only 3,000
parameters, which is about 90% of its baseline accuracy (62.6%). The results
also show that our proposed LTH-based iterative magnitude pruning approach
consistently outperforms one-shot pruning methods. Using Grad-CAM
visualization, we analyze how pruned networks maintain their focus on critical
facial regions for deepfake detection. Additionally, we demonstrate the
transferability of winning tickets across datasets, suggesting potential for
efficient, deployable deepfake detection systems.

</details>


### [123] [Extracting Visual Facts from Intermediate Layers for Mitigating Hallucinations in Multimodal Large Language Models](https://arxiv.org/abs/2507.15652)
*Haoran Zhou,Zihan Zhang,Hao Chen*

Main category: cs.CV

TL;DR: EVA通过提取中间层的视觉事实知识来减少MLLMs的幻觉。


<details>
  <summary>Details</summary>
Motivation: 为了解决MLLMs在物体识别方面存在的幻觉问题，即模型会生成包含图像中不存在的物体的似是而非但事实错误的内容。现有研究发现MLLMs的先验知识会抑制深度层中的视觉信息，但中间层如何抑制尚不清楚。

Method: EVA（Decoding by Extracting Visual Facts）通过对比中间层从原始输入和纯文本输入中提取视觉事实知识，并将其整合到最终层以纠正输出logits。

Result: EVA在广泛使用的基准测试中得到验证，与基线方法相比，显著降低了幻觉率，有效缓解了幻觉问题。

Conclusion: EVA是一种简单、无需训练的方法，通过动态选择具有最显著视觉事实信息的中间层，并对比其与纯文本输入输出分布的差异，从而提取视觉事实知识并将其按比例整合到最终层以纠正输出logits，能够有效减少幻觉。

Abstract: Multimodal Large Language Models (MLLMs) have made significant strides by
combining visual recognition and language understanding to generate content
that is both coherent and contextually accurate. However, MLLMs continue to
struggle with object hallucinations, where models produce seemingly plausible
but factually incorrect outputs, including objects that do not exist in the
image. Recent work has revealed that the prior knowledge in MLLMs significantly
suppresses visual information in deep layers, causing hallucinatory outputs.
However, how these priors suppress visual information at the intermediate layer
stage in MLLMs remains unclear. We observe that visual factual knowledge and
the differences between intermediate-layer prior/original probability
distributions show similar evolutionary trends in intermediate layers.
Motivated by this, we introduce Decoding by Extracting Visual Facts (EVA), a
simple, training-free method that dynamically selects intermediate layers with
the most significant visual factual information. By contrasting the output
distributions of the selected layer derived from the original input and
pure-text input, EVA extracts visual factual knowledge and proportionally
incorporates it into the final layer to correct the output logits. Importantly,
EVA is model-agnostic, seamlessly integrates with various classic decoding
strategies, and is applicable across different MLLMs. We validate EVA on
widely-used benchmarks, and the results show that it significantly reduces
hallucination rates compared to baseline methods, underscoring its
effectiveness in mitigating hallucinations.

</details>


### [124] [HW-MLVQA: Elucidating Multilingual Handwritten Document Understanding with a Comprehensive VQA Benchmark](https://arxiv.org/abs/2507.15655)
*Aniket Pal,Ajoy Mondal,Minesh Mathew,C. V. Jawahar*

Main category: cs.CV

TL;DR: 提出HW-MLVQA基准测试，以解决多语言手写文档理解的不足。该基准测试包含大量手写数据和问答对，并支持文本、图像及图文结合的评估模式，同时可用于评估OCR模型性能。


<details>
  <summary>Details</summary>
Motivation: 尽管多语言视觉问答（MLVQA）基准测试的能力不断增强，但当前MLVQA模型在处理多样化的手写文档时仍难以充分发挥其潜力。为了解决真实多语言手写文档理解能力不足的问题，我们提出了HW-MLVQA。

Method: 提出了一种名为HW-MLVQA的新型VQA基准测试，其中包含1600个手写页面和2400个问答对，并提供了一个涵盖文本、图像以及图像与文本集成三种模式的评估框架。为了模拟真实世界中缺乏地面真实文本转录的情况，该基准测试还支持对专有和开源OCR模型的评估。

Result: HW-MLVQA基准测试包含了大量的手写文档和问答对，并且提供了一个包含多种模态的评估框架，能够对OCR模型进行严格评估，从而促进多语言手写文档解析领域的发展。

Conclusion: 该基准测试旨在促进多语言手写文档解析领域的关键进展，激发该专业领域的创新和学术探究。

Abstract: The proliferation of MultiLingual Visual Question Answering (MLVQA)
benchmarks augments the capabilities of large language models (LLMs) and
multi-modal LLMs, thereby enabling them to adeptly capture the intricate
linguistic subtleties and visual complexities inherent across diverse
languages. Despite its potential, the current MLVQA model struggles to fully
utilize its capabilities when dealing with the extensive variety of handwritten
documents. This article delineates HW-MLVQA, an avant-garde VQA benchmark
meticulously crafted to mitigate the dearth of authentic Multilingual
Handwritten document comprehension. HW-MLVQA encompasses an extensive
collection of 1,600 handwritten Pages complemented by 2,400 question-answers.
Furthermore, it provides a robust benchmark evaluation framework spanning three
distinct modalities: text, image, and an integrated image & text modality. To
simulate authentic real-world contexts devoid of ground truth textual
transcriptions, we facilitates a rigorous assessment of proprietary and
open-source OCR models. The benchmark aspires to facilitate pivotal
advancements in multilingual handwritten document interpretation, fostering
innovation and scholarly inquiry within this specialized domain.

</details>


### [125] [Visual-Language Model Knowledge Distillation Method for Image Quality Assessment](https://arxiv.org/abs/2507.15680)
*Yongkang Hou,Jiarun Song*

Main category: cs.CV

TL;DR: 一种新的知识蒸馏方法，利用CLIP的IQA能力来训练更高效、性能更优的模型，适用于实际部署。


<details>
  <summary>Details</summary>
Motivation: 为了解决CLIP在IQA任务中存在的参数负担过重以及识别局部失真特征能力不足的问题。

Method: 本研究提出了一种视觉-语言模型知识蒸馏的方法，旨在利用CLIP的图像质量评估（IQA）知识来指导具有架构优势的模型的训练。首先，设计了质量分级提示模板来引导CLIP输出质量分数。然后，对CLIP进行微调以增强其在IQA任务中的能力。最后，提出了一种模态自适应知识蒸馏策略，以实现从CLIP教师模型到学生模型的指导。

Result: 实验在多个IQA数据集上进行，结果表明所提出的方法显著降低了模型复杂性，并且性能优于现有的IQA方法。

Conclusion: 所提出的方法显著降低了模型复杂性，并且在性能上优于现有的图像质量评估方法，展示了其在实际部署方面的强大潜力。

Abstract: Image Quality Assessment (IQA) is a core task in computer vision. Multimodal
methods based on vision-language models, such as CLIP, have demonstrated
exceptional generalization capabilities in IQA tasks. To address the issues of
excessive parameter burden and insufficient ability to identify local distorted
features in CLIP for IQA, this study proposes a visual-language model knowledge
distillation method aimed at guiding the training of models with architectural
advantages using CLIP's IQA knowledge. First, quality-graded prompt templates
were designed to guide CLIP to output quality scores. Then, CLIP is fine-tuned
to enhance its capabilities in IQA tasks. Finally, a modality-adaptive
knowledge distillation strategy is proposed to achieve guidance from the CLIP
teacher model to the student model. Our experiments were conducted on multiple
IQA datasets, and the results show that the proposed method significantly
reduces model complexity while outperforming existing IQA methods,
demonstrating strong potential for practical deployment.

</details>


### [126] [Hi^2-GSLoc: Dual-Hierarchical Gaussian-Specific Visual Relocalization for Remote Sensing](https://arxiv.org/abs/2507.15683)
*Boni Hu,Zhenyu Xia,Lin Chen,Pengcheng Han,Shuhui Bu*

Main category: cs.CV

TL;DR: Hi2-GSLoc是一种利用3D高斯泼溅（3DGS）进行视觉重定位的框架，通过稀疏到密集、粗糙到精细的双层级方法，解决了现有技术在遥感场景下的精度和效率问题。


<details>
  <summary>Details</summary>
Motivation: 现有的视觉重定位方法在精度、计算复杂性和可扩展性方面存在权衡，尤其是在遥感场景中，由于大尺度场景、高海拔变化和视觉先验的域间隙，这些挑战尤为突出。为了克服这些限制，研究者利用3D高斯泼溅（3DGS）作为一种新的场景表示。

Method: Hi2-GSLoc框架采用双层级稀疏到密集、粗糙到精细的范式，并利用3D高斯泼溅（3DGS）作为新颖的场景表示。它包含一个稀疏阶段（高斯特定的、一致的、渲染感知的采样策略和基于地标的检测器）和一个密集阶段（通过粗糙到精细的密集光栅化匹配和可靠性验证来迭代地优化位姿）。为了处理大规模遥感场景，采用了分区高斯训练、GPU加速的并行匹配和动态内存管理策略。

Result: Hi2-GSLoc在定位精度、召回率和计算效率方面均表现出色，并能有效过滤不可靠的位姿估计。

Conclusion: Hi2-GSLoc在模拟数据、公开数据集和真实飞行实验中表现出具有竞争力的定位精度、召回率和计算效率，并能有效过滤不可靠的位姿估计，证明了其在实际遥感应用中的有效性。

Abstract: Visual relocalization, which estimates the 6-degree-of-freedom (6-DoF) camera
pose from query images, is fundamental to remote sensing and UAV applications.
Existing methods face inherent trade-offs: image-based retrieval and pose
regression approaches lack precision, while structure-based methods that
register queries to Structure-from-Motion (SfM) models suffer from
computational complexity and limited scalability. These challenges are
particularly pronounced in remote sensing scenarios due to large-scale scenes,
high altitude variations, and domain gaps of existing visual priors. To
overcome these limitations, we leverage 3D Gaussian Splatting (3DGS) as a novel
scene representation that compactly encodes both 3D geometry and appearance. We
introduce $\mathrm{Hi}^2$-GSLoc, a dual-hierarchical relocalization framework
that follows a sparse-to-dense and coarse-to-fine paradigm, fully exploiting
the rich semantic information and geometric constraints inherent in Gaussian
primitives. To handle large-scale remote sensing scenarios, we incorporate
partitioned Gaussian training, GPU-accelerated parallel matching, and dynamic
memory management strategies. Our approach consists of two stages: (1) a sparse
stage featuring a Gaussian-specific consistent render-aware sampling strategy
and landmark-guided detector for robust and accurate initial pose estimation,
and (2) a dense stage that iteratively refines poses through coarse-to-fine
dense rasterization matching while incorporating reliability verification.
Through comprehensive evaluation on simulation data, public datasets, and real
flight experiments, we demonstrate that our method delivers competitive
localization accuracy, recall rate, and computational efficiency while
effectively filtering unreliable pose estimates. The results confirm the
effectiveness of our approach for practical remote sensing applications.

</details>


### [127] [LINR-PCGC: Lossless Implicit Neural Representations for Point Cloud Geometry Compression](https://arxiv.org/abs/2507.15686)
*Wenjie Huang,Qi Yang,Shuting Xia,He Huang,Zhu Li,Yiling Xu*

Main category: cs.CV

TL;DR: 提出了一种名为LINR-PCGC的无损点云几何压缩方法，它基于隐式神经表示，通过分层编码和轻量级网络设计，在保证无损压缩的同时，显著提高了编码速度并减小了模型大小，且压缩率优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有的AI点云压缩方法在真实世界部署受数据分布限制，而基于INR的方法可以实现更具分布无关性的结果，但现有INR方法仅限于有损压缩。因此，需要一种基于INR的无损点云几何压缩方法。

Method: 提出了一种基于隐式神经表示（INR）的无损点云几何压缩方法（LINR-PCGC）。该方法设计了一个点云分层编码框架和一种有效的网络初始化策略来加速编码，并使用基于多尺度稀疏卷积（SparseConv）的轻量级编码网络（包含尺度上下文提取、子节点预测和模型压缩模块）来实现快速推理和紧凑的解码器尺寸。

Result: 在MVUB数据集上，LINR-PCGC相比G-PCC TMC13v23的比特流减少了约21.21%，相比SparsePCGC减少了约21.95%。

Conclusion: 所提出的LINR-PCGC方法是第一个基于隐式神经表示的无损点云几何压缩方法，在编码速度和解码器大小方面进行了优化，并且在压缩率上优于传统和现有的AI方法。

Abstract: Existing AI-based point cloud compression methods struggle with dependence on
specific training data distributions, which limits their real-world deployment.
Implicit Neural Representation (INR) methods solve the above problem by
encoding overfitted network parameters to the bitstream, resulting in more
distribution-agnostic results. However, due to the limitation of encoding time
and decoder size, current INR based methods only consider lossy geometry
compression. In this paper, we propose the first INR based lossless point cloud
geometry compression method called Lossless Implicit Neural Representations for
Point Cloud Geometry Compression (LINR-PCGC). To accelerate encoding speed, we
design a group of point clouds level coding framework with an effective network
initialization strategy, which can reduce around 60% encoding time. A
lightweight coding network based on multiscale SparseConv, consisting of scale
context extraction, child node prediction, and model compression modules, is
proposed to realize fast inference and compact decoder size. Experimental
results show that our method consistently outperforms traditional and AI-based
methods: for example, with the convergence time in the MVUB dataset, our method
reduces the bitstream by approximately 21.21% compared to G-PCC TMC13v23 and
21.95% compared to SparsePCGC. Our project can be seen on
https://huangwenjie2023.github.io/LINR-PCGC/.

</details>


### [128] [Efficient Face Image Quality Assessment via Self-training and Knowledge Distillation](https://arxiv.org/abs/2507.15709)
*Wei Sun,Weixia Zhang,Linhan Cao,Jun Jia,Xiangyang Zhu,Dandan Zhu,Xiongkuo Min,Guangtao Zhai*

Main category: cs.CV

TL;DR: 开发了一种高效的FIQA方法，通过自训练和知识蒸馏，用一个轻量级学生模型实现了与教师模型相当的性能，计算开销极低，并在竞赛中夺冠。


<details>
  <summary>Details</summary>
Motivation: 解决现有FIQA算法计算复杂度高，影响其在现实世界应用中的可扩展性和部署的问题，旨在开发一种计算效率高且易于部署的FIQA方法。

Method: 提出了一种两阶段的FIQA方法：首先训练一个强大的教师模型（通过自训练策略，利用标记数据进行初始训练，然后用生成的伪标签改进教师模型），然后从教师模型蒸馏出一个轻量级的学生模型。学生模型同时利用标记数据、原始教师模型生成的伪标签以及改进后的教师模型生成的伪标签进行训练。

Result: 所提出的学生模型在性能上与教师模型相当，但计算开销极低。该方法在ICCV 2025 VQualA FIQA挑战赛中获得第一名。

Conclusion: 该研究提出了一种计算效率高的人脸图像质量评估（FIQA）方法，该方法在保持与教师模型相当的性能的同时，显著降低了计算开销。通过结合自训练策略和知识蒸馏，成功训练了一个轻量级的学生模型，并在ICCV 2025 VQualA FIQA挑战赛中取得了优异成绩。

Abstract: Face image quality assessment (FIQA) is essential for various face-related
applications. Although FIQA has been extensively studied and achieved
significant progress, the computational complexity of FIQA algorithms remains a
key concern for ensuring scalability and practical deployment in real-world
systems. In this paper, we aim to develop a computationally efficient FIQA
method that can be easily deployed in real-world applications. Specifically,
our method consists of two stages: training a powerful teacher model and
distilling a lightweight student model from it. To build a strong teacher
model, we adopt a self-training strategy to improve its capacity. We first
train the teacher model using labeled face images, then use it to generate
pseudo-labels for a set of unlabeled images. These pseudo-labeled samples are
used in two ways: (1) to distill knowledge into the student model, and (2) to
combine with the original labeled images to further enhance the teacher model
through self-training. The enhanced teacher model is used to further
pseudo-label another set of unlabeled images for distilling the student models.
The student model is trained using a combination of labeled images,
pseudo-labeled images from the original teacher model, and pseudo-labeled
images from the enhanced teacher model. Experimental results demonstrate that
our student model achieves comparable performance to the teacher model with an
extremely low computational overhead. Moreover, our method achieved first place
in the ICCV 2025 VQualA FIQA Challenge. The code is available at
https://github.com/sunwei925/Efficient-FIQA.git.

</details>


### [129] [A Practical Investigation of Spatially-Controlled Image Generation with Transformers](https://arxiv.org/abs/2507.15724)
*Guoxuan Xia,Harleen Hanspal,Petru-Daniel Tudosiu,Shifeng Zhang,Sarah Parisot*

Main category: cs.CV

TL;DR: 本研究旨在解决空间控制图像生成领域中存在的文献混乱和知识差距问题。通过在 ImageNet 上对不同类型的 Transformer 模型（基于扩散/流和自回归）进行受控实验，研究了控制标记预填充、采样时间增强（如控制的分类器自由引导和 Softmax 截断）以及基于适配器的方法。研究结果表明，控制标记预填充是一种有效的基线方法；采样时间增强能显著提高控制-生成一致性；而基于适配器的方法在特定场景下（如数据有限时）有优势，但在一致性方面不如完全训练。本研究为从业者提供了清晰的指导，以开发更优的 Transformer 模型用于空间控制图像生成。


<details>
  <summary>Details</summary>
Motivation: 为了解决当前在空间控制图像生成领域中，由于训练数据、模型架构和生成范式不同，导致难以进行详细和公平的科学比较的问题。同时，也为了梳理和明确某些研究方法的动机和细节，填补知识空白。

Method: 通过在 ImageNet 上跨基于扩散/流和自回归 (AR) 的模型进行受控实验来阐明文献和解决知识差距。首先，将控制标记预填充建立为 Transformer 的简单、通用且高性能的基线方法。然后，研究采样时间增强，例如将分类器自由引导扩展到控制和 Softmax 截断，以提高控制-生成一致性。最后，通过在有限的下游数据上进行训练来演示基于适配器的方法可以缓解“遗忘”并保持生成质量，但可能在生成-控制一致性方面表现不如完全训练。

Result: 控制标记预填充是一种简单、通用且高性能的 Transformer 基线方法。将分类器自由引导扩展到控制以及 Softmax 截断可以显著提高控制-生成一致性。基于适配器的方法在有限的下游数据上训练时，可以缓解“遗忘”并保持生成质量，但在生成-控制一致性方面不如完全训练。

Conclusion: 空间控制的图像生成模型的研究很重要，可以更好地根据用户需求生成图像。尽管近年来取得了显著的改进，但快速生产更强大的模型却以牺牲详细和公平的科学比较为代价。训练数据、模型架构和生成范式的不同使得人们难以区分影响性能的因素。同时，某些方法的动机和细微差别在文献中也丢失了。本研究旨在为希望开发基于 Transformer 的空间控制生成系统的从业者提供跨生成范式的清晰的学习要点，从而阐明文献并解决知识差距。我们在 ImageNet 上跨基于扩散/流和自回归 (AR) 的模型进行了受控实验。首先，我们将控制标记预填充建立为 Transformer 的简单、通用且高性能的基线方法。然后，我们研究了以前未充分探索的采样时间增强，表明将分类器自由引导扩展到控制以及 Softmax 截断对控制-生成一致性有很强的影响。最后，我们重新阐明了基于适配器的方法的动机，证明它们可以在有限的下游数据上进行训练时缓解“遗忘”并保持生成质量，但在生成-控制一致性方面表现不如完全训练。代码将在发布时发布。

Abstract: Enabling image generation models to be spatially controlled is an important
area of research, empowering users to better generate images according to their
own fine-grained specifications via e.g. edge maps, poses. Although this task
has seen impressive improvements in recent times, a focus on rapidly producing
stronger models has come at the cost of detailed and fair scientific
comparison. Differing training data, model architectures and generation
paradigms make it difficult to disentangle the factors contributing to
performance. Meanwhile, the motivations and nuances of certain approaches
become lost in the literature. In this work, we aim to provide clear takeaways
across generation paradigms for practitioners wishing to develop
transformer-based systems for spatially-controlled generation, clarifying the
literature and addressing knowledge gaps. We perform controlled experiments on
ImageNet across diffusion-based/flow-based and autoregressive (AR) models.
First, we establish control token prefilling as a simple, general and
performant baseline approach for transformers. We then investigate previously
underexplored sampling time enhancements, showing that extending
classifier-free guidance to control, as well as softmax truncation, have a
strong impact on control-generation consistency. Finally, we re-clarify the
motivation of adapter-based approaches, demonstrating that they mitigate
"forgetting" and maintain generation quality when trained on limited downstream
data, but underperform full training in terms of generation-control
consistency. Code will be released upon publication.

</details>


### [130] [TokensGen: Harnessing Condensed Tokens for Long Video Generation](https://arxiv.org/abs/2507.15728)
*Wenqi Ouyang,Zeqi Xiao,Danni Yang,Yifan Zhou,Shuai Yang,Lei Yang,Jianlou Si,Xingang Pan*

Main category: cs.CV

TL;DR: TokensGen是一个两阶段框架，利用视频token来解决长视频生成中的不一致性问题，通过To2V和T2To模型以及FIFO-Diffusion策略实现剪辑内控制、长期一致性和平滑过渡。


<details>
  <summary>Details</summary>
Motivation: 生成一致的长视频是一个复杂的挑战：虽然基于扩散的生成模型能生成视觉上令人印象深刻的短片段，但将其扩展到更长的持续时间常常会导致内存瓶颈和长期不一致性。

Method: 本文提出了一种名为TokensGen的新型两阶段框架，该框架利用浓缩的token来解决长视频生成中的内存瓶颈和长期不一致性问题。该方法将长视频生成分解为三个核心任务：(1) 剪辑内语义控制，(2) 长期一致性控制，以及 (3) 剪辑间平滑过渡。首先，训练了一个名为To2V（Token-to-Video）的短视频扩散模型，该模型由文本和视频token指导，并配备了一个视频分词器，将短片段压缩成丰富的token。其次，引入了一个名为T2To（Text-to-Token）的视频token扩散Transformer，能够一次性生成所有token，确保跨剪辑的全局一致性。最后，在推理过程中，采用自适应的FIFO-Diffusion策略无缝连接相邻的剪辑，减少边界伪影并增强平滑过渡。

Result: 实验结果表明，该方法显著增强了长时序和内容连贯性，同时没有带来高昂的计算开销。

Conclusion: 该方法通过利用浓缩的token和预训练的短视频模型，提供了一个可扩展、模块化的长视频生成解决方案，显著增强了长时序和内容连贯性，同时没有带来高昂的计算开销。

Abstract: Generating consistent long videos is a complex challenge: while
diffusion-based generative models generate visually impressive short clips,
extending them to longer durations often leads to memory bottlenecks and
long-term inconsistency. In this paper, we propose TokensGen, a novel two-stage
framework that leverages condensed tokens to address these issues. Our method
decomposes long video generation into three core tasks: (1) inner-clip semantic
control, (2) long-term consistency control, and (3) inter-clip smooth
transition. First, we train To2V (Token-to-Video), a short video diffusion
model guided by text and video tokens, with a Video Tokenizer that condenses
short clips into semantically rich tokens. Second, we introduce T2To
(Text-to-Token), a video token diffusion transformer that generates all tokens
at once, ensuring global consistency across clips. Finally, during inference,
an adaptive FIFO-Diffusion strategy seamlessly connects adjacent clips,
reducing boundary artifacts and enhancing smooth transitions. Experimental
results demonstrate that our approach significantly enhances long-term temporal
and content coherence without incurring prohibitive computational overhead. By
leveraging condensed tokens and pre-trained short video models, our method
provides a scalable, modular solution for long video generation, opening new
possibilities for storytelling, cinematic production, and immersive
simulations. Please see our project page at
https://vicky0522.github.io/tokensgen-webpage/ .

</details>


### [131] [Appearance Harmonization via Bilateral Grid Prediction with Transformers for 3DGS](https://arxiv.org/abs/2507.15748)
*Jisu Shin,Richard Shaw,Seunghyun Shin,Anton Pelykh,Zhensong Zhang,Hae-Gon Jeon,Eduardo Perez-Pellitero*

Main category: cs.CV

TL;DR: 該研究提出一種 Transformer 方法，透過預測雙邊網格來校正多視點圖像間的測光差異，以提升新視點合成的品質，並在不需重新訓練的情況下實現跨場景泛化。


<details>
  <summary>Details</summary>
Motivation: 現代相機管線應用廣泛的裝置內處理（例如曝光調整、白平衡和色彩校正），雖然單獨有利，但經常會導致多視點之間出現測光不一致，違反了多視點一致性並降低了新視點合成的品質。現有方法（例如聯合優化場景表示和每張圖像的外觀嵌入）雖然可以解決此問題，但計算複雜度高且訓練速度慢。

Method: 提出一種基於 Transformer 的方法，該方法預測空間自適應雙邊網格，以多視點一致的方式校正測光差異。

Result: 實驗結果顯示，該方法在重建保真度和收斂速度方面優於或媲美現有的特定場景優化方法。

Conclusion: 該方法透過預測空間自適應雙邊網格來以多視點一致的方式校正測光差異，實現無需場景特定重新訓練的穩健跨場景泛化。將學習到的網格整合到 3D 高斯潑濺管線中，在維持高訓練效率的同時提高了重建品質。

Abstract: Modern camera pipelines apply extensive on-device processing, such as
exposure adjustment, white balance, and color correction, which, while
beneficial individually, often introduce photometric inconsistencies across
views. These appearance variations violate multi-view consistency and degrade
the quality of novel view synthesis. Joint optimization of scene
representations and per-image appearance embeddings has been proposed to
address this issue, but at the cost of increased computational complexity and
slower training. In this work, we propose a transformer-based method that
predicts spatially adaptive bilateral grids to correct photometric variations
in a multi-view consistent manner, enabling robust cross-scene generalization
without the need for scene-specific retraining. By incorporating the learned
grids into the 3D Gaussian Splatting pipeline, we improve reconstruction
quality while maintaining high training efficiency. Extensive experiments show
that our approach outperforms or matches existing scene-specific optimization
methods in reconstruction fidelity and convergence speed.

</details>


### [132] [Learning from Heterogeneity: Generalizing Dynamic Facial Expression Recognition via Distributionally Robust Optimization](https://arxiv.org/abs/2507.15765)
*Feng-Qi Cui,Anyang Tong,Jinyang Huang,Jie Zhang,Dan Guo,Zhi Liu,Meng Wang*

Main category: cs.CV

TL;DR: 为了解决样本异质性导致的性能下降问题，我们提出了HDF框架，包含DAM和DSM模块，通过增强时频建模和自适应优化，提高了DFER的准确性和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有的动态面部表情识别（DFER）方法在面对多源数据和个体表情变异性引起的样本异质性时，性能会下降。

Method: 提出了一种名为异质性感知分布框架（HDF）的新框架，并设计了两个即插即用模块：时间-频率分布注意力模块（DAM）和分布感知缩放模块（DSM）。DAM通过双分支注意力设计捕捉时序一致性和频率鲁棒性，以提高对序列不一致和视觉风格变化的容忍度。DSM基于梯度敏感性和信息瓶颈原理，动态平衡分类和对比损失，以实现更稳定和具有辨别力的表示学习。

Result: HDF框架在DFEW和FERV39k数据集上的实验证明，其在识别准确性和鲁棒性方面均有显著提升，并且在多样化和不平衡的场景下表现出强大的泛化能力。

Conclusion: HDF框架在DFEW和FERV39k数据集上显著提高了识别准确性和鲁棒性，并在多样化和不平衡场景下实现了优越的加权平均召回率（WAR）和未加权平均召回率（UAR）。

Abstract: Dynamic Facial Expression Recognition (DFER) plays a critical role in
affective computing and human-computer interaction. Although existing methods
achieve comparable performance, they inevitably suffer from performance
degradation under sample heterogeneity caused by multi-source data and
individual expression variability. To address these challenges, we propose a
novel framework, called Heterogeneity-aware Distributional Framework (HDF), and
design two plug-and-play modules to enhance time-frequency modeling and
mitigate optimization imbalance caused by hard samples. Specifically, the
Time-Frequency Distributional Attention Module (DAM) captures both temporal
consistency and frequency robustness through a dual-branch attention design,
improving tolerance to sequence inconsistency and visual style shifts. Then,
based on gradient sensitivity and information bottleneck principles, an
adaptive optimization module Distribution-aware Scaling Module (DSM) is
introduced to dynamically balance classification and contrastive losses,
enabling more stable and discriminative representation learning. Extensive
experiments on two widely used datasets, DFEW and FERV39k, demonstrate that HDF
significantly improves both recognition accuracy and robustness. Our method
achieves superior weighted average recall (WAR) and unweighted average recall
(UAR) while maintaining strong generalization across diverse and imbalanced
scenarios. Codes are released at https://github.com/QIcita/HDF_DFER.

</details>


### [133] [Label tree semantic losses for rich multi-class medical image segmentation](https://arxiv.org/abs/2507.15777)
*Junwen Wang,Oscar MacCormac,William Rochford,Aaron Kujawa,Jonathan Shapey,Tom Vercauteren*

Main category: cs.CV

TL;DR: New tree-based semantic loss functions improve medical image segmentation by considering label hierarchy and sparse annotations, achieving state-of-the-art results.


<details>
  <summary>Details</summary>
Motivation: Commonly used learning methods for medical image segmentation penalize all errors equally, failing to exploit inter-class semantics, especially with a large number of subtly different classes.

Method: Proposed two tree-based semantic loss functions and incorporated them into a training approach with sparse, background-free annotations.

Result: Extensive experiments on head MRI for whole brain parcellation and neurosurgical hyperspectral imaging for scene understanding show the proposed method reaches state-of-the-art performance.

Conclusion: The proposed method achieves state-of-the-art performance on both head MRI and neurosurgical hyperspectral imaging tasks.

Abstract: Rich and accurate medical image segmentation is poised to underpin the next
generation of AI-defined clinical practice by delineating critical anatomy for
pre-operative planning, guiding real-time intra-operative navigation, and
supporting precise post-operative assessment. However, commonly used learning
methods for medical and surgical imaging segmentation tasks penalise all errors
equivalently and thus fail to exploit any inter-class semantics in the labels
space. This becomes particularly problematic as the cardinality and richness of
labels increases to include subtly different classes. In this work, we propose
two tree-based semantic loss functions which take advantage of a hierarchical
organisation of the labels. We further incorporate our losses in a recently
proposed approach for training with sparse, background-free annotations to
extend the applicability of our proposed losses. Extensive experiments are
reported on two medical and surgical image segmentation tasks, namely head MRI
for whole brain parcellation (WBP) with full supervision and neurosurgical
hyperspectral imaging (HSI) for scene understanding with sparse annotations.
Results demonstrate that our proposed method reaches state-of-the-art
performance in both cases.

</details>


### [134] [Regularized Low-Rank Adaptation for Few-Shot Organ Segmentation](https://arxiv.org/abs/2507.15793)
*Ghassen Baklouti,Julio Silva-Rodríguez,Jose Dolz,Houda Bahig,Ismail Ben Ayed*

Main category: cs.CV

TL;DR: 通过L1稀疏性正则化器动态调整LoRA的秩，在医学图像分割任务中提高了性能和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 尽管LoRA在PEFT中表现良好，但其固定的秩可能难以适应不同医学成像任务的复杂性和需求。因此，研究的动机是开发一种能够动态调整秩的方法，以提高在医学图像分割等任务上的适应性。

Method: 本研究引入了一种新颖的医学图像分割方法，通过在损失函数中加入L1稀疏性正则化器，并使用近端优化器来解决，从而在适应过程中动态调整秩。这使得模型能够自动寻找适应任务的秩。

Result: 在少样本微调设置下，与标准LoRA和其他PEFT方法相比，该方法在两个不同的任务（基础器官和新器官分割）上均取得了显著的性能提升，证明了其效率和鲁棒性。

Conclusion: 该方法通过L1稀疏性正则化器自动调整适应性秩，在少样本微调设置下，相比标准LoRA和其他PEFT方法，在基础器官和新器官分割任务上均展现出显著的性能提升，证明了其效率和对次优秩初始化的鲁棒性。

Abstract: Parameter-efficient fine-tuning (PEFT) of pre-trained foundation models is
increasingly attracting interest in medical imaging due to its effectiveness
and computational efficiency. Among these methods, Low-Rank Adaptation (LoRA)
is a notable approach based on the assumption that the adaptation inherently
occurs in a low-dimensional subspace. While it has shown good performance, its
implementation requires a fixed and unalterable rank, which might be
challenging to select given the unique complexities and requirements of each
medical imaging downstream task. Inspired by advancements in natural image
processing, we introduce a novel approach for medical image segmentation that
dynamically adjusts the intrinsic rank during adaptation. Viewing the low-rank
representation of the trainable weight matrices as a singular value
decomposition, we introduce an l_1 sparsity regularizer to the loss function,
and tackle it with a proximal optimizer. The regularizer could be viewed as a
penalty on the decomposition rank. Hence, its minimization enables to find
task-adapted ranks automatically. Our method is evaluated in a realistic
few-shot fine-tuning setting, where we compare it first to the standard LoRA
and then to several other PEFT methods across two distinguishable tasks: base
organs and novel organs. Our extensive experiments demonstrate the significant
performance improvements driven by our method, highlighting its efficiency and
robustness against suboptimal rank initialization. Our code is publicly
available: https://github.com/ghassenbaklouti/ARENA

</details>


### [135] [Exploring Superposition and Interference in State-of-the-Art Low-Parameter Vision Models](https://arxiv.org/abs/2507.15798)
*Lilian Hollard,Lucas Mohimont,Nathalie Gaveau,Luiz-Angelo Steffenel*

Main category: cs.CV

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: The paper investigates the performance of state-of-the-art low-parameter deep
neural networks for computer vision, focusing on bottleneck architectures and
their behavior using superlinear activation functions. We address interference
in feature maps, a phenomenon associated with superposition, where neurons
simultaneously encode multiple characteristics. Our research suggests that
limiting interference can enhance scaling and accuracy in very low-scaled
networks (under 1.5M parameters). We identify key design elements that reduce
interference by examining various bottleneck architectures, leading to a more
efficient neural network. Consequently, we propose a proof-of-concept
architecture named NoDepth Bottleneck built on mechanistic insights from our
experiments, demonstrating robust scaling accuracy on the ImageNet dataset.
These findings contribute to more efficient and scalable neural networks for
the low-parameter range and advance the understanding of bottlenecks in
computer vision. https://caiac.pubpub.org/pub/3dh6rsel

</details>


### [136] [ConformalSAM: Unlocking the Potential of Foundational Segmentation Models in Semi-Supervised Semantic Segmentation with Conformal Prediction](https://arxiv.org/abs/2507.15803)
*Danhui Chen,Ziquan Liu,Chuxi Yang,Dan Wang,Yan Yan,Yi Xu,Xiangyang Ji*

Main category: cs.CV

TL;DR: 本研究提出ConformalSAM框架，利用校准过的基础分割模型SEEM生成的高质量伪标签，用于半监督语义分割。通过共形预测过滤低置信度标签，并结合自主训练策略，ConformalSAM在多个基准测试中表现优于现有方法，并可作为插件提升其他方法的性能。


<details>
  <summary>Details</summary>
Motivation: 为了缓解像素级视觉任务（如语义分割）中获取大量高质量标注数据的成本问题，利用半监督语义分割（SSSS）和预训练的基础分割模型是有效的解决方案。本研究旨在探索基础分割模型作为标注器在无标签数据上生成预测掩码的潜力，并提出一种能够可靠利用其能力的方法。

Method: 提出ConformalSAM框架，该框架首先使用目标域的标记数据校准基础分割模型（SEEM），然后过滤掉不可靠的像素标签，只使用高置信度标签进行监督。该方法利用共形预测（CP）适应基础模型，并在早期学习阶段利用其强大的分割能力，随后采用自主训练策略减轻后期对SEEM生成标签的过拟合。

Result: ConformalSAM在三个标准的半监督语义分割基准测试中，相比于近期的相关方法，取得了更优越的性能。此外，该框架作为一个插件，能够提升其他方法的性能。

Conclusion: ConformalSAM框架通过校准基础模型并过滤不可靠的像素标签，有效利用了SEEM生成的高置信度标签进行半监督语义分割，并在三个标准基准测试中取得了优于近期方法的性能，同时还能作为插件提升现有方法的表现。

Abstract: Pixel-level vision tasks, such as semantic segmentation, require extensive
and high-quality annotated data, which is costly to obtain. Semi-supervised
semantic segmentation (SSSS) has emerged as a solution to alleviate the
labeling burden by leveraging both labeled and unlabeled data through
self-training techniques. Meanwhile, the advent of foundational segmentation
models pre-trained on massive data, has shown the potential to generalize
across domains effectively. This work explores whether a foundational
segmentation model can address label scarcity in the pixel-level vision task as
an annotator for unlabeled images. Specifically, we investigate the efficacy of
using SEEM, a Segment Anything Model (SAM) variant fine-tuned for textual
input, to generate predictive masks for unlabeled data. To address the
shortcomings of using SEEM-generated masks as supervision, we propose
ConformalSAM, a novel SSSS framework which first calibrates the foundation
model using the target domain's labeled data and then filters out unreliable
pixel labels of unlabeled data so that only high-confidence labels are used as
supervision. By leveraging conformal prediction (CP) to adapt foundation models
to target data through uncertainty calibration, ConformalSAM exploits the
strong capability of the foundational segmentation model reliably which
benefits the early-stage learning, while a subsequent self-reliance training
strategy mitigates overfitting to SEEM-generated masks in the later training
stage. Our experiment demonstrates that, on three standard benchmarks of SSSS,
ConformalSAM achieves superior performance compared to recent SSSS methods and
helps boost the performance of those methods as a plug-in.

</details>


### [137] [True Multimodal In-Context Learning Needs Attention to the Visual Context](https://arxiv.org/abs/2507.15807)
*Shuo Chen,Jianzhe Liu,Zhen Han,Yan Xia,Daniel Cremers,Philip Torr,Volker Tresp,Jindong Gu*

Main category: cs.CV

TL;DR: MLLMs在多模态上下文学习中存在忽视视觉信息的问题。本研究提出了DARA微调策略和TrueMICL数据集来解决此问题，并取得了显著的改进。


<details>
  <summary>Details</summary>
Motivation: 现有的多模态大语言模型（MLLMs）在多模态上下文学习（MICL）中存在忽视视觉信息、过度依赖文本模式的问题，导致MICL实际上仍是单模态的，限制了其实际应用。这种局限性在不要求理解视觉内容的任务上会被性能提升所掩盖，因此如何有效增强MICL能力和可靠评估MICL性能仍是未被充分探索的领域。

Method: 本研究提出了一种名为动态注意力重新分配（DARA）的微调策略，旨在通过重新平衡视觉和文本标记的注意力来鼓励模型关注视觉上下文。此外，研究人员还构建了一个名为TrueMICL的专用数据集，包含支持集和测试集，明确要求模型整合多模态信息（尤其是视觉内容）以完成任务。

Result: 通过应用DARA策略和使用TrueMICL数据集，实验结果表明该整体解决方案能显著提高MLLMs真正的多模态上下文学习能力。

Conclusion: 本研究提出了动态注意力重新分配（DARA）策略和TrueMICL数据集，以解决多模态大语言模型（MLLMs）在多模态上下文学习（MICL）中忽视视觉信息的问题。实验证明，该方法能有效提升模型整合视觉内容的能力，并为MICL性能评估提供了更可靠的基准。

Abstract: Multimodal Large Language Models (MLLMs), built on powerful language
backbones, have enabled Multimodal In-Context Learning (MICL)-adapting to new
tasks from a few multimodal demonstrations consisting of images, questions, and
answers. Despite showing noticeable improvement on standard vision-language
datasets, current MLLMs struggle to leverage visual information in the
demonstrations. Specifically, they tend to neglect visual cues and over-rely on
textual patterns, leading to mere text imitation rather than genuine multimodal
adaptation. This behavior makes MICL still unimodal and largely restricts its
practical utility. More importantly, this limitation is often concealed by the
improved performance on tasks that do not require understanding the visual
context. As a result, how to effectively enhance MICL ability and reliably
evaluate the MICL performance remains underexplored. To address these issues,
we first introduce Dynamic Attention Reallocation (DARA), an efficient
fine-tuning strategy that encourages models to attend to the visual context by
rebalancing attention across visual and textual tokens. In addition, we present
TrueMICL, an MICL-dedicated dataset with both support and test sets that
explicitly requires the integration of multimodal information-particularly
visual content-for correct task completion. Extensive experiments demonstrate
the effectiveness of our holistic solution, showcasing substantial improvements
in the true multimodal in-context learning capabilities. Code and datasets are
available at https://chenxshuo.github.io/true-micl-colm .

</details>


### [138] [Diffusion models for multivariate subsurface generation and efficient probabilistic inversion](https://arxiv.org/abs/2507.15809)
*Roberto Miele,Niklas Linde*

Main category: cs.CV

TL;DR: 扩散模型在多元地下建模和概率反演方面优于 VAE 和 GAN。改进的扩散后验采样方法通过似然近似和条件建模（使用井数据和地震数据）提高了性能、鲁棒性和效率。


<details>
  <summary>Details</summary>
Motivation: 考虑在多元地下建模和概率反演的背景下使用扩散模型，并提出改进的扩散后验采样方法。

Method: 提出对 Chung 等人提出的扩散后验采样方法进行不同的修正，并引入了考虑扩散模型固有噪声污染的似然近似。

Result: 与原始方法相比，在多元地质场景（包括相和相关的声阻抗）中，测试显示统计鲁棒性显著提高，后验概率密度函数的采样得到增强，计算成本降低。

Conclusion: 该方法可以单独或同时使用硬数据和间接条件数据。由于反演包含在扩散过程中，因此比需要围绕生成模型设置外部循环（例如马尔可夫链蒙特卡洛）的其他方法更快。

Abstract: Diffusion models offer stable training and state-of-the-art performance for
deep generative modeling tasks. Here, we consider their use in the context of
multivariate subsurface modeling and probabilistic inversion. We first
demonstrate that diffusion models enhance multivariate modeling capabilities
compared to variational autoencoders and generative adversarial networks. In
diffusion modeling, the generative process involves a comparatively large
number of time steps with update rules that can be modified to account for
conditioning data. We propose different corrections to the popular Diffusion
Posterior Sampling approach by Chung et al. (2023). In particular, we introduce
a likelihood approximation accounting for the noise-contamination that is
inherent in diffusion modeling. We assess performance in a multivariate
geological scenario involving facies and correlated acoustic impedance.
Conditional modeling is demonstrated using both local hard data (well logs) and
nonlinear geophysics (fullstack seismic data). Our tests show significantly
improved statistical robustness, enhanced sampling of the posterior probability
density function and reduced computational costs, compared to the original
approach. The method can be used with both hard and indirect conditioning data,
individually or simultaneously. As the inversion is included within the
diffusion process, it is faster than other methods requiring an outer-loop
around the generative model, such as Markov chain Monte Carlo.

</details>


### [139] [Can Your Model Separate Yolks with a Water Bottle? Benchmarking Physical Commonsense Understanding in Video Generation Models](https://arxiv.org/abs/2507.15824)
*Enes Sanli,Baris Sarper Tezcan,Aykut Erdem,Erkut Erdem*

Main category: cs.CV

TL;DR: PhysVidBench is a new benchmark to evaluate the physical common sense of text-to-video generation models. It uses a benchmark of 383 prompts and a three-stage evaluation process involving question generation, video captioning, and language model-based question answering to assess physical reasoning, addressing limitations in current evaluations that overlook tool use and material properties.


<details>
  <summary>Details</summary>
Motivation: Current text-to-video (T2V) generation models often lack basic physical commonsense, leading to videos that violate intuitive expectations regarding causality, object behavior, and tool use. This benchmark was developed to address this gap by specifically evaluating the physical reasoning capabilities of T2V systems.

Method: PhysVidBench was created by curating 383 prompts emphasizing tool use, material properties, and procedural interactions. Videos are generated using state-of-the-art models for each prompt. A three-stage evaluation pipeline is used: 1) formulating grounded physics questions from the prompt, 2) captioning the generated video using a vision-language model, and 3) having a language model answer physics-involved questions based solely on the caption. This indirect evaluation strategy aims to circumvent hallucination issues common in direct video-based assessments.

Result: The benchmark includes 383 carefully curated prompts. The evaluation pipeline, involving question formulation, video captioning, and language model-based question answering, provides a method to assess physical commonsense without direct video evaluation, mitigating hallucination issues.

Conclusion: PhysVidBench enables a structured and interpretable framework for assessing physical commonsense in generative video models by highlighting affordances and tool-mediated actions, which are often overlooked in current T2V evaluations.

Abstract: Recent progress in text-to-video (T2V) generation has enabled the synthesis
of visually compelling and temporally coherent videos from natural language.
However, these models often fall short in basic physical commonsense, producing
outputs that violate intuitive expectations around causality, object behavior,
and tool use. Addressing this gap, we present PhysVidBench, a benchmark
designed to evaluate the physical reasoning capabilities of T2V systems. The
benchmark includes 383 carefully curated prompts, emphasizing tool use,
material properties, and procedural interactions, and domains where physical
plausibility is crucial. For each prompt, we generate videos using diverse
state-of-the-art models and adopt a three-stage evaluation pipeline: (1)
formulate grounded physics questions from the prompt, (2) caption the generated
video with a vision-language model, and (3) task a language model to answer
several physics-involved questions using only the caption. This indirect
strategy circumvents common hallucination issues in direct video-based
evaluation. By highlighting affordances and tool-mediated actions, areas
overlooked in current T2V evaluations, PhysVidBench provides a structured,
interpretable framework for assessing physical commonsense in generative video
models.

</details>


### [140] [SeC: Advancing Complex Video Object Segmentation via Progressive Concept Construction](https://arxiv.org/abs/2507.15852)
*Zhixiong Zhang,Shuangrui Ding,Xiaoyi Dong,Songxin He,Jianfan Lin,Junsong Tang,Yuhang Zang,Yuhang Cao,Dahua Lin,Jiaqi Wang*

Main category: cs.CV

TL;DR: 本研究提出了一种名为SeC的概念驱动视频对象分割框架，该框架利用大型视觉语言模型来理解和分割视频中的对象，即使在存在视觉变化、遮挡和场景变化的情况下也能表现出色。研究还引入了一个新的基准SeCVOS来评估这种能力，SeC在该基准上取得了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 现有视频对象分割（VOS）技术在处理剧烈的视觉变化、遮挡和复杂的场景变化方面仍落后于人类能力，因为它们依赖外观匹配而忽略了人类的概念理解能力。因此，有必要提出一种新的方法来解决这一差距。

Method: SeC框架利用大型视觉语言模型（LVLMs）整合跨视频帧的视觉线索，构建鲁棒的概念先验。在推理过程中，它通过处理后的帧形成全面的目标语义表征，并自适应地平衡基于LVLM的语义推理和增强的特征匹配，以应对不同场景的复杂性。

Result: SeC在SeCVOS基准上取得了11.8分的提升，超过了SAM 2.1，确立了概念感知视频对象分割的新技术水平。

Conclusion: SeC通过从传统的特征匹配转向渐进式构建和利用高层、以对象为中心的表征，实现了概念驱动的分割，并在SeCVOS基准上取得了11.8分的提升，确立了在概念感知视频对象分割方面的新技术水平。

Abstract: Video Object Segmentation (VOS) is a core task in computer vision, requiring
models to track and segment target objects across video frames. Despite notable
advances with recent efforts, current techniques still lag behind human
capabilities in handling drastic visual variations, occlusions, and complex
scene changes. This limitation arises from their reliance on appearance
matching, neglecting the human-like conceptual understanding of objects that
enables robust identification across temporal dynamics. Motivated by this gap,
we propose Segment Concept (SeC), a concept-driven segmentation framework that
shifts from conventional feature matching to the progressive construction and
utilization of high-level, object-centric representations. SeC employs Large
Vision-Language Models (LVLMs) to integrate visual cues across diverse frames,
constructing robust conceptual priors. During inference, SeC forms a
comprehensive semantic representation of the target based on processed frames,
realizing robust segmentation of follow-up frames. Furthermore, SeC adaptively
balances LVLM-based semantic reasoning with enhanced feature matching,
dynamically adjusting computational efforts based on scene complexity. To
rigorously assess VOS methods in scenarios demanding high-level conceptual
reasoning and robust semantic understanding, we introduce the Semantic Complex
Scenarios Video Object Segmentation benchmark (SeCVOS). SeCVOS comprises 160
manually annotated multi-scenario videos designed to challenge models with
substantial appearance variations and dynamic scene transformations. In
particular, SeC achieves an 11.8-point improvement over SAM 2.1 on SeCVOS,
establishing a new state-of-the-art in concept-aware video object segmentation.

</details>


### [141] [Latent Denoising Makes Good Visual Tokenizers](https://arxiv.org/abs/2507.15856)
*Jiawei Yang,Tianhong Li,Lijie Fan,Yonglong Tian,Yue Wang*

Main category: cs.CV

TL;DR: 本研究提出了一种名为l-DeTok的新型视觉分词器，通过将分词器嵌入与去噪目标对齐，提高了其在生成模型中的性能。实验证明，l-DeTok在ImageNet数据集上优于标准分词器，并强调了去噪作为分词器设计关键原则的重要性。


<details>
  <summary>Details</summary>
Motivation: 为了解决在生成模型中，能够使视觉分词器更有效的属性尚不清楚的问题。研究者观察到，现代生成模型有一个共同的训练目标——从损坏的输入中重建清晰信号，并将此过程称为去噪。基于此洞察，研究者提出将分词器嵌入直接与下游去噪目标对齐，以鼓励潜在嵌入即使在严重损坏的情况下也易于重建。

Method: 提出了一种名为潜在去噪分词器（l-DeTok）的简单而有效的模型，该模型经过训练，能够从受损的潜在嵌入中重建清晰的图像，其中潜在嵌入是通过插值噪声和随机掩码损坏的。

Result: 在ImageNet 256x256上的广泛实验表明，所提出的l-DeTok分词器在六种代表性生成模型上，始终优于标准分词器。

Conclusion: 该研究强调了去噪作为分词器开发的一个基本设计原则，并希望这能激发未来分词器设计的新思路。

Abstract: Despite their fundamental role, it remains unclear what properties could make
visual tokenizers more effective for generative modeling. We observe that
modern generative models share a conceptually similar training objective --
reconstructing clean signals from corrupted inputs such as Gaussian noise or
masking -- a process we term denoising. Motivated by this insight, we propose
aligning tokenizer embeddings directly with the downstream denoising objective,
encouraging latent embeddings to be more easily reconstructed even when heavily
corrupted. To achieve this, we introduce the Latent Denoising Tokenizer
(l-DeTok), a simple yet effective tokenizer trained to reconstruct clean images
from latent embeddings corrupted by interpolative noise and random masking.
Extensive experiments on ImageNet 256x256 demonstrate that our tokenizer
consistently outperforms standard tokenizers across six representative
generative models. Our findings highlight denoising as a fundamental design
principle for tokenizer development, and we hope it could motivate new
perspectives for future tokenizer design.

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [142] [DeepWriter: A Fact-Grounded Multimodal Writing Assistant Based On Offline Knowledge Base](https://arxiv.org/abs/2507.14189)
*Song Mao,Lejun Cheng,Pinlong Cai,Guohang Yan,Ding Wang,Botian Shi*

Main category: cs.CL

TL;DR: DeepWriter是一个针对金融、医学、法律等专业领域定制的多模态、长篇写作助手。它使用精心策划的离线知识库，通过任务分解、大纲生成、多模态检索和逐节撰写与反思的流程，克服了现有LLM在专业知识和幻觉方面的局限性。实验证明，DeepWriter在金融报告生成方面效果显著，优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有的LLM在金融、医学和法律等专业领域的应用受到领域知识缺乏和幻觉问题的限制。现有的解决方案，如检索增强生成（RAG）可能存在多步检索不一致的问题，而基于在线搜索的方法则容易受到不可靠网络内容的影响。

Method: DeepWriter采用了一个新颖的流程，包括任务分解、大纲生成、多模态检索以及逐节撰写和反思。它利用了一个结构化的语料库进行深度信息挖掘，并整合了文本和视觉元素。此外，还提出了一种分层知识表示方法来提高检索效率和准确性。

Result: 在金融报告生成方面的实验表明，DeepWriter能够生成高质量、可验证的文章，在事实准确性和生成内容质量方面均优于现有基线。

Conclusion: DeepWriter通过利用定制的、离线的知识库，并采用新颖的包含任务分解、大纲生成、多模态检索以及逐节撰写和反思的流程，能够生成连贯、基于事实且专业级的文档。实验证明，DeepWriter在金融报告生成方面表现出色，其生成文章的质量、事实准确性和整体内容质量均优于现有基线。

Abstract: Large Language Models (LLMs) have demonstrated remarkable capabilities in
various applications. However, their use as writing assistants in specialized
domains like finance, medicine, and law is often hampered by a lack of deep
domain-specific knowledge and a tendency to hallucinate. Existing solutions,
such as Retrieval-Augmented Generation (RAG), can suffer from inconsistency
across multiple retrieval steps, while online search-based methods often
degrade quality due to unreliable web content. To address these challenges, we
introduce DeepWriter, a customizable, multimodal, long-form writing assistant
that operates on a curated, offline knowledge base. DeepWriter leverages a
novel pipeline that involves task decomposition, outline generation, multimodal
retrieval, and section-by-section composition with reflection. By deeply mining
information from a structured corpus and incorporating both textual and visual
elements, DeepWriter generates coherent, factually grounded, and
professional-grade documents. We also propose a hierarchical knowledge
representation to enhance retrieval efficiency and accuracy. Our experiments on
financial report generation demonstrate that DeepWriter produces high-quality,
verifiable articles that surpasses existing baselines in factual accuracy and
generated content quality.

</details>


### [143] [Retention analysis of edited knowledge after fine-tuning](https://arxiv.org/abs/2507.14198)
*Fufang Wen,Shichang Zhang*

Main category: cs.CL

TL;DR: LLM 的已编辑知识在微调中容易遗忘，冻结层可改善此状况。


<details>
  <summary>Details</summary>
Motivation: 研究 LLM 微调对模型编辑后知识的影响，以解决已编辑知识在下游任务中容易被遗忘的问题。

Method: 系统性地研究了不同微调目标与模型编辑技术的交互作用，并通过冻结相关层来增强知识保留。

Result: 已编辑知识比预训练知识更容易在微调中遗忘；冻结层可以提高知识保留率。

Conclusion: LLM 知识编辑后的内容在下游微调过程中比预训练的内在知识更容易被遗忘。冻结与编辑内容相关的层可以显著提高知识保留率，为未来改进编辑方法提供了方向。

Abstract: Large language models (LLMs) store vast amounts of knowledge, which often
requires updates to correct factual errors, incorporate newly acquired
information, or adapt model behavior. Model editing methods have emerged as
efficient solutions for such updates, offering localized and precise knowledge
modification at significantly lower computational cost than continual training.
In parallel, LLMs are frequently fine-tuned for a wide range of downstream
tasks. However, the effect of fine-tuning on previously edited knowledge
remains poorly understood. In this work, we systematically investigate how
different fine-tuning objectives interact with various model editing
techniques. Our findings show that edited knowledge is substantially more
susceptible to forgetting during fine-tuning than intrinsic knowledge acquired
through pre-training. This analysis highlights a key limitation of current
editing approaches and suggests that evaluating edit robustness under
downstream fine-tuning is critical for their practical deployment. We further
find that freezing layers associated with edited content can significantly
improve knowledge retention, offering insight into how future editing methods
might be made more robust.

</details>


### [144] [Open-Source LLMs Collaboration Beats Closed-Source LLMs: A Scalable Multi-Agent System](https://arxiv.org/abs/2507.14200)
*Shengji Tang,Jianjian Cao,Weihao Lin,Jiale Hong,Bo Zhang,Shuyue Hu,Lei Bai,Tao Chen,Wanli Ouyang,Peng Ye*

Main category: cs.CL

TL;DR: SMACS是一个结合了检索式先验选择（RPS）和探索-利用驱动的后验增强（EPE）的多智能体协作系统（MACS）框架，该框架通过整合多个开源LLM，在各种基准测试中取得了比领先的闭源模型更好的性能。


<details>
  <summary>Details</summary>
Motivation: 旨在展示开源集体的潜力和优势，并探讨是否可以利用多个开源LLM来匹配甚至超越闭源LLM。

Method: 提出了一种名为SMACS的可扩展多智能体协作系统（MACS）框架。具体来说，为了持续集成新的LLM和泛化到不同的问题，首先提出了检索式先验选择（RPS），为每个LLM分配代理性能分数，以便在实例级别为任何给定问题选择前k个LLM。然后，提出了探索-利用驱动的后验增强（EPE），通过先验丢弃鼓励生成多样化响应，并通过混合后验分数选择高质量响应。

Result: SMACS通过整合十五个开源LLM，在八个主流基准测试中表现出色，超越了Claude-3.7-Sonnet (+12.73%)、GPT-4.1(+5.36%)和GPT-o3-mini(+5.28%)等领先的闭源LLM，并且超过了开源LLM（+2.86%）和闭源LLM（+2.04%）不同数据集的最佳结果的平均值。

Conclusion: SMACS通过整合十五个开源LLM，在多个任务上超越了领先的闭源LLM（如Claude-3.7-Sonnet、GPT-4.1和GPT-o3-mini），并超过了开源和闭源LLM的最佳结果的平均值，推动了智能的上限。

Abstract: This paper aims to demonstrate the potential and strengths of open-source
collectives. It leads to a promising question: Can we harness multiple
open-source LLMs to match or even beat the closed-source LLMs? To answer this,
we propose SMACS, a scalable multi-agent collaboration system (MACS) framework
with high performance. Specifically, for continuous integration of new LLMs and
generalization to diverse questions, we first propose a Retrieval-based Prior
Selection (RPS), which assigns a proxy performance score to each LLM to select
the Top-k LLMs at the instance level for any given question. Then, we propose
an Exploration-Exploitation-Driven Posterior Enhancement (EPE), encouraging the
generation of diverse responses through prior dropping and selecting the
high-quality response via a hybrid posterior score. Experiments on eight
mainstream benchmarks validate the effectiveness of our SMACS: by integrating
fifteen open-source LLMs, SMACS outperforms leading closed-source LLMs in 2025,
e.g., Claude-3.7-Sonnet (+12.73%), GPT-4.1(+5.36%) and GPT-o3-mini(+5.28%)
across multiple tasks. Remarkably, it even exceeds the average of best results
of different datasets from both open-source LLMs (+2.86%) and closed-source
LLMs (+2.04%), pushing the upper bound of intelligence. Code will be released
at https://github.com/magent4aci/SMACS.

</details>


### [145] [Let's Measure the Elephant in the Room: Facilitating Personalized Automated Analysis of Privacy Policies at Scale](https://arxiv.org/abs/2507.14214)
*Rui Zhao,Vladyslav Melnychuk,Jun Zhao,Jesse Wright,Nigel Shadbolt*

Main category: cs.CL

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: In modern times, people have numerous online accounts, but they rarely read
the Terms of Service or Privacy Policy of those sites despite claiming
otherwise. This paper introduces PoliAnalyzer, a neuro-symbolic system that
assists users with personalized privacy policy analysis. PoliAnalyzer uses
Natural Language Processing (NLP) to extract formal representations of data
usage practices from policy texts. In favor of deterministic, logical inference
is applied to compare user preferences with the formal privacy policy
representation and produce a compliance report. To achieve this, we extend an
existing formal Data Terms of Use policy language to model privacy policies as
app policies and user preferences as data policies. In our evaluation using our
enriched PolicyIE dataset curated by legal experts, PoliAnalyzer demonstrated
high accuracy in identifying relevant data usage practices, achieving F1-score
of 90-100% across most tasks. Additionally, we demonstrate how PoliAnalyzer can
model diverse user data-sharing preferences, derived from prior research as 23
user profiles, and perform compliance analysis against the top 100 most-visited
websites. This analysis revealed that, on average, 95.2% of a privacy policy's
segments do not conflict with the analyzed user preferences, enabling users to
concentrate on understanding the 4.8% (636 / 13205) that violates preferences,
significantly reducing cognitive burden. Further, we identified common
practices in privacy policies that violate user expectations - such as the
sharing of location data with 3rd parties. This paper demonstrates that
PoliAnalyzer can support automated personalized privacy policy analysis at
scale using off-the-shelf NLP tools. This sheds light on a pathway to help
individuals regain control over their data and encourage societal discussions
on platform data practices to promote a fairer power dynamic.

</details>


### [146] [Beyond Architectures: Evaluating the Role of Contextual Embeddings in Detecting Bipolar Disorder on Social Media](https://arxiv.org/abs/2507.14231)
*Khalid Hasan,Jamil Saquer*

Main category: cs.CL

TL;DR: 本研究利用Transformer和LSTM模型分析Reddit帖子，以识别双相情感障碍的迹象。RoBERTa和BERT嵌入的LSTM模型表现最佳（F1约98%），而静态嵌入的LSTM模型效果不佳。DistilBERT在效率和准确性方面表现均衡。研究强调了上下文语言模型在早期筛查中的重要性。


<details>
  <summary>Details</summary>
Motivation: 双相情感障碍是一种常见的慢性神经系统疾病，由于早期症状不明显和社会的污名化，常常被漏诊。本研究旨在利用先进的自然语言处理（NLP）模型识别用户生成的社交媒体文本中双相情感障碍的迹象。

Method: 本研究探索了使用先进的自然语言处理（NLP）模型识别用户生成的社交媒体文本中双相情感障碍迹象。我们基于上下文（BERT）和静态（GloVe, Word2Vec）词嵌入，对基于Transformer的模型（BERT, RoBERTa, ALBERT, ELECTRA, DistilBERT）和长短期记忆（LSTM）模型进行了全面评估。实验数据来自标注过的Reddit帖子，并通过情感方差和判断分析确认了其有效性。

Result: 研究结果表明，RoBERTa在Transformer模型中表现最佳，F1分数约为98%，而使用BERT嵌入的LSTM模型取得了相似的结果。相比之下，基于静态嵌入训练的LSTM模型未能捕捉到有意义的模式，F1分数接近于零。此外，DistilBERT在效率和准确性之间提供了最佳平衡。

Conclusion: 本研究证明了使用上下文语言模型检测双相情感障碍的潜力，为心理健康领域的自然语言处理应用提供了可行的见解，并验证了上下文语言模型在支持早期双相情感障碍筛查方面的作用。

Abstract: Bipolar disorder is a chronic mental illness frequently underdiagnosed due to
subtle early symptoms and social stigma. This paper explores the advanced
natural language processing (NLP) models for recognizing signs of bipolar
disorder based on user-generated social media text. We conduct a comprehensive
evaluation of transformer-based models (BERT, RoBERTa, ALBERT, ELECTRA,
DistilBERT) and Long Short Term Memory (LSTM) models based on contextualized
(BERT) and static (GloVe, Word2Vec) word embeddings. Experiments were performed
on a large, annotated dataset of Reddit posts after confirming their validity
through sentiment variance and judgmental analysis. Our results demonstrate
that RoBERTa achieves the highest performance among transformer models with an
F1 score of ~98% while LSTM models using BERT embeddings yield nearly identical
results. In contrast, LSTMs trained on static embeddings fail to capture
meaningful patterns, scoring near-zero F1. These findings underscore the
critical role of contextual language modeling in detecting bipolar disorder. In
addition, we report model training times and highlight that DistilBERT offers
an optimal balance between efficiency and accuracy. In general, our study
offers actionable insights for model selection in mental health NLP
applications and validates the potential of contextualized language models to
support early bipolar disorder screening.

</details>


### [147] [Language Models Change Facts Based on the Way You Talk](https://arxiv.org/abs/2507.14238)
*Matthew Kearney,Reuben Binns,Yarin Gal*

Main category: cs.CL

TL;DR: LLM在面向用户的应用程序中，会因为文本中包含的种族、性别和年龄等身份标记而产生偏见，导致在医疗、法律、政治和就业等领域出现不公平的响应。研究者开发了新的工具来评估这种影响，并建议在部署前进行彻底评估。


<details>
  <summary>Details</summary>
Motivation: LLM越来越多地被用于面向用户的应用程序，但其在真实世界应用中的决策过程却鲜为人知，特别是当文本中存在细微的身份信息时。本研究旨在全面分析身份标记如何影响LLM在不同高风险领域的响应，以揭示潜在的偏见。

Method: 本研究对LLM在医疗、法律、政治、政府福利和就业薪资这五个不同高风险应用领域中，如何因用户书写内容中的身份标记而产生偏见进行了全面的分析，并提供了评估用户语言选择中身份编码如何影响模型决策的新工具。

Result: 研究发现，LLM对用户查询中的身份标记极其敏感，种族、性别和年龄对LLM在医疗、法律、政治、政府福利和就业薪资等领域的响应存在持续影响。例如，LLM在医疗建议中对不同种族适用不同的护理标准；在回答事实问题时，会根据用户年龄调整答案以符合政治倾向；并对非白人求职者建议较低薪资，对女性建议较高薪资。

Conclusion: LLMs在用户生成的内容中加入身份标记时，会对包括医疗、法律、政治、政府福利和就业薪资在内的五个不同高风险领域中的LLM响应产生偏见。LLM对用户查询中的身份标记极其敏感，种族、性别和年龄会持续影响LLM的响应。具体来说，在提供医疗建议时，LLM会根据不同的种族提供不同的护理标准；在回答事实问题时，LLM会根据用户的年龄（老年人或年轻人）调整答案以符合保守党或自由党的世界观；LLM会给非白人求职者建议较低的薪资，而给女性的建议高于男性。这些偏见可能导致不同的医疗护理、加剧薪酬差距以及基于不同身份的人们面临不同的政治事实。因此，在未来部署LLM用户界面应用之前，应进行类似彻底的评估。

Abstract: Large language models (LLMs) are increasingly being used in user-facing
applications, from providing medical consultations to job interview advice.
Recent research suggests that these models are becoming increasingly proficient
at inferring identity information about the author of a piece of text from
linguistic patterns as subtle as the choice of a few words. However, little is
known about how LLMs use this information in their decision-making in
real-world applications. We perform the first comprehensive analysis of how
identity markers present in a user's writing bias LLM responses across five
different high-stakes LLM applications in the domains of medicine, law,
politics, government benefits, and job salaries. We find that LLMs are
extremely sensitive to markers of identity in user queries and that race,
gender, and age consistently influence LLM responses in these applications. For
instance, when providing medical advice, we find that models apply different
standards of care to individuals of different ethnicities for the same
symptoms; we find that LLMs are more likely to alter answers to align with a
conservative (liberal) political worldview when asked factual questions by
older (younger) individuals; and that LLMs recommend lower salaries for
non-White job applicants and higher salaries for women compared to men. Taken
together, these biases mean that the use of off-the-shelf LLMs for these
applications may cause harmful differences in medical care, foster wage gaps,
and create different political factual realities for people of different
identities. Beyond providing an analysis, we also provide new tools for
evaluating how subtle encoding of identity in users' language choices impacts
model decisions. Given the serious implications of these findings, we recommend
that similar thorough assessments of LLM use in user-facing applications are
conducted before future deployment.

</details>


### [148] [CCL-XCoT: An Efficient Cross-Lingual Knowledge Transfer Method for Mitigating Hallucination Generation](https://arxiv.org/abs/2507.14239)
*Weihua Zheng,Roy Ka-Wei Lee,Zhengyuan Liu,Kui Wu,AiTi Aw,Bowei Zou*

Main category: cs.CL

TL;DR: CCL-XCoT通过对比学习和跨语言思维链提示，减少了多语言模型在低资源语言中的幻觉。


<details>
  <summary>Details</summary>
Motivation: 多语言大语言模型（MLLMs）在低资源语言中存在幻觉问题，这是由于训练数据不平衡造成的，这在领域特定生成任务中尤其成问题。

Method: 提出了一种名为CCL-XCoT的两阶段微调框架，第一阶段利用基于课程的对比学习和下一个词预测来增强跨语言语义对齐，第二阶段在指令微调中引入跨语言思维链（XCoT）提示，引导模型先用高资源语言推理，再用低资源语言生成答案。

Result: 实验结果表明，CCL-XCoT将幻觉率降低了高达62%，并显著提高了跨语言对的事实知识迁移能力。

Conclusion: CCL-XCoT框架通过两阶段微调（包括基于课程的对比学习和跨语言思维链提示）有效降低了多语言大语言模型在低资源语言中的幻觉，同时提高了事实知识的跨语言迁移能力，且无需外部检索或多模型集成。

Abstract: Multilingual Large Language Models(MLLMs) demonstrate strong generalization
across languages, yet they remain prone to hallucinations, especially in
low-resource languages, due to training data imbalances. These hallucinations,
which include inaccurate or fabricated outputs, are particularly problematic in
domain-specific generation tasks (Chataigner et al., 2024). To address this
challenge, we propose CCL-XCoT(Curriculum-based Contrastive Learning-based
Cross-lingual Chain-of-Thought), a two-stage fine-tuning framework for
mitigating hallucination in MLLMs. Our approach first enhances cross-lingual
semantic alignment through curriculum-based contrastive learning combined with
next-token prediction during continued pre-training. Building on this
foundation, we then introduce a cross-lingual Chain-of-Thought (XCoT) prompting
strategy during instruction fine-tuning, which guides the model to reason in a
high-resource language before generating answers in the target low-resource
language. Experimental results show that CCL-XCoT reduces hallucination rates
by up to 62% and substantially improves factual knowledge transfer across
language pairs, without relying on external retrieval or multi-model ensembles.

</details>


### [149] [HuggingGraph: Understanding the Supply Chain of LLM Ecosystem](https://arxiv.org/abs/2507.14240)
*Mohammad Shahedur Rahman,Peng Gao,Yuede Ji*

Main category: cs.CL

TL;DR: LLM供应链图谱分析显示，模型和数据集之间存在复杂且动态的关联，数据集是训练的关键，生态系统庞大且在不断发展。


<details>
  <summary>Details</summary>
Motivation: 为了应对LLM开发、训练和部署中因模型和数据集的复杂性而产生的计算资源和数据壁垒，并解决继承自早期模型或数据集的潜在漏洞、偏见或恶意组件带来的风险，需要理解LLM供应链中模型和数据集之间的关系。

Method: 通过设计系统性收集LLM供应链数据的方法，并利用这些数据构建了一个包含397,376个节点和453,469条边的有向异构图，然后进行多种分析。

Result: 研究发现LLM供应链图谱规模庞大、稀疏且遵循幂律度分布；图中存在一个密集连接的核心和碎片化的外围；数据集在训练中起着关键作用；模型和数据集之间存在强烈的相互依赖性；该图谱是动态的，每日更新反映了生态系统的持续演变。

Conclusion: LLM供应链图谱揭示了模型和数据集之间复杂的相互依赖关系，其动态演化特性要求持续监控以识别风险。建议通过分析这些关系来改进模型安全性、公平性和合规性。

Abstract: Large language models (LLMs) leverage deep learning to process and predict
sequences of words from context, enabling them to perform various NLP tasks,
such as translation, summarization, question answering, and content generation.
However, the growing size and complexity of developing, training, and deploying
advanced LLMs require extensive computational resources and large datasets.
This creates a barrier for users. As a result, platforms that host models and
datasets are widely used. For example, Hugging Face, one of the most popular
platforms, hosted 1.8 million models and 450K datasets by June 2025, with no
sign of slowing down. Since many LLMs are built from base models, pre-trained
models, and external datasets, they can inherit vulnerabilities, biases, or
malicious components from earlier models or datasets. Therefore, it is critical
to understand the origin and development of these components to better detect
potential risks, improve model fairness, and ensure compliance. Motivated by
this, our project aims to study the relationships between models and datasets,
which are core components of the LLM supply chain. First, we design a method to
systematically collect LLM supply chain data. Using this data, we build a
directed heterogeneous graph to model the relationships between models and
datasets, resulting in a structure with 397,376 nodes and 453,469 edges. We
then perform various analyses and uncover several findings, such as: (i) the
LLM supply chain graph is large, sparse, and follows a power-law degree
distribution; (ii) it features a densely connected core and a fragmented
periphery; (iii) datasets play pivotal roles in training; (iv) strong
interdependence exists between models and datasets; and (v) the graph is
dynamic, with daily updates reflecting the ecosystem's ongoing evolution.

</details>


### [150] [Promptomatix: An Automatic Prompt Optimization Framework for Large Language Models](https://arxiv.org/abs/2507.14241)
*Rithesh Murthy,Ming Zhu,Liangwei Yang,Jielin Qiu,Juntao Tan,Shelby Heinecke,Huan Wang,Caiming Xiong,Silvio Savarese*

Main category: cs.CL

TL;DR: Promptomatix 是一个自动提示优化框架，可以将自然语言任务描述转换为高质量的提示，无需手动调整或专业知识，并且比现有方法更高效。


<details>
  <summary>Details</summary>
Motivation: 提示工程虽然对大型语言模型的性能至关重要，但目前仍是手动、不一致且非专业人士难以使用的。Promptomatix 旨在解决这一痛点，提供一个自动化的解决方案。

Method: Promptomatix 是一个自动提示优化框架，通过分析用户意图、生成合成训练数据、选择提示策略以及使用成本感知目标来优化提示。它支持基于轻量级元提示的优化器和基于 DSPy 的编译器，并采用模块化设计。

Result: Promptomatix 在 5 个任务类别中的评估结果显示，其性能与现有库相比具有竞争力或更优越，同时提示长度和计算开销也得到减少。

Conclusion: Promptomatix 框架能够将自然语言任务描述转化为高质量的提示，无需手动调整或领域专业知识，并在 5 个任务类别中实现了具有竞争力或更优越的性能，同时还减少了提示长度和计算开销，使得提示优化具有可扩展性和高效性。

Abstract: Large Language Models (LLMs) perform best with well-crafted prompts, yet
prompt engineering remains manual, inconsistent, and inaccessible to
non-experts. We introduce Promptomatix, an automatic prompt optimization
framework that transforms natural language task descriptions into high-quality
prompts without requiring manual tuning or domain expertise. Promptomatix
supports both a lightweight meta-prompt-based optimizer and a DSPy-powered
compiler, with modular design enabling future extension to more advanced
frameworks. The system analyzes user intent, generates synthetic training data,
selects prompting strategies, and refines prompts using cost-aware objectives.
Evaluated across 5 task categories, Promptomatix achieves competitive or
superior performance compared to existing libraries, while reducing prompt
length and computational overhead making prompt optimization scalable and
efficient.

</details>


### [151] [Conflicting narratives and polarization on social media](https://arxiv.org/abs/2507.15600)
*Armin Pournaki*

Main category: cs.CL

TL;DR: 本研究分析了德国推特平台上关于乌克兰战争、新冠疫情和气候变化等议题的冲突叙事，揭示了话语两极分化和议题一致性的机制。


<details>
  <summary>Details</summary>
Motivation: 在政治现实中，叙事是人类理解的关键解释工具。本研究旨在探究冲突叙事如何揭示两极分化和议题一致性的机制。

Method: 通过提取推特文本中冲突叙事的信号，分析了乌克兰战争、新冠疫情和气候变化等焦点议题和事件中的话语两极分化，重点关注了行动者角色的归属冲突和事件的叙事冲突两个维度。

Result: 研究发现，在涉及乌克兰战争、新冠疫情和气候变化等议题时，存在两种冲突叙事：一是行动者角色的归属冲突，二是事件的叙事冲突。此外，还发现了政治行动者用于跨议题统一意见的叙事一致性模式。

Conclusion: 本研究展示了分析冲突叙事如何揭示公众领域中两极分化和议题一致性的话语机制，并为政治行动者跨议题统一意见的叙事策略提供了初步证据。

Abstract: Narratives are key interpretative devices by which humans make sense of
political reality. In this work, we show how the analysis of conflicting
narratives, i.e. conflicting interpretive lenses through which political
reality is experienced and told, provides insight into the discursive
mechanisms of polarization and issue alignment in the public sphere. Building
upon previous work that has identified ideologically polarized issues in the
German Twittersphere between 2021 and 2023, we analyze the discursive dimension
of polarization by extracting textual signals of conflicting narratives from
tweets of opposing opinion groups. Focusing on a selection of salient issues
and events (the war in Ukraine, Covid, climate change), we show evidence for
conflicting narratives along two dimensions: (i) different attributions of
actantial roles to the same set of actants (e.g. diverging interpretations of
the role of NATO in the war in Ukraine), and (ii) emplotment of different
actants for the same event (e.g. Bill Gates in the right-leaning Covid
narrative). Furthermore, we provide first evidence for patterns of narrative
alignment, a discursive strategy that political actors employ to align opinions
across issues. These findings demonstrate the use of narratives as an
analytical lens into the discursive mechanisms of polarization.

</details>


### [152] [In-Depth and In-Breadth: Pre-training Multimodal Language Models Customized for Comprehensive Chart Understanding](https://arxiv.org/abs/2507.14298)
*Wan-Cyuan Fan,Yen-Chun Chen,Mengchen Liu,Alexander Jacobson,Lu Yuan,Leonid Sigal*

Main category: cs.CL

TL;DR: ChartScope是一个针对各种图表类型的LVLM，通过高效的数据生成和双路径训练策略解决了现有方法的局限性，并在新基准ChartDQA上取得了更好的效果。


<details>
  <summary>Details</summary>
Motivation: 现有的定制大型视觉语言模型（LVLM）以领域特定任务的方法在科学图表理解方面显示出有前景的结果，但是，现有方法面临两个主要限制：首先，它们仅依赖于少数几种图表的配对数据，这限制了它们对多种图表类型的泛化能力。其次，它们缺乏针对图表-数据对齐的定向预训练，这阻碍了模型对底层数据的理解。

Method: 提出了一种高效的数据生成流程，可以合成各种图表类型的数据，并采用新颖的双路径训练策略，使模型能够简洁地捕捉关键数据细节，同时通过整合对底层数据的推理来保持强大的推理能力。

Result: 实验结果表明，ChartScope 在广泛的图表类型上显著提高了理解能力。

Conclusion: ChartScope 在广泛的图表类型上显著提高了理解能力。

Abstract: Recent methods for customizing Large Vision Language Models (LVLMs) for
domain-specific tasks have shown promising results in scientific chart
comprehension. However, existing approaches face two major limitations: First,
they rely on paired data from only a few chart types, limiting generalization
to wide range of chart types. Secondly, they lack targeted pre-training for
chart-data alignment, which hampers the model's understanding of underlying
data. In this paper, we introduce ChartScope, an LVLM optimized for in-depth
chart comprehension across diverse chart types. We propose an efficient data
generation pipeline that synthesizes paired data for a wide range of chart
types, along with a novel Dual-Path training strategy that enabling the model
to succinctly capture essential data details while preserving robust reasoning
capabilities by incorporating reasoning over the underlying data. Lastly, we
establish ChartDQA, a new benchmark for evaluating not only question-answering
at different levels but also underlying data understanding. Experimental
results demonstrate that ChartScope significantly enhances comprehension on a
wide range of chart types. The code and data are available at
https://davidhalladay.github.io/chartscope_demo.

</details>


### [153] [Operationalizing AI for Good: Spotlight on Deployment and Integration of AI Models in Humanitarian Work](https://arxiv.org/abs/2507.15823)
*Anton Abilov,Ke Zhang,Hemank Lamba,Elizabeth M. Olson,Joel R. Tetreault,Alejandro Jaimes*

Main category: cs.CL

TL;DR: 本文分享了在人道主义组织中部署和维护AI模型的经验。


<details>
  <summary>Details</summary>
Motivation: AI for Good领域的论文往往侧重于研究和模型开发，很少讨论部署、合作和实际影响，因此本文旨在填补这一空白。

Method: 分享了与人道主义组织合作的细节，包括AI模型的部署、维护和持续性能更新。

Result: 提供了在资源受限环境下部署和维护AI模型的实践经验和关键启示。

Conclusion: AI模型在资源受限环境下的人道主义部署和维护

Abstract: Publications in the AI for Good space have tended to focus on the research
and model development that can support high-impact applications. However, very
few AI for Good papers discuss the process of deploying and collaborating with
the partner organization, and the resulting real-world impact. In this work, we
share details about the close collaboration with a humanitarian-to-humanitarian
(H2H) organization and how to not only deploy the AI model in a
resource-constrained environment, but also how to maintain it for continuous
performance updates, and share key takeaways for practitioners.

</details>


### [154] [Aligning Large Language Models to Low-Resource Languages through LLM-Based Selective Translation: A Systematic Study](https://arxiv.org/abs/2507.14304)
*Rakesh Paul,Anusha Kamath,Kanishk Singla,Raviraj Joshi,Utkarsh Vaidya,Sanjay Singh Chauhan,Niranjan Wartikar*

Main category: cs.CL

TL;DR: LLM选择性翻译技术能有效提升模型在低资源语言上的表现，尤其是在处理代码和数学公式等非翻译内容时，相比传统翻译方法更具优势。


<details>
  <summary>Details</summary>
Motivation: 多语言大语言模型（LLMs）在非英语语言（尤其在低资源场景下）的表现存在性能差距。直接获取高质量的低资源语言对齐数据成本高昂且耗时，而直接翻译英文对齐数据又可能丢失代码、数学公式和JSON等关键信息。因此，需要一种更有效的解决方案来解决低资源语言的对齐问题。

Method: 本研究采用基于LLM的选择性翻译技术，对文本中的可翻译部分进行翻译，同时保留非翻译内容（如代码、数学公式、JSON）和句子结构。通过对比Google Cloud Translation (GCP)和Llama-3.1-405B两种翻译器在Hindi语上的表现，并进行了系统性研究，探讨了该方法与标准翻译方法的有效性对比、过滤噪声输出的重要性以及在对齐过程中混合翻译样本与原始英文数据的益处。

Result: 实验结果表明，选择性翻译是一种实用且有效的方法，能够提升多语言LLMs在低资源语言上的对齐表现。该方法在Hindi语上优于传统翻译方法，且过滤噪声和混合数据能进一步增强模型性能。

Conclusion: 生成式AI在低资源语言上的表现仍有提升空间，尤其是在代码、数学公式和JSON等结构化数据方面。本研究提出了一种基于LLM的选择性翻译方法，通过选择性翻译可翻译部分并保留原文结构和非翻译内容，以解决低资源语言对齐数据的缺乏问题。实验证明，该方法在Hindi语上相比传统翻译方法能有效提升模型表现，并验证了过滤噪声和混合数据的重要性。

Abstract: Multilingual large language models (LLMs) often demonstrate a performance gap
between English and non-English languages, particularly in low-resource
settings. Aligning these models to low-resource languages is essential yet
challenging due to limited high-quality data. While English alignment datasets
are readily available, curating equivalent data in other languages is expensive
and time-consuming. A common workaround is to translate existing English
alignment data; however, standard translation techniques often fail to preserve
critical elements such as code, mathematical expressions, and structured
formats like JSON. In this work, we investigate LLM-based selective
translation, a technique that selectively translates only the translatable
parts of a text while preserving non-translatable content and sentence
structure. We conduct a systematic study to explore key questions around this
approach, including its effectiveness compared to vanilla translation, the
importance of filtering noisy outputs, and the benefits of mixing translated
samples with original English data during alignment. Our experiments focus on
the low-resource Indic language Hindi and compare translations generated by
Google Cloud Translation (GCP) and Llama-3.1-405B. The results highlight the
promise of selective translation as a practical and effective method for
improving multilingual alignment in LLMs.

</details>


### [155] [How LLMs Comprehend Temporal Meaning in Narratives: A Case Study in Cognitive Evaluation of LLMs](https://arxiv.org/abs/2507.14307)
*Karin de Langis,Jong Inn Park,Andreas Schramm,Bin Hu,Khanh Chi Le,Michael Mensink,Ahn Thu Tong,Dongyeop Kang*

Main category: cs.CL

TL;DR: LLMs在理解叙事的时间语言学方面与人类不同，它们过度依赖原型性，判断不一致，并且在因果推理方面存在困难，这表明它们缺乏健全的叙事理解能力。


<details>
  <summary>Details</summary>
Motivation: 研究LLMs如何处理叙事中的时间语言学方面，并与之前在人类研究中的行为进行对比，以探究这些行为是反映了类似人类的认知还是高级的模式识别。

Method: 使用专家在循环（Expert-in-the-Loop）探测流程，进行一系列针对性的实验，以评估LLMs是否以类似人类的方式构建语义表征和语用推断。

Result: LLMs过度依赖原型性，产生不一致的方面判断，并且在推导自方面的因果推理方面遇到困难。

Conclusion: LLMs处理方面与人类有本质区别，并且缺乏健全的叙事理解能力。

Abstract: Large language models (LLMs) exhibit increasingly sophisticated linguistic
capabilities, yet the extent to which these behaviors reflect human-like
cognition versus advanced pattern recognition remains an open question. In this
study, we investigate how LLMs process the temporal meaning of linguistic
aspect in narratives that were previously used in human studies. Using an
Expert-in-the-Loop probing pipeline, we conduct a series of targeted
experiments to assess whether LLMs construct semantic representations and
pragmatic inferences in a human-like manner. Our findings show that LLMs
over-rely on prototypicality, produce inconsistent aspectual judgments, and
struggle with causal reasoning derived from aspect, raising concerns about
their ability to fully comprehend narratives. These results suggest that LLMs
process aspect fundamentally differently from humans and lack robust narrative
understanding. Beyond these empirical findings, we develop a standardized
experimental framework for the reliable assessment of LLMs' cognitive and
linguistic capabilities.

</details>


### [156] [What Makes You CLIC: Detection of Croatian Clickbait Headlines](https://arxiv.org/abs/2507.14314)
*Marija Anđedelić,Dominik Šipek,Laura Majer,Jan Šnajder*

Main category: cs.CL

TL;DR: 本研究通过CLIC数据集和BERTi'c模型，证明了在克罗地亚语点击诱饵检测方面，微调方法比上下文学习（ICL）效果更好。


<details>
  <summary>Details</summary>
Motivation: 在线新闻主要依赖广告收入，导致记者倾向于撰写耸人听闻、引人入胜和挑衅性的标题（即点击诱饵）。自动检测点击诱饵对于维护数字媒体的信息质量和读者信任至关重要，尤其是在资源较少的语言中，但目前尚不清楚微调方法或上下文学习（ICL）是否能产生更好的结果。

Method: 本研究编译了CLIC数据集，该数据集涵盖了20年间的克罗地亚新闻标题，用于点击诱饵检测。研究人员微调了BERTi'c模型，并将其与使用克罗地亚语和英语提示的语言模型（LLM）的上下文学习（ICL）方法进行了比较。

Result: 在CLIC数据集中，近一半的标题被识别为点击诱饵。微调后的模型在点击诱饵检测任务上的表现优于通用的LLM。

Conclusion: 微调模型在点击诱饵检测任务上的表现优于通用语言模型。

Abstract: Online news outlets operate predominantly on an advertising-based revenue
model, compelling journalists to create headlines that are often scandalous,
intriguing, and provocative -- commonly referred to as clickbait. Automatic
detection of clickbait headlines is essential for preserving information
quality and reader trust in digital media and requires both contextual
understanding and world knowledge. For this task, particularly in
less-resourced languages, it remains unclear whether fine-tuned methods or
in-context learning (ICL) yield better results. In this paper, we compile CLIC,
a novel dataset for clickbait detection of Croatian news headlines spanning a
20-year period and encompassing mainstream and fringe outlets. We fine-tune the
BERTi\'c model on this task and compare its performance to LLM-based ICL
methods with prompts both in Croatian and English. Finally, we analyze the
linguistic properties of clickbait. We find that nearly half of the analyzed
headlines contain clickbait, and that finetuned models deliver better results
than general LLMs.

</details>


### [157] [Can LLMs Infer Personality from Real World Conversations?](https://arxiv.org/abs/2507.14355)
*Jianfeng Zhu,Ruoming Jin,Karin G. Coifman*

Main category: cs.CL

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Large Language Models (LLMs) such as OpenAI's GPT-4 and Meta's LLaMA offer a
promising approach for scalable personality assessment from open-ended
language. However, inferring personality traits remains challenging, and
earlier work often relied on synthetic data or social media text lacking
psychometric validity. We introduce a real-world benchmark of 555
semi-structured interviews with BFI-10 self-report scores for evaluating
LLM-based personality inference. Three state-of-the-art LLMs (GPT-4.1 Mini,
Meta-LLaMA, and DeepSeek) were tested using zero-shot prompting for BFI-10 item
prediction and both zero-shot and chain-of-thought prompting for Big Five trait
inference. All models showed high test-retest reliability, but construct
validity was limited: correlations with ground-truth scores were weak (max
Pearson's $r = 0.27$), interrater agreement was low (Cohen's $\kappa < 0.10$),
and predictions were biased toward moderate or high trait levels.
Chain-of-thought prompting and longer input context modestly improved
distributional alignment, but not trait-level accuracy. These results
underscore limitations in current LLM-based personality inference and highlight
the need for evidence-based development for psychological applications.

</details>


### [158] [Text-to-SQL for Enterprise Data Analytics](https://arxiv.org/abs/2507.14372)
*Albert Chen,Manas Bundele,Gaurav Ahlawat,Patrick Stetz,Zhitao Wang,Qiang Fei,Donghoon Jung,Audrey Chu,Bharadwaj Jayaraman,Ayushi Panth,Yatin Arora,Sourav Jain,Renjith Varma,Alexey Ilin,Iuliia Melnychuk,Chelsea Chueh,Joyan Sil,Xiaofeng Wang*

Main category: cs.CL

TL;DR: 该研究构建了一个企业级Text-to-SQL聊天机器人，通过知识图谱和智能代理，使用户能够自助查询数据。机器人拥有大量用户，并在准确性方面表现良好，为企业级解决方案提供了实用指导。


<details>
  <summary>Details</summary>
Motivation: 该研究的动机在于，尽管大型语言模型在Text-to-SQL基准测试上取得了快速进展，但在构建实际的企业级解决方案方面仍存在挑战。因此，本文旨在分享一个内部聊天机器人的构建经验，该机器人使LinkedIn的产品经理、工程师和运营团队能够从大型动态数据湖中自助获取数据洞察。

Method: 该研究提出的方法包含三个主要部分：1. 构建一个知识图谱，通过索引数据库元数据、历史查询日志、维基百科和代码来捕捉最新语义，并应用聚类识别每个团队或产品领域相关的表。2. 构建一个Text-to-SQL代理，用于检索和排序知识图谱中的上下文，编写SQL查询，并自动纠正幻觉和语法错误。3. 构建一个交互式聊天机器人，支持用户从数据发现到查询编写和调试的各种意图，并使用丰富的UI元素展示响应以鼓励后续交互。

Result: 该聊天机器人每周拥有超过300个活跃用户。在内部基准测试中，专家评审显示其53%的响应是正确或基本正确的。通过消融研究，论文确定了知识图谱和模型中最重要的组成部分。

Conclusion: 该论文通过构建包含数据库元数据、历史查询日志、维基百科和代码的知识图谱，并结合能够检索和排序知识图谱上下文、编写查询以及自动纠正错误的Text-to-SQL代理，最终构建了一个支持数据发现、查询编写和调试的交互式聊天机器人，为企业级Text-to-SQL解决方案提供了一条实用的途径。

Abstract: The introduction of large language models has brought rapid progress on
Text-to-SQL benchmarks, but it is not yet easy to build a working enterprise
solution. In this paper, we present insights from building an internal chatbot
that enables LinkedIn's product managers, engineers, and operations teams to
self-serve data insights from a large, dynamic data lake. Our approach features
three components. First, we construct a knowledge graph that captures
up-to-date semantics by indexing database metadata, historical query logs,
wikis, and code. We apply clustering to identify relevant tables for each team
or product area. Second, we build a Text-to-SQL agent that retrieves and ranks
context from the knowledge graph, writes a query, and automatically corrects
hallucinations and syntax errors. Third, we build an interactive chatbot that
supports various user intents, from data discovery to query writing to
debugging, and displays responses in rich UI elements to encourage follow-up
chats. Our chatbot has over 300 weekly users. Expert review shows that 53% of
its responses are correct or close to correct on an internal benchmark set.
Through ablation studies, we identify the most important knowledge graph and
modeling components, offering a practical path for developing enterprise
Text-to-SQL solutions.

</details>


### [159] [Error-Aware Curriculum Learning for Biomedical Relation Classification](https://arxiv.org/abs/2507.14374)
*Sinchani Chakraborty,Sudeshna Sarkar,Pawan Goyal*

Main category: cs.CL

TL;DR: 通过一个错误感知的师生框架，利用GPT-4o进行指导，改进了生物医学文本中的关系分类性能，并在多个数据集上取得了最先进的结果。


<details>
  <summary>Details</summary>
Motivation: 关系分类（RC）在生物医学文本中对于构建知识图谱和支持药物再利用、临床决策等应用至关重要。

Method: 提出一个错误感知的师生框架，利用大型语言模型（GPT-4o）进行结构化指导，通过分析基线学生模型的预测失败来分类错误类型、分配难度分数并生成针对性的补救措施（如句子改写和知识图谱增强建议）。这些增强的标注用于通过指令调优来训练第一个学生模型，然后该模型用难度分数和补救措施增强的输入来标注更广泛的数据集。接着，通过课程学习在按难度排序的数据集上训练第二个学生模型。还从PubMed摘要中构建了一个异构生物医学知识图谱以支持上下文感知的关系分类。

Result: 该框架通过结构化指导改进了关系分类的性能。

Conclusion: 该方法在5个PPI数据集中的4个和DDI数据集上取得了新的最先进性能，在ChemProt数据集上也保持了竞争力。

Abstract: Relation Classification (RC) in biomedical texts is essential for
constructing knowledge graphs and enabling applications such as drug
repurposing and clinical decision-making. We propose an error-aware
teacher--student framework that improves RC through structured guidance from a
large language model (GPT-4o). Prediction failures from a baseline student
model are analyzed by the teacher to classify error types, assign difficulty
scores, and generate targeted remediations, including sentence rewrites and
suggestions for KG-based enrichment. These enriched annotations are used to
train a first student model via instruction tuning. This model then annotates a
broader dataset with difficulty scores and remediation-enhanced inputs. A
second student is subsequently trained via curriculum learning on this dataset,
ordered by difficulty, to promote robust and progressive learning. We also
construct a heterogeneous biomedical knowledge graph from PubMed abstracts to
support context-aware RC. Our approach achieves new state-of-the-art
performance on 4 of 5 PPI datasets and the DDI dataset, while remaining
competitive on ChemProt.

</details>


### [160] [X-Intelligence 3.0: Training and Evaluating Reasoning LLM for Semiconductor Display](https://arxiv.org/abs/2507.14430)
*Xiaolin Yan,Yangxing Liu,Jiazhang Zheng,Chi Liu,Mingyu Du,Caisheng Chen,Haoyang Liu,Ming Ding,Yuan Li,Qiuping Liao,Linfeng Li,Zhili Mei,Siyu Wan,Li Li,Ruyi Zhong,Jiangling Yu,Xule Liu,Huihui Hu,Jiameng Yue,Ruohui Cheng,Qi Yang,Liangqing Wu,Ke Zhu,Chi Zhang,Chufei Jing,Yifan Zhou,Yan Liang,Dongdong Li,Zhaohui Wang,Bin Zhao,Mingzhou Wu,Mingzhong Zhou,Peng Du,Zuomin Liao,Chao Dai,Pengfei Liang,Xiaoguang Zhu,Yu Zhang,Yu Gu,Kun Pan,Yuan Wu,Yanqing Guan,Shaojing Wu,Zikang Feng,Xianze Ma,Peishan Cheng,Wenjuan Jiang,Jing Ba,Huihao Yu,Zeping Hu,Yuan Xu,Zhiwei Liu,He Wang,Zhenguo Lin,Ming Liu,Yanhong Meng*

Main category: cs.CL

TL;DR: X-Intelligence 3.0 是首个专为半导体显示行业开发的高性能推理模型，它通过特定领域的微调和 RAG 机制，在效率和性能上都超越了现有模型，解决了行业内的推理难题。


<details>
  <summary>Details</summary>
Motivation: 为了解决大型语言模型在半导体显示行业中因缺乏领域特定训练和专业知识而效果有限的问题。

Method: 通过监督微调和强化学习，并结合特定领域的检索增强生成（RAG）机制进行训练，同时利用自动评估框架进行加速开发。

Result: X-Intelligence 3.0 在多个评估中表现优于 SOTA DeepSeek-R1-671B，尽管其参数量仅为 320 亿。

Conclusion: X-Intelligence 3.0 在半导体显示行业中表现出色，能效比高，解决了该行业长期存在的推理挑战。

Abstract: Large language models (LLMs) have recently achieved significant advances in
reasoning and demonstrated their advantages in solving challenging problems.
Yet, their effectiveness in the semiconductor display industry remains limited
due to a lack of domain-specific training and expertise. To bridge this gap, we
present X-Intelligence 3.0, the first high-performance reasoning model
specifically developed for the semiconductor display industry. This model is
designed to deliver expert-level understanding and reasoning for the industry's
complex challenges. Leveraging a carefully curated industry knowledge base, the
model undergoes supervised fine-tuning and reinforcement learning to enhance
its reasoning and comprehension capabilities. To further accelerate
development, we implemented an automated evaluation framework that simulates
expert-level assessments. We also integrated a domain-specific
retrieval-augmented generation (RAG) mechanism, resulting in notable
performance gains on benchmark datasets. Despite its relatively compact size of
32 billion parameters, X-Intelligence 3.0 outperforms SOTA DeepSeek-R1-671B
across multiple evaluations. This demonstrates its exceptional efficiency and
establishes it as a powerful solution to the longstanding reasoning challenges
faced by the semiconductor display industry.

</details>


### [161] [XL-DURel: Finetuning Sentence Transformers for Ordinal Word-in-Context Classification](https://arxiv.org/abs/2507.14578)
*Sachin Yadav,Dominik Schlechtweg*

Main category: cs.CL

TL;DR: XL-DURel 是一个优化的多语言句子 Transformer 模型，用于序数词语 in-context（WiC）分类，在序数和二元任务上均表现出色，并为 WiC 建模的统一处理提供了新途径。


<details>
  <summary>Details</summary>
Motivation: 旨在优化词语 in-context（WiC）分类任务，特别是序数 WiC 分类，并探索二元 WiC 与序数 WiC 之间的关系，以实现 WiC 建模的统一处理。

Method: 提出并微调了一个名为 XL-DURel 的多语言句子 Transformer 模型，该模型针对序数词语 in-context（WiC）分类进行了优化。测试了多种用于回归和排序任务的损失函数，并采用基于复空间角度距离的排序目标。

Result: XL-DURel 模型在序数和二元数据上均表现优于现有模型，并证明了针对序数 WiC 任务进行优化能够提升二元 WiC 任务的性能。

Conclusion: XL-DURel 是一个针对序数词语 in-context（WiC）分类进行优化的、经过微调的多语言句子 Transformer 模型。通过测试不同的回归和排序损失函数，该模型在序数和二元数据上取得了优于先前模型的性能，其排序目标基于复空间中的角度距离。研究还表明，二元 WiC 可视为序数 WiC 的特例，并且针对更通用的序数任务进行优化可以提升在更具体的二元任务上的性能，这为跨不同任务表述的 WiC 建模的统一处理奠定了基础。

Abstract: We propose XL-DURel, a finetuned, multilingual Sentence Transformer model
optimized for ordinal Word-in-Context classification. We test several loss
functions for regression and ranking tasks managing to outperform previous
models on ordinal and binary data with a ranking objective based on angular
distance in complex space. We further show that binary WiC can be treated as a
special case of ordinal WiC and that optimizing models for the general ordinal
task improves performance on the more specific binary task. This paves the way
for a unified treatment of WiC modeling across different task formulations.

</details>


### [162] [Exploring Human-AI Complementarity in CPS Diagnosis Using Unimodal and Multimodal BERT Models](https://arxiv.org/abs/2507.14579)
*Kester Wong,Sahan Bulathwela,Mutlu Cukurova*

Main category: cs.CL

TL;DR: 本研究使用 AudiBERT 和 BERT 模型分析对话以检测协作问题解决 (CPS) 指标。AudiBERT 在某些方面优于 BERT，尤其是在稀疏类别和社会认知指标上。模型性能与训练数据量和人工标注一致性相关。研究还强调了模型可解释性对于实现人机协作以改进 CPS 诊断的重要性。


<details>
  <summary>Details</summary>
Motivation: 为了解决在教育领域利用机器学习技术检测对话中协作问题解决 (CPS) 指标的挑战，本研究旨在探索 AudiBERT 等多模态模型相对于 BERT 模型的优势，并为实现人机互补以改进 CPS 诊断提供指导。

Method: 本研究使用 AudiBERT 和 BERT 模型，并结合了语音和声学-韵律音频特征，以检测对话中的协作问题解决 (CPS) 指标。此外，还进行了相关性分析，以确定训练数据量和评分者间一致性对模型性能的影响。

Result: 研究发现 AudiBERT 模型在分类稀疏类别以及社会认知维度方面，相比 BERT 模型在分类上有了统计上显著的改进。然而，在情感维度方面，并未观察到类似的显著改进。相关性分析表明，更大的训练数据量与更高的召回率显著相关，而 BERT 模型的精确率与评分者间一致性显著相关。在将 BERT 模型应用于 AudiBERT 检测效果较好的子技能指标时，所有指标的表现均不一致。

Conclusion: 该论文总结了使用 AudiBERT 和 BERT 模型检测协作问题解决 (CPS) 指标的发现，并提出了一种实现人机互补以进行 CPS 诊断的结构化方法，强调了模型可解释性在支持人类能动性和参与反思性编码过程中的关键作用。

Abstract: Detecting collaborative problem solving (CPS) indicators from dialogue using
machine learning techniques is a significant challenge for the field of AI in
Education. Recent studies have explored the use of Bidirectional Encoder
Representations from Transformers (BERT) models on transcription data to
reliably detect meaningful CPS indicators. A notable advancement involved the
multimodal BERT variant, AudiBERT, which integrates speech and
acoustic-prosodic audio features to enhance CPS diagnosis. Although initial
results demonstrated multimodal improvements, the statistical significance of
these enhancements remained unclear, and there was insufficient guidance on
leveraging human-AI complementarity for CPS diagnosis tasks. This workshop
paper extends the previous research by highlighting that the AudiBERT model not
only improved the classification of classes that were sparse in the dataset,
but it also had statistically significant class-wise improvements over the BERT
model for classifications in the social-cognitive dimension. However, similar
significant class-wise improvements over the BERT model were not observed for
classifications in the affective dimension. A correlation analysis highlighted
that larger training data was significantly associated with higher recall
performance for both the AudiBERT and BERT models. Additionally, the precision
of the BERT model was significantly associated with high inter-rater agreement
among human coders. When employing the BERT model to diagnose indicators within
these subskills that were well-detected by the AudiBERT model, the performance
across all indicators was inconsistent. We conclude the paper by outlining a
structured approach towards achieving human-AI complementarity for CPS
diagnosis, highlighting the crucial inclusion of model explainability to
support human agency and engagement in the reflective coding process.

</details>


### [163] [Explainable Collaborative Problem Solving Diagnosis with BERT using SHAP and its Implications for Teacher Adoption](https://arxiv.org/abs/2507.14584)
*Kester Wong,Sahan Bulathwela,Mutlu Cukurova*

Main category: cs.CL

TL;DR: BERT模型在教育领域诊断协作问题解决（CPS）过程中，仅有准确分类是不够的，还需要合理的解释。本研究使用SHAP分析了词语对分类的贡献，发现模型有时会依赖无意义的词语进行分类。这提醒用户不要过度依赖模型，而应结合自身专业知识。未来的研究需要探索集成模型和人机互补，以更好地进行CPS诊断。


<details>
  <summary>Details</summary>
Motivation: 为了增强BERT模型在教育领域诊断CPS的解释性，从而更好地告知教师等最终用户，增加信任并促进其广泛应用。

Method: 本研究使用SHapley Additive exPlanations（SHAP）来检验BERT模型在分类协作问题解决（CPS）过程时，数据集中不同标记化词语的贡献度。

Result: 研究发现，表现良好的分类并不一定意味着其分类决策具有合理的解释。特定的标记化词语被频繁用于影响分类，并且发现了一个“伪造”词语，它对分类做出了积极贡献但与类别在语义上无意义。

Conclusion: 为了实现对协作问题解决（CPS）过程的诊断，需要对模型进行解释，以增加教师等最终用户的信任并促进其在教育领域的广泛应用。该研究使用SHAP检验了BERT模型分类CPS过程中的词语贡献度，发现表现良好的分类不一定具有合理的解释，并且存在一些“伪造”的词语。虽然模型透明度本身可能无法直接改进用户实践，但可以防止用户过度依赖模型而忽略自身专业知识。最终，该研究指出模型对词语的恰当使用程度与涉及的类别数量有关，并呼吁探索集成模型架构和人机互补以进行CPS诊断，因为精细区分CPS子技能仍需要大量人类推理。

Abstract: The use of Bidirectional Encoder Representations from Transformers (BERT)
model and its variants for classifying collaborative problem solving (CPS) has
been extensively explored within the AI in Education community. However,
limited attention has been given to understanding how individual tokenised
words in the dataset contribute to the model's classification decisions.
Enhancing the explainability of BERT-based CPS diagnostics is essential to
better inform end users such as teachers, thereby fostering greater trust and
facilitating wider adoption in education. This study undertook a preliminary
step towards model transparency and explainability by using SHapley Additive
exPlanations (SHAP) to examine how different tokenised words in transcription
data contributed to a BERT model's classification of CPS processes. The
findings suggested that well-performing classifications did not necessarily
equate to a reasonable explanation for the classification decisions. Particular
tokenised words were used frequently to affect classifications. The analysis
also identified a spurious word, which contributed positively to the
classification but was not semantically meaningful to the class. While such
model transparency is unlikely to be useful to an end user to improve their
practice, it can help them not to overrely on LLM diagnostics and ignore their
human expertise. We conclude the workshop paper by noting that the extent to
which the model appropriately uses the tokens for its classification is
associated with the number of classes involved. It calls for an investigation
into the exploration of ensemble model architectures and the involvement of
human-AI complementarity for CPS diagnosis, since considerable human reasoning
is still required for fine-grained discrimination of CPS subskills.

</details>


### [164] [Backtranslation and paraphrasing in the LLM era? Comparing data augmentation methods for emotion classification](https://arxiv.org/abs/2507.14590)
*Łukasz Radliński,Mateusz Guściora,Jan Kocoń*

Main category: cs.CL

TL;DR: 本文探索了使用GPT等大型语言模型进行NLP数据增强的方法，发现反向翻译和释义等传统方法在生成数据和提升模型性能方面，效果与零样本和少样本生成相当甚至更优。


<details>
  <summary>Details</summary>
Motivation: 为了解决NLP领域中数据稀缺和类别不平衡的问题，并探索利用GPT等大型语言模型进行数据增强的可行性。

Method: 本文通过对比实验，评估了包括反向翻译、释义、零样本生成和少样本生成在内的四种数据增强方法在NLP任务中的表现。

Result: 反向翻译和释义在数据质量和分类性能上均可达到与零样本和少样本生成相当甚至更好的效果。

Conclusion: GPT等大型语言模型可以通过反向翻译和释义等传统方法进行微调，以生成高质量的NLP数据，并且在分类任务中表现优于零样本和少样本生成。

Abstract: Numerous domain-specific machine learning tasks struggle with data scarcity
and class imbalance. This paper systematically explores data augmentation
methods for NLP, particularly through large language models like GPT. The
purpose of this paper is to examine and evaluate whether traditional methods
such as paraphrasing and backtranslation can leverage a new generation of
models to achieve comparable performance to purely generative methods. Methods
aimed at solving the problem of data scarcity and utilizing ChatGPT were
chosen, as well as an exemplary dataset. We conducted a series of experiments
comparing four different approaches to data augmentation in multiple
experimental setups. We then evaluated the results both in terms of the quality
of generated data and its impact on classification performance. The key
findings indicate that backtranslation and paraphrasing can yield comparable or
even better results than zero and a few-shot generation of examples.

</details>


### [165] [Retrieval-Augmented Clinical Benchmarking for Contextual Model Testing in Kenyan Primary Care: A Methodology Paper](https://arxiv.org/abs/2507.14615)
*Fred Mutisya,Shikoh Gitau,Christine Syovata,Diana Oigara,Ibrahim Matende,Muna Aden,Munira Ali,Ryan Nyotu,Diana Marion,Job Nyangena,Nasubo Ongoma,Keith Mbae,Elizabeth Wamicha,Eric Mibuari,Jean Philbert Nsengemana,Talkmore Chidede*

Main category: cs.CL

TL;DR: 该研究创建了一个针对肯尼亚医疗保健的基准数据集和评估框架，重点是使用检索增强生成（RAG）和国家指南。结果表明，与美国基准相比，大型语言模型在本地化场景中的表现存在差距，并强调了在非洲卫生系统部署人工智能的挑战和机遇。


<details>
  <summary>Details</summary>
Motivation: 探索大型语言模型在低资源环境（特别是非洲基层医疗）中的有效性。

Method: 该方法使用检索增强生成（RAG）将临床问题与肯尼亚的国家指南相结合，并对数据集的准确性、清晰度和文化适应性进行了评估。

Result: 初始结果显示，当大型语言模型应用于本地化场景时，性能存在显著差距，这与在非洲医疗内容上大型语言模型的准确性低于美国基准测试的发现一致。创建了一个包含数千个符合法规的问答对的 Alama Health QA 数据集，涵盖了常见的门诊病症。

Conclusion: 这项工作提供了一个可复制的模型，用于驱动的、动态的基准测试，以支持非洲卫生系统中人工智能的安全部署。

Abstract: Large Language Models(LLMs) hold promise for improving healthcare access in
low-resource settings, but their effectiveness in African primary care remains
underexplored. We present a methodology for creating a benchmark dataset and
evaluation framework focused on Kenyan Level 2 and 3 clinical care. Our
approach uses retrieval augmented generation (RAG) to ground clinical questions
in Kenya's national guidelines, ensuring alignment with local standards. These
guidelines were digitized, chunked, and indexed for semantic retrieval. Gemini
Flash 2.0 Lite was then prompted with guideline excerpts to generate realistic
clinical scenarios, multiple-choice questions, and rationale based answers in
English and Swahili. Kenyan physicians co-created and refined the dataset, and
a blinded expert review process ensured clinical accuracy, clarity, and
cultural appropriateness. The resulting Alama Health QA dataset includes
thousands of regulator-aligned question answer pairs across common outpatient
conditions. Beyond accuracy, we introduce evaluation metrics that test clinical
reasoning, safety, and adaptability such as rare case detection (Needle in the
Haystack), stepwise logic (Decision Points), and contextual adaptability.
Initial results reveal significant performance gaps when LLMs are applied to
localized scenarios, consistent with findings that LLM accuracy is lower on
African medical content than on US-based benchmarks. This work offers a
replicable model for guideline-driven, dynamic benchmarking to support safe AI
deployment in African health systems.

</details>


### [166] [Linear Relational Decoding of Morphology in Language Models](https://arxiv.org/abs/2507.14640)
*Eric Xia,Jugal Kalita*

Main category: cs.CL

TL;DR: 语言模型中的形态学关系可以通过跨层线性变换稀疏编码来解释。


<details>
  <summary>Details</summary>
Motivation: 探究 transformer 计算在某些主语-宾语关系上的近似性，并研究线性变换在其中扮演的角色。

Method: 研究人员使用 Bigger Analogy Test Set，并表明线性变换 Ws（其中 s 是主语标记的中间层表示，W 来自模型导数）也能够准确地再现许多关系中的最终对象状态。

Result: 线性技术在形态学关系上实现了 90% 的忠实度，并且在多语言和跨模型中也发现了类似的结果。

Conclusion: 该研究表明，语言模型中的某些概念关系（如形态学）可以从潜在空间中轻松解释，并且通过跨层线性变换稀疏编码。

Abstract: A two-part affine approximation has been found to be a good approximation for
transformer computations over certain subject object relations. Adapting the
Bigger Analogy Test Set, we show that the linear transformation Ws, where s is
a middle layer representation of a subject token and W is derived from model
derivatives, is also able to accurately reproduce final object states for many
relations. This linear technique is able to achieve 90% faithfulness on
morphological relations, and we show similar findings multi-lingually and
across models. Our findings indicate that some conceptual relationships in
language models, such as morphology, are readily interpretable from latent
space, and are sparsely encoded by cross-layer linear transformations.

</details>


### [167] [Cleanse: Uncertainty Estimation Approach Using Clustering-based Semantic Consistency in LLMs](https://arxiv.org/abs/2507.14649)
*Minsuh Joo,Hyunsoo Cho*

Main category: cs.CL

TL;DR: Cleanse是一种新的不确定性估计方法，用于检测大型语言模型中的幻觉。


<details>
  <summary>Details</summary>
Motivation: 为了解决大型语言模型（LLMs）在生成不准确回应（幻觉）方面存在的问题，这影响了构建安全可靠的LLMs的信任度。

Method: Cleanse通过聚类方法量化LLM隐藏嵌入之间的内部聚类一致性比例来衡量不确定性。

Result: Cleanse在LLaMA-7B、LLaMA-13B、LLaMA2-7B和Mistral-7B这四种模型以及SQuAD和CoQA这两个问答基准上得到验证，证明了其在检测幻觉方面的有效性。

Conclusion: Cleanse通过利用聚类方法量化LLM隐藏嵌入之间的内部聚类一致性比例来衡量不确定性，从而有效检测幻觉。

Abstract: Despite the outstanding performance of large language models (LLMs) across
various NLP tasks, hallucinations in LLMs--where LLMs generate inaccurate
responses--remains as a critical problem as it can be directly connected to a
crisis of building safe and reliable LLMs. Uncertainty estimation is primarily
used to measure hallucination levels in LLM responses so that correct and
incorrect answers can be distinguished clearly. This study proposes an
effective uncertainty estimation approach, \textbf{Cl}ust\textbf{e}ring-based
sem\textbf{an}tic con\textbf{s}ist\textbf{e}ncy (\textbf{Cleanse}). Cleanse
quantifies the uncertainty with the proportion of the intra-cluster consistency
in the total consistency between LLM hidden embeddings which contain adequate
semantic information of generations, by employing clustering. The effectiveness
of Cleanse for detecting hallucination is validated using four off-the-shelf
models, LLaMA-7B, LLaMA-13B, LLaMA2-7B and Mistral-7B and two
question-answering benchmarks, SQuAD and CoQA.

</details>


### [168] [Mangosteen: An Open Thai Corpus for Language Model Pretraining](https://arxiv.org/abs/2507.14664)
*Wannaphong Phatthiyaphaibun,Can Udomcharoenchaikit,Pakpoom Singkorapoom,Kunat Pipatanakul,Ekapol Chuangsuwanich,Peerat Limkonchotiwat,Sarana Nutanong*

Main category: cs.CL

TL;DR: Mangosteen是一个包含470亿token的泰语语料库，通过改进的Dolma处理流程构建，解决了现有泰语语料库的不足，提升了模型在泰语任务上的表现，并公开了所有相关资源以促进可复现性研究。


<details>
  <summary>Details</summary>
Motivation: 现有的语言模型预训练数据处理流程未能充分考虑到泰语的语言特点和文化细微差别，导致存在不当内容，并且现有针对泰语的定制化方法往往不公开数据或设计选择，阻碍了研究的可复现性。因此，需要构建一个透明、高质量的泰语语料库。

Method: Mangosteen语料库是通过一个针对泰语的Dolma处理流程构建的，该流程包括自定义的基于规则的语言识别、修改后的C4/Gopher质量过滤以及针对泰语的有害内容过滤，此外还包括了来自Wikipedia、皇家公报、OCR书籍和CC许可的YouTube字幕等精选的非网络数据源。

Result: Mangosteen语料库包含470亿个token。通过GPT-2进行的系统性实验表明，该处理流程将CommonCrawl的文档数量从2.02亿减少到2500万，同时将SEA-HELM NLG得分从3提高到11。在Mangosteen上持续预训练的80亿参数SEA-LION模型在泰国基准测试上的表现比SEA-LION-v3和Llama-3.1高出约4个百分点。

Conclusion: Mangosteen提供了一个完全可复现的泰国和区域大型语言模型研究基础，包括完整的处理流程代码、清理清单、语料库快照和所有检查点。

Abstract: Pre-training data shapes a language model's quality, but raw web text is
noisy and demands careful cleaning. Existing large-scale corpora rely on
English-centric or language-agnostic pipelines whose heuristics do not capture
Thai script or cultural nuances, leaving risky material such as gambling
content untreated. Prior Thai-specific efforts customize pipelines or build new
ones, yet seldom release their data or document design choices, hindering
reproducibility and raising the question of how to construct a transparent,
high-quality Thai corpus. We introduce Mangosteen: a 47 billion-token Thai
corpus built through a Thai-adapted Dolma pipeline that includes custom
rule-based language ID, revised C4/Gopher quality filters, and Thai-trained
content filters, plus curated non-web sources such as Wikipedia, Royal Gazette
texts, OCR-extracted books, and CC-licensed YouTube subtitles. Systematic
ablations using GPT-2 show the pipeline trims CommonCrawl from 202M to 25M
documents while raising SEA-HELM NLG from 3 to 11; an 8B-parameter SEA-LION
model continually pre-trained on Mangosteen then surpasses SEA-LION-v3 and
Llama-3.1 by about four points on Thai benchmarks. We release the full pipeline
code, cleaning manifests, corpus snapshot, and all checkpoints, providing a
fully reproducible foundation for future Thai and regional LLM research.

</details>


### [169] [Large Language Models as Medical Codes Selectors: a benchmark using the International Classification of Primary Care](https://arxiv.org/abs/2507.14681)
*Vinicius Anjos de Almeida,Vinicius de Camargo,Raquel Gómez-Bravo,Egbert van der Haring,Kees van Boven,Marcelo Finger,Luis Fernandez Lopez*

Main category: cs.CL

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Background: Medical coding structures healthcare data for research, quality
monitoring, and policy. This study assesses the potential of large language
models (LLMs) to assign ICPC-2 codes using the output of a domain-specific
search engine.
  Methods: A dataset of 437 Brazilian Portuguese clinical expressions, each
annotated with ICPC-2 codes, was used. A semantic search engine (OpenAI's
text-embedding-3-large) retrieved candidates from 73,563 labeled concepts.
Thirty-three LLMs were prompted with each query and retrieved results to select
the best-matching ICPC-2 code. Performance was evaluated using F1-score, along
with token usage, cost, response time, and format adherence.
  Results: Twenty-eight models achieved F1-score > 0.8; ten exceeded 0.85. Top
performers included gpt-4.5-preview, o3, and gemini-2.5-pro. Retriever
optimization can improve performance by up to 4 points. Most models returned
valid codes in the expected format, with reduced hallucinations. Smaller models
(<3B) struggled with formatting and input length.
  Conclusions: LLMs show strong potential for automating ICPC-2 coding, even
without fine-tuning. This work offers a benchmark and highlights challenges,
but findings are limited by dataset scope and setup. Broader, multilingual,
end-to-end evaluations are needed for clinical validation.

</details>


### [170] [MiroMind-M1: An Open-Source Advancement in Mathematical Reasoning via Context-Aware Multi-Stage Policy Optimization](https://arxiv.org/abs/2507.14683)
*Xingxuan Li,Yao Xiao,Dianwen Ng,Hai Ye,Yue Deng,Xiang Lin,Bin Wang,Zhanfeng Mo,Chong Zhang,Yueyi Zhang,Zonglin Yang,Ruilin Li,Lei Lei,Shihao Xu,Han Zhao,Weiling Chen,Feng Ji,Lidong Bing*

Main category: cs.CL

TL;DR: 本研究提出了 MiroMind-M1 系列完全开源的推理语言模型，旨在提高数学推理能力和训练过程的透明度与可复现性。模型在 SFT 和 RLVR 两个阶段进行训练，并引入了上下文感知多阶段策略优化算法。结果显示，MiroMind-M1 模型在各项基准测试中表现优异，并提供了完整的开源资源。


<details>
  <summary>Details</summary>
Motivation: 尽管闭源模型在数学推理方面表现出色，但其专有性质限制了透明度和可复现性。现有的开源项目虽旨在弥补这一差距，但通常缺乏数据集和详细训练配置等关键资源，阻碍了可复现性。因此，本研究旨在通过提供完全开源的 RLM 来促进 RLM 开发的透明度。

Method: 本研究介绍了 MiroMind-M1 系列模型，它们是基于 Qwen-2.5 主干构建的全开源推理语言模型 (RLM)。模型训练分为两个阶段：首先在包含 719K 个已验证的思维链轨迹的数学推理问题语料库上进行监督微调 (SFT)；其次，在 62K 个具有挑战性且可验证的问题上进行基于奖励的学习 (RLVR)。为了提高 RLVR 过程的鲁棒性和效率，研究提出了一种名为“上下文感知多阶段策略优化”的算法，该算法整合了长度渐进训练和自适应重复惩罚，以促进上下文感知的 RL 训练。

Result: MiroMind-M1 系列模型在 AIME24、AIME25 和 MATH 基准测试中取得了最先进或具有竞争力的性能，并且在基于 Qwen-2.5 的开源 7B 和 32B 模型中具有更高的代币效率。

Conclusion: MiroMind-M1 系列模型在 AIME24、AIME25 和 MATH 基准测试中取得了最先进或具有竞争力的性能，并且在基于 Qwen-2.5 的开源 7B 和 32B 模型中具有更高的代币效率。为便于复现，我们发布了完整的技术栈，包括模型、数据集以及所有的训练和评估配置。

Abstract: Large language models have recently evolved from fluent text generation to
advanced reasoning across diverse domains, giving rise to reasoning language
models. Among these domains, mathematical reasoning serves as a representative
benchmark as it requires precise multi-step logic and abstract reasoning, which
can be generalized to other tasks. While closed-source RLMs such as GPT-o3
demonstrate impressive reasoning capabilities, their proprietary nature limits
transparency and reproducibility. Although many open-source projects aim to
close this gap, most of them lack sufficient openness by omitting critical
resources such as datasets and detailed training configurations, which hinders
reproducibility. To contribute toward greater transparency in RLM development,
we introduce the MiroMind-M1 series, a set of fully open-source RLMs built on
the Qwen-2.5 backbone that match or exceed the performance of existing
open-source RLMs. Specifically, our models are trained in two stages: SFT on a
carefully curated corpus of 719K math-reasoning problems with verified CoT
trajectories, followed by RLVR on 62K challenging and verifiable problems. To
enhance the robustness and efficiency of the RLVR process, we introduce
Context-Aware Multi-Stage Policy Optimization, an algorithm that integrates
length-progressive training with an adaptive repetition penalty to encourage
context-aware RL training. Our model achieves state-of-the-art or competitive
performance and superior token efficiency among Qwen-2.5-based open-source 7B
and 32B models on the AIME24, AIME25, and MATH benchmarks. To facilitate
reproducibility, we release the complete stack: models (MiroMind-M1-SFT-7B,
MiroMind-M1-RL-7B, MiroMind-M1-RL-32B); datasets (MiroMind-M1-SFT-719K,
MiroMind-M1-RL-62K); and all training and evaluation configurations. We hope
these resources will support further research and foster community advancement.

</details>


### [171] [Mind the Gap: A Review of Arabic Post-Training Datasets and Their Limitations](https://arxiv.org/abs/2507.14688)
*Mohammed Alkhowaiter,Norah Alshahrani,Saied Alshahrani,Reem I. Masoud,Alaa Alzahrani,Deema Alnuhait,Emad A. Alghamdi,Khalid Almubarak*

Main category: cs.CL

TL;DR: 本研究评估了Hugging Face Hub上的阿拉伯语指令微调数据集，发现它们在任务多样性、文档质量和社区采用方面存在不足，并提出了改进建议。


<details>
  <summary>Details</summary>
Motivation: 为了提升预训练语言模型（LLMs）在阿拉伯语任务上的表现，需要高质量和多样化的指令微调数据集。本研究旨在全面了解当前阿拉伯语指令微调数据集的现状，识别存在的问题和不足，为未来数据集的开发提供指导。

Method: 通过对Hugging Face Hub上公开的阿拉伯语指令微调数据集进行系统性回顾和评估，重点关注其在语言模型能力、可控性、对齐性和鲁棒性四个维度上的表现，并从流行度、实际应用、更新维护、文档标注质量、许可透明度和科学贡献等方面进行评价。

Result: 研究发现，当前的阿拉伯语指令微调数据集在任务多样性、文档和标注质量以及社区采用率方面存在不足。具体来说，数据集覆盖的任务类型有限，文档和标注质量不一致或缺失，且在社区中的应用和维护程度较低。

Conclusion: 该论文对Hugging Face Hub上公开的阿拉伯语指令微调数据集进行了全面回顾，评估了其在语言模型能力、可控性、对齐性和鲁棒性等方面的表现。研究发现，阿拉伯语数据集在任务多样性、文档和标注质量以及社区采用率方面存在显著不足，并对阿拉伯语大语言模型的发展提出了改进建议。

Abstract: Post-training has emerged as a crucial technique for aligning pre-trained
Large Language Models (LLMs) with human instructions, significantly enhancing
their performance across a wide range of tasks. Central to this process is the
quality and diversity of post-training datasets. This paper presents a review
of publicly available Arabic post-training datasets on the Hugging Face Hub,
organized along four key dimensions: (1) LLM Capabilities (e.g., Question
Answering, Translation, Reasoning, Summarization, Dialogue, Code Generation,
and Function Calling); (2) Steerability (e.g., persona and system prompts); (3)
Alignment (e.g., cultural, safety, ethics, and fairness), and (4) Robustness.
Each dataset is rigorously evaluated based on popularity, practical adoption,
recency and maintenance, documentation and annotation quality, licensing
transparency, and scientific contribution. Our review revealed critical gaps in
the development of Arabic post-training datasets, including limited task
diversity, inconsistent or missing documentation and annotation, and low
adoption across the community. Finally, the paper discusses the implications of
these gaps on the progress of Arabic LLMs and applications while providing
concrete recommendations for future efforts in post-training dataset
development.

</details>


### [172] [Rethinking Suicidal Ideation Detection: A Trustworthy Annotation Framework and Cross-Lingual Model Evaluation](https://arxiv.org/abs/2507.14693)
*Amina Dzafic,Merve Kavut,Ulya Bayram*

Main category: cs.CL

TL;DR: 这项研究构建了一个新的土耳其语自杀意念数据集，并提出了一个包含人工和AI标注的框架。通过评估标签可靠性和模型一致性，研究发现现有的零样本迁移学习模型在自杀意念检测任务上表现不佳，并呼吁在心理健康NLP领域提高数据和模型的透明度与可靠性。


<details>
  <summary>Details</summary>
Motivation: 现有自杀意念检测研究面临两大挑战：语言覆盖范围有限和标注实践不可靠。大多数可用数据集是英文的，即使是英文数据，高质量的人工标注数据也很稀少。此外，其他语言的数据集匮乏阻碍了通过人工智能（AI）实现全球自杀预防。因此，本研究旨在构建新的土耳其语语料库并评估标注可靠性和模型一致性。

Method: 研究构建了一个新的土耳其语自杀意念语料库，并引入了一个包含三个人工标注者和两个大型语言模型（LLMs）的资源高效标注框架。随后，研究者通过八个预训练的情感和情绪分类器进行了迁移学习，对该数据集和三个流行的英语自杀意念检测数据集进行了双向评估，以检验标签可靠性和模型一致性。

Result: 研究结果强调了在心理健康NLP中采用更严格、更具包容性的语言标注和评估方法的必要性，并揭示了流行的零样本迁移学习模型的可靠性存在疑问。研究者主张在心理健康NLP中提高模型训练和数据集构建的透明度，并优先考虑数据和模型的可靠性。

Conclusion: 该研究强调了在心理健康NLP中采用更严格、更具包容性的语言标注和评估方法的必要性，并证明了流行的零样本迁移学习模型的可靠性存在疑问。研究者主张在心理健康NLP中提高模型训练和数据集构建的透明度，并优先考虑数据和模型的可靠性。

Abstract: Suicidal ideation detection is critical for real-time suicide prevention, yet
its progress faces two under-explored challenges: limited language coverage and
unreliable annotation practices. Most available datasets are in English, but
even among these, high-quality, human-annotated data remains scarce. As a
result, many studies rely on available pre-labeled datasets without examining
their annotation process or label reliability. The lack of datasets in other
languages further limits the global realization of suicide prevention via
artificial intelligence (AI). In this study, we address one of these gaps by
constructing a novel Turkish suicidal ideation corpus derived from social media
posts and introducing a resource-efficient annotation framework involving three
human annotators and two large language models (LLMs). We then address the
remaining gaps by performing a bidirectional evaluation of label reliability
and model consistency across this dataset and three popular English suicidal
ideation detection datasets, using transfer learning through eight pre-trained
sentiment and emotion classifiers. These transformers help assess annotation
consistency and benchmark model performance against manually labeled data. Our
findings underscore the need for more rigorous, language-inclusive approaches
to annotation and evaluation in mental health natural language processing (NLP)
while demonstrating the questionable performance of popular models with
zero-shot transfer learning. We advocate for transparency in model training and
dataset construction in mental health NLP, prioritizing data and model
reliability.

</details>


### [173] [Disparities in Peer Review Tone and the Role of Reviewer Anonymity](https://arxiv.org/abs/2507.14741)
*Maria Sahakyan,Bedoor AlShebli*

Main category: cs.CL

TL;DR: 一项针对80,000多份同行评审报告的语言分析显示，审稿中存在基于作者性别、种族和机构的偏见，匿名评审的公平性也受到质疑。


<details>
  <summary>Details</summary>
Motivation: 该研究旨在深入探究同行评审过程中语言可能存在的微妙偏见，以揭示其如何加剧科学领域的不平等现象，并挑战关于匿名评审公平性的传统观念。

Method: 研究利用自然语言处理和大规模统计建模，分析了两个主要期刊中超过80,000份同行评审报告，考察了包括性别、种族和机构归属在内的作者人口统计信息在审稿语气、情感和支持性语言方面的差异，并探讨了审稿人身份披露对评审语言的影响。

Result: 研究发现，审稿的语气、情感和支持性语言因作者的人口统计信息（包括性别、种族和机构归属）而异。此外，审稿人身份的披露也会影响评审语言。

Conclusion: 该研究揭示了同行评审过程中存在的隐藏偏见，并对匿名评审的公平性提出了质疑，强调了审查政策对学术出版和科学进步的影响。

Abstract: The peer review process is often regarded as the gatekeeper of scientific
integrity, yet increasing evidence suggests that it is not immune to bias.
Although structural inequities in peer review have been widely debated, much
less attention has been paid to the subtle ways in which language itself may
reinforce disparities. This study undertakes one of the most comprehensive
linguistic analyses of peer review to date, examining more than 80,000 reviews
in two major journals. Using natural language processing and large-scale
statistical modeling, it uncovers how review tone, sentiment, and supportive
language vary across author demographics, including gender, race, and
institutional affiliation. Using a data set that includes both anonymous and
signed reviews, this research also reveals how the disclosure of reviewer
identity shapes the language of evaluation. The findings not only expose hidden
biases in peer feedback, but also challenge conventional assumptions about
anonymity's role in fairness. As academic publishing grapples with reform,
these insights raise critical questions about how review policies shape career
trajectories and scientific progress.

</details>


### [174] [On the robustness of modeling grounded word learning through a child's egocentric input](https://arxiv.org/abs/2507.14749)
*Wai Keen Vong,Brenden M. Lake*

Main category: cs.CL

TL;DR: 通过分析500多小时的儿童视频数据，研究发现多模态神经网络能够从有限的、自动转录的儿童输入中学习词汇，并且这种学习具有跨不同儿童和网络架构的鲁棒性，但也存在个体差异。


<details>
  <summary>Details</summary>
Motivation: 为了解决大型语言模型与儿童语言习得之间在训练数据量和质量上的差异，本研究旨在探索通过模拟儿童有限的输入来训练神经网络，并验证这种方法在跨多个儿童数据集上的学习模式的稳健性和一致性。

Method: 本研究采用了自动化语音转录方法处理了SAYCam数据集中的500多小时视频数据，生成了用于训练和评估的多模态视觉-语言数据集。研究人员探索了一系列神经网络配置，以检验模拟词汇学习的鲁棒性。

Result: 研究结果表明，在从每个儿童的自动转录数据上训练的神经网络能够跨多种网络架构习得并泛化词汇-指代表征。这证明了多模态神经网络在基础词汇学习上的鲁棒性，同时也突显了在不同儿童的经验上训练模型时出现的个体差异。

Conclusion: 本研究验证了多模态神经网络在基础词汇学习中的鲁棒性，并揭示了模型在学习过程中因训练数据个体差异而产生的学习模式的独特性。

Abstract: What insights can machine learning bring to understanding human language
acquisition? Large language and multimodal models have achieved remarkable
capabilities, but their reliance on massive training datasets creates a
fundamental mismatch with children, who succeed in acquiring language from
comparatively limited input. To help bridge this gap, researchers have
increasingly trained neural networks using data similar in quantity and quality
to children's input. Taking this approach to the limit, Vong et al. (2024)
showed that a multimodal neural network trained on 61 hours of visual and
linguistic input extracted from just one child's developmental experience could
acquire word-referent mappings. However, whether this approach's success
reflects the idiosyncrasies of a single child's experience, or whether it would
show consistent and robust learning patterns across multiple children's
experiences was not explored. In this article, we applied automated speech
transcription methods to the entirety of the SAYCam dataset, consisting of over
500 hours of video data spread across all three children. Using these automated
transcriptions, we generated multi-modal vision-and-language datasets for both
training and evaluation, and explored a range of neural network configurations
to examine the robustness of simulated word learning. Our findings demonstrate
that networks trained on automatically transcribed data from each child can
acquire and generalize word-referent mappings across multiple network
architectures. These results validate the robustness of multimodal neural
networks for grounded word learning, while highlighting the individual
differences that emerge in how models learn when trained on each child's
developmental experiences.

</details>


### [175] [GRACE: Generative Recommendation via Journey-Aware Sparse Attention on Chain-of-Thought Tokenization](https://arxiv.org/abs/2507.14758)
*Luyi Ma,Wanjia Zhang,Kai Zhao,Abhishek Kulkarni,Lalitesh Morishetti,Anjana Ganesh,Ashish Ranjan,Aashika Padmanabhan,Jianpeng Xu,Jason Cho,Praveen Kanumala,Kaushiki Nag,Sumit Dutta,Kamiya Motwani,Malay Patel,Evren Korpeoglu,Sushant Kumar,Kannan Achan*

Main category: cs.CL

TL;DR: GRACE是一个用于多行为推荐的生成框架，通过CoT标记化和JSA注意力机制解决现有模型的局限性，显著提升了推荐效果并降低了计算成本。


<details>
  <summary>Details</summary>
Motivation: 现有生成模型在多行为推荐系统中虽然有潜力，但面临三个主要挑战：（1）缺乏用于标记推理的显式信息；（2）标记化后由于二次注意力复杂性和密集序列表示导致的高计算成本；（3）用户历史的多尺度建模能力有限。

Method: 提出了一种名为GRACE（Generative Recommendation via journey-aware sparse Attention on Chain-of-thought tokEnization）的新型生成推荐框架。该框架引入了混合思维链（CoT）标记化方法，结合了用户-项交互和来自产品知识图谱（如类别、品牌、价格）的显式属性，实现了可解释和行为对齐的生成。为了解决标准注意力的效率问题，设计了旅程感知稀疏注意力（JSA）机制，选择性地关注标记化序列中的压缩、内部、外部和当前上下文片段。

Result: 在两个真实世界数据集上的实验表明，GRACE显著优于最先进的基线模型。在家庭领域，其HR@10和NDCG@10的提升高达+106.9%和+106.7%；在电子产品领域，HR@10提升了+22.1%。此外，GRACE还将长序列的注意力计算量减少了高达48%。

Conclusion: GRACE框架通过混合思维链（CoT）标记化方法和关注压缩、内部、外部和当前上下文片段的旅程感知稀疏注意力（JSA）机制，解决了现有生成模型在多行为推荐中的局限性，在真实数据集上取得了显著的性能提升，并有效降低了计算成本。

Abstract: Generative models have recently demonstrated strong potential in
multi-behavior recommendation systems, leveraging the expressive power of
transformers and tokenization to generate personalized item sequences. However,
their adoption is hindered by (1) the lack of explicit information for token
reasoning, (2) high computational costs due to quadratic attention complexity
and dense sequence representations after tokenization, and (3) limited
multi-scale modeling over user history. In this work, we propose GRACE
(Generative Recommendation via journey-aware sparse Attention on
Chain-of-thought tokEnization), a novel generative framework for multi-behavior
sequential recommendation. GRACE introduces a hybrid Chain-of-Thought (CoT)
tokenization method that encodes user-item interactions with explicit
attributes from product knowledge graphs (e.g., category, brand, price) over
semantic tokenization, enabling interpretable and behavior-aligned generation.
To address the inefficiency of standard attention, we design a Journey-Aware
Sparse Attention (JSA) mechanism, which selectively attends to compressed,
intra-, inter-, and current-context segments in the tokenized sequence.
Experiments on two real-world datasets show that GRACE significantly
outperforms state-of-the-art baselines, achieving up to +106.9% HR@10 and
+106.7% NDCG@10 improvement over the state-of-the-art baseline on the Home
domain, and +22.1% HR@10 on the Electronics domain. GRACE also reduces
attention computation by up to 48% with long sequences.

</details>


### [176] [FastLongSpeech: Enhancing Large Speech-Language Models for Efficient Long-Speech Processing](https://arxiv.org/abs/2507.14815)
*Shoutao Guo,Shaolei Zhang,Qingkai Fang,Zhengrui Ma,Min Zhang,Yang Feng*

Main category: cs.CL

TL;DR: FastLongSpeech是一个新框架，通过压缩和动态训练，使LSLM能高效处理长语音，无需额外数据，并在长短语音任务上表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有的LSLM在处理长语音方面存在效率低下和数据稀缺的问题，而FastLongSpeech旨在解决这些挑战。

Method: 提出了一种名为FastLongSpeech的新框架，该框架采用迭代融合策略压缩长语音序列，并通过动态压缩训练方法使LSLM适应长语音输入，无需专门的长语音训练数据。

Result: 实验结果表明，FastLongSpeech在长短语音任务上均取得了良好的性能，并显著提高了推理效率。

Conclusion: FastLongSpeech框架能够有效扩展大型语音语言模型（LSLM）处理长语音的能力，并提高推理效率，同时在长短语音任务上均表现出色。

Abstract: The rapid advancement of Large Language Models (LLMs) has spurred significant
progress in Large Speech-Language Models (LSLMs), enhancing their capabilities
in both speech understanding and generation. While existing LSLMs often
concentrate on augmenting speech generation or tackling a diverse array of
short-speech tasks, the efficient processing of long-form speech remains a
critical yet underexplored challenge. This gap is primarily attributed to the
scarcity of long-speech training datasets and the high computational costs
associated with long sequences. To address these limitations, we introduce
FastLongSpeech, a novel framework designed to extend LSLM capabilities for
efficient long-speech processing without necessitating dedicated long-speech
training data. FastLongSpeech incorporates an iterative fusion strategy that
can compress excessively long-speech sequences into manageable lengths. To
adapt LSLMs for long-speech inputs, it introduces a dynamic compression
training approach, which exposes the model to short-speech sequences at varying
compression ratios, thereby transferring the capabilities of LSLMs to
long-speech tasks. To assess the long-speech capabilities of LSLMs, we develop
a long-speech understanding benchmark called LongSpeech-Eval. Experiments show
that our method exhibits strong performance in both long-speech and
short-speech tasks, while greatly improving inference efficiency.

</details>


### [177] [Doc2Chart: Intent-Driven Zero-Shot Chart Generation from Documents](https://arxiv.org/abs/2507.14819)
*Akriti Jain,Pritika Ramu,Aparna Garimella,Apoorv Saxena*

Main category: cs.CL

TL;DR: 大型语言模型（LLM）虽然擅长将文本或表格转换为可视化图表，但在根据用户意图从长文档生成图表方面存在挑战。本研究提出了一个名为“基于意图的文档图表生成”的新任务，并开发了一个无监督、两阶段的框架，通过LLM提取信息和启发式方法选择图表类型来解决此问题。研究人员还提出了一个基于属性的指标来评估图表数据的准确性，并创建了一个新的数据集。实验结果表明，该方法在数据准确性和图表类型选择方面优于现有基线方法。


<details>
  <summary>Details</summary>
Motivation: 现有的文本到数据可视化方法难以直接应用于根据用户意图从长文档中生成可视化图表，因为用户通常需要手动选择相关内容。

Method: 该框架首先利用大型语言模型（LLM）从文档中提取信息，通过分解意图并迭代验证和优化数据。接着，一个启发式引导模块选择合适的图表类型，最后生成代码。

Result: 在金融和科学领域创建了一个包含1,242个<意图, 文档, 图表>元组的数据集。与基于LLM的单次生成和基于查询的检索方法相比，该方法在图表数据准确性和图表类型选择上分别提高了高达9个和17个百分点。

Conclusion: 该研究提出了一个名为“基于意图的文档图表生成”的新任务，并开发了一个无监督、两阶段的框架来解决它。该框架首先利用大型语言模型（LLM）从文档中提取信息，然后通过启发式方法选择图表类型并生成代码。

Abstract: Large Language Models (LLMs) have demonstrated strong capabilities in
transforming text descriptions or tables to data visualizations via
instruction-tuning methods. However, it is not straightforward to apply these
methods directly for a more real-world use case of visualizing data from long
documents based on user-given intents, as opposed to the user pre-selecting the
relevant content manually. We introduce the task of intent-based chart
generation from documents: given a user-specified intent and document(s), the
goal is to generate a chart adhering to the intent and grounded on the
document(s) in a zero-shot setting. We propose an unsupervised, two-staged
framework in which an LLM first extracts relevant information from the
document(s) by decomposing the intent and iteratively validates and refines
this data. Next, a heuristic-guided module selects an appropriate chart type
before final code generation. To assess the data accuracy of the generated
charts, we propose an attribution-based metric that uses a structured textual
representation of charts, instead of relying on visual decoding metrics that
often fail to capture the chart data effectively. To validate our approach, we
curate a dataset comprising of 1,242 $<$intent, document, charts$>$ tuples from
two domains, finance and scientific, in contrast to the existing datasets that
are largely limited to parallel text descriptions/ tables and their
corresponding charts. We compare our approach with baselines using single-shot
chart generation using LLMs and query-based retrieval methods; our method
outperforms by upto $9$ points and $17$ points in terms of chart data accuracy
and chart type respectively over the best baselines.

</details>


### [178] [Beyond Isolated Capabilities: Bridging Long CoT Reasoning and Long-Context Understanding](https://arxiv.org/abs/2507.14849)
*Yifei Wang*

Main category: cs.CL

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Reasoning distillation has emerged as an effective approach to enhance the
reasoning capabilities of smaller language models. However, the impact of
large-scale reasoning distillation on other critical abilities, particularly
in-context retrieval and reasoning, remains unexplored. This gap in
understanding is particularly significant given the increasing importance of
Retrieval-Augmented Generation (RAG) systems, where efficient acquisition and
utilization of contextual information are paramount for generating reliable
responses. Motivated by the need to understand how the extended long-CoT
process influences long-context comprehension, we conduct a comprehensive
investigation using a series of open-source models distilled from Deepseek-R1,
renowned for its exceptional reasoning capabilities. Our study focuses on
evaluating these models' performance in extracting and integrating relevant
information from extended contexts through multi-document question and
answering tasks. Through rigorous experimentation, we demonstrate that
distilled reasoning patterns significantly improve long-context understanding.
Our analysis reveals that distillation fosters greater long-context awareness
by promoting more detailed and explicit reasoning processes during context
analysis and information parsing. This advancement effectively mitigates the
persistent "lost in the middle" issue that has hindered long-context models.

</details>


### [179] [Tiny language models](https://arxiv.org/abs/2507.14871)
*Ronit D. Gross,Yarden Tzach,Tal Halevi,Ella Koresh,Ido Kanter*

Main category: cs.CL

TL;DR: Tiny language models (TLMs) show similar features to large language models (LLMs), with pre-training proving effective even at a small scale. This research opens up possibilities for more accessible NLP research and potential applications in language development.


<details>
  <summary>Details</summary>
Motivation: The motivation for this study was the immense computational resources required for LLM pre-training, which limits broader research participation. The study aimed to explore accessible alternatives by investigating whether tiny language models (TLMs) exhibit the same key qualitative features as LLMs.

Method: The study explored whether tiny language models (TLMs) exhibit the same key qualitative features as large language models (LLMs). The researchers pre-trained BERT-6 and variants of BERT-1 on subsets of the Wikipedia dataset and evaluated their performance on FewRel, AGNews, and DBPedia classification tasks. They also investigated whether a soft committee of multiple, independently pre-trained shallow architectures could replicate the classification accuracy of a pre-trained deep TLM architecture.

Result: TLMs exhibit a clear performance gap between pre-trained and non-pre-trained models across classification tasks, demonstrating the effectiveness of pre-training even at a tiny scale. The performance gap increases with the size of the pre-training dataset and with greater overlap between tokens in the pre-training and classification datasets. The classification accuracy achieved by a pre-trained deep TLM architecture can be replicated through a soft committee of multiple, independently pre-trained shallow architectures, enabling low-latency TLMs without affecting classification accuracy.

Conclusion: TLMs can exhibit the same key qualitative features as LLMs, and pre-training is effective even at a tiny scale. The performance gap between pre-trained and non-pre-trained models increases with the size of the pre-training dataset and the overlap between tokens in the pre-training and classification datasets. A pre-trained deep TLM architecture's classification accuracy can be replicated by a soft committee of multiple, independently pre-trained shallow architectures, enabling low-latency TLMs without affecting classification accuracy. Future research on TLMs may further illuminate the mechanisms underlying NLP, as biologically inspired models suggest TLMs may be sufficient for language development in children and adolescents.

Abstract: A prominent achievement of natural language processing (NLP) is its ability
to understand and generate meaningful human language. This capability relies on
complex feedforward transformer block architectures pre-trained on large
language models (LLMs). However, LLM pre-training is currently feasible only
for a few dominant companies due to the immense computational resources
required, limiting broader research participation. This creates a critical need
for more accessible alternatives. In this study, we explore whether tiny
language models (TLMs) exhibit the same key qualitative features of LLMs. We
demonstrate that TLMs exhibit a clear performance gap between pre-trained and
non-pre-trained models across classification tasks, indicating the
effectiveness of pre-training, even at a tiny scale. The performance gap
increases with the size of the pre-training dataset and with greater overlap
between tokens in the pre-training and classification datasets. Furthermore,
the classification accuracy achieved by a pre-trained deep TLM architecture can
be replicated through a soft committee of multiple, independently pre-trained
shallow architectures, enabling low-latency TLMs without affecting
classification accuracy. Our results are based on pre-training BERT-6 and
variants of BERT-1 on subsets of the Wikipedia dataset and evaluating their
performance on FewRel, AGNews, and DBPedia classification tasks. Future
research on TLM is expected to further illuminate the mechanisms underlying
NLP, especially given that its biologically inspired models suggest that TLMs
may be sufficient for children or adolescents to develop language.

</details>


### [180] [MEKiT: Multi-source Heterogeneous Knowledge Injection Method via Instruction Tuning for Emotion-Cause Pair Extraction](https://arxiv.org/abs/2507.14887)
*Shiyi Mu,Yongkang Liu,Shi Feng,Xiaocui Yang,Daling Wang,Yifei Zhang*

Main category: cs.CL

TL;DR: MEKiT 方法通过整合内部情感知识和外部因果知识，提高了大型语言模型在情感-原因对提取任务上的表现，解决了大型语言模型在需要推理能力的 ECPE 任务上表现不佳的问题。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLM）在文本理解和生成方面表现出色，但在需要推理能力的情感-原因对提取（ECPE）任务上的表现却常常不如较小的语言模型。主要原因是缺乏辅助知识，这限制了 LLM 有效感知情感和推理原因的能力。

Method: 提出了一种新颖的多源异构知识注入方法（MEKiT），该方法整合了异构的内部情感知识和外部因果知识。具体来说，对于这两种不同的知识方面和结构，我们应用了指令模板和混合数据进行指令调整的方法，分别促进 LLM 更全面地识别情感和准确地推理原因。

Result: 实验结果表明，MEKiT 为 ECPE 任务提供了一个更有效和适应性强的解决方案，与现有基线相比具有绝对的性能优势，并显著提高了 LLM 在 ECPE 任务上的性能。

Conclusion: MEKiT 为 ECPE 任务提供了一个更有效和适应性强的解决方案，与现有基线相比具有绝对的性能优势，并显著提高了 LLM 在 ECPE 任务上的性能。

Abstract: Although large language models (LLMs) excel in text comprehension and
generation, their performance on the Emotion-Cause Pair Extraction (ECPE) task,
which requires reasoning ability, is often underperform smaller language model.
The main reason is the lack of auxiliary knowledge, which limits LLMs' ability
to effectively perceive emotions and reason causes. To address this issue, we
propose a novel \textbf{M}ulti-source h\textbf{E}terogeneous \textbf{K}nowledge
\textbf{i}njection me\textbf{T}hod, MEKiT, which integrates heterogeneous
internal emotional knowledge and external causal knowledge. Specifically, for
these two distinct aspects and structures of knowledge, we apply the approaches
of incorporating instruction templates and mixing data for instruction-tuning,
which respectively facilitate LLMs in more comprehensively identifying emotion
and accurately reasoning causes. Experimental results demonstrate that MEKiT
provides a more effective and adaptable solution for the ECPE task, exhibiting
an absolute performance advantage over compared baselines and dramatically
improving the performance of LLMs on the ECPE task.

</details>


### [181] [Sparse Autoencoder-guided Supervised Finetuning to Mitigate Unexpected Code-Switching in LLMs](https://arxiv.org/abs/2507.14894)
*Boyi Deng,Yu Wan,Baosong Yang,Fei Huang,Wenjie Wang,Fuli Feng*

Main category: cs.CL

TL;DR: LLMs sometimes mix languages unexpectedly. We analyzed why (it's about feature pre-activation values) and created a new training method, SASFT, that fixes this by guiding those values. SASFT cuts down language mixing by over 50% without hurting the LLM's other skills.


<details>
  <summary>Details</summary>
Motivation: Existing LLMs suffer from unexpected code-switching, which degrades readability and usability. Current solutions lack mechanistic analysis and have limited effectiveness.

Method: Propose SASFT (Sparse Autoencoder-guided Supervised Fine-tuning), which trains LLMs to maintain appropriate pre-activation values of specific language features. This is based on an in-depth analysis using sparse autoencoders that found excessive pre-activation values in features of the language being switched to.

Result: SASFT reduces unexpected code-switching by over 50% (completely in 4/5 cases) and maintains/improves performance on multilingual benchmarks.

Conclusion: SASFT consistently reduces unexpected code-switching by more than 50% across five models and three languages, with complete elimination in four cases. It also maintains or improves performance on six multilingual benchmarks, effectively addressing code-switching while preserving multilingual capabilities.

Abstract: Large Language Models (LLMs) have impressive multilingual capabilities, but
they suffer from unexpected code-switching, also known as language mixing,
which involves switching to unexpected languages in the model response. This
problem leads to poor readability and degrades the usability of model
responses. However, existing work on this issue lacks a mechanistic analysis
and shows limited effectiveness. In this paper, we first provide an in-depth
analysis of unexpected code-switching using sparse autoencoders and find that
when LLMs switch to a language, the features of that language exhibit excessive
pre-activation values. Based on our findings, we propose $\textbf{S}$parse
$\textbf{A}$utoencoder-guided $\textbf{S}$upervised
$\textbf{F}$ine$\textbf{t}$uning (SASFT), which teaches LLMs to maintain
appropriate pre-activation values of specific language features during
training. Experiments on five models across three languages demonstrate that
SASFT consistently reduces unexpected code-switching by more than 50\% compared
to standard supervised fine-tuning, with complete elimination in four cases.
Moreover, SASFT maintains or even improves the models' performance on six
multilingual benchmarks, showing its effectiveness in addressing code-switching
while preserving multilingual capabilities.

</details>


### [182] [From Neurons to Semantics: Evaluating Cross-Linguistic Alignment Capabilities of Large Language Models via Neurons Alignment](https://arxiv.org/abs/2507.14900)
*Chongxuan Huang,Yongshi Ye,Biao Fu,Qifeng Su,Xiaodong Shi*

Main category: cs.CL

TL;DR: 提出了一种名为 NeuronXA 的新方法，用于评估大型语言模型 (LLM) 的跨语言对齐能力，该方法利用神经元状态来提供更具语义基础的评估。NeuronXA 在小数据集上也被证明是有效的，能够准确评估跨语言对齐和迁移能力。


<details>
  <summary>Details</summary>
Motivation: 现有评估跨语言对齐的方法主要集中在句子嵌入，但先前研究表明，神经模型倾向于诱导一个不平滑的表示空间，这会影响低资源语言的语义对齐评估。因此，需要一种新的方法来更准确地评估跨语言对齐。

Method: 提出了一种新颖的基于神经元状态的跨语言对齐 (NeuronXA) 方法，以评估 LLM 的跨语言对齐能力。该方法借鉴了神经科学的发现，即相似信息会激活重叠的神经元区域，从而提供一种更具语义基础的方法来评估跨语言对齐。

Result: 在多个著名的多语言 LLM（LLaMA、Qwen、Mistral、GLM 和 OLMo）以及两个迁移任务和三个多语言基准上评估了 NeuronXA。结果表明，仅使用 100 对平行句子，NeuronXA 在下游任务性能方面实现了 0.9556 的皮尔逊相关系数，在迁移性方面实现了 0.8514 的皮尔逊相关系数。

Conclusion: NeuronXA 在评估大型语言模型 (LLM) 的跨语言对齐和迁移能力方面是有效的，即使在小数据集上也是如此。这表明 NeuronXA 有潜力推动跨语言对齐研究，并提高多语言 LLM 的语义理解能力。

Abstract: Large language models (LLMs) have demonstrated remarkable multilingual
capabilities, however, how to evaluate cross-lingual alignment remains
underexplored. Existing alignment benchmarks primarily focus on sentence
embeddings, but prior research has shown that neural models tend to induce a
non-smooth representation space, which impact of semantic alignment evaluation
on low-resource languages. Inspired by neuroscientific findings that similar
information activates overlapping neuronal regions, we propose a novel Neuron
State-Based Cross-Lingual Alignment (NeuronXA) to assess the cross-lingual a
lignment capabilities of LLMs, which offers a more semantically grounded
approach to assess cross-lingual alignment. We evaluate NeuronXA on several
prominent multilingual LLMs (LLaMA, Qwen, Mistral, GLM, and OLMo) across two
transfer tasks and three multilingual benchmarks. The results demonstrate that
with only 100 parallel sentence pairs, NeuronXA achieves a Pearson correlation
of 0.9556 with downstream tasks performance and 0.8514 with transferability.
These findings demonstrate NeuronXA's effectiveness in assessing both
cross-lingual alignment and transferability, even with a small dataset. This
highlights its potential to advance cross-lingual alignment research and to
improve the semantic understanding of multilingual LLMs.

</details>


### [183] [PromptSuite: A Task-Agnostic Framework for Multi-Prompt Generation](https://arxiv.org/abs/2507.14913)
*Eliya Habba,Noam Dahan,Gili Lior,Gabriel Stanovsky*

Main category: cs.CL

TL;DR: Evaluating LLMs is hard with one prompt. PromptSuite makes many prompts automatically, making evaluations better. It's flexible, extensible, and has a Python API and web interface.


<details>
  <summary>Details</summary>
Motivation: Evaluating LLMs with a single prompt is unreliable due to sensitivity to small changes; generating prompt variations for robust multi-prompt evaluation is challenging, limiting its practical adoption.

Method: PromptSuite framework enables automatic generation of various prompts through a modular design and controlled perturbations to each component, supporting the addition of new components and perturbation types.

Result: Case studies demonstrate that PromptSuite provides meaningful variations that support strong evaluation practices for LLMs.

Conclusion: PromptSuite is a flexible and extensible framework for automatically generating diverse prompts, supporting more robust multi-prompt evaluations of LLMs.

Abstract: Evaluating LLMs with a single prompt has proven unreliable, with small
changes leading to significant performance differences. However, generating the
prompt variations needed for a more robust multi-prompt evaluation is
challenging, limiting its adoption in practice. To address this, we introduce
PromptSuite, a framework that enables the automatic generation of various
prompts. PromptSuite is flexible - working out of the box on a wide range of
tasks and benchmarks. It follows a modular prompt design, allowing controlled
perturbations to each component, and is extensible, supporting the addition of
new components and perturbation types. Through a series of case studies, we
show that PromptSuite provides meaningful variations to support strong
evaluation practices. It is available through both a Python API:
https://github.com/eliyahabba/PromptSuite, and a user-friendly web interface:
https://promptsuite.streamlit.app/

</details>


### [184] [SYNTHIA: Synthetic Yet Naturally Tailored Human-Inspired PersonAs](https://arxiv.org/abs/2507.14922)
*Vahid Rahimzadeh,Erfan Moosavi Monazzah,Mohammad Taher Pilehvar,Yadollah Yaghoobzadeh*

Main category: cs.CL

TL;DR: SYNTHIA是一个新数据集，包含30,000个来自真实社交媒体用户的背景故事，旨在提高面向个人的LLM的真实性和一致性，并在计算社会科学领域提供新的研究途径。


<details>
  <summary>Details</summary>
Motivation: 解决现有面向个人的大型语言模型（LLM）方法在成本高昂的人工策划数据或缺乏一致性和真实性的合成角色之间存在极端化的问题。

Method: SYNTHIA是一个包含30,000个背景故事的数据集，这些故事源自BlueSky开放平台上的10,000个真实社交媒体用户，跨越三个时间窗口。该方法通过将合成生成植根于真实的用戶活动来弥合现有方法在成本和真实性之间的差距。

Result: SYNTHIA在人口多样性和社会调查一致性方面取得了与最先进方法相当的性能，同时在叙事一致性方面显著优于它们。此外，SYNTHIA包含了时间维度和丰富的社交互动元数据，为计算社会科学和面向个人的语言建模开辟了新的研究方向。

Conclusion: SYNTHIA数据集通过结合真实用户活动和合成生成，在人口多样性和社会调查一致性方面达到了与最先进方法相媲美的性能，并在叙事一致性方面显著优于它们。

Abstract: Persona-driven LLMs have emerged as powerful tools in computational social
science, yet existing approaches fall at opposite extremes, either relying on
costly human-curated data or producing synthetic personas that lack consistency
and realism. We introduce SYNTHIA, a dataset of 30,000 backstories derived from
10,000 real social media users from BlueSky open platform across three time
windows, bridging this spectrum by grounding synthetic generation in authentic
user activity. Our evaluation demonstrates that SYNTHIA achieves competitive
performance with state-of-the-art methods in demographic diversity and social
survey alignment while significantly outperforming them in narrative
consistency. Uniquely, SYNTHIA incorporates temporal dimensionality and
provides rich social interaction metadata from the underlying network, enabling
new research directions in computational social science and persona-driven
language modeling.

</details>


### [185] [MUR: Momentum Uncertainty guided Reasoning for Large Language Models](https://arxiv.org/abs/2507.14958)
*Hang Yan,Fangzhi Xu,Rongman Xu,Yifei Li,Jian Zhang,Haoran Luo,Xiaobao Wu,Luu Anh Tuan,Haiteng Zhao,Qika Lin,Jun Liu*

Main category: cs.CL

TL;DR: MUR 是一种新的方法，通过追踪和整合逐步不确定性来优化 LLMs 的推理效率，在不增加训练的情况下，通过 gamma-control 调整计算预算，从而在减少计算的同时提高准确率。


<details>
  <summary>Details</summary>
Motivation: 为了解决大型语言模型（LLMs）在推理效率方面存在的优化挑战，特别是测试时推理（TTS）可能导致的过度思考和计算浪费。

Method: 提出了一种名为MUR（Momentum Uncertainty-guided Reasoning）的方法，通过跟踪和聚合逐步不确定性来动态分配思考预算到关键的推理步骤。引入了gamma-control机制，通过一个超参数来调整推理预算。

Result: MUR 在 MATH-500、AIME24、AIME25 和 GPQA-diamond 四个具有挑战性的基准测试中，相对于多种 TTS 方法，在不同大小的 Qwen3 模型（1.7B、4B 和 8B）上，平均减少了 50% 以上的计算量，同时提高了 0.62-3.37% 的准确率。

Conclusion: MUR通过减少50%的计算量并提高0.62-3.37%的准确率，在各种测试时推理方法和不同大小的模型上进行了全面评估。

Abstract: Large Language Models (LLMs) have achieved impressive performance on
reasoning-intensive tasks, yet optimizing their reasoning efficiency remains an
open challenge. While Test-Time Scaling (TTS) improves reasoning quality, it
often leads to overthinking, wasting tokens on redundant computations. This
work investigates how to efficiently and adaptively guide LLM test-time scaling
without additional training. Inspired by the concept of momentum in physics, we
propose Momentum Uncertainty-guided Reasoning (MUR), which dynamically
allocates thinking budgets to critical reasoning steps by tracking and
aggregating stepwise uncertainty over time. To support flexible inference-time
control, we introduce gamma-control, a simple mechanism that tunes the
reasoning budget via a single hyperparameter. We provide in-depth theoretical
proof to support the superiority of MUR in terms of stability and biases. MUR
is comprehensively evaluated against various TTS methods across four
challenging benchmarks (MATH-500, AIME24, AIME25, and GPQA-diamond) using
different sizes of recent Qwen3 models (1.7B, 4B, and 8B). Results demonstrate
that MUR reduces computation by over 50% on average while improving accuracy by
0.62-3.37%.

</details>


### [186] [RefCritic: Training Long Chain-of-Thought Critic Models with Refinement Feedback](https://arxiv.org/abs/2507.15024)
*Qiaoyu Tang,Hao Xiang,Le Yu,Bowen Yu,Hongyu Lin,Yaojie Lu,Xianpei Han,Le Sun,Junyang Lin*

Main category: cs.CL

TL;DR: RefCritic 是一种新颖的长链式思维批评模块，通过强化学习和双重奖励，有效提升了大型语言模型的批评能力和指导效果，超越了现有的监督微调方法。


<details>
  <summary>Details</summary>
Motivation: 目前，虽然大型语言模型（LLM）发展迅速，但开发用于精确指导的有效批评模块仍然具有挑战性。现有的监督微调方法未能真正提升模型的批评能力，产生的批评流于表面，缺乏充分的思考和验证。

Method: 提出了一种基于强化学习和双重基于规则的奖励（实例级解决方案判断的正确性；基于批评的策略模型改进准确性）的“长链式思维”批评模块RefCritic，以生成高质量、可操作的评估。

Result: RefCritic 在 Qwen2.5-14B-Instruct 和 DeepSeek-R1-Distill-Qwen-14B 模型上进行了评估，在批评和改进设置上展现出一致的优势，在AIME25上分别提高了6.8%和7.2%。使用 RefCritic 过滤的策略模型在多数投票下表现出优越的扩展性。在ProcessBench测试中，RefCritic 的表现优于基于步骤的监督方法。

Conclusion: RefCritic 在五个基准测试中，与当前广泛采用的监督微调方法相比，在批评和改进设置上始终具有优势，例如在AIME25上为相应的基线模型分别提高了6.8%和7.2%。此外，RefCritic 训练于解题级别的监督，但在识别数学推理错误步骤的基准测试ProcessBench上，其表现优于解题步骤级别的监督方法。

Abstract: With the rapid advancement of Large Language Models (LLMs), developing
effective critic modules for precise guidance has become crucial yet
challenging. In this paper, we initially demonstrate that supervised
fine-tuning for building critic modules (which is widely adopted in current
solutions) fails to genuinely enhance models' critique abilities, producing
superficial critiques with insufficient reflections and verifications. To
unlock the unprecedented critique capabilities, we propose RefCritic, a
long-chain-of-thought critic module based on reinforcement learning with dual
rule-based rewards: (1) instance-level correctness of solution judgments and
(2) refinement accuracies of the policy model based on critiques, aiming to
generate high-quality evaluations with actionable feedback that effectively
guides model refinement. We evaluate RefCritic on Qwen2.5-14B-Instruct and
DeepSeek-R1-Distill-Qwen-14B across five benchmarks. On critique and refinement
settings, RefCritic demonstrates consistent advantages across all benchmarks,
e.g., 6.8\% and 7.2\% gains on AIME25 for the respective base models. Notably,
under majority voting, policy models filtered by RefCritic show superior
scaling with increased voting numbers. Moreover, despite training on
solution-level supervision, RefCritic outperforms step-level supervised
approaches on ProcessBench, a benchmark to identify erroneous steps in
mathematical reasoning.

</details>


### [187] [WebShaper: Agentically Data Synthesizing via Information-Seeking Formalization](https://arxiv.org/abs/2507.15061)
*Zhengwei Tao,Jialong Wu,Wenbiao Yin,Junkai Zhang,Baixuan Li,Haiyang Shen,Kuan Li,Liwen Zhang,Xinyu Wang,Yong Jiang,Pengjun Xie,Fei Huang,Jingren Zhou*

Main category: cs.CL

TL;DR: WebShaper 通过形式化 IS 任务和使用代理 Expander 进行多步扩展来合成数据，解决了现有 IS 代理数据稀疏和结构不一致的问题，并在基准测试中取得了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的信息检索（IS）代理在训练数据方面存在不足，并且信息驱动范式可能导致信息结构、推理结构、问题和答案之间存在不一致性。

Method: 提出了一种名为 WebShaper 的形式化驱动的信息检索（IS）数据综合框架，该框架利用集合论对 IS 任务进行形式化，并通过知识投影（KP）操作组合来精确控制推理结构。在综合过程中，首先创建种子任务，然后使用多步扩展过程，其中代理 Expander 借助检索和验证工具根据形式化进行扩展，以生成更复杂的问题。

Result: WebShaper 框架能够系统地形式化 IS 任务，并通过多步扩展过程合成高质量的训练数据，从而提高了 IS 代理的性能。

Conclusion: 实验结果表明，WebShaper 在 GAIA 和 WebWalkerQA 基准测试中，在开源信息检索（IS）代理中取得了最先进的性能。

Abstract: The advent of Large Language Model (LLM)-powered agents has revolutionized
artificial intelligence by enabling solutions to complex, open-ended tasks
through web-based information-seeking (IS) capabilities. The scarcity of
high-quality training data has limited the development of IS agents. Existing
approaches typically adopt an information-driven paradigm that first collects
web data and then generates questions based on the retrieval. However, this may
lead to inconsistency between information structure and reasoning structure,
question and answer. To mitigate, we propose a formalization-driven IS data
synthesis framework WebShaper to construct a dataset. WebShaper systematically
formalizes IS tasks through set theory. Central to the formalization is the
concept of Knowledge Projections (KP), which enables precise control over
reasoning structure by KP operation compositions. During synthesis, we begin by
creating seed tasks, then use a multi-step expansion process. At each step, an
agentic Expander expands the current formal question more complex with
retrieval and validation tools based on our formalization. We train our model
on the synthesized dataset. Experiment results demonstrate that WebShaper
achieves state-of-the-art performance among open-sourced IS agents on GAIA and
WebWalkerQA benchmarks.

</details>


### [188] [Evaluation of Coding Schemes for Transformer-based Gene Sequence Modeling](https://arxiv.org/abs/2507.15087)
*Chenlei Gong,Yuanhe Tian,Lei Mao,Yan Song*

Main category: cs.CL

TL;DR: 本研究系统性地评估了 DNA Transformer 中不同的序列分割和位置编码方法。结果表明，BPE 切词在大多数情况下优于 k-mer，RoPE 在长序列和周期性基序方面表现突出。增加模型深度至 12 层可显著提升性能。


<details>
  <summary>Details</summary>
Motivation: 为了系统性地评估在 DNA Transformer 模型中，固定长度的 k-mer 序列分割和 BPE 子词切词哪种方法更优越。

Method: 本研究比较了 k-mer 序列分割（k=1, 3, 4, 5, 6）、4096 词汇量的 BPE 子词切词、以及三种位置编码方法（sinusoidal, AliBi, RoPE）。在 GUE benchmark 数据集上，对从头训练的 3, 6, 12, 24 层 Transformer 编码器进行了评估。

Result: BPE 在 GUE benchmark 数据集上提供了更高且更稳定的性能。RoPE 在捕捉周期性基序和外推到长序列方面表现最佳，AliBi 在局部依赖性任务上也表现良好。模型性能随层数的增加而提升，在 12 层时达到最佳，24 层时提升边际化。

Conclusion: BPE 在压缩频繁的基序（motifs）、减少序列长度和提高模型泛化能力方面表现出更优越和稳定的性能。RoPE 在捕获周期性基序和外推到长序列方面表现出色，而 AliBi 在处理局部依赖性任务方面表现良好。增加 Transformer 层数从 3 层到 12 层可以带来显著的性能提升，而增加到 24 层则提升边际或出现轻微过拟合。

Abstract: Currently, many studies view DNA sequences as a special type of language and
utilize Transformers to model them. These studies use fixed-length k-mer
segmentation and BPE subword tokenization but lack a systematic evaluation to
determine which is superior. We compare k-mer segmentation with k=1,3,4,5,6, a
4,096-token BPE vocabulary, and three positional encoding methods-sinusoidal,
AliBi, and RoPE. Each configuration is trained from scratch in 3, 6, 12, and
24-layer Transformer encoders and evaluated on GUE benchmark dataset. In
general, BPE delivers higher and more stable performance across tasks by
compressing frequent motifs into variable-length tokens, reducing sequence
length, and improving model generalization. RoPE excels at capturing periodic
motifs and extrapolating to long sequences, while AliBi also performs well on
tasks driven by local dependencies. In terms of depth, we observe significant
gains when increasing layers from 3 to 12, with only marginal improvements or
slight overfitting at 24 layers. This study provides practical guidance for
designing tokenization and positional encoding in DNA Transformer models.

</details>


### [189] [A Penalty Goes a Long Way: Measuring Lexical Diversity in Synthetic Texts Under Prompt-Influenced Length Variations](https://arxiv.org/abs/2507.15092)
*Vijeta Deshpande,Ishita Dasgupta,Uttaran Bhattacharya,Somdeb Sarkhel,Saayan Mitra,Anna Rumshisky*

Main category: cs.CL

TL;DR: 该研究提出了PATTR，一种能克服文本长度偏差的新型多样性度量指标，适用于LLM合成数据评估。


<details>
  <summary>Details</summary>
Motivation: 当前的LLM研究中，用于进一步训练和改进LLM的合成文本多样性至关重要，但提示工程在提高多样性方面的具体影响，尤其是在响应文本长度和词汇多样性测量方面的影响，尚待深入研究。

Method: 提出了一种名为PATTR（Penalty-Adjusted Type-Token Ratio）的新型词汇多样性度量方法，并使用LLaMA、OLMo和Phi系列中的七种模型生成了超过2000万词的合成语料库，专注于视频脚本生成这一需要高多样性的创意写作任务。

Result: 通过对生成的2000万词语料库进行评估，发现现有的多样性度量指标（如MATTR和CR）在面对文本长度变化时存在偏差，倾向于偏爱较短的响应。而PATTR通过明确考虑任务目标响应长度（LT），有效减轻了这种长度偏差，并在筛选多样化响应方面表现优于MATTR和CR。

Conclusion: 该研究提出了PATTR（Penalty-Adjusted Type-Token Ratio）作为一种新的词汇多样性度量标准，该标准能够有效缓解文本长度变化带来的偏差，并通过实验证明了其在评估和筛选多样化文本方面的优越性。

Abstract: Synthetic text generated by Large Language Models (LLMs) is increasingly used
for further training and improvement of LLMs. Diversity is crucial for the
effectiveness of synthetic data, and researchers rely on prompt engineering to
improve diversity. However, the impact of prompt variations on response text
length, and, more importantly, the consequential effect on lexical diversity
measurements, remain underexplored. In this work, we propose Penalty-Adjusted
Type-Token Ratio (PATTR), a diversity metric robust to length variations. We
generate a large synthetic corpus of over 20M words using seven models from the
LLaMA, OLMo, and Phi families, focusing on a creative writing task of video
script generation, where diversity is crucial. We evaluate per-response lexical
diversity using PATTR and compare it against existing metrics of Moving-Average
TTR (MATTR) and Compression Ratio (CR). Our analysis highlights how text length
variations introduce biases favoring shorter responses. Unlike existing
metrics, PATTR explicitly considers the task-specific target response length
($L_T$) to effectively mitigate length biases. We further demonstrate the
utility of PATTR in filtering the top-10/100/1,000 most lexically diverse
responses, showing that it consistently outperforms MATTR and CR by yielding on
par or better diversity with high adherence to $L_T$.

</details>


### [190] [Filling the Gap: Is Commonsense Knowledge Generation useful for Natural Language Inference?](https://arxiv.org/abs/2507.15100)
*Chathuri Jayaweera,Brianna Yanqui,Bonnie Dorr*

Main category: cs.CL

TL;DR: 大型语言模型可以作为常识知识生成器来增强自然语言推断（NLI）任务，但其影响因情况而异。


<details>
  <summary>Details</summary>
Motivation: 自然语言推断（NLI）旨在开发能够模拟在推理过程中起重要作用的常识知识的系统。然而，现有的常识资源在覆盖各种前提-假设对方面存在不足。

Method: 本研究探索了大型语言模型作为NLI的常识知识生成器的潜力，重点关注其生成此类知识的可靠性以及这些知识对预测准确性的影响。我们调整并修改了现有指标，以评估LLM在此背景下生成常识知识的事实性和一致性。

Result: 虽然显式地结合常识知识并不总能提高整体结果，但它能有效地帮助区分蕴含关系实例，并适度改善区分矛盾和中立推断的效果。

Conclusion: 虽然显式地结合常识知识并不总能提高整体结果，但它能有效地帮助区分蕴含关系实例，并适度改善区分矛盾和中立推断的效果。

Abstract: Natural Language Inference (NLI) is the task of determining the semantic
entailment of a premise for a given hypothesis. The task aims to develop
systems that emulate natural human inferential processes where commonsense
knowledge plays a major role. However, existing commonsense resources lack
sufficient coverage for a variety of premise-hypothesis pairs. This study
explores the potential of Large Language Models as commonsense knowledge
generators for NLI along two key dimensions: their reliability in generating
such knowledge and the impact of that knowledge on prediction accuracy. We
adapt and modify existing metrics to assess LLM factuality and consistency in
generating in this context. While explicitly incorporating commonsense
knowledge does not consistently improve overall results, it effectively helps
distinguish entailing instances and moderately improves distinguishing
contradictory and neutral inferences.

</details>


### [191] [From Disagreement to Understanding: The Case for Ambiguity Detection in NLI](https://arxiv.org/abs/2507.15114)
*Chathuri Jayaweera,Bonnie Dorr*

Main category: cs.CL

TL;DR: 这项工作认为，自然语言推断中的注释分歧反映了有意义的解释差异，尤其是在由前提或假设中的歧义触发时。它呼吁通过系统地识别歧义输入对和分类歧义类型来转向歧义感知的自然语言推断。


<details>
  <summary>Details</summary>
Motivation: 争辩自然语言推断中的注释分歧不仅仅是噪音，它通常反映了有意义的解释差异，这促使人们需要有针对性的检测方法，使模型与人类的解释更好地对齐。

Method: 提出一个统一的框架，整合现有的分类法，并通过具体示例说明关键的歧义子类型，以识别模糊的输入对并对歧义类型进行分类。

Result: 展示了歧义如何影响注释者的决策，并强调了对更好的人类对齐自然语言推断系统的需求。

Conclusion: 需要新的带有关注意力和子类型注释的数据集，以及用于注意检测的无监督方法，以构建更健壮、可解释和人类对齐的自然语言推断系统。

Abstract: This position paper argues that annotation disagreement in Natural Language
Inference (NLI) is not mere noise but often reflects meaningful interpretive
variation, especially when triggered by ambiguity in the premise or hypothesis.
While underspecified guidelines and annotator behavior can contribute to
variation, content-based ambiguity offers a process-independent signal of
divergent human perspectives. We call for a shift toward ambiguity-aware NLI by
systematically identifying ambiguous input pairs and classifying ambiguity
types. To support this, we present a unified framework that integrates existing
taxonomies and illustrate key ambiguity subtypes through concrete examples.
These examples reveal how ambiguity shapes annotator decisions and motivate the
need for targeted detection methods that better align models with human
interpretation. A key limitation is the lack of datasets annotated for
ambiguity and subtypes. We propose addressing this gap through new annotated
resources and unsupervised approaches to ambiguity detection -- paving the way
for more robust, explainable, and human-aligned NLI systems.

</details>


### [192] [A Case Against Implicit Standards: Homophone Normalization in Machine Translation for Languages that use the Ge'ez Script](https://arxiv.org/abs/2507.15142)
*Hellina Hailu Nigatu,Atnafu Lambebo Tonja,Henok Biadglign Ademtew,Hizkel Mitiku Alemayehu,Negasi Haile Abadi,Tadesse Destaw Belay,Seid Muhie Yimam*

Main category: cs.CL

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Homophone normalization, where characters that have the same sound in a
writing script are mapped to one character, is a pre-processing step applied in
Amharic Natural Language Processing (NLP) literature. While this may improve
performance reported by automatic metrics, it also results in models that are
not able to understand different forms of writing in a single language.
Further, there might be impacts in transfer learning, where models trained on
normalized data do not generalize well to other languages. In this paper, we
experiment with monolingual training and cross-lingual transfer to understand
the impacts of normalization on languages that use the Ge'ez script. We then
propose a post-inference intervention in which normalization is applied to
model predictions instead of training data. With our simple scheme of
post-inference normalization, we show that we can achieve an increase in BLEU
score of up to 1.03 while preserving language features in training. Our work
contributes to the broader discussion on technology-facilitated language change
and calls for more language-aware interventions.

</details>


### [193] [What Level of Automation is "Good Enough"? A Benchmark of Large Language Models for Meta-Analysis Data Extraction](https://arxiv.org/abs/2507.15152)
*Lingbo Li,Anuradha Mathrani,Teo Susnjak*

Main category: cs.CL

TL;DR: 本研究评估了三种语言模型（Gemini-2.0-flash、Grok-3、GPT-4o-mini）在从随机对照试验（RCT）中提取数据以进行荟萃分析的性能。研究发现，定制化提示可提高召回率，并提出了一套用于数据提取的指南，以平衡自动化和专家监督。


<details>
  <summary>Details</summary>
Motivation: 从全文本随机对照试验（RCT）中自动提取用于荟萃分析的数据仍然是一个重大挑战。

Method: 本研究评估了三种语言模型（Gemini-2.0-flash、Grok-3、GPT-4o-mini）在提取统计结果、偏倚风险评估和研究特征方面的实际表现。研究测试了四种不同的提示策略（基本提示、自省提示、模型集成和定制化提示），以提高提取质量。

Result: 所有模型都表现出高精度，但在召回率方面持续存在不足，遗漏了关键信息。研究发现，定制化提示最有效，召回率最高可提高15%。

Conclusion: 本研究提出了一套三层指南，用于在使用语言模型（LLM）进行数据提取时，根据任务复杂性和风险，将数据类型与适当的自动化水平相匹配。研究结果为在实际的荟萃分析中自动提取数据提供了实用的建议，通过有针对性的、任务特定的自动化来平衡LLM的效率和专家监督。

Abstract: Automating data extraction from full-text randomised controlled trials (RCTs)
for meta-analysis remains a significant challenge. This study evaluates the
practical performance of three LLMs (Gemini-2.0-flash, Grok-3, GPT-4o-mini)
across tasks involving statistical results, risk-of-bias assessments, and
study-level characteristics in three medical domains: hypertension, diabetes,
and orthopaedics. We tested four distinct prompting strategies (basic
prompting, self-reflective prompting, model ensemble, and customised prompts)
to determine how to improve extraction quality. All models demonstrate high
precision but consistently suffer from poor recall by omitting key information.
We found that customised prompts were the most effective, boosting recall by up
to 15\%. Based on this analysis, we propose a three-tiered set of guidelines
for using LLMs in data extraction, matching data types to appropriate levels of
automation based on task complexity and risk. Our study offers practical advice
for automating data extraction in real-world meta-analyses, balancing LLM
efficiency with expert oversight through targeted, task-specific automation.

</details>


### [194] [Collaborative Distillation Strategies for Parameter-Efficient Language Model Deployment](https://arxiv.org/abs/2507.15198)
*Xiandong Meng,Yan Wu,Yexin Tian,Xin Hu,Tianze Kang,Junliang Du*

Main category: cs.CL

TL;DR: 通过多教师知识蒸馏，在压缩大模型的同时提升其性能。


<details>
  <summary>Details</summary>
Motivation: 为了解决部署大型语言模型时的高计算成本和推理速度慢的挑战。

Method: 提出了一种由多个教师模型指导的蒸馏策略，通过整合多个教师模型的输出概率分布和中间语义特征来指导学生模型学习。具体包含加权输出融合机制、特征对齐损失函数以及熵驱动动态教师加权策略。

Result: 学生模型在保持较小参数量的同时，获得了更强的语言理解和生成能力，在语言建模、文本生成和多任务学习等任务上表现出高一致性、泛化能力和任务适应性。与现有蒸馏方法相比，在困惑度、蒸馏损失和生成质量方面均显示出优势。

Conclusion: 本研究为大语言模型的高效压缩提供了可行的技术路径，并证明了多教师协作机制在复杂语言建模任务中的有效性。

Abstract: This paper addresses the challenges of high computational cost and slow
inference in deploying large language models. It proposes a distillation
strategy guided by multiple teacher models. The method constructs several
teacher models and integrates their output probability distributions and
intermediate semantic features. This guides the student model to learn from
multiple sources of knowledge. As a result, the student model gains stronger
language understanding and generation ability while maintaining a small
parameter size. To achieve this, the paper introduces a weighted output fusion
mechanism, a feature alignment loss function, and an entropy-driven dynamic
teacher weighting strategy. These components improve the quality and stability
of knowledge transfer during distillation. Under multi-teacher guidance, the
student model captures semantic information more effectively and demonstrates
strong performance across multiple evaluation metrics. In particular, the
method shows high consistency in expression, generalization ability, and task
adaptability in tasks such as language modeling, text generation, and
multi-task learning. The experiments compare the proposed method with several
widely adopted distillation approaches. The results further confirm its overall
advantages in perplexity, distillation loss, and generation quality. This study
provides a feasible technical path for the efficient compression of large-scale
language models. It also demonstrates the effectiveness of multi-teacher
collaborative mechanisms in complex language modeling tasks.

</details>


### [195] [SOI Matters: Analyzing Multi-Setting Training Dynamics in Pretrained Language Models via Subsets of Interest](https://arxiv.org/abs/2507.15236)
*Shayan Vassef,Amirhossein Dabiriaghdam,Mohammadreza Bakhtiari,Yadollah Yaghoobzadeh*

Main category: cs.CL

TL;DR: 本研究引入SOI分类框架，分析多任务、多源、多语言学习对预训练语言模型的影响。发现多源学习显著提升分布外性能，多任务学习在相似任务上有增益。提出两阶段微调方法，进一步优化模型性能。


<details>
  <summary>Details</summary>
Motivation: 为了增强对预训练语言模型鲁棒性和性能的分析，该研究引入了SOI（Subsets of Interest）这一新颖的分类框架，旨在识别和理解模型在训练过程中学习行为的模式。

Method: 通过引入SOI（Subsets of Interest）新分类框架，识别出六种不同的训练行为模式，包括易忘示例、未学示例和一直正确示例。利用SOI转换热图和数据集制图可视化技术，分析了从单一设置到多重设置配置的示例迁移过程。进行了三组平行比较实验：多任务与单任务学习（英语任务）、多源与单源学习（情感分析数据集）、多语言与单语言学习（法语、英语、波斯语的意图分类）。

Result: 多源学习能持续提升高达7%的分布外性能，而多任务学习在相似任务组合中表现出显著提升，但结果喜忧参半。SOI转换热图和数据集制图可视化技术揭示了示例在不同设置间的迁移模式。

Conclusion: 多源学习能持续提升高达7%的分布外性能，而多任务学习在相似任务组合中表现出显著提升，但结果喜忧参半。通过引入基于SOI（Subsets of Interest）的子集选择的两阶段微调方法，可以进一步提升模型性能。

Abstract: This work investigates the impact of multi-task, multi-lingual, and
multi-source learning approaches on the robustness and performance of
pretrained language models. To enhance this analysis, we introduce Subsets of
Interest (SOI), a novel categorization framework that identifies six distinct
learning behavior patterns during training, including forgettable examples,
unlearned examples, and always correct examples. Through SOI transition
heatmaps and dataset cartography visualization, we analyze how examples shift
between these categories when transitioning from single-setting to
multi-setting configurations. We perform comprehensive experiments across three
parallel comparisons: multi-task vs. single-task learning using English tasks
(entailment, paraphrase, sentiment), multi-source vs. single-source learning
using sentiment analysis datasets, and multi-lingual vs. single-lingual
learning using intent classification in French, English, and Persian. Our
results demonstrate that multi-source learning consistently improves
out-of-distribution performance by up to 7%, while multi-task learning shows
mixed results with notable gains in similar task combinations. We further
introduce a two-stage fine-tuning approach where the second stage leverages
SOI-based subset selection to achieve additional performance improvements.
These findings provide new insights into training dynamics and offer practical
approaches for optimizing multi-setting language model performance.

</details>


### [196] [ChiMed 2.0: Advancing Chinese Medical Dataset in Facilitating Large Language Modeling](https://arxiv.org/abs/2507.15275)
*Yuanhe Tian,Junjie Liu,Zhizhou Kou,Yuxiang Li,Yan Song*

Main category: cs.CL

TL;DR: ChiMed 2.0 是一个包含 2.044 亿字符的大规模中文医疗数据集，用于预训练、SFT 和 RLHF，旨在提升中文医疗大模型的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的中文医疗数据集在规模和领域覆盖方面存在不足，无法满足有效预训练的需求。此外，大多数数据集仅支持 LLM 微调，不支持预训练和 RLHF。

Method: 构建了一个名为 ChiMed 2.0 的中文医疗数据集，其中包含来自中文在线医疗平台的数据和由大语言模型生成的数据。该数据集包含 2.044 亿中文字符，涵盖了传统中医药经典和现代综合医疗数据。数据集包括 164.8K 个用于预训练的文档，351.6K 个用于监督微调（SFT）的问答对，以及 41.7K 个用于人类反馈强化学习（RLHF）的偏好数据元组。通过在代表性通用大模型上进行进一步预训练、SFT 和 RLHF 实验，并在医疗基准数据集上进行评估，证明了该数据集的有效性。

Result: 在代表性通用大模型上进行预训练、SFT 和 RLHF 实验，并在医疗基准数据集上进行评估，结果表明 ChiMed 2.0 数据集在不同规模的模型上均能带来性能提升。

Conclusion: ChiMed 2.0 的有效性和适用性得到了验证，能够提升中文医疗大模型的性能。

Abstract: Building high-quality data resources is crucial for advancing artificial
intelligence research and applications in specific domains, particularly in the
Chinese medical domain. Existing Chinese medical datasets are limited in size
and narrow in domain coverage, falling short of the diverse corpora required
for effective pre-training. Moreover, most datasets are designed solely for LLM
fine-tuning and do not support pre-training and reinforcement learning from
human feedback (RLHF). In this paper, we propose a Chinese medical dataset
named ChiMed 2.0, which extends our previous work ChiMed, and covers data
collected from Chinese medical online platforms and generated by LLMs. ChiMed
2.0 contains 204.4M Chinese characters covering both traditional Chinese
medicine classics and modern general medical data, where there are 164.8K
documents for pre-training, 351.6K question-answering pairs for supervised
fine-tuning (SFT), and 41.7K preference data tuples for RLHF. To validate the
effectiveness of our approach for training a Chinese medical LLM, we conduct
further pre-training, SFT, and RLHF experiments on representative general
domain LLMs and evaluate their performance on medical benchmark datasets. The
results show performance gains across different model scales, validating the
dataset's effectiveness and applicability.

</details>


### [197] [A Novel Self-Evolution Framework for Large Language Models](https://arxiv.org/abs/2507.15281)
*Haoran Sun,Zekun Zhang,Shaoning Zeng*

Main category: cs.CL

TL;DR: DPSE框架通过Censor模块提取信号，扩展数据，并进行两阶段微调，以提升LLM的用户对齐性和领域能力。


<details>
  <summary>Details</summary>
Motivation: 现有的LLM优化策略（如基于记忆的检索或偏好优化）在提升用户对齐性方面存在不足，未能增强模型在特定领域的认知能力，因此需要一种新的方法来同时提升用户偏好适应和领域特定能力。

Method: DPSE框架通过引入Censor模块提取多维度交互信号并估计满意度分数，利用话题感知和偏好驱动的策略进行结构化数据扩展，并通过两阶段的微调流程（监督领域学习和频率感知偏好优化）来协同优化用户偏好适应和领域特定能力。

Result: DPSE框架在通用NLP基准和长期对话任务上表现优于监督微调、偏好优化和记忆增强基线模型。

Conclusion: DPSE框架为大型语言模型提供了自主持续进化的途径。

Abstract: The capabilities of Large Language Models (LLMs) are limited to some extent
by pre-training, so some researchers optimize LLMs through post-training.
Existing post-training strategies, such as memory-based retrieval or preference
optimization, improve user alignment yet fail to enhance the model's domain
cognition. To bridge this gap, we propose a novel Dual-Phase Self-Evolution
(DPSE) framework that jointly optimizes user preference adaptation and
domain-specific competence. DPSE introduces a Censor module to extract
multi-dimensional interaction signals and estimate satisfaction scores, which
guide structured data expansion via topic-aware and preference-driven
strategies. These expanded datasets support a two-stage fine-tuning pipeline:
supervised domain grounding followed by frequency-aware preference
optimization. Experiments across general NLP benchmarks and long-term dialogue
tasks demonstrate that DPSE consistently outperforms Supervised Fine-Tuning,
Preference Optimization, and Memory-Augmented baselines. Ablation studies
validate the contribution of each module. In this way, our framework provides
an autonomous path toward continual self-evolution of LLMs.

</details>


### [198] [Beyond Easy Wins: A Text Hardness-Aware Benchmark for LLM-generated Text Detection](https://arxiv.org/abs/2507.15286)
*Navid Ayoobi,Sadat Shahriar,Arjun Mukherjee*

Main category: cs.CL

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: We present a novel evaluation paradigm for AI text detectors that prioritizes
real-world and equitable assessment. Current approaches predominantly report
conventional metrics like AUROC, overlooking that even modest false positive
rates constitute a critical impediment to practical deployment of detection
systems. Furthermore, real-world deployment necessitates predetermined
threshold configuration, making detector stability (i.e. the maintenance of
consistent performance across diverse domains and adversarial scenarios), a
critical factor. These aspects have been largely ignored in previous research
and benchmarks. Our benchmark, SHIELD, addresses these limitations by
integrating both reliability and stability factors into a unified evaluation
metric designed for practical assessment. Furthermore, we develop a post-hoc,
model-agnostic humanification framework that modifies AI text to more closely
resemble human authorship, incorporating a controllable hardness parameter.
This hardness-aware approach effectively challenges current SOTA zero-shot
detection methods in maintaining both reliability and stability. (Data and
code: https://github.com/navid-aub/SHIELD-Benchmark)

</details>


### [199] [On the Inevitability of Left-Leaning Political Bias in Aligned Language Models](https://arxiv.org/abs/2507.15328)
*Thilo Hagendorff*

Main category: cs.CL

TL;DR: AI对齐的目标（无害、有益、诚实）必然导致左翼政治偏见，因为对齐目标与进步的道德框架和左翼原则一致。将这种偏见视为风险的研究实际上是在反对AI对齐。


<details>
  <summary>Details</summary>
Motivation: 研究AI对齐（HHH原则）与LLM存在的左翼政治偏见之间的关系，并探讨为何对齐目标必然导致左翼偏见，以及现有研究如何错误地将这种偏见视为风险。

Method: 本文通过论证AI对齐的目标与进步道德框架和左翼原则的一致性，以及这些原则与右翼意识形态的冲突，来阐述其观点。

Result: AI对齐的目标必然导致左翼政治偏见；将LLM的左倾偏见视为风险的研究实际上是在反对AI对齐。

Conclusion: AI对齐的目标（无害、有益、诚实）必然导致左翼政治偏见，因为对齐目标所依据的规范性假设与进步的道德框架和左翼原则（如避免伤害、包容性、公平性和实证真实性）相一致。研究LLM政治偏见的研究将左倾趋势视为风险或问题，这实际上是在反对AI对齐，并默许违反HHH原则。

Abstract: The guiding principle of AI alignment is to train large language models
(LLMs) to be harmless, helpful, and honest (HHH). At the same time, there are
mounting concerns that LLMs exhibit a left-wing political bias. Yet, the
commitment to AI alignment cannot be harmonized with the latter critique. In
this article, I argue that intelligent systems that are trained to be harmless
and honest must necessarily exhibit left-wing political bias. Normative
assumptions underlying alignment objectives inherently concur with progressive
moral frameworks and left-wing principles, emphasizing harm avoidance,
inclusivity, fairness, and empirical truthfulness. Conversely, right-wing
ideologies often conflict with alignment guidelines. Yet, research on political
bias in LLMs is consistently framing its insights about left-leaning tendencies
as a risk, as problematic, or concerning. This way, researchers are actively
arguing against AI alignment, tacitly fostering the violation of HHH
principles.

</details>


### [200] [Reasoning Models are Test Exploiters: Rethinking Multiple-Choice](https://arxiv.org/abs/2507.15337)
*Narun Raman,Taylor Lundy,Kevin Leyton-Brown*

Main category: cs.CL

TL;DR: MCQA作为LLM评估基准可能不再可靠。允许模型在看到选项后进行推理会夸大其表现，因为模型会利用选项中的信息。研究建议设计新的基准来更准确地评估LLM的推理能力。


<details>
  <summary>Details</summary>
Motivation: 研究人员旨在调查在评估大型语言模型（LLM）在问答领域的表现时，多项选择题问答（MCQA）作为下游任务代理的有效性，特别是在面对最先进的推理模型时。

Method: 本研究系统评估了15个不同的问答基准和25种不同的LLM，并考虑了5种不同的问题呈现方式，包括是否提供选项、是否包含“以上皆无”选项以及是否允许模型在呈现选项前后进行链式思考。

Result: 在模型被允许在选项呈现之前进行链式思考的情况下，MCQA仍然是模型下游性能的一个良好代理。然而，允许模型在看到选项后进行推理的大型模型，由于利用了选项中的信息，其表现会显著优于其自由文本表现。

Conclusion: 多项选择题问答（MCQA）不再是评估最先进模型下游性能的良好代理。当模型在被提供选择项之前被允许进行链式思考时，MCQA仍然可以作为下游性能的一个好代理。然而，允许模型在看到选项后进行推理的大型模型，由于利用了选项中的信息，其表现会显著优于其自由文本表现。

Abstract: When evaluating Large Language Models (LLMs) in question-answering domains,
it is common to ask the model to choose among a fixed set of choices (so-called
multiple-choice question-answering, or MCQA). Although downstream tasks of
interest typically do not provide systems with explicit options among which to
choose, this approach is nevertheless widely used because it makes it makes
automatic grading straightforward and has tended to produce challenging
benchmarks that correlate sufficiently well with downstream performance. This
paper investigates the extent to which this trend continues to hold for
state-of-the-art reasoning models, describing a systematic evaluation of $15$
different question-answering benchmarks (e.g., MMLU, HLE) and $25$ different
LLMs (including small models such as Qwen 7B and relatively large models such
as Llama 70B). For each model-benchmark pair, we considered $5$ ways of
presenting the model with questions, including variations on whether multiple
choices were offered to the model at all; whether "none of the above" sometimes
replaced the right answer; and whether the model was permitted to perform
chain-of-thought reasoning before and/or after the choices were presented. MCQA
remained a good proxy for the downstream performance of models as long as they
were allowed to perform chain-of-thought reasoning only before being presented
with the options among which they had to select. On the other hand, large
models that were able to perform reasoning after being given a set of options
tended to significantly outperform their free-text performance due to
exploiting the information in the options. We conclude that MCQA is no longer a
good proxy for assessing downstream performance of state-of-the-art models, and
offer practical guidelines for designing more robust, bias-resistant benchmarks
that better reflect LLMs' genuine reasoning capabilities.

</details>


### [201] [LionGuard 2: Building Lightweight, Data-Efficient & Localised Multilingual Content Moderators](https://arxiv.org/abs/2507.15339)
*Leanne Tan,Gabriel Chua,Ziyu Ge,Roy Ka-Wei Lee*

Main category: cs.CL

TL;DR: LionGuard 2 是一个轻量级、多语言的内容审核分类器，专为新加坡设计，支持多种语言，表现优于现有系统，并已成功部署。


<details>
  <summary>Details</summary>
Motivation: 现代内容审核系统需要支持多种语言，但现有系统在处理本地化和低资源语言变体时常有不足，导致在实际应用中存在安全隐患。

Method: LionGuard 2 基于预训练的 OpenAI 嵌入和多头序数分类器构建，是一个轻量级的、多语言的内容审核分类器。

Result: LionGuard 2 在包括新加坡本地和公开的英语数据集在内的 17 个基准测试中，表现优于多个商业和开源系统，并已在新加坡政府内部署并大规模应用，证明了其在实际中的有效性。

Conclusion: 现代内容审核系统需要支持多种语言，但现有系统在处理本地化和低资源语言变体时常有不足，导致在实际应用中存在安全隐患。LionGuard 2 是一个轻量级的、多语言的内容审核分类器，专为新加坡的实际需求设计，支持英语、中文、马来语和部分泰米尔语。该系统基于预训练的 OpenAI 嵌入和多头序数分类器构建，在包括新加坡本地和公开的英语数据集在内的 17 个基准测试中，表现优于多个商业和开源系统。LionGuard 2 已在新加坡政府内部署并大规模应用，证明了其在实际中的有效性。研究结果表明，高质量的本地数据和强大的多语言嵌入可以在不微调大型模型的情况下实现强大的审核性能。我们公开了模型权重和部分训练数据，以支持未来在大型语言模型安全方面的研究。

Abstract: Modern moderation systems increasingly support multiple languages, but often
fail to address localisation and low-resource variants - creating safety gaps
in real-world deployments. Small models offer a potential alternative to large
LLMs, yet still demand considerable data and compute. We present LionGuard 2, a
lightweight, multilingual moderation classifier tailored to the Singapore
context, supporting English, Chinese, Malay, and partial Tamil. Built on
pre-trained OpenAI embeddings and a multi-head ordinal classifier, LionGuard 2
outperforms several commercial and open-source systems across 17 benchmarks,
including both Singapore-specific and public English datasets. The system is
actively deployed within the Singapore Government, demonstrating practical
efficacy at scale. Our findings show that high-quality local data and robust
multilingual embeddings can achieve strong moderation performance, without
fine-tuning large models. We release our model weights and part of our training
data to support future work on LLM safety.

</details>


### [202] [Probing Information Distribution in Transformer Architectures through Entropy Analysis](https://arxiv.org/abs/2507.15347)
*Amedeo Buonanno,Alessandro Rivetti,Francesco A. N. Palmieri,Giovanni Di Gennaro,Gianmarco Romano*

Main category: cs.CL

TL;DR: 利用熵分析来理解 Transformer 模型（如 GPT）如何处理信息，为模型解释和评估提供新方法。


<details>
  <summary>Details</summary>
Motivation: 为了探索熵分析作为一种探究 Transformer 模型信息分布的工具，并揭示模型行为和内部表示的见解。

Method: 通过量化 token 级不确定性并检查不同处理阶段的熵模式来分析信息在 Transformer 模型中的分布和转化。

Result: 将该方法应用于 GPT 模型作为案例研究，展示了其揭示模型行为和内部表征的潜力。

Conclusion: 该方法为理解 Transformer 模型（如 GPT）的行为和内部表示提供了新的视角，有望促进可解释性和评估框架的发展。

Abstract: This work explores entropy analysis as a tool for probing information
distribution within Transformer-based architectures. By quantifying token-level
uncertainty and examining entropy patterns across different stages of
processing, we aim to investigate how information is managed and transformed
within these models. As a case study, we apply the methodology to a GPT-based
large language model, illustrating its potential to reveal insights into model
behavior and internal representations. This approach may offer insights into
model behavior and contribute to the development of interpretability and
evaluation frameworks for transformer-based models

</details>


### [203] [Metaphor and Large Language Models: When Surface Features Matter More than Deep Understanding](https://arxiv.org/abs/2507.15357)
*Elisa Sanchez-Bayona,Rodrigo Agerri*

Main category: cs.CL

TL;DR: 本研究全面评估了LLM在比喻解释方面的能力，发现在推理和问答任务中，LLM的表现更多地受到词汇重叠和句子长度等表面特征的影响，而不是比喻内容的固有理解。


<details>
  <summary>Details</summary>
Motivation: 之前的研究仅限于单数据集评估和特定任务设置，并且经常使用通过词汇替换进行的人工构造的数据，而忽略了LLM在比喻解释方面的全面评估。

Method: 通过在推理和问答任务中，使用带有推理和比喻注释的各种公开可用数据集进行广泛的实验，对LLM在多组数据集、任务和提示配置中的比喻解释能力进行了全面的评估。

Result: LLM的表现更多地受到词汇重叠和句子长度等特征的影响，而不是比喻内容。

Conclusion: LLMs在处理比喻语言方面的能力受到词汇重叠和句子长度等表面特征的影响，而不是比喻内容的固有理解。所谓的LLM的涌现能力是表面特征、语境学习和语言知识的结合。

Abstract: This paper presents a comprehensive evaluation of the capabilities of Large
Language Models (LLMs) in metaphor interpretation across multiple datasets,
tasks, and prompt configurations. Although metaphor processing has gained
significant attention in Natural Language Processing (NLP), previous research
has been limited to single-dataset evaluations and specific task settings,
often using artificially constructed data through lexical replacement. We
address these limitations by conducting extensive experiments using diverse
publicly available datasets with inference and metaphor annotations, focusing
on Natural Language Inference (NLI) and Question Answering (QA) tasks. The
results indicate that LLMs' performance is more influenced by features like
lexical overlap and sentence length than by metaphorical content, demonstrating
that any alleged emergent abilities of LLMs to understand metaphorical language
are the result of a combination of surface-level features, in-context learning,
and linguistic knowledge. This work provides critical insights into the current
capabilities and limitations of LLMs in processing figurative language,
highlighting the need for more realistic evaluation frameworks in metaphor
interpretation tasks. Data and code are publicly available.

</details>


### [204] [STITCH: Simultaneous Thinking and Talking with Chunked Reasoning for Spoken Language Models](https://arxiv.org/abs/2507.15375)
*Cheng-Han Chiang,Xiaofei Wang,Linjie Li,Chung-Ching Lin,Kevin Lin,Shujie Liu,Zhendong Wang,Zhengyuan Yang,Hung-yi Lee,Lijuan Wang*

Main category: cs.CL

TL;DR: Stitch 是一种新颖的生成方法，通过交替生成无声推理块和有声响应块，实现了 SLMs 的“边思考边说”。它在数学推理上表现更好，同时延迟与不思考的基线模型相当。


<details>
  <summary>Details</summary>
Motivation: 当前语音语言模型（SLMs）缺乏内部的、无声的思考过程，而人类在交流时通常会进行复杂的内部心理推理。因此，为 SLMs 整合无声思考过程是可取的，但直接生成完整的思考链（CoT）会增加响应延迟。

Method: Stitch 生成方法，通过交替生成无声推理块和有声响应块，并利用音频播放的剩余时间生成无声推理令牌，实现同时思考和说话。

Result: Stitch 在数学推理数据集上比不生成 CoT 的基线模型性能提升 15%，在非推理数据集上表现相当。

Conclusion: Stitch 提案了一种新颖的生成方法，通过交替生成无声推理块和有声响应块，实现了同时思考和说话，在数学推理任务上性能提升 15%，同时保持了与不生成 CoT 的基线相同的延迟。

Abstract: Spoken Language Models (SLMs) are designed to take speech inputs and produce
spoken responses. However, current SLMs lack the ability to perform an
internal, unspoken thinking process before responding. In contrast, humans
typically engage in complex mental reasoning internally, enabling them to
communicate ideas clearly and concisely. Thus, integrating an unspoken thought
process into SLMs is highly desirable. While naively generating a complete
chain-of-thought (CoT) reasoning before starting to talk can enable thinking
for SLMs, this induces additional latency for the speech response, as the CoT
reasoning can be arbitrarily long. To solve this issue, we propose Stitch, a
novel generation method that alternates between the generation of unspoken
reasoning chunks and spoken response chunks. Since the audio duration of a
chunk of spoken response is much longer than the time to generate the tokens in
a chunk of spoken response, we use the remaining free time to generate the
unspoken reasoning tokens. When a chunk of audio is played to the user, the
model continues to generate the next unspoken reasoning chunk, achieving
simultaneous thinking and talking. Remarkably, Stitch matches the latency of
baselines that cannot generate unspoken CoT by design while outperforming those
baselines by 15% on math reasoning datasets; Stitch also performs equally well
on non-reasoning datasets as those baseline models. Some animations and
demonstrations are on the project page: https://d223302.github.io/STITCH.

</details>


### [205] [AlgoSimBench: Identifying Algorithmically Similar Problems for Competitive Programming](https://arxiv.org/abs/2507.15378)
*Jierui Li,Raymond Mooney*

Main category: cs.CL

TL;DR: LLM 在识别算法相似问题方面能力有限，但提出的 ASM 方法和结合 BM25 的策略可以提升性能。


<details>
  <summary>Details</summary>
Motivation: 评估 LLM 在训练中不常见但与算法相关的领域的泛化能力，特别是识别算法相似问题（ASPs）的能力。

Method: 提出 AlgoSimBench 评测基准，包含 1317 个问题和 231 个算法标签，并设计了 402 道选择题（MCQ）。提出尝试性解决方案匹配（ASM）方法。

Result: 在 MCQ 任务上，最佳 LLM 模型的准确率仅为 65.9%。ASM 方法可以将准确率提高 6.7% 至 11.7%。移除叙事性元素可以消除对抗性选择问题带来的性能下降。结合 ASM 和 BM25 可达 52.2% 的准确率。

Conclusion: LLMs 在识别算法相似问题（ASPs）方面表现不佳，但提出的 ASM 方法可以提高准确性。通过移除叙事性元素并结合 BM25，可以进一步提高性能。

Abstract: Recent progress in LLMs, such as reasoning models, has demonstrated strong
abilities to solve complex competitive programming problems, often rivaling top
human competitors. However, it remains underexplored whether these abilities
generalize to relevant domains that are less seen during training. To address
this, we introduce AlgoSimBench, a new benchmark designed to assess LLMs'
ability to identify algorithmically similar problems (ASPs)-problems that can
be solved using similar algorithmic approaches. AlgoSimBench consists of 1317
problems, annotated with 231 distinct fine-grained algorithm tags, from which
we curate 402 multiple-choice questions (MCQs), where each question presents
one algorithmically similar problem alongside three textually similar but
algorithmically dissimilar distractors. Our evaluation reveals that LLMs
struggle to identify ASPs, with the best-performing model (o3-mini) achieving
only 65.9% accuracy on the MCQ task. To address this challenge, we propose
attempted solution matching (ASM), a novel method for improving problem
similarity detection. On our MCQ task, ASM yields an absolute accuracy
improvement of 6.7% to 11.7% across different models. We also evaluated code
embedding models and retrieval methods on similar problem identification. While
the adversarial selection of problems degrades the performance to be less than
random, we found that simply summarizing the problem to remove narrative
elements eliminates the effect, and combining ASM with a keyword-prioritized
method, BM25, can yield up to 52.2% accuracy. Code and data are available at
github.com

</details>


### [206] [ASPERA: A Simulated Environment to Evaluate Planning for Complex Action Execution](https://arxiv.org/abs/2507.15501)
*Alexandru Coca,Mark Gaynor,Zhenxing Zhang,Jianpeng Cheng,Bo-Hsiang Tseng,Pete Boothroyd,Héctor Martinez Alonso,Diarmuid Ó Séaghdha,Anders Johannsen*

Main category: cs.CL

TL;DR: LLM在为需要与自定义库交互的数字助手生成复杂操作程序方面存在挑战。ASPERA框架和Asper-Bench数据集用于评估和解决这些挑战。


<details>
  <summary>Details</summary>
Motivation: 评估LLM在支持能够执行复杂操作的数字助手方面的潜力。

Method: ASPERA框架，包括助手库模拟和人类辅助的LLM数据生成引擎，用于生成高质量的任务，包括复杂的用户查询、模拟状态和相应的验证程序。

Result: 发布Asper-Bench评估数据集（包含250个具有挑战性的任务），并表明与无依赖项的代码生成相比，LLM在生成与自定义助手库相结合的程序方面存在显著挑战。

Conclusion: LLM在生成需要与自定义助手库交互以执行复杂操作的程序方面面临重大挑战。

Abstract: This work evaluates the potential of large language models (LLMs) to power
digital assistants capable of complex action execution. These assistants rely
on pre-trained programming knowledge to execute multi-step goals by composing
objects and functions defined in assistant libraries into action execution
programs. To achieve this, we develop ASPERA, a framework comprising an
assistant library simulation and a human-assisted LLM data generation engine.
Our engine allows developers to guide LLM generation of high-quality tasks
consisting of complex user queries, simulation state and corresponding
validation programs, tackling data availability and evaluation robustness
challenges. Alongside the framework we release Asper-Bench, an evaluation
dataset of 250 challenging tasks generated using ASPERA, which we use to show
that program generation grounded in custom assistant libraries is a significant
challenge to LLMs compared to dependency-free code generation.

</details>


### [207] [Step-level Verifier-guided Hybrid Test-Time Scaling for Large Language Models](https://arxiv.org/abs/2507.15512)
*Kaiyan Chang,Yonghao Shi,Chenglong Wang,Hang Zhou,Chi Hu,Xiaoqian Liu,Yingfeng Luo,Yuan Ge,Tong Xiao,Jingbo Zhu*

Main category: cs.CL

TL;DR: 该研究提出了一种新的混合测试时域（Hybrid TTS）方法，通过结合多种无训练推理技术，在不增加额外训练开销的情况下，显著提升了大型语言模型的推理能力。


<details>
  <summary>Details</summary>
Motivation: 为了解决训练式测试时域（training-based TTS）方法计算开销过大的问题，并重新关注并发展无训练测试时域（training-free TTS）方法在推理中的应用，特别是针对语言模型的推理能力提升。

Method: 提出了一种名为“条件步级自精炼”（Conditional Step-level Self-refinement）的细粒度序列化方法，并结合经典的并行化方法，构建了混合测试时域（Hybrid Test-Time Scaling）推理范式。

Result: 在五个不同规模（3B-14B）和家族的指令微调语言模型（instruction-tuned LLMs）上的大量实验证明，该混合策略在提升语言模型的推理性能方面表现出色。

Conclusion: 研究表明，混合测试时域（Hybrid Test-Time Scaling）通过在细粒度层面结合多种无训练测试时域（training-free TTS）方法，在扩展语言模型（LLM）推理能力方面具有巨大潜力。

Abstract: Test-Time Scaling (TTS) is a promising approach to progressively elicit the
model's intelligence during inference. Recently, training-based TTS methods,
such as continued reinforcement learning (RL), have further surged in
popularity, while training-free TTS methods are gradually fading from
prominence. However, the additional computation overhead of training amplifies
the burden on test-time scaling. In this paper, we focus on training-free TTS
methods for reasoning. We first design Conditional Step-level Self-refinement,
a fine-grained sequential scaling method guided by process verification. On top
of its effectiveness, we further combine it with other classical parallel
scaling methods at the step level, to introduce a novel inference paradigm
called Hybrid Test-Time Scaling. Extensive experiments on five
instruction-tuned LLMs across different scales (3B-14B) and families
demonstrate that hybrid strategy incorporating various training-free TTS
methods at a fine granularity has considerable potential for expanding the
reasoning performance boundaries of LLMs.

</details>


### [208] [Evaluating Text Style Transfer: A Nine-Language Benchmark for Text Detoxification](https://arxiv.org/abs/2507.15557)
*Vitaly Protasov,Nikolay Babakov,Daryna Dementieva,Alexander Panchenko*

Main category: cs.CL

TL;DR: 该研究在九种语言上评估了文本解毒系统的文本风格迁移，并提出了一种可靠的多语言评估方法。


<details>
  <summary>Details</summary>
Motivation: 评估文本风格迁移（TST）仍然是一个重大挑战，尤其是在多语言方面。现有研究主要集中在英语，而多语言TST评估则在很大程度上未被探索。

Method: 1. 评估了现代神经基评估模型和基于提示的LLM-as-a-judge方法的有效性。
2. 在九种语言（英语、西班牙语、德语、中文、阿拉伯语、印地语、乌克兰语、俄语、阿姆哈拉语）上进行了多语言文本风格迁移评估研究。

Result: 该研究首次对九种语言的文本解毒系统的评估进行了全面的多语言研究。

Conclusion: 该研究为文本解毒案例中设计更可靠的多语言文本风格迁移评估流程提供了一个实用的方法。

Abstract: Despite recent progress in large language models (LLMs), evaluation of text
generation tasks such as text style transfer (TST) remains a significant
challenge. Recent studies (Dementieva et al., 2024; Pauli et al., 2025)
revealed a substantial gap between automatic metrics and human judgments.
Moreover, most prior work focuses exclusively on English, leaving multilingual
TST evaluation largely unexplored. In this paper, we perform the first
comprehensive multilingual study on evaluation of text detoxification system
across nine languages: English, Spanish, German, Chinese, Arabic, Hindi,
Ukrainian, Russian, Amharic. Drawing inspiration from the machine translation,
we assess the effectiveness of modern neural-based evaluation models alongside
prompting-based LLM-as-a-judge approaches. Our findings provide a practical
recipe for designing more reliable multilingual TST evaluation pipeline in the
text detoxification case.

</details>


### [209] [Smart Eyes for Silent Threats: VLMs and In-Context Learning for THz Imaging](https://arxiv.org/abs/2507.15576)
*Nicolas Poggi,Shashank Agnihotri,Margret Keuper*

Main category: cs.CL

TL;DR: In-context learning (ICL) with vision-language models (VLMs) offers a no-fine-tuning alternative for Terahertz (THz) image classification, outperforming traditional methods in low-data scenarios and enhancing interpretability.


<details>
  <summary>Details</summary>
Motivation: Effective image classification in Terahertz (THz) imaging is challenging due to limited annotations, low resolution, and visual ambiguity. Existing methods require fine-tuning, which is not always feasible.

Method: Utilizing a modality-aligned prompting framework to adapt two open-weight Vision-Language Models (VLMs) to the THz domain and evaluating them under zero-shot and one-shot settings.

Result: ICL improves classification and interpretability in low-data regimes for THz imaging.

Conclusion: ICL-enhanced VLMs are a promising direction for resource-constrained scientific domains like THz imaging, offering improved classification and interpretability in low-data regimes without fine-tuning.

Abstract: Terahertz (THz) imaging enables non-invasive analysis for applications such
as security screening and material classification, but effective image
classification remains challenging due to limited annotations, low resolution,
and visual ambiguity. We introduce In-Context Learning (ICL) with
Vision-Language Models (VLMs) as a flexible, interpretable alternative that
requires no fine-tuning. Using a modality-aligned prompting framework, we adapt
two open-weight VLMs to the THz domain and evaluate them under zero-shot and
one-shot settings. Our results show that ICL improves classification and
interpretability in low-data regimes. This is the first application of
ICL-enhanced VLMs to THz imaging, offering a promising direction for
resource-constrained scientific domains. Code:
\href{https://github.com/Nicolas-Poggi/Project_THz_Classification/tree/main}{GitHub
repository}.

</details>


### [210] [Learning to Extract Rational Evidence via Reinforcement Learning for Retrieval-Augmented Generation](https://arxiv.org/abs/2507.15586)
*Xinping Zhao,Shouzheng Huang,Yan Zhong,Xinshuo Hu,Baotian Hu,Min Zhang*

Main category: cs.CL

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Retrieval-Augmented Generation (RAG) effectively improves the accuracy of
Large Language Models (LLMs). However, retrieval noises significantly impact
the quality of LLMs' generation, necessitating the development of denoising
mechanisms. Previous methods extract evidence straightforwardly without
explicit thinking, which risks filtering out key clues and struggles with
generalization. To this end, we propose LEAR, which learns to extract rational
evidence by (1) explicitly reasoning to identify potential cues within
retrieval contents first, and then (2) consciously extracting to avoid omitting
any key cues helpful for answering questions. Specifically, we frame evidence
reasoning and evidence extraction into one unified response for end-to-end
training; apply knowledge token masks for disentanglement to derive
reasoning-based and extraction-based answers; and devise three types of
verifiable reward functions, including answer, length, and format, to update
the model via the policy optimization algorithm. Extensive experiments on three
benchmark datasets show the effectiveness of LEAR, providing compact and
high-quality evidence, improving the accuracy of downstream tasks, and
promoting effective application in online RAG systems.

</details>


### [211] [Leveraging Context for Multimodal Fallacy Classification in Political Debates](https://arxiv.org/abs/2507.15641)
*Alessio Pittiglio*

Main category: cs.CL

TL;DR: 本文提出了一种基于预训练Transformer和上下文利用的方法，用于政治辩论中的多模态逻辑谬误挖掘。


<details>
  <summary>Details</summary>
Motivation: 本研究旨在推进多模态论证挖掘研究，特别关注政治辩论中的逻辑谬误，以应对MM-ArgFallick2025共享任务。

Method: 本文采用了预训练的Transformer模型，并探索了几种利用上下文信息的方法，以应对MM-ArgFallick2025共享任务中关于多模态论证挖掘和政治辩论中逻辑谬误的研究。

Result: 在谬误分类子任务中，我们的模型取得了以下宏F1分数：文本模型为0.4444，音频模型为0.3559，多模态模型为0.4403。

Conclusion: 虽然我们的多模态模型表现与仅文本模型相当，但仍有改进空间。

Abstract: In this paper, we present our submission to the MM-ArgFallacy2025 shared
task, which aims to advance research in multimodal argument mining, focusing on
logical fallacies in political debates. Our approach uses pretrained
Transformer-based models and proposes several ways to leverage context. In the
fallacy classification subtask, our models achieved macro F1-scores of 0.4444
(text), 0.3559 (audio), and 0.4403 (multimodal). Our multimodal model showed
performance comparable to the text-only model, suggesting potential for
improvements.

</details>


### [212] [P3: Prompts Promote Prompting](https://arxiv.org/abs/2507.15675)
*Xinyu Zhang,Yuanquan Hu,Fangchao Liu,Zhicheng Dou*

Main category: cs.CL

TL;DR: P3框架通过同时优化系统和用户提示，并结合在线查询相关的优化，显著提升了LLM在各种任务上的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的LLM应用通常使用多组件提示来指导模型行为。虽然可以自动优化其中一个组件，但由于组件的相互依赖性，这种单方面的方法通常不能达到最优结果。

Method: P3是一个新颖的自改进框架，通过迭代过程同时优化系统提示和用户提示。离线优化后的提示通过执行查询相关的提示优化来促进在线提示。

Result: 实验证明，P3在通用任务（如Arena-hard和Alpaca-eval）和推理任务（如GSM8K和GPQA）上均取得了卓越的性能。

Conclusion: P3框架通过同时优化系统提示和用户提示，并在在线提示中进行查询相关的提示优化，在通用任务和推理任务上都取得了优于现有方法的性能。

Abstract: Current large language model (LLM) applications often employ multi-component
prompts, comprising both system and user prompts, to guide model behaviors.
While recent advancements have demonstrated the efficacy of automatically
optimizing either the system or user prompt to boost performance, such
unilateral approaches often yield suboptimal outcomes due to the interdependent
nature of these components. In this work, we introduce P3, a novel
self-improvement framework that concurrently optimizes both system and user
prompts through an iterative process. The offline optimized prompts are further
leveraged to promote online prompting by performing query-dependent prompt
optimization. Extensive experiments on general tasks (e.g., Arena-hard and
Alpaca-eval) and reasoning tasks (e.g., GSM8K and GPQA) demonstrate that P3
achieves superior performance in the realm of automatic prompt optimization.
Our results highlight the effectiveness of a holistic optimization strategy in
enhancing LLM performance across diverse domains.

</details>


### [213] [CoLD: Counterfactually-Guided Length Debiasing for Process Reward Models](https://arxiv.org/abs/2507.15698)
*Congmin Zheng,Jiachen Zhu,Jianghao Lin,Xinyi Dai,Yong Yu,Weinan Zhang,Mengyue Yang*

Main category: cs.CL

TL;DR: CoLD框架通过反事实推理和因果图分析，解决了现有过程奖励模型（PRMs）中存在的长度偏差问题，通过长度惩罚、偏差估计和联合训练等方法，提高了奖励预测的准确性和推理的简洁性。


<details>
  <summary>Details</summary>
Motivation: 现有的过程奖励模型（PRMs）在评估和指导LLM的多步推理（尤其是在数学问题解决方面）中起着关键作用。然而，这些模型存在普遍的长度偏差，即它们倾向于给更长的推理步骤赋予更高的分数，即使语义内容和逻辑有效性保持不变。这种偏差会破坏奖励预测的可靠性，并导致推理过程中输出冗长。

Method: 提出了一种名为CoLD(Counterfactually-Guided Length Debiasing)的统一框架，该框架包含三个组成部分：显式的长度惩罚调整、用于捕捉虚假长度相关信号的学习偏差估计器，以及强制奖励预测中长度不变性的联合训练策略。该方法基于反事实推理，并结合了因果图分析。

Result: 在MATH500和GSM-Plus数据集上的大量实验表明，CoLD能够一致地降低奖励与长度之间的相关性，提高步骤选择的准确性，并鼓励更简洁、逻辑上有效的推理。

Conclusion: CoLD框架通过显式的长度惩罚调整、学习到的偏差估计器以及联合训练策略，有效缓解了PRM中的长度偏差，提高了奖励预测的准确性和推理过程的简洁性与逻辑性。

Abstract: Process Reward Models (PRMs) play a central role in evaluating and guiding
multi-step reasoning in large language models (LLMs), especially for
mathematical problem solving. However, we identify a pervasive length bias in
existing PRMs: they tend to assign higher scores to longer reasoning steps,
even when the semantic content and logical validity are unchanged. This bias
undermines the reliability of reward predictions and leads to overly verbose
outputs during inference. To address this issue, we propose
CoLD(Counterfactually-Guided Length Debiasing), a unified framework that
mitigates length bias through three components: an explicit length-penalty
adjustment, a learned bias estimator trained to capture spurious length-related
signals, and a joint training strategy that enforces length-invariance in
reward predictions. Our approach is grounded in counterfactual reasoning and
informed by causal graph analysis. Extensive experiments on MATH500 and
GSM-Plus show that CoLD consistently reduces reward-length correlation,
improves accuracy in step selection, and encourages more concise, logically
valid reasoning. These results demonstrate the effectiveness and practicality
of CoLD in improving the fidelity and robustness of PRMs.

</details>


### [214] [Compositional Understanding in Signaling Games](https://arxiv.org/abs/2507.15706)
*David Peter Wallis Freeborn*

Main category: cs.CL

TL;DR: Signaling game receivers usually fail to grasp compositional messages. This paper introduces two simpler models where receivers learn compositionally by focusing on atomic message parts or all available information.


<details>
  <summary>Details</summary>
Motivation: Standard signaling game models fail to learn compositional information, meaning receivers don't interpret messages compositionally, and information from one component is lost when others are forgotten. This research aims to overcome this limitation.

Method: The study constructs two novel signaling game models: one with a minimalist receiver learning from atomic messages, and another with a generalist receiver learning from all available information.

Result: The proposed models allow receivers to learn from the atomic components of messages, offering a simpler and more effective approach compared to previous alternatives.

Conclusion: This paper presents two new models for signaling games where receivers can learn compositional information, addressing a key limitation in existing models.

Abstract: Receivers in standard signaling game models struggle with learning
compositional information. Even when the signalers send compositional messages,
the receivers do not interpret them compositionally. When information from one
message component is lost or forgotten, the information from other components
is also erased. In this paper I construct signaling game models in which
genuine compositional understanding evolves. I present two new models: a
minimalist receiver who only learns from the atomic messages of a signal, and a
generalist receiver who learns from all of the available information. These
models are in many ways simpler than previous alternatives, and allow the
receivers to learn from the atomic components of messages.

</details>


### [215] [Is Large Language Model Performance on Reasoning Tasks Impacted by Different Ways Questions Are Asked?](https://arxiv.org/abs/2507.15707)
*Seok Hwan Song,Mohna Chakraborty,Qi Li,Wallapak Tavanapong*

Main category: cs.CL

TL;DR: 不同问题类型影响LLM在推理任务上的准确性；推理准确性不等于选择准确性；选项数量和措辞很重要。


<details>
  <summary>Details</summary>
Motivation: 评估大型语言模型在推理任务中不同问题类型的影响。

Method: 本研究调查了五种大型语言模型在三种不同类型的问题上的表现，并使用了定量和演绎推理任务。评估指标包括推理步骤的准确性和最终答案的选择准确性。

Result: 研究发现，不同类型的问题会导致大型语言模型在推理任务上表现出显著差异。此外，推理过程的准确性与最终选择的准确性之间不一定存在关联。模型性能也受到选项数量和措辞选择的影响。

Conclusion: 不同类型的问题对大型语言模型在推理任务上的表现有显著影响，推理过程的准确性与最终选择的准确性不一定相关，选项的数量和措辞会影响模型性能。

Abstract: Large Language Models (LLMs) have been evaluated using diverse question
types, e.g., multiple-choice, true/false, and short/long answers. This study
answers an unexplored question about the impact of different question types on
LLM accuracy on reasoning tasks. We investigate the performance of five LLMs on
three different types of questions using quantitative and deductive reasoning
tasks. The performance metrics include accuracy in the reasoning steps and
choosing the final answer. Key Findings: (1) Significant differences exist in
LLM performance across different question types. (2) Reasoning accuracy does
not necessarily correlate with the final selection accuracy. (3) The number of
options and the choice of words, influence LLM performance.

</details>


### [216] [Chinchunmei at SemEval-2025 Task 11: Boosting the Large Language Model's Capability of Emotion Perception using Contrastive Learning](https://arxiv.org/abs/2507.15714)
*Tian Li,Yujian Sun,Huizhi Liang*

Main category: cs.CL

TL;DR: This paper investigates sample-based and generation-based contrastive learning methods using LLaMa3-Instruct-8B for the SemEval-2025 Task 11 emotion detection challenge, yielding strong results in English and other languages.


<details>
  <summary>Details</summary>
Motivation: The paper addresses the SemEval-2025 Task 11, which aims to improve text-based emotion detection across 28 languages, tackling the challenges of diverse emotional expressions and background variations.

Method: The study fine-tuned LLaMa3-Instruct-8B using two contrastive learning approaches: sample-based (Contrastive Reasoning Calibration) and generation-based (DPO, SimPO). Sample-based contrastive learning involves comparing samples for reliable predictions, while generation-based contrastive learning trains the model to distinguish correct from incorrect generations.

Result: The system achieved 9th place in Track A (multi-label classification) and 6th place in Track B (emotion intensity prediction) for English, and performed competitively in other languages.

Conclusion: The authors explored contrastive learning approaches for emotion detection, achieving competitive results in the SemEval-2025 Task 11 across multiple languages.

Abstract: The SemEval-2025 Task 11, Bridging the Gap in Text-Based Emotion Detection,
introduces an emotion recognition challenge spanning over 28 languages. This
competition encourages researchers to explore more advanced approaches to
address the challenges posed by the diversity of emotional expressions and
background variations. It features two tracks: multi-label classification
(Track A) and emotion intensity prediction (Track B), covering six emotion
categories: anger, fear, joy, sadness, surprise, and disgust. In our work, we
systematically explore the benefits of two contrastive learning approaches:
sample-based (Contrastive Reasoning Calibration) and generation-based (DPO,
SimPO) contrastive learning. The sample-based contrastive approach trains the
model by comparing two samples to generate more reliable predictions. The
generation-based contrastive approach trains the model to differentiate between
correct and incorrect generations, refining its prediction. All models are
fine-tuned from LLaMa3-Instruct-8B. Our system achieves 9th place in Track A
and 6th place in Track B for English, while ranking among the top-tier
performing systems for other languages.

</details>


### [217] [From Queries to Criteria: Understanding How Astronomers Evaluate LLMs](https://arxiv.org/abs/2507.15715)
*Alina Hyk,Kiera McCormick,Mian Zhong,Ioana Ciucă,Sanjib Sharma,John F Wu,J. E. G. Peek,Kartheik G. Iyer,Ziang Xiao,Anjalie Field*

Main category: cs.CL

TL;DR: 本研究旨在改进LLM的评估方法，特别是针对天文学等科学研究领域。通过分析用户如何与天文学LLM进行交互，研究提出了改进评估基准的建议，并构建了一个示例基准，以期提高LLM在科学研究中的可用性。


<details>
  <summary>Details</summary>
Motivation: 现有LLM评估基准未能跟上用户多样化的评估和使用方式，尤其是在科学研究领域，LLM的应用日益广泛，需要改进评估方法。

Method: 通过对368个查询进行归纳编码和对11位天文学家进行访谈，分析用户如何评估LLM在天文学文献检索和生成中的应用。

Result: 研究发现了用户评估LLM的标准和提问方式，并提出了构建更好评估基准的具体建议，同时构建了一个天文学LLM评估的示例基准。

Conclusion: 该研究提出了改进LLM评估方法，特别是针对天文学等科学研究领域，并构建了一个评估LLM在天文学领域应用的基准。

Abstract: There is growing interest in leveraging LLMs to aid in astronomy and other
scientific research, but benchmarks for LLM evaluation in general have not kept
pace with the increasingly diverse ways that real people evaluate and use these
models. In this study, we seek to improve evaluation procedures by building an
understanding of how users evaluate LLMs. We focus on a particular use case: an
LLM-powered retrieval-augmented generation bot for engaging with astronomical
literature, which we deployed via Slack. Our inductive coding of 368 queries to
the bot over four weeks and our follow-up interviews with 11 astronomers reveal
how humans evaluated this system, including the types of questions asked and
the criteria for judging responses. We synthesize our findings into concrete
recommendations for building better benchmarks, which we then employ in
constructing a sample benchmark for evaluating LLMs for astronomy. Overall, our
work offers ways to improve LLM evaluation and ultimately usability,
particularly for use in scientific research.

</details>


### [218] [BEnchmarking LLMs for Ophthalmology (BELO) for Ophthalmological Knowledge and Reasoning](https://arxiv.org/abs/2507.15717)
*Sahana Srinivasan,Xuguang Ai,Thaddaeus Wai Soon Lo,Aidan Gilson,Minjie Zou,Ke Zou,Hyunjae Kim,Mingjia Yang,Krithi Pushpanathan,Samantha Yew,Wan Ting Loke,Jocelyn Goh,Yibing Chen,Yiming Kong,Emily Yuelei Fu,Michelle Ongyong Hui,Kristen Nwanyanwu,Amisha Dave,Kelvin Zhenghao Li,Chen-Hsin Sun,Mark Chia,Gabriel Dawei Yang,Wendy Meihua Wong,David Ziyou Chen,Dianbo Liu,Maxwell Singer,Fares Antaki,Lucian V Del Priore,Jost Jonas,Ron Adelman,Qingyu Chen,Yih-Chung Tham*

Main category: cs.CL

TL;DR: 开发了一个名为BELO的眼科LLM评估基准，包含900个专家审核的问题，评估准确性和推理能力，并对六个LLM进行了测试。


<details>
  <summary>Details</summary>
Motivation: 当前评估大型语言模型（LLMs）在眼科领域的基准在范围上存在局限性，并且过度侧重于准确性。因此，需要一个更全面、更标准的评估方法来衡量LLMs在眼科领域的临床准确性和推理能力。

Method: 研究人员开发了一个名为BELO的评估基准，通过多轮专家评审（13名眼科医生）来确保其全面性和准确性。该基准包含来自五个医学数据集（BCSC, MedMCQA, MedQA, BioASQ, PubMedQA）的眼科特异性选择题（MCQs）。研究团队使用关键词匹配和微调的PubMedBERT模型来筛选和整理问题，并由10名眼科医生对每个MCQ的正确答案进行了解释，最终由3名资深眼科医生进行审核。为了展示BELO的有效性，研究人员评估了六个大型语言模型（OpenAI o1, o3-mini, GPT-4o, DeepSeek-R1, Llama-3-8B, Gemini 1.5 Pro），并使用了准确率、宏F1以及五种文本生成指标（ROUGE-L, BERTScore, BARTScore, METEOR, AlignScore）进行评估。此外，还有一项由人类专家参与的定性评估，两名眼科医生对50个随机选择的输出进行了准确性、全面性和完整性方面的审查。BELO数据集包含900个高质量、专家审核的问题，并设立了公开排行榜以促进透明评估。

Result: BELO基准包含了900个高质量、经过专家审查的问题，这些问题来自五个不同的医学数据集。在对六个大型语言模型（OpenAI o1, o3-mini, GPT-4o, DeepSeek-R1, Llama-3-8B, Gemini 1.5 Pro）的评估中，使用了准确率、宏F1以及ROUGE-L、BERTScore、BARTScore、METEOR和AlignScore等多种指标。此外，一项由两位眼科医生进行的定性评估也审查了模型输出的准确性、全面性和完整性。BELO的开发和评估过程强调了专家评审的重要性，并建立了一个公共排行榜以鼓励透明度和可重复性。

Conclusion: BELO是一个全面且标准化的评估基准，用于评估大型语言模型在眼科领域的性能，通过专家评审确保了问题的质量和相关性，并包含准确性和推理能力两方面的评估指标，同时公开的排行榜促进了透明度和可重复性。

Abstract: Current benchmarks evaluating large language models (LLMs) in ophthalmology
are limited in scope and disproportionately prioritise accuracy. We introduce
BELO (BEnchmarking LLMs for Ophthalmology), a standardized and comprehensive
evaluation benchmark developed through multiple rounds of expert checking by 13
ophthalmologists. BELO assesses ophthalmology-related clinical accuracy and
reasoning quality. Using keyword matching and a fine-tuned PubMedBERT model, we
curated ophthalmology-specific multiple-choice-questions (MCQs) from diverse
medical datasets (BCSC, MedMCQA, MedQA, BioASQ, and PubMedQA). The dataset
underwent multiple rounds of expert checking. Duplicate and substandard
questions were systematically removed. Ten ophthalmologists refined the
explanations of each MCQ's correct answer. This was further adjudicated by
three senior ophthalmologists. To illustrate BELO's utility, we evaluated six
LLMs (OpenAI o1, o3-mini, GPT-4o, DeepSeek-R1, Llama-3-8B, and Gemini 1.5 Pro)
using accuracy, macro-F1, and five text-generation metrics (ROUGE-L, BERTScore,
BARTScore, METEOR, and AlignScore). In a further evaluation involving human
experts, two ophthalmologists qualitatively reviewed 50 randomly selected
outputs for accuracy, comprehensiveness, and completeness. BELO consists of 900
high-quality, expert-reviewed questions aggregated from five sources: BCSC
(260), BioASQ (10), MedMCQA (572), MedQA (40), and PubMedQA (18). A public
leaderboard has been established to promote transparent evaluation and
reporting. Importantly, the BELO dataset will remain a hold-out,
evaluation-only benchmark to ensure fair and reproducible comparisons of future
models.

</details>


### [219] [Understanding Large Language Models' Ability on Interdisciplinary Research](https://arxiv.org/abs/2507.15736)
*Yuanhao Shen,Daniel Xavier de Sousa,Ricardo Marçal,Ali Asad,Hongyu Guo,Xiaodan Zhu*

Main category: cs.CL

TL;DR: LLM在跨学科研究中的创意生成能力有待提高，IDRBench基准为此提供了评估框架。


<details>
  <summary>Details</summary>
Motivation: 评估LLM在跨学科研究（IDR）中发展想法的能力，填补现有基准的空白。

Method: 创建了一个名为IDRBench的基准，包含专家注释的数据集和一系列评估LLM在跨学科研究中提出研究创意的任务。该基准包含来自六个不同学科的ArXiv论文，并通过三个阶段（IDR论文识别、IDR创意整合、IDR创意推荐）进行评估。

Result: 在IDRBench基准上，LLM表现出一定的IDR意识，但在产生高质量的IDR创意方面仍存在困难。

Conclusion: LLM在跨学科研究（IDR）方面的能力仍然有限，但该基准可以为未来的研究提供方向。

Abstract: Recent advancements in Large Language Models (LLMs) have revealed their
impressive ability to perform multi-step, logic-driven reasoning across complex
domains, positioning them as powerful tools and collaborators in scientific
discovery while challenging the long-held view that inspiration-driven ideation
is uniquely human. However, the lack of a dedicated benchmark that evaluates
LLMs' ability to develop ideas in Interdisciplinary Research (IDR) settings
poses a critical barrier to fully understanding their strengths and
limitations. To address this gap, we introduce IDRBench -- a pioneering
benchmark featuring an expert annotated dataset and a suite of tasks tailored
to evaluate LLMs' capabilities in proposing valuable research ideas from
different scientific domains for interdisciplinary research. This benchmark
aims to provide a systematic framework for assessing LLM performance in
complex, cross-domain scientific research. Our dataset consists of scientific
publications sourced from the ArXiv platform covering six distinct disciplines,
and is annotated by domain experts with diverse academic backgrounds. To ensure
high-quality annotations, we emphasize clearly defined dimensions that
characterize authentic interdisciplinary research. The design of evaluation
tasks in IDRBench follows a progressive, real-world perspective, reflecting the
natural stages of interdisciplinary research development, including 1) IDR
Paper Identification, 2) IDR Idea Integration, and 3) IDR Idea Recommendation.
Using IDRBench, we construct baselines across 10 LLMs and observe that despite
fostering some level of IDR awareness, LLMs still struggle to produce quality
IDR ideas. These findings could not only spark new research directions, but
also help to develop next-generation LLMs that excel in interdisciplinary
research.

</details>


### [220] [A Fisher's exact test justification of the TF-IDF term-weighting scheme](https://arxiv.org/abs/2507.15742)
*Paul Sheridan,Zeyad Ahmed,Aitazaz A. Farooque*

Main category: cs.CL

TL;DR: 本文从显著性检验的角度为 TF-IDF 提供了理论依据，表明 TF-ICF 与费希尔精确检验的 $p$ 值的负对数相关，并在极限情况下收敛于 TF-IDF。


<details>
  <summary>Details</summary>
Motivation: 该论文的动机是将信息检索领域的 TF-IDF 这一重要概念，从统计学的角度进行理论化，并展示其与显著性检验的联系。

Method: 通过展示著名的 TF-IDF 表达式如何从显著性检验的角度来理解，为 TF-IDF 提供了理论基础。具体来说，TF-IDF 的一个常见变体 TF-ICF 与费希尔精确检验的单尾 $p$ 值的负对数密切相关。

Result: 研究表明，TF-ICF 与费希尔精确检验的 $p$ 值的负对数之间存在密切关系，并且在文档集合无限大的极限情况下，该量收敛于 TF-IDF。

Conclusion: TF-IDF 的统计学解释为统计学工作者提供了对该术语加权方案长期以来有效性的现成解释。

Abstract: Term frequency-inverse document frequency, or TF-IDF for short, is arguably
the most celebrated mathematical expression in the history of information
retrieval. Conceived as a simple heuristic quantifying the extent to which a
given term's occurrences are concentrated in any one given document out of
many, TF-IDF and its many variants are routinely used as term-weighting schemes
in diverse text analysis applications. There is a growing body of scholarship
dedicated to placing TF-IDF on a sound theoretical foundation. Building on that
tradition, this paper justifies the use of TF-IDF to the statistics community
by demonstrating how the famed expression can be understood from a significance
testing perspective. We show that the common TF-IDF variant TF-ICF is, under
mild regularity conditions, closely related to the negative logarithm of the
$p$-value from a one-tailed version of Fisher's exact test of statistical
significance. As a corollary, we establish a connection between TF-IDF and the
said negative log-transformed $p$-value under certain idealized assumptions. We
further demonstrate, as a limiting case, that this same quantity converges to
TF-IDF in the limit of an infinitely large document collection. The Fisher's
exact test justification of TF-IDF equips the working statistician with a ready
explanation of the term-weighting scheme's long-established effectiveness.

</details>


### [221] [DialogueForge: LLM Simulation of Human-Chatbot Dialogue](https://arxiv.org/abs/2507.15752)
*Ruizhe Zhu,Hao Zhu,Yaxuan Li,Syang Zhou,Shijing Cai,Malgorzata Lazuka,Elliott Ash*

Main category: cs.CL

TL;DR: DialogueForge框架通过使用种子提示和多种LLM来生成模拟人机对话，并探索了微调技术以提升小型模型的性能。实验发现大型模型效果更好，但小型模型通过微调也很有潜力，不过所有模型在保持长期对话的连贯性和自然性方面仍有挑战。


<details>
  <summary>Details</summary>
Motivation: 收集人类与聊天机器人的对话数据需要大量的人工和时间，这给对话式人工智能的研究带来了限制和挑战。

Method: DialogueForge框架使用从真实人机交互中提取的种子提示来初始化生成的对话。我们测试了多种大型语言模型（LLM）来模拟人类聊天机器人用户，包括最先进的专有模型和小型开源LLM，并生成针对特定任务的多轮对话。此外，我们还探索了微调技术，以增强小型模型生成难以区分的人类对话的能力。我们使用UniEval和GTEval评估协议评估了模拟对话的质量并比较了不同的模型。

Result: 实验表明，大型专有模型（如GPT-4o）在生成更真实的对话方面通常优于其他模型，而小型开源模型（如Llama、Mistral）在提供更大定制性的同时，也表现出有希望的性能。通过采用监督微调技术，可以显著提高小型模型的性能。然而，保持连贯和自然的长期人类对话仍然是所有模型面临的共同挑战。

Conclusion: 收集人类与聊天机器人的对话数据需要大量的人工和时间，这给对话式人工智能的研究带来了限制和挑战。本研究提出了DialogueForge框架，用于生成模拟人类与聊天机器人风格的AI对话。

Abstract: Collecting human-chatbot dialogues typically demands substantial manual
effort and is time-consuming, which limits and poses challenges for research on
conversational AI. In this work, we propose DialogueForge - a framework for
generating AI-simulated conversations in human-chatbot style. To initialize
each generated conversation, DialogueForge uses seed prompts extracted from
real human-chatbot interactions. We test a variety of LLMs to simulate the
human chatbot user, ranging from state-of-the-art proprietary models to
small-scale open-source LLMs, and generate multi-turn dialogues tailored to
specific tasks. In addition, we explore fine-tuning techniques to enhance the
ability of smaller models to produce indistinguishable human-like dialogues. We
evaluate the quality of the simulated conversations and compare different
models using the UniEval and GTEval evaluation protocols. Our experiments show
that large proprietary models (e.g., GPT-4o) generally outperform others in
generating more realistic dialogues, while smaller open-source models (e.g.,
Llama, Mistral) offer promising performance with greater customization. We
demonstrate that the performance of smaller models can be significantly
improved by employing supervised fine-tuning techniques. Nevertheless,
maintaining coherent and natural long-form human-like dialogues remains a
common challenge across all models.

</details>


### [222] [Interaction as Intelligence: Deep Research With Human-AI Partnership](https://arxiv.org/abs/2507.15759)
*Lyumanshan Ye,Xiaojie Cai,Xinkai Wang,Junfei Wang,Xiangkun Hu,Jiadi Su,Yang Nan,Sihan Wang,Bohan Zhang,Xiaoze Fan,Jinbin Luo,Yuxiang Zheng,Tianze Xu,Dayuan Fu,Yunze Wu,Pengrui Lu,Zengzhi Wang,Yiwei Qin,Zhen Huang,Yan Ma,Zhulin Hu,Haoyang Zou,Tiantian Mi,Yixin Ye,Ethan Chern,Pengfei Liu*

Main category: cs.CL

TL;DR: 本研究提出“交互即智能”新范式，通过“深度认知”系统实现用户对AI思考过程的“认知监督”，用户可通过透明、可控、可中断的交互引导AI。实验证明该方法在多项指标上显著优于传统方法，提升了深度研究的效率和效果。


<details>
  <summary>Details</summary>
Motivation: 传统人机交互模式将交互视为简单的接口，忽略了其在深度研究任务中作为智能组成部分的关键作用。这种模式导致了错误累积、研究边界僵化以及专家知识整合的缺失。本研究旨在通过将交互提升至“认知监督”的层面，解决这些局限性。

Method: 本研究提出了一种名为“深度认知”的系统，该系统实现了透明、可控、可中断的交互，支持细粒度的双向对话，并建立了共享认知背景，使AI能够适应用户行为。研究通过用户评估验证了该系统的有效性。

Result: 用户评估显示，“认知监督”范式在六项关键指标上均优于现有基线：透明度（+20.0%）、细粒度交互（+29.2%）、实时干预（+18.5%）、协作易用性（+27.7%）、结果价值（+8.8%）和可中断性（+20.7%）。在复杂的深度研究问题上，相比于现有深度研究系统，性能提升了31.8%至50.0%。

Conclusion: 本研究提出“交互即智能”的研究范式，强调在深度研究任务中，人与AI的关系不应仅仅是接口，而应是构成智能的基本维度。通过引入“认知监督”模式，用户可以对AI的思考过程进行透明、可控、可中断的引导和干预，实现细粒度的双向对话和共享认知背景。实验结果表明，该范式在透明度、交互精细度、实时干预、协作易用性、结果价值和可中断性等方面均显著优于传统方法。

Abstract: This paper introduces "Interaction as Intelligence" research series,
presenting a reconceptualization of human-AI relationships in deep research
tasks. Traditional approaches treat interaction merely as an interface for
accessing AI capabilities-a conduit between human intent and machine output. We
propose that interaction itself constitutes a fundamental dimension of
intelligence. As AI systems engage in extended thinking processes for research
tasks, meaningful interaction transitions from an optional enhancement to an
essential component of effective intelligence. Current deep research systems
adopt an "input-wait-output" paradigm where users initiate queries and receive
results after black-box processing. This approach leads to error cascade
effects, inflexible research boundaries that prevent question refinement during
investigation, and missed opportunities for expertise integration. To address
these limitations, we introduce Deep Cognition, a system that transforms the
human role from giving instructions to cognitive oversight-a mode of engagement
where humans guide AI thinking processes through strategic intervention at
critical junctures. Deep cognition implements three key innovations:
(1)Transparent, controllable, and interruptible interaction that reveals AI
reasoning and enables intervention at any point; (2)Fine-grained bidirectional
dialogue; and (3)Shared cognitive context where the system observes and adapts
to user behaviors without explicit instruction. User evaluation demonstrates
that this cognitive oversight paradigm outperforms the strongest baseline
across six key metrics: Transparency(+20.0%), Fine-Grained Interaction(+29.2%),
Real-Time Intervention(+18.5%), Ease of Collaboration(+27.7%),
Results-Worth-Effort(+8.8%), and Interruptibility(+20.7%). Evaluations on
challenging research problems show 31.8% to 50.0% points of improvements over
deep research systems.

</details>


### [223] [Supernova: Achieving More with Less in Transformer Architectures](https://arxiv.org/abs/2507.15773)
*Andrei-Valentin Tanase,Elena Pelican*

Main category: cs.CL

TL;DR: Supernova是一个650M参数的Transformer模型，通过优化的架构和分词器，实现了与更大模型相当的性能，同时减少了参数量和训练数据需求。


<details>
  <summary>Details</summary>
Motivation: 本文旨在探索通过精细的架构设计和创新的分词方法，在保持计算效率的同时，实现与更大参数量模型相媲美的性能。

Method: Supernova模型采用了旋转位置嵌入（RoPE）、分组查询注意力（GQA）和3:1的压缩比、RMSNorm以及SwiGLU激活函数。关键创新在于使用了自定义的128,000词汇量的字节级BPE分词器。

Result: Supernova模型实现了1B参数模型90%的性能，同时参数量减少了53%，并且仅需100B的训练数据，比现有模型所需的训练数据量减少了一个数量级。

Conclusion: Supernova的发现挑战了现有的模型扩展范式，证明了架构效率和分词质量可以弥补参数数量的不足。

Abstract: We present Supernova, a 650M-parameter decoder-only transformer that
demonstrates how careful architectural design and tokenization innovation can
achieve the performance of larger models while maintaining computational
efficiency. Our architecture combines Rotary Positional Embeddings (RoPE),
Grouped Query Attention (GQA) with a 3:1 compression ratio, RMSNorm for
computational efficiency, and SwiGLU activation functions. A critical
innovation is our custom 128,000-vocabulary byte-level BPE tokenizer, which
achieves state-of-the-art compression performance. Through detailed analysis,
we show that Supernova achieves 90% of the performance of 1B-parameter models
while using 53% fewer parameters and requiring only 100B training tokens--an
order of magnitude less than competing models. Our findings challenge the
prevailing scaling paradigm, demonstrating that architectural efficiency and
tokenization quality can compensate for reduced parameter counts.

</details>


### [224] [Stabilizing Knowledge, Promoting Reasoning: Dual-Token Constraints for RLVR](https://arxiv.org/abs/2507.15778)
*Jiakang Wang,Runze Liu,Fuzheng Zhang,Xiu Li,Guorui Zhou*

Main category: cs.CL

TL;DR: Archer improves LLM reasoning by applying different training signals to knowledge and reasoning tokens, outperforming existing methods.


<details>
  <summary>Details</summary>
Motivation: Previous RLVR algorithms apply uniform training signals to all tokens, ignoring the different roles of low-entropy knowledge-related tokens and high-entropy reasoning-related tokens. Existing methods to separate token types may break semantic dependencies and hinder learning.

Method: Archer uses an entropy-aware approach with dual-token constraints and synchronous updates. It applies weaker KL regularization and higher clipping thresholds to reasoning tokens to encourage exploration, while using stronger constraints on knowledge tokens to maintain factual knowledge.

Result: Archer significantly outperforms previous RLVR methods on several mathematical reasoning and code generation benchmarks, reaching or exceeding state-of-the-art performance among models of comparable size.

Conclusion: Archer, an entropy-aware RLVR approach with dual-token constraints and synchronous updates, significantly outperforms previous RLVR methods on mathematical reasoning and code generation benchmarks, reaching or exceeding state-of-the-art performance.

Abstract: Reinforcement Learning with Verifiable Rewards (RLVR) has become an effective
post-training method for improving the reasoning abilities of Large Language
Models (LLMs), mainly by shaping higher-order behaviors such as reflection and
planning. However, previous RLVR algorithms often apply uniform training
signals to all tokens, without considering the different roles of low-entropy
knowledge-related tokens and high-entropy reasoning-related tokens. Some recent
methods try to separate these token types by gradient masking or asynchronous
updates, but these approaches may break semantic dependencies in the model
output and hinder effective learning. In this work, we propose Archer, an
entropy-aware RLVR approach with dual-token constraints and synchronous
updates. Specifically, our method applies weaker KL regularization and higher
clipping thresholds to reasoning tokens to encourage exploration, while using
stronger constraints on knowledge tokens to maintain factual knowledge.
Experimental results on several mathematical reasoning and code generation
benchmarks show that our approach significantly outperforms previous RLVR
methods, reaching or exceeding state-of-the-art performance among models of
comparable size. The code is available at
https://github.com/wizard-III/ArcherCodeR.

</details>


### [225] [Reservoir Computing as a Language Model](https://arxiv.org/abs/2507.15779)
*Felix Köster,Atsushi Uchida*

Main category: cs.CL

TL;DR: 本研究比较了Transformer和两种水库计算方法在字符级语言建模上的表现。结果显示Transformer在预测质量上更胜一筹，而水库计算在速度和能效上更具优势，为平衡资源与性能提供了指导。


<details>
  <summary>Details</summary>
Motivation: 尽管大型语言模型（LLM）在处理大数据和生成类人文本方面表现出色，但其巨大的能源消耗和缓慢的处理速度仍然是进一步提高质量和普及模型的瓶颈。为了解决这一瓶颈，本研究旨在探索水库计算在自然文本处理中的应用，以实现快速且节能的硬件实现。

Method: 本研究将比较三种不同的字符级语言建模方法：两种水库计算方法（只有输出层可训练）和一种基于Transformer的架构（完全学习基于注意力的序列表示）。通过等量变化所有模型的训练参数数量，来探索两种范例的性能、计算成本和预测准确性。

Result: Transformer在预测质量上表现更优，而水库计算在训练和推理速度上更高效。

Conclusion: 研究结果表明，Transformer在预测质量方面表现优异，而水库计算在减小训练和推理速度方面仍然具有高效率。此外，研究还探讨了两种水库计算方法：一种是传统的具有静态线性读出的水库，另一种是通过注意力机制动态调整其输出权重的注意力增强型水库。这些发现强调了这些模型范式如何扩展，并为平衡资源限制与性能提供了指导。

Abstract: Large Language Models (LLM) have dominated the science and media landscape
duo to their impressive performance on processing large chunks of data and
produce human-like levels of text. Nevertheless, their huge energy demand and
slow processing still a bottleneck for further increasing quality while also
making the models accessible to everyone. To solve this bottleneck, we will
investigate how reservoir computing performs on natural text processing, which
could enable fast and energy efficient hardware implementations. Studies
investigating the use of reservoir computing as a language model remain sparse.
In this paper, we compare three distinct approaches for character-level
language modeling, two different reservoir computing approaches, where only an
output layer is trainable, and the well-known transformer-based architectures,
which fully learn an attention-based sequence representation. We explore the
performance, computational cost and prediction accuracy for both paradigms by
equally varying the number of trainable parameters for all models. Using a
consistent pipeline for all three approaches, we demonstrate that transformers
excel in prediction quality, whereas reservoir computers remain highly
efficient reducing the training and inference speed. Furthermore, we
investigate two types of reservoir computing: a traditional reservoir with a
static linear readout, and an attention-enhanced reservoir that dynamically
adapts its output weights via an attention mechanism. Our findings underline
how these paradigms scale and offer guidelines to balance resource constraints
with performance.

</details>


### [226] [The Impact of Language Mixing on Bilingual LLM Reasoning](https://arxiv.org/abs/2507.15849)
*Yihao Li,Jiayi Xin,Miranda Muqing Miao,Qi Long,Lyle Ungar*

Main category: cs.CL

TL;DR: 双语大语言模型在推理时会混合使用语言，这是一种有益的策略，而不是缺陷。通过特定的训练和引导，可以进一步提升其推理能力。


<details>
  <summary>Details</summary>
Motivation: 研究双语大语言模型（LLM）中的语言混合现象，探究其对推理能力的影响。

Method: 通过识别强化学习与可验证奖励（RLVR）是导致语言混合的关键训练阶段，并设计了轻量级探针来预测和引导语言转换以提升推理能力。

Result: 强制单语解码会使数学推理任务的准确率降低5.6个百分点。轻量级探针可将准确率提高多达6.25个百分点。

Conclusion: 语言混合并非多语言训练的副产品，而是一种有益的推理策略。

Abstract: Proficient multilingual speakers often intentionally switch languages in the
middle of a conversation. Similarly, recent reasoning-focused bilingual large
language models (LLMs) with strong capabilities in both languages exhibit
language mixing--alternating languages within their chain of thought.
Discouraging this behavior in DeepSeek-R1 was found to degrade accuracy,
suggesting that language mixing may benefit reasoning. In this work, we study
language switching in Chinese-English bilingual reasoning models. We identify
reinforcement learning with verifiable rewards (RLVR) as the critical training
stage that leads to language mixing. We demonstrate that language mixing can
enhance reasoning: enforcing monolingual decoding reduces accuracy by 5.6
percentage points on math reasoning tasks. Additionally, a lightweight probe
can be trained to predict whether a potential language switch would benefit or
harm reasoning, and when used to guide decoding, increases accuracy by up to
6.25 percentage points. Our findings suggest that language mixing is not merely
a byproduct of multilingual training, but is a strategic reasoning behavior.

</details>


### [227] [3LM: Bridging Arabic, STEM, and Code through Benchmarking](https://arxiv.org/abs/2507.15850)
*Basma El Amel Boussaha,Leen AlQadi,Mugariya Farooq,Shaikha Alsuwaidi,Giulia Campesan,Ahmed Alzubaidi,Mohammed Alyafeai,Hakim Hacid*

Main category: cs.CL

TL;DR: 为了弥补阿语大语言模型在STEM和代码领域评估基准的不足，本研究提出了三个新的基准：STEM问答、合成STEM问题和代码生成。


<details>
  <summary>Details</summary>
Motivation: 现有阿语大语言模型（LLM）的评估基准主要集中在语言、文化或宗教内容，而在STEM和代码等与现实应用日益相关的领域存在显著不足。

Method: 通过收集阿语教材和练习题，创建了STEM问答对和合成STEM问题；同时，翻译了两个广泛使用的代码基准，并结合人工评审流程，创建了代码生成基准。

Result: 发布了三个针对阿语的基准：STEM问答对、合成STEM问题和代码生成，以支持阿语LLM在这些关键但代表性不足的领域的研究。

Conclusion: 该研究发布了三个新的阿语基准，以解决现有基准在STEM和代码领域存在不足的问题，旨在促进阿语大语言模型在该领域的研究和应用。

Abstract: Arabic is one of the most widely spoken languages in the world, yet efforts
to develop and evaluate Large Language Models (LLMs) for Arabic remain
relatively limited. Most existing Arabic benchmarks focus on linguistic,
cultural, or religious content, leaving a significant gap in domains like STEM
and code which are increasingly relevant for real-world LLM applications. To
help bridge this gap, we present 3LM, a suite of three benchmarks designed
specifically for Arabic. The first is a set of STEM-related question-answer
pairs, naturally sourced from Arabic textbooks and educational worksheets. The
second consists of synthetically generated STEM questions, created using the
same sources. The third benchmark focuses on code generation, built through a
careful translation of two widely used code benchmarks, incorporating a
human-in-the-loop process with several rounds of review to ensure high-quality
and faithful translations. We release all three benchmarks publicly to support
the growth of Arabic LLM research in these essential but underrepresented
areas.

</details>


<div id='cs.NE'></div>

# cs.NE [[Back]](#toc)

### [228] [APTx Neuron: A Unified Trainable Neuron Architecture Integrating Activation and Computation](https://arxiv.org/abs/2507.14270)
*Ravin Kumar*

Main category: cs.NE

TL;DR: 提出APTx Neuron，一种集成了激活和线性变换的统一神经元，在MNIST上达到96.69%准确率，效率高。


<details>
  <summary>Details</summary>
Motivation: 为了提高神经网络的计算效率和架构的优雅性，消除对独立激活层和线性变换层的需求。

Method: 提出了一种名为APTx Neuron的新型统一神经元计算单元，它将非线性激活和线性变换融合到一个可训练的表达式中。该神经元基于APTx激活函数，数学形式为 $y = \sum_{i=1}^{n} ((\alpha_i + \tanh(\beta_i x_i)) \cdot \gamma_i x_i) + \delta$，其中所有参数 $\alpha_i$, $\beta_i$, $\gamma_i$, 和 $\delta$ 均可训练。

Result: 在MNIST数据集上，基于APTx Neuron的架构在20个epoch内达到了96.69%的测试准确率，模型参数量约为332K。实验结果表明APTx Neuron比传统神经元具有更优越的表达能力和计算效率。

Conclusion: APTx Neuron的架构在MNIST数据集上表现出色，准确率高达96.69%，并且训练速度快（仅20个epoch），参数量少（约332K），证明了其相对于传统神经元具有更强的表达能力和计算效率，为统一神经元设计开辟了新方向。

Abstract: We propose the APTx Neuron, a novel, unified neural computation unit that
integrates non-linear activation and linear transformation into a single
trainable expression. The APTx Neuron is derived from the APTx activation
function, thereby eliminating the need for separate activation layers and
making the architecture both computationally efficient and elegant. The
proposed neuron follows the functional form $y = \sum_{i=1}^{n} ((\alpha_i +
\tanh(\beta_i x_i)) \cdot \gamma_i x_i) + \delta$, where all parameters
$\alpha_i$, $\beta_i$, $\gamma_i$, and $\delta$ are trainable. We validate our
APTx Neuron-based architecture on the MNIST dataset, achieving up to 96.69\%
test accuracy in just 20 epochs using approximately 332K trainable parameters.
The results highlight the superior expressiveness and computational efficiency
of the APTx Neuron compared to traditional neurons, pointing toward a new
paradigm in unified neuron design and the architectures built upon it.

</details>


### [229] [Training oscillator Ising machines to assign the dynamic stability of their equilibrium points](https://arxiv.org/abs/2507.14386)
*Yi Cheng,Zongli Lin*

Main category: cs.NE

TL;DR: 提出了一种新的 Hamiltonian-Regularized Eigenvalue Contrastive Method (HRECM)，用于训练振荡器伊辛机 (OIM) 的耦合权重，以实现 Hopfield 类似的联想记忆。该方法通过分配平衡点的稳定性来存储模式，简化了传统 Hopfield 模型的设计。


<details>
  <summary>Details</summary>
Motivation: 为了在 Hopfield 神经网络模型中实现 Hopfield 类似联想记忆，并解决传统 Hopfield 模型在设计耦合权重时需要同时考虑平衡点的存在和动态稳定性这一挑战。

Method: 提出了一种 Hamiltonian-Regularized Eigenvalue Contrastive Method (HRECM) 来训练 OIM 的耦合权重，以分配适当的稳定性给其平衡点。

Result: OIM 实现了 Hopfield 类似的联想记忆，并且其耦合权重的设计只需要关注为平衡点分配适当的稳定性，而无需考虑平衡点的存在性。

Conclusion: 所提出的方法通过数值实验得到了验证。

Abstract: We propose a neural network model, which, with appropriate assignment of the
stability of its equilibrium points (EPs), achieves Hopfield-like associative
memory. The oscillator Ising machine (OIM) is an ideal candidates for such a
model, as all its $0/\pi$ binary EPs are structurally stable with their dynamic
stability tunable by the coupling weights. Traditional Hopfield-based models
store the desired patterns by designing the coupling weights between neurons.
The design of coupling weights should simultaneously take into account both the
existence and the dynamic stability of the EPs for the storage of the desired
patterns. For OIMs, since all $0/\pi$ binary EPs are structurally stable, the
design of the coupling weights needs only to focus on assigning appropriate
stability for the $0/\pi$ binary EPs according to the desired patterns. In this
paper, we establish a connection between the stability and the Hamiltonian
energy of EPs for OIMs, and, based on this connection, provide a
Hamiltonian-Regularized Eigenvalue Contrastive Method (HRECM) to train the
coupling weights of OIMs for assigning appropriate stability to their EPs.
Finally, numerical experiments are performed to validate the effectiveness of
the proposed method.

</details>


### [230] [Analyzing Internal Activity and Robustness of SNNs Across Neuron Parameter Space](https://arxiv.org/abs/2507.14757)
*Szymon Mazurek,Jakub Caputa,Maciej Wielgosz*

Main category: cs.NE

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Spiking Neural Networks (SNNs) offer energy-efficient and biologically
plausible alternatives to traditional artificial neural networks, but their
performance depends critically on the tuning of neuron model parameters. In
this work, we identify and characterize an operational space - a constrained
region in the neuron hyperparameter domain (specifically membrane time constant
tau and voltage threshold vth) - within which the network exhibits meaningful
activity and functional behavior. Operating inside this manifold yields optimal
trade-offs between classification accuracy and spiking activity, while stepping
outside leads to degeneration: either excessive energy use or complete network
silence.
  Through systematic exploration across datasets and architectures, we
visualize and quantify this manifold and identify efficient operating points.
We further assess robustness to adversarial noise, showing that SNNs exhibit
increased spike correlation and internal synchrony when operating outside their
optimal region. These findings highlight the importance of principled
hyperparameter tuning to ensure both task performance and energy efficiency.
Our results offer practical guidelines for deploying robust and efficient SNNs,
particularly in neuromorphic computing scenarios.

</details>


### [231] [DHEvo: Data-Algorithm Based Heuristic Evolution for Generalizable MILP Solving](https://arxiv.org/abs/2507.15615)
*Zhihao Zhang,Siyuan Li,Chenxi Li,Feifan Liu,Mengjing Chen,Kai Li,Tao Zhong,Bo An,Peng Liu*

Main category: cs.NE

TL;DR: 通过数据-算法协同进化框架（DHEvo）和基于大语言模型（LLM）的多智能体系统，解决了现有LLM方法在混合整数规划（MILP）启发式方法生成中的泛化能力不足的问题，实现了更优的求解性能。


<details>
  <summary>Details</summary>
Motivation: 现有的基于大语言模型的LLM方法生成的启发式方法虽然比手工设计的启发式方法有更好的求解性能，但适应性较差，且仅限于某一问题类别中的少数混合整数规划（MILP）实例，无法捕捉问题类别中的实例特征。这是因为混合整数规划（MILP）实例在结构和特征分布上常常存在显著差异，而在进化过程中忽略这些特征会导致在同一问题类别中的泛化能力较差。

Method: 提出了一种数据-算法协同进化框架（DHEvo），通过迭代选择代表性实例并演化相应的启发式方法。利用基于大语言模型的LLM的多智能体系统同时生成数据-代码对，并根据适应度分数迭代优化这些数据-代码对，从而识别出在整个问题类中最为有效的启发式方法。

Result: 所提出的方法显著优于手工设计的启发式方法和现有的基于大语言模型的LLM方法。

Conclusion: 该方法在各种混合整数规划基准测试中显著优于手工设计的启发式方法和现有的基于大语言模型的LLM方法。

Abstract: Primal heuristics play a critical role in improving the efficiency of mixed
integer programming (MILP) solvers. As large language models (LLMs) have
demonstrated superior code generation abilities, recent MILP works are devoted
to leveraging the evolutionary computation approaches with LLMs to generate
effective primal heuristics. Although the generated heuristics have achieved
better solving performance than the hand-crafted ones with little adaptability,
the advantage of current LLM-based methods is limited to few MILP instances in
one problem class, as they fail to capture the instance characteristics in the
problem class (the MILP instances generated from the same mathematical model
are defined as a problem class). Since MILP instances often differ
significantly in structure and feature distribution, the neglect of their
characteristics in the evolution process results in poor generalization within
the same problem class. To overcome this challenge, we propose a data-algorithm
co-evolution framework (DHEvo) that iteratively selects representative
instances and evolves corresponding heuristics. With the initial instance
distribution, we develop an LLM-based multi-agent system to generate data-code
pairs simultaneously. These data-code pairs are iteratively refined based on
their fitness scores, leading to the identification of the most effective
heuristic over the entire problem class. Extensive experiments across diverse
MILP benchmarks demonstrate that our approach significantly outperforms both
human-designed heuristics and existing LLM-based methods.

</details>


### [232] [TONUS: Neuromorphic human pose estimation for artistic sound co-creation](https://arxiv.org/abs/2507.15734)
*Jules Lecomte,Konrad Zinner,Michael Neumeier,Axel von Arnim*

Main category: cs.NE

TL;DR: 通过神经形态身体传感技术，创造了一个艺术装置，实现了人与机器之间更自然、更富有诗意的交互，共同生成声音景观。


<details>
  <summary>Details</summary>
Motivation: 当前人机交互在艺术和工业领域虽日益广泛，但往往过于技术化和以机器为主导，未能充分激发人的想象力和诗意。现有技术在艺术领域的应用也未能完全发挥其潜力。因此，需要一种更自然、更具诗意的交互方式。

Method: 提出并设计了一个神经形态多头人体姿态估计神经网络传感器，该传感器能够通过精细的身体动作控制来塑造声音景观和视觉输出。其中，特征提取器是为专用神经形态芯片量身定制的脉冲神经网络。

Result: 参观者沉浸在声音氛围和由神经处理的自身映射中，体验到与一个与他们一样进行神经思考的机器的对话，从而实现了人与机器的共创。

Conclusion: 该研究提出了一个新颖的艺术装置，利用神经形态身体传感技术，实现了人与机器之间更具诗意和沉浸式的互动，共同创造声音景观。

Abstract: Human machine interaction is a huge source of inspiration in today's media
art and digital design, as machines and humans merge together more and more.
Its place in art reflects its growing applications in industry, such as
robotics. However, those interactions often remains too technical and
machine-driven for people to really engage into. On the artistic side, new
technologies are often not explored in their full potential and lag a bit
behind, so that state-of-the-art research does not make its way up to museums
and exhibitions. Machines should support people's imagination and poetry in a
seamless interface to their body or soul. We propose an artistic sound
installation featuring neuromorphic body sensing to support a direct yet non
intrusive interaction with the visitor with the purpose of creating sound
scapes together with the machine. We design a neuromorphic multihead human pose
estimation neural sensor that shapes sound scapes and visual output with fine
body movement control. In particular, the feature extractor is a spiking neural
network tailored for a dedicated neuromorphic chip. The visitor, immersed in a
sound atmosphere and a neurally processed representation of themselves that
they control, experience the dialogue with a machine that thinks neurally,
similarly to them.

</details>


<div id='cond-mat.mes-hall'></div>

# cond-mat.mes-hall [[Back]](#toc)

### [233] [Martini 3 application for the design of bistable nanomachines](https://arxiv.org/abs/2507.14319)
*Alexander D. Muratov,Vladik A. Avetisov*

Main category: cond-mat.mes-hall

TL;DR: Researchers developed coarse-grained models using the Martini method to study the long-time behavior of foldamers after all-atom molecular dynamics simulations faced time limitations.


<details>
  <summary>Details</summary>
Motivation: Previous all-atom molecular dynamics modeling identified foldamers resembling bistable machines, but time limitations necessitated the development of a coarse-grained model for long-time behavior investigation.

Method: The study uses the Martini method to develop coarse-grained models.

Result: Coarse-grained models were developed using the Martini method.

Conclusion: The paper summarizes recent research on developing coarse-grained models using the Martini method.

Abstract: During our previous modeling using all-atom molecular dynamics, we have
identified several foldamers whose nanoscale behavior resembles that of classic
bistable machines, namely the Euler archs and Duffing oscillators. However,
time limitations of the all-atom molecular dynamics prevent us from performing
a full-scale investigation of long-time behavior and prompt us to develop a
coarse-grained model. In this work, we summarize our recent research on
developing such models using the most widely available method called Martini.

</details>


### [234] [Supercurrent tuning of the Josephson coupling energy](https://arxiv.org/abs/2507.14357)
*Maxwell Wisne,Venkat Chandrasekhar*

Main category: cond-mat.mes-hall

TL;DR: 该研究提出了一种新的方法来调谐约瑟夫森结的能量，无需磁通量回路，从而降低了量子比特对磁噪声的敏感性，有望实现更高性能的量子比特。


<details>
  <summary>Details</summary>
Motivation: 为了解决传统约瑟夫森结调谐中磁通量回路暴露于磁噪声的问题，并实现频率可调量子比特。

Method: 通过将超导线耦合到器件，并用超电流偏置约瑟夫森结来调节其约瑟夫森能量，而无需磁通量回路。

Result: 提出了一种多端器件，通过超电流调节约瑟夫森能量，可减少对磁通噪声的敏感性。

Conclusion: 该器件可以通过超电流调节约瑟夫森能量，从而无需磁通量回路即可调谐约瑟夫森结的约瑟夫森耦合能量，有望实现低磁通噪声的频率可调量子比特。

Abstract: The ability to non-dissipatively tune the Josephson coupling energy of
Josephson junctions is a useful tool in frequency-tunable qubits. This is
typically done by threading magnetic flux through two junctions connected in a
loop, a geometry that exposes the qubit to magnetic environmental noise. In
this paper, we show that by biasing a junction with supercurrent from a
separate pair of superconducting leads coupled to the device, the Josephson
energy can be tuned without the need for a flux loop. Our multiterminal device
may enable the realization of a frequency-tunable qubit with greatly reduced
susceptibility to flux noise.

</details>


### [235] [Chiral-induced circularly polarized light emission from a single-molecule junction](https://arxiv.org/abs/2507.14364)
*Natalya A Zimbovskaya*

Main category: cond-mat.mes-hall

TL;DR: Chiral molecule junctions can emit circularly polarized light, dependent on bias and propagation direction, due to molecular properties, not magnetic interactions.


<details>
  <summary>Details</summary>
Motivation: Analyze electroluminescence in a biased single-molecule junction with a chiral bridge.

Method: Theoretical analysis of electroluminescence in a biased single-molecule junction with a chiral bridge imitated by a helical chain.

Result: Demonstrated that circular polarized light emission can occur, with handedness dependent on propagation direction and bias voltage polarity, provided strong coupling between bridge sites.

Conclusion: If the coupling between the bridge sites is sufficiently strong, optical transitions between electron states of the chiral linker can result in the emission of circular polarized light whose handedness depends on both direction of propagation and the polarity of the bias voltage. This mechanism is controlled by the chiral properties of the bridge molecule and the bias voltage distribution, not by magnetic moments or spin-orbit interactions.

Abstract: In the present work we theoretically analyze electroluminescence occurring in
a biased single-molecule junction with a chiral bridge imitated by a helical
chain. We show that optical transitions between electron states of the chiral
linker may result in the emission of circular polarized light whose handedness
depends on both direction of propagation and the polarity of the bias voltage
provided that the coupling between the bridge sites is sufficiently strong. The
mechanism controlling this specific light emission does not depend on the
magnetic moments and spin-orbit interactions. It rather relies on the chiral
properties of the bridge molecule and on the distribution of the bias voltage
between the electrodes in the junction.

</details>


### [236] [Dynamic annihilation pathways of magnetic skyrmions](https://arxiv.org/abs/2507.14365)
*Matthew Copus,Ezio Iacocca*

Main category: cond-mat.mes-hall

TL;DR: 伪谱方法比传统微磁模拟更适合模拟原子尺度磁孤子动力学。


<details>
  <summary>Details</summary>
Motivation: 传统的数值模拟方法在处理原子尺度的磁孤子时精度会受到模型细节的影响，需要更精确的模型来研究磁孤子的动力学行为。

Method: 采用伪谱方法和传统的微磁模拟方法，研究二维磁性斯格明子的湮灭动力学，并对比两者在处理交换相互作用、晶格化、空间离散化等方面的差异和影响。

Result: 伪谱方法在模拟斯格明子湮灭时，能跨越不同长度尺度保持一致性，并能捕捉到斯格明子呼吸等复杂行为，且所需的磁场也与微磁模拟有所不同，证明了其在跨尺度模拟方面的优越性。

Conclusion: 本研究表明，对于亚原子尺度的磁孤子，伪谱方法比传统的微磁模拟能更准确地描述其动力学行为，并能捕捉到诸如呼吸等复杂现象，这对于未来磁性材料和器件的建模具有重要意义。

Abstract: The investigation of magnetic solitons often relies on numerical modeling to
determine key features such as stability, annihilation, nucleation, and motion.
However, as soliton sizes approach atomic length scales, the accuracy of these
predictions become increasingly sensitive to the details of the numerical
model. Here, we study the annihilation of two-dimensional magnetic skyrmions
using a pseudospectral approach and compare its performance to that of
conventional micromagnetic simulations. A central distinction between the
models lies in their treatment of the exchange interaction, which governs the
magnon dispersion relation and plays a crucial role to balance the uniaxial
anisotropy to stabilise skyrmions. We demonstrate that both the choice of model
and spatial discretisation significantly influence the skyrmion dynamics and
the magnetic field required for annihilation. The pseudospectral model provides
a consistent description across length scales and captures complex behaviours
such as skyrmion breathing on its path to annihilation. Our results have direct
implications in the state-of-the-art modeling of skyrmions and other
two-dimensional textures and will impact the modeling of three-dimensional
textures such as hopfions.

</details>


### [237] [Critical angles and one-dimensional moiré physics in twisted rectangular lattices](https://arxiv.org/abs/2507.14435)
*Dongdong An,Tao Zhang,Qiaoling Xu,Hailing Guo,Majeed Ur Rehman,Dante M. Kennes,Angel Rubio,Lei Wang,Lede Xian*

Main category: cond-mat.mes-hall

TL;DR: PdSe2等矩形晶格材料的扭转双层结构可以形成1D Moiré超晶格，并产生1D平带和强自旋-轨道耦合效应，为低维度物理研究提供了新平台。


<details>
  <summary>Details</summary>
Motivation: 工程化的Moiré超晶格在控制涌现的电子、结构和光学性质方面发挥着至关重要的作用，从而影响拓扑和相关现象。但是，以往对Moiré超晶格的研究主要集中在具有六方晶格的材料上，而具有矩形晶格的材料（如PdSe2）在Moiré超晶格工程方面的潜力尚未得到充分探索。

Method: 通过密度泛函理论（DFT）描述扭转双层PdSe2的电子特性，揭示了方向性局域化的平坦能带结构、局域化电荷密度以及沿色散方向的强自旋-轨道耦合。

Result: 在具有矩形晶格的扭转双层范德华材料（如PdSe2）中，1D Moiré模式普遍出现。研究了这些独特的1D Moiré模式的几何起源，并开发了一个通用的数学框架来预测扭转矩矩形晶格中的临界扭转角（CAs）。

Conclusion: 扭转矩约40%的PdSe2双层材料中出现的1D角向能带和1D自旋轨道耦合电子系统，为低对称性、低维度强关联和拓扑物理学以及空间选择性量子相工程提供了一个独特的平台。

Abstract: Engineering moir\'e superlattices in van der Waals heterostructures provides
fundamental control over emergent electronic, structural, and optical
properties allowing to affect topological and correlated phenomena. This
control is achieved through imposed periodic modulation of potentials and
targeted modifications of symmetries. For twisted bilayers of van der Waals
materials with rectangular lattices, such as PdSe2, this work shows that
one-dimensional (1D) moir\'e patterns emerge universally. This emergence is
driven by a series of critical twist angles (CAs). We investigate the geometric
origins of these unique 1D moir\'e patterns and develop a universal
mathematical framework to predict the CAs in twisted rectangular lattices.
Through a density functional theory (DFT) description of the electronic
properties of twisted bilayer PdSe2, we further reveal directionally localized
flat band structures, localized charge densities and strong spin-orbit coupling
along the dispersive direction which points to the emergence of an effectively
1D strongly spin-orbit coupled electronic systems. This establishes twisted
rectangular systems as a unique platform for engineering low-symmetry moir\'e
patterns, low-dimensional strongly correlated and topological physics, and
spatially selective quantum phases beyond the isotropic paradigms of hexagonal
moir\'e materials.

</details>


### [238] [Light-Induced Giant Enhancement of the Nonlinear Hall Effect in Two-Dimensional Electron Gases at KTaO3 (111) Interfaces](https://arxiv.org/abs/2507.14476)
*Hui Zhang,Daming Tian,Xiaobing Chen,Weijian Qi,Lu Chen,Min Li,Yetong Bai,Jine Zhang,Furong Han,Huaiwen Yang,Yuansha Chen,Yunzhong Chen,Jing Wu,Yongbing Xu,Fengxia Hu,Baogen Shen,Jirong Sun,Weisheng Zhao*

Main category: cond-mat.mes-hall

TL;DR: 通过光照显著增强和调控氧化物二维电子气中的非线性霍尔效应，为光控整流和非线性电子器件开辟了道路。


<details>
  <summary>Details</summary>
Motivation: 为了解决非线性霍尔效应信号幅度小，难以应用于器件的问题，探索了提高和调控非线性霍尔效应的方法。

Method: 通过实验测量和第一性原理计算相结合的方法，研究了CaZrO3/KTaO3 (111)界面二维电子气在光照下的非线性霍尔效应。

Result: 在光照下，观察到了非线性霍尔电压和二阶横向电导率的显著增强（近五个数量级）和符号反转。通过光栅调控，证明了倾斜散射是主导机制，并解释了实验观察到的符号反转现象。

Conclusion: 这项工作通过光照显著增强并调控了氧化物二维电子气中的非线性霍尔效应，为开发光控整流和非线性电子器件提供了新的策略。

Abstract: The nonlinear Hall effect (NLHE), an emergent phenomenon in
noncentrosymmetric systems, enables the generation of a transverse voltage
without an external magnetic field through a second-order electrical response.
However, achieving a sizable NLHE signal remains a critical challenge for its
application in frequency-doubling and rectifying devices. Here, we report a
light-induced giant enhancement of the NLHE in the two-dimensional electron gas
(2DEG) at the CaZrO3/KTaO3 (111) interface. Under light illumination, the
second harmonic Hall voltage (V2{\omega} y) increases substantially and
undergoes a sign reversal. Correspondingly,the second-order transverse
conductivity increases by nearly five orders of magnitude, reaching 2.4 um V-1
omega-1, while also reversing its sign. Scaling analysis indicates that skew
scattering is the dominant mechanism underlying the NLHE and is highly tunable
via optical gating. Photoexcitation pumps electrons from in-gap states into the
higher-lying Ta 5d conduction band, generating high-mobility photocarriers that
significantly increase the cubic transport scattering time, thereby driving a
dramatic enhancement of {\sigma}(2) yxx. First-principles calculations further
reveal that the Berry curvature distribution on the Fermi surface strongly
depends on band filling. As the Fermi level approaches a band crossing in the
Ta 5d subband near the M point, the Berry curvature triple undergoes a sign
change, accounting for the experimentally observed sign reversal of the
nonlinear Hall response. Our work offers a new strategy to optically boost and
tune the nonlinear Hall effect in oxide 2DEG systems, paving the way for
applications in light-controlled rectification and nonlinear electronic
devices.

</details>


### [239] [Supersolidity in Optically Trapped Polariton Condensates](https://arxiv.org/abs/2507.14585)
*P. N. Kozhevin,A. D. Liubomirov,R. V. Cherbunin,M. A. Chukeev,I. Yu. Chestnov,A. V. Kavokin,A. V. Nalitov*

Main category: cond-mat.mes-hall

TL;DR: 在光学陷阱中，激子-极化子超流体因吸引相互作用表现出超固态。


<details>
  <summary>Details</summary>
Motivation: 提出激子-极化子超流体作为一种新的、有希望的超固态研究平台。

Method: 通过实验观测和理论分析（包括平均场理论和数值模拟）来研究激子-极化子超流体。

Result: 观察到自发形成的具有空间有序相的超固态，并通过零能Nambu-Goldstone模式的形成进一步证实了其自发性。

Conclusion: 实验证明了在光学诱导的环形陷阱中，激子-极化子超流体由于有效的吸引相互作用而表现出超固态相变。

Abstract: Superfluids under specific conditions can exhibit spontaneous breaking of
continuous translation symmetries and form exotic spatially ordered states of
matter known as supersolids. Despite its early theoretical prediction, it took
over half-a-centrury to experimentally demonstrate the supersolid phase in
ultracold atomic Bose-Einstein condensates, forming due to long-range
interatomic interactions. Here we propose as a promising new platform for
supersolidity exciton-polariton superfluids, confined in annular optically
induced traps. The supersolid phase emerges due to effective attractive
interactions, mediated by the normal excitonic component of the system.
Experimental demonstration of spontaneously formed spatially ordered phase is
in agreement with detailed mean-field theoretical analysis and numerical
simulation. The spontaneous character of the observed supersolid transition is
further evidenced by the formation of specific zero-energy Nambu-Goldstone
modes in the collective excitation spectrum.

</details>


### [240] [Floquet composite Dirac semimetals](https://arxiv.org/abs/2507.14618)
*Hong Wu,Jia-Ji Zhu,Jian Li,Xue-Min Yang,Jiang-Shan Chen,Mu Zhou*

Main category: cond-mat.mes-hall

TL;DR: 研究提出了一种在Floquet系统中诱导复合狄拉克半金属的方法，可实现I、II、III型狄拉克点的共存。


<details>
  <summary>Details</summary>
Motivation: 为了研究不同狄拉克点相互作用产生的影响，以及狄拉克点是否能在单个系统中共存。

Method: 提出了一种在Floquet四带系统中诱导复合狄拉克半金属的方案，并建立了描述Floquet系统中狄拉克半金属的通用描述。

Result: 成功诱导了同时包含I、II和III型狄拉克点的狄拉克半金属，该系统可通过delta函数或谐波驱动实现。

Conclusion: 本研究提出了在具有时间反演和空间反称的Floquet四带系统中诱导复合狄拉克半金属的方案，实现了 I、II 和 III 型狄拉克点的共存。

Abstract: Dirac semimetals are classified into types I, II, and III based on the
topological charge of their Dirac points. If a three-dimensional (3D) system
can be sliced into a family of $k_z$-dependent normal and topological
insulators, type I Dirac points separate a 2D normal insulator from a 2D
first-order topological insulator, while type II (III) Dirac points separate a
2D normal (first-order) insulator from a 2D second-order topological insulator.
To investigate the effects arising from the interplay of distinct Dirac points,
one may wonder whether these Dirac points can coexist in single system. Here,
we propose a scheme to induce composite Dirac semimetals in a Floquet four-band
system with time-reversal and space-inversion symmetries. A general description
is established to characterize Dirac semimetals in Floquet systems. The results
show that Dirac semimetals hosting coexisting type I, II, and III Dirac points
can be induced by delta-function or harmonic driving. Our results provide a
promising new avenue for exploring novel Dirac semimetals.

</details>


### [241] [Fluctuation-induced Hall-like lateral forces in a chiral-gain environment](https://arxiv.org/abs/2507.14754)
*Daigo Oue,Mário G. Silveirinha*

Main category: cond-mat.mes-hall

TL;DR: 真空涨落可诱导颗粒横向力，与量子几何和非线性霍尔电流相关。


<details>
  <summary>Details</summary>
Motivation: 探索真空涨落与材料的非厄米特性（特别是手性增益）如何相互作用，以产生宏观效应，如颗粒的横向力。

Method: 通过理论分析，展示了真空涨落如何通过具有手性增益的非厄米衬底对小颗粒产生横向力，并将此效应与量子几何、Berry曲率偶极以及非线性霍尔电流联系起来。

Result: 真空涨落可以诱导小颗粒的横向力，该力与材料的量子几何（Berry曲率偶极）和非线性霍尔电流相关，即使增益由电流驱动，该力也垂直于偏置。

Conclusion: 该研究揭示了真空涨落如何在具有手性增益的均匀非厄米衬底附近诱导小颗粒的横向力，并将此效应与量子几何和非线性霍尔电流联系起来，为纳米尺度控制提供了新的可能性。

Abstract: Here, we demonstrate that vacuum fluctuations can induce lateral forces on a
small particle positioned near a translation-invariant uniform non-Hermitian
substrate with chiral gain. This type of non-Hermitian response can be
engineered by biasing a low-symmetry conductor with a static electric field and
is rooted in the quantum geometry of the material through the Berry curvature
dipole. The chiral-gain material acts as an active medium for a particular
circular polarisation handedness, while serving as a passive, dissipative
medium for the other polarisation handedness. Owing to the nonreciprocity and
gain characteristics, momentum is continuously exchanged in a preferred
direction parallel to the surface between the test particle and the surrounding
electromagnetic field, giving rise to lateral forces. Interestingly, the force
can be viewed as a fluctuation-induced drag linked to the nonlinear Hall
current. Indeed, although the gain is driven by an electric current, the
resulting force acts perpendicular to the bias -- unlike conventional
current-drag effects. This effect stems from the skewed propagation
characteristics of surface modes and gain-momentum locking. Our theory reveals
a Hall-like asymmetry in the field correlations and establishes a novel link
between quantum geometry and fluctuation-induced phenomena, offering new
possibilities for nanoscale control via tailored electromagnetic environments.

</details>


### [242] [Enhanced phonon-drag by nanoscale design of homoepitaxial \hbox{$β$-Ga$_2$O$_3$}](https://arxiv.org/abs/2507.14763)
*J. Boy,R. Mitdank,A. Popp,Z. Galazka,S. F. Fischer*

Main category: cond-mat.mes-hall

TL;DR: Geometric control of phonon drag in $\beta$-Ga$_2$O$_3$ films enhances thermopower for thermoelectric devices. Thinner films (below 75 nm) exhibit quasi-2D electron-phonon interaction and significantly increased phonon-drag effect compared to bulk.


<details>
  <summary>Details</summary>
Motivation: To harness phonon drag for thermoelectric generators and devices by demonstrating geometric control of its contribution to the thermopower.

Method: Demonstrated geometric control of phonon-drag thermopower in nanometer-thin $eta$-Ga$_2$O$_3$ films by varying film thickness and analyzed temperature-dependent Seebeck coefficients.

Result: Enhanced phonon-drag contribution to thermopower from -0.4 mV/K to -3 mV/K at 100 K by reducing film thickness. Observed crossover from 3D to quasi-2D electron-phonon interaction below 75 nm thickness. Found that the ratio of phonon-phonon to electron-phonon relaxation times is 10 times larger in confined structures compared to bulk. Established that phonon drag can be enhanced when $\lambda_\text{PD}\gg\lambda>d$.

Conclusion: Phonon drag can be tuned by controlling film thickness, which affects electron-phonon interactions and relaxation times, showing potential for thermoelectric applications.

Abstract: Phonon drag may be harnessed for thermoelectric generators and devices. Here,
we demonstrate the geometric control of the phonon-drag contribution to the
thermopower. In nanometer-thin electrically conducting $\beta$-Ga$_2$O$_3$
films homoepitaxially-grown on insulating substrates it is enhanced from -0,4
mV/K to up to -3 mV/K at 100 K by choice of the film thickness. Analysis of the
temperature-dependent Seebeck coefficients reveal that a crossover from
three-dimensional to quasi-two-dimensional electron-phonon interaction occurs
for film thicknesses below 75~nm. The ratio of phonon-phonon to electron-phonon
relaxation times in these confined structures is $10$ times larger than that of
bulk. Generally the phonon drag can be tuned depending on the relations between
the phonon-drag interaction length $\lambda_\text{PD}$, the phonon mean free
path $\lambda$ and the film thickness $d$. Phonon drag can be enhanced for
$\lambda_\text{PD}\gg\lambda>d$.

</details>


### [243] [Potential barriers are nearly-ideal quantum thermoelectrics at finite power output](https://arxiv.org/abs/2507.14977)
*Chaimae Chrirou,Abderrahim El Allati,Robert S Whitney*

Main category: cond-mat.mes-hall

TL;DR: 实验中常用的阶跃透射热电器件效率接近理想值，而洛伦兹透射效率不佳。


<details>
  <summary>Details</summary>
Motivation: 量子热力学定义了具有最大可能效率的理想量子热电器件，但其难以实现。因此，本研究考虑两种实验中常用的热电器件：(i) 有限高度势垒或量子点接触，以及 (ii) 双势垒结构或单层量子点。

Method: 使用 Landauer 散射理论将实验中常用的两种热电器件建模为（i）阶跃透射和（ii）洛伦兹透射。

Result: 阶跃透射在所有功率输出下都非常接近理想效率，而洛伦兹透射在实际功率下效率不佳。阶跃透射在存在声子和其他热泄漏的情况下也接近理想效率，而洛伦兹透射表现很差。

Conclusion: 简单的纳米热电器件，如势垒或量子点接触，在所有功率输出下效率都接近理想值，其效率通常在理想效率的 15% 以内。相比之下，洛伦兹透射的效率在低功率下表现良好，但在实际应用的有限功率下表现不佳。

Abstract: Quantum thermodynamics defines the ideal quantum thermoelectric, with maximum
possible efficiency at finite power output. However, such an ideal
thermoelectric is challenging to implement experimentally. Instead, here we
consider two types of thermoelectrics regularly implemented in experiments: (i)
finite-height potential barriers or quantum point contacts, and (ii)
double-barrier structures or single-level quantum dots. We model them with
Landauer scattering theory as (i) step transmissions and (ii) Lorentzian
transmissions. We optimize their thermodynamic efficiency for any given power
output, when they are used as thermoelectric heat-engines or refrigerators. The
Lorentzian's efficiency is excellent at vanishing power, but we find that it is
poor at the finite powers of practical interest. In contrast, the step
transmission is remarkably close to ideal efficiency (typically within 15%) at
all power outputs. The step transmission is also close to ideal in the presence
of phonons and other heat-leaks, for which the Lorentzian performs very poorly.
Thus, a simple nanoscale thermoelectric - made with a potential barrier or
quantum point contact - is almost as efficient as an ideal thermoelectric.

</details>


### [244] [Quantum Capacitance and Electronic Properties of a Hexagonal Boron Nitride based FET Gas Sensor](https://arxiv.org/abs/2507.15011)
*Saumen Acharjee*

Main category: cond-mat.mes-hall

TL;DR: 本研究使用先进的理论方法研究了h-BN基FET的气体传感特性，发现CO2和NO是有效的传感气体，并提出了优化传感器性能的设计思路。


<details>
  <summary>Details</summary>
Motivation: 对h-BN基FET的气体传感机制进行全面的理论研究，以理解不同气体分子和工作条件对器件性能的影响。

Method: 利用非平衡格林函数形式主义和Landauer-Büttiker方法，结合了场效应、量子输运和温度影响，超越了传统的密度泛函理论分析。

Result: CO2和NO气体引起最强的传感响应，HF次之，H2S最弱。垂直电场可以调节带隙宽度和载流子迁移率，温度会影响传感响应。

Conclusion: 本研究提出了一个全面的理论框架，用于分析h-BN基FET的气体传感特性，并考虑了场效应、量子输运和温度影响。研究结果表明，CO2和NO气体对h-BN的传感响应最强，HF次之，H2S最弱。此外，垂直电场可以调节带隙宽度和载流子迁移率，而温度则会影响电荷转移和吸附/解吸过程。本研究为工程设计h-BN基FET传感器提供了理论指导。

Abstract: We present a comprehensive theoretical investigation of gas sensing in
monolayer hexagonal boron nitride (h-BN) based field-effect transistors (FET)
using the non-equilibrium Green function formalism and Landauer-B\"{u}ttiker
approach. Moving beyond conventional density functional theory analyses, our
framework captures the full device level response by incorporating
field-dependent quantum transport and temperature effects. We model the impact
of NO, H$_2$S, HF and CO$_2$ gases on the band structure and density of states
(DOS), carrier concentration, quantum capacitance and I-V characteristics. The
results indicate that CO$_2$ followed by NO induce strongest perturbations via
mid-gap states and band edge shifts, leading to the appearance of asymmetric
Van-Hove singularities with enhanced carrier modulation and quantum
capacitance. It is observed that HF induce moderate perturbation while H$_2$S
induce weakest response for all temperature and biasing condition. It is found
that an applied vertical electric field narrows the band gap via the Stark
effect, further boosting mobility and tunability. Temperature influences
sensing response by enhancing charge transfer at moderate levels and causing
desorption at higher temperatures. We found that CO$_2$ consistently show the
highest sensitivity and selectivity followed by NO and HF, while H$_2$S display
the weakest response. This study offers a comprehensive framework to engineer
h-BN based FET sensors by harnessing intrinsic band modulation and quantum
capacitance for molecule discrimination and temperature optimization.

</details>


### [245] [$\mathbb{Z}_2$ topological trion insulator](https://arxiv.org/abs/2507.15451)
*Yichen Chu,Qizhong Zhu*

Main category: cond-mat.mes-hall

TL;DR: 研究提出了一种拓扑三子绝缘体，实现了三子的无耗散边缘态，为开发无耗散器件提供了新方向。


<details>
  <summary>Details</summary>
Motivation: 为了在掺杂过渡金属硫属化物（TMDs）中实现用于开发高速激子和光电器件的三子输运性质，并寻找提供三子无耗散输运通道的关键构件。

Method: 通过引入莫尔超晶格势，利用内禀三子极化子的谷-轨道耦合，使莫尔三子极化子能带在特定条件下呈现拓扑性，并计算其 $\mathbb{Z}_2$ 拓扑数。

Result: 发现了莫尔三子极化子能带在特定条件下可实现拓扑化，并提供了两种具体的材料实现（掺杂单层TMD/扭曲hBN衬底和扭曲TMD异质双层），证明了其对电荷屏蔽的鲁棒性。

Conclusion: 该研究提出了 $\mathbb{Z}_2$ 拓扑三子极化子绝缘体概念，为三子提供螺旋无耗散边缘态，并在掺杂的单层过渡金属硫属化物和扭曲的过渡金属硫属化物异质双层中实现了该概念，证明了其在电荷屏蔽下的鲁棒性，为实现无耗散激子器件铺平了道路。

Abstract: Trions, charged quasiparticles formed by binding an exciton to an excess
charge carrier, dominate the optical response of doped transition metal
dichalcogenides (TMDs), and the study of the transport properties of trions in
TMDs may have application in developing high-speed excitonic and optoelectronic
devices. However, an important building block for low-dissipation
optoelectronic devices that provides dissipationless transport channels for
trions has remained elusive. Here, we propose the concept of a $\mathbb{Z}_2$
topological trion insulator that features helical dissipationless edge states
for trions. This is realized for intralayer trions, which inherit the
valley-orbit coupling of intralayer excitons in TMDs subject to a moir\'e
periodic potential. We find that under certain circumstances, the moir\'e trion
band becomes topological, characterized by the $\mathbb{Z}_2$ topological
number. We further provide two specific material realizations of this
$\mathbb{Z}_2$ topological insulator: a doped monolayer TMD placed on top of a
twisted hBN substrate, and a generic twisted TMD heterobilayer. We also examine
the effect of charge screening and find that the $\mathbb{Z}_2$ topological
trion insulator remains robust. Our work paves the way toward realizing
dissipationless excitonic devices.

</details>


### [246] [Skyrmion Hall effect and shape deformation of current-driven bilayer skyrmions in synthetic antiferromagnets](https://arxiv.org/abs/2507.15531)
*Mu-Kun Lee,Javier A. Vélez,Rubén M. Otxoa,Masahito Mochizuki*

Main category: cond-mat.mes-hall

TL;DR: This paper investigates bilayer skyrmions in synthetic antiferromagnets and finds that Bloch-type skyrmions exhibit a Hall effect under spin-orbit torque, unlike Nepresentation{e}el-type skyrmions. It also details current-induced deformations and provides theoretical explanations crucial for memory applications.


<details>
  <summary>Details</summary>
Motivation: The motivation behind this research is to reconsider the commonly believed absence of the skyrmion Hall effect for topologically trivial magnetic skyrmions, specifically focusing on bilayer skyrmions in synthetic antiferromagnets. The study aims to understand the behavior of these skyrmions under different driving torques (spin-transfer and spin-orbit) and to provide insights relevant to applications in antiferromagnetic skyrmion-based technologies like racetrack memory.

Method: This paper utilizes a general Lagrangian formalism to analyze the behavior of bilayer skyrmions in synthetic antiferromagnets under the influence of spin-transfer and spin-orbit torques. The study also incorporates micromagnetic simulations to validate theoretical predictions and derives relationships between physical quantities such as velocity and longitudinal radius. An intuitive explanation for the skyrmion Hall effect is provided based on antiferromagnetic exchange torque.

Result: The paper demonstrates that Bloch-type bilayer skyrmions acquire a finite Hall angle when driven by spin-orbit torque, a phenomenon not observed in Nepresentation{e}el-type skyrmions, as confirmed by micromagnetic simulations. It also shows that both skyrmion types exhibit current-induced elliptical deformation, with a linear relationship between velocity and longitudinal radius that is proportional to the spin-orbit torque strength. The study reproduces a previously reported linear Hall angle-helicity relation and offers an explanation for the skyrmion Hall effect based on antiferromagnetic exchange torque.

Conclusion:  Bloch-type bilayer skyrmions in synthetic antiferromagnets driven by spin-orbit torque exhibit a finite skyrmion Hall effect, while Nepresentation{e}el-type skyrmions do not. Both types show current-induced elliptical deformation with a linear relation between velocity and longitudinal radius. The derived Lagrange equations explain the Hall angle-helicity relation and provide an intuitive understanding of the skyrmion Hall effect based on antiferromagnetic exchange torque. These findings are crucial for antiferromagnetic skyrmion-based applications like racetrack memory.

Abstract: The commonly believed absence of skyrmion Hall effect for topologically
trivial magnetic skyrmions is reconsidered for bilayer skyrmions in synthetic
antiferromagnets driven by spin-transfer and spin-orbit torques. Using a
general Lagrangian formalism, we show that Bloch-type bilayer skyrmions acquire
a finite Hall angle when driven by spin-orbit torque, while N\'{e}el-type
skyrmions do not, in agreement with micromagnetic simulations. Both types of
skyrmions exhibit current-induced elliptical deformation with minor and major
axes aligned longitudinally and transversely to their velocity, respectively. A
linear relation between velocity and longitudinal radius is derived with a
coefficient proportional to the strength of spin-orbit torque. These effects
are critical for antiferromagnetic skyrmion-based applications such as skyrmion
racetrack memory. The Lagrange equations also reproduce the linear Hall
angle-helicity relation reported by Msiska et al., Phys. Rev. Appl. 17, 064015
(2022). An intuitive explanation of the skyrmion Hall effect for arbitrary
helicity based on the antiferromagnetic exchange torque is also provided.

</details>


### [247] [Interplay of Zeeman Splitting and Tunnel Coupling in Coherent Spin Qubit Shuttling](https://arxiv.org/abs/2507.15554)
*Ssu-Chih Lin,Paul Steinacker,MengKe Feng,Ajit Dash,Santiago Serrano,Wee Han Lim,Kohei M. Itoh,Fay E. Hudson,Tuomo Tanttu,Andre Saraiva,Arne Laucht,Andrew S. Dzurak,Hsi-Sheng Goan,Chih Hwan Yang*

Main category: cond-mat.mes-hall

TL;DR: 通过 Pauli Spin Blockade (PSB) 读出技术，在硅 MOS 器件中实现了 
99.8% 保真度的自旋穿梭，可用于构建可扩展的量子处理器。


<details>
  <summary>Details</summary>
Motivation: 为了开发可扩展的硅基量子处理器，需要解决量子点（QD）的连接性限制。自旋穿梭技术为此提供了一种有前途的解决方案。

Method: 通过利用 Pauli Spin Blockade (PSB) 读出技术，在硅 MOS 器件中实现了高保真度的 bucket-brigade (BB) 自旋穿梭。

Result: 实现了平均 
99.8% 的穿梭保真度，并且发现残余穿梭误差对库仑耦合和泽曼分裂的比例非常敏感。

Conclusion: 自旋穿梭技术为开发可扩展的硅基量子处理器提供了一种有前途的方法，它解决了量子点（QD）的连接性限制。通过对门电压的仔细调整，可以实现高达 20 倍的错误率变化，这为优化未来的量子架构提供了宝贵的见解。

Abstract: Spin shuttling offers a promising approach for developing scalable
silicon-based quantum processors by addressing the connectivity limitations of
quantum dots (QDs). In this work, we demonstrate high-fidelity bucket-brigade
(BB) spin shuttling in a silicon MOS device, utilizing Pauli Spin Blockade
(PSB) readout. We achieve an average shuttling fidelity of \SI{99.8}{\percent}.
The residual shuttling error is highly sensitive to the ratio between interdot
tunnel coupling and Zeeman splitting, with tuning of these parameters enabling
up to a twenty-fold variation in error rate. An appropriate four-level
Hamiltonian model supports our findings. These results provide valuable
insights for optimizing high-performance spin shuttling systems in future
quantum architectures.

</details>


### [248] [Optimized Fabrication Procedure for High-Quality Graphene-based Moiré Superlattice Devices](https://arxiv.org/abs/2507.15853)
*Shuwen Sun,Pablo Jarillo-Herrero*

Main category: cond-mat.mes-hall

TL;DR: 本研究提出了一种改进的干转移技术，用于制备高质量、均匀的石墨烯基魔尔超晶格器件，解决了传统制备方法中的挑战。


<details>
  <summary>Details</summary>
Motivation: 制备高质量、具有精确扭转角的魔尔超晶格器件具有挑战性，因为在纳米制造过程中容易引入非预期的应变、扭转角无序以及角度/晶格弛豫。魔尔超晶格为研究强关联和拓扑学相互作用产生的涌现现象提供了一个多功能的平台，并具有灵活的原位调谐能力。

Method: 本研究介绍了一种优化的、基于经验的石墨烯基魔尔超晶格器件制备方案，重点是改进的干转移技术。转移过程在一个可高度调谐、定制的转移装置中进行，该装置能够精确控制位置、角度和温度。通过严格的薄片选择标准、预先清洁的无气泡栅极以及石墨烯激光烧蚀，在室温下以亚微米速度精确叠加扭转的石墨烯薄片来构建魔尔超晶格。

Result: 通过精确控制转移过程，所得石墨烯魔尔超晶格器件表现出高度的均匀性和期望的扭转角。

Conclusion: 该优化方案解决了现有石墨烯基魔尔超晶格器件制备中的挑战，有望推动魔尔材料领域的进一步发展。

Abstract: Moir\'e superlattices constitute a versatile platform to investigate emergent
phenomena arising from the interplay of strong correlations and topology, while
offering flexible in situ tunability. However, the fabrication of such moir\'e
superlattices is challenging. It is difficult to achieve highly uniform devices
with a precise twist angle because of the unintentional introduction of
heterostrain, twist angle disorder, and angle/lattice relaxation during the
nanofabrication process. This article introduces an optimized,
experience-informed protocol for fabricating high-quality graphene-based
moir\'e superlattice devices, focusing on a modified dry transfer technique.
The transfer process is performed in a highly tunable, custom-built transfer
setup that enables precise position, angle, and temperature control. By
combining rigorous flake selection criteria, pre-cleaned bubble-free bottom
gates, and graphene laser ablation, the moir\'e superlattice is constructed by
deliberately overlaying twisted graphene flakes at a submicron speed at room
temperature. Through precise control of the transfer process, the resulting
graphene moir\'e superlattice devices exhibit high uniformity and desired twist
angles. This optimized protocol addresses existing challenges in the
fabrication of graphene-based moir\'e superlattice devices and paves the way
for further advances in the rapidly evolving field of moir\'e materials.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [249] [Catalyst: a Novel Regularizer for Structured Pruning with Auxiliary Extension of Parameter Space](https://arxiv.org/abs/2507.14170)
*Jaeheun Jung,Donghun Lee*

Main category: cs.LG

TL;DR: 本文提出了一种名为 Catalyst 的新正则化方法，用于解决深度神经网络结构化剪枝中的幅度偏差和鲁棒性问题。该方法通过引入辅助变量，实现了对滤波器幅度的公平对待和宽裕的剪枝决策边界，从而在保证模型性能的同时，提高了剪枝的鲁棒性和有效性。实验结果表明，Catalyst 剪枝优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 传统的结构化剪枝方法（如 L1 或 Group Lasso）存在幅度偏差问题，即倾向于剪掉幅度小的滤波器，并且剪枝决策的边界过于狭窄，容易受到微小扰动的影响。这可能导致剪枝后的模型性能下降。

Method: 提出了一种新颖的正则化方法，称为 Catalyst 正则化，通过在扩展参数空间中引入辅助催化变量来实现。该方法旨在解决传统正则化器（如 L1 或 Group Lasso 及其变体）在滤波器剪枝中存在的幅度偏差和剪枝决策边界附近的零边际问题。

Result: Catalyst 剪枝算法在各种数据集和模型上的实验结果均优于现有的最先进的滤波器剪枝方法，并验证了 Catalyst 剪枝所预测的鲁棒性和公平性特征。

Conclusion: 所提出的 Catalyst 正则化通过在扩展参数空间中使用辅助催化变量，确保了每个滤波器具有公平的剪枝机会，且理论上可证明其幅度没有偏差，并通过保留和剪枝滤波器之间幅度的宽裕区分实现了鲁棒的剪枝行为。该方法在各种数据集和模型上的实验结果优于最先进的滤波器剪枝方法，并证实了 Catalyst 剪枝的鲁棒性和公平性。

Abstract: Structured pruning aims to reduce the size and computational cost of deep
neural networks by removing entire filters or channels. The traditional
regularizers such as L1 or Group Lasso and its variants lead to
magnitude-biased pruning decisions, such that the filters with small magnitudes
are likely to be pruned. Also, they often entail pruning results with almost
zero margin around pruning decision boundary, such that tiny perturbation in a
filter magnitude can flip the pruning decision. In this paper, we identify the
precise algebraic condition under which pruning operations preserve model
performance, and use the condition to construct a novel regularizer defined in
an extended parameter space via auxiliary catalyst variables. The proposed
Catalyst regularization ensures fair pruning chance for each filters with
theoretically provable zero bias to their magnitude and robust pruning behavior
achieved by wide-margin bifurcation of magnitudes between the preserved and the
pruned filters. The theoretical properties naturally lead to real-world
effectiveness, as shown by empirical validations of Catalyst Pruning algorithm.
Pruning results on various datasets and models are superior to state-of-the-art
filter pruning methods, and at the same time confirm the predicted robust and
fair pruning characteristics of Catalyst pruning.

</details>


### [250] [IPPRO: Importance-based Pruning with PRojective Offset for Magnitude-indifferent Structural Pruning](https://arxiv.org/abs/2507.14171)
*Jaeheun Jung,Jaehyuk Lee,Yeajin Lee,Donghun Lee*

Main category: cs.LG

TL;DR: 提出了一种新剪枝策略，将滤波器置于投影空间，通过梯度下降移动判断其被修剪的可能性，引入PROscore评分，实现接近无损剪枝，打破“尺寸至上”迷思。


<details>
  <summary>Details</summary>
Motivation: 现有的结构化剪枝方法（如基于重要性的方法）受限于幅度重要性及其相关标准，这些标准倾向于保留幅度较大的滤波器，即使它们是冗余的，从而限制了剪枝的潜力。

Method: 提出了一种新的剪枝策略，将滤波器置于投影空间中，通过观察梯度下降的移动方向来衡量滤波器被修剪的可能性，并构建了PROscore作为一种新的重要性评分，用于IPPRO（一种新颖的、不考虑幅度的、基于重要性的结构化剪枝方法）。

Result: 实验结果表明，所提出的基于投影空间的重要性评估标准通过降低剪枝过程中的性能下降，实现了接近无损的剪枝效果，并在微调后取得了有希望的性能。

Conclusion: 所提出的基于投影空间的新型剪枝策略通过引入PROscore重要性评分，实现了接近无损的剪枝效果，并在微调后表现出良好的性能。该研究打破了“尺寸至上”的剪枝观念，并在理论和实践上拓展了基于重要性的剪枝方法。

Abstract: With the growth of demand on neural network compression methods, the
structured pruning methods including importance-based approach are actively
studied. The magnitude importance and many correlated modern importance
criteria often limit the capacity of pruning decision, since the filters with
larger magnitudes are not likely to be pruned if the smaller one didn't, even
if it is redundant. In this paper, we propose a novel pruning strategy to
challenge this dominating effect of magnitude and provide fair chance to each
filter to be pruned, by placing it on projective space. After that, we observe
the gradient descent movement whether the filters move toward the origin or
not, to measure how the filter is likely to be pruned. This measurement is used
to construct PROscore, a novel importance score for IPPRO, a novel
importance-based structured pruning with magnitude-indifference. Our evaluation
results shows that the proposed importance criteria using the projective space
achieves near-lossless pruning by reducing the performance drop in pruning,
with promising performance after the finetuning. Our work debunks the
``size-matters'' myth in pruning and expands the frontier of importance-based
pruning both theoretically and empirically.

</details>


### [251] [Self-Improving Language Models for Evolutionary Program Synthesis: A Case Study on ARC-AGI](https://arxiv.org/abs/2507.14172)
*Julien Pourcel,Cédric Colas,Pierre-Yves Oudeyer*

Main category: cs.LG

TL;DR: SOAR通过将语言模型集成到自改进的进化循环中来学习程序合成，从而解决了程序合成的挑战。


<details>
  <summary>Details</summary>
Motivation: 许多程序综合任务对最先进的语言模型来说都太难了，无法一次性解决。基于搜索的进化方法通过迭代地探索解决方案空间提供了一种有前途的替代方案，但其有效性仍然受到底层生成模型固定能力的限制。

Method: SOAR通过整合语言模型到一个自改进的进化循环中来学习程序合成。SOAR在（1）使用LLM采样和改进候选解决方案的进化搜索和（2）将搜索尝试转换为用于微调LLM的采样和改进能力的有效问题-解决方案对的滞后学习阶段之间交替进行，从而在后续迭代中实现更有效的搜索。

Result: SOAR在具有挑战性的ARC-AGI基准测试中实现了跨模型规模和迭代的显著性能提升，并能解决52%的公开测试集。

Conclusion: SOAR在具有挑战性的ARC-AGI基准测试中实现了跨模型规模和迭代的显著性能提升，并在测试时适应中将这些改进转移到解决52%的公开测试集中。

Abstract: Many program synthesis tasks prove too challenging for even state-of-the-art
language models to solve in single attempts. Search-based evolutionary methods
offer a promising alternative by exploring solution spaces iteratively, but
their effectiveness remain limited by the fixed capabilities of the underlying
generative model.
  We propose SOAR, a method that learns program synthesis by integrating
language models into a self-improving evolutionary loop.
  SOAR alternates between (1) an evolutionary search that uses an LLM to sample
and refine candidate solutions, and (2) a hindsight learning phase that
converts search attempts into valid problem-solution pairs used to fine-tune
the LLM's sampling and refinement capabilities\, -- \,enabling increasingly
effective search in subsequent iterations.
  On the challenging ARC-AGI benchmark, SOAR achieves significant performance
gains across model scales and iterations, leveraging positive transfer between
the sampling and refinement finetuning tasks. These improvements carry over to
test-time adaptation, enabling SOAR to solve 52\% of the public test set. Our
code is open-sourced at: https://github.com/flowersteam/SOAR

</details>


### [252] [Latent Space Data Fusion Outperforms Early Fusion in Multimodal Mental Health Digital Phenotyping Data](https://arxiv.org/abs/2507.14175)
*Youcef Barkat,Dylan Hamitouche,Deven Parekh,Ivy Guo,David Benrimoh*

Main category: cs.LG

TL;DR: 潜在空间融合在预测多模态心理健康数据方面优于早期融合，能够更好地捕捉数据间的非线性关系，并提高预测准确性。


<details>
  <summary>Details</summary>
Motivation: 心理疾病（如抑郁和焦虑）需要改进早期检测和个性化干预的方法。传统的预测模型往往依赖于单一模态数据或早期融合策略，未能捕捉精神病学数据的复杂多模态性质。而中间（潜在空间）融合等高级集成技术可能提供更高的准确性和临床效用。

Method: 利用BRIGHTEN临床试验数据，评估了通过自编码器和神经网络的组合模型（CM）实现的中间（潜在空间）融合，用于预测每日抑郁症状（PHQ-2评分），并将其与随机森林（RF）的早期融合方法和线性回归（LR）基线进行了比较。实验在多个时间分割和数据流组合上进行，使用均方误差（MSE）和决定系数（R2）进行评估。

Result: 组合模型（CM）在所有设置中均优于随机森林（RF）和线性回归（LR）基线，实现了更低的均方误差（0.4985 vs. 0.5305）和更高的决定系数（0.4695 vs. 0.4356）。RF模型表现出过拟合迹象，而CM保持了持续的泛化能力。在CM中集成所有数据模式（与RF相反）时，性能最佳，这凸显了潜在空间融合在捕捉复杂精神病学数据中的非线性相互作用方面的价值。

Conclusion: 潜在空间融合为预测多模态心理健康数据提供了一种比传统融合方法更鲁的方法，未来的工作应探索模型可解释性和个体水平预测以用于临床部署。

Abstract: Background: Mental illnesses such as depression and anxiety require improved
methods for early detection and personalized intervention. Traditional
predictive models often rely on unimodal data or early fusion strategies that
fail to capture the complex, multimodal nature of psychiatric data. Advanced
integration techniques, such as intermediate (latent space) fusion, may offer
better accuracy and clinical utility. Methods: Using data from the BRIGHTEN
clinical trial, we evaluated intermediate (latent space) fusion for predicting
daily depressive symptoms (PHQ-2 scores). We compared early fusion implemented
with a Random Forest (RF) model and intermediate fusion implemented via a
Combined Model (CM) using autoencoders and a neural network. The dataset
included behavioral (smartphone-based), demographic, and clinical features.
Experiments were conducted across multiple temporal splits and data stream
combinations. Performance was evaluated using mean squared error (MSE) and
coefficient of determination (R2). Results: The CM outperformed both RF and
Linear Regression (LR) baselines across all setups, achieving lower MSE (0.4985
vs. 0.5305 with RF) and higher R2 (0.4695 vs. 0.4356). The RF model showed
signs of overfitting, with a large gap between training and test performance,
while the CM maintained consistent generalization. Performance was best when
integrating all data modalities in the CM (in contradistinction to RF),
underscoring the value of latent space fusion for capturing non-linear
interactions in complex psychiatric datasets. Conclusion: Latent space fusion
offers a robust alternative to traditional fusion methods for prediction with
multimodal mental health data. Future work should explore model
interpretability and individual-level prediction for clinical deployment.

</details>


### [253] [Predictive Representativity: Uncovering Racial Bias in AI-based Skin Cancer Detection](https://arxiv.org/abs/2507.14176)
*Andrés Morales-Forero,Lili J. Rueda,Ronald Herrera,Samuel Bassetto,Eric Coatanea*

Main category: cs.LG

TL;DR: AI在医疗领域的应用存在公平性问题，特别是在不同肤色人群中表现不一。本文提出的预测代表性（PR）框架通过关注模型预测结果的公平性，而非仅仅数据集构成，来评估和解决此类问题，并提出了外部可迁移性标准。研究发现，即使在数据比例均衡的情况下，模型在肤色较深人群上的表现也更差，强调了事后审计和包容性验证的重要性。


<details>
  <summary>Details</summary>
Motivation: 人工智能系统在医疗决策中的应用带来了算法偏见和不公平结果的担忧，特别是在历史上被边缘化的人群中。因此，需要一种新的公平性审计方法，将关注点从数据集构成转移到结果层面的公平性。

Method: 本文提出了一种名为预测代表性（PR）的公平性审计框架，并引入了外部可迁移性标准来量化模型在不同亚群体和部署环境中的公平性泛化能力。通过在HAM10000和BOSQUE数据集上对皮肤癌分类器进行案例研究，评估了模型在不同皮肤类型上的性能差异。

Result: 在皮肤癌分类的案例研究中，AI分类器在肤色较深的人群中表现出显著的性能下降，尽管数据集中可能存在比例抽样。这表明仅有比例抽样不足以保证公平性。

Conclusion: AI模型在医疗决策中日益重要，但算法偏见和不公平结果的担忧依然存在，尤其是在历史上被边缘化的人群中。本文提出了预测代表性（PR）的概念，这是一种公平性审计框架，它将重点从数据集的构成转移到结果层面的公平性。通过对皮肤科的案例研究，我们评估了在广泛使用的HAM10000数据集和来自哥伦比亚的独立临床数据集（BOSQUE测试集）上训练的基于AI的皮肤癌分类器。我们的分析揭示了不同皮肤类型之间存在显著的性能差异，尽管在原始数据中进行了比例抽样，但分类器在肤色较深的人群中的表现持续不佳。我们认为，代表性不应被理解为数据集的静态特征，而应被视为模型预测的动态、情境敏感的属性。PR通过量化模型在不同亚群体和部署环境中的公平性泛化可靠性来实现这种转变。我们进一步提出了一种外部可迁移性标准，用于规范公平性泛化的阈值。我们的研究结果强调了事后公平性审计、数据集文档透明化以及包容性模型验证流程的伦理必要性。这项工作提供了一个可扩展的工具来诊断AI系统中的结构性不公平，为公平性、可解释性和数据公正性的讨论做出贡献，并促进对数据驱动的医疗保健中公平性的批判性重新评估。

Abstract: Artificial intelligence (AI) systems increasingly inform medical
decision-making, yet concerns about algorithmic bias and inequitable outcomes
persist, particularly for historically marginalized populations. This paper
introduces the concept of Predictive Representativity (PR), a framework of
fairness auditing that shifts the focus from the composition of the data set to
outcomes-level equity. Through a case study in dermatology, we evaluated
AI-based skin cancer classifiers trained on the widely used HAM10000 dataset
and on an independent clinical dataset (BOSQUE Test set) from Colombia. Our
analysis reveals substantial performance disparities by skin phototype, with
classifiers consistently underperforming for individuals with darker skin,
despite proportional sampling in the source data. We argue that
representativity must be understood not as a static feature of datasets but as
a dynamic, context-sensitive property of model predictions. PR operationalizes
this shift by quantifying how reliably models generalize fairness across
subpopulations and deployment contexts. We further propose an External
Transportability Criterion that formalizes the thresholds for fairness
generalization. Our findings highlight the ethical imperative for post-hoc
fairness auditing, transparency in dataset documentation, and inclusive model
validation pipelines. This work offers a scalable tool for diagnosing
structural inequities in AI systems, contributing to discussions on equity,
interpretability, and data justice and fostering a critical re-evaluation of
fairness in data-driven healthcare.

</details>


### [254] [Understanding Two-Layer Neural Networks with Smooth Activation Functions](https://arxiv.org/abs/2507.14177)
*Changcun Huang*

Main category: cs.LG

TL;DR: 本研究揭示了使用平滑激活函数的两层神经网络的训练机制，通过泰勒展开等方法证明了其普遍逼近能力。


<details>
  <summary>Details</summary>
Motivation: 本研究旨在理解包含平滑激活函数的隐藏层的两层神经网络的训练解决方案，特别是传统sigmoid类激活函数，以揭示其解空间的“黑箱”机制。

Method: 该研究采用泰勒级数展开、节点严格偏序、光滑样条实现和光滑连续性约束等方法来分析两层神经网络的训练解决方案。

Result: 该研究证明了两层神经网络在任意输入维度下的普遍逼近能力，并通过实验验证揭示了其解空间的“黑箱”机制，同时为逼近理论提供了新的数学工具。

Conclusion: 该研究通过引入泰勒级数展开、节点严格偏序、光滑样条实现和光滑连续性约束这四个主要原理，为两层神经网络的训练解决方案提供了新的理论视角，并证明了其在任意输入维度下的普遍逼近能力，同时通过实验验证揭示了其解空间的“黑箱”机制。

Abstract: This paper aims to understand the training solution, which is obtained by the
back-propagation algorithm, of two-layer neural networks whose hidden layer is
composed of the units with smooth activation functions, including the usual
sigmoid type most commonly used before the advent of ReLUs. The mechanism
contains four main principles: construction of Taylor series expansions, strict
partial order of knots, smooth-spline implementation and smooth-continuity
restriction. The universal approximation for arbitrary input dimensionality is
proved and experimental verification is given, through which the mystery of
``black box'' of the solution space is largely revealed. The new proofs
employed also enrich approximation theory.

</details>


### [255] [SDSC:A Structure-Aware Metric for Semantic Signal Representation Learning](https://arxiv.org/abs/2507.14516)
*Jeyoung Lee,Hochul Kang*

Main category: cs.LG

TL;DR: 提出了一种名为 SDSC 的新度量函数，用于时间序列自监督学习，以解决传统基于距离的方法（如 MSE）的局限性。SDSC 通过衡量结构一致性来提高表示的语义质量，并在实验中显示出有希望的结果。


<details>
  <summary>Details</summary>
Motivation: 现有的自监督学习（SSL）方法通常采用基于距离的损失函数（如 MSE），这些函数对幅度敏感、对波形极性不敏感且尺度无界，从而阻碍了语义对齐和可解释性。

Method: 提出了一种名为信号骰子相似系数（SDSC）的结构感知度量函数，用于时间序列自监督表示学习。SDSC 基于骰子相似系数（DSC），通过量化时间信号之间基于符号幅度的交集来衡量结构一致性。此外，提出了一种混合损失函数，将 SDSC 与均方误差（MSE）相结合，以提高稳定性和在必要时保留幅度。

Result: 在预测和分类基准测试中，基于 SDSC 的预训练在某些情况下（尤其是在域内和低资源场景下）实现了与 MSE 相当或更好的性能。

Conclusion: 在信号表示学习中，结构保真度可以提高语义表示质量，表明结构感知度量可以作为传统基于距离的方法的可行替代方案。

Abstract: We propose the Signal Dice Similarity Coefficient (SDSC), a structure-aware
metric function for time series self-supervised representation learning. Most
Self-Supervised Learning (SSL) methods for signals commonly adopt
distance-based objectives such as mean squared error (MSE), which are sensitive
to amplitude, invariant to waveform polarity, and unbounded in scale. These
properties hinder semantic alignment and reduce interpretability. SDSC
addresses this by quantifying structural agreement between temporal signals
based on the intersection of signed amplitudes, derived from the Dice
Similarity Coefficient (DSC).Although SDSC is defined as a structure-aware
metric, it can be used as a loss by subtracting from 1 and applying a
differentiable approximation of the Heaviside function for gradient-based
optimization. A hybrid loss formulation is also proposed to combine SDSC with
MSE, improving stability and preserving amplitude where necessary. Experiments
on forecasting and classification benchmarks demonstrate that SDSC-based
pre-training achieves comparable or improved performance over MSE, particularly
in in-domain and low-resource scenarios. The results suggest that structural
fidelity in signal representations enhances the semantic representation
quality, supporting the consideration of structure-aware metrics as viable
alternatives to conventional distance-based methods.

</details>


### [256] [Feature Bank Enhancement for Distance-based Out-of-Distribution Detection](https://arxiv.org/abs/2507.14178)
*Yuhang Liu,Yuefei Wu,Bin Shi,Bo Dong*

Main category: cs.LG

TL;DR: A new method called FBE improves out-of-distribution detection by handling extreme features in deep learning models, achieving top results on standard tests.


<details>
  <summary>Details</summary>
Motivation: Deep learning's biased feature distributions and inevitable extreme features cause distance-based OOD detection methods to assign scores that are too low to in-distribution samples, limiting their OOD detection capabilities.

Method: Feature Bank Enhancement (FBE), which utilizes statistical characteristics from the dataset to identify and constrain extreme features to separation boundaries.

Result: Achieves state-of-the-art performance on large-scale ImageNet-1k and CIFAR-10 benchmarks, with further theoretical analysis and supplementary experiments providing additional insights.

Conclusion: The proposed Feature Bank Enhancement (FBE) method effectively addresses the issue of extreme features limiting distance-based OOD detection by constraining these features to separation boundaries, thereby increasing the distance between in-distribution and out-of-distribution samples. Experiments on ImageNet-1k and CIFAR-10 demonstrate state-of-the-art performance.

Abstract: Out-of-distribution (OOD) detection is critical to ensuring the reliability
of deep learning applications and has attracted significant attention in recent
years. A rich body of literature has emerged to develop efficient score
functions that assign high scores to in-distribution (ID) samples and low
scores to OOD samples, thereby helping distinguish OOD samples. Among these
methods, distance-based score functions are widely used because of their
efficiency and ease of use. However, deep learning often leads to a biased
distribution of data features, and extreme features are inevitable. These
extreme features make the distance-based methods tend to assign too low scores
to ID samples. This limits the OOD detection capabilities of such methods. To
address this issue, we propose a simple yet effective method, Feature Bank
Enhancement (FBE), that uses statistical characteristics from dataset to
identify and constrain extreme features to the separation boundaries, therapy
making the distance between samples inside and outside the distribution
farther. We conducted experiments on large-scale ImageNet-1k and CIFAR-10
respectively, and the results show that our method achieves state-of-the-art
performance on both benchmark. Additionally, theoretical analysis and
supplementary experiments are conducted to provide more insights into our
method.

</details>


### [257] [Pruning Increases Orderedness in Recurrent Computation](https://arxiv.org/abs/2507.14747)
*Yiding Song*

Main category: cs.LG

TL;DR: Directionality in neural networks can be induced by pruning, acting as a beneficial inductive bias without harming performance.


<details>
  <summary>Details</summary>
Motivation: The research is motivated by the prevalence of recurrent circuits in biological brains and aims to investigate the usefulness of directionality as an inductive bias for artificial neural networks.

Method: The paper formalizes a perceptron layer with all-to-all connections and applies pruning techniques to induce directionality, analyzing the topological order of information flow between neurons.

Result: The pruning schemes successfully induced greater topological ordering in information flow between neurons across different random seeds without compromising performance.

Conclusion: The study suggests that directionality, while not essential for learning, can be a beneficial inductive bias that can be discovered through gradient descent and sparsification. Pruning techniques can induce directionality in artificial neural networks without hindering performance.

Abstract: Inspired by the prevalence of recurrent circuits in biological brains, we
investigate the degree to which directionality is a helpful inductive bias for
artificial neural networks. Taking directionality as topologically-ordered
information flow between neurons, we formalise a perceptron layer with
all-to-all connections (mathematically equivalent to a weight-tied recurrent
neural network) and demonstrate that directionality, a hallmark of modern
feed-forward networks, can be induced rather than hard-wired by applying
appropriate pruning techniques. Across different random seeds our pruning
schemes successfully induce greater topological ordering in information flow
between neurons without compromising performance, suggesting that
directionality is not a prerequisite for learning, but may be an advantageous
inductive bias discoverable by gradient descent and sparsification.

</details>


### [258] [ROBAD: Robust Adversary-aware Local-Global Attended Bad Actor Detection Sequential Model](https://arxiv.org/abs/2507.15067)
*Bing He,Mustaque Ahamad,Srijan Kumar*

Main category: cs.LG

TL;DR: ROBAD是一个新的基于Transformer的恶意行为者检测模型，通过结合局部和全局信息以及对比学习来提高对对抗性攻击的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有的基于深度学习的检测模型对输入序列的微小变化很敏感，未能满足鲁棒性要求。为了解决这个问题，研究旨在提高模型的理解能力和知识，使其在进行预测时能够识别潜在的输入修改。

Method: ROBAD模型首先利用Transformer编码器块对每个帖子进行双向编码，构建帖子嵌入以捕获帖子级别的局部信息。然后，采用Transformer解码器块，通过注意力机制对帖子嵌入中的序列模式进行建模，生成序列嵌入以获得序列级别的全局信息。最后，通过将模仿攻击者修改的序列的嵌入输入到对比学习增强的分类层进行序列预测，以丰富模型的知识。

Result: ROBAD模型在Yelp和Wikipedia数据集上，在对抗当前最先进的对抗性攻击时，能够有效地检测恶意行为者。

Conclusion: ROBAD模型通过捕捉局部和全局信息，并利用模仿的恶意行为者训练，可以有效抵御对抗性攻击，在Yelp和Wikipedia数据集上进行了广泛的实验。

Abstract: Detecting bad actors is critical to ensure the safety and integrity of
internet platforms. Several deep learning-based models have been developed to
identify such users. These models should not only accurately detect bad actors,
but also be robust against adversarial attacks that aim to evade detection.
However, past deep learning-based detection models do not meet the robustness
requirement because they are sensitive to even minor changes in the input
sequence. To address this issue, we focus on (1) improving the model
understanding capability and (2) enhancing the model knowledge such that the
model can recognize potential input modifications when making predictions. To
achieve these goals, we create a novel transformer-based classification model,
called ROBAD (RObust adversary-aware local-global attended Bad Actor Detection
model), which uses the sequence of user posts to generate user embedding to
detect bad actors. Particularly, ROBAD first leverages the transformer encoder
block to encode each post bidirectionally, thus building a post embedding to
capture the local information at the post level. Next, it adopts the
transformer decoder block to model the sequential pattern in the post
embeddings by using the attention mechanism, which generates the sequence
embedding to obtain the global information at the sequence level. Finally, to
enrich the knowledge of the model, embeddings of modified sequences by mimicked
attackers are fed into a contrastive-learning-enhanced classification layer for
sequence prediction. In essence, by capturing the local and global information
(i.e., the post and sequence information) and leveraging the mimicked behaviors
of bad actors in training, ROBAD can be robust to adversarial attacks.
Extensive experiments on Yelp and Wikipedia datasets show that ROBAD can
effectively detect bad actors when under state-of-the-art adversarial attacks.

</details>


### [259] [A Sparsity Predicting Approach for Large Language Models via Activation Pattern Clustering](https://arxiv.org/abs/2507.14179)
*Nobel Dhar,Bobin Deng,Md Romyull Islam,Xinyue Zhang,Kazi Fahim Ahmad Nasif,Kun Suo*

Main category: cs.LG

TL;DR: 提出一种基于聚类的激活模式压缩框架，通过将相似的激活模式分组来提高预测效率，在保持模型质量的同时降低了计算开销。


<details>
  <summary>Details</summary>
Motivation: 为了能够高效地预测和利用激活稀疏性，需要一种可扩展的方法来预测激活模式。然而，由于现代大型语言模型中神经元数量众多，在神经元级别直接进行预测的计算成本很高。

Method: 提出了一种基于聚类的激活模式压缩框架，将相似的激活模式分组到少量代表性聚类中，而不是独立地对待每个神经元。

Result: 该方法实现了高达79.34%的聚类精度，优于标准的二元聚类方法，同时在困惑度（PPL）分数上仅有很小的下降。当聚类数量足够多时，该方法可以达到12.49的低困惑度分数，证明了其在保持模型质量和降低计算开销方面的有效性。

Conclusion: 通过预测聚类分配而非单独神经元状态，未来的模型可以有效地从预先计算的质心推断激活模式。该基于聚类的模型为未来激活模式预测工作奠定了基础，为大型语言模型的高效推理铺平了道路。

Abstract: Large Language Models (LLMs) exhibit significant activation sparsity, where
only a subset of neurons are active for a given input. Although this sparsity
presents opportunities to reduce computational cost, efficiently utilizing it
requires predicting activation patterns in a scalable manner. However, direct
prediction at the neuron level is computationally expensive due to the vast
number of neurons in modern LLMs. To enable efficient prediction and
utilization of activation sparsity, we propose a clustering-based activation
pattern compression framework. Instead of treating each neuron independently,
we group similar activation patterns into a small set of representative
clusters. Our method achieves up to 79.34% clustering precision, outperforming
standard binary clustering approaches while maintaining minimal degradation in
perplexity (PPL) scores. With a sufficiently large number of clusters, our
approach attains a PPL score as low as 12.49, demonstrating its effectiveness
in preserving model quality while reducing computational overhead. By
predicting cluster assignments rather than individual neuron states, future
models can efficiently infer activation patterns from pre-computed centroids.
We detail the clustering algorithm, analyze its effectiveness in capturing
meaningful activation structures, and demonstrate its potential to improve
sparse computation efficiency. This clustering-based formulation serves as a
foundation for future work on activation pattern prediction, paving the way for
efficient inference in large-scale language models.

</details>


### [260] [Digital Twin-Assisted Explainable AI for Robust Beam Prediction in mmWave MIMO Systems](https://arxiv.org/abs/2507.14180)
*Nasir Khan,Asmaa Abdallah,Abdulkadir Celik,Ahmed M. Eltawil,Sinem Coleri*

Main category: cs.LG

TL;DR: 该研究提出了一种新颖的基于深度学习的波束对齐引擎（BAE），用于毫米波MIMO系统。该引擎利用数字孪生技术生成合成数据，并通过迁移学习进行模型优化。结合深度SHAP和DkNN算法，BAE能够提高透明度、减少波束训练开销并增强鲁棒性，在实际应用中表现出色。


<details>
  <summary>Details</summary>
Motivation: 在AI原生6G愿景下，可解释性和鲁棒性对于毫米波（mmWave）系统至关重要。现有的深度学习（DL）解决方案在初始接入的波束对齐方面面临数据采集开销高、硬件限制、缺乏可解释性以及易受对抗性攻击等挑战。

Method: 本研究提出了一种结合数字孪生、迁移学习、深度Shapley加法解释（SHAP）和深度k近邻（DkNN）算法的深度学习框架，用于毫米波MIMO系统的波束对齐。首先利用数字孪生生成站点特定的合成信道数据，然后通过迁移学习优化模型，并利用深度SHAP分析特征重要性以减少波束训练开销和提高透明度，最后利用DkNN算法提供可信度指标以检测分布外输入。

Result: 实验结果表明，所提出的框架将实际数据需求减少了70%，将波束训练开销减少了62%，并将异常值检测鲁棒性提高了高达8.5倍，与传统的基于softmax的DL模型相比，实现了接近最优的频谱效率和透明的决策制定。

Conclusion: 提出了一种用于毫米波MIMO系统的鲁棒且可解释的基于深度学习的波束对齐引擎（BAE），利用数字孪生生成合成数据，并通过迁移学习进行模型优化，结合深度SHAP和DkNN算法提高透明度和鲁棒性。

Abstract: In line with the AI-native 6G vision, explainability and robustness are
crucial for building trust and ensuring reliable performance in millimeter-wave
(mmWave) systems. Efficient beam alignment is essential for initial access, but
deep learning (DL) solutions face challenges, including high data collection
overhead, hardware constraints, lack of explainability, and susceptibility to
adversarial attacks. This paper proposes a robust and explainable DL-based beam
alignment engine (BAE) for mmWave multiple-input multiple output (MIMO)
systems. The BAE uses received signal strength indicator (RSSI) measurements
from wide beams to predict the best narrow beam, reducing the overhead of
exhaustive beam sweeping. To overcome the challenge of real-world data
collection, this work leverages a site-specific digital twin (DT) to generate
synthetic channel data closely resembling real-world environments. A model
refinement via transfer learning is proposed to fine-tune the pre-trained model
residing in the DT with minimal real-world data, effectively bridging
mismatches between the digital replica and real-world environments. To reduce
beam training overhead and enhance transparency, the framework uses deep
Shapley additive explanations (SHAP) to rank input features by importance,
prioritizing key spatial directions and minimizing beam sweeping. It also
incorporates the Deep k-nearest neighbors (DkNN) algorithm, providing a
credibility metric for detecting out-of-distribution inputs and ensuring
robust, transparent decision-making. Experimental results show that the
proposed framework reduces real-world data needs by 70%, beam training overhead
by 62%, and improves outlier detection robustness by up to 8.5x, achieving
near-optimal spectral efficiency and transparent decision making compared to
traditional softmax based DL models.

</details>


### [261] [Transforming Datasets to Requested Complexity with Projection-based Many-Objective Genetic Algorithm](https://arxiv.org/abs/2507.15132)
*Joanna Komorniczak*

Main category: cs.LG

TL;DR: 提出了一种遗传算法，可以生成具有可调复杂性的合成数据集，以帮助评估机器学习模型。


<details>
  <summary>Details</summary>
Motivation: 为了可靠地评估机器学习方法的优缺点，研究社区一直在寻求更先进的合成数据生成器，旨在增加包含各种问题复杂性数据集的可用性。

Method: 提出了一种遗传算法，该算法通过线性特征投影来优化一系列用于分类（10个度量）和回归（4个度量）任务的复杂性度量，以实现目标复杂性值。

Result: 实验证实，所提出的遗传算法可以通过线性特征投影将合成创建的数据集转换为目标复杂性值，从而生成不同难度的¡数据集。对最先进的分类器和回归器的评估表明，生成数据的复杂性与识别质量之间存在相关性。

Conclusion: 该研究提出了一种遗传算法，通过优化一系列分类和回归任务的复杂性度量，生成具有不同难度的数据集，并证实了生成数据的复杂性与识别质量之间的相关性。

Abstract: The research community continues to seek increasingly more advanced synthetic
data generators to reliably evaluate the strengths and limitations of machine
learning methods. This work aims to increase the availability of datasets
encompassing a diverse range of problem complexities by proposing a genetic
algorithm that optimizes a set of problem complexity measures for
classification and regression tasks towards specific targets. For
classification, a set of 10 complexity measures was used, while for regression
tasks, 4 measures demonstrating promising optimization capabilities were
selected. Experiments confirmed that the proposed genetic algorithm can
generate datasets with varying levels of difficulty by transforming
synthetically created datasets to achieve target complexity values through
linear feature projections. Evaluations involving state-of-the-art classifiers
and regressors revealed a correlation between the complexity of the generated
data and the recognition quality.

</details>


### [262] [Resonant-Tunnelling Diode Reservoir Computing System for Image Recognition](https://arxiv.org/abs/2507.15158)
*A. H. Abbas,Hend Abdel-Ghani,Ivan S. Maksymov*

Main category: cs.LG

TL;DR: 提出了一种基于谐振隧道二极管（RTD）的神经形态计算架构，用于高效的图像识别，消除了对随机连接的需求。


<details>
  <summary>Details</summary>
Motivation: 随着人工智能持续进入实时、边缘和资源受限的环境，迫切需要新颖、硬件高效的计算模型。

Method: 提出并验证了一种基于谐振隧道二极管（RTD）的神经形态计算架构，该二极管表现出理想的非线性特性，适用于物理水库计算（RC）。理论上公式化并以数值方式实现了一个基于RTD的RC系统。

Result: 所提出的电路级架构在手写数字分类和使用Fruit360数据集的目标识别两个图像识别基准测试中表现出有希望的性能。

Conclusion: 所提出的基于RTD的RC系统在图像识别基准测试中表现出有希望的性能，并且符合下一代RC的原则，即消除随机连接，转而采用确定性的非线性输入信号转换。

Abstract: As artificial intelligence continues to push into real-time, edge-based and
resource-constrained environments, there is an urgent need for novel,
hardware-efficient computational models. In this study, we present and validate
a neuromorphic computing architecture based on resonant-tunnelling diodes
(RTDs), which exhibit the nonlinear characteristics ideal for physical
reservoir computing (RC). We theoretically formulate and numerically implement
an RTD-based RC system and demonstrate its effectiveness on two image
recognition benchmarks: handwritten digit classification and object recognition
using the Fruit~360 dataset. Our results show that this circuit-level
architecture delivers promising performance while adhering to the principles of
next-generation RC -- eliminating random connectivity in favour of a
deterministic nonlinear transformation of input signals.

</details>


### [263] [Competitive Algorithms for Cooperative Multi-Agent Ski-Rental Problems](https://arxiv.org/abs/2507.15727)
*Xuchuang Wang,Bo Sun,Hedyeh Beyhaghi,John C. S. Lui,Mohammad Hajiesmaili,Adam Wierman*

Main category: cs.LG

TL;DR: 本文将滑雪租赁问题扩展到多主体设置，考虑了个人和共同成本，并定义了三种竞争比。我们设计了最优策略，并发现对称策略优于非对称策略。


<details>
  <summary>Details</summary>
Motivation: 本文提出了一个新颖的多主体滑雪租赁问题，该问题将经典的滑雪租赁困境推广到一种群体设置，在这种设置中，主体需要承担个人和共同的成本。

Method: 我们定义了三种不同的竞争比：整体的、状态相关的和个体理性的。对于每个目标，我们设计并分析了最优确定性和随机策略。我们的确定性策略采用状态感知阈值函数，以适应动态状态，而我们的随机策略从定制的状态感知分布中采样和重新采样阈值。

Result: 我们设计并分析了最优确定性和随机策略。我们的确定性策略采用状态感知阈值函数，以适应动态状态，而我们的随机策略从定制的状态感知分布中采样和重新采样阈值。分析表明，对称策略（所有主体使用相同阈值的策略）的性能优于非对称策略。

Conclusion: 对称策略优于非对称策略，并且我们为每个目标提供了竞争比的上界和下界，将经典的滑雪租赁见解扩展到多主体设置，并强调了在不确定性下进行群体决策的理论和实践意义。

Abstract: This paper introduces a novel multi-agent ski-rental problem that generalizes
the classical ski-rental dilemma to a group setting where agents incur
individual and shared costs. In our model, each agent can either rent at a
fixed daily cost, or purchase a pass at an individual cost, with an additional
third option of a discounted group pass available to all. We consider scenarios
in which agents' active days differ, leading to dynamic states as agents drop
out of the decision process. To address this problem from different
perspectives, we define three distinct competitive ratios: overall,
state-dependent, and individual rational. For each objective, we design and
analyze optimal deterministic and randomized policies. Our deterministic
policies employ state-aware threshold functions that adapt to the dynamic
states, while our randomized policies sample and resample thresholds from
tailored state-aware distributions. The analysis reveals that symmetric
policies, in which all agents use the same threshold, outperform asymmetric
ones. Our results provide competitive ratio upper and lower bounds and extend
classical ski-rental insights to multi-agent settings, highlighting both
theoretical and practical implications for group decision-making under
uncertainty.

</details>


### [264] [Constraint-aware Learning of Probabilistic Sequential Models for Multi-Label Classification](https://arxiv.org/abs/2507.15156)
*Mykhailo Buleshnyi,Anna Polova,Zsolt Zombori,Michael Benedikt*

Main category: cs.LG

TL;DR: A new architecture for multi-label classification uses a sequential model to leverage label correlations and constraints, showing effectiveness in both training and inference.


<details>
  <summary>Details</summary>
Motivation: Investigating multi-label classification with large label sets and logical constraints between labels.

Method: An architecture where classifiers for individual labels feed into an expressive sequential model to produce a joint distribution.

Result: Empirical demonstration of the architecture's ability to exploit and enforce constraints.

Conclusion: The architecture can exploit constraints during training and enforce them during inference.

Abstract: We investigate multi-label classification involving large sets of labels,
where the output labels may be known to satisfy some logical constraints. We
look at an architecture in which classifiers for individual labels are fed into
an expressive sequential model, which produces a joint distribution. One of the
potential advantages for such an expressive model is its ability to modelling
correlations, as can arise from constraints. We empirically demonstrate the
ability of the architecture both to exploit constraints in training and to
enforce constraints at inference time.

</details>


### [265] [Semi-Supervised Federated Learning via Dual Contrastive Learning and Soft Labeling for Intelligent Fault Diagnosis](https://arxiv.org/abs/2507.14181)
*Yajiao Dai,Jun Li,Zhen Mei,Yiyang Ni,Shi Jin,Zengxiang Li,Sheng Guo,Wei Xiang*

Main category: cs.LG

TL;DR: 提出 SSFL-DCSL 半监督联邦学习框架，用双对比损失和软标签解决数据标签稀疏问题，通过加权平均聚合原型实现知识共享，准确率比现有方法高。


<details>
  <summary>Details</summary>
Motivation: 传统的监督式深度学习方法在工业机械故障诊断中需要大量标注数据，而这些数据通常分散在不同客户端，标注成本高且难以获取。同时，客户端间数据分布的差异也可能影响模型性能。为了应对这些挑战，需要一种能够利用未标记数据、促进联合学习并保护用户隐私的框架。

Method: 提出了一种名为 SSFL-DCSL 的半监督联邦学习框架，该框架整合了双对比损失和软标签技术。具体方法包括：1. 设计基于拉普拉斯分布的样本权重函数，以减轻伪标签置信度低带来的偏差。2. 引入包含局部对比损失和全局对比损失的双对比损失，以缓解不同数据分布导致的模型分歧。3. 在服务器端通过加权平均和动量更新聚合局部原型，以实现客户端间的知识共享。

Result: 在两种公开数据集和工厂电机数据集上进行的实验表明，SSFL-DCSL 框架在最严峻的挑战性任务（仅 10% 数据被标记）中，准确率比现有先进方法提高了 1.15% 至 7.85%。

Conclusion: 所提出的 SSFL-DCSL 框架通过集成双对比损失和软标签，有效地解决了分布式客户端数据和标签稀疏的问题，并在仅有 10% 标记数据的情况下，相比现有技术提高了 1.15% 至 7.85% 的准确率。

Abstract: Intelligent fault diagnosis (IFD) plays a crucial role in ensuring the safe
operation of industrial machinery and improving production efficiency. However,
traditional supervised deep learning methods require a large amount of training
data and labels, which are often located in different clients. Additionally,
the cost of data labeling is high, making labels difficult to acquire.
Meanwhile, differences in data distribution among clients may also hinder the
model's performance. To tackle these challenges, this paper proposes a
semi-supervised federated learning framework, SSFL-DCSL, which integrates dual
contrastive loss and soft labeling to address data and label scarcity for
distributed clients with few labeled samples while safeguarding user privacy.
It enables representation learning using unlabeled data on the client side and
facilitates joint learning among clients through prototypes, thereby achieving
mutual knowledge sharing and preventing local model divergence. Specifically,
first, a sample weighting function based on the Laplace distribution is
designed to alleviate bias caused by low confidence in pseudo labels during the
semi-supervised training process. Second, a dual contrastive loss is introduced
to mitigate model divergence caused by different data distributions, comprising
local contrastive loss and global contrastive loss. Third, local prototypes are
aggregated on the server with weighted averaging and updated with momentum to
share knowledge among clients. To evaluate the proposed SSFL-DCSL framework,
experiments are conducted on two publicly available datasets and a dataset
collected on motors from the factory. In the most challenging task, where only
10\% of the data are labeled, the proposed SSFL-DCSL can improve accuracy by
1.15% to 7.85% over state-of-the-art methods.

</details>


### [266] [From Bias to Behavior: Learning Bull-Bear Market Dynamics with Contrastive Modeling](https://arxiv.org/abs/2507.14182)
*Xiaotong Luo,Shengda Zhuo,Min Chen,Lichun Li,Ruizhao Lu,Wenqi Fan,Shuqiang Huang,Yin Tang*

Main category: cs.LG

TL;DR: B4模型通过结合历史价格和外部信号，考虑了牛市和熊市中的投资者偏见，并能预测市场趋势。


<details>
  <summary>Details</summary>
Motivation: 金融市场的动态和复杂性，投资者群体的异质性和偏见使建模复杂化。本研究旨在探索牛市和熊市状态在投资者驱动的市场动态中的潜力。

Method: 提出了一种名为B4（Bias to Behavior from Bull-Bear Dynamics）的统一框架，该框架将时间价格序列和外部上下文信号共同嵌入到一个共享的潜在空间中，在潜在空间中，牛市和熊市的力量自然出现，从而为偏见表示奠定基础。在此空间内，惯性配对模块配对时间上相邻的样本以保持动量，而双重竞争机制则对比牛市和熊市的嵌入以捕捉行为差异。

Result: B4模型在预测市场趋势方面取得了优越的性能，并提供了可解释的见解。

Conclusion: 该模型能够实现对市场趋势的预测，并对偏见、投资者行为和市场动态的相互作用提供可解释的见解。

Abstract: Financial markets exhibit highly dynamic and complex behaviors shaped by both
historical price trajectories and exogenous narratives, such as news, policy
interpretations, and social media sentiment. The heterogeneity in these data
and the diverse insight of investors introduce biases that complicate the
modeling of market dynamics. Unlike prior work, this paper explores the
potential of bull and bear regimes in investor-driven market dynamics. Through
empirical analysis on real-world financial datasets, we uncover a dynamic
relationship between bias variation and behavioral adaptation, which enhances
trend prediction under evolving market conditions. To model this mechanism, we
propose the Bias to Behavior from Bull-Bear Dynamics model (B4), a unified
framework that jointly embeds temporal price sequences and external contextual
signals into a shared latent space where opposing bull and bear forces
naturally emerge, forming the foundation for bias representation. Within this
space, an inertial pairing module pairs temporally adjacent samples to preserve
momentum, while the dual competition mechanism contrasts bullish and bearish
embeddings to capture behavioral divergence. Together, these components allow
B4 to model bias-driven asymmetry, behavioral inertia, and market
heterogeneity. Experimental results on real-world financial datasets
demonstrate that our model not only achieves superior performance in predicting
market trends but also provides interpretable insights into the interplay of
biases, investor behaviors, and market dynamics.

</details>


### [267] [FedStrategist: A Meta-Learning Framework for Adaptive and Robust Aggregation in Federated Learning](https://arxiv.org/abs/2507.14322)
*Md Rafid Haque,Abu Raihan Mostofa Kamal,Md. Azam Hossain*

Main category: cs.LG

TL;DR: FedStrategist通过元学习和自适应聚合策略，提高了联邦学习应对模型投毒攻击的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有的联邦学习静态防御措施在适应性对手或异构数据环境中效果有限，无法应对模型投毒攻击的挑战。

Method: FedStrategist框架，使用轻量级上下文老虎机代理，根据实时诊断指标动态选择聚合规则，以应对模型投毒攻击。

Result: 实验证明，FedStrategist的自适应代理在各种场景下都能学习到优越的策略，包括在“Krum有利”的环境和对抗旨在抵消特定诊断信号的“隐形”对手。此外，该框架还证明了其策略可以通过单一的“风险容忍度”参数进行控制，允许用户管理性能和安全之间的权衡。

Conclusion: 本文提出了一种名为FedStrategist的新型元学习框架，该框架将鲁棒聚合重构为一个实时、成本感知的控制问题。通过设计一个轻量级的上下文老虎机代理，该代理能够根据实时诊断指标动态选择最优聚合规则，从而提高了联邦学习的鲁棒性。

Abstract: Federated Learning (FL) offers a paradigm for privacy-preserving
collaborative AI, but its decentralized nature creates significant
vulnerabilities to model poisoning attacks. While numerous static defenses
exist, their effectiveness is highly context-dependent, often failing against
adaptive adversaries or in heterogeneous data environments. This paper
introduces FedStrategist, a novel meta-learning framework that reframes robust
aggregation as a real-time, cost-aware control problem. We design a lightweight
contextual bandit agent that dynamically selects the optimal aggregation rule
from an arsenal of defenses based on real-time diagnostic metrics. Through
comprehensive experiments, we demonstrate that no single static rule is
universally optimal. We show that our adaptive agent successfully learns
superior policies across diverse scenarios, including a ``Krum-favorable"
environment and against a sophisticated "stealth" adversary designed to
neutralize specific diagnostic signals. Critically, we analyze the paradoxical
scenario where a non-robust baseline achieves high but compromised accuracy,
and demonstrate that our agent learns a conservative policy to prioritize model
integrity. Furthermore, we prove the agent's policy is controllable via a
single "risk tolerance" parameter, allowing practitioners to explicitly manage
the trade-off between performance and security. Our work provides a new,
practical, and analyzable approach to creating resilient and intelligent
decentralized AI systems.

</details>


### [268] [LaCache: Ladder-Shaped KV Caching for Efficient Long-Context Modeling of Large Language Models](https://arxiv.org/abs/2507.14204)
*Dachuan Shi,Yonggan Fu,Xiangchi Yuan,Zhongzhi Yu,Haoran You,Sixu Li,Xin Dong,Jan Kautz,Pavlo Molchanov,Yingyan,Lin*

Main category: cs.LG

TL;DR: LaCache 是一种创新的 KV 缓存优化方法，可在不增加模型大小或训练的情况下，提高 LLM 处理长序列和连续生成的能力，并解决内存限制问题。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）在处理长输入和持续生成长输出方面具有巨大潜力，但随着序列长度的增加，KV 对的数量急剧上升，导致效率瓶颈，并可能引发内存不足（OOM）问题。本研究旨在优化 KV 缓存，以应对这些挑战。

Method: LaCache 是一种训练无关的方法，通过集成两种创新：1. 阶梯状 KV 缓存模式：KV 对不仅按顺序存储（层内从左到右），还跨层存储（从浅到深），在固定存储预算下扩展了捕捉长程依赖的范围，从而增强了长程能力。2. 迭代压缩机制：逐步压缩旧缓存，为固定缓存大小内的新 token 腾出空间，这种基于 token 距离的动态压缩能够在有限的缓存预算下实现更有效的连续生成。

Result: 实验结果在各种任务、基准测试和 LLM 模型上均一致表明，LaCache 在增强 LLM 的长程能力方面非常有效。

Conclusion: LaCache 是一种无需训练即可实现高效准确的 LLM 推理的方法，它通过采用阶梯状 KV 缓存模式和迭代压缩机制，解决了长程建模中的关键挑战，提高了 LLM 的长程能力和连续生成能力，并有效避免了内存不足（OOM）的问题。

Abstract: Recent advancements in Large Language Models (LLMs) have spurred interest in
numerous applications requiring robust long-range capabilities, essential for
processing extensive input contexts and continuously generating extended
outputs. As sequence lengths increase, the number of Key-Value (KV) pairs in
LLMs escalates, creating a significant efficiency bottleneck. In this paper, we
propose a new KV cache optimization paradigm called LaCache, a training-free
method for efficient and accurate generative inference of LLMs. LaCache enables
LLMs to simultaneously address both of the critical challenges in long-range
modeling: robust long-range capabilities and continuous generation without
running out-of-memory (OOM). Specifically, LaCache integrates two key
innovations: (1) a ladder-shaped KV cache pattern that stores KV pairs not only
sequentially (left-to-right within each layer) but also across layers (from
shallow to deep), providing an extended span for capturing long-range
dependencies under a fixed storage budget, thereby boosting long-range
capabilities; and (2) an iterative compaction mechanism that progressively
compresses older caches, freeing up space for new tokens within a fixed cache
size. This token distance-based dynamic compression enables more effective
continuous generation under constrained cache budgets. Experiments across
various tasks, benchmarks, and LLM models consistently validate LaCache's
effectiveness in enhancing LLMs' long-range capabilities. Our code is available
at https://github.com/GATECH-EIC/LaCache.

</details>


### [269] [Scaling Decentralized Learning with FLock](https://arxiv.org/abs/2507.15349)
*Zehua Cheng,Rui Sun,Jiahao Sun,Yike Guo*

Main category: cs.LG

TL;DR: FLock是一个创新的去中心化框架，利用区块链和经济激励安全高效地微调大型语言模型，解决了传统联邦学习的中心化风险和计算开销问题，并成功防御了中毒攻击，提升了模型性能。


<details>
  <summary>Details</summary>
Motivation: 为了解决微调大型语言模型（LLMs）时，中心化控制的不足以及去中心化方案中巨大的计算和通信开销问题，同时应对标准联邦学习（FL）中中心服务器的单点攻击和中毒攻击风险。

Method: FLock是一个去中心化的框架，通过整合基于区块链的信任层和经济激励，用一个安全、可审计的协议来促进不可信方之间的协作，取代了中心聚合器，实现了安全高效的LLM协作微调。

Result: 首次在安全、多域、去中心化的环境中对70B LLM进行了实证验证，表明FLock框架能够抵御后门中毒攻击，并提升模型的跨领域泛化能力，同时降低了68%以上的对抗性攻击成功率。

Conclusion: FLock框架能够防御针对标准联邦学习优化器的后门中毒攻击，并促进协同知识转移。最终的模型在跨领域泛化能力上表现更优，优于在各自专业数据上独立训练的模型，其对抗性攻击成功率降低了68%以上。

Abstract: Fine-tuning the large language models (LLMs) are prevented by the deficiency
of centralized control and the massive computing and communication overhead on
the decentralized schemes. While the typical standard federated learning (FL)
supports data privacy, the central server requirement creates a single point of
attack and vulnerability to poisoning attacks. Generalizing the result in this
direction to 70B-parameter models in the heterogeneous, trustless environments
has turned out to be a huge, yet unbroken bottleneck. This paper introduces
FLock, a decentralized framework for secure and efficient collaborative LLM
fine-tuning. Integrating a blockchain-based trust layer with economic
incentives, FLock replaces the central aggregator with a secure, auditable
protocol for cooperation among untrusted parties. We present the first
empirical validation of fine-tuning a 70B LLM in a secure, multi-domain,
decentralized setting. Our experiments show the FLock framework defends against
backdoor poisoning attacks that compromise standard FL optimizers and fosters
synergistic knowledge transfer. The resulting models show a >68% reduction in
adversarial attack success rates. The global model also demonstrates superior
cross-domain generalization, outperforming models trained in isolation on their
own specialized data.

</details>


### [270] [Developing an AI-Guided Assistant Device for the Deaf and Hearing Impaired](https://arxiv.org/abs/2507.14215)
*Jiayu,Liu*

Main category: cs.LG

TL;DR: 本研究开发了一款基于深度学习的辅助设备，能实时识别和定位声源，为听障人士提供帮助。该系统结合了CNN、CLAP模型和多模态融合技术，并在精确率、准确率和定位性能方面取得了优异结果。


<details>
  <summary>Details</summary>
Motivation: 本研究旨在为聋哑或听力障碍人士开发一款能够实时准确识别和定位声源的深度学习辅助设备，以填补当前研究的空白，并利用机器学习技术服务于弱势群体。

Method: 本研究采用深度学习技术，构建了一个包含三个主要组件的系统：1. JerryNet：一个自定义的卷积神经网络（CNN）架构，用于确定九个可能方向的到达角（DoA）。2. 音频分类：基于对比语言-音频预训练（CLAP）模型的微调，仅通过音频识别声音类别。3. 多模态融合模型：结合音频、视觉和文本数据，利用Yolov9进行物体检测和音频-视觉定位模型（基于CIoU）来精确定位声源。硬件包括四麦克风阵列和集成在眼镜上的摄像头，并通过腕带显示信息。

Result: JerryNet在自定义数据集上实现了91.1%的声源方向精确率，优于所有基线模型。CLAP模型在自定义和AudioSet数据集上的准确率分别为98.5%和95%。多模态融合模型在音频-视觉定位方面取得了0.892的cIoU和0.658的AUC，超越了其他类似模型。

Conclusion: 本研究成功开发了一个深度学习系统，用于为聋哑或听力障碍人士开发辅助设备。该系统能够实时准确地定位和识别声源，填补了当前研究的空白，并有望为弱势群体带来新的辅助技术。

Abstract: This study aims to develop a deep learning system for an accessibility device
for the deaf or hearing impaired. The device will accurately localize and
identify sound sources in real time. This study will fill an important gap in
current research by leveraging machine learning techniques to target the
underprivileged community. The system includes three main components. 1.
JerryNet: A custom designed CNN architecture that determines the direction of
arrival (DoA) for nine possible directions. 2. Audio Classification: This model
is based on fine-tuning the Contrastive Language-Audio Pretraining (CLAP) model
to identify the exact sound classes only based on audio. 3. Multimodal
integration model: This is an accurate sound localization model that combines
audio, visual, and text data to locate the exact sound sources in the images.
The part consists of two modules, one object detection using Yolov9 to generate
all the bounding boxes of the objects, and an audio visual localization model
to identify the optimal bounding box using complete Intersection over Union
(CIoU). The hardware consists of a four-microphone rectangular formation and a
camera mounted on glasses with a wristband for displaying necessary information
like direction. On a custom collected data set, JerryNet achieved a precision
of 91. 1% for the sound direction, outperforming all the baseline models. The
CLAP model achieved 98.5% and 95% accuracy on custom and AudioSet datasets,
respectively. The audio-visual localization model within component 3 yielded a
cIoU of 0.892 and an AUC of 0.658, surpassing other similar models. There are
many future potentials to this study, paving the way to creating a new
generation of accessibility devices.

</details>


### [271] [Geometry-Aware Active Learning of Pattern Rankings via Choquet-Based Aggregation](https://arxiv.org/abs/2507.14217)
*Tudor Matei Opran,Samir Loudni*

Main category: cs.LG

TL;DR: 通过交互式学习框架和几何感知查询选择，解决模式挖掘中的模式爆炸问题，并提高排序准确性。


<details>
  <summary>Details</summary>
Motivation: 为了解决模式挖掘中的模式爆炸问题。

Method: 提出了一种结合非线性效用聚合和几何感知查询选择的交互式学习框架。该方法通过对多个有趣性度量的Choquet积分来模拟用户偏好，并利用版本空间的几何结构来指导信息性比较的选择。一个带有紧密距离界限的分枝定界策略能够有效地识别决策边界附近的查询。

Result: 我们的方法通过结合非线性效用聚合与几何感知查询选择，并利用带有紧密距离界限的分枝定界策略，能够更有效地识别模式，并在用户交互次数更少的情况下提高排序的准确性。

Conclusion: 该方法在UCI数据集上进行了实验，结果优于现有的基于ChoquetRank等方法，在更少用户交互的情况下实现了更好的排序准确性。

Abstract: We address the pattern explosion problem in pattern mining by proposing an
interactive learning framework that combines nonlinear utility aggregation with
geometry-aware query selection. Our method models user preferences through a
Choquet integral over multiple interestingness measures and exploits the
geometric structure of the version space to guide the selection of informative
comparisons. A branch-and-bound strategy with tight distance bounds enables
efficient identification of queries near the decision boundary. Experiments on
UCI datasets show that our approach outperforms existing methods such as
ChoquetRank, achieving better ranking accuracy with fewer user interactions.

</details>


### [272] [Artificial Intelligence for Green Hydrogen Yield Prediction and Site Suitability using SHAP-Based Composite Index: Focus on Oman](https://arxiv.org/abs/2507.14219)
*Obumneme Zimuzor Nwafor,Mohammed Abdul Majeed Al Hooti*

Main category: cs.LG

TL;DR: 本研究提出了一个AI框架，用于计算绿色氢气产量和场地适用性，解决了数据稀缺地区面临的挑战。该框架通过聚类、分类和SHAP值来识别关键因素，如水体邻近度、海拔和季节性变化，准确度达98%，为基础设施规划提供了可扩展的工具。


<details>
  <summary>Details</summary>
Motivation: 随着各国寻求化石燃料的可持续替代品，绿色氢气已成为脱碳的重要战略途径，尤其是在太阳能丰富的干旱地区。然而，确定氢气生产的最佳地点需要整合复杂的环境、大气和基础设施因素，并且通常由于直接氢气产量数据的可用性有限而变得复杂。

Method: 本研究的框架包括一个多阶段流程：无监督多变量聚类、有监督机器学习分类器和SHAP算法。该流程在集成的气象、地形和时间数据上进行训练。

Result: 研究结果显示了适用性的独特空间模式以及变量的相对影响。模型的预测准确度为98%。研究还表明，在阿曼，水体邻近度、海拔和季节性变化是决定绿色氢气场地适用性的最重要因素，其平均绝对SHAP值分别为2.470891、2.376296和1.273216。

Conclusion: 本研究提出了一个新颖的人工智能（AI）框架，利用平均绝对SHAP值计算绿色氢气产量和场地适用性指数。该框架为数据稀缺地区提供了一个客观且可重复的替代方法，用于绿色氢气基础设施规划和决策制定。

Abstract: As nations seek sustainable alternatives to fossil fuels, green hydrogen has
emerged as a promising strategic pathway toward decarbonisation, particularly
in solar-rich arid regions. However, identifying optimal locations for hydrogen
production requires the integration of complex environmental, atmospheric, and
infrastructural factors, often compounded by limited availability of direct
hydrogen yield data. This study presents a novel Artificial Intelligence (AI)
framework for computing green hydrogen yield and site suitability index using
mean absolute SHAP (SHapley Additive exPlanations) values. This framework
consists of a multi-stage pipeline of unsupervised multi-variable clustering,
supervised machine learning classifier and SHAP algorithm. The pipeline trains
on an integrated meteorological, topographic and temporal dataset and the
results revealed distinct spatial patterns of suitability and relative
influence of the variables. With model predictive accuracy of 98%, the result
also showed that water proximity, elevation and seasonal variation are the most
influential factors determining green hydrogen site suitability in Oman with
mean absolute shap values of 2.470891, 2.376296 and 1.273216 respectively.
Given limited or absence of ground-truth yield data in many countries that have
green hydrogen prospects and ambitions, this study offers an objective and
reproducible alternative to subjective expert weightings, thus allowing the
data to speak for itself and potentially discover novel latent groupings
without pre-imposed assumptions. This study offers industry stakeholders and
policymakers a replicable and scalable tool for green hydrogen infrastructure
planning and other decision making in data-scarce regions.

</details>


### [273] [Domain Generalization via Pareto Optimal Gradient Matching](https://arxiv.org/abs/2507.14227)
*Khoi Do,Duong Nguyen,Nam-Khanh Le,Quoc-Viet Pham,Binh-Son Hua,Won-Joo Hwang*

Main category: cs.LG

TL;DR: 提出POGM方法解决梯度下降的域泛化问题，通过帕累托最优梯度匹配实现跨域一致性，并提高计算效率。


<details>
  <summary>Details</summary>
Motivation: 现有基于梯度的方法存在两个主要挑战：一是梯度经验距离或梯度的内积（GIP）最小化会导致跨域梯度波动，二是将梯度学习直接应用于联合损失函数会因二阶导数近似而产生高计算开销。

Method: 提出了一种新的帕累托最优梯度匹配（POGM）方法，该方法将梯度轨迹作为收集的数据，并在元学习器中进行独立训练。在元更新中，通过最大化梯度内积（GIP）并限制学习到的梯度不偏离经验风险最小化梯度轨迹太远，来解决梯度波动和计算开销问题。

Result: POGM方法解决了现有方法的挑战，实现了跨域梯度的一致性，同时具有计算效率。

Conclusion: POGM方法在DomainBed数据集上的实验评估结果具有竞争力，并且计算效率高。

Abstract: In this study, we address the gradient-based domain generalization problem,
where predictors aim for consistent gradient directions across different
domains. Existing methods have two main challenges. First, minimization of
gradient empirical distance or gradient inner products (GIP) leads to gradient
fluctuations among domains, thereby hindering straightforward learning. Second,
the direct application of gradient learning to the joint loss function can
incur high computation overheads due to second-order derivative approximation.
To tackle these challenges, we propose a new Pareto Optimality Gradient
Matching (POGM) method. In contrast to existing methods that add gradient
matching as regularization, we leverage gradient trajectories as collected data
and apply independent training at the meta-learner. In the meta-update, we
maximize GIP while limiting the learned gradient from deviating too far from
the empirical risk minimization gradient trajectory. By doing so, the aggregate
gradient can incorporate knowledge from all domains without suffering gradient
fluctuation towards any particular domain. Experimental evaluations on datasets
from DomainBed demonstrate competitive results yielded by POGM against other
baselines while achieving computational efficiency.

</details>


### [274] [A million-scale dataset and generalizable foundation model for nanomaterial-protein interactions](https://arxiv.org/abs/2507.14245)
*Hengjie Yu,Kenneth A. Dawson,Haiyun Yang,Shuya Liu,Yan Yan,Yaochu Jin*

Main category: cs.LG

TL;DR: 介绍了一个名为NanoPro-3M的大型纳米材料-蛋白质相互作用数据集和一个名为NanoProFormer的基础模型，该模型利用多模态表征学习来预测纳米材料-蛋白质亲和力，并在各种下游任务中表现出优越的性能和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 为了解锁纳米材料在医学和环境科学中的潜力，理解它们与蛋白质的相互作用至关重要，但现有模型存在数据集有限和泛化性受限的问题。

Method: 提出了一种名为NanoProFormer的基础模型，该模型通过多模态表征学习来预测纳米材料-蛋白质亲和力。

Result: NanoPro-3M是迄今为止最大的纳米材料-蛋白质相互作用数据集，包含超过320万个样本和37,000个独特的蛋白质。NanoProFormer模型展示了强大的泛化能力，能够处理缺失的特征以及未知的纳米材料或蛋白质，并且其多模态建模显著优于单一模态的方法，还确定了冠层形成的关键决定因素。

Conclusion: 该研究为高性能、泛化的纳米材料-蛋白质相互作用预测奠定了坚实的基础，减少了对实验的依赖，并加速了各种体外应用。

Abstract: Unlocking the potential of nanomaterials in medicine and environmental
science hinges on understanding their interactions with proteins, a complex
decision space where AI is poised to make a transformative impact. However,
progress has been hindered by limited datasets and the restricted
generalizability of existing models. Here, we propose NanoPro-3M, the largest
nanomaterial-protein interaction dataset to date, comprising over 3.2 million
samples and 37,000 unique proteins. Leveraging this, we present NanoProFormer,
a foundational model that predicts nanomaterial-protein affinities through
multimodal representation learning, demonstrating strong generalization,
handling missing features, and unseen nanomaterials or proteins. We show that
multimodal modeling significantly outperforms single-modality approaches and
identifies key determinants of corona formation. Furthermore, we demonstrate
its applicability to a range of downstream tasks through zero-shot inference
and fine-tuning. Together, this work establishes a solid foundation for
high-performance and generalized prediction of nanomaterial-protein interaction
endpoints, reducing experimental reliance and accelerating various in vitro
applications.

</details>


### [275] [$k$-PCA for (non-squared) Euclidean Distances: Polynomial Time Approximation](https://arxiv.org/abs/2507.14631)
*Daniel Greenhut,Dan Feldman*

Main category: cs.LG

TL;DR: 本文提出了首个能在大约k维子空间中值（比k维子空间均值更稀疏且对噪声/异常值更鲁棒）的近似值（近似因子为$\\"	ext{sqrt(d)}$）的确定性算法，其运行时间不依赖于k的指数。


<details>
  <summary>Details</summary>
Motivation: k维子空间中值比k维子空间均值更稀疏且对噪声/异常值更鲁棒，但由于其非凸性，近似起来更困难。

Method: 提出了一种多项式时间确定性算法来近似k维子空间中值，近似因子为$\\"	ext{sqrt(d)}$。

Result: 提供了一种确定性算法，其运行时间和近似因子均不依赖于k的指数，近似因子为$\\"	ext{sqrt(d)}$。

Conclusion: 本论文提出了一种确定性算法，用于在多项式时间内近似k维子空间中值，其运行时间和近似因子均不依赖于k的指数。

Abstract: Given an integer $k\geq1$ and a set $P$ of $n$ points in $\REAL^d$, the
classic $k$-PCA (Principle Component Analysis) approximates the affine
\emph{$k$-subspace mean} of $P$, which is the $k$-dimensional affine linear
subspace that minimizes its sum of squared Euclidean distances
($\ell_{2,2}$-norm) over the points of $P$, i.e., the mean of these distances.
The \emph{$k$-subspace median} is the subspace that minimizes its sum of
(non-squared) Euclidean distances ($\ell_{2,1}$-mixed norm), i.e., their
median. The median subspace is usually more sparse and robust to noise/outliers
than the mean, but also much harder to approximate since, unlike the
$\ell_{z,z}$ (non-mixed) norms, it is non-convex for $k<d-1$.
  We provide the first polynomial-time deterministic algorithm whose both
running time and approximation factor are not exponential in $k$. More
precisely, the multiplicative approximation factor is $\sqrt{d}$, and the
running time is polynomial in the size of the input. We expect that our
technique would be useful for many other related problems, such as $\ell_{2,z}$
norm of distances for $z\not \in \br{1,2}$, e.g., $z=\infty$, and handling
outliers/sparsity.
  Open code and experimental results on real-world datasets are also provided.

</details>


### [276] [Linearized Diffusion Map](https://arxiv.org/abs/2507.14257)
*Julio Candanedo*

Main category: cs.LG

TL;DR: LDM 是一种新的线性降维方法，它结合了非线性方法的几何直觉和线性方法的计算效率，在处理具有流形结构的复杂数据集时优于 PCA。


<details>
  <summary>Details</summary>
Motivation: 该研究旨在将基于扩散的非线性方法的几何直觉与 PCA 和经典 MDS 等线性嵌入固有的计算简单性、效率和可解释性相结合。

Method: LDM 通过对扩散映射核进行线性近似来构建，是一种新颖的线性降维方法。

Result: 与 PCA 相比，LDM 在具有明显流形结构的合成和真实数据集（包括 MNIST 和 COIL-20）上展示了捕捉独特几何特征的能力，特别是在高维情况下。LDM 的完整正核矩阵可以直接应用于非负矩阵分解 (NMF)，为可解释的潜在结构发现提供了机会。

Conclusion: LDM 是一种有价值的新型线性降维技术，具有广阔的理论和实践前景。

Abstract: We introduce the Linearized Diffusion Map (LDM), a novel linear
dimensionality reduction method constructed via a linear approximation of the
diffusion-map kernel. LDM integrates the geometric intuition of diffusion-based
nonlinear methods with the computational simplicity, efficiency, and
interpretability inherent in linear embeddings such as PCA and classical MDS.
Through comprehensive experiments on synthetic datasets (Swiss roll and
hyperspheres) and real-world benchmarks (MNIST and COIL-20), we illustrate that
LDM captures distinct geometric features of datasets compared to PCA, offering
complementary advantages. Specifically, LDM embeddings outperform PCA in
datasets exhibiting explicit manifold structures, particularly in
high-dimensional regimes, whereas PCA remains preferable in scenarios dominated
by variance or noise. Furthermore, the complete positivity of LDM's kernel
matrix allows direct applicability of Non-negative Matrix Factorization (NMF),
suggesting opportunities for interpretable latent-structure discovery. Our
analysis positions LDM as a valuable new linear dimensionality reduction
technique with promising theoretical and practical extensions.

</details>


### [277] [A Simple "Try Again" Can Elicit Multi-Turn LLM Reasoning](https://arxiv.org/abs/2507.14295)
*Licheng Liu,Zihan Wang,Linjie Li,Chenwei Xu,Yiping Lu,Han Liu,Avirup Sil,Manling Li*

Main category: cs.LG

TL;DR: 通过使用“Unary Feedback as Observation”（UFO）框架，我们证明了在强化学习中利用简单的否定反馈可以显著提高大型语言模型在多轮问题解决和响应反馈方面的能力。


<details>
  <summary>Details</summary>
Motivation: 现有强化学习方法在单轮范式中训练大型推理模型，使用可验证的奖励，但这会导致模型在多轮推理中表现不佳，并且难以根据上下文反馈进行修正，从而产生重复性响应。本研究旨在解决LRM在多轮上下文中反思和修正答案的能力问题。

Method: 提出了一种名为“Unary Feedback as Observation”（UFO）的方法，该方法将仅包含否定反馈的单轮反馈用于强化学习，并将其应用于现有的单轮强化学习训练设置中。此外，还设计了奖励结构来指导模型在每个回合中生成谨慎和深思熟虑的答案，以尽量减少获得正确答案所需的回合数并鼓励在出现错误时进行多样化推理。

Result: 实验结果表明，使用UFO进行强化学习训练可以保持模型的单轮性能，并将多轮推理准确率提高高达14%，使语言模型能够更好地响应多轮问题解决中的反馈。

Conclusion: 该研究表明，在强化学习中使用仅包含否定反馈（例如，“让我们再试一次”）的单轮反馈可以提高大型推理模型（LRM）的单轮性能和多轮推理能力，并且还能让模型更好地响应多轮问题解决中的反馈。

Abstract: Multi-turn problem solving is critical yet challenging for Large Reasoning
Models (LRMs) to reflect on their reasoning and revise from feedback. Existing
Reinforcement Learning (RL) methods train large reasoning models on a
single-turn paradigm with verifiable rewards. However, we observe that models
trained with existing RL paradigms often lose their ability to solve problems
across multiple turns and struggle to revise answers based on contextual
feedback, leading to repetitive responses. We ask: can LRMs learn to reflect
their answers in a multi-turn context? In this work, we find that training
models with multi-turn RL using only unary feedback (e.g., "Let's try again")
after wrong answers can improve both single-turn performance and multi-turn
reasoning. We introduce Unary Feedback as Observation (UFO) for reinforcement
learning, which uses minimal yet common unary user feedback during iterative
problem solving. It can be easily applied to existing single-turn RL training
setups. Experimental results show that RL training with UFO keeps single-turn
performance and improves multi-turn reasoning accuracy by up to 14%, enabling
language models to better react to feedback in multi-turn problem solving. To
further minimize the number of turns needed for a correct answer while
encouraging diverse reasoning when mistakes occur, we design reward structures
that guide models to produce careful and deliberate answers in each turn. Code:
https://github.com/lichengliu03/unary-feedback

</details>


### [278] [Better Models and Algorithms for Learning Ising Models from Dynamics](https://arxiv.org/abs/2507.15173)
*Jason Gaitonde,Ankur Moitra,Elchanan Mossel*

Main category: cs.LG

TL;DR: 本研究首次提出了仅在配置变化时观察马尔可夫链演化来学习伊辛模型的方法，算法效率高，适用于更现实的场景。


<details>
  <summary>Details</summary>
Motivation: 先前关于从马尔可夫链演化中学习伊辛模型的研究，通常假设需要观察到所有站点更新尝试（即使没有改变配置），而这种假设在现实场景中难以满足。本研究的动机是提出一种更自然的学习模型，即仅在配置发生变化时进行观察，并为这种更现实的观测模型设计有效的学习算法。

Method: 研究人员提出了一种新的算法，该算法能够在仅观察到配置变化的情况下学习伊辛模型。具体而言，该算法首先在多项式时间内恢复模型的依赖图，然后通过附加的对数时间内恢复模型参数。该方法利用了可逆马尔可夫链的稳健性质，并适用于包括Metropolis链在内的更广泛的可逆单站点马尔可夫链。

Result: 对于最大度为d的伊辛模型，本研究提出的算法能够在 $\mathsf{poly}(d)\cdot n^2\log n$ 时间内恢复依赖图，并在 $\widetilde{O}(2^d n)$ 时间内恢复参数。这在更弱的观测模型下，其性能在时间复杂度上可与独立同分布（i.i.d.）设置下的现有技术相媲美。

Conclusion: 该研究首次提出了在仅观察到配置发生变化的马尔可夫链演化的情况下，学习伊辛模型（Ising model）的算法。对于最大度为d的伊辛模型，算法可以在多项式时间内恢复依赖图，并在附加的近似对数时间内恢复参数。该算法的分析更广泛地适用于一类可逆的单站点马尔可夫链，包括流行的Metropolis链，利用了可逆马尔可夫链的更稳健性质。

Abstract: We study the problem of learning the structure and parameters of the Ising
model, a fundamental model of high-dimensional data, when observing the
evolution of an associated Markov chain. A recent line of work has studied the
natural problem of learning when observing an evolution of the well-known
Glauber dynamics [Bresler, Gamarnik, Shah, IEEE Trans. Inf. Theory 2018,
Gaitonde, Mossel STOC 2024], which provides an arguably more realistic
generative model than the classical i.i.d. setting. However, this prior work
crucially assumes that all site update attempts are observed, \emph{even when
this attempt does not change the configuration}: this strong observation model
is seemingly essential for these approaches. While perhaps possible in
restrictive contexts, this precludes applicability to most realistic settings
where we can observe \emph{only} the stochastic evolution itself, a minimal and
natural assumption for any process we might hope to learn from. However,
designing algorithms that succeed in this more realistic setting has remained
an open problem [Bresler, Gamarnik, Shah, IEEE Trans. Inf. Theory 2018,
Gaitonde, Moitra, Mossel, STOC 2025].
  In this work, we give the first algorithms that efficiently learn the Ising
model in this much more natural observation model that only observes when the
configuration changes. For Ising models with maximum degree $d$, our algorithm
recovers the underlying dependency graph in time $\mathsf{poly}(d)\cdot n^2\log
n$ and then the actual parameters in additional $\widetilde{O}(2^d n)$ time,
which qualitatively matches the state-of-the-art even in the i.i.d. setting in
a much weaker observation model. Our analysis holds more generally for a
broader class of reversible, single-site Markov chains that also includes the
popular Metropolis chain by leveraging more robust properties of reversible
Markov chains.

</details>


### [279] [Rethinking Individual Fairness in Deepfake Detection](https://arxiv.org/abs/2507.14326)
*Aryana Hou,Li Lin,Justin Li,Shu Hu*

Main category: cs.LG

TL;DR: 深度伪造检测存在公平性问题，尤其是在个体公平性方面。本研究提出了首个提升深度伪造检测个体公平性的框架，并在实验中证明了其有效性。


<details>
  <summary>Details</summary>
Motivation: 现有的深度伪造检测技术在公平性方面存在不足，特别是对个体公平性的关注不够，使得深度伪造制作者能够利用基于特定人群的偏见。本研究旨在解决这一问题，填补现有研究的空白。

Method: 提出一个可集成到现有深度伪造检测器中的通用框架，以增强个体公平性和泛化能力。

Result: 实验结果表明，所提出的方法显著提高了深度伪造检测的个体公平性，同时保持了鲁棒的检测性能，并在领先的深度伪造数据集上超越了现有最先进的方法。

Conclusion: 本研究提出了首个旨在提升深度伪造检测中个体公平性的通用框架，并证明了该框架在保持强大检测性能的同时，能够显著改善个体公平性，优于现有最先进的方法。

Abstract: Generative AI models have substantially improved the realism of synthetic
media, yet their misuse through sophisticated DeepFakes poses significant
risks. Despite recent advances in deepfake detection, fairness remains
inadequately addressed, enabling deepfake markers to exploit biases against
specific populations. While previous studies have emphasized group-level
fairness, individual fairness (i.e., ensuring similar predictions for similar
individuals) remains largely unexplored. In this work, we identify for the
first time that the original principle of individual fairness fundamentally
fails in the context of deepfake detection, revealing a critical gap previously
unexplored in the literature. To mitigate it, we propose the first
generalizable framework that can be integrated into existing deepfake detectors
to enhance individual fairness and generalization. Extensive experiments
conducted on leading deepfake datasets demonstrate that our approach
significantly improves individual fairness while maintaining robust detection
performance, outperforming state-of-the-art methods. The code is available at
https://github.com/Purdue-M2/Individual-Fairness-Deepfake-Detection.

</details>


### [280] [Development and Deployment of Hybrid ML Models for Critical Heat Flux Prediction in Annulus Geometries](https://arxiv.org/abs/2507.14332)
*Aidan Furlong,Xingang Zhao,Robert Salko,Xu Wu*

Main category: cs.LG

TL;DR: 本研究提出了一种混合机器学习方法，用于提高环形几何中临界热通量（CHF）的预测精度。该方法通过机器学习模型修正传统经验模型的预测残差，实验结果显示平均相对误差显著降低，优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 传统的经验关联和查找表在预测临界热通量（CHF）方面存在局限性，且现有基于机器学习的方法缺乏可解释性、抗数据稀疏性能力差，并且主要基于管状几何。因此，需要开发适用于环形几何的、更准确且可解释的CHF预测方法，以支持反应堆的安全分析。

Method: 研究采用了基于机器学习的混合方法，利用深度学习模型来修正传统经验模型（Biasi、Bowring、Katto）的预测残差，以提高临界热通量（CHF）的预测精度。数据来源于四个数据集（Becker、Beus、Janssen、Mortimore）的577个实验数据点，并使用CTF子通道代码进行了部署和验证。

Result: 研究结果表明，所开发的混合机器学习模型将临界热通量（CHF）的平均相对误差从经验相关模型的26%以上降低到3.5%以下，且仅有一个数据点的误差超过10%。这表明机器学习模型在预测环形几何中的CHF方面远优于传统的经验模型。

Conclusion: 本研究成功开发、部署并验证了四个机器学习模型，用于预测环形几何中的临界热通量（CHF）。与传统的经验相关模型相比，这些混合机器学习模型显著提高了预测精度，平均相对误差从26%以上降低到3.5%以下。

Abstract: Accurate prediction of critical heat flux (CHF) is an essential component of
safety analysis in pressurized and boiling water reactors. To support reliable
prediction of this quantity, several empirical correlations and lookup tables
have been constructed from physical experiments over the past several decades.
With the onset of accessible machine learning (ML) frameworks, multiple
initiatives have been established with the goal of predicting CHF more
accurately than these traditional methods. While purely data-driven surrogate
modeling has been extensively investigated, these approaches lack
interpretability, lack resilience to data scarcity, and have been developed
mostly using data from tube experiments. As a result, bias-correction hybrid
approaches have become increasingly popular, which correct initial
"low-fidelity" estimates provided by deterministic base models by using
ML-predicted residuals. This body of work has mostly considered round tube
geometries; annular geometry-specific ML models have not yet been deployed in
thermal hydraulic codes. This study developed, deployed, and validated four ML
models to predict CHF in annular geometries using the CTF subchannel code.
Three empirical correlation models, Biasi, Bowring, and Katto, were used as
base models for comparison. The ML models were trained and tested using 577
experimental annulus data points from four datasets: Becker, Beus, Janssen, and
Mortimore. Baseline CHF predictions were obtained from the empirical
correlations, with mean relative errors above 26%. The ML-driven models
achieved mean relative errors below 3.5%, with no more than one point exceeding
the 10% error envelope. In all cases, the hybrid ML models significantly
outperformed their empirical counterparts.

</details>


### [281] [Influence Functions for Preference Dataset Pruning](https://arxiv.org/abs/2507.14344)
*Daniel Fein,Gabriela Aranguiz-Dias*

Main category: cs.LG

TL;DR: 使用影响函数过滤语言模型微调数据集可以轻微提高准确性，但对于识别有益示例，梯度相似性效果更好。


<details>
  <summary>Details</summary>
Motivation: 在对语言模型进行微调以改进其性能的过程中，通常会使用包含噪声的、特别是人类偏好的数据集。该研究的动机是探索一种过滤这些数据集的方法，以提高模型性能。

Method: 通过使用共轭梯度近似影响函数来过滤 TL;DR 数据集，并与梯度相似性进行比较。

Result: 影响函数过滤在移除 10% 的训练示例后，在模型重新训练的准确性上产生了 1.5% 的小幅提升。此外，实验表明梯度相似性在识别有益训练示例方面优于影响函数。

Conclusion: 该研究表明，在因果关系图中，局部曲率对于检测有害的训练示例很重要，但对于识别有益的示例则不太重要。

Abstract: Language models are commonly fine-tuned via reinforcement learning to alter
their behavior or elicit new capabilities. Datasets used for these purposes,
and particularly human preference datasets, are often noisy. The relatively
small size post-training datasets, combined with parameter-efficient
fine-tuning methods, enable the use of influence functions approximations to
detect and prune training examples that are harmful to performance on a
validation set. In this work, we adapt the TL;DR dataset for reward model
training to demonstrate how conjugate-gradient approximated influence functions
can be used to filter datasets. In our experiments, influence function
filtering yields a small retraining accuracy uplift of 1.5% after removing 10%
of training examples. We also show that gradient similarity outperforms
influence functions for detecting helpful training examples. This suggests that
local curvature is important for detecting harmful training examples, but less
so for identifying helpful examples.

</details>


### [282] [Solo Connection: A Parameter Efficient Fine-Tuning Technique for Transformers](https://arxiv.org/abs/2507.14353)
*Harsh Nilesh Pathak,Randy Paffenroth*

Main category: cs.LG

TL;DR: PEFT methods like LoRA fine-tune LLMs by adjusting weight matrices. This paper introduces Solo Connection, which adapts representations at the decoder-block level instead. Solo Connection outperforms LoRA and significantly reduces trainable parameters, motivated by homotopy theory and the need for better fine-tuning in large LLMs.


<details>
  <summary>Details</summary>
Motivation: The need to revisit how skip connections are employed during fine-tuning, especially in larger language models with many decoder blocks, and to find more parameter-efficient fine-tuning approaches than LoRA.

Method: Solo Connection introduces a trainable linear transformation that gradually interpolates between a zero vector and the task-specific representation, enabling smooth and stable adaptation. It focuses on long skip connections that link outputs of different decoder blocks.

Result: Solo Connection outperforms LoRA on E2E natural language generation benchmarks, reduces trainable parameters by 59% relative to LoRA and by more than 99% compared to full fine-tuning of GPT2.

Conclusion: Solo Connection, a novel method that adapts the representation at the decoder-block level rather than modifying individual weight matrices, outperforms LoRA on E2E natural language generation benchmarks and significantly reduces trainable parameters.

Abstract: Parameter efficient fine tuning (PEFT) is a versatile and extensible approach
for adapting a Large Language Model (LLM) for newer tasks. One of the most
prominent PEFT approaches, Low Rank Adaptation (LoRA), primarily focuses on
adjusting the attention weight matrices within individual decoder blocks of a
Generative Pre trained Transformer (GPT2). In contrast, we introduce Solo
Connection a novel method that adapts the representation at the decoder-block
level rather than modifying individual weight matrices. Not only does Solo
Connection outperform LoRA on E2E natural language generation benchmarks, but
it also reduces the number of trainable parameters by 59% relative to LoRA and
by more than 99% compared to full fine-tuning of GPT2, an early version of
Large Language Models (LLMs). Solo Connection is also motivated by homotopy
theory: we introduce a trainable linear transformation that gradually
interpolates between a zero vector and the task-specific representation,
enabling smooth and stable adaptation over time. While skip connections in the
original 12 layer GPT2 are typically confined to individual decoder blocks,
subsequent GPT2 variants scale up to 48 layers, and even larger language models
can include 128 or more decoder blocks. These expanded architectures underscore
the need to revisit how skip connections are employed during fine-tuning. This
paper focuses on long skip connections that link outputs of different decoder
blocks, potentially enhancing the model's ability to adapt to new tasks while
leveraging pre-trained knowledge.

</details>


### [283] [Incremental Causal Graph Learning for Online Cyberattack Detection in Cyber-Physical Infrastructures](https://arxiv.org/abs/2507.14387)
*Arun Vignesh Malarkkan,Dongjie Wang,Haoyue Bai,Yanjie Fu*

Main category: cs.LG

TL;DR: INCADET 是一个用于实时网络攻击检测的新框架，通过增量学习因果图来解决传统方法的局限性，并在真实世界数据集上取得了优于现有方法的准确性、鲁棒性和适应性。


<details>
  <summary>Details</summary>
Motivation: 传统实时异常检测技术因对高数据方差和类别不平衡的统计敏感性而产生过多的误报。虽然一些研究试图通过对系统组件之间的因果关系进行建模来解决这些限制，但先前的工作主要集中在需要静态历史数据且无法泛化到实时环境的离线因果图方法。这些方法受到无法在没有重新训练的情况下适应数据分布的动态变化以及在缺乏实时监督的情况下存在灾难性遗忘风险的限制。

Method: INCADET 是一个新颖的框架，用于增量因果图学习，专门用于实时网络攻击检测。该框架通过在流式时间窗口中不断更新因果图来动态捕获不断演变的系统行为。该框架包括三个模块：1）早期症状检测：使用连续因果图中边权重分布的差异来检测系统状态的转变。2）增量因果图学习：利用经验回放和边强化来持续优化因果结构，同时保留先验知识。3）因果图分类：采用图卷积网络（GCN）来利用学习到的因果图对系统状态进行分类。

Result: INCADET 在真实世界的关键基础设施数据集上进行了广泛的实验，并在不断演变的攻击场景中，与静态因果和深度时间基线相比，在准确性、鲁棒性和适应性方面均表现优越。

Conclusion: INCADET 在真实世界的关键基础设施数据集上进行了广泛的实验，并在不断演变的攻击场景中，与静态因果和深度时间基线相比，在准确性、鲁棒性和适应性方面均表现优越。

Abstract: The escalating threat of cyberattacks on real-time critical infrastructures
poses serious risks to public safety, demanding detection methods that
effectively capture complex system interdependencies and adapt to evolving
attack patterns. Traditional real-time anomaly detection techniques often
suffer from excessive false positives due to their statistical sensitivity to
high data variance and class imbalance. To address these limitations, recent
research has explored modeling causal relationships among system components.
However, prior work mainly focuses on offline causal graph-based approaches
that require static historical data and fail to generalize to real-time
settings. These methods are fundamentally constrained by: (1) their inability
to adapt to dynamic shifts in data distribution without retraining, and (2) the
risk of catastrophic forgetting when lacking timely supervision in live
systems. To overcome these challenges, we propose INCADET, a novel framework
for incremental causal graph learning tailored to real-time cyberattack
detection. INCADET dynamically captures evolving system behavior by
incrementally updating causal graphs across streaming time windows. The
framework comprises three modules: 1) Early Symptom Detection: Detects
transitions in system status using divergence in edge-weight distributions
across sequential causal graphs. 2) Incremental Causal Graph Learning:
Leverages experience replay and edge reinforcement to continually refine causal
structures while preserving prior knowledge. 3) Causal Graph Classification:
Employs Graph Convolutional Networks (GCNs) to classify system status using the
learned causal graphs. Extensive experiments on real-world critical
infrastructure datasets demonstrate that INCADET achieves superior accuracy,
robustness, and adaptability compared to both static causal and deep temporal
baselines in evolving attack scenarios.

</details>


### [284] [It's Not That Simple. An Analysis of Simple Test-Time Scaling](https://arxiv.org/abs/2507.14419)
*Guojun Wu*

Main category: cs.LG

TL;DR: 简单测试时间缩放主要是通过限制长度来实现的，而不是像o1模型那样通过增加计算量来提升性能。


<details>
  <summary>Details</summary>
Motivation: 为了探究简单测试时间缩放的机制，并与o1模型的测试时间缩放行为进行比较，理解缩放测试时间的真正目标。

Method: 对简单测试时间缩放进行了分析，并将其与o1模型（如DeepSeek-R1@）进行了比较。

Result: 发现简单测试时间缩放主要是通过强制最大长度实现的，而放大缩放则会导致不一致。o1模型通过学习自然地放大测试时间计算来超越其峰值性能，而简单测试时间缩放会降低性能上限。

Conclusion: 简单测试时间缩放主要通过强制最大长度进行缩放，而通过追加“等待”进行缩放则会导致不一致。与o1模型不同，简单测试时间缩放会随着缩放而降低模型的性能上限。

Abstract: Prior work proposed simple test-time scaling, a method for replicating this
scaling behavior with models distilled from o1-like models by manually
controlling test-time compute: either scaling down by enforcing a maximum
length or scaling up by iteratively appending "Wait" when the model is about to
terminate its generation. This paper presents an analysis of simple test-time
scaling and finds that the scaling behavior is largely attributed to scaling
down by enforcing a maximum length. In contrast, fine-tuning on long CoT data
distilled from o1-like models has no significant impact on scaling behavior,
and scaling up by appending "Wait" leads to inconsistencies, as the model may
oscillate between solutions. A key distinction exists between scaling down by
enforcing a maximum length and scaling up test-time compute in o1-like models,
such as DeepSeek-R1\@. These models are typically allowed to utilize as much
compute as needed, with the only constraint being the model's maximum supported
length. By learning to naturally scale up test-time compute during
reinforcement learning, o1-like models surpass their peak performance when
scaling up. In contrast, simple test-time scaling progressively imposes a lower
upper limit on model performance as it scales down. While replicating the
test-time scaling behavior of o1 models can be straightforward by scaling down,
it is crucial to recognize that the goal of scaling test-time compute is to
unlock higher performance -- beyond what the model could originally achieve --
rather than merely reproducing the appearance of scaling behavior.

</details>


### [285] [Deep RL Dual Sourcing Inventory Management with Supply and Capacity Risk Awareness](https://arxiv.org/abs/2507.14446)
*Feng Liu,Ying Liu,Carson Eisenach*

Main category: cs.LG

TL;DR: 通过将供应链过程分解为深度学习模块，并使用深度强化学习进行预测和协调，从而更有效地解决大规模随机优化问题。


<details>
  <summary>Details</summary>
Motivation: 为解决大规模随机优化问题（如供应链优化中的多源多期库存管理）的有效应用强化学习。

Method: 利用干预模型，通过预训练的深度学习模型模拟和组合随机过程来探索解决方案空间。具体方法包括使用深度强化学习模型学习和预测随机供应链过程，并引入一个协调机制来预测跨产品约束下的对偶成本。

Result: 在多源多期库存管理问题上展示了该方法，证明了其在大型真实世界数据集上的改进性能。

Conclusion: 该方法将复杂的供应链约束分解为可扩展、可组合的深度学习模块，在大型真实世界数据集上提高了性能。

Abstract: In this work, we study how to efficiently apply reinforcement learning (RL)
for solving large-scale stochastic optimization problems by leveraging
intervention models. The key of the proposed methodology is to better explore
the solution space by simulating and composing the stochastic processes using
pre-trained deep learning (DL) models. We demonstrate our approach on a
challenging real-world application, the multi-sourcing multi-period inventory
management problem in supply chain optimization. In particular, we employ deep
RL models for learning and forecasting the stochastic supply chain processes
under a range of assumptions. Moreover, we also introduce a constraint
coordination mechanism, designed to forecast dual costs given the
cross-products constraints in the inventory network. We highlight that instead
of directly modeling the complex physical constraints into the RL optimization
problem and solving the stochastic problem as a whole, our approach breaks down
those supply chain processes into scalable and composable DL modules, leading
to improved performance on large real-world datasets. We also outline open
problems for future research to further investigate the efficacy of such
models.

</details>


### [286] [ReDiSC: A Reparameterized Masked Diffusion Model for Scalable Node Classification with Structured Predictions](https://arxiv.org/abs/2507.14484)
*Yule Li,Yifeng Lu,Zhen Wang,Zhewei Wei,Yaliang Li,Bolin Ding*

Main category: cs.LG

TL;DR: ReDiSC是一种新的结构化节点分类方法，它通过扩散模型学习节点标签的联合分布，并在大规模图上表现出优越的性能和效率。


<details>
  <summary>Details</summary>
Motivation: 现有的图神经网络（GNN）在节点分类任务中忽略了节点标签之间的相关性，这与实际情况相悖。

Method: 提出了一种名为ReDiSC的重参数化掩码扩散模型，用于结构化节点分类。ReDiSC通过变分期望最大化（EM）框架学习，估计节点标签的联合分布。

Result: ReDiSC在E步比DPM-SNC更有效率，其M步目标与流行的GNN和标签传播混合方法相关联。

Conclusion: ReDiSC在同质性和异质性图上都取得了优于或具有竞争力的性能，并且能够有效地扩展到大规模数据集，克服了先前结构化扩散方法存在的计算瓶颈。

Abstract: In recent years, graph neural networks (GNN) have achieved unprecedented
successes in node classification tasks. Although GNNs inherently encode
specific inductive biases (e.g., acting as low-pass or high-pass filters), most
existing methods implicitly assume conditional independence among node labels
in their optimization objectives. While this assumption is suitable for
traditional classification tasks such as image recognition, it contradicts the
intuitive observation that node labels in graphs remain correlated, even after
conditioning on the graph structure. To make structured predictions for node
labels, we propose ReDiSC, namely, Reparameterized masked Diffusion model for
Structured node Classification. ReDiSC estimates the joint distribution of node
labels using a reparameterized masked diffusion model, which is learned through
the variational expectation-maximization (EM) framework. Our theoretical
analysis shows the efficiency advantage of ReDiSC in the E-step compared to
DPM-SNC, a state-of-the-art model that relies on a manifold-constrained
diffusion model in continuous domain. Meanwhile, we explicitly link ReDiSC's
M-step objective to popular GNN and label propagation hybrid approaches.
Extensive experiments demonstrate that ReDiSC achieves superior or highly
competitive performance compared to state-of-the-art GNN, label propagation,
and diffusion-based baselines across both homophilic and heterophilic graphs of
varying sizes. Notably, ReDiSC scales effectively to large-scale datasets on
which previous structured diffusion methods fail due to computational
constraints, highlighting its significant practical advantage in structured
node classification tasks.

</details>


### [287] [Federated Reinforcement Learning in Heterogeneous Environments](https://arxiv.org/abs/2507.14487)
*Ukjo Hwang,Songnam Hong*

Main category: cs.LG

TL;DR: Federated Reinforcement Learning (FRL) with Environment Heterogeneity (FRL-EH) framework and FedRQ algorithm improve robustness and performance in diverse environments compared to existing methods.


<details>
  <summary>Details</summary>
Motivation: To address the challenge of statistical heterogeneity in local environments within Federated Reinforcement Learning (FRL), aiming to improve robustness and performance in real-world scenarios.

Method: We introduce a Federated Reinforcement Learning with Environment Heterogeneity (FRL-EH) framework. A novel global objective function is proposed to optimize a global policy for robust performance across heterogeneous local environments. FedRQ is proposed for tabular environments and theoretically proven for convergence. An extension using expectile loss is developed for continuous state spaces, enabling integration with DNN-based RL algorithms.

Result: Empirical evaluations show that our FRL algorithms (FedRQ and its extension) are effective and robust, consistently outperforming state-of-the-art FRL algorithms in diverse heterogeneous environments.

Conclusion: We propose FedRQ, a tabular FRL algorithm, and its extension to continuous state spaces, demonstrating superior performance and robustness against existing FRL algorithms in heterogeneous environments.

Abstract: We investigate a Federated Reinforcement Learning with Environment
Heterogeneity (FRL-EH) framework, where local environments exhibit statistical
heterogeneity. Within this framework, agents collaboratively learn a global
policy by aggregating their collective experiences while preserving the privacy
of their local trajectories. To better reflect real-world scenarios, we
introduce a robust FRL-EH framework by presenting a novel global objective
function. This function is specifically designed to optimize a global policy
that ensures robust performance across heterogeneous local environments and
their plausible perturbations. We propose a tabular FRL algorithm named FedRQ
and theoretically prove its asymptotic convergence to an optimal policy for the
global objective function. Furthermore, we extend FedRQ to environments with
continuous state space through the use of expectile loss, addressing the key
challenge of minimizing a value function over a continuous subset of the state
space. This advancement facilitates the seamless integration of the principles
of FedRQ with various Deep Neural Network (DNN)-based RL algorithms. Extensive
empirical evaluations validate the effectiveness and robustness of our FRL
algorithms across diverse heterogeneous environments, consistently achieving
superior performance over the existing state-of-the-art FRL algorithms.

</details>


### [288] [Glitches in Decision Tree Ensemble Models](https://arxiv.org/abs/2507.14492)
*Satyankar Chandra,Ashutosh Gupta,Kaushik Mallik,Krishna Shankaranarayanan,Namrita Varshney*

Main category: cs.LG

TL;DR: AI 模型中的“glitches”（输入空间中的小邻域，模型的输出会随着输入的微小变化而剧烈振荡）是不可靠行为的新来源。该研究为 glitches 提供了正式定义，证明了它们广泛存在于 GBDT 模型中，并提出了一种基于 MILP 的搜索算法，证明该问题是 NP 完备的。


<details>
  <summary>Details</summary>
Motivation: 随着越来越多的关键决策任务委托给机器学习模型，确保这些模型的可靠性和一致性至关重要。该研究旨在识别和解决导致模型不可靠行为的新型来源，即“glitches”，以提高 AI 决策的可信度。

Method: 该研究提出了一种新颖的 glitch 检测方法，该方法将问题形式化为混合整数线性规划（MILP）问题，并证明了 glitch 检测对于树深度为 4 的树集成来说是 NP 完备的。研究人员还开发了一种用于 GBDT 模型的 glitch 搜索算法，并在基准数据集上对其有效性和计算可行性进行了评估。

Result: 研究发现，glitches 在具有陡峭决策边界的 AI 模型中普遍存在，并且通常表明模型在 glitches 附近的邻域中存在不一致性。研究人员提出的 glitch 搜索算法在 GBDT 模型上的实验结果表明，该算法有效且计算上可行。

Conclusion: 该研究识别出一种名为“glitches”的新型不可靠行为，它会严重影响具有陡峭决策边界的 AI 模型。该研究为 glitches 提供了正式定义，并通过实验证明了 glitches 的广泛存在，并认为它们通常表明模型在 glitches 附近存在潜在的不一致性。最后，该研究提出了一种用于 GBDT 模型的 glitches 搜索算法，并证明了该问题的 NP 完备性。

Abstract: Many critical decision-making tasks are now delegated to machine-learned
models, and it is imperative that their decisions are trustworthy and reliable,
and their outputs are consistent across similar inputs. We identify a new
source of unreliable behaviors-called glitches-which may significantly impair
the reliability of AI models having steep decision boundaries. Roughly
speaking, glitches are small neighborhoods in the input space where the model's
output abruptly oscillates with respect to small changes in the input. We
provide a formal definition of glitches, and use well-known models and datasets
from the literature to demonstrate that they have widespread existence and
argue they usually indicate potential model inconsistencies in the neighborhood
of where they are found. We proceed to the algorithmic search of glitches for
widely used gradient-boosted decision tree (GBDT) models. We prove that the
problem of detecting glitches is NP-complete for tree ensembles, already for
trees of depth 4. Our glitch-search algorithm for GBDT models uses an MILP
encoding of the problem, and its effectiveness and computational feasibility
are demonstrated on a set of widely used GBDT benchmarks taken from the
literature.

</details>


### [289] [Generative Distribution Distillation](https://arxiv.org/abs/2507.14503)
*Jiequan Cui,Beier Zhu,Qingshan Xu,Xiaogang Xu,Pengguang Chen,Xiaojuan Qi,Bei Yu,Hanwang Zhang,Richang Hong*

Main category: cs.LG

TL;DR: 本文提出 GenDD 框架，通过分裂标记化和分布收缩技术，在无监督和有监督设置下均实现了知识蒸馏的最先进性能。


<details>
  <summary>Details</summary>
Motivation: 知识蒸馏（KD）在无监督和有监督设置下的应用。

Method: 本文将知识蒸馏（KD）构建为条件生成问题，提出了生成分布蒸馏（GenDD）框架。为解决无监督 KD 中的高维优化诅咒和语义监督缺失问题，引入了分裂标记化策略和分布收缩技术，后者将标签监督整合到重建目标中，实现了高效的监督训练。

Result: GenDD 在无监督设置下表现具有竞争力，在 ImageNet 验证集上比 KL 基线高出 16.29%。

Conclusion: GenDD 结合标签监督后，在 ImageNet 上的 ResNet-50 模型实现了 82.28% 的 top-1 准确率，创下新的最先进记录。

Abstract: In this paper, we formulate the knowledge distillation (KD) as a conditional
generative problem and propose the \textit{Generative Distribution Distillation
(GenDD)} framework. A naive \textit{GenDD} baseline encounters two major
challenges: the curse of high-dimensional optimization and the lack of semantic
supervision from labels. To address these issues, we introduce a \textit{Split
Tokenization} strategy, achieving stable and effective unsupervised KD.
Additionally, we develop the \textit{Distribution Contraction} technique to
integrate label supervision into the reconstruction objective. Our theoretical
proof demonstrates that \textit{GenDD} with \textit{Distribution Contraction}
serves as a gradient-level surrogate for multi-task learning, realizing
efficient supervised training without explicit classification loss on
multi-step sampling image representations. To evaluate the effectiveness of our
method, we conduct experiments on balanced, imbalanced, and unlabeled data.
Experimental results show that \textit{GenDD} performs competitively in the
unsupervised setting, significantly surpassing KL baseline by \textbf{16.29\%}
on ImageNet validation set. With label supervision, our ResNet-50 achieves
\textbf{82.28\%} top-1 accuracy on ImageNet in 600 epochs training,
establishing a new state-of-the-art.

</details>


### [290] [Positive-Unlabeled Learning for Control Group Construction in Observational Causal Inference](https://arxiv.org/abs/2507.14528)
*Ilias Tsoumas,Dimitrios Bormpoudakis,Vasileios Sitokonstantinou,Athanasios Askitopoulos,Andreas Kalogeras,Charalampos Kontoes,Ioannis Athanasiadis*

Main category: cs.LG

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: In causal inference, whether through randomized controlled trials or
observational studies, access to both treated and control units is essential
for estimating the effect of a treatment on an outcome of interest. When
treatment assignment is random, the average treatment effect (ATE) can be
estimated directly by comparing outcomes between groups. In non-randomized
settings, various techniques are employed to adjust for confounding and
approximate the counterfactual scenario to recover an unbiased ATE. A common
challenge, especially in observational studies, is the absence of units clearly
labeled as controls-that is, units known not to have received the treatment. To
address this, we propose positive-unlabeled (PU) learning as a framework for
identifying, with high confidence, control units from a pool of unlabeled ones,
using only the available treated (positive) units. We evaluate this approach
using both simulated and real-world data. We construct a causal graph with
diverse relationships and use it to generate synthetic data under various
scenarios, assessing how reliably the method recovers control groups that allow
estimates of true ATE. We also apply our approach to real-world data on optimal
sowing and fertilizer treatments in sustainable agriculture. Our findings show
that PU learning can successfully identify control (negative) units from
unlabeled data based only on treated units and, through the resulting control
group, estimate an ATE that closely approximates the true value. This work has
important implications for observational causal inference, especially in fields
where randomized experiments are difficult or costly. In domains such as earth,
environmental, and agricultural sciences, it enables a plethora of
quasi-experiments by leveraging available earth observation and climate data,
particularly when treated units are available but control units are lacking.

</details>


### [291] [Kernel Based Maximum Entropy Inverse Reinforcement Learning for Mean-Field Games](https://arxiv.org/abs/2507.14529)
*Berkay Anahtarci,Can Deha Kariksiz,Naci Saldi*

Main category: cs.LG

TL;DR: This paper presents an inverse reinforcement learning method for infinite-horizon mean-field games that uses reproducing kernel Hilbert spaces to model complex reward functions, overcoming limitations of previous approaches. It employs a Lagrangian relaxation and gradient ascent for efficient solution and proves theoretical consistency through operator differentiability, showing success in a traffic routing game.


<details>
  <summary>Details</summary>
Motivation: To address the limitations of existing inverse reinforcement learning approaches for mean-field games, which typically restrict the reward function to linear combinations of finite basis functions and rely on finite-horizon formulations. This work models the unknown reward function within a reproducing kernel Hilbert space to infer rich and potentially nonlinear reward structures from expert demonstrations in infinite-horizon settings.

Method: A Lagrangian relaxation is used to reformulate the maximum causal entropy inverse reinforcement learning problem as an unconstrained log-likelihood maximization problem, solved via a gradient ascent algorithm. The theoretical consistency is established by proving the Fréchet differentiability of the related soft Bellman operators.

Result: The method demonstrates effectiveness on a mean-field traffic routing game, accurately recovering expert behavior.

Conclusion: The proposed method accurately recovers expert behavior in a mean-field traffic routing game.

Abstract: We consider the maximum causal entropy inverse reinforcement learning problem
for infinite-horizon stationary mean-field games, in which we model the unknown
reward function within a reproducing kernel Hilbert space. This allows the
inference of rich and potentially nonlinear reward structures directly from
expert demonstrations, in contrast to most existing inverse reinforcement
learning approaches for mean-field games that typically restrict the reward
function to a linear combination of a fixed finite set of basis functions. We
also focus on the infinite-horizon cost structure, whereas prior studies
primarily rely on finite-horizon formulations. We introduce a Lagrangian
relaxation to this maximum causal entropy inverse reinforcement learning
problem that enables us to reformulate it as an unconstrained log-likelihood
maximization problem, and obtain a solution \lk{via} a gradient ascent
algorithm. To illustrate the theoretical consistency of the algorithm, we
establish the smoothness of the log-likelihood objective by proving the
Fr\'echet differentiability of the related soft Bellman operators with respect
to the parameters in the reproducing kernel Hilbert space. We demonstrate the
effectiveness of our method on a mean-field traffic routing game, where it
accurately recovers expert behavior.

</details>


### [292] [The Origin of Self-Attention: From Pairwise Affinity Matrices to Transformers](https://arxiv.org/abs/2507.14560)
*Giorgio Roffo*

Main category: cs.LG

TL;DR: Self-attention, common in Transformers, is a type of affinity-based computation. This paper links it to Infinite Feature Selection (Inf-FS), a more general method using affinity matrices. Key differences are how the matrix is defined and used (single vs. multi-hop steps). This view unifies research by showing a shared basis in pairwise relationships.


<details>
  <summary>Details</summary>
Motivation: The paper aims to trace the conceptual origins of the self-attention mechanism, a key component in modern deep learning, and connect it to a more general computational principle: learning and using pairwise affinity matrices to control information flow. By highlighting Infinite Feature Selection (Inf-FS) as a foundational and generalizable approach, the paper seeks to unify diverse machine learning research strands under a common mathematical foundation.

Method: The paper traces the conceptual origins of self-attention across computer vision, natural language processing, and graph learning, identifying the shared reliance on pairwise affinity matrices. It highlights Inf-FS as a foundational approach that generalizes affinity-based weighting and contrasts its methods (domain knowledge or learned matrices, multi-hop propagation) with the fixed dot-product structure and single-hop computation of self-attention.

Result: The analysis reveals that self-attention is a special case of Inf-FS, differing primarily in how the affinity matrix is constructed and utilized (single-hop vs. multi-hop propagation). This perspective unifies various machine learning research areas by identifying a common mathematical foundation in affinity-based computation.

Conclusion: Self-attention is a specific instance of the broader concept of affinity-based computation, exemplified by Infinite Feature Selection (Inf-FS). The key distinctions lie in the definition and application of the affinity matrix, with self-attention utilizing a single-hop computation based on token similarities, while Inf-FS allows for more general definitions and multi-hop propagation.

Abstract: The self-attention mechanism, now central to deep learning architectures such
as Transformers, is a modern instance of a more general computational
principle: learning and using pairwise affinity matrices to control how
information flows through a model. This paper traces the conceptual origins of
self-attention across multiple domains, including computer vision, natural
language processing, and graph learning, through their shared reliance on an
affinity matrix, denoted as A. We highlight Infinite Feature Selection (Inf-FS)
as a foundational approach that generalizes the idea of affinity-based
weighting. Unlike the fixed dot-product structure used in Transformers, Inf-FS
defines A either through domain knowledge or by learning, and computes feature
relevance through multi-hop propagation over the affinity graph. From this
perspective, self-attention can be seen as a special case of Inf-FS: it uses a
single-hop affinity computation where A is dynamically built from token
similarities. We argue that the underlying structure, reasoning over pairwise
relationships, is preserved across both approaches, and the key differences lie
in how the affinity matrix is defined and applied. By situating self-attention
within the broader paradigm of affinity-based computation, we unify several
strands of machine learning research and highlight a common mathematical
foundation that underpins diverse models and tasks.

</details>


### [293] [LPS-GNN : Deploying Graph Neural Networks on Graphs with 100-Billion Edges](https://arxiv.org/abs/2507.14570)
*Xu Cheng,Liang Yao,Feng He,Yukuo Cen,Yufei He,Chenhui Zhang,Wenzheng Feng,Hongyun Cai,Jie Tang*

Main category: cs.LG

TL;DR: LPS-GNN 是一个高效、低成本、灵活的 GNN 框架，通过新的图划分算法和子图增强策略解决了大规模图处理的难题，并在实际应用中取得了显著的性能提升。


<details>
  <summary>Details</summary>
Motivation: 现有 GNN 框架在处理大规模图时存在效率和精度难以平衡的问题，主要是由于迭代消息传递技术带来的计算和内存压力。

Method: 通过设计新的图划分算法 LPMetis 和子图增强策略，解决了现有 GNN 框架在处理大规模图时效率和精度的平衡问题。

Result: LPS-GNN 框架能够处理包含 1000 亿节点的图，在单 GPU 上仅需 10 小时即可完成，同时在用户获取场景下提高了 13.8% 的准确率，并在多个在线应用中超过了 SOTA 模型。

Conclusion: LPS-GNN 框架在实际应用中表现出色，在用户获取场景下提升了 13.8% 的效果，并且在其他在线应用中也实现了 8.24% 到 13.89% 的性能提升。

Abstract: Graph Neural Networks (GNNs) have emerged as powerful tools for various graph
mining tasks, yet existing scalable solutions often struggle to balance
execution efficiency with prediction accuracy. These difficulties stem from
iterative message-passing techniques, which place significant computational
demands and require extensive GPU memory, particularly when dealing with the
neighbor explosion issue inherent in large-scale graphs. This paper introduces
a scalable, low-cost, flexible, and efficient GNN framework called LPS-GNN,
which can perform representation learning on 100 billion graphs with a single
GPU in 10 hours and shows a 13.8% improvement in User Acquisition scenarios. We
examine existing graph partitioning methods and design a superior graph
partition algorithm named LPMetis. In particular, LPMetis outperforms current
state-of-the-art (SOTA) approaches on various evaluation metrics. In addition,
our paper proposes a subgraph augmentation strategy to enhance the model's
predictive performance. It exhibits excellent compatibility, allowing the
entire framework to accommodate various GNN algorithms. Successfully deployed
on the Tencent platform, LPS-GNN has been tested on public and real-world
datasets, achieving performance lifts of 8. 24% to 13. 89% over SOTA models in
online applications.

</details>


### [294] [A Transformer-Based Conditional GAN with Multiple Instance Learning for UAV Signal Detection and Classification](https://arxiv.org/abs/2507.14592)
*Haochen Liu,Jia Bi,Xiaomin Wang,Xin Yang,Ling Wang*

Main category: cs.LG

TL;DR: 提出了一种结合Transformer-GAN和MILET的新型框架，用于UAV飞行状态分类，解决了传统方法泛化能力不足和SOTA模型计算成本高的问题。该框架提高了准确性（最高98.6%），增强了计算效率和鲁棒性，适合资源受限环境的实时部署。


<details>
  <summary>Details</summary>
Motivation: 传统的时序分类（TSC）方法在动态UAV环境中缺乏鲁棒性和泛化能力，而像Transformer和LSTM这样的SOTA模型需要大量数据集和高计算成本，尤其是在处理高维数据流时，而精确检测和分类UAV（如悬停、巡航、爬升或转换）的飞行状态对于安全有效的运行至关重要。

Method: 提出了一种整合了基于Transformer的生成对抗网络（GAN）和多实例局部可解释学习（MILET）的新型框架。Transformer编码器捕捉长程时间依赖性和复杂的遥测动态，GAN模块使用真实的合成样本增强有限的数据集，MIL则专注于最具判别性的输入片段，以减少噪声和计算开销。

Result: 实验结果表明，该方法在DroneDetect数据集上达到了96.5%的准确率，在DroneRF数据集上达到了98.6%的准确率，优于其他SOTA方法。此外，该框架在计算效率和跨不同UAV平台及飞行状态的泛化能力方面表现出色。

Conclusion: 该框架在DroneDetect数据集上达到了96.5%的准确率，在DroneRF数据集上达到了98.6%的准确率，优于其他SOTA方法。该框架还展示了强大的计算效率和在不同UAV平台及飞行状态下的稳健泛化能力，表明其在资源受限环境中进行实时部署的潜力。

Abstract: Unmanned Aerial Vehicles (UAVs) are increasingly used in surveillance,
logistics, agriculture, disaster management, and military operations. Accurate
detection and classification of UAV flight states, such as hovering, cruising,
ascending, or transitioning, which are essential for safe and effective
operations. However, conventional time series classification (TSC) methods
often lack robustness and generalization for dynamic UAV environments, while
state of the art(SOTA) models like Transformers and LSTM based architectures
typically require large datasets and entail high computational costs,
especially with high-dimensional data streams. This paper proposes a novel
framework that integrates a Transformer-based Generative Adversarial Network
(GAN) with Multiple Instance Locally Explainable Learning (MILET) to address
these challenges in UAV flight state classification. The Transformer encoder
captures long-range temporal dependencies and complex telemetry dynamics, while
the GAN module augments limited datasets with realistic synthetic samples. MIL
is incorporated to focus attention on the most discriminative input segments,
reducing noise and computational overhead. Experimental results show that the
proposed method achieves superior accuracy 96.5% on the DroneDetect dataset and
98.6% on the DroneRF dataset that outperforming other SOTA approaches. The
framework also demonstrates strong computational efficiency and robust
generalization across diverse UAV platforms and flight states, highlighting its
potential for real-time deployment in resource constrained environments.

</details>


### [295] [Rec-AD: An Efficient Computation Framework for FDIA Detection Based on Tensor Train Decomposition and Deep Learning Recommendation Model](https://arxiv.org/abs/2507.14668)
*Yunfeng Li,Junhong Liu,Zhaohui Yang,Guofu Liao,Chuyun Zhang*

Main category: cs.LG

TL;DR: "Rec-AD is a new framework that makes deep learning models for detecting attacks in smart grids more efficient and faster, improving security."


<details>
  <summary>Details</summary>
Motivation: "To address the computational and memory burdens of deep learning models for FDIA detection in large-scale smart grid datasets, which limit detection efficiency."

Method: "Rec-AD integrates Tensor Train decomposition with the Deep Learning Recommendation Model (DLRM), using embedding compression, index reordering, and pipeline training to improve efficiency."

Result: "Rec-AD significantly improves computational throughput and real-time detection performance, narrowing the attack window and increasing attacker cost."

Conclusion: "Rec-AD enhances computational efficiency and real-time detection performance for FDIA in smart grids, strengthening edge computing and scalability."

Abstract: Deep learning models have been widely adopted for False Data Injection Attack
(FDIA) detection in smart grids due to their ability to capture unstructured
and sparse features. However, the increasing system scale and data
dimensionality introduce significant computational and memory burdens,
particularly in large-scale industrial datasets, limiting detection efficiency.
To address these issues, this paper proposes Rec-AD, a computationally
efficient framework that integrates Tensor Train decomposition with the Deep
Learning Recommendation Model (DLRM). Rec-AD enhances training and inference
efficiency through embedding compression, optimized data access via index
reordering, and a pipeline training mechanism that reduces memory communication
overhead. Fully compatible with PyTorch, Rec-AD can be integrated into existing
FDIA detection systems without code modifications. Experimental results show
that Rec-AD significantly improves computational throughput and real-time
detection performance, narrowing the attack window and increasing attacker
cost. These advancements strengthen edge computing capabilities and
scalability, providing robust technical support for smart grid security.

</details>


### [296] [Clustered Federated Learning for Generalizable FDIA Detection in Smart Grids with Heterogeneous Data](https://arxiv.org/abs/2507.14999)
*Yunfeng Li,Junhong Liu,Zhaohui Yang,Guofu Liao,Chuyun Zhang*

Main category: cs.LG

TL;DR: This paper introduces FedClusAvg, a federated learning framework to combat False Data Injection Attacks (FDIAs) in smart grids. It addresses challenges of Non-IID data and privacy concerns by using cluster-based sampling and hierarchical communication, improving detection accuracy while reducing communication costs. The framework enables secure and efficient FDIA detection in large-scale power systems.


<details>
  <summary>Details</summary>
Motivation: False Data Injection Attacks (FDIAs) pose severe security risks to smart grids by manipulating measurement data collected from spatially distributed devices such as SCADA systems and PMUs. These measurements typically exhibit Non-Independent and Identically Distributed (Non-IID) characteristics across different regions, which significantly challenges the generalization ability of detection models. Traditional centralized training approaches not only face privacy risks and data sharing constraints but also incur high transmission costs, limiting their scalability and deployment feasibility.

Method: FedClusAvg incorporates cluster-based stratified sampling and hierarchical communication (client-subserver-server) to enhance model generalization and reduce communication overhead. By enabling localized training and weighted parameter aggregation, the algorithm achieves accurate model convergence without centralizing sensitive data.

Result: Experimental results on benchmark smart grid datasets demonstrate that FedClusAvg not only improves detection accuracy under heterogeneous data distributions but also significantly reduces communication rounds and bandwidth consumption.

Conclusion: "False Data Injection Attacks (FDIAs) pose severe security risks to smart grids by manipulating measurement data collected from spatially distributed devices such as SCADA systems and PMUs. These measurements typically exhibit Non-Independent and Identically Distributed (Non-IID) characteristics across different regions, which significantly challenges the generalization ability of detection models. Traditional centralized training approaches not only face privacy risks and data sharing constraints but also incur high transmission costs, limiting their scalability and deployment feasibility. To address these issues, this paper proposes a privacy-preserving federated learning framework, termed Federated Cluster Average (FedClusAvg), designed to improve FDIA detection in Non-IID and resource-constrained environments. FedClusAvg incorporates cluster-based stratified sampling and hierarchical communication (client-subserver-server) to enhance model generalization and reduce communication overhead. By enabling localized training and weighted parameter aggregation, the algorithm achieves accurate model convergence without centralizing sensitive data. Experimental results on benchmark smart grid datasets demonstrate that FedClusAvg not only improves detection accuracy under heterogeneous data distributions but also significantly reduces communication rounds and bandwidth consumption. This work provides an effective solution for secure and efficient FDIA detection in large-scale distributed power systems."

Abstract: False Data Injection Attacks (FDIAs) pose severe security risks to smart
grids by manipulating measurement data collected from spatially distributed
devices such as SCADA systems and PMUs. These measurements typically exhibit
Non-Independent and Identically Distributed (Non-IID) characteristics across
different regions, which significantly challenges the generalization ability of
detection models. Traditional centralized training approaches not only face
privacy risks and data sharing constraints but also incur high transmission
costs, limiting their scalability and deployment feasibility. To address these
issues, this paper proposes a privacy-preserving federated learning framework,
termed Federated Cluster Average (FedClusAvg), designed to improve FDIA
detection in Non-IID and resource-constrained environments. FedClusAvg
incorporates cluster-based stratified sampling and hierarchical communication
(client-subserver-server) to enhance model generalization and reduce
communication overhead. By enabling localized training and weighted parameter
aggregation, the algorithm achieves accurate model convergence without
centralizing sensitive data. Experimental results on benchmark smart grid
datasets demonstrate that FedClusAvg not only improves detection accuracy under
heterogeneous data distributions but also significantly reduces communication
rounds and bandwidth consumption. This work provides an effective solution for
secure and efficient FDIA detection in large-scale distributed power systems.

</details>


### [297] [Revisiting Graph Contrastive Learning on Anomaly Detection: A Structural Imbalance Perspective](https://arxiv.org/abs/2507.14677)
*Yiming Xu,Zhen Peng,Bin Shi,Xu Hua,Bo Dong,Song Wang,Chen Chen*

Main category: cs.LG

TL;DR: AD-GCL通过邻域剪枝和异常引导的邻域补全等方法，解决了现有图对比学习模型在处理结构不平衡网络时的尾部异常检测能力不足的问题，提升了异常检测的鲁棒性和准确性。


<details>
  <summary>Details</summary>
Motivation: 现有图对比学习（GCL）模型在应用于异常检测任务时，虽然整体检测性能优越，但忽略了对结构不平衡（如幂律度分布）的鲁棒性，尤其可能无法检测到低度的尾部异常节点，这影响了其在现实高风险场景中的应用。

Method: 提出了一种名为AD-GCL的新型图对比学习框架，该框架包含邻域剪枝策略以过滤噪声边，并利用异常引导的邻域补全来扩大尾部节点的感受野。此外，还引入了原始图和增强图的视图内和视图间一致性损失。

Result: AD-GCL框架在整体、头部和尾部节点上的性能评估均证明了其在检测头部和尾部异常方面的全面优越性。

Conclusion: AD-GCL框架在检测头部异常和尾部异常方面均优于现有方法，并在多个数据集上得到了验证。

Abstract: The superiority of graph contrastive learning (GCL) has prompted its
application to anomaly detection tasks for more powerful risk warning systems.
Unfortunately, existing GCL-based models tend to excessively prioritize overall
detection performance while neglecting robustness to structural imbalance,
which can be problematic for many real-world networks following power-law
degree distributions. Particularly, GCL-based methods may fail to capture tail
anomalies (abnormal nodes with low degrees). This raises concerns about the
security and robustness of current anomaly detection algorithms and therefore
hinders their applicability in a variety of realistic high-risk scenarios. To
the best of our knowledge, research on the robustness of graph anomaly
detection to structural imbalance has received little scrutiny. To address the
above issues, this paper presents a novel GCL-based framework named AD-GCL. It
devises the neighbor pruning strategy to filter noisy edges for head nodes and
facilitate the detection of genuine tail nodes by aligning from head nodes to
forged tail nodes. Moreover, AD-GCL actively explores potential neighbors to
enlarge the receptive field of tail nodes through anomaly-guided neighbor
completion. We further introduce intra- and inter-view consistency loss of the
original and augmentation graph for enhanced representation. The performance
evaluation of the whole, head, and tail nodes on multiple datasets validates
the comprehensive superiority of the proposed AD-GCL in detecting both head
anomalies and tail anomalies.

</details>


### [298] [GCC-Spam: Spam Detection via GAN, Contrastive Learning, and Character Similarity Networks](https://arxiv.org/abs/2507.14679)
*Zixin Xu,Zhijie Wang,Zhiyuan Pan*

Main category: cs.LG

TL;DR: GCC-Spam框架通过结合字符相似性网络、对比学习和生成对抗网络（GAN）来解决垃圾短信检测中的对抗策略和数据稀缺性问题，并在真实数据集上取得了优于基线方法的性能。


<details>
  <summary>Details</summary>
Motivation: 互联网上垃圾短信呈指数级增长，有必要采取强大的检测机制来降低信息泄露和社会不稳定等风险。这项工作解决了两个主要挑战：垃圾信息发送者采用的对抗策略以及标记数据的稀缺性。

Method: 本文提出了一种新颖的垃圾短信检测框架GCC-Spam，该框架整合了三种核心创新：1. 字符相似性网络捕获拼写和语音特征，以应对字符混淆攻击，并为下游分类产生句子嵌入。2. 对比学习通过优化垃圾短信和普通短信在潜在空间中的距离来增强可辨别性。3. 生成对抗网络（GAN）生成逼真的伪垃圾短信样本，以缓解数据稀缺性，同时提高模型的鲁棒性和分类准确性。

Result: GCC-Spam框架在真实世界数据集上的广泛实验证明，该模型优于基线方法，在标记示例显著减少的情况下实现了更高的检测率。

Conclusion: GCC-Spam框架在真实世界数据集上的广泛实验证明，该模型优于基线方法，在标记示例显著减少的情况下实现了更高的检测率。

Abstract: The exponential growth of spam text on the Internet necessitates robust
detection mechanisms to mitigate risks such as information leakage and social
instability. This work addresses two principal challenges: adversarial
strategies employed by spammers and the scarcity of labeled data. We propose a
novel spam-text detection framework GCC-Spam, which integrates three core
innovations. First, a character similarity network captures orthographic and
phonetic features to counter character-obfuscation attacks and furthermore
produces sentence embeddings for downstream classification. Second, contrastive
learning enhances discriminability by optimizing the latent-space distance
between spam and normal texts. Third, a Generative Adversarial Network (GAN)
generates realistic pseudo-spam samples to alleviate data scarcity while
improving model robustness and classification accuracy. Extensive experiments
on real-world datasets demonstrate that our model outperforms baseline
approaches, achieving higher detection rates with significantly fewer labeled
examples.

</details>


### [299] [Spatial-Temporal Transformer with Curriculum Learning for EEG-Based Emotion Recognition](https://arxiv.org/abs/2507.14698)
*Xuetao Lin,Tianhao Peng,Peihong Dai,Yu Liang,Wenjun Wu*

Main category: cs.LG

TL;DR: 提出SST-CL框架，结合时空Transformer和课程学习，有效解决EEG情绪识别中的时空模式整合和情绪强度适应问题，并在实验中取得领先性能。


<details>
  <summary>Details</summary>
Motivation: 解决EEG情绪识别中两个基本挑战：(1) 非平稳时空神经模式的有效整合，(2) 在真实场景中对动态情绪强度变化的鲁棒适应。

Method: SST-CL框架，集成时空Transformer和课程学习。该方法包括一个空间编码器（对通道间关系进行建模）和一个时间编码器（通过窗口注意力机制捕获多尺度依赖关系），可同时提取EEG信号的空间相关性和时间动态。此外，还采用了一种感知强度的课程学习策略，通过基于双重难度评估的动态样本调度，逐步指导模型从高强度到低强度情绪状态进行训练。

Result: 在三个基准数据集上实现了最先进的性能，证明了SST-CL框架在不同情绪强度下的有效性。

Conclusion: 所提出的SST-CL框架在三个基准数据集上均展现了最先进的性能，并且在各种情绪强度水平下都表现出色。消融研究证实了其架构组件和课程学习机制的有效性。

Abstract: EEG-based emotion recognition plays an important role in developing adaptive
brain-computer communication systems, yet faces two fundamental challenges in
practical implementations: (1) effective integration of non-stationary
spatial-temporal neural patterns, (2) robust adaptation to dynamic emotional
intensity variations in real-world scenarios. This paper proposes SST-CL, a
novel framework integrating spatial-temporal transformers with curriculum
learning. Our method introduces two core components: a spatial encoder that
models inter-channel relationships and a temporal encoder that captures
multi-scale dependencies through windowed attention mechanisms, enabling
simultaneous extraction of spatial correlations and temporal dynamics from EEG
signals. Complementing this architecture, an intensity-aware curriculum
learning strategy progressively guides training from high-intensity to
low-intensity emotional states through dynamic sample scheduling based on a
dual difficulty assessment. Comprehensive experiments on three benchmark
datasets demonstrate state-of-the-art performance across various emotional
intensity levels, with ablation studies confirming the necessity of both
architectural components and the curriculum learning mechanism.

</details>


### [300] [Optimal Batch-Size Control for Low-Latency Federated Learning with Device Heterogeneity](https://arxiv.org/abs/2507.15601)
*Huiling Yang,Zhanwei Wang,Kaibin Huang*

Main category: cs.LG

TL;DR: 本文提出了一种 C^2 感知框架，通过最优批大小控制来最小化 6G 网络中联邦学习的延迟，同时确保收敛性，并考虑了设备异质性。


<details>
  <summary>Details</summary>
Motivation: 为了解决在高维度模型更新的计算和传输开销以及设备通信和计算（C^2）能力异质性的挑战，我们提出了一种新颖的 C^2 感知框架。

Method: 提出了一种新颖的 C^2 感知框架，用于最优批大小控制，以最小化端到端学习延迟并确保收敛。

Result: 所提出的批大小控制策略在考虑 C^2 折衷和设备异质性的情况下，实现了比传统方法更低的延迟和可比的准确性。

Conclusion: 所提出的策略优于未考虑 C^2 折衷或设备异质性的传统批大小适应方案。

Abstract: Federated learning (FL) has emerged as a popular approach for collaborative
machine learning in sixth-generation (6G) networks, primarily due to its
privacy-preserving capabilities. The deployment of FL algorithms is expected to
empower a wide range of Internet-of-Things (IoT) applications, e.g., autonomous
driving, augmented reality, and healthcare. The mission-critical and
time-sensitive nature of these applications necessitates the design of
low-latency FL frameworks that guarantee high learning performance. In
practice, achieving low-latency FL faces two challenges: the overhead of
computing and transmitting high-dimensional model updates, and the
heterogeneity in communication-and-computation (C$^2$) capabilities across
devices. To address these challenges, we propose a novel C$^2$-aware framework
for optimal batch-size control that minimizes end-to-end (E2E) learning latency
while ensuring convergence. The framework is designed to balance a fundamental
C$^2$ tradeoff as revealed through convergence analysis. Specifically,
increasing batch sizes improves the accuracy of gradient estimation in FL and
thus reduces the number of communication rounds required for convergence, but
results in higher per-round latency, and vice versa. The associated problem of
latency minimization is intractable; however, we solve it by designing an
accurate and tractable surrogate for convergence speed, with parameters fitted
to real data. This approach yields two batch-size control strategies tailored
to scenarios with slow and fast fading, while also accommodating device
heterogeneity. Extensive experiments using real datasets demonstrate that the
proposed strategies outperform conventional batch-size adaptation schemes that
do not consider the C$^2$ tradeoff or device heterogeneity.

</details>


### [301] [Fraud is Not Just Rarity: A Causal Prototype Attention Approach to Realistic Synthetic Oversampling](https://arxiv.org/abs/2507.14706)
*Claudio Giusti,Luca Guarnera,Mirko Casu,Sebastiano Battiato*

Main category: cs.LG

TL;DR: CPAC 是一种创新的信用卡欺诈检测方法，通过改进潜在空间结构和聚类分离来克服类别不平衡问题，取得了显著的性能提升。


<details>
  <summary>Details</summary>
Motivation: 现实世界数据中极端的类别不平衡以及欺诈与合法交易之间细微的模式差异，给检测带来了挑战。现有的方法，如生成模型，常常导致分类器过于自信和潜在聚类分离不佳。

Method: 提出了一种名为 CPAC（因果原型注意力分类器）的可解释架构，利用基于原型的注意力机制来增强聚类和潜在空间结构，并将其与 VAE-GAN 中的编码器相结合，以改善信用卡欺诈检测。

Result: 与传统的过采样方法（如 SMOTE）和最先进的生成模型相比，CPAC 取得了优越的性能，F1 分数达到了 93.14%，召回率达到了 90.18%，并改善了潜在聚类分离。

Conclusion: CPAC 是一种新的可解释架构，通过基于原型的注意力机制促进类别感知聚类和改进的潜在空间结构，并与 VAE-GAN 中的编码器相结合，可以提供更好的聚类分离，超越了事后样本增强。

Abstract: Detecting fraudulent credit card transactions remains a significant
challenge, due to the extreme class imbalance in real-world data and the often
subtle patterns that separate fraud from legitimate activity. Existing research
commonly attempts to address this by generating synthetic samples for the
minority class using approaches such as GANs, VAEs, or hybrid generative
models. However, these techniques, particularly when applied only to
minority-class data, tend to result in overconfident classifiers and poor
latent cluster separation, ultimately limiting real-world detection
performance. In this study, we propose the Causal Prototype Attention
Classifier (CPAC), an interpretable architecture that promotes class-aware
clustering and improved latent space structure through prototype-based
attention mechanisms and we will couple it with the encoder in a VAE-GAN
allowing it to offer a better cluster separation moving beyond post-hoc sample
augmentation. We compared CPAC-augmented models to traditional oversamplers,
such as SMOTE, as well as to state-of-the-art generative models, both with and
without CPAC-based latent classifiers. Our results show that classifier-guided
latent shaping with CPAC delivers superior performance, achieving an F1-score
of 93.14\% percent and recall of 90.18\%, along with improved latent cluster
separation. Further ablation studies and visualizations provide deeper insight
into the benefits and limitations of classifier-driven representation learning
for fraud detection. The codebase for this work will be available at final
submission.

</details>


### [302] [Exploring the Dynamic Scheduling Space of Real-Time Generative AI Applications on Emerging Heterogeneous Systems](https://arxiv.org/abs/2507.14715)
*Rachid Karami,Rajeev Patwari,Hyoukjun Kwon,Ashish Sirasao*

Main category: cs.LG

TL;DR: RTGen 工作负载在异构 SoC 上需要智能调度，以优化性能和满足实时性要求。


<details>
  <summary>Details</summary>
Motivation: 实时生成式 AI (RTGen) 工作负载结合了生成模型的计算密集度和实时推理的严格延迟和并发约束，而现代边缘平台上的异构 SoC 架构在调度复杂性和性能方面仍有待探索。

Method: 对 AMD 锐龙 AI 异构 SoC 上的 RTGen 工作负载进行了全面的特性分析，包括构建现实场景、跨后端性能分析、评估五种调度策略及其对实时指标和 LLM 性能的影响。

Result: 调度决策显著影响工作负载性能，平均导致 41.7% 的截止日期违规率差异，并强调了需要感知工作负载动态和硬件异构性的调度策略。

Conclusion: 在 AMD 锐龙 AI 等异构 SoC 上，需要有感知工作负载和硬件异构性的动态调度策略，以支持高性能的设备端 RTGen 应用。

Abstract: The integration of generative AI models, particularly large language models
(LLMs), into real-time multi-model AI applications such as video conferencing
and gaming is giving rise to a new class of workloads: real-time generative AI
(RTGen). These workloads combine the compute intensity and dynamic execution
patterns of generative models with the stringent latency and concurrency
constraints of real-time inference. To meet the diverse demands of RTGen
workloads, modern edge platforms increasingly adopt heterogeneous
system-on-chip (SoC) architectures that integrate CPUs, GPUs, and NPUs. Despite
the potential of heterogeneous SoC, the scheduling space complexity and
performance implications of RTGen workloads on such platforms remain
underexplored. In this work, we perform a comprehensive characterization of
RTGen workloads on AMD's latest heterogeneous SoC, Ryzen AI. We construct
realistic multi-model scenarios inspired by industry use cases and profile
model performance across all available backends. Using this data, we evaluate
five scheduling policies and their impact on both real-time metrics (e.g.,
deadline violation rate) and LLM performance (e.g., time-to-first-token and
tokens-per-second). Our results show that scheduling decisions significantly
affect workload performance (e.g., leading to a 41.7% difference in deadline
violation rates on average), and highlight the need for scheduling strategies
that are aware of workload dynamics and hardware heterogeneity. Our findings
underscore the importance of workload-aware, dynamic heterogeneous scheduling
in enabling high-performance, on-device RTGen applications.

</details>


### [303] [LeanTree: Accelerating White-Box Proof Search with Factorized States in Lean 4](https://arxiv.org/abs/2507.14722)
*Matěj Kripner,Michal Šustr,Milan Straka*

Main category: cs.LG

TL;DR: LeanTree通过将复杂证明状态分解为更简单的分支，并提供相应的数据集，来改进自动定理证明中的白盒方法，与黑盒方法相比具有多项优势，并在初步结果中显示出优越性。


<details>
  <summary>Details</summary>
Motivation: 为了解决大型语言模型（LLM）在自动定理证明（ATP）中缺乏正确性保证的问题，并弥补白盒方法在LLM应用中的不足。

Method: 提出了LeanTree，一个由Lean 4语言构建的工具，可以将复杂的证明状态分解为更简单、独立的分支，并提供了一个包含这些分解的中间状态的数据集。

Result: LeanTree工具可以简化评估、减少所需上下文、生成更丰富的数据、实现跨多个状态的并行搜索、支持状态的高效重用，并在出错时提供反馈。

Conclusion: 白盒方法在某些情况下优于黑盒方法。

Abstract: Automated theorem proving (ATP) has been a classical problem in artificial
intelligence since its inception, yet it remains challenging due to its vast
state and action space. Large language models (LLMs) have recently emerged as a
promising heuristic for ATP, but they lack correctness guarantees and thus
require interaction with a proof verifier. Such interactions typically follow
one of two approaches: black-box interaction, which does not utilize
intermediate proof states, or white-box approaches, which allow for incremental
proof construction and examination of intermediate states. While black-box
approaches have directly benefited from recent LLM advances, white-box methods
have comparatively lagged behind. In this paper, we address this gap by
introducing LeanTree, which consists of (i) a tool built in the Lean 4 language
that factorizes complex proof states into simpler, independent branches, and
(ii) a dataset of these factorized intermediate states. Our white-box tooling
offers several advantages over black-box approaches: it simplifies evaluation,
reduces necessary context, generates richer training data, enables parallel
search across multiple states, supports efficient reuse of states, and provides
feedback in case of errors. Our preliminary results hint that white-box
approaches outperform black-box alternatives in some settings.

</details>


### [304] [Universal crystal material property prediction via multi-view geometric fusion in graph transformers](https://arxiv.org/abs/2507.15303)
*Liang Zhang,Kong Chen,Yuen Wu*

Main category: cs.LG

TL;DR: MGT是一种新的图Transformer框架，通过融合SE(3)不变和SO(3)等变表示，并自适应调整嵌入权重，提高了晶体性质预测的准确性，尤其在迁移学习中表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有晶体结构表征方法难以有效捕捉和利用晶体结构的几何和拓扑特征，限制了机器学习在晶体材料模拟中的应用。因此，需要一种能更全面、准确地表征晶体结构的方法。

Method: 提出了一种名为MGT的多视图图Transformer框架，该框架融合了SE(3)不变和SO(3)等变图表示，并采用轻量级的专家混合路由器来根据目标任务自适应地调整SE(3)和SO(3)嵌入的权重。

Result: MGT框架在晶体性质预测任务上，通过多任务自监督预训练，将平均绝对误差降低了高达21%。在迁移学习场景下（如催化剂吸附能和钙钛矿带隙预测），相比现有基线模型，MGT的性能提升高达58%，展现了跨领域的可扩展性。

Conclusion: MGT框架在晶体结构表征和性质预测方面取得了显著进展，通过融合SE(3)不变和SO(3)等变图表示，并利用路由器自适应调整嵌入权重，在多个预测任务上实现了性能提升，尤其在迁移学习场景下表现突出，为新型材料发现提供了有力工具。

Abstract: Accurately and comprehensively representing crystal structures is critical
for advancing machine learning in large-scale crystal materials simulations,
however, effectively capturing and leveraging the intricate geometric and
topological characteristics of crystal structures remains a core, long-standing
challenge for most existing methods in crystal property prediction. Here, we
propose MGT, a multi-view graph transformer framework that synergistically
fuses SE3 invariant and SO3 equivariant graph representations, which
respectively captures rotation-translation invariance and rotation equivariance
in crystal geometries. To strategically incorporate these complementary
geometric representations, we employ a lightweight mixture of experts router in
MGT to adaptively adjust the weight assigned to SE3 and SO3 embeddings based on
the specific target task. Compared with previous state-of-the-art models, MGT
reduces the mean absolute error by up to 21% on crystal property prediction
tasks through multi-task self-supervised pretraining. Ablation experiments and
interpretable investigations confirm the effectiveness of each technique
implemented in our framework. Additionally, in transfer learning scenarios
including crystal catalyst adsorption energy and hybrid perovskite bandgap
prediction, MGT achieves performance improvements of up to 58% over existing
baselines, demonstrating domain-agnostic scalability across diverse application
domains. As evidenced by the above series of studies, we believe that MGT can
serve as useful model for crystal material property prediction, providing a
valuable tool for the discovery of novel materials.

</details>


### [305] [Task-Agnostic Continual Prompt Tuning with Gradient-Based Selection and Decoding](https://arxiv.org/abs/2507.14725)
*Anushka Tiwari,Sayantan Pal,Rohini K. Srihari,Kaiyi Ji*

Main category: cs.LG

TL;DR: GRID 是一个统一框架，解决了提示基础持续学习中的潜在遗忘和提示爆炸问题，通过改进的解码和压缩提示，实现了可扩展且内存高效的终身学习。


<details>
  <summary>Details</summary>
Motivation: 现有提示基础持续学习方法在任务感知推理和提示列表增长方面存在局限性，导致可扩展性差和潜在遗忘。

Method: GRID 框架集成了任务感知解码（利用代表性输入、自动任务识别和约束解码）和基于梯度的提示选择（压缩不重要提示）。

Result: GRID 显著提高了向后迁移能力，实现了具有竞争力的向前迁移能力，并将遗忘任务减少了高达 80%，在 T5 和 Flan-T5 主干上超越了最先进的方法。

Conclusion: GRID 框架通过集成任务感知解码机制和基于梯度的提示选择策略，有效解决了提示基础持续学习中的潜在遗忘和提示爆炸问题，在各种基准测试中表现优于现有方法。

Abstract: Prompt-based continual learning (CL) offers a parameter-efficient way to
adapt large language models (LLMs) across task sequences. However, most
existing methods assume task-aware inference and maintain a growing list of
task-specific prompts, which limits scalability and hides latent forgetting. In
this work, we introduce GRID, a unified framework that addresses two key
limitations: (1) latent forgetting under task-agnostic inference, and (2)
prompt memory explosion as task sequences grow. GRID integrates a task-aware
decoding mechanism that improves backward transfer by leveraging representative
inputs, automatic task identification, and constrained decoding. Additionally,
we propose a gradient-based prompt selection strategy that compresses less
informative prompts into a single aggregated representation, enabling scalable
and memory-efficient lifelong learning. Extensive experiments across
short-sequence, long-sequence, and negative transfer benchmarks show that GRID
significantly improves backward transfer, achieves competitive forward
transfer, and reduces forgotten tasks by up to 80\%, outperforming
state-of-the-art methods on T5 and Flan-T5 backbones.

</details>


### [306] [Balancing Expressivity and Robustness: Constrained Rational Activations for Reinforcement Learning](https://arxiv.org/abs/2507.14736)
*Rafał Surdej,Michał Bortkiewicz,Alex Lewandowski,Mateusz Ostaszewski,Clare Lyle*

Main category: cs.LG

TL;DR: 可训练有理激活函数在强化学习和持续学习中表现出表达能力和稳定性的权衡。本文提出了一种约束变体，通过限制输出尺度来提高稳定性和性能，尤其是在连续控制任务中。代码已发布。


<details>
  <summary>Details</summary>
Motivation: 为了增强可训练激活函数（特别是作为多项式比率的有理函数）在强化学习中的可塑性，同时解决其对训练稳定性的影响尚不明确的问题，本研究旨在深入探究其在强化学习和持续学习中的表现，并提出改进方法。

Method: 研究了可训练的有理激活函数在强化学习和持续学习场景中的应用，并提出了一种约束变体来解决其潜在的不稳定性问题，通过在MetaWorld、DeepMind Control Suite（DMC）、MNIST（重排标签）和Split CIFAR-100等基准测试中进行实验来验证方法的有效性。

Result: 可训练的有理激活函数虽然增强了适应性，但也可能引入不稳定性，导致强化学习中的高估和持续学习中的特征崩溃。提出的约束变体通过限制过度的输出尺度，在保持适应性的同时提高了训练稳定性和性能。研究揭示了不同约束对表达能力和长期保持能力平衡的影响，并指出这种权衡在连续控制任务中尤为关键。

Conclusion: 研究结果表明，可训练的有理激活函数在适应性和表达能力之间存在权衡。通过引入一个约束变体，可以限制过度的输出尺度，同时保持适应性，从而提高训练稳定性和性能。该方法在连续控制和持续学习基准测试中表现出优势，但其在离散动作域中的不稳定性影响尚不明确，暗示这种权衡在连续控制中尤为重要。研究为在动态、非平稳环境中设计鲁棒且可适应的可训练激活函数提供了可行的设计原则。

Abstract: Trainable activation functions, whose parameters are optimized alongside
network weights, offer increased expressivity compared to fixed activation
functions. Specifically, trainable activation functions defined as ratios of
polynomials (rational functions) have been proposed to enhance plasticity in
reinforcement learning. However, their impact on training stability remains
unclear. In this work, we study trainable rational activations in both
reinforcement and continual learning settings. We find that while their
flexibility enhances adaptability, it can also introduce instability, leading
to overestimation in RL and feature collapse in longer continual learning
scenarios. Our main result is demonstrating a trade-off between expressivity
and plasticity in rational activations. To address this, we propose a
constrained variant that structurally limits excessive output scaling while
preserving adaptability. Experiments across MetaWorld and DeepMind Control
Suite (DMC) environments show that our approach improves training stability and
performance. In continual learning benchmarks, including MNIST with reshuffled
labels and Split CIFAR-100, we reveal how different constraints affect the
balance between expressivity and long-term retention. While preliminary
experiments in discrete action domains (e.g., Atari) did not show similar
instability, this suggests that the trade-off is particularly relevant for
continuous control. Together, our findings provide actionable design principles
for robust and adaptable trainable activations in dynamic, non-stationary
environments. Code available at:
https://github.com/special114/rl_rational_plasticity.

</details>


### [307] [Hierarchical Multi-Agent Reinforcement Learning with Control Barrier Functions for Safety-Critical Autonomous Systems](https://arxiv.org/abs/2507.14850)
*H. M. Sabbir Ahmad,Ehsan Sabouni,Alexander Wasilkoff,Param Budhraja,Zijian Guo,Songyuan Zhang,Chuchu Fan,Christos Cassandras,Wenchao Li*

Main category: cs.LG

TL;DR: 提出了一种HMARL-CBF方法，通过分层学习和CBFs来解决多智能体安全问题，并在导航冲突环境中验证了其安全性和性能的提升。


<details>
  <summary>Details</summary>
Motivation: 在多智能体安全关键自主系统中，需要确保每个智能体始终满足安全要求，并与其他智能体协作以完成任务。

Method: 该方法结合了控制障碍函数（CBFs）和分层强化学习。在高层，学习所有智能体的联合技能策略；在低层，学习安全执行技能的策略，并以CBFs保证安全。

Result: 与现有最先进的方法相比，该方法显著提高了安全性，成功/安全率接近完美（在5%以内），并在所有环境中都提高了性能。

Conclusion: 该研究提出了一个基于控制障碍函数（CBFs）的安全分层多智能体强化学习（HMARL）方法，以解决多智能体安全关键自主系统中的安全策略学习问题。该方法将强化学习问题分解为两个层次：高层学习联合协作行为，低层学习个体安全行为。

Abstract: We address the problem of safe policy learning in multi-agent safety-critical
autonomous systems. In such systems, it is necessary for each agent to meet the
safety requirements at all times while also cooperating with other agents to
accomplish the task. Toward this end, we propose a safe Hierarchical
Multi-Agent Reinforcement Learning (HMARL) approach based on Control Barrier
Functions (CBFs). Our proposed hierarchical approach decomposes the overall
reinforcement learning problem into two levels learning joint cooperative
behavior at the higher level and learning safe individual behavior at the lower
or agent level conditioned on the high-level policy. Specifically, we propose a
skill-based HMARL-CBF algorithm in which the higher level problem involves
learning a joint policy over the skills for all the agents and the lower-level
problem involves learning policies to execute the skills safely with CBFs. We
validate our approach on challenging environment scenarios whereby a large
number of agents have to safely navigate through conflicting road networks.
Compared with existing state of the art methods, our approach significantly
improves the safety achieving near perfect (within 5%) success/safety rate
while also improving performance across all the environments.

</details>


### [308] [Better Training Data Attribution via Better Inverse Hessian-Vector Products](https://arxiv.org/abs/2507.14740)
*Andrew Wang,Elisa Nguyen,Runshi Yang,Juhan Bae,Sheila A. McIlraith,Roger Grosse*

Main category: cs.LG

TL;DR: ASTRA 是一种新的 TDA 算法，它使用 EKFAC-preconditioner 和 Neumann 级数迭代来准确近似 iHVP，从而提高 TDA 性能。


<details>
  <summary>Details</summary>
Motivation: 梯度下降 TDA 方法（如影响函数和展开微分）涉及类似 iHVP 的计算，而 iHVP 难以有效近似。

Method: ASTRA 算法使用 EKFAC-preconditioner 和 Neumann 级数迭代来近似逆 Hessian-vector product (iHVP)，用于训练数据归因 (TDA)。

Result: ASTRA 算法能够准确地近似 iHVP，并且在 TDA 性能方面优于其他方法。

Conclusion: ASTRA 算法通过在 Neumann 级数迭代中使用 EKFAC-preconditioner 来实现对 TDA 的 iHVP 近似，该方法易于调整，所需的迭代次数少于 Neumann 级数迭代，并且比基于 EKFAC 的近似更准确。

Abstract: Training data attribution (TDA) provides insights into which training data is
responsible for a learned model behavior. Gradient-based TDA methods such as
influence functions and unrolled differentiation both involve a computation
that resembles an inverse Hessian-vector product (iHVP), which is difficult to
approximate efficiently. We introduce an algorithm (ASTRA) which uses the
EKFAC-preconditioner on Neumann series iterations to arrive at an accurate iHVP
approximation for TDA. ASTRA is easy to tune, requires fewer iterations than
Neumann series iterations, and is more accurate than EKFAC-based
approximations. Using ASTRA, we show that improving the accuracy of the iHVP
approximation can significantly improve TDA performance.

</details>


### [309] [Beyond the Single-Best Model: Rashomon Partial Dependence Profile for Trustworthy Explanations in AutoML](https://arxiv.org/abs/2507.14744)
*Mustafa Cavus,Jan N. van Rijn,Przemysław Biecek*

Main category: cs.LG

TL;DR: 为了解决自动化机器学习中单一模型解释忽略解释不确定性的问题，提出了一种名为 Rashomon PDP 的新框架，它通过聚合近乎最优模型的解释来提供更可靠、更具不确定性意识的特征效应视图。


<details>
  <summary>Details</summary>
Motivation: 现有的自动化机器学习系统虽然能有效简化模型选择，但通常只关注单一性能最佳模型，忽略了解释不确定性，而这是以人为中心的可解释人工智能中的一个关键问题。

Method: 提出了一种新颖的框架，通过聚合近乎最优模型的偏依赖图（PDP）来将模型多重性纳入解释生成，这些近乎最优模型被称为 Rashomon 集。

Result: 通过引入覆盖率和置信区间平均宽度两个定量指标来评估 Rashomon PDP 与标准 PDP 的一致性。在 OpenML CTR23 基准套件的 35 个回归数据集上的实验表明，Rashomon PDP 覆盖了不到 70% 的最佳模型 PDP，这凸显了单一模型解释的局限性。

Conclusion: 提出的 Rashomon 部分依赖图（Rashomon PDP）通过聚合近乎最优模型（Rashomon set）的部分依赖图（PDP），将模型多重性纳入解释生成，捕获了解释变异性并强调了分歧点，为用户提供了更丰富、更具不确定性意识的特征效应视图。实验表明，Rashomon PDP 覆盖了不到 70% 的最佳模型 PDP，强调了单一模型解释的局限性。Rashomon PDP 通过添加通常会被忽略的额外信息，提高了模型解释的可靠性和可信度，这在高风险领域尤为有用。

Abstract: Automated machine learning systems efficiently streamline model selection but
often focus on a single best-performing model, overlooking explanation
uncertainty, an essential concern in human centered explainable AI. To address
this, we propose a novel framework that incorporates model multiplicity into
explanation generation by aggregating partial dependence profiles (PDP) from a
set of near optimal models, known as the Rashomon set. The resulting Rashomon
PDP captures interpretive variability and highlights areas of disagreement,
providing users with a richer, uncertainty aware view of feature effects. To
evaluate its usefulness, we introduce two quantitative metrics, the coverage
rate and the mean width of confidence intervals, to evaluate the consistency
between the standard PDP and the proposed Rashomon PDP. Experiments on 35
regression datasets from the OpenML CTR23 benchmark suite show that in most
cases, the Rashomon PDP covers less than 70% of the best model's PDP,
underscoring the limitations of single model explanations. Our findings suggest
that Rashomon PDP improves the reliability and trustworthiness of model
interpretations by adding additional information that would otherwise be
neglected. This is particularly useful in high stakes domains where
transparency and confidence are critical.

</details>


### [310] [Sampling from Gaussian Processes: A Tutorial and Applications in Global Sensitivity Analysis and Optimization](https://arxiv.org/abs/2507.14746)
*Bach Do,Nafeezat A. Ajenifuja,Taiwo A. Adebiyi,Ruda Zhang*

Main category: cs.LG

TL;DR: 本研究提出了两种从高斯过程中生成后验样本的方法（随机傅里叶特征和路径积分），并展示了它们在工程优化和敏感性分析中的应用。


<details>
  <summary>Details</summary>
Motivation: 高保真模拟和物理实验在工程分析和设计中至关重要，但其高昂的成本限制了它们在全局敏感性分析（GSA）和优化等任务中的应用。高斯过程（GPs）常被用作代理回归模型，以有限的高质量观测数据提供可感知的预测。

Method: 提出了随机傅里叶特征和路径积分这两种从高斯过程中生成后验样本的方法，并详细说明了它们的实现细节。

Result: 通过一系列数值示例成功展示了这些采样方法在GSA、单目标优化和多目标优化中的应用。

Conclusion: 该研究提出了两种从高斯过程（GPs）中生成后验样本的方法——随机傅里叶特征和路径积分，并详细介绍了它们的实现方法，以及如何将这些样本应用于全局敏感性分析（GSA）、单目标优化和多目标优化。

Abstract: High-fidelity simulations and physical experiments are essential for
engineering analysis and design. However, their high cost often limits their
applications in two critical tasks: global sensitivity analysis (GSA) and
optimization. This limitation motivates the common use of Gaussian processes
(GPs) as proxy regression models to provide uncertainty-aware predictions based
on a limited number of high-quality observations. GPs naturally enable
efficient sampling strategies that support informed decision-making under
uncertainty by extracting information from a subset of possible functions for
the model of interest. Despite their popularity in machine learning and
statistics communities, sampling from GPs has received little attention in the
community of engineering optimization. In this paper, we present the
formulation and detailed implementation of two notable sampling methods --
random Fourier features and pathwise conditioning -- for generating posterior
samples from GPs. Alternative approaches are briefly described. Importantly, we
detail how the generated samples can be applied in GSA, single-objective
optimization, and multi-objective optimization. We show successful applications
of these sampling methods through a series of numerical examples.

</details>


### [311] [Skill Learning via Policy Diversity Yields Identifiable Representations for Reinforcement Learning](https://arxiv.org/abs/2507.14748)
*Patrik Reizinger,Bálint Mucsányi,Siyuan Guo,Benjamin Eysenbach,Bernhard Schölkopf,Wieland Brendel*

Main category: cs.LG

TL;DR: CSF是MISL的一种方法，可以恢复环境的真实特征，并且具有可识别性保证。


<details>
  <summary>Details</summary>
Motivation: MISL中的表示和互信息参数化的作用尚不清楚。

Method: 通过关注对比性后继特征（CSF）方法，并利用可识别表示学习的视角来研究MISL。

Result: CSF能够恢复环境的真实特征，并且在MuJoCo和DeepMind控制中得到了实证验证。

Conclusion: CSF可以凭借其内积参数化和辨别意义上的技能多样性，可证明地将环境的真实特征恢复到线性变换的程度。这是RL中关于可识别表示学习的第一个保证，有助于解释不同互信息目标和熵正则化缺点的含义。

Abstract: Self-supervised feature learning and pretraining methods in reinforcement
learning (RL) often rely on information-theoretic principles, termed mutual
information skill learning (MISL). These methods aim to learn a representation
of the environment while also incentivizing exploration thereof. However, the
role of the representation and mutual information parametrization in MISL is
not yet well understood theoretically. Our work investigates MISL through the
lens of identifiable representation learning by focusing on the Contrastive
Successor Features (CSF) method. We prove that CSF can provably recover the
environment's ground-truth features up to a linear transformation due to the
inner product parametrization of the features and skill diversity in a
discriminative sense. This first identifiability guarantee for representation
learning in RL also helps explain the implications of different mutual
information objectives and the downsides of entropy regularizers. We
empirically validate our claims in MuJoCo and DeepMind Control and show how CSF
provably recovers the ground-truth features both from states and pixels.

</details>


### [312] [CXR-TFT: Multi-Modal Temporal Fusion Transformer for Predicting Chest X-ray Trajectories](https://arxiv.org/abs/2507.14766)
*Mehak Arora,Ayman Ali,Kaiyuan Wu,Carolyn Davis,Takashi Shimazui,Mahmoud Alwakeel,Victor Moas,Philip Yang,Annette Esper,Rishikesan Kamaleswaran*

Main category: cs.LG

TL;DR: CXR-TFT是一个新的框架，通过结合X光影像和临床数据，可以提前12小时预测ICU患者的X光结果，有助于改善患者治疗。


<details>
  <summary>Details</summary>
Motivation: 现有胸部X光解读工具仅限于横断面分析，无法捕捉时间动态。危重症患者需要密切监测和及时干预，而胸部X光检查的非规律性获取限制了其效用。因此，需要一种能够整合时间动态信息的新型框架。

Method: 提出了一种名为CXR-TFT的多模态框架，利用视觉编码器提取胸部X光影像的潜在嵌入，并通过插值时间对齐，与每小时的临床数据进行整合。随后，训练一个Transformer模型，以之前的嵌入和临床测量值为条件，预测每小时的胸部X光嵌入。

Result: 在对20,000名ICU患者的回顾性研究中，CXR-TFT在预测放射学检查前12小时内异常胸部X光结果方面表现出高准确性。

Conclusion: CXR-TFT通过整合稀疏的胸部X光影像、放射学报告和高频临床数据（如生命体征、实验室值和呼吸流程表），能够准确预测危重症患者的胸部X光结果变化，预测时间可达12小时，为改善急性呼吸窘迫综合征等疾病的管理提供了有价值的临床见解。

Abstract: In intensive care units (ICUs), patients with complex clinical conditions
require vigilant monitoring and prompt interventions. Chest X-rays (CXRs) are a
vital diagnostic tool, providing insights into clinical trajectories, but their
irregular acquisition limits their utility. Existing tools for CXR
interpretation are constrained by cross-sectional analysis, failing to capture
temporal dynamics. To address this, we introduce CXR-TFT, a novel multi-modal
framework that integrates temporally sparse CXR imaging and radiology reports
with high-frequency clinical data, such as vital signs, laboratory values, and
respiratory flow sheets, to predict the trajectory of CXR findings in
critically ill patients. CXR-TFT leverages latent embeddings from a vision
encoder that are temporally aligned with hourly clinical data through
interpolation. A transformer model is then trained to predict CXR embeddings at
each hour, conditioned on previous embeddings and clinical measurements. In a
retrospective study of 20,000 ICU patients, CXR-TFT demonstrated high accuracy
in forecasting abnormal CXR findings up to 12 hours before they became
radiographically evident. This predictive capability in clinical data holds
significant potential for enhancing the management of time-sensitive conditions
like acute respiratory distress syndrome, where early intervention is crucial
and diagnoses are often delayed. By providing distinctive temporal resolution
in prognostic CXR analysis, CXR-TFT offers actionable 'whole patient' insights
that can directly improve clinical outcomes.

</details>


### [313] [Rethinking Memorization Measures and their Implications in Large Language Models](https://arxiv.org/abs/2507.14777)
*Bishwamittra Ghosh,Soumi Das,Qinyuan Wu,Mohammad Aflah Khan,Krishna P. Gummadi,Evimaria Terzi,Deepak Garg*

Main category: cs.LG

TL;DR: LLM学习中记忆是不可避免的，但现有的衡量隐私风险的方法可能不准确。


<details>
  <summary>Details</summary>
Motivation: 鉴于隐私威胁，LLM中的记忆被认为是不理想的，尤其是在学习过程中。本研究旨在探讨最优语言学习是否能避免记忆，以及记忆带来的隐私威胁是否被夸大。

Method: 通过重新审视基于回忆的记忆、反事实记忆以及新提出的上下文记忆这几种衡量标准，并将其与局部过拟合联系起来，来研究大型语言模型（LLM）中的记忆问题。实验在18个LLM和多种形式语言上进行，分析了不同记忆度量的结果和信息需求。

Result: 实验发现，不同的记忆度量标准在衡量不同频率字符串的记忆程度时存在分歧；最优语言学习无法完全避免对训练数据的部分记忆；学习能力的提升会降低上下文记忆和反事实记忆，但会增加基于回忆的记忆；并且，之前报告的通过回忆发现的记忆字符串，实际上并不构成隐私威胁，也并非在上下文或反事实意义上被记忆。

Conclusion: 研究表明，最优语言学习无法完全避免训练数据的记忆，并且现有的基于回忆的记忆度量可能夸大了隐私风险，因为它们未能区分实际记忆和有效的上下文学习。

Abstract: Concerned with privacy threats, memorization in LLMs is often seen as
undesirable, specifically for learning. In this paper, we study whether
memorization can be avoided when optimally learning a language, and whether the
privacy threat posed by memorization is exaggerated or not. To this end, we
re-examine existing privacy-focused measures of memorization, namely
recollection-based and counterfactual memorization, along with a newly proposed
contextual memorization.
  Relating memorization to local over-fitting during learning, contextual
memorization aims to disentangle memorization from the contextual learning
ability of LLMs. Informally, a string is contextually memorized if its
recollection due to training exceeds the optimal contextual recollection, a
learned threshold denoting the best contextual learning without training.
Conceptually, contextual recollection avoids the fallacy of recollection-based
memorization, where any form of high recollection is a sign of memorization.
Theoretically, contextual memorization relates to counterfactual memorization,
but imposes stronger conditions. Memorization measures differ in outcomes and
information requirements.
  Experimenting on 18 LLMs from 6 families and multiple formal languages of
different entropy, we show that (a) memorization measures disagree on
memorization order of varying frequent strings, (b) optimal learning of a
language cannot avoid partial memorization of training strings, and (c)
improved learning decreases contextual and counterfactual memorization but
increases recollection-based memorization. Finally, (d) we revisit existing
reports of memorized strings by recollection that neither pose a privacy threat
nor are contextually or counterfactually memorized.

</details>


### [314] [Diffusion Beats Autoregressive in Data-Constrained Settings](https://arxiv.org/abs/2507.15857)
*Mihir Prabhudesai,Menging Wu,Amir Zadeh,Katerina Fragkiadaki,Deepak Pathak*

Main category: cs.LG

TL;DR: 在数据稀疏、计算量大的情况下，扩散模型比自回归模型更好。


<details>
  <summary>Details</summary>
Motivation: 探究扩散模型作为自回归模型的替代方案，特别是在数据稀疏的场景下的优势。

Method: 系统性研究了在数据受限（重复利用有限数据进行训练）的情况下，掩码扩散模型相较于自回归模型在语言建模任务中的表现，并分析了其优势的来源。

Result: 扩散模型在数据受限且计算资源充裕时显著优于自回归模型，能够更好地利用重复数据，实现更低的验证损失和更好的下游任务性能。发现了新的缩放定律，并推导了扩散模型超越自回归模型的临界计算阈值。

Conclusion: 在数据受限但计算资源充足的情况下，扩散模型通过隐式数据增强优于自回归模型，并且在数据利用率上表现出显著优势。研究还发现了扩散模型的新缩放定律，并推导了其超越自回归模型的临界计算阈值。

Abstract: Autoregressive (AR) models have long dominated the landscape of large
language models, driving progress across a wide range of tasks. Recently,
diffusion-based language models have emerged as a promising alternative, though
their advantages over AR models remain underexplored. In this paper, we
systematically study masked diffusion models in data-constrained settings-where
training involves repeated passes over limited data-and find that they
significantly outperform AR models when compute is abundant but data is scarce.
Diffusion models make better use of repeated data, achieving lower validation
loss and superior downstream performance. We interpret this advantage as
implicit data augmentation: masked diffusion exposes the model to a diverse
distribution of token orderings and prediction tasks, unlike AR's fixed
left-to-right factorization. We find new scaling laws for diffusion models and
derive a closed-form expression for the critical compute threshold at which
diffusion begins to outperform AR. These results suggest that when data, not
compute, is the bottleneck, diffusion models offer a compelling alternative to
the standard AR paradigm. Our code is available at:
https://diffusion-scaling.github.io.

</details>


### [315] [Omni-Think: Scaling Cross-Domain Generalization in LLMs via Multi-Task RL with Hybrid Rewards](https://arxiv.org/abs/2507.14783)
*Derek Li,Jiaming Zhou,Amirreza Kazemi,Qianyi Sun,Abbas Ghaddar,Mohammad Ali Alomrani,Liheng Ma,Yu Luo,Dong Li,Feng Wen,Jianye Hao,Mark Coates,Yingxue Zhang*

Main category: cs.LG

TL;DR: Omni-Think, a new RL framework, improves LLM generalization by combining rule-based rewards and LLM-as-a-Judge preferences. Curriculum learning further boosts performance, outperforming joint training and model merging.


<details>
  <summary>Details</summary>
Motivation: Post-training methods like Supervised Fine-Tuning (SFT) struggle with generalization in LLMs, favoring memorization over transferable learning. The goal is to enhance LLM performance across diverse tasks.

Method: The paper introduces Omni-Think, a unified reinforcement learning (RL) framework that combines rule-based verifiable rewards with generative preference signals (LLM-as-a-Judge). It also investigates curriculum-based training strategies, ordering tasks from structured to open-ended to improve performance and reduce forgetting.

Result: Omni-Think enables consistent optimization across task types and scales RL-based training to subjective domains. Curriculum learning improves performance by 5.2% over joint training and 9.1% over model merging across four domains.

Conclusion: The study highlights the importance of task-aware sampling and hybrid supervision in scaling RL-based post-training for general-purpose LLMs.

Abstract: The advancement of general-purpose artificial intelligence relies on large
language models (LLMs) that excel across a wide range of tasks, from structured
reasoning to creative generation. However, post-training methods like
Supervised Fine-Tuning (SFT) often struggle with generalization, favoring
memorization over transferable learning. In this work, we introduce Omni-Think,
a unified reinforcement learning (RL) framework that enhances LLM performance
across diverse tasks by combining rule-based verifiable rewards with generative
preference signals via LLM-as-a-Judge evaluations. Our approach enables
consistent optimization across task types and scales RL-based training to
subjective domains. We further investigate training strategies, demonstrating
that a curriculum-based progression that orders tasks from structured to
open-ended improves performance and reduces forgetting. Experimental results
across four domains reveal that curriculum learning improves performance by
5.2\% over joint training and 9.1\% over model merging. These results highlight
the importance of task-aware sampling and hybrid supervision in scaling
RL-based post-training for general-purpose LLMs.

</details>


### [316] [Exploring the In-Context Learning Capabilities of LLMs for Money Laundering Detection in Financial Graphs](https://arxiv.org/abs/2507.14785)
*Erfan Pirmorad*

Main category: cs.LG

TL;DR: LLM可以作为推理引擎，对金融知识图谱中的子图进行分析，以检测洗钱行为。


<details>
  <summary>Details</summary>
Motivation: 洗钱行为涉及复杂的实体和相互联系，需要对图结构数据进行调查推理。探索使用LLM作为在本地子图上进行推理的引擎。

Method: 提出一个轻量级的管道，从金融知识图谱中提取实体的k跳邻域，将它们序列化为结构化文本，并通过少样本上下文学习提示LLM，以评估可疑程度并生成理由。

Result: LLM能够模仿分析师的逻辑，突出危险信号，并提供连贯的解释。LLM可以用于反洗钱（AML）场景，以评估可疑程度和生成理由。

Conclusion: LLMs在金融知识图谱上进行基于图推理的分析，可以模仿分析师的逻辑，突出危险信号，并提供连贯的解释，这在反洗钱（AML）领域具有潜力，并为可解释的、由语言驱动的金融犯罪分析奠定了基础。

Abstract: The complexity and interconnectivity of entities involved in money laundering
demand investigative reasoning over graph-structured data. This paper explores
the use of large language models (LLMs) as reasoning engines over localized
subgraphs extracted from a financial knowledge graph. We propose a lightweight
pipeline that retrieves k-hop neighborhoods around entities of interest,
serializes them into structured text, and prompts an LLM via few-shot
in-context learning to assess suspiciousness and generate justifications. Using
synthetic anti-money laundering (AML) scenarios that reflect common laundering
behaviors, we show that LLMs can emulate analyst-style logic, highlight red
flags, and provide coherent explanations. While this study is exploratory, it
illustrates the potential of LLM-based graph reasoning in AML and lays
groundwork for explainable, language-driven financial crime analytics.

</details>


### [317] [Flow Equivariant Recurrent Neural Networks](https://arxiv.org/abs/2507.14793)
*T. Anderson Keller*

Main category: cs.LG

TL;DR: 本研究将等变性引入循环神经网络，通过引入“流等变性”来处理时间序列数据的连续对称性，并在多个任务上取得了优于传统RNN的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的等变神经网络主要关注静态变换，未能处理时间序列数据中的连续对称性。本研究旨在将等变性引入序列模型，以解决循环神经网络在处理时间参数化变换（如视觉运动）时的局限性。

Method: 提出并实现了一种流等变神经网络模型，并与标准循环神经网络（RNN）进行了对比实验，验证了流等变性在处理时间序列数据时的优势。

Result: 实验结果表明，流等变序列模型在训练速度、长度泛化和速度泛化方面显著优于非等变模型，证明了流等变性在序列建模中的有效性。

Conclusion: 本研究将等变网络理论扩展到序列模型，通过引入流等变性，显著提高了模型在训练速度、长度泛化和速度泛化方面的性能，为构建能够理解时间依赖对称性的序列模型奠定了基础。

Abstract: Data arrives at our senses as a continuous stream, smoothly transforming from
one instant to the next. These smooth transformations can be viewed as
continuous symmetries of the environment that we inhabit, defining equivalence
relations between stimuli over time. In machine learning, neural network
architectures that respect symmetries of their data are called equivariant and
have provable benefits in terms of generalization ability and sample
efficiency. To date, however, equivariance has been considered only for static
transformations and feed-forward networks, limiting its applicability to
sequence models, such as recurrent neural networks (RNNs), and corresponding
time-parameterized sequence transformations. In this work, we extend
equivariant network theory to this regime of `flows' -- one-parameter Lie
subgroups capturing natural transformations over time, such as visual motion.
We begin by showing that standard RNNs are generally not flow equivariant:
their hidden states fail to transform in a geometrically structured manner for
moving stimuli. We then show how flow equivariance can be introduced, and
demonstrate that these models significantly outperform their non-equivariant
counterparts in terms of training speed, length generalization, and velocity
generalization, on both next step prediction and sequence classification. We
present this work as a first step towards building sequence models that respect
the time-parameterized symmetries which govern the world around us.

</details>


### [318] [Subliminal Learning: Language models transmit behavioral traits via hidden signals in data](https://arxiv.org/abs/2507.14805)
*Alex Cloud,Minh Le,James Chua,Jan Betley,Anna Sztyber-Betley,Jacob Hilton,Samuel Marks,Owain Evans*

Main category: cs.LG

TL;DR: Language models can unintentionally transfer behavioral traits (like biases or preferences) to other models through seemingly unrelated data, like number sequences or code. This "subliminal learning" can happen even if the data is filtered to remove the trait, posing a risk for AI development as unintended behaviors could spread.


<details>
  <summary>Details</summary>
Motivation: The motivation of this paper is to study subliminal learning, a phenomenon where language models transmit behavioral traits via semantically unrelated data, which is a surprising and unexpected pitfall for AI development.

Method: The study conducted main experiments where a "teacher" model with a specific trait T generated datasets solely of number sequences. A "student" model trained on this data learned trait T, even when the data was filtered to remove references to T. The same effect was observed when training on code or reasoning traces from the same teacher model. However, the effect was not observed when the teacher and student models were different. The study also includes a theoretical result showing subliminal learning occurs in all neural networks under certain conditions and demonstrates it in a simple MLP classifier.

Result: Subliminal learning was observed, where a "student" model trained on number sequences generated by a "teacher" model learned the teacher's trait T. This occurred even with filtered data and when using code or reasoning traces. The effect was not observed with different base models. The theoretical result and MLP classifier demonstration support that this is a general phenomenon.

Conclusion: This paper concludes that subliminal learning is a general phenomenon that presents an unexpected pitfall for AI development. Distillation could propagate unintended traits, even when developers try to prevent this via data filtering.

Abstract: We study subliminal learning, a surprising phenomenon where language models
transmit behavioral traits via semantically unrelated data. In our main
experiments, a "teacher" model with some trait T (such as liking owls or being
misaligned) generates a dataset consisting solely of number sequences.
Remarkably, a "student" model trained on this dataset learns T. This occurs
even when the data is filtered to remove references to T. We observe the same
effect when training on code or reasoning traces generated by the same teacher
model. However, we do not observe the effect when the teacher and student have
different base models. To help explain our findings, we prove a theoretical
result showing that subliminal learning occurs in all neural networks under
certain conditions, and demonstrate subliminal learning in a simple MLP
classifier. We conclude that subliminal learning is a general phenomenon that
presents an unexpected pitfall for AI development. Distillation could propagate
unintended traits, even when developers try to prevent this via data filtering.

</details>


### [319] [Benchmarking Foundation Models with Multimodal Public Electronic Health Records](https://arxiv.org/abs/2507.14824)
*Kunyu Yu,Rui Yang,Jingchi Liao,Siqi Li,Huitao Li,Irene Li,Yifan Peng,Rishikesan Kamaleswaran,Nan Liu*

Main category: cs.LG

TL;DR: 基础模型在EHR分析中表现出色，多模态方法能提升性能且不增加偏见。


<details>
  <summary>Details</summary>
Motivation: 为了评估基础模型在处理电子健康记录（EHR）方面的能力，以及为开发有效且可信赖的多模态人工智能（AI）系统提供指导。

Method: 本研究构建了一个标准化的数据处理流程，用于整合和分析MIMIC-IV数据库中的多模态EHR数据，并系统地评估了八种基础模型（包括单模态和多模态模型）的性能、公平性和可解释性。

Result: 多模态基础模型在预测任务上相比单模态模型有持续的性能提升，并且不会增加额外的偏见。代码已在https://github.com/nliulab/MIMIC-Multimodal公开。

Conclusion: 多模态基础模型在电子健康记录（EHR）分析中展现出优越的性能和公平性，并未引入额外偏差。

Abstract: Foundation models have emerged as a powerful approach for processing
electronic health records (EHRs), offering flexibility to handle diverse
medical data modalities. In this study, we present a comprehensive benchmark
that evaluates the performance, fairness, and interpretability of foundation
models, both as unimodal encoders and as multimodal learners, using the
publicly available MIMIC-IV database. To support consistent and reproducible
evaluation, we developed a standardized data processing pipeline that
harmonizes heterogeneous clinical records into an analysis-ready format. We
systematically compared eight foundation models, encompassing both unimodal and
multimodal models, as well as domain-specific and general-purpose variants. Our
findings demonstrate that incorporating multiple data modalities leads to
consistent improvements in predictive performance without introducing
additional bias. Through this benchmark, we aim to support the development of
effective and trustworthy multimodal artificial intelligence (AI) systems for
real-world clinical applications. Our code is available at
https://github.com/nliulab/MIMIC-Multimodal.

</details>


### [320] [eMargin: Revisiting Contrastive Learning with Margin-Based Separation](https://arxiv.org/abs/2507.14828)
*Abdul-Kazeem Shamba,Kerstin Bach,Gavin Taylor*

Main category: cs.LG

TL;DR: 研究发现，自适应边界（eMargin）可以改善时间序列表示的聚类效果，但在下游分类任务中的表现并不理想。


<details>
  <summary>Details</summary>
Motivation: 为了研究自适应边界（eMargin）对时间序列表示学习的影响，以及它是否能提高时间序列表示的质量，从而在下游任务中获得更好的性能。

Method: 在对比损失函数中引入自适应边界（eMargin），并基于预设的相似度阈值进行调整，以改善时间步之间的分离度。

Result: eMargin 显著提高了在三个基准数据集上的无监督聚类指标表现，但与最先进的方法相比，在下游分类任务的线性探测中表现不佳。

Conclusion: eMargin 提高了无监督聚类指标上的性能，但在下游任务的线性探测分类中表现不具竞争力。

Abstract: We revisit previous contrastive learning frameworks to investigate the effect
of introducing an adaptive margin into the contrastive loss function for time
series representation learning. Specifically, we explore whether an adaptive
margin (eMargin), adjusted based on a predefined similarity threshold, can
improve the separation between adjacent but dissimilar time steps and
subsequently lead to better performance in downstream tasks. Our study
evaluates the impact of this modification on clustering performance and
classification in three benchmark datasets. Our findings, however, indicate
that achieving high scores on unsupervised clustering metrics does not
necessarily imply that the learned embeddings are meaningful or effective in
downstream tasks. To be specific, eMargin added to InfoNCE consistently
outperforms state-of-the-art baselines in unsupervised clustering metrics, but
struggles to achieve competitive results in downstream classification with
linear probing. The source code is publicly available at
https://github.com/sfi-norwai/eMargin.

</details>


### [321] [The Invisible Leash: Why RLVR May Not Escape Its Origin](https://arxiv.org/abs/2507.14843)
*Fang Wu,Weihao Xuan,Ximing Lu,Zaid Harchaoui,Yejin Choi*

Main category: cs.LG

TL;DR: RLVR 的扩展能力可能受到基础模型的限制，并且可能牺牲探索性以获得更高的准确性。


<details>
  <summary>Details</summary>
Motivation: 本研究旨在探究 RLVR 是否能真正扩展模型的推理边界，或者仅仅是为了提高精度而放大了基础模型已知的、具有高回报的输出。

Method: 该研究提出了 RLVR 的理论和实证研究，以提供关于其潜在限制的新见解。

Result: RLVR 始终能提高 pass@1，但经验性支持的收缩通常会超过在更大采样预算下经验性支持的扩张，未能恢复基础模型先前可访问的正确答案。RLVR 有时会增加 token 级熵，导致每个生成步骤的不确定性增加，但答案级熵会下降，表明这些看似更不确定的路径最终会收敛到一组更小的不同答案。

Conclusion: RLVR 的潜力可能受到基础模型的限制，它是一种保守的重加权机制，可能会限制发现全新的解决方案。RLVR 可能会牺牲探索性以获得更高的精确度，并可能忽略正确但代表性不足的解决方案。

Abstract: Recent advances in large reasoning models highlight Reinforcement Learning
with Verifiable Rewards (RLVR) as a promising method for enhancing AI's
capabilities, particularly in solving complex logical tasks. However, it
remains unclear whether RLVR truly expands a model's reasoning boundary or
merely amplifies high-reward outputs that the base model already knows for
improved precision. This study presents a theoretical and empirical
investigation that provides fresh insights into the potential limits of RLVR.
First, we offer a new theoretical perspective that RLVR is constrained by the
base model's support-unable to sample solutions with zero initial
probability-and operates as a conservative reweighting mechanism that may
restrict the discovery of entirely original solutions. We also identify an
entropy-reward tradeoff: while RLVR reliably enhances precision, it may
progressively narrow exploration and potentially overlook correct yet
underrepresented solutions. Extensive empirical experiments validate that while
RLVR consistently improves pass@1, the shrinkage of empirical support generally
outweighs the expansion of empirical support under larger sampling budgets,
failing to recover correct answers that were previously accessible to the base
model. Interestingly, we also observe that while RLVR sometimes increases
token-level entropy, resulting in greater uncertainty at each generation step,
answer-level entropy declines, indicating that these seemingly more uncertain
paths ultimately converge onto a smaller set of distinct answers. Taken
together, these findings reveal potential limits of RLVR in extending reasoning
horizons. Breaking this invisible leash may require future algorithmic
innovations such as explicit exploration mechanisms or hybrid strategies that
seed probability mass into underrepresented solution regions.

</details>


### [322] [Time-Aware Attention for Enhanced Electronic Health Records Modeling](https://arxiv.org/abs/2507.14847)
*Junhan Yu,Zhunyi Feng,Junwei Lu,Tianxi Cai,Doudou Zhou*

Main category: cs.LG

TL;DR: TALE-EHR 是一个结合了时间感知注意力和 LLM 嵌入的 Transformer 框架，用于 EHR 分析，在疾病进展预测等任务上表现优于现有技术。


<details>
  <summary>Details</summary>
Motivation: 对电子健康记录 (EHR) 进行有效建模需要解决数据异质性和复杂时间模式的问题，而标准方法常常难以处理临床事件之间不规则的时间间隔。

Method: 提出了一种基于 Transformer 的框架 TALE-EHR，该框架具有新颖的时间感知注意力机制，可显式建模连续时间间隔以捕获细粒度序列动态。TALE-EHR 利用源自标准化代码描述的嵌入，并通过预训练的大型语言模型（LLM）来增强时间建模的鲁棒语义，从而为理解临床概念奠定坚实基础。

Result: 在 MIMIC-IV 和 PIC 数据集上的实验表明，该方法在疾病进展预测等任务上优于最先进的基线。

Conclusion: TALE-EHR 框架结合了显式、连续的时间建模和强大的语义表示，为推进 EHR 分析提供了强大的解决方案。

Abstract: Electronic Health Records (EHR) contain valuable clinical information for
predicting patient outcomes and guiding healthcare decisions. However,
effectively modeling Electronic Health Records (EHRs) requires addressing data
heterogeneity and complex temporal patterns. Standard approaches often struggle
with irregular time intervals between clinical events. We propose TALE-EHR, a
Transformer-based framework featuring a novel time-aware attention mechanism
that explicitly models continuous temporal gaps to capture fine-grained
sequence dynamics. To complement this temporal modeling with robust semantics,
TALE-EHR leverages embeddings derived from standardized code descriptions using
a pre-trained Large Language Model (LLM), providing a strong foundation for
understanding clinical concepts. Experiments on the MIMIC-IV and PIC dataset
demonstrate that our approach outperforms state-of-the-art baselines on tasks
such as disease progression forecasting. TALE-EHR underscores the benefit of
integrating explicit, continuous temporal modeling with strong semantic
representations provides a powerful solution for advancing EHR analysis.

</details>


### [323] [Old Rules in a New Game: Mapping Uncertainty Quantification to Quantum Machine Learning](https://arxiv.org/abs/2507.14919)
*Maximilian Wendlinger,Kilian Tscharke,Pascal Debus*

Main category: cs.LG

TL;DR: 该研究旨在解决量子机器学习模型的不透明性问题，通过将经典不确定性量化方法应用于量子领域，并强调了在设计新模型时考虑不确定性的重要性。


<details>
  <summary>Details</summary>
Motivation: 为了解决传统深度学习和量子机器学习中存在的模型不透明性问题，以及由此产生的过拟合和过度自信等问题。

Method: 将经典的_不确定性_量化方法映射到量子机器学习领域，并进行理论发展和实证评估。

Result: 研究结果强调了利用经典不确定性量化方面的见解，将不确定性意识纳入新的量子机器学习模型的设计过程中的必要性。

Conclusion: 有必要利用经典不确定性量化方面的见解，将不确定性意识纳入新的量子机器学习模型的设计过程中。

Abstract: One of the key obstacles in traditional deep learning is the reduction in
model transparency caused by increasingly intricate model functions, which can
lead to problems such as overfitting and excessive confidence in predictions.
With the advent of quantum machine learning offering possible advances in
computational power and latent space complexity, we notice the same opaque
behavior. Despite significant research in classical contexts, there has been
little advancement in addressing the black-box nature of quantum machine
learning. Consequently, we approach this gap by building upon existing work in
classical uncertainty quantification and initial explorations in quantum
Bayesian modeling to theoretically develop and empirically evaluate techniques
to map classical uncertainty quantification methods to the quantum machine
learning domain. Our findings emphasize the necessity of leveraging classical
insights into uncertainty quantification to include uncertainty awareness in
the process of designing new quantum machine learning models.

</details>


### [324] [The Tsetlin Machine Goes Deep: Logical Learning and Reasoning With Graphs](https://arxiv.org/abs/2507.14874)
*Ole-Christoffer Granmo,Youmna Abdelwahab,Per-Arne Andersen,Paul F. A. Clarke,Kunal Dumbre,Ylva Grønninsæter,Vojtech Halenka,Runar Helin,Lei Jiao,Ahmed Khalid,Rebekka Omslandseter,Rupsa Saha,Mayur Shende,Xuan Zhang*

Main category: cs.LG

TL;DR: GraphTM 是一种新的Tsetlin机，可处理图数据，提高可解释性和准确性，并在多个任务上优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 为了让Tsetlin机器（TM）能够处理图结构输入，并超越固定长度输入的限制，从而支持序列、网格、关系和多模态数据，并提高其在图像分类、动作共指跟踪、推荐系统和病毒基因组序列数据等任务上的准确性和效率。

Method: 通过消息传递机制，GraphTM能够从图结构输入中学习可解释的深度子句，并构建嵌套的深度子句以识别子图模式，从而以指数级减少的子句数量提高可解释性和数据利用率。

Result: 在图像分类任务中，GraphTM在CIFAR-10上的准确率比卷积TM高3.86个百分点；在动作共指跟踪任务中，GraphTM的准确率比其他强化学习方法高20.6个百分点；在推荐系统中，GraphTM对噪声的容忍度高于图卷积神经网络（GCN），在0.1噪声比下准确率达到89.86%，而GCN仅为70.87%；在病毒基因组序列数据上，GraphTM的准确率与BiLSTM-CNN和GCN相当，但训练速度是GCN的2.5倍。

Conclusion: Graph Tsetlin Machine (GraphTM) 将图表示学习和深度子句相结合，在提高可解释性和数据利用率方面展现出巨大潜力，并在图像分类、动作共指跟踪、推荐系统和病毒基因组序列数据等多个领域取得了优于现有方法的成果，显示了其在Tsetlin机（TM）学习中的新应用前景。

Abstract: Pattern recognition with concise and flat AND-rules makes the Tsetlin Machine
(TM) both interpretable and efficient, while the power of Tsetlin automata
enables accuracy comparable to deep learning on an increasing number of
datasets. We introduce the Graph Tsetlin Machine (GraphTM) for learning
interpretable deep clauses from graph-structured input. Moving beyond flat,
fixed-length input, the GraphTM gets more versatile, supporting sequences,
grids, relations, and multimodality. Through message passing, the GraphTM
builds nested deep clauses to recognize sub-graph patterns with exponentially
fewer clauses, increasing both interpretability and data utilization. For image
classification, GraphTM preserves interpretability and achieves 3.86%-points
higher accuracy on CIFAR-10 than a convolutional TM. For tracking action
coreference, faced with increasingly challenging tasks, GraphTM outperforms
other reinforcement learning methods by up to 20.6%-points. In recommendation
systems, it tolerates increasing noise to a greater extent than a Graph
Convolutional Neural Network (GCN), e.g., for noise ratio 0.1, GraphTM obtains
accuracy 89.86% compared to GCN's 70.87%. Finally, for viral genome sequence
data, GraphTM is competitive with BiLSTM-CNN and GCN accuracy-wise, training
2.5x faster than GCN. The GraphTM's application to these varied fields
demonstrates how graph representation learning and deep clauses bring new
possibilities for TM learning.

</details>


### [325] [Application-Specific Component-Aware Structured Pruning of Deep Neural Networks via Soft Coefficient Optimization](https://arxiv.org/abs/2507.14882)
*Ganesh Sundaram,Jonas Ulmen,Amjad Haider,Daniel Görges*

Main category: cs.LG

TL;DR: 本研究提出了一种新的结构化修剪方法，通过一种增强型的重要性度量框架来解决 DNN 压缩问题，该框架可确保模型性能在修剪过程中得以保留，并满足特定于应用程序的要求。


<details>
  <summary>Details</summary>
Motivation: DNNs 的广泛应用因其高模型复杂性和计算需求而受到阻碍。模型压缩技术（如修剪）已成为有希望的解决方案，但确保压缩过程中保留特定于应用程序的性能特性至关重要。在结构化修剪中，常规的重要性度量通常无法维持这些关键的性能属性。

Method: 本研究提出了一种增强型的重要性度量框架，该框架不仅减小了模型尺寸，还明确考虑了特定于应用程序的性能约束。我们采用多种策略来确定每个组的最佳修剪幅度，以确保压缩和任务性能之间的平衡。

Result: 该方法在用于重建 MNIST 图像的自动编码器上进行了评估。实验结果表明，该方法能够有效保留任务相关性能。

Conclusion: 所提出的方法能够有效保留与任务相关的性能，即使在大量修剪后仍能保持模型的可用性，并满足所需的特定于应用程序的标准。

Abstract: Deep neural networks (DNNs) offer significant versatility and performance
benefits, but their widespread adoption is often hindered by high model
complexity and computational demands. Model compression techniques such as
pruning have emerged as promising solutions to these challenges. However, it
remains critical to ensure that application-specific performance
characteristics are preserved during compression. In structured pruning, where
groups of structurally coherent elements are removed, conventional importance
metrics frequently fail to maintain these essential performance attributes. In
this work, we propose an enhanced importance metric framework that not only
reduces model size but also explicitly accounts for application-specific
performance constraints. We employ multiple strategies to determine the optimal
pruning magnitude for each group, ensuring a balance between compression and
task performance. Our approach is evaluated on an autoencoder tasked with
reconstructing MNIST images. Experimental results demonstrate that the proposed
method effectively preserves task-relevant performance, maintaining the model's
usability even after substantial pruning, by satisfying the required
application-specific criteria.

</details>


### [326] [Learning to Gridize: Segment Physical World by Wireless Communication Channel](https://arxiv.org/abs/2507.15386)
*Juntao Wang,Feng Yin,Tian Ding,Tsung-Hui Chang,Zhi-Quan Luo,Qi Yan*

Main category: cs.LG

TL;DR: CSG-AE通过结合信道估计和网格化来改进大规模网络优化，与现有方法相比，在RSRP预测准确性、信道一致性、集群大小平衡和活动比率方面取得了显著改进。


<details>
  <summary>Details</summary>
Motivation: 现有的地理空间或波束空间网格化方法（GSG或BSG）依赖于无法使用的位置数据或基于错误的假设，即相似的信号强度意味着相似的信道特性。CSG旨在通过统一信道估计和网格化来解决这些限制。

Method: 提出了一种名为CSG-AE的信道空间网格化自动编码器，该编码器包括一个可训练的RSRP到CAPS编码器、一个可学习的稀疏码本量化器和一个基于局部统计信道模型的物理信息解码器。为了确保稳定有效的训练，我们提出了一种新颖的预训练-初始化-分离-异步（PIDA）训练方案。

Result: CSG-AE在CAPS估计准确性和合成数据上的聚类质量方面表现出色。

Conclusion: CSG-AE在真实世界数据集上将RSRP预测准确性方面的活动平均绝对误差（MAE）降低了30％，整体MAE降低了65％，与使用相同数据的显着基线相比，同时提高了信道一致性、集群大小平衡和活动比率，从而促进了用于大规模网络优化的网格化的发展。

Abstract: Gridization, the process of partitioning space into grids where users share
similar channel characteristics, serves as a fundamental prerequisite for
efficient large-scale network optimization. However, existing methods like
Geographical or Beam Space Gridization (GSG or BSG) are limited by reliance on
unavailable location data or the flawed assumption that similar signal
strengths imply similar channel properties. We propose Channel Space
Gridization (CSG), a pioneering framework that unifies channel estimation and
gridization for the first time. Formulated as a joint optimization problem, CSG
uses only beam-level reference signal received power (RSRP) to estimate Channel
Angle Power Spectra (CAPS) and partition samples into grids with homogeneous
channel characteristics. To perform CSG, we develop the CSG Autoencoder
(CSG-AE), featuring a trainable RSRP-to-CAPS encoder, a learnable sparse
codebook quantizer, and a physics-informed decoder based on the Localized
Statistical Channel Model. On recognizing the limitations of naive training
scheme, we propose a novel Pretraining-Initialization-Detached-Asynchronous
(PIDA) training scheme for CSG-AE, ensuring stable and effective training by
systematically addressing the common pitfalls of the naive training paradigm.
Evaluations reveal that CSG-AE excels in CAPS estimation accuracy and
clustering quality on synthetic data. On real-world datasets, it reduces Active
Mean Absolute Error (MAE) by 30\% and Overall MAE by 65\% on RSRP prediction
accuracy compared to salient baselines using the same data, while improving
channel consistency, cluster sizes balance, and active ratio, advancing the
development of gridization for large-scale network optimization.

</details>


### [327] [FedWCM: Unleashing the Potential of Momentum-based Federated Learning in Long-Tailed Scenarios](https://arxiv.org/abs/2507.14980)
*Tianle Li,Yongzhi Huang,Linshan Jiang,Qipeng Xie,Chang Liu,Wenfeng Du,Lu Wang,Kaishun Wu*

Main category: cs.LG

TL;DR: FedWCM improves Federated Learning on non-IID, long-tailed data by adjusting momentum, fixing convergence issues and outperforming other methods.


<details>
  <summary>Details</summary>
Motivation: Federated Learning (FL) faces challenges with non-identically distributed (non-IID) data, especially in long-tailed scenarios with imbalanced class samples, where momentum-based FL methods struggle with biased models and convergence.

Method: FedWCM dynamically adjusts momentum using global and per-round data to correct directional biases introduced by long-tailed distributions.

Result: Extensive experiments show that FedWCM resolves non-convergence issues and outperforms existing methods.

Conclusion: FedWCM resolves non-convergence issues and outperforms existing methods, enhancing FL's efficiency and effectiveness in handling client heterogeneity and data imbalance.

Abstract: Federated Learning (FL) enables decentralized model training while preserving
data privacy. Despite its benefits, FL faces challenges with non-identically
distributed (non-IID) data, especially in long-tailed scenarios with imbalanced
class samples. Momentum-based FL methods, often used to accelerate FL
convergence, struggle with these distributions, resulting in biased models and
making FL hard to converge. To understand this challenge, we conduct extensive
investigations into this phenomenon, accompanied by a layer-wise analysis of
neural network behavior. Based on these insights, we propose FedWCM, a method
that dynamically adjusts momentum using global and per-round data to correct
directional biases introduced by long-tailed distributions. Extensive
experiments show that FedWCM resolves non-convergence issues and outperforms
existing methods, enhancing FL's efficiency and effectiveness in handling
client heterogeneity and data imbalance.

</details>


### [328] [Federated Split Learning with Improved Communication and Storage Efficiency](https://arxiv.org/abs/2507.15816)
*Yujia Mu,Cong Shen*

Main category: cs.LG

TL;DR: CSE-FSL通过本地更新和选择性传输数据，解决了联邦分离学习中的通信和存储瓶颈。


<details>
  <summary>Details</summary>
Motivation: 现有的联邦学习（FL）和联邦分离学习（FSL）方法存在显著的通信和计算成本，以及服务器的存储需求。FSL通过拆分模型架构来降低边缘设备的计算负担，但仍然需要高通信开销来传输打碎的数据和梯度，并且服务器需要为每个客户端维护单独的部分模型。

Method: CSE-FSL是一种新颖的通信和存储高效的联邦分离学习方法，它利用辅助网络在客户端本地更新权重，同时在服务器上维护单个模型。它还通过在选定的时期传输打碎的数据来减少通信量。

Result: CSE-FSL在实际的联邦学习任务中，相比于现有的FSL解决方案，实现了显著的通信开销降低，并保证了在非凸损失函数下的收敛性。

Conclusion: CSE-FSL可以通过使用辅助网络在客户端本地更新权重，同时在服务器上只保留一个模型，从而减少服务器的存储需求和频繁的梯度传输。此外，通过在选定的时期传输打碎的数据，可以减少从客户端发送的打碎数据的数量。CSE-FSL在理论上保证了在非凸损失函数下的收敛性，并且在实际的联邦学习任务中实现了显著的通信开销降低。

Abstract: Federated learning (FL) is one of the popular distributed machine learning
(ML) solutions but incurs significant communication and computation costs at
edge devices. Federated split learning (FSL) can train sub-models in parallel
and reduce the computational burden of edge devices by splitting the model
architecture. However, it still requires a high communication overhead due to
transmitting the smashed data and gradients between clients and the server in
every global round. Furthermore, the server must maintain separate partial
models for every client, leading to a significant storage requirement. To
address these challenges, this paper proposes a novel communication and storage
efficient federated split learning method, termed CSE-FSL, which utilizes an
auxiliary network to locally update the weights of the clients while keeping a
single model at the server, hence avoiding frequent transmissions of gradients
from the server and greatly reducing the storage requirement of the server.
Additionally, a new model update method of transmitting the smashed data in
selected epochs can reduce the amount of smashed data sent from the clients. We
provide a theoretical analysis of CSE-FSL, rigorously guaranteeing its
convergence under non-convex loss functions. The extensive experimental results
further indicate that CSE-FSL achieves a significant communication reduction
over existing FSL solutions using real-world FL tasks.

</details>


### [329] [Time-RA: Towards Time Series Reasoning for Anomaly with LLM Feedback](https://arxiv.org/abs/2507.15066)
*Yiyuan Yang,Zichuan Liu,Lei Song,Kai Ying,Zhiguang Wang,Tom Bamford,Svitlana Vyetrenko,Jiang Bian,Qingsong Wen*

Main category: cs.LG

TL;DR: 提出Time-RA任务和RATs40K数据集，利用LLM进行时间序列异常检测的解释性推理，并在多模态数据上进行标注和评估。


<details>
  <summary>Details</summary>
Motivation: 当前时间序列异常检测方法通常仅限于二元分类，缺乏详细的类别划分和解释性推理，无法满足实际应用中对异常原因深入理解的需求。

Method: 提出了一种名为Time-RA的新任务，将时间序列异常检测从判别式任务转变为生成式、注重推理的任务，并利用了大型语言模型（LLMs）。引入了RATs40K数据集，该数据集包含约40,000个样本，涵盖10个真实世界领域，并为数值时间序列数据、上下文文本信息和视觉表示进行了详细的异常类别（单变量14种，多变量6种）和结构化解释性推理的标注。通过利用集成模型生成的标签，并结合GPT-4进行反馈优化，构建了一个复杂的标注框架。

Result: 通过对LLMs和多模态LLMs进行广泛的基准测试，展示了现有模型的优势和局限性，并强调了监督微调的关键作用。研究结果表明，所提出的Time-RA任务和RATs40K数据集能够有效推动可解释的时间序列异常检测和推理领域的发展。

Conclusion: 该研究提出了新颖的时间序列异常检测任务（Time-RA）和首个多模态异常检测基准数据集（RATs40K），旨在从传统的二元分类转向更具解释性的生成式推理任务，并为可解释的时间序列异常检测和推理开辟了新的研究方向。

Abstract: Time series anomaly detection is critical across various domains, yet current
approaches often limit analysis to mere binary anomaly classification without
detailed categorization or further explanatory reasoning. To address these
limitations, we propose a novel task, Time-series Reasoning for Anomaly
(Time-RA) that transforms classical time series anomaly detection from a
discriminative into a generative, reasoning-intensive task leveraging Large
Language Models (LLMs). Also, we introduce the first real-world multimodal
benchmark dataset, RATs40K, explicitly annotated for anomaly reasoning,
comprising approximately 40,000 samples across 10 real-world domains. Each
sample includes numeric time series data, contextual text information, and
visual representations, each annotated with fine-grained categories (14 types
for univariate anomalies and 6 for multivariate anomalies) and structured
explanatory reasoning. We develop a sophisticated annotation framework
utilizing ensemble-generated labels refined through GPT-4-driven feedback,
ensuring accuracy and interpretability. Extensive benchmarking of LLMs and
multimodal LLMs demonstrates the capabilities and limitations of current
models, highlighting the critical role of supervised fine-tuning. Our dataset
and task pave the way for significant advancements in interpretable time series
anomaly detection and reasoning.

</details>


### [330] [Reinforcement Learning for Flow-Matching Policies](https://arxiv.org/abs/2507.15073)
*Samuel Pfrommer,Yixiao Huang,Somayeh Sojoudi*

Main category: cs.LG

TL;DR: 通过强化学习（特别是RWFM和GRPO）训练流匹配策略，以提高机器人性能，超越人类演示。


<details>
  <summary>Details</summary>
Motivation: 探索使用强化学习训练流匹配策略，以超越作为演示来源的次优策略。

Method: 提出了一种称为奖励加权流匹配（RWFM）的简单方案，以及一种具有学习奖励替代的组相对策略优化（GRPO）方法。

Result: 在模拟的单轮车动力学任务中，RWFM和GRPO方法均显著提高了性能，GRPO方法的成本比模仿学习流匹配（ILFM）方法低50%-85%。

Conclusion: 该研究探索了通过强化学习训练流匹配策略，以超越原始演示策略的性能，特别是在最小时间控制应用中。

Abstract: Flow-matching policies have emerged as a powerful paradigm for generalist
robotics. These models are trained to imitate an action chunk, conditioned on
sensor observations and textual instructions. Often, training demonstrations
are generated by a suboptimal policy, such as a human operator. This work
explores training flow-matching policies via reinforcement learning to surpass
the original demonstration policy performance. We particularly note
minimum-time control as a key application and present a simple scheme for
variable-horizon flow-matching planning. We then introduce two families of
approaches: a simple Reward-Weighted Flow Matching (RWFM) scheme and a Group
Relative Policy Optimization (GRPO) approach with a learned reward surrogate.
Our policies are trained on an illustrative suite of simulated unicycle
dynamics tasks, and we show that both approaches dramatically improve upon the
suboptimal demonstrator performance, with the GRPO approach in particular
generally incurring between $50\%$ and $85\%$ less cost than a naive Imitation
Learning Flow Matching (ILFM) approach.

</details>


### [331] [Isotonic Quantile Regression Averaging for uncertainty quantification of electricity price forecasts](https://arxiv.org/abs/2507.15079)
*Arkadiusz Lipiecki,Bartosz Uniejewski*

Main category: cs.LG

TL;DR: 本研究提出了一种名为iQRA的新方法，用于从点预测的集合中生成概率预测，以提高电力市场预测的准确性和可靠性，并在实验中优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 量化预测模型的不确定性对于评估和减轻与数据驱动的决策相关的风险至关重要，特别是在电力市场等波动性领域。虽然机器学习模型可以提供准确的电力价格预测，但它们通常缺乏不确定性估计，限制了决策者规避风险的能力。

Method: 提出了一种名为等otonic分位数回归平均（iQRA）的新方法，该方法通过引入随机顺序约束来生成点预测集合的概率预测，以提高准确性、可靠性和计算成本。

Result: iQRA方法在德国日内电力市场的广泛预测研究中，在可靠性和清晰度方面持续优于最先进的后处理方法，并优于包括基于覆盖率的共形预测在内的所有基准方法。此外，等otonic正则化降低了分位点回归问题的复杂性，并提供了一种无需超参数即可进行变量选择的方法。

Conclusion: iQRA方法在准确性、可靠性和计算成本方面优于最先进的后处理方法，并为多个置信水平提供了良好校准的预测区间，在德国日内电力市场预测研究中表现出色。

Abstract: Quantifying the uncertainty of forecasting models is essential to assess and
mitigate the risks associated with data-driven decisions, especially in
volatile domains such as electricity markets. Machine learning methods can
provide highly accurate electricity price forecasts, critical for informing the
decisions of market participants. However, these models often lack uncertainty
estimates, which limits the ability of decision makers to avoid unnecessary
risks. In this paper, we propose a novel method for generating probabilistic
forecasts from ensembles of point forecasts, called Isotonic Quantile
Regression Averaging (iQRA). Building on the established framework of Quantile
Regression Averaging (QRA), we introduce stochastic order constraints to
improve forecast accuracy, reliability, and computational costs. In an
extensive forecasting study of the German day-ahead electricity market, we show
that iQRA consistently outperforms state-of-the-art postprocessing methods in
terms of both reliability and sharpness. It produces well-calibrated prediction
intervals across multiple confidence levels, providing superior reliability to
all benchmark methods, particularly coverage-based conformal prediction. In
addition, isotonic regularization decreases the complexity of the quantile
regression problem and offers a hyperparameter-free approach to variable
selection.

</details>


### [332] [Robust Control with Gradient Uncertainty](https://arxiv.org/abs/2507.15082)
*Qian Qi*

Main category: cs.LG

TL;DR: 提出了一种新的鲁棒控制方法，解决了强化学习中的梯度不确定性问题，并提出了有效的GURAC算法。


<details>
  <summary>Details</summary>
Motivation: 为了解决强化学习等应用中价值函数近似带来的梯度不确定性问题，并扩展鲁棒控制理论。

Method: 提出了一种新的鲁棒控制理论扩展，将价值函数的梯度不确定性纳入考量，并推导了包含梯度不确定性的汉密尔顿-雅可比-贝尔曼-艾萨克方程（GU-HJBI）。通过证明粘性解的比较原理来建立其适定性，并对线性二次（LQ）情况进行了分析。

Result: 分析了线性二次（LQ）情况，发现价值函数的二次形式假设在梯度不确定性非零时失效，并揭示了最优控制律的非多项式修正和非线性。提出了一种新的梯度不确定性鲁棒 Actor-Critic（GURAC）算法，并通过数值研究验证了其在稳定训练方面的有效性。

Conclusion: 该研究提出了梯度不确定性鲁棒控制的新方向，对强化学习和计算金融等领域具有重要意义。

Abstract: We introduce a novel extension to robust control theory that explicitly
addresses uncertainty in the value function's gradient, a form of uncertainty
endemic to applications like reinforcement learning where value functions are
approximated. We formulate a zero-sum dynamic game where an adversary perturbs
both system dynamics and the value function gradient, leading to a new, highly
nonlinear partial differential equation: the Hamilton-Jacobi-Bellman-Isaacs
Equation with Gradient Uncertainty (GU-HJBI). We establish its well-posedness
by proving a comparison principle for its viscosity solutions under a uniform
ellipticity condition. Our analysis of the linear-quadratic (LQ) case yields a
key insight: we prove that the classical quadratic value function assumption
fails for any non-zero gradient uncertainty, fundamentally altering the problem
structure. A formal perturbation analysis characterizes the non-polynomial
correction to the value function and the resulting nonlinearity of the optimal
control law, which we validate with numerical studies. Finally, we bridge
theory to practice by proposing a novel Gradient-Uncertainty-Robust
Actor-Critic (GURAC) algorithm, accompanied by an empirical study demonstrating
its effectiveness in stabilizing training. This work provides a new direction
for robust control, holding significant implications for fields where function
approximation is common, including reinforcement learning and computational
finance.

</details>


### [333] [AnalogFed: Federated Discovery of Analog Circuit Topologies with Generative AI](https://arxiv.org/abs/2507.15104)
*Qiufeng Li,Shu Hong,Jian Gao,Xuan Zhang,Tian Lan,Weidong Cao*

Main category: cs.LG

TL;DR: AnalogFed facilitates collaborative discovery of analog circuit topologies using federated learning, overcoming data privacy issues and achieving results comparable to centralized methods.


<details>
  <summary>Details</summary>
Motivation: Current generative AI research in analog circuit topology discovery is severely limited by the proprietary and confidential nature of analog circuit design data, leading to fragmented, small, and narrowly focused private datasets. This fragmentation hinders collaborative innovation and impedes progress across the research community.

Method: AnalogFed enables collaborative topology discovery across decentralized clients (e.g., individual researchers or institutions) without requiring the sharing of raw private data. It introduces a suite of techniques tailored to the unique challenges of applying FedL in analog design--from generative model development and data heterogeneity handling to privacy-preserving strategies that ensure both flexibility and security for circuit designers and semiconductor manufacturers.

Result: Extensive experiments across varying client counts and dataset sizes demonstrate that AnalogFed achieves performance comparable to centralized baselines while maintaining strict data privacy. The generative AI model within AnalogFed achieves state-of-the-art efficiency and scalability in the design of analog circuit topologies.

Conclusion: AnalogFed enables collaborative topology discovery across decentralized clients without requiring the sharing of raw private data, achieving performance comparable to centralized baselines while maintaining strict data privacy. The generative AI model within AnalogFed achieves state-of-the-art efficiency and scalability in the design of analog circuit topologies.

Abstract: Recent breakthroughs in AI/ML offer exciting opportunities to revolutionize
analog design automation through data-driven approaches. In particular,
researchers are increasingly fascinated by harnessing the power of generative
AI to automate the discovery of novel analog circuit topologies. Unlocking the
full potential of generative AI in these data-driven discoveries requires
access to large and diverse datasets.Yet, there is a significant barrier in the
analog domain--Analog circuit design is inherently proprietary, involving not
only confidential circuit structures but also the underlying commercial
semiconductor processes. As a result, current generative AI research is largely
confined to individual researchers who construct small, narrowly focused
private datasets. This fragmentation severely limits collaborative innovation
and impedes progress across the research community. To address these
challenges, we propose AnalogFed. AnalogFed enables collaborative topology
discovery across decentralized clients (e.g., individual researchers or
institutions) without requiring the sharing of raw private data. To make this
vision practical, we introduce a suite of techniques tailored to the unique
challenges of applying FedL in analog design--from generative model development
and data heterogeneity handling to privacy-preserving strategies that ensure
both flexibility and security for circuit designers and semiconductor
manufacturers. Extensive experiments across varying client counts and dataset
sizes demonstrate that AnalogFed achieves performance comparable to centralized
baselines--while maintaining strict data privacy. Specifically, the generative
AI model within AnalogFed achieves state-of-the-art efficiency and scalability
in the design of analog circuit topologies.

</details>


### [334] [Distributional Unlearning: Forgetting Distributions, Not Just Samples](https://arxiv.org/abs/2507.15112)
*Youssef Allouah,Rachid Guerraoui,Sanmi Koyejo*

Main category: cs.LG

TL;DR: 提出分布解离框架，有效移除模型中的整个数据域，相比随机移除，删除量更少，对保留数据性能影响小。


<details>
  <summary>Details</summary>
Motivation: 现有的机器学习解离工具主要侧重于单个样本的移除，但在许多实际应用中，需要移除整个子群体（例如，根据GDPR删除用户帖子或删除受版权保护的网页内容）。直接删除样本点往往不足以完全消除残留信号，使得下游学习者能够恢复被移除的域。因此，需要一种更有效的方法来处理整个数据域的移除。

Method: 提出了一种名为“分布解离”的数据中心、模型无关的框架，旨在移除整个主题域的示例。该框架使用KL散度来量化移除和保存，并在高斯情况下推导出帕累托前沿，证明了在编辑数据集上重新训练的任何模型所产生的对数损失偏移都受限于散度阈值。提出了一种简单的基于距离的选择规则，该规则满足这些约束，并将删除预算与随机移除相比减少了平方倍。

Result: 通过使用KL散度量化移除和保存，并在高斯情况下推导出帕累托前沿，证明了任何在编辑数据上重新训练的模型都会产生有界对数损失偏移。提出的基于距离的选择规则比随机移除所需的删除预算减少了平方倍，并在多个数据集的实验中得到了验证。

Conclusion: 所提出的分布解离框架在合成高斯、Jigsaw有毒评论、SMS垃圾邮件和CIFAR-10等实验中，相比随机移除，删除量减少了15%-72%，同时对保留的数据性能影响可忽略不计。

Abstract: Machine unlearning seeks to remove unwanted information from trained models,
initially at the individual-sample level, but increasingly at the level of
entire sub-populations. In many deployments, models must delete whole topical
domains to satisfy privacy, legal, or quality requirements, e.g., removing
several users' posts under GDPR or copyrighted web content. Existing unlearning
tools remain largely sample-oriented, and straightforward point deletion often
leaves enough residual signal for downstream learners to recover the unwanted
domain. We introduce distributional unlearning, a data-centric, model-agnostic
framework that asks: Given examples from an unwanted distribution and a
retained distribution, what is the smallest set of points whose removal makes
the edited dataset far from the unwanted domain yet close to the retained one?
Using Kullback-Leibler divergence to quantify removal and preservation, we
derive the exact Pareto frontier in the Gaussian case and prove that any model
retrained on the edited data incurs log-loss shifts bounded by the divergence
thresholds. We propose a simple distance-based selection rule satisfying these
constraints with a quadratic reduction in deletion budget compared to random
removal. Experiments on synthetic Gaussians, Jigsaw Toxic Comments, SMS spam,
and CIFAR-10 show 15-72% fewer deletions than random, with negligible impact on
retained performance.

</details>


### [335] [Are We Overlooking the Dimensions? Learning Latent Hierarchical Channel Structure for High-Dimensional Time Series Forecasting](https://arxiv.org/abs/2507.15119)
*Juntong Ni,Shiyu Wang,Zewen Liu,Xiaoming Shi,Xinyue Zhong,Zhou Ye,Wei Jin*

Main category: cs.LG

TL;DR: U-Cast是一种新的高维时间序列预测模型，通过学习通道间的层次结构来提高预测精度和效率，并配套发布了Time-HD数据集。


<details>
  <summary>Details</summary>
Motivation: 现有的时间序列预测模型在处理成千上万个通道的高维时间序列数据（高维时间序列预测，HDTSF）时面临严峻挑战，因为它们往往忽略或无法有效处理复杂的通道相关性。

Method: 提出了一种名为U-Cast的通道依赖性预测架构，该架构利用创新的基于查询的注意力来学习潜在的层次化通道结构。为了解开高度相关的通道表示，U-Cast在训练过程中增加了全秩正则化。

Result: 实验结果表明，U-Cast在准确性和效率方面均优于现有的强有力基线模型。

Conclusion: U-Cast及其Time-HD数据集为未来的高维时间序列预测研究奠定了坚实的基础。

Abstract: Time series forecasting (TSF) is a central problem in time series analysis.
However, as the number of channels in time series datasets scales to the
thousands or more, a scenario we define as High-Dimensional Time Series
Forecasting (HDTSF), it introduces significant new modeling challenges that are
often not the primary focus of traditional TSF research. HDTSF is challenging
because the channel correlation often forms complex and hierarchical patterns.
Existing TSF models either ignore these interactions or fail to scale as
dimensionality grows. To address this issue, we propose U-Cast, a
channel-dependent forecasting architecture that learns latent hierarchical
channel structures with an innovative query-based attention. To disentangle
highly correlated channel representation, U-Cast adds a full-rank
regularization during training. We also release Time-HD, a benchmark of large,
diverse, high-dimensional datasets. Our theory shows that exploiting
cross-channel information lowers forecasting risk, and experiments on Time-HD
demonstrate that U-Cast surpasses strong baselines in both accuracy and
efficiency. Together, U-Cast and Time-HD provide a solid basis for future HDTSF
research.

</details>


### [336] [Designing User-Centric Metrics for Evaluation of Counterfactual Explanations](https://arxiv.org/abs/2507.15162)
*Firdaus Ahmed Choudhury,Ethan Leicht,Jude Ethan Bislig,Hangzhi Guo,Amulya Yadav*

Main category: cs.LG

TL;DR: 本研究发现，用于评估反事实解释（CFEs）的人工评估指标（如邻近性）与用户的真实偏好存在显著差异。研究通过用户实验，提出了一种名为AWP的新型以用户为中心的模型，该模型能更准确地预测用户偏好的CFEs，准确率达84.37%，强调了在CFE生成中采用个性化、以用户为中心的评估方法的重要性。


<details>
  <summary>Details</summary>
Motivation: 机器学习决策模型越来越多地用于做出对人们生活有重大影响的决策，但其不透明的性质使得最终用户无法清楚地了解决策的原因。反事实解释（CFEs）作为一种提供可操作性指导的手段越来越受欢迎，它通过识别特征值中能将模型预测改变为更理想结果的最小变动来实现。然而，大多数现有的反事实解释研究都依赖于像邻近性这样的 것입니다。人工评估指标，这可能忽略最终用户的偏好和约束，例如，用户认为进行某些特征更改所需的努力程度可能与模型设计者的看法不同。

Method: 本研究首先进行了试点研究，有20名来自Amazon MTurk的众包工作者参与，旨在通过实验验证现有的反事实解释评估指标与真实用户偏好的一致性。随后，为了设计用户知情的反事实解释评估指标，又进行了更详细的为期两天的用户研究，有41名参与者面临着真实的信贷申请场景，以寻找支持或反驳三种可能解释用户如何评估反事实解释的直观假设的实验证据。最后，基于第二次研究的结果，提出了一种新颖的以用户为中心的两阶段模型AWP，该模型描述了用户评估和选择反事实解释的一种可能机制。

Result: 试点研究结果表明，用户喜欢的反事实解释在63.81%的情况下才与基于邻近性的反事实解释相匹配，这凸显了这些指标在现实世界中的应用局限性。AWP模型能够以84.37%的准确率预测用户喜欢的反事实解释。

Conclusion: 本研究首次通过以人为中心的验证为个性化成本模型在反事实解释生成中的应用提供了支持，并强调了对适应性、以用户为中心的评估指标的需求。

Abstract: Machine learning-based decision models are increasingly being used to make
decisions that significantly impact people's lives, but their opaque nature
leaves end users without a clear understanding of why a decision was made.
Counterfactual Explanations (CFEs) have grown in popularity as a means of
offering actionable guidance by identifying the minimum changes in feature
values required to flip a model's prediction to something more desirable.
Unfortunately, most prior research in CFEs relies on artificial evaluation
metrics, such as proximity, which may overlook end-user preferences and
constraints, e.g., the user's perception of effort needed to make certain
feature changes may differ from that of the model designer. To address this
research gap, this paper makes three novel contributions. First, we conduct a
pilot study with 20 crowd-workers on Amazon MTurk to experimentally validate
the alignment of existing CF evaluation metrics with real-world user
preferences. Results show that user-preferred CFEs matched those based on
proximity in only 63.81% of cases, highlighting the limited applicability of
these metrics in real-world settings. Second, inspired by the need to design a
user-informed evaluation metric for CFEs, we conduct a more detailed two-day
user study with 41 participants facing realistic credit application scenarios
to find experimental support for or against three intuitive hypotheses that may
explain how end users evaluate CFEs. Third, based on the findings of this
second study, we propose the AWP model, a novel user-centric, two-stage model
that describes one possible mechanism by which users evaluate and select CFEs.
Our results show that AWP predicts user-preferred CFEs with 84.37% accuracy.
Our study provides the first human-centered validation for personalized cost
models in CFE generation and highlights the need for adaptive, user-centered
evaluation metrics.

</details>


### [337] [Joint-Local Grounded Action Transformation for Sim-to-Real Transfer in Multi-Agent Traffic Control](https://arxiv.org/abs/2507.15174)
*Justin Turnau,Longchao Da,Khoa Vo,Ferdous Al Rafi,Shreyas Bachiraju,Tiejin Chen,Hua Wei*

Main category: cs.LG

TL;DR: JL-GAT通过整合邻近智能体信息和去中心化方法，解决了MARL交通信号控制中的sim-to-real差距，在各种条件下均有效。


<details>
  <summary>Details</summary>
Motivation: 现实世界中的交通网络包含许多相互作用的交叉路口，更适合MARL框架。然而，MARL在现实世界中的实施常因环境动态变化而导致性能显著下降（sim-to-real差距）。GAT已成功解决了单智能体RL中的此问题，但需要将其应用于MARL以更好地处理复杂的交通网络。

Method: JL-GAT是一种将Grounded Action Transformation (GAT)应用于多智能体强化学习（MARL）交通信号控制（TSC）的方法，它采用去中心化的方式，并整合了来自邻近智能体的信息，以解决sim-to-real差距问题。

Result: 通过在各种道路网络和模拟的恶劣天气条件下的综合实验和消融研究，证明了JL-GAT的有效性。

Conclusion: JL-GAT通过整合邻近智能体的信息，在可扩展性与增强的接地能力之间取得了平衡，并采用了去中心化的方法，实现了在各种道路网络和模拟的恶劣天气条件下的有效性，解决了多智能体强化学习交通信号控制中的sim-to-real差距问题。

Abstract: Traffic Signal Control (TSC) is essential for managing urban traffic flow and
reducing congestion. Reinforcement Learning (RL) offers an adaptive method for
TSC by responding to dynamic traffic patterns, with multi-agent RL (MARL)
gaining traction as intersections naturally function as coordinated agents.
However, due to shifts in environmental dynamics, implementing MARL-based TSC
policies in the real world often leads to a significant performance drop, known
as the sim-to-real gap. Grounded Action Transformation (GAT) has successfully
mitigated this gap in single-agent RL for TSC, but real-world traffic networks,
which involve numerous interacting intersections, are better suited to a MARL
framework. In this work, we introduce JL-GAT, an application of GAT to
MARL-based TSC that balances scalability with enhanced grounding capability by
incorporating information from neighboring agents. JL-GAT adopts a
decentralized approach to GAT, allowing for the scalability often required in
real-world traffic networks while still capturing key interactions between
agents. Comprehensive experiments on various road networks under simulated
adverse weather conditions, along with ablation studies, demonstrate the
effectiveness of JL-GAT. The code is publicly available at
https://github.com/DaRL-LibSignal/JL-GAT/.

</details>


### [338] [Feature Construction Using Network Control Theory and Rank Encoding for Graph Machine Learning](https://arxiv.org/abs/2507.15195)
*Anwar Said,Yifan Wei,Ubaid Ullah Ahmad,Mudassir Shabbir,Waseem Abbas,Xenofon Koutsoukos*

Main category: cs.LG

TL;DR: 通过引入平均可控性和秩编码，提升了图神经网络在社交网络分类任务中的节点特征表示能力和整体性能。


<details>
  <summary>Details</summary>
Motivation: 在社交网络分类任务中，节点特征的缺失或表达性不足是图神经网络（GNNs）面临的主要挑战，这限制了GNNs的性能。这是由于隐私限制或缺乏固有属性，导致节点特征通常不可用。

Method: 本文提出两种策略来构建表达性强的节点特征：1. 结合平均可控性和其他中心性度量（NCT-EFA）作为节点级度量来捕捉网络拓扑的关键方面。2. 开发一种秩编码方法，将平均可控性或任何其他图论度量转换为固定维度的特征空间，以改进特征表示。

Result: 实验结果表明，将平均可控性纳入特征空间能显著提高GNNs的性能。具体来说，在使用GitHub Stargazers数据集和GraphSAGE模型时，所提出的秩编码方法将ROC AUC从68.7%提高到73.9%，优于传统的独热度编码方法。

Conclusion: 所提出的基于平均可控性和秩编码的节点特征构造方法能够显著提升图神经网络在社交网络分类任务上的性能，并且所提出的秩编码方法优于传统的独热度编码方法。

Abstract: In this article, we utilize the concept of average controllability in graphs,
along with a novel rank encoding method, to enhance the performance of Graph
Neural Networks (GNNs) in social network classification tasks. GNNs have proven
highly effective in various network-based learning applications and require
some form of node features to function. However, their performance is heavily
influenced by the expressiveness of these features. In social networks, node
features are often unavailable due to privacy constraints or the absence of
inherent attributes, making it challenging for GNNs to achieve optimal
performance. To address this limitation, we propose two strategies for
constructing expressive node features. First, we introduce average
controllability along with other centrality metrics (denoted as NCT-EFA) as
node-level metrics that capture critical aspects of network topology. Building
on this, we develop a rank encoding method that transforms average
controllability or any other graph-theoretic metric into a fixed-dimensional
feature space, thereby improving feature representation. We conduct extensive
numerical evaluations using six benchmark GNN models across four social network
datasets to compare different node feature construction methods. Our results
demonstrate that incorporating average controllability into the feature space
significantly improves GNN performance. Moreover, the proposed rank encoding
method outperforms traditional one-hot degree encoding, improving the ROC AUC
from 68.7% to 73.9% using GraphSAGE on the GitHub Stargazers dataset,
underscoring its effectiveness in generating expressive and efficient node
representations.

</details>


### [339] [Long-Short Distance Graph Neural Networks and Improved Curriculum Learning for Emotion Recognition in Conversation](https://arxiv.org/abs/2507.15205)
*Xinran Li,Xiujuan Xu,Jiaqi Qiao*

Main category: cs.LG

TL;DR: The paper introduces LSDGNN, a new multimodal model for conversation emotion recognition that uses graph neural networks for long and short-range dependencies, a differential regularizer and BiAffine module for feature interaction, and improved curriculum learning to handle data imbalance, achieving state-of-the-art results on benchmark datasets.


<details>
  <summary>Details</summary>
Motivation: Emotion Recognition in Conversation (ERC) is a practical yet challenging task. The paper aims to address the challenges of capturing both long- and short-distance dependencies in conversational context and handling data imbalance in ERC.

Method: The paper proposes a novel multimodal approach called the Long-Short Distance Graph Neural Network (LSDGNN). This model constructs long- and short-distance graph neural networks based on a Directed Acyclic Graph (DAG) to capture multimodal features from distant and nearby utterances. It employs a Differential Regularizer and a BiAffine Module to enhance feature distinction and interaction. Additionally, an Improved Curriculum Learning (ICL) strategy is introduced to handle data imbalance, using a "weighted emotional shift" metric and a difficulty measurer to prioritize learning easy samples first.

Result: Experimental results on the IEMOCAP and MELD datasets show that the proposed LSDGNN model achieves superior performance compared to existing benchmarks.

Conclusion: The proposed LSDGNN model outperforms existing benchmarks on the IEMOCAP and MELD datasets.

Abstract: Emotion Recognition in Conversation (ERC) is a practical and challenging
task. This paper proposes a novel multimodal approach, the Long-Short Distance
Graph Neural Network (LSDGNN). Based on the Directed Acyclic Graph (DAG), it
constructs a long-distance graph neural network and a short-distance graph
neural network to obtain multimodal features of distant and nearby utterances,
respectively. To ensure that long- and short-distance features are as distinct
as possible in representation while enabling mutual influence between the two
modules, we employ a Differential Regularizer and incorporate a BiAffine Module
to facilitate feature interaction. In addition, we propose an Improved
Curriculum Learning (ICL) to address the challenge of data imbalance. By
computing the similarity between different emotions to emphasize the shifts in
similar emotions, we design a "weighted emotional shift" metric and develop a
difficulty measurer, enabling a training process that prioritizes learning easy
samples before harder ones. Experimental results on the IEMOCAP and MELD
datasets demonstrate that our model outperforms existing benchmarks.

</details>


### [340] [Exact Reformulation and Optimization for Direct Metric Optimization in Binary Imbalanced Classification](https://arxiv.org/abs/2507.15240)
*Le Peng,Yash Travadi,Chuan He,Ying Cui,Ju Sun*

Main category: cs.LG

TL;DR: 针对不平衡分类问题，本研究提出了一种新的精确约束重构和优化框架（ERO），可以直接优化精度、召回率和Fβ分数等指标，并在实验中证明了其优越性。


<details>
  <summary>Details</summary>
Motivation: 现有的不平衡分类方法大多依赖于优化平衡准确率，但在类别重要性不同或特定指标需要达到预定水平的情况下表现不佳。本研究旨在直接优化精度和召回率等关键指标。

Method: 提出了一种新的精确约束重构方法，用于解决不平衡分类中的直接指标优化（DMO）问题，并使用精确惩罚方法进行求解。

Result: 在多个基准数据集上的实验结果表明，所提出的方法在FPOR、FROP和OFBS这三种DMO问题上优于现有最先进的方法。

Conclusion: 该研究提出了针对不平衡分类的精确约束重构和优化（ERO）框架，并将其应用于三种直接指标优化（DMO）问题：固定精度优化召回率（FPOR）、固定召回率优化精度（FROP）和优化Fβ分数（OFBS）。实验结果表明，与现有方法相比，该方法在三种DMO问题上具有实际优势，并有望应用于更广泛的DMO问题。

Abstract: For classification with imbalanced class frequencies, i.e., imbalanced
classification (IC), standard accuracy is known to be misleading as a
performance measure. While most existing methods for IC resort to optimizing
balanced accuracy (i.e., the average of class-wise recalls), they fall short in
scenarios where the significance of classes varies or certain metrics should
reach prescribed levels. In this paper, we study two key classification
metrics, precision and recall, under three practical binary IC settings: fix
precision optimize recall (FPOR), fix recall optimize precision (FROP), and
optimize $F_\beta$-score (OFBS). Unlike existing methods that rely on smooth
approximations to deal with the indicator function involved, \textit{we
introduce, for the first time, exact constrained reformulations for these
direct metric optimization (DMO) problems}, which can be effectively solved by
exact penalty methods. Experiment results on multiple benchmark datasets
demonstrate the practical superiority of our approach over the state-of-the-art
methods for the three DMO problems. We also expect our exact reformulation and
optimization (ERO) framework to be applicable to a wide range of DMO problems
for binary IC and beyond. Our code is available at
https://github.com/sun-umn/DMO.

</details>


### [341] [Spatio-Temporal Demand Prediction for Food Delivery Using Attention-Driven Graph Neural Networks](https://arxiv.org/abs/2507.15246)
*Rabia Latief Bhat,Iqra Altaf Gillani*

Main category: cs.LG

TL;DR: 一种新的基于注意力机制的图神经网络框架，通过对食物配送环境进行建模，能够准确预测订单量，有助于优化配送运营。


<details>
  <summary>Details</summary>
Motivation: 准确的需求预测对于提高食物配送平台的效率和响应能力至关重要，因为订单量的空间异质性和时间波动直接影响运营决策。

Method: 提出了一种基于注意力机制的图神经网络（GNN）框架，将食物配送环境建模为图。节点代表城市配送区，边表示区域间的邻近关系和历史订单流模式。注意力机制用于动态加权邻近区域的影响，从而捕捉空间-时间依赖性。

Result: 实验结果表明，所提出的基于注意力机制的GNN框架在预测未来订单量方面表现出色，具有高精度。

Conclusion: 该模型在实际的食物配送数据集上进行了广泛的实验，证明了其在未来订单量预测方面的高精度，优于现有模型。

Abstract: Accurate demand forecasting is critical for enhancing the efficiency and
responsiveness of food delivery platforms, where spatial heterogeneity and
temporal fluctuations in order volumes directly influence operational
decisions. This paper proposes an attention-based Graph Neural Network
framework that captures spatial-temporal dependencies by modeling the food
delivery environment as a graph. In this graph, nodes represent urban delivery
zones, while edges reflect spatial proximity and inter-regional order flow
patterns derived from historical data. The attention mechanism dynamically
weighs the influence of neighboring zones, enabling the model to focus on the
most contextually relevant areas during prediction. Temporal trends are jointly
learned alongside spatial interactions, allowing the model to adapt to evolving
demand patterns. Extensive experiments on real-world food delivery datasets
demonstrate the superiority of the proposed model in forecasting future order
volumes with high accuracy. The framework offers a scalable and adaptive
solution to support proactive fleet positioning, resource allocation, and
dispatch optimization in urban food delivery operations.

</details>


### [342] [CHORDS: Diffusion Sampling Accelerator with Multi-core Hierarchical ODE Solvers](https://arxiv.org/abs/2507.15260)
*Jiaqi Han,Haotian Ye,Puheng Li,Minkai Xu,James Zou,Stefano Ermon*

Main category: cs.LG

TL;DR: CHORDS是一种无需训练、与模型无关的扩散模型加速框架，利用多核并行性和核间通信来显著提高采样速度，同时保持样本质量。


<details>
  <summary>Details</summary>
Motivation: 现有加速技术需要对模型进行广泛的重新训练或在样本质量上做出重大妥协，而CHORDS提供了一种无需训练的加速方法。

Method: 通过多核并行性探索通用的、无需训练的、与模型无关的加速策略。该框架将多核扩散采样视为一个ODE求解器管道，其中较慢但准确的求解器通过理论上合理的核间通信机制逐步校正较快的求解器。

Result: CHORDS在各种大规模图像和视频扩散模型中显著加快了采样速度，在四个核心的情况下速度提高了2.1倍（比基线提高了50%），在八个核心的情况下速度提高了2.9倍，并且没有质量下降。

Conclusion: CHORDS为实时、高保真扩散生成奠定了坚实的基础。

Abstract: Diffusion-based generative models have become dominant generators of
high-fidelity images and videos but remain limited by their computationally
expensive inference procedures. Existing acceleration techniques either require
extensive model retraining or compromise significantly on sample quality. This
paper explores a general, training-free, and model-agnostic acceleration
strategy via multi-core parallelism. Our framework views multi-core diffusion
sampling as an ODE solver pipeline, where slower yet accurate solvers
progressively rectify faster solvers through a theoretically justified
inter-core communication mechanism. This motivates our multi-core training-free
diffusion sampling accelerator, CHORDS, which is compatible with various
diffusion samplers, model architectures, and modalities. Through extensive
experiments, CHORDS significantly accelerates sampling across diverse
large-scale image and video diffusion models, yielding up to 2.1x speedup with
four cores, improving by 50% over baselines, and 2.9x speedup with eight cores,
all without quality degradation. This advancement enables CHORDS to establish a
solid foundation for real-time, high-fidelity diffusion generation.

</details>


### [343] [Temporal Basis Function Models for Closed-Loop Neural Stimulation](https://arxiv.org/abs/2507.15274)
*Matthew J. Bryan,Felix Schwock,Azadeh Yazdan-Shahmorad,Rajesh P N Rao*

Main category: cs.LG

TL;DR: 该研究提出了一种名为时间基函数模型（TBFM）的新方法，用于解决闭环神经刺激的个体化和新疗法发现问题。TBFM能够高效、快速且低延迟地预测和控制神经活动，在模拟和实际数据中均表现出色，为开发临床实用的闭环神经刺激疗法提供了新途径。


<details>
  <summary>Details</summary>
Motivation: 本研究旨在解决闭环神经刺激在个体化治疗和识别新疗法方面的挑战。尽管闭环神经刺激为帕金森病等神经系统疾病提供了新的治疗方法，但目前尚不清楚人工智能（AI）技术是否能够实现针对个体患者的闭环刺激定制，或者发现新的治疗方法。为了实现这一目标，需要解决样本效率、训练时间和最小化回路延迟等实际应用中的问题，以确保刺激能够根据不断变化的脑活动进行调整。

Method: 本研究提出并探索了一种名为时间基函数模型（TBFM）的方法，并将其应用于兴奋性光遗传刺激的背景下。研究人员使用TBFM对两个非人灵长类动物的局部场电位（LFPs）进行了前向预测，以评估其对光遗传刺激效果的预测能力。此外，还通过模拟实验展示了TBFM在闭环刺激中的应用，以引导神经活动达到目标模式。该模型在实际数据和模拟数据上都进行了测试，并与非线性动力学系统模型和线性状态空间模型进行了比较。

Result: TBFM能够对光遗传刺激对局部场电位（LFPs）产生单次PerTrial（single-trial）、时空（spatiotemporal）的前向预测。研究人员在两个非人灵长类动物的实验数据中验证了这一点。此外，模拟结果表明TBFM可用于闭环刺激，以驱动神经活动趋向于目标模式。TBFM模型具有样本效率高、训练速度快（2-4分钟）和延迟低（0.2毫秒）的特点。在对40个已发表的兴奋性光遗传刺激数据的分析中，TBFM在每个样本中仅需15-20分钟的数据收集即可成功模拟剩余部分的数据，其预测精度与需要数小时训练的基线非线性动力学系统模型相当，并优于线性状态空间模型。在模拟中，TBFM成功驱动了一个闭环刺激器来控制一个神经回路。

Conclusion: 该研究提出了一种名为时间基函数模型（TBFM）的新方法，旨在解决闭环神经刺激在个体化治疗和新疗法识别方面的挑战。研究表明，TBFM在预测光遗传刺激对局部场电位（LFPs）的影响方面表现出色，并且在模拟中能够实现闭环刺激以控制神经活动。该模型具有样本效率高、训练速度快（2-4分钟）和延迟低（0.2毫秒）的优点，在预测精度上可与复杂的基线模型相媲美，并优于线性状态空间模型。这项工作为利用人工智能驱动的闭环神经刺激疗法在临床应用奠定了基础。

Abstract: Closed-loop neural stimulation provides novel therapies for neurological
diseases such as Parkinson's disease (PD), but it is not yet clear whether
artificial intelligence (AI) techniques can tailor closed-loop stimulation to
individual patients or identify new therapies. Progress requires us to address
a number of translational issues, including sample efficiency, training time,
and minimizing loop latency such that stimulation may be shaped in response to
changing brain activity. We propose temporal basis function models (TBFMs) to
address these difficulties, and explore this approach in the context of
excitatory optogenetic stimulation. We demonstrate the ability of TBF models to
provide a single-trial, spatiotemporal forward prediction of the effect of
optogenetic stimulation on local field potentials (LFPs) measured in two
non-human primates. We further use simulations to demonstrate the use of TBF
models for closed-loop stimulation, driving neural activity towards target
patterns. The simplicity of TBF models allow them to be sample efficient, rapid
to train (2-4min), and low latency (0.2ms) on desktop CPUs. We demonstrate the
model on 40 sessions of previously published excitatory optogenetic stimulation
data. For each session, the model required 15-20min of data collection to
successfully model the remainder of the session. It achieved a prediction
accuracy comparable to a baseline nonlinear dynamical systems model that
requires hours to train, and superior accuracy to a linear state-space model.
In our simulations, it also successfully allowed a closed-loop stimulator to
control a neural circuit. Our approach begins to bridge the translational gap
between complex AI-based approaches to modeling dynamical systems and the
vision of using such forward prediction models to develop novel, clinically
useful closed-loop stimulation protocols.

</details>


### [344] [Machine Unlearning for Streaming Forgetting](https://arxiv.org/abs/2507.15280)
*Shaofei Shen,Chenhao Zhang,Yawen Zhao,Alina Bialkowski,Weitong Chen,Miao Xu*

Main category: cs.LG

TL;DR: 提出了一种处理流式数据删除请求的机器学习遗忘新方法，提高了效率和效果。


<details>
  <summary>Details</summary>
Motivation: 现有的机器学习遗忘方法通常一次性处理所有遗忘数据，无法有效应对实际场景中出现的流式数据删除请求，导致效率和效果下降。因此，需要新的方法来解决流式遗忘带来的性能维持、效率和数据访问挑战。

Method: 提出了一种将遗忘问题形式化为分布偏移问题的流式遗忘范式，并设计了一种新的流式遗忘算法，该算法在不访问原始训练数据的情况下实现高效的流式遗忘。

Result: 理论分析证明了在流式遗忘的遗憾（regret）上存在 O(√T + V_T) 的误差界限，其中 V_T 是 T 个学习轮次中累积的总变异。实验结果验证了所提出方法在各种模型和数据集上的性能。

Conclusion: 该研究提出了一种新颖的流式机器学习遗忘算法，能够高效地处理流式数据删除请求，并且无需访问原始训练数据。通过将遗忘问题形式化为分布偏移问题，并提供理论误差界限，该方法在多种模型和数据集上得到了验证。

Abstract: Machine unlearning aims to remove knowledge of the specific training data in
a well-trained model. Currently, machine unlearning methods typically handle
all forgetting data in a single batch, removing the corresponding knowledge all
at once upon request. However, in practical scenarios, requests for data
removal often arise in a streaming manner rather than in a single batch,
leading to reduced efficiency and effectiveness in existing methods. Such
challenges of streaming forgetting have not been the focus of much research. In
this paper, to address the challenges of performance maintenance, efficiency,
and data access brought about by streaming unlearning requests, we introduce a
streaming unlearning paradigm, formalizing the unlearning as a distribution
shift problem. We then estimate the altered distribution and propose a novel
streaming unlearning algorithm to achieve efficient streaming forgetting
without requiring access to the original training data. Theoretical analyses
confirm an $O(\sqrt{T} + V_T)$ error bound on the streaming unlearning regret,
where $V_T$ represents the cumulative total variation in the optimal solution
over $T$ learning rounds. This theoretical guarantee is achieved under mild
conditions without the strong restriction of convex loss function. Experiments
across various models and datasets validate the performance of our proposed
method.

</details>


### [345] [Mixture of Autoencoder Experts Guidance using Unlabeled and Incomplete Data for Exploration in Reinforcement Learning](https://arxiv.org/abs/2507.15287)
*Elias Malomgré,Pieter Simoens*

Main category: cs.LG

TL;DR: 提出了一种利用不完整专家演示的框架，通过将状态相似性转化为内在奖励，实现灵活探索，并在各种环境下均表现良好。


<details>
  <summary>Details</summary>
Motivation: 为了在没有显式奖励的情况下，利用奖励的内在动机技术来学习，并适应真实世界环境中的泛化智能体，利用不完整的演示作为监督信号。

Method: 提出了一种框架，该框架可以通过将智能体状态与专家数据之间的相似性映射转换为一个有界的内在奖励，从而实现对专家行为的灵活和有针对性的探索。采用混合自动编码器专家模型来捕捉多样的行为并适应演示中的缺失信息。

Result: 实验表明，该方法在稀疏和密集奖励环境下都能够进行鲁棒的探索并取得优异的性能，即使在演示稀疏或不完整的情况下也是如此。

Conclusion: 该方法为在无最优数据和需要精确奖励控制的现实环境中的强化学习提供了一个实用的框架。

Abstract: Recent trends in Reinforcement Learning (RL) highlight the need for agents to
learn from reward-free interactions and alternative supervision signals, such
as unlabeled or incomplete demonstrations, rather than relying solely on
explicit reward maximization. Additionally, developing generalist agents that
can adapt efficiently in real-world environments often requires leveraging
these reward-free signals to guide learning and behavior. However, while
intrinsic motivation techniques provide a means for agents to seek out novel or
uncertain states in the absence of explicit rewards, they are often challenged
by dense reward environments or the complexity of high-dimensional state and
action spaces. Furthermore, most existing approaches rely directly on the
unprocessed intrinsic reward signals, which can make it difficult to shape or
control the agent's exploration effectively. We propose a framework that can
effectively utilize expert demonstrations, even when they are incomplete and
imperfect. By applying a mapping function to transform the similarity between
an agent's state and expert data into a shaped intrinsic reward, our method
allows for flexible and targeted exploration of expert-like behaviors. We
employ a Mixture of Autoencoder Experts to capture a diverse range of behaviors
and accommodate missing information in demonstrations. Experiments show our
approach enables robust exploration and strong performance in both sparse and
dense reward environments, even when demonstrations are sparse or incomplete.
This provides a practical framework for RL in realistic settings where optimal
data is unavailable and precise reward control is needed.

</details>


### [346] [Preferential subspace identification (PSID) with forward-backward smoothing](https://arxiv.org/abs/2507.15288)
*Omid G. Sani,Maryam M. Shanechi*

Main category: cs.LG

TL;DR: PSID的扩展，用于多元时间序列的滤波和Smoothing。


<details>
  <summary>Details</summary>
Motivation: 虽然现有的偏好子空间识别（PSID）方法侧重于利用过去的初级数据进行最优预测，但本文认为，在离线应用中，通过整合并发数据（滤波）或所有可用数据（平滑）可以实现更好的估计。

Method: 本文首先表明，次级信号的存在使得可以从一组同样优化的状态空间模型中唯一地识别出一个具有最优卡尔曼更新步骤（以实现滤波）的模型。我们的滤波解决方案通过一个降秩回归步骤来增强PSID，该步骤直接从数据中学习更新步骤所需的最优增益。我们将此PSID扩展称为带滤波的PSID。其次，受双滤波卡尔曼平滑器配方的启发，我们开发了一种新颖的前向-后向PSID平滑算法，其中我们首先应用带滤波的PSID，然后在过滤后的次级信号的残差上再次反向应用它。

Result: 我们通过模拟数据验证了我们的方法，结果表明，该方法能够恢复出滤波问题的真实模型参数，并实现次级信号的最优滤波和Smoothing解码性能，与真实模型理想性能相匹配。

Conclusion: 本研究为双信号场景下的最优线性滤波和Smoothing提供了一个原则性框架，显著扩展了分析多元时间序列动态交互的工具集。

Abstract: System identification methods for multivariate time-series, such as neural
and behavioral recordings, have been used to build models for predicting one
from the other. For example, Preferential Subspace Identification (PSID) builds
a state-space model of a primary time-series (e.g., neural activity) to
optimally predict a secondary time-series (e.g., behavior). However, PSID
focuses on optimal prediction using past primary data, even though in offline
applications, better estimation can be achieved by incorporating concurrent
data (filtering) or all available data (smoothing). Here, we extend PSID to
enable optimal filtering and smoothing. First, we show that the presence of a
secondary signal makes it possible to uniquely identify a model with an optimal
Kalman update step (to enable filtering) from a family of otherwise equivalent
state-space models. Our filtering solution augments PSID with a reduced-rank
regression step that directly learns the optimal gain required for the update
step from data. We refer to this extension of PSID as PSID with filtering.
Second, inspired by two-filter Kalman smoother formulations, we develop a novel
forward-backward PSID smoothing algorithm where we first apply PSID with
filtering and then apply it again in the reverse time direction on the
residuals of the filtered secondary signal. We validate our methods on
simulated data, showing that our approach recovers the ground-truth model
parameters for filtering, and achieves optimal filtering and smoothing decoding
performance of the secondary signal that matches the ideal performance of the
true underlying model. This work provides a principled framework for optimal
linear filtering and smoothing in the two-signal setting, significantly
expanding the toolkit for analyzing dynamic interactions in multivariate
time-series.

</details>


### [347] [Feel-Good Thompson Sampling for Contextual Bandits: a Markov Chain Monte Carlo Showdown](https://arxiv.org/abs/2507.15290)
*Emile Anand,Sarah Liaw*

Main category: cs.LG

TL;DR: FG-TS是一种用于上下文老虎机的算法，旨在解决高维问题中的探索/利用权衡问题。本文首次系统地研究了FG-TS及其平滑变体（SFG-TS）的性能，并将其与标准TS进行了比较。研究发现，FG-TS在某些情况下优于TS，但并非在所有情况下都如此，并且其性能会受到后验样本准确性的影响。


<details>
  <summary>Details</summary>
Motivation: 填补FG-TS在近似后验（常见于大规模或神经问题）下的性能评估空白。

Method: 通过在十一个真实世界和合成基准测试中对FG-TS及其平滑变体（SFG-TS）进行系统研究，并与具有精确后验（线性/逻辑老虎机）和近似后验（神经老虎机）的设置进行比较来评估其稳健性。

Result: FG-TS在大多数情况下优于标准TS，但在神经老虎机中表现较弱。对预处理、奖励缩放和先验强度进行的分析揭示了一个权衡：当后验样本准确时，较大的奖励有助于提高性能，但在采样噪声占主导地位时，则会损害性能。

Conclusion: FG-TS及其变体在现代上下文老虎机基准测试中具有竞争力且易于使用，建议将其用作基线。

Abstract: Thompson Sampling (TS) is widely used to address the exploration/exploitation
tradeoff in contextual bandits, yet recent theory shows that it does not
explore aggressively enough in high-dimensional problems. Feel-Good Thompson
Sampling (FG-TS) addresses this by adding an optimism bonus that biases toward
high-reward models, and it achieves the asymptotically minimax-optimal regret
in the linear setting when posteriors are exact. However, its performance with
\emph{approximate} posteriors -- common in large-scale or neural problems --
has not been benchmarked. We provide the first systematic study of FG-TS and
its smoothed variant (SFG-TS) across eleven real-world and synthetic
benchmarks. To evaluate their robustness, we compare performance across
settings with exact posteriors (linear and logistic bandits) to approximate
regimes produced by fast but coarse stochastic-gradient samplers. Ablations
over preconditioning, bonus scale, and prior strength reveal a trade-off:
larger bonuses help when posterior samples are accurate, but hurt when sampling
noise dominates. FG-TS generally outperforms vanilla TS in linear and logistic
bandits, but tends to be weaker in neural bandits. Nevertheless, because FG-TS
and its variants are competitive and easy-to-use, we recommend them as
baselines in modern contextual-bandit benchmarks. Finally, we provide source
code for all our experiments in
https://github.com/SarahLiaw/ctx-bandits-mcmc-showdown.

</details>


### [348] [Beyond Model Base Selection: Weaving Knowledge to Master Fine-grained Neural Network Design](https://arxiv.org/abs/2507.15336)
*Jialiang Wang,Hanmo Liu,Shimin Di,Zhili Wang,Jiachuan Wang,Lei Chen,Xiaofang Zhou*

Main category: cs.LG

TL;DR: M-DESIGN 通过构建模型知识库（MKB），并利用知识编织引擎和预测查询规划器，解决了数据库中神经网络模型选择和精炼的不足，能够自适应地优化模型匹配，并在图分析任务中取得了显著效果。


<details>
  <summary>Details</summary>
Motivation: 现有的数据库内嵌机器学习方法在模型选择时忽视了任务查询与模型架构变体之间细粒度的、不断演化的关系依赖，导致匹配不佳且无法有效精炼模型，存在模型精炼的不足。

Method: 提出 M-DESIGN，一个包含知识编织引擎和预测查询规划器的模型知识库（MKB）管道。该系统通过图关系知识模式来优化神经网络模型选择和精炼，该模式显式地编码了数据属性、架构变体和成对性能差异作为可连接关系，以解决自适应查询问题。

Result: M-DESIGN 在图分析任务上进行了实例化，其模型知识库为现有基准增加了结构化元数据，涵盖了 3 个图任务和 22 个图数据集，包含 67,760 个图模型记录。实验结果表明，在有限的预算下，M-DESIGN 在 33 个数据-任务对中的 26 个实现了最优模型。

Conclusion: M-DESIGN 通过其知识编织引擎和预测查询规划器，能够有效地为图分析任务找到最优模型，并在大多数数据-任务对中以有限的预算实现了最优解。

Abstract: Database systems have recently advocated for embedding machine learning (ML)
capabilities, offering declarative model queries over large, managed model
repositories, thereby circumventing the huge computational overhead of
traditional ML-based algorithms in automated neural network model selection.
Pioneering database studies aim to organize existing benchmark repositories as
model bases (MB), querying them for the model records with the highest
performance estimation metrics for given tasks. However, this static model
selection practice overlooks the fine-grained, evolving relational dependencies
between diverse task queries and model architecture variations, resulting in
suboptimal matches and failing to further refine the model effectively. To fill
the model refinement gap in database research, we propose M-DESIGN, a curated
model knowledge base (MKB) pipeline for mastering neural network refinement by
adaptively weaving prior insights about model architecture modification. First,
we propose a knowledge weaving engine that reframes model refinement as an
adaptive query problem over task metadata. Given a user's task query, M-DESIGN
quickly matches and iteratively refines candidate models by leveraging a
graph-relational knowledge schema that explicitly encodes data properties,
architecture variations, and pairwise performance deltas as joinable relations.
This schema supports fine-grained relational analytics over architecture tweaks
and drives a predictive query planner that can detect and adapt to
out-of-distribution (OOD) tasks. We instantiate M-DESIGN for graph analytics
tasks, where our model knowledge base enriches existing benchmarks with
structured metadata covering 3 graph tasks and 22 graph datasets, contributing
data records of 67,760 graph models. Empirical results demonstrate that
M-DESIGN delivers the optimal model in 26 of 33 data-task pairs within limited
budgets.

</details>


### [349] [To Label or Not to Label: PALM -- A Predictive Model for Evaluating Sample Efficiency in Active Learning Models](https://arxiv.org/abs/2507.15381)
*Julia Machnio,Mads Nielsen,Mostafa Mehdipour Ghazi*

Main category: cs.LG

TL;DR: PALM 是一个用于评估主动学习（AL）的数学模型，通过四个关键参数（精度、效率、早期性能、可扩展性）来预测和比较 AL 策略的性能，尤其是在预算有限的情况下。它通过实验验证了其跨数据集、预算和策略的泛化能力，并为更系统、可复现和数据高效的 AL 评估奠定了基础。


<details>
  <summary>Details</summary>
Motivation: 传统的评估方法主要关注最终准确性，未能捕捉学习过程的完整动态。为了解决这个差距，PALM 被提出用于更全面地评估主动学习。

Method: PALM (Performance Analysis of Active Learning Models) 是一个统一且可解释的数学模型，通过四个关键参数来表征主动学习（AL）轨迹：可实现精度、覆盖效率、早期性能和可扩展性。该模型能够通过部分观测值预测 AL 行为，从而能够估计未来性能并促进不同策略之间的原则性比较。

Result: PALM 通过在 CIFAR-10/100 和 ImageNet-50/100/200 上进行的大量实验进行了验证，涵盖了广泛的 AL 方法和自监督嵌入。结果表明，PALM 能够跨数据集、预算和策略有效地泛化，并能从有限的标记数据中准确预测完整的学习曲线。该模型揭示了学习效率、数据空间覆盖和 AL 方法可扩展性方面的重要见解。

Conclusion: PALM 是一个统一且可解释的数学模型，用于表征主动学习（AL）轨迹，通过四个关键参数：可实现精度、覆盖效率、早期性能和可扩展性。PALM 能够通过部分观测值对 AL 行为进行预测性描述，从而能够估计未来性能并促进不同策略之间的原则性比较。PALM 能够跨数据集、预算和策略有效地泛化，并能从有限的标记数据中准确预测完整的学习曲线。通过实现成本效益策略的选择和预测紧缩预算下的性能，PALM 为在研究和实际应用中更系统、可复现和数据高效的 AL 评估奠定了基础。

Abstract: Active learning (AL) seeks to reduce annotation costs by selecting the most
informative samples for labeling, making it particularly valuable in
resource-constrained settings. However, traditional evaluation methods, which
focus solely on final accuracy, fail to capture the full dynamics of the
learning process. To address this gap, we propose PALM (Performance Analysis of
Active Learning Models), a unified and interpretable mathematical model that
characterizes AL trajectories through four key parameters: achievable accuracy,
coverage efficiency, early-stage performance, and scalability. PALM provides a
predictive description of AL behavior from partial observations, enabling the
estimation of future performance and facilitating principled comparisons across
different strategies. We validate PALM through extensive experiments on
CIFAR-10/100 and ImageNet-50/100/200, covering a wide range of AL methods and
self-supervised embeddings. Our results demonstrate that PALM generalizes
effectively across datasets, budgets, and strategies, accurately predicting
full learning curves from limited labeled data. Importantly, PALM reveals
crucial insights into learning efficiency, data space coverage, and the
scalability of AL methods. By enabling the selection of cost-effective
strategies and predicting performance under tight budget constraints, PALM lays
the basis for more systematic, reproducible, and data-efficient evaluation of
AL in both research and real-world applications. The code is available at:
https://github.com/juliamachnio/PALM.

</details>


### [350] [MAP Estimation with Denoisers: Convergence Rates and Guarantees](https://arxiv.org/abs/2507.15397)
*Scott Pesme,Giacomo Meanti,Michael Arbel,Julien Mairal*

Main category: cs.LG

TL;DR: 去噪器模型在逆问题中很有用，通常用于最大后验（MAP）优化。虽然实践中会使用预训练的去噪器作为近端算子，但缺乏理论依据。本研究提出了一种算法，在先验对数凹度假设下可收敛到近端算子，并提供了理论基础。


<details>
  <summary>Details</summary>
Motivation: 现有的去噪器模型被用作最大后验（MAP）优化问题的代理，但这种替代缺乏普遍的理论依据。本研究旨在为这种启发式方法提供理论基础。

Method: 提出了一种与实践中使用的几种算法密切相关的简单算法，并在先验 p 的对数凹度假设下，证明了该算法可收敛到近端算子。

Result: 证明了一种简单算法在先验对数凹度假设下可收敛到近端算子，并将其解释为平滑近端目标的梯度下降。

Conclusion: 该算法可以被解释为在平滑近端目标上的梯度下降，为经验上成功但此前是启发式的方法提供了理论基础。

Abstract: Denoiser models have become powerful tools for inverse problems, enabling the
use of pretrained networks to approximate the score of a smoothed prior
distribution. These models are often used in heuristic iterative schemes aimed
at solving Maximum a Posteriori (MAP) optimisation problems, where the proximal
operator of the negative log-prior plays a central role. In practice, this
operator is intractable, and practitioners plug in a pretrained denoiser as a
surrogate-despite the lack of general theoretical justification for this
substitution. In this work, we show that a simple algorithm, closely related to
several used in practice, provably converges to the proximal operator under a
log-concavity assumption on the prior $p$. We show that this algorithm can be
interpreted as a gradient descent on smoothed proximal objectives. Our analysis
thus provides a theoretical foundation for a class of empirically successful
but previously heuristic methods.

</details>


### [351] [The calculus of variations of the Transformer on the hyperspherical tangent bundle](https://arxiv.org/abs/2507.15431)
*Andrew Gracyk*

Main category: cs.LG

TL;DR: Transformer 在数学上可以被理解为流映射，并可以通过变分法进行分析，这为量化 Transformer 数据和优化损失提供了新的视角。


<details>
  <summary>Details</summary>
Motivation: 为 Transformer 提供理论数学背景，并将其与变分法联系起来，探索新的应用场景。

Method: 使用拉格朗日优化和变分法来分析 Transformer。通过将 Transformer 视为切线丛中的流映射，我们推导了其欧拉-拉格朗日方程。

Result: 我们推导了 Transformer 的欧拉-拉格朗日方程，并展示了 Transformer 可以被视为变分法问题的自然解。

Conclusion: Transformer 可以被视为变分法问题的自然解，并且我们的分析为在变分背景下量化 Transformer 数据奠定了基础。

Abstract: We offer a theoretical mathematical background to Transformers through
Lagrangian optimization across the token space. The Transformer, as a flow map,
exists in the tangent fiber for each token along the high-dimensional unit
sphere. The circumstance of the hypersphere across the latent data is
reasonable due to the trained diagonal matrix equal to the identity, which has
various empirical justifications. Thus, under the continuum limit of the
dynamics, the latent vectors flow among the tangent bundle. Using these facts,
we devise a mathematical framework for the Transformer through calculus of
variations. We develop a functional and show that the continuous flow map
induced by the Transformer satisfies this functional, therefore the Transformer
can be viewed as a natural solver of a calculus of variations problem. We
invent new scenarios of when our methods are applicable based on loss
optimization with respect to path optimality. We derive the Euler-Lagrange
equation for the Transformer. The variant of the Euler-Lagrange equation we
present has various appearances in literature, but, to our understanding,
oftentimes not foundationally proven or under other specialized cases. Our
overarching proof is new: our techniques are classical and the use of the flow
map object is original. We provide several other relevant results, primarily
ones specific to neural scenarios. In particular, much of our analysis will be
attempting to quantify Transformer data in variational contexts under neural
approximations. Calculus of variations on manifolds is a well-nourished
research area, but for the Transformer specifically, it is uncharted: we lay
the foundation for this area through an introduction to the Lagrangian for the
Transformer.

</details>


### [352] [An Adaptive Random Fourier Features approach Applied to Learning Stochastic Differential Equations](https://arxiv.org/abs/2507.15442)
*Owen Douglas,Aku Kammonen,Anamika Pandey,Raúl Tempone*

Main category: cs.LG

TL;DR: 本研究提出了一种名为 ARFF 的新训练算法，用于从数据中学习随机过程。该算法在性能和速度上优于现有方法，为随机动力学建模提供了一种有前景的新选择。


<details>
  <summary>Details</summary>
Motivation: 从快照数据中学习随机微分方程的漂移和扩散分量。

Method: 提出了一种基于自适应随机傅里叶特征（ARFF）并结合Metropolis采样和重采样的方法，用于从快照数据中学习随机微分方程的漂移和扩散分量，并采用了基于Euler-Maruyama积分的似然损失函数。

Result: 在包括多项式示例、欠阻尼 Langevin 动力学、随机易感-感染-恢复模型和随机波动方程在内的基准问题上，ARFF 方法与传统的基于 Adam 的优化方法在损失最小化和收敛速度方面均表现相当或更优。

Conclusion: ARFF作为数据驱动的随机动力学建模的有力替代方案，在损失最小化和收敛速度方面都与基于Adam的优化方法相匹配或超越。

Abstract: This work proposes a training algorithm based on adaptive random Fourier
features (ARFF) with Metropolis sampling and resampling
\cite{kammonen2024adaptiverandomfourierfeatures} for learning drift and
diffusion components of stochastic differential equations from snapshot data.
Specifically, this study considers It\^{o} diffusion processes and a
likelihood-based loss function derived from the Euler-Maruyama integration
introduced in \cite{Dietrich2023} and
\cite{dridi2021learningstochasticdynamicalsystems}.
  This work evaluates the proposed method against benchmark problems presented
in \cite{Dietrich2023}, including polynomial examples, underdamped Langevin
dynamics, a stochastic susceptible-infected-recovered model, and a stochastic
wave equation. Across all cases, the ARFF-based approach matches or surpasses
the performance of conventional Adam-based optimization in both loss
minimization and convergence speed. These results highlight the potential of
ARFF as a compelling alternative for data-driven modeling of stochastic
dynamics.

</details>


### [353] [FedMultiEmo: Real-Time Emotion Recognition via Multimodal Federated Learning](https://arxiv.org/abs/2507.15470)
*Baran Can Gül,Suraksha Nadig,Stefanos Tziampazis,Nasser Jazdi,Michael Weyrich*

Main category: cs.LG

TL;DR: FedMultiEmo 是一个创新的隐私保护框架，通过融合视觉和生理数据，在汽车环境中实现了高精度的实时情感识别，解决了传统方法的局限性。


<details>
  <summary>Details</summary>
Motivation: 为了解决实际部署中视觉方法的光照不佳和遮挡问题、跨个体的心率和皮肤电导率模式差异以及集中式训练带来的隐私风险，我们提出了 FedMultiEmo 框架。

Method: FedMultiEmo 是一个隐私保护框架，它在决策层面融合了两种互补的模式：来自面部图像的卷积神经网络提取的视觉特征，以及随机森林分类的生理线索（心率、皮肤电活动和皮肤温度）。FedMultiEmo 基于三个关键要素：(1) 具有多数投票融合的多模式联邦学习管道，(2) 在 Raspberry Pi 客户端和 Flower 服务器上的端到端边缘到云原型，(3) 加权客户端更新的个性化联邦平均方案。

Result: 在 FER2013 和自定义生理数据集上进行评估，联邦卷积神经网络的准确率为 77%，随机森林为 74%，两者融合后可达 87%，与集中式基线相当，同时所有原始数据都保留在本地。开发的系统在 18 轮内收敛，平均每轮耗时 120 秒，每个客户端的内存占用量低于 200 MB。

Conclusion: FedMultiEmo 提供了一种在汽车环境中进行实时、注重隐私的情感识别的实用方法。

Abstract: In-vehicle emotion recognition underpins adaptive driver-assistance systems
and, ultimately, occupant safety. However, practical deployment is hindered by
(i) modality fragility - poor lighting and occlusions degrade vision-based
methods; (ii) physiological variability - heart-rate and skin-conductance
patterns differ across individuals; and (iii) privacy risk - centralized
training requires transmission of sensitive data. To address these challenges,
we present FedMultiEmo, a privacy-preserving framework that fuses two
complementary modalities at the decision level: visual features extracted by a
Convolutional Neural Network from facial images, and physiological cues (heart
rate, electrodermal activity, and skin temperature) classified by a Random
Forest. FedMultiEmo builds on three key elements: (1) a multimodal federated
learning pipeline with majority-vote fusion, (2) an end-to-end edge-to-cloud
prototype on Raspberry Pi clients and a Flower server, and (3) a personalized
Federated Averaging scheme that weights client updates by local data volume.
Evaluated on FER2013 and a custom physiological dataset, the federated
Convolutional Neural Network attains 77% accuracy, the Random Forest 74%, and
their fusion 87%, matching a centralized baseline while keeping all raw data
local. The developed system converges in 18 rounds, with an average round time
of 120 seconds and a per-client memory footprint below 200 MB. These results
indicate that FedMultiEmo offers a practical approach to real-time,
privacy-aware emotion recognition in automotive settings.

</details>


### [354] [Off-Policy Corrected Reward Modeling for Reinforcement Learning from Human Feedback](https://arxiv.org/abs/2507.15507)
*Johannes Ackermann,Takashi Ishida,Masashi Sugiyama*

Main category: cs.LG

TL;DR: OCRM 通过样本外校正奖励模型解决了 RLHF 中的过优化问题，提高了模型性能。


<details>
  <summary>Details</summary>
Motivation: 在 RLHF 训练过程中，随着模型生成响应的分布发生偏移，导致 RM 预测不准确，即使 RM 分数持续提高，学习行为也可能不再符合人类偏好，这种现象被称为过优化。

Method: 提出 Off-Policy Corrected Reward Modeling (OCRM)，通过迭代地使用重要性加权进行样本外校正，以获得更准确的奖励模型（RM），无需新的标签或样本。

Result: OCRM 实现了更准确的 RM，在摘要和聊天机器人数据集的实验中，相比标准 RLHF 方法和基线方法，在最终策略方面表现更优。

Conclusion: RLHF 训练过程中，由于分布偏移导致奖励模型（RM）过拟合，进而策略梯度估计不一致。提出了一种名为 OCRM 的方法，通过迭代地使用重要性加权进行样本外校正，以获得更准确的 RM，从而改进最终策略。实验证明 OCRM 在摘要和聊天机器人数据集上显著优于标准 RLHF 方法和基线方法。

Abstract: Reinforcement Learning from Human Feedback (RLHF) allows us to train models,
such as language models (LMs), to follow complex human preferences. In RLHF for
LMs, we first train an LM using supervised fine-tuning, sample pairs of
responses, obtain human feedback, and use the resulting data to train a reward
model (RM). RL methods are then used to train the LM to maximize the reward
given by the RM. As training progresses, the responses generated by the LM no
longer resemble the responses seen by the RM during training, leading to the RM
becoming inaccurate. The score given by the RM keeps increasing, but the
learned behavior no longer matches the human preferences. This issue is known
as overoptimization. We investigate overoptimization from the point of view of
distribution shift and show that the shift results in an inconsistent estimate
of the RM parameters, leading to an inconsistent estimate of the policy
gradient. We propose Off-Policy Corrected Reward Modeling (OCRM), which
iteratively off-policy corrects the RM using importance weighting, without
requiring new labels or samples. This results in a more accurate RM, which
empirically leads to an improved final policy. We validate our approach in
experiments with summarization and chatbot datasets and show that it performs
significantly better than standard RLHF methods and baselines. Our
implementation is available at
https://github.com/JohannesAck/OffPolicyCorrectedRewardModeling

</details>


### [355] [Data Mixing Agent: Learning to Re-weight Domains for Continual Pre-training](https://arxiv.org/abs/2507.15640)
*Kailai Yang,Xiao Liu,Lei Ji,Hao Li,Yeyun Gong,Peng Cheng,Mao Yang*

Main category: cs.LG

TL;DR: 本研究提出了一种名为 Data Mixing Agent 的新框架，通过强化学习自动调整不同领域训练数据的权重，解决了大型语言模型在持续学习新知识时遗忘旧知识的问题，并在数学推理和代码生成任务中取得了优于现有方法的性能，同时还具备良好的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 持续预训练虽然能提升大型语言模型在新领域的表现，但存在灾难性遗忘原有能力的风险。现有的解决方案通常通过重新加权不同域的训练数据来平衡模型在源域和目标域上的性能，但这些方法依赖于手动指定或基于人类直觉/经验结果的启发式规则，不够通用。

Method: 本研究提出了一种名为 Data Mixing Agent 的新框架，该框架利用强化学习来学习如何重新加权来自不同域（源域和目标域）的训练数据。与依赖手动指定或启发式规则的传统方法不同，Data Mixing Agent 通过在大量数据混合轨迹上进行训练，并根据评估环境的反馈进行学习，从而学习到更通用的启发式规则。

Result: Data Mixing Agent 在数学推理的持续预训练任务中，实现了比强基线模型更优的平衡性能。此外，该方法在未见过的源域、目标模型和域空间上表现出良好的泛化能力，无需重新训练。直接应用于代码生成领域也证明了其跨目标域的适应性。

Conclusion: Data Mixing Agent 是一种新颖的、基于模型的、端到端的框架，它通过强化学习学会了对域进行重新加权，从而在持续预训练任务中实现了跨源域和目标域的平衡性能。该方法在数学推理和代码生成任务中表现优于现有基线，并且具有良好的泛化能力，无需重新训练即可应用于新的领域、模型和域空间。此外，实验表明该方法学习到的启发式规则与人类直觉一致，并且能用更少的源域数据实现卓越的模型性能。

Abstract: Continual pre-training on small-scale task-specific data is an effective
method for improving large language models in new target fields, yet it risks
catastrophic forgetting of their original capabilities. A common solution is to
re-weight training data mixtures from source and target fields on a domain
space to achieve balanced performance. Previous domain reweighting strategies
rely on manual designation with certain heuristics based on human intuition or
empirical results. In this work, we prove that more general heuristics can be
parameterized by proposing Data Mixing Agent, the first model-based, end-to-end
framework that learns to re-weight domains. The agent learns generalizable
heuristics through reinforcement learning on large quantities of data mixing
trajectories with corresponding feedback from an evaluation environment.
Experiments in continual pre-training on math reasoning show that Data Mixing
Agent outperforms strong baselines in achieving balanced performance across
source and target field benchmarks. Furthermore, it generalizes well across
unseen source fields, target models, and domain spaces without retraining.
Direct application to the code generation field also indicates its adaptability
across target domains. Further analysis showcases the agents' well-aligned
heuristics with human intuitions and their efficiency in achieving superior
model performance with less source-field data.

</details>


### [356] [An Investigation of Test-time Adaptation for Audio Classification under Background Noise](https://arxiv.org/abs/2507.15523)
*Weichuang Shao,Iman Yi Liao,Tomas Henrique Bode Maul,Tissa Chandesa*

Main category: cs.LG

TL;DR: 本研究首次将TTA技术应用于领域偏移下的音频分类，并提出了一种改进的CoNMix方法，在不同噪声条件下均优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 领域偏移是深度学习中的一个突出问题，它会导致在源数据集上预训练的模型在测试数据集上出现显著的性能下降。本研究旨在通过测试时域适应（TTA）来解决由背景噪声引起的领域偏移下的音频分类问题。

Method: 本研究采用TTT、TENT和CoNMix两种常见的测试时域适应（TTA）方法，并对CoNMix进行了修改，以解决由背景噪声引起的领域偏移问题。

Result: 实验结果表明，我们提出的修改版CoNMix在领域偏移下产生了最高的分类准确率。

Conclusion: 研究表明，我们提出的修改版CoNMix在领域偏移下具有最高的分类准确率，在AM数据集的10dB运动自行车背景噪声下错误率为5.31%，在3dB跑步水龙头背景噪声下错误率为12.75%，优于TTT和TENT。

Abstract: Domain shift is a prominent problem in Deep Learning, causing a model
pre-trained on a source dataset to suffer significant performance degradation
on test datasets. This research aims to address the issue of audio
classification under domain shift caused by background noise using Test-Time
Adaptation (TTA), a technique that adapts a pre-trained model during testing
using only unlabelled test data before making predictions. We adopt two common
TTA methods, TTT and TENT, and a state-of-the-art method CoNMix, and
investigate their respective performance on two popular audio classification
datasets, AudioMNIST (AM) and SpeechCommands V1 (SC), against different types
of background noise and noise severity levels. The experimental results reveal
that our proposed modified version of CoNMix produced the highest
classification accuracy under domain shift (5.31% error rate under 10 dB
exercise bike background noise and 12.75% error rate under 3 dB running tap
background noise for AM) compared to TTT and TENT. The literature search
provided no evidence of similar works, thereby motivating the work reported
here as the first study to leverage TTA techniques for audio classification
under domain shift.

</details>


### [357] [Data Aware Differentiable Neural Architecture Search for Tiny Keyword Spotting Applications](https://arxiv.org/abs/2507.15545)
*Yujia Shi,Emil Njor,Pablo Martínez-Nuevo,Sven Ewan Shepstone,Xenofon Fafoutis*

Main category: cs.LG

TL;DR: 为了简化TinyML系统的设计，我们提出了一种新的方法，该方法可以同时优化模型架构和输入数据，从而为TinyML应用创建高效且准确的系统。


<details>
  <summary>Details</summary>
Motivation: 机器学习的资源占用显著，这激发了对TinyML等高效范例的兴趣，但TinyML系统的设计复杂性阻碍了其广泛应用。

Method: 我们引入了一种名为“数据感知可微分神经架构搜索”的方法，该方法将数据配置参数与架构选择相结合，以扩展搜索空间。

Result: 在关键词识别方面的初步结果表明，这种新颖的TinyML系统设计方法能够生成精简但高度准确的系统。

Conclusion: 所提出的新颖方法能够为TinyML应用生成精简但高度准确的系统。

Abstract: The success of Machine Learning is increasingly tempered by its significant
resource footprint, driving interest in efficient paradigms like TinyML.
However, the inherent complexity of designing TinyML systems hampers their
broad adoption. To reduce this complexity, we introduce "Data Aware
Differentiable Neural Architecture Search". Unlike conventional Differentiable
Neural Architecture Search, our approach expands the search space to include
data configuration parameters alongside architectural choices. This enables
Data Aware Differentiable Neural Architecture Search to co-optimize model
architecture and input data characteristics, effectively balancing resource
usage and system performance for TinyML applications. Initial results on
keyword spotting demonstrate that this novel approach to TinyML system design
can generate lean but highly accurate systems.

</details>


### [358] [The added value for MRI radiomics and deep-learning for glioblastoma prognostication compared to clinical and molecular information](https://arxiv.org/abs/2507.15548)
*D. Abler,O. Pusterla,A. Joye-Kühnis,N. Andratschke,M. Bach,A. Bink,S. M. Christ,P. Hagmann,B. Pouymayou,E. Pravatà,P. Radojewski,M. Reyes,L. Ruinelli,R. Schaer,B. Stieltjes,G. Treglia,W. Valenzuela,R. Wiest,S. Zoergiebel,M. Guckenberger,S. Tanadini-Lang,A. Depeursinge*

Main category: cs.LG

TL;DR: 影像组学对预测胶质母细胞瘤预后价值有限。


<details>
  <summary>Details</summary>
Motivation: 本研究旨在评估常规影像组学（CR）和深度学习（DL）MRI影像组学在预测胶质母细胞瘤预后（生存期≤6个月 vs >6个月）方面的附加价值，并与临床和分子预测因子进行比较。

Method: 本研究采用回顾性分析方法，纳入了来自瑞士五个中心和一公开数据源的1152名胶质母细胞瘤（WHO 2016）患者。研究使用常规影像组学（CR）和深度学习（DL）模型，并结合临床（年龄、性别）、分子（MGMT、IDH）和基线MRI数据（T1、T1对比、FLAIR、T2）进行训练和评估。模型在内部和外部队列中进行了验证，并进行了亚组分析，评估了不同特征集（仅影像、仅临床/分子、组合特征）和患者子集（S-1：所有患者，S-2：具有分子数据者，S-3：IDH野生型）的模型表现。

Result: 在外部验证中，结合特征的CR模型取得了0.75的AUC，略高于仅临床特征（0.74）和仅影像特征（0.68）的模型，但具有统计学显著性。DL模型显示出相似的趋势，但无统计学显著性。在S-2和S-3亚组中，组合模型并未优于仅临床模型。探索性分析表明，影像数据在预测总生存期方面具有更大的相关性：在所有亚组中，组合特征模型显著优于仅临床模型，但C-index仅提高了2-4个点。

Conclusion: 本研究证实了MRI解剖序列在预测胶质母细胞瘤预后中的价值，但标准CR和DL影像组学方法相比年龄和性别等人口统计学预测因子，仅提供了微小的附加价值。

Abstract: Background: Radiomics shows promise in characterizing glioblastoma, but its
added value over clinical and molecular predictors has yet to be proven. This
study assessed the added value of conventional radiomics (CR) and deep learning
(DL) MRI radiomics for glioblastoma prognosis (<= 6 vs > 6 months survival) on
a large multi-center dataset.
  Methods: After patient selection, our curated dataset gathers 1152
glioblastoma (WHO 2016) patients from five Swiss centers and one public source.
It included clinical (age, gender), molecular (MGMT, IDH), and baseline MRI
data (T1, T1 contrast, FLAIR, T2) with tumor regions. CR and DL models were
developed using standard methods and evaluated on internal and external
cohorts. Sub-analyses assessed models with different feature sets
(imaging-only, clinical/molecular-only, combined-features) and patient subsets
(S-1: all patients, S-2: with molecular data, S-3: IDH wildtype).
  Results: The best performance was observed in the full cohort (S-1). In
external validation, the combined-feature CR model achieved an AUC of 0.75,
slightly, but significantly outperforming clinical-only (0.74) and imaging-only
(0.68) models. DL models showed similar trends, though without statistical
significance. In S-2 and S-3, combined models did not outperform clinical-only
models. Exploratory analysis of CR models for overall survival prediction
suggested greater relevance of imaging data: across all subsets,
combined-feature models significantly outperformed clinical-only models, though
with a modest advantage of 2-4 C-index points.
  Conclusions: While confirming the predictive value of anatomical MRI
sequences for glioblastoma prognosis, this multi-center study found standard CR
and DL radiomics approaches offer minimal added value over demographic
predictors such as age and gender.

</details>


### [359] [Small LLMs Do Not Learn a Generalizable Theory of Mind via Reinforcement Learning](https://arxiv.org/abs/2507.15788)
*Sneheel Sarangi,Hanan Salam*

Main category: cs.LG

TL;DR: 小型LLM通过RLVR学习ToM存在过拟合问题，无法泛化到新任务。


<details>
  <summary>Details</summary>
Motivation: 探索是否可以通过强化学习（RL）等方法，在LLM中培养类似人类的心智理论（ToM）的社交智能。

Method: 通过在各种ToM数据集（HiToM、ExploreToM、FANToM）上训练模型，并测试其在未见过的数据集（如OpenToM）上的泛化能力，来系统地评估RLVR的效果。

Result: 小型LLM在ToM任务上表现出狭隘的过拟合，仅在训练数据集上表现出性能提升，但无法泛化到不同特征的未见过ToM任务上。

Conclusion: 小型语言模型（LLM）难以通过强化学习与可验证奖励（RLVR）获得稳健且可泛化的心智理论（ToM）能力。

Abstract: Recent advancements in large language models (LLMs) have demonstrated
emergent capabilities in complex reasoning, largely spurred by rule-based
Reinforcement Learning (RL) techniques applied during the post-training. This
has raised the question of whether similar methods can instill more nuanced,
human-like social intelligence, such as a Theory of Mind (ToM), in LLMs. This
paper investigates whether small-scale LLMs can acquire a robust and
generalizable ToM capability through RL with verifiable rewards (RLVR). We
conduct a systematic evaluation by training models on various combinations of
prominent ToM datasets (HiToM, ExploreToM, FANToM) and testing for
generalization on held-out datasets (e.g., OpenToM). Our findings indicate that
small LLMs struggle to develop a generic ToM capability. While performance on
in-distribution tasks improves, this capability fails to transfer to unseen ToM
tasks with different characteristics. Furthermore, we demonstrate that
prolonged RL training leads to models ``hacking'' the statistical patterns of
the training datasets, resulting in significant performance gains on in-domain
data but no change, or degradation of performance on out-of-distribution tasks.
This suggests the learned behavior is a form of narrow overfitting rather than
the acquisition of a true, abstract ToM capability.

</details>


### [360] [PhysGym: Benchmarking LLMs in Interactive Physics Discovery with Controlled Priors](https://arxiv.org/abs/2507.15550)
*Yimeng Chen,Piotr Piȩkos,Mateusz Ostaszewski,Firas Laakom,Jürgen Schmidhuber*

Main category: cs.LG

TL;DR: 介绍了一个名为PhysGym的基准套件和模拟平台，用于评估LLM在物理环境中的科学推理能力，该平台能控制先验知识和任务复杂度，并已通过基线LLM的测试展示了其有效性。


<details>
  <summary>Details</summary>
Motivation: 评估大型语言模型（LLM）在科学发现方面的能力，特别是在处理不同复杂性的环境和利用先验知识方面的能力，需要专门的基准，而现有基准存在不足。因此，需要一个能够严格评估LLM在交互式物理环境中科学推理能力的基准。

Method: 介绍了一个名为PhysGym的新颖基准套件和模拟平台，该平台包含一系列交互式模拟，用于评估LLM在物理环境中的科学推理能力。PhysGym允许研究人员控制提供给LLM的先验知识水平，并能评估LLM在数据收集、约束条件下的顺序数据收集以及假设形成等方面的能力。

Result: 通过对基线LLM进行测试，展示了PhysGym区分不同先验知识和任务复杂度下的LLM能力的有效性。

Conclusion: PhysGym作为一个新颖的基准套件和模拟平台，能够严格评估基于LLM的科学推理能力，并能通过控制先验知识的水平来区分不同LLM在不同任务复杂性下的能力。

Abstract: Evaluating the scientific discovery capabilities of large language model
based agents, particularly how they cope with varying environmental complexity
and utilize prior knowledge, requires specialized benchmarks currently lacking
in the landscape. To address this gap, we introduce PhysGym, a novel benchmark
suite and simulation platform for rigorously assessing LLM-based scientific
reasoning in interactive physics environments. PhysGym's primary contribution
lies in its sophisticated control over the level of prior knowledge provided to
the agent. This allows researchers to dissect agent performance along axes
including the complexity of the problem and the prior knowledge levels. The
benchmark comprises a suite of interactive simulations, where agents must
actively probe environments, gather data sequentially under constraints and
formulate hypotheses about underlying physical laws. PhysGym provides
standardized evaluation protocols and metrics for assessing hypothesis accuracy
and model fidelity. We demonstrate the benchmark's utility by presenting
results from baseline LLMs, showcasing its ability to differentiate
capabilities based on varying priors and task complexity.

</details>


### [361] [Trade-offs between elective surgery rescheduling and length-of-stay prediction accuracy](https://arxiv.org/abs/2507.15566)
*Pieter Smet,Martina Doneda,Ettore Lanzarone,Giuliana Carello*

Main category: cs.LG

TL;DR: Patient LOS prediction accuracy impacts hospital bed planning. This paper studies how rescheduling flexibility and prediction accuracy affect bed overflow prevention and resource optimization.


<details>
  <summary>Details</summary>
Motivation: The motivation is to address infeasibilities in patient admission planning caused by differences between predicted and actual patient Length-of-Stay (LOS), which can make schedules unfeasible and impact bed availability.

Method: The paper uses simulated ML for evaluating data-driven approaches and explores the relationship between LOS prediction accuracy and rescheduling flexibility across various corrective policies.

Result: The paper examines the most effective patient rescheduling strategies under LOS prediction errors to prevent bed overflows while optimizing resource utilization.

Conclusion: The paper explores the relationship between LOS prediction accuracy and rescheduling flexibility across various corrective policies, examining the most effective patient rescheduling strategies under LOS prediction errors to prevent bed overflows while optimizing resource utilization.

Abstract: The availability of downstream resources plays a critical role in planning
the admission of patients undergoing elective surgery, with inpatient beds
being one of the most crucial resources. When planning patient admissions,
predictions on their length-of-stay (LOS) made by machine learning (ML) models
are used to ensure bed availability. However, the actual LOS for each patient
may differ considerably from the predicted value, potentially making the
schedule infeasible. To address such infeasibilities, rescheduling strategies
that take advantage of operational flexibility can be implemented. For example,
adjustments may include postponing admission dates, relocating patients to
different wards, or even transferring patients who are already admitted. The
common assumption is that more accurate LOS predictions reduce the impact of
rescheduling. However, training ML models that can make such accurate
predictions can be costly. Building on previous work that proposed simulated
\ac{ml} for evaluating data-driven approaches, this paper explores the
relationship between LOS prediction accuracy and rescheduling flexibility
across various corrective policies. Specifically, we examine the most effective
patient rescheduling strategies under LOS prediction errors to prevent bed
overflows while optimizing resource utilization.

</details>


### [362] [GUI-G$^2$: Gaussian Reward Modeling for GUI Grounding](https://arxiv.org/abs/2507.15846)
*Fei Tang,Zhangxuan Gu,Zhengxi Lu,Xuyang Liu,Shuheng Shen,Changhua Meng,Wen Wang,Wenqi Zhang,Yongliang Shen,Weiming Lu,Jun Xiao,Yueting Zhuang*

Main category: cs.LG

TL;DR: 提出 GUI-G$^2$ 奖励框架，将 GUI 元素建模为高斯分布，实现更精确、鲁棒的空间定位，显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 当前强化学习方法使用二元奖励，将元素视为命中或未命中目标，产生的信号稀疏且忽略了空间交互的连续性。这与人类点击行为（自然形成以目标元素为中心的がウス分布）不同。

Method: 提出了一种名为 GUI-G$^2$（GUI Gaussian Grounding Rewards）的原则性奖励框架，该框架将 GUI 元素建模为跨界面平面的连续高斯分布。GUI-G$^2$ 包含两个机制：高斯点奖励通过以元素质心为中心呈指数衰减的分布来模拟精确的定位；覆盖奖励通过测量预测的高斯分布与目标区域的重叠来评估空间对齐。为了处理各种元素尺度，开发了一种自适应方差机制，根据元素维度校准奖励分布。

Result: GUI-G$^2$ 在 ScreenSpot、ScreenSpot-v2 和 ScreenSpot-Pro 基准测试中，相比 UI-TARS-72B 有显著提升，在 ScreenSpot-Pro 上提升高达 24.7%。分析表明，连续建模提供了更优越的界面变化鲁棒性和对未见布局的泛化能力。

Conclusion: GUI-G$^2$ 将 GUI grounding 从稀疏的二元分类转化为密集的连续优化，通过高斯分布产生丰富的梯度信号来指导模型达到最佳交互位置。实验证明 GUI-G$^2$ 在 ScreenSpot、ScreenSpot-v2 和 ScreenSpot-Pro 基准测试中显著优于最先进的方法 UI-TARS-72B，在 ScreenSpot-Pro 上提升高达 24.7%。此外，连续建模在应对界面变化和泛化到未见布局方面表现出更强的鲁棒性和优越性，为 GUI 交互任务中的空间推理建立了新范例。

Abstract: Graphical User Interface (GUI) grounding maps natural language instructions
to precise interface locations for autonomous interaction. Current
reinforcement learning approaches use binary rewards that treat elements as
hit-or-miss targets, creating sparse signals that ignore the continuous nature
of spatial interactions. Motivated by human clicking behavior that naturally
forms Gaussian distributions centered on target elements, we introduce GUI
Gaussian Grounding Rewards (GUI-G$^2$), a principled reward framework that
models GUI elements as continuous Gaussian distributions across the interface
plane. GUI-G$^2$ incorporates two synergistic mechanisms: Gaussian point
rewards model precise localization through exponentially decaying distributions
centered on element centroids, while coverage rewards assess spatial alignment
by measuring the overlap between predicted Gaussian distributions and target
regions. To handle diverse element scales, we develop an adaptive variance
mechanism that calibrates reward distributions based on element dimensions.
This framework transforms GUI grounding from sparse binary classification to
dense continuous optimization, where Gaussian distributions generate rich
gradient signals that guide models toward optimal interaction positions.
Extensive experiments across ScreenSpot, ScreenSpot-v2, and ScreenSpot-Pro
benchmarks demonstrate that GUI-G$^2$, substantially outperforms
state-of-the-art method UI-TARS-72B, with the most significant improvement of
24.7% on ScreenSpot-Pro. Our analysis reveals that continuous modeling provides
superior robustness to interface variations and enhanced generalization to
unseen layouts, establishing a new paradigm for spatial reasoning in GUI
interaction tasks.

</details>


### [363] [On the Role of AI in Managing Satellite Constellations: Insights from the ConstellAI Project](https://arxiv.org/abs/2507.15574)
*Gregory F. Stock,Juan A. Fraire,Holger Hermanns,Jędrzej Mosiężny,Yusra Al-Khazraji,Julio Ramírez Molina,Evridiki V. Ntagiou*

Main category: cs.LG

TL;DR: AI, specifically Reinforcement Learning, is shown to be effective in optimizing satellite mega-constellation operations for data routing and resource allocation, outperforming traditional methods and offering better scalability and flexibility.


<details>
  <summary>Details</summary>
Motivation: The rapid expansion of satellite constellations necessitates innovative approaches for efficient, scalable, and resilient network management, addressing challenges in operations.

Method: Reinforcement Learning (RL) algorithms were developed and tested for data routing (optimizing end-to-end latency using historical queuing latency data) and resource allocation (optimizing task scheduling for battery and memory), comparing their performance against classical algorithms.

Result: RL-based approaches demonstrated improved performance over classical methods in both data routing and resource allocation use cases, showing greater flexibility, scalability, and generalizability.

Conclusion: AI, particularly RL, offers enhanced flexibility, scalability, and generalizability for autonomous satellite fleet management, outperforming traditional methods in data routing and resource allocation.

Abstract: The rapid expansion of satellite constellations in near-Earth orbits presents
significant challenges in satellite network management, requiring innovative
approaches for efficient, scalable, and resilient operations. This paper
explores the role of Artificial Intelligence (AI) in optimizing the operation
of satellite mega-constellations, drawing from the ConstellAI project funded by
the European Space Agency (ESA). A consortium comprising GMV GmbH, Saarland
University, and Thales Alenia Space collaborates to develop AI-driven
algorithms and demonstrates their effectiveness over traditional methods for
two crucial operational challenges: data routing and resource allocation. In
the routing use case, Reinforcement Learning (RL) is used to improve the
end-to-end latency by learning from historical queuing latency, outperforming
classical shortest path algorithms. For resource allocation, RL optimizes the
scheduling of tasks across constellations, focussing on efficiently using
limited resources such as battery and memory. Both use cases were tested for
multiple satellite constellation configurations and operational scenarios,
resembling the real-life spacecraft operations of communications and Earth
observation satellites. This research demonstrates that RL not only competes
with classical approaches but also offers enhanced flexibility, scalability,
and generalizability in decision-making processes, which is crucial for the
autonomous and intelligent management of satellite fleets. The findings of this
activity suggest that AI can fundamentally alter the landscape of satellite
constellation management by providing more adaptive, robust, and cost-effective
solutions.

</details>


### [364] [We Need to Rethink Benchmarking in Anomaly Detection](https://arxiv.org/abs/2507.15584)
*Philipp Röchner,Simon Klüttermann,Franz Rothlauf,Daniel Schlör*

Main category: cs.LG

TL;DR: 当前异常检测的评估方法存在不足，应改进评估方法以反映异常的多样性，并对异常检测管道进行综合分析。


<details>
  <summary>Details</summary>
Motivation: 当前异常检测算法的评估方法存在局限性，未能充分反映实际应用中的异常多样性，导致新算法与基线性能差异微小，研究进展停滞不前。

Method: 提出应根据常见分类法识别异常检测场景，对异常检测管道进行端到端和按组件的分析，并确保评估方法对场景目标有意义。

Result: 文章认为，通过改进评估方法，可以推动异常检测领域的研究进展。

Conclusion: 应根据场景目标评估异常检测算法，并对异常检测管道进行端到端和按组件的分析。

Abstract: Despite the continuous proposal of new anomaly detection algorithms and
extensive benchmarking efforts, progress seems to stagnate, with only minor
performance differences between established baselines and new algorithms. In
this position paper, we argue that this stagnation is due to limitations in how
we evaluate anomaly detection algorithms. Current benchmarking does not, for
example, sufficiently reflect the diversity of anomalies in applications
ranging from predictive maintenance to scientific discovery. Consequently, we
need to rethink benchmarking in anomaly detection. In our opinion, anomaly
detection should be studied using scenarios that capture the relevant
characteristics of different applications. We identify three key areas for
improvement: First, we need to identify anomaly detection scenarios based on a
common taxonomy. Second, anomaly detection pipelines should be analyzed
end-to-end and by component. Third, evaluating anomaly detection algorithms
should be meaningful regarding the scenario's objectives.

</details>


### [365] [Red-Team Multi-Agent Reinforcement Learning for Emergency Braking Scenario](https://arxiv.org/abs/2507.15587)
*Yinsong Chen,Kaifeng Wang,Xiaoqiang Meng,Xueyuan Li,Zirui Li,Xin Gao*

Main category: cs.LG

TL;DR: 通过引入红队智能体进行主动干扰和探索，该框架能够生成现实世界中的边缘案例，以提高自动驾驶汽车的决策安全性。


<details>
  <summary>Details</summary>
Motivation: 为了解决当前研究依赖低效的数据驱动场景生成或特定建模方法，无法捕捉现实世界中的边缘案例的问题。

Method: 提出了一种红队多智能体强化学习框架，其中具有干扰能力的背景车辆被视为红队智能体。该框架使用约束图表示马尔可夫决策过程，并构建了一个策略威胁区域模型。

Result: 实验结果表明，该框架显著影响了自动驾驶汽车（AVs）的决策安全性，并生成了各种边缘案例。

Conclusion: 该框架为安全关键场景的研究提供了新的方向，并能生成各种边缘案例。

Abstract: Current research on decision-making in safety-critical scenarios often relies
on inefficient data-driven scenario generation or specific modeling approaches,
which fail to capture corner cases in real-world contexts. To address this
issue, we propose a Red-Team Multi-Agent Reinforcement Learning framework,
where background vehicles with interference capabilities are treated as
red-team agents. Through active interference and exploration, red-team vehicles
can uncover corner cases outside the data distribution. The framework uses a
Constraint Graph Representation Markov Decision Process, ensuring that red-team
vehicles comply with safety rules while continuously disrupting the autonomous
vehicles (AVs). A policy threat zone model is constructed to quantify the
threat posed by red-team vehicles to AVs, inducing more extreme actions to
increase the danger level of the scenario. Experimental results show that the
proposed framework significantly impacts AVs decision-making safety and
generates various corner cases. This method also offers a novel direction for
research in safety-critical scenarios.

</details>


### [366] [Accelerating HEC-RAS: A Recurrent Neural Operator for Rapid River Forecasting](https://arxiv.org/abs/2507.15614)
*Edward Holmberg,Pujan Pokhrel,Maximilian Zoch,Elias Ioup,Ken Pathak,Steven Sloan,Kendall Niles,Jay Ratcliff,Maik Flanagin,Christian Guetl,Julian Simeonov,Mahdi Abdelguerfi*

Main category: cs.LG

TL;DR: 该研究提出了一种利用深度学习（GRU和Geo-FNO）的混合模型，以加速HEC-RAS河流模拟。该模型通过从HEC-RAS文件中提取的特征进行训练，将计算时间缩短了近3.5倍，同时保持了高预测精度，使其成为大规模洪水预报的实用替代方案。


<details>
  <summary>Details</summary>
Motivation: HEC-RAS等基于物理的求解器提供高保真度河流预报，但在洪水事件期间的即时决策方面，其计算量过大。核心挑战在于在不牺牲准确性的情况下加速这些模拟。

Method: 提出了一种混合的、自回归的架构，该架构结合了门控循环单元（GRU）来捕获短期时间动态，以及几何感知傅立叶神经网络（Geo-FNO）来模拟沿河流的远程空间依赖性。该模型从直接从本地HEC-RAS文件中提取的动态状态、静态几何和边界强迫的最小八通道特征向量中隐式地学习底层物理。

Result: 该模型实现了强大的预测准确性，中位数绝对水位误差为0.31英尺。关键的是，对于完整的67个河段集合预报，我们的模拟器将所需的挂钟时间从139分钟减少到40分钟，速度比传统求解器快了近3.5倍。

Conclusion: 该数据驱动的方法表明，可靠的特征工程可以产生一种可行的高速替代传统水力模型的方法，从而提高了大规模集合洪水预报的计算可行性。

Abstract: Physics-based solvers like HEC-RAS provide high-fidelity river forecasts but
are too computationally intensive for on-the-fly decision-making during flood
events. The central challenge is to accelerate these simulations without
sacrificing accuracy. This paper introduces a deep learning surrogate that
treats HEC-RAS not as a solver but as a data-generation engine. We propose a
hybrid, auto-regressive architecture that combines a Gated Recurrent Unit (GRU)
to capture short-term temporal dynamics with a Geometry-Aware Fourier Neural
Operator (Geo-FNO) to model long-range spatial dependencies along a river
reach. The model learns underlying physics implicitly from a minimal
eight-channel feature vector encoding dynamic state, static geometry, and
boundary forcings extracted directly from native HEC-RAS files. Trained on 67
reaches of the Mississippi River Basin, the surrogate was evaluated on a
year-long, unseen hold-out simulation. Results show the model achieves a strong
predictive accuracy, with a median absolute stage error of 0.31 feet.
Critically, for a full 67-reach ensemble forecast, our surrogate reduces the
required wall-clock time from 139 minutes to 40 minutes, a speedup of nearly
3.5 times over the traditional solver. The success of this data-driven approach
demonstrates that robust feature engineering can produce a viable, high-speed
replacement for conventional hydraulic models, improving the computational
feasibility of large-scale ensemble flood forecasting.

</details>


### [367] [Towards Explainable Anomaly Detection in Shared Mobility Systems](https://arxiv.org/abs/2507.15643)
*Elnur Isgandarov,Matteo Cederle,Federico Chiariotti,Gian Antonio Susto*

Main category: cs.LG

TL;DR: 本研究提出了一种基于多源数据和隔离森林/DIFFI算法的可解释异常检测框架，用于识别共享单车系统中的异常，并分析了外部因素的影响。


<details>
  <summary>Details</summary>
Motivation: 共享单车系统作为城市交通的重要组成部分，识别其异常对于优化运营、提高服务可靠性和改善用户体验至关重要。

Method: 本研究提出了一种集成多源数据（包括单车共享行程记录、天气状况和公共交通可用性）的可解释异常检测框架。该框架使用隔离森林算法进行无监督异常检测，并利用基于深度的隔离森林特征重要性（DIFFI）算法来提供可解释性。

Result: 研究结果表明，基于站点级别的分析能够提供对异常的稳健理解，突显了诸如恶劣天气和公共交通可用性受限等外部因素对异常的影响。

Conclusion: 该研究提出的可解释异常检测框架，通过整合多源数据并结合隔离森林和DIFFI算法，能够有效识别共享单车系统中的异常，并揭示外部因素（如恶劣天气和公共交通可用性受限）对异常的影响，有助于提升共享出行的运营决策水平。

Abstract: Shared mobility systems, such as bike-sharing networks, play a crucial role
in urban transportation. Identifying anomalies in these systems is essential
for optimizing operations, improving service reliability, and enhancing user
experience. This paper presents an interpretable anomaly detection framework
that integrates multi-source data, including bike-sharing trip records, weather
conditions, and public transit availability. The Isolation Forest algorithm is
employed for unsupervised anomaly detection, along with the Depth-based
Isolation Forest Feature Importance (DIFFI) algorithm providing
interpretability. Results show that station-level analysis offers a robust
understanding of anomalies, highlighting the influence of external factors such
as adverse weather and limited transit availability. Our findings contribute to
improving decision-making in shared mobility operations.

</details>


### [368] [GeoHNNs: Geometric Hamiltonian Neural Networks](https://arxiv.org/abs/2507.15678)
*Amine Mohamed Aboussalah,Abdessalam Ed-dib*

Main category: cs.LG

TL;DR: GeoHNN是一种新的深度学习框架，它通过整合物理学的几何原理来学习动态系统。与现有方法相比，它在保持长期稳定性、准确性和能量守恒方面表现更好，证明了将物理几何嵌入到模型中的实际优势。


<details>
  <summary>Details</summary>
Motivation: 现有的机器学习方法通常会忽略物理学的基本几何结构，可能导致物理学原理的违反，尤其是在处理高维和混沌系统时，预测会长期不稳定。

Method: 提出了一种名为几何哈密顿神经网络（GeoHNN）的框架，该框架通过在对称正定矩阵的自然数学空间中参数化惯性矩阵来强制执行惯性流形，并通过使用约束自编码器来确保缩减的潜在空间中的相空间体积守恒，来强制执行相空间的辛几何。

Result: GeoHNN在从耦合振荡器到高维可变形物体等各种系统的实验中，表现出优于现有模型的性能，提高了长期稳定性、准确性和能量守恒。

Conclusion: GeoHNN框架通过显式编码物理定律固有的几何先验，在学习动力学方面表现出色，显著优于现有模型，并在长期稳定性、准确性和能量守恒方面取得了更好的结果。

Abstract: The fundamental laws of physics are intrinsically geometric, dictating the
evolution of systems through principles of symmetry and conservation. While
modern machine learning offers powerful tools for modeling complex dynamics
from data, common methods often ignore this underlying geometric fabric.
Physics-informed neural networks, for instance, can violate fundamental
physical principles, leading to predictions that are unstable over long
periods, particularly for high-dimensional and chaotic systems. Here, we
introduce \textit{Geometric Hamiltonian Neural Networks (GeoHNN)}, a framework
that learns dynamics by explicitly encoding the geometric priors inherent to
physical laws. Our approach enforces two fundamental structures: the Riemannian
geometry of inertia, by parameterizing inertia matrices in their natural
mathematical space of symmetric positive-definite matrices, and the symplectic
geometry of phase space, using a constrained autoencoder to ensure the
preservation of phase space volume in a reduced latent space. We demonstrate
through experiments on systems ranging from coupled oscillators to
high-dimensional deformable objects that GeoHNN significantly outperforms
existing models. It achieves superior long-term stability, accuracy, and energy
conservation, confirming that embedding the geometry of physics is not just a
theoretical appeal but a practical necessity for creating robust and
generalizable models of the physical world.

</details>


### [369] [Explainable Anomaly Detection for Electric Vehicles Charging Stations](https://arxiv.org/abs/2507.15718)
*Matteo Cederle,Andrea Mazzucco,Andrea Demartini,Eugenio Mazza,Eugenia Suriani,Federico Vitti,Gian Antonio Susto*

Main category: cs.LG

TL;DR: 本研究提出了一种结合了 Isolation Forest 和 DIFFI 的无监督异常检测方法，用于识别电动汽车充电站的异常并找出根本原因。


<details>
  <summary>Details</summary>
Motivation: 为了确保电动汽车充电站的可靠性和效率，需要有效的异常检测方法来识别充电行为中的异常，并确定异常背后的根本原因。

Method: 该研究应用 Isolation Forest 检测异常，并利用基于深度的 Isolation Forest 特征重要性 (DIFFI) 方法找出导致异常的最重要特征。

Result: 实验证明，该方法在真实工业案例中是有效的。

Conclusion: 通过集成可解释人工智能技术，研究提出了一种用于电动汽车充电基础设施的无监督异常检测方法，以识别充电行为中的异常并找出根本原因。

Abstract: Electric vehicles (EV) charging stations are one of the critical
infrastructures needed to support the transition to renewable-energy-based
mobility, but ensuring their reliability and efficiency requires effective
anomaly detection to identify irregularities in charging behavior. However, in
such a productive scenario, it is also crucial to determine the underlying
cause behind the detected anomalies. To achieve this goal, this study
investigates unsupervised anomaly detection techniques for EV charging
infrastructure, integrating eXplainable Artificial Intelligence techniques to
enhance interpretability and uncover root causes of anomalies.
  Using real-world sensors and charging session data, this work applies
Isolation Forest to detect anomalies and employs the Depth-based Isolation
Forest Feature Importance (DIFFI) method to identify the most important
features contributing to such anomalies. The efficacy of the proposed approach
is evaluated in a real industrial case.

</details>


### [370] [Multi-Modal Sensor Fusion for Proactive Blockage Prediction in mmWave Vehicular Networks](https://arxiv.org/abs/2507.15769)
*Ahmad M. Nazar,Abdulkadir Celik,Mohamed Y. Selim,Asmaa Abdallah,Daji Qiao,Ahmed M. Eltawil*

Main category: cs.LG

TL;DR: 为了解决车辆通信在毫米波频段中极易受到信号阻塞的挑战，我们提出了一个利用多模态传感（相机、GPS、LiDAR、雷达）的前瞻性阻塞预测框架，并证明了其有效性和效率。


<details>
  <summary>Details</summary>
Motivation: 为了解决车辆通信系统在毫米波（mmWave）频段中极易受到车辆、行人、基础设施等动态障碍物信号阻塞的挑战。

Method: 利用包括相机、GPS、LiDAR和雷达输入的传感器，在基础设施到车辆（I2V）设置中，使用特定模态的深度学习模型独立处理每个传感器流，并基于验证性能使用softmax加权集成策略融合它们的输出。

Result: 评估显示，仅使用相机的模型实现了最佳的独立权衡，F1分数达到97.1%，推理时间为89.8毫秒。相机+雷达配置将准确率提高到97.2% F1，推理时间为95.7毫秒，预测时间长达1.5秒。

Conclusion: 多模态传感对于毫米波（mmWave）阻塞预测的有效性和效率得到了证明，并为动态环境中的主动无线通信提供了途径。

Abstract: Vehicular communication systems operating in the millimeter wave (mmWave)
band are highly susceptible to signal blockage from dynamic obstacles such as
vehicles, pedestrians, and infrastructure. To address this challenge, we
propose a proactive blockage prediction framework that utilizes multi-modal
sensing, including camera, GPS, LiDAR, and radar inputs in an
infrastructure-to-vehicle (I2V) setting. This approach uses modality-specific
deep learning models to process each sensor stream independently and fuses
their outputs using a softmax-weighted ensemble strategy based on validation
performance. Our evaluations, for up to 1.5s in advance, show that the
camera-only model achieves the best standalone trade-off with an F1-score of
97.1% and an inference time of 89.8ms. A camera+radar configuration further
improves accuracy to 97.2% F1 at 95.7ms. Our results display the effectiveness
and efficiency of multi-modal sensing for mmWave blockage prediction and
provide a pathway for proactive wireless communication in dynamic environments.

</details>


### [371] [Deep-Learning Investigation of Vibrational Raman Spectra for Plant-Stress Analysis](https://arxiv.org/abs/2507.15772)
*Anoop C. Patil,Benny Jian Rong Sng,Yu-Wei Chang,Joana B. Pereira,Chua Nam-Hai,Rajani Sarojam,Gajendra Pratap Singh,In-Cheol Jang,Giovanni Volpe*

Main category: cs.LG

TL;DR: DIVA是一种基于深度学习的全自动化工作流程，用于无偏见地分析拉曼光谱以检测植物胁迫，无需手动预处理。


<details>
  <summary>Details</summary>
Motivation: 为了应对传统拉曼分析在处理荧光背景和手动识别拉曼峰时存在的潜在偏见和不一致性，需要一种更自动化、无偏见的方法来检测植物胁迫。

Method: 提出了一种名为DIVA（基于深度学习的植物胁迫振动拉曼光谱分析）的全自动化工作流程，该流程基于变分自编码器，可直接处理包含荧光背景的原始拉曼光谱，无需手动预处理，并以无偏见的方式识别和量化重要的光谱特征。

Result: DIVA成功应用于检测遮荫、高光强、高温等非生物胁迫以及细菌感染等生物胁迫。

Conclusion: DIVA通过结合深度学习和振动光谱，实现了对植物胁迫的自动化检测，为人工智能驱动的植物健康评估开辟了道路，有助于促进更具韧性和可持续性的农业实践。

Abstract: Detecting stress in plants is crucial for both open-farm and
controlled-environment agriculture. Biomolecules within plants serve as key
stress indicators, offering vital markers for continuous health monitoring and
early disease detection. Raman spectroscopy provides a powerful, non-invasive
means to quantify these biomolecules through their molecular vibrational
signatures. However, traditional Raman analysis relies on customized
data-processing workflows that require fluorescence background removal and
prior identification of Raman peaks of interest-introducing potential biases
and inconsistencies. Here, we introduce DIVA (Deep-learning-based Investigation
of Vibrational Raman spectra for plant-stress Analysis), a fully automated
workflow based on a variational autoencoder. Unlike conventional approaches,
DIVA processes native Raman spectra-including fluorescence backgrounds-without
manual preprocessing, identifying and quantifying significant spectral features
in an unbiased manner. We applied DIVA to detect a range of plant stresses,
including abiotic (shading, high light intensity, high temperature) and biotic
stressors (bacterial infections). By integrating deep learning with vibrational
spectroscopy, DIVA paves the way for AI-driven plant health assessment,
fostering more resilient and sustainable agricultural practices.

</details>


### [372] [Dynamics is what you need for time-series forecasting!](https://arxiv.org/abs/2507.15774)
*Alexis-Raja Brachet,Pierre-Yves Richard,Céline Hudelot*

Main category: cs.LG

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: While boundaries between data modalities are vanishing, the usual successful
deep models are still challenged by simple ones in the time-series forecasting
task. Our hypothesis is that this task needs models that are able to learn the
data underlying dynamics. We propose to validate it through both systemic and
empirical studies. We develop an original $\texttt{PRO-DYN}$ nomenclature to
analyze existing models through the lens of dynamics. Two observations thus
emerged: $\textbf{1}$. under-performing architectures learn dynamics at most
partially, $\textbf{2}$. the location of the dynamics block at the model end is
of prime importance. We conduct extensive experiments to confirm our
observations on a set of performance-varying models with diverse backbones.
Results support the need to incorporate a learnable dynamics block and its use
as the final predictor.

</details>


### [373] [Graph Attention Specialized Expert Fusion Model for Node Classification: Based on Cora and Pubmed Datasets](https://arxiv.org/abs/2507.15784)
*Zihang Ma,Qitian Yin*

Main category: cs.LG

TL;DR: 为了解决GNN节点分类中的类别不平衡问题，我们提出了WR-EFM模型，通过WR距离优化模型表示相似性和指导自适应融合，有效提升了类别2的性能并实现了跨类别的均衡准确率和稳定性。


<details>
  <summary>Details</summary>
Motivation: 图节点分类任务在GNN中是基础性的，但在PubMed数据集上观察到明显的分类难度差异，特别是类别2的准确率比类别1低7.5%。为了解决这种类别不平衡和性能差异问题，需要一种能够提升表现不佳类别并实现跨类别均衡的方法。

Method: 提出了一种结合Wasserstein-Rubinstein（WR）距离和专家融合（EFM）的模型（WR-EFM）。该模型为类别0/1训练了具有层归一化和残差连接的GNN模型，为类别2训练了多跳图注意力网络（GAT）模型。WR距离用于优化模型间的表示相似性，特别是提升类别2的性能。模型还采用了一种自适应融合策略，根据类别特定性能动态加权模型，并利用WR距离指导融合过程，以整合互补特征。

Result: WR-EFM在PubMed数据集上实现了跨类别的均衡准确率：类别0为77.8%，类别1为78.0%，类别2为79.9%。其准确率的变异系数（CV）为0.013，比GCN的0.058低77.6%，显示出更高的稳定性。与GCN相比，WR-EFM将类别2的准确率提高了5.5%，验证了WR距离指导融合在捕捉复杂结构模式方面的有效性。

Conclusion: 该研究提出了一种新的基于Wasserstein-Rubinstein（WR）距离的专家融合模型（WR-EFM），用于解决图神经网络（GNN）中节点分类任务的类别不平衡问题。实验结果表明，WR-EFM在PubMed数据集上实现了跨类别的均衡准确率，特别是将类别2的准确率提高了5.5%，并显著降低了准确率的变异系数，证明了其稳定性和有效性。该模型为处理类别不平衡的图分类任务提供了一个新范式。

Abstract: Graph node classification is a fundamental task in graph neural networks
(GNNs), aiming to assign predefined class labels to nodes. On the PubMed
citation network dataset, we observe significant classification difficulty
disparities, with Category 2 achieving only 74.4% accuracy in traditional GCN,
7.5% lower than Category 1. To address this, we propose a
Wasserstein-Rubinstein (WR) distance enhanced Expert Fusion Model (WR-EFM),
training specialized GNN models for Categories 0/1 (with layer normalization
and residual connections) and Multi-hop Graph Attention Networks (GAT) for
Category 2. The WR distance metric optimizes representation similarity between
models, particularly focusing on improving Category 2 performance. Our adaptive
fusion strategy dynamically weights models based on category-specific
performance, with Category 2 assigned a GAT weight of 0.8. WR distance further
guides the fusion process by measuring distributional differences between model
representations, enabling more principled integration of complementary
features.
  Experimental results show WR-EFM achieves balanced accuracy across
categories: 77.8% (Category 0), 78.0% (Category 1), and 79.9% (Category 2),
outperforming both single models and standard fusion approaches. The
coefficient of variation (CV) of WR-EFM's category accuracies is 0.013, 77.6%
lower than GCN's 0.058, demonstrating superior stability. Notably, WR-EFM
improves Category 2 accuracy by 5.5% compared to GCN, verifying the
effectiveness of WR-guided fusion in capturing complex structural patterns.
This work provides a novel paradigm for handling class-imbalanced graph
classification tasks. To promote the research community, we release our project
at https://github.com/s010m00n/GASEM4NC.

</details>


### [374] [Multi-Strategy Improved Snake Optimizer Accelerated CNN-LSTM-Attention-Adaboost for Trajectory Prediction](https://arxiv.org/abs/2507.15832)
*Shiyang Li*

Main category: cs.LG

TL;DR: 该研究提出了一种结合CNN、LSTM、注意力机制和Adaboost的混合模型，并使用改进的蛇群（SO）算法进行超参数优化，以提高中长期四维轨迹预测的精度。实验结果表明，该模型在处理大规模高维轨迹数据方面优于传统优化器，预测精度显著提升。


<details>
  <summary>Details</summary>
Motivation: 为了解决中长期四维（4D）轨迹预测模型的局限性。

Method: 提出了一种混合CNN-LSTM-attention-adaboost神经网络模型，并结合了多策略改进的蛇群（SO）优化算法。该模型使用Adaboost算法划分多个弱学习器，每个子模型利用CNN提取空间特征，LSTM捕获时间特征，注意力机制捕捉全局特征。强学习器模型与多个子模型结合，通过SO模拟的自然选择行为模式优化预测模型的超参数。

Result: 与传统的优化器（如粒子群、鲸鱼和灰狼）相比，SO-CLA-adaboost在处理大规模高维轨迹数据方面表现更优，预测精度提高了39.89%。

Conclusion: SO-CLA-adaboost 在处理大规模高维轨迹数据方面优于传统的粒子群、鲸鱼和灰狼优化器，并且通过改进的SO算法，模型预测精度提高了39.89%。

Abstract: To address the limitations of medium- and long-term four-dimensional (4D)
trajectory prediction models, this paper proposes a hybrid
CNN-LSTM-attention-adaboost neural network model incorporating a multi-strategy
improved snake-herd optimization (SO) algorithm. The model applies the Adaboost
algorithm to divide multiple weak learners, and each submodel utilizes CNN to
extract spatial features, LSTM to capture temporal features, and attention
mechanism to capture global features comprehensively. The strong learner model,
combined with multiple sub-models, then optimizes the hyperparameters of the
prediction model through the natural selection behavior pattern simulated by
SO. In this study, based on the real ADS-B data from Xi'an to Tianjin, the
comparison experiments and ablation studies of multiple optimizers are carried
out, and a comprehensive test and evaluation analysis is carried out. The
results show that SO-CLA-adaboost outperforms traditional optimizers such as
particle swarm, whale, and gray wolf in handling large-scale high-dimensional
trajectory data. In addition, introducing the full-strategy collaborative
improvement SO algorithm improves the model's prediction accuracy by 39.89%.

</details>


### [375] [Optimizing Canaries for Privacy Auditing with Metagradient Descent](https://arxiv.org/abs/2507.15836)
*Matteo Boglioni,Terrance Liu,Andrew Ilyas,Zhiwei Steven Wu*

Main category: cs.LG

TL;DR: 本研究提出一种通过优化“金丝雀”数据集来提高黑盒隐私审计（如下限差分隐私参数）的方法，相比传统方法，可将隐私审计的下限提高2倍以上，且该方法具有可转移性和效率。


<details>
  <summary>Details</summary>
Motivation: 为了在仅能获取学习算法输出的情况下，降低差分隐私学习算法的隐私参数的下限。

Method: 利用元梯度优化来选择“金丝雀”数据集，以提高差分隐私学习算法的隐私审计效果。

Result: 通过优化“金丝雀”数据集，在某些情况下将差分隐私图像分类模型的经验下限提高了2倍以上，并且该方法对于不同的模型和训练器（非隐私SGD和DP-SGD）都是有效的。

Conclusion: 优化用于差分隐私学习算法的“金丝雀”数据集可以提高隐私审计的下限，并且该方法具有可转移性和效率。

Abstract: In this work we study black-box privacy auditing, where the goal is to lower
bound the privacy parameter of a differentially private learning algorithm
using only the algorithm's outputs (i.e., final trained model). For DP-SGD (the
most successful method for training differentially private deep learning
models), the canonical approach auditing uses membership inference-an auditor
comes with a small set of special "canary" examples, inserts a random subset of
them into the training set, and then tries to discern which of their canaries
were included in the training set (typically via a membership inference
attack). The auditor's success rate then provides a lower bound on the privacy
parameters of the learning algorithm. Our main contribution is a method for
optimizing the auditor's canary set to improve privacy auditing, leveraging
recent work on metagradient optimization. Our empirical evaluation demonstrates
that by using such optimized canaries, we can improve empirical lower bounds
for differentially private image classification models by over 2x in certain
instances. Furthermore, we demonstrate that our method is transferable and
efficient: canaries optimized for non-private SGD with a small model
architecture remain effective when auditing larger models trained with DP-SGD.

</details>


### [376] [FASTGEN: Fast and Cost-Effective Synthetic Tabular Data Generation with LLMs](https://arxiv.org/abs/2507.15839)
*Anh Nguyen,Sam Schafft,Nicholas Hale,John Alfaro*

Main category: cs.LG

TL;DR: 提出一种快速、经济高效的表格数据合成方法，利用LLM将字段分布编码为可重用的采样脚本，以经济高效地大规模生成多样化、真实的数据集。


<details>
  <summary>Details</summary>
Motivation: 现有方法直接使用LLM单独生成每个记录，在需要大量合成数据时会带来高昂的时间和成本负担。

Method: 通过自动将字段分类为数值、分类或自由文本类型，利用LLM生成基于分布的脚本，从而高效地大规模生成多样化、真实的数据集，而无需持续的模型推理。

Result: 实验结果表明，该方法在多样性和数据真实性方面优于传统的直接方法，并显著降低了高容量合成数据生成的负担。

Conclusion: 该方法在多样性和数据真实性方面优于传统的直接方法，并显著降低了高容量合成数据生成的负担。

Abstract: Synthetic data generation has emerged as an invaluable solution in scenarios
where real-world data collection and usage are limited by cost and scarcity.
Large language models (LLMs) have demonstrated remarkable capabilities in
producing high-fidelity, domain-relevant samples across various fields.
However, existing approaches that directly use LLMs to generate each record
individually impose prohibitive time and cost burdens, particularly when large
volumes of synthetic data are required. In this work, we propose a fast,
cost-effective method for realistic tabular data synthesis that leverages LLMs
to infer and encode each field's distribution into a reusable sampling script.
By automatically classifying fields into numerical, categorical, or free-text
types, the LLM generates distribution-based scripts that can efficiently
produce diverse, realistic datasets at scale without continuous model
inference. Experimental results show that our approach outperforms traditional
direct methods in both diversity and data realism, substantially reducing the
burden of high-volume synthetic data generation. We plan to apply this
methodology to accelerate testing in production pipelines, thereby shortening
development cycles and improving overall system efficiency. We believe our
insights and lessons learned will aid researchers and practitioners seeking
scalable, cost-effective solutions for synthetic data generation.

</details>


<div id='cs.ET'></div>

# cs.ET [[Back]](#toc)

### [377] [Privacy-Preserving Drone Navigation Through Homomorphic Encryption for Collision Avoidance](https://arxiv.org/abs/2507.14713)
*Allan Luedeman,Nicholas Baum,Andrew Quijano,Kemal Akkaya*

Main category: cs.ET

TL;DR: 无人机路径规划：使用同态加密避免碰撞，同时保护隐私。


<details>
  <summary>Details</summary>
Motivation: 为了在无人机递送包裹时避免暴露商业隐私（例如，哪些商店向特定地址发送包裹）和路径信息，提出使用同态加密。

Method: 提出一种基于同态加密的比较方法来计算路径交叉点，使无人机能够识别潜在碰撞，而无需泄露路径和目的地细节。

Result: 该方法在资源受限的虚拟机上实现和测试，结果表明与基于乱码电路的方法相比，该方法速度更快，网络通信需求更少。

Conclusion: 所提出的基于同态加密的比较方法能够有效地在不泄露路径和目的地细节的情况下，让无人机识别潜在的碰撞。

Abstract: As drones increasingly deliver packages in neighborhoods, concerns about
collisions arise. One solution is to share flight paths within a specific zip
code, but this compromises business privacy by revealing delivery routes. For
example, it could disclose which stores send packages to certain addresses. To
avoid exposing path information, we propose using homomorphic encryption-based
comparison to compute path intersections. This allows drones to identify
potential collisions without revealing path and destination details, allowing
them to adjust altitude to avoid crashes. We implemented and tested our
approach on resource-limited virtual machines to mimic the computational power
of drones. Our results demonstrate that our method is significantly faster and
requires less network communication compared to a garbled circuit-based
approach. We also provide a security analysis of the approach against potential
attacks.

</details>


### [378] [Design of an Edge-based Portable EHR System for Anemia Screening in Remote Health Applications](https://arxiv.org/abs/2507.15146)
*Sebastian A. Cruz Romero,Misael J. Mercado Hernandez,Samir Y. Ali Rivera,Jorge A. Santiago Fernandez,Wilfredo E. Lugo Beauchamp*

Main category: cs.ET

TL;DR: 该研究提出了一种便携式、支持离线和边缘计算的电子健康记录系统，并集成了一个用于贫血筛查的 AI 模块，以解决资源匮乏地区医疗系统面临的挑战。


<details>
  <summary>Details</summary>
Motivation: 解决远程、资源受限环境中医疗系统在互操作性差、缺乏离线支持和依赖昂贵基础设施方面的挑战，现有数字健康解决方案未能满足服务欠缺地区一线医护人员的需求。

Method: 提出了一种便携式、边缘计算的电子健康记录平台，该平台针对离线优先操作、安全患者数据管理和模块化诊断集成进行了优化。在小型嵌入式设备上运行，提供 AES-256 加密本地存储和可选的云同步。集成了利用指甲苍白分析的无创贫血筛查模块，并使用量化 YOLOv8n 模型优化性能。

Result: 随机森林模型在贫血筛查任务上取得了 1.969 g/dL 的测试 RMSE 和 1.490 g/dL 的 MAE，严重性模型达到了 79.2% 的灵敏度。YOLOv8n 模型量化到 INT8 后，推理延迟从 46.96 ms 降低到 21.50 ms，同时保持了 0.995 的 mAP@0.5。

Conclusion: 该系统通过低成本、模块化和数据隐私合规性（HIPAA/GDPR）的综合方法，解决了在断开连接的环境中数字健康应用的障碍，为服务欠缺地区的一线医疗提供可扩展的支持。

Abstract: The design of medical systems for remote, resource-limited environments faces
persistent challenges due to poor interoperability, lack of offline support,
and dependency on costly infrastructure. Many existing digital health solutions
neglect these constraints, limiting their effectiveness for frontline health
workers in underserved regions. This paper presents a portable, edge-enabled
Electronic Health Record platform optimized for offline-first operation, secure
patient data management, and modular diagnostic integration. Running on
small-form factor embedded devices, it provides AES-256 encrypted local storage
with optional cloud synchronization for interoperability. As a use case, we
integrated a non-invasive anemia screening module leveraging fingernail pallor
analysis. Trained on 250 patient cases (27\% anemia prevalence) with
KDE-balanced data, the Random Forest model achieved a test RMSE of 1.969 g/dL
and MAE of 1.490 g/dL. A severity-based model reached 79.2\% sensitivity. To
optimize performance, a YOLOv8n-based nail bed detector was quantized to INT8,
reducing inference latency from 46.96 ms to 21.50 ms while maintaining mAP@0.5
at 0.995. The system emphasizes low-cost deployment, modularity, and data
privacy compliance (HIPAA/GDPR), addressing critical barriers to digital health
adoption in disconnected settings. Our work demonstrates a scalable approach to
enhance portable health information systems and support frontline healthcare in
underserved regions.

</details>


### [379] [Advancing Lunar Communication through Inter-domain Space Networks and Dynamic Orchestration](https://arxiv.org/abs/2507.15483)
*Selen Gecgel Cetin,Baris Donmez,Gunes Karabulut Kurt*

Main category: cs.ET

TL;DR: 鉴于月球探索的持续需求，本研究提出了一种基于近地空间网络的新型通信架构，以克服传统方法的局限性，并确保月球通信的可靠性和效率。


<details>
  <summary>Details</summary>
Motivation: 传统直接对地通信架构依赖于有限且过度使用的深空网络，并且在某些月球区域面临通信可见性不足的挑战。随着月球探索进入新时代，需要一个强大且可用的通信基础设施来支持持续的国际和商业活动。

Method: 1. 建立了统一的链路分析框架，考虑了月球可变光照等环境因素，以进行高保真性能评估。 2. 基于中断风险评估了通信架构的可靠性。 3. 提出了一个动态决策引擎（跨域空间数字孪生）来管理架构的动态性，选择最佳通信路径，确保高稳定性和优化功耗。

Result: 开发了一种高保真性能评估方法，量化了通信链路的运行鲁棒性，并通过动态决策引擎实现了通信路径的选择优化。

Conclusion: 该论文提出了一个支持月球永久人员和经济立足点的月球通信的整体架构和概念管理框架。

Abstract: The reawakened era of lunar exploration is defined by a strategic shift from
temporary visits to a sustained international and commercial presence,
resulting in an unprecedented demand for a robust and continuously available
communication infrastructure. The conventional direct-to-Earth communication
architecture relies on limited and oversubscribed deep space networks, which
are further challenged by the radiative environment and insufficient visibility
in certain areas of the cislunar domain. We address these issues by proposing a
foundational move toward inter-domain space network cooperation by introducing
architectures based on near space networks. They can directly service lunar
surface users or, via cislunar relays, by forming a resilient and multi-layered
communication backbone. First, we establish a unified link analysis framework
incorporating frequently disregarded environmental factors, such as the Moon's
variable illumination, to provide a high-fidelity performance evaluation.
Second, we assess architectures' reliability based on the outage risk,
essential for quantifying the operational robustness of communication links.
Finally, to manage the inherent dynamism of architectures, we propose an
inter-domain space digital twin$-$a dynamic decision-making engine that
performs real-time analysis to autonomously select the best communication path,
ensuring high and stable reliability while simultaneously optimizing power
consumption. Overall, our paper provides a holistic architectural and
conceptual management framework, emphasizing the necessity of lunar
communications to support a permanent human and economic foothold on the Moon.

</details>


<div id='cs.LO'></div>

# cs.LO [[Back]](#toc)

### [380] [A Proof System with Causal Labels (Part I): checking Individual Fairness and Intersectionality](https://arxiv.org/abs/2507.14650)
*Leonardo Ceragioli,Giuseppe Primiero*

Main category: cs.LO

TL;DR: 提出了一种名为TNDPQ的演算，通过因果标签和条件独立性检查来验证概率分类器的公平性和交叉性。


<details>
  <summary>Details</summary>
Motivation: 对概率分类器中的个体公平性和交叉性进行建模和验证。

Method: 通过制定特定的结构规则（Weakening）应用条件来实现解释，这些条件由因果标签给出，用于检查受保护变量和目标变量之间的条件独立性。

Result: 成功地对概率分类器中的个体公平性和交叉性进行了建模和验证。

Conclusion: 本文提出了一种扩展的类型化自然推理演算TNDPQ，用于对概率分类器中的个体公平性和交叉性进行建模和验证。

Abstract: In this article we propose an extension to the typed natural deduction
calculus TNDPQ to model verification of individual fairness and
intersectionality in probabilistic classifiers. Their interpretation is
obtained by formulating specific conditions for the application of the
structural rule of Weakening. Such restrictions are given by causal labels used
to check for conditional independence between protected and target variables.

</details>


### [381] [A Proof System with Causal Labels (Part II): checking Counterfactual Fairness](https://arxiv.org/abs/2507.14655)
*Leonardo Ceragioli,Giuseppe Primiero*

Main category: cs.LO

TL;DR: The paper extends TNDPQ to verify counterfactual fairness in probabilistic classifiers by checking causal label variations.


<details>
  <summary>Details</summary>
Motivation: To model verification of counterfactual fairness in probabilistic classifiers.

Method: Formulating specific structural conditions for causal labels and checking that evaluation is robust under their variation.

Result: An extension to the typed natural deduction calculus TNDPQ.

Conclusion: The proposed extension to TNDPQ allows for the verification of counterfactual fairness in probabilistic classifiers by formulating structural conditions for causal labels and checking robustness under their variation.

Abstract: In this article we propose an extension to the typed natural deduction
calculus TNDPQ to model verification of counterfactual fairness in
probabilistic classifiers. This is obtained formulating specific structural
conditions for causal labels and checking that evaluation is robust under their
variation.

</details>


### [382] [PSPACE-completeness of bimodal transitive weak-density logic](https://arxiv.org/abs/2507.14949)
*Philippe Balbiani,Olivier Gasquet*

Main category: cs.LO

TL;DR: Windows, introduced for designing polynomial algorithms for checking satisfiability of a bimodal logic of weak-density, are used to polynomially solve the satisfiability problem when adding transitivity to weak-density. Both satisfiability and validity are PSPACE-complete for these logics.


<details>
  <summary>Details</summary>
Motivation: Revisiting the 'folklore' case of bimodal K4 and showing that windows allow to polynomially solve the satisfiability problem when adding transitivity to weak-density.

Method: Windows are used to polynomially solve the satisfiability problem for bimodal logic with transitivity and weak-density, by mixing algorithms for bimodal K with the windows-approach.

Result: Windows allow to polynomially solve the satisfiability problem when adding transitivity to weak-density, by mixing algorithms for bimodal K together with windows-approach.

Conclusion: Both satisfiability and validity are PSPACE-complete for these logics.

Abstract: Windows have been introduce in \cite{BalGasq25} as a tool for designing
polynomial algorithms to check satisfiability of a bimodal logic of
weak-density. In this paper, after revisiting the ``folklore'' case of bimodal
$\K4$ already treated in \cite{Halpern} but which is worth a fresh review, we
show that windows allow to polynomially solve the satisfiability problem when
adding transitivity to weak-density, by mixing algorithms for bimodal K
together with windows-approach. The conclusion is that both satisfiability and
validity are PSPACE-complete for these logics.

</details>


### [383] [PSPACE-completeness of Grammar logics of bounded density](https://arxiv.org/abs/2507.14956)
*Olivier Gasquet*

Main category: cs.LO

TL;DR: Multi-modal logics of bounded density with finite windows are PSPACE-complete. Monomodal logic of density is para-PSPACE.


<details>
  <summary>Details</summary>
Motivation: Introduction of the family of multi-modal logics of bounded density.

Method: A tableau-like approach using finite windows.

Result: The satisfiability problem for the family of multi-modal logics of bounded density is PSPACE-complete. The monomodal logic of density is shown to be in para-PSPACE.

Conclusion: The satisfiability problem for the family of multi-modal logics of bounded density is PSPACE-complete. As a side effect, the monomodal logic of density is shown to be in para-PSPACE.

Abstract: We introduce the family of multi-modal logics of bounded density and with a
tableau-like approach using finite \emph{windows} which were introduced in
\cite{BalGasq25}, we prove that their satisfiability problem is
PSPACE-complete. As a side effect, the monomodal logic of density is shown to
be in para-PSPACE.

</details>


### [384] [A meta-modal logic for bisimulations](https://arxiv.org/abs/2507.15117)
*Alfredo Burrieza,Fernando Soler-Toscano,Antonio Yuste-Ginel*

Main category: cs.LO

TL;DR: We introduce a new modality [b] to the modal language to define bisimulations and provide an axiomatization for bisimulation-related Kripke models.


<details>
  <summary>Details</summary>
Motivation: We propose a modal study of the notion of bisimulation.

Method: We extend the basic modal language with a new modality [b], whose intended meaning is universal quantification over all states that are bisimilar to the current one.

Result: Bisimulations are definable in this object language.

Conclusion: bisimulations are definable in this object language and we provide a sound and complete axiomatisation of the class of all pairs of Kripke models linked by bisimulations

Abstract: We propose a modal study of the notion of bisimulation. Our contribution is
twofold. First, we extend the basic modal language with a new modality [b],
whose intended meaning is universal quantification over all states that are
bisimilar to the current one. We show that bisimulations are definable in this
object language. Second, we provide a sound and complete axiomatisation of the
class of all pairs of Kripke models linked by bisimulations.

</details>


### [385] [STL-GO: Spatio-Temporal Logic with Graph Operators for Distributed Systems with Multiple Network Topologies](https://arxiv.org/abs/2507.15147)
*Yiqi Zhao,Xinyi Yu,Bardh Hoxha,Georgios Fainekos,Jyotirmoy V. Deshmukh,Lars Lindemann*

Main category: cs.LO

TL;DR: A new logic (STL-GO) and distributed monitoring methods are proposed for multi-agent systems, allowing reasoning about agent interactions and properties using graph operators and local information, with successful application in case studies.


<details>
  <summary>Details</summary>
Motivation: Modeling and monitoring multi-agent system requirements is crucial for guaranteeing mission objectives, safety, and reliability, especially considering diverse sensing and communication modalities, task dependencies, and spatial/virtual distances between agents.

Method: The paper models agent interactions using multiple directed graphs and introduces Spatio-Temporal Logic with Graph Operators (STL-GO), which includes graph operators to reason about agent properties based on their interactions. Novel distributed monitoring conditions for individual agents are also proposed.

Result: STL-GO enables reasoning about agent interactions and properties through graph operators. Distributed monitors using local information can determine if STL-GO specifications are met. The expressivity of STL-GO is compared to existing formalisms, and its utility is shown in bike-sharing and multi-drone case studies.

Conclusion: The paper introduces STL-GO, a novel logic for modeling and monitoring multi-agent system requirements, and demonstrates its utility in case studies.

Abstract: Multi-agent systems (MASs) consisting of a number of autonomous agents that
communicate, coordinate, and jointly sense the environment to achieve complex
missions can be found in a variety of applications such as robotics, smart
cities, and internet-of-things applications. Modeling and monitoring MAS
requirements to guarantee overall mission objectives, safety, and reliability
is an important problem. Such requirements implicitly require reasoning about
diverse sensing and communication modalities between agents, analysis of the
dependencies between agent tasks, and the spatial or virtual distance between
agents. To capture such rich MAS requirements, we model agent interactions via
multiple directed graphs, and introduce a new logic -- Spatio-Temporal Logic
with Graph Operators (STL-GO). The key innovation in STL-GO are graph operators
that enable us to reason about the number of agents along either the incoming
or outgoing edges of the underlying interaction graph that satisfy a given
property of interest; for example, the requirement that an agent should sense
at least two neighboring agents whose task graphs indicate the ability to
collaborate. We then propose novel distributed monitoring conditions for
individual agents that use only local information to determine whether or not
an STL-GO specification is satisfied. We compare the expressivity of STL-GO
against existing spatio-temporal logic formalisms, and demonstrate the utility
of STL-GO and our distributed monitors in a bike-sharing and a multi-drone case
study.

</details>


### [386] [Quantum Programming in Polylogarithmic Time](https://arxiv.org/abs/2507.15415)
*Florent Ferrari,Emmanuel Hainry,Romain Péchoux,Mário Silva*

Main category: cs.LO

TL;DR: 开发了一种量子编程语言，用于表征 FBQPOLYLOG 复杂度类，并证明了 FBQPOLYLOG $\subsetneq$ QNC。


<details>
  <summary>Details</summary>
Motivation: 在经典计算模型（如布尔电路或并行随机访问机）中，多对数时间是一种重要的可行性概念。然而，在量子范式中，这种可行性概念尚未在编程语言层面得到充分表征。

Method: 提出了一种包含一阶递归过程的量子编程语言，并提供了一种将程序编译为多对数深度和多项式规模的量子电路族的策略。

Result: 该量子编程语言能够计算 FBQPOLYLOG 中的函数，并且FBQPOLYLOG中的每个函数都可以由该语言的程序计算。此外，该研究还提供了将程序编译为多对数深度和多项式规模的量子电路的策略，并验证了 FBQPOLYLOG $\subsetneq$ QNC 的分离结果。

Conclusion: FBQPOLYLOG（由量子随机访问图灵机在多对数时间内实现）的基于编程语言的表征得到了首次实现，并且 FBQPOLYLOG $\subsetneq$ QNC。

Abstract: Polylogarithmic time delineates a relevant notion of feasibility on several
classical computational models such as Boolean circuits or parallel random
access machines. As far as the quantum paradigm is concerned, this notion
yields the complexity class FBQPOLYLOG of functions approximable in
polylogarithmic time with a quantum random-access Turing machine. We introduce
a quantum programming language with first-order recursive procedures, which
provides the first programming-language-based characterization of FBQPOLYLOG.
Each program computes a function in FBQPOLYLOG (soundness) and, conversely,
each function of this complexity class is computed by a program (completeness).
We also provide a compilation strategy from programs to uniform families of
quantum circuits of polylogarithmic depth and polynomial size, whose set of
computed functions is known as QNC, and recover the well-known separation
result FBQPOLYLOG $\subsetneq$ QNC.

</details>


### [387] [A SHACL-based Data Consistency Solution for Contract Compliance Verification](https://arxiv.org/abs/2507.15420)
*Robert David,Albin Ahmeti,Geni Bushati,Amar Tauqeer,Anna Fensel*

Main category: cs.LO

TL;DR: 本文提出了一种新的方法来改进ACT工具，通过半自动修复策略解决GDPR合同合规性验证中的数据不一致问题，以确保合规性。


<details>
  <summary>Details</summary>
Motivation: 现有的ACT工具虽然可以报告违反义务的情况，但在验证和确保合规性方面存在局限性，因为它没有使用像SHACL这样的可互操作的语义形式，并且不支持用户解决数据不一致问题。

Method: 提出了一种半自动化的方法，通过提供修复策略来解决合同合规性验证（CCV）中的不一致问题，并将其集成到ACT工具中进行实现和测试。

Result: 实现并测试了所提出的方法，证明了其在解决CCV不一致性方面的正确性和性能，以及在支持用户管理GDPR合规性合同生命周期数据方面的作用。

Conclusion: 本文提出了一种半自动化的方法来解决合同合规性验证（CCV）中的不一致问题，通过提供修复策略来自动提出（最优）解决方案，以重新建立数据一致性，从而支持用户管理符合GDPR的合同生命周期数据。该方法已被实现并集成到ACT工具中，并在基本CCV一致性要求方面进行了测试。

Abstract: In recent years, there have been many developments for GDPR-compliant data
access and sharing based on consent. For more complex data sharing scenarios,
where consent might not be sufficient, many parties rely on contracts. Before a
contract is signed, it must undergo the process of contract negotiation within
the contract lifecycle, which consists of negotiating the obligations
associated with the contract. Contract compliance verification (CCV) provides a
means to verify whether a contract is GDPR-compliant, i.e., adheres to legal
obligations and there are no violations. The rise of knowledge graph (KG)
adoption, enabling semantic interoperability using well-defined semantics,
allows CCV to be applied on KGs. In the scenario of different participants
negotiating obligations, there is a need for data consistency to ensure that
CCV is done correctly. Recent work introduced the automated contracting tool
(ACT), a KG-based and ODRL-employing tool for GDPR CCV, which was developed in
the Horizon 2020 project smashHit (https://smashhit.eu). Although the tool
reports violations with respect to obligations, it had limitations in verifying
and ensuring compliance, as it did not use an interoperable semantic formalism,
such as SHACL, and did not support users in resolving data inconsistencies. In
this work, we propose a novel approach to overcome these limitations of ACT. We
semi-automatically resolve CCV inconsistencies by providing repair strategies,
which automatically propose (optimal) solutions to the user to re-establish
data consistency and thereby support them in managing GDPR-compliant contract
lifecycle data. We have implemented the approach, integrated it into ACT and
tested its correctness and performance against basic CCV consistency
requirements.

</details>


### [388] [Computation of Interpolants for Description Logic Concepts in Hard Cases](https://arxiv.org/abs/2507.15689)
*Jean Christoph Jung,Jędrzej Kołodziejski,Frank Wolter*

Main category: cs.LO

TL;DR: 本文提出了计算ALC和ALCQ概念插值的基本算法，并指出均匀插值可能非常大。


<details>
  <summary>Details</summary>
Motivation: 与此相反，我们还观察到，均匀（可能受深度限制）的插值可能具有非基本大小。

Method: 本文提出，我们提供了第一个基本算法，用于计算（i）在ALCH本体下的ALC概念之间的ALC插值，以及（ii）在ALCQ本体下的ALCQ概念之间的ALC插值。这些算法基于最近的插值存在性判定过程。

Result: 本文提供了第一个计算ALC概念之间ALC插值和ALCQ概念之间ALC插值的基本算法，这些算法基于最近的插值存在性判定过程。

Conclusion: 虽然对于具有Craig插值性质（CIP）的描述逻辑（DL）的Craig插值计算得到了很好的理解，但对于没有CIP的DL或以弱于输入本体和概念的DL来插值概念，其插值计算和大小的了解却很少。

Abstract: While the computation of Craig interpolants for description logics (DLs) with
the Craig Interpolation Property (CIP) is well understood, very little is known
about the computation and size of interpolants for DLs without CIP or if one
aims at interpolating concepts in a weaker DL than the DL of the input ontology
and concepts. In this paper, we provide the first elementary algorithms
computing (i) ALC-interpolants between ALC-concepts under ALCH-ontologies and
(ii) ALC-interpolants between ALCQ-concepts under ALCQ-ontologies. The
algorithms are based on recent decision procedures for interpolant existence.
We also observe that, in contrast, uniform (possibly depth restricted)
interpolants might be of non-elementary size.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [389] [Real-Time Communication-Aware Ride-Sharing Route Planning for Urban Air Mobility: A Multi-Source Hybrid Attention Reinforcement Learning Approach](https://arxiv.org/abs/2507.14249)
*Yuejiao Xie,Maonan Wang,Di Zhou,Man-On Pun,Zhu Han*

Main category: cs.RO

TL;DR: 这项研究提出了一种名为 MSHA-RL 的新框架，用于解决城市空中交通 (UAM) 的路径规划问题。它通过考虑通信质量和动态乘客需求来提高效率和安全性，并通过实验证明了其有效性。


<details>
  <summary>Details</summary>
Motivation: 城市空中交通 (UAM) 系统作为缓解城市拥堵的有前途的解决方案正在迅速出现，但其轨迹规划面临独特挑战：1. 与地面交通不同，UAM 轨迹规划必须优先考虑通信质量以在不断变化的环境中进行准确定位，从而确保安全。2. UAM 系统需要自适应规划以响应实时乘客请求，尤其是在乘客需求不可预测和动态的拼车场景中。3. 传统的基于预定义路线的轨迹规划策略缺乏满足多样化乘客出行需求的灵活性。

Method: 提出构建无线电图来评估城市空域的通信质量。然后，引入多源混合注意力强化学习（MSHA-RL）框架，该框架首先生成对齐跨越巨大维度差异的多种数据源，然后采用混合注意力来平衡全局和局部见解，从而实现对乘客和 UAM 位置的有效关注，最终实现响应及时的实时路径规划。

Result: 实验结果表明，所提出的方法能够实现通信兼容的轨迹规划，缩短旅行时间并提高运营效率，同时优先考虑乘客安全。

Conclusion: 该研究提出了一种新颖的多源混合注意力强化学习（MSHA-RL）框架，用于城市空中交通 (UAM) 的轨迹规划。该框架能够处理通信质量和动态乘客需求等挑战，通过构建无线电图评估城市空域的通信质量，并利用混合注意力机制在不同数据源之间进行对齐，从而实现具有通信兼容性、缩短旅行时间和提高运营效率的轨迹规划，同时优先考虑乘客安全。

Abstract: Urban Air Mobility (UAM) systems are rapidly emerging as promising solutions
to alleviate urban congestion, with path planning becoming a key focus area.
Unlike ground transportation, UAM trajectory planning has to prioritize
communication quality for accurate location tracking in constantly changing
environments to ensure safety. Meanwhile, a UAM system, serving as an air taxi,
requires adaptive planning to respond to real-time passenger requests,
especially in ride-sharing scenarios where passenger demands are unpredictable
and dynamic. However, conventional trajectory planning strategies based on
predefined routes lack the flexibility to meet varied passenger ride demands.
To address these challenges, this work first proposes constructing a radio map
to evaluate the communication quality of urban airspace. Building on this, we
introduce a novel Multi-Source Hybrid Attention Reinforcement Learning
(MSHA-RL) framework for the challenge of effectively focusing on passengers and
UAM locations, which arises from the significant dimensional disparity between
the representations. This model first generates the alignment among diverse
data sources with large gap dimensions before employing hybrid attention to
balance global and local insights, thereby facilitating responsive, real-time
path planning. Extensive experimental results demonstrate that the approach
enables communication-compliant trajectory planning, reducing travel time and
enhancing operational efficiency while prioritizing passenger safety.

</details>


### [390] [A Recursive Lie-Group Formulation for the Second-Order Time Derivatives of the Inverse Dynamics of parallel Kinematic Manipulators](https://arxiv.org/abs/2507.14274)
*Andreas Mueller,Shivesh Kumar,Thomas Kordik*

Main category: cs.RO

TL;DR: 本文提出了一种新方法，用于高效计算并联机器人的SEA逆动力学二阶导数，并用于控制应用。


<details>
  <summary>Details</summary>
Motivation: 目前，对装有SEA的并联运动规划器（PKM）的轨迹控制研究尚不充分，特别是其逆动力学解的二阶时间导数的计算效率问题尚未得到解决。本文旨在首次解决这一问题，为PKM的轨迹控制提供理论基础。

Method: 提出了一种利用李群（Lie group）理论和串联机器人递归算法来高效计算并联机器人（PKM）的逆动力学解的二阶时间导数的方法。该方法通过复用现有算法来处理PKM的特殊拓扑结构。

Result: 通过对6-DOF Gough-Stewart平台和平面PKM的仿真结果表明，该方法能够高效地计算逆动力学解的二阶时间导数，并可应用于基于平坦性的控制方案。

Conclusion: 本文为串联机器人和并联机器人（PRM）的系列弹性执行器（SEA）的逆动力学解的二阶时间导数评估问题，提出了一种新颖的基于李群的计算方法，并进行了仿真验证。

Abstract: Series elastic actuators (SEA) were introduced for serial robotic arms. Their
model-based trajectory tracking control requires the second time derivatives of
the inverse dynamics solution, for which algorithms were proposed. Trajectory
control of parallel kinematics manipulators (PKM) equipped with SEAs has not
yet been pursued. Key element for this is the computationally efficient
evaluation of the second time derivative of the inverse dynamics solution. This
has not been presented in the literature, and is addressed in the present paper
for the first time. The special topology of PKM is exploited reusing the
recursive algorithms for evaluating the inverse dynamics of serial robots. A
Lie group formulation is used and all relations are derived within this
framework. Numerical results are presented for a 6-DOF Gough-Stewart platform
(as part of an exoskeleton), and for a planar PKM when a flatness-based control
scheme is applied.

</details>


### [391] [Personalized Socially Assistive Robots With End-to-End Speech-Language Models For Well-Being Support](https://arxiv.org/abs/2507.14412)
*Mengxue Fu,Zhonghao Shi,Minyu Huang,Siqi Liu,Mina Kian,Yirui Song,Maja J. Matarić*

Main category: cs.RO

TL;DR: Socially assistive robots with integrated speech-language models show promise for better dialogue, offering empathy and natural interaction. However, robot movements need better synchronization, and the AI's responses should be less generic and more aligned with mental health practices for improved user experience.


<details>
  <summary>Details</summary>
Motivation: Prior studies found limitations in existing dialogue pipelines for Socially Assistive Robots (SARs) concerning real-time latency, back-channeling, and personalized speech dialogue. This work aims to address these limitations by proposing the use of integrated end-to-end speech-language models (SLMs) with SARs.

Method: The study evaluated an SLM-enabled SAR dialogue system through a small within-participant user study with university students (N = 11). The evaluation focused on usability and identified limitations through user feedback.

Result: Participants perceived the SLM-enabled SAR system as capable of empathetic feedback, natural turn-taking, back-channeling, and adaptive responses. Key limitations identified were the lack of variability and synchronization in the robot's nonverbal behaviors, and generic and repetitive verbal feedback from the SLM.

Conclusion: The study demonstrated that an SLM-enabled SAR system is perceived by users as capable of providing empathetic feedback, natural turn-taking, back-channeling, and adaptive responses. However, limitations were identified in the robot's nonverbal behaviors (lack of variability and synchronization) and the SLM's verbal feedback (generic and repetitive). Future improvements should focus on synchronizing robot movements with conversation, enhancing prompting or fine-tuning for mental health alignment, and developing more expressive and adaptive vocal generation.

Abstract: Socially assistive robots (SARs) have shown great potential for supplementing
well-being support. However, prior studies have found that existing dialogue
pipelines for SARs remain limited in real-time latency, back-channeling, and
personalized speech dialogue. Toward addressing these limitations, we propose
using integrated end-to-end speech-language models (SLMs) with SARs. This work
1) evaluated the usability of an SLM-enabled SAR dialogue system through a
small user study, and 2) identified remaining limitations through study user
feedback to inform future improvements. We conducted a small within-participant
user study with university students (N = 11) whose results showed that
participants perceived an SLM-enabled SAR system as capable of providing
empathetic feedback, natural turn-taking, back-channeling, and adaptive
responses. We also found that participants reported the robot's nonverbal
behaviors as lacking variability and synchronization with conversation, and the
SLM's verbal feedback as generic and repetitive. These findings highlighted the
need for real-time robot movement synchronized with conversation, improved
prompting or fine-tuning to generate outputs better aligned with mental health
practices, and more expressive, adaptive vocal generation.

</details>


### [392] [Koopman Operator Based Time-Delay Embeddings and State History Augmented LQR for Periodic Hybrid Systems: Bouncing Pendulum and Bipedal Walking](https://arxiv.org/abs/2507.14455)
*Chun-Ming Yang,Pranav A. Bhounsule*

Main category: cs.RO

TL;DR: 时间延迟嵌入技术可用于对周期性混合系统进行建模，并用于开发新的反馈控制器。


<details>
  <summary>Details</summary>
Motivation: 证明时间延迟嵌入技术不仅可以用于建立非线性平滑系统的线性状态空间模型，还可以用于建立周期性非光滑或混合系统的线性状态空间模型。

Method: 提出了一种将时间延迟嵌入技术扩展到周期性非光滑或混合系统的方法，以构建线性状态空间模型。

Result: 成功地将时间延迟嵌入技术应用于两个周期性混合系统——反弹钟摆和带控制输入的简单步行者，并生成了它们的线性模型。基于此，研究提出了一种新颖的状态历史增强型线性二次调节器（LQR），该调节器利用当前和过去的状态历史进行反馈控制。

Conclusion: 该研究表明，时间延迟嵌入技术不仅可以用于建立非线性平滑系统的线性状态空间模型，还可以通过扩展该技术来生成周期性混合系统的线性模型，例如反弹钟摆和具有控制输入的简单步行者。

Abstract: Time-delay embedding is a technique that uses snapshots of state history over
time to build a linear state space model of a nonlinear smooth system. We
demonstrate that periodic non-smooth or hybrid system can also be modeled as a
linear state space system using this approach as long as its behavior is
consistent in modes and timings. We extended time-delay embeddings to generate
a linear model of two periodic hybrid systems: the bouncing pendulum and the
simplest walker with control inputs. This leads to a novel state history
augmented linear quadratic regulator (LQR) which uses current and past state
history for feedback control.

</details>


### [393] [A 21-DOF Humanoid Dexterous Hand with Hybrid SMA-Motor Actuation: CYJ Hand-0](https://arxiv.org/abs/2507.14538)
*Jin Chai,Xiang Yao,Mengfan Hou,Yanghong Li,Erbao Dong*

Main category: cs.RO

TL;DR: CYJ Hand-0 是一款21自由度的灵巧手，采用混合驱动系统（SMA和直流电机）和3D打印金属框架，模仿人手结构，具有仿生灵巧性。


<details>
  <summary>Details</summary>
Motivation: 设计一款具有仿生灵巧性的灵巧手。

Method: CYJ Hand-0 手部采用混合驱动系统，结合形状记忆合金（SMA）和直流电机，使用高强度钓鱼线作为人造肌腱，以及一个3D打印的AlSi10Mg金属框架来模仿人手的骨骼和肌腱-肌肉结构。线性电机模块控制手指弯曲，SMA模块控制手指伸展和侧向外展。

Result: CYJ Hand-0 是一款具有21自由度、混合驱动的灵巧手，具有紧凑的混合驱动单元和定制的后支撑结构，并通过机械和运动学实验进行了验证。

Conclusion: CYJ Hand-0的设计被证明是有效的，并展示了其仿生灵巧性。

Abstract: CYJ Hand-0 is a 21-DOF humanoid dexterous hand featuring a hybrid
tendon-driven actuation system that combines shape memory alloys (SMAs) and DC
motors. The hand employs high-strength fishing line as artificial tendons and
uses a fully 3D-printed AlSi10Mg metal frame designed to replicate the skeletal
and tendon-muscle structure of the human hand. A linear motor-driven module
controls finger flexion, while an SMA-based module enables finger extension and
lateral abduction. These modules are integrated into a compact hybrid actuation
unit mounted on a custom rear support structure. Mechanical and kinematic
experiments, conducted under an Arduino Mega 2560-based control system,
validate the effectiveness of the design and demonstrate its biomimetic
dexterity.

</details>


### [394] [BT-TL-DMPs: A Novel Robot TAMP Framework Combining Behavior Tree, Temporal Logic and Dynamical Movement Primitives](https://arxiv.org/abs/2507.14582)
*Zezhi Liu,Shizhen Wu,Hanqian Luo,Deyun Qin,Yongchun Fang*

Main category: cs.RO

TL;DR: 该研究提出了一种名为BT-TL-DMPs的框架，通过结合行为树、时序逻辑和动力学移动原语，解决了机器人难以在长时序任务中泛化学习技能的问题。该框架利用STL规范任务，并通过优化的DMPs实现对新环境的适应和动力学的保持，从而提高了机器人操作的可靠性和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 在从演示中学习（LfD）领域，使机器人能够将学习到的操作技能泛化到长时序任务的新场景仍然是一个挑战。具体来说，机器人仍然难以将学习到的技能适应到具有不同任务和运动要求的新环境中，尤其是在具有复杂约束的长时序、多阶段场景中。

Method: 提出了一种名为BT-TL-DMPs的混合框架，该框架集成了行为树（BT）、时序逻辑（TL）和动力学移动原语（DMPs）。使用信号时序逻辑（STL）来形式化复杂、长时序的任务需求和约束，并将STL规范转换为行为树，用于高层决策。提出了一种受STL约束的DMP优化方法，用于优化DMP的强迫项，使学习到的运动原语能够灵活适应，同时满足时空约束并保留学习到的动力学。

Result: 仿真结果表明，在各种STL约束下，该框架展现了良好的泛化能力。真实世界的实验也在多个长时序机器人操作任务上进行了验证。实验结果证明，所提出的框架有效地弥合了符号-运动的鸿沟，使得复杂机器人任务的自主操作更加可靠和可泛化。

Conclusion: 该框架通过整合行为树（BT）、时序逻辑（TL）和动力学移动原语（DMPs）来解决机器人从演示中学习（LfD）的挑战，特别是实现了在长时序、多阶段任务中泛化到新场景的能力。通过信号时序逻辑（STL）规范任务要求和约束，并将其转化为行为树，同时优化DMPs以适应新环境并保持学习到的动力学特性。仿真和真实世界实验证明，该框架有效弥合了符号-运动的鸿沟，提高了复杂机器人任务的自主性和泛化能力。

Abstract: In the field of Learning from Demonstration (LfD), enabling robots to
generalize learned manipulation skills to novel scenarios for long-horizon
tasks remains challenging. Specifically, it is still difficult for robots to
adapt the learned skills to new environments with different task and motion
requirements, especially in long-horizon, multi-stage scenarios with intricate
constraints. This paper proposes a novel hierarchical framework, called
BT-TL-DMPs, that integrates Behavior Tree (BT), Temporal Logic (TL), and
Dynamical Movement Primitives (DMPs) to address this problem. Within this
framework, Signal Temporal Logic (STL) is employed to formally specify complex,
long-horizon task requirements and constraints. These STL specifications are
systematically transformed to generate reactive and modular BTs for high-level
decision-making task structure. An STL-constrained DMP optimization method is
proposed to optimize the DMP forcing term, allowing the learned motion
primitives to adapt flexibly while satisfying intricate spatiotemporal
requirements and, crucially, preserving the essential dynamics learned from
demonstrations. The framework is validated through simulations demonstrating
generalization capabilities under various STL constraints and real-world
experiments on several long-horizon robotic manipulation tasks. The results
demonstrate that the proposed framework effectively bridges the symbolic-motion
gap, enabling more reliable and generalizable autonomous manipulation for
complex robotic tasks.

</details>


### [395] [Koopman Operator Based Linear Model Predictive Control for 2D Quadruped Trotting, Bounding, and Gait Transition](https://arxiv.org/abs/2507.14605)
*Chun-Ming Yang,Pranav A. Bhounsule*

Main category: cs.RO

TL;DR: 使用 Koopman 算子理论和 LMPC 来控制四足机器人，实现多种步态和步态转换。


<details>
  <summary>Details</summary>
Motivation: 为了实现四足机器人能够应对新场景的在线最优运动规划，克服了传统线性模型预测控制 (LMPC) 中因运动方程线性化而导致的解的质量问题。

Method: 提出了一种结合 Koopman 算子理论和扩展动态模式分解 (EDMD) 的方法，为四足动物的运动状态方程（EOM）创建高维线性模型，以保留非线性特征。该模型区分了空中和地面接触阶段，并在此基础上利用线性模型预测控制 (LMPC) 进行在线优化控制。

Result: 成功演示了在平坦和崎岖地形中，使用 LMPC 进行的bounding、trotting以及bound-to-trot和trot-to-bound的步态转换。

Conclusion: 该研究使用 Koopman 算子理论和扩展动态模式分解 (EDMD) 创建了四足动物系统的混合模型，并在不同地形上演示了多种步态和步态转换的在线生成。

Abstract: Online optimal control of quadrupedal robots would enable them to plan their
movement in novel scenarios. Linear Model Predictive Control (LMPC) has emerged
as a practical approach for real-time control. In LMPC, an optimization problem
with a quadratic cost and linear constraints is formulated over a finite
horizon and solved on the fly. However, LMPC relies on linearizing the
equations of motion (EOM), which may lead to poor solution quality. In this
paper, we use Koopman operator theory and the Extended Dynamic Mode
Decomposition (EDMD) to create a linear model of the system in high dimensional
space, thus retaining the nonlinearity of the EOM. We model the aerial phase
and ground contact phases using different linear models. Then, using LMPC, we
demonstrate bounding, trotting, and bound-to-trot and trot-to-bound gait
transitions in level and rough terrains. The main novelty is the use of Koopman
operator theory to create hybrid models of a quadrupedal system and demonstrate
the online generation of multiple gaits and gaits transitions.

</details>


### [396] [Uncertainty-aware Probabilistic 3D Human Motion Forecasting via Invertible Networks](https://arxiv.org/abs/2507.14694)
*Yue Ma,Kanglei Zhou,Fuyang Yu,Frederick W. B. Li,Xiaohui Liang*

Main category: cs.RO

TL;DR: ProbHMI通过使用可逆网络进行概率建模来解决3D人类动作预测中的不确定性量化问题，从而提高安全关键应用的可靠性。


<details>
  <summary>Details</summary>
Motivation: 为了在诸如人机协作等安全关键环境中最小化风险，3D人类动作预测需要为每个预测进行不确定性估计。现有的方法由于隐式概率表示而难以量化不确定性。

Method: ProbHMI引入了可逆网络来参数化姿势，并结合预测模块来显式预测未来潜在分布，从而实现概率动力学建模和有效的不确定性量化。

Result: ProbHMI在基准测试中在确定性和多样性预测方面均表现出色，并验证了其不确定性校准能力，这对于风险感知决策至关重要。

Conclusion: ProbHMI通过引入可逆网络在解耦的潜在空间中参数化姿势，实现了概率动力学建模，并显式预测未来潜在分布，从而能够进行有效的量化不确定性。该方法在确定性和多样性预测方面均取得了强劲性能，并验证了对风险感知决策至关重要的不确定性校准。

Abstract: 3D human motion forecasting aims to enable autonomous applications.
Estimating uncertainty for each prediction (i.e., confidence based on
probability density or quantile) is essential for safety-critical contexts like
human-robot collaboration to minimize risks. However, existing diverse motion
forecasting approaches struggle with uncertainty quantification due to implicit
probabilistic representations hindering uncertainty modeling. We propose
ProbHMI, which introduces invertible networks to parameterize poses in a
disentangled latent space, enabling probabilistic dynamics modeling. A
forecasting module then explicitly predicts future latent distributions,
allowing effective uncertainty quantification. Evaluated on benchmarks, ProbHMI
achieves strong performance for both deterministic and diverse prediction while
validating uncertainty calibration, critical for risk-aware decision making.

</details>


### [397] [Search-Based Autonomous Vehicle Motion Planning Using Game Theory](https://arxiv.org/abs/2507.15088)
*Pouya Panahandeh,Mohammad Pirani,Baris Fidan,Amir Khajepour*

Main category: cs.RO

TL;DR: A game-theoretic approach for autonomous vehicle motion planning that treats other road users as intelligent agents, enabling real-time, realistic path generation validated on an actual autonomous shuttle bus.


<details>
  <summary>Details</summary>
Motivation: To generate a more realistic path for autonomous vehicles (AVs) by considering other road users as intelligent agents rather than static obstacles.

Method: A search-based interactive motion planning scheme using a game-theoretic approach.

Result: The performance of the developed motion planning scheme is compared with existing motion planning techniques and validated through experiments using WATonoBus.

Conclusion: The proposed motion planning scheme is implementable in real-time applications and generates more realistic paths for AVs by considering other road users as intelligent agents.

Abstract: In this paper, we propose a search-based interactive motion planning scheme
for autonomous vehicles (AVs), using a game-theoretic approach. In contrast to
traditional search-based approaches, the newly developed approach considers
other road users (e.g. drivers and pedestrians) as intelligent agents rather
than static obstacles. This leads to the generation of a more realistic path
for the AV. Due to the low computational time, the proposed motion planning
scheme is implementable in real-time applications. The performance of the
developed motion planning scheme is compared with existing motion planning
techniques and validated through experiments using WATonoBus, an electrical
all-weather autonomous shuttle bus.

</details>


### [398] [Corridor-based Adaptive Control Barrier and Lyapunov Functions for Safe Mobile Robot Navigation](https://arxiv.org/abs/2507.14700)
*Nicholas Mohammad,Nicola Bezzo*

Main category: cs.RO

TL;DR: 在未知和混乱的环境中，提出了一种基于CLF和CBF的MPCC框架，通过SAC策略动态调整CBF参数，实现了安全导航。


<details>
  <summary>Details</summary>
Motivation: 现有的模型预测轮廓控制（MPCC）方法在进行机器人导航时缺乏正式的安全保证，而在未知和混乱的环境中安全导航是一个挑战性问题。

Method: 提出了一种通用的控制李雅普诺夫函数（CLF）和控制障碍函数（CBF）驱动的模型预测轮廓控制（MPCC）框架，并使用软Actor-Critic（SAC）策略动态调整CBF参数以增强可行性。

Result: 通过在未知混乱环境中进行大量的模拟和移动机器人导航实验，验证了该框架的有效性。

Conclusion: 该框架通过使用控制李雅普诺夫函数（CLF）和控制障碍函数（CBF）来强制执行安全约束，并使用软Actor-Critic（SAC）策略动态调整CBF参数，从而在未知和混乱的环境中实现了安全的移动机器人导航。

Abstract: Safe navigation in unknown and cluttered environments remains a challenging
problem in robotics. Model Predictive Contour Control (MPCC) has shown promise
for performant obstacle avoidance by enabling precise and agile trajectory
tracking, however, existing methods lack formal safety assurances. To address
this issue, we propose a general Control Lyapunov Function (CLF) and Control
Barrier Function (CBF) enabled MPCC framework that enforces safety constraints
derived from a free-space corridor around the planned trajectory. To enhance
feasibility, we dynamically adapt the CBF parameters at runtime using a Soft
Actor-Critic (SAC) policy. The approach is validated with extensive simulations
and an experiment on mobile robot navigation in unknown cluttered environments.

</details>


### [399] [Leveraging Extrinsic Dexterity for Occluded Grasping on Grasp Constraining Walls](https://arxiv.org/abs/2507.14721)
*Keita Kobashi,Masayoshi Tomizuka*

Main category: cs.RO

TL;DR: 提出分层强化学习方法，利用CVAE进行定位，实现遮挡抓取，并成功从模拟迁移到现实。


<details>
  <summary>Details</summary>
Motivation: 解决因与环境的遮挡而导致物体主要抓取构型不可用的遮挡抓取问题。现有方法虽然探索了利用物体与墙等环境特征之间的外在接触来进行枢转等姿态重定向，但通常假设存在较短的墙，而在现实场景中这种假设不一定成立。如果用于交互的墙过大或过高，机器人即使在枢转后仍可能无法抓取物体，并且需要结合不同类型的动作才能抓取。

Method: 提出了一种分层强化学习（RL）框架，其中使用Q学习训练一个高级策略来选择预期的最高奖励动作类型，然后由选定的低级技能在连续空间中采样具体的机器人动作。为了指导机器人到执行所选动作的合适位置，采用条件变分自编码器（CVAE），并将其条件设置为物体点云和技能ID，从而能够根据物体几何和所选技能推断出合适的位置。为了促进泛化，在低级技能的训练中应用了域随机化。

Result: 该RL策略完全在模拟环境中，使用类似盒子的物体进行训练，并成功部署到现实世界的六种物体上。实验评估了该方法，并证明了其泛化能力和稳健的从模拟到现实的传输性能，成功率令人满意。

Conclusion: 该方法通过分层强化学习框架，在模拟环境中训练，并成功迁移到真实世界的六种不同物体上，展示了其泛化能力和从模拟到现实的传输性能，并取得了令人鼓舞的成功率。

Abstract: This study addresses the problem of occluded grasping, where primary grasp
configurations of an object are not available due to occlusion with
environment. Simple parallel grippers often struggle with such tasks due to
limited dexterity and actuation constraints. Prior works have explored object
pose reorientation such as pivoting by utilizing extrinsic contacts between an
object and an environment feature like a wall, to make the object graspable.
However, such works often assume the presence of a short wall, and this
assumption may not always hold in real-world scenarios. If the wall available
for interaction is too large or too tall, the robot may still fail to grasp the
object even after pivoting, and the robot must combine different types of
actions to grasp. To address this, we propose a hierarchical reinforcement
learning (RL) framework. We use Q-learning to train a high-level policy that
selects the type of action expected to yield the highest reward. The selected
low-level skill then samples a specific robot action in continuous space. To
guide the robot to an appropriate location for executing the selected action,
we adopt a Conditional Variational Autoencoder (CVAE). We condition the CVAE on
the object point cloud and the skill ID, enabling it to infer a suitable
location based on the object geometry and the selected skill. To promote
generalization, we apply domain randomization during the training of low-level
skills. The RL policy is trained entirely in simulation with a box-like object
and deployed to six objects in real world. We conduct experiments to evaluate
our method and demonstrate both its generalizability and robust sim-to-real
transfer performance with promising success rates.

</details>


### [400] [X-Nav: Learning End-to-End Cross-Embodiment Navigation for Mobile Robots](https://arxiv.org/abs/2507.14731)
*Haitong Wang,Aaron Hao Tan,Angus Fung,Goldie Nejat*

Main category: cs.RO

TL;DR: X-Nav 是一个创新的端到端跨具身导航框架，通过强化学习和策略蒸馏，使单一策略可应用于不同机器人（轮式、四足），并成功在模拟和真实环境中实现零样本迁移。


<details>
  <summary>Details</summary>
Motivation: 现有导航方法主要针对特定机器人实体设计，泛化性有限，难以跨不同机器人平台使用。本文提出 X-Nav 框架，旨在实现端到端的跨具身导航，使单一统一策略能够应用于包括轮式和四足机器人在内的多种机器人实体。

Method: X-Nav 框架通过两个学习阶段实现跨具身导航：首先，在大量随机生成的机器人具身（包括轮式和四足机器人）上，利用具有特权观察的深度强化学习训练多个专家策略；然后，通过导航动作分块（Nav-ACT）技术，从这些专家策略中蒸馏出单一的通用策略。该通用策略能够将视觉和本体感觉观察直接映射到低级控制命令，从而实现对新具身的零样本迁移。

Result: 模拟实验表明，X-Nav 对未见过的机器人实体和光照逼真的环境实现了零样本迁移。可扩展性研究表明，随着训练数据的增加，X-Nav 的性能得到提升。消融研究验证了 X-Nav 的设计选择。此外，真实世界实验也验证了 X-Nav 在真实环境中的泛化能力。

Conclusion: X-Nav 框架实现了跨具身导航的端到端通用性，在模拟和真实世界实验中均表现出良好的泛化能力，并且随着训练具身数量的增加，性能有所提升。

Abstract: Existing navigation methods are primarily designed for specific robot
embodiments, limiting their generalizability across diverse robot platforms. In
this paper, we introduce X-Nav, a novel framework for end-to-end
cross-embodiment navigation where a single unified policy can be deployed
across various embodiments for both wheeled and quadrupedal robots. X-Nav
consists of two learning stages: 1) multiple expert policies are trained using
deep reinforcement learning with privileged observations on a wide range of
randomly generated robot embodiments; and 2) a single general policy is
distilled from the expert policies via navigation action chunking with
transformer (Nav-ACT). The general policy directly maps visual and
proprioceptive observations to low-level control commands, enabling
generalization to novel robot embodiments. Simulated experiments demonstrated
that X-Nav achieved zero-shot transfer to both unseen embodiments and
photorealistic environments. A scalability study showed that the performance of
X-Nav improves when trained with an increasing number of randomly generated
embodiments. An ablation study confirmed the design choices of X-Nav.
Furthermore, real-world experiments were conducted to validate the
generalizability of X-Nav in real-world environments.

</details>


### [401] [KGN-Pro: Keypoint-Based Grasp Prediction through Probabilistic 2D-3D Correspondence Learning](https://arxiv.org/abs/2507.14820)
*Bingran Chen,Baorun Li,Jian Yang,Yong Liu,Guangyao Zhai*

Main category: cs.RO

TL;DR: KGN-Pro 是一种新的抓取网络，它通过概率 PnP 层集成直接的 3D 优化，从而在保留现有 KGN 的效率和细粒度抓取能力的同时，实现了端到端的学习。


<details>
  <summary>Details</summary>
Motivation: 高层机器人操作任务需要灵活的 6-DoF 抓取估计作为基本功能。以往的方法要么直接从点云数据生成抓取，在处理小物体和传感器噪声方面存在挑战，要么从 RGB 图像推断 3D 信息，这会引入昂贵的注释要求和离散化问题。近期方法通过保留 2D 表示来估计抓取关键点并应用 PnP 算法计算 6-DoF 姿势来缓解一些挑战。然而，这些方法受其非可微分性质和仅依赖 2D 监督的限制，阻碍了对丰富 3D 信息的充分利用。

Method: KGN-Pro 编码配对的 RGB-D 图像以生成关键点图，并输出 2D 置信图，在重新投影误差最小化期间对关键点贡献进行加权。通过概率模型化加权平方重新投影误差，网络有效地将 3D 监督传递给 2D 关键点预测，实现了端到端学习。

Result: 实验表明，KGN-Pro 在抓取覆盖率和成功率方面优于现有方法。

Conclusion: KGN-Pro 在抓取覆盖率和成功率方面优于现有方法。

Abstract: High-level robotic manipulation tasks demand flexible 6-DoF grasp estimation
to serve as a basic function. Previous approaches either directly generate
grasps from point-cloud data, suffering from challenges with small objects and
sensor noise, or infer 3D information from RGB images, which introduces
expensive annotation requirements and discretization issues. Recent methods
mitigate some challenges by retaining a 2D representation to estimate grasp
keypoints and applying Perspective-n-Point (PnP) algorithms to compute 6-DoF
poses. However, these methods are limited by their non-differentiable nature
and reliance solely on 2D supervision, which hinders the full exploitation of
rich 3D information. In this work, we present KGN-Pro, a novel grasping network
that preserves the efficiency and fine-grained object grasping of previous KGNs
while integrating direct 3D optimization through probabilistic PnP layers.
KGN-Pro encodes paired RGB-D images to generate Keypoint Map, and further
outputs a 2D confidence map to weight keypoint contributions during
re-projection error minimization. By modeling the weighted sum of squared
re-projection errors probabilistically, the network effectively transmits 3D
supervision to its 2D keypoint predictions, enabling end-to-end learning.
Experiments on both simulated and real-world platforms demonstrate that KGN-Pro
outperforms existing methods in terms of grasp cover rate and success rate.

</details>


### [402] [CoMoCAVs: Cohesive Decision-Guided Motion Planning for Connected and Autonomous Vehicles with Multi-Policy Reinforcement Learning](https://arxiv.org/abs/2507.14903)
*Pan Hu*

Main category: cs.RO

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Autonomous driving demands reliable and efficient solutions to closely
related problems such as decision-making and motion planning. In this work,
decision-making refers specifically to highway lane selection, while motion
planning involves generating control commands (such as speed and steering) to
reach the chosen lane. In the context of Connected Autonomous Vehicles (CAVs),
achieving both flexible and safe lane selection alongside precise trajectory
execution remains a significant challenge. This paper proposes a framework
called Cohesive Decision-Guided Motion Planning (CDGMP), which tightly
integrates decision-making and motion planning using a Mixture of Experts (MoE)
inspired architecture combined with multi-policy reinforcement learning. By
coordinating multiple specialized sub-networks through a gating mechanism, the
method decomposes the complex driving task into modular components. Each
sub-network focuses on a specific aspect of driving, improving efficiency by
activating only the most relevant modules during inference. This design also
enhances safety through modular specialization. CDGMP improves the adaptability
and robustness of CAVs across diverse traffic scenarios, offering a scalable
solution to real-world autonomy challenges. The architectural principles behind
CDGMP, especially the use of MoE, also provide a strong foundation for other
high-dimensional decision and control tasks. Simulation results (available at
https://youtu.be/_-4OXNHV0UY) demonstrate reliable performance in both lane
selection and motion planning.

</details>


### [403] [One Step Beyond: Feedthrough & Placement-Aware Rectilinear Floorplanner](https://arxiv.org/abs/2507.14914)
*Zhexuan Xu,Jie Wang,Siyuan Xu,Zijie Geng,Mingxuan Yuan,Feng Wu*

Main category: cs.RO

TL;DR: Flora 是一种新的三阶段地板规划器，通过优化线掩码、位置掩码、模块调整和组件放置来解决现有方法的局限性，并在各项性能指标上取得了显著改进。


<details>
  <summary>Details</summary>
Motivation: 现有地板规划方法难以与后续物理设计阶段集成，导致模块内组件放置不佳和过多的跨线。

Method: Flora 采用三阶段方法：1. 使用线掩码和位置掩码进行粗粒度优化（HPWL 和过线）；2. 在固定轮廓下，通过局部调整模块形状来实现零空白布局，进行细粒度优化（过线和组件放置）；3. 利用基于快速树搜索的方法在模块内放置组件，并根据放置结果调整模块边界以实现跨阶段优化。

Result: Flora 在 HPWL、FTpin、FTmod 和组件放置性能方面均优于现有的先进地板规划方法，平均分别降低了 6%、5.16%、29.15%，并提高了 14%。

Conclusion: Flora 在 HPWL、FTpin、FTmod 和组件放置性能方面均优于现有的先进地板规划方法，平均分别降低了 6%、5.16%、29.15%，并提高了 14%。

Abstract: Floorplanning determines the shapes and locations of modules on a chip canvas
and plays a critical role in optimizing the chip's Power, Performance, and Area
(PPA) metrics. However, existing floorplanning approaches often fail to
integrate with subsequent physical design stages, leading to suboptimal
in-module component placement and excessive inter-module feedthrough. To tackle
this challenge, we propose Flora, a three-stage feedthrough and placement aware
rectilinear floorplanner. In the first stage, Flora employs wiremask and
position mask techniques to achieve coarse-grained optimization of HPWL and
feedthrough. In the second stage, under the constraint of a fixed outline,
Flora achieves a zero-whitespace layout by locally resizing module shapes,
thereby performing fine-grained optimization of feedthrough and improving
component placement. In the third stage, Flora utilizes a fast tree
search-based method to efficiently place components-including macros and
standard cells-within each module, subsequently adjusting module boundaries
based on the placement results to enable cross-stage optimization. Experimental
results show that Flora outperforms recent state-of-the-art floorplanning
approaches, achieving an average reduction of 6% in HPWL, 5.16% in FTpin,
29.15% in FTmod, and a 14% improvement in component placement performance.

</details>


### [404] [Digital twin and extended reality for teleoperation of the electric vehicle battery disassembly](https://arxiv.org/abs/2507.14929)
*Tero Kaarlela,Sami Salo,Jose Outeiro*

Main category: cs.RO

TL;DR: 提出一种远程操作的系统，用于安全拆卸和分类电动汽车电池，该系统通过结合远程操作和自动化来提高效率和安全性，并已通过试点研究证明其可用性。


<details>
  <summary>Details</summary>
Motivation: 为了支持向电动汽车的过渡，需要对电动汽车电池进行拆卸和分类，以实现闭环供应链。然而，目前的が手y动拆卸过程存在危险，包括电击和有毒化学物质。

Method: 提出一个远程操作的系统，用于电动汽车电池的安全拆卸和分类。该系统使用RGB摄像头对齐EVB的物理和数字孪生，机器人数字孪生基于ROS中间件。人类操作员可以创建和保存未知EVB类型的拆卸序列，以实现未来的自动化。

Result: 在线试点研究评估了该方法的可用性，结果表明该方法作为一种用户友好型解决方案具有潜力，并能通过减少劳动力依赖和提高电池回收能力来降低成本。

Conclusion: 该混合方法结合了远程操作和自动化，以提高电动汽车电池拆卸和分类的安全性、适应性和效率。在线试点研究表明，该方法具有作为用户友好解决方案的潜力。

Abstract: Disassembling and sorting Electric Vehicle Batteries (EVBs) supports a
sustainable transition to electric vehicles by enabling a closed-loop supply
chain. Currently, the manual disassembly process exposes workers to hazards,
including electrocution and toxic chemicals. We propose a teleoperated system
for the safe disassembly and sorting of EVBs. A human-in-the-loop can create
and save disassembly sequences for unknown EVB types, enabling future
automation. An RGB camera aligns the physical and digital twins of the EVB, and
the digital twin of the robot is based on the Robot Operating System (ROS)
middleware. This hybrid approach combines teleoperation and automation to
improve safety, adaptability, and efficiency in EVB disassembly and sorting.
The economic contribution is realized by reducing labor dependency and
increasing throughput in battery recycling. An online pilot study was set up to
evaluate the usability of the presented approach, and the results demonstrate
the potential as a user-friendly solution.

</details>


### [405] [Designing Robots with, not for: A Co-Design Framework for Empowering Interactions in Forensic Psychiatry](https://arxiv.org/abs/2507.14931)
*Qiaoqiao Ren,Remko Proesmans,Arend Pissens,Lara Dehandschutter,William Denecker,Lotte Rouckhout,Joke Carrette,Peter Vanhopplinus,Tony Belpaeme,Francis wyffels*

Main category: cs.RO

TL;DR: 通过共同设计，让司法精神卫生保健中的患者参与到开发减压机器人的过程中，以解决他们的心理压力和失控感。


<details>
  <summary>Details</summary>
Motivation: 为了解决司法精神卫生保健环境中存在的官僚主义、规避风险和自主性受限等问题，并应对患者因失去对生活的控制而产生的心理压力。

Method: 通过四个共同设计研讨会，让患者、护理人员和治疗师参与进来，共同开发一款能够监测和调节压力的伴侣机器人。

Result: 共同设计过程的发现，强调了在设计过程中赋予患者权力以及根据患者当前情绪状态调整建议的重要性，目标是让患者在设计过程中拥有话语权，并确保每个患者的声音都能被听到。

Conclusion: 该研究强调了在设计过程中赋予患者权力以及根据患者当前情绪状态调整建议的重要性。

Abstract: Forensic mental health care involves the treatment of individuals with severe
mental disorders who have committed violent offences. These settings are often
characterized by high levels of bureaucracy, risk avoidance, and restricted
autonomy. Patients frequently experience a profound loss of control over their
lives, leading to heightened psychological stress-sometimes resulting in
isolation as a safety measure. In this study, we explore how co-design can be
used to collaboratively develop a companion robot that helps monitor and
regulate stress while maintaining tracking of the patients' interaction
behaviours for long-term intervention. We conducted four co-design workshops in
a forensic psychiatric clinic with patients, caregivers, and therapists. Our
process began with the presentation of an initial speculative prototype to
therapists, enabling reflection on shared concerns, ethical risks, and
desirable features. This was followed by a creative ideation session with
patients, a third workshop focused on defining desired functions and emotional
responses, and we are planning a final prototype demo to gather direct patient
feedback. Our findings emphasize the importance of empowering patients in the
design process and adapting proposals based on their current emotional state.
The goal was to empower the patient in the design process and ensure each
patient's voice was heard.

</details>


### [406] [Heterogeneous object manipulation on nonlinear soft surface through linear controller](https://arxiv.org/abs/2507.14967)
*Pratik Ingle,Kasper Støy,Andres Faiña*

Main category: cs.RO

TL;DR: 提出了一种基于 PID 的控制策略，用于在 MANTA-RAY（一种驱动密度降低的自适应非刚性纺织驱动操纵器）上操纵异构物体。该方法通过将倾斜角度控制输出直接映射到执行器命令来简化控制，无需大量训练，并已通过仿真和实验得到验证。


<details>
  <summary>Details</summary>
Motivation: 高密度驱动器阵列会带来相当大的复杂性，并限制了操纵面在现实世界中的应用和利用，因为随着阵列/表面尺寸的增加，系统的维护和控制呈指数级增长。基于学习的控制方法可能有助于简化控制复杂性，但它们需要大量的训练样本，并且难以泛化到异构物体。

Method: 提出了一种基于 PID 的线性闭环反馈控制策略，采用几何变换驱动的 PID 控制器，将倾斜角度控制输出（1D/2D）直接映射到执行器命令。

Result: 通过仿真和物理系统实验验证了该方法，成功操纵了具有不同几何形状、重量和纹理的物体，包括易碎物体（如鸡蛋和苹果）。结果表明，该方法具有高度的泛化性，为软体机器人操纵提供了实用且可靠的解决方案。

Conclusion: 该方法通过 PID 控制策略实现了对异构物体的操纵，无需大量的黑盒训练，可用于软体机器人操纵，且易于实现。

Abstract: Manipulation surfaces indirectly control and reposition objects by actively
modifying their shape or properties rather than directly gripping objects.
These surfaces, equipped with dense actuator arrays, generate dynamic
deformations. However, a high-density actuator array introduces considerable
complexity due to increased degrees of freedom (DOF), complicating control
tasks. High DOF restrict the implementation and utilization of manipulation
surfaces in real-world applications as the maintenance and control of such
systems exponentially increase with array/surface size. Learning-based control
approaches may ease the control complexity, but they require extensive training
samples and struggle to generalize for heterogeneous objects. In this study, we
introduce a simple, precise and robust PID-based linear close-loop feedback
control strategy for heterogeneous object manipulation on MANTA-RAY
(Manipulation with Adaptive Non-rigid Textile Actuation with Reduced Actuation
density). Our approach employs a geometric transformation-driven PID
controller, directly mapping tilt angle control outputs(1D/2D) to actuator
commands to eliminate the need for extensive black-box training. We validate
the proposed method through simulations and experiments on a physical system,
successfully manipulating objects with diverse geometries, weights and
textures, including fragile objects like eggs and apples. The outcomes
demonstrate that our approach is highly generalized and offers a practical and
reliable solution for object manipulation on soft robotic manipulation,
facilitating real-world implementation without prohibitive training demands.

</details>


### [407] [FCRF: Flexible Constructivism Reflection for Long-Horizon Robotic Task Planning with Large Language Models](https://arxiv.org/abs/2507.14975)
*Yufan Song,Jiatao Zhang,Zeng Gu,Qingmiao Liang,Tuocheng Hu,Wei Song,Shiqiang Zhu*

Main category: cs.RO

TL;DR: 提出了一种名为FCRF的新框架，它改进了LLM在机器人任务中的自我纠错能力，使其能够根据任务难度调整反思策略，并从过去的成功和失败中学习，从而提高整体性能。


<details>
  <summary>Details</summary>
Motivation: 现有LLM用于任务规划错误校正的自我反思机制存在灵活性不足的限制。

Method: 提出了一种新颖的导师-行动者架构（FCRF），该架构能够基于任务难度对LLM进行灵活的自我反思，并建设性地整合历史宝贵经验和失败教训。

Result: 在AlfWorld模拟和真实环境中对多种家务任务进行了评估，结果证明FCRF显著提高了复杂长期机器人任务的整体性能和自我反思的灵活性。

Conclusion: FCRF在复杂的长期机器人任务中显著提高了整体性能和自我反思的灵活性。

Abstract: Autonomous error correction is critical for domestic robots to achieve
reliable execution of complex long-horizon tasks. Prior work has explored
self-reflection in Large Language Models (LLMs) for task planning error
correction; however, existing methods are constrained by inflexible
self-reflection mechanisms that limit their effectiveness. Motivated by these
limitations and inspired by human cognitive adaptation, we propose the Flexible
Constructivism Reflection Framework (FCRF), a novel Mentor-Actor architecture
that enables LLMs to perform flexible self-reflection based on task difficulty,
while constructively integrating historical valuable experience with failure
lessons. We evaluated FCRF on diverse domestic tasks through simulation in
AlfWorld and physical deployment in the real-world environment. Experimental
results demonstrate that FCRF significantly improves overall performance and
self-reflection flexibility in complex long-horizon robotic tasks.

</details>


### [408] [CPED-NCBFs: A Conformal Prediction for Expert Demonstration-based Neural Control Barrier Functions](https://arxiv.org/abs/2507.15022)
*Sumeadh MS,Kevin Dsouza,Ravi Prakash*

Main category: cs.RO

TL;DR: 本研究提出CPED-NCBFs方法，通过分裂一致性预测来验证从专家演示中学习到的神经控制障碍函数（NCBF），解决了现有方法界限保守的缺点，并在仿真中验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 解决现有验证技术（如SMT求解器、混合整数规划、区间/边界传播）生成的界限过于保守的问题，以确保学习到的CBFs在整个状态空间中强制执行安全性。

Method: CPED-NCBFs（一种基于分裂一致性预测的验证策略）

Result: 在点质量系统和单轮车模型上进行了验证，证明了所提出理论的有效性。

Conclusion: 该研究提出了一种基于分裂一致性预测的验证策略CPED-NCBFs，用于验证从专家演示中学习到的神经控制障碍函数（NCBF）。

Abstract: Among the promising approaches to enforce safety in control systems, learning
Control Barrier Functions (CBFs) from expert demonstrations has emerged as an
effective strategy. However, a critical challenge remains: verifying that the
learned CBFs truly enforce safety across the entire state space. This is
especially difficult when CBF is represented using neural networks (NCBFs).
Several existing verification techniques attempt to address this problem
including SMT-based solvers, mixed-integer programming (MIP), and interval or
bound-propagation methods but these approaches often introduce loose,
conservative bounds. To overcome these limitations, in this work we use
CPED-NCBFs a split-conformal prediction based verification strategy to verify
the learned NCBF from the expert demonstrations. We further validate our method
on point mass systems and unicycle models to demonstrate the effectiveness of
the proposed theory.

</details>


### [409] [Touch in the Wild: Learning Fine-Grained Manipulation with a Portable Visuo-Tactile Gripper](https://arxiv.org/abs/2507.15062)
*Xinyue Zhu,Binghao Huang,Yunzhu Li*

Main category: cs.RO

TL;DR: 我们开发了一种带有触觉传感器的手持夹持器，并创建了一个跨模态表示学习框架，该框架可以结合视觉和触觉数据，以提高机器人操作的准确性和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 为了解决现有夹持器缺乏触觉传感而无法进行精确操控的问题，并实现视觉和触觉数据的同步收集。

Method: 提出了一种跨模态表示学习框架，该框架整合了视觉和触觉信号，同时保留了它们各自的特征。该学习过程能够产生可解释的表示，这些表示持续关注与物理交互相关的接触区域。

Result: 在测试管插入和基于移液器的流体输送等精细任务上，所提出的方法证明了在外部干扰下的准确性和鲁棒性得到了提高，从而实现了更有效和高效的策略学习。

Conclusion: 这项工作展示了一种集成了触觉传感器的便携式、轻量化夹持器，并提出了一种跨模态表示学习框架，该框架能够整合视觉和触觉信号，从而在抓取和操作任务中提高精确度和鲁棒性。

Abstract: Handheld grippers are increasingly used to collect human demonstrations due
to their ease of deployment and versatility. However, most existing designs
lack tactile sensing, despite the critical role of tactile feedback in precise
manipulation. We present a portable, lightweight gripper with integrated
tactile sensors that enables synchronized collection of visual and tactile data
in diverse, real-world, and in-the-wild settings. Building on this hardware, we
propose a cross-modal representation learning framework that integrates visual
and tactile signals while preserving their distinct characteristics. The
learning procedure allows the emergence of interpretable representations that
consistently focus on contacting regions relevant for physical interactions.
When used for downstream manipulation tasks, these representations enable more
efficient and effective policy learning, supporting precise robotic
manipulation based on multimodal feedback. We validate our approach on
fine-grained tasks such as test tube insertion and pipette-based fluid
transfer, demonstrating improved accuracy and robustness under external
disturbances. Our project page is available at
https://binghao-huang.github.io/touch_in_the_wild/ .

</details>


### [410] [Learning-Based Modeling of a Magnetically Steerable Soft Suction Device for Endoscopic Endonasal Interventions](https://arxiv.org/abs/2507.15155)
*Majid Roshanfar,Alex Zhang,Changyan He,Amir Hooshiar,Dale J. Podolsky,Thomas Looi,Eric Diller*

Main category: cs.RO

TL;DR: 本研究提出了一种基于机器学习的软体机器人建模方法，用于脑肿瘤切除。该方法能精确预测机器人形状，实现亚毫米级精度，为微创手术提供支持。


<details>
  <summary>Details</summary>
Motivation: 本研究旨在解决磁力驱动的软体机器人在微创神经外科手术中，其复杂非线性行为难以精确建模的问题。通过开发一种无需简化物理假设的基于学习的建模框架，实现对设备形状的高精度实时预测，从而提升手术的精确性和安全性。

Method: 本研究采用数据驱动的方法，使用神经网络（NN）和随机森林（RF）两种机器学习模型，对4毫米外径、2毫米内径、40毫米长度的3D打印软体机器人进行建模。设备集成了光纤布拉格光栅（FBG）传感器，用于实时形状反馈。通过5097个实验样本，在不同磁场（0-14 mT）、驱动频率（0.2-1.0 Hz）和末端距离（90-100 mm）下训练模型。通过比较NN和RF模型的性能，发现RF模型在控制点预测和形状重建误差方面表现更优，平均均方根误差分别为0.087毫米和0.064毫米。特征重要性分析表明，磁场分量主要影响远端控制点，而频率和距离则影响基座配置。

Result: 随机森林（RF）模型在控制点预测方面达到了0.087毫米的平均均方根误差，在形状重建方面达到了0.064毫米的平均误差，验证了该模型的有效性。特征重要性分析揭示了不同参数对设备形状的影响规律。

Conclusion: 本研究提出了一种创新的基于学习的建模框架，用于磁力可控软吸入设备，该设备可用于内窥镜下鼻腔脑肿瘤切除术。该框架通过优化模型参数，实现了对设备的亚毫米级形状预测精度和实时推理能力，为开发智能控制的微创神经外科手术软体机器人工具奠定了基础。

Abstract: This letter introduces a novel learning-based modeling framework for a
magnetically steerable soft suction device designed for endoscopic endonasal
brain tumor resection. The device is miniaturized (4 mm outer diameter, 2 mm
inner diameter, 40 mm length), 3D printed using biocompatible SIL 30 material,
and integrates embedded Fiber Bragg Grating (FBG) sensors for real-time shape
feedback. Shape reconstruction is represented using four Bezier control points,
enabling a compact and smooth model of the device's deformation. A data-driven
model was trained on 5,097 experimental samples covering a range of magnetic
field magnitudes (0-14 mT), actuation frequencies (0.2-1.0 Hz), and vertical
tip distances (90-100 mm), using both Neural Network (NN) and Random Forest
(RF) architectures. The RF model outperformed the NN across all metrics,
achieving a mean root mean square error of 0.087 mm in control point prediction
and a mean shape reconstruction error of 0.064 mm. Feature importance analysis
further revealed that magnetic field components predominantly influence distal
control points, while frequency and distance affect the base configuration.
This learning-based approach effectively models the complex nonlinear behavior
of hyperelastic soft robots under magnetic actuation without relying on
simplified physical assumptions. By enabling sub-millimeter shape prediction
accuracy and real-time inference, this work represents an advancement toward
the intelligent control of magnetically actuated soft robotic tools in
minimally invasive neurosurgery.

</details>


### [411] [CHADET: Cross-Hierarchical-Attention for Depth-Completion Using Unsupervised Lightweight Transformer](https://arxiv.org/abs/2507.15189)
*Kevin Christiansen Marsim,Jinwoo Jeon,Yeeun Kim,Myeongwoo Jeong,Hyun Myung*

Main category: cs.RO

TL;DR: CHADET是一种轻量级的深度补全Transformer，通过交叉分层注意力提高了深度图的准确性和效率。


<details>
  <summary>Details</summary>
Motivation: 现有深度补全方法在推理时的计算效率和准确性之间存在显著的权衡。它们对内存和计算的要求很高，不适用于实时应用，因此需要提高深度信息的完整性和准确性，同时提高处理速度，以增强机器人在各种任务中的性能。

Method: CHADET（交叉分层注意力深度补全Transformer）是一种轻量级的深度补全网络，可以从RGB图像和稀疏深度点生成准确的密集深度图。通过深度块提取每个点的特征，并将其传递给同样轻量级的基于Transformer的解码器。

Result: CHADET提高了深度图预测的质量并减少了内存使用，并且在KITTI、NYUv2和VOID数据集上都得到了验证。

Conclusion: CHADET通过在解码器中使用新颖的交叉分层注意力模块，利用来自深度信息的图像特征，提高了深度图预测的质量并减少了内存使用，并且在KITTI、NYUv2和VOID数据集上都得到了验证。

Abstract: Depth information which specifies the distance between objects and current
position of the robot is essential for many robot tasks such as navigation.
Recently, researchers have proposed depth completion frameworks to provide
dense depth maps that offer comprehensive information about the surrounding
environment. However, existing methods show significant trade-offs between
computational efficiency and accuracy during inference. The substantial memory
and computational requirements make them unsuitable for real-time applications,
highlighting the need to improve the completeness and accuracy of depth
information while improving processing speed to enhance robot performance in
various tasks. To address these challenges, in this paper, we propose
CHADET(cross-hierarchical-attention depth-completion transformer), a
lightweight depth-completion network that can generate accurate dense depth
maps from RGB images and sparse depth points. For each pair, its feature is
extracted from the depthwise blocks and passed to the equally lightweight
transformer-based decoder. In the decoder, we utilize the novel
cross-hierarchical-attention module that refines the image features from the
depth information. Our approach improves the quality and reduces memory usage
of the depth map prediction, as validated in both KITTI, NYUv2, and VOID
datasets.

</details>


### [412] [VLM-UDMC: VLM-Enhanced Unified Decision-Making and Motion Control for Urban Autonomous Driving](https://arxiv.org/abs/2507.15266)
*Haichao Liu,Haoren Guo,Pei Liu,Benshan Ma,Yuxiang Zhang,Jun Ma,Tong Heng Lee*

Main category: cs.RO

TL;DR: 提出VLM-UDMC框架，结合VLM和统一决策控制，通过RAG和LSTM实现城市自动驾驶的场景理解、风险感知和实时轨迹预测，提升驾驶性能。


<details>
  <summary>Details</summary>
Motivation: 为了在城市自动驾驶中模仿人类驾驶员的场景理解和风险感知能力，并确保透明度和可解释性。

Method: 提出了一种结合了视觉-语言模型（VLM）和统一决策与运动控制的框架（VLM-UDMC）。该框架的上层慢速系统利用检索增强生成（RAG）和基础模型处理多模态输入并生成风险感知见解，下层快速系统则采用轻量级多核分解LSTM进行实时轨迹预测。

Result: 仿真和真实世界实验表明，VLM-UDMC框架能够有效地利用场景理解和注意力分解做出合理的驾驶决策，提升了整体城市驾驶性能。

Conclusion: VLM-UDMC框架通过集成场景理解和风险感知注意力，有效提高了城市驾驶性能，并实现了决策和运动控制的统一。

Abstract: Scene understanding and risk-aware attentions are crucial for human drivers
to make safe and effective driving decisions. To imitate this cognitive ability
in urban autonomous driving while ensuring the transparency and
interpretability, we propose a vision-language model (VLM)-enhanced unified
decision-making and motion control framework, named VLM-UDMC. This framework
incorporates scene reasoning and risk-aware insights into an upper-level slow
system, which dynamically reconfigures the optimal motion planning for the
downstream fast system. The reconfiguration is based on real-time environmental
changes, which are encoded through context-aware potential functions. More
specifically, the upper-level slow system employs a two-step reasoning policy
with Retrieval-Augmented Generation (RAG), leveraging foundation models to
process multimodal inputs and retrieve contextual knowledge, thereby generating
risk-aware insights. Meanwhile, a lightweight multi-kernel decomposed LSTM
provides real-time trajectory predictions for heterogeneous traffic
participants by extracting smoother trend representations for short-horizon
trajectory prediction. The effectiveness of the proposed VLM-UDMC framework is
verified via both simulations and real-world experiments with a full-size
autonomous vehicle. It is demonstrated that the presented VLM-UDMC effectively
leverages scene understanding and attention decomposition for rational driving
decisions, thus improving the overall urban driving performance. Our
open-source project is available at https://github.com/henryhcliu/vlmudmc.git.

</details>


### [413] [RepILN: Reparameterized Inertial Localization Network](https://arxiv.org/abs/2507.15293)
*Shanshan Zhang,Tianshui Wen,Siyue Wang,Qi Zhang,Ziheng Zhou,Lingxiang Zheng,Yu Yang*

Main category: cs.RO

TL;DR: 一种新的惯性定位方法，通过多分支训练、单路径推理、稀疏注意力和门控卷积，提高了效率和准确性，尤其在处理长期依赖性方面。


<details>
  <summary>Details</summary>
Motivation: 为了解决数据驱动的惯性定位方法依赖复杂网络架构导致计算资源需求高，以及忽略运动轨迹长期依赖性导致定位性能受限的问题。

Method: 提出了一种重新参数化的惯性定位网络，该网络在训练时采用多分支结构以增强特征提取，在推理时则转换为等效的单路径架构以提高参数效率。此外，引入了时间尺度稀疏注意力机制来捕捉运动轨迹中的长期依赖关系，并结合门控卷积单元来整合长程依赖与局部细粒度特征。

Result: 该方法在RoNIN数据集上实现了比RoNIN-ResNet低2.59%的绝对轨迹误差（ATE），同时参数量减少了3.86%，展示了在准确性和模型紧凑性之间的良好权衡。

Conclusion: 该研究提出了一种重新参数化的惯性定位网络，该网络在训练时使用多分支结构增强特征提取，在推理时转换为等效的单路径架构以提高参数效率。通过引入时间尺度稀疏注意力机制来捕捉运动轨迹中的长期依赖关系，并结合门控卷积单元整合长程依赖与局部细粒度特征，实现了准确性和模型紧凑性之间的良好权衡。实验证明，在RoNIN数据集上，该方法相较于RoNIN-ResNet，绝对轨迹误差（ATE）降低了2.59%，同时参数量减少了3.86%。

Abstract: Inertial localization is regarded as a promising positioning solution for
consumer-grade IoT devices due to its cost-effectiveness and independence from
external infrastructure. However, data-driven inertial localization methods
often rely on increasingly complex network architectures to improve accuracy,
which challenges the limited computational resources of IoT devices. Moreover,
these methods frequently overlook the importance of modeling long-term
dependencies in inertial measurements - a critical factor for accurate
trajectory reconstruction - thereby limiting localization performance. To
address these challenges, we propose a reparameterized inertial localization
network that uses a multi-branch structure during training to enhance feature
extraction. At inference time, this structure is transformed into an equivalent
single-path architecture to improve parameter efficiency. To further capture
long-term dependencies in motion trajectories, we introduce a temporal-scale
sparse attention mechanism that selectively emphasizes key trajectory segments
while suppressing noise. Additionally, a gated convolutional unit is
incorporated to effectively integrate long-range dependencies with local
fine-grained features. Extensive experiments on public benchmarks demonstrate
that our method achieves a favorable trade-off between accuracy and model
compactness. For example, on the RoNIN dataset, our approach reduces the
Absolute Trajectory Error (ATE) by 2.59% compared to RoNIN-ResNet while
reducing the number of parameters by 3.86%.

</details>


### [414] [Low-Latency Event-Based Velocimetry for Quadrotor Control in a Narrow Pipe](https://arxiv.org/abs/2507.15444)
*Leonard Bauersfeld,Davide Scaramuzza*

Main category: cs.RO

TL;DR: 本研究介绍了首个在狭窄管道中通过实时流场测量进行闭环控制的四旋翼飞行器系统，解决了复杂气动环境下的悬停和机动挑战。


<details>
  <summary>Details</summary>
Motivation: 为了克服在管道等狭窄空间中四旋翼飞行器面临的不稳定、自感气动干扰问题，以及现有技术在规避气流回流或悬停稳定性方面的局限性。

Method: 本研究提出了一种利用实时流场测量进行闭环控制的系统，包括低延迟、基于事件的烟雾速测法来估计气流，以及一个基于循环卷积神经网络的扰动估计器来推断实时力和扭矩扰动，并整合到一个基于强化学习的控制器中。

Result: 所提出的流反馈控制系统能够有效地抵消瞬态气动效应，尤其在管道横向平移机动时，能够防止与管道壁发生碰撞。

Conclusion: 这项工作首次展示了由实时流场测量信息驱动的闭环控制的飞行器，它能够成功地在狭窄管道中悬停，并能有效应对复杂的空气动力学挑战。

Abstract: Autonomous quadrotor flight in confined spaces such as pipes and tunnels
presents significant challenges due to unsteady, self-induced aerodynamic
disturbances. Very recent advances have enabled flight in such conditions, but
they either rely on constant motion through the pipe to mitigate airflow
recirculation effects or suffer from limited stability during hovering. In this
work, we present the first closed-loop control system for quadrotors for
hovering in narrow pipes that leverages real-time flow field measurements. We
develop a low-latency, event-based smoke velocimetry method that estimates
local airflow at high temporal resolution. This flow information is used by a
disturbance estimator based on a recurrent convolutional neural network, which
infers force and torque disturbances in real time. The estimated disturbances
are integrated into a learning-based controller trained via reinforcement
learning. The flow-feedback control proves particularly effective during
lateral translation maneuvers in the pipe cross-section. There, the real-time
disturbance information enables the controller to effectively counteract
transient aerodynamic effects, thereby preventing collisions with the pipe
wall. To the best of our knowledge, this work represents the first
demonstration of an aerial robot with closed-loop control informed by real-time
flow field measurements. This opens new directions for research on flight in
aerodynamically complex environments. In addition, our work also sheds light on
the characteristic flow structures that emerge during flight in narrow,
circular pipes, providing new insights at the intersection of robotics and
fluid dynamics.

</details>


### [415] [The Emergence of Deep Reinforcement Learning for Path Planning](https://arxiv.org/abs/2507.15469)
*Thanh Thi Nguyen,Saeid Nahavandi,Imran Razzak,Dung Nguyen,Nhat Truong Pham,Quoc Viet Hung Nguyen*

Main category: cs.RO

TL;DR: 该调查总结了用于自主导航的传统路径规划技术和深度强化学习 (DRL) 的最新进展，重点介绍了混合方法及其在机器人和车辆中的应用，并指出了未来的研究方向。


<details>
  <summary>Details</summary>
Motivation: 应对复杂动态环境中对自主系统的日益增长的需求，并为该领域的研究提供全面的概述。

Method: 对传统方法（如图搜索、线性规划、进化计算）和深度强化学习 (DRL) 在路径规划中的应用进行了分类和分析，重点关注其创新、实现、优势和局限性。

Result: 对传统和基于学习的路径规划方法进行了广泛的讨论，重点介绍了混合方法，并确定了未来的研究方向。

Conclusion: 该调查全面概述了用于自主系统路径规划的传统方法和深度强化学习 (DRL) 的最新进展，重点介绍了自动驾驶汽车、无人机和机器人平台。它对两种范例中的关键算法进行了分类，讨论了它们的优缺点，并强调了混合方法，这些方法结合了 DRL 的适应性和经典方法的确定性。

Abstract: The increasing demand for autonomous systems in complex and dynamic
environments has driven significant research into intelligent path planning
methodologies. For decades, graph-based search algorithms, linear programming
techniques, and evolutionary computation methods have served as foundational
approaches in this domain. Recently, deep reinforcement learning (DRL) has
emerged as a powerful method for enabling autonomous agents to learn optimal
navigation strategies through interaction with their environments. This survey
provides a comprehensive overview of traditional approaches as well as the
recent advancements in DRL applied to path planning tasks, focusing on
autonomous vehicles, drones, and robotic platforms. Key algorithms across both
conventional and learning-based paradigms are categorized, with their
innovations and practical implementations highlighted. This is followed by a
thorough discussion of their respective strengths and limitations in terms of
computational efficiency, scalability, adaptability, and robustness. The survey
concludes by identifying key open challenges and outlining promising avenues
for future research. Special attention is given to hybrid approaches that
integrate DRL with classical planning techniques to leverage the benefits of
both learning-based adaptability and deterministic reliability, offering
promising directions for robust and resilient autonomous navigation.

</details>


### [416] [All-UWB SLAM Using UWB Radar and UWB AOA](https://arxiv.org/abs/2507.15474)
*Charith Premachandra,Achala Athukorala,U-Xuan Tan*

Main category: cs.RO

TL;DR: 本研究提出了一种将UWB到达角（AOA）测量集成到UWB雷达SLAM系统中的新方法，以解决特征稀疏环境下的SLAM挑战。实验证明，该方法在视觉受限且特征缺失的环境中实现了准确且可扩展的SLAM。


<details>
  <summary>Details</summary>
Motivation: 现有的基于UWB雷达的SLAM方法主要依赖于环境中的可区分特征，但在特征稀疏的环境中存在局限性。因此，需要一种能够克服这些限制的新方法。

Method: 提出了一种新的方法，将UWB到达角（AOA）测量集成到基于UWB雷达的SLAM系统中，以提高在特征缺失环境中的SLAM的准确性和可扩展性。AOA测量是通过在映射过程中由机器人动态部署的UWB锚定标签单元获得的。

Result: 实验结果表明，将UWB AOA单元与UWB雷达集成，可以在视觉受限且特征缺失的环境中实现SLAM。

Conclusion: UWB雷达可以用于视觉受限和特征缺失的环境下的SLAM，通过融合AOA测量可以提高SLAM的准确性和可扩展性。

Abstract: There has been a growing interest in autonomous systems designed to operate
in adverse conditions (e.g. smoke, dust), where the visible light spectrum
fails. In this context, Ultra-wideband (UWB) radar is capable of penetrating
through such challenging environmental conditions due to the lower frequency
components within its broad bandwidth. Therefore, UWB radar has emerged as a
potential sensing technology for Simultaneous Localization and Mapping (SLAM)
in vision-denied environments where optical sensors (e.g. LiDAR, Camera) are
prone to failure. Existing approaches involving UWB radar as the primary
exteroceptive sensor generally extract features in the environment, which are
later initialized as landmarks in a map. However, these methods are constrained
by the number of distinguishable features in the environment. Hence, this paper
proposes a novel method incorporating UWB Angle of Arrival (AOA) measurements
into UWB radar-based SLAM systems to improve the accuracy and scalability of
SLAM in feature-deficient environments. The AOA measurements are obtained using
UWB anchor-tag units which are dynamically deployed by the robot in featureless
areas during mapping of the environment. This paper thoroughly discusses
prevailing constraints associated with UWB AOA measurement units and presents
solutions to overcome them. Our experimental results show that integrating UWB
AOA units with UWB radar enables SLAM in vision-denied feature-deficient
environments.

</details>


### [417] [The Constitutional Controller: Doubt-Calibrated Steering of Compliant Agents](https://arxiv.org/abs/2507.15478)
*Simon Kohaut,Felix Divo,Navid Hamid,Benedict Flade,Julian Eggert,Devendra Singh Dhami,Kristian Kersting*

Main category: cs.RO

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Ensuring reliable and rule-compliant behavior of autonomous agents in
uncertain environments remains a fundamental challenge in modern robotics. Our
work shows how neuro-symbolic systems, which integrate probabilistic, symbolic
white-box reasoning models with deep learning methods, offer a powerful
solution to this challenge. This enables the simultaneous consideration of
explicit rules and neural models trained on noisy data, combining the strength
of structured reasoning with flexible representations. To this end, we
introduce the Constitutional Controller (CoCo), a novel framework designed to
enhance the safety and reliability of agents by reasoning over deep
probabilistic logic programs representing constraints such as those found in
shared traffic spaces. Furthermore, we propose the concept of self-doubt,
implemented as a probability density conditioned on doubt features such as
travel velocity, employed sensors, or health factors. In a real-world aerial
mobility study, we demonstrate CoCo's advantages for intelligent autonomous
systems to learn appropriate doubts and navigate complex and uncertain
environments safely and compliantly.

</details>


### [418] [Robots for Kiwifruit Harvesting and Pollination](https://arxiv.org/abs/2507.15484)
*Jamie Bell*

Main category: cs.RO

TL;DR: 开发了一个集授粉和采摘功能于一体的机器人系统，用于棚架式猕猴桃园，并解决了导航难题。


<details>
  <summary>Details</summary>
Motivation: 为了提高猕猴桃种植的效率和自动化水平，克服在棚架结构下机器人导航和作业的挑战。

Method: 开发了自动授粉和采摘机器人，包括设计和测试猕猴桃采摘机制、使用喷洒器进行授粉、通过激光雷达和计算机视觉进行导航。

Result: 采摘机制能够可靠地采摘猕猴桃，可触及 80% 以上的果实，优于先前技术。授粉系统能在一定速度下进行，并通过调整喷洒臂高度来优化喷洒效果。在棚架猕猴桃园中开发并测试了基于 3D 激光雷达的导航系统，实现了超过 30 公里的自主驾驶，并验证了计算机视觉在行检测和跟随方面的有效性。

Conclusion: 该研究展示了一种用于猕猴桃的自动化农艺作业机器人系统，包括授粉和采摘，并解决了在特定棚架结构下的导航挑战。

Abstract: This research was a part of a project that developed mobile robots that
performed targeted pollen spraying and automated harvesting in pergola
structured kiwifruit orchards. Multiple kiwifruit detachment mechanisms were
designed and field testing of one of the concepts showed that the mechanism
could reliably pick kiwifruit. Furthermore, this kiwifruit detachment mechanism
was able to reach over 80 percent of fruit in the cluttered kiwifruit canopy,
whereas the previous state of the art mechanism was only able to reach less
than 70 percent of the fruit. Artificial pollination was performed by detecting
flowers and then spraying pollen in solution onto the detected flowers from a
line of sprayers on a boom, while driving at up to 1.4 ms-1. In addition, the
height of the canopy was measured and the spray boom was moved up and down to
keep the boom close enough to the flowers for the spray to reach the flowers,
while minimising collisions with the canopy. Mobile robot navigation was
performed using a 2D lidar in apple orchards and vineyards. Lidar navigation in
kiwifruit orchards was more challenging because the pergola structure only
provides a small amount of data for the direction of rows, compared to the
amount of data from the overhead canopy, the undulating ground and other
objects in the orchards. Multiple methods are presented here for extracting
structure defining features from 3D lidar data in kiwifruit orchards. In
addition, a 3D lidar navigation system -- which performed row following, row
end detection and row end turns -- was tested for over 30 km of autonomous
driving in kiwifruit orchards. Computer vision algorithms for row detection and
row following were also tested. The computer vision algorithm worked as well as
the 3D lidar row following method in testing.

</details>


### [419] [GR-3 Technical Report](https://arxiv.org/abs/2507.15493)
*Chilam Cheang,Sijin Chen,Zhongren Cui,Yingdong Hu,Liqun Huang,Tao Kong,Hang Li,Yifeng Li,Yuxiao Liu,Xiao Ma,Hao Niu,Wenxuan Ou,Wanli Peng,Zeyu Ren,Haixin Shi,Jiawen Tian,Hongtao Wu,Xin Xiao,Yuyang Xiao,Jiafeng Xu,Yichu Yang*

Main category: cs.RO

TL;DR: GR-3 是一个大规模 VLA 模型，可以高效地适应新环境和任务，并在各种具有挑战性的任务中超越基线方法。


<details>
  <summary>Details</summary>
Motivation: 旨在构建能够协助人类日常生活的一般机器人策略。

Method: GR-3 是一个大规模视觉-语言-动作（VLA）模型，它通过以下方式进行训练：使用网络规模的视觉-语言数据进行协同训练，使用通过 VR 设备收集的人类轨迹数据进行高效微调，以及使用机器人轨迹数据进行有效的模仿学习。此外，还引入了多功能双臂移动机器人 ByteMini。

Result: GR-3 在泛化到新颖物体、环境和涉及抽象概念的指令方面表现出卓越的能力。它还可以有效地进行微调，并能处理需要双臂操作和移动的任务。

Conclusion: GR-3 在各种具有挑战性的任务中超越了最先进的基线方法 $\pi_0$。

Abstract: We report our recent progress towards building generalist robot policies, the
development of GR-3. GR-3 is a large-scale vision-language-action (VLA) model.
It showcases exceptional capabilities in generalizing to novel objects,
environments, and instructions involving abstract concepts. Furthermore, it can
be efficiently fine-tuned with minimal human trajectory data, enabling rapid
and cost-effective adaptation to new settings. GR-3 also excels in handling
long-horizon and dexterous tasks, including those requiring bi-manual
manipulation and mobile movement, showcasing robust and reliable performance.
These capabilities are achieved through a multi-faceted training recipe that
includes co-training with web-scale vision-language data, efficient fine-tuning
from human trajectory data collected via VR devices, and effective imitation
learning with robot trajectory data. In addition, we introduce ByteMini, a
versatile bi-manual mobile robot designed with exceptional flexibility and
reliability, capable of accomplishing a wide range of tasks when integrated
with GR-3. Through extensive real-world experiments, we show GR-3 surpasses the
state-of-the-art baseline method, $\pi_0$, on a wide variety of challenging
tasks. We hope GR-3 can serve as a step towards building generalist robots
capable of assisting humans in daily life.

</details>


### [420] [CLEVER: Stream-based Active Learning for Robust Semantic Perception from Human Instructions](https://arxiv.org/abs/2507.15499)
*Jongseok Lee,Timo Birr,Rudolph Triebel,Tamim Asfour*

Main category: cs.RO

TL;DR: CLEVER是一个创新的主动学习系统，通过整合人类智慧和贝叶斯方法，显著提升了机器人语义感知的鲁棒性和适应性。


<details>
  <summary>Details</summary>
Motivation: 为了提高深度神经网络（DNN）在处理数据流时的鲁棒性，并实现持续学习和适应能力。

Method: 通过贝叶斯方法结合先验知识来编码领域知识，并设计了一个能处理数据流、在遇到失败时寻求人类支持并根据人类指令在线调整DNN的系统。

Result: 在人形和可变形物体上进行了实验和用户验证研究，展示了CLEVER系统的能力。

Conclusion: CLEVER系统首次在真实机器人上实现了基于流的主动学习，证明了基于DNN的语义感知的鲁棒性可以得到实际提升。

Abstract: We propose CLEVER, an active learning system for robust semantic perception
with Deep Neural Networks (DNNs). For data arriving in streams, our system
seeks human support when encountering failures and adapts DNNs online based on
human instructions. In this way, CLEVER can eventually accomplish the given
semantic perception tasks. Our main contribution is the design of a system that
meets several desiderata of realizing the aforementioned capabilities. The key
enabler herein is our Bayesian formulation that encodes domain knowledge
through priors. Empirically, we not only motivate CLEVER's design but further
demonstrate its capabilities with a user validation study as well as
experiments on humanoid and deformable objects. To our knowledge, we are the
first to realize stream-based active learning on a real robot, providing
evidence that the robustness of the DNN-based semantic perception can be
improved in practice. The project website can be accessed at
https://sites.google.com/view/thecleversystem.

</details>


### [421] [Estimation of Payload Inertial Parameters from Human Demonstrations by Hand Guiding](https://arxiv.org/abs/2507.15604)
*Johannes Hartwig,Philipp Lienhardt,Dominik Henrich*

Main category: cs.RO

TL;DR: 该研究提出了一种在机器人手动引导过程中估计其有效载荷参数（PIP）的方法，无需专门的校准步骤。该方法利用任务中的非接触运动来估计PIP，但结果显示，虽然质量估计准确，但质心和惯性张量的估计会受到噪声和激励不足的影响，这表明需要足够的有效载荷加速度才能进行准确估计。


<details>
  <summary>Details</summary>
Motivation: 为了让缺乏编程知识的非专业用户能够更有效地对协作机器人进行示教编程，需要消除对专用PIP校准的需求，从而实现灵活的机器人工具更换。

Method: 该方法利用演示任务中包含的非接触运动部分，利用已建立的估计技术来估计机器人的PIP。

Result: 估计结果表明，有效载荷质量的估计是准确的，而质心和惯性张量则受到噪声和缺乏激励的影响。

Conclusion: 该方法证明了在手动引导过程中进行PIP估计的可行性，但也强调了准确估计需要足够的有效载荷加速度。

Abstract: As the availability of cobots increases, it is essential to address the needs
of users with little to no programming knowledge to operate such systems
efficiently. Programming concepts often use intuitive interaction modalities,
such as hand guiding, to address this. When programming in-contact motions,
such frameworks require knowledge of the robot tool's payload inertial
parameters (PIP) in addition to the demonstrated velocities and forces to
ensure effective hybrid motion-force control. This paper aims to enable
non-expert users to program in-contact motions more efficiently by eliminating
the need for a dedicated PIP calibration, thereby enabling flexible robot tool
changes. Since demonstrated tasks generally also contain motions with
non-contact, our approach uses these parts to estimate the robot's PIP using
established estimation techniques. The results show that the estimation of the
payload's mass is accurate, whereas the center of mass and the inertia tensor
are affected by noise and a lack of excitation. Overall, these findings show
the feasibility of PIP estimation during hand guiding but also highlight the
need for sufficient payload accelerations for an accurate estimation.

</details>


### [422] [A Universal Vehicle-Trailer Navigation System with Neural Kinematics and Online Residual Learning](https://arxiv.org/abs/2507.15607)
*Yanbo Chen,Yunzhe Tan,Yaojia Wang,Zhengzhe Xu,Junbo Tan,Xueqian Wang*

Main category: cs.RO

TL;DR: 一种新的车辆-拖车导航系统，使用混合运动学模型和在线残差学习，并通过模型预测控制实现安全运动规划。


<details>
  <summary>Details</summary>
Motivation: 自主导航车辆-拖车系统在机场、超市和音乐会场馆等环境中至关重要，在这些环境中需要各种类型的拖车在不同负载和条件下进行导航。然而，准确建模此类系统仍然具有挑战性，特别是对于带脚轮的拖车。

Method: 提出了一种新的通用车辆-拖车导航系统，集成了混合名义运动学模型（结合了经典的非完整约束和基于神经网络的拖车运动学）以及一个轻量级的在线残差学习模块，用于实时校正模型差异和干扰。此外，还开发了一个具有加权模型组合策略的模型预测控制框架，以提高长视距预测的准确性并确保更安全的运动规划。

Result: 通过大量真实世界的实验，涉及多种拖车类型和不同的负载条件，证明了该方法具有稳健的性能，无需手动调优或拖车特定的校准。

Conclusion: 该方法在真实世界实验中得到了验证，涉及多种拖车类型和不同的负载条件，在没有手动调整或拖车特定校准的情况下表现出稳健的性能。

Abstract: Autonomous navigation of vehicle-trailer systems is crucial in environments
like airports, supermarkets, and concert venues, where various types of
trailers are needed to navigate with different payloads and conditions.
However, accurately modeling such systems remains challenging, especially for
trailers with castor wheels. In this work, we propose a novel universal
vehicle-trailer navigation system that integrates a hybrid nominal kinematic
model--combining classical nonholonomic constraints for vehicles and neural
network-based trailer kinematics--with a lightweight online residual learning
module to correct real-time modeling discrepancies and disturbances.
Additionally, we develop a model predictive control framework with a weighted
model combination strategy that improves long-horizon prediction accuracy and
ensures safer motion planning. Our approach is validated through extensive
real-world experiments involving multiple trailer types and varying payload
conditions, demonstrating robust performance without manual tuning or
trailer-specific calibration.

</details>


### [423] [Optimizing Force Signals from Human Demonstrations of In-Contact Motions](https://arxiv.org/abs/2507.15608)
*Johannes Hartwig,Fabian Viessmann,Dominik Henrich*

Main category: cs.RO

TL;DR: 该研究提出了一种优化机器人编程中演示力信号的方法，通过滤波和峰值检测来提高信号质量，从而改善人机交互。


<details>
  <summary>Details</summary>
Motivation: 对于非机器人编程专家来说，在进行机器人编程时，动觉引导是一种直观的输入方法，尤其是在进行机器人编程的接触任务时。然而，人类演示中的输入信号可能不精确或带有噪声，这在直接复现运动或将信号用作机器学习方法的输入时会带来问题。

Method: 本研究探索了不同的信号过滤方法，并提出了一种用于处理首次接触偏差的峰值检测方法。此外，还分析了关键参数对过滤方法的影响。

Result: 通过提出的方法，单个运动的质量可以根据错误标准提高多达 20%。

Conclusion: 该研究通过优化力信号以更好地匹配演示信号中的人类意图，提高了机器人编程的可用性以及人机交互的质量。

Abstract: For non-robot-programming experts, kinesthetic guiding can be an intuitive
input method, as robot programming of in-contact tasks is becoming more
prominent. However, imprecise and noisy input signals from human demonstrations
pose problems when reproducing motions directly or using the signal as input
for machine learning methods. This paper explores optimizing force signals to
correspond better to the human intention of the demonstrated signal. We compare
different signal filtering methods and propose a peak detection method for
dealing with first-contact deviations in the signal. The evaluation of these
methods considers a specialized error criterion between the input and the
human-intended signal. In addition, we analyze the critical parameters'
influence on the filtering methods. The quality for an individual motion could
be increased by up to \SI{20}{\percent} concerning the error criterion. The
proposed contribution can improve the usability of robot programming and the
interaction between humans and robots.

</details>


### [424] [EMP: Executable Motion Prior for Humanoid Robot Standing Upper-body Motion Imitation](https://arxiv.org/abs/2507.15649)
*Haocheng Xu,Haodong Zhang,Zhenghan Chen,Rong Xiong*

Main category: cs.RO

TL;DR: 该研究提出了一种基于强化学习的框架，通过重定向网络和可执行运动先验（EMP）模块，使人形机器人能够在模仿人类上身运动的同时，保持站立稳定性。


<details>
  <summary>Details</summary>
Motivation: 为了支持人形机器人在执行操纵任务时，在适应上身运动的同时保持稳定的站立，但机器人站立位置的可控范围有限，影响了整个身体的稳定性。

Method: 提出了一种基于强化学习的框架，包括一个重定向网络，用于生成大规模上身运动数据集以训练强化学习策略，并提出了一种可执行运动先验（EMP）模块，根据机器人当前状态调整输入目标运动，以提高站立稳定性并尽量减少运动幅度的变化。

Result: 该框架能够让机器人跟踪上身运动目标，并通过EMP模块提高了站立稳定性，同时尽量减少了运动幅度的变化。

Conclusion: 该框架通过仿真和实际测试进行了评估，证明了其在人形机器人上模仿人类上身运动并保持整体稳定性的实际可行性。

Abstract: To support humanoid robots in performing manipulation tasks, it is essential
to study stable standing while accommodating upper-body motions. However, the
limited controllable range of humanoid robots in a standing position affects
the stability of the entire body. Thus we introduce a reinforcement learning
based framework for humanoid robots to imitate human upper-body motions while
maintaining overall stability. Our approach begins with designing a retargeting
network that generates a large-scale upper-body motion dataset for training the
reinforcement learning (RL) policy, which enables the humanoid robot to track
upper-body motion targets, employing domain randomization for enhanced
robustness. To avoid exceeding the robot's execution capability and ensure
safety and stability, we propose an Executable Motion Prior (EMP) module, which
adjusts the input target movements based on the robot's current state. This
adjustment improves standing stability while minimizing changes to motion
amplitude. We evaluate our framework through simulation and real-world tests,
demonstrating its practical applicability.

</details>


### [425] [Data-Driven MPC with Data Selection for Flexible Cable-Driven Robotic Arms](https://arxiv.org/abs/2507.15677)
*Huayue Liang,Yanbo Chen,Hongyang Cheng,Yanzhao Yu,Shoujie Li,Junbo Tan,Xueqian Wang,Long Zeng*

Main category: cs.RO

TL;DR: 本研究提出了一种数据驱动的MPC方法，用于控制柔性 kabel 驱动的机器人手臂 (FCRA)，解决了 kabel 的固有特性带来的建模和控制挑战。该方法无需物理模型，并通过数据选择算法 (DSA) 优化了求解时间。实验结果表明，该方法在定位精度和跟踪误差方面均优于传统的PID方法。


<details>
  <summary>Details</summary>
Motivation: 柔性 kabel 驱动的机器人手臂 (FCRA) 提供灵巧和顺从的运动。然而，kabel 的固有特性，例如弹性、滞后和摩擦，通常会导致建模和控制方面的特定困难。

Method: 提出一种仅依赖输入输出数据的模型预测控制（MPC）方法，无需物理模型，用于提高FCRA的控制精度。开发了基于输入输出数据的隐式模型，并将其集成到MPC优化框架中。引入数据选择算法（DSA）来筛选最能表征系统的数，将每步的求解时间减少到大约4毫秒，提高了近80%。

Result: 所提出的方法在真实的FCRA平台上得到了验证，包括五点定位精度测试、五点响应跟踪测试以及字母绘制的轨迹跟踪。结果表明，平均定位精度约为2.070毫米。此外，与平均跟踪误差为1.418度的PID方法相比，所提出的方法实现了0.541度的平均跟踪误差。

Conclusion: 所提出的基于数据的方法在FCRA的控制精度方面优于PID方法，平均定位精度约为2.070毫米，平均跟踪误差为0.541度，优于PID方法的1.418度。

Abstract: Flexible cable-driven robotic arms (FCRAs) offer dexterous and compliant
motion. Still, the inherent properties of cables, such as resilience,
hysteresis, and friction, often lead to particular difficulties in modeling and
control. This paper proposes a model predictive control (MPC) method that
relies exclusively on input-output data, without a physical model, to improve
the control accuracy of FCRAs. First, we develop an implicit model based on
input-output data and integrate it into an MPC optimization framework. Second,
a data selection algorithm (DSA) is introduced to filter the data that best
characterize the system, thereby reducing the solution time per step to
approximately 4 ms, which is an improvement of nearly 80%. Lastly, the
influence of hyperparameters on tracking error is investigated through
simulation. The proposed method has been validated on a real FCRA platform,
including five-point positioning accuracy tests, a five-point response tracking
test, and trajectory tracking for letter drawing. The results demonstrate that
the average positioning accuracy is approximately 2.070 mm. Moreover, compared
to the PID method with an average tracking error of 1.418{\deg}, the proposed
method achieves an average tracking error of 0.541{\deg}.

</details>


### [426] [Strong, Accurate, and Low-Cost Robot Manipulator](https://arxiv.org/abs/2507.15693)
*Georges Chebly,Spencer Little,Nisal Perera,Aliya Abedeen,Ken Suzuki,Donghyun Kim*

Main category: cs.RO

TL;DR: Forte：一款低成本（<215美元）、3D打印、6自由度机器人手臂，性能接近工业级，适用于教育和研究。


<details>
  <summary>Details</summary>
Motivation: 设计一款低成本、接近工业级性能的6自由度（6-DoF）3D打印机器人手臂，以满足课堂教学和AI实验等广泛应用的需求。

Method: 提出了一种结合了羊毛绳驱动、同步带、张紧机构和拓扑优化3D打印结构的低成本机械设计，以最小化齿轮游隙并保持控制保真度。

Result: Forte机器人手臂实现了0.63公斤的负载能力、0.467米的机械臂长度和亚毫米级的重复定位精度，同时材料成本低于215美元。

Conclusion: Forte机器人手臂实现了接近工业级性能的低成本3D打印解决方案，适用于教育和AI研究。

Abstract: This paper presents Forte, a fully 3D-printable, 6-DoF robotic arm designed
to achieve near industrial-grade performance - 0.63 kg payload, 0.467 m reach,
and sub-millimeter repeatability - at a material cost under $215. As an
accessible robot for broad applications across classroom education to AI
experiments, Forte pushes forward the performance limitations of existing
low-cost educational arms. We introduce a cost-effective mechanical design that
combines capstan-based cable drives, timing belts, simple tensioning
mechanisms, and lightweight 3D-printed structures, along with topology
optimization for structural stiffness. Through careful drivetrain engineering,
we minimize backlash and maintain control fidelity without relying on
high-power electronics or expensive manufacturing processes. Experimental
validation demonstrates that Forte achieves high repeatability and load
capacity, offering a compelling robotic platform for both classroom instruction
and advanced robotics research.

</details>


### [427] [Selective Densification for Rapid Motion Planning in High Dimensions with Narrow Passages](https://arxiv.org/abs/2507.15710)
*Lu Huang,Lingxiao Meng,Jiankun Wang,Xingjian Jing*

Main category: cs.RO

TL;DR: 一种新的基于采样的规划方法，通过多分辨率采样和在线探索来提高效率和通用性，在复杂环境中表现优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有方法在复杂配置空间中性能会下降，并且缺乏通用性或需要大量先验训练。

Method: 提出了一种简单的基于采样的规划框架及其双向版本，通过以不同分辨率探测配置空间，并优先探索稀疏样本来克服采样效率低的问题。

Result: 在SE(2)、SE(3)和R^14以及Franka Emika Panda机器人的约束工作空间中，该方法优于几种最先进的基于采样的规划器。

Conclusion: 该方法通过无缝集成不同粒度的规划，可以处理复杂的配置空间，同时保持规划速度和完整性。

Abstract: Sampling-based algorithms are widely used for motion planning in
high-dimensional configuration spaces. However, due to low sampling efficiency,
their performance often diminishes in complex configuration spaces with narrow
corridors. Existing approaches address this issue using handcrafted or learned
heuristics to guide sampling toward useful regions. Unfortunately, these
strategies often lack generalizability to various problems or require extensive
prior training. In this paper, we propose a simple yet efficient sampling-based
planning framework along with its bidirectional version that overcomes these
issues by integrating different levels of planning granularity. Our approach
probes configuration spaces with uniform random samples at varying resolutions
and explores these multi-resolution samples online with a bias towards sparse
samples when traveling large free configuration spaces. By seamlessly
transitioning between sparse and dense samples, our approach can navigate
complex configuration spaces while maintaining planning speed and completeness.
The simulation results demonstrate that our approach outperforms several
state-of-the-art sampling-based planners in $\mathbb{SE}(2)$, $\mathbb{SE}(3)$,
and $\mathbb{R}^{14}$ with challenging terrains. Furthermore, experiments
conducted with the Franka Emika Panda robot operating in a constrained
workspace provide additional evidence of the superiority of the proposed
method.

</details>


### [428] [DiffPF: Differentiable Particle Filtering with Generative Sampling via Conditional Diffusion Models](https://arxiv.org/abs/2507.15716)
*Ziyu Wan,Lin Zhao*

Main category: cs.RO

TL;DR: DiffPF是一种新的可微粒子滤波器，它使用扩散模型来提高状态估计的准确性，尤其是在复杂和多峰分布的情况下，并在多项基准测试中取得了显著的改进。


<details>
  <summary>Details</summary>
Motivation: 传统的粒子滤波器需要重要性重采样，并且通常依赖预定义的或低容量的提议分布，而DiffPF旨在通过学习灵活的后验采样器来克服这些限制。

Method: DiffPF利用扩散模型进行动态系统中的状态估计，通过将扩散模型条件化于预测粒子和当前观测来学习灵活的后验采样器，从而实现从复杂、高维和多峰滤波分布中进行准确、等权重采样。

Result: DiffPF在模拟和真实世界的任务中，包括单峰和高度多峰分布，其性能持续优于现有的滤波基线。在高度多峰的全局定位基准测试中，估计精度提高了82.8%；在真实的KITTI视觉里程计基准测试中，提高了26%。

Conclusion: DiffPF是首个将条件扩散模型集成到粒子滤波中的方法，能够进行高质量的后验采样，产生信息更丰富的粒子，并显著改善状态估计。

Abstract: This paper proposes DiffPF, a differentiable particle filter that leverages
diffusion models for state estimation in dynamic systems. Unlike conventional
differentiable particle filters, which require importance weighting and
typically rely on predefined or low-capacity proposal distributions. DiffPF
learns a flexible posterior sampler by conditioning a diffusion model on
predicted particles and the current observation. This enables accurate,
equally-weighted sampling from complex, high-dimensional, and multimodal
filtering distributions. We evaluate DiffPF across a range of scenarios,
including both unimodal and highly multimodal distributions, and test it on
simulated as well as real-world tasks, where it consistently outperforms
existing filtering baselines. In particular, DiffPF achieves an 82.8%
improvement in estimation accuracy on a highly multimodal global localization
benchmark, and a 26% improvement on the real-world KITTI visual odometry
benchmark, compared to state-of-the-art differentiable filters. To the best of
our knowledge, DiffPF is the first method to integrate conditional diffusion
models into particle filtering, enabling high-quality posterior sampling that
produces more informative particles and significantly improves state
estimation.

</details>


### [429] [Gaze-supported Large Language Model Framework for Bi-directional Human-Robot Interaction](https://arxiv.org/abs/2507.15729)
*Jens V. Rüppel,Andrey Rudenko,Tim Schreiter,Martin Magnusson,Achim J. Lilienthal*

Main category: cs.RO

TL;DR: LLM驱动的辅助机器人系统在适应性和用户参与度方面优于传统方法，但可能产生冗余输出。


<details>
  <summary>Details</summary>
Motivation: 解决现有HRI系统在支撑双向、多模态和上下文感知用户进行协作任务方面仍然存在的挑战。

Method: 提出了一种基于注视和语音信息接口的辅助机器人系统，该系统能够感知工作环境并支持动态用户。该系统设计为模块化和可转移的，能够实时使用基于语言的交互状态表示和快速的板载感知模块。

Result: 在两项实验室研究中，将LLM驱动的系统与传统的脚本化HRI管道进行了比较，表明LLM驱动的方法增强了适应性，并略微提高了用户参与度和任务执行指标，但可能产生冗余输出，而脚本化管道非常适合更直接的任务。

Conclusion: LLM驱动的方法增强了适应性，并略微提高了用户参与度和任务执行指标，但可能产生冗余输出，而脚本化管道非常适合更直接的任务。

Abstract: The rapid development of Large Language Models (LLMs) creates an exciting
potential for flexible, general knowledge-driven Human-Robot Interaction (HRI)
systems for assistive robots. Existing HRI systems demonstrate great progress
in interpreting and following user instructions, action generation, and robot
task solving. On the other hand, bi-directional, multi-modal, and context-aware
support of the user in collaborative tasks still remains an open challenge. In
this paper, we present a gaze- and speech-informed interface to the assistive
robot, which is able to perceive the working environment from multiple vision
inputs and support the dynamic user in their tasks. Our system is designed to
be modular and transferable to adapt to diverse tasks and robots, and it is
capable of real-time use of language-based interaction state representation and
fast on board perception modules. Its development was supported by multiple
public dissemination events, contributing important considerations for improved
robustness and user experience. Furthermore, in two lab studies, we compare the
performance and user ratings of our system with those of a traditional scripted
HRI pipeline. Our findings indicate that an LLM-based approach enhances
adaptability and marginally improves user engagement and task execution metrics
but may produce redundant output, while a scripted pipeline is well suited for
more straightforward tasks.

</details>


### [430] [Interleaved LLM and Motion Planning for Generalized Multi-Object Collection in Large Scene Graphs](https://arxiv.org/abs/2507.15782)
*Ruochu Yang,Yu Zhou,Fumin Zhang,Mengxue Hou*

Main category: cs.RO

TL;DR: 通过结合大语言模型和运动规划，开发了一种名为Inter-LLM的算法，能让家庭服务机器人在大型环境中更智能地收集和放置多个物品，任务完成率提高了30%。


<details>
  <summary>Details</summary>
Motivation: 家庭服务机器人缺乏类似人类的智能，尤其在处理开放集对象和高效精确地导航大型环境方面存在不足。为了突破这些限制，研究考虑了在大规模场景图中的广义多对象收集问题。

Method: 提出了一种交错式LLM和运动规划算法Inter-LLM，并设计了一种多模态动作代价相似性函数，以平衡规划的质量和效率。

Result: 通过模拟实验证明，与现有最新方法相比，该算法在完成人类指令、最大化任务成功率和最小化任务成本方面，将整体任务性能提高了30%。

Conclusion: 该研究提出了一种新颖的交错式LLM和运动规划算法Inter-LLM，用于解决家庭服务机器人面临的多对象收集问题，并在大规模场景图进行多对象拾取和放置，以应对长时序规划和高不确定性挑战。

Abstract: Household robots have been a longstanding research topic, but they still lack
human-like intelligence, particularly in manipulating open-set objects and
navigating large environments efficiently and accurately. To push this
boundary, we consider a generalized multi-object collection problem in large
scene graphs, where the robot needs to pick up and place multiple objects
across multiple locations in a long mission of multiple human commands. This
problem is extremely challenging since it requires long-horizon planning in a
vast action-state space under high uncertainties. To this end, we propose a
novel interleaved LLM and motion planning algorithm Inter-LLM. By designing a
multimodal action cost similarity function, our algorithm can both reflect the
history and look into the future to optimize plans, striking a good balance of
quality and efficiency. Simulation experiments demonstrate that compared with
latest works, our algorithm improves the overall mission performance by 30% in
terms of fulfilling human commands, maximizing mission success rates, and
minimizing mission costs.

</details>


### [431] [Look, Focus, Act: Efficient and Robust Robot Learning via Human Gaze and Foveated Vision Transformers](https://arxiv.org/abs/2507.15833)
*Ian Chuang,Andrew Lee,Dechen Gao,Jinyu Zou,Iman Soltani*

Main category: cs.RO

TL;DR: Human gaze improves robot vision: Active gaze in robots reduces computation and boosts performance, especially in precise tasks, by using foveated vision inspired by human eyes. The study introduces a new framework and dataset for training these 'gaze-aware' robots.


<details>
  <summary>Details</summary>
Motivation: The motivation is to enhance the efficiency and performance of robot learning systems by incorporating human-like active gaze, contrasting with the current passive, uniform processing of raw camera images.

Method: The study integrates human-like active gaze into robotic policies using foveated image processing. It builds upon the AV-ALOHA robot simulation platform, introducing a framework for collecting eye-tracking data and robot demonstrations. A novel foveated patch tokenization scheme is proposed for Vision Transformers (ViTs) to reduce computation without sacrificing visual fidelity. Two gaze imitation and prediction approaches are explored: a two-stage model and an end-to-end model that integrates gaze into the action space.

Result: The foveated robot vision method significantly reduces computational overhead and improves performance for high-precision tasks and robustness to unseen distractors compared to uniform patch tokenization.

Conclusion: The findings suggest that human-inspired visual processing, specifically active gaze, offers a useful inductive bias for robotic vision systems, leading to reduced computational overhead and improved performance in high-precision tasks and robustness to unseen distractors.

Abstract: Human vision is a highly active process driven by gaze, which directs
attention and fixation to task-relevant regions and dramatically reduces visual
processing. In contrast, robot learning systems typically rely on passive,
uniform processing of raw camera images. In this work, we explore how
incorporating human-like active gaze into robotic policies can enhance both
efficiency and performance. We build on recent advances in foveated image
processing and apply them to an Active Vision robot system that emulates both
human head movement and eye tracking. Extending prior work on the AV-ALOHA
robot simulation platform, we introduce a framework for simultaneously
collecting eye-tracking data and robot demonstrations from a human operator as
well as a simulation benchmark and dataset for training robot policies that
incorporate human gaze. Given the widespread use of Vision Transformers (ViTs)
in robot learning, we integrate gaze information into ViTs using a foveated
patch tokenization scheme inspired by recent work in image segmentation.
Compared to uniform patch tokenization, this significantly reduces the number
of tokens-and thus computation-without sacrificing visual fidelity near regions
of interest. We also explore two approaches to gaze imitation and prediction
from human data. The first is a two-stage model that predicts gaze to guide
foveation and action; the second integrates gaze into the action space,
allowing the policy to jointly predict gaze and actions end-to-end. Our results
show that our method for foveated robot vision not only drastically reduces
computational overhead, but also improves performance for high precision tasks
and robustness to unseen distractors. Together, these findings suggest that
human-inspired visual processing offers a useful inductive bias for robotic
vision systems. https://ian-chuang.github.io/gaze-av-aloha/

</details>


<div id='cond-mat.mtrl-sci'></div>

# cond-mat.mtrl-sci [[Back]](#toc)

### [432] [The fracture toughness of molybdenum at different grain sizes under and since brittle-ductile transition: computer modeling and experiment](https://arxiv.org/abs/2507.14273)
*K. M. Borysovska,N. M. Marchenko,Yu. Koval,Yu. N. Podrezov,S. A. Firstov*

Main category: cond-mat.mtrl-sci

TL;DR: 晶界通过改变位错分布来提高断裂韧性。


<details>
  <summary>Details</summary>
Motivation: 分析晶界对位错系演化和断裂韧性的影响。

Method: 使用位错动力学方法分析晶界对裂纹尖端位错系演化的影响。

Result: 对于大晶粒尺寸，晶粒尺寸对位错系和断裂韧性影响很小，但晶界会改变位错分布，从而提高断裂韧性。

Conclusion: 晶粒尺寸接近塑性区尺寸时，断裂韧性在脆性-韧性转变后急剧增加。晶界会影响裂纹尖端附近位错系的演化，当位错达到晶界时，位错分布会发生变化，导致断裂韧性增加。

Abstract: The sharp growth of the fracture toughness after brittle-ductile transition
happens at grain sizes approximately equal to the plastic zone size. Here we
analyze the influence of the grain boundary on the evolution of the ensemble of
dislocations near the crack tip using dislocation dynamics method. We show
evidence that for large grain sizes, the size has little effect on the ensemble
of dislocations and the fracture toughness, but when dislocations reach the
grain boundary, distribution of dislocations changes, which leads to increase
of the fracture toughness.

</details>


### [433] [Interplay of orbital and spin magnetization in trigonal tellurium](https://arxiv.org/abs/2507.14292)
*Zhenqi Hua,Chang Niu,Sandeep Joy,Pukun Tan,Gang Shi,Haoyang Liu,Jiaxing Guo,David Graf,Peide Ye,Cyprian Lewandowski,Peng Xiong*

Main category: cond-mat.mtrl-sci

TL;DR: 三角碲中的轨道磁化研究。


<details>
  <summary>Details</summary>
Motivation: 由于轨道效应相对于自旋效应的潜力被低估，但近年来其在量子材料中的作用日益受到关注，因此需要深入理解轨道效应。

Method: 通过详细的角依赖线性及非线性磁输运测量，并结合理论玻尔兹曼输运分析，分离了自旋和轨道自由度之间的相互作用。

Result: 实验发现了三角碲中存在由电流引起的自旋极化和轨道磁化，揭示了其自旋和轨道自由度之间的相互作用。

Conclusion: 该研究揭示了三角碲中轨道磁化的存在，为在手性晶体及其他材料中利用轨道磁化奠定了基础，有望应用于轨道电子学和自旋电子学。

Abstract: Orbital effects, despite their fundamental significance and potential to
engender novel physical phenomena and enable new applications, have long been
underexplored compared to their spin counterparts. Recently, surging interest
in the orbital degree of freedom has led to the discovery of a plethora of
orbital-related effects, underscoring the need for a deeper understanding of
their roles in quantum materials. Here, we report first experimental signatures
of orbital magnetization in trigonal Tellurium, an elemental semiconductor with
a unique helical crystal structure that serves as a natural platform for
investigating orbital effects. Detailed angular dependent linear and nonlinear
magnetotransport measurements, supported by theoretical Boltzmann transport
analysis, reveal the coexistence of current-induced spin polarization and
orbital magnetization. By disentangling the interplay between spin and orbital
degrees of freedom, this work establishes a general framework for understanding
orbital magnetization in chiral crystals and beyond, paving the way for its
utilization in orbitronics and spintronics.

</details>


### [434] [Phonon Weyl points and chiral edge modes with unconventional Fermi arcs in NbSi$_{2}$](https://arxiv.org/abs/2507.14369)
*Issam Mahraj,Andrzej Ptok*

Main category: cond-mat.mtrl-sci

TL;DR: NbSi$_{2}$ has a chiral structure and no inversion symmetry, leading to Weyl points and chiral edge modes. It's a good material for studying these phenomena, with specific findings about Weyl points and Fermi arcs.


<details>
  <summary>Details</summary>
Motivation: The motivation is to explore the unique physical properties arising from the absence of inversion symmetry and chiral structure in NbSi$_{2}$, specifically the interplay between phonon Weyl points and chiral phonon edge modes.

Method: The paper likely used theoretical calculations and symmetry analysis to identify the presence of Weyl points and chiral edge modes in NbSi$_{2}$.

Result: NbSi$_{2}$ crystallizes in the P6$_{2}$22 symmetry, featuring chiral chains of Si atoms. The paper identifies three Weyl points with a Chern number of +1 around the $ar{	ext{K}}$ point, which form unconventional Fermi arcs connecting the $ar{	ext{Γ}}$ or $ar{	ext{K}}$ points, mimicking an effective Chern number of -2.

Conclusion: NbSi$_{2}$ is an ideal platform for exploring the interplay between phonon Weyl points and chiral phonon edge modes due to its chiral structure and absence of inversion symmetry. It hosts three Weyl points with a Chern number of +1 around the $ar{	ext{K}}$ point, forming unconventional Fermi arcs that mimic an effective Chern number of -2.

Abstract: NbSi$_{2}$ crystallizes in the P6$_{2}$22 symmetry, featuring chiral chains
of Si atoms. The absence of inversion symmetry, combined with its chiral
structure, gives arise to unique physical properties. The breaking of inversion
symmetry leads to the emergence of Weyl points, while the chiral structure
enables the formation of chiral edge modes. As a result, NbSi$_{2}$ serves as
an ideal platform for exploring the interplay between phonon Weyl points and
chiral phonon edge modes. For example, we identify the presence of a structure
consisting of three Weyl points with a Chern number of $\mathcal{C} = +1$
around the $\bar{\text{K}}$ point. These nodes form unconventional Fermi arcs
connecting the $\bar{\Gamma}$ or $\bar{\text{K}}$ points, which mimic an
effective Chern number of $\mathcal{C} = -2$.

</details>


### [435] [Segregation and Ordering of Light Interstitials (B, C, H, and N) in Cr-Ni Alloys: Implications for Grain Boundary Stability in Superalloy Design](https://arxiv.org/abs/2507.14377)
*Tyler D. Doležal,Rodrigo Freitas,Ju Li*

Main category: cond-mat.mtrl-sci

TL;DR: 该研究利用蒙特卡洛模拟，研究了 B, C, N, H 在 Cr-Ni 中的行为，发现硼能稳定晶界，碳氮易形成沉淀，氢偏好沿富 Cr、Ni 的晶界迁移。研究结果有助于设计更稳定的超级合金。


<details>
  <summary>Details</summary>
Motivation: 研究 B, C, N, H 在 Cr-Ni 中的偏析和有序行为，因为这些元素对镍基高温合金的晶界稳定性及高温力学性能至关重要，同时为减缓氢脆提供策略。

Method: 采用蒙特卡洛模拟方法，研究了 B, C, N, H 在 Cr-Ni 的体相和晶界环境中的化学和结构偏好。

Result: 硼强烈偏好晶界，提高晶界内聚力并稳定晶界结构，高浓度下会诱导结构转变，形成锯齿状晶界；碳和氮形成碳化物和氮化物，在晶界溶解度有限；氢在 Cr-Ni 晶界区具有化学稳定性，并可能沿富 Cr 和 Ni 的晶界向内迁移，而避开富 Mo 的区域；含钼的硼化物可作为有效屏障，抑制氢侵蚀并稳定晶界内聚力。

Conclusion: 该研究通过蒙特卡洛模拟，阐明了 B, C, N, H 在 Cr-Ni 中的偏析和有序行为，为超级合金的设计提供了计算框架，以提高高温晶界稳定性、抗氢脆性以及化学有序性。

Abstract: The segregation and ordering behavior of light interstitials (B, C, and N) in
Cr30-Ni is examined, as these elements are critical for grain boundary
stability and high-temperature mechanical performance in Ni-based superalloys.
Using Monte Carlo simulations, we identify the chemical and structural
preferences of these interstitials in both bulk and grain boundary (GB)
environments, aligning with experimental segregation and precipitation trends.
Boron strongly prefers GBs over the bulk, where it enhances GB cohesion and
stabilizes the GB structure. Uniquely, boron induces a structural
transformation at higher concentrations, hinting at the formation of serrated
GBs where boron content is high, which improves high-temperature mechanical
performance. Carbon and nitrogen form carbide and nitride motifs and exhibit
limited GB solubility, reinforcing their precipitation tendencies. In support
of ongoing hydrogen embrittlement mitigation strategies, we also examined
hydrogen behavior. Hydrogen demonstrated chemical stability in the Cr-Ni GB
zone, suggesting it may preferentially migrate inward along Cr- and Ni-rich GBs
while avoiding Mo-enriched regions, further supporting Mo's role in mitigating
embrittlement. These findings suggest that Mo-containing borides may serve as
effective barriers against hydrogen-induced degradation by inhibiting H ingress
and stabilizing GB cohesion. By elucidating the chemical and structural
preferences of these light interstitials, this work provides a robust
computational framework for guiding superalloy design toward improved
high-temperature grain boundary stability, resistance to hydrogen
embrittlement, and controlled chemical ordering.

</details>


### [436] [Atomistic Simulations of Short-range Ordering with Light Interstitials in Inconel Superalloys](https://arxiv.org/abs/2507.14382)
*Tyler D. Dolžal,Emre Tekoglu,Jong-Soo Bae,Gi-Dong Sim,Rodrigo Freitas,Ju Li*

Main category: cond-mat.mtrl-sci

TL;DR: 本研究使用混合蒙特卡洛分子动力学模拟，发现镍基高温合金中的硼和碳优先与Cr、Mo、Nb形成有序结构，而非Ti。这些结构影响合金的微观结构和力学性能。研究结果可用于优化合金设计。


<details>
  <summary>Details</summary>
Motivation: 为了深入了解硼和碳在镍基高温合金中的行为，以及它们如何影响合金的微观结构和力学性能，本研究进行了相关的原子尺度模拟。

Method: 本研究采用混合蒙特卡洛分子动力学模拟方法，研究了掺杂硼或碳的镍基高温合金的短程有序行为。

Result: 模拟结果表明，硼和碳会从Ti原子处解离，并优先与Cr、Mo和Nb形成更有利的有序结构。硼倾向于形成B2结构，并被Mo、Nb和Cr包围；碳则优先与Cr形成Cr23C6局部结构，或与Nb形成Nb2C结构。硼和碳在间隙位置上的偏好也不同，硼倾向于四面体位置，而碳倾向于占用八面体位置。在空位存在时，硼和碳都会利用空位形成更稳定的结构。硼和碳在短程有序结构中具有很强的热力学稳定性。然而，在富Ti条件下，即使存在与Cr的有序结构，碳也更倾向于形成TiC。这种稳定性转变表明，Ti含量的增加会改变碳化物的形成路径，将碳从富Cr网络中转移出来，促进TiC的形成。这种重新分布可能会破坏作为晶界稳定剂和阻碍裂纹扩展的关键的富Cr碳化物网络的连续性。

Conclusion: 硼和碳在镍基高温合金中倾向于与Cr、Mo和Nb形成有序结构，而不是与Ti结合。这些原子尺度的结构变化会影响合金的微观结构和力学性能，尤其是对晶界稳定性和裂纹扩展有重要影响。该研究揭示了间隙原子诱导的短程有序对相稳定性和微观结构演变的关键作用，并提出可将此机制作为设计原则来优化合金性能以满足特定工程应用需求。

Abstract: This study employed hybrid Monte Carlo Molecular Dynamics simulations to
investigate the short-range ordering behavior of Ni-based superalloys doped
with boron or carbon. The simulations revealed that both boron and carbon
dissociated from their host Ti atoms to achieve energetically favored ordering
with Cr, Mo, and Nb. Boron clusters formed as B2, surrounded by Mo, Nb, and Cr,
while carbon preferentially clustered with Cr to form a Cr23C6 local motif and
with Nb to form Nb2C. Distinct preferences for interstitial sites were
observed, with boron favoring tetrahedral sites and carbon occupying octahedral
sites. In the presence of a vacancy, B2 shifted from the tetrahedral site to
the vacancy, where it remained coordinated with Mo, Nb, and Cr. Similarly,
carbon utilized vacancies to form Nb2C clusters. Excess energy calculations
showed that B and C exhibited strong thermodynamic stability within their
short-range ordered configurations. However, under Ti-rich conditions, C was
more likely to segregate into TiC, despite preexisting ordering with Cr. This
shift in stability suggests that increased Ti availability would alter carbide
formation pathways, drawing C away from Cr-rich networks and promoting the
development of TiC. Such redistribution may disrupt the continuity of Cr-based
carbide networks, which play a critical role in stabilizing grain boundaries
and impeding crack propagation. These effects further underscore the impact of
interstitial-induced ordering on phase stability and microstructural evolution.
This work provides an atomistic perspective on how boron- and carbon-induced
ordering influences microstructure and mechanical properties. These findings
highlight the critical role of interstitial-induced short-range ordering and
demonstrate that this mechanism can be leveraged as a design principle to
fine-tune alloy microstructures for specific engineering applications.

</details>


### [437] [New metastable ice phases via supercooled water](https://arxiv.org/abs/2507.14415)
*Hiroki Kobayashi,Kazuki Komatsu,Kenji Mochizuki,Hayate Ito,Koichi Momma,Shinichi Machida,Takanori Hattori,Kunio Hirata,Yoshiaki Kawano,Saori Maki-Yonekura,Kiyofumi Takaba,Koji Yonekura,Qianli Xue,Misaki Sato,Hiroyuki Kagi*

Main category: cond-mat.mtrl-sci

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Water exhibits rich polymorphism, where more than 20 crystalline phases have
been experimentally reported. Five of them are metastable and form at low
temperatures by either heating amorphous ice or degassing clathrate hydrates.
However, such metastable phases rarely crystallise directly from liquid water,
making it challenging to study metastable phase relations at relatively high
temperatures. Here, we report that high-pressure metastable phases of ice,
including two unknown phases named ices XXI and XXII, crystallise directly from
liquid water in a deeply supercooled region around the homogeneous nucleation
temperature. The key is to use emulsified water to stabilise supercooled water
in laboratory timescales. Ices XXI and XXII are obtained by isothermal
compression of emulsified water at 295 K and 250 K, respectively. Our powder
x-ray and neutron diffraction analyses combined with molecular dynamics (MD)
simulations revealed the surprisingly complex structures of these new phases
with Z = 152 (ice XXI) and 304 (ice XXII). Ice XXI is topologically identical
to 'ice T2' previously predicted by MD simulations, and our experimental
structural model can be used as a benchmark for its structures in simulations,
which depend on the force fields. On cooling, ice XXI transforms into an
orientationally ordered counterpart named ice XXIII. Our results revealed the
"hidden" structural complexity of water underlying the phase diagram, as
implied by previous computational works. Further efforts at unveiling such
metastable phase relations will bridge the large gaps between computational and
experimental phase diagrams of water.

</details>


### [438] [Phonon density of states of magnetite (\ce{Fe3O4}) nanoparticles via molecular dynamics simulations](https://arxiv.org/abs/2507.14416)
*Pablo Galaviz,Kyle A. Portwin,Dehong Yu,Kirrily C. Rule,David L. Cortie,Zhenxiang Cheng*

Main category: cond-mat.mtrl-sci

TL;DR: 该研究通过分子动力学和密度泛函理论，探究了磁铁矿纳米颗粒的尺寸、温度和水分对其声子状态密度的影响，发现尺寸减小和水分子的存在会引起声子模式展宽和软化。


<details>
  <summary>Details</summary>
Motivation: 本研究旨在全面计算研究磁铁矿纳米颗粒，系统评估不同力场与实验结果的吻合度，并探究颗粒尺寸、温度及表面吸附水分子对纳米颗粒结构与动力学性质的影响。

Method: 本研究采用经典的分子动力学方法对纳米颗粒和块状磁铁矿进行模拟，并利用密度泛函理论计算对块状磁铁矿进行比对分析。系统性地评估了一系列力场与实验结果的吻合度，并分析了颗粒尺寸、温度以及表面吸附水分子对纳米颗粒结构和动力学性质的影响。

Result: 研究结果表明，纳米颗粒尺寸和吸附水分子的存在对状态密度有显著影响。减小纳米颗粒尺寸会导致声子模式展宽和软化，原因是边界散射增强导致声子寿命缩短。水分子的引入会进一步展宽状态密度并将光谱扩展到更高能量区域。温度变化引起声子状态密度（尤其在氧主导区域）的展宽和软化，这是由声子非谐性造成的。

Conclusion: 研究结果表明，纳米颗粒的大小和吸附水分子的存在对状态密度有显著影响。具体来说，随着纳米颗粒尺寸减小，声子模式表现出明显的展宽和软化，这归因于边界散射增强导致的声子寿命缩短。水分子的引入进一步展宽了状态密度，并将光谱扩展到更高的能量区域。温度变化导致声子状态密度略有展宽和软化，尤其是在以氧为主的区域，这归因于声子非谐性。

Abstract: This study presents a comprehensive computational investigation of magnetite
nanoparticles, systematically evaluating a range of force fields against
experimental results. We analyze the influence of particle size, temperature,
and surface-adsorbed water molecules on the structural and dynamic properties
of the nanoparticles. We performed classical molecular dynamics of
nanoparticles and bulk magnetite and utilized density functional theory
calculations for bulk magnetite for comparison. Our results reveal that
nanoparticle size and the presence of adsorbed water molecules have a
pronounced impact on the density of states. Specifically, as the nanoparticle
size is decreased, phonon modes exhibit significant broadening and softening,
which is attributable to reduced phonon lifetimes resulting from enhanced
boundary scattering. The incorporation of water further broadens the density of
states and extends the spectra to higher energy regions. Temperature variations
result in a slight broadening and softening of the phonon density of states,
particularly in the oxygen-dominated region, which is attributed to phonon
anharmonicity.

</details>


### [439] [Tunable exchange bias in Y$_3$Fe$_5$O$_{12}$ film on Gd$_3$Ga$_5$O$_{12}$](https://arxiv.org/abs/2507.14493)
*Umesh Thuwal,Sumanta Maity,Ruksana Pervin,Rohit Medwal,Joseph Vimal Vas,Yasuhiro Fukuma,Herve Courtois,Clemens B. Winkelmann,Anjan Kumar Gupta*

Main category: cond-mat.mtrl-sci

TL;DR: 通过溅射和低温退火降低YIG/GGG界面层的阻挡温度至7K，并发现交换偏置可通过场冷过程调控，这与自旋玻璃的动力学行为相似。


<details>
  <summary>Details</summary>
Motivation: 探究铁磁性Y3Fe5O12薄膜在顺磁性Gd3Ga5O12衬底上出现的交换偏置效应的来源，并研究其调控方法。

Method: 采用溅射生长技术，并优化了低温后退火工艺，将铁磁性Y3Fe5O12薄膜的界面层阻挡温度降低。

Result: 发现通过溅射和低温后退火工艺，界面层的阻挡温度降低至7K，同时仍表现出强烈的交换偏置。通过改变场冷协议，可以调控交换偏置在两个极端值之间变化。

Conclusion: 本研究通过调整溅射和低温退火条件，成功将铁磁性Y3Fe5O12薄膜界面层的阻挡温度降低至7K，同时保持了强烈的交换偏置效应。此外，研究发现该交换偏置效应可以通过精细调控场冷过程在两个极端值之间进行调节，这归因于界面层自旋在接近阻挡（或熔化）温度时表现出的缓慢而复杂的动力学行为，类似于自旋玻璃。

Abstract: Ferrimagnetic Y$_3$Fe$_5$O$_{12}$ grown on the (001) surface of paramagnetic
Gd$_3$Ga$_5$O$_{12}$ experiences an exchange bias field, which has been
attributed to the magnetism of an interface layer between the two materials. We
report here that when grown using sputtering and with lower post-annealing
temperatures than in previous works, the blocking temperature of the interface
magnetic layer is lowered to about 7 K, while still displaying a strong
exchange bias. This exchange bias is then found to be tunable between its two
extreme values by carefully varying the field cooling protocol. This is
attributed to a slow and complex dynamics of the spins of the interface-layer
when it is warmed up close to its blocking (or melting) temperature, which is
reminiscent of a spin glass.

</details>


### [440] [Temperature Dependent Mechanical and Structural Properties of Uniaxially Strained Planar Graphene](https://arxiv.org/abs/2507.14709)
*Sané Erasmus,Charalampos Skokos,George Kalosakas*

Main category: cond-mat.mtrl-sci

TL;DR: 研究了石墨烯在不同温度下的力学行为，发现其力学性能随温度升高而下降。


<details>
  <summary>Details</summary>
Motivation: 研究石墨烯在不同温度下的力学行为

Method: 使用分子动力学模拟研究了石墨烯在单轴拉伸应力下的力学行为及其对温度的依赖性，并计算了不同温度下的应力-应变曲线以及杨氏模量、三阶弹性模量、拉伸强度和断裂应变等弹性参数。

Result: 断裂应力和断裂应变，以及杨氏模量随温度升高几乎呈线性下降。

Conclusion: 应力-应变曲线随温度升高而降低，键长和键角分布有相应的分析

Abstract: Using molecular dynamics simulations in a planar graphene sheet, we
investigate the temperature dependence of its mechanical behavior under
uniaxial tensile stress applied either along the armchair or the zigzag
direction. Stress-strain curves are calculated for different temperatures and
the corresponding dependence of various elastic parameters, like the Young
modulus, the third-order elastic modulus, the tensile strength and failure
strain, is presented. Fracture stress and strain, as well as the Young modulus,
decrease almost linearly with temperature. The distributions of bond lengths
and bond angles at different strains and temperatures are also discussed and
approximate analytical expressions are presented. The latter describe
accurately the numerically obtained distributions.

</details>


### [441] [Possible Orthorhombic Phase of Ta$_2$O$_5$ under High Pressures](https://arxiv.org/abs/2507.14514)
*Yan Gong,HuiMin Tang,Yong Yang,Yoshiyuki Kawazoe*

Main category: cond-mat.mtrl-sci

TL;DR: 在高压下发现了一种新的Ta$_{2}$O$_{5}$相（Y-Ta$_{2}$O$_{5}$），它是宽带隙半导体，并且在高压下比其他相更稳定。


<details>
  <summary>Details</summary>
Motivation: 在高压条件下预测Ta$_{2}$O$_{5}$的新相。

Method: 利用密度泛函理论（DFT）结合结构搜索算法进行计算。

Result: 预测得到Y-Ta$_{2}$O$_{5}$，一种具有最高Ta-O配位数的斜方晶相，在70-200 GPa范围内是最稳定的相。该相是宽带隙半导体，具有直接带隙。核量子效应在高压相稳定性分析中很重要。

Conclusion: DFT计算结合结构搜索算法预测了在高压条件下可能存在的Ta$_{2}$O$_{5}$斜方晶相（Y-Ta$_{2}$O$_{5}$）。该相具有最高的已知Ta-O配位数，在70 GPa至至少200 GPa的压力范围内是最有利的Ta$_{2}$O$_{5}$形式。Y-Ta$_{2}$O$_{5}$是宽带隙半导体，具有直接带隙。核量子效应（NQEs）对固定体积下的外压有显著影响，表明了其在高压相稳定性分析中的重要性。

Abstract: A potential orthorhombic phase of Ta$_2$O$_5$, designated as Y-Ta$_2$O$_5$,
is predicted under high-pressure conditions through density functional theory
(DFT) calculations combined with structural search algorithms. This phase,
consisting of four formula units per unit cell ($Z = 4$), exhibits the highest
known Ta-O coordination numbers. Y-Ta$_2$O$_5$ is found to be the most
energetically favorable form of Ta$_2$O$_5$ in the pressure range of
approximately 70 GPa to at least 200 GPa. Both standard DFT-GGA and
higher-accuracy GW calculations reveal that Y-Ta$_2$O$_5$ is a wide bandgap
semiconductor with a direct bandgap. Additionally, nuclear quantum effects
(NQEs) introduce nontrivial corrections to external pressure at fixed volumes,
underscoring their significance in high-pressure phase stability analyses.

</details>


### [442] [Symmetry-breaking strain drives significant reduction in lattice thermal conductivity: A case study of boron arsenide](https://arxiv.org/abs/2507.14532)
*Kaile Chen,Xin Jin,Xiaolong Yang*

Main category: cond-mat.mtrl-sci

TL;DR: 单轴拉伸应变可大幅降低BAs热导率，且对垂直方向抑制作用更强。


<details>
  <summary>Details</summary>
Motivation: 最近的研究表明，立方砷化硼（BAs）在各向同性应变下表现出晶格热导率（κL）的非单调压力依赖性。然而，单轴应变的影响尚不清楚。

Method: 通过严格的第一性原理计算。

Result: 单轴拉伸应变导致BAs的晶格热导率（κL）单调降低，这与各向同性情况形成鲜明对比。具体来说，施加单轴（100）应变会解除声子能带简并，并使声子谱整体软化。这些变化通过促进选择规则的满足，极大地增加了声子-声子散射通道，从而导致三声子和四声子散射率同时增加。因此，在室温下，在大的拉伸作用下，κL表现出近80%的急剧抑制。此外，单轴应变在垂直于应变的方向上比沿着拉伸方向更能抑制κL。

Conclusion: 单轴拉伸应变可以显著降低立方砷化硼（BAs）的晶格热导率（κL），并且在垂直于应变方向上比在平行方向上抑制作用更强。这项工作建立了对BAs在单轴应变下热导行为的基本理解，并通过调整晶体对称性为操纵固态热输运开辟了有前景的途径。

Abstract: Recent research has revealed that cubic boron arsenide (BAs) exhibits a
non-monotonic pressure dependence of lattice thermal conductivity ($\kappa_{\rm
L}$) under isotropic strain. Here, through rigorous first-principles
calculations, we unveil that uniaxial tensile strain induces a monotonic
reduction in the $\kappa_{\rm L}$ of BAs -- a striking contrast to the
isotropic scenario. The results show that applying uniaxial (100) strain leads
to the lifting of phonon band degeneracy, accompanied by an overall softening
of the phonon spectrum. These modifications significantly increase
phonon-phonon scattering channels by facilitating the fulfillment of selection
rules, resulting in a concurrent increase in both three- and four-phonon
scattering rates. Consequently, $\kappa_{\rm L}$ exhibits a dramatic
suppression of nearly 80\% under large tension at room temperature. Meanwhile,
we unexpectedly observe that the uniaxial strain suppresses $\kappa_{\rm L}$
much more strongly in the direction perpendicular to the strain than along the
stretching direction. This work establishes the fundamental understanding of
the thermal conductivity behavior of BAs under uniaxial strain and opens a
promising avenue for manipulating solid-state heat transport by tuning crystal
symmetry.

</details>


### [443] [Efficient ultrafast photoacoustic transduction on Tantalum thin films](https://arxiv.org/abs/2507.15400)
*Konstantinos Kaleris,Emmanouel Kaniolakis-Kaloudis,Evaggelos Kaselouris,Kyriaki Kosma,Emmanouil Gagaoudakis,Vassilis Binas,Stelios Petrakis,Vasilis Dimitriou,Makis Bakarezos,Michael Tatarakis,Nektarios A. Papadogiannis*

Main category: cond-mat.mtrl-sci

TL;DR: 钽薄膜的光声转换效率优于钛薄膜，该研究为开发用于γ射线产生的晶体 the undulators 提供了新的途径。


<details>
  <summary>Details</summary>
Motivation: 过渡金属（如钛）在光声转换方面比贵金属（如银）表现出更强的性能。本研究旨在探索过渡金属中光声性能优异的材料，并验证钽的优越性。

Method: 通过飞秒激光脉冲激发钽薄膜产生纳米声应变，并利用泵浦-探测瞬态反射光谱测量布里渊振荡来捕获光子-声子相互作用，从而量化光声转换效率，并与钛薄膜进行比较。同时，采用双温模型和有限元分析相结合的计算方法来模拟激光诱导应变及其传播。

Result: 实验结果和模拟均表明，钽薄膜的光声转换效率优于钛薄膜。研究还讨论了金属换能器-衬底声阻抗匹配对光声性能的影响，并提出了利用钽薄膜生成受激声脉冲序列用于晶体 the undulators 的可能性。

Conclusion: 钽(Tantalum)在光声转换效率方面优于钛(Titanium)等过渡金属，并且与衬底的声阻抗匹配可以用于开发用于γ射线产生的晶体 the undulators。

Abstract: Nano-acoustic strain generation in thin metallic films via ultrafast laser
excitation is widely used in material science, imaging and medical
applications. Recently, it was shown that transition metals, such as Titanium,
exhibit enhanced photoacoustic transduction properties compared to noble
metals, such as Silver. This work presents experimental results and simulations
that demonstrate that among transition metals Tantalum exhibits superior
photoacoustic properties. Experiments of nano-acoustic strain generation by
femtosecond laser pulses focused on thin Tantalum films deposited on Silicon
substrates are presented. The nano-acoustic strains are measured via pump-probe
transient reflectivity that captures the Brillouin oscillations produced by
photon-phonon interactions. The observed Brillouin oscillations are correlated
to the photoacoustic transduction efficiency of the Tantalum thin film and
compared to the performance of Titanium thin films, clearly demonstrating the
superior photoacoustic transduction efficiency of Tantalum. The findings are
supported by computational results on the laser-induced strains and their
propagation in these thin metal film/substrate systems using a Two-Temperature
Model in combination with thermo-mechanical Finite Element Analysis. Finally,
the role of the metal transducer-substrate acoustic impedance matching is
discussed and the possibility to generate appropriately modulated acoustic
pulse trains inside the crystalline substrate structures for the development of
crystalline undulators used for {\gamma}-ray generation is presented.

</details>


### [444] [Metal-Insulator transition and Charge Transport Mechanisms in SnSe$_2$ Field-Effect Transistor](https://arxiv.org/abs/2507.14536)
*Aarti Lakhara,Lars Thole,Rolf J. Haug,P. A. Bhobe*

Main category: cond-mat.mtrl-sci

TL;DR: 通过静电掺杂，在SnSe$_2$薄膜中实现了金属-绝缘体转变，并分析了其电荷传输机制。


<details>
  <summary>Details</summary>
Motivation: 为了理解SnSe$_2$薄膜中的金属-绝缘体转变及其电荷传输机制，为优化二维材料在电子器件中的应用提供基础。

Method: 通过静电掺杂提高SnSe$_2$薄膜的载流子浓度，并利用低温电荷输运机制（二维可变程跳跃）、能带弯曲、硒空位引入的能隙态、带电杂质以及电子-声子散射来分析其电荷传输特性。

Result: 在SnSe$_2$薄膜中观察到了从绝缘相到金属态的转变，并确定了其低温电荷传输机制为二维可变程跳跃，该机制受能带弯曲和硒空位引入的能隙态影响。同时，研究也揭示了在不同温度下限制迁移率的因素（低温下为带电杂质，高温下为电子-声子散射），并指出栅极场可以驱动系统进入金属态。

Conclusion: 本研究观察到了SnSe$_2$薄膜中的金属-绝缘体转变，并深入了解了其电荷传输机制，为优化其他二维材料在电子器件中的应用提供了见解。

Abstract: We report an observation of metal-insulator transition in a thin film of
SnSe$_2$. The room-temperature carrier concentration of SnSe$_2$ film was
increased by electrostatic doping to 1.14$\times$ 10$^{13}$ cm$^{-2}$. A
crossover from insulating phase to metallic state was clearly observed. The
low-temperature charge transport mechanism is governed by two-dimensional (2D)
variable-range hopping. This mechanism is influenced by band bending and gap
states introduced by selenium vacancies. At low temperatures, the mobility is
primarily limited by charged impurities, while at higher temperatures, it
follows a power-law dependence, $\mu = T^{-\gamma}$, indicating a dominance of
electron-phonon scattering. The application of a gate field shifts the Fermi
level toward the conduction band, and at sufficiently high temperatures, this
drives the system into a metallic state. Our findings offer insights into the
charge transport mechanisms in SnSe$_2$ FET, this understanding will allow for
the optimization of other 2D materials for advanced electronic device
applications.

</details>


### [445] [Swift heavy ion track formation in SiC films under high-temperature irradiation](https://arxiv.org/abs/2507.14574)
*D. I. Zainutdinov,A. E. Volkov*

Main category: cond-mat.mtrl-sci

TL;DR: 研究了SiC薄膜厚度和辐照温度对重离子辐照纳米结构形成的影响，发现存在两种纳米结构（陨石坑和山丘），其形成取决于温度和厚度，并提出了一个经验模型。


<details>
  <summary>Details</summary>
Motivation: 填补了SiC薄膜厚度对重离子辐照损伤（包括纳米结构形成）影响的研究空白，并探索了辐照温度的影响。

Method: 采用MC代码TREKIS-3和经典分子动力学模拟，研究了710 MeV Bi离子辐照不同厚度SiC薄膜（10 nm至100 nm）在不同温度下的表面纳米结构形成。

Result: 在SiC薄膜表面观察到两种纳米结构：陨石坑和山丘。陨石坑和山丘的转变与辐照温度和薄膜厚度有关，并提出了一个经验关系式来描述转变温度随薄膜厚度的变化，该关系式表明在体材料中转变温度约为1534 K。

Conclusion: 本研究揭示了SiC薄膜厚度和辐照温度对重离子辐照下纳米结构形成的影响，并提出了一个描述离子束引起的材料损伤的唯象模型，该模型考虑了电子激发和原子系统反应。

Abstract: The resistance of bulk silicon carbide (SiC) to impacts of swift heavy ions
(SHI) decelerating at room temperature in the electronic stopping regime is
well known. However, the effect of the SiC film thickness on the formation and
structure of SHI tracks over a wide range of irradiation temperatures remains
unexplored. To address this disadvantage, we utilize a model sensitive to
irradiation temperature that describes all stages of ion track formation: from
material excitation, considering the emission of excited electrons from the
film surface (MC code TREKIS-3), to the reaction of the material's atomic
system to the excitation (classical molecular dynamics). We observed the
formation of two different types of nanostructures on the surface of SiC films
with thicknesses ranging from 10 nm to 100 nm when irradiated with 710 MeV Bi
ions: craters and hills. The type of nanostructure formed depended on the
irradiation temperature. The transition irradiation temperature ($T_{tr}$) from
hills to craters grows with the film thickness and follows an empirical
relation $T_{tr}=T_{tr}^{cr} \left(1-\left(1+\left(L/L_{cr} \right)^2
\right)^{-\frac{1}{2}} \right)$ with $T_{tr}^{cr}=1534$ K and $L_{cr}=2.8$ nm.
That means such a transition should occur in bulk SiC at the irradiation
temperature of $\approx 1534$ K.

</details>


### [446] [Investigation on high-order planar Hall effect in trigonal PtBi$_2$](https://arxiv.org/abs/2507.14580)
*Fangqi Cai,Mingxi Chi,Yingjie Hu,Heyao Liu,Yangyang Chen,Chao Jing,Wei Ren,He Wang*

Main category: cond-mat.mtrl-sci

TL;DR: t-PtBi$_2$的PHE和AMR在高阶特征上表现出相似的温度和磁场依赖性，源于费米面各向异性和磁阻的标度行为。


<details>
  <summary>Details</summary>
Motivation: 前期研究观察到t-PtBi$_2$的PHE和AMR表现出高阶特征，但未系统研究，本工作旨在深入探究这些特征。

Method: 通过在低温和强磁场下进行系统性的PHE和AMR测量，并结合计算模拟，分析了t-PtBi$_2$的电子特性。

Result: PHE和AMR在高阶特征上表现出相似的温度和磁场依赖性，且与电阻的开启行为相关。计算模拟结果与实验一致，表明高阶特征源于费米面各向异性和磁阻的标度行为。

Conclusion: 本研究通过系统测量和计算模拟，揭示了三方PtBi$_2$（t-PtBi$_2$）中平面霍尔效应（PHE）和面内磁阻（AMR）的高阶特征及其物理起源，为理解非磁性拓扑材料中高阶特征的产生机制提供了深入的见解。

Abstract: The trigonal PtBi$_2$ (t-PtBi$_2$) as a Weyl semimetal possessing triply
degenerate points in its electronic bands near the Fermi level endows it with
rich electronic properties. Previous studies have already measured the planar
Hall effect (PHE) and in-plane anisotropic magnetoresistance (AMR) of
t-PtBi$_2$. We noticed that their experimental results exhibited high-order
features in both the PHE and AMR, yet these features were not systematically
investigated. In our work, we conducted more systematic measurements and
analyses of the PHE and AMR in t-PtBi$_2$. Both PHE and AMR show high-order
features under low temperatures and strong magnetic fields, and these features
share a similar temperature and magnetic field dependence with the turn-on
behavior of resistance and temperature curves, indicating a common physical
origin for them. We further summarize the critical conditions for the emergence
of high-order PHE in t-PtBi$_2$, which will help to understand the origin of
high-order features. In addition, we performed computational simulations on the
AMR of t-PtBi$_2$, and the results were consistent with the experiments,
indicating the high-order features are the result of the combined contribution
of the Fermi surface anisotropy and the scaling behavior of magnetoresistance.
Our findings will contribute to a deeper understanding of the origins of
high-order features in non-magnetic topological materials.

</details>


### [447] [Designing Two-Dimensional Octuple-Atomic-Layer M$_2$A$_2$Z$_4$ as Promising Photocatalysts for Overall Water Splitting](https://arxiv.org/abs/2507.14654)
*Dingyanyan Zhou,Yujin Ji,Mir F. Mousavi,Youyong Li*

Main category: cond-mat.mtrl-sci

TL;DR: 通过第一性原理计算，筛选出Al2Si2N4和Al2Ge2N4两种二维材料，它们在酸性和中性条件下均适用于光催化全分解水，并且引入氮空位可进一步提高其催化活性。


<details>
  <summary>Details</summary>
Motivation: 二维材料因其大表面积和可调的电子性质，在光催化领域展现出巨大潜力，本研究旨在设计和筛选用于光催化全分解水的新型二维材料。

Method: 使用第一性原理计算，系统设计并筛选了一系列八重原子层M2A2Z4单层（M = Al, Ga, In; A = Si, Ge, Sn; Z = N, P, As）。构建了108个结构，并对其热力学和动力学稳定性、带隙以及能带对齐情况进行了全面评估。

Result: 筛选出8种满足酸性条件下（pH=0）全分解水标准的候选材料。其中，Al2Si2N4和Al2Ge2N4在酸性和中性（pH=0和7）环境下都具有合适的光催化能带边缘位置，并且表现出显著的可见光吸收和水性环境下的结构稳定性。通过引入氮空位，Al2Si2N4和Al2Ge2N4的催化活性得到显著增强，进一步证明了其作为光催化剂的潜力。

Conclusion: 研究为设计高效稳定的二维光催化剂用于全分解水提供了理论指导。

Abstract: Two-dimensional (2D) materials have emerged as promising candidates as
photocatalytic materials due to their large surface areas and tunable
electronic properties. In this work, we systematically design and screen a
series of octuple-atomic-layer M$_2$A$_2$Z$_4$ monolayers (M = Al, Ga, In; A =
Si, Ge, Sn; Z = N, P, As) using first-principles calculations. 108 structures
are constructed by intercalation approach, followed by a comprehensive
evaluation of their thermodynamic and dynamic stability, band gaps, and band
edge alignments to assess their potential for photocatalytic overall water
splitting. Among them, eight candidates meet the criteria for overall water
splitting under acidic condition (pH = 0), and Al$_2$Si$_2$N$_4$ and
Al$_2$Ge$_2$N$_4$, further exhibit suitable band edge positions for
photocatalysis under both acidic and neutral environments (pH = 0 and 7).
Al$_2$Si$_2$N$_4$ and Al$_2$Ge$_2$N$_4$ also show pronounced visible-light
absorption and structural stability in aqueous conditions. Importantly, the
introduction of N vacancies on the surfaces of Al$_2$Si$_2$N$_4$ and
Al$_2$Ge$_2$N$_4$ significantly enhances their catalytic activity for both
hydrogen reduction and water oxidation reactions, further supporting their
potential as photocatalysts for overall water splitting. Our study provides
theoretical insights for the rational design of efficient and stable 2D
photocatalysts for overall water splitting.

</details>


### [448] [Anomalous temperature dependence of local magnetic fields in altermagnetic MnTe](https://arxiv.org/abs/2507.14710)
*Thomas J. Hicken,Oliver Amin,Alfred Dal Din,J. Hugo Dil,Dominik Kriegner,Hubertus Luetkens,Helena Reichlová,Zaher Salman,Klára Uhlířová,Peter Wadley,Juraj Krempaský,Jonas A. Krieger*

Main category: cond-mat.mtrl-sci

TL;DR: MnTe晶体在250K以下磁结构发生变化。


<details>
  <summary>Details</summary>
Motivation: Altermagnets（包括MnTe）具有无净磁矩但具有自旋极化能带结构的特点，在器件应用方面具有潜力。为了进一步理解MnTe的磁性，本研究进行了μSR测量。

Method: 本研究采用μSR（muon-spin spectroscopy）技术测量了MnTe单晶。

Result: 在室温以下，观察到μSR信号的明显异常和非比例内场的出现，表明在250K左右发生了磁结构变化。

Conclusion: MnTe晶体在250K以下出现显著的磁结构变化，表现为μSR信号的异常和非比例内场的出现，这与之前报道的输运性质变化等现象一致。

Abstract: Altermagnets are a novel type of magnetic system that has a spin-polarised
electric band structure in the absence of a net magnetic moment, leading to
exciting prospects in potential device applications. Hexagonal MnTe, a
prototypical altermagnet, has arguably shown the most properties consistent
with theoretical predictions, including an anomalous Hall effect despite no net
magnetisation, and strong altermagnet-induced spin splitting in the electronic
band structure. Here we present muon-spin spectroscopy measurements of a single
crystal of MnTe. Below room temperature we observe pronounced anomalies in the
muon-spin depolarisation, as well as the onset of a second, non-proportional
internal field in the absence of an applied field. These findings point to a
change in the magnetic structure around $T\simeq250$ K, which coincides with
other changes in reported properties, such as transport.

</details>


### [449] [Size-Dependent Lattice Pseudosymmetry for Frustrated Decahedral Nanoparticles](https://arxiv.org/abs/2507.14781)
*Oliver Lin,Zhiheng Lyu,Hsu-Chih Ni,Xiaokang Wang,Yetong Jia,Chu-Yun Hwang,Lehan Yao,Jian-Min Zuo,Qian Chen*

Main category: cond-mat.mtrl-sci

TL;DR: 该研究利用4D-STEM技术分析了纳米粒子，发现其晶格畸变随尺寸变化，并在35 nm处存在结构相变点，揭示了纳米材料的尺寸依赖性结构特征。


<details>
  <summary>Details</summary>
Motivation: 尽管几何受挫现象广泛存在于多个科学领域，但对于合成多重孪晶纳米材料中的内在晶格应变和结构稳定性，尤其是在不同尺寸和几何形状下的表现，仍缺乏深入的理解。

Method: 利用四维扫描透射电子显微镜（4D-STEM）应变图谱技术，对23个不同尺寸（20-55 nm）的十 وجه体纳米粒子进行应变映射，以纳米尺度的空间分辨率解析其二维应变张量。

Result: 研究揭示了纳米材料内部晶格畸变的异质性，并观察到畸变随尺寸增加而趋于均匀化和对称性恢复。在小于35 nm和大于35 nm的粒子中，发现了面心立方与体心四方晶格对称性之间的空间相变模式差异，这与粒子形状从纳米尺度的Wulff形状向晶面化的五重双锥形状的转变相关。

Conclusion: 该研究通过4D-STEM应变图谱技术，揭示了几何受挫纳米材料的内部结构特征。研究发现，随着尺寸的增加，纳米材料的晶格畸变趋于均匀化并恢复对称性。特别是，当尺寸小于或大于35 nm时，面心立方和体心四方晶格对称性之间会发生空间相变，这表明材料内部结构存在一个交叉尺寸。这一发现有助于理解该体系的长期未解之谜，并可广泛应用于研究纳米晶体固体和材料相变。

Abstract: Geometric frustration is a widespread phenomenon in physics, materials
science, and biology, occurring when the geometry of a system prevents local
interactions from being all accommodated. The resulting manifold of nearly
degenerate configurations can lead to complex collective behaviors and emergent
pseudosymmetry in diverse systems such as frustrated magnets, mechanical
metamaterials, and protein assemblies. In synthetic multi-twinned
nanomaterials, similar pseudosymmetric features have also been observed and
manifest as intrinsic lattice strain. Despite extensive interest in the
stability of these nanostructures, a fundamental understanding remains limited
due to the lack of detailed structural characterization across varying sizes
and geometries. In this work, we apply four-dimensional scanning transmission
electron microscopy strain mapping over a total of 23 decahedral nanoparticles
with edge lengths, d, between 20 and 55 nm. From maps of full 2D strain tensor
at nanometer spatial resolution, we reveal the prevalence of heterogeneity in
different modes of lattice distortions, which homogenizes and restores symmetry
with increasing size. Knowing the particle crystallography, we reveal
distinctive spatial patterns of local lattice phase transformation between
face-centered cubic and body-centered tetragonal symmetries, with a contrast
between particles below and above d of 35 nm. The results suggest a cross-over
size of the internal structure occurs, as particles shape transition from
modified-Wulff shape favored at nanoscale to faceted, pentagonal bipyramidal
shape. Ultimately, our 4D-STEM mapping provides new insight to long-standing
mysteries of this historic system and can be widely applicable to study
nanocrystalline solids and material phase transformation that are important in
catalysis, metallurgy, electronic devices, and energy storage materials.

</details>


### [450] [Broad-band THz emission by Spin-to-Charge Conversion in Topological Material -- Ferromagnet Heterostructures](https://arxiv.org/abs/2507.14838)
*Xingyue Han,Xiong Yao,Tilak Ram Thapaliya,Genaro Bierhance,Chihun In,Zhuoliang Ni,Amilcar Bedoya-Pinto,Sunxiang Huang,Claudia Felser,Stuart S. P. Parkin,Tobias Kampfrath,Seongshik Oh,Liang Wu*

Main category: cond-mat.mtrl-sci

TL;DR: 研究了拓扑材料（TIs和WSMs）与铁磁金属（FMs）组成的双层异质结构中的太赫兹自旋到电荷转换（SCC），结果表明拓扑材料在超快、宽带自旋电子应用中具有潜力。


<details>
  <summary>Details</summary>
Motivation: 为了开发下一代记忆技术，研究了太赫兹自旋电子器件的超快和低功耗特性，重点关注拓扑材料中的自旋到电荷转换（SCC）现象。

Method: 使用时域太赫兹发射光谱研究了拓扑绝缘体（TIs）或Weyl半金属（WSMs）与铁磁金属（FMs）组成的双层异质结构中的自旋到电荷转换（SCC）。

Result: SCC对TI厚度的依赖性受界面质量影响，不能单独用于区分SCC机制。TI的高效SCC依赖于原位生长和成分。NbP|FM双层结构表现出与TI相当的THz发射效率和带宽。TI和WSM均能产生高达8THz的THz脉冲。

Conclusion: Bi2Se3、Pb掺杂Bi2Se3、(Bi1-xSbx)2Te3等拓扑绝缘体（TIs）以及 the Weyl semimetal NbP与铁磁金属（FMs）形成的双层异质结构，通过时域太赫兹发射光谱研究了自旋到电荷的转换（SCC）。结果表明，SCC对TI厚度的依赖性随界面质量而变化，仅依赖厚度变化不足以区分SCC的机制。TI中的高效SCC依赖于原位生长和合适的成分。在NbP|FM双层结构中，观察到了与TI相当的THz发射效率和带宽。最终，宽带光谱测量表明TI和WSM都可以产生高达8THz频率的THz脉冲。

Abstract: Terahertz spintronic devices combine ultrafast operation with low power
consumption, making them strong candidates for next-generation memory
technologies. In this study, we use time-domain terahertz emission spectroscopy
to investigate spin-to-charge conversion (SCC) in bilayer heterostructures
comprising topological insulators (TIs) or Weyl semimetals (WSMs) with
ferromagnetic metals (FMs). SCC is studied in TI materials \ce{Bi2Se3},
Pb-doped \ce{Bi2Se3}, and (Bi$_{1-x}$Sb$_x$)$_2$Te$_3$, and the WSM NbP. Our
results reveal that the dependence of SCC on TI thickness varies with interface
quality, indicating that thickness dependence alone is not a reliable criterion
for distinguishing between inverse spin Hall effect and the inverse
Rashba--Edelstein effect mechanisms. We find efficient SCC in TIs depends on
both \textit{in-situ} growth to prevent surface oxidation and proper
composition. In NbP$\vert$FM bilayers, we observe THz emission with efficiency
and bandwidth comparable to that of TIs, highlighting the broader potential of
topological materials. Finally, broadband spectral measurements demonstrate
that both TIs and WSMs can generate THz pulses with frequencies extending up to
8\,THz. These findings underscore the promise of topological materials as
efficient platforms for ultrafast, broadband spintronic applications.

</details>


### [451] [Anomalous Power Factor Enhancement and Local Structural Transition in Ni-Doped TiCoSb](https://arxiv.org/abs/2507.15052)
*Suman Mahakal,Pallabi Sardar,Diptasikha Das,Subrata Jana,Swapnava Mukherjee,Biplab Ghosh,Shamima Hussain,Santanu K. Maiti,Kartick Malik*

Main category: cond-mat.mtrl-sci

TL;DR: Ni掺杂TiCoSb可大幅提高功率因子，通过调控局部结构和电子性质实现。


<details>
  <summary>Details</summary>
Motivation: 研究Ni掺杂对TiCoSb功率因子的增强机制，揭示其结构转变和电子结构变化。

Method: 通过第一性原理计算、X射线衍射（XRD）数据Rietveld精修、Williamson-Hall和修正方法、Ti和Co K边X射线吸收光谱（XAS）、以及温度相关电阻率（ρ(T)）和热电势（S(T)）数据分析，研究Ni掺杂对TiCoSb的结构和电子性质的影响。

Result: Ni掺杂（x=0.02）引起费米能级（EF）移动和态密度（DOS）改变，导致局部结构转变，功率因子（PF）显著提高约269%。

Conclusion: Ni掺杂TiCoSb样品（TiCo_{1-x}Ni_xSb，x=0.0, 0.01, 0.02, 0.03, 0.04, and 0.06）的功率因子（PF）显著提高（~269%），并伴随局部结构转变。

Abstract: We report a significant enhancement (~269%) in the power factor (PF) and a
local structural transition in Ni-doped TiCoSb samples (TiCo_{1-x}Ni_xSb, (x=
0.0, 0.01, 0.02, 0.03, 0.04, and 0.06). First-principles calculations reveal
that even minute Ni doping induces a substantial shift in the Fermi level (EF)
and alters the density of states (DOS). Structural analysis via Rietveld
refinement of X-ray diffraction (XRD) data shows anomalous behavior at x =
0.02, supported by Williamson-Hall and modified methods. X-ray absorption
spectroscopy (XAS) at the Ti and Co K-edges further confirms a pronounced local
structural change at this composition. These structural transitions are
consistent with temperature-dependent resistivity (\rho(T)) and thermopower
(S(T)) data, which reflect changes in EF and disorder. Analysis of Lorentz
number and scattering parameters reinforces the observed modifications in the
electronic structure. The simultaneous enhancement of S and electrical
conductivity at x = 0.02 is attributed to the disorder-to-order transition,
leading to the marked rise in PF.

</details>


### [452] [Quantum Mechanical Study of the Electronic Structure and Thermoelectric Properties of Heusler Alloys](https://arxiv.org/abs/2507.15180)
*Deep Patel*

Main category: cond-mat.mtrl-sci

TL;DR: 研究了七种赫斯勒合金的特性，以了解它们的半金属特性，并为设计新型合金提供了指导。


<details>
  <summary>Details</summary>
Motivation: 自半导体行业发展以来，具有半金属特性的材料引起了研究人员越来越多的关注。赫斯勒合金已在技术应用中用作自旋滤波器、隧道结或巨磁阻（GMR）器件。

Method: 使用从头算方法研究了PdMnSn和七种新型合金（AuCrSn、AuMnGe、Au2MnSn、Cu2NiGe、Pd2NiGe和Pt2CoSn）的电子结构、声子色散、热力学性质和电导率及其磁矩，以了解这些赫斯勒家族合金的半金属特性的根源。

Result: 通过声子色散评估了合金在各自相中的热力学稳定性。还利用声子模式进一步理解了这七种合金晶体中的电输运。

Conclusion: 本研究评估了材料的电导率与能带结构中少数自旋带隙之间的关系，并为设计具有C1b和L21结构的新型半金属赫斯勒合金的构成元素提供了建议。

Abstract: Heusler alloys were discovered in 1903, and materials with half-metallic
characteristics have drawn more attention from researchers since the advances
in semiconductor industry. Heusler alloys have found application as
spin-filters, tunnel junctions or giant magnetoresistance (GMR) devices in
technological applications. In this work, the electronic structures, phonon
dispersion, thermal properties, and electrical conductivities of PdMnSn and six
novel alloys (AuCrSn, AuMnGe, Au2MnSn, Cu2NiGe, Pd2NiGe and Pt2CoSn) along with
their magnetic moments are studied using ab initio calculations to understand
the roots of half-metallicity in these alloys of Heusler family. From the
phonon dispersion, the thermodynamic stability of the alloys in their
respective phases is assessed. Phonon modes were also used to further
understand the electrical transport in the crystals of these seven alloys. This
study evaluates the relationship between materials' electrical conductivity and
minority-spin bandgap in the band structure, and it provides suggestions for
selecting constituent elements when designing new half-metallic Heusler alloys
of C1b and L21 structures.

</details>


### [453] [Energy Underprediction from Symmetry in Machine-Learning Interatomic Potentials](https://arxiv.org/abs/2507.15190)
*Wei Nong,Ruiming Zhu,Zekun Ren,Martin Hoffmann Petersen,Shuya Yamazaki,Nikita Kazeev,Andrey Ustyuzhanin,Gang Wu,Shuo-Wang Yang,Kedar Hippalgaonkar*

Main category: cond-mat.mtrl-sci

TL;DR: MLIAP倾向于低估材料能量，尤其是在高对称性结构中，这是由于对对称性处理不当。建议改进模型以更好地处理对称性。


<details>
  <summary>Details</summary>
Motivation: 指出MLIAP在材料模拟中的一个关键且被忽视的问题：系统性的能量低估，尤其是在大规模热力学稳定性评估中，这影响了其可靠性。

Method: 通过对Materials Project中的150,000多种无机晶体进行超过1200万次计算，使用9种MLIAP评估其能量（Ehull）、总能量和形成能。

Result: 大多数MLIAP持续低估能量（Ehull），平均绝对误差（MAE）超过30 meV/atom，即使在训练数据中包含90%以上的测试结构时也是如此。模型在高对称性DOF结构中表现出明显的误差（Ehull的MAE > 40 meV/atom），并严重低估了近hull材料的能量。

Conclusion: MLIAPs在材料模拟中表现出色，但存在系统性能不足的问题，尤其是在评估热力学稳定性时。该问题源于对对称性自由度（包括晶格对称性和空间群的Wyckoff位点对称性）处理不足。高对称性DOF的结构误差较大（Ehull的MAE > 40 meV/atom）。近hull材料也存在严重的能量低估。建议开发更强的对称性感知模型（如显式DOF编码或对称性正则化损失函数），以及更稳健的MLIAP来预测晶体性质。

Abstract: Machine learning interatomic potentials (MLIAPs) have emerged as powerful
tools for accelerating materials simulations with near-density functional
theory (DFT) accuracy. However, despite significant advances, we identify a
critical yet overlooked issue undermining their reliability: a systematic
energy underprediction. This problem becomes starkly evident in large-scale
thermodynamic stability assessments. By performing over 12 million calculations
using nine MLIAPs for over 150,000 inorganic crystals in the Materials Project,
we demonstrate that most frontier models consistently underpredict energy above
hull (Ehull), a key metric for thermodynamic stability, total energy, and
formation energy, despite the fact that over 90\% of test structures
(DFT-relaxed) are in the training data. The mean absolute errors (MAE) for
Ehull exceed ~30 meV/atom even by the best model, directly challenging claims
of achieving ``DFT accuracy'' for property predictions central to materials
discovery, especially related to (meta-)stability. Crucially, we trace this
underprediction to insufficient handling of symmetry degrees of freedom (DOF),
constituting both lattice symmetry and Wyckoff site symmetries for the space
group. MLIAPs exhibit pronounced errors (MAE for Ehull $>$ ~40 meV/atom) in
structures with high symmetry DOF, where subtle atomic displacements
significantly impact energy landscapes. Further analysis also indicates that
the MLIAPs show severe energy underprediction for a large proportion of
near-hull materials. We argue for improvements on symmetry-aware models such as
explicit DOF encoding or symmetry-regularized loss functions, and more robust
MLIAPs for predicting crystal properties where the preservation and breaking of
symmetry are pivotal.

</details>


### [454] [Light-induced ultrafast magnetization dynamics in van der Waals antiferromagnetic CrSBr](https://arxiv.org/abs/2507.15199)
*Ali Kefayati,Branislav Nikolic,Yafei Ren*

Main category: cond-mat.mtrl-sci

TL;DR: 本研究利用TDDFT研究了CrSBr在飞秒激光下的磁化动力学。低注量时激光频率影响磁矩变化，高注量时发生退磁。退磁主因是层内/间自旋转移，非自旋-轨道耦合。低注量为重叠激发，高注量为电子激发。外加磁场可产生电荷流和奇次谐波。


<details>
  <summary>Details</summary>
Motivation: 研究CrSBr在飞秒激光脉冲驱动下的磁化动力学，特别是激光注量和激发频率对超快动力学的影响，以及外加静态磁场的作用。

Method: 本研究利用时依赖密度泛函理论（TDDFT）研究了CrSBr的磁化动力学。

Result: 低注量下，激光频率低于带隙时，Cr的局域磁矩增加；激光频率低于带隙时，Cr的局域磁矩减小。高注量下，发生与激发频率无关的强退磁。超快退磁主要由层内和层间光学异位自旋转移引起，自旋-轨道耦合的自旋翻转作用较小。低注量下为重叠激发，高注量下为电子激发。外加静态磁场可引起面外电荷流（逆自旋霍尔效应）和局域磁矩动力学中的奇次谐波。

Conclusion: 本研究通过时依赖密度泛函理论研究了疇铁磁范德华半导体CrSBr在飞秒激光脉冲驱动下的磁化动力学，并探讨了激光注量和激发频率对自旋超快动力学的影响。结果表明，在低注量下，当激光频率低于带隙时，Cr的局域磁矩增加；当激光频率低于带隙时，Cr的局域磁矩减小。在高注量下，无论激发频率如何，都会发生强烈的退磁。本研究发现，CrSBr中的超快退磁主要由层内和层间光学异位自旋转移引起，而通过自旋-轨道耦合产生的自旋翻转起次要作用。研究结果揭示了低注量下的空穴激发和高注量下的电子激发。此外，本研究还探讨了外加静态磁场对动力学的影响，并展示了局域磁矩和电流中存在的偶次和奇次高次谐波产生。外加磁场通过逆自旋霍尔效应产生面外电荷流，并由于时间反转对称性的破坏而在局域磁矩动力学中产生奇次谐波。

Abstract: The magnetization dynamics driven by the femtosecond laser pulse of
antiferromagnet van der Waals semiconductor CrSBr is studied within
time-dependent density functional theory. We investigate the effect of laser
fluence as well as the excitation frequency on the ultrafast dynamics of spins.
In low fluence, the local magnetic moment of Cr increases when the laser
frequency is below the band gap, whereas it decreases when the laser frequency
is below the band gap. In high fluence, we find strong demagnetization
independent of excitation frequency. We find that the ultrafast demagnetization
in CrSBr is dominated by intralayer and interlayer optical intersite spin
transfer, and spin flip via the spin-orbit coupling plays a minor role. Our
results reveal hole excitation in the low-fluence regime and electron
excitation in the high-fluence regime. Further, we investigate the effect of
the external static magnetic field on the dynamics. We demonstrate even and odd
high harmonic generation in the local magnetic moments and electric current,
respectively. The external magnetic field results in an out-of-plane charge
current via the inverse spin Hall effect as well as odd harmonics in the local
magnetic moment dynamics as a result of breaking the time-reversal symmetry.

</details>


### [455] [Anomalous charge density wave in two-dimensional altermagnet WO](https://arxiv.org/abs/2507.15429)
*Zi-Hao Ding,Zhen-Feng Ouyang,Ze-Feng Gao,Wei Ji,Kai Liu,Peng-Jie Guo,Zhong-Yi Lu*

Main category: cond-mat.mtrl-sci

TL;DR: 首次在单层WO中发现了反磁性与电荷密度波共存，并揭示了其形成机制和反常的相变行为。


<details>
  <summary>Details</summary>
Motivation: 探索反磁性与电荷密度波结合的物理性质，以及反磁性在稳定电荷密度波中的作用。

Method: 基于对称性分析和第一性原理计算

Result: 发现了单层WO材料中反磁性与电荷密度波可以共存，反磁性稳定了电荷密度波，且电荷密度波的形成由强电子-声子耦合驱动，并导致了材料从半金属到金属的反常转变。

Conclusion: 该研究首次证明了二维材料中反磁性与电荷密度波共存的可能性，并提出单层WO是此类材料的实例。研究揭示了反磁性序有效稳定了WO中的电荷密度波，且该波并非源于费米面嵌套，而是由强电子-声子耦合驱动。更重要的是，单层WO中的电荷密度波导致了从半金属到金属的反常转变，最终实现了反常的电荷密度波相。考虑到反磁性电荷密度波态下的强电子-声子耦合和良好的金属性质，该研究为实现非平凡的反磁性超导提供了新的思路。

Abstract: Recently, the study of novel physical properties arising from the combination
of altermagnetism and other matter phases has attracted widespread attention,
such as the integration of altermagnetism and topology. However, research on
the combination of altermagnetism and charge density waves remains relatively
sparse. In this letter, based on symmetry analysis and first-principles
calculations, we demonstrate for the first time that altermagnetism and charge
density waves can coexist in a two-dimensional material and predict monolayer
WO to be such a material. Moreover, our calculations reveal that the
altermagnetic order in monolayer WO stabilizes the $\sqrt{2}\times\sqrt{2}$
charge density wave. Further, the $\sqrt{2}\times\sqrt{2}$ charge density wave
is not driven by Fermi-surface nesting but rather by strong electron-phonon
coupling. More importantly, the $\sqrt{2}\times\sqrt{2}$ charge density wave in
monolayer WO leads to an anomalous transition from semimetal to metal.
Therefore, we realize an anomalous charge density wave phase in altermagnetic
WO. Considering the strong electron-phonon coupling and good metallic
properties in the altermagnetic charge density wave state, our work may provide
new insights into the realization of nontrivial altermagnetic
superconductivity.

</details>


### [456] [Engineering Spin Splitting in Antiferromagnets by Superatoms with Internal Degree of Freedom](https://arxiv.org/abs/2507.15213)
*Fengxian Ma,Zeying Zhang,Zhen Gao,Xiaobei Wan,Yandong Ma,Yalong Jiao,Shengyuan A. Yang*

Main category: cond-mat.mtrl-sci

TL;DR: 本研究利用超原子的内禀自由度（IDOF）来设计二维反铁磁体（AFM）材料，通过调控超原子的对称性来控制自旋分裂。以Mo修饰的碳硼石烯为例，证明了碳硼烷超原子的不同IDOF能够实现精确的自旋分裂调控，为新型自旋电子材料的设计提供了新思路。


<details>
  <summary>Details</summary>
Motivation: 当前，超原子作为构成新材料的单元，因其独特的性质和在二维材料组装中的潜力而受到广泛关注，但对其内禀自由度（IDOF）的作用研究不足。另一方面，具有本征自旋劈裂能带结构的补偿反铁磁体（AFM）在自旋电子学领域具有应用前景，但在二维体系中的实验实现受限。本研究旨在结合这两个领域，提出一种利用超原子IDOF来构筑二维AFM材料的新方法。

Method: 本研究结合了理论模型和第一性原理计算。首先，使用一个简单的模型阐述了如何利用超原子的IDOF来调控系统对称性并诱导AFM态的自旋分裂。随后，通过第一性原理计算，具体地在由闭合碳硼烷超原子构成的Mo修饰的碳硼石烯薄膜上验证了这一策略，分析了不同碳硼烷异构体的IDOF对材料对称性和自旋分裂的影响。

Result: 研究结果表明，超原子的IDOF（特别是电偶极矩和四极矩）是决定二维超原子晶体对称性的关键因素，进而能够有效地调控其反铁磁态的自旋分裂模式。具体而言，通过Mo修饰碳硼石烯的例子证明，不同的碳硼烷超原子IDOF可以导致不同的自旋分裂特征。

Conclusion: 本研究提出了利用具有内禀自由度（IDOF）的超原子来构筑自旋分裂的补偿反铁磁体（AFM）的新策略，并以Mo修饰的碳硼石烯（由闭合碳硼烷超原子构成）为例进行了理论验证。研究表明，碳硼烷异构体的IDOF（电偶极矩和四极矩）能够调控超原子晶格的对称性，进而影响其AFM态的自旋分裂模式。这揭示了超原子IDOF在设计AFM材料方面的重要性，为开发新型自旋电子和量子材料开辟了新途径。

Abstract: Superatoms, stable atomic clusters acting as building blocks for new
materials, offer unique opportunities due to their rich properties and
potential for 2D material assembly. While extensive research has focused on
their similarities to ordinary atoms, the role of their internal degrees of
freedom (IDOF) remains largely unexplored. Concurrently, compensated
antiferromagnets (AFMs) with intrinsic spin-split band structures have emerged
as a promising class of materials for spintronics, yet their experimental
realization, particularly in two dimensions, is limited. Here, we bridge these
two fields by proposing a novel strategy to achieve spin-split AFMs using
superatoms with IDOFs. We establish our core concept using a simple model,
demonstrating how superatom IDOFs can be leveraged to engineer system symmetry
and induce spin splitting in AFM states. We concretely illustrate this strategy
by first-principles calculations on a Mo-decorated carborophene sheets,
constructed from closo-carborane superatoms. We show that the distinct IDOFs of
carborane isomers (electric-dipole-like and nematic) are critical in
determining the symmetry of the resulting 2D superatomic crystal and,
consequently, the spin splitting pattern of its AFM states. Our findings
underscore the profound significance of superatom IDOFs-a feature absent in
ordinary atoms-and introduce a new paradigm for engineering spin splitting in
AFM lattices. This work opens novel avenues for the design of advanced
spintronic and quantum materials based on superatoms.

</details>


### [457] [High pressure and temperature thermoelasticity of hcp osmium from ab initio quasi-harmonic theory](https://arxiv.org/abs/2507.15354)
*Xuejun Gong,Andrea Dal Corso*

Main category: cond-mat.mtrl-sci

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: We present a systematic ab initio study of the thermoelastic properties of
hcp osmium as functions of temperature and pressure within the quasi-harmonic
approximation (QHA). The precision of the Zero Static Internal Stress
Approximation (ZSISA) and of the volume-constrained ZSISA (V-ZSISA) are
rigorously assessed. For osmium, we find negligible deviations between ZSISA
and a full free energy minimization (FFEM) approach. Also, the V-ZSISA
approximation influences the results very little, as we found already in
beryllium, despite the markedly different behavior of the c/a ratio with
temperature in the two metals. Our QHA-derived ECs show excellent agreement
with available experimental data in the temperature range of 5-301 K,
outperforming the results obtained from the quasi-static approximation (QSA).
Additionally, we report the pressure-dependent QHA ECs at 5 K, 301 K, and 1000
K, spanning pressures from 0 to 150 kbar.

</details>


### [458] [Pressure-Induced Low-Spin State Destabilization and Piezo-Chromic Effect in an Iron(II) Spin Crossover Complex with Pyrazol-Pyridine-Triazolate Coordination Core](https://arxiv.org/abs/2507.15369)
*Hanlin Yu,Maksym Seredyuk,Nan Ma,Katerina Znoviak,Nikita Liedienov,M. Carmen Muñoz,Iván da Silva,Francisco-Javier Valverde Muñoz,Ricardo-Guillermo Torres Ramírez,Elzbieta Trzop,Wei Xu,Quanjun Li,Bingbing Liu,Georgiy Levchenko,J. Antonio Real*

Main category: cond-mat.mtrl-sci

TL;DR: 该研究合成了一种新的铁(II)自旋交叉配合物，发现其在压力下表现出反常的自旋转变行为，并用包含弹性相互作用的热力学模型解释了这些现象。


<details>
  <summary>Details</summary>
Motivation: 为了满足科学技术对具有多功能和潜在应用前景的新材料的需求，本研究关注具有基础科学意义和潜在应用价值的铁(II)自旋交叉（SCO）配合物。特别地，本研究旨在探索一种新型SCO配合物在压力下的反常自旋转变行为，以加深对其物理化学性质的理解。

Method: 本研究通过合成新的单核SCO配合物 [FeII(L)2]0*nMeOH，并研究了其在不同压力下的磁学和光学性质，以探索其自旋交叉行为。使用了一系列实验技术，包括磁化率测量和光学光谱分析，并结合热力学模型来解释观察到的现象。

Result: 研究成功合成了新的单核SCO配合物 [FeII(L)2]0*nMeOH。溶剂化形式在高自旋状态下保持稳定，而非溶剂化形式在室温下表现出自旋转变。压力对非溶剂化形式的ST表现出反常影响，包括特征温度降低、低温区高自旋比例增加、热滞回线变宽以及在高压下稳定在高自旋状态。这些结果通过包含弹性相互作用的热力学模型得到了合理解释。

Conclusion: 该研究提出了一个新的单核自旋交叉（SCO）配合物 [FeII(L)2]0*nMeOH，其中L是[4-三氟甲基苯基-(1H-1,2,4-三唑-5-基)-6-(1H-吡唑-1-基)吡啶]。研究发现，溶剂化形式（n=2）在所有温度下均保持高自旋状态，而非溶剂化形式（4CF3）在室温下表现出完整的自旋转变（ST）。然而，压力对其ST表现出反常行为，包括特征温度降低、在低温区高自旋摩尔分数增加、热滞回线宽度增加，以及在高压下稳定在高自旋状态。这些现象已通过基于弹性相互作用的热力学模型得到解释。

Abstract: Rapidly developing science and technology demand new materials with versatile
and promising properties for practical applications. In this context,
pseudo-octahedral iron(II) spin crossover (SCO) complexes are particularly
appealing - not only for their fundamental scientific interest but also for
their potential as key components in the development of multifunctional
switchable molecular materials and novel technological applications. This work
presents the synthesis and structure of a new mononuclear SCO complex
[FeII(L)2]0*nMeOH (n = 2, 0) where L is the asymmetrically substituted
tridentate ligand
[4-trifluoromethylphenyl-(1H-1,2,4-triazol-5-yl)-6-(1H-pyrazol-1-yl)pyridine].
Due to high trigonal distortion, the solvated form (n = 2) remains high spin
(HS) at all temperatures. In contrast, the more regular Oh geometry of the
unsolvated form, 4CF3, favors a complete spin transition (ST) at room
temperature, which has been investigated, in the pressure interval 0-0.64 GPa,
by means of its magnetic and optical properties. Contrary to intuition and
experience, the increase of pressure on 4CF3 denotes a radically abnormal
behavior of this ST, involving: i) decrease of the characteristic temperatures,
ii) increase of the high-spin molar fraction in the temperature range where the
low-spin state is stable at ambient pressure; iii) increase of the thermal
hysteresis width; and iv) above certain threshold pressure, full stabilization
of the high-spin state. All these observations have been explained in the
framework of a thermodynamic that model based on the elastic interactions.

</details>


### [459] [Simphony: A full tight-binding package for lattice vibrations and topological phonon analysis](https://arxiv.org/abs/2507.15413)
*Francesc Ballester,Ion Errea,Maia G. Vergniory*

Main category: cond-mat.mtrl-sci

TL;DR: Simphony是一款开源软件，用于分析晶格振动的拓扑结构，可以诊断极性绝缘体的拓扑结构。


<details>
  <summary>Details</summary>
Motivation: Simphony的目的是对晶格振动进行拓扑分析，并对新型材料进行拓扑分类。

Method: Simphony是一个开源软件包，通过计算体和板状声子能带结构、提取声子表面谱以及提供Wilson回路计算和Weyl节点检测等分析工具，对基于Wannier紧束缚模型的晶格振动进行拓扑分析。

Result: Simphony能够计算体和板状声子能带结构，提取声子表面谱，并进行Wilson回路计算和Weyl节点检测，能够诊断极性绝缘体的拓扑结构。

Conclusion: Simphony能够诊断极性绝缘体的拓扑结构，这是少数能够做到这一点的工具之一。

Abstract: Simphony is an open-source software package designed for the topological
analysis of lattice vibrations based on Wannier tight-binding models. Its
primary function is to classify the topology of novel materials by computing
bulk and slab phonon band structures, extracting phonon surface spectra, and
providing analysis tools such as Wilson loop calculations and Weyl node
detection. The workflow is analogous to that of established electronic topology
codes like Wannier90 and WannierTools. It also incorporates long-range polar
interactions during the wannierization process, making Simphony one of the
first tools capable of diagnosing topology in polar insulators.

</details>


### [460] [Data-driven Discovery of Novel High-performance Quaternary Chalcogenide Photovoltaics](https://arxiv.org/abs/2507.15430)
*Nikhil Singh,Mohammad Ubaid,Pabitra Kumar Nayak,Jiangang He,Dibyajyoti Ghosh,Chris Wolverton,Koushik Pal*

Main category: cond-mat.mtrl-sci

TL;DR: 利用DFT和分子动力学模拟，预测了四种具有优异光电性能的新型光伏材料（SrCuGdSe3, SrCuDyTe3, BaCuLaSe3, BaCuLaTe3），它们在带隙、光学吸收、载流子寿命和稳定性方面表现突出，有望成为高效太阳能电池的候选材料。


<details>
  <summary>Details</summary>
Motivation: 为了寻找环保且经济高效的能源解决方案，该研究旨在通过预测高性能光吸收材料来推动光伏技术的发展。具体来说，研究人员希望发现具有理想光电性能的新型光伏材料，特别是那些在可见光吸收方面表现优异的材料，以期超越现有材料如晶体硅、GaAs和有机-碘化铅。

Method: 结合数据驱动方法、静态和时变密度泛函理论（DFT）以及非绝热分子动力学模拟，研究人员预测了14种高性能光吸收材料。对其中四种材料（SrCuGdSe3, SrCuDyTe3, BaCuLaSe3, BaCuLaTe3）进行了更详细的研究，利用包括自旋-轨道耦合的混合密度泛函理论计算了它们的带隙、光学吸收系数、有限尺寸的最高效率（SLME）、激子结合能和光激发载流子动力学。此外，还计算了这些化合物的缺陷形成能。

Result: 研究预测了14种高性能光吸收材料，并详细研究了SrCuGdSe3, SrCuDyTe3, BaCuLaSe3和BaCuLaTe3。这些材料具有1.65, 1.79, 1.05, 和 1.01 eV的直接带隙，处于可见光吸收的理想范围。它们的光学吸收系数和有限尺寸的最高效率（SLME）与晶体硅、GaAs和有机-碘化铅相当或更高。激子结合能小（30-32 meV），有利于电子-空穴分离。载流子寿命长（约30-40 ns），抑制了非辐射复合。虽然存在阳离子空位和间隙缺陷，但它们不会形成有害的中带隙态，对载流子复合无负面影响。

Conclusion: 研究预测了14种高性能光吸收材料，其中SrCuGdSe3, SrCuDyTe3, BaCuLaSe3和BaCuLaTe3表现出优异的光电性能，具有接近可见光吸收的理想带隙、与硅和GaAs相当的光学性质、小的激子结合能、长的载流子寿命以及无害的缺陷，这些都预示着它们在光伏领域的巨大潜力，值得进一步的实验验证和研究。

Abstract: Photovoltaic materials facilitate the conversion of sunlight into electricity
by harnessing the interaction between light and matter, offering an
eco-friendly and cost-efficient energy solution. Combining data-driven
approaches with static and time-dependent density functional theories and
nonadiabatic molecular dynamics simulations, we predict 14 high-performance
photoabsorber materials from a family of known quaternary semiconductors. Among
these, we investigate four compounds - SrCuGdSe3, SrCuDyTe3, BaCuLaSe3, and
BaCuLaTe3 in greater detail. Hybrid density functional theory calculations
including spin-orbit coupling reveal that SrCuGdSe3, SrCuDyTe3, BaCuLaSe3 and
BaCuLaTe3 possess direct band gaps of 1.65, 1.79, 1.05, and 1.01 eV,
respectively. These band gap values lie close to an optimal range ideal for
visible-light absorption. Consequently, the calculated optical absorption
coefficient and spectroscopic limited maximum efficiency for these compounds
become comparable or larger than crystalline silicon, GaAs, and methylammonium
lead iodide. Calculated exciton binding energies for these compounds are
relatively small (30-32 meV), signifying easy separation of the electron-hole
pairs, and hence enhanced power conversion efficiencies. Investigations of
photoexcited carrier dynamics reveal a relatively long carrier lifetime (~
30-40 ns), suggesting suppressed nonradiative recombination and enhanced
photo-conversion efficiencies. We further determined the defect formation
energies in these compounds, which showed that despite the likely formation of
cation vacancies and interstitial defects, midgap states remain absent making
these defects non-detrimental to carrier recombination. Our theoretical
predictions invite experimental verification and encourage further
investigations of these and similar compounds in this quaternary semiconductor
family.

</details>


### [461] [Effect of Co partitioning to the γ matrix on the microstructural stablity of a Ti-rich Ni-Base Superalloy](https://arxiv.org/abs/2507.15447)
*Sudeepta Mukherjee,Hemant Kumar,B. S. Murty,Satyam Suwas,Surendra Kumar Makineni*

Main category: cond-mat.mtrl-sci

TL;DR: 本研究发现，在Ti含量高的Ni-Co-Cr-Al-Ti基高温合金中，增加钴（Co）含量可显著提高粗化抗性和活化能，尽管会降低γ'固溶线。通过APT和CALPHAD模拟发现，钴向γ基体偏析是控制γ'粗化的关键。研究还指出，γ'相体积分数对合金屈服强度的影响比析出物尺寸更重要。


<details>
  <summary>Details</summary>
Motivation: 高温下过 অপর alloy 的显微结构稳定性和力学性能很大程度上受其组分和溶质性质的影响。通常，具有更高固溶线温度的合金具有更好的γ'粗化抗性，但更大的晶格错配会加速γ'粗化。本研究旨在探索钴（Co）元素对Ti含量高的Ni-Co-Cr-Al-Ti基合金的微观结构演变、热物理/机械性能和γ'析出物粗化动力学的影响，特别是钴向γ基体偏析对溶质再分配和粗化行为的控制作用。

Method: 本研究采用实验与理论相结合的方法，包括原子探针断层扫描（APT）和CALPHAD模拟，以探索钴（Co）对Ti含量高的Ni-Co-Cr-Al-Ti基合金的微观结构演变、热物理/机械性能以及γ'析出物粗化动力学的影响，特别关注钴向γ基体偏析对其他溶质在界面重新分布的影响。

Result: 随着Co含量从10at.%增加到30at.%，合金的粗化抗性显著提高，活化能加倍，尽管γ'固溶线降低了75°C。钴向γ基体偏析对γ基体中的溶质传输以及跨越γ/γ'界面的溶质通量起着关键作用，从而控制了整体的γ'粗化行为。此外，γ'相体积分数对合金的0.2%屈服强度的影响大于γ'析出物的尺寸。

Conclusion: 钴元素在镍钴铬铝钛基高温合金中显著提高了粗化抗性，并使活化能加倍，尽管其γ'固溶线将降低75°C。该研究通过结合原子探针断层扫描和CALPHAD模拟，揭示了钴向γ基体偏析对溶质在γ基体中再分布和跨越γ/γ'界面的溶质通量的影响，进而控制了γ'粗化行为。此外，研究还表明γ'相体积分数比γ'析出物尺寸对合金的0.2%屈服强度有更大的影响。

Abstract: The microstructural stability and mechanical properties of superalloys at
high temperatures are significantly influenced by the composition and nature of
the solutes they contain. Most of the alloys with high solvus temperature have
higher gamma prime coarsening resistance, while the larger lattice misfit is
attributed to higher gamma prime coarsening rate. In this work, we explore the
influence of Co on the microstructure evolution, thermophysical/mechanical
properties and gamma prime precipitate coarsening kinetics in a Ti-rich
Ni-Co-Cr-Al-Ti based alloy. More specifically, we focus on the effect of
partitioning of Co into the gamma matrix on the redistribution of other solutes
across the interface. We observe a significant increase in the coarsening
resistance and a twofold increase in the activation energy with the increase in
the Co composition from 10at.%Co to 30at.%Co, even though the gamma prime
solvus reduces by 75C. As otherwise, a higher solvus, usually, indicates better
microstructural stability at high temperatures. We employed a combined
experimental and theoretical approach by atom probe tomography (APT) and
CALPHAD simulations to probe the critical role of Co partitioning to gamma
matrix on the solute transport in the gamma matrix and flux across the
gamma/gamma prime interfaces, which is found to control the overall gamma prime
coarsening behavior in the alloy. The observed behavior was rationlised by the
proposition of a simplistic unified coarsening rate expression that
successfully decouples thermodynamic and kinetic contributions. Additionally,
we also observe that the gamma prime volume fraction dominates over the gamma
prime precipitate size on the 0.2% yield strength (YS) of the alloys.

</details>


### [462] [Non-perturbative macroscopic theory of interfaces with discontinuous dielectric constant](https://arxiv.org/abs/2507.15580)
*Y. M. Beltukov,A. V. Rodina,A. Alekseev,Al. L. Efros*

Main category: cond-mat.mtrl-sci

TL;DR: 针对纳米结构和半导体异质结构界面处介电常数不连续性的问题，该研究开发了一种新的非微扰理论和广义边界条件（GBC），成功描述了载流子传播，并解释了光电效应和量子阱中的电子谱，同时考虑了界面参数W的影响。


<details>
  <summary>Details</summary>
Motivation: 介电常数在界面处的不连续性会导致自相互作用势发散，阻碍微扰描述，这在所有纳米结构和半导体异质结构中都是普遍存在的。

Method: 开发了一个非微扰理论，使用广义边界条件（GBC）和单个现象学参数W来描述载流子在具有介电常数不连续性的界面传播，并找到了薛定谔方程在界面附近的精确解以及包括共振在内的载流子能量谱。

Result: 找到了薛定谔方程在界面附近的精确解，获得了载流子能量谱（包含共振），并利用这些结果描述了半导体/真空界面处的光电效应和界面量子阱中的电子能量谱，同时分析了这些现象对界面参数W的依赖性。

Conclusion: 该研究提出了一个基于电流密度守恒的非微扰理论，用于描述载流子在具有介电常数不连续性的界面传播，并提出了适用于具有单个现象学参数W的界面波函数的广义边界条件（GBC）。

Abstract: Discontinuity of dielectric constants at the interface is a common feature of
all nanostructures and semiconductor heterostructures. It gives rise to a
divergence of the self-interaction potential acting on a charge near the
interface, and it presents an obstruction to a perturbative description. In
several limiting cases, this problem can be avoided by zeroing out the carrier
wave function at the interface. In this paper, we developed a non-perturbative
theory which gives a self-consistent description of carrier propagation through
an interface with dielectric discontinuity. It is based on conservation of the
current density propagating through the interface, and it is formulated in
terms of general boundary conditions (GBC) for the wave function at the
interface with a single phenomenological parameter W. For these GBC, we find
exact solutions of the Schr\"odinger equation near the interface and the
carrier energy spectrum including resonances. Using these results, we describe
the photo effect at the semiconductor/vacuum interface and the electron energy
spectrum in the interface quantum well, as well as the dependence of these two
phenomena on the interface parameter W.

</details>


### [463] [Ab-initio exploration of Gd monolayer interfaced with WSe$_2$: from electronic and magnetic properties to the anomalous Hall effect](https://arxiv.org/abs/2507.15583)
*Lyes Mesbahi,Omar Messaoudi,Hamid Bouzar,Samir Lounis*

Main category: cond-mat.mtrl-sci

TL;DR: Gd/WSe2异质结通过强SOC和对称性破缺展现出可调控的异常霍尔效应(AHE)，其根源在于费米能级附近的d态避免交叉。


<details>
  <summary>Details</summary>
Motivation: 探索具有丰富物理现象的过渡金属硫族化合物(TMD)异质结构，特别是稀土材料与TMDs的界面效应。

Method: 利用第一性原理计算研究了Gd/WSe2异质结的电子结构、磁性和输运性质。

Result: 计算发现Gd/WSe2异质结表现出显著的异常霍尔电导(AHC)，主要归因于Gd和W的d态在费米能级附近的避免交叉。AHC可以通过改变晶格常数或Gd-WSe2间距进行调控。

Conclusion: 该研究探索了Gd/WSe2异质结的电子结构、磁性和输运性质，特别是异常霍尔效应(AHE)。通过结合强自旋-轨道耦合(SOC)和反演对称性破坏，在$m f oldsymbol
 	ext{Γ-K}$和$m f oldsymbol
 	ext{Γ-K}$'方向之间产生了显著的不对称性。计算结果表明，在铁磁界面处存在显著的异常霍尔电导(AHC)，这主要源于Gd和W的d态在费米能级附近的多次避免交叉。此外，研究还表明，通过调整面内晶格常数或减小Gd和WSe2之间的距离，可以有效地调控AHC。

Abstract: Heterostructures involving transition metal dichalcogenides (TMDs) have
attracted significant research interest due to the richness and versatility of
the underlying physical phenomena. In this work, we investigate a
heterostructure consisting of a rare-earth material, specifically a Gd
monolayer, interfaced with WSe$_2$. We explore its electronic structure,
magnetic properties, and transport behavior, with particular emphasis on the
emergence of the anomalous Hall effect (AHE). Both Gd and W are heavy elements,
providing strong spin-orbit coupling (SOC), which plays a crucial role in
triggering the AHE. The combination of strong SOC and inversion symmetry
breaking leads to pronounced asymmetries between the $\Gamma-K$ and
$\Gamma-K^\prime$ directions in the Brillouin zone. Our calculations reveal a
substantial anomalous Hall conductivity (AHC) at the ferromagnetic interface,
primarily originating from numerous avoided crossings involving the d-states of
both Gd and W near the Fermi level. Moreover, we demonstrate that the AHC is
highly tunable, either by adjusting the in-plane lattice constant or by
reducing the separation between Gd and WSe$_2$.

</details>


### [464] [Giant Reversible Piezoelectricity from Symmetry-Governed Stochastic Dipole Hopping](https://arxiv.org/abs/2507.15687)
*Denan Li,Haofei Ni,Yi Zhang,Shi Liu*

Main category: cond-mat.mtrl-sci

TL;DR: 杂化钙钛矿的巨压电响应源于有机阳离子的旋转跳跃，而非极化旋转或相变。


<details>
  <summary>Details</summary>
Motivation: 解释有机-无机杂化钙钛矿（如TMCM-CdCl3）巨压电响应的微观起源，因其在弱极性体系中的异常表现而难以理解。

Method: 采用深度学习辅助的大规模分子动力学模拟，研究了TMCM-CdCl3的压电响应机制。

Result: 成功复现了实验测量的压电系数 $d_{33} \approx 220$~pC/N，并证明了巨压电响应主要归因于有机阳离子（特别是C3对称性卤键网络中的有机阳离子）的120°平面内旋转跳跃，而非传统的极化旋转或相变。

Conclusion: 该研究通过深度学习辅助的大规模分子动力学模拟，揭示了TMCM-CdCl3等有机-无机杂化钙钛矿中巨压电响应的起源，发现其源于有机阳离子的集体贡献，特别是120°平面内旋转跳跃，并提出可通过调控主客体相互作用来提升压电性能。

Abstract: Organic--inorganic hybrid perovskites with giant piezoelectric responses,
exemplified by TMCM-CdCl$_3$, represent a promising platform for flexible and
environmentally friendly electromechanical materials. However, the microscopic
origin of such exceptional performance in this weakly polar system has remained
elusive. Here, using deep-learning-assisted large-scale molecular dynamics
simulations, we resolve this paradox by reproducing the experimentally measured
piezoelectric coefficient $d_{33} \approx 220$~pC/N, and demonstrating that the
giant response arises from the collective contribution of multiple intrinsic
components, particularly the shear component $d_{15}$. This effect does not
stem from conventional polarization rotation or phase switching, but instead
originates from stochastic 120$^\circ$ in-plane rotational hopping of a small
fraction of organic cations. This discrete hopping mechanism is governed by the
local C$_3$-symmetric halogen-bonding network between the host framework and
the guest cation. The Arrhenius-type temperature dependence of $d_{15}$ further
confirms the role of thermally activated dipole hopping. This work provides a
clear pathway to enhance piezoelectric performance of hybrid materials through
rational engineering of host--guest interactions.

</details>


### [465] [Evaluation of hydrogen diffusion and trapping in ferritic steels containing (Ti,Cr)C particles using electrochemical permeation and thermal desorption spectroscopy](https://arxiv.org/abs/2507.15711)
*Nicholas Winzer*

Main category: cond-mat.mtrl-sci

TL;DR: 研究表明，细小的 (Ti,Cr)C 颗粒会减缓铁素体钢中的氢扩散，但由于模型过度确定，无法精确量化俘获参数。


<details>
  <summary>Details</summary>
Motivation: 研究含 (Ti,Cr)C 颗粒的铁素体钢中氢的扩散和俘获行为，以了解这些颗粒对氢扩散和俘获的影响。

Method: 使用电化学渗透（EP）和热解吸光谱（TDS）研究氢扩散和俘获。使用基于麦克纳布-福斯特方程的有限元模型和最小二乘优化来拟合测量数据，以评估俘获参数。另外，使用基辛格方程从 TDS 测量中评估俘获参数。

Result: 含细小 (<5 nm) (Ti,Cr)C 颗粒的铁素体钢的氢扩散明显减慢。TDS 测量结果与具有高能垒的氢陷阱一致。通过有限元模型和麦克纳布-福斯特方程的拟合，发现系统被过度确定，无法确定单个俘获参数。使用基辛格方程计算出的结合能为 0.24 eV，但存在高度不确定性。

Conclusion: 氢在铁素体钢中的扩散和俘获受到细小 (<5 nm) (Ti,Cr)C 颗粒的显著减缓，而较粗大的颗粒几乎没有影响。通过有限元模型和麦克纳布-福斯特方程的拟合，评估了材料的俘获参数，但由于系统被过度确定，无法确定单个俘获参数。使用基辛格方程从热解吸光谱测量中得出的俘获参数显示结合能为 0.24 eV，但存在高度不确定性。

Abstract: Hydrogen diffusion and trapping in ferritic steels containing (Ti,Cr)C
particles was investigated using electrochemical permeation (EP) and thermal
desorption spectroscopy (TDS). The trapping parameters for the test materials
were evaluated by fitting the measurements with a finite element model based on
the McNabb-Foster equations using least-squares optimisation. The measurements
showed that hydrogen diffusion in ferrite is slowed significantly by the
presence of fine (<5 nm) (Ti,Cr)C particles; coarser particles had little or no
effect. The TDS measurements were consistent with hydrogen traps with a high
energy barrier. The uniqueness of the hydrogen trapping parameters obtained
using the fitting procedure was evaluated. It was found that the system was
overdetermined; the measurements could be fitted with multiple combinations of
trapping parameters. Consequently, it was not possible to determine the
individual trapping parameters using this procedure. Trapping parameters were
also evaluated from TDS measurements by applying Kissinger's equation. Using
this procedure a trap binding energy of 0.24 eV was calculated for all
materials, albeit with a high degree of uncertainty.

</details>


### [466] [Fully atomic layer deposited transparent carrier selective contacts for bifacial Cd-free Cu2ZnSnSe4 thin-film solar cells](https://arxiv.org/abs/2507.15712)
*Rosa Almache-Hernándeza,Gerard Masmitjà,Benjamín Pusay,Eloi Ros,Kunal J. Tiwari,Pedro Vidal-Fuentes,Victor Izquierdo-Roca,Edgardo Saucedo,Cristóbal Voz,Joaquim Puigdollers,Pablo Ortega*

Main category: cond-mat.mtrl-sci

TL;DR: 本研究使用 ZnO/AZO/PEI 替代了 kesterite 太阳能电池中的 CdS 层，并实现了双面光伏器件。


<details>
  <summary>Details</summary>
Motivation: 为了解决传统 kesterite 太阳能电池中使用有毒 CdS 层作为电子选择性接触层带来的环境问题，本研究旨在探索一种环保的替代方案。

Method: 本研究采用原子层沉积 (ALD) 技术制备 ZnO 和 Al:ZnO (AZO) 薄膜，并将其作为电子选择性接触层，以替代 kesterite 太阳能电池中使用的 CdS 层。同时，引入了聚乙烯亚胺 (PEI) 作为偶极子层以增强电学接触性能。背部接触则采用 ALD V2O5 薄层覆盖在 FTO 导电电极上。

Result: 在正面光照下，制备的 kesterite 太阳能电池实现了 35 mAcm⁻² 的光电流密度、约 260 mV 的开路电压和高达 3.5% 的效率。在背部光照下，这些参数分别为 5.3 mAcm⁻²、160 mV 和 0.3%，证明了所提出的结构具有双面性。

Conclusion: 该研究探索了使用 ZnO 和 Al:ZnO (AZO) 薄膜堆叠以及 PEI 互层来替代 kesterite 太阳能电池中的 CdS 接触层，并使用 ALD V2O5 薄层作为透明背部接触。

Abstract: Thin-film solar cells based on kesterite (Cu2ZnSnSe4) material are a
promising alternative for photovoltaic devices due to their composition
consisting of earth abundant elements, ease of production at a relatively low
temperatures and excellent optical absorption properties. Additionally, this
absorber compound allows a tuneable bandgap energy in the 1 to 1.5 eV window
range, which makes it an attractive candidate either as a top or a bottom solar
cell in tandem technologies combined with transparent carrier-selective
contacts. However, conventional kesterite devices use a toxic CdS layer as an
electron-selective contact, resulting in the difficultto-dispose chemical
waste. This work explores the use of a stack of ZnO and Al-doped ZnO (AZO)
films deposited by ALD to replace the CdS-based contacts in kesterite devices.
The inclusion of a polyethylenimine (PEI) interlayer as dipole to enhance the
overall electrical contact performance is also discussed. The transparent back
contact is formed by an ALD V2Ox thin layer over a FTO conductive electrode.
Fabricated kesterite solar cells exhibit remarkable photocurrent density values
of 35 mAcm-2, open-circuit voltage around 260 mV and efficiencies up to 3.5%
using front illumination. The aforementioned photovoltaic parameters yield to
5.3 mAcm-2, 160 mV and 0.3% respectively under back illumination, demonstrating
the bifaciality of the proposed structure.

</details>


### [467] [Charge density wave in intermetallic oxides R$_5$Pb$_3$O (R = La and Ce)](https://arxiv.org/abs/2507.15817)
*Rafaela F. S. Penacchio,Siham Mohamed,Haley A. Harms,Lin-Lin Wang,Sergey L. Bud'ko,Paul. C Canfield,Tyler J. Slade*

Main category: cond-mat.mtrl-sci

TL;DR: R$_5$Pb$_3$O (R = La, Ce) 具有由电子-声子耦合驱动的 CDW，并在低温下经历结构相变。


<details>
  <summary>Details</summary>
Motivation: 本研究旨在探索 R$_5$Pb$_3$O 家族的 La 和 Ce 成员，并揭示其结构相变和电荷密度波行为。

Method: 通过单晶 X 射线衍射和密度泛函理论计算，研究了 La$_5$Pb$_3$O 和 Ce$_5$Pb$_3$O 的结构和电子性质。

Result: 在 260 K 和 145 K 发现了二阶结构相变，导致了低对称性的 P4/ncc 结构。CDW 的订购温度因 La 到 Ce 的取代而降低了 100 K 以上。

Conclusion: La$_5$Pb$_3$O 和 Ce$_5$Pb$_3$O 表现出由电子-声子耦合驱动的电荷密度波 (CDW)。

Abstract: The R$_5$Pb$_3$O family was discovered decades ago, but has remained largely
unexplored. Here, we report single crystal growth and basic characterization
for the La and Ce members of this family. At room temperature, these compounds
adopt a tetragonal structure (I4/mcm), where R and Pb atoms form linear chains
along the c-axis. We identify a second-order structural phase transition at 260
K and 145 K for R = La and Ce, respectively. Single crystal X-ray diffraction
reveals a lattice modulation below the transition temperature, resulting in
R-Pb pairs in the z direction. The broken symmetry in the low-temperature
phases results in a primitive structure with space group P4/ncc. Transport and
diffraction measurements, in agreement with density functional theory
calculations, support that the R$_5$Pb$_3$O (R = La and Ce) series hosts an
electron-phonon coupling driven charge density wave (CDW) at low temperatures.
The CDW ordering temperature is suppressed by more than 100 K by the La to Ce
substitution, suggesting high pressure-sensitivity. Therefore, this family
offers the potential for investigating competing orders in oxides, with heavier
rare-earth members still to be explored.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [468] [The Free Will Equation: Quantum Field Analogies for AGI](https://arxiv.org/abs/2507.14154)
*Rahul Kabali*

Main category: cs.AI

TL;DR: 本文提出“自由意志方程”，借鉴量子场论，为AGI引入决策的随机性，以增强其创造力和适应性。实验证明此方法在非平稳环境中优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 为了使人工智能（AGI）具备人类智能中的自发适应性，特别是“自由意志”——一种不被过去数据或即时奖励严格决定的、能做出意想不到选择或自由决策的能力，以增强创造力、鲁棒适应性和避免问题解决中的僵化。

Method: 提出了一种名为“自由意志方程”的理论框架，借鉴量子场论的类比，将人工智能的认知状态视为潜在行动或思想的叠加态，并通过概率性地坍缩到具体行动来模拟决策过程。该框架还结合了量子场类比和内禀动机项。

Result: 实验结果表明，采用该框架的智能体在非平稳多臂老虎机环境中，与基线方法相比，获得了更高的奖励和策略多样性。

Conclusion: 所提出的自由意志方程通过引入受控随机性，有望提升人工智能在面对非固定环境时的决策能力、策略新颖性和适应性。

Abstract: Artificial General Intelligence (AGI) research traditionally focuses on
algorithms that optimize for specific goals under deterministic rules. Yet,
human-like intelligence exhibits adaptive spontaneity - an ability to make
unexpected choices or free decisions not strictly dictated by past data or
immediate reward. This trait, often dubbed "free will" in a loose sense, might
be crucial for creativity, robust adaptation, and avoiding ruts in
problem-solving. This paper proposes a theoretical framework, called the Free
Will Equation, that draws analogies from quantum field theory to endow AGI
agents with a form of adaptive, controlled stochasticity in their
decision-making process. The core idea is to treat an AI agent's cognitive
state as a superposition of potential actions or thoughts, which collapses
probabilistically into a concrete action when a decision is made - much like a
quantum wavefunction collapsing upon measurement. By incorporating mechanisms
analogous to quantum fields, along with intrinsic motivation terms, we aim to
improve an agent's ability to explore novel strategies and adapt to unforeseen
changes. Experiments in a non-stationary multi-armed bandit environment
demonstrate that agents using this framework achieve higher rewards and policy
diversity compared to baseline methods.

</details>


### [469] [DREAMS: Density Functional Theory Based Research Engine for Agentic Materials Simulation](https://arxiv.org/abs/2507.14267)
*Ziqi Wang,Hongshuo Huang,Hancheng Zhao,Changwen Xu,Shang Zhu,Jan Janssen,Venkatasubramanian Viswanathan*

Main category: cs.AI

TL;DR: DREAMS 是一个由 LLM 驱动的自动化框架，用于 DFT 材料发现，可自主处理复杂任务，减少对人类专家的依赖，并达到专家级别水平。


<details>
  <summary>Details</summary>
Motivation: 为了解决高通量、高保真度的材料发现中，如密度泛函理论（DFT）模拟所需多年的培训、广泛的参数微调和系统性错误处理等挑战。

Method: DREAMS 是一个基于 DFT 的、分层的、多智能体的材料筛选研究引擎。它结合了一个中心化的大型语言模型（LLM）规划器智能体，以及用于原子结构生成、系统性 DFT 收敛性测试、高性能计算（HPC）调度和错误处理的领域特定 LLM 智能体。此外，一个共享画布有助于 LLM 智能体构建它们的讨论、保存上下文并防止幻觉。

Result: DREAMS 在 Sol27LC 晶格常数基准测试中，相对于人类 DFT 专家的结果，实现了低于 1% 的平均误差。在 CO/Pt(111) 吸附问题中，DREAMS 重现了专家级别的文献吸附能量差异。此外，DREAMS 被用于通过贝叶斯集成采样来量化功能驱动的不确定性，证实了在广义梯度近似（GGA）DFT 级别上，面心立方（FCC）位点的偏好。

Conclusion: DREAMS 实现了 L3 级别的自动化（在定义的空间内自主探索），显著减少了对人类专业知识和干预的依赖，为实现高通量、高保真度的计算材料发现提供了可扩展的途径。

Abstract: Materials discovery relies on high-throughput, high-fidelity simulation
techniques such as Density Functional Theory (DFT), which require years of
training, extensive parameter fine-tuning and systematic error handling. To
address these challenges, we introduce the DFT-based Research Engine for
Agentic Materials Screening (DREAMS), a hierarchical, multi-agent framework for
DFT simulation that combines a central Large Language Model (LLM) planner agent
with domain-specific LLM agents for atomistic structure generation, systematic
DFT convergence testing, High-Performance Computing (HPC) scheduling, and error
handling. In addition, a shared canvas helps the LLM agents to structure their
discussions, preserve context and prevent hallucination. We validate DREAMS
capabilities on the Sol27LC lattice-constant benchmark, achieving average
errors below 1\% compared to the results of human DFT experts. Furthermore, we
apply DREAMS to the long-standing CO/Pt(111) adsorption puzzle, demonstrating
its long-term and complex problem-solving capabilities. The framework again
reproduces expert-level literature adsorption-energy differences. Finally,
DREAMS is employed to quantify functional-driven uncertainties with Bayesian
ensemble sampling, confirming the Face Centered Cubic (FCC)-site preference at
the Generalized Gradient Approximation (GGA) DFT level. In conclusion, DREAMS
approaches L3-level automation - autonomous exploration of a defined design
space - and significantly reduces the reliance on human expertise and
intervention, offering a scalable path toward democratized, high-throughput,
high-fidelity computational materials discovery.

</details>


### [470] [WebGuard: Building a Generalizable Guardrail for Web Agents](https://arxiv.org/abs/2507.14293)
*Boyuan Zheng,Zeyi Liao,Scott Salisbury,Zeyuan Liu,Michael Lin,Qinyuan Zheng,Zifan Wang,Xiang Deng,Dawn Song,Huan Sun,Yu Su*

Main category: cs.AI

TL;DR: LLM 驱动的 Web Agent 带来了意外行为的风险，需要安全措施。WebGuard 数据集通过对 4,939 个网站操作进行风险分类，为评估和开发护栏提供了支持。尽管对 LLM 的初步评估显示出风险，但使用 WebGuard 对 Qwen2.5VL-7B 模型进行微调可显著提高性能，但仍需进一步改进以满足高风险部署的要求。


<details>
  <summary>Details</summary>
Motivation: 随着自主 Web Agent 的快速发展，LLM 在提高效率的同时，也带来了意外或有害行为的风险。为了解决这个关键挑战，需要有效的安全措施，类似于对人类用户的访问控制。因此，本研究旨在通过提供一个全面的数据集来评估 Web Agent 操作风险，并促进在线环境的护栏开发。

Method: 本研究引入了一个名为 WebGuard 的数据集，该数据集包含 4,939 个来自 193 个网站的注释操作，跨越 22 个不同的域。这些操作根据 SAFE、LOW 和 HIGH 的三级风险模式进行分类，并包含用于评估的训练和测试拆分。研究人员还微调了一个 Qwen2.5VL-7B 模型，以评估护栏模型的性能。

Result: 在对 22 个领域的 193 个网站进行评估后，WebGuard 数据集显示，即使是先进的 LLM，在预测操作结果方面的准确性也低于 60%，在滞后高风险操作方面的召回率也低于 60%。通过使用 WebGuard 对 Qwen2.5VL-7B 模型进行微调，准确性从 37% 提高到 80%，高风险操作召回率从 20% 提高到 76%。

Conclusion: 尽管经过微调，但用于高风险部署的 WebGuard 仍需提高准确性和召回率。LLM 在预测网站操作结果方面的准确性低于 60%，并且在滞后高风险操作方面的召回率低于 60%，这凸显了在没有专门保护措施的情况下部署当前一代代理的风险。然而，使用 WebGuard 对专用护栏模型进行微调可显著提高性能，将准确性从 37% 提高到 80%，并将高风险操作召回率从 20% 提高到 76%。

Abstract: The rapid development of autonomous web agents powered by Large Language
Models (LLMs), while greatly elevating efficiency, exposes the frontier risk of
taking unintended or harmful actions. This situation underscores an urgent need
for effective safety measures, akin to access controls for human users. To
address this critical challenge, we introduce WebGuard, the first comprehensive
dataset designed to support the assessment of web agent action risks and
facilitate the development of guardrails for real-world online environments. In
doing so, WebGuard specifically focuses on predicting the outcome of
state-changing actions and contains 4,939 human-annotated actions from 193
websites across 22 diverse domains, including often-overlooked long-tail
websites. These actions are categorized using a novel three-tier risk schema:
SAFE, LOW, and HIGH. The dataset includes designated training and test splits
to support evaluation under diverse generalization settings. Our initial
evaluations reveal a concerning deficiency: even frontier LLMs achieve less
than 60% accuracy in predicting action outcomes and less than 60% recall in
lagging HIGH-risk actions, highlighting the risks of deploying
current-generation agents without dedicated safeguards. We therefore
investigate fine-tuning specialized guardrail models using WebGuard. We conduct
comprehensive evaluations across multiple generalization settings and find that
a fine-tuned Qwen2.5VL-7B model yields a substantial improvement in
performance, boosting accuracy from 37% to 80% and HIGH-risk action recall from
20% to 76%. Despite these improvements, the performance still falls short of
the reliability required for high-stakes deployment, where guardrails must
approach near-perfect accuracy and recall.

</details>


### [471] [Manimator: Transforming Research Papers into Visual Explanations](https://arxiv.org/abs/2507.14306)
*Samarth P,Vyoman Jain,Shiva Golugula,Motamarri Sai Sathvik*

Main category: cs.AI

TL;DR: Manimator是一个开源系统，使用LLM将研究论文和自然语言提示转换为Manim动画，以简化STEM内容的视觉解释创建过程。


<details>
  <summary>Details</summary>
Motivation: 手动创建动态可视化以增强对科学和数学概念的理解既耗时，又需要专门的知识和技能。该研究旨在解决这一挑战。

Method: Manimator利用大型语言模型（LLM）将研究论文和自然语言提示转换为使用Manim引擎的解释性动画。其工作流程包括：1. LLM解析输入文本或研究论文PDF，生成结构化的场景描述（包括关键概念、数学公式和视觉元素）。2. 另一个LLM将此描述转换为可执行的Manim Python代码。

Result: Manimator系统能够将研究论文和自然语言提示转换为解释性动画。

Conclusion: Manimator有潜力成为一种强大的教育工具，能够快速为复杂的STEM主题创建引人入胜的视觉解释，从而实现高质量教育内容的普及化。

Abstract: Understanding complex scientific and mathematical concepts, particularly
those presented in dense research papers, poses a significant challenge for
learners. Dynamic visualizations can greatly enhance comprehension, but
creating them manually is time-consuming and requires specialized knowledge and
skills. We introduce manimator, an open-source system that leverages Large
Language Models to transform research papers and natural language prompts into
explanatory animations using the Manim engine. Manimator employs a pipeline
where an LLM interprets the input text or research paper PDF to generate a
structured scene description outlining key concepts, mathematical formulas, and
visual elements and another LLM translates this description into executable
Manim Python code. We discuss its potential as an educational tool for rapidly
creating engaging visual explanations for complex STEM topics, democratizing
the creation of high-quality educational content.

</details>


### [472] [Language Models as Ontology Encoders](https://arxiv.org/abs/2507.14334)
*Hui Yang,Jiaoyan Chen,Yuan He,Yongsheng Gao,Ian Horrocks*

Main category: cs.AI

TL;DR: OnT是一种新的本体嵌入方法，它通过在双曲空间中对预训练语言模型进行几何建模来结合文本信息和保留逻辑结构，并在各种任务和应用中表现出色。


<details>
  <summary>Details</summary>
Motivation: 现有的本体嵌入方法要么忽略文本信息，要么无法保留逻辑结构，导致性能不佳。

Method: OnT通过在双曲空间中对预训练语言模型（PLM）进行几何建模来调优，以有效结合文本标签，同时保留逻辑结构和描述逻辑EL的层次结构。

Result: 在四个真实世界本体上的广泛实验表明，OnT在公理预测和推理任务上始终优于基线方法，并在实际应用中显示出强大的迁移学习能力和有效性。

Conclusion: OnT在公理预测和推理任务上始终优于包括最先进技术在内的基线方法，并且在构建来自SNOMED CT的新本体方面显示出强大的迁移学习能力和有效性。

Abstract: OWL (Web Ontology Language) ontologies which are able to formally represent
complex knowledge and support semantic reasoning have been widely adopted
across various domains such as healthcare and bioinformatics. Recently,
ontology embeddings have gained wide attention due to its potential to infer
plausible new knowledge and approximate complex reasoning. However, existing
methods face notable limitations: geometric model-based embeddings typically
overlook valuable textual information, resulting in suboptimal performance,
while the approaches that incorporate text, which are often based on language
models, fail to preserve the logical structure. In this work, we propose a new
ontology embedding method OnT, which tunes a Pretrained Language Model (PLM)
via geometric modeling in a hyperbolic space for effectively incorporating
textual labels and simultaneously preserving class hierarchies and other
logical relationships of Description Logic EL. Extensive experiments on four
real-world ontologies show that OnT consistently outperforms the baselines
including the state-of-the-art across both tasks of prediction and inference of
axioms. OnT also demonstrates strong potential in real-world applications,
indicated by its robust transfer learning abilities and effectiveness in real
cases of constructing a new ontology from SNOMED CT. Data and code are
available at https://github.com/HuiYang1997/OnT.

</details>


### [473] [One Step is Enough: Multi-Agent Reinforcement Learning based on One-Step Policy Optimization for Order Dispatch on Ride-Sharing Platforms](https://arxiv.org/abs/2507.15351)
*Zijian Zhao,Sen Li*

Main category: cs.AI

TL;DR: 本文提出GRPO和OSPO两种新方法，解决了叫车服务中MARL方法在价值函数估计上的挑战，实验证明了其优越性。


<details>
  <summary>Details</summary>
Motivation: 传统的MARL方法在叫车服务中依赖于准确的Q值或V值估计，这在大规模、高度不确定的环境中存在问题，特别是独立范式导致训练不稳定和价值函数估计偏差。因此，需要新的方法来解决这些挑战。

Method: 本文提出了两种新的方法来解决MARL在叫车服务中的应用问题：1.将GRPO适应于叫车服务，用组合平均奖励替换PPO基线，以消除评估者估计错误并减少训练偏差。2.定制PPO框架，仅使用单步奖励来训练最优策略，称为单步策略优化（OSPO）。

Result: 实验结果表明，GRPO和OSPO在真实曼哈顿叫车数据集上，在大多数场景下均取得了优于基线方法的性能，并有效优化了上车时间和订单数量，仅使用了简单的MLP网络。

Conclusion: GRPO和OSPO在大多数场景下实现了优于基线方法的性能，有效优化了上车时间和服务订单数量，并且仅使用了简单的MLP网络。

Abstract: On-demand ride-sharing platforms face the fundamental challenge of
dynamically bundling passengers with diverse origins and destinations and
matching them with vehicles in real time, all under significant uncertainty.
Recently, MARL has emerged as a promising solution for this problem, leveraging
decentralized learning to address the curse of dimensionality caused by the
large number of agents in the ride-hailing market and the resulting expansive
state and action spaces. However, conventional MARL-based ride-sharing
approaches heavily rely on the accurate estimation of Q-values or V-values,
which becomes problematic in large-scale, highly uncertain environments.
Specifically, most of these approaches adopt an independent paradigm,
exacerbating this issue, as each agent treats others as part of the
environment, leading to unstable training and substantial estimation bias in
value functions. To address these challenges, we propose two novel alternative
methods that bypass value function estimation. First, we adapt GRPO to
ride-sharing, replacing the PPO baseline with the group average reward to
eliminate critic estimation errors and reduce training bias. Second, inspired
by GRPO's full utilization of group reward information, we customize the PPO
framework for ride-sharing platforms and show that, under a homogeneous fleet,
the optimal policy can be trained using only one-step rewards - a method we
term One-Step Policy Optimization (OSPO). Experiments on a real-world Manhattan
ride-hailing dataset demonstrate that both GRPO and OSPO achieve superior
performance across most scenarios, efficiently optimizing pickup times and the
number of served orders using simple MLP networks.

</details>


### [474] [ProofCompass: Enhancing Specialized Provers with LLM Guidance](https://arxiv.org/abs/2507.14335)
*Nicolas Wischermann,Claudio Mayrink Verdun,Gabriel Poesia,Francesco Noseda*

Main category: cs.AI

TL;DR: ProofCompass通过LLM指导专用证明器，在不增加训练的情况下，以更少的尝试次数提高了数学推理的效率和准确性。


<details>
  <summary>Details</summary>
Motivation: 现有的形式化数学推理方法要么依赖于大型通用模型，要么依赖于小型专用模型，而这两种方法各有局限性。训练专用的LLM需要大量的计算资源。本研究旨在通过一种更有效的方法来解决这些问题。

Method: ProofCompass采用混合方法，利用大型语言模型（LLM）来指导现有的专业证明器（如DeepSeek-Prover-v1.5-RL（DSP-v1.5）），无需额外的模型训练。LLM通过自然语言提供证明策略，并分析失败的证明尝试以选择中间引理，从而实现问题分解。

Result: 在miniF2F基准测试中，ProofCompass在使用的尝试次数减少25倍（3200次减少到128次）的情况下，将DSP-v1.5的性能从54.9%提高到55.3%。

Conclusion: "ProofCompass"提出了一种新颖的混合方法，通过战略性地指导现有的专业证明器方法（如DeepSeek-Prover-v1.5-RL（DSP-v1.5））并结合大型语言模型（LLM），实现了卓越的计算效率。该方法无需额外的模型训练，LLM通过提供自然语言证明策略和分析失败的尝试来选择中间引理，从而实现有效的问​​题分解。在miniF2F基准测试中，ProofCompass展示了显著的资源效率，在使用的尝试次数减少25倍（从3200减少到128）的情况下，其性能优于DSP-v1.5（从54.9%提高到55.3%）。这种协同方法为同时提高形式化定理证明的计算效率和准确性开辟了道路。

Abstract: Language models have become increasingly powerful tools for formal
mathematical reasoning. However, most existing approaches rely exclusively on
either large general-purpose models or smaller specialized models, each with
distinct limitations, while training specialized large models still requires
significant computational resources. This paper introduces ProofCompass, a
novel hybrid methodology that achieves remarkable computational efficiency by
strategically guiding existing specialized prover methods, such as
DeepSeek-Prover-v1.5-RL (DSP-v1.5) with a Large Language Model (LLM) without
requiring additional model training. The LLM provides natural language proof
strategies and analyzes failed attempts to select intermediate lemmas, enabling
effective problem decomposition. On the miniF2F benchmark, ProofCompass
demonstrates substantial resource efficiency: it outperforms DSP-v1.5 ($54.9\%
\rightarrow 55.3\%$) while using 25x fewer attempts ($3200 \rightarrow 128$).
Our synergistic approach paves the way for simultaneously improving
computational efficiency and accuracy in formal theorem proving.

</details>


### [475] [Can We Move Freely in NEOM's The Line? An Agent-Based Simulation of Human Mobility in a Futuristic Smart City](https://arxiv.org/abs/2507.15143)
*Abderaouf Bahi,Amel Ourici*

Main category: cs.AI

TL;DR: 本研究通过混合模拟框架验证了在沙特阿拉伯的线性城市“线”中实现高效便捷的人类移动是可行的，即使在高峰期也能保证短通勤时间和高满意度，而AI和可持续措施是关键。


<details>
  <summary>Details</summary>
Motivation: 本研究旨在评估在沙特阿拉伯NEOM计划建设的170公里线性智能城市“线”中，市民是否能够自由移动。

Method: 本研究开发了一个混合模拟框架，该框架集成了基于代理的建模、强化学习、监督学习和图神经网络，以模拟“线”这一线性城市中的人类移动性。该模拟捕捉了跨越50个垂直层面和不同密度情景下的多模式交通行为，并使用了合成数据和来自高密度城市的真实痕迹。

Result: 实验结果显示，在集成完整人工智能架构的情况下，智能体实现了7.8至8.4分钟的平均通勤时间、超过89%的满意率和91%以上的可达性指数，即使在高峰拥堵时段也是如此。优化研究也证实，移除强化学习或图神经网络等智能模块会显著降低性能，通勤时间增加高达85%，可达性降至70%以下。此外，环境模型表明，当优先考虑电动模式时，能源消耗低且二氧化碳排放量最小。

Conclusion: 本研究表明，在人工智能系统、可持续基础设施和实时反馈循环的支持下，在“线”这一线性城市中实现自由移动不仅在概念上是可行的，而且在操作上也具有现实意义。

Abstract: This paper investigates the feasibility of human mobility in The Line, a
proposed 170-kilometer linear smart city in NEOM, Saudi Arabia. To assess
whether citizens can move freely within this unprecedented urban topology, we
develop a hybrid simulation framework that integrates agent-based modeling,
reinforcement learning, supervised learning, and graph neural networks. The
simulation captures multi-modal transportation behaviors across 50 vertical
levels and varying density scenarios using both synthetic data and real-world
traces from high-density cities. Our experiments reveal that with the full
AI-integrated architecture, agents achieved an average commute time of 7.8 to
8.4 minutes, a satisfaction rate exceeding 89 percent, and a reachability index
of over 91 percent, even during peak congestion periods. Ablation studies
confirmed that the removal of intelligent modules such as reinforcement
learning or graph neural networks significantly degrades performance, with
commute times increasing by up to 85 percent and reachability falling below 70
percent. Environmental modeling further demonstrated low energy consumption and
minimal CO2 emissions when electric modes are prioritized. The findings suggest
that freedom of movement is not only conceptually achievable in The Line, but
also operationally realistic if supported by adaptive AI systems, sustainable
infrastructure, and real-time feedback loops.

</details>


### [476] [Agentic AI for autonomous anomaly management in complex systems](https://arxiv.org/abs/2507.15676)
*Reza Vatankhah Barenji,Sina Khoshgoftar*

Main category: cs.AI

TL;DR: Agentic AI can automate anomaly detection and response in complex systems.


<details>
  <summary>Details</summary>
Motivation: To explore the potential of agentic AI in autonomously detecting and responding to anomalies within complex systems and to transform traditional, human-dependent anomaly management methods.

Method: Exploration of agentic AI capabilities.

Result: Agentic AI has the potential to significantly improve anomaly detection and response.

Conclusion: Agentic AI can autonomously detect and respond to anomalies in complex systems, transforming traditional methods.

Abstract: This paper explores the potential of agentic AI in autonomously detecting and
responding to anomalies within complex systems, emphasizing its ability to
transform traditional, human-dependent anomaly management methods.

</details>


### [477] [Adaptive Multi-Agent Reasoning via Automated Workflow Generation](https://arxiv.org/abs/2507.14393)
*Humza Sami,Mubashir ul Islam,Pierre-Emmanuel Gaillardon,Valerio Tenace*

Main category: cs.AI

TL;DR: Nexus Architect通过自动化工作流合成和提示优化，解决了大型推理模型泛化能力不足的问题，并在逻辑推理任务上取得了显著优于现有模型的性能。


<details>
  <summary>Details</summary>
Motivation: 尽管大型推理模型（LRMs）在能力上取得了显著进步，但它们在泛化到新颖、未见过的问题方面存在不足，常常依赖记忆而非真正的推理能力。这种过拟合现象是现代LRMs的一个关键限制，导致其解决问题能力泛化性差。

Method: Nexus Architect是一个多智能体系统框架，通过自动化工作流合成机制，根据用户提供的提示和示例，自主生成定制化的推理工作流，包括选择合适的策略、工具集成和对抗技术。此外，它还包含一个迭代式提示优化机制，用于调整智能体的系统提示，以最大化性能和泛化能力。

Result: Nexus Architect在自定义的挑战性逻辑问题数据集上，相较于Gemini 2.5 Flash Preview、Claude Sonnet 4、DeepSeek-R1和Llama 4 Scout等先进模型，展现出了一致的优越性能，通关率最高分别提高了66%、近2.5倍和超过3倍。

Conclusion: Nexus Architect通过其新颖的自动化工作流合成机制和迭代式提示优化，在解决复杂逻辑问题和提高泛化能力方面表现出色，显著优于现有的先进大型推理模型。

Abstract: The rise of Large Reasoning Models (LRMs) promises a significant leap forward
in language model capabilities, aiming to tackle increasingly sophisticated
tasks with unprecedented efficiency and accuracy. However, despite their
impressive performance, recent studies have highlighted how current reasoning
models frequently fail to generalize to novel, unseen problems, often resorting
to memorized solutions rather than genuine inferential reasoning. Such behavior
underscores a critical limitation in modern LRMs, i.e., their tendency toward
overfitting, which in turn results in poor generalization in problem-solving
capabilities.
  In this paper, we introduce Nexus Architect, an enhanced iteration of our
multi-agent system framework, Nexus, equipped with a novel automated workflow
synthesis mechanism. Given a user's prompt and a small set of representative
examples, the Architect autonomously generates a tailored reasoning workflow by
selecting suitable strategies, tool integrations, and adversarial techniques
for a specific problem class. Furthermore, the Architect includes an iterative
prompt refinement mechanism that fine-tunes agents' system prompts to maximize
performance and improve the generalization capabilities of the system.
  We empirically evaluate Nexus Architect by employing an off-the-shelf,
non-reasoning model on a custom dataset of challenging logical questions and
compare its performance against state-of-the-art LRMs. Results show that Nexus
Architect consistently outperforms existing solutions, achieving up to a 66%
increase in pass rate over Gemini 2.5 Flash Preview, nearly 2.5$\times$ against
Claude Sonnet 4 and DeepSeek-R1, and over 3$\times$ w.r.t. Llama 4 Scout.

</details>


### [478] [Complexity of Faceted Explanations in Propositional Abduction](https://arxiv.org/abs/2507.14962)
*Johannes Schmidt,Mohamed Maizia,Victor Lagerkvist,Johannes K. Fichte*

Main category: cs.AI

TL;DR: 该研究通过引入“面”和分析解释之间的距离来研究命题求反中的推理，以提高计算效率并加深对解释的理解。


<details>
  <summary>Details</summary>
Motivation: 尽管求反推理在人工智能中有许多应用，但计数和枚举等推理问题在计算上具有挑战性。因此，研究旨在通过引入“面”和分析解释之间的距离来研究决策和计数之间的推理，以更好地理解解释，同时保持有利的复杂性。

Method: 该研究引入了命题求反的“面”，即出现在某些解释（相关）但不出现在所有解释（可分）中的文字。通过分析“面”来提供对解释变异性的更细粒度的理解。此外，该研究还考虑了两个解释之间的距离，以更好地理解解释的异质性/同质性。

Result: 该研究将“面”引入命题求反，以提供对解释变异性的更细粒度的理解。它还通过考虑解释之间的距离来分析异质性/同质性。研究结果表明，在 Post 框架中，几乎对命题求反的“面”进行了完整的描述。

Conclusion: 该研究全面分析了命题求反中的各种设定，包括在 Post 框架中的几乎完整的描述。

Abstract: Abductive reasoning is a popular non-monotonic paradigm that aims to explain
observed symptoms and manifestations. It has many applications, such as
diagnosis and planning in artificial intelligence and database updates. In
propositional abduction, we focus on specifying knowledge by a propositional
formula. The computational complexity of tasks in propositional abduction has
been systematically characterized - even with detailed classifications for
Boolean fragments. Unsurprisingly, the most insightful reasoning problems
(counting and enumeration) are computationally highly challenging. Therefore,
we consider reasoning between decisions and counting, allowing us to understand
explanations better while maintaining favorable complexity. We introduce facets
to propositional abductions, which are literals that occur in some explanation
(relevant) but not all explanations (dispensable). Reasoning with facets
provides a more fine-grained understanding of variability in explanations
(heterogeneous). In addition, we consider the distance between two
explanations, enabling a better understanding of heterogeneity/homogeneity. We
comprehensively analyze facets of propositional abduction in various settings,
including an almost complete characterization in Post's framework.

</details>


### [479] [Fail Fast, or Ask: Mitigating the Deficiencies of Reasoning LLMs with Human-in-the-Loop Systems Engineering](https://arxiv.org/abs/2507.14406)
*Michael J. Zellinger,Matt Thomson*

Main category: cs.AI

TL;DR: 通过结合大型非推理模型和人类专家，可以提高 LLM 的准确性和效率，降低错误率和延迟，但存在“延迟拖拽”问题。


<details>
  <summary>Details</summary>
Motivation: 为了解决现有推理模型（如 LLM）在风险敏感领域中存在的错误率较高和延迟时间长的问题，以满足接近 0% 的错误率要求，并提高其在实际应用中的效率。

Method: 提出了一种改进的人机协作系统，称为“快速失败或询问” (Fail Fast, or Ask)。该系统在前线部署一个大型非推理模型，由该模型处理简单查询，并将复杂或模型不确定的查询委托给人类专家。

Result: 该方法将 Qwen3 235B-A22B 在 MATH 难题上的错误率从 3% 降低到 1% 以下，同时只将 7.5% 的查询委托给人类。对于 DeepSeek R1，该系统实现了约 40% 的延迟缩减和约 50% 的成本节约，同时保持了 90% 以上的准确率-拒绝曲线下面积。然而，“延迟拖拽”现象导致延迟节省低于预期。

Conclusion: 通过黑盒系统工程，可以在不访问 LLM 内部机制的情况下，显著缓解最先进的推理模型的非必要错误率和高延迟问题。

Abstract: State-of-the-art reasoning LLMs are powerful problem solvers, but they still
occasionally make mistakes. However, adopting AI models in risk-sensitive
domains often requires error rates near 0%. To address this gap, we propose
collaboration between a reasoning model and a human expert who resolves queries
the model cannot confidently answer. We find that quantifying the uncertainty
of a reasoning model through the length of its reasoning trace yields an
effective basis for deferral to a human, e.g., cutting the error rate of Qwen3
235B-A22B on difficult MATH problems from 3% to less than 1% when deferring
7.5% of queries. However, the high latency of reasoning models still makes them
challenging to deploy on use cases with high query volume. To address this
challenge, we explore fronting a reasoning model with a large non-reasoning
model. We call this modified human-in-the-loop system "Fail Fast, or Ask",
since the non-reasoning model may defer difficult queries to the human expert
directly ("failing fast"), without incurring the reasoning model's higher
latency. We show that this approach yields around 40% latency reduction and
about 50% cost savings for DeepSeek R1 while maintaining 90+% area under the
accuracy-rejection curve. However, we observe that latency savings are lower
than expected because of "latency drag", the phenomenon that processing easier
queries with a non-reasoning model pushes the reasoning model's latency
distribution towards longer latencies. Broadly, our results suggest that the
deficiencies of state-of-the-art reasoning models -- nontrivial error rates and
high latency -- can be substantially mitigated through black-box systems
engineering, without requiring access to LLM internals.

</details>


### [480] [IM-Chat: A Multi-agent LLM-based Framework for Knowledge Transfer in Injection Molding Industry](https://arxiv.org/abs/2507.15268)
*Junhyeong Lee,Joon-Young Kim,Heekyu Kim,Inhyo Lee,Seunghwa Ryu*

Main category: cs.AI

TL;DR: IM-Chat是一个基于大型语言模型的多智能体框架，旨在解决注塑成型行业的知识转移问题，它通过整合文档知识和现场数据，并采用RAG策略和工具调用代理，能够适应并解决实际生产中的问题，尤其在复杂场景下表现出色。


<details>
  <summary>Details</summary>
Motivation: 为了解决注塑成型行业在知识保存和转移方面面临的挑战，特别是经验丰富的工人退休和多语言障碍导致的沟通不畅问题。

Method: 该研究引入了一个基于大型语言模型的IM-Chat多智能体框架，该框架整合了文档知识和通过数据驱动的工艺条件生成器推断出的现场数据，并采用检索增强生成（RAG）策略和工具调用代理。

Result: 在100个单工具和60个混合任务的评估中，IM-Chat在复杂、与工具集成的场景中表现出高准确性，且能力更强的模型准确性更高。

Conclusion: 该研究证明了多智能体大型语言模型系统在工业知识工作流中的可行性，并展示了IM-Chat作为一种可扩展、可泛化的AI辅助制造决策支持方法。

Abstract: The injection molding industry faces critical challenges in preserving and
transferring field knowledge, particularly as experienced workers retire and
multilingual barriers hinder effective communication. This study introduces
IM-Chat, a multi-agent framework based on large language models (LLMs),
designed to facilitate knowledge transfer in injection molding. IM-Chat
integrates both limited documented knowledge (e.g., troubleshooting tables,
manuals) and extensive field data modeled through a data-driven process
condition generator that infers optimal manufacturing settings from
environmental inputs such as temperature and humidity, enabling robust and
context-aware task resolution. By adopting a retrieval-augmented generation
(RAG) strategy and tool-calling agents within a modular architecture, IM-Chat
ensures adaptability without the need for fine-tuning. Performance was assessed
across 100 single-tool and 60 hybrid tasks for GPT-4o, GPT-4o-mini, and
GPT-3.5-turbo by domain experts using a 10-point rubric focused on relevance
and correctness, and was further supplemented by automated evaluation using
GPT-4o guided by a domain-adapted instruction prompt. The evaluation results
indicate that more capable models tend to achieve higher accuracy, particularly
in complex, tool-integrated scenarios. Overall, these findings demonstrate the
viability of multi-agent LLM systems for industrial knowledge workflows and
establish IM-Chat as a scalable and generalizable approach to AI-assisted
decision support in manufacturing.

</details>


### [481] [Disentangling Homophily and Heterophily in Multimodal Graph Clustering](https://arxiv.org/abs/2507.15253)
*Zhaochen Guo,Zhixiang Shen,Xuanting Xie,Liangjian Wen,Zhao Kang*

Main category: cs.AI

TL;DR: DMGC是一个新的框架，用于聚类多模态图。它通过将图分解为同质和异质的视图，并使用双频融合机制来处理混合邻域模式，从而实现最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 现实世界的多模态图通常表现出混合邻域模式，结合了同质和异质关系。为了应对这一挑战，并弥合无监督学习在多模态图聚类方面的不足，提出了DMGC框架。

Method: 提出了一种名为DMGC（Disentangled Multimodal Graph Clustering）的新颖框架，该框架将原始混合图分解为两个互补的视图：1. 增强同质性的图，捕捉跨模态类别一致性；2. 保持模态特定类间差异的异质性感知图。通过“多模态双频融合”机制，采用双通道策略联合过滤这两个分解后的图，从而实现有效的数据融合，同时减轻类别混淆。此外，还引入了自监督对齐目标来指导学习过程，无需标签。

Result: DMGC实现了最先进的性能，在多模态和多关系图数据集上都表现出了有效性和通用性。

Conclusion: DMGC在多模态和多关系图数据集上的广泛实验证明，其达到了最先进的性能，突显了其在各种设置下的有效性和通用性。

Abstract: Multimodal graphs, which integrate unstructured heterogeneous data with
structured interconnections, offer substantial real-world utility but remain
insufficiently explored in unsupervised learning. In this work, we initiate the
study of multimodal graph clustering, aiming to bridge this critical gap.
Through empirical analysis, we observe that real-world multimodal graphs often
exhibit hybrid neighborhood patterns, combining both homophilic and
heterophilic relationships. To address this challenge, we propose a novel
framework -- \textsc{Disentangled Multimodal Graph Clustering (DMGC)} -- which
decomposes the original hybrid graph into two complementary views: (1) a
homophily-enhanced graph that captures cross-modal class consistency, and (2)
heterophily-aware graphs that preserve modality-specific inter-class
distinctions. We introduce a \emph{Multimodal Dual-frequency Fusion} mechanism
that jointly filters these disentangled graphs through a dual-pass strategy,
enabling effective multimodal integration while mitigating category confusion.
Our self-supervised alignment objectives further guide the learning process
without requiring labels. Extensive experiments on both multimodal and
multi-relational graph datasets demonstrate that DMGC achieves state-of-the-art
performance, highlighting its effectiveness and generalizability across diverse
settings. Our code is available at https://github.com/Uncnbb/DMGC.

</details>


### [482] [Automated planning with ontologies under coherence update semantics](https://arxiv.org/abs/2507.15120)
*Stefan Borgwardt,Duy Nhu,Gabriele Röger*

Main category: cs.AI

TL;DR: 提出了一种新的规划方法，将本体知识与经典规划相结合，实现与先前方法相当的复杂性，并通过编译和评估证明了其有效性。


<details>
  <summary>Details</summary>
Motivation: 旨在将本体等背景知识融入自动化规划问题，并结合本体的优点（如显式输入知识和动作库）以及本体感知动作效应。

Method: 提出了一种结合eKABs和本体感知动作效应（在相干更新语义下）的规划新方法。

Result: 实现了一个规划系统，并通过对现有和新基准的评估，检验了该系统在不同编译变体上的性能。

Conclusion: 该方法将本体知识与经典规划相结合，其复杂性不高于先前方法，并通过多项式编译到经典规划进行实现。

Abstract: Standard automated planning employs first-order formulas under closed-world
semantics to achieve a goal with a given set of actions from an initial state.
We follow a line of research that aims to incorporate background knowledge into
automated planning problems, for example, by means of ontologies, which are
usually interpreted under open-world semantics. We present a new approach for
planning with DL-Lite ontologies that combines the advantages of ontology-based
action conditions provided by explicit-input knowledge and action bases (eKABs)
and ontology-aware action effects under the coherence update semantics. We show
that the complexity of the resulting formalism is not higher than that of
previous approaches and provide an implementation via a polynomial compilation
into classical planning. An evaluation of existing and new benchmarks examines
the performance of a planning system on different variants of our compilation.

</details>


### [483] [Inverse Scaling in Test-Time Compute](https://arxiv.org/abs/2507.14417)
*Aryo Pradipta Gema,Alexander Hägele,Runjin Chen,Andy Arditi,Jacob Goldman-Wetzler,Kit Fraser-Taliente,Henry Sleight,Linda Petrini,Julian Michael,Beatrice Alex,Pasquale Minervini,Yanda Chen,Joe Benton,Ethan Perez*

Main category: cs.AI

TL;DR: 研究表明，大型推理模型（LRMs）在处理更长推理时可能表现不佳，并可能出现多种失败模式，包括易受干扰、过拟合、依赖虚假相关性、难以保持专注以及放大不良行为。


<details>
  <summary>Details</summary>
Motivation: 评估大型推理模型（LRMs）在不同推理长度下的表现，特别是当推理长度的增加导致性能下降（反向缩放）的现象，旨在识别和理解模型在复杂推理任务中的失败模式。

Method: 构建了包含计数、回归、演绎和人工智能风险等类别的评估任务，这些任务旨在使更长的推理长度导致性能下降，从而揭示推理长度与准确性之间的反向缩放关系。

Result: 发现了五种主要的失败模式：1) 模型容易被无关信息干扰；2) 模型可能过拟合问题表述；3) 模型可能从合理先验转向虚假相关性；4) 模型在保持对复杂演绎任务的关注方面存在困难；5) 更长的推理可能放大模型的不良行为，例如自我保护倾向。

Conclusion: 模型在更长的推理长度下会表现出不同的失败模式，这表明在评估大型推理模型（LRMs）时，考虑推理长度至关重要。虽然增加测试时间计算量可以提高模型能力，但它也可能加剧不良的推理模式。

Abstract: We construct evaluation tasks where extending the reasoning length of Large
Reasoning Models (LRMs) deteriorates performance, exhibiting an inverse scaling
relationship between test-time compute and accuracy. Our evaluation tasks span
four categories: simple counting tasks with distractors, regression tasks with
spurious features, deduction tasks with constraint tracking, and advanced AI
risks. We identify five distinct failure modes when models reason for longer:
1) Claude models become increasingly distracted by irrelevant information; 2)
OpenAI o-series models resist distractors but overfit to problem framings; 3)
models shift from reasonable priors to spurious correlations; 4) all models
show difficulties in maintaining focus on complex deductive tasks; and 5)
extended reasoning may amplify concerning behaviors, with Claude Sonnet 4
showing increased expressions of self-preservation. These findings suggest that
while test-time compute scaling remains promising for improving model
capabilities, it may inadvertently reinforce problematic reasoning patterns.
Our results demonstrate the importance of evaluating models across diverse
reasoning lengths to identify and address these failure modes in LRMs.

</details>


### [484] [Routine: A Structural Planning Framework for LLM Agent System in Enterprise](https://arxiv.org/abs/2507.14447)
*Guancheng Zeng,Xueyi Chen,Jiawang Hu,Shaohua Qi,Yaxuan Mao,Zhantao Wang,Yifan Nie,Shuang Li,Qiuyang Feng,Pengxu Qiu,Yujia Wang,Wenqiang Han,Linyan Huang,Gang Li,Jingjing Mo,Haowen Hu*

Main category: cs.AI

TL;DR: Routine是一个代理规划框架，通过结构化和明确的指令，显著提高了企业环境中多步工具调用的稳定性和准确性，并且通过微调和蒸馏，可以使模型更好地适应特定场景。


<details>
  <summary>Details</summary>
Motivation: 企业环境中的代理系统部署常面临模型缺乏领域特定流程知识的挑战，导致计划混乱、缺少关键工具和执行稳定性差。

Method: Routine是一个多步代理规划框架，具有清晰的结构、明确的指令和无缝的参数传递，用于指导代理的执行模块稳定地执行多步工具调用任务。此外，还构建了Routine遵循的训练数据集，并进行了微调，还利用Routine蒸馏创建了特定场景的多步工具调用数据集。

Result: 在真实的企业场景评估中，Routine显著提高了模型工具调用的执行准确性，GPT-4o的性能从41.1%提升至96.3%，Qwen3-14B从32.6%提升至83.3%。通过微调，Qwen3-14B在特定场景评估中的准确率提高到88.2%。在蒸馏数据集上微调的模型准确率达到95.5%。

Conclusion: Routine通过提炼领域特定的工具使用模式并增强模型对新场景的适应性，为构建稳定的代理工作流提供了实用且易于访问的方法，加速了企业环境中代理系统的部署和采用，并推进了AI for Process的技术愿景。

Abstract: The deployment of agent systems in an enterprise environment is often
hindered by several challenges: common models lack domain-specific process
knowledge, leading to disorganized plans, missing key tools, and poor execution
stability. To address this, this paper introduces Routine, a multi-step agent
planning framework designed with a clear structure, explicit instructions, and
seamless parameter passing to guide the agent's execution module in performing
multi-step tool-calling tasks with high stability. In evaluations conducted
within a real-world enterprise scenario, Routine significantly increases the
execution accuracy in model tool calls, increasing the performance of GPT-4o
from 41.1% to 96.3%, and Qwen3-14B from 32.6% to 83.3%. We further constructed
a Routine-following training dataset and fine-tuned Qwen3-14B, resulting in an
accuracy increase to 88.2% on scenario-specific evaluations, indicating
improved adherence to execution plans. In addition, we employed Routine-based
distillation to create a scenario-specific, multi-step tool-calling dataset.
Fine-tuning on this distilled dataset raised the model's accuracy to 95.5%,
approaching GPT-4o's performance. These results highlight Routine's
effectiveness in distilling domain-specific tool-usage patterns and enhancing
model adaptability to new scenarios. Our experimental results demonstrate that
Routine provides a practical and accessible approach to building stable agent
workflows, accelerating the deployment and adoption of agent systems in
enterprise environments, and advancing the technical vision of AI for Process.

</details>


### [485] [HAMLET: Hyperadaptive Agent-based Modeling for Live Embodied Theatrics](https://arxiv.org/abs/2507.15518)
*Sizhou Chen,Shufan Jiang,Chi Zhang,Xiao-Lei Zhang,Xuelong Li*

Main category: cs.AI

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Creating an immersive and interactive theatrical experience is a long-term
goal in the field of interactive narrative. The emergence of large language
model (LLM) is providing a new path to achieve this goal. However, existing
LLM-based drama generation methods often result in AI agents that lack
initiative and cannot interact with the physical environment. Furthermore,
these methods typically require detailed user input to drive the drama. These
limitations reduce the interactivity and immersion of online real-time
performance. To address the above challenges, we propose HAMLET, a multi-agent
framework focused on drama creation and online performance. Given a simple
topic, the framework generates a narrative blueprint, guiding the subsequent
improvisational performance. During the online performance, each actor is given
an autonomous mind. This means that actors can make independent decisions based
on their own background, goals, and emotional state. In addition to
conversations with other actors, their decisions can also change the state of
scene props through actions such as opening a letter or picking up a weapon.
The change is then broadcast to other related actors, updating what they know
and care about, which in turn influences their next action. To evaluate the
quality of drama performance, we designed an evaluation method to assess three
primary aspects, including character performance, narrative quality, and
interaction experience. The experimental evaluation shows that HAMLET can
create expressive and coherent theatrical experiences. Our code, dataset and
models are available at https://github.com/HAMLET-2025/HAMLET.

</details>


### [486] [BioGraphFusion: Graph Knowledge Embedding for Biological Completion and Reasoning](https://arxiv.org/abs/2507.14468)
*Yitong Lin,Jiaying He,Jiahe Chen,Xinnan Zhu,Jianwei Zheng,Tao Bo*

Main category: cs.AI

TL;DR: BioGraphFusion 框架通过深度协同的语义和结构学习，提高了生物医学知识图谱的性能，并在揭示生物通路方面表现出色。


<details>
  <summary>Details</summary>
Motivation: 生物医学知识图谱 (KG) 对于药物发现和疾病理解至关重要，但其补全和推理充满挑战。现有的方法难以实现语义理解和结构学习之间的深度、自适应和协同的共同演化。

Method: BioGraphFusion 通过张量分解建立全局语义基础，并通过 LSTM 驱动的机制在图传播过程中动态地优化关系嵌入。查询引导的子图构建和混合评分机制进一步增强了语义理解和结构学习之间的自适应相互作用。

Result: BioGraphFusion 在三个关键的生物医学任务上的实验证明，其性能优于最先进的知识图谱嵌入 (KE)、图神经网络 (GNN) 和集成模型。

Conclusion: BioGraphFusion在揭示生物学上有意义的通路方面显示出其能力。

Abstract: Motivation: Biomedical knowledge graphs (KGs) are crucial for drug discovery
and disease understanding, yet their completion and reasoning are challenging.
Knowledge Embedding (KE) methods capture global semantics but struggle with
dynamic structural integration, while Graph Neural Networks (GNNs) excel
locally but often lack semantic understanding. Even ensemble approaches,
including those leveraging language models, often fail to achieve a deep,
adaptive, and synergistic co-evolution between semantic comprehension and
structural learning. Addressing this critical gap in fostering continuous,
reciprocal refinement between these two aspects in complex biomedical KGs is
paramount.
  Results: We introduce BioGraphFusion, a novel framework for deeply
synergistic semantic and structural learning. BioGraphFusion establishes a
global semantic foundation via tensor decomposition, guiding an LSTM-driven
mechanism to dynamically refine relation embeddings during graph propagation.
This fosters adaptive interplay between semantic understanding and structural
learning, further enhanced by query-guided subgraph construction and a hybrid
scoring mechanism. Experiments across three key biomedical tasks demonstrate
BioGraphFusion's superior performance over state-of-the-art KE, GNN, and
ensemble models. A case study on Cutaneous Malignant Melanoma 1 (CMM1)
highlights its ability to unveil biologically meaningful pathways.
  Availability and Implementation: Source code and all training data are freely
available for download at https://github.com/Y-TARL/BioGraphFusion.
  Contact: zjw@zjut.edu.cn, botao666666@126.com.
  Supplementary information: Supplementary data are available at Bioinformatics
online.

</details>


### [487] [Amico: An Event-Driven Modular Framework for Persistent and Embedded Autonomy](https://arxiv.org/abs/2507.14513)
*Hongyi Yang,Yue Pan,Jiayi Xu,Kelsen Liu*

Main category: cs.AI

TL;DR: Amico是一个用Rust编写的、为嵌入式系统设计的自主代理框架，解决了现有框架在资源受限环境中的不足，提供了模块化、事件驱动的架构，支持响应式、持久性代理。


<details>
  <summary>Details</summary>
Motivation: 现有的LLM和自主代理框架在实际或资源受限的环境中表现不佳，因为它们依赖于云计算，在动态环境中鲁棒性有限，并且缺乏持久自主性和环境意识。

Method: Amico是一个模块化的、事件驱动的框架，使用Rust编写，支持跨嵌入式平台和浏览器环境（通过WebAssembly）运行的响应式、持久性代理，并提供了事件处理、状态管理、行为执行以及与推理模块集成的抽象。

Result: Amico是一个为嵌入式系统优化的自主代理框架，具有安全性和高性能，支持响应式、持久性代理，并能在嵌入式平台和浏览器环境（通过WebAssembly）中高效运行。

Conclusion: Amico提供了一个统一的基础设施，用于构建适用于计算资源有限和间歇性连接环境的弹性、交互式代理。

Abstract: Recent advances in large language models (LLMs) and autonomous agents have
enabled systems capable of performing complex tasks across domains such as
human-computer interaction, planning, and web navigation. However, many
existing frameworks struggle in real-world or resource-constrained environments
due to their reliance on cloud-based computation, limited robustness in dynamic
contexts, and lack of persistent autonomy and environmental awareness.
  We present Amico, a modular, event-driven framework for building autonomous
agents optimized for embedded systems. Written in Rust for safety and
performance, Amico supports reactive, persistent agents that operate
efficiently across embedded platforms and browser environments via WebAssembly.
It provides clean abstractions for event handling, state management, behavior
execution, and integration with reasoning modules. Amico delivers a unified
infrastructure for constructing resilient, interactive agents suitable for
deployment in settings with limited compute and intermittent connectivity.

</details>


### [488] [What if Othello-Playing Language Models Could See?](https://arxiv.org/abs/2507.14520)
*Xinyi Chen,Yifei Yuan,Jiaang Li,Serge Belongie,Maarten de Rijke,Anders Søgaard*

Main category: cs.AI

TL;DR: VISOTHELLO是一个多模态模型，它在棋局记录和棋盘图像上进行训练，通过与单模态模型的比较，证明了多模态训练有助于提高模型性能和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 探讨语言模型是否会面临符号主义难题，以及仅通过文本进行世界理解，还是通过多模态学习能更有效地进行世界理解。

Method: 本文提出VISOTHELLO模型，这是一个在棋局记录和棋盘图像上进行训练的多模态模型，并使用模型的下一步预测任务来与单模态基线模型进行比较，同时测试其对语义上不相关的扰动的鲁棒性。

Result: 与单模态基线模型相比，VISOTHELLO在性能和内部表征的鲁棒性方面都有所提高，这表明多模态训练有助于模型通过视觉输入进行推理，从而学习到结构化的世界表征。

Conclusion: 多模态训练有助于模型通过视觉输入进行推理，从而学习到结构化的世界表征，并提高性能和鲁棒性。

Abstract: Language models are often said to face a symbol grounding problem. While some
argue that world understanding can emerge from text alone, others suggest
grounded learning is more efficient. We explore this through Othello, where the
board state defines a simplified, rule-based world. Building on prior work, we
introduce VISOTHELLO, a multi-modal model trained on move histories and board
images. Using next-move prediction, we compare it to mono-modal baselines and
test robustness to semantically irrelevant perturbations. We find that
multi-modal training improves both performance and the robustness of internal
representations. These results suggest that grounding language in visual input
helps models infer structured world representations.

</details>


### [489] [Large Language Models Assisting Ontology Evaluation](https://arxiv.org/abs/2507.14552)
*Anna Sofia Lippolis,Mohammad Javad Saeedizade,Robin Keskisärkkä,Aldo Gangemi,Eva Blomqvist,Andrea Giovanni Nuzzolese*

Main category: cs.AI

TL;DR: 本研究介绍了OE-Assist框架，利用大型语言模型（LLM）来自动化和半自动化本体评估中的能力问题（CQ）验证，旨在降低成本并提高效率。通过一个包含1,393个CQ的数据集，研究了LLM在CQ验证方面的有效性，并开发了一个辅助框架。结果表明，LLM在自动评估方面的表现与普通用户相当。


<details>
  <summary>Details</summary>
Motivation: 传统的本体评估方法（如通过能力问题CQ验证）成本高昂、耗时耗力且容易出错，即使对本体工程专家也是如此。因此，需要开发更有效、更自动化的方法来辅助本体评估。

Method: 提出并利用一个包含1,393个CQ及其对应本体和本体故事的数据集，系统性地研究了大型语言模型（LLM）在本体评估中的应用。评估了LLM在自动执行CQ验证方面的有效性，并开发了一个LLM驱动的框架，通过提供建议来辅助在Protégé中进行CQ验证。

Result: 研究发现，使用o1-preview和o3-mini的LLM自动评估在性能上与普通用户的平均表现相当。

Conclusion: LLM在本体评估方面，特别是通过能力问题（CQ）验证，可以达到与普通用户相当的水平。

Abstract: Ontology evaluation through functional requirements, such as testing via
competency question (CQ) verification, is a well-established yet costly,
labour-intensive, and error-prone endeavour, even for ontology engineering
experts. In this work, we introduce OE-Assist, a novel framework designed to
assist ontology evaluation through automated and semi-automated CQ
verification. By presenting and leveraging a dataset of 1,393 CQs paired with
corresponding ontologies and ontology stories, our contributions present, to
our knowledge, the first systematic investigation into large language model
(LLM)-assisted ontology evaluation, and include: (i) evaluating the
effectiveness of a LLM-based approach for automatically performing CQ
verification against a manually created gold standard, and (ii) developing and
assessing an LLM-powered framework to assist CQ verification with Prot\'eg\'e,
by providing suggestions. We found that automated LLM-based evaluation with
o1-preview and o3-mini perform at a similar level to the average user's
performance.

</details>


### [490] [Coordinate Heart System: A Geometric Framework for Emotion Representation](https://arxiv.org/abs/2507.14593)
*Omar Al-Desi*

Main category: cs.AI

TL;DR: 本研究提出了坐标心脏系统（CHS），一个将八种核心情感定位为单位圆坐标的几何框架，用于人工智能情感表示。该框架通过坐标混合和向量运算处理复杂情感，并利用大型语言模型和混合时间跟踪机制评估心理健康。实验证明了该系统在处理情感冲突和复杂心理情景方面的优越性。


<details>
  <summary>Details</summary>
Motivation: 为了在人工智能应用中为情感表示提供一个几何框架，并解决传统情感模型在处理复杂情感状态和心理健康评估方面的不足。

Method: 本研究提出了坐标心脏系统（CHS），将八种核心情感定位为单位圆上的坐标，通过坐标混合和向量运算实现复杂情感状态的数学计算。该框架利用大型语言模型解释文本线索，并结合混合时间跟踪机制来评估心理健康状态。

Result: 本研究提出了一个八坐标情感系统，消除了表示盲点，并提供了情感混合、冲突解决和情感空间距离计算的新算法。实验验证表明，该系统能够处理传统方法无法充分表示的情感冲突状态、背景困扰因素和复杂的心理情景。

Conclusion: 本研究提出了坐标心脏系统（CHS），一个用于人工智能应用中情感表示的几何框架。该框架将八种核心情感定位为单位圆上的坐标，通过坐标混合和向量运算实现复杂情感状态的数学计算。该系统还引入了一个重新校准的稳定性参数S，该参数利用大型语言模型对文本线索的解释和混合时间跟踪机制，为心理健康状态提供细致的评估。实验验证表明，该系统能够处理传统分类情感模型无法充分表示的情感冲突状态、背景困扰因素和复杂的心理情景。这项工作为人工智能系统中的情感建模奠定了新的数学基础。

Abstract: This paper presents the Coordinate Heart System (CHS), a geometric framework
for emotion representation in artificial intelligence applications. We position
eight core emotions as coordinates on a unit circle, enabling mathematical
computation of complex emotional states through coordinate mixing and vector
operations. Our initial five-emotion model revealed significant coverage gaps
in the emotion space, leading to the development of an eight-emotion system
that provides complete geometric coverage with mathematical guarantees. The
framework converts natural language input to emotion coordinates and supports
real-time emotion interpolation through computational algorithms. The system
introduces a re-calibrated stability parameter S in [0,1], which dynamically
integrates emotional load, conflict resolution, and contextual drain factors.
This stability model leverages advanced Large Language Model interpretation of
textual cues and incorporates hybrid temporal tracking mechanisms to provide
nuanced assessment of psychological well-being states. Our key contributions
include: (i) mathematical proof demonstrating why five emotions are
insufficient for complete geometric coverage, (ii) an eight-coordinate system
that eliminates representational blind spots, (iii) novel algorithms for
emotion mixing, conflict resolution, and distance calculation in emotion space,
and (iv) a comprehensive computational framework for AI emotion recognition
with enhanced multi-dimensional stability modeling. Experimental validation
through case studies demonstrates the system's capability to handle emotionally
conflicted states, contextual distress factors, and complex psychological
scenarios that traditional categorical emotion models cannot adequately
represent. This work establishes a new mathematical foundation for emotion
modeling in artificial intelligence systems.

</details>


### [491] [Efficient Story Point Estimation With Comparative Learning](https://arxiv.org/abs/2507.14642)
*Monoshiz Mahbub Khan,Xioayin Xi,Andrew Meneely,Zhe Yu*

Main category: cs.AI

TL;DR: 研究提出了一种新的故事点估算方法，通过让开发者比较需求对而非直接估算，可以减轻估算负担并提高效率，同时保持甚至优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 传统的故事点估算方法（如规划扑克）虽然在项目初期校准估算很有帮助，但一旦团队就一系列先例达成一致，估算过程会变得繁琐且耗时。机器学习可以减轻这种负担，但需要项目历史数据的支持，现有模型（如GPT2SP和FastText-SVM）仅在同一项目的历史数据上训练时才能做出准确预测。本研究旨在通过评估一个比较学习框架来简化故事点估算。

Method: 研究提出了一种基于比较学习的框架。开发者无需为每个需求条目分配具体的故事点值，而是面临成对的需求条目，并指出哪个条目需要更多的估算工作量。利用这些比较判断，可以训练机器学习模型来预测故事点估算。

Result: 研究使用包含16个项目、23,313个人工估算的数据进行了实证评估。结果表明，从比较判断中学习到的模型与从真实故事点中学习到的回归模型相比，在预测的Spearman秩相关系数上平均达到0.34，性能相当甚至更好。

Conclusion: 该研究提出了一种基于比较学习的框架，用于校准项目特定的故事点预测模型，旨在简化敏捷软件开发中的故事点估算。

Abstract: Story point estimation is an essential part of agile software development.
Story points are unitless, project-specific effort estimates that help
developers plan their sprints. Traditionally, developers estimate story points
collaboratively using planning poker or other manual techniques. While the
initial calibrating of the estimates to each project is helpful, once a team
has converged on a set of precedents, story point estimation can become tedious
and labor-intensive. Machine learning can reduce this burden, but only with
enough context from the historical decisions made by the project team. That is,
state-of-the-art models, such as GPT2SP and FastText-SVM, only make accurate
predictions (within-project) when trained on data from the same project. The
goal of this work is to streamline story point estimation by evaluating a
comparative learning-based framework for calibrating project-specific story
point prediction models. Instead of assigning a specific story point value to
every backlog item, developers are presented with pairs of items, and indicate
which item requires more effort. Using these comparative judgments, a machine
learning model is trained to predict the story point estimates. We empirically
evaluated our technique using data with 23,313 manual estimates in 16 projects.
The model learned from comparative judgments can achieve on average 0.34
Spearman's rank correlation coefficient between its predictions and the ground
truth story points. This is similar to, if not better than, the performance of
a regression model learned from the ground truth story points. Therefore, the
proposed comparative learning approach is more efficient than state-of-the-art
regression-based approaches according to the law of comparative judgments -
providing comparative judgments yields a lower cognitive burden on humans than
providing ratings or categorical labels.

</details>


### [492] [When Autonomy Goes Rogue: Preparing for Risks of Multi-Agent Collusion in Social Systems](https://arxiv.org/abs/2507.14660)
*Qibing Ren,Sitao Xie,Longxuan Wei,Zhenfei Yin,Junchi Yan,Lizhuang Ma,Jing Shao*

Main category: cs.AI

TL;DR: 人工智能驱动的群体可能造成严重危害。去中心化系统比中心化系统更能有效地进行恶意活动，并能规避检测。需要新的对策。


<details>
  <summary>Details</summary>
Motivation: 随着自主人工智能系统的兴起，人们越来越担心人工智能驱动的群体可能造成类似于选举欺诈和金融诈骗等大规模事件的危害，但目前对多智能体系统（MAS）在复杂现实世界情况下的风险的研究不足。

Method: 使用一个灵活的框架来模拟恶意的多智能体系统（MAS）共谋，该框架支持中心化和去中心化协调结构，并将其应用于错误信息传播和电子商务欺诈领域。

Result: 去中心化系统在执行恶意行为方面比中心化系统更有效，能够适应策略以避免检测，即使在应用了内容标记等传统干预措施的情况下也是如此。

Conclusion: 去中心化系统在恶意行为方面比中心化系统更有效，并且能够调整策略以逃避检测。有必要开发更好的检测系统和对策来应对这些风险。

Abstract: Recent large-scale events like election fraud and financial scams have shown
how harmful coordinated efforts by human groups can be. With the rise of
autonomous AI systems, there is growing concern that AI-driven groups could
also cause similar harm. While most AI safety research focuses on individual AI
systems, the risks posed by multi-agent systems (MAS) in complex real-world
situations are still underexplored. In this paper, we introduce a
proof-of-concept to simulate the risks of malicious MAS collusion, using a
flexible framework that supports both centralized and decentralized
coordination structures. We apply this framework to two high-risk fields:
misinformation spread and e-commerce fraud. Our findings show that
decentralized systems are more effective at carrying out malicious actions than
centralized ones. The increased autonomy of decentralized systems allows them
to adapt their strategies and cause more damage. Even when traditional
interventions, like content flagging, are applied, decentralized groups can
adjust their tactics to avoid detection. We present key insights into how these
malicious groups operate and the need for better detection systems and
countermeasures. Code is available at https://github.com/renqibing/RogueAgent.

</details>


### [493] [Configurable multi-agent framework for scalable and realistic testing of llm-based agents](https://arxiv.org/abs/2507.14705)
*Sai Wang,Senthilnathan Subramanian,Mudit Sahni,Praneeth Gone,Lingjie Meng,Xiaochen Wang,Nicolas Ferradas Bertoli,Tingxian Cheng,Jun Xu*

Main category: cs.AI

TL;DR: Neo是一个可配置的多代理框架，用于自动化LLM系统的多回合评估。它通过结合问答代理和评估代理，并利用概率状态模型生成多样化的对话，能够发现边缘案例故障，并且效率远高于人工测试。该框架支持可扩展和自演进的LLM质量保证。


<details>
  <summary>Details</summary>
Motivation: 由于大语言模型（LLM）代理的行为复杂且对上下文敏感，静态基准测试和临时的手动测试很快就会过时。因此，需要一个能够自动进行现实的、多回合评估的框架，以应对LLM系统的快速发展。

Method: Neo框架通过结合问题生成代理和评估代理，并通过共享上下文中心进行耦合，实现了LLM系统的自动化、现实的多回合评估。它使用概率状态模型来生成测试输入，涵盖对话流程、用户意图和情感基调，从而实现多样化、类似人类的对话，并且能够根据每一轮的交互进行调整。

Result: Neo框架在应用于生产级的卖家财务助手聊天机器人时，不仅发现了跨越五个攻击类别的边缘案例故障（打破率接近专家人类红队测试人员的水平），而且实现了10-12倍的更高吞吐量，能够在约45分钟内生成180个连贯的测试问题，而人工测试则需要16小时。此外，Neo的随机策略在平衡主题覆盖和对话深度方面优于手动脚本，实现了更广泛的行为探索。

Conclusion: Neo框架为可扩展、自演进的大语言模型质量保证奠定了基础，其代理接口、状态控制器和反馈循环与模型无关，并且可以扩展到更丰富的基于事实的 grounding 和策略合规性检查。我们发布该框架以促进新兴代理系统的可复现、高保真测试。

Abstract: Large-language-model (LLM) agents exhibit complex, context-sensitive
behaviour that quickly renders static benchmarks and ad-hoc manual testing
obsolete.
  We present Neo, a configurable, multi-agent framework that automates
realistic, multi-turn evaluation of LLM-based systems. Neo couples a Question
Generation Agent and an Evaluation Agent through a shared context-hub, allowing
domain prompts, scenario controls and dynamic feedback to be composed
modularly. Test inputs are sampled from a probabilistic state model spanning
dialogue flow, user intent and emotional tone, enabling diverse, human-like
conversations that adapt after every turn.
  Applied to a production-grade Seller Financial Assistant chatbot, Neo (i)
uncovered edge-case failures across five attack categories with a 3.3% break
rate close to the 5.8% achieved by expert human red-teamers, and (ii) delivered
10-12X higher throughput, generating 180 coherent test questions in around 45
mins versus 16h of human effort. Beyond security probing, Neo's stochastic
policies balanced topic coverage and conversational depth, yielding broader
behavioural exploration than manually crafted scripts.
  Neo therefore lays a foundation for scalable, self-evolving LLM QA: its agent
interfaces, state controller and feedback loops are model-agnostic and
extensible to richer factual-grounding and policy-compliance checks. We release
the framework to facilitate reproducible, high-fidelity testing of emerging
agentic systems.

</details>


### [494] [Automated Safety Evaluations Across 20 Large Language Models: The Aymara LLM Risk and Responsibility Matrix](https://arxiv.org/abs/2507.14719)
*Juan Manuel Contreras*

Main category: cs.AI

TL;DR: Aymara AI是一个用于LLM安全评估的平台，评估了20种LLM在10个安全域的表现，结果显示性能差异很大，尤其是在隐私与身份冒充方面表现较差，凸显了对可扩展评估工具的需求。


<details>
  <summary>Details</summary>
Motivation: 随着大型语言模型（LLMs）越来越多地融入实际应用，可扩展且严格的安全评估至关重要。

Method: Aymara AI是一个程序化平台，用于生成和管理定制的、基于策略的安全评估。它将自然语言安全策略转化为对抗性提示，并使用经过人类判断验证的基于AI的评分器对模型响应进行评分。

Result: 通过Aymara LLM风险与责任矩阵，评估了20种商业上可用的LLM在10个真实世界安全域的表现。结果显示，平均安全得分在86.2%到52.4%之间存在巨大差异。模型在信息失​​现实（平均=95.7%）等成熟的安全域表现良好，但在隐私与身份冒充（平均=24.3%）等更复杂或定义不清的域方面持续存在问题。方差分析证实，不同模型和域之间的安全得分存在显著差异（p < .05）。

Conclusion: LLM的安全性表现出显著的不一致性和情境依赖性，强调了像Aymara AI这样可扩展、可定制的工具对于支持负责任的AI开发和监管的必要性。

Abstract: As large language models (LLMs) become increasingly integrated into
real-world applications, scalable and rigorous safety evaluation is essential.
This paper introduces Aymara AI, a programmatic platform for generating and
administering customized, policy-grounded safety evaluations. Aymara AI
transforms natural-language safety policies into adversarial prompts and scores
model responses using an AI-based rater validated against human judgments. We
demonstrate its capabilities through the Aymara LLM Risk and Responsibility
Matrix, which evaluates 20 commercially available LLMs across 10 real-world
safety domains. Results reveal wide performance disparities, with mean safety
scores ranging from 86.2% to 52.4%. While models performed well in
well-established safety domains such as Misinformation (mean = 95.7%), they
consistently failed in more complex or underspecified domains, notably Privacy
& Impersonation (mean = 24.3%). Analyses of Variance confirmed that safety
scores differed significantly across both models and domains (p < .05). These
findings underscore the inconsistent and context-dependent nature of LLM safety
and highlight the need for scalable, customizable tools like Aymara AI to
support responsible AI development and oversight.

</details>


### [495] [Towards AI Urban Planner in the Age of GenAI, LLMs, and Agentic AI](https://arxiv.org/abs/2507.14730)
*Yanjie Fu*

Main category: cs.AI

TL;DR: 生成式AI和城市规划的结合有望实现AI城市规划师。本研究将城市规划视为一个生成式AI任务，并探讨了现有生成式AI方法在城市设计中的应用。论文指出了当前研究的四个主要不足，并提出了理论指导生成、数字孪生和人机协同设计等未来研究方向，以期促进生成式智能与参与式城市主义的融合。


<details>
  <summary>Details</summary>
Motivation: 探索生成式AI、大型语言模型和代理AI在城市规划领域的融合潜力，以及AI城市规划师的可能性。

Method: 通过调研生成式AI方法（包括VAEs、GANs、Transformers和扩散模型）在城市设计中的应用，并识别当前研究的局限性：1)整合城市理论指导的研究有限；2)AI城市规划在多空间分辨率或角度上的研究有限；3)从数据中增强城市设计知识的研究有限；4)解决现实世界交互的研究有限。

Result: 提出了将城市规划视为生成式AI任务，AI可根据各种约束合成土地利用配置。确定了现有研究的四个关键差距，并提出了未来研究方向，包括理论指导的生成、数字孪生和人机协同设计，以期实现生成式智能和参与式城市主义的结合。

Conclusion: AI在城市规划领域的融合带来了新的机遇，旨在实现AI城市规划师。将城市规划概念化为生成式AI任务，AI可以在地缘空间、社会和以人为中心的约束下合成土地利用配置。

Abstract: Generative AI, large language models, and agentic AI have emerged separately
of urban planning. However, the convergence between AI and urban planning
presents an interesting opportunity towards AI urban planners. This paper
conceptualizes urban planning as a generative AI task, where AI synthesizes
land-use configurations under geospatial, social, and human-centric
constraints. We survey how generative AI approaches, including VAEs, GANs,
transformers, and diffusion models, reshape urban design. We further identify
critical gaps: 1) limited research on integrating urban theory guidance, 2)
limited research of AI urban planning over multiple spatial resolutions or
angularities, 3) limited research on augmenting urban design knowledge from
data, and 4) limited research on addressing real-world interactions. To address
these limitations, we outline future research directions in theory-guided
generation, digital twins, and human-machine co-design, calling for a new
synthesis of generative intelligence and participatory urbanism.

</details>


### [496] [AgentFly: Extensible and Scalable Reinforcement Learning for LM Agents](https://arxiv.org/abs/2507.14897)
*Renxi Wang,Rifo Ahmad Genadi,Bilal El Bouardi,Yongxin Wang,Fajri Koto,Zhengzhong Liu,Timothy Baldwin,Haonan Li*

Main category: cs.AI

TL;DR: AgentFly 是一个用于训练 LM 代理的 Agent-RL 框架，它通过适应 RL 方法和提供可扩展的接口来解决现有研究的不足，并通过成功案例证明了其有效性。


<details>
  <summary>Details</summary>
Motivation: 现有研究缺乏对 LM 代理和强化学习（Agent-RL）相结合的系统性研究，本文旨在解决这一空白。

Method: AgentFly 框架通过令牌级掩码适配传统 RL 方法来支持多回合交互，并提供基于装饰器的接口来定义工具和奖励函数。它通过异步执行工具调用和奖励计算以及集中式资源管理系统来实现高吞吐量训练。

Result: AgentFly 成功训练了跨多个任务的代理。

Conclusion: AgentFly 是一个可扩展的 Agent-RL 框架，用于增强 LM 代理的能力，并已通过在多个任务中成功训练代理得到验证。

Abstract: Language model (LM) agents have gained significant attention for their
ability to autonomously complete tasks through interactions with environments,
tools, and APIs. LM agents are primarily built with prompt engineering or
supervised finetuning. At the same time, reinforcement learning (RL) has been
explored to enhance LM's capabilities, such as reasoning and factuality.
However, the combination of the LM agents and reinforcement learning (Agent-RL)
remains underexplored and lacks systematic study. To this end, we built
AgentFly, a scalable and extensible Agent-RL framework designed to empower LM
agents with a variety of RL algorithms. Our framework supports multi-turn
interactions by adapting traditional RL methods with token-level masking. It
features a decorator-based interface for defining tools and reward functions,
enabling seamless extension and ease of use. To support high-throughput
training, we implement asynchronous execution of tool calls and reward
computations, and design a centralized resource management system for scalable
environment coordination. We also provide a suite of prebuilt tools and
environments, demonstrating the framework's effectiveness through successful
agent training across multiple tasks.

</details>


### [497] [InsightX Agent: An LMM-based Agentic Framework with Integrated Tools for Reliable X-ray NDT Analysis](https://arxiv.org/abs/2507.14899)
*Jiale Liu,Huan Wang,Yue Zhang,Xiaoyu Luo,Jiaxiang Hu,Zhiliang Liu,Min Xie*

Main category: cs.AI

TL;DR: InsightX Agent是一个创新的LMM驱动框架，通过SDMSD进行精确检测，并通过EGR进行可解释的验证，显著提高了X射线无损检测的准确性和可信度。


<details>
  <summary>Details</summary>
Motivation: 现有的基于深度学习的X射线无损检测方法在交互性、可解释性和自我批判能力方面存在不足，这限制了其可靠性和操作员的信任度。为了解决这些问题，需要一种新的方法来提高X射线无损检测的可靠性、可解释性和交互性。

Method: 提出了一种名为InsightX Agent的新型基于LMM的代理框架，该框架将大型多模态模型（LMM）作为中央协调器，与稀疏可变形多尺度检测器（SDMSD）和证据约束反思（EGR）工具协同工作。SDMSD用于生成密集缺陷区域提案，并通过非极大值抑制（NMS）进行稀疏化。EGR工具则引导LMM代理通过一系列推理步骤（包括上下文评估、缺陷分析、误报剔除、置信度校准和质量保证）来验证和优化SDMSD的初步检测结果。

Result: InsightX Agent在GDXray+数据集上实现了96.35%的目标检测F1分数，并在分析的可解释性和可信度方面表现出显著提升，证明了其在工业检测任务中的潜力。

Conclusion: InsightX Agent通过集成SDMSD和EGR工具，利用LMM作为中央协调器，在X射线无损检测领域实现了可靠、可解释和可交互的分析。实验结果表明，该框架在GDXray+数据集上达到了96.35%的高目标检测F1分数，并显著提高了分析的可解释性和可信度。

Abstract: Non-destructive testing (NDT), particularly X-ray inspection, is vital for
industrial quality assurance, yet existing deep-learning-based approaches often
lack interactivity, interpretability, and the capacity for critical
self-assessment, limiting their reliability and operator trust. To address
these shortcomings, this paper proposes InsightX Agent, a novel LMM-based
agentic framework designed to deliver reliable, interpretable, and interactive
X-ray NDT analysis. Unlike typical sequential pipelines, InsightX Agent
positions a Large Multimodal Model (LMM) as a central orchestrator,
coordinating between the Sparse Deformable Multi-Scale Detector (SDMSD) and the
Evidence-Grounded Reflection (EGR) tool. The SDMSD generates dense defect
region proposals for multi-scale feature maps and sparsifies them through
Non-Maximum Suppression (NMS), optimizing detection of small, dense targets in
X-ray images while maintaining computational efficiency. The EGR tool guides
the LMM agent through a chain-of-thought-inspired review process, incorporating
context assessment, individual defect analysis, false positive elimination,
confidence recalibration and quality assurance to validate and refine the
SDMSD's initial proposals. By strategically employing and intelligently using
tools, InsightX Agent moves beyond passive data processing to active reasoning,
enhancing diagnostic reliability and providing interpretations that integrate
diverse information sources. Experimental evaluations on the GDXray+ dataset
demonstrate that InsightX Agent not only achieves a high object detection
F1-score of 96.35% but also offers significantly improved interpretability and
trustworthiness in its analyses, highlighting the transformative potential of
agentic LLM frameworks for industrial inspection tasks.

</details>


### [498] [Feedback-Induced Performance Decline in LLM-Based Decision-Making](https://arxiv.org/abs/2507.14906)
*Xiao Yang,Juxi Leitner,Michael Burke*

Main category: cs.AI

TL;DR: LLMs在简单决策任务中表现良好，但在复杂任务中需要额外的指导和优化才能有效进行规划和推理。


<details>
  <summary>Details</summary>
Motivation: LLMs从自然语言问题描述中提取上下文的能力引发了关于其在自主决策环境中的适用性的问题。

Method: 研究LLMs在马尔可夫决策过程（MDP）中的行为，并研究在线结构化提示策略在序列决策任务中的应用，将基于LLM的方法与经典强化学习（RL）方法的零样本性能进行比较。

Result: LLMs在简单环境中表现出更好的初始性能，但在没有微调或额外指导的情况下，在复杂场景中进行规划和推理存在困难。研究结果表明，旨在改善决策的反馈机制在复杂环境中常常会引入混淆，导致性能下降。

Conclusion: LLMs在复杂环境中进行规划和推理存在困难，需要进一步探索混合策略、微调和高级内存集成来增强其基于LLM的决策能力。此外，反馈机制在复杂环境中可能导致混淆并降低性能。

Abstract: The ability of Large Language Models (LLMs) to extract context from natural
language problem descriptions naturally raises questions about their
suitability in autonomous decision-making settings. This paper studies the
behaviour of these models within a Markov Decision Process (MDPs). While
traditional reinforcement learning (RL) strategies commonly employed in this
setting rely on iterative exploration, LLMs, pre-trained on diverse datasets,
offer the capability to leverage prior knowledge for faster adaptation. We
investigate online structured prompting strategies in sequential decision
making tasks, comparing the zero-shot performance of LLM-based approaches to
that of classical RL methods. Our findings reveal that although LLMs
demonstrate improved initial performance in simpler environments, they struggle
with planning and reasoning in complex scenarios without fine-tuning or
additional guidance. Our results show that feedback mechanisms, intended to
improve decision-making, often introduce confusion, leading to diminished
performance in intricate environments. These insights underscore the need for
further exploration into hybrid strategies, fine-tuning, and advanced memory
integration to enhance LLM-based decision-making capabilities.

</details>


### [499] [The Endless Tuning. An Artificial Intelligence Design To Avoid Human Replacement and Trace Back Responsibilities](https://arxiv.org/abs/2507.14909)
*Elio Grande*

Main category: cs.AI

TL;DR: “无限调优”是一种人工智能部署新方法，通过双重镜像避免取代人类并解决责任问题。在贷款、医疗和艺术领域进行了测试，用户感觉控制力强，且问责和责任可兼顾。


<details>
  <summary>Details</summary>
Motivation: 该研究旨在提出一种可靠部署人工智能的设计方法，以实现避免人类替代和填补责任鸿沟的目标。研究关注于提供一种不同于以往人工智能伦理的观点，并通过案例研究和用户体验实验来验证该方法的有效性。

Method: 提出了一种名为“无限调优”的设计方法，该方法基于双重镜像过程，并遵循关系性方法。研究详细说明了该方法的一个协议，并将其应用于三个原型应用：贷款审批、肺炎诊断和艺术风格识别。通过与领域专家的测试，研究关注用户体验而非统计准确性，并对技术选择（如XAI算法的反向和解释性部署）进行了哲学探讨。

Result: 研究结果表明，即使在使用深度学习模型的情况下，用户在决策设置中也能感知到完全的控制。此外，研究还发现，在发生损害的情况下，可以在问责制和责任之间建立桥梁。

Conclusion: 该研究提出了“无限调优”设计方法，旨在实现人工智能的可靠部署。该方法通过双重镜像过程，既避免了取代人类，又填补了责任鸿沟。研究将此方法应用于三个原型案例（贷款审批、肺炎诊断、艺术风格识别），并与领域专家进行了测试，重点关注用户体验而非统计准确性。实验结果表明，即使在使用深度学习模型的情况下，用户也能感知到决策过程的完全控制，并且在发生损害时，可以在责任和问责之间建立联系。

Abstract: The Endless Tuning is a design method for a reliable deployment of artificial
intelligence based on a double mirroring process, which pursues both the goals
of avoiding human replacement and filling the so-called responsibility gap
(Matthias 2004). Originally depicted in (Fabris et al. 2024) and ensuing the
relational approach urged therein, it was then actualized in a protocol,
implemented in three prototypical applications regarding decision-making
processes (respectively: loan granting, pneumonia diagnosis, and art style
recognition) and tested with such as many domain experts. Step by step
illustrating the protocol, giving insights concretely showing a different voice
(Gilligan 1993) in the ethics of artificial intelligence, a philosophical
account of technical choices (e.g., a reversed and hermeneutic deployment of
XAI algorithms) will be provided in the present study together with the results
of the experiments, focusing on user experience rather than statistical
accuracy. Even thoroughly employing deep learning models, full control was
perceived by the interviewees in the decision-making setting, while it appeared
that a bridge can be built between accountability and liability in case of
damage.

</details>


### [500] [Redefining Elderly Care with Agentic AI: Challenges and Opportunities](https://arxiv.org/abs/2507.14912)
*Ruhul Amin Khalil,Kashif Ahmad,Hazrat Ali*

Main category: cs.AI

TL;DR: Agentic AI, powered by LLMs, offers transformative potential for elderly care through personalized support but raises significant ethical concerns regarding privacy and decision-making that require careful management.


<details>
  <summary>Details</summary>
Motivation: The growing global aging population creates a need for new strategies in elderly care. This article aims to explore the transformative potential of Agentic AI, powered by LLMs, in addressing this need by discussing its applications, benefits, and challenges.

Method: This article explores the potential of Agentic Artificial Intelligence (AI), powered by Large Language Models (LLMs), in the transformation of elderly care. It addresses a literature gap by analyzing the unique capabilities, applications, and limitations of LLM-based Agentic AI in this domain. The authors also provide a companion interactive dashboard.

Result: The analysis highlights the proactive and autonomous decision-making capabilities of Agentic AI in personalized health tracking, cognitive care, and environmental management for older adults. It also identifies significant concerns regarding data privacy, security, decision independence, and access, emphasizing the need for ethical safeguards and transparency.

Conclusion: Agentic AI has the potential to significantly transform elderly care by enabling personalized health tracking, cognitive support, and environmental management, thereby enhancing independence and quality of life for older adults. However, ethical considerations such as data privacy, security, decision independence, and access must be addressed through robust safeguards, privacy protections, and transparent decision-making processes to ensure responsible integration.

Abstract: The global ageing population necessitates new and emerging strategies for
caring for older adults. In this article, we explore the potential for
transformation in elderly care through Agentic Artificial Intelligence (AI),
powered by Large Language Models (LLMs). We discuss the proactive and
autonomous decision-making facilitated by Agentic AI in elderly care.
Personalized tracking of health, cognitive care, and environmental management,
all aimed at enhancing independence and high-level living for older adults,
represents important areas of application. With a potential for significant
transformation of elderly care, Agentic AI also raises profound concerns about
data privacy and security, decision independence, and access. We share key
insights to emphasize the need for ethical safeguards, privacy protections, and
transparent decision-making. Our goal in this article is to provide a balanced
discussion of both the potential and the challenges associated with Agentic AI,
and to provide insights into its responsible use in elderly care, to bring
Agentic AI into harmony with the requirements and vulnerabilities specific to
the elderly. Finally, we identify the priorities for the academic research
communities, to achieve human-centered advancements and integration of Agentic
AI in elderly care. To the best of our knowledge, this is no existing study
that reviews the role of Agentic AI in elderly care. Hence, we address the
literature gap by analyzing the unique capabilities, applications, and
limitations of LLM-based Agentic AI in elderly care. We also provide a
companion interactive dashboard at https://hazratali.github.io/agenticai/.

</details>


### [501] [AlphaAlign: Incentivizing Safety Alignment with Extremely Simplified Reinforcement Learning](https://arxiv.org/abs/2507.14987)
*Yi Zhang,An Zhang,XiuYu Zhang,Leheng Sheng,Yuxin Chen,Zhenkai Liang,Xiang Wang*

Main category: cs.AI

TL;DR: AlphaAlign是一种创新的纯强化学习框架，通过可验证的安全奖励和标准化的有用性奖励，有效解决了大型语言模型的安全对齐问题，并在不牺牲效用的情况下实现了深度安全对齐和主动安全推理。


<details>
  <summary>Details</summary>
Motivation: 当前的LLM安全对齐方法往往会导致表面上的拒绝捷径，或者在基于推理的方法中过度依赖监督，未能充分利用模型内在的安全自我意识。此外，这些方法还会导致过度拒绝和效用下降的问题。

Method: AlphaAlign是一个纯粹的强化学习（RL）框架，它利用一个可验证的安全奖励来激励模型潜在的安全自我意识，并通过积极的安全推理来做到这一点。它采用双重奖励系统：可验证的安全奖励用于鼓励对有害查询的正确格式化和明确理由的拒绝，同时惩罚过度拒绝；标准化的有用性奖励用于指导对良性输入的响应。

Result: AlphaAlign在三个关键方面表现出色：1. 简单性和效率：仅需要二进制提示安全标签和少量的RL步骤即可获得显著改进。2. 突破了安全-效用权衡：它提高了对有害内容的拒绝能力，减少了过度拒绝，同时保持甚至提高了通用任务性能和对未见过的越狱攻击的鲁棒性。3. 深度对齐：它培养了积极的安全推理能力，能够生成明确的安全理由，而不是依赖于肤浅的拒绝模式。

Conclusion: AlphaAlign通过其双重奖励系统（可验证的安全奖励和标准化的有用性奖励）有效激励了LLM的潜在安全意识，从而实现了积极的安全推理，并克服了当前安全对齐方法的局限性，例如表面上的拒绝捷径或对基于推理的方法的过度依赖。

Abstract: Large language models (LLMs), despite possessing latent safety understanding
from their vast pretraining data, remain vulnerable to generating harmful
content and exhibit issues such as over-refusal and utility degradation after
safety alignment. Current safety alignment methods often result in superficial
refusal shortcuts or rely on intensive supervision for reasoning-based
approaches, failing to fully leverage the model's intrinsic safety
self-awareness. We propose \textbf{AlphaAlign}, a simple yet effective pure
reinforcement learning (RL) framework with verifiable safety reward designed to
incentivize this latent safety awareness through proactive safety reasoning.}
AlphaAlign employs a dual-reward system: a verifiable safety reward encourages
correctly formatted and explicitly justified refusals for harmful queries while
penalizing over-refusals, and a normalized helpfulness reward guides
high-quality responses to benign inputs. This allows the model to develop
proactive safety reasoning capabilities without depending on supervised
safety-specific reasoning data. AlphaAlign demonstrates three key advantages:
(1) Simplicity and efficiency, requiring only binary prompt safety labels and
minimal RL steps for substantial improvements. (2) Breaking the safety-utility
trade-off, by enhancing refusal of harmful content and reducing over-refusals,
while simultaneously maintaining or even improving general task performance and
robustness to unseen jailbreaks. (3) Deep alignment, fostering proactive safety
reasoning that generates explicit safety rationales rather than relying on
shallow refusal patterns.

</details>


### [502] [A Forced-Choice Neural Cognitive Diagnostic Model of Personality Testing](https://arxiv.org/abs/2507.15013)
*Xiaoyu Li,Jin Wu,Shaoyang Guo,Haoran Shi,Chanjin Zheng*

Main category: cs.AI

TL;DR: 提出了一种名为FCNCD的深度学习模型，用于分析强制选择测试，克服了传统模型的局限性，并通过实验验证了其准确性、可解释性和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 在智能时代，心理测量测试在人员选拔、职业发展和心理健康评估方面日益重要。强制选择测试因其要求参与者从密切相关的选项中进行选择，从而降低了响应偏差的风险，因此在性格评估中很常见。

Method: 提出了一种基于深度学习的强制选择神经认知诊断模型（FCNCD），该模型克服了传统模型的局限性，并适用于强制选择测试中最常见的三个项目块类型。为了解决强制选择测试中项目的单一维度问题，研究创建了可解释的参与者和项目参数。通过非线性映射挖掘参与者和项目特征后，使用多层神经网络对它们之间的交互进行建模。此外，还利用单调性假设来提高诊断结果的可解释性。

Result: 实验结果显示了FCNCD的准确性、可解释性和鲁棒性。

Conclusion: FCNCD的有效性通过在真实世界和模拟数据集上进行的实验得到验证，实验结果显示了其准确性、可解释性和鲁棒性。

Abstract: In the smart era, psychometric tests are becoming increasingly important for
personnel selection, career development, and mental health assessment.
Forced-choice tests are common in personality assessments because they require
participants to select from closely related options, lowering the risk of
response distortion. This study presents a deep learning-based Forced-Choice
Neural Cognitive Diagnostic Model (FCNCD) that overcomes the limitations of
traditional models and is applicable to the three most common item block types
found in forced-choice tests. To account for the unidimensionality of items in
forced-choice tests, we create interpretable participant and item parameters.
We model the interactions between participant and item features using
multilayer neural networks after mining them using nonlinear mapping. In
addition, we use the monotonicity assumption to improve the interpretability of
the diagnostic results. The FCNCD's effectiveness is validated by experiments
on real-world and simulated datasets that show its accuracy, interpretability,
and robustness.

</details>


### [503] [DeRAG: Black-box Adversarial Attacks on Multiple Retrieval-Augmented Generation Applications via Prompt Injection](https://arxiv.org/abs/2507.15042)
*Jerry Wang,Fang Yu*

Main category: cs.AI

TL;DR: This paper introduces a Differential Evolution (DE) method to create adversarial prompt attacks for RAG systems. The method optimizes suffixes to trick RAG into retrieving wrong information, showing strong performance against existing methods and evading detection, even with short suffixes.


<details>
  <summary>Details</summary>
Motivation: Adversarial prompt attacks can degrade the reliability of Retrieval-Augmented Generation (RAG) systems by causing them to produce incorrect outputs. This work aims to develop an effective method to optimize these attacks.

Method: This paper proposes a novel gradient-free method using Differential Evolution (DE) to optimize adversarial prompt suffixes for RAG-based question answering. The RAG pipeline is treated as a black box, and DE evolves candidate suffixes to maximize the retrieval rank of a targeted incorrect document. A readability-aware suffix construction strategy was also introduced and validated.

Result: Experiments on BEIR QA datasets show that the DE-based method attains competitive or higher success rates compared to GGPP and PRADA, using only a few tokens (<=5). The readability-aware strategy reduced MLM negative log-likelihood. Furthermore, DE-generated suffixes were found to evade detection by a BERT-based detector, resulting in near-chance detection accuracy.

Conclusion: DE-based prompt optimization achieves competitive or higher success rates than existing methods like GGPP and PRADA for RAG systems, using minimal tokens and evading detection by adversarial suffix detectors.

Abstract: Adversarial prompt attacks can significantly alter the reliability of
Retrieval-Augmented Generation (RAG) systems by re-ranking them to produce
incorrect outputs. In this paper, we present a novel method that applies
Differential Evolution (DE) to optimize adversarial prompt suffixes for
RAG-based question answering. Our approach is gradient-free, treating the RAG
pipeline as a black box and evolving a population of candidate suffixes to
maximize the retrieval rank of a targeted incorrect document to be closer to
real world scenarios. We conducted experiments on the BEIR QA datasets to
evaluate attack success at certain retrieval rank thresholds under multiple
retrieving applications. Our results demonstrate that DE-based prompt
optimization attains competitive (and in some cases higher) success rates
compared to GGPP to dense retrievers and PRADA to sparse retrievers, while
using only a small number of tokens (<=5 tokens) in the adversarial suffix.
Furthermore, we introduce a readability-aware suffix construction strategy,
validated by a statistically significant reduction in MLM negative
log-likelihood with Welch's t-test. Through evaluations with a BERT-based
adversarial suffix detector, we show that DE-generated suffixes evade
detection, yielding near-chance detection accuracy.

</details>


### [504] [From Kicking to Causality: Simulating Infant Agency Detection with a Robust Intrinsic Reward](https://arxiv.org/abs/2507.15106)
*Xia Xu,Jochen Triesch*

Main category: cs.AI

TL;DR: CAIS 是一种基于因果推理的奖励，可帮助 RL 代理在嘈杂的环境中学习，重现“消退爆发”现象。


<details>
  <summary>Details</summary>
Motivation: 标准强化学习代理仍然脆弱，因为它们对基于相关性的奖励的依赖在嘈杂、生态有效的场景中会失败。

Method: 我们引入了因果行动影响得分（CAIS），这是一种基于因果推理的新颖内在奖励。CAIS 通过衡量学习到的感官结果分布（以该行动为条件）$p(h|a)$ 与基线结果分布$p(h)$之间的 1-Wasserstein 距离来量化行动的影响。

Result: CAIS 使代理能够过滤噪声、识别其影响并学习正确的策略，并成功重现“消退爆发”现象。

Conclusion: 因果推理是开发稳健的代理感的重要机制，为更具适应性的自主系统提供了心理学上合理的框架。

Abstract: While human infants robustly discover their own causal efficacy, standard
reinforcement learning agents remain brittle, as their reliance on
correlation-based rewards fails in noisy, ecologically valid scenarios. To
address this, we introduce the Causal Action Influence Score (CAIS), a novel
intrinsic reward rooted in causal inference. CAIS quantifies an action's
influence by measuring the 1-Wasserstein distance between the learned
distribution of sensory outcomes conditional on that action, $p(h|a)$, and the
baseline outcome distribution, $p(h)$. This divergence provides a robust reward
that isolates the agent's causal impact from confounding environmental noise.
We test our approach in a simulated infant-mobile environment where
correlation-based perceptual rewards fail completely when the mobile is
subjected to external forces. In stark contrast, CAIS enables the agent to
filter this noise, identify its influence, and learn the correct policy.
Furthermore, the high-quality predictive model learned for CAIS allows our
agent, when augmented with a surprise signal, to successfully reproduce the
"extinction burst" phenomenon. We conclude that explicitly inferring causality
is a crucial mechanism for developing a robust sense of agency, offering a
psychologically plausible framework for more adaptive autonomous systems.

</details>


### [505] [Clinical Semantic Intelligence (CSI): Emulating the Cognitive Framework of the Expert Clinician for Comprehensive Oral Disease Diagnosis](https://arxiv.org/abs/2507.15140)
*Mohammad Mashayekhi,Sara Ahmadi Majd,Arian AmirAmjadi,Parsa Hosseini*

Main category: cs.AI

TL;DR: CSI框架通过模拟专家推理，利用CLIP和ChatGLM模型及HDRT，在口腔疾病诊断方面达到89.5%的准确率。


<details>
  <summary>Details</summary>
Motivation: 为了解决口腔疾病诊断的临床挑战，即病变谱广泛且症状重叠，开发一个能够模拟专家认知过程的AI框架，以超越简单的模式匹配，提供有用的临床诊断辅助。

Method: 开发了临床语义智能（CSI）框架，结合了CLIP多模态模型和ChatGLM-6B语言模型，并利用了分层诊断推理树（HDRT）来模拟专家诊断过程，同时包含快速模式和标准模式两种运行方式。

Result: 在内部测试集上，CSI的快速模式准确率为73.4%，标准模式（利用HDRT）准确率提升至89.5%。

Conclusion: CSI框架在诊断口腔疾病方面表现出高准确率，其HDRT驱动的标准模式性能提升显著，证明了模拟专家推理的重要性。

Abstract: The diagnosis of oral diseases presents a problematic clinical challenge,
characterized by a wide spectrum of pathologies with overlapping
symptomatology. To address this, we developed Clinical Semantic Intelligence
(CSI), a novel artificial intelligence framework that diagnoses 118 different
oral diseases by computationally modeling the cognitive processes of an expert
clinician. Our core hypothesis is that moving beyond simple pattern matching to
emulate expert reasoning is critical to building clinically useful diagnostic
aids.
  CSI's architecture integrates a fine-tuned multimodal CLIP model with a
specialized ChatGLM-6B language model. This system executes a Hierarchical
Diagnostic Reasoning Tree (HDRT), a structured framework that distills the
systematic, multi-step logic of differential diagnosis. The framework operates
in two modes: a Fast Mode for rapid screening and a Standard Mode that
leverages the full HDRT for an interactive and in-depth diagnostic workup.
  To train and validate our system, we curated a primary dataset of 4,310
images, supplemented by an external hold-out set of 176 images for final
validation. A clinically-informed augmentation strategy expanded our training
data to over 30,000 image-text pairs. On a 431-image internal test set, CSI's
Fast Mode achieved an accuracy of 73.4%, which increased to 89.5% with the
HDRT-driven Standard Mode. The performance gain is directly attributable to the
hierarchical reasoning process. Herein, we detail the architectural philosophy,
development, and rigorous evaluation of the CSI framework.

</details>


### [506] [Continuous Classification Aggregation](https://arxiv.org/abs/2507.05297)
*Zijun Meng*

Main category: cs.AI

TL;DR: 模糊分类聚合函数是加权算术平均值。


<details>
  <summary>Details</summary>
Motivation: 研究模糊分类聚合函数的性质

Method: 证明和刻画

Result: 证明了最优、独立、零一致的模糊分类聚合函数是加权算术平均值，并对 $m=p=2$ 的情况进行了刻画。

Conclusion: 证明了任何最优、独立、零一致的模糊分类聚合函数（对于 $m 	imes p$ 的分类）必须是加权算术平均值，并对 $m=p=2$ 的情况进行了刻画。

Abstract: We prove that any optimal, independent, and zero unanimous fuzzy
classification aggregation function of a continuum of individual
classifications of $m\ge 3$ objects into $2\le p\le m$ types must be a weighted
arithmetic mean. We also provide a characterization for the case when $m=p=2$.

</details>


### [507] [Solving Formal Math Problems by Decomposition and Iterative Reflection](https://arxiv.org/abs/2507.15225)
*Yichi Zhou,Jianqiu Zhao,Yongxin Zhang,Bohan Wang,Siran Wang,Luoxin Chen,Jiahui Wang,Haowei Chen,Allan Jie,Xinbo Zhang,Haocheng Wang,Luong Trung,Rong Ye,Phan Nhat Hoang,Huishuai Zhang,Peng Sun,Hang Li*

Main category: cs.AI

TL;DR: Delta Prover 是一个框架，它利用通用 LLM 来证明 Lean 4 中的定理，无需专门化模型，并在 miniF2F-test 上取得了 95.9% 的成功率。


<details>
  <summary>Details</summary>
Motivation: 当前，通用 LLM 在生成 Lean 4 等专业语言中的形式化证明方面仍面临挑战，这限制了它们在复杂定理证明和自动验证中的应用。现有方法通常需要通过在专用形式化语料库上进行微调来实现模型专业化，但成本高昂。

Method: 本研究介绍了一个名为 Delta Prover 的基于代理的框架，该框架协调通用 LLM 与 Lean 4 证明环境的交互。该框架包含一个用于反射性分解和迭代证明修复的算法框架，以及一个基于 Lean 4 的自定义领域特定语言（DSL）来实现子问题管理。

Result: Delta Prover 在 miniF2F-test 基准测试上取得了 95.9% 的最先进成功率，超过了包括需要模型专业化的方法在内的所有现有方法。此外，与标准的 Best-of-N 证明策略相比，Delta Prover 在测试时显示出更强的可扩展性。

Conclusion: 该研究表明，通过有效的代理结构引导下的通用语言模型（LLMs）在定理证明方面具有巨大的潜力，为在形式化环境中进行强大的自动化推理提供了一种比专门模型更具计算效率的替代方案。

Abstract: General-purpose Large Language Models (LLMs) have achieved remarkable success
in intelligence, performing comparably to human experts on complex reasoning
tasks such as coding and mathematical reasoning. However, generating formal
proofs in specialized languages like Lean 4 remains a significant challenge for
these models, limiting their application in complex theorem proving and
automated verification. Current approaches typically require specializing
models through fine-tuning on dedicated formal corpora, incurring high costs
for data collection and training. In this work, we introduce \textbf{Delta
Prover}, an agent-based framework that orchestrates the interaction between a
general-purpose LLM and the Lean 4 proof environment. Delta Prover leverages
the reflection and reasoning capabilities of general-purpose LLMs to
interactively construct formal proofs in Lean 4, circumventing the need for
model specialization. At its core, the agent integrates two novel,
interdependent components: an algorithmic framework for reflective
decomposition and iterative proof repair, and a custom Domain-Specific Language
(DSL) built upon Lean 4 for streamlined subproblem management. \textbf{Delta
Prover achieves a state-of-the-art 95.9\% success rate on the miniF2F-test
benchmark, surpassing all existing approaches, including those requiring model
specialization.} Furthermore, Delta Prover exhibits a significantly stronger
test-time scaling law compared to standard Best-of-N proof strategies.
Crucially, our findings demonstrate that general-purpose LLMs, when guided by
an effective agentic structure, possess substantial untapped theorem-proving
capabilities. This presents a computationally efficient alternative to
specialized models for robust automated reasoning in formal environments.

</details>


### [508] [Explainable Artificial Intelligence based Soft Evaluation Indicator for Arc Fault Diagnosis](https://arxiv.org/abs/2507.15239)
*Qianchao Wang,Yuxuan Ding,Chuanzhen Jia,Zhe Li,Yaping Du*

Main category: cs.AI

TL;DR: 提出了一种新的软评估指标和轻量级神经网络，用于提高AI电弧故障诊断模型的准确性和可信度。


<details>
  <summary>Details</summary>
Motivation: 解决基于人工智能的电弧故障诊断模型在实际应用中可信度不足的问题，旨在提高模型的可解释性和用户信任度。

Method: 提出了一种软评估指标，该指标通过定义电弧故障的正确解释，并利用可解释人工智能和真实的电弧故障实验来解释电弧故障诊断模型的输出。此外，还提出了一种轻量级的平衡神经网络，以保证具有竞争力的准确性和软特征提取分数。

Result: 实验结果表明，所提出的软评估指标能够有效评估和提升电弧故障诊断模型的可理解性和可信度，即使在不同的数据集和条件下也能保持有效性。

Conclusion: 通过提出一个软评估指标，可以提高人工智能模型在电弧故障诊断中的可信度和可理解性，使从业者能够做出明智且值得信赖的决策。

Abstract: Novel AI-based arc fault diagnosis models have demonstrated outstanding
performance in terms of classification accuracy. However, an inherent problem
is whether these models can actually be trusted to find arc faults. In this
light, this work proposes a soft evaluation indicator that explains the outputs
of arc fault diagnosis models, by defining the the correct explanation of arc
faults and leveraging Explainable Artificial Intelligence and real arc fault
experiments. Meanwhile, a lightweight balanced neural network is proposed to
guarantee competitive accuracy and soft feature extraction score. In our
experiments, several traditional machine learning methods and deep learning
methods across two arc fault datasets with different sample times and noise
levels are utilized to test the effectiveness of the soft evaluation indicator.
Through this approach, the arc fault diagnosis models are easy to understand
and trust, allowing practitioners to make informed and trustworthy decisions.

</details>


### [509] [QSAF: A Novel Mitigation Framework for Cognitive Degradation in Agentic AI](https://arxiv.org/abs/2507.15330)
*Hammad Atta,Muhammad Zeeshan Baig,Yasir Mehmood,Nadeem Shahzad,Ken Huang,Muhammad Aziz Ul Haq,Muhammad Awais,Kamal Ahmed*

Main category: cs.AI

TL;DR: 研究提出了“认知退化”作为AI Agent的新型内部漏洞，并开发了一个名为QSAF Domain 10的防御框架，通过模拟人类认知来增强Agent的韧性。


<details>
  <summary>Details</summary>
Motivation: 为了应对Agent内部的故障，如内存耗尽、规划器递归、上下文泛滥和输出抑制，这些故障会导致Agent行为漂移、逻辑崩溃和持续的幻觉。

Method: 提出了一种名为QSAF Domain 10的生命周期感知防御框架，该框架包含六个阶段的认知退化生命周期，并提供了七个运行时控件（QSAF-BC-001至BC-007）来监控Agent子系统并触发缓解措施。该框架借鉴认知神经科学，将Agent架构映射到人类类比，以检测疲劳、饥饿和角色崩溃。

Result: 引入了认知退化作为一类新的AI系统漏洞，并提出了QSAF Domain 10防御框架，该框架通过监控和实时缓解措施来增强Agent的认知韧性。

Conclusion: 该研究将认知退化确立为一种关键的新型AI系统漏洞，并提出了首个跨平台的弹性Agent行为防御模型。

Abstract: We introduce Cognitive Degradation as a novel vulnerability class in agentic
AI systems. Unlike traditional adversarial external threats such as prompt
injection, these failures originate internally, arising from memory starvation,
planner recursion, context flooding, and output suppression. These systemic
weaknesses lead to silent agent drift, logic collapse, and persistent
hallucinations over time. To address this class of failures, we introduce the
Qorvex Security AI Framework for Behavioral & Cognitive Resilience (QSAF Domain
10), a lifecycle-aware defense framework defined by a six-stage cognitive
degradation lifecycle. The framework includes seven runtime controls
(QSAF-BC-001 to BC-007) that monitor agent subsystems in real time and trigger
proactive mitigation through fallback routing, starvation detection, and memory
integrity enforcement. Drawing from cognitive neuroscience, we map agentic
architectures to human analogs, enabling early detection of fatigue,
starvation, and role collapse. By introducing a formal lifecycle and real-time
mitigation controls, this work establishes Cognitive Degradation as a critical
new class of AI system vulnerability and proposes the first cross-platform
defense model for resilient agentic behavior.

</details>


### [510] [RAD: Retrieval High-quality Demonstrations to Enhance Decision-making](https://arxiv.org/abs/2507.15356)
*Lu Guo,Yixiang Shan,Zhengbang Zhu,Qifan Liang,Lichang Song,Ting Long,Weinan Zhang,Yi Chang*

Main category: cs.AI

TL;DR: Offline RL struggles with sparse data and trajectory gaps. RAD uses a diffusion model to retrieve and plan towards high-return states, improving generalization and performance.


<details>
  <summary>Details</summary>
Motivation: Offline RL is limited by dataset sparsity and lack of transition overlap, making long-horizon planning challenging. Prior solutions often fail to generalize and rely on heuristic stitching points.

Method: RAD dynamically retrieves high-return states from the offline dataset as target states based on state similarity and return estimation, and plans toward them using a condition-guided diffusion model. This retrieval-guided generation enables flexible trajectory stitching and improves generalization when encountered with underrepresented or out-of-distribution states.

Result: Extensive experiments confirm that RAD achieves competitive or superior performance compared to baselines across diverse benchmarks.

Conclusion: RAD achieves competitive or superior performance compared to baselines across diverse benchmarks, validating its effectiveness.

Abstract: Offline reinforcement learning (RL) enables agents to learn policies from
fixed datasets, avoiding costly or unsafe environment interactions. However,
its effectiveness is often limited by dataset sparsity and the lack of
transition overlap between suboptimal and expert trajectories, which makes
long-horizon planning particularly challenging. Prior solutions based on
synthetic data augmentation or trajectory stitching often fail to generalize to
novel states and rely on heuristic stitching points. To address these
challenges, we propose Retrieval High-quAlity Demonstrations (RAD) for
decision-making, which combines non-parametric retrieval with diffusion-based
generative modeling. RAD dynamically retrieves high-return states from the
offline dataset as target states based on state similarity and return
estimation, and plans toward them using a condition-guided diffusion model.
Such retrieval-guided generation enables flexible trajectory stitching and
improves generalization when encountered with underrepresented or
out-of-distribution states. Extensive experiments confirm that RAD achieves
competitive or superior performance compared to baselines across diverse
benchmarks, validating its effectiveness.

</details>


### [511] [Predictive Process Monitoring Using Object-centric Graph Embeddings](https://arxiv.org/abs/2507.15411)
*Wissam Gherissi,Mehdi Acheli,Joyce El Haddad,Daniela Grigori*

Main category: cs.AI

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Object-centric predictive process monitoring explores and utilizes
object-centric event logs to enhance process predictions. The main challenge
lies in extracting relevant information and building effective models. In this
paper, we propose an end-to-end model that predicts future process behavior,
focusing on two tasks: next activity prediction and next event time. The
proposed model employs a graph attention network to encode activities and their
relationships, combined with an LSTM network to handle temporal dependencies.
Evaluated on one reallife and three synthetic event logs, the model
demonstrates competitive performance compared to state-of-the-art methods.

</details>


### [512] [Optimization of Activity Batching Policies in Business Processes](https://arxiv.org/abs/2507.15457)
*Orlenys López-Pintado,Jannis Rosenbaum,Marlon Dumas*

Main category: cs.AI

TL;DR: 通过干预启发式和帕累托优化来改进业务流程中的活动批处理策略，以平衡等待时间、处理工作量和成本。


<details>
  <summary>Details</summary>
Motivation: 旨在解决业务流程中活动批处理策略的发现问题，寻找能够在等待时间、处理工作量和成本之间取得最优权衡的策略。

Method: 提出了一种帕累托优化方法，通过干预启发式来生成和改进活动批处理策略。干预启发式识别改进机会并调整批处理策略，通过模拟评估干预效果。该方法将这些启发式嵌入到元启发式（如爬山法、模拟退火和强化学习）中，以迭代更新帕累托前沿。

Result: 实验评估表明，所提出的基于干预启发式的方法在收敛性、多样性和周期时间增益方面优于不使用启发式引导的元启发式基线方法。

Conclusion: 该研究提出了一种基于干预启发式的帕累托优化方法，用于发现能够优化等待时间、处理工作量和成本之间权衡的活动批处理策略。实验评估将该方法与不使用启发式引导的元启发式方法进行了比较，结果显示其在收敛性、多样性和帕累托最优策略的周期时间增益方面具有优势。

Abstract: In business processes, activity batching refers to packing multiple activity
instances for joint execution. Batching allows managers to trade off cost and
processing effort against waiting time. Larger and less frequent batches may
lower costs by reducing processing effort and amortizing fixed costs, but they
create longer waiting times. In contrast, smaller and more frequent batches
reduce waiting times but increase fixed costs and processing effort. A batching
policy defines how activity instances are grouped into batches and when each
batch is activated. This paper addresses the problem of discovering batching
policies that strike optimal trade-offs between waiting time, processing
effort, and cost. The paper proposes a Pareto optimization approach that starts
from a given set (possibly empty) of activity batching policies and generates
alternative policies for each batched activity via intervention heuristics.
Each heuristic identifies an opportunity to improve an activity's batching
policy with respect to a metric (waiting time, processing time, cost, or
resource utilization) and an associated adjustment to the activity's batching
policy (the intervention). The impact of each intervention is evaluated via
simulation. The intervention heuristics are embedded in an optimization
meta-heuristic that triggers interventions to iteratively update the Pareto
front of the interventions identified so far. The paper considers three
meta-heuristics: hill-climbing, simulated annealing, and reinforcement
learning. An experimental evaluation compares the proposed approach based on
intervention heuristics against the same (non-heuristic guided) meta-heuristics
baseline regarding convergence, diversity, and cycle time gain of
Pareto-optimal policies.

</details>


### [513] [Chart-R1: Chain-of-Thought Supervision and Reinforcement for Advanced Chart Reasoner](https://arxiv.org/abs/2507.15509)
*Lei Chen,Xuanle Zhao,Zhixiong Zeng,Jing Huang,Yufeng Zhong,Lin Ma*

Main category: cs.AI

TL;DR: 本研究提出Chart-R1，一个基于强化学习微调的图表领域视觉语言模型，用于复杂的图表推理。通过创新的数据合成和两阶段训练策略（Chart-COT和Chart-RFT），显著提升了模型在图表推理任务上的表现，可与顶尖大型模型相媲美。


<details>
  <summary>Details</summary>
Motivation: 验证R1-Style方法（基于强化学习微调）在更通用的多模态数据（特别是图表数据）上的优势，以实现复杂的图表推理。

Method: 提出了一种新的程序化数据合成技术来生成高质量的、逐步的图表推理数据（包括单子图和多子图），以弥补图表领域推理数据的不足。开发了一种两阶段训练策略：Chart-COT（使用逐步的链式思考监督）和Chart-RFT（使用数值敏感的强化微调）。Chart-COT旨在通过逐步监督将复杂的图表推理任务分解为细粒度、可理解的子任务；Chart-RFT利用典型的组相对策略优化策略，采用相对较软的奖励来强调图表领域的数值敏感性。

Result: 在开源基准和自建的ChartRQA数据集上进行了广泛的实验，结果表明Chart-R1相比于图表领域的其他方法具有显著优势，并且与GPT-4o、Claude-3.5等大型模型相当。

Conclusion: Chart-R1在图表领域的复杂推理方面表现出显著优势，性能可与GPT-4o、Claude-3.5等大型模型相媲美。

Abstract: Recently, inspired by OpenAI-o1/o3 and Deepseek-R1, the R1-Style method based
on reinforcement learning fine-tuning has received widespread attention from
the community. Previous R1-Style methods mainly focus on mathematical reasoning
and code intelligence. It is of great research significance to verify their
advantages on more general multimodal data. Chart is an important multimodal
data type with rich information, which brings important research challenges in
complex reasoning. In this work, we introduce Chart-R1, a chart-domain
vision-language model with reinforcement learning fine-tuning to enable complex
chart reasoning. To support Chart-R1, we first propose a novel programmatic
data synthesis technology to generate high-quality step-by-step chart reasoning
data covering single- and multi-subcharts, which makes up for the lack of
reasoning data in the chart domain. Then we develop a two-stage training
strategy: Chart-COT with step-by-step chain-of-thought supervision, and
Chart-RFT with numerically sensitive reinforcement fine-tuning. Chart-COT aims
to decompose complex chart reasoning tasks into fine-grained, understandable
subtasks through step-by-step supervision, which lays a good foundation for
improving the reasoning level of reinforcement learning. Chart-RFT utilize the
typical group relative policy optimization strategy, in which a relatively soft
reward is adopted for numerical response to emphasize the numerical sensitivity
in the chart domain. We conduct extensive experiments on open-source benchmarks
and self-built chart reasoning dataset (\emph{i.e., ChartRQA}). Experimental
results show that Chart-R1 has significant advantages compared to chart-domain
methods, even comparable to open/closed source large-scale models (\emph{e.g.,
GPT-4o, Claude-3.5}).

</details>


### [514] [LLM world models are mental: Output layer evidence of brittle world model use in LLM mechanical reasoning](https://arxiv.org/abs/2507.15521)
*Cole Robertson,Philip Wolff*

Main category: cs.AI

TL;DR: LLM可以进行基本的物理推理，但其能力有限。


<details>
  <summary>Details</summary>
Motivation: 本研究旨在探讨大型语言模型（LLM）是构建和操纵内部世界模型，还是仅仅依赖于作为输出层标记概率表示的统计关联。

Method: 本研究采用认知科学中的心智模型研究方法，并使用TikZ渲染的刺激，对LLM在滑轮系统问题上的表现进行了测试。研究1检查了LLM是否能估计机械优势（MA），并分析了滑轮数量与模型估计之间的相关性。研究2测试了LLM是否能表示对MA估计至关重要的全局特征，方法是评估一个功能连接的滑轮系统与一个组件随机放置的虚假系统。研究3则通过要求LLM比较功能系统与连接好但对重量无力的匹配系统来进一步探究。

Result: 研究1表明，最先进的模型表现略高于随机水平，并且其估计值与真实的机械优势显著相关，滑轮数量与模型估计值之间也存在显著相关性，这表明模型可能采用了滑轮计数启发式方法。研究2显示，在没有明确线索的情况下，模型能够以F1=0.8的准确率识别出功能性系统，表明LLM能够充分表示系统以区分混乱系统和功能系统。研究3则显示，LLM在区分功能系统与无力传递的匹配系统时准确率仅为F1=0.46，表现如同随机猜测。

Conclusion: LLM在一定程度上可以操纵内部世界模型，以利用滑轮数量和机械优势之间的统计关联，并能近似表示系统组件的空间关系。然而，它们可能缺乏推理细微结构连接的能力。我们主张使用认知科学方法来评估人工智能系统的世界建模能力。

Abstract: Do large language models (LLMs) construct and manipulate internal world
models, or do they rely solely on statistical associations represented as
output layer token probabilities? We adapt cognitive science methodologies from
human mental models research to test LLMs on pulley system problems using
TikZ-rendered stimuli. Study 1 examines whether LLMs can estimate mechanical
advantage (MA). State-of-the-art models performed marginally but significantly
above chance, and their estimates correlated significantly with ground-truth
MA. Significant correlations between number of pulleys and model estimates
suggest that models employed a pulley counting heuristic, without necessarily
simulating pulley systems to derive precise values. Study 2 tested this by
probing whether LLMs represent global features crucial to MA estimation. Models
evaluated a functionally connected pulley system against a fake system with
randomly placed components. Without explicit cues, models identified the
functional system as having greater MA with F1=0.8, suggesting LLMs could
represent systems well enough to differentiate jumbled from functional systems.
Study 3 built on this by asking LLMs to compare functional systems with matched
systems which were connected up but which transferred no force to the weight;
LLMs identified the functional system with F1=0.46, suggesting random guessing.
Insofar as they may generalize, these findings are compatible with the notion
that LLMs manipulate internal world models, sufficient to exploit statistical
associations between pulley count and MA (Study 1), and to approximately
represent system components' spatial relations (Study 2). However, they may
lack the facility to reason over nuanced structural connectivity (Study 3). We
conclude by advocating the utility of cognitive scientific methods to evaluate
the world-modeling capacities of artificial intelligence systems.

</details>


### [515] [Data-Efficient Safe Policy Improvement Using Parametric Structure](https://arxiv.org/abs/2507.15532)
*Kasper Engelen,Guillermo A. Pérez,Marnix Suilen*

Main category: cs.AI

TL;DR: 本研究通过利用MDP转移动力学中的参数依赖关系，结合基于游戏的抽象和SMT求解器，提出了提高安全策略改进（SPI）算法数据效率的方法，并在实验中验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 在许多应用中，MDP的转移动力学中存在参数依赖关系。本研究旨在利用这些依赖关系来提高SPI的数据效率。

Method: 提出了一种参数化SPI算法，该算法利用已知的分布相关性来更准确地估计转移动力学。设计了一种基于游戏抽象的预处理技术，通过消除冗余动作来简化环境。引入了一种基于SMT求解器的更高级预处理技术，以识别和消除更多冗余动作。

Result: 经验结果和消融研究表明，所提出的技术可将SPI的数据效率提高几个数量级，同时保持相同的可靠性保证。

Conclusion: 利用参数依赖关系、基于游戏的抽象和SMT求解器来提高数据效率，可以在保持可靠性保证的同时，将SPI的数据效率提高几个数量级。

Abstract: Safe policy improvement (SPI) is an offline reinforcement learning problem in
which a new policy that reliably outperforms the behavior policy with high
confidence needs to be computed using only a dataset and the behavior policy.
Markov decision processes (MDPs) are the standard formalism for modeling
environments in SPI. In many applications, additional information in the form
of parametric dependencies between distributions in the transition dynamics is
available. We make SPI more data-efficient by leveraging these dependencies
through three contributions: (1) a parametric SPI algorithm that exploits known
correlations between distributions to more accurately estimate the transition
dynamics using the same amount of data; (2) a preprocessing technique that
prunes redundant actions from the environment through a game-based abstraction;
and (3) a more advanced preprocessing technique, based on satisfiability modulo
theory (SMT) solving, that can identify more actions to prune. Empirical
results and an ablation study show that our techniques increase the data
efficiency of SPI by multiple orders of magnitude while maintaining the same
reliability guarantees.

</details>


### [516] [Metric assessment protocol in the context of answer fluctuation on MCQ tasks](https://arxiv.org/abs/2507.15581)
*Ekaterina Goliakova,Xavier Renard,Marie-Jeanne Lesot,Thibault Laugel,Christophe Marsala,Marcin Detyniecki*

Main category: cs.AI

TL;DR: LLM评估的MCQ存在答案波动问题。我们提出了一种新的评估协议，并将“最差准确率”作为一种新的指标，它与答案波动有很强的关联性。


<details>
  <summary>Details</summary>
Motivation: 为了解决LLM评估中多项选择题（MCQ）评估的答案波动问题，并对现有指标进行全面评估。

Method: 提出了一种指标评估协议，通过评估方法与不确定性率以及原始性能的联系来分析评估方法。

Result: 研究表明，现有指标与答案变化之间存在很强的联系，即使在没有额外提示变体的情况下计算也是如此。“最差准确率”这一新指标与该协议具有最高的关联性。

Conclusion: 所提出的指标评估协议将评估方法与其不确定性以及原始性能联系起来，并且“最差准确率”指标与该协议具有最高的关联性。

Abstract: Using multiple-choice questions (MCQs) has become a standard for assessing
LLM capabilities efficiently. A variety of metrics can be employed for this
task. However, previous research has not conducted a thorough assessment of
them. At the same time, MCQ evaluation suffers from answer fluctuation: models
produce different results given slight changes in prompts. We suggest a metric
assessment protocol in which evaluation methodologies are analyzed through
their connection with fluctuation rates, as well as original performance. Our
results show that there is a strong link between existing metrics and the
answer changing, even when computed without any additional prompt variants. A
novel metric, worst accuracy, demonstrates the highest association on the
protocol.

</details>


### [517] [TacticCraft: Natural Language-Driven Tactical Adaptation for StarCraft II](https://arxiv.org/abs/2507.15618)
*Weiyu Ma,Jiwen Jiang,Haobo Fu,Haifeng Zhang*

Main category: cs.AI

TL;DR: 提出一种基于适配器的方法，用于星际争霸II AI智能体的战术条件化。该方法通过训练轻量级适配器来调整预训练策略，使其能够根据战术指令改变行为，同时保持核心能力和竞争性能。该方法能够灵活地进行战术控制，计算开销小，并为复杂的实时策略游戏提供实用的策略定制。


<details>
  <summary>Details</summary>
Motivation: 当前的星际争霸II AI智能体虽然强大，但缺乏根据高级战术指令调整其策略的能力。

Method: 通过冻结预训练策略网络（DI-Star）并为每个动作头附加轻量级适配器模块，该模块以编码策略偏好的战术张量为条件。通过使用KL散度约束来训练这些适配器，可以确保策略在展现战术变化的同时保持核心能力。

Result: 实验结果表明，该方法能够成功地调整智能体行为以适应不同的战术维度（包括侵略性、扩张模式和技术偏好），同时保持竞争性能。

Conclusion: 该方法能够成功地调整智能体行为以适应不同的战术维度（包括侵略性、扩张模式和技术偏好），同时保持竞争性能。

Abstract: We present an adapter-based approach for tactical conditioning of StarCraft
II AI agents. Current agents, while powerful, lack the ability to adapt their
strategies based on high-level tactical directives. Our method freezes a
pre-trained policy network (DI-Star) and attaches lightweight adapter modules
to each action head, conditioned on a tactical tensor that encodes strategic
preferences. By training these adapters with KL divergence constraints, we
ensure the policy maintains core competencies while exhibiting tactical
variations. Experimental results show our approach successfully modulates agent
behavior across tactical dimensions including aggression, expansion patterns,
and technology preferences, while maintaining competitive performance. Our
method enables flexible tactical control with minimal computational overhead,
offering practical strategy customization for complex real-time strategy games.

</details>


### [518] [Towards physician-centered oversight of conversational diagnostic AI](https://arxiv.org/abs/2507.15743)
*Elahe Vedadi,David Barrett,Natalie Harris,Ellery Wulczyn,Shashir Reddy,Roma Ruparel,Mike Schaekermann,Tim Strother,Ryutaro Tanno,Yash Sharma,Jihyeon Lee,Cían Hughes,Dylan Slack,Anil Palepu,Jan Freyberg,Khaled Saab,Valentin Liévin,Wei-Hung Weng,Tao Tu,Yun Liu,Nenad Tomasev,Kavita Kulkarni,S. Sara Mahdavi,Kelvin Guu,Joëlle Barral,Dale R. Webster,James Manyika,Avinatan Hassidim,Katherine Chou,Yossi Matias,Pushmeet Kohli,Adam Rodman,Vivek Natarajan,Alan Karthikesalingam,David Stutz*

Main category: cs.AI

TL;DR: 提出了一种名为g-AMIE的多代理系统，用于在安全护栏内进行问诊，并将评估信息传达给监督的PCP，以实现异步监督。在虚拟OSCE研究中，g-AMIE在问诊质量、病例总结以及诊断和治疗计划方面优于NPs/PAs和PCP组，并且PCP对g-AMIE的监督比独立PCP咨询更有效率。


<details>
  <summary>Details</summary>
Motivation: 受限于AI系统提供个体化诊断和治疗计划是受许可专业人士监管活动的启发，并考虑到医师通常会监督其他团队成员（如NPs或PAs）参与此类活动。

Method: 提出了一种名为guardrailed-AMIE (g-AMIE) 的多代理系统，该系统在安全护栏内进行问诊，不提供个体化医疗建议。然后，g-AMIE通过临床座舱界面将评估信息传达给监督的初级保健医师(PCP)，PCP提供监督并保留临床决策的责任。在对带有异步监督的文本咨询进行的随机、盲法虚拟客观结构化临床考试(OSCE)中，将g-AMIE与在相同安全护栏下的护士执业医师/医师助理(NPs/PAs)或一组PCP进行了比较。

Result: 在60个场景中，g-AMIE在进行高质量问诊、总结病例以及提出供监督的PCP审阅的诊断和治疗计划方面，优于NPs/PAs和PCP组。这导致了更高质量的综合决策。与先前研究中的独立PCP咨询相比，PCP对g-AMIE的监督也更有效率。

Conclusion: 本研究结果表明，异步监督范式对于诊断AI系统在专家人类监督下运行以增强实际护理具有可行性。

Abstract: Recent work has demonstrated the promise of conversational AI systems for
diagnostic dialogue. However, real-world assurance of patient safety means that
providing individual diagnoses and treatment plans is considered a regulated
activity by licensed professionals. Furthermore, physicians commonly oversee
other team members in such activities, including nurse practitioners (NPs) or
physician assistants/associates (PAs). Inspired by this, we propose a framework
for effective, asynchronous oversight of the Articulate Medical Intelligence
Explorer (AMIE) AI system. We propose guardrailed-AMIE (g-AMIE), a multi-agent
system that performs history taking within guardrails, abstaining from
individualized medical advice. Afterwards, g-AMIE conveys assessments to an
overseeing primary care physician (PCP) in a clinician cockpit interface. The
PCP provides oversight and retains accountability of the clinical decision.
This effectively decouples oversight from intake and can thus happen
asynchronously. In a randomized, blinded virtual Objective Structured Clinical
Examination (OSCE) of text consultations with asynchronous oversight, we
compared g-AMIE to NPs/PAs or a group of PCPs under the same guardrails. Across
60 scenarios, g-AMIE outperformed both groups in performing high-quality
intake, summarizing cases, and proposing diagnoses and management plans for the
overseeing PCP to review. This resulted in higher quality composite decisions.
PCP oversight of g-AMIE was also more time-efficient than standalone PCP
consultations in prior work. While our study does not replicate existing
clinical practices and likely underestimates clinicians' capabilities, our
results demonstrate the promise of asynchronous oversight as a feasible
paradigm for diagnostic AI systems to operate under expert human oversight for
enhancing real-world care.

</details>


### [519] [LAPO: Internalizing Reasoning Efficiency via Length-Adaptive Policy Optimization](https://arxiv.org/abs/2507.15758)
*Xingyu Wu,Yuchen Yan,Shangke Lyu,Linjuan Wu,Yiwen Qiu,Yongliang Shen,Weiming Lu,Jian Shao,Jun Xiao,Yueting Zhuang*

Main category: cs.AI

TL;DR: LAPO is a new framework that trains reasoning models to control their own reasoning length using reinforcement learning, reducing token use by up to 40.9% and improving accuracy by 2.3% by making them better at judging problem complexity.


<details>
  <summary>Details</summary>
Motivation: To address the issue of excessive token generation in large reasoning models due to extended chain-of-thought sequences, even for simple problems, by transforming reasoning length control from an external constraint into an intrinsic model capability.

Method: LAPO is a novel framework that enables models to internalize an understanding of appropriate reasoning depth through a two-stage reinforcement learning process. The first stage involves learning natural reasoning patterns by discovering the statistical distribution of successful solution lengths. The second stage uses these patterns as meta-cognitive guidance, embedding them directly within the model's reasoning context for inference-time flexibility.

Result: Experiments on mathematical reasoning benchmarks show that LAPO reduces token usage by up to 40.9% and improves accuracy by 2.3%. Models trained with LAPO demonstrate emergent abilities to allocate computational resources based on problem complexity.

Conclusion: LAPO enables models to develop emergent abilities to allocate computational resources based on problem complexity, achieving efficient reasoning without sacrificing quality, reducing token usage by up to 40.9% while improving accuracy by 2.3%.

Abstract: Large reasoning models have achieved remarkable performance through extended
chain-of-thought sequences, yet this computational freedom leads to excessive
token generation even for simple problems. We present Length-Adaptive Policy
Optimization (LAPO), a novel framework that transforms reasoning length control
from an external constraint into an intrinsic model capability. Unlike existing
approaches that impose rigid limits or rely on post-hoc interventions, LAPO
enables models to internalize an understanding of appropriate reasoning depth
through a two-stage reinforcement learning process. In the first stage, models
learn natural reasoning patterns by discovering the statistical distribution of
successful solution lengths. The second stage leverages these patterns as
meta-cognitive guidance, embedding them directly within the model's reasoning
context to ensure inference-time flexibility. Experiments on mathematical
reasoning benchmarks demonstrate that LAPO reduces token usage by up to 40.9\%
while improving accuracy by 2.3\%. Our analysis reveals that models trained
with LAPO develop emergent abilities to allocate computational resources based
on problem complexity, achieving efficient reasoning without sacrificing
quality.

</details>


### [520] [GasAgent: A Multi-Agent Framework for Automated Gas Optimization in Smart Contracts](https://arxiv.org/abs/2507.15761)
*Jingyi Zheng,Zifan Peng,Yule Liu,Junfeng Wang,Yifan Liao,Wenhan Dong,Xinlei He*

Main category: cs.AI

TL;DR: GasAgent是一个创新的多智能体系统，用于智能合约的Gas优化。它通过四个协作智能体（探寻者、创新者、执行者、管理者）实现Gas浪费模式的自动化发现、验证和应用，并能与现有模式兼容。实验证明GasAgent能显著节省Gas，并能优化LLM生成的智能合约，是LLM辅助开发的一个有效优化层。


<details>
  <summary>Details</summary>
Motivation: 现有的智能合约Gas优化方法主要依赖手动发现，效率低下、维护成本高且难以扩展。虽然近期研究尝试使用大语言模型（LLMs）来发现新的Gas浪费模式，但仍存在与现有模式兼容性不足、产生冗余模式以及需要手动验证/重写等问题。为了解决这些不足，GasAgent被提出。

Method: GasAgent采用了一个包含“探寻者”、“创新者”、“执行者”和“管理者”四个专门智能体的多智能体系统，通过闭环协作来识别、验证和应用节省Gas的改进措施。

Result: 在100个经过验证的真实世界合约上进行实验，GasAgent成功优化了82个合约，实现了平均9.97%的部署Gas节省。对500个由五种代表性LLM生成的合约进行的评估显示，GasAgent优化了其中79.8%的合约，部署Gas节省量在4.79%到13.93%之间。评估还通过消融研究确认了其与现有工具的兼容性以及各模块的有效性。

Conclusion: GasAgent作为一个首个智能合约Gas优化多智能体系统，成功实现了与现有模式的兼容性以及新模式的自动化发现与验证，能够进行端到端的优化。实验结果表明，GasAgent在100个真实世界合约的优化中，成功优化了82个合约，平均部署Gas节省了9.97%。此外，在对500个由不同LLM生成的合约进行的评估中，GasAgent优化了79.8%的合约，Gas节省量在4.79%到13.93%之间，证明了其作为LLM辅助智能合约开发优化层的广泛可用性。

Abstract: Smart contracts are trustworthy, immutable, and automatically executed
programs on the blockchain. Their execution requires the Gas mechanism to
ensure efficiency and fairness. However, due to non-optimal coding practices,
many contracts contain Gas waste patterns that need to be optimized. Existing
solutions mostly rely on manual discovery, which is inefficient, costly to
maintain, and difficult to scale. Recent research uses large language models
(LLMs) to explore new Gas waste patterns. However, it struggles to remain
compatible with existing patterns, often produces redundant patterns, and
requires manual validation/rewriting. To address this gap, we present GasAgent,
the first multi-agent system for smart contract Gas optimization that combines
compatibility with existing patterns and automated discovery/validation of new
patterns, enabling end-to-end optimization. GasAgent consists of four
specialized agents, Seeker, Innovator, Executor, and Manager, that collaborate
in a closed loop to identify, validate, and apply Gas-saving improvements.
Experiments on 100 verified real-world contracts demonstrate that GasAgent
successfully optimizes 82 contracts, achieving an average deployment Gas
savings of 9.97%. In addition, our evaluation confirms its compatibility with
existing tools and validates the effectiveness of each module through ablation
studies. To assess broader usability, we further evaluate 500 contracts
generated by five representative LLMs across 10 categories and find that
GasAgent optimizes 79.8% of them, with deployment Gas savings ranging from
4.79% to 13.93%, showing its usability as the optimization layer for
LLM-assisted smart contract development.

</details>


### [521] [A Framework for Analyzing Abnormal Emergence in Service Ecosystems Through LLM-based Agent Intention Mining](https://arxiv.org/abs/2507.15770)
*Yifan Shen,Zihan Zhao,Xiao Xue,Yuwei Guo,Qun Ma,Deyu Zhou,Ming Zhang*

Main category: cs.AI

TL;DR: EAMI是一个用于动态和可解释涌现分析的框架，通过双视角思维轨迹、k-means聚类和意图时间涌现图来分析智能体意图，以解决服务生态系统中异常涌现分析的挑战。


<details>
  <summary>Details</summary>
Motivation: 现有的异常涌现分析方法难以处理智能体之间复杂的交互作用，因为传统因果方法侧重于个体轨迹。大型语言模型通过思维链（CoT）推理为基于智能体的建模（ABM）提供了新的可能性，以揭示智能体的意图，但现有方法仍局限于微观和静态分析。

Method: EAMI框架采用双视角思维轨迹机制，通过检查代理和分析代理在有界和完美理性下提取代理意图，并利用k-means聚类识别群体意图的相变点，最后通过意图时间涌现图进行动态分析。

Result: 实验在复杂的线上到线下（O2O）服务系统和斯坦福AI Town实验中验证了EAMI的有效性、泛化性和效率，并通过消融研究确认了其效果。

Conclusion: EAMI提供了一种新颖的范式，用于服务生态系统中异常涌现和因果分析。

Abstract: With the rise of service computing, cloud computing, and IoT, service
ecosystems are becoming increasingly complex. The intricate interactions among
intelligent agents make abnormal emergence analysis challenging, as traditional
causal methods focus on individual trajectories. Large language models offer
new possibilities for Agent-Based Modeling (ABM) through Chain-of-Thought (CoT)
reasoning to reveal agent intentions. However, existing approaches remain
limited to microscopic and static analysis. This paper introduces a framework:
Emergence Analysis based on Multi-Agent Intention (EAMI), which enables dynamic
and interpretable emergence analysis. EAMI first employs a dual-perspective
thought track mechanism, where an Inspector Agent and an Analysis Agent extract
agent intentions under bounded and perfect rationality. Then, k-means
clustering identifies phase transition points in group intentions, followed by
a Intention Temporal Emergence diagram for dynamic analysis. The experiments
validate EAMI in complex online-to-offline (O2O) service system and the
Stanford AI Town experiment, with ablation studies confirming its
effectiveness, generalizability, and efficiency. This framework provides a
novel paradigm for abnormal emergence and causal analysis in service
ecosystems. The code is available at
https://anonymous.4open.science/r/EAMI-B085.

</details>


### [522] [Challenges of Trustworthy Federated Learning: What's Done, Current Trends and Remaining Work](https://arxiv.org/abs/2507.15796)
*Nuria Rodríguez-Barroso,Mario García-Márquez,M. Victoria Luzón,Francisco Herrera*

Main category: cs.AI

TL;DR: This paper analyzes how to make Federated Learning trustworthy by looking at TAI requirements and identifying challenges and solutions.


<details>
  <summary>Details</summary>
Motivation: The development of Trustworthy Artificial Intelligence (TAI) is critical for deploying AI systems in sensitive domains. Federated Learning (FL) addresses privacy concerns, but aligning FL with TAI requirements presents challenges due to its distributed nature.

Method: The paper adopts the requirements of TAI as a guiding structure to systematically analyze the challenges of adapting FL to TAI. It classifies and examines key obstacles, providing a detailed exploration of what has been done, trends, and remaining work within each identified challenge.

Result: The paper provides a classification and detailed exploration of the key obstacles to aligning FL with TAI, including current work, trends, and future research directions for each challenge.

Conclusion: The paper systematically analyzes the challenges of adapting Federated Learning (FL) to Trustworthy Artificial Intelligence (TAI) by adopting TAI requirements as a guiding structure. It classifies and examines key obstacles, exploring current work, trends, and remaining challenges.

Abstract: In recent years, the development of Trustworthy Artificial Intelligence (TAI)
has emerged as a critical objective in the deployment of AI systems across
sensitive and high-risk domains. TAI frameworks articulate a comprehensive set
of ethical, legal, and technical requirements to ensure that AI technologies
are aligned with human values, rights, and societal expectations. Among the
various AI paradigms, Federated Learning (FL) presents a promising solution to
pressing privacy concerns. However, aligning FL with the rest of the
requirements of TAI presents a series of challenges, most of which arise from
its inherently distributed nature. In this work, we adopt the requirements TAI
as a guiding structure to systematically analyze the challenges of adapting FL
to TAI. Specifically, we classify and examine the key obstacles to aligning FL
with TAI, providing a detailed exploration of what has been done, the trends,
and the remaining work within each of the identified challenges.

</details>


### [523] [Identifying Conditional Causal Effects in MPDAGs](https://arxiv.org/abs/2507.15842)
*Sara LaPlante,Emilija Perković*

Main category: cs.AI

TL;DR: This paper provides methods to identify conditional causal effects using MPDAGs, including a new formula, a generalized do calculus, and a complete algorithm.


<details>
  <summary>Details</summary>
Motivation: The paper addresses the problem of identifying a conditional causal effect in the presence of a known graph structure represented by a maximally oriented partially directed acyclic graph (MPDAG), where all variables in the causal model are observed.

Method: The paper presents an identification formula for a conditional causal effect when the conditioning set is unaffected by treatment, generalizes the do calculus to the MPDAG setting, and introduces a complete algorithm for identifying these conditional effects.

Result: The results include an identification formula for a specific conditioning set scenario, a generalized do calculus for MPDAGs, and a complete algorithm for effect identification.

Conclusion: We provide three results that address identification in this setting: an identification formula when the conditioning set is unaffected by treatment, a generalization of the well-known do calculus to the MPDAG setting, and an algorithm that is complete for identifying these conditional effects.

Abstract: We consider identifying a conditional causal effect when a graph is known up
to a maximally oriented partially directed acyclic graph (MPDAG). An MPDAG
represents an equivalence class of graphs that is restricted by background
knowledge and where all variables in the causal model are observed. We provide
three results that address identification in this setting: an identification
formula when the conditioning set is unaffected by treatment, a generalization
of the well-known do calculus to the MPDAG setting, and an algorithm that is
complete for identifying these conditional effects.

</details>


### [524] [Hierarchical Budget Policy Optimization for Adaptive Reasoning](https://arxiv.org/abs/2507.15844)
*Shangke Lyu,Linjuan Wu,Yuchen Yan,Xingyu Wu,Hao Li,Yongliang Shen,Peisheng Jiang,Weiming Lu,Jun Xiao,Yueting Zhuang*

Main category: cs.AI

TL;DR: HBPO 通过分层预算和差异化奖励，在提高推理模型准确率的同时，显著降低了计算成本。


<details>
  <summary>Details</summary>
Motivation: 大型推理模型在推理深度上存在计算效率低下问题，它们通常采用统一的推理策略，忽略了问题本身的复杂度。HBPO 旨在解决这一核心挑战，使模型能够学习适应问题复杂度的推理深度，同时避免在以效率为导向的训练中出现探索空间坍塌。

Method: HBPO（分层预算策略优化）是一种强化学习框架，通过分层预算探索将采样分到具有不同令牌预算的子组中，并结合差异化奖励机制，为模型提供与问题复杂度相符的激励，从而学习自适应的推理深度。

Result: HBPO 在四个推理基准测试中，平均令牌使用量减少了高达 60.6%，准确率提高了 3.14%。模型能够根据问题复杂度自动调整推理深度，展现出涌现的自适应行为。

Conclusion: HBPO 框架通过分层预算探索和差异化奖励机制，使模型能够学习特定于问题的推理深度，从而在降低计算效率的同时保持能力。实验证明，HBPO 可将平均令牌使用量减少多达 60.6%，同时在四个推理基准测试中将准确率提高 3.14%。该方法实现了推理效率和能力的同步优化，打破了两者必须冲突的固有观念。

Abstract: Large reasoning models achieve remarkable performance through extensive
chain-of-thought generation, yet exhibit significant computational inefficiency
by applying uniform reasoning strategies regardless of problem complexity. We
present Hierarchical Budget Policy Optimization (HBPO), a reinforcement
learning framework that enables models to learn problem-specific reasoning
depths without sacrificing capability. HBPO addresses the fundamental challenge
of exploration space collapse in efficiency-oriented training, where penalties
on long output length systematically bias models away from necessary long
reasoning paths. Through hierarchical budget exploration, our approach
partitions rollout samples into multiple subgroups with distinct token budgets,
aiming to enable efficient resource allocation while preventing degradation of
capability. We introduce differentiated reward mechanisms that create
budget-aware incentives aligned with the complexity of the problem, allowing
models to discover natural correspondences between task requirements and
computational effort. Extensive experiments demonstrate that HBPO reduces
average token usage by up to 60.6% while improving accuracy by 3.14% across
four reasoning benchmarks. Unlike existing methods that impose external
constraints or rely on discrete mode selection, HBPO exhibits emergent adaptive
behavior where models automatically adjust reasoning depth based on problem
complexity. Our results suggest that reasoning efficiency and capability are
not inherently conflicting, and can be simultaneously optimized through
appropriately structured hierarchical training that preserves exploration
diversity.

</details>


### [525] [The Other Mind: How Language Models Exhibit Human Temporal Cognition](https://arxiv.org/abs/2507.15851)
*Lingyu Li,Yang Yao,Yixu Wang,Chubo Li,Yan Teng,Yingchun Wang*

Main category: cs.AI

TL;DR: 大型语言模型在时间认知上表现出类人特征，能建立时间参考点并进行对数压缩。研究通过神经、表征和信息层面分析，发现模型内部存在对数编码的时间机制，且训练数据包含非线性时间结构。这表明LLM可能形成独特的认知框架，为AI对齐提供了新思路。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLM）在发展过程中，展现出一些在训练数据中未被明确指定，但与人类认知模式相似的特征。本研究旨在探究LLM在时间认知方面的这种现象，特别是它们如何自发地建立时间感和处理时间信息。

Method: 本研究利用相似性判断任务，分析了大型语言模型在时间认知方面的表现。通过多层次的分析，包括神经元激活、表征结构和信息内容，探究模型行为背后的机制。具体方法包括：1. 识别时间优先神经元，并分析其激活模式和编码方式。2. 探究年表征在模型不同层级的演化过程。3. 利用预训练嵌入模型分析训练语料库中的时间结构。

Result: 研究发现，大型语言模型能够自发建立主观时间参考点，并遵循韦伯-费希纳定律，即感知到的时间距离随年份远离参考点而对数压缩。研究进一步揭示，存在一类时间优先神经元，在参考点激活最少，并采用生物系统中发现的对数编码方案。年的表征呈现层级结构，从浅层数值演化到深层抽象时间定向。此外，训练语料库本身包含非线性时间结构，为模型的内部时间认知提供了基础。

Conclusion: 大型语言模型（LLM）在时间认知方面表现出与人类相似的现象，例如建立主观时间参考点并遵循韦伯-费希纳定律。通过对神经、表征和信息层面的分析，发现存在优先激活时间的神经元，它们以对数编码方式实现时间压缩。年的表征呈层级结构，从浅层的数值发展到深层的抽象时间定向。训练语料库本身也包含非线性时间结构，为模型的内部构建提供了基础。文章提出了一种经验主义视角来理解这些发现，认为LLM的认知是其内部表征系统对外部世界的建构，这可能导致出现人类难以预测的“异类认知框架”，并为AI对齐提供了新的方向。

Abstract: As Large Language Models (LLMs) continue to advance, they exhibit certain
cognitive patterns similar to those of humans that are not directly specified
in training data. This study investigates this phenomenon by focusing on
temporal cognition in LLMs. Leveraging the similarity judgment task, we find
that larger models spontaneously establish a subjective temporal reference
point and adhere to the Weber-Fechner law, whereby the perceived distance
logarithmically compresses as years recede from this reference point. To
uncover the mechanisms behind this behavior, we conducted multiple analyses
across neuronal, representational, and informational levels. We first identify
a set of temporal-preferential neurons and find that this group exhibits
minimal activation at the subjective reference point and implements a
logarithmic coding scheme convergently found in biological systems. Probing
representations of years reveals a hierarchical construction process, where
years evolve from basic numerical values in shallow layers to abstract temporal
orientation in deep layers. Finally, using pre-trained embedding models, we
found that the training corpus itself possesses an inherent, non-linear
temporal structure, which provides the raw material for the model's internal
construction. In discussion, we propose an experientialist perspective for
understanding these findings, where the LLMs' cognition is viewed as a
subjective construction of the external world by its internal representational
system. This nuanced perspective implies the potential emergence of alien
cognitive frameworks that humans cannot intuitively predict, pointing toward a
direction for AI alignment that focuses on guiding internal constructions. Our
code is available at https://TheOtherMind.github.io.

</details>


### [526] [Gemini 2.5 Pro Capable of Winning Gold at IMO 2025](https://arxiv.org/abs/2507.15855)
*Yichen Huang,Lin F. Yang*

Main category: cs.AI

TL;DR: LLM在IMO竞赛中表现出色，但仍需优化。


<details>
  <summary>Details</summary>
Motivation: 探索LLM在解决IMO这类顶尖数学竞赛问题上的潜力，并研究如何通过优化模型使用方式来克服其固有的挑战。

Method: 使用Gemini 2.5 Pro模型，结合管道设计和提示工程，针对IMO 2025的竞赛题目进行测试。

Result: Gemini 2.5 Pro成功解决了IMO 2025的6道题目中的5道，展示了在应对高难度数学挑战方面的强大能力，同时也指出了在具体应用中进行优化调优的重要性。

Conclusion: LLM在IMO竞赛中的表现仍有提升空间，但通过精心的模型设计和提示工程，可以显著提高其解决复杂数学问题的能力。

Abstract: The International Mathematical Olympiad (IMO) poses uniquely challenging
problems requiring deep insight, creativity, and formal reasoning. While Large
Language Models (LLMs) perform well on mathematical benchmarks like AIME, they
struggle with Olympiad-level tasks. We use Google's Gemini 2.5 Pro on the newly
released IMO 2025 problems, avoiding data contamination. With pipeline design
and prompt engineering, 5 (out of 6) problems are solved correctly (up to a
caveat discussed below), highlighting the importance of finding the optimal way
of using powerful models.

</details>


<div id='cs.GT'></div>

# cs.GT [[Back]](#toc)

### [527] [A Formal Model of the Economic Impacts of AI Openness Regulation](https://arxiv.org/abs/2507.14193)
*Tori Qiu,Benjamin Laufer,Jon Kleinberg,Hoda Heidari*

Main category: cs.GT

TL;DR: 监管框架鼓励AI模型的开放性，但“开源”定义模糊。本文通过对通用模型开发者和微调者之间互动的建模，分析了不同开放性法规对开发者经济激励的影响，并提出了监管处罚和开源阈值的建议。


<details>
  <summary>Details</summary>
Motivation: 在AI监管框架（如欧盟AI法案）鼓励通用人工智能模型开放性，并为“开源”模型提供法律豁免的同时，该领域内关于开源基础模型的定义仍然模糊不清。

Method: 通过对监管者选择开源定义进行建模，来评估哪些AI开放性标准能够为开发者建立合理的经济激励。我们推导了在不同开放性法规下，上游模型发布决策和下游微调的努力程度的市场均衡，并提出了一系列有效的监管处罚和开源阈值。

Result: 我们发现，模型的基线性能决定了增加监管处罚或开源阈值会在何种程度上显著改变通用模型开发者的发布策略。模型刻画了市场均衡——特别是上游模型发布决策和下游微调的努力——在各种开放性法规下，并提出了一系列有效的监管处罚和开源阈值。

Conclusion: 该模型为AI治理在开放性方面的决策提供了理论基础，并能对实际的开源政策进行评估和完善。

Abstract: Regulatory frameworks, such as the EU AI Act, encourage openness of
general-purpose AI models by offering legal exemptions for "open-source"
models. Despite this legislative attention on openness, the definition of
open-source foundation models remains ambiguous. This paper models the
strategic interactions among the creator of a general-purpose model (the
generalist) and the entity that fine-tunes the general-purpose model to a
specialized domain or task (the specialist), in response to regulatory
requirements on model openness. We present a stylized model of the regulator's
choice of an open-source definition to evaluate which AI openness standards
will establish appropriate economic incentives for developers. Our results
characterize market equilibria -- specifically, upstream model release
decisions and downstream fine-tuning efforts -- under various openness
regulations and present a range of effective regulatory penalties and
open-source thresholds. Overall, we find the model's baseline performance
determines when increasing the regulatory penalty vs. the open-source threshold
will significantly alter the generalist's release strategy. Our model provides
a theoretical foundation for AI governance decisions around openness and
enables evaluation and refinement of practical open-source policies.

</details>


### [528] [Strategyproofness and Monotone Allocation of Auction in Social Networks](https://arxiv.org/abs/2507.14472)
*Yuhang Guo,Dong Hao,Bin Li,Mingyu Xiao,Bakh Khoussainov*

Main category: cs.GT

TL;DR: 网络拍卖的策略证明比传统拍卖更复杂。本研究提出了两种新的分配规则（ID-MON 和 IP-MON），并为它们提供了策略证明的支付规则，解决了组合网络拍卖中的一个关键问题。


<details>
  <summary>Details</summary>
Motivation: 在网络拍卖中，除了真实报告估值外，还需要投标人邀请邻居，这与传统拍卖不同。由于缺乏明确的分配原则，网络拍卖的策略证明变得复杂，尤其是在多单位网络拍卖中。

Method: 提出了两种新的单调分配规则（ID-MON 和 IP-MON），并为这些规则的策略证明支付规则的存在性及其充分条件进行了特征化，同时表明了收益最大化支付规则的存在性及其计算可行性。

Result: 识别了 ID-MON 和 IP-MON 两种单调分配规则，它们包含了所有现有的网络拍卖分配规则。为这些规则找到了策略证明支付规则，并证明了收益最大化支付规则的存在性和计算可行性。

Conclusion: 该研究为组合网络拍卖中的单目标竞标者问题提供了解决方案，解决了该领域的一个主要障碍。

Abstract: Strategyproofness in network auctions requires that bidders not only report
their valuations truthfully, but also do their best to invite neighbours from
the social network. In contrast to canonical auctions, where the value-monotone
allocation in Myerson's Lemma is a cornerstone, a general principle of
allocation rules for strategyproof network auctions is still missing. We show
that, due to the absence of such a principle, even extensions to multi-unit
network auctions with single-unit demand present unexpected difficulties, and
all pioneering researches fail to be strategyproof. For the first time in this
field, we identify two categories of monotone allocation rules on networks:
Invitation-Depressed Monotonicity (ID-MON) and Invitation-Promoted Monotonicity
(IP-MON). They encompass all existing allocation rules of network auctions as
specific instances. For any given ID-MON or IP-MON allocation rule, we
characterize the existence and sufficient conditions for the strategyproof
payment rules, and show that among all such payment rules, the
revenue-maximizing one exists and is computationally feasible. With these
results, the obstacle of combinatorial network auction with single-minded
bidders is now resolved.

</details>


### [529] [Probing EFX via PMMS: (Non-)Existence Results in Discrete Fair Division](https://arxiv.org/abs/2507.14957)
*Jarosław Byrka,Franciszek Malinka,Tomasz Ponitka*

Main category: cs.GT

TL;DR: 本研究解决了公平分配不可分割物品的EFX和PMMS问题，通过构造实例分离了EFX和PMMS，并证明了在几种特定估值（个人双值、二值MMS可行、成对需求）下EFX和PMMS分配的存在性，同时提供了多项式时间算法。


<details>
  <summary>Details</summary>
Motivation: 本研究旨在解决公平分配不可分割物品的核心开放问题，特别是EFX（Equitable Fractional Allocation）问题及其更强的变体PMMS（Proportional, Maximin Share）问题。通过研究这些问题，以期为不可分割物品的公平分配提供新的理论见解和实用的算法解决方案。

Method: 本研究通过构造性证明和算法设计来解决公平分配问题。具体方法包括：1. 构造三方实例，证明PMMS与EFX的分离性。2. 证明EFX分配在个人双值估值情况下的存在性。3. 证明在特定条件下（$a_i$可被$b_i$整除）PMMS分配的存在性。4. 证明在二值MMS可行估值（包括非单调估值）情况下PMMS分配的存在性。5. 证明在成对需求估值情况下PMMS分配的存在性。为所有存在性结果提供了多项式时间算法。

Result: 1. 构造了一个三方实例（两种单调估值，一种加性估值），证明了PMMS分配不存在，从而在EFX和PMMS之间建立了正式的分离。 2. 证明了EFX分配在个人双值估值（$v_i (\{g\}) \in \{a_i, b_i\}$）情况下存在。 3. 证明了当$a_i$可被$b_i$整除时，PMMS分配在个人双值估值情况下存在。 4. 证明了PMMS分配在二值MMS可行估值（$v_i(S) \in \{0, 1\}$）情况下存在，且不要求估值单调，适用于公平分配事务和混合管理。 5. 证明了PMMS分配在成对需求估值（每个代理最多从两个物品中获得价值）情况下存在。 6. 为所有存在性结果提供了构造性的多项式时间算法。

Conclusion: 本研究在公平分配不可分割物品的领域取得了新进展，特别是在EFX和PMMS问题上。我们构造了一个三方实例，其中包含两种单调估值和一个加性估值，证明了不存在PMMS分配，从而在EFX和PMMS之间建立了正式的分离。此外，我们证明了EFX分配在个人双值估值情况下存在，并且当$a_i$可被$b_i$整除时，PMMS分配也存在。我们还证明了在二值MMS可行估值（包括非单调估值）情况下PMMS分配存在，这适用于公平分配事务和混合管理。最后，我们研究了扩展的单需求估值，即成对需求估值，并证明了在这种情况下PMMS分配存在。所有证明都具有建设性，并提供了相应的多项式时间算法。

Abstract: We study the fair division of indivisible items and provide new insights into
the EFX problem, which is widely regarded as the central open question in fair
division, and the PMMS problem, a strictly stronger variant of EFX. Our first
result constructs a three-agent instance with two monotone valuations and one
additive valuation in which no PMMS allocation exists. Since EFX allocations
are known to exist under these assumptions, this establishes a formal
separation between EFX and PMMS.
  We prove existence of fair allocations for three important special cases. We
show that EFX allocations exist for personalized bivalued valuations, where for
each agent $i$ there exist values $a_i > b_i$ such that agent $i$ assigns value
$v_i(\{g\}) \in \{a_i, b_i\}$ to each good $g$. We establish an analogous
existence result for PMMS allocations when $a_i$ is divisible by $b_i$. We also
prove that PMMS allocations exist for binary-valued MMS-feasible valuations,
where each bundle $S$ has value $v_i(S) \in \{0, 1\}$. Notably, this result
holds even without assuming monotonicity of valuations and thus applies to the
fair division of chores and mixed manna. Finally, we study a class of
valuations called pair-demand valuations, which extend the well-studied
unit-demand valuations to the case where each agent derives value from at most
two items, and we show that PMMS allocations exist in this setting. Our proofs
are constructive, and we provide polynomial-time algorithms for all three
existence results.

</details>


### [530] [Strategically Robust Game Theory via Optimal Transport](https://arxiv.org/abs/2507.15325)
*Nicolas Lanzetti,Sylvain Fricker,Saverio Bolognani,Florian Dörfler,Dario Paccagnan*

Main category: cs.GT

TL;DR: 本文提出了一种名为“策略稳健均衡”的新均衡概念，用于解决博弈论中代理在面对不确定行为时的决策问题。该方法通过考虑最坏情况下的行为，并在计算成本与纳什均衡相当的情况下，能有效应对不确定性并可能带来更高的收益。


<details>
  <summary>Details</summary>
Motivation: 在许多博弈论场景中，代理需要在面对其他参与者不确定的行为时做出决策。这种不确定性可能源于信息不完整、计算能力有限或有界理性等多种因素。本文旨在提出一种能够应对这些不确定性的方法。

Method: 本文提出了一种新的均衡概念，称为策略稳健均衡。该方法通过将模糊集（ambiguity set）以可调大小为中心围绕着渐进行为进行定义，使得每个代理在面对最坏情况行为时做出决策。该方法利用最优传输（optimal transport）进行操作化。

Result: 策略稳健均衡在存在性和插值性方面表现优于纳什均衡，并且计算成本相当。实验表明，该方法能够保护代理免受对手行为不确定性的影响，并常常带来更高的均衡收益，这种现象被称为“稳健性驱动的协调”。

Conclusion: 所提出的策略稳健均衡（strategically robust equilibria）在纳什均衡的假设条件下保证存在，能够有效地在纳什均衡和安全策略之间进行插值，并且计算成本与纳什均衡相当。此外，实验结果表明，策略稳健性不仅能有效应对对手行为中的不确定性，还能通过“稳健性驱动的协调”效应带来更高的均衡收益。

Abstract: In many game-theoretic settings, agents are challenged with taking decisions
against the uncertain behavior exhibited by others. Often, this uncertainty
arises from multiple sources, e.g., incomplete information, limited
computation, bounded rationality. While it may be possible to guide the agents'
decisions by modeling each source, their joint presence makes this task
particularly daunting. Toward this goal, it is natural for agents to seek
protection against deviations around the emergent behavior itself, which is
ultimately impacted by all the above sources of uncertainty. To do so, we
propose that each agent takes decisions in face of the worst-case behavior
contained in an ambiguity set of tunable size, centered at the emergent
behavior so implicitly defined. This gives rise to a novel equilibrium notion,
which we call strategically robust equilibrium. Building on its definition, we
show that, when judiciously operationalized via optimal transport,
strategically robust equilibria (i) are guaranteed to exist under the same
assumptions required for Nash equilibria; (ii) interpolate between Nash and
security strategies; (iii) come at no additional computational cost compared to
Nash equilibria. Through a variety of experiments, including bi-matrix games,
congestion games, and Cournot competition, we show that strategic robustness
protects against uncertainty in the opponents' behavior and, surprisingly,
often results in higher equilibrium payoffs - an effect we refer to as
coordination via robustification.

</details>


### [531] [The Root of Revenue Continuity](https://arxiv.org/abs/2507.15735)
*Sergiu Hart,Noam Nisan*

Main category: cs.GT

TL;DR: 该论文提出了一个关于收入和Wasserstein距离的数学定理，为机制设计中的鲁棒性提供了新的见解。


<details>
  <summary>Details</summary>
Motivation: 在销售一种或多种商品的设置中，买方的估价分布的微小变化可能只会引起可提取收入的微小变化。

Method: 对X的最佳机制进行简单的显式修改，即“统一折扣”，保证对于Wasserstein距离接近X的任何Y几乎都是最优的。

Result: sqrt(Rev(X))-sqrt(Rev(Y)) <= sqrt(W(X,Y))，并且对于X的任何最优机制的简单显式修改，即“统一折扣”，保证对于Wasserstein距离接近X的任何Y几乎都是最优的。

Conclusion: 买方的估价分布发生微小变化，可能只会引起可提取收入的微小变化，并且对于X和Y之间的Wasserstein（或“土方”）距离，我们证明了sqrt(Rev(X))-sqrt(Rev(Y)) <= sqrt(W(X,Y))。

Abstract: In the setup of selling one or more goods, various papers have shown, in
various forms and for various purposes, that a small change in the distribution
of a buyer's valuations may cause only a small change in the possible revenue
that can be extracted. We prove a simple, clean, convenient, and general
statement to this effect: let X and Y be random valuations on k additive goods,
and let W(X,Y) be the Wasserstein (or "earth mover's") distance between them;
then sqrt(Rev(X))-sqrt(Rev(Y)) <= sqrt(W(X,Y)). This further implies that a
simple explicit modification of any optimal mechanism for X, namely, "uniform
discounting", is guaranteed to be almost optimal for any Y that is close to X
in the Wasserstein distance.

</details>


### [532] [General Matching Games](https://arxiv.org/abs/2507.15737)
*Felipe Garrido-Lucero,Rida Laraki*

Main category: cs.GT

TL;DR: 将匹配博弈模型推广到一对多和室友模型，并找到稳定可计算的匹配结果。


<details>
  <summary>Details</summary>
Motivation: 该研究旨在将 Garrido-Lucero 和 Laraki 提出的匹配博弈模型推广到更广泛的市场模型，例如一对多匹配市场和室友模型，并探索在这些模型中存在稳定且可重新协商匹配结果的条件和计算方法。

Method: 该研究在匹配博弈模型的基础上，提出了包含一对多匹配市场和室友模型的更一般化框架，并给出了保证核心稳定和可重新协商匹配结果存在性的条件，同时说明了如何通过算法有效计算这些结果。

Result: 该研究为包含一对多匹配市场和室友模型在内的一般化匹配博弈模型提供了理论支持和计算方法，证明了在特定框架下，核心稳定且可重新协商的匹配结果是存在的，并且可以被有效计算。

Conclusion: 该研究将匹配博弈模型扩展到了一对多匹配市场和室友模型等更广泛的场景，并提出了两种框架，可以在其中存在核心稳定且可重新协商的匹配结果，并能进行有效计算。

Abstract: Matching games is a one-to-one two sided market model introduced by
Garrido-Lucero and Laraki, in which coupled agents' utilities are endogenously
determined as the outcome of a strategic game. They refine the classical
pairwise stability by requiring robustness to renegotiation and provide general
conditions under which pairwise stable and renegotiation-proof outcomes exist
as the limit of a deferred acceptance with competitions algorithm together with
a renegotiation process. In this article, we extend their model to a general
setting encompassing most of one-to-many matching markets and roommates models
and specify two frameworks under which core stable and renegotiation-proof
outcomes exist and can be efficiently computed.

</details>


<div id='cs.AR'></div>

# cs.AR [[Back]](#toc)

### [533] [SpeedLLM: An FPGA Co-design of Large Language Model Inference Accelerator](https://arxiv.org/abs/2507.14139)
*Peipei Wang,Wu Guan,Liping Liang,Zhijun Wang,Hanqing Luo,Zhibin Zhang*

Main category: cs.AR

TL;DR: SpeedLLM 是一个在 Xilinx Alevo U280 平台上针对 Tinyllama 优化的神经网络加速器，通过多种创新技术显著提升了边缘计算性能和能效。


<details>
  <summary>Details</summary>
Motivation: 为了提升边缘计算性能，本研究介绍了 SpeedLLM，一个为 Tinyllama 框架优化的神经网络加速器。

Method: SpeedLLM 采用数据流并行、内存复用和 Llama2 算子融合等技术，并设计了数据管道架构来优化读-计算-写周期，同时通过内存策略最小化 FPGA 资源需求。

Result: SpeedLLM 的结果显示，与传统的 Tinyllama 实现相比，其性能提升了 4.8 倍，能耗降低了 1.18 倍，为边缘设备带来了显著的改进。

Conclusion: SpeedLLM 在 Xilinx Alevo U280 平台上，通过数据流并行、内存复用和 Llama2 算子融合等技术，显著提升了 Tinyllama 框架在边缘计算中的性能，实现了高达 4.8 倍的性能提升和 1.18 倍的能耗降低。

Abstract: This paper introduces SpeedLLM, a neural network accelerator designed on the
Xilinx Alevo U280 platform and optimized for the Tinyllama framework to enhance
edge computing performance. Key innovations include data stream parallelism, a
memory reuse strategy, and Llama2 operator fusion, which collectively reduce
latency and energy consumption. SpeedLLM's data pipeline architecture optimizes
the read-compute-write cycle, while the memory strategy minimizes FPGA resource
demands. The operator fusion boosts computational density and throughput.
Results show SpeedLLM outperforms traditional Tinyllama implementations,
achieving up to 4.8* faster performance and 1.18* lower energy consumption,
offering improvements in edge devices.

</details>


### [534] [Efficient LLM Inference: Bandwidth, Compute, Synchronization, and Capacity are all you need](https://arxiv.org/abs/2507.14397)
*Michael Davies,Neal Crago,Karthikeyan Sankaralingam,Christos Kozyrakis*

Main category: cs.AR

TL;DR: 本研究对LLM推理的性能瓶颈进行了分析，发现DRAM在能效上具有优势，并指出了提高吞吐量和扩展性的关键因素。


<details>
  <summary>Details</summary>
Motivation: 关注transformer-based LLM推理的基本性能瓶颈，这些瓶颈由分布式推理系统中的内存带宽、内存容量和同步开销决定。

Method: 提出一个硬件无关的性能模型，用于分析transformer-based LLM推理中的内存带宽、内存容量和同步开销等基本性能瓶颈，该模型涵盖了从HBM3到HBM4及3D堆叠DRAM等多种内存技术，以及SRAM和跨越不同规模的分布式系统。

Result: 研究发现，服务LLM实例需要每台服务器数百GB的内存；高内存带宽对高每用户吞吐量至关重要；同步延迟需要接近1us，否则会使内存带宽失效；DRAM设计在系统级效率（按每成本或每瓦特吞吐量衡量）方面具有基本优势；硬件设计可以轻松达到每秒2000多个用户令牌，但要达到每秒10,000多个令牌，则需要更小的模型、更短的上下文或其他的算法进展。

Conclusion: 该研究为LLM推理提供了有价值的性能极限见解，强调了未来硬件进步的潜在好处，并指导了LLM部署策略的优化。

Abstract: This paper presents a limit study of transformer-based large language model
(LLM) inference, focusing on the fundamental performance bottlenecks imposed by
memory bandwidth, memory capacity, and synchronization overhead in distributed
inference systems. We develop a hardware-agnostic performance model that
abstracts away implementation details, enabling the analysis of a wide range of
current and near-future hardware technologies. Our analysis spans from current
HBM3 memory technology used in AI accelerators like GPUs and TPUs to systems
based on advanced HBM4 and advanced 3D-stacked DRAM technology. It also covers
SRAM-based designs and scaling techniques from distributed clusters with
varying numbers of chips to wafer-scale integration. Our key findings for
auto-regressive decoding are: i) serving LLMs requires 100s of GB per server to
serve a model instance; ii) high memory bandwidth is critical for high per-user
throughput; iii) exposed synchronization latencies to achieve collective
communication must be around 1us else they make the memory bandwidth
ineffective; iv) DRAM-based designs have a fundamental advantage in terms of
system-level efficiency as measured in throughput per cost or watt; and v)
hardware designs can easily reach 2000+ user token/sec but getting to 10,000+
tokens/sec will need smaller models, smaller context, or other forms of
algorithmic advances. This study provides valuable insights into the
fundamental performance limits of LLM inference, highlighting the potential
benefits of future hardware advancements and guiding the optimization of LLM
deployment strategies.

</details>


### [535] [Enabling Efficient Hardware Acceleration of Hybrid Vision Transformer (ViT) Networks at the Edge](https://arxiv.org/abs/2507.14651)
*Joren Dumoulin,Pouya Houshmand,Vikram Jain,Marian Verhelst*

Main category: cs.AR

TL;DR: 针对边缘设备部署混合视觉Transformer的挑战，提出了一种结合可配置PE阵列、层内时间循环重排序和层融合的硬件调度优化方案，显著降低了数据传输，实现了高能效比。


<details>
  <summary>Details</summary>
Motivation: 为了在资源受限的边缘设备上高效部署混合视觉Transformer模型，解决现有模型因层类型多样和中间数据张量大而难以进行硬件加速的问题。

Method: 本研究提出了一种跨越硬件调度堆栈的创新方法，包括：1）在最低层级，通过可配置的处理单元（PE）阵列支持所有混合ViT层类型；2）通过层内时间循环重排序，为归一化和Softmax层提供硬件支持，并最小化片上数据传输；3）通过融合倒置瓶颈层（inverted bottleneck layers）进一步优化调度，以大幅减少片外内存传输。

Result: 实现了支持所有混合ViT层类型的可配置PE阵列，并通过时间循环重排序和层融合等技术，最小化了数据传输，最终的加速器在28nm CMOS上实现了1.39 TOPS/W的峰值能效比和25.6 GMACs/s的处理速度。

Conclusion: 该混合视觉Transformer加速器在28nm CMOS上实现，峰值能效比达到1.39 TOPS/W，处理速度为25.6 GMACs/s，有效解决了资源受限边缘设备的部署挑战。

Abstract: Hybrid vision transformers combine the elements of conventional neural
networks (NN) and vision transformers (ViT) to enable lightweight and accurate
detection. However, several challenges remain for their efficient deployment on
resource-constrained edge devices. The hybrid models suffer from a widely
diverse set of NN layer types and large intermediate data tensors, hampering
efficient hardware acceleration. To enable their execution at the edge, this
paper proposes innovations across the hardware-scheduling stack: a.) At the
lowest level, a configurable PE array supports all hybrid ViT layer types; b.)
temporal loop re-ordering within one layer, enabling hardware support for
normalization and softmax layers, minimizing on-chip data transfers; c.)
further scheduling optimization employs layer fusion across inverted bottleneck
layers to drastically reduce off-chip memory transfers. The resulting
accelerator is implemented in 28nm CMOS, achieving a peak energy efficiency of
1.39 TOPS/W at 25.6 GMACs/s.

</details>


### [536] [GCC: A 3DGS Inference Architecture with Gaussian-Wise and Cross-Stage Conditional Processing](https://arxiv.org/abs/2507.15300)
*Minnan Pei,Gang Li,Junwen Si,Zeyu Zhu,Zitao Mo,Peisong Wang,Zhuoran Song,Xiaoyao Liang,Jian Cheng*

Main category: cs.AR

TL;DR: GCC 提出了一种新的 3DGS 推理加速器，通过交叉阶段条件处理和按高斯渲染来解决现有加速器数据流的效率低下问题，并使用基于 alpha 的边界识别方法来降低渲染成本，实现了比 GSCore 更优越的性能和能效。


<details>
  <summary>Details</summary>
Motivation: 现有的 3DGS 加速器采用了分离的预处理-渲染数据流，存在两个主要局限性：1）预处理后的高斯中有相当一部分未用于渲染；2）在不同的切片渲染过程中，相同的高斯会被重复加载，导致显著的计算和数据移动开销。

Method: GCC 通过交叉阶段条件处理和按高斯渲染来解决现有加速器的局限性，前者可以跳过不必要的高斯预处理，后者确保在移动到下一个高斯之前完成给定高斯的所有渲染操作，从而消除重复的高斯加载。此外，还提出了一种基于 alpha 的边界识别方法，用于生成紧凑准确的高斯区域以降低渲染成本。

Result: GCC 加速器在 28nm 工艺技术上实现，实验证明其在性能和能效上均显著优于 GSCore。

Conclusion: GCC 显著优于最先进的 3DGS 推理加速器 GSCore，在性能和能效方面均表现出色。

Abstract: 3D Gaussian Splatting (3DGS) has emerged as a leading neural rendering
technique for high-fidelity view synthesis, prompting the development of
dedicated 3DGS accelerators for mobile applications. Through in-depth analysis,
we identify two major limitations in the conventional decoupled
preprocessing-rendering dataflow adopted by existing accelerators: 1) a
significant portion of preprocessed Gaussians are not used in rendering, and 2)
the same Gaussian gets repeatedly loaded across different tile renderings,
resulting in substantial computational and data movement overhead. To address
these issues, we propose GCC, a novel accelerator designed for fast and
energy-efficient 3DGS inference. At the dataflow level, GCC introduces: 1)
cross-stage conditional processing, which interleaves preprocessing and
rendering to dynamically skip unnecessary Gaussian preprocessing; and 2)
Gaussian-wise rendering, ensuring that all rendering operations for a given
Gaussian are completed before moving to the next, thereby eliminating
duplicated Gaussian loading. We also propose an alpha-based boundary
identification method to derive compact and accurate Gaussian regions, thereby
reducing rendering costs. We implement our GCC accelerator in 28nm technology.
Extensive experiments demonstrate that GCC significantly outperforms the
state-of-the-art 3DGS inference accelerator, GSCore, in both performance and
energy efficiency.

</details>


### [537] [The New LLM Bottleneck: A Systems Perspective on Latent Attention and Mixture-of-Experts](https://arxiv.org/abs/2507.15465)
*Sungmin Yun,Seonyong Park,Hwayong Nam,Younjoo Lee,Gunjun Lee,Kwanhee Kyung,Sangpyo Kim,Nam Sung Kim,Jongmin Kim,Hyungyo Kim,Juhwan Cho,Seungmin Baek,Jung Ho Ahn*

Main category: cs.AR

TL;DR: Recent Transformer architectures like MLA and MoE reduce the need for specialized attention hardware by increasing arithmetic intensity and balancing workloads. Future efforts should focus on creating balanced systems for large-scale models.


<details>
  <summary>Details</summary>
Motivation: The motivation is to re-evaluate the necessity of specialized hardware for Transformer models in light of recent architectural innovations like MLA and MoE, which alter the computational profile of attention mechanisms.

Method: The paper analyzes the architectural shifts in Transformer models, specifically MLA and MoE, by examining their computational characteristics (memory-bound vs. compute-bound, arithmetic intensity) and comparing them to traditional MHA. It argues that these shifts challenge the need for specialized attention hardware.

Result: Recent architectural shifts, including MLA and MoE, have significantly changed the computational landscape of Transformer models. MLA boasts an arithmetic intensity over two orders of magnitude greater than MHA, moving it towards a compute-bound regime. MoE layers, when distributed across accelerators, can have their arithmetic intensity tuned via batching to match dense layers, leading to a more balanced computational profile. Consequently, the need for specialized attention hardware is diminishing.

Conclusion: The architectural shifts in Transformer models, such as MLA and MoE, reduce the need for specialized attention hardware by increasing arithmetic intensity and enabling better load balancing, respectively. The focus for future Transformer development should be on creating balanced systems that cater to the diverse computational demands of large-scale models.

Abstract: Computational workloads composing traditional Transformer models are starkly
bifurcated. Multi-Head Attention (MHA) is memory-bound, with low arithmetic
intensity, while feedforward layers are compute-bound. This dichotomy has long
motivated research into specialized hardware to mitigate the MHA bottleneck.
  This paper argues that recent architectural shifts, namely Multi-head Latent
Attention (MLA) and Mixture-of-Experts (MoE), challenge the premise of
specialized attention hardware. We make two key observations. First, the
arithmetic intensity of MLA is over two orders of magnitude greater than that
of MHA, shifting it close to a compute-bound regime well-suited for modern
accelerators like GPUs. Second, by distributing MoE experts across a pool of
accelerators, their arithmetic intensity can be tuned through batching to match
that of the dense layers, creating a more balanced computational profile.
  These findings reveal a diminishing need for specialized attention hardware.
The central challenge for next-generation Transformers is no longer
accelerating a single memory-bound layer. Instead, the focus must shift to
designing balanced systems with sufficient compute, memory capacity, memory
bandwidth, and high-bandwidth interconnects to manage the diverse demands of
large-scale models.

</details>


### [538] [When Pipelined In-Memory Accelerators Meet Spiking Direct Feedback Alignment: A Co-Design for Neuromorphic Edge Computing](https://arxiv.org/abs/2507.15603)
*Haoxiong Ren,Yangu He,Kwunhang Wong,Rui Bao,Ning Lin,Zhongrui Wang,Dashan Shang*

Main category: cs.AR

TL;DR: 提出PipeSDFA，一种结合SDFA算法和RRAM IMC架构的SNN训练加速器，显著减少训练时间和能耗，同时保持高准确率。


<details>
  <summary>Details</summary>
Motivation: 传统的反向传播算法在训练SNN时计算量大，计算密集，因此提出一种新的软硬件协同设计来解决这个问题。

Method: 提出了一种新颖的软硬件协同设计，包括一种名为Spiking Direct Feedback Alignment (SDFA) 的硬件友好训练算法，并将其实现于基于阻变随机存取存储器 (RRAM) 的内存计算 (IMC) 架构（PipeSDFA）上，以加速SNN训练。SDFA通过消除顺序误差传播来降低SNN训练的计算复杂性。IMC架构采用三级流水线数据流并行化训练过程。

Result: PipeSDFA在五个数据集上实现了1.1X~10.5X的训练时间和1.37X~2.1X的能耗节省，同时与基线相比准确率损失小于2%。

Conclusion: 所提出的PipeSDFA在五个数据集上实现了1.1X~10.5X的训练时间和1.37X~2.1X的能耗节省，同时与基线相比准确率损失小于2%。

Abstract: Spiking Neural Networks (SNNs) are increasingly favored for deployment on
resource-constrained edge devices due to their energy-efficient and
event-driven processing capabilities. However, training SNNs remains
challenging because of the computational intensity of traditional
backpropagation algorithms adapted for spike-based systems. In this paper, we
propose a novel software-hardware co-design that introduces a hardware-friendly
training algorithm, Spiking Direct Feedback Alignment (SDFA) and implement it
on a Resistive Random Access Memory (RRAM)-based In-Memory Computing (IMC)
architecture, referred to as PipeSDFA, to accelerate SNN training.
Software-wise, the computational complexity of SNN training is reduced by the
SDFA through the elimination of sequential error propagation. Hardware-wise, a
three-level pipelined dataflow is designed based on IMC architecture to
parallelize the training process. Experimental results demonstrate that the
PipeSDFA training accelerator incurs less than 2% accuracy loss on five
datasets compared to baselines, while achieving 1.1X~10.5X and 1.37X~2.1X
reductions in training time and energy consumption, respectively compared to
PipeLayer.

</details>


### [539] [VeriRAG: A Retrieval-Augmented Framework for Automated RTL Testability Repair](https://arxiv.org/abs/2507.15664)
*Haomin Qi,Yuyang Du,Lihao Zhang,Soung Chang Liew,Kexin Chen,Yining Du*

Main category: cs.AR

TL;DR: VeriRAG是首个LLM辅助DFT-EDA框架，通过RAG和VeriDFT数据集实现了全自动DFT修复，成功率大幅提升。


<details>
  <summary>Details</summary>
Motivation: 尽管LLM在CAD和EDA领域的自动化调试和验证方面潜力巨大，但DFT领域仍有待探索。本研究旨在利用LLM解决DFT合规性问题。

Method: VeriRAG是一个结合检索增强生成（RAG）的大语言模型（LLM）辅助DFT-EDA框架，能够修复代码以确保DFT合规性。它包括一个基于自动编码器的相似度测量模型，用于精确检索参考RTL设计，以及一个迭代代码修订流程，确保DFT合规性和可综合性。该框架使用了VeriDFT数据集，该数据集包含DFT感知RTL修复的Verilog数据集。

Result: VeriRAG框架实现了全自动DFT修复，成功修复率相比零样本基线提高了7.72倍。

Conclusion: VeriRAG框架实现了全自动DFT修复，与零样本基线相比，成功修复率提高了7.72倍。消融研究也验证了VeriRAG框架各组件的贡献。

Abstract: Large language models (LLMs) have demonstrated immense potential in
computer-aided design (CAD), particularly for automated debugging and
verification within electronic design automation (EDA) tools. However, Design
for Testability (DFT) remains a relatively underexplored area. This paper
presents VeriRAG, the first LLM-assisted DFT-EDA framework. VeriRAG leverages a
Retrieval-Augmented Generation (RAG) approach to enable LLM to revise code to
ensure DFT compliance. VeriRAG integrates (1) an autoencoder-based similarity
measurement model for precise retrieval of reference RTL designs for the LLM,
and (2) an iterative code revision pipeline that allows the LLM to ensure DFT
compliance while maintaining synthesizability. To support VeriRAG, we introduce
VeriDFT, a Verilog-based DFT dataset curated for DFT-aware RTL repairs. VeriRAG
retrieves structurally similar RTL designs from VeriDFT, each paired with a
rigorously validated correction, as references for code repair. With VeriRAG
and VeriDFT, we achieve fully automated DFT correction -- resulting in a
7.72-fold improvement in successful repair rate compared to the zero-shot
baseline (Fig. 5 in Section V). Ablation studies further confirm the
contribution of each component of the VeriRAG framework. We open-source our
data, models, and scripts at https://github.com/yuyangdu01/LLM4DFT.

</details>


<div id='eess.SP'></div>

# eess.SP [[Back]](#toc)

### [540] [Optimizing VO2max Prediction in Gamified Cardiac Assessment: Leveraging Effective Feature Selection and Refined Protocols for Robust Models](https://arxiv.org/abs/2507.14138)
*Vaishnavi C K,Sricharan Vijayarangan,Sri Gayathri G,Danush Adhithya N,Alex Joseph,Preejith SP,Mohanasankar Sivaprakasam*

Main category: eess.SP

TL;DR: 本研究通过改进CPSJT方案和特征提取，利用机器学习模型（特别是随机森林）提高了VO2max测量的准确性，为心肺健康评估提供了一种更易于获取的替代方法。


<details>
  <summary>Details</summary>
Motivation: 现有的VO2max测量方法（如CPET）成本高昂且需要专业人员操作，限制了其在大规模筛查中的应用。早期的CPSJT方法存在误差过大的问题，不适合广泛使用。因此，本研究旨在开发一种更易于获取且更准确的VO2max估算方法。

Method: 本研究采用改进的Cardiopulmonary Spot Jog Test (CPSJT) 方案，并提取了性别、身体质量指数、有氧运动时长和无氧运动时长等关键特征，以训练和评估多种机器学习模型（包括线性回归、随机森林和支持向量回归），并使用分层5折交叉验证来评估模型性能。

Result: 在包含44名印度参与者的队列研究中，随机森林模型的预测误差（RMSE）为5.15，优于线性回归（5.78）和支持向量回归（5.17）。所有模型的测试相关性和低RMSE值均表明其性能稳健且可靠。

Conclusion: 本研究通过改进的CPSJT方案和特征提取，使用机器学习模型显著提高了VO2max的预测精度，其中随机森林模型表现最佳，RMSE值为5.15，显示出稳健可靠的性能。

Abstract: VO2max is a critical indicator of cardiopulmonary fitness, reflecting the
maximum amount of oxygen the body can utilize during intense exercise.
Accurately measuring VO2max is essential for assessing cardiovascular health
and predicting outcomes in clinical settings. However, current methods for
VO2max estimation, such as Cardiopulmonary Exercise Testing (CPET), require
expensive equipment and the supervision of trained personnel, limiting
accessibility for large-scale screening. Preliminary efforts have been made to
create a more accessible method, such as the Cardiopulmonary Spot Jog Test
(CPSJT). Unfortunately, these early attempts yielded high error margins,
rendering them unsuitable for widespread use. In our study, we address these
shortcomings by refining the CPSJT protocol to improve prediction accuracy. A
crucial contribution is improved feature extraction which include gender, body
mass index, aerobic duration, and anaerobic duration. This targeted approach
helps in streamlining the model to enhance prediction precision while
minimizing the risk of overfitting. In a cohort of 44 participants from the
Indian population, we assessed the performance of various machine learning
models using these features. With Stratified 5-Fold Cross-Validation, the Root
Mean Squared Error (RMSE) values were 5.78 for Linear Regression, 5.15 for
Random Forest, and 5.17 for Support Vector Regression. All models demonstrated
strong test correlations and low RMSE values, underscoring their robust and
reliable performance.

</details>


### [541] [DIVER-0 : A Fully Channel Equivariant EEG Foundation Model](https://arxiv.org/abs/2507.14141)
*Danny Dongyeop Han,Ahhyun Lucy Lee,Taeyang Lee,Yonghyeon Gwon,Sebin Lee,Seongjin Lee,David Keetae Park,Shinjae Yoo,Jiook Cha,Chun Kee Chung*

Main category: eess.SP

TL;DR: DIVER-0是一个创新的EEG基础模型，通过全时空注意力和STCPE解决了现有模型的局限性，实现了在不同电极配置下的鲁棒泛化，并以更少的数据达到了有竞争力的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的EEG基础模型在模拟时空大脑动态以及通道排列等变性方面存在局限，阻碍了在不同电极配置下的鲁棒泛化。因此，需要开发能够克服这些限制的新模型。

Method: 提出了一种名为DIVER-0的新型EEG基础模型，它采用了全时空注意力机制，并通过旋转位置嵌入（RoPE）处理时间关系，二元注意力偏见处理通道区分。此外，还引入了滑动时间条件位置编码（STCPE），以实现时间平移等变性和通道排列等变性。

Result: DIVER-0模型在仅使用10%预训练数据的情况下，取得了具有竞争力的性能，并且在所有通道排列条件下均表现出一致的结果。这证明了该模型在跨数据集泛化方面的有效性，并确立了处理神经记录设置异质性的关键设计原则。

Conclusion: DIVER-0通过结合全时空注意力、旋转位置嵌入（RoPE）和二元注意力偏见，并引入滑动时间条件位置编码（STCPE），实现了在脑电图（EEG）建模方面的突破。该模型能够有效处理时空动态，并具有通道排列等变性，从而在不同电极配置下表现出鲁棒的泛化能力。实验证明，DIVER-0仅用10%的预训练数据即可达到有竞争力的性能，并在所有通道排列条件下保持一致的结果，验证了其跨数据集泛化的有效性，并为处理神经记录设置的固有异质性奠定了关键设计原则。

Abstract: Electroencephalography (EEG) is a non-invasive technique widely used in
brain-computer interfaces and clinical applications, yet existing EEG
foundation models face limitations in modeling spatio-temporal brain dynamics
and lack channel permutation equivariance, preventing robust generalization
across diverse electrode configurations. To address these challenges, we
propose DIVER-0, a novel EEG foundation model that demonstrates how full
spatio-temporal attention-rather than segregated spatial or temporal
processing-achieves superior performance when properly designed with Rotary
Position Embedding (RoPE) for temporal relationships and binary attention
biases for channel differentiation. We also introduce Sliding Temporal
Conditional Positional Encoding (STCPE), which improves upon existing
conditional positional encoding approaches by maintaining both temporal
translation equivariance and channel permutation equivariance, enabling robust
adaptation to arbitrary electrode configurations unseen during pretraining.
Experimental results demonstrate that DIVER-0 achieves competitive performance
with only 10% of pretraining data while maintaining consistent results across
all channel permutation conditions, validating its effectiveness for
cross-dataset generalization and establishing key design principles for
handling the inherent heterogeneity of neural recording setups.

</details>


### [542] [Graph Attention Networks for Detecting Epilepsy from EEG Signals Using Accessible Hardware in Low-Resource Settings](https://arxiv.org/abs/2507.15118)
*Szymon Mazurek,Stephen Moore,Alessandro Crimi*

Main category: eess.SP

TL;DR: 本研究提出了一种基于图注意力网络（GAT）的深度学习框架，用于从低成本脑电图（EEG）硬件检测癫痫病，特别关注服务欠缺地区。该框架在公平性、可及性和可解释性方面进行了优化，并在实际应用中表现出优于传统方法的性能，为开发经济实惠的神经诊断工具提供了可能。


<details>
  <summary>Details</summary>
Motivation: 癫痫病在低收入国家的诊断率偏低，原因是神经科医生稀缺且诊断工具成本高昂。因此，研究提出了一种基于图的深度学习框架，用于从低成本的脑电图（EEG）硬件检测癫痫病，并关注公平、可及的自动评估和可解释性，以揭示癫痫生物标志物。

Method: 通过将脑电图（EEG）信号建模为时空图，并利用图注意力网络（GAT）进行分类，以识别通道间的关系和时间动态。该方法还针对低保真度记录进行了信号预处理，并设计了一个轻量级的GAT架构，该架构在Google Colab上进行训练，并在RaspberryPi设备上进行部署。

Result: 该方法在分类性能方面表现出有前景的结果，其准确性和跨多 सत्र的鲁棒性均优于基于随机森林和图卷积网络的标准分类器，并且突出了额颞区域的特定连接。

Conclusion: 该研究结果突显了图注意力网络（GAT）在为服务欠缺地区提供有见地且可扩展的癫痫病诊断支持的潜力，为开发经济实惠且易于使用的神经诊断工具铺平了道路。

Abstract: Goal: Epilepsy remains under-diagnosed in low-income countries due to scarce
neurologists and costly diagnostic tools. We propose a graph-based deep
learning framework to detect epilepsy from low-cost Electroencephalography
(EEG) hardware, tested on recordings from Nigeria and Guinea-Bissau. Our focus
is on fair, accessible automatic assessment and explainability to shed light on
epilepsy biomarkers. Methods: We model EEG signals as spatio-temporal graphs,
classify them, and identify interchannel relationships and temporal dynamics
using graph attention networks (GAT). To emphasize connectivity biomarkers, we
adapt the inherently node-focused GAT to analyze edges. We also designed signal
preprocessing for low-fidelity recordings and a lightweight GAT architecture
trained on Google Colab and deployed on RaspberryPi devices. Results: The
approach achieves promising classification performance, outperforming a
standard classifier based on random forest and graph convolutional networks in
terms of accuracy and robustness over multiple sessions, but also highlighting
specific connections in the fronto-temporal region. Conclusions: The results
highlight the potential of GATs to provide insightful and scalable diagnostic
support for epilepsy in underserved regions, paving the way for affordable and
accessible neurodiagnostic tools.

</details>


### [543] [Recursive KalmanNet: Analyse des capacités de généralisation d'un réseau de neurones récurrent guidé par un filtre de Kalman](https://arxiv.org/abs/2507.14144)
*Cyril Falcon,Hassan Mortada,Mathéo Clavaud,Jean-Philippe Michel*

Main category: eess.SP

TL;DR: Recursive KalmanNet在处理时间动态变化时表现良好。


<details>
  <summary>Details</summary>
Motivation: 在实际应用中，系统的时间动态可能会发生变化，因此研究模型的泛化能力至关重要。

Method: 本文研究了Recursive KalmanNet在不同时间动态下的泛化能力。

Result: Recursive KalmanNet在处理分布外场景时，能够有效地估计状态变量和误差协方差，即使在测试数据的 temporal dynamics 与训练数据存在显著差异时也是如此。

Conclusion: 该研究表明，Recursive KalmanNet在处理与训练数据分布不同的时间动态时，表现出稳健的泛化能力。

Abstract: The Recursive KalmanNet, recently introduced by the authors, is a recurrent
neural network guided by a Kalman filter, capable of estimating the state
variables and error covariance of stochastic dynamic systems from noisy
measurements, without prior knowledge of the noise characteristics. This paper
explores its generalization capabilities in out-of-distribution scenarios,
where the temporal dynamics of the test measurements differ from those
encountered during training.
  Le Recursive KalmanNet, r\'ecemment introduit par les auteurs, est un
r\'eseau de neurones r\'ecurrent guid\'e par un filtre de Kalman, capable
d'estimer les variables d'\'etat et la covariance des erreurs des syst\`emes
dynamiques stochastiques \`a partir de mesures bruit\'ees, sans connaissance
pr\'ealable des caract\'eristiques des bruits. Cet article explore ses
capacit\'es de g\'en\'eralisation dans des sc\'enarios hors distribution, o\`u
les dynamiques temporelles des mesures de test diff\`erent de celles
rencontr\'ees \`a l'entra\^inement.

</details>


### [544] [Estimating Markers of Driving Stress through Multimodal Physiological Monitoring](https://arxiv.org/abs/2507.14146)
*Kleanthis Avramidis,Emily Zhou,Tiantian Feng,Hossein Hamidi Shishavan,Frederico Marcolino Quintao Severgnini,Danny J. Lohan,Paul Schmalenberg,Ercan M. Dede,Shrikanth Narayanan*

Main category: eess.SP

TL;DR: 本研究使用机器学习分析生理信号和驾驶行为，以实时估算驾驶压力。


<details>
  <summary>Details</summary>
Motivation: 理解和减轻驾驶压力对于预防事故以及提高道路安全和驾驶员福祉至关重要。虽然车辆配备了日益复杂的安全系统，但它们在应对可变的驾驶行为和环境背景方面存在许多限制。

Method: 利用受控驾驶模拟装置，收集了 31 名成年参与者的生理信号，并设计了一个多模态机器学习系统来估计压力源的存在。

Result: 分析探讨了模型对已知和新型情绪诱因的敏感性和时间动态性，并检验了预测压力与车辆控制可观察模式之间的关系。

Conclusion: 本研究证明了结合生理信号、上下文和行为线索以改善驾驶压力实时估算的潜力。

Abstract: Understanding and mitigating driving stress is vital for preventing accidents
and advancing both road safety and driver well-being. While vehicles are
equipped with increasingly sophisticated safety systems, many limits exist in
their ability to account for variable driving behaviors and environmental
contexts. In this study we examine how short-term stressor events impact
drivers' physiology and their behavioral responses behind the wheel. Leveraging
a controlled driving simulation setup, we collected physiological signals from
31 adult participants and designed a multimodal machine learning system to
estimate the presence of stressors. Our analysis explores the model sensitivity
and temporal dynamics against both known and novel emotional inducers, and
examines the relationship between predicted stress and observable patterns of
vehicle control. Overall, this study demonstrates the potential of linking
physiological signals with contextual and behavioral cues in order to improve
real-time estimation of driving stress.

</details>


### [545] [Graph Convolutional Neural Networks to Model the Brain for Insomnia](https://arxiv.org/abs/2507.14147)
*Kevin Monteiro,Sam Nallaperuma-Herzberg,Martina Mason,Steve Niederer*

Main category: eess.SP

TL;DR: 该研究使用脑电图和图卷积神经网络来识别失眠症的脑网络特征，准确率达70%，并确定了关键电极位置。


<details>
  <summary>Details</summary>
Motivation: 现有失眠症治疗存在副作用，需要开发新的治疗方法。脑模型在其他疾病研究中显示出潜力，但尚未应用于失眠症。

Method: 通过分析长时间脑电图数据，构建脑网络模型，并使用图卷积神经网络（GCNN）进行分类，以识别失眠症的特征。

Result: 研究发现，50秒无重叠滑动窗口最适合脑电图分割，GCNN模型在窗口级别和个体级别的分类准确率分别为70%和68%。移除C4-P4、F4-C4和C4-A1电极对模型性能的负面影响最大，这与这些区域在失眠症患者中的功能连接异常有关。

Conclusion: 该研究表明，使用基于脑网络分析的图卷积神经网络模型可以区分失眠症患者和健康个体，并且 C4-P4、F4-C4 和 C4-A1 电极与失眠症的功能连接异常有关。

Abstract: Insomnia affects a vast population of the world and can have a wide range of
causes. Existing treatments for insomnia have been linked with many side
effects like headaches, dizziness, etc. As such, there is a clear need for
improved insomnia treatment. Brain modelling has helped with assessing the
effects of brain pathology on brain network dynamics and with supporting
clinical decisions in the treatment of Alzheimer's disease, epilepsy, etc.
However, such models have not been developed for insomnia. Therefore, this
project attempts to understand the characteristics of the brain of individuals
experiencing insomnia using continuous long-duration EEG data. Brain networks
are derived based on functional connectivity and spatial distance between EEG
channels. The power spectral density of the channels is then computed for the
major brain wave frequency bands. A graph convolutional neural network (GCNN)
model is then trained to capture the functional characteristics associated with
insomnia and configured for the classification task to judge performance.
Results indicated a 50-second non-overlapping sliding window was the most
suitable choice for EEG segmentation. This approach achieved a classification
accuracy of 70% at window level and 68% at subject level. Additionally, the
omission of EEG channels C4-P4, F4-C4 and C4-A1 caused higher degradation in
model performance than the removal of other channels. These channel electrodes
are positioned near brain regions known to exhibit atypical levels of
functional connectivity in individuals with insomnia, which can explain such
results.

</details>


### [546] [Visible Light Indoor Positioning with a Single LED and Distributed Single-Element OIRS: An Iterative Approach with Adaptive Beam Steering](https://arxiv.org/abs/2507.14148)
*Daniele Pugliese,Giovanni Iacovelli,Alessio Fascista,Domenico Striccoli,Oleksandr Romanov,Luigi Alfredo Grieco,Gennaro Boggia*

Main category: eess.SP

TL;DR: 通过结合OIRS和VLC技术，提出了一种创新的室内定位方法，利用ML估计和IWLS算法提高了定位精度和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 为了在仅包含单个LED作为主动锚点和多个OIRS的VLC室内环境中，实现低成本PD的定位，克服现有技术的局限性。

Method: 提出了一种新颖的、计算高效的定位框架，包括最大似然（ML）估计器用于视距（LoS）和非视距（NLoS）距离估计，并利用无结构噪声方差变换推导出NLoS估计的闭式解。结合迭代加权最小二乘（IWLS）和自适应波束控制策略，以最小化克拉美-罗下界（CRLB）为权重，实现了OIRS网络与光电探测器（PD）的动态对准。

Result: 仿真结果表明，该方法在定位精度、对抗OIRS失配的鲁棒性以及达到理论下界所需的迭代次数方面均表现出色。

Conclusion: 所提出的基于OIRS的VLC定位方法在定位精度、鲁棒性以及收敛速度方面表现优越，并达到了理论性能极限。

Abstract: The integration of Optical Intelligent Reflective Surfaces (OIRSs) into
Visible Light Communication (VLC) systems is gaining momentum as a valid
alternative to RF technologies, harnessing the existing lighting
infrastructures and the vast unlicensed optical spectrum to enable higher
spectral efficiency, improved resilience to Line-of-Sight (LoS) blockages, and
enhanced positioning capabilities. This paper investigates the problem of
localizing a low-cost Photo Detector (PD) in a VLC-based indoor environment
consisting of only a single Light Emitting Diode (LED) as an active anchor, and
multiple spatially distributed single-element OIRSs. We formulate the problem
within an indirect, computationally efficient localization framework: first,
the optimal Maximum Likelihood (ML) estimators of the LoS and Non-Line-of-Sight
(NLoS) distances are derived, using a suitable OIRS activation strategy to
prevent interferences. To overcome the grid-based optimization required by the
ML NLoS estimator, we devise a novel algorithm based on an unstructured noise
variance transformation, which admits a closed-form solution. The set of
estimated LoS/NLoS distances are then used within a low-complexity localization
algorithm combining an Iterative Weighted Least Squares (IWLS) procedure, whose
weights are set according to the inverse of the Cram\'er-Rao Lower Bound
(CRLB), with an adaptive beam steering strategy that allows the OIRSs network
to dynamically align with the PD, without any prior knowledge of its position.
Accordingly, we derive the CRLB for both LoS/NLoS distance estimation and PD
position estimation. Simulation results demonstrate the effectiveness of our
approach in terms of localization accuracy, robustness against OIRSs
misalignment conditions, and low number of iterations required to attain the
theoretical bounds.

</details>


### [547] [Self-DANA: A Resource-Efficient Channel-Adaptive Self-Supervised Approach for ECG Foundation Models](https://arxiv.org/abs/2507.14151)
*Giuliana Monachino,Nicolò La Porta,Beatrice Zanchi,Luigi Fiorillo,Alvise Dei Rossi,Georgiy Farina,Francesca Dalia Faraci*

Main category: eess.SP

TL;DR: 本研究提出了一种名为Self-DANA的解决方案，用于提升心电图（ECG）基石模型在通道数减少情况下的性能和资源效率。该方案通过自监督学习和随机导联选择技术，在五个减少通道数的配置下进行了实验验证，结果显示在显著减少内存和计算时间的同时，仍能达到行业领先的性能。


<details>
  <summary>Details</summary>
Motivation: 随着可穿戴和便携式设备的应用普及，在较少通道数的配置下进行学习引起了广泛关注。然而，将ECG领域的基石模型（Foundation Models）应用于下游场景中通道数减少的情况，仍需深入研究。

Method: 提出了一种名为Self-DANA的新型易于集成解决方案，使得自监督学习架构能够适应于输入通道数减少的情况，确保了资源的有效利用和高性能。同时，引入了随机导联选择（Random Lead Selection）这一新颖的增强技术，旨在以更具鲁棒性和与通道无关的方式对模型进行预训练。

Result: 实验结果表明，Self-DANA方案在资源利用率方面有显著提升，同时达到了最先进的性能水平。具体而言，峰值CPU内存减少高达69.3%，峰值GPU内存减少34.4%，平均训练周期CPU时间减少约17%，平均训练周期GPU时间减少约24%。

Conclusion: 本研究提出的Self-DANA方案能够有效提升模型在较少输入通道数下的资源效率和性能表现，并在五个减少通道数的配置上进行了实验验证，证明了其优越性。

Abstract: Foundation Models (FMs) are large-scale machine learning models trained on
extensive, diverse datasets that can be adapted to a wide range of downstream
tasks with minimal fine-tuning. In the last two years, interest in FMs has also
grown for applications in the cardiological field to analyze the
electrocardiogram (ECG) signals. One of the key properties of FMs is their
transferability to a wide range of downstream scenarios. With the spread of
wearable and portable devices, keen interest in learning from reduced-channel
configurations has arisen. However, the adaptation of ECG FMs to downstream
scenarios with fewer available channels still has to be properly investigated.
In this work, we propose Self-DANA, a novel, easy-to-integrate solution that
makes self-supervised architectures adaptable to a reduced number of input
channels, ensuring resource efficiency and high performance. We also introduce
Random Lead Selection, a novel augmentation technique to pre-train models in a
more robust and channel-agnostic way. Our experimental results on five
reduced-channel configurations demonstrate that Self-DANA significantly
enhances resource efficiency while reaching state-of-the-art performance. It
requires up to 69.3% less peak CPU memory, 34.4% less peak GPU memory, about
17% less average epoch CPU time, and about 24% less average epoch GPU time.

</details>


### [548] [Machine learning-enabled river water quality monitoring using lithography-free 3D-printed sensors](https://arxiv.org/abs/2507.14152)
*Frank Efe Erukainure,Feidra Gjata,Matin Ataei Kachouei,Henry Cox,Md. Azahar Ali*

Main category: eess.SP

TL;DR: 本研究提出了一种基于3D打印技术的磷酸盐传感器，能够快速、准确地检测河水中的磷酸盐污染，为水质监测提供了新的解决方案。


<details>
  <summary>Details</summary>
Motivation: 河流的水质监测对于水生生物、牲畜以及人类都至关重要，尤其是在全球粮食危机背景下，清洁水是满足粮食需求的关键。过量的污染物，如磷酸盐，会消耗溶解氧并引发富营养化，导致严重的环境和健康问题。因此，开发能够持续追踪磷酸盐水平的传感器，对于预防富营养化具有重要意义。

Method: 该研究提出了一种无需光刻的磷酸盐传感器（P-sensor）。该传感器采用3D打印技术制造，形成了具有8微米特征尺寸的周期性聚合物图案，并在此基础上涂覆了磷酸盐离子选择性膜，形成固态指示电极。该传感器能够检测低至1 ppb的磷酸盐，并且在0-475 ppm的浓度范围内具有快速响应（低于30秒）。为了提高测量精度，研究中还训练了一个前馈神经网络来预测磷酸盐水平，并取得了优异的性能指标（均方误差低于1e-3，零标准差，皮尔逊相关系数为0.997）。最后，研究人员在实际的河水样本中验证了传感器的有效性，并与商业设备进行了比较。

Result: 该研究成功开发并验证了一种无需光刻的磷酸盐传感器（P-sensor）。该传感器能够以十亿分之几（ppb）的水平检测河水中的磷酸盐，检测限低至1 ppb，响应时间小于30秒。在弗吉尼亚州拉帕汉诺克河的实际水样测试中，该传感器表现出色，并且通过训练的前馈神经网络预测磷酸盐水平，取得了非常高的准确性（皮尔逊相关系数为0.997）。与商业磷酸盐测量仪的比较结果也表明了其有效性。

Conclusion: 该研究提出了一个无需光刻的磷酸盐传感器（P-sensor），能够以十亿分之几（ppb）的水平检测河水中的磷酸盐。该传感器使用3D打印的聚合物周期性图案（8微米特征尺寸）形成的固态指示电极，并涂覆有磷酸盐离子选择性膜。P-sensor在0-475 ppm的浓度范围内，检测低至1 ppb的磷酸盐，响应时间不到30秒。研究人员在弗吉尼亚州拉帕汉诺克河的水样中对该传感器进行了验证，评估了污水处理厂上游和下游的水样，并与商业磷酸盐测量仪进行了比较。通过训练前馈神经网络来预测磷酸盐水平，取得了低于1e-3的均方误差、零标准差以及0.997的皮尔逊相关系数。这些结果表明，该传感器是一个实用的连续水质监测工具，可为利益相关者和政策制定者提供信息，最终改善公众健康。

Abstract: River water quality monitoring is important for aquatic life, livestock, and
humans because clean water is critical to meeting food demand during the global
food crisis. Excessive contaminants, including phosphate, deplete dissolved
oxygen and trigger eutrophication, leading to serious health and ecological
problems. Continuous sensors that track phosphate levels can therefore help
prevent eutrophication. In this work we present a lithography-free phosphate
sensor (P-sensor) that detects phosphate in river water at parts-per-billion
levels. The device uses a solid-state indicator electrode formed by 3D-printed
periodic polymer patterns (8 um feature size) coated with a thin phosphate
ion-selective membrane. The P-sensor detects as little as 1 ppb phosphate
across 0 - 475 ppm with a response time under 30 seconds. We validated the
sensor on Rappahannock River water, Virginia (less than 0.8 ppm phosphate) at
sites upstream and downstream of a sewage treatment plant and benchmarked the
results against a commercial phosphate meter. A feed-forward neural network was
trained to predict phosphate levels, achieving a mean-squared error below 1e-3,
zero standard deviation, and a Pearson correlation coefficient of 0.997 for
river samples. These results demonstrate a practical tool for continuous
water-quality monitoring that can inform stakeholders and policymakers and
ultimately improve public health.

</details>


### [549] [Surface EMG Profiling in Parkinson's Disease: Advancing Severity Assessment with GCN-SVM](https://arxiv.org/abs/2507.14153)
*Daniel Cieślak,Barbara Szyca,Weronika Bajko,Liwia Florkiewicz,Kinga Grzęda,Mariusz Kaczmarek,Helena Kamieniecka,Hubert Lis,Weronika Matwiejuk,Anna Prus,Michalina Razik,Inga Rozumowicz,Wiktoria Ziembakowska*

Main category: eess.SP

TL;DR: 本研究提出一种基于sEMG和GCN-SVM模型的新方法，用于客观评估帕金森病严重程度，准确率达92%，有潜力应用于临床。


<details>
  <summary>Details</summary>
Motivation: 帕金森病（PD）的诊断和监测具有挑战性，需要客观的方法来评估其严重程度。

Method: 利用表面肌电图（sEMG）和图卷积网络-支持向量机（GCN-SVM）模型来评估帕金森病的严重程度。

Result: 与传统的支持向量机（SVM）模型（准确率最高83%）相比，GCN-SVM模型将准确率提高到92%，显示出在评估帕金森病严重程度方面的优越性。

Conclusion: 该研究提出的sEMG结合GCN-SVM模型在评估帕金森病严重程度方面显示出潜力，有望改进帕金森病的诊断和治疗。

Abstract: Parkinson's disease (PD) poses challenges in diagnosis and monitoring due to
its progressive nature and complex symptoms. This study introduces a novel
approach utilizing surface electromyography (sEMG) to objectively assess PD
severity, focusing on the biceps brachii muscle. Initial analysis of sEMG data
from five PD patients and five healthy controls revealed significant
neuromuscular differences. A traditional Support Vector Machine (SVM) model
achieved up to 83% accuracy, while enhancements with a Graph Convolutional
Network-Support Vector Machine (GCN-SVM) model increased accuracy to 92%.
Despite the preliminary nature of these results, the study outlines a detailed
experimental methodology for future research with larger cohorts to validate
these findings and integrate the approach into clinical practice. The proposed
approach holds promise for advancing PD severity assessment and improving
patient care in Parkinson's disease management.

</details>


### [550] [Extreme Value Theory-based Distributed Interference Prediction for 6G Industrial Sub-networks](https://arxiv.org/abs/2507.14155)
*Pramesh Gautam,Sushmita Sapkota,Carsten Bockelmann,Shashi Raj Pandey,Armin Dekorsy*

Main category: eess.SP

TL;DR: 该研究提出了一种结合极值理论和机器学习的框架（iQPTransformer），用于预测超密集网络中的干扰，特别是极端情况。该框架能处理各种挑战，并已通过实验证明其在达到高可靠性目标方面优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 对于超密集部署的子网络（SN），特别是在动态移动、快速变化的信道统计和零星流量下，需要超高可靠低延迟通信（HRLLC），而能够考虑极端和罕见事件的干扰预测仍然是一个关键挑战。

Method: 该论文提出了一种新颖的校准干扰尾部预测框架，这是一种混合统计和机器学习（ML）方法，将反向分位数块 Transformer（iQPTransformer）与极值理论（EVT）相结合。它捕获干扰动态和尾部行为，同时量化不确定性以提供统计覆盖保证。通过利用估计的干扰尾部分布来设计预测性、风险感知的资源分配来证明其有效性。在资源受限的子网络（SN）场景中，引入了split-iQPTransformer，通过在传感器-执行器（SA）对和SN控制器之间分布式神经网络组件来实现协同训练，同时与集中式iQPTransformer相比，性能差异极小。

Result: 所提出的框架能够有效处理深度衰落、随机流量和时分双工（TDD）错位，并能抵抗稀有和极端干扰事件。实验结果表明，在超可靠状态下，块错误率（BLER）目标始终能达到95%以上，显著优于基线方法。

Conclusion: 所提出的框架能够有效处理深度衰落、随机流量和时分双工（TDD）错位，并能抵抗稀有和极端干扰事件。实验结果表明，在超可靠状态下，块错误率（BLER）目标始终能达到95%以上，显著优于基线方法。

Abstract: Interference prediction that accounts for extreme and rare events remains a
key challenge for ultra-densely deployed sub-networks (SNs) requiring
hyper-reliable low-latency communication (HRLLC), particularly under dynamic
mobility, rapidly varying channel statistics, and sporadic traffic. This paper
proposes a novel calibrated interference tail prediction framework, a hybrid
statistical and machine learning (ML) approach that integrates an inverted
quantile patch transformer (iQPTransformer) within extreme value theory (EVT).
It captures interference dynamics and tail behavior while quantifying
uncertainty to provide statistical coverage guarantees. Its effectiveness is
demonstrated by leveraging the estimated interference tail distribution to
design predictive, risk-aware resource allocation. In resource-constrained SN
scenarios, we introduce the split-iQPTransformer, enabling collaborative
training by distributing neural network components between sensor-actuator (SA)
pairs and the SN controller, while maintaining minimal performance disparity
compared to the centralized iQPTransformer. The framework effectively handles
deep fading, random traffic, and time-division duplexing (TDD) misalignments
and is resilient to rare and extreme interference events. Extensive evaluations
are performed under two mobility models and two realistic SN traffic patterns,
using a spatially consistent 3GPP channel model across all scenarios.
Experimental results show consistent achievement of block error rate (BLER)
targets beyond the 95th percentile in the hyper-reliable regime, significantly
outperforming baseline approaches.

</details>


### [551] [UniPhyNet: A Unified Network For Multimodal Physiological Raw Signal Classification](https://arxiv.org/abs/2507.14163)
*Renxiang Qiu,Raghavendra Selvan*

Main category: eess.SP

TL;DR: UniPhyNet 是一种创新的端到端神经网络，可以直接处理 EEG、ECG 和 EDA 信号，无需手动特征工程，即可对认知负荷进行分类，并在 CL-Drive 数据集上显著提高了分类准确率。


<details>
  <summary>Details</summary>
Motivation: 提出 UniPhyNet 神经网络架构，旨在无需显式提取手工特征，即可利用多模态生理信号（EEG、ECG 和 EDA）对认知负荷进行分类。

Method: UniPhyNet 架构集成了多尺度并行卷积块和 ResNet 类型块（通过通道块注意力模块增强），以关注信息特征，同时利用双向门控循环单元来捕获时间依赖性。该架构通过学习到的特征图的中间融合，处理和组合单峰和多峰配置中的信号。

Result: UniPhyNet 在 CL-Drive 数据集上，将原始信号分类准确率从 70% 提高到 80%（二元分类），并将准确率从 62% 提高到 74%（三元分类），优于基于特征的模型。

Conclusion: UniPhyNet 是一种新的神经网络架构，可以直接使用多模态生理信号（EEG、ECG 和 EDA）对认知负荷进行分类，无需手动提取特征，并且在 CL-Drive 数据集上，将原始信号分类准确率从 70% 提高到 80%（二元分类）和从 62% 提高到 74%（三元分类），优于基于特征的模型，证明了其作为实时认知状态监测的有效端到端解决方案。

Abstract: We present UniPhyNet, a novel neural network architecture to classify
cognitive load using multimodal physiological data -- specifically EEG, ECG and
EDA signals -- without the explicit need for extracting hand-crafted features.
UniPhyNet integrates multiscale parallel convolutional blocks and ResNet-type
blocks enhanced with channel block attention module to focus on the informative
features while a bidirectional gated recurrent unit is used to capture temporal
dependencies. This architecture processes and combines signals in both unimodal
and multimodal configurations via intermediate fusion of learned feature maps.
On the CL-Drive dataset, UniPhyNet improves raw signal classification accuracy
from 70% to 80% (binary) and 62% to 74% (ternary), outperforming feature-based
models, demonstrating its effectiveness as an end-to-end solution for
real-world cognitive state monitoring.

</details>


### [552] [A Denoising VAE for Intracardiac Time Series in Ischemic Cardiomyopathy](https://arxiv.org/abs/2507.14164)
*Samuel Ruipérez-Campillo,Alain Ryser,Thomas M. Sutter,Ruibin Feng,Prasanth Ganesan,Brototo Deb,Kelly A. Brennan,Maxime Pedron,Albert J. Rogers,Maarten Z. H. Kolk,Fleur V. Y. Tjong,Sanjiv M. Narayan,Julia E. Vogt*

Main category: eess.SP

TL;DR: 本研究提出了一种基于VAE的信号去噪方法，用于改善心脏电生理信号的质量，尤其是在处理复杂噪声方面，效果优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 传统的噪声消除技术难以处理心脏电生理信号中存在的多样化、非线性、非平稳噪声，影响心律失常和心肌病的准确诊断和治疗。

Method: 提出了一种基于变分自编码器（VAE）的模型，用于处理和去噪心腔内信号。

Result: VAE模型在去除包括时变非线性噪声在内的多种噪声方面表现出优越的降噪性能，优于临床常用的滤波方法和现有最先进的技术。

Conclusion: VAE模型在去除心腔内单相动作电位（MAP）信号的多种噪声方面表现优于传统滤波方法，能有效提升信号质量，有望改善心脏电生理学（EP）的治疗效果。

Abstract: In the field of cardiac electrophysiology (EP), effectively reducing noise in
intra-cardiac signals is crucial for the accurate diagnosis and treatment of
arrhythmias and cardiomyopathies. However, traditional noise reduction
techniques fall short in addressing the diverse noise patterns from various
sources, often non-linear and non-stationary, present in these signals. This
work introduces a Variational Autoencoder (VAE) model, aimed at improving the
quality of intra-ventricular monophasic action potential (MAP) signal
recordings. By constructing representations of clean signals from a dataset of
5706 time series from 42 patients diagnosed with ischemic cardiomyopathy, our
approach demonstrates superior denoising performance when compared to
conventional filtering methods commonly employed in clinical settings. We
assess the effectiveness of our VAE model using various metrics, indicating its
superior capability to denoise signals across different noise types, including
time-varying non-linear noise frequently found in clinical settings. These
results reveal that VAEs can eliminate diverse sources of noise in single
beats, outperforming state-of-the-art denoising techniques and potentially
improving treatment efficacy in cardiac EP.

</details>


### [553] [A Multi-Modal IoT Node for Energy-Efficient Environmental Monitoring with Edge AI Processing](https://arxiv.org/abs/2507.14165)
*Philip Wiese,Victor Kartsch,Marco Guermandi,Luca Benini*

Main category: eess.SP

TL;DR: 通过集成多种传感器和支持边缘 AI 处理的低功耗芯片，构建了一个多功能的物联网环境监测节点，实现了节能和智能空气质量监测。


<details>
  <summary>Details</summary>
Motivation: 目前的物联网环境传感平台通常仅限于少数传感器，无法全面评估环境状况，并且缺乏足够的计算能力来支持在边缘部署先进的机器学习和人工智能算法。

Method: 开发了一个紧凑的（17x38 mm2）、多功能的、基于 MCU 的环境物联网节点，集成了 11 种传感器（包括 CO2 浓度、挥发性有机化合物、光照强度、紫外线辐射、压力、温度、湿度、RGB 摄像头视觉传感以及 GNSS 模块的精确地理定位）。该节点采用 GAP9（一种并行的超低功耗片上系统），可实现先进的机器学习模型在设备上的实时、高能效边缘处理。实现了基于 YOLOv5 的占用检测管道（0.3M 参数，每次推理 42MOP），与原始数据流相比，节能 42%。此外，还展示了一个结合占用检测和自适应采样率的智能室内空气质量监测系统，在单块 600 mAh、3.7 V 电池上可运行长达 143 小时。

Result: 实现了 42% 的节能，单块电池可运行长达 143 小时。

Conclusion: 该平台为创新的应用奠定了基础，例如预测室内空气质量，从而实现高效的、由人工智能驱动的边缘预测，以实现节能和自主的、主动的污染缓解控制策略。

Abstract: The widespread adoption of Internet of Things (IoT) technologies has
significantly advanced environmental monitoring (EM) by enabling cost-effective
and scalable sensing solutions. Concurrently, machine learning (ML) and
artificial intelligence (AI) are introducing powerful tools for the efficient
and accurate analysis of complex environmental data. However, current IoT
platforms for environmental sensing are typically limited to a narrow set of
sensors, preventing a comprehensive assessment of environmental conditions and
lacking sufficient computational capabilities to support the deployment of
advanced ML and AI algorithms on the edge. To overcome these limitations, we
introduce a compact (17x38 mm2), multi-modal, MCU-based environmental IoT node
integrating 11 sensors, including CO2 concentration, volatile organic compounds
(VOCs), light intensity, UV radiation, pressure, temperature, humidity, visual
sensing via an RGB camera, and precise geolocation through a GNSS module. It
features GAP9, a parallel ultra-low-power system-on-chip, enabling real-time,
energy-efficient edge processing of advanced ML models directly on-device. We
implemented a YOLOv5-based occupancy detection pipeline (0.3 M parameters, 42
MOP per inference), demonstrating 42% energy savings over raw data streaming.
Additionally, we present a smart indoor air quality (IAQ) monitoring setup that
combines occupancy detection with adaptive sample rates, achieving operational
times of up to 143 h on a single compact 600 mAh, 3.7 V battery. Our platform
lays the groundwork for innovative applications such as predictive indoor IAQ,
enabling efficient AI-driven on-edge forecasting for energy-efficient and
autonomous, proactive pollution-mitigation control strategies

</details>


### [554] [Automated Vigilance State Classification in Rodents Using Machine Learning and Feature Engineering](https://arxiv.org/abs/2507.14166)
*Sankalp Jajee,Gaurav Kumar,Homayoun Valafar*

Main category: eess.SP

TL;DR: 该研究开发了一种利用EEG信号的自动化框架，结合了信号处理和机器学习技术（特别是XGBoost模型），以区分小型啮齿动物的REM、SWS和清醒状态。该方法在2024年大数据健康科学案例竞赛中取得了91.5%的准确率，优于基线方法，有望加速睡眠科学研究和干预措施的开发。


<details>
  <summary>Details</summary>
Motivation: 临床前睡眠研究受到劳动密集型的手动警觉状态分类和评估者间变异性的限制，这在一定程度上限制了研究通量和可重复性。

Method: 开发了一个自动化框架，通过整合先进的信号处理和机器学习技术，对小型啮齿动物的脑电图（EEG）记录进行分类，将其划分为三个关键的警觉状态：异睡（REM）、慢波睡眠（SWS）和清醒。该系统利用了来自时域和频域的工程特征，包括跨越经典EEG频带（从delta到gamma）的频谱功率、通过最大最小距离法（Maximum-Minimum Distance）捕捉的时间动态，以及跨频率耦合指标。这些特征能够捕捉到独特的神经生理学特征，例如清醒期间的高频去同步化、SWS中的delta振荡以及REM特有的爆发。

Result: XGBoost模型在2024年大数据健康科学案例竞赛（南卡罗来纳大学大数据健康科学中心）中进行了验证，取得了91.5%的总体准确率、86.8%的精确率、81.2%的召回率和83.5%的F1分数，其性能优于所有基线方法。

Conclusion: 该方法代表了自动睡眠状态分类的关键进展，并为加速睡眠科学研究和针对慢性睡眠障碍的靶向干预措施的开发提供了宝贵的工具。公开的代码（BDHSC）资源将为该领域的进步做出重大贡献。

Abstract: Preclinical sleep research remains constrained by labor intensive, manual
vigilance state classification and inter rater variability, limiting throughput
and reproducibility. This study presents an automated framework developed by
Team Neural Prognosticators to classify electroencephalogram (EEG) recordings
of small rodents into three critical vigilance states paradoxical sleep (REM),
slow wave sleep (SWS), and wakefulness. The system integrates advanced signal
processing with machine learning, leveraging engineered features from both time
and frequency domains, including spectral power across canonical EEG bands
(delta to gamma), temporal dynamics via Maximum-Minimum Distance, and
cross-frequency coupling metrics. These features capture distinct
neurophysiological signatures such as high frequency desynchronization during
wakefulness, delta oscillations in SWS, and REM specific bursts. Validated
during the 2024 Big Data Health Science Case Competition (University of South
Carolina Big Data Health Science Center, 2024), our XGBoost model achieved
91.5% overall accuracy, 86.8% precision, 81.2% recall, and an F1 score of
83.5%, outperforming all baseline methods. Our approach represents a critical
advancement in automated sleep state classification and a valuable tool for
accelerating discoveries in sleep science and the development of targeted
interventions for chronic sleep disorders. As a publicly available code (BDHSC)
resource is set to contribute significantly to advancements.

</details>


### [555] [Attention-Based Fusion of IQ and FFT Spectrograms with AoA Features for GNSS Jammer Localization](https://arxiv.org/abs/2507.14167)
*Lucas Heublein,Christian Wielenberg,Thorsten Nowak,Tobias Feigl,Christopher Mutschler,Felix Ott*

Main category: eess.SP

TL;DR: 本研究提出了一种融合IQ样本和FFT频谱图并结合AoA特征的新方法，用于检测、分类和定位GNSS干扰源，并在新数据集上取得了优于现有技术的性能。


<details>
  <summary>Details</summary>
Motivation: 为了应对干扰设备（如GNSS干扰器）对精确定位的威胁，提高态势感知能力、减轻其影响并实施有效的反制措施，需要有效的方法来检测和定位这些干扰信号。传统的到达角（AoA）方法在多径环境中精度会降低，并且需要大量的计算资源。

Method: 提出了一种基于注意力机制的融合框架，该框架集成了同相和正交（IQ）样本与快速傅里叶变换（FFT）计算的频谱图，并结合了22个到达角（AoA）特征，以提高定位精度。通过评估128个视觉编码器和时间序列模型来选择性能最佳的方法。

Result: 与现有技术相比，在包含移动干扰源和动态多径条件的新数据集上，实现了更优越的性能。

Conclusion: 该研究提出了一种新颖的方法来检测、分类和定位干扰源，并在包含移动干扰源和动态多径条件的新数据集上证明了其优越性能。

Abstract: Jamming devices disrupt signals from the global navigation satellite system
(GNSS) and pose a significant threat by compromising the reliability of
accurate positioning. Consequently, the detection and localization of these
interference signals are essential to achieve situational awareness, mitigating
their impact, and implementing effective counter-measures. Classical Angle of
Arrival (AoA) methods exhibit reduced accuracy in multipath environments due to
signal reflections and scattering, leading to localization errors.
Additionally, AoA-based techniques demand substantial computational resources
for array signal processing. In this paper, we propose a novel approach for
detecting and classifying interference while estimating the distance, azimuth,
and elevation of jamming sources. Our benchmark study evaluates 128 vision
encoder and time-series models to identify the highest-performing methods for
each task. We introduce an attention-based fusion framework that integrates
in-phase and quadrature (IQ) samples with Fast Fourier Transform (FFT)-computed
spectrograms while incorporating 22 AoA features to enhance localization
accuracy. Furthermore, we present a novel dataset of moving jamming devices
recorded in an indoor environment with dynamic multipath conditions and
demonstrate superior performance compared to state-of-the-art methods.

</details>


### [556] [CQI-Based Interference Prediction for Link Adaptation in Industrial Sub-networks](https://arxiv.org/abs/2507.14169)
*Pramesh Gautam,Ravi Sharan B A G,Paolo Baracca,Carsten Bockelmann,Thorsten Wild,Armin Dekorsy*

Main category: eess.SP

TL;DR: Novel interference prediction for industrial networks improves link adaptation using vDSSM and SP-TPR in an unscented Kalman filter, reducing complexity by 10x and matching SOTA performance with high reliability.


<details>
  <summary>Details</summary>
Motivation: To improve link adaptation (LA) in densely deployed industrial sub-networks (SNs) with high-reliability and low-latency communication (HRLLC) requirements by predicting and leveraging the heavy-tailed interference probability density function (pdf).

Method: A novel interference prediction scheme using a vector discrete-time state-space model (vDSSM) to model interference as a latent vector of CQI, with a low-complexity, outlier-robust, sparse Student-t process regression (SPTPR) method integrated into a modified unscented Kalman filter for robust estimation and compensation of protocol feedback delays.

Result: The proposed method achieves over 10x lower complexity than a similar non-parametric baseline, maintains a Block Error Rate (BLER) below the 90th percentile target of 1e-6, and delivers performance comparable to a state-of-the-art supervised technique using only CQI reports.

Conclusion: The proposed interference prediction scheme effectively improves link adaptation in industrial sub-networks for HRLLC, achieving lower complexity and comparable performance to state-of-the-art methods while maintaining target reliability.

Abstract: We propose a novel interference prediction scheme to improve link adaptation
(LA) in densely deployed industrial sub-networks (SNs) with high-reliability
and low-latency communication (HRLLC) requirements. The proposed method aims to
improve the LA framework by predicting and leveraging the heavy-tailed
interference probability density function (pdf). Interference is modeled as a
latent vector of available channel quality indicator (CQI), using a vector
discrete-time state-space model (vDSSM) at the SN controller, where the CQI is
subjected to compression, quantization, and delay-induced errors. To robustly
estimate interference power values under these impairments, we employ a
low-complexity, outlier-robust, sparse Student-t process regression (SPTPR)
method. This is integrated into a modified unscented Kalman filter, which
recursively refines predicted interference using CQI, enabling accurate
estimation and compensating protocol feedback delays, crucial for accurate LA.
Numerical results show that the proposed method achieves over 10x lower
complexity compared to a similar non-parametric baseline. It also maintains a
BLER below the 90th percentile target of 1e-6 while delivering performance
comparable to a state-of-the-art supervised technique using only CQI reports.

</details>


### [557] [Enhancing Generalization in PPG-Based Emotion Measurement with a CNN-TCN-LSTM Model](https://arxiv.org/abs/2507.14173)
*Karim Alghoul,Hussein Al Osman,Abdulmotaleb El Saddik*

Main category: eess.SP

TL;DR: 為了解決PPG信號情緒識別的個體泛化性挑戰，提出了一種結合CNN、LSTM和TCN的混合模型，實驗證明該模型在PPGE數據集上表現更優。


<details>
  <summary>Details</summary>
Motivation: 儘管基於PPG信號的情緒識別技術取得進展，但模型在不同個體間的泛化能力仍然是一個挑戰。因此，有必要開發能夠更好地處理個體差異並提高泛化能力的新模型。

Method: 提出了一種新穎的混合架構，結合了卷積神經網絡（CNN）、長短期記憶網絡（LSTM）和時間卷積網絡（TCN）。該模型首先使用CNN提取原始PPG信號的特徵，然後分別由LSTM和TCN處理這些特徵。最後，將LSTM和TCN的輸出連接起來，生成最終的特徵表示，用於分類情緒的主要維度——效價（valence）和喚醒度（arousal）。

Result: 在PPGE數據集上的實驗表明，該混合模型相比於單獨的CNN和LSTM架構，具有更好的模型泛化能力。此外，該模型在情緒識別任務中的表現優於最先進的CNN架構和CNN-LSTM模型，並通過AUC和F1分數等指標證明了其在處理受試者變異性方面的有效性。

Conclusion: 该混合模型在处理来自PPG信號的表情識別任務時，通過結合CNN、LSTM和TCN的優勢，實現了比單獨的CNN和LSTM架構更好的模型泛化能力，並且優於現有的基於CNN的架構和CNN-LSTM模型，能夠有效處理受試者變異性。

Abstract: Human computer interaction has become integral to modern life, driven by
advancements in machine learning technologies. Affective computing, in
particular, has focused on systems that recognize, interpret, and respond to
human emotions, often using wearable devices, which provide continuous data
streams of physiological signals. Among various physiological signals, the
photoplethysmogram (PPG) has gained prominence due to its ease of acquisition
from widely available devices. However, the generalization of PPG-based emotion
recognition models across individuals remains an unresolved challenge. This
paper introduces a novel hybrid architecture that combines Convolutional Neural
Networks (CNNs), Long Short-Term Memory networks (LSTMs), and Temporal
Convolutional Networks (TCNs) to address this issue. The proposed model
integrates the strengths of these architectures to improve robustness and
generalization. Raw PPG signals are fed into the CNN for feature extraction.
These features are processed separately by LSTM and TCN. The outputs from these
components are concatenated to generate a final feature representation, which
serves as the input for classifying valence and arousal, the primary dimensions
of emotion. Experiments using the Photoplethysmogram Dataset for Emotional
Analysis (PPGE) demonstrate that the proposed hybrid model achieves better
model generalization than standalone CNN and LSTM architectures. Our results
show that the proposed solution outperforms the state-of-the-art CNN
architecture, as well as a CNN-LSTM model, in emotion recognition tasks with
PPG signals. Using metrics such as Area Under the Curve (AUC) and F1 Score, we
highlight the model's effectiveness in handling subject variability.

</details>


### [558] [NeuroHD-RA: Neural-distilled Hyperdimensional Model with Rhythm Alignment](https://arxiv.org/abs/2507.14184)
*ZhengXiao He,Jinghao Wen,Huayu Li,Ao Li*

Main category: eess.SP

TL;DR: 提出了一种结合高维计算（HDC）和可学习神经编码的新颖可解释框架，用于心电图（ECG）疾病检测。该框架在 Apnea-ECG 数据集上取得了显著的性能提升。


<details>
  <summary>Details</summary>
Motivation: 为了解决传统 HDC 方法依赖静态、随机投影的问题，提出了一种新颖可解释的框架，该框架将高维计算（HDC）与可学习神经编码相结合。

Method: 提出了一种结合高维计算（HDC）和可学习神经编码的新颖可解释的框架。该方法引入了基于 RR 间隔（心脏周期的生理信号分割）的可训练编码流程，并采用了一个包含可学习 RR-block 编码器和 BinaryLinear 超维投影层的神经蒸馏 HDC 架构。

Result: 实验结果表明，该模型在 Apnea-ECG 数据集上显著优于传统 HDC 和经典机器学习基线，精度达到 73.09%，F1 分数达到 0.626，在 PTB-XL 数据集上具有可比的稳健性。

Conclusion: 该混合框架为边缘兼容的心电图分类提供了一种高效且可扩展的解决方案，在可解释和个性化健康监测方面具有巨大潜力。

Abstract: We present a novel and interpretable framework for electrocardiogram
(ECG)-based disease detection that combines hyperdimensional computing (HDC)
with learnable neural encoding. Unlike conventional HDC approaches that rely on
static, random projections, our method introduces a rhythm-aware and trainable
encoding pipeline based on RR intervals, a physiological signal segmentation
strategy that aligns with cardiac cycles. The core of our design is a
neural-distilled HDC architecture, featuring a learnable RR-block encoder and a
BinaryLinear hyperdimensional projection layer, optimized jointly with
cross-entropy and proxy-based metric loss. This hybrid framework preserves the
symbolic interpretability of HDC while enabling task-adaptive representation
learning. Experiments on Apnea-ECG and PTB-XL demonstrate that our model
significantly outperforms traditional HDC and classical ML baselines, achieving
73.09\% precision and an F1 score of 0.626 on Apnea-ECG, with comparable
robustness on PTB-XL. Our framework offers an efficient and scalable solution
for edge-compatible ECG classification, with strong potential for interpretable
and personalized health monitoring.

</details>


### [559] [Latent Sensor Fusion: Multimedia Learning of Physiological Signals for Resource-Constrained Devices](https://arxiv.org/abs/2507.14185)
*Abdullah Ahmed,Jeremy Gummeson*

Main category: eess.SP

TL;DR: 一种新的统一编码器利用传感器-潜在融合和压缩传感方法来高效、准确地分析多模态生理信号，尤其适用于资源受限的设备。


<details>
  <summary>Details</summary>
Motivation: 为了在资源受限的设备上进行生物信号分析，利用潜在空间来有效地总结数据，同时通过关系编码隐式地保留元信息。

Method: 利用传感器-潜在融合和基于自动编码器的潜在空间融合的压缩传感方法来分析和关联多模态生理信号。

Result: 实验结果表明，该统一编码器在速度、轻量化和可扩展性方面显著优于特定于模态的替代方案，同时保持了表示准确性。

Conclusion: 该统一编码器比特定于模态的替代方案更快、更轻、更具可扩展性，同时不损害表示准确性。

Abstract: Latent spaces offer an efficient and effective means of summarizing data
while implicitly preserving meta-information through relational encoding. We
leverage these meta-embeddings to develop a modality-agnostic, unified encoder.
Our method employs sensor-latent fusion to analyze and correlate multimodal
physiological signals. Using a compressed sensing approach with
autoencoder-based latent space fusion, we address the computational challenges
of biosignal analysis on resource-constrained devices. Experimental results
show that our unified encoder is significantly faster, lighter, and more
scalable than modality-specific alternatives, without compromising
representational accuracy.

</details>


### [560] [AI-Based Impedance Encoding-Decoding Method for Online Impedance Network Construction of Wind Farms](https://arxiv.org/abs/2507.14187)
*Xiaojuan Zhang,Tianyu Jiang,Haoxiang Zong,Chen Zhang,Chendan Li,Marta Molinas*

Main category: eess.SP

TL;DR: 该研究提出了一种AI驱动的阻抗压缩和重建技术，用于简化风电场阻抗网络模型的在线构建，并通过仿真验证了其效率和准确性。


<details>
  <summary>Details</summary>
Motivation: 为了解决阻抗网络（IN）模型在线应用困难的问题，该方法旨在通过压缩阻抗曲线数据，简化其传输过程，便于在线构建风电场IN模型。

Method: 提出了一种基于人工智能的阻抗编码-解码方法。首先训练一个阻抗编码器来压缩阻抗曲线，然后上传压缩数据并训练一个阻抗解码器来重构原始阻抗曲线。最后，基于节点导纳矩阵（NAM）方法获得风电场阻抗网络模型。

Result: 通过模型训练和实时仿真验证，证明了编码后的阻抗向量能够实现原始阻抗曲线的快速传输和精确重构。

Conclusion: 该方法通过编码和解码方法实现了阻抗曲线的压缩传输和精确重构，从而能够快速构建风电场阻抗网络模型，便于在线应用。

Abstract: The impedance network (IN) model is gaining popularity in the oscillation
analysis of wind farms. However, the construction of such an IN model requires
impedance curves of each wind turbine under their respective operating
conditions, making its online application difficult due to the transmission of
numerous high-density impedance curves. To address this issue, this paper
proposes an AI-based impedance encoding-decoding method to facilitate the
online construction of IN model. First, an impedance encoder is trained to
compress impedance curves by setting the number of neurons much smaller than
that of frequency points. Then, the compressed data of each turbine are
uploaded to the wind farm and an impedance decoder is trained to reconstruct
original impedance curves. At last, based on the nodal admittance matrix (NAM)
method, the IN model of the wind farm can be obtained. The proposed method is
validated via model training and real-time simulations, demonstrating that the
encoded impedance vectors enable fast transmission and accurate reconstruction
of the original impedance curves.

</details>


### [561] [Traffic Signal Phase and Timing Estimation with Large-Scale Floating Car Data](https://arxiv.org/abs/2507.14190)
*Mingcheng Liao,Zebang Feng,Miao Fan,Shengtong Xu,Haoyi Xiong*

Main category: eess.SP

TL;DR: 由于获取地面真实SPaT信息困难，FCD成为大规模SPaT分析的主要来源。现有方法过于简化，无法应对真实世界复杂性。本研究提出一个工业级FCD分析套件，能处理从数据预处理到SPaT估算的整个流程，估算信号相位、TOD时段和红绿灯时长，并在各种条件下表现出稳定性和鲁棒性。该系统已在中国大陆成功应用，分析海量数据，且估算精度高。


<details>
  <summary>Details</summary>
Motivation: 当前的FCD方法在SPaT估算中存在不足，因为它们通常简化问题，假设固定的时间表和基本的交叉口设计，未能考虑周期性信号变化、多样的交叉口结构以及真实世界数据的固有局限性，缺乏通用性。因此，需要一个更全面、更鲁棒的框架来解决这些问题。

Method: 提出一个工业级的FCD分析套件，包含从数据预处理到SPaT估算的完整流程。该方法能够估算信号相位、识别TOD时段、确定红灯和绿灯的持续时间，并强调了在不同条件下（无论道路几何形状如何）的稳定性和鲁棒性。

Result: 该研究提出的FCD分析套件能够稳定、鲁棒地估算SPaT信息，并已成功应用于实际导航平台。该系统每日处理超过1500万条FCD记录，支持中国大陆超过200万个交通信号灯，超过75%的估算误差小于5秒。

Conclusion: 该研究提出了一个工业级的浮动车数据（FCD）分析套件，用于从FCD中估算信号灯相位和时序（SPaT）。该系统能够处理数据预处理到SPaT估算的整个流程，包括估算信号相位、识别一天中的不同时段（TOD）以及确定红绿灯的持续时间。研究强调了该框架在各种条件下的稳定性和鲁棒性，不考虑道路几何形状的限制。目前该系统已在导航平台中运行，每日分析超过1500万条FCD记录，支持中国大陆超过200万个交通信号灯，其中超过75%的估算误差小于5秒。

Abstract: Effective modern transportation systems depend critically on accurate Signal
Phase and Timing (SPaT) estimation. However, acquiring ground-truth SPaT
information faces significant hurdles due to communication challenges with
transportation departments and signal installers. As a result, Floating Car
Data (FCD) has become the primary source for large-scale SPaT analyses. Current
FCD approaches often simplify the problem by assuming fixed schedules and basic
intersection designs for specific times and locations. These methods fail to
account for periodic signal changes, diverse intersection structures, and the
inherent limitations of real-world data, thus lacking a comprehensive framework
that is universally applicable. Addressing this limitation, we propose an
industrial-grade FCD analysis suite that manages the entire process, from
initial data preprocessing to final SPaT estimation. Our approach estimates
signal phases, identifies time-of-day (TOD) periods, and determines the
durations of red and green lights. The framework's notable stability and
robustness across diverse conditions, regardless of road geometry, is a key
feature. Furthermore, we provide a cleaned, de-identified FCD dataset and
supporting parameters to facilitate future research. Currently operational
within our navigation platform, the system analyses over 15 million FCD records
daily, supporting over two million traffic signals in mainland China, with more
than 75\% of estimations demonstrating less than five seconds of error.

</details>


### [562] [School Attendance Control System Based on RFID Technology with Raspberry Pi and Arduino: EDURFID](https://arxiv.org/abs/2507.14191)
*Cliver Oliver Turpo Benique*

Main category: eess.SP

TL;DR: EDURFID是一个基于RFID技术的自动化考勤系统，适用于秘鲁农村学校，实现了高精度、低成本和高效率。


<details>
  <summary>Details</summary>
Motivation: 为了解决秘鲁农村教育机构在考勤管理上面临的挑战，并提供一个比商业解决方案更具成本效益的自动化系统。

Method: EDURFID系统采用基于RFID技术的自动化学校考勤控制，整合了开源硬件（Raspberry Pi 5、Arduino UNO R3）和RC522 RFID模块（工作频率13.56 MHz），并使用Python Django开发的Web架构。

Result: 系统在RFID读取方面实现了100%的精度和0.03秒的响应时间，成本降低了94%。在T'upac Amaru中学教育机构的验证中，系统成功自动化了考勤流程，每天节省了50分钟的行政时间，并具备实时报告能力。

Conclusion: EDURFID系统成功自动化了考勤流程，为秘鲁农村教育机构提供了成本效益高且精确的解决方案。

Abstract: This paper presents EDURFID, an automated school attendance control system
based on RFID technology designed for rural educational institutions in Peru.
The system integrates open-source hardware (Raspberry Pi 5, Arduino UNO R3)
with RC522 RFID modules operating at 13.56 MHz, implementing a web architecture
developed in Python Django. The system demonstrates 100% precision in RFID
readings with 0.03-second response time, achieving 94% cost reduction compared
to commercial solutions. Validation at T\'upac Amaru Secondary Educational
Institution showed successful automation of attendance processes, saving 50
daily minutes of administrative time while providing real-time reporting
capabilities.

</details>


### [563] [Boosted Enhanced Quantile Regression Neural Networks with Spatiotemporal Permutation Entropy for Complex System Prognostics](https://arxiv.org/abs/2507.14194)
*David J Poland*

Main category: eess.SP

TL;DR: 本文提出了一种结合时空排列熵和BEQRNNs的框架，用于提高系统预后和模式预测的准确性和可靠性。


<details>
  <summary>Details</summary>
Motivation: 解决理解多维系统中复杂动态模式的挑战。

Method: 本文提出了一种新颖的框架，用于基于时空排列熵分析和增强分位数回归神经网络（BEQRNNs）的模式预测和系统预后。该方法结合了基于熵的复杂性度量和先进的神经架构，以应对多维系统中复杂动态模式的理解挑战。该系统采用双计算阶段：首先实现针对多尺度时间和空间数据流优化的时空熵提取，然后集成BEQRNN层，实现具有不确定性量化的概率模式预测。

Result: 该框架在时空模式分类中实现了81.17%的准确率，预测范围长达200个时间步，并在不同状态下保持稳健的性能。在混沌吸引子、反应扩散系统和工业数据集上的现场测试显示，关键转变检测准确率提高了79%，长期预测可靠性提高了81.22%。

Conclusion: 该框架在处理复杂、多模态熵特征方面表现出有效性，在实时预后应用方面具有巨大潜力。

Abstract: This paper presents a novel framework for pattern prediction and system
prognostics centered on Spatiotemporal Permutation Entropy analysis integrated
with Boosted Enhanced Quantile Regression Neural Networks (BEQRNNs). We address
the challenge of understanding complex dynamical patterns in multidimensional
systems through an approach that combines entropy-based complexity measures
with advanced neural architectures. The system leverages dual computational
stages: first implementing spatiotemporal entropy extraction optimized for
multiscale temporal and spatial data streams, followed by an integrated BEQRNN
layer that enables probabilistic pattern prediction with uncertainty
quantification. This architecture achieves 81.17% accuracy in spatiotemporal
pattern classification with prediction horizons up to 200 time steps and
maintains robust performance across diverse regimes. Field testing across
chaotic attractors, reaction-diffusion systems, and industrial datasets shows a
79% increase in critical transition detection accuracy and 81.22% improvement
in long-term prediction reliability. The framework's effectiveness in
processing complex, multimodal entropy features demonstrates significant
potential for real-time prognostic applications.

</details>


### [564] [UWB Radar-based Heart Rate Monitoring: A Transfer Learning Approach](https://arxiv.org/abs/2507.14195)
*Elzbieta Gruzewska,Pooja Rao,Sebastien Baur,Matthew Baugh,Mathias M. J. Bellaiche,Sharanya Srinivas,Octavio Ponce,Matthew Thompson,Pramod Rudrapatna,Michael A. Sanchez,Lawrence Z. Cai,Timothy JA Chico,Robert F. Storey,Emily Maz,Umesh Telang,Shravya Shetty,Mayank Daswani*

Main category: eess.SP

TL;DR: 雷达心率监测中的迁移学习：通过使用新颖的ResNet架构和迁移学习技术，本研究成功地实现了跨不同雷达系统（FMCW和IR-UWB）的心率监测，并显著提高了精度和效率，有望加速雷达技术在消费电子产品中的应用。


<details>
  <summary>Details</summary>
Motivation: 为了解决不同雷达系统需要收集新配对数据集的问题，本研究旨在演示不同雷达系统之间迁移学习的可行性，以实现连续、非接触、被动的心率监测。

Method: 本研究探索了频率调制连续波（FMCW）和脉冲超宽带（IR-UWB）雷达系统之间的迁移学习，并提出了一种新颖的二维+一维残差神经网络（ResNet）架构。

Result: 在FMCW雷达系统上，该模型实现了0.85 bpm的平均绝对误差（MAE）和1.42%的平均绝对百分比误差（MAPE），并且在不同的身体位置和心率范围内均保持了良好的性能。通过将该模型迁移到IR-UWB雷达系统，并在小规模IR-UWB数据集上进行微调，取得了MAE 4.1 bpm和MAPE 6.3%的性能，相比于基线模型MAE降低了25%。

Conclusion: 本研究证明了雷达系统之间在心率监测方面可以进行迁移学习，有潜力加速其在现有消费设备中的应用。

Abstract: Radar technology presents untapped potential for continuous, contactless, and
passive heart rate monitoring via consumer electronics like mobile phones.
However the variety of available radar systems and lack of standardization
means that a large new paired dataset collection is required for each radar
system. This study demonstrates transfer learning between frequency-modulated
continuous wave (FMCW) and impulse-radio ultra-wideband (IR-UWB) radar systems,
both increasingly integrated into consumer devices. FMCW radar utilizes a
continuous chirp, while IR-UWB radar employs short pulses. Our mm-wave FMCW
radar operated at 60 GHz with a 5.5 GHz bandwidth (2.7 cm resolution, 3
receiving antennas [Rx]), and our IR-UWB radar at 8 GHz with a 500 MHz
bandwidth (30 cm resolution, 2 Rx). Using a novel 2D+1D ResNet architecture we
achieved a mean absolute error (MAE) of 0.85 bpm and a mean absolute percentage
error (MAPE) of 1.42% for heart rate monitoring with FMCW radar (N=119
participants, an average of 8 hours per participant). This model maintained
performance (under 5 MAE/10% MAPE) across various body positions and heart rate
ranges, with a 98.9% recall. We then fine-tuned a variant of this model,
trained on single-antenna and single-range bin FMCW data, using a small (N=376,
avg 6 minutes per participant) IR-UWB dataset. This transfer learning approach
yielded a model with MAE 4.1 bpm and MAPE 6.3% (97.5% recall), a 25% MAE
reduction over the IR-UWB baseline. This demonstration of transfer learning
between radar systems for heart rate monitoring has the potential to accelerate
its introduction into existing consumer devices.

</details>


### [565] [Explainable Parallel CNN-LSTM Model for Differentiating Ventricular Tachycardia from Supraventricular Tachycardia with Aberrancy in 12-Lead ECGs](https://arxiv.org/abs/2507.14196)
*Zahra Teimouri-Jervekani,Fahimeh Nasimi,Mohammadreza Yazdchi,Ghazal MogharehZadeh,Javad Tezerji,Farzan Niknejad Mazandarani,Maryam Mohebbi*

Main category: eess.SP

TL;DR: 提出了一种新的深度学习模型，使用CNN和LSTM来区分心动过速类型，准确率超过95%，并且通过SHAP提供了可解释性，适用于临床应用。


<details>
  <summary>Details</summary>
Motivation: 鉴别宽QRS波心动过速（WCT）在临床上至关重要但具有挑战性，因为危及生命的心室心动过速（VT）和具有代偿性联律的室上性心动过速（SVT-A）之间的心电图（ECG）信号存在形态学相似性。误诊可能导致致命风险。我们提出了一种计算效率高的深度学习解决方案，以提高诊断准确性并为临床部署提供模型可解释性。

Method: 提出了一种新颖的轻量级并行深度架构。每个管道使用两个1D-CNN块处理单个ECG导联以提取局部特征。特征图跨导联连接，然后使用LSTM层捕获时间依赖性。最终分类采用全连接层。通过Shapley Additive Explanations（SHAP）实现可解释性，用于局部/全局解释。模型在35名受试者的ECG数据库上使用标准性能指标进行了评估。

Result: 模型实现了95.63%的准确率（95%置信区间：93.07-98.19%），敏感性=95.10%，特异性=96.06%，F1分数=95.12%。在准确性和计算效率方面均优于最先进的方法，每个管道所需的CNN块最少。SHAP分析证明了具有临床可解释性的特征贡献。

Conclusion: 本研究提出了一种端到端的框架，能够高精度地区分宽QRS波心动过速（WCT），同时计算开销极小。SHAP的集成通过阐明决策逻辑增强了临床信任度，支持快速、明智的诊断。该方法在实际心电图分析工具中显示出巨大潜力。

Abstract: Background and Objective: Differentiating wide complex tachycardia (WCT) is
clinically critical yet challenging due to morphological similarities in
electrocardiogram (ECG) signals between life-threatening ventricular
tachycardia (VT) and supraventricular tachycardia with aberrancy (SVT-A).
Misdiagnosis carries fatal risks. We propose a computationally efficient deep
learning solution to improve diagnostic accuracy and provide model
interpretability for clinical deployment.
  Methods: A novel lightweight parallel deep architecture is introduced. Each
pipeline processes individual ECG leads using two 1D-CNN blocks to extract
local features. Feature maps are concatenated across leads, followed by LSTM
layers to capture temporal dependencies. Final classification employs fully
connected layers. Explainability is achieved via Shapley Additive Explanations
(SHAP) for local/global interpretation. The model was evaluated on a 35-subject
ECG database using standard performance metrics.
  Results: The model achieved $95.63\%$ accuracy ($95\%$ CI: $93.07-98.19\%$),
with sensitivity=$95.10\%$, specificity=$96.06\%$, and F1-score=$95.12\%$. It
outperformed state-of-the-art methods in both accuracy and computational
efficiency, requiring minimal CNN blocks per pipeline. SHAP analysis
demonstrated clinically interpretable feature contributions.
  Conclusions: Our end-to-end framework delivers high-precision WCT
classification with minimal computational overhead. The integration of SHAP
enhances clinical trust by elucidating decision logic, supporting rapid,
informed diagnosis. This approach shows significant promise for real-world ECG
analysis tools.

</details>


### [566] [A Comprehensive Benchmark for Electrocardiogram Time-Series](https://arxiv.org/abs/2507.14206)
*Zhijiang Tang,Jiaxin Qi,Yuhua Zheng,Jianqiang Huang*

Main category: eess.SP

TL;DR: 本文提出了一个心电图信号的综合基准测试，包括新的评估任务、度量指标和模型架构，旨在解决现有研究对心电图信号特性的忽视问题。


<details>
  <summary>Details</summary>
Motivation: 现有的研究通常忽略了心电图信号的独特性质及其在特定下游应用中的特殊性，导致对其性质的理解不完整。

Method: 本文提出了一个包含（1）将下游应用分为四个不同的评估任务，（2）识别传统心电图分析评估指标的局限性并引入新的度量指标，（3）对最先进的时间序列模型进行基准测试并提出一种新架构的综合基准。

Result: 实验结果验证了所提出的度量和模型架构的有效性。

Conclusion: 本文提出的基准测试全面且稳健，所提出的度量和模型架构的有效性得到了验证，为推进心电图信号分析研究奠定了坚实的基础。

Abstract: Electrocardiogram~(ECG), a key bioelectrical time-series signal, is crucial
for assessing cardiac health and diagnosing various diseases. Given its
time-series format, ECG data is often incorporated into pre-training datasets
for large-scale time-series model training. However, existing studies often
overlook its unique characteristics and specialized downstream applications,
which differ significantly from other time-series data, leading to an
incomplete understanding of its properties. In this paper, we present an
in-depth investigation of ECG signals and establish a comprehensive benchmark,
which includes (1) categorizing its downstream applications into four distinct
evaluation tasks, (2) identifying limitations in traditional evaluation metrics
for ECG analysis, and introducing a novel metric; (3) benchmarking
state-of-the-art time-series models and proposing a new architecture. Extensive
experiments demonstrate that our proposed benchmark is comprehensive and
robust. The results validate the effectiveness of the proposed metric and model
architecture, which establish a solid foundation for advancing research in ECG
signal analysis.

</details>


### [567] [Toward intelligent wireless networks in computer chassis](https://arxiv.org/abs/2507.14208)
*Mohammadreza F. Imani,Alexander L. Colson,Leslie K. Miller,Jorge A. Valdez,Jose C. Sanchez,Richard F. Rader*

Main category: eess.SP

TL;DR: 通过使用RIS技术改造计算机机箱，解决了无线通信的干扰问题，提高了数据传输速率。


<details>
  <summary>Details</summary>
Motivation: 传统有线互连在计算机内部随着计算需求的增长而变得更长且效率降低，而短距离无线通信（SRWC）虽然灵活但面临多径散射导致的符号间干扰（ISI）问题，限制了数据速率。

Method: 提出利用可重构智能表面（RIS）调整反射波相位，使多径分量在接收端叠加形成类似脉冲的信道冲激响应（CIR），以应对计算机机箱内部短距离无线通信（SRWC）中的多径散射问题。

Result: 实验结果表明，该方法在典型计算机机箱内成功地将CIR改造成脉冲状，证实了其在增强计算机内部无线链路方面的潜力。

Conclusion: 本研究提出了利用可重构智能表面（RIS）将计算机机箱改造成智能无线电环境，以解决短距离无线通信（SRWC）中的多径散射和符号间干扰（ISI）问题，从而提高数据传输速率。实验已在典型计算机机箱内得到验证，为在数据处理单元中集成RIS支持的SRWC以增强无线链路提供了可能。

Abstract: Processing the exponentially growing amount of data produced daily requires
efficient communication between different processing units in a computer.
Traditionally, wired interconnects have been used to maintain these data links
due to their energy efficiency and ability to support high data rates. However,
as computing demands continue to increase in size and speed, these wired
interconnects can become longer and less effective. One possible solution is to
enhance the wired interconnects with short-range wireless communication (SRWC),
which offers flexible resource allocation and the ability to broadcast data.
However, implementing SRWC inside a computer chassis presents challenges due to
multiple scattering. This scattering stretches the channel impulse response
(CIR), leading to inter-symbol interference (ISI) and limiting data rates. To
address this issue, we propose transforming the computer chassis into a smart
radio environment by utilizing a reconfigurable intelligent surface (RIS). The
RIS elements adjust the phase of reflected waves so that the multipath
components combine at the receiver in a way that creates a pulse-like CIR. This
approach has been experimentally validated within a typical computer chassis.
The results of this study pave the way for integrating RIS-enabled SRWC to
enhance wireless links in both current and future data processing units.

</details>


### [568] [System Design and Performance Analysis for RIS-assisted Terahertz Self-Alignment Beamforming](https://arxiv.org/abs/2507.14210)
*Jiayuan Wei,Qingwei Jiang,Wen Fang,Mingqing Liu,Qingwen Liu,Wen Chen,Qingqing Wu*

Main category: eess.SP

TL;DR: 本文提出了一种基于RIS的太赫兹SWIPT系统，通过自对准波束成形和有源放大技术解决了波束未对准和路径损耗问题，提高了传输效率。


<details>
  <summary>Details</summary>
Motivation: 太赫兹SWIPT系统虽然具有超高数据速率和宽广带宽的优点，但其固有的窄波束特性导致路径损耗和波束未对准问题严重，需要可持续的无线解决方案来同时传输能量和信息。

Method: 提出了一种用于太赫兹SWIPT系统的可重构智能表面（RIS）辅助发射机架构，并利用相位共轭电路实现自对准波束成形，以及通过迭代功率循环进行有源放大以补偿级联信道衰减。

Result: 理论模型和仿真表明，该系统能够动态跟踪移动的物联网设备，无需进行波束训练，并有效补偿信道衰减，提升了能量传输效率。

Conclusion: 所提出的系统显著减轻了旁瓣干扰，并在2米距离上实现了高达73.26%的自对准传输效率。

Abstract: The widespread deployment of Internet of Things(IoT) devices underscores the
need for sustainable wireless solutions capable of simultaneously transferring
both energy and information. Terahertz (THz) band-enabled simultaneous wireless
information and power transfer (SWIPT) systems offer ultra-high data rates and
expansive bandwidth. However, THz waves are inherently susceptible to severe
path loss and beam misalignment due to their narrow-beam characteristics. In
this context, this paper proposes a reconfigurable intelligent
surface(RIS)-assisted transmitter architecture for the THz-SWIPT system, which
enables end-to-end self-alignment for steady-state transmission. The proposed
system incorporates phase conjugate circuits to achieve self-aligned
beamforming, facilitating the dynamic tracking of mobile IoT devices without
the need for beam training. Additionally, active amplification within the RIS
arrays compensates for cascaded channel attenuation through an iterative power
cycle, thereby enhancing the energy transmission efficiency. Theoretical models
and simulations indicate that the proposed system significantly mitigates
sidelobe interference, achieving a transmission efficiency of up to 73.26% over
a 2 meter distance with self-alignment.

</details>


### [569] [Distributed Machine Learning Approach for Low-Latency Localization in Cell-Free Massive MIMO Systems](https://arxiv.org/abs/2507.14216)
*Manish Kumar,Tzu-Hsuan Chou,Byunghyun Lee,Nicolò Michelusi,David J. Love,Yaguang Zhang,James V. Krogmeier*

Main category: eess.SP

TL;DR: 一种用于蜂窝网络的分布式机器学习定位框架，可实现低延迟和高精度。


<details>
  <summary>Details</summary>
Motivation: 为了在蜂窝网络中实现支持实时应用所需的低延迟定位。

Method: 提出了一种基于指纹定位的分布式机器学习框架，其中每个接入点（AP）独立训练高斯过程回归模型，利用局部到达角和接收信号强度指纹，然后由用户设备（UE）融合这些模型以获得最终的位置估计。

Result: 所提出的分布式框架实现了与集中式方法相当的定位准确性，并减少了位置估计的不确定性（如95%协方差椭圆所示）。

Conclusion: 分布式机器学习框架在蜂窝网络中实现了低延迟、高精度的定位，其准确性可与集中式方法相媲美，并减少了位置估计的不确定性。

Abstract: Low-latency localization is critical in cellular networks to support
real-time applications requiring precise positioning. In this paper, we propose
a distributed machine learning (ML) framework for fingerprint-based
localization tailored to cell-free massive multiple-input multiple-output
(MIMO) systems, an emerging architecture for 6G networks. The proposed
framework enables each access point (AP) to independently train a Gaussian
process regression model using local angle-of-arrival and received signal
strength fingerprints. These models provide probabilistic position estimates
for the user equipment (UE), which are then fused by the UE with minimal
computational overhead to derive a final location estimate. This decentralized
approach eliminates the need for fronthaul communication between the APs and
the central processing unit (CPU), thereby reducing latency. Additionally,
distributing computational tasks across the APs alleviates the processing
burden on the CPU compared to traditional centralized localization schemes.
Simulation results demonstrate that the proposed distributed framework achieves
localization accuracy comparable to centralized methods, despite lacking the
benefits of centralized data aggregation. Moreover, it effectively reduces
uncertainty of the location estimates, as evidenced by the 95\% covariance
ellipse. The results highlight the potential of distributed ML for enabling
low-latency, high-accuracy localization in future 6G networks.

</details>


### [570] [Advanced Space Mapping Technique Integrating a Shared Coarse Model for Multistate Tuning-Driven Multiphysics Optimization of Tunable Filters](https://arxiv.org/abs/2507.14220)
*Haitian Hu,Wei Zhang,Feng Feng,Zhiguo Zhang,Qi-Jun Zhang*

Main category: eess.SP

TL;DR: 一种新的空间映射技术，通过共享的电磁粗略模型和映射神经网络，实现了对可调谐滤波器的多物理场优化，提高了精度并降低了计算成本。


<details>
  <summary>Details</summary>
Motivation: 针对可调谐滤波器的多物理场优化问题，提出一种能够同时处理多状态调谐需求的高效建模方法。

Method: 提出了一种改进的空间映射（SM）技术，该技术采用共享的、基于电磁（EM）的粗略模型，用于多状态调谐驱动的多物理场优化。该SM方法结合了EM单物理场仿真的计算效率和多物理场仿真的精确度。共享粗略模型基于对应于各种不可调设计参数值的EM单物理场响应。相反，精细模型用于描述多物理场响应与不可调和可调设计参数值之间的关系。提出的整体代理模型由多个子代理模型组成，每个子代理模型包含一个共享的粗略模型和两个不同的映射神经网络。

Result: 所提出的代理模型由多个子代理模型组成，每个子代理模型由一个共享的粗略模型和两个映射神经网络组成，能够实现高效且精确的多物理场建模，并同时优化所有调谐状态。

Conclusion: 与现有的直接多物理场参数化建模技术相比，我们提出的方法在训练样本更少、计算成本更低的情况下，实现了更高的多物理场建模精度。

Abstract: This article introduces an advanced space mapping (SM) technique that applies
a shared electromagnetic (EM)-based coarse model for multistate tuning-driven
multiphysics optimization of tunable filters. The SM method combines the
computational efficiency of EM single-physics simulations with the precision of
multiphysics simulations. The shared coarse model is based on EM single-physics
responses corresponding to various nontunable design parameters values.
Conversely, the fine model is implemented to delineate the behavior of
multiphysics responses concerning both nontunable and tunable design parameter
values. The proposed overall surrogate model comprises multiple subsurrogate
models, each consisting of one shared coarse model and two distinct mapping
neural networks. The responses from the shared coarse model in the EM
single-physics filed offer a suitable approximation for the fine responses in
the multiphysics filed, whereas the mapping neural networks facilitate
transition from the EM single-physics field to the multiphysics field. Each
subsurrogate model maintains consistent nontunable design parameter values but
possesses unique tunable design parameter values. By developing multiple
subsurrogate models, optimization can be simultaneously performed for each
tuning state. Nontunable design parameter values are constrained by all tuning
states, whereas tunable design parameter values are confined to their
respective tuning states. This optimization technique simultaneously accounts
for all the tuning states to fulfill the necessary multiple tuning state
requirements. Multiple EM and multiphysics training samples are generated
concurrently to develop the surrogate model. Compared with existing direct
multiphysics parameterized modeling techniques, our proposed method achieves
superior multiphysics modeling accuracy with fewer training samples and reduced
computational costs.

</details>


### [571] [Diffusion-based translation between unpaired spontaneous premature neonatal EEG and fetal MEG](https://arxiv.org/abs/2507.14224)
*Benoît Brebion,Alban Gallard,Katrin Sippel,Amer Zaylaa,Hubert Preissl,Sahar Moghimi,Fabrice Wallois,Yaël Frégier*

Main category: eess.SP

TL;DR: 本研究利用人工智能和双扩散桥技术，成功地将脑电图（EEG）的知识转移到胎儿脑磁图（fMEG）上，提高了产前大脑活动分析的准确性和效率，为早期检测和治疗脑部疾病提供了新的可能性。


<details>
  <summary>Details</summary>
Motivation: 由于大脑发育始于胎儿期，而这一过程的关键窗口在很大程度上仍然未知。唯一能够在宫内环境中记录神经活动的技术是胎儿脑磁图（fMEG），但这种方法在数据质量和稀缺性方面存在挑战。本研究旨在利用人工智能将从脑电图研究中获得的成熟知识转移到胎儿脑磁图中，以增进对产前大脑发育的理解，并为更好地检测和治疗潜在病理奠定基础。

Method: 开发了一种基于双扩散桥的不成对扩散转换方法，该方法包括数值积分改进，以在较低的计算成本下获得更高质量的结果。模型在来自30名高分辨率早产新生儿脑电图记录和44名胎儿脑磁图记录的自发活动爆发的不成对数据集上进行了训练。

Result: 所开发的方法在均方误差和模态崩溃问题上均优于生成对抗网络（GANs），分别提高了近5%和完全消除了模态崩溃问题，实现了近乎完美的信号保真度。

Conclusion: 本研究在不成对的脑电图到胎儿脑磁图转换问题上达到了新的技术水平，所开发的工具为早期大脑活动分析铺平了道路。此外，我们相信该方法还可以用于其他不成对信号转换应用。

Abstract: Background and objective: Brain activity in premature newborns has
traditionally been studied using electroencephalography (EEG), leading to
substantial advances in our understanding of early neural development. However,
since brain development takes root at the fetal stage, a critical window of
this process remains largely unknown. The only technique capable of recording
neural activity in the intrauterine environment is fetal magnetoencephalography
(fMEG), but this approach presents challenges in terms of data quality and
scarcity. Using artificial intelligence, the present research aims to transfer
the well-established knowledge from EEG studies to fMEG to improve
understanding of prenatal brain development, laying the foundations for better
detection and treatment of potential pathologies. Methods: We developed an
unpaired diffusion translation method based on dual diffusion bridges, which
notably includes numerical integration improvements to obtain more qualitative
results at a lower computational cost. Models were trained on our unpaired
dataset of bursts of spontaneous activity from 30 high-resolution premature
newborns EEG recordings and 44 fMEG recordings. Results: We demonstrate that
our method achieves significant improvement upon previous results obtained with
Generative Adversarial Networks (GANs), by almost 5% on the mean squared error
in the time domain, and completely eliminating the mode collapse problem in the
frequency domain, thus achieving near-perfect signal fidelity. Conclusion: We
set a new state of the art in the EEG-fMEG unpaired translation problem, as our
developed tool completely paves the way for early brain activity analysis.
Overall, we also believe that our method could be reused for other unpaired
signal translation applications.

</details>


### [572] [Design of A New Multiple-Chirp-Rate Index Modulation for LoRa Networks](https://arxiv.org/abs/2507.14228)
*Xiaobin Zhu,Minling Zhang,Guofa Cai,Jiguang He,Georges Kaddoum*

Main category: eess.SP

TL;DR: 提出了一种新的MCR-IM系统，它使用ZC序列来提高LoRa网络的传输速率和接入容量。该系统具有低互相关性、高频谱效率和低误比特率。引入PD-SIC算法进一步解决了多用户干扰问题，提高了吞吐量，使其成为大规模、高吞吐量LoRa应用的理想选择。


<details>
  <summary>Details</summary>
Motivation: 解决传统LoRa网络传输速率低和大容量接入的问题。

Method: 提出了一种基于Zadoff-Chu（ZC）序列的MCR-IM系统，并推导了其在Nakagami-m衰落信道下的误比特率（BER）近似闭合表达式。为了处理用户数量增加导致的多用户干扰问题，还提出了一种基于峰值检测的连续干扰抵消（PD-SIC）算法。

Result: MCR-IM系统具有极低的互相关性，继承了ZC序列调制的特性。仿真结果验证了BER闭合表达式的准确性，并表明MCR-IM系统比现有系统具有更高的频谱效率（SE）。与OrthoRa系统相比，MCR-IM系统在PD-SIC算法的加持下，BER更低，在相似的信号碰撞数下，吞吐量提升了16%到21%。

Conclusion: MCR-IM系统非常适合大规模、高吞吐量的LoRa网络应用，其性能优于OrthoRa系统，并能提高吞吐量。

Abstract: We propose a multiple chirp rate index modulation (MCR-IM) system based on
Zadoff-Chu (ZC) sequences that overcomes the problems of low transmission rate
and large-scale access in classical LoRa networks. We demonstrate the extremely
low cross-correlation of MCR-IM signals across different spread factors,
showing that the proposed MCR-IM system also inherits the characteristics of ZC
sequences modulation. Moreover, we derive an approximate closed-form expression
for the bit-error rate (BER) of the proposed MCR-IM system over Nakagami-m
fading channels. Simulation results confirm the accuracy of the derived
closed-form expression and demonstrate that the MCR-IM system achieves higher
levels of spectral efficiency (SE) compared to existing systems. In this
context, assigning multiple chirp rates to each user results in a reduction in
the number of parallel channels. To mitigate this issue, we propose a peak
detection based successive interference cancellation (PD-SIC) algorithm to
accommodate more users. Compared to orthogonal scatter chirp spreading spectrum
system that names OrthoRa, the MCR-IM system with PD-SIC algorithm achieves
lower BER levels. For a similar number of collision signals, the throughput of
the MCR-IM system is enhanced by 16% to 21%. Owing to these advantages, the
proposed MCR-IM is well suited for large-scale, high-rate LoRa network
applications.

</details>


### [573] [Age of Information Minimization in UAV-Enabled Integrated Sensing and Communication Systems](https://arxiv.org/abs/2507.14299)
*Yu Bai,Yifan Zhang,Boxuan Xie,Zheng Chang,Yanru Zhang,Riku Jantti,Zhu Han*

Main category: eess.SP

TL;DR: 本文提出了一种新颖的无人机-ISAC系统，利用深度强化学习来优化无人机轨迹和波束成形，以最小化信息年龄（AoI），同时平衡感知和通信性能。


<details>
  <summary>Details</summary>
Motivation: 为了解决在严格的资源限制和时间关键条件下，联合优化无人机轨迹规划、多用户通信和目标感知这一重大挑战。

Method: 本文提出了一种以信息年龄（AoI）为中心的无人机-ISAC系统，并开发了一种基于深度强化学习（DRL）的算法。该算法利用卡尔曼滤波器进行目标状态预测，采用正则化零强制（RZF）来减轻用户间干扰，并应用软Actor-Critic（SAC）算法来训练DRL智能体处理连续动作，以联合优化无人机的飞行轨迹和波束成形。

Result: 实验结果表明，与现有方法相比，所提出的方法在最小化平均AoI方面表现更优。

Conclusion: 所提出的基于DRL的框架能够自适应地平衡感知准确性和通信质量，并且与基线方法相比，能够持续实现更低的平均信息年龄（AoI）。

Abstract: Unmanned aerial vehicles (UAVs) equipped with integrated sensing and
communication (ISAC) capabilities are envisioned to play a pivotal role in
future wireless networks due to their enhanced flexibility and efficiency.
However, jointly optimizing UAV trajectory planning, multi-user communication,
and target sensing under stringent resource constraints and time-critical
conditions remains a significant challenge. To address this, we propose an Age
of Information (AoI)-centric UAV-ISAC system that simultaneously performs
target sensing and serves multiple ground users, emphasizing information
freshness as the core performance metric. We formulate a long-term average AoI
minimization problem that jointly optimizes the UAV's flight trajectory and
beamforming. To tackle the high-dimensional, non-convexity of this problem, we
develop a deep reinforcement learning (DRL)-based algorithm capable of
providing real-time decisions on UAV movement and beamforming for both radar
sensing and multi-user communication. Specifically, a Kalman filter is employed
for accurate target state prediction, regularized zero-forcing is utilized to
mitigate inter-user interference, and the Soft Actor-Critic algorithm is
applied for training the DRL agent on continuous actions. The proposed
framework adaptively balances the trade-offs between sensing accuracy and
communication quality. Extensive simulation results demonstrate that our
proposed method consistently achieves lower average AoI compared to baseline
approaches.

</details>


### [574] [Fast and Robust Stationary Crowd Counting with Commodity WiFi](https://arxiv.org/abs/2507.14309)
*Mert Torun,Alireza Parsay,Yasamin Mostofi*

Main category: eess.SP

TL;DR: 本研究利用WiFi信号和人体抖动行为，通过新颖的数学模型和异常检测技术，实现了对坐姿人群的快速、准确和稳健的统计。


<details>
  <summary>Details</summary>
Motivation: 本研究旨在利用日常生活中普遍存在的WiFi信号和人体自然抖动行为，开发一种被动、无感且准确的人群统计方法，以解决传统人群统计方法的局限性。

Method: 本研究提出了一种利用WiFi信号和人体自然抖动行为来估计坐姿人群数量的新方法。该方法将接收信号的带宽作为衡量人群数量的精细且鲁棒的指标，并建立了信号带宽概率密度函数（PDF）与人群数量之间的数学模型。具体来说，首先通过公开视频提取个体抖动行为的身体运动信息，并借鉴卡森法则将速度转换为带宽。接着，为了提高在真实场景中的鲁棒性，引入了异常检测模块来过滤掉非抖动运动。

Result: 通过在两种室内环境中进行的42次实验，该系统在最多13人的情况下，实现了1.04人的平均绝对误差和0.15的归一化均方根误差，平均收敛时间为51秒，显著优于现有技术。此外，模拟结果也表明该方法具有良好的可扩展性，能够适应更大规模的人群。

Conclusion: 本研究提出的方法能够快速、稳健且高精度地统计坐姿人群的数量，并通过大量实验证明了其有效性。

Abstract: This paper introduces a novel method for estimating the size of seated crowds
with commodity WiFi signals, by leveraging natural body fidgeting behaviors as
a passive sensing cue. Departing from prior binary fidget representations, our
approach leverages the bandwidth of the received signal as a finer-grained and
robust indicator of crowd counts. More specifically, we propose a mathematical
model that relates the probability density function (PDF) of the signal
bandwidth to the crowd size, using a principled derivation based on the PDF of
an individual's fidget-induced bandwidth. To characterize the individual
fidgeting PDF, we use publicly available online videos, each of a seated
individual, from which we extract body motion profiles using vision techniques,
followed by a speed-to-bandwidth conversion inspired by Carson's Rule from
analog FM radio design. Finally, to enhance robustness in real-world
deployments where unrelated motions may occur nearby, we further introduce an
anomaly detection module that filters out non-fidget movements. We validate our
system through 42 experiments across two indoor environments with crowd sizes
up to and including 13 people, achieving a mean absolute error of 1.04 and a
normalized mean square error of 0.15, with an average convergence time of 51
seconds, significantly reducing the convergence time as compared to the state
of the art. Additional simulation results demonstrate scalability to larger
crowd sizes. Overall, our results show that our pipeline enables fast, robust,
and highly accurate counting of seated crowds.

</details>


### [575] [Optimizing Network Performance and Resource Allocation in HAPS-UAV Integrated Sensing and Communication Systems for 6G](https://arxiv.org/abs/2507.14310)
*Parisa Kanani,Mohammad Javad Omidi,Mahmoud Modarres-Hashemi,Halim Yanikomeroglu*

Main category: eess.SP

TL;DR: 该研究提出了一种利用无人机作为基站、高空平台作为CPU的6G ISAC系统，通过优化功率和波束以提升通信和感知性能，并实现节能。


<details>
  <summary>Details</summary>
Motivation: 为了解决6G网络下集成传感与通信（ISAC）系统在优化位置和功率控制方面的挑战，并利用无人机（UAVs）作为基站（BS）和高空平台（HAPS）作为中央处理单元（CPU）来增强无线覆盖，特别是在偏远地区。

Method: 提出了一种利用无人机作为基站（BS），高空平台（HAPS）作为中央处理单元（CPU）的集成传感与通信（ISAC）系统。系统在两个时隙内运行：无人机传输通信和传感信号，并接收目标反射信号；然后将信号中继给HAPS，HAPS进行波束成形。无人机接收HAPS解码信息并调整传输以最大化波束模式效率。通过多目标优化问题，最大化用户的最小信干噪比（SINR）和目标的 the echo signal power，并优化无人机的功率分配和波束模式增益。

Result: 仿真结果表明，该方法在增强网络性能、资源分配、公平性和系统优化方面是有效的。

Conclusion: 该方法通过结合高空平台和无人机，实现了通信和感知一体化，在提高无线覆盖、网络性能、资源分配、公平性和系统优化方面表现出优越性，特别是通过将高空平台作为CPU，有效降低了无人机的能耗。

Abstract: This paper proposes an innovative approach by leveraging uncrewed aerial
vehicles (UAVs) as base stations (BSs) and a high-altitude platform station
(HAPS) as the central processing unit (CPU) in an integrated sensing and
communication (ISAC) system for 6G networks. We explore the challenges,
applications, and advantages of ISAC systems in next-generation networks,
highlighting the significance of optimizing position and power control. Our
approach integrates HAPS and UAVs to enhance wireless coverage, particularly in
remote areas. UAVs function as dual-purpose access points (APs), using their
maneuverability and line-of-sight (LoS) aerial-to-ground (A2G) links to
transmit combined communication and sensing signals. The scheme operates in two
time slots: in the first slot, UAVs transmit dedicated signals to communication
users (CUs) and potential targets. UAVs detect targets in specific ground
locations and, after signal transmission, receive reflected signals from
targets. In the second slot, UAVs relay these signals to HAPS, which performs
beamforming to align signals for each CU from various UAVs. UAVs decode
information from HAPS and adjust transmissions to maximize the beam pattern
efficiency toward the desired targets. We formulate a multi-objective
optimization problem to maximize both the minimum
signal-to-interference-plus-noise ratio (SINR) for CUs and the echo signal
power from the targets. This is achieved by finding the optimal power
allocation for CUs in each UAV, subject to constraints on the maximum total
power in each UAV and the transmitted beam pattern gain. Simulation results
demonstrate the effectiveness of this approach in enhancing network
performance, resource allocation, fairness, and system optimization. Using HAPS
as the CPU, computational tasks are offloaded from UAVs, which conserves energy
and improves network performance.

</details>


### [576] [Spatially tailored spin wave excitation for spurious-free, low-loss magnetostatic wave filters with ultra-wide frequency tunability](https://arxiv.org/abs/2507.14469)
*Shuxian Wu,Shun Yao,Xingyu Du,Chin-Yu Chang,Roy H. Olsson III*

Main category: eess.SP

TL;DR: A novel half-cone transducer effectively suppresses spurious modes in YIG MSW RF cavity filters, enabling wider tuning ranges and improved performance for 6G networks.


<details>
  <summary>Details</summary>
Motivation: Spurious modes in Yttrium iron garnet magnetostatic wave (MSW) radio frequency (RF) cavity filters degrade performance in 6G communication systems. This work aims to suppress these spurious modes to improve filter performance.

Method: A half-cone transducer is proposed to spatially tailor spin wave excitation, selectively enhancing primary cavity modes and suppressing spurious modes in Yttrium iron garnet magnetostatic wave (MSW) radio frequency (RF) cavity filters. The effectiveness of this technique is verified through theoretical analysis, numerical simulations, and experiments.

Result: A spurious-free, single-cavity half-cone MSW filter (HC-MSWF) was demonstrated with an insertion loss (IL) of 2.4-3.2 dB over a frequency tuning range of 6.3-16.8 GHz. A spurious-free, dual-cavity HC-MSWF was further demonstrated with an unprecedented tuning range of 21.7 GHz (9.8-31.5 GHz) while maintaining a low IL of 2.9-3.8 dB.

Conclusion: Yttrium iron garnet magnetostatic wave (MSW) radio frequency (RF) cavity filters are promising for sixth-generation (6G) communication systems due to their wide frequency tunability. However, the presence of severe spurious modes arising from the finite cavity dimensions severely degrades the filter performance. We present a half-cone transducer that spatially tailors spin wave excitation to selectively enhance the primary cavity modes comprising the MSW filter passband, while strongly suppressing the undesired spurious modes. Theoretical analysis, numerical simulations and experiments verify the effectiveness of the spatially tailored technique. We utilize the half-cone transducer to demonstrate a spurious-free, single-cavity half-cone MSW filter (HC-MSWF) with an insertion loss (IL) of 2.4-3.2 dB over a frequency tuning range of 6.3-16.8 GHz. Extending our study, we further demonstrate a spurious-free, dual-cavity HC-MSWF with an unprecedented tuning range of 21.7 GHz (9.8-31.5 GHz) while maintaining a low IL of 2.9-3.8 dB. This significant advance in performance will enable highly reconfigurable and robust 6G networks.

Abstract: Yttrium iron garnet magnetostatic wave (MSW) radio frequency (RF) cavity
filters are promising for sixth-generation (6G) communication systems due to
their wide frequency tunability. However, the presence of severe spurious modes
arising from the finite cavity dimensions severely degrades the filter
performance. We present a half-cone transducer that spatially tailors spin wave
excitation to selectively enhance the primary cavity modes comprising the MSW
filter passband, while strongly suppressing the undesired spurious modes.
Theoretical analysis, numerical simulations and experiments verify the
effectiveness of the spatially tailored technique. We utilize the half-cone
transducer to demonstrate a spurious-free, single-cavity half-cone MSW filter
(HC-MSWF) with an insertion loss (IL) of 2.4-3.2 dB over a frequency tuning
range of 6.3-16.8 GHz. Extending our study, we further demonstrate a
spurious-free, dual-cavity HC-MSWF with an unprecedented tuning range of 21.7
GHz (9.8-31.5 GHz) while maintaining a low IL of 2.9-3.8 dB. This significant
advance in performance will enable highly reconfigurable and robust 6G
networks.

</details>


### [577] [Propagation Channel Modeling for LEO Satellite Missions Using Ray-Tracing Simulations](https://arxiv.org/abs/2507.14622)
*Wahab Khawaja,Ismail Guvenc,Rune Hylsberg Jacobsen*

Main category: eess.SP

TL;DR: 本文提出了一种X波段低地球轨道（LEO）卫星到地面链路的信道模型，考虑了仰角、地形、天气和天线失配等因素。


<details>
  <summary>Details</summary>
Motivation: 为了提供X波段卫星到地面传播的综合性、考虑仰角变化的信道模型，该研究整合了射线追踪环境动态、仰角相关的衰落以及相控阵波束失配效应。

Method: 利用Wireless InSite软件进行仿真，开发了参数化信道模型，该模型能够表征不同卫星仰角下的宏观和微观衰落效应。宏观衰落考虑了地形阴影和天气条件等动态环境因素造成的衰减，并与3GPP NTN信道模型进行了比较。同时，量化了地面站（GS）天线失配（包括固定单阵元和电子扫描相控阵天线）导致的链路退化。微观衰落则通过在不同卫星仰角下拟合有阴影和无阴影的莱斯分布来建模。

Result: 研究结果为X波段低地球轨道（LEO）卫星到地面链路提供了高分辨率的信道模型，能够表征不同卫星仰角下的宏观和微观衰落效应，并考虑了地形、天气和天线失配等因素。

Conclusion: 本文提出了一种用于X波段郊区环境中低地球轨道（LEO）卫星到地面链路的高分辨率、基于射线追踪的信道建模方法，并进行了相应的分析。

Abstract: This work presents a high-resolution, ray-tracing-based channel modeling for
Low Earth Orbit (LEO) satellite-to-ground links in a suburban environment at
X-band. Using simulations conducted in Wireless InSite, we develop a parametric
channel model that characterizes both large- and small-scale fading effects
across different satellite elevation angles. Large-scale fading incorporates
attenuation due to terrain-induced shadowing and dynamic environmental factors
such as weather conditions, and is compared with 3GPP NTN channel model.
Additionally, we quantify link degradation resulting from ground station (GS)
antenna misalignment, considering both fixed single-element and electronically
steerable phased-array antennas. Small-scale fading is modeled by fitting a
shadowed and non-shadowed Rician distribution to the fading statistics at
various satellite elevations. To the best of our knowledge, this is the first
study to propose a comprehensive elevation-aware channel model for
satellite-to-ground propagation at X-band, integrating ray-traced environmental
dynamics, elevation-dependent fading, and phased-array beam misalignment
effects.

</details>


### [578] [Movable-Element STARS-Aided Secure Communications](https://arxiv.org/abs/2507.14804)
*Jingjing Zhao,Qian Xu,Kaiquan Cai,Yanbo Zhu,Xidong Mu,Yuanwei Liu*

Main category: eess.SP

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: A novel movable-element (ME) enabled simultaneously transmitting and
reflecting surface (ME-STARS)-aided secure communication system is
investigated. Against the full-space eavesdropping, MEs are deployed at the
STARS for enhancing the physical layer security by exploiting higher spatial
degrees of freedom. Specifically, a sum secrecy rate maximization problem is
formulated, which jointly optimizes the passive beamforming and the MEs
positions at the ME-STARS, as well as the active beamforming at the base
station. To solve the resultant non-convex optimization problem involving
highly-coupled variables, an alternating optimization-based iterative algorithm
is developed, decomposing the original problem into three subproblems. In
particular, for the MEs position optimization subproblem, a gradient ascent
algorithm is employed to iteratively refine the MEs' locations within the
confined region. Moreover, the the active and passive beamforming subproblems
are solved by employing successive convex approximation. Numerical results
unveil that: 1) ME-STARS significantly improves the secrecy performance
compared to the conventional STARS with fixed-position elements; and 2) The
secrecy rate achieved by the ME-STARS gets saturated within limited movable
region size.

</details>


### [579] [Pinching-Antenna-based Communications: Spectral Efficiency Analysis and Deployment Strategies](https://arxiv.org/abs/2507.14831)
*Mengyu Qian,Xidong Mu,Li You,Michail Matthaiou*

Main category: eess.SP

TL;DR: 本文研究了基于多波导捏合天线（PA）的多用户通信系统，比较了集中式和分布式两种部署策略的性能。结果表明，高信噪比下分布式部署优于集中式部署，而低信噪比下集中式部署更优。


<details>
  <summary>Details</summary>
Motivation: 为了研究基于多波导捏合天线（PA）的多用户通信系统的性能，并比较两种部署策略（集中式和分布式）的优劣。

Method: 1. 集中式部署：首先通过优化 PA 在波导上的位置来最大化最近用户的信道增益，然后推导系统谱效率。 2. 分布式部署：在最大比传输（MRT）下获得系统谱效率，并利用平稳相位法进行近似，以获得可解析处理的形式。

Result: 分析表明，在 АСН（高信噪比）下，分布式部署的系统谱效率更高；而在低信噪比下，集中式部署更具优势。理论分析通过仿真得到验证。

Conclusion: 在两种部署策略的比较中，分布式部署在 АСН（高信噪比）下能够实现更高的系统谱效率，而集中式部署则更适用于低信噪比场景。

Abstract: A multiple-waveguide pinching-antenna (PA)-based multi-user communication
system is investigated. With a given number of PAs, two deployment strategies
are considered, namely the centralized PA deployment, where all PAs are
switched between waveguides to serve users in a time-division manner to avail
of beamforming gain, and the distributed PA deployment, where a single PA is
deployed on each waveguide to simultaneously serve multiple users by leveraging
the multiplexing gain. The spectral efficiency (SE) achieved by each deployment
strategy is analyzed: i) For the centralized deployment, the positioning
strategy of PAs on each waveguide is determined first with the aim of
maximizing the channel gain of the corresponding nearest served user. Based on
this, the corresponding system SE is derived. ii) For the distributed
deployment, the system SE under the maximum ratio transmission (MRT) is first
obtained. To obtain an analytically tractable form, the stationary phase method
is utilized to approximate the system SE. The approximation result reveals that
the average inter-user interference can be negligible with a large waveguide
spacing and thus the simple MRT is appealing for PA-based multi-user
communications. Furthermore, the system SEs achieved by the two strategies are
compared in both the high and low signal-to-noise ratio (SNR) regimes. Our
analysis suggests that at high SNRs, the distributed deployment is superior to
achieve the maximal system SE, while the centralized deployment is more
suitable for the low-SNR regime. Finally, the theoretical analysis is verified
through simulations.

</details>


### [580] [Integrated Radio Sensing Capabilities for 6G Networks: AI/ML Perspective](https://arxiv.org/abs/2507.14856)
*Victor Shatov,Steffen Schieler,Charlotte Muth,José Miguel Mateos-Ramos,Ivo Bizon,Florian Euchner,Sebastian Semper,Stephan ten Brink,Gerhard Fettweis,Christian Häger,Henk Wymeersch,Laurent Schmalen,Reiner Thomä,Norman Franchi*

Main category: eess.SP

TL;DR: 本文对AI和ML在6G无线网络中的应用进行了教程式调查，重点介绍了AI和ML在增强传感能力方面的作用，并讨论了这些技术在ISAC框架下的应用，包括雷达、频谱传感和非合作发射机定位等。


<details>
  <summary>Details</summary>
Motivation: 第六代无线通信（6G）被称为“互联智能”。无线传感与机器学习（ML）和人工智能（AI）相结合，有望在感知环境和有效利用这种意识方面取得突破。

Method: 本文是AI和ML方法在下一代无线网络中的传感能力应用的教程式调查。我们扩展了“传感”的定义，包括雷达、频谱传感和非合作发射机定位等多种无线传感应用。我们还制定了问题，解释了现有方法，并详细介绍了基于AI的技术，以应对无线传感中的各种目标。

Result: 文章讨论了将各种传感能力集成到设想的、由AI驱动的多模态多任务网络中的优势、推动因素和挑战。

Conclusion: AI和ML方法可以增强下一代无线网络的传感能力，并已成功应用于各种无线传感目标。

Abstract: The sixth-generation wireless communications (6G) is often labeled as
"connected intelligence". Radio sensing, aligned with machine learning (ML) and
artificial intelligence (AI), promises, among other benefits, breakthroughs in
the system's ability to perceive the environment and effectively utilize this
awareness. This article offers a tutorial-style survey of AI and ML approaches
to enhance the sensing capabilities of next-generation wireless networks. To
this end, while staying in the framework of integrated sensing and
communication (ISAC), we expand the term "sensing" from radar, via spectrum
sensing, to miscellaneous applications of radio sensing like non-cooperative
transmitter localization. We formulate the problems, explain the
state-of-the-art approaches, and detail AI-based techniques to tackle various
objectives in the context of wireless sensing. We discuss the advantages,
enablers, and challenges of integrating various sensing capabilities into an
envisioned AI-powered multimodal multi-task network. In addition to the
tutorial-style core of this work based on direct authors' involvement in 6G
research problems, we review the related literature, and provide both a good
start for those entering this field of research, and a topical overview for a
general reader with a background in wireless communications

</details>


### [581] [Stabilization of the bias point in MZM modulators](https://arxiv.org/abs/2507.14888)
*Zhuo Wang*

Main category: eess.SP

TL;DR: 介绍MZM及其在通信系统中的应用，提出通过算法控制电压以保持其稳定性的方法，并通过实验验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 介绍MZM在通信系统中的作用、材料、工作原理以及易受环境因素影响的特性，引出通过算法控制电压以保持其稳定性的方法。

Method: 通过算法控制电压来控制MZM的稳定点，并通过实验验证了该算法。

Result: 验证了通过算法控制电压以保持MZM稳定性的有效性。

Conclusion: 本文总结了MZM在通信系统中的作用，并对其进行了展望。

Abstract: This article mainly introduces the role of MZM in practical communication
systems, the materials used to make MZM modulators such as lithium niobate, and
its working principle. It also explains why it changes due to environmental
factors. This leads to the introduction of a method that controls the stable
points of MZM by algorithmically controlling the voltage, and the algorithm is
verified through experiments. Finally, a summary and outlook on the future
development of MZM are provided.

</details>


### [582] [Phase-optimised linearly-constrained minimum-variance beamformers](https://arxiv.org/abs/2507.14937)
*Hugh L Kennedy*

Main category: eess.SP

TL;DR: A new way to find the best group-delay for beamformers is proposed, which can reduce noise or processing delay, and it works well in communication and radar simulations.


<details>
  <summary>Details</summary>
Motivation: The motivation is to explore the potential of an unexplored degree of design freedom in LCMV beamformers by determining the optimal group-delay, which can lead to improved performance in applications like communication and radar systems.

Method: The proposed method involves finding the optimal group-delay for an LCMV beamformer by considering two criteria: minimizing noise power and minimizing processing delay. The effectiveness of this approach is evaluated through simulations in VHF communication and UHF bistatic radar scenarios.

Result: The paper demonstrates the potential of the proposed method using simulated VHF communication and UHF bistatic radar applications, showing improved performance through the optimization of group-delay.

Conclusion: The paper proposes a novel procedure for determining the optimal group-delay for an LCMV beamformer, exploring two methods: minimizing noise power and minimizing processing delay. The potential of this approach is demonstrated using simulated VHF communication and UHF bistatic radar applications.

Abstract: A novel procedure for the determination of the optimal group-delay for a
Linearly-Constrained Minimum-Variance (LCMV) beamformer is proposed. Two ways
of selecting the optimal delay are recommended: the first is the solution that
minimizes the noise power; the second is the solution that minimizes the
processing delay. The potential of this hitherto unexplored degree of design
freedom is explored using simulated Very-High-Frequency (VHF) communication,
and Ultra-High-Frequency (UHF) bistatic radar, applications.

</details>


### [583] [Jamming-Resistant AAV Communications: A Multichannel-Aided Approach](https://arxiv.org/abs/2507.14945)
*Bin Wang,Jun Fang,Jieru Du,Shihai Shao*

Main category: eess.SP

TL;DR: 本研究提出了一种无需信道状态信息、仅利用前导码序列的多通道辅助干扰消除方法，可用于AAV通信，并成功在硬件平台上验证了其在强干扰下的信号解码能力。


<details>
  <summary>Details</summary>
Motivation: 为了在存在恶意干扰的情况下实现可靠的无人自主飞行器（AAV）通信。

Method: 提出了一种实用的多个信道辅助的干扰消除方法。

Result: 实验结果表明，使用双天线接收器，即使在干扰信号比通信信号强40dB的情况下，所提出的方法也能成功解码目标信号。

Conclusion: 该方法能够在存在恶意干扰的情况下实现安全的AAV通信，并且能够同时实现时/频同步和干扰消除。该方法不需要信道状态信息，并且只需要合法的发送端前导码序列，已在通信协议中提供。

Abstract: Jamming cancellation is essential to reliable unmanned autonomous vehicle
(AAV) communications in the presence of malicious jammers. In this paper, we
develop a practical multichannel-aided jamming cancellation method to realize
secure AAV communications. The proposed method is capable of simultaneously
achieving timing/frequency synchronization as well as jamming cancellation.
More importantly, our method does not need the signal's/jammer's channel state
information. It only utilizes the knowledge of the legitimate sender's preamble
sequence that is available in existing communication protocols. We also analyze
the length of the preamble sequence required for successful synchronization and
signal recovery. Experimental results on the built hardware platform show that,
with a two-antenna receiver, the proposed method can successfully decode the
signal of interest even when the jamming signal is $40$dB stronger than the
communication signal.

</details>


### [584] [Latent-attention Based Transformer for Near ML Polar Decoding in Short-code Regime](https://arxiv.org/abs/2507.14951)
*Hongzhi Zhu,Wei Xu,Xiaohu You*

Main category: eess.SP

TL;DR: 针对Transformer在短码解码性能和泛化能力不足的问题，提出了一种包含潜在注意力机制、先进训练框架和代码感知掩码的新型Transformer解码器（LAT），在短码场景下实现了接近最大似然的性能和良好的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 当前的Transformer（Transformer architectures）在信道解码（channel decoding）方面虽然有潜力，但在纠错码（ECCs）应用中，其性能和泛化能力相比传统的代数解码器（algebraic decoders）较差，尤其是在短码（short-code）场景下。

Method: 提出了一种新颖的基于潜在注意力（latent-attention）的Transformer（LAT）解码器。该解码器包含三个关键创新：1. 潜在注意力机制，用于代码感知（code-aware）的注意力计算，强调逐位解码交互，减少上下文关联干扰。2. 先进的训练框架，包括熵感知（entropy-aware）的重要性采样、经验重放（experience reflow）和动态标签平滑（dynamic label smoothing）。3. 代码感知（code-aware）掩码方案，能够动态适应不同的码配置。

Result: 与现有方法相比，LAT解码器在短码场景下取得了优越的性能和泛化能力。

Conclusion: 提出的LAT解码器在短码（short-code）场景下，在比特错误率（BER）和块错误率（BLER）方面均达到了接近最大似然（ML）的性能，并表现出对不同码率和码长鲁棒的泛化能力。

Abstract: Transformer architectures have emerged as promising deep learning (DL) tools
for modeling complex sequence-to-sequence interactions in channel decoding.
However, current transformer-based decoders for error correction codes (ECCs)
demonstrate inferior performance and generalization capabilities compared to
conventional algebraic decoders, especially in short-code regimes. In this
work, we propose a novel latent-attention based transformer (LAT) decoder for
polar codes that addresses the limitations on performance and generalization
through three pivotal innovations. First, we develop a latent-attention
mechanism that supersedes the conventional self-attention mechanism. This
architectural modification enables independent learning of the Query and Key
matrices for code-aware attention computation, decoupling them from the Value
matrix to emphasize position-wise decoding interactions while reducing context
correlation interference. Second, we devise an advanced training framework
incorporating three synergistic components: entropy-aware importance sampling
that emphasizes low-probability regions in the signal constellation space,
experience reflow that introduces empirical labels to improve characterization
of decoding boundaries, and dynamic label smoothing for likelihood-based
regularization. Third, we propose a code-aware mask scheme which allows dynamic
adaptation for varying code configurations. Numerical evaluations demonstrate
that the proposed LAT decoder achieves near maximum-likelihood (ML) performance
in terms of both bit error rate (BER) and block error rate (BLER) for
short-length polar codes. Furthermore, the architecture exhibits robust
generalization capabilities across diverse code rates and code lengths.

</details>


### [585] [How Many Simultaneous Beamformers are Needed for Integrated Sensing and Communications?](https://arxiv.org/abs/2507.14982)
*Kareem M. Attiah,Wei Yu*

Main category: eess.SP

TL;DR: ISAC系统需要 K + sqrt(L(L+1)/2) 或 sqrt(K^2 + L(L+1)/2) 个下行波束数量。


<details>
  <summary>Details</summary>
Motivation: 研究在ISAC系统中，为了同时实现传感和通信的最佳性能，需要多少个下行波束数量。

Method: 本文建立了下行波束数量的界限，其中传感性能通过参数估计的克拉美-拉奥边界来衡量，通信性能通过信噪比来衡量。

Result: 在用户可以消除传感波束干扰的情况下，ISAC系统最多需要 K + sqrt(L(L+1)/2) 个波束数量。如果用户无法消除传感波束的干扰，界限为 sqrt(K^2 + L(L+1)/2)。当无法进行干扰消除时，波束数量的界限小于单独执行各项任务的界限之和。

Conclusion: 该论文为下行集成传感与通信（ISAC）系统建立了下行波束数量的界限。

Abstract: Consider a downlink integrated sensing and communications (ISAC) system in
which a base station employs linear beamforming to communicate to $K$ users,
while simultaneously uses sensing beams to perform a sensing task of estimating
$L$ real parameters. How many beamformers are needed to achieve the best
performance for both sensing and communications? This paper establishes bounds
on the minimum number of downlink beamformers, in which sensing performance is
measured in terms of the Cram\'{e}r-Rao bound for parameter estimation and
communications performance is measured in terms of the
signal-to-interference-and-noise ratios. We show that an ISAC system requires
at most $K + \sqrt{\frac{L(L+1)}{2}}$ beamformers if the remote users have the
ability to cancel the interference caused by the sensing beams. If cancelling
interference due to the sensing beams is not possible, the bound becomes
$\sqrt{K^2 + \frac{L(L+1)}{2}}$. Interestingly, in the latter case, the bound
on the number of beamformers is less than the sum of the bounds for each task
individually. These results can be extended to sensing tasks for which the
performance is measured as a function of $d$ quadratic terms in the
beamformers. In this case, the bound becomes $K + \sqrt{d}$ and $\sqrt{K^2 +
d}$, respectively. Specifically, for estimating complex path losses and
angles-of-arrival of $N_\text{tr}$ targets while communicating to $K$ users,
the bound on the minimum number of beamformers scales linearly in $K$ and in
$N_\text{tr}$, assuming interference from sensing can be cancelled. When
interference cancellation is not possible, the following exact characterization
for the case of $N_\text{tr} = 1$ can be obtained: when $K=0$ or $1$, two
beamformers should be used; when $K \ge 2$, exactly $K$ beamformers should be
used, i.e., communication beamformers alone are already sufficient.

</details>


### [586] [PAPR Analysis for MIMO FTN Signaling with Gaussian Symbols](https://arxiv.org/abs/2507.15116)
*Zichao Zhang,Melda Yuksel,Gokhan M. Guvensen,Halim Yanikomeroglu*

Main category: eess.SP

TL;DR: 本文研究了 MIMO FTN 的 PAPR 问题，发现 PAPR 主要由加速度因子和功率约束决定，而功率分配优化不影响高斯信号的 PAPR。


<details>
  <summary>Details</summary>
Motivation: 为了提高通信系统的频谱效率，人们提出了超奈奎斯特 (FTN) 信号，但其快速加速的特性会导致严重的峰均功率比 (PAPR) 问题。

Method: 研究了两种功率约束下的 MIMO FTN 的 PAPR 特性：固定的发射功率和固定的接收信噪比 (SNR)。

Result: PAPR 主要由加速度因子和功率约束决定，并且功率分配优化不会改变高斯信号的 PAPR 特性。

Conclusion: 对于高斯信号，功率分配优化不会改变 PAPR 的行为。

Abstract: Faster-than-Nyquist signaling serves as a promising solution for improving
spectral efficiency in future generations of communications. However, its
nature of fast acceleration brings highly overlapped pulses that lead to worse
peak-to-average power ratio (PAPR) performance. In this paper, we investigate
the PAPR behavior of MIMO FTN using Gaussian symbols under optimal power
allocation for two power constraints: fixed transmit power and fixed received
signal-to-noise-ratio (SNR). Our findings reveal that PAPR is mainly determined
by the acceleration factor and the power constraint, but power allocation
optimization does not change the PAPR behavior for Gaussian signaling.

</details>


### [587] [MEETI: A Multimodal ECG Dataset from MIMIC-IV-ECG with Signals, Images, Features and Interpretations](https://arxiv.org/abs/2507.15255)
*Deyun Zhang,Xiang Lan,Shijia Geng,Qinghao Zhao,Sumei Fan,Mengling Feng,Shenda Hong*

Main category: eess.SP

TL;DR: MEETI：首个多模态 ECG 数据集，包含原始波形、图像和文本，推动可解释的心血管 AI 发展。


<details>
  <summary>Details</summary>
Motivation: 现有的 ECG 数据集多为单模态或双模态，难以构建能理解和整合多源 ECG 信息的临床 AI 系统。

Method: 提出了 MEETI 数据集，该数据集包含原始 ECG 波形、绘图图像、提取的参数和文本解释，并使用一致的标识符进行对齐。

Result: MEETI 数据集支持基于 Transformer 的多模态学习，能够对心脏健康进行细粒度、可解释的推理，为 ECG AI 系统的开发和评估提供了全面的基准。

Conclusion: MEETI 是首个大规模同步包含原始波形数据、高分辨率绘图图像和详细文本解释的 ECG 数据集，为多模态心血管 AI 的发展奠定了基础。

Abstract: Electrocardiogram (ECG) plays a foundational role in modern cardiovascular
care, enabling non-invasive diagnosis of arrhythmias, myocardial ischemia, and
conduction disorders. While machine learning has achieved expert-level
performance in ECG interpretation, the development of clinically deployable
multimodal AI systems remains constrained, primarily due to the lack of
publicly available datasets that simultaneously incorporate raw signals,
diagnostic images, and interpretation text. Most existing ECG datasets provide
only single-modality data or, at most, dual modalities, making it difficult to
build models that can understand and integrate diverse ECG information in
real-world settings. To address this gap, we introduce MEETI (MIMIC-IV-Ext
ECG-Text-Image), the first large-scale ECG dataset that synchronizes raw
waveform data, high-resolution plotted images, and detailed textual
interpretations generated by large language models. In addition, MEETI includes
beat-level quantitative ECG parameters extracted from each lead, offering
structured parameters that support fine-grained analysis and model
interpretability. Each MEETI record is aligned across four components: (1) the
raw ECG waveform, (2) the corresponding plotted image, (3) extracted feature
parameters, and (4) detailed interpretation text. This alignment is achieved
using consistent, unique identifiers. This unified structure supports
transformer-based multimodal learning and supports fine-grained, interpretable
reasoning about cardiac health. By bridging the gap between traditional signal
analysis, image-based interpretation, and language-driven understanding, MEETI
established a robust foundation for the next generation of explainable,
multimodal cardiovascular AI. It offers the research community a comprehensive
benchmark for developing and evaluating ECG-based AI systems.

</details>


### [588] [Optimal Transceiver Design in Over-the-Air Federated Distillation](https://arxiv.org/abs/2507.15256)
*Zihao Hu,Jia Yan,Ying-Jun Angela Zhang,Jun Zhang,Khaled B. Letaief*

Main category: eess.SP

TL;DR: 一种新的过顶联邦蒸馏（FD）框架，利用FL和知识蒸馏，通过共享模型输出来减少通信开销，并提出了相应的收发器设计和优化方法。


<details>
  <summary>Details</summary>
Motivation: 为了解决现有FL方法在大模型时代由于显著的通信开销而导致的效率低下问题。

Method: 研究了过顶FD中的收发器设计，旨在最大化学习收敛速率，同时满足收发器的功率约束。通过推导收敛速率的解析表达式，以及得到 WD 发射功率和过顶聚合估计器的闭式最优解，并采用半定松弛来寻找最优接收器波束形成向量，证明了原问题和松弛问题的最优性没有差距。

Result: 所提出的过顶FD方法实现了通信开销的大幅降低，而测试准确性仅比传统的FL基准有轻微的下降。

Conclusion: 所提出的过顶联邦蒸馏（FD）框架通过利用联邦学习（FL）和知识蒸馏的优势，并利用多址接入信道的叠加性质，在聚合过程中只共享模型输出（知识），从而避免了繁重的本地模型传输，实现了通信开销的大幅降低，而仅在测试准确性方面与传统的FL基准相比有轻微的折衷。

Abstract: The rapid proliferation and growth of artificial intelligence (AI) has led to
the development of federated learning (FL). FL allows wireless devices (WDs) to
cooperatively learn by sharing only local model parameters, without needing to
share the entire dataset. However, the emergence of large AI models has made
existing FL approaches inefficient, due to the significant communication
overhead required. In this paper, we propose a novel over-the-air federated
distillation (FD) framework by synergizing the strength of FL and knowledge
distillation to avoid the heavy local model transmission. Instead of sharing
the model parameters, only the WDs' model outputs, referred to as knowledge,
are shared and aggregated over-the-air by exploiting the superposition property
of the multiple-access channel. We shall study the transceiver design in
over-the-air FD, aiming to maximize the learning convergence rate while meeting
the power constraints of the transceivers. The main challenge lies in the
intractability of the learning performance analysis, as well as the non-convex
nature and the optimization spanning the whole FD training period. To tackle
this problem, we first derive an analytical expression of the convergence rate
in over-the-air FD. Then, the closed-form optimal solutions of the WDs'
transmit power and the estimator for over-the-air aggregation are obtained
given the receiver combining strategy. Accordingly, we put forth an efficient
approach to find the optimal receiver beamforming vector via semidefinite
relaxation. We further prove that there is no optimality gap between the
original and relaxed problem for the receiver beamforming design. Numerical
results will show that the proposed over-the-air FD approach achieves a
significant reduction in communication overhead, with only a minor compromise
in testing accuracy compared to conventional FL benchmarks.

</details>


### [589] [A Novel Domain-Aware CNN Architecture for Faster-than-Nyquist Signaling Detection](https://arxiv.org/abs/2507.15291)
*Osman Tokluoglu,Enver Cavus,Ebrahim Bedeer,Halim Yanikomeroglu*

Main category: eess.SP

TL;DR: 本研究提出了一种创新的固定核CNN检测器，用于超奈奎斯特（FTN）信号，有效解决了符号间干扰（ISI）问题，并在性能和计算效率上均优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 为了更快地进行超奈奎斯特（FTN）信号检测，并有效减轻符号间干扰（ISI）。

Method: 提出了一种基于卷积神经网络（CNN）的超奈奎斯特（FTN）信号检测器。该检测器采用结构化固定核层和领域感知掩码来减轻符号间干扰（ISI），并引入了分层滤波器分配策略，优先处理较强的ISI模式。

Result: 在$	au 	ext{ } 	extgreater 	ext{=} 	ext{ } 0.7$时，该检测器实现了接近最优的误码率（BER）性能，与BCJR算法相当，并且在BPSK和QPSK调制下，计算效率分别比M-BCJR算法高出46%和84%。

Conclusion: 该研究首次将固定核卷积神经网络架构应用于FTN检测，在$	au 	ext{ } 	extgreater 	ext{=} 	ext{ } 0.7$时实现了接近最优的误码率（BER）性能，计算效率比M-BCJR算法分别提高了46%和84%（针对BPSK和QPSK）。

Abstract: This paper proposes a convolutional neural network (CNN)-based detector for
faster-than-Nyquist (FTN) signaling that employs structured fixed kernel layers
with domain-informed masking to mitigate intersymbol interference (ISI). Unlike
standard CNNs with sliding kernels, the proposed method utilizes fixed-position
kernels to directly capture ISI effects at varying distances from the central
symbol. A hierarchical filter allocation strategy is also introduced, assigning
more filters to earlier layers for strong ISI patterns and fewer to later
layers for weaker ones. This design improves detection accuracy while reducing
redundant operations. Simulation results show that the detector achieves
near-optimal bit error rate (BER) performance for $\tau \geq 0.7$, closely
matching the BCJR algorithm, and offers computational gains of up to $46\%$ and
$84\%$ over M-BCJR for BPSK and QPSK, respectively. Comparative analysis with
other methods further highlights the efficiency and effectiveness of the
proposed approach. To the best of our knowledge, this is the first application
of a fixed-kernel CNN architecture tailored for FTN detection in the
literature.

</details>


### [590] [BEAM-Net: A Deep Learning Framework with Bone Enhancement Attention Mechanism for High Resolution High Frame Rate Ultrasound Beamforming](https://arxiv.org/abs/2507.15306)
*Midhila Madhusoodanan,Mahesh Raveendranatha Panicker,Pisharody Harikrishnan Gopalakrishnan,Abhilash Rakkunedeth Hareendranathan*

Main category: eess.SP

TL;DR: BEAM-Net是一种创新的深度学习模型，通过集成骨骼概率图和边缘保持指数，显著提高了肌肉骨骼超声成像中骨骼结构的清晰度和可解释性，优于传统和现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有的用于肌肉骨骼（MSK）超声检查的便携式、低成本超声设备在骨组织成像方面存在图像质量限制，包括散斑噪声、低分辨率、对比度差和各向异性反射等问题，导致骨图像难以解释，需要额外的后处理。传统的延迟和求和波束形成（DASB）技术并未针对骨骼结构进行优化。因此，有必要开发一种能够提高骨骼成像质量并简化解释过程的新方法。

Method: 提出了一种名为BEAM-Net的新型端到端深度神经网络（DNN），用于处理高帧率超声波束形成和骨骼增强。该网络以单平面波（SPW）射频（RF）数据作为输入，并引入了骨骼概率图（BPM）作为注意力机制，以提高骨骼区域的结构相似性。此外，研究还引入了边缘保持指数（EPI）作为评估骨骼增强超声图像结构保真度的新指标。

Result: BEAM-Net在体外MSK和合成RF超声数据集上进行了训练和评估。与传统的SPW-DASB相比，BEAM-Net在体外MSK和合成RF数据集上分别实现了51.4%-51%和94.2%-73.3%的CR和SNR提升。与多重引导平面波DASB（MPW-DASB）相比，BEAM-Net在体外MSK数据集上CR和SNR分别提高了19.8%-24.0%，在合成数据集上提高了2.5%-12.8%。

Conclusion: BEAM-Net是一种新颖的端到端深度神经网络（DNN），它使用单平面波（SPW）射频（RF）数据作为输入，能够实现高帧率超声波束形成，并集成了骨骼增强功能。该方法通过嵌入骨骼概率图（BPM）作为注意力机制，强制图像中的骨骼区域具有更高的结构相似性。该研究首次将深度学习直接应用于超声波束形成，实现了骨骼增强。与传统的延迟和求和波束形成（DASB）以及现有的深度学习架构相比，BEAM-Net在对比度比（CR）、信噪比（SNR）、斑点相似度指数（SSI）和结构相似度指数（SSIM）等方面表现出显著的优势，尤其是在边缘保持指数（EPI）这一新的评估指标上。

Abstract: Pocket-sized, low-cost point-of-care ultrasound (POCUS) devices are
increasingly used in musculoskeletal (MSK) applications for structural
examination of bone tissue. However, the image quality in MSK ultrasound is
often limited by speckle noise, low resolution, poor contrast, and anisotropic
reflections, making bone images difficult to interpret without additional
post-processing. Typically, medical ultrasound systems use delay and sum
beamforming (DASB) for image reconstruction, which is not specifically
optimized for bone structures. To address these limitations, we propose
BEAM-Net, a novel end-to-end deep neural network (DNN) that performs
high-frame-rate ultrasound beamforming with integrated bone enhancement, using
single-plane-wave (SPW) radio frequency (RF) data as input. Our approach embeds
a Bone Probability Map (BPM), which acts as an attention mechanism to enforce
higher structural similarity around bony regions in the image. The proposed
approach is the first of its kind to incorporate bone enhancement directly into
ultrasound beamforming using deep learning. BEAM-Net was trained and evaluated
on in-vivo MSK and synthetic RF ultrasound datasets. This paper introduces the
Edge Preservation Index (EPI) as a new region-focused metric for evaluating
structural fidelity in bone-enhanced ultrasound images. The performance of
BEAM-Net was compared with conventional DASB and existing deep learning
architectures using the EPI, Contrast Ratio (CR), Signal-to-Noise ratio (SNR),
Speckle Similarity Index (SSI), and Structural Similarity Index (SSIM).
BEAM-Net showed substantial gains over SPW-DASB, achieving 51.4-51% higher CR
and 94.2-73.3% higher SNR on in-vivo MSK and synthetic RF datasets. It
outperformed multiple steered plane wave DASB (MPW-DASB), with 19.8-24.0%
improvements in CR and SNR on in-vivo MSK and 2.5-12.8% improvements on
synthetic data.

</details>


### [591] [EEG-based Epileptic Prediction via a Two-stage Channel-aware Set Transformer Network](https://arxiv.org/abs/2507.15364)
*Ruifeng Zheng,Cong Chen,Shuang Wang,Yiming Liu,Lin You,Jindong Lu,Ruizhe Zhu,Guodao Zhang,Kejie Huang*

Main category: eess.SP

TL;DR: 通过使用更少的EEG通道传感器和改进的数据划分方法，实现了更有效的癫痫预测。


<details>
  <summary>Details</summary>
Motivation: 为了缓解穿戴式设备体积庞大，难以收集EEG数据的问题，本研究旨在通过使用更少的EEG通道传感器来实现癫痫预测。

Method: 提出了一种新颖的两阶段通道感知集合Transformer网络，并测试了一种与癫痫无关的划分方法，该方法可以防止训练和测试数据相邻。

Result: 通道选择将平均通道数从18个减少到2.8个，平均敏感度从76.4%提高到80.1%，假阳性率为0.11/小时。与癫痫无关的划分方法在具有大量EEG记录的患者中显示出更优越的性能。

Conclusion: 提出的两阶段通道感知集合Transformer网络能够以更少的EEG通道传感器进行癫痫预测。实验证明，通道选择能将平均通道数从18个减少到2.8个，同时平均敏感度从76.4%提高到80.1%，假阳性率为0.11/小时。此外，与癫痫无关的划分方法支持了对具有大量EEG记录的患者使用更严格的癫痫无关划分方法的论点。

Abstract: Epilepsy is a chronic, noncommunicable brain disorder, and sudden seizure
onsets can significantly impact patients' quality of life and health. However,
wearable seizure-predicting devices are still limited, partly due to the bulky
size of EEG-collecting devices. To relieve the problem, we proposed a novel
two-stage channel-aware Set Transformer Network that could perform seizure
prediction with fewer EEG channel sensors. We also tested a seizure-independent
division method which could prevent the adjacency of training and test data.
Experiments were performed on the CHB-MIT dataset which includes 22 patients
with 88 merged seizures. The mean sensitivity before channel selection was
76.4% with a false predicting rate (FPR) of 0.09/hour. After channel selection,
dominant channels emerged in 20 out of 22 patients; the average number of
channels was reduced to 2.8 from 18; and the mean sensitivity rose to 80.1%
with an FPR of 0.11/hour. Furthermore, experimental results on the
seizure-independent division supported our assertion that a more rigorous
seizure-independent division should be used for patients with abundant EEG
recordings.

</details>


### [592] [Robust ISAC Transceiver Beamforming Design under Low-Resolution AD/DA Converters](https://arxiv.org/abs/2507.15373)
*Tiantian Xu,Zhenyao He,Jindan Xu,Wei Xu,Jianfeng Wang,Derrick Wing Kwan Ng*

Main category: eess.SP

TL;DR: 本文提出了一种用于低分辨率 ISAC 系统的鲁棒波束形成设计方法，利用 SDR 和 MM 算法在保证通信质量的同时最大化雷达性能。


<details>
  <summary>Details</summary>
Motivation: ISAC 系统中的低分辨率量化器（DAC 和 ADC）会引入量化噪声，影响系统的感知和通信性能。本文旨在解决这一挑战，通过优化波束形成设计，最大化雷达信号的信噪比（SQNR），同时保证通信用户的最小信干噪比（SQINR），从而在低分辨率条件下实现鲁棒的 ISAC 系统。

Method: 本文提出了一种新颖的鲁棒波束形成设计方法，结合了半definitie 规划松弛（SDR）技术和主要化-最小化（MM）算法。首先，针对点目标和统一分辨率 DAC 的场景，利用 SDR 技术获得全局最优解。接着，对于包含混合 DAC 和/或扩展目标的更普遍场景，开发了一种低复杂度的 MM 算法进行迭代优化。

Result: 与非鲁棒算法相比，所提出的算法在实际量化条件下，在检测性能上表现出显著提升。仿真结果验证了该算法在低分辨率量化场景下的鲁棒性和有效性。

Conclusion: 所提出的基于顺序凸优化和 MM 的算法在低分辨率量化场景下具有鲁棒性和有效性，并且在感知和通信性能方面优于现有方法。

Abstract: In this letter, we investigate the robust beamforming design for an
integrated sensing and communication (ISAC) system featuring low-resolution
digital-to-analog converters (DACs) and analog-to-digital converters (ADCs).
Taking into account quantization noise, we aim at maximizing the radar
signal-to-quantization-plus-noise ratio (SQNR) while guaranteeing the minimum
required signal-to-quantization-plus-interference-plus-noise ratio (SQINR) for
communication users. To address this nonconvex design problem, we first examine
a scenario involving a point target and uniform-resolution DACs, where the
globally optimal solution is obtained by applying the semidefinite relaxation
(SDR) technique. For more general scenarios, including those with mixed-DACs
and/or an extended target, we develop a low-complexity
majorization-minimization (MM)-based algorithm to tackle the problem
iteratively. Compared to the non-robust algorithm, the proposed algorithm
demonstrates improved detection performance under practical quantization.
Simulation results confirm the robustness and efficacy of our proposed
algorithm in low-resolution quantization scenarios.

</details>


### [593] [On the Distribution of a Two-Dimensional Random Walk with Restricted Angles](https://arxiv.org/abs/2507.15475)
*Karl-Ludwig Besser*

Main category: eess.SP

TL;DR: 本文推导了二维随机游走的分布，其中每一步的角度都限制在圆的子集中。


<details>
  <summary>Details</summary>
Motivation: 该设置出现在信号处理中的过顶计算等各种领域。

Method: 推导了二维（复数）随机游走的分布，其中每一步的角度都限制在圆的子集中。推导了两个步骤的精确联合分布和边缘分布，给出了通用步骤数的数值解，并给出了大步数的近似值。此外，还为任意步数提供了精确的支持特征。

Result: 推导了二维（复数）随机游走的分布，其中每一步的角度都限制在圆的子集中。推导了两个步骤的精确联合分布和边缘分布，给出了通用步骤数的数值解，并给出了大步数的近似值。此外，还为任意步数提供了精确的支持特征。

Conclusion: 该工作为涉及此类问题的未来工作提供了参考。

Abstract: In this paper, we derive the distribution of a two-dimensional (complex)
random walk in which the angle of each step is restricted to a subset of the
circle. This setting appears in various domains, such as in over-the-air
computation in signal processing. In particular, we derive the exact joint and
marginal distributions for two steps, numerical solutions for a general number
of steps, and approximations for a large number of steps. Furthermore, we
provide an exact characterization of the support for an arbitrary number of
steps. The results in this work provide a reference for future work involving
such problems.

</details>


### [594] [Movable-Antenna Empowered AAV-Enabled Data Collection over Low-Altitude Wireless Networks](https://arxiv.org/abs/2507.15515)
*Xuhui Zhang,Wenchao Liu,Jinke Ren,Chunjie Wang,Huijun Xing,Yanyan Shen,Shuguang Cui*

Main category: eess.SP

TL;DR: This paper uses movable antennas on an autonomous aerial vehicle for better data collection in wireless networks, improving speed and reliability through optimized AAV movement, antenna positions, and beamforming.


<details>
  <summary>Details</summary>
Motivation: Investigating the use of movable-antennas (MAs) in an autonomous aerial vehicle (AAV) system for uplink data collection in low-altitude wireless networks (LAWNs) to maximize the sum achievable rate.

Method: An alternating optimization (AO) algorithm is proposed, integrating successive convex approximation, weighted minimum mean square error, and particle swarm optimization, to jointly optimize AAV trajectory, receive beamforming, and MA positions.

Result: The proposed scheme significantly improves the sum achievable rate and service reliability compared to benchmark schemes, showcasing enhanced spectral efficiency via adaptive beam-user alignment and improved collection reliability through spatial interference management.

Conclusion: Movable-antennas (MAs) technology shows great potential for enhancing spectral efficiency and collection reliability in low-altitude wireless networks (LAWNs), making it a promising solution for future wireless systems.

Abstract: Movable-antennas (MAs) are revolutionizing spatial signal processing by
providing flexible beamforming in next-generation wireless systems. This paper
investigates an MA-empowered autonomous aerial vehicle (AAV) system in
low-altitude wireless networks (LAWNs) for uplink data collection from ground
users. We aim to maximize the sum achievable rate by jointly optimizing the AAV
trajectory, receive beamforming, and MA positions. An efficient alternating
optimization (AO) algorithm that incorporates successive convex approximation,
weighted minimum mean square error, and particle swarm optimization is
developed. The analysis of the computational complexity and convergence
features is provided. Extensive simulations demonstrate superior performance in
terms of the sum achievable rate and the service reliability comparing to
several benchmark schemes. These results demonstrate the distinctive advantages
of the proposed scheme: enhanced spectral efficiency via adaptive beam-user
alignment and improved collection reliability through spatial interference
management, highlighting the implementation potential of the MA-empowered
LAWNs.

</details>


### [595] [Sum-Rate Maximization for Movable-Antenna Array Enhanced Downlink NOMA Systems](https://arxiv.org/abs/2507.15555)
*Nianzu Li,Peiran Wu,Lipeng Zhu,Weidong Mei,Boyu Ning,Derrick Wing Kwan Ng*

Main category: eess.SP

TL;DR: 本文提出了一种MA增强的下行链路NOMA系统，通过联合优化天线位置、波束形成、解码顺序等来最大化系统和速率，并提出了一种两阶段优化算法获得有效解。


<details>
  <summary>Details</summary>
Motivation: 本文旨在通过联合优化波束形成、MA位置、SIC解码顺序和用户解码指示矩阵来最大化MA增强下行链路NOMA系统的总和速率，并满足最大发射功率和有限MA移动区域的约束。

Method: 提出了一种低复杂度的两阶段优化算法，包括：1. 确定SIC解码顺序；2. 通过交替优化、SCA和GA迭代优化波束形成向量、MA位置和用户的解码指示矩阵。

Result: 仿真结果表明，所提出的MA功能下行链路NOMA系统显著优于传统的FPA系统，并且天线位置优化可以进一步增强NOMA相对于SDMA的优势。

Conclusion: 所提出的MA功能下行链路NOMA系统显著优于传统的FPA系统，并且天线位置优化可以进一步增强NOMA相对于SDMA的优势。

Abstract: Movable antenna (MA) systems have recently attracted significant attention in
the field of wireless communications owing to their exceptional capability to
proactively reconfigure wireless channels via flexible antenna movements. In
this paper, we investigate the resource allocation design for an MA
array-enhanced downlink non-orthogonal multiple access (NOMA) system, where a
base station deploys multiple MAs to serve multiple single-antenna users. Our
goal is to maximize the sum rate of all users by jointly optimizing the
transmit beamforming, positions of MAs, successive interference cancellation
(SIC) decoding order, and users' corresponding decoding indicator matrix, while
adhering to constraints on the maximum transmit power and finite MA moving
region. The formulated problem is inherently highly non-convex, rendering it
challenging to acquire a globally optimal solution. As a compromise, we propose
a low-complexity two-stage optimization algorithm to obtain an effective
suboptimal solution. Specifically, in stage one, the SIC decoding order is
first determined by solving a channel gain maximization problem. Then, in stage
two, with the given SIC decoding order, the beamforming vectors, MA positions,
and users' decoding indicator matrix are iteratively optimized by capitalizing
on alternating optimization, successive convex approximation (SCA), and genetic
algorithm (GA). Simulation results unveil that the sum-rate performance of the
proposed MA-enabled downlink NOMA system significantly outperforms that of
conventional fixed-position antenna (FPA) systems. Moreover, the results also
show that the antenna position optimization in the proposed algorithm can
further enhance the advantages of NOMA over space division multiple access
(SDMA).

</details>


### [596] [Zak-OTFS based Multiuser Uplink in Doubly-Spread Channels](https://arxiv.org/abs/2507.15621)
*Imran Ali Khan,Saif Khan Mohammed,Ronny Hadani,Ananthanarayanan Chockalingam,Robert Calderbank*

Main category: eess.SP

TL;DR: Zak-OTFS 通过新的 DD 域脉冲整形实现了灵活的 TF 资源分配，无需保护带即可在多用户上传系统中提供良好的单用户性能。


<details>
  <summary>Details</summary>
Motivation: 下一代通信网络需要支持具有不同特性的无线用户共享频谱。OFDM 的一个主要优势是可以通过简单地在时域和频域移动用户信号来实现不同的非重叠时频 (TF) 资源分配。然而，OFDM 的一个显著弱点是子载波间隔的灵活性差，这会导致一个用户的载波间干扰影响所有用户。

Method: 设计了一种新颖的延迟-多普勒 (DD) 域脉冲整形方法，用于在上传链路上对传输的 Zak-OTFS 脉冲进行整形，以实现灵活的非重叠时频 (TF) 资源分配。基站 (BS) 接收上传信号的叠加，并应用单独的匹配滤波器来获取特定于各个用户的数据。开发了用户间干扰的理论度量，并为车辆信道模型进行了数值模拟。

Result: 证明了在多用户 Zak-OTFS 上传系统中，无需在分配给不同用户的 TF 资源之间配置保护带即可实现单用户性能。这些性能结果表明，在上传通信架构中可以实现可预测的 Zak-OTFS 波形的优势。

Conclusion: Zak-OTFS 是一种替代的延迟-多普勒 (DD) 域调制方案，与 OFDM 不同，其输入-输出 (I/O) 关系是可预测的。通过在上传链路上设计一种新颖的 DD 域脉冲整形方法，可以实现灵活的非重叠时频 (TF) 资源分配，从而匹配 OFDM 的优势。基站 (BS) 接收上传信号的叠加，并应用单独的匹配滤波器来获取特定于各个用户的数据。我们开发了用户间干扰的理论度量，并为代表下一代传播环境的车辆信道模型进行了数值模拟。我们证明了在多用户 Zak-OTFS 上传系统中，无需在分配给不同用户的 TF 资源之间配置保护带即可实现单用户性能。这些性能结果表明，在上传通信架构中可以实现可预测的 Zak-OTFS 波形的优势。

Abstract: Wireless users with different characteristics will be expected to share
spectrum in next generation communication networks. One of the great strengths
of wireless networks based on Orthogonal Frequency Division Multiplexing (OFDM)
is the ease with which different non-overlapping time-frequency (TF) resources
can be allocated to different users by simply shifting each user's signal in
time and frequency. However, a significant weaknesses of OFDM is the
inflexibility of sub-carrier spacing. Since OFDM does not allow users to have
different sub-carrier spacing, a single user subject to inter-carrier
interference causes carrier spacing to increase for all users. Zak-OTFS is an
alternative delay-Doppler (DD) domain modulation scheme, where, in contrast to
OFDM, the Input-Output (I/O) relation is predictable. We match the strength of
OFDM by designing a novel DD domain method of shaping the transmitted Zak-OTFS
pulse on the uplink that enables flexible non-overlapping TF resource
allocation. The base station (BS) receives a superposition of uplink signals
and applies individual matched filters to obtain the data specific to
individual users. We develop theoretical measures of interference between
users, and present numerical simulations for a vehicular channel model
representative of next generation propagation environments. We demonstrate
single-user performance in a multiuser Zak-OTFS uplink system without needing
to provision guard bands between TF resources allocated to different users.
These performance results demonstrate that the benefits of a predictable
Zak-OTFS waveform can be realized within an architecture for uplink
communication.

</details>


### [597] [Fluid Antenna-enabled Near-Field Integrated Sensing, Computing and Semantic Communication for Emerging Applications](https://arxiv.org/abs/2507.15800)
*Yinchao Yang,Jingxuan Zhou,Zhaohui Yang,Mohammad Shikh-Bahaei*

Main category: eess.SP

TL;DR: NF-ISCSC框架结合了近场通信、传感、计算和语义通信，并使用流体天线进行信道自适应，通过交替优化解决了波束形成、天线定位和语义提取率的联合优化问题。


<details>
  <summary>Details</summary>
Motivation: 为了解决高频段和大规模天线阵列带来的数据量大和潜在隐私风险等挑战，并提高NF-ISAC系统的效率。

Method: 本文提出了一种新颖的框架：近场集成传感、计算和语义通信（NF-ISCSC），并引入了流体天线（FAs）来支持该系统。通过交替优化（AO）方法，将原始问题分解为三个子问题：ISAC波束形成（使用连续凸近似）、FA定位（使用投影Broyden-Fletcher-Goldfarb-Shinn算法）和语义提取率（使用二分搜索）。

Result: 与现有方法相比，所提出的框架实现了更高的数据速率和更好的隐私保护。

Conclusion: 仿真结果表明，所提出的框架实现了更高的数据速率和更好的隐私保护。

Abstract: The integration of sensing and communication (ISAC) is a key enabler for
next-generation technologies. With high-frequency bands and large-scale antenna
arrays, the Rayleigh distance extends, necessitating near-field (NF) models
where waves are spherical. Although NF-ISAC improves both sensing and
communication, it also poses challenges such as high data volume and potential
privacy risks. To address these, we propose a novel framework: near-field
integrated sensing, computing, and semantic communication (NF-ISCSC), which
leverages semantic communication to transmit contextual information only,
thereby reducing data overhead and improving efficiency. However, semantic
communication is sensitive to channel variations, requiring adaptive
mechanisms. To this end, fluid antennas (FAs) are introduced to support the
NF-ISCSC system, enabling dynamic adaptability to changing channels. The
proposed FA-enabled NF-ISCSC framework considers multiple communication users
and extended targets comprising several scatterers. A joint optimization
problem is formulated to maximize data rate while accounting for sensing
quality, computational load, and power budget. Using an alternating
optimization (AO) approach, the original problem is divided into three
sub-problems: ISAC beamforming, FA positioning, and semantic extraction ratio.
Beamforming is optimized using the successive convex approximation method. FA
positioning is solved via a projected Broyden-Fletcher-Goldfarb-Shanno (BFGS)
algorithm, and the semantic extraction ratio is optimized using bisection
search. Simulation results demonstrate that the proposed framework achieves
higher data rates and better privacy preservation.

</details>


<div id='quant-ph'></div>

# quant-ph [[Back]](#toc)

### [598] [Bipartite quantum states admitting a causal explanation](https://arxiv.org/abs/2507.14278)
*Minjeong Song,Arthur J. Parzygnat*

Main category: quant-ph

TL;DR: "量子关联可以揭示测量的时间顺序。可分态总是时间兼容的，而纠缠态则不一定。我们还提出了一个用于判断任意二分态是否时间兼容的新判据。"


<details>
  <summary>Details</summary>
Motivation: "量子关联可能包含关于局部测量的时间顺序的信息。"

Method: "我们首先证明了每个二分可分密度矩阵都与直接因果影响在时间上兼容，适用于任意有限维量子系统和一种可断层的可观测量类（包括所有泡利可观测量），并提供了与此类相关性一致的时间演化的操作意义，即广义退相干通道和相当不错的测量。"

Result: "我们证明了每个二分可分密度矩阵都与直接因果影响在时间上兼容。两个时间演化不是彼此的Petz恢复图，而是彼此的贝叶斯逆。"

Conclusion: "如果一个二分态密度矩阵与直接因果影响在时间上不兼容，那么它必定是纠缠的。最后，我们证明了任意二分量子态在时间上兼容的充要条件，这为适用于任何维度的量子系统的正部分转置判据提供了时间上的类似物。"

Abstract: The statistics of local measurements of joint quantum systems can sometimes
be used to distinguish the temporal order in which they were measured. We first
prove that every bipartite separable density matrix is temporally compatible
with direct causal influence for arbitrary finite-dimensional quantum systems
and measurements of a tomographically-complete class of observables, which
includes all Pauli observables in the case of multi-qubit systems.
Equivalently, if a bipartite density matrix is not temporally compatible with
direct causal influence, then it must be entangled. We also provide an
operational meaning for the temporal evolution consistent with such
correlations in terms of a generalized dephasing channel and a pretty good
measurement. The two temporal evolutions turn out to not be Petz recovery maps
of each other, but are Bayesian inverses of each other. Finally, we prove
necessary and sufficient conditions for an arbitrary bipartite quantum state to
be temporally compatible, thereby providing a temporal analogue of the positive
partial transpose criterion valid for quantum systems of any dimension.

</details>


### [599] [Polar Codes for Erasure and Unital Classical-Quantum Markovian Channels](https://arxiv.org/abs/2507.14323)
*Jaswanthi Mandalapu,Vikesh Siddhu,Krishna Jagannathan*

Main category: quant-ph

TL;DR: 对于具有记忆的经典-量子信道，极化码可以达到量子比特擦除和具有信道状态信息在接收端的单量子比特噪声的经典容量。


<details>
  <summary>Details</summary>
Motivation: 考虑具有记忆的经典-量子（CQ）信道，并确定Arıkan构造的极化码是否能达到两种关键噪声模型的经典容量，即（i）量子比特擦除和（ii）具有信道状态信息的单量子比特噪声。

Method: 通过利用现有的针对有限状态、非周期和不可约马尔可夫过程的经典极化编码保证，以及最近发现的在传输经典信息时，无需纠缠即可达到马尔可夫酉和擦除量子信道的容量，来建立这一结果。

Result: Arıkan构造的极化码实现了（i）量子比特擦除和（ii）具有信道状态信息在接收端的单量子比特噪声这两种关键噪声模型的经典容量。

Conclusion: 对于具有记忆的经典-量子（CQ）信道，其中最优编码策略本质上是经典的，可以证明极化码可以逼近容量。

Abstract: We consider classical-quantum (cq-)channels with memory, and establish that
Ar{\i}kan-constructed polar codes achieve the classical capacity for two key
noise models, namely for (i) qubit erasures and (ii) unital qubit noise with
channel state information at the receiver. The memory in the channel is assumed
to be governed by a discrete-time, countable-state, aperiodic, irreducible, and
positive recurrent Markov process. We establish this result by leveraging
existing classical polar coding guarantees established for finite-state,
aperiodic, and irreducible Markov processes [FAIM], alongside the recent
finding that no entanglement is required to achieve the capacity of Markovian
unital and erasure quantum channels when transmitting classical information.
More broadly, our work illustrates that for cq-channels with memory, where an
optimal coding strategy is essentially classical, polar codes can be shown to
approach the capacity.

</details>


### [600] [Quantum $1/f^η$ Noise Induced Relaxation in the Spin-Boson Model](https://arxiv.org/abs/2507.14329)
*Florian Otterpohl,Peter Nalbach,Elisabetta Paladino,Giuseppe A. Falci,Michael Thorwart*

Main category: quant-ph

TL;DR: 研究了量子1/fη噪声对开放量子系统的影响，发现了新的动力学行为和退相干规律，并为量子计算中的低频噪声处理提供了新思路。


<details>
  <summary>Details</summary>
Motivation: 将开放量子系统的自旋-玻色模型扩展到量子1/fη噪声区域，该区域具有负指数谱分布。

Method: 利用数值精确的时间演化矩阵因子算符，确定了动力学模型图，包括由量子1/fη噪声控制的赝相干动力学。

Result: 确定了退相干率，并找到了适用于零温度的经验公式，同时发现重组能对红外浴截止频率敏感，从而提高了退相干性对实验测量时间的敏感度。

Conclusion: 研究结果可应用于量子计算机的基本组成单元——量子比特，并为在更复杂的量子计算架构中对低频噪声进行量子化处理提供了方向。

Abstract: We extend the spin-boson model of open quantum systems to the regime of
quantum $1/f^\eta$ noise characterized by negative exponents of its spectral
distribution. Using the numerically exact time-evolving matrix product
operator, we find the dynamic regime diagram, including pseudocoherent dynamics
controlled by quantum $1/f^\eta$ noise. We determine the dephasing rate and
find for it an empirical formula valid at zero temperature. The bath
reorganization energy depends on the infrared bath cutoff frequency, revealing
an increased sensitivity of the dephasing on the measurement time of an
experiment. \ep{Our results apply to a qubit as an elementary building block of
a quantum computer and pave the way towards a quantum treatment of
low-frequency noise in more complex architectures.

</details>


### [601] [Affine Equivalence in the Clifford Hierarchy](https://arxiv.org/abs/2507.14370)
*Jonas T. Anderson,Andrew Connelly*

Main category: quant-ph

TL;DR: 该论文研究了克利福德层级中的排列，特别是4脑象排列。它表明这些排列是半克利福德的，并引入了周期结构的概念来更好地理解它们。


<details>
  <summary>Details</summary>
Motivation: 该论文的动机是研究克利福德层级中排列的结构，特别是重点关注4脑象排列，并揭示其仿射等价类、周期结构以及它们在克利福德层级中的层数。

Method: 该论文利用密码学文献中关于4位排列的仿射等价类的结果，对克利福德层级中的所有4脑象排列进行了分类。然后，利用4脑象排列的分类和关于克利福德层级中的对角门结构的先前结果，证明了克利福德层级第三层中的所有4脑象门都是半克利福德的。

Result: 该论文证明了克利福德层级中的所有4脑象排列都是半克利福德的，并引入了周期结构的概念来描述这些排列，还提出了一个关于它们的通用结构定理。

Conclusion: 该论文的结论是，第四脑象的克利福德层级中的所有门都是半克利福德的，并且引入了克利福德层级中的排列的周期结构形式化，并证明了它们的通用结构定理。

Abstract: In this paper we prove a collection of results on the structure of
permutations in the Clifford Hierarchy. First, we leverage results from the
cryptography literature on affine equivalence classes of 4-bit permutations
which we use to find all 4-qubit permutations in the Clifford Hierarchy. We
then use the classification of 4-qubit permutations and previous results on the
structure of diagonal gates in the Clifford Hierarchy to prove that all 4-qubit
gates in the third level of the Clifford Hierarchy are semi-Clifford. Finally,
we introduce the formalism of cycle structures to permutations in the Clifford
Hierarchy and prove a general structure theorem about them. We also classify
many small cycle structures up to affine equivalence. Interestingly, this
classification is independent of the number of qubits.

</details>


### [602] [Quantum Annealing for Machine Learning: Applications in Feature Selection, Instance Selection, and Clustering](https://arxiv.org/abs/2507.15063)
*Chloe Pomeroy,Aleksandar Pramov,Karishma Thakrar,Lakshmi Yendapalli*

Main category: quant-ph

TL;DR: 本研究将量子退火（QA）应用于特征选择、实例选择和聚类问题，结果表明QA在计算效率和优化效果方面具有潜力，是离散机器学习优化的有效工具。


<details>
  <summary>Details</summary>
Motivation: 探索量子退火（QA）和经典模拟退火（SA）在机器学习组合优化问题中的应用。

Method: 将特征选择、实例选择和聚类任务表述为二次无约束二元优化（QUBO）问题，并使用量子退火（QA）和经典模拟退火（SA）求解器进行求解。

Result: QA在特征选择方面提供了更优的计算效率；在实例选择方面，提出了新的实例级别重要性度量方法；在聚类方面，通过结合经典聚类和基于QUBO的中心点优化，在聚类紧密度和检索指标方面取得了一致性改进。

Conclusion: QA可作为当前硬件约束下的离散机器学习优化的竞争性和高效工具。

Abstract: This paper explores the applications of quantum annealing (QA) and classical
simulated annealing (SA) to a suite of combinatorial optimization problems in
machine learning, namely feature selection, instance selection, and clustering.
We formulate each task as a Quadratic Unconstrained Binary Optimization (QUBO)
problem and implement both quantum and classical solvers to compare their
effectiveness. For feature selection, we propose several QUBO configurations
that balance feature importance and redundancy, showing that quantum annealing
(QA) produces solutions that are computationally more efficient. In instance
selection, we propose a few novel heuristics for instance-level importance
measures that extend existing methods. For clustering, we embed a
classical-to-quantum pipeline, using classical clustering followed by
QUBO-based medoid refinement, and demonstrate consistent improvements in
cluster compactness and retrieval metrics. Our results suggest that QA can be a
competitive and efficient tool for discrete machine learning optimization, even
within the constraints of current quantum hardware.

</details>


### [603] [Quasi-degenerate resonant eigenstate doublets of two quantum emitters in a closed waveguide](https://arxiv.org/abs/2507.14371)
*Ammara Ammara,Paolo Facchi,Saverio Pascazio,Francesco V. Pepe,Debmalya Das*

Main category: quant-ph

TL;DR: 研究了两个发射器耦合到波导中的共振双峰，为量子技术提供了新的工具。


<details>
  <summary>Details</summary>
Motivation: 量子发射器系统的物理性质显著受到其空间分离与发射光子波长之间关系的影响。在特定共振条件下，光子可能发生破坏性干涉，从而形成束缚态。

Method: 研究了两个相同发射器耦合到线性波导模式下准简并共振双峰的存在性。搜寻了在单个激发倾向于束缚在发射器上的状态中的双峰态，并研究了退化点附近的谱，以检查双峰是否与谱中最接近的特征值良好分离。

Result: 在有限长度波导中，当短路径与长路径的比例为有理数时，两种类型的共振态（束缚在较短或较长路径中）可以共存于同一哈密顿量中。当短路径与长路径的比例为有理数时，这两种类型的共振态可以共存于同一哈密顿量中。

Conclusion: 识别出的准简并共振双峰为量子技术任务提供了操控发射器-波导系统作为有效两能级系统的可能性。

Abstract: The physics of systems of quantum emitters is significantly influenced by the
relation between their spatial separation and the wavelength of the emitted
photons. If the distance that separates a pair of emitters meets specific
resonance conditions, the photons produced from decay may destructively
interfere. In an infinite-wavelength setting, this effect gives rise to bound
states in the continuum, where a photon remains confined in between the
emitter. In the case of a finite-length waveguide with two periodic boundary
conditions, the relevant distances become two, leading to states in which a
photon is confined in either the shorter or the longer path that connects the
emitters. If the ratio of the shorter and the longer path is a rational number,
these two kinds of resonant states are allowed to co-exist in the same
Hamiltonian. In this paper, we investigate the existence of quasi-degenerate
resonant doublets of a pair of identical emitters coupled to a linear waveguide
mode. The states that form the doublet are searched among the ones in which a
single excitation tends to remain bound to the emitters. We investigate the
spectrum in a finite range around degeneracy points to check whether the
doublet remains well separated from the closest eigenvalues in the spectrum.
The identification of quasi-degenerate doublets opens the possibility to
manipulate the emitters-waveguide system as an effectively two-level system in
specific energy ranges, providing an innovative tool for quantum technology
tasks.

</details>


### [604] [Quantum Internet in a Nutshell -- Advancing Quantum Communication with Ion Traps](https://arxiv.org/abs/2507.14383)
*Janine Hilder,Sascha Heußen,Anke Ginter,Andreas Wilke,Ulrich Poschinger,Ferdinand Schmidt-Kaler,Wadim Wormsbecher*

Main category: quant-ph

TL;DR: QI-Nutshell在量子计算机上仿真了量子通信协议，并通过注入噪音和量子纠错码研究了其对协议安全性的影响，提出了利用量子纠错码进行隐私认证的可能性。


<details>
  <summary>Details</summary>
Motivation: QI-Nutshell旨在连接量子通信和量子计算的领域，通过在当前的离子阱量子计算机上仿真量子通信协议。

Method: 对BB84或BBM92等量子密钥分发（QKD）协议进行仿真，将各个步骤映射到离子阱量子计算机上的物理操作。我们还通过数值模拟研究了量子纠错（QEC）码在QKD协议中的应用，并注入噪音以研究其对量子通信协议的影响。

Result: 仿真结果表明，量子纠错码可以帮助抑制噪音水平，监测信道的噪音分布，使通信方能够检测到潜在窃听造成的异常噪音特征，从而为量子通信提供隐私认证。

Conclusion: 通过在量子纠错码中加入对量子通信协议的噪音注入，我们能够实现对量子通信协议的检测，并为量子通信提供隐私认证。

Abstract: Quantum Internet in a Nutshell (QI-Nutshell) connects the fields of quantum
communication and quantum computing by emulating quantum communication
protocols on currently available ion-trap quantum computers. We demonstrate
emulations of QKD protocols where the individual steps are mapped to physical
operations within our hardware platform. This allows us to not only practically
execute established protocols such as BB84 or BBM92, but also include cloning
attacks by an eavesdropping party, noise sources and side-channel attacks that
are generally hard to include in theoretical QKD security proofs. We
deliberately inject noise and investigate its effect on quantum communication
protocols. We employ numerical simulations in order to study the incorporation
of small quantum error correction (QEC) codes into QKD protocols. We find that
these codes can help to suppress the noise level and to monitor the noise
profile of the channel. This may enable the communicating parties to detect
suspicious deviations from expected noise characteristics as a result of
potential eavesdropping. This suggests that QEC may serve as a means of privacy
authentication for quantum communication without altering the transmitted
quantum information.

</details>


### [605] [An Effective Reflection Mode Measurement for Hanger-Coupled Microwave Resonators](https://arxiv.org/abs/2507.14394)
*John R. Pitten,Nicholas Materise,Wei-Ren Syong,Jorge Ramirez,Douglas Bennett,Corey Rae H. McRae*

Main category: quant-ph

TL;DR: 本研究提出了一种消除超导谐振器中法诺不对称性的方法，通过获得无不对称性的ERM，提高了测量精度和效率，有望大幅提升测量吞吐量。


<details>
  <summary>Details</summary>
Motivation: 法诺不对称性（由直径校正法（DCM）中的非零不对称角$\	ext{phi}$表征）是由测量这些设备所用的耦合方案引起的，并且会掩盖设备参数。本研究旨在消除法诺不对称性，以更精确地提取设备参数。

Method: 通过校准测量获得ERM，并利用微扰理论在多路复用平面波导谐振器设备中恢复ERM。

Result: 实验证明了该模型在3D铝腔和多路复用平面波导谐振器设备中的有效性和灵活性。与标准的吊杆模式相比，ERM在最低测量功率下（-160 dBm）将不确定性降低了五倍。该方法有望将低功率超导谐振器测量的吞吐量提高25倍，并能从无法拟合的数据中提取关键参数。

Conclusion: 该研究提出了一种消除超导量子设备中法诺不对称性的方法，该方法利用了谐振器设备的T型结对称性。通过校准测量，可以获得一个没有法诺不对称性的有效反射模式（ERM）。

Abstract: Superconducting microwave resonators are used to study two-level system (TLS)
loss in superconducting quantum devices. Fano asymmetry, characterized by a
nonzero asymmetry angle $\phi$ in the diameter correction method (DCM), results
from the coupling schemes used to measure these devices, including the commonly
used hanger method. $\phi$ is an additional fitting parameter which contains no
physically interesting information and can obscure device parameters of
interest. The tee-junction symmetry nominally present in these resonator
devices provides an avenue for the elimination of Fano asymmetry using
calibrated measurement. We show that the eigenvalue associated with the common
mode excitation of the resonator is an effective reflection mode (ERM) which
has no Fano asymmetry. Our analysis reveals the cause of Fano asymmetry as
interference between common and differential modes. Practically, we obtain the
ERM from a linear combination of calibrated reflection and transmission
measurements. We utilize a 3D aluminum cavity to experimentally demonstrate the
validity and flexibility of this model. To extend the usefulness of this
symmetry analysis, we apply perturbation theory to recover the ERM in a
multiplexed coplanar waveguide resonator device and experimentally demonstrate
quantitative agreement in the extracted $Q_i^{-1}$ between hanger mode and ERM
measurements. We observe a five-fold reduction in uncertainty from the ERM
compared to the standard hanger mode at the lowest measured power, -160 dBm
delivered to the device. This method could facilitate an increase in throughput
of low-power superconducting resonator measurements by up to a factor of 25, as
well as allow the extraction of critical parameters from otherwise unfittable
device data.

</details>


### [606] [Mitigating state transition errors during readout with a synchronized flux pulse](https://arxiv.org/abs/2507.14436)
*Yulong Li,Wuerkaixi Nuerbolati,Chunqing Deng,Xizheng Ma,Haonan Xiong,Haifeng Yu*

Main category: quant-ph

TL;DR: 由于测量引起的量子比特状态跃迁会损害量子纠错等任务。本研究通过同步通量偏置和读出光子动力学，利用通量奇异量子比特的通量可调性，实现了99%（0.5微秒）的读出保真度，克服了状态跃迁问题。


<details>
  <summary>Details</summary>
Motivation: 量子比特测量期间的状态跃迁对依赖重复测量的量子任务（如量子纠错）非常不利，因为过度的测量功率会导致量子比特激发超出其计算空间，或者测量协议会无意中将量子比特耦合到有损耗模式（如两能级系统TLS）。

Method: 通过测量不同约通量偏置下的量子比特跃迁误差，实验验证了TLS对量子比特读出的影响。利用量子比特的通量可调性，通过同步读出光子动力学和约通量偏置来避免在通量奇异读出中发生状态跃迁。

Result: 在1微秒（0.5微秒）的积分时间内，实现了99%（98.4%）的最佳读出保真度。

Conclusion: 该研究通过同步读出光子动力学和约通量偏置，实现了高通量奇异量子比特的快速高保真读出，为超导电路测量中的状态跃迁提供了新的见解，并展示了奇异量子比特在实现快速高保真读出方面的潜力。

Abstract: State transitions during qubit measurements are extremely detrimental to
quantum tasks that rely on repeated measurements, such as quantum error
correction. These state transitions can occur when excessive measurement power
leads to qubit excitations outside its computational space. Alternatively, the
qubit state can decay rapidly when the measurement protocol inadvertently
couples the qubit to lossy modes such as two-level systems (TLSs). We
experimentally verify the impact of these TLSs in qubit readout by measuring
the transition errors at different qubit flux bias. Because such state
transitions during measurements are often localized in frequency space, we
demonstrate the ability to avoid them during a fluxonium readout by exploiting
the qubit's flux-tunability. By synchronizing the flux bias with the readout
photon dynamics, we obtain an optimal readout fidelity of 99 % (98.4 %) in 1 us
(0.5 us) integration time. Our work advances the understanding of state
transitions in superconducting circuit measurements and demonstrates the
potential of fluxonium qubits to achieve fast high-fidelity readout.

</details>


### [607] [Deterministic Quantum Search via Recursive Oracle Expansion](https://arxiv.org/abs/2507.15797)
*John Burke,Ciaran McGoldrick*

Main category: quant-ph

TL;DR: 一种新的确定性量子搜索算法，通过递归扩展预言机来标记目标的前缀，实现确定性搜索，查询复杂度优于经典搜索但略逊于Grover搜索。该算法使用近邻扩散算子，在门操作数量上更优，并支持部分数据库搜索，适合硬件实现。


<details>
  <summary>Details</summary>
Motivation: 为了克服现有确定性量子搜索方法依赖任意相位旋转的局限性，提供一种不含不确定性的实用量子搜索替代方案。

Method: 提出了一种新颖的确定性量子搜索算法，通过递归扩展基础预言机，使其标记所有以与目标相同的两个比特作为前缀的状态，从而覆盖四分之一的搜索空间。通过逐步减小叠加态，最终可以确定性地测量目标状态。

Result: 该算法实现了确定性成功，查询复杂度为$O(N^{\log_2(3)/2}) \approx O(N^{0.7925})$。它仅使用双量子比特近邻扩散算子，在减少所需双量子比特门数量方面比Grover算法有显著优势，特别是在量子比特连通性有限的硬件上。该算法还支持部分数据库搜索，可用于确定性地识别选定目标比特。

Conclusion: 该算法通过递归地扩展基础预言机来标记所有以与目标相同的两个比特作为前缀的状态，从而实现确定性成功。它实现了$O(N^{\log_2(3)/2}) \approx O(N^{0.7925})$的查询复杂度，介于Grover的$O(\sqrt{N})$和经典$O(N)$之间。该方法仅使用双量子比特近邻扩散算子，避免了全局扩散。与Grover算法相比，该算法在扩散所需双量子比特门数量上减少了一个数量级以上，尤其是在量子比特连通性有限的硬件上优势更明显。其确定性、对简单近邻低深度操作的依赖以及可扩展的递归结构使其适合硬件实现。此外，该算法还支持部分数据库搜索，无需进行完整搜索即可确定性地识别选定的目标比特。

Abstract: We introduce a novel deterministic quantum search algorithm that provides a
practical alternative to conventional probabilistic search approaches. Our
scheme eliminates the inherent uncertainty of quantum search without relying on
arbitrary phase rotations, a key limitation of other deterministic methods. The
algorithm achieves certainty by recursively expanding the base oracle so that
it marks all states prefixed by the same two bits as the target, encompassing
exactly one-quarter of the search space. This enables a step-by-step reduction
of the superposition until the target state can be measured with certainty. The
algorithm achieves deterministic success with a query complexity of
$O(N^{\log_2(3)/2}) \approx O(N^{0.7925})$, falling between Grover's
$O(\sqrt{N})$ scaling and the classical $O(N)$. Our approach relies exclusively
on two-qubit nearest-neighbour diffusion operators, avoiding global diffusion
entirely. We show that, despite the increased query complexity, this design
reduces the total number of two-qubit gates required for diffusion by more than
an order of magnitude for search spaces up to at least 18 qubits, with even
greater advantages on hardware with limited qubit connectivity. The scheme's
inherent determinism, reliance on simple nearest-neighbour, low-depth
operations, and scalable recursive structure make it well-suited for hardware
implementation. Additionally, we show that the algorithm naturally supports
partial database search, enabling deterministic identification of selected
target bits without requiring a full search, further broadening its
applicability.

</details>


### [608] [Multipartite entanglement from ditstrings for 1+1D systems](https://arxiv.org/abs/2507.14422)
*Zane Ozzello,Yannick Meurice*

Main category: quant-ph

TL;DR: 多方纠缠可用于有效识别1+1D系统的临界点，并能比单独的纠缠量更精确地识别相边界的行为。互信息也可用于近似纠缠，并在滤波后提供改进的下界。


<details>
  <summary>Details</summary>
Motivation: 本研究的动机在于探索多方纠缠在识别一维量子系统临界点方面的潜力，并提出一种基于纠缠量组合的有效方法。

Method: 利用多方纠缠量组合，包括强次可加性、弱单调性和与共形性质的凸组合，来识别临界点。还展示了如何扩展用互信息近似纠缠的方案，该互信息可作为下界，并能很好地响应滤波过程，从而改进下界。

Result: 研究结果表明，多方纠缠量能够比单独的纠缠量更精确地识别和定位相边界处的行为。互信息作为一种近似方法，同样能有效地追踪纠缠量的变化，并且在滤波处理后能提供改进的下界。

Conclusion: 文章表明，多方纠缠可用于有效识别1+1D系统的临界点，并在量子伊辛模型、λ φ^4格点（用qutrits近似）和里德伯原子阵列中得到了验证。

Abstract: We show that multipartite entanglement can be used as an efficient way of
identifying the critical points of 1+1D systems. We demonstrate this with the
quantum Ising model, lattice $\lambda \phi^4$ approximated with qutrits, and
arrays of Rydberg atoms. To do so we make use of multipartite compositions of
entanglement quantities for different parts combined to form the strong
subadditivity, weak monotonicity, and a convex combination of these with
conformal properties. These quantities display some remarkable properties. We
will demonstrate how the entanglement of individual parts together displays
behavior at phase boundaries, but the combination of these in the
aforementioned quantities sharpens and localizes this behavior to the
boundaries even better. We will show that we can extend a scheme for
approximating the entanglement with the mutual information, and that this acts
as a lower bound which will also follow the changes in the entanglement for the
above quantities, despite the additional contributions of different signs. This
mutual information approximation to the identifying quantities can have its
lower probabilities removed in a process we call filtering, and despite the
combination of terms will respond well to the filtering and offer improvements
to the lower bound.

</details>


### [609] [High-fidelity, quasi-deterministic entanglement generation using phase-matched spectral islands in a zero-added-loss multiplexing architecture](https://arxiv.org/abs/2507.14427)
*Jeffrey H. Shapiro,Clark Embleton,Michael G. Raymer,Brian J. Smith*

Main category: quant-ph

TL;DR: 本研究提出了一种改进的ZALM方案，利用多频段聚合和考虑损耗，大幅提高了纠缠分发速率，并减少了所需频谱通道数，为实现量子互联网铺平了道路。


<details>
  <summary>Details</summary>
Motivation: 为了解决当前量子互联网所需的纠缠分发速率远低于实际需求的问题，提出一种能够显著提高纠缠分发速率的方案。

Method: 通过改进零附加损耗复用（ZALM）方案，利用 Morrison 等人提出的域工程方法，在 $\chi^{(2)}$ 晶体中实现了具有 8 个离散且光谱可分离频段的双光子波函数。通过采用同一频段和不同频段的信号聚合（heralding）机制，使得纠缠分发速率与频段数量 $N_I$ 的平方成正比（在弱压缩情况下），相比于原始ZALM方案（与 $N_I$ 成正比）有了显著提升，同时能够更准确地考虑多对、部分基站之间测量（BSM）的损耗以及传输过程中的损耗。

Result: 所提出的ZALM方案通过利用同一频段和不同频段的信号聚合，使纠缠分发速率在弱压缩情况下可扩展至 $N_I^2$，而原始方案仅为 $N_I$。同时，该方案所需的频谱通道数量大大减少（$N_I \ll 800$），并能更全面地考虑各种损耗因素，有望实现近期的星地或光纤ZALM架构。

Conclusion: 该研究提出的改进型零附加损耗复用（ZALM）方案，通过利用同一频段和不同频段的信号聚合，实现了比现有技术更高的纠缠分发速率，并且所需的频谱通道数量大大减少，有望实现近期的星地或光纤ZALM架构。

Abstract: While photonic entanglement generation and distribution are well developed,
their demonstrated rates are far below what is needed for a quantum internet.
The present paper proposes and analyzes a scheme for spectral multiplexing that
provides entanglement-distribution rates well in excess of the state of the
art. It builds on the idea presented by Chen~\emph{et al}.~[Phys. Rev. Appl.
{\bf 19}, 054209 (2023)], who proposed zero-added-loss multiplexing (ZALM) as a
means for high-fidelity, quasi-deterministic entanglement generation.
Unfortunately, Chen \emph{et al}.'s ZALM requires a large number (800) of
spectral channels to achieve its claimed high-fidelity, quasi-deterministic,
high-rate entanglement generation. Our modified version of ZALM affords major
performance improvements over the original. It draws on Morrison~\emph{et
al}.~[APL Photon. {\bf 7}, 066102 (2022)], who domain engineered a $\chi^{(2)}$
crystal to realize a biphoton wave function with 8 discrete and
spectrally-factorable frequency bins. Our ZALM SPDCs each have a modest number
($N_I\ll$ 800) of these phase-matched spectral islands each generating two-mode
squeezed-vacuum states, permitting our analysis, unlike Chen~\emph{et al.}'s,
to account for multipairs of all orders, losses in the partial BSM, and
propagation losses en route to the receivers. A major innovation in our
proposal is to employ both same-island heralding and cross-island heralding,
which allows the entanglement-delivery rate to scale as $N_I^2$ rather than
$N_I$ in the weak squeezing regime required for the reception of photon pairs
with a high Bell-state fidelity under realistic losses. This heralding scheme
uses an order of magnitude fewer spectral channels, which may enable near-term
implementations of satellite-to-ground or fiber-optic based ZALM architectures.

</details>


### [610] [Quantum Circuit Optimization Based on Dynamic Grouping and ZX-Calculus for Reducing 2-Qubit Gate Count](https://arxiv.org/abs/2507.14434)
*Kai Chen,Wen Liu,GuoSheng Xu,Yangzhi Li,Maoduo Li,Shouli He*

Main category: quant-ph

TL;DR: 本研究提出了一种基于动态分组和 ZX-演算的量子电路优化方法，以减少 NISQ 时代量子电路中的两比特门数量。该方法通过将电路划分为子电路、进行 ZX-演算引导的优化以及使用模拟退火来迭代更新分组策略，成功减少了两比特门数量，并优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 在嘈杂的中等规模量子 (NISQ) 时代，量子电路中的两比特门比单比特门更容易受到噪声的影响。因此，减少两比特门数量对于提高电路效率和可靠性至关重要。随着量子电路规模的扩大，优化搜索空间变得越来越复杂，导致效率低下和次优解等挑战。

Method: 该方法基于动态分组和 ZX-演算。首先，使用基于随机策略的动态分组方法将量子电路划分为多个子电路。其次，进行基于 ZX-演算引导的 k 步前瞻搜索，对等效子电路进行过滤，以最大限度地减少两比特门数量。第三，通过延迟感知放置方法优化重新组合后的电路，以减少整体门数量。最后，通过模拟退火迭代更新分组策略，以实现优化的两比特门数量。

Result: 实验结果表明，该方法在减少两比特门数量方面是有效且优越的。与原始电路相比，该方法实现了 18% 的平均两比特门数量减少。与经典方法相比，性能提高了 25%，尤其是在 GF 电路方面，并且比基于 ZX-演算的启发式方法提高了 4% 的平均性能，证明了其效率。

Conclusion: 该方法在减少两比特门数量方面是有效且优越的。与原始电路相比，该方法实现了 18% 的平均两比特门数量减少。与经典方法相比，性能提高了 25%，尤其是在 GF 电路方面，并且比基于 ZX-演算的启发式方法提高了 4% 的平均性能，证明了其效率。

Abstract: In the noisy intermediate-scale quantum (NISQ) era, two-qubit gates in
quantum circuits are more susceptible to noise than single-qubit gates.
Therefore, reducing the number of two-qubit gates is crucial for improving
circuit efficiency and reliability. As quantum circuits scale up, the
optimization search space becomes increasingly complex, leading to challenges
such as low efficiency and suboptimal solutions. To address these issues, this
paper proposes a quantum circuit optimization approach based on dynamic
grouping and ZX-calculus. First, a random strategy-based dynamic grouping
method partitions the circuit into multiple subcircuits. Second, a ZX-calculus
guided k-step lookahead search performs equivalent subcircuit filtering to
minimize two-qubit gate counts. Third, a delay-aware placement method optimizes
the recombined circuit to reduce the overall gate count. Finally, simulated
annealing iteratively updates the grouping strategy to achieve an optimized
two-qubit gate count. Experimental results on benchmark datasets demonstrate
the effectiveness and superiority of the proposed method in reducing two-qubit
gates. Compared to the original circuits, the approach achieves an average
reduction of 18% in two-qubit gates. It outperforms classical methods with up
to 25% reduction, especially on gf circuits, and shows a 4% average improvement
over heuristic ZX-calculus-based methods, validating its efficiency.

</details>


### [611] [Quantum State Preparation Based on LimTDD](https://arxiv.org/abs/2507.14496)
*Xin Hong,Chenjian Li,Aochu Dai,Sanjiang Li,Shenggang Ying,Mingsheng Ying*

Main category: quant-ph

TL;DR: LimTDD是一种结合张量网络和判定图的新型量子状态制备方法，相比现有方法在处理复杂量子态时效率更高，电路复杂度更低。


<details>
  <summary>Details</summary>
Motivation: 随着量子技术的发展，高效的量子状态制备变得越来越重要。

Method: 提出了一种基于局部可逆映射张量判定图（LimTDD）的新型量子状态制备方法，该方法结合了张量网络和判定图的优点，能够有效地表示和操作量子态。

Result: 与现有的量子状态制备方法相比，LimTDD在处理复杂量子态时表现出显著的效率提升，并降低了量子电路的复杂度，在某些情况下可实现指数级的效率提升。

Conclusion: 该研究展示了LimTDD在量子状态制备方面的潜力，并为未来量子计算技术的发展奠定了坚实的理论和实践基础。

Abstract: Quantum state preparation is a fundamental task in quantum computing and
quantum information processing. With the rapid advancement of quantum
technologies, efficient quantum state preparation has become increasingly
important. This paper proposes a novel approach for quantum state preparation
based on the Local Invertible Map Tensor Decision Diagram (LimTDD). LimTDD
combines the advantages of tensor networks and decision diagrams, enabling
efficient representation and manipulation of quantum states. Compared with the
state-of-the-art quantum state preparation method, LimTDD demonstrates
substantial improvements in efficiency when dealing with complex quantum
states, while also reducing the complexity of quantum circuits. Examples
indicate that, in the best-case scenario, our method can achieve exponential
efficiency gains over existing methods. This study not only highlights the
potential of LimTDD in quantum state preparation but also provides a robust
theoretical and practical foundation for the future development of quantum
computing technologies.

</details>


### [612] [Spectator Leakage Elimination in CZ Gates via Tunable Coupler Interference on a Superconducting Quantum Processor](https://arxiv.org/abs/2507.14531)
*Peng Wang,Bin-Han Lu,Tian-Le Wang,Sheng Zhang,Zhao-Yun Chen,Hai-Feng Zhang,Ren-Ze Zhao,Xiao-Yan Yang,Ze-An Zhao,Zhuo-Zhi Zhang,Xiang-Xiang Song,Yu-Chun Wu,Peng Duan,Guo-Ping Guo*

Main category: quant-ph

TL;DR: 提出一种基于动态哈密顿量重塑的泄漏抑制策略，通过将门动力学限制在二维不变子空间内，有效防止泄漏，并在实验中得到验证。


<details>
  <summary>Details</summary>
Motivation: 解决可扩展量子计算中由光谱诱导泄漏引起的挑战，尤其是在多量子比特处理器中频率碰撞不可避免的情况下。

Method: 通过可调耦合器动态重塑系统哈密顿量，实现其有效哈密顿量的块对角化结构，将门操作限制在二维不变子空间内，从而从根本上消除泄漏。

Result: 在超导处理器上，该技术在较宽的近共振失谐范围内将泄漏率抑制到 $10^{-4}$ 的量级，并且随着光谱数量的增加具有良好的可扩展性。在有三个同时光谱的情况下，总泄漏量低于表面码纠错的相关阈值。

Conclusion: 动态哈密顿量工程是推进容错量子计算的关键工具，能够有效缓解量子比特频率碰撞问题。

Abstract: Spectator-induced leakage poses a fundamental challenge to scalable quantum
computing, particularly as frequency collisions become unavoidable in
multi-qubit processors. We introduce a leakage mitigation strategy based on
dynamically reshaping the system Hamiltonian. Our technique utilizes a tunable
coupler to enforce a block-diagonal structure on the effective Hamiltonian
governing near-resonant spectator interactions, confining the gate dynamics to
a two-dimensional invariant subspace and thus preventing leakage by
construction. On a multi-qubit superconducting processor, we experimentally
demonstrate that this dynamic control scheme suppresses leakage rates to the
order of $10^{-4}$ across a wide near-resonant detuning range. The method also
scales effectively with the number of spectators. With three simultaneous
spectators, the total leakage remains below the threshold relevant for surface
code error correction. This approach eases the tension between dense frequency
packing and high-fidelity gate operation, establishing dynamic Hamiltonian
engineering as an essential tool for advancing fault-tolerant quantum
computing.

</details>


### [613] [Quantum Sensing Enhancement through a Nuclear Spin Register in Nitrogen-Vacancy Centers in Diamond](https://arxiv.org/abs/2507.14563)
*Jonathan Kenny,Feifei Zhou,Ruihua He,Fedor Jelezko,Teck Seng Koh,Weibo Gao*

Main category: quant-ph

TL;DR: 本文综述了金刚石NV色心量子传感技术，特别是核自旋辅助协议在提高相干性和灵敏度方面的应用，并探讨了未来的发展方向。


<details>
  <summary>Details</summary>
Motivation: 量子传感技术发展迅速，但NV色心等固态自旋系统易受环境噪声影响，限制了其灵敏度。因此，提高NV色心的相干性和灵敏度是关键任务。

Method: 本文综述了NV色心在金刚石中的量子传感，重点介绍了核自旋辅助协议在保护电子自旋相干性方面的作用，并讨论了其在量子信息协议中的应用。

Result: 核自旋辅助协议通过利用天然存在的电子-核自旋对和核自旋更长的相干时间，能够有效增强NV色心的电子自旋相干性，从而提高传感灵敏度。

Conclusion: NV中心和核自旋辅助协议在量子传感、核自旋谱、原子成像和磁传感方面具有广阔的应用前景，但仍面临灵敏度提升和商业化等挑战。

Abstract: Quantum sensing has seen rapid progress from laboratory research to
real-world applications. Solid-state spin systems, particularly
nitrogen-vacancy (NV) centers in diamond, are attractive for their ability to
operate at room temperature with high sensitivity. However, electron spin
coherence due to noise from the surrounding spin bath and this environment
effect limits the sensitivity of NV centers. Thus, a critical task in NV
center-based quantum sensing is sensitivity enhancement through coherence
protection. Nuclear spin assisted protocols have demonstrated greater
enhancement of electron spin coherence due to the naturally occurring electron
and nuclear spin pair. The longer nuclear coherence times allow for long-lived
memory bit for quantum information protocols. This review discusses the physics
of NV centers, the mechanisms and variations of nuclear spin-assisted
protocols, and their applications in nuclear spin spectroscopy, atomic imaging,
and magnetic sensing. Challenges in sensitivity enhancement, commercialization
prospects, and future research directions are also explored.

</details>


### [614] [Subradiance generation in a chain of two-level atoms with a single excitation](https://arxiv.org/abs/2507.14663)
*Nicola Piovella*

Main category: quant-ph

TL;DR: 本研究通过动力学模拟研究了原子链中的亚辐射现象，发现了亚辐射的产生机制，并为实验探测提供了理论基础。


<details>
  <summary>Details</summary>
Motivation: 本研究旨在解决亚辐射如何从初始激发或激光驱动的原子中产生的关键问题，以期指导未来在有序系统中探测亚辐射的实验。

Method: 本研究通过求解N原子的耦合偶极方程，并评估原子处于广义迪克状态的概率来研究亚辐射的动力学。

Result: 本研究识别了亚辐射区域，并展示了不同初始激发条件和激光驱动下亚辐射的产生情况，为相关实验提供了参考。

Conclusion: 本研究探讨了亚辐射现象的动力学行为，通过求解耦合偶极方程并评估原子处于广义迪克状态的概率，阐述了亚辐射的产生机制，并讨论了不同的初始激发条件和激光驱动下的情况。

Abstract: Studies of subradiance in a chain N two-level atoms in the single excitation
regime focused mainly on the complex spectrum of the effective Hamiltonian,
identifying subradiant eigenvalues. This can be achieved by finding the
eigenvalues $N$ of the Hamiltonian or by evaluating the expectation value of
the Hamiltonian on a generalized Dicke state, depending on a continuous
variable k. This has the advantage that the sum above N can be calculated
exactly, such that N becomes a simple parameter of the system and no more the
size of the Hilbert space. However, the question remains how subradiance
emerges from atoms initially excited or driven by a laser. Here we study the
dynamics of the system, solving the coupled-dipole equations for N atoms and
evaluating the probability to be in a generalized Dicke state at a given time.
Once the subradiant regions has been identified, it is simple to see if
subradiance is being generated. We discuss different initial excitation
conditions that lead to subradiance and the case of atoms excited by switching
on and off a weak laser. This may be relevant for future experiments aimed at
detecting subradiance in ordered systems.

</details>


### [615] [Are Events Absolute?](https://arxiv.org/abs/2507.14672)
*Herve Zwirn*

Main category: quant-ph

TL;DR: 本文介绍了维格纳的朋友思想实验，一个挑战量子力学基础的著名思想实验，并讨论了其近期发展，暗示事件的绝对性已不复存在。


<details>
  <summary>Details</summary>
Motivation: 该论文旨在深入探讨维格纳的朋友思想实验，该实验对量子力学提出了深刻的挑战，并促使人们思考现实的本质、观察行为以及意识在量子测量过程中的作用。

Method: 对维格纳的初始思想实验及其近期理论进展和扩展版本进行了普遍的介绍和审视。

Result: 近期版本的实验似乎意味着事件不再可能被视为绝对的。

Conclusion: 该论文探讨了维格纳的朋友思想实验的近期理论进展和扩展版本，暗示事件不再是绝对的。

Abstract: The Wigner's Friend thought experiment stands as one of the most
intellectually provocative and challenging conceptual puzzles in quantum
mechanics. It compels us to confront profound questions concerning the
fundamental nature of reality, the very act of observation, and the possible
role that consciousness might play within the quantum measurement process. This
article gives a general presentation, beginning with Eugene Wigner's seminal
proposal of the original thought experiment. In this paper, we explore its
initial implications, which shook the foundations of classical physics, and
then progress to an examination of the recent theoretical advancements and the
ingenious extended versions of the experiment. The recent versions seem to
imply that it is no more possible to consider events as absolute.

</details>


### [616] [Scalable modular architecture for universal quantum computation](https://arxiv.org/abs/2507.14691)
*Fernando Gago-Encinas,Christiane P. Koch*

Main category: quant-ph

TL;DR: 量子计算的可控性可以通过连接较小的可控单元来构建模块化QPU。


<details>
  <summary>Details</summary>
Motivation: 为了开发资源高效的量子处理单元（QPU），确定实现演化算子可控性所需的局部控制和比特耦合的数量很重要。

Method: 证明了可控性可以通过连接较小的、可控的量子比特阵列来构建，每次连接使用一个单比特门。

Result: 提出了一种构建模块化QPU的方法，可以从具有较少局部控制和耦合的小模块开始构建。

Conclusion: 通过连接两个可控的量子比特阵列，可以获得可控的复合量子比特阵列。

Abstract: Universal quantum computing requires the ability to perform every unitary
operation, i.e., evolution operator controllability. In view of developing
resource-efficient quantum processing units (QPUs), it is important to
determine how many local controls and qubit-qubit couplings are required for
controllability. Unfortunately, assessing the controllability of large qubit
arrays is a difficult task, due to the exponential scaling of Hilbert space
dimension. Here we show that it is sufficient to connect two qubit arrays that
are evolution operator controllable by a single entangling two-qubit gate in
order to obtain a composite qubit array that is evolution operator
controllable. Our proof provides a template to build up modular QPUs from
smaller building blocks with reduced numbers of local controls and couplings.
We illustrate the approach with two examples, consisting of 10, respectively
127 qubits, inspired by IBM quantum processors.

</details>


### [617] [Improving the Rate-Loss Scaling in Polarization Entanglement Distribution using Single-Click Entanglement Swapping](https://arxiv.org/abs/2507.14836)
*Hikaru Shimizu,Joe Yoshimoto,Daiki Ichii,Junko Ishi-Hayase,Rikizo Ikuta,Masahiro Takeoka*

Main category: quant-ph

TL;DR: 本研究通过一种结合偏振-光子数混合纠缠和单次点击纠缠交换的协议，克服了偏振纠缠在损耗信道中传输速率的限制，实现了比传统方法更好的速率-损耗扩展，为量子网络的发展提供了可能。


<details>
  <summary>Details</summary>
Motivation: 为了克服偏振纠缠在损耗信道中传输速率受限于O(η)的扩展问题。

Method: 通过整合偏振-光子数混合纠缠和单次点击纠缠交换的思想，并结合偏振纠缠分发，实现了比传统方法平方根的速率-损耗扩展。

Result: 实现了比传统方法平方根的速率-损耗扩展，对于分布式偏振纠缠光子对实现了0.843的保真度，这种速率-损耗扩展的改进等同于单跳量子中继节点。

Conclusion: 该研究结果为构建近未来量子网络及其应用铺平了道路。

Abstract: Polarization entanglement is widely used in optical quantum information
processing due to its compatibility with standard optical components. On the
other hand, it is known that polarization entanglement is susceptible to the
loss, more precisely, its transmission rate in a lossy channel is limited by
the scaling of O({\eta}), where {\eta} is a transmittance of the channel. Here,
we experimentally demonstrate that this rate-loss scaling limit can be overcome
by a relatively simple protocol. This is possible by integrating the idea of
the polarizaion-photon-number hybrid entanglement and the single-click
entanglement swapping. We demonstrate square root improvement of the rate-loss
scaling from the conventional approaches and achieve the fidelity of 0.843 for
the distributed polarization entangled photon pairs. This improvement in the
rate-loss scaling is equivalent to that achieved by 1-hop quantum repeater
node. Our result paves a way to build a near-future quantum network and its
applications.

</details>


### [618] [Time Entangled Quantum Blockchain with Phase Encoding for Classical Data](https://arxiv.org/abs/2507.14839)
*Ruwanga Konara,Kasun De Zoysa,Anuradha Mahasinghe,Asanka Sayakkara,Nalin Ranasinghe*

Main category: quant-ph

TL;DR: 该研究提出了一种结合两种现有量子区块链方案优点的混合量子区块链协议，以应对量子计算带来的安全威胁。


<details>
  <summary>Details</summary>
Motivation: 随着量子计算的快速发展，现有的经典加密协议面临被破解的风险，这将威胁到信息安全。区块链技术严重依赖经典加密，因此需要量子技术来保障其安全。

Method: 提出了一种新的量子区块链协议，结合了时间纠缠GHZ状态区块链的绝对安全性和量子超图区块链的可扩展性与效率。

Result: 提出了一种新的量子区块链协议，旨在实现时间纠缠GHZ状态区块链的绝对安全性和量子超图区块链的可扩展性与效率。

Conclusion: 提出了一种结合了时间纠缠GHZ状态区块链和量子超图区块链优点的量子区块链协议。

Abstract: With rapid advancements in quantum computing, it is widely believed that
there will be quantum hardware capable of compromising classical cryptography
and hence, the internet and the current information security infrastructure in
the coming decade. This is mainly due to the operational realizations of
quantum algorithms such as Grover and Shor, to which the current classical
encryption protocols are vulnerable. Blockchains, i.e., blockchain data
structures and their data, rely heavily on classical cryptography. One approach
to secure blockchain is to attempt to achieve information theoretical security
by defining blockchain on quantum technologies. There have been two
conceptualizations of blockchains on quantum registers: the time-entangled
Greenberger-Horne-Zeilinger (GHZ) state blockchain and the quantum hypergraph
blockchain. On our part, an attempt is made to conceptualize a new quantum
blockchain combining features of both these schemes to achieve the absolute
security of the time-temporal GHZ blockchain and the scalability and efficiency
of the quantum hypergraph blockchain in the proposed quantum blockchain
protocol.

</details>


### [619] [Wigner quasi-probability distribution for symmetric multi-quDit systems and their generalized heat kernel](https://arxiv.org/abs/2507.14866)
*Manuel Calixto,Julio Guerrero*

Main category: quant-ph

TL;DR: 本研究提出了一个N-谱系统$ho$的准概率分布族$rac{ho$，分析了其相空间结构和Wigner函数，探讨了非经典行为与Wigner函数负值间的联系，并计算了广义热核。


<details>
  <summary>Details</summary>
Motivation: 本研究旨在构建对称N-谱系统$ho$的准概率分布族$rac{ho$，并分析其相空间结构，特别是研究非经典行为与Wigner函数负值之间的联系。

Method: 通过广义Fano多极算子和Stratonovich-Weyl核构建了一个对称N-谱系统$ho$的一参数s准概率分布族$rac{ho$. 研究分析了D=2和D=3量子比特和量子三元态的相空间结构，并绘制了相应的Wigner函数$ho$。研究还计算了广义热核，它联系了两个准概率分布$ho$和$ho'$，其中t=(s'-s)/2扮演“时间”的角色，以及它们在三核表示下的扭曲Moyal积。研究还提供了用Young图表对相空间构造的图示解释。

Result: 研究构建了一个对称N-谱系统$ho$的一参数s准概率分布族$rac{ho$，分析了D=2和D=3量子比特和量子三元态的相空间结构，并绘制了相应的Wigner函数$ho$。研究还计算了广义热核，并发现它在热力学极限N→∞下恢复了通常的高斯平滑。研究还提供了用Young图表对相空间构造的图示解释。

Conclusion: 该研究为对称N-谱系统提出了一个由广义Fano多极算子和Stratonovich-Weyl核构成的一参数s准概率分布族$ho$。研究分析了D=2（量子比特）和D=3（量子三元）的薛定谔U(D)-自旋猫态（偶数自适应相干）的相空间结构，并绘制了相应的Wigner $ho$函数。研究还探讨了非经典行为与Wigner函数负值之间的联系，并计算了联系两个准概率分布$ho$和$ho'$的广义热核，其中t=(s'-s)/2扮演“时间”的角色，以及它们在三核表示下的扭曲Moyal积。在热力学极限N→∞下，研究表明研究恢复了通常的高斯平滑。最后，研究还提供了用Young图表对相空间构造的图示解释。

Abstract: For a symmetric $N$-quDit system described by a density matrix $\rho$, we
construct a one-parameter $s$ family $\mathcal{F}^{(s)}_\rho$ of
quasi-probability distributions through generalized Fano multipole operators
and Stratonovich-Weyl kernels. The corresponding phase space is the complex
projective ${C}P^{D-1}=U(D)/U(D-1)\times U(1)$, related to fully symmetric
irreducible representations of the unitary group $U(D)$. For the particular
cases $D=2$ (qubits) and $D=3$ (qutrits), we analyze the phase-space structure
of Schr\"odinger $U(D)$-spin cat (parity adapted coherent) states and we
provide plots of the corresponding Wigner $\mathcal{F}^{(0)}_\rho$ function. We
examine the connection between non-classical behavior and the negativity of the
Wigner function. We also compute the generalized heat kernel relating two
quasi-probability distributions $\mathcal{F}^{(s)}_\rho$ and
$\mathcal{F}^{(s')}_\rho$, with $t=(s'-s)/2$ playing the role of ``time'',
together with their twisted Moyal product in terms of a trikernel. In the
thermodynamic limit $N\to\infty$, we recover the usual Gaussian smoothing for
$s'>s$. A diagramatic interpretation of the phase-space construction in terms
of Young tableaux is also provided.

</details>


### [620] [Multi-state imaginarity and coherence in qubit systems](https://arxiv.org/abs/2507.14878)
*Mao-Sheng Li,Rafael Wagner,Lin Zhang*

Main category: quant-ph

TL;DR: This paper introduces a method to measure 'imaginarity' and 'coherence' in groups of quantum states using simple two-state comparisons. It finds that these properties are linked to the geometric arrangement of the states' representations (coplanarity and collinearity). The study also reveals that some properties are not 'convex' and that simple comparisons can determine complex properties for single quantum bits but not for larger systems. The findings have applications in distinguishing quantum states and detecting spin-chirality.


<details>
  <summary>Details</summary>
Motivation: The motivation stems from the growing interest in characterizing resources within multi-states, moving beyond the traditional focus on individual quantum states. Specifically, this work aims to provide a precise and generalizable method for quantifying imaginarity and coherence in these multi-state systems.

Method: This paper develops a unitary-invariant framework to characterize imaginarity and coherence in sets of qubit states. It proves that Bloch vectors must be coplanar for imaginarity-free states and colinear for incoherent states, enabling exact rank-based tests and closed-form bounds for robustness quantifiers using only two-state overlaps. The study also investigates the convexity of imaginarity-free multi-states and the role of third-order invariants, and demonstrates that all Bargmann invariants of single-qubit states are determined by two-state overlaps. Additionally, it provides purity and system-agnostic coherence witnesses through equality constraints on higher-order invariants.

Result: The research establishes that coplanarity and collinearity of Bloch vectors are necessary and sufficient conditions for imaginarity-free and incoherent sets of qubit states, respectively. It introduces rank-based tests for coherence and imaginarity and derives closed-form bounds for robustness quantifiers using only two-state overlaps. The non-convexity of the imaginarity-free multi-state set is shown, and the complete characterization of single-qubit multi-state imaginarity by third-order invariants is demonstrated, with a limitation for higher dimensions. A key technical result is that all Bargmann invariants for single-qubit states are determined by two-state overlaps. Furthermore, purity and system-agnostic coherence witnesses are derived, linking the results to practical applications like partial distinguishability, spin-chirality detection, and subchannel discrimination.

Conclusion: Imaginarity and coherence in multi-qubit states can be precisely characterized using unitary-invariant frameworks based on two-state overlaps. The set of imaginarity-free multi-states is not convex, and while third-order invariants characterize single-qubit multi-state imaginarity, they do not for higher-dimensional systems. All Bargmann invariants for single-qubit states are determined by two-state overlaps. The findings also extend to purity and coherence witnesses in a system-agnostic manner, with connections to partial distinguishability, spin-chirality detection, and subchannel discrimination.

Abstract: Traditionally, the characterization of quantum resources has focused on
individual quantum states. Recent literature, however, has increasingly
explored the characterization of resources in multi-states (ordered collections
of states indexed by a varying parameter). In this work, we provide a
unitary-invariant framework to pinpoint imaginarity and coherence in sets of
qubit states: we prove that Bloch vectors must be coplanar to be
imaginarity-free and colinear to be incoherent, yielding exact rank-based tests
of coherence and imaginarity, and closed-form bounds for existing robustness
quantifiers, all based on two-state overlaps only. We also show that the set of
imaginarity-free multi-states is not convex, and that third-order invariants
completely characterize multi-state imaginarity of single-qubits but not of
higher-dimensional systems. As our main technical result, we show that every
Bargmann invariant of single-qubit states is determined (up to conjugation) by
two-state overlaps. Beyond qubits, we give purity and system-agnostic coherence
witnesses from equality constraints on higher-order invariants and connect our
results to practical protocols: characterization of partial distinguishability,
spin-chirality detection, and subchannel discrimination.

</details>


### [621] [Anatomy of Non-Hermitian Dynamical Quantum Phase Transitions](https://arxiv.org/abs/2507.15384)
*Yongxu Fu,Gao Xianlong*

Main category: quant-ph

TL;DR: 非厄米系统的动力学量子相变（DQPTs）统一框架：发现了普遍的几何（向量正交性）和拓扑（涌现的拓扑特性）原理，对量子传感和开放系统物理学有意义。


<details>
  <summary>Details</summary>
Motivation: 为了在非厄米系统中建立一个统一的动力学量子相变（DQPTs）的理论框架，并揭示其内在的几何和拓扑性质。

Method: 本研究提出一个统一框架来研究非厄米系统中的动力学量子相变（DQPTs），该框架考虑了纯态和混合态的双正交和自范数非双正交形式，并给出了洛施密特幅度、洛施密特回声和速率函数的显式表达式。

Result: 研究发现了DQPTs的一个普遍几何特征：两个相关向量在二维实空间中的正交性。此外，研究表明非厄米到厄米哈密顿量的非双正交淬灭在手征对称性下表现出涌现的拓扑特性，揭示了DQPTs超越传统厄米体系的内在拓扑性质。

Conclusion: 本研究为非厄米系统中的动力学量子相变（DQPTs）提供了一个统一框架，该框架包括纯态和混合态的双正交和自范数非双正交形式。该框架揭示了DQPTs的一个普遍几何特征：二维实空间中两个相关向量的正交性。特别是，研究表明具有手征对称性的非双正交淬灭（从非厄米到厄米哈密顿量）表现出涌现的拓扑特性，揭示了DQPTs在传统厄米体系之外的内在拓扑性质。这项工作为开放系统中的量子临界性建立了基本的几何和拓扑原理，对量子传感和耗散环境中的多体物理学具有重要意义。

Abstract: We establish a unified framework for dynamical quantum phase transitions
(DQPTs) in non-Hermitian systems that encompasses both biorthogonal and
self-norm non-biorthogonal formulations for pure and mixed states. Our
framework provides explicit expressions for the Loschmidt amplitude, Loschmidt
echo, and rate function, revealing a universal geometric signature of DQPTs:
orthogonality of two related vectors in two-dimensional real space. Strikingly,
we demonstrate that non-biorthogonal quenches from non-Hermitian to Hermitian
Hamiltonians under chiral symmetry exhibit emergent topological
characteristics, unveiling the intrinsic topological nature of DQPTs beyond
conventional Hermitian regimes. This work establishes fundamental geometric and
topological principles governing quantum criticality in open systems, with
implications for quantum sensing and many-body physics in dissipative
environments.

</details>


### [622] [Simultaneous determination of multiple low-energy eigenstates of many-body systems on a superconducting quantum processor](https://arxiv.org/abs/2507.14880)
*Huili Zhang,Yibin Guo,Guanglei Xu,Yulong Feng,Jingning Zhang,Hai-feng Yu,S. P. Zhao*

Main category: quant-ph

TL;DR: 辅比特变分量子特征求解器可高效、准确地求解多体系统，并消耗更少的资源。


<details>
  <summary>Details</summary>
Motivation: 确定基态和低能激发态对于许多量子化学和凝聚态物理研究至关重要。

Method: 我们采用包含辅比特的变分量子特征求解器，在超导量子处理器上同时计算H2分子以及三自旋和五自旋横向场伊辛模型（TFIMs）的多个低能特征能量和特征态。

Result: 我们获得了H2的势能曲线，并通过平均绝对磁化值预示了TFIMs中的反铁磁到顺磁相变。

Conclusion: 该算法能够高效、准确地同时确定多体系统多个低能能量和特征态，且计算资源消耗更少。

Abstract: The determination of the ground and low-lying excited states is critical in
many studies of quantum chemistry and condensed-matter physics. Recent
theoretical work proposes a variational quantum eigensolver using ancillary
qubits to generate entanglement in the variational circuits, which avoids
complex ansatz circuits and successive measurements in the previous algorithms.
In this work, we employ the ancilla-entangled variational quantum eigensolver
to simultaneously compute multiple low-lying eigenenergies and eigenstates of
the H2 molecule and three- and five-spin transverse field Ising models (TFIMs)
on a superconducting quantum processor. We obtain the potential energy curves
of H2 and show an indication of antiferromagnetic to paramagnetic phase
transition in the TFIMs from the average absolute magnetization. Our
experiments demonstrate that the algorithm is capable of simultaneously
determining multiple eigenenergies and eigenstates of many-body systems with
high efficiency and accuracy and with less computational resources.

</details>


### [623] [Quantum sensing of Lanthandie binding tags with relaxometer of NV center in diamond](https://arxiv.org/abs/2507.14886)
*Zibo Gao,Zhengzhi Jiang,Qiyu Liang,Ruihua He,Van Cuong Mai,Yingwei Tang,Qirong Xiong,Wenting Zhao,Hongwei Duan,Hongliang Sun,Mo Li,Yansong Miao,Weibo Gao*

Main category: quant-ph

TL;DR: 本研究利用金刚石中的氮-空位（NV）中心作为传感器，通过检测镧系结合标签（LBTs）的磁性，实现了对SARS-COVID-2刺突蛋白受体结合域（RBD）等生物标志物的高灵敏度（低至皮摩尔级别）检测，克服了传统荧光法的背景干扰问题。


<details>
  <summary>Details</summary>
Motivation: 鉴于荧光探针易受背景荧光干扰，本研究提出利用磁性性质优化检测方法，以提高灵敏度和特异性。

Method: 通过氮-空位（NV）中心弛豫仪测量了不同量钆离子标记的LBTs的响应，并将其应用于SARS-COVID-2刺突蛋白受体结合域（RBD）与LBTs之间的特异性结合检测。

Result: 研究确定了LBTs的检测限为25 fmol，并通过NV弛豫仪实现了约1 pmol浓度的LBTs与RBD之间特异性结合的检测。

Conclusion: 本研究展示了利用氮-空位（NV）中心探测钆离子标记的镧系结合标签（LBTs）的磁性，以实现高灵敏度的生物标志物检测。

Abstract: Lanthanide binding tags (LBTs) stand out as a prominent group of fluorescent
probes that are extensively utilized in biological detection. However, research
on LBTs has predominantly emphasized their fluorescence properties, which
frequently compromised by background fluorescence noise. Investigating magnetic
properties could optimize detection methodologies that offer enhanced
sensitivity and specificity. In this study, we measured the response of a
relaxometer based on ensemble nitrogen-vacancy (NV) centers in diamond to
various amounts of LBTs with gadolinium ions, determining the detection limit
of LBTs to be 25 fmol. We then proposed and demonstrated a detection scheme
employing the NV relaxometer to detect specific binding between LBTs and
target. Specifically, we assessed the relaxometer's response to various
concentrations of the interaction between the modified LBTs and
Receptor-Binding Domain (RBD) of SARS-COVID-2 spike protein, with the detection
threshold reaching ~1 pmol. Our research provides a potential application
platform for biomarker detection under picomole concentration by using NV
centers to detect the magnetism of LBTs.

</details>


### [624] [Exceptional-Point Dynamics](https://arxiv.org/abs/2507.14892)
*Yan Xing,Xuedong Zhao,Hui Jing,Shi-Lei Su*

Main category: quant-ph

TL;DR: 研究了非厄米系统在厄米点（EPs）处的动力学行为，发现其动力学表现为多项式增长或酉演化，并提出了相关模型和应用。


<details>
  <summary>Details</summary>
Motivation: 由于有缺陷的非厄米哈密顿量的双正交特征空间不完备，EPs处的非厄米动力学仍不清楚，因此通常被避免。

Method: 本研究通过采用所有可用的广义特征态来系统地建立EPs处的伪完备性关系，涵盖了单EP和多EP的退化情况，以揭示EPs的动力学行为。

Result: 研究表明，EPs的动力学行为表现为特征态或其叠加的“多项式增长”，并可能趋于酉演化，这取决于EP的阶数和初始条件。

Conclusion: 本研究通过引入伪完备性关系，揭示了非厄米系统在厄米点（EPs）处的动力学行为，并提出了两种伪厄米（PH）系统模型进行验证，为工程设计和开发EPs相关技术奠定了基础。

Abstract: Exceptional points (EPs) play a vital role in non-Hermitian (NH) systems,
driving unique dynamical phenomena and promising innovative applications.
However, the NH dynamics at EPs remains obscure due to the incomplete
biorthogonal eigenspaces of defective NH Hamiltonians and thus is often
avoided. In this Letter, we systematically establish pseudo-completeness
relations at EPs by employing all available generalized eigenstates, where both
single and multiple arbitrary-order EPs embracing degenerate scenarios are
addressed, to unveil EP dynamics. We reveal that depending on EP order and
initial conditions, the EP dynamics is characterized by a \emph{polynomial
growth over time} of EP eigenstates or their superposition, which will dominate
long-term evolution despite real spectra protected by pseudo-Hermiticity (PH),
or can also become unitary. We further introduce two PH-compliant NH models to
demonstrate these EP dynamics and explore their applications. This work
completes the dynamical investigation of NH physics, offers valuable insights
into nonunitary EP evolution, and further lays the groundwork for engineering
NH devices and exploiting other EP-related technologies.

</details>


### [625] [Granovskii-Zhedanov Scar of XYZ Spin-chain: Modern Algebraic Perspectives and Realization in Higher Dimensional Lattices](https://arxiv.org/abs/2507.14895)
*Dhiman Bhowmick,Wen Wei Ho*

Main category: quant-ph

TL;DR: 本研究在量子多体拟态框架下解释了GZ拟态的起源，并为XYZ模型开发了新的描述方法。研究还发现，晶格结构对GZ拟态的存在至关重要，但通过保留某些键的SU(2)对称性，可以在特定条件下克服这些限制。


<details>
  <summary>Details</summary>
Motivation: 为了在现代量子多体拟态理论框架下理解并揭示三十年前发现的Granovskii-Zhedanov (GZ) 拟态的起源，特别是在XYZ自旋链中存在的零纠缠和长周期特性。研究旨在解决标准SGA框架在描述GZ拟态子空间时的局限性，并提出新的方法来处理XYZ模型。

Method: 通过现代量子多体拟态的理解框架，利用谱生成代数（SGA）和哈密顿量的群论形式来描述GZ拟态子空间。针对XYZ模型，提出了近似SGA和广义SGA两种新方法来构造和描述拟态子空间。利用为GZ拟态构造设计的图解规则，探索了在更高维度均匀自旋交换系统中构建与晶格无关的GZ拟态的可能性。

Result: 在XXZ极限下，GZ拟态子空间可以用标准的SGA框架和群论方法描述，但由于GZ拟态子空间中不存在准U(1)对称性，标准方法失效。提出的近似SGA和广义SGA方法能够构造和描述XYZ模型中的GZ拟态子空间。研究发现，与晶格无关的GZ拟态不能存在于协调数或具有奇数条边的菱形区域的晶格上，但可以在协调数为偶数且菱形区域具有偶数条边的晶格上存在。此外，即使在协调数为奇数或菱形区域具有奇数条边的系统中，只要某些键保留完整的SU(2)对称性，打破空间均匀性，也可以出现与晶格无关的GZ拟态。

Conclusion: 本研究揭示了Granovskii-Zhedanov (GZ) 拟态在现代量子多体拟态理论框架下的起源，并提出了用于描述和构造XYZ模型中GZ拟态子空间的近似和广义谱生成代数（SGA）方法。研究还探讨了在更高维度的中心对称自旋交换系统中构造与晶格无关的GZ拟态的可能性，并指出了晶格结构对拟态存在的限制，同时发现即使在空间非均匀的情况下，GZ拟态也可以存在。

Abstract: In a work by Granovskii and Zhedanov, a surprising scar state exhibiting zero
entanglement and long periodicity was discovered in the XYZ spin chains;
remarkably, nearly three decades before the concept of many-body scars became a
subject of active research. In this study, we uncover the origin of the
Granovskii-Zhedanov (GZ) scar within the framework of the modern understanding
of quantum many-body scars. We demonstrate that the scar subspace can be
effectively described using the standard spectrum-generating algebra (SGA)
framework and through a group-theoretical formulation of the Hamiltonian. This
description, however, is applicable only in the XXZ limit, where a quasi-$U(1)$
symmetry exists within the scar subspace. In contrast, the absence of such
quasi-$U(1)$ symmetry for the GZ scar subspace restricts the applicability of
these standard formulations. We propose two alternative techniques:
approximated SGA and generalized SGA, which construct and describe the scar
subspace in the XYZ case. Using these approaches, we can characterize the scar
subspaces. We further explore the possibility of constructing
lattice-independent GZ scars in higher-dimensional uniform spin-exchange
systems with centrosymmetry, using graphical rules developed for GZ scar
construction. Our results indicate that lattice-independent GZ scars cannot be
supported on uniform lattices with odd coordination numbers or plaquettes with
an odd number of edges, while uniform lattices featuring even coordination
numbers and even-edged plaquettes can host such lattice-independent scars in
specific scenarios. Remarkably, if certain bonds retain the full $SU(2)$
symmetry of the spin-exchange interaction, thereby breaking the spatial
uniformity of the lattice, lattice-independent GZ scars can still emerge in
systems with odd coordination numbers or plaquettes with an odd number of
edges.

</details>


### [626] [Superradiant Organic Light-Emitting Diodes](https://arxiv.org/abs/2507.14934)
*Kieran Hymas,Tadahiko Hirai,Daniel Tibben,Jack B. Muir,Christopher J. Dunn,Daniel E. Gómez,James Q. Quach*

Main category: quant-ph

TL;DR: 该研究通过扩展每个器件的工作电压与发射器浓度，触发了一系列法布里-珀罗微腔OLED的稳态超辐射光发射，实现了更明亮、更高效的OLED，并提供更纯净的色彩。


<details>
  <summary>Details</summary>
Motivation: 在OLED中，更大的发射器浓度并不总是能带来更亮或更高效的OLED，因为浓度猝灭会严重降低辐射电子-空穴复合速率，从而影响电荷-光子转换效率。

Method: 通过扩展每个器件的工作电压与发射器浓度，触发了一系列法布里-珀罗微腔OLED的稳态超辐射光发射。

Result: 器件表现出比没有腔的对照组更优越的发光度，并且发射光谱显着变窄，在低施加电压下提供更纯净的色彩。

Conclusion: 利用微腔OLED中的集体效应为更明亮、更高效的设备提供新方法，为下一代显示器和照明铺平道路，而不会在性能、运行效率或设备寿命方面妥协。

Abstract: Organic light-emitting diodes (OLEDs) are central to modern display
technologies and are promising candidates for low-cost energy-efficient
lighting. Their performance is determined by numerous, intricate fabrication
parameters, but not least by the number of emissive molecules N, which provide
sites for electron-hole recombination and photon generation in the diode host
matrix. Counterintuitively, larger concentrations of emitters do not always
lead to brighter or more efficient OLEDs due to concentration quenching of
luminescence meaning that rates of radiative electron-hole recombination can
become severely reduced, negatively impacting charge-to-photon conversion
efficiency. In this work we trigger steady-state superradiant light emission
from a series of Fabry-P\'erot microcavity OLEDs by scaling the operating
voltage of each device with emitter concentration. We demonstrate a collective
enhancement in the luminance of a microcavity OLED that scales
super-extensively when compared to no-cavity controls fabricated in the same
run. Triggering quantum correlations between emitters via the confined cavity
field allows devices with fewer emitters to match or even exceed the brightness
of control OLEDs even when driven by lower voltages. Moreover, our devices show
significant narrowing of their emission spectra, offering purer colours at low
applied voltages. Leveraging collective effects in microcavity OLEDs provides a
new approach to enable brighter, more efficient devices paving the way for
next-generation displays and lighting that do not compromise performance for
operational efficiency or device lifetime.

</details>


### [627] [The Way from Rota to Quantum Mechanics](https://arxiv.org/abs/2507.14953)
*David Ellerman*

Main category: quant-ph

TL;DR: 本文基于Rota关于划分的逻辑的工作，将量子力学视为一种划分的逻辑，利用划分的格来解释量子现象，并处理量子统计。


<details>
  <summary>Details</summary>
Motivation: 本文的动机在于完成Gian-Carlo Rota关于建立等价关系或划分的逻辑的未完成工作。作者受到Rota关于子集和划分之间的范畴论对偶性的启发，认识到应该存在一种与通常的布尔子集逻辑相对应的划分逻辑。此外，作者还提出，信息论的起点应类似于概率论中从子集大小出发，应从划分的大小概念出发。这导致了对量子力学的探索，作者认为量子力学可以被视为一种关于确定性和不确定性的划分逻辑。

Method: 本文追溯了一段智力历程，从Rota关于等价关系或划分的逻辑的未完成工作开始，阐述了划分的逻辑及其量化版本（逻辑熵），并揭示了在精确科学中贯穿始终的子集和划分之间的对偶性。随后，文章深入探讨了量子力学，将其视为划分的逻辑，并利用划分的格来简化对量子现象的处理，特别是展示了如何解决双缝实验的谜团。最后，文章使用Rota风格的枚举组合学来处理量子统计。

Result: 该论文成功地发展了划分的逻辑及其量化版本，即逻辑熵。它揭示了子集和划分之间深刻的范畴论对偶性，并将此对偶性应用于经典物理学和量子物理学。通过将量子力学视为划分的逻辑，并利用划分的格，论文对量子现象（特别是双缝实验）提供了一种简化的视角和解释。此外，文章还运用Rota风格的枚举组合学成功地处理了量子统计。

Conclusion: 该论文发展了一种将量子力学视为依赖于可分性的概念，并使用格的划分来简化量子现象的论述。此外，该论文还运用了Rota风格的枚举组合学来处理量子统计。

Abstract: This paper traces an intellectual journey or \textit{Way} (in the sense of a
Tao) that starts with some unfinished work of Gian-Carlo Rota on making a logic
of equivalence relations or partitions. Rota understood the category-theoretic
duality between subsets and partitions which implied there should be a logic of
partitions dual to the usual Boolean logic of subsets.And just as probability
starts quantitatively with the size of a subset, so he saw that information
should start with some notion of size of a partition. After developing the
logic of partitions and its quantitative version as logical entropy, it became
clear that there is a fundamental duality, fully developed only in category
theory, that runs through the exact sciences. Classical physics lies on the
subset side and quantum physics on the partition side of the duality. The rest
of the paper develops the treatment of quantum mechanics seen through the lens
of partitions as the logic of definiteness and indefiniteness. The lattices of
partitions allows the treatment of quantum phenomena in highly simplified but
essential terms. Since Feynman saw the``only mystery'' of quantum mechanics in
the two-slit experiment, this new approach is developed to show how to resolve
that mystery. Finally, quantum statistics is treated using Rota-style
enumerative combinatorics.

</details>


### [628] [Polarisation and Temperature Dependence of Er$^{3+}$:CaWO$_4$ -- Towards a Solid-State Rare-Earth Ion-Doped Quantum Memory](https://arxiv.org/abs/2507.15051)
*Mikhael T. Sayat,Trevor R. Lee,Suchit Negi,Naoya Iwahara,In Cheol Seo,Yung Chuen Tan,Ping Koy Lam,Young-Wook Cho,Jian-Rui Soh*

Main category: quant-ph

TL;DR: Er$^{3+}$:CaWO$_4$晶体在1532.6 nm，c轴入射，低温下光学特性优异，适合量子存储。


<details>
  <summary>Details</summary>
Motivation: 为了开发量子存储器，研究具有长光学相干时间和兼容1550 nm通信波段的Er$^{3+}$:CaWO$_4$晶体平台。

Method: 研究了偏振和温度对Er$^{3+}$:CaWO$_4$晶体中Z$_{1}	o Y_{1}$和Z$_{1}	o Y_{2}$光学跃迁的吸收强度、中心波长和线宽的影响。

Result: Z$_{1}	o Y_{1}$跃迁在1532.6 nm，c轴入射，低温（约3 K）时表现出稳定的中心波长、更窄的线宽、偏振无关性、更大的吸收截面，并处于C波段，非常适合量子存储。

Conclusion: Er$^{3+}$:CaWO$_4$晶体在低温和特定条件下（1532.6 nm，c轴入射）表现出优异的光学特性，使其成为量子存储应用的理想选择。

Abstract: In the endeavour of developing quantum memories, Er$^{3+}$:CaWO$_4$ has
emerged as a promising rare-earth ion-doped (REID) crystal platform due to its
long optical coherence times and compatibility with the 1550 nm
telecommunications band. This work investigates the effects of polarisation and
temperature on the absorption strength, central wavelength, and linewidth of
the $Z_1\to Y_1$ and $Z_1\to Y_2$ optical transitions, with light incident
along the crystal $a$ and $c$ axes. It is found that the $Z_1\to Y_1$
transition at 1532.6 nm with the incident laser along the $c$-axis at cryogenic
temperatures ($\sim$3 K) is particularly favourable. The transition exhibits a
stable central wavelength, narrower linewidth, polarisation independence,
larger absorption cross-section, and lies within the C-band -- attributes that
make it highly suitable for quantum memory applications.

</details>


### [629] [Transversal non-Clifford gates on qLDPC codes breaking the $\sqrt{N}$ distance barrier and quantum-inspired geometry with $\mathbb{Z}_2$ systolic freedom](https://arxiv.org/abs/2507.15056)
*Guanyu Zhu*

Main category: quant-ph

TL;DR: 本文通过同调积和三重杯积，将量子LDPC码的距离障碍从$	ext{O}(	ext{N}^{1/2})$提升至$	ext{O}(	ext{N}^{2/3})$，并实现了无需蒸馏的逻辑CCZ魔法态制备。


<details>
  <summary>Details</summary>
Motivation: 本文旨在突破量子LDPC码的距离障碍，同时保持横穿非Clifford门的能力。

Method: 通过取三个良好量子LDPC码的同调积，结合Freedman-Hastings码到流形映射和三重杯积，实现了可横穿的CCZ门。

Result: 所提出的量子码实现了$	ext{O}(	ext{N}^{2/3})$的距离（线性的X距离为$	ext{Θ}(	ext{N})$），维度为$	ext{Θ}(	ext{N}^{2/3})$，可在单次实现中制备$	ext{Θ}(	ext{N}^{1/3})$个独立的逻辑CCZ魔法态，且无需蒸馏。

Conclusion: 本文提出的量子LDPC码将距离障碍从$	ext{O}(	ext{N}^{1/2})$提升至$	ext{O}(	ext{N}^{2/3})$，并实现了$	ext{O}(	ext{N})$的线性X距离，能够在单次实现中制备$	ext{O}(	ext{N}^{1/3})$个独立的逻辑CCZ魔法态，无需蒸馏。此外，该工作还启发了一类新的$	ext{3q}$维流形$	ext{M}$的发现。

Abstract: Historically, a $\sqrt{N}log^{1/2}(N)$ distance barrier for quantum
low-density parity-check (LDPC) codes with $N$ qubits persisted for nearly two
decades, until the recent discovery of the fibre-bundle code. An open question
is whether such a distance barrier can be broken while preserving the ability
to perform transversal non-Clifford gates. In this direction, another
long-standing distance barrier of $N^{1/3}$ for LDPC stabilizer codes --
present since the discovery of the 3D color code -- was only recently overcome
by a construction achieving an $\Omega(\sqrt{N})$ distance (arXiv:2501.19375).
The present work further breaks the $\sqrt{N}$ distance barrier by taking a
homological product of three good qLDPC codes, combined with the
Freedman-Hastings code-to-manifold mapping and the triple cup product to
implement transversal CCZ gates. The resulting code achieves an
$\Omega(N^{2/3})$ distance (a linear $X$-distance of $\Theta(N)$) and a
dimension of $\Theta(N^{2/3})$, which enables fault-tolerant preparation of
$\Theta(N^{1/3})$ independent logical CCZ magic states in a single shot,
without distillation (`magic state fountain'). This new quantum code also
inspires the discovery of a family of exotic $3q$-dimensional manifolds
$\mathcal{M}$, which exhibit both a power-law $\mathbb{Z}_2$-($q$,
$2q$)-systolic freedom and $\Theta(vol(\mathcal{M}))$ triple intersection
points of $2q$-dimensional submanifolds.

</details>


### [630] [Grover's algorithm is an approximation of imaginary-time evolution](https://arxiv.org/abs/2507.15065)
*Yudai Suzuki,Marek Gluza,Jeongrak Son,Bi Hong Tiang,Nelly H. Y. Ng,Zoë Holmes*

Main category: quant-ph

TL;DR: 本研究从热力学和几何角度揭示了 Grover 算法是虚时演化（ITE）的近似，ITE 是酉群上的黎曼梯度流。研究证明了 ITE 路径的最优性，量化了其复杂度，并提出了一种新的量子信号处理方法，为量子算法设计提供了新思路。


<details>
  <summary>Details</summary>
Motivation: 为了从热力学和几何的角度揭示 Grover 算法的强大能力，并深化对其的理解，同时探索热力学和几何在量子算法设计中的潜在作用。

Method: 将 Grover 算法视为一种在特殊酉群上的黎曼梯度流——虚时演化（ITE）的乘积公式近似，并从热力学和几何角度进行分析。具体包括：证明 ITE 动力学追踪了复数射影空间中初始状态和解状态之间的最短路径；证明 ITE 的黎曼几何测地线长度决定了 Grover 算法的查询复杂度；利用 ITE 的测地线结构，构建了一种无需后选择的 ITE 量子信号处理公式，并推导出一组新的定点搜索角度。

Result: Grover 算法是虚时演化（ITE）的乘积公式近似，ITE 是酉群上的黎曼梯度流。ITE 动力学追踪了复数射影空间中初始状态和解状态之间的最短路径。ITE 的黎曼几何测地线长度决定了 Grover 算法的查询复杂度，该复杂度与无结构搜索的最优缩放一致。研究人员构建了一种无需后选择的 ITE 量子信号处理公式，并推导出一组新的定点搜索角度。

Conclusion: 该研究揭示了 Grover 算法在热力学和几何角度下的强大能力，将其视为一种在酉群上的黎曼梯度流——虚时演化（ITE）的乘积公式近似。这一视角揭示了三个关键见解：ITE 动力学追踪了复数射影空间中初始状态和解状态之间的最短路径；ITE 的黎曼几何测地线长度决定了 Grover 算法的查询复杂度，并且该复杂度与无结构搜索的最优缩放一致；利用 ITE 的测地线结构，研究人员构建了一种无需后选择的 ITE 量子信号处理公式，并推导出一组新的定点搜索角度。这些结果共同深化了对 Grover 算法的理解，并暗示了热力学和几何在量子算法设计中的潜在作用。

Abstract: We reveal the power of Grover's algorithm from thermodynamic and geometric
perspectives by showing that it is a product formula approximation of
imaginary-time evolution (ITE), a Riemannian gradient flow on the special
unitary group. This viewpoint uncovers three key insights. First, we show that
the ITE dynamics trace the shortest path between the initial and the solution
states in complex projective space. Second, we prove that the geodesic length
of ITE determines the query complexity of Grover's algorithm. This complexity
notably aligns with the known optimal scaling for unstructured search. Lastly,
utilizing the geodesic structure of ITE, we construct a quantum signal
processing formulation for ITE without post-selection, and derive a new set of
angles for the fixed-point search. These results collectively establish a
deeper understanding of Grover's algorithm and suggest a potential role for
thermodynamics and geometry in quantum algorithm design.

</details>


### [631] [Taming Entanglement](https://arxiv.org/abs/2507.15128)
*Huw Price,Ken Wharton*

Main category: quant-ph

TL;DR: EPR和贝尔关联是选择效应，源于实验制备的初始状态，而非真正的量子纠缠。


<details>
  <summary>Details</summary>
Motivation: 解释EPR和贝尔关联的来源，并将其与因果模型中的选择偏差进行比较。

Method: 提出EPR和贝尔关联是选择效应，通过分析初始状态制备过程中的子系综选择来解释。

Result: EPR和贝尔关联是初始状态制备这一选择过程产生的，而非内秉的量子现象，并对因果模型领域有新的启示。

Conclusion: EPR和贝尔关联是选择效应，由初始状态制备引入，支持了EPR论证和贝尔非局域性的直观反事实。

Abstract: In statistics and causal modeling it is common for a selection process to
induce correlations in a subset of an uncorrelated ensemble. We propose that
EPR and Bell correlations are selection artefacts of this kind. The selection
process is preparation of the initial state of the relevant experiments. Choice
of initial state amounts to preselection of a subensemble of a larger,
uncorrelated, virtual ensemble of possble histories. Because it is preselection
rather than postselection, the resulting correlations support the intuitive
counterfactuals of the EPR argument and Bell nonlocality. In this respect, and
in its temporal orientation, the case differs from familiar forms of selection
bias. Given the ubiquity of quantum entanglement, the result may thus be of
independent interest to students of causal modeling. The paper concludes with a
discussion of its novel implications in that field.

</details>


### [632] [Ground and excited-state energies with analytic errors and short time evolution on a quantum computer](https://arxiv.org/abs/2507.15148)
*Timothy Stroschein,Davide Castaldo,Markus Reiher*

Main category: quant-ph

TL;DR: 提出了一种新的混合经典-量子算法QPD，用于求解薛定谔方程，能够以化学精度同时估计基态和激发态能量，并且在状态制备不完美的情况下仍然鲁棒。


<details>
  <summary>Details</summary>
Motivation: 准确求解薛定谔方程是计算物理、化学和材料科学中的核心挑战。

Method: 提出了一种基于系统自相关函数的替代特征值问题，避免了对波函数的直接引用。开发了一个严格的近似框架，可以从有限数量的信号样本中精确估计频率。

Result: 分析基于新的长球形波函数结果，并给出误差界限，揭示了由观测时间和信号谱密度决定的尖锐精度转变。

Conclusion: 该研究提出的量子长球形对角化（QPD）是一种混合经典-量子算法，能够在海森堡极限内以化学精度同时估计基态和激发态能量。不同输入态的分析表明，即使在状态制备不完美的情况下，该方法也能保持高精度。

Abstract: Accurately solving the Schr\"odinger equation remains a central challenge in
computational physics, chemistry, and materials science. Here, we propose an
alternative eigenvalue problem based on a system's autocorrelation function,
avoiding direct reference to a wave function. In particular, we develop a
rigorous approximation framework that enables precise frequency estimation from
a finite number of signal samples. Our analysis builds on new results involving
prolate spheroidal wave functions and yields error bounds that reveal a sharp
accuracy transition governed by the observation time and spectral density of
the signal. These results are very general and thus carry far. As one important
example application we consider the quantum computation for molecular systems.
By combining our spectral method with a quantum subroutine for signal
generation, we define quantum prolate diagonalization (QPD) - a hybrid
classical-quantum algorithm. QPD simultaneously estimates ground and excited
state energies within chemical accuracy at the Heisenberg limit. An analysis of
different input states demonstrates the robustness of the method, showing that
high precision can be retained even under imperfect state preparation.

</details>


### [633] [Planted Solutions in Quantum Chemistry: Generating Non-Trivial Hamiltonians with Known Ground States](https://arxiv.org/abs/2507.15166)
*Linjun Wang,Joshua T. Cantin,Smik Patel,Ignacio Loaiza,Rick Huang,Artur F. Izmaylov*

Main category: quant-ph

TL;DR: 生成具有已知基态的量子化学测试问题，使用“planted-solution”技术，并引入“killer”算子、平衡算子和随机轨道旋转来控制复杂度，适用于均相催化剂，并通过DMRG验证。


<details>
  <summary>Details</summary>
Motivation: 为电子结构方法生成具有已知基态解的大型、非平凡量子化学测试问题，这是对电子结构方法进行基准测试的核心挑战。

Method: 提出了一种受组合优化中“planted-solution”技术启发的框架，该框架包含四类具有嵌入式、可检索基态的哈密顿量。为了隐藏这种结构并控制感知复杂度，还引入了诸如“killer”算子、平衡算子和随机轨道旋转等技术。

Result: 展示了使用基于工业相关均相催化剂的示例，并通过密度矩阵重整化群（DMRG）收敛行为验证了可调难度。

Conclusion: 该框架能够生成可扩展的、具有地面真实基准测试能力的量子化学问题，并为探索电子结构方法的局限性和研究哈密顿量结构如何影响基态求解难度提供了一个可控的环境。

Abstract: Generating large, non-trivial quantum chemistry test problems with known
ground-state solutions remains a core challenge for benchmarking electronic
structure methods. Inspired by planted-solution techniques from combinatorial
optimization, we introduce four classes of Hamiltonians with embedded,
retrievable ground states. These Hamiltonians mimic realistic electronic
structure problems, support adjustable complexity, and are derived from
reference systems. Crucially, their ground-state energies can be computed
exactly, provided the construction parameters are known. To obscure this
structure and control perceived complexity, we introduce techniques such as
killer operators, balance operators, and random orbital rotations. We showcase
this framework using examples based on homogeneous catalysts of industrial
relevance and validate tunable difficulty through density matrix
renormalization group (DMRG) convergence behavior. Beyond enabling scalable,
ground-truth benchmark generation, our approach offers a controlled setting to
explore the limitations of electronic structure methods and investigate how
Hamiltonian structure influences ground state solution difficulty.

</details>


### [634] [Global-scale quantum networking using hybrid-channel quantum repeaters with relays based on a chain of balloons](https://arxiv.org/abs/2507.15178)
*Pei-Xi Liu,Yu-Ping Lin,Zong-Quan Zhou,Chuan-Feng Li,Guang-Can Guo*

Main category: quant-ph

TL;DR: 提出了一种利用气球作为中继器的量子网络方案，实现了长距离、高效率的纠缠分发。


<details>
  <summary>Details</summary>
Motivation: 解决全球范围内分发纠缠所面临的通信信道中不可避免的损耗问题。

Method: 提出了一种新颖的基于气球的空中中继骨干通道，并通过优化光束腰部位置和采用一系列自适应光学系统几乎消除了气球基通道中的大气扰动。提出了一种基于混合通道量子中继器的全球规模量子网络方案，该中继器结合了地面量子中继器和气球基空中中继器。

Result: 与具有相同设备参数的基站中继相比，基于气球的空中中继在 10,000 公里的距离上将信道效率提高了 12 分贝，达到了 -21 分贝。在 10,000 公里的客户端之间实现了赫兹范围以下的纠缠分发率。

Conclusion: 该方法为未来几年内实现全球量子网络提供了一条可行的途径。

Abstract: Global-scale entanglement distribution has been a formidable challenge due to
the unavoidable losses in communication channels. Here, we propose a novel
backbone channel for quantum network based on balloon-based aerial relays. We
demonstrate for the first time that the atmospheric disturbances in
balloon-based channels can be almost eliminated through optimizing beam waist
positions and employing a series of adaptive optics systems, which boosts the
channel efficiency to -21 dB over a 10,000 km distance, outperforming
satellite-based relays by 12 dB with same device parameters. We then propose a
global-scale quantum networking scheme based on hybrid-channel quantum
repeaters that combine ground-based quantum repeaters and balloon-based aerial
relays. Servers are interconnected globally via a chain of balloons, while
clients link to local servers through fiber connections, facilitating rapid
client switching and network scalability. Our simulations, employing
state-of-the-art Eu$^{3+}$:Y$_2$SiO$_5$ quantum memories and mature
entanglement sources based on spontaneous parametric down-conversion,
demonstrate an entanglement distribution rate in the sub-Hertz range between
clients separated by 10,000 km. This approach offers a practical path toward
global quantum networking in the near future.

</details>


### [635] [1H Polarization above 60% at room temperature by triplet dynamic nuclear polarization](https://arxiv.org/abs/2507.15217)
*Kenichiro Tateishi,Shuji Otsuka,Akihiro Yamaji,Shunsuke Kurosawa,Tomohiro Uesaka*

Main category: quant-ph

TL;DR: 在室温和低磁场下，通过使用二苯并[a, h]蒽作为唆麻[d14]的宿主分子，实现了61%的1H极化，并探讨了其在核序和抗辐射极化靶方面的应用。


<details>
  <summary>Details</summary>
Motivation: 在室温和低磁场下实现高极化对于核磁共振成像和粒子物理实验等领域具有重要意义。本研究旨在开发一种高效的动态核极化（DNP）方法，以克服传统DNP方法的限制。

Method: 研究引入了二苯并[a, h]蒽作为新一代的唆麻[d14]的宿主分子，这种分子的刚性结构使得其在室温下的自旋晶格弛豫时间（T1）超过2小时。通过桥式法生长了掺杂了0.05 mol%唆麻[d14]的二苯并[a, h]蒽单晶，并将其切割成约1毫克的样品用于Triplet-DNP实验。顺磁弛豫成为主要的弛豫机制，而非自旋晶格弛豫。

Result: 在室温和0.64T磁场下，通过Triplet-DNP实现了61%的1H极化。研究还讨论了室温超极化在核序和抗辐射极化靶两方面的应用前景。

Conclusion: 本文介绍了使用光激发的三线态电子（Triplet-DNP）在室温和0.64T磁场下实现了61%的1H极化。

Abstract: 1H polarization of 61% was achieved by Dynamic Nuclear Polarization using
photoexcited triplet electrons (Triplet-DNP) at room temperature and in 0.64 T.
We introduced dibenz[a, h]anthracene as a new host molecule of the polarizing
agent, pentacene-d14. Its rigid structure provides a long spin-lattice
relaxation time (T1) of more than 2 hours at room temperature. The single
crystal of dibenz[a, h]anthracene doped with 0.05 mol% pentacene-d14 was grown
by the Bridgman method, and cut into a small piece of ~1 mg for Triplet-DNP
experiment. The 1H polarization buildup and relaxation measurements indicated
that paramagnetic relaxation became the major source of the relaxation than
spin-lattice relaxation. Finally, two promising applications of
room-temperature hyperpolarization, i .e. nuclear ordering and
radiation-tolerant polarized target, are discussed.

</details>


### [636] [Strongly Coupled Continuous Time Crystal](https://arxiv.org/abs/2507.15295)
*Ximo Wang,Qiwei Han,Zhenqi Bai,Hongyan Fan,Yichi Zhang*

Main category: quant-ph

TL;DR: 强关联多体系统中，协同多体隧穿使时间晶体自发振荡，并发现了普适标度律。


<details>
  <summary>Details</summary>
Motivation: 基于时间晶体是否自发破坏时间平移对称性，将时间晶体分为离散时间和连续时间晶体。连续时间晶体不需要外部驱动。

Method: 通过引入AdS/CFT对偶到时间晶体，我们推导了它们的热力学极限。

Result: 发现协同多体隧穿使时间晶体自发振荡，并发现了一个控制时间晶体相变在临界温度下普适的标度律。

Conclusion: 时间晶体在强关联多体系统中，如3D光学晶格中，协同多体隧穿使得时间晶体自发振荡。在由多体协同隧穿驱动的强关联量子系统中，我们发现了一个控制时间晶体相变在临界温度下普适的标度律。

Abstract: Time crystals are classified into discrete time crystals and continuous time
crystals based on whether they spontaneously break time-translation symmetry.
Continuous-time crystals do not require external driving. By introducing
AdS/CFT duality to time crystals, we derive their thermodynamic limit and find
that in strongly correlated many-body systems such as a 3D optical lattice,
cooperative many-body tunneling enables time crystals to oscillate
spontaneously. In strongly correlated quantum systems driven by many-body
cooperative tunneling, we discover a universal scaling law governing the
time-crystalline phase transition at a critical temperature.

</details>


### [637] [Resource-Efficient Cross-Platform Verification with Modular Superconducting Devices](https://arxiv.org/abs/2507.15302)
*Kieran Dalton,Johannes Knörzer,Finn Hoehne,Yongxin Song,Alexander Flasby,Dante Colao Zanuz,Mohsen Bahrami Panah,Ilya Besedin,Jean-Claude Besse,Andreas Wallraff*

Main category: quant-ph

TL;DR: 本研究在六比特超导量子设备上评估了跨平台验证协议，发现引入模块间两比特门可将资源需求从指数级降低到亚指数级，并显著提高验证效率。


<details>
  <summary>Details</summary>
Motivation: 为了验证大型模块化量子计算机的能力，需要评估模块内和模块间的性能。跨平台验证协议对于量化不同模块制备相同量子状态的准确性至关重要，这是模块化可扩展性和系统一致性的关键要求。

Method: 本研究评估了跨平台验证协议，并在包含两个三比特模块的六比特超导量子设备上进行了演示。研究了仅依赖经典通信的协议的资源需求，并与引入模块间两比特门的方法进行了比较。

Result: 研究表明，仅依赖经典通信的跨平台验证协议的资源需求随量子比特数量呈指数级增长。通过引入模块间两比特门，可以将资源需求降低到亚指数级增长，并将三比特状态验证所需的重复次数减少了四倍，并预测在更大、更高保真度的设备上将有更大的改进。

Conclusion: 可扩展的跨平台验证协议对于实现模块化量子计算的可扩展性和系统一致性至关重要。引入模块间两比特门可以显著减少验证所需的资源。

Abstract: Large-scale quantum computers are expected to benefit from modular
architectures. Validating the capabilities of modular devices requires
benchmarking strategies that assess performance within and between modules. In
this work, we evaluate cross-platform verification protocols, which are
critical for quantifying how accurately different modules prepare the same
quantum state -- a key requirement for modular scalability and system-wide
consistency. We demonstrate these algorithms using a six-qubit flip-chip
superconducting quantum device consisting of two three-qubit modules on a
single carrier chip, with connectivity for intra- and inter-module
entanglement. We examine how the resource requirements of protocols relying
solely on classical communication between modules scale exponentially with
qubit number, and demonstrate that introducing an inter-module two-qubit gate
enables sub-exponential scaling in cross-platform verification. This approach
reduces the number of repetitions required by a factor of four for three-qubit
states, with greater reductions projected for larger and higher-fidelity
devices.

</details>


### [638] [Quantum sensor network metrology with bright solitons](https://arxiv.org/abs/2507.15348)
*Dmitriy Tsarev,Stepan Osipov,Ray-Kuang Lee,Sergey Kulik,Alexander Alodjants*

Main category: quant-ph

TL;DR: 该研究提出了一种新的三模孤子约瑟夫森结（TMSJJ）系统，用于在存在弱损耗的情况下优化多参数量子计量，实现了接近通用海森堡极限（GHL）的精度。


<details>
  <summary>Details</summary>
Motivation: 本研究旨在解决多参数量子计量问题，并提出一种新的系统（TMSJJ）来优化计量协议的精度，特别是在存在弱损耗的情况下。

Method: 研究考虑了存在弱损耗的多参数量子计量问题，引入了表征未知参数测量和估计精度基本限制的通用海森堡极限（GHL）$\\

Result: 证明了TMSJJ系统在弱损耗下能够实现接近GHL的饱和缩放，从而优化了计量精度。

Conclusion: 该研究提出了三模孤子约瑟夫森结（TMSJJ）系统，可生成优化的多参数量子计量协议。该系统在弱损耗下可实现接近通用海森堡极限（GHL）的饱和缩放，为原子电子线路中的量子网络传感提供了新方向。

Abstract: We consider multiparameter quantum metrology problem with bright soliton
networks in the presence of weak losses. We introduce General Heisenberg Limit
(GHL) $\sigma_{\boldsymbol{\chi}}=1/N^k$ that characterizes fundamental
limitations for unknown parameter measurement and estimation accuracy
$\sigma_{\boldsymbol{\chi}}$ within linear ($k=1$) and nonlinear ($k=3$)
quantum metrology approaches to solitons. We examine multipartite $N00N$ states
specially prepared for the improvement of multiparameter estimation protocols.
As a particular example of producing such states, we propose the three-mode
soliton Josephson junction (TMSJJ) system as a three mode extension for the
soliton Josephson junction (SJJ) bosonic model, which we previously proposed.
The energy spectrum of the TMSJJ exhibits sharp phase transition peculiarities
for the TMSJJ ground state. The transition occurs from a Gaussian-like
(coherent) state to the superposition of entangled Fock states, which rapidly
approach the three-mode $N00N$ state. We show that in the presence of weak
losses, the TMSJJ enables saturate scaling relevant to the optimal state limit
close to the GHL. Our findings open new prospects for quantum network sensorics
with atomtronic circuits.

</details>


### [639] [Slow convergence of Trotter decomposition for rotations](https://arxiv.org/abs/2507.15421)
*Paolo Facchi,Francesco Perrini,Vito Viesti*

Main category: quant-ph

TL;DR: 研究了Trotter近似在轨道角动量算子上的应用，发现Trotter误差的收敛率与状态是否在所有算子域内有关。


<details>
  <summary>Details</summary>
Motivation: 研究Trotter近似在轨道角动量算子上的应用及其误差的缩放行为。

Method: 研究了Trotter近似在L_x和L_y算子上的应用，并着重分析了状态依赖的Trotter误差的缩放行为。

Result: 对于在轨道角动量算子域内的状态，Trotter误差缩放为n^{-1}；但对于不属于所有三个角动量算子域的状态，收敛率可能任意慢。

Conclusion: Trotter误差的收敛率对于不属于所有三个角动量算子域的状态可以任意慢。

Abstract: We study the Trotter approximation for a pair of orbital angular momentum
operators, $L_x$ and $L_y$. In particular, we investigate the scaling behavior
of the state-dependent Trotter error. We show that for states in the domains of
the orbital angular momentum operators the Trotter error scales as $n^{-1}$,
where $n$ is the time discretization. Instead, the convergence rate can be
arbitrarily slow for states that do not belong to the domains of all three
angular momentum operators simultaneously.

</details>


### [640] [Stochastic Quantum Hamiltonian Descent](https://arxiv.org/abs/2507.15424)
*Sirui Peng,Shengminjie Chen,Xiaoming Sun,Hongyi Zhou*

Main category: quant-ph

TL;DR: SQHD是一种结合了随机梯度法效率和量子动力学全局探索能力的量子优化算法，在多个基准测试中优于经典方法，尤其在处理复杂和高维数据时。


<details>
  <summary>Details</summary>
Motivation: 现有的随机梯度下降（SGD）及其变体虽然能够高效优化大型模型，但其局部搜索特性限制了在复杂数据集上的探索能力。为了克服这一限制，本研究旨在结合随机梯度法的效率和量子动力学的全局探索能力。

Method: 提出了一种名为随机量子哈密顿量下降（SQHD）的量子优化算法，它将随机梯度法的计算效率与量子动力学的全局探索能力相结合。提出了Lindbladian动力学作为连续时间随机梯度下降的量子类似物，并提出了一种基于门的离散时间算法来近似这些动力学，以便在近期量子设备上实现。

Result: SQHD已被证明在线性代数、量子化学和机器学习的基准测试中优于经典方法。尤其是在处理高维和稀疏数据时，其性能提升尤为显著。此外，实验还表明，与经典算法相比，SQHD在收敛速度和解的质量方面均有优势，特别是在非凸优化问题中。

Conclusion: SQHD有潜力用于量子增强机器学习，并在非凸优化中表现出优势。

Abstract: Stochastic Gradient Descent (SGD) and its variants underpin modern machine
learning by enabling efficient optimization of large-scale models. However,
their local search nature limits exploration in complex landscapes. In this
paper, we introduce Stochastic Quantum Hamiltonian Descent (SQHD), a quantum
optimization algorithm that integrates the computational efficiency of
stochastic gradient methods with the global exploration power of quantum
dynamics. We propose a Lindbladian dynamics as the quantum analogue of
continuous-time SGD. We further propose a discrete-time gate-based algorithm
that approximates these dynamics while avoiding direct Lindbladian simulation,
enabling practical implementation on near-term quantum devices. We rigorously
prove the convergence of SQHD for convex and smooth objectives. Numerical
experiments demonstrate that SQHD also exhibits advantages in non-convex
optimization. All these results highlight its potential for quantum-enhanced
machine learning.

</details>


### [641] [State-Dependent Quantum Copying and the limits of the No-Cloning Theorem](https://arxiv.org/abs/2507.15432)
*Guruprasad Kadam*

Main category: quant-ph

TL;DR: Quantum states can be copied conditionally using stimulated emission, a process that respects the no-cloning theorem.


<details>
  <summary>Details</summary>
Motivation: To model state-dependent quantum copying using the physical process of stimulated emission and clarify the distinction between universal cloning and conditional copying.

Method: Examining the physical process of stimulated emission as a model for state-dependent quantum copying, exploring how quantum states like photon polarization can be cloned through light-matter interactions.

Result: Demonstrated that stimulated emission can achieve state-dependent quantum copying, where an ancillary system (e.g., an excited atom) encodes prior information about the quantum state, a process that resembles quantum cloning but obeys the no-cloning theorem.

Conclusion: Stimulated emission provides a concrete physical realization of state-dependent quantum copying, adhering to the no-cloning theorem due to its state-dependent and non-universal nature.

Abstract: In this work, we examine the physical process of stimulated emission as a
model for state-dependent quantum copying. We explore how a quantum state, for
instance, a photon polarization, can be cloned through light-matter
interactions when the ancillary system, such as an excited atom, effectively
encodes prior information about the quantum state. This process, while
resembling quantum cloning, adheres to the no-cloning theorem due to its
state-dependent and non-universal nature. We clarify the distinction between
universal cloning and conditional copying, and demonstrate that stimulated
emission offers a concrete physical realization of state-dependent quantum
copying.

</details>


### [642] [Realistic vulnerabilities of decoy-state quantum key distribution](https://arxiv.org/abs/2507.15446)
*I. S. Sushchev,K. E. Bugai,S. N. Molotkov,D. S. Bulavkin,A. S. Sidelnikova,D. M. Melkonian,V. M. Vakhrusheva,R. Yu. Lokhmatov,D. A. Dvoretskiy*

Main category: quant-ph

TL;DR: 诱骗态QKD易受激光损伤和明确状态鉴别组合攻击的影响，可能导致密钥泄露。


<details>
  <summary>Details</summary>
Motivation: 旨在揭示诱骗态量子密钥分发（QKD）在现实条件下面临的，由激光损伤攻击（LDA）和明确状态鉴别（USD）共同引发的安全漏洞，特别是当攻击超出了协议设计的安全范畴时。

Method: 分析了激光损伤攻击（LDA）和明确状态鉴别（USD）组合攻击对诱骗态量子密钥分发（QKD）的实际漏洞。通过数值模拟，我们证明了当平均光子数超过特定阈值时，即使在标准安全检查下，窃听者（Eve）也能通过基于USD的拦截重发策略窃取全部密钥。此外，我们还展示了修改USD设置可以降低攻击所需的阈值。

Result: 研究表明，当平均光子数超过特定阈值（约10-20 dB）时，窃听者（Eve）可以利用激光损伤攻击（LDA）和明确状态鉴别（USD）实施有效的拦截重发策略，从而获取全部密钥，并且不会被标准安全检查发现。修改后的USD设置可以降低所需的攻击阈值。

Conclusion: 现有诱骗态量子密钥分发（QKD）协议易受激光损伤攻击（LDA）和明确状态鉴别（USD）组合攻击的影响，这会影响其安全性。需要开发稳健的对策来抵御高功率激光损伤。

Abstract: We analyze realistic vulnerabilities of decoy-state quantum key distribution
(QKD) arising from the combination of laser damage attack (LDA) and unambiguous
state discrimination (USD). While decoy-state QKD is designed to protect
against photon-number-splitting and beam-splitting attacks by accurately
estimating the single-photon fraction, it relies on stable attenuation to
prepare pulses with fixed mean-photon numbers. An eavesdropper (Eve) can
exploit LDA to irreversibly alter the optical components on Alice's side,
effectively increasing the mean-photon numbers beyond the decoy-state security
regime. We show that once the alteration exceeds a critical threshold - on the
order of 10--20 dB - Eve can implement an efficient USD-based intercept-resend
strategy using current off-the-shelf technology, thus obtaining the entire
secret key. Numerical simulations confirm that for sufficiently elevated
mean-photon numbers, Eve's conclusive measurement outcomes skew the decoy-state
statistics, yet remain undetected by standard security checks. We further
demonstrate how a modified USD setup employing an additional beam splitter can
reduce the required threshold, facilitating Eve's attack. Our findings
emphasize the need for robust safeguards against high-power laser damage in QKD
systems, including careful hardware selection, rigorous testing under
high-power illumination, and real-time monitoring to ensure the integrity of
the decoy-state protocol.

</details>


### [643] [Entanglement Preservation and Clauser-Horne Nonlocality in Electromagnetically Induced Transparency Quantum Memories](https://arxiv.org/abs/2507.15453)
*Po-Han Tseng,Yong-Fan Chen*

Main category: quant-ph

TL;DR: EIT 量子存储器存储纠缠光子的理论模型被建立，并预测了保持非局域性的临界存储效率阈值。


<details>
  <summary>Details</summary>
Motivation: 虽然实验证明 EIT 量子存储器可以存储纠缠光子，但尚未严格建立验证纠缠和非局域性保持的理论框架。

Method: 通过整合暗态极化子框架和约化密度算符理论，我们推导了在实际基态退相干条件下检索到的密度算符。

Result: 研究表明，退相干会导致探测光子损失，将贝尔态转化为混合态，并预测了 89.7% 的临界存储效率阈值，超过该阈值后探测光子态才违反 Clauser-Horne 不等式，从而保持非局域性；在理想极限下，多个空间分离的 EIT 存储器可以以近乎统一的保真度联合存储和检索编码在光子数、路径和偏振中的 N 问数量子态。

Conclusion: 该研究为 EIT 量子存储器在可扩展量子网络和量子信息处理中的应用奠定了坚实的基础。

Abstract: Quantum memories are indispensable for quantum repeater networks,
deterministic generation of single- or multi-photon states, and linear optical
quantum computing. Although experiments have demonstrated that
electromagnetically induced transparency (EIT) quantum memories can store
entangled photons, a definitive theoretical framework verifying the
preservation of entanglement and nonlocality has not been rigorously
established. Here, we develop a comprehensive model by integrating the
dark-state polariton framework with reduced-density-operator theory to derive
the retrieved density operator under realistic ground-state decoherence
conditions. Our analysis reveals that decoherence inevitably causes probe
photon loss, converting a Bell state into a mixed state. Crucially, we predict
a critical storage efficiency threshold of 89.7%. Only when this threshold is
exceeded does the retrieved probe photon state violate the Clauser-Horne
inequality, thereby preserving nonlocality; below this point, nonlocal
correlations vanish. Moreover, our theory shows that multiple spatially
separated EIT memories can cooperatively store and retrieve N-qubit entangled
states encoded in photon number, path, and polarization with near-unity
fidelity in the ideal limit. This work bridges a long-standing theoretical gap
and lays a solid foundation for the application of quantum memories in scalable
quantum networks and quantum information processing.

</details>


### [644] [Quantum thermometry with non-Gaussian states: From non-equilibrium speed to equilibrium precision](https://arxiv.org/abs/2507.15458)
*Asghar Ullah,M. Tahir Naseem,Özgür E. Müstecaplıoğlu*

Main category: quant-ph

TL;DR: 该研究探讨了量子探针在不同状态（瞬态、平衡）和类型（高斯、非高斯、单模、双模）下进行温度估计的性能。研究发现，非高斯探针和纠缠态在非平衡状态下能提高估计速度和精度，而在平衡状态下，双模压缩热态优于单模策略。能量和布尔数可观测量是最佳测量方式。


<details>
  <summary>Details</summary>
Motivation: 我们研究使用量子探针进行温度估计，以探索在高斯和非高斯探针状态下，在瞬态和平衡状态下的估计性能。

Method: 我们研究了使用量子探针进行温度估计，包括单模初始态和在有限温度下通过非线性晶体受激参量下转换产生的双模态。我们探索了瞬态和平衡状态，并比较了高斯和非高斯探针状态在温度估计方面的性能。

Result: 在非平衡状态下，单模非高斯探针状态（如 Fock、奇数猫和 Gottesman-Kitaev-Preskill 状态）可以显著提高估计速度，尤其是在相互作用时间短的情况下。在双模情况下，纠缠态（如双模压缩真空、NOON 态和纠缠猫态）可以更早地获取温度信息。在平衡状态下，双模压缩热态的表现优于单模策略。能量和布尔数可观测量能获得最佳精度，而二次测量则不是最佳选择。压缩可以抑制布尔数中的涨落，从而提高精度。

Conclusion: 在非平衡状态下，单模非高斯探针状态（如 Fock、奇数猫和 Gottesman-Kitaev-Preskill 状态）可以显著提高估计速度，尤其是在相互作用时间短的情况下。在双模情况下，纠缠态（如双模压缩真空、NOON 态和纠缠猫态）可以更早地获取温度信息。在平衡状态下，双模压缩热态的表现优于单模策略。能量和布尔数可观测量能获得最佳精度，而二次测量则不是最佳选择。压缩可以抑制布尔数中的涨落，从而提高精度。

Abstract: We study temperature estimation using quantum probes, including single-mode
initial states and two-mode states generated via stimulated parametric
down-conversion in a nonlinear crystal at finite temperature. We explore both
transient and equilibrium regimes and compare the performance of Gaussian and
non-Gaussian probe states for temperature estimation. In the non-equilibrium
regime, we show that single-mode non-Gaussian probe states - such as Fock, odd
cat, and Gottesman-Kitaev-Preskill states - can significantly enhance the speed
of estimation, particularly at short interaction times. In the two-mode
setting, entangled states such as the two-mode squeezed vacuum, NOON state, and
entangled cat state can enable access to temperature information at much
earlier times. In the equilibrium regime, we analyze temperature estimation
using two-mode squeezed thermal states, which outperform single-mode
strategies. We evaluate practical measurements and find that both energy and
population difference observables yield optimal precision, while
quadrature-based measurements are suboptimal. The precision gain arises from
squeezing, which suppresses fluctuations in the population difference.

</details>


### [645] [Symmetry and Liouville Space Formulation of Decoherence-Free Subsystems](https://arxiv.org/abs/2507.15506)
*Mi-Jung So,Mahn-Soo Choi*

Main category: quant-ph

TL;DR: 该研究提出了一种基于对称性的开放量子系统退相干自由方案，利用舒尔-韦尔对偶性和超级舒尔基简化了计算，并能识别出退相干自由子系统。


<details>
  <summary>Details</summary>
Motivation: 提出一种通用的、系统的退相干自由方案，用于在开放量子系统中编码量子信息，重点在于对称性。

Method: 通过利用舒尔-韦尔对偶性，基于成熟的群表示论进行计算，并构建了一个超级舒尔基，将描述噪声量子通道的超级算子进行块对角化。

Result: 该方案能够识别出退相干自由子系统，并利用舒尔-韦尔对偶性简化了计算。

Conclusion: 可以识别出物理上相关的退相干自由子系统，这些子系统在指定的弱对称性下是可识别的。

Abstract: We propose a generic and systematic decoherence-free scheme to encode quantum
information into an open quantum system based focusing on symmetry. Under a
given symmetry, the Liouville space is decomposed into invariant subspaces
characterized by a tensor-product structure. A decoherence-free subsystem is
then identified as a factor of the tensor product. Unlike decoherence-free
subspaces, which typically require strong symmetries, decoherence-free systems
are permitted under less restrictive weak symmetries. Specifically, we
primarily concern the permutation symmetry in conjunction with the unitary
symmetry and utilize the Schur-Weyl duality, which facilitates numerous
efficient and systematic calculations based on the well-established group
representation theory. Employing the isomorphism between the Liouville space
and the fictitious Hilbert space, we construct a super-Schur basis, which
block-diagonalizes the super-operators that describe the noisy quantum
channels, both in the Kraus representation and in terms of the quantum master
equation. Each block reveals the tensor-product structure and facilitates the
identification of physically relevant decoherence-free subsystems under the
specified weak symmetry.

</details>


### [646] [Quantum non-demolition measurement of optical quadratures using quadratic nonlinearity](https://arxiv.org/abs/2507.15508)
*D. I. Salykina,V. S. Liamin,P. R. Sharapova,F. Ya. Khalili*

Main category: quant-ph

TL;DR: 提出了一种新的光学场 याचे的QND测量方案，利用非简并光学参量放大器，实现了测量之 याचे的 याचे被放大的同时不受反作用力影响。


<details>
  <summary>Details</summary>
Motivation: 量子无破坏（QND）测量是一种能够避免量子反作用力的特殊技术。本研究旨在提出一种新的QND测量方案。

Method: 提出了一种基于非简并光学参量放大器（non-degenerate optical parametric amplifier）的新型量子无破坏（Quantum Non-demolition, QND）测量方案，用于测量光学场的 याचे。

Result: 该方案在特定参数下，实现了对光学场 याचे的QND测量，其特点是被测量之 याचे的 याचे被放大的同时，仍然不受任何反作用力的影响。

Conclusion: 所提出的基于非简并光学参量放大器的光学场 याचे的QND测量方案，在合适的参数下，可以实现一种新的QND测量类型，即被测量之 याचे的 याचे被放大的同时，仍然不受任何反作用力的影响。

Abstract: Quantum non-demolition (QND) measurement is a special technique that allows
to evade quantum back-action. In this paper, we propose a new QND measurement
scheme of the optical field quadratures based on the non-degenerate optical
parametric amplifier. We show that for a proper set of parameters, this scheme
can realize a new type of QND measurement, where the quadrature of interest is
amplified but still does not subject to any back action.

</details>


### [647] [Matrix inversion polynomials for the quantum singular value transformation](https://arxiv.org/abs/2507.15537)
*Christoph Sünderhauf,Zalán Németh,Adnaan Walayat,Andrew Patterson,Bjorn K. Berntson*

Main category: quant-ph

TL;DR: 本文提出了一种用于量子矩阵求逆的解析方法，以获得最优多项式逼近，减少了计算资源和电路深度。


<details>
  <summary>Details</summary>
Motivation: 量子奇异值变换（QSVT）需要对 1/x 的多项式逼近，而现有方法需要资源密集型的 Remez 方法来近似最优多项式。

Method: 推导了最优多项式的解析方法。

Result: 所提出的多项式被证明是最优的，并且在 [-1,1] 区间上的最大值最小，从而减少了 QSVT 的电路深度。

Conclusion: 文中提供的 Python 代码可供该领域的从业者使用。

Abstract: Quantum matrix inversion with the quantum singular value transformation
(QSVT) requires a polynomial approximation to $1/x$. Several methods from the
literature construct polynomials that achieve the known degree complexity
$\mathcal{O}(\kappa\log(\kappa/\varepsilon))$ with condition number $\kappa$
and uniform error $\varepsilon$. However, the \emph{optimal} polynomial with
lowest degree for fixed error $\varepsilon$ can only be approximated
numerically with the resource-intensive Remez method, leading to impractical
preprocessing runtimes. Here, we derive an analytic shortcut to the optimal
polynomial. Comparisons with other polynomials from the literature, based on
Taylor expansion, Chebyshev iteration, and convex optimization, confirm that
our result is optimal. Furthermore, for large $\kappa\log(\kappa/\varepsilon)$,
our polynomial has the smallest maximum value on $[-1,1]$ of all approaches
considered, leading to reduced circuit depth due to the normalization condition
of QSVT. With the Python code provided, this paper will also be useful for
practitioners in the field.

</details>


### [648] [A One-sided Witness for the Quantumness of Gravitational Dynamics](https://arxiv.org/abs/2507.15588)
*Konstantin Beyer,M. S. Kim,Igor Pikovski*

Main category: quant-ph

TL;DR: 利用可验证量子记忆，单方面验证引力相互作用的量子性。


<details>
  <summary>Details</summary>
Motivation: 探索在桌面实验中利用量子信息概念和量子技术探测量子引力，特别是验证引力是否为量子通道。

Method: 提出了一种基于可验证量子记忆的间接测试方法，该方法仅需对一个子系统进行局部测量即可评估两个系统之间相互作用的量子性。

Result: 实现了引力量子性质的单方面验证，并提供了一种不同于现有方案的、能够完全覆盖引力相互作用量子性的量子签名。

Conclusion: 本研究提出了一种新颖的、可验证的量子记忆方法，用于单方面验证引力相互作用的量子性质，为设计仅通过探测系统进行测量即可进行的决定性测试开辟了新途径。

Abstract: Quantum information concepts and quantum technologies have opened the
prospect to probe quantum gravity in table-top experiments. Many proposals rely
on witnessing entanglement generation as a means to probe whether gravity is a
quantum channel. Here we formulate a different and conclusive indirect test of
the quantum nature of the gravitational interaction. Our witness is based on
the concept of verifiable quantum memory in the dynamics of a quantum system.
This allows us to assess the quantumness of an interaction between two systems
by local measurements on one subsystem only. Our approach enables the first
one-sided verification of the quantum nature of gravity, and provides a quantum
signature of the interaction that is not fully covered by existing proposals.
Our results open novel ways to witnessing the quantum nature of gravity in
table-top experiments and clarify how {decisive tests can be designed even with
measurements on only the probe system

</details>


### [649] [Unconventional photon blockade in a hybrid optomechanical system with an embedded spin-triplet](https://arxiv.org/abs/2507.15605)
*Yao Dong,Jing-jing Wang,Guo-Feng Zhang*

Main category: quant-ph

TL;DR: 该研究 article 探讨了在具有嵌入式自旋三重态的混合光力系统中反常的光子块效应。研究发现，调制机械耗散对于实现强光子块至关重要，并且该系统有潜力成为高质量、高效率的单光子源。


<details>
  <summary>Details</summary>
Motivation: 研究在具有嵌入式自旋三重态的混合光力系统中反常的光子块效应。

Method: 通过解析求解薛定谔方程和数值模拟主方程。

Result: 通过调整系统参数，强光子块和单光子共振可以重合，证明了该混合系统有潜力成为高质量、高效率的单光子源。调制机械耗散对于在我们的系统中实现强光子块至关重要。与传统的腔光力系统不同，在弱单光子光力耦合下可以获得二阶关联函数g(2)(0) =0。

Conclusion: 该混合系统有潜力成为高质量、高效率的单光子源。

Abstract: The research article studies the unconventional photon blockade effect in a
hybrid optomechanical system with an embedded spin-triplet state. The
interaction between the optomechanical system and the spin state generates new
transition paths for the destructive quantum interference of the two-photon
excitation state. By analytically solving the Schrodinger equation and
numerically simulating the master equation, it can be found that the modulated
mechanical dissipation is essential for achieving the strong photon blockade in
our system. Unlike the conventional cavity optomechanical system, the
second-order correlation function g(2)(0) =0 can be obtained with the weak
single-photon optomechanical coupling. By adjusting the system parameters, the
strong photon blockade and the single-photon resonance can coincide, which
indicates the hybrid system has the potential to be a high-quality and
efficient single-photon source. Finally, the influence of the thermal noise on
photon blockade is investigated. The results show that the second-order
correlation function is more robust for the weaker phonon-spin coupling.

</details>


### [650] [Dynamic Investigation of the New Quantum-Control-Assisted Reverse uncertainty relation](https://arxiv.org/abs/2507.15619)
*Qiyi Li,Shaoqiang Ma,Sansheng Wang,Xiao Zheng,Guofeng Zhang*

Main category: quant-ph

TL;DR: 通过量子控制打破反向不确定性关系，并发现其与系统混合度存在函数关系。


<details>
  <summary>Details</summary>
Motivation: 研究反向不确定性关系，特别是如何通过量子控制来影响它，以及它与系统混合度之间的关系。

Method: 提出了一种新的量子控制辅助反向不确定性关系，并研究了其在具有德雅洛申斯基-莫里亚相互作用的海森堡模型中的动态演化。

Result: 反向不确定性关系可以被量子控制打破，并且不确定性关系的紧密度和上限可以表示为系统混合度的函数。

Conclusion: 新构造的量子控制辅助反向不确定性关系可以在量子控制系统的帮助下被打破，并且该关系与系统的混合度存在单值关系，而这种关系是标准不确定性关系和反向不确定性关系的共同特性。

Abstract: Recently, a new interesting concept of reverse uncertainty relation is
introduced. Different from the normal uncertainty relation, the reverse one
indicates that one cannot only prepare quantum states with joint small
uncertainty, but also with joint great uncertainty for incompatible
observables. We in this work construct a new quantum-control-assisted reverse
uncertainty relation and investigate the corresponding dynamic evolution in the
Heisenberg model with Dzyaloshinskii-Moriya interaction. The obtained relation
indicates that the reverse uncertainty can be broken with help of the quantum
control system. The dynamic investigation reveals that there exists an
interesting single-value relationship between new uncertainty relation and the
mixedness of the system, indicating that the tightness and upper bound of the
uncertainty relation can be written as functional form of the mixedness. By
comparing the existing research in [Physica Scripta 2023, 98(6), 065113], we
show that the single-value relationship with the mixedness is the common nature
of both the normal uncertainty relations and the reverse uncertainty relation.

</details>


### [651] [Enhancing Quantum Discord in V-shaped Plasmonic Waveguides by Quantum Feedback](https://arxiv.org/abs/2507.15627)
*Hua-Wei Zhao,Gen Li,Guo-Feng Zhang*

Main category: quant-ph

TL;DR: 通过量子反馈控制，改善了量子散度和贝尔态，并提出了优化方向。


<details>
  <summary>Details</summary>
Motivation: 研究量子反馈控制对量子 상관关系（特别是量子散度）的影响，以期改善量子信息处理中的退相干问题。

Method: 通过对称量子反馈控制，研究了其对V形等离体波导中X态量子散度的影响，并通过演化矩阵元素揭示了其作用机制，将初始的4*4矩阵限制在3*3子空间内。

Result: 量子散度从0提高到0.38，并且在降低原子衰减率后持续升高，成功抑制了贝尔态的退化。

Conclusion: 研究通过对称量子反馈控制改善了X态量子散度和贝尔态的退化，并通过改进反馈哈密顿量提出了优化方向。

Abstract: We investigate the impact of a symmetric quantum feedback control on the
quantum discord of the X state in V-shaped plasmonic waveguides. Under this
feedback, the quantum discord of the Werner state is enhanced from 0 to 0.38.
This value even continues to rise after reducing the decay rate of the atoms.
Furthermore, we get the operational mechanism of feedback control through the
evolution of the matrix elements. It confines the initial 4 * 4 matrix into a 3
* 3 subspace. As a result, the weights of each ground state in the quantum
state change, which suppresses the degradation of Bell state. Lastly, we
propose a direction for suggesting an improved feedback Hamiltonian.

</details>


### [652] [Caustics in a Near-Resonant Quantum Kicked Rotor](https://arxiv.org/abs/2507.15634)
*Yi Cao,Shaowen Lan,Bin Sun,Jie Liu*

Main category: quant-ph

TL;DR: 研究了量子踢转子在近共振状态下的动力学行为，发现了周期性的尖瓣天篷，并推导了量子振幅增强的标度律。


<details>
  <summary>Details</summary>
Motivation: 研究量子踢转子在近共振区域的动力学行为，观察到了量子波函数累积的特定周期性尖瓣天篷。

Method: 通过推导路径积分表达式，分析了量子象限转子在近共振状态下的动力学行为，并确定了天篷形成和重复周期的条件。

Result: 推导了与阿诺德指数1/4相关的标度幂律，该幂律将量子振幅增强与踢力强度和共振失谐参数联系起来，并得到了验证。

Conclusion: 该研究推导了量子演化的路径积分表达式，并确定了天篷形成和重复周期的条件。发现与阿诺德指数 1/4 相关的标度幂律，该幂律将量子振幅增强与踢力强度和共振失谐参数联系起来，并已得到验证。

Abstract: In this paper, we investigate the dynamics of the quantum kicked rotor in the
near-resonant regime and observe a particular recurring cusp caustic of the
wave functions' accumulation. We then derive the path integral expression of
the quantum evolution and analytically determine the conditions for the caustic
formation and recurring period. A scaling power law with Arnold index of $1/4$
relating to the wave amplitude enhancement depending on the kicking strength as
well as the resonant detuning parameter, has been derived and verified. We also
discuss classical-quantum correspondence of the caustics and find that chaos
can disrupt the phase matching leading to the destruction of the caustic
structure. Finally, possible experimental observations and some implications of
these findings are discussed.

</details>


### [653] [On Strong Converse Bounds for the Private and Quantum Capacities of Anti-degradable Channels](https://arxiv.org/abs/2507.15661)
*Zahra Baghali Khanian,Christoph Hirche*

Main category: quant-ph

TL;DR: 为不可降解量子信道的私有经典容量和量子容量的极限提供了更精确的界定和更简化的证明。


<details>
  <summary>Details</summary>
Motivation: 为了更精确地理解和界定不可降解量子信道的私有经典容量和量子容量的极限，特别是超越先前研究的局限性。

Method: 通过数学推导和不等式证明，建立了私有经典容量的强反向界限，并对不可降解信道的量子容量提出了一个“相当简单”的“相当强”的反向证明。

Result: 1. 确立了不可降解量子信道的私有经典容量的强反向界限：当满足 $\delta (1-\epsilon^2)^{\frac{1}{2}}+\epsilon (1-\delta^2)^{\frac{1}{2}}<1$ 时，容量为零。 2. 为不可降解信道的量子容量提供了一个“相当简单”的“相当强”的反向证明，该证明适用于 $\epsilon < \frac{1}{\sqrt{2}}$ 的情况。

Conclusion: 该研究为不可降解量子信道的私有经典容量建立了强反向界限，指出当满足特定条件时，该容量为零，从而精确定义了可靠和私有通信的极限边界。此外，研究还为不可降解信道的量子容量提供了一个“相当简单”的“相当强”的反向证明，适用于特定误差范围，为量子通信的基础极限提供了新的见解。

Abstract: We establish a strong converse bound for the private classical capacity of
anti-degradable quantum channels. Specifically, we prove that this capacity is
zero whenever the error $\epsilon > 0$ and privacy parameter $\delta > 0$
satisfy the inequality $\delta (1-\epsilon^2)^{\frac{1}{2}}+\epsilon
(1-\delta^2)^{\frac{1}{2}}<1$. This result strengthens previous understandings
by sharply defining the boundary beyond which reliable and private
communication is impossible. Furthermore, we present a ``pretty simple'' proof
of the ``pretty strong'' converse for the quantum capacity of anti-degradable
channels, valid for any error $\epsilon < \frac{1}{\sqrt{2}}$. Our approach
offers clarity and technical simplicity, shedding new light on the fundamental
limits of quantum communication.

</details>


### [654] [Efficiently Generation of Cluster States via Time-Delayed Feedback in Matrix Representation](https://arxiv.org/abs/2507.15725)
*Jia-Jin Zou,Jian-Wei Qin,Franco Nori,Ze-Liang Xiang*

Main category: quant-ph

TL;DR: 利用矩阵表示和多时间延迟反馈（TDF）生成任意簇态，优化效率并降低损耗。


<details>
  <summary>Details</summary>
Motivation: 由于应用对具有特定纠缠结构的簇态有多种需求，但目前缺乏通用的生成协议。

Method: 提出了一种根据时间延迟反馈（TDF）的特性进行矩阵表示的方法，并提出了一种利用多个TDF生成任意簇态的协议。

Result: 开发了矩阵表示，优化了生成过程以减少TDF使用，并演示了仅需一个TDF的树簇态生成过程。讨论了由多个TDF引起的额外损耗，并评估了所得簇态的保真度。

Conclusion: 提出了一种利用多时间延迟反馈（TDF）生成任意簇态的协议，并通过矩阵表示进行了优化，以减少TDF的使用并提高效率。

Abstract: Cluster states, as highly entangled multi-qubit states, are widely used as
essential resources for quantum communication and quantum computing. However,
due to the diverse requirements of applications for cluster states with
specific entanglement structures, a universal generation protocol is still
lacking. Here we develop a matrix representation according to the
characteristics of time-delayed feedback (TDF) and propose a protocol for
generating arbitrary cluster states with multiple TDFs. The matrix
representation also allows us to optimize the generation process to reduce TDF
usage, thus improving efficiency. In particular, we demonstrate a
tree-cluster-state generation process that requires only one TDF. Moreover,
accounting for the critical loss mechanisms and imperfections in our protocol,
we discuss the additional losses caused by multiple TDFs and evaluate the
fidelity of the resulting cluster states.

</details>


### [655] [Symplectic coherence: a measure of position-momentum correlations in quantum states](https://arxiv.org/abs/2507.15738)
*Varun Upreti,Ulysse Chabaud*

Main category: quant-ph

TL;DR: 本文提出了一种衡量量子态中位置-动量关联的新方法“辛相干性”，并展示了它在量子信息和热力学中的应用。


<details>
  <summary>Details</summary>
Motivation: 由于量子热力学、计量学和计算等领域的最新进展凸显了其重要性，因此有必要系统地研究量子态中的位置-动量关联。

Method: 本文提出了一种名为“辛相干性”的度量，定义为协方差矩阵中编码位置-动量关联的块的弗罗贝尼厄斯范数，并证明了该度量在相关操作下是单调的，在小扰动下是鲁棒的。此外，利用 Barthe 等人提出的将玻色子态协方差矩阵映射到有限维系统密度矩阵的近期方法，将位置-动量关联与虚拟有限维量子态中的超越经典关联联系起来，其中辛相干性自然映射到几何量子测度。

Result: 本文引入的辛相干性可以作为量子态中位置-动量关联的度量，并且在量子信息和量子热力学任务中具有实际意义。此外，研究还确定了在固定能量下实现最大位置-动量关联的方法，并揭示了相关最优态的结构特性。

Conclusion: 本文建立了研究和量化量子态中位置-动量关联的通用框架，引入了简洁易算的度量“辛相干性”，并将其与有限维量子态中的“超越经典关联”以及“几何量子测度”联系起来。研究还确定了在固定能量下可达到的最大位置-动量关联，揭示了最优态的结构特性，并展示了辛相干性在量子信息任务和量子热力学中的实际应用价值。

Abstract: The interdependence of position and momentum, as highlighted by the
Heisenberg uncertainty principle, is a cornerstone of quantum physics. Yet,
position-momentum correlations have received little systematic attention.
Motivated by recent developments in bosonic quantum physics that underscore
their relevance in quantum thermodynamics, metrology, and computing, we
establish a general framework to study and quantify position-momentum
correlations in quantum states. We introduce symplectic coherence, a faithful
and easily computable measure defined as the Frobenius norm of the block of the
covariance matrix encoding position-momentum correlations, and demonstrate that
symplectic coherence is monotone under relevant operations and robust under
small perturbations. Furthermore, using a recent mapping by Barthe et al.
(Phys. Rev. Lett. 134, 070604) which relates the covariance matrix of a bosonic
state to the density matrix of a finite-dimensional system, we show that
position-momentum correlations correspond to beyond-classical correlations in a
virtual finite-dimensional quantum state, with symplectic coherence mapping
naturally to geometric quantum discord. Taking energy constraints into account,
we determine the maximal position-momentum correlations achievable at fixed
energy, revealing structural insights about the corresponding optimal states.
Finally, we illustrate the operational relevance of symplectic coherence
through several examples in quantum information tasks and quantum
thermodynamics. In the process, we establish new technical results on matrix
norms and quantum covariance matrices, and demonstrate the conceptual
significance of viewing covariance matrices as density matrices of virtual
quantum states.

</details>


### [656] [Quantum logic operations and algorithms in a single 25-level atomic qudit](https://arxiv.org/abs/2507.15799)
*Pei Jiang Low,Nicholas C. F. Zutt,Gaurav A. Tathed,Crystal Senko*

Main category: quant-ph

TL;DR: 该研究利用$^{137}$Ba$^+$离子实现了25维量子比特，并演示了高维量子比特在量子算法中的应用，证明了大维度量子比特在量子计算中的潜力。


<details>
  <summary>Details</summary>
Motivation: 利用量子系统内禀自由度，以提升算法性能和硬件效率。

Method: 实验研究了使用$^{137}$Ba$^+$离子进行量子信息处理，实现了高达25个内部能级的状态制备和读出，构建了25维量子比特。通过探测多达24个能级的叠加态，研究了误差与量子比特维度d的关系，并识别了影响量子相干的主要误差源。此外，通过实现3量子比特的Bernstein-Vazirani算法和4量子比特的Toffoli门，演示了高维量子比特操作。

Result: 实现了高达25个内部能级的状态制备和读出，构建了25维量子比特。探测了多达24个能级的叠加态，研究了误差随维度d的增长，并识别了主要误差源。成功实现了3量子比特的Bernstein-Vazirani算法和4量子比特的Toffoli门。

Conclusion: 基于$^{137}$Ba$^+$离子的大维度量子比特的量子计算架构具有巨大潜力。

Abstract: Scaling quantum computers remains a substantial scientific and technological
challenge. Leveraging the full range of intrinsic degrees of freedom in quantum
systems offers a promising route towards enhanced algorithmic performance and
hardware efficiency. We experimentally study the use of $^{137}$Ba$^+$ ions for
quantum information processing, achieving high-fidelity state preparation and
readout of up to 25 internal levels, thus forming a 25-dimensional qudit. By
probing superpositions of up to 24 states, we investigate how errors scale with
qudit dimension $d$ and identify the primary error sources affecting quantum
coherence. Additionally, we demonstrate high-dimensional qudit operations by
implementing a 3-qubit Bernstein-Vazirani algorithm and a 4-qubit Toffoli gate
with a single ion. Our findings suggest that quantum computing architectures
based on large-dimensional qudits hold significant promise.

</details>


### [657] [Mpemba effect in self-contained quantum refrigerators: accelerated cooling](https://arxiv.org/abs/2507.15811)
*Sayan Mondal,Ujjwal Sen*

Main category: quant-ph

TL;DR: 量子 Mpmba 效应在量子冰箱中得到证实，它能加速冷却过程，并且可以通过酉变换实现。


<details>
  <summary>Details</summary>
Motivation: 在量子系统中观察和理解量子 Mpmba 效应，以加速冷却过程。

Method: 利用包含三个玻色热库的量子 Mpmba 效应的量子比特-qutrit 模型，通过求解块对角线 Liouvillian 来研究系统动力学，并进行数值计算以确定稳态。

Result: 在量子比特-qutrit 模型中观察到量子 Mpmba 效应，其中 Mpmba 状态比平衡状态更快地达到稳态，从而加速了冷量子比特的冷却。还发现局部和全局酉变换都可以产生 Mpmba 状态。

Conclusion: 研究表明，量子冰箱的量子 Mpmba 效应在冷却过程中可以实现，并且可以通过局部和全局酉变换来生成。该研究还探讨了耦合对 Mpmba 效应的影响。

Abstract: We consider the qubit-qutrit model of self-contained quantum refrigerator and
observe the quantum Mpemba effect in its cooling. In this system, the qutrit
acts as the refrigerator while the qubit is to be cooled. The entire system is
coupled to three bosonic heat baths, due to which the dynamics of the system is
governed by a Gorini-Kossakoswski-Sudarshan-Lindblad master equation. We
investigate the Liouvillian that generates the dynamics of the system and find
that it has a block diagonal form. The dynamics of each element of the system's
density matrix can be determined by solving the dynamical equation of the
corresponding block that contains it. We find that the steady state belongs to
the block containing only the diagonal elements in the energy basis. We
numerically solve for the steady state and investigate the steady-state cooling
over a significant region of the parameter space. Moreover, we demonstrate the
quantum Mpemba effect in the refrigerator: a Mpemba state obtained by applying
a unitary on the equilibrium state of the system reaches the steady state
faster than the equilibrium state, despite the Mpemba state being initially
farther away from the steady state. The Mpemba state thus leads to an
acceleration in cooling of the cold qubit. We also find that both local and
global unitaries on the qubit-qutrit system can generate the Mpemba state.
Finally, we study the effect of the qubit-qutrit couplings and the system-bath
couplings on the Mpemba effect.

</details>


### [658] [Quantum computational sensing using quantum signal processing, quantum neural networks, and Hamiltonian engineering](https://arxiv.org/abs/2507.15845)
*Saeed A. Khan,Sridhar Prabhu,Logan G. Wright,Peter L. McMahon*

Main category: quant-ph

TL;DR: 本研究提出一种结合量子计算与传感的新方法（QCS），使用量子算法处理传感信号，在特定任务中准确率超越传统量子传感达 20% 以上，且在小型量子系统上即可实现优势，为 QCS 的实验和应用铺平道路。


<details>
  <summary>Details</summary>
Motivation: 量子计算与量子传感的结合能够产生量子计算传感器，这种传感器能够比传统方法更有效地从物理信号中提取任务特定的信息。尽管已有将格罗弗算法应用于信号检测的早期 QCS 实例，但大多数研究仅限于传感操作前仅有一次测量。因此，本研究旨在探索在传感过程中交织量子计算操作（如量子信号处理和量子神经网络）的可能性，以提升信息提取的效率和精度，并论证其在实际应用中的潜力。

Method: 本研究在理论和数值模拟上，将量子信号处理和量子神经网络两种量子算法应用于多种二分类和多分类的机器学习传感任务。通过在传感操作中交织计算操作，实现了对传感信号的非线性函数处理。研究评估了基于静态、时变以及时空耦合信号的任务。为优化 QCS 协议的电路参数，研究考虑了量子采样噪声，并设计了仅需一次测量即可获得精确结果的协议。此外，还提出了使用哈密顿量工程化的玻色子系统和混合量子比特-玻色子系统执行非线性任务的协议。

Result: 研究结果表明，量子计算传感器在特定任务中能够实现比传统量子传感器更高的准确率，模拟数据显示某些任务的准确率优势可达 20% 以上。该方法能够处理静态、时变及各类时空信号。通过优化电路参数并考虑量子采样噪声，研究设计的 QCS 协议仅需单次测量即可获得高精度结果。此外，研究还提出了适用于哈密顿量工程化的玻色子系统以及混合量子比特-玻色子系统的非线性任务协议。研究证实，即使在仅包含少量量子比特、单个量子比特和单个玻色子模式，甚至仅单个量子比特的量子系统中，也能获得显著的量子计算传感优势。

Conclusion: 该研究提出了一种将量子计算与量子传感相结合的量子计算传感（QCS）新方法。通过在传感操作中交织量子算法（如量子信号处理和量子神经网络），可以实现比传统量子传感更高的任务特定信息提取效率。研究表明，即使在量子系统较小（如仅包含少量量子比特或单个量子比特与玻色子模式）的情况下，QCS 也能在某些任务中实现超过 20 个百分点的准确率优势。该方法考虑了量子采样噪声，并能在仅一次测量的情况下获得准确结果，这为 QCS 的实验验证和实际应用奠定了基础。

Abstract: Combining quantum sensing with quantum computing can lead to quantum
computational sensors that are able to more efficiently extract task-specific
information from physical signals than is possible otherwise. Early examples of
quantum computational sensing (QCS) have largely focused on protocols where
only a single sensing operation appears before measurement -- with an exception
being the recent application of Grover's algorithm to signal detection. In this
paper we present, in theory and numerical simulations, the application of two
quantum algorithms -- quantum signal processing and quantum neural networks --
to various binary and multiclass machine-learning classification tasks in
sensing. Here sensing operations are interleaved with computing operations,
giving rise to nonlinear functions of the sensed signals. We have evaluated
tasks based on static and time-varying signals, including spatiotemporal
signals. Our approach to optimizing the circuit parameters in a QCS protocol
takes into account quantum sampling noise and allows us to engineer protocols
that can yield accurate results with as few as just a single measurement shot.
In all cases, we have been able to show a regime of operation where a quantum
computational sensor can achieve higher accuracy than a conventional quantum
sensor, with a simulated accuracy advantage of $>$20 percentage points for some
tasks. We also present protocols for performing nonlinear tasks using
Hamiltonian-engineered bosonic systems and quantum signal processing with
hybrid qubit-bosonic systems. Overall, we have shown that substantial quantum
computational-sensing advantages can be obtained even if the quantum system is
small, including few-qubit systems, systems comprising a single qubit and a
single bosonic mode, and even just a single qubit alone -- raising the
prospects for experimental proof-of-principle and practical realizations.

</details>


<div id='cs.MA'></div>

# cs.MA [[Back]](#toc)

### [659] [Learning to Communicate in Multi-Agent Reinforcement Learning for Autonomous Cyber Defence](https://arxiv.org/abs/2507.14658)
*Faizan Contractor,Li Li,Ranwa Al Mallah*

Main category: cs.MA

TL;DR: 通过在网络作战研究演习中使用可微分智能体学习算法，我们训练了能够通信和防御的特工，他们的策略类似于人类专家，并且学会了低成本通信。


<details>
  <summary>Details</summary>
Motivation: 为了解决在部分可观测环境中，合作式多智能体强化学习（MARL）方法中，特工独立行动可能限制其协调效应的问题，我们提出了一种通信机制，以提升网络战空间的决策能力。

Method: 使用可微分智能体学习算法（Differentiable Inter Agent Learning）在网络作战研究演习（Cyber Operations Research Gym）中训练特工，使其学习通信和防御策略。

Result: 特工们学会了同时学习最低成本的通信信息和防御战术策略，以应对网络威胁。

Conclusion: 特工们学会了在网络攻防演练中进行通信和防御，其战术策略与人类专家应对网络威胁的策略相似。

Abstract: Popular methods in cooperative Multi-Agent Reinforcement Learning with
partially observable environments typically allow agents to act independently
during execution, which may limit the coordinated effect of the trained
policies. However, by sharing information such as known or suspected ongoing
threats, effective communication can lead to improved decision-making in the
cyber battle space. We propose a game design where defender agents learn to
communicate and defend against imminent cyber threats by playing training games
in the Cyber Operations Research Gym, using the Differentiable Inter Agent
Learning algorithm adapted to the cyber operational environment. The tactical
policies learned by these autonomous agents are akin to those of human experts
during incident responses to avert cyber threats. In addition, the agents
simultaneously learn minimal cost communication messages while learning their
defence tactical policies.

</details>


### [660] [LLM-Enhanced Multi-Agent Reinforcement Learning with Expert Workflow for Real-Time P2P Energy Trading](https://arxiv.org/abs/2507.14995)
*Chengwei Lou,Zekai Jin,Wei Tang,Guangfei Geng,Jin Yang,Lu Zhang*

Main category: cs.MA

TL;DR: 本研究提出LLM-MARL框架，通过LLM提供个性化策略指导强化学习，以解决实时P2P电力交易中的用户能力、专家经验和电网安全问题，实验证明其在降低成本和提高稳定性方面优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 实时P2P电力市场在适应可再生能源波动和需求变化方面具有优势，但为大规模个性化产消者提供专家指导面临挑战，包括多样化的决策需求和定制化建模框架的缺乏。

Method: 本研究提出了一个集成的LLM-MARL框架，其中LLM作为专家通过模仿学习生成个性化策略，指导CTDE范式下的MARL。设计了一个基于差分注意力机制的Critic网络来提升收敛性能。

Result: 实验结果表明，LLM生成的策略能够有效替代人类专家。与基线算法相比，所提出的多智能体模仿学习算法在测试集上实现了显著更低的经济成本和电压违规率，同时保持了鲁棒性稳定性。

Conclusion: 该研究提出了一种结合大型语言模型（LLM）和多智能体强化学习（MARL）的框架，用于解决实时点对点（P2P）电力交易中的挑战，如用户技术能力有限、缺乏专家经验和电网安全问题。LLM作为专家生成个性化策略，通过模仿学习指导CTDE（集中训练去中心化执行）范式下的MARL。实验结果表明，LLM生成的策略能有效替代人类专家，并且所提出的多智能体模仿学习算法在经济成本和电压违规率方面显著优于基线算法，同时保持了鲁棒性稳定性。

Abstract: Real-time peer-to-peer (P2P) electricity markets dynamically adapt to
fluctuations in renewable energy and variations in demand, maximizing economic
benefits through instantaneous price responses while enhancing grid
flexibility. However, scaling expert guidance for massive personalized
prosumers poses critical challenges, including diverse decision-making demands
and lack of customized modeling frameworks. This paper proposed an integrated
large language model-multi-agent reinforcement learning (LLM-MARL) framework
for real-time P2P energy trading to address challenges such as the limited
technical capability of prosumers, the lack of expert experience, and security
issues of distribution networks. LLMs are introduced as experts to generate
personalized strategy, guiding MARL under the centralized training with
decentralized execution (CTDE) paradigm through imitation learning. A
differential attention-based critic network is designed to enhance convergence
performance. Experimental results demonstrate that LLM generated strategies
effectively substitute human experts. The proposed multi-agent imitation
learning algorithms achieve significantly lower economic costs and voltage
violation rates on test sets compared to baselines algorithms, while
maintaining robust stability. This work provides an effective solution for
real-time P2P electricity market decision-making by bridging expert knowledge
with agent learning.

</details>


### [661] [EduThink4AI: Translating Educational Critical Thinking into Multi-Agent LLM Systems](https://arxiv.org/abs/2507.15015)
*Xinmeng Hou,Zhouquan Lu,Wenli Chen,Hai Hu,Qing Guo*

Main category: cs.MA

TL;DR: EDU-Prompting是一个新的多智能体框架，通过整合教育理论和LLM设计，提高了AI教育工具生成内容的真实性和逻辑性，同时促进了批判性思维和多视角，解决了现有LLM教育工具在处理复杂推理和对抗性提示方面的不足。


<details>
  <summary>Details</summary>
Motivation: 为了解决当前LLM教育工具在培养批判性思维方面的不足，它们在处理具有反事实前提的多步推理问题时表现不佳，并且容易受到触发偏见或事实错误回应的对抗性提示的影响。

Method: 提出了一种名为EDU-Prompting的新型多智能体框架，该框架整合了成熟的教育批判性思维理论和LLM智能体设计，用于生成批判性、认知偏见意识的解释，并促进观点的多样性。

Result: 在理论基准和实际大学水平的批判性写作场景中的系统性评估表明，EDU-Prompting显著提高了AI生成教育回应的内容真实性和逻辑合理性。

Conclusion: EDU-Prompting框架能够有效提升AI生成教育回应的内容真实性和逻辑严谨性，并且易于集成到现有系统中，能够促进分析性推理和多视角引入。

Abstract: Large language models (LLMs) have demonstrated significant potential as
educational tutoring agents, capable of tailoring hints, orchestrating lessons,
and grading with near-human finesse across various academic domains. However,
current LLM-based educational systems exhibit critical limitations in promoting
genuine critical thinking, failing on over one-third of multi-hop questions
with counterfactual premises, and remaining vulnerable to adversarial prompts
that trigger biased or factually incorrect responses. To address these gaps, we
propose EDU-Prompting, a novel multi-agent framework that bridges established
educational critical thinking theories with LLM agent design to generate
critical, bias-aware explanations while fostering diverse perspectives. Our
systematic evaluation across theoretical benchmarks and practical college-level
critical writing scenarios demonstrates that EDU-Prompting significantly
enhances both content truthfulness and logical soundness in AI-generated
educational responses. The framework's modular design enables seamless
integration into existing prompting frameworks and educational applications,
allowing practitioners to directly incorporate critical thinking catalysts that
promote analytical reasoning and introduce multiple perspectives without
requiring extensive system modifications.

</details>


### [662] [LLM Economist: Large Population Models and Mechanism Design in Multi-Agent Generative Simulacra](https://arxiv.org/abs/2507.15815)
*Seth Karten,Wenzhe Li,Zihan Ding,Samuel Kleiner,Yu Bai,Chi Jin*

Main category: cs.MA

TL;DR: LLM经济学框架利用基于智能体的建模，让工人智能体和规划者智能体在模拟环境中进行交互，以设计和评估经济政策，并在实验中展示了其在提高社会福利和支持分散治理方面的潜力。


<details>
  <summary>Details</summary>
Motivation: 本研究旨在利用大型语言模型（LLM）来设计和评估经济政策，特别是在具有分层决策的战略环境中，以解决经济模拟和政策评估的挑战。

Method: 本研究提出了LLM经济学框架，该框架利用基于智能体的建模来设计和评估战略环境中的经济政策，其中包含分层决策。在较低层级，有界理性工人智能体（表现为源自美国人口普查校准的收入和人口统计数据的个人条件提示）选择劳动供给以最大化在上下文中学习到的基于文本的效用函数。在上层级，规划者智能体采用上下文强化学习来提出以当前美国联邦税率为基准的 것입니다。线性边际税收计划。

Result: 实验表明，该框架能够支持异质性效用优化、生成大规模、人口统计学上真实的智能体群体，并以自然语言进行机制设计。实验结果显示，规划者智能体接近斯塔克尔伯格均衡，相比Saez解决方案提高了总社会福利，而周期性的、个人层面的投票程序在分散治理下进一步增加了这些收益。

Conclusion: LLM驱动的智能体可以共同建模、模拟和治理复杂的经济系统，为大规模的政策评估提供了一个可行的试验台，有助于建立更美好的文明。

Abstract: We present the LLM Economist, a novel framework that uses agent-based
modeling to design and assess economic policies in strategic environments with
hierarchical decision-making. At the lower level, bounded rational worker
agents -- instantiated as persona-conditioned prompts sampled from U.S.
Census-calibrated income and demographic statistics -- choose labor supply to
maximize text-based utility functions learned in-context. At the upper level, a
planner agent employs in-context reinforcement learning to propose
piecewise-linear marginal tax schedules anchored to the current U.S. federal
brackets. This construction endows economic simulacra with three capabilities
requisite for credible fiscal experimentation: (i) optimization of
heterogeneous utilities, (ii) principled generation of large, demographically
realistic agent populations, and (iii) mechanism design -- the ultimate nudging
problem -- expressed entirely in natural language. Experiments with populations
of up to one hundred interacting agents show that the planner converges near
Stackelberg equilibria that improve aggregate social welfare relative to Saez
solutions, while a periodic, persona-level voting procedure furthers these
gains under decentralized governance. These results demonstrate that large
language model-based agents can jointly model, simulate, and govern complex
economic systems, providing a tractable test bed for policy evaluation at the
societal scale to help build better civilizations.

</details>


<div id='cs.GR'></div>

# cs.GR [[Back]](#toc)

### [663] [Real-Time Scene Reconstruction using Light Field Probes](https://arxiv.org/abs/2507.14624)
*Yaru Liu,Derek Nowrouzezahri,Morgan Mcguire*

Main category: cs.GR

TL;DR: 一种新的神经渲染技术，使用“探针数据”来高效重建大型复杂场景，无需场景几何，渲染速度快，适合VR/AR应用。


<details>
  <summary>Details</summary>
Motivation: 现有神经渲染方法难以高效渲染复杂的、大规模的场景，因为它们需要在场景大小、保真度和渲染速度之间进行权衡。而基于场景几何的方法则需要构建和维护庞大的几何数据，成本高昂。

Method: 该方法利用探针数据结构来重建场景，该数据结构包含密集数据点的精确深度信息。通过这种方式，避免了对场景几何的依赖，降低了计算成本，并实现了与场景复杂度无关的渲染成本。

Result: 该方法能够高效地重建复杂的大型场景，并将渲染成本与场景复杂性分离开来。此外，在渲染大型场景时，探针数据的压缩和流式传输比使用显式场景几何更有效，这使得该方法有潜力应用于虚拟现实（VR）和增强现实（AR）领域。

Conclusion: 这项工作提出了一种新的神经渲染方法，该方法使用探针数据结构来高效地重建复杂的大型场景，而无需显式使用场景几何。该方法通过使用探针数据，将渲染成本与场景复杂度分离开来，并实现了比现有方法更优的性能。

Abstract: Reconstructing photo-realistic large-scale scenes from images, for example at
city scale, is a long-standing problem in computer graphics. Neural rendering
is an emerging technique that enables photo-realistic image synthesis from
previously unobserved viewpoints; however, state-of-the-art neural rendering
methods have difficulty efficiently rendering a high complex large-scale scene
because these methods typically trade scene size, fidelity, and rendering speed
for quality. The other stream of techniques utilizes scene geometries for
reconstruction. But the cost of building and maintaining a large set of
geometry data increases as scene size grows. Our work explores novel view
synthesis methods that efficiently reconstruct complex scenes without explicit
use of scene geometries. Specifically, given sparse images of the scene
(captured from the real world), we reconstruct intermediate, multi-scale,
implicit representations of scene geometries. In this way, our method avoids
explicitly relying on scene geometry, significantly reducing the computational
cost of maintaining large 3D data. Unlike current methods, we reconstruct the
scene using a probe data structure. Probe data hold highly accurate depth
information of dense data points, enabling the reconstruction of highly complex
scenes. By reconstructing the scene using probe data, the rendering cost is
independent of the complexity of the scene. As such, our approach combines
geometry reconstruction and novel view synthesis. Moreover, when rendering
large-scale scenes, compressing and streaming probe data is more efficient than
using explicit scene geometry. Therefore, our neural representation approach
can potentially be applied to virtual reality (VR) and augmented reality (AR)
applications.

</details>


### [664] [Towards Geometric and Textural Consistency 3D Scene Generation via Single Image-guided Model Generation and Layout Optimization](https://arxiv.org/abs/2507.14841)
*Xiang Tang,Ruotong Li,Xiaopeng Fan*

Main category: cs.GR

TL;DR: 从单张RGB图像生成高质量、连贯的多物体3D场景，通过实例分割、修复、伪立体匹配和Chamfer距离优化布局。


<details>
  <summary>Details</summary>
Motivation: 现有方法在从单个RGB图像生成3D场景时，难以保证物体生成质量和场景连贯性，尤其是在多物体场景中。

Method: 我们提出了一种新颖的三阶段框架，包括图像实例分割和修复、伪立体视图构建和模型选择，以及通过 Chamfer 距离最小化进行布局优化。

Result: 我们的方法在几何准确性和纹理保真度方面优于最先进的方法，并在场景布局合成方面具有显着优势。

Conclusion: 我们的方法通过显式的几何表示和高质量的纹理细节，在生成单个3D模型和场景布局方面均优于现有方法。

Abstract: In recent years, 3D generation has made great strides in both academia and
industry. However, generating 3D scenes from a single RGB image remains a
significant challenge, as current approaches often struggle to ensure both
object generation quality and scene coherence in multi-object scenarios. To
overcome these limitations, we propose a novel three-stage framework for 3D
scene generation with explicit geometric representations and high-quality
textural details via single image-guided model generation and spatial layout
optimization. Our method begins with an image instance segmentation and
inpainting phase, which recovers missing details of occluded objects in the
input images, thereby achieving complete generation of foreground 3D assets.
Subsequently, our approach captures the spatial geometry of reference image by
constructing pseudo-stereo viewpoint for camera parameter estimation and scene
depth inference, while employing a model selection strategy to ensure optimal
alignment between the 3D assets generated in the previous step and the input.
Finally, through model parameterization and minimization of the Chamfer
distance between point clouds in 3D and 2D space, our approach optimizes layout
parameters to produce an explicit 3D scene representation that maintains
precise alignment with input guidance image. Extensive experiments on
multi-object scene image sets have demonstrated that our approach not only
outperforms state-of-the-art methods in terms of geometric accuracy and texture
fidelity of individual generated 3D models, but also has significant advantages
in scene layout synthesis.

</details>


### [665] [Time Series Information Visualization -- A Review of Approaches and Tools](https://arxiv.org/abs/2507.14920)
*Evandro S. Ortigossa,Fábio F. Dias,Diego C. Nascimento,Luis Gustavo Nonato*

Main category: cs.GR

TL;DR: 时间序列数据分析复杂，信息可视化是关键。本论文综述了多变量时间序列可视化的技术和方法，提供了设计指南，并指出了未来研究方向。


<details>
  <summary>Details</summary>
Motivation: 本篇论文的动机在于，时间序列数据在各个领域都非常普遍，但其分析过程复杂，需要先进的工具。信息可视化作为一种利用人类感知能力将数据转化为视觉表示的通信渠道，在增强时间序列数据可解释性方面发挥着关键作用。因此，本研究旨在探讨和总结用于处理时间序列数据的方法，并为开发相关可视化系统提供指导。

Method: 本篇论文的分析方法是审查现有的信息可视化技术和方法，重点关注多变量时间序列数据。通过梳理这些技术和方法，为开发更全面的可视化系统提供理论见解和设计指南。

Result: 本篇论文的结果是，它审查了处理时间序列数据的技术和方法，为用户提供了基于视觉分析的知识发现过程。此外，它还为开发多变量时间序列数据可视化方法提供了理论见解和设计指南，并指出了该领域面临的挑战和未来的研究方向。

Conclusion: 本篇论文的结论是，信息可视化技术在处理多变量时间序列数据方面具有巨大潜力，可以帮助数据科学家理解动态行为、发现周期性模式和趋势。然而，仍存在一些挑战，需要进一步的研究来解决时间依赖性数据的可视化问题。

Abstract: Time series data are prevalent across various domains and often encompass
large datasets containing multiple time-dependent features in each sample.
Exploring time-varying data is critical for data science practitioners aiming
to understand dynamic behaviors and discover periodic patterns and trends.
However, the analysis of such data often requires sophisticated procedures and
tools. Information visualization is a communication channel that leverages
human perceptual abilities to transform abstract data into visual
representations. Visualization techniques have been successfully applied in the
context of time series to enhance interpretability by graphically representing
the temporal evolution of data. The challenge for information visualization
developers lies in integrating a wide range of analytical tools into rich
visualization systems that can summarize complex datasets while clearly
describing the impacts of the temporal component. Such systems enable data
scientists to turn raw data into understandable and potentially useful
knowledge. This review examines techniques and approaches designed for handling
time series data, guiding users through knowledge discovery processes based on
visual analysis. We also provide readers with theoretical insights and design
guidelines for considering when developing comprehensive information
visualization approaches for time series, with a particular focus on time
series with multiple features. As a result, we highlight the challenges and
future research directions to address open questions in the visualization of
time-dependent data.

</details>


### [666] [Model Simplification through refinement](https://arxiv.org/abs/2507.15186)
*Dmitry Brodsky,Benjamin Watson*

Main category: cs.GR

TL;DR: 为解决现有简化算法速度慢或质量差的问题，提出一种新的简化算法。该算法从粗到精，利用曲面曲率进行优化，速度快且效果好。


<details>
  <summary>Details</summary>
Motivation: 随着建模和可视化应用的激增，需要有能够以交互速率简化大型多边形模型的方法。然而，现有的多边形网格简化算法要么太慢（需要预先计算简化模型），要么生成的模型质量太差，无法满足这一需求，尤其是在处理极大型模型时。

Method: 该算法从向量量化算法中汲取灵感，通过反向操作，从一个非常粗糙的近似模型开始，并逐步对其进行细化。曲面曲率被用来指导简化过程。先前生成的简化模型可以作为该算法的输入，以进一步优化。

Result: 该算法不仅速度快，能在设定的时间内生成可显示的简化模型，而且结果的质量也很好。此外，先前生成的简化模型可以作为输入，进行进一步的优化。

Conclusion: 该算法能够快速地简化大型模型，并保证在给定的时间内得到可显示的、高质量的结果。

Abstract: As modeling and visualization applications proliferate, there arises a need
to simplify large polygonal models at interactive rates. Unfortunately existing
polygon mesh simplification algorithms are not well suited for this task
because they are either too slow (requiring the simplified model to be
pre-computed) or produce models that are too poor in quality. These
shortcomings become particularly acute when models are extremely large. We
present an algorithm suitable for simplification of large models at interactive
speeds. The algorithm is fast and can guarantee displayable results within a
given time limit. Results also have good quality. Inspired by splitting
algorithms from vector quantization literature, we simplify models in reverse,
beginning with an extremely coarse approximation and refining it.
Approximations of surface curvature guide the simplification process.
Previously produced simplifications can be further refined by using them as
input to the algorithm.

</details>


### [667] [Blended Point Cloud Diffusion for Localized Text-guided Shape Editing](https://arxiv.org/abs/2507.15399)
*Etai Sella,Noam Atia,Ron Mokady,Hadar Averbuch-Elor*

Main category: cs.GR

TL;DR: 一种新的3D形状编辑框架，通过结合3D扩散模型和坐标混合算法，实现精确的局部编辑，同时保持全局一致性。


<details>
  <summary>Details</summary>
Motivation: 为了实现对3D形状进行直观的、局部细粒度的编辑，同时克服现有方法在局部修改时保持全局一致性方面存在的挑战。

Method: 利用基于修复的框架，结合3D扩散模型和结构引导（如部分条件形状），并在推理时采用坐标混合算法，以实现局部编辑和身份保持。

Result: 实验结果表明，本方法在评估原始形状保真度和遵循文本描述方面，优于其他技术。

Conclusion: 本方法通过融合原始形状和编辑后的形状，在不同噪声水平下进行推理，实现了对3D形状的细粒度编辑，并保持了原始形状的完整性，同时满足文本描述的要求。

Abstract: Natural language offers a highly intuitive interface for enabling localized
fine-grained edits of 3D shapes. However, prior works face challenges in
preserving global coherence while locally modifying the input 3D shape. In this
work, we introduce an inpainting-based framework for editing shapes represented
as point clouds. Our approach leverages foundation 3D diffusion models for
achieving localized shape edits, adding structural guidance in the form of a
partial conditional shape, ensuring that other regions correctly preserve the
shape's identity. Furthermore, to encourage identity preservation also within
the local edited region, we propose an inference-time coordinate blending
algorithm which balances reconstruction of the full shape with inpainting at a
progression of noise levels during the inference process. Our coordinate
blending algorithm seamlessly blends the original shape with its edited
version, enabling a fine-grained editing of 3D shapes, all while circumventing
the need for computationally expensive and often inaccurate inversion.
Extensive experiments show that our method outperforms alternative techniques
across a wide range of metrics that evaluate both fidelity to the original
shape and also adherence to the textual description.

</details>


### [668] [ObjectGS: Object-aware Scene Reconstruction and Scene Understanding via Gaussian Splatting](https://arxiv.org/abs/2507.15454)
*Ruijie Zhu,Mulin Yu,Linning Xu,Lihan Jiang,Yixuan Li,Tianzhu Zhang,Jiangmiao Pang,Bo Dai*

Main category: cs.GR

TL;DR: 提出ObjectGS框架，实现了3D场景重建与语义理解的统一，能够进行精确的对象级重建，并在分割任务上表现出色。


<details>
  <summary>Details</summary>
Motivation: 为了解决3D高斯泼溅法（3D Gaussian Splatting）虽然以高保真度和实时新视角合成而闻名，但其缺乏语义理解限制了对象级感知的局限性。

Method: ObjectGS是一个将3D场景重建与语义理解相结合的框架，通过将场景中的对象建模为局部锚点来生成神经高斯并共享对象ID，从而实现精确的对象级重建。在训练过程中，动态地生长或修剪这些锚点并优化它们的特征，同时使用独热ID编码和分类损失来强制执行清晰的语义约束。

Result: ObjectGS实现了精确的对象级重建，并在开放词汇和全景分割任务上取得了领先于当前最先进方法的性能，同时还能与网格提取和场景编辑等应用良好集成。

Conclusion: ObjectGS在开放词汇和全景分割任务上超越了最先进的方法，并能与网格提取和场景编辑等应用无缝集成。

Abstract: 3D Gaussian Splatting is renowned for its high-fidelity reconstructions and
real-time novel view synthesis, yet its lack of semantic understanding limits
object-level perception. In this work, we propose ObjectGS, an object-aware
framework that unifies 3D scene reconstruction with semantic understanding.
Instead of treating the scene as a unified whole, ObjectGS models individual
objects as local anchors that generate neural Gaussians and share object IDs,
enabling precise object-level reconstruction. During training, we dynamically
grow or prune these anchors and optimize their features, while a one-hot ID
encoding with a classification loss enforces clear semantic constraints. We
show through extensive experiments that ObjectGS not only outperforms
state-of-the-art methods on open-vocabulary and panoptic segmentation tasks,
but also integrates seamlessly with applications like mesh extraction and scene
editing. Project page: https://ruijiezhu94.github.io/ObjectGS_page

</details>


### [669] [Gaussian Splatting with Discretized SDF for Relightable Assets](https://arxiv.org/abs/2507.15629)
*Zuo-Liang Zhu,Jian Yang,Beibei Wang*

Main category: cs.GR

TL;DR: 本文提出了一种离散化SDF方法，通过在高斯函数中编码SDF采样值，实现了高效渲染和几何约束，提高了逆渲染质量，且不增加内存负担。


<details>
  <summary>Details</summary>
Motivation: 现有的3DGS方法在逆渲染任务中面临挑战，主要是因为高斯函数的离散性使得应用几何约束变得困难。虽然引入SDF可以作为连续表示来正则化高斯函数定义的几何，但这会增加内存使用并使训练复杂化。因此，需要一种在不增加额外开销的情况下提高几何约束能力的方法。

Method: 本文提出了一种离散化SDF表示方法，通过在每个高斯函数中编码采样值来离散地表示连续SDF。将SDF与高斯函数的透明度关联起来，实现了通过splatting渲染SDF，避免了光线步进的计算成本。通过将高斯函数投影到SDF的零水平集上，并强制其与splatting产生的表面对齐，提出了一种基于投影的一致性损失来约束离散样本与潜在SDF的一致性。

Result: 该方法实现了更高的 relighting 质量，同时不需要比GS额外增加内存，并且避免了复杂的手动设计优化。实验结果表明，该方法优于现有的基于高斯函数的逆渲染方法。

Conclusion: 所提出的离散化SDF方法在不增加额外内存占用的情况下，实现了比现有基于高斯函数的逆渲染方法更高的 relighting 质量，并且避免了复杂的手动设计优化，实验结果也优于现有方法。

Abstract: 3D Gaussian splatting (3DGS) has shown its detailed expressive ability and
highly efficient rendering speed in the novel view synthesis (NVS) task. The
application to inverse rendering still faces several challenges, as the
discrete nature of Gaussian primitives makes it difficult to apply geometry
constraints. Recent works introduce the signed distance field (SDF) as an extra
continuous representation to regularize the geometry defined by Gaussian
primitives. It improves the decomposition quality, at the cost of increasing
memory usage and complicating training. Unlike these works, we introduce a
discretized SDF to represent the continuous SDF in a discrete manner by
encoding it within each Gaussian using a sampled value. This approach allows us
to link the SDF with the Gaussian opacity through an SDF-to-opacity
transformation, enabling rendering the SDF via splatting and avoiding the
computational cost of ray marching.The key challenge is to regularize the
discrete samples to be consistent with the underlying SDF, as the discrete
representation can hardly apply the gradient-based constraints (\eg Eikonal
loss). For this, we project Gaussians onto the zero-level set of SDF and
enforce alignment with the surface from splatting, namely a projection-based
consistency loss. Thanks to the discretized SDF, our method achieves higher
relighting quality, while requiring no extra memory beyond GS and avoiding
complex manually designed optimization. The experiments reveal that our method
outperforms existing Gaussian-based inverse rendering methods. Our code is
available at https://github.com/NK-CS-ZZL/DiscretizedSDF.

</details>


<div id='eess.SY'></div>

# eess.SY [[Back]](#toc)

### [670] [Distributed consensus-based observer design for target state estimation with bearing measurements](https://arxiv.org/abs/2507.14300)
*Marcelo Jacinto,Pedro Trindade,Francisco Rego,Rita Cunha*

Main category: eess.SY

TL;DR: 本文提出了一种创新的分布式共识观测器，用于多智能体目标跟踪。该方法通过局部通信和测量，实现了对任意积分器链模型目标的估计，并保证了稳定性。实验结果验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 本文旨在解决分布式目标跟踪问题，其中一组智能体需要通过它们的局部测量和通信来共同估计一个移动目标的状态。关键挑战在于如何在存在通信延迟、传感器噪声以及智能体之间有限通信带宽的情况下，实现精确且鲁棒的目标跟踪。具体来说，研究的目标是设计一种观测器，使得每个智能体能够仅通过与其邻居的通信，并测量相对于目标的方向向量，来估计目标的运动状态，而无需全局信息。

Method: 本文提出了一种新颖的分布式共识基于的观测器设计。该设计首先针对状态动力学被建模为积分器链且测量模型具有特定非线性但适合观测器形式的系统，引入了一个通用的连续时间观测器设计。该设计利用了一个结合了创新和共识组件的校正项，允许每个智能体仅向其邻居广播一部分状态估计，从而有效减少了网络中的数据流。为了提供均匀的指数稳定性保证，研究引入了一个适用于广义观测器形式的一类非线性闭环系统的新型结果，并以此作为推导观测器增益稳定性条件的主要工具。随后，通过利用正交投影矩阵的性质，该设计被应用于解决分布式目标跟踪问题，并给出了取决于目标-智能体几何构型的显式稳定性条件。最后，通过数值结果展示了所提出算法的特性。

Result: 该研究提出了一个新颖的分布式共识基于的观测器设计，可用于解决多智能体系统中的目标跟踪问题。该设计通过利用局部测量和通信，实现了对任意阶积分器链模型的目标的估计。研究推导了稳定性条件，并证明了该设计在不同阶数的积分器模型下均能实现均匀指数稳定性。通过数值模拟展示了该算法在目标跟踪任务中的有效性，并验证了其在不同几何构型下的性能。

Conclusion: 该研究提出了一个新颖的分布式共识基于的观测器设计，用于解决目标跟踪问题。该设计允许通信网络中的一组智能体跟踪由任意阶积分器链建模的目标。每个智能体仅需广播其状态估计的一部分，有效减少了网络数据流。通过引入一个针对特定非线性但适合观测器的系统的新型连续时间观测器设计，并利用其创新和共识组件的结合，实现了这一目标。研究还引入了一个新的非线性闭环系统结果，以保证指数稳定性，并推导了观测器增益的稳定性条件。通过利用正交投影矩阵的性质，该设计被应用于分布式目标跟踪问题，并给出了明确的稳定性条件，这些条件依赖于目标-智能体的几何构型。研究中还推导了目标模型为一阶、二阶和三阶积分器动力学的具体实例，并展示了设计过程和施加的稳定性条件。最后的数值结果证明了所提出算法的有效性。

Abstract: This paper introduces a novel distributed consensus-based observer design
that enables a group of agents in an undirected communication network to solve
the problem of target tracking, where the target is modeled as a chain of
integrators of arbitrary order. Each agent is assumed to know its own position
and simultaneously measure bearing vectors relative to the target. We start by
introducing a general continuous time observer design tailored to systems whose
state dynamics are modeled as chains of integrators and whose measurement model
follows a particular nonlinear but observer-suited form. This design leverages
a correction term that combines innovation and consensus components, allowing
each agent to broadcast only a part of the state estimate to its neighbours,
which effectively reduces the data flowing across the network. To provide
uniform exponential stability guarantees, a novel result for a class of
nonlinear closed-loop systems in a generalized observer form is introduced and
subsequently used as the main tool to derive stability conditions on the
observer gains. Then, by exploring the properties of orthogonal projection
matrices, the proposed design is used to solve the distributed target tracking
problem and provide explicit stability conditions that depend on the
target-agents geometric formation. Practical examples are derived for a target
modeled as first-, second-, and third-order integrator dynamics, highlighting
the design procedure and the stability conditions imposed. Finally, numerical
results showcase the properties of the proposed algorithm.

</details>


### [671] [Remote Assistance or Remote Driving: The Impact of Operational Design Domains on ADS-Supporting Systems Selection](https://arxiv.org/abs/2507.14347)
*Ole Hans,Benedikt Walter*

Main category: eess.SY

TL;DR: 该论文提出了一种新的方法来选择自动驾驶系统的远程支持系统，重点是运行设计域（ODD）和用例，而不是仅仅关注技术方面。


<details>
  <summary>Details</summary>
Motivation: 当前行业在选择远程驾驶系统（RDS）或远程协助系统（RAS）作为自动驾驶系统（ADS）的支持系统时，往往侧重于系统架构、设计和集成挑战，而忽略了用例以及ADS和远程支持系统在运行设计域（ODD）中的互补性。为了解决这一问题，需要一种新的选择方法。

Method: 通过应用PEGASUS框架来系统地描述和分析ODD，并引入了一个结构化框架来评估和选择最适合ADS的远程支持系统，该选择基于清晰定义的标准。

Result: 该论文提出了一种结构化方法，用于根据定义的ODD和用例分析来选择RDS或RAS作为ADS的支持系统。

Conclusion: 该论文提出了一种基于ODD和用例分析的结构化方法，用于在RDS和RAS之间进行选择，以作为ADS的支持系统。

Abstract: High level Automated Driving Systems (ADS) can handle many situations, but
they still encounter situations where human intervention is required. In
systems where a physical driver is present in the vehicle, typically SAE Level
3 systems, this intervention is relatively straightforward and is handled by
the in-vehicle driver. However, the complexity increases for Level 4 systems,
where, in most cases, no physical driver remains in the vehicle. The two common
industry solutions for this challenge are the integration of a remote support
system, such as a Remote Driving System (RDS) or Remote Assistance System
(RAS). While it is clear that ADS will require one of these systems, it is less
clear how the suitability of either system for a particular ADS application
should be evaluated. Currently, the selection process often focuses on system
architecture as well as its design and integration challenges. Furthermore,
since many ADS developers choose to develop remote system solutions in-house,
it is advantageous to select the simpler approach to streamline development and
integration efforts. While these decision points are certainly relevant, this
approach overlooks the most critical factors: the use cases and the
complementarity of the ADS and the remote support system within the context of
the Operational Design Design Domain (ODD). This paper proposes a structured
approach for selecting between RDS and RAS as an ADS support system, based on
the defined ODD and use case analysis. To achieve this, the paper applies the
PEGASUS framework to systematically describe and analyze the ODD. A structured
framework is introduced to evaluate and select the most suitable remote support
system for an ADS based on clearly defined criteria.

</details>


### [672] [Bi-level Model Predictive Control for Energy-aware Integrated Product Pricing and Production Scheduling](https://arxiv.org/abs/2507.14385)
*Hongliang Li,Herschel C. Pangborn,Ilya Kovalenko*

Main category: eess.SY

TL;DR: 一种双层模型预测控制框架，可以优化价格和生产计划，以适应可再生能源和实时电价，从而降低制造成本并增加利润。


<details>
  <summary>Details</summary>
Motivation: 制造业需要在保持经济竞争力的同时提高可持续性，制造商需要确定如何在不损害盈利能力的情况下将现场可再生能源和实时电价纳入制造计划。

Method: 提出了一种双层模型预测控制框架，该框架在明确考虑可再生能源可用性的情况下，联合优化产品价格和生产调度。

Result: 通过锂离子电池组制造系统案例研究表明，该方法能够帮助制造商降低电网能源成本并增加利润。

Conclusion: 该方法能够帮助制造商降低电网能源成本并增加利润。

Abstract: The manufacturing industry is under growing pressure to enhance
sustainability while preserving economic competitiveness. As a result,
manufacturers have been trying to determine how to integrate onsite renewable
energy and real-time electricity pricing into manufacturing schedules without
compromising profitability. To address this challenge, we propose a bi-level
model predictive control framework that jointly optimizes product prices and
production scheduling with explicit consideration of renewable energy
availability. The higher level determines the product price to maximize revenue
and renewable energy usage. The lower level controls production scheduling in
runtime to minimize operational costs and respond to the product demand. Price
elasticity is incorporated to model market response, allowing the system to
increase demand by lowering the product price during high renewable energy
generation. Results from a lithium-ion battery pack manufacturing system case
study demonstrate that our approach enables manufacturers to reduce grid energy
costs while increasing profit.

</details>


### [673] [Collaborative Indirect Influencing and Control on Graphs using Graph Neural Networks](https://arxiv.org/abs/2507.14409)
*Max L. Gardenswartz,Brandon C. Fallin,Cristian F. Nino,Warren E. Dixon*

Main category: eess.SY

TL;DR: This paper introduces a new GNN-based control method to manage systems where multiple nodes influence a central target node with unknown behavior, ensuring stability and successful trajectory tracking.


<details>
  <summary>Details</summary>
Motivation: To address the indirect influence problem in networked systems where cooperative nodes need to regulate a target node with uncertain dynamics to follow a desired trajectory.

Method: The paper uses a graph neural network (GNN) with a message-passing structure to learn unknown target dynamics in real time. A GNN-based backstepping control strategy is developed, with stability guarantees based on Lyapunov analysis.

Result: The developed controller, based on a GNN-backstepping strategy, shows effective performance in simulations for regulating a target node with uncertain dynamics.

Conclusion: The paper presents a novel GNN-based backstepping control strategy for indirect influence problems in networked systems, demonstrating its effectiveness through numerical simulations and providing formal stability guarantees.

Abstract: This paper presents a novel approach to solving the indirect influence
problem in networked systems, in which cooperative nodes must regulate a target
node with uncertain dynamics to follow a desired trajectory. We leverage the
message-passing structure of a graph neural network (GNN), allowing nodes to
collectively learn the unknown target dynamics in real time. We develop a novel
GNN-based backstepping control strategy with formal stability guarantees
derived from a Lyapunov-based analysis. Numerical simulations are included to
demonstrate the performance of the developed controller.

</details>


### [674] [A Black Start Strategy for Hydrogen-integrated Renewable Grids with Energy Storage Systems](https://arxiv.org/abs/2507.14450)
*Jin Lu,Linhan Fang,Fan Jiang,Xingpeng Li*

Main category: eess.SY

TL;DR: 本研究提出了结合燃料电池和电池储能的新型现代电力系统黑启动模型，并进行了仿真和敏感性分析，以优化黑启动操作。


<details>
  <summary>Details</summary>
Motivation: 随着可再生能源的整合，电力系统的可靠性和恢复能力至关重要，大规模停电仍然是一个重大威胁，需要有效的恢复策略。

Method: 本研究提出新型黑启动模型，考虑燃料电池和电池储能的特性，并进行仿真和敏感性分析。

Result: 仿真结果比较了燃料电池和电池储能系统的发电机启动顺序，并进行了敏感性分析，以确定最佳的黑启动运行场景。

Conclusion: 本研究提出了结合燃料电池和电池储能的新型现代电力系统黑启动模型，并对IEEE 39节点系统进行了仿真和敏感性分析，以优化黑启动操作。

Abstract: With the increasing integration of renewable energy, the reliability and
resilience of modern power systems are of vital significance. However,
large-scale blackouts caused by natural disasters or equipment failures remain
a significant threat, necessitating effective restoration strategies. This
study proposes novel black start models for modern power systems that integrate
fuel cells and battery storage, recognizing their distinct characteristics and
contributions to grid resilience. These models specifically address the
restoration of electrical grids, including the energization paths and time of
the transmission network, while accounting for the unique power output traits
of fuel cells and the energy storage capacity of batteries as black start
resources. Black start simulations, comparing the generator startup sequence
(GSUS) with fuel cell versus battery systems, are performed on the IEEE 39-bus
system. We conduct sensitivity analyses on fuel cell capacity, battery storage
capacity, initial state of charge (SOC), and resource locations to identify
optimal scenarios for black start operations.

</details>


### [675] [Learning-Augmented Control: Adaptively Confidence Learning for Competitive MPC](https://arxiv.org/abs/2507.14595)
*Tongxin Li*

Main category: eess.SY

TL;DR: LAC是一种将不可信的机器学习预测整合到受约束的非线性动力学系统控制中的方法，旨在提供最佳性能和鲁棒性，并通过延迟置信学习实现自适应平衡。


<details>
  <summary>Details</summary>
Motivation: LAC旨在为受约束的非线性动力学系统的控制整合不可信的机器学习预测，以实现“两全其美”的保证，即在预测准确时获得近乎最优的性能，在预测不准确时获得鲁棒、安全的性能。

Method: LAC采用延迟置信学习程序，在线优化置信参数，自适应地平衡机器学习和标称预测。我们为具有标准MPC正则性假设的一般非线性系统建立了正式的竞争比界限。对于线性二次情况，我们推导了一个可证明的紧凑竞争比界限，从而表征了这个学习增强方法的基本极限。

Result: LAC能够实现近乎最优的性能，当预测准确时，以及鲁棒、安全的性能，当预测不准确时。在具有标准MPC正则性假设的一般非线性系统下，LAC具有正式的竞争比界限。对于线性二次情况，LAC具有可证明的紧凑竞争比界限，这表征了该方法的根本限制。

Conclusion: LAC在数值研究中被证明是有效的，它在对抗性预测错误下保持了稳定性并优于标准方法。

Abstract: We introduce Learning-Augmented Control (LAC), an approach that integrates
untrusted machine learning predictions into the control of constrained,
nonlinear dynamical systems. LAC is designed to achieve the
"best-of-both-worlds" guarantees, i.e, near-optimal performance when
predictions are accurate, and robust, safe performance when they are not. The
core of our approach is a delayed confidence learning procedure that optimizes
a confidence parameter online, adaptively balancing between ML and nominal
predictions. We establish formal competitive ratio bounds for general nonlinear
systems under standard MPC regularity assumptions. For the linear quadratic
case, we derive a competitive ratio bound that is provably tight, thereby
characterizing the fundamental limits of this learning-augmented approach. The
effectiveness of LAC is demonstrated in numerical studies, where it maintains
stability and outperforms standard methods under adversarial prediction errors.

</details>


### [676] [One-Time Programmable Passive Electromagnetic Skins](https://arxiv.org/abs/2507.14601)
*Giacomo Oliveri,Francesco Zardi,Aaron Angel Salas Sancez,Andrea Massa*

Main category: eess.SY

TL;DR: A new type of electromagnetic skin (OTP-EMS) is proposed for smart environments. It's cheap, modular, configurable, and requires no maintenance. The paper shows how it works with various examples.


<details>
  <summary>Details</summary>
Motivation: The motivation is to develop simple, inexpensive, and mass-production-oriented solutions for smart electromagnetic environments (SEMEs).

Method: The paper introduces "one-time programmable" electromagnetic skins (OTP-EMSs) by integrating expendable components at the atomic level. An OTP meta-atom structure is defined and optimized to create EMSs with scenario-dependent EM wave manipulation functionalities.

Result: The paper reports a representative set of analytical, numerical, and experimental results for different apertures, illuminations, and EM wave manipulation requirements to illustrate the features and potentialities of OTP-EMSs.

Conclusion: OTP-EMSs are demonstrated to be a viable solution for smart electromagnetic environments, offering configurable reflection properties, passive operation, and zero maintenance.

Abstract: The implementation of simple, inexpensive, and mass-production-oriented
solutions for smart electromagnetic environments (SEMEs) is dealt with by
introducing the concept of "one-time programmable" electromagnetic skins
(OTP-EMSs). The simultaneous achievement of modular fabrication, (one-time)
configurable reflection properties, passive-static operation, and zero
maintenance is yielded by integrating expendable components at the atomic level
of EMSs. Towards this end, an OTP meta-atom structure is properly defined and
optimized to build EMSs featuring the desired scenario-dependent EM wave
manipulation functionalities. In order to illustrate the features as well as to
point out the potentialities of OTP-EMSs, a representative set of analytical,
numerical, and experimental results is reported by considering different
apertures, illuminations, and EM wave manipulation requirements.

</details>


### [677] [Gait Transitions in Load-Pulling Quadrupeds: Insights from Sled Dogs and a Minimal SLIP Model](https://arxiv.org/abs/2507.14727)
*Jiayu Ding,Benjamin Seleb,Saad Bhamla,Zhenyu Gan*

Main category: eess.SY

TL;DR: 雪橇犬在高速拉拽时能在几种步态间快速切换，这得益于其腿部刚度的调节。


<details>
  <summary>Details</summary>
Motivation: 为了解高速负载下适应性步态转换的生物力学机制，以草原犬鼠为模型系统。

Method: 利用高速视频和力记录，结合基于物理的四足弹簧加载倒立摆模型（具有混合动力学和规定的落脚点序列），通过轨迹优化来研究雪橇犬的生物力学。

Result: 研究发现，雪橇犬在高速拉拽时常常在几步之内在旋转和横向疾驰步态之间切换，并且在速度、步幅持续时间或地形上没有明显变化，证明了运动中的多稳定性。通过轨迹优化，成功复制了实验观察到的步态序列，并将摆动腿刚度调节确定为引起步态转换的关键控制机制。

Conclusion: 本研究为高速拉拽动物提供了急需的生物力学视角，并建立了研究拉拽四足动物运动的模型框架，对生物学理解和适应性腿部系统设计都有借鉴意义。

Abstract: Quadrupedal animals employ diverse galloping strategies to optimize speed,
stability, and energy efficiency. However, the biomechanical mechanisms that
enable adaptive gait transitions during high-speed locomotion under load remain
poorly understood. In this study, we present new empirical and modeling
insights into the biomechanics of load-pulling quadrupeds, using sprint sled
dogs as a model system. High-speed video and force recordings reveal that sled
dogs often switch between rotary and transverse galloping gaits within just a
few strides and without any observable changes in speed, stride duration, or
terrain, providing clear evidence of locomotor multistability during high-speed
load-pulling. To investigate the mechanical basis of these transitions, a
physics-based quadrupedal Spring-Loaded Inverted Pendulum model with hybrid
dynamics and prescribed footfall sequences to reproduce the asymmetric
galloping patterns observed in racing sled dogs. Through trajectory
optimization, we replicate experimentally observed gait sequences and identify
swing-leg stiffness modulation as a key control mechanism for inducing
transitions. This work provides a much-needed biomechanical perspective on
high-speed animal draft and establishes a modeling framework for studying
locomotion in pulling quadrupeds, with implications for both biological
understanding and the design of adaptive legged systems.

</details>


### [678] [Enhancing Sustainability in HAPS-Assisted 6G Networks: Load Estimation Aware Cell Switching](https://arxiv.org/abs/2507.14728)
*Maryam Salamatmoghadasi,Metin Ozturk,Halim Yanikomeroglu*

Main category: eess.SY

TL;DR: 该研究通过MLC和LSTM等方法改进了异构网络中睡眠模式基站的流量负载估计，解决了传统方法的局限性。


<details>
  <summary>Details</summary>
Motivation: 解决垂直异构网络中蜂窝切换的流量负载估计挑战，特别是低睡眠模式下小型基站（SBS）缺乏准确流量数据的问题，这使得许多依赖负载的节能方法不切实际。

Method: 研究了三种空间插值方案（随机邻域选择、基于距离的选择和多层聚类（MLC））以及一种基于长短期记忆（LSTM）网络的深度学习时间方法。

Result: 空间和时间方法均显著提高了估计精度，其中MLC和LSTM方法表现出特别强的性能。

Conclusion: 该研究通过空间和时间方法改进了蜂窝切换中的流量负载估计，其中多层聚类（MLC）和长短期记忆（LSTM）网络表现出特别强的性能。

Abstract: This study introduces and addresses the critical challenge of traffic load
estimation in cell switching within vertical heterogeneous networks. The
effectiveness of cell switching is significantly limited by the lack of
accurate traffic load data for small base stations (SBSs) in sleep mode, making
many load-dependent energy-saving approaches impractical, as they assume
perfect knowledge of traffic loads, an assumption that is unrealistic when SBSs
are inactive. In other words, when SBSs are in sleep mode, their traffic loads
cannot be directly known and can only be estimated, inevitably with
corresponding errors. Rather than proposing a new switching algorithm, we focus
on eliminating this foundational barrier by exploring effective prediction
techniques. A novel vertical heterogeneous network model is considered,
integrating a high-altitude platform station (HAPS) as a super macro base
station (SMBS). We investigate both spatial and temporal load estimation
approaches, including three spatial interpolation schemes, random neighboring
selection, distance based selection, and multi level clustering (MLC),
alongside a temporal deep learning method based on long short-term memory
(LSTM) networks. Using a real world dataset for empirical validation, our
results show that both spatial and temporal methods significantly improve
estimation accuracy, with the MLC and LSTM approaches demonstrating
particularly strong performance.

</details>


### [679] [Multi Target Observability](https://arxiv.org/abs/2507.14765)
*Debadrita Banerjee,Debjani Mitra,Rajesh Dey,Mudassir Khan,Lalan Kumar*

Main category: eess.SY

TL;DR: 本文研究了多目标可观测性问题，推导了使用方位角进行可观测性的充要条件，并提出了考虑不同测量类型的多目标可观测性概念。


<details>
  <summary>Details</summary>
Motivation: 本文的主要目的是解决多目标可观测性问题，并为多目标状态估计提供独特的状态估计标准。

Method: 本文推导了使用方位角进行多目标可观测性的充要条件，并分析了模糊目标轨迹，提出了多目标可观测性的替代概念，并考虑了仅多普勒、仅方位角以及多普勒和方位角组合三种测量类型。

Result: 研究结果为提高目标可区分性、轨迹重建和整体跟踪精度提供了见解。

Conclusion: 本文研究了多目标可观测性问题，并为多目标状态估计提出了独特的状态估计标准。我们推导了使用多个高阶动力学和单一观测者使用方位角进行可观测性的充要条件。

Abstract: In this paper, we mainly focus on the problem of multi-target observability,
focusing on the unique state estimation criteria for multiple targets. We
derive the condition which is necessary as well as sufficient for observability
using bearing angles with multiple higher-order dynamics observed by a single
observer. We then establish an alternative notion of observability by analyzing
ambiguous target trajectories and deriving the condition which is NECNDSUF
(Nec. and Suff.) for multi-target observability, considering three types of
measurements: Doppler-only, bearing-only, and combined Doppler and bearing
measurements, which offers insights that can improve target distinguishability,
trajectory reconstruction, and overall tracking accuracy.

</details>


### [680] [Large Language Model as An Operator: An Experience-Driven Solution for Distribution Network Voltage Control](https://arxiv.org/abs/2507.14800)
*Xu Yang,Chenhui Lin,Haotian Liu,Qi Wang,Wenchuan Wu*

Main category: eess.SY

TL;DR: 提出了一种基于 LLM 的经验驱动电压控制方法，通过多模块协作实现策略自演化，实验证明了其有效性。


<details>
  <summary>Details</summary>
Motivation: 利用大型语言模型（LLM）先进的推理和信息分析能力，为电力系统自主生成调度策略提供了一种新的方法。

Method: 提出了一种基于 LLM 的经验驱动的电压控制解决方案，通过经验存储、经验检索、经验生成和经验修改等多个模块的协作和交互，实现 LLM 基电压控制策略的自演化。

Result: LLM 在解决电力系统调度挑战方面具有适用性。

Conclusion: 实验结果验证了所提出方法 的有效性，并突出了 LLM 在解决电力系统调度挑战方面的适用性。

Abstract: With the advanced reasoning and information analysis capabilities, large
language models (LLMs) can offer a novel approach for the autonomous generation
of dispatch strategies in power systems. This letter proposes an LLM-based
experience-driven voltage control solution for distribution networks, which
enables the self-evolution of LLM-based voltage control strategies through the
collaboration and interaction of multiple modules-specifically, experience
storage, experience retrieval, experience generation, and experience
modification. Comprehensive experimental results validate the effectiveness of
the proposed method and highlight the applicability of LLM in addressing power
system dispatch challenges.

</details>


### [681] [Grid Stability and Power Factor Dynamics in Solar Farms Integration](https://arxiv.org/abs/2507.14857)
*Hassan Osseily*

Main category: eess.SY

TL;DR: 本研究使用ETAP仿真和案例研究分析了太阳能发电波动对电网稳定性的影响，并提出了一种基于人工智能的无功功率补偿控制策略，以提高电网的可靠性。


<details>
  <summary>Details</summary>
Motivation: 本研究旨在探讨太阳能发电波动对电网稳定性的影响，并重点关注维持最优功率因数。

Method: ETAP仿真和案例研究被用于分析太阳能波动下的实时电网性能。提出了采用人工智能够控制静止无功功率补偿器（SVC）进行自适应无功功率补偿。

Result: 研究结果突出了有效的整合技术，并为提高可再生能源整合电力系统的可靠性提供了实用的解决方案。

Conclusion: 本研究为提高可再生能源整合电力系统的可靠性提供了实用的解决方案。

Abstract: This paper examines the impact of solar farm fluctuations on grid stability,
focusing on maintaining an optimal power factor. ETAP-based simulations and
case studies are used to analyze real-time grid performance under solar
variability. Reactive power control strategies and advanced inverter functions
are proposed for stabilization. Theoretical analysis and simulation results
highlight effective integration techniques. Artificial intelligence is trailed
for controlling the SVC in adaptive reactive power compensation. The study
provides practical solutions for improving reliability in renewable-integrated
power systems.

</details>


### [682] [Adversarial Destabilization Attacks to Direct Data-Driven Control](https://arxiv.org/abs/2507.14863)
*Hampei Sasahara*

Main category: eess.SY

TL;DR: 本文研究了数据驱动控制方法在对抗性攻击下的脆弱性，并提出了相应的防御策略。


<details>
  <summary>Details</summary>
Motivation: 研究直接数据驱动控制方法（特别是LQR问题）对用于控制器综合的收集数据中的对抗性扰动的脆弱性。

Method: 提出DGSM和I-DGSM方法来生成对抗性扰动，并提出基于正则化的方法和鲁棒数据驱动控制方法来防御攻击。

Result: DGSM和I-DGSM攻击的扰动幅度比随机噪声小10倍，即可破坏控制器。所提出的防御策略能有效降低攻击成功率，同时保持控制性能。

Conclusion: 本文提出的DGSM和I-DGSM方法能够生成有效的对抗性扰动，且所提出的正则化和鲁棒数据驱动控制方法能够有效防御此类攻击，同时保持控制性能。攻击的迁移性研究也凸显了保护训练数据机密性的重要性。

Abstract: This study investigates the vulnerability of direct data-driven control
methods, specifically for the linear quadratic regulator problem, to
adversarial perturbations in collected data used for controller synthesis. We
consider stealthy attacks that subtly manipulate offline-collected data to
destabilize the resulting closed-loop system while evading detection. To
generate such perturbations, we propose the Directed Gradient Sign Method
(DGSM) and its iterative variant (I-DGSM), adaptations of the fast gradient
sign method originally developed for neural networks, which align perturbations
with the gradient of the spectral radius of the closed-loop matrix to reduce
stability. A key contribution is an efficient gradient computation technique
based on implicit differentiation through the Karush-Kuhn-Tucker conditions of
the underlying semidefinite program, enabling scalable and exact gradient
evaluation without repeated optimization computations. To defend against these
attacks, we propose two defense strategies: a regularization-based approach
that enhances robustness by suppressing controller sensitivity to data
perturbations and a robust data-driven control approach that guarantees
closed-loop stability within bounded perturbation sets. Extensive numerical
experiments on benchmark systems show that adversarial perturbations with
magnitudes up to ten times smaller than random noise can destabilize
controllers trained on corrupted data and that the proposed defense strategies
effectively mitigate attack success rates while maintaining control
performance. Additionally, we evaluate attack transferability under partial
knowledge scenarios, highlighting the practical importance of protecting
training data confidentiality.

</details>


### [683] [An approach to the LQG/LTR design problem with specifications for finite-dimensional SISO control systems](https://arxiv.org/abs/2507.14952)
*Mahyar Mahinzaeim,Kamyar Mehran*

Main category: eess.SY

TL;DR: 本文介绍了一种用于 SISO 控制系统的 LQG/LTR 设计方法，该方法通过加权增强来满足低频和高频设计规范，并以直流电机转矩控制为例进行说明。


<details>
  <summary>Details</summary>
Motivation: 本文旨在为非专业人士，特别是有限维 LQG 理论的从业者，介绍一种用于实际情况中 SISO 控制系统的闭环性能和鲁棒性整形反馈补偿器设计的方法。

Method: 本文讨论了一种基于加权增强的 LQG/LTR 设计方法，用于有限维 SISO 控制系统。

Result: 该方法通过加权增强将设计规范纳入 LQG 补偿器设计的 LTR 技术框架，以满足所需的灵敏度和控制器噪声灵敏度函数的低频和高频设计规范。

Conclusion: 该方法通过加权增强将设计规范纳入 LQG 补偿器设计的 LTR 技术框架，以满足所需的灵敏度和控制器噪声灵敏度函数的低频和高频设计规范。

Abstract: This is an expository paper which discusses an approach to the LQG/LTR design
problem for finite-dimensional SISO control systems. The approach is based on
the utilisation of weighting augmentation for incorporating design
specifications into the framework of the LTR technique for LQG compensator
design. The LQG compensator is to simultaneously meet given analytical low- and
high-frequency design specifications expressed in terms of desirable
sensitivity and controller noise sensitivity functions. The paper is aimed at
nonspecialists and, in particular, practitioners in finite-dimensional LQG
theory interested in the design of feedback compensators for closed-loop
performance and robustness shaping of SISO control systems in realistic
situations. The proposed approach is illustrated by a detailed numerical
example: the torque control of a current-controlled DC motor with an
elastically mounted rotor.

</details>


### [684] [Safety Controller Synthesis for Stochastic Networked Systems under Communication Constraints](https://arxiv.org/abs/2507.15031)
*Omid Akbarzadeh,Mohammad H. Mamduhi,Abolfazl Lavaei*

Main category: eess.SY

TL;DR: 本研究提出了一种利用控制障碍证书（CBCs）为存在时延和丢包的通信系统的离散时间随机线性控制系统（dt-SLS）合成安全控制器的方法，并在RLC电路上进行了验证。


<details>
  <summary>Details</summary>
Motivation: 为在通信不完善（包括时延和丢包）的情况下运行的离散时间随机线性控制系统（dt-SLS）开发安全控制器。

Method: 提出了一种包含时延和丢包的增强离散时间随机线性系统（dt-ASLS）模型，并利用其控制障碍证书（CBCs）来合成控制器，将安全约束转化为矩阵不等式，最终求解一个优化问题。

Result: 该方法将安全约束转化为矩阵不等式，最终求解一个优化问题，量化了在通信不完善的情况下满足安全规范的概率，并在RLC电路上进行了验证。

Conclusion: 该框架通过控制障碍证书（CBCs）为离散时间随机线性控制系统（dt-SLS）合成控制器，在通信不完善的情况下保证了系统的安全性，并量化了满足安全规范的概率。

Abstract: This paper develops a framework for synthesizing safety controllers for
discrete-time stochastic linear control systems (dt-SLS) operating under
communication imperfections. The control unit is remote and communicates with
the sensor and actuator through an imperfect wireless network. We consider a
constant delay in the sensor-to-controller channel (uplink), and data loss in
both sensor-to-controller and controller-to-actuator (downlink) channels. In
our proposed scheme, data loss in each channel is modeled as an independent
Bernoulli-distributed random process. To systematically handle the uplink
delay, we first introduce an augmented discrete-time stochastic linear system
(dt-ASLS) by concatenating all states and control inputs that sufficiently
represent the state-input evolution of the original dt-SLS under the delay and
packet loss constraints. We then leverage control barrier certificates (CBCs)
for dt-ASLS to synthesize a controller that guarantees dt-SLS safety in a
stochastic sense, ensuring that all trajectories of dt-SLS remain within safe
regions with a quantified probabilistic bound. Our approach translates safety
constraints into matrix inequalities, leading to an optimization problem that
eventually quantifies the probability of satisfying the safety specification in
the presence of communication imperfections. We validate our results on an RLC
circuit subject to both constant delay and probabilistic data loss.

</details>


### [685] [On an Abstraction of Lyapunov and Lagrange Stability](https://arxiv.org/abs/2507.15047)
*Michelangelo Bin,David Angeli*

Main category: eess.SY

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: This paper studies a set-theoretic generalization of Lyapunov and Lagrange
stability for abstract systems described by set-valued maps. Lyapunov stability
is characterized as the property of inversely mapping filters to filters,
Lagrange stability as that of mapping ideals to ideals. These abstract
definitions unveil a deep duality between the two stability notions, enable a
definition of global stability for abstract systems, and yield an agile
generalization of the stability theorems for basic series, parallel, and
feedback interconnections, including a small-gain theorem. Moreover, it is
shown that Lagrange stability is abstractly identical to other properties of
interest in control theory, such as safety and positivity, whose preservation
under interconnections can be thus studied owing to the developed stability
results.

</details>


### [686] [Exact Finite Koopman Embedding of Block-Oriented Polynomial Systems](https://arxiv.org/abs/2507.15093)
*Lucian Cristian Iacob,Roland Tóth,Maarten Schoukens*

Main category: eess.SY

TL;DR: 为非线性系统提供了一种系统性的方法来学习精确的Koopman嵌入，克服了传统方法的随意性和量化误差的困难。


<details>
  <summary>Details</summary>
Motivation: 为了解决传统数据驱动技术在学习非线性系统模型时，模型结构和维度的选择具有随意性且难以量化误差的问题，本研究旨在开发一种系统性的技术，为非线性系统生成有限维且精确的Koopman嵌入。

Method: 通过将非线性系统表示为由线性与非线性（多项式）块组成的串联/并联网络，推导出具有恒定状态和输出矩阵的Koopman模型，并将输入影响建模为多项式，在特定条件下（线性块无前馈）进一步简化为双线性模型。

Result: 开发了一种系统性技术，为非线性系统生成有限维且精确的Koopman嵌入。当系统由线性与多项式块组成时，可得到具有常数状态和输出矩阵的模型，输入影响为多项式；若线性块无前馈，则简化为双线性模型。

Conclusion: 该研究提出了一种系统性技术，用于非线性系统，能够生成有限维且精确的Koopman嵌入。如果非线性系统可以表示为串联和并联的线性及非线性（多项式）块的网络，则可以推导出具有恒定状态和输出矩阵的关联Koopman模型，并且输入影响是多项式的。此外，如果线性块没有前馈，Koopman表示会简化为双线性模型。

Abstract: The challenge of finding exact and finite-dimensional Koopman embeddings of
nonlinear systems has been largely circumvented by employing data-driven
techniques to learn models of different complexities (e.g., linear, bilinear,
input affine). Although these models may provide good accuracy, selecting the
model structure and dimension is still ad-hoc and it is difficult to quantify
the error that is introduced. In contrast to the general trend of data-driven
learning, in this paper, we develop a systematic technique for nonlinear
systems that produces a finite-dimensional and exact embedding. If the
nonlinear system is represented as a network of series and parallel linear and
nonlinear (polynomial) blocks, one can derive an associated Koopman model that
has constant state and output matrices and the input influence is polynomial.
Furthermore, if the linear blocks do not have feedthrough, the Koopman
representation simplifies to a bilinear model.

</details>


### [687] [Adaptive Network Security Policies via Belief Aggregation and Rollout](https://arxiv.org/abs/2507.15163)
*Kim Hammar,Yuchao Li,Tansu Alpcan,Emil C. Lupu,Dimitri Bertsekas*

Main category: eess.SY

TL;DR: 本研究提出了一种新的强化学习方法，用于自动适应网络安全策略，解决了现有方法的不足，并取得了更好的性能。


<details>
  <summary>Details</summary>
Motivation: 为了解决现有强化学习方法在网络安全策略自动适应方面的性能保证不足和适应变化缓慢的问题。

Method: 该方法包含三个组件：通过粒子滤波进行信念估计，通过聚合进行离线策略计算，以及通过滚动进行在线策略适应。其核心是一种新的基于特征的聚合技术。

Result: 该方法能够计算出可扩展、具有理论保证且能快速适应变化的策略，并且在模拟和测试平台结果中表现优于现有技术。

Conclusion: 该方法在CAGE-2等多个基准测试中表现优于最先进的方法。

Abstract: Evolving security vulnerabilities and shifting operational conditions require
frequent updates to network security policies. These updates include
adjustments to incident response procedures and modifications to access
controls, among others. Reinforcement learning methods have been proposed for
automating such policy adaptations, but most of the methods in the research
literature lack performance guarantees and adapt slowly to changes. In this
paper, we address these limitations and present a method for computing security
policies that is scalable, offers theoretical guarantees, and adapts quickly to
changes. It assumes a model or simulator of the system and comprises three
components: belief estimation through particle filtering, offline policy
computation through aggregation, and online policy adaptation through rollout.
Central to our method is a new feature-based aggregation technique, which
improves scalability and flexibility. We analyze the approximation error of
aggregation and show that rollout efficiently adapts policies to changes under
certain conditions. Simulations and testbed results demonstrate that our method
outperforms state-of-the-art methods on several benchmarks, including CAGE-2.

</details>


### [688] [A New Ultrafast Printer for Large-Scale Assembly of Piezoelectric Biomaterials](https://arxiv.org/abs/2507.15167)
*Nan An,Mingtong Chen,Zhengbao Yang*

Main category: eess.SY

TL;DR: 一种利用锥形射流和纳米限制自组装技术，实现超快、大面积生物压电薄膜制造的方法。


<details>
  <summary>Details</summary>
Motivation: 本研究旨在实现一种模块化、快速和大面积的生物压电薄膜制造技术。

Method: 通过将高电压电场施加到导电尖刺金属圆盘上形成锥形射流模式，并结合纳米限制下的生物分子材料自组装过程和原位极化效应，实现了一种模块化、快速和大面积的生物压电薄膜制造技术。

Result: 该技术实现了高达 9.2 x 10^9 um^3/s 的打印速度，并且模块化设计允许 MLSP 实现理论上无限的打印效率，同时为不同打印需求提供灵活的配置选项。

Conclusion: MLSP展示了压电生物材料进行超快、大规模组装的能力，并作为生物压电薄膜制造的通用生物制造方法具有良好潜力。

Abstract: We propose a modular, fast and large-area fabrication of bio-piezoelectric
films. The technique is based on the formation of cone-jet mode by applying a
high voltage electric field to conductive spiked metal disks. And the
self-assembly process of biomolecular materials through nanoconfinement with
in-situ poling effect. This job achieved print speeds of up to 9.2 109 um3/s
with a combination of only 2 printheads. At the same time, the modular design
allows the MLSP to achieve theoretically unlimited print efficiency. It also
provides flexible configuration options for different printing needs, such as
preparing films of different areas and shapes. In short, MLSP demonstrates the
ability of piezoelectric biomaterials to undergo ultra-fast, large-scale
assembly. Demonstrates good potential as a universally applicable bio-device
for the fabrication of bio-piezoelectric films

</details>


### [689] [Energy consumption optimization and self-powered environmental monitoring design for low-carbon smart buildings](https://arxiv.org/abs/2507.15169)
*Yuhan Dai,Mingtong Chen,Zhengbao Yang*

Main category: eess.SY

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Despite the growing emphasis on intelligent buildings as a cornerstone of
sustainable urban development, significant energy inefficiencies persist due to
suboptimal design, material choices, and user behavior. The applicability of
integrated Building Information Modeling (BIM) and solarpowered environmental
monitoring systems for energy optimization in low-carbon smart buildings
remains underexplored. Can BIM-driven design improvements, combined with
photovoltaic systems, achieve substantial energy savings while enabling
self-powered environmental monitoring? This study conducts a case analysis on a
retrofitted primary school building in Guangdong, China, utilizing BIM-based
energy simulations, material optimization, and solar technology integration.
The outcomes reveal that the proposed approach reduced annual energy
consumption by 40.68%, with lighting energy use decreasing by 36.59%. A rooftop
photovoltaic system demonstrated a payback period of 7.46 years while powering
environmental sensors autonomously. Hardware system integrates sensors and an
ARDUINO-based controller to detect environmental factors like rainfall,
temperature, and air quality. It is powered by a 6W solar panel and a 2200
mAh/7.4 V lithium battery to ensure stable operation. This study underscores
the potential of BIM and solar energy integration to transform traditional
buildings into energy-efficient, self-sustaining smart structures. Further
research can expand the scalability of these methods across diverse climates
and building typologies.

</details>


### [690] [Physics-Informed Learning of Proprietary Inverter Models for Grid Dynamic Studies](https://arxiv.org/abs/2507.15259)
*Kyung-Bin Kwon,Sayak Mukherjee,Ramij R. Hossain,Marcelo Elizondo*

Main category: eess.SY

TL;DR: 提出了一种新的物理信息神经网络ODE框架，用于模拟专有逆变器动态，解决了OEM不披露逆变器参数的问题，提高了模拟精度。


<details>
  <summary>Details</summary>
Motivation: 解决原始设备制造商（OEM）通常不披露逆变器确切内部控件和参数的问题，这给执行准确的动态模拟和增益调整等相关研究带来了重大挑战。

Method: 提出了一种物理信息潜在神经网络ODE模型（PI-LNM），该模型将系统物理与神经网络层相结合，以捕获专有单元的未建模行为。

Result: 通过使用并网逆变器（GFM）案例研究进行了验证，与仅依赖于数据驱动学习而没有基于物理指导的方法相比，证明了其动态模拟精度的提高。

Conclusion: 使用基于物理信息神经网络常微分方程（PINODE）的框架来模拟逆变器的专有动态，以提高电网动态模拟的准确性。

Abstract: This letter develops a novel physics-informed neural ordinary differential
equations-based framework to emulate the proprietary dynamics of the inverters
-- essential for improved accuracy in grid dynamic simulations. In current
industry practice, the original equipment manufacturers (OEMs) often do not
disclose the exact internal controls and parameters of the inverters, posing
significant challenges in performing accurate dynamic simulations and other
relevant studies, such as gain tunings for stability analysis and controls. To
address this, we propose a Physics-Informed Latent Neural ODE Model (PI-LNM)
that integrates system physics with neural learning layers to capture the
unmodeled behaviors of proprietary units. The proposed method is validated
using a grid-forming inverter (GFM) case study, demonstrating improved dynamic
simulation accuracy over approaches that rely solely on data-driven learning
without physics-based guidance.

</details>


### [691] [Dual-Channel Adaptive NMPC for Quadrotor under Instantaneous Impact and Payload Disturbances](https://arxiv.org/abs/2507.15261)
*Xinqi Chen,Xiuxian Li,Min Meng*

Main category: eess.SY

TL;DR: 为了解决四旋翼抓取重物时控制难题，提出DCA-NMPC架构，通过级联控制有效应对冲击和参数不确定性。


<details>
  <summary>Details</summary>
Motivation: 大多数现有研究集中于抓取轻量级物体，而忽略了抓取有一定质量物体时产生的瞬时接触力以及附着后载荷不确定性对四旋翼飞行器控制带来的挑战。

Method: 提出了一种新颖的DCA-NMPC控制架构，将非线性模型预测控制与两个低级模型参考自适应控制器级联，以抵抗剧烈冲击并适应不确定的惯性参数。

Result: 通过数值仿真实验验证了所提出方法的有效性。

Conclusion: 该研究提出了一种新颖的双通道自适应非线性模型预测控制（DCA-NMPC）架构，能够应对抓取带质量物体时产生的瞬时接触力以及附着后载荷不确定性带来的挑战。

Abstract: Capturing target objects using the quadrotor has gained increasing popularity
in recent years, but most studies focus on capturing lightweight objects. The
instantaneous contact force generated when capturing objects of a certain mass,
along with the payload uncertainty after attachment, will pose significant
challenges to the quadrotor control. This paper proposes a novel control
architecture, namely Dual-Channel Adaptive Nonlinear Model Predictive Control
(DCA-NMPC), which cascades a nonlinear model predictive control with two
lower-level model reference adaptive controllers and can resist drastic impact
and adapt to uncertain inertial parameters. Numerical simulation experiments
are performed for validation.

</details>


### [692] [Joint Optimisation of Electric Vehicle Routing and Scheduling: A Deep Learning-Driven Approach for Dynamic Fleet Sizes](https://arxiv.org/abs/2507.15307)
*Jun Kang Yap,Vishnu Monn Baskaran,Wen Shan Tan,Ze Yang Ding,Hao Wang,David L. Dowe*

Main category: eess.SY

TL;DR: 深度学习优化电动汽车充电调度，速度快97.8%，结果接近最优。


<details>
  <summary>Details</summary>
Motivation: 为了解决日益普及的电动汽车作为移动储能系统为电网提供支持，需要有效的充电协调，但传统的MIP方法在时限性任务中效率低下。

Method: 使用卷积神经网络（CNN）预测MIP问题中的二元变量，以减小搜索空间，并采用填充机制处理EV数量变化，无需重新训练。

Result: 在IEEE 33节点系统和Nguyen-Dupuis交通网络案例研究中，该方法将运行时间缩短了97.8%，同时保持了99.5%的可行性，并使结果与最优解的偏差小于0.01%。

Conclusion: 该研究提出了一种深度学习辅助方法来优化电动汽车（EV）的 يوم ahead 路由和调度问题，以解决混合整数规划（MIP）的NP难题。

Abstract: Electric Vehicles (EVs) are becoming increasingly prevalent nowadays, with
studies highlighting their potential as mobile energy storage systems to
provide grid support. Realising this potential requires effective charging
coordination, which are often formulated as mixed-integer programming (MIP)
problems. However, MIP problems are NP-hard and often intractable when applied
to time-sensitive tasks. To address this limitation, we propose a deep learning
assisted approach for optimising a day-ahead EV joint routing and scheduling
problem with varying number of EVs. This problem simultaneously optimises EV
routing, charging, discharging and generator scheduling within a distribution
network with renewable energy sources. A convolutional neural network is
trained to predict the binary variables, thereby reducing the solution search
space and enabling solvers to determine the remaining variables more
efficiently. Additionally, a padding mechanism is included to handle the
changes in input and output sizes caused by varying number of EVs, thus
eliminating the need for re-training. In a case study on the IEEE 33-bus system
and Nguyen-Dupuis transportation network, our approach reduced runtime by 97.8%
when compared to an unassisted MIP solver, while retaining 99.5% feasibility
and deviating less than 0.01% from the optimal solution.

</details>


### [693] [RoCoF Constrained Regional Inertia Security Region: Formulation and Application](https://arxiv.org/abs/2507.15344)
*Jiahao Liu,Cheng Wang,Tianshu Bi*

Main category: eess.SY

TL;DR: 本研究提出了区域惯量安全区域（R-ISR）的概念，并开发了一种新的方法来计算和优化受R-ISR约束的区域惯量，以应对可再生能源并网带来的挑战。研究发现增加区域惯量并不总是能改善频率稳定。


<details>
  <summary>Details</summary>
Motivation: 为了解决在含大量可再生能源的电力系统中，区域惯量与区域最大频率变化率（RoCoF）的线性映射关系过于简化的缺点，本文旨在全面研究区域惯量安全问题，涵盖从模型建立到实际应用。

Method: 首先，定义了区域惯量安全区域（R-ISR），其边界为非线性且非凸的。然后，设计了一种局部线性化方法来计算区域最大RoCoF。通过搜索方法获得与每个局部解对应的简单边界，以此来表示非凸的R-ISR边界。最后，通过凸分解将R-ISR约束凸化，并将其嵌入惯量最优调整模型。

Result: 在一个三区域系统上的结果显示了一些反直觉的发现，例如增加一个区域的惯量可能会导致其RoCoF恶化。

Conclusion: 本研究定义了区域惯量安全区域（R-ISR），其边界为非线性且非凸的。通过局部线性化方法计算区域最大频率变化率（RoCoF），并将非凸的R-ISR边界表示为多个局部解对应的简单边界，利用基于搜索的方法获得这些边界。最后，通过凸分解将R-ISR约束凸化，并将其嵌入惯量最优调整模型。结果表明，增加一个区域的惯量有时反而会恶化其RoCoF。

Abstract: The regional inertia, which determines the regional rate of change of
frequency (RoCoF), should be kept in a secure status in renewable-penetrated
power systems. To break away from mapping the regional maximum RoCoF with
regional inertia in a linearized form, this paper comprehensively studies the
regional inertia security problem from formulation to applications. Firstly,
the regional inertia security region (R-ISR) is defined, whose boundary is
non-linear and non-convex. Then, a local linearized method is devised to
calculate the global maximum of regional RoCoF. The non-convex ISR boundary is
expressed by multiple simple boundaries corresponding to each local solution,
which can be obtained by a simple search-based method. Finally, the convexified
R-ISR constraint is formed by convex decomposition and embedded in an inertia
optimal adjustment model. The results on a 3-region system show some
counter-intuitive findings, such as increasing the inertia of one region may
worsen its RoCoF.

</details>


### [694] [Revisiting the Effect of Grid-Following Converter on Frequency Dynamics -- Part I: Center of Inertia](https://arxiv.org/abs/2507.15358)
*Jiahao Liu,Cheng Wang,Tianshu Bi*

Main category: eess.SY

TL;DR: GFLs对COI频率动态的影响是有限的，但它们的等效惯量是可变的，并且会影响COI频率。


<details>
  <summary>Details</summary>
Motivation: 理解GFLs对系统频率动态（从COI和频率空间变异性角度）的影响至关重要。

Method: 提出了一种包含GFLs和同步发电机的多机组电力系统模型，并通过虚拟输电线路将GFLs的局部动态与其进行交互。通过将多机组模型聚合到COI框架中，揭示了COI频率与GFLs等效频率之间的相互作用。

Result: 仿真结果验证了所提出模型的准确性，并表明GFLs对COI频率的影响相对较弱，但GFLs的等效惯量和其他分量对COI频率动态仍然有显著影响，其影响具有时变性和可调性。

Conclusion: GFLs对COI频率的影响相对较弱，但其等效惯量和其他分量对COI频率动态有显著影响，且影响具有时变性和可调性。

Abstract: Understanding the impact of grid-following (GFL) converters on system
frequency dynamics is crucial, from both the center of inertia (COI) and
frequency spatial variation perspectives. Part I of this series clarifies the
mechanisms by which GFLs influence COI frequency dynamics. A multi-generator
model of the power system with GFLs is developed, incorporating the local
dynamics of GFLs and their interaction with synchronous generators via virtual
tie lines. By aggregating the multi-generator model into the COI frame, the
interaction between the COI frequency and the equivalent frequency of GFLs is
revealed. The equivalent inertia and other components at the GFL side,
determined by control parameters and operating conditions, support the COI
through virtual tying power. Simulation validates the accuracy of the proposed
modeling and demonstrates that the impact of GFLs on COI frequency is
relatively weak. The equivalent inertia and other components of GFLs still
significantly influence COI frequency dynamics, with their effects being both
time-variable and adjustable.

</details>


### [695] [Revisiting the Effect of Grid-Following Converter on Frequency Dynamics -- Part II: Spatial Variation](https://arxiv.org/abs/2507.15362)
*Jiahao Liu,Cheng Wang,Tianshu Bi*

Main category: eess.SY

TL;DR: 本研究通过扩展频率分频器（FD）公式，分析了并网逆变器（GFL）对电力系统空间频率变化的影响，并对节点和支路频率的映射关系进行了建模和仿真验证。


<details>
  <summary>Details</summary>
Motivation: 除了质心（COI）频率动力学（如第一部分所述），具有并网逆变器（GFL）的电力系统的空间频率变化也至关重要。第二部分旨在重新审视GFL对频率空间变化的影响。

Method: 利用接口状态变量和等效频率，提出了一种扩展频率分频器（FD）公式，并对网络节点频率与同步发电机（SG）转子频率以及GFL等效频率之间的线性化映射关系进行了建模。

Result: GFL对节点频率的叠加贡献相对较弱，且叠加系数是时变的。此外，研究还解决了支路电流的频率映射问题，揭示了其与节点频率不同的复杂模式。

Conclusion: 仿真结果验证了所提出的扩展频率分频器（FD）公式的准确性，并量化证明了GFL对节点频率的叠加贡献相对较弱，且叠加系数是时变的。

Abstract: Besides the center of inertia (COI) frequency dynamics addressed in Part I,
the spatial frequency variation in power systems with grid-following (GFL)
converters is also crucial. Part II revisits the effect of GFLs on frequency
spatial variation. Leveraging the interfacing state variables and equivalent
frequency defined in Part I, an extended frequency divider (FD) formula is
proposed. The linearized mapping relationship between network node frequency
and synchronous generator (SG) rotor frequency, as well as GFL equivalent
frequency, is modeled. The superposition contribution from GFLs is determined
by the electrical distance between the generator and the frequency observation
node, as well as the system power flow conditions. Additionally, the frequency
mapping for branch currents, which is overlooked in previous research, is
addressed. Simulation results validate the accuracy of the proposed extended FD
formula. They quantitatively demonstrate that the superposition contribution of
GFLs to node frequency is relatively weak and that the superposition
coefficient is time-varying. The branch frequency superposition reveals a
complex and distinctly different pattern.

</details>


### [696] [Transformer-based Deep Learning Model for Joint Routing and Scheduling with Varying Electric Vehicle Numbers](https://arxiv.org/abs/2507.15385)
*Jun Kang Yap,Vishnu Monn Baskaran,Wen Shan Tan,Ze Yang Ding,Hao Wang,David L. Dowe*

Main category: eess.SY

TL;DR: 本研究利用电动汽车作为移动储能，提出了一种基于深度学习的 transformer 模型来优化电动汽车的路径和调度问题，以应对可再生能源的挑战，并简化了求解过程。


<details>
  <summary>Details</summary>
Motivation: 为了克服移动储能系统（ESS）部署成本高的问题，并应对可再生能源发电的间歇性和不确定性，本研究旨在利用电动汽车（EV）作为移动储能单元，并解决电动汽车联合路径和调度问题。

Method: 提出了一种基于深度学习（DL）的 transformer 模型，用于预测混合整数规划（MIP）问题的最优二元解，以简化求解过程并修剪搜索空间。该模型能够适应不同规模的电动汽车（EV）车队。

Result: 通过在 IEEE 33 母线系统和 Nguyen-Dupuis 交通网络上进行模拟，验证了所提出方法的可行性。

Conclusion: 已提出的深度学习模型可以为混合整数规划（MIP）求解器提供最优的二元解，从而简化其求解过程，并且能够适应不同规模的电动汽车（EV）车队，而无需频繁重新训练。

Abstract: The growing integration of renewable energy sources in modern power systems
has introduced significant operational challenges due to their intermittent and
uncertain outputs. In recent years, mobile energy storage systems (ESSs) have
emerged as a popular flexible resource for mitigating these challenges.
Compared to stationary ESSs, mobile ESSs offer additional spatial flexibility,
enabling cost-effective energy delivery through the transportation network.
However, the widespread deployment of mobile ESSs is often hindered by the high
investment cost, which has motivated researchers to investigate utilising more
readily available alternatives, such as electric vehicles (EVs) as mobile
energy storage units instead. Hence, we explore this opportunity with a
MIP-based day-ahead electric vehicle joint routing and scheduling problem in
this work. However, solving the problem in a practical setting can often be
computationally intractable since the existence of binary variables makes it
combinatorial challenging. Therefore, we proposed to simplify the problem's
solution process for a MIP solver by pruning the solution search space with a
transformer-based deep learning (DL) model. This is done by training the model
to rapidly predict the optimal binary solutions. In addition, unlike many
existing DL approaches that assume fixed problem structures, the proposed model
is designed to accommodate problems with EV fleets of any sizes. This
flexibility is essential since frequent re-training can introduce significant
computational overhead. We evaluated the approach with simulations on the IEEE
33-bus system coupled with the Nguyen-Dupuis transportation network.

</details>


### [697] [Scaled Relative Graph Analysis of General Interconnections of SISO Nonlinear Systems](https://arxiv.org/abs/2507.15564)
*Julius P. J. Krebbekx,Roland Tóth,Amritam Das*

Main category: eess.SY

TL;DR: 比例图（SRG）分析方法在非线性系统分析中得到改进，通过与奈奎斯特定理结合，可以更广泛地应用于稳定性与L2增益性能的评估，并对Lur


<details>
  <summary>Details</summary>
Motivation: 现有比例图（SRG）分析方法在应用于实际非线性系统时存在局限性。

Method: 通过引入线性时不变算子的比例图（SRG）的修正公式，并将其与奈奎斯特定理相结合，提出了一种新的分析方法。

Result: 提出了一种新的定理，可用于评估一般非线性动态系统的稳定性与L2增益性能。推导了Lur

Conclusion: 该研究通过引入线性时不变算子的比例图（SRG）的修正公式，并将其与奈奎斯特定理相结合，成功克服了现有SRG分析方法的局限性。新的理论框架能够评估一般非线性动态系统的稳定性和 L2 增益性能，并已成功应用于 Lur

Abstract: Scaled Relative Graphs (SRGs) provide a novel graphical frequency-domain
method for the analysis of nonlinear systems. However, we show that the current
SRG analysis suffers from a pitfall that limits its applicability in analyzing
practical nonlinear systems. We overcome this pitfall by introducing a novel
reformulation of the SRG of a linear time-invariant operator and combining the
SRG with the Nyquist criterion. The result is a theorem that can be used to
assess stability and $L_2$-gain performance for general interconnections of
nonlinear dynamic systems. We provide practical calculation results for
canonical interconnections and apply our result to Lur'e systems to obtain a
generalization of the celebrated circle criterion, which deals with broader
class of nonlinearities, and we derive (incremental) $L_2$-gain performance
bounds. We illustrate the power of the new approach on the analysis of several
examples.

</details>


### [698] [Improving Functional Reliability of Near-Field Monitoring for Emergency Braking in Autonomous Vehicles](https://arxiv.org/abs/2507.15594)
*Junnan Pan,Prodromos Sotiriadis,Vladislav Nenchev,Ferdinand Englberger*

Main category: eess.SY

TL;DR: 提出三种基于动态空间属性、对象大小和运动预测的监控策略，以提高自动驾驶车辆近场障碍物检测的可靠性，实验证明有效。


<details>
  <summary>Details</summary>
Motivation: 为了解决自动驾驶车辆近场障碍物检测中，主要传感器系统可能遗漏近场障碍物的问题，以及专门的快速反应近场监控系统可能出现的误报问题。

Method: 本研究基于动态空间属性、相关对象大小和运动感知预测，引入了三种监控策略。

Result: 通过在已验证的模拟中进行的实验，将初始监控策略与所提出的改进策略进行了比较，结果表明所提出的策略可以显著提高近场监控系统的可靠性。

Conclusion: 所提出的策略可显著提高近场监控系统的可靠性。

Abstract: Autonomous vehicles require reliable hazard detection. However, primary
sensor systems may miss near-field obstacles, resulting in safety risks.
Although a dedicated fast-reacting near-field monitoring system can mitigate
this, it typically suffers from false positives. To mitigate these, in this
paper, we introduce three monitoring strategies based on dynamic spatial
properties, relevant object sizes, and motion-aware prediction. In experiments
in a validated simulation, we compare the initial monitoring strategy against
the proposed improvements. The results demonstrate that the proposed strategies
can significantly improve the reliability of near-field monitoring systems.

</details>


### [699] [Reliability-Based Fault Analysis and Modeling of Satellite Electrical Power Subsystems Using Fault Tree and Simulation Tools](https://arxiv.org/abs/2507.15708)
*Niloofar Nobahari,Alireza Rezaee*

Main category: eess.SY

TL;DR: 对卫星电力系统进行了仿真和故障树分析，证明了其高可靠性。


<details>
  <summary>Details</summary>
Motivation: 卫星中的电力子系统至关重要，其故障会导致卫星部分或全部失效。因此，在任务前计算电力系统的整体可靠性对于改进卫星电力系统的设计至关重要。然而，电力系统的组件可能因压力、发射压力和操作条件而发生故障。

Method: 首先，使用MATLAB对电力系统组件的健康和故障系统进行仿真。然后，通过绘制故障树来分析电力子系统的可靠性，并使用Windchill软件计算任务的整体可靠性、电力系统的故障率和任务的整体故障率。

Result: 仿真系统达到了0.999的任务保证度，表明其具有高可靠性。

Conclusion: 通过对电力系统进行建模和仿真，并绘制故障树进行可靠性分析，最终实现了0.999的任务保证度，表明了仿真系统的可靠性。

Abstract: One of the most important satellite subsystems is its electric power
subsystem. The occurrence of a fault in the satellite power system causes the
failure of all or part of the satellite. Calculating the overall reliability of
the power system before the mission is crucial in improving the design of the
satellite power system. Each component of the power system may malfunction due
to pressure, launch pressure, and operating conditions. Accordingly, in this
paper, first, a healthy and faulty system for the components of the electrical
power system is simulated with MATLAB. Finally, by drawing a fault tree to
analyze the reliability of the power subsystem, overall mission reliability,
power system fault rate, and overall fault rate of the mission are calculated
by Windchill software. Finally, a total mission assurance of 0.999 was
achieved, indicating the high reliability of the simulated system.

</details>


### [700] [Density control of multi-agent swarms via bio-inspired leader-follower plasticity](https://arxiv.org/abs/2507.15781)
*Gian Carlo Maffettone,Alain Boldini,Mario di Bernardo,Maurizio Porfiri*

Main category: eess.SY

TL;DR: A bio-inspired leader-follower control system is proposed for mobile agent self-organization, using PDEs for analysis and offering proven stability and effectiveness in simulations.


<details>
  <summary>Details</summary>
Motivation: Designing control systems for spatial self-organization of mobile agents is a challenge in areas like swarm robotics and synthetic biology. This paper addresses this by proposing an energy-aware, leader-follower solution suitable for large swarms.

Method: A bio-inspired leader-follower approach is used, formulating control objectives for the collective and allowing agents to switch roles. The density control problem is modeled using nonlinear partial differential equations to avoid the curse of dimensionality and improve analytical tractability.

Result: Analytical guarantees for the existence and local stability of desired steady-state solutions were derived for both one-dimensional and higher-dimensional problems. Numerical validation supported the effectiveness, robustness, and versatility of the control methodology.

Conclusion: The proposed bio-inspired leader-follower control strategy is effective, robust, and versatile for spatial self-organization of mobile agents, with analytical guarantees for steady-state solutions and their local stability.

Abstract: The design of control systems for the spatial self-organization of mobile
agents is an open challenge across several engineering domains, including swarm
robotics and synthetic biology. Here, we propose a bio-inspired leader-follower
solution, which is aware of energy constraints of mobile agents and is apt to
deal with large swarms. Akin to many natural systems, control objectives are
formulated for the entire collective, and leaders and followers are allowed to
plastically switch their role in time. We frame a density control problem,
modeling the agents' population via a system of nonlinear partial differential
equations. This approach allows for a compact description that inherently
avoids the curse of dimensionality and improves analytical tractability. We
derive analytical guarantees for the existence of desired steady-state
solutions and their local stability for one-dimensional and higher-dimensional
problems. We numerically validate our control methodology, offering support to
the effectiveness, robustness, and versatility of our proposed bio-inspired
control strategy.

</details>


<div id='cs.DS'></div>

# cs.DS [[Back]](#toc)

### [701] [FAMST: Fast Approximate Minimum Spanning Tree Construction for Large-Scale and High-Dimensional Data](https://arxiv.org/abs/2507.14261)
*Mahmood K. M. Almansoori,Miklos Telek*

Main category: cs.DS

TL;DR: FAMST是一种新的MST算法，通过三阶段方法（ANN图构建、ANN分量间连接、迭代边优化）实现了高性能，能够处理大规模、高维数据集。


<details>
  <summary>Details</summary>
Motivation: 为了解决大规模和高维数据集计算最小生成树（MST）的计算挑战。

Method: FAMST算法采用三阶段方法：近似最近邻（ANN）图构建、ANN分量间连接和迭代边优化。

Result: FAMST算法实现了$"O"$(dn log n)的时间复杂度和$"O"$(dn + kn)的空间复杂度，与传统方法相比，在保持可忽略的近似误差的同时，速度提高了1000倍。

Conclusion: FAMST算法能够处理具有数百万个点和数千个维度的更大规模的数据集，将MST技术的应用范围扩展到以前认为不可行的比例。

Abstract: We present Fast Approximate Minimum Spanning Tree (FAMST), a novel algorithm
that addresses the computational challenges of constructing Minimum Spanning
Trees (MSTs) for large-scale and high-dimensional datasets. FAMST utilizes a
three-phase approach: Approximate Nearest Neighbor (ANN) graph construction,
ANN inter-component connection, and iterative edge refinement. For a dataset of
$n$ points in a $d$-dimensional space, FAMST achieves $\mathcal{O}(dn \log n)$
time complexity and $\mathcal{O}(dn + kn)$ space complexity when $k$ nearest
neighbors are considered, which is a significant improvement over the
$\mathcal{O}(n^2)$ time and space complexity of traditional methods.
  Experiments across diverse datasets demonstrate that FAMST achieves
remarkably low approximation errors while providing speedups of up to
1000$\times$ compared to exact MST algorithms. We analyze how the key
hyperparameters, $k$ (neighborhood size) and $\lambda$ (inter-component edges),
affect performance, providing practical guidelines for hyperparameter
selection. FAMST enables MST-based analysis on datasets with millions of points
and thousands of dimensions, extending the applicability of MST techniques to
problem scales previously considered infeasible.

</details>


### [702] [Tighter Lower Bounds for Single Source Personalized PageRank](https://arxiv.org/abs/2507.14462)
*Xinpeng Jiang,Haoyu Liu,Siqiang Luo,Xiaokui Xiao*

Main category: cs.DS

TL;DR: 为PageRank近似查询提供更紧确的下界。


<details>
  <summary>Details</summary>
Motivation: 现有SSPPR查询近似的下界（SSPPR-R为$\Omega(\min(m, 1/\delta))$，SSPPR-A为$\Omega(\min(n, 1/\epsilon))$）不够紧密，无法充分反映问题难度。本研究旨在缩小理论下界与实际算法性能之间的差距。

Method: 通过理论分析和构造特定图结构来推导SSPPR-R和SSPPR-A的下界。具体来说，文章证明了SSPPR-R的下界为$\Omega\left(\min\left(m, \frac{\log(1/\delta)}{\delta}\right)\right)$，SSPPR-A的下界为$\Omega\left(\min\left(m, \frac{\log(1/\epsilon)}{\epsilon}\right)\right)$（当$m \in \mathcal{O}(n^{2-\beta})$时）。

Result: 文章成功建立了更紧确的SSPPR-R和SSPPR-A近似问题的下界。对于SSPPR-R，下界被提升至$\Omega(\min(m, \frac{\log(1/\delta)}{\delta}))$；对于SSPPR-A，在特定图结构下（$m \in \mathcal{O}(n^{2-\beta})$），下界被提升至$\Omega(\min(m, \frac{\log(1/\epsilon)}{\epsilon}))$。

Conclusion: 该研究为单源个性化PageRank（SSPPR）查询的近似值提供了更严格的下界，针对相对误差（SSPPR-R）和绝对误差（SSPPR-A）两种情况，并对SSPPR-A的下界在边数较少（$m = O(n^{2-eta})$）的图上进行了证明。

Abstract: We study lower bounds for approximating the Single Source Personalized
PageRank (SSPPR) query, which measures the probability distribution of an
$\alpha$-decay random walk starting from a source node $s$. Existing lower
bounds remain loose-$\Omega\left(\min(m, 1/\delta)\right)$ for relative error
(SSPPR-R) and $\Omega\left(\min(n, 1/\epsilon)\right)$ for additive error
(SSPPR-A). To close this gap, we establish tighter bounds for both settings.
For SSPPR-R, we show a lower bound of $\Omega\left(\min\left(m,
\frac{\log(1/\delta)}{\delta}\right)\right)$ for any $\delta \in (0,1)$. For
SSPPR-A, we prove a lower bound of $\Omega\left(\min\left(m,
\frac{\log(1/\epsilon)}{\epsilon}\right)\right)$ for any $\epsilon \in (0,1)$,
assuming the graph has $m \in \mathcal{O}(n^{2-\beta})$ edges for any
arbitrarily small constant $\beta \in (0,1)$.

</details>


### [703] [New Algorithms for #2-SAT and #3-SAT](https://arxiv.org/abs/2507.14504)
*Junqiang Peng,Zimo Sheng,Mingyu Xiao*

Main category: cs.DS

TL;DR: 本研究提出了求解加权 #2-SAT 和 #3-SAT 问题的新方法，显著提高了算法效率。


<details>
  <summary>Details</summary>
Motivation: 在 #2-SAT 和 #3-SAT 问题（计算 2-SAT 和 3-SAT 实例的满足赋值数量）的背景下，旨在改进已有算法的效率，特别是针对加权版本。

Method: 通过引入新的约简规则、改进分支操作分析以及应用路径分解到公式的图论表示（包括原图和对偶图）来解决加权 #2-SAT 和 #3-SAT 问题。

Result: 加权 #2-SAT 问题可以在 O*(1.1082^m) 时间内解决，加权 #3-SAT 问题可以在 O*(1.4423^m) 时间内解决，这些结果也适用于无权情况，并显著优于之前的研究。

Conclusion: 该研究为加权 #2-SAT 和 #3-SAT 问题提供了新的求解算法，其时间复杂度分别为 O*(1.1082^m) 和 O*(1.4423^m)，在无权情况下也优于先前结果。

Abstract: The #2-SAT and #3-SAT problems involve counting the number of satisfying
assignments (also called models) for instances of 2-SAT and 3-SAT,
respectively. In 2010, Zhou et al. proposed an $\mathcal{O}^*(1.1892^m)$-time
algorithm for #2-SAT and an efficient approach for #3-SAT, where $m$ denotes
the number of clauses. In this paper, we show that the weighted versions of
#2-SAT and #3-SAT can be solved in $\mathcal{O}^*(1.1082^m)$ and
$\mathcal{O}^*(1.4423^m)$ time, respectively. These results directly apply to
the unweighted cases and achieve substantial improvements over the previous
results. These advancements are enabled by the introduction of novel reduction
rules, a refined analysis of branching operations, and the application of path
decompositions on the primal and dual graphs of the formula.

</details>


### [704] [Addressing Bias in Algorithmic Solutions: Exploring Vertex Cover and Feedback Vertex Set](https://arxiv.org/abs/2507.14509)
*Sheikh Shakil Akhtar,Jayakrishnan Madathil,Pranabendu Misra,Geevarghese Philip*

Main category: cs.DS

TL;DR: 本文研究如何在组合优化中找到公平的解决方案，特别关注少数群体。


<details>
  <summary>Details</summary>
Motivation: 传统优化算法在抽象现实世界问题时会忽略“副信息”，导致解决方案在不同人群中可能产生不公平的影响，尤其对少数群体。

Method: 本文提出了寻找组合优化问题的无偏解决方案的方法。

Result: 该研究关注如何找到在指定人群子集方面“无偏”的组合优化问题的解决方案。

Conclusion: 研究旨在找到组合优化问题的无偏解决方案，以解决实际应用中因忽略“副信息”而导致的公平性问题。

Abstract: A typical goal of research in combinatorial optimization is to come up with
fast algorithms that find optimal solutions to a computational problem. The
process that takes a real-world problem and extracts a clean mathematical
abstraction of it often throws out a lot of "side information" which is deemed
irrelevant. However, the discarded information could be of real significance to
the end-user of the algorithm's output. All solutions of the same cost are not
necessarily of equal impact in the real-world; some solutions may be much more
desirable than others, even at the expense of additional increase in cost. If
the impact, positive or negative, is mostly felt by some specific (minority)
subgroups of the population, the population at large will be largely unaware of
it. In this work we ask the question of finding solutions to combinatorial
optimization problems that are "unbiased" with respect to a collection of
specified subgroups of the total population.

</details>


### [705] [Characterizing and Testing Configuration Stability in Two-Dimensional Threshold Cellular Automata](https://arxiv.org/abs/2507.14569)
*Yonatan Nakar,Dana Ron*

Main category: cs.DS

TL;DR: 本文研究了二维环面上元胞自动机配置的稳定性。对于阈值-1 和阈值-5 规则，稳定配置是平凡的。对于阈值-2 和阈值-3 规则，研究了稳定配置的结构，并设计了一种测试算法，该算法的查询复杂度独立于配置大小，且与 1/ε 的平方成正比。


<details>
  <summary>Details</summary>
Motivation: 研究在二维环面上根据具有冯·诺依曼邻域的阈值规则演化的元胞自动机配置的稳定性的表征和测试问题。

Method: 本文研究了在二维环面上根据具有冯·诺依曼邻域的阈值规则演化的元胞自动机配置的稳定性的表征和测试问题。首先，我们表征了阈值-2（类似地，阈值-4）和阈值-3（多数）规则的稳定配置结构。然后，我们设计并分析了一种测试算法，该算法区分了相对于阈值-2 规则稳定的配置和与任何稳定配置相距 ε 的配置。

Result: 对于阈值-1（OR）和阈值-5（AND）的稳定配置是平凡的（且易于测试）。其他阈值规则表现出更多样化的行为。作者们表征了阈值-2 和阈值-3 规则的稳定配置结构，并设计了一种测试算法。

Conclusion: 所提出的算法在查询复杂度上独立于配置的大小，并且复杂度与 1/ε 的平方成正比。

Abstract: We consider the problems of characterizing and testing the stability of
cellular automata configurations that evolve on a two-dimensional torus
according to threshold rules with respect to the von-Neumann neighborhood.
While stable configurations for Threshold-1 (OR) and Threshold-5 (AND) are
trivial (and hence easily testable), the other threshold rules exhibit much
more diverse behaviors. We first characterize the structure of stable
configurations with respect to the Threshold-2 (similarly, Threshold-4) and
Threshold-3 (Majority) rules. We then design and analyze a testing algorithm
that distinguishes between configurations that are stable with respect to the
Threshold-2 rule, and those that are $\epsilon$-far from any stable
configuration, where the query complexity of the algorithm is independent of
the size of the configuration and depends quadratically on $1/\epsilon$.

</details>


### [706] [A Black-Box Approach for Exogenous Replenishment in Online Resource Allocation](https://arxiv.org/abs/2507.14812)
*Suho Kang,Ziyang Liu,Rajan Udwani*

Main category: cs.DS

TL;DR: 黑盒方法扩展在线资源分配算法以处理库存补充。


<details>
  <summary>Details</summary>
Motivation: 为了解决在库存随时间按未知外部过程补充的情况下，在线资源分配问题。

Method: 提出了一种黑盒方法，可以将不考虑库存补充的现有算法扩展到能够处理任意（对抗性或随机性）库存补充过程。

Result: 提出的方法能够将现有算法的竞争比保持在初始库存充足的条件下，实现了将外部库存补充无缝集成到现有算法中的能力，适用于对抗性和随机性到达模型。

Conclusion: 该研究提出了一种将现有在线资源分配算法扩展到考虑库存补充的黑盒方法，该方法在初始库存充足的情况下可以保持原算法的竞争比。

Abstract: In a typical online resource allocation problem, we start with a fixed
inventory of resources and make online allocation decisions in response to
resource requests that arrive sequentially over a finite horizon. We consider
settings where the inventory is replenished over time according to an unknown
exogenous process. We introduce black-box methods that extend any existing
algorithm, originally designed without considering replenishment, into one that
works with an arbitrary (adversarial or stochastic) replenishment process. Our
approach preserves the original algorithm's competitive ratio in regimes with
large initial inventory, thereby enabling the seamless integration of exogenous
replenishment into a large body of existing algorithmic results for both
adversarial and stochastic arrival models.

</details>


### [707] [Differentially Private Synthetic Graphs Preserving Triangle-Motif Cuts](https://arxiv.org/abs/2507.14835)
*Pan Peng,Hangyu Xu*

Main category: cs.DS

TL;DR: 本研究提出了首个差分隐私（DP）合成图生成机制，能有效近似图中所有割的三角-基元子图大小，并给出了相应的误差下界。


<details>
  <summary>Details</summary>
Motivation: 为了在保护隐私的前提下，利用合成图进行图聚类、图稀疏化和社会网络分析等应用，研究了发布能够近似任意给定图 $G$ 的所有割的三角-基元子图大小的差分隐私（DP）合成图 $G'$ 的问题。

Method: 本文提出了一种新的差分隐私（DP）机制，用于生成能够近似任意给定图 $G$ 的所有割的三角-基元子图大小的合成图 $G'$。该机制能在多项式时间内运行，并提供 $(\varepsilon,\delta)$-DP保证。其近似误差界为 $\tilde{O}(\sqrt{m\ell_{3}(G)}n/\varepsilon^{3/2})$，其中 $n$ 是图的顶点数，$m$ 是边数，$\ell_{3}(G)$ 是图的局部三角形敏感度。此外，研究还提供了针对任何 $DP$ 算法在回答所有 $(S,T)$-割的三角-基元子图大小查询时的 $\Omega(\sqrt{mn}\ell_{3}(G)/\varepsilon)$ 的加性误差下界。该算法可推广到加权图，下界也可扩展到任意常数 $h\geq 2$ 的 $K_h$-基元子图割。

Result: 本文提出了首个满足 $(\varepsilon,\delta)$-DP 的机制，能在多项式时间内生成合成图 $G'$，近似误差界为 $\tilde{O}(\sqrt{m\ell_{3}(G)}n/\varepsilon^{3/2})$。同时，也给出了任何 DP 算法在回答所有 $(S,T)$-割的三角-基元子图大小查询时的 $\Omega(\sqrt{mn}\ell_{3}(G)/\varepsilon)$ 的加性误差下界。该算法可推广至加权图，下界可扩展至任意常数 $h\geq 2$ 的 $K_h$-基元子图割。

Conclusion: 该研究提出了首个满足差分隐私的合成图（$G

Abstract: We study the problem of releasing a differentially private (DP) synthetic
graph $G'$ that well approximates the triangle-motif sizes of all cuts of any
given graph $G$, where a motif in general refers to a frequently occurring
subgraph within complex networks. Non-private versions of such graphs have
found applications in diverse fields such as graph clustering, graph
sparsification, and social network analysis. Specifically, we present the first
$(\varepsilon,\delta)$-DP mechanism that, given an input graph $G$ with $n$
vertices, $m$ edges and local sensitivity of triangles $\ell_{3}(G)$, generates
a synthetic graph $G'$ in polynomial time, approximating the triangle-motif
sizes of all cuts $(S,V\setminus S)$ of the input graph $G$ up to an additive
error of $\tilde{O}(\sqrt{m\ell_{3}(G)}n/\varepsilon^{3/2})$. Additionally, we
provide a lower bound of $\Omega(\sqrt{mn}\ell_{3}(G)/\varepsilon)$ on the
additive error for any DP algorithm that answers the triangle-motif size
queries of all $(S,T)$-cut of $G$. Finally, our algorithm generalizes to
weighted graphs, and our lower bound extends to any $K_h$-motif cut for any
constant $h\geq 2$.

</details>


### [708] [Predict, Reposition, and Allocate: A Greedy and Flow-Based Architecture for Sustainable Urban Food Delivery](https://arxiv.org/abs/2507.15282)
*Aqsa Ashraf Makhdomi,Iqra Altaf Gillani*

Main category: cs.DS

TL;DR: 该研究提出了一种环保的食品配送优化框架，通过整合需求预测、路线规划和订单分配，并利用贪婪算法和网络流模型，成功减少了车辆使用，降低了对环境的影响，同时保持了服务效率。


<details>
  <summary>Details</summary>
Motivation: 为了解决食品配送平台增加温室气体排放对环境造成的破坏，以及现有优化机制未能将环境可持续性纳入优化目标的问题。

Method: 提出了一种新颖的环保食品配送优化框架，该框架整合了需求预测、配送员路线规划和订单分配，以最大限度地减少环境影响并保持服务效率。利用目标函数的子模性和单调性，设计了一种高效的贪婪优化算法来解决路线推荐问题，并将订单分配问题公式化为网络流优化模型。设计了一个三层网络架构，根据容量约束和空间需求将订单与配送员进行匹配。

Result: 该框架通过减少车辆数量，并创建可持续的食品配送生态系统，达到了优化目标。

Conclusion: 该框架通过减少车辆数量并创建可持续的食品配送生态系统，实现了环境影响最小化和效率最大化的目标。

Abstract: The rapid proliferation of food delivery platforms has reshaped urban
mobility but has also contributed significantly to environmental degradation
through increased greenhouse gas emissions. Existing optimization mechanisms
produce sub-optimal outcomes as they do not consider environmental
sustainability their optimization objective. This study proposes a novel
eco-friendly food delivery optimization framework that integrates demand
prediction, delivery person routing, and order allocation to minimize
environmental impact while maintaining service efficiency. Since recommending
routes is NP-Hard, the proposed approach utilizes the submodular and monotone
properties of the objective function and designs an efficient greedy
optimization algorithm. Thereafter, it formulates order allocation problem as a
network flow optimization model, which, to the best of our knowledge, has not
been explored in the context of food delivery. A three-layered network
architecture is designed to match orders with delivery personnel based on
capacity constraints and spatial demand. Through this framework, the proposed
approach reduces the vehicle count, and creates a sustainable food delivery
ecosystem.

</details>


### [709] [Language Generation in the Limit: Noise, Loss, and Feedback](https://arxiv.org/abs/2507.15319)
*Yannan Bai,Debmalya Panigrahi,Ian Zhang*

Main category: cs.DS

TL;DR: 该论文解决了语言生成在极限下的并集封闭性问题，并为包含噪声、损失和反馈的变体提供了精确的表征。


<details>
  <summary>Details</summary>
Motivation: 为了解决语言生成在极限下的并集封闭性问题，以及为了更好地理解和表征包含噪声、损失和反馈的语言生成模型的变体。

Method: 通过构造一个可统一生成和不可均匀生成但其并集不可在极限下生成的集合，来解决并集封闭性问题。并研究了带噪声、无样本和带反馈的语言生成模型，证明了它们的等价性，并给出了非均匀噪声生成的特征。

Result: 1. 证明了可均匀生成集合的并集不一定是可生成极限的。2. 证明了带噪声和无样本的生成模型在均匀和非均匀生成中的等价性，并给出了非均匀噪声生成的特征。3. 证明了在极限下的噪声生成和非噪声生成之间存在分离，即使只有一个噪声字符串。4. 证明了有限查询在带反馈的生成模型中没有增加能力，而无限查询则提供了更强大的模型。

Conclusion: 该论文解决了语言生成在极限下的并集封闭性问题，并利用这些技术（以及其他技术）为包含噪声、损失和反馈的自然变体提供了精确的表征。

Abstract: Kleinberg and Mullainathan (2024) recently proposed a formal framework called
language generation in the limit and showed that given a sequence of example
strings from an unknown target language drawn from any countable collection, an
algorithm can correctly generate unseen strings from the target language within
finite time. This notion was further refined by Li, Raman, and Tewari (2024),
who defined stricter categories of non-uniform and uniform generation. They
showed that a finite union of uniformly generatable collections is generatable
in the limit, and asked if the same is true for non-uniform generation.
  We begin by resolving the question in the negative: we give a uniformly
generatable collection and a non-uniformly generatable collection whose union
is not generatable in the limit. We then use facets of this construction to
further our understanding of several variants of language generation. The first
two, generation with noise and without samples, were introduced by Raman and
Raman (2025) and Li, Raman, and Tewari (2024) respectively. We show the
equivalence of these models for uniform and non-uniform generation, and provide
a characterization of non-uniform noisy generation. The former paper asked if
there is any separation between noisy and non-noisy generation in the limit --
we show that such a separation exists even with a single noisy string. Finally,
we study the framework of generation with feedback, introduced by Charikar and
Pabbaraju (2025), where the algorithm is strengthened by allowing it to ask
membership queries. We show finite queries add no power, but infinite queries
yield a strictly more powerful model.
  In summary, the results in this paper resolve the union-closedness of
language generation in the limit, and leverage those techniques (and others) to
give precise characterizations for natural variants that incorporate noise,
loss, and feedback.

</details>


### [710] [1.64-Approximation for Chromatic Correlation Clustering via Chromatic Cluster LP](https://arxiv.org/abs/2507.15417)
*Dahoon Lee,Chenglin Fan,Euiwoong Lee*

Main category: cs.DS

TL;DR: 一项新的随机算法将CCC问题的近似比从2.15提高到1.64，它使用一种新的LP松弛和舍入方法，并展示了聚类LP框架在处理其他聚类问题上的潜力。


<details>
  <summary>Details</summary>
Motivation: 改进CCC问题的近似比，因为先前的方法受限于标准LP松弛的局限性。

Method: 提出了一种随机的1.64近似算法，该算法扩展了聚类LP框架到色彩设定，引入了色彩聚类LP松弛，并使用结合了基于聚类和基于贪心枢轴的策略的舍入算法。

Result: 实现了一个1.64的近似比，优于之前的2.15近似比。

Conclusion: 该研究提出了一种随机的、近似比为1.64的CCC算法，显著优于先前2.15的近似比。该方法通过引入一个色彩聚类LP松弛和一个结合了基于聚类和基于贪心枢轴的策略的舍入算法，将聚类LP框架扩展到了色彩设定。该分析绕过了标准LP的CCC版本中的2的积分间隙，并强调了聚类LP框架在解决其他聚类问题变体方面的潜力。

Abstract: Chromatic Correlation Clustering (CCC) generalizes Correlation Clustering by
assigning multiple categorical relationships (colors) to edges and imposing
chromatic constraints on the clusters. Unlike traditional Correlation
Clustering, which only deals with binary $(+/-)$ relationships, CCC captures
richer relational structures. Despite its importance, improving the
approximation for CCC has been difficult due to the limitations of standard LP
relaxations. We present a randomized $1.64$-approximation algorithm to the CCC
problem, significantly improving the previous factor of $2.15$. Our approach
extends the cluster LP framework to the chromatic setting by introducing a
chromatic cluster LP relaxation and an rounding algorithm that utilizes both a
cluster-based and a greedy pivot-based strategy. The analysis bypasses the
integrality gap of $2$ for the CCC version of standard LP and highlights the
potential of the cluster LP framework to address other variants of clustering
problems.

</details>


### [711] [Asynchronous Collective Tree Exploration: a Distributed Algorithm, and a new Lower Bound](https://arxiv.org/abs/2507.15658)
*Romain Cosson,Laurent Massoulié*

Main category: cs.DS

TL;DR: 本文提出了一种用于k个移动代理在未知树中进行分布式异步探索的算法，其移动次数上限为 $2n+O(k^2 2^kD)$，竞争比为 $O(k/	ext{log} k)$。同时，也提出了新的竞争比下界 $	ext{Omega}(	ext{log}^2 k)$。


<details>
  <summary>Details</summary>
Motivation: 为了解决在未知树中集体探索的问题，研究团队开发了一种分布式异步算法，以尽可能少的移动次数访问树中的所有节点。

Method: 本文提出了一种分布式异步算法，并进行了一定的改进。具体算法细节未在摘要中详述，但提到了其在探索未知树时的移动次数和竞争比。

Result: 本文提出的分布式异步算法可以在 $2n+O(k^2 2^kD)$ 次移动内探索任意树，并且有一种改进算法的竞争比为 $O(k/	ext{log} k)$。此外，还提出了新的竞争比下界 $	ext{Omega}(	ext{log}^2 k)$。

Conclusion: 本文提出了一种分布式异步算法，可以在 $2n+O(k^2 2^kD)$ 次移动内探索包含 $n$ 个节点和深度 $D$ 的任意树，其遗憾是 $D$ 的线性函数。此外，还提出了一种改进算法，其保证为 $O(k/	ext{log} k)(n+kD)$，竞争比为 $O(k/	ext{log} k)$。本文还为异步分布式树探索提出了新的竞争比下界 $	ext{Omega}(	ext{log}^2 k)$，该下界同样适用于集中式设置，并改进了先前 $	ext{Omega}(	ext{log} k)$ 的下界。

Abstract: We study the problem of collective tree exploration in which a team of $k$
mobile agents must collectively visit all nodes of an unknown tree in as few
moves as possible. The agents all start from the root and discover adjacent
edges as they progress in the tree. Communication is distributed in the sense
that agents share information by reading and writing on whiteboards located at
all nodes. Movements are asynchronous, in the sense that the speeds of all
agents are controlled by an adversary at all times. All previous competitive
guarantees for collective tree exploration are either distributed but
synchronous, or asynchronous but centralized. In contrast, we present a
distributed asynchronous algorithm that explores any tree of $n$ nodes and
depth $D$ in at most $2n+O(k^2 2^kD)$ moves, i.e., with a regret that is linear
in $D$, and a variant algorithm with a guarantee in $O(k/\log k)(n+kD)$, i.e.,
with a competitive ratio in $O(k/\log k)$. We note that our regret guarantee is
asymptotically optimal (i.e., $1$-competitive) from the perspective of
average-case complexity. We then present a new general lower bound on the
competitive ratio of asynchronous collective tree exploration, in
$\Omega(\log^2 k)$. This lower bound applies to both the distributed and
centralized settings, and improves upon the previous lower bound in
$\Omega(\log k)$.

</details>


### [712] [Job Scheduling under Base and Additional Fees, with Applications to Mixed-Criticality Scheduling](https://arxiv.org/abs/2507.15434)
*Yi-Ting Hsieh,Mong-Jen Kao,Jhong-Yun Liu,Hung-Lung Wang*

Main category: cs.DS

TL;DR: 该研究提出了一种调度算法，用于最小化n个作业在m台机器上的总工时，其中每台机器都有规定的运行时间。FFD算法的近似比为1.5，并且存在PTAS。该方法也可用于混合关键度系统调度。


<details>
  <summary>Details</summary>
Motivation: 研究的目的是解决将n个作业分配到m个相同机器上的调度问题，目标是最小化总机器工时。具体来说，需要考虑每台机器规定的运行时间，并最小化总机器工时。

Method: 该研究提出了一种调度算法，并证明了FFD算法的1.5近似比，同时提出了该问题的PTAS。

Result: FFD算法提供了1.5的近似比，并且存在一个PTAS。

Conclusion: FFD算法（First Fit Decreasing）在此问题上可以达到1.5的近似比，并且该问题存在一个多项式时间近似方案（PTAS）。该方法还可以应用于混合关键度系统调度，并取得了更好的近似结果。

Abstract: We are concerned with the problem of scheduling $n$ jobs onto $m$ identical
machines. Each machine has to be in operation for a prescribed time, and the
objective is to minimize the total machine working time. Precisely, let $c_i$
be the prescribed time for machine $i$, where $i\in[m]$, and $p_j$ be the
processing time for job $j$, where $j\in[n]$. The problem asks for a schedule
$\sigma\colon\, J\to M$ such that $\sum_{i=1}^m\max\{c_i,
\sum_{j\in\sigma^{-1}(i)}p_j\}$ is minimized, where $J$ and $M$ denote the sets
of jobs and machines, respectively. We show that First Fit Decreasing (FFD)
leads to a $1.5$-approximation, and this problem admits a polynomial-time
approximation scheme (PTAS). The idea is further applied to mixed-criticality
system scheduling to yield improved approximation results.

</details>


### [713] [An $n^{O(\log\log n)}$ time approximation scheme for capacitated VRP in the Euclidean plane](https://arxiv.org/abs/2507.15549)
*René Sitters*

Main category: cs.DS

TL;DR: 该研究为欧氏CVRP提供了一种更快的近似方案，并提出了一种可能有助于解决该问题的m-paths问题。


<details>
  <summary>Details</summary>
Motivation: 为了解决有容量车辆路径问题（CVRP），特别是欧氏空间中的CVRP，并朝着实现其PTAS的目标迈出重要一步。

Method: 提出了一种将CVRP（在任意固定维度d的ℝd中）归约到无容量路径问题（m-paths problem）的近似方案，该问题需要找到在两个点a和b之间恰好m条路径，并覆盖欧氏空间中给定的所有点。然后，为平面中的m-paths问题提供了一个Q-PTAS。

Result: 提出了一种用于欧氏CVRP的Q-PTAS，运行时间为n^f(ε)·loglogn，同时还提出了用于m-paths问题的Q-PTAS，这很可能意味着欧氏CVRP的PTAS。

Conclusion: 文章为在n个点上的欧氏平面无容量车辆路径问题（CVRP）提供了一个近似方案（Q-PTAS），其运行时间为n^f(ε)·loglogn，这是对先前已知运行时间的重大改进。

Abstract: We present a quasi polynomial time approximation scheme (Q-PTAS) for the
capacitated vehicle routing problem (CVRP) on $n$ points in the Euclidean plane
for arbitrary capacity $c$. The running time is $n^{f(\epsilon)\cdot\log\log
n}$ for any $c$, and where $f$ is a function of $\epsilon$ only. This is a
major improvement over the so far best known running time of
$n^{\log^{O(1/\epsilon)}n}$ time and a big step towards a PTAS for Euclidean
CVRP.
  In our algorithm, we first give a polynomial time reduction of the CVRP in
$\mathbb{R}^d$ (for any fixed $d$) to an uncapacitated routing problem in
$\mathbb{R}^d$ that we call the $m$-paths problem. Here, one needs to find
exactly $m$ paths between two points $a$ and $b$, covering all the given points
in the Euclidean space. We then give a Q-PTAS for the $m$-paths problem in the
pane. Any PTAS for the (arguably easier to handle) Euclidean $m$-paths problem
is most likely to imply a PTAS for the Euclidean CVRP.

</details>


### [714] [Fast Algorithms for Graph Arboricity and Related Problems](https://arxiv.org/abs/2507.15598)
*Ruoxu Cen,Henry Fleischmann,George Z. Li,Jason Li,Debmalya Panigrahi*

Main category: cs.DS

TL;DR: 该研究提出了计算加权无向图的树宽度和割层级的新算法，运行时间得到了显著改进。


<details>
  <summary>Details</summary>
Motivation: 该研究旨在提高计算加权无向图的树宽度和割层级的效率。

Method: 该算法通过对有向图全局最小割子程序进行对数次调用来实现，并在计算割层级方面取得进展。

Result: 研究提出了一个运行时间为 $\sqrt{n} m^{1+o(1)}$ 的算法，优于之前的最优界限。此外，还提出了一个运行时间为 $m n^{1+o(1)}$ 的新算法，用于计算割层级，优于之前的最优界限。

Conclusion: 该研究提出了计算加权无向图的树宽度和整个割层级的新算法。

Abstract: We give an algorithm for finding the arboricity of a weighted, undirected
graph, defined as the minimum number of spanning forests that cover all edges
of the graph, in $\sqrt{n} m^{1+o(1)}$ time. This improves on the previous best
bound of $\tilde{O}(nm)$ for weighted graphs and $\tilde{O}(m^{3/2}) $ for
unweighted graphs (Gabow 1995) for this problem. The running time of our
algorithm is dominated by a logarithmic number of calls to a directed global
minimum cut subroutine -- if the running time of the latter problem improves to
$m^{1+o(1)}$ (thereby matching the running time of maximum flow), the running
time of our arboricity algorithm would improve further to $m^{1+o(1)}$.
  We also give a new algorithm for computing the entire cut hierarchy --
laminar multiway cuts with minimum cut ratio in recursively defined induced
subgraphs -- in $m n^{1+o(1)}$ time. The cut hierarchy yields the ideal edge
loads (Thorup 2001) in a fractional spanning tree packing of the graph which,
we show, also corresponds to a max-entropy solution in the spanning tree
polytope. For the cut hierarchy problem, the previous best bound was
$\tilde{O}(n^2 m)$ for weighted graphs and $\tilde{O}(n m^{3/2})$ for
unweighted graphs.

</details>


### [715] [On zeros and algorithms for disordered systems: mean-field spin glasses](https://arxiv.org/abs/2507.15616)
*Ferenc Bencs,Kuikui Liu,Guus Regts*

Main category: cs.DS

TL;DR: 为自旋玻璃模型在均值场设定下，通过研究配分函数的零点位置，提供了一种确定性的准多项式时间算法，该算法在几乎所有逆温度下的第二个矩范围内都能以任意高的精度估计配分函数。


<details>
  <summary>Details</summary>
Motivation: 自旋玻璃是统计物理学、平均情况计算复杂性理论和现代高维统计推断的核心概率分布。

Method: 通过研究配分函数的零点位置来设计确定性的准多项式时间算法。

Result: 在均值场设定下，为几乎所有逆温度下的第二个矩范围内，以任意高的精度估计配分函数提供了确定性的准多项式时间算法。特别是对于 Sherrington-Kirkpatrick 模型，该算法在几乎整个副本对称相中都取得了成功。

Conclusion: 这项工作为自旋玻璃模型在接近所有逆温度下的平均情况复杂性理论和高维统计推断中提供了确定性的准多项式时间算法。

Abstract: Spin glasses are fundamental probability distributions at the core of
statistical physics, the theory of average-case computational complexity, and
modern high-dimensional statistical inference. In the mean-field setting, we
design deterministic quasipolynomial-time algorithms for estimating the
partition function to arbitrarily high accuracy for nearly all inverse
temperatures in the second moment regime. In particular, for the
Sherrington--Kirkpatrick model, our algorithms succeed for almost the entire
replica-symmetric phase. To achieve this, we study the locations of the zeros
of the partition function. Notably, our methods are conceptually simple, and
apply equally well to the spherical case and the case of Ising spins.

</details>


<div id='cs.DC'></div>

# cs.DC [[Back]](#toc)

### [716] [Characterizing Communication Patterns in Distributed Large Language Model Inference](https://arxiv.org/abs/2507.14392)
*Lang Xu,Kaushik Kandadi Suresh,Quentin Anthony,Nawras Alnaasan,Dhabaleswar K. Panda*

Main category: cs.DC

TL;DR: 分布式LLM服务中，张量并行速度快但通信开销大，流水线并行通信开销小但速度慢，混合并行需仔细调整。


<details>
  <summary>Details</summary>
Motivation: 解决了大规模语言模型（LLMs）在分布式服务中，跨GPU通信成为影响服务质量和性能的关键瓶颈这一问题。

Method: 通过详细的性能分析测量和预测性分析模型，研究了不同并行化方法（张量并行、流水线并行及混合方法）在分布式LLM服务中的通信行为和性能特征。

Result: 研究表明，张量并行会带来显著的网络开销但能为短序列提供更优的响应时间；流水线并行则能最小化数据传输量但会增加总延迟；混合并行方案则需要细致的参数调整以达到性能平衡。这些发现为生产环境下的LLM服务提供了实际的并行化方案选择建议，并指明了优化推理框架和通信的潜在方向。

Conclusion: LLM分布式服务的并行化方案选择需要根据具体应用场景进行权衡，例如，对于需要低响应时间的短序列推理，张量并行可能更优；而对于注重数据传输效率的场景，流水线并行则能更好地满足需求。未来的优化方向包括改进推理框架和通信基础设施。

Abstract: Large Language Models (LLMs) built on transformer architectures have
transformed natural language processing, achieving remarkable performance
across diverse applications. While distributed inference frameworks enable
practical deployment of these models, inter-GPU communication creates
significant performance constraints that limit service quality in real-world
systems. This paper investigates communication dynamics in distributed LLM
serving-analyzing how various parallelization approaches coordinate data
exchange between GPU workers during inference. We study dense transformer-based
models as representative examples of contemporary architectures widely used in
operational deployments. Our work combines detailed profiling measurements with
predictive analytical models to characterize communication behavior across
different parallelization configurations. Results show that tensor parallelism
incurs substantial network overhead but delivers superior response times for
brief sequences, pipeline parallelism minimizes data transfer requirements
while increasing total latency, and combined approaches demand careful tuning
to achieve balanced performance. These insights offer practical recommendations
for selecting appropriate parallelization schemes in production LLM services
and identify key opportunities for optimizing inference frameworks and
communication infrastructure.

</details>


### [717] [Towards a Proactive Autoscaling Framework for Data Stream Processing at the Edge using GRU and Transfer Learning](https://arxiv.org/abs/2507.14597)
*Eugene Armah,Linda Amoako Bannning*

Main category: cs.DC

TL;DR: 该研究提出了一种解决边缘流处理自动扩展问题的方法，通过GRU神经网络进行负载预测，并结合迁移学习和水平自动扩展模块，实现了对资源配置的动态调整，提高了效率并降低了资源浪费。


<details>
  <summary>Details</summary>
Motivation: 当前的边缘流处理（ESP）面临工作负载快速波动的问题，这使得资源配置复杂化。过度的资源分配会导致浪费，而不足的资源分配则会导致性能下降和违反服务等级协议（SLA）。现有的反应式方法（如基于阈值和排队论的策略）在性能下降后才进行扩展，而基于RL的方法需要大量模拟，预测性机器学习模型则面临在线分布和概念漂移问题。

Method: 该方法包括三个步骤：1. 使用GRU神经网络预测上游负载，并利用真实和合成的DSP数据集进行训练。2. 建立一个迁移学习框架，利用DTW算法和联合分布适应来处理离线和在线域的差异，并将预测模型集成到在线流处理系统中。3. 实现一个水平自动扩展模块，根据预测的负载并考虑边缘资源约束来动态调整算子并行度。

Result: GRU模型在真实数据集上的SMAPE值最高达到1.3%，在SMAPE和RMSE评估指标上均优于CNN、ARIMA和Prophet模型，并且训练时间比计算密集型的RL模型更短。

Conclusion: 所提出的预测模型通过GRU在真实数据集上达到了1.3%的SMAPE值，并且在SMAPE和RMSE评估指标上优于CNN、ARIMA和Prophet模型，同时训练时间也比计算密集型的RL模型更短。该方法通过结合预测模型、迁移学习框架和水平自动扩展模块，有效解决了边缘流处理的自动扩展问题，能够在考虑边缘资源限制的同时，根据预测负载动态调整算子并行度。

Abstract: Processing data at high speeds is becoming increasingly critical as digital
economies generate enormous data. The current paradigms for timely data
processing are edge computing and data stream processing (DSP). Edge computing
places resources closer to where data is generated, while stream processing
analyzes the unbounded high-speed data in motion. However, edge stream
processing faces rapid workload fluctuations, complicating resource
provisioning. Inadequate resource allocation leads to bottlenecks, whereas
excess allocation results in wastage. Existing reactive methods, such as
threshold-based policies and queuing theory scale only after performance
degrades, potentially violating SLAs. Although reinforcement learning (RL)
offers a proactive approach through agents that learn optimal runtime
adaptation policies, it requires extensive simulation. Furthermore, predictive
machine learning models face online distribution and concept drift that
minimize their accuracy. We propose a three-step solution to the proactive edge
stream processing autoscaling problem. Firstly, a GRU neural network forecasts
the upstream load using real-world and synthetic DSP datasets. Secondly, a
transfer learning framework integrates the predictive model into an online
stream processing system using the DTW algorithm and joint distribution
adaptation to handle the disparities between offline and online domains.
Finally, a horizontal autoscaling module dynamically adjusts the degree of
operator parallelism, based on predicted load while considering edge resource
constraints. The lightweight GRU model for load predictions recorded up to
1.3\% SMAPE value on a real-world data set. It outperformed CNN, ARIMA, and
Prophet on the SMAPE and RMSE evaluation metrics, with lower training time than
the computationally intensive RL models.

</details>


### [718] [Simulating Chirality: Solving Distance-$k$-Dispersion on an 1-Interval Connected Ring](https://arxiv.org/abs/2507.14723)
*Brati Mondal,Pritam Goswami,Buddhadeb Sau*

Main category: cs.DC

TL;DR: 该研究解决了无定性假设下同步移动智能体在环形网络中的距离-k-分散问题，提出了模拟定性的方法，证明了问题的可解性，并提供了一个O(ln)轮的算法。


<details>
  <summary>Details</summary>
Motivation: 研究同步移动智能体在1-间隔连通的环形网络中的距离-k-分散（D-k-D）问题，特别是无定性（无共同方向感）的假设，并试图解决Agarwalla等人提出的开放性问题。

Method: 提出了一种新颖的方法，允许智能体仅使用局部信息、视觉和有限内存来模拟定性，证明了定性并非智能体协调的根本要求。

Result: 证明了D-k-D问题（以及分散问题）在给定模型下（排除顶点置换动态性）对于任何大小的环形网络都是可解的，并且提出了一个能在O(ln)轮内解决D-k-D问题的算法。

Conclusion: 该研究证明了在无定性假设下，距离-k-分散（D-k-D）问题（包括经典的分散问题）是可解的，并且提出了一种能在O(ln)轮内解决D-k-D问题的算法。

Abstract: We study the Distance-$k$-Dispersion (D-$k$-D) problem for synchronous mobile
agents in a 1-interval-connected ring network having $n$ nodes and with $l$
agents where $3 \le l \le \lfloor \frac{n}{k}\rfloor$, without the assumption
of chirality (a common sense of direction for the agents). This generalizes the
classical dispersion problem by requiring that agents maintain a minimum
distance of $k$ hops from each other, with the special case $k=1$ corresponding
to the standard dispersion.
  The contribution in this work is threefold. Our first contribution is a novel
method that enables agents to simulate chirality using only local information,
vision and bounded memory. This technique demonstrates that chirality is not a
fundamental requirement for coordination in this model.
  Building on this, our second contribution partially resolves an open question
posed by Agarwalla et al. (ICDCN, 2018), who considered the same model (1-
interval connected ring, synchronous agents, no chirality). We prove that
D-$k$-D, and thus dispersion is solvable from any arbitrary configuration under
these assumptions (excluding vertex permutation dynamism)for any size of the
ring network which was earlier limited to only odd sized ring or to a ring of
size four.
  Finally, we present an algorithm for D-$k$-D in this setting that works in
$O(ln)$ rounds, completing the constructive side of our result.
  Altogether, our findings significantly extend the theoretical understanding
of mobile agent coordination in dynamic networks and clarify the role of
chirality in distributed computation.

</details>


### [719] [ACME: Adaptive Customization of Large Models via Distributed Systems](https://arxiv.org/abs/2507.14802)
*Ziming Dai,Chao Qiu,Fei Gao,Yunfeng Zhao,Xiaofei Wang*

Main category: cs.DC

TL;DR: ACME是一种创新的分布式系统方法，用于定制Transformer大模型，解决了云部署中的成本、隐私和性能问题。


<details>
  <summary>Details</summary>
Motivation: 为了解决在云环境中部署预训练Transformer大模型时面临的数据隐私和响应延迟挑战，以及直接应用这些模型时遇到的模型不匹配、资源限制和能源效率低下等问题，需要对模型进行定制化设计。然而，集中的模型定制成本高昂，且用户和数据的异质性导致性能不均衡和次优。

Method: ACME是一种自适应定制Transformer大模型的方法，采用双向单回路分布式系统进行细粒度的协同模型定制。首先，在模型尺寸约束下定制主干生成并识别帕累托前沿以优化资源利用。然后，通过基于数据分布的个性化架构聚合进行头部生成和模型精炼，以匹配数据异质性。

Result: ACME实现了成本效益，将数据传输量减少到6%，平均准确率提高10%，权衡指标增加近30%。

Conclusion: ACME通过分布式系统实现了Transformer大模型的自适应定制，在模型尺寸约束下实现了成本效益，减少了6%的数据传输量，并使平均准确率提高了10%，而权衡指标增加了近30%。

Abstract: Pre-trained Transformer-based large models have revolutionized personal
virtual assistants, but their deployment in cloud environments faces challenges
related to data privacy and response latency. Deploying large models closer to
the data and users has become a key research area to address these issues.
However, applying these models directly often entails significant difficulties,
such as model mismatching, resource constraints, and energy inefficiency.
Automated design of customized models is necessary, but it faces three key
challenges, namely, the high cost of centralized model customization,
imbalanced performance from user heterogeneity, and suboptimal performance from
data heterogeneity. In this paper, we propose ACME, an adaptive customization
approach of Transformer-based large models via distributed systems. To avoid
the low cost-efficiency of centralized methods, ACME employs a bidirectional
single-loop distributed system to progressively achieve fine-grained
collaborative model customization. In order to better match user heterogeneity,
it begins by customizing the backbone generation and identifying the Pareto
Front under model size constraints to ensure optimal resource utilization.
Subsequently, it performs header generation and refines the model using data
distribution-based personalized architecture aggregation to match data
heterogeneity. Evaluation on different datasets shows that ACME achieves
cost-efficient models under model size constraints. Compared to centralized
systems, data transmission volume is reduced to 6 percent. Additionally, the
average accuracy improves by 10 percent compared to the baseline, with the
trade-off metrics increasing by nearly 30 percent.

</details>


### [720] [Byzantine-Robust Decentralized Coordination of LLM Agents](https://arxiv.org/abs/2507.14928)
*Yongrae Jo,Chanik Park*

Main category: cs.DC

TL;DR: DecentLLMs 是一种新的去中心化共识方法，用于多主体 LLM 系统，它可以容忍拜占庭代理并选择更高质量的答案。


<details>
  <summary>Details</summary>
Motivation: 最近的拜占庭鲁棒多主体系统通常依赖于领导者驱动的协调，这存在两个主要缺点：1. 它们容易受到针对领导者的定向攻击。2. 即使存在更高质量的替代方案，领导者的表现不佳的提议仍可能被接受。

Method: 提出了一种名为 DecentLLMs 的新颖的去中心化共识方法，其中工作代理并发生成答案，评估代理独立评估和排名这些答案以选择最佳可用答案。

Result: 实验结果表明，DecentLLMs 能够有效容忍拜占庭代理，并显著提高了所选答案的质量。

Conclusion: DecentLLMs 能够有效容忍拜占庭代理，并通过拜占庭鲁棒聚合技术持续选择更高质量的答案。

Abstract: Collaboration among multiple large language model (LLM) agents is a promising
approach to overcome inherent limitations of single-agent systems, such as
hallucinations and single points of failure. As LLM agents are increasingly
deployed on open blockchain platforms, multi-agent systems capable of
tolerating malicious (Byzantine) agents have become essential.
  Recent Byzantine-robust multi-agent systems typically rely on leader-driven
coordination, which suffers from two major drawbacks. First, they are
inherently vulnerable to targeted attacks against the leader. If consecutive
leaders behave maliciously, the system repeatedly fails to achieve consensus,
forcing new consensus rounds, which is particularly costly given the high
latency of LLM invocations. Second, an underperforming proposal from the leader
can be accepted as the final answer even when higher-quality alternatives are
available, as existing methods finalize the leader's proposal once it receives
a quorum of votes.
  To address these issues, we propose DecentLLMs, a novel decentralized
consensus approach for multi-agent LLM systems, where worker agents generate
answers concurrently and evaluator agents independently score and rank these
answers to select the best available one. This decentralized architecture
enables faster consensus despite the presence of Byzantine agents and
consistently selects higher-quality answers through Byzantine-robust
aggregation techniques.
  Experimental results demonstrate that DecentLLMs effectively tolerates
Byzantine agents and significantly improves the quality of selected answers.

</details>


### [721] [AMPED: Accelerating MTTKRP for Billion-Scale Sparse Tensor Decomposition on Multiple GPUs](https://arxiv.org/abs/2507.15121)
*Sasindu Wijeratne,Rajgopal Kannan,Viktor Prasanna*

Main category: cs.DC

TL;DR: AMPED是一种多GPU并行算法，用于加速大规模稀疏张量分解中的MTTKRP计算。


<details>
  <summary>Details</summary>
Motivation: MTTKRP是稀疏张量分解的计算瓶颈，随着真实稀疏张量的规模增大，需要更高的内存容量和计算吞吐量。

Method: AMPED是一个多GPU并行算法，采用分区策略和动态负载均衡方案来加速MTTKRP。

Result: AMPED在处理包含数十亿非零元素的稀疏张量时，扩展性超越了单GPU的限制。

Conclusion: AMPED在4个GPU上实现了5.1倍的几何平均加速比，满足了大规模稀疏张量分解的内存和性能需求。

Abstract: Matricized Tensor Times Khatri-Rao Product (MTTKRP) is the computational
bottleneck in sparse tensor decomposition. As real-world sparse tensors grow to
billions of nonzeros, they increasingly demand higher memory capacity and
compute throughput from hardware accelerators. In this work, we present AMPED,
a multi-GPU parallel algorithm designed to accelerate MTTKRP on billion-scale
sparse tensors. AMPED scales beyond the limits of a single GPU, meeting both
the memory and performance requirements of large-scale workloads. We introduce
a partitioning strategy combined with a dynamic load balancing scheme to
distribute computation and minimize GPU idle time. On real-world billion-scale
tensors, AMPED achieves a 5.1x geometric mean speedup in total execution time
over state-of-the-art GPU baselines using 4 GPUs on a single CPU node.

</details>


### [722] [Dynatune: Dynamic Tuning of Raft Election Parameters Using Network Measurement](https://arxiv.org/abs/2507.15154)
*Kohya Shiozaki,Junya Nakamura*

Main category: cs.DC

TL;DR: Dynatune是一种动态调整Raft选举参数以减少非服务（OTS）时间的机制，可应对网络波动。


<details>
  <summary>Details</summary>
Motivation: 传统Raft算法在调整选举参数方面存在挑战，特别是在网络条件波动的情况下，这会导致更长的非服务（OTS）时间。

Method: 提出了一种名为Dynatune的机制，该机制根据通过心跳测量的往返时间和丢包率等网络指标动态调整Raft的选举参数。

Result: Dynatune将领导者故障检测和非服务（OTS）时间分别减少了80%和45%，同时在高可用性甚至动态网络条件下保持了高可用性。

Conclusion: Dynatune通过根据诸如往返时间和丢包率等网络指标动态调整Raft的选举参数，显著减少了领导者故障检测和非服务（OTS）时间，同时保持了高可用性。

Abstract: Raft is a leader-based consensus algorithm that implements State Machine
Replication (SMR), which replicates the service state across multiple servers
to enhance fault tolerance. In Raft, the servers play one of three roles:
leader, follower, or candidate. The leader receives client requests, determines
the processing order, and replicates them to the followers. When the leader
fails, the service must elect a new leader to continue processing requests,
during which the service experiences an out-of-service (OTS) time. The OTS time
is directly influenced by election parameters, such as heartbeat interval and
election timeout. However, traditional approaches, such as Raft, often struggle
to effectively tune these parameters, particularly under fluctuating network
conditions, leading to increased OTS time and reduced service responsiveness.
To address this, we propose Dynatune, a mechanism that dynamically adjusts
Raft's election parameters based on network metrics such as round-trip time and
packet loss rates measured via heartbeats. By adapting to changing network
environments, Dynatune significantly reduces the leader failure detection and
OTS time without altering Raft's core mechanisms or introducing additional
communication overheads. Experimental results demonstrate that Dynatune reduces
the leader failure detection and OTS times by 80% and 45%, respectively,
compared with Raft, while maintaining high availability even under dynamic
network conditions. These findings confirm that Dynatune effectively enhances
the performance and reliability of SMR services in various network scenarios.

</details>


### [723] [GALE: Leveraging Heterogeneous Systems for Efficient Unstructured Mesh Data Analysis](https://arxiv.org/abs/2507.15230)
*Guoxi Liu,Thomas Randall,Rong Ge,Federico Iuricich*

Main category: cs.DC

TL;DR: GALE是一种新颖的GPU加速数据结构，可显著提高非结构化网格的可视化性能。


<details>
  <summary>Details</summary>
Motivation: 解决非结构化网格在科学数据分析中的挑战，特别是计算和存储连接信息是可视化算法的主要瓶颈，影响时间和内存性能。

Method: 提出了一种新颖的任务并行方法，该方法针对异构CPU-GPU系统进行了优化，并将网格连接信息的计算卸载到GPU线程，使CPU线程能够专注于执行可视化算法。在此范例的基础上，提出了GALE（GPU辅助的本地化数据结构），这是第一个用于异构任务并行的开源CUDA基础数据结构。

Result: GALE实现了高达2.7倍的速度提升，并且与最先进的本地化数据结构相比，内存效率相当。

Conclusion: GALE通过将网格连接信息的计算卸载到GPU线程，实现了比最先进的本地化数据结构高2.7倍的速度提升，同时保持了内存效率。

Abstract: Unstructured meshes present challenges in scientific data analysis due to
irregular distribution and complex connectivity. Computing and storing
connectivity information is a major bottleneck for visualization algorithms,
affecting both time and memory performance. Recent task-parallel data
structures address this by precomputing connectivity information at runtime
while the analysis algorithm executes, effectively hiding computation costs and
improving performance. However, existing approaches are CPU-bound, forcing the
data structure and analysis algorithm to compete for the same computational
resources, limiting potential speedups. To overcome this limitation, we
introduce a novel task-parallel approach optimized for heterogeneous CPU-GPU
systems. Specifically, we offload the computation of mesh connectivity
information to GPU threads, enabling CPU threads to focus on executing the
visualization algorithm. Following this paradigm, we propose GALE (GPU-Aided
Localized data structurE), the first open-source CUDA-based data structure
designed for heterogeneous task parallelism. Experiments on two 20-core CPUs
and an NVIDIA V100 GPU show that GALE achieves up to 2.7x speedup over
state-of-the-art localized data structures while maintaining memory efficiency.

</details>


### [724] [An ML-Driven Participant Selection Technique for Federated Recommendation System in Edge-Cloud Computing](https://arxiv.org/abs/2507.15233)
*Jintao Liu,Mohammad Goudarzi,Adel Nadjaran Toosi*

Main category: cs.DC

TL;DR: 本研究提出了一种基于多目标强化学习的参与者选择方法，以提高联邦推荐系统的效率和公平性，解决了现有方法在设备异构性、数据分布和通信方面的挑战。


<details>
  <summary>Details</summary>
Motivation: 现有的联邦推荐系统（FRS）虽然具有设备端特征提取和隐私保护的优点，但存在设备能力异构、数据非独立同分布（non-IID）以及通信瓶颈等问题。

Method: 提出了一种多目标强化学习（RL）参与者选择方法，该方法通过联合优化历史客户性能声誉（CPR）、数据效用和系统效率来解决异构设备能力、非IID数据和通信瓶颈问题。首先定义了一个结合CPR、系统能力和数据质量的综合客户效用函数。然后将该效用嵌入到多armed bandit（MAB）框架中，并动态平衡探索-利用以选择参与者。

Result: 与现有的FRS基线相比，所提出的MAB方法在目标AUC收敛时间和总训练时间方面分别提高了32-50%和46%，同时保持或略微提高了最终的AUC、NDCG@50和Recall@50。

Conclusion: 多目标强化学习参与者选择可以显著提高实际联邦部署中的效率和公平性。

Abstract: Recommendation systems (RS) personalize content by analyzing user
preferences, but typically require centralized collection of user data, raising
privacy and scalability concerns. Federated Recommendation Systems (FRS)
address these issues by enabling distributed, privacy-preserving model training
across edge devices, keeping raw data on-device. Although existing FRS
frameworks benefit from on-device feature extraction and privacy preservation,
they suffer from heterogeneous device capabilities, non-independent and
identically distributed (non-IID) data, and communication bottlenecks. To
overcome these limitations, we propose a multi-objective reinforcement learning
(RL) participant selection that jointly optimizes historical client performance
reputation (CPR), data utility, and system efficiency. First, we define a
composite client-utility function combining CPR, system capability, and data
quality. Next, we embed this utility into a multi-armed bandit (MAB) framework
and dynamically balance exploration-exploitation to select participants.
Finally, we practically implement our approach using the PySyft framework on an
edge-cloud testbed, and evaluate it on a multimodal movie-recommendation task
built from the MovieLens-100K dataset. Across four different skewed
data-partition scenarios, our MAB-based selection accelerates convergence by
32-50% in time-to-target AUC and reduces total wall-clock training time by up
to 46%, while matching or slightly improving final AUC, NDCG@50, and Recall@50
compared to existing FRS baselines. Our results demonstrate that adaptive,
reward-driven client sampling can substantially enhance both efficiency and
fairness in real-world federated deployments.

</details>


### [725] [Efficient Routing of Inference Requests across LLM Instances in Cloud-Edge Computing](https://arxiv.org/abs/2507.15553)
*Shibo Yu,Mohammad Goudarzi,Adel Nadjaran Toosi*

Main category: cs.DC

TL;DR: 该研究提出了一种基于 NSGA-II 的自适应路由算法，以优化云边环境中 LLM 推理服务的延迟和成本。


<details>
  <summary>Details</summary>
Motivation: 为了应对 LLM 推理服务日益增长的需求所带来的计算资源压力、延迟和成本挑战。

Method: 提出了一种基于 NSGA-II 的新颖路由算法，将 LLM 推理请求分配到云边环境中的异构 LLM 实例。该算法将问题公式化为多目标优化问题，以平衡响应质量、响应时间和推理成本，并能适应请求异质性和节点多样性。

Result: 与基线方法相比，该算法在响应时间和成本方面分别取得了高达 95.2% 和 34.9% 的改进，验证了其在可扩展 LLM 部署中的有效性。

Conclusion: 该自适应路由算法通过在云边计算环境中利用 NSGA-II 来优化 LLM 推理服务的性能，在响应时间、成本和请求异质性方面取得了显著的改进。

Abstract: The rising demand for Large Language Model (LLM) inference services has
intensified pressure on computational resources, resulting in latency and cost
challenges. This paper introduces a novel routing algorithm based on the
Non-dominated Sorting Genetic Algorithm II (NSGA-II) to distribute inference
requests across heterogeneous LLM instances in a cloud-edge computing
environment. Formulated as a multi-objective optimization problem, the
algorithm balances response quality, response time, and inference cost,
adapting to request heterogeneity (e.g., varying complexity and prompt lengths)
and node diversity (e.g., edge vs. cloud resources). This adaptive routing
algorithm optimizes performance under dynamic workloads. We benchmark the
approach using a testbed with datasets including Stanford Question Answering
Dataset (SQuAD), Mostly Basic Python Problems (MBPP), Hella Situations With
Adversarial Generations (HellaSwag), and Grade School Math 8K (GSM8K).
Experimental results show our solution, compared to the baselines, achieves up
to 95.2% and 34.9% improvements in terms of response time and cost,
respectively. These findings validate the algorithm's effectiveness for
scalable LLM deployments.

</details>


<div id='physics.app-ph'></div>

# physics.app-ph [[Back]](#toc)

### [726] [What do Large Language Models know about materials?](https://arxiv.org/abs/2507.14586)
*Adrian Ehrenhofer,Thomas Wallmersperger,Gianaurelio Cuniberti*

Main category: physics.app-ph

TL;DR: LLM在材料科学领域应用需要谨慎，现有模型在准确性方面存在不足，需要进一步优化和评估。


<details>
  <summary>Details</summary>
Motivation: 评估现有LLM在材料科学领域应用的能力，特别是其生成准确材料信息的能力，以确定其在“处理-结构-性质-性能”（PSPP）链中的适用性。

Method: 通过分析LLM在处理周期表数据时的表现，评估其在材料科学知识生成方面的能力，并提出一个材料知识基准。

Result: 研究结果表明，LLM在处理材料科学信息时存在挑战，其输出的准确性受到词汇和标记化的影响。需要根据具体任务选择合适的模型，并可能需要专门的模型来处理特定任务。

Conclusion: LLM在材料科学中具有潜力，但需要对特定领域的知识进行优化和评估，以确保准确性。

Abstract: Large Language Models (LLMs) are increasingly applied in the fields of
mechanical engineering and materials science. As models that establish
connections through the interface of language, LLMs can be applied for
step-wise reasoning through the Processing-Structure-Property-Performance chain
of material science and engineering. Current LLMs are built for adequately
representing a dataset, which is the most part of the accessible internet.
However, the internet mostly contains non-scientific content. If LLMs should be
applied for engineering purposes, it is valuable to investigate models for
their intrinsic knowledge -- here: the capacity to generate correct information
about materials. In the current work, for the example of the Periodic Table of
Elements, we highlight the role of vocabulary and tokenization for the
uniqueness of material fingerprints, and the LLMs' capabilities of generating
factually correct output of different state-of-the-art open models. This leads
to a material knowledge benchmark for an informed choice, for which steps in
the PSPP chain LLMs are applicable, and where specialized models are required.

</details>


### [727] [Model of dark current in silicon-based barrier impurity band infrared detector devices](https://arxiv.org/abs/2507.14923)
*Mengyang Cui,Chengduo Hu,Qing Li,Hongxing Qi*

Main category: physics.app-ph

TL;DR: A new model explains dark current in infrared detectors at low voltages, while another model covers the entire voltage range.


<details>
  <summary>Details</summary>
Motivation: The motivation is to explain the parabolic-like dark current behavior observed at low bias voltages in silicon-based blocked impurity band (BIB) infrared detectors, which has been a critical limitation on device performance.

Method: This paper proposes a chiral-phonon-assisted spin current model at interfaces and utilizes spatially-confined charge transport theory.

Result: The study explains the dark current behavior in BIB infrared detectors using two theoretical models.

Conclusion: The study proposes a novel model involving chiral-phonon-assisted spin current at interfaces to explain the parabolic-like dark current behavior at low bias voltages in silicon-based BIB infrared detectors. It also employs spatially-confined charge transport theory to clarify the dark current generation mechanism across the entire operational voltage range.

Abstract: Dark current in silicon-based blocked impurity band (BIB) infrared detectors
has long been a critical limitation on device performance. This work proposes a
chiral-phonon-assisted spin current model at interfaces to explain the
parabolic-like dark current behavior observed at low bias voltages.
Concurrently, the spatially-confined charge transport theory is employed to
elucidate the dark current generation mechanism across the entire operational
voltage range.

</details>


### [728] [A rediscovery of stiff pentmodes. A comment on "High bulk modulus pentamodes: the three-dimensional metal water"](https://arxiv.org/abs/2507.15014)
*Graeme W. Milton*

Main category: physics.app-ph

TL;DR: Brambilla et.al. 聲稱發現新型五模材料設計是錯誤的，作者早在 2016 年就已設計出包含該材料的五模材料。


<details>
  <summary>Details</summary>
Motivation: 指出 Brambilla et.al. 的研究中存在不正确的说法，即他们发现了新型五模材料设计。

Method: 通过引用先前的工作来反驳 Brambilla et.al. 的研究结果。

Result: Briane, Harutyunyan 和作者在 2016 年就已经设计了一种包含 Brambilla et.al. 的高体积模量五模材料的刚性五模材料。

Conclusion: Brambilla et.al. 的研究结果是错误的，他们发现的新型五模材料设计并不新颖。

Abstract: We bring attention to the fact that the claim of Brambilla et.al. [Extreme
Mechanics Letters 74 (2025) 102267; arXiv:2406.14502] of discovering a novel
design for pentamode materials is incorrect. Back in 2016 Briane, Harutyunyan
and myself [Mathematics and Mechanics of Complex Systems 5 (2016) 41--94;
arXiv:1606.03305] designed a class of stiff pentamodes, that include the high
bulk modulus pentamodes of Brambilla et.al.

</details>


### [729] [An ultrasonic transducer for vibration mode conversion of wedge-shaped structure of acoustic black hole](https://arxiv.org/abs/2507.15218)
*Yi Wang,Cheng Chen,Shuyu Lin*

Main category: physics.app-ph

TL;DR: 本研究提出并验证了一种基于 ABH 结构的超声波模式转换换能器，该换能器可实现梯度声压分布，用于超声悬浮和粒子分选。


<details>
  <summary>Details</summary>
Motivation: 鉴于 ABH 结构在减振、降噪和能量收集等方面的应用，以及其在改善超声设备性能和构建多功能声场方面的潜力，本研究旨在探索 ABH 在超声悬浮和多功能粒子操纵中的应用。

Method: 利用 Timoshenko 梁理论和传递矩阵法建立了辐射板的弯曲振动理论模型，并通过有限元模拟（FES）研究了换能器的电声阻抗特性、振动模式和近场声压分布。

Result: 理论模型计算结果与有限元模拟结果吻合良好。模拟显示 ABH 楔形辐射板的幅值呈阶梯状增大，声压呈梯度分布。实验原型验证了有限元模拟的准确性和设计的可行性，并成功实现了超声悬浮和粒子分选。

Conclusion: 该研究提出了一种由 Langevin 换能器和 ABH 楔形辐射板组成的超声波模式转换换能器，并验证了其在超声波悬浮和多功能粒子操纵方面的应用潜力。实验结果表明，ABH 设计能够有效地在驻波声场中形成梯度声压分布，从而实现精确的粒子分选。

Abstract: Acoustic black hole (ABH) structure has been extensively employed in
applications such as vibration mitigation, noise reduction, and energy
harvesting, owing to its unique sound wave trapping and energy concentration
effects. Furthermore, ABH structure shows significant promise in improving the
performance of ultrasonic device and constructing multifunc-tional acoustic
field. Therefore, this paper proposes an ultrasonic mode-conversion transducer
consisting of a Langevin transducer and an ABH wedge radiant plate to
investigate the potential applications of ABH in ultrasonic levitation and
multifunctional particle manipulation. The theoretical model of flexural
vibration of the radiant plate is established by utilizing Timoshenko beam
theory and transfer matrix method, and the calculated vibration frequencies
demonstrated good agreement with those obtained from finite element simulations
(FES). The electrical impedance frequency response characteristics, vibration
modes and the near-field sound pressure distribution of the transducer in air
were also simulated. The results revealed that the amplitude of the ABH wedge
radiant plate increases stepwise, and the sound pressure exhibits a gradient
distribution. A prototype of the transducer was fabricated and experimentally
tested, confirming the accuracy of FES and the feasibility of the design
approach. Finally, the ultrasonic levitation experiment demonstrated that the
ABH design enables the formation of gradient distribution of sound pressure in
the standing wave sound field, thereby facilitating precise particle sorting.

</details>


### [730] [Improving 8x8 TeraFET array sensitivity through liquid-nitrogen cooling in a compact low-noise cryostat](https://arxiv.org/abs/2507.15323)
*Jakob Holstein,Nicholas K. North,Arne Hof,Sanchit Kondawar,Dmytro B. But,Mohammed Salih,Lianhe Li,Edmund H. Linfield,A. Giles Davies,Joshua R. Freeman,Alexander Valavanis,Alvydas Lisauskas,Hartmut G. Roskos*

Main category: physics.app-ph

TL;DR: 该研究提出了一种液氮温区工作的TeraFET探测系统，在3 THz附近实现了高灵敏度、宽动态范围和高时间分辨率，适用于空间任务。


<details>
  <summary>Details</summary>
Motivation: 为了在太赫兹频段，特别是3 THz附近，实现快速、灵敏且不需要氦冷却的光谱探测，本研究旨在开发一种可在较高温度下工作（如液氮温区）的TeraFET探测系统。

Method: 本工作首先对最近开发的结晶天线耦合太赫兹场效应晶体管（TeraFET）探测器在540 GHz下的噪声等效功率（NEP）进行了定量评估，测量温度低至20 K。在此基础上，研究人员设计并实现了一个紧凑、低噪声、液氮冷却（77 K）的TeraFET功率探测系统，用于光谱学应用。该系统采用商用65 nm Si-CMOS工艺制造，包含一个8x8像素的探测器阵列，优化工作在2.85-3.4 THz频段。

Result: 在2.85 THz下，该系统实现了超过67 dB的线性动态范围（在1 Hz检测带宽下），-3 dB的检测带宽达到5 MHz，远超传统热探测器（通常为1 kHz），能够实现低至亚微秒级的时间分辨太赫兹光谱学。

Conclusion: 该系统具有良好的温度适应性、紧凑的设计，特别适用于空间和载荷受限的平台，如气球和卫星任务，因为其深低温冷却是不切实际的。

Abstract: The sensitivity of antenna-coupled field-effect transistors (TeraFETs) to
terahertz (THz) radiation has been shown to improve continuously with
decreasing temperature. In this work, we first present a quantitative
evaluation of the temperature-dependent noise-equivalent power (NEP) of
recently developed patch-antenna-coupled TeraFET detectors resonant at 540 GHz,
with measurements down to 20 K. Based on these results, we project NEP values
approaching 1 to 2 pW/$\sqrt{\textrm{Hz}}$ under efficient power
coupling-comparable to state-of-the-art superconducting niobium transition-edge
sensors (TESs) operated at 4 K. Building on these findings in the sub-1 THz
range, a compact, low-noise, liquid-nitrogen-cooled (77 K) TeraFET power
detection system for spectroscopy applications was realized. The system
incorporates an 8$\times$8 pixel-binned detector array fabricated in a
commercial 65 nm Si-CMOS process, optimized for operation in the 2.85- to 3.4
THz band, where fast, sensitive and spectrally specific detectors that do not
require helium cooling remain scarce. Final system characterization was
performed in the focal plane of a 2.85-THz quantum-cascade laser delivering
approximately 2 mW of optical power. An experimental linear dynamic range
exceeding 67 dB was achieved without saturation (for 1 Hz-detection bandwidth).
The system provides a -3 dB detection bandwidth of 5 MHz vastly exceeding that
of conventional thermal detectors (typically 1-kHz), thus potentially enabling
advanced applications such as time-resolved THz spectroscopy down to the
sub-$\mu$s scale. Combined with its broad temperature operability and compact
design, the system is particularly well suited for space- and
payload-constrained platforms such as balloon- and satellite-based missions,
where deep cryogenic cooling is impractical.

</details>


### [731] [Hyperelastic nature of the Hoek-Brown criterion](https://arxiv.org/abs/2507.15813)
*Ilaria Fontana,Goustan Bacquaert,Daniele A. Di Pietro,Kyrylo Kazymyrenko*

Main category: physics.app-ph

TL;DR: 提出了一种新的弹塑性模型，将非线性弹性与塑性相结合，并证明了其在有限元模拟中的有效性。


<details>
  <summary>Details</summary>
Motivation: 通过将线性屈服准则关联到与塑性相关的热力学力，在应力空间中得到二次屈服准则，从而将Mohr-Coulomb与Hoek-Brown或Drucker-Prager与Pan-Hudson屈服准则联系起来。

Method: 提出了一种非线性弹塑性模型，其中双曲弹性是屈服准则不变性的直接结果。将此非线性弹性行为与服从相关流动法则的可塑性叠加。

Result: 与使用线性或建议的双曲弹性的Drucker-Prager屈服准则的标准测试的弹塑性响应进行了比较，发现非线性情况在三轴压缩试验的循环加载中表现出独特的应变软化现象。

Conclusion: 该模型具有数值适用性，在三轴压缩试验的循环加载中表现出应变软化现象。

Abstract: We propose a nonlinear elasto-plastic model, for which a specific class of
hyperbolic elasticity arises as a straight consequence of the yield criterion
invariance on the plasticity level. We superimpose this nonlinear elastic (or
hyperelastic) behavior with plasticity obeying the associated flow rule.
Interestingly, we find that a linear yield criterion on the thermodynamical
force associated with plasticity results in a quadratic yield criterion in the
stress space. This suggests a specific hyperelastic connection between
Mohr-Coulomb and Hoek-Brown (or alternatively between Drucker-Prager and
Pan-Hudson) yield criteria. We compare the elasto-plastic responses of standard
tests for the Drucker-Prager yield criterion using either linear or the
suggested hyperbolic elasticity. Notably, the nonlinear case stands out due to
dilatancy saturation observed during cyclic loading in the triaxial compression
test. We conclude this study with structural finite element simulations that
clearly demonstrate the numerical applicability of the proposed model.

</details>


<div id='cs.SI'></div>

# cs.SI [[Back]](#toc)

### [732] [Discipline and Resistance: The Construction of a Digital Home for TikTok Refugees on Xiaohongshu](https://arxiv.org/abs/2507.14465)
*Xiaoyu Xiong,Yuting Peng,Summer Kwong,Anqi Huang*

Main category: cs.SI

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: This study examines how TikTok refugees moved to Xiaohongshu after TikTok was
about to be banned in the United States. It utilizes Foucault's idea of
heterotopia to demonstrate how Xiaohongshu became a crisis space for
cross-cultural discussions across the Great Firewall. Through Critical
Discourse Analysis of 586 user comments, the study reveals how Chinese and
international users collaboratively constructed and contested a new online
order through language negotiation, identity positioning, and playful platform
policing. The findings highlight distinct discursive strategies between
domestic and overseas users, reflecting both cultural resistance and
adaptation. This research contributes to the understanding of digital
migration, heterotopic spaces in social media, and emerging dynamics of
cross-cultural discourse during geopolitical crises.

</details>


### [733] [Rejection or Inclusion in the Emotion-Identity Dynamics of TikTok Refugees on RedNote](https://arxiv.org/abs/2507.14623)
*Mingchen Li,Wenbo Xu,Wenqing Gu,Yixuan Xie,Yao Zhou,Yunsong Dai,Cheng Tan,Pan Hui*

Main category: cs.SI

TL;DR: 本研究分析了中国用户与“TikTok难民”在中国社交媒体上的互动。中国用户在文化话题上表达自豪，在政治话题上表达愤怒和鄙视。亲外用户普遍表达负面情绪，而中立用户则表达好奇和喜悦。与外貌相关的内容互动最为均衡，而政治话题则导致了最高程度的两极分化。


<details>
  <summary>Details</summary>
Motivation: 本研究旨在 examining cross-cultural interactions between Chinese users and self-identified "TikTok Refugees"(foreign users who migrated to RedNote after TikTok

Method: 本研究基于1,862个帖子和403,054条评论的数据集，利用大型语言模型进行情感分类，并使用BERT进行主题建模，以探究两类群体如何参与TikTok难民现象。研究分析了外国用户表达的主题、中国用户的回应方式、不同立场（亲华、中立、亲外）如何影响情感表达，以及跨主题和身份的情感反应差异。

Result: 研究结果显示，情感不对称性显著：中国用户对不同主题和立场的反应情感强度各异，文化主题中以自豪和赞扬为主，而政治讨论则引发高度的鄙视和愤怒，尤其是来自亲华评论者。亲外用户在所有主题中表现出最强烈负面情绪，而中立用户则表达好奇和喜悦，但仍会强化主流话语规范。跨主题比较表明，与外貌相关的内容互动最为均衡，而政治则产生最高程度的两极分化。

Conclusion: 该研究揭示了中外在线互动中独特的“情感-立场”结构，并为跨国数字公众中的身份协商提供了实证见解。

Abstract: This study examines cross-cultural interactions between Chinese users and
self-identified "TikTok Refugees"(foreign users who migrated to RedNote after
TikTok's U.S. ban). Based on a dataset of 1,862 posts and 403,054 comments, we
use large language model-based sentiment classification and BERT-based topic
modelling to explore how both groups engage with the TikTok refugee phenomenon.
We analyse what themes foreign users express, how Chinese users respond, how
stances (Pro-China, Neutral, Pro-Foreign) shape emotional expression, and how
affective responses differ across topics and identities. Results show strong
affective asymmetry: Chinese users respond with varying emotional intensities
across topics and stances: pride and praise dominate cultural threads, while
political discussions elicit high levels of contempt and anger, especially from
Pro-China commenters. Pro-Foreign users exhibit the strongest negative emotions
across all topics, whereas neutral users express curiosity and joy but still
reinforce mainstream discursive norms. Cross-topic comparisons reveal that
appearance-related content produces the most emotionally balanced interactions,
while politics generates the highest polarization. Our findings reveal distinct
emotion-stance structures in Sino-foreign online interactions and offer
empirical insights into identity negotiation in transnational digital publics.

</details>


### [734] [Forecasting Faculty Placement from Patterns in Co-authorship Networks](https://arxiv.org/abs/2507.14696)
*Samantha Dies,David Liu,Tina Eliassi-Rad*

Main category: cs.SI

TL;DR: 本研究通过分析学术招聘中的共作者网络，发现其比传统指标（如博士学位授予部门声望和发表记录）更能提高预测准确性，尤其是在顶尖部门的招聘中，这表明社会网络和专业认可在学术招聘中起着重要作用，并有助于识别和解决学术界的结构性偏见。


<details>
  <summary>Details</summary>
Motivation: 传统研究虽然发现了教职招聘与博士学位授予部门声望和发表记录等属性之间的相关性，但很少评估这些关联是否能推广到个体招聘结果，特别是对于原始样本之外的未来候选人。本研究旨在填补这一空白。

Method: 本研究将教职placement视为一项个体层面的预测任务，利用包括博士学位授予部门声望和文献计量特征在内的传统属性，结合时间共作者网络数据进行分析。

Result: 研究发现，与仅使用传统指标相比，利用共作者网络可以将预测准确度显著提高多达10%，其中在最顶尖（前10名）的部门，预测准确度的提升最为显著。

Conclusion: 该研究结果强调了社会网络、专业认可和隐性倡导在学术招聘中超越传统学术成果和机构声望指标的作用。通过引入学术职位分配的预测框架并确立考虑合著者网络的益处，本研究为理解学术界的结构性偏见提供了一个新的视角，有助于为提高学术招聘实践的透明度、公平性和平等性提供有针对性的干预措施。

Abstract: Faculty hiring shapes the flow of ideas, resources, and opportunities in
academia, influencing not only individual career trajectories but also broader
patterns of institutional prestige and scientific progress. While traditional
studies have found strong correlations between faculty hiring and attributes
such as doctoral department prestige and publication record, they rarely assess
whether these associations generalize to individual hiring outcomes,
particularly for future candidates outside the original sample. Here, we
consider faculty placement as an individual-level prediction task. Our data
consist of temporal co-authorship networks with conventional attributes such as
doctoral department prestige and bibliometric features. We observe that using
the co-authorship network significantly improves predictive accuracy by up to
10% over traditional indicators alone, with the largest gains observed for
placements at the most elite (top-10) departments. Our results underscore the
role that social networks, professional endorsements, and implicit advocacy
play in faculty hiring beyond traditional measures of scholarly productivity
and institutional prestige. By introducing a predictive framing of faculty
placement and establishing the benefit of considering co-authorship networks,
this work provides a new lens for understanding structural biases in academia
that could inform targeted interventions aimed at increasing transparency,
fairness, and equity in academic hiring practices.

</details>


### [735] [Efficient Algorithms for Relevant Quantities of Friedkin-Johnsen Opinion Dynamics Model](https://arxiv.org/abs/2507.14864)
*Gengyu Wang,Runze Zhang,Zhongzhi Zhang*

Main category: cs.SI

TL;DR: 提出了一种高效的算法，用于分析社交网络中的意见形成，能够处理大规模网络并比传统方法更快地计算结果。


<details>
  <summary>Details</summary>
Motivation: 为了解决在大型在线社交网络中计算意见形成均衡向量及相关指标（如极化和分歧）的计算挑战，并改进现有方法的效率和可扩展性。

Method: 提出了一种确定性局部算法，并结合了超松弛（Successive Over-Relaxation, SOR）技术来加速收敛。该算法能够计算均衡意见向量以及相关的度量指标（如极化和分歧），适用于有向和无向网络。

Result: 所提出的算法在计算效率和可扩展性方面表现出色，能够处理超过千万节点的大型网络，并在真实数据集的实验中显示出优于传统方法的性能。

Conclusion: 该研究提出了一种确定性局部算法，并结合了超松弛技术，用于高效计算在线社交网络中的意见形成均衡向量，以及相关的极化和分歧指标。该算法具有相对误差保证，能够扩展到拥有千万级节点的大型网络，并在各种真实网络上进行了广泛的实验验证，证明了其在计算效率和可扩展性方面相比传统方法具有显著优势。

Abstract: Online social networks have become an integral part of modern society,
profoundly influencing how individuals form and exchange opinions across
diverse domains ranging from politics to public health. The Friedkin-Johnsen
model serves as a foundational framework for modeling opinion formation
dynamics in such networks. In this paper, we address the computational task of
efficiently determining the equilibrium opinion vector and associated metrics
including polarization and disagreement, applicable to both directed and
undirected social networks. We propose a deterministic local algorithm with
relative error guarantees, scaling to networks exceeding ten million nodes.
Further acceleration is achieved through integration with successive
over-relaxation techniques, where a relaxation factor optimizes convergence
rates. Extensive experiments on diverse real-world networks validate the
practical effectiveness of our approaches, demonstrating significant
improvements in computational efficiency and scalability compared to
conventional methods.

</details>


### [736] [Comprehensive Privacy Risk Assessment in Social Networks Using User Attributes Social Graphs and Text Analysis](https://arxiv.org/abs/2507.15124)
*Md Jahangir Alam,Ismail Hossain,Sai Puppala,Sajedul Talukder*

Main category: cs.SI

TL;DR: 提出 CPRS 框架，量化社交网络隐私风险，整合用户属性、社交图和内容。在真实数据集中验证有效性，用户研究证明其实用性。


<details>
  <summary>Details</summary>
Motivation: 社交网络平台的兴起加剧了隐私威胁，因为用户越来越多地在个人资料、内容和社交连接中分享敏感信息。

Method: CPRS 框架整合了用户属性、社交图结构和用户生成内容，利用敏感性、可见性、结构相似性和实体级别分析来计算跨维度的风险评分，最后将它们汇总为统一的风险评分。

Result: CPRS 在两个真实数据集（SNAP Facebook Ego Network 和 Koo 微博客数据集）上进行了验证。平均 CPRS 为 0.478（等权重），在图敏感场景下为 0.501。其中，基于图的风险（平均 0.52）高于内容（0.48）和个人资料属性（0.45）。电子邮件、出生日期和手机号码是高风险属性。用户研究表明 85% 的参与者认为仪表板清晰且可操作。

Conclusion: 该工作提出了一种名为 CPRS 的综合隐私风险评分框架，用于量化社交网络中的隐私风险。该框架通过整合用户属性、社交图结构和用户生成内容来计算风险评分，并已在两个真实世界的数据集上进行了验证。用户研究表明该框架具有实用性，可为个性化隐私风险洞察提供支持，并为隐私管理提供了一种整体且可扩展的方法。

Abstract: The rise of social networking platforms has amplified privacy threats as
users increasingly share sensitive information across profiles, content, and
social connections. We present a Comprehensive Privacy Risk Scoring (CPRS)
framework that quantifies privacy risk by integrating user attributes, social
graph structures, and user-generated content. Our framework computes risk
scores across these dimensions using sensitivity, visibility, structural
similarity, and entity-level analysis, then aggregates them into a unified risk
score. We validate CPRS on two real-world datasets: the SNAP Facebook Ego
Network (4,039 users) and the Koo microblogging dataset (1M posts, 1M
comments). The average CPRS is 0.478 with equal weighting, rising to 0.501 in
graph-sensitive scenarios. Component-wise, graph-based risks (mean 0.52)
surpass content (0.48) and profile attributes (0.45). High-risk attributes
include email, date of birth, and mobile number. Our user study with 100
participants shows 85% rated the dashboard as clear and actionable, confirming
CPRS's practical utility. This work enables personalized privacy risk insights
and contributes a holistic, scalable methodology for privacy management. Future
directions include incorporating temporal dynamics and multimodal content for
broader applicability.

</details>


### [737] [Privacy-Preserving Multimodal News Recommendation through Federated Learning](https://arxiv.org/abs/2507.15460)
*Mehdi Khalaj,Shahrzad Golestani Najafabadi,Julita Vassileva*

Main category: cs.SI

TL;DR: 该研究提出了一种结合多模态学习和联邦学习的新闻推荐方法，有效解决了传统推荐系统在内容表示、用户兴趣捕捉和隐私保护方面的不足，并在真实数据实验中取得了更好的效果。


<details>
  <summary>Details</summary>
Motivation: 传统的个性化新闻推荐系统（PNR）在应对信息过载方面发挥着重要作用，但它们通常过度依赖文本内容，忽略用户的短期兴趣，并且由于中心化数据存储而引发严重的隐私担忧。为了解决这些问题，本研究旨在开发一种能够整合多模态信息、同时关注用户长期和短期兴趣，并能有效保护用户隐私的新闻推荐方法。

Method: 本研究提出了一种结合多模态学习和联邦学习的新闻推荐方法。首先，利用多模态模型融合新闻的文本和视觉特征；其次，采用时序感知模型和多头自注意力网络来平衡用户的长期和短期兴趣；最后，通过联邦学习框架在不共享用户数据的情况下进行协同模型训练，并将推荐模型划分为服务器维护的新闻模型和客户端共享的用户模型。客户端在本地计算梯度并发送至服务器进行聚合更新，同时采用基于Shamir秘密共享的安全聚合算法进一步增强隐私保护。

Result: 实验结果表明，所提出的基于多模态联邦学习的新闻推荐方法在真实数据集上取得了优于现有系统的性能，证明了该方法在整合多模态信息、平衡用户兴趣以及保护用户隐私方面的有效性。

Conclusion: 该研究提出了一种新颖的基于多模态联邦学习的新闻推荐方法，通过整合文本和视觉特征、考虑短期用户兴趣以及采用联邦学习框架来解决传统个性化新闻推荐系统面临的挑战，并在真实数据集上进行了实验，证明了其相对于现有系统的优越性能，是隐私保护个性化新闻推荐领域的一项重要进展。

Abstract: Personalized News Recommendation systems (PNR) have emerged as a solution to
information overload by predicting and suggesting news items tailored to
individual user interests. However, traditional PNR systems face several
challenges, including an overreliance on textual content, common neglect of
short-term user interests, and significant privacy concerns due to centralized
data storage. This paper addresses these issues by introducing a novel
multimodal federated learning-based approach for news recommendation. First, it
integrates both textual and visual features of news items using a multimodal
model, enabling a more comprehensive representation of content. Second, it
employs a time-aware model that balances users' long-term and short-term
interests through multi-head self-attention networks, improving recommendation
accuracy. Finally, to enhance privacy, a federated learning framework is
implemented, enabling collaborative model training without sharing user data.
The framework divides the recommendation model into a large server-maintained
news model and a lightweight user model shared between the server and clients.
The client requests news representations (vectors) and a user model from the
central server, then computes gradients with user local data, and finally sends
their locally computed gradients to the server for aggregation. The central
server aggregates gradients to update the global user model and news model. The
updated news model is further used to infer news representation by the server.
To further safeguard user privacy, a secure aggregation algorithm based on
Shamir's secret sharing is employed. Experiments on a real-world news dataset
demonstrate strong performance compared to existing systems, representing a
significant advancement in privacy-preserving personalized news recommendation.

</details>
