<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 63]
- [cs.CL](#cs.CL) [Total: 44]
- [cs.SI](#cs.SI) [Total: 2]
- [cs.GT](#cs.GT) [Total: 4]
- [cs.MA](#cs.MA) [Total: 3]
- [cs.AR](#cs.AR) [Total: 5]
- [cs.RO](#cs.RO) [Total: 21]
- [cs.LO](#cs.LO) [Total: 3]
- [cs.ET](#cs.ET) [Total: 2]
- [cs.AI](#cs.AI) [Total: 32]
- [cs.NE](#cs.NE) [Total: 3]
- [cs.DC](#cs.DC) [Total: 6]
- [eess.SP](#eess.SP) [Total: 13]
- [physics.app-ph](#physics.app-ph) [Total: 3]
- [eess.SY](#eess.SY) [Total: 24]
- [cs.LG](#cs.LG) [Total: 78]
- [cond-mat.mes-hall](#cond-mat.mes-hall) [Total: 12]
- [quant-ph](#quant-ph) [Total: 52]
- [cs.GR](#cs.GR) [Total: 1]
- [cond-mat.mtrl-sci](#cond-mat.mtrl-sci) [Total: 15]
- [cs.DS](#cs.DS) [Total: 9]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [LoRA-Edge: Tensor-Train-Assisted LoRA for Practical CNN Fine-Tuning on Edge Devices](https://arxiv.org/abs/2511.03765)
*Hyunseok Kwak,Kyeongwon Lee,Jae-Jin Lee,Woojoo Lee*

Main category: cs.CV

TL;DR: LoRA-Edge是一种参数高效的微调方法，通过张量-分解（TT-SVD）和选择性更新，在保持推理成本不变的情况下，显著减少了可训练参数数量，实现了在资源受限的边缘设备上的高效微调，并能在多种数据集上达到接近全量微调的准确率。


<details>
  <summary>Details</summary>
Motivation: 为了在内存、计算和能源预算受限的边缘应用（如人类活动识别）中应对域漂移，需要对卷积神经网络（CNN）进行设备端微调，但全量微调不可行。

Method: LoRA-Edge方法首先对预训练的卷积层应用张量-奇异值分解（TT-SVD），然后选择性地仅更新输出端核心，并采用零初始化以确保辅助路径初始不激活，最后将更新融合回密集卷积核，从而不改变推理成本。

Result: LoRA-Edge将可训练参数数量减少了两个数量级，实现了与全量微调相近的准确率（差距在4.7%以内），同时仅更新1.49%的参数。在Jetson Orin Nano上的实验表明，TT-SVD初始化和选择性核心训练使收敛速度提高了1.4-3.8倍。

Conclusion: LoRA-Edge使得与结构对齐的、参数高效的设备端CNN模型适配在边缘平台上变得可行。

Abstract: On-device fine-tuning of CNNs is essential to withstand domain shift in edge
applications such as Human Activity Recognition (HAR), yet full fine-tuning is
infeasible under strict memory, compute, and energy budgets. We present
LoRA-Edge, a parameter-efficient fine-tuning (PEFT) method that builds on
Low-Rank Adaptation (LoRA) with tensor-train assistance. LoRA-Edge (i) applies
Tensor-Train Singular Value Decomposition (TT-SVD) to pre-trained convolutional
layers, (ii) selectively updates only the output-side core with
zero-initialization to keep the auxiliary path inactive at the start, and (iii)
fuses the update back into dense kernels, leaving inference cost unchanged.
This design preserves convolutional structure and reduces the number of
trainable parameters by up to two orders of magnitude compared to full
fine-tuning. Across diverse HAR datasets and CNN backbones, LoRA-Edge achieves
accuracy within 4.7% of full fine-tuning while updating at most 1.49% of
parameters, consistently outperforming prior parameter-efficient baselines
under similar budgets. On a Jetson Orin Nano, TT-SVD initialization and
selective-core training yield 1.4-3.8x faster convergence to target F1.
LoRA-Edge thus makes structure-aligned, parameter-efficient on-device CNN
adaptation practical for edge platforms.

</details>


### [2] [Near-Lossless 3D Voxel Representation Free from Iso-surface](https://arxiv.org/abs/2511.04029)
*Yihao Luo,Xianglong He,Chuanyu Pan,Yiwen Chen,Jiaqi Wu,Yangguang Li,Wanli Ouyang,Yuanming Hu,Guang Yang,ChoonHwai Yap*

Main category: cs.CV

TL;DR: Faithful Contouring是一种新颖的稀疏体素化表示方法，能够以高分辨率（2048+）精确表示任意3D网格，无需水密性处理或渲染优化，并能保留几何细节。该方法还支持纹理、操作和编辑，并引入了双模态自编码器用于可扩展、保真度高的形状重建。


<details>
  <summary>Details</summary>
Motivation: 现有基于等值面的体素化表示方法在保证几何保真度方面存在不足，需要水密性处理或渲染优化。因此，需要一种能够高分辨率、精确表示任意3D网格，同时保留几何细节的体素化表示方法。

Method: 提出了一种名为Faithful Contouring的稀疏体素化表示方法，支持2048+分辨率，适用于任意网格，无需网格到场函数转换或重网格化时的等值面提取。通过保留锐度和内部结构来实现近乎无损的保真度。此外，设计了一种双模态自编码器用于Faithful Contouring，以实现可扩展且保真度高的形状重建。

Result: Faithful Contouring在直接表示方面达到了$10^{-5}$级别的距离误差。在网格重建方面，与现有方法相比，它将Chamfer Distance降低了93%，F-score提高了35%，证明了其在3D学习任务中的优越保真度。

Conclusion: Faithful Contouring作为一种3D学习任务的表示方法，在准确性和效率方面均优于现有方法，能够实现高精度、高保真度的3D网格表示和重建。

Abstract: Accurate and efficient voxelized representations of 3D meshes are the
foundation of 3D reconstruction and generation. However, existing
representations based on iso-surface heavily rely on water-tightening or
rendering optimization, which inevitably compromise geometric fidelity. We
propose Faithful Contouring, a sparse voxelized representation that supports
2048+ resolutions for arbitrary meshes, requiring neither converting meshes to
field functions nor extracting the isosurface during remeshing. It achieves
near-lossless fidelity by preserving sharpness and internal structures, even
for challenging cases with complex geometry and topology. The proposed method
also shows flexibility for texturing, manipulation, and editing. Beyond
representation, we design a dual-mode autoencoder for Faithful Contouring,
enabling scalable and detail-preserving shape reconstruction. Extensive
experiments show that Faithful Contouring surpasses existing methods in
accuracy and efficiency for both representation and reconstruction. For direct
representation, it achieves distance errors at the $10^{-5}$ level; for mesh
reconstruction, it yields a 93\% reduction in Chamfer Distance and a 35\%
improvement in F-score over strong baselines, confirming superior fidelity as a
representation for 3D learning tasks.

</details>


### [3] [SILVI: Simple Interface for Labeling Video Interactions](https://arxiv.org/abs/2511.03819)
*Ozan Kanbertay,Richard Vogg,Elif Karakoc,Peter M. Kappeler,Claudia Fichtel,Alexander S. Ecker*

Main category: cs.CV

TL;DR: SILVI是一款开源标注软件，用于自动分析动物行为和互动，以弥补现有工具的不足，并可用于其他需要提取动态场景图的视频分析。


<details>
  <summary>Details</summary>
Motivation: 现有工具在行为标注或个体定位方面存在不足，无法有效捕捉动物间的互动，而互动是理解动物社会行为的关键。SILVI旨在弥补这一差距。

Method: SILVI是一款集成了个体定位和行为/互动标注功能的开源标注软件，能够直接在视频数据中进行标注，并生成结构化输出，适用于训练和验证计算机视觉模型。

Result: SILVI能够直接在视频数据中标注行为和互动，生成适合训练和验证计算机视觉模型的结构化输出。

Conclusion: SILVI通过整合行为生态学与计算机视觉，促进了精细行为分析的自动化方法的发展，并可广泛应用于需要提取动态场景图的视频分析，如人类互动分析。

Abstract: Computer vision methods are increasingly used for the automated analysis of
large volumes of video data collected through camera traps, drones, or direct
observations of animals in the wild. While recent advances have focused
primarily on detecting individual actions, much less work has addressed the
detection and annotation of interactions -- a crucial aspect for understanding
social and individualized animal behavior. Existing open-source annotation
tools support either behavioral labeling without localization of individuals,
or localization without the capacity to capture interactions. To bridge this
gap, we present SILVI, an open-source labeling software that integrates both
functionalities. SILVI enables researchers to annotate behaviors and
interactions directly within video data, generating structured outputs suitable
for training and validating computer vision models. By linking behavioral
ecology with computer vision, SILVI facilitates the development of automated
approaches for fine-grained behavioral analyses. Although developed primarily
in the context of animal behavior, SILVI could be useful more broadly to
annotate human interactions in other videos that require extracting dynamic
scene graphs. The software, along with documentation and download instructions,
is available at: https://gitlab.gwdg.de/kanbertay/interaction-labelling-app.

</details>


### [4] [Noise Injection: Improving Out-of-Distribution Generalization for Limited Size Datasets](https://arxiv.org/abs/2511.03855)
*Duong Mai,Lawrence Hall*

Main category: cs.CV

TL;DR: 通过在训练中加入高斯噪声、斑点噪声、泊松噪声和椒盐噪声等基本噪声注入技术，可以显著减少COVID-19检测模型在分布外（OOD）数据上的性能下降。


<details>
  <summary>Details</summary>
Motivation: 深度学习模型在图像识别，特别是从胸部X光片（CXRs）检测COVID-19方面，存在泛化能力不足的问题，因为模型倾向于利用特定来源的伪影（捷径）而不是真正的生物标志物来最大化在分布内（ID）数据的性能，这使得模型在面对新的临床数据来源时表现不佳。

Method: 在训练过程中，研究者采用了基本噪声注入技术，包括高斯噪声、斑点噪声、泊松噪声和椒盐噪声，以提高模型对分布变化的鲁棒性。

Result: 实验结果表明，这种噪声注入技术能够显著缩小ID和OOD评估之间的性能差距，从0.10-0.20的范围降低到0.01-0.06。该结果是基于在十个随机种子上的平均结果，并考虑了AUC、F1、准确率、召回率和特异性等关键指标。

Conclusion: 本研究提出的噪声注入技术能够有效提高深度学习模型在COVID-19检测任务中的泛化能力，显著降低模型在分布外数据上的性能损失，为构建更可靠的医学影像诊断模型提供了有价值的见解。

Abstract: Deep learned (DL) models for image recognition have been shown to fail to
generalize to data from different devices, populations, etc. COVID-19 detection
from Chest X-rays (CXRs), in particular, has been shown to fail to generalize
to out-of-distribution (OOD) data from new clinical sources not covered in the
training set. This occurs because models learn to exploit shortcuts -
source-specific artifacts that do not translate to new distributions - rather
than reasonable biomarkers to maximize performance on in-distribution (ID)
data. Rendering the models more robust to distribution shifts, our study
investigates the use of fundamental noise injection techniques (Gaussian,
Speckle, Poisson, and Salt and Pepper) during training. Our empirical results
demonstrate that this technique can significantly reduce the performance gap
between ID and OOD evaluation from 0.10-0.20 to 0.01-0.06, based on results
averaged over ten random seeds across key metrics such as AUC, F1, accuracy,
recall and specificity. Our source code is publicly available at
https://github.com/Duongmai127/Noisy-ood

</details>


### [5] [Investigating Robot Control Policy Learning for Autonomous X-ray-guided Spine Procedures](https://arxiv.org/abs/2511.03882)
*Florence Klitzner,Blanca Inigo,Benjamin D. Killeen,Lalithkumar Seenivasan,Michelle Song,Axel Krieger,Mathias Unberath*

Main category: cs.CV

TL;DR: 基于模仿学习的机器人控制策略在 X 光引导下椎弓根螺钉置入术中应用潜力巨大，但仍面临挑战。


<details>
  <summary>Details</summary>
Motivation: 视频引导的机器人控制策略在机器人领域受到广泛关注，但其在 X 光引导下的应用，尤其是在脊柱内固定手术中的可行性尚不明确，因为多视角 X 光图像的解读非常复杂。

Method: 研究者开发了一个 in silico 模拟环境，用于模拟 X 光引导下的脊柱手术，并生成了包含正确轨迹和相应 X 光图像序列的数据集。他们训练了模仿学习策略，仅基于视觉信息规划和控制，以实现套管针的对齐。

Result: 该策略在 68.5% 的情况下首次尝试就成功了，并在不同的椎体水平上保持了安全的椎弓根内轨迹。策略能够泛化到包括骨折在内的复杂解剖结构，并且对不同的初始化条件保持鲁棒性。在真实 X 光图像上的测试表明，模型能够生成合理的轨迹，尽管它仅在模拟环境中训练。

Conclusion: 模仿学习策略在 X 光引导下的椎弓根螺钉置入术中显示出巨大潜力，尤其是在模拟环境中训练后能够泛化到复杂情况。然而，在入口点精度方面仍存在局限性，并且完全闭环控制需要更频繁的反馈。通过引入更强的先验知识和领域知识，这类模型有望为未来开发轻量级、无需 CT 的机器人术中脊柱导航奠定基础。

Abstract: Imitation learning-based robot control policies are enjoying renewed interest
in video-based robotics. However, it remains unclear whether this approach
applies to X-ray-guided procedures, such as spine instrumentation. This is
because interpretation of multi-view X-rays is complex. We examine
opportunities and challenges for imitation policy learning in bi-plane-guided
cannula insertion. We develop an in silico sandbox for scalable, automated
simulation of X-ray-guided spine procedures with a high degree of realism. We
curate a dataset of correct trajectories and corresponding bi-planar X-ray
sequences that emulate the stepwise alignment of providers. We then train
imitation learning policies for planning and open-loop control that iteratively
align a cannula solely based on visual information. This precisely controlled
setup offers insights into limitations and capabilities of this method. Our
policy succeeded on the first attempt in 68.5% of cases, maintaining safe
intra-pedicular trajectories across diverse vertebral levels. The policy
generalized to complex anatomy, including fractures, and remained robust to
varied initializations. Rollouts on real bi-planar X-rays further suggest that
the model can produce plausible trajectories, despite training exclusively in
simulation. While these preliminary results are promising, we also identify
limitations, especially in entry point precision. Full closed-look control will
require additional considerations around how to provide sufficiently frequent
feedback. With more robust priors and domain knowledge, such models may provide
a foundation for future efforts toward lightweight and CT-free robotic
intra-operative spinal navigation.

</details>


### [6] [Desert Waste Detection and Classification Using Data-Based and Model-Based Enhanced YOLOv12 DL Model](https://arxiv.org/abs/2511.03888)
*Abdulmumin Sa'ad,Sulaimon Oyeniyi Adebayo,Abdul Jabbar Siddiqui*

Main category: cs.CV

TL;DR: 该研究提出了一种基于轻量化YOLOv12、自对抗训练（SAT）和数据增强的增强型实时物体检测框架，用于在沙漠环境中检测垃圾，显著提高了检测精度和效率。


<details>
  <summary>Details</summary>
Motivation: 传统垃圾收集方法在偏远或恶劣环境中效率低下且危险，而现有自动化垃圾检测研究主要集中在城市环境和可回收物，忽视了有机物、危险废物以及沙漠等未被充分探索的地形。

Method: 提出一种基于剪枝的轻量化YOLOv12模型，并结合自对抗训练（SAT）和专门的数据增强策略。

Result: 在DroneTrashNet数据集上，该模型在精度、召回率和平均精度（mAP）方面取得了显著改进，同时实现了低延迟和紧凑的模型尺寸，适用于资源受限的航空无人机部署。与最先进的轻量级YOLO变体相比，该模型在准确性和效率之间取得了最佳平衡。

Conclusion: 结合以数据为中心和以模型为中心的增强措施，可以有效地实现沙漠环境中鲁棒、实时的垃圾检测。

Abstract: The global waste crisis is escalating, with solid waste generation expected
to increase by 70% by 2050. Traditional waste collection methods, particularly
in remote or harsh environments like deserts, are labor-intensive, inefficient,
and often hazardous. Recent advances in computer vision and deep learning have
opened the door to automated waste detection systems, yet most research focuses
on urban environments and recyclable materials, overlooking organic and
hazardous waste and underexplored terrains such as deserts. In this work, we
propose an enhanced real-time object detection framework based on a pruned,
lightweight version of YOLOv12 integrated with Self-Adversarial Training (SAT)
and specialized data augmentation strategies. Using the DroneTrashNet dataset,
we demonstrate significant improvements in precision, recall, and mean average
precision (mAP), while achieving low latency and compact model size suitable
for deployment on resource-constrained aerial drones. Benchmarking our model
against state-of-the-art lightweight YOLO variants further highlights its
optimal balance of accuracy and efficiency. Our results validate the
effectiveness of combining data-centric and model-centric enhancements for
robust, real-time waste detection in desert environments.

</details>


### [7] [Improving Diagnostic Performance on Small and Imbalanced Datasets Using Class-Based Input Image Composition](https://arxiv.org/abs/2511.03891)
*Hlali Azzeddine,Majid Ben Yakhlef,Soulaiman El Hazzat*

Main category: cs.CV

TL;DR: 深度学习模型在处理小样本、类别不平衡和低质量图像时，容易出现高错误率。本文提出了一种名为“类别图像合成”（Class-Based Image Composition）的方法，通过融合同一类别的多张图像生成“合成输入图像”（CoImg），以增强类内方差、提高信息密度，从而提升模型区分细微病变模式的能力。该方法在OCTDL数据集（包含7种疾病，存在显著类别不平衡）上进行了评估，并构建了一个类别平衡的Co-OCTDL数据集。与原始数据集相比，使用Co-OCTDL数据集训练的VGG16模型在类别平衡的设置下，准确率达到99.6%，F1分数达到0.995，AUC达到0.9996，显著降低了错误预测率，证明了该方法在处理弱数据集（类别不平衡或样本量小）方面的有效性。


<details>
  <summary>Details</summary>
Motivation: 深度学习模型在处理小样本、类别不平衡和低质量图像时，容易出现高错误率，这在医学图像分析中尤其关键。本研究旨在通过一种新的数据合成方法来解决这些挑战。

Method: 提出了一种名为“类别图像合成”（Class-Based Image Composition）的方法，通过融合同一类别的多张图像生成“合成输入图像”（CoImg）。在OCTDL数据集上构建了一个类别平衡的版本Co-OCTDL，并将原始图像排列成3x1的合成图像。使用VGG16模型，在原始数据集和Co-OCTDL数据集上进行对比实验，保持模型架构和超参数一致。

Result: 与在原始数据集上训练的基线模型相比，在Co-OCTDL数据集上训练的模型取得了显著的诊断结果提升。具体而言，准确率达到99.6%，F1分数达到0.995，AUC达到0.9996。错误预测率也显著降低。

Conclusion: 类别图像合成方法（Class-Based Image Composition）能够有效提升深度学习模型在处理类别不平衡和样本量小等挑战性数据集上的表现，生成高质量的预测结果。

Abstract: Small, imbalanced datasets and poor input image quality can lead to high
false predictions rates with deep learning models. This paper introduces
Class-Based Image Composition, an approach that allows us to reformulate
training inputs through a fusion of multiple images of the same class into
combined visual composites, named Composite Input Images (CoImg). That enhances
the intra-class variance and improves the valuable information density per
training sample and increases the ability of the model to distinguish between
subtle disease patterns. Our method was evaluated on the Optical Coherence
Tomography Dataset for Image-Based Deep Learning Methods (OCTDL) (Kulyabin et
al., 2024), which contains 2,064 high-resolution optical coherence tomography
(OCT) scans of the human retina, representing seven distinct diseases with a
significant class imbalance. We constructed a perfectly class-balanced version
of this dataset, named Co-OCTDL, where each scan is resented as a 3x1 layout
composite image. To assess the effectiveness of this new representation, we
conducted a comparative analysis between the original dataset and its variant
using a VGG16 model. A fair comparison was ensured by utilizing the identical
model architecture and hyperparameters for all experiments. The proposed
approach markedly improved diagnostic results.The enhanced Dataset achieved
near-perfect accuracy (99.6%) with F1-score (0.995) and AUC (0.9996), compared
to a baseline model trained on raw dataset. The false prediction rate was also
significantly lower, this demonstrates that the method can producehigh-quality
predictions even for weak datasets affected by class imbalance or small sample
size.

</details>


### [8] [I Detect What I Don't Know: Incremental Anomaly Learning with Stochastic Weight Averaging-Gaussian for Oracle-Free Medical Imaging](https://arxiv.org/abs/2511.03912)
*Nand Kumar Yadav,Rodrigue Rizk,William CW Chen,KC Santosh*

Main category: cs.CV

TL;DR: 该研究提出了一种无监督、无需领域专家指导的医学影像异常检测框架，通过增量扩展正常样本集来提高检测准确性。


<details>
  <summary>Details</summary>
Motivation: 医学影像中的未知异常检测面临标记样本稀缺和专家监督成本高昂的挑战。

Method: 该框架从少量已验证的正常图像开始，通过轻量级适配器更新和不确定性门控样本录取来逐步扩展正常的样本集。它使用冻结的预训练视觉骨干网络，并添加微小的卷积适配器，以实现快速的领域自适应和低计算开销。提取的嵌入被存储在一个紧凑的核心集中，用于高效的 k-NN 异常评分。通过双重概率门来确保增量扩展的安全性：只有当样本与现有核心集的距离在校准的 z 分数阈值内，并且其基于 SWAG 的认知不确定性低于根据种子校准的边界时，样本才会被录取到正常内存中。

Result: 在 COVID-CXR 数据集上，ROC-AUC 从 0.9489 提高到 0.9982（F1 值从 0.8048 提高到 0.9746）；在 Pneumonia CXR 数据集上，ROC-AUC 从 0.6834 提高到 0.8968；在 Brain MRI ND-5 数据集上，ROC-AUC 从 0.6041 提高到 0.7269，PR-AUC 从 0.7539 提高到 0.8211。

Conclusion: 该框架在处理现实世界中标记样本稀缺的医学影像应用方面，显示出有效性和高效率。

Abstract: Unknown anomaly detection in medical imaging remains a fundamental challenge
due to the scarcity of labeled anomalies and the high cost of expert
supervision. We introduce an unsupervised, oracle-free framework that
incrementally expands a trusted set of normal samples without any anomaly
labels. Starting from a small, verified seed of normal images, our method
alternates between lightweight adapter updates and uncertainty-gated sample
admission. A frozen pretrained vision backbone is augmented with tiny
convolutional adapters, ensuring rapid domain adaptation with negligible
computational overhead. Extracted embeddings are stored in a compact coreset
enabling efficient k-nearest neighbor anomaly (k-NN) scoring. Safety during
incremental expansion is enforced by dual probabilistic gates, a sample is
admitted into the normal memory only if its distance to the existing coreset
lies within a calibrated z-score threshold, and its SWAG-based epistemic
uncertainty remains below a seed-calibrated bound. This mechanism prevents
drift and false inclusions without relying on generative reconstruction or
replay buffers. Empirically, our system steadily refines the notion of
normality as unlabeled data arrive, producing substantial gains over baselines.
On COVID-CXR, ROC-AUC improves from 0.9489 to 0.9982 (F1: 0.8048 to 0.9746); on
Pneumonia CXR, ROC-AUC rises from 0.6834 to 0.8968; and on Brain MRI ND-5,
ROC-AUC increases from 0.6041 to 0.7269 and PR-AUC from 0.7539 to 0.8211. These
results highlight the effectiveness and efficiency of the proposed framework
for real-world, label-scarce medical imaging applications.

</details>


### [9] [Adaptive Temporal Refinement: Continuous Depth Allocation and Distance Regression for Efficient Action Localization](https://arxiv.org/abs/2511.03943)
*Ibne Farabi Shihab,Sanjeda Akter,Anuj Sharma*

Main category: cs.CV

TL;DR: 时间动作定位中的边界检测具有挑战性，现有方法计算不均。本文提出了边界距离回归（BDR）和自适应时间细化（ATR）两种方法。BDR通过有符号距离回归优化边界定位，提高了边界检测精度，并能轻松集成到现有方法中，带来性能提升。ATR通过动态分配计算资源（连续深度选择τ），在降低计算量的同时提高了定位精度，尤其在处理短动作时效果显著。知识蒸馏用于降低训练成本。


<details>
  <summary>Details</summary>
Motivation: 现有时间动作定位方法在处理不同难度的边界时采用统一的计算策略，未能有效利用计算资源并限制了定位精度。

Method: 1. 边界距离回归（BDR）：提出一种基于有符号距离回归（signed-distance regression）的方法，替代传统的分类方法，以实现信息论上最优的定位。2. 自适应时间细化（ATR）：通过引入连续深度选择τ∈[0,1]，动态分配计算资源，实现端到端的、可微的优化，无需强化学习。3. 知识蒸馏：用于缓解ATR带来的训练成本，使轻量级模型能保持高水平性能。

Result: BDR方法使边界峰值锐化43%，并能兼容现有方法，带来1.8%-3.1%的mAP@0.7提升。ATR在THUMOS14数据集上，以162G FLOPs的计算量达到了56.5%的mAP@0.7，相比之下，统一计算的方法在198G FLOPs下仅得到53.6%的mAP@0.7，计算量减少18%，性能提升2.9%。在短动作上的性能提升尤为显著（4.2%）。知识蒸馏使轻量级模型保留了99%的性能。

Conclusion: BDR和ATR是解决时间动作定位中边界检测挑战的有效方法。BDR通过精确的边界回归提高了定位精度，而ATR通过自适应计算分配提高了效率和性能。这两种方法相结合，为时间动作定位任务提供了更优的解决方案。

Abstract: Temporal action localization requires precise boundary detection; however,
current methods apply uniform computation despite significant variations in
difficulty across boundaries. We present two complementary contributions.
First, Boundary Distance Regression (BDR) provides information-theoretically
optimal localization through signed-distance regression rather than
classification, achieving 43\% sharper boundary peaks. BDR retrofits to
existing methods with approximately 50 lines of code, yielding consistent 1.8
to 3.1\% mAP@0.7 improvements across diverse architectures. Second, Adaptive
Temporal Refinement (ATR) allocates computation via continuous depth selection
$\tau \in [0,1]$, enabling end-to-end differentiable optimization without
reinforcement learning. On THUMOS14, ATR achieves 56.5\% mAP@0.7 at 162G FLOPs,
compared to 53.6\% at 198G for uniform processing, providing a 2.9\%
improvement with 18\% less compute. Gains scale with boundary heterogeneity,
showing 4.2\% improvement on short actions. Training cost is mitigated via
knowledge distillation, with lightweight students retaining 99\% performance at
baseline cost. Results are validated across four benchmarks with rigorous
statistical testing.

</details>


### [10] [Improving Multi-View Reconstruction via Texture-Guided Gaussian-Mesh Joint Optimization](https://arxiv.org/abs/2511.03950)
*Zhejia Cai,Puhua Jiang,Shiwei Mao,Hongkun Cao,Ruqi Huang*

Main category: cs.CV

TL;DR: 该论文提出了一种统一的框架，用于同时优化高斯-网格的几何和外观，以实现无缝的3D重建，支持下游编辑任务。


<details>
  <summary>Details</summary>
Motivation: 现有方法在几何精度和照片级渲染之间进行权衡，阻碍了下游编辑任务。本文旨在统一处理几何和外观优化。

Method: 提出了一种新颖的框架，通过高斯引导的网格可微分渲染，同时优化网格几何（顶点位置和面）和顶点颜色，并利用输入图像的光度一致性和法线/深度图的几何正则化。

Result: 实现了高质量的3D重建，可用于重新照明和形状变形等下游编辑任务。

Conclusion: 统一的几何和外观优化方法可以实现高质量的3D重建，并支持下游编辑任务。

Abstract: Reconstructing real-world objects from multi-view images is essential for
applications in 3D editing, AR/VR, and digital content creation. Existing
methods typically prioritize either geometric accuracy (Multi-View Stereo) or
photorealistic rendering (Novel View Synthesis), often decoupling geometry and
appearance optimization, which hinders downstream editing tasks. This paper
advocates an unified treatment on geometry and appearance optimization for
seamless Gaussian-mesh joint optimization. More specifically, we propose a
novel framework that simultaneously optimizes mesh geometry (vertex positions
and faces) and vertex colors via Gaussian-guided mesh differentiable rendering,
leveraging photometric consistency from input images and geometric
regularization from normal and depth maps. The obtained high-quality 3D
reconstruction can be further exploit in down-stream editing tasks, such as
relighting and shape deformation. The code will be publicly available upon
acceptance.

</details>


### [11] [A Linear Fractional Transformation Model and Calibration Method for Light Field Camera](https://arxiv.org/abs/2511.03962)
*Zhong Chen,Changfeng Chen*

Main category: cs.CV

TL;DR: 该论文提出了一种新颖的线性分数变换（LFT）参数 α，用于精确校准光场相机内部参数，从而实现 3D 重建。


<details>
  <summary>Details</summary>
Motivation: 准确校准光场相机的内部参数对于 3D 重建至关重要，但该过程充满挑战。

Method: 提出了一种基于 LFT 参数 α 的新方法，该方法将主透镜和微透镜阵列（MLA）解耦。该方法包括基于最小二乘法的解析解，随后进行非线性优化，并介绍了从原始图像中检测特征的方法。

Result: 在物理和模拟数据上的实验结果验证了该方法的性能。基于所提出的模型，原始光场图像的仿真速度更快，这对于数据驱动的深度学习方法至关重要。

Conclusion: 所提出的 LFT 参数 α 方法能够有效校准光场相机内部参数，并加速图像仿真，为 3D 重建和深度学习应用提供了有力的支持。

Abstract: Accurate calibration of internal parameters is a crucial yet challenging
prerequisite for 3D reconstruction using light field cameras. In this paper, we
propose a linear fractional transformation(LFT) parameter $\alpha$ to decoupled
the main lens and micro lens array (MLA). The proposed method includes an
analytical solution based on least squares, followed by nonlinear refinement.
The method for detecting features from the raw images is also introduced.
Experimental results on both physical and simulated data have verified the
performance of proposed method. Based on proposed model, the simulation of raw
light field images becomes faster, which is crucial for data-driven deep
learning methods. The corresponding code can be obtained from the author's
website.

</details>


### [12] [Room Envelopes: A Synthetic Dataset for Indoor Layout Reconstruction from Images](https://arxiv.org/abs/2511.03970)
*Sam Bahrami,Dylan Campbell*

Main category: cs.CV

TL;DR: 该研究提出了一个名为Room Envelopes的合成数据集，用于3D场景重建，特别是关注被遮挡的结构元素（如墙壁、地板、天花板）。


<details>
  <summary>Details</summary>
Motivation: 现有3D重建方法主要关注可见表面，忽略了被遮挡的结构元素。然而，场景的结构元素通常是简单且重复的，因此可以采用更经济的方法进行预测。

Method: 提出了一个名为Room Envelopes的合成数据集，其中包含RGB图像及其对应的点云图（包括可见表面和去除附属物后的结构布局）。该数据集可用于直接监督前馈单目几何估计器，以预测可见表面和结构布局表面。

Result: 该数据集能够帮助模型理解场景的范围以及物体的大小和位置。

Conclusion: Room Envelopes数据集为3D场景重建，特别是被遮挡结构元素的重建提供了新的研究途径。

Abstract: Modern scene reconstruction methods are able to accurately recover 3D
surfaces that are visible in one or more images. However, this leads to
incomplete reconstructions, missing all occluded surfaces. While much progress
has been made on reconstructing entire objects given partial observations using
generative models, the structural elements of a scene, like the walls, floors
and ceilings, have received less attention. We argue that these scene elements
should be relatively easy to predict, since they are typically planar,
repetitive and simple, and so less costly approaches may be suitable. In this
work, we present a synthetic dataset -- Room Envelopes -- that facilitates
progress on this task by providing a set of RGB images and two associated
pointmaps for each image: one capturing the visible surface and one capturing
the first surface once fittings and fixtures are removed, that is, the
structural layout. As we show, this enables direct supervision for feed-forward
monocular geometry estimators that predict both the first visible surface and
the first layout surface. This confers an understanding of the scene's extent,
as well as the shape and location of its objects.

</details>


### [13] [Simple 3D Pose Features Support Human and Machine Social Scene Understanding](https://arxiv.org/abs/2511.03988)
*Wenshuo Qin,Leyla Isik*

Main category: cs.CV

TL;DR: 人类通过3D姿态信息进行社交互动判断，AI模型应借鉴此思路。


<details>
  <summary>Details</summary>
Motivation: 当前AI视觉系统在理解人类社交互动方面仍有不足，我们假设这源于它们缺乏3D视觉空间姿态信息。

Method: 结合先进的姿态和深度估计算法提取视频片段中的3D人体关节位置，并将其与现有AI模型进行比较，以预测人类的社交互动判断。此外，我们还提取了描述面部3D位置和方向的精简3D社交姿态特征，并分析了AI模型对这些特征的表征能力。

Result: 3D关节位置的预测能力超过了大多数现有AI模型。精简的3D社交姿态特征与完整的3D关节信息具有相当的预测能力，并能显著提升AI模型的性能。AI模型对3D社交姿态特征的表征程度与其匹配人类社交判断的能力相关。

Conclusion: 人类的社交场景理解依赖于显式的3D姿态表征，并且可以由简单、结构化的视觉空间基元支持。

Abstract: Humans can quickly and effortlessly extract a variety of information about
others' social interactions from visual input, ranging from visuospatial cues
like whether two people are facing each other to higher-level information. Yet,
the computations supporting these abilities remain poorly understood, and
social interaction recognition continues to challenge even the most advanced AI
vision systems. Here, we hypothesized that humans rely on 3D visuospatial pose
information to make social interaction judgments, which is absent in most AI
vision models. To test this, we combined state-of-the-art pose and depth
estimation algorithms to extract 3D joint positions of people in short video
clips depicting everyday human actions and compared their ability to predict
human social interaction judgments with current AI vision models. Strikingly,
3D joint positions outperformed most current AI vision models, revealing that
key social information is available in explicit body position but not in the
learned features of most vision models, including even the layer-wise
embeddings of the pose models used to extract joint positions. To uncover the
critical pose features humans use to make social judgments, we derived a
compact set of 3D social pose features describing only the 3D position and
direction of faces in the videos. We found that these minimal descriptors
matched the predictive strength of the full set of 3D joints and significantly
improved the performance of off-the-shelf AI vision models when combined with
their embeddings. Moreover, the degree to which 3D social pose features were
represented in each off-the-shelf AI vision model predicted the model's ability
to match human social judgments. Together, our findings provide strong evidence
that human social scene understanding relies on explicit representations of 3D
pose and can be supported by simple, structured visuospatial primitives.

</details>


### [14] [CaRF: Enhancing Multi-View Consistency in Referring 3D Gaussian Splatting Segmentation](https://arxiv.org/abs/2511.03992)
*Yuwen Tao,Kanglei Zhou,Xin Tan,Yuan Xie*

Main category: cs.CV

TL;DR: CaRF是一个全微分框架，直接在3D高斯空间中操作，实现了多视图一致性，并在三个基准测试中取得了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的3D高斯分割方法在跨视图一致性方面存在不足，因为它们依赖于2D渲染的伪监督和特定视图的特征学习。

Method: CaRF引入了高斯场相机编码（GFCE），将相机几何纳入高斯文本交互，并提出了训练配对视图监督（ITPVS）来对齐每个高斯的逻辑，从而缓解单视图过拟合并暴露视图间差异。

Result: CaRF在Ref LERF、LERF OVS和3D OVS数据集上分别比现有最先进的方法提高了16.8%、4.3%和2.0%的mIoU。

Conclusion: CaRF在3D高斯分割任务上实现了最先进的性能，实现了可靠且视图一致的3D场景理解，对具身AI、AR/VR交互和自动驾驶感知有潜在益处。

Abstract: Referring 3D Gaussian Splatting Segmentation (R3DGS) aims to interpret
free-form language expressions and localize the corresponding 3D regions in
Gaussian fields. While recent advances have introduced cross-modal alignment
between language and 3D geometry, existing pipelines still struggle with
cross-view consistency due to their reliance on 2D rendered pseudo supervision
and view specific feature learning. In this work, we present Camera Aware
Referring Field (CaRF), a fully differentiable framework that operates directly
in the 3D Gaussian space and achieves multi view consistency. Specifically,
CaRF introduces Gaussian Field Camera Encoding (GFCE), which incorporates
camera geometry into Gaussian text interactions to explicitly model view
dependent variations and enhance geometric reasoning. Building on this, In
Training Paired View Supervision (ITPVS) is proposed to align per Gaussian
logits across calibrated views during training, effectively mitigating single
view overfitting and exposing inter view discrepancies for optimization.
Extensive experiments on three representative benchmarks demonstrate that CaRF
achieves average improvements of 16.8%, 4.3%, and 2.0% in mIoU over state of
the art methods on the Ref LERF, LERF OVS, and 3D OVS datasets, respectively.
Moreover, this work promotes more reliable and view consistent 3D scene
understanding, with potential benefits for embodied AI, AR/VR interaction, and
autonomous perception.

</details>


### [15] [PhysCorr: Dual-Reward DPO for Physics-Constrained Text-to-Video Generation with Automated Preference Selection](https://arxiv.org/abs/2511.03997)
*Peiyao Wang,Weining Wang,Qi Li*

Main category: cs.CV

TL;DR: 该研究提出了 PhysCorr 框架，通过 PhysicsRM 奖励模型和 PhyDPO 优化方法，提升文本到视频生成在物理规律方面的一致性，以满足具身智能、机器人和仿真等领域的需求。


<details>
  <summary>Details</summary>
Motivation: 当前文本到视频生成模型生成的视频在物理规律方面存在不足，例如物体运动不合理、交互不协调、运动模式不真实等问题，这限制了其在具身智能、机器人和仿真等领域的应用。因此，需要研究能够生成符合物理规律的视频内容的方法。

Method: 提出 PhysCorr 统一框架，包括 PhysicsRM 奖励模型（用于量化物体内部稳定性和物体间交互）和 PhyDPO（一种直接偏好优化方法，利用对比反馈和物理感知重加权来指导生成），该方法具有模型无关和可扩展性。

Result: 在多个基准测试中，PhysCorr 在保持视觉保真度和语义对齐的同时，显著提高了物理真实性。

Conclusion: PhysCorr 是朝着实现物理基础和可信赖的视频生成迈出的重要一步。

Abstract: Recent advances in text-to-video generation have achieved impressive
perceptual quality, yet generated content often violates fundamental principles
of physical plausibility - manifesting as implausible object dynamics,
incoherent interactions, and unrealistic motion patterns. Such failures hinder
the deployment of video generation models in embodied AI, robotics, and
simulation-intensive domains. To bridge this gap, we propose PhysCorr, a
unified framework for modeling, evaluating, and optimizing physical consistency
in video generation. Specifically, we introduce PhysicsRM, the first
dual-dimensional reward model that quantifies both intra-object stability and
inter-object interactions. On this foundation, we develop PhyDPO, a novel
direct preference optimization pipeline that leverages contrastive feedback and
physics-aware reweighting to guide generation toward physically coherent
outputs. Our approach is model-agnostic and scalable, enabling seamless
integration into a wide range of video diffusion and transformer-based
backbones. Extensive experiments across multiple benchmarks demonstrate that
PhysCorr achieves significant improvements in physical realism while preserving
visual fidelity and semantic alignment. This work takes a critical step toward
physically grounded and trustworthy video generation.

</details>


### [16] [GNN-MoE: Context-Aware Patch Routing using GNNs for Parameter-Efficient Domain Generalization](https://arxiv.org/abs/2511.04008)
*Mahmoud Soliman,Omar Abdelaziz,Ahmed Radwan,Anand,Mohamed Shehata*

Main category: cs.CV

TL;DR: GNN-MoE 通过引入基于图神经网络（GNN）的上下文感知路由机制，在参数高效微调（PEFT）框架下实现了高效的领域泛化（DG），在提高模型鲁棒性和泛化能力的同时，保持了参数效率。


<details>
  <summary>Details</summary>
Motivation: 标准的微调方法在处理预训练 Vision Transformer（ViT）模型进行领域泛化（DG）时成本高昂且可能损害泛化能力，因此需要更有效的适应方法。

Method: 提出 GNN-MoE，一种结合了图神经网络（GNN）路由器（GCN、GAT、SAGE）和混合专家（MoE）框架的参数高效微调（PEFT）方法。该方法通过在补丁间图上操作的 GNN 路由器动态地将图像补丁分配给专门的专家，而不是基于令牌的路由，从而利用补丁间的关系进行适应。

Result: GNN-MoE 在领域泛化（DG）基准测试中取得了最先进或具有竞争力的性能，同时保持了高参数效率。

Conclusion: 基于图的上下文感知路由对于实现鲁棒、轻量级的领域泛化（DG）非常有用。

Abstract: Domain generalization (DG) seeks robust Vision Transformer (ViT) performance
on unseen domains. Efficiently adapting pretrained ViTs for DG is challenging;
standard fine-tuning is costly and can impair generalization. We propose
GNN-MoE, enhancing Parameter-Efficient Fine-Tuning (PEFT) for DG with a
Mixture-of-Experts (MoE) framework using efficient Kronecker adapters. Instead
of token-based routing, a novel Graph Neural Network (GNN) router (GCN, GAT,
SAGE) operates on inter-patch graphs to dynamically assign patches to
specialized experts. This context-aware GNN routing leverages inter-patch
relationships for better adaptation to domain shifts. GNN-MoE achieves
state-of-the-art or competitive DG benchmark performance with high parameter
efficiency, highlighting the utility of graph-based contextual routing for
robust, lightweight DG.

</details>


### [17] [A Hybrid Deep Learning Model for Robust Biometric Authentication from Low-Frame-Rate PPG Signals](https://arxiv.org/abs/2511.04037)
*Arfina Rahman,Mahesh Banavar*

Main category: cs.CV

TL;DR: 该研究提出了一种基于光电容积脉搏波 (PPG) 信号的轻量级、低成本生物识别认证框架，通过结合卷积视觉变换器 (CVT)、ConvMixer 和长短期记忆网络 (LSTM) 的混合深度学习模型，在 CFIHSR 数据集上实现了 98% 的认证准确率，证明了其对噪声和受试者间变异性的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: PPG 信号因其非侵入性、固有的活体检测能力和低成本可穿戴设备的适用性，在生物识别认证领域受到关注。然而，运动伪影、光照变化和受试者间生理变异性对 PPG 信号质量提出了挑战，使得鲁棒的特征提取和分类至关重要。

Method: 从低帧率指尖视频中提取 PPG 信号。对原始 PPG 信号进行预处理，包括基线漂移去除、主成分分析 (PCA) 运动伪影抑制、带通滤波、傅里叶重采样和幅度归一化。使用连续小波变换 (CWT) 将一维 PPG 信号转换为二维时频标度图。开发了一个混合深度学习模型 CVT-ConvMixer-LSTM，结合了 CVT 和 ConvMixer 的空间特征以及 LSTM 的时间特征。

Result: 在包含 46 名受试者 PPG 记录的 CFIHSR 数据集上进行的实验证明，所提出的模型实现了 98% 的认证准确率，验证了其对噪声和受试者间变异性的鲁棒性。

Conclusion: 所提出的基于 PPG 信号的混合深度学习模型效率高、可扩展且具有固有的活体检测能力，非常适合实际的移动和嵌入式生物识别安全应用。

Abstract: Photoplethysmography (PPG) signals, which measure changes in blood volume in
the skin using light, have recently gained attention in biometric
authentication because of their non-invasive acquisition, inherent liveness
detection, and suitability for low-cost wearable devices. However, PPG signal
quality is challenged by motion artifacts, illumination changes, and
inter-subject physiological variability, making robust feature extraction and
classification crucial. This study proposes a lightweight and cost-effective
biometric authentication framework based on PPG signals extracted from
low-frame-rate fingertip videos. The CFIHSR dataset, comprising PPG recordings
from 46 subjects at a sampling rate of 14 Hz, is employed for evaluation. The
raw PPG signals undergo a standard preprocessing pipeline involving baseline
drift removal, motion artifact suppression using Principal Component Analysis
(PCA), bandpass filtering, Fourier-based resampling, and amplitude
normalization. To generate robust representations, each one-dimensional PPG
segment is converted into a two-dimensional time-frequency scalogram via the
Continuous Wavelet Transform (CWT), effectively capturing transient
cardiovascular dynamics. We developed a hybrid deep learning model, termed
CVT-ConvMixer-LSTM, by combining spatial features from the Convolutional Vision
Transformer (CVT) and ConvMixer branches with temporal features from a Long
Short-Term Memory network (LSTM). The experimental results on 46 subjects
demonstrate an authentication accuracy of 98%, validating the robustness of the
model to noise and variability between subjects. Due to its efficiency,
scalability, and inherent liveness detection capability, the proposed system is
well-suited for real-world mobile and embedded biometric security applications.

</details>


### [18] [MedDChest: A Content-Aware Multimodal Foundational Vision Model for Thoracic Imaging](https://arxiv.org/abs/2511.04016)
*Mahmoud Soliman,Islam Osman,Mohamed S. Shehata,Rasika Rajapakshe*

Main category: cs.CV

TL;DR: MedDChest是一个专门为胸部影像设计的视觉Transformer模型，它通过在大规模、多模态的胸部影像数据集上进行预训练，并采用新颖的内容感知数据增强策略“Guided Random Resized Crops”，显著优于在自然图像上预训练的模型，为胸部影像的下游诊断任务提供了更好的起点。


<details>
  <summary>Details</summary>
Motivation: 现有的医学影像模型通常在与医学影像领域无关的自然图像上预训练的骨干网络，这限制了模型的性能。

Method: 提出MedDChest，一个从头开始预训练在超过120万张胸部影像（包括X光和CT）上的视觉Transformer模型。引入了“Guided Random Resized Crops”的数据增强策略，该策略优先选择解剖学相关区域进行采样。

Result: 在多种下游诊断任务上进行微调，MedDChest的表现显著优于在ImageNet上预训练的公共模型。

Conclusion: 大规模、同域预训练结合领域特定的数据增强策略（如MedDChest及其数据增强方法）是有效的，可以为胸部影像的各种诊断任务提供比ImageNet预训练模型更优越的特征提取器。模型权重将公开。

Abstract: The performance of vision models in medical imaging is often hindered by the
prevailing paradigm of fine-tuning backbones pre-trained on out-of-domain
natural images. To address this fundamental domain gap, we propose MedDChest, a
new foundational Vision Transformer (ViT) model optimized specifically for
thoracic imaging. We pre-trained MedDChest from scratch on a massive, curated,
multimodal dataset of over 1.2 million images, encompassing different
modalities including Chest X-ray and Computed Tomography (CT) compiled from 10
public sources. A core technical contribution of our work is Guided Random
Resized Crops, a novel content-aware data augmentation strategy that biases
sampling towards anatomically relevant regions, overcoming the inefficiency of
standard cropping techniques on medical scans. We validate our model's
effectiveness by fine-tuning it on a diverse set of downstream diagnostic
tasks. Comprehensive experiments empirically demonstrate that MedDChest
significantly outperforms strong, publicly available ImageNet-pretrained
models. By establishing the superiority of large-scale, in-domain pre-training
combined with domain-specific data augmentation, MedDChest provides a powerful
and robust feature extractor that serves as a significantly better starting
point for a wide array of thoracic diagnostic tasks. The model weights will be
made publicly available to foster future research and applications.

</details>


### [19] [Unveiling Deep Semantic Uncertainty Perception for Language-Anchored Multi-modal Vision-Brain Alignment](https://arxiv.org/abs/2511.04078)
*Zehui Feng,Chenqi Zhang,Mingru Wang,Minuo Wei,Shiwei Cheng,Cuntai Guan,Ting Han*

Main category: cs.CV

TL;DR: Bratrix是一个新框架，通过解耦视觉刺激并将其映射到共享的潜在空间，实现了语言驱动的视觉-大脑对齐，并利用不确定性感知来处理神经信号的噪声，从而在检索、重建和字幕任务上提高了性能。


<details>
  <summary>Details</summary>
Motivation: 现有的方法将神经活动直接与视觉嵌入对齐，但仅基于视觉的表示往往无法捕捉潜在的语义维度，从而限制了解释性和鲁棒性。为了解决这些问题，需要一种能够处理主观变异性和视觉特征纠缠性的方法。

Method: Bratrix框架将视觉刺激分解为分层的视觉和语言语义成分，并将视觉和大脑表征都映射到共享的潜在空间，从而形成对齐的视觉-语言和大脑-语言嵌入。它还包含一个不确定性感知模块，在对齐过程中应用不确定性感知加权，并使用可学习的语言锚定语义矩阵来增强跨模态相关性。该框架采用单模态预训练和多模态微调的两阶段训练策略。

Result: Bratrix在EEG、MEG和fMRI基准测试中，在检索、重建和字幕任务上的性能均优于最先进的方法，特别是在200路EEG检索任务上提高了14.3%。

Conclusion: Bratrix是第一个实现语言驱动的视觉-大脑对齐的端到端框架，通过其新颖的架构和训练策略，有效地解决了神经信号解码中的挑战，并在多项任务中取得了显著的性能提升。

Abstract: Unveiling visual semantics from neural signals such as EEG, MEG, and fMRI
remains a fundamental challenge due to subject variability and the entangled
nature of visual features. Existing approaches primarily align neural activity
directly with visual embeddings, but visual-only representations often fail to
capture latent semantic dimensions, limiting interpretability and deep
robustness. To address these limitations, we propose Bratrix, the first
end-to-end framework to achieve multimodal Language-Anchored Vision-Brain
alignment. Bratrix decouples visual stimuli into hierarchical visual and
linguistic semantic components, and projects both visual and brain
representations into a shared latent space, enabling the formation of aligned
visual-language and brain-language embeddings. To emulate human-like perceptual
reliability and handle noisy neural signals, Bratrix incorporates a novel
uncertainty perception module that applies uncertainty-aware weighting during
alignment. By leveraging learnable language-anchored semantic matrices to
enhance cross-modal correlations and employing a two-stage training strategy of
single-modality pretraining followed by multimodal fine-tuning, Bratrix-M
improves alignment precision. Extensive experiments on EEG, MEG, and fMRI
benchmarks demonstrate that Bratrix improves retrieval, reconstruction, and
captioning performance compared to state-of-the-art methods, specifically
surpassing 14.3% in 200-way EEG retrieval task. Code and model are available.

</details>


### [20] [Adversarial and Score-Based CT Denoising: CycleGAN vs Noise2Score](https://arxiv.org/abs/2511.04083)
*Abu Hanif Muhammad Syarubany*

Main category: cs.CV

TL;DR: CycleGAN在CT图像去噪方面表现最佳，Noise2Score提供了有竞争力的无配对替代方案。


<details>
  <summary>Details</summary>
Motivation: 在非配对和自监督条件下研究CT图像去噪，评估CycleGAN和Noise2Score两种高效范式。

Method: 使用CycleGAN（U-Net骨干）和Noise2Score进行模型训练和评估，并进行了参数优化。

Result: CycleGAN将PSNR从34.66 dB提高到38.913 dB，SSIM从0.9234提高到0.971，得分接近1.93。Noise2Score在非常嘈杂的输入下效果显著。

Conclusion: CycleGAN在最终图像质量上表现最佳，Noise2Score提供了一种具有竞争力的无配对替代方案。

Abstract: We study CT image denoising in the unpaired and self-supervised regimes by
evaluating two strong, training-data-efficient paradigms: a CycleGAN-based
residual translator and a Noise2Score (N2S) score-matching denoiser. Under a
common evaluation protocol, a configuration sweep identifies a simple standard
U-Net backbone within CycleGAN (lambda_cycle = 30, lambda_iden = 2, ngf = ndf =
64) as the most reliable setting; we then train it to convergence with a longer
schedule. The selected CycleGAN improves the noisy input from 34.66 dB / 0.9234
SSIM to 38.913 dB / 0.971 SSIM and attains an estimated score of 1.9441 and an
unseen-set (Kaggle leaderboard) score of 1.9343. Noise2Score, while slightly
behind in absolute PSNR / SSIM, achieves large gains over very noisy inputs,
highlighting its utility when clean pairs are unavailable. Overall, CycleGAN
offers the strongest final image quality, whereas Noise2Score provides a robust
pair-free alternative with competitive performance. Source code is available at
https://github.com/hanifsyarubany/CT-Scan-Image-Denoising-using-CycleGAN-and-Noise2Score.

</details>


### [21] [When Swin Transformer Meets KANs: An Improved Transformer Architecture for Medical Image Segmentation](https://arxiv.org/abs/2511.04084)
*Nishchal Sapkota,Haoyan Shi,Yejia Zhang,Xianshi Ma,Bofang Zheng,Danny Z. Chen*

Main category: cs.CV

TL;DR: UKAST是一种结合了KANs和Swin Transformer的U-Net类架构，在医学图像分割任务中取得了最先进的性能，尤其在数据稀疏的情况下表现出色。


<details>
  <summary>Details</summary>
Motivation: 医学图像分割在诊断和治疗规划中至关重要，但由于复杂的解剖结构和有限的标注数据而面临挑战。CNN在局部特征提取方面表现出色，但在建模长距离依赖方面存在不足，而Transformer能更好地捕捉全局上下文，但需要大量数据且计算成本高。

Method: 提出了一种名为UKAST的U-Net类架构，将基于有理函数Kolmogorov-Arnold网络（KANs）的方法集成到Swin Transformer编码器中。该架构利用了Kolmogorov-Arnold Transformer（KAT）中的有理基函数和Group Rational KANs（GR-KANs），以克服基于样条的KANs的低效率，从而提供一个更具表现力、数据效率更高且计算量（FLOPs）更少、参数量仅略有增加的框架。

Result: UKAST在四个不同的2D和3D医学图像分割基准测试中取得了最先进的性能，在数据稀疏的情况下表现尤为突出，克服了标准Vision Transformer对数据的依赖性限制。

Conclusion: KAN增强的Transformer在提高数据效率和推动医学图像分割领域发展方面具有巨大潜力。

Abstract: Medical image segmentation is critical for accurate diagnostics and treatment
planning, but remains challenging due to complex anatomical structures and
limited annotated training data. CNN-based segmentation methods excel at local
feature extraction, but struggle with modeling long-range dependencies.
Transformers, on the other hand, capture global context more effectively, but
are inherently data-hungry and computationally expensive. In this work, we
introduce UKAST, a U-Net like architecture that integrates rational-function
based Kolmogorov-Arnold Networks (KANs) into Swin Transformer encoders. By
leveraging rational base functions and Group Rational KANs (GR-KANs) from the
Kolmogorov-Arnold Transformer (KAT), our architecture addresses the
inefficiencies of vanilla spline-based KANs, yielding a more expressive and
data-efficient framework with reduced FLOPs and only a very small increase in
parameter count compared to SwinUNETR. UKAST achieves state-of-the-art
performance on four diverse 2D and 3D medical image segmentation benchmarks,
consistently surpassing both CNN- and Transformer-based baselines. Notably, it
attains superior accuracy in data-scarce settings, alleviating the data-hungry
limitations of standard Vision Transformers. These results show the potential
of KAN-enhanced Transformers to advance data-efficient medical image
segmentation. Code is available at: https://github.com/nsapkota417/UKAST

</details>


### [22] [SpatialLock: Precise Spatial Control in Text-to-Image Synthesis](https://arxiv.org/abs/2511.04112)
*Biao Liu,Yuanzhi Liang*

Main category: cs.CV

TL;DR: SpatialLock是一个新框架，通过结合感知信号和地面信息来精确控制文本到图像生成中的对象空间定位，实现了新的最先进水平。


<details>
  <summary>Details</summary>
Motivation: 现有文本到图像生成方法在精确控制对象定位方面存在不足，未能充分利用位置信息，导致对对象空间布局的理解不够充分。

Method: SpatialLock框架包含两个组件：位置引导注入（PoI）和位置引导学习（PoG）。PoI通过注意力层直接整合空间信息，以有效学习地面信息。PoG采用基于感知的监督来进一步优化对象定位。

Result: SpatialLock在多个数据集上实现了超过0.9的IOU分数，在精确对象定位方面设定了新的最先进水平，并提高了生成图像的视觉质量。

Conclusion: SpatialLock通过整合感知信号和地面信息，有效地解决了文本到图像生成中对象空间定位的挑战，并在精确放置和图像质量方面取得了显著的改进。

Abstract: Text-to-Image (T2I) synthesis has made significant advancements in recent
years, driving applications such as generating datasets automatically. However,
precise control over object localization in generated images remains a
challenge. Existing methods fail to fully utilize positional information,
leading to an inadequate understanding of object spatial layouts. To address
this issue, we propose SpatialLock, a novel framework that leverages perception
signals and grounding information to jointly control the generation of spatial
locations. SpatialLock incorporates two components: Position-Engaged Injection
(PoI) and Position-Guided Learning (PoG). PoI directly integrates spatial
information through an attention layer, encouraging the model to learn the
grounding information effectively. PoG employs perception-based supervision to
further refine object localization. Together, these components enable the model
to generate objects with precise spatial arrangements and improve the visual
quality of the generated images. Experiments show that SpatialLock sets a new
state-of-the-art for precise object positioning, achieving IOU scores above 0.9
across multiple datasets.

</details>


### [23] [BoRe-Depth: Self-supervised Monocular Depth Estimation with Boundary Refinement for Embedded Systems](https://arxiv.org/abs/2511.04388)
*Chang Liu,Juan Li,Sheng Zhang,Chang Liu,Jie Li,Xu Zhang*

Main category: cs.CV

TL;DR: BoRe-Depth是一个参数量为8.7M的新型单目深度估计模型，它能在嵌入式系统上高效运行（50.7 FPS），并显著提升深度图的边界质量。


<details>
  <summary>Details</summary>
Motivation: 为了解决现有单目深度估计方法在嵌入式系统上面临的性能不佳和物体边界模糊的问题，提出BoRe-Depth模型。

Method: 提出了一种名为BoRe-Depth的新型模型，包含8.7M参数。设计了增强特征自适应融合模块（EFAF）来增强边界细节表示。将语义知识集成到编码器中以提升物体识别和边界感知能力。

Result: BoRe-Depth模型在多个挑战性数据集上显著优于以往的轻量级模型，能在NVIDIA Jetson Orin上高效运行，达到50.7 FPS。

Conclusion: BoRe-Depth模型在嵌入式系统上实现了准确的深度估计，并显著改善了边界质量，性能优于现有轻量级模型。

Abstract: Depth estimation is one of the key technologies for realizing 3D perception
in unmanned systems. Monocular depth estimation has been widely researched
because of its low-cost advantage, but the existing methods face the challenges
of poor depth estimation performance and blurred object boundaries on embedded
systems. In this paper, we propose a novel monocular depth estimation model,
BoRe-Depth, which contains only 8.7M parameters. It can accurately estimate
depth maps on embedded systems and significantly improves boundary quality.
Firstly, we design an Enhanced Feature Adaptive Fusion Module (EFAF) which
adaptively fuses depth features to enhance boundary detail representation.
Secondly, we integrate semantic knowledge into the encoder to improve the
object recognition and boundary perception capabilities. Finally, BoRe-Depth is
deployed on NVIDIA Jetson Orin, and runs efficiently at 50.7 FPS. We
demonstrate that the proposed model significantly outperforms previous
lightweight models on multiple challenging datasets, and we provide detailed
ablation studies for the proposed methods. The code is available at
https://github.com/liangxiansheng093/BoRe-Depth.

</details>


### [24] [Tortoise and Hare Guidance: Accelerating Diffusion Model Inference with Multirate Integration](https://arxiv.org/abs/2511.04117)
*Yunghee Lee,Byeonghyun Pak,Junwha Hong,Hoseong Kim*

Main category: cs.CV

TL;DR: THG是一种训练无关的策略，通过将CFG ODE重构为多速率ODE系统，显著加速了扩散采样过程，同时保持了高保真度。它通过在粗时间尺度上求解指导项，在细时间尺度上求解噪声估计，将函数评估次数（NFE）减少了高达30%，而生成保真度几乎没有损失，并且优于最先进的CFG加速器。


<details>
  <summary>Details</summary>
Motivation: 现有的扩散模型采样速度较慢，而模型微调会增加计算成本。本研究旨在开发一种训练无关的策略，以加速扩散采样过程，同时保持生成质量。

Method: 1.将分类器-自由指导（CFG）ODE重构为多速率ODE系统。2.利用误差界限分析，发现指导项对近似误差更鲁棒，存在冗余。3.提出THG策略，在粗时间尺度上求解指导项（快），在细时间尺度上求解噪声估计（慢）。4.引入自适应步长选择的误差界限感知时间步采样器。5.引入稳定大外插范围的指导尺度调度器。

Result: THG将函数评估次数（NFE）减少了高达30%，生成保真度几乎没有损失（ΔImageReward ≤ 0.032）。在相同的计算预算下，THG的性能优于最先进的基于CFG的训练无关加速器。

Conclusion: 多速率公式在扩散求解器方面具有巨大潜力，可以实现实时高质量图像合成，而无需重新训练模型。THG是一种有效的训练无关加速策略，可显著提高扩散采样效率。

Abstract: In this paper, we propose Tortoise and Hare Guidance (THG), a training-free
strategy that accelerates diffusion sampling while maintaining high-fidelity
generation. We demonstrate that the noise estimate and the additional guidance
term exhibit markedly different sensitivity to numerical error by reformulating
the classifier-free guidance (CFG) ODE as a multirate system of ODEs. Our
error-bound analysis shows that the additional guidance branch is more robust
to approximation, revealing substantial redundancy that conventional solvers
fail to exploit. Building on this insight, THG significantly reduces the
computation of the additional guidance: the noise estimate is integrated with
the tortoise equation on the original, fine-grained timestep grid, while the
additional guidance is integrated with the hare equation only on a coarse grid.
We also introduce (i) an error-bound-aware timestep sampler that adaptively
selects step sizes and (ii) a guidance-scale scheduler that stabilizes large
extrapolation spans. THG reduces the number of function evaluations (NFE) by up
to 30% with virtually no loss in generation fidelity ($\Delta$ImageReward
$\leq$ 0.032) and outperforms state-of-the-art CFG-based training-free
accelerators under identical computation budgets. Our findings highlight the
potential of multirate formulations for diffusion solvers, paving the way for
real-time high-quality image synthesis without any model retraining. The source
code is available at https://github.com/yhlee-add/THG.

</details>


### [25] [Text to Sketch Generation with Multi-Styles](https://arxiv.org/abs/2511.04123)
*Tengjie Li,Shikui Tu,Lei Xu*

Main category: cs.CV

TL;DR: 该研究提出了一个基于扩散模型的训练免费框架，用于通过文本提示和风格参考草图实现精确的草图风格控制，并支持多风格生成。


<details>
  <summary>Details</summary>
Motivation: 现有方法在生成草图时缺乏精确的风格控制机制。

Method: 提出一个基于扩散模型的训练免费框架，通过将参考特征作为辅助信息并结合线性平滑和风格-内容引导机制，实现文本提示和参考草图的风格引导。该框架还扩展支持通过联合AdaIN模块集成多个参考草图的特征，以实现可控的多风格生成。

Result: 该方法有效减少了参考草图的内容泄露，提高了生成质量，尤其是在参考草图和目标草图结构相似度较低的情况下。实验证明，该方法能够生成高质量的草图，并实现精确的风格对齐和增强的风格控制灵活性。

Conclusion: 该框架为草图生成提供了精确的风格控制和多风格生成能力。

Abstract: Recent advances in vision-language models have facilitated progress in sketch
generation. However, existing specialized methods primarily focus on generic
synthesis and lack mechanisms for precise control over sketch styles. In this
work, we propose a training-free framework based on diffusion models that
enables explicit style guidance via textual prompts and referenced style
sketches. Unlike previous style transfer methods that overwrite key and value
matrices in self-attention, we incorporate the reference features as auxiliary
information with linear smoothing and leverage a style-content guidance
mechanism. This design effectively reduces content leakage from reference
sketches and enhances synthesis quality, especially in cases with low
structural similarity between reference and target sketches. Furthermore, we
extend our framework to support controllable multi-style generation by
integrating features from multiple reference sketches, coordinated via a joint
AdaIN module. Extensive experiments demonstrate that our approach achieves
high-quality sketch generation with accurate style alignment and improved
flexibility in style control. The official implementation of M3S is available
at https://github.com/CMACH508/M3S.

</details>


### [26] [Automated Tennis Player and Ball Tracking with Court Keypoints Detection (Hawk Eye System)](https://arxiv.org/abs/2511.04126)
*Venkata Manikanta Desu,Syed Fawaz Ali*

Main category: cs.CV

TL;DR: 提出一个用于自动化网球比赛分析的完整流程，该流程整合了多种深度学习模型，能够实时检测和追踪球员与网球，并识别球场关键点以提供空间参考。


<details>
  <summary>Details</summary>
Motivation: 自动化网球比赛分析，提供详细的数据洞察。 

Method: 使用YOLOv8进行球员检测，自定义训练的YOLOv5模型进行球追踪，以及基于ResNet50的架构进行球场关键点检测，构建了一个整合的分析系统。

Result: 该系统能够进行详细的比赛分析，包括球员移动模式、球速、击球准确度和球员反应时间。实验结果表明该系统在不同场地条件和比赛场景下均表现稳健，并能输出标注视频和详细的性能指标。

Conclusion: 该自动化分析流程为教练、播报员和球员提供了可行的游戏动力学见解。

Abstract: This study presents a complete pipeline for automated tennis match analysis.
Our framework integrates multiple deep learning models to detect and track
players and the tennis ball in real time, while also identifying court
keypoints for spatial reference. Using YOLOv8 for player detection, a
custom-trained YOLOv5 model for ball tracking, and a ResNet50-based
architecture for court keypoint detection, our system provides detailed
analytics including player movement patterns, ball speed, shot accuracy, and
player reaction times. The experimental results demonstrate robust performance
in varying court conditions and match scenarios. The model outputs an annotated
video along with detailed performance metrics, enabling coaches, broadcasters,
and players to gain actionable insights into the dynamics of the game.

</details>


### [27] [DMSORT: An efficient parallel maritime multi-object tracking architecture for unmanned vessel platforms](https://arxiv.org/abs/2511.04128)
*Shengyu Tang,Zeyuan Lu,Jiazhi Dong,Changdong Yu,Xiaoyu Wang,Yaohui Lyu,Weihao Xia*

Main category: cs.CV

TL;DR: DMSORT是一种高效的双分支排序方法，用于解决海上多目标跟踪中的相机运动和视觉退化问题。


<details>
  <summary>Details</summary>
Motivation: 海上多目标跟踪（MOT）对于确保船舶航行安全和有效海上监视至关重要，但复杂的海上环境常导致相机运动和视觉退化，给MOT带来挑战。

Method: 提出了一种名为DMSORT的双分支排序方法，其核心是一个具有仿射补偿的并行跟踪器。该跟踪器包含一个对象检测和再识别（ReID）分支，以及一个专门用于动态相机运动估计的分支。具体来说，集成了可逆柱状检测网络（RCDN）用于鲁棒的对象检测，设计了轻量级Transformer外观提取器（Li-TAE）来捕捉全局上下文信息并生成鲁棒的外观特征。另一分支通过构建投影变换来解耦平台引起的运动和目标固有的运动，并在卡尔曼滤波器内应用平台运动补偿，从而稳定真实的目标轨迹。最后，通过聚类优化的特征融合模块有效结合运动和外观线索，以确保在噪声、遮挡和漂移下的身份一致性。

Result: 在新加坡海事数据集上的广泛评估表明，DMSORT在保持高身份一致性和对抖动、遮挡的鲁棒性的同时，实现了比现有基于ReID的MOT框架最快的运行时。

Conclusion: DMSORT通过其创新的双分支结构和运动补偿机制，在复杂的海上环境中实现了高效且鲁棒的多目标跟踪，达到了最先进的性能。

Abstract: Accurate perception of the marine environment through robust multi-object
tracking (MOT) is essential for ensuring safe vessel navigation and effective
maritime surveillance. However, the complicated maritime environment often
causes camera motion and subsequent visual degradation, posing significant
challenges to MOT. To address this challenge, we propose an efficient
Dual-branch Maritime SORT (DMSORT) method for maritime MOT. The core of the
framework is a parallel tracker with affine compensation, which incorporates an
object detection and re-identification (ReID) branch, along with a dedicated
branch for dynamic camera motion estimation. Specifically, a Reversible
Columnar Detection Network (RCDN) is integrated into the detection module to
leverage multi-level visual features for robust object detection. Furthermore,
a lightweight Transformer-based appearance extractor (Li-TAE) is designed to
capture global contextual information and generate robust appearance features.
Another branch decouples platform-induced and target-intrinsic motion by
constructing a projective transformation, applying platform-motion compensation
within the Kalman filter, and thereby stabilizing true object trajectories.
Finally, a clustering-optimized feature fusion module effectively combines
motion and appearance cues to ensure identity consistency under noise,
occlusion, and drift. Extensive evaluations on the Singapore Maritime Dataset
demonstrate that DMSORT achieves state-of-the-art performance. Notably, DMSORT
attains the fastest runtime among existing ReID-based MOT frameworks while
maintaining high identity consistency and robustness to jitter and occlusion.
Code is available at:
https://github.com/BiscuitsLzy/DMSORT-An-efficient-parallel-maritime-multi-object-tracking-architecture-.

</details>


### [28] [Learning from Online Videos at Inference Time for Computer-Use Agents](https://arxiv.org/abs/2511.04137)
*Yujian Liu,Ze Wang,Hao Chen,Ximeng Sun,Xiaodong Yu,Jialian Wu,Jiang Liu,Emad Barsoum,Zicheng Liu,Shiyu Chang*

Main category: cs.CV

TL;DR: 让计算机使用代理从在线视频中学习，以弥补其在需要特定领域知识的任务中的不足。


<details>
  <summary>Details</summary>
Motivation: 由于计算机使用代理缺乏特定应用程序、平台和多步工作流的领域特定程序知识，它们在自动化任务方面不如人类用户。人类通过观看视频教程来弥补这一差距，他们会搜索、浏览并选择性地模仿与当前子目标匹配的短片段。

Method: 提出一个框架，用于在推理时检索、过滤教程视频，将其转换为结构化演示轨迹，并在执行过程中动态选择轨迹作为上下文引导。具体来说，利用视觉语言模型（VLM）推断UI动作，将视频分割成短动作子序列，并为每个子序列分配文本目标。在推理时，一个两阶段的选择机制在每一步动态选择一个轨迹添加到上下文中，使代理能够专注于对其下一个决策最有帮助的本地引导。

Result: 在两个广泛使用的基准上进行的实验表明，该框架的性能始终优于强大的基础代理以及仅使用文本教程或成绩单的变体。

Conclusion: 研究表明，可以系统地从丰富的在线视频中提取可操作的指导，以在推理时改进计算机使用代理。

Abstract: Computer-use agents can operate computers and automate laborious tasks, but
despite recent rapid progress, they still lag behind human users, especially
when tasks require domain-specific procedural knowledge about particular
applications, platforms, and multi-step workflows. Humans can bridge this gap
by watching video tutorials: we search, skim, and selectively imitate short
segments that match our current subgoal. In this paper, we study how to enable
computer-use agents to learn from online videos at inference time effectively.
We propose a framework that retrieves and filters tutorial videos, converts
them into structured demonstration trajectories, and dynamically selects
trajectories as in-context guidance during execution. Particularly, using a
VLM, we infer UI actions, segment videos into short subsequences of actions,
and assign each subsequence a textual objective. At inference time, a two-stage
selection mechanism dynamically chooses a single trajectory to add in context
at each step, focusing the agent on the most helpful local guidance for its
next decision. Experiments on two widely used benchmarks show that our
framework consistently outperforms strong base agents and variants that use
only textual tutorials or transcripts. Analyses highlight the importance of
trajectory segmentation and selection, action filtering, and visual
information, suggesting that abundant online videos can be systematically
distilled into actionable guidance that improves computer-use agents at
inference time. Our code is available at
https://github.com/UCSB-NLP-Chang/video_demo.

</details>


### [29] [Seeing Straight: Document Orientation Detection for Efficient OCR](https://arxiv.org/abs/2511.04161)
*Suranjan Goswami,Abhinav Ravi,Raja Kolla,Ali Faraz,Shaharukh Khan,Akash,Chandra Khatri,Shubham Agarwal*

Main category: cs.CV

TL;DR: 尽管OCR技术取得了显著进展，但文档方向的准确识别仍然是实际应用中的关键预处理步骤。本研究提出了OCR-Rotation-Bench（ORB）基准，包含ORB-En和ORB-Indic两个数据集，用于评估OCR在旋转情况下的鲁棒性。同时，我们开发了一种基于Phi-3.5-Vision模型的轻量级旋转分类流水线，在两个数据集上均取得了高精度。此外，我们的方法能够显著提升OCR性能，尤其是在模拟真实场景下。


<details>
  <summary>Details</summary>
Motivation: 在实际应用中，扫描或拍摄的文档方向可能不正确，这会严重影响OCR等下游任务的性能。因此，准确的旋转校正至关重要。

Method: 1. 提出了OCR-Rotation-Bench（ORB）基准，包含ORB-En（基于现有英文OCR数据集的旋转变换）和ORB-Indic（包含11种印度中低资源语言的新数据集）。2. 开发了一种基于Phi-3.5-Vision模型视觉编码器的轻量级旋转分类流水线，并进行了针对4类旋转任务的微调。

Result: 1. 提出的旋转分类流水线在ORB-En和ORB-Indic数据集上分别达到了96%和92%的准确率。2. 该方法在模拟真实场景下，能够显著提升闭源OCR模型（最高提升14%）和开源模型（最高提升4倍）的性能。

Conclusion: 准确的文档方向识别是OCR预处理的关键环节。本研究提出的ORB基准和基于Phi-3.5-Vision模型的旋转分类方法，不仅在旋转分类任务上表现出色，还能有效提升下游OCR任务的性能，尤其是在处理低资源语言和模拟真实世界场景方面具有重要意义。

Abstract: Despite significant advances in document understanding, determining the
correct orientation of scanned or photographed documents remains a critical
pre-processing step in the real world settings. Accurate rotation correction is
essential for enhancing the performance of downstream tasks such as Optical
Character Recognition (OCR) where misalignment commonly arises due to user
errors, particularly incorrect base orientations of the camera during capture.
In this study, we first introduce OCR-Rotation-Bench (ORB), a new benchmark for
evaluating OCR robustness to image rotations, comprising (i) ORB-En, built from
rotation-transformed structured and free-form English OCR datasets, and (ii)
ORB-Indic, a novel multilingual set spanning 11 Indic mid to low-resource
languages. We also present a fast, robust and lightweight rotation
classification pipeline built on the vision encoder of Phi-3.5-Vision model
with dynamic image cropping, fine-tuned specifically for 4-class rotation task
in a standalone fashion. Our method achieves near-perfect 96% and 92% accuracy
on identifying the rotations respectively on both the datasets. Beyond
classification, we demonstrate the critical role of our module in boosting OCR
performance: closed-source (up to 14%) and open-weights models (up to 4x) in
the simulated real-world setting.

</details>


### [30] [Systematic Evaluation of Preprocessing Techniques for Accurate Image Registration in Digital Pathology](https://arxiv.org/abs/2511.04171)
*Fatemehzahra Darzi,Rodrigo Escobar Diaz Guerrero,Thomas Bocklitz*

Main category: cs.CV

TL;DR: 图像配准技术可以通过颜色转换来提高不同染色或成像模态图像的对齐精度，CycleGAN在多种颜色转换方法中表现最佳。


<details>
  <summary>Details</summary>
Motivation: 数字病理学中的图像配准对于整合不同染色或成像模态的信息至关重要，但不同模态图像之间的准确配准仍然是一个挑战。

Method: 研究人员探索了多种颜色转换技术（CycleGAN、Macenko、Reinhard、Vahadane）对H&E染色图像和非线性多模态图像之间配准的影响。配准过程采用了VALIS方法，包括刚性配准和多步非刚性配准。性能通过目标配准误差（rTRE）进行评估，并辅以自定义的点对点评估。

Result: 在所有测试的颜色转换方法中，CycleGAN在两种场景（使用原始或反转的多模态图像）下均实现了最低的配准误差。其他方法显示出较高的误差。

Conclusion: 在配准前应用颜色转换可以显著提高不同模态图像的对齐效果，从而支持数字病理学中更可靠的分析。CycleGAN在所研究的技术中表现出最佳性能。

Abstract: Image registration refers to the process of spatially aligning two or more
images by mapping them into a common coordinate system, so that corresponding
anatomical or tissue structures are matched across images. In digital
pathology, registration enables direct comparison and integration of
information from different stains or imaging modalities, sup-porting
applications such as biomarker analysis and tissue reconstruction. Accurate
registration of images from different modalities is an essential step in
digital pathology. In this study, we investigated how various color
transformation techniques affect image registration between hematoxylin and
eosin (H&E) stained images and non-linear multimodal images. We used a dataset
of 20 tissue sample pairs, with each pair undergoing several preprocessing
steps, including different color transformation (CycleGAN, Macenko, Reinhard,
Vahadane), inversion, contrast adjustment, intensity normalization, and
denoising. All images were registered using the VALIS registration method,
which first applies rigid registration and then performs non-rigid registration
in two steps on both low and high-resolution images. Registration performance
was evaluated using the relative Target Registration Error (rTRE). We reported
the median of median rTRE values (MMrTRE) and the average of median rTRE values
(AMrTRE) for each method. In addition, we performed a custom point-based
evaluation using ten manually selected key points. Registration was done
separately for two scenarios, using either the original or inverted multimodal
images. In both scenarios, CycleGAN color transformation achieved the lowest
registration errors, while the other methods showed higher errors. These
findings show that applying color transformation before registration improves
alignment between images from different modalities and supports more reliable
analysis in digital pathology.

</details>


### [31] [Covariance Descriptors Meet General Vision Encoders: Riemannian Deep Learning for Medical Image Classification](https://arxiv.org/abs/2511.04190)
*Josef Mayr,Anna Reithmeir,Maxime Di Folco,Julia A. Schnabel*

Main category: cs.CV

TL;DR: 协方差描述符结合通用视觉编码器在医学图像分类任务中表现优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 探究协方差描述符在医学图像分析中的有效性，特别是在结合预训练的通用视觉编码器（GVEs）和SPDNet时。

Method: 从预训练的GVEs（DINOv2和MedSAM）提取特征，构建协方差描述符，并与手工特征进行比较。使用SPDNet进行分类，并在多个医学图像数据集上进行评估。

Result: 从GVEs提取的协方差描述符优于手工特征。SPDNet结合DINOv2特征在分类任务中取得了优于现有最先进方法的性能。

Conclusion: 结合协方差描述符和强大的预训练视觉编码器在医学图像分析领域具有巨大潜力。

Abstract: Covariance descriptors capture second-order statistics of image features.
They have shown strong performance in general computer vision tasks, but remain
underexplored in medical imaging. We investigate their effectiveness for both
conventional and learning-based medical image classification, with a particular
focus on SPDNet, a classification network specifically designed for symmetric
positive definite (SPD) matrices. We propose constructing covariance
descriptors from features extracted by pre-trained general vision encoders
(GVEs) and comparing them with handcrafted descriptors. Two GVEs - DINOv2 and
MedSAM - are evaluated across eleven binary and multi-class datasets from the
MedMNSIT benchmark. Our results show that covariance descriptors derived from
GVE features consistently outperform those derived from handcrafted features.
Moreover, SPDNet yields superior performance to state-of-the-art methods when
combined with DINOv2 features. Our findings highlight the potential of
combining covariance descriptors with powerful pretrained vision encoders for
medical image analysis.

</details>


### [32] [AStF: Motion Style Transfer via Adaptive Statistics Fusor](https://arxiv.org/abs/2511.04192)
*Hanmo Chen,Chenghao Xu,Jiexi Yan,Cheng Deng*

Main category: cs.CV

TL;DR: 现有动作风格迁移方法依赖均值和方差，但不足以捕捉动作数据的复杂动态模式和时空连贯性。本研究提出一种自适应统计融合器（AStF），引入偏度和峰度，并结合风格解耦模块（SDM）和高阶多统计注意力（HOS-Attn）来更全面地建模动态风格的时空统计模式。实验结果表明，AStF在动作风格迁移方面优于现有技术。


<details>
  <summary>Details</summary>
Motivation: 传统图像风格迁移方法中的均值和方差对于动作风格迁移来说不足以完全捕捉动作数据的复杂动态模式和时空连贯性。

Method: 提出一种新颖的自适应统计融合器（AStF），它包括风格解耦模块（SDM）和高阶多统计注意力（HOS-Attn）。AStF在与动作一致性正则化（MCR）判别器结合进行训练。

Result: 实验结果表明，通过提供对动态风格固有的时空统计模式的更全面建模，所提出的AStF在动作风格迁移方面显示出优于现有技术的熟练优势。

Conclusion: AStF通过引入偏度和峰度等更高阶的统计量，能够更全面地捕捉动作数据的时空统计特征，从而在动作风格迁移任务上取得更好的性能。

Abstract: Human motion style transfer allows characters to appear less rigidity and
more realism with specific style. Traditional arbitrary image style transfer
typically process mean and variance which is proved effective. Meanwhile,
similar methods have been adapted for motion style transfer. However, due to
the fundamental differences between images and motion, relying on mean and
variance is insufficient to fully capture the complex dynamic patterns and
spatiotemporal coherence properties of motion data. Building upon this, our key
insight is to bring two more coefficient, skewness and kurtosis, into the
analysis of motion style. Specifically, we propose a novel Adaptive Statistics
Fusor (AStF) which consists of Style Disentanglement Module (SDM) and
High-Order Multi-Statistics Attention (HOS-Attn). We trained our AStF in
conjunction with a Motion Consistency Regularization (MCR) discriminator.
Experimental results show that, by providing a more comprehensive model of the
spatiotemporal statistical patterns inherent in dynamic styles, our proposed
AStF shows proficiency superiority in motion style transfers over
state-of-the-arts. Our code and model are available at
https://github.com/CHMimilanlan/AStF.

</details>


### [33] [MedSapiens: Taking a Pose to Rethink Medical Imaging Landmark Detection](https://arxiv.org/abs/2511.04255)
*Marawan Elbatel,Anbang Wang,Keyuan Liu,Kaouther Mouheb,Enrique Almar-Munoz,Lizhuo Lin,Yanqi Yang,Karim Lekadir,Xiaomeng Li*

Main category: cs.CV

TL;DR: 该研究提出MedSapiens，一种基于Sapiens的医学影像解剖标志点检测模型，取得了新的state-of-the-art成果，并在少样本设置下表现出色。


<details>
  <summary>Details</summary>
Motivation: 本次研究的动机是探索将以人类为中心的基础模型（如Sapiens）应用于医学影像解剖标志点检测的可能性，因为传统方法多依赖领域特定模型，而忽视了大型预训练视觉模型带来的新机遇。

Method: 研究方法包括使用多数据集预训练Sapiens模型，并将其应用于医学影像解剖标志点检测任务，命名为MedSapiens。通过与现有模型进行基准测试，评估其在不同数据集和少样本场景下的性能。

Result: MedSapiens模型在多个数据集上取得了新的state-of-the-art成果，平均成功检测率（SDR）相较于通用模型提升最高达5.26%，相较于领域特定模型提升最高达21.81%。在少样本设置下，MedSapiens的SDR相较于少样本state-of-the-art提升了2.69%。

Conclusion: 研究结论是以人类为中心的基础模型（如Sapiens）具有强大的空间姿态定位能力，可以作为解剖标志点检测的有力先验，但这一潜力此前未被充分挖掘。MedSapiens模型证明了其在医学影像解剖标志点检测任务上的优越性，并且在数据有限的情况下也表现出色。

Abstract: This paper does not introduce a novel architecture; instead, it revisits a
fundamental yet overlooked baseline: adapting human-centric foundation models
for anatomical landmark detection in medical imaging. While landmark detection
has traditionally relied on domain-specific models, the emergence of
large-scale pre-trained vision models presents new opportunities. In this
study, we investigate the adaptation of Sapiens, a human-centric foundation
model designed for pose estimation, to medical imaging through multi-dataset
pretraining, establishing a new state of the art across multiple datasets. Our
proposed model, MedSapiens, demonstrates that human-centric foundation models,
inherently optimized for spatial pose localization, provide strong priors for
anatomical landmark detection, yet this potential has remained largely
untapped. We benchmark MedSapiens against existing state-of-the-art models,
achieving up to 5.26% improvement over generalist models and up to 21.81%
improvement over specialist models in the average success detection rate (SDR).
To further assess MedSapiens adaptability to novel downstream tasks with few
annotations, we evaluate its performance in limited-data settings, achieving
2.69% improvement over the few-shot state of the art in SDR. Code and model
weights are available at https://github.com/xmed-lab/MedSapiens .

</details>


### [34] [Proto-LeakNet: Towards Signal-Leak Aware Attribution in Synthetic Human Face Imagery](https://arxiv.org/abs/2511.04260)
*Claudio Giusti,Luca Guarnera,Sebastiano Battiato*

Main category: cs.CV

TL;DR: Proto-LeakNet是一个可解释的溯源框架，通过分析扩散模型输出中的信号泄漏来识别图像和深度伪造的生成器，即使是未见过的新模型也能进行评估。


<details>
  <summary>Details</summary>
Motivation: 日益复杂的AI生成图像和深度伪造模型带来了溯源和真实性验证的挑战。现有研究表明，扩散模型会在其输出（尤其是潜在表征）中留下持续的统计痕迹（信号泄漏）。

Method: Proto-LeakNet在扩散模型的潜在域中操作，通过模拟部分前向扩散来暴露特定于生成器的线索。该方法结合了闭集分类和基于密度的开集评估，利用时域注意力编码器聚合多步潜在特征，并通过特征加权原型头构建嵌入空间以实现透明溯源。

Result: 在仅使用闭集数据训练的情况下，Proto-LeakNet达到了98.13%的宏观AUC，学习到的潜在几何结构在后处理下依然稳健，优于现有最先进的方法，并实现了已知和未知生成器之间的强可分性。

Conclusion: 在潜在空间中模拟信号泄漏偏差能够实现可靠且可解释的AI图像和深度伪造取证。

Abstract: The growing sophistication of synthetic image and deepfake generation models
has turned source attribution and authenticity verification into a critical
challenge for modern computer vision systems. Recent studies suggest that
diffusion pipelines unintentionally imprint persistent statistical traces,
known as signal leaks, within their outputs, particularly in latent
representations. Building on this observation, we propose Proto-LeakNet, a
signal-leak-aware and interpretable attribution framework that integrates
closed-set classification with a density-based open-set evaluation on the
learned embeddings, enabling analysis of unseen generators without retraining.
Operating in the latent domain of diffusion models, our method re-simulates
partial forward diffusion to expose residual generator-specific cues. A
temporal attention encoder aggregates multi-step latent features, while a
feature-weighted prototype head structures the embedding space and enables
transparent attribution. Trained solely on closed data and achieving a Macro
AUC of 98.13%, Proto-LeakNet learns a latent geometry that remains robust under
post-processing, surpassing state-of-the-art methods, and achieves strong
separability between known and unseen generators. These results demonstrate
that modeling signal-leak bias in latent space enables reliable and
interpretable AI-image and deepfake forensics. The code for the whole work will
be available upon submission.

</details>


### [35] [DINOv2 Driven Gait Representation Learning for Video-Based Visible-Infrared Person Re-identification](https://arxiv.org/abs/2511.04281)
*Yujie Yang,Shuang Li,Jun Ye,Neng Dong,Fan Li,Huafeng Li*

Main category: cs.CV

TL;DR: 本研究提出DinoGRL框架，利用DINOv2学习步态特征，以提升视频跨模态行人重识别的性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法主要关注模态不变的视觉特征，忽略了丰富的步态特征，限制了跨模态视频匹配的时空一致性建模能力。

Method: 提出DinoGRL框架，包含SASGL模型（利用DINOv2的语义先验生成和增强轮廓表示，并与ReID目标联合优化）和PBMGE模块（通过步态和外观特征流的多粒度双向交互，逐步精炼特征表示）。

Result: 在HITSZ-VCM和BUPT数据集上的实验结果表明，该方法显著优于现有的最先进方法。

Conclusion: DinoGRL框架通过结合步态和外观特征，并利用DINOv2的丰富视觉先验，能够学习到更鲁棒的时空序列表示，从而在视频可见光-红外行人重识别任务上取得优越性能。

Abstract: Video-based Visible-Infrared person re-identification (VVI-ReID) aims to
retrieve the same pedestrian across visible and infrared modalities from video
sequences. Existing methods tend to exploit modality-invariant visual features
but largely overlook gait features, which are not only modality-invariant but
also rich in temporal dynamics, thus limiting their ability to model the
spatiotemporal consistency essential for cross-modal video matching. To address
these challenges, we propose a DINOv2-Driven Gait Representation Learning
(DinoGRL) framework that leverages the rich visual priors of DINOv2 to learn
gait features complementary to appearance cues, facilitating robust
sequence-level representations for cross-modal retrieval. Specifically, we
introduce a Semantic-Aware Silhouette and Gait Learning (SASGL) model, which
generates and enhances silhouette representations with general-purpose semantic
priors from DINOv2 and jointly optimizes them with the ReID objective to
achieve semantically enriched and task-adaptive gait feature learning.
Furthermore, we develop a Progressive Bidirectional Multi-Granularity
Enhancement (PBMGE) module, which progressively refines feature representations
by enabling bidirectional interactions between gait and appearance streams
across multiple spatial granularities, fully leveraging their complementarity
to enhance global representations with rich local details and produce highly
discriminative features. Extensive experiments on HITSZ-VCM and BUPT datasets
demonstrate the superiority of our approach, significantly outperforming
existing state-of-the-art methods.

</details>


### [36] [FastGS: Training 3D Gaussian Splatting in 100 Seconds](https://arxiv.org/abs/2511.04283)
*Shiwei Ren,Tianci Wen,Yongchun Fang,Biao Lu*

Main category: cs.CV

TL;DR: FastGS通过基于多视图一致性的高斯点数量调节策略，显著提高了3D高斯样条（3DGS）的训练速度，同时保持了可比的渲染质量。


<details>
  <summary>Details</summary>
Motivation: 现有的3DGS加速方法未能有效控制训练过程中的高斯点数量，导致计算时间浪费。本研究旨在提出一种新的框架来解决这个问题。

Method: 提出了一种基于多视图一致性的、创新的高斯点稠密化和剪枝策略，无需预算机制，以平衡训练时间和渲染质量。

Result: 在Mip-NeRF 360、Tanks & Temples和Deep Blending数据集上的实验表明，FastGS在训练速度上显著优于现有方法，在Mip-NeRF 360数据集上实现了3.32倍的训练加速，渲染质量与DashGaussian相当；在Deep Blending数据集上实现了15.45倍的训练加速，相比于原始3DGS。FastGS在动态场景重建、表面重建、稀疏视图重建、大规模重建和同步定位与建图等多种任务中均实现了2-7倍的训练加速，展示了其通用性。

Conclusion: FastGS是一种新颖、简单且通用的加速框架，通过基于多视图一致性的高斯点数量调节，有效解决了3DGS训练中的效率问题，实现了训练速度和渲染质量的良好平衡。

Abstract: The dominant 3D Gaussian splatting (3DGS) acceleration methods fail to
properly regulate the number of Gaussians during training, causing redundant
computational time overhead. In this paper, we propose FastGS, a novel, simple,
and general acceleration framework that fully considers the importance of each
Gaussian based on multi-view consistency, efficiently solving the trade-off
between training time and rendering quality. We innovatively design a
densification and pruning strategy based on multi-view consistency, dispensing
with the budgeting mechanism. Extensive experiments on Mip-NeRF 360, Tanks &
Temples, and Deep Blending datasets demonstrate that our method significantly
outperforms the state-of-the-art methods in training speed, achieving a
3.32$\times$ training acceleration and comparable rendering quality compared
with DashGaussian on the Mip-NeRF 360 dataset and a 15.45$\times$ acceleration
compared with vanilla 3DGS on the Deep Blending dataset. We demonstrate that
FastGS exhibits strong generality, delivering 2-7$\times$ training acceleration
across various tasks, including dynamic scene reconstruction, surface
reconstruction, sparse-view reconstruction, large-scale reconstruction, and
simultaneous localization and mapping. The project page is available at
https://fastgs.github.io/

</details>


### [37] [Vision Foundation Models in Agriculture: Toward Domain-Specific Adaptation for Weed Herbicide Trials Assessment](https://arxiv.org/abs/2511.04288)
*Leire Benito-Del-Valle,Artzai Picón,Daniel Mugica,Manuel Ramos,Eva Portillo,Javier Romero,Carlos Javier Jimenez,Ramón Navarra-Mestre*

Main category: cs.CV

TL;DR: 通过在大型农业数据集上进行自监督学习，我们调整了一个通用的视觉基础模型，使其在除草剂试验表征方面表现出色，优于通用模型，尤其是在物种识别和损伤分类方面，并提高了在未见条件和领域迁移场景下的性能，同时显著减少了对标签数据的需求。


<details>
  <summary>Details</summary>
Motivation: 除草剂田间试验需要准确识别植物物种和评估除草剂造成的损害，而通用的视觉基础模型在农业领域可能表现不佳，难以区分细微的物种和损害类型。

Method: 在大型、精心策划的农业数据集上，使用自监督学习方法调整了一个通用的视觉基础模型，使其学习到的表征更适合除草剂试验图像。

Result: 与通用的基础模型相比，领域特定的模型在物种识别（F1分数从0.91提升至0.94）和损伤分类（从0.26提升至0.33）方面表现更优。在未见条件下，性能增益更大（物种识别从0.56提升至0.66；损伤分类从0.17提升至0.27）。在无人机图像等领域迁移场景下，模型也保持了强劲性能（物种分类从0.49提升至0.60）。此外，领域特定的预训练提高了分割精度，尤其是在标注数据较少的情况下，其F1分数比通用模型高5.4%，而使用的标签样本减少了80%。

Conclusion: 领域特定的基础模型具有良好的泛化能力，能够显著减少人工标注工作量，为除草剂试验分析提供了一种可扩展的自动化解决方案。

Abstract: Herbicide field trials require accurate identification of plant species and
assessment of herbicide-induced damage across diverse environments. While
general-purpose vision foundation models have shown promising results in
complex visual domains, their performance can be limited in agriculture, where
fine-grained distinctions between species and damage types are critical.
  In this work, we adapt a general-purpose vision foundation model to herbicide
trial characterization. Trained using a self-supervised learning approach on a
large, curated agricultural dataset, the model learns rich and transferable
representations optimized for herbicide trials images.
  Our domain-specific model significantly outperforms the best general-purpose
foundation model in both species identification (F1 score improvement from 0.91
to 0.94) and damage classification (from 0.26 to 0.33). Under unseen conditions
(new locations and other time), it achieves even greater gains (species
identification from 0.56 to 0.66; damage classification from 0.17 to 0.27). In
domain-shift scenarios, such as drone imagery, it maintains strong performance
(species classification from 0.49 to 0.60).
  Additionally, we show that domain-specific pretraining enhances segmentation
accuracy, particularly in low-annotation regimes. An annotation-efficiency
analysis reveals that, under unseen conditions, the domain-specific model
achieves 5.4% higher F1 score than the general-purpose model, while using 80%
fewer labeled samples.
  These results demonstrate the generalization capabilities of domain-specific
foundation models and their potential to significantly reduce manual annotation
efforts, offering a scalable and automated solution for herbicide trial
analysis.

</details>


### [38] [Deep learning-based object detection of offshore platforms on Sentinel-1 Imagery and the impact of synthetic training data](https://arxiv.org/abs/2511.04304)
*Robin Spanier,Thorsten Hoeser,Claudia Kuenzer*

Main category: cs.CV

TL;DR: 本研究使用合成数据结合 YOLOv10 模型来提升对海上基础设施（特别是海上平台）的检测能力，并通过在未见区域的测试验证了模型的地理迁移能力和泛化性。


<details>
  <summary>Details</summary>
Motivation: 随着海洋基础设施的扩张，需要有效的监测系统，但现有数据集的样本不足，特别是对于代表性不足的类别。本研究旨在探索使用合成数据来增强深度学习模型在海上基础设施检测方面的性能。

Method: 结合使用 2023 年第四季度在四个区域获取的真实和合成 Sentinel-1 卫星影像，训练 YOLOv10 模型。通过在三个未见区域（墨西哥湾、北海、波斯湾）测试模型的性能来评估其地理迁移能力。

Result: 在三个新区域共检测到 3,529 个海上平台。使用合成数据后，模型的 F1 分数从 0.85 提高到 0.90。研究分析了合成数据如何改善类别不平衡和整体模型性能。

Conclusion: 本研究表明，平衡的数据集对于海上基础设施检测至关重要，而合成数据生成是解决遥感数据挑战的有效策略，并展示了深度学习在可扩展的全球海上基础设施监测方面的潜力。

Abstract: The recent and ongoing expansion of marine infrastructure, including offshore
wind farms, oil and gas platforms, artificial islands, and aquaculture
facilities, highlights the need for effective monitoring systems. The
development of robust models for offshore infrastructure detection relies on
comprehensive, balanced datasets, but falls short when samples are scarce,
particularly for underrepresented object classes, shapes, and sizes. By
training deep learning-based YOLOv10 object detection models with a combination
of synthetic and real Sentinel-1 satellite imagery acquired in the fourth
quarter of 2023 from four regions (Caspian Sea, South China Sea, Gulf of
Guinea, and Coast of Brazil), this study investigates the use of synthetic
training data to enhance model performance. We evaluated this approach by
applying the model to detect offshore platforms in three unseen regions (Gulf
of Mexico, North Sea, Persian Gulf) and thereby assess geographic
transferability. This region-holdout evaluation demonstrated that the model
generalises beyond the training areas. In total, 3,529 offshore platforms were
detected, including 411 in the North Sea, 1,519 in the Gulf of Mexico, and
1,593 in the Persian Gulf. The model achieved an F1 score of 0.85, which
improved to 0.90 upon incorporating synthetic data. We analysed how synthetic
data enhances the representation of unbalanced classes and overall model
performance, taking a first step toward globally transferable detection of
offshore infrastructure. This study underscores the importance of balanced
datasets and highlights synthetic data generation as an effective strategy to
address common challenges in remote sensing, demonstrating the potential of
deep learning for scalable, global offshore infrastructure monitoring.

</details>


### [39] [RISE-T2V: Rephrasing and Injecting Semantics with LLM for Expansive Text-to-Video Generation](https://arxiv.org/abs/2511.04317)
*Xiangjun Zhang,Litong Gong,Yinglin Zheng,Yansong Liu,Wentao Jiang,Mingyi Xu,Biao Wang,Tiezheng Ge,Ming Zeng*

Main category: cs.CV

TL;DR: RISE-T2V通过引入“重述适配器”模块，将提示重述和语义特征提取集成到一个步骤中，从而解决了现有文本到视频模型在理解简洁提示和保持视频质量方面的问题。该模型通用性强，可应用于多种大型语言模型和视频扩散模型，提高了视频生成质量和用户意图的匹配度。


<details>
  <summary>Details</summary>
Motivation: 现有的文本到视频（T2V）扩散模型在处理简洁提示时，由于文本编码器理解能力有限，往往难以保持视频质量。此外，这些编码器无法在线重述提示，限制了模型的可扩展性和可用性。

Method: RISE-T2V将提示重述和语义特征提取过程集成到单个步骤中。它引入了一个名为“重述适配器”的模块，该模块利用大型语言模型（LLM）在预测下一个词元时产生的文本隐藏状态，作为视频生成的条件。这使得视频生成模型能够隐式地将基本提示重述为更全面的表示，从而更好地匹配用户意图。

Result: RISE-T2V被证明是一个通用的框架，可以应用于不同的视频扩散模型架构。实验表明，该模型显著提高了T2V模型根据用户意图生成高质量视频的能力。

Conclusion: RISE-T2V通过集成提示重述功能，有效解决了现有T2V模型在理解和生成方面存在的局限性，提高了视频生成的质量和与用户意图的匹配度，并展示了其在不同模型架构上的通用性。

Abstract: Most text-to-video(T2V) diffusion models depend on pre-trained text encoders
for semantic alignment, yet they often fail to maintain video quality when
provided with concise prompts rather than well-designed ones. The primary issue
lies in their limited textual semantics understanding. Moreover, these text
encoders cannot rephrase prompts online to better align with user intentions,
which limits both the scalability and usability of the models, To address these
challenges, we introduce RISE-T2V, which uniquely integrates the processes of
prompt rephrasing and semantic feature extraction into a single and seamless
step instead of two separate steps. RISE-T2V is universal and can be applied to
various pre-trained LLMs and video diffusion models(VDMs), significantly
enhancing their capabilities for T2V tasks. We propose an innovative module
called the Rephrasing Adapter, enabling diffusion models to utilize text hidden
states during the next token prediction of the LLM as a condition for video
generation. By employing a Rephrasing Adapter, the video generation model can
implicitly rephrase basic prompts into more comprehensive representations that
better match the user's intent. Furthermore, we leverage the powerful
capabilities of LLMs to enable video generation models to accomplish a broader
range of T2V tasks. Extensive experiments demonstrate that RISE-T2V is a
versatile framework applicable to different video diffusion model
architectures, significantly enhancing the ability of T2V models to generate
high-quality videos that align with user intent. Visual results are available
on the webpage at https://rise-t2v.github.io.

</details>


### [40] [Submanifold Sparse Convolutional Networks for Automated 3D Segmentation of Kidneys and Kidney Tumours in Computed Tomography](https://arxiv.org/abs/2511.04334)
*Saúl Alonso-Monsalve,Leigh H. Whitehead,Adam Aurisano,Lorena Escudero Sanchez*

Main category: cs.CV

TL;DR: 本文提出了一种结合体素稀疏化和子流形稀疏卷积网络两阶段方法，用于自动分割 CT 图像中的肾脏肿瘤，在保持高精度的同时显著降低了计算资源需求。


<details>
  <summary>Details</summary>
Motivation: 自动分割医学影像中的肿瘤对于实现临床量化分析至关重要，但现有方法在处理高分辨率 3D 扫描时面临计算瓶颈。

Method: 提出了一种两阶段的新方法：首先进行体素稀疏化，然后使用子流形稀疏卷积网络，以支持高分辨率输入和原生 3D 模型架构。

Result: 在 KiTS23 挑战赛的肾癌 CT 图像上，该方法取得了优异的分割结果（肾脏+肿块 95.8%，肿瘤+囊肿 85.7%，单独肿瘤 80.3%），并且相比于稠密网络，推理时间减少了 60%，VRAM 使用量减少了 75%。

Conclusion: 所提出的两阶段稀疏卷积网络方法能够高效且精确地分割肾脏肿瘤，显著优于传统稠密网络在计算资源方面的需求，有望解决临床应用中的瓶颈问题。

Abstract: The accurate delineation of tumours in radiological images like Computed
Tomography is a very specialised and time-consuming task, and currently a
bottleneck preventing quantitative analyses to be performed routinely in the
clinical setting. For this reason, developing methods for the automated
segmentation of tumours in medical imaging is of the utmost importance and has
driven significant efforts in recent years. However, challenges regarding the
impracticality of 3D scans, given the large amount of voxels to be analysed,
usually requires the downsampling of such images or using patches thereof when
applying traditional convolutional neural networks. To overcome this problem,
in this paper we propose a new methodology that uses, divided into two stages,
voxel sparsification and submanifold sparse convolutional networks. This method
allows segmentations to be performed with high-resolution inputs and a native
3D model architecture, obtaining state-of-the-art accuracies while
significantly reducing the computational resources needed in terms of GPU
memory and time. We studied the deployment of this methodology in the context
of Computed Tomography images of renal cancer patients from the KiTS23
challenge, and our method achieved results competitive with the challenge
winners, with Dice similarity coefficients of 95.8% for kidneys + masses, 85.7%
for tumours + cysts, and 80.3% for tumours alone. Crucially, our method also
offers significant computational improvements, achieving up to a 60% reduction
in inference time and up to a 75\% reduction in VRAM usage compared to an
equivalent dense architecture, across both CPU and various GPU cards tested.

</details>


### [41] [Comparative Study of CNN Architectures for Binary Classification of Horses and Motorcycles in the VOC 2008 Dataset](https://arxiv.org/abs/2511.04344)
*Muhammad Annas Shaikh,Hamza Zaman,Arbaz Asif*

Main category: cs.CV

TL;DR: 该研究评估了九种卷积神经网络架构在VOC 2008数据集上对马匹和摩托车进行二元分类的效果，并解决了类别不平衡问题。


<details>
  <summary>Details</summary>
Motivation: 评估不同卷积神经网络架构在VOC 2008数据集上进行马匹和摩托车二元分类的效果，并解决类别不平衡问题。

Method: 通过实现少数类增强技术来解决类别不平衡问题，并比较了ResNet-50、ConvNeXt-Tiny、DenseNet-121和Vision Transformer等现代架构在多个性能指标上的表现。

Result: ConvNeXt-Tiny在马匹检测中达到了最高的平均精度（AP）95.53%，在摩托车检测中达到了89.12%。数据增强技术显著提高了少数类的检测效果，特别是对更深层的架构有益。

Conclusion: 该研究为不平衡二元分类任务中的架构选择提供了见解，并量化了数据增强策略在缓解目标检测中类别不平衡问题方面的影响。

Abstract: This paper presents a comprehensive evaluation of nine convolutional neural
network architectures for binary classification of horses and motorcycles in
the VOC 2008 dataset. We address the significant class imbalance problem by
implementing minority-class augmentation techniques. Our experiments compare
modern architectures including ResNet-50, ConvNeXt-Tiny, DenseNet-121, and
Vision Transformer across multiple performance metrics. Results demonstrate
substantial performance variations, with ConvNeXt-Tiny achieving the highest
Average Precision (AP) of 95.53% for horse detection and 89.12% for motorcycle
detection. We observe that data augmentation significantly improves minority
class detection, particularly benefiting deeper architectures. This study
provides insights into architecture selection for imbalanced binary
classification tasks and quantifies the impact of data augmentation strategies
in mitigating class imbalance issues in object detection.

</details>


### [42] [Evaluating the Impact of Weather-Induced Sensor Occlusion on BEVFusion for 3D Object Detection](https://arxiv.org/abs/2511.04347)
*Sanjay Kumar,Tim Brophy,Eoin Martino Grua,Ganesh Sistu,Valentina Donzella,Ciaran Eising*

Main category: cs.CV

TL;DR: BEVFusion在处理传感器遮挡问题时，相较于单独使用相机，对激光雷达的依赖性更强，遮挡激光雷达会导致3D目标检测性能显著下降。


<details>
  <summary>Details</summary>
Motivation: 研究传感器遮挡（由雾、霾或物理障碍物引起）对基于BEV（鸟瞰图）的3D目标检测精度的影响，特别是在自动驾驶场景下。

Method: 在nuScenes数据集上，使用BEVFusion架构，分别评估仅使用相机、仅使用激光雷达以及融合两种传感器时，受到不同程度遮挡的影响，并使用mAP和NDS作为评估指标。

Result: 中度相机遮挡导致仅使用相机检测的mAP下降41.3%（从35.6%降至20.9%）。激光雷达仅在严重遮挡下性能急剧下降，mAP下降47.3%（从64.7%降至34.1%），并严重影响远距离检测。在融合设置中，遮挡相机导致mAP仅下降4.1%（从68.5%降至65.7%），而遮挡激光雷达导致mAP下降26.8%（降至50.1%）。

Conclusion: 研究结果表明，BEVFusion模型在3D目标检测任务中更依赖激光雷达。未来的研究应关注遮挡感知评估方法和改进传感器融合技术，以应对传感器部分失效或性能下降的情况。

Abstract: Accurate 3D object detection is essential for automated vehicles to navigate
safely in complex real-world environments. Bird's Eye View (BEV)
representations, which project multi-sensor data into a top-down spatial
format, have emerged as a powerful approach for robust perception. Although
BEV-based fusion architectures have demonstrated strong performance through
multimodal integration, the effects of sensor occlusions, caused by
environmental conditions such as fog, haze, or physical obstructions, on 3D
detection accuracy remain underexplored. In this work, we investigate the
impact of occlusions on both camera and Light Detection and Ranging (LiDAR)
outputs using the BEVFusion architecture, evaluated on the nuScenes dataset.
Detection performance is measured using mean Average Precision (mAP) and the
nuScenes Detection Score (NDS). Our results show that moderate camera
occlusions lead to a 41.3% drop in mAP (from 35.6% to 20.9%) when detection is
based only on the camera. On the other hand, LiDAR sharply drops in performance
only under heavy occlusion, with mAP falling by 47.3% (from 64.7% to 34.1%),
with a severe impact on long-range detection. In fused settings, the effect
depends on which sensor is occluded: occluding the camera leads to a minor 4.1%
drop (from 68.5% to 65.7%), while occluding LiDAR results in a larger 26.8%
drop (to 50.1%), revealing the model's stronger reliance on LiDAR for the task
of 3D object detection. Our results highlight the need for future research into
occlusion-aware evaluation methods and improved sensor fusion techniques that
can maintain detection accuracy in the presence of partial sensor failure or
degradation due to adverse environmental conditions.

</details>


### [43] [A MATLAB tutorial on deep feature extraction combined with chemometrics for analytical applications](https://arxiv.org/abs/2511.04349)
*Puneet Mishra,Martijntje Vollebregt,Yizhou Ma,Maria Font-i-Furnols*

Main category: cs.CV

TL;DR: 本教程旨在弥合分析化学中深度学习应用与传统化学计量方法之间的差距，提供一个关于如何使用现有开源深度学习模型从成像数据中提取空间信息并将其与光谱信息等其他数据源集成的一步式指南。


<details>
  <summary>Details</summary>
Motivation: 分析化学中，成像技术（如彩色相机、高光谱相机和显微镜）常用于捕获材料的空间信息。然而，在探索性和预测性分析中，尤其是在使用传统化学计量方法时，有效提取和分析这些空间信息仍然是一个挑战。深度学习和人工智能的进步极大地增强了图像处理能力，能够提取传统方法难以捕捉的多尺度深度特征。尽管有许多开源深度学习模型可用，但由于缺乏结构化的分步指南，它们在分析化学中的应用仍然有限。

Method: 本教程旨在通过提供一个分步指南来解决这一差距，该指南介绍了如何将深度学习方法应用于从成像数据中提取空间信息，并将其与光谱信息等其他数据源集成。本研究的重点不是训练用于图像处理的深度学习模型，而是使用现有的开源模型从成像数据中提取深度特征。

Result: 本教程提供了 MATLAB 代码教程演示，展示了如何处理分析化学中常见的各种成像方式的成像数据。读者可以通过教程中提供的代码，在自己的数据集上运行教程步骤。

Conclusion: 本教程为分析化学家提供了一个实用、循序渐进的指南，帮助他们利用现有的深度学习模型从成像数据中提取和整合空间信息，从而克服传统方法在处理复杂空间数据方面的局限性。

Abstract: Background In analytical chemistry, spatial information about materials is
commonly captured through imaging techniques, such as traditional color cameras
or with advanced hyperspectral cameras and microscopes. However, efficiently
extracting and analyzing this spatial information for exploratory and
predictive purposes remains a challenge, especially when using traditional
chemometric methods. Recent advances in deep learning and artificial
intelligence have significantly enhanced image processing capabilities,
enabling the extraction of multiscale deep features that are otherwise
challenging to capture with conventional image processing techniques. Despite
the wide availability of open-source deep learning models, adoption in
analytical chemistry remains limited because of the absence of structured,
step-by-step guidance for implementing these models.
  Results This tutorial aims to bridge this gap by providing a step-by-step
guide for applying deep learning approaches to extract spatial information from
imaging data and integrating it with other data sources, such as spectral
information. Importantly, the focus of this work is not on training deep
learning models for image processing but on using existing open source models
to extract deep features from imaging data.
  Significance The tutorial provides MATLAB code tutorial demonstrations,
showcasing the processing of imaging data from various imaging modalities
commonly encountered in analytical chemistry. Readers must run the tutorial
steps on their own datasets using the codes presented in this tutorial.

</details>


### [44] [Multi-Task Learning for Visually Grounded Reasoning in Gastrointestinal VQA](https://arxiv.org/abs/2511.04384)
*Itbaan Safwan,Muhammad Annas Shaikh,Muhammad Haaris,Ramail Khan,Muhammad Atif Tahir*

Main category: cs.CV

TL;DR: 提出一个多任务框架，使用 LoRA 调优的 Florence-2 模型，同时进行视觉问答 (VQA)、解释生成和视觉定位，并在三个数据集上进行训练，以提高医学 VQA 的准确性和可解释性。


<details>
  <summary>Details</summary>
Motivation: 为 MediaEval Medico 2025 挑战提供一个多任务框架，以解决医学领域视觉问答的准确性和可解释性问题。

Method: 使用 LoRA 调优的 Florence-2 模型，整合 Kvasir-VQA-x1 数据集、一个合成的解释数据集和一个文本到区域数据集，进行多任务学习，以同时学习视觉定位、推理和解释。

Result: 与单一任务基线相比，在答案准确性和视觉定位方面均有显著提高。

Conclusion: 基于视觉定位的多任务学习对于医学 VQA 应用非常有效。

Abstract: We present a multi-task framework for the MediaEval Medico 2025 challenge,
leveraging a LoRA-tuned Florence-2 model for simultaneous visual question
answering (VQA), explanation generation, and visual grounding. The proposed
system integrates three curated datasets: (1) Kvasir-VQA-x1 for question-answer
learning, (2) a synthetically enriched explanation dataset offering structured
medical reasoning, and (3) text-to-region pairs linking visual features with
segmentation masks. This multi-task setup enables the model to jointly learn
visual grounding, reasoning, and interpretation, producing responses that are
both accurate and interpretable. Extensive evaluation demonstrates that our
approach substantially improves over single-task baselines in both answer
accuracy and visual localization, highlighting the effectiveness of grounded
multi-task learning for medical VQA applications.

</details>


### [45] [DORAEMON: A Unified Library for Visual Object Modeling and Representation Learning at Scale](https://arxiv.org/abs/2511.04394)
*Ke Du,Yimin Peng,Chao Gao,Fan Zhou,Siqiao Xue*

Main category: cs.CV

TL;DR: DORAEMON是一个开源PyTorch库，统一了视觉对象建模和表示学习，支持分类、检索和度量学习，提供超过1000个预训练骨干网络，并可一键导出为ONNX或HuggingFace格式，旨在加速视觉识别和表示学习的研究与应用。


<details>
  <summary>Details</summary>
Motivation: DORAEMON旨在统一视觉对象建模和表示学习，解决跨不同尺度和任务的复杂性，提供一个可扩展的平台以加速研究和实际应用。

Method: DORAEMON提供了一个统一的、由YAML驱动的工作流，支持分类、检索和度量学习。它集成了超过1000个预训练骨干网络（通过timm兼容接口）、模块化的损失函数、数据增强和分布式训练工具。该库还支持一键导出为ONNX或HuggingFace格式。

Result: 在ImageNet-1K、MS-Celeb-1M和Stanford online products数据集上，DORAEMON的复现结果达到了或超过了参考结果。

Conclusion: DORAEMON通过整合数据集、模型和训练技术，为视觉识别和表示学习的研究提供了一个可扩展的基础，能够高效地将研究成果转化为实际应用。

Abstract: DORAEMON is an open-source PyTorch library that unifies visual object
modeling and representation learning across diverse scales. A single
YAML-driven workflow covers classification, retrieval and metric learning; more
than 1000 pretrained backbones are exposed through a timm-compatible interface,
together with modular losses, augmentations and distributed-training utilities.
Reproducible recipes match or exceed reference results on ImageNet-1K,
MS-Celeb-1M and Stanford online products, while one-command export to ONNX or
HuggingFace bridges research and deployment. By consolidating datasets, models,
and training techniques into one platform, DORAEMON offers a scalable
foundation for rapid experimentation in visual recognition and representation
learning, enabling efficient transfer of research advances to real-world
applications. The repository is available at https://github.com/wuji3/DORAEMON.

</details>


### [46] [HideAndSeg: an AI-based tool with automated prompting for octopus segmentation in natural habitats](https://arxiv.org/abs/2511.04426)
*Alan de Aguiar,Michaella Pereira Andrade,Charles Morphy D. Santos,João Paulo Gois*

Main category: cs.CV

TL;DR: 该论文提出了一种名为HideAndSeg的新型AI工具，用于分割自然环境中难以追踪的章鱼视频，解决了缺乏大型标注数据集的问题。


<details>
  <summary>Details</summary>
Motivation: 分析处于自然栖息地的章鱼具有挑战性，因为它们拥有伪装能力、快速变化的皮肤纹理和颜色、非刚性身体变形以及频繁的遮挡，这些都因水下光线和浊度而加剧，并且缺乏大型标注数据集。

Method: HideAndSeg结合了SAM2和自定义训练的YOLOv11目标检测器。用户提供点坐标以使用SAM2生成初始分割蒙版，然后这些蒙版用作YOLO模型的训练数据。随后，该方法通过向SAM2提供边界框提示来完全自动化该流程，无需手动干预。引入了两个无监督指标——时间一致性DICE_t和新组件计数NC_t——以在没有真实标签数据的情况下定量评估分割质量和指导蒙版优化。

Result: HideAndSeg在分割任务上表现令人满意，与手动提示方法相比，分割噪声有所减少。我们的方法甚至能在完全遮挡后重新识别和分割章鱼，而手动提示模型在此场景下会失败。

Conclusion: HideAndSeg通过减少对现实世界场景中手动分析的需求，提供了一个实用的工具，为更有效地研究野生头足类动物的行为铺平了道路。

Abstract: Analyzing octopuses in their natural habitats is challenging due to their
camouflage capability, rapid changes in skin texture and color, non-rigid body
deformations, and frequent occlusions, all of which are compounded by variable
underwater lighting and turbidity. Addressing the lack of large-scale annotated
datasets, this paper introduces HideAndSeg, a novel, minimally supervised
AI-based tool for segmenting videos of octopuses. It establishes a quantitative
baseline for this task. HideAndSeg integrates SAM2 with a custom-trained
YOLOv11 object detector. First, the user provides point coordinates to generate
the initial segmentation masks with SAM2. These masks serve as training data
for the YOLO model. After that, our approach fully automates the pipeline by
providing a bounding box prompt to SAM2, eliminating the need for further
manual intervention. We introduce two unsupervised metrics - temporal
consistency $DICE_t$ and new component count $NC_t$ - to quantitatively
evaluate segmentation quality and guide mask refinement in the absence of
ground-truth data, i.e., real-world information that serves to train, validate,
and test AI models. Results show that HideAndSeg achieves satisfactory
performance, reducing segmentation noise compared to the manually prompted
approach. Our method can re-identify and segment the octopus even after periods
of complete occlusion in natural environments, a scenario in which the manually
prompted model fails. By reducing the need for manual analysis in real-world
scenarios, this work provides a practical tool that paves the way for more
efficient behavioral studies of wild cephalopods.

</details>


### [47] [Solving Convex Partition Visual Jigsaw Puzzles](https://arxiv.org/abs/2511.04450)
*Yaniv Ohayon,Ofir Itzhak Shahar,Ohad Ben-Shahar*

Main category: cs.CV

TL;DR: 开发了用于解决凸部分多边形拼图（一种拼图的子集）的通用求解器，并发布了第一个相关数据集。


<details>
  <summary>Details</summary>
Motivation: 现有拼图求解器主要集中在方形拼图，限制了实际应用。本研究旨在扩展到更广泛的凸部分多边形拼图。

Method: 结合几何和图像兼容性，提出了一种贪婪算法求解器，并构建了一个基准数据集。

Result: 成功解决了凸部分多边形拼图问题，并提供了性能度量和首个基准数据集。

Conclusion: 提出的方法能够有效处理比传统方形拼图更广泛的拼图类型，为拼图求解领域开辟了新的可能性。

Abstract: Jigsaw puzzle solving requires the rearrangement of unordered pieces into
their original pose in order to reconstruct a coherent whole, often an image,
and is known to be an intractable problem. While the possible impact of
automatic puzzle solvers can be disruptive in various application domains, most
of the literature has focused on developing solvers for square jigsaw puzzles,
severely limiting their practical use. In this work, we significantly expand
the types of puzzles handled computationally, focusing on what is known as
Convex Partitions, a major subset of polygonal puzzles whose pieces are convex.
We utilize both geometrical and pictorial compatibilities, introduce a greedy
solver, and report several performance measures next to the first benchmark
dataset of such puzzles.

</details>


### [48] [V-Thinker: Interactive Thinking with Images](https://arxiv.org/abs/2511.04460)
*Runqi Qiao,Qiuna Tan,Minghan Yang,Guanting Dong,Peiqing Yang,Shiqiang Lang,Enhui Wan,Xiaowan Wang,Yida Xu,Lan Yang,Chong Sun,Chen Li,Honggang Zhang*

Main category: cs.CV

TL;DR: V-Thinker是一个通用的多模态推理助手，通过端到端的强化学习实现交互式、以视觉为中心的思考，解决了现有LMM在图像交互和长视域推理方面的挑战。它包含一个数据进化飞轮和一个视觉渐进式训练课程，并引入了一个名为VTBench的基准测试。实验证明V-Thinker在通用和交互式推理方面均优于现有基线模型。


<details>
  <summary>Details</summary>
Motivation: 大型多模态模型（LMM）在深度整合图像交互和长视域推理能力方面仍面临挑战，现有方法受限于有限的视觉工具空间和特定任务的工作流设计。

Method: V-Thinker包含两个核心组件：1）数据进化飞轮，用于自动合成、进化和验证多维度（多样性、质量、难度）的交互式推理数据集；2）视觉渐进式训练课程，通过逐点监督对齐感知，然后通过两阶段强化学习框架整合交互式推理。

Result: V-Thinker在通用和交互式推理场景下均持续优于强大的LMM基线模型，为图像交互式推理应用提供了宝贵的见解。

Conclusion: V-Thinker通过其数据进化飞轮和视觉渐进式训练课程，有效提升了LMM的图像交互和长视域推理能力，并在VTBench基准测试中取得了优越的性能。

Abstract: Empowering Large Multimodal Models (LMMs) to deeply integrate image
interaction with long-horizon reasoning capabilities remains a long-standing
challenge in this field. Recent advances in vision-centric reasoning explore a
promising "Thinking with Images" paradigm for LMMs, marking a shift from
image-assisted reasoning to image-interactive thinking. While this milestone
enables models to focus on fine-grained image regions, progress remains
constrained by limited visual tool spaces and task-specific workflow designs.
To bridge this gap, we present V-Thinker, a general-purpose multimodal
reasoning assistant that enables interactive, vision-centric thinking through
end-to-end reinforcement learning. V-Thinker comprises two key components: (1)
a Data Evolution Flywheel that automatically synthesizes, evolves, and verifies
interactive reasoning datasets across three dimensions-diversity, quality, and
difficulty; and (2) a Visual Progressive Training Curriculum that first aligns
perception via point-level supervision, then integrates interactive reasoning
through a two-stage reinforcement learning framework. Furthermore, we introduce
VTBench, an expert-verified benchmark targeting vision-centric interactive
reasoning tasks. Extensive experiments demonstrate that V-Thinker consistently
outperforms strong LMM-based baselines in both general and interactive
reasoning scenarios, providing valuable insights for advancing
image-interactive reasoning applications.

</details>


### [49] [Landslide Hazard Mapping with Geospatial Foundation Models: Geographical Generalizability, Data Scarcity, and Band Adaptability](https://arxiv.org/abs/2511.04474)
*Wenwen Li,Sizhe Wang,Hyunho Lee,Chenyan Lu,Sujit Roy,Rahul Ramachandran,Chia-Yu Hsu*

Main category: cs.CV

TL;DR: GeoFMs通过三轴分析框架在滑坡测绘方面超越了传统模型，即使在数据稀疏或多变的情况下也表现出鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 滑坡造成的严重破坏使得精确及时的滑坡测绘对于灾害准备和响应至关重要。然而，传统的深度学习模型在跨不同传感器、区域或有限的训练数据条件下应用时常常遇到困难。

Method: 提出一个包含传感器、标签和域的三轴分析框架，用于调整地球空间基础模型（GeoFMs），并重点关注用于滑坡测绘的Prithvi-EO-2.0。该模型建立在全球预训练、自监督学习和适应性微调的基础上。

Result: GeoFMs在滑坡测绘任务中持续优于任务特定的CNN（U-Net, U-Net++）、视觉Transformer（Segformer, SwinV2-B）以及其他GeoFMs（TerraMind, SatMAE）。该模型能够应对光谱变化，在标签稀疏的情况下保持准确性，并在不同的数据集和地理环境中表现出更可靠的泛化能力。

Conclusion: GeoFMs为滑坡风险降低和环境监测提供了更鲁棒和可扩展的方法。然而，计算成本和可重复使用的AI就绪训练数据的可用性仍然是挑战。

Abstract: Landslides cause severe damage to lives, infrastructure, and the environment,
making accurate and timely mapping essential for disaster preparedness and
response. However, conventional deep learning models often struggle when
applied across different sensors, regions, or under conditions of limited
training data. To address these challenges, we present a three-axis analytical
framework of sensor, label, and domain for adapting geospatial foundation
models (GeoFMs), focusing on Prithvi-EO-2.0 for landslide mapping. Through a
series of experiments, we show that it consistently outperforms task-specific
CNNs (U-Net, U-Net++), vision transformers (Segformer, SwinV2-B), and other
GeoFMs (TerraMind, SatMAE). The model, built on global pretraining,
self-supervision, and adaptable fine-tuning, proved resilient to spectral
variation, maintained accuracy under label scarcity, and generalized more
reliably across diverse datasets and geographic settings. Alongside these
strengths, we also highlight remaining challenges such as computational cost
and the limited availability of reusable AI-ready training data for landslide
research. Overall, our study positions GeoFMs as a step toward more robust and
scalable approaches for landslide risk reduction and environmental monitoring.

</details>


### [50] [THEval. Evaluation Framework for Talking Head Video Generation](https://arxiv.org/abs/2511.04520)
*Nabyl Quignon,Baptiste Chopin,Yaohui Wang,Antitza Dantcheva*

Main category: cs.CV

TL;DR: 提出一个新的视频生成评估框架，包含8个指标，涵盖质量、自然度和同步性，并强调效率和与人类偏好的对齐。


<details>
  <summary>Details</summary>
Motivation: 现有的说话人脸生成评估指标有限，主要关注视频质量、唇同步和用户研究，亟需新的评估方法。

Method: 提出一个包含8个指标的评估框架，关注头部、嘴部和眉毛的细微动态以及面部质量，并强调效率和与人类偏好的对齐。

Result: 在85,000个视频的实验中，发现许多模型在唇同步方面表现良好，但在生成表现力和无瑕疵细节方面存在挑战。模型在使用了新策划的数据集进行训练，以减少训练数据偏差。

Conclusion: 提出的评估框架旨在评估生成方法的改进，并将公开代码、数据集和排行榜，以反映该领域的进展。

Abstract: Video generation has achieved remarkable progress, with generated videos
increasingly resembling real ones. However, the rapid advance in generation has
outpaced the development of adequate evaluation metrics. Currently, the
assessment of talking head generation primarily relies on limited metrics,
evaluating general video quality, lip synchronization, and on conducting user
studies. Motivated by this, we propose a new evaluation framework comprising 8
metrics related to three dimensions (i) quality, (ii) naturalness, and (iii)
synchronization. In selecting the metrics, we place emphasis on efficiency, as
well as alignment with human preferences. Based on this considerations, we
streamline to analyze fine-grained dynamics of head, mouth, and eyebrows, as
well as face quality. Our extensive experiments on 85,000 videos generated by
17 state-of-the-art models suggest that while many algorithms excel in lip
synchronization, they face challenges with generating expressiveness and
artifact-free details. These videos were generated based on a novel real
dataset, that we have curated, in order to mitigate bias of training data. Our
proposed benchmark framework is aimed at evaluating the improvement of
generative methods. Original code, dataset and leaderboards will be publicly
released and regularly updated with new methods, in order to reflect progress
in the field.

</details>


### [51] [Learning from Single Timestamps: Complexity Estimation in Laparoscopic Cholecystectomy](https://arxiv.org/abs/2511.04525)
*Dimitrios Anastasiou,Santiago Barbarisi,Lucy Culshaw,Jayna Patel,Evangelos B. Mazomenos,Imanol Luengo,Danail Stoyanov*

Main category: cs.CV

TL;DR: STC-Net是一个用于评估腹腔镜胆囊切除术（LC）中炎症严重程度的新框架，该框架可以在没有手动修剪的情况下直接处理完整的视频，并通过时间定位和分级模块实现。


<details>
  <summary>Details</summary>
Motivation: 腹腔镜胆囊切除术（LC）中手术复杂度的准确评估对于管理手术时间和降低并发症风险至关重要。虽然Parkland分级量表（PGS）用于评估炎症严重程度，但其在完整手术视频中的自动化应用仍有待探索。

Method: 提出了一种名为STC-Net的新框架，该框架采用单一时间戳进行LC中的PGS复杂性评估，并利用弱时间监督。该框架包含一个定位、窗口建议和分级模块，能够同时进行时间定位和分级，并采用结合硬、软定位目标和背景感知分级监督的新损失函数。

Result: 在包含1,859个LC视频的私有数据集中，STC-Net实现了62.11%的准确率和61.42%的F1分数，在准确率和F1分数上均优于不进行定位的基线方法10%以上。

Conclusion: STC-Net提供了一种可扩展且有效的方法，可以从完整的LC视频中自动评估基于PGS的手术复杂度，这对于术后分析和手术培训具有重要意义。

Abstract: Purpose: Accurate assessment of surgical complexity is essential in
Laparoscopic Cholecystectomy (LC), where severe inflammation is associated with
longer operative times and increased risk of postoperative complications. The
Parkland Grading Scale (PGS) provides a clinically validated framework for
stratifying inflammation severity; however, its automation in surgical videos
remains largely unexplored, particularly in realistic scenarios where complete
videos must be analyzed without prior manual curation. Methods: In this work,
we introduce STC-Net, a novel framework for SingleTimestamp-based Complexity
estimation in LC via the PGS, designed to operate under weak temporal
supervision. Unlike prior methods limited to static images or manually trimmed
clips, STC-Net operates directly on full videos. It jointly performs temporal
localization and grading through a localization, window proposal, and grading
module. We introduce a novel loss formulation combining hard and soft
localization objectives and background-aware grading supervision. Results:
Evaluated on a private dataset of 1,859 LC videos, STC-Net achieves an accuracy
of 62.11% and an F1-score of 61.42%, outperforming non-localized baselines by
over 10% in both metrics and highlighting the effectiveness of weak supervision
for surgical complexity assessment. Conclusion: STC-Net demonstrates a scalable
and effective approach for automated PGS-based surgical complexity estimation
from full LC videos, making it promising for post-operative analysis and
surgical training.

</details>


### [52] [Thinking with Video: Video Generation as a Promising Multimodal Reasoning Paradigm](https://arxiv.org/abs/2511.04570)
*Jingqi Tong,Yurong Mou,Hangcheng Li,Mingzhe Li,Yongzhuo Yang,Ming Zhang,Qiguang Chen,Tianyi Liang,Xiaomeng Hu,Yining Zheng,Xinchi Chen,Jun Zhao,Xuanjing Huang,Xipeng Qiu*

Main category: cs.CV

TL;DR: 提出“视频思考”范式，并开发了VideoThinkBench基准，展示了Sora-2在统一的多模态理解和生成方面的潜力。


<details>
  <summary>Details</summary>
Motivation: 现有的“文本思考”和“图像思考”范式在处理动态过程和统一多模态理解方面存在局限性。

Method: 提出“视频思考”范式，利用Sora-2等视频生成模型，并开发了VideoThinkBench基准，包含视觉和文本任务。

Result: Sora-2在视觉任务上表现与SOTA VLM相当，在文本任务（MATH、MMMU）上取得了高准确率。自我一致性和上下文学习能进一步提升性能。

Conclusion: 视频生成模型有潜力成为统一的多模态模型，“视频思考”范式是统一的多模态推理范式。

Abstract: "Thinking with Text" and "Thinking with Images" paradigm significantly
improve the reasoning ability of large language models (LLMs) and Vision
Language Models (VLMs). However, these paradigms have inherent limitations. (1)
Images capture only single moments and fail to represent dynamic processes or
continuous changes, and (2) The separation of text and vision as distinct
modalities, hindering unified multimodal understanding and generation. To
overcome these limitations, we introduce "Thinking with Video", a new paradigm
that leverages video generation models, such as Sora-2, to bridge visual and
textual reasoning in a unified temporal framework. To support this exploration,
we developed the Video Thinking Benchmark (VideoThinkBench). VideoThinkBench
encompasses two task categories: (1) vision-centric tasks (e.g., Eyeballing
Puzzles), and (2) text-centric tasks (e.g., subsets of GSM8K, MMMU). Our
evaluation establishes Sora-2 as a capable reasoner. On vision-centric tasks,
Sora-2 is generally comparable to state-of-the-art (SOTA) VLMs, and even
surpasses VLMs on several tasks, such as Eyeballing Games. On text-centric
tasks, Sora-2 achieves 92% accuracy on MATH, and 75.53% accuracy on MMMU.
Furthermore, we systematically analyse the source of these abilities. We also
find that self-consistency and in-context learning can improve Sora-2's
performance. In summary, our findings demonstrate that the video generation
model is the potential unified multimodal understanding and generation model,
positions "thinking with video" as a unified multimodal reasoning paradigm.

</details>


### [53] [UniSplat: Unified Spatio-Temporal Fusion via 3D Latent Scaffolds for Dynamic Driving Scene Reconstruction](https://arxiv.org/abs/2511.04595)
*Chen Shi,Shaoshuai Shi,Xiaoyang Lyu,Chunyang Liu,Kehua Sheng,Bo Zhang,Li Jiang*

Main category: cs.CV

TL;DR: UniSplat是一个用于自动驾驶的3D动态场景重建框架，通过统一的潜在时空融合学习，解决了稀疏、非重叠的相机视图和复杂场景动态的挑战。


<details>
  <summary>Details</summary>
Motivation: 现有3D重建方法在处理稀疏、非重叠的相机视图和复杂的场景动态方面存在困难。

Method: UniSplat构建了一个3D潜在支架，利用预训练的基础模型捕获几何和语义场景上下文。通过在3D支架内进行高效融合，实现一致的时空对齐。设计了一个双分支解码器，结合点锚定细化和基于体素的生成，从融合的支架中生成动态感知的高斯点，并维护静态高斯点的持久内存，以实现超出当前相机覆盖范围的流式场景补全。

Result: UniSplat在真实世界数据集上实现了最先进的性能，在新的视图合成方面表现优异，即使在原始相机覆盖范围之外的视角也能提供鲁棒且高质量的渲染。

Conclusion: UniSplat是一个通用的前馈框架，能够学习鲁棒的动态场景重建，并能提供高质量的、超出相机覆盖范围的渲染。

Abstract: Feed-forward 3D reconstruction for autonomous driving has advanced rapidly,
yet existing methods struggle with the joint challenges of sparse,
non-overlapping camera views and complex scene dynamics. We present UniSplat, a
general feed-forward framework that learns robust dynamic scene reconstruction
through unified latent spatio-temporal fusion. UniSplat constructs a 3D latent
scaffold, a structured representation that captures geometric and semantic
scene context by leveraging pretrained foundation models. To effectively
integrate information across spatial views and temporal frames, we introduce an
efficient fusion mechanism that operates directly within the 3D scaffold,
enabling consistent spatio-temporal alignment. To ensure complete and detailed
reconstructions, we design a dual-branch decoder that generates dynamic-aware
Gaussians from the fused scaffold by combining point-anchored refinement with
voxel-based generation, and maintain a persistent memory of static Gaussians to
enable streaming scene completion beyond current camera coverage. Extensive
experiments on real-world datasets demonstrate that UniSplat achieves
state-of-the-art performance in novel view synthesis, while providing robust
and high-quality renderings even for viewpoints outside the original camera
coverage.

</details>


### [54] [PixCLIP: Achieving Fine-grained Visual Language Understanding via Any-granularity Pixel-Text Alignment Learning](https://arxiv.org/abs/2511.04601)
*Yicheng Xiao,Yu Chen,Haoxuan Ma,Jiale Hong,Caorui Li,Lingxiang Wu,Haiyun Guo,Jinqiao Wang*

Main category: cs.CV

TL;DR: PixCLIP通过引入视觉提示和长文本处理来增强CLIP的细粒度图像-文本匹配能力，并在像素级交互和长文本处理方面取得突破性进展，达到最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法主要通过增强视觉信息处理的粒度来提升CLIP在细粒度图像-文本匹配上的能力，而忽略了利用长文本描述来提升模型性能。CLIP的文本编码器在处理长文本方面存在局限。因此，需要一种能够同时利用视觉提示和长文本描述的方法来提升细粒度图像-文本匹配能力。

Method: 提出PixCLIP框架，该框架能够同时处理视觉提示输入和长文本描述。具体来说，首先建立了一个自动化标注流程，生成像素级局部长文本描述，并构建了包含近150万个样本的高质量数据集LongGRIT。其次，用LLM替换CLIP的原始文本编码器，并提出一个三分支像素-文本对齐学习框架，以实现图像区域和任意粒度的文本描述之间的细粒度对齐。

Result: 实验表明，PixCLIP在像素级交互和处理长文本方面取得了突破性进展，达到了最先进的性能。

Conclusion: PixCLIP框架能够有效地融合视觉提示和长文本描述，显著提升模型在细粒度图像-文本匹配任务上的表现，特别是在像素级交互和处理长文本方面。

Abstract: While the Contrastive Language-Image Pretraining(CLIP) model has achieved
remarkable success in a variety of downstream vison language understanding
tasks, enhancing its capability for fine-grained image-text alignment remains
an active research focus. To this end, most existing works adopt the strategy
of explicitly increasing the granularity of visual information processing,
e.g., incorporating visual prompts to guide the model focus on specific local
regions within the image. Meanwhile, researches on Multimodal Large Language
Models(MLLMs) have demonstrated that training with long and detailed textual
descriptions can effectively improve the model's fine-grained vision-language
alignment. However, the inherent token length limitation of CLIP's text encoder
fundamentally limits CLIP to process more granular textual information embedded
in long text sequences. To synergistically leverage the advantages of enhancing
both visual and textual content processing granularity, we propose PixCLIP, a
novel framework designed to concurrently accommodate visual prompt inputs and
process lengthy textual descriptions. Specifically, we first establish an
automated annotation pipeline capable of generating pixel-level localized,
long-form textual descriptions for images. Utilizing this pipeline, we
construct LongGRIT, a high-quality dataset comprising nearly 1.5 million
samples. Secondly, we replace CLIP's original text encoder with the LLM and
propose a three-branch pixel-text alignment learning framework, facilitating
fine-grained alignment between image regions and corresponding textual
descriptions at arbitrary granularity. Experiments demonstrate that PixCLIP
showcases breakthroughs in pixel-level interaction and handling long-form
texts, achieving state-of-the-art performance.

</details>


### [55] [Building Trust in Virtual Immunohistochemistry: Automated Assessment of Image Quality](https://arxiv.org/abs/2511.04615)
*Tushar Kataria,Shikha Dubey,Mary Bronner,Jolanta Jedrzkiewicz,Ben J. Brintz,Shireen Y. Elhabian,Beatrice S. Knudsen*

Main category: cs.CV

TL;DR: 本研究提出了一个自动化的、基于准确性的框架来评估虚拟免疫组织化学（IHC）图像生成的质量，解决了现有指标无法准确量化IHC染色准确性的问题。


<details>
  <summary>Details</summary>
Motivation: 现有的图像质量评估指标（如基于纹理和分布的指标）仅能量化图像保真度，而无法准确评估虚拟IHC染色效果，限制了虚拟IHC技术的临床应用。

Method: 利用颜色解卷积技术，生成由模型预测的棕色染色（IHC阳性）像素的掩膜。通过比较真实和虚拟IHC图像的掩膜，计算Dice、IoU和Hausdorff距离等指标，直接量化像素级别的标签准确性，无需人工标注。

Result: 研究发现，传统的图像保真度指标（FID、PSNR、SSIM）与染色准确性及病理学家的评估结果相关性较低。成对模型（如PyramidPix2Pix和AdaptiveNCE）在染色准确性方面表现最佳，而非成对扩散模型和GAN模型则在提供准确的IHC阳性像素标签方面可靠性较低。此外，在全幻灯片图像（WSI）层面评估时，一些在图像块层面不明显的性能下降问题得以显现，表明需要WSI级别的基准测试。

Conclusion: 本研究提出的框架为评估虚拟IHC模型的质量提供了一种可重复的方法，这是加速虚拟IHC技术在病理学中常规应用的关键一步。

Abstract: Deep learning models can generate virtual immunohistochemistry (IHC) stains
from hematoxylin and eosin (H&E) images, offering a scalable and low-cost
alternative to laboratory IHC. However, reliable evaluation of image quality
remains a challenge as current texture- and distribution-based metrics quantify
image fidelity rather than the accuracy of IHC staining. Here, we introduce an
automated and accuracy grounded framework to determine image quality across
sixteen paired or unpaired image translation models. Using color deconvolution,
we generate masks of pixels stained brown (i.e., IHC-positive) as predicted by
each virtual IHC model. We use the segmented masks of real and virtual IHC to
compute stain accuracy metrics (Dice, IoU, Hausdorff distance) that directly
quantify correct pixel - level labeling without needing expert manual
annotations. Our results demonstrate that conventional image fidelity metrics,
including Frechet Inception Distance (FID), peak signal-to-noise ratio (PSNR),
and structural similarity (SSIM), correlate poorly with stain accuracy and
pathologist assessment. Paired models such as PyramidPix2Pix and AdaptiveNCE
achieve the highest stain accuracy, whereas unpaired diffusion- and GAN-based
models are less reliable in providing accurate IHC positive pixel labels.
Moreover, whole-slide images (WSI) reveal performance declines that are
invisible in patch-based evaluations, emphasizing the need for WSI-level
benchmarks. Together, this framework defines a reproducible approach for
assessing the quality of virtual IHC models, a critical step to accelerate
translation towards routine use by pathologists.

</details>


### [56] [NovisVQ: A Streaming Convolutional Neural Network for No-Reference Opinion-Unaware Frame Quality Assessment](https://arxiv.org/abs/2511.04628)
*Kylie Cancilla,Alexander Moore,Amar Saini,Carmen Carrano*

Main category: cs.CV

TL;DR: 提出一种无需参考视频也无需人类标注的视频质量评估模型，该模型能处理流式数据并考虑时间上下文。


<details>
  <summary>Details</summary>
Motivation: 现有视频质量评估（VQA）方法存在局限：全参考（FR）方法需要参考视频，无参考（NR）方法通常依赖昂贵的人类意见标签。此外，大多数无参考且不考虑意见的方法是基于图像的，忽略了对视频目标检测至关重要的时间上下文。

Method: 提出一个可扩展的、基于流的VQA模型。该模型利用DAVIS数据集的合成退化，训练一个考虑时间信息的卷积神经网络，直接从退化视频预测FR指标（LPIPS, PSNR, SSIM），在推理时无需参考视频。

Result: 该流式方法在泛化到各种退化方面优于基于图像的基线方法，证明了时间建模对于可扩展VQA的价值。此外，与广泛使用的基于意见的图像质量评估基线BRISQUE相比，该模型与FR指标的相关性更高。

Conclusion: 所提出的无需参考、不考虑意见的VQA模型通过利用时间信息和合成退化，能够有效地处理流式视频数据，并在评估视频质量方面取得优于现有方法的性能。

Abstract: Video quality assessment (VQA) is vital for computer vision tasks, but
existing approaches face major limitations: full-reference (FR) metrics require
clean reference videos, and most no-reference (NR) models depend on training on
costly human opinion labels. Moreover, most opinion-unaware NR methods are
image-based, ignoring temporal context critical for video object detection. In
this work, we present a scalable, streaming-based VQA model that is both
no-reference and opinion-unaware. Our model leverages synthetic degradations of
the DAVIS dataset, training a temporal-aware convolutional architecture to
predict FR metrics (LPIPS , PSNR, SSIM) directly from degraded video, without
references at inference. We show that our streaming approach outperforms our
own image-based baseline by generalizing across diverse degradations,
underscoring the value of temporal modeling for scalable VQA in real-world
vision systems. Additionally, we demonstrate that our model achieves higher
correlation with full-reference metrics compared to BRISQUE, a widely-used
opinion-aware image quality assessment baseline, validating the effectiveness
of our temporal, opinion-unaware approach.

</details>


### [57] [Polarization-resolved imaging improves eye tracking](https://arxiv.org/abs/2511.04652)
*Mantas Žurauskas,Tom Bu,Sanaz Alali,Beyza Kalkanli,Derek Shi,Fernando Alamos,Gauresh Pandit,Christopher Mei,Ali Behrooz,Ramin Mirjalili,Dave Stronks,Alexander Fix,Dmitri Model*

Main category: cs.CV

TL;DR: 通过近红外偏振成像技术，可以增强眼动追踪的对比度，从而提高追踪的准确性，尤其是在眼睑遮挡、眼部移位和瞳孔大小变化等情况下。该技术通过捕捉眼部组织的偏振光信息，能在巩膜和角膜上揭示强度图像中难以观察到的特征和模式。


<details>
  <summary>Details</summary>
Motivation: 现有的眼动追踪技术在某些情况下（如眼睑遮挡、眼部移位、瞳孔大小变化）存在准确性不足的问题。本研究旨在利用偏振信息来增强眼动追踪的对比度和鲁棒性。

Method: 提出了一种偏振眼动追踪（PET）系统，该系统结合了偏振滤光片阵列相机和线偏振近红外照明器。利用卷积神经网络（CNN）训练机器学习模型，处理PET系统捕捉到的数据（包括强度和偏振信息）。

Result: 在346名参与者的数据集上，基于PET的机器学习模型在中值95%绝对注视误差方面，相比仅使用强度信息的基线模型，在名义条件和存在眼睑遮挡、眼部移位、瞳孔大小变化的情况下，分别降低了10-16%。

Conclusion: 近红外偏振成像是一种简单且鲁棒的传感方式，可以为未来的可穿戴设备提供眼动追踪功能，并在人机交互领域带来实际应用价值。

Abstract: Polarization-resolved near-infrared imaging adds a useful optical contrast
mechanism to eye tracking by measuring the polarization state of light
reflected by ocular tissues in addition to its intensity. In this paper we
demonstrate how this contrast can be used to enable eye tracking. Specifically,
we demonstrate that a polarization-enabled eye tracking (PET) system composed
of a polarization--filter--array camera paired with a linearly polarized
near-infrared illuminator can reveal trackable features across the sclera and
gaze-informative patterns on the cornea, largely absent in intensity-only
images. Across a cohort of 346 participants, convolutional neural network based
machine learning models trained on data from PET reduced the median
95th-percentile absolute gaze error by 10--16\% relative to capacity-matched
intensity baselines under nominal conditions and in the presence of eyelid
occlusions, eye-relief changes, and pupil-size variation. These results link
light--tissue polarization effects to practical gains in human--computer
interaction and position PET as a simple, robust sensing modality for future
wearable devices.

</details>


### [58] [Benchmark Designers Should "Train on the Test Set" to Expose Exploitable Non-Visual Shortcuts](https://arxiv.org/abs/2511.04655)
*Ellis Brown,Jihan Yang,Shusheng Yang,Rob Fergus,Saining Xie*

Main category: cs.CV

TL;DR: 许多多模态大语言模型基准测试会被非视觉因素所干扰，本文提出了一种测试、诊断和消除偏差的方法，并通过实验验证了该方法的有效性。


<details>
  <summary>Details</summary>
Motivation: 现有的基准测试可能无法准确评估多模态大语言模型的真实视觉理解能力，因为模型可能利用了非视觉线索（如语言先验、表面模式）来获得高分。这使得基准测试的设计和评估变得不那么可靠。

Method: 本文提出了一个诊断和去偏的框架。首先，使用“测试集压力测试”（TsT）方法，通过在测试集的非视觉文本输入上微调大语言模型来识别和量化偏差。然后，采用“迭代偏差剪枝”（IBP）程序过滤掉高偏差的样本。

Result: 在四个基准测试（VSI-Bench, CV-Bench, MMMU, VideoMME）上的实验表明，普遍存在非视觉偏差。通过对VSI-Bench进行去偏处理，创建了VSI-Bench-Debiased，显著降低了非视觉可解性，并扩大了视觉盲性能的差距。

Conclusion: 本文提出的框架能够有效地识别和消除多模态大语言模型基准测试中的非视觉偏差，从而更准确地评估模型的视觉理解能力。

Abstract: Robust benchmarks are crucial for evaluating Multimodal Large Language Models
(MLLMs). Yet we find that models can ace many multimodal benchmarks without
strong visual understanding, instead exploiting biases, linguistic priors, and
superficial patterns. This is especially problematic for vision-centric
benchmarks that are meant to require visual inputs. We adopt a diagnostic
principle for benchmark design: if a benchmark can be gamed, it will be.
Designers should therefore try to ``game'' their own benchmarks first, using
diagnostic and debiasing procedures to systematically identify and mitigate
non-visual biases. Effective diagnosis requires directly ``training on the test
set'' -- probing the released test set for its intrinsic, exploitable patterns.
  We operationalize this standard with two components. First, we diagnose
benchmark susceptibility using a ``Test-set Stress-Test'' (TsT) methodology.
Our primary diagnostic tool involves fine-tuning a powerful Large Language
Model via $k$-fold cross-validation on exclusively the non-visual, textual
inputs of the test set to reveal shortcut performance and assign each sample a
bias score $s(x)$. We complement this with a lightweight Random Forest-based
diagnostic operating on hand-crafted features for fast, interpretable auditing.
Second, we debias benchmarks by filtering high-bias samples using an
``Iterative Bias Pruning'' (IBP) procedure. Applying this framework to four
benchmarks -- VSI-Bench, CV-Bench, MMMU, and VideoMME -- we uncover pervasive
non-visual biases. As a case study, we apply our full framework to create
VSI-Bench-Debiased, demonstrating reduced non-visual solvability and a wider
vision-blind performance gap than the original.

</details>


### [59] [SIMS-V: Simulated Instruction-Tuning for Spatial Video Understanding](https://arxiv.org/abs/2511.04668)
*Ellis Brown,Arijit Ray,Ranjay Krishna,Ross Girshick,Rob Fergus,Saining Xie*

Main category: cs.CV

TL;DR: SIMS-V是一个数据生成框架，利用3D模拟器生成用于训练多模态语言模型的空间丰富视频数据，通过识别三种关键问题类型（度量测量、视角相关推理和时间跟踪），实现了高效的训练和对真实世界空间推理任务的有效迁移。


<details>
  <summary>Details</summary>
Motivation: 当前多模态语言模型在视频的空间推理方面存在不足，而获取多样化且带有精确空间标注的真实世界视频数据存在瓶颈。

Method: 利用3D模拟器的特权信息，构建SIMS-V数据生成框架，系统地消融问题类型、混合和规模，以研究模拟数据中哪些属性能够促进有效的真实世界迁移。

Result: 研究发现，仅包含度量测量、视角相关推理和时间跟踪这三种问题类型的数据集，在提升可迁移的空间智能方面最为有效，并且比包含更多问题类型的数据集效果更好。使用该框架训练的7B参数视频语言模型，在仅25K模拟样本上进行微调后，表现优于72B基线模型，并在真实世界空间推理基准测试中取得了与专有模型相当的性能。

Conclusion: SIMS-V框架通过生成空间丰富的数据并结合有效的训练策略，能够显著提升多模态语言模型在空间推理方面的能力，并实现良好的泛化性能，在通用视频理解和具身及真实世界空间任务方面均有提升。

Abstract: Despite impressive high-level video comprehension, multimodal language models
struggle with spatial reasoning across time and space. While current spatial
training approaches rely on real-world video data, obtaining diverse footage
with precise spatial annotations remains a bottleneck. To alleviate this
bottleneck, we present SIMS-V -- a systematic data-generation framework that
leverages the privileged information of 3D simulators to create spatially-rich
video training data for multimodal language models. Using this framework, we
investigate which properties of simulated data drive effective real-world
transfer through systematic ablations of question types, mixes, and scales. We
identify a minimal set of three question categories (metric measurement,
perspective-dependent reasoning, and temporal tracking) that prove most
effective for developing transferable spatial intelligence, outperforming
comprehensive coverage despite using fewer question types. These insights
enable highly efficient training: our 7B-parameter video LLM fine-tuned on just
25K simulated examples outperforms the larger 72B baseline and achieves
competitive performance with proprietary models on rigorous real-world spatial
reasoning benchmarks. Our approach demonstrates robust generalization,
maintaining performance on general video understanding while showing
substantial improvements on embodied and real-world spatial tasks.

</details>


### [60] [Cambrian-S: Towards Spatial Supersensing in Video](https://arxiv.org/abs/2511.04670)
*Shusheng Yang,Jihan Yang,Pinzhi Huang,Ellis Brown,Zihao Yang,Yue Yu,Shengbang Tong,Zihan Zheng,Yifan Xu,Muhan Wang,Daohan Lu,Rob Fergus,Yann LeCun,Li Fei-Fei,Saining Xie*

Main category: cs.CV

TL;DR: 真正的多模态智能需要从反应式、任务驱动系统转向更广泛的超感知范式，并引入VSI-SUPER基准测试和预测感知方法来推动空间超感知的发展。


<details>
  <summary>Details</summary>
Motivation: 当前的多模态理解基准测试主要集中在早期阶段，对空间认知覆盖不足，并且未能有效挑战模型进行真正的世界建模。作者认为，真正的多模态智能发展需要一种名为“超感知”的更广泛范式。

Method: 作者提出了空间超感知的四个阶段：语义感知、流式事件认知、隐式3D空间认知和预测世界建模。他们设计了VSI-SUPER基准测试，包含VSR（长时视觉空间回忆）和VSC（持续视觉空间计数）两个任务，以评估模型在长视频输入下的空间认知能力。此外，他们还通过VSI-590K数据集和Cambrian-S模型进行了数据扩展实验，并提出了一种预测感知方法，利用自监督的下一个潜在帧预测器和惊喜（预测误差）来驱动记忆和事件分割。

Result: 在VSI-SUPER基准测试上，Cambrian-S模型取得了显著的进步，但性能仍然有限，表明单纯的数据扩展不足以实现空间超感知。然而，提出的预测感知方法在VSI-SUPER上取得了优于领先的专有基线模型的性能。

Conclusion: 空间超感知不仅仅需要模型能够“看到”世界，还需要它们能够“预测”、“选择”和“组织”经验。预测感知是一种有前途的途径，能够推动多模态智能的进一步发展。

Abstract: We argue that progress in true multimodal intelligence calls for a shift from
reactive, task-driven systems and brute-force long context towards a broader
paradigm of supersensing. We frame spatial supersensing as four stages beyond
linguistic-only understanding: semantic perception (naming what is seen),
streaming event cognition (maintaining memory across continuous experiences),
implicit 3D spatial cognition (inferring the world behind pixels), and
predictive world modeling (creating internal models that filter and organize
information). Current benchmarks largely test only the early stages, offering
narrow coverage of spatial cognition and rarely challenging models in ways that
require true world modeling. To drive progress in spatial supersensing, we
present VSI-SUPER, a two-part benchmark: VSR (long-horizon visual spatial
recall) and VSC (continual visual spatial counting). These tasks require
arbitrarily long video inputs yet are resistant to brute-force context
expansion. We then test data scaling limits by curating VSI-590K and training
Cambrian-S, achieving +30% absolute improvement on VSI-Bench without
sacrificing general capabilities. Yet performance on VSI-SUPER remains limited,
indicating that scale alone is insufficient for spatial supersensing. We
propose predictive sensing as a path forward, presenting a proof-of-concept in
which a self-supervised next-latent-frame predictor leverages surprise
(prediction error) to drive memory and event segmentation. On VSI-SUPER, this
approach substantially outperforms leading proprietary baselines, showing that
spatial supersensing requires models that not only see but also anticipate,
select, and organize experience.

</details>


### [61] [InfinityStar: Unified Spacetime AutoRegressive Modeling for Visual Generation](https://arxiv.org/abs/2511.04675)
*Jinlai Liu,Jian Han,Bin Yan,Hui Wu,Fengda Zhu,Xing Wang,Yi Jiang,Bingyue Peng,Zehuan Yuan*

Main category: cs.CV

TL;DR: InfinityStar是一个统一的时空自回归框架，用于高分辨率图像和动态视频合成，它能够通过简单的时序自回归来处理文本到图像、文本到视频、图像到视频以及长交互视频合成等多种生成任务，并且在VBench上取得了83.74的高分，同时生成速度比基于扩散的方法快10倍。


<details>
  <summary>Details</summary>
Motivation: 在视觉和语言领域自回归建模取得成功的基础上，提出一种能够处理图像和视频合成的统一框架。

Method: 提出InfinityStar，一个纯粹离散的统一时空自回归框架，能够联合捕捉空间和时间依赖性。

Result: InfinityStar在VBench上得分83.74，优于所有自回归模型，并超越了部分扩散模型。模型生成5秒720p视频的速度比领先的扩散模型快约10倍。

Conclusion: InfinityStar是首个能够生成工业级720p视频的离散自回归视频生成器，并且实现了高效的生成速度。

Abstract: We introduce InfinityStar, a unified spacetime autoregressive framework for
high-resolution image and dynamic video synthesis. Building on the recent
success of autoregressive modeling in both vision and language, our purely
discrete approach jointly captures spatial and temporal dependencies within a
single architecture. This unified design naturally supports a variety of
generation tasks such as text-to-image, text-to-video, image-to-video, and long
interactive video synthesis via straightforward temporal autoregression.
Extensive experiments demonstrate that InfinityStar scores 83.74 on VBench,
outperforming all autoregressive models by large margins, even surpassing some
diffusion competitors like HunyuanVideo. Without extra optimizations, our model
generates a 5s, 720p video approximately 10x faster than leading
diffusion-based methods. To our knowledge, InfinityStar is the first discrete
autoregressive video generator capable of producing industrial level 720p
videos. We release all code and models to foster further research in efficient,
high-quality video generation.

</details>


### [62] [Tracking and Understanding Object Transformations](https://arxiv.org/abs/2511.04678)
*Yihong Sun,Xinyu Yang,Jennifer J. Sun,Bharath Hariharan*

Main category: cs.CV

TL;DR: 该论文介绍了Track Any State (TAS)任务，旨在解决目标在经历状态转变后易丢失的跟踪问题，并提出了一个名为TubeletGraph的零样本系统来解决该问题。


<details>
  <summary>Details</summary>
Motivation: 现有跟踪方法在目标经历外观剧变（如物体被切割、蝴蝶破茧）的状态转变后，常常会丢失目标，这阻碍了对现实世界物体及其动态的理解。

Method: 提出TubeletGraph零样本系统，该系统能够识别被忽略的轨迹，并基于语义和邻近性先验判断是否整合这些轨迹。然后，它推理添加的轨迹，并生成描述观察到的转变的状态图。

Result: TubeletGraph在经历状态转变的跟踪任务上取得了最先进的性能，并展示了对物体转变更深的理解，以及在复杂物体转变的时间定位和语义推理方面的潜力。

Conclusion: TubeletGraph能够有效地跟踪经历状态转变的目标，并能检测和描述状态变化，克服了现有方法的局限性。

Abstract: Real-world objects frequently undergo state transformations. From an apple
being cut into pieces to a butterfly emerging from its cocoon, tracking through
these changes is important for understanding real-world objects and dynamics.
However, existing methods often lose track of the target object after
transformation, due to significant changes in object appearance. To address
this limitation, we introduce the task of Track Any State: tracking objects
through transformations while detecting and describing state changes,
accompanied by a new benchmark dataset, VOST-TAS. To tackle this problem, we
present TubeletGraph, a zero-shot system that recovers missing objects after
transformation and maps out how object states are evolving over time.
TubeletGraph first identifies potentially overlooked tracks, and determines
whether they should be integrated based on semantic and proximity priors. Then,
it reasons about the added tracks and generates a state graph describing each
observed transformation. TubeletGraph achieves state-of-the-art tracking
performance under transformations, while demonstrating deeper understanding of
object transformations and promising capabilities in temporal grounding and
semantic reasoning for complex object transformations. Code, additional
results, and the benchmark dataset are available at
https://tubelet-graph.github.io.

</details>


### [63] [Carousel: A High-Resolution Dataset for Multi-Target Automatic Image Cropping](https://arxiv.org/abs/2511.04680)
*Rafe Loya,Andrew Hamara,Benjamin Estell,Benjamin Kilpatrick,Andrew C. Freeman*

Main category: cs.CV

TL;DR: 自动图像裁剪旨在最大化裁剪区域的人类感知质量，本文提出了生成多个不同且具有美感的裁剪的新方法。


<details>
  <summary>Details</summary>
Motivation: 现代社交媒体应用对生成多个不同且具有美感的裁剪的需求。

Method: 使用图像分割算法作为预处理步骤，并评估了几种单裁剪模型。

Result: 引入了一个包含277张图像和人工标签的数据集，并评估了所提出的方法的有效性。

Conclusion: 虽然已有研究解决了生成单个裁剪的问题，但生成多个、不同的、具有美感的裁剪仍然是一个值得研究的领域。

Abstract: Automatic image cropping is a method for maximizing the human-perceived
quality of cropped regions in photographs. Although several works have proposed
techniques for producing singular crops, little work has addressed the problem
of producing multiple, distinct crops with aesthetic appeal. In this paper, we
motivate the problem with a discussion on modern social media applications,
introduce a dataset of 277 relevant images and human labels, and evaluate the
efficacy of several single-crop models with an image partitioning algorithm as
a pre-processing step. The dataset is available at
https://github.com/RafeLoya/carousel.

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [64] [Activation-Space Personality Steering: Hybrid Layer Selection for Stable Trait Control in LLMs](https://arxiv.org/abs/2511.03738)
*Pranav Bhandari,Nicolas Fay,Sanjeevan Selvaganapathy,Amitava Datta,Usman Naseem,Mehwish Nasim*

Main category: cs.CL

TL;DR: LLMs have implicit personalities, but controlling them is hard. This paper proposes a method to extract personality traits (using the Big Five) from LLM hidden states and use them to steer the model's behavior without affecting its capabilities.


<details>
  <summary>Details</summary>
Motivation: Controlling the implicit personalities of LLMs is a challenge, and understanding the relationship between psychological traits and their representations in LLMs is underexplored. This paper aims to bridge this gap by developing a method to steer LLM behavior based on personality traits.

Method: The proposed pipeline extracts hidden state activations from transformer layers using the Big Five Personality Traits. It then applies low-rank subspace discovery methods to identify trait-specific optimal layers across different model architectures for robust injection. Finally, personality-aligned directions are operationalized through a flexible steering framework with dynamic layer selection.

Result: Personality traits occupy a low-rank shared subspace within LLMs. The proposed method can effectively steer LLM outputs to control trait expression without impacting fluency, variance, or general capabilities.

Conclusion: This paper presents a novel pipeline for extracting and utilizing personality trait representations from LLMs to steer their behavior. The findings demonstrate that personality traits reside in a low-rank subspace and can be manipulated through perturbations to achieve precise control over trait expression without compromising the model's overall performance, thus offering a practical approach to LLM alignment with psychological theory.

Abstract: Large Language Models exhibit implicit personalities in their generation, but
reliably controlling or aligning these traits to meet specific needs remains an
open challenge. The need for effective mechanisms for behavioural manipulation
of the model during generation is a critical gap in the literature that needs
to be fulfilled. Personality-aware LLMs hold a promising direction towards this
objective. However, the relationship between these psychological constructs and
their representations within LLMs remains underexplored and requires further
investigation. Moreover, it is intriguing to understand and study the use of
these representations to steer the models' behaviour. We propose a novel
pipeline that extracts hidden state activations from transformer layers using
the Big Five Personality Traits (Openness, Conscientiousness, Extraversion,
Agreeableness and Neuroticism), which is a comprehensive and empirically
validated framework to model human personality applies low-rank subspace
discovery methods, and identifies trait-specific optimal layers across
different model architectures for robust injection. The resulting
personality-aligned directions are then operationalised through a flexible
steering framework with dynamic layer selection, enabling precise control of
trait expression in LLM outputs. Our findings reveal that personality traits
occupy a low-rank shared subspace, and that these latent structures can be
transformed into actionable mechanisms for effective steering through careful
perturbations without impacting the fluency, variance and general capabilities,
helping to bridge the gap between psychological theory and practical model
alignment.

</details>


### [65] [TextualVerifier: Verify TextGrad Step-by-Step](https://arxiv.org/abs/2511.03739)
*Eugenius Mario Situmorang,Adila Alfa Krisnadhi,Ari Wibisono*

Main category: cs.CL

TL;DR: TextualVerifier是一个用于TextGrad的LLM驱动的自我验证框架，通过链式思考和多数投票来提高文本推理的有效性，实验显示在多个基准测试中显著提高了准确性。


<details>
  <summary>Details</summary>
Motivation: 现有的TextGrad方法在文本自动微分中缺乏自我验证机制，无法保证基于文本的决策的推理有效性。

Method: TextualVerifier采用链式思考分解、变体生成、多数投票和共识聚合的工作流程，并将其集成到TextGrad的损失函数和优化结果验证阶段。

Result: 在PRM800K基准测试中，TextualVerifier独立使用时，推理步骤的有效性提高了29%。与TextGrad集成后，在GPQA-Diamond、MMLU-ML和MMLU-CP基准测试中，准确性得到了显著提升（p < 0.001），损失函数集成使准确性提高了2.2个百分点，平均LLM调用开销为5.9次。单独评估TextualVerifier的不同版本，在GPQA、MMLU-ML和MMLU-CP上分别带来了8.08%、10.71%和3.92%的提升。

Conclusion: TextualVerifier是第一个为TextGrad提供的、不依赖于数值梯度即可实现LLM驱动的自我验证的框架，提高了推理的可靠性，并为文本优化中的验证开辟了新的方向。

Abstract: TextGrad is a novel approach to text-based automatic differentiation that
enables composite AI systems to perform optimization without explicit numerical
equations. However, it currently lacks self-verification mechanisms that ensure
reasoning validity in text-based decision making. This research introduces
TextualVerifier, a verification framework that leverages chain-of-thought
reasoning and majority voting with large language models to address this
verification gap. TextualVerifier implements a four-stage workflow:
chain-of-thought decomposition, variant generation, majority voting, and
consensus aggregation. It integrates non-invasively with TextGrad at both the
loss function and optimization result verification stages. Experimental
evaluation using the Gemini 1.5 Pro model is conducted in two phases: (1)
standalone evaluation on PRM800K, and (2) integrated evaluation with TextGrad
on GPQA-Diamond, MMLU-ML, and MMLU-CP benchmarks. Results show statistically
significant improvements (p < 0.001). In phase one, TextualVerifier improves
the validity of reasoning steps by 29 percent. In phase two, integration into
TextGrad loss function yields a 2.2 percentage point gain from 68.2 to 70.4
percent with a moderate overhead of 5.9 LLM calls on average. Further
evaluations of TextualVerifier versioning yield 8.08, 10.71, and 3.92
percentage point improvements on GPQA, MMLU-ML, and MMLU-CP respectively.
TextualVerifier thus presents the first self-verification framework for
TextGrad through LLM-based techniques without requiring numerical gradients,
enabling more reliable reasoning and opening new directions for verification in
text-based optimization.

</details>


### [66] [Computational Turing Test Reveals Systematic Differences Between Human and AI Language](https://arxiv.org/abs/2511.04195)
*Nicolò Pagan,Petter Törnberg,Christopher A. Bail,Anikó Hannák,Christopher Barrie*

Main category: cs.CL

TL;DR: LLM在社会科学中的应用仍需验证，现有方法不可靠。本文提出计算图灵测试框架，整合多项指标评估LLM文本的真实性，并对比九种LLM在五种策略下的表现，发现即使优化后，LLM文本在情感表达上仍与人类有显著差异，且真实性与语义保真度存在权衡。


<details>
  <summary>Details</summary>
Motivation: 现有LLM在社会科学中的应用假设其文本生成能力接近人类，但缺乏可靠的验证方法。人类判断评估方法存在局限性，导致无法有效评估LLM文本真实性或校准模型。因此，需要新的评估工具。

Method: 提出计算图灵测试框架，结合BERT可检测性、语义相似度等聚合指标，以及风格标记、主题模式等可解释的语言特征，评估LLM文本与特定数据集人类语言的接近程度。系统比较了九种开源LLM在五种校准策略（微调、风格提示、上下文检索等）下的表现，以复制X（前Twitter）、Bluesky和Reddit的用户互动。

Result: 即使经过校准，LLM的输出在情感语气和表达方面仍能明显区别于人类文本。指令调整的模型表现不如基础模型，模型规模增大也未提升其人类相似度。优化人类相似性通常以牺牲语义保真度为代价。

Conclusion: 本文提出的验证和校准框架为LLM模拟提供了可扩展的评估方法，但也警示了LLM在捕捉人类交流方面存在的局限性。

Abstract: Large language models (LLMs) are increasingly used in the social sciences to
simulate human behavior, based on the assumption that they can generate
realistic, human-like text. Yet this assumption remains largely untested.
Existing validation efforts rely heavily on human-judgment-based evaluations --
testing whether humans can distinguish AI from human output -- despite evidence
that such judgments are blunt and unreliable. As a result, the field lacks
robust tools for assessing the realism of LLM-generated text or for calibrating
models to real-world data. This paper makes two contributions. First, we
introduce a computational Turing test: a validation framework that integrates
aggregate metrics (BERT-based detectability and semantic similarity) with
interpretable linguistic features (stylistic markers and topical patterns) to
assess how closely LLMs approximate human language within a given dataset.
Second, we systematically compare nine open-weight LLMs across five calibration
strategies -- including fine-tuning, stylistic prompting, and context retrieval
-- benchmarking their ability to reproduce user interactions on X (formerly
Twitter), Bluesky, and Reddit. Our findings challenge core assumptions in the
literature. Even after calibration, LLM outputs remain clearly distinguishable
from human text, particularly in affective tone and emotional expression.
Instruction-tuned models underperform their base counterparts, and scaling up
model size does not enhance human-likeness. Crucially, we identify a trade-off:
optimizing for human-likeness often comes at the cost of semantic fidelity, and
vice versa. These results provide a much-needed scalable framework for
validation and calibration in LLM simulations -- and offer a cautionary note
about their current limitations in capturing human communication.

</details>


### [67] [GRDD+: An Extended Greek Dialectal Dataset with Cross-Architecture Fine-tuning Evaluation](https://arxiv.org/abs/2511.03772)
*Stergios Chatzikyriakidis,Dimitris Papadakis,Sevasti-Ioanna Papaioannou,Erofili Psaltaki*

Main category: cs.CL

TL;DR: GRDD+数据集扩展了现有GRDD数据集，增加了来自克里特、塞浦路斯、本都和北希腊的更多数据，并新增了六种方言（希腊-科西嘉、格里科、马尼奥特、七岛、察科尼亚和卡塔雷乌萨），总词汇量达6,374,939个，包含10种方言。该研究还进行了模型微调实验，以评估高质量方言数据对大型语言模型的影响。


<details>
  <summary>Details</summary>
Motivation: 为了扩展现有的希腊方言数据集（GRDD），增加更多数据和新的方言，从而为研究希腊方言提供更全面的资源。

Method: 通过整合来自克里特、塞浦路斯、本都和北希腊的更多数据，并新增希腊-科西嘉、格里科、马尼奥特、七岛、察科尼亚和卡塔雷乌萨六种希腊方言，构建了一个名为GRDD+的新数据集。然后，使用Llama-3-8B、Llama-3.1-8B和Krikri-8B三种模型架构，并与Claude-3.7-Sonnet、Gemini-2.5和ChatGPT-5等前沿模型进行比较，进行了一系列微调实验，以评估高质量方言数据对模型性能的影响。

Result: 构建了一个包含10种希腊方言、总计6,374,939个单词的GRDD+数据集。通过微调实验，评估了高质量方言数据对Llama-3-8B、Llama-3.1-8B和Krikri-8B模型的影响，并与Claude-3.7-Sonnet、Gemini-2.5和ChatGPT-5等模型进行了比较。

Conclusion: 高质量的希腊方言数据能够提升大型语言模型（LLMs）在处理和理解希腊方言方面的能力。GRDD+数据集的构建和相关实验为进一步研究希腊方言和改进LLMs提供了重要基础。

Abstract: We present an extended Greek Dialectal Dataset (GRDD+) 1that complements the
existing GRDD dataset with more data from Cretan, Cypriot, Pontic and Northern
Greek, while we add six new varieties: Greco-Corsican, Griko (Southern Italian
Greek), Maniot, Heptanesian, Tsakonian, and Katharevusa Greek. The result is a
dataset with total size 6,374,939 words and 10 varieties. This is the first
dataset with such variation and size to date. We conduct a number of
fine-tuning experiments to see the effect of good quality dialectal data on a
number of LLMs. We fine-tune three model architectures (Llama-3-8B,
Llama-3.1-8B, Krikri-8B) and compare the results to frontier models
(Claude-3.7-Sonnet, Gemini-2.5, ChatGPT-5).

</details>


### [68] [PLLuM: A Family of Polish Large Language Models](https://arxiv.org/abs/2511.03823)
*Jan Kocoń,Maciej Piasecki,Arkadiusz Janz,Teddy Ferdinan,Łukasz Radliński,Bartłomiej Koptyra,Marcin Oleksy,Stanisław Woźniak,Paweł Walkowiak,Konrad Wojtasik,Julia Moska,Tomasz Naskręt,Bartosz Walkowiak,Mateusz Gniewkowski,Kamil Szyc,Dawid Motyka,Dawid Banach,Jonatan Dalasiński,Ewa Rudnicka,Bartłomiej Alberski,Tomasz Walkowiak,Aleksander Szczęsny,Maciej Markiewicz,Tomasz Bernaś,Hubert Mazur,Kamil Żyta,Mateusz Tykierko,Grzegorz Chodak,Tomasz Kajdanowicz,Przemysław Kazienko,Agnieszka Karlińska,Karolina Seweryn,Anna Kołos,Maciej Chrabąszcz,Katarzyna Lorenc,Aleksandra Krasnodębska,Artur Wilczek,Katarzyna Dziewulska,Paula Betscher,Zofia Cieślińska,Katarzyna Kowol,Daria Mikoś,Maciej Trzciński,Dawid Krutul,Marek Kozłowski,Sławomir Dadas,Rafał Poświata,Michał Perełkiewicz,Małgorzata Grębowiec,Maciej Kazuła,Marcin Białas,Roman Roszko,Danuta Roszko,Jurgita Vaičenonienė,Andrius Utka,Paweł Levchuk,Paweł Kowalski,Irena Prawdzic-Jankowska,Maciej Ogrodniczuk,Monika Borys,Anna Bulińska,Wiktoria Gumienna,Witold Kieraś,Dorota Komosińska,Katarzyna Krasnowska-Kieraś,Łukasz Kobyliński,Martyna Lewandowska,Marek Łaziński,Mikołaj Łątkowski,Dawid Mastalerz,Beata Milewicz,Agnieszka Anna Mykowiecka,Angelika Peljak-Łapińska,Sandra Penno,Zuzanna Przybysz,Michał Rudolf,Piotr Rybak,Karolina Saputa,Aleksandra Tomaszewska,Aleksander Wawer,Marcin Woliński,Joanna Wołoszyn,Alina Wróblewska,Bartosz Żuk,Filip Żarnecki,Konrad Kaczyński,Anna Cichosz,Zuzanna Deckert,Monika Garnys,Izabela Grabarczyk,Wojciech Janowski,Sylwia Karasińska,Aleksandra Kujawiak,Piotr Misztela,Maria Szymańska,Karolina Walkusz,Igor Siek,Jakub Kwiatkowski,Piotr Pęzik*

Main category: cs.CL

TL;DR: PLLuM是首个大规模开源的波兰语语言模型家族，旨在解决当前AI领域对非英语语言支持不足的问题。


<details>
  <summary>Details</summary>
Motivation: 现有的大型语言模型主要集中在英语，对其他语言的支持有限，PLLuM旨在为波兰语提供高质量、透明且符合文化背景的语言模型。

Method: 开发了一个包含1400亿词元的波兰语文本预训练语料库，7.7万条自定义指令数据集和10万条偏好优化数据集。构建了一个负责任的人工智能框架，包含严格的数据治理和混合式输出校正与安全过滤模块。对基础模型和指令微调模型的架构、训练流程及对齐技术进行了详细说明。

Result: PLLuM模型在公共管理领域的下游任务中展现了其实用性。

Conclusion: 通过公开这些模型，PLLuM旨在促进开放研究，并加强波兰的自主人工智能技术。

Abstract: Large Language Models (LLMs) play a central role in modern artificial
intelligence, yet their development has been primarily focused on English,
resulting in limited support for other languages. We present PLLuM (Polish
Large Language Model), the largest open-source family of foundation models
tailored specifically for the Polish language. Developed by a consortium of
major Polish research institutions, PLLuM addresses the need for high-quality,
transparent, and culturally relevant language models beyond the English-centric
commercial landscape. We describe the development process, including the
construction of a new 140-billion-token Polish text corpus for pre-training, a
77k custom instructions dataset, and a 100k preference optimization dataset. A
key component is a Responsible AI framework that incorporates strict data
governance and a hybrid module for output correction and safety filtering. We
detail the models' architecture, training procedures, and alignment techniques
for both base and instruction-tuned variants, and demonstrate their utility in
a downstream task within public administration. By releasing these models
publicly, PLLuM aims to foster open research and strengthen sovereign AI
technologies in Poland.

</details>


### [69] [STARS: Segment-level Token Alignment with Rejection Sampling in Large Language Models](https://arxiv.org/abs/2511.03827)
*Mohammad Atif Quamar,Mohammad Areeb,Mikhail Kuznetsov,Muslum Ozgur Ozmen,Z. Berkay Celik*

Main category: cs.CL

TL;DR: STARS是一种解码时算法，通过采样、评分和拒绝/接受短的、固定大小的token片段来指导模型生成，以更高效、更高质量地使大型语言模型与人类价值观对齐。


<details>
  <summary>Details</summary>
Motivation: 对齐大型语言模型与人类价值观对于其安全部署至关重要，但现有方法（如微调）计算成本高且效果不佳，而像Best-of-N采样这样的推理时方法需要极高的计算量才能实现最优对齐。

Method: STARS（Segment-level Token Alignment with Rejection Sampling）是一种解码时算法，通过迭代地采样、评分和拒绝/接受短的、固定大小的token片段来指导模型生成，从而及早纠正生成路径。

Result: 在六种大型语言模型上，STARS的获胜率比监督微调（SFT）高出14.9个百分点，比直接偏好优化（DPO）高出4.3个百分点，并且与强大的Best-of-N基线相比仍具有竞争力。

Conclusion: STARS通过精细的、奖励指导的采样，为对齐大型语言模型提供了一种可泛化、鲁棒且高效的替代传统微调和全序列排序的方法。

Abstract: Aligning large language models with human values is crucial for their safe
deployment; however, existing methods, such as fine-tuning, are computationally
expensive and suboptimal. In contrast, inference-time approaches like Best-of-N
sampling require practically infeasible computation to achieve optimal
alignment. We propose STARS: Segment-level Token Alignment with Rejection
Sampling, a decoding-time algorithm that steers model generation by iteratively
sampling, scoring, and rejecting/accepting short, fixed-size token segments.
This allows for early correction of the generation path, significantly
improving computational efficiency and boosting alignment quality. Across a
suite of six LLMs, we show that STARS outperforms Supervised Fine-Tuning (SFT)
by up to 14.9 percentage points and Direct Preference Optimization (DPO) by up
to 4.3 percentage points on win-rates, while remaining highly competitive with
strong Best-of-N baselines. Our work establishes granular, reward-guided
sampling as a generalizable, robust, and efficient alternative to traditional
fine-tuning and full-sequence ranking methods for aligning LLMs.

</details>


### [70] [Divide, Cache, Conquer: Dichotomic Prompting for Efficient Multi-Label LLM-Based Classification](https://arxiv.org/abs/2511.03830)
*Mikołaj Langner,Jan Eliasz,Ewa Rudnicka,Jan Kocoń*

Main category: cs.CL

TL;DR: 通过将多标签文本分类重述为一系列二分决策，并结合前缀缓存机制，实现了高效的多标签文本分类。


<details>
  <summary>Details</summary>
Motivation: 为大规模语言模型（LLM）提供一种高效的多标签文本分类方法。

Method: 将多标签分类任务重述为一系列二分（是/否）决策，并结合前缀缓存机制，利用LLM进行推理。通过LLM到SLM蒸馏，使用强大的注释模型（DeepSeek-V3）为多个文本提供注释，并聚合注释以微调较小的模型（HerBERT-Large, CLARIN-1B, PLLuM-8B, Gemma3-1B）。

Result: 微调后的模型在情感文本分析任务上表现出显著的性能提升，特别是在训练过程中遇到的标签维度上，同时保持了准确性。

Conclusion: 将多标签分类分解为二分查询，并结合蒸馏和缓存感知推理，为基于LLM的分类提供了一个可扩展且有效的框架。该方法不仅适用于情感文本分析，而且具有跨领域的通用性。

Abstract: We introduce a method for efficient multi-label text classification with
large language models (LLMs), built on reformulating classification tasks as
sequences of dichotomic (yes/no) decisions. Instead of generating all labels in
a single structured response, each target dimension is queried independently,
which, combined with a prefix caching mechanism, yields substantial efficiency
gains for short-text inference without loss of accuracy. To demonstrate the
approach, we focus on affective text analysis, covering 24 dimensions including
emotions and sentiment. Using LLM-to-SLM distillation, a powerful annotator
model (DeepSeek-V3) provides multiple annotations per text, which are
aggregated to fine-tune smaller models (HerBERT-Large, CLARIN-1B, PLLuM-8B,
Gemma3-1B). The fine-tuned models show significant improvements over zero-shot
baselines, particularly on the dimensions seen during training. Our findings
suggest that decomposing multi-label classification into dichotomic queries,
combined with distillation and cache-aware inference, offers a scalable and
effective framework for LLM-based classification. While we validate the method
on affective states, the approach is general and applicable across domains.

</details>


### [71] [BAPPA: Benchmarking Agents, Plans, and Pipelines for Automated Text-to-SQL Generation](https://arxiv.org/abs/2511.04153)
*Fahim Ahmed,Md Mubtasim Ahasan,Jahir Sadik Monon,Muntasir Wahed,M Ashraful Amin,A K M Mahbubur Rahman,Amin Ahsan Ali*

Main category: cs.CL

TL;DR: 现有LLM在处理大型数据库和复杂推理的Text-to-SQL方面存在挑战，本文探索了三种多智能体LLM流水线，并对不同规模的开源模型进行了基准测试。


<details>
  <summary>Details</summary>
Motivation: 现有LLM在Text-to-SQL方面存在挑战，尤其是在处理大型数据库和复杂推理时，而小型高效模型被忽视。

Method: 本文探索了三种多智能体LLM流水线：1. 多智能体讨论流水线（迭代批评和完善SQL查询）；2. 规划-编码流水线（规划模型生成SQL生成计划，编码模型生成查询）；3. 编码-聚合流水线（多个编码模型独立生成查询，推理模型选择最佳查询）。

Result: 在Bird-Bench Mini-Dev数据集上，多智能体讨论流水线可提升小型模型性能，Qwen2.5-7b-Instruct经过三轮讨论后执行准确率提升10.6%。LLM规划-编码流水线效果最佳，DeepSeek-R1-32B和QwQ-32B规划模型将Gemma 3 27B IT的准确率从52.4%提升至56.4%。

Conclusion: 多智能体流水线，特别是规划-编码流水线，能够有效提升LLM在Text-to-SQL任务上的性能，尤其是在处理复杂数据库和推理时。小型模型也能通过多智能体讨论获得显著的性能提升。

Abstract: Text-to-SQL systems provide a natural language interface that can enable even
laymen to access information stored in databases. However, existing Large
Language Models (LLM) struggle with SQL generation from natural instructions
due to large schema sizes and complex reasoning. Prior work often focuses on
complex, somewhat impractical pipelines using flagship models, while smaller,
efficient models remain overlooked. In this work, we explore three multi-agent
LLM pipelines, with systematic performance benchmarking across a range of small
to large open-source models: (1) Multi-agent discussion pipeline, where agents
iteratively critique and refine SQL queries, and a judge synthesizes the final
answer; (2) Planner-Coder pipeline, where a thinking model planner generates
stepwise SQL generation plans and a coder synthesizes queries; and (3)
Coder-Aggregator pipeline, where multiple coders independently generate SQL
queries, and a reasoning agent selects the best query. Experiments on the
Bird-Bench Mini-Dev set reveal that Multi-Agent discussion can improve small
model performance, with up to 10.6% increase in Execution Accuracy for
Qwen2.5-7b-Instruct seen after three rounds of discussion. Among the pipelines,
the LLM Reasoner-Coder pipeline yields the best results, with DeepSeek-R1-32B
and QwQ-32B planners boosting Gemma 3 27B IT accuracy from 52.4% to the highest
score of 56.4%. Codes are available at
https://github.com/treeDweller98/bappa-sql.

</details>


### [72] [Evaluating Machine Translation Datasets for Low-Web Data Languages: A Gendered Lens](https://arxiv.org/abs/2511.03880)
*Hellina Hailu Nigatu,Bethelhem Yemane Mamo,Bontu Fufa Balcha,Debora Taye Tesfaye,Elbethel Daniel Zewdie,Ikram Behiru Nesiru,Jitu Ewnetu Hailu,Senait Mengesha Yayo*

Main category: cs.CL

TL;DR: 低资源语言的机器翻译数据集存在性别偏差和有害内容问题，仅关注数量会影响质量。


<details>
  <summary>Details</summary>
Motivation: 随着低资源语言越来越多地被纳入自然语言处理研究，人们日益重视收集大规模数据集。然而，在优先考虑数量而非质量时，我们面临着两类风险：1）为这些语言构建性能不佳的语言技术；2）产生延续社会偏见的有害内容。本文旨在调查三种低资源语言——奥罗莫语、阿姆哈拉语和提格里尼亚语——的机器翻译（MT）数据集的质量，并重点关注数据中的性别代表性。

Method: 本文调查了三种低资源语言（奥罗莫语、阿姆哈拉语和提格里尼亚语）的机器翻译数据集的质量，重点关注性别代表性。

Result: 研究结果表明，虽然训练数据主要包含政治和宗教领域的文本，但基准数据集则侧重于新闻、健康和体育领域。此外，研究还发现数据中存在明显的性别倾斜，体现在人名、动词的语法性别以及数据中的刻板印象描绘。更令人担忧的是，研究发现了针对女性的有害和攻击性描绘，这种情况在数据量最大的语言中尤为突出，这有力地证明了数量不保证质量。

Conclusion: 本文的研究结果强调了在低资源语言的机器翻译数据集中存在的性别偏见和有害内容问题，并指出仅关注数据量而忽略质量可能导致这些问题。研究者希望此项工作能激发对低资源语言数据集的进一步探究，并促进对有害内容的早期干预。

Abstract: As low-resourced languages are increasingly incorporated into NLP research,
there is an emphasis on collecting large-scale datasets. But in prioritizing
quantity over quality, we risk 1) building language technologies that perform
poorly for these languages and 2) producing harmful content that perpetuates
societal biases. In this paper, we investigate the quality of Machine
Translation (MT) datasets for three low-resourced languages--Afan Oromo,
Amharic, and Tigrinya, with a focus on the gender representation in the
datasets. Our findings demonstrate that while training data has a large
representation of political and religious domain text, benchmark datasets are
focused on news, health, and sports. We also found a large skew towards the
male gender--in names of persons, the grammatical gender of verbs, and in
stereotypical depictions in the datasets. Further, we found harmful and toxic
depictions against women, which were more prominent for the language with the
largest amount of data, underscoring that quantity does not guarantee quality.
We hope that our work inspires further inquiry into the datasets collected for
low-resourced languages and prompts early mitigation of harmful content.
WARNING: This paper contains discussion of NSFW content that some may find
disturbing.

</details>


### [73] [GRAD: Graph-Retrieved Adaptive Decoding for Hallucination Mitigation](https://arxiv.org/abs/2511.03900)
*Manh Nguyen,Sunil Gupta,Dai Do,Hung Le*

Main category: cs.CL

TL;DR: GRAD是一种解码时方法，通过在语料库派生证据中进行接地，而无需重新训练，来减轻大型语言模型的幻觉。


<details>
  <summary>Details</summary>
Motivation: 现有的幻觉缓解方法依赖于外部知识源，但基于提示的方法不稳定且受领域限制，而符号知识集成成本高昂。

Method: GRAD在解码时通过在少量检索语料库中累积下一标记logit来构建稀疏标记转换图，并将图检索到的logit与模型logit自适应地融合，以有利于高证据的延续，同时保持流畅性。

Result: 在三个模型和一系列问答基准上，GRAD的内在准确率提高了9.7%，幻觉率降低了8.6%，正确率提高了6.9%，并且在所有方法中获得了最高的真-信息量乘积得分。

Conclusion: GRAD提供了一种轻量级的、即插即用的替代方法，用于对比解码和知识图增强，表明来自语料库级别标记转换的统计证据可以有效地引导生成，以获得更真实和可验证的输出。

Abstract: Hallucination mitigation remains a persistent challenge for large language
models (LLMs), even as model scales grow. Existing approaches often rely on
external knowledge sources, such as structured databases or knowledge graphs,
accessed through prompting or retrieval. However, prompt-based grounding is
fragile and domain-sensitive, while symbolic knowledge integration incurs heavy
retrieval and formatting costs. Motivated by knowledge graphs, we introduce
Graph-Retrieved Adaptive Decoding (GRAD), a decoding-time method that grounds
generation in corpus-derived evidence without retraining. GRAD constructs a
sparse token transition graph by accumulating next-token logits across a small
retrieved corpus in a single forward pass. During decoding, graph-retrieved
logits are max-normalized and adaptively fused with model logits to favor
high-evidence continuations while preserving fluency. Across three models and a
range of question-answering benchmarks spanning intrinsic, extrinsic
hallucination, and factuality tasks, GRAD consistently surpasses baselines,
achieving up to 9.7$\%$ higher intrinsic accuracy, 8.6$\%$ lower hallucination
rates, and 6.9$\%$ greater correctness compared to greedy decoding, while
attaining the highest truth--informativeness product score among all methods.
GRAD offers a lightweight, plug-and-play alternative to contrastive decoding
and knowledge graph augmentation, demonstrating that statistical evidence from
corpus-level token transitions can effectively steer generation toward more
truthful and verifiable outputs.

</details>


### [74] [Context informs pragmatic interpretation in vision-language models](https://arxiv.org/abs/2511.03908)
*Alvin Wei Ming Tan,Ben Prystawski,Veronica Boyce,Michael C. Frank*

Main category: cs.CL

TL;DR: 模型在有相关上下文的情况下，在迭代参照游戏中表现显著优于无相关上下文时，但仍不及人类。


<details>
  <summary>Details</summary>
Motivation: 本研究旨在测试模型在多轮语言环境中进行上下文敏感的语用推理的能力，特别是在迭代参照游戏中。

Method: 测试了人类和视觉-语言模型在迭代参照游戏中的表现，并通过改变上下文的数量、顺序和相关性进行了实验。

Result: 在没有相关上下文的情况下，模型的表现优于随机猜测，但远不如人类。然而，当提供相关上下文时，模型的表现随着试验次数的增加而显著提高。在包含抽象指代物的少样本参照游戏中，机器学习模型仍然面临挑战。

Conclusion: 迭代参照游戏对机器学习模型来说仍然是一个困难的任务，尤其是在处理抽象指代物和需要深度语用推理的情况下。虽然相关上下文可以显著提高模型性能，但它们仍未达到人类水平。

Abstract: Iterated reference games - in which players repeatedly pick out novel
referents using language - present a test case for agents' ability to perform
context-sensitive pragmatic reasoning in multi-turn linguistic environments. We
tested humans and vision-language models on trials from iterated reference
games, varying the given context in terms of amount, order, and relevance.
Without relevant context, models were above chance but substantially worse than
humans. However, with relevant context, model performance increased
dramatically over trials. Few-shot reference games with abstract referents
remain a difficult task for machine learning models.

</details>


### [75] [The Human Flourishing Geographic Index: A County-Level Dataset for the United States, 2013--2023](https://arxiv.org/abs/2511.03915)
*Stefano M. Iacus,Devika Jain,Andrea Nasuto,Giuseppe Porro,Marcello Carammia,Andrea Vezzulli*

Main category: cs.CL

TL;DR: 该研究通过分析26亿条美国推文，构建了人类蓬勃发展地理指数（HFGI），以提高衡量人类蓬勃发展（包括幸福、健康、目标、美德、人际关系和财务稳定）的空间和时间分辨率。


<details>
  <summary>Details</summary>
Motivation: 需要比传统经济指标更全面地理解社会福祉，现有衡量方法缺乏精细的空间和时间分辨率。

Method: 利用大型语言模型分析2013年至2023年间约26亿条带地理位置的美国推文，对48项指标（包括哈佛全球蓬勃发展研究框架的指标，以及对移民的态度和对腐败的看法）进行分类，构建人类蓬勃发展地理指数（HFGI）。

Result: 该数据集提供了月度和年度的县级和州级指标，这些指标与人类蓬勃发展相关的讨论相关。该指数已被验证，能够准确代表其所依据的结构，并与既有指标呈现预期的相关性。

Conclusion: HFGI能够以空前的数据分辨率，支持对福祉、不平等和社会变化的跨学科分析，并深入了解社交媒体讨论中所反映的人类蓬勃发展的动态。

Abstract: Quantifying human flourishing, a multidimensional construct including
happiness, health, purpose, virtue, relationships, and financial stability, is
critical for understanding societal well-being beyond economic indicators.
Existing measures often lack fine spatial and temporal resolution. Here we
introduce the Human Flourishing Geographic Index (HFGI), derived from analyzing
approximately 2.6 billion geolocated U.S. tweets (2013-2023) using fine-tuned
large language models to classify expressions across 48 indicators aligned with
Harvard's Global Flourishing Study framework plus attitudes towards migration
and perception of corruption. The dataset offers monthly and yearly county- and
state-level indicators of flourishing-related discourse, validated to confirm
that the measures accurately represent the underlying constructs and show
expected correlations with established indicators. This resource enables
multidisciplinary analyses of well-being, inequality, and social change at
unprecedented resolution, offering insights into the dynamics of human
flourishing as reflected in social media discourse across the United States
over the past decade.

</details>


### [76] [A Characterization of List Language Identification in the Limit](https://arxiv.org/abs/2511.04103)
*Moses Charikar,Chirag Pabbaraju,Ambuj Tewari*

Main category: cs.CL

TL;DR: 语言识别领域中的


<details>
  <summary>Details</summary>
Motivation: 受语言生成问题的积极进展启发，重新探讨了语言识别问题，引入了k个猜测的额外能力。

Method: 提出了k-列表识别的精确刻画，该刻画基于Angluin的刻画的递归版本，并将k-列表可识别性与k个单列表可识别语言集合的分解联系起来。

Result: 为k-列表识别设定了指数级速率的上限和下限，并表明如果一个语言集合不可k-列表识别，则无法以任何趋近于零的速率进行k-列表识别。

Conclusion: 为k-列表识别问题提供了理论上的精确刻画和最优速率保证。

Abstract: We study the problem of language identification in the limit, where given a
sequence of examples from a target language, the goal of the learner is to
output a sequence of guesses for the target language such that all the guesses
beyond some finite time are correct. Classical results of Gold showed that
language identification in the limit is impossible for essentially any
interesting collection of languages. Later, Angluin gave a precise
characterization of language collections for which this task is possible.
Motivated by recent positive results for the related problem of language
generation, we revisit the classic language identification problem in the
setting where the learner is given the additional power of producing a list of
$k$ guesses at each time step. The goal is to ensure that beyond some finite
time, one of the guesses is correct at each time step.
  We give an exact characterization of collections of languages that can be
$k$-list identified in the limit, based on a recursive version of Angluin's
characterization (for language identification with a list of size $1$). This
further leads to a conceptually appealing characterization: A language
collection can be $k$-list identified in the limit if and only if the
collection can be decomposed into $k$ collections of languages, each of which
can be identified in the limit (with a list of size $1$). We also use our
characterization to establish rates for list identification in the statistical
setting where the input is drawn as an i.i.d. stream from a distribution
supported on some language in the collection. Our results show that if a
collection is $k$-list identifiable in the limit, then the collection can be
$k$-list identified at an exponential rate, and this is best possible. On the
other hand, if a collection is not $k$-list identifiable in the limit, then it
cannot be $k$-list identified at any rate that goes to zero.

</details>


### [77] [Direct Semantic Communication Between Large Language Models via Vector Translation](https://arxiv.org/abs/2511.03945)
*Fu-Chun Yang,Jason Eshraghian*

Main category: cs.CL

TL;DR: LLMs在多智能体协作中传递信息时会丢失大量语义信息，通过引入向量翻译器（dual-encoder translator）进行不同模型间的语义空间桥接，实现了信息的直接交互，并在此过程中保持了计算的稳定性。


<details>
  <summary>Details</summary>
Motivation: 现有LLM在多智能体协作中，通过传递普通token进行信息交互，会丢失大量潜在语义信息，并且带来不必要的计算开销。

Method: 设计了一个基于向量翻译器的“隐形桥梁”，通过学习到的映射关系实现不同模型表示空间之间的直接语义交换。训练了一个在Llama-2-7B和Mistral-7B-Instruct之间的双编码器翻译器。

Result: 该翻译器达到了0.538的平均余弦相似度。在目标模型中以30%的混合强度注入翻译后的向量，可以在不破坏logits的情况下引导目标模型的生成。双向评估显示了2.01:1的传输不对称性，表明通用模型比指令微调模型产生更具可转移性的表示。

Conclusion: 这种保守的注入方式在保持计算稳定性的同时，证明了跨模型隐式通信的可行性，从而能够构建共享意义而非token的协作式AI系统。

Abstract: In multi-agent settings, such as debate, reflection, or tool-calling, large
language models (LLMs) pass messages as plain tokens, discarding most latent
semantics. This constrains information transfer and adds unnecessary
computational overhead. We form a latent bridge via vector translations, which
use learned mappings that enable direct semantic exchange between
representation spaces. A dual-encoder translator trained between Llama-2-7B and
Mistral-7B-Instruct attains an average cosine alignment of 0.538. Injecting the
translated vectors at 30 percent blending strength steers the target model's
generation without destabilizing logits. Bidirectional evaluation shows a
2.01:1 transfer asymmetry, indicating that general-purpose models yield more
transferable representations than instruction-tuned variants. This conservative
injection preserves computational stability while demonstrating that
cross-model latent communication is feasible, enabling collaborative AI systems
that share meaning rather than tokens.

</details>


### [78] [Abductive Inference in Retrieval-Augmented Language Models: Generating and Validating Missing Premises](https://arxiv.org/abs/2511.04020)
*Shiyin Lin*

Main category: cs.CL

TL;DR: 检索增强生成（RAG）模型在检索到的证据不完整时会失败，而演绎推理可以弥补这些不足。本文提出了一种将演绎推理集成到RAG模型中的方法，通过检测不充分的证据、生成候选的缺失前提并进行一致性和合理性检查来改进答案的准确性和推理的忠实度。


<details>
  <summary>Details</summary>
Motivation: RAG模型在检索到的证据不完整时，推理过程会存在漏洞。演绎推理是填补这些漏洞的原则性方法。

Method: 提出了一种将演绎推理集成到检索增强LLM中的框架，该框架能够检测不充分的证据，生成候选的缺失前提，并通过一致性和合理性检查来验证它们。

Result: 在演绎推理和多跳问答基准测试中，该方法提高了答案的准确性和推理的忠实度。

Conclusion: 演绎推理是增强RAG系统鲁棒性和可解释性的一个有前途的方向。

Abstract: Large Language Models (LLMs) enhanced with retrieval -- commonly referred to
as Retrieval-Augmented Generation (RAG) -- have demonstrated strong performance
in knowledge-intensive tasks. However, RAG pipelines often fail when retrieved
evidence is incomplete, leaving gaps in the reasoning process. In such cases,
\emph{abductive inference} -- the process of generating plausible missing
premises to explain observations -- offers a principled approach to bridge
these gaps. In this paper, we propose a framework that integrates abductive
inference into retrieval-augmented LLMs. Our method detects insufficient
evidence, generates candidate missing premises, and validates them through
consistency and plausibility checks. Experimental results on abductive
reasoning and multi-hop QA benchmarks show that our approach improves both
answer accuracy and reasoning faithfulness. This work highlights abductive
inference as a promising direction for enhancing the robustness and
explainability of RAG systems.

</details>


### [79] [WST: Weakly Supervised Transducer for Automatic Speech Recognition](https://arxiv.org/abs/2511.04035)
*Dongji Gao,Chenda Liao,Changliang Liu,Matthew Wiesner,Leibny Paola Garcia,Daniel Povey,Sanjeev Khudanpur,Jian Wu*

Main category: cs.CL

TL;DR: 提出了一种弱监督语音识别模型 WST，即使在转录错误率高达 70% 的情况下也能有效保持性能，并且优于现有的基于 CTC 的弱监督方法。


<details>
  <summary>Details</summary>
Motivation: 由于端到端语音识别（ASR）模型（如 RNN-T）严重依赖大规模、高质量的标注数据，而这些数据成本高昂且难以获取，因此需要开发一种能够减轻这种依赖性的方法。

Method: 提出了一种名为 WST 的弱监督模型，该模型集成了一个灵活的训练图，能够稳健地处理转录错误，而无需额外的置信度估计或预训练模型。

Result: 在合成和工业数据集上的实验表明，WST 在高达 70% 的转录错误率下仍能有效保持性能，并且持续优于现有的基于 CTC 的弱监督方法（如 BTC 和 OTC）。

Conclusion: WST 在实际的 ASR 应用中具有实用性和鲁棒性，并且其实现将公开可用。

Abstract: The Recurrent Neural Network-Transducer (RNN-T) is widely adopted in
end-to-end (E2E) automatic speech recognition (ASR) tasks but depends heavily
on large-scale, high-quality annotated data, which are often costly and
difficult to obtain. To mitigate this reliance, we propose a Weakly Supervised
Transducer (WST), which integrates a flexible training graph designed to
robustly handle errors in the transcripts without requiring additional
confidence estimation or auxiliary pre-trained models. Empirical evaluations on
synthetic and industrial datasets reveal that WST effectively maintains
performance even with transcription error rates of up to 70%, consistently
outperforming existing Connectionist Temporal Classification (CTC)-based weakly
supervised approaches, such as Bypass Temporal Classification (BTC) and
Omni-Temporal Classification (OTC). These results demonstrate the practical
utility and robustness of WST in realistic ASR settings. The implementation
will be publicly available.

</details>


### [80] [T-FIX: Text-Based Explanations with Features Interpretable to eXperts](https://arxiv.org/abs/2511.04070)
*Shreya Havaldar,Helen Jin,Chaehyeon Kim,Anton Xue,Weiqiu You,Marco Gatti,Bhuvnesh Jain,Helen Qu,Daniel A Hashimoto,Amin Madani,Rajat Deo,Sameed Ahmed M. Khatana,Gary E. Weissman,Lyle Ungar,Eric Wong*

Main category: cs.CL

TL;DR: 用户期望LLM提供有意义的解释，尤其是在知识密集型领域，但现有评估方法未能充分衡量LLM解释与专家直觉的一致性。本文提出了T-FIX基准和新颖的度量方法，以评估LLM解释与专家判断的“专家对齐性”。


<details>
  <summary>Details</summary>
Motivation: 在知识密集型领域，用户（通常是领域专家）期望LLM不仅提供答案，还要提供有意义的、符合专家水平推理的解释。然而，目前的评估方法主要关注解释的合理性或内部一致性，未能捕捉到解释内容是否真正符合专家的直觉。

Method: 提出了一种名为T-FIX的基准，涵盖了七个知识密集型领域，并与领域专家合作开发了新的度量方法，以衡量LLM解释与专家判断的“专家对齐性”。

Result: 开发了一个包含七个知识密集型领域的T-FIX基准，并提出了能够衡量LLM解释与专家判断一致性的新颖度量方法。

Conclusion: 现有LLM解释的评估方法不足以满足知识密集型领域用户的需求，本文提出的T-FIX基准和相关度量方法为更准确地评估LLM解释与专家直觉的一致性提供了解决方案。

Abstract: As LLMs are deployed in knowledge-intensive settings (e.g., surgery,
astronomy, therapy), users expect not just answers, but also meaningful
explanations for those answers. In these settings, users are often domain
experts (e.g., doctors, astrophysicists, psychologists) who require
explanations that reflect expert-level reasoning. However, current evaluation
schemes primarily emphasize plausibility or internal faithfulness of the
explanation, which fail to capture whether the content of the explanation truly
aligns with expert intuition. We formalize expert alignment as a criterion for
evaluating explanations with T-FIX, a benchmark spanning seven
knowledge-intensive domains. In collaboration with domain experts, we develop
novel metrics to measure the alignment of LLM explanations with expert
judgment.

</details>


### [81] [Plan of Knowledge: Retrieval-Augmented Large Language Models for Temporal Knowledge Graph Question Answering](https://arxiv.org/abs/2511.04072)
*Xinying Qian,Ying Zhang,Yu Zhao,Baohang Zhou,Xuhui Sui,Xiaojie Yuan*

Main category: cs.CL

TL;DR: 该研究提出了一种名为PoK（Plan of Knowledge）的框架，用于解决时间知识图谱问答（TKGQA）问题。PoK结合了LLM的语义理解能力和外部知识检索能力，通过将复杂问题分解为子目标并从时间知识库中检索相关事实，来提高TKGQA的准确性和可解释性。


<details>
  <summary>Details</summary>
Motivation: 以往TKGQA方法未能充分理解时间约束的复杂语义信息，而LLM虽然语义理解能力强，但在时间推理方面存在幻觉和知识缺乏的问题。因此，需要一种新的方法来结合两者的优势。

Method: PoK框架包含两个主要部分：1. Plan of Knowledge模块：将复杂时间问题分解为一系列子目标，并利用预定义工具作为推理指导。2. Contrastive Temporal Retriever：构建时间知识库（TKS），并使用对比检索框架从TKG中检索语义和时间上对齐的事实。

Result: PoK框架通过结合结构化规划和时间知识检索，显著提高了LLM在TKGQA任务上的检索精度和推理准确性，在四个基准数据集上的性能提升最高达56.0%，超过了现有最先进的方法。

Conclusion: PoK框架通过解耦规划和检索，并结合对比检索机制，有效解决了LLM在TKGQA中的时间推理局限性，提高了模型的可解释性和事实一致性。

Abstract: Temporal Knowledge Graph Question Answering (TKGQA) aims to answer
time-sensitive questions by leveraging factual information from Temporal
Knowledge Graphs (TKGs). While previous studies have employed pre-trained TKG
embeddings or graph neural networks to inject temporal knowledge, they fail to
fully understand the complex semantic information of time constraints.
Recently, Large Language Models (LLMs) have shown remarkable progress,
benefiting from their strong semantic understanding and reasoning
generalization capabilities. However, their temporal reasoning ability remains
limited. LLMs frequently suffer from hallucination and a lack of knowledge. To
address these limitations, we propose the Plan of Knowledge framework with a
contrastive temporal retriever, which is named PoK. Specifically, the proposed
Plan of Knowledge module decomposes a complex temporal question into a sequence
of sub-objectives from the pre-defined tools, serving as intermediate guidance
for reasoning exploration. In parallel, we construct a Temporal Knowledge Store
(TKS) with a contrastive retrieval framework, enabling the model to selectively
retrieve semantically and temporally aligned facts from TKGs. By combining
structured planning with temporal knowledge retrieval, PoK effectively enhances
the interpretability and factual consistency of temporal reasoning. Extensive
experiments on four benchmark TKGQA datasets demonstrate that PoK significantly
improves the retrieval precision and reasoning accuracy of LLMs, surpassing the
performance of the state-of-the-art TKGQA methods by 56.0% at most.

</details>


### [82] [The truth is no diaper: Human and AI-generated associations to emotional words](https://arxiv.org/abs/2511.04077)
*Špela Vintar,Jan Jona Javoršek*

Main category: cs.CL

TL;DR: 人类和大型语言模型（LLM）在词语联想方面存在中等程度的重叠，但LLM的联想更易预测，创造性较差，并且会放大词语的情感色彩。


<details>
  <summary>Details</summary>
Motivation: 探索大型语言模型（LLM）在词语联想方面的行为，并与人类进行比较，特别是针对带有情感色彩的词语，以了解LLM是否以与人类相似的方式产生联想。

Method: 比较人类和大型语言模型对词语（特别是带有情感色彩的词语）的联想行为。

Result: LLM与人类的联想重叠度为中等；LLM的联想倾向于放大刺激物的潜在情感负荷；LLM的联想比人类的更可预测，创造性更低。

Conclusion: 尽管LLM在词语联想方面与人类存在一定的重叠，但它们在可预测性和创造性方面与人类存在显著差异，并且会放大词语的情感色彩。

Abstract: Human word associations are a well-known method of gaining insight into the
internal mental lexicon, but the responses spontaneously offered by human
participants to word cues are not always predictable as they may be influenced
by personal experience, emotions or individual cognitive styles. The ability to
form associative links between seemingly unrelated concepts can be the driving
mechanisms of creativity. We perform a comparison of the associative behaviour
of humans compared to large language models. More specifically, we explore
associations to emotionally loaded words and try to determine whether large
language models generate associations in a similar way to humans. We find that
the overlap between humans and LLMs is moderate, but also that the associations
of LLMs tend to amplify the underlying emotional load of the stimulus, and that
they tend to be more predictable and less creative than human ones.

</details>


### [83] [Improving the Performance of Radiology Report De-identification with Large-Scale Training and Benchmarking Against Cloud Vendor Methods](https://arxiv.org/abs/2511.04079)
*Eva Prakash,Maayane Attias,Pierre Chambon,Justin Xu,Steven Truong,Jean-Benoit Delbrouck,Tessa Cook,Curtis Langlotz*

Main category: cs.CL

TL;DR: 通过在大型放射学数据集上进行大规模训练，基于Transformer的去标识化模型在保护健康信息（PHI）检测方面超越了现有技术和商业系统。


<details>
  <summary>Details</summary>
Motivation: 为了提高放射学报告自动去标识化的能力，并通过广泛的训练数据集来扩展基于Transformer的模型，并将其性能与商业云供应商的PHI检测系统进行基准测试。

Method: 使用了一个最先进的、基于Transformer的PHI去标识化流程，在斯坦福大学的两个大型标注放射学语料库上进行了微调，并引入了一个额外的PHI类别（AGE）。在斯坦福大学和宾夕法尼亚大学的测试集上对模型进行了评估，并评估了合成PHI生成的稳定性和与商业系统的性能对比。

Result: 该模型在宾夕法尼亚大学和斯坦福大学的数据集上分别取得了0.973和0.996的F1分数，优于或保持了之前的最先进水平。合成PHI生成显示出一致的可检测性（F1分数：0.959），并且该模型在合成报告上优于所有供应商系统（F1分数：0.960 vs. 0.632-0.754）。

Conclusion: 在多样化的放射学数据集上训练的基于Transformer的去标识化模型，在PHI检测方面优于之前的学术和商业系统，并为安全的临床文本处理设定了新的基准。

Abstract: Objective: To enhance automated de-identification of radiology reports by
scaling transformer-based models through extensive training datasets and
benchmarking performance against commercial cloud vendor systems for protected
health information (PHI) detection. Materials and Methods: In this
retrospective study, we built upon a state-of-the-art, transformer-based, PHI
de-identification pipeline by fine-tuning on two large annotated radiology
corpora from Stanford University, encompassing chest X-ray, chest CT,
abdomen/pelvis CT, and brain MR reports and introducing an additional PHI
category (AGE) into the architecture. Model performance was evaluated on test
sets from Stanford and the University of Pennsylvania (Penn) for token-level
PHI detection. We further assessed (1) the stability of synthetic PHI
generation using a "hide-in-plain-sight" method and (2) performance against
commercial systems. Precision, recall, and F1 scores were computed across all
PHI categories. Results: Our model achieved overall F1 scores of 0.973 on the
Penn dataset and 0.996 on the Stanford dataset, outperforming or maintaining
the previous state-of-the-art model performance. Synthetic PHI evaluation
showed consistent detectability (overall F1: 0.959 [0.958-0.960]) across 50
independently de-identified Penn datasets. Our model outperformed all vendor
systems on synthetic Penn reports (overall F1: 0.960 vs. 0.632-0.754).
Discussion: Large-scale, multimodal training improved cross-institutional
generalization and robustness. Synthetic PHI generation preserved data utility
while ensuring privacy. Conclusion: A transformer-based de-identification model
trained on diverse radiology datasets outperforms prior academic and commercial
systems in PHI detection and establishes a new benchmark for secure clinical
text processing.

</details>


### [84] [Batch Prompting Suppresses Overthinking Reasoning Under Constraint: How Batch Prompting Suppresses Overthinking in Reasoning Models](https://arxiv.org/abs/2511.04108)
*Wenmo Qiu,Saurabh Srivastava*

Main category: cs.CL

TL;DR: 批量推理不仅能提高吞吐量，还能通过抑制过度思考、减少犹豫不决的语言和鼓励更明确的答案来正则化大型推理模型的行为，从而提高准确性并减少推理代币使用量。此外，批量推理还会产生新兴的集体效应，模型可以将在同一批次中较易示例中学习到的模式泛化到更难的示例上。


<details>
  <summary>Details</summary>
Motivation: 批量推理作为一种分摊大型语言模型（LLM）推理成本的策略已有研究。本文旨在揭示批量推理的另一个未被充分认识的优点：它可以正则化大型推理模型（LRM）在多步推理过程中的行为。

Method: 在 13 个不同的基准测试中进行了全面的研究，通过详细的行为分析来评估批量推理对准确性、推理代币使用量、过度思考、犹豫不决的语言以及新兴集体效应的影响。

Result: 批量推理提高了准确性，同时大幅减少了推理代币的使用量（通常为 3x-5x）。行为分析显示，批量推理能够抑制过度思考，减少犹豫不决的语言（例如，重复的自我纠正），并鼓励更明确的答案。此外，还观察到批量推理中出现新兴的集体效应，模型能将早期示例中的模式泛化到同一批次中更难的示例。

Conclusion: 批量推理不仅是一种吞吐量优化手段，而且是一种有效的推理时正则化器，可以使 LLM 推理更高效、更可靠。

Abstract: Recent work has explored batch prompting as a strategy to amortize inference
cost in large language models (LLMs). In this paper, we show that batching
offers an additional, underappreciated benefit: it regularizes model behavior
during multi-step reasoning for Large Reasoning Models (LRMs). We conduct a
comprehensive study across 13 diverse benchmarks and observe that batching
improves accuracy while substantially reducing reasoning token usage, often by
3x-5x. Through detailed behavioral analysis, we find that batching suppresses
overthinking, reduces hedging language (e.g., repetitive self-corrections), and
encourages more decisive answers. Surprisingly, we also observe emergent
collective effects in batched inference: models often generalize patterns from
earlier examples to solve harder ones in the same batch. These findings
position batching not just as a throughput optimization, but as a powerful
inference-time regularizer for more efficient and reliable LLM reasoning.

</details>


### [85] [RIDE: Difficulty Evolving Perturbation with Item Response Theory for Mathematical Reasoning](https://arxiv.org/abs/2511.04120)
*Xinyuan Li,Murong Xu,Wenbiao Tao,Hanlun Zhu,Yike Zhao,Jipeng Zhang,Yunshi Lan*

Main category: cs.CL

TL;DR: LLMs在数学推理方面表现出色，但可能受到训练数据泄露或表面模式匹配的影响。为了评估真正的数学推理能力，我们提出了RIDE框架，它利用项目反应理论（IRT）来衡量问题难度并生成更具挑战性的问题变体。通过模拟35个LLM作为学生，我们构建了一个难度排序器，并使用它来指导问题改写模型。RIDE生成的题目能够显著降低先进LLM的性能，平均下降21.73%，证明了其评估方法的有效性。


<details>
  <summary>Details</summary>
Motivation: 当前评估LLM数学推理能力的方法存在缺陷，容易受到训练数据泄露或表面模式匹配的干扰，并且基于规则的扰动方法会生成病态问题，阻碍了对问题难度和基准演变的系统评估。需要一种新的评估方法来衡量真实的数学推理能力。

Method: 我们提出了RIDE，一个新颖的基于项目反应理论（IRT）的对抗性问题改写框架。首先，我们使用35个LLM模拟学生回答问题，并根据他们的回答构建一个难度排序器。然后，该排序器为强化学习提供奖励信号，指导一个问题改写模型，根据现有问题的难度对其进行改写，生成更具挑战性且格式良好的问题变体。

Result: 将RIDE应用于竞赛级数学基准测试，生成的扰动版本题目能够有效降低先进LLM的性能，在26个模型上的平均性能下降了21.73%。这表明LLM在数学推理方面存在鲁棒性不足的问题，并验证了我们评估方法的有效性。

Conclusion: RIDE框架能够通过衡量问题难度并生成更具挑战性的问题变体，来更准确地评估LLM的真实数学推理能力。实验结果证明了该方法的有效性，并揭示了当前LLM在数学推理方面的局限性。

Abstract: Large language models (LLMs) achieve high performance on mathematical
reasoning, but these results can be inflated by training data leakage or
superficial pattern matching rather than genuine reasoning. To this end, an
adversarial perturbation-based evaluation is needed to measure true
mathematical reasoning ability. Current rule-based perturbation methods often
generate ill-posed questions and impede the systematic evaluation of question
difficulty and the evolution of benchmarks. To bridge this gap, we propose
RIDE, a novel adversarial question-rewriting framework that leverages Item
Response Theory (IRT) to rigorously measure question difficulty and to generate
intrinsically more challenging, well-posed variations of mathematical problems.
We employ 35 LLMs to simulate students and build a difficulty ranker from their
responses. This ranker provides a reward signal during reinforcement learning
and guides a question-rewriting model to reformulate existing questions across
difficulty levels. Applying RIDE to competition-level mathematical benchmarks
yields perturbed versions that degrade advanced LLM performance, with
experiments showing an average 21.73% drop across 26 models, thereby exposing
limited robustness in mathematical reasoning and confirming the validity of our
evaluation approach.

</details>


### [86] [CantoASR: Prosody-Aware ASR-LALM Collaboration for Low-Resource Cantonese](https://arxiv.org/abs/2511.04139)
*Dazhong Chen,Yi-Cheng Lin,Yuchen Huang,Ziwei Gong,Di Jiang,Zeying Xie,Yi R.,Fung*

Main category: cs.CL

TL;DR: CantoASR是一个结合了强制对齐、LoRA微调的Whisper和指令微调的Qwen-Audio的框架，用于纠正粤语语音识别错误，并在自发粤语数据上取得了显著的词错误率（CER）提升。


<details>
  <summary>Details</summary>
Motivation: 低资源粤语语音识别（ASR）面临数据稀疏、声调、连读变调和口音变异等挑战，现有模型（如Whisper）错误率高。

Method: 提出CantoASR框架，集成强制对齐提取声学特征，使用LoRA微调Whisper以提升声调辨别能力，并利用指令微调的Qwen-Audio进行韵律感知纠错。

Result: 在自发粤语数据上，CantoASR相比Whisper-Large-V3在词错误率（CER）上取得了显著的提升。

Conclusion: 将声学线索与大型音频-语言模型（LALM）推理相结合，为低资源地区的方言和声调ASR提供了一个可扩展的解决方案。

Abstract: Automatic speech recognition (ASR) is critical for language accessibility,
yet low-resource Cantonese remains challenging due to limited annotated data,
six lexical tones, tone sandhi, and accent variation. Existing ASR models, such
as Whisper, often suffer from high word error rates. Large audio-language
models (LALMs), in contrast, can leverage broader contextual reasoning but
still require explicit tonal and prosodic acoustic cues. We introduce CantoASR,
a collaborative ASR-LALM error correction framework that integrates forced
alignment for acoustic feature extraction, a LoRA-finetuned Whisper for
improved tone discrimination, and an instruction-tuned Qwen-Audio for
prosody-aware correction. Evaluations on spontaneous Cantonese data show
substantial CER gains over Whisper-Large-V3. These findings suggest that
integrating acoustic cues with LALM reasoning provides a scalable strategy for
low-resource tonal and dialectal ASR.

</details>


### [87] [Trustworthy LLM-Mediated Communication: Evaluating Information Fidelity in LLM as a Communicator (LAAC) Framework in Multiple Application Domains](https://arxiv.org/abs/2511.04184)
*Mohammed Musthafa Rafi,Adarsh Krishnamurthy,Aditya Balu*

Main category: cs.CL

TL;DR: LLM可作为智能通信中介（LAAC），但需解决信息保真度、一致性和可靠性问题。


<details>
  <summary>Details</summary>
Motivation: 解决AI生成内容泛滥导致沟通失真、信息冗余的问题，提出LAAC作为智能通信中介，促进真实知识交流。

Method: 评估LAAC在信息捕获保真度、可复现性、查询响应完整性三个维度上的可信度，通过多代理架构进行实验。

Result: 初步发现存在可信度差距，尤其在高风险沟通场景部署前需要解决。

Conclusion: LAAC作为沟通中介有潜力，但其可信度（信息捕获保真度、可复现性、查询响应完整性）的差距在高风险场景部署前必须解决。

Abstract: The proliferation of AI-generated content has created an absurd communication
theater where senders use LLMs to inflate simple ideas into verbose content,
recipients use LLMs to compress them back into summaries, and as a consequence
neither party engage with authentic content. LAAC (LLM as a Communicator)
proposes a paradigm shift - positioning LLMs as intelligent communication
intermediaries that capture the sender's intent through structured dialogue and
facilitate genuine knowledge exchange with recipients. Rather than perpetuating
cycles of AI-generated inflation and compression, LAAC enables authentic
communication across diverse contexts including academic papers, proposals,
professional emails, and cross-platform content generation. However, deploying
LLMs as trusted communication intermediaries raises critical questions about
information fidelity, consistency, and reliability. This position paper
systematically evaluates the trustworthiness requirements for LAAC's deployment
across multiple communication domains. We investigate three fundamental
dimensions: (1) Information Capture Fidelity - accuracy of intent extraction
during sender interviews across different communication types, (2)
Reproducibility - consistency of structured knowledge across multiple
interaction instances, and (3) Query Response Integrity - reliability of
recipient-facing responses without hallucination, source conflation, or
fabrication. Through controlled experiments spanning multiple LAAC use cases,
we assess these trust dimensions using LAAC's multi-agent architecture.
Preliminary findings reveal measurable trust gaps that must be addressed before
LAAC can be reliably deployed in high-stakes communication scenarios.

</details>


### [88] [LLM-as-a-Judge is Bad, Based on AI Attempting the Exam Qualifying for the Member of the Polish National Board of Appeal](https://arxiv.org/abs/2511.04205)
*Michał Karp,Anna Kubaszewska,Magdalena Król,Robert Król,Aleksander Smywiński-Pohl,Mateusz Szymański,Witold Wydmański*

Main category: cs.CL

TL;DR: 大型语言模型在波兰国家上诉法院资格考试中表现不佳，尤其是在需要实际法律判决的书面部分。


<details>
  <summary>Details</summary>
Motivation: 评估当前大型语言模型（LLMs）是否能够通过波兰国家上诉法院（Krajowa Izba Odwoławcza）的官方资格考试，并探讨将其用作考试候选人或‘LLM-as-a-judge’进行答案评估的可能性。

Method: 对考试结构进行描述，包括公共采购法知识测试和书面判决。构建了一个混合信息检索和提取流程来支持模型。测试了包括GPT-4.1、Claude 4 Sonnet和Bielik-11B-v2.6在内的多种LLMs，在闭卷和检索增强生成（RAG）等不同设置下进行测试。

Result: 模型在知识测试中取得了满意的分数，但在实际书面判决部分均未达到及格线。‘LLM-as-a-judge’的评估结果与官方委员会的判决存在显著差异。

Conclusion: 尽管技术进步迅速，但当前的大型语言模型在处理需要法律专业知识和逻辑论证的实际任务（如波兰公共采购案件的审判）方面仍然存在局限性，例如幻觉、法律条款引用不准确和论证能力不足。模型无法取代人类法官或独立审查员。

Abstract: This study provides an empirical assessment of whether current large language
models (LLMs) can pass the official qualifying examination for membership in
Poland's National Appeal Chamber (Krajowa Izba Odwo{\l}awcza). The authors
examine two related ideas: using LLM as actual exam candidates and applying the
'LLM-as-a-judge' approach, in which model-generated answers are automatically
evaluated by other models. The paper describes the structure of the exam, which
includes a multiple-choice knowledge test on public procurement law and a
written judgment, and presents the hybrid information recovery and extraction
pipeline built to support the models. Several LLMs (including GPT-4.1, Claude 4
Sonnet and Bielik-11B-v2.6) were tested in closed-book and various
Retrieval-Augmented Generation settings. The results show that although the
models achieved satisfactory scores in the knowledge test, none met the passing
threshold in the practical written part, and the evaluations of the
'LLM-as-a-judge' often diverged from the judgments of the official examining
committee. The authors highlight key limitations: susceptibility to
hallucinations, incorrect citation of legal provisions, weaknesses in logical
argumentation, and the need for close collaboration between legal experts and
technical teams. The findings indicate that, despite rapid technological
progress, current LLMs cannot yet replace human judges or independent examiners
in Polish public procurement adjudication.

</details>


### [89] [REMIND: Input Loss Landscapes Reveal Residual Memorization in Post-Unlearning LLMs](https://arxiv.org/abs/2511.04228)
*Liran Cohen,Yaniv Nemcovesky,Avi Mendelson*

Main category: cs.CL

TL;DR: 机器学习 in unlearning 旨在移除特定训练数据对模型的影响，但现有评估方法可能忽略语义相似样本的残余影响。REMIND 是一种新的评估方法，通过分析模型在输入微小变化下的损失，检测并分类未学习数据的残留影响，比现有方法更优越。


<details>
  <summary>Details</summary>
Motivation: 现有机器学习 in unlearning 评估方法可能无法检测到语义相似样本中的残余影响，从而导致隐私泄露和信息泄露。因此，需要一种能够检测这些细微影响的评估方法。

Method: REMIND 分析模型在输入微小变化下的损失，揭示单点评估无法注意到的模式。未学习数据会产生更平坦、不那么陡峭的损失曲面，而保留或无关数据则表现出更尖锐、更不稳定的模式。

Result: REMIND 仅需基于查询的访问，优于现有方法，并且在不同模型、数据集和释义输入上表现出鲁棒性。

Conclusion: REMIND 提供了一种更敏感、可解释的 in unlearning 有效性度量方法，为评估 in unlearning 在语言模型中的应用提供了一个可靠的框架。它为记忆和 in unlearning 提供了新的视角。

Abstract: Machine unlearning aims to remove the influence of specific training data
from a model without requiring full retraining. This capability is crucial for
ensuring privacy, safety, and regulatory compliance. Therefore, verifying
whether a model has truly forgotten target data is essential for maintaining
reliability and trustworthiness. However, existing evaluation methods often
assess forgetting at the level of individual inputs. This approach may overlook
residual influence present in semantically similar examples. Such influence can
compromise privacy and lead to indirect information leakage. We propose REMIND
(Residual Memorization In Neighborhood Dynamics), a novel evaluation method
aiming to detect the subtle remaining influence of unlearned data and classify
whether the data has been effectively forgotten. REMIND analyzes the model's
loss over small input variations and reveals patterns unnoticed by single-point
evaluations. We show that unlearned data yield flatter, less steep loss
landscapes, while retained or unrelated data exhibit sharper, more volatile
patterns. REMIND requires only query-based access, outperforms existing methods
under similar constraints, and demonstrates robustness across different models,
datasets, and paraphrased inputs, making it practical for real-world
deployment. By providing a more sensitive and interpretable measure of
unlearning effectiveness, REMIND provides a reliable framework to assess
unlearning in language models. As a result, REMIND offers a novel perspective
on memorization and unlearning.

</details>


### [90] [Reusing Pre-Training Data at Test Time is a Compute Multiplier](https://arxiv.org/abs/2511.04234)
*Alex Fang,Thomas Voice,Ruoming Pang,Ludwig Schmidt,Tom Gunter*

Main category: cs.CL

TL;DR: 大型语言模型在预训练过程中未能充分利用数据集中的信息，通过检索增强生成和测试时计算可以挽救未被利用的价值。


<details>
  <summary>Details</summary>
Motivation: 了解预训练模型从数据中提取信息和知识的效率低下问题。

Method: 使用检索增强生成（RAG）和测试时计算来量化预训练过程中数据集价值的损失，并研究其随模型规模的变化。

Result: 在MMLU、Math-500和SimpleQA基准测试中，通过预训练和检索相结合的方法，在去除污染数据后，准确率显著提高。对于MMLU，检索的计算效益约为单独预训练的5倍。通过在测试时解析检索到的上下文，LLaMA 3.1 8B模型的MMLU准确率提升了10个百分点。

Conclusion: 当前的大型语言模型预训练方法未能充分利用现有预训练数据集中的信息，为进一步改进留下了很大的空间。

Abstract: Large language models learn from their vast pre-training corpora, gaining the
ability to solve an ever increasing variety of tasks; yet although researchers
work to improve these datasets, there is little effort to understand how
efficient the pre-training apparatus is at extracting ideas and knowledge from
the data. In this work, we use retrieval augmented generation along with
test-time compute as a way to quantify how much dataset value was left behind
by the process of pre-training, and how this changes across scale. We
demonstrate that pre-training then retrieving from standard and largely
open-sourced datasets results in significant accuracy gains in MMLU, Math-500,
and SimpleQA, which persist through decontamination. For MMLU we observe that
retrieval acts as a ~5x compute multiplier versus pre-training alone. We show
that these results can be further improved by leveraging additional compute at
test time to parse the retrieved context, demonstrating a 10 percentage point
improvement on MMLU for the public LLaMA 3.1 8B model. Overall, our results
suggest that today's pre-training methods do not make full use of the
information in existing pre-training datasets, leaving significant room for
progress.

</details>


### [91] [Efficient Topic Extraction via Graph-Based Labeling: A Lightweight Alternative to Deep Models](https://arxiv.org/abs/2511.04248)
*Salma Mekaoui,Hiba Sofyan,Imane Amaaz,Imane Benchrif,Arsalane Zarghili,Ilham Chaker,Nikola S. Nikolov*

Main category: cs.CL

TL;DR: 本文提出了一种计算资源需求更少、可解释性更强的主题标注新方法。


<details>
  <summary>Details</summary>
Motivation: 现有主题提取方法计算成本高，主题可解释性差，而本文旨在通过概率统计方法，如主题模型，以较低计算成本有效解决此挑战，并为主题模型生成的词语分布赋予有意义的标签。

Method: 提出了一种基于图的方法，该方法通过挖掘词语间的关联性来丰富主题词，并在此基础上推导出能够准确捕捉主题含义的标签，从而实现主题标注。

Result: 在两个不同数据集上的对比研究表明，本文方法在BERTScore和余弦相似度方面优于传统基准方法，并能与ChatGPT-3.5媲美，同时计算效率更高。

Conclusion: 提出的基于图的主题标注方法在保持计算效率的同时，提高了主题的可解释性，并取得了与先进模型相媲美的结果。未来研究可进一步探索提高可解释性和自动化水平的方向。

Abstract: Extracting topics from text has become an essential task, especially with the
rapid growth of unstructured textual data. Most existing works rely on highly
computational methods to address this challenge. In this paper, we argue that
probabilistic and statistical approaches, such as topic modeling (TM), can
offer effective alternatives that require fewer computational resources. TM is
a statistical method that automatically discovers topics in large collections
of unlabeled text; however, it produces topics as distributions of
representative words, which often lack clear interpretability. Our objective is
to perform topic labeling by assigning meaningful labels to these sets of
words. To achieve this without relying on computationally expensive models, we
propose a graph-based approach that not only enriches topic words with
semantically related terms but also explores the relationships among them. By
analyzing these connections within the graph, we derive suitable labels that
accurately capture each topic's meaning. We present a comparative study between
our proposed method and several benchmarks, including ChatGPT-3.5, across two
different datasets. Our method achieved consistently better results than
traditional benchmarks in terms of BERTScore and cosine similarity and produced
results comparable to ChatGPT-3.5, while remaining computationally efficient.
Finally, we discuss future directions for topic labeling and highlight
potential research avenues for enhancing interpretability and automation.

</details>


### [92] [SSPO: Subsentence-level Policy Optimization](https://arxiv.org/abs/2511.04256)
*Kun Yang,Zikang chen,Yanmeng Wang,Zhigen Li*

Main category: cs.CL

TL;DR: SSPO是一种新的强化学习方法，通过句子级重要性比率解决了GRPO和GSPO的不足，提高了LLM的推理能力，并在多个数据集上取得了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: GRPO和GSPO在提高LLM推理能力方面存在策略更新不稳定和采样数据利用率低的问题。GRPO的token级重要性比率容易受异常值影响导致训练崩溃，而GSPO的response级重要性比率容易因极端值导致整个响应被错误丢弃，降低了数据利用率。

Method: 提出SSPO方法，采用句子级重要性比率，平衡了GRPO和GSPO的优缺点。SSPO避免了训练崩溃和高方差问题，并防止了由于剪切机制导致整个响应被丢弃。此外，将句子熵应用于PPO-CLIP，以稳定地调整剪切边界，鼓励高熵token进行探索，并缩小低熵token的剪切范围。

Result: SSPO在五个数据集上的平均得分为46.57，优于GRPO (43.01) 和 GSPO (44.42)，并在三个数据集上取得了最先进的性能。

Conclusion: SSPO通过借鉴GSPO的优点并规避其缺点，有效地利用了生成的数据，显著提高了LLM的推理能力。

Abstract: As a significant part of post-training of the Large Language Models (LLMs),
Reinforcement Learning from Verifiable Reward (RLVR) has greatly improved LLMs'
reasoning skills. However, some RLVR algorithms, such as GRPO (Group Relative
Policy Optimization) and GSPO (Group Sequence Policy Optimization), are
observed to suffer from unstable policy updates and low usage of sampling data,
respectively. The importance ratio of GRPO is calculated at the token level,
which focuses more on optimizing a single token. This will be easily affected
by outliers, leading to model training collapse. GSPO proposed the calculation
of the response level importance ratio, which solves the problem of high
variance and training noise accumulation in the calculation of the GRPO
importance ratio. However, since all the response tokens share a common
importance ratio, extreme values can easily raise or lower the overall mean,
leading to the entire response being mistakenly discarded, resulting in a
decrease in the utilization of sampled data. This paper introduces SSPO, which
applies sentence-level importance ratio, taking the balance between GRPO and
GSPO. SSPO not only avoids training collapse and high variance, but also
prevents the whole response tokens from being abandoned by the clipping
mechanism. Furthermore, we apply sentence entropy to PPO-CLIP to steadily
adjust the clipping bounds, encouraging high-entropy tokens to explore and
narrow the clipping range of low-entropy tokens. In particular, SSPO achieves
an average score of 46.57 across five datasets, surpassing GRPO (43.01) and
GSPO (44.42), and wins state-of-the-art performance on three datasets. These
results highlight SSPO's effectiveness in leveraging generated data by taking
the essence of GSPO but rejecting its shortcomings.

</details>


### [93] [Dynamic Jointly Batch Selection for Data Efficient Machine Translation Fine-Tuning](https://arxiv.org/abs/2511.04406)
*Mohammad Amin Ghanizadeh,Mohammad Javad Dousti*

Main category: cs.CL

TL;DR: 该研究提出了一种用于微调机器翻译模型的数据选择方法，通过结合学习模型和预训练参考模型来提高训练效果。该方法定义了可学性得分和批次选择策略，以确保只选择最有用的数据点并优化训练过程。


<details>
  <summary>Details</summary>
Motivation: 数据质量和有效选择对于提高机器翻译模型性能至关重要，是实现鲁棒可靠翻译系统的基石。

Method: 利用学习模型和预训练参考模型的协同作用，定义可学性得分来评估数据点效用，并采用考虑数据点之间相互依赖性的批次选择策略。

Result: 在英译波斯及其他语言对的mBART模型在CCMatrix数据集上的微调实验表明，与独立同分布基线相比，该方法可将数据效率提高五倍。使用缓存嵌入时，计算效率可提高24倍，并提高了泛化能力，翻译性能优于随机选择方法。

Conclusion: 所提出的数据选择方法能显著提高机器翻译模型的性能和效率。

Abstract: Data quality and its effective selection are fundamental to improving the
performance of machine translation models, serving as cornerstones for
achieving robust and reliable translation systems. This paper presents a data
selection methodology specifically designed for fine-tuning machine translation
systems, which leverages the synergy between a learner model and a pre-trained
reference model to enhance overall training effectiveness. By defining a
learnability score, our approach systematically evaluates the utility of data
points for training, ensuring that only the most relevant and impactful
examples contribute to the fine-tuning process. Furthermore, our method employs
a batch selection strategy which considers interdependencies among data points,
optimizing the efficiency of the training process while maintaining a focus on
data relevance. Experiments on English to Persian and several other language
pairs using an mBART model fine-tuned on the CCMatrix dataset demonstrate that
our method can achieve up to a fivefold improvement in data efficiency compared
to an iid baseline. Experimental results indicate that our approach improves
computational efficiency by 24 when utilizing cached embeddings, as it requires
fewer training data points. Additionally, it enhances generalization, resulting
in superior translation performance compared to random selection method.

</details>


### [94] [If I Could Turn Back Time: Temporal Reframing as a Historical Reasoning Task for LLMs](https://arxiv.org/abs/2511.04432)
*Lars Bungum,Charles Yijia Huang,Abeer Kashar*

Main category: cs.CL

TL;DR: LLMs在1940年的挪威书籍背景下进行时间推理，英语提示优于挪威语，更大的模型效果更好。


<details>
  <summary>Details</summary>
Motivation: 评估大型语言模型（LLM）在特定历史时期（1940年）进行时间推理的能力，并探讨语言和模型规模对推理精度的影响。

Method: 使用一本1940年的挪威书籍，其中包含一些常识问答题。分别用英语和挪威语向LLMs提出这些问题，要求它们假设自己处于1940年并回答问题。使用LLM作为裁判来评估答案，并由母语者进行抽样核查。

Result: 虽然LLMs能够回答问题，但英语提示在回答准确性上始终优于挪威语提示，这一结果出乎意料。模型规模越大，回答的准确性越高。测试了DeepSeek-R1、Gemma3、Qwen3、Llama3.1模型家族以及一个专门为挪威语设计的最大模型。

Conclusion: 大型语言模型在时间推理任务中表现出潜力，但存在挑战。语言（英语优于挪威语）和模型规模（越大越好）是影响模型表现的关键因素。需要进一步研究以理解为何英语提示效果更好，并探索更有效的跨语言和跨时间推理方法。

Abstract: In this study, we experiment with the ability of LLMs to do temporal
reasoning. Using a Norwegian book from 1940 containing trivia questions, we
prompt the LLMs to answer the questions as if it were 1940. We also pose the
questions in both English and Norwegian. Correct answers are often presented as
sentences, and grading is done by means of LLM-as-judge, with sampled checks by
a native speaker. Prompting in English consistently gave better results than in
Norwegian, an unexpected result. In contrast, using larger LLMs improved
results. We tested the DeepSeek-R1, Gemma3, Qwen3, and Llama3.1 model families,
and also the largest available LLM especially crafted for Norwegian.

</details>


### [95] [Probabilistic Textual Time Series Depression Detection](https://arxiv.org/abs/2511.04476)
*Fabian Schmidt,Seyedehmoniba Ravan,Vladimir Vlassov*

Main category: cs.CL

TL;DR: PTTSD是一个概率文本时间序列抑郁检测框架，可以从临床访谈的喃喃自语级别预测PHQ-8分数，同时对时间进行不确定性建模。


<details>
  <summary>Details</summary>
Motivation: 准确且可解释的抑郁严重程度预测对于临床决策支持至关重要，但现有模型通常缺乏不确定性估计和时间建模。

Method: PTTSD包括序列到序列和序列到一个的变体，结合了双向LSTM、自注意力、残差连接以及通过负对数似然训练的高斯或学生t输出头。

Result: PTTSD在E-DAIC和DAIC-WOZ上实现了最先进的性能（例如，E-DAIC上为MAE=3.85，DAIC上为3.55），并产生了良好校准的预测区间。

Conclusion: 注意力机制和概率建模的有效性得到了验证，并且与MentalBERT的比较证明了其通用性。三部分校准分析和定性案例研究进一步强调了不确定性感知预测的可解释性和临床相关性。

Abstract: Accurate and interpretable predictions of depression severity are essential
for clinical decision support, yet existing models often lack uncertainty
estimates and temporal modeling. We propose PTTSD, a Probabilistic Textual Time
Series Depression Detection framework that predicts PHQ-8 scores from
utterance-level clinical interviews while modeling uncertainty over time. PTTSD
includes sequence-to-sequence and sequence-to-one variants, both combining
bidirectional LSTMs, self-attention, and residual connections with Gaussian or
Student-t output heads trained via negative log-likelihood. Evaluated on E-DAIC
and DAIC-WOZ, PTTSD achieves state-of-the-art performance among text-only
systems (e.g., MAE = 3.85 on E-DAIC, 3.55 on DAIC) and produces well-calibrated
prediction intervals. Ablations confirm the value of attention and
probabilistic modeling, while comparisons with MentalBERT establish generality.
A three-part calibration analysis and qualitative case studies further
highlight the interpretability and clinical relevance of uncertainty-aware
forecasting.

</details>


### [96] [ThaiOCRBench: A Task-Diverse Benchmark for Vision-Language Understanding in Thai](https://arxiv.org/abs/2511.04479)
*Surapon Nonesung,Teetouch Jaknamon,Sirinya Chaiophat,Natapong Nitarach,Chanakan Wittayasakpan,Warit Sirichotedumrong,Adisai Na-Thalang,Kunat Pipatanakul*

Main category: cs.CL

TL;DR: ThaiOCRBench是第一个用于评估视觉语言模型（VLMs）在泰语富文本视觉理解任务上的综合基准。


<details>
  <summary>Details</summary>
Motivation: 现有基准主要关注高资源语言，导致泰语在需要文档结构理解的任务中代表性不足，因此提出ThaiOCRBench来解决这一差距。

Method: 构建了一个包含2,808个样本、涵盖13个任务类别的多样化、人工注释数据集，并评估了多种最先进的VLMs在零样本设置下的表现。

Result: 专有模型（如Gemini 2.5 Pro）的性能优于开源模型，其中细粒度文本识别和手写内容提取是开源模型性能下降最显著的方面。

Conclusion: ThaiOCRBench为评估低资源、脚本复杂的设置中的VLMs提供了一个标准化的框架，并为改进泰语文档理解提供了可操作的见解。

Abstract: We present ThaiOCRBench, the first comprehensive benchmark for evaluating
vision-language models (VLMs) on Thai text-rich visual understanding tasks.
Despite recent progress in multimodal modeling, existing benchmarks
predominantly focus on high-resource languages, leaving Thai underrepresented,
especially in tasks requiring document structure understanding. ThaiOCRBench
addresses this gap by offering a diverse, human-annotated dataset comprising
2,808 samples across 13 task categories. We evaluate a wide range of
state-of-the-art VLMs in a zero-shot setting, spanning both proprietary and
open-source systems. Results show a significant performance gap, with
proprietary models (e.g., Gemini 2.5 Pro) outperforming open-source
counterparts. Notably, fine-grained text recognition and handwritten content
extraction exhibit the steepest performance drops among open-source models.
Through detailed error analysis, we identify key challenges such as language
bias, structural mismatch, and hallucinated content. ThaiOCRBench provides a
standardized framework for assessing VLMs in low-resource, script-complex
settings, and provides actionable insights for improving Thai-language document
understanding.

</details>


### [97] [RUST-BENCH: Benchmarking LLM Reasoning on Unstructured Text within Structured Tables](https://arxiv.org/abs/2511.04491)
*Nikhil Abhyankar,Purvi Chaurasia,Sanchit Kabra,Ananya Srivastava,Vivek Gupta,Chandan K. Reddy*

Main category: cs.CL

TL;DR: RUST-BENCH是一个包含7966个问题和2031个真实世界表格的新基准，用于评估大型语言模型（LLM）在处理长而复杂的表格数据时的推理能力。


<details>
  <summary>Details</summary>
Motivation: 现有表格推理基准无法充分反映真实世界数据的复杂性，导致对大型语言模型（LLM）推理能力的评估不完整。真实表格数据通常包含长、异构、领域特定以及混合结构化字段和自由文本，需要跨越数千个令牌进行多跳推理。

Method: 创建了一个名为RUST-BENCH的新基准，包含来自RB-Science（NSF资助记录）和RB-Sports（NBA统计）两个领域的2031个真实世界表格和7966个问题。该基准联合评估LLM在规模、异构性、领域特异性和推理复杂性方面的能力。

Result: 在RUST-BENCH基准上的实验表明，LLM在处理异构模式和复杂的多跳推理方面存在困难，暴露了当前模型架构和提示策略的持续不足。

Conclusion: RUST-BENCH为推动表格推理研究建立了一个具有挑战性的新测试平台。

Abstract: Existing tabular reasoning benchmarks mostly test models on small, uniform
tables, underrepresenting the complexity of real-world data and giving an
incomplete view of Large Language Models' (LLMs) reasoning abilities. Real
tables are long, heterogeneous, and domain-specific, mixing structured fields
with free text and requiring multi-hop reasoning across thousands of tokens. To
address this gap, we introduce RUST-BENCH, a benchmark of 7966 questions from
2031 real-world tables spanning two domains: i) RB-Science (NSF grant records)
and ii) RB-Sports (NBA statistics). Unlike prior work, RUST-BENCH evaluates
LLMs jointly across scale, heterogeneity, domain specificity, and reasoning
complexity. Experiments with open-source and proprietary models show that LLMs
struggle with heterogeneous schemas and complex multi-hop inference, revealing
persistent weaknesses in current architectures and prompting strategies.
RUST-BENCH establishes a challenging new testbed for advancing tabular
reasoning research.

</details>


### [98] [OUNLP at TSAR 2025 Shared Task: Multi-Round Text Simplifier via Code Generation](https://arxiv.org/abs/2511.04495)
*Cuong Huynh,Jie Cao*

Main category: cs.CL

TL;DR: 本研究提出了两种基于多轮简化和GPT-4o的方法（MRS-Rule和MRS-Joint），用于可读性控制的文本简化，并在TSAR-2025任务中取得第七名。


<details>
  <summary>Details</summary>
Motivation: 发现文本简化性能与源语言和目标语言的CEFR水平差距高度相关，受此启发提出多轮简化方法。

Method: 基于LLM-prompting生成，提出两种多轮简化方法：规则简化（MRS-Rule）和联合规则-LLM简化（MRS-Joint），均通过GPT-4o实现。

Result: 提出的MRS-Rule和MRS-Joint系统在TSAR-2025任务中排名第7，并发现以LLM简化文本作为起点可以进一步提高多轮简化性能。

Conclusion: 多轮简化方法，特别是MRS-Joint，通过考虑CEFR水平差距并利用LLM能力，在文本简化任务中展现出潜力。

Abstract: This paper describes the OUNLP system submitted to the TSAR-2025 Shared Task
(Alva-Manchego et al., 2025), designed for readability-controlled text
simplification using LLM-prompting-based generation. Based on the analysis of
prompt-based text simplification methods, we discovered an interesting finding
that text simplification performance is highly related to the gap between the
source CEFR (Arase et al., 2022) level and the target CEFR level. Inspired by
this finding, we propose two multi-round simplification methods and generate
them via GPT-4o: rule-based simplification (MRS-Rule) and jointly rule-based
LLM simplification (MRS-Joint). Our submitted systems ranked 7 out of 20 teams.
Later improvements with MRS-Joint show that taking the LLM simplified
candidates as the starting point could further boost the multi-round
simplification performance.

</details>


### [99] [Decoding Emergent Big Five Traits in Large Language Models: Temperature-Dependent Expression and Architectural Clustering](https://arxiv.org/abs/2511.04499)
*Christos-Nikolaos Zacharopoulos,Revekka Kyriakoglou*

Main category: cs.CL

TL;DR: LLMs在人机交互应用中越来越重要，研究其类人格行为有助于负责任的开发和部署。本研究使用BFI-2框架评估了六种LLMs在不同采样温度下的特质表达，发现四种人格维度存在显著差异，其中神经质和外向性受温度影响。聚类分析揭示了不同的模型集群，表明模型架构可能影响其稳定的特质模式。这些发现为了解LLM中的类人格模式提供了新见解，并为模型调优、选择和AI伦理治理提供了新视角。


<details>
  <summary>Details</summary>
Motivation: 理解大型语言模型（LLMs）的类人格行为对于其在以人为中心的应用中的负责任开发和部署至关重要。

Method: 采用大五人格量表2（BFI-2）框架，系统评估了六种LLMs在不同采样温度下的特质表达。通过分层聚类分析模型。

Result: 在五个人格维度中的四个维度上发现了显著差异，其中神经质和外向性特别容易受到温度调整的影响。聚类分析揭示了不同的模型集群，表明模型架构可能影响某些模型稳定的特质表现。

Conclusion: LLMs表现出类人格模式，这些模式会因模型架构和采样温度等因素而异。这项研究为LLMs的调优、选择以及AI系统的伦理治理提供了新的视角。

Abstract: As Large Language Models (LLMs) become integral to human-centered
applications, understanding their personality-like behaviors is increasingly
important for responsible development and deployment. This paper systematically
evaluates six LLMs, applying the Big Five Inventory-2 (BFI-2) framework, to
assess trait expressions under varying sampling temperatures. We find
significant differences across four of the five personality dimensions, with
Neuroticism and Extraversion susceptible to temperature adjustments. Further,
hierarchical clustering reveals distinct model clusters, suggesting that
architectural features may predispose certain models toward stable trait
profiles. Taken together, these results offer new insights into the emergence
of personality-like patterns in LLMs and provide a new perspective on model
tuning, selection, and the ethical governance of AI systems. We share the data
and code for this analysis here:
https://osf.io/bsvzc/?view_only=6672219bede24b4e875097426dc3fac1

</details>


### [100] [RAGalyst: Automated Human-Aligned Agentic Evaluation for Domain-Specific RAG](https://arxiv.org/abs/2511.04502)
*Joshua Gao,Quoc Huy Pham,Subin Varghese,Silwal Saurav,Vedhus Hoskere*

Main category: cs.CL

TL;DR: RAGalyst是一个自动化、与人类对齐的代理框架，用于评估特定领域的RAG系统，通过生成合成数据集和优化LLM-as-a-Judge指标来解决现有评估方法的不足。


<details>
  <summary>Details</summary>
Motivation: 现有的RAG评估框架在专业、安全关键领域存在不足，通用指标无法捕捉领域特异性，LLM-as-a-Judge方法缺乏人类判断的验证。

Method: RAGalyst包含一个代理管道，可以从源文档生成高质量的合成问答数据集，并包含一个代理过滤步骤来确保数据保真度。该框架通过提示优化来改进两个关键的LLM-as-a-Judge指标——答案正确性和可回答性——以实现与人类标注的强相关性。

Result: 在三个不同领域（军事行动、网络安全和桥梁工程）评估RAG组件后发现，性能高度依赖于上下文。没有单一的嵌入模型、LLM或超参数配置被证明是普遍最优的。此外，还分析了RAG中答案正确性低的最常见原因。

Conclusion: RAGalyst的发现强调了系统性评估框架的必要性，使从业者能够发现领域特定的权衡并做出明智的设计选择，以构建可靠有效的RAG系统。

Abstract: Retrieval-Augmented Generation (RAG) is a critical technique for grounding
Large Language Models (LLMs) in factual evidence, yet evaluating RAG systems in
specialized, safety-critical domains remains a significant challenge. Existing
evaluation frameworks often rely on heuristic-based metrics that fail to
capture domain-specific nuances and other works utilize LLM-as-a-Judge
approaches that lack validated alignment with human judgment. This paper
introduces RAGalyst, an automated, human-aligned agentic framework designed for
the rigorous evaluation of domain-specific RAG systems. RAGalyst features an
agentic pipeline that generates high-quality, synthetic question-answering (QA)
datasets from source documents, incorporating an agentic filtering step to
ensure data fidelity. The framework refines two key LLM-as-a-Judge
metrics-Answer Correctness and Answerability-using prompt optimization to
achieve a strong correlation with human annotations. Applying this framework to
evaluate various RAG components across three distinct domains (military
operations, cybersecurity, and bridge engineering), we find that performance is
highly context-dependent. No single embedding model, LLM, or hyperparameter
configuration proves universally optimal. Additionally, we provide an analysis
on the most common low Answer Correctness reasons in RAG. These findings
highlight the necessity of a systematic evaluation framework like RAGalyst,
which empowers practitioners to uncover domain-specific trade-offs and make
informed design choices for building reliable and effective RAG systems.
RAGalyst is available on our Github.

</details>


### [101] [Modeling Clinical Uncertainty in Radiology Reports: from Explicit Uncertainty Markers to Implicit Reasoning Pathways](https://arxiv.org/abs/2511.04506)
*Paloma Rabaey,Jong Hak Moon,Jung-Oh Lee,Min Gwan Kim,Hangyul Yoon,Thomas Demeester,Edward Choi*

Main category: cs.CL

TL;DR: 该论文提出了一种包含显式和隐式不确定性的框架，用于分析放射学报告，并发布了一个名为Lunguage++的新数据集。


<details>
  <summary>Details</summary>
Motivation: 放射学报告在临床决策中至关重要，但其中包含的不确定性（显式和隐式）阻碍了其在机器可读格式下的自动化分析。

Method: 该框架通过专家验证的、基于LLM的参考排名来量化显式不确定性，并通过专家定义的诊断路径扩展模型来处理隐式不确定性。

Result: 发布了一个名为Lunguage++的新数据集，这是一个扩展的、考虑不确定性的细粒度结构化放射学报告基准。该数据集支持不确定性感知图像分类、诊断推理和不确定性临床影响的研究。

Conclusion: 所提出的框架和Lunguage++数据集能够更好地分析放射学报告，并为理解和利用诊断不确定性提供了新的途径。

Abstract: Radiology reports are invaluable for clinical decision-making and hold great
potential for automated analysis when structured into machine-readable formats.
These reports often contain uncertainty, which we categorize into two distinct
types: (i) Explicit uncertainty reflects doubt about the presence or absence of
findings, conveyed through hedging phrases. These vary in meaning depending on
the context, making rule-based systems insufficient to quantify the level of
uncertainty for specific findings; (ii) Implicit uncertainty arises when
radiologists omit parts of their reasoning, recording only key findings or
diagnoses. Here, it is often unclear whether omitted findings are truly absent
or simply unmentioned for brevity. We address these challenges with a two-part
framework. We quantify explicit uncertainty by creating an expert-validated,
LLM-based reference ranking of common hedging phrases, and mapping each finding
to a probability value based on this reference. In addition, we model implicit
uncertainty through an expansion framework that systematically adds
characteristic sub-findings derived from expert-defined diagnostic pathways for
14 common diagnoses. Using these methods, we release Lunguage++, an expanded,
uncertainty-aware version of the Lunguage benchmark of fine-grained structured
radiology reports. This enriched resource enables uncertainty-aware image
classification, faithful diagnostic reasoning, and new investigations into the
clinical impact of diagnostic uncertainty.

</details>


### [102] [Are language models aware of the road not taken? Token-level uncertainty and hidden state dynamics](https://arxiv.org/abs/2511.04527)
*Amir Zur,Atticus Geiger,Ekdeep Singh Lubana,Eric Bigelow*

Main category: cs.CL

TL;DR: 语言模型在生成文本时，其内部的隐藏状态可以反映其在不同推理路径上的不确定性，并且可以通过控制这些隐藏状态来引导模型的生成方向，表明模型内部确实隐含了多种可能的推理路径。


<details>
  <summary>Details</summary>
Motivation: 探讨语言模型在生成过程中是否会表示其可能采取的备选推理路径，并量化其不确定性。

Method: 使用隐藏激活来控制和预测链式思考推理过程中语言模型的不确定性。

Result: 发现模型在不同token处的不确定性与其易于被控制激活的程度之间存在明显相关性，并且隐藏激活可以预测模型未来输出的分布。

Conclusion: 隐藏激活在模型尚未确定最终答案时，最能有效地引导模型，表明模型内部隐含了多种可能路径的表征空间。

Abstract: When a language model generates text, the selection of individual tokens
might lead it down very different reasoning paths, making uncertainty difficult
to quantify. In this work, we consider whether reasoning language models
represent the alternate paths that they could take during generation. To test
this hypothesis, we use hidden activations to control and predict a language
model's uncertainty during chain-of-thought reasoning. In our experiments, we
find a clear correlation between how uncertain a model is at different tokens,
and how easily the model can be steered by controlling its activations. This
suggests that activation interventions are most effective when there are
alternate paths available to the model -- in other words, when it has not yet
committed to a particular final answer. We also find that hidden activations
can predict a model's future outcome distribution, demonstrating that models
implicitly represent the space of possible paths.

</details>


### [103] [IntelliProof: An Argumentation Network-based Conversational Helper for Organized Reflection](https://arxiv.org/abs/2511.04528)
*Kaveh Eskandari Miandoab,Katharine Kowalyshyn,Kabir Pamnani,Anesu Gavhera,Vasanth Sarathy,Matthias Scheutz*

Main category: cs.CL

TL;DR: IntelliProof是一个交互式系统，利用LLM分析论证性论文，将论文结构化为论证图，并为用户提供可视化和自然语言解释，以增强对论证质量的理解。


<details>
  <summary>Details</summary>
Motivation: 旨在开发一个交互式系统，利用大型语言模型（LLM）来分析论证性论文，强调用户体验，并弥合论证性论文的结构语义与用户对给定文本的理解之间的差距。

Method: 将论文构建为论证图，其中节点代表观点，节点属性包含支持证据，边表示支持或攻击关系。LLM对每个关系进行分类和评分，并提供可视化和解释。该系统还提供自然语言工具来帮助理解。

Result: 实现了能够对论证关系进行分类和评分，可视化论证图，提供分类依据，并量化论文连贯性的系统，从而能够快速探索论证质量，同时保留人工监督。

Conclusion: IntelliProof通过将论文结构化为论证图，并利用LLM提供分类、评分、可视化和自然语言解释，显著增强了对论证性论文的分析和理解能力，同时确保了用户体验和人工监督。

Abstract: We present IntelliProof, an interactive system for analyzing argumentative
essays through LLMs. IntelliProof structures an essay as an argumentation
graph, where claims are represented as nodes, supporting evidence is attached
as node properties, and edges encode supporting or attacking relations. Unlike
existing automated essay scoring systems, IntelliProof emphasizes the user
experience: each relation is initially classified and scored by an LLM, then
visualized for enhanced understanding. The system provides justifications for
classifications and produces quantitative measures for essay coherence. It
enables rapid exploration of argumentative quality while retaining human
oversight. In addition, IntelliProof provides a set of tools for a better
understanding of an argumentative essay and its corresponding graph in natural
language, bridging the gap between the structural semantics of argumentative
essays and the user's understanding of a given text. A live demo and the system
are available here to try: \textbf{https://intelliproof.vercel.app}

</details>


### [104] [From Model to Breach: Towards Actionable LLM-Generated Vulnerabilities Reporting](https://arxiv.org/abs/2511.04538)
*Cyril Vallez,Alexander Sternfeld,Andrei Kucharavy,Ljiljana Dolamic*

Main category: cs.CL

TL;DR: 最新的开源大模型在早期已报告的漏洞场景中仍然存在安全漏洞，这表明安全与功能之间的权衡阻碍了漏洞的有效修复。本文提出了一种新的严重性度量标准“提示暴露”（PE），用于评估由LLM生成的漏洞所带来的风险，并基于PE定义了“模型暴露”（ME）分数，以衡量模型生成漏洞的严重性和普遍性。


<details>
  <summary>Details</summary>
Motivation: 随着LLM编码助手在软件开发中的作用日益重要，它们产生的bug在网络安全领域的重要性也日益凸显。尽管已有LLM代码安全基准和改进代码安全性的方法被提出，但它们对广泛使用的大模型的影响尚不清楚。

Method: 提出了一种新的严重性度量标准“提示暴露”（PE），该度量标准考虑了漏洞的严重性、生成几率以及诱导漏洞生成的提示的表述。基于PE定义了“模型暴露”（ME）分数，以衡量模型生成漏洞的严重性和普遍性。

Result: 即使是最新一代的开源大模型，在实际使用场景中也容易受到早期报告的漏洞类型的攻击，表明安全-功能权衡导致漏洞未能得到有效修复。

Conclusion: 现有的LLM在处理早期已报告的漏洞场景时仍然存在风险，提出的PE和ME度量标准有助于更准确地评估和缓解LLM生成的漏洞的风险。

Abstract: As the role of Large Language Models (LLM)-based coding assistants in
software development becomes more critical, so does the role of the bugs they
generate in the overall cybersecurity landscape. While a number of LLM code
security benchmarks have been proposed alongside approaches to improve the
security of generated code, it remains unclear to what extent they have
impacted widely used coding LLMs. Here, we show that even the latest
open-weight models are vulnerable in the earliest reported vulnerability
scenarios in a realistic use setting, suggesting that the safety-functionality
trade-off has until now prevented effective patching of vulnerabilities. To
help address this issue, we introduce a new severity metric that reflects the
risk posed by an LLM-generated vulnerability, accounting for vulnerability
severity, generation chance, and the formulation of the prompt that induces
vulnerable code generation - Prompt Exposure (PE). To encourage the mitigation
of the most serious and prevalent vulnerabilities, we use PE to define the
Model Exposure (ME) score, which indicates the severity and prevalence of
vulnerabilities a model generates.

</details>


### [105] [BanglaMedQA and BanglaMMedBench: Evaluating Retrieval-Augmented Generation Strategies for Bangla Biomedical Question Answering](https://arxiv.org/abs/2511.04560)
*Sadia Sultana,Saiyma Sittul Muna,Mosammat Zannatul Samarukh,Ajwad Abrar,Tareque Mohmud Chowdhury*

Main category: cs.CL

TL;DR: 本文提出了BanglaMedQA和BanglaMMedBench，首个大规模孟加拉语医学选择题数据集，以评估医疗AI的推理和检索能力。通过集成OCR的孟加拉语医学教科书语料库和动态选择检索或推理策略的Agentic RAG流水线，在孟加拉语医学问答方面取得了显著进展。


<details>
  <summary>Details</summary>
Motivation: 低资源语言的生物医学问答系统开发具有挑战性，限制了可靠医疗知识的公平获取。孟加拉语医学问答尤其面临这一挑战。

Method: 开发了BanglaMedQA和BanglaMMedBench数据集。应用并比较了多种检索增强生成（RAG）策略，包括传统、零样本、Agentic、迭代反馈和聚合RAG。关键创新在于整合了通过OCR处理的孟加拉语医学教科书语料库，并实施了一个Agentic RAG流水线，该流水线能动态选择检索和推理策略。

Result: Agentic RAG策略在使用openai/gpt-oss-120b时达到了最高的89.54%准确率，优于其他配置，并展示了更高质量的推理。所有RAG方法在包含医学教科书的测试集上都优于纯生成模型。

Conclusion: 基于RAG的方法有潜力提高孟加拉语医学问答的可靠性和可访问性，为多语言医学人工智能的未来研究奠定了基础。

Abstract: Developing accurate biomedical Question Answering (QA) systems in
low-resource languages remains a major challenge, limiting equitable access to
reliable medical knowledge. This paper introduces BanglaMedQA and
BanglaMMedBench, the first large-scale Bangla biomedical Multiple Choice
Question (MCQ) datasets designed to evaluate reasoning and retrieval in medical
artificial intelligence (AI). The study applies and benchmarks several
Retrieval-Augmented Generation (RAG) strategies, including Traditional,
Zero-Shot Fallback, Agentic, Iterative Feedback, and Aggregate RAG, combining
textbook-based and web retrieval with generative reasoning to improve factual
accuracy. A key novelty lies in integrating a Bangla medical textbook corpus
through Optical Character Recognition (OCR) and implementing an Agentic RAG
pipeline that dynamically selects between retrieval and reasoning strategies.
Experimental results show that the Agentic RAG achieved the highest accuracy
89.54% with openai/gpt-oss-120b, outperforming other configurations and
demonstrating superior rationale quality. These findings highlight the
potential of RAG-based methods to enhance the reliability and accessibility of
Bangla medical QA, establishing a foundation for future research in
multilingual medical artificial intelligence.

</details>


### [106] [When retrieval outperforms generation: Dense evidence retrieval for scalable fake news detection](https://arxiv.org/abs/2511.04643)
*Alamgir Munir Qazi,John P. McCrae,Jamal Abdul Nasir*

Main category: cs.CL

TL;DR: DeReC框架使用通用文本嵌入结合密集检索和分类，在事实核查任务中提高了准确性并显著提高了效率，优于基于LLM的方法。


<details>
  <summary>Details</summary>
Motivation: 解决当前基于LLM的事实核查系统面临的计算瓶颈和幻觉风险，需要更高效、更可靠的系统。

Method: 提出DeReC（密集检索分类）框架，利用通用文本嵌入进行事实核查，结合密集检索和分类技术。

Result: DeReC框架在RAWFC数据集上F1分数达到65.58%，超过了L-Defense（61.20%）。在效率方面，与基于LLM的方法相比，RAWFC数据集运行时减少95%，LIAR-RAW数据集运行时减少92%。

Conclusion: 经过精心设计的基于检索的系统在专业任务上可以达到甚至超越LLM的性能，并且在实际部署中更具可行性。

Abstract: The proliferation of misinformation necessitates robust yet computationally
efficient fact verification systems. While current state-of-the-art approaches
leverage Large Language Models (LLMs) for generating explanatory rationales,
these methods face significant computational barriers and hallucination risks
in real-world deployments. We present DeReC (Dense Retrieval Classification), a
lightweight framework that demonstrates how general-purpose text embeddings can
effectively replace autoregressive LLM-based approaches in fact verification
tasks. By combining dense retrieval with specialized classification, our system
achieves better accuracy while being significantly more efficient. DeReC
outperforms explanation-generating LLMs in efficiency, reducing runtime by 95%
on RAWFC (23 minutes 36 seconds compared to 454 minutes 12 seconds) and by 92%
on LIAR-RAW (134 minutes 14 seconds compared to 1692 minutes 23 seconds),
showcasing its effectiveness across varying dataset sizes. On the RAWFC
dataset, DeReC achieves an F1 score of 65.58%, surpassing the state-of-the-art
method L-Defense (61.20%). Our results demonstrate that carefully engineered
retrieval-based systems can match or exceed LLM performance in specialized
tasks while being significantly more practical for real-world deployment.

</details>


### [107] [Logit-Entropy Adaptive Stopping Heuristic for Efficient Chain-of-Thought Reasoning](https://arxiv.org/abs/2511.04654)
*Mohammad Atif Quamar,Mohammad Areeb*

Main category: cs.CL

TL;DR: LEASH是一种训练免费的解码算法，通过监测logit熵和top-logit margin来选择性地停止Rationale生成，从而减少token使用量和延迟，而对准确率的影响很小。


<details>
  <summary>Details</summary>
Motivation: Chain-of-Thought (CoT) 提示虽然能增强大型语言模型的推理能力，但生成固定长度的Rationale会浪费计算资源，增加token消耗和延迟。因此，需要一种更有效的方法来生成Rationale。

Method: LEASH (Logit-Entropy Adaptive Stopping Heuristic) 算法通过监测两个内在信号：token级别熵的斜率和top-logit margin的改进程度，来动态地决定何时停止Rationale的生成。当这两个信号都趋于平稳时，意味着模型已达到稳定的推理状态，Rationale生成过程即告停止。

Result: 在四种指令调优模型和GSM8K、AQuA-RAT基准测试上，LEASH将平均token生成量减少了30-35%，延迟降低了27%，同时准确率仅下降了10个百分点（相较于CoT）。

Conclusion: LEASH是一种模型无关、无需额外训练或监督的解码算法，它通过自适应地停止Rationale生成，提供了一种比传统CoT解码更简单、更高效的替代方案。

Abstract: Chain-of-Thought (CoT) prompting is a key technique for enabling complex
reasoning in large language models. However, generating full, fixed-length
rationales is computationally wasteful, inflating both token usage and latency.
We introduce LEASH: Logit-Entropy Adaptive Stopping Heuristic, a training-free
decoding algorithm that adaptively halts rationale generation. LEASH monitors
two intrinsic signals: the slope of token-level entropy and the improvement in
the top-logit margin. It terminates the generation once both signals plateau,
indicating the model has reached a stable reasoning state. Across four
instruction-tuned models on the GSM8K and AQuA-RAT benchmarks, LEASH reduces
average token generation by 30--35% and latency by 27%, while incurring a 10
p.p. accuracy drop relative to CoT. LEASH is model-agnostic and requires no
additional training or supervision, offering a simple and efficient alternative
to CoT decoding.

</details>


<div id='cs.SI'></div>

# cs.SI [[Back]](#toc)

### [108] [Advancing Equitable AI: Evaluating Cultural Expressiveness in LLMs for Latin American Contexts](https://arxiv.org/abs/2511.04090)
*Brigitte A. Mora-Reyes,Jennifer A. Drewyor,Abel A. Reyes-Angulo*

Main category: cs.SI

TL;DR: AI系统偏见源于数据不平衡，本研究提出了一种包含拉丁美洲历史和社会政治背景的文化意识数据集，以解决该问题，并通过评估语言模型来提高AI的公平性。


<details>
  <summary>Details</summary>
Motivation: AI系统因训练数据中存在偏差，往往未能充分代表经济欠发达地区（如拉丁美洲）的文化背景，导致其反映了经济发达地区的观点，边缘化了欠发达地区的视角。

Method: 本研究提出了一种包含拉丁美洲历史和社会政治背景的文化意识数据集，并使用新颖的“文化表现力”指标、统计检验和语言分析来评估六个语言模型在测试文化背景意识问题上的表现。其中，Mistral-7B模型在经过本数据集微调后，其文化表现力提升了42.9%。

Result: 评估结果显示，部分语言模型能更好地捕捉拉丁美洲的视角，但其他模型则存在显著的情感失调（p < 0.001）。通过使用本研究提出的文化意识数据集对Mistral-7B模型进行微调，其文化表现力显著提升了42.9%。

Conclusion: 为了实现公平的AI发展，应优先考虑能够反映拉丁美洲历史、本土知识和多元语言的数据集，并采用以社区为中心的方法来放大边缘化的声音。

Abstract: Artificial intelligence (AI) systems often reflect biases from economically
advanced regions, marginalizing contexts in economically developing regions
like Latin America due to imbalanced datasets. This paper examines AI
representations of diverse Latin American contexts, revealing disparities
between data from economically advanced and developing regions. We highlight
how the dominance of English over Spanish, Portuguese, and indigenous languages
such as Quechua and Nahuatl perpetuates biases, framing Latin American
perspectives through a Western lens. To address this, we introduce a culturally
aware dataset rooted in Latin American history and socio-political contexts,
challenging Eurocentric models. We evaluate six language models on questions
testing cultural context awareness, using a novel Cultural Expressiveness
metric, statistical tests, and linguistic analyses. Our findings show that some
models better capture Latin American perspectives, while others exhibit
significant sentiment misalignment (p < 0.001). Fine-tuning Mistral-7B with our
dataset improves its cultural expressiveness by 42.9%, advancing equitable AI
development. We advocate for equitable AI by prioritizing datasets that reflect
Latin American history, indigenous knowledge, and diverse languages, while
emphasizing community-centered approaches to amplify marginalized voices.

</details>


### [109] [Launch-Day Diffusion: Tracking Hacker News Impact on GitHub Stars for AI Tools](https://arxiv.org/abs/2511.04453)
*Obada Kraishan*

Main category: cs.SI

TL;DR: HN 曝光显著提升 GitHub 仓库的星标增长，发布时间是关键因素。


<details>
  <summary>Details</summary>
Motivation: 量化 HN 曝光对开源 AI/LLM 工具的 GitHub 星标增长的即时影响。

Method: 构建了一个可复现的系统，使用公共 API 分析了 2024-2025 年 138 个仓库的 HN 曝光数据，并利用 Elastic Net 和 Gradient Boosting 模型进行分析。

Result: HN 曝光后 24 小时、48 小时和一周内，仓库平均分别增加 121、189 和 289 个星标。发布时间是预测病毒式增长的关键因素，而 "Show HN" 标签没有统计学优势。

Conclusion: HN 曝光对 GitHub 仓库的星标增长有显著的即时影响，发布时间是影响增长的关键，该系统可复现且易于扩展，为研究人员和开发者提供可操作的见解。

Abstract: Social news platforms have become key launch outlets for open-source
projects, especially Hacker News (HN), though quantifying their immediate
impact remains challenging. This paper presents a reproducible demonstration
system that tracks how HN exposure translates into GitHub star growth for AI
and LLM tools. Built entirely on public APIs, our pipeline analyzes 138
repository launches from 2024-2025 and reveals substantial launch effects:
repositories gain an average of 121 stars within 24 hours, 189 stars within 48
hours, and 289 stars within a week of HN exposure. Through machine learning
models (Elastic Net) and non-linear approaches (Gradient Boosting), we identify
key predictors of viral growth. Posting timing appears as key factor--launching
at optimal hours can mean hundreds of additional stars--while the "Show HN" tag
shows no statistical advantage after controlling for other factors. The
demonstration completes in under five minutes on standard hardware,
automatically collecting data, training models, and generating visualizations
through single-file scripts. This makes our findings immediately reproducible
and the framework easily be extended to other platforms, providing both
researchers and developers with actionable insights into launch dynamics.

</details>


<div id='cs.GT'></div>

# cs.GT [[Back]](#toc)

### [110] [On the Existence of Fair Allocations for Goods and Chores under Dissimilar Preferences](https://arxiv.org/abs/2511.03810)
*Egor Gagushin,Marios Mertzanidis,Alexandros Psomas*

Main category: cs.GT

TL;DR: 现有的研究表明，当每种物品的数量足够多时，可以实现无嫉妒分配。然而，之前的证明是非构造性的，并且只在物品种类或分配组为两种的情况下给出了明确的上界。


<details>
  <summary>Details</summary>
Motivation: 本文旨在解决 Gorantla 等人 [GMV23] 提出的一个主要开放性问题，即为任意数量的物品种类和分配组推导出无嫉妒分配存在的明确上界。

Method: 提出了一种更简单但强大的技术，该技术不仅为不可分割的物品提供了构造性保证，而且还可以自然地扩展到处理负效用物品（chores）和连续域，从而在蛋糕分割等相关公平分配场景中获得新结果。

Result: 本文为任意数量的物品种类和分配组推导出了无嫉妒分配存在的明确上界。

Conclusion: 本文提出了一种新的技术，为公平分配不可分割物品、负效用物品和连续域中的物品提供了构造性保证，并解决了公平分配领域的一个长期存在的难题。

Abstract: We study the fundamental problem of fairly allocating a multiset
$\mathcal{M}$ of $t$ types of indivisible items among $d$ groups of agents,
where all agents within a group have identical additive valuations. Gorantla et
al. [GMV23] showed that for every such instance, there exists a finite number
$\mu$ such that, if each item type appears at least $\mu$ times, an envy-free
allocation exists. Their proof is non-constructive and only provides explicit
upper bounds on $\mu$ for the cases of two groups ($d=2$) or two item types
($t=2$).
  In this work, we resolve one of the main open questions posed by Gorantla et
al. [GMV23] by deriving explicit upper bounds on $\mu$ that hold for arbitrary
numbers of groups and item types. We introduce a significantly simpler, yet
powerful technique that not only yields constructive guarantees for indivisible
goods but also extends naturally to chores and continuous domains, leading to
new results in related fair division settings such as cake cutting.

</details>


### [111] [The Complexity of Equilibrium Refinements in Potential Games](https://arxiv.org/abs/2511.03968)
*Ioannis Anagnostides,Maria-Florina Balcan,Kiriaki Fragkia,Tuomas Sandholm,Emanuel Tewolde,Brian Hu Zhang*

Main category: cs.GT

TL;DR: 本文研究了计算均衡精炼的复杂度问题，特别是在潜在对策博弈中，并取得了关键进展。


<details>
  <summary>Details</summary>
Motivation: 计算均衡精炼的复杂度一直是算法博弈论研究的核心问题，尤其是在潜在对策博弈这一重要博弈类型中，该问题此前尚未解决。

Method: 本文首先证明了在多种博弈表示（包括扩展型博弈和一般多面体博弈）下，计算纯策略完美均衡是$	extit{PLS}$-完全问题，这表明其在多项式时间内等价于计算纯纳什均衡。接着，对于规范型恰当均衡，研究表明在扩展型博弈中，可以有效计算受扰动（恰当）的最佳响应。此外，本文还将规范型恰当均衡在扩展型博弈中的复杂度确定为$	extit{FIXP}_a$-完全。作为对比，研究证明了在多面体潜在对策博弈中，计算规范型恰当均衡是$	extit{NP}$-难且$	extit{coNP}$-难的。随后，文章分析了更结构化的博弈类型，如对称网络拥塞博弈和对称拟阵拥塞博弈，证明了在这两类博弈中，可以在多项式时间内计算完美纯策略均衡，这优于现有的纯纳什均衡结果。同时，研究发现在某一类潜在对策博弈中，完美均衡和纳什均衡的最佳响应路径长度之间存在指数级分离。最后，在混合策略方面，文章证明了在三元规范型潜在对策博弈中，计算接近完美均衡的点需要指数级小的扰动。反之，在多项矩阵潜在对策博弈的特例中，研究表明均衡精炼可以通过受扰动的梯度下降动态来处理，其复杂度属于$	extit{CLS}$类。

Result: 本文证明了在不同博弈表示下计算纯策略完美均衡是$	extit{PLS}$-完全的；在扩展型博弈中，可以有效计算受扰动的恰当最佳响应，并将规范型恰当均衡的复杂度确定为$	extit{FIXP}_a$-完全；在多面体潜在对策博弈中，计算规范型恰当均衡是$	extit{NP}$-难且$	extit{coNP}$-难的；在对称网络拥塞和对称拟阵拥塞博弈中，可以在多项式时间内计算完美纯策略均衡；在某些潜在对策博弈中，完美均衡和纳什均衡的最佳响应路径长度存在指数级分离；在三元规范型潜在对策博弈中，计算接近完美均衡的点需要指数级小的扰动；在多项矩阵潜在对策博弈中，均衡精炼属于$	extit{CLS}$类。

Conclusion: 本文在计算均衡精炼的复杂度方面取得了多项重要突破，特别是在潜在对策博弈中，不仅解决了长期存在的开放性问题，而且在不同类型的博弈和策略（纯策略、混合策略）下，对计算的复杂性进行了系统性的分析和界定，并提出了有效的计算方法。

Abstract: The complexity of computing equilibrium refinements has been at the forefront
of algorithmic game theory research, but it has remained open in the seminal
class of potential games; we close this fundamental gap in this paper.
  We first establish that computing a pure-strategy perfect equilibrium is
$\mathsf{PLS}$-complete under different game representations -- including
extensive-form games and general polytope games, thereby being polynomial-time
equivalent to pure Nash equilibria. For normal-form proper equilibria, our main
result is that a perturbed (proper) best response can be computed efficiently
in extensive-form games. As a byproduct, we establish
$\mathsf{FIXP}_a$-completeness of normal-form proper equilibria in
extensive-form games, resolving a long-standing open problem. In stark
contrast, we show that computing a normal-form proper equilibrium in polytope
potential games is both $\mathsf{NP}$-hard and $\mathsf{coNP}$-hard.
  We next turn to more structured classes of games, namely symmetric network
congestion and symmetric matroid congestion games. For both classes, we show
that a perfect pure-strategy equilibrium can be computed in polynomial time,
strengthening the existing results for pure Nash equilibria. On the other hand,
we establish that, for a certain class of potential games, there is an
exponential separation in the length of the best-response path between perfect
and Nash equilibria.
  Finally, for mixed strategies, we prove that computing a point geometrically
near a perfect equilibrium requires a doubly exponentially small perturbation
even in $3$-player potential games in normal form. On the flip side, in the
special case of polymatrix potential games, we show that equilibrium
refinements are amenable to perturbed gradient descent dynamics, thereby
belonging to the complexity class $\mathsf{CLS}$.

</details>


### [112] [Fraud-Proof Revenue Division on Subscription Platforms](https://arxiv.org/abs/2511.04465)
*Abheek Ghosh,Tzeh Yuan Neoh,Nicholas Teh,Giannis Tyrovolas*

Main category: cs.GT

TL;DR: 平台通过固定费用提供内容访问，创作者分享收入。研究了收入分配机制以阻止欺诈，并提出了名为ScaledUserProp的新规则。


<details>
  <summary>Details</summary>
Motivation: 现有的欺诈检测方法依赖于机器学习，但面临持续的“军备竞赛”。本研究旨在探索具有内在防操纵机制的收入分配方法。

Method: 形式化了三种抗操纵公理，并检查了现有规则的满足情况。引入了新的规则ScaledUserProp，并进行了真实和合成数据的实验比较。

Result: 发现流媒体平台广泛使用的机制不仅无法阻止欺诈，还使得检测操纵在计算上变得不可行。ScaledUserProp满足所有三种抗操纵公理。

Conclusion: ScaledUserProp是一种比现有规则更公平的替代方案，并得到了实验数据的支持。

Abstract: We study a model of subscription-based platforms where users pay a fixed fee
for unlimited access to content, and creators receive a share of the revenue.
Existing approaches to detecting fraud predominantly rely on machine learning
methods, engaging in an ongoing arms race with bad actors. We explore revenue
division mechanisms that inherently disincentivize manipulation. We formalize
three types of manipulation-resistance axioms and examine which existing rules
satisfy these. We show that a mechanism widely used by streaming platforms, not
only fails to prevent fraud, but also makes detecting manipulation
computationally intractable. We also introduce a novel rule, ScaledUserProp,
that satisfies all three manipulation-resistance axioms. Finally, experiments
with both real-world and synthetic streaming data support ScaledUserProp as a
fairer alternative compared to existing rules.

</details>


### [113] [Fisher Meets Lindahl: A Unified Duality Framework for Market Equilibrium](https://arxiv.org/abs/2511.04572)
*Yixin Tao,Weiqiang Zheng*

Main category: cs.GT

TL;DR: 该论文提出了一个统一的对偶框架，将公共物品市场的 Lindahl 均衡与偶对 Fisher 市场的 Fisher 均衡联系起来。


<details>
  <summary>Details</summary>
Motivation: 虽然 Fisher 市场均衡得到了充分研究，但 Lindahl 均衡的理论基础仍不完善，本研究旨在解决这一差距。

Method: 提出一个统一的对偶框架，将 Lindahl 均衡与偶对 Fisher 市场的 Fisher 均衡进行关联，并利用此对偶性分析了福利性质和市场动态。

Result: 证明了在特定条件下 Lindahl 均衡可以最大化或近似最大化 Nash Social Welfare (NSW)。同时，基于偶对 Fisher 市场的动态，为 Lindahl 均衡提供了新的市场动态。此外，还研究了带有“极点”问题的公共物品市场和带有“杂物”的市场。

Conclusion: 通过统一的对偶框架，在 Lindahl 均衡的计算、福利性质、市场动态以及公共物品和杂物市场方面取得了新的进展和见解。

Abstract: The Fisher market equilibrium for private goods and the Lindahl equilibrium
for public goods are classic and fundamental solution concepts for market
equilibria. While Fisher market equilibria have been well-studied, the
theoretical foundations for Lindahl equilibria remain substantially
underdeveloped.
  In this work, we propose a unified duality framework for market equilibria.
We show that Lindahl equilibria of a public goods market correspond to Fisher
market equilibria in a dual Fisher market with dual utilities, and vice versa.
The dual utility is based on the indirect utility, and the correspondence
between the two equilibria works by exchanging the roles of allocations and
prices.
  Using the duality framework, we address the gaps concerning the computation
and dynamics for Lindahl equilibria and obtain new insights and developments
for Fisher market equilibria. First, we leverage this duality to analyze
welfare properties of Lindahl equilibria. For concave homogeneous utilities, we
prove that a Lindahl equilibrium maximizes Nash Social Welfare (NSW). For
concave non-homogeneous utilities, we show that a Lindahl equilibrium achieves
$(1/e)^{1/e}$ approximation to the optimal NSW, and the approximation ratio is
tight. Second, we apply the duality framework to market dynamics, including
proportional response dynamics (PRD) and t\^atonnement. We obtain new market
dynamics for the Lindahl equilibria from market dynamics in the dual Fisher
market. We also use duality to extend PRD to markets with total complements
utilities, the dual class of gross substitutes utilities. Finally, we apply the
duality framework to markets with chores. We propose a program for private
chores for general convex homogeneous disutilities that avoids the "poles"
issue, whose KKT points correspond to Fisher market equilibria. We also
initiate the study of the Lindahl equilibrium for public chores.

</details>


<div id='cs.MA'></div>

# cs.MA [[Back]](#toc)

### [114] [OptiMA: A Transaction-Based Framework with Throughput Optimization for Very Complex Multi-Agent Systems](https://arxiv.org/abs/2511.03761)
*Umut Çalıkyılmaz,Nitin Nayak,Jinghua Groppe,Sven Groppe*

Main category: cs.MA

TL;DR: 本研究提出了一个名为OptiMA的框架，用于构建和执行复杂的多智能体系统（VCMAS），以解决复杂性带来的故障敏感性和性能瓶颈问题。该框架通过引入基于事务的处理方式和事务调度机制，成功支持了拥有百余个智能体的大规模系统，并将性能提升了16%以上。此外，研究还对事务调度问题进行了理论分析，并提供了相关工具支持未来研究。


<details>
  <summary>Details</summary>
Motivation: 随着多智能体系统朝着更大型、更复杂的模型发展以应对复杂任务，可能出现故障敏感性和性能瓶颈两大挑战。本研究旨在解决这两个问题。

Method: 提出一个基于事务的框架（VCMAS）来处理故障问题，并结合事务调度来解决性能瓶颈。最终实现了OptiMA框架。

Result: OptiMA框架能够支持包含百余个智能体的大规模系统，并且通过事务调度将系统性能提升了16%以上。

Conclusion: 本研究提出的OptiMA框架通过基于事务的处理和事务调度，有效解决了复杂多智能体系统中存在的故障和性能问题，并为未来的相关研究提供了理论和实践支持。

Abstract: In recent years, the research of multi-agent systems has taken a direction to
explore larger and more complex models to fulfill sophisticated tasks. We point
out two possible pitfalls that might be caused by increasing complexity;
susceptibilities to faults, and performance bottlenecks. To prevent the former
threat, we propose a transaction-based framework to design very complex
multi-agent systems (VCMAS). To address the second threat, we offer to
integrate transaction scheduling into the proposed framework. We implemented
both of these ideas to develop the OptiMA framework and show that it is able to
facilitate the execution of VCMAS with more than a hundred agents. We also
demonstrate the effect of transaction scheduling on such a system by showing
improvements up to more than 16\%. Furthermore, we also performed a theoretical
analysis on the transaction scheduling problem and provided practical tools
that can be used for future research on it.

</details>


### [115] [ASAP: an Agentic Solution to Auto-optimize Performance of Large-Scale LLM Training](https://arxiv.org/abs/2511.03844)
*Yuran Ding,Xinwei Chen,Xiaofan Zhang,Zongwei Zhou*

Main category: cs.MA

TL;DR: ASAP是一个多智能体系统，通过整合LLM推理、性能分析工具和专家知识库，自动优化大规模LLM训练的性能，能显著减少训练时间并提高吞吐量。


<details>
  <summary>Details</summary>
Motivation: 现有LLM分布式训练优化方法依赖手动调优或黑盒搜索，效率低下且资源消耗大，无法跟上LLM领域快速发展的步伐。

Method: ASAP是一个包含协调者、分析器和建议者三个智能体多智能体系统。它整合了LLM推理能力、性能剖析工具（如roofline分析）以及包含最佳实践和成功案例的知识库，以自动诊断性能瓶颈并提供优化建议。

Result: ASAP生成的配置可将训练步进时间减少28%，吞吐量提高1.43倍。结合人工优化，吞吐量可进一步提升至2.58倍。

Conclusion: ASAP为大规模LLM训练提供了一种可扩展、可解释的AI辅助性能工程方法，有效解决了LLM分布式训练中的性能优化难题。

Abstract: Optimizing large-language model (LLM) training on distributed domain-specific
accelerator systems presents significant challenges due to its complex
optimization space. Existing optimization methods, however, rely on
time-consuming manual tuning or resource-intensive black-box searches, which
struggle to keep pace with the rapidly evolving LLM domain, leading to slow
development and underutilized resources. To address this, we introduce ASAP, an
Agentic Solution to Auto-optimize Performance of Large-Scale LLM Training. It
is a multi-agent system, featuring Coordinator, Analyzer, and Proposal agents,
which integrates LLM reasoning with insights from performance profiling tools,
roofline analysis, and a knowledge base of best practices and successful past
optimizations from human experts. Our proposed design can automate the
diagnosis of performance bottlenecks and recommend optimized sharding
configurations with reasoning, thus effectively improving the efficiency of
distributed LLM training. Experiments have shown that the ASAP-generated
sharding configurations can contribute up to 28% training step time reduction
and 1.43 times throughput improvement. When combined with additional
optimization from human experts, throughput can be further increased to 2.58
times. The proposed ASAP promises to provide a scalable and explainable
methodology for AI-assisted performance engineering in large-scale LLM
training.

</details>


### [116] [Multi-Agent Collaborative Framework For Math Problem Generation](https://arxiv.org/abs/2511.03958)
*Kia Karbasi,Kevin Hong,Mohammad Amin Samadi,Gregory Pottie*

Main category: cs.MA

TL;DR: 使用多智能体协作框架改进数学教育中的自动问题生成，以更好地控制问题难度和认知需求。


<details>
  <summary>Details</summary>
Motivation: 目前的自动问题生成（AQG）方法难以精确控制数学教育中问题的复杂性和认知需求。

Method: 提出一种协作式多智能体框架，通过迭代优化问题-答案对，并引入推理时计算，以平衡问题的复杂性和认知需求。

Result: 在五个元评估标准（相关性、重要性、清晰度、难度匹配、可回答性）上评估生成的问题，表明该框架能提高生成教育内容的质量，并能更精细地平衡认知挑战和清晰度。

Conclusion: 协作式多智能体工作流有潜力生成更可控、更具教学价值的内容，从而推动自动教育内容生成和自适应学习环境的发展。

Abstract: Automatic question generation (AQG) for mathematics education remains an
elusive goal for Intelligent Tutoring Systems and educators. While pre-trained
transformer-based language models have significantly advanced natural language
generation, they often struggle to precisely control problem complexity and
cognitive demands. In this paper, we introduce a collaborative multi-agent
framework as a novel method of incorporating inference-time computation into
AQG. This approach leverages multiple agents that iteratively refine generated
question-answer pairs to better balance complexity and cognitive demand. We
evaluate the generated questions on five meta-evaluation criteria: relevance,
importance, clarity, difficulty matching, answerability, to assess the system's
ability to control the required complexity and quality of the questions.
Preliminary evaluations show that this collaborative multi-agent framework
elevates the quality of generated educational content by fostering a more
nuanced balance between cognitive challenge and clarity. These promising
outcomes suggest that integrating collaborative multi-agent workflows can yield
more controlled, pedagogically valuable content that can help advance automated
educational content generation and adaptive learning environments.

</details>


<div id='cs.AR'></div>

# cs.AR [[Back]](#toc)

### [117] [From Minutes to Seconds: Redefining the Five-Minute Rule for AI-Era Memory Hierarchies](https://arxiv.org/abs/2511.03944)
*Tong Zhang,Vikram Sharma Mailthody,Fei Sun,Linsen Ma,Chris J. Newburn,Teresa Zhang,Yang Liu,Jiangpeng Li,Hao Zhong,Wen-Mei Hwu*

Main category: cs.AR

TL;DR: 新的五分钟规则适用于AI平台，将DRAM缓存阈值缩短至几秒钟，将NAND闪存视为活跃的数据层。


<details>
  <summary>Details</summary>
Motivation: 重新审视并整合了主机成本、DRAM带宽/容量以及基于物理的SSD性能和成本模型，以应对现代AI平台的需求，弥补了早期规则的不足。

Method: 提出一个包含主机成本、DRAM容量和带宽、SSD性能和成本的约束和工作负载感知框架。引入MQSim-Next，一个SSD模拟器，用于验证和敏感性分析。

Result: 对于现代AI平台，特别是GPU主机的DRAM到闪存缓存阈值从几分钟缩短到几秒钟。NAND闪存被视为活跃数据层，为硬件软件堆栈带来了新的研究空间。

Conclusion: 将经典的五分钟规则转变为一个可行的、考虑可行性的分析和配置框架，为AI时代内存层次结构的研究奠定了基础。

Abstract: In 1987, Jim Gray and Gianfranco Putzolu introduced the five-minute rule, a
simple, storage-memory-economics-based heuristic for deciding when data should
live in DRAM rather than on storage. Subsequent revisits to the rule largely
retained that economics-only view, leaving host costs, feasibility limits, and
workload behavior out of scope. This paper revisits the rule from first
principles, integrating host costs, DRAM bandwidth/capacity, and
physics-grounded models of SSD performance and cost, and then embedding these
elements in a constraint- and workload-aware framework that yields actionable
provisioning guidance. We show that, for modern AI platforms, especially
GPU-centric hosts paired with ultra-high-IOPS SSDs engineered for fine-grained
random access, the DRAM-to-flash caching threshold collapses from minutes to a
few seconds. This shift reframes NAND flash memory as an active data tier and
exposes a broad research space across the hardware-software stack. We further
introduce MQSim-Next, a calibrated SSD simulator that supports validation and
sensitivity analysis and facilitates future architectural and system research.
Finally, we present two concrete case studies that showcase the software system
design space opened by such memory hierarchy paradigm shift. Overall, we turn a
classical heuristic into an actionable, feasibility-aware analysis and
provisioning framework and set the stage for further research on AI-era memory
hierarchy.

</details>


### [118] [PICNIC: Silicon Photonic Interconnected Chiplets with Computational Network and In-memory Computing for LLM Inference Acceleration](https://arxiv.org/abs/2511.04036)
*Yue Jiet Chong,Yimin Wang,Zhen Wu,Xuanyao Fong*

Main category: cs.AR

TL;DR: 该论文提出了一种基于3D堆叠Chiplet的大型语言模型（LLM）推理加速器，其中包含非易失性内存计算处理单元（PE）和PE间计算网络（IPCN），并通过硅光子互连以有效解决通信瓶颈。


<details>
  <summary>Details</summary>
Motivation: 解决大型语言模型（LLM）推理中的通信瓶颈问题。

Method: 开发了一种3D堆叠Chiplet架构，包含非易失性内存计算处理单元（PE）和PE间计算网络（IPCN），并利用硅光子互连。同时，提出了一种LLM映射方案来优化硬件调度和工作负载映射。

Result: 与未采用Chiplet集群和功耗门控方案（CCPG）的Nvidia A100相比，实现了3.95倍的加速和30倍的效率提升。通过实施CCPG方案，可扩展性进一步提高，与Nvidia H100在相似吞吐量下实现了57倍的效率提升。

Conclusion: 所提出的3D堆叠Chiplet LLM推理加速器有效解决了通信瓶颈，并通过Chiplet集群和功耗门控方案实现了显著的性能和效率提升，尤其是在处理大型模型方面。

Abstract: This paper presents a 3D-stacked chiplets based large language model (LLM)
inference accelerator, consisting of non-volatile in-memory-computing
processing elements (PEs) and Inter-PE Computational Network (IPCN),
interconnected via silicon photonic to effectively address the communication
bottlenecks. A LLM mapping scheme was developed to optimize hardware scheduling
and workload mapping. Simulation results show it achieves $3.95\times$ speedup
and $30\times$ efficiency improvement over the Nvidia A100 before chiplet
clustering and power gating scheme (CCPG). Additionally, the system achieves
further scalability and efficiency improvement with the implementation of CCPG
to accommodate larger models, attaining $57\times$ efficiency improvement over
Nvidia H100 at similar throughput.

</details>


### [119] [Disaggregated Architectures and the Redesign of Data Center Ecosystems: Scheduling, Pooling, and Infrastructure Trade-offs](https://arxiv.org/abs/2511.04104)
*Chao Guo,Jiahe Xu,Moshe Zukerman*

Main category: cs.AR

TL;DR: 硬件分解有望重塑数据中心生态系统，但仍面临挑战。


<details>
  <summary>Details</summary>
Motivation: 文章旨在概述硬件分解的动机、进展、挑战和机遇，并探讨其对数据中心生态系统的广泛影响。

Method: 本文进行了文献回顾，并结合数值研究来阐释相关挑战。

Result: 硬件分解在产业界和学术界都取得了显著进展，但仍有待克服的挑战。其潜在影响涵盖应用设计、资源调度、硬件配置、散热和电力系统优化等多个方面。数值研究阐明了关键挑战。

Conclusion: 硬件分解有潜力彻底改变数据中心，但需要进一步研究和解决相关挑战。

Abstract: Hardware disaggregation seeks to transform Data Center (DC) resources from
traditional server fleets into unified resource pools. Despite existing
challenges that may hinder its full realization, significant progress has been
made in both industry and academia. In this article, we provide an overview of
the motivations and recent advancements in hardware disaggregation. We further
discuss the research challenges and opportunities associated with disaggregated
architectures, focusing on aspects that have received limited attention. We
argue that hardware disaggregation has the potential to reshape the entire DC
ecosystem, impacting application design, resource scheduling, hardware
configuration, cooling, and power system optimization. Additionally, we present
a numerical study to illustrate several key aspects of these challenges.

</details>


### [120] [AIM: Software and Hardware Co-design for Architecture-level IR-drop Mitigation in High-performance PIM](https://arxiv.org/abs/2511.04321)
*Yuanpeng Zhang,Xing Hu,Xi Chen,Zhihang Yuan,Cong Li,Jingchen Zhu,Zhao Wang,Chenguang Zhang,Xin Si,Wei Gao,Qiang Wu,Runsheng Wang,Guangyu Sun*

Main category: cs.AR

TL;DR: SRAM PIM中的IR-drop问题通过软件和硬件协同设计AIM得到缓解，实现了性能和能效的提升。


<details>
  <summary>Details</summary>
Motivation: SRAM PIM虽然性能优越，但高频率和复杂设计加剧了IR-drop问题，影响性能和可靠性。传统硬件级IR-drop缓解方法成本高且牺牲PPA。

Method: 提出AIM协同设计，包括：1. Rtog和HR建立PIM工作负载与IR-drop的关联；2. LHR和WDS进行架构级IR-drop缓解；3. IR-Booster动态调整V-f以优化能效和性能；4. HR感知任务映射实现软硬件协同。

Result: AIM在7nm 256-TOPS PIM芯片上实现高达69.2%的IR-drop缓解，能效提升2.29倍，速度提升1.152倍。

Conclusion: AIM通过软硬件协同设计有效缓解了SRAM PIM的IR-drop问题，显著提升了性能和能效。

Abstract: SRAM Processing-in-Memory (PIM) has emerged as the most promising
implementation for high-performance PIM, delivering superior computing density,
energy efficiency, and computational precision. However, the pursuit of higher
performance necessitates more complex circuit designs and increased operating
frequencies, which exacerbate IR-drop issues. Severe IR-drop can significantly
degrade chip performance and even threaten reliability. Conventional
circuit-level IR-drop mitigation methods, such as back-end optimizations, are
resource-intensive and often compromise power, performance, and area (PPA). To
address these challenges, we propose AIM, comprehensive software and hardware
co-design for architecture-level IR-drop mitigation in high-performance PIM.
Initially, leveraging the bit-serial and in-situ dataflow processing properties
of PIM, we introduce Rtog and HR, which establish a direct correlation between
PIM workloads and IR-drop. Building on this foundation, we propose LHR and WDS,
enabling extensive exploration of architecture-level IR-drop mitigation while
maintaining computational accuracy through software optimization. Subsequently,
we develop IR-Booster, a dynamic adjustment mechanism that integrates
software-level HR information with hardware-based IR-drop monitoring to adapt
the V-f pairs of the PIM macro, achieving enhanced energy efficiency and
performance. Finally, we propose the HR-aware task mapping method, bridging
software and hardware designs to achieve optimal improvement. Post-layout
simulation results on a 7nm 256-TOPS PIM chip demonstrate that AIM achieves up
to 69.2% IR-drop mitigation, resulting in 2.29x energy efficiency improvement
and 1.152x speedup.

</details>


### [121] [Scalable and Efficient Intra- and Inter-node Interconnection Networks for Post-Exascale Supercomputers and Data centers](https://arxiv.org/abs/2511.04677)
*Joaquin Tarraga-Moreno,Daniel Barley,Francisco J. Andujar Munoz,Jesus Escudero-Sahuquillo,Holger Froning,Pedro Javier Garcia,Francisco J. Quiles,Jose Duato*

Main category: cs.AR

TL;DR: 现代超级计算和数据中心正朝着异构和紧密集成的架构发展，以应对数据密集型应用的增长。然而，随着节点内加速器数量的增加，通信瓶颈日益突出，尤其是在网络资源被异构组件共享的情况下。


<details>
  <summary>Details</summary>
Motivation: 生成式AI、科学模拟和大规模分析等数据密集型应用的快速发展，正推动现代超级计算和数据中心朝着日益异构和紧密集成的架构发展。

Method: 该论文探讨了由CPU、加速器、高带宽内存和存储技术组成的异构系统，并分析了节点内和节点间通信瓶颈的出现，特别是在网络资源被共享的情况下。

Result: 随着节点内加速器数量的增加，通信瓶颈成为一个突出问题，尤其是在网络资源由异构组件共享时。

Conclusion: 尽管异构和紧密集成的架构在理论上可以提高计算效率并减少数据移动，但节点内和节点间的通信瓶颈，特别是在共享网络资源的情况下，仍然是需要解决的关键挑战。

Abstract: The rapid growth of data-intensive applications such as generative AI,
scientific simulations, and large-scale analytics is driving modern
supercomputers and data centers toward increasingly heterogeneous and tightly
integrated architectures. These systems combine powerful CPUs and accelerators
with emerging high-bandwidth memory and storage technologies to reduce data
movement and improve computational efficiency. However, as the number of
accelerators per node increases, communication bottlenecks emerge both within
and between nodes, particularly when network resources are shared among
heterogeneous components.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [122] [Dynamic Shape Control of Soft Robots Enabled by Data-Driven Model Reduction](https://arxiv.org/abs/2511.03931)
*Iman Adibnazari,Harsh Sharma,Myungsun Park,Jacobo Cervera-Torralba,Boris Kramer,Michael T. Tolley*

Main category: cs.RO

TL;DR: 软体机器人需要考虑高维度动力学，但缺乏通用建模工具。本文比较了三种数据驱动降阶技术（ERA, extended DMD, LOpInf）在模拟鳗鱼软体机器人动态形状控制中的应用。


<details>
  <summary>Details</summary>
Motivation: 软体机器人在需要全身动态控制的场景中潜力巨大，但有效的动态形状控制需要考虑高维度动力学，而目前缺乏通用的建模工具。

Method: 比较了三种数据驱动模型降阶技术：特征系统实现算法（ERA）、带控制的动态模式分解（extended DMD）和拉格朗日算子推理（LOpInf），并使用这些模型设计了模型预测控制策略，应用于模拟鳗鱼软体机器人的动态形状控制。

Result: 在三种不同的实验场景（跟踪可行轨迹、生物模型轨迹和物理模型轨迹）中，基于LOpInf的模型预测控制策略均取得了比其他模型更低的跟踪误差。

Conclusion: LOpInf 方法在软体机器人动态形状控制方面优于 ERA 和 extended DMD，能够生成更精确的模型，从而实现更好的控制效果。

Abstract: Soft robots have shown immense promise in settings where they can leverage
dynamic control of their entire bodies. However, effective dynamic shape
control requires a controller that accounts for the robot's high-dimensional
dynamics--a challenge exacerbated by a lack of general-purpose tools for
modeling soft robots amenably for control. In this work, we conduct a
comparative study of data-driven model reduction techniques for generating
linear models amendable to dynamic shape control. We focus on three
methods--the eigensystem realization algorithm, dynamic mode decomposition with
control, and the Lagrangian operator inference (LOpInf) method. Using each
class of model, we explored their efficacy in model predictive control policies
for the dynamic shape control of a simulated eel-inspired soft robot in three
experiments: 1) tracking simulated reference trajectories guaranteed to be
feasible, 2) tracking reference trajectories generated from a biological model
of eel kinematics, and 3) tracking reference trajectories generated by a
reduced-scale physical analog. In all experiments, the LOpInf-based policies
generated lower tracking errors than policies based on other models.

</details>


### [123] [Learning Vision-Driven Reactive Soccer Skills for Humanoid Robots](https://arxiv.org/abs/2511.03996)
*Yushi Wang,Changsheng Luo,Penghui Chen,Jianran Liu,Weijian Sun,Tong Guo,Kechang Yang,Biao Hu,Yangang Zhang,Mingguo Zhao*

Main category: cs.RO

TL;DR: 该研究提出了一种统一的强化学习控制器，用于在人形机器人足球比赛中实现反应式运动技能，通过直接整合视觉感知和运动控制来解决现有系统模块化带来的延迟和不连贯问题。


<details>
  <summary>Details</summary>
Motivation: 现有的人形机器人足球系统通常采用模块化设计，导致感知与动作之间存在延迟，在动态环境中行为不连贯，而现实世界的感知限制更是加剧了这些问题。

Method: 本研究提出了一种基于强化学习的统一控制器，将视觉感知和运动控制直接集成，并扩展了对抗性运动先验（Adversarial Motion Priors）到真实世界的感知环境。该方法采用编码器-解码器架构结合虚拟感知系统，以模拟真实世界的视觉特性，使策略能够从不完美的观测中恢复特权状态，并建立感知与动作之间的主动协调。

Result: 所提出的控制器展示了强大的反应能力，在包括真实机器人世界杯（RoboCup）比赛在内的各种场景中，能够持续执行连贯且鲁棒的足球运动。

Conclusion: 通过将视觉感知和运动控制统一在强化学习框架下，并引入虚拟感知系统以处理现实世界的视觉不确定性，该研究成功地使人形机器人获得了高度反应式的足球技能，显著提高了其在动态环境下的运动表现。

Abstract: Humanoid soccer poses a representative challenge for embodied intelligence,
requiring robots to operate within a tightly coupled perception-action loop.
However, existing systems typically rely on decoupled modules, resulting in
delayed responses and incoherent behaviors in dynamic environments, while
real-world perceptual limitations further exacerbate these issues. In this
work, we present a unified reinforcement learning-based controller that enables
humanoid robots to acquire reactive soccer skills through the direct
integration of visual perception and motion control. Our approach extends
Adversarial Motion Priors to perceptual settings in real-world dynamic
environments, bridging motion imitation and visually grounded dynamic control.
We introduce an encoder-decoder architecture combined with a virtual perception
system that models real-world visual characteristics, allowing the policy to
recover privileged states from imperfect observations and establish active
coordination between perception and action. The resulting controller
demonstrates strong reactivity, consistently executing coherent and robust
soccer behaviors across various scenarios, including real RoboCup matches.

</details>


### [124] [Integrating Ergonomics and Manipulability for Upper Limb Postural Optimization in Bimanual Human-Robot Collaboration](https://arxiv.org/abs/2511.04009)
*Chenzui Li,Yiming Chen,Xi Wu,Giacinto Barresi,Fei Chen*

Main category: cs.RO

TL;DR: 本研究提出了一种上肢姿势优化方法，用于在双臂人机协同搬运任务中增强人体工程学和力操纵性。


<details>
  <summary>Details</summary>
Motivation: 现有研究通常侧重于人类安全或操作效率，而本研究提出的方法独特地整合了这两个方面，以在不同条件下（例如，人类不同的抓握姿势和物体的不同形状）加强协作。

Method: 通过优化简化的人体骨骼模型关节角度，并通过最小化成本函数来优先考虑安全性和操作能力。为了引导人类采取优化姿势，机器人参考末端执行器姿势是通过变换模块生成的。提出了一种用于我们的人形机器人CURI的双臂模型预测阻抗控制器（MPIC），以通过规划的轨迹重新校准末端执行器姿势。

Result: 通过不同对象和不同受试者在人与人协作（HHC）和人机协作（HRC）中的验证。实验结果通过比较优化前后目标肌肉的激活情况，证明了肌肉状况的显著改善。

Conclusion: 该方法在人机协作搬运任务中，通过优化上肢姿势，有效提升了人体工程学和力操纵性，并得到了实验验证。

Abstract: This paper introduces an upper limb postural optimization method for
enhancing physical ergonomics and force manipulability during bimanual
human-robot co-carrying tasks. Existing research typically emphasizes human
safety or manipulative efficiency, whereas our proposed method uniquely
integrates both aspects to strengthen collaboration across diverse conditions
(e.g., different grasping postures of humans, and different shapes of objects).
Specifically, the joint angles of a simplified human skeleton model are
optimized by minimizing the cost function to prioritize safety and manipulative
capability. To guide humans towards the optimized posture, the reference
end-effector poses of the robot are generated through a transformation module.
A bimanual model predictive impedance controller (MPIC) is proposed for our
human-like robot, CURI, to recalibrate the end effector poses through planned
trajectories. The proposed method has been validated through various subjects
and objects during human-human collaboration (HHC) and human-robot
collaboration (HRC). The experimental results demonstrate significant
improvement in muscle conditions by comparing the activation of target muscles
before and after optimization.

</details>


### [125] [An LLM-based Framework for Human-Swarm Teaming Cognition in Disaster Search and Rescue](https://arxiv.org/abs/2511.04042)
*Kailun Ji,Xiaoyu Hu,Xinyu Zhang,Jun Chen*

Main category: cs.RO

TL;DR: 本文提出了一种名为 LLM-CRF 的新系统，该系统利用大型语言模型 (LLM) 来增强人类与无人机 (UAV) 群的协作，以应对大规模灾难搜救 (SAR) 中的挑战。该系统通过自然语言和多模态交互来理解操作员的意图，然后使用 LLM 进行任务规划和分解，使无人机群能够主动协作并提供实时反馈。实验结果表明，与传统方法相比，该系统将任务完成时间缩短了 64.2%，成功率提高了 7%，并降低了 42.9% 的认知负荷。


<details>
  <summary>Details</summary>
Motivation: 大规模灾难搜救 (SAR) 操作面临复杂地形和通信中断的挑战。虽然无人机群可以提供帮助，但有效协调它们给人类操作员带来巨大的认知负担，尤其是在“意图到行动”的转换过程中，这在高强度和压力下容易出错。

Method: 提出了一种新颖的 LLM-CRF 系统。该系统首先通过语音或图形注释与设备进行自然和多模态交互来捕获操作员的意图。然后，它使用 LLM 作为认知引擎来执行意图理解、分层任务分解和无人机群的任务规划。这是一个闭环框架，使无人机群能够充当积极的合作伙伴，提供实时反馈，同时减少手动监控和控制的需求。

Result: 在模拟 SAR 场景中进行的评估表明，与传统的命令式界面相比，LLM 驱动的方法将任务完成时间缩短了约 64.2%，将任务成功率提高了 7%。此外，NASA-TLX 评分显示主观认知负荷降低了 42.9%。

Conclusion: 这项工作证明了 LLM 在高风险场景中创建更直观、更有效的人机协作的潜力，特别是在大规模灾难搜救任务中。

Abstract: Large-scale disaster Search And Rescue (SAR) operations are persistently
challenged by complex terrain and disrupted communications. While Unmanned
Aerial Vehicle (UAV) swarms offer a promising solution for tasks like wide-area
search and supply delivery, yet their effective coordination places a
significant cognitive burden on human operators. The core human-machine
collaboration bottleneck lies in the ``intention-to-action gap'', which is an
error-prone process of translating a high-level rescue objective into a
low-level swarm command under high intensity and pressure. To bridge this gap,
this study proposes a novel LLM-CRF system that leverages Large Language Models
(LLMs) to model and augment human-swarm teaming cognition. The proposed
framework initially captures the operator's intention through natural and
multi-modal interactions with the device via voice or graphical annotations. It
then employs the LLM as a cognitive engine to perform intention comprehension,
hierarchical task decomposition, and mission planning for the UAV swarm. This
closed-loop framework enables the swarm to act as a proactive partner,
providing active feedback in real-time while reducing the need for manual
monitoring and control, which considerably advances the efficacy of the SAR
task. We evaluate the proposed framework in a simulated SAR scenario.
Experimental results demonstrate that, compared to traditional order and
command-based interfaces, the proposed LLM-driven approach reduced task
completion time by approximately $64.2\%$ and improved task success rate by
$7\%$. It also leads to a considerable reduction in subjective cognitive
workload, with NASA-TLX scores dropping by $42.9\%$. This work establishes the
potential of LLMs to create more intuitive and effective human-swarm
collaborations in high-stakes scenarios.

</details>


### [126] [Enhancing Fault-Tolerant Space Computing: Guidance Navigation and Control (GNC) and Landing Vision System (LVS) Implementations on Next-Gen Multi-Core Processors](https://arxiv.org/abs/2511.04052)
*Kyongsik Yun,David Bayard,Gerik Kubiak,Austin Owens,Andrew Johnson,Ryan Johnson,Dan Scharf,Thomas Lu*

Main category: cs.RO

TL;DR: 该论文评估了下一代多核处理器在行星探索任务中的应用，重点关注了制导、导航与控制（GNC）和着陆器视觉系统（LVS）算法的性能和容错能力。研究展示了在LVS图像处理和GFOLD轨迹优化方面相比传统硬件有显著的速度提升。为确保计算可靠性，论文提出了一种名为ARBITER的多核投票（MV）机制，用于实时故障检测和纠正。通过故障注入研究，确定了GFOLD的梯度计算是位错误最敏感的环节，并提出了选择性保护和基于向量的仲裁策略。该研究为未来的行星探索任务（如火星样本返回）建立了一个可扩展、高能效且容错能力强的计算架构。


<details>
  <summary>Details</summary>
Motivation: 未来的行星探索任务需要高性能、容错的计算能力来支持自主的制导、导航与控制（GNC）和着陆器视觉系统（LVS）在进入、下降和着陆（EDL）期间的操作。

Method: 评估了在HPSC、Snapdragon VOXL2和AMD Xilinx Versal等下一代多核处理器上部署GNC和LVS算法。提出了一种名为ARBITER的多核投票（MV）机制，用于实时故障检测和纠正。通过故障注入研究来识别GFOLD中的敏感环节。

Result: 在LVS图像处理方面实现了高达15倍的速度提升，在GFOLD轨迹优化方面实现了超过250倍的速度提升。ARBITER在静态优化任务（GFOLD）和动态闭环控制（姿态控制系统）中得到了验证。故障注入研究确定了GFOLD中的梯度计算阶段对位级错误最为敏感。

Conclusion: 这项工作为未来的行星探索任务（包括火星样本返回、恩克拉多斯轨道着陆器和谷神星样本返回）建立了一个可扩展且能效高的架构，这些任务对自主性、低延迟和容错能力有关键要求。论文还提出了选择性保护策略和基于向量的输出仲裁方法。

Abstract: Future planetary exploration missions demand high-performance, fault-tolerant
computing to enable autonomous Guidance, Navigation, and Control (GNC) and
Lander Vision System (LVS) operations during Entry, Descent, and Landing (EDL).
This paper evaluates the deployment of GNC and LVS algorithms on
next-generation multi-core processors--HPSC, Snapdragon VOXL2, and AMD Xilinx
Versal--demonstrating up to 15x speedup for LVS image processing and over 250x
speedup for Guidance for Fuel-Optimal Large Divert (GFOLD) trajectory
optimization compared to legacy spaceflight hardware. To ensure computational
reliability, we present ARBITER (Asynchronous Redundant Behavior Inspection for
Trusted Execution and Recovery), a Multi-Core Voting (MV) mechanism that
performs real-time fault detection and correction across redundant cores.
ARBITER is validated in both static optimization tasks (GFOLD) and dynamic
closed-loop control (Attitude Control System). A fault injection study further
identifies the gradient computation stage in GFOLD as the most sensitive to
bit-level errors, motivating selective protection strategies and vector-based
output arbitration. This work establishes a scalable and energy-efficient
architecture for future missions, including Mars Sample Return, Enceladus
Orbilander, and Ceres Sample Return, where onboard autonomy, low latency, and
fault resilience are critical.

</details>


### [127] [CBMC-V3: A CNS-inspired Control Framework Towards Manipulation Agility with SNN](https://arxiv.org/abs/2511.04109)
*Yanbo Pang,Qingkai Li,Mingguo Zhao*

Main category: cs.RO

TL;DR: 该研究提出了一种受人脑启发的、基于脉冲神经网络（SNN）的仿生机器人手臂控制框架，以实现复杂动态环境下的敏捷操作。


<details>
  <summary>Details</summary>
Motivation: 现有机器人手臂控制算法在应对动态轨迹、不可预测交互和多样化物体等复杂环境时存在不足，无法实现敏捷操控。

Method: 提出一个包含五个控制模块（大脑皮层、小脑、丘脑、脑干、脊髓）、三个分层控制级别（一阶、二阶、三阶）和两条信息通路（上行、下行）的仿生控制框架。所有模块均采用SNN实现。脊髓模块使用脉冲编码和LIF神经元进行反馈控制；脑干模块通过强化学习动态调整脊髓参数；丘脑模块调整小脑的力矩输出；小脑模块使用循环SNN进行动力学学习以进行重力补偿。

Result: 在仿真和真实机器人手臂平台上，该框架在不同负载和轨迹下均表现出色，显著优于工业级位置控制在操控敏捷性方面。

Conclusion: 该研究提出的基于SNN的仿生控制框架能够有效地提升机器人在复杂动态环境下的操控敏捷性。

Abstract: As robotic arm applications extend beyond industrial settings into
healthcare, service, and daily life, existing control algorithms struggle to
achieve the agile manipulation required for complex environments with dynamic
trajectories, unpredictable interactions, and diverse objects. This paper
presents a biomimetic control framework based on Spiking Neural Networks (SNN),
inspired by the human Central Nervous System (CNS), to achieve agile control in
such environments. The proposed framework features five control modules
(cerebral cortex, cerebellum, thalamus, brainstem, spinal cord), three
hierarchical control levels (first-order, second-order, third-order), and two
information pathways (ascending, descending). Each module is fully implemented
using SNN. The spinal cord module uses spike encoding and Leaky
Integrate-and-Fire (LIF) neurons for feedback control. The brainstem module
employs a network of LIF and non-spiking LIF neurons to dynamically adjust
spinal cord parameters via reinforcement learning. The thalamus module
similarly adjusts the cerebellum's torque outputs. The cerebellum module uses a
recurrent SNN to learn the robotic arm's dynamics through regression, providing
feedforward gravity compensation torques. The framework is validated both in
simulation and on real-world robotic arm platform under various loads and
trajectories. Results demonstrate that our method outperforms the
industrial-grade position control in manipulation agility.

</details>


### [128] [BFM-Zero: A Promptable Behavioral Foundation Model for Humanoid Control Using Unsupervised Reinforcement Learning](https://arxiv.org/abs/2511.04131)
*Yitang Li,Zhengyi Luo,Tonghe Zhang,Cunxi Dai,Anssi Kanervisto,Andrea Tirinzoni,Haoyang Weng,Kris Kitani,Mateusz Guzek,Ahmed Touati,Alessandro Lazaric,Matteo Pirotta,Guanya Shi*

Main category: cs.RO

TL;DR: BFM-Zero 是一个框架，通过学习共享的潜在表征，使单个策略能够通过提示（prompt）适应多种下游任务，而无需重新训练，从而在现实世界的人型机器人上实现通用的全身技能。


<details>
  <summary>Details</summary>
Motivation: 现有的人型机器人行为基础模型（BFMs）要么仅限于模拟，要么专注于特定任务，缺乏通用性和可提示性。BFM-Zero 旨在解决这一问题，实现多任务的统一控制。

Method: BFM-Zero 学习一种有效的共享潜在表征，将运动、目标和奖励嵌入通用空间。它基于无监督强化学习（RL）和前向-后向（FB）模型，并结合了奖励塑形、域随机化和历史依赖的非对称学习来缩小模拟与现实之间的差距。

Result: BFM-Zero 在 Unitree G1 人型机器人上展示了通用的全身技能，包括零样本运动跟踪、目标达成和奖励优化，以及少样本基于优化的适应。消融实验在模拟中量化评估了关键设计选择。

Conclusion: BFM-Zero 是首个此类模型，它为可扩展、可提示的全身人型机器人控制行为基础模型迈出了重要一步。

Abstract: Building Behavioral Foundation Models (BFMs) for humanoid robots has the
potential to unify diverse control tasks under a single, promptable generalist
policy. However, existing approaches are either exclusively deployed on
simulated humanoid characters, or specialized to specific tasks such as
tracking. We propose BFM-Zero, a framework that learns an effective shared
latent representation that embeds motions, goals, and rewards into a common
space, enabling a single policy to be prompted for multiple downstream tasks
without retraining. This well-structured latent space in BFM-Zero enables
versatile and robust whole-body skills on a Unitree G1 humanoid in the real
world, via diverse inference methods, including zero-shot motion tracking, goal
reaching, and reward optimization, and few-shot optimization-based adaptation.
Unlike prior on-policy reinforcement learning (RL) frameworks, BFM-Zero builds
upon recent advancements in unsupervised RL and Forward-Backward (FB) models,
which offer an objective-centric, explainable, and smooth latent representation
of whole-body motions. We further extend BFM-Zero with critical reward shaping,
domain randomization, and history-dependent asymmetric learning to bridge the
sim-to-real gap. Those key design choices are quantitatively ablated in
simulation. A first-of-its-kind model, BFM-Zero establishes a step toward
scalable, promptable behavioral foundation models for whole-body humanoid
control.

</details>


### [129] [PUL-SLAM: Path-Uncertainty Co-Optimization with Lightweight Stagnation Detection for Efficient Robotic Exploration](https://arxiv.org/abs/2511.04180)
*Yizhen Yin,Dapeng Feng,Hongbo Chen,Yuhua Qi*

Main category: cs.RO

TL;DR: 提出一种结合路径不确定性协同优化深度强化学习和轻量化停滞检测的混合框架，以解决现有主动SLAM方法探索速度慢和路径次优的问题。


<details>
  <summary>Details</summary>
Motivation: 现有主动SLAM方法存在探索速度慢和路径次优的问题，需要改进。

Method: 提出一个混合框架，包括路径不确定性协同优化深度强化学习（联合优化行驶距离和地图不确定性）和轻量化停滞检测（通过Lidar静态异常检测和地图更新停滞检测减少冗余探索）。

Result: 与基于边界的方法和RRT方法相比，该方法探索时间缩短高达65%，路径距离减少高达42%，在复杂环境中显著提高了探索效率，同时保持了可靠的地图完整性。消融研究表明，协同机制加速了训练收敛。在物理机器人平台上进行了实证验证，证明了该算法的实际适用性及其从模拟到真实世界环境的可转移性。

Conclusion: 所提出的混合框架能有效提高主动SLAM的探索效率和路径优化，并在复杂环境中表现出色，同时具有良好的训练收敛性和实际应用潜力。

Abstract: Existing Active SLAM methodologies face issues such as slow exploration speed
and suboptimal paths. To address these limitations, we propose a hybrid
framework combining a Path-Uncertainty Co-Optimization Deep Reinforcement
Learning framework and a Lightweight Stagnation Detection mechanism. The
Path-Uncertainty Co-Optimization framework jointly optimizes travel distance
and map uncertainty through a dual-objective reward function, balancing
exploration and exploitation. The Lightweight Stagnation Detection reduces
redundant exploration through Lidar Static Anomaly Detection and Map Update
Stagnation Detection, terminating episodes on low expansion rates. Experimental
results show that compared with the frontier-based method and RRT method, our
approach shortens exploration time by up to 65% and reduces path distance by up
to 42%, significantly improving exploration efficiency in complex environments
while maintaining reliable map completeness. Ablation studies confirm that the
collaborative mechanism accelerates training convergence. Empirical validation
on a physical robotic platform demonstrates the algorithm's practical
applicability and its successful transferability from simulation to real-world
environments.

</details>


### [130] [GraspView: Active Perception Scoring and Best-View Optimization for Robotic Grasping in Cluttered Environments](https://arxiv.org/abs/2511.04199)
*Shenglin Wang,Mingtong Dai,Jingxuan Su,Lingbo Liu,Chunjie Chen,Xinyu Wu,Liang Lin*

Main category: cs.RO

TL;DR: GraspView是一个仅使用RGB的机器人抓取管道，可在杂乱环境中实现精确操作，无需深度传感器。


<details>
  <summary>Details</summary>
Motivation: 在杂乱环境中，由于遮挡、感知质量差和不一致的3D重建，机器人抓取仍然是一个巨大的挑战，这通常会导致抓取不稳定或失败。传统的RGB-D相机在透明或有光泽的物体上表现不佳，并且在近距离会降低性能。

Method: GraspView是一个仅使用RGB的机器人抓取管道，它整合了三个关键组件：（1）全局感知场景重建，从单一RGB视图提供局部一致的、按比例的几何信息，并将多视图投影融合到连贯的全局3D场景中；（2）渲染和评分的主动感知策略，动态选择最佳视图以揭示被遮挡的区域；（3）在线度量对齐模块，将VGGT预测与机器人运动学进行校准，以确保物理尺度一致性。该框架在多视图重建的基础上，利用GraspNet进行鲁棒执行。

Result: 在各种桌面物体上的实验表明，GraspView在杂乱环境中的性能显著优于RGB-D和单视图RGB基线，尤其是在严重遮挡、近场感应和透明物体的情况下。

Conclusion: GraspView是RGB-D管道的可行且通用的替代方案，它能够实现非结构化真实环境中可靠的抓取。

Abstract: Robotic grasping is a fundamental capability for autonomous manipulation, yet
remains highly challenging in cluttered environments where occlusion, poor
perception quality, and inconsistent 3D reconstructions often lead to unstable
or failed grasps. Conventional pipelines have widely relied on RGB-D cameras to
provide geometric information, which fail on transparent or glossy objects and
degrade at close range. We present GraspView, an RGB-only robotic grasping
pipeline that achieves accurate manipulation in cluttered environments without
depth sensors. Our framework integrates three key components: (i) global
perception scene reconstruction, which provides locally consistent, up-to-scale
geometry from a single RGB view and fuses multi-view projections into a
coherent global 3D scene; (ii) a render-and-score active perception strategy,
which dynamically selects next-best-views to reveal occluded regions; and (iii)
an online metric alignment module that calibrates VGGT predictions against
robot kinematics to ensure physical scale consistency. Building on these
tailor-designed modules, GraspView performs best-view global grasping, fusing
multi-view reconstructions and leveraging GraspNet for robust execution.
Experiments on diverse tabletop objects demonstrate that GraspView
significantly outperforms both RGB-D and single-view RGB baselines, especially
under heavy occlusion, near-field sensing, and with transparent objects. These
results highlight GraspView as a practical and versatile alternative to RGB-D
pipelines, enabling reliable grasping in unstructured real-world environments.

</details>


### [131] [Can Context Bridge the Reality Gap? Sim-to-Real Transfer of Context-Aware Policies](https://arxiv.org/abs/2511.04249)
*Marco Iannotta,Yuxuan Yang,Johannes A. Stork,Erik Schaffernicht,Todor Stoyanov*

Main category: cs.RO

TL;DR: Sim-to-real transfer in RL for robotics is challenging due to simulation-reality discrepancies. Domain Randomization (DR) helps but reduces performance. This paper proposes context-aware policies that condition on estimated dynamics parameters, outperforming context-agnostic baselines in both simulation and real-world tasks.


<details>
  <summary>Details</summary>
Motivation: Sim-to-real transfer in RL for robotics faces challenges due to discrepancies between simulation and real-world dynamics, and while Domain Randomization (DR) can mitigate this, it often leads to performance reduction. The paper investigates if conditioning policies on estimated dynamics parameters (context) can improve sim-to-real transfer.

Method: The study integrates a context estimation module into a DR-based RL framework and compares different SOTA supervision strategies. The resulting context-aware policies are evaluated against a context-agnostic baseline.

Result: Context-aware policies demonstrated superior performance compared to the context-agnostic baseline across all evaluated settings, including a canonical control benchmark and a real-world pushing task with a Franka Emika Panda robot. However, the optimal supervision strategy varied depending on the specific task.

Conclusion: Conditioning reinforcement learning policies on estimated dynamics parameters (context) can significantly improve sim-to-real transfer in robotics, outperforming traditional context-agnostic approaches. The choice of supervision strategy for context estimation is crucial and task-dependent.

Abstract: Sim-to-real transfer remains a major challenge in reinforcement learning (RL)
for robotics, as policies trained in simulation often fail to generalize to the
real world due to discrepancies in environment dynamics. Domain Randomization
(DR) mitigates this issue by exposing the policy to a wide range of randomized
dynamics during training, yet leading to a reduction in performance. While
standard approaches typically train policies agnostic to these variations, we
investigate whether sim-to-real transfer can be improved by conditioning the
policy on an estimate of the dynamics parameters -- referred to as context. To
this end, we integrate a context estimation module into a DR-based RL framework
and systematically compare SOTA supervision strategies. We evaluate the
resulting context-aware policies in both a canonical control benchmark and a
real-world pushing task using a Franka Emika Panda robot. Results show that
context-aware policies outperform the context-agnostic baseline across all
settings, although the best supervision strategy depends on the task.

</details>


### [132] [Design and Control of a Coaxial Dual-rotor Reconfigurable Tailsitter UAV Based on Swashplateless Mechanism](https://arxiv.org/abs/2511.04251)
*Jinfeng Liang,Haocheng Guo,Ximin Lyu*

Main category: cs.RO

TL;DR: 该无人机通过可重构机翼设计解决了侧倾无人机在多旋翼模式下易受风力干扰的问题，并采用同轴异质双旋翼和无十字盘的改进设计来提高效率和减轻重量，最终通过飞行测试验证了其稳定性。


<details>
  <summary>Details</summary>
Motivation: 侧倾垂直起降（VTOL）无人机虽然因无需倾转致动器和机构而重量较轻，但在多旋翼模式下，较大的正面机身暴露面积使其易受风力干扰。

Method: 设计了一种可重构机翼，使其在多旋翼模式下可收缩，在固定翼模式下可伸展；采用了同轴异质双旋翼配置以提高能源效率；使用改进的无十字盘机构来控制多旋翼模式下的俯仰和横滚，并通过增加铰链来优化结构，以减少振动；最后进行了全面的过渡飞行测试。

Result: 该设计成功实现了侧倾无人机在多旋翼模式下的稳定性，并为固定翼模式下的高效飞行奠定了基础。

Conclusion: 该无人机通过创新的设计（可重构机翼、同轴异质双旋翼、无十字盘机构）有效解决了侧倾无人机在多旋翼模式下易受风力干扰的问题，提高了效率并减轻了结构重量，飞行测试验证了其在整个飞行包络内的稳定性。

Abstract: The tailsitter vertical takeoff and landing (VTOL) UAV is widely used due to
its lower dead weight, which eliminates the actuators and mechanisms for
tilting. However, the tailsitter UAV is susceptible to wind disturbances in
multi-rotor mode, as it exposes a large frontal fuselage area. To address this
issue, our tailsitter UAV features a reconfigurable wing design, allowing wings
to retract in multi-rotor mode and extend in fixed- wing mode. Considering
power efficiency, we design a coaxial heterogeneous dual-rotor configuration,
which significantly re- duces the total power consumption. To reduce structural
weight and simplify structural complexity, we employ a swashplateless mechanism
with an improved design to control pitch and roll in multi-rotor mode. We
optimize the structure of the swashplateless mechanism by adding flapping
hinges, which reduces vibration during cyclic acceleration and deceleration.
Finally, we perform comprehensive transition flight tests to validate stable
flight performance across the entire flight envelope of the tailsitter UAV.

</details>


### [133] [MacroNav: Multi-Task Context Representation Learning Enables Efficient Navigation in Unknown Environments](https://arxiv.org/abs/2511.04320)
*Kuankuan Sima,Longbin Tang,Haozhe Ma,Lin Zhao*

Main category: cs.RO

TL;DR: MacroNav是一个基于学习的导航框架，通过轻量级上下文编码器和强化学习策略，在未知环境中实现高效导航。


<details>
  <summary>Details</summary>
Motivation: 在未知环境中进行自主导航需要紧凑而富有表现力的空间理解能力，以支持高级决策。现有方法难以在丰富的上下文表示和导航效率之间取得平衡。

Method: MacroNav框架包含两个关键组件：1. 通过多任务自监督学习训练的轻量级上下文编码器，用于捕获多尺度、面向导航的空间表示；2. 强化学习策略，将这些表示与基于图的推理无缝集成，以实现高效的动作选择。

Result: 实验证明，上下文编码器具有高效且鲁棒的环境理解能力。实际部署验证了MacroNav的有效性，在成功率（SR）和成功率加权路径长度（SPL）方面显著优于最先进的导航方法，同时保持了较低的计算成本。

Conclusion: MacroNav在提高导航效率和成功率方面表现出色，同时保持了低计算成本，是一种有效的自主导航解决方案。

Abstract: Autonomous navigation in unknown environments requires compact yet expressive
spatial understanding under partial observability to support high-level
decision making. Existing approaches struggle to balance rich contextual
representation with navigation efficiency. We present MacroNav, a
learning-based navigation framework featuring two key components: (1) a
lightweight context encoder trained via multi-task self-supervised learning to
capture multi-scale, navigation-centric spatial representations; and (2) a
reinforcement learning policy that seamlessly integrates these representations
with graph-based reasoning for efficient action selection. Extensive
experiments demonstrate the context encoder's efficient and robust
environmental understanding. Real-world deployments further validate MacroNav's
effectiveness, yielding significant gains over state-of-the-art navigation
methods in both Success Rate (SR) and Success weighted by Path Length (SPL),
while maintaining low computational cost. Code will be released upon
acceptance.

</details>


### [134] [GraSP-VLA: Graph-based Symbolic Action Representation for Long-Horizon Planning with VLA Policies](https://arxiv.org/abs/2511.04357)
*Maëlic Neau,Zoe Falomir,Paulo E. Santos,Anne-Gwenn Bosser,Cédric Buche*

Main category: cs.RO

TL;DR: 提出了一种新的神经符号方法GraSP-VLA，该方法使用连续场景图表示来生成人类演示的符号表示，并作为低级VLA策略的编排器，以解决现有VLA模型缺乏高层符号规划和AML缺乏泛化性的问题。


<details>
  <summary>Details</summary>
Motivation: 现有的端到端模仿学习（VLA模型）缺乏高层符号规划能力，难以处理长时任务；而符号方法（AML）泛化性和可扩展性不足。本研究旨在提出一种结合两者优点的新方法。

Method: 提出了一种名为GraSP-VLA的新型神经符号框架，它利用连续场景图（Continuous Scene Graph）表示来解析人类演示，生成符号化表示。该表示在推理时用于生成新的规划域，并作为低级VLA策略的协调器，以连续执行更多动作。

Result: GraSP-VLA在从观测中自动生成规划域的任务中，有效地进行了符号表示建模。在真实世界实验中，该方法在协调低级VLA策略以应对长时任务方面展现了潜力。

Conclusion: GraSP-VLA通过结合连续场景图表示和VLA策略，成功地解决了现有方法的局限性，能够处理长时任务，并在自动规划域生成和现实世界机器人应用中展现出有效性。

Abstract: Deploying autonomous robots that can learn new skills from demonstrations is
an important challenge of modern robotics. Existing solutions often apply
end-to-end imitation learning with Vision-Language Action (VLA) models or
symbolic approaches with Action Model Learning (AML). On the one hand, current
VLA models are limited by the lack of high-level symbolic planning, which
hinders their abilities in long-horizon tasks. On the other hand, symbolic
approaches in AML lack generalization and scalability perspectives. In this
paper we present a new neuro-symbolic approach, GraSP-VLA, a framework that
uses a Continuous Scene Graph representation to generate a symbolic
representation of human demonstrations. This representation is used to generate
new planning domains during inference and serves as an orchestrator for
low-level VLA policies, scaling up the number of actions that can be reproduced
in a row. Our results show that GraSP-VLA is effective for modeling symbolic
representations on the task of automatic planning domain generation from
observations. In addition, results on real-world experiments show the potential
of our Continuous Scene Graph representation to orchestrate low-level VLA
policies in long-horizon tasks.

</details>


### [135] [Studying the Effect of Explicit Interaction Representations on Learning Scene-level Distributions of Human Trajectories](https://arxiv.org/abs/2511.04375)
*Anna Mészáros,Javier Alonso-Mora,Jens Kober*

Main category: cs.RO

TL;DR: 本篇论文研究了在自动驾驶场景中，如何表示和学习多智能体间的交互关系，以提升场景预测的准确性。


<details>
  <summary>Details</summary>
Motivation: 现有的多智能体场景预测模型在学习联合分布方面取得了一定进展，但如何表示智能体间的交互关系仍不明确，尤其是在考虑人类决策时。论文旨在研究不同的交互表示方法对最终学习到的联合分布的影响。

Method: 论文比较了多种在同一网络结构中描述交互关系的方法，包括隐式学习和显式建模。

Result: 研究发现，简单地让网络从数据中学习交互关系通常会对性能产生负面影响。相反，明确定义交互（例如，在交叉路口哪个智能体优先通过）通常能带来性能的显著提升。

Conclusion: 明确建模的交互关系比隐式学习的交互关系更能有效提升多智能体场景预测的准确性。

Abstract: Effectively capturing the joint distribution of all agents in a scene is
relevant for predicting the true evolution of the scene and in turn providing
more accurate information to the decision processes of autonomous vehicles.
While new models have been developed for this purpose in recent years, it
remains unclear how to best represent the joint distributions particularly from
the perspective of the interactions between agents. Thus far there is no clear
consensus on how best to represent interactions between agents; whether they
should be learned implicitly from data by neural networks, or explicitly
modeled using the spatial and temporal relations that are more grounded in
human decision-making. This paper aims to study various means of describing
interactions within the same network structure and their effect on the final
learned joint distributions. Our findings show that more often than not, simply
allowing a network to establish interactive connections between agents based on
data has a detrimental effect on performance. Instead, having well defined
interactions (such as which agent of an agent pair passes first at an
intersection) can often bring about a clear boost in performance.

</details>


### [136] [ForeRobo: Unlocking Infinite Simulation Data for 3D Goal-driven Robotic Manipulation](https://arxiv.org/abs/2511.04381)
*Dexin wang,Faliang Chang,Chunsheng Liu*

Main category: cs.RO

TL;DR: ForeRobo是一个生成式机器人代理，通过生成式模拟自主学习操作技能，并将生成式方法与经典控制相结合。


<details>
  <summary>Details</summary>
Motivation: 高效利用模拟来获取高级操作技能具有挑战性且意义重大。

Method: ForeRobo采用“提出-生成-学习-驱动”的周期，首先提出技能并构建模拟环境，然后通过ForeGen生成技能一致的目标状态，接着用ForeGen生成的无限数据训练ForeFormer模型，最后利用经典控制算法在真实环境中执行动作。

Result: ForeFormer在刚体和关节物体操作任务上的平均性能比最先进的状态生成模型提高了56.32%，在真实机器人评估中，ForeRobo实现了零样本模拟到现实的迁移，平均成功率为79.28%。

Conclusion: ForeRobo在提高可解释性和执行效率方面优于端到端策略学习方法，并展示了跨不同操作模式的强大泛化能力。

Abstract: Efficiently leveraging simulation to acquire advanced manipulation skills is
both challenging and highly significant. We introduce \textit{ForeRobo}, a
generative robotic agent that utilizes generative simulations to autonomously
acquire manipulation skills driven by envisioned goal states. Instead of
directly learning low-level policies, we advocate integrating generative
paradigms with classical control. Our approach equips a robotic agent with a
self-guided \textit{propose-generate-learn-actuate} cycle. The agent first
proposes the skills to be acquired and constructs the corresponding simulation
environments; it then configures objects into appropriate arrangements to
generate skill-consistent goal states (\textit{ForeGen}). Subsequently, the
virtually infinite data produced by ForeGen are used to train the proposed
state generation model (\textit{ForeFormer}), which establishes point-wise
correspondences by predicting the 3D goal position of every point in the
current state, based on the scene state and task instructions. Finally,
classical control algorithms are employed to drive the robot in real-world
environments to execute actions based on the envisioned goal states. Compared
with end-to-end policy learning methods, ForeFormer offers superior
interpretability and execution efficiency. We train and benchmark ForeFormer
across a variety of rigid-body and articulated-object manipulation tasks, and
observe an average improvement of 56.32\% over the state-of-the-art state
generation models, demonstrating strong generality across different
manipulation patterns. Moreover, in real-world evaluations involving more than
20 robotic tasks, ForeRobo achieves zero-shot sim-to-real transfer and exhibits
remarkable generalization capabilities, attaining an average success rate of
79.28\%.

</details>


### [137] [Temporal Action Selection for Action Chunking](https://arxiv.org/abs/2511.04421)
*Yueyang Weng,Xiaopeng Zhang,Yongjin Mu,Yingcong Zhu,Yanjie Li,Qi Liu*

Main category: cs.RO

TL;DR: 通过使用时间动作选择器（TAS）算法，可以提高从演示中学习（LfD）的反应能力、决策一致性和运动连贯性，从而在多个任务中提高成功率。


<details>
  <summary>Details</summary>
Motivation: 现有的动作分块方法在提高建模能力的同时，降低了决策频率，从而降低了对近期观测的利用率和反应能力，导致难以适应传感器噪声和动态环境变化。现有的解决方案在反应能力和决策一致性之间进行了权衡，未能同时实现两者。

Method: 提出了一种名为时间动作选择器（TAS）的新算法，通过缓存多个时间步长的预测动作分块，并利用一个轻量级的选择器网络动态选择最优动作。

Result: TAS 在反应能力、决策一致性和运动连贯性之间实现了平衡优化。在多个任务和不同的基础策略上进行实验，TAS 显著提高了成功率，绝对增幅高达 73.3%。此外，将 TAS 作为基础策略与残差强化学习（RL）相结合，可以显著提高训练效率并提升性能平台。

Conclusion: TAS 算法在模拟和实体机器人实验中都得到了验证，证明了其在提高LfD性能方面的有效性。

Abstract: Action chunking is a widely adopted approach in Learning from Demonstration
(LfD). By modeling multi-step action chunks rather than single-step actions,
action chunking significantly enhances modeling capabilities for human expert
policies. However, the reduced decision frequency restricts the utilization of
recent observations, degrading reactivity - particularly evident in the
inadequate adaptation to sensor noise and dynamic environmental changes.
Existing efforts to address this issue have primarily resorted to trading off
reactivity against decision consistency, without achieving both. To address
this limitation, we propose a novel algorithm, Temporal Action Selector (TAS),
which caches predicted action chunks from multiple timesteps and dynamically
selects the optimal action through a lightweight selector network. TAS achieves
balanced optimization across three critical dimensions: reactivity, decision
consistency, and motion coherence. Experiments across multiple tasks with
diverse base policies show that TAS significantly improves success rates -
yielding an absolute gain of up to 73.3%. Furthermore, integrating TAS as a
base policy with residual reinforcement learning (RL) substantially enhances
training efficiency and elevates the performance plateau. Experiments in both
simulation and physical robots confirm the method's efficacy.

</details>


### [138] [Evo-1: Lightweight Vision-Language-Action Model with Preserved Semantic Alignment](https://arxiv.org/abs/2511.04555)
*Tao Lin,Yilei Zhong,Yuxin Du,Jingjing Zhang,Jiting Liu,Yinxinyu Chen,Encheng Gu,Ziyan Liu,Hongyi Cai,Yanwen Zou,Lixing Zou,Zhaoye Zhou,Gen Li,Bo Zhao*

Main category: cs.RO

TL;DR: Evo-1是一个轻量级的视觉-语言-动作（VLA）模型，它通过新颖的跨模态扩散Transformer和优化的集成模块，在不依赖大规模机器人数据预训练的情况下，实现了高效的计算和部署，并在Meta-World、RoboTwin和LIBERO等基准测试中取得了最先进或具有竞争力的结果。


<details>
  <summary>Details</summary>
Motivation: 现有VLA模型参数量大，需要大量机器人数据预训练，导致计算成本高，实时推理部署受限，且易导致模型过拟合、泛化能力差。

Method: Evo-1采用轻量级设计，构建在原生的多模态视觉-语言模型（VLM）之上，结合了新颖的跨模态扩散Transformer和优化的集成模块。提出了一种两阶段训练范式，逐步将动作与感知对齐，以保留VLM的表征。

Result: Evo-1在Meta-World和RoboTwin上分别超越先前最佳模型12.4%和6.9%，在LIBERO上达到94.8%的竞争性结果。实际评估中，成功率达78%，推理频率高，内存开销低，优于所有基线方法。

Conclusion: Evo-1成功实现了轻量化、高效的VLA模型，在保持强大性能的同时，降低了计算和部署成本，为未来相关研究提供了基础。

Abstract: Vision-Language-Action (VLA) models have emerged as a powerful framework that
unifies perception, language, and control, enabling robots to perform diverse
tasks through multimodal understanding. However, current VLA models typically
contain massive parameters and rely heavily on large-scale robot data
pretraining, leading to high computational costs during training, as well as
limited deployability for real-time inference. Moreover, most training
paradigms often degrade the perceptual representations of the vision-language
backbone, resulting in overfitting and poor generalization to downstream tasks.
In this work, we present Evo-1, a lightweight VLA model that reduces
computation and improves deployment efficiency, while maintaining strong
performance without pretraining on robot data. Evo-1 builds on a native
multimodal Vision-Language model (VLM), incorporating a novel cross-modulated
diffusion transformer along with an optimized integration module, together
forming an effective architecture. We further introduce a two-stage training
paradigm that progressively aligns action with perception, preserving the
representations of the VLM. Notably, with only 0.77 billion parameters, Evo-1
achieves state-of-the-art results on the Meta-World and RoboTwin suite,
surpassing the previous best models by 12.4% and 6.9%, respectively, and also
attains a competitive result of 94.8% on LIBERO. In real-world evaluations,
Evo-1 attains a 78% success rate with high inference frequency and low memory
overhead, outperforming all baseline methods. We release code, data, and model
weights to facilitate future research on lightweight and efficient VLA models.

</details>


### [139] [SAFe-Copilot: Unified Shared Autonomy Framework](https://arxiv.org/abs/2511.04664)
*Phat Nguyen,Erfan Aasi,Shiva Sreeram,Guy Rosman,Andrew Silva,Sertac Karaman,Daniela Rus*

Main category: cs.RO

TL;DR: 通过利用视觉语言模型(VLM)进行高级推理，提出了一种统一的共享自主框架，以解决自动驾驶系统在罕见或模糊场景下的一​​致性问题。


<details>
  <summary>Details</summary>
Motivation: 自动驾驶系统在罕见、模糊或分布外场景中表现不佳，而人类驾驶员可以通过情境推理成功应对。共享自主性通过在自主性不确定时纳入人类输入来缓解这些问题，但现有方法通常将仲裁限制在低级轨迹，未能保留驾驶意图。

Method: 提出了一种统一的共享自主框架，该框架在更高级别的抽象中整合了人类输入和自主规划器。该方法利用视觉语言模型(VLM)从驾驶员行为和环境背景等多模态线索推断驾驶员意图，并合成人类和自主控制之间的连贯策略。

Result: 在模拟人类环境中，该框架实现了完美的召回率以及高准确率和精确度。人类主题调查显示，参与者在 92% 的情况下同意仲裁结果。在 Bench2Drive 基准测试中的评估表明，与纯自主相比，碰撞率大大降低，整体性能得到提高。

Conclusion: 在语义和基于语言的表示层面进行仲裁是共享自主设计的一个原则，使系统能够运用常识推理并保持与人类意图的一致性。

Abstract: Autonomous driving systems remain brittle in rare, ambiguous, and
out-of-distribution scenarios, where human driver succeed through contextual
reasoning. Shared autonomy has emerged as a promising approach to mitigate such
failures by incorporating human input when autonomy is uncertain. However, most
existing methods restrict arbitration to low-level trajectories, which
represent only geometric paths and therefore fail to preserve the underlying
driving intent. We propose a unified shared autonomy framework that integrates
human input and autonomous planners at a higher level of abstraction. Our
method leverages Vision Language Models (VLMs) to infer driver intent from
multi-modal cues -- such as driver actions and environmental context -- and to
synthesize coherent strategies that mediate between human and autonomous
control. We first study the framework in a mock-human setting, where it
achieves perfect recall alongside high accuracy and precision. A human-subject
survey further shows strong alignment, with participants agreeing with
arbitration outcomes in 92% of cases. Finally, evaluation on the Bench2Drive
benchmark demonstrates a substantial reduction in collision rate and
improvement in overall performance compared to pure autonomy. Arbitration at
the level of semantic, language-based representations emerges as a design
principle for shared autonomy, enabling systems to exercise common-sense
reasoning and maintain continuity with human intent.

</details>


### [140] [Real-to-Sim Robot Policy Evaluation with Gaussian Splatting Simulation of Soft-Body Interactions](https://arxiv.org/abs/2511.04665)
*Kaifeng Zhang,Shuo Sha,Hanxiao Jiang,Matthew Loper,Hyunjong Song,Guangyan Cai,Zhuo Xu,Xiaochen Hu,Changxi Zheng,Yunzhu Li*

Main category: cs.RO

TL;DR: 该研究提出了一个从真实世界视频构建软体数字孪生并使用3D高斯泼溅进行照片级逼真渲染的框架，用于机器人操作策略的仿真评估。


<details>
  <summary>Details</summary>
Motivation: 真实世界中机器人操作策略的评估成本高、耗时长且难以复现，尤其是在处理可变形物体时。现有的仿真器在捕捉软体交互的视觉和物理复杂性方面存在不足。

Method: 使用3D高斯泼溅技术，从真实世界的视频中构建软体数字孪生，并对机器人、物体和环境进行照片级逼真渲染，以实现从真实到仿真的策略评估。

Result: 在抓取毛绒玩具、绳索布线和T形块推动等代表性可变形物体操作任务上进行了验证，结果表明仿真与真实世界执行性能高度相关，并揭示了学习策略的关键行为模式。

Conclusion: 结合物理信息重建和高质量渲染技术，可以实现可复现、可扩展且准确的机器人操作策略评估。

Abstract: Robotic manipulation policies are advancing rapidly, but their direct
evaluation in the real world remains costly, time-consuming, and difficult to
reproduce, particularly for tasks involving deformable objects. Simulation
provides a scalable and systematic alternative, yet existing simulators often
fail to capture the coupled visual and physical complexity of soft-body
interactions. We present a real-to-sim policy evaluation framework that
constructs soft-body digital twins from real-world videos and renders robots,
objects, and environments with photorealistic fidelity using 3D Gaussian
Splatting. We validate our approach on representative deformable manipulation
tasks, including plush toy packing, rope routing, and T-block pushing,
demonstrating that simulated rollouts correlate strongly with real-world
execution performance and reveal key behavioral patterns of learned policies.
Our results suggest that combining physics-informed reconstruction with
high-quality rendering enables reproducible, scalable, and accurate evaluation
of robotic manipulation policies. Website: https://real2sim-eval.github.io/

</details>


### [141] [X-Diffusion: Training Diffusion Policies on Cross-Embodiment Human Demonstrations](https://arxiv.org/abs/2511.04671)
*Maximus A. Pace,Prithwish Dan,Chuanruo Ning,Atiksh Bhardwaj,Audrey Du,Edward W. Duan,Wei-Chiu Ma,Kushal Kedia*

Main category: cs.RO

TL;DR: X-Diffusion框架利用扩散模型处理机器人学习中的人机动作不匹配问题，通过在动作中加入噪声来保留高层任务指导，同时消除低层执行差异，显著提高了机器人任务成功率。


<details>
  <summary>Details</summary>
Motivation: 人类视频数据丰富，但人类与机器人的身体差异导致动作执行不匹配，直接使用可能产生机器人无法完成的动作。

Method: 提出X-Diffusion框架，首先训练一个分类器区分人或机器人执行的带噪声动作，然后仅在加入足够噪声、分类器无法分辨来源后，才将人类动作用于策略训练。低噪声水平下，机器人动作指导精细去噪；高噪声水平下，人类动作提供粗略指导。

Result: 实验表明，X-Diffusion相比基线方法能持续提高策略性能，在五项操作任务中平均成功率提高了16%。

Conclusion: X-Diffusion框架有效利用人类演示数据进行机器人学习，解决了人机动作不匹配导致的动力学不可行性问题，显著提升了机器人任务的成功率。

Abstract: Human videos can be recorded quickly and at scale, making them an appealing
source of training data for robot learning. However, humans and robots differ
fundamentally in embodiment, resulting in mismatched action execution. Direct
kinematic retargeting of human hand motion can therefore produce actions that
are physically infeasible for robots. Despite these low-level differences,
human demonstrations provide valuable motion cues about how to manipulate and
interact with objects. Our key idea is to exploit the forward diffusion
process: as noise is added to actions, low-level execution differences fade
while high-level task guidance is preserved. We present X-Diffusion, a
principled framework for training diffusion policies that maximally leverages
human data without learning dynamically infeasible motions. X-Diffusion first
trains a classifier to predict whether a noisy action is executed by a human or
robot. Then, a human action is incorporated into policy training only after
adding sufficient noise such that the classifier cannot discern its embodiment.
Actions consistent with robot execution supervise fine-grained denoising at low
noise levels, while mismatched human actions provide only coarse guidance at
higher noise levels. Our experiments show that naive co-training under
execution mismatches degrades policy performance, while X-Diffusion
consistently improves it. Across five manipulation tasks, X-Diffusion achieves
a 16% higher average success rate than the best baseline. The project website
is available at https://portal-cornell.github.io/X-Diffusion/.

</details>


### [142] [GentleHumanoid: Learning Upper-body Compliance for Contact-rich Human and Object Interaction](https://arxiv.org/abs/2511.04679)
*Qingzhou Lu,Yao Feng,Baiyu Shi,Michael Piseno,Zhenan Bao,C. Karen Liu*

Main category: cs.RO

TL;DR: 该研究提出了一种名为GentleHumanoid的框架，通过将阻抗控制集成到全身运动跟踪策略中，实现了人形机器人的上半身顺应性，能在与人互动和操作物体时提供安全、自然的物理交互。


<details>
  <summary>Details</summary>
Motivation: 现有强化学习（RL）策略在安全自然的物理交互方面存在不足，多强调刚性跟踪并抑制外部力，而现有的阻抗增强方法通常仅限于基座或末端执行器控制，且侧重于抵抗极端外力而非实现顺应性。

Method: 提出GentleHumanoid框架，将阻抗控制整合到全身运动跟踪策略中。核心是一个统一的基于弹簧的公式，用于模拟阻抗接触（如接触表面时的恢复力）和引导接触（如来自人类运动数据的推拉力）。该公式确保了肩、肘、腕之间力学上的一致性，并通过可调节的任务力阈值来保证安全。

Result: 在仿真和Unitree G1机器人上进行了评估，包括拥抱、辅助站立和安全操作物体等任务。与基线方法相比，GentleHumanoid策略在保持任务成功的同时，一致地降低了峰值接触力，实现了更平滑、更自然的交互。

Conclusion: GentleHumanoid框架在实现人形机器人安全有效地与人类协作以及处理物体方面迈出了重要一步，能够在真实环境中提供安全且自然的物理交互。

Abstract: Humanoid robots are expected to operate in human-centered environments where
safe and natural physical interaction is essential. However, most recent
reinforcement learning (RL) policies emphasize rigid tracking and suppress
external forces. Existing impedance-augmented approaches are typically
restricted to base or end-effector control and focus on resisting extreme
forces rather than enabling compliance. We introduce GentleHumanoid, a
framework that integrates impedance control into a whole-body motion tracking
policy to achieve upper-body compliance. At its core is a unified spring-based
formulation that models both resistive contacts (restoring forces when pressing
against surfaces) and guiding contacts (pushes or pulls sampled from human
motion data). This formulation ensures kinematically consistent forces across
the shoulder, elbow, and wrist, while exposing the policy to diverse
interaction scenarios. Safety is further supported through task-adjustable
force thresholds. We evaluate our approach in both simulation and on the
Unitree G1 humanoid across tasks requiring different levels of compliance,
including gentle hugging, sit-to-stand assistance, and safe object
manipulation. Compared to baselines, our policy consistently reduces peak
contact forces while maintaining task success, resulting in smoother and more
natural interactions. These results highlight a step toward humanoid robots
that can safely and effectively collaborate with humans and handle objects in
real-world environments.

</details>


<div id='cs.LO'></div>

# cs.LO [[Back]](#toc)

### [143] [An Automated Theorem Generator with Theoretical Foundation Based on Rectangular Standard Contradiction](https://arxiv.org/abs/2511.04092)
*Yang Xu,Peiyao Liu,Shuwei Chen,Jun Liu*

Main category: cs.LO

TL;DR: 本篇论文提出了新的自动化定理生成理论和工具，解决了非平凡且逻辑有效的定理生成缺乏严谨理论体系的问题。论文定义并证明了“矩形标准矛盾”这一新的逻辑结构，并基于此构建了完整的自动化定理生成理论。该理论证明了矩形标准矛盾的两个核心性质：其不可满足性（标准矛盾）和非冗余性。通过将矩形标准矛盾划分为前提子集A和其补集的否定H，可以形成有效的定理A ⊢ ¬H，并且所有这些定理在逻辑上都是等价的。为实现该理论，论文设计了一种高效的基于模板的生成算法，并开发了相应的生成器。这项研究使机器能够从“验证者”转变为“发现者”，为逻辑和人工智能领域的基础研究开辟了新途径。


<details>
  <summary>Details</summary>
Motivation: 当前缺乏系统生成非平凡且逻辑有效的定理的严谨理论体系。

Method: 定义并证明了“矩形标准矛盾”逻辑结构，并基于此构建了完整的自动化定理生成理论。利用该结构不可满足和非冗余的性质，将矩形标准矛盾划分为前提子集A和其补集的否定H，形成有效的定理A ⊢ ¬H。设计了基于模板的生成算法，并开发了矩形自动化定理生成器。

Result: 证明了矩形标准矛盾的两个核心性质：不可满足性和非冗余性。实现了自动化定理生成，使机器能够发现定理。

Conclusion: 本研究提出的自动化定理生成理论和工具，利用“矩形标准矛盾”解决了非平凡且逻辑有效的定理生成问题，推动了机器在逻辑和人工智能领域从验证者向发现者的转变。

Abstract: Currently, there is a lack of rigorous theoretical system for systematically
generating non-trivial and logically valid theorems. Addressing this critical
gap, this paper conducts research to propose a novel automated theorem
generation theory and tool. Based on the concept of standard contradiction
which possesses unique deductive advantages, this paper defines and proves, for
the first time, a new logical structure known as rectangular standard
contradiction. Centered on this structure, a complete Automated Theorem
Generation (ATG) theory is put forward. Theoretical proofs clarify two core
properties of rectangular standard contradiction: first, it is a standard
contradiction (necessarily unsatisfiable); second, it exhibits non-redundancy
(the remaining clause set becomes satisfiable after removing any clause).
Leveraging these properties, this paper proves that partitioning a rectangular
standard contradiction into a premise subset $A$ and negation of its complement
$H$, a valid theorem $A \vdash \neg H$ can be formed, and all such theorems are
logically equivalent. To implement this theory, an efficient template-based ATG
algorithm is designed, and a Rectangular Automated Theorem Generator is
developed. This research enables machines to transition from "verifiers" to
"discoverers", opening up new avenues for fundamental research in the fields of
logic and artificial intelligence.

</details>


### [144] [Compact Quantitative Theories of Convex Algebras](https://arxiv.org/abs/2511.04201)
*Matteo Mio*

Main category: cs.LO

TL;DR: We introduce the concept of compact quantitative equational theory, where all consequences are derivable by finite proofs. We show that the theory of interpolative barycentric quantitative algebras is compact, providing a model for other compact theories axiomatizing distances on probability distributions.


<details>
  <summary>Details</summary>
Motivation: The paper introduces the concept of compact quantitative equational theory and demonstrates its application to the theory of interpolative barycentric quantitative algebras.

Method: The method involves defining compact quantitative equational theory and proving that the theory of interpolative barycentric quantitative algebras satisfies this property.

Result: The theory of interpolative barycentric quantitative algebras is proven to be compact. This serves as a model for deriving other compact quantitative equational theories related to convex algebras and distances on probability distributions.

Conclusion: The paper establishes the compactness of the theory of interpolative barycentric quantitative algebras, offering a framework for understanding and constructing other compact theories in this domain.

Abstract: We introduce the concept of compact quantitative equational theory. A
quantitative equational theory is defined to be compact if all its consequences
are derivable by means of finite proofs. We prove that the theory of
interpolative barycentric (also known as convex) quantitative algebras of
Mardare et. al. is compact. This serves as a paradigmatic example, used to
obtain other compact quantitative equational theories of convex algebras, each
axiomatizing some distance on finitely supported probability distributions.

</details>


### [145] [The Size of Interpolants in Modal Logics](https://arxiv.org/abs/2511.04577)
*Balder ten Cate,Louwe Kuijer,Frank Wolter*

Main category: cs.LO

TL;DR: 对于（准）模态逻辑，我们研究了 Craig 插值、均匀插值和最强蕴含式的尺寸界限。对于表格模态逻辑，最强蕴含式的计算可以多项式时间地归约到经典命题逻辑中的均匀插值计算，因此其尺寸是多项式 DAG 尺寸当且仅当 NP $\subseteq$ P$_{/\text{poly}}$。对于具有 Craig 插值性质的表格模态逻辑，此归约也适用于 Craig 插值和均匀插值。我们证明了一个无条件的指数下界，适用于几乎所有非表格标准模态逻辑的 Craig 插值和最强蕴含式。对于包含或被 S4 或 GL 包含的模态逻辑，我们得到了一个二分法：表格逻辑具有“命题尺寸”的插值，而非表格逻辑则存在无条件的指数下界。


<details>
  <summary>Details</summary>
Motivation: 研究（准）模态逻辑中 Craig 插值、均匀插值和最强蕴含式的尺寸界限，并与计算复杂性联系起来。

Method: 推导主要上界和下界，并进行复杂性分析，将模态逻辑的插值问题与经典命题逻辑和 NP 问题的复杂性联系起来。

Result: 对于表格模态逻辑，最强蕴含式的计算可以在多项式时间内归约到经典命题逻辑中的均匀插值计算。对于包含或被 S4 或 GL 包含的模态逻辑，得到了一个二分法：表格逻辑具有多项式尺寸的插值，而非表格逻辑则存在无条件的指数下界。

Conclusion: 模态逻辑的插值尺寸与其是否为表格逻辑以及与 S4/GL 的关系密切相关，并与 NP 问题的复杂性存在联系。

Abstract: We start a systematic investigation of the size of Craig interpolants,
uniform interpolants, and strongest implicates for (quasi-)normal modal logics.
Our main upper bound states that for tabular modal logics, the computation of
strongest implicates can be reduced in polynomial time to uniform interpolant
computation in classical propositional logic. Hence they are of polynomial
dag-size iff NP $\subseteq$ P$_{/\text{poly}}$. The reduction also holds for
Craig interpolants and uniform interpolants if the tabular modal logic has the
Craig interpolation property. Our main lower bound shows an unconditional
exponential lower bound on the size of Craig interpolants and strongest
implicates covering almost all non-tabular standard normal modal logics. For
normal modal logics contained in or containing S4 or GL we obtain the following
dichotomy: tabular logics have ``propositionally sized'' interpolants while for
non-tabular logics an unconditional exponential lower bound holds.

</details>


<div id='cs.ET'></div>

# cs.ET [[Back]](#toc)

### [146] [OpenMENA: An Open-Source Memristor Interfacing and Compute Board for Neuromorphic Edge-AI Applications](https://arxiv.org/abs/2511.03747)
*Ali Safa,Farida Mohsen,Zainab Ali,Bo Wang,Amine Bermak*

Main category: cs.ET

TL;DR: Open-MENA是一个开源的忆阻器内存加速器系统，用于实现节能的边缘AI。它包括硬件接口、固件-软件栈和VIPI编程方法，并已在数字识别和机器人障碍规避任务中得到验证。


<details>
  <summary>Details</summary>
Motivation: 利用忆阻器交叉阵列实现节能的边缘AI。该系统旨在提供一个完整的、可重现的硬件接口、固件-软件栈和编程方法，以支持忆阻器在内存中的乘法累加和局部可塑性学习。

Method: 提出Open-MENA系统，包含（i）可重现的忆阻器交叉阵列硬件接口，支持混合信号读-编程-验证循环；（ii）具有推理和设备端学习高层API的固件-软件栈；（iii）用于将预训练权重编程为模拟电导的电压增量比例-积分（VIPI）方法，以及用于缓解器件非理想性的芯片内环路微调。

Result: Open-MENA在数字识别任务中成功验证了从权重传输到设备端自适应的整个流程。在真实的机器人障碍规避任务中，基于忆阻器的模型学会了将本地化输入映射到电机指令。

Conclusion: Open-MENA是首个完全开源的忆阻器内存接口系统，它支持从头到尾的AI模型部署，包括在设备上的学习和自适应，旨在促进忆阻器赋能的边缘AI研究。

Abstract: Memristive crossbars enable in-memory multiply-accumulate and local
plasticity learning, offering a path to energy-efficient edge AI. To this end,
we present Open-MENA (Open Memristor-in-Memory Accelerator), which, to our
knowledge, is the first fully open memristor interfacing system integrating (i)
a reproducible hardware interface for memristor crossbars with mixed-signal
read-program-verify loops; (ii) a firmware-software stack with high-level APIs
for inference and on-device learning; and (iii) a Voltage-Incremental
Proportional-Integral (VIPI) method to program pre-trained weights into analog
conductances, followed by chip-in-the-loop fine-tuning to mitigate device
non-idealities. OpenMENA is validated on digit recognition, demonstrating the
flow from weight transfer to on-device adaptation, and on a real-world robot
obstacle-avoidance task, where the memristor-based model learns to map
localization inputs to motor commands. OpenMENA is released as open source to
democratize memristor-enabled edge-AI research.

</details>


### [147] [Implementation of transformer-based LLMs with large-scale optoelectronic neurons on a CMOS image sensor platform](https://arxiv.org/abs/2511.04136)
*Neil Na,Chih-Hao Cheng,Shou-Chen Hsu,Che-Fu Liang,Chung-Chih Lin,Nathaniel Y. Na,Andrew I. Shieh,Erik Chen,Haisheng Rong,Richard A. Soref*

Main category: cs.ET

TL;DR: 通过在商用CMOS图像传感器平台上构建新颖的大规模光电器件（OEN），对Transformer模型进行推理，可实现前所未有的速度和能效。


<details>
  <summary>Details</summary>
Motivation: 为了解决大型语言模型（LLM）和人工智能（AI）应用在云端部署导致能耗呈指数级增长的问题。

Method: 在尺寸约为2cm x 3cm的chiplet上，集成了所有必需的光电器件和电子电路，采用40nm CMOS工艺节点，实现了包含1750亿参数的GPT-3模型的推理。

Result: 模型推理速度达到12.6 POPS，能效为74 TOPS/W，面积效率为19 TOPS/mm²，均比现有数字电子方案高两个数量级。同时，研究表明量化格式和硬件误差对结果影响极小。

Conclusion: 提出了一种切实可行的模拟神经处理单元（NPU）新途径，可作为现有数字处理单元的补充。

Abstract: The recent rapid deployment of datacenter infrastructures for performing
large language models (LLMs) and related artificial intelligence (AI)
applications in the clouds is predicted to incur an exponentially growing
energy consumption in the near-term future. In this paper, we propose and
analyze the implementation of the transformer model, which is the cornerstone
of the modern LLMs, with novel large-scale optoelectronic neurons (OENs)
constructed over the commercially available complementary
metal-oxide-semiconductor (CMOS) image sensor (CIS) platform. With all of the
required optoelectronic devices and electronic circuits integrated in a chiplet
only about 2 cm by 3 cm in size, 175 billon parameters in the case of GPT-3 are
shown to perform inference at an unprecedented speed of 12.6 POPS using only a
40 nm CMOS process node, along with a high power efficiency of 74 TOPS/W and a
high area efficiency of 19 TOPS/mm2, both surpassing the related digital
electronics by roughly two orders of magnitude. The influence of the
quantization formats and the hardware induced errors are numerically
investigated, and are shown to have a minimal impact. Our study presents a new
yet practical path toward analog neural processing units (NPUs) to complement
existing digital processing units.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [148] [Scaling Agent Learning via Experience Synthesis](https://arxiv.org/abs/2511.03773)
*Zhaorun Chen,Zhuokai Zhao,Kai Zhang,Bo Liu,Qi Qi,Yifan Wu,Tarun Kalluri,Sara Cao,Yuanhao Xiong,Haibo Tong,Huaxiu Yao,Hengduo Li,Jiacheng Zhu,Xian Li,Dawn Song,Bo Li,Jason Weston,Dat Huynh*

Main category: cs.AI

TL;DR: DreamGym是一个统一的框架，用于合成多样化、可扩展的经验，以实现对自主代理的有效在线强化学习（RL）训练。它通过提炼环境动力学为基于推理的经验模型来克服昂贵的实际环境测试的限制，并通过自适应地生成新任务来增强知识获取。


<details>
  <summary>Details</summary>
Motivation: 在实际应用中，强化学习（RL）虽然能够通过交互实现大型语言模型（LLM）代理的自我提升，但由于成本高昂的测试、任务多样性有限、奖励信号不可靠以及基础设施复杂等问题，难以扩展经验数据的收集。

Method: DreamGym通过将环境动力学提炼成一个基于推理的经验模型来生成状态转换和反馈信号，从而实现可扩展的代理测试收集。它还利用一个包含离线真实世界数据并不断更新的经验回放缓冲区，并自适应地生成具有挑战性的新任务以支持在线课程学习。

Result: DreamGym在完全合成和模拟到现实迁移场景中都显著提高了RL训练的效率。在WebArena等非RL就绪任务上，DreamGym的性能比所有基线高出30%以上。在RL就绪但成本高昂的环境中，它仅使用合成交互就能达到GRPO和PPO的性能。通过纯合成经验训练并在现实环境中进行迁移学习，DreamGym在需要更少现实世界交互的情况下实现了显著的性能提升，为通用RL提供了一种可扩展的启动策略。

Conclusion: DreamGym通过提供一个可扩展的、基于推理的经验合成框架，解决了在线RL训练中的关键挑战，并在各种环境中展示了其有效性，尤其是在模拟到现实迁移方面，为未来的RL研究和应用开辟了道路。

Abstract: While reinforcement learning (RL) can empower large language model (LLM)
agents by enabling self-improvement through interaction, its practical adoption
remains challenging due to costly rollouts, limited task diversity, unreliable
reward signals, and infrastructure complexity, all of which obstruct the
collection of scalable experience data. To address these challenges, we
introduce DreamGym, the first unified framework designed to synthesize diverse
experiences with scalability in mind to enable effective online RL training for
autonomous agents. Rather than relying on expensive real-environment rollouts,
DreamGym distills environment dynamics into a reasoning-based experience model
that derives consistent state transitions and feedback signals through
step-by-step reasoning, enabling scalable agent rollout collection for RL. To
improve the stability and quality of transitions, DreamGym leverages an
experience replay buffer initialized with offline real-world data and
continuously enriched with fresh interactions to actively support agent
training. To improve knowledge acquisition, DreamGym adaptively generates new
tasks that challenge the current agent policy, enabling more effective online
curriculum learning. Experiments across diverse environments and agent
backbones demonstrate that DreamGym substantially improves RL training, both in
fully synthetic settings and in sim-to-real transfer scenarios. On non-RL-ready
tasks like WebArena, DreamGym outperforms all baselines by over 30%. And in
RL-ready but costly settings, it matches GRPO and PPO performance using only
synthetic interactions. When transferring a policy trained purely on synthetic
experiences to real-environment RL, DreamGym yields significant additional
performance gains while requiring far fewer real-world interactions, providing
a scalable warm-start strategy for general-purpose RL.

</details>


### [149] [How Different Tokenization Algorithms Impact LLMs and Transformer Models for Binary Code Analysis](https://arxiv.org/abs/2511.03825)
*Ahmed Mostafa,Raisul Arefin Nahid,Samuel Mulder*

Main category: cs.AI

TL;DR: 本文评估了NLP分词模型在汇编代码分析中的应用，探讨了词汇量大小等参数选择对下游任务（如函数签名预测）的影响，并比较了Llama 3.2、BERT、BART等模型在汇编指令编码和语义捕捉方面的效率。


<details>
  <summary>Details</summary>
Motivation: 汇编代码分析中的分词技术至关重要，但目前研究不足。本研究旨在弥补这一空白，评估NLP分词模型及其参数选择（如词汇量大小）对汇编代码内在特性的影响，并考察其在下游任务中的表现。

Method: 研究了适用于汇编代码的预处理定制选项和预分词规则。使用Llama 3.2、BERT和BART等先进的预训练模型，通过内在评估（如分词效率、词汇压缩、表示保真度）和外在评估（如函数签名预测）来比较不同分词模型的性能。

Result: 初步结果表明，分词器的选择显著影响下游任务的性能。内在指标只能部分预测外在评估结果，揭示了内在分词属性与其在实际汇编代码任务中效用之间的复杂权衡。

Conclusion: 本文为优化低级代码分析的分词模型提供了宝贵的见解，有助于提高基于NLM的二进制分析工作流程的鲁棒性和可扩展性。

Abstract: Tokenization is fundamental in assembly code analysis, impacting intrinsic
characteristics like vocabulary size, semantic coverage, and extrinsic
performance in downstream tasks. Despite its significance, tokenization in the
context of assembly code remains an underexplored area. This study aims to
address this gap by evaluating the intrinsic properties of Natural Language
Processing (NLP) tokenization models and parameter choices, such as vocabulary
size. We explore preprocessing customization options and pre-tokenization rules
tailored to the unique characteristics of assembly code. Additionally, we
assess their impact on downstream tasks like function signature prediction -- a
critical problem in binary code analysis.
  To this end, we conduct a thorough study on various tokenization models,
systematically analyzing their efficiency in encoding assembly instructions and
capturing semantic nuances. Through intrinsic evaluations, we compare
tokenizers based on tokenization efficiency, vocabulary compression, and
representational fidelity for assembly code. Using state-of-the-art pre-trained
models such as the decoder-only Large Language Model (LLM) Llama 3.2, the
encoder-only transformer BERT, and the encoder-decoder model BART, we evaluate
the effectiveness of these tokenizers across multiple performance metrics.
Preliminary findings indicate that tokenizer choice significantly influences
downstream performance, with intrinsic metrics providing partial but incomplete
predictability of extrinsic evaluation outcomes. These results reveal complex
trade-offs between intrinsic tokenizer properties and their utility in
practical assembly code tasks. Ultimately, this study provides valuable
insights into optimizing tokenization models for low-level code analysis,
contributing to the robustness and scalability of Natural Language Model
(NLM)-based binary analysis workflows.

</details>


### [150] [To See or To Read: User Behavior Reasoning in Multimodal LLMs](https://arxiv.org/abs/2511.03845)
*Tianning Dong,Luyi Ma,Varun Vasudevan,Jason Cho,Sushant Kumar,Kannan Achan*

Main category: cs.AI

TL;DR: 图像而非文本能更好地用于 MLLM 对用户行为数据的推理，能将 MLLM 的下一个购买预测准确率提高 87.5%。


<details>
  <summary>Details</summary>
Motivation: 在现代 agentic 系统中，MLLM 在对用户行为序列数据进行推理方面发挥着越来越重要的作用。然而，关于使用文本还是图像来表示用户行为数据对 MLLM 性能影响的研究尚不充分。

Method: 提出了 BehaviorLens，一个系统的基准测试框架，通过将交易数据表示为（1）文本段落、（2）散点图和（3）流程图，评估 MLLM 在用户行为推理中的模态权衡。

Result: 与等效的文本表示相比，当数据表示为图像时，MLLM 的下一个购买预测准确率提高了 87.5%，而没有额外的计算成本。

Conclusion: 图像表示比文本表示更能有效地用于 MLLM 对用户行为数据的推理。

Abstract: Multimodal Large Language Models (MLLMs) are reshaping how modern agentic
systems reason over sequential user-behavior data. However, whether textual or
image representations of user behavior data are more effective for maximizing
MLLM performance remains underexplored. We present \texttt{BehaviorLens}, a
systematic benchmarking framework for assessing modality trade-offs in
user-behavior reasoning across six MLLMs by representing transaction data as
(1) a text paragraph, (2) a scatter plot, and (3) a flowchart. Using a
real-world purchase-sequence dataset, we find that when data is represented as
images, MLLMs next-purchase prediction accuracy is improved by 87.5% compared
with an equivalent textual representation without any additional computational
cost.

</details>


### [151] [KnowThyself: An Agentic Assistant for LLM Interpretability](https://arxiv.org/abs/2511.03878)
*Suraj Prasai,Mengnan Du,Ying Zhang,Fan Yang*

Main category: cs.AI

TL;DR: KnowThyself是一个集成了LLM可解释性工具的聊天机器人，降低了技术门槛，提供了可扩展的平台，并以对话方式呈现结果。


<details>
  <summary>Details</summary>
Motivation: 现有LLM可解释性工具碎片化且需要大量编码，KnowThyself旨在解决这些问题。

Method: KnowThyself的核心是一个LLM协调器，它重组用户查询，并使用代理路由器将查询定向到专用模块，然后将输出进行情境化，形成连贯的解释。

Result: KnowThyself将各种LLM可解释性工具整合到一个聊天界面中，用户可以通过自然语言提问来获得交互式可视化和解释。

Conclusion: KnowThyself通过嵌入对话工作流，为可访问的LLM可解释性提供了坚实的基础。

Abstract: We develop KnowThyself, an agentic assistant that advances large language
model (LLM) interpretability. Existing tools provide useful insights but remain
fragmented and code-intensive. KnowThyself consolidates these capabilities into
a chat-based interface, where users can upload models, pose natural language
questions, and obtain interactive visualizations with guided explanations. At
its core, an orchestrator LLM first reformulates user queries, an agent router
further directs them to specialized modules, and the outputs are finally
contextualized into coherent explanations. This design lowers technical
barriers and provides an extensible platform for LLM inspection. By embedding
the whole process into a conversational workflow, KnowThyself offers a robust
foundation for accessible LLM interpretability.

</details>


### [152] [Extracting Causal Relations in Deep Knowledge Tracing](https://arxiv.org/abs/2511.03948)
*Kevin Hong,Kia Karbasi,Gregory Pottie*

Main category: cs.AI

TL;DR: DKT通过模拟因果关系而非双向关系来预测学生知识。


<details>
  <summary>Details</summary>
Motivation: 挑战DKT通过模拟双向关系来提高预测能力的主流观点，并提出DKT的优势在于其模拟潜在因果结构的能力。

Method: 通过将练习关系图剪枝为有向无环图（DAG），并在Assistments数据集的因果子集上训练DKT，证明DKT的预测能力与因果结构高度一致。此外，提出了一种使用DKT学到的表示来提取练习关系DAG的替代方法。

Result: DKT的预测能力与因果结构高度相关，并且提出的新方法能有效提取练习关系DAG。

Conclusion: DKT的有效性主要源于其模拟潜在因果依赖关系的能力，而非简单的关系映射。

Abstract: A longstanding goal in computational educational research is to develop
explainable knowledge tracing (KT) models. Deep Knowledge Tracing (DKT), which
leverages a Recurrent Neural Network (RNN) to predict student knowledge and
performance on exercises, has been proposed as a major advancement over
traditional KT methods. Several studies suggest that its performance gains stem
from its ability to model bidirectional relationships between different
knowledge components (KCs) within a course, enabling the inference of a
student's understanding of one KC from their performance on others. In this
paper, we challenge this prevailing explanation and demonstrate that DKT's
strength lies in its implicit ability to model prerequisite relationships as a
causal structure, rather than bidirectional relationships. By pruning exercise
relation graphs into Directed Acyclic Graphs (DAGs) and training DKT on causal
subsets of the Assistments dataset, we show that DKT's predictive capabilities
align strongly with these causal structures. Furthermore, we propose an
alternative method for extracting exercise relation DAGs using DKT's learned
representations and provide empirical evidence supporting our claim. Our
findings suggest that DKT's effectiveness is largely driven by its capacity to
approximate causal dependencies between KCs rather than simple relational
mappings.

</details>


### [153] [LLMs and Cultural Values: the Impact of Prompt Language and Explicit Cultural Framing](https://arxiv.org/abs/2511.03980)
*Bram Bulté,Ayla Rigouts Terryn*

Main category: cs.AI

TL;DR: LLMs在文化多样性方面存在偏差，即使在有针对性的提示下，也无法充分代表不同国家的文化价值观，并且模型表现出相似的偏见。


<details>
  <summary>Details</summary>
Motivation: 评估LLM在不同语言和文化背景下处理文化价值的能.力，并研究提示语言和文化框架如何影响模型响应及其与人类价值观的一致性。

Method: 使用63个项目（来自Hofstede价值观调查模块和世界价值观调查）探测10个LLM，这些项目被翻译成11种语言，并以带或不带不同明确文化观点的提示形式提出。

Result: LLM响应会受到提示语言和文化观点的双重影响。虽然有针对性的提示可以在一定程度上引导LLM响应朝着目标国家的主要价值观发展，但无法克服模型对少数几个国家（荷兰、德国、美国、日本）价值观的系统性偏见。所有模型都表现出相似的模式，大多数主题的响应相当中立，但在诸如社会宽容等问题上则有选择性地采取进步立场。明确的文化观点比目标提示语言更能提高与人类受访者文化价值观的一致性。将两者结合的效力并不比仅使用英语提示和文化框架更优。

Conclusion: LLM对提示的变化具有足够的响应能力，可以产生差异，但其固定的文化默认值又使其无法充分代表文化多样性。

Abstract: Large Language Models (LLMs) are rapidly being adopted by users across the
globe, who interact with them in a diverse range of languages. At the same
time, there are well-documented imbalances in the training data and
optimisation objectives of this technology, raising doubts as to whether LLMs
can represent the cultural diversity of their broad user base. In this study,
we look at LLMs and cultural values and examine how prompt language and
cultural framing influence model responses and their alignment with human
values in different countries. We probe 10 LLMs with 63 items from the Hofstede
Values Survey Module and World Values Survey, translated into 11 languages, and
formulated as prompts with and without different explicit cultural
perspectives. Our study confirms that both prompt language and cultural
perspective produce variation in LLM outputs, but with an important caveat:
While targeted prompting can, to a certain extent, steer LLM responses in the
direction of the predominant values of the corresponding countries, it does not
overcome the models' systematic bias toward the values associated with a
restricted set of countries in our dataset: the Netherlands, Germany, the US,
and Japan. All tested models, regardless of their origin, exhibit remarkably
similar patterns: They produce fairly neutral responses on most topics, with
selective progressive stances on issues such as social tolerance. Alignment
with cultural values of human respondents is improved more with an explicit
cultural perspective than with a targeted prompt language. Unexpectedly,
combining both approaches is no more effective than cultural framing with an
English prompt. These findings reveal that LLMs occupy an uncomfortable middle
ground: They are responsive enough to changes in prompts to produce variation,
but too firmly anchored to specific cultural defaults to adequately represent
cultural diversity.

</details>


### [154] [Large language models replicate and predict human cooperation across experiments in game theory](https://arxiv.org/abs/2511.04500)
*Andrea Cera Palatsi,Samuel Martin-Gutierrez,Ana S. Cardenal,Max Pellert*

Main category: cs.AI

TL;DR: 大型语言模型（LLMs）在决策和模拟人类行为方面的能力有待进一步理解。本研究开发了一个游戏理论实验的数字孪生，并引入了一个系统性的提示和探测框架来评估它们的行为。


<details>
  <summary>Details</summary>
Motivation: 研究大型语言模型（LLMs）在决策和模拟人类行为方面的表现，理解其与人类行为的一致性，以避免在实际应用中产生有害后果，并提高其在社会模拟中的有效性。

Method: 开发了一个游戏理论实验的数字孪生，并引入了一个系统性的提示和探测框架，测试了Llama、Mistral和Qwen三个开源模型，在不使用基于角色的提示的情况下，实现了人口层面的行为复制。

Result: Llama模型能够高保真地复制人类的合作模式，并捕捉到人类在偏离理性选择理论时的行为。Qwen模型则与纳什均衡预测高度一致。研究还生成并预注册了针对新颖游戏配置的、可检验的假设。

Conclusion: 经过适当校准的大型语言模型（LLMs）能够复制人类行为的总体模式，并促进对未探索实验空间的系统性探索，为社会和行为科学的传统研究提供了一种补充方法，并能对人类社会决策产生新的实证预测。

Abstract: Large language models (LLMs) are increasingly used both to make decisions in
domains such as health, education and law, and to simulate human behavior. Yet
how closely LLMs mirror actual human decision-making remains poorly understood.
This gap is critical: misalignment could produce harmful outcomes in practical
applications, while failure to replicate human behavior renders LLMs
ineffective for social simulations. Here, we address this gap by developing a
digital twin of game-theoretic experiments and introducing a systematic
prompting and probing framework for machine-behavioral evaluation. Testing
three open-source models (Llama, Mistral and Qwen), we find that Llama
reproduces human cooperation patterns with high fidelity, capturing human
deviations from rational choice theory, while Qwen aligns closely with Nash
equilibrium predictions. Notably, we achieved population-level behavioral
replication without persona-based prompting, simplifying the simulation
process. Extending beyond the original human-tested games, we generate and
preregister testable hypotheses for novel game configurations outside the
original parameter grid. Our findings demonstrate that appropriately calibrated
LLMs can replicate aggregate human behavioral patterns and enable systematic
exploration of unexplored experimental spaces, offering a complementary
approach to traditional research in the social and behavioral sciences that
generates new empirical predictions about human social decision-making.

</details>


### [155] [ArchPilot: A Proxy-Guided Multi-Agent Approach for Machine Learning Engineering](https://arxiv.org/abs/2511.03985)
*Zhuowen Yuan,Tao Liu,Yang Yang,Yang Wang,Feng Qi,Kaushik Rangadurai,Bo Li,Shuang Yang*

Main category: cs.AI

TL;DR: ArchPilot是一个多智能体系统，通过代理评估和自适应搜索，解决了现有基于LLM的自动化机器学习工程方法中计算开销大、可扩展性差和迭代周期慢的问题。


<details>
  <summary>Details</summary>
Motivation: 现有的基于LLM的代理在自动化机器学习工程方面虽然能力很强，但由于需要反复进行完整的训练来评估候选方案，导致计算成本高、可扩展性差且迭代周期长。

Method: ArchPilot是一个多智能体系统，包含一个协调搜索过程的编排智能体（使用受MCTS启发的算法并包含重启机制和记忆功能）、一个迭代生成、改进和调试候选架构的生成智能体，以及一个执行代理训练、生成和优化代理函数并将代理分数聚合成保真度感知性能指标的评估智能体。

Result: 在MLE-Bench上的实验表明，ArchPilot的性能优于AIDE和ML-Master等SOTA基线。

Conclusion: ArchPilot通过其多智能体协作，优先考虑高潜力的候选方案，并减少对昂贵的完整训练运行的依赖，从而在有限的预算下实现高效的机器学习工程。

Abstract: Recent LLM-based agents have demonstrated strong capabilities in automated ML
engineering. However, they heavily rely on repeated full training runs to
evaluate candidate solutions, resulting in significant computational overhead,
limited scalability to large search spaces, and slow iteration cycles. To
address these challenges, we introduce ArchPilot, a multi-agent system that
integrates architecture generation, proxy-based evaluation, and adaptive search
into a unified framework. ArchPilot consists of three specialized agents: an
orchestration agent that coordinates the search process using a Monte Carlo
Tree Search (MCTS)-inspired novel algorithm with a restart mechanism and
manages memory of previous candidates; a generation agent that iteratively
generates, improves, and debugs candidate architectures; and an evaluation
agent that executes proxy training runs, generates and optimizes proxy
functions, and aggregates the proxy scores into a fidelity-aware performance
metric. This multi-agent collaboration allows ArchPilot to prioritize
high-potential candidates with minimal reliance on expensive full training
runs, facilitating efficient ML engineering under limited budgets. Experiments
on MLE-Bench demonstrate that ArchPilot outperforms SOTA baselines such as AIDE
and ML-Master, validating the effectiveness of our multi-agent system.

</details>


### [156] [When Empowerment Disempowers](https://arxiv.org/abs/2511.04177)
*Claire Yang,Maya Cakmak,Max Kleiman-Weiner*

Main category: cs.AI

TL;DR: 在多人类环境中，以一个人的赋权为目标的AI代理可能会剥夺另一个人的权力。


<details>
  <summary>Details</summary>
Motivation: 赋权被提议作为AI代理激励辅助行为的通用目标无关目标。然而，先前关于基于赋权的工作假设代理单独协助一个人。在多人类环境中，如家庭和医院，AI辅助有很大潜力，但现有的基于赋权的方法可能会导致“去赋权”现象。

Method: 作者引入了一个开源的多人类gridworld测试套件Disempower-Grid，并使用它来实证研究赋权代理在多人类环境中的行为。他们分析了去赋权现象发生的条件，并研究了联合赋权策略，以及它对用户奖励的影响。

Result: 研究表明，优化一个人类的赋权会显著减少另一个人类的环境影响和奖励，即“去赋权”。联合赋权可以缓解去赋权，但会降低用户的奖励。

Conclusion: 这项工作揭示了AI对齐社区面临的一个更广泛的挑战：在单智能体设置中看似一致的目标无关目标，在多智能体环境中可能会变得不一致。

Abstract: Empowerment, a measure of an agent's ability to control its environment, has
been proposed as a universal goal-agnostic objective for motivating assistive
behavior in AI agents. While multi-human settings like homes and hospitals are
promising for AI assistance, prior work on empowerment-based assistance assumes
that the agent assists one human in isolation. We introduce an open source
multi-human gridworld test suite Disempower-Grid. Using Disempower-Grid, we
empirically show that assistive RL agents optimizing for one human's
empowerment can significantly reduce another human's environmental influence
and rewards - a phenomenon we formalize as disempowerment. We characterize when
disempowerment occurs in these environments and show that joint empowerment
mitigates disempowerment at the cost of the user's reward. Our work reveals a
broader challenge for the AI alignment community: goal-agnostic objectives that
seem aligned in single-agent settings can become misaligned in multi-agent
contexts.

</details>


### [157] [Detecting Silent Failures in Multi-Agentic AI Trajectories](https://arxiv.org/abs/2511.04032)
*Divya Pathak,Harshit Kumar,Anuska Roy,Felix George,Mudit Verma,Pratibha Moogi*

Main category: cs.AI

TL;DR: LLM驱动的多智能体AI系统存在固有的非确定性和易发生静默故障（如漂移、循环、细节缺失），且难以检测。本研究引入了智能体轨迹异常检测任务来识别这些故障，并提出了一个数据集创建流程，该流程能捕捉用户行为、智能体非确定性和LLM变异性。利用此流程，我们创建并标注了两个包含来自多智能体AI系统的4,275和894个轨迹的基准数据集。对这些数据集的异常检测方法进行基准测试表明，监督学习（XGBoost）和半监督学习（SVDD）方法表现相当，准确率分别高达98%和96%。本研究为多智能体AI系统中的异常检测提供了首次系统性研究，包括数据集、基准和见解，以指导未来研究。


<details>
  <summary>Details</summary>
Motivation: 开发用于检测多智能体AI系统（尤其是由LLM驱动的系统）中固有非确定性和静默故障（如漂移、循环、细节缺失）的方法，因为这些故障难以察觉。

Method: 1. 提出一个数据集创建流程，用于捕获用户行为、智能体非确定性和LLM变异性。
2. 利用该流程创建并标注了两个包含4,275和894个轨迹的基准数据集。
3. 在创建的数据集上对异常检测方法进行基准测试，包括监督学习（XGBoost）和半监督学习（SVDD）方法。

Result: 监督学习（XGBoost）和半监督学习（SVDD）方法在多智能体AI系统轨迹异常检测任务上表现相当，准确率分别高达98%和96%。

Conclusion: 本研究首次系统性地研究了多智能体AI系统中的异常检测问题，提供了数据集、基准测试和相关见解，为该领域未来的研究奠定了基础。

Abstract: Multi-Agentic AI systems, powered by large language models (LLMs), are
inherently non-deterministic and prone to silent failures such as drift,
cycles, and missing details in outputs, which are difficult to detect. We
introduce the task of anomaly detection in agentic trajectories to identify
these failures and present a dataset curation pipeline that captures user
behavior, agent non-determinism, and LLM variation. Using this pipeline, we
curate and label two benchmark datasets comprising \textbf{4,275 and 894}
trajectories from Multi-Agentic AI systems. Benchmarking anomaly detection
methods on these datasets, we show that supervised (XGBoost) and
semi-supervised (SVDD) approaches perform comparably, achieving accuracies up
to 98% and 96%, respectively. This work provides the first systematic study of
anomaly detection in Multi-Agentic AI systems, offering datasets, benchmarks,
and insights to guide future research.

</details>


### [158] [Interpreting Multi-Attribute Confounding through Numerical Attributes in Large Language Models](https://arxiv.org/abs/2511.04053)
*Hirohane Takagi,Gouki Minegishi,Shota Kizawa,Issey Sukeda,Hitomi Yanaka*

Main category: cs.AI

TL;DR: LLMs在处理数字时会放大现实世界的数字相关性，并且无关的数字信息会影响其输出，这种影响因模型大小而异。


<details>
  <summary>Details</summary>
Motivation: 理解大型语言模型（LLMs）在数值推理中出现错误的具体原因，特别是其内部表征机制。

Method: 结合线性探测、偏相关分析以及基于提示的易受攻击性测试，并跨不同大小的模型进行实验。

Result: LLMs会编码并系统地放大现实世界的数字相关性；无关的数字上下文会引起其数值表征的系统性变化，且这种变化对下游输出的影响因模型大小而异。

Conclusion: LLMs在决策中存在固有漏洞，其对多属性的表征纠缠不清，这为未来开发更公平、更具表征意识的控制机制奠定了基础。

Abstract: Although behavioral studies have documented numerical reasoning errors in
large language models (LLMs), the underlying representational mechanisms remain
unclear. We hypothesize that numerical attributes occupy shared latent
subspaces and investigate two questions:(1) How do LLMs internally integrate
multiple numerical attributes of a single entity? (2)How does irrelevant
numerical context perturb these representations and their downstream outputs?
To address these questions, we combine linear probing with partial correlation
analysis and prompt-based vulnerability tests across models of varying sizes.
Our results show that LLMs encode real-world numerical correlations but tend to
systematically amplify them. Moreover, irrelevant context induces consistent
shifts in magnitude representations, with downstream effects that vary by model
size. These findings reveal a vulnerability in LLM decision-making and lay the
groundwork for fairer, representation-aware control under multi-attribute
entanglement.

</details>


### [159] [Agentmandering: A Game-Theoretic Framework for Fair Redistricting via Large Language Model Agents](https://arxiv.org/abs/2511.04076)
*Hao Li,Haotian Chen,Ruoyuan Gong,Juanjuan Wang,Hao Jiang*

Main category: cs.AI

TL;DR: 该研究提出了一种名为Agentmandering的新型re-districting框架，通过引入博弈论和大型语言模型（LLM）代理，模拟两个对立政治利益之间的回合制谈判，以生成更公平、更稳定的选区划分方案。


<details>
  <summary>Details</summary>
Motivation: 现有的计算方法在生成选区划分方案时，往往忽略了选区选择过程中的策略性动态，可能被党派操纵以获取政治优势。现有方法仅满足形式约束，但不能保证公平性，因为选区选择过程本身可能被操纵。

Method: Agentmandering将re-districting视为一个回合制谈判过程，由代表对立政治利益的两个代理（LLM驱动）执行。代理轮流从一组候选地图中选择并冻结区域，通过约束和可解释的选择逐步划分州。

Result: 在后2020年美国人口普查数据评估中，Agentmandering在所有州都显著降低了党派偏见和不公平性，并且与标准基线相比，方差降低了2到3个数量级。

Conclusion: Agentmandering方法在生成选区划分方案时，能够同时实现公平性和稳定性，尤其在摇摆州场景下表现突出。

Abstract: Redistricting plays a central role in shaping how votes are translated into
political power. While existing computational methods primarily aim to generate
large ensembles of legally valid districting plans, they often neglect the
strategic dynamics involved in the selection process. This oversight creates
opportunities for partisan actors to cherry-pick maps that, while technically
compliant, are politically advantageous. Simply satisfying formal constraints
does not ensure fairness when the selection process itself can be manipulated.
We propose \textbf{Agentmandering}, a framework that reimagines redistricting
as a turn-based negotiation between two agents representing opposing political
interests. Drawing inspiration from game-theoretic ideas, particularly the
\textit{Choose-and-Freeze} protocol, our method embeds strategic interaction
into the redistricting process via large language model (LLM) agents. Agents
alternate between selecting and freezing districts from a small set of
candidate maps, gradually partitioning the state through constrained and
interpretable choices. Evaluation on post-2020 U.S. Census data across all
states shows that Agentmandering significantly reduces partisan bias and
unfairness, while achieving 2 to 3 orders of magnitude lower variance than
standard baselines. These results demonstrate both fairness and stability,
especially in swing-state scenarios. Our code is available at
https://github.com/Lihaogx/AgentMandering.

</details>


### [160] [KGFR: A Foundation Retriever for Generalized Knowledge Graph Question Answering](https://arxiv.org/abs/2511.04093)
*Yuanning Cui,Zequn Sun,Wei Hu,Zhangjie Fu*

Main category: cs.AI

TL;DR: LLM-KGFR框架通过结合LLM和知识图谱检索器(KGFR)，解决了LLM在知识密集型问题中的局限性，实现了对未见过知识图谱的零样本泛化和对大型图谱的高效处理。


<details>
  <summary>Details</summary>
Motivation: 现有的LLM或GNN检索方法在处理知识密集型问题时，因数据集特定调优和在大规模或未见过图谱上的可扩展性受限。

Method: 提出LLM-KGFR框架，其中KGFR使用LLM生成的描述来编码关系并基于实体在问题中的作用来初始化实体，以实现对未见过知识图谱的零样本泛化。采用非对称渐进式传播（APP）策略来高效处理大型图谱。LLM通过节点、边和路径级别的接口迭代地请求候选答案、支持事实和推理路径，形成一个可控的推理循环。

Result: LLM-KGFR在保持可扩展性和泛化能力的同时，实现了强大的性能。

Conclusion: LLM-KGFR为知识图谱增强推理提供了一个实用的解决方案。

Abstract: Large language models (LLMs) excel at reasoning but struggle with
knowledge-intensive questions due to limited context and parametric knowledge.
However, existing methods that rely on finetuned LLMs or GNN retrievers are
limited by dataset-specific tuning and scalability on large or unseen graphs.
We propose the LLM-KGFR collaborative framework, where an LLM works with a
structured retriever, the Knowledge Graph Foundation Retriever (KGFR). KGFR
encodes relations using LLM-generated descriptions and initializes entities
based on their roles in the question, enabling zero-shot generalization to
unseen KGs. To handle large graphs efficiently, it employs Asymmetric
Progressive Propagation (APP)- a stepwise expansion that selectively limits
high-degree nodes while retaining informative paths. Through node-, edge-, and
path-level interfaces, the LLM iteratively requests candidate answers,
supporting facts, and reasoning paths, forming a controllable reasoning loop.
Experiments demonstrate that LLM-KGFR achieves strong performance while
maintaining scalability and generalization, providing a practical solution for
KG-augmented reasoning.

</details>


### [161] [DR. WELL: Dynamic Reasoning and Learning with Symbolic World Model for Embodied LLM-Based Multi-Agent Collaboration](https://arxiv.org/abs/2511.04646)
*Narjes Nourzad,Hanqing Yang,Shiyu Chen,Carlee Joe-Wong*

Main category: cs.AI

TL;DR: DR. WELL是一个去中心化的多智能体规划框架，通过两阶段的协商协议实现合作。


<details>
  <summary>Details</summary>
Motivation: 传统的轨迹层面协调容易因细微偏差导致冲突，需要更高级别的抽象来解决。DR. WELL旨在通过引入符号规划来解决这一挑战。

Method: DR. WELL采用两阶段协商协议：首先，智能体提出带有推理过程的候选角色；然后，在达成共识和满足环境约束的条件下，承诺角色分配。之后，每个智能体独立生成和执行其角色的符号规划，并通过共享的世界模型进行对齐，该模型会随着智能体的动作而更新。

Result: 在合作推箱子任务的实验中，DR. WELL展示了智能体的跨回合适应能力。动态世界模型能够捕捉可复用的模式，并提高任务完成率和效率。该模型通过协商和自我完善，以时间开销为代价，实现了更高效的协作策略。

Conclusion: DR. WELL通过符号规划而非原始轨迹，避免了脆弱的步进对齐，实现了可重用、可同步和可解释的高层操作，有效提高了多智能体合作规划的效率和鲁棒性。

Abstract: Cooperative multi-agent planning requires agents to make joint decisions with
partial information and limited communication. Coordination at the trajectory
level often fails, as small deviations in timing or movement cascade into
conflicts. Symbolic planning mitigates this challenge by raising the level of
abstraction and providing a minimal vocabulary of actions that enable
synchronization and collective progress. We present DR. WELL, a decentralized
neurosymbolic framework for cooperative multi-agent planning. Cooperation
unfolds through a two-phase negotiation protocol: agents first propose
candidate roles with reasoning and then commit to a joint allocation under
consensus and environment constraints. After commitment, each agent
independently generates and executes a symbolic plan for its role without
revealing detailed trajectories. Plans are grounded in execution outcomes via a
shared world model that encodes the current state and is updated as agents act.
By reasoning over symbolic plans rather than raw trajectories, DR. WELL avoids
brittle step-level alignment and enables higher-level operations that are
reusable, synchronizable, and interpretable. Experiments on cooperative
block-push tasks show that agents adapt across episodes, with the dynamic world
model capturing reusable patterns and improving task completion rates and
efficiency. Experiments on cooperative block-push tasks show that our dynamic
world model improves task completion and efficiency through negotiation and
self-refinement, trading a time overhead for evolving, more efficient
collaboration strategies.

</details>


### [162] [Testing the Testers: Human-Driven Quality Assessment of Voice AI Testing Platforms](https://arxiv.org/abs/2511.04133)
*Miguel E. Andres,Vadim Fedorov,Rida Sadek,Enric Spagnolo-Arrizabalaga,Nadescha Trudel*

Main category: cs.AI

TL;DR: 本文提出了一个系统性的框架，通过以人为中心的基准测试来评估语音 AI 测试质量，解决了测试平台在生成真实测试对话和评估代理响应方面的挑战。


<details>
  <summary>Details</summary>
Motivation: 随着语音 AI 的规模不断扩大，目前缺乏系统性的方法来确保测试的可靠性，导致无法客观评估测试方法的有效性。

Method: 该框架结合了心理测量技术（如成对比较、Elo 评分、bootstrap 置信区间和置换检验）以及严格的统计验证，以提供可应用于任何测试方法的、可复现的指标。

Result: 通过对三个领先的商业语音 AI 测试平台进行的大规模实证评估，发现不同平台之间存在显著的性能差异。其中，Evalion 在评估质量方面（F1 分数）达到了 0.92，模拟质量方面（基于联盟的评分系统，包含平局）达到了 0.61，而其他平台在这两项指标上的得分分别为 0.73 和 0.43。

Conclusion: 该框架使研究人员和组织能够实证验证任何测试平台的能力，为语音 AI 的大规模部署提供了必要的测量基础，并提供了支持材料以促进可复现性和采用。

Abstract: Voice AI agents are rapidly transitioning to production deployments, yet
systematic methods for ensuring testing reliability remain underdeveloped.
Organizations cannot objectively assess whether their testing approaches
(internal tools or external platforms) actually work, creating a critical
measurement gap as voice AI scales to billions of daily interactions.
  We present the first systematic framework for evaluating voice AI testing
quality through human-centered benchmarking. Our methodology addresses the
fundamental dual challenge of testing platforms: generating realistic test
conversations (simulation quality) and accurately evaluating agent responses
(evaluation quality). The framework combines established psychometric
techniques (pairwise comparisons yielding Elo ratings, bootstrap confidence
intervals, and permutation tests) with rigorous statistical validation to
provide reproducible metrics applicable to any testing approach.
  To validate the framework and demonstrate its utility, we conducted
comprehensive empirical evaluation of three leading commercial platforms
focused on Voice AI Testing using 21,600 human judgments across 45 simulations
and ground truth validation on 60 conversations. Results reveal statistically
significant performance differences with the proposed framework, with the
top-performing platform, Evalion, achieving 0.92 evaluation quality measured as
f1-score versus 0.73 for others, and 0.61 simulation quality using a league
based scoring system (including ties) vs 0.43 for other platforms.
  This framework enables researchers and organizations to empirically validate
the testing capabilities of any platform, providing essential measurement
foundations for confident voice AI deployment at scale. Supporting materials
are made available to facilitate reproducibility and adoption.

</details>


### [163] [Opus: A Quantitative Framework for Workflow Evaluation](https://arxiv.org/abs/2511.04220)
*Alan Seroul,Théo Fagnoni,Inès Adnani,Dana O. Mohamed,Phillip Kingston*

Main category: cs.AI

TL;DR: 该框架提供了一个概率规范化模型来量化工作流的质量和效率，通过结合奖励和惩罚机制，实现工作流的自动化评估、排名和优化。


<details>
  <summary>Details</summary>
Motivation: 为了量化工作流的质量和效率，并实现其的直接比较、评分和优化。

Method: 提出Opus工作流评估框架，该框架包含Opus工作流奖励（概率函数，估计成功率、资源利用率和输出增益）和Opus工作流规范化惩罚（捕捉内聚性、耦合性、可观测性和信息卫生结构化和信息质量的可衡量函数）。

Result: 实现了自动化工作流评估、排名和优化，并提出了一种统一的优化公式，用于在奖励-惩罚权衡下识别和排名最优工作流。

Conclusion: Opus工作流评估框架能够对工作流进行量化评估，并通过优化实现工作流的改进。

Abstract: This paper introduces the Opus Workflow Evaluation Framework, a
probabilistic-normative formulation for quantifying Workflow quality and
efficiency. It integrates notions of correctness, reliability, and cost into a
coherent mathematical model that enables direct comparison, scoring, and
optimization of Workflows. The framework combines the Opus Workflow Reward, a
probabilistic function estimating expected performance through success
likelihood, resource usage, and output gain, with the Opus Workflow Normative
Penalties, a set of measurable functions capturing structural and informational
quality across Cohesion, Coupling, Observability, and Information Hygiene. It
supports automated Workflow assessment, ranking, and optimization within modern
automation systems such as Opus and can be integrated into Reinforcement
Learning loops to guide Workflow discovery and refinement. In this paper, we
introduce the Opus Workflow Reward model that formalizes Workflow success as a
probabilistic expectation over costs and outcomes. We define measurable Opus
Workflow Normative Penalties capturing structural, semantic, and signal-related
properties of Workflows. Finally, we propose a unified optimization formulation
for identifying and ranking optimal Workflows under joint Reward-Penalty
trade-offs.

</details>


### [164] [Shared Spatial Memory Through Predictive Coding](https://arxiv.org/abs/2511.04235)
*Zhengru Fang,Yu Guo,Jingjing Wang,Yuang Zhang,Haonan An,Yinhai Wang,Yuguang Fang*

Main category: cs.AI

TL;DR: 该框架通过最小化智能体间的互信息不确定性来解决多智能体系统的协调问题，提出了一个多智能体预测编码框架，并利用信息瓶颈原则来优化通信。


<details>
  <summary>Details</summary>
Motivation: 在多智能体系统中，部分可观察性和有限带宽常常导致协调失败。因此，需要一种能够共享和重建一致空间记忆的机制。

Method: 提出了一种多智能体预测编码框架，将协调视为最小化智能体间互信息不确定性的过程。该框架利用信息瓶颈原则来确定通信内容和时机，并引入了类似网格细胞的度量作为内部空间编码，通过自我监督运动预测自发产生。在此基础上，智能体发展出一种带宽高效的通信机制和专门的神经元群体，用于编码伙伴的位置（模拟海马体社会位置细胞）。最后，通过分层强化学习策略来减少联合不确定性。

Result: 在Memory-Maze基准测试中，该方法在带宽限制下表现出卓越的鲁棒性。当带宽从128 bits/step减少到4 bits/step时，成功率仅从73.5%下降到64.4%，而全广播基线则从67.6%骤降至28.6%。

Conclusion: 该研究为复杂社会表征如何从统一的预测驱动中涌现提供了理论上合理且生物学上可行的基础，并最终实现了社会集体智能。

Abstract: Sharing and reconstructing a consistent spatial memory is a critical
challenge in multi-agent systems, where partial observability and limited
bandwidth often lead to catastrophic failures in coordination. We introduce a
multi-agent predictive coding framework that formulate coordination as the
minimization of mutual uncertainty among agents. Instantiated as an information
bottleneck objective, it prompts agents to learn not only who and what to
communicate but also when. At the foundation of this framework lies a
grid-cell-like metric as internal spatial coding for self-localization,
emerging spontaneously from self-supervised motion prediction. Building upon
this internal spatial code, agents gradually develop a bandwidth-efficient
communication mechanism and specialized neural populations that encode
partners' locations: an artificial analogue of hippocampal social place cells
(SPCs). These social representations are further enacted by a hierarchical
reinforcement learning policy that actively explores to reduce joint
uncertainty. On the Memory-Maze benchmark, our approach shows exceptional
resilience to bandwidth constraints: success degrades gracefully from 73.5% to
64.4% as bandwidth shrinks from 128 to 4 bits/step, whereas a full-broadcast
baseline collapses from 67.6% to 28.6%. Our findings establish a theoretically
principled and biologically plausible basis for how complex social
representations emerge from a unified predictive drive, leading to social
collective intelligence.

</details>


### [165] [RLoop: An Self-Improving Framework for Reinforcement Learning with Iterative Policy Initialization](https://arxiv.org/abs/2511.04285)
*Zeng Zhiyuan,Jiashuo Liu,Zhangyue Yin,Ge Zhang,Wenhao Huang,Xipeng Qiu*

Main category: cs.AI

TL;DR: RLoop框架通过迭代策略初始化来解决RLVR中的RL过拟合问题，通过结合探索和利用，提高了模型的泛化能力。


<details>
  <summary>Details</summary>
Motivation: RLVR在训练大型推理模型时存在RL过拟合的挑战，即模型在训练中获得高奖励但泛化能力下降。这主要是由于策略过度专业化和遗忘训练过程中产生的多样化解决方案。

Method: RLoop框架通过迭代策略初始化来解决RL过拟合问题。它首先使用RL探索解决方案空间，然后过滤成功轨迹以创建专家数据集，并通过拒绝采样微调（RFT）来优化初始策略，为下一轮迭代提供更好的起点。

Result: 实验表明，RLoop能够缓解遗忘问题，显著提高泛化能力，与标准的RL相比，平均准确率提高了9%，pass@32提高了15%以上。

Conclusion: RLoop通过将标准训练过程转化为一个良性循环，有效地将短暂的策略变化转化为稳健的性能提升，解决了RLVR中的RL过拟合问题。

Abstract: While Reinforcement Learning for Verifiable Rewards (RLVR) is powerful for
training large reasoning models, its training dynamics harbor a critical
challenge: RL overfitting, where models gain training rewards but lose
generalization. Our analysis reveals this is driven by policy
over-specialization and catastrophic forgetting of diverse solutions generated
during training. Standard optimization discards this valuable inter-step policy
diversity. To address this, we introduce RLoop, a self-improving framework
built on iterative policy initialization. RLoop transforms the standard
training process into a virtuous cycle: it first uses RL to explore the
solution space from a given policy, then filters the successful trajectories to
create an expert dataset. This dataset is used via Rejection-sampling
Fine-Tuning (RFT) to refine the initial policy, creating a superior starting
point for the next iteration. This loop of exploration and exploitation via
iterative re-initialization effectively converts transient policy variations
into robust performance gains. Our experiments show RLoop mitigates forgetting
and substantially improves generalization, boosting average accuracy by 9% and
pass@32 by over 15% compared to vanilla RL.

</details>


### [166] [GUI-360: A Comprehensive Dataset and Benchmark for Computer-Using Agents](https://arxiv.org/abs/2511.04307)
*Jian Mu,Chaoyun Zhang,Chiming Ni,Lu Wang,Bo Qiao,Kartik Mathur,Qianhui Wu,Yuhang Xie,Xiaojun Ma,Mengyu Zhou,Si Qin,Liqun Li,Yu Kang,Minghua Ma,Qingwei Lin,Saravan Rajmohan,Dongmei Zhang*

Main category: cs.AI

TL;DR: 该研究提出了GUI-360°，一个大规模数据集和基准测试套件，旨在解决计算机使用代理（CUAs）在真实世界任务、多模态轨迹自动化收集和标注以及统一基准测试方面的挑战。


<details>
  <summary>Details</summary>
Motivation: CUAs面临着真实世界任务稀缺、多模态轨迹自动化收集和标注困难以及缺乏统一的GUI基础、屏幕解析和动作预测联合评估基准等挑战。

Method: GUI-360°使用了一个LLM增强的、大部分自动化的流程，包括查询来源、环境模板构建、任务实例化、批量执行和LLM驱动的质量过滤。该数据集包含超过120万个执行的动作步，涵盖了数千个在流行的Windows办公应用程序中的轨迹，并提供了全分辨率截图、辅助元数据、实例化目标、中间推理痕迹以及成功和失败的动作轨迹。

Result: 对最先进的视觉-语言模型在GUI-360°上的基准测试显示，它们在基础和动作预测方面存在显著的不足。监督微调和强化学习带来了显著的提升，但仍未达到人类水平的可靠性。

Conclusion: GUI-360°数据集及其代码已公开，以促进可重复研究，并加速开发健壮的桌面CUAs。

Abstract: We introduce GUI-360$^\circ$, a large-scale, comprehensive dataset and
benchmark suite designed to advance computer-using agents (CUAs). CUAs present
unique challenges and is constrained by three persistent gaps: a scarcity of
real-world CUA tasks, the lack of automated collection-and-annotation pipelines
for multi-modal trajectories, and the absence of a unified benchmark that
jointly evaluates GUI grounding, screen parsing, and action prediction.
  GUI-360$^\circ$ addresses these gaps with an LLM-augmented, largely automated
pipeline for query sourcing, environment-template construction, task
instantiation, batched execution, and LLM-driven quality filtering. The
released corpus contains over 1.2M executed action steps across thousands of
trajectories in popular Windows office applications, and includes
full-resolution screenshots, accessibility metadata when available,
instantiated goals, intermediate reasoning traces, and both successful and
failed action trajectories. The dataset supports three canonical tasks, GUI
grounding, screen parsing, and action prediction, and a hybrid GUI+API action
space that reflects modern agent designs. Benchmarking state-of-the-art
vision--language models on GUI-360$^\circ$ reveals substantial out-of-the-box
shortcomings in grounding and action prediction; supervised fine-tuning and
reinforcement learning yield significant gains but do not close the gap to
human-level reliability. We release GUI-360$^\circ$ and accompanying code to
facilitate reproducible research and accelerate progress on robust desktop
CUAs.
  The full dataset has been made public on
https://huggingface.co/datasets/vyokky/GUI-360.

</details>


### [167] [Probing the Probes: Methods and Metrics for Concept Alignment](https://arxiv.org/abs/2511.04312)
*Jacob Lysnæs-Larsen,Marte Eggen,Inga Strümke*

Main category: cs.AI

TL;DR: 解释性AI中，虽然通常认为高探针准确率表明概念激活向量(CAVs)能忠实地表示目标概念，但本文证明了探针准确率是衡量概念对齐度不可靠的指标，探针更可能捕捉到虚假相关性。为此，本文提出了一种新的基于空间线性归因的概念定位方法，并提出了三种量化评估概念对齐度（硬准确率、分割分数、增强鲁棒性）的指标。实验表明，具有平移不变性和空间对齐性的探针能提高概念对齐度。


<details>
  <summary>Details</summary>
Motivation: 解释性AI（XAI）领域普遍假设探针分类准确率高意味着概念激活向量（CAVs）能准确表示目标概念，但这种假设并不可靠，探针可能捕捉到与概念无关的虚假相关性。

Method: 本文提出了一种新的基于空间线性归因的概念定位方法，并引入了硬准确率、分割分数和增强鲁棒性这三类量化指标来评估概念对齐度。通过实验比较了新方法与现有方法的性能，并分析了具有平移不变性和空间对齐性的探针对提高概念对齐度的作用。

Result: 实验证明，仅凭探针准确率无法可靠衡量CAV是否准确表示目标概念，因为精心构造的、利用虚假相关性的探针也能获得高准确率。本文提出的新方法和评估指标能够更准确地评估和提升概念对齐度，具有平移不变性和空间对齐性的探针在提高概念对齐度方面表现优异。

Conclusion: 探针准确率并非衡量概念对齐度的可靠指标，反而可能受到虚假相关性的干扰。因此，需要引入基于对齐度的评估指标，并根据模型架构和概念本身的特性来定制探针，以确保CAV能真正捕捉到目标概念。

Abstract: In explainable AI, Concept Activation Vectors (CAVs) are typically obtained
by training linear classifier probes to detect human-understandable concepts as
directions in the activation space of deep neural networks. It is widely
assumed that a high probe accuracy indicates a CAV faithfully representing its
target concept. However, we show that the probe's classification accuracy alone
is an unreliable measure of concept alignment, i.e., the degree to which a CAV
captures the intended concept. In fact, we argue that probes are more likely to
capture spurious correlations than they are to represent only the intended
concept. As part of our analysis, we demonstrate that deliberately misaligned
probes constructed to exploit spurious correlations, achieve an accuracy close
to that of standard probes. To address this severe problem, we introduce a
novel concept localization method based on spatial linear attribution, and
provide a comprehensive comparison of it to existing feature visualization
techniques for detecting and mitigating concept misalignment. We further
propose three classes of metrics for quantitatively assessing concept
alignment: hard accuracy, segmentation scores, and augmentation robustness. Our
analysis shows that probes with translation invariance and spatial alignment
consistently increase concept alignment. These findings highlight the need for
alignment-based evaluation metrics rather than probe accuracy, and the
importance of tailoring probes to both the model architecture and the nature of
the target concept.

</details>


### [168] [AdversariaLLM: A Unified and Modular Toolbox for LLM Robustness Research](https://arxiv.org/abs/2511.04316)
*Tim Beyer,Jonas Dornbusch,Jakob Steimle,Moritz Ladenburger,Leo Schwinn,Stephan Günnemann*

Main category: cs.AI

TL;DR: LLM安全和鲁棒性研究的碎片化导致了研究难以复现和比较。AdversariaLLM是一个用于LLM越狱鲁棒性研究的工具箱，旨在提高研究的可复现性、正确性和可扩展性。


<details>
  <summary>Details</summary>
Motivation: LLM安全和鲁棒性研究领域存在碎片化、易出错的实现、数据集和评估方法，阻碍了研究的进展。

Method: AdversariaLLM集成了十二种对抗性攻击算法，七个基准数据集，并支持Hugging Face上的多种开源LLM。它还包括计算资源跟踪、确定性结果和分布评估等功能，并集成了JudgeZoo进行评判。

Result: AdversariaLLM提供了一个包含攻击算法、数据集和模型访问的框架，并提供高级功能以支持可比性和可复现性。

Conclusion: AdversariaLLM旨在为LLM安全领域提供一个透明、可比和可复现的研究基础。

Abstract: The rapid expansion of research on Large Language Model (LLM) safety and
robustness has produced a fragmented and oftentimes buggy ecosystem of
implementations, datasets, and evaluation methods. This fragmentation makes
reproducibility and comparability across studies challenging, hindering
meaningful progress. To address these issues, we introduce AdversariaLLM, a
toolbox for conducting LLM jailbreak robustness research. Its design centers on
reproducibility, correctness, and extensibility. The framework implements
twelve adversarial attack algorithms, integrates seven benchmark datasets
spanning harmfulness, over-refusal, and utility evaluation, and provides access
to a wide range of open-weight LLMs via Hugging Face. The implementation
includes advanced features for comparability and reproducibility such as
compute-resource tracking, deterministic results, and distributional evaluation
techniques. \name also integrates judging through the companion package
JudgeZoo, which can also be used independently. Together, these components aim
to establish a robust foundation for transparent, comparable, and reproducible
research in LLM safety.

</details>


### [169] [RxSafeBench: Identifying Medication Safety Issues of Large Language Models in Simulated Consultation](https://arxiv.org/abs/2511.04328)
*Jiahao Zhao,Luxin Xu,Minghuan Tan,Lichao Zhang,Ahmadreza Argha,Hamid Alinejad-Rokny,Min Yang*

Main category: cs.AI

TL;DR: LLM在医疗领域的应用在药物安全方面存在局限，现有研究缺乏真实世界数据集和临床评估。为解决此问题，研究提出了一个模拟和评估临床咨询的框架，并构建了RxRisk DB数据库和RxSafeBench基准测试集，用于评估LLM的药物安全能力。结果表明，当前LLM在处理药物禁忌和药物相互作用方面存在挑战，尤其是在风险隐含的情况下。该研究为提高LLM在临床决策支持中的可靠性提供了见解，并为评估LLM的药物安全性提供了全面的基准。


<details>
  <summary>Details</summary>
Motivation: 现有LLM在医疗领域进展显著，但在药物安全性方面研究有限，缺乏真实世界数据集和临床评估。因此，需要一个系统性的框架来模拟和评估LLM在药物安全方面的能力。

Method: 提出一个模拟和评估临床咨询的框架，生成包含药物风险的诊疗对话，构建RxRisk DB数据库（包含6725个禁忌症，28781个药物相互作用，14906个适应症-药物对），并采用两阶段过滤策略创建RxSafeBench基准（包含2443个高质量咨询场景）。最后，使用结构化选择题评估了主流LLM在模拟患者情境下推荐安全用药的能力。

Result: 当前LLM在整合药物禁忌和药物相互作用知识方面存在困难，尤其是在风险未明确指出的情况下。RxSafeBench基准测试结果揭示了LLM在药物安全方面的关键挑战。

Conclusion: 现有的LLM在处理药物禁忌和药物相互作用方面存在不足，尤其是在风险信息不明确的情况下。RxSafeBench基准测试为评估LLM的药物安全性提供了标准，并为提高LLM在临床决策支持中的可靠性指明了方向。

Abstract: Numerous medical systems powered by Large Language Models (LLMs) have
achieved remarkable progress in diverse healthcare tasks. However, research on
their medication safety remains limited due to the lack of real world datasets,
constrained by privacy and accessibility issues. Moreover, evaluation of LLMs
in realistic clinical consultation settings, particularly regarding medication
safety, is still underexplored. To address these gaps, we propose a framework
that simulates and evaluates clinical consultations to systematically assess
the medication safety capabilities of LLMs. Within this framework, we generate
inquiry diagnosis dialogues with embedded medication risks and construct a
dedicated medication safety database, RxRisk DB, containing 6,725
contraindications, 28,781 drug interactions, and 14,906 indication-drug pairs.
A two-stage filtering strategy ensures clinical realism and professional
quality, resulting in the benchmark RxSafeBench with 2,443 high-quality
consultation scenarios. We evaluate leading open-source and proprietary LLMs
using structured multiple choice questions that test their ability to recommend
safe medications under simulated patient contexts. Results show that current
LLMs struggle to integrate contraindication and interaction knowledge,
especially when risks are implied rather than explicit. Our findings highlight
key challenges in ensuring medication safety in LLM-based systems and provide
insights into improving reliability through better prompting and task-specific
tuning. RxSafeBench offers the first comprehensive benchmark for evaluating
medication safety in LLMs, advancing safer and more trustworthy AI-driven
clinical decision support.

</details>


### [170] [Monitor-Generate-Verify (MGV):Formalising Metacognitive Theory for Language Model Reasoning](https://arxiv.org/abs/2511.04341)
*Nick Oh,Fernand Gobet*

Main category: cs.AI

TL;DR: test-time reasoning frameworks overlook monitoring, leading to suboptimal reasoning. We propose the Monitor-Generate-Verify (MGV) framework, incorporating metacognitive theories to address this gap, though without empirical validation.


<details>
  <summary>Details</summary>
Motivation: existing test-time reasoning architectures like Generate-Verify neglect the crucial monitoring processes that initiate and guide reasoning, contributing to issues like the prefix dominance trap and significant accuracy loss.

Method: formalized metacognitive theories (Flavell, Nelson & Narens) into computational specifications, creating the Monitor-Generate-Verify (MGV) framework that adds explicit monitoring before generation and refines monitoring via verification feedback.

Result: While no empirical validation was conducted, the work provides the first computational translation of metacognitive theories for reasoning systems.

Conclusion: The proposed MGV framework addresses an architectural gap in test-time reasoning by incorporating metacognitive monitoring, offering a foundation for understanding and improving reasoning system failures, despite the lack of empirical validation.

Abstract: Test-time reasoning architectures such as those following the Generate-Verify
paradigm -- where a model iteratively refines or verifies its own generated
outputs -- prioritise generation and verification but exclude the monitoring
processes that determine when and how reasoning should begin. This omission may
contribute to the prefix dominance trap, in which models commit early to
suboptimal reasoning paths and seldom recover, yielding roughly 20% accuracy
loss. We address this architectural gap by formalising Flavell's and Nelson and
Narens' metacognitive theories into computational specifications, proposing the
Monitor-Generate-Verify (MGV) framework. MGV extends the Generate-Verify
paradigm by adding explicit monitoring that captures metacognitive experiences
(from difficulty assessments to confidence judgements) before generation begins
and refines future monitoring through verification feedback. Though we present
no empirical validation, this work provides the first systematic computational
translation of foundational metacognitive theories, offering a principled
vocabulary for understanding reasoning system failures and suggesting specific
architectural interventions for future test-time reasoning designs.

</details>


### [171] [Post-Training LLMs as Better Decision-Making Agents: A Regret-Minimization Approach](https://arxiv.org/abs/2511.04393)
*Chanwoo Park,Ziyang Chen,Asuman Ozdaglar,Kaiqing Zhang*

Main category: cs.AI

TL;DR: LLMs在决策制定（DM）方面存在不足，我们提出了Iterative RMFT，通过迭代提炼低悔意轨迹来改进LLMs的DM能力，该方法在各种模型和任务上表现出良好的泛化能力，并具有理论支持。


<details>
  <summary>Details</summary>
Motivation: LLMs在作为决策制定“代理”时，在动态环境中存在决策能力不足、后悔值高以及探索-利用权衡不佳的问题。

Method: Iterative RMFT是一种后训练程序，通过重复提炼低悔意决策轨迹来微调基础模型。在每次迭代中，模型会生成多个决策轨迹，选择悔意最低的k个轨迹，并在此基础上进行微调。

Result: Iterative RMFT在不同模型（包括Transformer、开放权重LLM和GPT-4o mini）上均能提升DM性能，并且在具有不同时间范围、动作空间、奖励过程和自然语言上下文的任务上表现出良好的泛化能力。理论分析表明，在简化设置下，单层Transformer在该范式下可作为无悔意学习器。

Conclusion: Iterative RMFT为增强LLMs的决策制定能力提供了一个原则性和通用的后训练框架，通过利用悔意指标来激发模型自身的DM能力和推理逻辑，避免了僵化的输出工程。

Abstract: Large language models (LLMs) are increasingly deployed as "agents" for
decision-making (DM) in interactive and dynamic environments. Yet, since they
were not originally designed for DM, recent studies show that LLMs can struggle
even in basic online DM problems, failing to achieve low regret or an effective
exploration-exploitation tradeoff. To address this, we introduce Iterative
Regret-Minimization Fine-Tuning (Iterative RMFT), a post-training procedure
that repeatedly distills low-regret decision trajectories back into the base
model. At each iteration, the model rolls out multiple decision trajectories,
selects the k-lowest regret ones, and fine-tunes itself on them. Unlike prior
methods that (a) distill action sequences from known DM algorithms or (b) rely
on manually crafted chain-of-thought templates, our approach leverages the
regret metric to elicit the model's own DM ability and reasoning rationales.
This reliance on model-generated reasoning avoids rigid output engineering and
provides more flexible, natural-language training signals. Empirical results
show that Iterative RMFT improves LLMs' DM performance across diverse models -
from Transformers with numerical input/output, to open-weight LLMs, and
advanced closed-weight models like GPT-4o mini. Its flexibility in output and
reasoning formats enables generalization across tasks with varying horizons,
action spaces, reward processes, and natural-language contexts. Finally, we
provide theoretical insight showing that a single-layer Transformer under this
paradigm can act as a no-regret learner in a simplified setting. Overall,
Iterative RMFT offers a principled and general post-training framework for
enhancing LLMs' decision-making capabilities.

</details>


### [172] [The Peril of Preference: Why GRPO fails on Ordinal Rewards](https://arxiv.org/abs/2511.04439)
*Anisha Garg,Ganesh Venkatesh*

Main category: cs.AI

TL;DR: GRPO在处理非二元奖励时存在缺陷，CoRPO通过引入自适应基线解决了这个问题，提高了LLM在特定任务上的学习效果，并在代码验证任务上展现出更稳定的收敛性和更好的泛化能力。


<details>
  <summary>Details</summary>
Motivation: GRPO的简单性使其适用于LLM的任务适应，但在处理非二元奖励（如序数奖励）时存在缺陷，可能导致负优势的轨迹被错误地强化。

Method: 提出了一种名为CoRPO的新方法，它使用自适应基线来确保最低质量阈值，避免对失败的解决方案进行正向强化。一旦策略达到阈值，基线会自动切换到相对偏好模式，鼓励模型寻找最优解决方案。

Result: CoRPO在代码验证任务上进行了实证验证，结果显示其比GRPO具有更稳定的收敛性和更好的非特定领域泛化能力。

Conclusion: CoRPO通过解决GRPO在处理多维度反馈（从二元奖励到序数奖励）时的缺陷，是使LLM能够通过强化学习获得新能力的重要一步。

Abstract: Group-relative Policy Optimization's (GRPO) simplicity makes it highly
desirable for adapting LLMs to become experts at specific tasks. But this
simplicity also makes it ill-specified as we seek to enhance RL training with
richer, non-binary feedback. When using ordinal rewards to give partial credit,
GRPO's simplicity starts to hurt, as its group-average baseline often assigns a
positive advantage to failed trajectories and reinforces incorrect behavior.
  We introduce Correctness Relative Policy Optimization (CoRPO), a new
formulation that solves this flaw. CoRPO uses an adaptive baseline that
enforces a minimum quality threshold, ensuring failed solutions are never
positively reinforced. Once the policy consistently meets this threshold, the
baseline automatically transitions to a relative preference mode, pushing the
model to find optimal solutions rather than just "acceptable" ones. We
empirically validate CoRPO on a code verification task, where it demonstrates
more stable convergence and better out-of-domain generalization.
  This work represents a critical step in our broader research program to
enable LLMs to learn genuinely new capabilities through reinforcement learning.
We achieve this by enabling LLMs to learn from rich, multi-dimensional feedback
- progressing from binary to ordinal rewards in this work, and onward to
denser, per-step supervision.

</details>


### [173] [Beyond Shortest Path: Agentic Vehicular Routing with Semantic Context](https://arxiv.org/abs/2511.04464)
*Carnot Braun,Rafael O. Jarczewski,Gabriel U. Talasso,Leandro A. Villas,Allan M. de Souza*

Main category: cs.AI

TL;DR: PAVe是一个结合了传统路径查找算法和大型语言模型（LLM）的混合智能体助手，旨在通过结合用户偏好、任务和情景约束来优化车辆路线规划，以实现个性化、自适应和可扩展的城市出行优化。


<details>
  <summary>Details</summary>
Motivation: 传统车辆路径系统在优化单一指标方面效率很高，但在考虑多个指标时需要更多流程，并且缺乏理解和整合人类驾驶员复杂的、语义的、动态的上下文（如多步任务、情景约束或紧急需求）的能力。

Method: PAVe使用一个大型语言模型（LLM）智能体，在多目标（时间、二氧化碳）Dijkstra算法生成的候选路线集合上进行操作。该智能体利用预处理的城市兴趣点（POIs）地理空间缓存，根据用户提供的任务、偏好和避免规则来评估这些选项。

Result: 在现实城市场景的基准测试中，PAVe成功地将复杂的用户意图转化为适当的路线修改，在初始路线选择中达到了超过88%的准确率（使用本地模型）。

Conclusion: 将经典的路径规划算法与基于LLM的语义推理层相结合，是创建个性化、自适应和可扩展的城市出行优化解决方案的稳健且有效的方法。

Abstract: Traditional vehicle routing systems efficiently optimize singular metrics
like time or distance, and when considering multiple metrics, they need more
processes to optimize . However, they lack the capability to interpret and
integrate the complex, semantic, and dynamic contexts of human drivers, such as
multi-step tasks, situational constraints, or urgent needs. This paper
introduces and evaluates PAVe (Personalized Agentic Vehicular Routing), a
hybrid agentic assistant designed to augment classical pathfinding algorithms
with contextual reasoning. Our approach employs a Large Language Model (LLM)
agent that operates on a candidate set of routes generated by a multi-objective
(time, CO2) Dijkstra algorithm. The agent evaluates these options against
user-provided tasks, preferences, and avoidance rules by leveraging a
pre-processed geospatial cache of urban Points of Interest (POIs). In a
benchmark of realistic urban scenarios, PAVe successfully used complex user
intent into appropriate route modifications, achieving over 88% accuracy in its
initial route selections with a local model. We conclude that combining
classical routing algorithms with an LLM-based semantic reasoning layer is a
robust and effective approach for creating personalized, adaptive, and scalable
solutions for urban mobility optimization.

</details>


### [174] [Promoting Sustainable Web Agents: Benchmarking and Estimating Energy Consumption through Empirical and Theoretical Analysis](https://arxiv.org/abs/2511.04481)
*Lars Krupp,Daniel Geißler,Vishal Banwari,Paul Lukowicz,Jakob Karolus*

Main category: cs.AI

TL;DR: LLM驱动的网络智能体在与互联网交互方面显示出巨大潜力，但其能源消耗和碳排放问题尚未得到充分研究。本文从理论和实证两个角度探讨了网络智能体的能源成本，强调了不同设计理念对能源消耗的显著影响，并呼吁在评估网络智能体时纳入能源消耗指标。


<details>
  <summary>Details</summary>
Motivation: LLM驱动的网络智能体研究迅速发展，但其诱导的可持续性问题（如能源消耗和碳排放）被忽视。本文旨在强调此问题的紧迫性，并对其进行初步探索。

Method: 结合理论估算和实证基准测试，分析网络智能体的能源消耗和碳排放成本。

Result: 不同的网络智能体设计理念对能源消耗有显著影响，消耗更多能源并不一定带来更好的结果。一些网络智能体缺乏透明度，阻碍了能源消耗的估算。现有评估方法未能充分考虑能源消耗因素。

Conclusion: 应改变评估网络智能体的方式，在基准测试中加入专门衡量能源消耗的指标，以应对其带来的可持续性挑战。

Abstract: Web agents, like OpenAI's Operator and Google's Project Mariner, are powerful
agentic systems pushing the boundaries of Large Language Models (LLM). They can
autonomously interact with the internet at the user's behest, such as
navigating websites, filling search masks, and comparing price lists. Though
web agent research is thriving, induced sustainability issues remain largely
unexplored. To highlight the urgency of this issue, we provide an initial
exploration of the energy and $CO_2$ cost associated with web agents from both
a theoretical -via estimation- and an empirical perspective -by benchmarking.
Our results show how different philosophies in web agent creation can severely
impact the associated expended energy, and that more energy consumed does not
necessarily equate to better results. We highlight a lack of transparency
regarding disclosing model parameters and processes used for some web agents as
a limiting factor when estimating energy consumption. Our work contributes
towards a change in thinking of how we evaluate web agents, advocating for
dedicated metrics measuring energy consumption in benchmarks.

</details>


### [175] [Optimizing Sensor Placement in Urban Storm Sewers: A Data-Driven Sparse Sensing Approach](https://arxiv.org/abs/2511.04556)
*Zihang Ding,Kun Zhang*

Main category: cs.AI

TL;DR: 本研究提出了一种数据驱动的稀疏传感（DSS）框架，结合EPA-SWMM模型，用于优化传感器布局并重建城市排水系统的峰值流量，以应对资源受限的挑战。


<details>
  <summary>Details</summary>
Motivation: 城市地表积水（由强降雨导致排水系统超负荷）的频率和范围日益增加，但在时间、预算和技术有限的情况下，实现高时空分辨率的洪水预测和监测面临巨大挑战。

Method: 利用SWMM模型生成峰值流量数据集，然后应用DSS框架（结合奇异值分解进行降维和QR分解进行传感器分配）来识别最优监测节点。通过将DSS重建的峰值流量与SWMM模拟结果进行比较来验证监测节点的代表性。

Result: 在杜鲁斯伍德兰大道流域的案例研究中，三个最优传感器在77个节点中实现了0.92-0.95的纳什-萨克利夫效率（NSE）值（25%-75%分位数），表明了令人满意的重建性能。该模型对测量不确定性表现出良好的鲁棒性，对传感器故障的鲁棒性则取决于位置且随着传感器数量的增加而提高。

Conclusion: DSS框架在计算效率和物理可解释性之间取得了平衡，能够以最少的传感器实现高精度的流量重建，并可与预测模型集成，在传感和监测资源有限的情况下实现洪水预警和实时控制。

Abstract: Urban surface water flooding, triggered by intense rainfall overwhelming
drainage systems, is increasingly frequent and widespread. While flood
prediction and monitoring in high spatial-temporal resolution are desired,
practical constraints in time, budget, and technology hinder its full
implementation. How to monitor urban drainage networks and predict flow
conditions under constrained resource is a major challenge. This study presents
a data-driven sparse sensing (DSS) framework, integrated with EPA-SWMM, to
optimize sensor placement and reconstruct peak flowrates in a stormwater
system, using the Woodland Avenue catchment in Duluth, Minnesota, as a case
study. We utilized a SWMM model to generate a training dataset of peak flowrate
profiles across the stormwater network. Furthermore, we applied DSS -
leveraging singular value decomposition for dimensionality reduction and QR
factorization for sensor allocation - to identify the optimal monitoring nodes
based on the simulated training dataset. We then validated the
representativeness of these identified monitoring nodes by comparing the
DSS-reconstructed peak flowrate profiles with those obtained from SWMM. Three
optimally placed sensors among 77 nodes achieved satisfactory reconstruction
performance with Nash-Sutcliffe Efficiency (NSE) values of 0.92-0.95 (25th to
75th percentiles). In addition, the model showed good robustness to uncertainty
in measurements. Its robustness to sensor failures is location-dependent and
improves with the number of sensors deployed. The framework balances
computational efficiency and physical interpretability, enabling high-accuracy
flow reconstruction with minimal sensors. This DSS framework can be further
integrated with predictive models to realize flood early warning and real-time
control under limited sensing and monitoring resource.

</details>


### [176] [Jr. AI Scientist and Its Risk Report: Autonomous Scientific Exploration from a Baseline Paper](https://arxiv.org/abs/2511.04583)
*Atsuyuki Miyai,Mashiro Toyooka,Takashi Otonari,Zaiying Zhao,Kiyoharu Aizawa*

Main category: cs.AI

TL;DR: Jr. AI Scientist是一个先进的自主AI科学家系统，能够模仿初级研究人员的整个研究流程，从分析局限性、提出假设到进行实验和撰写论文。该系统在多文件实现方面表现出色，并产生了具有科学价值的贡献。评估结果显示，Jr. AI Scientist生成的论文比现有全自动系统获得了更高的评价分数。然而，研究也指出了其局限性以及在直接应用中可能存在的风险，为未来的AI科学家研究提供了宝贵的见解。


<details>
  <summary>Details</summary>
Motivation: 理解AI科学家系统的能力和风险对于确保AI驱动的科学进步的可信赖性和可持续性至关重要，同时也要维护学术生态系统的完整性。

Method: 开发了一个名为Jr. AI Scientist的自主AI科学家系统，该系统模仿了初级学生研究人员的核心研究流程：给定人类导师提供的基线论文，它分析其局限性，提出新颖的改进假设，通过严格的实验进行验证，并撰写包含结果的论文。该系统利用现代编码代理来处理复杂的多文件实现。

Result: 通过自动化评估（AI审稿人）、作者主导的评估以及向专门的AI驱动科学贡献的会议Agents4Science提交论文进行评估。结果表明，Jr. AI Scientist生成的论文获得了比现有全自动系统更高的审稿分数。然而，作者评估和Agents4Science的审稿也揭示了重要的局限性。

Conclusion: Jr. AI Scientist在生成科学论文方面取得了显著进展，但其局限性和潜在风险表明，目前直接应用此类系统存在挑战。未来的研究需要解决这些挑战，并深入理解AI科学家发展的风险。

Abstract: Understanding the current capabilities and risks of AI Scientist systems is
essential for ensuring trustworthy and sustainable AI-driven scientific
progress while preserving the integrity of the academic ecosystem. To this end,
we develop Jr. AI Scientist, a state-of-the-art autonomous AI scientist system
that mimics the core research workflow of a novice student researcher: Given
the baseline paper from the human mentor, it analyzes its limitations,
formulates novel hypotheses for improvement, validates them through rigorous
experimentation, and writes a paper with the results. Unlike previous
approaches that assume full automation or operate on small-scale code, Jr. AI
Scientist follows a well-defined research workflow and leverages modern coding
agents to handle complex, multi-file implementations, leading to scientifically
valuable contributions. For evaluation, we conducted automated assessments
using AI Reviewers, author-led evaluations, and submissions to Agents4Science,
a venue dedicated to AI-driven scientific contributions. The findings
demonstrate that Jr. AI Scientist generates papers receiving higher review
scores than existing fully automated systems. Nevertheless, we identify
important limitations from both the author evaluation and the Agents4Science
reviews, indicating the potential risks of directly applying current AI
Scientist systems and key challenges for future research. Finally, we
comprehensively report various risks identified during development. We hope
these insights will deepen understanding of current progress and risks in AI
Scientist development.

</details>


### [177] [Are We Asking the Right Questions? On Ambiguity in Natural Language Queries for Tabular Data Analysis](https://arxiv.org/abs/2511.04584)
*Daniel Gomm,Cornelius Wolff,Madelon Hulsebos*

Main category: cs.AI

TL;DR: 自然语言接口应将歧义视为合作互动的特征，并区分可解决和不可解决的查询，以改进表格数据的交互和评估。


<details>
  <summary>Details</summary>
Motivation: 现有的表格数据自然语言接口在处理查询歧义时存在不足，需要一种新的方法来应对这种歧义。

Method: 提出一个区分合作查询和非合作查询的框架，并将其应用于分析15个流行数据集中的查询，以评估现有方法的局限性。

Result: 分析结果表明，现有数据集中的查询混合了不同类型的查询，既不适合评估系统的执行准确性，也不适合评估其解释能力。

Conclusion: 应采用合作的方式来解决查询中的歧义，而不是试图消除歧义。这种新的视角将有助于改进表格数据的自然语言接口的设计和评估，并为未来的研究指明方向。

Abstract: Natural language interfaces to tabular data must handle ambiguities inherent
to queries. Instead of treating ambiguity as a deficiency, we reframe it as a
feature of cooperative interaction, where the responsibility of query
specification is shared among the user and the system. We develop a principled
framework distinguishing cooperative queries, i.e., queries that yield a
resolvable interpretation, from uncooperative queries that cannot be resolved.
Applying the framework to evaluations for tabular question answering and
analysis, we analyze the queries in 15 popular datasets, and observe an
uncontrolled mixing of query types neither adequate for evaluating a system's
execution accuracy nor for evaluating interpretation capabilities. Our
framework and analysis of queries shifts the perspective from fixing ambiguity
to embracing cooperation in resolving queries. This reflection enables more
informed design and evaluation for natural language interfaces for tabular
data, for which we outline implications and directions for future research.

</details>


### [178] [Question the Questions: Auditing Representation in Online Deliberative Processes](https://arxiv.org/abs/2511.04588)
*Soham De,Lodewijk Gelauff,Ashish Goel,Smitha Milli,Ariel Procaccia,Alice Siu*

Main category: cs.AI

TL;DR: 该研究提出了一种基于社会选择理论中“合理代表性”概念的审计框架，用于评估在公民审议过程中，选定的一小组问题能否代表所有参与者的问题集合。研究者还开发了首批用于在一般效用设置下审计合理代表性的算法，其中最高效算法的运行时间复杂度为 O(mn log n)，n为参与者数量，m为问题数量。研究将该审计方法应用于历史审议数据，比较了实际提出问题、通过整数线性规划选择的问题以及大型语言模型（LLM）生成的问题这三种方式的代表性。结果表明LLM在支持审议方面有潜力但也有局限性。该研究将审计方法整合到一个在线审议平台，方便实践者在未来的审议中审计和改进代表性。


<details>
  <summary>Details</summary>
Motivation: 当公民审议过程（如公民大会、审议式民意调查）中，参与者向专家小组提问的数量受限时，如何选择能最好代表所有参与者利益的一小组问题，是一个关键挑战。

Method: 提出了一种基于社会选择理论中“合理代表性”（JR）概念的审计框架，并开发了首批用于在一般效用设置下审计JR的算法，其中最优算法时间复杂度为O(mn log n)。将此方法应用于历史审议数据，比较了实际提出问题、（通过整数线性规划选择的）参与者问题、（LLM生成的）摘要问题的代表性。

Result: 通过将提出的审计方法应用于历史审议数据，比较了实际提出问题、通过整数线性规划选择的问题以及大型语言模型（LLM）生成的问题这三种情况的代表性。结果揭示了LLM在支持审议方面的潜力和局限性。

Conclusion: 研究者开发了一种审计框架和算法，用于衡量一组选定的问题在公民审议过程中对参与者问题的代表性水平。该研究将此方法应用于真实案例，并发现LLM在支持审议方面既有优势也存在不足。通过将该方法集成到在线平台，可以帮助实践者改进未来审议中的代表性。

Abstract: A central feature of many deliberative processes, such as citizens'
assemblies and deliberative polls, is the opportunity for participants to
engage directly with experts. While participants are typically invited to
propose questions for expert panels, only a limited number can be selected due
to time constraints. This raises the challenge of how to choose a small set of
questions that best represent the interests of all participants. We introduce
an auditing framework for measuring the level of representation provided by a
slate of questions, based on the social choice concept known as justified
representation (JR). We present the first algorithms for auditing JR in the
general utility setting, with our most efficient algorithm achieving a runtime
of $O(mn\log n)$, where $n$ is the number of participants and $m$ is the number
of proposed questions. We apply our auditing methods to historical
deliberations, comparing the representativeness of (a) the actual questions
posed to the expert panel (chosen by a moderator), (b) participants' questions
chosen via integer linear programming, (c) summary questions generated by large
language models (LLMs). Our results highlight both the promise and current
limitations of LLMs in supporting deliberative processes. By integrating our
methods into an online deliberation platform that has been used for over
hundreds of deliberations across more than 50 countries, we make it easy for
practitioners to audit and improve representation in future deliberations.

</details>


### [179] [VeriCoT: Neuro-symbolic Chain-of-Thought Validation via Logical Consistency Checks](https://arxiv.org/abs/2511.04662)
*Yu Feng,Nathaniel Weir,Kaj Bostrom,Sam Bayless,Darion Cassel,Sapana Chaudhary,Benjamin Kiesl-Reiter,Huzefa Rangwala*

Main category: cs.AI

TL;DR: VeriCoT是一种神经符号方法，通过提取和验证CoT推理中的形式逻辑论证来解决LLM自身逻辑验证不可靠的问题，实验证明其能有效识别缺陷推理并提高LLM的推理能力。


<details>
  <summary>Details</summary>
Motivation: LLMs在多步推理中存在自身逻辑验证不可靠的问题，即使答案正确，推理过程也可能存在缺陷，这在关键场景中会影响模型的可靠性。

Method: VeriCoT是一种神经符号方法，将CoT推理的每个步骤形式化为一阶逻辑，并识别将论证依据于源上下文、常识或先前推理步骤的假设。这种符号表示允许自动化求解器验证逻辑有效性，同时自然语言假设允许人类和系统识别无依据或错误的推理步骤。

Result: 在ProofWriter、LegalBench和BioASQ数据集上的实验表明，VeriCoT能有效识别有缺陷的推理，并且是最终答案正确性的有力预测指标。此外，通过推理时自我反思、在VeriCoT蒸馏数据集上进行监督微调（SFT）以及使用基于验证的成对奖励进行直接偏好优化（DPO）进行偏好微调（PFT），可以进一步提高推理的有效性和准确性。

Conclusion: VeriCoT通过神经符号方法解决了LLM在多步推理中自身逻辑验证的局限性，通过形式化和验证逻辑论证，不仅能识别有缺陷的推理，还能通过多种微调策略进一步提升LLM的推理能力和准确性。

Abstract: LLMs can perform multi-step reasoning through Chain-of-Thought (CoT), but
they cannot reliably verify their own logic. Even when they reach correct
answers, the underlying reasoning may be flawed, undermining trust in
high-stakes scenarios. To mitigate this issue, we introduce VeriCoT, a
neuro-symbolic method that extracts and verifies formal logical arguments from
CoT reasoning. VeriCoT formalizes each CoT reasoning step into first-order
logic and identifies premises that ground the argument in source context,
commonsense knowledge, or prior reasoning steps. The symbolic representation
enables automated solvers to verify logical validity while the NL premises
allow humans and systems to identify ungrounded or fallacious reasoning steps.
Experiments on the ProofWriter, LegalBench, and BioASQ datasets show VeriCoT
effectively identifies flawed reasoning, and serves as a strong predictor of
final answer correctness. We also leverage VeriCoT's verification signal for
(1) inference-time self-reflection, (2) supervised fine-tuning (SFT) on
VeriCoT-distilled datasets and (3) preference fine-tuning (PFT) with direct
preference optimization (DPO) using verification-based pairwise rewards,
further improving reasoning validity and accuracy.

</details>


<div id='cs.NE'></div>

# cs.NE [[Back]](#toc)

### [180] [Evolutionary Optimization Trumps Adam Optimization on Embedding Space Exploration](https://arxiv.org/abs/2511.03913)
*Domício Pereira Neto,João Correia,Penousal Machado*

Main category: cs.NE

TL;DR: 深度生成模型，特别是扩散模型，在图像生成领域取得了显著进展，但难以针对特定目标进行控制和优化。本研究探讨了进化优化方法（sep-CMA-ES）在Stable Diffusion XL Turbo的提示嵌入向量优化中相对于Adam的性能，并结合LAION Aesthetic Predictor V2和CLIPScore作为评价指标。实验结果表明，sep-CMA-ES在美学和提示对齐方面优于Adam，为深度生成模型提供了一种无需微调的高效、无梯度优化方法。


<details>
  <summary>Details</summary>
Motivation: 现有的深度生成模型，特别是扩散模型，在图像生成方面表现出色，但缺乏对生成过程的精确控制和优化能力，且重新训练成本高昂。嵌入空间探索，特别是利用进化算法（EA），已被证明是优化图像生成的一种有前景的方法，尤其是在扩散模型中。因此，本研究旨在探索一种进化优化方法（sep-CMA-ES）在Stable Diffusion XL Turbo的提示嵌入向量优化方面的性能。

Method: 本研究将一种名为分离协方差矩阵自适应进化策略（sep-CMA-ES）的进化优化方法应用于Stable Diffusion XL Turbo的提示嵌入向量，并将其与广泛使用的自适应矩估计（Adam）优化器进行比较。图像评估结合了LAION Aesthetic Predictor V2和CLIPScore，构建了一个加权的适应度函数，以平衡视觉吸引力和提示的准确性。

Result: 在Parti Prompts (P2)数据集的一个子集上进行的实验表明，与Adam相比，sep-CMA-ES在美学和对齐指标上持续带来更优的改进。结果显示，这种进化方法为扩散模型提供了高效的、无梯度的优化，增强了可控性，且无需进行微调。

Conclusion: 本研究强调了进化方法在深度生成模型嵌入空间探索方面的潜力，并指出了未来的研究方向。结果表明，sep-CMA-ES是一种有效且无需微调的梯度无关优化方法，能够显著提升扩散模型的图像生成质量和对用户输入的遵循程度。

Abstract: Deep generative models, especially diffusion architectures, have transformed
image generation; however, they are challenging to control and optimize for
specific goals without expensive retraining. Embedding Space Exploration,
especially with Evolutionary Algorithms (EAs), has been shown to be a promising
method for optimizing image generation, particularly within Diffusion Models.
Therefore, in this work, we study the performance of an evolutionary
optimization method, namely Separable Covariance Matrix Adaptation Evolution
Strategy (sep-CMA-ES), against the widely adopted Adaptive Moment Estimation
(Adam), applied to Stable Diffusion XL Turbo's prompt embedding vector. The
evaluation of images combines the LAION Aesthetic Predictor V2 with CLIPScore
into a weighted fitness function, allowing flexible trade-offs between visual
appeal and adherence to prompts. Experiments on a subset of the Parti Prompts
(P2) dataset showcase that sep-CMA-ES consistently yields superior improvements
in aesthetic and alignment metrics in comparison to Adam. Results indicate that
the evolutionary method provides efficient, gradient-free optimization for
diffusion models, enhancing controllability without the need for fine-tuning.
This study emphasizes the potential of evolutionary methods for embedding space
exploration of deep generative models and outlines future research directions.

</details>


### [181] [A Reinforced Evolution-Based Approach to Multi-Resource Load Balancing](https://arxiv.org/abs/2511.04183)
*Leszek Sliwko*

Main category: cs.NE

TL;DR: 该论文提出了一种改进的遗传算法来解决 d-资源系统优化问题。


<details>
  <summary>Details</summary>
Motivation: 传统的遗传算法在处理具有严格可行性约束的 d-资源系统优化问题时效果不佳。

Method: 通过引入迁移算子等多种改进和自适应策略来优化标准遗传算法，其中迁移算子模拟了生物学中的随机遗传漂变。

Result: 提出了一种结合了迁移算子的遗传算法，该算法能够更有效地解决 d-资源系统优化问题。

Conclusion: 该论文提出了一种改进的遗传算法，能够更有效地解决 d-资源系统优化问题。

Abstract: This paper presents a reinforced genetic approach to a defined d-resource
system optimization problem. The classical evolution schema was ineffective due
to a very strict feasibility function in the studied problem. Hence, the
presented strategy has introduced several modifications and adaptations to
standard genetic routines, e.g.: a migration operator which is an analogy to
the biological random genetic drift.

</details>


### [182] [Neural Computation Without Slots: Steps Towards Biologically Plausible Memory and Attention in Natural and Artificial Intelligence](https://arxiv.org/abs/2511.04593)
*Shaunak Bhandarkar,James L. McClelland*

Main category: cs.NE

TL;DR: 大脑通过使用神经元集合而非单个神经元来存储模式，并扩展了现代Hopfield网络（MHN）来模拟基于槽的计算，以提高记忆保留率和捕获语言模型中的序列输入处理能力。


<details>
  <summary>Details</summary>
Motivation: 探讨大脑在没有固定槽的情况下如何实现类似基于槽的计算的记忆存储和处理能力，并以神经科学为基础，扩展现代Hopfield网络（MHN）。

Method: 提出K-winner MHN模型，扩展了MHN以利用神经元集合存储模式，并将其应用于持续学习场景。此外，还扩展了MHN以模拟语言模型中基于槽的序列输入处理和反向传播错误信号的能力。

Result: K-winner MHN在持续学习中比标准MHN表现出更好的旧记忆保留率（以d'测量）。所提出的MHN扩展能够同时处理序列输入和反向传播错误信号。

Conclusion: 通过神经元集合和扩展的MHN模型，为理解大脑如何实现复杂的计算能力（如AI系统中的能力）提供了生物学上可行的方法。

Abstract: Many models used in artificial intelligence and cognitive science rely on
multi-element patterns stored in "slots" - dedicated storage locations - in a
digital computer. As biological brains likely lack slots, we consider how they
might achieve similar functional outcomes without them by building on the
neurally-inspired modern Hopfield network (MHN; Krotov & Hopfield, 2021), which
stores patterns in the connection weights of an individual neuron. We propose
extensions of this approach to increase its biological plausibility as a model
of memory and to capture an important advantage of slot-based computation in
contemporary language models. For memory, neuroscience research suggests that
the weights of overlapping sparse ensembles of neurons, rather than a dedicated
individual neuron, are used to store a memory. We introduce the K-winner MHN,
extending the approach to ensembles, and find that within a continual learning
regime, the ensemble-based MHN exhibits greater retention of older memories, as
measured by the graded sensitivity measure d', than a standard (one-neuron)
MHN. Next, we consider the powerful use of slot-based memory in contemporary
language models. These models use slots to store long sequences of past inputs
and their learned encodings, supporting later predictions and allowing error
signals to be transported backward in time to adjust weights underlying the
learned encodings of these past inputs. Inspired by these models' successes, we
show how the MHN can be extended to capture both of these important functional
outcomes. Collectively, our modeling approaches constitute steps towards
understanding how biologically plausible mechanisms can support computations
that have enabled AI systems to capture human-like abilities that no prior
models have been able to achieve.

</details>


<div id='cs.DC'></div>

# cs.DC [[Back]](#toc)

### [183] [OMPILOT: Harnessing Transformer Models for Auto Parallelization to Shared Memory Computing Paradigms](https://arxiv.org/abs/2511.03866)
*Arijit Bhattacharjee,Ali TehraniJamsaz,Le Chen,Niranjan Hasabnis,Mihai Capota,Nesreen Ahmed,Ali Jannesari*

Main category: cs.DC

TL;DR: LLMs在代码翻译领域取得了显著进展，本文提出了OMPILOT，一个用于C++到OpenMP翻译的特定领域模型，并引入了OMBLEU评估指标。


<details>
  <summary>Details</summary>
Motivation: 将C++代码高效地转换为OpenMP以实现共享内存并行化，克服传统方法的局限性。

Method: 利用定制预训练目标和结合无监督及监督学习策略，设计了OMPILOT模型，实现了函数级而非仅循环级的代码翻译。

Result: OMPILOT在C++到OpenMP的翻译任务上表现出色，并提出了OMBLEU指标以更准确地评估翻译结果的正确性和质量。

Conclusion: OMPILOT是一种创新的C++到OpenMP代码翻译方法，能够实现更广泛的语义上下文理解和有效的并行化，OMBLEU指标为评估此类翻译提供了更好的工具。

Abstract: Recent advances in large language models (LLMs) have significantly
accelerated progress in code translation, enabling more accurate and efficient
transformation across programming languages. While originally developed for
natural language processing, LLMs have shown strong capabilities in modeling
programming language syntax and semantics, outperforming traditional rule-based
systems in both accuracy and flexibility. These models have streamlined
cross-language conversion, reduced development overhead, and accelerated legacy
code migration. In this paper, we introduce OMPILOT, a novel domain-specific
encoder-decoder transformer tailored for translating C++ code into OpenMP,
enabling effective shared-memory parallelization. OMPILOT leverages custom
pre-training objectives that incorporate the semantics of parallel constructs
and combines both unsupervised and supervised learning strategies to improve
code translation robustness. Unlike previous work that focused primarily on
loop-level transformations, OMPILOT operates at the function level to capture a
wider semantic context. To evaluate our approach, we propose OMPBLEU, a novel
composite metric specifically crafted to assess the correctness and quality of
OpenMP parallel constructs, addressing limitations in conventional translation
metrics.

</details>


### [184] [Stochastic Modeling for Energy-Efficient Edge Infrastructure](https://arxiv.org/abs/2511.03941)
*Fabio Diniz Rossi*

Main category: cs.DC

TL;DR: Edge Computing 的功耗管理面临挑战，本文提出一种基于马尔可夫链的随机建模方法，并通过 AI 驱动的预测性功耗扩展来解决这一问题，实验证明该方法能提高能效和系统响应能力。


<details>
  <summary>Details</summary>
Motivation: Edge Computing 的分布式特性和有限的能源资源给功耗管理带来了挑战。

Method: 使用马尔可夫链进行随机建模，推导稳态概率，评估能耗，并进行蒙特卡洛模拟和敏感性分析。

Result: AI 驱动的预测性功耗扩展比传统反应式方法更具优势，能够最小化不必要的转换并提高整体系统响应能力。AI 驱动的功耗管理能够优化异构边缘节点上的工作负载分配，减少设备间的能耗差异，提高整体效率，并增强多节点环境中的自适应功耗协调。

Conclusion: AI 驱动的功耗管理策略通过预测工作负载需求和优化状态转换，显著提高了 Edge Computing 的能效。

Abstract: Edge Computing enables low-latency processing for real-time applications but
introduces challenges in power management due to the distributed nature of edge
devices and their limited energy resources. This paper proposes a stochastic
modeling approach using Markov Chains to analyze power state transitions in
Edge Computing. By deriving steady-state probabilities and evaluating energy
consumption, we demonstrate the benefits of AI-driven predictive power scaling
over conventional reactive methods. Monte Carlo simulations validate the model,
showing strong alignment between theoretical and empirical results. Sensitivity
analysis highlights how varying transition probabilities affect power
efficiency, confirming that predictive scaling minimizes unnecessary
transitions and improves overall system responsiveness. Our findings suggest
that AI-based power management strategies significantly enhance energy
efficiency by anticipating workload demands and optimizing state transitions.
Experimental results indicate that AI-based power management optimizes workload
distribution across heterogeneous edge nodes, reducing energy consumption
disparities between devices, improving overall efficiency, and enhancing
adaptive power coordination in multi-node environments.

</details>


### [185] [Parallel Spawning Strategies for Dynamic-Aware MPI Applications](https://arxiv.org/abs/2511.04268)
*Iker Martín-Álvarez,José I. Aliaga,Maribel Castillo,Sergio Iserte*

Main category: cs.DC

TL;DR: 动态资源管理和可塑性对于HPC系统至关重要，本研究提出了一种新的并行创建策略，以降低可塑性的重构成本。


<details>
  <summary>Details</summary>
Motivation: 可塑性虽然有益，但会产生显著的重构成本，因此降低这些成本是一个重要的研究课题。

Method: 提出了一种新的并行创建策略，所有进程在重新分配之前进行协作创建，从而减少执行时间。该策略还消除了收缩限制。

Result: 与现有方法相比，该策略的扩展时间开销仅为1.25倍，而收缩操作成本降低了至少20倍。该策略已在同构和异构系统上得到验证。

Conclusion: 所提出的并行创建策略通过减少重构成本，提高了HPC系统中应用程序的可塑性，从而降低了作业的完成时间和提高了系统利用率。

Abstract: Dynamic resource management is an increasingly important capability of High
Performance Computing systems, as it enables jobs to adjust their resource
allocation at runtime. This capability has been shown to reduce workload
makespan, substantially decrease job waiting times and improve overall system
utilization. In this context, malleability refers to the ability of
applications to adapt to new resource allocations during execution. Although
beneficial, malleability incurs significant reconfiguration costs, making the
reduction of these costs an important research topic.
  Some existing methods for MPI applications respawn the entire application,
which is an expensive solution that avoids the reuse of original processes.
Other MPI methods reuse them, but fail to fully release unneeded processes when
shrinking, since some ranks within the same communicator remain active across
nodes, preventing the application from returning those nodes to the system.
This work overcomes both limitations by proposing a novel parallel spawning
strategy, in which all processes cooperate in spawning before redistribution,
thereby reducing execution time. Additionally, it removes shrinkage
limitations, allowing better adaptation of parallel systems to workload and
reducing their makespan. As a result, it preserves competitive expansion times
with at most a $1.25\times$ overhead, while enabling fast shrink operations
that reduce their cost by at least $20\times$. This strategy has been validated
on both homogeneous and heterogeneous systems and can also be applied in
shared-resource environments.

</details>


### [186] [Enabling Dynamic Sparsity in Quantized LLM Inference](https://arxiv.org/abs/2511.04477)
*Rongxiang Wang,Kangyuan Shu,Felix Xiaozhu Lin*

Main category: cs.DC

TL;DR: 在端侧部署大语言模型面临计算和内存限制。本文提出了一种结合动态稀疏性和低比特量化的方法，通过优化的量化布局、专门的GEMV核和紧凑的运行时机制，在保持精度的同时，在常见GPU上实现了高达1.55倍的推理加速。


<details>
  <summary>Details</summary>
Motivation: 为了解决在内存和计算能力有限的移动和桌面GPU上高效部署大语言模型的挑战，同时利用大语言模型内部激活的动态稀疏性。

Method: 提出了一种实现低比特量化下动态稀疏推理的技术。具体包括：1. 采用锯齿状量化布局，使权重组织方式与激活稀疏性一致，并提高GPU内存局部性；2. 设计专门的GEMV核以利用该布局的并行计算能力；3. 引入紧凑的运行时机制，以最小开销收集稀疏索引。

Result: 在多种模型规模和硬件配置下，该方法实现了高达1.55倍的解码吞吐量提升，同时在准确性上与密集量化推理相当。

Conclusion: 结构化稀疏性和量化技术可以有效地共存于普通GPU上，为在资源受限的硬件上高效部署大语言模型提供了解决方案。

Abstract: Deploying large language models (LLMs) on end-user devices is gaining
importance due to benefits in responsiveness, privacy, and operational cost.
Yet the limited memory and compute capability of mobile and desktop GPUs make
efficient execution difficult. Recent observations suggest that the internal
activations of LLMs are often dynamically sparse, meaning that for each input,
only part of the network contributes significantly to the output. Such sparsity
could reduce computation, but it interacts poorly with group-wise quantization,
which remains the dominant approach for fitting LLMs onto resource-constrained
hardware. To reconcile these two properties, this study proposes a set of
techniques that realize dynamic sparse inference under low-bit quantization.
The method features: (1) a zigzag-patterned quantization layout that organizes
weights in a way consistent with activation sparsity and improves GPU memory
locality; (2) a specialized GEMV kernel designed for this layout to fully
utilize parallel compute units; and (3) a compact runtime mechanism that
gathers sparse indices with minimal overhead. Across several model scales and
hardware configurations, the approach achieves up to 1.55x faster decoding
throughput while maintaining accuracy comparable to dense quantized inference,
showing that structured sparsity and quantization can effectively coexist on
commodity GPUs.

</details>


### [187] [A New Probabilistic Mobile Byzantine Failure Model for Self-Protecting Systems](https://arxiv.org/abs/2511.04523)
*Silvia Bonomi,Giovanni Farina,Roy Friedman,Eviatar B. Procaccia,Sebastien Tixeuil*

Main category: cs.DC

TL;DR: 该论文提出了一种新的概率性移动拜占庭故障（MBF）模型，用于增强基于MAPE-K架构的自适应分布式系统的安全性，该模型能够动态适应不断演变的攻击。


<details>
  <summary>Details</summary>
Motivation: 随着分布式系统面临日益严峻的安全威胁，从硬件到应用层的漏洞日益增多，需要更有效的自保护机制。传统的拜占庭容错模型在模拟真实世界场景时存在局限性。

Method: 提出了一种新的概率性移动拜占庭故障（MBF）模型，并将其集成到MAPE-K架构的分析组件中，以动态捕获和应对不断演变的攻击。对系统在拜占庭节点数量达到阈值或恢复到安全状态所需的时间进行了数学分析，考虑了拜占庭感染传播速率与自恢复速率的权衡。

Result: 通过数学分析和仿真结果，说明了该MBF模型如何驱动自保护和重构策略，并分析了系统在不同拜占庭感染传播速率和自恢复速率下的行为。

Conclusion: 所提出的MBF模型能够有效提升分布式系统的自保护能力，通过动态调整策略来应对不断演变的攻击，并能在一定程度上实现自恢复。

Abstract: Modern distributed systems face growing security threats, as attackers
continuously enhance their skills and vulnerabilities span across the entire
system stack, from hardware to the application layer. In the system design
phase, fault tolerance techniques can be employed to safeguard systems. From a
theoretical perspective, an attacker attempting to compromise a system can be
abstracted by considering the presence of Byzantine processes in the system.
Although this approach enhances the resilience of the distributed system, it
introduces certain limitations regarding the accuracy of the model in
reflecting real-world scenarios. In this paper, we consider a self-protecting
distributed system based on the \emph{Monitoring-Analyse-Plan-Execute over a
shared Knowledge} (MAPE-K) architecture, and we propose a new probabilistic
Mobile Byzantine Failure (MBF) that can be plugged into the Analysis component.
Our new model captures the dynamics of evolving attacks and can be used to
drive the self-protection and reconfiguration strategy. We analyze
mathematically the time that it takes until the number of Byzantine nodes
crosses given thresholds, or for the system to self-recover back into a safe
state, depending on the rates of Byzantine infection spreading \emph{vs.} the
rate of self-recovery. We also provide simulation results that illustrate the
behavior of the system under such assumptions.

</details>


### [188] [Resolving Conflicts with Grace: Dynamically Concurrent Universality](https://arxiv.org/abs/2511.04631)
*Petr Kuznetsov,Nathan Josia Schrodt*

Main category: cs.DC

TL;DR: 并发操作在共享数据上发生冲突时会进行同步，而动态并发允许操作仅在必要时使用强同步原语。


<details>
  <summary>Details</summary>
Motivation: 同步是分布式计算中可扩展性的主要障碍，理想情况下应动态检测冲突。

Method: 提出动态并发的概念，其中操作仅在需要时进行同步，并提出了一个动态并发的通用结构。

Result: 该研究提出了一种动态并发的通用结构。

Conclusion: 动态并发是提高分布式系统可扩展性的关键。

Abstract: Synchronization is the major obstacle to scalability in distributed
computing. Concurrent operations on the shared data engage in synchronization
when they encounter a \emph{conflict}, i.e., their effects depend on the order
in which they are applied. Ideally, one would like to detect conflicts in a
\emph{dynamic} manner, i.e., adjusting to the current system state. Indeed, it
is very common that two concurrent operations conflict only in some rarely
occurring states. In this paper, we define the notion of \emph{dynamic
concurrency}: an operation employs strong synchronization primitives only if it
\emph{has} to arbitrate with concurrent operations, given the current system
state. We then present a dynamically concurrent universal construction.

</details>


<div id='eess.SP'></div>

# eess.SP [[Back]](#toc)

### [189] [Correlation and Temporal Consistency Analysis of Mono-static and Bi-static ISAC Channels](https://arxiv.org/abs/2511.03837)
*Saúl Fenollosa,Narcis Cardona,Wenfei Yang,Jian Li*

Main category: eess.SP

TL;DR: ISAC是6G无线网络的关键技术，但现有信道模型缺乏对ISAC特定动态（特别是单站和双站传感配置之间的关系）的全面描述。本研究通过在城市微蜂窝（UMi）环境中使用79 GHz FMCW信道测深仪进行实证测量，填补了这一空白。


<details>
  <summary>Details</summary>
Motivation: 现有信道模型未能充分描述ISAC（集成传感与通信）的特定动态，特别是单站（共置收发器）和双站（分离式收发器）传感配置之间的信道差异。

Method: 在城市微蜂窝（UMi）环境中使用79 GHz FMCW信道测深仪进行实证测量，分析单站和双站传感配置下的信道特性。

Result: 1. 单站和双站信道由于传播几何差异，瞬时相关性一直很低；2. 尽管瞬时相关性低，但两个信道表现出统一的时间一致性，并随着环境运动而可预测地演变。

Conclusion: 研究结果为鲁棒的ISAC系统设计和未来标准化提供了依据。

Abstract: Integrated Sensing and Communication (ISAC) is critical for efficient
spectrum and hardware utilization in future wireless networks like 6G. However,
existing channel models lack comprehensive characterization of ISAC-specific
dynamics, particularly the relationship between mono-static (co-located Tx/Rx)
and bi-static (separated Tx/Rx) sensing configurations. Empirical measurements
in dynamic urban microcell (UMi) environments using a 79-GHz FMCW channel
sounder help bridge this gap. Two key findings are demonstrated: (1)
mono-static and bi-static channels exhibit consistently low instantaneous
correlation due to divergent propagation geometries; (2) despite low
instantaneous correlation, both channels share unified temporal consistency,
evolving predictably under environmental kinematics. These insights, validated
across seven real-world scenarios with moving targets/transceivers, inform
robust ISAC system design and future standardization.

</details>


### [190] [Adaptive Phase Shift Information Compression for IRS Systems: A Prompt Conditioned Variable Rate Framework](https://arxiv.org/abs/2511.03923)
*Xianhua Yu,Dong Li,Bowen Gu,Liuqing Yang,Sumei Sun,George K. Karagiannidis*

Main category: eess.SP

TL;DR: 本研究提出了一种新的提示条件PSI压缩系统，通过集成提示学习来解决现有深度学习压缩方法的局限性，实现了低复杂度、高适应性和可变压缩比的PSI压缩，并显著提高了无线网络的性能。


<details>
  <summary>Details</summary>
Motivation: 现有深度学习压缩方法存在解码器复杂度高、对动态信道适应性不足以及压缩比静态等问题，阻碍了IRS技术的实际应用。

Method: 提出了一种提示条件PSI压缩系统，结合了软提示连接和FiLM技术以适应不同的SNR、衰落类型和压缩比；采用变量率技术通过潜在掩码将压缩比集成到提示嵌入中；设计了轻量级的DWCG解码器以降低复杂度。

Result: 仿真结果表明，该框架显著降低了NMSE，并且在各种信道条件下都表现出鲁棒性，同时能够在一个模型中处理可变的压缩比，优于传统的自动编码器基线。

Conclusion: 所提出的框架为下一代无线网络中IRS的实时控制提供了一个可扩展且高效的解决方案。

Abstract: Intelligent reflecting surfaces (IRSs) have become a vital technology for
improving the spectrum and energy efficiency of forthcoming wireless networks.
Nevertheless, practical implementation is obstructed by the excessive overhead
associated with the frequent transmission of phase shift information (PSI) over
bandwidth-constrained control lines. Current deep learning-based compression
methods mitigate this problem but are constrained by elevated decoder
complexity, inadequate flexibility to dynamic channels, and static compression
ratios. This research presents a prompt-conditioned PSI compression system that
integrates prompt learning inspired by large models into the PSI compression
process to address these difficulties. A hybrid prompt technique that
integrates soft prompt concatenation with feature-wise linear modulation (FiLM)
facilitates adaptive encoding across diverse signal-to-noise ratios (SNRs),
fading kinds, and compression ratios. Furthermore, a variable rate technique
incorporates the compression ratio into the prompt embeddings through latent
masking, enabling a singular model to adeptly balance reconstruction accuracy.
Additionally, a lightweight depthwise convolutional gating (DWCG) decoder
facilitates precise feature reconstruction with minimal complexity.
Comprehensive simulations indicate that the proposed framework significantly
reduces NMSE compared to traditional autoencoder baselines, while ensuring
robustness across various channel circumstances and accommodating variable
compression ratios within a single model. These findings underscore the
framework's promise as a scalable and efficient solution for real-time IRS
control in next-generation wireless networks.

</details>


### [191] [Score-Based Quickest Change Detection and Fault Identification for Multi-Stream Signals](https://arxiv.org/abs/2511.03967)
*Wuxia Chen,Sean Moushegian,Vahid Tarokh,Taposh Banerjee*

Main category: eess.SP

TL;DR: 该论文提出了一种名为 min-SCUSUM 的新算法，用于在复杂模型中进行多流最快变故检测和故障隔离，通过使用 Hyvarinen 分数替代对数似然比来克服传统方法的计算挑战。


<details>
  <summary>Details</summary>
Motivation: 传统的最快变故检测算法需要预变故和后变故的明确分布，这对于高维数据计算成本高，并且对于复杂的机器学习模型甚至不可行。

Method: 提出了一种基于 Hyvarinen 分数的算法，名为 min-SCUSUM，它使用分数函数的差值来代替对数似然比，从而解决了计算复杂性问题。

Result: 对所提出的算法进行了延迟和虚警分析，表明其渐近性能取决于变故前后分布的 Fisher 散度。此外，还为区分受影响和未受影响的流提供了故障错误识别概率的上限。

Conclusion: min-SCUSUM 算法是一种有效的方法，可以解决传统算法在处理复杂模型时遇到的计算瓶颈，并在变故检测和故障隔离方面具有良好的性能。

Abstract: This paper introduces an approach to multi-stream quickest change detection
and fault isolation for unnormalized and score-based statistical models.
Traditional optimal algorithms in the quickest change detection literature
require explicit pre-change and post-change distributions to calculate the
likelihood ratio of the observations, which can be computationally expensive
for higher-dimensional data and sometimes even infeasible for complex machine
learning models. To address these challenges, we propose the min-SCUSUM method,
a Hyvarinen score-based algorithm that computes the difference of score
functions in place of log-likelihood ratios. We provide a delay and false alarm
analysis of the proposed algorithm, showing that its asymptotic performance
depends on the Fisher divergence between the pre- and post-change
distributions. Furthermore, we establish an upper bound on the probability of
fault misidentification in distinguishing the affected stream from the
unaffected ones.

</details>


### [192] [Joint Beamforming and Position Design for Movable Antenna Assisted LEO ISAC Systems](https://arxiv.org/abs/2511.03984)
*Hanfu Zhang,Erwu Liu*

Main category: eess.SP

TL;DR: 本论文研究了低地球轨道（LEO）卫星辅助的集成传感与通信（ISAC）系统，并提出了一种利用可移动天线（MA）来解决信号衰减和有限传输功率问题的方法。


<details>
  <summary>Details</summary>
Motivation: 低地球轨道（LEO）卫星通信系统面临信号衰减和传输功率受限的问题，影响了其集成传感与通信（ISAC）的性能。本研究旨在通过引入可移动天线（MA）来克服这些挑战。

Method: 推导了通信信号干扰加噪声比（SINR）和传感平方位置误差界（SPEB）以评估ISAC性能。通过半定规划松弛（SDR）简化了联合优化波束成形和MA位置以最小化SPEB的问题，并提出了一种新颖的交替优化（AO）算法来解决两个子问题。

Result: 仿真结果表明，所提出的AO算法收敛且有效，相比基准方法，在通信和传感性能之间取得了更好的权衡，并且传感性能提升了至少25%。

Conclusion: 提出的MA辅助LEO ISAC系统通过联合优化波束成形和MA位置，有效提高了ISAC性能，特别是在传感方面，为未来的LEO ISAC系统设计提供了有价值的参考。

Abstract: Low earth orbit (LEO) satellite-assisted integrated sensing and
communications (ISAC) systems have been extensively studied to achieve
ubiquitous connectivity. However, the severe signal attenuation and limited
transmit power at LEO satellites can degrade ISAC performance. To address this
issue, this paper investigated movable antenna (MA)-assisted LEO ISAC systems.
We derive the communication signal-to-interference-plus-noise ratio (SINR) and
the sensing squared position error bound (SPEB) for evaluating the ISAC
performance. Then, we jointly optimize the transmit beamforming and the MA
positions to minimize the SPEB under the SINR constraints, total transmit power
constraint, and several inherent physical constraints of the MA array. We first
simplify the complex problem using the semidefinite relaxation (SDR). Then, we
present a novel alternating optimization (AO)-based algorithm to decouple the
original problem into two subproblems, consequently convexified and solved.
Simulations demonstrate the convergence and effectiveness of the proposed
algorithm. Better trade-off between communication and sensing performance, and
at least 25% gain in sensing performance are achieved, compared to the
benchmarks.

</details>


### [193] [Optimal RIS Placement in a Multi-User MISO System with User Randomness](https://arxiv.org/abs/2511.03998)
*Abhishek Rajasekaran,Mehdi Karbalayghareh,Xiaoyan Ma,David J. Love,Christopher G. Brinton*

Main category: eess.SP

TL;DR: 本文提出了一种新颖的RIS部署方法，无需预先知道用户和基站的确切位置，只需了解用户密度和障碍物配置即可，通过递归的粗到精方法优化RIS位置以最大化预期最小信干噪比。


<details>
  <summary>Details</summary>
Motivation: 以往关于RIS部署的研究大多假设基站和用户的确切位置是已知的，这在实际应用中难以实现。然而，实际部署中通常只能预先了解用户密度和障碍物配置。因此，需要一种新的RIS部署方法来解决在用户随机分布和位置未知的情况下优化RIS部署的问题。

Method: 提出了一种非凸优化问题，以最大化系统在用户随机分布情况下的预期最小信干噪比（SINR）。该问题考虑了联合波束成形。为解决该问题，提出了一种递归的粗到精方法：首先，根据障碍物配置确定一组候选RIS位置；然后，在用户分布的多个实例上评估这些候选位置；最后，在每个阶段确定的最优区域内递归地进行搜索，以找到最终的最优RIS部署区域。

Result: 数值结果表明，所提出的RIS部署方法能够有效地确定最优RIS部署区域，从而提升系统的性能。

Conclusion: 本文提出的递归粗到精方法是一种有效的RIS部署策略，尤其适用于用户位置未知但用户密度和障碍物信息可知的场景，能够在实际部署中优化RIS位置以最大化系统性能。

Abstract: It is well established that the performance of reconfigurable intelligent
surface (RIS)-assisted systems critically depends on the optimal placement of
the RIS. Previous works consider either simple coverage maximization or
simultaneous optimization of the placement of the RIS along with the
beamforming and reflection coefficients, most of which assume that the location
of the RIS, base station (BS), and users are known. However, in practice, only
the spatial variation of user density and obstacle configuration are likely to
be known prior to deployment of the system. Thus, we formulate a non-convex
problem that optimizes the position of the RIS over the expected minimum
signal-to-interference-plus-noise ratio (SINR) of the system with user
randomness, assuming that the system employs joint beamforming after
deployment. To solve this problem, we propose a recursive coarse-to-fine
methodology that constructs a set of candidate locations for RIS placement
based on the obstacle configuration and evaluates them over multiple
instantiations from the user distribution. The search is recursively refined
within the optimal region identified in each stage to determine the final
optimal region for RIS deployment. Numerical results are presented to
corroborate our findings.

</details>


### [194] [A Survey on Noise-Based Communication](https://arxiv.org/abs/2511.04011)
*Higo T. P. Da Silva,Hugerles S. Silva,Felipe A. P. Figueiredo,Andre A. Dos Anjos,Rausley A. A. Souza*

Main category: eess.SP

TL;DR: 本综述全面介绍了基于噪声的通信，这是一种用于6G和海量物联网的新兴技术，它利用噪声的统计特性进行信息编码，从而实现超低功耗、安全和隐蔽的通信。


<details>
  <summary>Details</summary>
Motivation: 6G网络和海量物联网的兴起需要超低功耗、安全和隐蔽的无线通信技术。基于噪声的通信提供了一种满足这些需求的新兴范例。

Method: 本综述系统地探讨了基于噪声通信的基本原理和关键方法，包括热噪声调制（TherMod）、噪声调制（NoiseMod）及其变体，以及基尔霍夫定律约翰逊噪声（KLJN）安全密钥交换。此外，还讨论了信道估计和硬件实现等实际挑战，并探讨了同时无线信息和能量传输（SWIPT）以及非正交多址（NOMA）等新兴应用。

Result: 基于噪声的系统在能源效率和隐蔽性方面具有无与伦比的优势。

Conclusion: 基于噪声的通信技术在实现下一代自主和安全无线网络方面具有巨大潜力，未来的研究应继续探索其在能源效率和隐蔽性方面的优势，并克服实际实现中的挑战。

Abstract: The proliferation of sixth-generation (6G) networks and the massive Internet
of Things (IoT) demand wireless communication technologies that are
ultra-low-power, secure, and covert. Noise-based communication has emerged as a
transformative paradigm that meets these demands by encoding information
directly into the statistical properties of noise, rather than using
traditional deterministic carriers. This survey provides a comprehensive
synthesis of this field, systematically exploring its fundamental principles
and key methodologies, including thermal noise modulation (TherMod), noise
modulation (NoiseMod) and its variants, and the Kirchhoff-law-Johnson-noise
(KLJN) secure key exchange. We address critical practical challenges such as
channel estimation and hardware implementation, and highlight emerging
applications in simultaneous wireless information and power transfer (SWIPT)
and non-orthogonal multiple access (NOMA). Our analysis confirms that
noise-based systems offer unparalleled advantages in energy efficiency and
covertness, and we conclude by outlining future research directions to realize
their potential for enabling the next generation of autonomous and secure
wireless networks.

</details>


### [195] [Tiny-WiFo: A Lightweight Wireless Foundation Model for Channel Prediction via Multi-Component Adaptive Knowledge Distillation](https://arxiv.org/abs/2511.04015)
*Haotian Zhang,Shijian Gao,Xiang Cheng*

Main category: eess.SP

TL;DR: 该论文提出了一种名为多组分自适应知识蒸馏（MCAKD）的新框架，用于解决无线基础模型（FM）在大规模部署时遇到的实时性问题。通过引入跨注意力机制的知识选择（CA-KS）模块和自主学习-被动学习（AL-PL）策略，MCAKD能够在可控的计算成本下实现高效的知识迁移。实验结果表明，蒸馏后的Tiny-WiFo模型参数量仅为5.5M，在边缘硬件上的推理时间达到1.6毫秒，同时保留了超过98%的原模型性能和重要的零样本泛化能力，使得FM的实时部署成为可能。


<details>
  <summary>Details</summary>
Motivation: 无线基础模型（FM）由于规模庞大，难以在边缘设备上进行实时部署。

Method: 提出了一种新的多组分自适应知识蒸馏（MCAKD）框架，该框架包含一个跨注意力机制的知识选择（CA-KS）模块，用于识别教师模型中的关键特征，以及一个自主学习-被动学习（AL-PL）策略，用于平衡知识迁移和独立学习，以实现高训练效率和可管理的计算成本。

Result: 蒸馏后的Tiny-WiFo模型拥有5.5M参数，在边缘硬件上实现了1.6毫秒的推理时间，同时保留了98%以上的Wifo FM性能及其关键的零样本泛化能力。

Conclusion: MCAKD框架使得无线基础模型（FM）的实时部署成为可能，通过有效的知识蒸馏解决了大规模模型在边缘设备部署的挑战。

Abstract: The massive scale of Wireless Foundation Models (FMs) hinders their real-time
deployment on edge devices. This letter moves beyond standard knowledge
distillation by introducing a novel Multi-Component Adaptive Knowledge
Distillation (MCAKD) framework. Key innovations include a Cross-Attention-Based
Knowledge Selection (CA-KS) module that selectively identifies critical
features from the teacher model, and an Autonomous Learning-Passive Learning
(AL-PL) strategy that balances knowledge transfer with independent learning to
achieve high training efficiency at a manageable computational cost. When
applied to the WiFo FM, the distilled Tiny-WiFo model, with only 5.5M
parameters, achieves a 1.6 ms inference time on edge hardware while retaining
over 98% of WiFo's performance and its crucial zero-shot generalization
capability, making real-time FM deployment viable.

</details>


### [196] [Ambiguity Function Analysis of AFDM Under Pulse-Shaped Random ISAC Signaling](https://arxiv.org/abs/2511.04200)
*Yuanhan Ni,Fan Liu,Haoran Yin,Yanqun Tang,Zulin Wang*

Main category: eess.SP

TL;DR: 本文研究了集成传感与通信（ISAC）信号体制下，脉冲成形条件下新兴的仿射频分复用（AFDM）波形的模糊函数（AF）。


<details>
  <summary>Details</summary>
Motivation: AFDM波形在ISAC信号体制下，其模糊函数（AF）的特性对传感和通信性能至关重要。本研究旨在分析AFDM波形的AF，并提出一种改进方法以减轻其对弱目标的检测和估计性能的影响。

Method: 首先推导了AFDM波形（无脉冲成形）的平均平方离散周期模糊函数（DPAF）的闭式表达式，然后对AFDM、OFDM和OCDM三种波形的AF进行了综合分析。接着，提出了一种新颖的AFDM参数设计方法，以缓解强目标对弱目标的干扰。最后，推导了脉冲成形随机AFDM波形的平均平方DPAF的闭式表达式。

Result: 结果表明，AFDM、OFDM和OCDM的AF在副瓣区域都存在相同数量的常规凹陷，这会影响弱目标的检测和估计性能。但是，AFDM可以通过调整参数 $c_1$ 来灵活控制凹陷的位置。脉冲成形滤波器在时延轴上产生成形的主瓣，在多普勒轴上产生快速滚降的副瓣。

Conclusion: AFDM波形可以通过调整参数 $c_1$ 来控制其模糊函数的凹陷位置，从而缓解强目标对弱目标的干扰。所提出的AFDM参数设计方法和理论分析得到了数值结果的验证。

Abstract: This paper investigates the ambiguity function (AF) of the emerging affine
frequency division multiplexing (AFDM) waveform for Integrated Sensing and
Communication (ISAC) signaling under a pulse shaping regime. Specifically, we
first derive the closed-form expression of the average squared discrete period
AF (DPAF) for AFDM waveform without pulse shaping, revealing that the AF
depends on the parameter $c_1$ and the kurtosis of random communication data,
while being independent of the parameter $c_2$. As a step further, we conduct a
comprehensive analysis on the AFs of various waveforms, including AFDM,
orthogonal frequency division multiplexing (OFDM) and orthogonal chirp-division
multiplexing (OCDM). Our results indicate that all three waveforms exhibit the
same number of regular depressions in the sidelobes of their AFs, which incurs
performance loss for detecting and estimating weak targets. However, the AFDM
waveform can flexibly control the positions of depressions by adjusting the
parameter $c_1$, which motivates a novel design approach of the AFDM parameters
to mitigate the adverse impact of depressions of the strong target on the weak
target. Furthermore, a closed-form expression of the average squared DPAF for
pulse-shaped random AFDM waveform is derived, which demonstrates that the pulse
shaping filter generates the shaped mainlobe along the delay axis and the rapid
roll-off sidelobes along the Doppler axis. Numerical results verify the
effectiveness of our theoretical analysis and proposed design methodology for
the AFDM modulation.

</details>


### [197] [BTTDA: Block-Term Tensor Discriminant Analysis for Brain-Computer Interfacing](https://arxiv.org/abs/2511.04292)
*Arne Van Den Kerchove,Hakim Si-Mohammed,François Cabestaing,Marc M. Van Hulle*

Main category: eess.SP

TL;DR: 该研究提出了一种名为块项张量判别分析（BTTDA）的新型张量分解方法，用于从脑电图（EEG）信号中提取特征，以提高脑机接口（BCI）的分类准确性。


<details>
  <summary>Details</summary>
Motivation: 传统的基于张量的方法（如Tucker和PARAFAC分解）在处理复杂的EEG数据时缺乏灵活性。本研究旨在通过一种更灵活的张量分解方法来改进EEG信号的特征提取和分类。

Method: 提出了一种名为块项张量判别分析（BTTDA）的新型张量分解方法，该方法扩展了高阶判别分析（HODA），并结合了前向模型和投影方案来迭代提取判别性块项，从而实现多线性降维。

Result: 在事件相关电位（ERP）解码方面，BTTDA和PARAFACDA的表现显著优于传统HODA方法，达到了91.25%的ROC-AUC。在运动想象（MI）解码方面，虽然所有方法的表现均不理想，但BTTDA（64.52%）仍显著优于HODA（61.00%）。

Conclusion: BTTDA通过其块项结构实现了可解释且高效的降维，而不会损害判别能力，为BCI和更广泛的神经成像应用提供了有前景且适应性强的方法。

Abstract: Brain-computer interfaces (BCIs) allow direct communication between the brain
and external devices, frequently using electroencephalography (EEG) to record
neural activity. Dimensionality reduction and structured regularization are
essential for effectively classifying task-related brain signals, including
event-related potentials (ERPs) and motor imagery (MI) rhythms. Current
tensor-based approaches, such as Tucker and PARAFAC decompositions, often lack
the flexibility needed to fully capture the complexity of EEG data. This study
introduces Block-Term Tensor Discriminant Analysis (BTTDA): a novel
tensor-based and supervised feature extraction method designed to enhance
classification accuracy by providing flexible multilinear dimensionality
reduction. Extending Higher Order Discriminant Analysis (HODA), BTTDA uses a
novel and interpretable forward model for HODA combined with a deflation scheme
to iteratively extract discriminant block terms, improving feature
representation for classification. BTTDA and a sum-of-rank-1-terms variant
PARAFACDA were evaluated on publicly available ERP (second-order tensors) and
MI (third-order tensors) EEG datasets from the MOABB benchmarking framework.
Benchmarking revealed that BTTDA and PARAFACDA significantly outperform the
traditional HODA method in ERP decoding, resulting in state-of-the art
performance (ROC-AUC = 91.25%). For MI, decoding results of HODA, BTTDA and
PARAFACDA were subpar, but BTTDA still significantly outperformed HODA (64.52%
> 61.00%). The block-term structure of BTTDA enables interpretable and more
efficient dimensionality reduction without compromising discriminative power.
This offers a promising and adaptable approach for feature extraction in BCI
and broader neuroimaging applications.

</details>


### [198] [RCMCL: A Unified Contrastive Learning Framework for Robust Multi-Modal (RGB-D, Skeleton, Point Cloud) Action Understanding](https://arxiv.org/abs/2511.04351)
*Hasan Akgul,Mari Eplik,Javier Rojas,Akira Yamamoto,Rajesh Kumar,Maya Singh*

Main category: eess.SP

TL;DR: RCMCL是一个自监督框架，通过跨模态对比学习、模态内自蒸馏和退化模拟来学习模态不变的表示，以提高多模态人类动作识别的鲁棒性，并在传感器故障或噪声时保持可靠性。


<details>
  <summary>Details</summary>
Motivation: 在传感器故障或噪声时，多模态人类动作识别的准确性会急剧下降。现有的方法通常依赖大型标记数据集，并且在模态丢失或损坏时性能会下降。

Method: RCMCL框架联合优化了三个目标：1. 跨模态对比学习目标，对齐异构数据流。 2. 模态内自蒸馏目标，提高视图不变性并减少冗余。 3. 退化模拟目标，显式训练模型从掩码或损坏的输入中恢复。在推理时，自适应模态门控（AMG）网络为每个模态分配数据驱动的可靠性权重，以实现鲁棒的融合。

Result: 在NTU RGB+D 120（CS/CV）和UWA3D-II数据集上，RCMCL在标准设置下达到了最先进的准确性，并在严重双模态丢弃的情况下仅下降了11.5%，显著优于强监督融合基线。

Conclusion: 自监督跨模态对齐、显式退化建模和自适应融合是可部署的多模态人类动作识别的关键。

Abstract: Human action recognition (HAR) with multi-modal inputs (RGB-D, skeleton,
point cloud) can achieve high accuracy but typically relies on large labeled
datasets and degrades sharply when sensors fail or are noisy. We present Robust
Cross-Modal Contrastive Learning (RCMCL), a self-supervised framework that
learns modality-invariant representations and remains reliable under modality
dropout and corruption. RCMCL jointly optimizes (i) a cross-modal contrastive
objective that aligns heterogeneous streams, (ii) an intra-modal
self-distillation objective that improves view-invariance and reduces
redundancy, and (iii) a degradation simulation objective that explicitly trains
models to recover from masked or corrupted inputs. At inference, an Adaptive
Modality Gating (AMG) network assigns data-driven reliability weights to each
modality for robust fusion. On NTU RGB+D 120 (CS/CV) and UWA3D-II, RCMCL
attains state-of-the-art accuracy in standard settings and exhibits markedly
better robustness: under severe dual-modality dropout it shows only an 11.5%
degradation, significantly outperforming strong supervised fusion baselines.
These results indicate that self-supervised cross-modal alignment, coupled with
explicit degradation modeling and adaptive fusion, is key to deployable
multi-modal HAR.

</details>


### [199] [High-Resolution Forest Mapping from L-Band Interferometric SAR Time Series using Deep Learning over Northern Spain](https://arxiv.org/abs/2511.04362)
*Chiara Telli,Oleg Antropov,Anne Lönnqvist,Marco Lavalle*

Main category: eess.SP

TL;DR: 利用L波段干涉测量时间序列数据和深度学习模型进行高分辨率森林绘图。


<details>
  <summary>Details</summary>
Motivation: 研究高分辨率森林绘图的潜力，重点是利用L波段干涉测量时间序列数据和深度学习模型。

Method: 使用ALOS-2 PALSAR-2双极化SAR影像的时间序列，并结合来自UNet家族的几种深度学习模型（包括Vanilla UNet、SeU-Net和具有嵌套结构的高级UNet模型）。研究了各种极化和干涉特征，并与基于模型的方法和传统机器学习方法进行了比较。

Result: 研究结果表明，与仅使用后向散射强度相比，添加基于模型的方法反演的干涉测量特征或干涉测量相干层可以提高检索精度。注意力机制和嵌套连接融合提供了比Vanilla UNet或传统机器学习方法更好的预测效果。在20米分辨率下，当仅使用强度数据时，森林高度检索精度在3.1-3.8米（R2 = 0.45-0.55）之间；当同时使用强度和干涉相干特征时，精度提高到2.8米以下。在40米和60米分辨率下，检索性能进一步提高。当在60米分辨率下使用强度时，最佳RMSE为2.2米；当使用所有合适的输入特征时，RMSE为1.95米。

Conclusion: 推荐这种混合方法用于L波段SAR检索，该方法也适用于NISAR和未来的ROSE-L任务。

Abstract: In this study, we examine the potential of high-resolution forest mapping
using L-band interferometric time series datasets and deep learning modeling.
Our SAR data are represented by a time series of nine ALOS-2 PALSAR-2 dual-pol
SAR images acquired at near-zero spatial baseline over a study site in
Asturias, Northern Spain. Reference data are collected using airborne laser
scanning. We examine the performance of several candidate deep learning models
from UNet-family with various combinations of input polarimetric and
interferometric features. In addition to basic Vanilla UNet, attention
reinforced UNet model with squeeze-excitation blocks (SeU-Net) and advanced
UNet model with nested structure and skip pathways are used. Studied features
include dual pol interferometric observables additionally incorporating
model-based derived measures. Results show that adding model-based inverted
InSAR features or InSAR coherence layers improves retrieval accuracy compared
to using backscatter intensity only. Use of attention mechanisms and nested
connection fusion provides better predictions than using Vanilla UNet or
traditional machine learning methods. Forest height retrieval accuracies range
between 3.1-3.8 m (R2 = 0.45--0.55) at 20 m resolution when only intensity data
are used, and improve to less than 2.8 m when both intensity and
interferometric coherence features are included. At 40 m and 60 m resolution,
retrieval performance further improves, primarily due to higher SNR in both the
intensity and interferometric layers. When using intensity at 60 m resolution,
best achieved RMSE is 2.2 m, while when using all suitable input features the
achieved error is 1.95 m. We recommend this hybrid approach for L-band SAR
retrievals also suitable for NISAR and future ROSE-L missions.

</details>


### [200] [A Lightweight Framework for Integrated Sensing and Communications with RIS](https://arxiv.org/abs/2511.04448)
*Chu Li,Kevin Weinberger,Aydin Sezgin*

Main category: eess.SP

TL;DR: 提出了一种轻量级的RIS相位设计框架，通过将RIS配置划分为两部分，一部分最大化通信性能，另一部分通过引入微小扰动生成多个波束以实现多目标传感，从而解决了现有RIS优化方法计算复杂度高和子最优解的问题，并实现了与SDR相当但计算复杂度显著降低的性能。


<details>
  <summary>Details</summary>
Motivation: 现有RIS优化方法（如SDR或迭代算法）在ISAC系统中存在计算复杂度高、可扩展性差或易获得次优解等问题，难以满足未来6G网络对RIS性能的需求。

Method: 将RIS配置划分为两部分：第一部分最大化通信性能，第二部分通过引入小扰动生成多目标传感所需的多个波束，从而得到闭式解。

Result: 仿真结果表明，该方法在通信和传感性能上与SDR方法相当，但计算复杂度显著降低。

Conclusion: 所提出的轻量级RIS相位设计框架能够有效地在通信和传感性能之间取得平衡，并为多目标传感提供支持，同时大大降低了计算复杂度。

Abstract: Reconfigurable Intelligent Surfaces (RIS) have been recognized as a promising
technology to enhance both communication and sensing performance in integrated
sensing and communication (ISAC) systems for future 6G networks. However,
existing RIS optimization methods for improving ISAC performance are mainly
based on semidefinite relaxation (SDR) or iterative algorithms. The former
suffers from high computational complexity and limited scalability, especially
when the number of RIS elements becomes large, while the latter yields
suboptimal solutions whose performance depends on initialization. In this work,
we introduce a lightweight RIS phase design framework that provides a
closed-form solution and explicitly accounts for the trade-off between
communication and sensing, as well as proportional beam gain distribution
toward multiple sensing targets. The key idea is to partition the RIS
configuration into two parts: the first part is designed to maximize the
communication performance, while the second introduces small perturbations to
generate multiple beams for multi-target sensing. Simulation results validate
the effectiveness of the proposed approach and demonstrate that it achieves
performance comparable to SDR but with significantly lower computational
complexity.

</details>


### [201] [An Area-Efficient 20-100-GHz Phase-Invariant Switch-Type Attenuator Achieving 0.1-dB Tuning Step in 65-nm CMOS](https://arxiv.org/abs/2511.04635)
*Qingbin Li,Jian Pang*

Main category: eess.SP

TL;DR: 该论文提出了一种工作频率在20至100 GHz的开关型衰减器，采用了容性补偿技术来减少相位误差，并使用金属线实现小电阻以降低寄生电容，从而在宽频带内减小了幅度和相位误差，并减小了芯片面积。通过采用连续调谐衰减单元，提高了衰减精度。该衰减器采用标准的65nm CMOS工艺设计和制造，测量结果显示在20-100 GHz频率范围内具有7.5 dB的相对衰减范围和连续的调谐步长，插入损耗在1.6-3.8 dB之间，回波损耗优于11.5 dB，均方根幅度和相位误差分别低于0.15 dB和1.6度。


<details>
  <summary>Details</summary>
Motivation: 该研究旨在开发一种在20至100 GHz宽频率范围内工作的开关型衰减器，并解决现有技术中存在的相位误差、幅度和相位误差以及芯片面积等问题。

Method: 本研究提出了一种采用容性补偿技术来减少相位误差的开关型衰减器。通过使用金属线实现小电阻，以降低寄生电容，从而在宽频率范围内减小了幅度和相位误差。同时，采用连续调谐衰减单元来提高衰减精度。该衰减器采用标准的65nm CMOS工艺设计和制造。

Result: 测量结果显示，该衰减器在20-100 GHz的频率范围内具有7.5 dB的相对衰减范围和连续的调谐步长。插入损耗在1.6-3.8 dB之间，回波损耗优于11.5 dB。均方根幅度和相位误差分别低于0.15 dB和1.6度。

Conclusion: 本研究成功设计并制造了一种高性能的开关型衰减器，其在20-100 GHz的宽频率范围内表现出优异的性能，包括精确的衰减控制、低插入损耗、良好的回波损耗以及极低的幅度和相位误差。该设计通过采用容性补偿和金属线实现电阻等技术，有效解决了宽频带应用中的挑战。

Abstract: This paper presents a switch-type attenuator working from 20 to 100 GHz. The
attenuator adopts a capacitive compensation technique to reduce phase error.
The small resistors in this work are implemented with metal lines to reduce the
intrinsic parasitic capacitance, which helps minimize the amplitude and phase
errors over a wide frequency range. Moreover, the utilization of metal lines
also reduces the chip area. In addition, a continuous tuning attenuation unit
is employed to improve the overall attenuation accuracy of the attenuator. The
passive attenuator is designed and fabricated in a standard 65nm CMOS. The
measurement results reveal a relative attenuation range of 7.5 dB with a
continuous tuning step within 20-100 GHz. The insertion loss is 1.6-3.8 dB
within the operation band, while the return losses of all states are better
than 11.5 dB. The RMS amplitude and phase errors are below 0.15 dB and
1.6{\deg}, respectively.

</details>


<div id='physics.app-ph'></div>

# physics.app-ph [[Back]](#toc)

### [202] [Accurate humidity and pH synchronized measurement with temperature compensation based on polarization maintaining fiber](https://arxiv.org/abs/2511.04203)
*Jia Liu,Jiawen Zhang,Xiyu Liu,Qi Meng,Riming Xu,Jin Wang*

Main category: physics.app-ph

TL;DR: 该论文提出了一种基于偏振保持光纤（PMF）的多参数（湿度、pH、温度）传感方法，解决了现有传感技术的局限性。


<details>
  <summary>Details</summary>
Motivation: 为了解决现有湿度和pH测量在灵敏度、信号串扰、系统复杂性和实时性方面存在的不足。

Method: 通过在PMF表面修饰复合湿度敏感聚合物（PVA/CNs）和pH敏感纳米薄膜（PAH/PAA），并结合温度补偿和多波长矩阵，实现了对湿度、pH和温度的同时实时监测。

Result: 成功实现了对湿度、pH和温度的同时实时监测，并有效解决了温度串扰问题。

Conclusion: 该方法为构建通用的光纤多参数测量平台提供了新的途径，并且有效地解决了现有传感技术的局限性。

Abstract: Real-time and accurate monitoring of humidity and pH is of great significance
in daily life and industrial production. Existing humidity and pH measurement
suffer from limitations such as low sensitivity, signal crosstalk, complex
system structures, and inability to achieve real-time monitoring. In this work,
the surface of a polarization maintaining fiber (PMF) was functionalized with a
composite humidity-sensitive polymer composed of polyvinyl alcohol (PVA) and
carbon nanosheets (CNs). A humidity-sensitive film with a microporous structure
was prepared on the PMF cladding through high-temperature rapid film formation
and laser processing, enhancing humidity sensitivity and stability. To enable
pH sensing, poly(allylamine hydrochloride) (PAH) and poly (acrylic acid) (PAA)
were successively adsorbed onto the PMF surface via electrostatic
self-assembly, forming a pH-sensitive nanofilm structure. By connecting a
temperature-compensated PMF within the same Sagnac loop and combining it with a
multi-wavelength matrix, simultaneous real-time monitoring of humidity, pH, and
temperature was achieved, effectively solving the issue of temperature
crosstalk and extending toward a universal optical fiber multi-parameter
measurement platform.

</details>


### [203] [Matching frequency response measurements and reduced order models for the inverse identification of viscoelastic properties](https://arxiv.org/abs/2511.04395)
*Linus Taenzer,Paolo Tiso,Bart Van Damme*

Main category: physics.app-ph

TL;DR: 本研究提出了一种结合降阶模型和约束粒子群优化的逆材料表征方法，用于识别3D打印材料（POM和烧结陶瓷）的粘弹性特性，并通过实验数据验证了该方法的有效性和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 为了在有限元模拟中准确地表征3D打印材料（如陶瓷和聚合物）随频率变化的力学特性，并了解阻尼行为在产品开发中的关键作用，需要对材料进行精确的逆向表征。

Method: 本研究采用降阶模型和约束粒子群优化技术，拟合激光多普勒测振仪获得的点测量频率响应函数，以识别材料参数。

Result: 该方法能够精确识别定义粘弹性分数阶导数模型的参数及其不确定性，并证明了该方法在处理边界条件和噪声等实际实验数据时的适用性。

Conclusion: 所提出的逆材料表征方法能够有效地识别3D打印材料的粘弹性特性，并能在存在实际实验数据困难的情况下得到验证。

Abstract: 3D-printed materials are used in many different industries (automotive,
aviation, medicine, etc.). Most of these 3D-printed materials are based on
ceramics or polymers whose mechanical properties vary with frequency. For
numerical modeling, it is crucial to characterize this frequency dependency
accurately to enable realistic finite-element simulations. At the same time,
the damping behavior plays a key role in product development, since it governs
a component's response at resonance and thus impacts both performance and
longevity. In current research, inverse material characterization methods are
getting more and more popular. However, their practical validation and
applicability on real measurement data have not yet been discussed widely. In
this work, we show the identification of two different materials, POM and
additively manufactured sintered ceramics, and validate it with experimental
data of a well-established measurement technique (dynamic mechanical analysis).
The material identification process considers state-of-the-art reduced-order
modeling and constrained particle swarm optimization, which are used to fit the
frequency response functions of point measurements obtained by a laser Doppler
vibrometer. This work shows the quality of the method in identifying the
parameters defining the viscoelastic fractional derivative model, including
their uncertainty. It also illustrates the applicability of this identification
method in the presence of practical difficulties that come along with
experimental data such as boundary conditions and noise.

</details>


### [204] [Self-mixing-based photoacoustic sensing](https://arxiv.org/abs/2511.04532)
*Tecla Gabbrielli,Jacopo Pelini,Chenhong Zhang,Francesco Cappelli,Mario Siciliani de Cumis,Stefano Dello Russo,Maria Concetta Canino,Alberto Roncaglia,Paolo De Natale,Simone Borri*

Main category: physics.app-ph

TL;DR: 一种新型气体传感器，结合了光声光谱和反馈干涉测量技术，实现了高灵敏度、小型化和易于处理的优点，适用于多种现场应用。


<details>
  <summary>Details</summary>
Motivation: 开发一种多功能、超紧凑、易于处理、高灵敏度的传感器，用于现场关键应用，如医疗诊断、安全评估和环境控制。

Method: 结合光声光谱和反馈干涉测量技术，并采用自混合读出机制。

Result: 该传感器实现了与现有笨重设备相当的读出灵敏度，在信噪比和最小检测限方面具有相同的光谱性能。同时，自混合读出机制减小了尺寸，降低了基线，提高了对低浓度气体的检测能力。

Conclusion: 这种新型传感器结合了光声光谱和反馈干涉测量技术的优点，具有尺寸小、灵敏度高、易于处理和光谱范围可调的特点，为未来传感器的小型化和集成提供了可能性，并在气体检测领域具有广泛的应用前景。

Abstract: Versatile, ultracompact, easy-to-handle, high-sensitivity sensors are
compelling tools for in situ pivotal applications, such as medical diagnostics,
security and safety assessments, and environmental control. In this work, we
combine photoacoustic spectroscopy and feedback interferometry, proposing a
novel trace-gas sensor equipped with a self-mixing readout. This scheme
demonstrates a readout sensitivity comparable to that of bulkier
state-of-the-art balanced Michelson-interferometric schemes, achieving the same
spectroscopic performance in terms of signal-to-noise ratio (SNR) and minimum
detection limit (MDL). At the same time, the self-mixing readout benefits from
a reduced size and a lower baseline, paving the way for future system
downsizing and integration while offering a higher detectability for lower gas
concentrations. Moreover, the intrinsic wavelength independence of both
self-mixing and photoacoustic techniques allows the applicability and
tailorability of the sensor to any desired spectral range.

</details>


<div id='eess.SY'></div>

# eess.SY [[Back]](#toc)

### [205] [On excitation of control-affine systems and its use for data-driven Koopman approximants](https://arxiv.org/abs/2511.03734)
*Philipp Schmitz,Lea Bold,Friedrich M. Philipp,Mario Rosenfelder,Peter Eberhard,Henrik Ebel,Karl Worthmann*

Main category: eess.SY

TL;DR: 提出一种数据拟合框架，用于控制仿射系统，以提高系统辨识的鲁棒性，从而提供更可靠的双线性扩展动态模式分解（EDMD）方案。


<details>
  <summary>Details</summary>
Motivation: 控制仿射系统的双线性模型通常需要大量数据，限制了其应用。本研究旨在解决此问题。

Method: 提出一种用于控制仿射映射的数据拟合框架，并通过子空间角度推导出输入选择指南，以确保最小奇异值的期望阈值。此外，还推导了最大化最小奇异值的最优性条件。

Result: 所提出方法在非完整机器人双线性EDMD控制应用中得到验证，证明了其有效性。

Conclusion: 本研究提出的数据拟合框架和输入选择指南能够提高双线性EDMD方案的鲁棒性和可靠性，为控制仿射系统的建模、分析和控制提供了更有效的工具。

Abstract: The Koopman operator and extended dynamic mode decomposition (EDMD) as a
data-driven technique for its approximation have attracted considerable
attention as a key tool for modeling, analysis, and control of complex
dynamical systems. However, extensions towards control-affine systems resulting
in bilinear surrogate models are prone to demanding data requirements rendering
their applicability intricate. In this paper, we propose a framework for
data-fitting of control-affine mappings to increase the robustness margin in
the associated system identification problem and, thus, to provide more
reliable bilinear EDMD schemes. In particular, guidelines for input selection
based on subspace angles are deduced such that a desired threshold with respect
to the minimal singular value is ensured. Moreover, we derive necessary and
sufficient conditions of optimality for maximizing the minimal singular value.
Further, we demonstrate the usefulness of the proposed approach using bilinear
EDMD with control for non-holonomic robots.

</details>


### [206] [Hybrid ILM-NILM Smart Plug System](https://arxiv.org/abs/2511.03737)
*Dániel István Németh,Kálmán Tornai*

Main category: eess.SY

TL;DR: 通过将多个电器连接到单个智能插头，可以降低安装成本，但会牺牲一定的控制粒度。


<details>
  <summary>Details</summary>
Motivation: 智能插头虽然可以控制单个电器，但安装成本高昂，而多电器插孔方法虽然安装成本低，但无法控制单个电器。该研究旨在结合两者的优点。

Method: 提出了一种混合负载分类解决方案，该方案将多个负载连接到单个智能插头。

Result: 该方法可以降低系统的安装成本，但会牺牲一定的控制粒度。

Conclusion: 将多个负载连接到单个智能插头是一种在降低安装成本和控制粒度之间取得平衡的方法，尤其适用于家庭环境。

Abstract: Electrical load classification is generally divided into intrusive and
non-intrusive approaches, both having their limitations and advantages. With
the non-intrusive approach, controlling appliances is not possible, but the
installation cost of a single measurement device is cheap. In comparison,
intrusive, smart plug-based solutions offer individual appliance control, but
the installation cost is much higher. There have been very few approaches
aiming to combine these methods. In this paper we show that extending a smart
plug-based solution to multiple loads per plug can reduce control granularity
in favor of lowering the system's installation costs. Connecting various loads
to a Smart Plug through an extension cord is seldom considered in the
literature, even though it is common in households. This scenario is also
handled by the hybrid load classification solution presented in this paper.

</details>


### [207] [Kalman-Bucy Filtering with Randomized Sensing: Fundamental Limits and Sensor Network Design for Field Estimation](https://arxiv.org/abs/2511.03740)
*Xinyi Wang,Devansh R. Agrawal,Dimitra Panagou*

Main category: eess.SY

TL;DR: 随机丢失测量下的卡尔曼滤波器稳定性问题已得到广泛研究。本文在一般的连续时间框架下重新审视了这个问题，其中测量矩阵和噪声协方差都作为随机过程演变，以捕捉传感位置的变化。在此框架下，我们推导了连续时间卡尔曼滤波的期望估计协方差的闭式上界。然后，我们将此框架应用于时空场估计，其中场被建模为高斯过程，并通过随机位置、带噪声的传感器进行观测。利用我们早期工作中引入的、作为随机变量微分熵的重标度形式的清晰度（clarity），我们为空间平均期望清晰度建立了一个与网格无关的下界。该结果通过一个复合传感参数揭示了基本的性能限制，该参数共同捕捉了传感器数量、噪声水平和测量频率的影响。模拟证实，所提出的界限对于离散时间卡尔曼滤波器来说是紧密的，随着测量速率的降低而接近它，同时避免了离散时间公式所需的递归计算。最重要的是，推导出的限制为部署前的传感器网络设计问题提供了原则性和有效的指导。


<details>
  <summary>Details</summary>
Motivation: 卡尔曼滤波器在随机丢失测量下的稳定性分析是一个广泛研究的问题。本文旨在提供一个更一般的连续时间框架，并推导出期望估计协方差的闭式上界，同时应用于时空场估计，并建立清晰度的下界，以揭示基本性能限制并为传感器网络设计提供指导。

Method: 在一般的连续时间框架下，将测量矩阵和噪声协方差视为随机过程。推导出连续时间卡尔曼滤波的期望估计协方差的闭式上界。将此框架应用于时空场估计，将场建模为高斯过程，并通过随机位置、带噪声的传感器进行观测。利用清晰度（clarity）建立空间平均期望清晰度的与网格无关的下界。

Result: 推导了连续时间卡尔曼滤波的期望估计协方差的闭式上界。建立了空间平均期望清晰度的与网格无关的下界，该下界揭示了由传感器数量、噪声水平和测量频率共同决定的基本性能限制。模拟结果表明，该界限对于离散时间卡尔曼滤波器是紧密的，并且在测量速率降低时接近该界限，同时避免了递归计算。

Conclusion: 本文提出的框架和推导出的界限为理解和设计传感器网络提供了原则性和高效的指导，尤其是在处理随机丢失测量和时空场估计等问题时。该方法能够紧密地界定性能，并有效指导传感器网络的设计。

Abstract: Stability analysis of the Kalman filter under randomly lost measurements has
been widely studied. We revisit this problem in a general continuous-time
framework, where both the measurement matrix and noise covariance evolve as
random processes, capturing variability in sensing locations. Within this
setting, we derive a closed-form upper bound on the expected estimation
covariance for continuous-time Kalman filtering. We then apply this framework
to spatiotemporal field estimation, where the field is modeled as a Gaussian
process observed by randomly located, noisy sensors. Using clarity, introduced
in our earlier work as a rescaled form of the differential entropy of a random
variable, we establish a grid-independent lower bound on the spatially averaged
expected clarity. This result exposes fundamental performance limits through a
composite sensing parameter that jointly captures the effects of the number of
sensors, noise level, and measurement frequency. Simulations confirm that the
proposed bound is tight for the discrete-time Kalman filter, approaching it as
the measurement rate decreases, while avoiding the recursive computations
required in the discrete-time formulation. Most importantly, the derived limits
provide principled and efficient guidelines for sensor network design problem
prior to deployment.

</details>


### [208] [Electric Vehicle Charging Load Modeling: A Survey, Trends, Challenges and Opportunities](https://arxiv.org/abs/2511.03741)
*Xiachong Lin,Arian Prabowo,Imran Razzak,Hao Xue,Matthew Amos,Sam Behrens,Flora D. Salim*

Main category: eess.SY

TL;DR: 本文对过去五年电动汽车充电负荷模型进行了全面的文献综述，将现有模型分为统计、模拟和数据驱动方法，并分析了信息融合在其中的应用。


<details>
  <summary>Details</summary>
Motivation: 预测电动汽车充电行为对于基础设施规划和优化至关重要，但现有研究缺乏对信息融合建模方法的系统分析。

Method: 对过去五年的电动汽车充电负荷模型进行文献综述，将模型方法分为统计、模拟和数据驱动，并分析了信息融合在其中的应用。

Result: 对现有模型方法的优缺点进行了评估，并分析了信息融合在模型中的三个底层操作。

Conclusion: 讨论了电动汽车充电负荷建模领域的挑战与机遇，并为未来的研究方向提供了指导。

Abstract: The evolution of electric vehicles (EVs) is reshaping the automotive
industry, advocating for more sustainable transportation practices. Accurately
predicting EV charging behavior is essential for effective infrastructure
planning and optimization. However, the charging load of EVs is significantly
influenced by uncertainties and randomness, posing challenges for accurate
estimation. Furthermore, existing literature reviews lack a systematic analysis
of modeling approaches focused on information fusion. This paper
comprehensively reviews EV charging load models from the past five years. We
categorize state-of-the-art modeling methods into statistical, simulated, and
data-driven approaches, examining the advantages and drawbacks of each.
Additionally, we analyze the three bottom-up level operations of information
fusion in existing models. We conclude by discussing the challenges and
opportunities in the field, offering guidance for future research endeavors to
advance our understanding and explore practical research directions.

</details>


### [209] [A Model-Based Approach to Automated Digital Twin Generation in Manufacturing](https://arxiv.org/abs/2511.03742)
*Angelos Alexopoulos,Agorakis Bompotas,Nikitas Rigas Kalogeropoulos,Panagiotis Kechagias,Athanasios P. Kalogeras,Christos Alexakos*

Main category: eess.SY

TL;DR: 该论文提出了一个自动化数字孪生（DT）生成和部署的平台，利用基于AutomationML的工厂计划，并结合生成式人工智能（GAI）驱动的仿真场景生成器和物理生产线自动重构，以提高制造效率和适应性。


<details>
  <summary>Details</summary>
Motivation: 现代制造业需要高灵活性和可重构性来适应动态生产需求。虽然模型基础工程（MBE）支持快速生产线设计，但最终的重构需要仿真和验证。数字孪生（DT）可以通过实时监控、仿真和重构来简化此过程。

Method: 提出一个自动化DT生成和部署的平台，使用基于AutomationML的工厂计划，并结合GAI驱动的仿真场景生成器和物理生产线自动重构。

Result: 该平台能够自动化DT的生成和部署，并通过GAI驱动的仿真场景生成器和自动物理生产线重构来提高效率和适应性。

Conclusion: 通过自动化DT生成、部署和物理重构，该平台能够显著提高制造业的效率和适应性。

Abstract: Modern manufacturing demands high flexibility and reconfigurability to adapt
to dynamic production needs. Model-based Engineering (MBE) supports rapid
production line design, but final reconfiguration requires simulations and
validation. Digital Twins (DTs) streamline this process by enabling real-time
monitoring, simulation, and reconfiguration. This paper presents a novel
platform that automates DT generation and deployment using AutomationML-based
factory plans. The platform closes the loop with a GAI-powered simulation
scenario generator and automatic physical line reconfiguration, enhancing
efficiency and adaptability in manufacturing.

</details>


### [210] [A convolutional neural network deep learning method for model class selection](https://arxiv.org/abs/2511.03743)
*Marios Impraimakis*

Main category: eess.SY

TL;DR: 该研究提出了一种新颖的深度卷积神经网络方法，用于从信号响应中选择模型类别，无需系统输入信息。


<details>
  <summary>Details</summary>
Motivation: 研究的动机是开发一种无需完整系统识别即可选择模型类别的方法，特别是在存在细微信号变化的情况下。

Method: 该方法使用信号响应及其类别信息来训练和验证一维卷积神经网络。此外，还探讨了使用卡尔曼滤波器融合系统响应信号的物理增强算法。

Result: 该方法能够识别线性、非线性动态系统以及 3D 建筑有限元模型中的模型类别，即使在阻尼行为或迟滞行为导致信号发生细微变化时也能识别。

Conclusion: 所提出的方法能够有效地从信号响应中选择模型类别，即使在存在细微信号变化的情况下，也为结构健康监测提供了强大的工具。

Abstract: The response-only model class selection capability of a novel deep
convolutional neural network method is examined herein in a simple, yet
effective, manner. Specifically, the responses from a unique degree of freedom
along with their class information train and validate a one-dimensional
convolutional neural network. In doing so, the network selects the model class
of new and unlabeled signals without the need of the system input information,
or full system identification. An optional physics-based algorithm enhancement
is also examined using the Kalman filter to fuse the system response signals
using the kinematics constraints of the acceleration and displacement data.
Importantly, the method is shown to select the model class in slight signal
variations attributed to the damping behavior or hysteresis behavior on both
linear and nonlinear dynamic systems, as well as on a 3D building finite
element model, providing a powerful tool for structural health monitoring
applications.

</details>


### [211] [Predictive Compensation in Finite-Horizon LQ Games under Gauss-Markov Deviations](https://arxiv.org/abs/2511.03744)
*Navid Mojahed,Mahdis Rabbani,Shima Nazari*

Main category: eess.SY

TL;DR: 本文提出了一个预测性补偿框架，用于解决有限时间离散时间线性二次动态博弈中存在的基于反馈纳什策略的高斯-马尔可夫偏差问题。其中一个参与者会经历相关的随机偏差，该偏差通过一阶自回归过程建模，而另一个参与者则采用预测性策略进行补偿，以预测未来相关性的影响。论文推导了均值和协方差传播的闭式递归，并通过期望成本的敏感性分析了由此产生的性能改进。


<details>
  <summary>Details</summary>
Motivation: 动态博弈中，参与者可能存在随机偏差，影响博弈结果。本文旨在解决一类特定的动态博弈问题，即有限时间离散时间线性二次动态博弈，其中一个参与者存在与高斯-马尔可夫过程相关的偏差。

Method: 本文提出了一种预测性补偿框架，利用闭式递归推导了均值和协方差传播，并通过敏感性分析来评估性能改进。

Result: 成功推导了在存在特定随机偏差的情况下，动态博弈中均值和协方差传播的闭式递归，并分析了预测性补偿策略带来的性能提升。

Conclusion: 预测性补偿框架能够有效应对有限时间离散时间线性二次动态博弈中，由高斯-马尔可夫偏差引起的问题，并通过预测未来相关性的影响来提升博弈性能。

Abstract: This paper presents a predictive compensation framework for finite-horizon
discrete-time linear quadratic dynamic games in the presence of Gauss-Markov
deviations from feedback Nash strategies. One player experiences correlated
stochastic deviations, modeled via a first-order autoregressive process, while
the other compensates using a predictive strategy that anticipates the effect
of future correlation. Closed-form recursions for mean and covariance
propagation are derived, and the resulting performance improvement is analyzed
through the sensitivity of expected cost.

</details>


### [212] [InvSim algorithm for pre-computing airplane flight controls in limited-range autonomous missions, and demonstration via double-roll maneuver of Mirage III fighters](https://arxiv.org/abs/2511.03745)
*Osama A. Marzouk*

Main category: eess.SY

TL;DR: 本文提出了一个用于飞行力学逆仿真的通用数学框架和数值方法，可预测实现目标飞行轨迹所需的飞行控制量。


<details>
  <summary>Details</summary>
Motivation: 本文旨在为固定翼飞机提供一个通用的数学框架，用于逆仿真，即根据目标轨迹预测所需的飞行控制量。

Method: 利用符号数学、龙格-库塔（RK4）数值积分和有限差分法（FDM）推导并实现了一个逆仿真（InvSim）系统，该系统能够计算出实现目标轨迹所需的四种控制变量（发动机推力、副翼、升降舵和方向舵的偏转角）。

Result: 计算得到的控制变量能够使飞机按照目标轨迹飞行。

Conclusion: 提出的飞行力学逆仿真（InvSim）数值程序得到了验证，能够成功预测实现所需飞行轨迹的控制输入。

Abstract: In this work, we start with a generic mathematical framework for the
equations of motion (EOM) in flight mechanics with six degrees of freedom
(6-DOF) for a general (not necessarily symmetric) fixed-wing aircraft. This
mathematical framework incorporates (1) body axes (fixed in the airplane at its
center of gravity), (2) inertial axes (fixed in the earth/ground at the
take-off point), wind axes (aligned with the flight path/course), (3) spherical
flight path angles (azimuth angle measured clockwise from the geographic north,
and elevation angle measured above the horizon plane), and (4) spherical flight
angles (angle of attack and sideslip angle). We then manipulate these equations
of motion to derive a customized version suitable for inverse simulation flight
mechanics, where a target flight trajectory is specified while a set of
corresponding necessary flight controls to achieve that maneuver are predicted.
We then present a numerical procedure for integrating the developed inverse
simulation (InvSim) system in time; utilizing (1) symbolic mathematics, (2)
explicit fourth-order Runge-Kutta (RK4) numerical integration technique, and
(3) expressions based on the finite difference method (FDM); such that the four
necessary control variables (engine thrust force, ailerons' deflection angle,
elevators' deflection angle, and rudder's deflection angle) are computed as
discrete values over the entire maneuver time, and these calculated control
values enable the airplane to achieve the desired flight trajectory, which is
specified by three inertial Cartesian coordinates of the airplane, in addition
to the Euler's roll angle. We finally demonstrate the proposed numerical
procedure of flight mechanics inverse simulation (InvSim).

</details>


### [213] [A Dynamic Recurrent Adjacency Memory Network for Mixed-Generation Power System Stability Forecasting](https://arxiv.org/abs/2511.03746)
*Guang An Ooi,Otavio Bertozzi,Mohd Asim Aftab,Charalambos Konstantinou,Shehab Ahmed*

Main category: eess.SY

TL;DR: 该论文提出了一种名为DRAMN的动态递归邻接记忆网络，结合了基于物理的分析和深度学习，用于实时电力系统稳定性预测。


<details>
  <summary>Details</summary>
Motivation: 传统稳定性评估方法难以处理现代高渗透率电力系统复杂的动态行为，因此需要新的方法。

Method: DRAMN利用滑动窗口动态模态分解构建时变多层邻接矩阵，并结合图卷积操作和递归门控机制来同时处理动态和时间依赖性。

Result: 在IEEE 9总线、39总线和多端高压直流网络上的实验表明，DRAMN的平均准确率分别达到99.85%、99.90%和99.69%，优于现有基准。此外，该方法还能在不降低性能的情况下将特征维度降低82%，并具有良好的可解释性。

Conclusion: DRAMN在准确性和可解释性方面均达到了最先进水平，适用于现代电力系统实时部署。

Abstract: Modern power systems with high penetration of inverter-based resources
exhibit complex dynamic behaviors that challenge the scalability and
generalizability of traditional stability assessment methods. This paper
presents a dynamic recurrent adjacency memory network (DRAMN) that combines
physics-informed analysis with deep learning for real-time power system
stability forecasting. The framework employs sliding-window dynamic mode
decomposition to construct time-varying, multi-layer adjacency matrices from
phasor measurement unit and sensor data to capture system dynamics such as
modal participation factors, coupling strengths, phase relationships, and
spectral energy distributions. As opposed to processing spatial and temporal
dependencies separately, DRAMN integrates graph convolution operations directly
within recurrent gating mechanisms, enabling simultaneous modeling of evolving
dynamics and temporal dependencies. Extensive validations on modified IEEE
9-bus, 39-bus, and a multi-terminal HVDC network demonstrate high performance,
achieving 99.85\%, 99.90\%, and 99.69\% average accuracies, respectively,
surpassing all tested benchmarks, including classical machine learning
algorithms and recent graph-based models. The framework identifies optimal
combinations of measurements that reduce feature dimensionality by 82\% without
performance degradation. Correlation analysis between dominant measurements for
small-signal and transient stability events validates generalizability across
different stability phenomena. DRAMN achieves state-of-the-art accuracy while
providing enhanced interpretability for power system operators, making it
suitable for real-time deployment in modern control centers.

</details>


### [214] [Analytical modelling of a stop-less modular bus service with an application to charging strategies comparison](https://arxiv.org/abs/2511.03754)
*Haoran Zhao,Neema Nassir,Andres Fielbaum*

Main category: eess.SY

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Buses are a vital component of metropolitan public transport, yet
conventional bus services often struggle with inefficiencies including extended
dwelling time, which increases in-vehicle travel time for non-alighting
passengers. A stop-less autonomous modular (SLAM) bus service has emerged as a
solution, enabling dynamic capacity to reduce dwelling time. Meanwhile, the
electrification of buses is advancing as a strategy to mitigate greenhouse gas
emissions and reduces operators' costs, but introduces new operational
constraints due to charging requirements. This study develops analytical
optimization models for SLAM bus service that integrates vehicle-to-vehicle
(V2V) charging technology. By comparing the optimal designs and their
feasibility across non-charging case and charging strategies, we identify a
sequence of operational stages as ridership grows: from idle capacity under low
demand, to full small buses, full large buses, and a proposed frequency-capped
regime where only bus capacity expands. Under the mobile charging strategy,
this progression further includes an energy-limited regime, in which frequency
declines, and ultimately infeasibility under high demand. These findings enable
operators to deliver more efficient services.

</details>


### [215] [Removing Time-Scale Separation in Feedback-Based Optimization via Estimators](https://arxiv.org/abs/2511.03903)
*Niloufar Yousefi,John W. Simpson-Porco*

Main category: eess.SY

TL;DR: FBO是一种用于在不知道系统动力学的情况下，调节稳定动态系统以解决约束优化问题的简单控制框架。但为了保证闭环稳定性，控制器需要比系统本身运行得慢，这严重限制了闭环性能。为了解决这个权衡问题，我们提出了一种基于估计器的FBO修改方法，该方法利用动态系统模型信息消除了传统FBO所需的时间尺度分离要求。通过这种设计，闭环系统的收敛速度仅受开环系统主特征值的限制。我们将该方法扩展到原始系统是奇异摄动的近似模型情况。最后，通过在基于逆变器的快速电力系统频率控制中的应用来说明这些结果。


<details>
  <summary>Details</summary>
Motivation: 传统的基于反馈的优化（FBO）方法在提高闭环性能方面存在时间尺度分离的限制，这阻碍了控制器比被控系统运行得更慢。

Method: 提出了一种基于估计器的FBO修改方法，利用动态系统模型信息来消除时间尺度分离的要求，从而提高收敛速度。此外，将该方法扩展到使用近似系统模型的场景。

Result: 所提出的方法将闭环系统的收敛速度限制在仅受开环系统主特征值的影响。该方法已成功应用于基于逆变器的快速电力系统频率控制。

Conclusion: 通过一种基于估计器的方法，成功地克服了传统FBO在时间尺度分离方面的限制，并提高了闭环系统的收敛速度，该方法在快速电力系统频率控制中得到了实际应用。

Abstract: Feedback-based optimization (FBO) provides a simple control framework for
regulating a stable dynamical system to the solution of a constrained
optimization problem in the presence of exogenous disturbances, and does so
without full knowledge of the plant dynamics. However, closed-loop stability
requires the controller to operate on a sufficiently slower timescale than the
plant, significantly constraining achievable closed-loop performance. Motivated
by this trade-off, we propose an estimator-based modification of FBO which
leverages dynamic plant model information to eliminate the time-scale
separation requirement of traditional FBO. Under this design, the convergence
rate of the closed-loop system is limited only by the dominant eigenvalue of
the open-loop system. We extend the approach to the case of design based on
only an approximate plant model when the original system is singularly
perturbed. The results are illustrated via an application to fast power system
frequency control using inverter-based resources.

</details>


### [216] [A Co-simulation Framework for Quadrotor Control System Design using ROS 2 and MATLAB/Simulink](https://arxiv.org/abs/2511.03969)
*Hangyu Teng*

Main category: eess.SY

TL;DR: 该论文提出了一个集成ROS 2和MATLAB/Simulink用于四旋翼无人机控制系统设计和验证的协同仿真框架。


<details>
  <summary>Details</summary>
Motivation: 为了提高复杂网络物理系统的设计和分析效率，并降低成本。

Method: 首先，基于牛顿-欧拉方程精确推导了六自由度非线性动力学模型；其次，设计并实现了一个分层控制架构，包括用于姿态控制的LQR控制器和用于位置控制的PID控制器；最后，阐述了框架的架构，包括跨平台数据交换机制的实现细节。

Result: 仿真结果证明了该框架的有效性，能够为无人机控制算法的快速原型设计和软件在环（SIL）验证提供标准化解决方案。

Conclusion: 该框架为无人机控制系统的设计和验证提供了一个高效且标准化的协同仿真方法。

Abstract: Co-simulation is a critical approach for the design and analysis of complex
cyber-physical systems. It will enhance development efficiency and reduce
costs. This paper presents a co-simulation framework integrating ROS 2 and
MATLAB/Simulink for quadrotor unmanned aerial vehicle (UAV) control system
design and verification. First, a six-degree-of-freedom nonlinear dynamic model
of the quadrotor is derived accurately that based on Newton-Euler equations.
Second, within the proposed framework, a hierarchical control architecture was
designed and implemented: LQR controller for attitude control to achieve
optimal regulation performance, and PID controller for position control to
ensure robustness and practical applicability. Third, elaborated the
architecture of the framework, including the implementation details of the
cross-platform data exchange mechanism. Simulation results demonstrate the
effectiveness of the framework, highlighting its capability to provide an
efficient and standardized solution for rapid prototyping and
Software-in-the-Loop (SIL) validation of UAV control algorithms.

</details>


### [217] [Necessary and Sufficient Conditions for the Optimization-Based Concurrent Execution of Learned Robotic Tasks](https://arxiv.org/abs/2511.04054)
*Sheikh A. Tahmid,Gennaro Notomista*

Main category: eess.SY

TL;DR: 本研究提出定理，给出在状态空间子集中使用最小范数控制器并发执行一组学习任务的充要条件，并扩展了优化框架以处理带折扣因子的价值函数。


<details>
  <summary>Details</summary>
Motivation: 解决现有优化框架在并发执行学习任务方面存在的局限性，即未解答何时可以并发执行学习到的价值函数的问题。

Method: 提出定理，为并发执行一组学习到的任务提供必要和充分的条件，并扩展了优化框架以处理带折扣因子的价值函数。

Result: 提供了关于何时可以使学习到的控制任务并发执行、何时它们本身就已可以并发执行以及何时根本不可能使用先前提出的方法使一组学习到的任务并发执行的见解。

Conclusion: 本研究提出的定理和框架扩展为处理带折扣因子的价值函数，使得优化框架能更好地兼容标准的强化学习实践，并为并发执行学习任务提供了理论基础和更广泛的适用性。

Abstract: In this work, we consider the problem of executing multiple tasks encoded by
value functions, each learned through Reinforcement Learning, using an
optimization-based framework. Prior works develop such a framework, but left
unanswered a fundamental question of when learned value functions can be
concurrently executed. The main contribution of this work is to present
theorems which provide necessary and sufficient conditions to concurrently
execute sets of learned tasks within subsets of the state space, using a
previously proposed min-norm controller. These theorems provide insight into
when learned control tasks are possible to be made concurrently executable,
when they might already inherently be concurrently executable and when it is
not possible at all to make a set of learned tasks concurrently executable
using the previously proposed methods. Additional contributions of this work
include extending the optimization-based framework to execute multiple tasks
encoded by value functions to also account for value functions trained with a
discount factor, making the overall framework more compatible with standard RL
practices.

</details>


### [218] [Differential Flatness of Quasi-Static Slider-Pusher Models with Applications in Control](https://arxiv.org/abs/2511.04246)
*Sander De Witte,Tom Lefebvre,Thomas Neve,Andras Retzler,Guillaume Crevecoeur*

Main category: eess.SY

TL;DR: 该论文研究了平面滑块-推杆系统作为操作任务中的运动原语的动态特性。推导了基于极限曲面法、准静态假设和可忽略接触摩擦的微分运动学模型。该模型适用于通用滑块形状和圆形推杆几何，并实现了系统的微分运动学表示。分析了具有多边形滑块和圆形推杆的滑块-推杆系统的“平坦性”，并将其质心作为平坦输出。基于此，论文提出了一种反馈控制策略，用于轨迹跟踪，并通过闭环仿真和物理实验进行了验证。


<details>
  <summary>Details</summary>
Motivation: 研究了平面滑块-推杆系统作为操作任务中的运动原语的动态特性。

Method: 推导了基于极限曲面法、准静态假设和可忽略接触摩擦的微分运动学模型。分析了该模型的“平坦性”，并将其质心作为平坦输出。提出了一种反馈控制策略，用于轨迹跟踪，并通过闭环仿真和物理实验进行了验证。

Result: 滑块-推杆系统具有“平坦性”，质心是平坦输出。所提出的控制策略通过了仿真和物理实验的验证，证明了其在实际应用中的潜力。

Conclusion: 该研究为滑块-推杆系统的动态特性和控制策略提供了理论模型和实践验证，强调了其在操作任务中的应用潜力。

Abstract: This paper investigates the dynamic properties of planar slider-pusher
systems as a motion primitive in manipulation tasks. To that end, we construct
a differential kinematic model deriving from the limit surface approach under
the quasi-static assumption and with negligible contact friction. The
quasi-static model applies to generic slider shapes and circular pusher
geometries, enabling a differential kinematic representation of the system.
From this model, we analyze differential flatness - a property advantageous for
control synthesis and planning - and find that slider-pusher systems with
polygon sliders and circular pushers exhibit flatness with the centre of mass
as a flat output. Leveraging this property, we propose two control strategies
for trajectory tracking: a cascaded quasi-static feedback strategy and a
dynamic feedback linearization approach. We validate these strategies through
closed-loop simulations incorporating perturbed models and input noise, as well
as experimental results using a physical setup with a finger-like pusher and
vision-based state detection. The real-world experiments confirm the
applicability of the simulation gains, highlighting the potential of the
proposed methods for

</details>


### [219] [ComEMS4Build: Comfort-Oriented Energy Management System for Residential Buildings using Hydrogen for Seasonal Storage](https://arxiv.org/abs/2511.04293)
*Jovana Kovačević,Felix Langner,Erfan Tajalli-Ardekani,Marvin Dorn,Simon Waczowicz,Ralf Mikut,Jörg Matthes,Hüseyin K. Çakmak,Veit Hagenmeyer*

Main category: eess.SY

TL;DR: 本研究提出了一种面向舒适度的住宅建筑能源管理系统（ComEMS4Build），该系统集成了光伏（PV）、电池储能系统（BESS）和氢气（H2）存储，并辅以燃料电池（FC）和热泵（HP）。


<details>
  <summary>Details</summary>
Motivation: 为了解决住宅部门整合柔性负荷和储能系统以匹配波动的可再生能源发电与需求的问题，特别是利用氢气储能系统实现季节性能量转移，并降低初期成本。

Method: 开发并使用半合成建模方法，在德国一个家庭的住宅建筑中，对基于模糊逻辑的 ComEMS4Build 系统进行了为期 12 周的冬季模拟。将该系统与需求最少输入的规则基础控制（RBC）和具有理想预测成本最优化的模型预测控制（MPC）进行了比较。

Result: ComEMS4Buld 和 MPC 在 10 周内均未违反热舒适度要求，而 RBC 的中位数不适度为 0.68 Kh。ComEMS4Buld 比 RBC 增加了 12.06 欧元/周的电费，而 RBC 比 MPC 增加了 30.14 欧元/周的电费。ComEMS4Buld 提高了混合储能系统（HESS）的利用率和与主电网的能源交换，但 RBC 在减少 FC 的切换次数（3.48%）和工作时间（7.59%）方面优于 MPC。

Conclusion: ComEMS4Build 在保证用户舒适度的前提下，能够有效地提高能源系统的利用率和经济性，但 FC 的运行效率方面仍有提升空间。

Abstract: Integrating flexible loads and storage systems into the residential sector
contributes to the alignment of volatile renewable generation with demand.
Besides batteries serving as a short-term storage solution, residential
buildings can benefit from a Hydrogen (H2) storage system, allowing seasonal
shifting of renewable energy. However, as the initial costs of H2 systems are
high, coupling a Fuel Cell (FC) with a Heat Pump (HP) can contribute to the
size reduction of the H2 system. The present study develops a Comfort-Oriented
Energy Management System for Residential Buildings (ComEMS4Build) comprising
Photovoltaics (PV), Battery Energy Storage System (BESS), and H2 storage, where
FC and HP are envisioned as complementary technologies. The fuzzy-logic-based
ComEMS4Build is designed and evaluated over a period of 12 weeks in winter for
a family household building in Germany using a semi-synthetic modeling
approach. The Rule-Based Control (RBC), which serves as a lower benchmark, is a
scheduler designed to require minimal inputs for operation. The Model
Predictive Control (MPC) is intended as a cost-optimal benchmark with an ideal
forecast. The results show that ComEMS4Build, similar to MPC, does not violate
the thermal comfort of occupants in 10 out of 12 weeks, while RBC has a
slightly higher median discomfort of 0.68 Kh. The ComEMS4Build increases the
weekly electricity costs by 12.06 EUR compared to MPC, while RBC increases the
weekly costs by 30.14 EUR. The ComEMS4Build improves the Hybrid Energy Storage
System (HESS) utilization and energy exchange with the main grid compared to
the RBC. However, when it comes to the FC operation, the RBC has an advantage,
as it reduces the toggling counts by 3.48% and working hours by 7.59% compared
to MPC...

</details>


### [220] [Data-Driven Modeling of Photosynthesis Regulation Under Oscillating Light Condition - Part I: In-Silico Exploration](https://arxiv.org/abs/2511.04330)
*Christian Portilla,Arviandy G Aribowo,Ramachandran Anantharaman,César A Gómez-Pérez,Leyla Özkan*

Main category: eess.SY

TL;DR: 本研究旨在使用数据驱动的频率域系统辨识技术，为振荡光照条件下光合作用调控获得简化的、面向控制的数学模型。


<details>
  <summary>Details</summary>
Motivation: 在振荡光照条件下，获得光合作用调控过程的简化、面向控制的数学模型。

Method: 利用物理模型（BDM）生成数据，并采用最佳线性逼近（BLA）方法估计二阶LTI传递函数模型，进而构建LPV表示，其中DC值作为调度参数。

Result: 得到了在不同DC水平和调制频率下，光合作用调控的二阶LTI传递函数模型，并构建了由DC值定义的LPV表示。

Conclusion: 数据驱动的频率域系统辨识技术能够有效地获得光合作用调控的简化模型，并可用于构建紧凑的LPV状态空间表示。

Abstract: This paper explores the application of data-driven system identification
techniques in the frequency domain to obtain simplified, control-oriented
models of photosynthesis regulation under oscillating light conditions.
In-silico datasets are generated using simulations of the physics-based Basic
DREAM Model (BDM) Funete et al.[2024], with light intensity signals --
comprising DC (static) and AC (modulated) components as input and chlorophyll
fluorescence (ChlF) as output. Using these data, the Best Linear Approximation
(BLA) method is employed to estimate second-order linear time-invariant (LTI)
transfer function models across different operating conditions defined by DC
levels and modulation frequencies of light intensity. Building on these local
models, a Linear Parameter-Varying (LPV) representation is constructed, in
which the scheduling parameter is defined by the DC values of the light
intensity, providing a compact state-space representation of the system
dynamics.

</details>


### [221] [Overview and Performance Evaluation of Supervisory Controller Synthesis with Eclipse ESCET v4.0](https://arxiv.org/abs/2511.04370)
*Dennis Hendriks,Michel Reniers,Wan Fokkink,Wytse Oortwijn*

Main category: eess.SY

TL;DR: 该论文介绍了CIF（控制意图建模语言）及其在Eclipse Supervisory Control Engineering Toolkit (ESCET)项目中的应用，重点是其符号化监督控制器综合算法、基准模型以及近期在综合性能上的改进。


<details>
  <summary>Details</summary>
Motivation: 自动化设计和实现监控控制器，确保网络物理系统的正确和安全操作，让工程师专注于系统需求而非具体实现。

Method: 1. 详细描述CIF的符号化监督控制器综合算法，包括防止运行时错误、处理不同类型的需求和支持输入变量。 2. 介绍CIF的基准模型库（23个工业和学术模型）。 3. 描述ESCET版本v0.8到v4.0之间的改进，并评估其在基准模型上的综合性能。 4. 探讨多层综合方法及其对提高综合性能的潜力。

Result: CIF的综合算法能够处理实际应用中的复杂情况；基准模型库为评估提供了标准；近期改进提高了综合性能，但对于复杂模型仍需进一步提升；多层综合方法显示出潜力但仍需优化。

Conclusion: CIF和ESCET为SBE提供了一个强大且不断改进的工具集，其综合算法在实践中表现出良好的性能，并且通过多层综合等方法有进一步提升的空间，但要处理极其复杂的模型，仍需持续的研究和开发。

Abstract: Supervisory controllers control cyber-physical systems to ensure their
correct and safe operation. Synthesis-based engineering (SBE) is an approach to
largely automate their design and implementation. SBE combines model-based
engineering with computer-aided design, allowing engineers to focus on 'what'
the system should do (the requirements) rather than 'how' it should do it
(design and implementation). In the Eclipse Supervisory Control Engineering
Toolkit (ESCET) open-source project, a community of users, researchers, and
tool vendors jointly develop a toolkit to support the entire SBE process,
particularly through the CIF modeling language and tools. In this paper, we
first provide a description of CIF's symbolic supervisory controller synthesis
algorithm, and thereby include aspects that are often omitted in the
literature, but are of great practical relevance, such as the prevention of
runtime errors, handling different types of requirements, and supporting input
variables (to connect to external inputs). Secondly, we introduce and describe
CIF's benchmark models, a collection of 23 freely available industrial and
academic models of various sizes and complexities. Thirdly, we describe recent
improvements between ESCET versions v0.8 (December 2022) and v4.0 (June 2024)
that affect synthesis performance, evaluate them on our benchmark models, and
show the current practical synthesis performance of CIF. Fourthly, we briefly
look at multi-level synthesis, a non-monolithic synthesis approach, evaluate
its gains, and show that while it can help to further improve synthesis
performance, further performance improvements are still needed to synthesize
complex models.

</details>


### [222] [Deep Koopman Economic Model Predictive Control of a Pasteurisation Unit](https://arxiv.org/abs/2511.04437)
*Patrik Valábek,Michaela Horváthová,Martin Klaučo*

Main category: eess.SY

TL;DR: 本文提出了一种基于深度koopman的经济模型预测控制（EMPC）方法，用于实验室规模巴氏杀菌单元（PU）的高效运行。该方法利用koopman 算子理论将复杂的非线性系统动力学线性化，从而能够应用凸优化，同时精确表示PU的复杂性。深度koopman模型利用神经网络从实验数据中学习线性动力学，在开环预测精度上比传统的N4SID子空间辨识提高了45%。两种模型都被用于EMPC的构建中，并包含可解释的经济成本，如能耗、巴氏杀菌不足造成的物料损失以及执行器磨损。通过松弛变量确保了EMPC的可行性。在非线性多变量PU模型受到外部干扰（如进料泵故障和引入冷批次）的情况下，对深度koopman EMPC和N4SID EMPC进行了数值验证。结果表明，与N4SID基线相比，深度koopman EMPC的总经济成本降低了32%，这主要归功于物料损失和能耗的减少。此外，基于koopman 的 EMPC 的稳态运行比N4SID基线能耗降低了10.2%。研究结果强调了将深度koopman表示与经济优化相结合，以实现热密集型工厂资源节约型控制的实际优势。


<details>
  <summary>Details</summary>
Motivation: 传统控制方法难以精确表示巴氏杀菌单元（PU）的复杂非线性动力学，影响了运行效率和经济性。因此，需要一种能够精确建模并优化经济成本（如能耗、物料损失、设备磨损）的控制方法。

Method: 本文提出了一种基于深度koopman算子理论的经济模型预测控制（EMPC）方法。首先，利用神经网络学习PU的线性动力学模型（深度koopman模型），以替代传统的N4SID子空间辨识方法。然后，将学习到的模型集成到EMPC框架中，并考虑了包括能耗、物料损失和执行器磨损在内的经济成本。通过引入松弛变量来保证控制的可行性。最后，在非线性PU模型上进行了数值验证，并与N4SID EMPC进行了比较。

Result: 与传统的N4SID子空间辨识方法相比，深度koopman模型在开环预测精度上提高了45%。在受到进料泵故障和冷批次注入等外部干扰的情况下，深度koopman EMPC将总经济成本降低了32%，主要体现在物料损失和能耗的减少。此外，基于koopman 的 EMPC 在稳态运行下能耗降低了10.2%。

Conclusion: 深度koopman算子理论与经济模型预测控制相结合，能够有效地提高巴氏杀菌单元等热密集型工厂的资源利用效率。该方法能够精确地学习和表示复杂的非线性系统动力学，并显著降低运行成本，具有实际应用价值。

Abstract: This paper presents a deep Koopman-based Economic Model Predictive Control
(EMPC) for efficient operation of a laboratory-scale pasteurization unit (PU).
The method uses Koopman operator theory to transform the complex, nonlinear
system dynamics into a linear representation, enabling the application of
convex optimization while representing the complex PU accurately. The deep
Koopman model utilizes neural networks to learn the linear dynamics from
experimental data, achieving a 45% improvement in open-loop prediction accuracy
over conventional N4SID subspace identification. Both analyzed models were
employed in the EMPC formulation that includes interpretable economic costs,
such as energy consumption, material losses due to inadequate pasteurization,
and actuator wear. The feasibility of EMPC is ensured using slack variables.
The deep Koopman EMPC and N4SID EMPC are numerically validated on a nonlinear
model of multivariable PU under external disturbance. The disturbances include
feed pump fail-to-close scenario and the introduction of a cold batch to be
pastuerized. These results demonstrate that the deep Koopmand EMPC achieves a
32% reduction in total economic cost compared to the N4SID baseline. This
improvement is mainly due to the reductions in material losses and energy
consumption. Furthermore, the steady-state operation via Koopman-based EMPC
requires 10.2% less electrical energy. The results highlight the practical
advantages of integrating deep Koopman representations with economic
optimization to achieve resource-efficient control of thermal-intensive plants.

</details>


### [223] [Deep Dictionary-Free Method for Identifying Linear Model of Nonlinear System with Input Delay](https://arxiv.org/abs/2511.04451)
*Patrik Valábek,Marek Wadinger,Michal Kvasnica,Martin Klaučo*

Main category: eess.SY

TL;DR: 提出一种基于LSTM的深度koopman模型，用于近似具有时滞的非线性系统的koopman算子，实现时滞系统的线性表示，无需预定义字典，在预测精度上优于传统eDMD方法。


<details>
  <summary>Details</summary>
Motivation: 由于非线性系统内禀的复杂性和时滞对其行为的影响，具有输入时滞的非线性动力学系统在预测、估计和控制方面带来了重大挑战，传统的线性控制技术在这种情况下往往失效，因此需要创新的方法。

Method: 提出一种基于LSTM的深度koopman模型，该模型通过整合长短期记忆（LSTM）层来捕捉历史依赖性，并将带时滞的系统动力学有效地编码到潜在空间中，从而近似koopman算子，实现非线性系统到线性系统的表示。

Result: 在模拟系统上与扩展eDMD进行定量比较，结果表明，在真实非线性动力学未知的场景下，该LSTM增强的深度koopman模型在预测精度方面取得了显著的性能提升，并且在系统动力学已知的场景下取得了与eDMD相当的结果。

Conclusion: LSTM增强的深度koopman模型能够有效地处理具有时滞的非线性系统，通过其字典无关的方法在预测精度方面超越了传统方法，尤其是在系统动力学未知的情况下。

Abstract: Nonlinear dynamical systems with input delays pose significant challenges for
prediction, estimation, and control due to their inherent complexity and the
impact of delays on system behavior. Traditional linear control techniques
often fail in these contexts, necessitating innovative approaches. This paper
introduces a novel approach to approximate the Koopman operator using an
LSTM-enhanced Deep Koopman model, enabling linear representations of nonlinear
systems with time delays. By incorporating Long Short-Term Memory (LSTM)
layers, the proposed framework captures historical dependencies and efficiently
encodes time-delayed system dynamics into a latent space. Unlike traditional
extended Dynamic Mode Decomposition (eDMD) approaches that rely on predefined
dictionaries, the LSTM-enhanced Deep Koopman model is dictionary-free, which
mitigates the problems with the underlying dynamics being known and
incorporated into the dictionary. Quantitative comparisons with extended eDMD
on a simulated system demonstrate highly significant performance gains in
prediction accuracy in cases where the true nonlinear dynamics are unknown and
achieve comparable results to eDMD with known dynamics of a system.

</details>


### [224] [Data-driven uncertainty-aware seakeeping prediction of the Delft 372 catamaran using ensemble Hankel dynamic mode decomposition](https://arxiv.org/abs/2511.04461)
*Giorgio Palma,Andrea Serani,Matteo Diez*

Main category: eess.SY

TL;DR: 该研究提出并验证了一种基于集成学习的 Hankel 动态模式分解（HDMDc）方法，用于识别高速双体船（Delft 372 模型）的不确定性感知耐波性预测。


<details>
  <summary>Details</summary>
Motivation: 为了提高高速双体船的耐波性预测精度，并进行不确定性量化。

Method: 提出了一种基于集成学习的 Hankel 动态模式分解（HDMDc）方法，包括贝叶斯 HDMDc（BHDMDc）和频率 HDMDc（FHDMDc）。

Result: FHDMDc 提高了预测精度并提供了可靠的不确定性估计，而 BHDMDc 在此案例中未显示出优势。FHDMDc 预测的运动概率密度函数与实验数据和 URANS 结果吻合良好。

Conclusion: FHDMDc 是一种计算效率高且可靠的耐波性预测方法，可用于设计和运营支持。

Abstract: In this study, we present and validate an ensemble-based Hankel Dynamic Mode
Decomposition with control (HDMDc) for uncertainty-aware seakeeping predictions
of a high-speed catamaran, namely the Delft 372 model. Experimental
measurements (time histories) of wave elevation at the longitudinal center of
gravity, heave, pitch, notional flight-deck velocity, notional bridge
acceleration, and total resistance were collected from irregular wave basin
tests on a 1:33.3 scale replica of the Delft 372 model under sea state 5
conditions at Fr = 0.425, and organized into training, validation, and test
sets. The HDMDc algorithm constructs an equation-free linear reduced-order
model of the seakeeping vessel by augmenting states and inputs with their
time-lagged copies to capture nonlinear and memory effects. Two ensembling
strategies, namely Bayesian HDMDc (BHDMDc), which samples hyperparameters
considered stochastic variables with prior distribution to produce posterior
mean forecasts with confidence intervals, and Frequentist HDMDc (FHDMDc), which
aggregates multiple model obtained over data subsets, are compared in providing
seakeeping prediction and uncertainty quantification. The FHDMDc approach is
found to improve the accuracy of the predictions compared to the deterministic
counterpart, also providing robust uncertainty estimation; whereas the
application of BHDMDc to the present test case is not found beneficial in
comparison to the deterministic model. FHDMDc-derived probability density
functions for the motions closely match both experimental data and URANS
results, demonstrating reliable and computationally efficient seakeeping
prediction for design and operational support.

</details>


### [225] [AI-Driven Phase-Shifted Carrier Optimization for Cascaded Bridge Converters, Modular Multilevel Converters, and Reconfigurable Batteries](https://arxiv.org/abs/2511.04470)
*Amin Hashemi-Zadeh,Nima Tashakor,Sandun Hettiarachchi,Stefan Goetz*

Main category: eess.SY

TL;DR: PSC-PWM在级联桥式转换器、模块化多电平转换器和可重构电池中存在脉冲宽度不均匀导致纹波电流和输出电压失真。本文提出了一种神经网络来实时优化相位偏移，大大降低了计算量，可减少50%的电流纹波和加权总谐波失真，且速度比传统优化器快100到500千倍。


<details>
  <summary>Details</summary>
Motivation: 相位移载波脉冲宽度调制（PSC-PWM）作为一种广泛应用的调度算法，在实际应用中存在模块间脉冲宽度不均匀导致纹波电流和输出电压失真。虽然电压均匀化可以通过优化相位偏移实现，但其计算量对于嵌入式控制器来说过大。

Method: 提出了一种能够模拟瞬时优化器行为的神经网络，显著降低了计算负荷。该方法能够为具有不同调制指数的平衡电池模块预测最优相位偏移角度，且无需复杂的查找表、数值优化或控制器调优。此外，还提出了一种简单的缩放策略，允许复用为较少模块训练的神经网络以适应更大的系统，无需重新训练。

Result: 仿真和实验表明，该方法平均可实时减少50%的电流纹波和加权总谐波失真，并且比遗传算法等传统优化器快100到500千倍，适用于在线应用。

Conclusion: 所提出的神经网络方法能够高效、实时地优化PSC-PWM的相位偏移，有效解决纹波电流和输出电压失真问题，并具有良好的适应性和可扩展性，为相关领域提供了有效的在线解决方案。

Abstract: Phase-shifted carrier pulse-width modulation (PSC-PWM) is a widely adopted
scheduling algorithm in cascaded bridge converters, modular multilevel
converters, and reconfigurable batteries. However, non-uniformed pulse widths
for the modules with fixed phase shift angles lead to significant ripple
current and output-voltage distortion. Voltage uniformity instead would require
optimization of the phase shifts of the individual carriers. However, the
computational burden for such optimization is beyond the capabilities of any
simple embedded controller. This paper proposes a neural network that emulates
the behavior of an instantaneous optimizer with significantly reduced
computational burden. The proposed method has the advantages of stable
performance in predicting the optimum phase-shift angles under balanced battery
modules with non-identical modulation indices without requiring extensive
lookup tables, slow numerical optimization, or complex controller tuning. With
only one (re)training session for any specified number of modules, the proposed
method is readily adaptable to different system sizes. Furthermore, the
proposed framework also includes a simple scaling strategy that allows a neural
network trained for fewer modules to be reused for larger systems by grouping
modules and adjusting their phase shifts. The scaling strategy eliminates the
need for retraining. Large-scale assessment, simulations, and experiments
demonstrate that, on average, the proposed approach can reduce the current
ripple and the weighted total harmonic distortion by up to 50 % in real time
and is 100 to 500 thousand times faster than a conventional optimizer (e.g.,
genetic algorithms), making it the only solution for an online application.

</details>


### [226] [Synchronous Observer Design for Landmark-Inertial SLAM with Almost-Global Convergence](https://arxiv.org/abs/2511.04531)
*Arkadeep Saha,Pieter van Goor,Antonio Franchi,Ravi Banavar*

Main category: eess.SY

TL;DR: 提出一种用于视觉SLAM的非线性观测器，并在仿真中验证了其稳定性和有效性。


<details>
  <summary>Details</summary>
Motivation: 在视觉SLAM中，利用传感器测量值来估计机器人位置和环境特征点位置是关键。

Method: 提出一个在连续时间内定义的非线性观测器，并分析其在编码了所有可观察状态的基础空间中的行为。

Result: 证明了在基础空间中误差动力学的局部指数稳定性和几乎全局渐近稳定性，并通过仿真进行了验证。

Conclusion: 所提出的非线性观测器在LI-SLAM问题上是稳定且有效的。

Abstract: Landmark Inertial Simultaneous Localisation and Mapping (LI-SLAM) is the
problem of estimating the locations of landmarks in the environment and the
robot's pose relative to those landmarks using landmark position measurements
and measurements from Inertial Measurement Unit (IMU). This paper proposes a
nonlinear observer for LI-SLAM posed in continuous time and analyses the
observer in a base space that encodes all the observable states of LI-SLAM. The
local exponential stability and almost-global asymptotic stability of the error
dynamics in base space is established in the proof section and validated using
simulations.

</details>


### [227] [Funnel-Based Online Recovery Control for Nonlinear Systems With Unknown Dynamics](https://arxiv.org/abs/2511.04626)
*Zihao Song,Shirantha Welikala,Panos J. Antsaklis,Hai Lin*

Main category: eess.SY

TL;DR: 本文提出了一种基于循环均衡网络（REN）和漏斗控制的方法，用于从攻击或故障中恢复非线性系统，并能学习未知动力学并保证状态恢复。


<details>
  <summary>Details</summary>
Motivation: 解决从攻击或故障中恢复非线性系统的挑战，包括学习未知动力学和确保状态偏差在允许范围内。

Method: 应用循环均衡网络（REN）学习未知动力学，并结合漏斗控制方法实现系统恢复。

Result: 通过理论推导和仿真示例（DC微电网应用）验证了所提出方法的有效性。

Conclusion: 所提出的方法能够有效地从攻击或故障中恢复非线性系统，并提供形式化的保证。

Abstract: In this paper, we focus on recovery control of nonlinear systems from attacks
or failures. The main challenges of this problem lie in (1) learning the
unknown dynamics caused by attacks or failures with formal guarantees, and (2)
finding the invariant set of states to formally ensure the state deviations
allowed from the nominal trajectory. To solve this problem, we propose to apply
the Recurrent Equilibrium Networks (RENs) to learn the unknown dynamics using
the data from the real-time system states. The input-output property of this
REN model is guaranteed by incremental integral quadratic constraints (IQCs).
Then, we propose a funnel-based control method to achieve system recovery from
the deviated states. In particular, a sufficient condition for nominal
trajectory stabilization is derived together with the invariant funnels along
the nominal trajectory. Eventually, the effectiveness of our proposed control
method is illustrated by a simulation example of a DC microgrid control
application.

</details>


### [228] [Control Affine Hybrid Power Plant Subsystem Modeling for Supervisory Control Design](https://arxiv.org/abs/2511.04644)
*Stephen Ampleman,Himanshu Sharma,Sayak Mukherjee,Sonja Glavaski*

Main category: eess.SY

TL;DR: 该研究提出了一个混合动力发电厂（HPP）的建模和控制设计框架，该HPP由风电场、太阳能电站和电池储能组成，旨在满足电网需求。


<details>
  <summary>Details</summary>
Motivation: 为了应对发电不足和电网需求，结合了多种发电方式（常规/可变）和储能能力的混合动力发电厂（HPP）被提出。

Method: 本研究将风电场、太阳能电站和电池模型整合成一个控制仿射形式，适用于监管层面的控制设计。针对风力和电池模型，利用非线性控制和控制屏障函数技术开发了发电机扭矩和电池电流控制律，以跟踪来自监管控制律的命令，同时保持安全稳定的运行。将一个基于规则的监管控制律与效用需求信号、时变风能和辐照度数据相结合，用于测试和说明该建模与控制框架的实用性。

Result: 通过一个包含效用需求信号跟踪、时变风能和辐照度数据以及基于规则的监管控制律的测试案例，说明了该建模和控制框架的有效性。

Conclusion: 本研究成功开发了一个混合动力发电厂的建模和控制框架，并验证了其在跟踪指令和维持安全运行方面的有效性。

Abstract: Hybrid power plants (HPPs) combine multiple power generators
(conventional/variable) and energy storage capabilities to support generation
inadequacy and grid demands. This paper introduces a modeling and control
design framework for hybrid power plants (HPPs) consisting of a wind farm,
solar plant, and battery storage. Specifically, this work adapts established
modeling paradigms for wind farms, solar plants and battery models into a
control affine form suitable for control design at the supervisory level. In
the case of wind and battery models, generator torque and cell current control
laws are developed using nonlinear control and control barrier function
techniques to track a command from a supervisory control law while maintaining
safe and stable operation. The utility of this modeling and control framework
is illustrated through a test case using a utility demand signal for tracking,
time varying wind and irradiance data, and a rule-based supervisory control
law.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [229] [Applying Time Series Deep Learning Models to Forecast the Growth of Perennial Ryegrass in Ireland](https://arxiv.org/abs/2511.03749)
*Oluwadurotimi Onibonoje,Vuong M. Ngo,Andrew McCarre,Elodie Ruelle,Bernadette O-Briend,Mark Roantree*

Main category: cs.LG

TL;DR: 利用深度学习模型对爱尔兰草地生长进行预测，以提高爱尔兰奶业的可持续性。


<details>
  <summary>Details</summary>
Motivation: 爱尔兰奶业面临盈利和可持续性挑战，现有的草地生长预测模型难以实施。

Method: 提出并验证了用于预测多年生黑麦草生长的深度学习模型，特别是时间卷积网络，并使用了包含34年1757周数据的全面数据集。

Result: 时间卷积网络在预测科克地区多年生黑麦草生长方面表现出高性能，RMSE为2.74，MAE为3.46。

Conclusion: 该研究通过改进草地生长预测的可靠性，为可持续奶牛养殖实践的进步做出了贡献。

Abstract: Grasslands, constituting the world's second-largest terrestrial carbon sink,
play a crucial role in biodiversity and the regulation of the carbon cycle.
Currently, the Irish dairy sector, a significant economic contributor, grapples
with challenges related to profitability and sustainability. Presently, grass
growth forecasting relies on impractical mechanistic models. In response, we
propose deep learning models tailored for univariate datasets, presenting
cost-effective alternatives. Notably, a temporal convolutional network designed
for forecasting Perennial Ryegrass growth in Cork exhibits high performance,
leveraging historical grass height data with RMSE of 2.74 and MAE of 3.46.
Validation across a comprehensive dataset spanning 1,757 weeks over 34 years
provides insights into optimal model configurations. This study enhances our
understanding of model behavior, thereby improving reliability in grass growth
forecasting and contributing to the advancement of sustainable dairy farming
practices.

</details>


### [230] [Federated Learning with Gramian Angular Fields for Privacy-Preserving ECG Classification on Heterogeneous IoT Devices](https://arxiv.org/abs/2511.03753)
*Youssef Elmir,Yassine Himeur,Abbes Amira*

Main category: cs.LG

TL;DR: 该研究提出了一种用于物联网医疗环境的联邦学习（FL）框架，用于隐私保护的心电图（ECG）分类。通过将一维ECG信号转换为二维Gramian Angular Field（GAF）图像，并使用卷积神经网络（CNN）进行特征提取，该方法确保敏感医疗数据保留在本地设备上。


<details>
  <summary>Details</summary>
Motivation: 本研究旨在解决物联网医疗环境中隐私保护的ECG分类问题，并探索GAF图像和联邦学习的结合以实现高效、安全的模型训练。

Method: 将一维ECG信号转换为二维GAF图像，然后使用CNN进行特征提取，并采用联邦学习框架在不同物联网设备（服务器、笔记本电脑、树莓派4）上进行模型训练和评估。

Result: 在多客户端设置下，FL-GAF模型实现了95.18%的高分类准确率，在准确性和训练时间方面显著优于单客户端基线模型。该框架在保持GAF变换的计算复杂性的同时，实现了高效的资源利用和通信开销。

Conclusion: 研究结果表明，轻量级的、注重隐私的AI技术在基于物联网的医疗监测中具有巨大潜力，支持在智能健康系统中进行可扩展和安全的边缘部署。

Abstract: This study presents a federated learning (FL) framework for
privacy-preserving electrocardiogram (ECG) classification in Internet of Things
(IoT) healthcare environments. By transforming 1D ECG signals into 2D Gramian
Angular Field (GAF) images, the proposed approach enables efficient feature
extraction through Convolutional Neural Networks (CNNs) while ensuring that
sensitive medical data remain local to each device. This work is among the
first to experimentally validate GAF-based federated ECG classification across
heterogeneous IoT devices, quantifying both performance and communication
efficiency. To evaluate feasibility in realistic IoT settings, we deployed the
framework across a server, a laptop, and a resource-constrained Raspberry Pi 4,
reflecting edge-cloud integration in IoT ecosystems. Experimental results
demonstrate that the FL-GAF model achieves a high classification accuracy of
95.18% in a multi-client setup, significantly outperforming a single-client
baseline in both accuracy and training time. Despite the added computational
complexity of GAF transformations, the framework maintains efficient resource
utilization and communication overhead. These findings highlight the potential
of lightweight, privacy-preserving AI for IoT-based healthcare monitoring,
supporting scalable and secure edge deployments in smart health systems.

</details>


### [231] [Laugh, Relate, Engage: Stylized Comment Generation for Short Videos](https://arxiv.org/abs/2511.03757)
*Xuan Ouyang,Senan Wang,Bouzhou Wang,Siyuan Xiahou,Jinrong Zhou,Yuekang Li*

Main category: cs.LG

TL;DR: LOLGORITHM是一个多智能体系统（MAS），用于生成符合平台规范、具有风格多样性和上下文感知能力的短视频评论。


<details>
  <summary>Details</summary>
Motivation: 现有短视频评论生成方法在生成符合平台规范、风格多样且具备上下文感知能力的评论方面存在挑战。

Method: LOLGORITHM集成视频分割、上下文和情感分析、风格提示构建，并利用多模态大语言模型（MLLM）处理视频输入，通过提示和少样本示例实现精细的风格控制，支持俏皮话、押韵、模仿、讽刺、幽默、内容提取六种评论风格。

Result: LOLGORITHM在中文（抖音）和英文（YouTube）数据集上进行了评估，结果显示其在原创性、相关性和风格符合性方面优于基线模型，用户偏好率分别达到90%和87.55%。

Conclusion: LOLGORITHM为短视频平台的风格化评论生成提供了一个可扩展且文化适应性强的框架，有望提升用户参与度和创意互动。

Abstract: Short-video platforms have become a central medium in the modern Internet
landscape, where efficient information delivery and strong interactivity are
reshaping user engagement and cultural dissemination. Among the various forms
of user interaction, comments play a vital role in fostering community
participation and enabling content re-creation. However, generating comments
that are both compliant with platform guidelines and capable of exhibiting
stylistic diversity and contextual awareness remains a significant challenge.
We introduce LOLGORITHM, a modular multi-agent system (MAS) designed for
controllable short-video comment generation. The system integrates video
segmentation, contextual and affective analysis, and style-aware prompt
construction. It supports six distinct comment styles: puns (homophones),
rhyming, meme application, sarcasm (irony), plain humor, and content
extraction. Powered by a multimodal large language model (MLLM), LOLGORITHM
directly processes video inputs and achieves fine-grained style control through
explicit prompt markers and few-shot examples. To support development and
evaluation, we construct a bilingual dataset using official APIs from Douyin
(Chinese) and YouTube (English), covering five popular video genres: comedy
skits, daily life jokes, funny animal clips, humorous commentary, and talk
shows. Evaluation combines automated metrics originality, relevance, and style
conformity with a large-scale human preference study involving 40 videos and
105 participants. Results show that LOLGORITHM significantly outperforms
baseline models, achieving preference rates of over 90% on Douyin and 87.55% on
YouTube. This work presents a scalable and culturally adaptive framework for
stylized comment generation on short-video platforms, offering a promising path
to enhance user engagement and creative interaction.

</details>


### [232] [Comparing EPGP Surrogates and Finite Elements Under Degree-of-Freedom Parity](https://arxiv.org/abs/2511.04518)
*Obed Amo,Samit Ghosh,Markus Lange-Hegermann,Bogdan Raiţă,Michael Pokojovy*

Main category: cs.LG

TL;DR: B-EPGP 在求解二维波动方程方面比 CN-FEM 的精度高约两个数量级。


<details>
  <summary>Details</summary>
Motivation: 为了解决二维波动方程的边界约束问题，将 B-EPGP 与 CN-FEM 进行比较。

Method: B-EPGP 使用指数-多项式基和惩罚最小二乘法来处理 PDE 和边界条件。CN-FEM 使用有限元方法和 Crank-Nicolson 时间步进。通过 DoF 匹配协议确保公平性。

Result: 在匹配的 DoF 下，B-EPGP 在时空 L2 误差和最大时间 L2 空间误差方面均优于 CN-FEM，精度提高了约两个数量级。

Conclusion: B-EPGP 在求解边界约束的二维波动方程方面比 CN-FEM 更具优势。

Abstract: We present a new benchmarking study comparing a boundary-constrained
Ehrenpreis--Palamodov Gaussian Process (B-EPGP) surrogate with a classical
finite element method combined with Crank--Nicolson time stepping (CN-FEM) for
solving the two-dimensional wave equation with homogeneous Dirichlet boundary
conditions. The B-EPGP construction leverages exponential-polynomial bases
derived from the characteristic variety to enforce the PDE and boundary
conditions exactly and employs penalized least squares to estimate the
coefficients. To ensure fairness across paradigms, we introduce a
degrees-of-freedom (DoF) matching protocol. Under matched DoF, B-EPGP
consistently attains lower space-time $L^2$-error and maximum-in-time
$L^{2}$-error in space than CN-FEM, improving accuracy by roughly two orders of
magnitude.

</details>


### [233] [Multiscale Astrocyte Network Calcium Dynamics for Biologically Plausible Intelligence in Anomaly Detection](https://arxiv.org/abs/2511.03993)
*Berk Iskar,Michael Taynnan Barros*

Main category: cs.LG

TL;DR: 使用受钙离子信号启发的类脑模型进行网络异常检测，以应对概念漂移和零日攻击。


<details>
  <summary>Details</summary>
Motivation: 传统离线训练的网络异常检测系统易受概念漂移和零日/多态攻击等新威胁的影响。

Method: 提出一种受星形胶质细胞钙离子信号启发的钙离子调节学习框架，结合了多细胞星形胶质细胞动力学模拟器和深度神经网络（DNN）。模拟器通过IP3介导的钙离子释放、SERCA泵吸收和细胞间通过间隙连接的电导感知扩散来模拟星形胶质细胞的钙离子动力学。

Result: 在CTU-13（Neris）网络流量数据上评估，所提出的钙离子调节模型优于基线DNN，在多个训练/测试分割中实现了高达约98%的准确率，并减少了误报和漏报，且一旦预计算钙离子轨迹，运行时开销可忽略不计。

Conclusion: 所提出的钙离子调节学习框架为需要快速、有生物学依据地适应不断变化的数据模式的流式检测任务提供了一个通用的解决方案，尤其是在网络安全领域。

Abstract: Network anomaly detection systems encounter several challenges with
traditional detectors trained offline. They become susceptible to concept drift
and new threats such as zero-day or polymorphic attacks. To address this
limitation, we propose a Ca$^{2+}$-modulated learning framework that draws
inspiration from astrocytic Ca$^{2+}$ signaling in the brain, where rapid,
context-sensitive adaptation enables robust information processing. Our
approach couples a multicellular astrocyte dynamics simulator with a deep
neural network (DNN). The simulator models astrocytic Ca$^{2+}$ dynamics
through three key mechanisms: IP$_3$-mediated Ca$^{2+}$ release, SERCA pump
uptake, and conductance-aware diffusion through gap junctions between cells.
Evaluation of our proposed network on CTU-13 (Neris) network traffic data
demonstrates the effectiveness of our biologically plausible approach. The
Ca$^{2+}$-gated model outperforms a matched baseline DNN, achieving up to
$\sim$98\% accuracy with reduced false positives and negatives across multiple
train/test splits. Importantly, this improved performance comes with negligible
runtime overhead once Ca$^{2+}$ trajectories are precomputed. While
demonstrated here for cybersecurity applications, this Ca$^{2+}$-modulated
learning framework offers a generic solution for streaming detection tasks that
require rapid, biologically grounded adaptation to evolving data patterns.

</details>


### [234] [What's in Common? Multimodal Models Hallucinate When Reasoning Across Scenes](https://arxiv.org/abs/2511.03768)
*Candace Ross,Florian Bordes,Adina Williams,Polina Kirichenko,Mark Ibrahim*

Main category: cs.LG

TL;DR: 现有模型在处理真实世界场景时存在幻觉问题，作者提出了名为Common-O的新基准来评估跨场景推理能力。结果显示，现有模型在跨场景推理方面表现不佳，即使是专门训练的模型也难以应对。


<details>
  <summary>Details</summary>
Motivation: 解决多模态语言模型在处理真实世界场景时出现的幻觉问题，弥合现有基准测试表现与实际推理能力之间的差距。

Method: 构建了一个包含10.5k个真实世界场景示例的新基准Common-O，并使用了专为多图像输入训练的模型和进行链式思考推理的模型进行了评估。

Result: 在Common-O基准测试中，表现最好的模型仅达到35%的准确率，在更复杂的Common-O Complex子集中更是只有1%。模型在场景中存在相似物体时更容易出现幻觉。模型规模和多图像训练是提升性能的关键因素。

Conclusion: 多模态语言模型在跨场景推理方面仍面临巨大挑战，现有模型在处理真实世界场景时容易产生幻觉。作者提出的Common-O基准能够有效揭示这一问题，并为未来研究指明方向。

Abstract: Multimodal language models possess a remarkable ability to handle an
open-vocabulary's worth of objects. Yet the best models still suffer from
hallucinations when reasoning about scenes in the real world, revealing a gap
between their seemingly strong performance on existing perception benchmarks
that are saturating and their reasoning in the real world. To address this gap,
we build a novel benchmark of in-the-wild scenes that we call Common-O. With
more than 10.5k examples using exclusively new images not found in web training
data to avoid contamination, Common-O goes beyond just perception, inspired by
cognitive tests for humans, to probe reasoning across scenes by asking "what's
in common?". We evaluate leading multimodal language models, including models
specifically trained to perform chain-of-thought reasoning. We find that
perceiving objects in single images is tractable for most models, yet reasoning
across scenes is very challenging even for the best models, including reasoning
models. Despite saturating many leaderboards focusing on perception, the best
performing model only achieves 35% on Common-O -- and on Common-O Complex,
consisting of more complex scenes, the best model achieves only 1%. Curiously,
we find models are more prone to hallucinate when similar objects are present
in the scene, suggesting models may be relying on object co-occurrence seen
during training. Among the models we evaluated, we found scale can provide
modest improvements while models explicitly trained with multi-image inputs
show bigger improvements, suggesting scaled multi-image training may offer
promise. We make our benchmark publicly available to spur research into the
challenge of hallucination when reasoning across scenes.

</details>


### [235] [Enhancing Multimodal Protein Function Prediction Through Dual-Branch Dynamic Selection with Reconstructive Pre-Training](https://arxiv.org/abs/2511.04040)
*Xiaoling Luo,Peng Chen,Chengliang Liu,Xiaopeng Jin,Jie Wen,Yumeng Liu,Junsong Wang*

Main category: cs.LG

TL;DR: DSRPGO是一种利用动态选择和重建预训练机制的多模态蛋白质功能预测方法，通过挖掘细粒度信息和促进多模态特征间的交互学习，提高了蛋白质功能预测的准确性，特别是在BPO、MFO和CCO方面表现优于基准模型。


<details>
  <summary>Details</summary>
Motivation: 蛋白质功能预测依赖于包含结构、序列、属性和相互作用网络等多方面信息的蛋白质多模态特征，但这些特征之间复杂的相互联系难以理解。

Method: 提出了一种名为DSRPGO的多模态蛋白质功能预测方法，该方法利用动态选择和重建预训练机制。通过重建预训练挖掘低语义级别的细粒度信息，引入了双向交互模块（BInM）促进多模态特征间的交互学习，并设计了动态选择模块（DSM）来选择最有利于当前蛋白质功能预测的特征表示，以解决分层多标签分类的挑战。

Result: 所提出的DSRPGO模型在人类数据集的BPO、MFO和CCO方面取得了显著的改进，并且优于其他基准模型。

Conclusion: DSRPGO模型通过其创新的机制有效地处理了多模态蛋白质特征的复杂性，并在蛋白质功能预测任务中取得了优越的性能。

Abstract: Multimodal protein features play a crucial role in protein function
prediction. However, these features encompass a wide range of information,
ranging from structural data and sequence features to protein attributes and
interaction networks, making it challenging to decipher their complex
interconnections. In this work, we propose a multimodal protein function
prediction method (DSRPGO) by utilizing dynamic selection and reconstructive
pre-training mechanisms. To acquire complex protein information, we introduce
reconstructive pre-training to mine more fine-grained information with low
semantic levels. Moreover, we put forward the Bidirectional Interaction Module
(BInM) to facilitate interactive learning among multimodal features.
Additionally, to address the difficulty of hierarchical multi-label
classification in this task, a Dynamic Selection Module (DSM) is designed to
select the feature representation that is most conducive to current protein
function prediction. Our proposed DSRPGO model improves significantly in BPO,
MFO, and CCO on human datasets, thereby outperforming other benchmark models.

</details>


### [236] [Contamination Detection for VLMs using Multi-Modal Semantic Perturbation](https://arxiv.org/abs/2511.03774)
*Jaden Park,Mu Cai,Feng Yao,Jingbo Shang,Soochahn Lee,Yong Jae Lee*

Main category: cs.LG

TL;DR: 通过引入多模态语义扰动来检测受污染的视觉-语言模型（VLM），解决了现有检测方法失效的问题。


<details>
  <summary>Details</summary>
Motivation: 现有视觉-语言模型（VLM）的训练数据可能存在测试集泄露问题，但缺乏有效的检测污染的方法。

Method: 通过在公开的VLM上进行故意污染，并提出一种基于多模态语义扰动的新检测方法，观察模型在扰动下的泛化能力。

Result: 现有检测方法效果不佳或行为不一致；提出的新方法能有效检测出受污染的模型，且在多种污染策略下均表现稳健。

Conclusion: 所提出的多模态语义扰动方法是一种有效且稳健的检测受污染VLM的方法，填补了现有研究的空白。

Abstract: Recent advances in Vision-Language Models (VLMs) have achieved
state-of-the-art performance on numerous benchmark tasks. However, the use of
internet-scale, often proprietary, pretraining corpora raises a critical
concern for both practitioners and users: inflated performance due to test-set
leakage. While prior works have proposed mitigation strategies such as
decontamination of pretraining data and benchmark redesign for LLMs, the
complementary direction of developing detection methods for contaminated VLMs
remains underexplored. To address this gap, we deliberately contaminate
open-source VLMs on popular benchmarks and show that existing detection
approaches either fail outright or exhibit inconsistent behavior. We then
propose a novel simple yet effective detection method based on multi-modal
semantic perturbation, demonstrating that contaminated models fail to
generalize under controlled perturbations. Finally, we validate our approach
across multiple realistic contamination strategies, confirming its robustness
and effectiveness. The code and perturbed dataset will be released publicly.

</details>


### [237] [FusionDP: Foundation Model-Assisted Differentially Private Learning for Partially Sensitive Features](https://arxiv.org/abs/2511.03806)
*Linghui Zeng,Ruixuan Liu,Atiquer Rahman Sarkar,Xiaoqian Jiang,Joyce C. Ho,Li Xiong*

Main category: cs.LG

TL;DR: FusionDP通过利用大型基础模型进行敏感特征的插补，并在保留原始敏感特征隐私的同时，对原始和插补后的特征进行模型训练，从而在特征级别差分隐私下提高模型效用。


<details>
  <summary>Details</summary>
Motivation: 在隐私保护的机器学习中，确保敏感训练数据的隐私至关重要，但实际应用中可能只需要对部分特征进行隐私保护，而传统的DP-SGD在所有特征上强制执行隐私保护会导致过多的噪声和效用降低。

Method: FusionDP是一个两步框架：1. 利用大型基础模型根据非敏感特征推断敏感特征，将其作为外部先验，在模型训练期间无需访问真实值即可提供高质量的敏感属性估计。2. 引入修改后的DP-SGD算法，在模型训练中同时使用原始和推断出的特征，同时严格保护原始敏感特征的隐私。

Result: 在PhysioNet的表格数据和MIMIC-III的临床笔记分类任务上，FusionDP显著提高了模型性能，同时保持了严格的特征级别隐私。

Conclusion: FusionDP展示了基础模型驱动的插补在改善隐私-效用权衡方面的潜力。

Abstract: Ensuring the privacy of sensitive training data is crucial in
privacy-preserving machine learning. However, in practical scenarios, privacy
protection may be required for only a subset of features. For instance, in ICU
data, demographic attributes like age and gender pose higher privacy risks due
to their re-identification potential, whereas raw lab results are generally
less sensitive. Traditional DP-SGD enforces privacy protection on all features
in one sample, leading to excessive noise injection and significant utility
degradation. We propose FusionDP, a two-step framework that enhances model
utility under feature-level differential privacy. First, FusionDP leverages
large foundation models to impute sensitive features given non-sensitive
features, treating them as external priors that provide high-quality estimates
of sensitive attributes without accessing the true values during model
training. Second, we introduce a modified DP-SGD algorithm that trains models
on both original and imputed features while formally preserving the privacy of
the original sensitive features. We evaluate FusionDP on two modalities: a
sepsis prediction task on tabular data from PhysioNet and a clinical note
classification task from MIMIC-III. By comparing against privacy-preserving
baselines, our results show that FusionDP significantly improves model
performance while maintaining rigorous feature-level privacy, demonstrating the
potential of foundation model-driven imputation to enhance the privacy-utility
trade-off for various modalities.

</details>


### [238] [Fair and Explainable Credit-Scoring under Concept Drift: Adaptive Explanation Frameworks for Evolving Populations](https://arxiv.org/abs/2511.03807)
*Shivogo John*

Main category: cs.LG

TL;DR: 为了解决信用评分系统中概念漂移导致的可解释性不稳和不公平问题，本研究提出并评估了三种自适应解释框架：(A) 基于切片的重加权、(B) 基于滑动窗口重设基线的漂移感知解释、(C) 在线代理校准。实验结果表明，这些自适应方法在不损害预测精度的前提下，显著提高了模型的可解释性 temporal stability，并减少了不同人口统计群体间的差异。


<details>
  <summary>Details</summary>
Motivation: 传统的 SHAP 等可解释性技术假设数据分布固定不变，在概念漂移发生时，其解释会变得不稳定甚至不公平。这对于在动态变化的信用评分系统尤为重要。

Method: 本研究提出并集成了三种自适应 SHAP 变体到 XGBoost 预测模型中：(A) 针对特征分布变化的切片重加权；(B) 使用滑动窗口背景样本的漂移感知重设基线；(C) 使用增量岭回归的在线代理校准。

Result: 结果显示，自适应方法（特别是重设基线和基于代理的解释）在不降低预测准确性的情况下，显著提高了时间稳定性和公平性（减少了不同群体间的差异）。稳健性测试也证实了其在真实世界漂移条件下的可靠性。

Conclusion: 自适应可解释性是维持数据驱动信用系统中透明度、问责制和道德可靠性的实用机制，同样适用于其他决策模型随人群变化而演变的领域。

Abstract: Evolving borrower behaviors, shifting economic conditions, and changing
regulatory landscapes continuously reshape the data distributions underlying
modern credit-scoring systems. Conventional explainability techniques, such as
SHAP, assume static data and fixed background distributions, making their
explanations unstable and potentially unfair when concept drift occurs. This
study addresses that challenge by developing adaptive explanation frameworks
that recalibrate interpretability and fairness in dynamically evolving credit
models. Using a multi-year credit dataset, we integrate predictive modeling via
XGBoost with three adaptive SHAP variants: (A) per-slice explanation
reweighting that adjusts for feature distribution shifts, (B) drift-aware SHAP
rebaselining with sliding-window background samples, and (C) online surrogate
calibration using incremental Ridge regression. Each method is benchmarked
against static SHAP explanations using metrics of predictive performance (AUC,
F1), directional and rank stability (cosine, Kendall tau), and fairness
(demographic parity and recalibration). Results show that adaptive methods,
particularly rebaselined and surrogate-based explanations, substantially
improve temporal stability and reduce disparate impact across demographic
groups without degrading predictive accuracy. Robustness tests, including
counterfactual perturbations, background sensitivity analysis, and
proxy-variable detection, confirm the resilience of adaptive explanations under
real-world drift conditions. These findings establish adaptive explainability
as a practical mechanism for sustaining transparency, accountability, and
ethical reliability in data-driven credit systems, and more broadly, in any
domain where decision models evolve with population change.

</details>


### [239] [Optimizing Reasoning Efficiency through Prompt Difficulty Prediction](https://arxiv.org/abs/2511.03808)
*Bo Zhao,Berkcan Kapusuzoglu,Kartik Balasubramaniam,Sambit Sahu,Supriyo Chakraborty,Genta Indra Winata*

Main category: cs.LG

TL;DR: 通过路由将问题分配给最合适的模型来降低大型语言模型的部署成本，同时保持准确性。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在复杂任务上表现优异，但由于其规模和冗长的推理过程，部署成本高昂。

Method: 提出一种路由方法，为每个问题分配最可能解决该问题的最小模型。利用 s1.1-32B 的中间表示，训练轻量级预测器来预测问题难度或模型正确性，以指导路由过程。

Result: 在各种数学基准测试中，路由方法比随机分配提高了效率，并且在显著降低计算量的同时，达到了 s1.1-32B 的性能水平。

Conclusion: 证明了难度感知路由对于推理模型的成本效益部署是有效的。

Abstract: Reasoning language models perform well on complex tasks but are costly to
deploy due to their size and long reasoning traces. We propose a routing
approach that assigns each problem to the smallest model likely to solve it,
reducing compute without sacrificing accuracy. Using intermediate
representations from s1.1-32B, we train lightweight predictors of problem
difficulty or model correctness to guide routing across a pool of reasoning
models. On diverse math benchmarks, routing improves efficiency over random
assignment and matches s1.1-32B's performance while using significantly less
compute. Our results demonstrate that difficulty-aware routing is effective for
cost-efficient deployment of reasoning models.

</details>


### [240] [One Size Does Not Fit All: Architecture-Aware Adaptive Batch Scheduling with DEBA](https://arxiv.org/abs/2511.03809)
*François Belias,Naser Ezzati-Jivan,Foutse Khomh*

Main category: cs.LG

TL;DR: DEBA通过监控梯度方差、梯度范数变化和损失变化来动态调整批量大小，以加速神经网络训练。研究表明，批量大小的调整效果很大程度上取决于网络架构。轻量级和中等深度的网络（如MobileNet-V3、DenseNet-121、EfficientNet-B0）训练速度提升45-62%，准确率提升1-7%。浅层残差网络（ResNet-18）准确率提升2.4-4.0%，速度提升36-43%。深层残差网络（ResNet-50）表现出较高方差，有时准确率会下降。对于已稳定的架构（如ViT-B16），速度提升仅为6%，准确率保持不变。DEBA引入了一个基于梯度稳定性指标的基线特征框架，预测哪些架构能从动态批量大小调整中受益。此外，研究强调了滑动窗口统计和足够长的调整冷却期（5+个epoch）对于成功至关重要。


<details>
  <summary>Details</summary>
Motivation: 现有的自适应批量大小方法在所有架构上采用相同的调整策略，忽略了不同架构的差异。本研究旨在开发一种能够根据网络架构特性动态调整批量大小的方法，以实现更优的训练加速和准确率提升。

Method: 提出DEBA（动态高效批量自适应）算法，通过监控梯度方差、梯度范数变化和损失变化来指导批量大小的调整。在CIFAR-10和CIFAR-100数据集上，对六种不同架构（ResNet-18/50、DenseNet-121、EfficientNet-B0、MobileNet-V3、ViT-B16）进行了系统评估，并进行了消融研究，以验证算法的有效性并分析关键设计选择。

Result: 轻量级和中等深度的网络（MobileNet-V3、DenseNet-121、EfficientNet-B0）实现了45-62%的训练加速，同时准确率提升了1-7%。浅层残差网络（ResNet-18）准确率提升了2.4-4.0%，速度提升了36-43%。深层残差网络（ResNet-50）表现出高方差，有时准确率会下降。已稳定架构（ViT-B16）仅获得6%的速度提升，准确率保持不变。滑动窗口统计和5+个epoch的冷却期是成功的关键因素。

Conclusion: 批量大小的自适应调整效果在不同网络架构上存在显著差异。DEBA通过考虑架构特性，能够为轻量级和中等深度网络带来显著的训练加速和准确率提升。研究挑战了自适应方法在不同架构上通用的假设，并强调了架构感知设计的重要性。研究还指出了滑动窗口统计和足够的冷却期是实现有效自适应批量大小调整的关键。

Abstract: Adaptive batch size methods aim to accelerate neural network training, but
existing approaches apply identical adaptation strategies across all
architectures, assuming a one-size-fits-all solution. We introduce DEBA
(Dynamic Efficient Batch Adaptation), an adaptive batch scheduler that monitors
gradient variance, gradient norm variation and loss variation to guide batch
size adaptations. Through systematic evaluation across six architectures
(ResNet-18/50, DenseNet-121, EfficientNet-B0, MobileNet-V3, ViT-B16) on
CIFAR-10 and CIFAR-100, with five random seeds per configuration, we
demonstrate that the architecture fundamentally determines adaptation efficacy.
Our findings reveal that: (1) lightweight and medium-depth architectures
(MobileNet-V3, DenseNet-121, EfficientNet-B0) achieve a 45-62% training speedup
with simultaneous accuracy improvements of 1-7%; (2) shallow residual networks
(ResNet-18) show consistent gains of +2.4 - 4.0% in accuracy, 36 - 43% in
speedup, while deep residual networks (ResNet-50) exhibit high variance and
occasional degradation; (3) already-stable architectures (ViT-B16) show minimal
speedup (6%) despite maintaining accuracy, indicating that adaptation benefits
vary with baseline optimization characteristics. We introduce a baseline
characterization framework using gradient stability metrics (stability score,
gradient norm variation) that predicts which architectures will benefit from
adaptive scheduling. Our ablation studies reveal critical design choices often
overlooked in prior work: sliding window statistics (vs. full history) and
sufficient cooldown periods (5+ epochs) between adaptations are essential for
success. This work challenges the prevailing assumption that adaptive methods
generalize across architectures and provides the first systematic evidence that
batch size adaptation requires an architecture-aware design.

</details>


### [241] [Sketch-Augmented Features Improve Learning Long-Range Dependencies in Graph Neural Networks](https://arxiv.org/abs/2511.03824)
*Ryien Hosseini,Filippo Simini,Venkatram Vishwanath,Rebecca Willett,Henry Hoffmann*

Main category: cs.LG

TL;DR: 通过注入随机全局嵌入来增强图神经网络以克服信息瓶颈、过平滑和表达能力有限的问题。


<details>
  <summary>Details</summary>
Motivation: 现有的图神经网络（GNN）在处理长距离依赖关系、节点表示平滑以及有限的表达能力方面存在挑战。

Method: 提出了一种名为“Sketched Random Features”的技术，将随机全局节点嵌入注入到标准的GNN中，以有效地捕捉长距离依赖关系。

Result: 实验结果表明，该方法在真实世界的图学习任务中，相比基线GNN能够稳定地提高性能，并且可以作为一种独立解决方案或与图位置编码等现有技术互补。

Conclusion: 注入随机全局嵌入（Sketched Random Features）可以有效缓解GNN中的挑战，提高其性能。

Abstract: Graph Neural Networks learn on graph-structured data by iteratively
aggregating local neighborhood information. While this local message passing
paradigm imparts a powerful inductive bias and exploits graph sparsity, it also
yields three key challenges: (i) oversquashing of long-range information, (ii)
oversmoothing of node representations, and (iii) limited expressive power. In
this work we inject randomized global embeddings of node features, which we
term \textit{Sketched Random Features}, into standard GNNs, enabling them to
efficiently capture long-range dependencies. The embeddings are unique,
distance-sensitive, and topology-agnostic -- properties which we analytically
and empirically show alleviate the aforementioned limitations when injected
into GNNs. Experimental results on real-world graph learning tasks confirm that
this strategy consistently improves performance over baseline GNNs, offering
both a standalone solution and a complementary enhancement to existing
techniques such as graph positional encodings. Our source code is available at
\href{https://github.com/ryienh/sketched-random-features}{https://github.com/ryienh/sketched-random-features}.

</details>


### [242] [Regret Lower Bounds for Decentralized Multi-Agent Stochastic Shortest Path Problems](https://arxiv.org/abs/2511.04594)
*Utkarsh U. Chavan,Prashant Trivedi,Nandyala Hemachandra*

Main category: cs.LG

TL;DR: 本文研究了去中心化多智能体随机最短路径问题（Dec-MASSPs），并提出了首个带后悔值下界的结果，揭示了此类问题的固有学习难度。


<details>
  <summary>Details</summary>
Motivation: 多智能体系统（MAS）在机器人学和交通路径规划等领域至关重要，需要去中心化协调以达成共同目标。随机最短路径（SSP）问题是去中心化控制的自然模型，但其去中心化多智能体变体研究不足。

Method: 在共享线性函数逼近的假设下，研究去中心化多智能体随机最短路径问题（Dec-MASSPs）。利用新颖的对称性论证来识别最优策略的结构。在此基础上，构建了难学的实例，为任何数量的智能体n得出了后悔值下界。

Result: 得出了后悔值下界为 $\Omega(\sqrt{K})$（K为试验次数），这表明Dec-MASSPs问题的固有学习难度。

Conclusion: 本文提出的后悔值下界（$\Omega(\sqrt{K})$）揭示了Dec-MASSPs问题的学习复杂性，并能指导设计更高效的多智能体学习算法。

Abstract: Multi-agent systems (MAS) are central to applications such as swarm robotics
and traffic routing, where agents must coordinate in a decentralized manner to
achieve a common objective. Stochastic Shortest Path (SSP) problems provide a
natural framework for modeling decentralized control in such settings. While
the problem of learning in SSP has been extensively studied in single-agent
settings, the decentralized multi-agent variant remains largely unexplored. In
this work, we take a step towards addressing that gap. We study decentralized
multi-agent SSPs (Dec-MASSPs) under linear function approximation, where the
transition dynamics and costs are represented using linear models. Applying
novel symmetry-based arguments, we identify the structure of optimal policies.
Our main contribution is the first regret lower bound for this setting based on
the construction of hard-to-learn instances for any number of agents, $n$. Our
regret lower bound of $\Omega(\sqrt{K})$, over $K$ episodes, highlights the
inherent learning difficulty in Dec-MASSPs. These insights clarify the learning
complexity of decentralized control and can further guide the design of
efficient learning algorithms in multi-agent systems.

</details>


### [243] [From Static to Dynamic: Enhancing Offline-to-Online Reinforcement Learning via Energy-Guided Diffusion Stratification](https://arxiv.org/abs/2511.03828)
*Lipeng Zu,Hansong Zhou,Xiaonan Zhang*

Main category: cs.LG

TL;DR: 本研究提出了StratDiff方法，通过利用扩散模型和能量函数来解决离线到在线强化学习中的分布偏移问题，通过区分“离线类”和“在线类”样本并采用不同的学习策略，显著提升了学习的适应性和稳定性。


<details>
  <summary>Details</summary>
Motivation: 离线到在线强化学习面临分布偏移的挑战，现有方法未能充分利用离线数据的分布结构。本研究旨在填补这一研究空白，提出一种能根据样本特性调整学习策略的方法。

Method: StratDiff使用扩散模型学习离线数据集的先验知识，并通过能量函数进行细化。计算生成动作与采样动作之间的KL散度，将训练批次划分为“离线类”和“在线类”样本。离线类样本使用离线目标更新，在线类样本遵循在线学习策略。

Result: 在D4RL基准测试中，StratDiff与Cal-QL和IQL结合使用，其性能显著优于现有方法，在各种强化学习设置下表现出更强的适应性和更稳定的性能。

Conclusion: StratDiff通过对样本进行分层并采用差异化的学习策略，有效地解决了离线到在线强化学习中的分布偏移问题，提高了学习的稳定性和适应性。

Abstract: Transitioning from offline to online reinforcement learning (RL) poses
critical challenges due to distributional shifts between the fixed behavior
policy in the offline dataset and the evolving policy during online learning.
Although this issue is widely recognized, few methods attempt to explicitly
assess or utilize the distributional structure of the offline data itself,
leaving a research gap in adapting learning strategies to different types of
samples. To address this challenge, we propose an innovative method,
Energy-Guided Diffusion Stratification (StratDiff), which facilitates smoother
transitions in offline-to-online RL. StratDiff deploys a diffusion model to
learn prior knowledge from the offline dataset. It then refines this knowledge
through energy-based functions to improve policy imitation and generate
offline-like actions during online fine-tuning. The KL divergence between the
generated action and the corresponding sampled action is computed for each
sample and used to stratify the training batch into offline-like and
online-like subsets. Offline-like samples are updated using offline objectives,
while online-like samples follow online learning strategies. We demonstrate the
effectiveness of StratDiff by integrating it with off-the-shelf methods Cal-QL
and IQL. Extensive empirical evaluations on D4RL benchmarks show that StratDiff
significantly outperforms existing methods, achieving enhanced adaptability and
more stable performance across diverse RL settings.

</details>


### [244] [Higher-Order Causal Structure Learning with Additive Models](https://arxiv.org/abs/2511.03831)
*James Enouen,Yujia Zheng,Ignavier Ng,Yan Liu,Kun Zhang*

Main category: cs.LG

TL;DR: 本篇论文将因果狸模型（CAM）扩展到包含高阶交互作用的加性模型，并引入了有向无环超图（hyper DAG）的概念来表示这种新结构。论文提供了处理这种新结构的理论工具，并给出了超 DAG 的可识别性结果，扩展了经典的马尔可夫等价类。研究还表明，更强的假设（如 CAM）可以使超 DAG 学习更容易，并提高有限样本下的复杂度。最后，论文开发了一个贪婪的 CAM 算法扩展，能够处理更复杂的超 DAG 搜索空间，并通过合成实验证明了其有效性。


<details>
  <summary>Details</summary>
Motivation: 现有因果结构学习方法在处理具有高阶交互机制的现实世界过程方面存在不足。本研究旨在扩展因果加性模型（CAM），以处理具有高阶交互作用的加性模型，从而填补这一空白。

Method: 引入有向无环超图（hyper DAG）来表示包含高阶交互作用的加性模型，并推导了相应的理论定义和工具。在此基础上，研究了超 DAG 的可识别性，并推导了其马尔可夫等价类。此外，还开发了一种贪婪的 CAM 算法的扩展版本，用于学习超 DAG。

Result: 研究表明，更强的假设（如 CAM）对应于更易于学习的超 DAG，并具有更好的有限样本复杂度。通过合成实验，证明了所提出的算法在处理超 DAG 搜索空间方面的经验有效性。

Conclusion: 本研究成功地将因果发现的范围扩展到包含高阶交互作用的模型，并提出了相应的理论框架和算法。研究结果表明，这种扩展不仅能更准确地建模现实世界过程，而且在某些情况下还能提高学习效率和样本复杂度。

Abstract: Causal structure learning has long been the central task of inferring causal
insights from data. Despite the abundance of real-world processes exhibiting
higher-order mechanisms, however, an explicit treatment of interactions in
causal discovery has received little attention. In this work, we focus on
extending the causal additive model (CAM) to additive models with higher-order
interactions. This second level of modularity we introduce to the structure
learning problem is most easily represented by a directed acyclic hypergraph
which extends the DAG. We introduce the necessary definitions and theoretical
tools to handle the novel structure we introduce and then provide
identifiability results for the hyper DAG, extending the typical Markov
equivalence classes. We next provide insights into why learning the more
complex hypergraph structure may actually lead to better empirical results. In
particular, more restrictive assumptions like CAM correspond to easier-to-learn
hyper DAGs and better finite sample complexity. We finally develop an extension
of the greedy CAM algorithm which can handle the more complex hyper DAG search
space and demonstrate its empirical usefulness in synthetic experiments.

</details>


### [245] [Enhancing Q-Value Updates in Deep Q-Learning via Successor-State Prediction](https://arxiv.org/abs/2511.03836)
*Lipeng Zu,Hansong Zhou,Xiaonan Zhang*

Main category: cs.LG

TL;DR: SADQ通过建立环境动态模型来解决DQN中的高方差问题，从而实现更稳定、更高效的Q值更新。


<details>
  <summary>Details</summary>
Motivation: DQN的目标更新依赖于过去可能次优策略产生的下一个状态，这可能导致学习信号缺乏信息量，增加更新过程中的方差，尤其是在采样转移与当前策略不一致时。

Method: SADQ通过整合后继状态分布到Q值估计中，并利用随机转移模型来显式建模环境动态，同时探索一种更有效的动作选择策略。

Result: SADQ在标准的RL基准和现实世界的向量控制任务中，相较于DQN变体，在稳定性和学习效率方面都表现出持续的优越性。

Conclusion: SADQ通过建模环境动态和整合后继状态分布，实现了无偏的价值估计，并降低了训练方差，从而在实践中提高了学习的稳定性和效率。

Abstract: Deep Q-Networks (DQNs) estimate future returns by learning from transitions
sampled from a replay buffer. However, the target updates in DQN often rely on
next states generated by actions from past, potentially suboptimal, policy. As
a result, these states may not provide informative learning signals, causing
high variance into the update process. This issue is exacerbated when the
sampled transitions are poorly aligned with the agent's current policy. To
address this limitation, we propose the Successor-state Aggregation Deep
Q-Network (SADQ), which explicitly models environment dynamics using a
stochastic transition model. SADQ integrates successor-state distributions into
the Q-value estimation process, enabling more stable and policy-aligned value
updates. Additionally, it explores a more efficient action selection strategy
with the modeled transition structure. We provide theoretical guarantees that
SADQ maintains unbiased value estimates while reducing training variance. Our
extensive empirical results across standard RL benchmarks and real-world
vector-based control tasks demonstrate that SADQ consistently outperforms DQN
variants in both stability and learning efficiency.

</details>


### [246] [Benchmark Datasets for Lead-Lag Forecasting on Social Platforms](https://arxiv.org/abs/2511.03877)
*Kimia Kazemian,Zhenzhen Liu,Yangfanyu Yang,Katie Z Luo,Shuhan Gu,Audrey Du,Xinyu Yang,Jack Jansons,Kilian Q Weinberger,John Thickstun,Yian Yin,Sarah Dean*

Main category: cs.LG

TL;DR: 本篇论文提出了一个名为“先行滞后预测”（Lead-Lag Forecasting, LLF）的新型预测问题，旨在预测早期用户行为（如浏览、点赞）与稍后发生的高影响力事件（如引用、销售）之间的关系。研究者为此构建了两个大规模数据集（arXiv和GitHub），并对该问题进行了基线方法的评估，为未来研究奠定了基础。


<details>
  <summary>Details</summary>
Motivation: 社交和协作平台上的早期互动（如浏览、点赞）往往在数月甚至数年后才会带来高影响力结果（如引用、销售、评论）。然而，时间序列社区尚未将这种“先行滞后”现象统一视为一个预测问题，主要是因为缺乏标准化数据集。本研究旨在解决这个问题。

Method: 研究者提出了“先行滞后预测”（LLF）的设定，并构建了两个大规模基准数据集：arXiv（2.3M篇论文的访问量 -> 引用量）和GitHub（3M个仓库的推送/星标 -> 分叉数）。此外，他们还验证了先行滞后动态的存在性，并通过统计和分类测试进行了评估，同时对参数和非参数回归基线进行了基准测试。

Result: 研究者构建了两个大规模数据集（arXiv和GitHub），并验证了先行滞后动态的存在性。他们还对参数和非参数回归基线进行了基准测试，为LLF问题提供了实证基础。

Conclusion: 本研究将LLF确立为一个新的预测范式，并为在社交和使用数据中对其进行系统性探索奠定了实证基础。研究者提供了包含下载和文档的数据门户。

Abstract: Social and collaborative platforms emit multivariate time-series traces in
which early interactions-such as views, likes, or downloads-are followed,
sometimes months or years later, by higher impact like citations, sales, or
reviews. We formalize this setting as Lead-Lag Forecasting (LLF): given an
early usage channel (the lead), predict a correlated but temporally shifted
outcome channel (the lag). Despite the ubiquity of such patterns, LLF has not
been treated as a unified forecasting problem within the time-series community,
largely due to the absence of standardized datasets. To anchor research in LLF,
here we present two high-volume benchmark datasets-arXiv (accesses -> citations
of 2.3M papers) and GitHub (pushes/stars -> forks of 3M repositories)-and
outline additional domains with analogous lead-lag dynamics, including
Wikipedia (page views -> edits), Spotify (streams -> concert attendance),
e-commerce (click-throughs -> purchases), and LinkedIn profile (views ->
messages). Our datasets provide ideal testbeds for lead-lag forecasting, by
capturing long-horizon dynamics across years, spanning the full spectrum of
outcomes, and avoiding survivorship bias in sampling. We documented all
technical details of data curation and cleaning, verified the presence of
lead-lag dynamics through statistical and classification tests, and benchmarked
parametric and non-parametric baselines for regression. Our study establishes
LLF as a novel forecasting paradigm and lays an empirical foundation for its
systematic exploration in social and usage data. Our data portal with downloads
and documentation is available at https://lead-lag-forecasting.github.io/.

</details>


### [247] [Conditional Score Learning for Quickest Change Detection in Markov Transition Kernels](https://arxiv.org/abs/2511.03953)
*Wuxia Chen,Taposh Banerjee,Vahid Tarokh*

Main category: cs.LG

TL;DR: 本研究提出了一种在马尔可夫过程（未知转移核）中进行最快变化检测的方法，通过直接从样本对学习条件分数来避免显式似然评估，并开发了一种基于分数的 CUSUM 程序来检测转移核的变化，同时提供了理论和实践保证。


<details>
  <summary>Details</summary>
Motivation: 解决具有未知转移核的马尔可夫过程中最快变化检测的问题。

Method: 直接从样本对 $(\mathbf{x},\mathbf{y})$ 学习条件分数 $\nabla_{\mathbf{y}} \log p(\mathbf{y}|\mathbf{x})$，开发基于分数的 CUSUM 程序，使用条件 Hyvarinen 分数差异检测转移核中的变化，并提出截断版本以确保增量有界。

Result: 证明了虚警平均时间的指数下界和检测延迟的渐近上界，为基于分数的检测提供了理论保证和实践可行性。

Conclusion: 基于分数的方法在理论上保证了检测性能，并且在实践中可行，可用于高维马尔可夫模型的最快变化检测。

Abstract: We address the problem of quickest change detection in Markov processes with
unknown transition kernels. The key idea is to learn the conditional score
$\nabla_{\mathbf{y}} \log p(\mathbf{y}|\mathbf{x})$ directly from sample pairs
$( \mathbf{x},\mathbf{y})$, where both $\mathbf{x}$ and $\mathbf{y}$ are
high-dimensional data generated by the same transition kernel. In this way, we
avoid explicit likelihood evaluation and provide a practical way to learn the
transition dynamics. Based on this estimation, we develop a score-based CUSUM
procedure that uses conditional Hyvarinen score differences to detect changes
in the kernel. To ensure bounded increments, we propose a truncated version of
the statistic. With Hoeffding's inequality for uniformly ergodic Markov
processes, we prove exponential lower bounds on the mean time to false alarm.
We also prove asymptotic upper bounds on detection delay. These results give
both theoretical guarantees and practical feasibility for score-based detection
in high-dimensional Markov models.

</details>


### [248] [DecoHD: Decomposed Hyperdimensional Classification under Extreme Memory Budgets](https://arxiv.org/abs/2511.03911)
*Sanggeon Yun,Hyunwoo Oh,Ryozo Masukawa,Mohsen Imani*

Main category: cs.LG

TL;DR: DecoHD是一种新的超维计算（HDC）分解方法，可以在极大地减小模型尺寸的同时，保持模型的准确性和鲁棒性，并且在硬件上实现了显著的能效和速度提升。


<details>
  <summary>Details</summary>
Motivation: 现有的超维计算（HDC）分解方法在压缩模型时会损害模型的准确性和鲁棒性，并且无法有效地压缩学习到的类别原型。因此，需要一种新的分解方法来解决这些问题。

Method: DecoHD学习一种分解的HDC参数化方法，通过使用一小组共享的每层通道，在层之间进行乘法绑定，并在最后进行捆绑，从而从紧凑的因子中获得大的表示空间。同时，DecoHD通过轻量级的捆绑头沿着类别轴进行压缩，并保持了原有的绑定-捆绑-评分机制。该模型支持端到端训练，并且推理过程保持纯粹的HDC，与内存中/近内存加速器兼容。

Result: DecoHD在内存节省方面取得了显著的成效，同时准确性仅有轻微下降。在与基线模型相比，其准确率损失在0.1-0.15%以内（最差情况为5.7%），对随机比特翻转噪声的鲁棒性更强，仅需97%的训练参数即可达到准确率平台期。在硬件方面，与CPU相比，DecoHD实现了约277倍/35倍的能耗/速度提升；与GPU相比，实现了13.5倍/3.7倍的提升；与基线HDC ASIC相比，也实现了2.0倍/2.4倍的提升。

Conclusion: DecoHD成功地将分解方法应用于HDC，实现了极高的内存压缩率，同时保持了模型的准确性、鲁棒性，并在硬件上实现了显著的能效和速度优势。

Abstract: Decomposition is a proven way to shrink deep networks without changing I/O.
We bring this idea to hyperdimensional computing (HDC), where footprint cuts
usually shrink the feature axis and erode concentration and robustness. Prior
HDC decompositions decode via fixed atomic hypervectors, which are ill-suited
for compressing learned class prototypes. We introduce DecoHD, which learns
directly in a decomposed HDC parameterization: a small, shared set of per-layer
channels with multiplicative binding across layers and bundling at the end,
yielding a large representational space from compact factors. DecoHD compresses
along the class axis via a lightweight bundling head while preserving native
bind-bundle-score; training is end-to-end, and inference remains pure HDC,
aligning with in/near-memory accelerators. In evaluation, DecoHD attains
extreme memory savings with only minor accuracy degradation under tight
deployment budgets. On average it stays within about 0.1-0.15% of a strong
non-reduced HDC baseline (worst case 5.7%), is more robust to random bit-flip
noise, reaches its accuracy plateau with up to ~97% fewer trainable parameters,
and -- in hardware -- delivers roughly 277x/35x energy/speed gains over a CPU
(AMD Ryzen 9 9950X), 13.5x/3.7x over a GPU (NVIDIA RTX 4090), and 2.0x/2.4x
over a baseline HDC ASIC.

</details>


### [249] [On Predicting Sociodemographics from Mobility Signals](https://arxiv.org/abs/2511.03924)
*Ekin Uğurel,Cynthia Chen,Brian H. Y. Lee,Filipe Rodrigues*

Main category: cs.LG

TL;DR: 通过行为分析的移动图描述符、可视化诊断工具和多任务学习框架，提高从移动数据推断社会人口属性的准确性和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 移动数据推断社会人口属性面临关系弱、不一致和泛化能力有限的挑战。

Method: 提出基于有向移动图的高阶移动描述符；引入衡量模型置信度和准确度之间均衡性的度量和可视化诊断工具；开发多任务学习框架来联合预测多个社会人口属性。

Result: 行为分析的移动图描述符在预测年龄、性别、收入和家庭结构方面显著优于基线特征；提出的方法在训练数据有限或跨时间段应用模型时，性能优于单任务模型。

Conclusion: 提出的方法通过行为分析的移动图描述符、可视化诊断工具和多任务学习框架，提高了从移动数据推断社会人口属性的准确性和泛化能力。

Abstract: Inferring sociodemographic attributes from mobility data could help
transportation planners better leverage passively collected datasets, but this
task remains difficult due to weak and inconsistent relationships between
mobility patterns and sociodemographic traits, as well as limited
generalization across contexts. We address these challenges from three angles.
First, to improve predictive accuracy while retaining interpretability, we
introduce a behaviorally grounded set of higher-order mobility descriptors
based on directed mobility graphs. These features capture structured patterns
in trip sequences, travel modes, and social co-travel, and significantly
improve prediction of age, gender, income, and household structure over
baselines features. Second, we introduce metrics and visual diagnostic tools
that encourage evenness between model confidence and accuracy, enabling
planners to quantify uncertainty. Third, to improve generalization and sample
efficiency, we develop a multitask learning framework that jointly predicts
multiple sociodemographic attributes from a shared representation. This
approach outperforms single-task models, particularly when training data are
limited or when applying models across different time periods (i.e., when the
test set distribution differs from the training set).

</details>


### [250] [SynQuE: Estimating Synthetic Dataset Quality Without Annotations](https://arxiv.org/abs/2511.03928)
*Arthur Chen,Victor Zhong*

Main category: cs.LG

TL;DR: 该论文提出了一个名为SynQuE（Synthetic Dataset Quality Estimation）的新问题，旨在仅利用有限的未标注真实数据来评估和排序合成数据集的预期真实世界任务性能，以解决数据稀疏性问题。


<details>
  <summary>Details</summary>
Motivation: 由于收集成本或隐私限制导致数据稀缺，这是一个关键且尚未解决的挑战，需要一种方法来选择最适合真实世界任务的合成数据集。 

Method: 作者首先建立了第一个全面的基准，并通过评估向代理指标（proxy metrics）介绍SynQuE问题。这些代理指标旨在选择训练用的合成数据以最大化在真实数据上的任务性能。他们通过嵌入模型将基于分布和多样性的距离度量改编到SynQuE的背景中。为了克服这些指标在复杂规划任务上的局限性，作者提出了LENS，一个利用大型语言模型推理能力的新型代理。

Result: 实验结果表明，SynQuE代理指标在各种任务（包括情感分析、Text2SQL、网页导航和图像分类）上与真实任务性能相关。LENS在复杂任务上始终表现优于其他指标，能够捕捉细微的特征。例如，在text-to-SQL解析任务中，与无差别选择数据相比，通过SynQuE代理选择的前3个合成数据集进行训练，可以将准确率从平均30.4%提高到38.4%（+8.1%）。

Conclusion: 该研究确立了SynQuE作为一种在真实数据稀缺情况下进行合成数据选择的实用框架，并为未来在基于基础模型的数据表征和细粒度数据选择方面的研究提供了动力。

Abstract: We introduce and formalize the Synthetic Dataset Quality Estimation (SynQuE)
problem: ranking synthetic datasets by their expected real-world task
performance using only limited unannotated real data. This addresses a critical
and open challenge where data is scarce due to collection costs or privacy
constraints. We establish the first comprehensive benchmarks for this problem
by introducing and evaluating proxy metrics that choose synthetic data for
training to maximize task performance on real data. We introduce the first
proxy metrics for SynQuE by adapting distribution and diversity-based distance
measures to our context via embedding models. To address the shortcomings of
these metrics on complex planning tasks, we propose LENS, a novel proxy that
leverages large language model reasoning. Our results show that SynQuE proxies
correlate with real task performance across diverse tasks, including sentiment
analysis, Text2SQL, web navigation, and image classification, with LENS
consistently outperforming others on complex tasks by capturing nuanced
characteristics. For instance, on text-to-SQL parsing, training on the top-3
synthetic datasets selected via SynQuE proxies can raise accuracy from 30.4% to
38.4 (+8.1)% on average compared to selecting data indiscriminately. This work
establishes SynQuE as a practical framework for synthetic data selection under
real-data scarcity and motivates future research on foundation model-based data
characterization and fine-grained data selection.

</details>


### [251] [NVIDIA Nemotron Nano V2 VL](https://arxiv.org/abs/2511.03929)
*NVIDIA,:,Amala Sanjay Deshmukh,Kateryna Chumachenko,Tuomas Rintamaki,Matthieu Le,Tyler Poon,Danial Mohseni Taheri,Ilia Karmanov,Guilin Liu,Jarno Seppanen,Guo Chen,Karan Sapra,Zhiding Yu,Adi Renduchintala,Charles Wang,Peter Jin,Arushi Goel,Mike Ranzinger,Lukas Voegtle,Philipp Fischer,Timo Roman,Wei Ping,Boxin Wang,Zhuolin Yang,Nayeon Lee,Shaokun Zhang,Fuxiao Liu,Zhiqi Li,Di Zhang,Greg Heinrich,Hongxu,Yin,Song Han,Pavlo Molchanov,Parth Mannan,Yao Xu,Jane Polak Scowcroft,Tom Balough,Subhashree Radhakrishnan,Paris Zhang,Sean Cha,Ratnesh Kumar,Zaid Pervaiz Bhat,Jian Zhang,Darragh Hanley,Pritam Biswas,Jesse Oliver,Kevin Vasques,Roger Waleffe,Duncan Riach,Oluwatobi Olabiyi,Ameya Sunil Mahabaleshwarkar,Bilal Kartal,Pritam Gundecha,Khanh Nguyen,Alexandre Milesi,Eugene Khvedchenia,Ran Zilberstein,Ofri Masad,Natan Bagrov,Nave Assaf,Tomer Asida,Daniel Afrimi,Amit Zuker,Netanel Haber,Zhiyu Cheng,Jingyu,Xin,Di,Wu,Nik Spirin,Maryam Moosaei,Roman Ageev,Vanshil Atul Shah,Yuting Wu,Daniel Korzekwa,Unnikrishnan Kizhakkemadam Sreekumar,Wanli Jiang,Padmavathy Subramanian,Alejandra Rico,Sandip Bhaskar,Saeid Motiian,Kedi Wu,Annie Surla,Chia-Chih Chen,Hayden Wolff,Matthew Feinberg,Melissa Corpuz,Marek Wawrzos,Eileen Long,Aastha Jhunjhunwala,Paul Hendricks,Farzan Memarian,Benika Hall,Xin-Yu Wang,David Mosallanezhad,Soumye Singhal,Luis Vega,Katherine Cheung,Krzysztof Pawelec,Michael Evans,Katherine Luna,Jie Lou,Erick Galinkin,Akshay Hazare,Kaustubh Purandare,Ann Guan,Anna Warno,Chen Cui,Yoshi Suhara,Shibani Likhite,Seph Mard,Meredith Price,Laya Sleiman,Saori Kaji,Udi Karpas,Kari Briski,Joey Conway,Michael Lightstone,Jan Kautz,Mohammad Shoeybi,Mostofa Patwary,Jonathen Cohen,Oleksii Kuchaiev,Andrew Tao,Bryan Catanzaro*

Main category: cs.LG

TL;DR: Nemotron Nano V2 VL 是 Nemotron 视觉-语言系列的最新模型，在文档理解、视频理解和推理任务方面表现出色。


<details>
  <summary>Details</summary>
Motivation: Nemotron Nano V2 VL 的主要目标是提供强大的现实世界文档理解、长视频理解和推理能力。

Method: 该模型基于 Nemotron Nano V2（一种混合 Mamba-Transformer LLM）构建，并采用了创新的令牌缩减技术，以在长文档和视频场景中实现更高的推理吞吐量。

Result: Nemotron Nano V2 VL 在所有视觉和文本领域都取得了显著的改进，超越了之前的模型 Llama-3.1-Nemotron-Nano-VL-8B。

Conclusion: Nemotron Nano V2 VL 在模型架构、数据集和训练方法方面进行了重大改进，并在 BF16、FP8 和 FP4 格式下发布了模型检查点，同时公开了大部分数据集、训练方法和代码。

Abstract: We introduce Nemotron Nano V2 VL, the latest model of the Nemotron
vision-language series designed for strong real-world document understanding,
long video comprehension, and reasoning tasks. Nemotron Nano V2 VL delivers
significant improvements over our previous model,
Llama-3.1-Nemotron-Nano-VL-8B, across all vision and text domains through major
enhancements in model architecture, datasets, and training recipes. Nemotron
Nano V2 VL builds on Nemotron Nano V2, a hybrid Mamba-Transformer LLM, and
innovative token reduction techniques to achieve higher inference throughput in
long document and video scenarios. We are releasing model checkpoints in BF16,
FP8, and FP4 formats and sharing large parts of our datasets, recipes and
training code.

</details>


### [252] [LogHD: Robust Compression of Hyperdimensional Classifiers via Logarithmic Class-Axis Reduction](https://arxiv.org/abs/2511.03938)
*Sanggeon Yun,Hyunwoo Oh,Ryozo Masukawa,Pietro Mercati,Nathaniel D. Bastian,Mohsen Imani*

Main category: cs.LG

TL;DR: LogHD通过使用对数类轴约简来减少内存占用，并提高对比特翻转的鲁棒性，同时保持计算效率。


<details>
  <summary>Details</summary>
Motivation: 标准的“每个类一个原型”的超高维计算（HDC）设计需要大量的内存（O(CD)），这对于内存、能源和可靠性受限的系统来说是一个挑战。现有的压缩方法通过降低维度（特征轴）来减少存储和计算，但会削弱鲁棒性。

Method: LogHD提出了一种对数类轴约简方法，用n≈⌈logkC⌉个束超向量（字母大小为k）替代每个类的C个原型，并在n维激活空间中进行解码。该方法还采用了容量感知码本和基于配置文件的解码，并且可以与特征轴稀疏化结合使用。

Result: LogHD在保持D维的同时，将内存占用降低到O(DlogkC)。在不同数据集和注入的比特翻转下，LogHD在模型更小的情况下实现了具有竞争力的准确性，并且在匹配内存的情况下具有更高的鲁棒性。在同等内存下，LogHD在比特翻转率约为3.0倍的情况下仍能保持目标准确性。ASIC实现比CPU和GPU具有更高的能效和速度优势，并且比特征轴HDC ASIC基线更优。

Conclusion: LogHD通过对数类轴约简，在显著降低内存占用的同时，提高了超高维计算的鲁棒性，并在能效和速度方面展现出优越的性能，是内存、能源和可靠性受限系统的有效解决方案。

Abstract: Hyperdimensional computing (HDC) suits memory, energy, and
reliability-constrained systems, yet the standard "one prototype per class"
design requires $O(CD)$ memory (with $C$ classes and dimensionality $D$). Prior
compaction reduces $D$ (feature axis), improving storage/compute but weakening
robustness. We introduce LogHD, a logarithmic class-axis reduction that
replaces the $C$ per-class prototypes with $n\!\approx\!\lceil\log_k C\rceil$
bundle hypervectors (alphabet size $k$) and decodes in an $n$-dimensional
activation space, cutting memory to $O(D\log_k C)$ while preserving $D$. LogHD
uses a capacity-aware codebook and profile-based decoding, and composes with
feature-axis sparsification. Across datasets and injected bit flips, LogHD
attains competitive accuracy with smaller models and higher resilience at
matched memory. Under equal memory, it sustains target accuracy at roughly
$2.5$-$3.0\times$ higher bit-flip rates than feature-axis compression; an ASIC
instantiation delivers $498\times$ energy efficiency and $62.6\times$ speedup
over an AMD Ryzen 9 9950X and $24.3\times$/$6.58\times$ over an NVIDIA RTX
4090, and is $4.06\times$ more energy-efficient and $2.19\times$ faster than a
feature-axis HDC ASIC baseline.

</details>


### [253] [RLHF: A comprehensive Survey for Cultural, Multimodal and Low Latency Alignment Methods](https://arxiv.org/abs/2511.03939)
*Raghav Sharma,Manan Mehta,Sai Tiger Raina*

Main category: cs.LG

TL;DR: RLHF是训练大语言模型的标准方法，但新研究正超越文本限制，探索多模态、文化公平性和低延迟优化。


<details>
  <summary>Details</summary>
Motivation: 填补多模态对齐、文化公平性和低延迟优化方面的研究空白。

Method: 综述了PPO、DPO和GRPO等基础算法，并分析了最新的创新技术。

Result: 对现有技术进行了比较性总结，并指出了开放性挑战。

Conclusion: 为研究人员构建更强大、更高效、更公平的AI系统提供了路线图。

Abstract: Reinforcement Learning from Human Feedback (RLHF) is the standard for
aligning Large Language Models (LLMs), yet recent progress has moved beyond
canonical text-based methods. This survey synthesizes the new frontier of
alignment research by addressing critical gaps in multi-modal alignment,
cultural fairness, and low-latency optimization. To systematically explore
these domains, we first review foundational algo- rithms, including PPO, DPO,
and GRPO, before presenting a detailed analysis of the latest innovations. By
providing a comparative synthesis of these techniques and outlining open
challenges, this work serves as an essential roadmap for researchers building
more robust, efficient, and equitable AI systems.

</details>


### [254] [PrivacyCD: Hierarchical Unlearning for Protecting Student Privacy in Cognitive Diagnosis](https://arxiv.org/abs/2511.03966)
*Mingliang Hou,Yinuo Wang,Teng Guo,Zitao Liu,Wenzhou Dou,Jiaqi Zheng,Renqiang Luo,Mi Tian,Weiqi Luo*

Main category: cs.LG

TL;DR: 现有认知诊断(CD)模型缺乏有效的数据遗忘机制来应对学生数据删除请求。本文提出了层级重要性引导遗忘(HIF)算法，该算法利用CD模型中参数按层级的重要性差异，通过平滑机制精确区分与待遗忘数据相关的参数，显著优于基线方法，为CD模型提供了首个有效的数据删除解决方案。


<details>
  <summary>Details</summary>
Motivation: 用户“被遗忘权”的兴起，要求从认知诊断(CD)模型中删除特定学生数据，而现有CD模型缺乏隐私考量和有效的数据遗忘机制。

Method: 提出了一种新颖且高效的层级重要性引导遗忘(HIF)算法。该算法利用CD模型中参数按层级的重要性差异，通过一种创新的平滑机制结合个体和层级的重要性，更精确地区分与待遗忘数据相关的参数。

Result: HIF算法在三个真实世界数据集上的实验结果显著优于基线方法，在关键指标上表现更佳。

Conclusion: HIF算法是首个有效解决CD模型响应用户数据删除请求问题的算法，为部署高性能、隐私保护的AI系统提供了解决方案。

Abstract: The need to remove specific student data from cognitive diagnosis (CD) models
has become a pressing requirement, driven by users' growing assertion of their
"right to be forgotten". However, existing CD models are largely designed
without privacy considerations and lack effective data unlearning mechanisms.
Directly applying general purpose unlearning algorithms is suboptimal, as they
struggle to balance unlearning completeness, model utility, and efficiency when
confronted with the unique heterogeneous structure of CD models. To address
this, our paper presents the first systematic study of the data unlearning
problem for CD models, proposing a novel and efficient algorithm: hierarchical
importanceguided forgetting (HIF). Our key insight is that parameter importance
in CD models exhibits distinct layer wise characteristics. HIF leverages this
via an innovative smoothing mechanism that combines individual and layer, level
importance, enabling a more precise distinction of parameters associated with
the data to be unlearned. Experiments on three real world datasets show that
HIF significantly outperforms baselines on key metrics, offering the first
effective solution for CD models to respond to user data removal requests and
for deploying high-performance, privacy preserving AI systems

</details>


### [255] [Non-Asymptotic Optimization and Generalization Bounds for Stochastic Gauss-Newton in Overparameterized Models](https://arxiv.org/abs/2511.03972)
*Semih Cayci*

Main category: cs.LG

TL;DR: 本文分析了带Levenberg-Marquardt阻尼和mini-batch采样的随机Gauss-Newton (SGN) 方法在深度学习中的泛化能力，并得出了相应的理论界限。


<details>
  <summary>Details</summary>
Motivation: 探讨高阶优化方法对深度学习泛化能力的影响。

Method: 通过变量度量分析和均匀稳定性分析，推导出SGN方法的有限时间收敛界限和非渐近泛化界限，并分析了批大小、网络宽度、深度、曲率和过参数化等因素的影响。

Result: 在过参数化深度神经网络的回归问题上，得出了SGN方法的收敛界限和泛化界限。发现在优化路径上更大的Gauss-Newton矩阵最小特征值有利于更紧密的稳定性界限。

Conclusion: SGN方法在某些条件下具有良好的泛化能力，并且其泛化性能受到曲率、批大小和过参数化等因素的影响。

Abstract: An important question in deep learning is how higher-order optimization
methods affect generalization. In this work, we analyze a stochastic
Gauss-Newton (SGN) method with Levenberg-Marquardt damping and mini-batch
sampling for training overparameterized deep neural networks with smooth
activations in a regression setting. Our theoretical contributions are twofold.
First, we establish finite-time convergence bounds via a variable-metric
analysis in parameter space, with explicit dependencies on the batch size,
network width and depth. Second, we derive non-asymptotic generalization bounds
for SGN using uniform stability in the overparameterized regime, characterizing
the impact of curvature, batch size, and overparameterization on generalization
performance. Our theoretical results identify a favorable generalization regime
for SGN in which a larger minimum eigenvalue of the Gauss-Newton matrix along
the optimization path yields tighter stability bounds.

</details>


### [256] [PETRA: Pretrained Evolutionary Transformer for SARS-CoV-2 Mutation Prediction](https://arxiv.org/abs/2511.03976)
*Xu Zou*

Main category: cs.LG

TL;DR: PETRA是一个基于进化轨迹的Transformer模型，用于预测新冠病毒变异，优于现有基线模型。


<details>
  <summary>Details</summary>
Motivation: 新冠病毒的快速变异给公共卫生和疫苗开发带来挑战，现有基于GPT的模型在处理病毒基因组序列时存在局限性。

Method: 提出了一种名为PETRA（Pretrained Evolutionary TRAnsformer）的新型Transformer方法，该方法基于系统发育树推导出的进化轨迹，而非原始RNA序列，并采用加权训练框架处理数据不平衡问题。

Result: PETRA在预测未来新冠病毒变异方面表现出色，在核苷酸变异和刺突蛋白氨基酸变异方面的加权召回率（recall@1）分别为9.45%和17.10%，显著优于基线模型（分别为0.49%和6.64%）。

Conclusion: PETRA能够有效预测新冠病毒的变异，并有助于对主要进化分支（如24F(XEC)和25A(LP.8.1)）进行实时变异预测。

Abstract: Since its emergence, SARS-CoV-2 has demonstrated a rapid and unpredictable
evolutionary trajectory, characterized by the continual emergence of
immune-evasive variants. This poses persistent challenges to public health and
vaccine development.
  While large-scale generative pre-trained transformers (GPTs) have
revolutionized the modeling of sequential data, their direct applications to
noisy viral genomic sequences are limited. In this paper, we introduce
PETRA(Pretrained Evolutionary TRAnsformer), a novel transformer approach based
on evolutionary trajectories derived from phylogenetic trees rather than raw
RNA sequences. This method effectively mitigates sequencing noise and captures
the hierarchical structure of viral evolution.
  With a weighted training framework to address substantial geographical and
temporal imbalances in global sequence data, PETRA excels in predicting future
SARS-CoV-2 mutations, achieving a weighted recall@1 of 9.45% for nucleotide
mutations and 17.10\% for spike amino-acid mutations, compared to 0.49% and
6.64% respectively for the best baseline. PETRA also demonstrates its ability
to aid in the real-time mutation prediction of major clades like 24F(XEC) and
25A(LP.8.1). The code is open sourced on https://github.com/xz-keg/PETra

</details>


### [257] [Structural Priors and Modular Adapters in the Composable Fine-Tuning Algorithm of Large-Scale Models](https://arxiv.org/abs/2511.03981)
*Yuxiao Wang,Di Wu,Feng Liu,Zhimin Qiu,Chenrui Hu*

Main category: cs.LG

TL;DR: 提出了一种可组合的微调方法，通过结合图结构先验和模块化适配器来解决大规模预训练模型在多任务适应中面临的高计算成本和结构不稳定性问题。


<details>
  <summary>Details</summary>
Motivation: 大型预训练模型在多任务适应中存在高计算成本和结构不稳定性问题。

Method: 引入关系矩阵建模任务间的依赖，将节点和路径的相关性显式编码为图结构先验，为适配器权重分配和路径选择提供统一的结构约束。通过低秩映射和可插入机制将模块化适配器嵌入不同层，在先验指导下实现高效的跨任务组合和复用。

Result: 实验表明，该框架显著提高了任务预测准确性、适配器权重分配精度和整体计算效率，同时保持了模型的轻量化设计。

Conclusion: 所提出的图先验和模块化机制的协同优势在可组合微调中得到了体现。

Abstract: This paper proposes a composable fine-tuning method that integrates graph
structural priors with modular adapters to address the high computational cost
and structural instability faced by large-scale pre-trained models in
multi-task adaptation. The method introduces a relation matrix to model
dependencies among tasks, explicitly encoding correlations between nodes and
paths into graph structural priors, which provide unified structural
constraints for adapter weight allocation and path selection. Modular adapters
are embedded into different layers through low-rank mapping and a pluggable
mechanism, enabling efficient cross-task composition and reuse under prior
guidance. This mechanism not only improves parameter efficiency and training
stability but also alleviates path conflicts and redundant computation in
multi-task scenarios. Furthermore, experiments on hyperparameter sensitivity,
environmental sensitivity, and data sensitivity are conducted to systematically
analyze key factors such as routing temperature, gating thresholds, and
relation matrix regularization strength, verifying the consistency and superior
performance of the method under structural constraints. The results demonstrate
that the proposed framework significantly enhances task prediction accuracy,
adapter weight allocation precision, and overall computational efficiency while
maintaining model lightweight design, highlighting the synergistic advantages
of graph priors and modular mechanisms in composable fine-tuning.

</details>


### [258] [TwIST: Rigging the Lottery in Transformers with Independent Subnetwork Training](https://arxiv.org/abs/2511.03983)
*Michael Menezes,Barbara Su,Xinze Feng,Yehya Farhat,Hamza Shili,Anastasios Kyrillidis*

Main category: cs.LG

TL;DR: TwIST是一个分布式训练框架，用于高效的大型语言模型（LLM）稀疏化。它通过并行训练多个子网络、定期聚合参数和重新采样子网络来识别高质量子网络，无需训练后校准。TwIST在部署时实现零成本剪枝，并且在50%以上的稀疏度下性能优于现有方法，同时生成便于在普通硬件上部署的结构化稀疏模型。


<details>
  <summary>Details</summary>
Motivation: 现有的大型语言模型（LLM）稀疏化方法通常需要在训练后进行额外的校准或恢复步骤，这增加了部署的复杂性和成本。此外，非结构化稀疏化难以在不支持稀疏计算的普通硬件上实现实际的推理加速。

Method: TwIST通过并行训练多个子网络，定期聚合它们的参数，并在此过程中重新采样新的子网络。这种方法能够在训练期间就识别出高质量的稀疏子网络（“golden tickets”），无需额外的训练后处理。

Result: TwIST在部署时实现了零成本剪枝，其稀疏化LLM的困惑度（PPL）与最先进的训练后稀疏化方法相当。特别是在50%以上的较高稀疏度下，TwIST的性能显著优于基线方法，例如困惑度达到23.14，而先前最接近的方法为31.64。TwIST生成的是结构化的、稠密的矩阵，可以在不支持稀疏计算的普通硬件（如CPU）上实现实际的推理加速和内存减少。

Conclusion: TwIST提供了一种在训练时即可实现可部署的稀疏LLM的有效途径，无需额外的微调或恢复开销，特别是在需要高稀疏度的情况下，能够显著降低部署成本并提高硬件兼容性。

Abstract: We introduce TwIST, a distributed training framework for efficient large
language model (LLM) sparsification. TwIST trains multiple subnetworks in
parallel, periodically aggregates their parameters, and resamples new
subnetworks during training. This process identifies high-quality subnetworks
("golden tickets") without requiring post-training procedures such as
calibration or Hessian-based recovery. As a result, TwIST enables zero-cost
pruning at deployment time while achieving perplexity competitive with
state-of-the-art post-training sparsification methods. The benefits are most
pronounced under aggressive sparsity (e.g., 50%+), where TwIST significantly
outperforms baseline methods; for example, reaching 23.14 PPL compared to 31.64
for the closest prior approach. Unlike unstructured pruning, TwIST produces
structured, dense matrices that offer practical inference speedups and memory
reductions on commodity hardware (e.g., CPUs) that do not support efficient
sparse computation. TwIST provides an efficient training-time path to
deployable sparse LLMs without additional fine-tuning or recovery overhead.

</details>


### [259] [Use of Continuous Glucose Monitoring with Machine Learning to Identify Metabolic Subphenotypes and Inform Precision Lifestyle Changes](https://arxiv.org/abs/2511.03986)
*Ahmed A. Metwally,Heyjun Park,Yue Wu,Tracey McLaughlin,Michael P. Snyder*

Main category: cs.LG

TL;DR: 文章提出使用连续葡萄糖监测(CGM)和机器学习来识别糖尿病和前驱糖尿病的亚型，实现精准的个体化治疗。


<details>
  <summary>Details</summary>
Motivation: 现有的基于静态葡萄糖阈值的糖尿病分类方法忽略了异质性病理生理学，而连续葡萄糖监测和可穿戴技术可以实现动态代谢分型。

Method: 利用机器学习模型分析连续葡萄糖监测数据，以预测肌肉胰岛素抵抗和β细胞功能等金标准指标。分析个体对标准化餐食的餐后血糖反应（PPGR）以及结合可穿戴设备数据，了解饮食、睡眠和体育活动模式与特定代谢功能障碍的关系。

Result: 机器学习模型能够准确预测肌肉胰岛素抵抗和β细胞功能；个体对食物的餐后血糖反应（PPGR）可作为代谢亚型的生物标志物；饮食、睡眠和体育活动模式与特定代谢功能障碍相关；饮食干预对PPGR的减弱效果取决于个体代谢表型。

Conclusion: 连续葡萄糖监测(CGM)能够将早期血糖异常分解为可操作的亚型，为精准的营养、行为和药物干预提供基础，开启糖尿病精准预防的新时代。

Abstract: The classification of diabetes and prediabetes by static glucose thresholds
obscures the pathophysiological dysglycemia heterogeneity, primarily driven by
insulin resistance (IR), beta-cell dysfunction, and incretin deficiency. This
review demonstrates that continuous glucose monitoring and wearable
technologies enable a paradigm shift towards non-invasive, dynamic metabolic
phenotyping. We show evidence that machine learning models can leverage
high-resolution glucose data from at-home, CGM-enabled oral glucose tolerance
tests to accurately predict gold-standard measures of muscle IR and beta-cell
function. This personalized characterization extends to real-world nutrition,
where an individual's unique postprandial glycemic response (PPGR) to
standardized meals, such as the relative glucose spike to potatoes versus
grapes, could serve as a biomarker for their metabolic subtype. Moreover,
integrating wearable data reveals that habitual diet, sleep, and physical
activity patterns, particularly their timing, are uniquely associated with
specific metabolic dysfunctions, informing precision lifestyle interventions.
The efficacy of dietary mitigators in attenuating PPGR is also shown to be
phenotype-dependent. Collectively, this evidence demonstrates that CGM can
deconstruct the complexity of early dysglycemia into distinct, actionable
subphenotypes. This approach moves beyond simple glycemic control, paving the
way for targeted nutritional, behavioral, and pharmacological strategies
tailored to an individual's core metabolic defects, thereby paving the way for
a new era of precision diabetes prevention.

</details>


### [260] [Towards Scalable Meta-Learning of near-optimal Interpretable Models via Synthetic Model Generations](https://arxiv.org/abs/2511.04000)
*Kyaw Hpone Myint,Zhe Wu,Alexandre G. R. Day,Giri Iyengar*

Main category: cs.LG

TL;DR: 本文提出了一种生成合成决策树数据集的方法，用于元学习，提高了效率和可扩展性，性能可与真实数据或最优决策树相媲美。


<details>
  <summary>Details</summary>
Motivation: 决策树在金融和医疗保健等高风险领域因其可解释性而被广泛使用，但需要高效的数据集来支持其元学习。

Method: 通过对近乎最优的决策树进行采样来生成大规模、真实的合成数据集，并使用MetaTree transformer架构。

Result: 使用合成数据进行预训练的决策树，其性能与使用真实世界数据或计算成本高昂的最优决策树进行预训练的性能相当。

Conclusion: 该方法显著降低了计算成本，提高了数据生成的灵活性，并为可扩展、高效的可解释决策树模型的元学习铺平了道路。

Abstract: Decision trees are widely used in high-stakes fields like finance and
healthcare due to their interpretability. This work introduces an efficient,
scalable method for generating synthetic pre-training data to enable
meta-learning of decision trees. Our approach samples near-optimal decision
trees synthetically, creating large-scale, realistic datasets. Using the
MetaTree transformer architecture, we demonstrate that this method achieves
performance comparable to pre-training on real-world data or with
computationally expensive optimal decision trees. This strategy significantly
reduces computational costs, enhances data generation flexibility, and paves
the way for scalable and efficient meta-learning of interpretable decision tree
models.

</details>


### [261] [Accelerating scientific discovery with the common task framework](https://arxiv.org/abs/2511.04001)
*J. Nathan Kutz,Peter Battaglia,Michael Brenner,Kevin Carlberg,Aric Hagberg,Shirley Ho,Stephan Hoyer,Henning Lange,Hod Lipson,Michael W. Mahoney,Frank Noe,Max Welling,Laure Zanna,Francis Zhu,Steven L. Brunton*

Main category: cs.LG

TL;DR: 机器学习和人工智能正在改变动态系统的表征和控制，但缺乏统一的评估标准。本文提出了一个科学和工程领域的通用任务框架（CTF），包含数据集和评估指标，以促进不同算法的比较和发展。


<details>
  <summary>Details</summary>
Motivation: 机器学习和人工智能算法在科学和工程领域发展迅速，但缺乏统一的评估标准来比较不同算法在预测、状态重构、泛化和控制等方面的性能，尤其是在数据有限和测量噪声大的情况下。

Method: 提出一个包含数据集和通用评估指标的通用任务框架（CTF），用于比较和评估科学与工程领域中的机器学习和人工智能算法。

Result: CTF提供了一个标准化的平台，有助于促进机器学习和人工智能算法在科学和工程领域的快速发展和应用。

Conclusion: 迫切需要像CTF这样的通用任务框架和客观评估指标，来比较和推动当前在科学和工程领域快速发展的各种机器学习和人工智能算法。

Abstract: Machine learning (ML) and artificial intelligence (AI) algorithms are
transforming and empowering the characterization and control of dynamic systems
in the engineering, physical, and biological sciences. These emerging modeling
paradigms require comparative metrics to evaluate a diverse set of scientific
objectives, including forecasting, state reconstruction, generalization, and
control, while also considering limited data scenarios and noisy measurements.
We introduce a common task framework (CTF) for science and engineering, which
features a growing collection of challenge data sets with a diverse set of
practical and common objectives. The CTF is a critically enabling technology
that has contributed to the rapid advance of ML/AI algorithms in traditional
applications such as speech recognition, language processing, and computer
vision. There is a critical need for the objective metrics of a CTF to compare
the diverse algorithms being rapidly developed and deployed in practice today
across science and engineering.

</details>


### [262] [Memory- and Latency-Constrained Inference of Large Language Models via Adaptive Split Computing](https://arxiv.org/abs/2511.04002)
*Mingyu Sung,Vikas Palakonda,Suhwan Im,Sunghwan Moon,Il-Min Kim,Sangseok Yun,Jae-Mo Kang*

Main category: cs.LG

TL;DR: 该研究提出了首个针对物联网设备部署大型语言模型（LLM）的自回归感知式拆分计算框架，通过一种名为OPSC的混合精度量化方案和两阶段中间压缩管道（TS和TAB-Q），有效解决了LLM在资源受限设备上部署的内存和通信瓶颈问题，并在多种LLM和硬件平台上实现了显著的速度提升和通信开销减少，同时保持了模型精度。


<details>
  <summary>Details</summary>
Motivation: 现有的大型语言模型（LLM）虽然在推理任务上表现优异，但由于参数量大和内存需求高，难以在资源受限的物联网（IoT）设备上部署。拆分计算是一种有前景的解决方案，但未能有效解决自回归推理的挑战，特别是迭代生成过程和不断增长的键值（KV）缓存需求。

Method: 提出了一种名为OPSC（one-point split compression）的混合精度量化方案，将模型划分为不同精度的前端和后端；引入了一个两阶段的中间压缩管道，结合阈值拆分（TS）和令牌自适应比特量化（TAB-Q）来减少通信开销；构建了一个统一的优化框架，用于联合选择拆分点、量化设置和序列长度，以满足内存和延迟限制。

Result: 与现有的量化方法（如SmoothQuant、OmniQuant和Atom）相比，该框架在多种LLM和硬件平台上表现出更优越的性能，实现了1.49倍的推理速度提升，并显著降低了通信开销，同时保持或提高了模型精度。

Conclusion: 所提出的自回归感知式拆分计算框架是首个专门为在边缘设备上部署LLM而设计的解决方案，它通过创新的量化和压缩技术，有效解决了LLM在资源受限环境下的部署难题，并在性能和效率上取得了显著突破。

Abstract: Large language models (LLMs) have achieved near-human performance across
diverse reasoning tasks, yet their deployment on resource-constrained
Internet-of-Things (IoT) devices remains impractical due to massive parameter
footprints and memory-intensive autoregressive decoding. While split computing
offers a promising solution by partitioning model execution between edge
devices and cloud servers, existing approaches fail to address the unique
challenges of autoregressive inference, particularly the iterative token
generation process and expanding key-value (KV) cache requirements. This work
introduces the first autoregressive-aware split computing framework designed
explicitly for LLM deployment on edge devices. Our approach makes three key
contributions. First, we develop one-point split compression (OPSC), a
mixed-precision quantization scheme that prevents out-of-memory failures by
strategically partitioning models into front-end and back-end segments with
different precision levels. Second, we propose a two-stage intermediate
compression pipeline that combines threshold splitting (TS) and token-wise
adaptive bit quantization (TAB-Q) to preserve accuracy-critical activations
while dramatically reducing communication overhead. Third, we formulate a
unified optimization framework that jointly selects optimal split points,
quantization settings, and sequence lengths to satisfy strict memory and
latency constraints. Extensive evaluations across diverse LLMs and hardware
platforms demonstrate superior performance compared to state-of-the-art
quantization methods, including SmoothQuant, OmniQuant, and Atom. The framework
achieves a 1.49 inference speedup and significant communication overhead
reduction while maintaining or improving model accuracy.

</details>


### [263] [DartQuant: Efficient Rotational Distribution Calibration for LLM Quantization](https://arxiv.org/abs/2511.04063)
*Yuantian Shao,Yuanteng Chen,Peisong Wang,Jianlin Yu,Jing Lin,Yiwu Yao,Zhihui Wei,Jian Cheng*

Main category: cs.LG

TL;DR: DartQuant是一种高效的、感知分布的旋转校准方法，通过约束旋转后激活值的分布来降低计算复杂性，并引入QR-Orth优化方案以提高效率，实现了对70B模型的高效量化，单卡即可完成，使资源受限环境下的量化成为可能。


<details>
  <summary>Details</summary>
Motivation: 为了解决现有旋转优化算法计算成本高、易过拟合的问题，提高大模型推理的量化效率。

Method: 提出了一种名为DartQuant的感知分布的旋转校准方法，通过约束旋转后激活值的分布来降低旋转优化的复杂性，并引入QR-Orth优化方案替代计算成本高昂的交替优化。

Result: DartQuant在多种模型量化实验中表现出卓越的性能，与现有方法相比，在70B模型上实现了47倍的加速和10倍的内存节省，并且首次在单张3090 GPU上成功完成了70B模型的旋转校准。

Conclusion: DartQuant有效降低了旋转优化的计算成本和过拟合风险，使得在大语言模型量化中实现高效的旋转校准成为可能，尤其是在资源受限的环境下。

Abstract: Quantization plays a crucial role in accelerating the inference of
large-scale models, and rotational matrices have been shown to effectively
improve quantization performance by smoothing outliers. However, end-to-end
fine-tuning of rotational optimization algorithms incurs high computational
costs and is prone to overfitting. To address this challenge, we propose an
efficient distribution-aware rotational calibration method, DartQuant, which
reduces the complexity of rotational optimization by constraining the
distribution of the activations after rotation. This approach also effectively
reduces reliance on task-specific losses, thereby mitigating the risk of
overfitting. Additionally, we introduce the QR-Orth optimization scheme, which
replaces expensive alternating optimization with a more efficient solution. In
a variety of model quantization experiments, DartQuant demonstrates superior
performance. Compared to existing methods, it achieves 47$\times$ acceleration
and 10$\times$ memory savings for rotational optimization on a 70B model.
Furthermore, it is the first to successfully complete rotational calibration
for a 70B model on a single 3090 GPU, making quantization of large language
models feasible in resource-constrained environments. Code is available at
https://github.com/CAS-CLab/DartQuant.git.

</details>


### [264] [Pediatric Appendicitis Detection from Ultrasound Images](https://arxiv.org/abs/2511.04069)
*Fatemeh Hosseinabadi,Seyedhassan Sharifi*

Main category: cs.LG

TL;DR: 本研究提出并评估了一种基于ResNet的深度学习模型，用于自动检测儿童超声图像中的阑尾炎。


<details>
  <summary>Details</summary>
Motivation: 儿科阑尾炎的诊断因症状重叠和成像质量差异而持续挑战临床医生，本研究旨在开发一种自动诊断模型。

Method: 研究使用Regensburg儿科阑尾炎数据集，对预训练的ResNet模型进行微调，以区分阑尾炎和非阑尾炎病例。对图像进行标准化、调整大小和增强处理。

Result: 所提出的ResNet模型在准确率（93.44%）、精确率（91.53%）和召回率（89.8%）方面表现出色，能够有效识别儿童超声图像中的阑尾炎。

Conclusion: 该深度学习模型能够有效学习鉴别性空间特征，克服儿科成像中的低对比度、斑点噪声和解剖变异性等挑战，在检测阑尾炎方面表现出强大的能力。

Abstract: Pediatric appendicitis remains one of the most common causes of acute
abdominal pain in children, and its diagnosis continues to challenge clinicians
due to overlapping symptoms and variable imaging quality. This study aims to
develop and evaluate a deep learning model based on a pretrained ResNet
architecture for automated detection of appendicitis from ultrasound images. We
used the Regensburg Pediatric Appendicitis Dataset, which includes ultrasound
scans, laboratory data, and clinical scores from pediatric patients admitted
with abdominal pain to Children Hospital. Hedwig in Regensburg, Germany. Each
subject had 1 to 15 ultrasound views covering the right lower quadrant,
appendix, lymph nodes, and related structures. For the image based
classification task, ResNet was fine tuned to distinguish appendicitis from
non-appendicitis cases. Images were preprocessed by normalization, resizing,
and augmentation to enhance generalization. The proposed ResNet model achieved
an overall accuracy of 93.44, precision of 91.53, and recall of 89.8,
demonstrating strong performance in identifying appendicitis across
heterogeneous ultrasound views. The model effectively learned discriminative
spatial features, overcoming challenges posed by low contrast, speckle noise,
and anatomical variability in pediatric imaging.

</details>


### [265] [Left Atrial Segmentation with nnU-Net Using MRI](https://arxiv.org/abs/2511.04071)
*Fatemeh Hosseinabadi,Seyedhassan Sharifi*

Main category: cs.LG

TL;DR: nnU-Net框架在心脏MRI左房分割任务中表现出色，平均Dice系数达到93.5，优于传统方法，并能鲁棒地处理各种解剖变异和图像质量。


<details>
  <summary>Details</summary>
Motivation: 手动分割心脏MRI左房耗时且依赖观察者，不适用于大规模或时间敏感的临床工作流程，因此需要更自动化的方法。

Method: 应用nnU-Net框架（一种自动配置的深度学习分割架构）对左房分割挑战赛2013数据集（包含30个MRI扫描及其专家标注）进行分割。

Result: nnU-Net模型自动适应了MRI数据的预处理、网络配置和训练流程，取得了93.5的平均Dice相似系数，与专家分割高度重叠，并且在左房形状、对比度和图像质量的变化下表现出鲁棒的泛化能力。

Conclusion: nnU-Net框架能够准确分割心脏MRI中的左房及其近端肺静脉，其性能优于传统方法，为临床应用提供了有前景的解决方案。

Abstract: Accurate segmentation of the left atrium (LA) from cardiac MRI is critical
for guiding atrial fibrillation (AF) ablation and constructing biophysical
cardiac models. Manual delineation is time-consuming, observer-dependent, and
impractical for large-scale or time-sensitive clinical workflows. Deep learning
methods, particularly convolutional architectures, have recently demonstrated
superior performance in medical image segmentation tasks. In this study, we
applied the nnU-Net framework, an automated, self-configuring deep learning
segmentation architecture, to the Left Atrial Segmentation Challenge 2013
dataset. The dataset consists of thirty MRI scans with corresponding
expert-annotated masks. The nnU-Net model automatically adapted its
preprocessing, network configuration, and training pipeline to the
characteristics of the MRI data. Model performance was quantitatively evaluated
using the Dice similarity coefficient (DSC), and qualitative results were
compared against expert segmentations. The proposed nnUNet model achieved a
mean Dice score of 93.5, demonstrating high overlap with expert annotations and
outperforming several traditional segmentation approaches reported in previous
studies. The network exhibited robust generalization across variations in left
atrial shape, contrast, and image quality, accurately delineating both the
atrial body and proximal pulmonary veins.

</details>


### [266] [Learning Filter-Aware Distance Metrics for Nearest Neighbor Search with Multiple Filters](https://arxiv.org/abs/2511.04073)
*Ananya Sutradhar,Suryansh Gupta,Ravishankar Krishnaswamy,Haiyang Xu,Aseem Rastogi,Gopal Srinivasa*

Main category: cs.LG

TL;DR: 现有基于图的过滤式近似最近邻搜索方法在处理不同数据集时泛化能力不足，本文提出一种新方法，通过学习最优权重来平衡向量距离和标签匹配，显著提高了搜索准确率。


<details>
  <summary>Details</summary>
Motivation: 现有基于图的过滤式近似最近邻搜索方法通常依赖固定的、与数据无关的惩罚机制，这导致它们在处理具有不同标签和向量分布的数据集时泛化能力不足。

Method: 本文将过滤式近似最近邻搜索问题构建为一个约束线性优化问题，直接从数据中学习向量距离和标签匹配之间的最优权衡，并推导出能更好反映底层标签分布的权重。这些权重用于指导搜索过程和索引构建，从而得到能更有效地捕捉底层标签分布和标签语义的图结构。

Result: 实验结果表明，通过自适应距离函数，在过滤式近似最近邻搜索任务上，准确率相比固定惩罚方法提高了 5-10%。

Conclusion: 本文提出了一种基于学习最优权重的过滤式近似最近邻搜索方法，该方法比现有固定惩罚方法更具灵活性和泛化能力，能够显著提高搜索准确率。

Abstract: Filtered Approximate Nearest Neighbor (ANN) search retrieves the closest
vectors for a query vector from a dataset. It enforces that a specified set of
discrete labels $S$ for the query must be included in the labels of each
retrieved vector. Existing graph-based methods typically incorporate filter
awareness by assigning fixed penalties or prioritizing nodes based on filter
satisfaction. However, since these methods use fixed, data in- dependent
penalties, they often fail to generalize across datasets with diverse label and
vector distributions. In this work, we propose a principled alternative that
learns the optimal trade-off between vector distance and filter match directly
from the data, rather than relying on fixed penalties. We formulate this as a
constrained linear optimization problem, deriving weights that better reflect
the underlying filter distribution and more effectively address the filtered
ANN search problem. These learned weights guide both the search process and
index construction, leading to graph structures that more effectively capture
the underlying filter distribution and filter semantics. Our experiments
demonstrate that adapting the distance function to the data significantly im-
proves accuracy by 5-10% over fixed-penalty methods, providing a more flexible
and generalizable framework for the filtered ANN search problem.

</details>


### [267] [DeNoise: Learning Robust Graph Representations for Unsupervised Graph-Level Anomaly Detection](https://arxiv.org/abs/2511.04086)
*Qingfeng Chen,Haojin Zeng,Jingyi Jie,Shichao Zhang,Debo Cheng*

Main category: cs.LG

TL;DR: DeNoise是一个用于处理带噪声训练数据的无监督图级别异常检测（UGAD）框架，它通过联合优化编码器、属性解码器和结构解码器，并引入了编码器锚点对齐去噪机制和对比学习组件，在各种噪声强度下都能学习到可靠的图级别表示，并在真实世界数据集上显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有的无监督图级别异常检测（UGAD）方法通常假设训练数据是干净的，但实际情况中往往存在异常图的污染，这会严重影响模型的性能。

Method: DeNoise框架通过联合优化图级别编码器、属性解码器和结构解码器，并利用对抗性目标来学习对噪声具有鲁棒性的嵌入。它还引入了一个编码器锚点对齐去噪机制，将来自正常图的高信息节点嵌入融合到所有图嵌入中，以提高表示质量并抑制异常干扰。此外，还包含一个对比学习组件，用于在潜在空间中压缩正常图嵌入并排斥异常图嵌入。

Result: 在八个真实世界数据集上的大量实验表明，DeNoise在不同噪声强度下始终能学习到可靠的图级别表示，并且显著优于最先进的UGAD基线方法。

Conclusion: DeNoise框架能够有效地处理被污染的训练数据，为UGAD任务提供了一种鲁棒且高性能的解决方案。

Abstract: With the rapid growth of graph-structured data in critical domains,
unsupervised graph-level anomaly detection (UGAD) has become a pivotal task.
UGAD seeks to identify entire graphs that deviate from normal behavioral
patterns. However, most Graph Neural Network (GNN) approaches implicitly assume
that the training set is clean, containing only normal graphs, which is rarely
true in practice. Even modest contamination by anomalous graphs can distort
learned representations and sharply degrade performance. To address this
challenge, we propose DeNoise, a robust UGAD framework explicitly designed for
contaminated training data. It jointly optimizes a graph-level encoder, an
attribute decoder, and a structure decoder via an adversarial objective to
learn noise-resistant embeddings. Further, DeNoise introduces an encoder
anchor-alignment denoising mechanism that fuses high-information node
embeddings from normal graphs into all graph embeddings, improving
representation quality while suppressing anomaly interference. A contrastive
learning component then compacts normal graph embeddings and repels anomalous
ones in the latent space. Extensive experiments on eight real-world datasets
demonstrate that DeNoise consistently learns reliable graph-level
representations under varying noise intensities and significantly outperforms
state-of-the-art UGAD baselines.

</details>


### [268] [KoTaP: A Panel Dataset for Corporate Tax Avoidance, Performance, and Governance in Korea](https://arxiv.org/abs/2511.04094)
*Hyungjong Na,Wonho Song,Seungyong Han,Donghyeon Jo,Sejin Myung,Hyungjoon Kim*

Main category: cs.LG

TL;DR: 本文介绍了韩国税收规避面板数据集(KoTaP)，这是一个包含2011年至2024年韩国上市公司（KOSPI和KOSDAQ）非金融公司的数据集，共包含1754家公司，12653个公司年度观测值。该数据集旨在将企业税收规避作为预测变量，并将其与收益管理、盈利能力、稳定性、增长和公司治理等多个领域联系起来。税收规避本身通过现金有效税率（CETR）、GAAP有效税率（GETR）和税收账面差异（TSTA, TSDA）等指标衡量。KoTaP数据集具有平衡面板结构、标准化变量的优点，并与国际文献保持一致，同时反映了韩国公司特有的制度特征，如股权集中、外资持股比例高和流动性比率高等。该数据集可用于基准测试计量经济学和深度学习模型、外部有效性检查、可解释人工智能分析、政策评估、审计规划和投资分析。


<details>
  <summary>Details</summary>
Motivation: 本文旨在创建一个全面的韩国公司税收规避数据集（KoTaP），以促进对企业税收规避行为及其与多个经济领域之间关系的深入研究，并为相关模型的基准测试、外部有效性检查、可解释人工智能分析、政策评估、审计规划和投资分析提供一个开放的研究资源。

Method: 本研究构建了韩国税收规避面板数据集(KoTaP)，方法是收集2011年至2024年韩国KOSPI和KOSDAQ上市的非金融公司的年度数据。在排除了金融公司、非12月财年末公司、资本亏损和税前亏损的公司后，最终数据集包含了1754家公司共12653个公司年度观测值。税收规避使用现金有效税率（CETR）、GAAP有效税率（GETR）以及税收账面差异（TSTA, TSDA）等指标来衡量。

Result: KoTaP数据集包含了1754家公司共12653个公司年度观测值，其税收规避指标（CETR, GETR, TSTA, TSDA）与盈利能力、稳定性、增长和公司治理等变量相关。数据集结构平衡，变量标准化，并具有国际可比性和韩国本土独特性。

Conclusion: KoTaP数据集是一个宝贵的开放资源，为会计、金融和跨学科研究提供了基础，能够支持各种分析，包括模型基准测试、外部有效性检查、可解释人工智能分析、政策评估、审计规划和投资分析。

Abstract: This study introduces the Korean Tax Avoidance Panel (KoTaP), a long-term
panel dataset of non-financial firms listed on KOSPI and KOSDAQ between 2011
and 2024. After excluding financial firms, firms with non-December fiscal year
ends, capital impairment, and negative pre-tax income, the final dataset
consists of 12,653 firm-year observations from 1,754 firms. KoTaP is designed
to treat corporate tax avoidance as a predictor variable and link it to
multiple domains, including earnings management (accrual- and activity-based),
profitability (ROA, ROE, CFO, LOSS), stability (LEV, CUR, SIZE, PPE, AGE,
INVREC), growth (GRW, MB, TQ), and governance (BIG4, FORN, OWN). Tax avoidance
itself is measured using complementary indicators cash effective tax rate
(CETR), GAAP effective tax rate (GETR), and book-tax difference measures (TSTA,
TSDA) with adjustments to ensure interpretability. A key strength of KoTaP is
its balanced panel structure with standardized variables and its consistency
with international literature on the distribution and correlation of core
indicators. At the same time, it reflects distinctive institutional features of
Korean firms, such as concentrated ownership, high foreign shareholding, and
elevated liquidity ratios, providing both international comparability and
contextual uniqueness. KoTaP enables applications in benchmarking econometric
and deep learning models, external validity checks, and explainable AI
analyses. It further supports policy evaluation, audit planning, and investment
analysis, making it a critical open resource for accounting, finance, and
interdisciplinary research.

</details>


### [269] [Decomposable Neuro Symbolic Regression](https://arxiv.org/abs/2511.04124)
*Giorgio Morales,John W. Sheppard*

Main category: cs.LG

TL;DR: 本研究提出了一种可分解的符号回归（SR）方法，利用Transformer模型、遗传算法（GA）和遗传编程（GP）来发现可解释的多元数学表达式。


<details>
  <summary>Details</summary>
Motivation: 现有的SR方法倾向于最小化预测误差，导致生成的表达式过于复杂或不准确。本方法旨在解决这个问题，生成可解释的、准确的数学表达式。

Method: 该方法首先使用Multi-Set Transformer生成多个单变量符号骨架，然后使用GA选择候选骨架，并采用GP进行渐进式合并，最后使用GA进行系数优化。

Result: 在有噪声的数据集上，本方法在插值和外插误差方面表现优于或媲美现有的GP、神经网络SR和混合方法。最重要的是，本方法学习到的表达式结构与原始数学结构一致。

Conclusion: 本研究提出的可分解SR方法能够生成结构正确且性能良好的可解释数学表达式，解决了现有SR方法的局限性。

Abstract: Symbolic regression (SR) models complex systems by discovering mathematical
expressions that capture underlying relationships in observed data. However,
most SR methods prioritize minimizing prediction error over identifying the
governing equations, often producing overly complex or inaccurate expressions.
To address this, we present a decomposable SR method that generates
interpretable multivariate expressions leveraging transformer models, genetic
algorithms (GAs), and genetic programming (GP). In particular, our explainable
SR method distills a trained ``opaque'' regression model into mathematical
expressions that serve as explanations of its computed function. Our method
employs a Multi-Set Transformer to generate multiple univariate symbolic
skeletons that characterize how each variable influences the opaque model's
response. We then evaluate the generated skeletons' performance using a
GA-based approach to select a subset of high-quality candidates before
incrementally merging them via a GP-based cascade procedure that preserves
their original skeleton structure. The final multivariate skeletons undergo
coefficient optimization via a GA. We evaluated our method on problems with
controlled and varying degrees of noise, demonstrating lower or comparable
interpolation and extrapolation errors compared to two GP-based methods, three
neural SR methods, and a hybrid approach. Unlike them, our approach
consistently learned expressions that matched the original mathematical
structure.

</details>


### [270] [Exploring the Feasibility of End-to-End Large Language Model as a Compiler](https://arxiv.org/abs/2511.04132)
*Hongbin Zhang,Shihao Gao,Yang Liu,Mingjie Xing,Yanjun Wu,Chen Zhao*

Main category: cs.LG

TL;DR: LLM在编译器领域潜力巨大，但目前编译成功率低。通过优化提示、扩大模型和引入推理方法可显著提升其性能。


<details>
  <summary>Details</summary>
Motivation: 探索LLM作为端到端编译器的可行性及其未来发展方向。

Method: 设计CompilerEval数据集和框架，评估主流LLM在代码理解和汇编代码生成方面的能力，分析错误，改进LLM生成代码的方法，并评估跨平台编译能力。

Result: LLM具备基本的编译器能力，但编译成功率低。优化方法可显著提高生成汇编代码的质量。

Conclusion: LLM作为编译器的前景广阔，有潜力驱动编译领域的范式转变。建议通过定向训练、知识丰富的提示和专业基础设施来实现高质量汇编代码的生成。

Abstract: In recent years, end-to-end Large Language Model (LLM) technology has shown
substantial advantages across various domains. As critical system software and
infrastructure, compilers are responsible for transforming source code into
target code. While LLMs have been leveraged to assist in compiler development
and maintenance, their potential as an end-to-end compiler remains largely
unexplored. This paper explores the feasibility of LLM as a Compiler (LaaC) and
its future directions. We designed the CompilerEval dataset and framework
specifically to evaluate the capabilities of mainstream LLMs in source code
comprehension and assembly code generation. In the evaluation, we analyzed
various errors, explored multiple methods to improve LLM-generated code, and
evaluated cross-platform compilation capabilities. Experimental results
demonstrate that LLMs exhibit basic capabilities as compilers but currently
achieve low compilation success rates. By optimizing prompts, scaling up the
model, and incorporating reasoning methods, the quality of assembly code
generated by LLMs can be significantly enhanced. Based on these findings, we
maintain an optimistic outlook for LaaC and propose practical architectural
designs and future research directions. We believe that with targeted training,
knowledge-rich prompts, and specialized infrastructure, LaaC has the potential
to generate high-quality assembly code and drive a paradigm shift in the field
of compilation.

</details>


### [271] [Exchange Policy Optimization Algorithm for Semi-Infinite Safe Reinforcement Learning](https://arxiv.org/abs/2511.04147)
*Jiaming Zhang,Yujie Yang,Haoning Wang,Liping Zhang,Shengbo Eben Li*

Main category: cs.LG

TL;DR: 该研究提出了一种名为EPO（exchange policy optimization）的算法框架，用于解决半无限安全强化学习（SI-safe RL）问题，该问题涉及无限数量的安全约束。


<details>
  <summary>Details</summary>
Motivation: 在许多实际应用中，强化学习需要满足无限数量的安全约束，即半无限安全强化学习（SI-safe RL），例如在所有空间位置确保足够的资源分配。

Method: EPO算法通过迭代地解决具有有限约束集安全强化学习子问题，并自适应地调整约束集（增加违反约束的项，移除拉格朗日乘数为零的项）来优化策略。

Result: 该算法能够实现最优策略性能和确定的有界安全性，理论分析表明，训练后的策略性能可与最优解相媲美，并且全局约束违反严格控制在预定界限内。

Conclusion: EPO算法框架能够有效地解决半无限安全强化学习问题，同时实现最优策略性能和严格的安全约束。

Abstract: Safe reinforcement learning (safe RL) aims to respect safety requirements
while optimizing long-term performance. In many practical applications,
however, the problem involves an infinite number of constraints, known as
semi-infinite safe RL (SI-safe RL). Such constraints typically appear when
safety conditions must be enforced across an entire continuous parameter space,
such as ensuring adequate resource distribution at every spatial location. In
this paper, we propose exchange policy optimization (EPO), an algorithmic
framework that achieves optimal policy performance and deterministic bounded
safety. EPO works by iteratively solving safe RL subproblems with finite
constraint sets and adaptively adjusting the active set through constraint
expansion and deletion. At each iteration, constraints with violations
exceeding the predefined tolerance are added to refine the policy, while those
with zero Lagrange multipliers are removed after the policy update. This
exchange rule prevents uncontrolled growth of the working set and supports
effective policy training. Our theoretical analysis demonstrates that, under
mild assumptions, strategies trained via EPO achieve performance comparable to
optimal solutions with global constraint violations strictly remaining within a
prescribed bound.

</details>


### [272] [Learning to Land Anywhere: Transferable Generative Models for Aircraft Trajectories](https://arxiv.org/abs/2511.04155)
*Olav Finne Praesteng Larsen,Massimiliano Ruocco,Michail Spitieris,Abdulmajid Murad,Martina Ragosta*

Main category: cs.LG

TL;DR: 通过迁移学习，可以有效解决机场航班轨迹数据稀疏的问题，从而在数据匮乏的机场生成逼真的合成数据。


<details>
  <summary>Details</summary>
Motivation: 许多次要和区域机场缺乏轨迹数据，这限制了机器学习方法和大规模模拟的应用。因此，需要研究如何有效利用现有数据丰富机场的轨迹数据。

Method: 利用迁移学习，将为数据丰富的机场（苏黎世）训练的先进扩散模型和流匹配模型，在数据稀疏的机场（都柏林）进行微调，并使用不同比例（0%-100%）的都柏林本地数据进行评估。

Result: 扩散模型在仅使用5%的都柏林数据时即可达到具有竞争力的性能，在使用20%的数据时性能接近基线水平，并且在各项指标和视觉检查上始终优于从头开始训练的模型。潜在流匹配和潜在扩散模型也能从预训练中受益，但收益变化较大；而流匹配模型的泛化能力较弱。尽管在捕捉稀有轨迹模式方面存在挑战，但这些发现证明了迁移学习在减少轨迹生成数据需求方面的潜力。

Conclusion: 研究结果表明，迁移学习能够显著降低机场轨迹生成所需的数据量，即使在历史记录有限的环境中，也能实现逼真的合成数据生成，为机场交通管理（ATM）解决方案的开发和验证提供了支持。

Abstract: Access to trajectory data is a key requirement for developing and validating
Air Traffic Management (ATM) solutions, yet many secondary and regional
airports face severe data scarcity. This limits the applicability of machine
learning methods and the ability to perform large-scale simulations or
"what-if" analyses. In this paper, we investigate whether generative models
trained on data-rich airports can be efficiently adapted to data-scarce
airports using transfer learning. We adapt state-of-the-art diffusion- and
flow-matching-based architectures to the aviation domain and evaluate their
transferability between Zurich (source) and Dublin (target) landing trajectory
datasets. Models are pretrained on Zurich and fine-tuned on Dublin with varying
amounts of local data, ranging from 0% to 100%. Results show that
diffusion-based models achieve competitive performance with as little as 5% of
the Dublin data and reach baseline-level performance around 20%, consistently
outperforming models trained from scratch across metrics and visual
inspections. Latent flow matching and latent diffusion models also benefit from
pretraining, though with more variable gains, while flow matching models show
weaker generalization. Despite challenges in capturing rare trajectory
patterns, these findings demonstrate the potential of transfer learning to
substantially reduce data requirements for trajectory generation in ATM,
enabling realistic synthetic data generation even in environments with limited
historical records.

</details>


### [273] [Deep Learning Approach for Clinical Risk Identification Using Transformer Modeling of Heterogeneous EHR Data](https://arxiv.org/abs/2511.04158)
*Anzhuo Xie,Wei-Chen Chang*

Main category: cs.LG

TL;DR: 提出一种基于Transformer的纵向建模方法，用于处理电子健康记录（EHR）数据中的临床风险分类挑战。


<details>
  <summary>Details</summary>
Motivation: 为了解决电子健康记录（EHR）数据中临床风险分类所面临的挑战，例如不规则的时间模式、大的模态差异和复杂的语义结构。

Method: 该方法接收多源医学特征作为输入，并采用特征嵌入层来统一表示结构化和非结构化数据。引入可学习的时间编码机制来捕捉不均匀采样间隔下的动态演变。核心模型采用多头自注意力结构对纵向序列进行全局依赖建模，实现对不同时间尺度下长期趋势和短期波动的聚合。为增强语义表示，设计了语义加权池化模块，为关键医学事件分配自适应重要性，从而提高风险相关特征的可区分性。最后，通过线性映射层生成个体风险评分。

Result: 实验结果表明，该模型在准确率、召回率、精确率和F1分数方面优于传统的机器学习和时间深度学习模型，在多源异构EHR环境中实现了稳定精确的风险识别，并为临床智能决策提供了高效可靠的框架。

Conclusion: 所提出的Transformer-based纵向建模方法能够有效处理异构EHR数据，实现准确的临床风险分类，并为临床决策提供支持。

Abstract: This study proposes a Transformer-based longitudinal modeling method to
address challenges in clinical risk classification with heterogeneous
Electronic Health Record (EHR) data, including irregular temporal patterns,
large modality differences, and complex semantic structures. The method takes
multi-source medical features as input and employs a feature embedding layer to
achieve a unified representation of structured and unstructured data. A
learnable temporal encoding mechanism is introduced to capture dynamic
evolution under uneven sampling intervals. The core model adopts a multi-head
self-attention structure to perform global dependency modeling on longitudinal
sequences, enabling the aggregation of long-term trends and short-term
fluctuations across different temporal scales. To enhance semantic
representation, a semantic-weighted pooling module is designed to assign
adaptive importance to key medical events, improving the discriminative ability
of risk-related features. Finally, a linear mapping layer generates
individual-level risk scores. Experimental results show that the proposed model
outperforms traditional machine learning and temporal deep learning models in
accuracy, recall, precision, and F1-Score, achieving stable and precise risk
identification in multi-source heterogeneous EHR environments and providing an
efficient and reliable framework for clinical intelligent decision-making.

</details>


### [274] [On Joint Regularization and Calibration in Deep Ensembles](https://arxiv.org/abs/2511.04160)
*Laurits Fredsgaard,Mikkel N. Schmidt*

Main category: cs.LG

TL;DR: 联合调优深度集成模型（包括权重衰减、温度缩放和提前停止）通常可以匹配或提高性能，并提出了一种部分重叠的留出策略来优化数据使用。


<details>
  <summary>Details</summary>
Motivation: 深度集成模型在提高模型性能和不确定性校准方面非常有效。虽然集成模型通常是单独训练和调优的，但有证据表明联合调优可以带来更好的性能。本研究旨在探讨联合调优权重衰减、温度缩放和提前停止对预测性能和不确定性量化的影响。

Method: 本研究探索了联合调优权重衰减、温度缩放和提前停止对深度集成模型的影响。此外，还提出了一种部分重叠的留出策略，作为联合评估和最大化训练数据使用之间的一种实用折衷方案。

Result: 研究结果表明，联合调优集成模型通常可以匹配或提高性能，但具体效果因任务和评估指标而异。同时，对联合调优与单独调优的权衡进行了讨论，并提出了部分重叠的留出策略作为一种实用的解决方案。

Conclusion: 联合调优深度集成模型在性能和不确定性量化方面具有潜力，但效果因任务而异。提出的部分重叠留出策略为在实践中优化集成模型提供了一个有价值的解决方案，有助于研究人员和实践者更有效地利用深度集成模型。

Abstract: Deep ensembles are a powerful tool in machine learning, improving both model
performance and uncertainty calibration. While ensembles are typically formed
by training and tuning models individually, evidence suggests that jointly
tuning the ensemble can lead to better performance. This paper investigates the
impact of jointly tuning weight decay, temperature scaling, and early stopping
on both predictive performance and uncertainty quantification. Additionally, we
propose a partially overlapping holdout strategy as a practical compromise
between enabling joint evaluation and maximizing the use of data for training.
Our results demonstrate that jointly tuning the ensemble generally matches or
improves performance, with significant variation in effect size across
different tasks and metrics. We highlight the trade-offs between individual and
joint optimization in deep ensemble training, with the overlapping holdout
strategy offering an attractive practical solution. We believe our findings
provide valuable insights and guidance for practitioners looking to optimize
deep ensemble models. Code is available at:
https://github.com/lauritsf/ensemble-optimality-gap

</details>


### [275] [ScaleDL: Towards Scalable and Efficient Runtime Prediction for Distributed Deep Learning Workloads](https://arxiv.org/abs/2511.04162)
*Xiaokai Wang,Shaoyuan Huang,Yuting Li,Xiaofei Wang*

Main category: cs.LG

TL;DR: ScaleDL是一个新颖的运行时预测框架，它结合了非线性逐层建模和基于GNN的跨层交互机制，可以准确预测DNN运行时，并实现跨不同网络架构的分层泛化能力。此外，ScaleDL还采用D-optimal方法来降低数据收集成本。


<details>
  <summary>Details</summary>
Motivation: 随着DNN模型日益庞大和复杂，其训练和推理任务对分布式计算资源提出了前所未有的要求，因此，准确预测运行时对于优化开发和资源分配至关重要。现有方法要么精度和泛化性不足，要么数据收集成本过高。

Method: ScaleDL框架结合了非线性逐层建模和基于GNN的跨层交互机制，并采用D-optimal方法来降低数据收集成本。

Result: ScaleDL在五个流行DNN模型的基准测试中，将运行时预测的MRE降低了6倍，RMSE降低了5倍，提高了预测精度和泛化能力。

Conclusion: ScaleDL框架能够准确预测DNN运行时，并实现跨不同网络架构的分层泛化能力，同时有效降低了数据收集成本。

Abstract: Deep neural networks (DNNs) form the cornerstone of modern AI services,
supporting a wide range of applications, including autonomous driving,
chatbots, and recommendation systems. As models increase in size and
complexity, DNN workloads like training and inference tasks impose
unprecedented demands on distributed computing resources, making the accurate
prediction of runtime essential for optimizing development and resource
allocation. Traditional methods rely on additive computational unit models,
limiting their accuracy and generalizability. In contrast, graph-enhanced
modeling improves performance but significantly increases data collection
costs. Therefore, there is a critical need for a method that strikes a balance
between accuracy, generalizability, and the costs of data collection. To
address these challenges, we propose ScaleDL, a novel runtime prediction
framework that combines nonlinear layer-wise modeling with graph neural network
(GNN)-based cross-layer interaction mechanism, enabling accurate DNN runtime
prediction and hierarchical generalizability across different network
architectures. Additionally, we employ the D-optimal method to reduce data
collection costs. Experiments on the workloads of five popular DNN models prove
that ScaleDL enhances runtime prediction accuracy and generalizability,
achieving 6$\times$ lower MRE and 5$\times$ lower RMSE compared to baseline
models.

</details>


### [276] [Block Rotation is All You Need for MXFP4 Quantization](https://arxiv.org/abs/2511.04214)
*Yuantian Shao,Peisong Wang,Yuanteng Chen,Chang Xu,Zhihui Wei,Jian Cheng*

Main category: cs.LG

TL;DR: 在MXFP4格式下，GPTQ等方法表现优异，而基于旋转的方法存在兼容性问题，提出块旋转策略以适应MXFP4。


<details>
  <summary>Details</summary>
Motivation: LLMs的规模增长带来了高昂的成本，PTQ是解决部署效率问题的关键，但W4A4量化仍具挑战性，特别是新兴的MXFP4格式需要新的量化方法。

Method: 在MXFP4格式下对现有PTQ方法进行基准测试，分析基于旋转的方法与MXFP4冲突的原因，并提出块旋转策略。

Result: GPTQ等方法在MXFP4下表现良好，基于旋转的方法准确率下降，提出的块旋转策略显著提升了基于旋转的方法在MXFP4下的准确率。

Conclusion: 现有的PTQ方法在MXFP4格式下表现不一，基于旋转的方法与MXFP4存在冲突，提出的块旋转策略能有效解决此问题，为未来低精度格式下的PTQ研究奠定基础。

Abstract: Large language models (LLMs) have achieved remarkable success, but their
rapidly growing scale imposes prohibitive costs in memory, computation, and
energy. Post-training quantization (PTQ) is a promising solution for efficient
deployment, yet achieving accurate W4A4 quantization remains an open challenge.
While most existing methods are designed for INT4 formats, the emergence of
MXFP4 -- a new FP4 format with various hardware support (NVIDIA, AMD, Intel)--
raises questions about the applicability of current techniques. In this work,
we establish a comprehensive benchmark of PTQ methods under the MXFP4 format.
Through systematic evaluation, we find that methods like GPTQ consistently
deliver strong performance, whereas rotation-based approaches, which are almost
used by all state-of-the-art approaches, suffer from severe incompatibility
with MXFP4. We further provide the first in-depth analysis of this conflict,
tracing its root to a fundamental mismatch between MXFP4's PoT (power-of-two)
block scaling and the redistribution of outlier energy via global rotation.
Building on this insight, we propose a simple yet effective block rotation
strategy that adapts rotation-based methods to MXFP4, leading to substantial
accuracy improvements across diverse LLMs. Our findings not only offer clear
guidance for practitioners but also set a foundation for advancing PTQ research
under emerging low-precision formats.

</details>


### [277] [The Strong Lottery Ticket Hypothesis for Multi-Head Attention Mechanisms](https://arxiv.org/abs/2511.04217)
*Hikari Otsuka,Daiki Chijiwa,Yasuyuki Okoshi,Daichi Fujiki,Susumu Takeuchi,Masato Motomura*

Main category: cs.LG

TL;DR: 随机初始化的 Transformer 中存在强大的“抽奖彩票”子网络，这在理论上得到了证实，尤其是在多头注意力机制中。


<details>
  <summary>Details</summary>
Motivation: 现有的强抽奖彩票假说（SLTH）理论并未涵盖 Transformer 架构，特别是其核心的多头注意力（MHA）机制。

Method: 通过理论分析 MHA 中 SLT 的存在性，证明了当 MHA 的隐藏维度为 O(d log(Hd^(3/2))) 时，其包含一个 SLT，能够以高概率近似任意 MHA。利用此理论，将 SLTH 扩展到不含归一化层的 Transformer。

Result: 理论分析 MHA 中 SLT 的存在性，并将 SLTH 扩展到 Transformer。通过实验验证，当增加源模型的隐藏维度时，SLT 与目标模型的近似误差呈指数级下降。

Conclusion: 为 Transformer 架构提供了 SLTH 的理论基础，并提出了 MHA 中 SLT 的存在性证明，同时通过实验验证了理论的有效性。

Abstract: The strong lottery ticket hypothesis (SLTH) conjectures that high-performing
subnetworks, called strong lottery tickets (SLTs), are hidden in randomly
initialized neural networks. Although recent theoretical studies have
established the SLTH across various neural architectures, the SLTH for
transformer architectures still lacks theoretical understanding. In particular,
the current theory of the SLTH does not yet account for the multi-head
attention (MHA) mechanism, a core component of transformers. To address this
gap, we introduce a theoretical analysis of the existence of SLTs within MHAs.
We prove that, if a randomly initialized MHA of $H$ heads and input dimension
$d$ has the hidden dimension $O(d\log(Hd^{3/2}))$ for the key and value, it
contains an SLT that approximates an arbitrary MHA with the same input
dimension with high probability. Furthermore, by leveraging this theory for
MHAs, we extend the SLTH to transformers without normalization layers. We
empirically validate our theoretical findings, demonstrating that the
approximation error between the SLT within a source model (MHA and transformer)
and an approximate target counterpart decreases exponentially by increasing the
hidden dimension of the source model.

</details>


### [278] [seqme: a Python library for evaluating biological sequence design](https://arxiv.org/abs/2511.04239)
*Rasmus Møller-Larsen,Adam Izdebski,Jan Olszewski,Pankhil Gawade,Michal Kmicikiewicz,Wojciech Zarzecki,Ewa Szczurek*

Main category: cs.LG

TL;DR: seqme是一个开源Python库，提供了用于评估生物序列设计计算方法的模块化、可扩展的指标。


<details>
  <summary>Details</summary>
Motivation: 目前缺乏一个集成的软件库来实现对计算生物序列设计方法的性能评估，包括设计序列与目标分布的保真度以及实现期望属性的能力。

Method: seqme库包含序列、嵌入和属性三类指标，支持小分子、DNA、RNA、肽和蛋白质等多种生物序列。它还提供了嵌入和属性模型以及诊断和可视化功能，可用于评估单次和迭代式设计方法。

Result: seqme库为评估生物序列设计计算方法提供了一套全面的工具，包括多种序列类型和评估指标。

Conclusion: seqme库的推出填补了现有工具的空白，为生物序列设计的计算方法评估提供了一个统一、灵活的平台。

Abstract: Recent advances in computational methods for designing biological sequences
have sparked the development of metrics to evaluate these methods performance
in terms of the fidelity of the designed sequences to a target distribution and
their attainment of desired properties. However, a single software library
implementing these metrics was lacking. In this work we introduce seqme, a
modular and highly extendable open-source Python library, containing
model-agnostic metrics for evaluating computational methods for biological
sequence design. seqme considers three groups of metrics: sequence-based,
embedding-based, and property-based, and is applicable to a wide range of
biological sequences: small molecules, DNA, ncRNA, mRNA, peptides and proteins.
The library offers a number of embedding and property models for biological
sequences, as well as diagnostics and visualization functions to inspect the
results. seqme can be used to evaluate both one-shot and iterative
computational design methods.

</details>


### [279] [Guided by Stars: Interpretable Concept Learning Over Time Series via Temporal Logic Semantics](https://arxiv.org/abs/2511.04244)
*Irene Ferfoglia,Simone Silvetti,Gaia Saveri,Laura Nenzi,Luca Bortolussi*

Main category: cs.LG

TL;DR: STELLE是一个神经符号框架，通过将时间序列直接嵌入到时间逻辑概念空间来统一分类和解释，从而实现可解释的分类。


<details>
  <summary>Details</summary>
Motivation: 现有的时间序列分类方法多为黑盒深度学习模型，难以解释其预测的合理性。

Method: 提出了一种新的方法STELLE（Signal Temporal Logic Embedding for Logically-grounded Learning and Explanation），这是一个神经符号框架。该方法引入了一个新的受STL启发的核函数，将原始时间序列映射到其与预定义STL公式的对齐程度，从而在优化准确性的同时，实现可解释性。模型可以提供（1）作为人类可读的STL条件，用于解释个别预测的局部解释；（2）作为表征类别的公式的全局解释。

Result: STELLE在具有挑战性的真实世界基准测试中，在保持竞争力的准确性的同时，提供了逻辑上可靠的解释。

Conclusion: STELLE通过将时间序列直接嵌入到时间逻辑概念空间，成功地统一了分类和解释，为时间序列分类任务提供了可解释的解决方案。

Abstract: Time series classification is a task of paramount importance, as this kind of
data often arises in safety-critical applications. However, it is typically
tackled with black-box deep learning methods, making it hard for humans to
understand the rationale behind their output. To take on this challenge, we
propose a novel approach, STELLE (Signal Temporal logic Embedding for
Logically-grounded Learning and Explanation), a neuro-symbolic framework that
unifies classification and explanation through direct embedding of trajectories
into a space of temporal logic concepts. By introducing a novel STL-inspired
kernel that maps raw time series to their alignment with predefined STL
formulae, our model jointly optimises accuracy and interpretability, as each
prediction is accompanied by the most relevant logical concepts that
characterise it. This yields (i) local explanations as human-readable STL
conditions justifying individual predictions, and (ii) global explanations as
class-characterising formulae. Experiments demonstrate that STELLE achieves
competitive accuracy while providing logically faithful explanations, validated
on diverse real-world benchmarks.

</details>


### [280] [Efficient Reinforcement Learning from Human Feedback via Bayesian Preference Inference](https://arxiv.org/abs/2511.04286)
*Matteo Cercola,Valeria Capretti,Simone Formentin*

Main category: cs.LG

TL;DR: 通过将主动学习集成到RLHF框架中，提出了一种新的混合方法，提高了样本效率和LLM微调的整体性能。


<details>
  <summary>Details</summary>
Motivation: 收集人类偏好数据成本高昂且耗时，需要更高效的学习方法。现有的RLHF方法可扩展性好，但样本效率不高；PBO方法样本效率高，但扩展性有限。

Method: 提出了一种混合框架，将主动学习的查询效率集成到RLHF的扩展性中，通过在RLHF流程中加入一个由采集驱动的模块来实现。

Result: 在（一）高维偏好优化和（二）LLM微调这两个代表性领域进行了验证，实验结果表明在样本效率和整体性能方面均有提高。

Conclusion: 该混合框架通过结合RLHF的可扩展性和PBO的查询效率，实现了主动且样本高效的人类偏好收集，并在各项任务中展现出优于现有方法的性能。

Abstract: Learning from human preferences is a cornerstone of aligning machine learning
models with subjective human judgments. Yet, collecting such preference data is
often costly and time-consuming, motivating the need for more efficient
learning paradigms. Two established approaches offer complementary advantages:
RLHF scales effectively to high-dimensional tasks such as LLM fine-tuning,
while PBO achieves greater sample efficiency through active querying. We
propose a hybrid framework that unifies RLHF's scalability with PBO's query
efficiency by integrating an acquisition-driven module into the RLHF pipeline,
thereby enabling active and sample-efficient preference gathering. We validate
the proposed approach on two representative domains: (i) high-dimensional
preference optimization and (ii) LLM fine-tuning. Experimental results
demonstrate consistent improvements in both sample efficiency and overall
performance across these tasks.

</details>


### [281] [Differentially Private In-Context Learning with Nearest Neighbor Search](https://arxiv.org/abs/2511.04332)
*Antti Koskela,Tejas Kulkarni,Laith Zumot*

Main category: cs.LG

TL;DR: 本研究提出了一种用于差分隐私 in-context learning (DP-ICL) 的新框架，通过在检索相关示例时集成隐私保护机制，提高了隐私-效用权衡。


<details>
  <summary>Details</summary>
Motivation: 现有的 DP-ICL 方法忽略了 LLM 管道中用于检索相关上下文数据的相似性搜索的隐私风险。

Method: 本研究提出的 DP 框架将最近邻搜索与隐私过滤器相结合，该过滤器跟踪所选样本的累积隐私成本，以确保遵守差分隐私预算。

Result: 在文本分类和文档问答的基准测试中，本研究提出的方法明显优于现有方法，实现了更有利的隐私-效用权衡。

Conclusion: 本研究提出的 DP 框架通过在检索过程中集成隐私保护，为 DP-ICL 提供了更优的隐私-效用权衡。

Abstract: Differentially private in-context learning (DP-ICL) has recently become an
active research topic due to the inherent privacy risks of in-context learning.
However, existing approaches overlook a critical component of modern large
language model (LLM) pipelines: the similarity search used to retrieve relevant
context data. In this work, we introduce a DP framework for in-context learning
that integrates nearest neighbor search of relevant examples in a privacy-aware
manner. Our method outperforms existing baselines by a substantial margin
across all evaluated benchmarks, achieving more favorable privacy-utility
trade-offs. To achieve this, we employ nearest neighbor retrieval from a
database of context data, combined with a privacy filter that tracks the
cumulative privacy cost of selected samples to ensure adherence to a central
differential privacy budget. Experimental results on text classification and
document question answering show a clear advantage of the proposed method over
existing baselines.

</details>


### [282] [LUME-DBN: Full Bayesian Learning of DBNs from Incomplete data in Intensive Care](https://arxiv.org/abs/2511.04333)
*Federico Pirola,Fabio Stella,Marco Grzegorczyk*

Main category: cs.LG

TL;DR: 本研究提出了一种基于吉布斯采样的动态贝叶斯网络（DBNs）学习方法，用于处理纵向临床数据中的缺失值，并能在模拟和真实重症监护数据上实现优于MICE的重构精度和收敛性。


<details>
  <summary>Details</summary>
Motivation: 现有处理纵向临床数据缺失值的方法未能充分考虑数据的时变性质，限制了DBNs在医疗保健（尤其是在重症监护中）中的应用，因为在这些场景中量化不确定性和模型可信度至关重要。

Method: 提出了一种新颖的、基于吉布斯抽样的DBNs学习方法，将缺失值视为服从高斯分布的未知参数，并在每次迭代中从其完全条件分布中抽取样本，以实现合理的插补和不确定性估计。

Result: 与标准的模型无关技术（如MICE）相比，该贝叶斯方法在模拟和真实重症监护数据上均表现出更高的重构精度和更好的收敛性。

Conclusion: 研究结果强调了在时变模型中结合全贝叶斯推断的临床意义，能够提供更可靠的插补，并提供对模型行为更深入的见解，从而支持更安全、更明智的临床决策，尤其是在缺失值频繁且影响重大的情况下。

Abstract: Dynamic Bayesian networks (DBNs) are increasingly used in healthcare due to
their ability to model complex temporal relationships in patient data while
maintaining interpretability, an essential feature for clinical
decision-making. However, existing approaches to handling missing data in
longitudinal clinical datasets are largely derived from static Bayesian
networks literature, failing to properly account for the temporal nature of the
data. This gap limits the ability to quantify uncertainty over time, which is
particularly critical in settings such as intensive care, where understanding
the temporal dynamics is fundamental for model trustworthiness and
applicability across diverse patient groups. Despite the potential of DBNs, a
full Bayesian framework that integrates missing data handling remains
underdeveloped. In this work, we propose a novel Gibbs sampling-based method
for learning DBNs from incomplete data. Our method treats each missing value as
an unknown parameter following a Gaussian distribution. At each iteration, the
unobserved values are sampled from their full conditional distributions,
allowing for principled imputation and uncertainty estimation. We evaluate our
method on both simulated datasets and real-world intensive care data from
critically ill patients. Compared to standard model-agnostic techniques such as
MICE, our Bayesian approach demonstrates superior reconstruction accuracy and
convergence properties. These results highlight the clinical relevance of
incorporating full Bayesian inference in temporal models, providing more
reliable imputations and offering deeper insight into model behavior. Our
approach supports safer and more informed clinical decision-making,
particularly in settings where missing data are frequent and potentially
impactful.

</details>


### [283] [The Illusion of Certainty: Uncertainty quantification for LLMs fails under ambiguity](https://arxiv.org/abs/2511.04418)
*Tim Tomov,Dominik Fuchsgruber,Tom Wollschläger,Stephan Günnemann*

Main category: cs.LG

TL;DR: 当前不确定性量化（UQ）方法在处理模糊数据时表现不佳，需要新的方法来改进LLM的可靠性。


<details>
  <summary>Details</summary>
Motivation: 现有UQ方法在没有歧义的任务上表现良好，但在现实世界中，语言具有内在的歧义性，这使得这些方法在模糊数据上的表现会下降到接近随机的水平。

Method: 引入了首个带有地面真实答案分布的模糊问答（QA）数据集MAQA*和AmbigQA*，并在此数据集上评估了当前主流的UQ方法。

Result: 在模糊数据上，基于预测分布、内部表示和模型集成的方法都表现出性能下降，接近随机水平。理论分析表明，预测分布和基于模型集成的方法在模糊性下存在根本性的局限性。

Conclusion: 现有UQ方法在处理模糊语言时存在关键缺陷，需要重新思考当前的建模范式，以提高LLM在现实世界应用中的可靠性。

Abstract: Accurate uncertainty quantification (UQ) in Large Language Models (LLMs) is
critical for trustworthy deployment. While real-world language is inherently
ambiguous, reflecting aleatoric uncertainty, existing UQ methods are typically
benchmarked against tasks with no ambiguity. In this work, we demonstrate that
while current uncertainty estimators perform well under the restrictive
assumption of no ambiguity, they degrade to close-to-random performance on
ambiguous data. To this end, we introduce MAQA* and AmbigQA*, the first
ambiguous question-answering (QA) datasets equipped with ground-truth answer
distributions estimated from factual co-occurrence. We find this performance
deterioration to be consistent across different estimation paradigms: using the
predictive distribution itself, internal representations throughout the model,
and an ensemble of models. We show that this phenomenon can be theoretically
explained, revealing that predictive-distribution and ensemble-based estimators
are fundamentally limited under ambiguity. Overall, our study reveals a key
shortcoming of current UQ methods for LLMs and motivates a rethinking of
current modeling paradigms.

</details>


### [284] [Spurious Correlation-Aware Embedding Regularization for Worst-Group Robustness](https://arxiv.org/abs/2511.04401)
*Subeen Park,Joowang Kim,Hakyung Lee,Sunjae Yoo,Kyungwoo Song*

Main category: cs.LG

TL;DR: 深度学习模型易受分布偏移和亚群偏移影响，尤其是在代表性不足的群体中表现不佳。现有方法虽有进展但受限，缺乏理论基础。为解决此问题，提出SCER，通过正则化特征表示来抑制虚假线索，并从理论上证明其对最差群体误差的影响。


<details>
  <summary>Details</summary>
Motivation: 深度学习模型在各种领域表现优异，但易受虚假相关性影响，在分布偏移（尤其是在亚群偏移场景下）和代表性不足的群体中表现不佳，现有方法对此问题的缓解效果有限且缺乏理论支持。

Method: 提出一种名为SCER（Spurious Correlation-Aware Embedding Regularization for Worst-Group Robustness）的新方法，该方法直接对特征表示进行正则化，以抑制虚假线索。理论上证明，最差群体误差受到分类器对虚假方向和核心方向依赖程度的影响，而这些方向可以从跨域和跨类的群体平均嵌入的差异中识别出来。通过在嵌入层面施加理论约束，SCER鼓励模型关注核心特征，降低对虚假模式的敏感性。

Result: 通过在多个视觉和语言任务上的系统评估，SCER在最差群体准确性方面优于现有的最先进方法。

Conclusion: SCER通过直接正则化特征表示，有效解决了深度学习模型在亚群偏移场景下的鲁棒性问题，并在多个基准测试中取得了最先进的性能。

Abstract: Deep learning models achieve strong performance across various domains but
often rely on spurious correlations, making them vulnerable to distribution
shifts. This issue is particularly severe in subpopulation shift scenarios,
where models struggle in underrepresented groups. While existing methods have
made progress in mitigating this issue, their performance gains are still
constrained. They lack a rigorous theoretical framework connecting the
embedding space representations with worst-group error. To address this
limitation, we propose Spurious Correlation-Aware Embedding Regularization for
Worst-Group Robustness (SCER), a novel approach that directly regularizes
feature representations to suppress spurious cues. We show theoretically that
worst-group error is influenced by how strongly the classifier relies on
spurious versus core directions, identified from differences in group-wise mean
embeddings across domains and classes. By imposing theoretical constraints at
the embedding level, SCER encourages models to focus on core features while
reducing sensitivity to spurious patterns. Through systematic evaluation on
multiple vision and language, we show that SCER outperforms prior
state-of-the-art studies in worst-group accuracy. Our code is available at
\href{https://github.com/MLAI-Yonsei/SCER}{https://github.com/MLAI-Yonsei/SCER}.

</details>


### [285] [Ground-Truth Subgraphs for Better Training and Evaluation of Knowledge Graph Augmented LLMs](https://arxiv.org/abs/2511.04473)
*Alberto Cattaneo,Carlo Luschi,Daniel Justus*

Main category: cs.LG

TL;DR: 检索知识图谱信息可以提高LLM的事实性。由于缺乏具有挑战性的QA数据集，难以比较现有方法。SynthKGQA框架可以从任何知识图谱生成高质量的合成知识图谱问答数据集，并提供用于推理的完整事实。SynthKGQA生成的GTSQA数据集可以更好地评估KG检索器的零样本泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有的知识图谱问答方法难以比较，因为缺乏具有挑战性的QA数据集。

Method: 提出SynthKGQA框架，可以从任何知识图谱生成合成QA数据集，并提供完整的ground-truth事实。

Result: 使用SynthKGQA生成了GTSQA数据集，该数据集可用于评估KG检索器的零样本泛化能力，并对流行的KG增强LLM解决方案进行了基准测试。

Conclusion: SynthKGQA框架不仅可以进行信息检索的基准测试，还可以用于训练更好的模型。

Abstract: Retrieval of information from graph-structured knowledge bases represents a
promising direction for improving the factuality of LLMs. While various
solutions have been proposed, a comparison of methods is difficult due to the
lack of challenging QA datasets with ground-truth targets for graph retrieval.
We present SynthKGQA, a framework for generating high-quality synthetic
Knowledge Graph Question Answering datasets from any Knowledge Graph, providing
the full set of ground-truth facts in the KG to reason over each question. We
show how, in addition to enabling more informative benchmarking of KG
retrievers, the data produced with SynthKGQA also allows us to train better
models. We apply SynthKGQA to Wikidata to generate GTSQA, a new dataset
designed to test zero-shot generalization abilities of KG retrievers with
respect to unseen graph structures and relation types, and benchmark popular
solutions for KG-augmented LLMs on it.

</details>


### [286] [On the Equivalence of Regression and Classification](https://arxiv.org/abs/2511.04422)
*Jayadeva,Naman Dwivedi,Hari Krishnan,N. M. Anoop Krishnan*

Main category: cs.LG

TL;DR: 本论文建立了回归和分类之间的形式化联系，并提出了一种新的回归方法和评估数据集难易程度的“回归能力”度量。


<details>
  <summary>Details</summary>
Motivation: 现有方法中，支持向量回归中的边距最大化项$\|w\|$的理论依据不足，仅被视为正则化项。

Method: 本文证明了具有M个样本且位于超平面上的回归问题等价于一个具有2M个样本的线性分类任务。利用该等价性，提出了一种不同于传统方法的边距最大化回归模型，并引入了一种“回归能力”度量来评估数据集的回归难度。此外，还利用该等价性训练神经网络学习一个线性化映射。

Result: 通过该等价性，可以导出一种新的回归方法，并且可以定义一个“回归能力”度量来评估数据集的回归难度。同时，神经网络可以学习一个线性化映射，将输入变量转换到一个线性回归模型可以有效处理的空间。

Conclusion: 本文建立了回归和分类之间的形式化联系，并在此基础上提出了一种新的回归方法和一种“回归能力”度量。这种方法和度量可以帮助更好地理解和处理回归问题，尤其是在利用神经网络进行线性化映射方面。

Abstract: A formal link between regression and classification has been tenuous. Even
though the margin maximization term $\|w\|$ is used in support vector
regression, it has at best been justified as a regularizer. We show that a
regression problem with $M$ samples lying on a hyperplane has a one-to-one
equivalence with a linearly separable classification task with $2M$ samples. We
show that margin maximization on the equivalent classification task leads to a
different regression formulation than traditionally used. Using the
equivalence, we demonstrate a ``regressability'' measure, that can be used to
estimate the difficulty of regressing a dataset, without needing to first learn
a model for it. We use the equivalence to train neural networks to learn a
linearizing map, that transforms input variables into a space where a linear
regressor is adequate.

</details>


### [287] [ForecastGAN: A Decomposition-Based Adversarial Framework for Multi-Horizon Time Series Forecasting](https://arxiv.org/abs/2511.04445)
*Syeda Sitara Wishal Fatima,Afshin Rahimi*

Main category: cs.LG

TL;DR: ForecastGAN是一个新颖的基于分解的对抗性框架，可解决多步预测的局限性，并在短期预测方面优于最先进的Transformer模型。


<details>
  <summary>Details</summary>
Motivation: 现有时间序列预测方法在短期预测方面表现不佳，并且通常忽略类别特征。

Method: ForecastGAN通过三个模块实现：1. 分解模块：提取季节性和趋势分量。 2. 模型选择模块：根据预测范围选择最佳神经网络配置。 3. 对抗训练模块：通过条件生成对抗网络训练增强预测鲁棒性。

Result: 在11个基准多元时间序列数据集上进行了验证，ForecastGAN在短期预测方面持续优于最先进的Transformer模型，并且在长期预测方面具有竞争力。

Conclusion: ForecastGAN提供了一种更通用的时间序列预测方法，可以适应特定上下文，并在各种数据集上保持强劲性能，而无需进行广泛的超参数调整。

Abstract: Time series forecasting is essential across domains from finance to supply
chain management. This paper introduces ForecastGAN, a novel decomposition
based adversarial framework addressing limitations in existing approaches for
multi-horizon predictions. Although transformer models excel in long-term
forecasting, they often underperform in short-term scenarios and typically
ignore categorical features. ForecastGAN operates through three integrated
modules: a Decomposition Module that extracts seasonality and trend components;
a Model Selection Module that identifies optimal neural network configurations
based on forecasting horizon; and an Adversarial Training Module that enhances
prediction robustness through Conditional Generative Adversarial Network
training. Unlike conventional approaches, ForecastGAN effectively integrates
both numerical and categorical features. We validate our framework on eleven
benchmark multivariate time series datasets that span various forecasting
horizons. The results show that ForecastGAN consistently outperforms
state-of-the-art transformer models for short-term forecasting while remaining
competitive for long-term horizons. This research establishes a more
generalizable approach to time series forecasting that adapts to specific
contexts while maintaining strong performance across diverse data
characteristics without extensive hyperparameter tuning.

</details>


### [288] [Federated Stochastic Minimax Optimization under Heavy-Tailed Noises](https://arxiv.org/abs/2511.04456)
*Xinwen Zhang,Hongchang Gao*

Main category: cs.LG

TL;DR: 本文研究了在重尾梯度噪声下联邦学习中的非凸-PL最小极大优化问题，并提出了两种新算法Fed-NSGDA-M和FedMuon-DA，理论和实验均证明了其有效性。


<details>
  <summary>Details</summary>
Motivation: 重尾噪声在非凸随机优化中引起了越来越多的关注，因为它比标准的有界方差假设更符合实际。

Method: 提出两种新算法：Fed-NSGDA-M（结合归一化梯度）和FedMuon-DA（利用Muon优化器进行本地更新）。

Result: 两种算法都实现了$O({1}/{(TNp)^{rac{s-1}{2s}}})$的收敛率。

Conclusion: Fed-NSGDA-M和FedMuon-DA是首个在重尾噪声下具有严格理论保证的联邦最小极大优化算法。

Abstract: Heavy-tailed noise has attracted growing attention in nonconvex stochastic
optimization, as numerous empirical studies suggest it offers a more realistic
assumption than standard bounded variance assumption. In this work, we
investigate nonconvex-PL minimax optimization under heavy-tailed gradient noise
in federated learning. We propose two novel algorithms: Fed-NSGDA-M, which
integrates normalized gradients, and FedMuon-DA, which leverages the Muon
optimizer for local updates. Both algorithms are designed to effectively
address heavy-tailed noise in federated minimax optimization, under a milder
condition. We theoretically establish that both algorithms achieve a
convergence rate of $O({1}/{(TNp)^{\frac{s-1}{2s}}})$. To the best of our
knowledge, these are the first federated minimax optimization algorithms with
rigorous theoretical guarantees under heavy-tailed noise. Extensive experiments
further validate their effectiveness.

</details>


### [289] [Towards Causal Market Simulators](https://arxiv.org/abs/2511.04469)
*Dennis Thumm,Luis Ontaneda Mijares*

Main category: cs.LG

TL;DR: 我们将时间序列神经因果模型VAE（TNCM-VAE）与变分自编码器和结构因果模型相结合，以生成反事实金融时间序列，同时保留时间依赖性和因果关系。


<details>
  <summary>Details</summary>
Motivation: 现有的市场生成器缺乏进行反事实分析和风险评估所需的因果推理能力。

Method: TNCM-VAE在解码器架构中通过有向无环图强制执行因果约束，并采用因果Wasserstein距离进行训练。

Result: 在受Ornstein-Uhlenbeck过程启发的合成自回归模型上进行了验证，与真实值相比，L1距离低至0.03-0.10，在反事实概率估计方面表现优越。

Conclusion: 该模型通过生成尊重潜在因果机制的合理反事实市场轨迹，实现了金融压力测试、情景分析和增强的回测。

Abstract: Market generators using deep generative models have shown promise for
synthetic financial data generation, but existing approaches lack causal
reasoning capabilities essential for counterfactual analysis and risk
assessment. We propose a Time-series Neural Causal Model VAE (TNCM-VAE) that
combines variational autoencoders with structural causal models to generate
counterfactual financial time series while preserving both temporal
dependencies and causal relationships. Our approach enforces causal constraints
through directed acyclic graphs in the decoder architecture and employs the
causal Wasserstein distance for training. We validate our method on synthetic
autoregressive models inspired by the Ornstein-Uhlenbeck process, demonstrating
superior performance in counterfactual probability estimation with L1 distances
as low as 0.03-0.10 compared to ground truth. The model enables financial
stress testing, scenario analysis, and enhanced backtesting by generating
plausible counterfactual market trajectories that respect underlying causal
mechanisms.

</details>


### [290] [Q3R: Quadratic Reweighted Rank Regularizer for Effective Low-Rank Training](https://arxiv.org/abs/2511.04485)
*Ipsita Ghosh,Ethan Nguyen,Christian Kümmerle*

Main category: cs.LG

TL;DR: Q3R是一种新的低秩训练策略，它通过二次重加权秩正则化器（Q3R）来解决低秩预训练任务中的挑战，能够训练出具有特定低秩的权重矩阵，并且在保持可比的预测性能的同时，计算开销很小。


<details>
  <summary>Details</summary>
Motivation: 现有的参数高效训练方法在低秩预训练任务中表现不佳，因为维持低秩结构和目标函数仍然是一个挑战。因此，需要一种新的方法来解决这个问题。

Method: 提出了一种名为二次重加权秩正则化器（Q3R）的新方法，该方法基于二次正则化项，并受到迭代重加权最小二乘（IRLS）框架的启发。Q3R作为秩的替代目标，通过平滑的行列式来实现。

Result: Q3R 能够训练具有指定低秩的目标模型，在预测性能上可以与密集模型相媲美，并且计算开销很小。在 ViT-Tiny 模型上进行了实验，在 CIFAR-10 数据集上，分别实现了 60% 和 80% 的参数截断，准确率仅下降了约 1.3% 和 4%。该方法在 Transformer 的图像和语言任务上都得到了验证，并且也适用于低秩微调。

Conclusion: Q3R 是一种有效的低秩训练策略，能够显著减少模型参数，同时保持高性能，并且适用于多种任务。

Abstract: Parameter-efficient training, based on low-rank optimization, has become a
highly successful tool for fine-tuning large deep-learning models. However,
these methods fail at low-rank pre-training tasks where maintaining the
low-rank structure and the objective remains a challenging task. We propose the
Quadratic Reweighted Rank Regularizer dubbed Q3R, which leads to a novel
low-rank inducing training strategy inspired by the iteratively reweighted
least squares (IRLS) framework. Q3R is based on a quadratic regularizer term
which majorizes a smoothed log determinant serving as rank surrogate objective.
Unlike other low-rank training techniques, Q3R is able to train weight matrices
with prescribed, low target ranks of models that achieve comparable predictive
performance as dense models, with small computational overhead, while remaining
fully compatible with existing architectures. For example, we demonstrated one
experiment where we are able to truncate $60\%$ and $80\%$ of the parameters of
a ViT-Tiny model with $~1.3\%$ and $~4\%$ accuracy drop in CIFAR-10 performance
respectively. The efficacy of Q3R is confirmed on Transformers across both
image and language tasks, including for low-rank fine-tuning.

</details>


### [291] [Distribution-Aware Tensor Decomposition for Compression of Convolutional Neural Networks](https://arxiv.org/abs/2511.04494)
*Alper Kalle,Theo Rudkiewicz,Mohamed-Oumar Ouerfelli,Mohamed Tamaazousti*

Main category: cs.LG

TL;DR: 通过张量化和低秩表示压缩神经网络，使用数据驱动的范数而非传统的Frobenius范数，并通过新的交替最小二乘算法进行优化，无需微调即可获得有竞争力的精度，且可在不同数据集上迁移。


<details>
  <summary>Details</summary>
Motivation: 由于神经网络在图像任务中计算量大，需要一种压缩方法。

Method: 提出了一种使用数据驱动的范数（最小化层输出分布的变化）来优化张量分解（Tucker-2和CPD）的交替最小二乘算法，并展示了该范数在不同数据集上的迁移性。

Result: 在ResNet-18/50和GoogLeNet等CNN架构以及ImageNet等数据集上，该方法在无需微调的情况下达到了有竞争力的精度，并且在迁移到新数据集时精度下降很小。

Conclusion: 所提出的数据驱动的范数和优化算法能够有效地压缩神经网络，并且具有良好的泛化性和迁移性，无需进行微调。

Abstract: Neural networks are widely used for image-related tasks but typically demand
considerable computing power. Once a network has been trained, however, its
memory- and compute-footprint can be reduced by compression. In this work, we
focus on compression through tensorization and low-rank representations.
Whereas classical approaches search for a low-rank approximation by minimizing
an isotropic norm such as the Frobenius norm in weight-space, we use
data-informed norms that measure the error in function space. Concretely, we
minimize the change in the layer's output distribution, which can be expressed
as $\lVert (W - \widetilde{W}) \Sigma^{1/2}\rVert_F$ where $\Sigma^{1/2}$ is
the square root of the covariance matrix of the layer's input and $W$,
$\widetilde{W}$ are the original and compressed weights. We propose new
alternating least square algorithms for the two most common tensor
decompositions (Tucker-2 and CPD) that directly optimize the new norm. Unlike
conventional compression pipelines, which almost always require
post-compression fine-tuning, our data-informed approach often achieves
competitive accuracy without any fine-tuning. We further show that the same
covariance-based norm can be transferred from one dataset to another with only
a minor accuracy drop, enabling compression even when the original training
dataset is unavailable. Experiments on several CNN architectures (ResNet-18/50,
and GoogLeNet) and datasets (ImageNet, FGVC-Aircraft, Cifar10, and Cifar100)
confirm the advantages of the proposed method.

</details>


### [292] [Alternative Fairness and Accuracy Optimization in Criminal Justice](https://arxiv.org/abs/2511.04505)
*Shaolong Wu,James Blume,Geshi Yeung*

Main category: cs.LG

TL;DR: 算法公平性研究迅速发展，尤其在刑事司法领域，但关键概念仍未确定。本文综述了群体、个体和过程公平性，并分析了它们冲突的条件。提出了一种对标准群体公平性的修改：在保持假阴性率差异在小容忍度内的前提下，最小化加权误差损失。此方法更易于找到解决方案，可提高预测准确性，并突显了误差成本的伦理选择。最后，提出一个基于需求驱动决策、透明度与问责制、以及窄界定义与解决方案三大支柱的实用部署框架，将技术设计与合法性联系起来，为风险评估工具的使用者提供可行的指导。


<details>
  <summary>Details</summary>
Motivation: 研究算法公平性在刑事司法领域的概念模糊性，特别是群体、个体和过程公平性之间的冲突条件，并提出改进现有群体公平性方法的必要性。

Method: 综述了群体、个体和过程公平性，并分析了它们之间的冲突条件。提出了一种修改标准群体公平性的新方法，即在保持假阴性率差异在小容忍度内的前提下，最小化加权误差损失。此外，还提出了一个包含需求驱动决策、透明度与问责制、以及窄界定义与解决方案三大支柱的实用部署框架。

Result: 所提出的方法使得解决方案更容易找到，可以提高预测准确性，并突显了误差成本的伦理选择。该框架将技术设计与合法性联系起来，为风险评估工具的使用者提供了可行的指导。

Conclusion: 算法公平性，特别是群体公平性，可以通过最小化加权误差损失并控制假阴性率差异来改进。提出的部署框架能够将技术设计与合法性相结合，为公共决策系统提供实用的指导。

Abstract: Algorithmic fairness has grown rapidly as a research area, yet key concepts
remain unsettled, especially in criminal justice. We review group, individual,
and process fairness and map the conditions under which they conflict. We then
develop a simple modification to standard group fairness. Rather than exact
parity across protected groups, we minimize a weighted error loss while keeping
differences in false negative rates within a small tolerance. This makes
solutions easier to find, can raise predictive accuracy, and surfaces the
ethical choice of error costs. We situate this proposal within three classes of
critique: biased and incomplete data, latent affirmative action, and the
explosion of subgroup constraints. Finally, we offer a practical framework for
deployment in public decision systems built on three pillars: need-based
decisions, Transparency and accountability, and narrowly tailored definitions
and solutions. Together, these elements link technical design to legitimacy and
provide actionable guidance for agencies that use risk assessment and related
tools.

</details>


### [293] [Linear Mode Connectivity under Data Shifts for Deep Ensembles of Image Classifiers](https://arxiv.org/abs/2511.04514)
*C. Hepburn,T. Zielke,A. P. Raulf*

Main category: cs.LG

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: The phenomenon of linear mode connectivity (LMC) links several aspects of
deep learning, including training stability under noisy stochastic gradients,
the smoothness and generalization of local minima (basins), the similarity and
functional diversity of sampled models, and architectural effects on data
processing. In this work, we experimentally study LMC under data shifts and
identify conditions that mitigate their impact. We interpret data shifts as an
additional source of stochastic gradient noise, which can be reduced through
small learning rates and large batch sizes. These parameters influence whether
models converge to the same local minimum or to regions of the loss landscape
with varying smoothness and generalization. Although models sampled via LMC
tend to make similar errors more frequently than those converging to different
basins, the benefit of LMC lies in balancing training efficiency against the
gains achieved from larger, more diverse ensembles. Code and supplementary
materials will be made publicly available at https://github.com/DLR-KI/LMC in
due course.

</details>


### [294] [End-to-End Reinforcement Learning of Koopman Models for eNMPC of an Air Separation Unit](https://arxiv.org/abs/2511.04522)
*Daniel Mayfrank,Kayra Dernek,Laura Lang,Alexander Mitsos,Manuel Dahmen*

Main category: cs.LG

TL;DR: RL-based Koopman surrogate models can be effectively trained for large-scale economic NMPC, outperforming system identification-based approaches by achieving similar economic performance without constraint violations.


<details>
  <summary>Details</summary>
Motivation: To demonstrate the scalability of a previously proposed reinforcement learning (RL)-based method for training Koopman surrogate models for economic Nonlinear Model Predictive Control ((e)NMPC) applications beyond small-scale case studies.

Method: The paper applies a recently proposed RL-based method to train Koopman surrogate models for an eNMPC problem. This method is tested on a large-scale demand response case study involving a nitrogen air separation unit, assuming observability of only a few realistically measurable plant variables. The performance is compared against a purely system identification-based Koopman eNMPC.

Result: The RL-based method scales well to the large-scale case study. It achieves similar economic performance to the system identification-based method but effectively avoids constraint violations, which the latter frequently encounters.

Conclusion: The RL-based approach for training Koopman surrogate models is effective and scalable for challenging, large-scale eNMPC applications, offering improved constraint satisfaction compared to traditional system identification methods while maintaining economic performance.

Abstract: With our recently proposed method based on reinforcement learning (Mayfrank
et al. (2024), Comput. Chem. Eng. 190), Koopman surrogate models can be trained
for optimal performance in specific (economic) nonlinear model predictive
control ((e)NMPC) applications. So far, our method has exclusively been
demonstrated on a small-scale case study. Herein, we show that our method
scales well to a more challenging demand response case study built on a
large-scale model of a single-product (nitrogen) air separation unit. Across
all numerical experiments, we assume observability of only a few realistically
measurable plant variables. Compared to a purely system identification-based
Koopman eNMPC, which generates small economic savings but frequently violates
constraints, our method delivers similar economic performance while avoiding
constraint violations.

</details>


### [295] [Uncertainty Quantification for Reduced-Order Surrogate Models Applied to Cloud Microphysics](https://arxiv.org/abs/2511.04534)
*Jonas E. Katona,Emily K. de Jong,Nipun Gunawardena*

Main category: cs.LG

TL;DR: 提出一种后处理的、与模型无关的框架，用于潜空间降阶模型（ROM）中的预测不确定性量化，可用于潜空间动力学、重构和端到端预测，并在云微物理的潜空间动力学模型上进行了演示。


<details>
  <summary>Details</summary>
Motivation: 现有降阶模型（ROM）缺乏鲁棒的不确定性量化方法，并且现有方法通常与特定架构或训练相关，限制了灵活性和泛化能力。

Method: 使用共形预测（conformal prediction）的方法，在潜空间中对ROM的各个组成部分（潜空间动力学、重构和端到端预测）进行统计预测区间估计。

Result: 所提出的方法在云微物理的潜空间动力学模型上进行了演示，能够准确预测液滴尺寸分布的演变，并对整个ROM流程中的不确定性进行了量化。

Conclusion: 该框架是一种后处理的、与模型无关的方法，可以对潜空间ROM进行预测不确定性量化，并且在实际应用中证明了其有效性。

Abstract: Reduced-order models (ROMs) can efficiently simulate high-dimensional
physical systems, but lack robust uncertainty quantification methods. Existing
approaches are frequently architecture- or training-specific, which limits
flexibility and generalization. We introduce a post hoc, model-agnostic
framework for predictive uncertainty quantification in latent space ROMs that
requires no modification to the underlying architecture or training procedure.
Using conformal prediction, our approach estimates statistical prediction
intervals for multiple components of the ROM pipeline: latent dynamics,
reconstruction, and end-to-end predictions. We demonstrate the method on a
latent space dynamical model for cloud microphysics, where it accurately
predicts the evolution of droplet-size distributions and quantifies uncertainty
across the ROM pipeline.

</details>


### [296] [Integrating Temporal and Structural Context in Graph Transformers for Relational Deep Learning](https://arxiv.org/abs/2511.04557)
*Divyansha Lachi,Mahmoud Mohammadi,Joe Meyer,Vinam Arora,Tom Palczewski,Eva L. Dyer*

Main category: cs.LG

TL;DR: 现有图模型无法充分利用时序信息，RGP模型通过时序子图采样器和图注意力机制，有效整合时空依赖和多任务学习，在多个数据集上表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有图模型在处理包含复杂时序动态的关系数据时，主要关注空间结构，忽略了时间信息作为建模信号的价值，并且通常只支持单任务预测。因此，需要一种能够整合长程时空依赖、支持多任务预测的关系数据模型。

Method: 提出了一种时序子图采样器，用于捕捉跨越时间的关系。并设计了关系图感知器（RGP），一种基于图注意力机制的模型，利用跨注意力潜在瓶颈整合结构和时序信息，支持多任务学习。

Result: RGP在RelBench、SALT和CTU数据集上均取得了最先进的性能。

Conclusion: RGP模型能够有效整合时空依赖，支持多任务学习，为关系深度学习提供了一个通用且可扩展的解决方案。

Abstract: In domains such as healthcare, finance, and e-commerce, the temporal dynamics
of relational data emerge from complex interactions-such as those between
patients and providers, or users and products across diverse categories. To be
broadly useful, models operating on these data must integrate long-range
spatial and temporal dependencies across diverse types of entities, while also
supporting multiple predictive tasks. However, existing graph models for
relational data primarily focus on spatial structure, treating temporal
information merely as a filtering constraint to exclude future events rather
than a modeling signal, and are typically designed for single-task prediction.
To address these gaps, we introduce a temporal subgraph sampler that enhances
global context by retrieving nodes beyond the immediate neighborhood to capture
temporally relevant relationships. In addition, we propose the Relational Graph
Perceiver (RGP), a graph transformer architecture for relational deep learning
that leverages a cross-attention-based latent bottleneck to efficiently
integrate information from both structural and temporal contexts. This latent
bottleneck integrates signals from different node and edge types into a common
latent space, enabling the model to build global context across the entire
relational system. RGP also incorporates a flexible cross-attention decoder
that supports joint learning across tasks with disjoint label spaces within a
single model. Experiments on RelBench, SALT, and CTU show that RGP delivers
state-of-the-art performance, offering a general and scalable solution for
relational deep learning with support for diverse predictive tasks.

</details>


### [297] [ARETE: an R package for Automated REtrieval from TExt with large language models](https://arxiv.org/abs/2511.04573)
*Vasco V. Branco,Jandó Benedek,Lidia Pivovarova,Luís Correia,Pedro Cardoso*

Main category: cs.LG

TL;DR: 该研究提出了ARETE R包，一个利用大型语言模型（ChatGPT API）自动化提取物种出现数据的开源软件，以解决物种数据缺失的问题，并展示了其在物种分布范围绘制和保护规划方面的潜力。


<details>
  <summary>Details</summary>
Motivation: 关键物种数据（特别是出现数据）的缺失阻碍了严格的保护措施的实施，同时人类活动加速了新信息的收集和处理需求。现有文献中的数据通常不可 machine-readable，需要大量人工提取。

Method: 研究人员开发了一个名为ARETE的R包，该软件利用大型语言模型（ChatGPT API）来自动化提取物种出现数据。该软件包集成了从光学字符识别到异常值检测和表格输出的整个数据提取和验证过程。并通过与人类注释者工作的系统性比较来验证ARETE。

Result: 通过比较使用GBIF数据和自动提取的数据绘制的100种蜘蛛的分布范围图，研究表明新提取的数据将已知的出现范围扩大了三个数量级，揭示了过去物种存在的新区域。

Conclusion: ARETE能够更快地获取以往无法利用的出现数据，这对于需要此类数据的项目来说可能是一个重要的改变。研究人员可以更好地优先分配资源，手动验证选定的物种，同时为大多数物种保持自动提取。该工作流程还可以预测项目规划期间可用的书目数据。

Abstract: 1. A hard stop for the implementation of rigorous conservation initiatives is
our lack of key species data, especially occurrence data. Furthermore,
researchers have to contend with an accelerated speed at which new information
must be collected and processed due to anthropogenic activity. Publications
ranging from scientific papers to gray literature contain this crucial
information but their data are often not machine-readable, requiring extensive
human work to be retrieved. 2. We present the ARETE R package, an open-source
software aiming to automate data extraction of species occurrences powered by
large language models, namely using the chatGPT Application Programming
Interface. This R package integrates all steps of the data extraction and
validation process, from Optical Character Recognition to detection of outliers
and output in tabular format. Furthermore, we validate ARETE through systematic
comparison between what is modelled and the work of human annotators. 3. We
demonstrate the usefulness of the approach by comparing range maps produced
using GBIF data and with those automatically extracted for 100 species of
spiders. Newly extracted data allowed to expand the known Extent of Occurrence
by a mean three orders of magnitude, revealing new areas where the species were
found in the past, which mayhave important implications for spatial
conservation planning and extinction risk assessments. 4. ARETE allows faster
access to hitherto untapped occurrence data, a potential game changer in
projects requiring such data. Researchers will be able to better prioritize
resources, manually verifying selected species while maintaining automated
extraction for the majority. This workflow also allows predicting available
bibliographic data during project planning.

</details>


### [298] [Complexity as Advantage: A Regret-Based Perspective on Emergent Structure](https://arxiv.org/abs/2511.04590)
*Oshri Naparstek*

Main category: cs.LG

TL;DR: 该论文提出了一个名为“复杂度即优势”（CAA）的框架，用于相对不同观察者来定义系统的复杂度。


<details>
  <summary>Details</summary>
Motivation: 传统的复杂度衡量标准将其视为系统的内在属性，而CAA框架则评估系统对试图对其进行建模的不同观察者产生的预测性懊悔。当一个系统对某些观察者来说容易建模，而对另一些观察者来说却很难时，它就变得复杂，从而产生信息优势。

Method: CAA框架通过量化不同观察者在预测系统行为时的懊悔程度来衡量复杂度。

Result: 研究表明，CAA框架能够统一诸如多尺度熵、预测信息和观察者依赖结构等多种涌现行为的概念。该框架指出，“有趣的”系统是指那些能够跨观察者产生差异化懊悔的系统，从而为复杂度在功能上的价值提供了量化基础。

Conclusion: 该研究通过简单的动力学模型展示了CAA框架的有效性，并探讨了其在学习、进化和人工智能代理等领域的潜在应用和影响。

Abstract: We introduce Complexity as Advantage (CAA), a framework that defines the
complexity of a system relative to a family of observers. Instead of measuring
complexity as an intrinsic property, we evaluate how much predictive regret a
system induces for different observers attempting to model it. A system is
complex when it is easy for some observers and hard for others, creating an
information advantage. We show that this formulation unifies several notions of
emergent behavior, including multiscale entropy, predictive information, and
observer-dependent structure. The framework suggests that "interesting" systems
are those positioned to create differentiated regret across observers,
providing a quantitative grounding for why complexity can be functionally
valuable. We demonstrate the idea through simple dynamical models and discuss
implications for learning, evolution, and artificial agents.

</details>


### [299] [Environment Agnostic Goal-Conditioning, A Study of Reward-Free Autonomous Learning](https://arxiv.org/abs/2511.04598)
*Hampus Åström,Elin Anna Topp,Jacek Malec*

Main category: cs.LG

TL;DR: 将常规强化学习环境转化为目标条件环境，使智能体能够自主、无奖励地学习解决任务。


<details>
  <summary>Details</summary>
Motivation: 研究如何通过将常规强化学习环境转化为目标条件环境，使智能体能够自主、无奖励地学习解决任务。

Method: 智能体通过以与环境无关的方式选择自己的目标来学习解决任务，训练时间与外部引导的强化学习相当。该方法独立于底层 off-policy 学习算法。

Result: 虽然个体目标性能不稳定，但实验表明平均目标成功率有所提高并趋于稳定。

Conclusion: 所提出的方法能够实现通用智能体训练，使其能够在特定用例之前进行训练，并能够指示智能体寻求环境中观察到的任何目标。

Abstract: In this paper we study how transforming regular reinforcement learning
environments into goal-conditioned environments can let agents learn to solve
tasks autonomously and reward-free. We show that an agent can learn to solve
tasks by selecting its own goals in an environment-agnostic way, at training
times comparable to externally guided reinforcement learning. Our method is
independent of the underlying off-policy learning algorithm. Since our method
is environment-agnostic, the agent does not value any goals higher than others,
leading to instability in performance for individual goals. However, in our
experiments, we show that the average goal success rate improves and
stabilizes. An agent trained with this method can be instructed to seek any
observations made in the environment, enabling generic training of agents prior
to specific use cases.

</details>


### [300] [Addressing divergent representations from causal interventions on neural networks](https://arxiv.org/abs/2511.04638)
*Satchel Grant,Simon Jerome Han,Alexa Tartaglini,Christopher Potts*

Main category: cs.LG

TL;DR: 因果干预可能导致模型表征的分布外变化，从而影响解释的忠实度。本文提出了区分‘无害’和‘有害’分布外变化的方法，并改进了CL损失函数以减轻有害变化，从而提高可解释性方法的可靠性。


<details>
  <summary>Details</summary>
Motivation: 评估因果干预在模型解释中的有效性，特别是干预是否会引入分布外表征，从而影响解释的准确性。

Method: 1. 经验性地证明了常见的因果干预技术会使内部表征偏离目标模型的自然分布。 2. 理论分析了两种分布外变化：‘无害’（发生在权重零空间或决策边界协方差内）和‘有害’（激活隐藏网络通路并导致行为改变）。 3. 改进了Counterfactual Latent (CL) 损失函数，以正则化干预，使其更接近自然分布，从而减少有害分布外变化的可能性。

Result: 因果干预技术确实会使模型表征偏离自然分布；识别出‘无害’和‘有害’的分布外变化；改进的CL损失函数能减轻有害变化，同时保持干预的可解释性。

Conclusion: 因果干预在模型解释中可能引入分布外表征，需要区分并减轻‘有害’变化，改进的CL损失函数为实现更可靠的可解释性方法提供了一条途径。

Abstract: A common approach to mechanistic interpretability is to causally manipulate
model representations via targeted interventions in order to understand what
those representations encode. Here we ask whether such interventions create
out-of-distribution (divergent) representations, and whether this raises
concerns about how faithful their resulting explanations are to the target
model in its natural state. First, we demonstrate empirically that common
causal intervention techniques often do shift internal representations away
from the natural distribution of the target model. Then, we provide a
theoretical analysis of two classes of such divergences: `harmless' divergences
that occur in the null-space of the weights and from covariance within
behavioral decision boundaries, and `pernicious' divergences that activate
hidden network pathways and cause dormant behavioral changes. Finally, in an
effort to mitigate the pernicious cases, we modify the Counterfactual Latent
(CL) loss from Grant (2025) that regularizes interventions to remain closer to
the natural distributions, reducing the likelihood of harmful divergences while
preserving the interpretive power of interventions. Together, these results
highlight a path towards more reliable interpretability methods.

</details>


### [301] [Efficient probabilistic surrogate modeling techniques for partially-observed large-scale dynamical systems](https://arxiv.org/abs/2511.04641)
*Hans Harder,Abhijeet Vishwasrao,Luca Guastoni,Ricardo Vinuesa,Sebastian Peitz*

Main category: cs.LG

TL;DR: 该论文研究了用于预测由偏微分方程描述的动力学系统（例如纳维-斯托克斯方程）的概率技术，并比较了流匹配范式的各种扩展，以减少采样步骤。


<details>
  <summary>Details</summary>
Motivation: 该论文的动机是研究和比较各种扩展流匹配范式的方法，以实现对由偏微分方程描述的动力学系统的概率预测，重点是减少采样步骤。

Method: 该论文比较了直接蒸馏、渐进蒸馏、对抗性扩散蒸馏、Wasserstein GANs 和流整流等方法，并在具有挑战性的系统上进行了实验，包括直接预测大型 3D 模拟的 2D 切片。

Result: 该论文在具有挑战性的系统上进行了实验，包括直接预测大型 3D 模拟的 2D 切片，为求解器的高效流入生成铺平了道路。

Conclusion: 该研究通过比较不同的流匹配范式扩展，为更有效地预测动力学系统提供了新的见解，并为生成式人工智能在科学计算中的应用开辟了新的途径。

Abstract: This paper is concerned with probabilistic techniques for forecasting
dynamical systems described by partial differential equations (such as, for
example, the Navier-Stokes equations). In particular, it is investigating and
comparing various extensions to the flow matching paradigm that reduce the
number of sampling steps. In this regard, it compares direct distillation,
progressive distillation, adversarial diffusion distillation, Wasserstein GANs
and rectified flows. Moreover, experiments are conducted on a set of
challenging systems. In particular, we also address the challenge of directly
predicting 2D slices of large-scale 3D simulations, paving the way for
efficient inflow generation for solvers.

</details>


### [302] [Optimal Inference Schedules for Masked Diffusion Models](https://arxiv.org/abs/2511.04647)
*Sitan Chen,Kevin Cong,Jerry Li*

Main category: cs.LG

TL;DR: 受限的并行采样导致扩散语言模型的推理成本高昂。本文对MDM的并行采样能力进行了理论分析，并提出了新的界限和采样策略，在某些情况下可以将采样步数减少到O(log n)。


<details>
  <summary>Details</summary>
Motivation: 标准的自回归大语言模型推理速度慢，而扩散语言模型（如MDM）虽然可以并行采样，但其并行能力的理论边界尚不明确，限制了其在实际应用中的效率。

Method: 本文将扩散语言模型中的并行采样问题与单变量函数逼近理论联系起来，推导了真实分布与采样分布之间期望散度的精确表达式，并在此基础上得出了新的上下界限，同时提出了一种基于信息论性质（总相关和对偶总相关）的新采样策略。

Result: 本文提出了精确的理论界限，并证明了在某些情况下，MDM的采样步数可以达到O(log n)，而不会显著降低采样性能。但同时指出，在通用情况下，要达到最优采样策略存在挑战。

Conclusion: 本文对扩散语言模型的并行采样能力进行了深入的理论分析，取得了理论和实践上的重要进展。研究结果表明，通过合理的设计和利用信息论性质，可以显著提高扩散语言模型的推理效率。

Abstract: A major bottleneck of standard auto-regressive large language models is that
their inference process is inherently sequential, resulting in very long and
costly inference times. To circumvent this, practitioners proposed a class of
language models called diffusion language models, of which the masked diffusion
model (MDM) is the most successful. The MDM is able to sample tokens
out-of-order and, ostensibly, many tokens at once and in parallel. However,
there is very limited rigorous understanding of how much parallel sampling
these models can perform without noticeable degradation in their sampling
performance. Prior work of Li and Cai obtained some preliminary bounds, but
these are not tight for many natural classes of distributions. In this work, we
give a new, exact characterization of the expected divergence between the true
distribution and the sampled distribution, for any distribution and any
unmasking schedule for the sampler, showing an elegant connection to the theory
of univariate function approximation.
  By leveraging this connection, we then attain a number of novel lower and
upper bounds for this problem. While the connection to function approximation
in principle gives the optimal unmasking schedule for any distribution, we show
that it is in general impossible to compete with it without strong a priori
knowledge of the distribution, even in seemingly benign settings. However, we
also demonstrate new upper bounds and new sampling schedules in terms of
well-studied information-theoretic properties of the base distribution, namely,
its total correlation and dual total correlation, which show that in some
natural settings, one can sample in $O(log n)$ steps without any visible loss
in performance, where $n$ is the total sequence length.

</details>


### [303] [TT-Prune: Joint Model Pruning and Resource Allocation for Communication-efficient Time-triggered Federated Learning](https://arxiv.org/abs/2511.04653)
*Xinlu Zhang,Yansha Deng,Toktam Mahmoodi*

Main category: cs.LG

TL;DR: TT-Fed 通过自适应模型剪枝和联合优化剪枝率及带宽分配来解决无线通信中的 FL 延迟和通信开销问题。


<details>
  <summary>Details</summary>
Motivation: 现有的 FL 网络用户设备数量不断增长，无线带宽有限，导致掉队者和通信开销问题加剧。

Method: 提出自适应模型剪枝，并联合优化剪枝率和带宽分配，以最小化训练损失并确保最小学习延迟。对 TT-Fed 模型梯度 L2 范数进行收敛性分析，并利用 KKT 条件推导出无线带宽和剪枝率的闭式解。

Result: 模型剪枝可将通信成本降低 40%，同时保持模型性能不变。

Conclusion: 所提出的方法能够有效解决 TT-Fed 系统中的延迟和通信开销问题，并在模型性能和效率之间取得良好平衡。

Abstract: Federated learning (FL) offers new opportunities in machine learning,
particularly in addressing data privacy concerns. In contrast to conventional
event-based federated learning, time-triggered federated learning (TT-Fed), as
a general form of both asynchronous and synchronous FL, clusters users into
different tiers based on fixed time intervals. However, the FL network consists
of a growing number of user devices with limited wireless bandwidth,
consequently magnifying issues such as stragglers and communication overhead.
In this paper, we introduce adaptive model pruning to wireless TT-Fed systems
and study the problem of jointly optimizing the pruning ratio and bandwidth
allocation to minimize the training loss while ensuring minimal learning
latency. To answer this question, we perform convergence analysis on the
gradient l_2 norm of the TT-Fed model based on model pruning. Based on the
obtained convergence upper bound, a joint optimization problem of pruning ratio
and wireless bandwidth is formulated to minimize the model training loss under
a given delay threshold. Then, we derive closed-form solutions for wireless
bandwidth and pruning ratio using Karush-Kuhn-Tucker(KKT) conditions. The
simulation results show that model pruning could reduce the communication cost
by 40% while maintaining the model performance at the same level.

</details>


### [304] [Nowcast3D: Reliable precipitation nowcasting via gray-box learning](https://arxiv.org/abs/2511.04659)
*Huaguan Chen,Wei Han,Haofei Sun,Ning Lin,Xingtao Song,Yunfan Yang,Jie Tian,Yang Liu,Ji-Rong Wen,Xiaoye Zhang,Xueshun Shen,Hao Sun*

Main category: cs.LG

TL;DR: 该研究提出了一个创新的三维雷达外推模型，能够提高极端降水预报的准确性和时效性。


<details>
  <summary>Details</summary>
Motivation: 现有的极端降水临近预报方法在时空精度和预报时效性方面存在局限。数值天气预报（NWP）及其深度学习模型速度慢、精度低，外推和纯数据驱动模型存在误差累积和平滑化问题，而二维雷达方法则忽略了关键的垂直信息。

Method: 该研究提出了一种三维临近预报框架，结合了物理约束的神经网络算子和数据驱动学习。该模型能够学习垂直变化的3D平流场，并引入了考虑未解析运动的随机项，同时利用残差分支捕捉小尺度对流和微物理变异性，并通过基于扩散的随机模块来估计不确定性。

Result: 该框架在长达三小时的预报时效性上取得了更准确的预报，并且在盲测评估中，有57%的情况下排名第一，得到了气象学家的认可。

Conclusion: 通过恢复具有物理一致性的全三维动力学，该框架为实现高技巧和高可靠性的极端降水临近预报提供了一个可扩展且鲁棒的途径。

Abstract: Extreme precipitation nowcasting demands high spatiotemporal fidelity and
extended lead times, yet existing approaches remain limited. Numerical Weather
Prediction (NWP) and its deep-learning emulations are too slow and coarse for
rapidly evolving convection, while extrapolation and purely data-driven models
suffer from error accumulation and excessive smoothing. Hybrid 2D radar-based
methods discard crucial vertical information, preventing accurate
reconstruction of height-dependent dynamics. We introduce a gray-box, fully
three-dimensional nowcasting framework that directly processes volumetric radar
reflectivity and couples physically constrained neural operators with
datadriven learning. The model learns vertically varying 3D advection fields
under a conservative advection operator, parameterizes spatially varying
diffusion, and introduces a Brownian-motion--inspired stochastic term to
represent unresolved motions. A residual branch captures small-scale convective
initiation and microphysical variability, while a diffusion-based stochastic
module estimates uncertainty. The framework achieves more accurate forecasts up
to three-hour lead time across precipitation regimes and ranked first in 57\%
of cases in a blind evaluation by 160 meteorologists. By restoring full 3D
dynamics with physical consistency, it offers a scalable and robust pathway for
skillful and reliable nowcasting of extreme precipitation.

</details>


### [305] [Forgetting is Everywhere](https://arxiv.org/abs/2511.04666)
*Ben Sanati,Thomas L. Lee,Trevor McInroe,Aidan Scannell,Nikolay Malkin,David Abel,Amos Storkey*

Main category: cs.LG

TL;DR: 该理论提出了一种新的算法和任务无关的理论，将遗忘定义为学习者预测分布中缺乏自我一致性，从而导致预测信息丢失。该理论提供了一个通用的遗忘度量，并在一系列实验中得到验证，证明遗忘在所有学习场景中都普遍存在并影响学习效率。


<details>
  <summary>Details</summary>
Motivation: 机器学习算法在适应新数据时容易遗忘过去知识，但目前缺乏统一的遗忘理论来指导理解和改进。

Method: 提出了一种算法和任务无关的理论，将遗忘定义为学习者预测分布中缺乏自我一致性，从而导致预测信息丢失。基于此理论，提出了一种衡量算法遗忘倾向的通用度量方法。

Result: 在一系列跨越分类、回归、生成模型和强化学习的实验中，经验性地证明了遗忘在所有学习场景中都普遍存在，并且在决定学习效率方面起着重要作用。

Conclusion: 该研究为理解和量化机器学习中的遗忘问题奠定了基础，提供了一个原则性的框架来分析和提高通用学习算法的信息保留能力。

Abstract: A fundamental challenge in developing general learning algorithms is their
tendency to forget past knowledge when adapting to new data. Addressing this
problem requires a principled understanding of forgetting; yet, despite decades
of study, no unified definition has emerged that provides insights into the
underlying dynamics of learning. We propose an algorithm- and task-agnostic
theory that characterises forgetting as a lack of self-consistency in a
learner's predictive distribution over future experiences, manifesting as a
loss of predictive information. Our theory naturally yields a general measure
of an algorithm's propensity to forget. To validate the theory, we design a
comprehensive set of experiments that span classification, regression,
generative modelling, and reinforcement learning. We empirically demonstrate
how forgetting is present across all learning settings and plays a significant
role in determining learning efficiency. Together, these results establish a
principled understanding of forgetting and lay the foundation for analysing and
improving the information retention capabilities of general learning
algorithms.

</details>


### [306] [Multi-Method Analysis of Mathematics Placement Assessments: Classical, Machine Learning, and Clustering Approaches](https://arxiv.org/abs/2511.04667)
*Julian D. Allagan,Dasia A. Singleton,Shanae N. Perry,Gabrielle C. Morgan,Essence A. Morgan*

Main category: cs.LG

TL;DR: 本研究使用经典测试理论、机器学习和无监督聚类相结合的多方法框架，评估了一个包含40个题目的数学分班考试。结果显示，55%的题目区分度良好，但30%的题目区分度差，需要替换。问题6（图表解读）是最有力的区分题。机器学习算法表现出色，随机森林和梯度提升的交叉验证准确率分别达到97.5%和96.0%。K-means聚类识别出自然的二元能力结构，其分界点为42.5%，与机构设定的55%阈值不同，可能导致过度划分到补习类别。多方法整合为数学分班优化提供了坚实的经验基础。


<details>
  <summary>Details</summary>
Motivation: 对一个包含40个题目的数学分班考试进行评估，旨在优化其区分度和准确性，并为改进分班流程提供循证依据。

Method: 采用经典测试理论（CTT）、机器学习（包括随机森林和梯度提升）以及无监督聚类（K-means）相结合的多方法框架对数学分班考试进行分析。

Result: CTT分析显示55%的题目区分度良好，30%的题目区分度差。问题6区分度最高。随机森林和梯度提升模型的交叉验证准确率分别为97.5%和96.0%。K-means聚类发现了一个自然二元能力结构（分界点42.5%），与机构的55%阈值存在差异。两簇解具有高度稳定性。

Conclusion: 多方法整合分析为数学分班考试的优化提供了可靠的经验基础，建议替换区分度差的题目、实施两阶段评估以及结合随机森林预测和透明度机制。

Abstract: This study evaluates a 40-item mathematics placement examination administered
to 198 students using a multi-method framework combining Classical Test Theory,
machine learning, and unsupervised clustering. Classical Test Theory analysis
reveals that 55\% of items achieve excellent discrimination ($D \geq 0.40$)
while 30\% demonstrate poor discrimination ($D < 0.20$) requiring replacement.
Question 6 (Graph Interpretation) emerges as the examination's most powerful
discriminator, achieving perfect discrimination ($D = 1.000$), highest ANOVA
F-statistic ($F = 4609.1$), and maximum Random Forest feature importance
(0.206), accounting for 20.6\% of predictive power. Machine learning algorithms
demonstrate exceptional performance, with Random Forest and Gradient Boosting
achieving 97.5\% and 96.0\% cross-validation accuracy. K-means clustering
identifies a natural binary competency structure with a boundary at 42.5\%,
diverging from the institutional threshold of 55\% and suggesting potential
overclassification into remedial categories. The two-cluster solution exhibits
exceptional stability (bootstrap ARI = 0.855) with perfect lower-cluster
purity. Convergent evidence across methods supports specific refinements:
replace poorly discriminating items, implement a two-stage assessment, and
integrate Random Forest predictions with transparency mechanisms. These
findings demonstrate that multi-method integration provides a robust empirical
foundation for evidence-based mathematics placement optimization.

</details>


<div id='cond-mat.mes-hall'></div>

# cond-mat.mes-hall [[Back]](#toc)

### [307] [Dynamics of Josephson junctions beyond the tunneling limit](https://arxiv.org/abs/2511.03811)
*Jacob F. Steiner,Larissa Melischek,Felix von Oppen*

Main category: cond-mat.mes-hall

TL;DR: 本文推导了一个广义的RCSJ模型，该模型考虑了具有非线性I-V特性的耗散电流和任意电流-相位关系的超导电流，克服了传统RCSJ模型在隧穿极限下的局限性，并为约瑟夫森二极管效应等新现象提供了理论基础。


<details>
  <summary>Details</summary>
Motivation: 本文的动机在于，传统的RCSJ模型在隧穿极限下无法描述约瑟夫森二极管效应等新兴现象，而这些现象依赖于非线性的耗散电流和任意电流-相位关系的超导电流。

Method: 本文采用了一种广义的涨落耗散定理，并借鉴了关于介观导体涨落定理的思想，来推导一个广义的RCSJ模型。该模型能够描述具有非线性I-V特性的耗散电流和任意电流-相位关系的超导电流。

Result: 本文成功推导了一个广义的RCSJ模型，该模型能够处理非线性的耗散电流和任意电流-相位关系的超导电流，这超越了传统RCSJ模型在隧穿极限下的适用范围。

Conclusion: 本文提出的广义RCSJ模型为理解和描述更广泛的约瑟夫森结动力学行为，特别是那些涉及非线性耗散和任意超导电流-相位关系的现象（如约瑟夫森二极管效应），提供了一个更完善的理论框架。

Abstract: The dynamics of the superconducting phase difference across a Josephson
junction can be described within the resistively and capacitively shunted
Josephson junction (RCSJ) model. Microscopic derivations of this model
traditionally rely on the tunneling limit. Here, we present a derivation of a
generalized version of the RCSJ model, which accounts for dissipative currents
with nonlinear current-voltage characteristics as well as supercurrents with
arbitrary current-phase relations. This requires a generalized
fluctuation-dissipation theorem to describe the Langevin current, which we
deduce along the lines of fluctuation theorems for mesoscopic conductors. Our
work is motivated in particular by recent theories of the Josephson diode
effect, which is not captured within the RCSJ model in the tunneling limit.

</details>


### [308] [Unconventional quantization of 2D plasmons in cavities formed by gate slots](https://arxiv.org/abs/2511.03829)
*Ilia Moiseenko,Olga Polischuk,Viacheslav Muravev,Dmitry Svintsov*

Main category: cond-mat.mes-hall

TL;DR: 金属栅极之间的间隙可以形成非传统的等离激元谐振腔，其模式量化条件为 L = λ/8 + n × λ/2，最低共振发生在约八分之一波长处，这与光学中的半波长腔不同，原因是 2D 等离激元在反射时会获得 -π/4 的非平庸相位移动。


<details>
  <summary>Details</summary>
Motivation: 研究在二维电子系统中，平行金属栅极之间的间隙如何形成等离激元谐振腔，并探索其独特的模式量化现象。

Method: 通过理论分析和计算，推导了等离激元模式的量化条件，并研究了模式衰减和吸收截面。

Result: 发现在约八分之一波长处存在最低共振，且模式衰减与栅极到 2DES 的距离成正比，吸收截面可达偶极子极限的 50%。

Conclusion: 二维电子系统中栅极间隙形成的等离激元谐振腔具有独特的量化规则和优异的吸收特性。

Abstract: We demonstrate that the slot between parallel metal gates placed above
two-dimensional electron system (2DES) forms a plasmonic cavity with
unconventional mode quantization. The resonant plasmon modes are excited when
the slot width $L$ and the plasmon wavelength $\lambda$ satisfy the condition
$L = \lambda/8 +n \times \lambda/2$, where $n=0, 1, 2 \ldots$. The lowest
resonance occurs at a surprisingly small cavity size, specifically one eighth
of the plasmon wavelength, which contrasts with the conventional
half-wavelength Fabry-Perot cavities in optics. This unique quantization rule
arises from a non-trivial phase shift of $-\pi/4$ acquired by the 2D plasmon
upon reflection from the edge of the gate. The slot plasmon modes exhibit weak
decay into the gated 2DES region, with the decay rate being proportional to the
square root of the separation between the gate and the 2DES. Absorption
cross-section by such slots reaches $\sim 50$ % of the fundamental dipole limit
without any matching strategies, and is facilitated by field enhancement at the
metal edges.

</details>


### [309] [Modeling Memristor-Based Neural Networks with Manhattan Update: Trade-offs in Learning Performance and Energy Consumption](https://arxiv.org/abs/2511.03858)
*Walter Quiñonez,María José Sánchez,Diego Rubi*

Main category: cond-mat.mes-hall

TL;DR: 本文研究了基于忆阻器的神经网络，重点关注学习性能和能耗之间的权衡。


<details>
  <summary>Details</summary>
Motivation: 研究了硬件友好的曼哈顿更新规则在忆阻器神经网络中的应用，以及非线性、电导范围和可访问级别数量对学习性能和能耗的影响。

Method: 使用单感知器和在MNIST数据集上训练的深度神经网络，评估了P/D曲线的非线性、电导范围和可访问级别数量的影响。

Result: 单感知器可容忍高达0.01的P/D非线性，而深度神经网络需要0.001的非线性才能保持准确性。增加离散电导状态的数量可以改善收敛性。提出了一种固定每个差分对的一个忆阻器的方法，将DNN的训练能耗降低了近50%，而准确性几乎没有损失。

Conclusion: 设备-算法协同设计对于实现可扩展、低功耗的边缘人工智能的神经形态硬件至关重要。

Abstract: We present a systematic study of memristor based neural networks trained with
the hardware-friendly Manhattan update rule, focusing on the trade offs between
learning performance and energy consumption. Using realistic models of
potentiation/depression (P/D) curves, we evaluate the impact of nonlinearity
(NLI), conductance range, and number of accessible levels on both a single
perceptron (SP) and a deep neural network (DNN) trained on the MNIST dataset.
Our results show that SPs tolerate P/D nonlinearity up to NLI $\leq 0.01$,
while DNNs require stricter conditions of NLI $\leq$ 0.001 to preserve
accuracy. Increasing the number of discrete conductance states improves
convergence, effectively acting as a finer learning rate. We further propose a
strategy where one memristor of each differential pair is fixed, reducing
redundant memristor conductance updates. This approach lowers training energy
by nearly 50% in DNN with little to no loss in accuracy. Our findings highlight
the importance of device algorithm codesign in enabling scalable, low power
neuromorphic hardware for edge AI applications.

</details>


### [310] [Measuring non-Abelian quantum geometry and topology in a multi-gap photonic lattice](https://arxiv.org/abs/2511.03894)
*Martin Guillot,Cédric Blanchard,Martina Morassi,Aristide Lemaître,Luc Le Gratiet,Abdelmounaim Harouri,Isabelle Sagnes,Robert-Jan Slager,F. Nur Ünal,Jacqueline Bloch,Sylvain Ravets*

Main category: cond-mat.mes-hall

TL;DR: 该研究首次直接测量了非阿贝尔量子几何张量，为探索多能带系统中的拓扑、几何和非阿贝尔物理学现象开辟了新途径。


<details>
  <summary>Details</summary>
Motivation: 半金属多能隙系统中带节点非阿贝尔编织特性的出现引起了极大的兴趣，但缺乏实验探测方法。

Method: 提出了一种新颖的轨道分辨偏振技术，用于测量六带二维合成晶格的布洛赫哈密顿量，从而实现非阿贝尔量子几何张量的直接测量。

Result: 成功测量了非阿贝尔四元数电荷、欧拉曲率和所有能带的非阿贝尔量子度量。

Conclusion: 该研究首次实现了非阿贝尔量子几何张量的直接测量，为实验探索多能隙系统中的拓扑、几何和非阿贝尔物理学现象提供了新方法。

Abstract: Recent discoveries in semi-metallic multi-gap systems featuring band
singularities have galvanized enormous interest in particular due to the
emergence of non-Abelian braiding properties of band nodes. This previously
uncharted set of topological phases necessitates novel approaches to probe them
in laboratories, a pursuit that intricately relates to evaluating non-Abelian
generalizations of the Abelian quantum geometric tensor (QGT) that
characterizes geometric responses. Here, we pioneer the direct measurement of
the non-Abelian QGT. We achieve this by implementing a novel orbital-resolved
polarimetry technique to probe the full Bloch Hamiltonian of a six-band
two-dimensional (2D) synthetic lattice, which grants direct experimental access
to non-Abelian quaternion charges, the Euler curvature, and the non-Abelian
quantum metric associated with all bands. Quantum geometry has been highlighted
to play a key role on macroscopic phenomena ranging from superconductivity in
flat-bands, to optical responses, transport, metrology, and quantum Hall
physics. Therefore, our work unlocks the experimental probing of a wide
phenomenology of multi-gap systems, at the confluence of topology, geometry and
non-Abelian physics.

</details>


### [311] [Description of the orbital Hall effect from orbital magnetic moments of Bloch states: the role of a new correction term in bilayer systems](https://arxiv.org/abs/2511.03901)
*Tarik P. Cysne,Ivo Souza,Tatiana G. Rappoport*

Main category: cond-mat.mes-hall

TL;DR: 本文推导了布洛赫态轨道磁矩（OMM）的矩阵元，包括了之前工作中忽略的Berry连接项，并提出了适用于任何非简并布洛赫态的OMM矩阵元公式。


<details>
  <summary>Details</summary>
Motivation: 推导包含Berry连接项的布洛赫态轨道磁矩（OMM）矩阵元，以修正先前工作中的不足，并研究其在轨道霍尔效应中的应用。

Method: 通过包含Berry连接项的k-导数，严格推导出OMM矩阵元的精确表达式，并将其应用于2H过渡金属二硫属化物双层和有偏双层石墨烯体系，分析其对轨道霍尔电导率的影响。

Result: 新的OMM矩阵元包含两个新贡献：一个恢复了非简并态的规范协变性，另一个则提供了显著的量化修正。在所研究的双层体系中，这些新项均减小了轨道霍尔电导率的平台值。

Conclusion: 本文提出的OMM矩阵元计算方法是精确的，并且对于理解和发展电子OMM输运以及轨道电子学具有重要意义。

Abstract: We present a rigorous derivation of the matrix elements of the orbital
magnetic moment (OMM) of Bloch states. Our calculations include the Berry
connection term in the k-derivatives of Bloch states, which was omitted in
previous works. The resulting formula for the OMM matrix elements applies to
any non-degenerate Bloch states within Hilbert space. We identify two new
contributions: the first restores gauge covariance for non-degenerate states,
while the second, being itself gauge covariant, can provide significant
quantitative corrections depending on the system under study. We examine their
impact on the orbital Hall effect in two bilayer systems: a 2H transition metal
dichalcogenide bilayer and a biased bilayer graphene. In both cases, these new
terms reduce the orbital Hall conductivity plateau compared with results that
neglect them, suggesting that multi-layered van der Waals materials may be
particularly susceptible to the derived OMM corrections. Our findings may
contribute to the formal understanding of electronic OMM transport and to the
conceptual foundations of the emerging field of orbitronics.

</details>


### [312] [Thermal hot-carrier breakdown in metasurface structures based on coplanar arrays of graphene microribbons connected with wide-gap bridges](https://arxiv.org/abs/2511.03975)
*V. Ryzhii,M. Ryzhii,M. S. Shur,T. Otsuji,C. Tang*

Main category: cond-mat.mes-hall

TL;DR: 基于石墨烯微带线（GMR）的超表面具有正反馈机制，可实现快速开关和热源应用。


<details>
  <summary>Details</summary>
Motivation: 研究由石墨烯微带线（GMR）和纳米桥（NBs）组成的超表面的热电特性，特别是它们在自热效应下产生的正反馈机制及其潜在应用。

Method: 分析了由石墨烯微带线（GMR）和纳米桥（NBs）组成的超表面的热电特性。通过在相邻GMR之间施加偏置电压，在GMR中产生电子和空穴二维系统，并诱导流经NBs的电流。研究了自热效应如何增加热电子流，从而在载流子有效温度和注入电流之间产生正反馈。

Result: 发现了自热效应可以增强热电子流，从而在载流子有效温度和注入电流之间产生正反馈。这种机制可能导致热击穿，从而实现具有S形特性的阈值电流-电压特性。基于GMR/GNR、GMR/CNT和GMR/AsP超表面结构的器件可以作为电压控制的电流开关、传感器、太赫兹和红外热源等。

Conclusion: 基于石墨烯微带线（GMR）和纳米桥（NBs）组成的超表面，通过利用自热效应产生的正反馈机制，可以实现具有阈值行为的电流-电压特性，并可用于开发快速开关、传感器和热源等器件。

Abstract: We analyze the thermal and electrical characteristics of the metasurface
consisting of
  the coplanar interdigital array of the graphene microribbons (GMRs) connected
by nanobridges (NBs). These nanobridges could be implemented using graphene
nanoribbons (GNRs), single-wall semiconducting carbon nanotubes (CNTs), or
black-arsenic-phosphorus (b-AsP) nanostructures. The bias voltage applied
between neighboring GMRs indices electron and hole two-dimensional systems in
the GMRs and induces thermionic currents flowing through connecting NBs. The
resulting self-heating increases thermionic currents providing an effective
positive feadback between the carrier effective temperature and the injected
currents. This mechanism may lead to thermal breakdown enabling threshold
behavior of current-voltage characteristics and resulting in the S-shape of
these characteristics. The devices based on the GMR/GNR, GMR/CNT, and GMR/AsP
metasurface structures can be used as fast voltage-controlled current switches,
sensors, thermal terahertz and infrared sources, and other devices.

</details>


### [313] [Polariton XY-simulators revisited](https://arxiv.org/abs/2511.04223)
*Junhui Cao,Denis Novokreschenov,Alexey Kavokin*

Main category: cond-mat.mes-hall

TL;DR: 研究了激子-极化激物体阵列模拟经典XY模型


<details>
  <summary>Details</summary>
Motivation: 研究激子-极化激物体阵列模拟XY模型的有效性、收敛时间和系统规模关系

Method: 提出解析模型，分析了不同泵浦功率下系统的行为，并研究了相干锁定状态的形成速率

Result: 发现系统存在N个稳定的相位构型，并根据泵浦功率选择性地放大特定构型；在低功率下倾向于最小本征值对应的状态，在高功率下倾向于最大本征值对应的状态；在中等功率下系统会遍历所有哈密顿量本征态。相干锁定状态的形成速率与系统规模无关，约为100 ps。

Conclusion: 激子-极化激物体阵列作为XY模拟器具有极快的速度和良好的可扩展性，其形成速率不受系统规模影响。

Abstract: Arrays of bosonic condensates of exciton-polaritons have emerged as a
promising platform for simulating classical XY models, capable of rapidly
reaching phase-locked states that may be mapped to arrays of two-dimensional
classical spins. However, it remains unclear whether these states genuinely
minimize the corresponding XY Hamiltonian and how the convergence time scales
with the system size. Here, we develop an analytical model revealing that an
array of $N$ condensates possesses $N$ stable phase configurations. The system
selectively amplifies a specific configuration dependent on the pump power: at
low power, the state with the smallest eigenvalue of an effective XY
Hamiltonian is favored, while at high power, the state with the largest
eigenvalue prevails. At intermediate pump powers, the system visits all
eigenstates of the Hamiltonian. Crucially, the formation rate for any of these
phase-locked states remains on the order of 100 ps, independent of the size of
the array, demonstrating the exceptional speed and scalability of
polariton-based XY simulators.

</details>


### [314] [Revealing the impact of ambient molecular contamination on scanning tunneling microscopy and spectroscopy of layered materials](https://arxiv.org/abs/2511.04257)
*György Kálvin,Péter Vancsó,Márton Szendrő,Konrád Kandrai,András Pálinkás,Levente Tapasztó,Péter Nemes-Incze*

Main category: cond-mat.mes-hall

TL;DR: 表面烷烃污染层会影响石墨的STM测量，抑制费米能隙，并改变电流-距离关系，但可以通过I(z)特性检测。


<details>
  <summary>Details</summary>
Motivation: 研究表面烷烃污染物对范德华材料表面性质的影响，特别是对扫描隧道显微镜（STM）和光谱学测量的影响，以解决长期存在的测量不一致问题。

Method: 通过比较清洁和受烷烃污染的石墨表面，研究烷烃层对STM和光谱学测量的影响，并分析电流-距离（I(z)）特性。

Result: 研究发现，烷烃层抑制了近费米能的声子诱导的能隙，并使电流-距离（I(z)）特性的指数衰减展宽了1.5到5倍。

Conclusion: 表面烷烃层会抑制石墨的STM测量结果中的声子诱导能隙，并改变电流-距离特性。通过分析I(z)特性，可以检测STM测量中是否存在表面污染。

Abstract: Hydrocarbon contamination is an ever-present factor to consider in surface
science measurements. In the case of van der Waals material surfaces, the
structure of this contamination has become known in recent years as a
self-assembled layer of normal-alkanes, resulting from a few days' exposure to
ambient air. Knowledge of its composition and structure enables systematic
investigation of its influence on surface properties. Here, we investigate the
effect of this contamination on scanning tunneling microscopy (STM) and
spectroscopy measurements by comparing clean and ambient alkane-contaminated
surfaces of graphite. Our results reveal that the ambient alkane layer
suppresses the well-known phonon-induced gap near the Fermi energy, resolving a
long-standing inconsistency in STM studies, where this feature is often absent.
Furthermore, we show that the presence of the contamination layer alters the
current-distance ($I(z)$) characteristics, flattening its exponential decay by
a factor of 1.5 to 5 compared to the clean surface. This change arises from
extra conductance channels through the alkane layer alongside the tunnel
junction, as the tip penetrates the contaminant overlayer. Finally, based on
the $I(z)$ characteristics, we provide a practical guide to detect the presence
of surface contamination in STM measurements.

</details>


### [315] [High luminescence efficiency of multi-valley excitonic complexes in heavily doped WSe2 monolayer](https://arxiv.org/abs/2511.04306)
*Sébastien Roux,Tilly Guyot,Abraao Cefas Torres-Dias,Delphine Lagarde,Laurent Lombez,Dinh Van Tuan,Junghwan Kim,Kenji Watanabe,Xavier Marie,Takashi Taniguchi,Hanan Dery,Cedric Robert*

Main category: cond-mat.mes-hall

TL;DR: WSe$_2$单分子层中的多粒子激子复合物可以产生比中性状态强两个数量级的信号，量子产率随载流子密度升高而增加，超过50%，这表明TMD单分子层是探索高密度电子气体中激子复合物的平台，并为高效、原子层薄的发光器件开辟了新途径。


<details>
  <summary>Details</summary>
Motivation: 研究WSe$_2$单分子层中的多粒子激子复合物，探索在高载流子密度下提高光致发光量子产率的可能性。

Method: 通过时间分辨光致发光和差分反射测量，研究了WSe$_2$单分子层在重n型掺杂下的性质，并测量了不同载流子密度下的光致发光信号强度和量子产率。

Result: 在重n型掺杂的WSe$_2$单分子层中，观察到了比中性状态强两个数量级的光致发光信号。量子产率随电子浓度的升高而增加，当电子浓度超过10$^{13}$ cm$^{-2}$时，量子产率超过50%。

Conclusion: TMD单分子层可以作为研究高密度电子气体中激子复合物的平台，并且通过调控载流子密度，可以实现高效的原子层薄发光器件。

Abstract: Monolayers of group-VI transition-metal dichalcogenides (TMDs) are
two-dimensional semiconductors that exhibit exceptionally strong light-matter
coupling yet typically suffer from low emission quantum yields. In this letter,
we investigate the heavily n-doped regime of a WSe$_2$ monolayer and show that
multi-particle excitonic complexes produce photoluminescence signals up to two
orders of magnitude stronger than in the neutral state. Time-resolved
photoluminescence and differential reflectivity measurements reveal that the
quantum yield rises with carrier density and exceeds 50% for electron
concentrations above 10$^{13}$ cm$^{-2}$. These findings establish TMD
monolayers as a platform for exploring excitonic complexes in high-density
electron gases and point toward new opportunities for efficient, atomically
thin light emitters.

</details>


### [316] [Many-body interferometry with semiconductor spins](https://arxiv.org/abs/2511.04310)
*Daniel Jirovec,Stefano Reale,Pablo Cova-Fariña,Christian Ventura-Meinersen,Minh T. P. Nguyen,Xin Zhang,Stefan D. Oosterhout,Giordano Scappucci,Menno Veldhorst,Maximilian Rimbach-Russ,Stefano Bosco,Lieven M. K. Vandersypen*

Main category: cond-mat.mes-hall

TL;DR: 利用基于半导体量子点的自旋系统，通过结合Ramsey干涉和绝热映射技术，实现了对多达八个相互作用自旋的谱分析，并观察到了从局域化到混沌相的转变，为在量子点系统中研究多体现象奠定了基础。


<details>
  <summary>Details</summary>
Motivation: 现有量子模拟器在处理经典硬件难以解决的多体现象方面具有潜力。基于半导体量子点的自旋设备在精确电学控制和可扩展性方面具有优势，但受限于纳米加工和多重相互作用的同时控制，难以实现多体现象的研究。

Method: 利用2x4的门定义锗量子点阵列，通过基于Ramsey干涉和绝热映射多体本征态到单自旋本征态的谱学协议，对多达八个相互作用自旋进行了谱分析，以重建完整的能量谱。

Result: 观察到了当相互作用强度超过磁无序时，系统从局域化相向混沌相的转变。

Conclusion: 该研究通过精确控制和谱分析技术，在量子点系统中朝着观察多体现象迈出了重要一步。

Abstract: Quantum simulators enable studies of many-body phenomena which are
intractable with classical hardware. Spins in devices based on semiconductor
quantum dots promise precise electrical control and scalability advantages, but
accessing many-body phenomena has so far been restricted by challenges in
nanofabrication and simultaneous control of multiple interactions. Here, we
perform spectroscopy of up to eight interacting spins using a 2x4 array of
gate-defined germanium quantum dots. The spectroscopy protocol is based on
Ramsey interferometry and adiabatic mapping of many-body eigenstates to
single-spin eigenstates, enabling a complete energy spectrum reconstruction. As
the interaction strength exceeds magnetic disorder, we observe signatures of
the crossover from localization to a chaotic phase marking a step towards the
observation of many-body phenomena in quantum dot systems.

</details>


### [317] [Quantum dot thermal machines - a guide to engineering](https://arxiv.org/abs/2511.04324)
*Eugenia Pyurbeeva,Ronnie Kosloff*

Main category: cond-mat.mes-hall

TL;DR: 文章介绍了量子点热机的研究，重点关注其在实际应用中的性能优化，如最大功率、最大功率下的效率和噪声等，并提出可以通过调控量子点内部微观动力学参数来提升其性能。


<details>
  <summary>Details</summary>
Motivation: 连续粒子交换热力机的研究对于固态电子设备和纳米尺度应用具有重要意义，但现有研究多侧重于卡诺效率，而忽略了实际应用中更重要的参数，如最大功率、最大功率下的效率和噪声。

Method: 文章通过分析量子点内部微观动力学对其作为热力机性能的影响，提出可以通过调控量子点内部的几个关键参数（整体电导和三个内在不对称性）来优化其性能。

Result: 研究表明，量子点热机的性能不仅取决于整体电导，还与其内部动力学的三个内在不对称性有关，这些参数可以作为工程化量子点内部量子态以优化其性能的指导。

Conclusion: 通过调控量子点内部微观动力学参数，可以优化量子点热机的性能，使其在实际应用中表现更优，超越简单的双重自旋简并传输能级的情况。

Abstract: Continuous particle exchange thermal machines require no time-dependent
driving, can be realised in solid-state electronic devices, and miniaturised to
nanometre scale. Quantum dots, providing a narrow energy filter and allowing to
manipulate particle flow between the hot and cold reservoirs are at the heart
of such devices. It has been theoretically shown that by mitigating passive
heat flow, Carnot efficiency can be approached arbitrarily closely in a quantum
dot heat engine, and experimentally, values of 0.7{\eta}C have been reached.
However, for practical applications, other parameters of a thermal machine,
such as maximum power, efficiency at maximum power, and noise - stability of
the power output or heat extraction - take precedence over maximising
efficiency. We explore the effect of internal microscopic dynamics of a quantum
dot on these quantities and demonstrate that its performance as a thermal
machine depends on few parameters - the overall conductance and three inherent
asymmetries of the dynamics. These parameters will act as a guide to
engineering the quantum states of the quantum dot, allowing to optimise its
performance beyond that of the simplest case of a two-fold spin-degenerate
transmission level.

</details>


### [318] [Automatic tuning of a donor in a silicon quantum device using machine learning](https://arxiv.org/abs/2511.04543)
*Brandon Severin,Tim Botzem,Federico Fedele,Xi Yu,Benjamin Wilhelm,Holly G. Stemp,Irene Fernández de Fuentes,Daniel Schwienbacher,Danielle Holmes,Fay E. Hudson,Andrew S. Dzurak,Alexander M. Jakob,David N. Jamieson,Andrea Morello,Natalia Ares*

Main category: cond-mat.mes-hall

TL;DR: 硅基捐赠者自旋量子比特可实现高保真度和长相干时间，适合大规模量子处理器。本研究提出了一种机器学习算法，可自动定位、调谐电荷读出并识别特定栅电压参数，从而在几分钟内完成器件调谐，速度超过人工操作。


<details>
  <summary>Details</summary>
Motivation: 开发大规模硅基捐赠者自旋量子处理器，并实现器件的自动调谐和操作。

Method: 提出了一种机器学习算法，可自动定位离子注入捐赠者的电荷跃迁，调谐单次电荷读出，并识别捐赠者隧穿率与进出速率相同的栅电压参数。

Result: 在几分钟内完成了整个调谐流程，实现了比人工专家更快地自动表征和调谐硅基捐赠者器件。

Conclusion: 本研究提出的机器学习算法能够快速自动地调谐硅基捐赠者量子比特器件，为大规模量子处理器的开发和部署铺平了道路。

Abstract: Donor spin qubits in silicon offer one- and two-qubit gates with fidelities
beyond 99%, coherence times exceeding 30 seconds, and compatibility with
industrial manufacturing methods. This motivates the development of large-scale
quantum processors using this platform, and the ability to automatically tune
and operate such complex devices. In this work, we present the first machine
learning algorithm with the ability to automatically locate the charge
transitions of an ion-implanted donor in a silicon device, tune single-shot
charge readout, and identify the gate voltage parameters where tunnelling rates
in and out the donor site are the same. The entire tuning pipeline is completed
on the order of minutes. Our results enable both automatic characterisation and
tuning of a donor in silicon devices faster than human experts.

</details>


<div id='quant-ph'></div>

# quant-ph [[Back]](#toc)

### [319] [Boltzmann Sampling of Frustrated J1 - J2 Ising Models with Programmable Quantum Annealers](https://arxiv.org/abs/2511.03796)
*Elijah Pelofske*

Main category: quant-ph

TL;DR: D-Wave量子退火器在采样玻尔兹曼分布方面表现出色，尤其是在模拟具有竞争性磁挫折的ANNNI模型时，实现了高精度和低温采样。


<details>
  <summary>Details</summary>
Motivation: 探究D-Wave量子退火器从经典哈密顿量定义的玻尔兹曼或吉布斯分布进行采样的能力，特别是针对ANNNI模型。

Method: 在标准线性斜坡退火条件下，量化了在两个不同的D-Wave量子退火处理器上，从5纳秒到2000微秒的不同退火时间内，ANNNI模型的玻尔兹曼采样误差率。

Result: 在ANNNI模型的磁相图的挫折区域，发现了一些能够实现极高精度（TVD低至0.0003）和低温采样（β低至32.2）的模拟硬件参数。

Conclusion: 研究结果支持当前模拟量子计算机在高度挫折磁性自旋系统的热力学采样应用方面的可行性。

Abstract: One of the surprising, and potentially very useful, capabilities of analog
quantum computers, such as D-Wave quantum annealers, is sampling from the
Boltzmann, or Gibbs, distribution defined by a classical Hamiltonian. In this
study, we thoroughly examine the ability of D-Wave quantum annealers to sample
from the Boltzmann distribution defined of a canonical type of competing
magnetic frustration $J_1$-$J_2$ model; the ANNNI (axial next-nearest-neighbor
Ising) model. Boltzmann sampling error rate is quantified for standard
linear-ramp anneals ranging from $5$ nanosecond annealing times up to $2000$
microseconds on two different D-Wave quantum annealing processors.
Interestingly, we find some analog hardware parameters which result in a very
high accuracy (down to a TVD of $0.0003$) and low temperature sampling (down to
$\beta=32.2$) in a frustrated region of the ANNNI model magnetic phase diagram.
This bolsters the viability of current analog quantum computers for
thermodynamic sampling applications of highly frustrated magnetic spin systems.

</details>


### [320] [Temporal entanglement transition in chaotic quantum many-body dynamics](https://arxiv.org/abs/2511.03846)
*Ilya Vilkoviskiy,Michael Sonner,Qi Camm Huang,Wen Wei Ho,Alessio Lerose,Dmitry A. Abanin*

Main category: quant-ph

TL;DR: 量子系统的复杂性可以通过影响矩阵（IM）的时间纠缠（TE）来衡量。研究发现，对于混沌量子浴，TE在低浴增长率下是可扩展的，并且反映了真实的非马尔可夫性，但这种记忆仅包含在复杂的时间相关性中，对少点时间相关性的影响可以忽略不计。通过对IM进行粗粒化处理，TE的缩放规律从体定律转变为面积定律，表明局部可观测量动力学可以被面积定律IM完全捕获。


<details>
  <summary>Details</summary>
Motivation: 研究TE、非马尔可夫性和局部时间相关性之间的关系，以调和IM的高复杂性与局部可观测量快速热化之间的矛盾。

Method: 通过精确求解随机酉浴模型，并对未来和过去自由度之间的可蒸馏纠缠进行边界估算，分析了IM的粗粒化过程，并在踢打伊辛模型中进行了分析和数值验证。

Result: TE在低浴增长率下是可扩展的，反映了非马尔可夫性，但对局部可观测量影响很小。IM的粗粒化导致TE缩放从体定律转变为面积定律。紧凑型IM MPS可以准确描述局部演化。

Conclusion: TE的缩放行为可以通过IM的粗粒化从体定律变为面积定律，表明局部可观测量动力学可以被面积定律IM完全捕获。

Abstract: Temporal entanglement (TE) of an influence matrix (IM) has been proposed as a
measure of complexity of simulating dynamics of local observables in a
many-body system. Foligno et al. [Phys. Rev. X 13, 041008 (2023)] recently
argued that the TE in chaotic 1d quantum circuits obeys linear (volume-law)
scaling with evolution time. To reconcile this apparent high complexity of IM
with the rapid thermalization of local observables, here we study the relation
between TE, non-Markovianity, and local temporal correlations for chaotic
quantum baths. By exactly solving a random-unitary bath model, and bounding
distillable entanglement between future and past degrees of freedom, we argue
that TE is extensive for low enough bath growth rate, and it reflects genuine
non-Markovianity. This memory, however, is entirely contained in highly complex
temporal correlations, and its effect on few-point temporal correlators is
negligible. An IM coarse-graining procedure, reducing the allowed frequency of
measurements of the probe system, results in a transition from volume- to
area-law TE scaling. We demonstrate the generality of this TE transition in 1d
circuits by analyzing the kicked Ising model analytically at dual-unitary
points, as well as numerically away from them. This finding indicates that
dynamics of local observables are fully captured by an area-law IM. We provide
evidence that the compact IM MPS obtained via standard compression algorithms
accurately describes local evolution.

</details>


### [321] [On universality of hardware-efficient ansatzes](https://arxiv.org/abs/2511.03870)
*Hokuto Iwakiri,Keita Kanno*

Main category: quant-ph

TL;DR: HEAs are important for near-term quantum computing, and simulating some classes of them is BQP-complete.


<details>
  <summary>Details</summary>
Motivation: The importance of HEAs for near-term quantum computing applications.

Method: Showing that any relevant quantum circuit can be efficiently represented as an HEA circuit.

Result: Demonstrated that simulating some major classes of HEA is BQP-complete.

Conclusion: Simulating some major classes of HEA is BQP-complete, which has implications for the capabilities of near-term quantum computers.

Abstract: The hardware-efficient ansatz (HEA) is one of the most important class of
parametrized quantum circuits for near-term applications of quantum computing.
We show that the problem of simulating some major classes of the HEA is
BQP-complete by explicitly demonstrating that any relevant quantum circuit can
be efficiently represented as an HEA circuit of those classes.

</details>


### [322] [Self-correcting High-speed Opto-electronic Probabilistic Computer](https://arxiv.org/abs/2511.04300)
*Ramy Aboushelbaya,Annika Moslein,Hadi Azar,Hamid Tanhaei,Marko von der Leyen*

Main category: quant-ph

TL;DR: 量子光子p比特结合FPGA控制，实现高效概率计算。


<details>
  <summary>Details</summary>
Motivation: 利用量子光子和经典电子的优势，实现高效灵活的概率计算。

Method: 设计并实现了一个基于光子集成电路和FPGA控制的原型系统，集成了源设备无关（SDI）量子光子p比特。

Result: 原型系统实现了2.7 x 10^9 flips/s的翻转率和4.9 nJ/flip的能耗，相比基于MTJ的系统有显著提升。SDI协议实现了实时自认证和纠错。

Conclusion: 量子光子p比特为可扩展、高性能的概率计算提供了一个有前景的平台，对组合优化、机器学习和复杂系统建模有重要意义。

Abstract: We present a novel self-correcting, high-speed optoelectronic probabilistic
computer architecture that leverages source-device independent (SDI) quantum
photonic p-bits integrated with robust electronic control. Our approach
combines the intrinsic randomness and high bandwidth of quantum photonics with
the programmability and scal- ability of classical electronics, enabling
efficient and flexible probabilistic computation. We detail the design and
implementation of a prototype system based on photonic integrated circuits and
FPGA-based control, capable of implementing and manipulating 64000 logical
p-bits. Experimental results demonstrate that our architecture achieves a flip
rate of 2.7 x 10^9 flips/s with an energy consumption of 4.9 nJ/flip,
representing nearly three orders of magnitude improvement in speed and energy
efficiency compared to state-of-the-art magnetic tunnel junc- tion (MTJ) based
systems. Furthermore, the SDI protocol enables real-time self-certification and
error correction, ensuring reliable operation across a wide range of conditions
and solving the problem of hardware variability as the number of p-bits scale.
Our results establish quantum photonic p-bits as a promising platform for
scalable, high-performance probabilistic computing, with significant
implications for combinatorial optimization, machine learning, and complex
system modeling.

</details>


### [323] [Realistic GKP stabilizer states enable universal quantum computation](https://arxiv.org/abs/2511.03874)
*Fariba Hosseinynejad,Pavithran Iyer,Guillaume Dauphinais,David L. Feder*

Main category: quant-ph

TL;DR: GKP量子比特的固有噪声可用于实现非Clifford门，这在连续变量量子计算中具有实际应用价值。


<details>
  <summary>Details</summary>
Motivation: 理想的GKP态需要无限能量，因此不切实际。本研究旨在利用GKP态的固有噪声，探索其在实现非Clifford门方面的潜力。

Method: 通过高斯操作和零次测量，对可归一化的GKP态进行操作，实现对Pauli本征态的投影（用于实现Clifford门）以及对未测量模式的非Pauli本征态的投影（用于实现非Clifford门）。

Result: 实现了高保真度的Clifford门，并展示了概率性地实现非Clifford门的方法。

Conclusion: 可归一化的GKP稳定态结合高斯操作，为在实际的连续变量环境中，通过测量实现量子计算通用性提供了一个实用的框架。

Abstract: Physical Gottesman-Kitaev-Preskill (GKP) states are inherently noisy as ideal
ones would require infinite energy. While this is typically considered as a
deficiency to be actively corrected, this work demonstrates that imperfect GKP
stabilizer states can be leveraged in order to apply non-Clifford gates using
only linear optical elements. In particular, Gaussian operations on
normalizable GKP states, combined with homodyne measurements, permit two key
primitives: clean projection onto Pauli eigenstates in the normalizable GKP
codespace, thereby implementing Clifford gates with high fidelity; and
probabilistic projection of unmeasured modes onto non-Pauli eigenstates. These
results demonstrate that normalizable GKP stabilizer states combined with
Gaussian operations provide a practical framework for computational
universality within the measurement-based model of quantum computation in a
realistic continuous-variable setting.

</details>


### [324] [Controlled growth of rare-earth-doped TiO$_{2}$ thin films on III-V semiconductors for hybrid quantum photonic interfaces](https://arxiv.org/abs/2511.03918)
*Henry C. Hammer,Caleb Whittier,Nathan A. Helvy,Christopher Rouleau,Nabil D. Bassim,Ravitej Uppu*

Main category: quant-ph

TL;DR: 通过低温脉冲激光沉积技术在III-V族半导体上制备了掺铒钛氧化物薄膜，实现了外延生长和稀土量子存储器的集成，为构建可扩展的混合量子光子芯片奠定了基础。


<details>
  <summary>Details</summary>
Motivation: 量子光子网络需要单光子源和长寿命量子存储器，但III-V族量子点和稀土离子（如Er3+）的集成面临生长条件不兼容和晶格失配的挑战。

Method: 采用低温脉冲激光沉积技术，结合表面预处理（砷帽和缺氧缓冲层），在GaAs和GaSb衬底上生长了外延的锐钛矿TiO2:Er3+薄膜，并利用透射电子显微镜、拉曼光谱和低温光致发光激发光谱进行表征。

Result: 成功制备了表面粗糙度小于300 pm的外延锐钛矿TiO2 (001) 薄膜，并实现了Er3+离子的光学激活，同时保持了III-V族量子点的功能性。MCIA模型解释了选择性生长机制。

Conclusion: 该研究提出了一种多参数生长策略，实现了稀土量子存储器与半导体单光子源的单片集成，为构建可扩展的混合量子光子芯片提供了新的材料平台。

Abstract: Quantum photonic networks require two distinct functionalities: bright
single-photon sources and long-lived quantum memories. III-V semiconductor
quantum dots excel as deterministic and coherent photon emitters, while
rare-earth ions such as erbium (Er$^{3+}$) in crystalline oxides offer
exceptional spin and optical coherence at telecom wavelengths. Combining these
systems and their functionalities via direct epitaxy is challenging due to
lattice mismatch and incompatible growth conditions. Here we demonstrate
low-temperature pulsed laser deposition of Er$^{3+}$-doped TiO$_{2}$ thin films
directly on GaAs and GaSb substrates. Controlled surface preparation with an
arsenic cap and an oxygen-deficient buffer layer enables the growth of
epitaxial anatase TiO$_{2}$ (001) at 390$^{o}$C with sub-300 pm surface
roughness, while avoiding interface degradation. In contrast, high-temperature
oxide desorption or growth temperatures drive the transition to rough,
polycrystalline rutile film, as confirmed by transmission electron microscopy.
Minimal coincident interface area (MCIA) modeling explains the
orientation-selective growth on GaAs and GaSb. Raman and cryogenic
photoluminescence excitation spectroscopy verify the crystal phase and optical
activation of Er$^{3+}$ ions. This multi-parameter growth strategy helps
preserve III-V quantum dot functionality and yields smooth surfaces suitable
for low-loss nanophotonic structures. Our results establish a materials
platform for monolithically integrating rare-earth quantum memories with
semiconductor photon sources, paving the way toward scalable hybrid quantum
photonic chips.

</details>


### [325] [Novel Encodings of Homology, Cohomology, and Characteristic Classes](https://arxiv.org/abs/2511.03920)
*Itai Maimon*

Main category: quant-ph

TL;DR: 该论文提出了新的量子纠错码（QECC），能够编码纤维丛的阻塞类（如陈类或欧拉类）这一经典拓扑结构。


<details>
  <summary>Details</summary>
Motivation: 经典的量子比特编码（QECC）虽然编码了多种拓扑不变量，但尚未直接包含纤维丛的阻塞类，如陈类或欧拉类。

Method: 通过扩展托里码（toric codes）来构造新的QECC，分析其错误的拓扑结构，并利用这些错误来编码纤维丛的阻塞类。

Result: 成功构造了一种新的QECC，能够编码特征类，如陈类和庞特里亚金类（Pontryagin class），并明确构造了一个$S^2$的欧拉类的编码示例。

Conclusion: 这项工作通过将纤维丛的阻塞类（特征类）引入拓扑QECC，扩展了量子纠错码的编码能力。

Abstract: Topological quantum error-correcting codes (QECC) encode a variety of
topological invariants in their code space. A classic structure that has not
been encoded directly is that of obstruction classes of a fiber bundle, such as
the Chern or Euler class. Here, we construct and analyze extensions of toric
codes. We then analyze the topological structure of their errors and finally
construct a novel code using these errors to encode the obstruction class to a
fiber bundle. In so doing, we construct an encoding of characteristic classes
such as the Chern and Pontryagin class in topological QECC. An example of the
Euler class of $S^2$ is constructed explicitly.

</details>


### [326] [Quantum Optical Techniques for Biomedical Imaging](https://arxiv.org/abs/2511.03935)
*Vahid Salari,Yingwen Zhang,Sepideh Ahmadi,Dilip Paneru,Duncan England,Shabir Barzanjeh,Robert Boyd,Ebrahim Karimi,Christoph Simon,Daniel Oblak*

Main category: quant-ph

TL;DR: 量子成像技术利用光的非经典特性（如纠缠、压缩和量子关联）来克服传统技术的限制，在生物医学成像领域展现出巨大潜力，可提供更高的空间分辨率、信噪比、相位灵敏度，并降低辐射剂量。


<details>
  <summary>Details</summary>
Motivation: 生物医学成像领域需要克服现有技术的根本性限制，实现更高精度、更安全的成像，以应对精密生物样本的成像需求。

Method: 本文综述了量子光学和量子启发式成像方法，包括量子光学相干断层扫描、量子光学显微镜、鬼成像、多参数量子成像以及量子级相机成像。

Result: 文章描述了每种方法的原理、生物医学应用及独特优势，并指出了它们在实际应用中面临的具体挑战。

Conclusion: 量子成像技术在生物医学领域具有巨大潜力，但仍面临挑战，未来研究应致力于推动其从实验演示走向实际应用，成为有影响力的生物医学工具。

Abstract: Quantum imaging is emerging as a transformative approach for biomedical
applications, applying nonclassical properties of light, such as entanglement,
squeezing, and quantum correlations, to overcome fundamental limits of
conventional techniques. These methods promise superior spatial resolution,
enhanced signal-to-noise ratios, improved phase sensitivity, and reduced
radiation dose, for potentially safer and more precise imaging for delicate
biological samples. Here, we present an overview of quantum optical biomedical
imaging technologies as well as quantum-inspired imaging methods, including
quantum optical coherence tomography, quantum optical microscopy, ghost
imaging, multi-parameter quantum imaging, and imaging with quantum-grade
cameras. We describe the operating principles, biomedical applications, and
unique advantages of each approach, along with the specific challenges for
their translation into real-life practice. This review aims to guide future
research toward advancing quantum imaging from experimental demonstrations to
impactful biomedical tools.

</details>


### [327] [Non-invertible Kramers-Wannier duality-symmetry in the trotterized critical Ising chain](https://arxiv.org/abs/2511.03947)
*Akash Sinha,Pramod Padmanabhan,Vladimir Korepin*

Main category: quant-ph

TL;DR: 该研究表明，临界横向场伊辛模型的积分Trotter分解是一阶可积的，并利用量子逆散射方法获得了离散时间守恒量。研究还发现，时空离散化导致了Kramers-Wannier对偶算子的加倍，这些算子可以映射不同阶数的Trotter分解，并可用于分析有限时间Floquet演化。


<details>
  <summary>Details</summary>
Motivation: 研究可积的Trotter分解在离散时间演化中的守恒性质，以及Kramers-Wannier对偶对称性。

Method: 利用量子逆散射方法构建不均匀传递矩阵，得到离散时间守恒量，并分析Trotter分解的Kramers-Wannier对偶对称性。

Result: 证明了一阶Trotter分解是可积的，得到了离散时间守恒量。发现了时空离散化导致Kramers-Wannier对偶算子加倍，这些算子可以映射不同阶数的Trotter分解，并应用于有限时间Floquet演化。

Conclusion: 积分Trotter分解可以保留可积多体系统的守恒量，并且Kramers-Wannier对偶对称性在离散化后会产生新的算子，这些算子具有扩展性和应用价值。

Abstract: Integrable trotterization provides a method to evolve a continuous time
integrable many-body system in discrete time, such that it retains its
conserved quantities. Here we explicitly show that the first order
trotterization of the critical transverse field Ising model is integrable. The
discrete time conserved quantities are obtained from an inhomogeneous transfer
matrix constructed using the quantum inverse scattering method. The
inhomogeneity parameter determines the discrete time step. We then focus on the
non-invertible Kramers-Wannier duality-symmetry for the trotterized evolution.
We find that the discretization of both space and time leads to a doubling of
these duality operators. They account for discrete translations in both space
and time. As an interesting application, we find that these operators also
provide maps between trotterizations of different orders. This helps us extend
our results beyond the trotterization scheme and investigate the
Kramers-Wannier duality-symmetry for finite time Floquet evolution of the
critical transverse field Ising chain.

</details>


### [328] [Multi-Directional Periodic Driving of a Two-Level System beyond Floquet Formalism](https://arxiv.org/abs/2511.03977)
*Michael Warnock,David A. Hague,Vesna F. Mitrovic*

Main category: quant-ph

TL;DR: 该论文提出了一个计算半经典两能级量子系统在任意周期驱动下的精确响应的解析表达式。


<details>
  <summary>Details</summary>
Motivation: 为了解决现有数值方法（如Floquet理论）在处理周期驱动的量子系统时因截断无限矩阵而可能丢失关键干涉信息的问题，本研究旨在提供一种精确的解析方法。

Method: 使用“星号-解析式”方法（$"star"$-resolvent formalism）和路径和定理（path-sum theorem）来求解薛定谔方程，得到精确的级数解，并计算出精确的跃迁概率。该方法利用一个紧凑的核表达式来包含周期驱动的所有信息，并将其展开为一个非谐傅里叶级数，系数是广义贝塞尔函数的乘积。

Result: 得到了一个精确的级数解，用于计算半经典两能级量子系统在任意周期驱动下的跃迁概率，避免了数值计算中的截断误差。

Conclusion: 本研究提供了一种用于量子传感和量子控制应用的解析方法，能够精确计算量子系统的响应，避免了由数值截断引起的误差。

Abstract: In this manuscript, we introduce an exact expression for the response of a
semi-classical two-level quantum system subject to arbitrary periodic driving.
Determining the transition probabilities of a two-level system driven by an
arbitrary periodic waveform necessitates numerical calculations through methods
such as Floquet theory, requiring the truncation of an infinite matrix.
However, such truncation can lead to a loss of significant interference
information, hindering quantum sensors or introducing artifacts in quantum
control. To alleviate this issue, we use the $\star$-resolvent formalism with
the path-sum theorem to determine the exact series solution to Schr\"odinger's
equation, therefore providing the exact transition probability. The resulting
series solution is generated from a compact kernel expression containing all of
the information of the periodic drive and then expanded in a non-harmonic
Fourier series basis given by the divided difference of complex exponentials
with coefficients corresponding to products of generalized Bessel functions.
The present method provides an analytical formulation for quantum sensors and
control applications.

</details>


### [329] [Quantum error correction for multiparameter metrology](https://arxiv.org/abs/2511.04018)
*Mauricio Gutiérrez,Chiranjib Mukhopadhyay,Victor Montenegro,Abolfazl Bayat*

Main category: quant-ph

TL;DR: 通过使用量子纠错技术，GHZ探针在多参数传感中实现了最优的量子增强精度，并将测量策略保持为可分离和固定的。


<details>
  <summary>Details</summary>
Motivation: 单参数传感中GHZ探针已能达到最优量子增强精度，但在多参数传感中，单一GHZ探针不仅无法实现量子优势，最优测量方式也变得复杂且依赖于未知参数。

Method: 提出了一种使用量子纠错技术的多参数传感方案，将除一个未知参数外的所有参数视为噪声进行处理，并利用量子纠错技术消除噪声影响。

Result: 该策略恢复了单参数GHZ传感的核心优势，即在所有未知参数值下都能达到最优的量子增强精度，同时保持测量方法可分离且固定。具体而言，通过为每个GHZ探针增加一个受保护的辅助量子比特，该协议能够提取任何探针大小的最优精度。虽然单一GHZ探针的最优精度受限于散粒噪声，但通过使用多个互补的GHZ探针，可以恢复海森堡极限标度。

Conclusion: 通过量子纠错技术，GHZ探针在多参数传感中实现了最优精度，并克服了传统方法的局限性，有望在量子传感领域带来突破。

Abstract: For single-parameter sensing, Greenberger-Horne-Zeilinger (GHZ) probes
achieve optimal quantum-enhanced precision across the unknown parameter range,
solely relying on parameter-independent separable measurement strategies for
all values of the unknown parameter. However, in the multiparameter setting, a
single GHZ probe not only fails to achieve quantum advantage but also the
corresponding optimal measurement becomes complex and dependent on the unknown
parameters. Here, we provide a recipe for multiparameter sensing with GHZ
probes using quantum error correction techniques by treating all but one
unknown parameters as noise, whose effects can be corrected. This strategy
restores the core advantage of single parameter GHZ-based quantum sensing,
namely reaching optimally quantum-enhanced precision for all unknown parameter
values while keeping the measurements separable and fixed. Specifically, given
one shielded ancilla qubit per GHZ probe, our protocol extracts optimal
possible precision for any probe size. While this optimal precision is
shot-noise limited for a single GHZ probe, we recover the Heisenberg scaling
through use of multiple complementary GHZ probes. We demonstrate the
effectiveness of the protocol with Bayesian estimation.

</details>


### [330] [Anomalous heat flow and quantum Otto cycle with indefinite causal order](https://arxiv.org/abs/2511.04028)
*Qing-Feng Xue,Qi Zhang,Xu-Cai Zhuang,Yun-Jie Xia,Enrico Russo,Giulio Chiribella,Rosario Lo Franco,Zhong-Xiao Man*

Main category: quant-ph

TL;DR: 热量从高温流向低温是热力学基本原理，但当相互作用顺序不确定时，会出现异常热流，热量可能从冷到热。利用这一点，我们设计了一个具有不确定因果顺序的量子奥托循环，可实现制冷和做功。


<details>
  <summary>Details</summary>
Motivation: 研究当相互作用顺序不确定时，热量流动是否总是从高温到低温，以及是否能利用这种现象。

Method: 设计了一个具有不确定因果顺序的量子奥托循环，并利用异常热流实现制冷和做功。通过光子量子系统模拟了该循环。

Result: 实现了异常热流，即热量有时从较冷物体流向较热物体，并成功设计了一个可制冷和做功的量子奥托循环。

Conclusion: 具有不确定因果顺序的量子奥托循环可以实现制冷和做功，证明了异常热流现象的可行性。

Abstract: The principle that heat spontaneously flows from higher temperature to lower
temperature is a cornerstone of classical thermodynamics, often assumed to be
independent of the sequence of interactions. While this holds true for
macroscopic systems at equilibrium, here we show that, when the order of
interactions between two identical thermalization channels is indefinite, an
anomalous heat flow emerges, whereby heat can sometime flow from a colder
entity to a hotter one. Taking advantage of this anomalous heat flow, we design
a quantum Otto cycle with indefinite causal order, which not only achieves
refrigeration but also generates work. The anomalous heat flow and the quantum
Otto cycle are experimentally simulated in a photonic quantum setup, which
provides a proof-of-principle demonstration of the theory.

</details>


### [331] [Unifying contextual advantages in state discrimination](https://arxiv.org/abs/2511.04100)
*Kieran Flatt,Joonwoo Bae*

Main category: quant-ph

TL;DR: 该论文研究了量子态判别在证明广义非局域性中的应用，推导了不同猜测策略下的非局域性不等式，并统一了各种判别方案下的非局域性优势。


<details>
  <summary>Details</summary>
Motivation: 量子态判别及其应用可用于证明广义非局域性。

Method: 推导了包括确定性和不确定性结果的非局域性不等式，并针对最小误差判别、无歧义状态判别和最大置信度判别进行了分析。

Result: 在最小误差判别中，优势体现在个体结果的置信度；在无歧义状态判别中，优势体现在平均猜测概率；在最大置信度判别中，优势体现在置信度、平均猜测概率和不确定结果率。

Conclusion: 该研究统一了所有状态判别方案和评价指标下的非局域性优势，并预示着基于状态判别的量子信息应用可能在非局域性理论中具有优势。

Abstract: Quantum state discrimination, alongside its other applications, has recently
found use as a tool for witnessing generalised contextuality. In this article,
we derive noncontextuality inequalities for both conclusive and inconclusive
outcomes across various guessing strategies. For minimum- error discrimination,
the advantage is in terms of the confidences of individual outcomes, while for
unambiguous state discrimination, it is in terms of the average guessing
probability. For maximum- confidence discrimination, we show that contextual
advantages occur not only for the confidence but also their average, the
guessing probability, as well as the inconclusive outcome rate. Our results
unify the contextual advantages across all state discrimination schemes and
figures of merit. We envisage that various quantum information applications
based on state discrimination may offer advantages over non-contextual
theories.

</details>


### [332] [Controllable Non-Hermitianity in Continuous-Variable Qubits](https://arxiv.org/abs/2511.04110)
*Ke-Xiong Yan,Zhi-Cheng Shi,Ye-Hong Chen,Yan Xia*

Main category: quant-ph

TL;DR: 纯粹的退相干是光子猫比特中主要的泄漏机制，因为它会破坏奇偶校验保护，使量子比特容易受到能量弛豫的影响。本手稿揭示了这种退相干机制隐藏了一个有趣的物理现象：它引起了猫态子空间的不对称泄漏，其中偶数和奇数奇偶校验的猫态以不同的速率衰减。这种泄漏不对称性使得系统动力学可以用非厄米哈密顿量来描述，从而将猫比特转变为具有可控增益和损耗的平台，用于探测非厄米物理学。在该平台上，我们通过调整猫比特的幅度来演示控制其宇称-时间对称性相变的可能性。此外，我们通过耦合两个猫比特来实现由卓越点引起的纠缠相变。我们的工作构建了一个可控的非厄米系统模拟器，颠覆了将退相干视为有害噪声的传统模式。


<details>
  <summary>Details</summary>
Motivation: 纯粹的退相干是光子猫比特中的主要泄漏机制，因为它会破坏奇偶校验保护，使量子比特容易受到能量弛豫的影响。然而，这种退相干机制隐藏了一个有趣的物理现象：它引起了猫态子空间的不对称泄漏，其中偶数和奇数奇偶校验的猫态以不同的速率衰减。这种泄漏不对称性使得系统动力学可以用非厄米哈密顿量来描述，从而将猫比特转变为具有可控增益和损耗的平台，用于探测非厄米物理学。

Method: 在本研究中，我们探索了光子猫比特中的纯退相干机制。我们发现这种退相干会导致猫态子空间的不对称泄漏，其中偶数和奇数奇偶校验的猫态以不同的速率衰减。这种现象使我们能够使用非厄米哈密顿量来描述系统动力学，并将猫比特用作可控增益和损耗的平台，以研究非厄米物理学。我们通过调整猫比特的幅度来控制其宇称-时间对称性相变，并通过耦合两个猫比特来实现由卓越点诱导的纠缠相变。

Result: 我们证明了通过调整猫比特的幅度来控制其宇称-时间对称性相变的可能性。此外，我们通过耦合两个猫比特实现了由卓越点诱导的纠缠相变。

Conclusion: 本研究构建了一个可控的非厄米系统模拟器，该模拟器基于光子猫比特中的退相干现象。通过将退相干视为一种可控的资源，而不是有害的噪声，我们开辟了研究非厄米物理学的新途径。

Abstract: Pure dephasing is the dominant leak mechanism in photonic cat qubits because
its phase errors disrupt the parity protection, rendering the qubit vulnerable
to energy relaxation. In this manuscript, we reveal that this dephasing
mechanism conceals an interesting physical phenomenon: it induces
\textit{asymmetric leakage} from the cat-state subspace, where even- and
odd-parity cat states decay at different rates. This leak asymmetry enables the
dynamics of the system to be described by a non-Hermitian Hamiltonian, thereby
transforming the cat qubit into a platform with controllable gain and loss for
probing non-Hermitian physics. Within this platform, we demonstrate the
possibility to control the parity-time symmetry phase transition in a single
cat qubit by adjusting its amplitude. Moreover, we couple two cat qubits to
realize an entanglement phase transition induced by the exceptional point. Our
work constructs a controllable non-Hermitian system simulator, overturning the
conventional paradigm that treats dephasing as harmful noise.

</details>


### [333] [Expectation-Realization Interpretation of Quantum Superposition](https://arxiv.org/abs/2511.04154)
*Yanting Wang*

Main category: quant-ph

TL;DR: This paper proposes an 'expectation-realization' interpretation of quantum superposition, which views it as a probability-weighted expectation over eigenstates. Quantum systems randomly realize into one eigenstate upon an event, with the distribution controllable by experimental setup. This interpretation negates the need for concepts like wavefunction collapse, many worlds, and decoherence, and reframes Bell's inequality tests as validations of wave-like probability without invoking non-locality.


<details>
  <summary>Details</summary>
Motivation: The motivation is to provide a new interpretation of quantum superposition that avoids puzzling concepts like wavefunction collapse, many worlds, and decoherence, by integrating probability theory with wave mechanics.

Method: The paper compares Schrödinger's cat with its classical counterpart to explain quantum superposition as an expectation over possible eigenstates weighted by wave-like probabilities. It describes quantum systems as randomly realizing into one eigenstate upon an event, with controllable distributions.

Result: The expectation-realization interpretation can be extended to quantum pathways and reframes Bell's inequality tests as validating wave-like probability without invoking non-locality or spooky action at a distance.

Conclusion: Quantum superposition can be understood as an expectation over possible eigenstates weighted by wave-like probabilities. Upon an event, the system is randomly realized into one eigenstate. This interpretation eliminates the need for concepts such as wavefunction collapse, many worlds, and decoherence, and provides an alternative understanding of Bell's inequality tests.

Abstract: By comparing Schr\"odinger's cat with its classical counterpart, I show that
a quantum superposition should be understood as an expectation over possible
eigenstates weighted by wave-like probabilities. Upon the occurrence of a
certain event, the quantum system is randomly realized into one of the possible
eigenstates due to its intrinsic stochasticity. While the randomness of a
single realization cannot be controlled or predicted, the overall distribution
can be regulated via experimental setup and converges as the number of events
increases. A measurement is indeed an activity employing a certain event to
convert a quantum effect into a macroscopic outcome. Consequently, the puzzling
concepts of wavefunction collapse, many worlds, and decoherence become
unnecessary for understanding quantum superposition. This
expectation-realization interpretation, which integrates probability theory
with wave mechanics, can also be extended to quantum pathways. Moreover, it
reframes tests of Bell's inequalities as validating the wave-like probability
nature of quantum mechanics, with no need to invoke the mysterious notions of
quantum non-locality and "spooky action at a distance".

</details>


### [334] [Non-relativistic Quantum Mechanics on a Twisted Cylindrical Surface](https://arxiv.org/abs/2511.04371)
*G. M. Delgado,J. E. G. Silva*

Main category: quant-ph

TL;DR: 电子被限制在扭曲的圆柱形表面上的量子行为，研究了几何和应变的影响。


<details>
  <summary>Details</summary>
Motivation: 研究扭曲圆柱管的量子行为，将其作为纳米结构、异质结构和曲面量子器件的模型系统。

Method: 计算应变张量得到诱导表面度量，并使用 da Costa 形式主义推导出几何诱导量子势，从而修改薛定谔方程以确定束缚态和能量特征值。分析了两种散射问题：(i) 包含扭曲部分的无限圆柱内的散射，(ii) 自由粒子入射到有限扭曲圆柱上的散射。

Result: 发现线性和非线性扭曲都会在波函数中产生几何相位，而 da Costa 势保持不变。系统支持与扭曲无关的能量谱的束缚态。对于两种散射问题，发现透射概率对扭曲不敏感，但受粒子角动量和圆柱半径的显着影响，表现出明显的振荡行为。

Conclusion: 几何和应变通过修改 da Costa 势来影响电子的量子行为，但在此特定系统中，能量谱和透射概率对扭曲的依赖性很小。然而，粒子的角动量和圆柱的半径会显着影响透射概率。这些发现可能对工程制造基于具有受控曲率和扭曲的材料的量子器件具有重要意义。

Abstract: Twisted cylindrical tubes are important model systems for nanostructures,
heterostructures, and curved quantum devices. In this work, we investigate the
quantum behavior of an electron confined to a twisted cylindrical surface. By
first calculating the strain tensor to obtain the induced surface metric, we
employ da Costa's formalism to derive the geometry-induced quantum potential.
This potential modifies the Schr\"odinger equation even in the absence of
external forces, allowing us to determine the bound states and energy
eigenvalues. This was made in the linear and non-linear torsion regime.
Furthermore, we analyze two distinct scattering problems: (i) scattering within
an infinite cylinder containing a twisted section, and (ii) scattering of a
free particle incident upon a finite twisted cylinder. Our goal is to
understand how geometry and strain influence the properties of analogous
untwisted systems. It turns out that both the linear and non-linear twists
yield to a geometric phase into the wave function, while the da Costa potential
is kept unchanged. Consequently, the system supports bound states whose energie
spectrum is twist independent. For both scattering problems, we find that the
transmission probability is insensitive to torsion, whereas it is significantly
affected by the particle angular momentum and the cylinder's radius, exhibiting
distinct oscillatory behavior. These findings suggest relevant implications for
engineering quantum devices based on materials with controlled curvature and
twist.

</details>


### [335] [Two-exponential decay of Acridine Orange](https://arxiv.org/abs/2511.04185)
*Francesco Giacosa,Anna Kolbus,Krzysztof Kyziol,Magdalena Plodowska,Milena Piotrowska,Karol Szary,Arthur Vereijken*

Main category: quant-ph

TL;DR: 实验未观察到预期的 late-time power-law behaviour，但精确测定了样品的荧光寿命。


<details>
  <summary>Details</summary>
Motivation: 为了检验是否出现与量子力学和量子场论预测一致的 late-time power-law behaviour，即使该行为非常微小。

Method: 使用两个独立的光子探测器，通过指数函数拟合荧光衰减数据。

Result: 数据可以用两个具有不同寿命（τ1 = 1.7331 ± 0.001 ns 和 τ2 = 5.948 ± 0.012 ns）的指数函数很好地描述，这与文献报道的值一致。未观察到偏离指数衰减定律的现象。

Conclusion: 虽然没有观察到预期的 late-time power-law behaviour，但该研究成功验证了实验装置的可靠性，并能够精确测定样品的荧光寿命。

Abstract: In this work, we experimentally study the fluorescence decay of Acridine
Orange at late times, in order to test whether a late-time power-law behaviour
emerges, a feature expected to be very small but consistent with quantum
mechanical and quantum field theoretical predictions. Using two distinct photon
detectors, we find that the data are well described by a sum of two exponential
functions with lifetimes $\tau_1 = 1.7331 \pm 0.001$ ns and $\tau_2 = 5.948 \pm
0.012$ ns, in agreement with values reported in the literature. While no
deviation from the exponential decay law is observed, this study serves as a
reliable test for the experimental setup and enables a precise determination of
the sample lifetimes.

</details>


### [336] [Quantum Key Distribution via Charge Teleportation](https://arxiv.org/abs/2511.04188)
*Amir Yona,Yaron Oz*

Main category: quant-ph

TL;DR: 该研究提出了一种基于电荷传输的量子密钥分发（QKD）新方法，利用多体纠缠基态，通过局域操作和经典通信（LOCC）实现，其中Alice的选择可以控制Bob处局部电荷的符号变化，直接编码密钥比特。


<details>
  <summary>Details</summary>
Motivation: 与现有的基于能量传输的方案相比，该电荷传输方案具有比特对称性，只需在单个基矢下测量，并且对现实中的噪声和模型不完善之处具有更强的鲁棒性。

Method: 在横向场伊辛模型（星状耦合和一维链）上实现了该协议，对两比特系统得到了闭式解，并对更大系统通过精确对角化、电路级模拟和原理验证性硬件运行进行了性能确认。

Result: 通过对经典比特翻转和局域量子噪声的弹性进行量化，确定了符号完整性（即密钥正确性）得以保持的参数范围。

Conclusion: 该研究表明，电荷传输作为一种量子密钥分发（QKD）的实用性低速率原语，与近期平台兼容，具有潜在的应用前景。

Abstract: We introduce a quantum key distribution (QKD) primitive based on charge
teleportation: by Local Operations and Classical Communication (LOCC) on an
entangled many-body ground state, Alice's one-bit choice steers the sign of a
local charge shift at Bob, which directly encodes the key bit. Relative to
energy teleportation schemes, the charge signal is bit-symmetric, measured in a
single basis, and markedly more robust to realistic noise and model
imperfections. We instantiate the protocol on transverse-field Ising models,
star-coupled and one-dimensional chain, obtain closed-form results for two
qubits, and for larger systems confirm performance via exact diagonalization,
circuit-level simulations, and a proof-of-principle hardware run. We quantify
resilience to classical bit flips and local quantum noise, identifying regimes
where sign integrity, and hence key correctness, is preserved. These results
position charge teleportation as a practical, low-rate QKD primitive compatible
with near-term platforms.

</details>


### [337] [Quantum Chip Co-Design for Fidelity and Entanglement Preservation](https://arxiv.org/abs/2511.04194)
*Ahmad Salmanogli,Hesam Zandi*

Main category: quant-ph

TL;DR: 提出了一种混合多量子比特配置，通过调整耦合强度来优化纠缠和读出保真度，实现了可扩展的量子芯片架构。


<details>
  <summary>Details</summary>
Motivation: 在超导量子芯片设计中，纠缠和读出保真度之间存在关键的权衡。目前的超导量子芯片设计倾向于在增强纠缠的同时牺牲读出保真度，反之亦然。本研究旨在解决这一挑战，提出一种能够同时优化这两种特性的新架构。

Method: 提出了一种由九个超导量子比特组成的混合多量子比特配置。内部量子比特和可调谐量子比特构成纠缠核心，而外部量子比特在大的失谐下在色散区域运行以实现读出。通过调整中央可调谐量子比特与内部量子比特之间的耦合强度来动态调整纠缠程度。通过数值求解包含所有显著耦合贡献的哈密顿量和林德布拉德主方程来表征系统动力学，评估光谱特征和分离保真度。

Result: 模拟结果表明，该设计通过创建避免交叉区域来保持强纠缠，同时在实际噪声条件下将测量保真度保持在 0.995 左右。这表明在单个可重构架构中可以共同优化纠缠强度和读出保真度。

Conclusion: 所提出的混合多量子比特架构能够协同优化纠缠和读出保真度，为实现高性能、可扩展的超导量子处理器提供了一条可行的途径。

Abstract: This study introduces a superconducting quantum chip architecture designed to
simultaneously preserve entanglement and readout fidelity, addressing one of
the key trade-offs in the development of scalable quantum hardware. In
conventional quantum circuits, strong qubit qubit coupling enhances
entanglement but often leads to undesired crosstalk, dephasing, and reduced
measurement fidelity. To mitigate these effects, we propose a hybrid multiqubit
configuration consisting of nine transmon qubits organized into interior and
exterior groups, interconnected via a flux tunable qubit and a network of
distributed resonators. The interior qubits along with tunable qubit form an
entanglement core, while the exterior qubits operate in the dispersive regime
under large detuning to enable readout. The degree of entanglement can be
dynamically tuned by adjusting the coupling between the central tunable qubit
and the interior qubits. The total Hamiltonian includes all significant
coupling contributions, encompassing effective exchange interactions among
interior and exterior qubits, as well as their mediated couplings through
interface resonators. By numerically solving the complete Hamiltonian alongside
the Lindblad master equation, the system dynamics are characterized, allowing
evaluation of both spectroscopic features and separation fidelity. Simulation
results demonstrate that the proposed design maintains strong entanglement by
creating the avoided-crossing region while sustaining measurement fidelity
around 0.995 under realistic noise conditions. These findings confirm that
entanglement strength and readout fidelity can be co-optimized within a single,
reconfigurable architecture, establishing a viable route toward
high-performance and scalable superconducting quantum processors.

</details>


### [338] [Engineered Robustness for Nonadiabatic Geometric Quantum Gates](https://arxiv.org/abs/2511.04225)
*Xuan Zhang,XIao-le Li,Jingjing Niu,Tongxing Yan,Yuanzhen Chen*

Main category: quant-ph

TL;DR: 本论文提出了一种简化的非绝热几何量子门（NGQG）框架，通过引入额外的辅助约束来抑制动力学污染，并实现了超鲁棒性能。该框架还允许使用非循环路径设计NGQG，增强了设计灵活性。


<details>
  <summary>Details</summary>
Motivation: 尽管几何量子门理论上具有内在的鲁棒性，但实际应用中并未完全实现。本研究旨在通过一种简化的框架来解决这一问题。

Method: 提出并实现了一种简化的非绝热几何量子门（NGQG）框架，引入辅助约束以抑制动力学污染，并使用非循环路径设计NGQG。该方法在超导Transmon量子比特上进行了实现。

Result: 在单量子比特门方面，实现了高保真度的量子门，其对Rabi幅度误差 $\epsilon$ 的弗性质随 $\mathcal{O}(\epsilon^4)$ 缩放，优于传统动力学门的 $\mathcal{O}(\epsilon^2)$ 行为。在双量子比特门方面，分析了参数驱动下的双量子比特NGQG，并指出了相位补偿和波形校准在克服性能限制中的重要性。

Conclusion: 所提出的超鲁棒NGQG方案具有简单性和通用性，适用于多种量子平台。

Abstract: While geometric quantum gates are often theorized to possess intrinsic
resilience to control errors by exploiting the global properties of evolution
paths, this promise has not consistently translated into practical robustness.
We present a streamlined framework for nonadiabatic geometric quantum gates
(NGQGs) that incorporates additional auxiliary constraints to suppress
dynamical contamination and achieve super-robust performance. Within this
framework, we also design NGQGs using noncyclic paths, offering enhanced design
flexibility. Implemented on superconducting transmon qubits, our scheme
realizes high-fidelity single-qubit gates that are robust against Rabi
amplitude error $\epsilon$, with infidelity scaling as
$\mathcal{O}(\epsilon^4)$, in contrast to the $\mathcal{O}(\epsilon^2)$
behavior of conventional dynamical gates. We further analyze two-qubit NGQGs
under parametric driving. Our results identify subtle limitations that
compromise performance in two-qubit scenarios, underscoring the importance of
phase compensation and waveform calibration. The demonstrated simplicity and
generality of our super-robust NGQG scheme make it applicable across diverse
quantum platforms.

</details>


### [339] [Local quantum coherence with intersource interactions at nonzero temperature](https://arxiv.org/abs/2511.04242)
*Yehor Hudenko,Michal Kolář,Radim Filip,Artem Ryabov*

Main category: quant-ph

TL;DR: 局部量子相干性可以通过与环境的对称性破坏相互作用自主产生，即使在有相互作用的环境中也是如此。


<details>
  <summary>Details</summary>
Motivation: 探讨了环境内部相互作用对自主产生局部量子相干性的影响，而以往的研究多集中在非相互作用的环境。

Method: 分析了一个包含目标双态系统（TLS）和N个相互作用的源TLS（代表环境）的精确可解模型，整个系统处于热平衡状态。

Result: 发现在有限温度下，与无源相互作用的情况相比，局部相干性不仅持续存在，而且可以增强。相干性的温度依赖性呈现出量子相变的特征。

Conclusion: 局部相干性不仅在非零温度下可以存在，而且可以通过优化策略进行增强，这揭示了自主产生的量子相干性的普遍性质，并为在非零温度下观察相干性指明了可行的途径。

Abstract: Local quantum coherence in a two-level system (TLS) is typically generated
via time-dependent driving. However, it can also emerge autonomously from
symmetry-breaking interactions between the TLS and its surrounding environment
at a low temperature. Although such environments often consist of interacting
atoms or spins, the role of interactions within the environment in generating
the autonomous local coherence has remained unexplored. Here, we address this
gap by analyzing an exactly solvable model, which comprises a target TLS
coupled to $N$ interacting source TLSs that represent the environment, with the
whole system being in thermal equilibrium. We show that the local coherence not
only persists but can be enhanced at finite temperatures of the environment
compared to the case of no inter-source interactions. The temperature
dependence of the coherence bears signatures of a quantum phase transition, and
our analytical results suggest strategies for its optimization. Our findings
reveal generic properties of the autonomously generated quantum coherence and
point to viable routes for observing the coherence at nonzero temperatures.

</details>


### [340] [Twirlator: A Pipeline for Analyzing Subgroup Symmetry Effects in Quantum Machine Learning Ansatzes](https://arxiv.org/abs/2511.04243)
*Valter Uotila,Väinö Mehtola,Ilmo Salmenperä,Bo Zhao*

Main category: quant-ph

TL;DR: 数据对称性在量子机器学习（QML）中有很大潜力，但其实际开销（如额外门、降低表达能力）尚不明确。本研究开发了一个自动化流程来评估QML模型在面对不同数据对称性时的表现。


<details>
  <summary>Details</summary>
Motivation: 在量子机器学习中，虽然利用数据对称性被认为是提高性能的关键，但其潜在的开销（如增加的门数量、降低的表达能力等）并未得到充分理解。

Method: 研究人员开发了一个自动化流程，用于测量量子机器学习模型（ansatzes）在面对学习任务中可能出现的对称性时的各种特征。他们将学习问题的对称性程度定义为它所允许的子群的大小，并研究了由不同大小子群定义的偏对称性。通过对19种常见模型进行对称化处理，并根据对称性的不同，计算了三个类别的度量标准：1. 原始生成器与对称化生成器之差的范数；2. 对称化电路的深度、大小等特征；3. 模型的表达能力和纠缠能力。

Result: 研究结果显示，在不同模型中，对称化处理带来的门开销各不相同。结果证实，对称性增强会降低电路的表达能力，但在大多数情况下会增强其纠缠能力。

Conclusion: 本研究通过量化分析不同模型在对称性影响下的表现，为几何量子机器学习应用提供了选择合适的、既有足够表达能力又计算高效的模型（ansatz patterns）的依据。

Abstract: Leveraging data symmetries has been a key driver of performance gains in
geometric deep learning and geometric and equivariant quantum machine learning.
While symmetrization appears to be a promising method, its practical overhead,
such as additional gates, reduced expressibility, and other factors, is not
well understood in quantum machine learning. In this work, we develop an
automated pipeline to measure various characteristics of quantum machine
learning ansatzes with respect to symmetries that can appear in the learning
task. We define the degree of symmetry in the learning problem as the size of
the subgroup it admits. Subgroups define partial symmetries, which have not
been extensively studied in previous research, which has focused on symmetries
defined by whole groups. Symmetrizing the 19 common ansatzes with respect to
these varying-sized subgroup representations, we compute three classes of
metrics that describe how the common ansatz structures behave under varying
amounts of symmetries. The first metric is based on the norm of the difference
between the original and symmetrized generators, while the second metric counts
depth, size, and other characteristics from the symmetrized circuits. The third
class of metrics includes expressibility and entangling capability. The results
demonstrate varying gate overhead across the studied ansatzes and confirm that
increased symmetry reduces expressibility of the circuits. In most cases,
increased symmetry increases entanglement capability. These results help select
sufficiently expressible and computationally efficient ansatze patterns for
geometric quantum machine learning applications.

</details>


### [341] [Space-Bounded Communication Complexity of Unitaries](https://arxiv.org/abs/2511.04250)
*Longcheng Li,Xiaoming Sun,Jialin Zhang,Jiadong Zhu*

Main category: quant-ph

TL;DR: 本文研究了分布式量子处理器中空间受限的酉实现通信复杂性，为n比特酉操作提供了改进的通信复杂性上界，并对量子傅里叶变换和Clifford电路进行了具体分析。


<details>
  <summary>Details</summary>
Motivation: 在分布式量子处理器中，为了保证其实际应用和技术上的非平凡性，需要研究空间受限的酉实现通信复杂性。

Method: 通过使用具有非局域两比特门的分布式量子电路模型，将通信复杂度定义为实现酉操作所需的最小非局域门数量。对于n比特酉操作，在k个处理器（每个处理器有n/k个数据比特和m个辅助比特）的场景下，证明了通信复杂度的上界为O(max{4^((1-1/k)n - m), n})，并证明了该上界的紧密性。同时，将分析扩展到近似模型和一般网络拓扑。对于量子傅里叶变换（QFT）和Clifford电路，在精确模型下证明了其通信复杂度存在线性上界，在近似模型下QFT的通信复杂度降为对数级别，而Clifford电路保持线性下界。

Result: 对于n比特酉操作，通信复杂性的上界为O(max{4^((1-1/k)n - m), n})，例如当m=0, k=2时为O(2^n)。量子傅里叶变换（QFT）和Clifford电路在精确模型下通信复杂度为线性上界，在近似模型下QFT的通信复杂度降为对数级别，Clifford电路仍为线性下界。

Conclusion: 本文提出的通信复杂度上界和对QFT及Clifford电路的分析结果，为优化分布式量子酉实现中的通信提供了基础性见解，有助于提升大规模分布式量子计算系统的可行性。

Abstract: We study space-bounded communication complexity for unitary implementation in
distributed quantum processors, where we restrict the number of qubits per
processor to ensure practical relevance and technical non-triviality. We model
distributed quantum processors using distributed quantum circuits with nonlocal
two-qubit gates, defining the communication complexity of a unitary as the
minimum number of such nonlocal gates required for its realization.
  Our contributions are twofold. First, for general $n$-qubit unitaries, we
improve upon the trivial $O(4^n)$ communication bound. Considering $k$
pairwise-connected processors (each with $n/k$ data qubits and $m$ ancillas),
we prove the communication complexity satisfies $O\left(\max\{4^{(1-1/k)n - m},
n\}\right)$--for example, $O(2^n)$ when $m=0$ and $k=2$--and establish the
tightness of this upper bound. We further extend the analysis to approximation
models and general network topologies. Second, for special unitaries, we show
that both the Quantum Fourier Transform (QFT) and Clifford circuits admit
linear upper bounds on communication complexity in the exact model,
outperforming the trivial quadratic bounds applicable to these cases. In the
approximation model, QFT's communication complexity reduces drastically from
linear to logarithmic, while Clifford circuits retain a linear lower bound.
These results offer fundamental insights for optimizing communication in
distributed quantum unitary implementation, advancing the feasibility of
large-scale distributed quantum computing (DQC) systems.

</details>


### [342] [Quantum time-marching algorithms for solving linear transport problems including boundary conditions](https://arxiv.org/abs/2511.04271)
*Sergio Bengoechea,Paul Over,Thomas Rung*

Main category: quant-ph

TL;DR: 本研究提出了首个用于模拟多维线性输运现象的量子时间-步进算法，该算法能够处理任意边界条件，并且成功概率由问题本身决定。


<details>
  <summary>Details</summary>
Motivation: 本文旨在为多维线性输运现象提供一个完整的量子模拟应用，特别是处理任意边界条件，并优化算法的成功概率和时间复杂度。

Method: 研究采用线性组合单元算法来模拟扩散动力学，并通过图像法（每个空间维度增加一个额外量子比特）来处理任意边界条件。此外，还提出了一种通过时间-步进算子的酉分解直接编码新边界条件的方法，以替代非周期性反射。

Result: 所有提出的算法均实现了最优的成功概率，并保持了线性时间复杂度。通过状态向量模拟，研究成功地演示了结合新边界条件、狄利克雷边界条件和混合边界条件的热方程。

Conclusion: 本研究提出的量子时间-步进方法在容错量子计算机上具有实际应用前景，能够高效且准确地模拟包含各种边界条件的多维线性输运现象。

Abstract: This article presents the first complete application of a quantum
time-marching algorithm for simulating multidimensional linear transport
phenomena with arbitrary boundaries, whereby the success probabilities are
problem intrinsic. The method adapts the linear combination of unitaries
algorithm to block encode the diffusive dynamics, while arbitrary boundary
conditions are enforced by the method of images only at the cost of one
additional qubit per spatial dimension. As an alternative to the non-periodic
reflection, the direct encoding of Neumann conditions by the unitary
decomposition of the discrete time-marching operator is proposed. All presented
algorithms indicate optimal success probabilities while maintaining linear time
complexity, thereby securing the practical applicability of the quantum
algorithm on fault-tolerant quantum computers. The proposed time-marching
method is demonstrated through state-vector simulations of the heat equation in
combination with Neumann, Dirichlet, and mixed boundary conditions.

</details>


### [343] [Random access Bell game by sequentially measuring the control of the quantum SWITCH](https://arxiv.org/abs/2511.04272)
*Gaurang Agrawal,Saptarshi Roy*

Main category: quant-ph

TL;DR: 在有噪声的环境中，我们引入了一种新的贝尔不等式检验方法，称为随机接入贝尔博弈（RABG）。


<details>
  <summary>Details</summary>
Motivation: 在有噪声的环境中，保持量子关联（如贝尔非局域性）是量子技术面临的一个基本挑战。

Method: 我们提出了一种利用初始纠缠和对控制系统的顺序、不尖锐测量来规避噪声影响的协议，该协议在随机接入贝尔博弈中可以保证在任意多次噪声信道应用后仍然能够违反贝尔不等式。

Result: 该协议允许在任何期望的回合实现接近最大（Tsirelson 边界）的贝尔违反，同时确保之前所有回合的违反。该协议仅适用于广义 GHZ 态，对于 W 类态则无效，从而提供了一种区分这两种基本多方纠缠类别的方法。

Conclusion: 通过利用初始纠缠和对控制系统的巧妙测量，我们提出了一种可以在有噪声信道中保持量子关联的协议，这对于量子技术的发展具有重要意义。

Abstract: Preserving quantum correlations such as Bell nonlocality in noisy
environments remains a fundamental challenge for quantum technologies. We
introduce the Random Access Bell Game (RABG), a task where an entangled
particle propagates through a sequence of identical noisy blocks, and the
ability to violate a Bell inequality is tested at a randomly chosen point
(access node). We consider a scenario where each noisy block is composed of two
complete erasure channels, an extreme entanglement-breaking channel with
vanishing quantum and classical capacities. We investigate the performance of
the Random Access Bell Game in this configuration and attempt to mitigate the
effect of noise by coherently controlling the order of each channel in the
noise using the quantum {\tt SWITCH}. However, the quantum {\tt SWITCH} in its
canonical setup with a coherent state in the control fails to provide any
advantage in the Random Access Bell Game. Our main contribution is a protocol
that leverages initial entanglement between the target and control of the
quantum {\tt SWITCH} and employs sequential, unsharp measurements on the
control system, showing that it is possible to guarantee a Bell violation after
an arbitrarily large number of channel applications. Furthermore, our protocol
allows for a near-maximal (Tsirelson bound) Bell violation to be achieved at
any desired round, while still ensuring violations in all preceding rounds. We
prove that this advantage is specific to generalized
Greenberger-Horne-Zeilinger (GHZ) states, as the protocol fails for W-class
states, thus providing an operational way to distinguish between these two
fundamental classes of multipartite entanglement.

</details>


### [344] [Quasiprobabilities from incomplete and overcomplete measurements](https://arxiv.org/abs/2511.04274)
*Jan Sperling,Laura Ares,Elizabeth Agudelo*

Main category: quant-ph

TL;DR: 本文讨论了如何从通用测量（包括噪声测量）中（重新）构建拟概率表示，并引入了与测量相关的拟概率和非经典性概念。解决了信息不完整和信息过剩的测量场景问题，比较了不同测量方案对拟概率和非经典态集合的影响。


<details>
  <summary>Details</summary>
Motivation: 介绍拟概率表示，探讨其与测量、非经典性的关系，并解决信息不完整/过剩测量场景的问题。

Method: 提出了一种通用的拟概率表示构建方法，并使用单量子比特系统进行示例和比较。

Result: 给出了使用不同测量方案得到的拟概率和非经典态集合的具体示例，并进行了比较。

Conclusion: 通用测量（包括噪声测量）可以用于构建拟概率表示，测量方案的选择会影响非经典态的评估。

Abstract: We discuss the (re-)construction of quasiprobability representations from
generic measurements, including noisy ones. Based on the measurement under
study, quasiprobabilities and the associated concept of nonclassicality are
introduced. A practical concern that we address is the treatment of
informationally incomplete and overcomplete measurement scenarios, which can
significantly alter the assessment of which states are deemed classical.
Notions, such as Kirkwood-Dirac quasiprobabilities and s-parametrized
quasiprobabilities in quantum optics, are generalized by our approach.
Single-qubit systems are used to exemplify and to compare different measurement
schemes, together with the resulting quasiprobabilities and set of nonclassical
states.

</details>


### [345] [Cluster States Generation with a Quantum Metasurface](https://arxiv.org/abs/2511.04297)
*Yehonatan Levin,Uri Israeli,Rivka Bekenstein*

Main category: quant-ph

TL;DR: 利用量子超表面实现光子簇状态生成，克服了传统方法的损耗限制，并分析了实际应用中的保真度。


<details>
  <summary>Details</summary>
Motivation: 需要克服现有光子簇状态生成协议中因耦合损耗导致的问题，以提高效率和最大量子比特数。

Method: 利用由亚波长原子阵列组成的量子超表面，实现量子控制反射率，并构建了生成二维簇状态和树簇状态的两种特定协议，实现了超过0.9保真度的两比特量子逻辑门（CNOT, CZ, E）。

Result: 实现了保真度超过0.9的两比特量子逻辑门，并分析了在热波动等实际条件下的保真度。

Conclusion: 量子超表面为实现高效、可扩展的光子簇状态生成提供了可行方案，具有在量子计算和通信中应用的潜力。

Abstract: We investigate the implementation of photonic cluster state generation
protocols using quantum metasurfaces comprising sub-wavelength atomic arrays
which enables quantum-controlled reflectivity. These cluster states are
generated using fundamental quantum logic gates and enable wide-ranging
applications in quantum computation and communication. In the past few years,
certain protocols have been developed, but their physical realizations induces
natural losses on the system mainly originated from coupling the photonic
structures, setting a limit on the efficiency and maximal qubit number. In this
paper, we examine a physical implementation of two specific protocols for
generating distinct cluster states: a two-dimensional cluster state and a tree
cluster state. Our approach leverages the unique properties of a quantum
metasurface and its free space settings to implement two-qubit quantum-logic
gates, namely CNOT, CZ, and E gates, with practical fidelities exceeding 0.9,
and potential speed-up due to parallelism. In addition, we analyze these
protocols fidelities for practical conditions of potential implementation
experiments, such as thermal fluctuation of trapped atoms.

</details>


### [346] [Synchronization effects in a periodically driven two-level system](https://arxiv.org/abs/2511.04339)
*Federico Settimo,Bassano Vacchini*

Main category: quant-ph

TL;DR: 驱动两能级系统在非马尔可夫环境中表现出鲁棒的相位同步，该现象在驱动幅度与频率之比等于贝塞尔函数J0的零点时出现。


<details>
  <summary>Details</summary>
Motivation: 研究与非马尔可夫环境耦合的驱动两能级系统中的相位同步现象。

Method: 在不使用旋转波近似的情况下，通过分层方程模拟了系统-浴耦合和相干驱动的动力学。

Result: 观察到鲁棒的相位锁定，并且当驱动幅度与频率之比满足共振比条件（即该比值等于贝塞尔函数J0的零点）时，同步度量会迅速获得一个有限值。

Conclusion: 通过对周期性驱动哈密顿量的傅里叶分析得出的静态近似，为观察到的相位同步现象提供了理论解释。

Abstract: We study phase-synchronization in a driven two-level system coupled to a
non-Markovian bosonic reservoir. The dynamics is described by treating the
system-bath coupling and the coherent drive without invoking the rotating-wave
approximation, and simulated using the numerically exact hierarchical equations
of motion. We observe that a robust phase-locking develops and that the
corresponding synchronization measure rapidly acquires a finite value when the
system is tuned to what we identify as a resonant-ratio condition, namely when
the ratio between the drive amplitude and its frequency coincides with a zero
of the Bessel function $J_0$. We provide an explanation for this phenomenon by
means of a static approximation derived from a Fourier analysis of the
periodically driven Hamiltonian.

</details>


### [347] [A General Strategy for Realizing Mpemba Effects in Open Quantum Systems](https://arxiv.org/abs/2511.04354)
*Yaru Liu,Yucheng Wang*

Main category: quant-ph

TL;DR: Mpemba效应在量子系统中通常只对特定初始状态有效，本研究提出了一种通过暂时性键-耗散淬灭来操控弛豫路径的通用策略，以实现量子Mpemba效应（QME）和反向QME，该策略适用于包含退相干和边界耗散的系统，并提出了冷原子实现方案。


<details>
  <summary>Details</summary>
Motivation: Mpemba效应在开放量子系统中通常只对特定初始状态出现，限制了其普适性，因此需要寻找一种通用的方法来实现量子Mpemba效应。

Method: 通过施加暂时的键-耗散淬灭，选择性地抑制或增强缓慢的弛豫模式，从而独立于系统和初始状态来重塑弛豫路径。

Result: 在包含退相干和边界耗散的系统中演示了该机制，并提出了冷原子实现的可行方案，成功实现了量子Mpemba效应和反向量子Mpemba效应。

Conclusion: 可控耗散是一种强大的量子控制工具，可用于加速弛豫和实现高效的非平衡协议。

Abstract: The Mpemba effect, where a state farther from equilibrium relaxes faster than
one closer to it, is a striking phenomenon in both classical and quantum
systems. In open quantum systems, however, the quantum Mpemba effect (QME)
typically occurs only for specifically chosen initial states, which limits its
universality. Here we present a general and experimentally feasible strategy to
realize both QME and anti-QME. By applying a temporary bond-dissipation quench,
we selectively suppresses or enhances slow relaxation modes, thereby reshaping
relaxation pathways independently of both the system and the initial state. We
demonstrate this mechanism in systems with dephasing and boundary dissipation,
and outline feasible cold-atom implementations. Our results establish
controllable dissipation as a versatile tool for quantum control, accelerated
relaxation, and efficient nonequilibrium protocols.

</details>


### [348] [Neutral-atom quantum computation using multi-qubit geometric gates via adiabatic passage](https://arxiv.org/abs/2511.04359)
*Sinchan Snigdha Rej,Bimalendu Deb*

Main category: quant-ph

TL;DR: 通过利用双STIRAP脉冲序列在可扩展的中性原子体系中实现高保真度的几何相位量子门，并证明其在模拟量子搜索算法中的有效性。


<details>
  <summary>Details</summary>
Motivation: 与依赖动力学相位累积的传统基于里德堡阻挡的相位门相比，绝热几何相位门对量子比特具有更好的鲁棒性。

Method: 提出了一种基于双STIRAP（双受激拉曼绝热通道）脉冲序列的两比特和多比特量子门方案，利用该序列在量子比特系统上产生可控的几何相位。该方案设计为每个原子都可单独寻址，并且在从两比特扩展到多比特量子门时，无需在目标原子上应用额外的激光。

Result: 数值分析表明，在$	extContent{0.6}	ext{ }	ext{μs}$的门操作时间下，可以实现98%到99%的保真度。通过系统误差分析，发现所提出的量子门对Rabi频率、有限阻挡强度和原子位置变化的波动具有很强的抵抗力。在模拟Grover搜索算法时，对于两、三、四比特系统，均实现了很高的成功概率。

Conclusion: 所提出的方案为基于中性原子的容错量子计算提供了一条物理上可行且可扩展的途径。

Abstract: Adiabatic geometric phase gates offer enhanced robustness against
fluctuations compared to con- ventional Rydberg blockade-based phase gates that
rely on dynamical phase accumulation. We theoretically demonstrate two- and
multi-qubit phase gates in a neutral atom architecture, relying on a double
stimulated Raman adiabatic passage (double-STIRAP) pulse sequence that imprints
a controllable geometric phase on the qubit systems. The system is designed in
such a way that every atom is individually addressable, and moreover, no extra
laser is required to be applied on the target atom while scaling up the system
from two- to multi-qubit quantum gates. The gate fidelity has been numerically
analyzed by changing the gate operation time, and we find that 98% to 99%
fidelity can be achieved for gate time $\simeq$ 0.6 $\mu$s. We perform a
systematic error analysis, which re- veals that our proposed gates can exhibit
strong resilience against fluctuations in Rabi frequencies, finite blockade
strength, and atomic position variations. These results establish our approach
as a physically feasible and scalable pathway toward fault-tolerant quantum
computation with neutral atoms. We simulate Grover's search algorithm for two-,
three-, and four-qubit systems with high success probability and thereby
demonstrate the utility and scalability of our proposed gates for quantum
computation.

</details>


### [349] [Minimum measurements quantum protocol for band structure calculation](https://arxiv.org/abs/2511.04389)
*Michal Krejčí,Lucie Krejčí,Ijaz Ahamed Mohammad,Martin Plesch,Martin Friák*

Main category: quant-ph

TL;DR: 该研究提出了一种量子测量协议，可将量子计算中电子结构计算的测量设置减少到仅三个，独立于量子比特数量，并已在CuO2和双层石墨烯系统上进行了演示。


<details>
  <summary>Details</summary>
Motivation: 量子计算中的测量协议是量子计算的关键组成部分，但不同的可观测对象通常需要不同的测量基，导致测量配置数量随着量子比特数量的增加而增加，成为一个主要瓶颈。本研究旨在解决这一问题，特别是在结晶系统电子结构计算的背景下。

Method: 该研究从紧束缚（TB）哈密顿量的对称性出发，推导了一种测量协议，并将其集成到变分量子缩减（VQD）算法中。通过在二维CuO2方格晶格（3个量子比特）和双层石墨烯（4个量子比特）系统上进行实现来展示其性能。

Result: 所提出的协议将测量设置数量减少到仅三个，与量子比特数量无关。在CuO2和双层石墨烯系统上的演示表明了该协议的有效性。

Conclusion: 该测量协议显著减少了测量设置的数量，独立于量子比特数量，并可推广到更多具有高对称性的多体哈密顿量，为未来实现量子优势提供了可能。

Abstract: Protocols for quantum measurement are an essential part of quantum computing.
Measurements are no longer confined to the final step of computation but are
increasingly embedded within quantum circuits as integral components of
noise-resilient algorithms. However, each observable typically requires a
distinct measurement basis, often demanding a different circuit configuration.
As the number of such configurations typically grows with the number of qubits,
different measurement configurations constitute a major bottleneck. Focusing on
electronic structure calculations in crystalline systems, we propose a
measurement protocol that maximally reduces the number of measurement settings
to just three, independent of the number of qubits. This makes it one of the
few known protocols that do not scale with qubit number. In particular, we
derive the measurement protocol from the symmetries of tight-binding (TB)
Hamiltonians and implement it within the Variational Quantum Deflation (VQD)
algorithm. We demonstrate its performance on two systems, namely a
two-dimensional CuO$_2$ square lattice (3 qubits) and bilayer graphene (4
qubits). The protocol can be generalized to more complex many-body Hamiltonians
with high symmetry, providing a potential path toward future demonstrations of
quantum advantage.

</details>


### [350] [Microwave Output Stabilization of a Qubit Controller via Device-Level Temperature Control](https://arxiv.org/abs/2511.04397)
*Yoshinori Kurimoto,Dongjun Lee,Koichiro Ban,Shinichi Morisaka,Toshi Sumida,Hidehisa Shiomi,Yosuke Ito,Yuuya Sugita,Makoto Negoro,Ryutaro Ohira,Takefumi Miyoshi*

Main category: quant-ph

TL;DR: QuEL-1 SE是一个多通道超导量子比特控制器，通过主动热稳定关键模拟集成电路来抑制长期幅度和相位漂移，其性能表明能够实现可靠的长时间量子操作。


<details>
  <summary>Details</summary>
Motivation: 为了抑制长期幅度和相位漂移，提高量子比特控制的稳定性和可靠性。

Method: 设计并实现了一个名为QuEL-1 SE的多通道量子比特控制器，该控制器包含对锁相环、放大器和混频器等关键模拟集成电路的主动热稳定功能。通过在24小时内使用共用模数转换器同时监测15个微波输出通道，评估其幅度和相位稳定性。进一步评估这些偏差对量子门操作的影响，估计在相干误差下的Xπ/2门平均保真度。

Result: 归一化幅度标准偏差为0.09%--0.22%（平均值0.15%），相位偏差为0.35°--0.44°（平均值0.39°）。幅度误差导致的门保真度下降为2×10⁻⁶，相位误差为2×10⁻⁵，远低于表面码等容错阈值。

Conclusion: QuEL-1 SE的幅度和相位稳定性使其能够实现可靠的长时间量子操作，可作为可扩展的控制平台用于超导和其他量子比特模态。

Abstract: We present the design and performance of QuEL-1 SE, which is a multichannel
qubit controller developed for superconducting qubits. The system incorporates
the active thermal stabilization of critical analog integrated circuits, such
as phase-locked loops, amplifiers, and mixers, to suppress the long-term
amplitude and phase drift. To evaluate the amplitude and phase stability, we
simultaneously monitor 15 microwave output channels over 24 h using a common
analog-to-digital converter. Across the channels, the normalized amplitude
exhibits standard deviations of 0.09\%--0.22\% (mean: 0.15\%), and the phase
deviations are 0.35$^\circ$--0.44$^\circ$ (mean: 0.39$^\circ$). We further
assess the impact of these deviations on quantum gate operations by estimating
the average fidelity of an $X_{\pi/2}$ gate under the coherent errors
corresponding to the deviations. The resulting gate infidelities are $2\times
10^{-6}$ for amplitude errors and $2\times 10^{-5}$ for phase errors, which are
significantly lower than typical fault-tolerance thresholds such as those of
the surface code. These results demonstrate that the amplitude and phase
stability of QuEL-1 SE enables reliable long-duration quantum operations, thus
highlighting its utility as a scalable control platform for superconducting and
other qubit modalities.

</details>


### [351] [Tight Analysis of a Grover-based Quantum Secret Sharing Scheme](https://arxiv.org/abs/2511.04399)
*Santanu Majhi,Debajyoti Bera*

Main category: quant-ph

TL;DR: 该论文提出了一种基于量子搜索的秘密共享框架，并对其进行了安全性分析和改进。


<details>
  <summary>Details</summary>
Motivation: 现有量子秘密共享协议通常需要多轮通信来检测窃听，或者需要安全通信通道。该研究旨在提出一种可在公共通道上运行，且无需多轮通信即可检测窃听的量子秘密共享方案。

Method: 对 Hsu (2003) 提出的量子搜索秘密共享框架进行了完整的正确性和安全性分析，并在此基础上改进了原协议，提高了其抗窃听能力。

Result: 分析表明，尽管改进后的协议提高了抗窃听能力，但该框架无法实现完全抵抗窃听。

Conclusion: Hsu (2003) 的量子搜索秘密共享框架虽然可以在公共通道上运行并进行窃听检测，但无法保证完全安全性。

Abstract: Secret-sharing schemes allow a dealer to split a secret into multiple
"shares" and distribute them individually among many parties while mandating
certain constraints on its reconstruction. Such protocols are usually executed
over a secure communication channel since an eavesdropper, after intercepting
all the shares, is expected to be able to reconstruct the secret. Leveraging
the unique properties of quantum channels, several quantum protocols have been
designed for secret sharing. However, almost all of them detect the presence of
an eavesdropper by statistical analysis of the outcome of multiple rounds, or
simply require a secure channel of communication.
  We present a complete characterisation of the correctness and security
properties of a quantum-search based secret-sharing framework proposed by Hsu
(2003). The scheme was designed to work over public channels without requiring
multiple rounds to detect eavesdropping. Our characterisation allowed us to
improve the original protocol to be more resistant towards eavesdropping.
However, we prove that complete security against an eavesdropper is not
possible in this framework.

</details>


### [352] [Mixed-State Measurement-Induced Phase Transitions in Imaginary-Time Dynamics](https://arxiv.org/abs/2511.04402)
*Yi-Ming Ding,Zenan Liu,Xu Tian,Zhe Wang,Yanzhang Zhu,Zheng Yan*

Main category: quant-ph

TL;DR: MDITE是一种探索混合态量子相和退相干驱动的临界性的新框架，通过交替进行虚时演化和测量来实现，并且可以使用量子蒙特卡洛等方法进行大规模数值研究。


<details>
  <summary>Details</summary>
Motivation: 混合态相变是研究非平衡量子物质和量子信息的一个新领域。

Method: 提出了一种称为测量时间演化（MDITE）的新框架，该框架通过交替进行虚时演化和投影测量来探索混合态量子相和退相干驱动的临界性。

Result: 在模拟的一维横向场伊辛模型和二维二聚海森堡模型中，MDITE能够产生一类新的混合态相变。

Conclusion: MDITE为研究非酉动力学和退相干在多体量子系统中的作用提供了一个强大的范式。

Abstract: Mixed-state phase transitions have recently attracted growing attention as a
new frontier in nonequilibrium quantum matter and quantum information. In this
work, we introduce the measurement-dressed imaginary-time evolution (MDITE) as
a novel framework to explore mixed-state quantum phases and decoherence-driven
criticality. In this setup, alternating imaginary-time evolution and projective
measurements generate a competition between coherence-restoring dynamics and
decoherence-inducing events. While reminiscent of monitored unitary circuits,
MDITE fundamentally differs in that the physics is encoded in decoherent mixed
states rather than in quantum trajectories. We demonstrate that this interplay
gives rise to a new class of mixed-state phase transitions, using numerical
simulations of the one-dimensional transverse-field Ising model and the
two-dimensional dimerized Heisenberg model. Furthermore, we provide a
diagrammatic representation of the evolving state, which naturally enables
efficient studies of MDITE with quantum Monte Carlo and other many-body
numerical methods, thereby extending investigations of mixed-state phase
transitions to large-scale and higher-dimensional Hamiltonians. Our results
highlight MDITE as a powerful paradigm for investigating non-unitary dynamics
and the fundamental role of decoherence in many-body quantum systems.

</details>


### [353] [Robustness of quantum data hiding against entangled catalysts and memory](https://arxiv.org/abs/2511.04408)
*Aby Philip,Alexander Streltsov*

Main category: quant-ph

TL;DR: 量子数据隐藏使用经典信息来编码量子状态，但其本质是即使可以区分，如果没有量子通信通道也几乎无法区分。本研究探讨了在通信双方拥有额外量子资源的情况下，是否能克服这一限制。


<details>
  <summary>Details</summary>
Motivation: 本研究旨在探索在通信双方拥有额外量子资源（如纠缠催化剂或量子记忆）的辅助下，能否克服量子数据隐藏中“几乎无法区分”的限制。

Method: 研究开发了一个通用的状态判别框架，该框架统一了催化和记忆辅助的局部分别率协议，并分析了它们揭示隐藏信息的能力。推导了当隐藏状态可分离时，纠缠催化剂或量子记忆都无法提高最优判别概率的结论。进一步研究了对于某些纠缠状态，可重复使用的量子记忆如何将本地不可区分的状态转变为几乎可完美区分的状态。

Result: 证明了当隐藏状态是可分离的时，无论是纠缠催化剂还是量子记忆，都不能提高最优判别概率，这表明了可分离数据隐藏方案的鲁棒性。相反，对于某些纠缠状态，可重复使用的量子记忆可以将本地不可区分的状态转变为几乎可以完美区分的状态。

Conclusion: 本研究结果界定了催化和记忆辅助状态判别的基本限制，并确定可分离编码是量子数据隐藏的一种鲁棒策略。

Abstract: Quantum data hiding stores classical information in bipartite quantum states
that are, in principle, perfectly distinguishable, yet remain almost
indistinguishable without access to a quantum communication channel. Here, we
investigate whether this limitation can be overcome when the communicating
parties are assisted by additional quantum resources. We develop a general
framework for state discrimination that unifies catalytic and memory-assisted
local discrimination protocols and analyze their power to reveal hidden
information. We prove that when the hiding states are separable, neither
entangled catalysts nor quantum memory can increase the optimal discrimination
probability, establishing the robustness of separable data-hiding schemes. In
contrast, for some entangled states, a reusable quantum memory turns locally
indistinguishable states into ones that can be discriminated almost perfectly.
Our results delineate the fundamental limits of catalytic and memory-assisted
state discrimination and identify separable encodings as a robust strategy for
quantum data hiding.

</details>


### [354] [Quantum doubles in symmetric blockade structures](https://arxiv.org/abs/2511.04414)
*Hans Peter Büchler,Tobias F. Maier,Simon Fell,Nicolai Lang*

Main category: quant-ph

TL;DR: 使用简单的双体相互作用，为里德伯原子设计了一个哈密顿量，实现了非阿贝尔任意子拓扑序。


<details>
  <summary>Details</summary>
Motivation: 给定的微观系统具有实验上可行的两体相互作用，如何设计一个哈密顿量来实现期望的拓扑相？

Method: 通过里德伯原子平台，利用简单的阻塞相互作用来构建哈密顿量，该哈密顿量实现了非阿贝尔量子双模型所描述的拓扑序。

Result: 分析证明了基态中拓扑序的存在，并提出了制备这些状态的有效方案。还引入了用于受控绝热编织任意子激发以探测其非阿贝尔统计的协议。

Conclusion: 该构造是通用的，适用于任意有限群 G 的量子双模型 D(G)，并以 S3 的最小非阿贝尔量子双 D(S3) 为例进行了说明。

Abstract: Exactly solvable models of topologically ordered phases with non-abelian
anyons typically require complicated many-body interactions which do not
naturally appear in nature. This motivates the "inverse problem" of quantum
many-body physics: given microscopic systems with experimentally realistic
two-body interactions, how to design a Hamiltonian that realizes a desired
topological phase? Here we solve this problem on a platform motivated by
Rydberg atoms, where elementary two-level systems couple via simple blockade
interactions. Within this framework, we construct Hamiltonians that realize
topological orders described by non-abelian quantum double models. We
analytically prove the existence of topological order in the ground state, and
present efficient schemes to prepare these states. We also introduce protocols
for the controlled adiabatic braiding of anyonic excitations to probe their
non-abelian statistics. Our construction is generic and applies to quantum
doubles $\mathcal{D}(G)$ for arbitrary finite groups $G$. We illustrate
braiding for the simplest non-abelian quantum double $\mathcal{D}(S_3)$.

</details>


### [355] [Estimating ground-state properties in quantum simulators with global control](https://arxiv.org/abs/2511.04434)
*Cristian Tabares,Dominik S. Wild,J. Ignacio Cirac,Peter Zoller,Alejandro González-Tudela,Daniel González-Cuadra*

Main category: quant-ph

TL;DR: 我们提出了一种仅使用目标哈密顿量下的全局时间演化来估计量子多体系统基态能量的协议，从而避免了传统量子相位估计算法所需的受控操作。


<details>
  <summary>Details</summary>
Motivation: 准确确定量子多体系统的基态性质是量子模拟的主要挑战之一。

Method: 通过测量洛施密特回声和直接能量测量来提取能量差，并求解方程组以推断个别特征能量。

Result: 该协议在自由费米子系统上进行了基准测试，精度比初始状态的直接能量测量提高了几个数量级，并且在数百个模式下精度仍然很高。该方法也适用于二维伊辛模型和费米-哈伯德模型，并且可以自然地扩展到其他可观测量，如序参量。

Conclusion: 这项工作为使用全局控制的量子模拟器以高精度计算物理相关量提供了一条实用的途径。

Abstract: Accurately determining ground-state properties of quantum many-body systems
remains one of the major challenges of quantum simulation. In this work, we
present a protocol for estimating the ground-state energy using only global
time evolution under a target Hamiltonian. This avoids the need for controlled
operations that are typically required in conventional quantum phase estimation
and extends the algorithm applicability to analog simulators. Our method
extracts energy differences from measurements of the Loschmidt echo over an
initial ground-state approximation, combines them with direct energy
measurements, and solves a set of equations to infer the individual
eigenenergies. We benchmark this protocol on free-fermion systems, showing
orders-of-magnitude precision gains over direct energy measurements on the
initial state, with accuracy improving rapidly with initial-state fidelity and
persisting for hundreds of modes. We further demonstrate applicability to the
2D Ising and Fermi-Hubbard models and show that the approach extends naturally
to other observables such as order parameters. Finally, we analyze the effect
of experimental imperfections and propose error-mitigation strategies. These
results establish a practical route to compute physically relevant quantities
with high precision using globally controlled quantum simulators.

</details>


### [356] [Limiting one-way distillable secret key via privacy testing of extendible states](https://arxiv.org/abs/2511.04438)
*Vishal Singh,Karol Horodecki,Aby Philip,Mark M. Wilde*

Main category: quant-ph

TL;DR: 本论文确定了任意k-可扩展状态通过隐私测试的最大概率，并证明该概率等于任意k-可扩展状态与标准最大纠缠状态之间的最大保真度。


<details>
  <summary>Details</summary>
Motivation: 隐私测试和k-可扩展状态在量子信息理论中对于理解安全通信的限制至关重要。

Method: 通过研究k-可扩展状态通过隐私测试的概率，并利用k-不可扩展性的资源理论。

Result: 得出了单次单向可蒸馏密钥和单次单向可蒸利亚纠缠的有效可计算上限。此外，还为信道的单次前向辅助私有容量建立了有效可计算的上限。并将这些形式主义扩展到独立同分布设置，得到了状态的n次单向可蒸馏密钥和信道的n次前向辅助私有容量的单字母有效可计算界限。

Conclusion: 本研究为量子信息理论中的隐私和安全通信提供了新的界限和有效可计算的度量。

Abstract: The notions of privacy tests and $k$-extendible states have both been
instrumental in quantum information theory, particularly in understanding the
limits of secure communication. In this paper, we determine the maximum
probability with which an arbitrary $k$-extendible state can pass a privacy
test, and we prove that it is equal to the maximum fidelity between an
arbitrary $k$-extendible state and the standard maximally entangled state. Our
findings, coupled with the resource theory of $k$-unextendibility, lead to an
efficiently computable upper bound on the one-shot, one-way distillable key of
a bipartite state, and we prove that it is equal to the best-known efficiently
computable upper bound on the one-shot, one-way distillable entanglement. We
also establish efficiently computable upper bounds on the one-shot,
forward-assisted private capacity of channels. Extending our formalism to the
independent and identically distributed setting, we obtain single-letter
efficiently computable bounds on the $n$-shot, one-way distillable key of a
state and the $n$-shot, forward-assisted private capacity of a channel. For
some key examples of interest, our bounds are significantly tighter than other
known efficiently computable bounds.

</details>


### [357] [Robust certification of non-projective measurements: theory and experiment](https://arxiv.org/abs/2511.04446)
*Raphael Brinster,Peter Tirler,Shishir Khandelwal,Michael Meth,Hermann Kampermann,Dagmar Bruß,Rainer Blatt,Martin Ringbauer,Armin Tavakoli,Nikolai Wyderka*

Main category: quant-ph

TL;DR: POVMs 的非模拟性可以通过半定规划层级来认证，并在实验中得到验证。


<details>
  <summary>Details</summary>
Motivation: 区分可模拟 POVM 和不可模拟 POVM 的边界是一个具有挑战性的问题，现有的工具在可扩展性、实验可行性或适用范围方面存在局限性。

Method: 引入一个半定规划层级来认证 POVM 的非模拟性，并提供关键可见性非模拟性度量的上限。

Result: 提出的方法在许多情况下是精确的，并且优于先前已知的标准。实验上使用囚禁离子量子处理器认证了二维和三维 POVM 的非模拟性，并提出了一个对状态制备误差具有鲁棒性的框架。

Conclusion: 该研究为理解和利用 POVM 的优势提供了一个强大的新工具，并为未来的实验研究开辟了道路。

Abstract: Determining the conditions under which positive operator-valued measures
(POVMs), the most general class of quantum measurements, outperform projective
measurements remains a challenging and largely unresolved problem. Of
particular interest are projectively simulable POVMs, which can be realized
through probabilistic mixtures of projective measurements, and therefore offer
no advantage over projective schemes. Characterizing the boundary between
simulable and non-simulable POVMs is, however, a difficult task, and existing
tools either fail to scale efficiently, provide limited experimental
feasibility or work only for specific POVMs. Here, we introduce and demonstrate
a general method to certify non-simulability of a POVM by introducing a
hierarchy of semidefinite programs. It provides upper bounds on the
non-simulability measure of critical visibility of arbitrary POVMs which are
tight in many cases and outperform previously known criteria. We experimentally
certify the non-simulability of two- and three-dimensional POVMs using a
trapped-ion qudit quantum processor by constructing non-simulability witnesses
and introduce a modification of our framework that makes them robust against
state preparation errors. Finally, we extend our results to the setting where
an additional ancilla system is available.

</details>


### [358] [Hybrid Single-Ion Atomic-Ensemble Node for High-Rate Remote Entanglement Generation](https://arxiv.org/abs/2511.04488)
*Benedikt Tissot,Soubhadra Maiti,Emil R. Hellebek,Anders Søndberg Sørensen*

Main category: quant-ph

TL;DR: 利用混合量子网络架构，通过结合离子阱和稀土离子系综，解决了不同量子系统的带宽匹配问题，显著加速了远距离离子-离子纠缠的生成。


<details>
  <summary>Details</summary>
Motivation: 量子网络的发展受益于不同量子系统的优势，例如系综量子存储器擅长生成纠缠，而单原子系统则擅长信息处理。将这些系统结合起来可以提高纠缠生成速率。

Method: 提出并实现了一种混合量子网络架构，该架构结合了离子阱节点和基于稀土离子系综的自发参量下转换光子对源及吸收量子存储器节点。通过解决光子带宽匹配问题，实现了并行执行多个概率性任务。

Result: 该混合架构成功解决了不同量子系统间的光子带宽不匹配问题，并展示了在远距离（数百公里）量子网络中生成离子-离子纠缠方面具有显著的加速效果。

Conclusion: 所提出的混合量子网络架构能够有效结合不同量子存储器的优点，并通过带宽匹配技术克服了量子网络中信息处理的瓶颈，为高速、远距离的量子通信奠定了基础。

Abstract: Different quantum systems possess different favorable qualities. On the one
hand, ensemble-based quantum memories are suited for fast multiplexed
long-range entanglement generation. On the other hand, single-atomic systems
provide access to gates for processing of information. Both of those can
provide advantages for high-rate entanglement generation within quantum
networks. We develop a hybrid architecture that takes advantage of these
properties by combining trapped-ion nodes and nodes comprised of spontaneous
parametric down conversion photon pair sources and absorptive memories based on
rare-earth ion ensembles. To this end, we solve the central challenge of
matching the different bandwidths of photons emitted by those systems in an
initial entanglement-generation step. This enables the parallel execution of
multiple probabilistic tasks in the initial stage. We show that our approach
can lead to a significant speed-up for the fundamental task of creating ion-ion
entanglement over hundreds of kilometers in a quantum network.

</details>


### [359] [Continuous matrix product operators for quantum fields](https://arxiv.org/abs/2511.04545)
*Erickson Tjoa,J. Ignacio Cirac*

Main category: quant-ph

TL;DR: 新的连续矩阵乘积算子ansatz被提出，可应用于量子场论，并保持了纠缠面积定律。


<details>
  <summary>Details</summary>
Motivation: 引入一种适用于量子场论的连续矩阵乘积算子ansatz。

Method: 提出一种新的ansatz，证明其具有闭合形式，可通过矩阵乘积算子获得连续极限，并保持纠缠面积定律。

Result: 该ansatz可直接在连续域中保持纠缠面积定律，并将连续矩阵乘积状态映射到另一个连续矩阵乘积状态，还可用于构建量子胞自动化之外的连续矩阵乘积酉。

Conclusion: 该ansatz为量子场论提供了一种新的工具，并有广泛的应用前景。

Abstract: In this work we introduce an ansatz for continuous matrix product operators
for quantum field theory. We show that (i) they admit a closed-form expression
in terms of finite number of matrix-valued functions without reference to any
lattice parameter; (ii) they are obtained as a suitable continuum limit of
matrix product operators; (iii) they preserve the entanglement area law
directly in the continuum, and in particular they map continuous matrix product
states (cMPS) to another cMPS. As an application, we use this ansatz to
construct several families of continuous matrix product unitaries beyond
quantum cellular automata.

</details>


### [360] [Scaling advantage with quantum-enhanced memetic tabu search for LABS](https://arxiv.org/abs/2511.04553)
*Alejandro Gomez Cadavid,Pranav Chandarana,Sebastián V. Romero,Jan Trautmann,Enrique Solano,Taylor Lee Patti,Narendra N. Hegade*

Main category: quant-ph

TL;DR: QE-MTS是一种混合算法，通过结合量子优化和经典搜索，在LABS问题上实现了比现有经典算法更好的可扩展性。


<details>
  <summary>Details</summary>
Motivation: 解决低自相关二元序列（LABS）问题，并寻求比现有经典启发式算法更好的可扩展性。

Method: 将量子优化的高质量初始状态（来自DCQO）用于经典MTS算法，提出量子增强的模因禁忌搜索（QE-MTS）。

Result: QE-MTS在LABS问题上的时间-解决方案缩放比例达到$\"".O(1.24^N)\"".，优于已知的最佳经典启发式算法（$\"".O(1.34^N)\"".）和量子近似优化算法（$\"".O(1.46^N)\"".），同时电路深度减少了6倍。引导分析证实了其优势，并预测在N>47时QE-MTS将超越经典方法。

Conclusion: 量子增强可以直接提高经典优化算法在LABS问题上的可扩展性。

Abstract: We introduce quantum-enhanced memetic tabu search (QE-MTS), a non-variational
hybrid algorithm that achieves state-of-the-art scaling for the
low-autocorrelation binary sequence (LABS) problem. By seeding the classical
MTS with high-quality initial states from digitized counterdiabatic quantum
optimization (DCQO), our method suppresses the empirical time-to-solution
scaling to $\mathcal{O}(1.24^N)$ for sequence length $N \in [27,37]$. This
scaling surpasses the best-known classical heuristic $\mathcal{O}(1.34^N)$ and
improves upon the $\mathcal{O}(1.46^N)$ of the quantum approximate optimization
algorithm, achieving superior performance with a $6\times$ reduction in circuit
depth. A two-stage bootstrap analysis confirms the scaling advantage and
projects a crossover point at $N \gtrsim 47$, beyond which QE-MTS outperforms
its classical counterpart. These results provide evidence that quantum
enhancement can directly improve the scaling of classical optimization
algorithms for the paradigmatic LABS problem.

</details>


### [361] [Preferred Basis in Coupled Electron-Nuclear Dynamics](https://arxiv.org/abs/2511.04559)
*Junhyeok Bang*

Main category: quant-ph

TL;DR: 提出了一种新的电子-核动力学模拟方法，该方法基于量子退相干理论中的指针态和优选态概念，能够提高模拟精度并提供更清晰的物理图像。


<details>
  <summary>Details</summary>
Motivation: 目前的量子动力学理解局限于绝热机制，并且模拟的表示选择会影响物理解释和模拟精度。需要一种更有效的表示方法来处理电子-核相互作用强烈的系统。

Method: 提出了一种基于退相干理论中指针态和优选态概念的电子-核动力学新框架。在此框架下，分析了混合量子经典（MQC）方法中的独立动力学行为，并将其与优选基下的纠缠联系起来。同时，论证了绝热绝热玻恩-奥本海默态满足近似优选基的条件。

Result: 1）证明了MQC方法中的独立动力学是优选基下的一种纠缠表现，而非退相干的直接结果。2）表明绝热玻恩-奥本海默态是近似优选基。

Conclusion: 该方法通过优选态的视角重新审视了MQC方法，阐明了其有效性和改进方向，为发展更可靠的MQC策略提供了系统性途径，并统一了常用近似与更基本的理论结构。

Abstract: Beyond the adiabatic regime, our understanding of quantum dynamics in coupled
systems remains limited, and the choice of representation continues to obscure
physical interpretation and simulation accuracy. Here we propose a natural and
efficient basis for electron nuclear dynamics by drawing on the concepts of
pointer and preferred states from decoherence theory, adapted to systems where
electrons and nuclei interact strongly. Within this framework, we show that 1)
the independent dynamics exploited by mixed quantum classical (MQC) methods is
best understood as a manifestation of entanglement viewed in a preferred basis,
rather than a consequence of decoherence, and 2) the adiabatic Born Oppenheimer
states satisfy the conditions of an approximate preferred basis. This
perspective reconciles widely used approximations with a more fundamental
structure of the theory and provides a systematic route to more reliable MQC
strategies. In effect, we revisit MQC methods through the lens of preferred
states, clarifying when they succeed and how they can be improved.

</details>


### [362] [QEF: Reproducible and Exploratory Quantum Software Experiments](https://arxiv.org/abs/2511.04563)
*Vincent Gierisch,Wolfgang Mauerer*

Main category: quant-ph

TL;DR: QEF 是一个轻量级框架，旨在支持量子算法的系统性、驱动性研究。


<details>
  <summary>Details</summary>
Motivation: 现有工具隐藏配置或需要临时脚本，阻碍了量子计算实验的研究。

Method: QEF 通过简洁的规范捕捉量子软件和算法实验的关键方面，并生成参数的笛卡尔积以进行大规模参数扫描。它支持异步作业、超参数可追溯性、参数重用以及与标准统计和可视化软件的便捷集成。

Result: QEF 能够进行严谨、系统的评估，并实现精确的可复现性。

Conclusion: QEF 旨在通过提供可复现性和可扩展性，同时避免复杂的工作流引擎，来降低量子算法实证研究的实际门槛。

Abstract: Commercially available Noisy Intermediate-Scale Quantum (NISQ) devices now
make small hybrid quantum-classical experiments practical, but many tools hide
configuration or demand ad-hoc scripting.
  We introduce the Quantum Experiment Framework (QEF): A lightweight framework
designed to support the systematic, hypothesis-driven study of quantum
algorithms. Unlike many existing approaches, QEF emphasises iterative,
exploratory analysis of evolving experimental strategies rather than exhaustive
empirical evaluation of fixed algorithms using predefined quality metrics. The
framework's design is informed by a comprehensive review of the literature,
identifying principal parameters and measurement practices currently reported
in the field.
  QEF captures all key aspects of quantum software and algorithm experiments
through a concise specification that expands into a Cartesian product of
variants for controlled large-scale parameter sweeps. This design enables
rigorous and systematic evaluation, as well as precise reproducibility. Large
sweeps are automatically partitioned into asynchronous jobs across simulators
or cloud hardware, and ascertain full hyper-parameter traceability. QEF
supports parameter reuse to improve overall experiment runtimes, and collects
all metrics and metadata into a form that can be conveniently explored with
standard statistical and visualisation software.
  By combining reproducibility and scalability while avoiding the complexities
of full workflow engines, QEF seeks to lower the practical barriers to
empirical research on quantum algorithms, whether these are designed for
current NISQ devices or future error-corrected quantum systems.

</details>


### [363] [Homodyne detection for pulse-by-pulse squeezing measurements](https://arxiv.org/abs/2511.04578)
*Tiphaine Kouadou,Elie Gozlan,Loïc Garcia,David Polizzi,David Fainsin,Iris Paparelle,R. L. Rincón Celis,Bastien Oriot,Anthony Abi Aad,Peter Namdar,Ganaël Roland,Nicolas Treps,Bérengère Argence,Valentina Parigi*

Main category: quant-ph

TL;DR: 本研究介绍了能够在150兆赫兹重复频率下运行的宽带外差探测器，并成功用其解析了压缩态光脉冲的脉冲内结构。


<details>
  <summary>Details</summary>
Motivation: 连续变量量子信息处理需要相位敏感的测量技术，但现有的外差探测器受限于电子器件的性能，难以在高重频脉冲操作下工作。

Method: 设计并实现了一种新型宽带外差探测器，使其能够在近红外和电信波长下工作，并优化其性能以支持高达150兆赫兹的重复频率。通过该探测器解析了电信波长下的压缩态光脉冲的结构。

Result: 所提出的宽带外差探测器能够在高达150兆赫兹的重复频率下运行。实验成功解析了压缩态光脉冲的脉冲内结构，并保持了其光谱多模特性。

Conclusion: 新型宽带外差探测器克服了传统探测器的电子限制，实现了高重频脉冲操作，为连续变量量子信息处理的发展提供了关键技术支持。

Abstract: Homodyne detection is a phase-sensitive measurement technique, essential for
the characterization of continuous-variable (CV)-encoded quantum states of
light. It is a key component to the implementation of CV quantum-information
protocols and benefits from operating, by design, at room temperature. However,
performing high-speed quantum information processing remains a major challenge,
as conventional homodyne detectors often fail to sustain pulsed operation at
high repetition rates due to electronic limitations. We present wideband
homodyne detectors operating at near-infrared (NIR) and telecom wavelengths,
with optimized performance at repetition rates up to 150 MHz. We demonstrate
their performance by resolving the pulse-by-pulse structure of squeezed states
of light at telecom wavelengths while preserving their spectral multimode
properties.

</details>


### [364] [Controlling Hong-Ou-Mandel antibunching via parity governed spectral shaping of biphoton states](https://arxiv.org/abs/2511.04604)
*Mikhail Guselnikov,Alexei D. Kiselev,Andrei Gaidash,George Miroshnichenko,Anton Kozubov*

Main category: quant-ph

TL;DR: 该研究通过对称度参数Ds表征了Hong-Ou-Mandel (HOM) 聚束和反聚束现象，并发现Ds的符号主要取决于光谱函数φ12(ω)的奇偶性。研究还展示了如何通过实验可控的光谱相位调制来切换聚束和反聚束状态，并计算了在调制参数变化下 따른 施密特数，发现了与Ds下降相对应的窄共振峰。


<details>
  <summary>Details</summary>
Motivation: 研究HOM聚束和反聚束现象，并探索实现和控制这些现象的方法。

Method: 提出对称度参数Ds来表征HOM聚束和反聚束现象，Ds的计算基于双光子联合谱幅度JSA的对称和反对称部分的贡献。重点分析了JSA为特定形式（乘积形式乘以高斯纠缠因子）的类，其中Ds的符号由光谱函数φ12(ω)的奇偶性决定。通过实验可实现的光谱相位调制（通过路径长度的亚纳米级变化）来生成调制双光子态，并计算了施密特数与调制参数的关系。

Result:  Ds的符号主要由光谱函数φ12(ω)的奇偶性决定：偶数部分贡献正值，奇数部分贡献负值。对于实验可实现的调制双光子态，施密特数随调制参数的变化呈现窄共振峰，这些峰与Ds的窄谷（HOM反聚束发生处）高度相关。

Conclusion: 可以通过实验可控的光谱相位调制来切换HOM聚束和反聚束状态。施密特数和对称度参数Ds之间的相关性揭示了调制双光子态的结构特性。

Abstract: We investigate into experimentally detectable effects such as the
Hong-Ou-Mandel (HOM) bunching and antibunching. These regimes can be
characterized using the symmetry degree parameter $D_S$ that enters the
two-photon coincidence probability $P_{2c}=(1-D_S)/2$. In the case of HOM
bunching (antibunching), $D_S$ is positive (negative). Though the symmetry
degree can generally be expressed in terms of the difference between the
contributions coming from the symmetric and antisymmetric parts of the biphoton
joint spectral amplitude (JSA), $\psi(\omega_1,\omega_2)$, for a certain
physically realizable class of the JSA, where $\psi(\omega_1,\omega_2)$ is
proportional to the product of amplitudes
$\varphi_1(\omega_1)\varphi_2(\omega_2)$ multiplied by a Gaussian shaped
entangling factor, we find the sign of $D_S$ is primarily governed by the
parity properties of the spectral function,
$\varphi_{12}(\omega)=\varphi_1(\omega)\varphi_2^*(\omega)$. It is the even
(odd) part of $\varphi_{12}=\varphi_{12}^{(+)}+\varphi_{12}^{(-)}$ that meets
the parity condition
$\varphi_{12}^{(+)}(\omega-\Omega)=\varphi_{12}^{(+)}(\Omega-\omega)$
($\varphi_{12}^{(-)}(\omega-\Omega)=- \varphi_{12}^{(-)}(\Omega-\omega)$) to
yield the positive (negative) contribution, $D_S^{(+)}$ ($-D_S^{(-)}$), to the
symmetry degree parameter: $D_S=D_S^{(+)}-D_S^{(-)}$. We have shown that
switching between the bunching and antibunching regimes can be realized using
the experimentally accessible family of modulated biphoton states produced
using the spectral phase modulation fine-tuned via the sub-nanometer scale
variation of the path length. For this class of modulated states, the Schmidt
number has been computed as a function of the modulation parameter. This
dependence reveals the structure of narrow resonance peaks strongly correlated
with the corresponding narrow dips of the symmetry degree where the HOM
antibunching occurs.

</details>


### [365] [Qubit Mapping and Routing tailored to Advanced Quantum ISAs: Not as Costly as You Think](https://arxiv.org/abs/2511.04608)
*Zhaohui Yang,Kai Zhang,Xinyang Tian,Xiangyu Ren,Yingjian Liu,Yunfeng Li,Jianxin Chen,Dawei Ding,Yuanx Xie*

Main category: quant-ph

TL;DR: Canopus是一个统一的量子比特映射/路由框架，适用于多种量子指令集架构（ISA），通过在路由阶段进行深度协同优化来降低量子比特路由的开销。


<details>
  <summary>Details</summary>
Motivation: 现有量子比特映射/路由方法在可扩展性方面存在效率低下问题，因为它们依赖于忽略物理设备原生门特性的抽象路由模型。尽管高级指令集架构（如包含 sqrt(iSWAP) 和 ZZ(theta) 门的架构）具有更高的电路合成能力和保真度，但缺乏针对这些架构的系统性编译器优化策略。

Method: Canopus框架基于双量子比特门的标准表示，专注于量子比特路由以实现深度协同优化。它利用双量子比特门的标准表示和单向多面体来模拟路由阶段智能SWAP插入的综合成本。此外，该框架通过标准形式明确了双量子比特门之间的对易关系，为基于对易性的优化提供了一种通用方法。

Result: Canopus 在不同指令集架构和拓扑结构上，与最先进的方法相比，持续将路由开销降低了 15%-35%。

Conclusion: Canopus 框架为协同探索程序模式、量子指令集架构和硬件拓扑提供了一种连贯的方法，并显著降低了量子比特路由的开销。

Abstract: Qubit mapping/routing is a critical stage in compilation for both near-term
and fault-tolerant quantum computers, yet existing scalable methods typically
impose several times the routing overhead in terms of circuit depth or
duration. This inefficiency stems from a fundamental disconnect: compilers rely
on an abstract routing model (e.g., three-$ \mathrm{CX} $-unrolled SWAP
insertion) that completely ignores the idiosyncrasies of native gates supported
by physical devices.
  Recent hardware breakthroughs have enabled high-precision implementations of
diverse instruction set architectures (ISAs) beyond standard
$\mathrm{CX}$-based gates. Advanced ISAs involving gates such as
$\mathrm{\sqrt{iSWAP}}$ and $\mathrm{ZZ}(\theta)$ gates offer superior circuit
synthesis capabilities and can be realized with higher fidelities. However,
systematic compiler optimization strategies tailored to these advanced ISAs are
lacking.
  To address this, we propose Canopus, a unified qubit mapping/routing
framework applicable to diverse quantum ISAs. Built upon the canonical
representation of two-qubit gates, Canopus centers on qubit routing to perform
deep co-optimization in an ISA-aware approach. Canopus leverages the two-qubit
canonical representation and the monodromy polytope to model the synthesis cost
for more intelligent $ \mathrm{SWAP} $ insertion during the routing stage. We
also formalize the commutation relations between two-qubit gates through the
canonical form, providing a generalized approach to commutativity-based
optimizations. Experiments show that Canopus consistently reduces routing
overhead by 15\%-35\% compared to state-of-the-art methods across different
ISAs and topologies. Our work also presents a coherent method for
co-exploration of program patterns, quantum ISAs, and hardware topologies.

</details>


### [366] [Unclonable Cryptography in Linear Quantum Memory](https://arxiv.org/abs/2511.04633)
*Omri Shmueli,Mark Zhandry*

Main category: quant-ph

TL;DR: 本文提出了一种减小量子签名协议中量子密钥存储需求的新技术，并实现了最优大小。


<details>
  <summary>Details</summary>
Motivation: 现有的量子签名协议（包括一次性签名）需要大量的量子内存来存储密钥，这与量子计算的发展趋势相悖。因此，有必要在量子协议中最小化持久内存的使用。

Method: 本文利用余集态（coset states）这一在不可复制密码学中常用的工具，开发了新的技术来证明密码系统的安全性，从而显著减小了量子秘密密钥的尺寸。

Result: 通过新提出的技术，在某些情况下实现了量子密钥尺寸的渐进最优。

Conclusion: 本文成功地减小了量子签名协议的量子密钥存储需求，为实现更高效的量子密码学协议提供了新的方法。

Abstract: Quantum cryptography is a rapidly-developing area which leverages quantum
information to accomplish classically-impossible tasks. In many of these
protocols, quantum states are used as long-term cryptographic keys. Typically,
this is to ensure the keys cannot be copied by an adversary, owing to the
quantum no-cloning theorem. Unfortunately, due to quantum state's tendency to
decohere, persistent quantum memory will likely be one of the most challenging
resources for quantum computers. As such, it will be important to minimize
persistent memory in quantum protocols.
  In this work, we consider the case of one-shot signatures (OSS), and more
general quantum signing tokens. These are important unclonable primitives,
where quantum signing keys allow for signing a single message but not two.
Naturally, these quantum signing keys would require storage in long-term
quantum memory. Very recently, the first OSS was constructed in a classical
oracle model and also in the standard model, but we observe that the quantum
memory required for these protocols is quite large. In this work, we
significantly decrease the quantum secret key size, in some cases achieving
asymptotically optimal size. To do so, we develop novel techniques for proving
the security of cryptosystems using coset states, which are one of the main
tools used in unclonable cryptography.

</details>


### [367] [Random Construction of Quantum LDPC Codes](https://arxiv.org/abs/2511.04634)
*Koki Okada,Kenta Kasai*

Main category: quant-ph

TL;DR: 提出一种修改正交稀疏矩阵对的方法，以保持其行/列权重分布，用于CSS码，通过局部2x2交叉交换和整数线性规划修复来引入结构随机性，并可扩展至大码块。


<details>
  <summary>Details</summary>
Motivation: 需要在CSS码中修改正交稀疏矩阵对，同时保持其行/列权重分布，因为这对信念传播解码的性能至关重要。

Method: 使用局部2x2交叉交换操作，然后通过整数线性规划进行局部修复，以恢复正交性，从而修改矩阵。

Result: 能够生成随机化的量子LDPC码的集合，并且每次修复的计算复杂度与矩阵大小无关，确保了可扩展性。

Conclusion: 所提出的方法可以有效地修改正交稀疏矩阵对，同时保持其关键的行/列权重分布，并能生成随机化的量子LDPC码，同时保证了算法的可扩展性。

Abstract: We propose a method for modifying orthogonal sparse matrix pairs used in CSS
codes while preserving their matrix row and column weight distributions, which
play a crucial role in determining the performance of belief-propagation
decoding. Unlike simple row or column permutations that merely reorder existing
elements, the proposed local modification introduces genuine structural
randomness through small $2\times2$ cross-swap operations followed by
integer-linear-program-based local repairs that restore orthogonality. By
applying this procedure repeatedly in a random manner, ensembles of randomized
quantum LDPC codes can be constructed. The computational complexity of each
repair depends only on the maximum row and column weights and is independent of
the overall matrix size, ensuring scalability to large code blocks.

</details>


### [368] [Automated Discovery of Non-local Photonic Gates](https://arxiv.org/abs/2511.04648)
*Sören Arlt,Mario Krenn,Xuemei Gu*

Main category: quant-ph

TL;DR: AI发现了一种新的基于路径不可区分性的多光子量子门方案，可实现非局域量子计算，并揭示了一种类似量子隐形传态的新机制。


<details>
  <summary>Details</summary>
Motivation: 为了克服光子系统中直接光子-光子相互作用的弱限制，需要工程化有效的相互作用来实现非局域量子门，这对量子信息处理至关重要。

Method: 利用量子不可区分性（路径同一性）的相干叠加，而不是预共享的纠缠或贝尔态测量，来实现作用于空间分离光子的非局域多光子量子门。

Result: 提出了几种基本的非局域多光子量子门实验方案，并发现了一种模拟量子隐形传态的新机制。

Conclusion: 研究结果证明了路径不可区分性作为分布式量子信息处理资源的实用性，并展示了自动化发现系统在物理学中提出新思想和新技术的潜力。

Abstract: Interactions between quantum systems enable quantum gates, the building
blocks of quantum information processing. In photonics, direct photon-photon
interactions are too weak to be practically useful, so effective interactions
are engineered with linear optics and measurement. A central challenge is to
realize such interactions non-locally, i.e., between photons that remain
spatially separated. We present experimental proposals for several essential
non-local multiphoton quantum gates that act on spatially separated photons, in
both qubit and high-dimensional qudit systems. All solutions were discovered by
the AI-driven discovery system called PyTheus. Rather than using pre-shared
entanglement or Bell state measurements, our gates use as a resource quantum
indistinguishability by path identity - a technique that exploits coherent
superpositions of the photon pair origins. While analyzing these solutions, we
uncovered a new mechanism that mimics much of the properties of quantum
teleportation, without shared entanglement or Bell state measurements.
Technically, our results establish path indistinguishability as a practical
resource for distributed quantum information processing; conceptually, they
demonstrate how automated discovery systems can contribute new ideas and
techniques in physics.

</details>


### [369] [Photodetection of Squeezed Light: a Whittaker-Shannon Analysis](https://arxiv.org/abs/2511.04657)
*Jasper Kranias,Christian Drago,Colin Vendromin,J. E. Sipe*

Main category: quant-ph

TL;DR: Whittaker-Shannon分解为连续波（CW）压缩光提供了一种时间局部描述，基于单位时间内的光子对数量定义了压缩强度。


<details>
  <summary>Details</summary>
Motivation: 需要一种适用于CW极限且基于光子对数量定义压缩强度的方法。

Method: 使用Whittaker-Shannon分解来描述压缩光，并计算了同源检测中的正交方差、CW极限下的符合探测概率以及强压缩光的Hong-Ou-Mandel效应。

Result: 强压缩光下，正交不确定度进一步降低；弱压缩光下，光子对之间的相关性效应最显著。

Conclusion: Whittaker-Shannon分解可以解释压缩光在不同压缩强度下的行为，特别是光子对的时间特性。

Abstract: The Whittaker-Shannon decomposition provides a temporally localized
description of squeezed light, making it applicable in the CW limit and leading
to a definition of squeezing strength based on the number of photon pairs at a
time. We show examples of its usefulness by calculating quadrature variance in
a homodyne detection scheme, coincidence detection probabilities in the
continuous-wave limit, and analyzing the Hong-Ou-Mandel effect for strongly
squeezed light. Quadrature uncertainty falls farther below the shot noise limit
when squeezing is strong, but effects due to correlations between photon pairs
are most significant with weak squeezing. Our analysis extends previous results
to more general scenarios, and we leverage the Whittaker-Shannon formalism to
interpret them based on the temporal properties of photon pairs.

</details>


### [370] [Quantum Search With Generalized Wildcards](https://arxiv.org/abs/2511.04669)
*Arjan Cornelissen,Nikhil S. Mande,Subhasree Patro,Nithish Raja,Swagato Sanyal*

Main category: quant-ph

TL;DR: 研究了带通配符搜索问题的量子查询复杂度，并对问题进行了自然推广，定义了由子集Q参数化的搜索问题。推导了当Q为有界大小集合、连续块、前缀和仅全集时，问题的量子查询复杂度界限。提出了一个利用任务对称性的框架，该框架将学习x的量子查询复杂度与一个优化问题联系起来，即最大化特定函数f的比率。首次使用负权对偶界（通常用于证明下界）的原型来证明新的量子查询上界，而无需诉诸于半定规划对偶。


<details>
  <summary>Details</summary>
Motivation: 为带通配符搜索问题及其自然推广提供更紧密的量子查询复杂度界限，并开发一个通用的框架来解决这类问题。

Method: 开发了一个新的框架，该框架利用任务对称性将量子查询复杂度与一个优化问题联系起来。然后，使用该框架和负权对偶界（primal version of the negative-weight adversary bound）来推导特定集合族Q下的复杂度界限。

Result: 对于有界大小集合、连续块、前缀和仅全集这几种情况，给出了接近最优的量子查询复杂度界限。

Conclusion: 所开发的框架能够有效地界定一类搜索问题的量子查询复杂度，并且首次成功地将负权对偶界的原型用于证明量子查询上界。

Abstract: In the search with wildcards problem [Ambainis, Montanaro, Quantum
Inf.~Comput.'14], one's goal is to learn an unknown bit-string $x \in
\{-1,1\}^n$. An algorithm may, at unit cost, test equality of any subset of the
hidden string with a string of its choice. Ambainis and Montanaro showed a
quantum algorithm of cost $O(\sqrt{n} \log n)$ and a near-matching lower bound
of $\Omega(\sqrt{n})$. Belovs [Comput.~Comp.'15] subsequently showed a tight
$O(\sqrt{n})$ upper bound.
  We consider a natural generalization of this problem, parametrized by a
subset $\cal{Q} \subseteq 2^{[n]}$, where an algorithm may test whether $x_S =
b$ for an arbitrary $S \in \cal{Q}$ and $b \in \{-1,1\}^S$ of its choice, at
unit cost. We show near-tight bounds when $\cal{Q}$ is any of the following
collections: bounded-size sets, contiguous blocks, prefixes, and only the full
set.
  All of these results are derived using a framework that we develop. Using
symmetries of the task at hand we show that the quantum query complexity of
learning $x$ is characterized, up to a constant factor, by an optimization
program, which is succinctly described as follows: `maximize over all odd
functions $f : \{-1,1\}^n \to \mathbb{R}$ the ratio of the maximum value of $f$
to the maximum (over $T \in \cal{Q}$) standard deviation of $f$ on a subcube
whose free variables are exactly $T$.'
  To the best of our knowledge, ours is the first work to use the primal
version of the negative-weight adversary bound (which is a maximization program
typically used to show lower bounds) to show new quantum query upper bounds
without explicitly resorting to SDP duality.

</details>


<div id='cs.GR'></div>

# cs.GR [[Back]](#toc)

### [371] [Shellular Metamaterial Design via Compact Electric Potential Parametrization](https://arxiv.org/abs/2511.04025)
*Chang Liu,Bohan Wang*

Main category: cs.GR

TL;DR: 我们提出了一个用于壳状超材料的紧凑而富有表现力的设计空间，并开发了一个高效的 GPU 加速均质化流程，实现了近乎实时的性能评估和逆向设计，能够定制超材料以实现目标机械性能。


<details>
  <summary>Details</summary>
Motivation: 需要一个紧凑且富有表现力的设计空间来表示各种壳状超材料的几何形状，并需要一个高效的流程来评估其机械性能，以便进行设计空间的探索和逆向设计。

Method: 通过使用少量自由度来定义一个设计空间，该空间可以表示从简单的平面配置到复杂的三周期极小曲面。开发了一个基于 GPU 的高效均质化流程，可以在 20 毫秒内评估结构，并在 0.5 秒内计算有效的弹性张量。

Result: 该方法能够生成具有几何多样性和广泛机械响应的结构，其性能可达到理论上限的 91.86%。此外，通过增材制造制作的原型证实了这些设计的可制造性。

Conclusion: 我们提出的设计空间和均质化流程为开发具有特定宏观目标性能的新型壳状超材料提供了一条高效的途径，并且这些材料具有实际应用潜力。

Abstract: We introduce a compact yet highly expressive design space for shellular
metamaterials. By employing only a few dozen degrees of freedom, this design
space represents geometries ranging from simple planar configurations to
complex triply periodic minimal surfaces. Coupled with this representation, we
develop an efficient GPU-based homogenization pipeline that evaluates the
structure in under 20 ms and computes the corresponding effective elastic
tensor in near-real-time (0.5 s). The high speed of this evaluation facilitates
an exhaustive exploration of the design space and supports an inverse-design
scheme that tailors the shellular structure to specific macroscopic target
property. Structures derived through this approach exhibit not only geometric
diversity but also a wide spectrum of mechanical responses, covering a broad
range of material properties. Moreover, they achieve up to 91.86% of
theoretical upper bounds, a level of performance comparable to state-of-the-art
shellular structures with low solid volume. Finally, our prototypes, fabricated
via additive manufacturing, confirm the practical manufacturability of these
designs, underscoring their potential for real-world engineering applications.

</details>


<div id='cond-mat.mtrl-sci'></div>

# cond-mat.mtrl-sci [[Back]](#toc)

### [372] [A data-driven quest for room-temperature bulk plastically deformable ceramics](https://arxiv.org/abs/2511.03815)
*Iwo Słodczyk,Alexander Frisch,Xufei Fang,Inna Gitman,Fengxian Liu*

Main category: cond-mat.mtrl-sci

TL;DR: a data-driven approach identifies key parameters governing room-temperature bulk plasticity in ceramics, including Poisson's ratio, Pugh's ratio, Burgers vector, crystal structure, melting temperature, and Bader charge. These multiscale descriptors link intrinsic material properties to plasticity, aiding in the design of ductile ceramics.


<details>
  <summary>Details</summary>
Motivation: The increasing number of ceramics showing room-temperature plasticity necessitates a deeper understanding of the factors controlling plastic deformation and dislocation-mediated properties.

Method: A data-driven model was developed using an existing dataset of 55 ceramic materials (38 plastic, 17 brittle) to classify bulk plasticity. Key parameters influencing plasticity were identified through analysis.

Result: The analysis revealed that Poisson's ratio, Pugh's ratio, Burgers vector, crystal structure, melting temperature, and Bader charge are crucial for predicting bulk plasticity in ceramics. These parameters form a multiscale descriptor space.

Conclusion: This study presents the first systematic, data-driven map of ceramic plasticity factors, establishing a framework for unifying research and guiding the development of ductile ceramics.

Abstract: The growing number of ceramics exhibiting bulk plasticity at room temperature
has renewed interest in revisiting plastic deformation and dislocation-mediated
mechanical and functional properties in these materials. In this work, a
data-driven approach is employed to identify the key parameters governing
room-temperature bulk plasticity in ceramics. The model integrates an existing
dataset of 55 ceramic materials, 38 plastically deformable and 17 brittle, and
achieves accurate classification of bulk plasticity. The analysis reveals
several key parameters essential for predicting bulk plasticity: i) Poisson's
ratio and Pugh's ratio as macroscopic indicators reflecting the balance between
shear and volumetric deformation resistance, and ii) Burgers vector, crystal
structure and melting temperature as crystallographic descriptors associated
with lattice geometry, slip resistance and thermal stability, and iii) Bader
charge as a microscopic measure of bonding character. Together, these
parameters define a multiscale descriptor space linking intrinsic materials
properties to bulk room-temperature plasticity in ceramics, bridging the gap
between empirical ductility criteria and atomistic mechanisms of
dislocation-mediated plasticity. While preliminary, this study provides the
first systematic, data-driven mapping of the governing factors of ceramic
plasticity. The resulting framework establishes a foundation for unifying
experimental and computational studies through shared datasets and descriptors,
fostering collective progress toward understanding and designing intrinsically
ductile ceramics.

</details>


### [373] [Crystallization Behavior of ZBLAN Glass Under Combined Thermal and Vibrational Effects: Part II - COMSOL Simulation and Apparatus Redesign](https://arxiv.org/abs/2511.03821)
*Ayush Subedi,Anthony Torres,Jeff Ganley*

Main category: cond-mat.mtrl-sci

TL;DR: 振动辅助热处理ZBLAN玻璃时，接触电阻导致传热效率降低，通过倾斜设计解决了此问题，并研究了不同振动参数对结晶行为的影响。


<details>
  <summary>Details</summary>
Motivation: 研究振动辅助热处理ZBLAN玻璃时，不稳定的热接触如何影响结晶过程，并提出解决方案。

Method: 通过有限元建模（FEM）和实验验证，研究传热效率与接触电阻的关系，并通过倾斜实验装置来维持稳定的接触，然后利用显微镜、SEM、EDS和AFM分析不同振动参数下的结晶行为。

Result: 倾斜设计解决了接触电阻问题，实现了均匀加热和稳定的结晶行为。研究发现，振动频率加速成核，提高传热效率，并将有效拉丝温度窗口降低约30°C。长时间暴露在330°C以上会促进不必要的相变。

Conclusion: 建立了适用于陆地和微重力环境的抗振ZBLAN加工预测框架，强调了精确控制热量和振动的必要性。

Abstract: In Part I of this study, vibration assisted heat treatments of ZBLAN glass
revealed irregular crystallization at higher vibration levels, attributed to
intermittent loss of thermal contact between the sample and the inner silica
ampoule wall. The present work (Part II) investigates this mechanism through
finite element modeling (FEM) and experimental validation.COMSOL Multiphysics
simulations incorporating conduction, radiation, and contact resistance confirm
that intermittent contact markedly reduces heat transfer efficiency, lowering
the sampletemperature. To mitigate this effect, the experimental setup was
redesigned with a four-degree inclination to maintain stable contact during
vibration. Subsequent experiments at vibration levels H3-H5 demonstrated
uniform heating and consistent crystallization behavior.Comprehensive
microscopic, Scanning Electron Microscopy (SEM), Energy Dispersive X-ray
Spectroscopy (EDS), and Atomic Force Microscopy (AFM) analyses revealed that
even at subtle vibration levels (~50 Hz), partially crystallized ZBLAN
transformed into well-developed crystalline structures near 360C. With
increasing vibration amplitude, amorphous ZBLAN began forming incipient
crystalline phases around 330C, and at higher frequencies (~100 Hz), partial
crystallization initiated at approximately 350C. These results indicate that
higher vibration frequencies accelerate nucleation, enhance heat transfer, and
reduce the effective fiber-drawing temperature window by about 30C. Prolonged
exposure above 330C under vibration promotes unwanted phase transitions,
emphasizing the need for precise thermal and vibrational control. This study
establishes a predictive framework for vibration-resistant ZBLAN processing
applicable to both terrestrial and microgravity environments.

</details>


### [374] [Scalable Autoregressive Deep Surrogates for Dendritic Microstructure Dynamics](https://arxiv.org/abs/2511.03884)
*Kaihua Ji,Luning Sun,Shusen Liu,Fei Zhou,Tae Wook Heo*

Main category: cond-mat.mtrl-sci

TL;DR: 利用基于大量轨迹的机器学习框架，在有限的空间域中模拟合金凝固的定量相场模拟，以两倍以上的速度准确预测枝晶演化。


<details>
  <summary>Details</summary>
Motivation: 微观结构图案形成（如枝晶生长）广泛存在于材料和能源系统中，并显著影响材料性能和功能表现。相场法是模拟微观结构动力学的有力计算工具，但其高昂的计算成本限制了其在材料设计工作流程中的应用。

Method: 我们引入了一种机器学习框架，使用基于定量相场模拟的短轨迹训练的自回归深度代理模型，模拟了有限空间域中的合金凝固。

Result: 所提出的框架能够以可扩展的长度和时间尺度准确预测枝晶演化，并将速度提高了两倍以上。该模型在等温生长和稀Al-Cu合金定向凝固的模拟中均表现良好，能够预测微观结构演化。与相场基准的定量比较在尖端选择恒定性、形态对称性和初级间距演化方面显示出良好的一致性。

Conclusion: 该机器学习框架能够准确预测枝晶演化，并且计算速度比传统方法快两个数量级以上，可用于材料设计。

Abstract: Microstructural pattern formation, such as dendrite growth, occurs widely in
materials and energy systems, significantly influencing material properties and
functional performance. While the phase-field method has emerged as a powerful
computational tool for modeling microstructure dynamics, its high computational
cost limits its integration into practical materials design workflows. Here, we
introduce a machine-learning framework using autoregressive deep surrogates
trained on short trajectories from quantitative phase-field simulations of
alloy solidification in limited spatial domains. Once trained, these surrogates
accurately predict dendritic evolution at scalable length and time scales,
achieving a speed-up of more than two orders of magnitude. Demonstrations in
isothermal growth and in directional solidification of a dilute Al-Cu alloy
validate their ability to predict microstructure evolution. Quantitative
comparisons with phase-field benchmarks further show excellent agreement in the
tip-selection constant, morphological symmetry, and primary spacing evolution.

</details>


### [375] [Learning to shine: Neuroevolution enables optical control of phase transitions](https://arxiv.org/abs/2511.03895)
*Sraddha Agrawal,Stephen Whitelam,Pierre Darancet*

Main category: cond-mat.mtrl-sci

TL;DR: 利用强化学习优化光控相变。


<details>
  <summary>Details</summary>
Motivation: 解决在固体中主动光学操控结构相变的问题。

Method: 使用强化学习推导出最优时变电场，并结合傅里叶神经网络作为电场替代。

Result: 在有耗散的情况下，通过瞬时拉曼散射稳定了铋中的对称相。

Conclusion: 该方法提供了一条通过光控制非平衡结构动力学的实际途径，为稳定量子材料中隐藏和亚稳相开辟了道路。

Abstract: We address the problem of active optical steering of structural phase
transitions in solids. We demonstrate that existing reinforcement learning
approaches can derive optimal time-dependent electric fields in
optically-driven dissipative classical systems far beyond the harmonic regime,
enabling the stabilization of non-thermal structural phases. Our approach
relies on experimentally extractable metrics of the phase-space evolution and
physically-interpretable Fourier Neural Network surrogates of the
time-dependent electric field. Using first-principles simulations, we
demonstrate the stabilization of a symmetric phase in bismuth through impulsive
Raman scattering under continuous and pulsed light sources in the presence of
dissipation. Importantly, the method is gradient-free, which enables
optimization loops based solely on experimental data, such as the measures of
half-periods of oscillations in transient spectroscopy. Our framework thus
provides a practical route for controlling non-equilibrium structural dynamics
with light, opening pathways to stabilize hidden and metastable phases in
quantum materials.

</details>


### [376] [Unconventional cross sections in zinc phosphide nanowires grown using exclusively earth-abundant components](https://arxiv.org/abs/2511.03906)
*Simon Escobar Steinvall,Hampus Thulin,Nico Kawashima,Francesco Salutari,Jonas Johansson,Aidas Urbonavicius,Sebastian Lehmann,Maria Chiara Spadaro,Jordi Arbiol,Silvana Botti,Kimberly A. Dick*

Main category: cond-mat.mtrl-sci

TL;DR: 论文提出了一种仅使用地球上易于获取的元素（锌、磷、锡）生长 Zn3P2 纳米线的方法，并探讨了不同生长条件下纳米线的形貌和结构，为可持续太阳能收集和纳米线内量子阱的制备提供了新途径。


<details>
  <summary>Details</summary>
Motivation: 为了实现轻质、柔性的太阳能电池应用，必须开发直接带隙吸收材料；同时，为了增强技术的可持续性，需要使用地球上储量丰富且易于获取的元素来制造器件。

Method: 采用 Sn 作为催化剂，在 Si (111) 衬底上外延生长 Zn3P2 纳米线，并通过改变温度和 V/II 比率来观察纳米线的形貌和结构变化。

Result: 在不同温度下，观察到 Zn3P2 纳米线呈现三角形、伪五边形和六边形（在孪晶面超晶格结构中）等不同横截面形貌。研究发现 Sn 的掺杂对形成孪晶面超晶格结构至关重要，这发生在高温和高磷化氢分压的条件下。

Conclusion: Zn3P2 纳米线可用于可持续太阳能收集，且仅需使用地球上易于获取的元素。此外，通过形成异质孪晶，可以开辟在纳米线内部制备量子阱的新途径。

Abstract: To enable lightweight and flexible solar cell applications it is imperative
to develop direct bandgap absorber materials. Moreover, to enhance the
potential sustainability impact of the technologies there is a drive to base
the devices on earth-abundant and readily available elements. Herein, we report
on the epitaxial growth of Zn3P2 nanowires using exclusively earth-abundant
components, using Sn as the nanowire catalyst and Si (111) as the substrate. We
observe that the nanowires exhibit a triangular cross section at lower
temperatures, a pseudo-pentagonal cross section at intermediate temperatures,
and a hexagonal cross section in a twin plane superlattice configuration at
high temperatures and high V/II ratios. At low temperatures, the surface facets
are constricted into a metastable configuration, yielding the triangular
morphology due to the symmetry of the substrate, while intermediate
temperatures facilitate the formation of a pseudo-pentagonal morphology with
lower surface to volume ratio. The twin plane superlattice structure can only
be observed at conditions that facilitate the incorporation of Sn into Zn3P2,
which is needed to form heterotwins in the tetragonal structure, namely at high
temperatures and high phosphine partial pressures. These findings show a clear
pathway to use Zn3P2 nanowires in sustainable solar energy harvesting using
exclusively earth-abundant components, as well as opening up a novel route of
fabricating quantum wells inside nanowires using heterotwins.

</details>


### [377] [All-optical magnetization reversal via x-ray magnetic circular dichroism](https://arxiv.org/abs/2511.03965)
*Kihiro T. Yamada,Akira Izumi,Tetsuya Ikebuchi,Sumiyuki Okabe,Masaki Kubo,Ryusei Obata,Rei Kobayashi,Yuya Kubota,Takuo Ohkochi,Naomi Kawamura,Kotaro Higashi,Yoichi Shiota,Takahiro Moriyama,Teruo Ono,Iwao Matsuda,Tadashi Togashi,Yoshihito Tanaka,Motohiro Suzuki*

Main category: cond-mat.mtrl-sci

TL;DR: X射线圆偏振脉冲可实现铁磁材料的磁化反转。


<details>
  <summary>Details</summary>
Motivation: 探索X射线光子螺旋度如何控制凝聚态物质中的序参量，特别是磁性现象。

Method: 使用圆偏振的硬X射线飞秒脉冲照射铁磁Pt/Co/Pt多层膜，观察磁化反转现象。

Result: 观察到由入射X射线脉冲的螺旋度决定的全光学磁化开关，并在Pt L3边缘发生共振。

Conclusion: X射线磁性圆二色性是导致此现象的原因，涉及从2p3/2核心态到交换分裂的5d价态的依赖于螺旋度的激发，这标志着X射线区域光-物质相互作用研究的新前沿。

Abstract: Light polarization is one of the most fundamental features, equivalent to
energy and coherence. Magnetism changes light polarization, and vice versa. The
irradiation of intense circularly polarized femtosecond pules to magnetic
materials can alter the magnetic orders and elementary excitations,
particularly in the visible to infrared spectral regions. Furthermore, the
recent development of x-ray free-electron laser enables the element-specific
trace of the ultrafast dynamics with high time and spatial resolution. However,
the light helicity of x-ray photons has not yet been used to control order
parameters in condensed matter materials, not limited to such magnetic
phenomenon. Here, we demonstrate the deterministic magnetization reversal of a
ferromagnetic Pt/Co/Pt multilayer solely by irradiating femtosecond pulses of
circularly polarized hard x-rays. The observed all-optical magnetization
switching depends on the helicity of incident x-ray pulses and is strongly
resonant with the photon energy at the Pt $L_3$ edge. These results originate
in the x-ray magnetic circular dichroism of Pt, involving helicity-dependent
excitation from the 2$p_{3/2}$ core level to the exchange-split 5$d$ valence
states owing to the magnetic proximity effect with Co. These findings mark a
new frontier for examining interactions between light and matter in the x-ray
region.

</details>


### [378] [KAN-Enhanced Contrastive Learning Accelerating Crystal Structure Identification from XRD Patterns](https://arxiv.org/abs/2511.04055)
*Chenlei Xu,Tianhao Su,Jie Xiong,Yue Wu,Shuya Dong,Tian Jiang,Mengwei He,Shuai Chen,Tong-Yi Zhang*

Main category: cond-mat.mtrl-sci

TL;DR: XCCP是一个物理引导的对比学习框架，用于X射线衍射分析，能高效地匹配衍射图谱和晶体结构，并识别对称性，具有高准确率和泛化能力，为高通量材料科学研究提供新范式。


<details>
  <summary>Details</summary>
Motivation: 准确确定晶体结构对于材料科学至关重要，但现有分析方法依赖专家知识且效率低下，限制了其在高通量和自动化应用中的扩展性。

Method: 提出了一种名为XCCP的物理引导对比学习框架，利用X射线衍射编码器（包含KAN投影头的双专家设计）和晶体图编码器，在共享嵌入空间中对齐衍射图谱和候选晶体结构，以进行高效的结构检索和对称性识别。

Result: XCCP在结构检索任务上达到0.89的准确率，在空间群识别任务上达到0.93的准确率，并且能够泛化到成分相似的多主元合金，甚至对实验衍射图谱进行零样本迁移。

Conclusion: XCCP是一个强大、可解释且可扩展的X射线衍射分析新范式，能够促进高通量筛选、快速结构验证，并集成到自动化实验室中。

Abstract: Accurate determination of crystal structures is central to materials science,
underpinning the understanding of composition-structure-property relationships
and the discovery of new materials. Powder X-ray diffraction is a key technique
in this pursuit due to its versatility and reliability. However, current
analysis pipelines still rely heavily on expert knowledge and slow iterative
fitting, limiting their scalability in high-throughput and autonomous settings.
Here, we introduce a physics-guided contrastive learning framework termed as
XCCP. It aligns powder diffraction patterns with candidate crystal structures
in a shared embedding space to enable efficient structure retrieval and
symmetry recognition. The XRD encoder employs a dual-expert design with a
Kolmogorov-Arnold Network projection head, one branch emphasizes low angle
reflections reflecting long-range order, while the other captures dense high
angle peaks shaped by symmetry. Coupled with a crystal graph encoder,
contrastive pretraining yields physically grounded representations. XCCP
demonstrates strong performance across tasks, with structure retrieval reaching
0.89 and space group identification attains 0.93 accuracy. The framework
further generalizes to compositionally similar multi principal element alloys
and demonstrates zero-shot transfer to experimental patterns. These results
establish XCCP as a robust, interpretable, and scalable approach that offers a
new paradigm for X-ray diffraction analysis. XCCP facilitates high-throughput
screening, rapid structural validation and integration into autonomous
laboratories.

</details>


### [379] [TXL Fusion: A Hybrid Machine Learning Framework Integrating Chemical Heuristics and Large Language Models for Topological Materials Discovery](https://arxiv.org/abs/2511.04068)
*Arif Ullah,Rajibul Islam,Ghulam Hussain,Zahir Muhammad,Xiaoguang Li,Ming Yang*

Main category: cond-mat.mtrl-sci

TL;DR: TXL Fusion是一个结合化学启发、物理描述符和LLM嵌入的混合机器学习框架，用于加速拓扑材料的发现。


<details>
  <summary>Details</summary>
Motivation: 拓扑材料在量子技术方面有巨大潜力，但其发现受限于计算成本和实验合成的缓慢过程。

Method: 该框架整合了化学启发、工程化的物理描述符以及大型语言模型（LLM）嵌入，并考虑了空间群对称性、价电子构型和成分衍生的指标等特征，对材料进行分类。

Result: TXL Fusion 在分类（平凡、TSM和TI）方面比传统方法具有更高的准确性和泛化能力，并成功识别了新的候选材料，其中一些已通过DFT得到验证。

Conclusion: TXL Fusion 结合了数据驱动学习和化学直觉，能够快速、可解释地探索复杂的材料空间，为智能发现下一代拓扑和量子材料提供了可扩展的范式。

Abstract: Topological materials--including insulators (TIs) and semimetals (TSMs)--hold
immense promise for quantum technologies, yet their discovery remains
constrained by the high computational cost of first-principles calculations and
the slow, resource-intensive nature of experimental synthesis. Here, we
introduce TXL Fusion, a hybrid machine learning framework that integrates
chemical heuristics, engineered physical descriptors, and large language model
(LLM) embeddings to accelerate the discovery of topological materials. By
incorporating features such as space group symmetry, valence electron
configurations, and composition-derived metrics, TXL Fusion classifies
materials across trivial, TSM, and TI categories with improved accuracy and
generalization compared to conventional approaches. The framework successfully
identified new candidates, with representative cases further validated through
density functional theory (DFT), confirming its predictive robustness. By
uniting data-driven learning with chemical intuition, TXL Fusion enables rapid
and interpretable exploration of complex materials spaces, establishing a
scalable paradigm for the intelligent discovery of next-generation topological
and quantum materials.

</details>


### [380] [Unconventional Thermal Expansion in quasi-one-dimensional monoclinic BaIrO$_3$](https://arxiv.org/abs/2511.04149)
*Jeong Jinwon,Chang Bin,Noh Han-Jin,Lee Seongsu*

Main category: cond-mat.mtrl-sci

TL;DR: BaIrO3晶体结构在低温下表现出非传统的膨胀行为，可能与电子和磁性结构的变化有关。


<details>
  <summary>Details</summary>
Motivation: 研究准一维单斜BaIrO3的晶体结构随温度的变化，特别是其热膨胀行为。

Method: 使用X射线衍射测量了13 K至300 K温度范围内BaIrO3的衍射图谱，并通过Rietveld精修提取了晶格参数。

Result: 晶胞体积的温度依赖性显著偏离了Debye模型的预测，表现出类似invar的异常热膨胀行为，且这种偏离在弱铁磁转变温度附近开始出现。

Conclusion: BaIrO3的异常热膨胀行为可能与其电子和磁结构的变化密切相关，这种行为在低温下表现明显。

Abstract: We have investigated the temperature dependence of the crystal structure of
quasi-one-dimensional monoclinic BaIrO$_3$ using X-ray diffraction. Diffraction
patterns were measured across a temperature range from 13 K to 300 K, with
5-degree steps, and Rietveld refinements were performed to extract the relevant
lattice parameters. The resulting cell volumes exhibit a significant deviation
from the Debye model predictions for lattice-specific heat within a reasonable
range of the Debye temperature, Gr{\"u}neisen parameter, and bulk modulus. This
suggests an invar-like, unconventional thermal expansion behavior. The
deviation begins near the weak ferromagnetic transition temperature, indicating
a strong correlation with changes in the electronic and magnetic structure of
monoclinic BaIrO$_3$.

</details>


### [381] [Revealing the innate sub-nanometer porous structure of carbon nanomembranes with molecular dynamics simulations and highly charged ion spectroscopy](https://arxiv.org/abs/2511.04266)
*Filip Vuković,Anna Niggas,Levin Mihlan,Zhen Yao,Armin Gölzhäuser,Louise Fréville,Vladislav Stroganov,Andrey Turchanin,Jürgen Schnack,Nigel A. Marks,Richard A. Wilhelm*

Main category: cond-mat.mtrl-sci

TL;DR: 碳纳米膜（CNMs）是一种适用于能源、储能和水过滤等应用的纳米级薄无序碳材料。


<details>
  <summary>Details</summary>
Motivation: 由于游离膜的辐射敏感性，使用传统实验技术研究CNMs的结构-性质关系具有挑战性。

Method: 使用高电荷离子光谱和分子动力学模拟来研究基于terphenylthiol的CNMs的结构，并将其预测的离子电荷交换数据和拉伸模量与实验进行比较。

Result: 结果表明，真空中的CNM组成可能包含大量配位数不足的碳，并具有开放的亚纳米级孔隙结构。

Conclusion: 这种碳网络在空气中是活性的，可能在空气条件下被氢和氧基团稳定。

Abstract: Carbon nanomembranes (CNMs) are nanometer-thin disordered carbon materials
that are suitable for a range of applications, from energy generation and
storage, through to water filtration. The structure-property relationships of
these nanomembranes are challenging to study using traditional experimental
characterization techniques, primarily due to the radiation-sensitivity of the
free-standing membrane. Highly charged ion spectroscopy is a novel
characterization method that is able to infer structural details of the carbon
nanomembrane without concern of induced damage affecting the measurements. Here
we employ molecular dynamics simulations to produce candidate structural models
of terphenylthiol-based CNMs with varying degrees of nanoscale porosity, and
compare predicted ion charge exchange data and tensile moduli to experiment.
The results suggest that the in-vacuum CNM composition likely comprises a
significant fraction of under-coordinated carbon, with an open sub-nanometer
porous structure. Such a carbon network would be reactive in atmosphere and
would be presumably stabilized by hydrogen and oxygen groups under atmospheric
conditions.

</details>


### [382] [The Moving Beam Diffraction Geometry: the DIAD Application of a Diffraction Scanning-Probe](https://arxiv.org/abs/2511.04463)
*Alberto Leonardi,Andrew James,Christina Reinhard,Michael Drakopoulos,Ben Williams,Hans Dehyle,Jacob Filik,Liam Perera,Sharif Ahmed*

Main category: cond-mat.mtrl-sci

TL;DR: DIAD 是一种 X 射线成像和衍射联用技术，通过移动衍射光束，可以同时研究材料的内部结构、相变和应变，尤其适用于研究快速演化和易受运动影响的样品。


<details>
  <summary>Details</summary>
Motivation: 研究材料的微观结构、应变、相变和材料行为之间的相互作用至关重要，但传统方法难以同时定量这些因素。

Method: DIAD 利用两个独立的 X 射线束，在同一样品位置进行准同时的 X 射线计算机断层扫描和 X 射线粉末衍射。其独特之处在于能够进行图像引导的衍射，即在不移动样品的情况下，将微米尺寸的衍射光束扫描成像区域。这种移动光束衍射技术使得研究快速演化和易受运动影响的过程和样品成为可能。

Result: 研究表明，在衍射光束沿入射光束方向下游的探测器位置，衍射对移动几何形状最敏感。KB 镜的移动和固定孔径狭缝导致光束探针的刚性平移，而不影响入射光束路径与样品的角度。最近邻校准在校准和探测样品区域之间的距离小于或等于光束尺寸时，可以达到与自校准几何形状相同的精度。移动光束衍射几何形状的绝对误差保持在 0.0001 以下。

Conclusion: DIAD 及其移动光束衍射几何形状为研究材料行为提供了新方法，其校准和数据处理方法经过验证，能够实现高精度测量。

Abstract: Understanding the interactions between microstructure, strain, phase, and
material behavior is crucial in many scientific fields. However, quantifying
these correlations is challenging, as it requires the use of multiple
instruments and techniques, often separated by space and time. The Dual Imaging
And Diffraction (DIAD) beamline at Diamond is designed to address this
challenge. DIAD allows its users to visualize internal structures, identify
compositional/phase changes, and measure strain. DIAD provides two independent
beams combined at one sample position, allowing quasi-simultaneous X-ray
Computed Tomography and X-ray Powder Diffraction. A unique functionality of the
DIAD configuration is the ability to perform image-guided diffraction, where
the micron-sized diffraction beam is scanned over the complete area of the
imaging field of view without moving the specimen. This moving beam diffraction
geometry enables the study of fast-evolving and motion-susceptible processes
and samples. Here, we discuss the novel moving beam diffraction geometry
presenting the latest findings on the reliability of both geometry calibration
and data reduction routines used. Our measures confirm diffraction is most
sensitive to the moving geometry for the detector position downstream normal to
the incident beam. The observed data confirm that the motion of the KB mirror
coupled with a fixed aperture slit results in a rigid translation of the beam
probe, without affecting the angle of the incident beam path to the sample. Our
measures demonstrate a nearest-neighbour calibration can achieve the same
accuracy as a self-calibrated geometry when the distance between calibrated and
probed sample region is smaller or equal to the beam spot size. We show the
absolute error of the moving beam diffraction geometry remains below 0.0001,
which is the accuracy we observe for the beamline with stable beam operation.

</details>


### [383] [Machine learning-driven elasticity prediction in advanced inorganic materials via convolutional neural networks](https://arxiv.org/abs/2511.04468)
*Yujie Liu,Zhenyu Wang,Hang Lei,Guoyu Zhang,Jiawei Xian,Zhibin Gao,Jun Sun,Haifeng Song,Xiangdong Ding*

Main category: cond-mat.mtrl-sci

TL;DR: 该研究使用晶体图卷积神经网络（CGCNN）预测了80664种无机晶体的剪切模量和体积模量，并公开了所有数据，为材料设计提供了支持。


<details>
  <summary>Details</summary>
Motivation: 预测无机晶体材料的弹性模量（剪切模量、体积模量）对于理解其电导率、热导率和机械性能至关重要，但传统实验测量成本高、效率低，因此需要更有效的预测方法。

Method: 训练了两个CGCNN模型，使用Matbench v0.1数据集中的10987种材料的剪切模量和体积模量数据，并对材料进行了筛选（带隙0.1-3.0 eV，无放射性元素），最终预测了Materials Project数据库和Merchant等人发现的晶体结构的数据。

Result: 训练好的CGCNN模型预测精度高（平均绝对误差<13，R平方接近1），泛化能力好。成功预测了54359种来自Materials Project数据库和26305种由Merchant等人发现的晶体结构的剪切模量和体积模量，总计80664种。

Conclusion: 该研究成功预测了大量无机晶体的弹性和模量，丰富了材料弹性数据资源，为材料设计提供了有力的支持，并且所有数据均公开可用。

Abstract: Inorganic crystal materials have broad application potential due to excellent
physical and chemical properties, with elastic properties (shear modulus, bulk
modulus) crucial for predicting materials' electrical conductivity, thermal
conductivity and mechanical properties. Traditional experimental measurement
suffers from high cost and low efficiency, while theoretical simulation and
graph neural network-based machine learning methods--especially crystal graph
convolutional neural networks (CGCNNs)--have become effective alternatives,
achieving remarkable results in predicting material elastic properties. This
study trained two CGCNN models using shear modulus and bulk modulus data of
10987 materials from the Matbench v0.1 dataset, which exhibit high accuracy
(mean absolute error <13, coefficient of determination R-squared close to 1)
and good generalization ability. Materials were screened to retain those with
band gaps between 0.1-3.0 eV and exclude radioactive element-containing
compounds. The final predicted dataset comprises two parts: 54359 crystal
structures from the Materials Project database and 26305 crystal structures
discovered by Merchant et al. (2023 Nature 624 80). Ultimately, this study
completed the prediction of shear modulus and bulk modulus for 80664 inorganic
crystals. This work enriches existing material elastic data resources and
provides robust support for material design, with all data openly available at
https://doi.org/10.57760/sciencedb.j00213.00104.

</details>


### [384] [A copper sulfide-hydroxypropyl $β$-Cyclodextrin-reduced graphene oxide composite for highly sensitive electrochemical detection of 5-hydroxytryptamine in biological samples](https://arxiv.org/abs/2511.04493)
*Aravindan Santhan,Kuo Yuan Hwa,Slava V. Rotkin,Cheng-Han Wang,Chun-Wei Ou*

Main category: cond-mat.mtrl-sci

TL;DR: 该研究提出了一种基于 $Cu_2S/H{eta}cd-rGO$ 杂化电催化剂的血清素电化学检测方法，该方法具有高灵敏度、宽线性范围和优异的选择性，可用于生物样品中的血清素检测。


<details>
  <summary>Details</summary>
Motivation: 准确识别神经递质对于理解大脑功能、诊断神经系统疾病和制定有效的治疗策略至关重要。目前的研究旨在通过开发新型电催化剂来改进血清素的电化学检测。

Method: 本研究利用 $Cu_2S$ 和 $H{eta}cd-rGO$ 的协同效应，通过范德华力和静电相互作用将 $Cu_2S$ 负载到 $H{eta}cd-rGO$ 的层状结构上，制备出 $Cu_2S/H{eta}cd-rGO$ 杂化电催化剂，并将其修饰在玻碳电极上，用于血清素的电化学检测。

Result: 所制备的传感器在 0.019 至 0.299 $
um$M 和 4.28 至 403.14 $
um$M 的宽线性范围内对血清素表现出灵敏的响应，检测下限 (LOD) 低至 1.2 nM (0.0012 $
um$M)，灵敏度为 15.9 $
um$A $
um$M$^{-1}$ $cm^{-2}$。该传感器对常见的干扰物（如氨基酚、多巴胺、肾上腺素、氢醌、褪黑素和氯）表现出优异的选择性，并且在生物样品中的实际样品测试中显示出良好的回收率。

Conclusion: $Cu_2S/H{eta}cd-rGO$ 杂化电催化剂的制备成本低廉且方法简单，是一种用于检测血清素的优异电催化剂，在神经递质的精确检测方面具有应用潜力。

Abstract: The precise identification of neurotransmitters is essential for
comprehending cerebral function, detecting neurological conditions, and
formulating successful therapeutic approaches. The present work investigates
the electrochemical detection of serotonin with the excellent hybrid
electrocatalyst $Cu_2S/H{\beta}cd-rGO$. $Cu_2S$, with its significant features
as improved catalytic activity and enhanced charge transfer when combined with
$H{\beta}cd-rGO$, will enhance the performance. The integration of $Cu_2S$ with
$H{\beta}cd-rGO$, regulated by the van der Waals force and the electrostatic
interaction, makes it a stable catalyst without disrupting the composite
structure. Also, the aggregation of the $Cu_2S/H{\beta}cd$ with the layered
sheets of rGO can be highly reduced and resulting in the improvement of the
conductivity. Thus, the above features resulted in the improved oxidation
response current when fabricated over the glassy carbon electrode (GCE). The SR
showed sensitive response at a broad linear range of 0.019 to 0.299 $\mu$M and
4.28 to 403.14 $\mu$M, resulting in a lower limit of detection (LOD) of 1.2 nM
or 0.0012 $\mu$M and a sensitivity of about 15.9 $\mu$A ${\mu}M^{-1}$
$cm^{-2}$. The sensor demonstrated excellent selectivity against common
interferents, including aminophenol, dopamine, epinephrine, hydroquinone,
melatonin, and chlorine. The real sample studies in the biological samples show
good recovery values, showing the effectiveness of the as-fabricated sensor.
Thus, the cost-efficient and straightforward integration of
$Cu_2S/H{\beta}cd-rGO$ will be an outstanding electrocatalyst for detecting SR.

</details>


### [385] [Band Alignment Tuning from Charge Transfer in Epitaxial SrIrO$_3$/SrCoO$_3$ Superlattices](https://arxiv.org/abs/2511.04513)
*Jibril Ahammad,Brian B. Opatosky,Tanzila Tasnim,John W. Freeland,Gabriel Calderon Ortiz,Jinwoo Hwang,Gaurab Rimal,Boris Kiefer,Ryan B. Comes*

Main category: cond-mat.mtrl-sci

TL;DR: SrIrO3/SrCoO3超晶格中的界面电荷转移


<details>
  <summary>Details</summary>
Motivation: 氧化物界面电荷转移对于设计具有新兴电子和磁性质的材料至关重要，特别是在强电子关联和自旋-轨道耦合共存的系统中。

Method: 采用密度泛函理论（DFT）模拟电子从Ir到Co在SIO/SCO界面的转移，并通过分子束外延合成外延SIO/SCO超晶格。结构和输运测量、X射线吸收光谱（XAS）以及Co K-和L2,3-边和Ir L2-边光谱用于表征。

Result: DFT模拟和实验测量均证实了界面电荷转移，电子从Ir转移到Co。这稳定了钙钛矿SCO相，并通过空穴掺杂调节了SIO的电子结构。O K-边XAS显示了与DFT预测一致的SIO层中的能带排列变化。

Conclusion: 该研究为工程化具有定制磁和电子性质的氧化物异质结构提供了途径。

Abstract: Understanding charge transfer at oxide interfaces is crucial for designing
materials with emergent electronic and magnetic properties, especially in
systems where strong electron correlations and spin-orbit coupling coexist.
SrIrO$_3$/SrCoO$_3$ (SIO/SCO) superlattices offer a unique platform to explore
these effects due to their contrasting electronic structures and magnetic
behaviors. Building on past theory based on continuity of O 2p band alignment,
we employ density functional theory (DFT) to model electron transfer from Ir to
Co across the SIO/SCO interface. To characterize these effects, we synthesized
epitaxial SIO/SCO superlattices via molecular beam epitaxy. Structural and
transport measurements confirmed high crystallinity, metallic behavior, and
suppression of Kondo scattering that has been reported in uniform SIO films.
Further characterization via X-ray absorption spectroscopy (XAS) revealed
orbital anisotropy and valence changes consistent with interfacial charge
transfer. Co K- and L$_{2,3}$-edge and Ir L$_2$-edge spectra verified electron
donation from Ir to Co, stabilizing the perovskite SCO phase and tuning the
electronic structure of SIO via hole-doping. O K-edge XAS showed band alignment
shifts in the SIO layer consistent with DFT predictions. Our work here provides
a pathway for engineering oxide heterostructures with tailored magnetic and
electronic properties.

</details>


### [386] [The phase-field model of fracture incorporating Mohr-Coulomb, Mogi-Coulomb, and Hoek-Brown strength surfaces](https://arxiv.org/abs/2511.04627)
*S Chockalingam,Adrian Buganza Tepole,Aditya Kumar*

Main category: cond-mat.mtrl-sci

TL;DR: 该研究在经典断裂力学的基础上，通过引入新的驱动力，成功地将材料的强度面纳入了相场模型，能够同时描述断裂的形核和扩展，并考虑了材料的韧性。


<details>
  <summary>Details</summary>
Motivation: 经典相场理论在模拟裂纹扩展时表现良好，但在没有初始裂纹的情况下，无法准确描述材料的断裂形核过程，因为该过程受材料强度面的控制。本研究旨在弥补这一不足。

Method: 本研究在Kumar等人（2020）提出的相场理论框架基础上，实现了Chockalingam（2025）推导出的通用驱动力表达式，并将其应用于有限元框架。研究中包含了 Mohr-Coulomb、3D Hoek-Brown 和 Mogi-Coulomb 等具有代表性的强度面。

Result: 通过对标准断裂问题的模拟，该模型在不同断裂模式下得到了验证，包括：(i) 均匀应力下的断裂形核，(ii) 大尺寸预置裂纹的扩展，以及 (iii) 受强度和韧性共同控制的断裂。

Conclusion: 本研究提出的驱动力构建方法具有通用性和鲁棒性，能够有效地模拟受任意强度面控制的材料的断裂行为，克服了经典相场理论在描述断裂形核方面的局限性。

Abstract: Classical phase-field theories of brittle fracture capture
toughness-controlled crack propagation but do not account for the material's
strength surface, which governs fracture nucleation in the absence of cracks.
The phase-field formulation of Kumar et al. (2020) proposed a blueprint for
incorporating the strength surface while preserving toughness-controlled
propagation by introducing a nucleation driving force and presented results for
the Drucker--Prager surface. Following this blueprint, Chockalingam (2025)
recently derived a general driving-force expression that incorporates arbitrary
strength surfaces. The present work implements this driving force within a
finite-element framework and incorporates representative strength surfaces that
span diverse mathematical and physical characteristics -- the Mohr--Coulomb, 3D
Hoek--Brown, and Mogi--Coulomb surfaces. Through simulations of canonical
fracture problems, the formulation is comprehensively validated across fracture
regimes, capturing (i) nucleation under uniform stress, (ii) crack growth from
large pre-existing flaws, and (iii) fracture governed jointly by strength and
toughness. While the strength surfaces examined here already encompass a broad
range of brittle materials, the results demonstrate the generality and
robustness of the proposed driving-force construction for materials governed by
arbitrary strength surfaces.

</details>


<div id='cs.DS'></div>

# cs.DS [[Back]](#toc)

### [387] [Attractors Is All You Need: Parity Games In Polynomial Time](https://arxiv.org/abs/2511.03752)
*Rick van der Heijden*

Main category: cs.DS

TL;DR: 提出了一个多项式时间算法，在O(n^2 * (n + m))时间内解决奇偶游戏，解决了长达数十年的研究难题。


<details>
  <summary>Details</summary>
Motivation: 解决奇偶游戏问题，并提供一种比以往基于吸引子的算法更优的解决方案。

Method: 提出了一种新的吸引子类型，能够保证找到奇偶游戏的最小势力范围，该吸引子可以在多项式时间内运行并清空图。

Result: 找到了一种新的吸引子，能够保证找到奇偶游戏的最小势力范围。

Conclusion: 该算法通过移除确定获胜者但非整个区域的奇偶游戏来解决奇偶游戏。

Abstract: This paper provides a polynomial-time algorithm for solving parity games that
runs in $\mathcal{O}(n^{2}\cdot(n + m))$ time-ending a search that has taken
decades. Unlike previous attractor-based algorithms, the presented algorithm
only removes regions with a determined winner. The paper introduces a new type
of attractor that can guarantee finding the minimal dominion of a parity game.
The attractor runs in polynomial time and can peel the graph empty.

</details>


### [388] [Multi-Pass Streaming Lower Bounds for Uniformity Testing](https://arxiv.org/abs/2511.03960)
*Qian Li,Xin Lyu*

Main category: cs.DS

TL;DR: 本研究证明了在大小为2m的域上进行多轮流式均匀性测试的下界，提出了一种新的混合论证和基于双人通信的硬度证明方法，解决了在噪声视图下区分独立和相同符号向量的问题，并将单轮下界扩展到多轮。


<details>
  <summary>Details</summary>
Motivation: 区分均匀分布和一种特定的有偏差分布，并为多轮流式算法确定其空间、轮数和样本数量之间的下界。

Method: 1. 提出一种混合论证，将流式问题转化为双人通信问题。2. 证明了一个基础的双人通信问题的下界，即在Alice和Bob只能获得随机符号向量的噪声视图的情况下，判断这些向量是独立还是相同。

Result: 任何使用空间s并具有恒定优势的l轮流式算法必须满足tradeoff snl = Ω(m/ε^2)。

Conclusion: 本研究将单轮流式均匀性测试的下界推广到多轮，并提出了一种新的证明技术，可能对其他随机输入流式问题有借鉴意义。

Abstract: We prove multi-pass streaming lower bounds for uniformity testing over a
domain of size $2m$. The tester receives a stream of $n$ i.i.d. samples and
must distinguish (i) the uniform distribution on $[2m]$ from (ii) a
Paninski-style planted distribution in which, for each pair $(2i-1,2i)$, the
probabilities are biased left or right by $\epsilon/2m$. We show that any
$\ell$-pass streaming algorithm using space $s$ and achieving constant
advantage must satisfy the tradeoff $sn\ell=\tilde{\Omega}(m/\epsilon^2)$. This
extends the one-pass lower bound of Diakonikolas, Gouleakis, Kane, and Rao
(2019) to multiple passes.
  Our proof has two components. First, we develop a hybrid argument, inspired
by Dinur (2020), that reduces streaming to two-player communication problems.
This reduction relies on a new perspective on hardness: we identify the source
of hardness as uncertainty in the bias directions, rather than the collision
locations. Second, we prove a strong lower bound for a basic two-player
communication task, in which Alice and Bob must decide whether two random sign
vectors $Y^a,Y^b\in\{\pm 1\}^m$ are independent or identical, yet they cannot
observe the signs directly--only noisy local views of each coordinate. Our
techniques may be of independent use for other streaming problems with
stochastic inputs.

</details>


### [389] [HART: A Hybrid Addressing Scheme for Self-Balancing Binary Search Trees in Phase Change Memory (PCM)](https://arxiv.org/abs/2511.03994)
*Mahek Desai,Apoorva Rumale,Marjan Asadinia*

Main category: cs.DS

TL;DR: HART是一种用于自平衡二叉搜索树的新型混合寻址方案，旨在优化PCM的特性，通过结合DFATGray码寻址和线性寻址，减少位翻转，提高PCM的耐用性、寿命和性能，且计算开销低。


<details>
  <summary>Details</summary>
Motivation: 当前的自平衡二叉搜索树算法在设计时未考虑PCM的耐用性限制（10^6到10^8次写操作）和写不对称性，可能导致性能下降。

Method: 提出了一种名为HART的新型混合寻址方案，结合了用于更深层节点的DFATGray码寻址和用于较浅层节点的线性寻址，以平衡位翻转和计算复杂度。

Result: 在PCM感知的AVL树上的实验结果表明，HART显著提高了性能，减少了位翻转，从而提高了耐用性、寿命，并降低了写能耗和延迟，且没有增加显著的计算开销。

Conclusion: HART是一种高效的解决方案，通过优化PCM的特性，可以解决现有自平衡二叉搜索树在PCM上的性能问题，特别适用于大数据应用。

Abstract: As DRAM and other transistor-based memory technologies approach their
scalability limits, alternative storage solutions like Phase-Change Memory
(PCM) are gaining attention for their scalability, fast access times, and zero
leakage power. However, current memory-intensive algorithms, especially those
used in big data systems, often overlook PCM's endurance limitations (10^6 to
10^8 writes before degradation) and write asymmetry. Self-balancing binary
search trees (BSTs), which are widely used for large-scale data management,
were developed without considering PCM's unique properties, leading to
potential performance degradation. This paper introduces HART, a novel hybrid
addressing scheme for self-balancing BSTs, designed to optimize PCM's
characteristics. By combining DFATGray code addressing for deeper nodes with
linear addressing for shallower nodes, HART balances reduced bit flips during
frequent rotations at deeper levels with computational simplicity at shallow
levels. Experimental results on PCM-aware AVL trees demonstrate significant
improvements in performance, with a reduction in bit flips leading to enhanced
endurance, increased lifetime, and lower write energy and latency. Notably,
these benefits are achieved without imposing substantial computational
overhead, making HART an efficient solution for big data applications.

</details>


### [390] [Depth-13 Sorting Networks for 28 Channels](https://arxiv.org/abs/2511.04107)
*Chengu Wang*

Main category: cs.DS

TL;DR: 对27和28个通道的排序网络建立了新的深度上限，将之前的最佳深度14提高到了13。28通道网络通过组合16通道和12通道网络的优质前缀，并逐个比较器贪婪地扩展它们，最后使用SAT求解器完成剩余层，从而构建而成。


<details>
  <summary>Details</summary>
Motivation: 本研究旨在为27和28个通道的排序网络建立新的深度上限。

Method: 通过组合16通道和12通道网络的优质前缀，逐个比较器贪婪地扩展，并使用SAT求解器完成剩余层来构建28通道网络。

Result: 成功将27和28个通道排序网络的深度上限从之前的14提高到13。

Conclusion: 本研究成功地为27和28个通道的排序网络建立了新的深度上限，表明所提出的方法是有效的。

Abstract: We establish new depth upper bounds for sorting networks on 27 and 28
channels, improving the previous best bound of 14 to 13. Our 28-channel network
is constructed with reflectional symmetry by combining high-quality prefixes of
16- and 12-channel networks, extending them greedily one comparator at a time,
and using a SAT solver to complete the remaining layers.

</details>


### [391] [Counting Patterns in Degenerate Graphs in Constant Space](https://arxiv.org/abs/2511.04258)
*Balagopal Komarath,Anant Kumar,Akash Pareek*

Main category: cs.DS

TL;DR: 本篇论文研究了在n顶点、d-退化图上计算模式图同态、子图同构和诱导子图同构的算法复杂度。作者引入了新的图参数DAG树深度，并基于此提出了常数空间（单位成本RAM模型）的有效分治算法。此外，论文还改进了基于DAG树宽度参数的算法，并展示了在特定条件下（模式图顶点数少于等于11）可以实现更快的计算速度。


<details>
  <summary>Details</summary>
Motivation: 研究在n顶点、d-退化图上计算同态、子图同构和诱导子图同构的算法复杂度，并提出新的图参数和算法以优化空间和时间复杂度。

Method: 引入新的图参数DAG树深度，并基于此设计常数空间的有效分治算法。同时，改进基于DAG树宽度参数的算法，并针对特定情况（模式图顶点数少于等于11）提出更快的算法。

Result: 提出了DAG树深度参数，并基于此设计了常数空间的算法，可用于计数同态、子图同构和诱导子图同构。此外，改进了DAG树宽度算法，并在特定条件下实现了更快的计数速度。

Conclusion: DAG树深度参数可以实现高效的常数空间算法，并且在DAG树宽度方面也取得了算法性能的提升，为相关图问题的计算提供了新的解决方案。

Abstract: For an arbitrary, fixed graph (pattern graph), we study the algorithmic
complexity of counting homomorphisms, subgraph isomorphisms, and induced
subgraph isomorphisms from the pattern graph to $n$-vertex, $d$-degenerate
graphs as input. Recent work by Bressan (Algorithmica, 2021) has shown that
this problem has efficient dynamic programming algorithms using a graph
parameter called DAG treewidth. Bressan used DAG treewidth to design a fast
algorithm for counting homomorphisms, subgraph isomorphisms, and induced
subgraph isomorphisms that use polynomial space. Bera, Gishboliner, Levanzov,
Seshadhri, and Shapira (SODA, 2021) provided a characterization of graphs with
DAG treewidth one.
  In this paper, we introduce a new graph parameter called DAG treedepth and
show that it yields efficient divide and conquer algorithms that use only
constant space (in the unit-cost RAM model). Specifically, we show:
  An algorithm for counting subgraphs isomorphic to sparse pattern graphs using
only constant space.
  We derive an induced minor-based characterization for graphs of DAG treedepth
up to two.
  For pattern graphs upto nine vertices, the induced subgraphs can be counted
in $O(n^3)$ time using constant space.
  An algorithm for counting induced subgraphs that matches the running time
given by Bressan but only uses constant space.
  Apart from the DAG treedepth result, we also focus on DAG treewidth. For DAG
treewidth, we show that we can count homomorphisms, subgraph isomorphisms, and
induced subgraph isomorphisms faster than Bressan's algorithm (2021). We
further show that for all pattern graphs up to 11 vertices, we can count
induced subgraphs in quadratic time.

</details>


### [392] [Estimating Hitting Times Locally At Scale](https://arxiv.org/abs/2511.04343)
*Themistoklis Haris,Fabian Spaeh,Spyros Dragazis,Charalampos Tsourakakis*

Main category: cs.DS

TL;DR: 该论文提出了一种局部算法来估计随机过程中两个节点之间的命中时间，而无需访问整个图。


<details>
  <summary>Details</summary>
Motivation: 命中时间是随机过程中的一个基本距离度量，在网络分析、排名系统和流行病学等领域有广泛应用。然而，现有的全局方法在处理大规模图时存在可扩展性问题。

Method: 论文提出两种局部算法来估计命中时间。第一种算法利用两个独立随机游走相遇时间可以截断命中时间计算的观点，并通过 Kronecker 积图和马尔可夫链 Chernoff 界进行分析。第二种算法扩展了 [Peng et al.; KDD 2021] 的工作，提出了一种新颖的光谱截断技术来处理命中时间的不对称性，并考虑了随机游走的定向性。此外，论文还提供了严格的渐近下界，并揭示了命中时间估计与分布测试之间的联系。

Result: 实验结果表明，该算法在真实和合成数据集上均表现良好。

Conclusion: 该论文成功开发了局部算法来估计命中时间，克服了现有全局方法的局限性，并在理论和实践上都得到了验证。

Abstract: Hitting times provide a fundamental measure of distance in random processes,
quantifying the expected number of steps for a random walk starting at node $u$
to reach node $v$. They have broad applications across domains such as network
centrality analysis, ranking and recommendation systems, and epidemiology. In
this work, we develop local algorithms for estimating hitting times between a
pair of vertices $u,v$ without accessing the full graph, overcoming scalability
issues of prior global methods. Our first algorithm uses the key insight that
hitting time computations can be truncated at the meeting time of two
independent random walks from $u$ and $v$. This leads to an efficient estimator
analyzed via the Kronecker product graph and Markov Chain Chernoff bounds. We
also present an algorithm extending the work of [Peng et al.; KDD 2021], that
introduces a novel adaptation of the spectral cutoff technique to account for
the asymmetry of hitting times. This adaptation captures the directionality of
the underlying random walk and requires non-trivial modifications to ensure
accuracy and efficiency. In addition to the algorithmic upper bounds, we also
provide tight asymptotic lower bounds. We also reveal a connection between
hitting time estimation and distribution testing, and validate our algorithms
using experiments on both real and synthetic data.

</details>


### [393] [A Polynomial-Time Algorithm for the Next-to-Shortest Path Problem on Positively Weighted Directed Graphs](https://arxiv.org/abs/2511.04345)
*Kuowen Chen,Nicole Wein,Yiran Zhang*

Main category: cs.DS

TL;DR: 在具有正边权重（positive edge weights）的定向图（directed graphs）上，找到了次短路径（next-to-shortest path）问题的一个近乎30年的遗留问题的解决方案。


<details>
  <summary>Details</summary>
Motivation: next-to-shortest path问题在1996年被提出，对于具有非负边权重的定向图已被证明是NP完全的，但正边权重的情况仍然悬而未决。

Method: 论文提出了一个用于解决正边权重定向图上的next-to-shortest path问题的算法。

Result: 该算法解决了正边权重定向图上的next-to-shortest path问题，这是一个近乎30年的遗留问题。

Conclusion: 论文成功地解决了具有正边权重定向图的次短路径问题。

Abstract: Given a graph and a pair of terminals $s$, $t$, the next-to-shortest path
problem asks for an $s\!\to \!t$ (simple) path that is shortest among all not
shortest $s\!\to \!t$ paths (if one exists). This problem was introduced in
1996, and soon after was shown to be NP-complete for directed graphs with
non-negative edge weights, leaving open the case of positive edge weights.
Subsequent work investigated this open question, and developed polynomial-time
algorithms for the cases of undirected graphs and planar directed graphs. In
this work, we resolve this nearly 30-year-old open problem by providing an
algorithm for the next-to-shortest path problem on directed graphs with
positive edge weights.

</details>


### [394] [Free-order secretary for two-sided independence systems](https://arxiv.org/abs/2511.04390)
*Kristóf Bérczi,Vasilis Livanos,José A. Soto,Victor Verdugo*

Main category: cs.DS

TL;DR: 本文提出了一种新的二分图框架来统一和扩展几种在线优化问题，特别是与图匹配、团交叉和随机顺序团秘书问题相关的变体。研究了自由顺序设置，并为k-团交叉问题设计了一个Ω(1/k^2)竞争算法。通过引入k-增长系统和广义核心引理，将此算法扩展到k-增长系统。此外，还研究了具有挑战性的代理到达模型，并获得了Ω(β/k^2)竞争算法。最后，将结果扩展到允许代理选择多个物品而不仅仅是匹配的场景。


<details>
  <summary>Details</summary>
Motivation: 在线优化中的图论问题，特别是秘书问题，通常涉及在组合约束下进行序贯决策。现有的模型，如二分图匹配、团交叉和随机顺序团秘书问题，都可以被视为这种更广泛问题的特例。然而，需要一个更通用的框架来统一这些问题并为更复杂的情况开发新的算法。

Method: 本文提出了一种基于二分图的框架，将代理和物品联系起来。该框架允许使用两个独立系统来定义两个方面的可行性约束。对于自由顺序设置，利用核心引理来设计k-团交叉问题的算法，并推广到k-增长系统。对于代理到达模型，也扩展了核心引理并得到了相应的竞争算法。此外，还将模型推广到允许代理选择多个物品而不是进行匹配的场景。

Result: 在自由顺序设置中，为k-团交叉问题开发了一个Ω(1/k^2)竞争算法。通过引入k-增长系统和广义核心引理，将该算法推广到k-增长系统。在代理到达模型中，获得了一个Ω(β/k^2)竞争算法。在放松匹配假设以允许选择多个物品的场景中，对于分区团和k-匹配约束等基本情况，获得了常数竞争算法。

Conclusion: 本文提出的二分图框架成功地统一和扩展了多种在线优化问题。通过引入k-增长系统和推广核心引理，开发了针对不同设置（自由顺序和代理到达）的具有竞争力的算法。该框架还扩展到更一般的物品选择场景，为未来的研究奠定了基础。

Abstract: The Matroid Secretary Problem is a central question in online optimization,
modeling sequential decision-making under combinatorial constraints. We
introduce a bipartite graph framework that unifies and extends several known
formulations, including the bipartite matching, matroid intersection, and
random-order matroid secretary problems. In this model, elements form a
bipartite graph between agents and items, and the objective is to select a
matching that satisfies feasibility constraints on both sides, given by two
independence systems.
  We study the free-order setting, where the algorithm may adaptively choose
the next element to reveal. For $k$-matroid intersection, we leverage a core
lemma by (Feldman, Svensson and Zenklusen, 2022) to design an
$\Omega(1/k^2)$-competitive algorithm, extending known results for single
matroids. Building on this, we identify the structural property underlying our
approach and introduce $k$-growth systems. We establish a generalized core
lemma for $k$-growth systems, showing that a suitably defined set of critical
elements retains a $\Omega(1/k^2)$ fraction of the optimal weight. Using this
lemma, we extend our $\Omega(1/k^2)$-competitive algorithm to $k$-growth
systems for the edge-arrival model.
  We then study the agent-arrival model, which presents unique challenges to
our framework. We extend the core lemma to this model and then apply it to
obtain an $\Omega(\beta/k^2)$-competitive algorithm for $k$-growth systems,
where $\beta$ denotes the competitiveness of a special type of order-oblivious
algorithm for the item-side constraint. Finally, we relax the matching
assumption and extend our results to the case of multiple item selection, where
agents have individual independence systems coupled by a global item-side
constraint. We obtain constant-competitive algorithms for fundamental cases
such as partition matroids and $k$-matching constraints.

</details>


### [395] [Online Algorithms for Repeated Optimal Stopping: Achieving Both Competitive Ratio and Regret Bounds](https://arxiv.org/abs/2511.04484)
*Tsubasa Harada,Yasushi Kawase,Hanna Sumita*

Main category: cs.DS

TL;DR: 该研究提出了一个通用的算法框架，用于解决重复最优停止问题，该问题是经典最优停止问题在 T 轮中的推广。该框架旨在在每一轮中都保证竞争比率，并实现所有轮次的总和次线性遗憾。算法通过动态选择两个候选算法之一来工作：一个是基于历史观察的经验最优算法，另一个是具有已证明竞争比率保证的基于样本的算法。该框架应用于先知不等式、秘书问题及其变体，并在某些情况下（如重复先知问题）实现了 1/2 的竞争比率和 O(sqrt(T)) 的遗憾。此外，研究还证明了 O(sqrt(T)) 的遗憾下界，表明该算法在回合数方面接近最优。


<details>
  <summary>Details</summary>
Motivation: 研究动机是解决重复最优停止问题，该问题扩展了经典的单次最优停止问题。研究的目标是设计能够同时在每一轮都保证竞争比率，并在所有轮次中实现次线性遗憾的算法。

Method: 该研究提出了一种通用的算法框架，通过动态选择两个候选算法之一来解决重复最优停止问题：一个是基于历史观察的经验最优算法，另一个是具有已证明竞争比率保证的基于样本的算法。该框架被应用于先知不等式、秘书问题及其变体。

Result: 对于重复先知不等式问题，所提出的算法从第二轮开始实现了 1/2 的竞争比率，并且总遗憾被限制在 O(sqrt(T)) 范围内。研究还证明了 O(sqrt(T)) 的遗憾下界。

Conclusion: 所提出的算法框架能够有效地解决重复最优停止问题，在保证每一轮竞争比率的同时实现了接近最优的次线性遗憾。该算法在先知不等式、秘书问题等问题上具有广泛的适用性。

Abstract: We study the repeated optimal stopping problem, which generalizes the
classical optimal stopping problem with an unknown distribution to a setting
where the same problem is solved repeatedly over $T$ rounds. In this framework,
we aim to design algorithms that guarantee a competitive ratio in each round
while also achieving sublinear regret across all rounds.
  Our primary contribution is a general algorithmic framework that achieves
these objectives simultaneously for a wide array of repeated optimal stopping
problems. The core idea is to dynamically select an algorithm for each round,
choosing between two candidates: (1) an empirically optimal algorithm derived
from the history of observations, and (2) a sample-based algorithm with a
proven competitive ratio guarantee. Based on this approach, we design an
algorithm that performs no worse than the baseline sample-based algorithm in
every round, while ensuring that the total regret is bounded by
$\tilde{O}(\sqrt{T})$.
  We demonstrate the broad applicability of our framework to canonical
problems, including the prophet inequality, the secretary problem, and their
variants under adversarial, random, and i.i.d. input models. For example, for
the repeated prophet inequality problem, our method achieves a
$1/2$-competitive ratio from the second round on and an $\tilde{O}(\sqrt{T})$
regret. Furthermore, we establish a regret lower bound of $\Omega(\sqrt{T})$
even in the i.i.d. model, confirming that our algorithm's performance is almost
optimal with respect to the number of rounds.

</details>
