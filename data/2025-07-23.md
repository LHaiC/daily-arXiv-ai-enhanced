<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 80]
- [cs.CL](#cs.CL) [Total: 47]
- [quant-ph](#quant-ph) [Total: 46]
- [cs.ET](#cs.ET) [Total: 3]
- [cs.NE](#cs.NE) [Total: 1]
- [cs.DS](#cs.DS) [Total: 5]
- [cs.LO](#cs.LO) [Total: 3]
- [eess.SY](#eess.SY) [Total: 14]
- [physics.app-ph](#physics.app-ph) [Total: 3]
- [cs.AI](#cs.AI) [Total: 42]
- [cs.GT](#cs.GT) [Total: 1]
- [cs.GR](#cs.GR) [Total: 2]
- [cond-mat.mes-hall](#cond-mat.mes-hall) [Total: 9]
- [cs.MA](#cs.MA) [Total: 2]
- [cond-mat.mtrl-sci](#cond-mat.mtrl-sci) [Total: 19]
- [eess.SP](#eess.SP) [Total: 8]
- [cs.AR](#cs.AR) [Total: 6]
- [cs.RO](#cs.RO) [Total: 24]
- [cs.DC](#cs.DC) [Total: 7]
- [cs.LG](#cs.LG) [Total: 54]
- [cs.SI](#cs.SI) [Total: 3]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [Salience Adjustment for Context-Based Emotion Recognition](https://arxiv.org/abs/2507.15878)
*Bin Han,Jonathan Gratch*

Main category: cs.CV

TL;DR: 本研究提出了一种新的情境感知情绪识别框架，通过显著性调整动态加权面部和情境信息，并使用BCI和VLMs，在模拟的囚徒困境实验中证明了其有效性。


<details>
  <summary>Details</summary>
Motivation: 旨在解决在动态社交环境中，情绪识别需要理解面部表情和情境线索之间复杂交互的问题。

Method: 本研究提出了一种包含贝叶斯线索集成（BCI）和视觉语言模型（VLMs）的显著性调整框架，用于情境感知的情绪识别。该框架能够根据面部线索的表达强度动态地调整面部信息和情境信息的权重。

Result: 实验结果表明，显著性调整能够提升情绪识别的性能，证明了该方法的有效性。

Conclusion: 本研究提出的新框架通过结合贝叶斯线索集成（BCI）和视觉语言模型（VLMs），并引入显著性调整机制，能够动态地根据面部表情的表达强度来权衡面部信息和情境信息，从而提高了在动态社交场景下的情绪识别性能。

Abstract: Emotion recognition in dynamic social contexts requires an understanding of
the complex interaction between facial expressions and situational cues. This
paper presents a salience-adjusted framework for context-aware emotion
recognition with Bayesian Cue Integration (BCI) and Visual-Language Models
(VLMs) to dynamically weight facial and contextual information based on the
expressivity of facial cues. We evaluate this approach using human annotations
and automatic emotion recognition systems in prisoner's dilemma scenarios,
which are designed to evoke emotional reactions. Our findings demonstrate that
incorporating salience adjustment enhances emotion recognition performance,
offering promising directions for future research to extend this framework to
broader social contexts and multimodal applications.

</details>


### [2] [Document Haystack: A Long Context Multimodal Image/Document Understanding Vision LLM Benchmark](https://arxiv.org/abs/2507.15882)
*Goeric Huybrechts,Srikanth Ronanki,Sai Muralidhar Jayanthi,Jack Fitzgerald,Srinivasan Veeravanallur*

Main category: cs.CV

TL;DR: 介绍了一个名为Document Haystack的新基准，用于评估视觉语言模型处理长而复杂的文档的能力，包含大量文档和问题，并附带评估框架。


<details>
  <summary>Details</summary>
Motivation: 为了解决现有基准在评估VLMs处理长文档方面的不足，并推动该领域的研究。

Method: 通过引入Document Haystack基准，该基准包含5到200页的文档，并在其中插入文本或多模态“针”，以测试VLMs的检索能力。

Result: Document Haystack基准包含400个文档变体和8250个问题，并提供了一个自动评估框架，为评估VLMs在长文档处理方面的能力提供了支持。

Conclusion: 该研究提出了Document Haystack基准，一个用于评估视觉语言模型（VLMs）处理长而复杂的文档的任务。

Abstract: The proliferation of multimodal Large Language Models has significantly
advanced the ability to analyze and understand complex data inputs from
different modalities. However, the processing of long documents remains
under-explored, largely due to a lack of suitable benchmarks. To address this,
we introduce Document Haystack, a comprehensive benchmark designed to evaluate
the performance of Vision Language Models (VLMs) on long, visually complex
documents. Document Haystack features documents ranging from 5 to 200 pages and
strategically inserts pure text or multimodal text+image "needles" at various
depths within the documents to challenge VLMs' retrieval capabilities.
Comprising 400 document variants and a total of 8,250 questions, it is
supported by an objective, automated evaluation framework. We detail the
construction and characteristics of the Document Haystack dataset, present
results from prominent VLMs and discuss potential research avenues in this
area.

</details>


### [3] [PAT++: a cautionary tale about generative visual augmentation for Object Re-identification](https://arxiv.org/abs/2507.15888)
*Leonardo Santiago Benitez Pereira,Arathy Jeevan*

Main category: cs.CV

TL;DR: 生成数据增强（如PAT++）在目标重识别任务中效果不佳，因其会引入域转移并破坏身份识别的关键特征。


<details>
  <summary>Details</summary>
Motivation: 评估身份保持图像生成对于目标重识别的有效性，因为该任务需要保留细粒度的视觉细节，而生成数据增强在此方面的应用尚不明确。

Method: 提出了一种名为PAT++的新型流水线，该流水线将扩散自蒸馏整合到部件感知Transformer中，并使用Urban Elements ReID Challenge数据集进行了广泛的实验。

Result: 实验结果显示，使用生成图像进行模型训练和查询扩展均导致了性能不一致的下降。

Conclusion: 生成数据增强方法在目标重识别任务中表现出性能下降，这主要是由于域转移和未能保留身份定义特征。

Abstract: Generative data augmentation has demonstrated gains in several vision tasks,
but its impact on object re-identification - where preserving fine-grained
visual details is essential - remains largely unexplored. In this work, we
assess the effectiveness of identity-preserving image generation for object
re-identification. Our novel pipeline, named PAT++, incorporates Diffusion
Self-Distillation into the well-established Part-Aware Transformer. Using the
Urban Elements ReID Challenge dataset, we conduct extensive experiments with
generated images used for both model training and query expansion. Our results
show consistent performance degradation, driven by domain shifts and failure to
retain identity-defining features. These findings challenge assumptions about
the transferability of generative models to fine-grained recognition tasks and
expose key limitations in current approaches to visual augmentation for
identity-preserving applications.

</details>


### [4] [Towards Railway Domain Adaptation for LiDAR-based 3D Detection: Road-to-Rail and Sim-to-Real via SynDRA-BBox](https://arxiv.org/abs/2507.16413)
*Xavier Diaz,Gianluca D'Amico,Raul Dominguez-Sanchez,Federico Nesti,Max Ronecker,Giorgio Buttazzo*

Main category: cs.CV

TL;DR: 由于缺乏铁路视觉数据集，我们创建了SynDRA-BBox合成数据集，并成功应用了域适应技术，实现了3D目标检测。


<details>
  <summary>Details</summary>
Motivation: 为了解决铁路领域缺乏公开标注数据集以支持视觉感知算法的问题。

Method: 提出了一种名为SynDRA-BBox的合成数据集，并评估了一种改编自汽车领域的半监督域适应方法在铁路环境中的应用。

Result: 实验结果表明，所提出的方法能够有效地将合成数据迁移到3D目标检测任务中，在铁路环境中取得了有希望的性能。

Conclusion: 该研究表明，合成数据集和域适应技术在提高铁路环境感知能力方面具有潜力。

Abstract: In recent years, interest in automatic train operations has significantly
increased. To enable advanced functionalities, robust vision-based algorithms
are essential for perceiving and understanding the surrounding environment.
However, the railway sector suffers from a lack of publicly available
real-world annotated datasets, making it challenging to test and validate new
perception solutions in this domain. To address this gap, we introduce
SynDRA-BBox, a synthetic dataset designed to support object detection and other
vision-based tasks in realistic railway scenarios. To the best of our
knowledge, is the first synthetic dataset specifically tailored for 2D and 3D
object detection in the railway domain, the dataset is publicly available at
https://syndra.retis.santannapisa.it. In the presented evaluation, a
state-of-the-art semi-supervised domain adaptation method, originally developed
for automotive perception, is adapted to the railway context, enabling the
transferability of synthetic data to 3D object detection. Experimental results
demonstrate promising performance, highlighting the effectiveness of synthetic
datasets and domain adaptation techniques in advancing perception capabilities
for railway environments.

</details>


### [5] [Local Dense Logit Relations for Enhanced Knowledge Distillation](https://arxiv.org/abs/2507.15911)
*Liuchi Xu,Kang Liu,Jinshuai Liu,Lu Wang,Lisheng Xu,Jun Cheng*

Main category: cs.CV

TL;DR: 提出了一种新的局部密集关系logit蒸馏（LDRLD）方法，通过递归地分离和重组logit信息来捕捉类间关系，并结合自适应衰减权重（ADW）策略来优化性能，以提高学生模型的学习效果。


<details>
  <summary>Details</summary>
Motivation: 现有研究尚未深入研究logit知识中的细粒度关系，本研究旨在解决这一问题，提出一种新的方法来捕捉和利用这些细粒度关系以改进学生模型的学习。

Method: 提出了一种名为局部密集关系logit蒸馏（LDRLD）的新颖方法，通过递归地分离和重组logit信息来捕捉类间关系。引入了自适应衰减权重（ADW）策略，使用逆秩加权（IRW）和指数秩衰减（ERD）来动态调整关键类别对的权重。递归分离后，蒸馏剩余的非目标知识以确保知识的完整性并提高性能。

Result: 与最先进的基于logit的蒸馏方法相比，该方法在CIFAR-100、ImageNet-1K和Tiny-ImageNet数据集上表现优于现有方法。

Conclusion: 该方法通过传递细粒度知识和强调最关键的关系来提高学生的表现。所提出的LDRLD方法在CIFAR-100、ImageNet-1K和Tiny-ImageNet等数据集上进行了广泛的实验，并与最先进的基于logit的方法进行了比较，结果显示出优于现有方法。

Abstract: State-of-the-art logit distillation methods exhibit versatility, simplicity,
and efficiency. Despite the advances, existing studies have yet to delve
thoroughly into fine-grained relationships within logit knowledge. In this
paper, we propose Local Dense Relational Logit Distillation (LDRLD), a novel
method that captures inter-class relationships through recursively decoupling
and recombining logit information, thereby providing more detailed and clearer
insights for student learning. To further optimize the performance, we
introduce an Adaptive Decay Weight (ADW) strategy, which can dynamically adjust
the weights for critical category pairs using Inverse Rank Weighting (IRW) and
Exponential Rank Decay (ERD). Specifically, IRW assigns weights inversely
proportional to the rank differences between pairs, while ERD adaptively
controls weight decay based on total ranking scores of category pairs.
Furthermore, after the recursive decoupling, we distill the remaining
non-target knowledge to ensure knowledge completeness and enhance performance.
Ultimately, our method improves the student's performance by transferring
fine-grained knowledge and emphasizing the most critical relationships.
Extensive experiments on datasets such as CIFAR-100, ImageNet-1K, and
Tiny-ImageNet demonstrate that our method compares favorably with
state-of-the-art logit-based distillation approaches. The code will be made
publicly available.

</details>


### [6] [An empirical study for the early detection of Mpox from skin lesion images using pretrained CNN models leveraging XAI technique](https://arxiv.org/abs/2507.15915)
*Mohammad Asifur Rahim,Muhammad Nazmul Arefin,Md. Mizanur Rahman,Md Ali Hossain,Ahmed Moustafa*

Main category: cs.CV

TL;DR: 研究人员评估了VGG16、VGG19、InceptionV3和MobileNetV2等预训练CNN模型在猴痘早期检测中的效果，并使用Grad-CAM技术增强了模型的可解释性。InceptionV3在二元分类任务中准确率达95%，MobileNetV2在多元分类任务中准确率达93%。研究结果表明，CNN模型在猴痘检测方面具有巨大潜力，XAI技术能够提高模型透明度。但研究也指出了数据集的局限性，并建议未来结合多模态数据和探索更多可解释性技术。


<details>
  <summary>Details</summary>
Motivation: 由于猴痘（Mpox）是一种与其它皮肤病症状相似的疾病，早期准确诊断面临挑战。虽然深度学习（DL）在医学图像分析方面表现出强大潜力，但关于使用预训练的CNN模型和可解释人工智能（XAI）技术进行猴痘检测的研究尚不充分。

Method: 本研究采用了迁移学习技术，对预训练的卷积神经网络（CNN）模型（包括VGG16、VGG19、InceptionV3和MobileNetV2）进行了微调，通过冻结初始层并添加自定义层来调整最终特征，以适应猴痘检测任务并避免过拟合。研究使用了MSLD和MSLD v2.0两个数据集进行训练和验证。通过准确率、精确率、召回率、F1分数和ROC曲线等指标评估模型性能。此外，研究还利用Grad-CAM技术对模型进行可视化解释，以突出关键的图像区域。

Result: 在二元分类任务中，InceptionV3模型表现最佳，准确率达到95%。而在多元分类任务中，MobileNetV2模型的表现更为出色，准确率为93%。Grad-CAM成功地可视化了图像的关键区域，为模型的决策过程提供了见解。尽管模型准确率较高，但部分模型在训练和验证损失之间存在差异，显示出一定的过拟合倾向。

Conclusion: 这项研究强调了预训练的卷积神经网络（CNN）在猴痘检测中的潜力，以及可解释人工智能（XAI）技术在提高模型透明度方面的价值。未来的工作应着眼于克服数据集的局限性，整合多模态数据，并探索更多的可解释性技术，以增强诊断的可靠性。

Abstract: Context: Mpox is a zoonotic disease caused by the Mpox virus, which shares
similarities with other skin conditions, making accurate early diagnosis
challenging. Artificial intelligence (AI), especially Deep Learning (DL), has a
strong tool for medical image analysis; however, pre-trained models like CNNs
and XAI techniques for mpox detection is underexplored. Objective: This study
aims to evaluate the effectiveness of pre-trained CNN models (VGG16, VGG19,
InceptionV3, MobileNetV2) for the early detection of monkeypox using binary and
multi-class datasets. It also seeks to enhance model interpretability using
Grad-CAM an XAI technique. Method: Two datasets, MSLD and MSLD v2.0, were used
for training and validation. Transfer learning techniques were applied to
fine-tune pre-trained CNN models by freezing initial layers and adding custom
layers for adapting the final features for mpox detection task and avoid
overfitting. Models performance were evaluated using metrics such as accuracy,
precision, recall, F1-score and ROC. Grad-CAM was utilized for visualizing
critical features. Results: InceptionV3 demonstrated the best performance on
the binary dataset with an accuracy of 95%, while MobileNetV2 outperformed on
the multi-class dataset with an accuracy of 93%. Grad-CAM successfully
highlighted key image regions. Despite high accuracy, some models showed
overfitting tendencies, as videnced by discrepancies between training and
validation losses. Conclusion: This study underscores the potential of
pre-trained CNN models in monkeypox detection and the value of XAI techniques.
Future work should address dataset limitations, incorporate multimodal data,
and explore additional interpretability techniques to improve diagnostic
reliability and model transparency

</details>


### [7] [A Lightweight Face Quality Assessment Framework to Improve Face Verification Performance in Real-Time Screening Applications](https://arxiv.org/abs/2507.15961)
*Ahmed Aman Ibrahim,Hamad Mansour Alawar,Abdulnasser Abbas Zehi,Ahmed Mohammad Alkendi,Bilal Shafi Ashfaq Ahmed Mirza,Shan Ullah,Ismail Lujain Jaleel,Hassan Ugail*

Main category: cs.CV

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Face image quality plays a critical role in determining the accuracy and
reliability of face verification systems, particularly in real-time screening
applications such as surveillance, identity verification, and access control.
Low-quality face images, often caused by factors such as motion blur, poor
lighting conditions, occlusions, and extreme pose variations, significantly
degrade the performance of face recognition models, leading to higher false
rejection and false acceptance rates. In this work, we propose a lightweight
yet effective framework for automatic face quality assessment, which aims to
pre-filter low-quality face images before they are passed to the verification
pipeline. Our approach utilises normalised facial landmarks in conjunction with
a Random Forest Regression classifier to assess image quality, achieving an
accuracy of 96.67\%. By integrating this quality assessment module into the
face verification process, we observe a substantial improvement in performance,
including a comfortable 99.7\% reduction in the false rejection rate and
enhanced cosine similarity scores when paired with the ArcFace face
verification model. To validate our approach, we have conducted experiments on
a real-world dataset collected comprising over 600 subjects captured from CCTV
footage in unconstrained environments within Dubai Police. Our results
demonstrate that the proposed framework effectively mitigates the impact of
poor-quality face images, outperforming existing face quality assessment
techniques while maintaining computational efficiency. Moreover, the framework
specifically addresses two critical challenges in real-time screening:
variations in face resolution and pose deviations, both of which are prevalent
in practical surveillance scenarios.

</details>


### [8] [FW-VTON: Flattening-and-Warping for Person-to-Person Virtual Try-on](https://arxiv.org/abs/2507.16010)
*Zheng Wang,Xianbing Sun,Shengyi Wu,Jiahui Zhan,Jianlou Si,Chi Zhang,Liqing Zhang,Jianfu Zhang*

Main category: cs.CV

TL;DR: This paper presents FW-VTON, a new three-stage method for virtual try-on that transfers clothing from one person to another. It overcomes data limitations with a new dataset and achieves state-of-the-art results.


<details>
  <summary>Details</summary>
Motivation: The paper addresses the person-to-person virtual try-on task, which differs from traditional garment-to-person try-on by using two input images (target person and garment on another person) instead of a flat garment representation. The goal is to generate a realistic combination of the target person with the desired garment.

Method: FW-VTON is a three-stage method for person-to-person virtual try-on. Stage 1 extracts a flattened garment image from a source image. Stage 2 warps the extracted garment to align with the target person's pose. Stage 3 seamlessly integrates the warped garment onto the target person.

Result: FW-VTON achieves state-of-the-art performance in person-to-person virtual try-on, with superior qualitative and quantitative results. It also excels in garment extraction subtasks.

Conclusion: FW-VTON achieves state-of-the-art performance in person-to-person virtual try-on, outperforming existing methods in both qualitative and quantitative evaluations, and also shows excellence in garment extraction.

Abstract: Traditional virtual try-on methods primarily focus on the garment-to-person
try-on task, which requires flat garment representations. In contrast, this
paper introduces a novel approach to the person-to-person try-on task. Unlike
the garment-to-person try-on task, the person-to-person task only involves two
input images: one depicting the target person and the other showing the garment
worn by a different individual. The goal is to generate a realistic combination
of the target person with the desired garment. To this end, we propose
Flattening-and-Warping Virtual Try-On (\textbf{FW-VTON}), a method that
operates in three stages: (1) extracting the flattened garment image from the
source image; (2) warping the garment to align with the target pose; and (3)
integrating the warped garment seamlessly onto the target person. To overcome
the challenges posed by the lack of high-quality datasets for this task, we
introduce a new dataset specifically designed for person-to-person try-on
scenarios. Experimental evaluations demonstrate that FW-VTON achieves
state-of-the-art performance, with superior results in both qualitative and
quantitative assessments, and also excels in garment extraction subtasks.

</details>


### [9] [Optimization of DNN-based HSI Segmentation FPGA-based SoC for ADS: A Practical Approach](https://arxiv.org/abs/2507.16556)
*Jon Gutiérrez-Zaballa,Koldo Basterretxea,Javier Echanobe*

Main category: cs.CV

TL;DR: 该研究提出了一种在FPGA SoC上部署基于DNN的HSI分割处理器的优化方法，以满足自动驾驶系统（ADS）的低延迟和高效率要求，并通过模型压缩技术显著提高了性能。


<details>
  <summary>Details</summary>
Motivation: 尽管基于HSI的视觉发展取得了有希望的结果，但像ADS这样的安全关键系统对延迟、资源消耗和安全提出了严格的限制，这促使将机器学习工作转移到边缘平台。

Method: 这项工作提出了一系列优化技术，用于在基于FPGA的SoC上部署基于DNN的HSI分割处理器，该处理器针对ADS。

Result: 应用压缩技术后，设计的DNN复杂度显著降低（为原始操作的24.34%，为原始参数数量的1.02%），在推理任务中实现了2.86倍的加速，同时分割精度没有明显下降。

Conclusion: 所提出的优化技术通过功能性软/硬件任务分配、感知感知预处理、机器学习模型压缩以及完整的流水线部署，实现了基于深度神经网络的HSI分割处理器的实际共同设计。

Abstract: The use of HSI for autonomous navigation is a promising research field aimed
at improving the accuracy and robustness of detection, tracking, and scene
understanding systems based on vision sensors. Combining advanced computer
algorithms, such as DNNs, with small-size snapshot HSI cameras enhances the
reliability of these systems. HSI overcomes intrinsic limitations of greyscale
and RGB imaging in depicting physical properties of targets, particularly
regarding spectral reflectance and metamerism. Despite promising results in
HSI-based vision developments, safety-critical systems like ADS demand strict
constraints on latency, resource consumption, and security, motivating the
shift of ML workloads to edge platforms. This involves a thorough
software/hardware co-design scheme to distribute and optimize the tasks
efficiently among the limited resources of computing platforms. With respect to
inference, the over-parameterized nature of DNNs poses significant
computational challenges for real-time on-the-edge deployment. In addition, the
intensive data preprocessing required by HSI, which is frequently overlooked,
must be carefully managed in terms of memory arrangement and inter-task
communication to enable an efficient integrated pipeline design on a SoC. This
work presents a set of optimization techniques for the practical co-design of a
DNN-based HSI segmentation processor deployed on a FPGA-based SoC targeted at
ADS, including key optimizations such as functional software/hardware task
distribution, hardware-aware preprocessing, ML model compression, and a
complete pipelined deployment. Applied compression techniques significantly
reduce the complexity of the designed DNN to 24.34% of the original operations
and to 1.02% of the original number of parameters, achieving a 2.86x speed-up
in the inference task without noticeable degradation of the segmentation
accuracy.

</details>


### [10] [Is Tracking really more challenging in First Person Egocentric Vision?](https://arxiv.org/abs/2507.16015)
*Matteo Dunnhofer,Zaira Manigrasso,Christian Micheloni*

Main category: cs.CV

TL;DR: egocentric 视觉中的跟踪和分割任务在人类-物体活动理解方面面临挑战。本研究旨在区分这些挑战是由第一人称视角还是活动理解领域引起的。通过新的基准测试，我们能够更精确地区分这些因素，从而为 egocentric 视觉研究提供更深入的见解。


<details>
  <summary>Details</summary>
Motivation: 为了回答“观察到的性能下降在多大程度上源于固有的第一人称视角，而多大程度上源于人类-物体活动领域？”这个关键问题。

Method: 通过设计新的基准测试来区分挑战因素。

Result: 该评估策略能够更精确地分离与第一人称视角相关的挑战以及与更广泛的人类-物体活动理解领域相关的挑战。

Conclusion: 该研究通过设计新的基准测试来区分第一人称视角和人类-物体活动理解这两个因素的挑战，从而为 egocentric 跟踪和分割的真正困难来源提供更深入的见解，以促进更具针对性的任务进展。

Abstract: Visual object tracking and segmentation are becoming fundamental tasks for
understanding human activities in egocentric vision. Recent research has
benchmarked state-of-the-art methods and concluded that first person egocentric
vision presents challenges compared to previously studied domains. However,
these claims are based on evaluations conducted across significantly different
scenarios. Many of the challenging characteristics attributed to egocentric
vision are also present in third person videos of human-object activities. This
raises a critical question: how much of the observed performance drop stems
from the unique first person viewpoint inherent to egocentric vision versus the
domain of human-object activities? To address this question, we introduce a new
benchmark study designed to disentangle such factors. Our evaluation strategy
enables a more precise separation of challenges related to the first person
perspective from those linked to the broader domain of human-object activity
understanding. By doing so, we provide deeper insights into the true sources of
difficulty in egocentric tracking and segmentation, facilitating more targeted
advancements on this task.

</details>


### [11] [Artifacts and Attention Sinks: Structured Approximations for Efficient Vision Transformers](https://arxiv.org/abs/2507.16018)
*Andrew Lu,Wentinn Liao,Liuhui Wang,Huzheng Yang,Jianbo Shi*

Main category: cs.CV

TL;DR: Vision Transformer 中的 massive tokens 和 artifact tokens 通过注意力机制相互抑制，调节信息流。基于此，提出 Fast Nystr"om Attention (FNA) 方法，以线性时间和空间复杂度近似自注意力，并降低计算开销，在多项视觉任务上表现出竞争力。


<details>
  <summary>Details</summary>
Motivation: 为了更深入地理解 Vision Transformer 的内部工作机制，特别是 massive tokens（具有高激活范数且充当注意力汇聚点的 token）和 artifact tokens（在推理过程中产生的副产物 token）的作用，并在此基础上提出一种更高效的自注意力近似方法。

Method: 本研究首先分析了 Vision Transformer 中 massive tokens 和 artifact tokens 的特性及其通过注意力机制相互抑制的现象，揭示了它们在调节网络信息流中的作用。在此基础上，提出了一种名为 Fast Nystr"om Attention (FNA) 的训练无关方法，该方法通过利用 massive tokens 和 artifact tokens 形成的结构化模式，以线性时间与空间复杂度近似自注意力。同时，提出了一种掩码策略来减轻这些 tokens 带来的噪声。

Result: Fast Nystr"om Attention (FNA) 在检索、分类、分割和视觉问答 (VQA) 等任务上，在常见的预训练 Vision Transformer 主干网络上进行了评估，证明了其具有竞争力的性能，同时显著降低了计算开销。提出的掩码策略也带来了微小的性能提升。

Conclusion: 该研究揭示了 Vision Transformer 中的 massive tokens 和 artifact tokens 之间的相互抑制作用，并利用这一发现提出了 Fast Nystr"om Attention (FNA) 方法，该方法能够在保持竞争力的性能的同时，以线性的时间和空间复杂度近似自注意力机制，并减少计算开销。此外，还提出了一种缓解这些 tokens 噪声的掩码策略。

Abstract: Vision transformers have emerged as a powerful tool across a wide range of
applications, yet their inner workings remain only partially understood. In
this work, we examine the phenomenon of massive tokens - tokens with
exceptionally high activation norms that act as attention sinks - and artifact
tokens that emerge as a byproduct during inference. Our analysis reveals that
these tokens mutually suppress one another through the attention mechanism,
playing a critical role in regulating information flow within the network.
Leveraging these insights, we introduce Fast Nystr\"om Attention (FNA), a
training-free method that approximates self-attention in linear time and space
by exploiting the structured patterns formed by massive and artifact tokens.
Additionally, we propose a masking strategy to mitigate noise from these
tokens, yielding modest performance gains at virtually no cost. We evaluate our
approach on popular pretrained vision backbones and demonstrate competitive
performance on retrieval, classification, segmentation, and visual question
answering (VQA), all while reducing computational overhead.

</details>


### [12] [Stop-band Energy Constraint for Orthogonal Tunable Wavelet Units in Convolutional Neural Networks for Computer Vision problems](https://arxiv.org/abs/2507.16114)
*An D. Le,Hung Nguyen,Sungbal Seo,You-Suk Bae,Truong Q. Nguyen*

Main category: cs.CV

TL;DR: 通过在可调小波单元中添加停止带能量约束，改进了CNN的图像分类和异常检测性能。


<details>
  <summary>Details</summary>
Motivation: 旨在提高卷积神经网络（CNN）在图像分类和异常检测方面的性能，特别是在处理纹理丰富的数据集时。

Method: 在正交可调小波单元的滤波器中引入了停止带能量约束，并采用晶格结构，将其集成到ResNet-18和ResNet-34中，以改进卷积、池化和下采样操作。

Result: 在CIFAR-10和可描述纹理数据集上，准确率分别提高了2.48%和13.56%。在MVTec榛子异常检测任务中，该方法在分割和检测方面均表现出色，优于现有方法。

Conclusion: 所提出的方法在CIFAR-10和可描述纹理数据集上显著提高了ResNet-18的准确性（分别为2.48%和13.56%），并且在MVTec榛子异常检测任务上取得了有竞争力的结果。

Abstract: This work introduces a stop-band energy constraint for filters in orthogonal
tunable wavelet units with a lattice structure, aimed at improving image
classification and anomaly detection in CNNs, especially on texture-rich
datasets. Integrated into ResNet-18, the method enhances convolution, pooling,
and downsampling operations, yielding accuracy gains of 2.48% on CIFAR-10 and
13.56% on the Describable Textures dataset. Similar improvements are observed
in ResNet-34. On the MVTec hazelnut anomaly detection task, the proposed method
achieves competitive results in both segmentation and detection, outperforming
existing approaches.

</details>


### [13] [Discovering and using Spelke segments](https://arxiv.org/abs/2507.16038)
*Rahul Venkatesh,Klemen Kotar,Lilian Naing Chen,Seungwoo Kim,Luca Thomas Wheeler,Jared Watrous,Ashley Xu,Gia Ancone,Wanhee Lee,Honglin Chen,Daniel Bear,Stefan Stojanov,Daniel Yamins*

Main category: cs.CV

TL;DR: 该研究提出了SpelkeNet，一种通过预测运动来识别与物理规律一致的“Spelke对象”的视觉模型，并在分割和物理操作任务中取得了优于现有方法的成果。


<details>
  <summary>Details</summary>
Motivation: 计算机视觉中的分割通常依赖于语义和特定类别约定，而人类感知可能基于“Spelke对象”——即遵循物理规律的、一起移动的物体集合。Spelke对象基于与类别无关的因果运动关系，可能更适合操作和规划任务。

Method: 提出SpelkeNet，一个视觉世界模型，通过预测未来运动分布来提取Spelke分割。SpelkeNet包含运动允许图和预期位移图，用于“统计反事实探测”，通过对高运动允许区域进行“虚拟戳”，并利用结果的预期位移图来定义Spelke分割。

Result: SpelkeNet在SpelkeBench数据集上表现优于SAM等监督基线，并在3DEditBench基准测试中，在多种现成的对象操作模型中用于下游应用时，在物理对象操作方面表现出优越的性能。

Conclusion: SpelkeNet在SpelkeBench上优于SAM等监督基线，并在3DEditBench上展示了其在物理对象操作中的实用性。

Abstract: Segments in computer vision are often defined by semantic considerations and
are highly dependent on category-specific conventions. In contrast,
developmental psychology suggests that humans perceive the world in terms of
Spelke objects--groupings of physical things that reliably move together when
acted on by physical forces. Spelke objects thus operate on category-agnostic
causal motion relationships which potentially better support tasks like
manipulation and planning. In this paper, we first benchmark the Spelke object
concept, introducing the SpelkeBench dataset that contains a wide variety of
well-defined Spelke segments in natural images. Next, to extract Spelke
segments from images algorithmically, we build SpelkeNet, a class of visual
world models trained to predict distributions over future motions. SpelkeNet
supports estimation of two key concepts for Spelke object discovery: (1) the
motion affordance map, identifying regions likely to move under a poke, and (2)
the expected-displacement map, capturing how the rest of the scene will move.
These concepts are used for "statistical counterfactual probing", where diverse
"virtual pokes" are applied on regions of high motion-affordance, and the
resultant expected displacement maps are used define Spelke segments as
statistical aggregates of correlated motion statistics. We find that SpelkeNet
outperforms supervised baselines like SegmentAnything (SAM) on SpelkeBench.
Finally, we show that the Spelke concept is practically useful for downstream
applications, yielding superior performance on the 3DEditBench benchmark for
physical object manipulation when used in a variety of off-the-shelf object
manipulation models.

</details>


### [14] [Universal Wavelet Units in 3D Retinal Layer Segmentation](https://arxiv.org/abs/2507.16119)
*An D. Le,Hung Nguyen,Melanie Tran,Jesse Most,Dirk-Uwe G. Bartsch,William R Freeman,Shyamanga Borooah,Truong Q. Nguyen,Cheolhong An*

Main category: cs.CV

TL;DR: 本研究首次将可调小波单元（UwUs）应用于3D视网膜层分割。通过引入三种小波下采样模块替代最大池化，显著提高了分割精度和结构一致性，LS-BiorthLattUwU表现尤为突出。


<details>
  <summary>Details</summary>
Motivation: 为了克服传统最大池化方法的局限性，并提高3D视网膜层从OCT图像分割的准确性和空间细节保留能力。

Method: 提出了一种将可调小波单元（UwUs）整合到运动校正MGU-Net架构中的新方法，并引入了三种小波基础的下采样模块：OrthLattUwU、BiorthLattUwU和LS-BiorthLattUwU，以替代传统的最大池化。

Result: 所提出的框架，特别是LS-BiorthLattUwU模块，在JRC OCT数据集上实现了准确性和Dice分数的显著提高，证明了该方法的有效性。

Conclusion: 该框架在体积医学图像分割方面显示出显著的准确性和Dice分数提升，特别是LS-BiorthLattUwU，凸显了可调小波滤波器在这一领域的优势。

Abstract: This paper presents the first study to apply tunable wavelet units (UwUs) for
3D retinal layer segmentation from Optical Coherence Tomography (OCT) volumes.
To overcome the limitations of conventional max-pooling, we integrate three
wavelet-based downsampling modules, OrthLattUwU, BiorthLattUwU, and
LS-BiorthLattUwU, into a motion-corrected MGU-Net architecture. These modules
use learnable lattice filter banks to preserve both low- and high-frequency
features, enhancing spatial detail and structural consistency. Evaluated on the
Jacobs Retina Center (JRC) OCT dataset, our framework shows significant
improvement in accuracy and Dice score, particularly with LS-BiorthLattUwU,
highlighting the benefits of tunable wavelet filters in volumetric medical
image segmentation.

</details>


### [15] [Disrupting Semantic and Abstract Features for Better Adversarial Transferability](https://arxiv.org/abs/2507.16052)
*Yuyang Luo,Xiaosen Wang,Zhijin Ge,Yingzhe He*

Main category: cs.CV

TL;DR: SAFER是一种新的对抗攻击方法，通过混合图像和频域信息来同时扰乱语义和抽象特征，提高了攻击的可迁移性。


<details>
  <summary>Details</summary>
Motivation: 现有的黑盒迁移攻击主要依赖于扰乱语义信息，但研究发现卷积神经网络（CNN）也关注高频分量（如纹理、边缘等抽象特征）。该研究的动机是利用这一发现，通过同时扰乱语义和抽象特征来提升攻击的可迁移性。

Method: SAFER方法结合了BLOCKMIX（输入图像混合）和SELF-MIX（频域混合）技术来计算权重矩阵，通过关注高频分量（抽象特征）和语义信息，使得攻击能够同时扰乱这两种特征，从而增强了对抗样本的可迁移性。

Result: 在ImageNet数据集上的广泛实验表明，SAFER方法能够有效提升对抗样本的可迁移性。

Conclusion: 该研究提出了一种名为SAFER（Semantic and Abstract FEatures disRuption）的对抗性攻击新方法，通过同时扰乱语义和抽象特征来提高对抗样本的可迁移性。实验证明，SAFER在ImageNet数据集上能够有效提升对抗性攻击的效果。

Abstract: Adversarial examples pose significant threats to deep neural networks (DNNs),
and their property of transferability in the black-box setting has led to the
emergence of transfer-based attacks, making it feasible to target real-world
applications employing DNNs. Among them, feature-level attacks, where
intermediate features are perturbed based on feature importance weight matrix
computed from transformed images, have gained popularity. In this work, we find
that existing feature-level attacks primarily manipulate the semantic
information to derive the weight matrix. Inspired by several works that find
CNNs tend to focus more on high-frequency components (a.k.a. abstract features,
e.g., texture, edge, etc.), we validate that transforming images in the
high-frequency space also improves transferability. Based on this finding, we
propose a balanced approach called Semantic and Abstract FEatures disRuption
(SAFER). Specifically, SAFER conducts BLOCKMIX on the input image and SELF-MIX
on the frequency spectrum when computing the weight matrix to highlight crucial
features. By using such a weight matrix, we can direct the attacker to disrupt
both semantic and abstract features, leading to improved transferability.
Extensive experiments on the ImageNet dataset also demonstrate the
effectiveness of our method in boosting adversarial transferability.

</details>


### [16] [Improving Personalized Image Generation through Social Context Feedback](https://arxiv.org/abs/2507.16095)
*Parul Gupta,Abhinav Dhall,Thanh-Toan Do*

Main category: cs.CV

TL;DR: 通过引入多模态反馈机制（姿态、交互、人脸、视线）和时间步注入策略，改进了个性化图像生成，解决了复杂活动、身份保持和视线一致性问题。


<details>
  <summary>Details</summary>
Motivation: 现有的个性化图像生成方法在处理复杂活动（如“人推摩托车”）、保持参考身份以及生成自然且与场景描述一致的视线模式方面存在不足。

Method: 提出了一种结合了姿态、人机交互、人脸识别和视线估计等检测器的反馈机制，并根据反馈信号的层级（低级如姿态，高级如视线）在不同时间步进行注入，以微调现有的个性化图像生成模型。

Result: 生成图像在交互的准确性、身份保持能力和图像质量方面优于三个基准数据集上的现有方法。

Conclusion: 通过结合姿态、人机交互、人脸识别和视线估计等检测器，并采用基于反馈的微调和基于时间步的反馈模块注入，我们提出的方法在交互、身份保持和图像质量方面取得了显著的改进。

Abstract: Personalized image generation, where reference images of one or more subjects
are used to generate their image according to a scene description, has gathered
significant interest in the community. However, such generated images suffer
from three major limitations -- complex activities, such as $<$man, pushing,
motorcycle$>$ are not generated properly with incorrect human poses, reference
human identities are not preserved, and generated human gaze patterns are
unnatural/inconsistent with the scene description. In this work, we propose to
overcome these shortcomings through feedback-based fine-tuning of existing
personalized generation methods, wherein, state-of-art detectors of pose,
human-object-interaction, human facial recognition and human gaze-point
estimation are used to refine the diffusion model. We also propose
timestep-based inculcation of different feedback modules, depending upon
whether the signal is low-level (such as human pose), or high-level (such as
gaze point). The images generated in this manner show an improvement in the
generated interactions, facial identities and image quality over three
benchmark datasets.

</details>


### [17] [PUSA V1.0: Surpassing Wan-I2V with $500 Training Cost by Vectorized Timestep Adaptation](https://arxiv.org/abs/2507.16116)
*Yaofang Liu,Yumeng Ren,Aitor Artola,Yuxuan Hu,Xiaodong Cun,Xiaotong Zhao,Alan Zhao,Raymond H. Chan,Suiyun Zhang,Rui Liu,Dandan Tu,Jean-Michel Morel*

Main category: cs.CV

TL;DR: Pusa通过矢量化时间步长适应（VTA）改进了视频扩散模型，显著降低了训练成本和数据需求，提高了图像到视频生成性能，并增加了零样本多任务能力。


<details>
  <summary>Details</summary>
Motivation: 传统的视频扩散模型在时间建模方面存在根本性的限制，特别是由于传统标量时间步长变量带来的帧演化刚性同步。现有的特定任务方法和自回归模型效率低下、容易遗忘或适用范围有限。

Method: 提出了一种名为Pusa的矢量化时间步长适应（VTA）的范式，用于在统一的视频扩散框架内实现精细的时间控制。VTA是一种非破坏性适应，可完全保留基础模型的能力。

Result: 通过在SOTA Wan2.1-T2V-14B模型上使用VTA进行微调，Pusa实现了前所未有的效率，训练成本（500美元 vs. 100,000美元以上）和数据集大小（4K vs. 10M以上）均远低于Wan-I2V-14B，同时在图像到视频生成方面取得了更高的VBench-I2V总分（87.32% vs. 86.86%），并实现了零样本多任务能力。

Conclusion: Pusa通过矢量化时间步长适应（VTA）为视频扩散模型提供了一种可扩展、高效、多功能的范例，实现了对时间的高精度控制，显著降低了训练成本和数据集需求，并在图像到视频生成方面设定了新标准，同时解锁了零样本多任务能力，如首尾帧和视频扩展，并保留了文本到视频生成能力。

Abstract: The rapid advancement of video diffusion models has been hindered by
fundamental limitations in temporal modeling, particularly the rigid
synchronization of frame evolution imposed by conventional scalar timestep
variables. While task-specific adaptations and autoregressive models have
sought to address these challenges, they remain constrained by computational
inefficiency, catastrophic forgetting, or narrow applicability. In this work,
we present Pusa, a groundbreaking paradigm that leverages vectorized timestep
adaptation (VTA) to enable fine-grained temporal control within a unified video
diffusion framework. Besides, VTA is a non-destructive adaptation, which means
it fully preserves the capabilities of the base model. By finetuning the SOTA
Wan2.1-T2V-14B model with VTA, we achieve unprecedented efficiency --
surpassing the performance of Wan-I2V-14B with $\leq$ 1/200 of the training
cost (\$500 vs. $\geq$ \$100,000) and $\leq$ 1/2500 of the dataset size (4K vs.
$\geq$ 10M samples). Pusa not only sets a new standard for image-to-video (I2V)
generation, achieving a VBench-I2V total score of 87.32\% (vs. 86.86\% of
Wan-I2V-14B), but also unlocks many zero-shot multi-task capabilities such as
start-end frames and video extension -- all without task-specific training.
Meanwhile, Pusa can still perform text-to-video generation. Mechanistic
analyses reveal that our approach preserves the foundation model's generative
priors while surgically injecting temporal dynamics, avoiding the combinatorial
explosion inherent to vectorized timesteps. This work establishes a scalable,
efficient, and versatile paradigm for next-generation video synthesis,
democratizing high-fidelity video generation for research and industry alike.
Code is open-sourced at https://github.com/Yaofang-Liu/Pusa-VidGen

</details>


### [18] [LongSplat: Online Generalizable 3D Gaussian Splatting from Long Sequence Images](https://arxiv.org/abs/2507.16144)
*Guichen Huang,Ruoyu Wang,Xiangjun Gao,Che Sun,Yuwei Wu,Shenghua Gao,Yunde Jia*

Main category: cs.CV

TL;DR: LongSplat是一种创新的在线3D高斯重建框架，通过流式更新和独特的GIR表示，有效解决了长序列图像处理的挑战，实现了高效、高质量的实时新视角合成。


<details>
  <summary>Details</summary>
Motivation: 现有3D高斯样条技术在在线长序列场景应用受限，因为它们要么依赖于缓慢的每场景优化，要么无法提供有效的增量更新，阻碍了其持续性能。

Method: 提出了一种名为LongSplat的在线实时3D高斯重建框架，采用了流式更新机制，通过高斯图像表示（GIR）来整合当前视角观测并压缩冗余历史高斯。GIR将3D高斯参数编码为图像状2D格式，实现了高效融合与感知无关的冗余压缩，从而适应长序列输入而没有过高的内存或计算成本。此外，还利用了现有的图像压缩方法来指导生成更紧凑、更高质量的3D高斯。

Result: LongSplat在实时新视角合成方面实现了最先进的效率-质量权衡，实现了实时重建，并将高斯数量减少了44%。

Conclusion: LongSplat通过其流式更新机制、高斯图像表示（GIR）以及结合图像压缩技术，实现了高效且高质量的在线3D高斯重建，能够处理长序列图像输入，并在实时新视角合成方面取得了最先进的效率-质量权衡。

Abstract: 3D Gaussian Splatting achieves high-fidelity novel view synthesis, but its
application to online long-sequence scenarios is still limited. Existing
methods either rely on slow per-scene optimization or fail to provide efficient
incremental updates, hindering continuous performance. In this paper, we
propose LongSplat, an online real-time 3D Gaussian reconstruction framework
designed for long-sequence image input. The core idea is a streaming update
mechanism that incrementally integrates current-view observations while
selectively compressing redundant historical Gaussians. Crucial to this
mechanism is our Gaussian-Image Representation (GIR), a representation that
encodes 3D Gaussian parameters into a structured, image-like 2D format. GIR
simultaneously enables efficient fusion of current-view and historical
Gaussians and identity-aware redundancy compression. These functions enable
online reconstruction and adapt the model to long sequences without
overwhelming memory or computational costs. Furthermore, we leverage an
existing image compression method to guide the generation of more compact and
higher-quality 3D Gaussians. Extensive evaluations demonstrate that LongSplat
achieves state-of-the-art efficiency-quality trade-offs in real-time novel view
synthesis, delivering real-time reconstruction while reducing Gaussian counts
by 44\% compared to existing per-pixel Gaussian prediction methods.

</details>


### [19] [SPACT18: Spiking Human Action Recognition Benchmark Dataset with Complementary RGB and Thermal Modalities](https://arxiv.org/abs/2507.16151)
*Yasser Ashraf,Ahmed Sharshar,Velibor Bojkovic,Bin Gu*

Main category: cs.CV

TL;DR: 该论文介绍了首个包含脉冲、RGB和热力学数据的动作识别数据集，以推动SNNs在能效和超低功耗视频理解领域的研究。


<details>
  <summary>Details</summary>
Motivation: 为了应对脉冲相机数据在视频动作识别中的应用需求，并为脉冲神经网络（SNNs）提供一个全面的基准测试平台。

Method: 提出了一种包含脉冲相机、同步RGB和热力学模式的新型数据集，用于视频动作识别。

Result: 创建了三个数据集，保留了脉冲数据的稀疏性和时间精度，可用于多模态视频理解，并直接比较脉冲、热力和RGB模式。

Conclusion: 该论文引入了首个使用脉冲相机、同步的RGB和热力学模式的视频动作识别（VAR）数据集，旨在为脉冲神经网络（SNNs）提供全面的基准测试。通过保留脉冲数据的固有稀疏性和时间精度，该数据集为探索多模态视频理解提供了一个独特的平台，并可直接比较脉冲、热力和RGB模式。这项工作为推动视频理解（特别是使用基于脉冲的数据进行动作识别任务）在能效和超低功耗方面的研究做出了贡献。

Abstract: Spike cameras, bio-inspired vision sensors, asynchronously fire spikes by
accumulating light intensities at each pixel, offering ultra-high energy
efficiency and exceptional temporal resolution. Unlike event cameras, which
record changes in light intensity to capture motion, spike cameras provide even
finer spatiotemporal resolution and a more precise representation of continuous
changes. In this paper, we introduce the first video action recognition (VAR)
dataset using spike camera, alongside synchronized RGB and thermal modalities,
to enable comprehensive benchmarking for Spiking Neural Networks (SNNs). By
preserving the inherent sparsity and temporal precision of spiking data, our
three datasets offer a unique platform for exploring multimodal video
understanding and serve as a valuable resource for directly comparing spiking,
thermal, and RGB modalities. This work contributes a novel dataset that will
drive research in energy-efficient, ultra-low-power video understanding,
specifically for action recognition tasks using spike-based data.

</details>


### [20] [LSSGen: Leveraging Latent Space Scaling in Flow and Diffusion for Efficient Text to Image Generation](https://arxiv.org/abs/2507.16154)
*Jyun-Ze Tang,Chih-Fan Hsu,Jeng-Lin Li,Ming-Ching Chang,Wei-Chao Chen*

Main category: cs.CV

TL;DR: LSSGen是一种在潜在空间中进行分辨率缩放的框架，可以加速文本到图像生成并提高图像质量，无需更改模型架构。


<details>
  <summary>Details</summary>
Motivation: 传统的文本到图像生成方法在加速合成时，通常在较低分辨率下进行早期去噪。然而，在像素空间中进行下采样和上采样会导致伪影和失真，因为在重新编码到潜在空间时会产生问题，从而降低最终图像质量。

Method: 提出了一种名为Latent Space Scaling Generation (LSSGen)的框架，该框架使用轻量级的潜在上采样器直接在潜在空间中执行分辨率缩放，以解决传统像素空间缩放方法在文本到图像生成中引入的伪影和失真问题。

Result: LSSGen显著优于传统的缩放方法，在相似速度下生成1024^2图像时，TOPIQ分数提高了246%，并且在文本-图像对齐和感知质量方面都表现出色。

Conclusion: LSSGen框架在不改变Transformer或U-Net架构的情况下，通过在潜在空间中执行分辨率缩放，提高了效率和视觉质量，并支持灵活的多分辨率生成。与传统的缩放方法相比，LSSGen在相似速度下生成1024^2图像时，TOPIQ分数提高了246%。

Abstract: Flow matching and diffusion models have shown impressive results in
text-to-image generation, producing photorealistic images through an iterative
denoising process. A common strategy to speed up synthesis is to perform early
denoising at lower resolutions. However, traditional methods that downscale and
upscale in pixel space often introduce artifacts and distortions. These issues
arise when the upscaled images are re-encoded into the latent space, leading to
degraded final image quality. To address this, we propose {\bf Latent Space
Scaling Generation (LSSGen)}, a framework that performs resolution scaling
directly in the latent space using a lightweight latent upsampler. Without
altering the Transformer or U-Net architecture, LSSGen improves both efficiency
and visual quality while supporting flexible multi-resolution generation. Our
comprehensive evaluation covering text-image alignment and perceptual quality
shows that LSSGen significantly outperforms conventional scaling approaches.
When generating $1024^2$ images at similar speeds, it achieves up to 246\%
TOPIQ score improvement.

</details>


### [21] [AMMNet: An Asymmetric Multi-Modal Network for Remote Sensing Semantic Segmentation](https://arxiv.org/abs/2507.16158)
*Hui Ye,Haodong Chen,Zeke Zexi Hu,Xiaoming Chen,Yuk Ying Chung*

Main category: cs.CV

TL;DR: AMMNet通过不对称架构（ADE、APF、DA模块）有效融合RGB和DSM数据，解决了计算复杂性和模态失准问题，在遥感语义分割任务中取得了优异的精度和效率。


<details>
  <summary>Details</summary>
Motivation: 解决遥感图像语义分割中，RGB图像和数字表面模型（DSM）融合时面临的两个主要限制：1. 由于架构冗余导致的计算复杂性增加。 2. 由于模态失准导致的分割性能下降。这在高要求精细化多模态融合的复杂城市环境中尤为重要。

Method: 提出了一种名为AMMNet（Asymmetric Multi-Modal Network）的新型不对称架构，该架构包含三个关键设计：1. 不对称双编码器（ADE）模块，为RGB图像设计更深的编码器以捕捉丰富的上下文信息，为DSM设计轻量级编码器以提取稀疏结构特征，从而减少冗余。 2. 不对称先验融合器（APF）模块，通过集成感知模态的先验矩阵到融合过程中，生成结构感知的上下文特征，以促进模态对齐。 3. 分布对齐（DA）模块，通过最小化散度来对齐特征分布，增强跨模态兼容性。

Result: AMMNet在ISPRS Vaihingen和Potsdam数据集上进行了广泛实验，结果表明该模型达到了最先进的分割精度，并且相较于其他多模态网络，在计算和内存需求方面有所降低。

Conclusion: AMMNet通过其新颖的不对称架构在ISPRS Vaihingen和Potsdam数据集上实现了最先进的分割精度，同时降低了计算和内存需求，克服了多模态融合中的计算复杂性和模态失准问题。

Abstract: Semantic segmentation in remote sensing (RS) has advanced significantly with
the incorporation of multi-modal data, particularly the integration of RGB
imagery and the Digital Surface Model (DSM), which provides complementary
contextual and structural information about the ground object. However,
integrating RGB and DSM often faces two major limitations: increased
computational complexity due to architectural redundancy, and degraded
segmentation performance caused by modality misalignment. These issues
undermine the efficiency and robustness of semantic segmentation, particularly
in complex urban environments where precise multi-modal integration is
essential. To overcome these limitations, we propose Asymmetric Multi-Modal
Network (AMMNet), a novel asymmetric architecture that achieves robust and
efficient semantic segmentation through three designs tailored for RGB-DSM
input pairs. To reduce architectural redundancy, the Asymmetric Dual Encoder
(ADE) module assigns representational capacity based on modality-specific
characteristics, employing a deeper encoder for RGB imagery to capture rich
contextual information and a lightweight encoder for DSM to extract sparse
structural features. Besides, to facilitate modality alignment, the Asymmetric
Prior Fuser (APF) integrates a modality-aware prior matrix into the fusion
process, enabling the generation of structure-aware contextual features.
Additionally, the Distribution Alignment (DA) module enhances cross-modal
compatibility by aligning feature distributions through divergence
minimization. Extensive experiments on the ISPRS Vaihingen and Potsdam datasets
demonstrate that AMMNet attains state-of-the-art segmentation accuracy among
multi-modal networks while reducing computational and memory requirements.

</details>


### [22] [AtrousMamaba: An Atrous-Window Scanning Visual State Space Model for Remote Sensing Change Detection](https://arxiv.org/abs/2507.16172)
*Tao Wang,Tiecheng Bai,Chao Xu,Bin Liu,Erlei Zhang,Jiyun Huang,Hongming Zhang*

Main category: cs.CV

TL;DR: 提出AtrousMamba模型，通过引入非对称窗口选择性扫描机制，有效结合了局部细节和全局上下文信息，在视觉变化检测任务上取得了优于现有方法的性能，证明了Mamba在处理视觉数据时的潜力。


<details>
  <summary>Details</summary>
Motivation: 现有的方法在增强Mamba全局感受野时，往往忽视了密集预测任务中局部信息的重要性。同时，Mamba是否能像卷积神经网络（CNN）一样有效地提取局部特征仍然是一个有待研究的问题。

Method: 提出了一种名为AtrousMamba的新模型，通过引入一种非对称窗口选择性扫描机制，能够逐步扩展扫描范围并调整扫描率。该机制缩短了相邻令牌之间的距离，从而能够有效捕获细粒度的局部特征和全局上下文。基于AWVSS模块，设计了专门的、端到端的、基于Mamba的二元变化检测（BCD）和语义变化检测（SCD）框架，分别称为AWMambaBCD和AWMambaSCD。

Result: 在六个基准数据集上的实验结果表明，所提出的框架在BCD和SCD任务上均优于现有的基于CNN、Transformer和Mamba的方法。

Conclusion: Mamba能够有效捕捉视觉数据的长程依赖关系，并且能够有效地保留细粒度的局部细节，在BCD和SCD任务上取得了优于现有基于CNN、Transformer和Mamba方法的结果。

Abstract: Recently, a novel visual state space (VSS) model, referred to as Mamba, has
demonstrated significant progress in modeling long sequences with linear
complexity, comparable to Transformer models, thereby enhancing its
adaptability for processing visual data. Although most methods aim to enhance
the global receptive field by directly modifying Mamba's scanning mechanism,
they tend to overlook the critical importance of local information in dense
prediction tasks. Additionally, whether Mamba can effectively extract local
features as convolutional neural networks (CNNs) do remains an open question
that merits further investigation. In this paper, We propose a novel model,
AtrousMamba, which effectively balances the extraction of fine-grained local
details with the integration of global contextual information. Specifically,
our method incorporates an atrous-window selective scan mechanism, enabling a
gradual expansion of the scanning range with adjustable rates. This design
shortens the distance between adjacent tokens, enabling the model to
effectively capture fine-grained local features and global context. By
leveraging the atrous window scan visual state space (AWVSS) module, we design
dedicated end-to-end Mamba-based frameworks for binary change detection (BCD)
and semantic change detection (SCD), referred to as AWMambaBCD and AWMambaSCD,
respectively. Experimental results on six benchmark datasets show that the
proposed framework outperforms existing CNN-based, Transformer-based, and
Mamba-based methods. These findings clearly demonstrate that Mamba not only
captures long-range dependencies in visual data but also effectively preserves
fine-grained local details.

</details>


### [23] [Explicit Context Reasoning with Supervision for Visual Tracking](https://arxiv.org/abs/2507.16191)
*Fansheng Zeng,Bineng Zhong,Haiying Xia,Yufei Tan,Xiantao Hu,Liangtao Shi,Shuxiang Song*

Main category: cs.CV

TL;DR: RSTrack 通过上下文推理机制、前向监督策略和高效状态建模，改进了视频跟踪中的上下文关联和时间一致性，实现了最先进的性能和实时速度。


<details>
  <summary>Details</summary>
Motivation: 主流跟踪算法通常仅通过堆叠历史信息来关联上下文，而没有明确监督关联过程，这使得有效建模目标演化动态变得困难。为了解决这个问题，我们提出了 RSTrack。

Method: RSTrack 包含三个核心机制：1) 上下文推理机制：构建目标状态推理流程，将无约束的上下文关联转化为基于历史目标状态预测当前表示的时间推理过程，从而增强时间一致性。2) 前向监督策略：利用真实目标特征作为锚点来约束推理流程，将预测输出引导至真实目标分布，并抑制上下文推理过程中的漂移。3) 高效状态建模：采用压缩-重建机制提取目标核心特征，去除跨帧冗余信息，防止无效的上下文关联。

Result: 实验结果表明，RSTrack 在多个基准数据集上取得了最先进的性能，同时保持了实时运行速度。

Conclusion: RSTrack 通过明确建模和监督上下文推理，有效解决了传统时间建模中的上下文关联发散问题，并在多个基准数据集上实现了最先进的性能，同时保持了实时运行速度。

Abstract: Contextual reasoning with constraints is crucial for enhancing temporal
consistency in cross-frame modeling for visual tracking. However, mainstream
tracking algorithms typically associate context by merely stacking historical
information without explicitly supervising the association process, making it
difficult to effectively model the target's evolving dynamics. To alleviate
this problem, we propose RSTrack, which explicitly models and supervises
context reasoning via three core mechanisms. \textit{1) Context Reasoning
Mechanism}: Constructs a target state reasoning pipeline, converting
unconstrained contextual associations into a temporal reasoning process that
predicts the current representation based on historical target states, thereby
enhancing temporal consistency. \textit{2) Forward Supervision Strategy}:
Utilizes true target features as anchors to constrain the reasoning pipeline,
guiding the predicted output toward the true target distribution and
suppressing drift in the context reasoning process. \textit{3) Efficient State
Modeling}: Employs a compression-reconstruction mechanism to extract the core
features of the target, removing redundant information across frames and
preventing ineffective contextual associations. These three mechanisms
collaborate to effectively alleviate the issue of contextual association
divergence in traditional temporal modeling. Experimental results show that
RSTrack achieves state-of-the-art performance on multiple benchmark datasets
while maintaining real-time running speeds. Our code is available at
https://github.com/GXNU-ZhongLab/RSTrack.

</details>


### [24] [LMM4Edit: Benchmarking and Evaluating Multimodal Image Editing with LMMs](https://arxiv.org/abs/2507.16193)
*Zitong Xu,Huiyu Duan,Bingnan Liu,Guangji Ma,Jiarui Wang,Liu Yang,Shiqi Gao,Xiaoyu Wang,Jia Wang,Xiongkuo Min,Guangtao Zhai,Weisi Lin*

Main category: cs.CV

TL;DR: 提出 EBench-18K 数据集和 LMM4Edit 评估指标，解决了现有文本引导图像编辑（TIE）模型评估中的局限性，并能更好地与人类偏好保持一致。


<details>
  <summary>Details</summary>
Motivation: 现有文本引导图像编辑（TIE）模型在图像质量、编辑对齐和与原始图像的一致性之间难以取得平衡，限制了其实际应用。此外，现有的 TIE 评估基准和指标在规模或与人类感知的匹配度方面存在局限性。

Method: 提出了一种名为 EBench-18K 的大规模图像编辑基准，其中包含 18K 张经过编辑的图像以及细粒度的人类偏好标注。该基准包括 1,080 张源图像、对应的编辑提示、17 个最先进的 TIE 模型生成的 18K+ 编辑图像、超过 55K 的平均意见得分（MOSs）以及 18K+ 的问答对。基于此基准，利用大型语言模型（LMM）评估编辑后的图像，并提出了一种名为 LMM4Edit 的 LMM 驱动的评估指标。

Result: EBench-18K 是首个包含 18K 张编辑图像和细粒度人类偏好标注的大规模图像编辑基准。提出的 LMM4Edit 指标能够综合评估感知质量、编辑对齐、属性保留和任务特定问答准确性，并与人类偏好保持良好一致性，在实验中表现出色，并具有良好的泛化能力。

Conclusion: LMM4Edit 作为一种基于大型语言模型（LMM）的评估指标，能够从感知质量、编辑对齐、属性保留和任务特定问答准确性等方面对图像编辑模型进行综合评估，并且在实验中表现出色，与人类偏好高度一致。此外，该模型在其他数据集上的零样本验证也证明了其泛化能力。

Abstract: The rapid advancement of Text-guided Image Editing (TIE) enables image
modifications through text prompts. However, current TIE models still struggle
to balance image quality, editing alignment, and consistency with the original
image, limiting their practical applications. Existing TIE evaluation
benchmarks and metrics have limitations on scale or alignment with human
perception. To this end, we introduce EBench-18K, the first large-scale image
Editing Benchmark including 18K edited images with fine-grained human
preference annotations for evaluating TIE. Specifically, EBench-18K includes
1,080 source images with corresponding editing prompts across 21 tasks, 18K+
edited images produced by 17 state-of-the-art TIE models, 55K+ mean opinion
scores (MOSs) assessed from three evaluation dimensions, and 18K+
question-answering (QA) pairs. Based on EBench-18K, we employ outstanding LMMs
to assess edited images, while the evaluation results, in turn, provide
insights into assessing the alignment between the LMMs' understanding ability
and human preferences. Then, we propose LMM4Edit, a LMM-based metric for
evaluating image Editing models from perceptual quality, editing alignment,
attribute preservation, and task-specific QA accuracy in an all-in-one manner.
Extensive experiments show that LMM4Edit achieves outstanding performance and
aligns well with human preference. Zero-shot validation on the other datasets
also shows the generalization ability of our model. The dataset and code are
available at https://github.com/IntMeGroup/LMM4Edit.

</details>


### [25] [A Single-step Accurate Fingerprint Registration Method Based on Local Feature Matching](https://arxiv.org/abs/2507.16201)
*Yuwei Jia,Zhe Cui,Fei Su*

Main category: cs.CV

TL;DR: 本研究提出了一种新的单步指纹配准方法，通过直接预测匹配点来解决传统两步法中因低质量指纹图像导致的初始配准失败问题，并取得了先进的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的指纹配准方法通常包括基于 त्याची点的初始配准和基于匹配点的密集配准两个步骤。然而，当指纹图像质量较低时，检测到的 त्याची点数量会减少，导致初始配准频繁失败，最终导致整个指纹配准过程失败。因此，需要一种能够解决此问题的新方法。

Method: 本研究提出了一种端到端的单步指纹配准算法，通过直接预测两个指纹之间的半密集匹配点对应关系来进行对齐。该方法利用全局-局部注意力机制来实现两个指纹之间的像素级对齐。

Result: 实验结果证明，本研究提出的方法仅用单步配准即可达到最先进的匹配性能，并且还可以与密集配准算法结合以进一步提高性能。

Conclusion: 本研究提出了一种端到端的单步指纹配准算法，通过直接预测两个指纹之间的半密集匹配点对应关系来进行对齐，从而最大限度地降低了 त्याची点配准失败的风险。实验结果证明，该方法仅用单步配准即可达到最先进的匹配性能，并且还可以与密集配准算法结合以进一步提高性能。

Abstract: Distortion of the fingerprint images leads to a decline in fingerprint
recognition performance, and fingerprint registration can mitigate this
distortion issue by accurately aligning two fingerprint images. Currently,
fingerprint registration methods often consist of two steps: an initial
registration based on minutiae, and a dense registration based on matching
points. However, when the quality of fingerprint image is low, the number of
detected minutiae is reduced, leading to frequent failures in the initial
registration, which ultimately causes the entire fingerprint registration
process to fail. In this study, we propose an end-to-end single-step
fingerprint registration algorithm that aligns two fingerprints by directly
predicting the semi-dense matching points correspondences between two
fingerprints. Thus, our method minimizes the risk of minutiae registration
failure and also leverages global-local attentions to achieve end-to-end
pixel-level alignment between the two fingerprints. Experiment results prove
that our method can achieve the state-of-the-art matching performance with only
single-step registration, and it can also be used in conjunction with dense
registration algorithms for further performance improvements.

</details>


### [26] [Advancing Visual Large Language Model for Multi-granular Versatile Perception](https://arxiv.org/abs/2507.16213)
*Wentao Xiang,Haoxian Tan,Cong Wei,Yujie Zhong,Dengjie Li,Yujiu Yang*

Main category: cs.CV

TL;DR: MVP-LM是一个多粒度的视觉感知框架，利用大型语言模型整合了多种视觉任务，并通过新的解码器和数据集策略提高了性能。


<details>
  <summary>Details</summary>
Motivation: 现有研究往往只关注有限的感知任务组合，限制了其在不同场景下的适用性和多功能性。MVP-LM旨在解决这一挑战，提供一个能够整合多种感知任务（包括基于词和基于句子的任务以及边界和掩码预测）的统一框架。

Method: MVP-LM框架是一个整合了语言大模型的多粒度视觉感知框架，它包含一个多粒度解码器和一种受CoT启发的全景分割、检测、指代、和参照表达分割等任务的数据集统一策略，并引入了一种查询增强策略来利用VLLM的解码和生成能力。

Result: 通过在多个基准的词和句子感知任务上进行的大量实验证明了MVP-LM框架的有效性。

Conclusion: MVP-LM框架在各种基于词和基于句子的感知任务上都展现了其有效性。

Abstract: Perception is a fundamental task in the field of computer vision,
encompassing a diverse set of subtasks that can be systematically categorized
into four distinct groups based on two dimensions: prediction type and
instruction type. Notably, existing researches often focus solely on a limited
subset of these potential combinations, which constrains their applicability
and versatility across various contexts. In response to this challenge, we
present MVP-LM, a Multi-granular and Versatile Perception framework
incorporating Visual Large Language Model. Our framework is designed to
integrate both word-based and sentence-based perception tasks alongside box and
mask predictions within a single architecture. MVP-LM features an innovative
multi-granularity decoder in conjunction with a CoT-inspired dataset
unification strategy, enabling seamless supervised fine-tuning across a wide
spectrum of tasks, including but not limited to panoptic segmentation,
detection, grounding, and referring expression segmentation. Furthermore, we
introduce a query enhancement strategy aimed at harnessing the decoding and
generative capabilities inherent in VLLMs. Extensive experiments conducted
across a range of benchmarks in both word-based and sentence-based perception
tasks substantiate the efficacy of our framework. The code will be available at
https://github.com/xiangwentao666/MVP-LM.

</details>


### [27] [LDRFusion: A LiDAR-Dominant multimodal refinement framework for 3D object detection](https://arxiv.org/abs/2507.16224)
*Jijun Wang,Yan Wu,Yujian Mo,Junqiao Zhao,Jun Yan,Yinghao Hu*

Main category: cs.CV

TL;DR: LDRFusion是一种创新的激光雷达为主导的融合框架，通过两阶段细化和伪点残差编码，解决了现有方法的噪声问题，并在KITTI数据集上取得了优异成果。


<details>
  <summary>Details</summary>
Motivation: 解决现有激光雷达-相机融合方法中，由于引入伪点云带来的噪声问题，以及各传感器的可靠性差异。

Method: 提出了一种新颖的、以激光雷达为主导的两阶段细化框架LDRFusion，用于多传感器融合。该框架首先仅依赖激光雷达生成精确的提议，然后引入伪点云来检测难例，并融合两个阶段的结果。为增强伪点云的局部结构表示，提出了一种分层伪点残差编码模块，通过特征和位置残差来编码邻域集。

Result: 在KITTI数据集上，LDRFusion框架在多个类别和难度级别上始终表现出强大的性能。

Conclusion: LDRFusion框架在KITTI数据集上实现了跨类别和难度的强大性能。

Abstract: Existing LiDAR-Camera fusion methods have achieved strong results in 3D
object detection. To address the sparsity of point clouds, previous approaches
typically construct spatial pseudo point clouds via depth completion as
auxiliary input and adopts a proposal-refinement framework to generate
detection results. However, introducing pseudo points inevitably brings noise,
potentially resulting in inaccurate predictions. Considering the differing
roles and reliability levels of each modality, we propose LDRFusion, a novel
Lidar-dominant two-stage refinement framework for multi-sensor fusion. The
first stage soley relies on LiDAR to produce accurately localized proposals,
followed by a second stage where pseudo point clouds are incorporated to detect
challenging instances. The instance-level results from both stages are
subsequently merged. To further enhance the representation of local structures
in pseudo point clouds, we present a hierarchical pseudo point residual
encoding module, which encodes neighborhood sets using both feature and
positional residuals. Experiments on the KITTI dataset demonstrate that our
framework consistently achieves strong performance across multiple categories
and difficulty levels.

</details>


### [28] [MONITRS: Multimodal Observations of Natural Incidents Through Remote Sensing](https://arxiv.org/abs/2507.16228)
*Shreelekha Revankar,Utkarsh Mall,Cheng Perng Phoo,Kavita Bala,Bharath Hariharan*

Main category: cs.CV

TL;DR: MONITRS是一个包含超过10,000个FEMA灾害事件、时间序列卫星图像、新闻文章注释、地理标记位置和问答对的多模态数据集，可用于改进机器学习辅助的灾害响应系统。


<details>
  <summary>Details</summary>
Motivation: 自然灾害每年都会对社区和基础设施造成破坏性损害，而有效的灾害响应因事件期间和之后难以进入受灾地区而受到阻碍。虽然计算机视觉和深度学习的最新进展有助于自动化卫星图像分析，但它们仍然局限于特定的灾害类型、依赖手动专家解释以及缺乏具有足够时间粒度或用于跟踪灾害进展的自然语言注释的数据集。

Method: 提出了一种名为MONITRS的新型多模态数据集，其中包含超过10,000个FEMA灾害事件，以及时间序列卫星图像和来自新闻文章的自然语言注释、地理标记位置和问答对。

Result: MONITRS数据集可以显著提高灾害监测任务的性能。

Conclusion: 微调现有的MLLMs可以显著提高灾害监测任务的性能，为机器学习辅助的灾害响应系统树立了新的基准。

Abstract: Natural disasters cause devastating damage to communities and infrastructure
every year. Effective disaster response is hampered by the difficulty of
accessing affected areas during and after events. Remote sensing has allowed us
to monitor natural disasters in a remote way. More recently there have been
advances in computer vision and deep learning that help automate satellite
imagery analysis, However, they remain limited by their narrow focus on
specific disaster types, reliance on manual expert interpretation, and lack of
datasets with sufficient temporal granularity or natural language annotations
for tracking disaster progression. We present MONITRS, a novel multimodal
dataset of more than 10,000 FEMA disaster events with temporal satellite
imagery and natural language annotations from news articles, accompanied by
geotagged locations, and question-answer pairs. We demonstrate that fine-tuning
existing MLLMs on our dataset yields significant performance improvements for
disaster monitoring tasks, establishing a new benchmark for machine
learning-assisted disaster response systems. Code can be found at:
https://github.com/ShreelekhaR/MONITRS

</details>


### [29] [Positive Style Accumulation: A Style Screening and Continuous Utilization Framework for Federated DG-ReID](https://arxiv.org/abs/2507.16238)
*Xin Xu,Chaoyue Ren,Wei Liu,Wenke Huang,Bin Yang,Zhixi Yu,Kui Jiang*

Main category: cs.CV

TL;DR: 通过SSCU框架，利用GGDSM和CST策略，有效筛选并持续利用积极风格，提升了FedDG-ReID模型的泛化性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法主要通过风格转换提高样本多样性，但并非所有风格都有助于泛化性能。因此，需要筛选出有利的风格（积极风格）和有害的风格（消极风格），并解决如何有效筛选和持续利用积极风格的问题。

Method: 提出了一种风格筛选和持续利用（SSCU）框架，包括：1. 针对每个客户端模型设计了由泛化增益指导的动态风格记忆（GGDSM），用于筛选和累积生成的风格。2. 提出了风格记忆识别损失，以充分利用记忆中存储的风格。3. 提出了一种协同风格训练（CST）策略，利用新生成的风格和内存中累积的风格，在两个不同的分支上训练客户端模型，以促进模型快速获取新风格并持续利用积极风格。

Result: 实验结果表明，该方法在源域和目标域上的表现均优于现有方法。

Conclusion: 该方法在源域和目标域上均优于现有方法。

Abstract: The Federated Domain Generalization for Person re-identification (FedDG-ReID)
aims to learn a global server model that can be effectively generalized to
source and target domains through distributed source domain data. Existing
methods mainly improve the diversity of samples through style transformation,
which to some extent enhances the generalization performance of the model.
However, we discover that not all styles contribute to the generalization
performance. Therefore, we define styles that are beneficial or harmful to the
model's generalization performance as positive or negative styles. Based on
this, new issues arise: How to effectively screen and continuously utilize the
positive styles. To solve these problems, we propose a Style Screening and
Continuous Utilization (SSCU) framework. Firstly, we design a Generalization
Gain-guided Dynamic Style Memory (GGDSM) for each client model to screen and
accumulate generated positive styles. Meanwhile, we propose a style memory
recognition loss to fully leverage the positive styles memorized by Memory.
Furthermore, we propose a Collaborative Style Training (CST) strategy to make
full use of positive styles. Unlike traditional learning strategies, our
approach leverages both newly generated styles and the accumulated positive
styles stored in memory to train client models on two distinct branches. This
training strategy is designed to effectively promote the rapid acquisition of
new styles by the client models, and guarantees the continuous and thorough
utilization of positive styles, which is highly beneficial for the model's
generalization performance. Extensive experimental results demonstrate that our
method outperforms existing methods in both the source domain and the target
domain.

</details>


### [30] [Scale Your Instructions: Enhance the Instruction-Following Fidelity of Unified Image Generation Model by Self-Adaptive Attention Scaling](https://arxiv.org/abs/2507.16240)
*Chao Zhou,Tianyi Wei,Nenghai Yu*

Main category: cs.CV

TL;DR: SaaS 是一种新的方法，用于解决统一图像生成模型在处理包含多个子指令的文本指令时出现的指令忽视问题，通过动态调整注意力激活来提高指令遵循能力。


<details>
  <summary>Details</summary>
Motivation: 统一的图像生成模型（如 OmniGen）虽然简化了多模态、交错文本和图像的统一框架，但存在文本指令忽视的问题，尤其是在文本指令包含多个子指令时。

Method: 提出了一种名为 SaaS（Self-Adaptive Attention Scaling）的方法，该方法利用相邻时间步长之间交叉注意力的ー致性来动态地为每个子指令调整注意力激活。

Result: 实验结果表明，SaaS 在基于指令的图像编辑和视觉条件图像生成任务上，其指令遵循保真度优于现有方法。

Conclusion: SaaS 能够增强指令遵循保真度，无需额外训练或测试时优化。

Abstract: Recent advancements in unified image generation models, such as OmniGen, have
enabled the handling of diverse image generation and editing tasks within a
single framework, accepting multimodal, interleaved texts and images in free
form. This unified architecture eliminates the need for text encoders, greatly
reducing model complexity and standardizing various image generation and
editing tasks, making it more user-friendly. However, we found that it suffers
from text instruction neglect, especially when the text instruction contains
multiple sub-instructions. To explore this issue, we performed a perturbation
analysis on the input to identify critical steps and layers. By examining the
cross-attention maps of these key steps, we observed significant conflicts
between neglected sub-instructions and the activations of the input image. In
response, we propose Self-Adaptive Attention Scaling (SaaS), a method that
leverages the consistency of cross-attention between adjacent timesteps to
dynamically scale the attention activation for each sub-instruction. Our SaaS
enhances instruction-following fidelity without requiring additional training
or test-time optimization. Experimental results on instruction-based image
editing and visual conditional image generation validate the effectiveness of
our SaaS, showing superior instruction-following fidelity over existing
methods. The code is available https://github.com/zhouchao-ops/SaaS.

</details>


### [31] [HoliTracer: Holistic Vectorization of Geographic Objects from Large-Size Remote Sensing Imagery](https://arxiv.org/abs/2507.16251)
*Yu Wang,Bo Dang,Wanchun Li,Wei Chen,Yansheng Li*

Main category: cs.CV

TL;DR: HoliTracer 是首个从大型遥感影像中整体提取矢量化地理对象的框架，通过结合上下文注意力网络（CAN）、掩码轮廓重建器（MCR）和多边形序列追踪器（PST），解决了小图像块处理带来的信息丢失和输出碎片化问题，并在多个数据集上取得了优于现有方法的性能。


<details>
  <summary>Details</summary>
Motivation: 为了解决现有方法在处理大型遥感影像时，由于通常只处理小图像块而导致的上下文信息丢失和矢量输出碎片化问题。

Method: HoliTracer 框架，包含上下文注意力网络（CAN）用于增强分割，以及掩码轮廓重建器（MCR）和多边形序列追踪器（PST）用于整体矢量化。

Result: HoliTracer 能够从大型遥感影像中整体提取矢量化地理对象，并在建筑物、水体和道路数据集上取得了优于现有最先进方法的性能。

Conclusion: HoliTracer 在处理建筑物、水体和道路等大型遥感影像数据集方面，相比于现有方法表现更优。

Abstract: With the increasing resolution of remote sensing imagery (RSI), large-size
RSI has emerged as a vital data source for high-precision vector mapping of
geographic objects. Existing methods are typically constrained to processing
small image patches, which often leads to the loss of contextual information
and produces fragmented vector outputs. To address these, this paper introduces
HoliTracer, the first framework designed to holistically extract vectorized
geographic objects from large-size RSI. In HoliTracer, we enhance segmentation
of large-size RSI using the Context Attention Net (CAN), which employs a
local-to-global attention mechanism to capture contextual dependencies.
Furthermore, we achieve holistic vectorization through a robust pipeline that
leverages the Mask Contour Reformer (MCR) to reconstruct polygons and the
Polygon Sequence Tracer (PST) to trace vertices. Extensive experiments on
large-size RSI datasets, including buildings, water bodies, and roads,
demonstrate that HoliTracer outperforms state-of-the-art methods. Our code and
data are available in https://github.com/vvangfaye/HoliTracer.

</details>


### [32] [ThinkAct: Vision-Language-Action Reasoning via Reinforced Visual Latent Planning](https://arxiv.org/abs/2507.16815)
*Chi-Pin Huang,Yueh-Hua Wu,Min-Hung Chen,Yu-Chiang Frank Wang,Fu-En Yang*

Main category: cs.CV

TL;DR: ThinkAct是一个创新的双系统框架，通过视觉潜在规划连接推理和执行，解决了现有VLA模型的局限性，并在具身AI任务中取得了显著成果。


<details>
  <summary>Details</summary>
Motivation: 现有方法通常以端到端的方式训练VLA模型，直接将输入映射到动作，缺乏显式的推理，这限制了它们进行多步规划或适应复杂任务变化的能力。

Method: ThinkAct是一个双系统框架，通过增强的视觉潜在规划连接高级推理和低级动作执行。它训练一个多模态LLM生成由基于目标完成和轨迹一致性的动作对齐视觉奖励驱动的具身推理计划。这些推理计划被压缩成一个视觉计划潜在表示，用于条件化下游动作模型，从而在目标环境中实现鲁棒的动作执行。

Result: 在具身推理和机器人操控基准上的大量实验表明，ThinkAct在复杂的具身AI任务中能够实现少样本适应、长时程规划和自我纠正行为。

Conclusion: ThinkAct框架通过结合高级推理和低级动作执行，利用增强的视觉潜在规划，在具身AI任务中实现了少样本适应、长时程规划和自我纠正行为。

Abstract: Vision-language-action (VLA) reasoning tasks require agents to interpret
multimodal instructions, perform long-horizon planning, and act adaptively in
dynamic environments. Existing approaches typically train VLA models in an
end-to-end fashion, directly mapping inputs to actions without explicit
reasoning, which hinders their ability to plan over multiple steps or adapt to
complex task variations. In this paper, we propose ThinkAct, a dual-system
framework that bridges high-level reasoning with low-level action execution via
reinforced visual latent planning. ThinkAct trains a multimodal LLM to generate
embodied reasoning plans guided by reinforcing action-aligned visual rewards
based on goal completion and trajectory consistency. These reasoning plans are
compressed into a visual plan latent that conditions a downstream action model
for robust action execution on target environments. Extensive experiments on
embodied reasoning and robot manipulation benchmarks demonstrate that ThinkAct
enables few-shot adaptation, long-horizon planning, and self-correction
behaviors in complex embodied AI tasks.

</details>


### [33] [Edge-case Synthesis for Fisheye Object Detection: A Data-centric Perspective](https://arxiv.org/abs/2507.16254)
*Seunghyeon Kim,Kyeongryeol Go*

Main category: cs.CV

TL;DR: 通过识别和合成鱼眼相机目标检测模型的失败案例，来提升模型性能。


<details>
  <summary>Details</summary>
Motivation: 鱼眼相机引入了显著的失真，并给在传统数据集上训练的目标检测模型带来了独特的挑战。

Method: 提出一个以数据为中心的管道，通过识别模型的盲点来系统地改进检测性能。通过详细的错误分析，识别关键的边缘情况（如易混淆的类别对、外围失真和表示不足的上下文），然后通过边缘情况合成直接解决这些问题。微调了图像生成模型，并用精心设计的提示进行引导，以生成复制真实世界失败模式的图像。使用高质量的检测器对这些合成图像进行伪标签，并将其整合到训练中。

Result: 该方法在鱼眼相机目标检测任务中取得了持续的性能提升。

Conclusion: 通过深入理解数据并有选择地修复其弱点，可以有效地提升鱼眼相机目标检测等专业领域的性能。

Abstract: Fisheye cameras introduce significant distortion and pose unique challenges
to object detection models trained on conventional datasets. In this work, we
propose a data-centric pipeline that systematically improves detection
performance by focusing on the key question of identifying the blind spots of
the model. Through detailed error analysis, we identify critical edge-cases
such as confusing class pairs, peripheral distortions, and underrepresented
contexts. Then we directly address them through edge-case synthesis. We
fine-tuned an image generative model and guided it with carefully crafted
prompts to produce images that replicate real-world failure modes. These
synthetic images are pseudo-labeled using a high-quality detector and
integrated into training. Our approach results in consistent performance gains,
highlighting how deeply understanding data and selectively fixing its
weaknesses can be impactful in specialized domains like fisheye object
detection.

</details>


### [34] [Quality Text, Robust Vision: The Role of Language in Enhancing Visual Robustness of Vision-Language Models](https://arxiv.org/abs/2507.16257)
*Futa Waseda,Saku Sugawara,Isao Echizen*

Main category: cs.CV

TL;DR: QT-AFT通过利用高质量的文本描述来增强预训练视觉-语言模型（VLMs）的对抗鲁棒性，克服了现有方法的不足，并在多项评估中取得了优异成果。


<details>
  <summary>Details</summary>
Motivation: 现有的对抗训练（AT）方法在增强预训练视觉-语言模型（VLMs）的视觉鲁棒性方面，忽视了语言的作用。监督AT方法依赖简短文本（如类别标签）生成对抗性扰动，易导致对训练数据的类别过拟合；无监督AT方法虽然避免了过拟合，但由于缺乏语义指导，在实际的文本引导的对抗攻击下效果不佳。

Method: 提出了一种名为QT-AFT（Quality Text-guided Adversarial Fine-Tuning）的方法，该方法在训练过程中利用高质量的文本描述来指导对抗样本，使其偏离图像中的多样化语义，从而增强视觉编码器的鲁棒性。

Result: QT-AFT通过利用高质量的文本描述，使视觉编码器能够在对抗噪声下稳健地识别更广泛的图像特征，从而在各种下游任务中增强鲁棒性，实现了最先进的零样本对抗鲁棒性和准确性。

Conclusion: QT-AFT克服了现有监督和无监督对抗训练方法的弱点，在16个零样本数据集上实现了最先进的零样本对抗鲁棒性和准确性。研究还揭示了语言在增强视觉鲁棒性方面的关键作用，例如描述物体属性可以进一步提高零样本鲁棒性。

Abstract: Defending pre-trained vision-language models (VLMs), such as CLIP, against
adversarial attacks is crucial, as these models are widely used in diverse
zero-shot tasks, including image classification. However, existing adversarial
training (AT) methods for robust fine-tuning largely overlook the role of
language in enhancing visual robustness. Specifically, (1) supervised AT
methods rely on short texts (e.g., class labels) to generate adversarial
perturbations, leading to overfitting to object classes in the training data,
and (2) unsupervised AT avoids this overfitting but remains suboptimal against
practical text-guided adversarial attacks due to its lack of semantic guidance.
To address these limitations, we propose Quality Text-guided Adversarial
Fine-Tuning (QT-AFT), which leverages high-quality captions during training to
guide adversarial examples away from diverse semantics present in images. This
enables the visual encoder to robustly recognize a broader range of image
features even under adversarial noise, thereby enhancing robustness across
diverse downstream tasks. QT-AFT overcomes the key weaknesses of prior methods
-- overfitting in supervised AT and lack of semantic awareness in unsupervised
AT -- achieving state-of-the-art zero-shot adversarial robustness and clean
accuracy, evaluated across 16 zero-shot datasets. Furthermore, our
comprehensive study uncovers several key insights into the role of language in
enhancing vision robustness; for example, describing object properties in
addition to object names further enhances zero-shot robustness. Our findings
point to an urgent direction for future work -- centering high-quality
linguistic supervision in robust visual representation learning.

</details>


### [35] [ToFe: Lagged Token Freezing and Reusing for Efficient Vision Transformer Inference](https://arxiv.org/abs/2507.16260)
*Haoyue Zhang,Jie Zhang,Song Guo*

Main category: cs.CV

TL;DR: ToFe框架通过冻结和复用令牌，解决了ViT在资源受限设备上的效率问题，降低了计算成本，同时保持了准确率。


<details>
  <summary>Details</summary>
Motivation: 现有的ViT模型在资源受限设备上的部署受限于计算成本高昂的自注意力机制。现有的令牌缩减方法将不重要的令牌不可逆地丢弃，阻止了它们在后续块中的重用，而这些令牌可能在后续阶段有用。因此，需要一种能够平衡模型性能和计算开销的方法。

Method: 提出了一种新颖的令牌冻结和复用（ToFe）框架，该框架通过设计一个用于令牌识别的预测模块和一个用于恢复冻结令牌的近似模块，并结合计算预算感知端到端训练，实现了自适应处理每个块的必要令牌，从而降低了计算成本并保持了性能。

Result: ToFe框架将LV-ViT模型的计算成本降低了50%，同时Top-1准确率下降不到2%，与现有最先进方法相比，在性能和复杂性之间实现了更好的权衡。

Conclusion: ToFe框架通过在每个阶段识别重要令牌并暂时冻结不重要的令牌，实现了在保持性能的同时将计算成本降低50%，而Top-1准确率下降不到2%，从而在性能和复杂性之间取得了比最先进方法更好的权衡。

Abstract: Although vision transformers (ViT) have shown remarkable success in various
vision tasks, their computationally expensive self-attention hinder their
deployment on resource-constrained devices. Token reduction, which discards
less important tokens during forward propagation, has been proposed to enhance
the efficiency of transformer models. However, existing methods handle
unimportant tokens irreversibly, preventing their reuse in subsequent blocks.
Considering that transformers focus on different information among blocks,
tokens reduced in early blocks might be useful later. Furthermore, to adapt
transformer models for resource-constrained devices, it is crucial to strike a
balance between model performance and computational overhead. To address these
challenges, in this paper, we introduce a novel Token Freezing and Reusing
(ToFe) framework, where we identify important tokens at each stage and
temporarily freeze the unimportant ones, allowing their lagged reusing at a
later stage. Specifically, we design a prediction module for token
identification and an approximate module for recovery of the frozen tokens. By
jointly optimizing with the backbone through computation budget-aware
end-to-end training, ToFe can adaptively process the necessary tokens at each
block, thereby reducing computational cost while maintaining performance.
Extensive experiments demonstrate that ToFe reduces the computational cost of
LV-ViT model by 50% with less than 2% drop in Top-1 accuracy, achieving a
better trade-off between performance and complexity compared to
state-of-the-art methods.

</details>


### [36] [MAN++: Scaling Momentum Auxiliary Network for Supervised Local Learning in Vision Tasks](https://arxiv.org/abs/2507.16279)
*Junhao Su,Feiyu Zhu,Hengyu Shi,Tianyang Han,Yurui Qiu,Junfeng Luo,Xiaoming Wei,Jialin Gao*

Main category: cs.CV

TL;DR: MAN++ 是一种新的监督式局部学习方法，通过使用相邻块参数的 EMA 和可学习的缩放偏差来改进信息流，实现了与端到端训练相当的性能，同时降低了内存消耗。


<details>
  <summary>Details</summary>
Motivation: 为了解决监督式局部学习中存在的性能下降问题，并促进块间信息流，MAN++ 引入了一种动态交互机制。

Method: MAN++ 提出了一种动态交互机制，通过使用相邻块参数的指数移动平均 (EMA) 来增强网络通信。通过 EMA 更新的辅助网络有效地弥合了块之间的信息差距。引入了一个可学习的缩放偏差来平衡特征差异，以解决直接应用 EMA 参数可能因局部块之间的特征差异而不理想的问题。

Result: MAN++ 在图像分类、目标检测和图像分割等任务以及多种网络架构上进行了广泛的实验验证，结果表明其性能与端到端训练相当，同时显著减少了 GPU 内存使用量。

Conclusion: MAN++ 实现了与端到端训练相当的性能，同时显著降低了 GPU 内存使用量，为监督式局部学习提供了新视角，并成为传统训练方法的可行替代方案。

Abstract: Deep learning typically relies on end-to-end backpropagation for training, a
method that inherently suffers from issues such as update locking during
parameter optimization, high GPU memory consumption, and a lack of biological
plausibility. In contrast, supervised local learning seeks to mitigate these
challenges by partitioning the network into multiple local blocks and designing
independent auxiliary networks to update each block separately. However,
because gradients are propagated solely within individual local blocks,
performance degradation occurs, preventing supervised local learning from
supplanting end-to-end backpropagation. To address these limitations and
facilitate inter-block information flow, we propose the Momentum Auxiliary
Network++ (MAN++). MAN++ introduces a dynamic interaction mechanism by
employing the Exponential Moving Average (EMA) of parameters from adjacent
blocks to enhance communication across the network. The auxiliary network,
updated via EMA, effectively bridges the information gap between blocks.
Notably, we observed that directly applying EMA parameters can be suboptimal
due to feature discrepancies between local blocks. To resolve this issue, we
introduce a learnable scaling bias that balances feature differences, thereby
further improving performance. We validate MAN++ through extensive experiments
on tasks that include image classification, object detection, and image
segmentation, utilizing multiple network architectures. The experimental
results demonstrate that MAN++ achieves performance comparable to end-to-end
training while significantly reducing GPU memory usage. Consequently, MAN++
offers a novel perspective for supervised local learning and presents a viable
alternative to conventional training methods.

</details>


### [37] [Beyond Label Semantics: Language-Guided Action Anatomy for Few-shot Action Recognition](https://arxiv.org/abs/2507.16287)
*Zefeng Qian,Xincheng Yao,Yifei Huang,Chongyang Zhang,Jiangyong Ying,Hong Sun*

Main category: cs.CV

TL;DR: 本研究提出LGA框架，利用LLM解析动作标签，提取关键表征特征，并通过解剖视频和精细融合，提升少样本动作识别的准确性，实验结果表明其性能优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 目前的少样本动作识别（FSAR）方法虽然利用文本模态，但未能充分挖掘动作标签背后隐藏的、关于姿势、运动动态和物体交互的细微变化等关键固有知识。本研究旨在超越单纯的标签语义，利用LLM来解析这些隐藏的表征特征，以提升FSAR的性能。

Method: 提出了一种名为语言引导动作解剖（LGA）的新颖框架。该框架利用大型语言模型（LLM）来解析动作标签，提取其潜在的表征特征。具体而言，它通过提示LLM将动作标签分解为原子动作描述序列，重点关注主语、动作和对象三个核心要素。同时，视频解剖模块将动作分割为原子视频片段，以捕捉动作的序列结构。最后，通过精细的融合策略整合文本和视频特征，并引入包含视频-视频和视频-文本匹配的多模态匹配机制，以实现鲁棒的少样本分类。

Result: LGA框架通过语言引导的动作解剖，有效捕捉了少样本场景下的丰富时空线索，实现了比现有方法更优的性能。

Conclusion: LGA框架在多个少样本动作识别（FSAR）基准测试中取得了最先进的性能。

Abstract: Few-shot action recognition (FSAR) aims to classify human actions in videos
with only a small number of labeled samples per category. The scarcity of
training data has driven recent efforts to incorporate additional modalities,
particularly text. However, the subtle variations in human posture, motion
dynamics, and the object interactions that occur during different phases, are
critical inherent knowledge of actions that cannot be fully exploited by action
labels alone. In this work, we propose Language-Guided Action Anatomy (LGA), a
novel framework that goes beyond label semantics by leveraging Large Language
Models (LLMs) to dissect the essential representational characteristics hidden
beneath action labels. Guided by the prior knowledge encoded in LLM, LGA
effectively captures rich spatiotemporal cues in few-shot scenarios.
Specifically, for text, we prompt an off-the-shelf LLM to anatomize labels into
sequences of atomic action descriptions, focusing on the three core elements of
action (subject, motion, object). For videos, a Visual Anatomy Module segments
actions into atomic video phases to capture the sequential structure of
actions. A fine-grained fusion strategy then integrates textual and visual
features at the atomic level, resulting in more generalizable prototypes.
Finally, we introduce a Multimodal Matching mechanism, comprising both
video-video and video-text matching, to ensure robust few-shot classification.
Experimental results demonstrate that LGA achieves state-of-the-art performance
across multipe FSAR benchmarks.

</details>


### [38] [Dens3R: A Foundation Model for 3D Geometry Prediction](https://arxiv.org/abs/2507.16290)
*Xianze Fang,Jingnan Gao,Zhe Wang,Zhuo Chen,Xingyu Ren,Jiangjing Lyu,Qiaomu Ren,Zhonglei Yang,Xiaokang Yang,Yichao Yan,Chengfei Lyu*

Main category: cs.CV

TL;DR: Dens3R是一个用于联合几何密集预测的3D基础模型，通过整合图像对匹配特征和内在不变性建模，能准确回归多种几何量，并支持多视图推理，在各种任务中表现优越。


<details>
  <summary>Details</summary>
Motivation: 现有的3D重建方法大多仅限于从输入图像中预测单一几何量。然而，深度、表面法线和点图等几何量本质上是相互关联的，孤立地估计它们往往无法确保一致性，从而限制了精度和实际应用性。这促使我们探索一个显式建模不同几何属性之间结构耦合的统一框架，以实现联合回归。

Method: Dens3R采用两阶段训练框架，逐步构建一个可泛化且内在地不变的点图表示。具体来说，我们设计了一个轻量级的共享编码器-解码器骨干，并引入了位置插值旋转位置编码，以在增强对高分辨率输入的鲁棒性的同时保持表达能力。通过整合图像对匹配特征与内在不变性建模，Dens3R能够从单视图到多视图输入准确回归表面法线和深度等多种几何量，实现一致的几何感知。此外，我们还提出了一种支持几何一致性多视图推理的后处理流程。

Result: Dens3R能够从单视图到多视图输入准确回归表面法线和深度等多种几何量，实现一致的几何感知。

Conclusion: Dens3R在各种密集3D预测任务中表现出优越的性能，并强调了其在更广泛应用中的潜力。

Abstract: Recent advances in dense 3D reconstruction have led to significant progress,
yet achieving accurate unified geometric prediction remains a major challenge.
Most existing methods are limited to predicting a single geometry quantity from
input images. However, geometric quantities such as depth, surface normals, and
point maps are inherently correlated, and estimating them in isolation often
fails to ensure consistency, thereby limiting both accuracy and practical
applicability. This motivates us to explore a unified framework that explicitly
models the structural coupling among different geometric properties to enable
joint regression. In this paper, we present Dens3R, a 3D foundation model
designed for joint geometric dense prediction and adaptable to a wide range of
downstream tasks. Dens3R adopts a two-stage training framework to progressively
build a pointmap representation that is both generalizable and intrinsically
invariant. Specifically, we design a lightweight shared encoder-decoder
backbone and introduce position-interpolated rotary positional encoding to
maintain expressive power while enhancing robustness to high-resolution inputs.
By integrating image-pair matching features with intrinsic invariance modeling,
Dens3R accurately regresses multiple geometric quantities such as surface
normals and depth, achieving consistent geometry perception from single-view to
multi-view inputs. Additionally, we propose a post-processing pipeline that
supports geometrically consistent multi-view inference. Extensive experiments
demonstrate the superior performance of Dens3R across various dense 3D
prediction tasks and highlight its potential for broader applications.

</details>


### [39] [MotionShot: Adaptive Motion Transfer across Arbitrary Objects for Text-to-Video Generation](https://arxiv.org/abs/2507.16310)
*Yanchen Liu,Yanan Sun,Zhening Xing,Junyao Gao,Kai Chen,Wenjie Pei*

Main category: cs.CV

TL;DR: MotionShot enables smooth and high-fidelity motion transfer between objects with different appearances and structures using semantic feature matching and shape retargeting.


<details>
  <summary>Details</summary>
Motivation: Existing text-to-video methods struggle to transfer motion smoothly from a reference object to a target object with significant differences in appearance or structure.

Method: MotionShot first performs semantic feature matching for high-level alignments and then establishes low-level morphological alignments through reference-to-target shape retargeting. Motion is encoded with temporal attention.

Result: The framework achieves high-fidelity motion transfer while preserving coherence in appearance and coherently transfers motion across objects, even in the presence of significant appearance and structure disparities, as demonstrated by extensive experiments.

Conclusion: MotionShot is a training-free framework that achieves high-fidelity motion transfer by parsing reference-target correspondences in a fine-grained manner, preserving appearance coherence and coherently transferring motion even with significant appearance and structure disparities.

Abstract: Existing text-to-video methods struggle to transfer motion smoothly from a
reference object to a target object with significant differences in appearance
or structure between them. To address this challenge, we introduce MotionShot,
a training-free framework capable of parsing reference-target correspondences
in a fine-grained manner, thereby achieving high-fidelity motion transfer while
preserving coherence in appearance. To be specific, MotionShot first performs
semantic feature matching to ensure high-level alignments between the reference
and target objects. It then further establishes low-level morphological
alignments through reference-to-target shape retargeting. By encoding motion
with temporal attention, our MotionShot can coherently transfer motion across
objects, even in the presence of significant appearance and structure
disparities, demonstrated by extensive experiments. The project page is
available at: https://motionshot.github.io/.

</details>


### [40] [M-SpecGene: Generalized Foundation Model for RGBT Multispectral Vision](https://arxiv.org/abs/2507.16318)
*Kailai Zhou,Fuqiang Yang,Shixian Wang,Bihan Wen,Chongde Zi,Linsen Chen,Qiu Shen,Xun Cao*

Main category: cs.CV

TL;DR: 提出 M-SpecGene，一个通用的 RGBT 多光谱基础模型，通过自监督学习和创新的掩码策略，实现了跨模态不变表征，并成功应用于多个下游任务，克服了传统方法的局限性。


<details>
  <summary>Details</summary>
Motivation: 现有 RGBT 多光谱视觉任务的研究范式依赖于手动定制模型，存在人工归纳偏见、模态偏见和数据瓶颈等限制。

Method: 提出了一种名为 M-SpecGene 的通用 RGBT 多光谱基础模型，采用自监督学习方法学习跨模态不变表征。引入了跨模态结构稀疏性（CMSS）指标来量化信息密度，并开发了 GMM-CMSS 渐进式掩码策略，以实现灵活、由易到难、以物体为中心的预训练过程。

Result: M-SpecGene 在四个 RGBT 下游任务和十一个数据集上进行了综合实验，验证了其泛化能力。

Conclusion: M-SpecGene 作为一个通用的 RGBT 多光谱基础模型，通过自监督学习跨模态不变表征，并引入 CMSS 指标和 GMM-CMSS 渐进式掩码策略来解决现有方法的局限性。实验证明了 M-SpecGene 在四个 RGBT 任务和十一个数据集上的泛化能力。

Abstract: RGB-Thermal (RGBT) multispectral vision is essential for robust perception in
complex environments. Most RGBT tasks follow a case-by-case research paradigm,
relying on manually customized models to learn task-oriented representations.
Nevertheless, this paradigm is inherently constrained by artificial inductive
bias, modality bias, and data bottleneck. To address these limitations, we make
the initial attempt to build a Generalized RGBT MultiSpectral foundation model
(M-SpecGene), which aims to learn modality-invariant representations from
large-scale broad data in a self-supervised manner. M-SpecGene provides new
insights into multispectral fusion and integrates prior case-by-case studies
into a unified paradigm. Considering the unique characteristic of information
imbalance in RGBT data, we introduce the Cross-Modality Structural Sparsity
(CMSS) metric to quantify the information density across two modalities. Then
we develop the GMM-CMSS progressive masking strategy to facilitate a flexible,
easy-to-hard, and object-centric pre-training process. Comprehensive
experiments validate M-SpecGene's generalizability across eleven datasets for
four RGBT downstream tasks. The code will be available at
https://github.com/CalayZhou/M-SpecGene.

</details>


### [41] [Scene Text Detection and Recognition "in light of" Challenging Environmental Conditions using Aria Glasses Egocentric Vision Cameras](https://arxiv.org/abs/2507.16330)
*Joseph De Mathia,Carlos Francisco Moreno-García*

Main category: cs.CV

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: In an era where wearable technology is reshaping applications, Scene Text
Detection and Recognition (STDR) becomes a straightforward choice through the
lens of egocentric vision. Leveraging Meta's Project Aria smart glasses, this
paper investigates how environmental variables, such as lighting, distance, and
resolution, affect the performance of state-of-the-art STDR algorithms in
real-world scenarios. We introduce a novel, custom-built dataset captured under
controlled conditions and evaluate two OCR pipelines: EAST with CRNN, and EAST
with PyTesseract. Our findings reveal that resolution and distance
significantly influence recognition accuracy, while lighting plays a less
predictable role. Notably, image upscaling emerged as a key pre-processing
technique, reducing Character Error Rate (CER) from 0.65 to 0.48. We further
demonstrate the potential of integrating eye-gaze tracking to optimise
processing efficiency by focusing on user attention zones. This work not only
benchmarks STDR performance under realistic conditions but also lays the
groundwork for adaptive, user-aware AR systems. Our contributions aim to
inspire future research in robust, context-sensitive text recognition for
assistive and research-oriented applications, such as asset inspection and
nutrition analysis. The code is available at
https://github.com/josepDe/Project_Aria_STR.

</details>


### [42] [One Polyp Identifies All: One-Shot Polyp Segmentation with SAM via Cascaded Priors and Iterative Prompt Evolution](https://arxiv.org/abs/2507.16337)
*Xinyu Mao,Xiaohan Xing,Fei Meng,Jianbang Liu,Fan Bai,Qiang Nie,Max Meng*

Main category: cs.CV

TL;DR: OP-SAM利用SAM模型，通过自动生成单个标注图像的提示，实现了高效、准确的息肉分割，解决了传统方法的痛点。


<details>
  <summary>Details</summary>
Motivation: 传统全监督方法在形态变异和域偏移方面存在不足，且需要大量标注数据。SAM虽然泛化性强，但其依赖提示的特性限制了自动化应用。

Method: 提出OP-SAM（One-shot Polyp segmentation framework based on SAM），利用CPG（Correlation-based Prior Generation）进行语义标签迁移，SPF（Scale-cascaded Prior Fusion）适应息肉大小变化并过滤噪声，EPE（Euclidean Prompt Evolution）进行迭代提示优化。

Result: OP-SAM在Kvasir数据集上实现了76.93%的IoU，超越现有技术11.44%。

Conclusion: OP-SAM通过自动生成单个标注图像的提示，实现了无需额外标注即可进行准确且可泛化的息肉分割。通过CPG进行语义标签迁移，SPF适应息肉大小变化并过滤噪声，EPE进行迭代提示优化，逐步提高分割质量。

Abstract: Polyp segmentation is vital for early colorectal cancer detection, yet
traditional fully supervised methods struggle with morphological variability
and domain shifts, requiring frequent retraining. Additionally, reliance on
large-scale annotations is a major bottleneck due to the time-consuming and
error-prone nature of polyp boundary labeling. Recently, vision foundation
models like Segment Anything Model (SAM) have demonstrated strong
generalizability and fine-grained boundary detection with sparse prompts,
effectively addressing key polyp segmentation challenges. However, SAM's
prompt-dependent nature limits automation in medical applications, since
manually inputting prompts for each image is labor-intensive and
time-consuming. We propose OP-SAM, a One-shot Polyp segmentation framework
based on SAM that automatically generates prompts from a single annotated
image, ensuring accurate and generalizable segmentation without additional
annotation burdens. Our method introduces Correlation-based Prior Generation
(CPG) for semantic label transfer and Scale-cascaded Prior Fusion (SPF) to
adapt to polyp size variations as well as filter out noisy transfers. Instead
of dumping all prompts at once, we devise Euclidean Prompt Evolution (EPE) for
iterative prompt refinement, progressively enhancing segmentation quality.
Extensive evaluations across five datasets validate OP-SAM's effectiveness.
Notably, on Kvasir, it achieves 76.93% IoU, surpassing the state-of-the-art by
11.44%.

</details>


### [43] [Navigating Large-Pose Challenge for High-Fidelity Face Reenactment with Video Diffusion Model](https://arxiv.org/abs/2507.16341)
*Mingtao Guo,Guanyu Xing,Yanci Zhang,Yanli Liu*

Main category: cs.CV

TL;DR: FRVD 是一种新颖的框架，用于在高保真度下进行面部重新演绎，尤其是在大幅度姿态变化的情况下。


<details>
  <summary>Details</summary>
Motivation: 现有方法在处理大幅度姿态变化时，由于扭曲伪影或粗糙面部标志的限制，难以实现逼真的说话头像生成。

Method: FRVD 首先采用运动提取器从源图像和驱动图像中提取隐式面部关键点，以表示细粒度运动，并通过扭曲模块执行运动对齐。为了解决扭曲引入的退化，我们引入了一个扭曲特征映射器（WFM），将扭曲的源图像映射到预训练的图像到视频（I2V）模型的感知运动潜在空间。该潜在空间编码了从大规模视频数据中学到的丰富的面部动力学先验，从而实现了有效的扭曲校正并增强了时间连贯性。

Result: FRVD 在姿态准确性、身份保持和视觉质量方面表现优于现有方法，尤其是在具有极端姿态变化的挑战性场景中。

Conclusion: FRVD 在姿态准确性、身份保持和视觉质量方面表现优于现有方法，尤其是在具有极端姿态变化的挑战性场景中。

Abstract: Face reenactment aims to generate realistic talking head videos by
transferring motion from a driving video to a static source image while
preserving the source identity. Although existing methods based on either
implicit or explicit keypoints have shown promise, they struggle with large
pose variations due to warping artifacts or the limitations of coarse facial
landmarks. In this paper, we present the Face Reenactment Video Diffusion model
(FRVD), a novel framework for high-fidelity face reenactment under large pose
changes. Our method first employs a motion extractor to extract implicit facial
keypoints from the source and driving images to represent fine-grained motion
and to perform motion alignment through a warping module. To address the
degradation introduced by warping, we introduce a Warping Feature Mapper (WFM)
that maps the warped source image into the motion-aware latent space of a
pretrained image-to-video (I2V) model. This latent space encodes rich priors of
facial dynamics learned from large-scale video data, enabling effective warping
correction and enhancing temporal coherence. Extensive experiments show that
FRVD achieves superior performance over existing methods in terms of pose
accuracy, identity preservation, and visual quality, especially in challenging
scenarios with extreme pose variations.

</details>


### [44] [Mamba-OTR: a Mamba-based Solution for Online Take and Release Detection from Untrimmed Egocentric Video](https://arxiv.org/abs/2507.16342)
*Alessandro Sebastiano Catinello,Giovanni Maria Farinella,Antonino Furnari*

Main category: cs.CV

TL;DR: Mamba-OTR是一种高效、准确的在线抓取与释放检测模型，优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 旨在解决在线视频中物体的抓取与释放（OTR）检测问题，该任务由于标签严重不平衡、时间预测精度要求高以及需要计算效率等挑战而变得困难。

Method: 提出了一种基于Mamba架构的Mamba-OTR模型，该模型在推理时利用了时间递归，同时在短视频片段上进行训练。为了解决标签不平衡问题，训练流程结合了focal loss和一种新颖的正则化方案，使模型预测与评估指标保持一致。

Result: Mamba-OTR在EPIC-KITCHENS-100数据集上的实验结果表明，与基于Transformer的方法和Vanilla Mamba相比，Mamba-OTR在准确性和效率方面均表现出优越性，尤其是在处理完整长度视频或高帧率序列时。

Conclusion: Mamba-OTR在准确性和效率方面均优于基于Transformer的方法和Vanilla Mamba，在滑动窗口模式下达到45.48 mp-mAP，在流式模式下达到43.35 mp-mAP，为OTR任务提供了一个强大的基准。

Abstract: This work tackles the problem of Online detection of Take and Release (OTR)
of an object in untrimmed egocentric videos. This task is challenging due to
severe label imbalance, with temporally sparse positive annotations, and the
need for precise temporal predictions. Furthermore, methods need to be
computationally efficient in order to be deployed in real-world online
settings. To address these challenges, we propose Mamba-OTR, a model based on
the Mamba architecture. Mamba-OTR is designed to exploit temporal recurrence
during inference while being trained on short video clips. To address label
imbalance, our training pipeline incorporates the focal loss and a novel
regularization scheme that aligns model predictions with the evaluation metric.
Extensive experiments on EPIC-KITCHENS-100, the comparisons with
transformer-based approach, and the evaluation of different training and test
schemes demonstrate the superiority of Mamba-OTR in both accuracy and
efficiency. These finding are particularly evident when evaluating full-length
videos or high frame-rate sequences, even when trained on short video snippets
for computational convenience. The proposed Mamba-OTR achieves a noteworthy
mp-mAP of 45.48 when operating in a sliding-window fashion, and 43.35 in
streaming mode, versus the 20.32 of a vanilla transformer and 25.16 of a
vanilla Mamba, thus providing a strong baseline for OTR. We will publicly
release the source code of Mamba-OTR to support future research.

</details>


### [45] [LPTR-AFLNet: Lightweight Integrated Chinese License Plate Rectification and Recognition Network](https://arxiv.org/abs/2507.16362)
*Guangzhu Xu,Pengcheng Zuo,Zhi Ke,Bangjun Lei*

Main category: cs.CV

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Chinese License Plate Recognition (CLPR) faces numerous challenges in
unconstrained and complex environments, particularly due to perspective
distortions caused by various shooting angles and the correction of single-line
and double-line license plates. Considering the limited computational resources
of edge devices, developing a low-complexity, end-to-end integrated network for
both correction and recognition is essential for achieving real-time and
efficient deployment. In this work, we propose a lightweight, unified network
named LPTR-AFLNet for correcting and recognizing Chinese license plates, which
combines a perspective transformation correction module (PTR) with an optimized
license plate recognition network, AFLNet. The network leverages the
recognition output as a weak supervisory signal to effectively guide the
correction process, ensuring accurate perspective distortion correction. To
enhance recognition accuracy, we introduce several improvements to LPRNet,
including an improved attention module to reduce confusion among similar
characters and the use of Focal Loss to address class imbalance during
training. Experimental results demonstrate the exceptional performance of
LPTR-AFLNet in rectifying perspective distortion and recognizing double-line
license plate images, maintaining high recognition accuracy across various
challenging scenarios. Moreover, on lower-mid-range GPUs platform, the method
runs in less than 10 milliseconds, indicating its practical efficiency and
broad applicability.

</details>


### [46] [STAR: A Benchmark for Astronomical Star Fields Super-Resolution](https://arxiv.org/abs/2507.16385)
*Kuo-Cheng Wu,Guohang Zhuang,Jinyang Huang,Xiang Zhang,Wanli Ouyang,Yan Lu*

Main category: cs.CV

TL;DR: STAR是一个大型天文超分辨率数据集，包含54,738个通量一致的星场图像对，并引入了通量误差（FE）指标。提出的FISR模型在通量一致性方面优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有的天文超分辨率（ASR）数据集存在通量不一致、对象裁剪和数据多样性不足等问题，阻碍了ASR的发展。

Method: 提出了一种名为STAR的新型数据集，包含54,738个通量一致的星场图像对，并引入了一个新的通量误差（FE）指标来评估ASR模型。在此基础上，提出了一种通量不变超分辨率（FISR）模型，用于从输入测光数据中推断出通量一致的高分辨率图像。

Result: FISR模型在新的通量一致性指标上比现有的SR方法提高了24.84%，证明了该方法在天体物理学中的优势。

Conclusion: STAR STAR-FE基准能够促进ASR研究，并且FISR模型在通量一致性方面优于现有SR方法。

Abstract: Super-resolution (SR) advances astronomical imaging by enabling
cost-effective high-resolution capture, crucial for detecting faraway celestial
objects and precise structural analysis. However, existing datasets for
astronomical SR (ASR) exhibit three critical limitations: flux inconsistency,
object-crop setting, and insufficient data diversity, significantly impeding
ASR development. We propose STAR, a large-scale astronomical SR dataset
containing 54,738 flux-consistent star field image pairs covering wide
celestial regions. These pairs combine Hubble Space Telescope high-resolution
observations with physically faithful low-resolution counterparts generated
through a flux-preserving data generation pipeline, enabling systematic
development of field-level ASR models. To further empower the ASR community,
STAR provides a novel Flux Error (FE) to evaluate SR models in physical view.
Leveraging this benchmark, we propose a Flux-Invariant Super Resolution (FISR)
model that could accurately infer the flux-consistent high-resolution images
from input photometry, suppressing several SR state-of-the-art methods by
24.84% on a novel designed flux consistency metric, showing the priority of our
method for astrophysics. Extensive experiments demonstrate the effectiveness of
our proposed method and the value of our dataset. Code and models are available
at https://github.com/GuoCheng12/STAR.

</details>


### [47] [From Flat to Round: Redefining Brain Decoding with Surface-Based fMRI and Cortex Structure](https://arxiv.org/abs/2507.16389)
*Sijin Yu,Zijiao Chen,Wenxuan Wu,Shengxian Chen,Zhongliang Liu,Jingxin Nie,Xiaofen Xing,Xiangmin Xu,Xin Zhang*

Main category: cs.CV

TL;DR: 通过结合皮层表面建模、个性化解剖编码和正样本混合策略，本研究提出了一种新的fMRI信号重建方法，该方法在准确性、可解释性和泛化能力方面均优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有方法在重建视觉刺激时，往往忽略了关键的脑结构-功能关系，忽略了空间信息，并且未能考虑个体解剖学上的差异。

Method: 提出了一种新颖的球形分词器，将fMRI信号建模为皮层表面上的空间相干2D球形数据；整合了结构MRI数据以实现个性化的个体解剖变异编码；并采用了正样本混合策略以有效利用与同一视觉刺激相关的多个fMRI扫描。

Result: 该方法提高了重建准确性、生物可解释性和跨个体泛化能力。

Conclusion: 该方法在重建准确性、生物可解释性和跨个体泛化能力方面均有提升，实验证明了其优于现有SOTA方法的性能。

Abstract: Reconstructing visual stimuli from human brain activity (e.g., fMRI) bridges
neuroscience and computer vision by decoding neural representations. However,
existing methods often overlook critical brain structure-function
relationships, flattening spatial information and neglecting individual
anatomical variations. To address these issues, we propose (1) a novel sphere
tokenizer that explicitly models fMRI signals as spatially coherent 2D
spherical data on the cortical surface; (2) integration of structural MRI
(sMRI) data, enabling personalized encoding of individual anatomical
variations; and (3) a positive-sample mixup strategy for efficiently leveraging
multiple fMRI scans associated with the same visual stimulus. Collectively,
these innovations enhance reconstruction accuracy, biological interpretability,
and generalizability across individuals. Experiments demonstrate superior
reconstruction performance compared to SOTA methods, highlighting the
effectiveness and interpretability of our biologically informed approach.

</details>


### [48] [Are Foundation Models All You Need for Zero-shot Face Presentation Attack Detection?](https://arxiv.org/abs/2507.16393)
*Lazaro Janier Gonzalez-Sole,Juan E. Tapia,Christoph Busch*

Main category: cs.CV

TL;DR: 本研究提出了一种用于零样本人脸识别防论文攻击的框架，解决了现有方法的局限性。


<details>
  <summary>Details</summary>
Motivation: 为了解决当前深度学习方法在防御论文攻击方面的局限性，即需要大量数据并且泛化能力差。

Method: 提出了一种简单的框架，用于在零样本场景下进行防论文攻击。

Result: 实验结果表明，所提出的框架在零样本设置下表现出色，并且优于最先进的方法。

Conclusion: 与最先进的模型相比，该框架在更具挑战性的零样本设置中表现更好，并且在 SiW-Mv2 数据库上实现了最先进的性能。

Abstract: Although face recognition systems have undergone an impressive evolution in
the last decade, these technologies are vulnerable to attack presentations
(AP). These attacks are mostly easy to create and, by executing them against
the system's capture device, the malicious actor can impersonate an authorised
subject and thus gain access to the latter's information (e.g., financial
transactions). To protect facial recognition schemes against presentation
attacks, state-of-the-art deep learning presentation attack detection (PAD)
approaches require a large amount of data to produce reliable detection
performances and even then, they decrease their performance for unknown
presentation attack instruments (PAI) or database (information not seen during
training), i.e. they lack generalisability. To mitigate the above problems,
this paper focuses on zero-shot PAD. To do so, we first assess the
effectiveness and generalisability of foundation models in established and
challenging experimental scenarios and then propose a simple but effective
framework for zero-shot PAD. Experimental results show that these models are
able to achieve performance in difficult scenarios with minimal effort of the
more advanced PAD mechanisms, whose weights were optimised mainly with training
sets that included APs and bona fide presentations. The top-performing
foundation model outperforms by a margin the best from the state of the art
observed with the leaving-one-out protocol on the SiW-Mv2 database, which
contains challenging unknown 2D and 3D attacks

</details>


### [49] [ADCD-Net: Robust Document Image Forgery Localization via Adaptive DCT Feature and Hierarchical Content Disentanglement](https://arxiv.org/abs/2507.16397)
*Kahim Wong,Jicheng Zhou,Haiwei Wu,Yain-Whar Si,Jiantao Zhou*

Main category: cs.CV

TL;DR: ADCD-Net 是一种新颖的文档伪造检测方法，它通过自适应地结合 RGB/DCT 特征、缓解文本-背景差异以及利用未篡改区域的原始原型来提高准确性和鲁棒性，从而在各种失真下提供卓越的性能。


<details>
  <summary>Details</summary>
Motivation: 鉴于图像编辑工具的进步导致了对敏感文档图像的恶意操作，因此需要强大的文档图像伪造检测。现有方法在处理文档图像方面存在不足，因为篡纽改区域可能与统一的文档背景和结构化文本无缝融合，并且现有特定文档的方法在面对各种降级时不够鲁棒。

Method: ADCD-Net 模型通过自适应地利用 RGB/DCT 法证痕迹并整合文档图像的关键特征来解决文档伪造检测的挑战。该模型通过预测的对齐分数自适应地调节 DCT 特征的贡献，以应对块错位的敏感性。它还采用分层内容分离方法来减轻文本-背景差异，并通过捕获未篡改区域痕迹的原始原型来增强定位准确性和鲁棒性。

Result: ADCD-Net 在伪造定位方面表现出色，在 5 种失真类型的平均性能优于最先进的方法 20.79%。

Conclusion: ADCD-Net是一个强大的文档伪造定位模型，在各种失真（包括调整大小和裁剪）方面表现出卓越的韧性，平均比最先进的方法提高了 20.79%。

Abstract: The advancement of image editing tools has enabled malicious manipulation of
sensitive document images, underscoring the need for robust document image
forgery detection.Though forgery detectors for natural images have been
extensively studied, they struggle with document images, as the tampered
regions can be seamlessly blended into the uniform document background (BG) and
structured text. On the other hand, existing document-specific methods lack
sufficient robustness against various degradations, which limits their
practical deployment. This paper presents ADCD-Net, a robust document forgery
localization model that adaptively leverages the RGB/DCT forensic traces and
integrates key characteristics of document images. Specifically, to address the
DCT traces' sensitivity to block misalignment, we adaptively modulate the DCT
feature contribution based on a predicted alignment score, resulting in much
improved resilience to various distortions, including resizing and cropping.
Also, a hierarchical content disentanglement approach is proposed to boost the
localization performance via mitigating the text-BG disparities. Furthermore,
noticing the predominantly pristine nature of BG regions, we construct a
pristine prototype capturing traces of untampered regions, and eventually
enhance both the localization accuracy and robustness. Our proposed ADCD-Net
demonstrates superior forgery localization performance, consistently
outperforming state-of-the-art methods by 20.79\% averaged over 5 types of
distortions. The code is available at https://github.com/KAHIMWONG/ACDC-Net.

</details>


### [50] [ReasonVQA: A Multi-hop Reasoning Benchmark with Structural Knowledge for Visual Question Answering](https://arxiv.org/abs/2507.16403)
*Thuy-Duong Tran,Trung-Kien Tran,Manfred Hauswirth,Danh Le Phuoc*

Main category: cs.CV

TL;DR: 提出ReasonVQA数据集，它利用结构化知识生成复杂问题，并对现有VQA模型提出挑战，且规模远超现有数据集。


<details>
  <summary>Details</summary>
Motivation: 为了应对视觉问答（VQA）任务的挑战，并提供一个能够生成复杂、多步问题并易于扩展的数据集。

Method: 提出了一种名为ReasonVQA的新数据集，该数据集自动集成结构化百科知识，并使用低成本框架构建，能够生成复杂的多步问题。

Result: 在ReasonVQA上评估了最先进的VQA模型，结果表明该数据集对这些模型构成了重大挑战。

Conclusion: ReasonVQA数据集对现有的VQA模型提出了巨大挑战，有潜力用于基准测试和推动VQA领域的发展。此外，该数据集可轻松扩展，其当前版本在需要外部知识的数据集规模上超过了现有最大数据集一个数量级以上。

Abstract: In this paper, we propose a new dataset, ReasonVQA, for the Visual Question
Answering (VQA) task. Our dataset is automatically integrated with structured
encyclopedic knowledge and constructed using a low-cost framework, which is
capable of generating complex, multi-hop questions. We evaluated
state-of-the-art VQA models on ReasonVQA, and the empirical results demonstrate
that ReasonVQA poses significant challenges to these models, highlighting its
potential for benchmarking and advancing the field of VQA. Additionally, our
dataset can be easily scaled with respect to input images; the current version
surpasses the largest existing datasets requiring external knowledge by more
than an order of magnitude.

</details>


### [51] [Sparse-View 3D Reconstruction: Recent Advances and Open Challenges](https://arxiv.org/abs/2507.16406)
*Tanveer Younis,Zhanglin Cheng*

Main category: cs.CV

TL;DR: 本次调查回顾了神经隐式模型、显式点云方法和混合框架的最新进展，重点关注稀疏视图 3D 重建。它分析了几种方法如何处理伪影，并比较了精度、效率和泛化能力。该调查为几何、神经隐式和生成方法提供了一个统一的视角，并指出了未来的研究方向，以实现更强大的稀疏视图重建。


<details>
  <summary>Details</summary>
Motivation: 稀疏视图 3D 重建对于机器人、增强/虚拟现实 (AR/VR) 和自主系统等应用至关重要，在这些应用中，密集的图像采集是不切实际的。在这些环境中，最小的图像重叠会阻止可靠的对应匹配，从而导致结构运动 (SfM) 和多视图立体 (MVS) 等传统方法失败。

Method: 本次调查回顾了神经隐式模型（例如 NeRF 及其正则化版本）、显式点云方法（例如 3D 高斯泼水）和利用来自扩散和视觉基础模型（VFM）的先验的混合框架的最新进展。我们分析了如何使用几何正则化、显式形状建模和生成推理来减轻稀疏视图设置中的伪影，例如漂浮物和姿态模糊。

Result: 与之前的调查不同，本次调查提供了对几何、神经隐式和生成（基于扩散）方法的统一视角。我们强调了域泛化和无姿态重建中持续存在的挑战，并概述了开发 3D本机生成先验和实现实时、无约束稀疏视图重建的未来方向。

Conclusion: 本次调查提供了对几何、神经隐式和生成（基于扩散）方法的统一视角。我们强调了域泛化和无姿态重建中持续存在的挑战，并概述了开发 3D本机生成先验和实现实时、无约束稀疏视图重建的未来方向。

Abstract: Sparse-view 3D reconstruction is essential for applications in which dense
image acquisition is impractical, such as robotics, augmented/virtual reality
(AR/VR), and autonomous systems. In these settings, minimal image overlap
prevents reliable correspondence matching, causing traditional methods, such as
structure-from-motion (SfM) and multiview stereo (MVS), to fail. This survey
reviews the latest advances in neural implicit models (e.g., NeRF and its
regularized versions), explicit point-cloud-based approaches (e.g., 3D Gaussian
Splatting), and hybrid frameworks that leverage priors from diffusion and
vision foundation models (VFMs).We analyze how geometric regularization,
explicit shape modeling, and generative inference are used to mitigate
artifacts such as floaters and pose ambiguities in sparse-view settings.
Comparative results on standard benchmarks reveal key trade-offs between the
reconstruction accuracy, efficiency, and generalization. Unlike previous
reviews, our survey provides a unified perspective on geometry-based, neural
implicit, and generative (diffusion-based) methods. We highlight the persistent
challenges in domain generalization and pose-free reconstruction and outline
future directions for developing 3D-native generative priors and achieving
real-time, unconstrained sparse-view reconstruction.

</details>


### [52] [Combined Image Data Augmentations diminish the benefits of Adaptive Label Smoothing](https://arxiv.org/abs/2507.16427)
*Georg Siedel,Ekagra Gupta,Weijia Shao,Silvia Vock,Andrey Morozov*

Main category: cs.CV

TL;DR: 该研究将自适应标签平滑扩展到随机擦除和噪声注入等增强技术，但发现其在多样化增强或旨在提高对常见损坏鲁棒性的情况下效果不佳。


<details>
  <summary>Details</summary>
Motivation: 将自适应标签平滑从随机裁剪扩展到其他类型的侵略性增强。

Method: 将自适应标签平滑框架扩展到随机擦除和噪声注入等更广泛的增强类型。

Result: 自适应标签平滑允许通过更强的随机擦除进行更强的正则化，但在与 TrivialAugment 等多样化的图像变换结合使用时效果会消失，并且过度的标签平滑会损害对常见损坏的鲁棒性。

Conclusion: 自适应标签平滑应仅应用于训练数据分布主要由有限、同质的图像变换类型主导的情况。

Abstract: Soft augmentation regularizes the supervised learning process of image
classifiers by reducing label confidence of a training sample based on the
magnitude of random-crop augmentation applied to it. This paper extends this
adaptive label smoothing framework to other types of aggressive augmentations
beyond random-crop. Specifically, we demonstrate the effectiveness of the
method for random erasing and noise injection data augmentation. Adaptive label
smoothing permits stronger regularization via higher-intensity Random Erasing.
However, its benefits vanish when applied with a diverse range of image
transformations as in the state-of-the-art TrivialAugment method, and excessive
label smoothing harms robustness to common corruptions. Our findings suggest
that adaptive label smoothing should only be applied when the training data
distribution is dominated by a limited, homogeneous set of image transformation
types.

</details>


### [53] [Robust Noisy Pseudo-label Learning for Semi-supervised Medical Image Segmentation Using Diffusion Model](https://arxiv.org/abs/2507.16429)
*Lin Xi,Yingliang Ma,Cheng Wang,Sandra Howell,Aldo Rinaldi,Kawal S. Rhode*

Main category: cs.CV

TL;DR: 提出了一种新的基于扩散的半监督医学图像分割方法，通过使用类别原型来约束潜在空间，提高了在噪声伪标签下的分割鲁棒性，并在公开基准测试中取得了领先结果。


<details>
  <summary>Details</summary>
Motivation: 现有的半监督方法在利用有限的标注数据和大量的无标注数据进行医学图像分割时，常因伪标签引入的噪声而难以在潜在空间中构建语义分布。解决此问题，以提高分割精度。

Method: 提出了一种新颖的基于扩散的半监督医学图像分割框架，通过在去噪扩散过程中强制执行基于原型的对比一致性来约束潜在语义标签的结构。该模型不明确描绘语义边界，而是利用潜在空间中以类别原型为中心的语义表示作为锚点，以提高密集预测的鲁棒性，尤其是在存在噪声伪标签的情况下。

Result: 在EndoScapes2023和MOSXAV数据集上进行了广泛的实验，证明了所提出的方法在半监督学习设置下优于现有的最先进的医学图像分割方法。

Conclusion: 所提出的扩散模型在半监督学习设置下，在EndoScapes2023和MOSXAV数据集上，相比于现有的最先进的医学图像分割方法表现更优，该模型鲁棒且数据效率高，具有灵活性和临床应用潜力。

Abstract: Obtaining pixel-level annotations in the medical domain is both expensive and
time-consuming, often requiring close collaboration between clinical experts
and developers. Semi-supervised medical image segmentation aims to leverage
limited annotated data alongside abundant unlabeled data to achieve accurate
segmentation. However, existing semi-supervised methods often struggle to
structure semantic distributions in the latent space due to noise introduced by
pseudo-labels. In this paper, we propose a novel diffusion-based framework for
semi-supervised medical image segmentation. Our method introduces a constraint
into the latent structure of semantic labels during the denoising diffusion
process by enforcing prototype-based contrastive consistency. Rather than
explicitly delineating semantic boundaries, the model leverages class
prototypes centralized semantic representations in the latent space as anchors.
This strategy improves the robustness of dense predictions, particularly in the
presence of noisy pseudo-labels. We also introduce a new publicly available
benchmark: Multi-Object Segmentation in X-ray Angiography Videos (MOSXAV),
which provides detailed, manually annotated segmentation ground truth for
multiple anatomical structures in X-ray angiography videos. Extensive
experiments on the EndoScapes2023 and MOSXAV datasets demonstrate that our
method outperforms state-of-the-art medical image segmentation approaches under
the semi-supervised learning setting. This work presents a robust and
data-efficient diffusion model that offers enhanced flexibility and strong
potential for a wide range of clinical applications.

</details>


### [54] [VGGT-Long: Chunk it, Loop it, Align it -- Pushing VGGT's Limits on Kilometer-scale Long RGB Sequences](https://arxiv.org/abs/2507.16443)
*Kai Deng,Zexin Ti,Jiawei Xu,Jian Yang,Jin Xie*

Main category: cs.CV

TL;DR: VGGT-Long 是一种用于公里级单目 3D 重建的系统，它通过分块处理、重叠对齐和回路闭合优化解决了内存限制问题，在长序列上表现优于基础模型。


<details>
  <summary>Details</summary>
Motivation: 尽管 3D 视觉基础模型展现了卓越的 3D 感知能力，但由于内存限制，将其扩展到大规模 RGB 流 3D 重建仍然具有挑战性。

Method: VGGT-Long 通过基于块的处理策略、重叠对齐和轻量级回路闭合优化来解决现有模型的可扩展性瓶颈。该方法不需要相机校准、深度监督或模型重新训练。

Result: VGGT-Long 在 KITTI、Waymo 和 Virtual KITTI 数据集上进行了评估，在轨迹和重建方面的性能与传统方法相当。

Conclusion: VGGT-Long 成功运行在通常会导致基础模型失败的长 RGB 序列上，并且在各种条件下都能生成准确且一致的几何形状。我们的结果凸显了在真实世界场景中，尤其是在自动驾驶场景中，利用基础模型进行可扩展单目 3D 场景重建的潜力。

Abstract: Foundation models for 3D vision have recently demonstrated remarkable
capabilities in 3D perception. However, extending these models to large-scale
RGB stream 3D reconstruction remains challenging due to memory limitations. In
this work, we propose VGGT-Long, a simple yet effective system that pushes the
limits of monocular 3D reconstruction to kilometer-scale, unbounded outdoor
environments. Our approach addresses the scalability bottlenecks of existing
models through a chunk-based processing strategy combined with overlapping
alignment and lightweight loop closure optimization. Without requiring camera
calibration, depth supervision or model retraining, VGGT-Long achieves
trajectory and reconstruction performance comparable to traditional methods. We
evaluate our method on KITTI, Waymo, and Virtual KITTI datasets. VGGT-Long not
only runs successfully on long RGB sequences where foundation models typically
fail, but also produces accurate and consistent geometry across various
conditions. Our results highlight the potential of leveraging foundation models
for scalable monocular 3D scene in real-world settings, especially for
autonomous driving scenarios. Code is available at
https://github.com/DengKaiCQ/VGGT-Long.

</details>


### [55] [DenseSR: Image Shadow Removal as Dense Prediction](https://arxiv.org/abs/2507.16472)
*Yu-Fan Lin,Chia-Ming Lee,Chih-Chung Hsu*

Main category: cs.CV

TL;DR: DenseSR通过深度场景理解和密集融合块（DFB）解决了单图像阴影去除中的细节恢复和边界模糊问题，尤其在间接照明下效果更佳。


<details>
  <summary>Details</summary>
Motivation: 传统单图像阴影去除方法在处理具有非均匀内容退化和固有模糊性的间接照明条件时，往往难以同时恢复阴影内的细节并保持清晰的边界，导致恢复不一致和模糊，影响下游应用和视觉体验。

Method: 本研究提出了一种名为DenseSR的框架，该框架从密集预测的角度处理单图像阴影去除问题。其核心策略包括：1.利用几何-语义先验指导的深度场景理解来解析模糊性并隐式地定位阴影。2.在解码器中引入新颖的密集融合块（DFB）来实现高保真恢复。DFB包含自适应组件处理，利用自适应内容平滑模块（ACSM）确保外观一致性，并利用纹理-边界恢复模块（TBRM）来恢复精细纹理和锐利边界，从而解决不一致的恢复和模糊问题。

Result: 通过密集的实验证明，所提出的DenseSR方法在性能上优于现有方法，有效地解决了不一致的恢复和模糊问题，实现了更好的阴影去除效果。

Conclusion: 该研究提出的DenseSR框架通过结合场景理解和高保真恢复策略，有效地解决了单图像阴影去除中的挑战，尤其是在间接照明条件下。

Abstract: Shadows are a common factor degrading image quality. Single-image shadow
removal (SR), particularly under challenging indirect illumination, is hampered
by non-uniform content degradation and inherent ambiguity. Consequently,
traditional methods often fail to simultaneously recover intra-shadow details
and maintain sharp boundaries, resulting in inconsistent restoration and
blurring that negatively affect both downstream applications and the overall
viewing experience. To overcome these limitations, we propose the DenseSR,
approaching the problem from a dense prediction perspective to emphasize
restoration quality. This framework uniquely synergizes two key strategies: (1)
deep scene understanding guided by geometric-semantic priors to resolve
ambiguity and implicitly localize shadows, and (2) high-fidelity restoration
via a novel Dense Fusion Block (DFB) in the decoder. The DFB employs adaptive
component processing-using an Adaptive Content Smoothing Module (ACSM) for
consistent appearance and a Texture-Boundary Recuperation Module (TBRM) for
fine textures and sharp boundaries-thereby directly tackling the inconsistent
restoration and blurring issues. These purposefully processed components are
effectively fused, yielding an optimized feature representation preserving both
consistency and fidelity. Extensive experimental results demonstrate the merits
of our approach over existing methods. Our code can be available on
https://github$.$com/VanLinLin/DenseSR

</details>


### [56] [Survival Modeling from Whole Slide Images via Patch-Level Graph Clustering and Mixture Density Experts](https://arxiv.org/abs/2507.16476)
*Ardhendu Sekhar,Vasu Soni,Keshav Aske,Garima Jain,Pranav Jeevan,Amit Sethi*

Main category: cs.CV

TL;DR: 提出了一种用于预测癌症生存期的模块化框架，通过动态块选择、图引导聚类、注意力机制和混合密度模型，在肾癌和肺腺癌数据上取得了优于现有技术的准确性。


<details>
  <summary>Details</summary>
Motivation: 为了提高从全视野病理图像（WSIs）预测癌症特异性生存期的准确性。

Method: 本研究提出了一个模块化框架，包含四个关键组件：1. 使用基于分位数的阈值动态选择块以分离预后信息丰富的组织区域，以处理WSIs的大尺寸问题。2. 使用图引导的k-means聚类来捕捉表型水平的异质性。3. 使用注意力机制来整合局部特征与各种组织区室之间的全局空间关系。4. 使用专家指导的混合密度模型来估计复杂的生存分布。

Result: 在TCGA-KIRC（肾癌）数据集上，模型实现了0.712 ± 0.028的协同指数和0.254 ± 0.018的Brier分数。在TCGA-LUAD（肺腺癌）数据集上，模型实现了0.645 ± 0.017的协同指数和0.281 ± 0.031的Brier分数。

Conclusion: 该模型在TCGA-KIRC和TCGA-LUAD数据集上显著优于现有技术，证明了其在不同癌症类型中的预测潜力。

Abstract: We introduce a modular framework for predicting cancer-specific survival from
whole slide pathology images (WSIs) that significantly improves upon the
state-of-the-art accuracy. Our method integrating four key components. Firstly,
to tackle large size of WSIs, we use dynamic patch selection via quantile-based
thresholding for isolating prognostically informative tissue regions. Secondly,
we use graph-guided k-means clustering to capture phenotype-level heterogeneity
through spatial and morphological coherence. Thirdly, we use attention
mechanisms that model both intra- and inter-cluster relationships to
contextualize local features within global spatial relations between various
types of tissue compartments. Finally, we use an expert-guided mixture density
modeling for estimating complex survival distributions using Gaussian mixture
models. The proposed model achieves a concordance index of $0.712 \pm 0.028$
and Brier score of $0.254 \pm 0.018$ on TCGA-KIRC (renal cancer), and a
concordance index of $0.645 \pm 0.017$ and Brier score of $0.281 \pm 0.031$ on
TCGA-LUAD (lung adenocarcinoma). These results are significantly better than
the state-of-art and demonstrate predictive potential of the proposed method
across diverse cancer types.

</details>


### [57] [PlantSAM: An Object Detection-Driven Segmentation Pipeline for Herbarium Specimens](https://arxiv.org/abs/2507.16506)
*Youcef Sklab,Florian Castanet,Hanane Ariouat,Souhila Arib,Jean-Daniel Zucker,Eric Chenin,Edi Prifti*

Main category: cs.CV

TL;DR: PlantSAM通过结合YOLOv10和SAM2来改善草图图像的分割和分类。


<details>
  <summary>Details</summary>
Motivation: 草图图像的深度学习分类受到背景异质性的阻碍，这会引入噪声和伪影，可能误导模型并降低分类准确性。解决这些与背景相关的挑战对于提高模型性能至关重要。

Method: 提出了一种名为PlantSAM的自动化分割流程，该流程集成了YOLOv10进行植物区域检测和Segment Anything Model (SAM2)进行分割。YOLOv10生成边界框提示来指导SAM2，从而提高分割精度。

Result: PlantSAM实现了最先进的分割性能，IoU为0.94，Dice系数为0.97。将分割后的图像纳入分类模型，在五个经过测试的植物性状中，性能得到了一致的提高，准确性提高了4.36%，F1分数提高了4.15%。

Conclusion: 研究结果强调了在草图图像分析中去除背景的重要性，因为它能显著提高分类准确性，使模型能够更有效地专注于前景植物结构。

Abstract: Deep learning-based classification of herbarium images is hampered by
background heterogeneity, which introduces noise and artifacts that can
potentially mislead models and reduce classification accuracy. Addressing these
background-related challenges is critical to improving model performance. We
introduce PlantSAM, an automated segmentation pipeline that integrates YOLOv10
for plant region detection and the Segment Anything Model (SAM2) for
segmentation. YOLOv10 generates bounding box prompts to guide SAM2, enhancing
segmentation accuracy. Both models were fine-tuned on herbarium images and
evaluated using Intersection over Union (IoU) and Dice coefficient metrics.
PlantSAM achieved state-of-the-art segmentation performance, with an IoU of
0.94 and a Dice coefficient of 0.97. Incorporating segmented images into
classification models led to consistent performance improvements across five
tested botanical traits, with accuracy gains of up to 4.36% and F1-score
improvements of 4.15%. Our findings highlight the importance of background
removal in herbarium image analysis, as it significantly enhances
classification accuracy by allowing models to focus more effectively on the
foreground plant structures.

</details>


### [58] [C2-Evo: Co-Evolving Multimodal Data and Model for Self-Improving Reasoning](https://arxiv.org/abs/2507.16518)
*Xiuwei Chen,Wentao Hu,Hanhui Li,Jun Zhou,Zisheng Chen,Meng Cao,Yihan Zeng,Kui Zhang,Yu-Jie Yuan,Jianhua Han,Hang Xu,Xiaodan Liang*

Main category: cs.CV

TL;DR: C2-Evo是一个闭环自改进框架，能同时优化多模态模型及其训练数据，解决了现有方法在数据增强和任务难度匹配上的不足，并在数学推理任务上取得了更好的效果。


<details>
  <summary>Details</summary>
Motivation: 现有的大型多模态模型（MLLMs）在推理方面表现出色，但进一步提升需要高质量、精心设计任务复杂度的视觉-语言数据集，这类数据集的扩展成本高且具挑战性。现有的自改进模型虽然可行，但存在数据增强仅限于视觉或文本、数据与模型演进分离导致任务难度不匹配的问题。

Method: 提出了一种名为C2-Evo的自动、闭环自改进框架，通过跨模态数据演进循环和数据-模型演进循环来共同改进模型和数据。前者通过生成结合结构化文本子问题和迭代指定的几何图的复杂多模态问题来扩展数据集；后者则根据基础模型的性能自适应地选择生成的问题，进行监督微调和强化学习。

Result: C2-Evo框架能够生成复杂的、包含结构化文本子问题和迭代指定的几何图的多模态问题，并根据模型性能自适应选择数据进行训练，最终在多个数学推理基准测试中取得了显著的性能提升。

Conclusion: C2-Evo框架通过联合演进训练数据和模型能力，能够持续优化模型和训练数据，并在多个数学推理基准测试中获得显著的性能提升。

Abstract: Recent advances in multimodal large language models (MLLMs) have shown
impressive reasoning capabilities. However, further enhancing existing MLLMs
necessitates high-quality vision-language datasets with carefully curated task
complexities, which are both costly and challenging to scale. Although recent
self-improving models that iteratively refine themselves offer a feasible
solution, they still suffer from two core challenges: (i) most existing methods
augment visual or textual data separately, resulting in discrepancies in data
complexity (e.g., over-simplified diagrams paired with redundant textual
descriptions); and (ii) the evolution of data and models is also separated,
leading to scenarios where models are exposed to tasks with mismatched
difficulty levels. To address these issues, we propose C2-Evo, an automatic,
closed-loop self-improving framework that jointly evolves both training data
and model capabilities. Specifically, given a base dataset and a base model,
C2-Evo enhances them by a cross-modal data evolution loop and a data-model
evolution loop. The former loop expands the base dataset by generating complex
multimodal problems that combine structured textual sub-problems with
iteratively specified geometric diagrams, while the latter loop adaptively
selects the generated problems based on the performance of the base model, to
conduct supervised fine-tuning and reinforcement learning alternately.
Consequently, our method continuously refines its model and training data, and
consistently obtains considerable performance gains across multiple
mathematical reasoning benchmarks. Our code, models, and datasets will be
released.

</details>


### [59] [Spatial 3D-LLM: Exploring Spatial Awareness in 3D Vision-Language Models](https://arxiv.org/abs/2507.16524)
*Xiaoyan Wang,Zeju Li,Yifan Xu,Jiaxing Qi,Zhifei Yang,Ruifei Ma,Xiangde Liu,Chao Zhang*

Main category: cs.CV

TL;DR: Spatial 3D-LLM通过渐进式空间感知方案增强了3D场景表示，提高了在3D视觉语言任务中的空间感知能力，并在新的3D对象距离测量和3D布局编辑任务上取得了优异成果。


<details>
  <summary>Details</summary>
Motivation: 现有3D多模态LLM（MLLM）在处理3D视觉语言任务时，由于对3D场景的整体信息进行压缩或分割独立对象，导致空间感知能力受限，无法充分表征3D场景的丰富性。

Method: Spatial 3D-LLM将LLM主干与渐进式空间感知方案相结合，该方案随着感知场的扩展而逐步捕获空间信息，从而生成富含位置信息的3D场景嵌入作为视觉提示。

Result: Spatial 3D-LLM在多种3D视觉语言任务中取得了最先进的性能，验证了其渐进式空间感知方案在挖掘更深层空间信息方面的有效性。

Conclusion: Spatial 3D-LLM在多种3D视觉语言任务中取得了最先进的性能，这表明我们的渐进式空间感知方案在挖掘更深层空间信息方面取得了改进。

Abstract: New era has unlocked exciting possibilities for extending Large Language
Models (LLMs) to tackle 3D vision-language tasks. However, most existing 3D
multimodal LLMs (MLLMs) rely on compressing holistic 3D scene information or
segmenting independent objects to perform these tasks, which limits their
spatial awareness due to insufficient representation of the richness inherent
in 3D scenes. To overcome these limitations, we propose Spatial 3D-LLM, a 3D
MLLM specifically designed to enhance spatial awareness for 3D vision-language
tasks by enriching the spatial embeddings of 3D scenes. Spatial 3D-LLM
integrates an LLM backbone with a progressive spatial awareness scheme that
progressively captures spatial information as the perception field expands,
generating location-enriched 3D scene embeddings to serve as visual prompts.
Furthermore, we introduce two novel tasks: 3D object distance measurement and
3D layout editing, and construct a 3D instruction dataset, MODEL, to evaluate
the model's spatial awareness capabilities. Experimental results demonstrate
that Spatial 3D-LLM achieves state-of-the-art performance across a wide range
of 3D vision-language tasks, revealing the improvements stemmed from our
progressive spatial awareness scheme of mining more profound spatial
information. Our code is available at
https://github.com/bjshuyuan/Spatial-3D-LLM.

</details>


### [60] [EarthCrafter: Scalable 3D Earth Generation via Dual-Sparse Latent Diffusion](https://arxiv.org/abs/2507.16535)
*Shang Liu,Chenjie Cao,Chaohui Yu,Wen Qian,Jing Wang,Fan Wang*

Main category: cs.CV

TL;DR: EarthCrafter利用Aerial-Earth3D数据集和新颖的框架，实现了大规模3D地球生成，解决了计算成本高和地理范围扩展的挑战。


<details>
  <summary>Details</summary>
Motivation: 解决现有3D生成方法在扩展到地理范围（如模拟数千平方公里的地球表面）方面存在的挑战。

Method: 提出了一种名为EarthCrafter的框架，采用稀疏解耦的潜在扩散模型，将高分辨率的几何体素和纹理2D高斯散点图压缩到紧凑的潜在空间中，并使用条件感知流匹配模型独立地对潜在几何和纹理特征进行建模。

Result: 通过在Aerial-Earth3D数据集上的实验证明，EarthCrafter在极大规模生成方面表现优于现有方法，并且支持从语义引导的城市布局生成到无条件的মিশ্র合成等多种应用。

Conclusion: EarthCrafter在生成大规模3D地球模型方面表现出色，并支持多种应用，同时保持地理上的合理性。

Abstract: Despite the remarkable developments achieved by recent 3D generation works,
scaling these methods to geographic extents, such as modeling thousands of
square kilometers of Earth's surface, remains an open challenge. We address
this through a dual innovation in data infrastructure and model architecture.
First, we introduce Aerial-Earth3D, the largest 3D aerial dataset to date,
consisting of 50k curated scenes (each measuring 600m x 600m) captured across
the U.S. mainland, comprising 45M multi-view Google Earth frames. Each scene
provides pose-annotated multi-view images, depth maps, normals, semantic
segmentation, and camera poses, with explicit quality control to ensure terrain
diversity. Building on this foundation, we propose EarthCrafter, a tailored
framework for large-scale 3D Earth generation via sparse-decoupled latent
diffusion. Our architecture separates structural and textural generation: 1)
Dual sparse 3D-VAEs compress high-resolution geometric voxels and textural 2D
Gaussian Splats (2DGS) into compact latent spaces, largely alleviating the
costly computation suffering from vast geographic scales while preserving
critical information. 2) We propose condition-aware flow matching models
trained on mixed inputs (semantics, images, or neither) to flexibly model
latent geometry and texture features independently. Extensive experiments
demonstrate that EarthCrafter performs substantially better in extremely
large-scale generation. The framework further supports versatile applications,
from semantic-guided urban layout generation to unconditional terrain
synthesis, while maintaining geographic plausibility through our rich data
priors from Aerial-Earth3D.

</details>


### [61] [Comparative validation of surgical phase recognition, instrument keypoint estimation, and instrument instance segmentation in endoscopy: Results of the PhaKIR 2024 challenge](https://arxiv.org/abs/2507.16559)
*Tobias Rueckert,David Rauber,Raphaela Maerkl,Leonard Klausmann,Suemeyye R. Yildiran,Max Gutbrod,Danilo Weber Nunes,Alvaro Fernandez Moreno,Imanol Luengo,Danail Stoyanov,Nicolas Toussaint,Enki Cho,Hyeon Bae Kim,Oh Sung Choo,Ka Young Kim,Seong Tae Kim,Gonçalo Arantes,Kehan Song,Jianjun Zhu,Junchen Xiong,Tingyi Lin,Shunsuke Kikuchi,Hiroki Matsuzaki,Atsushi Kouno,João Renato Ribeiro Manesco,João Paulo Papa,Tae-Min Choi,Tae Kyeong Jeong,Juyoun Park,Oluwatosin Alabi,Meng Wei,Tom Vercauteren,Runzhi Wu,Mengya Xu,An Wang,Long Bai,Hongliang Ren,Amine Yamlahi,Jakob Hennighausen,Lena Maier-Hein,Satoshi Kondo,Satoshi Kasai,Kousuke Hirasawa,Shu Yang,Yihui Wang,Hao Chen,Santiago Rodríguez,Nicolás Aparicio,Leonardo Manrique,Juan Camilo Lyons,Olivia Hosie,Nicolás Ayobi,Pablo Arbeláez,Yiping Li,Yasmina Al Khalil,Sahar Nasirihaghighi,Stefanie Speidel,Daniel Rueckert,Hubertus Feussner,Dirk Wilhelm,Christoph Palm*

Main category: cs.CV

TL;DR: 该研究组织了PhaKIR子挑战赛，并发布了一个包含13个腹腔镜胆囊切除视频的多中心数据集，该数据集支持对器械定位和手术背景的联合调查，以及跨整个手术过程的时间信息集成。该挑战赛旨在推动机器人辅助微创手术（RAMIS）领域的发展，并为未来的研究提供高质量的资源。


<details>
  <summary>Details</summary>
Motivation: 在机器人辅助微创手术（RAMIS）中，可靠地识别和定位手术器械对于计算机和机器人辅助手术等多种应用至关重要，然而，在真实世界的条件下实现稳健的性能仍然是一个重大挑战。纳入手术背景（如当前的手术阶段）已被证明是提高稳健性和可解释性的有前景的策略。

Method: 组织了2024年MICCAI上的EndoVis挑战赛的PhaKIR子挑战赛，并引入了一个包含13个完整腹腔镜胆囊切除视频的多中心数据集，该数据集对三个相关任务进行了统一标注：手术阶段识别、器械关键点估计和器械实例分割。

Result: 报告了根据生物医学图像分析挑战的BIAS指南得出的结果和发现。

Conclusion: 该PhaKIR子挑战赛通过提供一个独特的时间感知、上下文驱动的机器人辅助微创手术（RAMIS）方法的基准，并提供高质量的资源来支持手术场景理解的未来研究，从而推动了该领域的发展。

Abstract: Reliable recognition and localization of surgical instruments in endoscopic
video recordings are foundational for a wide range of applications in computer-
and robot-assisted minimally invasive surgery (RAMIS), including surgical
training, skill assessment, and autonomous assistance. However, robust
performance under real-world conditions remains a significant challenge.
Incorporating surgical context - such as the current procedural phase - has
emerged as a promising strategy to improve robustness and interpretability.
  To address these challenges, we organized the Surgical Procedure Phase,
Keypoint, and Instrument Recognition (PhaKIR) sub-challenge as part of the
Endoscopic Vision (EndoVis) challenge at MICCAI 2024. We introduced a novel,
multi-center dataset comprising thirteen full-length laparoscopic
cholecystectomy videos collected from three distinct medical institutions, with
unified annotations for three interrelated tasks: surgical phase recognition,
instrument keypoint estimation, and instrument instance segmentation. Unlike
existing datasets, ours enables joint investigation of instrument localization
and procedural context within the same data while supporting the integration of
temporal information across entire procedures.
  We report results and findings in accordance with the BIAS guidelines for
biomedical image analysis challenges. The PhaKIR sub-challenge advances the
field by providing a unique benchmark for developing temporally aware,
context-driven methods in RAMIS and offers a high-quality resource to support
future research in surgical scene understanding.

</details>


### [62] [A Multimodal Deviation Perceiving Framework for Weakly-Supervised Temporal Forgery Localization](https://arxiv.org/abs/2507.16596)
*Wenbo Xu,Junyan Wu,Wei Lu,Xiangyang Luo,Qian Wang*

Main category: cs.CV

TL;DR: 提出了一种名为MDP的多模态偏差感知框架，用于在只有视频级别注释的情况下定位视频中的伪造片段。该框架通过多模态交互和偏差感知损失，实现了比现有方法更精确、更高效的伪造检测。


<details>
  <summary>Details</summary>
Motivation: 当前深度伪造取证研究通常将检测视为分类任务或时间伪造定位问题，这些方法具有局限性、耗时且难以扩展到大型数据集。为了解决这些问题，提出了一种用于弱监督时间伪造定位的多模态偏差感知框架（MDP）。

Method: 提出了一种多模态交互机制（MI）和一个可扩展的偏差感知损失，以感知多模态偏差，从而实现伪造片段的精细起止时间戳定位。MI通过在概率嵌入空间中度量视觉和音频模态之间的相关性来引入时间属性保持交叉模态注意力，以识别跨模态偏差并构建用于时间伪造定位的综合视频特征。可扩展的偏差感知损失旨在扩大伪造样本相邻片段的偏差并减小真实样本的偏差。

Result: 实验证明了所提出框架的有效性，并在多个评估指标上取得了与全监督方法相媲美 results。

Conclusion: 该研究提出的MDP框架在弱监督下实现了对伪造视频片段的精细时间戳定位，并在多个评估指标上取得了与全监督方法相媲美的结果。

Abstract: Current researches on Deepfake forensics often treat detection as a
classification task or temporal forgery localization problem, which are usually
restrictive, time-consuming, and challenging to scale for large datasets. To
resolve these issues, we present a multimodal deviation perceiving framework
for weakly-supervised temporal forgery localization (MDP), which aims to
identify temporal partial forged segments using only video-level annotations.
The MDP proposes a novel multimodal interaction mechanism (MI) and an
extensible deviation perceiving loss to perceive multimodal deviation, which
achieves the refined start and end timestamps localization of forged segments.
Specifically, MI introduces a temporal property preserving cross-modal
attention to measure the relevance between the visual and audio modalities in
the probabilistic embedding space. It could identify the inter-modality
deviation and construct comprehensive video features for temporal forgery
localization. To explore further temporal deviation for weakly-supervised
learning, an extensible deviation perceiving loss has been proposed, aiming at
enlarging the deviation of adjacent segments of the forged samples and reducing
that of genuine samples. Extensive experiments demonstrate the effectiveness of
the proposed framework and achieve comparable results to fully-supervised
approaches in several evaluation metrics.

</details>


### [63] [Dyna3DGR: 4D Cardiac Motion Tracking with Dynamic 3D Gaussian Representation](https://arxiv.org/abs/2507.16608)
*Xueming Fu,Pei Wu,Yingtai Li,Xin Luo,Zihang Jiang,Junhao Mei,Jian Lu,Gao-Jun Teng,S. Kevin Zhou*

Main category: cs.CV

TL;DR: 提出了一种名为动态3D高斯表示（Dyna3DGR）的新框架，该框架结合了显式的3D高斯表示和隐式的神经运动场建模，以解决动态心脏MRI中细粒度的4D心脏运动跟踪挑战。该方法以自我监督的方式同时优化心脏结构和运动，无需大量的训练数据或点对点对应，并通过可微分的体积渲染有效解决了现有方法的局限性。


<details>
  <summary>Details</summary>
Motivation: 为了解决现有方法在心脏运动跟踪方面的局限性，例如基于图像的方法在拓扑一致性方面存在问题或依赖大量训练数据，以及基于表示的方法存在图像细节丢失的问题，提出了一种新的框架。

Method: 提出了一种名为动态3D高斯表示（Dyna3DGR）的新框架，该框架结合了显式的3D高斯表示和隐式的神经运动场建模。该方法以自我监督的方式同时优化心脏结构和运动，无需大量的训练数据或点对点对应。通过可微分的体积渲染，Dyna3DGR有效地将连续运动表示与图像空间对齐联系起来，同时保持拓扑和时间一致性。

Result: Dyna3DGR在跟踪精度上超越了最先进的基于深度学习的微分同胚配准方法。

Conclusion: 该方法在ACDC数据集上的综合评估表明，其在跟踪精度上优于最先进的基于深度学习的微分同胚配准方法。

Abstract: Accurate analysis of cardiac motion is crucial for evaluating cardiac
function. While dynamic cardiac magnetic resonance imaging (CMR) can capture
detailed tissue motion throughout the cardiac cycle, the fine-grained 4D
cardiac motion tracking remains challenging due to the homogeneous nature of
myocardial tissue and the lack of distinctive features. Existing approaches can
be broadly categorized into image based and representation-based, each with its
limitations. Image-based methods, including both raditional and deep
learning-based registration approaches, either struggle with topological
consistency or rely heavily on extensive training data. Representation-based
methods, while promising, often suffer from loss of image-level details. To
address these limitations, we propose Dynamic 3D Gaussian Representation
(Dyna3DGR), a novel framework that combines explicit 3D Gaussian representation
with implicit neural motion field modeling. Our method simultaneously optimizes
cardiac structure and motion in a self-supervised manner, eliminating the need
for extensive training data or point-to-point correspondences. Through
differentiable volumetric rendering, Dyna3DGR efficiently bridges continuous
motion representation with image-space alignment while preserving both
topological and temporal consistency. Comprehensive evaluations on the ACDC
dataset demonstrate that our approach surpasses state-of-the-art deep
learning-based diffeomorphic registration methods in tracking accuracy. The
code will be available in https://github.com/windrise/Dyna3DGR.

</details>


### [64] [CTSL: Codebook-based Temporal-Spatial Learning for Accurate Non-Contrast Cardiac Risk Prediction Using Cine MRIs](https://arxiv.org/abs/2507.16612)
*Haoyang Su,Shaohao Rui,Jinyi Xiang,Lianming Wu,Xiaosong Wang*

Main category: cs.CV

TL;DR: CTSL 是一种无需分割掩模即可从原始 Cine 数据中学习动态时空表示的自监督框架。CTSL 通过多视图蒸馏策略将时态和空间特征解耦，从而实现高置信度的 MACE 风险预测，提供了一种快速、非侵入性的心脏风险评估解决方案。


<details>
  <summary>Details</summary>
Motivation: 准确且无对比度 Major Adverse Cardiac Events (MACE) 从 Cine MRI 序列进行预测仍然是一个关键挑战。现有方法通常需要基于人工精炼的左心室心肌掩模的监督学习，而这在没有对比剂的情况下是不切实际的。

Method: CTSL 框架通过多视图蒸馏策略将时态和空间特征解耦，其中教师模型处理多个 Cine 视图，学生模型从降维的 Cine-SA 序列中学习。

Result: CTSL 框架能够从原始 Cine 数据中学习动态的时空表示，而无需分割掩模。

Conclusion: 通过利用基于码本的特征表示和动态病变自我检测（通过运动线索），CTSL 能够捕捉复杂的时态依赖性和运动模式。我们的模型实现了高置信度的 MACE 风险预测，为心脏风险评估提供了一种快速、非侵入性的解决方案，其性能优于传统的依赖对比度的方法，从而在临床环境中实现及时、易于获得的心脏病诊断。

Abstract: Accurate and contrast-free Major Adverse Cardiac Events (MACE) prediction
from Cine MRI sequences remains a critical challenge. Existing methods
typically necessitate supervised learning based on human-refined masks in the
ventricular myocardium, which become impractical without contrast agents. We
introduce a self-supervised framework, namely Codebook-based Temporal-Spatial
Learning (CTSL), that learns dynamic, spatiotemporal representations from raw
Cine data without requiring segmentation masks. CTSL decouples temporal and
spatial features through a multi-view distillation strategy, where the teacher
model processes multiple Cine views, and the student model learns from
reduced-dimensional Cine-SA sequences. By leveraging codebook-based feature
representations and dynamic lesion self-detection through motion cues, CTSL
captures intricate temporal dependencies and motion patterns. High-confidence
MACE risk predictions are achieved through our model, providing a rapid,
non-invasive solution for cardiac risk assessment that outperforms traditional
contrast-dependent methods, thereby enabling timely and accessible heart
disease diagnosis in clinical settings.

</details>


### [65] [Automatic Fine-grained Segmentation-assisted Report Generation](https://arxiv.org/abs/2507.16623)
*Frederic Jonske,Constantin Seibold,Osman Alperen Koras,Fin Bahnsen,Marie Bauer,Amin Dada,Hamza Kalisch,Anton Schily,Jens Kleesiek*

Main category: cs.CV

TL;DR: ASaRG是一种基于LLaVA的医学报告生成方法，通过融合分割图和中间特征，显著提高了报告的准确性和可信度，并实现了报告内容的事实依据溯源。


<details>
  <summary>Details</summary>
Motivation: 为了减轻放射科医生的工作负担，并为临床医生或患者提供第二意见，需要一个在医学机器学习领域中能够可靠生成临床报告的模型，该模型需要具备强大的通用性能和固有的事实依据能力，以使生成的报告可信。

Method: ASaRG通过将专家放射学模型产生的中间特征和细粒度分割图，通过简单的拼接方式融合到LLaVA的多模态投影层中，并仅增加了少量参数。

Result: 与LLaVA基线相比，ASaRG在仅使用中间特征时，CE F1分数提升了+0.89%（p=0.012）；在使用中间特征和细粒度分割图的组合时，CE F1分数提升了+2.77%（p<0.001）。与使用分割的其他报告生成方法COMG和ORID相比，F1分数分别提高了6.98%和6.28%。此外，ASaRG允许将报告的元素追溯到相应的分割图，验证评估的依据。

Conclusion: ASaRG通过融合专家放射学模型产生的中间特征和细粒度分割图，在LLaVA多模态投影层中实现了性能的提升，并提供了可追溯的报告生成能力，有望减轻放射科医生的工作负担并提供可靠的第二意见。

Abstract: Reliable end-to-end clinical report generation has been a longstanding goal
of medical ML research. The end goal for this process is to alleviate
radiologists' workloads and provide second opinions to clinicians or patients.
Thus, a necessary prerequisite for report generation models is a strong general
performance and some type of innate grounding capability, to convince
clinicians or patients of the veracity of the generated reports. In this paper,
we present ASaRG (\textbf{A}utomatic \textbf{S}egmentation-\textbf{a}ssisted
\textbf{R}eport \textbf{G}eneration), an extension of the popular LLaVA
architecture that aims to tackle both of these problems. ASaRG proposes to fuse
intermediate features and fine-grained segmentation maps created by specialist
radiological models into LLaVA's multi-modal projection layer via simple
concatenation. With a small number of added parameters, our approach achieves a
+0.89\% performance gain ($p=0.012$) in CE F1 score compared to the LLaVA
baseline when using only intermediate features, and +2.77\% performance gain
($p<0.001$) when adding a combination of intermediate features and fine-grained
segmentation maps. Compared with COMG and ORID, two other report generation
methods that utilize segmentations, the performance gain amounts to 6.98\% and
6.28\% in F1 score, respectively. ASaRG is not mutually exclusive with other
changes made to the LLaVA architecture, potentially allowing our method to be
combined with other advances in the field. Finally, the use of an arbitrary
number of segmentations as part of the input demonstrably allows tracing
elements of the report to the corresponding segmentation maps and verifying the
groundedness of assessments. Our code will be made publicly available at a
later date.

</details>


### [66] [A2Mamba: Attention-augmented State Space Models for Visual Recognition](https://arxiv.org/abs/2507.16624)
*Meng Lou,Yunxiang Fu,Yizhou Yu*

Main category: cs.CV

TL;DR: A2Mamba是一种新颖的Transformer-Mamba混合网络，通过名为MASS的token mixer实现了层间深度交互，在视觉识别任务上取得了优于现有模型的性能，并在多个基准测试中创下了新的记录。


<details>
  <summary>Details</summary>
Motivation: Transformer和Mamba模型在视觉识别领域表现出色，但现有将它们结合的方法仅限于简单的堆叠，缺乏层间的交互机制。因此，Transformer和Mamba层之间的深度集成仍然是一个待解决的问题。

Method: 提出了一种名为A2Mamba的混合网络架构，其核心是新颖的token mixer，称为多尺度注意力增强状态空间模型（MASS）。MASS通过将多尺度注意力图集成到注意力增强SSM（A2SSM）中，实现了Transformer和Mamba层之间的深度交互。A2SSM的关键步骤是通过多尺度注意力图在空间上聚合SSM的隐藏状态，以此增强二维空间相关的空间依赖性，并提高SSM的动态建模能力。

Result: A2Mamba在视觉识别任务上超越了所有之前的ConvNet、Transformer和Mamba模型。例如，A2Mamba-L在ImageNet-1K上取得了86.1%的top-1准确率。在语义分割任务中，A2Mamba-B比CAFormer-S36在mIoU上高2.5%，同时效率更高。在对象检测和实例分割任务中，使用Cascade Mask R-CNN时，A2Mamba-S比MambaVision-B在AP^b/AP^m上分别高1.2%/0.9%，且参数量减少了40%。

Conclusion: A2Mamba在视觉识别任务上超越了所有之前的卷积网络、Transformer和Mamba模型，并在ImageNet-1K上达到了86.1%的准确率。在语义分割方面，A2Mamba-B比CAFormer-S36的mIoU高2.5%，同时效率更高。在对象检测和实例分割方面，A2Mamba-S比MambaVision-B的AP^b/AP^m高1.2%/0.9%，且参数量减少了40%。

Abstract: Transformers and Mamba, initially invented for natural language processing,
have inspired backbone architectures for visual recognition. Recent studies
integrated Local Attention Transformers with Mamba to capture both local
details and global contexts. Despite competitive performance, these methods are
limited to simple stacking of Transformer and Mamba layers without any
interaction mechanism between them. Thus, deep integration between Transformer
and Mamba layers remains an open problem. We address this problem by proposing
A2Mamba, a powerful Transformer-Mamba hybrid network architecture, featuring a
new token mixer termed Multi-scale Attention-augmented State Space Model
(MASS), where multi-scale attention maps are integrated into an
attention-augmented SSM (A2SSM). A key step of A2SSM performs a variant of
cross-attention by spatially aggregating the SSM's hidden states using the
multi-scale attention maps, which enhances spatial dependencies pertaining to a
two-dimensional space while improving the dynamic modeling capabilities of
SSMs. Our A2Mamba outperforms all previous ConvNet-, Transformer-, and
Mamba-based architectures in visual recognition tasks. For instance, A2Mamba-L
achieves an impressive 86.1% top-1 accuracy on ImageNet-1K. In semantic
segmentation, A2Mamba-B exceeds CAFormer-S36 by 2.5% in mIoU, while exhibiting
higher efficiency. In object detection and instance segmentation with Cascade
Mask R-CNN, A2Mamba-S surpasses MambaVision-B by 1.2%/0.9% in AP^b/AP^m, while
having 40% less parameters. Code is publicly available at
https://github.com/LMMMEng/A2Mamba.

</details>


### [67] [Zebra-CoT: A Dataset for Interleaved Vision Language Reasoning](https://arxiv.org/abs/2507.16746)
*Ang Li,Charles Wang,Kaiyu Yue,Zikui Cai,Ollie Liu,Deqing Fu,Peng Guo,Wang Bill Zhu,Vatsal Sharan,Robin Jia,Willie Neiswanger,Furong Huang,Tom Goldstein,Micah Goldblum*

Main category: cs.CV

TL;DR: Zebra-CoT是一个包含182,384个图文推理样本的大型数据集，旨在提升多模态模型的视觉推理能力。使用Zebra-CoT微调模型可显著提高准确率和性能。


<details>
  <summary>Details</summary>
Motivation: 为了解决视觉语言模型（VLM）在解决复杂问题时缺乏视觉推理能力的问题，并应对现有视觉思维链（Visual CoT）方法在性能和数据上的挑战。

Method: 通过构建包含182,384个样本的大规模、多样化数据集Zebra-CoT，其中包含逻辑连贯的图文交织推理轨迹，并利用该数据集对Anole-7B和Bagel-7B模型进行微调。

Result: +12%的测试集准确率提升和标准VLM基准评估高达+13%的性能增益，以及Bagel-7B模型生成高质量视觉推理链的能力。

Conclusion: Zebra-CoT数据集和微调模型在多模态推理能力方面取得了显著成效，并已开源以促进相关研究。

Abstract: Humans often use visual aids, for example diagrams or sketches, when solving
complex problems. Training multimodal models to do the same, known as Visual
Chain of Thought (Visual CoT), is challenging due to: (1) poor off-the-shelf
visual CoT performance, which hinders reinforcement learning, and (2) the lack
of high-quality visual CoT training data. We introduce $\textbf{Zebra-CoT}$, a
diverse large-scale dataset with 182,384 samples, containing logically coherent
interleaved text-image reasoning traces. We focus on four categories of tasks
where sketching or visual reasoning is especially natural, spanning scientific
questions such as geometry, physics, and algorithms; 2D visual reasoning tasks
like visual search and jigsaw puzzles; 3D reasoning tasks including 3D
multi-hop inference, embodied and robot planning; visual logic problems and
strategic games like chess. Fine-tuning the Anole-7B model on the Zebra-CoT
training corpus results in an improvement of +12% in our test-set accuracy and
yields up to +13% performance gain on standard VLM benchmark evaluations.
Fine-tuning Bagel-7B yields a model that generates high-quality interleaved
visual reasoning chains, underscoring Zebra-CoT's effectiveness for developing
multimodal reasoning abilities. We open-source our dataset and models to
support development and evaluation of visual CoT.

</details>


### [68] [Benchmarking pig detection and tracking under diverse and challenging conditions](https://arxiv.org/abs/2507.16639)
*Jonathan Henrich,Christian Post,Maximilian Zilke,Parth Shiroya,Emma Chanut,Amir Mollazadeh Yamchi,Ramin Yahyapour,Thomas Kneib,Imke Traulsen*

Main category: cs.CV

TL;DR: 本研究创建了用于猪目标检测（PigDetect）和多目标跟踪（PigTrack）的数据集，并进行了基准测试。结果显示，具有挑战性的训练数据和最先进的模型能提升检测性能，而SORT方法在检测上优于端到端模型，端到端模型在关联上更优。模型泛化能力良好，高质量数据至关重要。数据集和代码已公开。


<details>
  <summary>Details</summary>
Motivation: 为了确保养猪业的动物福利和有效的管理，对个体行为进行监测是必不可少的前提。尽管传统上这些监测任务是手动进行的，但机器学习的进步使得以日益自动化的方式收集个体信息成为可能。然而，尽管在猪农场领域对目标检测（空间定位）和多目标跟踪（时空定位）这两个关键任务进行了广泛研究，但尚未进行系统的基准测试研究。本研究旨在填补这一空白。

Method: 本研究通过创建两个数据集（PigDetect用于目标检测，PigTrack用于多目标跟踪）来解决猪农场行为监测中的基准测试空白。研究人员利用了来自真实猪舍条件的多样化图像和视频材料，并包含了遮挡或可见性差等挑战性场景。对目标检测任务，研究人员比较了不同方法的性能，并强调了具有挑战性的训练图像的重要性。对于多目标跟踪任务，研究人员比较了基于SORT的方法和端到端可训练模型，并分析了它们各自的优缺点以及未来改进的方向。

Result: 在目标检测方面，研究表明具有挑战性的训练图像可以提高检测性能，优于仅使用随机抽样图像。与实时替代方案相比，最先进的模型在检测质量上提供了显著的改进。在多目标跟踪方面，基于SORT的方法在检测性能上优于端到端可训练模型，但后者在关联性能上表现更佳，显示出未来成为强大替代方案的潜力。研究还分析了端到端模型的典型失败案例，并为未来的改进提供了指导。在未见过的猪圈中，在所创建的数据集上训练的检测和跟踪模型表现良好，显示出良好的泛化能力，这凸显了高质量训练数据的重要性。

Conclusion: 该研究通过创建名为PigDetect和PigTrack的数据集，填补了猪农场行为监测中目标检测和多目标跟踪的基准测试空白。研究表明，使用具有挑战性的训练图像可以提高检测性能，并且最先进的模型在检测质量上优于实时替代方案。虽然基于SORT的方法在检测性能上优于端到端可训练模型，但后者在关联性能上表现更好，并有潜力成为未来的有力竞争者。在未见过的猪圈中，在这些数据集上训练的模型表现良好，显示出良好的泛化能力，强调了高质量训练数据的重要性。该研究公开了数据集和代码，以促进可重复性、再利用和进一步发展。

Abstract: To ensure animal welfare and effective management in pig farming, monitoring
individual behavior is a crucial prerequisite. While monitoring tasks have
traditionally been carried out manually, advances in machine learning have made
it possible to collect individualized information in an increasingly automated
way. Central to these methods is the localization of animals across space
(object detection) and time (multi-object tracking). Despite extensive research
of these two tasks in pig farming, a systematic benchmarking study has not yet
been conducted. In this work, we address this gap by curating two datasets:
PigDetect for object detection and PigTrack for multi-object tracking. The
datasets are based on diverse image and video material from realistic barn
conditions, and include challenging scenarios such as occlusions or bad
visibility. For object detection, we show that challenging training images
improve detection performance beyond what is achievable with randomly sampled
images alone. Comparing different approaches, we found that state-of-the-art
models offer substantial improvements in detection quality over real-time
alternatives. For multi-object tracking, we observed that SORT-based methods
achieve superior detection performance compared to end-to-end trainable models.
However, end-to-end models show better association performance, suggesting they
could become strong alternatives in the future. We also investigate
characteristic failure cases of end-to-end models, providing guidance for
future improvements. The detection and tracking models trained on our datasets
perform well in unseen pens, suggesting good generalization capabilities. This
highlights the importance of high-quality training data. The datasets and
research code are made publicly available to facilitate reproducibility, re-use
and further development.

</details>


### [69] [Synthetic Data Matters: Re-training with Geo-typical Synthetic Labels for Building Detection](https://arxiv.org/abs/2507.16657)
*Shuang Song,Yang Tang,Rongjun Qin*

Main category: cs.CV

TL;DR: 通过在测试时使用针对目标区域定制的合成数据重新训练模型，并结合对抗性域适应，显著提高了遥感建筑分割的泛化能力，解决了数据不足和模型泛化能力差的问题。


<details>
  <summary>Details</summary>
Motivation: 深度学习模型在处理不同地理区域的遥感建筑分割数据时存在泛化能力不足的问题，因为城市布局、建筑类型、大小和位置存在差异。而耗时的人工标注数据难以满足日益增长的数据需求。

Method: 提出一种新颖的方法：在测试时使用针对目标区域城市布局定制的合成数据来重新训练模型。该方法利用街区网络等地理空间数据生成地理典型合成数据，并通过程序化建模和基于物理的渲染创建高分辨率合成图像，同时在建筑形状、材料和环境光照方面进行领域随机化。采用对抗性域适应框架来弥合合成到真实域的差距。

Result: 实验证明，该方法在遥感建筑分割方面显著提高了性能，根据域差距的不同，中值提高了12%。

Conclusion: 该方法通过结合地理知识和合成图像，为提高遥感建筑分割的泛化能力提供了一种实用的途径，解决了纯合成数据集中的“模型崩溃”问题。

Abstract: Deep learning has significantly advanced building segmentation in remote
sensing, yet models struggle to generalize on data of diverse geographic
regions due to variations in city layouts and the distribution of building
types, sizes and locations. However, the amount of time-consuming annotated
data for capturing worldwide diversity may never catch up with the demands of
increasingly data-hungry models. Thus, we propose a novel approach: re-training
models at test time using synthetic data tailored to the target region's city
layout. This method generates geo-typical synthetic data that closely
replicates the urban structure of a target area by leveraging geospatial data
such as street network from OpenStreetMap. Using procedural modeling and
physics-based rendering, very high-resolution synthetic images are created,
incorporating domain randomization in building shapes, materials, and
environmental illumination. This enables the generation of virtually unlimited
training samples that maintain the essential characteristics of the target
environment. To overcome synthetic-to-real domain gaps, our approach integrates
geo-typical data into an adversarial domain adaptation framework for building
segmentation. Experiments demonstrate significant performance enhancements,
with median improvements of up to 12%, depending on the domain gap. This
scalable and cost-effective method blends partial geographic knowledge with
synthetic imagery, providing a promising solution to the "model collapse" issue
in purely synthetic datasets. It offers a practical pathway to improving
generalization in remote sensing building segmentation without extensive
real-world annotations.

</details>


### [70] [QRetinex-Net: Quaternion-Valued Retinex Decomposition for Low-Level Computer Vision Applications](https://arxiv.org/abs/2507.16683)
*Sos Agaian,Vladimir Frants*

Main category: cs.CV

TL;DR: 本文提出了一种新的四元数Retinex模型，通过将图像分解为四元数值的反射率和照明，并引入反射率一致性指数，解决了传统Retinex模型的局限性。实验结果表明，该模型在多项计算机视觉任务中表现优于现有方法，并能更好地处理低光照和颜色恒常性问题。


<details>
  <summary>Details</summary>
Motivation: 传统Retinex模型在处理低光照图像时存在独立处理颜色通道、缺乏神经科学色彩视觉模型、无法完美重建输入图像以及无法解释人类颜色恒常性等四个关键缺陷。这些缺陷导致低光照图像出现颜色偏移、对比度低、噪点多等问题，影响计算机视觉的准确性。

Method: 本文提出了一种新的四元数Retinex（Quaternion Retinex）模型，将图像表示为四元数值反射率和照明的Hamilton乘积。并提出了反射率一致性指数（Reflectance Consistency Index）来衡量反射率的不变性。

Result: 在低光照裂缝检测、面部检测（不同光照条件）和红外-可见光融合等任务上，与现有领先方法相比，性能提升了2-11个百分点，同时提高了颜色保真度、降低了噪点并增强了反射率稳定性。

Conclusion: 本文提出了一种新的四元数Retinex模型，该模型通过将场景表示为四元数值反射率和照明的Hamilton乘积来解决传统Retinex模型的局限性。通过引入反射率一致性指数来衡量反射率的不变性，并在低光照裂缝检测、不同光照下的面部检测以及红外-可见光融合等任务中取得了显著的性能提升。

Abstract: Images taken in low light often show color shift, low contrast, noise, and
other artifacts that hurt computer-vision accuracy. Retinex theory addresses
this by viewing an image S as the pixel-wise product of reflectance R and
illumination I, mirroring the way people perceive stable object colors under
changing light. The decomposition is ill-posed, and classic Retinex models have
four key flaws: (i) they treat the red, green, and blue channels independently;
(ii) they lack a neuroscientific model of color vision; (iii) they cannot
perfectly rebuild the input image; and (iv) they do not explain human color
constancy. We introduce the first Quaternion Retinex formulation, in which the
scene is written as the Hamilton product of quaternion-valued reflectance and
illumination. To gauge how well reflectance stays invariant, we propose the
Reflectance Consistency Index. Tests on low-light crack inspection, face
detection under varied lighting, and infrared-visible fusion show gains of 2-11
percent over leading methods, with better color fidelity, lower noise, and
higher reflectance stability.

</details>


### [71] [Enhancing Remote Sensing Vision-Language Models Through MLLM and LLM-Based High-Quality Image-Text Dataset Generation](https://arxiv.org/abs/2507.16716)
*Yiguo He,Junjie Zhu,Yiying Li,Xiaoyu Zhang,Chunping Qiu,Jun Wang,Qiangjuan Huang,Ke Yang*

Main category: cs.CV

TL;DR: 该研究提出了MpGI方法，通过多视角生成与集成技术，创建了高质量的遥感图像数据集HQRS-IT-210K。使用此数据集微调的HQRS-CLIP和RS-CoCa模型在性能上均超越了现有方法，尤其是在数据效率和文本描述质量方面。


<details>
  <summary>Details</summary>
Motivation: 现有遥感（RS）领域视觉-语言基础模型（VLFMs）应用广泛，但高质量、大规模的图文配对训练数据稀缺。先前研究虽然引入了RS图文数据集并训练了VLFMs，但由于文本描述生成方法初级，数据集质量不高，导致需要大量训练数据，而性能提升有限。

Method: 本文提出了一种名为MpGI（多视角生成与集成）的两阶段方法来生成高质量的遥感（RS）图像文本描述。首先，利用Rule-MLLM（多模态大语言模型）的Relay Generation和MLLMs生成方法从不同视角生成多样化且详细的描述。然后，利用大语言模型（LLMs）将这些多样化的描述整合成全面的文本描述，捕捉多视角细节。

Result: MpGI方法成功生成了HQRS-IT-210K数据集，包含约210,000张遥感图像和130万条文本描述。使用HQRS-IT-210K数据集微调的HQRS-CLIP模型在多种下游任务中，性能超越了之前的SOTA RS CLIP模型，且训练数据量仅占4.2%。RS-CoCa模型在基准数据集上的表现优于其他先进方法，并且其生成的文本描述质量可与人工标注相媲美甚至超越。

Conclusion: MpGI方法生成的HQRS-IT-210K数据集，包含约21万张遥感图像和130万条文本描述，在遥感图像领域展现出显著优势。基于该数据集微调的HQRS-CLIP模型在多种下游任务中，仅用4.2%的训练数据即超越了现有SOTA RS CLIP模型；RS-CoCa模型在基准数据集上表现优于其他先进方法，并能生成媲美甚至超越人工标注的遥感图像文本描述。

Abstract: The application of Vision-language foundation models (VLFMs) to remote
sensing (RS) imagery has garnered significant attention due to their superior
capability in various downstream tasks. A key challenge lies in the scarcity of
high-quality, large-scale, image-text paired training data. Recently, several
works introduced extensive image-text datasets for RS and trained their VLFMs.
However, due to the rudimentary methods used for generating captions, the
quality of datasets is suboptimal, requiring larger volumes of training data,
while only yielding modest performance improvements. In this paper, we propose
a two-stage method named MpGI(Multi-Perspective Generation and Integration) for
generating high-quality text captions for RS images. Firstly, we generate
distinct and detailed descriptions from different perspectives using
Rule-MLLM(Multimodal Large Language Model) Relay Generation and MLLMs
generation methods. Next, we utilize Large Language Models (LLMs) to integrate
these diverse descriptions into comprehensive captions, capturing details from
multiple perspectives. Finally, we have created the HQRS-IT-210K dataset,
including about 210,000 RS images and 1.3 million captions. We fine-tuned two
VLFMs using our dataset: CLIP, a discriminative model, and CoCa, an
image-to-text generative model. This process resulted in our proposed HQRS-CLIP
and RS-CoCa models. Experimental results demonstrate that HQRS-CLIP surpassed
the previous SOTA RS CLIP model in various downstream tasks while using only
4.2\% of the training data. RS-CoCa outperforms other advanced approaches
across benchmark datasets and can generate captions for RS images that rival or
even exceed manual annotations. Dataset, pre-trained models, and codes will be
released at https://github.com/YiguoHe/HQRS-210K-and-HQRS-CLIP.

</details>


### [72] [Temporally-Constrained Video Reasoning Segmentation and Automated Benchmark Construction](https://arxiv.org/abs/2507.16718)
*Yiqing Shen,Chenjia Li,Chenxiao Fan,Mathias Unberath*

Main category: cs.CV

TL;DR: 通过引入时序约束，解决了视频分割中对象动态变化 relevancy 的问题，并提供了一种自动化的数据集构建方法。


<details>
  <summary>Details</summary>
Motivation: 现有视频分割方法受限于预定义对象类别，无法识别未登录词或隐式引用的对象，在需要处理开放词汇量和动态变化对象的复杂场景（如手术视频分析）中存在局限性。现有的视频推理分割方法假设目标对象在整个视频序列中都相关，这不符合现实世界中对象动态变化 relevancy 的情况。

Method: 提出时序约束视频推理分割（TCVideoRS）新任务，并开发了一种自动化的基准数据集构建方法，最终构建了包含52个样本的TCVideoRSBenchmark数据集，该数据集基于MVOR数据集。

Result: 成功提出了时序约束视频推理分割任务和自动化的基准构建方法，并构建了TCVideoRSBenchmark数据集。

Conclusion: 该研究提出了一种新的时序约束视频推理分割任务，并开发了一种自动化的基准构建方法，旨在解决现有视频分割方法无法处理开放词汇量和动态变化对象的问题，尤其是在复杂的现实场景中，如手术视频分析。

Abstract: Conventional approaches to video segmentation are confined to predefined
object categories and cannot identify out-of-vocabulary objects, let alone
objects that are not identified explicitly but only referred to implicitly in
complex text queries. This shortcoming limits the utility for video
segmentation in complex and variable scenarios, where a closed set of object
categories is difficult to define and where users may not know the exact object
category that will appear in the video. Such scenarios can arise in operating
room video analysis, where different health systems may use different workflows
and instrumentation, requiring flexible solutions for video analysis. Reasoning
segmentation (RS) now offers promise towards such a solution, enabling natural
language text queries as interaction for identifying object to segment.
However, existing video RS formulation assume that target objects remain
contextually relevant throughout entire video sequences. This assumption is
inadequate for real-world scenarios in which objects of interest appear,
disappear or change relevance dynamically based on temporal context, such as
surgical instruments that become relevant only during specific procedural
phases or anatomical structures that gain importance at particular moments
during surgery. Our first contribution is the introduction of
temporally-constrained video reasoning segmentation, a novel task formulation
that requires models to implicitly infer when target objects become
contextually relevant based on text queries that incorporate temporal
reasoning. Since manual annotation of temporally-constrained video RS datasets
would be expensive and limit scalability, our second contribution is an
innovative automated benchmark construction method. Finally, we present
TCVideoRSBenchmark, a temporally-constrained video RS dataset containing 52
samples using the videos from the MVOR dataset.

</details>


### [73] [HarmonPaint: Harmonized Training-Free Diffusion Inpainting](https://arxiv.org/abs/2507.16732)
*Ying Li,Xinzhe Li,Yong Du,Yangyang Xu,Junyu Dong,Shengfeng He*

Main category: cs.CV

TL;DR: HarmonPaint is a new training-free image inpainting method that uses diffusion models' attention mechanisms to seamlessly blend inpainted areas with the background, preserving structure and style without retraining.


<details>
  <summary>Details</summary>
Motivation: Existing inpainting methods struggle to maintain coherence in structure and style and require extensive retraining or fine-tuning to integrate new content seamlessly. HarmonPaint addresses these limitations by providing a training-free solution.

Method: HarmonPaint integrates with the attention mechanisms of diffusion models, using masking strategies within self-attention to ensure structural fidelity and exploiting intrinsic diffusion model properties to transfer style information from unmasked to masked regions. This approach avoids the need for model retraining or fine-tuning.

Result: HarmonPaint demonstrates effectiveness across diverse scenes and styles, validating its versatility and performance in achieving harmonious image inpainting.

Conclusion: HarmonPaint is a versatile and effective training-free inpainting framework that achieves high-quality, harmonized image inpainting by leveraging masking strategies within self-attention and exploiting intrinsic diffusion model properties for style transfer.

Abstract: Existing inpainting methods often require extensive retraining or fine-tuning
to integrate new content seamlessly, yet they struggle to maintain coherence in
both structure and style between inpainted regions and the surrounding
background. Motivated by these limitations, we introduce HarmonPaint, a
training-free inpainting framework that seamlessly integrates with the
attention mechanisms of diffusion models to achieve high-quality, harmonized
image inpainting without any form of training. By leveraging masking strategies
within self-attention, HarmonPaint ensures structural fidelity without model
retraining or fine-tuning. Additionally, we exploit intrinsic diffusion model
properties to transfer style information from unmasked to masked regions,
achieving a harmonious integration of styles. Extensive experiments demonstrate
the effectiveness of HarmonPaint across diverse scenes and styles, validating
its versatility and performance.

</details>


### [74] [DFR: A Decompose-Fuse-Reconstruct Framework for Multi-Modal Few-Shot Segmentation](https://arxiv.org/abs/2507.16736)
*Shuai Chen,Fanman Meng,Xiwei Zhang,Haoran Wei,Chenhao Wu,Qingbo Wu,Hongliang Li*

Main category: cs.CV

TL;DR: DFR框架通过分解、融合和重建，有效整合视觉、文本和音频信息，提升少样本分割性能。


<details>
  <summary>Details</summary>
Motivation: 现有少样本分割方法主要依赖单一或双一模态（视觉或文本）的引导，未能充分利用现实世界中丰富的多模态感知信息。本文旨在克服这一局限，提出一种能有效利用多模态（视觉、文本、音频）信息的新框架。

Method: DFR框架提出了一种新颖的Decompose, Fuse and Reconstruct（DFR）方法，利用Segment Anything Model（SAM）来系统地整合视觉、文本和音频模态。具体包括：1）多模态分解：通过SAM提取视觉区域建议，扩展文本语义为细粒度描述符，并处理音频特征以进行上下文丰富。2）多模态对比融合：采用对比学习策略保持跨模态一致性，并实现前景与背景特征间的动态语义交互。3）双路径重建：结合三模态融合语义指导和多模态定位几何线索。

Result: DFR框架在视觉、文本和音频模态的综合实验中，无论是在合成还是真实场景下，都展示了相比现有最先进方法的显著性能提升。

Conclusion: DFR框架在少样本分割领域通过整合视觉、文本和音频模态取得了显著的性能提升，超越了现有最先进的方法。

Abstract: This paper presents DFR (Decompose, Fuse and Reconstruct), a novel framework
that addresses the fundamental challenge of effectively utilizing multi-modal
guidance in few-shot segmentation (FSS). While existing approaches primarily
rely on visual support samples or textual descriptions, their single or
dual-modal paradigms limit exploitation of rich perceptual information
available in real-world scenarios. To overcome this limitation, the proposed
approach leverages the Segment Anything Model (SAM) to systematically integrate
visual, textual, and audio modalities for enhanced semantic understanding. The
DFR framework introduces three key innovations: 1) Multi-modal Decompose: a
hierarchical decomposition scheme that extracts visual region proposals via
SAM, expands textual semantics into fine-grained descriptors, and processes
audio features for contextual enrichment; 2) Multi-modal Contrastive Fuse: a
fusion strategy employing contrastive learning to maintain consistency across
visual, textual, and audio modalities while enabling dynamic semantic
interactions between foreground and background features; 3) Dual-path
Reconstruct: an adaptive integration mechanism combining semantic guidance from
tri-modal fused tokens with geometric cues from multi-modal location priors.
Extensive experiments across visual, textual, and audio modalities under both
synthetic and real settings demonstrate DFR's substantial performance
improvements over state-of-the-art methods.

</details>


### [75] [Denoising-While-Completing Network (DWCNet): Robust Point Cloud Completion Under Corruption](https://arxiv.org/abs/2507.16743)
*Keneni W. Tesema,Lyndon Hill,Mark W. Jones,Gary K. L. Tam*

Main category: cs.CV

TL;DR: DWCNet是一种新的点云补全方法，可以处理噪声和遮挡等真实世界的损坏。它使用噪声管理模块（NMM）来抑制噪声并学习点云的结构。DWCNet在各种数据集上都取得了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 解决在自动驾驶、增强现实和机器人等领域至关重要的点云补全问题，同时应对真实世界中由噪声和遮挡引起的严重损坏。

Method: 提出了一种名为DWCNet的完成框架，该框架通过一个噪声管理模块（NMM）进行增强，该模块利用对比学习和自注意力来抑制噪声和建模结构关系。

Result: DWCNet在干净和损坏的、合成和真实世界的数据集上都取得了最先进的性能。

Conclusion: DWCNet在干净和损坏的、合成和真实世界的数据集上都取得了最先进的性能。

Abstract: Point cloud completion is crucial for 3D computer vision tasks in autonomous
driving, augmented reality, and robotics. However, obtaining clean and complete
point clouds from real-world environments is challenging due to noise and
occlusions. Consequently, most existing completion networks -- trained on
synthetic data -- struggle with real-world degradations. In this work, we
tackle the problem of completing and denoising highly corrupted partial point
clouds affected by multiple simultaneous degradations. To benchmark robustness,
we introduce the Corrupted Point Cloud Completion Dataset (CPCCD), which
highlights the limitations of current methods under diverse corruptions.
Building on these insights, we propose DWCNet (Denoising-While-Completing
Network), a completion framework enhanced with a Noise Management Module (NMM)
that leverages contrastive learning and self-attention to suppress noise and
model structural relationships. DWCNet achieves state-of-the-art performance on
both clean and corrupted, synthetic and real-world datasets. The dataset and
code will be publicly available at
https://github.com/keneniwt/DWCNET-Robust-Point-Cloud-Completion-against-Corruptions

</details>


### [76] [CMP: A Composable Meta Prompt for SAM-Based Cross-Domain Few-Shot Segmentation](https://arxiv.org/abs/2507.16753)
*Shuai Chen,Fanman Meng,Chunjin Yang,Haoran Wei,Chenhao Wu,Qingbo Wu,Hongliang Li*

Main category: cs.CV

TL;DR: 提出 CMP 框架通过 RCT、CMPG 和 FAI 模块改进了 SAM 在跨域少样本分割任务中的表现，在 1 次和 5 次样本场景下分别达到了 71.8% 和 74.5% 的 mIoU。


<details>
  <summary>Details</summary>
Motivation: 为了解决跨域少样本分割（CD-FSS）中数据限制和域转移带来的挑战，并改进现有基础模型（如 SAM）在手动提示依赖和有限的跨域能力方面的不足。

Method: 提出了一种名为可组合元提示（CMP）的框架，该框架包含三个关键模块：(i) 用于语义扩展的参考补充和变换（RCT）模块，(ii) 用于自动化元提示合成的可组合元提示生成（CMPG）模块，以及 (iii) 用于缓解域差异的频率感知交互（FAI）模块。

Result: 评估结果表明，CMP 在四个跨域数据集上均表现出色，在 1 次和 5 次样本场景下分别达到了 71.8% 和 74.5% 的 mIoU。

Conclusion: CMP 在跨域少样本分割任务中取得了最先进的性能，在 1 次和 5 次样本场景下分别达到了 71.8% 和 74.5% 的 mIoU。

Abstract: Cross-Domain Few-Shot Segmentation (CD-FSS) remains challenging due to
limited data and domain shifts. Recent foundation models like the Segment
Anything Model (SAM) have shown remarkable zero-shot generalization capability
in general segmentation tasks, making it a promising solution for few-shot
scenarios. However, adapting SAM to CD-FSS faces two critical challenges:
reliance on manual prompt and limited cross-domain ability. Therefore, we
propose the Composable Meta-Prompt (CMP) framework that introduces three key
modules: (i) the Reference Complement and Transformation (RCT) module for
semantic expansion, (ii) the Composable Meta-Prompt Generation (CMPG) module
for automated meta-prompt synthesis, and (iii) the Frequency-Aware Interaction
(FAI) module for domain discrepancy mitigation. Evaluations across four
cross-domain datasets demonstrate CMP's state-of-the-art performance, achieving
71.8\% and 74.5\% mIoU in 1-shot and 5-shot scenarios respectively.

</details>


### [77] [Faithful, Interpretable Chest X-ray Diagnosis with Anti-Aliased B-cos Networks](https://arxiv.org/abs/2507.16761)
*Marcel Kleinmann,Shashank Agnihotri,Margret Keuper*

Main category: cs.CV

TL;DR: 通过抗锯齿和支持多标签分类改进了 B-cos 网络，使其在医学影像分析中更具临床适用性。


<details>
  <summary>Details</summary>
Motivation: 深度神经网络（DNNs）在医疗影像等安全关键领域的应用需要高可信度和可解释性。标准 B-cos 网络虽然提供了固有的、类别特定的解释，但存在严重的锯齿伪影，不适合临床使用，并且原始 B-cos 模型的局限性在于仅限于多类别设置，而胸部 X 光分析常需要多标签分类。

Method: 提出抗锯齿策略（FLCPooling 和 BlurPool）来改进解释图谱的质量，并将 B-cos 网络扩展到支持多标签分类。

Result: 修改后的 B-cos 模型（B-cos_FLC 和 B-cos_BP）在胸部 X 光数据集上进行了实验，结果表明它们在保持强大预测能力的同时，提供了忠实且无伪影的可解释性，适用于多标签医学影像的临床应用。

Conclusion: 该研究通过引入抗锯齿策略（FLCPooling 和 BlurPool）并扩展 B-cos 网络以支持多标签分类，解决了标准 B-cos 网络在可解释性图谱中存在严重锯齿伪影和仅限于多类别设置的问题。实验证明，修改后的 B-cos 模型在保持强大预测能力的同时，能够提供适用于多标签医学影像临床应用、忠实且无伪影的可解释性。

Abstract: Faithfulness and interpretability are essential for deploying deep neural
networks (DNNs) in safety-critical domains such as medical imaging. B-cos
networks offer a promising solution by replacing standard linear layers with a
weight-input alignment mechanism, producing inherently interpretable,
class-specific explanations without post-hoc methods. While maintaining
diagnostic performance competitive with state-of-the-art DNNs, standard B-cos
models suffer from severe aliasing artifacts in their explanation maps, making
them unsuitable for clinical use where clarity is essential. Additionally, the
original B-cos formulation is limited to multi-class settings, whereas chest
X-ray analysis often requires multi-label classification due to co-occurring
abnormalities. In this work, we address both limitations: (1) we introduce
anti-aliasing strategies using FLCPooling (FLC) and BlurPool (BP) to
significantly improve explanation quality, and (2) we extend B-cos networks to
support multi-label classification. Our experiments on chest X-ray datasets
demonstrate that the modified $\text{B-cos}_\text{FLC}$ and
$\text{B-cos}_\text{BP}$ preserve strong predictive performance while providing
faithful and artifact-free explanations suitable for clinical application in
multi-label settings. Code available at:
$\href{https://github.com/mkleinma/B-cos-medical-paper}{GitHub repository}$.

</details>


### [78] [Task-Specific Zero-shot Quantization-Aware Training for Object Detection](https://arxiv.org/abs/2507.16782)
*Changhao Li,Xinrui Chen,Ji Wang,Kang Zhao,Jianfei Chen*

Main category: cs.CV

TL;DR: 本研究提出了一种新的零样本量化（ZSQ）框架，用于对象检测。该框架通过生成特定任务的合成数据（包含边界框和类别信息）并结合知识蒸馏来提高量化检测网络的性能，解决了现有方法使用通用合成数据导致性能不佳的问题。实验结果表明，该方法在MS-COCO和Pascal VOC数据集上达到了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的零样本量化（ZSQ）方法在对象检测任务上表现不佳，因为它们使用未经标注的、与任务无关的合成图像，缺乏特定任务所需的信息。

Method: 提出了一种新颖的、针对特定任务的零样本量化（ZSQ）框架，用于对象检测网络。该框架包含两个主要阶段：1. 引入边界框和类别采样策略，从预训练网络合成特定任务的校准集，在无先验知识的情况下重建对象位置、大小和类别分布。2. 将特定任务训练整合到知识蒸馏过程中，以恢复量化检测网络的性能。

Result: 通过在MS-COCO和Pascal VOC数据集上进行的大量实验，证明了所提出方法在对象检测任务上的效率和先进性能。

Conclusion: 所提出的零样本量化框架在MS-COCO和Pascal VOC数据集上进行了广泛的实验，证明了其效率和领先性能。

Abstract: Quantization is a key technique to reduce network size and computational
complexity by representing the network parameters with a lower precision.
Traditional quantization methods rely on access to original training data,
which is often restricted due to privacy concerns or security challenges.
Zero-shot Quantization (ZSQ) addresses this by using synthetic data generated
from pre-trained models, eliminating the need for real training data. Recently,
ZSQ has been extended to object detection. However, existing methods use
unlabeled task-agnostic synthetic images that lack the specific information
required for object detection, leading to suboptimal performance. In this
paper, we propose a novel task-specific ZSQ framework for object detection
networks, which consists of two main stages. First, we introduce a bounding box
and category sampling strategy to synthesize a task-specific calibration set
from the pre-trained network, reconstructing object locations, sizes, and
category distributions without any prior knowledge. Second, we integrate
task-specific training into the knowledge distillation process to restore the
performance of quantized detection networks. Extensive experiments conducted on
the MS-COCO and Pascal VOC datasets demonstrate the efficiency and
state-of-the-art performance of our method. Our code is publicly available at:
https://github.com/DFQ-Dojo/dfq-toolkit .

</details>


### [79] [Enhancing Domain Diversity in Synthetic Data Face Recognition with Dataset Fusion](https://arxiv.org/abs/2507.16790)
*Anjith George,Sebastien Marcel*

Main category: cs.CV

TL;DR: 为了解决人脸识别合成训练数据存在的隐私问题以及现有合成数据表现不佳的问题，本文提出了一种融合两种不同模型生成的合成数据集的方法，该方法通过增加数据多样性和减少伪影，显著提升了人脸识别模型的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的人脸识别系统虽然精度有所提升，但训练数据集（常通过网络爬取）涉及隐私和伦理问题。虽然使用合成数据可以解决这些问题，但目前的方法在真实数据上表现不佳，主要原因是单一生成器会引入模型特有的伪影，导致模型过拟合。

Method: 本文提出了一种通过融合两个采用不同架构的生成模型所产生的合成人脸数据集的解决方案，以克服单一生成模型产生的伪影问题，并提升模型的泛化能力。

Result: 在标准人脸识别基准测试中，使用融合数据集训练的模型表现优于使用单一数据集或真实数据集训练的模型。

Conclusion: 通过融合两个具有不同架构的生成模型生成的合成数据集，可以有效减少模型特定的伪影，增强数据的多样性（姿态、光照、人口统计学），并隐含地进行正则化，最终在标准人脸识别基准测试中实现超越现有技术水平的性能。

Abstract: While the accuracy of face recognition systems has improved significantly in
recent years, the datasets used to train these models are often collected
through web crawling without the explicit consent of users, raising ethical and
privacy concerns. To address this, many recent approaches have explored the use
of synthetic data for training face recognition models. However, these models
typically underperform compared to those trained on real-world data. A common
limitation is that a single generator model is often used to create the entire
synthetic dataset, leading to model-specific artifacts that may cause
overfitting to the generator's inherent biases and artifacts. In this work, we
propose a solution by combining two state-of-the-art synthetic face datasets
generated using architecturally distinct backbones. This fusion reduces
model-specific artifacts, enhances diversity in pose, lighting, and
demographics, and implicitly regularizes the face recognition model by
emphasizing identity-relevant features. We evaluate the performance of models
trained on this combined dataset using standard face recognition benchmarks and
demonstrate that our approach achieves superior performance across many of
these benchmarks.

</details>


### [80] [HOComp: Interaction-Aware Human-Object Composition](https://arxiv.org/abs/2507.16813)
*Dong Liang,Jinyuan Jia,Yuhao Liu,Rynson W. H. Lau*

Main category: cs.CV

TL;DR: HOComp是一种新颖的人体-物体组合方法，它利用MLLM进行姿势引导，并通过DCAP保持外观一致性，解决了现有方法在处理人与物交互时的不足，并在IHOC数据集上取得了优于其他方法的性能。


<details>
  <summary>Details</summary>
Motivation: 现有图像引导的组合方法在处理涉及人与物交互的任务时，在合成无缝的、感知的交互组合方面常常遇到困难。

Method: HOComp包含两个关键设计：(1) MLLMs驱动的基于区域的姿势引导（MRPG），利用MLLMs识别交互区域和交互类型，为交互的生成姿势提供粗到细的约束，并结合人体姿势地标来跟踪动作变化和强制执行细粒度姿势约束；(2) 细节一致的外观保持（DCAP），它统一了形状感知注意力调制机制、多视图外观损失和背景一致性损失，以确保前景形状/纹理的一致性以及背景人物的忠实再现。此外，还提出了首个用于该任务的数据集IHOC。

Result: 实验结果表明，HOComp能够生成和谐的人体-物体交互，并具有一致的外观，在定性和定量上均优于相关方法。

Conclusion: HOComp能够生成和谐的人体-物体交互，并具有一致的外观，在定性和定量上均优于相关方法。

Abstract: While existing image-guided composition methods may help insert a foreground
object onto a user-specified region of a background image, achieving natural
blending inside the region with the rest of the image unchanged, we observe
that these existing methods often struggle in synthesizing seamless
interaction-aware compositions when the task involves human-object
interactions. In this paper, we first propose HOComp, a novel approach for
compositing a foreground object onto a human-centric background image, while
ensuring harmonious interactions between the foreground object and the
background person and their consistent appearances. Our approach includes two
key designs: (1) MLLMs-driven Region-based Pose Guidance (MRPG), which utilizes
MLLMs to identify the interaction region as well as the interaction type (e.g.,
holding and lefting) to provide coarse-to-fine constraints to the generated
pose for the interaction while incorporating human pose landmarks to track
action variations and enforcing fine-grained pose constraints; and (2)
Detail-Consistent Appearance Preservation (DCAP), which unifies a shape-aware
attention modulation mechanism, a multi-view appearance loss, and a background
consistency loss to ensure consistent shapes/textures of the foreground and
faithful reproduction of the background human. We then propose the first
dataset, named Interaction-aware Human-Object Composition (IHOC), for the task.
Experimental results on our dataset show that HOComp effectively generates
harmonious human-object interactions with consistent appearances, and
outperforms relevant methods qualitatively and quantitatively.

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [81] [eSapiens's DEREK Module: Deep Extraction & Reasoning Engine for Knowledge with LLMs](https://arxiv.org/abs/2507.15863)
*Isaac Shi,Zeyuan Li,Fan Liu,Wenli Wang,Lewei He,Yang Yang,Tianyu Shi*

Main category: cs.CL

TL;DR: DEREK模块是一个安全的、可扩展的企业文档问答RAG流水线，通过GPT-4o查询优化、混合检索、Cohere重新排序和LangGraph验证，实现了高准确性和可追溯性，满足了法律和金融等高风险领域的需求。


<details>
  <summary>Details</summary>
Motivation: 该研究旨在开发一个安全、可扩展的、专门用于企业文档问答的检索增强生成（RAG）流水线，以满足企业对安全、可审计和上下文忠实检索的需求，特别是在法律和金融等高风险领域。

Method: DEREK模块采用安全的、可扩展的检索增强生成（RAG）流水线。它处理PDF、Office和Web等异构内容，将其分割成1000个token的重叠块，并使用混合HNSW+BM25存储进行索引。用户查询由GPT-4o优化，通过向量+BM25组合搜索进行检索，由Cohere重新排序，并使用CO-STAR提示工程由LLM进行回答。LangGraph验证器强制执行引用重叠，并重新生成答案，直到所有声明都有据可查。所有组件都在容器中运行，并强制执行端到端TLS 1.3和AES-256。

Result: 在四个LegalBench子集上，1000-token的块将Recall@50提高了约1个百分点，混合检索+重新排序将Precision@10提高了约7个百分点。验证器将TRACe利用率提高到0.50以上，并将不支持的陈述限制在3%以下。这些结果表明DEREK模块能够以最小的运营开销提供准确、可追溯且可投入生产的文档问答。

Conclusion: DEREK模块在法律文档问答方面表现出色，实现了高准确性、可追溯性和生产就绪性，同时具有较低的运营开销。它满足了企业对安全、可审计和上下文忠实检索的需求，为法律和金融等高风险领域提供了可靠的基准。

Abstract: We present the DEREK (Deep Extraction & Reasoning Engine for Knowledge)
Module, a secure and scalable Retrieval-Augmented Generation pipeline designed
specifically for enterprise document question answering. Designed and
implemented by eSapiens, the system ingests heterogeneous content (PDF, Office,
web), splits it into 1,000-token overlapping chunks, and indexes them in a
hybrid HNSW+BM25 store. User queries are refined by GPT-4o, retrieved via
combined vector+BM25 search, reranked with Cohere, and answered by an LLM using
CO-STAR prompt engineering. A LangGraph verifier enforces citation overlap,
regenerating answers until every claim is grounded. On four LegalBench subsets,
1000-token chunks improve Recall@50 by approximately 1 pp and hybrid+rerank
boosts Precision@10 by approximately 7 pp; the verifier raises TRACe
Utilization above 0.50 and limits unsupported statements to less than 3%. All
components run in containers, enforce end-to-end TLS 1.3 and AES-256. These
results demonstrate that the DEREK module delivers accurate, traceable, and
production-ready document QA with minimal operational overhead. The module is
designed to meet enterprise demands for secure, auditable, and context-faithful
retrieval, providing a reliable baseline for high-stakes domains such as legal
and finance.

</details>


### [82] [Adversarial Demonstration Learning for Low-resource NER Using Dual Similarity](https://arxiv.org/abs/2507.15864)
*Guowen Yuan,Tien-Hsuan Wu,Lianghao Xia,Ben Kao*

Main category: cs.CL

TL;DR: 通过结合特征相似性和对抗性训练来改进低资源NER的演示学习。


<details>
  <summary>Details</summary>
Motivation: 低资源场景下命名实体识别（NER）的演示学习存在两个问题：1. 现有方法主要依赖语义相似性选择演示示例，而特征相似性可以带来显著的性能提升。 2. NER标注器引用演示示例的能力通常不足。

Method: 1. 提出双重相似性（包括语义相似性和特征相似性）来选择示例。 2. 提出对抗性演示训练方法，强制模型在标注任务中参考演示。

Result: 所提出的方法在低资源NER任务中取得了优于现有方法的性能。

Conclusion: 该方法在低资源NER任务中优于一系列现有方法。

Abstract: We study the problem of named entity recognition (NER) based on demonstration
learning in low-resource scenarios. We identify two issues in demonstration
construction and model training. Firstly, existing methods for selecting
demonstration examples primarily rely on semantic similarity; We show that
feature similarity can provide significant performance improvement. Secondly,
we show that the NER tagger's ability to reference demonstration examples is
generally inadequate. We propose a demonstration and training approach that
effectively addresses these issues. For the first issue, we propose to select
examples by dual similarity, which comprises both semantic similarity and
feature similarity. For the second issue, we propose to train an NER model with
adversarial demonstration such that the model is forced to refer to the
demonstrations when performing the tagging task. We conduct comprehensive
experiments in low-resource NER tasks, and the results demonstrate that our
method outperforms a range of methods.

</details>


### [83] [Small Edits, Big Consequences: Telling Good from Bad Robustness in Large Language Models](https://arxiv.org/abs/2507.15868)
*Altynbek Ismailov,Salia Asanova*

Main category: cs.CL

TL;DR: LLMs 在代码生成中对提示过于鲁棒，对无害变化稳定，但对有意义的改变（如“最大”改“最小”）反应迟钝，甚至比基础模型更差。它们需要能区分噪声和语义变化的评估与训练方法。


<details>
  <summary>Details</summary>
Motivation: 探究大型语言模型（LLMs）在代码生成任务中的鲁棒性界限，特别是它们在面对可能影响安全性或成本的微小提示变化时的表现，以及区分无害的鲁棒性和有害的不敏感性。

Method: 通过编译 50 个 LeetCode 问题，并对提示进行三种最小扰动：渐进式低说明、词汇翻转和术语膨胀。然后，评估六种前沿模型（包括三种“推理微调”版本）在这些扰动提示下的 Python 代码生成能力，并与原始测试用例进行比对。

Result: 在 11853 个生成结果中，模型在 90% 的提示被删除的情况下仍有 85% 的正确率，表现出对低说明的过度鲁棒性。然而，在面对反转任务的单一量词翻转时，仅有 54% 的模型能正确响应，且推理微调版本比基础版本更不敏感。术语膨胀编辑的处理通过率为 56%。这表明 LLMs 常常将无害噪声和改变语义的编辑同等对待，忽略了它们之间的差异。

Conclusion: LLMs 当前在代码生成任务中表现出对提示的“过度鲁棒性”和“有害不敏感性”，它们在面对无害的噪声（如拼写错误）时过于稳定，但在面对有意义的改变（如量词的反转）时却不够敏感。模型倾向于忽略有意义的提示变化，这表明它们在区分无害噪声和语义改变的边界上存在模糊。

Abstract: Large language models (LLMs) now write code in settings where misreading a
single word can break safety or cost money, yet we still expect them to
overlook stray typos. To probe where useful robustness ends and harmful
insensitivity begins, we compile 50 LeetCode problems and craft three minimal
prompt perturbations that should vary in importance: (i) progressive
underspecification deleting 10 % of words per step; (ii) lexical flip swapping
a pivotal quantifier ("max" to "min"); and (iii) jargon inflation replacing a
common noun with an obscure technical synonym. Six frontier models, including
three "reasoning-tuned" versions, solve each mutated prompt, and their Python
outputs are checked against the original test suites to reveal whether they
reused the baseline solution or adapted. Among 11 853 generations we observe a
sharp double asymmetry. Models remain correct in 85 % of cases even after 90 %
of the prompt is missing, showing over-robustness to underspecification, yet
only 54 % react to a single quantifier flip that reverses the task, with
reasoning-tuned variants even less sensitive than their bases. Jargon edits lie
in between, passing through 56 %. Current LLMs thus blur the line between
harmless noise and meaning - changing edits, often treating both as ignorable.
Masking salient anchors such as function names can force re - evaluation. We
advocate evaluation and training protocols that reward differential
sensitivity: stay steady under benign noise but adapt - or refuse - when
semantics truly change.

</details>


### [84] [Enhancing Hindi NER in Low Context: A Comparative study of Transformer-based models with vs. without Retrieval Augmentation](https://arxiv.org/abs/2507.16002)
*Sumit Singh,Rohit Mishra,Uma Shanker Tiwary*

Main category: cs.CL

TL;DR: 本研究提出了一种结合预训练模型（MuRIL, XLM-R, Llama系列, GPT3.5）和检索增强（RA）的数据增强技术来提升印地语命名实体识别（NER）性能。结果表明，RA能显著提高模型性能，尤其是在低上下文数据上。微调模型和未微调的生成模型（特别是GPT3.5）均从RA中受益，但Llama2-70B和Llama3-70B未能有效利用RA。


<details>
  <summary>Details</summary>
Motivation: 自然语言处理中的一个主要挑战是命名实体识别（NER），即识别和分类文本输入中的命名实体。为了改进NER，本研究旨在探索一种利用印地语特定预训练编码器和生成模型，并通过检索外部相关上下文（如维基百科）来增强数据的方法，以提升NER性能，特别是在资源有限的语言中。

Method: 本研究提出了一种针对印地语的命名实体识别（NER）技术，该技术结合了特定于印地语的预训练编码器（MuRIL和XLM-R）以及生成模型（Llama-2-70B、Llama-3-70B、GPT3.5-turbo），并通过从维基百科等外部相关上下文中检索数据进行数据增强。研究对MuRIL、XLM-R和Llama2-7B进行了微调（有/无检索增强RA），而Llama2-70B、Llama3-70B和GPT3.5-turbo则用于少样本NER生成。

Result: 研究结果显示，采用检索增强（RA）的语言模型在大多数情况下优于不使用RA的基线方法。具体来说，RA将MuRIL的宏观F1分数从0.69提升到0.70，将XLM-R的宏观F1分数从0.495提升到0.71。微调的Llama2-70B显著优于未微调的Llama2-70B。此外，未微调的生成模型在加入增强数据后性能也有所提升。GPT3.5-turbo能很好地利用RA，但Llama2-70B和Llama3-70B未能有效利用检索到的上下文。

Conclusion: 本研究展示了检索增强（RA）能够显著提升命名实体识别（NER）性能，尤其是在低上下文数据上。研究表明，结合RA的预训练模型在大多数情况下优于不使用RA的基线方法。对于微调模型，RA提高了MuRIL和XLM-R的宏观F1分数，并显著优于微调的Llama2-7B。对于未微调的生成模型，RA也带来了性能提升，其中GPT3.5-turbo对RA的适应性较好，而Llama2-70B和Llama3-70B则未能很好地利用检索到的上下文。

Abstract: One major challenge in natural language processing is named entity
recognition (NER), which identifies and categorises named entities in textual
input. In order to improve NER, this study investigates a Hindi NER technique
that makes use of Hindi-specific pretrained encoders (MuRIL and XLM-R) and
Generative Models ( Llama-2-7B-chat-hf (Llama2-7B), Llama-2-70B-chat-hf
(Llama2-70B), Llama-3-70B-Instruct (Llama3-70B) and GPT3.5-turbo), and augments
the data with retrieved data from external relevant contexts, notably from
Wikipedia. We have fine-tuned MuRIL, XLM-R and Llama2-7B with and without RA.
However, Llama2-70B, lama3-70B and GPT3.5-turbo are utilised for few-shot NER
generation. Our investigation shows that the mentioned language models (LMs)
with Retrieval Augmentation (RA) outperform baseline methods that don't
incorporate RA in most cases. The macro F1 scores for MuRIL and XLM-R are 0.69
and 0.495, respectively, without RA and increase to 0.70 and 0.71,
respectively, in the presence of RA. Fine-tuned Llama2-7B outperforms Llama2-7B
by a significant margin. On the other hand the generative models which are not
fine-tuned also perform better with augmented data. GPT3.5-turbo adopted RA
well; however, Llama2-70B and llama3-70B did not adopt RA with our retrieval
context. The findings show that RA significantly improves performance,
especially for low-context data. This study adds significant knowledge about
how best to use data augmentation methods and pretrained models to enhance NER
performance, particularly in languages with limited resources.

</details>


### [85] [Learning without training: The implicit dynamics of in-context learning](https://arxiv.org/abs/2507.16003)
*Benoit Dherin,Michael Munn,Hanna Mazzawi,Michael Wunder,Javier Gonzalvo*

Main category: cs.CL

TL;DR: Transformer 块通过隐式修改 MLP 权重，使 LLM 能够进行上下文学习。


<details>
  <summary>Details</summary>
Motivation: 探讨 LLM 在推理时无需更新权重即可学习新模式的机制，并提出 Transformer 块中的隐式权重修改可能是原因。

Method: 通过理论和实验证明，Transformer 块可以通过堆叠自注意力层和 MLP 层来隐式地修改 MLP 层的权重，以适应上下文。

Result: Transformer 块可以隐式地将上下文转换为 MLP 层的低秩权重更新。

Conclusion: LLM 中的 Transformer 块可以通过隐式修改 MLP 层权重来在上下文中学习。

Abstract: One of the most striking features of Large Language Models (LLM) is their
ability to learn in context. Namely at inference time an LLM is able to learn
new patterns without any additional weight update when these patterns are
presented in the form of examples in the prompt, even if these patterns were
not seen during training. The mechanisms through which this can happen are
still largely unknown. In this work, we show that the stacking of a
self-attention layer with an MLP, allows the transformer block to implicitly
modify the weights of the MLP layer according to the context. We argue through
theory and experimentation that this simple mechanism may be the reason why
LLMs can learn in context and not only during training. Specifically, we show
under mild simplifying assumptions how a transformer block implicitly
transforms a context into a low-rank weight-update of the MLP layer.

</details>


### [86] [Help Me Write a Story: Evaluating LLMs' Ability to Generate Writing Feedback](https://arxiv.org/abs/2507.16007)
*Hannah Rashkin,Elizabeth Clark,Fantine Huot,Mirella Lapata*

Main category: cs.CL

TL;DR: LLM在写作反馈方面表现尚可，但未能有效识别主要问题并区分批评与表扬。


<details>
  <summary>Details</summary>
Motivation: 探索LLM为创意写手提供有意义的写作反馈的挑战和局限性。

Method: 提出一个新任务、数据集和评估框架，并构建了一个包含1300个虚构故事的测试集，其中包含故意引入的写作问题。使用常用的LLM在测试集上进行评估，并采用自动和人工评估指标。分析了LLM在提供具体且准确的写作反馈方面的表现，以及它们在识别主要写作问题和决定何时提供批评性或积极性反馈方面的不足。

Result: 目前LLM在许多方面表现出色，能够提供具体且大部分准确的写作反馈。然而，模型在识别故事中的主要写作问题以及正确判断何时提供批评性反馈或积极性反馈方面经常失败。

Conclusion: LLM可以为创意写手提供有意义的写作反馈，但仍有改进空间，尤其是在识别主要写作问题和恰当给出批评性或积极性反馈方面。

Abstract: Can LLMs provide support to creative writers by giving meaningful writing
feedback? In this paper, we explore the challenges and limitations of
model-generated writing feedback by defining a new task, dataset, and
evaluation frameworks. To study model performance in a controlled manner, we
present a novel test set of 1,300 stories that we corrupted to intentionally
introduce writing issues. We study the performance of commonly used LLMs in
this task with both automatic and human evaluation metrics. Our analysis shows
that current models have strong out-of-the-box behavior in many respects --
providing specific and mostly accurate writing feedback. However, models often
fail to identify the biggest writing issue in the story and to correctly decide
when to offer critical vs. positive feedback.

</details>


### [87] [mRAKL: Multilingual Retrieval-Augmented Knowledge Graph Construction for Low-Resourced Languages](https://arxiv.org/abs/2507.16011)
*Hellina Hailu Nigatu,Min Li,Maartje ter Hoeve,Saloni Potdar,Sarah Chasins*

Main category: cs.CL

TL;DR: mRAKL通过将mKGC任务视为QA任务，并利用RAG模型，在的黎尼雅语和阿姆哈拉语等低资源语言上取得了显著的性能提升。


<details>
  <summary>Details</summary>
Motivation: mKGC任务在低资源语言（如的黎尼雅语和阿姆哈拉语）上的挑战，并探索使用高资源语言（如阿拉伯语和英语）进行跨语言迁移。

Method: 将mKGC任务重构为QA任务，使用头实体和关系作为问题，模型预测尾实体作为答案。mRAKL是一个基于检索增强生成（RAG）的系统。

Result: 在包含的黎尼雅语和阿姆哈拉语的实验中，基于RAG的方法比无上下文设置表现更好。在理想检索系统的条件下，mRAKL将的黎尼雅语的准确率提高了4.92%，阿姆哈拉语的准确率提高了8.79%。

Conclusion: mRAKL是一个基于检索增强生成（RAG）的系统，被重新设计用于多语言知识图谱的构建（mKGC），通过将mKGC任务重构为问答（QA）任务来预测尾实体。实验证明，与无上下文设置相比，基于RAG的方法能够提升性能，并且在理想检索系统的加持下，mRAKL在的黎尼雅语和阿姆哈拉语上的准确率分别提高了4.92和8.79个百分点。

Abstract: Knowledge Graphs represent real-world entities and the relationships between
them. Multilingual Knowledge Graph Construction (mKGC) refers to the task of
automatically constructing or predicting missing entities and links for
knowledge graphs in a multilingual setting. In this work, we reformulate the
mKGC task as a Question Answering (QA) task and introduce mRAKL: a
Retrieval-Augmented Generation (RAG) based system to perform mKGC. We achieve
this by using the head entity and linking relation in a question, and having
our model predict the tail entity as an answer. Our experiments focus primarily
on two low-resourced languages: Tigrinya and Amharic. We experiment with using
higher-resourced languages Arabic and English for cross-lingual transfer. With
a BM25 retriever, we find that the RAG-based approach improves performance over
a no-context setting. Further, our ablation studies show that with an idealized
retrieval system, mRAKL improves accuracy by 4.92 and 8.79 percentage points
for Tigrinya and Amharic, respectively.

</details>


### [88] [AutoMeet: a proof-of-concept study of genAI to automate meetings in automotive engineering](https://arxiv.org/abs/2507.16054)
*Simon Baeuerle,Max Radyschevski,Ulrike Pado*

Main category: cs.CL

TL;DR: 该研究探讨了使用生成式人工智能（genAI）来自动化工程部门的会议记录和知识管理流程。研究人员开发了一个端到端的系统，利用genAI转录会议并创建一个可搜索的知识库。在实际工程部门的试点测试表明，虽然技术上可行且用户认为可以大大减少会议工作量，但系统的成功和合乎道德的使用在很大程度上取决于组织层面的考量。


<details>
  <summary>Details</summary>
Motivation: 为了解决大型组织中会议效率低下和文件记录不一致的问题，利用生成式人工智能（如大型语言模型）来处理口语和书面语言，以实现会议记录的自动化和知识管理的改进。

Method: 实现了一个端到端的管道来自动化整个会议文档工作流：使用生成式人工智能录制会议并创建会议记录，然后通过聊天机器人界面使其易于搜索。对一个实际的工程部门进行了测试，并收集了有关伦理和技术方面的调查数据。

Result: 用户认为生成式人工智能可以显著减少会议工作量，技术问题已基本解决，但组织方面对于合乎道德的成功使用至关重要，并指出了其中的机遇和风险。

Conclusion: 虽然技术方面已基本解决，但将生成式人工智能用于会议文档工作流的成功和合乎道德的使用，关键在于组织方面。

Abstract: In large organisations, knowledge is mainly shared in meetings, which takes
up significant amounts of work time. Additionally, frequent in-person meetings
produce inconsistent documentation -- official minutes, personal notes,
presentations may or may not exist. Shared information therefore becomes hard
to retrieve outside of the meeting, necessitating lengthy updates and
high-frequency meeting schedules.
  Generative Artificial Intelligence (genAI) models like Large Language Models
(LLMs) exhibit an impressive performance on spoken and written language
processing. This motivates a practical usage of genAI for knowledge management
in engineering departments: using genAI for transcribing meetings and
integrating heterogeneous additional information sources into an easily usable
format for ad-hoc searches.
  We implement an end-to-end pipeline to automate the entire meeting
documentation workflow in a proof-of-concept state: meetings are recorded and
minutes are created by genAI. These are further made easily searchable through
a chatbot interface. The core of our work is to test this genAI-based software
tooling in a real-world engineering department and collect extensive survey
data on both ethical and technical aspects. Direct feedback from this
real-world setup points out both opportunities and risks: a) users agree that
the effort for meetings could be significantly reduced with the help of genAI
models, b) technical aspects are largely solved already, c) organizational
aspects are crucial for a successful ethical usage of such a system.

</details>


### [89] [Deep Researcher with Test-Time Diffusion](https://arxiv.org/abs/2507.16075)
*Rujun Han,Yanfei Chen,Zoey CuiZhu,Lesly Miculicich,Guan Sun,Yuanjun Bi,Weiming Wen,Hui Wan,Chunfeng Wen,Solène Maître,George Lee,Vishy Tirumalashetty,Emily Xue,Zizhao Zhang,Salem Haykal,Burak Gokturk,Tomas Pfister,Chen-Yu Lee*

Main category: cs.CL

TL;DR: TTD-DR是一个新的框架，通过将研究报告生成视为一种扩散过程来改进LLM研究代理。它使用一个可更新的草稿作为基础，并通过结合检索和自我进化算法来迭代地优化它，从而在需要大量搜索和推理的任务中取得了优于现有方法的成果。


<details>
  <summary>Details</summary>
Motivation: 现有的深度研究代理在生成复杂、长篇研究报告时，性能常常会停滞不前，这是由于使用了通用的测试时间缩放算法。受到人类研究迭代性质的启发，该研究提出了一种新的框架。

Method: TTD-DR将研究报告生成概念化为一种扩散过程，通过一个可更新的、指导研究方向的初步草稿来启动。通过一个动态地在每一步都结合外部信息的检索机制，“去噪”过程迭代地优化草稿。此外，一个应用于代理工作流每个组件的自我进化算法进一步增强了核心过程，确保为扩散过程生成高质量的上下文。

Result: TTD-DR实现了最先进的成果，显著优于现有深度研究代理。

Conclusion: TTD-DR在需要密集搜索和多跳推理的各种基准测试中取得了最先进的结果，显著优于现有的深度研究代理。

Abstract: Deep research agents, powered by Large Language Models (LLMs), are rapidly
advancing; yet, their performance often plateaus when generating complex,
long-form research reports using generic test-time scaling algorithms. Drawing
inspiration from the iterative nature of human research, which involves cycles
of searching, reasoning, and revision, we propose the Test-Time Diffusion Deep
Researcher (TTD-DR). This novel framework conceptualizes research report
generation as a diffusion process. TTD-DR initiates this process with a
preliminary draft, an updatable skeleton that serves as an evolving foundation
to guide the research direction. The draft is then iteratively refined through
a "denoising" process, which is dynamically informed by a retrieval mechanism
that incorporates external information at each step. The core process is
further enhanced by a self-evolutionary algorithm applied to each component of
the agentic workflow, ensuring the generation of high-quality context for the
diffusion process. This draft-centric design makes the report writing process
more timely and coherent while reducing information loss during the iterative
search process. We demonstrate that our TTD-DR achieves state-of-the-art
results on a wide array of benchmarks that require intensive search and
multi-hop reasoning, significantly outperforming existing deep research agents.

</details>


### [90] [The Prompt Makes the Person(a): A Systematic Evaluation of Sociodemographic Persona Prompting for Large Language Models](https://arxiv.org/abs/2507.16076)
*Marlene Lutz,Indira Sen,Georg Ahnert,Elisa Rogers,Markus Strohmaier*

Main category: cs.CL

TL;DR: LLM在模拟边缘化群体时存在困难，但通过优化个人提示词（如采用访谈风格和姓名启动）可以改善其表现，并且小型模型有时优于大型模型。


<details>
  <summary>Details</summary>
Motivation: 现有研究对LLM模拟不同社会人口群体的准确性表示担忧，因为提示词的制定方式会显著影响结果。

Method: 本研究系统地检查了五种开源LLM在15个交叉人口群体中的不同个人提示策略（角色采纳格式和人口统计学启动策略）的影响，分别在开放式和封闭式任务中进行了评估。

Result: 研究发现LLM在模拟边缘化群体（特别是二元性别、西班牙裔和中东身份）方面存在困难。然而，提示词的制定策略（例如，访谈风格和基于姓名的启动）可以改善模拟效果。令人惊讶的是，像OLMo-2-7B这样的小型模型在某些方面的表现优于Llama-3.3-70B这样的大型模型。

Conclusion: 提示词工程中的个人提示策略，特别是基于姓名和访谈风格的提示，可以减少刻板印象并改善LLM在模拟社会人口群体时的对齐度。较小的模型在某些情况下可能比大型模型表现更好。

Abstract: Persona prompting is increasingly used in large language models (LLMs) to
simulate views of various sociodemographic groups. However, how a persona
prompt is formulated can significantly affect outcomes, raising concerns about
the fidelity of such simulations. Using five open-source LLMs, we
systematically examine how different persona prompt strategies, specifically
role adoption formats and demographic priming strategies, influence LLM
simulations across 15 intersectional demographic groups in both open- and
closed-ended tasks. Our findings show that LLMs struggle to simulate
marginalized groups, particularly nonbinary, Hispanic, and Middle Eastern
identities, but that the choice of demographic priming and role adoption
strategy significantly impacts their portrayal. Specifically, we find that
prompting in an interview-style format and name-based priming can help reduce
stereotyping and improve alignment. Surprisingly, smaller models like OLMo-2-7B
outperform larger ones such as Llama-3.3-70B. Our findings offer actionable
guidance for designing sociodemographic persona prompts in LLM-based simulation
studies.

</details>


### [91] [Efficient Compositional Multi-tasking for On-device Large Language Models](https://arxiv.org/abs/2507.16083)
*Ondrej Bohdal,Mete Ozay,Jijoong Moon,Kyeng-Hun Lee,Hyeonmok Ko,Umberto Michieli*

Main category: cs.CL

TL;DR: 研究提出了一种新的“可学习校准”方法和基准测试，以提高大型语言模型在设备上同时处理多个任务（如翻译和总结）的能力。


<details>
  <summary>Details</summary>
Motivation: 探索在实际应用中，尤其是在计算资源受限的设备上，如何使大型语言模型能够同时处理多个任务，解决了现有模型在处理需要并发执行多个任务（如翻译并总结长文本）的组合式任务时的局限性。

Method: 提出了一种名为“可学习校准”（Learnable Calibration）的高效方法，该方法专为计算资源有限的设备端应用设计，兼顾效率和性能。

Result: 构建了一个包含四个实际应用场景的基准测试，以促进对设备端组合式多任务处理的研究，并提出了“可学习校准”方法以应对资源受限的挑战。

Conclusion: 该研究为在资源受限的环境中提升大型语言模型的多任务处理能力奠定了基础，特别是在处理需要同时执行多个任务的组合式任务方面。

Abstract: Adapter parameters provide a mechanism to modify the behavior of machine
learning models and have gained significant popularity in the context of large
language models (LLMs) and generative AI. These parameters can be merged to
support multiple tasks via a process known as task merging. However, prior work
on merging in LLMs, particularly in natural language processing, has been
limited to scenarios where each test example addresses only a single task. In
this paper, we focus on on-device settings and study the problem of text-based
compositional multi-tasking, where each test example involves the simultaneous
execution of multiple tasks. For instance, generating a translated summary of a
long text requires solving both translation and summarization tasks
concurrently. To facilitate research in this setting, we propose a benchmark
comprising four practically relevant compositional tasks. We also present an
efficient method (Learnable Calibration) tailored for on-device applications,
where computational resources are limited, emphasizing the need for solutions
that are both resource-efficient and high-performing. Our contributions lay the
groundwork for advancing the capabilities of LLMs in real-world multi-tasking
scenarios, expanding their applicability to complex, resource-constrained use
cases.

</details>


### [92] [BIDWESH: A Bangla Regional Based Hate Speech Detection Dataset](https://arxiv.org/abs/2507.16183)
*Azizul Hakim Fayaz,MD. Shorif Uddin,Rayhan Uddin Bhuiyan,Zakia Sultana,Md. Samiul Islam,Bidyarthi Paul,Tashreef Muhammad,Shahriar Manzoor*

Main category: cs.CL

TL;DR: 该研究解决了孟加拉语地区方言中的仇恨言论检测问题，创建了一个名为BIDWESH的多方言数据集，包含9,183个实例，覆盖三种主要方言，并进行了详细标注，旨在提高检测准确性和促进公平的内容审核。


<details>
  <summary>Details</summary>
Motivation: 全球范围内，数字平台上的仇恨言论问题日益严重，尤其是在孟加拉国等语言多样化的国家，地区方言在日常交流中扮演着重要角色。然而，现有的仇恨言论检测数据集和系统未能充分解决像Barishal、Noakhali和Chittagong等方言中存在的非正式和文化丰富的表达方式，导致检测能力有限和审核偏见，使得大量有害内容未被有效识别。

Method: 研究人员构建了一个名为BIDWESH的多方言孟加拉语仇恨言论数据集，通过翻译和标注现有的BD-SHS语料库中的9,183个实例，涵盖了Barishal、Noakhali和Chittagong三种主要区域方言。每个实例都经过手动验证，并根据仇恨言论的存在、类型（诽谤、性别、宗教、暴力呼吁）和目标群体（个人、男性、女性、群体）进行了标注，以确保语言和上下文的准确性。

Result: 研究成功构建了一个名为BIDWESH的多方言孟加拉语仇恨言论数据集，包含9,183个经过翻译和标注的实例，覆盖了三种主要区域方言。该数据集在语言和上下文方面具有准确性，为孟加拉语仇恨言论检测提供了丰富、均衡且包容的资源，为开发区分方言的NLP工具奠定了基础，并为低资源语言环境中的公平且符合上下文的内容审核做出了贡献。

Conclusion: 该研究引入了首个多方言孟加拉语仇恨言论数据集BIDWESH，该数据集通过将BD-SHS语料库中的9,183个实例翻译并标注为三种主要区域方言（Barishal、Noakhali和Chittagong）而构建。研究强调了现有系统在处理孟加拉语方言方面的不足，并提出BIDWESH数据集通过手动验证和标注仇恨言论的存在、类型（诽谤、性别、宗教、暴力呼吁）和目标群体（个人、男性、女性、群体），确保了语言和上下文的准确性。该数据集为开发区分方言的NLP工具奠定了基础，并促进了低资源语言环境中公平且符合上下文的内容审核。

Abstract: Hate speech on digital platforms has become a growing concern globally,
especially in linguistically diverse countries like Bangladesh, where regional
dialects play a major role in everyday communication. Despite progress in hate
speech detection for standard Bangla, Existing datasets and systems fail to
address the informal and culturally rich expressions found in dialects such as
Barishal, Noakhali, and Chittagong. This oversight results in limited detection
capability and biased moderation, leaving large sections of harmful content
unaccounted for. To address this gap, this study introduces BIDWESH, the first
multi-dialectal Bangla hate speech dataset, constructed by translating and
annotating 9,183 instances from the BD-SHS corpus into three major regional
dialects. Each entry was manually verified and labeled for hate presence, type
(slander, gender, religion, call to violence), and target group (individual,
male, female, group), ensuring linguistic and contextual accuracy. The
resulting dataset provides a linguistically rich, balanced, and inclusive
resource for advancing hate speech detection in Bangla. BIDWESH lays the
groundwork for the development of dialect-sensitive NLP tools and contributes
significantly to equitable and context-aware content moderation in low-resource
language settings.

</details>


### [93] [Do Large Language Models Have a Planning Theory of Mind? Evidence from MindGames: a Multi-Step Persuasion Task](https://arxiv.org/abs/2507.16196)
*Jared Moore,Ned Cooper,Rasmus Overmark,Beba Cibralic,Nick Haber,Cameron R. Jones*

Main category: cs.CL

TL;DR: LLM在需要理解和影响他人信念以达成自身目标的“规划型心智理论”任务中表现不佳，而人类在此类任务中表现更好，尽管LLM在仅需规划而无需心智推断的任务中表现更优。这表明LLM在社交推理方面与人类存在差距。


<details>
  <summary>Details</summary>
Motivation: 探索LLM是否具备人类的心智理论（ToM）能力，特别是人类ToM在动态规划和策略干预他人心理状态方面的作用，并评估LLM在需要此类能力的任务上的表现。

Method: 提出了一种名为MindGames的新型“规划型心智理论”（PToM）任务，该任务要求智能体通过推断对话者的信念和欲望来劝说其改变行为，并明确评估了心智理论的应用场景。

Result: 在MindGames任务中，人类的表现显著优于LLM（高11%，p=0.006）；在仅需规划但心智状态推断极少（例如，已知对方偏好）的基线任务中，LLM的表现优于人类。

Conclusion: LLM在“规划型心智理论”任务上表现不如人类，这表明LLM在社交推理方面与人类存在显著差距。

Abstract: Recent evidence suggests Large Language Models (LLMs) display Theory of Mind
(ToM) abilities. Most ToM experiments place participants in a spectatorial
role, wherein they predict and interpret other agents' behavior. However, human
ToM also contributes to dynamically planning action and strategically
intervening on others' mental states. We present MindGames: a novel `planning
theory of mind' (PToM) task which requires agents to infer an interlocutor's
beliefs and desires to persuade them to alter their behavior. Unlike previous
evaluations, we explicitly evaluate use cases of ToM. We find that humans
significantly outperform o1-preview (an LLM) at our PToM task (11% higher;
$p=0.006$). We hypothesize this is because humans have an implicit causal model
of other agents (e.g., they know, as our task requires, to ask about people's
preferences). In contrast, o1-preview outperforms humans in a baseline
condition which requires a similar amount of planning but minimal mental state
inferences (e.g., o1-preview is better than humans at planning when already
given someone's preferences). These results suggest a significant gap between
human-like social reasoning and LLM abilities.

</details>


### [94] [WakenLLM: A Fine-Grained Benchmark for Evaluating LLM Reasoning Potential and Reasoning Process Stability](https://arxiv.org/abs/2507.16199)
*Zipeng Ling,Yuehao Tang,Shuliang Liu,Junqi Yang,Shenghong Fu,Yao Wan,Kejia Huang,Zhichao Hou,Xuming Hu*

Main category: cs.CL

TL;DR: 大型语言模型（LLMs）常输出“未知”标签，但现有评估忽略了“未知”产生的原因。本文提出“模糊感知”概念，并开发新框架以区分模型无能和真实不确定性，旨在更准确地评估LLM推理能力。


<details>
  <summary>Details</summary>
Motivation: 解决大型语言模型（LLMs）频繁输出“未知”标签的问题，并区分‘未知’响应是由于输入本身不确定还是模型无法解决。现有评估大多只关注‘诚实性’，忽略了“未知”产生的原因。

Method: 提出一个量化模型无能导致“未知”响应比例的框架，并测试引导性刺激是否能将这些响应转化为正确（“已知”）或内在不确定性结果。

Result: 在不同的LLM上获得推理任务的理论准确性，并应用不同方法测试模型在基线框架下能否达到该准确性。

Conclusion: 通过区分不确定性的来源，我们的方法为理解语言模型的推理限制及其改进潜力提供了更清晰的图景。本研究旨在探索大型语言模型的真实推理能力，并为解决‘模糊感知’现象提供新视角。

Abstract: Large Language Models (LLMs) frequently output the label \emph{Unknown}, yet
current evaluations focus almost exclusively on whether such answers are
\emph{honest} rather than why they arise. This blurs two distinct cases: (i) an
input that is genuinely indeterminate and (ii) a solvable problem that the
model fails to resolve. We call this phenomenon \emph{Vague Perception}. And
thus we introduce a framework that quantifies the proportion of \emph{Unknown}
responses attributable to model incapacity and tests whether guided stimulation
can convert them into either correct (\emph{Known}) or intrinsically
indeterminate outcomes. By separating these sources of uncertainty, our method
provides a clearer picture of LLM reasoning limits and their potential for
improvement. As we get a theoretical accuracy of reasoning task on different
LLMs, we apply different methods to test whether the model can reach the
accuracy given a baseline framework. Our work is meaningful in exploring the
true reasoning ability of LLMs and providing a new perspective on solving the
\emph{Vague Perception} phenomenon.

</details>


### [95] [Towards Compute-Optimal Many-Shot In-Context Learning](https://arxiv.org/abs/2507.16217)
*Shahriar Golchin,Yanfei Chen,Rujun Han,Manan Gandhi,Tianli Yu,Swaroop Mishra,Mihai Surdeanu,Rishabh Agarwal,Chen-Yu Lee,Tomas Pfister*

Main category: cs.CL

TL;DR: 本文提出两种简单高效的策略来选择多轮次语境学习（ICL）中的示范数据，以优化性能并降低成本，实验证明其效果优于随机选择，并能与最佳方法媲美。


<details>
  <summary>Details</summary>
Motivation: 在多轮次语境学习（ICL）中，通常会因为推理成本高、缓存和复用计算的好处以及与其他策略相似的性能而选择固定数量的随机数据。然而，本文旨在提出一种能够提高性能且计算开销最小化的数据选择策略。

Method: 文章提出了两种简单的数据选择策略：1. 结合少量基于与测试样本相似度选择的数据和大量缓存的随机数据。2. 在第一种策略基础上，用k-均值聚类得到的测试样本表示的质心来替代随机数据。

Result: 在Gemini Pro和Flash上的实验表明，本文提出的策略优于随机选择，并且在多项数据集上表现与现有最佳方法相当或更优，同时支持缓存并显著降低了推理成本。

Conclusion: 本文提出的两种数据选择策略在多轮次语境学习中能够持续的优于随机选择，并且在支持缓存和降低推理成本（可达一个数量级）的同时，达到或超过了性能最佳的选择方法。此外，通过调整不同标准选择的数据比例，可以在性能和推理成本之间取得平衡。

Abstract: Long-context large language models (LLMs) are able to process inputs
containing up to several million tokens. In the scope of in-context learning
(ICL), this translates into using hundreds/thousands of demonstrations in the
input prompt, enabling many-shot ICL. In practice, a fixed set of
demonstrations is often selected at random in many-shot settings due to (1)
high inference costs, (2) the benefits of caching and reusing computations, and
(3) the similar performance offered by this strategy compared to others when
scaled. In this work, we propose two straightforward strategies for
demonstration selection in many-shot ICL that improve performance with minimal
computational overhead. Our first method combines a small number of
demonstrations, selected based on their similarity to each test sample, with a
disproportionately larger set of random demonstrations that are cached. The
second strategy improves the first by replacing random demonstrations with
those selected using centroids derived from test sample representations via
k-means clustering. Our experiments with Gemini Pro and Flash across several
datasets indicate that our strategies consistently outperform random selection
and surpass or match the most performant selection approach while supporting
caching and reducing inference cost by up to an order of magnitude. We also
show that adjusting the proportion of demonstrations selected based on
different criteria can balance performance and inference cost in many-shot ICL.

</details>


### [96] [FinResearchBench: A Logic Tree based Agent-as-a-Judge Evaluation Framework for Financial Research Agents](https://arxiv.org/abs/2507.16248)
*Run Sun,Zuo Bai,Wentao Zhang,Yuxiang Zhang,Li Zhao,Shan Sun,Zhengwen Qiu*

Main category: cs.CL

TL;DR: A new benchmark, FinResearchBench, evaluates AI agents in financial research using a logic tree-based Agent-as-a-Judge system covering 7 task types and 70 financial questions.


<details>
  <summary>Details</summary>
Motivation: To address the lack of systematic and automatic evaluation frameworks and benchmarks for deep research agents, especially in the complex and subtle domain of financial research.

Method: Agent-as-a-Judge framework using a logic tree approach to extract the logic tree of the research outcome for evaluation.

Result: FinResearchBench provides a comprehensive, reliable, and robust evaluation of financial research agents across 7 key task types, covering 70 typical financial research questions.

Conclusion: The paper proposes FinResearchBench, a novel Agent-as-a-Judge framework for evaluating AI agents in financial research. It addresses the lack of systematic evaluation frameworks for deep research agents, particularly in the complex domain of finance. The framework utilizes a logic tree approach to assess agent capabilities across seven key financial research task types, covering 70 typical financial research questions.

Abstract: Recently, AI agents are rapidly evolving in intelligence and widely used in
professional research applications, such as STEM, software development,
finance, etc. Among these AI agents, deep research agent is a key category as
it can perform long-horizon tasks and solve problems of greater complexity.
However, there are few evaluation frameworks and benchmarks that systematically
and automatically investigate the capabilities of these research agents.
Furthermore, financial research problems have distinct complexity and subtlety.
To fill in the gap, we propose FinResearchBench, which is a logic tree based
Agent-as-a-Judge and targets specifically for the financial research agents. It
provides a comprehensive and automatic assessment of the research agents across
7 key types of tasks in the financial research domain. The contributions of
this work are two-folded: (1) the first and innovative Agent-as-a-Judge system
that extracts the logic tree of the research outcome and uses it as the
intermediate information to present a comprehensive, reliable and robust
evaluation; (2) finance oriented that it covers 70 typical financial research
questions, spreading across 7 frequently encountered types of tasks in the
domain.

</details>


### [97] [Efficient RL for optimizing conversation level outcomes with an LLM-based tutor](https://arxiv.org/abs/2507.16252)
*Hyunji Nam,Omer Gottesman,Amy Zhang,Dean Foster,Emma Brunskill,Lyle Ungar*

Main category: cs.CL

TL;DR: 提出一种新的LLM辅导方法，通过学生状态表示和长期优化策略，改进了多轮对话中的辅导效果。


<details>
  <summary>Details</summary>
Motivation: 现有的基于人类反馈的强化学习（RLHF）框架在优化LLM响应时，通常只关注即时轮次的人类偏好，这在多轮对话（如在线数学辅导）中效果不佳。本文旨在改进LLM辅导的效果，使其更好地引导学生解决问题。

Method: 通过引入低维度的学生潜在状态表示来表示对话历史，并基于该潜在状态优化一个长期策略，以确定高层级的辅导动作。

Result: 实验结果表明，该方法在LLM模拟辅导任务中，相比于现有方法，能够带来更好的长期效果。

Conclusion: 该方法在LLM模拟辅导任务中，相比于直接生成辅导语的端到端训练方法，能够更好地实现长期目标。

Abstract: Large language models (LLMs) built on existing reinforcement learning with
human feedback (RLHF) frameworks typically optimize responses based on
immediate turn-level human preferences. However, this approach falls short in
multi-turn dialogue settings, such as online math tutoring. We propose a method
to enhance LLM-based tutors by representing the dialogue history with a
lower-dimensional latent state representation of a student and optimizing a
long-term policy to determine high-level actions based on the latent state. The
goal is to better align the tutor's behavior with the long-term objective of
guiding the student towards solving a target math problem on their own. Our
model is lightweight, requiring less computational resources than prior work of
training the tutor policy end-to-end to directly output the tutor's next
utterance. Our experiment results demonstrate that these modifications lead to
improved long-term outcomes compared to prompting in LLM-simulated tutoring
tasks.

</details>


### [98] [iShumei-Chinchunmei at SemEval-2025 Task 4: A balanced forgetting and retention multi-task framework using effective unlearning loss](https://arxiv.org/abs/2507.16263)
*Yujian Sun,Tian Li*

Main category: cs.CL

TL;DR: 提出了一种名为 Effective Unlearning Loss 的新方法，并结合其他技术来改进大型语言模型（LLM）的机器学习遗忘过程，在竞赛中获得第五名。


<details>
  <summary>Details</summary>
Motivation: 随着大型语言模型（LLM）的广泛采用，如何有效地从 LLM 中擦除预训练期间记忆的违规数据（即机器学习遗忘）已成为一个日益受到关注的挑战。本研究旨在解决在有限的计算资源下，从 LLM 中高效擦除敏感信息的难题。

Method: 提出了一种名为 Effective Unlearning Loss 的可控遗忘损失，并将其与多种技术相结合，以实现更高效和可控的机器学习遗忘。

Result: 所提出的系统在 SemEval 2025 Task 4 竞赛的排行榜上名列第五，表明其在机器学习遗忘方面的有效性和潜力。

Conclusion: 该研究提出了一种更具可控性的遗忘损失（Effective Unlearning Loss），并探索了其与多种技术集成以实现更有效和可控的机器学习遗忘。所提出的方法在 SemEval 2025 Task 4 竞赛中取得了第五名的成绩。

Abstract: As the Large Language Model (LLM) gains widespread adoption, increasing
attention has been given to the challenge of making LLM forget non-compliant
data memorized during its pre-training. Machine Unlearning focuses on
efficiently erasing sensitive information from LLM under limited computational
resources. To advance research in this area, SemEval 2025 Task 4: "Unlearning
Sensitive Content from Large Language Models" introduces three unlearning
datasets and establishes a benchmark by evaluating both forgetting
effectiveness and the preservation of standard capabilities. In this work, we
propose a more controllable forgetting loss, Effective Unlearning Loss, and
explore its integration with various techniques to achieve more efficient and
controlled unlearning. Our system ultimately ranked 5th on the competition
leaderboard.

</details>


### [99] [Beyond Isolated Dots: Benchmarking Structured Table Construction as Deep Knowledge Extraction](https://arxiv.org/abs/2507.16271)
*Tianyun Zhong,Guozhao Mo,Yanjiang Liu,Yihan Chen,Lingdi Kong,Xuanang Chen,Yaojie Lu,Hongyu Lin,Ben He,Le Sun*

Main category: cs.CL

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: With the emergence of large language models (LLMs), there is an expectation
that LLMs can effectively extract explicit information from complex real-world
documents (e.g., papers, reports). However, most LLMs generate paragraph-style
answers that are chaotic, disorganized, and untraceable. To bridge this gap, we
introduce the Arranged and Organized Extraction Benchmark (AOE), a new
bilingual benchmark with data and documents of varying lengths designed to
systematically evaluate the ability of LLMs to comprehend fragmented documents
and reconstruct isolated information into one organized table. Unlike
conventional text-to-table tasks, which rely on fixed schema and narrow task
domains, AOE includes 11 carefully crafted tasks across three diverse domains,
requiring models to generate context-specific schema tailored to varied input
queries. In the experiment, we evaluated both open-source and closed-source
state-of-the-art LLMs. The results show that even the most advanced models
struggled significantly. The benchmark is available at
https://huggingface.co/datasets/tianyumyum/AOE.

</details>


### [100] [Language Detection by Means of the Minkowski Norm: Identification Through Character Bigrams and Frequency Analysis](https://arxiv.org/abs/2507.16284)
*Paul-Andrei Pogăcean,Sanda-Maria Avram*

Main category: cs.CL

TL;DR: Non-AI language identification using frequency analysis of monograms and bigrams remains effective, achieving high accuracy on diverse texts and offering a scalable alternative to AI models.


<details>
  <summary>Details</summary>
Motivation: The debate surrounding language identification has gained renewed attention in recent years, especially with the rapid evolution of AI-powered language models. However, the non-AI-based approaches to language identification have been overshadowed.

Method: This research explores a mathematical implementation of an algorithm for language determinism by leveraging monograms and bigrams frequency rankings derived from established linguistic research. The datasets used comprise texts varying in length, historical period, and genre, including short stories, fairy tales, and poems.

Result: Despite variations in text length, historical period, and genre, the method achieves over 80% accuracy on texts shorter than 150 characters and reaches 100% accuracy for longer texts and older writings.

Conclusion: The study demonstrates that classical frequency-based approaches, utilizing monograms and bigrams, remain effective and scalable alternatives to AI-driven models for language detection, achieving high accuracy across various text lengths and historical periods.

Abstract: The debate surrounding language identification has gained renewed attention
in recent years, especially with the rapid evolution of AI-powered language
models. However, the non-AI-based approaches to language identification have
been overshadowed. This research explores a mathematical implementation of an
algorithm for language determinism by leveraging monograms and bigrams
frequency rankings derived from established linguistic research. The datasets
used comprise texts varying in length, historical period, and genre, including
short stories, fairy tales, and poems. Despite these variations, the method
achieves over 80\% accuracy on texts shorter than 150 characters and reaches
100\% accuracy for longer texts and older writings. These results demonstrate
that classical frequency-based approaches remain effective and scalable
alternatives to AI-driven models for language detection.

</details>


### [101] [SpeLLM: Character-Level Multi-Head Decoding](https://arxiv.org/abs/2507.16323)
*Amit Ben-Artzy,Roy Schwartz*

Main category: cs.CL

TL;DR: SpeLLM通过多输出头预测字符级字符串，解耦了输入输出词汇量，降低了LLM运行成本，并有望支持更多语言。


<details>
  <summary>Details</summary>
Motivation: 为了减少LLM的输入序列长度并缓解注意力机制的二次成本，通常需要扩展LLM的词汇量。然而，当前LLM架构的输出投影层随着词汇量的线性增长，使得大规模扩展不切实际，成为一个关键瓶颈。

Method: SpeLLM通过解耦输入和输出词汇量，利用多个线性输出头同时预测单个字符，从而允许模型使用更小的、独立的线性头来表示更大的输出空间。文章还提出了一种自蒸馏方法，用于将标准LLM转换为SpeLLM。

Result: 在四个预训练LLM上的实验表明，SpeLLM变体在下游任务上实现了具有竞争力的性能，同时平均运行时减少了5.1%。

Conclusion: SpeLLM通过解耦输入和输出来预测字符级字符串，使用多个输出头，从而实现对LLM词汇量的扩展，并在不显著影响模型性能的情况下降低了运行成本。该方法为降低LLM成本提供了新途径，并有望增加对代表性不足的语言和领域支持。

Abstract: Scaling LLM vocabulary is often used to reduce input sequence length and
alleviate attention's quadratic cost. Yet, current LLM architectures impose a
critical bottleneck to this procedure: the output projection layer scales
linearly with vocabulary size, rendering substantial expansion impractical. We
propose SpeLLM, a method that decouples input and output vocabularies by
predicting character-level strings through multiple output heads. In SpeLLM,
each of the $k$ linear heads predicts a single character simultaneously,
enabling the model to represent a much larger output space using smaller,
independent linear heads. We present a self-distillation approach for
converting a standard LLM to a SpeLLM. Our experiments with four pre-trained
LLMs show their SpeLLM variants achieve competitive performance on downstream
tasks while reducing runtime by 5.1% on average across models. Our approach
provides a potential avenue for reducing LLM costs, while increasing support
for underrepresented languages and domains.

</details>


### [102] [Re:Form -- Reducing Human Priors in Scalable Formal Software Verification with RL in LLMs: A Preliminary Study on Dafny](https://arxiv.org/abs/2507.16331)
*Chuanhao Yan,Fengdi Che,Xuhan Huang,Xu Xu,Xin Li,Yizhi Li,Xingwei Qu,Jingzhe Shi,Zhuangzhuang He,Chenghua Lin,Yaodong Yang,Binhang Yuan,Hang Zhao,Yu Qiao,Bowen Zhou,Jie Fu*

Main category: cs.CL

TL;DR: 该研究提出了一种利用Dafny形式语言和RL来改进LLM在形式软件验证中的表现的方法，减少了对人工监督的需求，并在DafnyComp基准测试中取得了显著成果。


<details>
  <summary>Details</summary>
Motivation: 现有的基于非正式语言的LLM在验证方面存在可靠性和可扩展性挑战，而形式语言推理提供了一种潜在的解决方案，但需要解决人工先验成本过高的问题。

Method: 该研究探索了如何利用形式语言（Dafny）来解决LLM在验证方面的挑战，通过自动数据整理和RL设计，并引入了DafnyComp基准测试来评估模型性能。

Result: 研究表明，通过SFT阶段，即使是小型模型也能生成语法正确且可验证的Dafny代码，超越了专有模型；RL进一步提高了泛化能力，并在DafnyComp基准测试中表现优于所有强基线。

Conclusion: 通过引入自动和可扩展的数据整理管道以及与形式语言验证器集成的RL设计，该研究成功地减少了对人工先验的依赖，并实现了在DafnyComp基准测试中超越强基线。

Abstract: Existing informal language-based (e.g., human language) Large Language Models
(LLMs) trained with Reinforcement Learning (RL) face a significant challenge:
their verification processes, which provide crucial training signals, are
neither reliable nor scalable. In fact, the prevalent large proprietary models
could hardly generate verifiable programs. A promising yet largely uncharted
alternative is formal language-based reasoning. Grounding LLMs in rigorous
formal systems where generative models operate in formal language spaces (e.g.,
Dafny) enables the automatic and mathematically provable verification of their
reasoning processes and outcomes. This capability is pivotal for achieving
large-scale, reliable formal software verification. It is a common practice to
employ human-annotated chain-of-thought and other human priors to induce the
reasoning and coding capabilities of LLMs. Unfortunately, it becomes
unacceptably all-consuming to provide such priors for supervising complex
programming tasks. In this work, we systematically explore ways to reduce human
priors with the formal language, Dafny, as the main environment for our pilot
study. Our pipeline mainly relies on introducing an automatic and scalable data
curation pipeline, and careful RL designs integrated with feedback from the
formal language verifier. We introduce DafnyComp, a benchmark of compositional
formal programs with auto-formalized specifications for specification
reasoning. Our supervised fine-tuning (SFT) stage enables even small models
(e.g., 0.5B) to generate syntactically valid and verifiable Dafny code,
surpassing proprietary models. RL with regularization further improves
performance, achieving stronger generalization to out-of-domain tasks and
outperforming all strong baselines on the challenging DafnyComp benchmark.

</details>


### [103] [GG-BBQ: German Gender Bias Benchmark for Question Answering](https://arxiv.org/abs/2507.16410)
*Shalaka Satheesh,Katrin Klug,Katharina Beckh,Héctor Allende-Cid,Sebastian Houben,Teena Hassan*

Main category: cs.CL

TL;DR: 本研究创建了一个德语的性别偏见评估数据集，并发现所有被评估的德语大型语言模型都存在性别偏见。


<details>
  <summary>Details</summary>
Motivation: 在自然语言处理（NLP）领域，公平性评估与偏见评估和减少相关危害有关。本研究旨在评估德语大型语言模型（LLMs）中的性别偏见。

Method: 使用 Parrish 等人（2022）的性别偏见问题回答基准（Bias Benchmark for Question Answering）的德语版本，对德语大型语言模型（LLMs）进行性别偏见评估。通过手动审查和修正机器翻译的模板（包括与性别认同相关的词语以及用名字替换性别词语的子集）来创建评估数据集，并报告了模型的准确性和偏见得分。

Result: 评估结果表明，所有被评估的德语语言模型在性别偏见评估基准上都表现出偏见，这些偏见既符合也违背了现有的社会刻板印象。

Conclusion: 所有评估的德语语言模型都表现出性别偏见，同时符合和违背现有的社会刻板印象。

Abstract: Within the context of Natural Language Processing (NLP), fairness evaluation
is often associated with the assessment of bias and reduction of associated
harm. In this regard, the evaluation is usually carried out by using a
benchmark dataset, for a task such as Question Answering, created for the
measurement of bias in the model's predictions along various dimensions,
including gender identity. In our work, we evaluate gender bias in German Large
Language Models (LLMs) using the Bias Benchmark for Question Answering by
Parrish et al. (2022) as a reference. Specifically, the templates in the gender
identity subset of this English dataset were machine translated into German.
The errors in the machine translated templates were then manually reviewed and
corrected with the help of a language expert. We find that manual revision of
the translation is crucial when creating datasets for gender bias evaluation
because of the limitations of machine translation from English to a language
such as German with grammatical gender. Our final dataset is comprised of two
subsets: Subset-I, which consists of group terms related to gender identity,
and Subset-II, where group terms are replaced with proper names. We evaluate
several LLMs used for German NLP on this newly created dataset and report the
accuracy and bias scores. The results show that all models exhibit bias, both
along and against existing social stereotypes.

</details>


### [104] [PromptAL: Sample-Aware Dynamic Soft Prompts for Few-Shot Active Learning](https://arxiv.org/abs/2507.16424)
*Hui Xiang,Jinqiao Shi,Ting Zhang,Xiaojie Zhao,Yong Liu,Yong Ma*

Main category: cs.CL

TL;DR: PromptAL 是一种用于少样本主动学习的混合框架，它利用无标签数据和样本感知动态软提示来优化决策边界，并结合不确定性与多样性来选择信息量大的样本。


<details>
  <summary>Details</summary>
Motivation: 现有的主动学习方法在少样本场景下，由于经验分布与目标分布存在显著差异，导致决策边界偏移，选择的样本不能充分代表目标分布。PromptAL 旨在解决这个问题，通过利用无标签数据来改进经验分布，以更好地对齐目标分布，从而优化决策边界。

Method: PromptAL 提出了一种混合主动学习框架，该框架利用无标签数据构建样本感知动态软提示，以调整模型的预测分布和决策边界。然后，基于调整后的决策边界，它整合了不确定性估计以及全局和局部多样性，以选择更能准确代表目标分布的高质量样本。

Result: PromptAL 实现了优于九个基线方法的性能。

Conclusion: PromptAL 在六个域内和三个域外数据集上的实验结果表明，其性能优于九个基线方法，并且代码公开可用。

Abstract: Active learning (AL) aims to optimize model training and reduce annotation
costs by selecting the most informative samples for labeling. Typically, AL
methods rely on the empirical distribution of labeled data to define the
decision boundary and perform uncertainty or diversity estimation, subsequently
identifying potential high-quality samples. In few-shot scenarios, the
empirical distribution often diverges significantly from the target
distribution, causing the decision boundary to shift away from its optimal
position. However, existing methods overlook the role of unlabeled samples in
enhancing the empirical distribution to better align with the target
distribution, resulting in a suboptimal decision boundary and the selection of
samples that inadequately represent the target distribution. To address this,
we propose a hybrid AL framework, termed \textbf{PromptAL} (Sample-Aware
Dynamic Soft \textbf{Prompts} for Few-Shot \textbf{A}ctive \textbf{L}earning).
This framework accounts for the contribution of each unlabeled data point in
aligning the current empirical distribution with the target distribution,
thereby optimizing the decision boundary. Specifically, PromptAL first
leverages unlabeled data to construct sample-aware dynamic soft prompts that
adjust the model's predictive distribution and decision boundary. Subsequently,
based on the adjusted decision boundary, it integrates uncertainty estimation
with both global and local diversity to select high-quality samples that more
accurately represent the target distribution. Experimental results on six
in-domain and three out-of-domain datasets show that PromptAL achieves superior
performance over nine baselines. Our codebase is openly accessible.

</details>


### [105] [Dutch CrowS-Pairs: Adapting a Challenge Dataset for Measuring Social Biases in Language Models for Dutch](https://arxiv.org/abs/2507.16442)
*Elza Strazda,Gerasimos Spanakis*

Main category: cs.CL

TL;DR: 该研究创建了荷兰语Crow-Pairs数据集，评估了多种语言模型在荷兰语、英语和法语中的偏见。结果显示英语模型偏见最严重，荷兰语模型偏见最轻，且模型角色会影响偏见程度。


<details>
  <summary>Details</summary>
Motivation: 鉴于语言模型日益增长的普及性和广泛应用，确保语言模型的安全和公平性至关重要。虽然已有研究关注测量语言模型中的偏见，但大多数研究仅限于英语，因此需要扩展到其他语言，特别是荷兰语。

Method: 创建了一个包含1463个句子对的荷兰语Crow-Pairs数据集，涵盖了9个类别的偏见，如性取向、性别和残疾。利用该数据集和现有英语及法语数据集，评估了多种语言模型（包括BERT、RoBERTa、BERTje、RobBERT、多语言BERT、GEITje和Mistral-7B）的偏见。

Result: 荷兰语Crow-Pairs数据集包含了1463个句子对，涉及9个偏见类别。评估结果显示，BERTje、RobBERT、多语言BERT、GEITje和Mistral-7B等语言模型在荷兰语中表现出明显的偏见。与英语和法语模型相比，英语模型偏见最多，荷兰语模型偏见最少。为模型分配角色会影响其偏见水平。

Conclusion: 研究结果表明，语言模型在不同语言和语境下表现出显著的偏见，文化和语言因素在塑造模型偏见方面起着重要作用。荷兰语模型偏见程度最低，而英语模型偏见程度最高。此外，为语言模型分配特定角色会改变其偏见水平。

Abstract: Warning: This paper contains explicit statements of offensive stereotypes
which might be upsetting.
  Language models are prone to exhibiting biases, further amplifying unfair and
harmful stereotypes. Given the fast-growing popularity and wide application of
these models, it is necessary to ensure safe and fair language models. As of
recent considerable attention has been paid to measuring bias in language
models, yet the majority of studies have focused only on English language. A
Dutch version of the US-specific CrowS-Pairs dataset for measuring bias in
Dutch language models is introduced. The resulting dataset consists of 1463
sentence pairs that cover bias in 9 categories, such as Sexual orientation,
Gender and Disability. The sentence pairs are composed of contrasting
sentences, where one of the sentences concerns disadvantaged groups and the
other advantaged groups. Using the Dutch CrowS-Pairs dataset, we show that
various language models, BERTje, RobBERT, multilingual BERT, GEITje and
Mistral-7B exhibit substantial bias across the various bias categories. Using
the English and French versions of the CrowS-Pairs dataset, bias was evaluated
in English (BERT and RoBERTa) and French (FlauBERT and CamemBERT) language
models, and it was shown that English models exhibit the most bias, whereas
Dutch models the least amount of bias. Additionally, results also indicate that
assigning a persona to a language model changes the level of bias it exhibits.
These findings highlight the variability of bias across languages and contexts,
suggesting that cultural and linguistic factors play a significant role in
shaping model biases.

</details>


### [106] [Towards Enforcing Company Policy Adherence in Agentic Workflows](https://arxiv.org/abs/2507.16459)
*Naama Zwerdling,David Boaz,Ella Rabinovich,Guy Uziel,David Amid,Ateret Anaby-Tavor*

Main category: cs.CL

TL;DR: A new framework enforces business policies in LLM agents by compiling policies into verifiable code that checks compliance before each action, showing promise in early tests.


<details>
  <summary>Details</summary>
Motivation: LLM agents struggle to reliably follow complex company policies, necessitating a more robust solution for business process automation.

Method: The method involves a two-phase approach: an offline buildtime stage that compiles policy documents into verifiable guard code associated with tool use, and a runtime integration where these guards ensure compliance before each agent action.

Result: Encouraging preliminary results in policy enforcement on the Tau-bench Airlines domain.

Conclusion: The study introduces a deterministic, transparent, and modular framework for enforcing business policy adherence in LLM agentic workflows. Preliminary results on the Tau-bench Airlines domain show encouraging policy enforcement, with key challenges for real-world deployment outlined.

Abstract: Large Language Model (LLM) agents hold promise for a flexible and scalable
alternative to traditional business process automation, but struggle to
reliably follow complex company policies. In this study we introduce a
deterministic, transparent, and modular framework for enforcing business policy
adherence in agentic workflows. Our method operates in two phases: (1) an
offline buildtime stage that compiles policy documents into verifiable guard
code associated with tool use, and (2) a runtime integration where these guards
ensure compliance before each agent action. We demonstrate our approach on the
challenging $\tau$-bench Airlines domain, showing encouraging preliminary
results in policy enforcement, and further outline key challenges for
real-world deployments.

</details>


### [107] [ICR Probe: Tracking Hidden State Dynamics for Reliable Hallucination Detection in LLMs](https://arxiv.org/abs/2507.16488)
*Zhenliang Zhang,Xinyu Hu,Huixuan Zhang,Junzhe Zhang,Xiaojun Wan*

Main category: cs.CL

TL;DR: ICR Probe是一种新的LLM幻觉检测方法，通过分析隐藏状态的动态演变来提高准确性并减少参数。


<details>
  <summary>Details</summary>
Motivation: 现有LLM幻觉检测方法主要关注静态和孤立的表示，忽略了它们在跨层动态演变的过程，这限制了其有效性。

Method: 提出了一种名为ICR评分（信息对残差流的贡献）的新指标，该指标量化模块对隐藏状态更新的贡献。基于此，提出了一种名为ICR Probe的幻觉检测方法，该方法捕捉隐藏状态的跨层演变。

Result: ICR评分被证明在区分幻觉方面是有效和可靠的。ICR Probe方法取得了优越的性能，参数更少，并且通过消融研究和案例分析提供了更深入的机制见解，提高了可解释性。

Conclusion: LLM的幻觉检测方法ICR Probe通过捕捉跨层隐藏状态的演变，实现了优于现有方法的性能，并且参数更少，同时具有更好的可解释性。

Abstract: Large language models (LLMs) excel at various natural language processing
tasks, but their tendency to generate hallucinations undermines their
reliability. Existing hallucination detection methods leveraging hidden states
predominantly focus on static and isolated representations, overlooking their
dynamic evolution across layers, which limits efficacy. To address this
limitation, we shift the focus to the hidden state update process and introduce
a novel metric, the ICR Score (Information Contribution to Residual Stream),
which quantifies the contribution of modules to the hidden states' update. We
empirically validate that the ICR Score is effective and reliable in
distinguishing hallucinations. Building on these insights, we propose a
hallucination detection method, the ICR Probe, which captures the cross-layer
evolution of hidden states. Experimental results show that the ICR Probe
achieves superior performance with significantly fewer parameters. Furthermore,
ablation studies and case analyses offer deeper insights into the underlying
mechanism of this method, improving its interpretability.

</details>


### [108] [Combining Language and Topic Models for Hierarchical Text Classification](https://arxiv.org/abs/2507.16490)
*Jaco du Toit,Marcel Dunaiski*

Main category: cs.CL

TL;DR: "A hierarchical text classification approach combining PLM and topic model features was tested. Results show that including topic model features generally harms performance, challenging the assumption that such combinations are always beneficial."


<details>
  <summary>Details</summary>
Motivation: "To determine whether the combination of features extracted from a PLM and a topic model is beneficial to Hierarchical Text Classification (HTC) performance in general."

Method: "The approach uses a PLM and a topic model to extract features from text documents. These features are then passed through separate convolutional layers, and their outputs are combined. Finally, a label-wise attention mechanism obtains label-specific document representations by weighing the most important features for each class separately."

Result: "Using features extracted from the topic model generally decreases classification performance compared to only using features obtained by the PLM."

Conclusion: "In contrast to previous work, this shows that the incorporation of features extracted from topic models for text classification tasks should not be assumed beneficial."

Abstract: Hierarchical text classification (HTC) is a natural language processing task
which has the objective of categorising text documents into a set of classes
from a predefined structured class hierarchy. Recent HTC approaches use various
techniques to incorporate the hierarchical class structure information with the
natural language understanding capabilities of pre-trained language models
(PLMs) to improve classification performance. Furthermore, using topic models
along with PLMs to extract features from text documents has been shown to be an
effective approach for multi-label text classification tasks. The rationale
behind the combination of these feature extractor models is that the PLM
captures the finer-grained contextual and semantic information while the topic
model obtains high-level representations which consider the corpus of documents
as a whole. In this paper, we use a HTC approach which uses a PLM and a topic
model to extract features from text documents which are used to train a
classification model. Our objective is to determine whether the combination of
the features extracted from the two models is beneficial to HTC performance in
general. In our approach, the extracted features are passed through separate
convolutional layers whose outputs are combined and passed to a label-wise
attention mechanisms which obtains label-specific document representations by
weighing the most important features for each class separately. We perform
comprehensive experiments on three HTC benchmark datasets and show that using
the features extracted from the topic model generally decreases classification
performance compared to only using the features obtained by the PLM. In
contrast to previous work, this shows that the incorporation of features
extracted from topic models for text classification tasks should not be assumed
beneficial.

</details>


### [109] [The Ever-Evolving Science Exam](https://arxiv.org/abs/2507.16514)
*Junying Wang,Zicheng Zhang,Yijin Guo,Farong Wen,Ye Shen,Yingji Liang,Yalun Wu,Wenzhe Li,Chunyi Li,Zijian Chen,Qi Jia,Guangtao Zhai*

Main category: cs.CL

TL;DR: EESE是一个新的动态科学基准，旨在解决现有基准的数据泄露和效率问题，能够可靠地评估基础模型在科学领域的理解能力。


<details>
  <summary>Details</summary>
Motivation: 为了解决现有科学基准面临的数据泄露风险和评估效率低下等挑战，需要一种新的评估方法。

Method: 提出了一种名为“永恒演进科学考试”（EESE）的动态基准，包括一个包含超过10万个科学实例（问题-答案对）的非公开“EESE-Pool”，涵盖5个学科和500多个子领域，并设计了一个定期更新的500个实例的子集“EESE”，以实现防泄漏、低开销的评估。

Result: 在32个开源和闭源模型上进行的实验表明，EESE能够有效地区分模型在科学领域和认知维度上的优势和劣势。

Conclusion: EESE提供了一个健壮、可扩展且前向兼容的科学基准设计解决方案，能够真实衡量基础模型处理科学问题的能力。

Abstract: As foundation models grow rapidly in capability and deployment, evaluating
their scientific understanding becomes increasingly critical. Existing science
benchmarks have made progress towards broad **Range**, wide **Reach**, and high
**Rigor**, yet they often face two major challenges: **data leakage risks**
that compromise benchmarking validity, and **evaluation inefficiency** due to
large-scale testing. To address these issues, we introduce the **Ever-Evolving
Science Exam (EESE)**, a dynamic benchmark designed to reliably assess
scientific capabilities in foundation models. Our approach consists of two
components: 1) a non-public **EESE-Pool** with over 100K expertly constructed
science instances (question-answer pairs) across 5 disciplines and 500+
subfields, built through a multi-stage pipeline ensuring **Range**, **Reach**,
and **Rigor**, 2) a periodically updated 500-instance subset **EESE**, sampled
and validated to enable leakage-resilient, low-overhead evaluations.
Experiments on 32 open- and closed-source models demonstrate that EESE
effectively differentiates the strengths and weaknesses of models in scientific
fields and cognitive dimensions. Overall, EESE provides a robust, scalable, and
forward-compatible solution for science benchmark design, offering a realistic
measure of how well foundation models handle science questions. The project
page is at: https://github.com/aiben-ch/EESE.

</details>


### [110] [Introducing Quality Estimation to Machine Translation Post-editing Workflow: An Empirical Study on Its Usefulness](https://arxiv.org/abs/2507.16515)
*Siqi Liu,Guangrong Dai,Dechao Li*

Main category: cs.CL

TL;DR: 本研究发现，句子级质量估计（QE）能显著提高机器翻译译后编辑（MTPE）的效率，缩短编辑时间，并帮助译者评估和检查译文。但QE的准确性至关重要，不准确的QE可能适得其反。


<details>
  <summary>Details</summary>
Motivation: 本研究旨在探讨句子级质量估计（QE）在英中机器翻译译后编辑（MTPE）中的作用，以及它对译后编辑速度和译者感知的影响，并为QE在MTPE工作流程中的有效整合提供新的见解。

Method: 该研究调查了句子级质量估计（QE）在英中机器翻译译后编辑（MTPE）中的应用，重点关注其对译后编辑速度和学生译者感知的影响。研究还探讨了QE与机器翻译质量以及QE与翻译专业知识之间的交互效应。

Result: 研究结果表明，QE能够显著减少译后编辑时间，并且在各种质量的机器翻译输出和不同专业水平的学生译者中都能稳定地提高MTPE效率。QE还能在指出潜在问题片段的同时，验证译者对机器翻译质量的评估，并促使译者仔细检查译文。然而，访谈数据也表明，不准确的QE可能会对译后编辑过程产生负面影响。

Conclusion: 该研究表明，句子级质量估计（QE）可以显著减少机器翻译译后编辑（MTPE）的时间，提高译者效率。QE还可以验证译者对机器翻译质量的评估，并促使译者仔细检查译文。然而，不准确的QE可能会阻碍译后编辑过程。该研究为QE的优势和局限性提供了新的见解，有助于将其更有效地整合到MTPE工作流程中，以提高译者的生产力。

Abstract: This preliminary study investigates the usefulness of sentence-level Quality
Estimation (QE) in English-Chinese Machine Translation Post-Editing (MTPE),
focusing on its impact on post-editing speed and student translators'
perceptions. It also explores the interaction effects between QE and MT
quality, as well as between QE and translation expertise. The findings reveal
that QE significantly reduces post-editing time. The examined interaction
effects were not significant, suggesting that QE consistently improves MTPE
efficiency across medium- and high-quality MT outputs and among student
translators with varying levels of expertise. In addition to indicating
potentially problematic segments, QE serves multiple functions in MTPE, such as
validating translators' evaluations of MT quality and enabling them to
double-check translation outputs. However, interview data suggest that
inaccurate QE may hinder post-editing processes. This research provides new
insights into the strengths and limitations of QE, facilitating its more
effective integration into MTPE workflows to enhance translators' productivity.

</details>


### [111] [Learning Text Styles: A Study on Transfer, Attribution, and Verification](https://arxiv.org/abs/2507.16530)
*Zhiqiang Hu*

Main category: cs.CL

TL;DR: 本文研究文本风格转换和作者身份识别，利用LLM技术提升效率和可解释性。


<details>
  <summary>Details</summary>
Motivation: 通过文本风格转换、作者归属和作者身份验证三个相互关联的支柱来推进文本的计算理解和操作

Method: 利用参数高效的LLM适配、对比风格特征解耦以及基于指令的微调来实现可解释的验证

Result: 解决上述领域的关键挑战，实现文本风格的计算理解和操作，并能够进行作者身份验证。 TDL;DR: 本文利用LLM、对比解耦和指令微调来解决文本风格转换和作者身份识别问题。LLM在文本风格转换、作者归属和作者验证方面取得了进展。

Conclusion: 作者身份验证和文本风格转换

Abstract: This thesis advances the computational understanding and manipulation of text
styles through three interconnected pillars: (1) Text Style Transfer (TST),
which alters stylistic properties (e.g., sentiment, formality) while preserving
content; (2)Authorship Attribution (AA), identifying the author of a text via
stylistic fingerprints; and (3) Authorship Verification (AV), determining
whether two texts share the same authorship. We address critical challenges in
these areas by leveraging parameter-efficient adaptation of large language
models (LLMs), contrastive disentanglement of stylistic features, and
instruction-based fine-tuning for explainable verification.

</details>


### [112] [Exploring Gender Bias in Large Language Models: An In-depth Dive into the German Language](https://arxiv.org/abs/2507.16557)
*Kristin Gnadt,David Thulke,Simone Kopeinik,Ralf Schlüter*

Main category: cs.CL

TL;DR: 本研究提出了德语性别偏见评估数据集，并发现德语在性别偏见方面存在独特挑战。


<details>
  <summary>Details</summary>
Motivation: 解决现有性别偏见测量方法在应用于非英语语言（特别是德语）时的可转移性挑战。

Method: 开发了五个德语数据集，并使用多种方法对八个多语言LLM模型进行了评估。

Result: 发现德语在性别偏见方面存在独特挑战，例如男性职业术语的歧义解释以及看似中性名词对性别认知的影响。

Conclusion: 本研究提出了五个用于评估大型语言模型（LLM）中性别偏见的德语数据集，并分析了德语特有的性别偏见问题，强调了制定特定评估框架的必要性。

Abstract: In recent years, various methods have been proposed to evaluate gender bias
in large language models (LLMs). A key challenge lies in the transferability of
bias measurement methods initially developed for the English language when
applied to other languages. This work aims to contribute to this research
strand by presenting five German datasets for gender bias evaluation in LLMs.
The datasets are grounded in well-established concepts of gender bias and are
accessible through multiple methodologies. Our findings, reported for eight
multilingual LLM models, reveal unique challenges associated with gender bias
in German, including the ambiguous interpretation of male occupational terms
and the influence of seemingly neutral nouns on gender perception. This work
contributes to the understanding of gender bias in LLMs across languages and
underscores the necessity for tailored evaluation frameworks.

</details>


### [113] [Pixels to Principles: Probing Intuitive Physics Understanding in Multimodal Language Models](https://arxiv.org/abs/2507.16572)
*Mohamad Ballout,Serwan Jassim,Elia Bruni*

Main category: cs.CL

TL;DR: 最新MLLMs在直观物理任务上表现不佳，因为视觉信息未能有效整合到语言推理中，视觉-语言对齐是关键改进领域。


<details>
  <summary>Details</summary>
Motivation: 为了系统评估最先进的多模态大语言模型（MLLMs）在直观物理任务上的能力，并深入了解其失败原因。

Method: 通过在GRASP和IntPhys 2数据集上对InternVL 2.5、Qwen 2.5 VL、LLaVA-OneVision和Gemini 2.0 Flash Thinking等模型进行系统性评估，并结合对模型嵌入的探测分析，检查中间表示以了解任务相关信息如何被保留。

Result: 研究表明，即使是最新模型也难以可靠地区分物理上合理和不合理的场景。关键的视觉-语言不一致性会出现：视觉编码器成功捕捉到物理合理性线索，但语言模型未能有效利用这些信息，导致推理失败。

Conclusion: 该研究发现，当前最先进的多模态大语言模型（MLLMs）在直观物理任务上表现不佳，主要原因是视觉和语言信息整合不当，而非视觉编码器本身。研究强调了提升视觉-语言对齐以改进MLLMs性能的重要性。

Abstract: This paper presents a systematic evaluation of state-of-the-art multimodal
large language models (MLLMs) on intuitive physics tasks using the GRASP and
IntPhys 2 datasets. We assess the open-source models InternVL 2.5, Qwen 2.5 VL,
LLaVA-OneVision, and the proprietary Gemini 2.0 Flash Thinking, finding that
even the latest models struggle to reliably distinguish physically plausible
from implausible scenarios. To go beyond performance metrics, we conduct a
probing analysis of model embeddings, extracting intermediate representations
at key processing stages to examine how well task-relevant information is
preserved. Our results show that, depending on task difficulty, a critical
vision-language misalignment can emerge: vision encoders successfully capture
physical plausibility cues, but this information is not effectively utilized by
the language model, leading to failures in reasoning. This misalignment
suggests that the primary limitation of MLLMs in intuitive physics tasks is not
the vision component but the ineffective integration of visual and linguistic
information. Our findings highlight vision-language alignment as a key area for
improvement, offering insights for future MLLMs development.

</details>


### [114] [Step-Audio 2 Technical Report](https://arxiv.org/abs/2507.16632)
*Boyong Wu,Chao Yan,Chen Hu,Cheng Yi,Chengli Feng,Fei Tian,Feiyu Shen,Gang Yu,Haoyang Zhang,Jingbei Li,Mingrui Chen,Peng Liu,Wang You,Xiangyu Tony Zhang,Xingyuan Li,Xuerui Yang,Yayue Deng,Yechang Huang,Yuxin Li,Yuxin Zhang,Zhao You,Brian Li,Changyi Wan,Hanpeng Hu,Jiangjie Zhen,Siyu Chen,Song Yuan,Xuelin Zhang,Yimin Jiang,Yu Zhou,Yuxiang Yang,Bingxin Li,Buyun Ma,Changhe Song,Dongqing Pang,Guoqiang Hu,Haiyang Sun,Kang An,Na Wang,Shuli Gao,Wei Ji,Wen Li,Wen Sun,Xuan Wen,Yong Ren,Yuankai Ma,Yufan Lu,Bin Wang,Bo Li,Changxin Miao,Che Liu,Chen Xu,Dapeng Shi,Dingyuan Hu,Donghang Wu,Enle Liu,Guanzhe Huang,Gulin Yan,Han Zhang,Hao Nie,Haonan Jia,Hongyu Zhou,Jianjian Sun,Jiaoren Wu,Jie Wu,Jie Yang,Jin Yang,Junzhe Lin,Kaixiang Li,Lei Yang,Liying Shi,Li Zhou,Longlong Gu,Ming Li,Mingliang Li,Mingxiao Li,Nan Wu,Qi Han,Qinyuan Tan,Shaoliang Pang,Shengjie Fan,Siqi Liu,Tiancheng Cao,Wanying Lu,Wenqing He,Wuxun Xie,Xu Zhao,Xueqi Li,Yanbo Yu,Yang Yang,Yi Liu,Yifan Lu,Yilei Wang,Yuanhao Ding,Yuanwei Liang,Yuanwei Lu,Yuchu Luo,Yuhe Yin,Yumeng Zhan,Yuxiang Zhang,Zidong Yang,Zixin Zhang,Binxing Jiao,Daxin Jiang,Heung-Yeung Shum,Jiansheng Chen,Jing Li,Xiangyu Zhang,Yibo Zhu*

Main category: cs.CL

TL;DR: Step-Audio~2是一个端到端的多模态大语言模型，用于音频理解和语音对话。它通过集成潜在音频编码器、强化学习（RL）和检索增强生成（RAG）来提高性能，并能处理副语言信息和调用外部工具。在数百万小时的数据上训练，并在多个基准测试中取得了最先进的成果。


<details>
  <summary>Details</summary>
Motivation: 为了实现真正的端到端语音对话，并有效利用真实世界数据中丰富的文本和声学知识，同时减少幻觉和支持音色切换。

Method: 端到端多模态大语言模型，整合潜在音频编码器、推理中心强化学习（RL）、检索增强生成（RAG）以及通过生成离散音频令牌进行语言建模。

Result: 在自动语音识别（ASR）和音频理解方面取得了有希望的性能，增强了对说话风格和情感等副语言信息的响应能力，并在各种音频理解和对话基准测试中实现了最先进的性能。

Conclusion: Step-Audio~2 在自动语音识别和音频理解方面表现出色，通过整合潜在音频编码器和以推理为中心的强化学习（RL），实现了有希望的性能。它还通过生成离散音频令牌来增强响应能力，并利用检索增强生成（RAG）来减少幻觉并进行音频搜索。

Abstract: This paper presents Step-Audio~2, an end-to-end multi-modal large language
model designed for industry-strength audio understanding and speech
conversation. By integrating a latent audio encoder and reasoning-centric
reinforcement learning (RL), Step-Audio 2 achieves promising performance in
automatic speech recognition (ASR) and audio understanding. To facilitate
genuine end-to-end speech conversation, Step-Audio 2 incorporates the
generation of discrete audio tokens into language modeling, significantly
enhancing its responsiveness to paralinguistic information such as speaking
styles and emotions. To effectively leverage the rich textual and acoustic
knowledge in real-world data, Step-Audio 2 integrates retrieval-augmented
generation (RAG) and is able to call external tools such as web search to
mitigate hallucination and audio search to switch timbres. Trained on millions
of hours of speech and audio data, Step-Audio 2 delivers intelligence and
expressiveness across diverse conversational scenarios. Evaluation results
demonstrate that Step-Audio 2 achieves state-of-the-art performance on various
audio understanding and conversational benchmarks compared to other open-source
and commercial solutions. Please visit
https://github.com/stepfun-ai/Step-Audio2 for more information.

</details>


### [115] [Towards Automated Regulatory Compliance Verification in Financial Auditing with Large Language Models](https://arxiv.org/abs/2507.16642)
*Armin Berger,Lars Hillebrand,David Leonhard,Tobias Deußer,Thiago Bell Felix de Oliveira,Tim Dilmaghani,Mohamed Khaled,Bernd Kliem,Rüdiger Loitz,Christian Bauckhage,Rafet Sifa*

Main category: cs.CL

TL;DR: AI审计：开源LLMs（Llama-2）在检测不合规方面优于专有模型（GPT-4），但在跨语言和广泛场景下GPT-4表现更佳。


<details>
  <summary>Details</summary>
Motivation: 尽管AI驱动的解决方案已开始简化财报审计流程，但现有系统在验证推荐文本段落是否符合特定法律法规要求方面存在明显不足。

Method: 利用两个由普华永道德国提供的自定义数据集，对公开的大型语言模型（LLMs）在不同模型配置下的合规性进行效率评估，并着重比较了Llama-2等尖端开源LLMs与OpenAI的GPT模型等专有模型的性能。

Result: 开源的Llama-2 70B模型在检测不合规或真实负面情况方面表现突出，优于所有专有模型。但GPT-4等专有模型在广泛场景下（尤其是在非英语环境中）表现最佳。

Conclusion: 开源LLM（如Llama-2 70B）在检测不合规或真实负面情况方面表现出色，优于所有专有模型。然而，专有模型（如GPT-4）在包括非英语环境在内的多种场景下表现最佳。

Abstract: The auditing of financial documents, historically a labor-intensive process,
stands on the precipice of transformation. AI-driven solutions have made
inroads into streamlining this process by recommending pertinent text passages
from financial reports to align with the legal requirements of accounting
standards. However, a glaring limitation remains: these systems commonly fall
short in verifying if the recommended excerpts indeed comply with the specific
legal mandates. Hence, in this paper, we probe the efficiency of publicly
available Large Language Models (LLMs) in the realm of regulatory compliance
across different model configurations. We place particular emphasis on
comparing cutting-edge open-source LLMs, such as Llama-2, with their
proprietary counterparts like OpenAI's GPT models. This comparative analysis
leverages two custom datasets provided by our partner PricewaterhouseCoopers
(PwC) Germany. We find that the open-source Llama-2 70 billion model
demonstrates outstanding performance in detecting non-compliance or true
negative occurrences, beating all their proprietary counterparts. Nevertheless,
proprietary models such as GPT-4 perform the best in a broad variety of
scenarios, particularly in non-English contexts.

</details>


### [116] [P-CoT: A Pedagogically-motivated Participatory Chain-of-Thought Prompting for Phonological Reasoning in LLMs](https://arxiv.org/abs/2507.16656)
*Dongjun Jang,Youngchae Ahn,Hyopil Shin*

Main category: cs.CL

TL;DR: 该研究提出了一种名为P-CoT的新型提示方法，通过结构化指导来提高大型语言模型（LLM）的语音推理能力，并在多个任务上取得了显著的性能提升。


<details>
  <summary>Details</summary>
Motivation: 本研究探讨了基于文本的大型语言模型（LLM）中语音推理的潜力。

Method: 利用PhonologyBench基准，评估了韵律词生成、g2p转换和音节计数等任务。对12个LLM的评估显示，虽然少样本学习的收益不一致，但引入新颖的教育学启发式参与性思维链（P-CoT）提示，通过脚手架和发现学习等教育理论进行锚定，持续提高了性能。

Result: P-CoT方法利用结构化指导来激活潜在的语音能力，在某些任务上提高了52%的性能，甚至超过了人类基线。

Conclusion: 该研究表明，基于

Abstract: This study explores the potential of phonological reasoning within text-based
large language models (LLMs). Utilizing the PhonologyBench benchmark, we assess
tasks like rhyme word generation, g2p conversion, and syllable counting. Our
evaluations across 12 LLMs reveal that while few-shot learning offers
inconsistent gains, the introduction of a novel Pedagogically-motivated
Participatory Chain-of-Thought (P-CoT) prompt, which is anchored in educational
theories like scaffolding and discovery learning, consistently enhances
performance. This method leverages structured guidance to activate latent
phonological abilities, achieving up to 52% improvement and even surpassing
human baselines in certain tasks. Future work could aim to optimize P-CoT
prompts for specific models or explore their application across different
linguistic domains.

</details>


### [117] [Self-Contradiction as Self-Improvement: Mitigating the Generation-Understanding Gap in MLLMs](https://arxiv.org/abs/2507.16663)
*Yujin Han,Hao Chen,Andi Han,Zhiheng Wang,Xinyu Lin,Yingya Zhang,Shiwei Zhang,Difan Zou*

Main category: cs.CL

TL;DR: MLLM存在生成与提示不符的“自我矛盾”，主因是生成能力弱。研究提出用内部监督信号改进，通过SFT/DPO等后训练方法缩小生成-理解差距。仅微调生成分支也能共同提升两能力。警惕不良监督致“共同退化”，内部指标区分难。课程学习策略可优化MLLM性能。


<details>
  <summary>Details</summary>
Motivation: 多模态大语言模型（MLLM）在统一多模态生成和理解任务方面取得了进展，但普遍存在“自我矛盾”现象，即模型生成的图像与输入提示不匹配，即使模型自身的理解能力表明存在不匹配。这种现象阻碍了模型性能的提升和应用。本研究旨在深入探究这种自我矛盾产生的原因，并提出有效的解决方案，以期提升MLLM在生成和理解任务上的协同能力和整体性能。

Method: 本研究首先定义了一个“非统一分数”来量化多模态大语言模型（MLLM）在生成内容与输入提示之间的一致性问题，即“自我矛盾”。通过实证分析，研究区分了生成能力不足和理解能力偏差是导致自我矛盾的主要原因，指出生成能力通常是瓶颈。在此基础上，研究提出了一种利用模型内部监督信号来改进MLLM的策略，特别是通过后训练方法（如SFT、DPO）来缩小生成-理解能力之间的差距。研究还探索了仅微调生成分支对理解能力产生的“共同提升”效应，并从理论上解释了这种现象。此外，研究还发现了在不良监督下可能出现的“共同退化”现象，并通过实验进行了验证，并强调了现有内部指标无法区分“共同提升”和“共同退化”的局限性。最后，基于这些发现，研究提出了一种课程学习策略，通过分阶段引入不同难度的样本来优化模型的统一性。

Result: 研究发现，MLLM中的自我矛盾现象主要由生成能力不足引起，而非理解能力偏差。通过利用生成-理解能力的不对称性，并结合标准后训练方法（如SFT、DPO）进行内部监督，成功缩小了生成-理解的差距，提升了模型的统一性。实验证明，仅微调生成分支也能带来生成和理解能力的共同提升，这得益于模型对错误匹配样本检测能力的增强。理论分析表明，对齐训练有助于减少不匹配的生成，并提升理解能力。研究还发现了不良监督可能导致“共同退化”现象，并验证了现有内部指标（如Nonunified score）无法区分“共同提升”和“共同退化”。最终，研究提出的课程学习策略显著改善了MLLM的统一性、生成和理解能力。

Conclusion: 该研究表明，多模态大语言模型（MLLM）中普遍存在的“自我矛盾”现象，即生成内容与输入提示不一致，可以通过一种称为“非统一分数”的指标来量化。通过对生成和理解能力的分析，研究发现自我矛盾主要源于生成能力的不足，而非理解能力的偏差。基于这一发现，研究提出了一种利用模型内部监督来改善生成和理解能力不对称性的方法，通过后训练（如SFT、DPO）并结合内部监督，可以有效缩小生成-理解的差距。实验中，仅微调生成分支也实现了生成和理解能力的共同提升，这归因于模型对错误匹配的检测能力增强。理论分析支持了生成和理解对齐训练的益处，以及在不良监督下可能出现的“共同退化”风险。研究还强调了内部指标在区分共同提升与共同退化时的局限性，以及数据质量检查的重要性。最后，研究提出了一种基于课程学习的策略，通过逐步引入更难的样本来优化MLLM的统一性和整体性能。

Abstract: Despite efforts to unify multimodal generation and understanding tasks in a
single model, we show these MLLMs exhibit self-contradiction where generation
produces images deemed misaligned with input prompts based on the model's own
understanding. We define a Nonunified score that quantifies such
self-contradiction. Our empirical results reveal that the self-contradiction
mainly arises from weak generation that fails to align with prompts, rather
than misunderstanding. This capability asymmetry indicates the potential of
leveraging self-contradiction for self-improvement, where the stronger model
understanding guides the weaker generation to mitigate the
generation-understanding gap. Applying standard post-training methods (e.g.,
SFT, DPO) with such internal supervision successfully improves both generation
and unification. We discover a co-improvement effect on both generation and
understanding when only fine-tuning the generation branch, a phenomenon known
in pre-training but underexplored in post-training. Our analysis shows
improvements stem from better detection of false positives that are previously
incorrectly identified as prompt-aligned. Theoretically, we show the aligned
training dynamics between generation and understanding allow reduced
prompt-misaligned generations to also improve mismatch detection in the
understanding branch. Additionally, the framework reveals a potential risk of
co-degradation under poor supervision-an overlooked phenomenon that is
empirically validated in our experiments. Notably, we find intrinsic metrics
like Nonunified score cannot distinguish co-degradation from co-improvement,
which highlights the necessity of data quality check. Finally, we propose a
curriculum-based strategy based on our findings that gradually introduces
harder samples as the model improves, leading to better unification and
improved MLLM generation and understanding.

</details>


### [118] [PICACO: Pluralistic In-Context Value Alignment of LLMs via Total Correlation Optimization](https://arxiv.org/abs/2507.16679)
*Han Jiang,Dongyao Zhu,Zhihua Wei,Xiaoyuan Yi,Ziang Xiao,Xing Xie*

Main category: cs.CL

TL;DR: PICACO是一种不需微调的上下文对齐方法，通过优化元指令来解决指令瓶颈，更好地处理人类多元价值观，并在实验中表现优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有的上下文对齐（ICA）方法在处理人类价值观的内在多元性和经常出现的价值冲突方面存在局限性，因为大型语言模型（LLM）对输入提示的理解能力仍然是滞后（agnostic）的。这导致在单个提示中难以协调多个目标值，从而导致对齐不完全或有偏见。

Method: PICACO通过优化元指令来解决指令瓶颈问题，以最大化指定值与语言模型响应之间的总相关性，从而增强值相关性并减少干扰噪声。

Result: PICACO在五个价值观数据集上的广泛实验表明，该方法能够很好地与黑盒和开源语言模型协同工作，其性能优于最近的几种强有力基线方法，并且在最多8个不同的值之间实现了更好的平衡。

Conclusion: PICACO是一种新颖的多元化上下文学习方法，通过优化元指令来解决指令瓶颈问题，能够更好地引发语言模型对多个值的理解并改进其对齐。该方法在不进行微调的情况下，通过最大化指定值与语言模型响应之间的总相关性来增强值相关性并减少干扰噪声，从而产生有效的价值观指令。

Abstract: In-Context Learning has shown great potential for aligning Large Language
Models (LLMs) with human values, helping reduce harmful outputs and accommodate
diverse preferences without costly post-training, known as In-Context Alignment
(ICA). However, LLMs' comprehension of input prompts remains agnostic, limiting
ICA's ability to address value tensions--human values are inherently
pluralistic, often imposing conflicting demands, e.g., stimulation vs.
tradition. Current ICA methods therefore face the Instruction Bottleneck
challenge, where LLMs struggle to reconcile multiple intended values within a
single prompt, leading to incomplete or biased alignment. To address this, we
propose PICACO, a novel pluralistic ICA method. Without fine-tuning, PICACO
optimizes a meta-instruction that navigates multiple values to better elicit
LLMs' understanding of them and improve their alignment. This is achieved by
maximizing the total correlation between specified values and LLM responses,
theoretically reinforcing value correlation while reducing distractive noise,
resulting in effective value instructions. Extensive experiments on five value
sets show that PICACO works well with both black-box and open-source LLMs,
outperforms several recent strong baselines, and achieves a better balance
across up to 8 distinct values.

</details>


### [119] [Interpretable Topic Extraction and Word Embedding Learning using row-stochastic DEDICOM](https://arxiv.org/abs/2507.16695)
*Lars Hillebrand,David Biesner,Christian Bauckhage,Rafet Sifa*

Main category: cs.CL

TL;DR: DEDICOM算法的行随机变体在文本语料库中识别主题和学习词嵌入方面表现出色。


<details>
  <summary>Details</summary>
Motivation: DEDICOM算法为对称和非对称方阵提供了一种可解释的矩阵分解方法。在文本语料库的点态互信息矩阵上应用DEDICOM算法的行随机变体，旨在识别潜在的主题聚类并学习可解释的词嵌入。

Method: 提出了一种约束DEDICOM算法的高效训练方法，并对其主题建模和词嵌入性能进行了定性评估。

Result: 该方法能够有效识别潜在主题聚类，并学习可解释的词嵌入，在主题建模和词嵌入方面表现良好。

Conclusion: DEDICOM算法的行随机变体在文本语料库的点态互信息矩阵上能够有效识别潜在的主题聚类，并同时学习可解释的词嵌入。

Abstract: The DEDICOM algorithm provides a uniquely interpretable matrix factorization
method for symmetric and asymmetric square matrices. We employ a new
row-stochastic variation of DEDICOM on the pointwise mutual information
matrices of text corpora to identify latent topic clusters within the
vocabulary and simultaneously learn interpretable word embeddings. We introduce
a method to efficiently train a constrained DEDICOM algorithm and a qualitative
evaluation of its topic modeling and word embedding performance.

</details>


### [120] [Advancing Risk and Quality Assurance: A RAG Chatbot for Improved Regulatory Compliance](https://arxiv.org/abs/2507.16711)
*Lars Hillebrand,Armin Berger,Daniel Uedelhoven,David Berghaus,Ulrich Warning,Tim Dilmaghani,Bernd Kliem,Thomas Schmid,Rüdiger Loitz,Rafet Sifa*

Main category: cs.CL

TL;DR: 为解决监管行业R&Q查询难题，提出基于LLM的RAG系统，实际效果优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 为了解决高度监管行业中风险与质量（R&Q）保证流程中，员工在处理大量查询时遇到的准确解读政策的挑战，以及传统依赖专家方法造成的运营瓶颈和可扩展性限制。

Method: 提出了一种新颖的检索增强生成（RAG）系统，该系统利用大型语言模型（LLM）、混合搜索和相关性提升技术来优化风险与质量（R&Q）查询处理。通过对124个真实世界查询进行评估，并进行了广泛的超参数分析，以优化系统配置。

Result: 所提出的RAG系统在实际部署中，相较于传统的RAG方法，在处理风险与质量（R&Q）查询方面取得了显著的改进。通过详细的超参数分析，提供了有价值的实践指导。

Conclusion: 该研究提出了一个利用大型语言模型、混合搜索和相关性提升的新颖的检索增强生成（RAG）系统，以增强风险与质量（R&Q）查询处理能力，并在实际应用中展示了超越传统RAG方法的显著改进。

Abstract: Risk and Quality (R&Q) assurance in highly regulated industries requires
constant navigation of complex regulatory frameworks, with employees handling
numerous daily queries demanding accurate policy interpretation. Traditional
methods relying on specialized experts create operational bottlenecks and limit
scalability. We present a novel Retrieval Augmented Generation (RAG) system
leveraging Large Language Models (LLMs), hybrid search and relevance boosting
to enhance R&Q query processing. Evaluated on 124 expert-annotated real-world
queries, our actively deployed system demonstrates substantial improvements
over traditional RAG approaches. Additionally, we perform an extensive
hyperparameter analysis to compare and evaluate multiple configuration setups,
delivering valuable insights to practitioners.

</details>


### [121] [RAVine: Reality-Aligned Evaluation for Agentic Search](https://arxiv.org/abs/2507.16725)
*Yilong Xu,Xiang Long,Zhi Zheng,Jinhua Gao*

Main category: cs.CL

TL;DR: RAVine是一个评估智能体LLM（具有搜索功能）的新框架，它解决了现有评估方法的不足，能够更好地反映真实用户场景，进行更准确的细粒度评估，并同时考虑了迭代过程和效率。


<details>
  <summary>Details</summary>
Motivation: 现有评估框架未能很好地支持智能体搜索（一种更自主、更自适应的检索增强范式）。具体问题包括：1.复杂查询偏离真实用户场景；2.端到端评估中的地面真实提取引入噪声，导致细粒度评估失真；3.现有框架仅关注最终答案质量，忽略了智能体搜索的迭代过程评估。

Method: 提出RAVine框架，一个针对智能体LLM（具有搜索功能）的现实对齐评估框架。该框架针对多点查询和长答案，引入了可归因的地面真实构建策略以提高细粒度评估的准确性，并检查了模型在迭代过程中与搜索工具的交互以及效率因素。

Result: 使用RAVine对一系列模型进行了基准测试，并得出了几项见解，为推进智能体搜索系统的发展做出了贡献。

Conclusion: RAVine框架通过针对多点查询、长答案、可归因的地面真实构建策略以及对模型与搜索工具的迭代过程和效率因素的检查，解决了现有评估框架的局限性。我们使用RAVine对一系列模型进行了基准测试，并得出了几项见解，以期促进智能搜索系统的发展。

Abstract: Agentic search, as a more autonomous and adaptive paradigm of retrieval
augmentation, is driving the evolution of intelligent search systems. However,
existing evaluation frameworks fail to align well with the goals of agentic
search. First, the complex queries commonly used in current benchmarks often
deviate from realistic user search scenarios. Second, prior approaches tend to
introduce noise when extracting ground truth for end-to-end evaluations,
leading to distorted assessments at a fine-grained level. Third, most current
frameworks focus solely on the quality of final answers, neglecting the
evaluation of the iterative process inherent to agentic search. To address
these limitations, we propose RAVine -- a Reality-Aligned eValuation framework
for agentic LLMs with search. RAVine targets multi-point queries and long-form
answers that better reflect user intents, and introduces an attributable ground
truth construction strategy to enhance the accuracy of fine-grained evaluation.
Moreover, RAVine examines model's interaction with search tools throughout the
iterative process, and accounts for factors of efficiency. We benchmark a
series of models using RAVine and derive several insights, which we hope will
contribute to advancing the development of agentic search systems. The code and
datasets are available at https://github.com/SwordFaith/RAVine.

</details>


### [122] [Unpacking Ambiguity: The Interaction of Polysemous Discourse Markers and Non-DM Signals](https://arxiv.org/abs/2507.16748)
*Jingni Wu,Amir Zeldes*

Main category: cs.CL

TL;DR: 该研究探讨了话语标记（DMs）的多义性与非DM信号的共现之间的关系，并考虑了语体的影响。研究结果表明，多义性DMs与更多样化的非DMs相关，但信号总数不一定增加，语体起着重要作用。


<details>
  <summary>Details</summary>
Motivation: 为了弄清话语标记（DMs）与非DM信号的交互机制，因为它们对于消歧至关重要，而这种交互机制尚不清楚。

Method: 使用eRST框架，提出了一种渐进式的DM多义性定义，并进行相关性和回归分析，以检验多义性DM是否伴随更多数量和更多样化的非DM信号。

Result: 多义性DMs确实与更多样化的非DMs同时出现，但同时出现的信号总数不一定增加。语体对DM信号交互有显著影响。

Conclusion: 多义性话语标记（DMs）确实与更多样化的非DM信号同时出现，但同时出现的信号总数不一定增加，并且语体在塑造DM信号交互方面起着重要作用。

Abstract: Discourse markers (DMs) like 'but' or 'then' are crucial for creating
coherence in discourse, yet they are often replaced by or co-occur with non-DMs
('in the morning' can mean the same as 'then'), and both can be ambiguous
('since' can refer to time or cause). The interaction mechanism between such
signals remains unclear but pivotal for their disambiguation. In this paper we
investigate the relationship between DM polysemy and co-occurrence of non-DM
signals in English, as well as the influence of genre on these patterns.
  Using the framework of eRST, we propose a graded definition of DM polysemy,
and conduct correlation and regression analyses to examine whether polysemous
DMs are accompanied by more numerous and diverse non-DM signals. Our findings
reveal that while polysemous DMs do co-occur with more diverse non-DMs, the
total number of co-occurring signals does not necessarily increase. Moreover,
genre plays a significant role in shaping DM-signal interactions.

</details>


### [123] [Beyond Context Limits: Subconscious Threads for Long-Horizon Reasoning](https://arxiv.org/abs/2507.16784)
*Hongyin Luo,Nathaniel Morgan,Tina Li,Derek Zhao,Ai Vy Ngo,Philip Schroeder,Lijie Yang,Assaf Ben-Kish,Jack O'Brien,James Glass*

Main category: cs.CL

TL;DR: 提出TIM和TIMRUN模型，解决了LLM的上下文长度限制问题，实现了长距离推理和多跳工具使用，并保持了高效率。


<details>
  <summary>Details</summary>
Motivation: 为了突破大型语言模型（LLMs）中限制推理准确性和效率的上下文长度限制。

Method: 提出了一种名为Thread Inference Model（TIM）的大语言模型系列，并开发了一个名为TIMRUN的推理运行时。TIM模型被训练用于递归和分解式问题解决，而TIMRUN支持在单个语言模型推理中实现超越上下文限制的长距离结构化推理。该系统通过将自然语言建模为由长度和深度定义的推理树，而不是线性序列，来实现性能。在生成过程中，通过基于规则的子任务剪枝机制维护一个工作内存，该内存仅保留最相关上下文令牌的键值状态，从而在整个推理过程中实现位置嵌入和GPU内存页的重用。

Result: TIM和TIMRUN的结合使用，使得模型能够支持几乎无限的工作记忆和单次语言模型推理中的多跳工具调用，克服了输出限制、位置嵌入约束和GPU内存瓶颈。实验结果表明，该系统在处理长距离推理和多跳工具使用方面表现出色。

Conclusion: 该模型在数学任务和需要长距离推理及多跳工具使用的信息检索挑战中表现出准确的推理能力，并且在处理高达90%的GPU显存KV缓存时仍能保持高推理吞吐量。

Abstract: To break the context limits of large language models (LLMs) that bottleneck
reasoning accuracy and efficiency, we propose the Thread Inference Model (TIM),
a family of LLMs trained for recursive and decompositional problem solving, and
TIMRUN, an inference runtime enabling long-horizon structured reasoning beyond
context limits. Together, TIM hosted on TIMRUN supports virtually unlimited
working memory and multi-hop tool calls within a single language model
inference, overcoming output limits, positional-embedding constraints, and
GPU-memory bottlenecks. Performance is achieved by modeling natural language as
reasoning trees measured by both length and depth instead of linear sequences.
The reasoning trees consist of tasks with thoughts, recursive subtasks, and
conclusions based on the concept we proposed in Schroeder et al, 2025. During
generation, we maintain a working memory that retains only the key-value states
of the most relevant context tokens, selected by a rule-based subtask-pruning
mechanism, enabling reuse of positional embeddings and GPU memory pages
throughout reasoning. Experimental results show that our system sustains high
inference throughput, even when manipulating up to 90% of the KV cache in GPU
memory. It also delivers accurate reasoning on mathematical tasks and handles
information retrieval challenges that require long-horizon reasoning and
multi-hop tool use.

</details>


### [124] [Test-Time-Matching: Decouple Personality, Memory, and Linguistic Style in LLM-based Role-Playing Language Agent](https://arxiv.org/abs/2507.16799)
*Xiaoyu Zhan,Xinyu Fu,Hao Sun,Yuanqi Li,Jie Guo,Yanwen Guo*

Main category: cs.CL

TL;DR: 提出了一种名为测试时匹配（TTM）的免训练框架，通过测试时缩放和上下文工程，将角色特征分解为个性、记忆和语言风格，实现高保真度的角色扮演，并能融合多种风格、个性和记忆变体，在角色对话生成方面表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有基于提示和上下文输入的角色扮演方法难以实现深度沉浸，特别是扮演知名的虚构或公众人物。而基于微调的方法由于数据收集和计算资源限制了其广泛应用。

Method: 本文提出了一种名为测试时匹配（TTM）的免训练角色扮演框架，通过测试时缩放和上下文工程实现。TTM利用LLM代理自动将角色的特征分解为个性、记忆和语言风格，并通过一个结构化的三阶段生成流程来利用这些特征进行受控的角色扮演。

Result: 该框架实现了高保真度的角色扮演性能，并能够无缝地融合各种语言风格、个性和记忆的变体。通过人类评估，我们的方法在生成富有表现力和风格一致的角色对话方面取得了优异的性能。

Conclusion: 该框架在生成富有表现力和风格一致的角色对话方面取得了优异的性能。

Abstract: The rapid advancement of large language models (LLMs) has enabled
role-playing language agents to demonstrate significant potential in various
applications. However, relying solely on prompts and contextual inputs often
proves insufficient for achieving deep immersion in specific roles,
particularly well-known fictional or public figures. On the other hand,
fine-tuning-based approaches face limitations due to the challenges associated
with data collection and the computational resources required for training,
thereby restricting their broader applicability. To address these issues, we
propose Test-Time-Matching (TTM), a training-free role-playing framework
through test-time scaling and context engineering. TTM uses LLM agents to
automatically decouple a character's features into personality, memory, and
linguistic style. Our framework involves a structured, three-stage generation
pipeline that utilizes these features for controlled role-playing. It achieves
high-fidelity role-playing performance, also enables seamless combinations
across diverse linguistic styles and even variations in personality and memory.
We evaluate our framework through human assessment, and the results demonstrate
that our method achieves the outstanding performance in generating expressive
and stylistically consistent character dialogues.

</details>


### [125] [Agentar-Fin-R1: Enhancing Financial Intelligence through Domain Expertise, Training Efficiency, and Advanced Reasoning](https://arxiv.org/abs/2507.16802)
*Yanjun Zheng,Xiyang Du,Longfei Liao,Xiaoke Zhao,Zhaowen Zhou,Bo Zhang,Jiawei Liu,Xiang Qi,Zhe Li,Zhiqiang Zhang,Wang Wei,Peng Zhang*

Main category: cs.CL

TL;DR: Agentar-Fin-R1系列金融大型语言模型通过优化推理、可信度和领域专业化，在金融任务和通用推理方面取得了最先进的成果。


<details>
  <summary>Details</summary>
Motivation: 现有的大型语言模型在金融领域虽然潜力巨大，但在需要强大推理能力、严格可信度要求和任务特定高效适应性的场景中往往表现不佳。

Method: 通过整合高质量、系统化的金融任务分类以及包含高质量可信知识工程、多智能体可信数据合成和严格数据验证治理的多层次可信度保障框架，并采用标签引导的自动难度感知优化、两阶段学习过程和详细的归因系统进行优化。

Result: Agentar-Fin-R1系列金融大型语言模型（8B和32B参数）在金融任务和通用推理任务上均取得显著性能提升，在FinEva、FinEval、FinanceIQ、MATH-500和GPQA等基准测试以及新提出的Finova基准测试中表现优异。

Conclusion: Agentar-Fin-R1在金融任务和通用推理任务上均达到最先进的性能，并且能够有效处理高风险金融应用，是一款值得信赖的解决方案。

Abstract: Large Language Models (LLMs) demonstrate tremendous potential in the
financial domain, yet existing models often fall short in scenarios demanding
robust reasoning capabilities, stringent trustworthiness requirements, and
efficient adaptation to task-specific needs. We introduce the Agentar-Fin-R1
series of financial large language models (8B and 32B parameters), specifically
engineered based on the Qwen3 foundation model to enhance reasoning
capabilities, reliability, and domain specialization for financial
applications. Our optimization approach integrates a high-quality, systematic
financial task taxonomy with a comprehensive multi-layered trustworthiness
assurance framework. This framework encompasses high-quality trustworthy
knowledge engineering, multi-agent trustworthy data synthesis, and rigorous
data validation governance. Through label-guided automated difficulty-aware
optimization, tow-stage learning processes, and detailed attribution systems,
we achieve substantial improvements in training efficiency. Our models undergo
comprehensive evaluation on mainstream financial benchmarks including FinEva,
FinEval, and FinanceIQ, as well as general reasoning datasets such as MATH-500
and GPQA. To thoroughly assess real-world deployment capabilities, we
innovatively propose the Finova evaluation benchmark, which focuses on
agent-level financial reasoning and compliance verification. Experimental
results demonstrate that Agentar-Fin-R1 not only achieves state-of-the-art
performance on financial tasks but also exhibits exceptional general reasoning
capabilities, validating its effectiveness as a trustworthy solution for
high-stakes financial applications.

</details>


### [126] [LingBench++: A Linguistically-Informed Benchmark and Reasoning Framework for Multi-Step and Cross-Cultural Inference with LLMs](https://arxiv.org/abs/2507.16809)
*Da-Chen Lian,Ri-Sheng Huang,Pin-Er Chen,Chunki Lim,You-Kuan Lin,Guan-Yu Tseng,Zi-Cheng Yang,Shu-Kai Hsieh*

Main category: cs.CL

TL;DR: LingBench++ 是一个用于评估大型语言模型在复杂的、受国际语言学奥林匹克竞赛启发的语言任务上的基准和推理框架，具有结构化推理、多语言支持，并展示了结合外部知识和迭代推理的模型的优越性。


<details>
  <summary>Details</summary>
Motivation: 评估大型语言模型（LLMs）在复杂语言任务上的能力，这些任务的灵感来自国际语言学奥林匹克竞赛（IOL），重点关注结构化推理和多语言能力。

Method: 通过集成语法知识检索、工具增强推理和审慎的假设检验的多代理架构，并进行基线和我们提出的代理模型的系统比较。

Result: 配备外部知识源和迭代推理能力的模型在准确性和可解释性方面均优于单遍方法。

Conclusion: LingBench++ 为在语言学上扎实、文化上知情和认知上合理的语言模型推理奠定了全面的基础。

Abstract: We propose LingBench++, a linguistically-informed benchmark and reasoning
framework designed to evaluate large language models (LLMs) on complex
linguistic tasks inspired by the International Linguistics Olympiad (IOL).
Unlike prior benchmarks that focus solely on final answer accuracy, LingBench++
provides structured reasoning traces, stepwise evaluation protocols, and rich
typological metadata across over 90 low-resource and cross-cultural languages.
We further develop a multi-agent architecture integrating grammatical knowledge
retrieval, tool-augmented reasoning, and deliberate hypothesis testing. Through
systematic comparisons of baseline and our proposed agentic models, we
demonstrate that models equipped with external knowledge sources and iterative
reasoning outperform single-pass approaches in both accuracy and
interpretability. LingBench++ offers a comprehensive foundation for advancing
linguistically grounded, culturally informed, and cognitively plausible
reasoning in LLMs.

</details>


### [127] [MegaScience: Pushing the Frontiers of Post-Training Datasets for Science Reasoning](https://arxiv.org/abs/2507.16812)
*Run-Ze Fan,Zengzhi Wang,Pengfei Liu*

Main category: cs.CL

TL;DR: 研究人员创建了 TextbookReasoning 和 MegaScience 数据集，以解决科学推理领域数据集的缺失问题。这些数据集包含大量科学问题，并在评估系统中进行了测试。结果表明，使用这些新数据集训练的模型在性能和效率上均优于现有模型，尤其是在较大模型上表现更佳。研究团队已将相关资源开源。


<details>
  <summary>Details</summary>
Motivation: 为了解决当前 AI 研究社区在数学和编程领域关注较多，但在科学领域由于缺乏开放、大规模、高质量、可验证的科学推理数据集而滞后的问题，本研究旨在弥合这一差距，推动 AI 在自然科学发现中的应用。

Method: 1. 创建了包含大学科学教科书中的 65 万个推理问题的 TextbookReasoning 数据集。
2. 通过系统性消融研究，从大量高质量开源数据集中筛选出最优子集，构建了包含 125 万个实例的 MegaScience 数据集。
3. 建立了涵盖 15 个基准测试、多种学科和问题类型的综合评估体系，并采用了全面的答案提取策略以确保评估的准确性。
4. 在 MegaScience 数据集上训练 Llama3.1、Qwen2.5 和 Qwen3 系列基础模型，并与相应的官方指令模型进行性能对比。
5. 分析了 MegaScience 数据集对不同规模和能力的模型的有效性，探讨了其扩展潜力。
6. 公开了数据处理流程、评估系统、数据集以及七个训练好的模型。

Result: 1. 新数据集（TextbookReasoning 和 MegaScience）在性能和训练效率上优于现有开源科学数据集，并能生成更简洁的响应。
2. 在 MegaScience 上训练的基础模型（Llama3.1、Qwen2.5、Qwen3 系列）显著优于同系列官方指令模型。
3. MegaScience 数据集对更大、更强的模型更有效，显示出规模效益。

Conclusion: 该研究通过创建和发布包含海量科学推理问题的 TextbookReasoning 和 MegaScience 数据集，并构建了全面的评估系统，显著推动了科学推理领域的发展。实验结果表明，新数据集在提高模型性能、训练效率和缩短响应长度方面优于现有数据集。此外，在 MegaScience 数据集上训练的 Llama3.1、Qwen2.5 和 Qwen3 系列模型在平均性能上大幅超越了官方的指令模型，并且显示出随着模型规模增大而带来的效益提升。研究团队还公开了数据处理流程、评估系统、数据集及训练模型，以促进社区在科学推理方面的研究。

Abstract: Scientific reasoning is critical for developing AI scientists and supporting
human researchers in advancing the frontiers of natural science discovery.
However, the open-source community has primarily focused on mathematics and
coding while neglecting the scientific domain, largely due to the absence of
open, large-scale, high-quality, verifiable scientific reasoning datasets. To
bridge this gap, we first present TextbookReasoning, an open dataset featuring
truthful reference answers extracted from 12k university-level scientific
textbooks, comprising 650k reasoning questions spanning 7 scientific
disciplines. We further introduce MegaScience, a large-scale mixture of
high-quality open-source datasets totaling 1.25 million instances, developed
through systematic ablation studies that evaluate various data selection
methodologies to identify the optimal subset for each publicly available
scientific dataset. Meanwhile, we build a comprehensive evaluation system
covering diverse subjects and question types across 15 benchmarks,
incorporating comprehensive answer extraction strategies to ensure accurate
evaluation metrics. Our experiments demonstrate that our datasets achieve
superior performance and training efficiency with more concise response lengths
compared to existing open-source scientific datasets. Furthermore, we train
Llama3.1, Qwen2.5, and Qwen3 series base models on MegaScience, which
significantly outperform the corresponding official instruct models in average
performance. In addition, MegaScience exhibits greater effectiveness for larger
and stronger models, suggesting a scaling benefit for scientific tuning. We
release our data curation pipeline, evaluation system, datasets, and seven
trained models to the community to advance scientific reasoning research.

</details>


<div id='quant-ph'></div>

# quant-ph [[Back]](#toc)

### [128] [Quantum Complementarity ad Infinitum: Switching Higher-Order Coherence from Infinity to Zero](https://arxiv.org/abs/2507.15890)
*Arash Azizi*

Main category: quant-ph

TL;DR: 量子互补性在“Janus态”高阶光子统计中的体现：通过路径信息控制量子干涉，可实现高阶关联的完全抑制，并观察到非经典性的负Wigner函数。


<details>
  <summary>Details</summary>
Motivation: 研究量子互补性在“Janus态”中的高阶光子统计中的体现，以及量子干涉如何影响多光子关联。

Method: 利用“Janus态”（两种压缩真空的相干叠加）的高阶光子统计，报告了量子互补性的深刻体现。。

Result: 发现“Janus态”可以作为多光子关联的完美量子开关，由路径信息的可获得性控制。通过擦除路径信息，可以激活量子干涉，并调谐至最大破坏性。该状态可以实现高阶关联（k≥3）的完全抑制（g⁽ᵏ⁾→0），同时保持二光子关联有限。

Conclusion: 这项工作为多光子统计中的量子互补性提供了基础性演示，并为利用高斯资源设计高度有序的非经典光开辟了新途径。

Abstract: We report a profound manifestation of quantum complementarity in the
higher-order photon statistics of the ``Janus state,'' a coherent superposition
of two squeezed vacua. We find that the state acts as a perfect quantum switch
for multi-photon correlations, toggled by the availability of which-path
information. Erasing this information activates quantum interference that can
be tuned to be maximally destructive. This reveals a remarkable hierarchy of
suppression: while two-photon correlations remain finite, we prove analytically
and demonstrate numerically that it is possible to drive all higher-order
correlations ($g^{(k)}$ for $k \ge 3$) to zero. This transition from the
extreme bunching of the constituent states ($g^{(k)} \to \infty$) to a state of
profound quantum order is visualized by the emergence of negativity in the
state's Wigner function, an unambiguous signature of non-classicality. This
work provides a foundational demonstration of quantum complementarity in
multi-photon statistics and introduces a new paradigm for engineering highly
ordered, non-classical light from Gaussian resources.

</details>


### [129] [Coarse-Grained Quantum Thermodynamics: Observation-Dependent Quantities, Observation-Independent Laws](https://arxiv.org/abs/2507.15918)
*Giulia Rubino,Časlav Brukner,Gonzalo Manzano*

Main category: quant-ph

TL;DR: 量子热力学中的热力学量（如功和熵）的定义会受到测量仪器精度的影响。精度越低，这些量的值就越不精确。尽管如此，连接这些量的基本定律（如第二定律）仍然成立，这表明这些定律本身具有观测独立性。


<details>
  <summary>Details</summary>
Motivation: 质疑了物理量具有独立于观测的客观价值的传统观念，旨在探究精度限制对量子热力学定义的潜在影响。

Method: 研究了有限精度的实验仪器如何影响量子热力学中热力学量的定义，并分析了粗粒化和细粒化情景下的差异。

Result: 粗粒化热力学量可能导致与细粒化情景不同的结论，例如不可逆性或功的收益会随仪器精度显著变化。

Conclusion: 热力学量是依赖于观测的，但是连接这些量的不等式（如第二定律、耗散与可区分性之间的关系以及量子功涨落定理）却不依赖于观测。

Abstract: In both classical and quantum thermodynamics, physical quantities are
typically assigned objective values defined independently of our observations.
We then refer to the 'work performed by a gas', or the 'entropy of the gas',
regardless of how they are evaluated. Here, we question this conception in the
context of quantum thermodynamics, estimating how the definition of pivotal
thermodynamic quantities is affected by experimental instruments of limited
precision. We find that the coarse-grained thermodynamic quantities frequently
lead to different conclusions from those drawn in fine-grained scenarios. For
instance, the irreversibility of a process, or its work payoff, can
significantly vary with the instrument precision. We show nonetheless that
coarse-grained thermodynamic quantities satisfy the same relations (i.e., the
second law inequality, the relation between dissipation and distinguishability
of a process from its time-reverse, and the quantum work fluctuation theorems)
as their fine-grained counterparts. These results highlight the
observation-independence of relations linking thermodynamic quantities which
are themselves observation-dependent.

</details>


### [130] [Relaxation control of open quantum systems](https://arxiv.org/abs/2507.15948)
*Nicolò Beato,Gianluca Teza*

Main category: quant-ph

TL;DR: A new method to speed up steady-state convergence in open quantum systems by using unitary operations to cancel relaxation modes, demonstrated in a qubit chain.


<details>
  <summary>Details</summary>
Motivation: The motivation is to address the fundamental problem in experiments with open quantum systems of ensuring steady-state convergence within a given operational time window.

Method: The method involves constructing a unitary operation to cancel desired relaxation modes. An example is provided in a few-body interacting system (long-range qubit chain), considering limitations of experimentally accessible unitary operations.

Result: The devised recipe allows for controlling relaxation timescales and achieving steady-state convergence within experimental run times, with a demonstration in a few-body interacting system.

Conclusion: The paper proposes a general state preparation recipe to control relaxation timescales and achieve steady-state convergence within experimental run times by constructing a unitary operation that cancels desired relaxation modes.

Abstract: A fundamental problem in experiments with open quantum systems is to ensure
steady-state convergence within a given operational time window. Here, we
devise a general state preparation recipe to control relaxation timescales and
achieve steady-state convergence within experimental run times. We do so by
constructing a unitary operation that cancels the desired relaxation modes. We
provide an example in a few-body interacting system (long-range qubit chain),
taking into account limitations of experimentally accessible unitary operations
in quantum simulators.

</details>


### [131] [Non-Markovian Exceptional Points by Interpolating Quantum Channels](https://arxiv.org/abs/2507.16049)
*Wai Chun Wong,Bei Zeng,Jensen Li*

Main category: quant-ph

TL;DR: 本研究提出了在量子通道中生成奇异点的新方法，并在实验中成功实现。


<details>
  <summary>Details</summary>
Motivation: 虽然奇异点在非厄米系统中是重要的概念，但其在量子通道这一描述开放量子系统状态演化的最普遍框架下的存在性和性质仍未得到充分探索。本研究旨在填补这一空白。

Method: 提出了一种在量子通道中生成奇异点的通用策略，通过在不同相的量子通道之间进行插值来实现。实验上，在核磁共振量子计算机上实现了该策略，并验证了二阶奇异点的出现。

Result: 量子通道可以分为两个不同的相，它们之间的转变由奇异点的存在标志。实现了二阶奇异点，并进一步揭示了三阶奇异点的存在。

Conclusion: 本研究提出了在量子通道中生成量子奇异点的通用策略，并成功在核磁共振量子计算机上实现了二阶奇异点，通过进一步插值实现了三阶奇异点。本研究将量子通道插值确立为生成奇异点的多功能框架，并为开放量子系统中的奇异点提供了通用描述。

Abstract: Exceptional points (EPs) are special points in non-Hermitian systems where
both eigenvalues and eigenvectors coalesce. In open quantum systems, these
points are typically analyzed using effective non-Hermitian Hamiltonians or
Liouvillian superoperators. While quantum channels offer the most general
framework for describing state evolution in such systems, the existence and
properties of EPs within this setting remain largely unexplored. In this work,
we present a general strategy for generating quantum EPs for a single-qubit
setting. We show that quantum channels can be separated into two distinct
phases, with the transition between them marked by the presence of an EP. Based
on this, we propose a systematic method to realize EPs by interpolating between
quantum channels representing different phases. Experimentally, we implement
these interpolated channels on a nuclear magnetic resonance (NMR) quantum
computer and confirm the emergence of second-order EPs with high fidelity.
Extending the interpolation to three channels further reveals third-order EPs.
Our results establish quantum channel interpolation as a versatile framework
for generating EPs and provide a general description of EPs in open quantum
systems.

</details>


### [132] [Topological control of quantum speed limits](https://arxiv.org/abs/2507.15950)
*Alexander Kruchkov*

Main category: quant-ph

TL;DR: 研究了量子Fisher信息（QFI）的性质及其在量子计量学和量子速度极限中的应用。即使在无色散量子态下，QFI也具有动量分辨性。对于拓扑相，QFI项受到量子几何和拓扑不变量的限制，最大QFI由陈数 $|C|$ 控制。量子速度极限与 $\sqrt{|C|}$ 成正比。高陈数 $|C| 
（例如，在扭曲多层范德华异质结构中）的量子平台可以提高QFI容量并实现量子速度极限的控制。


<details>
  <summary>Details</summary>
Motivation: 研究量子Fisher信息（QFI）作为衡量量子计量学中量子态对调优参数变化的敏感性以及定义量子速度极限的度量。即使量子态完全无色散，QFI在动量上也是分辨的。

Method: 计算整数填充的拓扑相的量子Fisher信息（QFI），并证明每个动量分辨项受到量子几何和拓扑不变量的根本限制，最大QFI由拓扑不变量（陈数 $|C|$）控制。还发现了量子速度极限的边界，该边界在（无色散）拓扑相中与 $\sqrt{|C|}$ 成比例。

Result: 即使量子态完全无色散，QFI在动量上也是分辨的。每个动量分辨项受到量子几何和拓扑不变量的根本限制，最大QFI由拓扑不变量（陈数 $|C|$）控制。量子速度极限的边界与 $\sqrt{|C|}$ 成比例。 |C|>>1 的量子平台显著增强了量子Fisher信息容量，并提供了对量子速度极限的实际控制。 $|C|$ 越大，QFI容量越大，量子速度极限越容易控制。

Conclusion: 高陈数 $|C|$ 的量子平台（例如，具有扭曲多层范德华异质结构的平台）显著增强了量子Fisher信息容量，并提供了对量子速度极限的实际控制。

Abstract: Quantum Fisher Information (QFI) is a measure quantifying the sensitivity of
a quantum state with respect to changes in tuning parameters in quantum
metrology, and defining quantum speed limits. We show that even if the quantum
state is completely dispersionless, QFI in this state remains
momentum-resolved. We compute the QFI for topological phases at integer filling
and demonstrate that each momentum-resolved term is fundamentally bounded by
quantum geometric and topological invariants, with maximum QFI controlled by
topological invariants (Chern number $|C|$). We also finds bounds on quantum
speed limit which scales as $\sqrt{|C|}$ in a (dispersionless) topological
phase. We conclude that quantum platforms of high Chern numbers $|C| \gg 1$,
such as those featuring twisted multilayered van der Waals heterostructures,
significantly enhance capacity for quantum Fisher information, and provide
practical control over quantum speed limits.

</details>


### [133] [Fast Recovery of Niobium-based Superconducting Resonators after Laser Illumination](https://arxiv.org/abs/2507.16082)
*Chunzhen Li,Yuntao Xu,Yufeng Wu,Manuel C. C. Pace,Matthew D. LaHaye,Michael Senatore,Hong X. Tang*

Main category: quant-ph

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Interfacing superconducting microwave resonators with optical systems enables
sensitive photon detectors, quantum transducers, and related quantum
technologies. Achieving high optical pulse repetition is crucial for maximizing
the device throughput. However, light-induced deterioration, such as
quasiparticle poisoning, pair-breaking-phonon generation, and elevated
temperature, hinders the rapid recovery of superconducting circuits, limiting
their ability to sustain high optical pulse repetition rates. Understanding
these loss mechanisms and enabling fast circuit recovery are therefore
critical. In this work, we investigate the impact of optical illumination on
niobium nitride and niobium microwave resonators by immersing them in
superfluid helium-4 and demonstrate a three-order-of-magnitude faster resonance
recovery compared to vacuum. By analyzing transient resonance responses, we
provide insights into light-induced dynamics in these superconductors,
highlighting the advantages of niobium-based superconductors and superfluid
helium for rapid circuit recovery in superconducting quantum systems integrated
with optical fields.

</details>


### [134] [Impact of finite squeezing on near-term quantum computations using GKP qubits](https://arxiv.org/abs/2507.15955)
*Frederik K. Marqversen,Andreas B. Michelsen,Janus H. Wesenberg,Nikolaj T. Zinner*

Main category: quant-ph

TL;DR: 该研究首次详细模拟了基于GKP量子比特的测量型量子计算，在10dB以上压缩因子下，三比特Grover算法的性能超越了经典概率界限。


<details>
  <summary>Details</summary>
Motivation: 介绍第一个基于GKP量子比特的测量型量子计算的详细模拟，该计算在四轨格点（QRL）簇状态中进行，包含超过100个GKP模式，并探索了GKP量子计算的实际应用和性能。

Method: 使用新开发的函数矩阵乘积态（FMPS）框架来模拟GKP量子比特和连续变量量子电路，并显式建模有限压缩引起的内在相干误差源。

Result: 在5到15 dB压缩水平下进行的模拟随机基准测试与分析估计高度一致。模拟的三比特Grover算法表明，约10 dB的压缩阈值是超越经典概率界限的关键。

Conclusion: GKP超100个模式的量子计算可以在格点簇态中实现，并且在10dB以上的压缩因子下可以超越经典概率界限。

Abstract: We present the first detailed simulation of a measurement based quantum
computation based on Gottesman-Kitaev-Preskill (GKP) qubits within a quad-rail
lattice (QRL) cluster state involving over 100 GKP modes. This was enabled by
the recently developed functional matrix product states (FMPS) framework, with
which we simulate continuous-variable (CV) quantum circuits while explicitly
modelling intrinsic coherent error sources due to finite squeezing. We perform
simulated randomised benchmarking across squeezing levels between 5 and 15 dB
and find strong agreement with analytical estimates for high quality GKP
qubits. As a demonstration of practical computation, we simulate a three-qubit
Grover's algorithm within the QRL and identify a fundamental squeezing
threshold -- approximately 10 dB -- beyond which the algorithm outperforms
classical probability bounds.

</details>


### [135] [Tunneling driven by quantum light described via field Bohmian trajectories](https://arxiv.org/abs/2507.15972)
*Sangwon Kim,Seongjin Ahn,Denis V. Seletskiy,Andrey S. Moskalenko*

Main category: quant-ph

TL;DR: 本研究提出了一个描述量子光驱动隧穿的理论框架，该框架利用经典场系综和玻姆力学来解释量子光特性，并成功应用于描述扫描隧道显微镜中的电子隧穿过程。


<details>
  <summary>Details</summary>
Motivation: 尽管近期出现的强量子光（如明亮压缩真空）为量子光与物质的相互作用提供了新的视角，但理论预测与经典解释的结果惊人地一致。为了深入理解实验结果并预测新效应，需要对潜在物理机制进行更深入的理论洞察。

Method: 通过流体动力学（或称玻姆）形式，利用统计系综的经典场来描述量子光驱动的隧穿现象。将经典的非绝热隧穿理论推广，并通过玻姆轨迹的量子化光场描述来拟合电子的动力学。

Result: 本研究提出的理论框架与电子动力学的描述完美契合，能够一致且优雅地解释BSV引起电子从针尖到表面的隧穿输运，并展示了从多光子隧穿到直接隧穿的过渡。

Conclusion: 本研究提出了一个用于描述量子光驱动隧穿的理论框架，该框架通过统计系综的经典场和流体动力学（或称玻姆）形式来捕捉量子光的特性。将经典的非绝热隧穿理论推广，将单次隧穿事件描述为由系综中的经典场驱动的隧穿解束。通过玻姆轨迹的量子化光场描述，可以完美拟合电子的（低于或高于）势垒动力学，从而得到一个一致且优美的理论方法。

Abstract: Recent realization of an intense quantum light, namely bright squeezed
vacuum, opened a new perspective on quantum light-matter interaction. Several
theoretical works have appeared based on coherent state expansions of quantum
state of light to investigate non-classical driving of high-harmonic generation
in atomic gases and solids, or free-electron dynamics, but their predictions
surprisingly coincide with what one could expect from essentially classical
interpretations of the light statistics. A deeper theoretical insight into the
underlying physics is necessary for understanding of observed experimental
findings and predicting emerging effects relying on this new configuration.
Here we present a theoretical framework to describe tunneling driven by quantum
light, where the properties of such light are captured by a statistical
ensemble of classical fields via a hydrodynamic, also referred to as Bohmian,
formulation. Generalizing the quasiclassical theory of non-adiabatic tunneling
driven by classical light, a single tunneling event is described by a bundle of
tunneling solutions, each driven by a classical field corresponding to one
realization in the ensemble. Quantum statistics of light are thus imprinted on
the measured current. Fully quantum description of light via the Bohmian
trajectories of its field provides a perfect fit to the description of the
electron (under-) above-barrier dynamics in terms of (complex quasiclassical)
real classical trajectories, resulting in a consistent and elegant theoretical
approach. To illustrate this, we consider BSV-induced electron transport from
the tip to the surface in the tunneling microscope configuration demonstrating
the transition from the multiphoton to the direct tunneling regime.

</details>


### [136] [Engineering Non-Hermitian Quantum Evolution Using a Hermitian Bath Environment](https://arxiv.org/abs/2507.16286)
*Mahmoud A. Selim,Max Ehrhardt,Yuqiang Ding,Qi Zhong,Armando Perez Leija,Konstantinos G. Makris,Ramy El Ganainy,Sahin K. Ozdemir,Matthias Heinrich,Alexander Szameit,Demetrios N. Christodoulides,Mercedeh Khajavikhan*

Main category: quant-ph

TL;DR: 本研究提出了一种在完全厄米的光子平台上构建非厄米子系统的方法，通过离散到连续的耦合和兰佐斯变换实现可控的指数衰减，并成功在单光子和多光子激发机制下复制了非厄米动力学，为量子浴工程在量子技术中的应用提供了新的途径。


<details>
  <summary>Details</summary>
Motivation: 通过非厄米子系统哈密顿量构建量子浴网络，近来已成为一个有前途的策略，用于量子比特冷却、状态稳定和容错量子计算。然而，在扩展这些系统的规模时，如何在保持对其复杂互连（尤其是在光学领域）的精确控制，在理论建模和物理实现方面都带来了重大挑战。

Method: 通过利用量子和数学物理的原理，我们提出了一个在完全厄米的光子平台上构建非厄米子系统的系统性框架。通过离散到连续的耦合和兰佐斯变换，在有限的一维波导链中实现了在没有实际吸收损耗的情况下可控的指数衰减。

Result: 我们实现了具有奇异性时间对称性的量子系统，并通过实验证明，在单光子和多光子激发机制下，这些人工浴环境都能精确地复制非厄米排列的动力学。

Conclusion: 该方法为量子浴工程的理论模型和实验实现之间架起了一座桥梁，为在先进的信息处理和新兴的量子技术中利用量子浴工程铺平了道路。

Abstract: Engineering quantum bath networks through non-Hermitian subsystem
Hamiltonians has recently emerged as a promising strategy for qubit cooling,
state stabilization, and fault-tolerant quantum computation. However, scaling
these systems while maintaining precise control over their complex
interconnections, especially in the optical domain, poses significant
challenges in both theoretical modeling and physical implementation. In this
work, drawing on principles from quantum and mathematical physics, we introduce
a systematic framework for constructing non-Hermitian subsystems within
entirely Hermitian photonic platforms. In particular, controlled exponential
decay without actual absorption loss is realized in finite 1-D waveguide chains
through discrete-to-continuum coupling and Lanczos transformations. Using this
new methodology, we implement parity-time symmetric quantum systems and
experimentally demonstrate that these artificial bath environments accurately
replicate the dynamics of non-Hermitian arrangements in both single- and
multi-photon excitation regimes. Since the non-Hermitian subsystem response
deterministically arises from an artificially built Hermitian bath, the quantum
evolution can be monitored via post-selection in this fully conservative
configuration. This approach bridges the gap between theoretical models and
experimental realizations, thus paving the way for exploiting quantum bath
engineering in advanced information processing and emerging quantum
technologies.

</details>


### [137] [High-dimensional graphs convolution for quantum walks photonic applications](https://arxiv.org/abs/2507.15988)
*Roman Abramov,Leonid Fedichkin,Dmitry Tsarev,Alexander Alodjants*

Main category: quant-ph

TL;DR: 提出一种新的图卷积方法，用于在量子算法中模拟量子游走，可在超循环图上节省量子比特。


<details>
  <summary>Details</summary>
Motivation: 为了解决在量子算法中模拟量子游走时可能需要大量量子比特的问题，本研究旨在提出一种更有效的方法来处理图的卷积问题。

Method: 提出了一种基于Kronecker乘积的图卷积新方法，该方法可以保留量子游走动力学，并适用于格点和超循环图。

Result: 通过数值实验验证了所提出的方法在超循环图上的有效性，并与经典随机游走进行了比较。

Conclusion: 该方法通过数值实验在超循环图上对量子和经典随机游走进行了验证，结果表明该方法能够有效处理卷积问题并保留量子游走动力学，有望在量子算法中节省大量量子比特资源。

Abstract: Quantum random walks represent a powerful tool for the implementation of
various quantum algorithms. We consider a convolution problem for the graphs
which provide quantum and classical random walks. We suggest a new method for
lattices and hypercycle convolution that preserves quantum walk dynamics. Our
method is based on the fact that some graphs represent a result of Kronecker's
product of line graphs. We support our methods by means of various numerical
experiments that check quantum and classical random walks on hypercycles and
their convolutions. Our findings may be useful for saving a significant number
of qubits required for algorithms that use quantum walk simulation on quantum
devices.

</details>


### [138] [Towards a pulse-level intermediate representation for diverse quantum control systems](https://arxiv.org/abs/2507.15995)
*Jude Alnas,Aniket S. Dalvi,Kenneth R. Brown*

Main category: quant-ph

TL;DR: pulselib 是一个用于量子控制的中间表示（IR），可以跨平台使用，并且比其他 IR 更快。


<details>
  <summary>Details</summary>
Motivation: 为了实现跨不同平台的量子软件的快速开发和重用，需要一种独立于系统的中间表示（IR），用于量子控制系统的脉冲级编程。

Method: 本文档演示了 pulselib 作为量子控制系统的脉冲级编程的独立于系统的中间表示（IR）的效用。我们实现了基于图的 IR 和转译流水线，用于两个独特的频率合成器，并与现有的 IR 进行了性能基准测试。这些流水线中的关键要素是 munchers 和可参数化脉冲调度。前者编码目标特定的约束，并将本质上与系统无关的脉冲描述转换为任意低级表示，后者能够实现调度的重用，与特定设备的替代方案相比，可以节省转译时间。

Result: 基准测试显示，pulselib 提供的性能与快速的、特定于设备的 IR 相当，同时提供了比现有 IR 高 4.5 倍的速度。对于高度参数化的应用程序，pulselib 提供了有利的转译时间与参数数量的可扩展性，并且相对于现有 IR 的速度提升可能比优化的、特定设备的技术的速度提升大 69%。

Conclusion: pulselib作为一个候选IR，在性能上可与现有的特定设备IR媲美，同时比现有的IR快4.5倍。对于高度参数化的应用程序，pulselib在转译时间方面具有良好的可扩展性，并且在与现有IR相比时，速度提升可能比优化的、特定设备的技术大69%。

Abstract: A system-independent intermediate representation (IR) for pulse-level
programming of quantum control systems is required to enable rapid development
and reuse of quantum software across diverse platforms. In this work, we
demonstrate the utility of pulselib as a candidate for such an IR. We implement
graph-based IRs and transpilation pipelines for two unique frequency
synthesizers and benchmark performance against existing IRs. Key elements of
these pipelines are munchers and parametrizable pulse schedules. The former
encodes target-specific constraints and allows translation of fundamentally
system-agnostic pulse descriptions to arbitrary low-level representations, and
the latter enables schedule reuse that produces savings in transpilation time
relative to device-specific alternatives. Benchmarks reveal that pulselib
provides performance comparable to fast, device-specific IRs while providing a
speedup of up to 4.5x over existing IRs. For highly parametrized applications,
pulselib provides favorable scaling of transpilation times with respect to the
number of parameters and can exhibit speedups relative to existing IRs up to
69% larger than speedups provided by optimized, device-specific techniques.

</details>


### [139] [Automated Design of Structured Variational Quantum Circuits with Reinforcement Learning](https://arxiv.org/abs/2507.16001)
*Gloria Turati,Simone Foderà,Riccardo Nembrini,Maurizio Ferrari Dacrema,Paolo Cremonesi*

Main category: quant-ph

TL;DR: Reinforcement learning methods (RLVQC Block and RLVQC Global) create better quantum circuit designs than traditional methods like QAOA for optimization problems. RLVQC Block is better overall, while RLVQC Global creates shorter circuits. The best approach is a balance between fixed and flexible circuit designs.


<details>
  <summary>Details</summary>
Motivation: The effectiveness of Variational Quantum Algorithms (VQAs) heavily relies on the design of their circuit ansatze, which are often created using heuristic methods. This work aims to improve ansatz design by employing reinforcement learning.

Method: The paper introduces two reinforcement learning-based methods, RLVQC Global and RLVQC Block, which treat variational quantum circuit synthesis as a sequential decision-making problem. Both methods use the Proximal Policy Optimization (PPO) algorithm and empirical measurement outcomes as state observations. RLVQC Block creates QAOA-generalizing ansatze by discovering a two-qubit block applied to interacting qubit pairs, while RLVQC Global adds gates without constraints on qubit interactions.

Result: Both RLVQC methods showed strong performance on QUBO instances. RLVQC Block consistently outperformed QAOA and generally surpassed RLVQC Global. RLVQC Block produced circuits with depth comparable to QAOA, while RLVQC Global found significantly shorter circuits.

Conclusion: RLVQC Block and RLVQC Global are effective reinforcement learning-based methods for designing variational quantum circuit ansatze, with RLVQC Block consistently outperforming QAOA and RLVQC Global on QUBO instances. The study suggests that problem-specific ansatz discovery via RL is promising, and an optimal design lies between rigid and unconstrained architectures.

Abstract: Variational Quantum Algorithms (VQAs) are among the most promising approaches
for leveraging near-term quantum hardware, yet their effectiveness strongly
depends on the design of the underlying circuit ansatz, which is typically
constructed with heuristic methods. In this work, we represent the synthesis of
variational quantum circuits as a sequential decision-making problem, where
gates are added iteratively in order to optimize an objective function, and we
introduce two reinforcement learning-based methods, RLVQC Global and RLVQC
Block, tailored to combinatorial optimization problems. RLVQC Block creates
ansatzes that generalize the Quantum Approximate Optimization Algorithm (QAOA),
by discovering a two-qubits block that is applied to all the interacting qubit
pairs. While RLVQC Global further generalizes the ansatz and adds gates
unconstrained by the structure of the interacting qubits. Both methods adopt
the Proximal Policy Optimization (PPO) algorithm and use empirical measurement
outcomes as state observations to guide the agent. We evaluate the proposed
methods on a broad set of QUBO instances derived from classical graph-based
optimization problems. Our results show that both RLVQC methods exhibit strong
results with RLVQC Block consistently outperforming QAOA and generally
surpassing RLVQC Global. While RLVQC Block produces circuits with depth
comparable to QAOA, the Global variant is instead able to find significantly
shorter ones. These findings suggest that reinforcement learning methods can be
an effective tool to discover new ansatz structures tailored for specific
problems and that the most effective circuit design strategy lies between rigid
predefined architectures and completely unconstrained ones, offering a
favourable trade-off between structure and adaptability.

</details>


### [140] [Minor Embedding for Quantum Annealing with Reinforcement Learning](https://arxiv.org/abs/2507.16004)
*Riccardo Nembrini,Maurizio Ferrari Dacrema,Paolo Cremonesi*

Main category: quant-ph

TL;DR: Reinforcement learning (RL) offers a promising, flexible, and scalable solution for the computationally expensive minor embedding problem in quantum annealing (QA), outperforming traditional heuristics.


<details>
  <summary>Details</summary>
Motivation: Existing heuristics for minor embedding in QA are computationally expensive, scale poorly, and are difficult to generalize across different problem graphs and hardware topologies.

Method: Proposed a RL-based approach using a Proximal Policy Optimization agent to treat minor embedding as a sequential decision-making problem, iteratively mapping problem variables to hardware qubits.

Result: The RL agent consistently produced valid minor embeddings with reasonably efficient qubit usage, particularly on the Zephyr topology, and showed scalability to moderate problem sizes.

Conclusion: RL provides a flexible and general-purpose framework for minor embedding in QA, demonstrating scalability to moderate problem sizes and adaptability to different graph structures.

Abstract: Quantum Annealing (QA) is a quantum computing paradigm for solving
combinatorial optimization problems formulated as Quadratic Unconstrained
Binary Optimization (QUBO) problems. An essential step in QA is minor
embedding, which maps the problem graph onto the sparse topology of the quantum
processor. This process is computationally expensive and scales poorly with
increasing problem size and hardware complexity. Existing heuristics are often
developed for specific problem graphs or hardware topologies and are difficult
to generalize. Reinforcement Learning (RL) offers a promising alternative by
treating minor embedding as a sequential decision-making problem, where an
agent learns to construct minor embeddings by iteratively mapping the problem
variables to the hardware qubits. We propose a RL-based approach to minor
embedding using a Proximal Policy Optimization agent, testing its ability to
embed both fully connected and randomly generated problem graphs on two
hardware topologies, Chimera and Zephyr. The results show that our agent
consistently produces valid minor embeddings, with reasonably efficient number
of qubits, in particular on the more modern Zephyr topology. Our proposed
approach is also able to scale to moderate problem sizes and adapts well to
different graph structures, highlighting RL's potential as a flexible and
general-purpose framework for minor embedding in QA.

</details>


### [141] [Entanglement-Efficient Compilation of Quantum Circuits over Large-Scale Quantum Networks](https://arxiv.org/abs/2507.16036)
*Felix Burt,Kuan-Cheng Chen,Kin K. Leung*

Main category: quant-ph

TL;DR: 本研究提出了一种改进的分布式量子计算电路划分方法，考虑了网络拓扑约束，降低了纠缠成本和优化时间，并通过粗粒化技术实现了向大规模量子网络的扩展。


<details>
  <summary>Details</summary>
Motivation: 随着量子计算机的发展，需要研究分布式量子计算系统以克服量子处理单元（QPU）的扩展性挑战。然而，大量的QPU互联会带来网络层面的连接性约束，路径长度的增加会增加纠缠共享的难度，从而增加了量子电路划分问题的复杂性，因为在不同网络拓扑和链路下，端节点之间生成纠缠的成本也不同。

Method: 本研究提出了一种对现有面向全连接网络的划分方案进行的简单修改，该方案能够高效地同时考虑网络拓扑和现有链路对纠缠共享带来的影响。此外，研究中还采用了网络粗粒化和问题粗粒化技术来扩展到大规模量子网络。

Result: 通过在不同网络拓扑上对各种量子电路进行性能测试，本研究提出的方案在纠缠需求和优化时间方面均表现出色，大多数情况下相比现有最先进的方法能够实现更低的纠缠成本。同时，粗粒化方法在大多数情况下能够以显著降低的运行时间获得更优的解决方案质量。

Conclusion: 本研究提出了一种改进的量子电路划分方案，该方案考虑了网络拓扑和现有链路的限制，可以有效地降低纠缠需求并减少优化时间。通过结合网络和问题的粗粒化技术，研究表明该方法在大多数情况下能以显著更短的运行时间获得更高质量的解决方案，为扩展到大规模量子网络提供了有效途径。

Abstract: Quantum computers face inherent scaling challenges, a fact that necessitates
investigation of distributed quantum computing systems, whereby scaling is
achieved through interconnection of smaller quantum processing units. However,
connecting large numbers of QPUs will eventually result in connectivity
constraints at the network level, where the difficulty of entanglement sharing
increases with network path lengths. This increases the complexity of the
quantum circuit partitioning problem, since the cost of generating entanglement
between end nodes varies with network topologies and existing links. We address
this challenge using a simple modification to existing partitioning schemes
designed for all-to-all connected networks, that efficiently accounts for both
of these factors. We investigate the performance in terms of entanglement
requirements and optimisation time of various quantum circuits over different
network topologies, achieving lower entanglement costs in the majority of cases
than state-of-the-art methods. We provide techniques for scaling to large-scale
quantum networks employing both network and problem coarsening. We show that
coarsened methods can achieve improved solution quality in most cases with
significantly lower run-times than direct partitioning methods.

</details>


### [142] [Schr{ö}dinger cat state formation in small bosonic Josephson junctions at finite temperatures and dissipation](https://arxiv.org/abs/2507.16032)
*D V Tsarev,D V Ansimov,S A Podoshvedov,A P Alodjants*

Main category: quant-ph

TL;DR: 本研究证明了在玻色子约瑟夫森量子比特系统中，在零温度极限下，通过量子相变可以形成薛定谔猫态，并且随着粒子数增加，可以形成N00N态。研究还确定了在有限温度和弱耗散下形成薛定谔猫态的临界温度，该温度低于原子凝聚温度，并且是通过量子隧穿现象实现的。


<details>
  <summary>Details</summary>
Motivation: 本研究旨在探讨在方便的玻色子约瑟夫森量子比特（BJJ）系统中形成薛定谔猫（SC）态和N00N态的可行性。

Method: 研究利用了有效的势能方法，并通过维格纳函数方法来研究了薛定谔猫态和N00N态的形成过程。此外，还对有限温度和弱耗散下的薛定谔猫态形成进行了数值估算。

Result: 研究表明，在零温度极限下，薛定谔猫态是由于量子相变形成的。随着粒子数的增加，薛定谔猫态的两个半球分离度会增加，并形成N00N态。在有限温度和弱耗散下，存在一个临界温度，该温度低于原子凝聚温度，并决定了经典激活过程到量子隧穿现象形成薛定谔猫态的二阶相变。

Conclusion: 本研究证明了在零温度极限下，当非线性强度与约瑟夫森耦合参数相当时，会发生量子相变，从而形成薛定谔猫态。研究还表明，随着粒子数的增加，薛定谔猫态的两个半球分离度会增加，并形成N00N态。在有限温度和弱耗散下，存在一个临界温度，该温度决定了从经典激活过程到通过量子隧穿现象形成薛定谔猫态的二阶相变。

Abstract: In this work, we consider the feasibility of Schr{\"o}dinger cat (SC) and
$N00N$ states formation by a convenient bosonic Josephson junction (BJJ) system
in two-mode approximation. Starting with purely quantum description of two-mode
Bose-Einstein condensate we investigate the effective potential approach that
provides an accurate analytical description for the system with a large number
of particles. We show that in the zero temperature limit SC states result from
a quantum phase transition that occurs when the nonlinear strength becomes
comparable with the Josephson coupling parameter. The Wigner function approach
demonstrates the growth of the SC state halves separation and formation of
$N00N$-like states (a Fock state superposition) with the particle number
increase. We examine the possibility to attain the SC state at finite
temperatures and a weak dissipation leading to appearing of some critical
temperature; it defines the second-order phase transition from classical
activation process to the SC state formation through the quantum tunneling
phenomenon. Numerical estimations demonstrate that the critical temperature is
sufficiently below the temperature of atomic condensation. The results obtained
may be useful for experimental observation of SC states with small condensate
Josephson junctions.

</details>


### [143] [Ultrastable, low-error dynamic polarization encoding of deterministically generated single photons](https://arxiv.org/abs/2507.16578)
*Joscha Hanel,Zenghui Jiang,Jipeng Wang,Frederik Benthin,Tom Fandrich,Eddy Patrick Rugeramigabo,Raphael Joos,Michael Jetter,Simone Luca Portalupi,Jingzhong Yang,Michael Zopf,Peter Michler,Fei Ding*

Main category: quant-ph

TL;DR: 与之前依赖于易受环境影响的马赫-曾德尔或迈克尔逊干涉仪的编码器相比，我们使用Sagnac干涉仪演示了一种用于单光子量子比特的偏振编码器，从而实现了创纪录的低错误率。


<details>
  <summary>Details</summary>
Motivation: 高速在单光子上写入信息对于量子通信和基于测量的光量子计算等量子应用至关重要。

Method: 我们首次演示了一种基于自由空间Sagnac干涉仪的单光子量子比特的偏振编码器，它具有固有的相位稳定并且克服了先前的错误率限制。

Result: 使用量子点发射的电信波长单光子，在152 MHz的重复速率下通过编码器进行调制，实现了0.69(2)%的量子比特错误率，这是迄今为止单光子上高速信息编码的最低错误率记录。

Conclusion: 这项工作代表了朝着具有单光子源的鲁棒、可扩展和低错误率的量子信息处理迈出的关键一步。

Abstract: The ability to inscribe information on single photons at high speeds is a
crucial requirement for quantum applications such as quantum communication and
measurement-based photonic quantum computation. Nowadays, most experimental
implementations employ phase modulators in single-pass, Mach-Zehnder
interferometer or Michelson interferometer configurations to encode information
on photonic qubits. However, these approaches are intrinsically sensitive to
environmental influences, limiting the achievable quantum error rates in
practice. We report on the first demonstration of a polarization encoder for
single-photon qubits based on a free-space Sagnac interferometer, showcasing
inherent phase stability and overcoming previous error rate limitations.
Telecom-wavelength single photons emitted by a quantum dot are modulated by the
encoder under a repetition rate of 152 MHz. A quantum bit error rate of
0.69(2)% is achieved, marking the lowest error rate reported to date for
high-speed information encoding on single photons. This work represents a key
advance towards robust, scalable, and low-error quantum information processing
with single photon sources.

</details>


### [144] [Unidirectional perfect absorption induced by chiral coupling in spin-momentum locked waveguide magnonics](https://arxiv.org/abs/2507.16698)
*Jie Qian,Qi Hong,Zi-Yuan Wang,Wen-Xin Wu,Yihao Yang,C. -M. Hu,J. Q. You,Yi-Pu Wang*

Main category: quant-ph

TL;DR: 手性耦合可实现单向完美吸收，本研究利用YIG球和SSPPs实现此现象，并为相关技术提供新平台。


<details>
  <summary>Details</summary>
Motivation: 手性耦合为控制和利用光-物质相互作用开辟了新途径，本研究旨在利用手性耦合实现单向完美吸收。

Method: 通过将钇铁石榴石（YIG）球中的磁振子模式与由仿表面等离激元激子（SSPPs）支撑的自旋动量锁定波导模式耦合，实现了手性磁-光耦合。

Result: 通过耦合YIG球中的磁振子模式和SSPPs中的光子模式，实现了对微波单向传播的完美吸收，并提出通过增加YIG球数量实现多频吸收。

Conclusion: 该研究展示了手性耦合在实现单向完美吸收方面的潜力，并提出了一种利用自旋动量锁定器件探索和利用手性光-物质相互作用的新平台。

Abstract: Chiral coupling opens new avenues for controlling and exploiting light-matter
interactions. We demonstrate that chiral coupling can be utilized to achieve
unidirectional perfect absorption. In our experiments, chiral magnon-photon
coupling is realized by coupling the magnon modes in yttrium iron garnet (YIG)
spheres with spin-momentum-locked waveguide modes supported by spoof surface
plasmon polaritons (SSPPs). These photon modes exhibit transverse spin, with
the spin direction determined by the propagation direction. Due to the
intrinsic spin properties of the magnon mode, it exclusively couples with
microwaves traveling in one direction, effectively suppressing the reflection
channel. Under the critical coupling condition, transmission is also
eliminated, resulting in unidirectional perfect absorption. By incorporating
additional YIG spheres, bidirectional and multi-frequency perfect absorption
can be achieved. Our work introduces a novel platform for exploring and
harnessing chiral light-matter interactions within spin-momentum locked
devices, offering a paradigm for unidirectional signal processing and energy
harvesting technologies.

</details>


### [145] [Adaptive Bayesian Single-Shot Quantum Sensing](https://arxiv.org/abs/2507.16477)
*Ivana Nikoloska,Ruud Van Sloun,Osvaldo Simeone*

Main category: quant-ph

TL;DR: 研究提出了一种基于贝叶斯推理和活动信息增益最大化的自适应量子传感协议，优化了传感策略，支持单探针和多探针融合。


<details>
  <summary>Details</summary>
Motivation: 量子传感在测量精度方面超越经典传感器，但寻找合适的传感探针和测量方案是一个经典上难以处理的任务，需要优化高维希尔伯特空间。文章旨在解决这一优化问题。

Method: 提出了一种自适应协议，使用贝叶斯推理和最大化活动信息增益来优化传感策略，并支持多量子传感代理的估计融合。

Result: 提出了一种适用于非渐近 regimes 的变分方法，并扩展支持多量子传感代理的估计融合。

Conclusion: 该研究提出了一种自适应协议，利用贝叶斯推理通过最大化活动信息增益来优化量子传感策略，适用于单探测器和多探测器融合的非渐近场景。

Abstract: Quantum sensing harnesses the unique properties of quantum systems to enable
precision measurements of physical quantities such as time, magnetic and
electric fields, acceleration, and gravitational gradients well beyond the
limits of classical sensors. However, identifying suitable sensing probes and
measurement schemes can be a classically intractable task, as it requires
optimizing over Hilbert spaces of high dimension. In variational quantum
sensing, a probe quantum system is generated via a parameterized quantum
circuit (PQC), exposed to an unknown physical parameter through a quantum
channel, and measured to collect classical data. PQCs and measurements are
typically optimized using offline strategies based on frequentist learning
criteria. This paper introduces an adaptive protocol that uses Bayesian
inference to optimize the sensing policy via the maximization of the active
information gain. The proposed variational methodology is tailored for
non-asymptotic regimes where a single probe can be deployed in each time step,
and is extended to support the fusion of estimates from multiple quantum
sensing agents.

</details>


### [146] [Derivation of the Loop Hafnian Generating Function for Arbitrary Symmetric Matrices via Gaussian Integration](https://arxiv.org/abs/2507.16100)
*Sergey V. Tarasov*

Main category: quant-ph

TL;DR: 量子光学方法导出的用于环形哈夫尼矩阵的生成函数对任意对称矩阵是有效的


<details>
  <summary>Details</summary>
Motivation: 展示最近提出的用于环形哈夫尼矩阵的生成函数，最初是使用量子光学方法为一类受限的矩阵导出的，实际上对于任意对称矩阵都是有效的

Method: 利用高斯积分并且不依赖于量子高斯态的协方差矩阵的任何附加性质

Result: 该生成函数对于任意对称矩阵是有效的

Conclusion: 该理论对任意对称矩阵是有效的

Abstract: This short note shows that the recently proposed generating function for loop
hafnians -- originally derived using quantum-optical methods for a restricted
class of matrices -- is in fact valid for arbitrary symmetric matrices. The
proof relies solely on Gaussian integration and does not assume any additional
properties inherited from the covariance matrices of quantum Gaussian states.

</details>


### [147] [Einstein's Electron and Local Branching: Unitarity Does not Require Many-Worlds](https://arxiv.org/abs/2507.16123)
*Xing M. Wang*

Main category: quant-ph

TL;DR: 爱因斯坦的思想实验通过单电子源和封闭探测器阵列被重新审视，为多世界诠释和分支希尔伯特子空间诠释提供了经验比较，并提出了一种不涉及坍缩或全局分裂的局域单一性分支新观点。


<details>
  <summary>Details</summary>
Motivation: 本文旨在直接进行多世界诠释（MWI）和分支希尔伯特子空间诠释（BHSI）的经验比较，并探讨了量子测量和分支的本质。

Method: 本研究利用了现代传感器可实现的单电子源和不透明半球形探测器阵列，对爱因斯坦1927年的电子衍射思想实验进行了重新审视。

Result: 在封闭系统中，所有量子事件（分支、相互作用、分离和重新定位）都发生在局部系统中，并且可以通过探测器统计数据直接观察到通过分支权重自然出现的玻恩规则。

Conclusion: 该分析挑战了单一性需要平行世界存在的观点，而是主张一种更简单的观点：即不存在坍缩或全局分裂的局域单一性分支。

Abstract: We revisit the 1927 thought experiment of Einstein on electron diffraction,
using a single-electron source and an opaque hemispheric detector array, now
achievable with modern sensors. In this fully enclosed system, where no signals
escape the hemisphere, we provide a direct empirical comparison of the
Many-Worlds Interpretation (MWI) and the Branched Hilbert Subspace
Interpretation (BHSI). Both maintain unitarity without invoking wavefunction
collapse, as in the Copenhagen Interpretation (CI), but differ ontologically:
MWI proposes irreversible global branching into parallel worlds, while BHSI
describes local, potentially reversible branching into decohered subspaces. In
this setup, all quantum events (branching, engagement, disengagement, and
relocation) occur entirely within the local system, and the Born rule,
naturally emerging through branch weights, can be observed in detector
statistics. To explore branching dynamics more thoroughly, we suggest an
enhanced dual-layer experimental setup with an inner transparent detector.
Because the electron transit time between layers is shorter than the average
response times of the inner sensors, this allows for a crucial test of
measurement timing and potential anomalies, such as delayed or uncommitted
choices. Our analysis challenges the notion that unitarity necessitates
parallel worlds, instead advocating for a simpler view: local, unitary
branching without collapse or global splitting.

</details>


### [148] [Optimal schedule of multi-channel quantum Zeno dragging with application to solving the k-SAT problem](https://arxiv.org/abs/2507.16128)
*Yipei Zhang,Alain Sarlette,Philippe Lewalle,Tathagata Karmakar,K. Birgitta Whaley*

Main category: quant-ph

TL;DR: 量子芝诺拖拽通过频繁测量和绝热类测量基调制来制备一组可观测量。本研究深入分析了使用广义测量（同时测量一组非对易可观测量）的多通道齐纳拖拽，以将量子态拖向目标子空间。具体地，以测量驱动的k-SAT问题为例，计算了收敛时间的解析上限，并应用最优控制理论获得了最优拖拽调度。


<details>
  <summary>Details</summary>
Motivation: 为了更深入地分析多通道齐纳拖拽，并为量子信息任务（如测量驱动的量子算法）设计最优拖拽调度。

Method: 1. 提出了使用广义测量（同时测量一组随时间缓慢变化的非对易可观测量）的多通道齐纳拖拽分析方法。
2. 计算了收敛时间的解析上限，并考虑了有限测量时间分辨率的影响。
3. 应用最优控制理论获得了最优拖拽调度，该调度在低维情况下可以降低收敛时间。

Result: 1. 提供了多通道齐纳拖拽的理论基础和优化方法。
2. 确定了测量驱动的量子算法的最优拖拽调度。

Conclusion: 该研究为多通道齐纳拖拽及其优化提供了理论基础，并为包括测量驱动的量子算法在内的量子信息任务设计最优拖拽调度提供了指导。

Abstract: Quantum Zeno dragging enables the preparation of common eigenstates of a set
of observables by frequent measurement and adiabatic-like modulation of the
measurement basis. In this work, we present a deeper analysis of multi-channel
Zeno dragging using generalized measurements, i.e. simultaneously measuring a
set of non-commuting observables that vary slowly in time, to drag the state
towards a target subspace. For concreteness, we will focus on a
measurement-driven approach to solving k-SAT problems as examples. We first
compute some analytical upper bounds on the convergence time, including the
effect of finite measurement time resolution. We then apply optimal control
theory to obtain the optimal dragging schedule that lower bounds the
convergence time, for low-dimensional settings. This study provides a
theoretical foundation for multi-channel Zeno dragging and its optimization,
and also serves as a guide for designing optimal dragging schedules for quantum
information tasks including measurement-driven quantum algorithms.

</details>


### [149] [Practical blueprint for low-depth photonic quantum computing with quantum dots](https://arxiv.org/abs/2507.16152)
*Ming Lai Chan,Aliki Anna Capatos,Peter Lodahl,Anders Søndberg Sørensen,Stefano Paesani*

Main category: quant-ph

TL;DR: 利用量子点和线性光学，通过融合确定性光子发射、自适应重复成功融合和优化的架构设计，提出了一种可行的、低光学深度的、基于发射器的容错光量子计算机蓝图。


<details>
  <summary>Details</summary>
Motivation: 为了克服现有基于光子的大规模量子计算在访问概率光子源、易受光子损耗影响以及需要大规模多路复用方面的限制，提出了一种更优选的确定性光子源方案。

Method: 提出了一种融合确定性光子发射、自适应重复成功融合和优化架构设计的方法，并详细介绍了资源状态生成、融合网络、实验脉冲序列以及逻辑量子比特制备的资源估算。

Result: 研究模拟了容错的误差阈值，并估计一个逻辑时钟周期的纠错可以在几微秒内完成，该时间与码距呈线性关系。 证明了该方案可以实现低光学深度、基于发射器的容错光量子计算机。

Conclusion: 该研究提出了一个利用量子点和线性光学构建的光量子计算机的完整蓝图，该计算机具有低光学深度、基于发射器的容错能力。

Abstract: Fusion-based quantum computing is an attractive model for fault-tolerant
computation based on photonics requiring only finite-sized entangled resource
states followed by linear-optics operations and photon measurements.
Large-scale implementations have so far been limited due to the access only to
probabilistic photon sources, vulnerability to photon loss, and the need for
massive multiplexing. Deterministic photon sources offer an alternative and
resource-efficient route. By synergistically integrating deterministic photon
emission, adaptive repeat-until-success fusions, and an optimised architectural
design, we propose a complete blueprint for a photonic quantum computer using
quantum dots and linear optics. It features time-bin qubit encoding,
reconfigurable entangled-photon sources, and a fusion-based architecture with
low optical connectivity, significantly reducing the required optical depth per
photon and resource overheads. We present in detail the hardware required for
resource-state generation and fusion networking, experimental pulse sequences,
and exact resource estimates for preparing a logical qubit. We estimate that
one logical clock cycle of error correction can be executed within
microseconds, which scales linearly with the code distance. We also simulate
error thresholds for fault-tolerance by accounting for a full catalogue of
intrinsic error sources found in real-world quantum dot devices. Our work
establishes a practical blueprint for a low-optical-depth, emitter-based
fault-tolerant photonic quantum computer.

</details>


### [150] [Pulse-Level Simulation of Crosstalk Attacks on Superconducting Quantum Hardware](https://arxiv.org/abs/2507.16181)
*Syed Emad Uddin Shubha,Tasnuva Farheen*

Main category: quant-ph

TL;DR: 研究了量子计算机中的硬件串扰攻击，并提出了缓解方法。


<details>
  <summary>Details</summary>
Motivation: 多租户超导量子计算机中的硬件串扰对安全构成严重威胁，允许攻击者通过注入精心设计的脉冲在租户边界之间引发有针对性的错误。

Method: 通过基于仿真的研究，在脉冲级别分析了主动串扰攻击，模拟了三量子比特系统的时变动力学，并检查了两种攻击策略（攻击者优先和受害者优先），以确定导致最大逻辑错误的脉冲和耦合配置。

Result: 协议级别的实验表明，某些协议极易受到这些攻击，而其他协议则具有弹性，基于这些发现，讨论了检测和缓解的实际方法。

Conclusion: 为提高量子云平台的安全性，提出并讨论了用于检测和缓解硬件串扰攻击的实际方法。

Abstract: Hardware crosstalk in multi-tenant superconducting quantum computers poses a
severe security threat, allowing adversaries to induce targeted errors across
tenant boundaries by injecting carefully engineered pulses. We present a
simulation-based study of active crosstalk attacks at the pulse level,
analyzing how adversarial control of pulse timing, shape, amplitude, and
coupling can disrupt a victim's computation. Our framework models the
time-dependent dynamics of a three-qubit system in the rotating frame,
capturing both always-on couplings and injected drive pulses. We examine two
attack strategies: attacker-first (pulse before victim operation) and
victim-first (pulse after), and systematically identify the pulse and coupling
configurations that cause the largest logical errors. Protocol-level
experiments on quantum coin flip and XOR classification circuits show that some
protocols are highly vulnerable to these attacks, while others remain robust.
Based on these findings, we discuss practical methods for detection and
mitigation to improve security in quantum cloud platforms.

</details>


### [151] [Statistical Assertions for Debugging Quantum Circuits and States in CUDA-Q](https://arxiv.org/abs/2507.16255)
*Jocelyn Li,Ella Rubinshtein,Margaret Martonosi*

Main category: quant-ph

TL;DR: 为CUDA-Q提供基于统计断言的调试工作流，以提高量子电路调试的效率和准确性。


<details>
  <summary>Details</summary>
Motivation: 量子计算的发展吸引了越来越多的开发者设计、编码和模拟量子电路。然而，调试量子电路，特别是随着电路规模和复杂性的增大，存在着挑战。由于缺乏有效的调试工作流，开发者被迫手动检查电路和分析各种量子态，这既耗时又容易出错。

Method: 提出了一种基于统计断言的CUDA-Q调试工作流。通过在量子电路上插入统计断言，该工具可以提供关于量子比特在电路中任何时间点的状态的宝贵见解，跟踪它们的演变，并帮助检测与预期行为的偏差。此外，通过结合使用Fisher精确检验和蒙特卡洛方法，而不是卡方检验，改进了状态断言的可靠性和准确性。

Result: 与基于卡方检验的方法相比，所提出的方法提高了状态断言的可靠性和准确性。该研究还检查了CUDA-Q独特的基于内核的编程模型对其调试工具设计的潜在影响。

Conclusion: 该研究为CUDA-Q提供了一个实用的解决方案，解决了其可用性方面的不足，为更可靠、更高效的量子软件开发铺平了道路。

Abstract: As quantum computing continues to mature, more developers are designing,
coding, and simulating quantum circuits. A challenge exists, however, in
debugging quantum circuits, particularly as they scale in size and complexity.
Given the lack of effective debugging workflows, developers are forced to
manually inspect their circuits and analyze various quantum states, which is
error-prone and time-consuming.
  In this research, we present a statistical assertion-based debugging workflow
for CUDA-Q. CUDA-Q has gained popularity due to its ability to leverage GPUs to
accelerate quantum circuit simulations; this allows circuits to scale to larger
depths and widths, where they can be particularly hard to debug by hand.
Inspired by and building from prior Qiskit-based debuggers, our work allows
CUDA-Q users to verify quantum program correctness with greater ease. Through
the insertion of statistical assertions within a quantum circuit, our tool
provides valuable insights into the state of qubits at any point within a
circuit, tracks their evolution, and helps detect deviations from expected
behavior. Furthermore, we improve the reliability and accuracy of the product
state assertion by using a combination of Fisher's exact test and the Monte
Carlo Method instead of a chi-square test, and examine the impact of CUDA-Q's
distinct kernel-based programming model on the design of our debugging tool.
This work offers a practical solution to one of CUDA-Q's usability gaps, paving
the way for more reliable and efficient quantum software development.

</details>


### [152] [High temperature superradiant phase transition in novel quantum structures with complex network interface](https://arxiv.org/abs/2507.16316)
*A. Yu. Bazhenov,M. Nikitina,Alexander Alodjants*

Main category: quant-ph

TL;DR: 本文提出了一种量子材料概念，利用网络拓扑增强了系统与光子场的相互作用，有望实现高温量子信息处理。


<details>
  <summary>Details</summary>
Motivation: 提出了一种新颖的量子材料概念，能够在复杂网络中实现两能级系统与光子场之间超强或超强相互作用。

Method: 利用平均场近似检查超辐射相变，并分析了由两个激发（极化子）分支和非零宏观极化引起的相变。通过节点的度分布的一阶矩和二阶归一化矩来表征网络的统计特性。

Result: 在异常区域内，拉比频率因网络的拓扑结构而得到显著增强，其中一阶矩和二阶归一化矩均有增长。多通道（多模）物质-场相互作用结构导致了超强耦合，为高温相变提供了主要行为。

Conclusion: 该研究结果有望用于设计新的光子和极化子电路以及高效处理量子信息的高温量子网络。

Abstract: In the present work we propose a novel quantum material concept, which
enables super- and/or ultrastrong interaction of two-level systems with the
photonic field in a complex network. Within the mean field approximation we
examine phase transition to superradiance that results in two excitation
(polariton) branches and is accompanied by the appearance of non-zero
macroscopic polarization of two-level systems. We characterize the statistical
properties of networks by the first, ${\langle}k{\rangle}$, and second
normalized, $\zeta\equiv{\langle}k^2{\rangle}/{\langle}k{\rangle}$, moments for
node degree distribution. We have shown that the Rabi frequency is essentially
enhanced due to the topology of the network within the anomalous domain where
${\langle}k{\rangle}$ and $\zeta$ sufficiently grow. The multichannel
(multimode) structure of matter-field interaction leads superstrong coupling
that provides primary behavior of the high temperature phase transition. The
results obtained pave the way to design new photonic and polaritonic circuits,
quantum networks for efficient processing quantum information at high (room)
temperatures.

</details>


### [153] [Meta-learning of Gibbs states for many-body Hamiltonians with applications to Quantum Boltzmann Machines](https://arxiv.org/abs/2507.16373)
*Ruchira V Bhat,Rahul Bhowmick,Avinash Singh,Krishna Kumar Sabapathy*

Main category: quant-ph

TL;DR: 提出Meta-VQT和NN-Meta VQT两种元学习算法，用于在NISQ设备上高效制备量子吉布斯态，并在伊辛模型、海森堡模型以及量子玻尔兹曼机训练中展现出优越性能和加速效果。


<details>
  <summary>Details</summary>
Motivation: 量子计算中制备量子吉布斯态是一个基本挑战，对于模拟开放量子系统和量子机器学习等应用至关重要。现有的方法在效率和泛化能力方面存在局限性。

Method: 该研究基于Meta-Variational Quantum Eigensolver框架，提出Meta-VQT和NN-Meta VQT两种元学习算法。Meta-VQT采用全量子ansatz，NN-Meta VQT采用量子-经典混合架构。两种算法都利用了跨训练集的集体优化来泛化吉布斯态制备到未见过的参数。

Result: Meta-VQT和NN-Meta VQT算法成功地在8量子比特伊辛模型和2量子比特海森堡模型上制备了热态，并且能够泛化到训练数据之外的参数。对于较大的系统，元学习参数可以作为优化任务的良好初始化。此外，在训练量子玻尔兹曼机方面，该算法实现了30倍的运行时加速，提高了吉布斯态的准确性。

Conclusion: 该研究提出了Meta-VQT和NN-Meta VQT两种元学习算法，用于在NISQ设备上高效制备参数化哈密顿量的量子吉布斯态。实验结果表明，这些算法能够泛化到未见过的数据，并在8量子比特伊辛模型和2量子比特海森堡模型上表现出色。对于更大的系统，元学习参数可以作为优化任务的良好初始化，显著优于随机初始化。此外，该算法在训练量子玻尔兹曼机方面也表现出更高的效率和准确性，并实现了显著的运行时加速。

Abstract: The preparation of quantum Gibbs states is a fundamental challenge in quantum
computing, essential for applications ranging from modeling open quantum
systems to quantum machine learning. Building on the Meta-Variational Quantum
Eigensolver framework proposed by Cervera-Lierta et al.(2021) and a problem
driven ansatz design, we introduce two meta-learning algorithms:
Meta-Variational Quantum Thermalizer (Meta-VQT) and Neural Network Meta-VQT
(NN-Meta VQT) for efficient thermal state preparation of parametrized
Hamiltonians on Noisy Intermediate-Scale Quantum (NISQ) devices. Meta-VQT
utilizes a fully quantum ansatz, while NN Meta-VQT integrates a quantum
classical hybrid architecture. Both leverage collective optimization over
training sets to generalize Gibbs state preparation to unseen parameters. We
validate our methods on upto 8-qubit Transverse Field Ising Model and the
2-qubit Heisenberg model with all field terms, demonstrating efficient thermal
state generation beyond training data. For larger systems, we show that our
meta-learned parameters when combined with appropriately designed ansatz serve
as warm start initializations, significantly outperforming random
initializations in the optimization tasks. Furthermore, a 3- qubit Kitaev ring
example showcases our algorithm's effectiveness across finite-temperature
crossover regimes. Finally, we apply our algorithms to train a Quantum
Boltzmann Machine (QBM) on a 2-qubit Heisenberg model with all field terms,
achieving enhanced training efficiency, improved Gibbs state accuracy, and a
30-fold runtime speedup over existing techniques such as variational quantum
imaginary time (VarQITE)-based QBM highlighting the scalability and
practicality of meta-algorithm-based QBMs.

</details>


### [154] [On the Differential Topology of Expressivity of Parameterized Quantum Circuits](https://arxiv.org/abs/2507.16401)
*Johanna Barzen,Frank Leymann*

Main category: quant-ph

TL;DR: 提供参数化量子电路维度表达能力的数学基础、示例和证明。


<details>
  <summary>Details</summary>
Motivation: 阐述参数化量子电路的维度表达能力，解释其所需的微分拓扑背景，并提供关键声明的证明。

Method: 提供参数化量子电路的维度表达能力所需的数学基础和示例，并提供关键声明的证明。

Result: 提供理解维度表达能力所需的数学基础和示例，并给出关键声明的证明。

Conclusion: 提供参数化量子电路的维度表达能力所需的数学基础和示例，并提供关键声明的证明。

Abstract: Parameterized quantum circuits play a key role in quantum computing.
Measuring the suitability of such a circuit for solving a class of problems is
needed. One such promising measure is the expressivity of a circuit, which is
defined in two main variants. The variant in focus of this contribution is the
so-called dimensional expressivity which measures the dimension of the
submanifold of states produced by the circuit. Understanding this measure needs
a lot of background from differential topology which makes it hard to
comprehend. In this article we provide this background in a vivid as well as
pedagogical manner. Especially it strives towards being self-contained for
understanding expressivity, e.g. the required mathematical foundations are
provided and examples are given. Also, the literature makes several statements
about expressivity the proofs of which are omitted or only indicated. In this
article we give proofs for key statements from dimensional expressivity,
sometimes revealing limits for generalizing them, and also sketching how to
proceed in practice to determine this measure.

</details>


### [155] [A Mixed-Order Phase Transition in Continuous-Variable Quantum Networks](https://arxiv.org/abs/2507.16417)
*Yaqi Zhao,Kan He,Yongtao Zhang,Jinchuan Hou,Jianxi Gao,Shlomo Havlin,Xiangyi Meng*

Main category: quant-ph

TL;DR: 本研究提出了一个连续变量量子网络中的纠缠分发方案，并引入了负熵渗透理论（NegPT）和负熵比。研究发现，连续变量量子网络表现出与离散变量系统不同的混合阶相变，并揭示了其在反馈稳定性方面的临界脆弱性。


<details>
  <summary>Details</summary>
Motivation: 由于许多光学平台能够自然生成高斯态（连续变量系统的常见态），基于连续变量（CV）的量子网络（QN）为实现可扩展的、芯片集成的量子计算和通信提供了一条有吸引力的途径。然而，为了将广泛研究的离散变量（DV）纠缠渗透理论与连续变量（CV）的对应理论联系起来，需要一个能够实现高斯态到高斯态的纠缠分发方案。

Method: 本研究引入了一个从高斯到高斯的纠缠分发方案，能够确定性地将两模压缩真空态在连续变量（CV）量子网络中传输。利用统计物理方法分析了该方案的集体行为，揭示了一种新的纠缠渗透形式——负熵渗透理论（NegPT），并引入了有界的纠缠度量——负熵比。

Result: 本研究揭示了负熵渗透理论（NegPT），这是一种新的纠缠渗透形式，其特点是存在一个有界的纠缠度量，称为负熵比。研究发现，NegPT表现出混合阶相变，同时具有全局纠缠的突变和节点间的长程关联，这表明连续变量量子网络与离散变量系统在量子相变方面存在根本性差异，并将连续变量量子网络置于新的普适类中。此外，相变的突变性也揭示了连续变量量子网络在阈值附近的临界脆弱性，传统的反馈机制在此变得不稳定。

Conclusion: 该研究提出了一个将高斯态蒸馏成纠缠态的方案，并分析了其在连续变量量子网络中的集体行为，揭示了一种新的纠缠渗透形式——负熵渗透理论（NegPT）。该理论的特点是存在一个有界的纠缠度量，称为负熵比。研究发现，NegPT表现出混合阶相变，同时具有全局纠缠的突变和节点间的长程关联。这表明连续变量量子网络与离散变量系统在量子相变方面存在根本性差异，并将连续变量量子网络置于新的普适类中。此外，相变的突变性也揭示了连续变量量子网络在阈值附近的临界脆弱性，传统的反馈机制在此变得不稳定，这对稳定大规模连续变量量子网络具有重要的实际意义。该研究结果不仅统一了连续变量纠缠分发的统计模型，还揭示了连续变量系统特有的、先前未被探索的临界现象，为开发鲁棒的、反馈稳定的量子网络提供了宝贵的见解和指导。

Abstract: Quantum networks (QNs) have been predominantly driven by discrete-variable
(DV) architectures. Yet, many optical platforms naturally generate Gaussian
states--the common states of continuous-variable (CV) systems, making CV-based
QNs an attractive route toward scalable, chip-integrated quantum computation
and communication. To bridge the conceptual gap between well-studied DV
entanglement percolation theories and their CV counterpart, we introduce a
Gaussian-to-Gaussian entanglement distribution scheme that deterministically
transports two-mode squeezed vacuum states across large CV networks. Analysis
of the scheme's collective behavior using statistical-physics methods reveals a
new form of entanglement percolation--negativity percolation theory
(NegPT)--characterized by a bounded entanglement measure called the ratio
negativity. We discover that NegPT exhibits a mixed-order phase transition,
marked simultaneously by both an abrupt change in global entanglement and a
long-range correlation between nodes. This distinctive behavior places CV-based
QNs in a new universality class, fundamentally distinct from DV systems.
Additionally, the abruptness of this transition introduces a critical
vulnerability of CV-based QNs: conventional feedback mechanism becomes
inherently unstable near the threshold, highlighting practical implications for
stabilizing large-scale CV-based QNs. Our results not only unify statistical
models for CV-based entanglement distribution but also uncover previously
unexplored critical phenomena unique to CV systems, providing valuable insights
and guidelines essential for developing robust, feedback-stabilized QNs.

</details>


### [156] [Unconventional Floquet topological phases in the SSH lattice](https://arxiv.org/abs/2507.16441)
*Dunkan Martínez,Yuriko Baba,Benjamín Santos,Rodrigo P. A. Lima,Pedro Orellana,Francisco Domínguez-Adame,Alexander López*

Main category: quant-ph

TL;DR: 高频驱动和脉冲可动态诱导和切换拓扑相，为量子技术提供新方法。


<details>
  <summary>Details</summary>
Motivation: 拓扑材料在量子技术中有应用前景，但自然界中稀少且在静态系统中难以实现。SSH链是拓扑相的一维系统，但静态控制有限。

Method: 利用高频单色驱动和调制幅度脉冲（高斯和快速拍动包络）动态诱导和切换Floquet拓扑相。采用Kramers-Henneberger样变换将Floquet边带编码为单个有效哈密顿量。

Result: 单色和脉冲协议均可诱导拓扑边缘态，实现动态相切换。快速拍动调制所需的场强低于单色调制，尤其是在更大的 the dimer 分离度下。

Conclusion: 该研究提出利用高频单色驱动和调制幅度脉冲动态诱导和切换Floquet拓扑相，并提出了一种Kramers-Henneberger样变换将所有Floquet边带编码为单个有效哈密顿量。研究表明，单色和脉冲协议（高斯和快速拍动包络）均可诱导拓扑边缘态，实现动态相切换。该方法为Floquet工程提供了实验上可行的途径，有望实现拓扑相的超快、高能效控制，为动态量子材料领域开辟新可能性。

Abstract: Topological materials, known for their edge states robust against local
perturbations, hold promise for next-generation quantum technologies, but
remain scarce in nature and challenging to realize in static systems. The
Su-Schrieffer-Heeger chain is a one-dimensional system for topological phases,
although its static control is limited. To overcome these limitations, we
propose to use high-frequency monochromatic driving and modulated amplitude
pulses to dynamically induce and switch the Floquet topological phases. Using a
Kramers-Henneberger-like transformation, we encode all Floquet sidebands into a
single effective Hamiltonian. We demonstrate that both monochromatic and
experimental pulse protocols (Gaussian and fast-beating envelopes) can induce
topological edge states, enabling dynamic phase switching. Notably,
fast-beating modulations require significantly lower field strengths than
monochromatic ones, especially with larger inter-dimer separations. Our
findings offer an experimentally feasible route for Floquet engineering, paving
the way for ultrafast and energy efficient control of topological phases in
quantum platforms, opening up new possibilities in the field of dynamic quantum
materials.

</details>


### [157] [Application-Driven Benchmarking of the Traveling Salesperson Problem: a Quantum Hardware Deep-Dive](https://arxiv.org/abs/2507.16471)
*Amine Bentellis,Benedikt Poggel,Jeanette Miriam Lorenz*

Main category: quant-ph

TL;DR: 该研究分析了不同量子硬件（中性原子、离子阱、超导）在旅行商问题上的性能，为未来量子应用开发提供了见解。


<details>
  <summary>Details</summary>
Motivation: 在实现大规模容错之前，评估量子计算能力非常困难，因为现有的硬件技术种类繁多且成熟度各异。不同提供商的量子增强算法的运行过程也存在差异。

Method: 本研究对旅行商问题进行了比较分析，评估了不同提供商的量子硬件技术（中性原子、离子阱和超导硬件，包括门控和退火设备）的效率。

Result: 研究结果展示了在不同量子硬件上运行量子算法的相对效率，并强调了在量子硬件上运行实际应用所需的步骤。

Conclusion: 该研究通过比较不同量子硬件架构（包括中性原子、离子阱和超导硬件）在旅行商问题上的表现，为理解量子计算能力提供了应用层面的视角，并指出了未来在应用开发方面所需进行的改进。

Abstract: The potential analysis of the capabilities of quantum computing, especially
before fault tolerance at scale, is difficult due to the variety of existing
hardware technologies with a wide spread of maturity. Not only the result of
computations, but also the very process of running quantum-enhanced algorithms
differ from provider to provider. The study includes a comparative analysis of
various hardware architectures with the example of the Traveling Salesperson
Problem, a central class of combinatorial optimization. It highlights what
steps are necessary to run real-world applications on quantum hardware,
showcases how the providers and various technologies differ and presents
results in the relative efficiency of exemplary quantum algorithms on neutral
atom-based, ion trap and superconducting hardware, the latter including both
gate-based and annealing devices. This is an important step in advancing the
understanding of quantum computing capabilities from an application standpoint
- agnostic to the underlying qubit technology and projecting results into the
future to judge what further developments on the application side are
necessary.

</details>


### [158] [On two-dimensional tensor network group symmetries](https://arxiv.org/abs/2507.16475)
*José Garre-Rubio,András Molnár*

Main category: quant-ph

TL;DR: 本文将二维张量网络表示应用于具有4-cocycle指标的有限群，揭示了（2+1）D拓扑相，并发展了生成（3+1）D对称保护拓扑相的张量网络单元。


<details>
  <summary>Details</summary>
Motivation: 本文旨在统一现有的二维张量网络表示方法，并强调了显式构建能够编码全局一致性条件的局部张量方程的重要性。

Method: 研究引入了两种二维张量网络表示，分别对应于带有4-cocycle指标的有限群。通过分析这些对称性作用在张量网络基态上产生的现象，研究对其相关的（2+1）D拓扑相进行了表征。此外，研究还开发了相关的张量网络幺正算符，用于生成代表（3+1）D对称保护拓扑相的对称态。

Result: 该研究提出了一个统一的张量网络框架，用于理解和生成（2+1）D和（3+1）D的拓扑相，特别是那些由具有4-cocycle指标的有限群对称性所驱动的相。

Conclusion: 该研究将二维张量网络表示扩展到具有4-cocycle指标的有限群，并明确了其在张量网络基态上作用时产生的（2+1）D拓扑相。

Abstract: We introduce two-dimensional tensor network representations of finite groups
carrying a 4-cocycle index. We characterize the associated gapped (2+1)D phases
that emerge when these anomalous symmetries act on tensor network ground
states. We further develop related tensor network unitaries that generate
symmetric states representing (3+1)D symmetry protected topological phases.
Although aspects of these constructions have been previously addressed, our
contribution unifies them within a single tensor network framework and
emphasizes the explicit formulation of local tensor equations encoding global
consistency conditions.

</details>


### [159] [Efficient quantum state tomography with auxiliary systems](https://arxiv.org/abs/2507.16532)
*Wenlong Zhao,Da Zhang,Huili Zhang,Haifeng Yu,Zhang-qi Yin*

Main category: quant-ph

TL;DR: 为了解决量子态层析在大规模量子系统中测量设置和采样复杂度过高的问题，本文提出了一种基于辅助系统（量子或经典）的量子态层析新方法。该方法仅需两组测量设置，采样复杂度为 $O(d^2)$，显著降低了实验复杂度，并提高了信息提取效率。


<details>
  <summary>Details</summary>
Motivation: 量子态层析在量子信息科学中至关重要，但随着量子系统规模的增大，其测量设置和采样需求呈指数级增长，给实验设计、实施和资源消耗带来了巨大挑战，严重阻碍了其在大规模量子系统中的应用。因此，需要开发能够减少测量设置和提高采样效率的新方法。

Method: 本文提出了一种基于辅助系统的量子态层析方法，该方法通过将待测量子系统与量子辅助系统进行纠缠，或与概率性经典辅助系统产生关联，并在整个联合系统上进行测量，从而更有效地提取关于待测量子态的信息。该方法仅需要两组测量设置，采样复杂度为 $O(d^2)$，并提供了两种测量纯度的方案，其中一种方案达到了海森堡极限。

Result: 实验结果表明，该方法通过标准量子门操作，将测量设置减少到两组，采样复杂度降至 $O(d^2)$，大大简化了实验操作和测量过程。理论分析、数值模拟和实验结果均验证了该方法的有效性。

Conclusion: 该研究提出的基于辅助系统的量子态层析方法，能够显著减少测量设置和采样复杂度，有效解决了量子态层析在处理大规模量子系统时面临的挑战。通过与量子或经典辅助系统的耦合，该方法提高了信息提取效率，实验复杂度大大降低，并有望在量子计算、量子通信和量子模拟等领域得到广泛应用。

Abstract: Quantum state tomography is a technique in quantum information science used
to reconstruct the density matrix of an unknown quantum state, providing
complete information about the quantum state. It is of significant importance
in fields such as quantum computation, quantum communication, and quantum
simulation. However, as the size of the quantum system increases, the number of
measurement settings and sampling requirements for quantum state tomography
grow exponentially with the number of qubits. This not only makes experimental
design and implementation more complex, but also exacerbates the consumption of
experimental resources. These limitations severely hinder the application of
state tomography in large-scale quantum systems. To reduce measurement settings
and improve sampling efficiency, this study proposes a state tomography method
based on auxiliary systems. This method can be implemented through either
entanglement between the quantum system to be measured and a quantum auxiliary
system or through correlation between the quantum system and a probabilistic
classical auxiliary system. Measurements on the entire joint system enable more
efficient extraction of information about the quantum state to be measured.
This method relies on standard quantum gate operations and requires only two
measurement settings, with a total sampling complexity of $O(d^2)$,
significantly simplifying experimental operations and measurement processes.
Additionally, this study provides two schemes for measuring purity based on the
proposed circuit, one of which achieves measurement precision at the Heisenberg
limit. This study validates the effectiveness of the proposed method through a
detailed theoretical analysis, a series of numerical simulations, and
experiments.

</details>


### [160] [Quantum Dark Magic: Efficiency of Intermediate Non-Stabiliserness](https://arxiv.org/abs/2507.16543)
*Tom Krüger,Wolfgang Mauerer*

Main category: quant-ph

TL;DR: 研究提出了一种新的方法来分析量子资源利用效率，以期实现量子优势，并发现非稳定状态在不同算法中的消耗方式存在差异。


<details>
  <summary>Details</summary>
Motivation: 尽管量子计算优于经典计算已得到证实，但具有量子优势的原始算法仍然有限，这归因于对量子计算能力来源的理解不完整。为了实现量子优势，需要更好地理解非稳定状态的高效利用。

Method: 该研究提出了一种追踪非稳定状态在不同算法中行为的方法，结合了非稳定熵资源理论和量子态演化几何，并引入了排列不可知距离度量。

Result: 研究发现，结构化和非结构化变分方法在使用非稳定状态方面效率不同，并且经典优化的自由度越大，非稳定状态的消耗就越多。

Conclusion: 该研究通过将非稳定状态熵资源理论与量子态演化几何相结合，并引入排列不可知距离度量，为分析量子资源的高效利用开辟了新途径，有助于实现算法量子优势。

Abstract: While superiority of quantum over classical computation has been established,
the repertoire of primitives with proven or conjectured quantum advantage
remains limited. Despite considerable progress in delineating the
quantumclassical divide, the systematic construction of algorithms with quantum
advantage remains challenging, which can be attributed to a still incomplete
understanding of the sources of quantum computational power. While intermediate
non-stabiliserness (i.e., traversal of states outside the Clifford orbit)
indicates necessary non-classical behaviour for quantum advantage, naively
equating non-stabiliserness and non-classicality is misguided: Even random Haar
sampled states exhibit near-maximal non-stabiliserness. Advancing towards
quantum advantage calls for a better understanding of the efficient use of
non-stabiliser states. We present an approach to track the behaviour of
non-stabiliserness across various algorithms by pairing resource theory of
non-stabiliser entropies with the geometry of quantum state evolution, and
introduce permutation agnostic distance measures that reveal non-stabiliser
effects previously hidden by a subset of Clifford operations. We find different
efficiency in the use of non-stabiliserness for structured and unstructured
variational approaches, and show that greater freedom for classical
optimisation in quantum-classical methods increases unnecessary non-stabiliser
consumption. Our results open new means of analysing the efficient utilisation
of quantum resources, and contribute towards the targeted construction of
algorithmic quantum advantage.

</details>


### [161] [A photon density wavefunction](https://arxiv.org/abs/2507.16597)
*Stéphane Virally*

Main category: quant-ph

TL;DR: Maxwell's equations in vacuum can be related to Schrödinger's equation, but the derived vector is not a true wavefunction. We show how to derive a wavefunction from the EM field whose amplitude squared corresponds to photon density, linking it to Mandel's second quantized wavefunction.


<details>
  <summary>Details</summary>
Motivation: Maxwell's equations in vacuum can be formally cast in the form of Schrödinger's equation, but the equation directly applies to a vector whose amplitude squared is not a probability density but the expected energy density of the field. Since photons can be counted, there must be a more convincing wavefunction, derived from the EM field, whose amplitude squared is an expected photon density.

Method: Formal casting of Maxwell's equations in vacuum into the form of the Schrödinger's equation, and deriving a wavefunction from the EM field whose amplitude squared is an expected photon density.

Result: A method to directly link Mandel's second quantized wavefunction to the EM field.

Conclusion: We show how Mandel's second quantized wavefunction can be directly linked to the EM field.

Abstract: Maxwell's equations in the vacuum can be formally cast in the form of
Schr\"odinger's equation. Unfortunately, the vector to which this equation
directly applies is not a wavefunction: its amplitude squared is not a
probability density but the expected energy density of the field. Since we can
count photons, there must be a more convincing wavefunction, derived from the
EM field, whose amplitude squared is an expected photon density. Mandel
proposed the second quantized version of such a wavefunction, but did not link
it directly to the EM field. We show how this can be accomplished.

</details>


### [162] [Multi-qubit Rydberg gates between distant atoms](https://arxiv.org/abs/2507.16602)
*Antonis Delakouras,Georgios Doultsinos,David Petrosyan*

Main category: quant-ph

TL;DR: 该研究提出了一种基于中性原子里德堡态相互作用的高效多比特门实现方案，可用于构建可扩展的量子计算机。


<details>
  <summary>Details</summary>
Motivation: 实现高效的多比特门操作是构建可扩展量子计算机的关键挑战。

Method: 通过施加全局激光脉冲将原子激发到具有强阻塞相互作用的里德堡态，利用里德堡态相互作用和几何相位来实现多比特门操作，并通过单比特旋转将酉变换转换为C$_{k}$Z或C$_{k}$NOT门。

Result: 成功实现了一种高效的多比特门协议，该协议具有可扩展性，并能有效抑制串扰。

Conclusion: 该协议可以实现多比特酉变换，并可推广到星形和链形原子阵列，为基于中性原子的可扩展量子计算提供了新的途径。

Abstract: We propose an efficient protocol to realize multi-qubit gates in arrays of
neutral atoms. The atoms encode qubits in the long-lived hyperfine sublevels of
the ground electronic state. To realize the gate, we apply a global laser pulse
to transfer the atoms to a Rydberg state with strong blockade interaction that
suppresses simultaneous excitation of neighboring atoms arranged in a
star-graph configuration. The number of Rydberg excitations, and thereby the
parity of the resulting state, depends on the multiqubit input state. Upon
changing the sign of the interaction and de-exciting the atoms with an
identical laser pulse, the system acquires a geometric phase that depends only
on the parity of the excited state, while the dynamical phase is completely
canceled. Using single qubit rotations, this transformation can be converted to
the C$_k$Z or C$_k$NOT quantum gate for $k+1$ atoms. We also present extensions
of the scheme to implement quantum gates between distant atomic qubits
connected by a quantum bus consisting of a chain of atoms.

</details>


### [163] [Isocoherent Work Extraction from Quantum Batteries: Basis-Dependent Response](https://arxiv.org/abs/2507.16610)
*Shuva Mondal,Debarupa Saha,Ujjwal Sen*

Main category: quant-ph

TL;DR: 该研究发现了量子相干性与量子电池可提取的最大功之间的联系，并定义了相干性约束最大功（CCMW）。研究推导了 qubit 系统中 CCMW 与输入相干性之间的解析关系，并指出 CCMW 的响应依赖于基的选择。该研究还观察到这种依赖性在更高维度量子系统中也存在，并对 isocoherent 场景下被动态的结构进行了评论。


<details>
  <summary>Details</summary>
Motivation: 该研究的动机是探索量子相干性与量子电池可提取的最大功之间的联系，以期更好地理解和优化量子电池的性能。

Method: 该研究通过定义相干性约束最大功（CCMW）并分析其与输入相干性的关系来研究量子电池的最大可提取功。研究推导了 qubit 系统中 CCMW 与输入相干性的解析关系，并通过数值模拟观察了 CCMW 在更高维度量子系统中的行为。

Result: 研究发现了量子相干性与量子电池可提取的最大功之间的联系，并定义了相干性约束最大功（CCMW）。研究推导了 qubit 系统中 CCMW 与输入相干性之间的解析关系，并指出 CCMW 的响应依赖于基的选择。该研究还观察到这种依赖性在更高维度量子系统中也存在，并对 isocoherent 场景下被动态的结构进行了评论。

Conclusion: 该研究发现了量子相干性与量子电池可提取的最大功之间的联系，并定义了相干性约束最大功（CCMW）。研究推导了 qubit 系统中 CCMW 与输入相干性之间的解析关系，并指出 CCMW 的响应依赖于基的选择。此外，研究还观察到这种依赖性在更高维度的量子系统中也存在，并对 isocoherent 场景下被动态的结构进行了评论。

Abstract: We identify a connection between quantum coherence and the maximum
extractable work from a quantum battery, and to this end, we define the
coherence-constrained maximal work (CCMW) as the highest amount of work
extractable via coherence-preserving unitaries, optimized over all quantum
states with fixed coherence in a given dimension. For qubit systems, we derive
an analytical relation between the CCMW and the input coherence, defined with
respect to an arbitrary fixed basis. Strikingly, we find that for fixed quantum
coherence in the energy eigenbasis, the maximal extractable work decreases with
increase of coherence. In contrast, when quantum coherence is with respect to a
basis for which the Hamiltonian possesses off-diagonal elements, and has equal
diagonal elements, the CCMW increases with the level of quantum coherence. We
numerically observe that the basis-dependent response of the CCMW also persists
in higher-dimensional quantum systems. Moreover, we show that even in higher
dimensions one can derive closed-form relations between the CCMW and the input
quantum coherence within certain numerically-assessed conclusions. We also
comment on the structure of passive states in an isocoherent scenario, that is,
states from which no energy can be extracted under coherence-preserving
unitaries.

</details>


### [164] [Thermal operations from informational equilibrium](https://arxiv.org/abs/2507.16637)
*Seok Hyung Lie,Jeongrak Son,Paul Boes,Nelly H. Y. Ng,Henrik Wilming*

Main category: quant-ph

TL;DR: 热操作是量子信道，其特点是它们可以扩展为保持环境不变的酉变换。催化信道是一种特殊的热操作，与双酉量子电路有关。


<details>
  <summary>Details</summary>
Motivation: 本文旨在探索量子信道在量子热力学中的作用，特别是热操作的性质，以及它们与量子信息论性质的联系，并引入催化信道作为热浴行为的一种信息论理想化。

Method: 本文通过分析热操作的性质，证明了它们可以通过一个量子信息论的性质来唯一表征，即它们允许扩展为一个在应用于平衡态时保持环境不变的酉变换。此外，本文还探讨了保持环境局部不变的催化信道，并将其与双酉量子电路联系起来。

Result: 热操作可以被唯一地表征为能够扩展为保持环境不变的酉变换的量子信道。催化信道为全简并哈密顿量的吉布斯保持映射提供了一个精炼的层级结构，并与双酉量子电路密切相关。

Conclusion: 热操作是量子信息论中用于推导量子系统中基本热力学限制的关键量子信道。本文证明了热操作可以通过一个纯粹的量子信息论性质唯一表征，即它们允许扩展为一种酉变换，该变换在应用于平衡态时保持环境不变。换句话说，它们是唯一能保持系统与环境之间平衡的信道。

Abstract: Thermal operations are quantum channels that have taken a prominent role in
deriving fundamental thermodynamic limitations in quantum systems. We show that
these channels are uniquely characterized by a purely quantum information
theoretic property: They admit a dilation into a unitary process that leaves
the environment invariant when applied to the equilibrium state. In other
words, they are the only channels that preserve equilibrium between system and
environment. Extending this perspective, we explore an information theoretic
idealization of heat bath behavior, by considering channels where the
environment remains locally invariant for every initial state of the system.
These are known as catalytic channels. We show that catalytic channels provide
a refined hierarchy of Gibbs-preserving maps for fully-degenerate Hamiltonians,
and are closely related to dual unitary quantum circuits.

</details>


### [165] [Hybrid Reward-Driven Reinforcement Learning for Efficient Quantum Circuit Synthesis](https://arxiv.org/abs/2507.16641)
*Sara Giordano,Kornikar Sen,Miguel A. Martin-Delgado*

Main category: quant-ph

TL;DR: 通过强化学习（Q学习）和状态空间离散化，以及混合奖励机制，该方法能高效合成（近乎）最优的量子电路，用于量子状态制备。


<details>
  <summary>Details</summary>
Motivation: 为解决量子比特初态到目标态的量子线路合成问题，该方法旨在提高NISQ时代和未来容错量子计算的效率。

Method: 采用基于动作序列的表格型Q学习，并结合静态领域信息奖励和动态惩罚（抑制门拥塞和冗余状态访问），以及稀疏矩阵表示和状态空间离散化，以应对高维环境的挑战。

Result: 在高达七个量子比特的图态制备任务的基准测试中，该算法能够持续发现具有优化门数的最小深度量子电路。即使扩展到任意量子态的通用门集，该框架仍能生成最小深度量子电路，证明了其鲁棒性和适应性。

Conclusion: 该强化学习方法能够有效地探索复杂的量子态空间，并合成接近最优的量子电路，为量子电路优化提供了资源高效的基础。

Abstract: A reinforcement learning (RL) framework is introduced for the efficient
synthesis of quantum circuits that generate specified target quantum states
from a fixed initial state, addressing a central challenge in both the NISQ era
and future fault-tolerant quantum computing. The approach utilizes tabular
Q-learning, based on action sequences, within a discretized quantum state
space, to effectively manage the exponential growth of the space dimension. The
framework introduces a hybrid reward mechanism, combining a static,
domain-informed reward that guides the agent toward the target state with
customizable dynamic penalties that discourage inefficient circuit structures
such as gate congestion and redundant state revisits. By leveraging sparse
matrix representations and state-space discretization, the method enables
scalable navigation of high-dimensional environments while minimizing
computational overhead. Benchmarking on graph-state preparation tasks for up to
seven qubits, we demonstrate that the algorithm consistently discovers
minimal-depth circuits with optimized gate counts. Moreover, extending the
framework to a universal gate set for arbitrary quantum states, it still
produces minimal depth circuits, highlighting the algorithm's robustness and
adaptability. The results confirm that this RL-driven approach efficiently
explores the complex quantum state space and synthesizes near-optimal quantum
circuits, providing a resource-efficient foundation for quantum circuit
optimization.

</details>


### [166] [Studies of properties of bipartite graphs with quantum programming](https://arxiv.org/abs/2507.16653)
*Kh. P. Gnatenko*

Main category: quant-ph

TL;DR: 该研究通过CNOT门构造了多量子比特图态，推导了纠缠距离与图结构的解析关系，建立了纠缠与顶点度数的联系，并利用量子协议量化了图的奇偶度顶点数量，最后通过量子模拟验证了结果。


<details>
  <summary>Details</summary>
Motivation: 该研究的动机是探索多量子比特量子态与二分图结构之间的关系，并利用量子纠缠等特性来量化图的属性，为量子信息科学和图论研究开辟新的途径。

Method: 该研究通过应用CNOT门到可分离的多量子比特态来构造多量子比特图态，并分析了这些状态的纠缠距离。研究中推导了纠缠距离与任意二分图结构的解析关系，并建立了纠缠与顶点度数之间的联系。此外，研究还确定了量子关联与集合U和V中奇偶度顶点数量的关系。

Result: 该研究成功地推导了多量子比特图态的纠缠距离与任意二分图结构的解析关系，建立了纠缠与顶点度数之间的联系，并揭示了量子关联与奇偶度顶点数量的关系。此外，研究还提出了基于量子纠缠的图度量方法，并通过量子模拟验证了理论预测的准确性。

Conclusion: 该研究分析了多量子比特图态，建立了量子纠缠与图结构（特别是顶点度数）之间的联系，并提出了一种基于量子纠缠的新型图度量方法。研究还提出了利用量子协议量化图奇偶度顶点的数量，并通过量子模拟验证了理论结果。

Abstract: Multi-qubit quantum states corresponding to bipartite graphs $G(U,V,E)$ are
examined. These states are constructed by applying $CNOT$ gates to an arbitrary
separable multi-qubit quantum state. The entanglement distance of the resulting
states is derived analytically for an arbitrary bipartite graph structure. A
relationship between entanglement and the vertex degree is established.
Additionally, we identify how quantum correlators relate to the number of
vertices with odd and even degrees in the sets $U$ and $V$. Based on these
results, quantum protocols are proposed for quantifying the number of vertices
with odd and even degrees in the sets $U$ and $V$. For a specific case where
the bipartite graph is a star graph, we analytically calculate the dependence
of entanglement distance on the state parameters. These results are also
verified through quantum simulations on the AerSimulator, including noise
models. Furthermore, we use quantum calculations to quantify the number of
vertices with odd degrees in $U$ and $V$. The results agree with the
theoretical predictions.

</details>


### [167] [Reconfigurable qubit states and quantum trajectories in a synthetic artificial neuron network with a process to direct information generation from co-integrated burst-mode spiking under non-Markovianity](https://arxiv.org/abs/2507.16669)
*Osama M. Nayfeh,Chris S. Horne*

Main category: quant-ph

TL;DR: 通过将量子计算集成到脉冲神经网络中，提高了人工智能和自主任务的性能，并增强了信息包的安全性。


<details>
  <summary>Details</summary>
Motivation: 为了显著提高神经形态系统在人工智能和自主任务方面的能力，将量子信息处理与脉冲计算共集成。

Method: 利用忆阻器脉冲序列驱动具有内置超导-离子记忆体的合成神经元，并分析了考虑集成旋转依赖性的哈密顿量，研究了关键参数的影响，并探索了生成信息包的算法。

Result: 通过将量子信息处理与脉冲计算相结合，实现了神经形态系统能力的显著提升，能够执行读出和基本算术等功能，并提高了信息包的安全性。

Conclusion: 该系统能够生成具有先进功能和更高安全性的信息包，并通过量子过程定义信息包的规则性或意识水平。

Abstract: A synthetic artificial neuron network functional in a regime where quantum
information processes are co-integrated with spiking computation provides
significant improvement in the capabilities of neuromorphic systems in
performing artificial intelligence and autonomy tasks. This provides the
ability to execute with the qubit coherence states and entanglement as well as
in tandem to perform functions such as read out and basic arithmetic with
conventional spike-encoding. Ultimately, this enables the generation and
computational processing of information packets with advanced capabilities and
an increased level of security in their routing. We now use the dynamical pulse
sequences generated by a memristive spiking neuron to drive synthetic neurons
with built-in superconductor-ionic memories built in a lateral layout with
integrated Niobium metal electrodes as well as a gate terminal and an atomic
layer deposited ionic barrier. The memories operate at very low voltage and
with direct, and hysteretic Josephson tunneling and provide enhanced coherent
properties enabling qubit behavior. We operated now specifically in burst mode
to drive its built-in reconfigurable qubit states and direct the resulting
quantum trajectory. We analyze the new system with a Hamiltonian that considers
an integrated rotational dependence, dependent on the unique co-integrated
bursting mode spiking- and where the total above threshold spike count is
adjustable with variation of the level of coupling between the neurons. We then
examined the impact of key parameters with a longer-term non-Markovian quantum
memory and finally explored a process and algorithm for the generation of
information packets with a coupled and entangled set of these artificial neuron
qubits that provides for a quantum process to define the level of regularity or
awareness of the information packets.

</details>


### [168] [Computational aspects of the trace norm contraction coefficient](https://arxiv.org/abs/2507.16737)
*Idris Delsol,Omar Fawzi,Jan Kochanowski,Akshay Ramachandran*

Main category: quant-ph

TL;DR: 研究量化信道的复杂性，发现近似其迹范数收缩系数和比特编码成功概率是NP难的。


<details>
  <summary>Details</summary>
Motivation: 探索量化信道和量子系统编码的计算复杂性，并与经典问题进行对比。

Method: 利用NP难性证明，并建立了一系列关于收缩系数的半定规划上界。

Result: 量化信道的迹范数收缩系数的近似是NP难的，确定量子比特编码的最佳成功概率也是NP难的，并且发现非交换图的独立数至少为2是NP难的。

Conclusion: 证明了量化信道的迹范数收缩系数的近似是NP难的，以及确定量子系统中比特编码的最佳成功概率也是NP难的。这与经典情况形成对比，后者可以有效解决。

Abstract: We show that approximating the trace norm contraction coefficient of a
quantum channel within a constant factor is NP-hard. Equivalently, this shows
that determining the optimal success probability for encoding a bit in a
quantum system undergoing noise is NP-hard. This contrasts with the classical
analogue of this problem that can clearly by solved efficiently. Our hardness
results also hold for deciding if the contraction coefficient is equal to 1. As
a consequence, we show that deciding if a non-commutative graph has an
independence number of at least 2 is NP-hard. In addition, we establish a
converging hierarchy of semidefinite programming upper bounds on the
contraction coefficient.

</details>


### [169] [Parametric Amplification of Spin-Motion Coupling in Three-Dimensional Trapped-Ion Crystals](https://arxiv.org/abs/2507.16741)
*Samarth Hawaldar,N. Nikhil,Ana Maria Rey,John J. Bollinger,Athreya Shankar*

Main category: quant-ph

TL;DR: 本研究通过参数放大探索了在3D离子晶体中加速自旋相互作用的方法，发现只有相位敏感的MS门能被有效放大，并且反旋转项的影响被高估了。


<details>
  <summary>Details</summary>
Motivation: 为了在量子传感和量子模拟应用中扩展离子阱系统，需要扩展到三维（3D）晶体。然而，在大型晶体中工程相干自旋-运动耦合和有效的自旋-自旋相互作用带来了与退相干和产生可观纠缠的长时间尺度相关的技术挑战。本研究旨在探索通过参数放大加速这些相互作用的可能性。

Method: 本研究推导了适用于任何维度晶体在射频保罗陷阱和彭宁陷阱中自旋运动耦合的参数放大通用哈密顿量。通过研究光移（LS）门和相位不敏感/相位敏感的Mølmer-Sørensen（MS）门，发现只有相位敏感的MS门可以被通用3D晶体忠实地放大。

Result: 研究发现，与低维晶体不同，在3D晶体中忠实（均匀）放大自旋-自旋相互作用的能力取决于自旋-运动耦合的物理实现。研究还讨论了非均匀放大可能有利的情况，并重新考虑了反旋转项对参数放大的影响。

Conclusion: 在通用3D晶体中，只有相位敏感的Mølmer-Sørensen（MS）门可以被忠实地放大，并且反旋转项不像以前研究所暗示的那样有害。

Abstract: Three-dimensional (3D) crystals offer a route to scale up trapped ion systems
for quantum sensing and quantum simulation applications. However, engineering
coherent spin-motion couplings and effective spin-spin interactions in large
crystals poses technical challenges associated with decoherence and prolonged
timescales to generate appreciable entanglement. Here, we explore the
possibility to speed up these interactions in 3D crystals via parametric
amplification. We derive a general Hamiltonian for the parametric amplification
of spin-motion coupling that is applicable to crystals of any dimension in both
rf Paul traps and Penning traps. Unlike in lower dimensional crystals, we find
that the ability to faithfully (uniformly) amplify the spin-spin interactions
in 3D crystals depends on the physical implementation of the spin-motion
coupling. We consider the light-shift (LS) gate, and the so-called
phase-insensitive and phase-sensitive M{\o}lmer-S{\o}rensen (MS) gates, and
find that only the latter gate can be faithfully amplified in general 3D
crystals. We discuss a situation where non-uniform amplification can be
advantageous. We also reconsider the impact of counter-rotating terms on
parametric amplification and find that they are not as detrimental as previous
studies suggest.

</details>


### [170] [Multiparameter estimation with position-momentum correlated Gaussian probes](https://arxiv.org/abs/2507.16742)
*João C. P. Porto,Carlos H. S. Vieira,Pedro R. Dieguez,Irismar G. da Paz,Lucas S. Marinho*

Main category: quant-ph

TL;DR: 高斯量子探针的PM关联可用于提高温度估计精度。


<details>
  <summary>Details</summary>
Motivation: 受高斯量子探针中引入初始位置-动量（PM）关联可以提高估计精度以及高斯量子探针在量子计量和测温中的广泛应用启发，研究PM关联是否在同时估计PM关联和有效环境温度的设置中也具有优势。

Method: 使用量子费舍尔信息矩阵（QFIM）推导联合估计任务的精度边界。

Result: 推导了联合估计任务的精度边界，并证明了PM关联可以作为提高温度估计精度的资源。

Conclusion: 研究表明，在联合估计任务中，位置-动量（PM）关联可以作为一种资源来提高温度估计的精度，并分析了两个参数之间的兼容性，确定了可以满足所得精度边界的条件。

Abstract: Gaussian quantum probes have been widely used in quantum metrology and
thermometry, where the goal is to estimate the temperature of an environment
with which the probe interacts. It was recently shown that introducing initial
position-momentum (PM) correlations in such probes can enhance the estimation
precision compared to standard, uncorrelated Gaussian states. Motivated by
these findings, we investigate whether PM correlations can also be advantageous
in a simultaneous estimation setting, specifically, when estimating both the PM
correlations themselves and the effective environment temperature that
interacts with the probe. Using the Quantum Fisher Information Matrix, we
derive new precision bounds for this joint estimation task. Additionally, we
demonstrate that such correlations can serve as a resource to improve
temperature estimation within this multiparameter context. Finally, we analyze
the compatibility between the two parameters, establishing conditions under
which the derived bounds can be saturated.

</details>


### [171] [Quantum teleportation of an elemental silicon nanophotonic CNOT gate](https://arxiv.org/abs/2507.16783)
*Kai-Chi Chang,Xiang Cheng,Felix Ribuot-Hirsch,Murat Can Sarihan,Yujie Chen,Jaime Gonzalo Flor Flores,Mingbin Yu,Patrick Guo-Qiang Lo,Dim-Lee Kwong,Chee Wei Wong*

Main category: quant-ph

TL;DR: 利用光子芯片和硅基技术，成功实现了片上CNOT门的量子隐形传态，保真度高，可用于构建大规模分布式量子计算。


<details>
  <summary>Details</summary>
Motivation: 为了克服构建大规模量子计算机在扩展模块和远程量子比特纠缠方面的挑战，研究旨在实现远程量子比特的门操作，而量子门隐形传态是一种仅需本地操作、经典通信和共享纠缠即可实现此目标的关键方法。

Method: 研究利用可扩展的硅芯片平台、高保真度的本地量子逻辑门、线性光学元件、后选择纠缠以及光子量子比特的符合测量，实验演示了片上CNOT门的量子隐形传态。

Result: 研究结果包括：1. 实现了平均真值表保真度为93.1%（±0.3%）的片上CNOT门量子隐形传态。2. 对于不同的输入偏振态，实现了平均量子态保真度为87.0%（±2.2%）的片上CNOT门。3. 利用非局域CNOT门实现了四贝尔态的远程纠缠创建，平均量子态保真度为86.2%（±0.8%）。4. 对该片上CNOT门进行了完整的量子过程保真度（83.1% ±2.0%）和平均非局域CNOT门保真度（86.5% ±2.2%）的表征。

Conclusion: 该研究展示了一种通过光子芯片实现量子门隐形传态的方法，并成功实现了片上CNOT门的量子隐形传态，其保真度可达93.1%（真值表保真度）和87.0%（量子态保真度），为构建大规模分布式量子计算和容错量子计算提供了基础。

Abstract: Large-scale quantum computers possess the capacity to effectively tackle
practical problems that can be insurmountable for classical computers. The main
challenge in building these quantum computers is to realize scalable modules
for remote qubits and entanglement. By assembling small, specialized parts into
a larger architecture, the modular approach mitigates complexity and
uncertainty. Such a distributed architecture requires non-local quantum gate
operations between remote qubits. An essential method for implementing such
operations, known as quantum gate teleportation, requires only local
operations, classical communication, and shared entanglement. Till today, the
quantum gate teleportation using a photonic chip has remained elusive. Here we
experimentally demonstrate the quantum teleportation of an on-chip
controlled-NOT (CNOT) gate, assisted with the scalable silicon chip platform,
high-fidelity local quantum logic gates, linear optical components,
post-selected entanglement, and coincidence measurements from photonic qubits.
First, we measure and characterize our teleported chip-scale CNOT gate with an
average truth table fidelity of 93.1 +- 0.3%. Second, for different input
polarization states, we obtain an average quantum state fidelity of 87.0 +-
2.2% with our teleported on-chip CNOT gate. Third, we use our non-local CNOT
gate for remote entanglement creation of four Bell states, with an average
quantum state fidelity of 86.2 +- 0.8%. Fourthly, we fully characterize our
teleported on-chip CNOT gate with a quantum process fidelity 83.1 +- 2.0%, and
an average non-local CNOT gate fidelity of 86.5 +- 2.2%. Our teleported
photonic on-chip quantum logic gate could be extended both to multiple qubits
and chip-scale modules towards fault-tolerant and large-scale distributed
quantum computation.

</details>


### [172] [Broadband Relaxation Dynamics of Boron-Vacancy Centers in Hexagonal Boron Nitride](https://arxiv.org/abs/2507.16786)
*Abhishek Bharatbhai Solanki,Yueh-Chun Wu,Hamza Ather,Priyo Adhikary,Aravindh Shankar,Ian Gallagher,Xingyu Gao,Owen M. Matthiessen,Demid Sychev,Alexei Lagoutchev,Tongcang Li,Yong P. Chen,Vladimir M. Shalaev,Benjamin Lawrie,Pramey Upadhyaya*

Main category: quant-ph

TL;DR: 六方氮化硼中的硼空位（V_B^-）中心在强磁场下的自旋弛豫行为已被研究，发现在不同条件下存在不同的弛豫机制，这为开发高性能量子传感器提供了基础。


<details>
  <summary>Details</summary>
Motivation: 探索V_B^-中心在强磁场下的行为，以期在量子传感领域实现高场、亚太赫兹的应用。

Method: 通过在15-250 K的温度范围和高达7 T的磁场范围内，研究V_B^-中心的自旋弛豫动力学，并提取了依赖于温度和磁场的弛豫率缩放行为，以量化V_B^-中心与其环境之间的相互作用。

Result: 在低温和弱磁场下，观察到由自旋-自旋相互作用和无序诱导的拉伸指数弛豫动力学；在高温和强磁场下，弛豫过程主要由单声子过程驱动。成功提取了弛豫率的温度和磁场依赖缩放行为。

Conclusion: 本研究揭示了在15-250 K的温度和高达7 T的磁场下，六方氮化硼（hBN）中带负电的硼空位（V_B^-）中心的自旋弛豫动力学。研究结果为基于二维自旋缺陷平台的亚太赫兹量子传感器在强磁场下的应用奠定了基础。

Abstract: The negatively charged boron vacancy center ($\mathrm{V_B^-}$) in hexagonal
boron nitride ($\mathrm{hBN}$) has attracted attention for its potential
applications in quantum sensing. While GHz-scale sensing at low magnetic fields
has been demonstrated with these defects, their behavior at high fields remains
largely unexplored. We investigate the spin relaxation dynamics of
$\mathrm{V_B^-}$ centers over temperatures of $15-250$ K and magnetic fields of
up to $7$ T, corresponding to a ground-state splitting of $\sim 200$ GHz. Our
results uncover distinct relaxation regimes, transitioning from
spin-spin-interaction-driven and disorder-induced stretched exponential
dynamics at low temperatures and fields to relaxation dominated by
single-phonon processes at elevated magnetic fields. We extract temperature-
and magnetic-field-dependent scaling behaviors of the relaxation rate to
provide a quantitative picture of the interactions between $\mathrm{V_B^-}$
centers and their environment. Our results pave the way towards high-field,
sub-terahertz quantum sensors based on two-dimensional spin-defect platforms.

</details>


### [173] [No-go theorems for logical gates on product quantum codes](https://arxiv.org/abs/2507.16797)
*Xiaozhen Fu,Han Zheng,Zimu Li,Zi-Wen Liu*

Main category: quant-ph

TL;DR: 超图积码在实现非Clifford逻辑门方面存在根本性限制，并且对Clifford层级门的实现能力也受到维度约束。


<details>
  <summary>Details</summary>
Motivation: 为了实现容错量子计算，研究对量子纠错码（特别是qLDPC码）的构造和性质进行深入分析，重点关注超图积码在逻辑门实现方面的能力和限制。

Method: 基于Bravyi-König定理的推广，对所有积维度的超图积码进行了容错逻辑门分析，并探讨了具有或不具有几何局域性的示例。

Result: 证明了超图积码无法横向实现非Clifford逻辑门，并揭示了维度对Clifford层级门可及性的限制，这些限制源于高度通用的代数结构。

Conclusion: 本研究揭示了超图积码在容错逻辑门实现方面的基本限制，特别是对于非Clifford逻辑门，无法横向实现，并且约束了Clifford层级门的可及性。

Abstract: Quantum error-correcting codes are essential to the implementation of
fault-tolerant quantum computation. Homological products of classical codes
offer a versatile framework for constructing quantum error-correcting codes
with desirable properties, especially quantum low-density parity check (qLDPC)
codes. Based on extensions of the Bravyi--K\"{o}nig theorem that encompass
codes without geometric locality, we establish a series of general no-go
theorems for fault-tolerant logical gates supported by hypergraph product
codes. Specifically, we show that non-Clifford logical gates cannot be
implemented transversally on hypergraph product codes of all product
dimensions, and that the dimensions impose various limitations on the
accessible level of the Clifford hierarchy gates by constant-depth local
circuits. We also discuss examples both with and without geometric locality
which attain the Clifford hierarchy bounds. Our results reveal fundamental
restrictions on logical gates originating from highly general algebraic
structures, extending beyond existing knowledge only in geometrically local,
finite logical qubits, transversal, or 2-dimensional product cases, and may
guide the vital study of fault-tolerant quantum computation with qLDPC codes.

</details>


<div id='cs.ET'></div>

# cs.ET [[Back]](#toc)

### [174] [Prediction of Alpha-Particle-Immune Gate-All-Around Field-Effect Transistors (GAA-FET) Based SRAM Design](https://arxiv.org/abs/2507.15860)
*Albert Lu,Reza Arghavani,Hiu Yung Wong*

Main category: cs.ET

TL;DR: 通过 3D TCAD 模拟和 GAA-FET 设计，实现了对α粒子免疫的 SRAM。


<details>
  <summary>Details</summary>
Motivation: 为了设计一种能够抵抗单粒子翻转（SEU）的静态随机存取存储器（SRAM），特别是由α粒子引起的错误。

Method: 使用 3D TCAD 模拟，结合 PHITS 软件进行 ab initio 计算，以确定α粒子在 Si 和 SixGe1-x 中的最大线性能量转移（LETmax），并基于此设计了具有底部介电隔离（BDI）的亚 7nm GAA-FET SRAM。

Result: 成功设计出一种基于 GAA-FET 技术的 SRAM，即使在α粒子辐射的 worst-case scenario（LET > LETmax）下，SRAM 单元也不会发生翻转，证明了其对α粒子辐射的免疫力。

Conclusion: 使用 3D TCAD 模拟和 GAA-FET 技术设计的 SRAM 在最坏情况的α粒子辐射下也不会发生翻转，实现了抗单粒子翻转（SEU）的特性。

Abstract: In this paper, using 3D Technology Computer-Aided-Design (TCAD) simulations,
we show that it is possible to design a static random-access memory (SRAM)
using gate-all-around field-effect-transistor (GAA-FET) technology so that it
is immune to single alpha particle radiation error. In other words, with the
design, there will be no single-event upset (SEU) due to alpha particles. We
first use ab initio calculations in PHITS to show that there is a maximum
linear energy transfer (LET), LETmax, for the alpha particle in Si and
Si$_x$Ge$_{1-x}$. Based on that, by designing a sub-7nm GAA-FET-based SRAM with
bottom dielectric isolation (BDI), we show that the SRAM does not flip even if
the particle strike is in the worst-case scenario (LET > LETmax).

</details>


### [175] [AI-driven Orchestration at Scale: Estimating Service Metrics on National-Wide Testbeds](https://arxiv.org/abs/2507.16077)
*Rodrigo Moreira,Rafael Pasquini,Joberto S. B. Martins,Tereza C. Carvalho,Flávio de Oliveira Silva*

Main category: cs.ET

TL;DR: 本研究提出了一种使用AI预测模型（DNN和ML）大规模验证网络切片的方法，该方法在真实生产测试台中评估，旨在改进网络切片编排，并提供一种生产就绪的验证替代方案。


<details>
  <summary>Details</summary>
Motivation: 为了实现网络切片（NS），需要AI原生的编排架构来高效、智能地处理异构用户需求。然而，这些架构在生产环境中验证其结果面临挑战，特别是那些利用机器学习（ML）的编排架构，因为它们通常在本地网络或实验室模拟中进行测试。

Method: 提出了一种利用深度神经网络（DNN）和基础机器学习算法的网络切片预测模型，并在真实的大规模生产测试台中进行了验证，以预测延迟。研究比较了不同DNN和ML算法的性能，并考虑了一个部署在两个大规模生产测试台上的分布式数据库应用程序作为网络切片。

Result: 研究结果表明，基于AI的预测模型可以改进网络切片编排架构，并为网络切片验证提供了一种可行的、面向生产的方法。

Conclusion: 该研究提出了一种使用基于AI的预测模型来增强网络切片编排架构的方法，并提供了一种无需完全依赖模拟或实验室设置的、可用于生产环境的无缝验证方法。

Abstract: Network Slicing (NS) realization requires AI-native orchestration
architectures to efficiently and intelligently handle heterogeneous user
requirements. To achieve this, network slicing is evolving towards a more
user-centric digital transformation, focusing on architectures that incorporate
native intelligence to enable self-managed connectivity in an integrated and
isolated manner. However, these initiatives face the challenge of validating
their results in production environments, particularly those utilizing
ML-enabled orchestration, as they are often tested in local networks or
laboratory simulations. This paper proposes a large-scale validation method
using a network slicing prediction model to forecast latency using Deep Neural
Networks (DNNs) and basic ML algorithms embedded within an NS architecture,
evaluated in real large-scale production testbeds. It measures and compares the
performance of different DNNs and ML algorithms, considering a distributed
database application deployed as a network slice over two large-scale
production testbeds. The investigation highlights how AI-based prediction
models can enhance network slicing orchestration architectures and presents a
seamless, production-ready validation method as an alternative to fully
controlled simulations or laboratory setups.

</details>


### [176] [Quantum Annealing Hyperparameter Analysis for Optimal Sensor Placement in Production Environments](https://arxiv.org/abs/2507.16584)
*Nico Kraus,Marvin Erdmann,Alexander Kuzmany,Daniel Porawski,Jonas Stein*

Main category: cs.ET

TL;DR: 本研究使用量子退火方法解决了汽车制造中的传感器放置优化问题，通过QUBO建模和参数调优，并结合分解技术提高了可扩展性，证明了量子计算在未来大规模优化问题中的应用潜力。


<details>
  <summary>Details</summary>
Motivation: 为了提高汽车制造效率，需要优化传感器在生产线到配送区域的放置，以确保全面覆盖并最大限度地减少传感器数量。传统方法在解决大规模问题时效率低下且通常无法获得最优解，导致成本增加。

Method: 本研究探索了使用量子计算（特别是量子退火）来解决汽车制造中传感器优化放置的问题。研究人员将该问题转化为二次无约束二元优化（QUBO）问题，并使用了单热码和二进制编码。他们还优化了诸如罚项和退火时间等超参数，并将结果与默认参数设置进行了比较。此外，还采用了分解技术来处理大规模问题实例。

Result: 量子退火能够成功解决源自实际场景的问题实例。通过使用分解技术，可以进一步扩大问题规模，使其更接近工业实际应用。研究强调了量子退火参数设置的重要性，并展示了量子计算在成熟后为大规模优化问题带来的成本效益。

Conclusion: 量子退火在解决自动驾驶汽车制造中的传感器放置问题方面显示出潜力，通过使用分解技术可以扩展到实际应用规模。然而，量子硬件的成熟和量子退火参数的优化对于实现其全部潜力至关重要。

Abstract: To increase efficiency in automotive manufacturing, newly produced vehicles
can move autonomously from the production line to the distribution area. This
requires an optimal placement of sensors to ensure full coverage while
minimizing the number of sensors used. The underlying optimization problem
poses a computational challenge due to its large-scale nature. Currently,
classical solvers rely on heuristics, often yielding non-optimal solutions for
large instances, resulting in suboptimal sensor distributions and increased
operational costs.
  We explore quantum computing methods that may outperform classical heuristics
in the future. We implemented quantum annealing with D-Wave, transforming the
problem into a quadratic unconstrained binary optimization formulation with
one-hot and binary encoding. Hyperparameters like the penalty terms and the
annealing time are optimized and the results are compared with default
parameter settings.
  Our results demonstrate that quantum annealing is capable of solving
instances derived from real-world scenarios. Through the use of decomposition
techniques, we are able to scale the problem size further, bringing it closer
to practical, industrial applicability. Through this work, we provide key
insights into the importance of quantum annealing parametrization,
demonstrating how quantum computing could contribute to cost-efficient,
large-scale optimization problems once the hardware matures.

</details>


<div id='cs.NE'></div>

# cs.NE [[Back]](#toc)

### [177] [Beyond Rate Coding: Surrogate Gradients Enable Spike Timing Learning in Spiking Neural Networks](https://arxiv.org/abs/2507.16043)
*Ziqiao Yu,Pengfei Sun,Dan F. M. Goodman*

Main category: cs.NE

TL;DR: SNNs trained with Surrogate GD learn timing information in spike trains, outperforming rate-based models and showing human-like sensitivity to timing errors. Released new datasets for further research.


<details>
  <summary>Details</summary>
Motivation: To determine if SNNs trained with Surrogate GD can learn from precise spike timing, beyond just firing rates, and to evaluate their robustness under biologically inspired perturbations.

Method: Investigated Spiking Neural Networks (SNNs) trained with Surrogate Gradient Descent (Surrogate GD), with and without delay learning, on synthetic tasks and speech recognition datasets (SHD, SSC). Modified datasets to isolate spike timing information. Evaluated robustness against jitter, deletion, and temporal reversal.

Result: SNNs trained with Surrogate GD significantly outperformed chance on timing-dependent tasks, even when spike count information was removed. Networks showed perturbation-specific degradation in performance, with a notable drop when spike sequences were reversed, especially in networks trained with delays, indicating more human-like behavior.

Conclusion: Surrogate GD-trained SNNs can learn from precise spike timing, outperforming purely rate-based models and exhibiting human-like sensitivity to temporal order disruptions.

Abstract: We investigate the extent to which Spiking Neural Networks (SNNs) trained
with Surrogate Gradient Descent (Surrogate GD), with and without delay
learning, can learn from precise spike timing beyond firing rates. We first
design synthetic tasks isolating intra-neuron inter-spike intervals and
cross-neuron synchrony under matched spike counts. On more complex spike-based
speech recognition datasets (Spiking Heidelberg Digits (SHD) and Spiking Speech
Commands (SSC), we construct variants where spike count information is
eliminated and only timing information remains, and show that Surrogate
GD-trained SNNs are able to perform significantly above chance whereas purely
rate-based models perform at chance level. We further evaluate robustness under
biologically inspired perturbations -- including Gaussian jitter per spike or
per-neuron, and spike deletion -- revealing consistent but
perturbation-specific degradation. Networks show a sharp performance drop when
spike sequences are reversed in time, with a larger drop in performance from
SNNs trained with delays, indicating that these networks are more human-like in
terms of behaviour. To facilitate further studies of temporal coding, we have
released our modified SHD and SSC datasets.

</details>


<div id='cs.DS'></div>

# cs.DS [[Back]](#toc)

### [178] [Online Combinatorial Optimization with Graphical Dependencies](https://arxiv.org/abs/2507.16031)
*Zhimeng Gao,Evangelia Gergatsouli,Kalen Patton,Sahil Singla*

Main category: cs.DS

TL;DR: 该研究提出了在马尔可夫随机场（MRF）下在线组合优化的新方法，解决了输入相关性问题，并提供了具有竞争力的算法。


<details>
  <summary>Details</summary>
Motivation: 在实践中，在线随机组合优化中，输入通常来自独立的分布，这一假设常常不成立。但另一极端情况是，任意相关性相当于最坏情况输入，这使得设计出好的算法变得不可能。因此，研究能够捕获轻度相关性同时仍允许设计出非平凡算法的中间模型是非常有必要的。

Method: 作者提出了可以实现O（Δ）竞争性算法的通用技术，适用于MRF分布式输入的最小化和最大化问题。对于具有覆盖约束的最小化问题（例如，设备选址和斯特纳树），作者将其简化为研究中的p-样本模型。对于最大化问题（例如，匹配和具有XOS买方的组合拍卖），作者将“平衡价格”框架扩展到MRF以进行在线分配问题。

Result: 作者提出了可以实现O（Δ）竞争性算法的通用技术，适用于MRF分布式输入的最小化和最大化问题。

Conclusion: 虽然MRF参数化了相关性强度，但我们在很多情况下可以设计出具有竞争力的算法，这些算法具有与MRF相关的参数的线性竞争力。

Abstract: Most existing work in online stochastic combinatorial optimization assumes
that inputs are drawn from independent distributions -- a strong assumption
that often fails in practice. At the other extreme, arbitrary correlations are
equivalent to worst-case inputs via Yao's minimax principle, making good
algorithms often impossible. This motivates the study of intermediate models
that capture mild correlations while still permitting non-trivial algorithms.
  In this paper, we study online combinatorial optimization under Markov Random
Fields (MRFs), a well-established graphical model for structured dependencies.
MRFs parameterize correlation strength via the maximum weighted degree
$\Delta$, smoothly interpolating between independence ($\Delta = 0$) and full
correlation ($\Delta \to \infty$). While na\"ively this yields
$e^{O(\Delta)}$-competitive algorithms and $\Omega(\Delta)$ hardness, we ask:
when can we design tight $\Theta(\Delta)$-competitive algorithms?
  We present general techniques achieving $O(\Delta)$-competitive algorithms
for both minimization and maximization problems under MRF-distributed inputs.
For minimization problems with coverage constraints (e.g., Facility Location
and Steiner Tree), we reduce to the well-studied $p$-sample model. For
maximization problems (e.g., matchings and combinatorial auctions with XOS
buyers), we extend the "balanced prices" framework for online allocation
problems to MRFs.

</details>


### [179] [Online Joint Replenishment Problem with Arbitrary Holding and Backlog Costs](https://arxiv.org/abs/2507.16096)
*Yossi Azar,Shahar Lewkowicz*

Main category: cs.DS

TL;DR: We developed a new algorithm for the Joint Replenishment Problem (JRP) that handles complex cost functions, outperforming previous methods by offering constant competitive ratios (4x for single-item, 16x for multi-item) using dynamic request priorities.


<details>
  <summary>Details</summary>
Motivation: The motivation was to resolve an open problem in the Joint Replenishment Problem (JRP) concerning the design of a constant competitive algorithm for arbitrary request-dependent holding and backlog costs. Prior work provided a constant competitive algorithm only for the case where holding costs and backlog costs were the same for all items, and their algorithm did not work for arbitrary functions. The goal was to extend this to arbitrary functions.

Method: We designed a constant competitive algorithm for arbitrary request dependent holding and backlog costs. Specifically, we established a 4-competitive algorithm for the single-item case and a 16-competitive algorithm for the general (multi-item) version. Our algorithm uses dynamic priorities over requests, enabling the servicing of general subsets of requests, contrasting with the fixed priority by deadlines approach.

Result: We designed a constant competitive algorithm that works for arbitrary request dependent holding and backlog costs. We achieved a 4-competitive algorithm for the single-item case and a 16-competitive algorithm for the general multi-item version of the JRP.

Conclusion: We resolve the open problem of designing a constant competitive algorithm for arbitrary request-dependent holding and backlog costs in the Joint Replenishment Problem (JRP). We establish a 4-competitive algorithm for the single-item case and a 16-competitive algorithm for the general multi-item version. Our algorithm utilizes a dynamic priority over requests, allowing for the servicing of general subsets of requests, unlike the fixed priority based on deadlines used in prior work.

Abstract: In their seminal paper Moseley, Niaparast, and Ravi introduced the Joint
Replenishment Problem (JRP) with holding and backlog costs that models the
trade-off between ordering costs, holding costs, and backlog costs in supply
chain planning systems. Their model generalized the classical the make-to-order
version as well make-to-stock version. For the case where holding costs
function of all items are the same and all backlog costs are the same, they
provide a constant competitive algorithm, leaving designing a constant
competitive algorithm for arbitrary functions open. Moreover, they noticed that
their algorithm does not work for arbitrary (request dependent) holding costs
and backlog costs functions. We resolve their open problem and design a
constant competitive algorithm that works for arbitrary request dependent
functions. Specifically, we establish a 4-competitive algorithm for the
single-item case and a 16-competitive for the general (multi-item) version. The
algorithm of Moseley, Niaparast, and Ravi is based on fixed priority on the
requests to items, and request to an item are always served by order of
deadlines. In contrast, we design an algorithm with dynamic priority over the
requests such that instead of servicing a prefix by deadline of requests, we
may need to service a general subset of the requests.

</details>


### [180] [An Exact Solver for Maximizing a Submodular Function Subject to a Knapsack Constraint](https://arxiv.org/abs/2507.16149)
*Sabine Münch,Stephen Raach*

Main category: cs.DS

TL;DR: 该研究提出了一种用于子模背包问题的精确算法，并在实验中证明了其优越性。


<details>
  <summary>Details</summary>
Motivation: 许多应用需要精确解，因为近似解在实践中常常不够充分。

Method: 提出了一种用于子模背包问题的精确分支定界算法，并引入了几种加速技术以提高其效率。

Result: 所提出的方法优于现有的最先进方法。

Conclusion: 所提出的方法在基准问题的实例上优于现有的最先进方法。

Abstract: We study the problem of maximizing a monotone increasing submodular function
over a set of weighted elements subject to a knapsack constraint.
  Although this problem is NP-hard, many applications require exact solutions,
as approximate solutions are often insufficient in practice.
  To address this need, we propose an exact branch-and-bound algorithm tailored
for the submodular knapsack problem and introduce several acceleration
techniques to enhance its efficiency. We evaluate these techniques on instances
of three benchmark problems and compare the proposed solvers to two solvers by
Sakaue and Ishihata, which are considered state-of-the-art, demonstrating that
the presented methods outperform the existing methods.

</details>


### [181] [Toward a Lightweight and Robust Design for Caching with Predictions](https://arxiv.org/abs/2507.16242)
*Peng Chen,Hailiang Zhao,Jiaji Zhang,Xueyan Tang,Yixuan Wang,Shuiguang Deng*

Main category: cs.DS

TL;DR: Guard是一种轻量级的缓存框架，可以在不牺牲性能的情况下提高缓存的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 在线缓存问题旨在最小化缓存命中次数，同时满足有限的缓存大小。现有的鲁棒化方法要么牺牲1-一致性，要么引入显著的计算开销。

Method: 提出了一种轻量级的鲁棒化框架Guard，用于增强一类学习增强缓存算法的鲁棒性。

Result: Guard框架将学习增强缓存算法的鲁棒性提高到2Hk + 2，同时保持其1-一致性，且每请求的额外开销仅为O(1)。实验结果在多个真实世界数据集和预测模型上验证了Guard的有效性。

Conclusion: Guard框架在保持学习增强缓存算法的1-一致性的同时，将鲁棒性提高到2Hk + 2，实现了当前已知的最好一致性与鲁棒性权衡，每请求的额外开销仅为O(1)，并保留了基础算法的原始时间复杂度。

Abstract: The online caching problem aims to minimize cache misses when serving a
sequence of requests under a limited cache size. While naive learning-augmented
caching algorithms achieve ideal $1$-consistency, they lack robustness
guarantees. Existing robustification methods either sacrifice $1$-consistency
or introduce significant computational overhead. In this paper, we introduce
\textsc{Guard}, a lightweight robustification framework that enhances the
robustness of a broad class of learning-augmented caching algorithms to $2H_k +
2$, while preserving their $1$-consistency. \textsc{Guard} achieves the current
best-known trade-off between consistency and robustness, with only
$\mathcal{O}(1)$ additional per-request overhead, thereby maintaining the
original time complexity of the base algorithm. Extensive experiments across
multiple real-world datasets and prediction models validate the effectiveness
of \textsc{Guard} in practice.

</details>


### [182] [Longest Unbordered Factors on Run-Length Encoded Strings](https://arxiv.org/abs/2507.16285)
*Shoma Sekizaki,Takuya Mieno*

Main category: cs.DS

TL;DR: 本文提出了一种针对 RLE 字符串的最长无边界因子算法，在压缩域内实现了 O(m^1.5 log^2 m) 的时间复杂度，并在特定条件下优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 本文旨在解决字符串学中的一个基本问题——计算字符串的最长无边界因子。虽然已有亚二次和近线性时间复杂度的算法，但现有最佳最坏情况时间复杂度仍为 O(n log n)。本文将该问题置于压缩字符串处理的背景下，特别是针对游程编码（RLE）字符串，寻求更优的解决方案。

Method: 本文提出了一种基于结构性观察的算法，将无边界因子与 RLE 压缩字符串联系起来。该算法通过模拟 [Gawrychowski et al., SPIRE 2015] 中的 O(n^1.5) 算法思想，并结合新的组合学见解，将其适应于 RLE 环境。

Result: 本文提出了一种针对 RLE 字符串的最长无边界因子算法，时间复杂度为 O(m^1.5 log^2 m)，空间复杂度为 O(m log^2 m)。该算法在 m 远小于 n 的情况下，相比现有方法可能具有更好的性能。

Conclusion: 本文提出了一种针对游程编码（RLE）字符串的最长无边界因子问题的算法，时间复杂度为 O(m^1.5 log^2 m)，空间复杂度为 O(m log^2 m)，其中 m 是 RLE 字符串的大小。当 RLE 大小 m 相对于字符串长度 n 较小时，该算法可能表现出接近线性的时间复杂度。

Abstract: A border of a string is a non-empty proper prefix of the string that is also
a suffix. A string is unbordered if it has no border. The longest unbordered
factor is a fundamental notion in stringology, closely related to string
periodicity. This paper addresses the longest unbordered factor problem: given
a string of length $n$, the goal is to compute its longest factor that is
unbordered. While recent work has achieved subquadratic and near-linear time
algorithms for this problem, the best known worst-case time complexity remains
$O(n \log n)$ [Kociumaka et al., ISAAC 2018]. In this paper, we investigate the
problem in the context of compressed string processing, particularly focusing
on run-length encoded (RLE) strings. We first present a simple yet crucial
structural observation relating unbordered factors and RLE-compressed strings.
Building on this, we propose an algorithm that solves the problem in $O(m^{1.5}
\log^2 m)$ time and $O(m \log^2 m)$ space, where $m$ is the size of the
RLE-compressed input string. To achieve this, our approach simulates a key idea
from the $O(n^{1.5})$-time algorithm by [Gawrychowski et al., SPIRE 2015],
adapting it to the RLE setting through new combinatorial insights. When the RLE
size $m$ is sufficiently small compared to $n$, our algorithm may show
linear-time behavior in $n$, potentially leading to improved performance over
existing methods in such cases.

</details>


<div id='cs.LO'></div>

# cs.LO [[Back]](#toc)

### [183] [An Adequate While-Language for Stochastic Hybrid Computation](https://arxiv.org/abs/2507.15913)
*Renato Neves,José Proença,Juliana Souza*

Main category: cs.LO

TL;DR: A new language is introduced for reasoning about programs that mix differential and probabilistic features, with operational and denotational semantics provided.


<details>
  <summary>Details</summary>
Motivation: To provide a formal framework for reasoning about programs that integrate differential and probabilistic constructs, exemplified by systems like adaptive cruise controllers and physical processes.

Method: The paper presents a language with operational and denotational semantics and establishes an adequacy theorem between them. An interpreter for the language is also implemented.

Result: The paper introduces a novel language and its associated semantic frameworks, enabling formal reasoning about hybrid systems.

Conclusion: We have introduced a language for formally reasoning about programs that combine differential and probabilistic constructs, along with its operational and denotational semantics and an adequacy theorem.

Abstract: We introduce a language for formally reasoning about programs that combine
differential constructs with probabilistic ones. The language harbours, for
example, such systems as adaptive cruise controllers, continuous-time random
walks, and physical processes involving multiple collisions, like in Einstein's
Brownian motion.
  We furnish the language with an operational semantics and use it to implement
a corresponding interpreter. We also present a complementary, denotational
semantics and establish an adequacy theorem between both cases.

</details>


### [184] [On Expansions of Monadic Second-Order Logic with Dynamical Predicates](https://arxiv.org/abs/2507.16581)
*Joris Nieuwveld,Joël Ouaknine*

Main category: cs.LO

TL;DR: This paper proves the MSO theory of $\langle \mathbb{N} ; <,P \rangle$ is decidable, using a new technique called prodisjunctivity, for specific types of predicates related to linear recurrence sequences.


<details>
  <summary>Details</summary>
Motivation: The research is motivated by the ongoing interest in expansions of the monadic second-order (MSO) theory of the structure $\langle \mathbb{N} ; < \rangle$, an area active since the 1960s.

Method: The paper utilizes the novel concept of (effective) prodisjunctivity as a key technical tool.

Result: Decidability of the MSO theory of $\langle \mathbb{N} ; <,P \rangle$ has been established for a large class of unary 'dynamical' predicates.

Conclusion: The paper establishes the decidability of the MSO theory of $\langle \mathbb{N} ; <,P \rangle$ for a class of unary 'dynamical' predicates.

Abstract: Expansions of the monadic second-order (MSO) theory of the structure $\langle
\mathbb{N} ; < \rangle$ have been a fertile and active area of research ever
since the publication of the seminal papers of B\"uchi and Elgot & Rabin on the
subject in the 1960s. In the present paper, we establish decidability of the
MSO theory of $\langle \mathbb{N} ; <,P \rangle$, where $P$ ranges over a large
class of unary ''dynamical'' predicates, i.e., sets of non-negative values
assumed by certain integer linear recurrence sequences. One of our key
technical tools is the novel concept of (effective) prodisjunctivity, which we
expect may also find independent applications further afield.

</details>


### [185] [Transordinal Fixed-Point Operators and Self-Referential Games: A Categorical Framework for Reflective Semantic Convergence](https://arxiv.org/abs/2507.16620)
*Faruk Alpay,Hamdi Al Alakkad*

Main category: cs.LO

TL;DR: 通过迭代含义细化算子和分析无限对话的均衡，对语言解释的稳定进行了建模。


<details>
  <summary>Details</summary>
Motivation: 为语言解释如何通过无限的自我指涉稳定下来提供模型，统一了范畴论不动点构造、超限递归和基于游戏的语义。

Method: 通过跨越所有序数阶段迭代含义细化算子，分离出唯一的“超序数”不动点，并通过一系列反射游戏证明，该对象是文本与其解释者之间无限对话的唯一均衡。

Result: 该模型提供了一个数学上严谨的语义收敛的解释，该解释是单一同质的，不依赖于统计训练或经验基准。

Conclusion: 该研究提供了一个数学上严谨的语义收敛模型，该模型不依赖于统计训练或经验基准，并且可以为形式语言学提供精确的保证，并为设计能够推理自身输出的语言感知系统提供蓝图。

Abstract: We present a new theoretical framework that unifies category-theoretic
fixed-point constructions, transfinite recursion, and game-based semantics to
model how interpretations of language can stabilize through unlimited
self-reference. By iterating a meaning-refinement operator across all ordinal
stages, we isolate a unique "transordinal" fixed point and show, via a
hierarchy of reflective games, that this same object is the sole equilibrium of
an infinite dialogue between a text and its interpreter. The result delivers a
mathematically rigorous account of semantic convergence without resorting to
statistical training or empirical benchmarks, yet remains simple to explain:
start with a rough meaning, let speaker and listener correct each other
forever, and the process provably settles on a single, self-consistent
interpretation. Because the construction is entirely symbolic, it offers both
precise guarantees for formal linguistics and a blueprint for designing
language-aware systems that can reason about their own outputs. The paper
details the requisite transordinal machinery, proves existence and uniqueness
theorems, and connects them to long-standing questions about reflection, truth,
and equilibrium in formal systems and semantics.

</details>


<div id='eess.SY'></div>

# eess.SY [[Back]](#toc)

### [186] [Fast Feeder Reconfiguration via Mesh Adaptive Direct Search in Black-Box Distribution System Environments](https://arxiv.org/abs/2507.16027)
*Junyuan Zheng,Wenlong Shi,Zhaoyu Wang*

Main category: eess.SY

TL;DR: 本研究提出了一种基于MADS的馈线重构框架，通过仿真模块进行评估，以最小化功率损耗和约束违反，并在IEEE-123节点测试馈线上取得了优于启发式方法的结果。


<details>
  <summary>Details</summary>
Motivation: 现有的优化方法通常依赖于显式的数学公式和分析模型，这在实际的电力公用设施环境中是不可行的，因为这些环境的特点是存在异构的、专有的以及黑盒的仿真模块。为了解决这个挑战，本研究提出了一种新的方法。

Method: 本研究提出了一种基于网格自适应直接搜索（MADS）的快速馈线重构框架，仅需通过用于潮流、保护和电压调节分析的仿真模块进行性能指标评估。该方法采用基于帕累托前沿过滤器的双目标优化方法，以最小化有功功率损耗和运行约束违反，并通过局部轮询策略和收敛感知更新来适应性地细化有前景候选点周围的搜索空间。

Result: 该方法能够仅通过评估来优化馈线重构，并且在IEEE-123节点测试馈线上，相比启发式方法，以更少的评估次数实现了近乎最优的配置。

Conclusion: 该方法在IEEE-123节点测试馈线案例研究中，实现了近乎最优的配置，并且所需的评估次数明显少于启发式方法。

Abstract: Feeder reconfiguration is a critical operational strategy in power
distribution systems. However, existing optimization approaches typically rely
on explicit mathematical formulations and analytical models, which are often
infeasible in practical utility environments characterized by heterogeneous,
proprietary, and black-box simulation modules. To address this challenge, this
paper proposes a fast feeder reconfiguration framework based on Mesh Adaptive
Direct Search (MADS). The proposed approach requires only performance metric
evaluations through simulation modules used for power flow, protection, and
voltage regulation analysis. A bi-objective formulation is adopted to jointly
minimize active power loss and operational constraint violations. A
Pareto-based frontier filter is integrated into the MADS algorithm to
efficiently guide the search toward high-quality configurations while
systematically pruning dominated solutions. The approach adaptively refines the
search space around promising candidates using local polling strategies and
convergence aware updates. Case studies on the IEEE-123 node test feeder
demonstrate that the proposed approach achieves near-optimal configurations
with significantly fewer evaluations compared to heuristic methods.

</details>


### [187] [Analytical Framework for Power System Strength](https://arxiv.org/abs/2507.16061)
*Ignacio Ponce,Federico Milano*

Main category: eess.SY

TL;DR: A new framework and method (Delta operator) are proposed to evaluate power system strength using voltage and its rate of change indicators. It is applicable to various system devices and validated with numerical results.


<details>
  <summary>Details</summary>
Motivation: To propose a general framework to evaluate power system strength.

Method: The paper introduces a novel finite differentiation technique called the Delta operator to capture "jumps" of algebraic variables and utilizes the concept of complex frequency. The framework features twelve indicators, grouped in three dynamical orders, to quantify the resistance of bus voltage phasors and their rates of change to current injection changes. It can be applied to synchronous machines, converters, and loads.

Result: The framework quantifies the resistance of bus voltage phasors and their first and second order rates of change to sudden current injection changes using twelve indicators grouped in three dynamical orders. Numerical results validate the exactness of the formulation.

Conclusion: This paper proposes a general framework to evaluate power system strength, validated by numerical results in a benchmark system.

Abstract: This paper proposes a general framework to evaluate power system strength.
The formulation features twelve indicators, grouped in three dynamical orders,
that quantify the resistance of bus voltage phasors and their first and second
order rates of change to sudden current injection changes. To quantify such
changes the paper introduces a novel finite differentiation technique, that we
named Delta operator, able to properly capture "jumps" of algebraic variables
and utilizes the recently developed concept of complex frequency. The paper
also shows how the proposed framework can be systematically applied to any
system device, and provides a variety of examples based on synchronous
machines, converters and loads models are given. Numerical results in a
benchmark system validate the exactness of the formulation.

</details>


### [188] [Automating Capacitor Part Selection with Dual-Objective Optimization](https://arxiv.org/abs/2507.16071)
*Luke Brantingham,Jason Grover*

Main category: eess.SY

TL;DR: Optimized capacitor selection using multi-objective optimization to reduce cost and board area.


<details>
  <summary>Details</summary>
Motivation: To optimize capacitor selection in electronic design, focusing on minimizing cost and board area while satisfying performance requirements.

Method: Utilizes multi-objective linear and non-linear constrained optimization techniques.

Result: Demonstrates the effectiveness of the approach in achieving the optimization goals.

Conclusion: The presented framework effectively optimizes capacitor selection, minimizing cost and board area while meeting performance requirements.

Abstract: This paper presents a novel framework for optimizing capacitor selection in
electronic design using multi-objective linear and non-linear constrained
optimization techniques. We demonstrate the effectiveness of this approach in
minimizing cost and board area while meeting critical performance requirements.

</details>


### [189] [The Sustainability of the Leo Orbit Capacity via Risk-Driven Active Debris Removal](https://arxiv.org/abs/2507.16101)
*Yacob Medhin,Simone Servadio*

Main category: eess.SY

TL;DR: 该研究提出了一种名为FMM的新型风险指数，可以更有效地识别近地轨道上的空间碎片，但清除频率会影响其性能。


<details>
  <summary>Details</summary>
Motivation: 近地轨道空间碎片数量的增加威胁到轨道的可持续性，因此需要对主动碎片清除（ADR）任务进行有效的风险评估。

Method: 该研究利用MOCAT-MC模拟框架，对Filtered Modified MITRI (FMM)进行了全面的性能评估和敏感性分析。

Result: Filtered Modified MITRI (FMM)能够更好地识别用于年度清除活动的高风险目标，但风险模型在不同清除频率下的性能存在权衡。基于物理质量的项对于实际风险评估至关重要。

Conclusion: 该研究通过开发和验证Filtered Modified MITRI (FMM)来应对近地轨道空间碎片增多带来的挑战，FMM是一种用于改善高危碎片识别的风险指数。研究结果表明，FMM能更有效地识别用于年度清除任务的高风险目标，并强调了基于物理质量的风险评估的重要性。该研究还提供了一个经过验证的开源工具和对风险动态的深入见解，以支持近地轨道的可持续性。

Abstract: The growing number of space debris in Low Earth Orbit (LEO) jeopardizes
long-term orbital sustainability, requiring efficient risk assessment for
active debris removal (ADR) missions. This study presents the development and
validation of Filtered Modified MITRI (FMM), an enhanced risk index designed to
improve the prioritization of high-criticality debris. Leveraging the MOCAT-MC
simulation framework, we conducted a comprehensive performance evaluation and
sensitivity analysis to probe the robustness of the FMM formulation. The
results demonstrate that while the FMM provides superior identification of
high-risk targets for annual removal campaigns, a nuanced performance trade-off
exists between risk models depending on the operational removal cadence. The
analysis also confirms that physically grounded mass terms are indispensable
for practical risk assessment. By providing a validated open source tool and
critical insights into the dynamics of risk, this research enhances our ability
to select optimal ADR targets and ensure the long-term viability of LEO
operations.

</details>


### [190] [Design and Implementation of a Lightweight Object Detection System for Resource-Constrained Edge Environments](https://arxiv.org/abs/2507.16155)
*Jiyue Jiang,Mingtong Chen,Zhengbao Yang*

Main category: eess.SY

TL;DR: 本项目通过模型压缩技术（剪枝、量化、蒸馏），在STM32H7微控制器上实现了低功耗的YOLOv5行人车辆检测系统，满足便携和数据隐私需求。


<details>
  <summary>Details</summary>
Motivation: 本项目旨在开发一个低功耗物体检测系统，满足便携式需求和数据隐私的严格要求，适用于户外旅行场景，检测行人与车辆。

Method: 本项目使用STM32H7微控制器和YOLOv5模型，并应用了剪枝、量化和蒸馏等模型压缩技术，以提高模型性能和效率，减少计算量和模型参数量。

Result: 通过模型压缩技术，成功将YOLOv5模型部署到STM32H7微控制器上，实现了在低功耗和资源受限的嵌入式设备上运行物体检测模型。

Conclusion: 该项目成功开发了一个在低功耗条件下运行的物体检测系统，适用于户外旅行场景，并能检测行人与车辆。通过采用STM32H7微控制器和YOLOv5模型，并结合剪枝、量化和蒸馏等模型压缩技术，有效解决了嵌入式设备的资源限制问题，实现了在资源受限的微控制器上运行计算机视觉模型，为嵌入式视觉应用的发展奠定了基础。

Abstract: This project aims to develop a system to run the object detection model under
low power consumption conditions. The detection scene is set as an outdoor
traveling scene, and the detection categories include people and vehicles. In
this system, users data does not need to be uploaded to the cloud, which is
suitable for use in environments with portable needs and strict requirements
for data privacy. The MCU device used in this system is STM32H7, which has
better performance among low power devices. The YOLOv5 system is selected to
train the object detection model. To overcome the resource limitation of the
embedded devices, this project uses several model compression techniques such
as pruned, quantization, and distillation, which could improve the performance
and efficiency of the detection model. Through these processes, the model s
computation and the quantity of model parameters could be reduced, in order to
run computer vision models on micro-controller devices for the development of
embedded vision applications.

</details>


### [191] [Design and Optimization of Wearables for Human Motion Energy Harvesting](https://arxiv.org/abs/2507.16157)
*Weijia Peng,Mingtong Chen,Zhengbao Yang*

Main category: eess.SY

TL;DR: 研究人员开发了一种从行走中收集能量的鞋类发电系统，目标是为可穿戴电子设备提供能源。


<details>
  <summary>Details</summary>
Motivation: 随着可穿戴电子设备的普及，对可持续设计和能源自主系统产生了浓厚兴趣。

Method: 通过将弹簧连接到嵌入鞋跟的电磁发电机来收集行走产生的机械能，该发电机利用踩踏产生的垂直压力来发电。

Result: 模拟原型在 MATLAB 中设计，展示了最大 12V 的电压，而初步的低保真原型则展示了能量输出。

Conclusion: 该研究为自供电鞋类和独立能源的可穿戴电子设备奠定了基础。

Abstract: As wearable electronics become increasingly prevalent, there is a rise in
interest and demand for sustainably designed systems that are also energy
self-sufficient. The research described in this paper investigated a shoe-worn
energy harvesting system designed use the mechanical energy from walking to
output electrical energy. A spring is attached to electromagnetic generator
embedded in the heel of the shoe to recover the vertical pressure caused by the
foot strike. The simulated prototype consisted of a standard EM generator
designed in MATLAB demonstrating a maximum voltage of 12V. The initial low
fidelity prototype demonstrated testing the relationship between the EM
generator and a simple electrical circuit, with energy output observed. Future
research will explore enhancing the overall generator design, integrate a power
management IC for battery protect and regulation, and combine the system into a
final product, wearable footwear. This research lays a foundation for
self-powered footwear and energy independent wearable electronic devices.

</details>


### [192] [The Bode Plots for Sliding-Mode Control Design](https://arxiv.org/abs/2507.16281)
*Ulises Pérez-Ventura*

Main category: eess.SY

TL;DR: 本研究提出了一种统一的频域框架，利用描述函数理论分析滑模控制系统，推导了颤振特性和等效增益模型，并通过仿真验证了其在稳态性能分析和控制器设计中的有效性。


<details>
  <summary>Details</summary>
Motivation: 本研究旨在开发一个统一的频域框架，用于分析滑模控制系统，包括不连续和 Lipschitz-连续实现，以解决现有方法在处理不同类型滑模控制和分析其稳态性能方面的局限性。

Method: 本研究提出了一种统一的频域分析框架，利用描述函数（DF）理论推导了颤振振荡的幅度和频率以及等效增益（EG）模型的闭合形式表达式，并结合 Loebs 判据来考虑轨道稳定性，通过仿真验证了理论预测的准确性。

Result: 理论预测了颤振振荡的幅度和频率，并推导了等效增益（EG）模型，使得能够进行闭环灵敏度分析。仿真结果表明，在低频情况下，EG-आधारित 灵敏度函数能准确预测系统响应的幅度和相位，跟踪误差在 15% 以内。研究还表明，该框架能够考虑执行器动态、控制参数和扰动特性对稳态性能的影响，并确保颤振在有界范围内。

Conclusion: 该研究为滑模控制系统的分析提供了一个统一的频域框架，考虑了不连续和 Lipschitz-连续实现。通过描述函数（DF）理论，推导了颤振振荡的幅度和频率以及等效增益（EG）模型的闭合形式表达式，从而能够进行闭环灵敏度分析。该方法能够捕捉执行器动态、控制参数和扰动特性对稳态性能的影响。理论预测通过仿真得到验证，在低频情况下，EG-आधारित 灵敏度函数能准确预测系统响应的幅度和相位，跟踪误差在 DF 假设成立的情况下保持在 15% 以内。此外，该框架还通过 Loebs 判据纳入了轨道稳定性考虑，确保颤振是有界的。研究结果对滑模控制器的鲁棒设计提供了实际的见解，能够系统地调整增益，平衡扰动抑制和颤振衰减，同时考虑执行器和传感器约束。

Abstract: This paper develops a unified frequency-domain framework for the analysis of
sliding-mode control systems, encompassing both discontinuous and
Lipschitz-continuous implementations. Using describing function (DF) theory,
closed-form expressions are derived for the amplitude and frequency of
chattering oscillations, as well as equivalent gain (EG) models that enable
closed-loop sensitivity analysis. The proposed methodology captures the
influence of actuator dynamics, control parameters, and disturbance profiles on
steady-state performance.
  Theoretical predictions for bias and oscillatory components are validated
through simulations under both constant and sinusoidal perturbations. In the
low-frequency regime, the EG-based sensitivity functions accurately predict the
amplitude and phase of the system response, with tracking errors remaining
within a 15\% margin, provided that the DF assumptions hold. The framework also
incorporates orbital stability considerations via Loebs criterion, ensuring
that chattering remains bounded.
  Overall, the results offer practical insight into the robust design of
sliding-mode controllers, enabling systematic gain tuning that balances
disturbance rejection and chattering attenuation, while accounting for actuator
and sensor constraints.

</details>


### [193] [Polarforming Design for Movable Antenna Systems](https://arxiv.org/abs/2507.16311)
*Zijian Zhou,Jingze Ding,Rui Zhang*

Main category: eess.SY

TL;DR: 本研究提出了一种结合移动天线（MA）和极化形成技术的通信系统，通过优化天线位置和极化相位移，提高了通信速率和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 为了提高通信系统的性能，利用移动天线（MA）和极化形成技术来调整天线的极化状态，以匹配接收的电磁波或重新配置发射的电磁波。

Method: 提出了一种极化信道模型，并将信道响应表征为天线位置和极化形成移相的函数。随后，开发了一种基于连续凸近似（SCA）的优化算法，通过迭代优化发射端和接收端的移动天线位置和极化相位移，以最大化可实现速率。

Result: 仿真结果表明，与传统系统相比，所提出的系统在减轻信道去极化和适应信道衰落方面具有显著的性能增益。

Conclusion: 所提出的通信系统通过利用移动天线（MA）和极化形成技术，在最大化可实现速率和克服信道去极化及适应信道衰落方面表现出优越性能。

Abstract: Polarforming has emerged as a promising technique to enable the antenna to
shape its polarization into a desired state for aligning with that of the
received electromagnetic (EM) wave or reconfiguring that of the transmitted EM
wave. In this letter, we investigate polarforming design for the movable
antenna (MA)-enabled communication system. Specifically, we consider a
single-input single-output (SISO) system with reconfigurable antenna positions
and polarizations to leverage both spatial and polarization degrees of freedom
(DoFs). First, we present a polarized channel model and characterize the
channel response as a function of antenna positions and polarforming phase
shifts. To maximize the achievable rate of the proposed system, we then develop
a successive convex approximation (SCA)-based optimization algorithm by
iteratively optimizing the antenna positions and phase shifts at both the
transmitter and receiver. Furthermore, simulation results demonstrate the
performance gains of the proposed system over conventional systems in
mitigating channel depolarization and adapting to channel fading.

</details>


### [194] [Derivative-Agnostic Inference of Nonlinear Hybrid Systems](https://arxiv.org/abs/2507.16426)
*Hengzhi Yu,Bohan Ma,Mingshuai Chen,Jie An,Bin Gu,Naijun Zhan,Jianwei Yin*

Main category: eess.SY

TL;DR: Dainarx is a new approach to infer hybrid automata from input-output traces. It uses NARX models to represent the system in a unified, threshold-free way. Dainarx is more accurate than existing methods for learning complex hybrid systems.


<details>
  <summary>Details</summary>
Motivation: Inferring a hybrid automaton from a set of input-output traces of a hybrid system exhibiting discrete mode switching between continuously evolving dynamics.

Method: Dainarx employs nonlinear autoregressive exogenous (NARX) models as a unified, threshold-free representation through the detection of mode switching and trace-segment clustering.

Result: Dainarx suffices to learn models that closely approximate a general class of hybrid systems featuring high-order nonlinear dynamics with exogenous inputs, nonlinear guard conditions, and linear resets.

Conclusion: Dainarx can effectively and efficiently infer nontrivial hybrid automata with high-order dynamics yielding significantly more accurate approximations than state-of-the-art techniques.

Abstract: This paper addresses the problem of inferring a hybrid automaton from a set
of input-output traces of a hybrid system exhibiting discrete mode switching
between continuously evolving dynamics. Existing approaches mainly adopt a
derivative-based method where (i) the occurrence of mode switching is
determined by a drastic variation in derivatives and (ii) the clustering of
trace segments relies on signal similarity -- both subject to user-supplied
thresholds. We present a derivative-agnostic approach, named Dainarx, to infer
nonlinear hybrid systems where the dynamics are captured by nonlinear
autoregressive exogenous (NARX) models. Dainarx employs NARX models as a
unified, threshold-free representation through the detection of mode switching
and trace-segment clustering. We show that Dainarx suffices to learn models
that closely approximate a general class of hybrid systems featuring high-order
nonlinear dynamics with exogenous inputs, nonlinear guard conditions, and
linear resets. Experimental results on a collection of benchmarks indicate that
our approach can effectively and efficiently infer nontrivial hybrid automata
with high-order dynamics yielding significantly more accurate approximations
than state-of-the-art techniques.

</details>


### [195] [Arbitrage Tactics in the Local Markets via Hierarchical Multi-agent Reinforcement Learning](https://arxiv.org/abs/2507.16479)
*Haoyang Zhang,Mina Montazeri,Philipp Heer,Koen Kok,Nikolaos G. Paterakis*

Main category: eess.SY

TL;DR: 本研究提出了一种新的HMARL算法，使聚合商能够通过在LEM、LFM和平衡市场之间进行套利来增加利润。实验证明，该方法平均可将利润提高40.6%。


<details>
  <summary>Details</summary>
Motivation: 现有研究主要关注单个市场中的策略性投标，而忽略了跨本地市场的套利机会。本研究旨在填补这一空白，探索聚合商如何在本地电力市场（LEM）和本地灵活性市场（LFM）等多个市场中通过套利来最大化经济效益。

Method: 提出了一种分层多智能体强化学习（HMARL）算法，将聚合商跨多个本地市场进行套利的策略建模为一个两阶段马尔可夫博弈。在该框架中，每个聚合商有两个子智能体：一个主子智能体负责第一阶段（LEM）的利润，一个次级子智能体负责第二阶段（LFM和平衡市场）的利润。当采用套利策略时，子智能体之间会进行通信与协调，以实现跨本地市场的套利。

Result: 在所有聚合商都采用套利策略的场景下进行的案例研究表明，尽管在LEM中初始成本较高，但该策略在LFM和平衡市场中产生了可观的节省，平均总利润增加了40.6%。

Conclusion: 该研究提出的分层多智能体强化学习（HMARL）框架能够解决两阶段马尔可夫博弈，并促进跨本地市场的套利，从而提高参与者的盈利能力。

Abstract: Strategic bidding tactics employed by prosumers in local markets, including
the Local Electricity Market (LEM) and Local Flexibility Market (LFM), have
attracted significant attention due to their potential to enhance economic
benefits for market participants through optimized energy management and
bidding. While existing research has explored strategic bidding in a single
market with multi-agent reinforcement learning (MARL) algorithms, arbitrage
opportunities across local markets remain unexplored. This paper introduces a
hierarchical MARL (HMARL) algorithm designed to enable aggregator arbitrage
across multiple local markets. The strategic behavior of these aggregators in
local markets is modeled as a two-stage Markov game: the first stage involves
the LEM, while the second stage encompasses both the LFM and the balancing
market. To solve this two-stage Markov game, the HMARL framework assigns two
sub-agents to each aggregator, a primary sub-agent and a secondary sub-agent.
Without the arbitrage strategy, these sub-agents operate in silos, with the
primary sub-agent focusing on first-stage profits and the secondary sub-agent
on second-stage profits, each employing independent MARLs. On the contrary,
when implementing the arbitrage strategy with the proposed HMARL, the
sub-agents communicate and coordinate to perform arbitrage across multiple
local markets, enhancing overall efficiency. The case study, conducted under a
scenario where all aggregators employ the arbitrage strategy, shows that
despite higher initial costs in the LEM, this strategy generates substantial
savings in the LFM and the balancing market, resulting in a total profit
increase of $40.6\%$ on average. This highlights the capability of the proposed
HMARL to address the two-stage Markov game and facilitate arbitrage across
local markets, thereby enhancing profitability for participants.

</details>


### [196] [Graphical Analysis of Nonlinear Multivariable Feedback Systems](https://arxiv.org/abs/2507.16513)
*Julius P. J. Krebbekx,Roland Tóth,Amritam Das*

Main category: eess.SY

TL;DR: 本文提出了一种分析非线性、非对方块 MIMO 系统的 SRG 框架，通过将算子嵌入共同的希尔伯特空间并限制输入空间来解决现有方法的局限性。


<details>
  <summary>Details</summary>
Motivation: 已有的 SRG 分析方法仅限于平方系统，或仅适用于 LTI 系统。

Method: 通过将算子嵌入到作用于共同希尔伯特空间的算子空间，同时将输入空间限制在原始输入维度，来分析 MIMO 系统。开发了互联规则，利用受限输入空间和稳定性定理来保证因果关系、适定性和（增量）L2 增益界限。

Result: 为 LTI 算子和对角静态非线性算子计算 MIMO SRG 的公式，并演示了该方法的有效性。

Conclusion: 本文为 MIMO 系统开发了一个完整的 SRG 框架，该框架可用于非线性且不匹配的系统。

Abstract: Scaled Relative Graphs (SRGs) provide a novel graphical frequency-domain
method for the analysis of nonlinear systems. There have been recent efforts to
generalize SRG analysis to Multiple-Input Multiple-Output (MIMO) systems.
However, these attempts yielded only results for square systems, and in some
cases, only methods applicable for Linear Time-Invariant (LTI) systems. In this
paper, we develop a complete SRG framework for the analysis of MIMO systems,
which may be nonlinear and non-square. The key element is the embedding of
operators to a space of operators acting on a common Hilbert space, while
restricting the input space to the original input dimension. We develop
interconnection rules that use restricted input spaces and stability theorems
to guarantee causality, well-posedness and (incremental) $L_2$-gain bounds for
the overall interconnection. We show utilization of the proposed theoretical
concepts on the analysis of nonlinear systems in a linear fractional
representation form, which is a rather general class of systems with a
representation form directly utilizable for control. Moreover, we provide
formulas for the computation of MIMO SRGs of stable LTI operators and diagonal
static nonlinear operators. Finally, we demonstrate the capabilities of our
proposed approach on several examples.

</details>


### [197] [A Distributed Actor-Critic Algorithm for Fixed-Time Consensus in Nonlinear Multi-Agent Systems](https://arxiv.org/abs/2507.16520)
*Aria Delshad,Maryam Babazadeh*

Main category: eess.SY

TL;DR: 使用基于强化学习的反步控制策略，实现非线性多智能体系统的固定时间共识。


<details>
  <summary>Details</summary>
Motivation: 为了在存在未知非线性、智能体耦合和外部扰动的情况下，实现预先设定的、与初始条件无关的收敛时间，即固定时间共识。

Method: 本研究提出了一种基于强化学习（RL）的反步控制策略，并结合了新的固定时间自适应机制。每个智能体采用包含两个估计网络的actor-critic架构来处理系统不确定性和未知扰动，自适应律确保所有智能体在固定时间内跟踪领导者。

Result: 仿真结果表明，该方法能够实现固定时间共识，收敛半径可通过控制参数调节，并且在收敛速度和鲁棒性方面表现出优势。

Conclusion: 该研究提出的基于强化学习的固定时间反步控制策略，能够有效地使具有严格反馈的非线性多智能体系统实现固定时间共识，并且在收敛速度和鲁棒性方面优于现有方法。

Abstract: This paper proposes a reinforcement learning (RL)-based backstepping control
strategy to achieve fixed time consensus in nonlinear multi-agent systems with
strict feedback dynamics. Agents exchange only output information with their
neighbors over a directed communication graph, without requiring full state
measurements or symmetric communication. Achieving fixed time consensus, where
convergence occurs within a pre-specified time bound that is independent of
initial conditions is faced with significant challenges due to the presence of
unknown nonlinearities, inter-agent couplings, and external disturbances. This
work addresses these challenges by integrating actor critic reinforcement
learning with a novel fixed time adaptation mechanism. Each agent employs an
actor critic architecture supported by two estimator networks designed to
handle system uncertainties and unknown perturbations. The adaptation laws are
developed to ensure that all agents track the leader within a fixed time
regardless of their initial conditions. The consensus and tracking errors are
guaranteed to converge to a small neighborhood of the origin, with the
convergence radius adjustable through control parameters. Simulation results
demonstrate the effectiveness of the proposed approach and highlight its
advantages over state-of-the-art methods in terms of convergence speed and
robustness.

</details>


### [198] [Integral action for bilinear systems with application to counter current heat exchanger](https://arxiv.org/abs/2507.16553)
*Francesco Ripa,Daniele Astolfi,Boussad Hamroun,Diego Regruto*

Main category: eess.SY

TL;DR: 研究提出了一种用于逆流换热器的稳健控制策略，通过操纵一种流体的流量来调节另一种流体的出口温度。该方法基于双线性系统模型，并包含三种控制策略，通过实际实验进行了验证。


<details>
  <summary>Details</summary>
Motivation: 本研究的主要目标是通过操纵第二种逆流流体的流量来调节一种流体的出口温度。

Method: 通过利用能量平衡方程，推导出一个结构化双线性系统模型，该模型是通过将每个流体流均匀地空间离散化为一系列均匀体积，并考虑换热器内的传热和对流现象得出的。提出了三种控制策略：(i)一种增强的前馈控制器，(ii)一种结合状态观测器的输出反馈控制器，以及(iii)一种纯粹的积分控制律。

Result: 对一种流体的出口温度进行了稳健的控制。

Conclusion: 通过实际热交换器上的真实实验验证了所提出的控制策略的有效性。

Abstract: In this study, we propose a robust control strategy for a counter-current
heat exchanger. The primary objective is to regulate the outlet temperature of
one fluid stream by manipulating the flow rate of the second counter-current
fluid stream. By leveraging the energy balance equations, we develop a
structured bilinear system model derived by using a uniform spatial
discretization of each stream into a cascade of homogeneous volumes and by
considering the heat transfer and convective phenomena within the exchanger. We
introduce three control strategies: (i) an enhanced forwarding-based
controller, (ii) an output feedback controller incorporating a state observer,
and (iii) a purely integral control law. The effectiveness of the proposed
control strategy is validated through real experiments on a real heat
exchanger.

</details>


### [199] [Dynamic Activation and Assignment of SDN Controllers in LEO Satellite Constellations](https://arxiv.org/abs/2507.16774)
*Wafa Hasanain,Pablo G. Madoery,Halim Yanikomeroglu,Gunes Karabulut Kurt,Sameera Siddiqui,Stephane Martel,Khaled Ahmed,Colin Bellinger*

Main category: eess.SY

TL;DR: 该研究提出了一个SDN框架和DSCA方法，以动态优化LEO卫星网络的控制器分配，减少延迟并提高效率，优于静态分配方法。


<details>
  <summary>Details</summary>
Motivation: 为了解决传统卫星通信管理和未来服务（如卫星与地面网络融合）的挑战，以及应对LEO卫星星座中动态控制器分配的重大挑战，论文提出了一种SDN解决方案。

Method: 在OMNeT++仿真环境中，开发了一个支持OpenFlow协议的SDN框架，并提出DSCA优化问题来动态调整卫星与控制器的分配，以应对LEO卫星的移动性挑战。

Result: 与静态分配（SSCA）相比，DSCA方法显著提高了网络效率，并发现了控制器数量超过一定阈值后性能提升会逐渐减小，表明使用有限数量的控制器可实现最佳性能。

Conclusion: 该研究提出了一种动态卫星到控制器分配（DSCA）优化方法，并给出了最优DSCA（Opt-DSCA）的解决方案，以最小化网络延迟并优化控制器数量，从而提高了LEO卫星网络的性能。

Abstract: Software-defined networking (SDN) has emerged as a promising approach for
managing traditional satellite communication. This enhances opportunities for
future services, including integrating satellite and terrestrial networks. In
this paper, we have developed an SDN-enabled framework for Low Earth Orbit
(LEO) satellite networks, incorporating the OpenFlow protocol, all within an
OMNeT++ simulation environment. Dynamic controller assignment is one of the
most significant challenges for large LEO constellations. Due to the movement
of LEO satellites, satellite-controller assignments must be updated frequently
to maintain low propagation delays. To address this issue, we present a dynamic
satellite-to-controller assignment (DSCA) optimization problem that
continuously adjusts these assignments. Our optimal DSCA (Opt-DSCA) approach
minimizes propagation delay and optimizes the number of active controllers. Our
preliminary results demonstrate that the DSCA approach significantly
outperforms the static satellite-to-controller assignment (SSCA) approach.
While SSCA may perform better with more controllers, this scheme fails to adapt
to satellite movements. Our DSCA approach consistently improves network
efficiency by dynamically reassigning satellites based on propagation delays.
Further, we found diminishing returns when the number of controllers is
increased beyond a certain point, suggesting optimal performance with a limited
number of controllers. Opt-DSCA lowers propagation delays and improves network
performance by optimizing satellite assignments and reducing active
controllers.

</details>


<div id='physics.app-ph'></div>

# physics.app-ph [[Back]](#toc)

### [200] [Physics-Informed Regression Modelling for Vertical Facade Surface Temperature: A Tropical Case Study on Solar-reflective Material](https://arxiv.org/abs/2507.16174)
*Shisheng Chen,Shanshan Tong,Nyuk Hien Wong,May Lwin Oo,Joie Lim,Erna Tan,Ruohan Xu,Marcel Ignatius,Yang He,Zhenjiang Shen*

Main category: physics.app-ph

TL;DR: 本研究评估了太阳反射涂料在新加坡减少城市热岛效应的有效性。使用结合物理模型和机器学习（特别是物理信息MLR）的混合方法，发现提高涂料反照率可显著降低表面温度和热量储存，从而有效缓解城市热岛效应。


<details>
  <summary>Details</summary>
Motivation: 城市热岛效应（UHIs）是人口稠密城市和热带地区面临的严峻挑战，这些地区需要消耗大量能源来满足制冷需求。为了应对这一挑战，新加坡建设局（BCA）在其绿色建筑标志指南中，鼓励采用被动式降温措施，例如使用太阳反射材料。因此，了解这些材料在热带城市环境中的实际效果至关重要。

Method: 本研究采用混合建模框架，结合了瞬态物理模型和数据驱动模型，并通过实地测量进行评估。研究中比较了多种机器学习算法，包括多元线性回归（MLR）、随机森林回归（RF）、AdaBoost回归（AB）、极端梯度提升回归（XGB）和TabPFN回归（TPR）。

Result: 研究结果表明，瞬态物理模型在较低温度范围内高估了外墙温度。物理信息MLR模型在预涂漆（R²=0.96, RMSE=0.83°C）和后涂漆（R²=0.95, RMSE=0.65°C）情况下均表现最佳，分别将RMSE降低了26%和44%。混合模型有效预测了每小时热通量，显示随着反照率的增加，表面温度和热量储存显著降低。与预涂漆（反照率=0.31）相比，后涂漆（反照率=0.73）阶段的最大净热通量（q_net）减少了约30-65 W/m²。敏感性分析预测，当反照率从0.1增加到0.9时，最大白天表面温度将降低约11°C，净热通量的峰值热量释放将从约161 W/m²显著降低到27 W/m²。

Conclusion: 研究结果表明，太阳反射涂料在减少城市热岛效应方面是有效的。通过混合建模框架和实测数据，研究评估了太阳反射冷漆的有效性，并比较了几种机器学习算法。结果显示，物理信息MLR模型在预涂漆和后涂漆情况下均表现最佳，显著提高了准确性，降低了均方根误差（RMSE）。混合模型有效预测了热通量，表明随着反照率的增加，表面温度和热量储存显著降低。研究还预测，随着反照率的增加，最大白天表面温度将降低约11°C，净热通量的峰值热量释放将从约161 W/m²显著降低到27 W/m²。

Abstract: Urban heat islands (UHIs) pose a critical challenge in densely populated
cities and tropical climates where large amounts of energy are used to meet the
cooling demand. To address this, Building and Construction Authority (BCA) of
Singapore provides incentives for passive cooling such as using of
solar-reflective material in its Green Mark guidelines. Thus, understanding
about its real-world effectiveness in tropical urban environments is required.
This study evaluated the effectiveness of solar-reflective cool paint using a
hybrid modelling framework combining a transient physical model and data driven
model through field measurements. Several machine learning algorithms were
compared including multiple-linear regression (MLR), random forest regressor
(RF), AdaBoost regressor (AB), extreme gradient boosting regressor (XGB), and
TabPFN regressor (TPR). The results indicated that the transient physical model
overestimated facade temperatures in the lower temperature ranges. The
physics-informed MLR achieved best performance with improved accuracy for
pre-cool paint (R2=0.96, RMSE=0.83C) and post-cool paint (R2=0.95, RMSE=0.65C)
scenarios, reducing RMSE by 26% and 44%, respectively. The hybrid model also
effectively predicted hourly heat fluxes revealing substantial reductions in
surface temperature and heat storage with increasing albedo. The maximum net
heat flux q_net was reduced by about 30-65 W/m2 in the post-cool paint stage
(albedo = 0.73) compared to the pre-cool paint stage (albedo = 0.31). As albedo
increases from 0.1 to 0.9, the sensitivity analysis predicts that the maximum
daytime surface temperature will decrease by about 11C and the peak heat
release of the net heat flux will decrease significantly from about 161 W/m2 to
27 W/m2.

</details>


### [201] [Quantifying Key Design Factors for Thermal Comfort in Underground Space Through Global Sensitivity Analysis and Machine Learning](https://arxiv.org/abs/2507.16202)
*Shisheng Chen,Nyuk Hien Wong,Chao Cen,Ruohan Xu,Lei Xu,Zhenjiang Shen,Zhigang Wua,Jiayan Fu,Zhongqi Yu*

Main category: physics.app-ph

TL;DR: 福州高温下，地下空间比地面和屋顶更凉爽舒适。MET和风速是影响地下空间舒适度的关键因素。地下空间是理想的避暑场所。


<details>
  <summary>Details</summary>
Motivation: 本研究旨在识别和分析高温、高湿气候条件下，自然通风地下空间在提升城市热舒适度方面的关键设计因素，特别是在城市极端高温背景下，为提供避暑空间提供参考。

Method: 通过实地测量和统计分析（如Kolmogorov-Smirnov检验和全局敏感性分析）来评估福州在高温条件下（室外最高温度42.9$^	ext{o}	ext{C}$）的自然通风地下空间、行人层和屋顶的热舒适度。分析了平均辐射温度（MRT）、空气温度（AT）、风速（V）、相对湿度（RH）和平均行人热舒适指数（PET）等参数。

Result: 地下空间表现出最稳定且最低的PET（平均35.4$^	ext{o}	ext{C}$），优于行人层（平均37.4$^	ext{o}	ext{C}$）和屋顶（平均40.6$^	ext{o}	ext{C}$）。新陈代谢当量（MET）对地下空间PET的影响最大（占60%），其次是空气温度（AT）（20%）和风速（V）（10%）。增加风速和保持遮蔽是改善地下空间热舒适度的有效途径。

Conclusion: 地下空间在炎热条件下可作为有效的避暑场所，其热舒适度受新陈代谢当量（MET）和风速（V）等因素显著影响。研究确定了四个地下空间利用时段，并强调了良好的通风和遮蔽对于提升热舒适度的重要性。

Abstract: This study identified the key design factors related to thermal comfort in
naturally ventilated underground spaces under high temperature condition
(outdoor Tmax = 42.9$^\circ\mathrm{C}$) in Fuzhou, China. Fuzhou has a humid
subtropical climate and is one of the three hottest cities in China in 2024.
The reference roof measurement point showed the highest heat exposure (36.3%
>35$^\circ\mathrm{C}$) followed by pedestrian-level areas (20.4%
>35$^\circ\mathrm{C}$), while the underground remained consistently cooler (0%
>35$^\circ\mathrm{C}$). Kolmogorov-Smirnov tests confirmed significant
differences (p < 0.001) in environmental conditions (e.g., AT, GT, MRT, V, RH).
Underground spaces showed the most stable and lowest PET (mean PET =
35.4$^\circ\mathrm{C}$) due to high thermal mass and shading, although moderate
to intense thermal stresses still existed. Pedestrian-level spaces displayed
greater PET variation (mean = 37.4$^\circ\mathrm{C}$) influenced by direct and
diffuse solar radiation, while roofs suffered from extreme heat stress (mean
PET = 40.6$^\circ\mathrm{C}$) peaking at 100% frequency from 9:00 to 14:00.
Four distinct periods including early morning transition, evening transition,
cooling, and heat stressing were identified for optimal underground space
utilization as heat shelter. The global sensitivity analysis showed that
variations in MET explained 60% of the variance in PET within the underground
environment, followed by AT (20%), V (10%), MRT (5%), and RH (5%). The partial
dependence analysis indicated that PET in underground space rose by
approximately 7$^\circ\mathrm{C}$ when MET increased from 1 to 5 met, while a 1
m/s rise in V led to a 2$^\circ\mathrm{C}$ reduction in PET, suggesting shaded
areas with good ventilation can significantly improve thermal comfort even if
AT remains moderately high.

</details>


### [202] [High-efficiency atmospheric water harvesting enabled by ultrasonic extraction](https://arxiv.org/abs/2507.16684)
*Ikra Shuvo,Carlos D. Diaz-Marin,Marvin Christen,Michael Lherbette,Christopher Liem,Svetlana V. Boriskina*

Main category: physics.app-ph

TL;DR: 振动机械驱动可以替代热量提取空气中的水分，能效比现有技术提高45倍，使空气制水技术更具经济可行性。


<details>
  <summary>Details</summary>
Motivation: 解决现有空气制水技术能耗高，特别是热诱导蒸发过程的能耗问题，以实现去中心化制水。

Method: 通过振动机械驱动从湿气收集材料中提取水，而不是使用热诱导蒸发。

Result: 水提取的能量消耗低于水的蒸发焓，能效比现有技术热蒸发提高了约45倍。

Conclusion: 大气水收集技术通过振动机械驱动替代热量进行吸水，能效提高约45倍，使该技术在经济上可行。

Abstract: Atmospheric water harvesting technology, which extracts moisture from ambient
air to generate water, is a promising strategy to realize decentralized water
production. However, the prohibitively high energy consumption of heat-induced
evaporation process of water extraction hinders the technology deployment. Here
we demonstrate that vibrational mechanical actuation can be used instead of
heat to extract water from moisture harvesting materials, offering about
forty-five-fold increase in the extraction energy efficiency. We report the
energy consumption for water extraction below the enthalpy of water
evaporation, thus breaking the thermal limit of the energy efficiency inherent
to the state-of-the-art thermal evaporation and making atmospheric water
harvesting technology economically feasible for adoption on scale.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [203] [From Reasoning to Super-Intelligence: A Search-Theoretic Perspective](https://arxiv.org/abs/2507.15865)
*Shai Shalev-Shwartz,Amnon Shashua*

Main category: cs.AI

TL;DR: Diligent Learner 是一种新的学习范式，通过深度优先搜索和回溯来解决 CoT 学习中的挑战，并在理论上证明了其在复杂推理任务上的优越性。


<details>
  <summary>Details</summary>
Motivation: 现有 CoT 学习方法在复杂推理任务上存在不足，理论基础不完善，存在分布漂移、缺乏嵌入式搜索和指数级推理成本等问题。

Method: 提出了一种名为 Diligent Learner 的新学习范式，将推理显式地建模为由验证器指导的深度优先搜索，并支持失败时回溯。

Result: 证明了 Diligent Learner 在满足两个温和且现实的假设下，能够有效地从 CoT 数据中学习，而现有方法则会失败。

Conclusion: Diligent Learner 框架证明了其效率，有望构建可扩展、可靠的推理系统，并为开发具有鲁棒、可解释问题解决能力的LRM铺平道路。

Abstract: Chain-of-Thought (CoT) reasoning has emerged as a powerful tool for enhancing
the problem-solving capabilities of large language models (LLMs). However, the
theoretical foundations of learning from CoT data remain underdeveloped, and
existing approaches -- such as Supervised Fine-Tuning (SFT), Reinforcement
Learning (RL), Tree-of-Thoughts (ToT), and Monte Carlo Tree Search (MCTS) --
often fail on complex reasoning tasks. In this work, we identify core obstacles
that hinder effective CoT learning, including distribution drift, lack of
embedded search, and exponential inference costs. We introduce the Diligent
Learner, a new learning paradigm that explicitly models reasoning as a
depth-first search guided by a validator and supports backtracking upon
failure. Under two mild and realistic assumptions, we prove that the Diligent
Learner can efficiently learn from CoT data while existing methods fail to do
so. This framework offers a path toward building scalable and reliable
reasoning systems trained on naturally occurring, incomplete data -- paving the
way for the development of Large Reasoning Models (LRMs) with robust,
interpretable problem-solving abilities.

</details>


### [204] [Purchase and Production Optimization in a Meat Processing Plant](https://arxiv.org/abs/2507.15866)
*Marek Vlk,Premysl Sucha,Jaroslaw Rudy,Radoslaw Idzikowski*

Main category: cs.AI

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: The food production industry, especially the meat production sector, faces
many challenges that have even escalated due to the recent outbreak of the
energy crisis in the European Union. Therefore, efficient use of input
materials is an essential aspect affecting the profit of such companies. This
paper addresses an optimization problem concerning the purchase and subsequent
material processing we solved for a meat processing company. Unlike the
majority of existing papers, we do not concentrate on how this problem concerns
supply chain management, but we focus purely on the production stage. The
problem involves the concept of alternative ways of material processing, stock
of material with different expiration dates, and extra constraints widely
neglected in the current literature, namely, the minimum order quantity and the
minimum percentage in alternatives. We prove that each of these two constraints
makes the problem \mbox{$\mathcal{NP}$-hard}, and hence we design a simple
iterative approach based on integer linear programming that allows us to solve
real-life instances even using an open-source integer linear programming
solver. Another advantage of this approach is that it mitigates numerical
issues, caused by the extensive range of data values, we experienced with a
commercial solver. The results obtained using real data from the meat
processing company showed that our algorithm can find the optimum solution in a
few seconds for all considered use cases.

</details>


### [205] [Why Braking? Scenario Extraction and Reasoning Utilizing LLM](https://arxiv.org/abs/2507.15874)
*Yin Wu,Daniel Slieter,Vivek Subramanian,Ahmed Abouelazm,Robin Bohn,J. Marius Zöllner*

Main category: cs.AI

TL;DR: 本研究提出了一种利用大型语言模型（LLM）来理解和检索驾驶场景（特别是刹车事件）的新方法，解决了现有基于规则的方法在复杂城市环境中泛化能力不足的问题。该方法通过弥合数值信号和自然语言描述之间的差距，并采用双路径检索策略，能够有效处理已知和未知场景，并在实验中取得了优于基线方法的性能。


<details>
  <summary>Details</summary>
Motivation: 自动驾驶系统（ADAS）车辆的增加产生了大量驾驶数据，但大部分数据仅包含常规驾驶行为。在这些数据中识别和理解安全关键的边缘案例仍然是一个重大挑战。刹车事件尤其能指示潜在的危险情况，因此研究的核心问题是“车辆为何刹车？”。

Method: 提出了一种新颖的框架，利用大型语言模型（LLM）进行场景理解和推理，并提出了一种双路径场景检索方法，支持基于类别的搜索和基于嵌入的检索，以处理已知和未知的离群场景。

Result: 实验结果表明，本研究提出的方法优于基于规则的方法，并且能够很好地泛化到离群场景。

Conclusion: 本研究提出的新框架利用大型语言模型（LLM）进行场景理解和推理，成功弥补了低级数值信号与自然语言描述之间的差距，使 LLM 能够解释和分类驾驶场景。该方法支持基于类别的搜索和基于嵌入的检索，能够处理已知和未知的（离群）场景。

Abstract: The growing number of ADAS-equipped vehicles has led to a dramatic increase
in driving data, yet most of them capture routine driving behavior. Identifying
and understanding safety-critical corner cases within this vast dataset remains
a significant challenge. Braking events are particularly indicative of
potentially hazardous situations, motivating the central question of our
research: Why does a vehicle brake? Existing approaches primarily rely on
rule-based heuristics to retrieve target scenarios using predefined condition
filters. While effective in simple environments such as highways, these methods
lack generalization in complex urban settings. In this paper, we propose a
novel framework that leverages Large Language Model (LLM) for scenario
understanding and reasoning. Our method bridges the gap between low-level
numerical signals and natural language descriptions, enabling LLM to interpret
and classify driving scenarios. We propose a dual-path scenario retrieval that
supports both category-based search for known scenarios and embedding-based
retrieval for unknown Out-of-Distribution (OOD) scenarios. To facilitate
evaluation, we curate scenario annotations on the Argoverse 2 Sensor Dataset.
Experimental results show that our method outperforms rule-based baselines and
generalizes well to OOD scenarios.

</details>


### [206] [Advancing Responsible Innovation in Agentic AI: A study of Ethical Frameworks for Household Automation](https://arxiv.org/abs/2507.15901)
*Joydeep Chandra,Satyam Kumar Navneet*

Main category: cs.AI

TL;DR: 本文探讨了家庭环境中代理AI的伦理挑战，重点关注隐私、公平和用户控制。它为设计负责任的智能家居系统提供了指导，并强调了对老年人、儿童和神经多样性等弱势群体的保护。


<details>
  <summary>Details</summary>
Motivation: 在家庭环境中实施人工智能（AI），特别是以主动自主代理的形式，带来了舒适和关注的可能性，同时也带来了内外的伦理挑战。

Method: 本文分析了代理AI及其应用，重点关注其从被动到主动自主、隐私、公平和用户控制的转变。我们回顾了负责任的创新框架、以人为本的设计原则和治理实践，为符合伦理的智能家居系统提炼了实用的指导。

Result: 文章强调了量身定制的可解释性、渐进式同意机制和强大的覆盖控制等设计要求，并辅以参与性和包容性方法。还探讨了数据驱动的见解（包括通过自然语言处理（NLP）进行的社交媒体分析）如何为特定的用户需求和伦理问题提供信息。

Conclusion: 该调查旨在为开发透明、包容和值得信赖的家庭自动化代理AI提供概念基础和建议。

Abstract: The implementation of Artificial Intelligence (AI) in household environments,
especially in the form of proactive autonomous agents, brings about
possibilities of comfort and attention as well as it comes with intra or
extramural ethical challenges. This article analyzes agentic AI and its
applications, focusing on its move from reactive to proactive autonomy,
privacy, fairness and user control. We review responsible innovation
frameworks, human-centered design principles, and governance practices to
distill practical guidance for ethical smart home systems. Vulnerable user
groups such as elderly individuals, children, and neurodivergent who face
higher risks of surveillance, bias, and privacy risks were studied in detail in
context of Agentic AI. Design imperatives are highlighted such as tailored
explainability, granular consent mechanisms, and robust override controls,
supported by participatory and inclusive methodologies. It was also explored
how data-driven insights, including social media analysis via Natural Language
Processing(NLP), can inform specific user needs and ethical concerns. This
survey aims to provide both a conceptual foundation and suggestions for
developing transparent, inclusive, and trustworthy agentic AI in household
automation.

</details>


### [207] [A Unifying Framework for Semiring-Based Constraint Logic Programming With Negation (full version)](https://arxiv.org/abs/2507.16067)
*Jeroen Spaans,Jesse Heyninck*

Main category: cs.AI

TL;DR: 本研究提出了一个允许在子句体中使用否定的CLP扩展，并提供了相应的语义，为CLP领域提供了一个更统一和更具表现力的框架。


<details>
  <summary>Details</summary>
Motivation: 现有CLP扩展未能研究允许在子句体中使用否定的情况，本研究旨在解决这一空白，并提供一个更具表达力的语言。

Method: 使用近似不动点理论的框架来为该扩展的程序提供语义，并详细分析了半环的属性对结果语义的影响。

Result: 一个统一的CLP框架，能够捕捉现有方法并允许使用更具表现力的语言进行扩展。

Conclusion: 该研究提出了一个约束逻辑编程（CLP）的扩展，该扩展统一了许多现有的方法，并允许在子句体中使用否定。

Abstract: Constraint Logic Programming (CLP) is a logic programming formalism used to
solve problems requiring the consideration of constraints, like resource
allocation and automated planning and scheduling. It has previously been
extended in various directions, for example to support fuzzy constraint
satisfaction, uncertainty, or negation, with different notions of semiring
being used as a unifying abstraction for these generalizations. None of these
extensions have studied clauses with negation allowed in the body. We
investigate an extension of CLP which unifies many of these extensions and
allows negation in the body. We provide semantics for such programs, using the
framework of approximation fixpoint theory, and give a detailed overview of the
impacts of properties of the semirings on the resulting semantics. As such, we
provide a unifying framework that captures existing approaches and allows
extending them with a more expressive language.

</details>


### [208] [Differential Multimodal Transformers](https://arxiv.org/abs/2507.15875)
*Jerry Li,Timothy Oh,Joseph Hoang,Vardhit Veeramachaneni*

Main category: cs.AI

TL;DR: 本研究将差分注意力机制扩展到文本-视觉模型PaliGemma，以减轻噪声信息检索和减少幻觉。通过使用LoRA对PaliGemma 3B模型进行微调并集成差分注意力机制，我们证明了该机制可以有效提升模型的噪声信息检索和问答能力。


<details>
  <summary>Details</summary>
Motivation: 为了解决将视觉等额外模态引入可能加剧由噪声引起的问题，以及Transformer注意力机制不成比例地关注不相关上下文的挑战。

Method: 对PaliGemma 3B模型使用LoRA进行微调，并结合差分注意力机制，同时试验了各种参数设置和配置。

Result: 实验证明，Differential Attention可以适应并集成到现有模型的微调中，以增强噪声信息检索和问答能力。

Conclusion: Differential Attention机制可以适应并集成到现有模型的微调中，以增强噪声信息检索和问答能力。

Abstract: Small language models have gained significant popularity due to their
efficiency and growing capabilities. However, incorporating additional
modalities, such as vision, can exacerbate the challenge of limited context
windows by introducing noise. Recent studies have highlighted that Transformer
attention mechanisms often disproportionately focus on irrelevant contexts. In
this work, we extend the Differential Attention mechanism, originally designed
for text-only models, to the text-vision model PaliGemma. Our aim is to
evaluate its ability to mitigate noisy information retrieval and reduce
hallucinations. To this end, we fine-tuned the PaliGemma 3B model using LoRA,
incorporating Differential Attention, and experimented with various parameter
settings and configurations. We demonstrate that Differential Attention can be
adapted and integrated into the fine-tuning of existing models to enhance noisy
information retrieval and question-answering capabilities.

</details>


### [209] [Improving ASP-based ORS Schedules through Machine Learning Predictions](https://arxiv.org/abs/2507.16454)
*Pierangela Bruno,Carmine Dodaro,Giuseppe Galatà,Marco Maratea,Marco Mochi*

Main category: cs.AI

TL;DR: 本研究提出了一种结合机器学习和约束编程的方法，用于优化医院手术室调度，解决了现有方法的局限性。


<details>
  <summary>Details</summary>
Motivation: 解决现有基于ASP的医院手术室调度（ORS）方案在处理实际数据时无法生成临时调度且调度不够鲁棒的问题。

Method: 本研究结合了机器学习（用于预测手术持续时间）和约束编程（更新编码以生成更鲁棒的调度）技术。

Result: 通过整合归纳和演绎技术，能够生成临时调度并提高调度的鲁棒性，在ASL1 Liguria的历史数据上验证了该方法的有效性。

Conclusion: 本研究整合了归纳和演绎技术，利用机器学习预测手术持续时间，并考虑预测置信度来生成更优化的手术室调度方案，并在意大利ASL1 Liguria的历史数据上得到了验证。

Abstract: The Operating Room Scheduling (ORS) problem deals with the optimization of
daily operating room surgery schedules. It is a challenging problem subject to
many constraints, like to determine the starting time of different surgeries
and allocating the required resources, including the availability of beds in
different department units. Recently, solutions to this problem based on Answer
Set Programming (ASP) have been delivered. Such solutions are overall
satisfying but, when applied to real data, they can currently only verify
whether the encoding aligns with the actual data and, at most, suggest
alternative schedules that could have been computed. As a consequence, it is
not currently possible to generate provisional schedules. Furthermore, the
resulting schedules are not always robust.
  In this paper, we integrate inductive and deductive techniques for solving
these issues. We first employ machine learning algorithms to predict the
surgery duration, from historical data, to compute provisional schedules. Then,
we consider the confidence of such predictions as an additional input to our
problem and update the encoding correspondingly in order to compute more robust
schedules. Results on historical data from the ASL1 Liguria in Italy confirm
the viability of our integration.
  Under consideration in Theory and Practice of Logic Programming (TPLP).

</details>


### [210] [Re-evaluating Short- and Long-Term Trend Factors in CTA Replication: A Bayesian Graphical Approach](https://arxiv.org/abs/2507.15876)
*Eric Benhamou,Jean-Jacques Ohana,Alban Etienne,Béatrice Guez,Ethan Setrouk,Thomas Jacquot*

Main category: cs.AI

TL;DR: This paper uses a Bayesian model to break down CTA returns into short-term trends, long-term trends, and market beta, showing how mixing these timeframes affects performance.


<details>
  <summary>Details</summary>
Motivation: Addresses the ongoing debate regarding the relative merits and interactions of short-term versus long-term trend systems employed by CTAs.

Method: Utilizes a Bayesian graphical model to dynamically decompose CTA returns into short-term trend, long-term trend, and market beta factors.

Result: Demonstrates how the combination of different trend horizons influences a strategy's risk-adjusted performance.

Conclusion: The paper examines the impact of blending short-term and long-term trend horizons on the risk-adjusted performance of Commodity Trading Advisors (CTAs).

Abstract: Commodity Trading Advisors (CTAs) have historically relied on trend-following
rules that operate on vastly different horizons from long-term breakouts that
capture major directional moves to short-term momentum signals that thrive in
fast-moving markets. Despite a large body of work on trend following, the
relative merits and interactions of short-versus long-term trend systems remain
controversial. This paper adds to the debate by (i) dynamically decomposing CTA
returns into short-term trend, long-term trend and market beta factors using a
Bayesian graphical model, and (ii) showing how the blend of horizons shapes the
strategy's risk-adjusted performance.

</details>


### [211] [Out-of-Distribution Generalization in the ARC-AGI Domain: Comparing Execution-Guided Neural Program Synthesis and Test-Time Fine-Tuning](https://arxiv.org/abs/2507.15877)
*Simon Ouellette*

Main category: cs.AI

TL;DR: 神经程序合成在ARC-AGI上的泛化能力更强，TTFT则通过激发模型内隐性知识来提升性能。


<details>
  <summary>Details</summary>
Motivation: 在ARC-AGI域（一个开放域问题）中，通过实验评估神经程序合成和测试时微调在泛化新颖解决方案方面的能力，ARC-AGI域的设计特性要求必须具备在分布外泛化能力才能成功。

Method: 将神经程序合成与测试时微调（TTFT）方法在ARC-AGI域的控制性组合泛化实验中进行比较。

Result: 神经程序合成在组合新颖解决方案方面的能力优于所有参照算法。TTFT在ARC-AGI上的成功主要归因于其能诱导模型利用其内部蕴含的、但通常不直接依赖的分布内知识。

Conclusion: 神经程序合成在ARC-AGI域上的泛化能力优于所有参照算法，而测试时微调（TTFT）主要通过引发模型内隐性知识来提升表现。

Abstract: We run a controlled compositional generalization experiment in the ARC-AGI
domain: an open-world problem domain in which the ability to generalize
out-of-distribution is, by design, an essential characteristic for success. We
compare neural program synthesis and test-time fine-tuning approaches on this
experiment. We find that execution-guided neural program synthesis outperforms
all reference algorithms in its ability to compose novel solutions. Our
empirical findings also suggest that the success of TTFT on ARC-AGI lies mainly
in eliciting in-distribution knowledge that the LLM otherwise fails to rely on
directly.

</details>


### [212] [The Recursive Coherence Principle: A Formal Constraint on Scalable Intelligence, Alignment, and Reasoning Architecture](https://arxiv.org/abs/2507.15880)
*Andy E. Williams*

Main category: cs.AI

TL;DR: 智能扩展的关键在于递归相干性。文章提出了递归相干性原理（RCP）和功能智能模型（FMI），强调了语义一致性在递归推理中的重要性。缺乏FMI会导致AI系统在扩展时出现不一致、幻觉等问题。该研究主张AI发展应关注结构相干性而非仅行为约束。


<details>
  <summary>Details</summary>
Motivation: 智能（无论是生物的、人工的还是集体的）需要跨递归推理过程的结构相干性才能有效扩展。随着复杂系统的增长，除非更高阶的结构确保语义一致性，否则相干性会变得脆弱。该研究旨在提出一个能够解决智能系统在扩展时普遍存在的相干性脆弱性问题的基本原理。

Method: 该研究形式化定义了“功能智能模型”（FMI）作为满足RCP的算子。FMI被描述为一个最小的、可组合的架构，包含内部功能（评估、建模、适应、稳定性、分解、桥接）和外部功能（存储、回忆、系统1和系统2推理），这些功能对于在推理和协调层中保持语义结构至关重要。研究并通过证明，缺乏FMI的系统在扩展时会出现递归相干性崩溃，并认为常见的AI问题（如错位、幻觉和不稳定性）是这种结构相干性损失的症状。

Result: 研究结果表明，递归相干性原理（RCP）是智能有效扩展的关键。功能智能模型（FMI）被证明是满足RCP的唯一已知算子。缺乏FMI的系统在扩展时必然会经历递归相干性崩溃，导致AI中的常见问题。RCP提供了一个从行为约束转向结构相干性的新视角，为实现安全、可泛化、鲁棒且大规模一致的AI提供了途径。

Conclusion: 该研究提出递归相干性原理（RCP）作为智能扩展的基础，强调了语义一致性在递归推理过程中的重要性。RCP指出，为了在扩展时保持语义一致性，N阶推理系统必须依赖一个可递归评估的泛化算子来跨越和对齐较低阶的概念空间。该原理是实现结构对齐的关键，缺乏递归相干性会导致系统在扩展时目标、意义和推理一致性的不可靠。

Abstract: Intelligence-biological, artificial, or collective-requires structural
coherence across recursive reasoning processes to scale effectively. As complex
systems grow, coherence becomes fragile unless a higher-order structure ensures
semantic consistency. This paper introduces the Recursive Coherence Principle
(RCP): a foundational constraint stating that for any reasoning system of order
N, composed of systems operating over conceptual spaces of order N-1, semantic
coherence is preserved only by a recursively evaluable generalization operator
that spans and aligns those lower-order conceptual spaces. Crucially, this
coherence enables structural alignment. Without recursive coherence, no system
can reliably preserve goals, meanings, or reasoning consistency at scale. We
formally define the Functional Model of Intelligence (FMI) as the only known
operator capable of satisfying the RCP at any scale. The FMI is a minimal,
composable architecture with internal functions (evaluation, modeling,
adaptation, stability, decomposition, bridging) and external functions
(storage, recall, System 1 and System 2 reasoning) vital for preserving
semantic structure across inference and coordination layers. We prove that any
system lacking the FMI will experience recursive coherence breakdown as it
scales, arguing that common AI issues like misalignment, hallucination, and
instability are symptoms of this structural coherence loss. Unlike other
foundational principles, RCP uniquely captures the internal, recursive dynamics
needed for coherent, alignable intelligence, modeling semantic coherence under
recursion. This work significantly impacts AI alignment, advocating a shift
from behavioral constraints to structural coherence, and offers a pathway for
safely generalizable, robustly coherent AI at scale.

</details>


### [213] [ADEPTS: A Capability Framework for Human-Centered Agent Design](https://arxiv.org/abs/2507.15885)
*Pierluca D'Oro,Caley Drooff,Joy Chen,Joseph Tighe*

Main category: cs.AI

TL;DR: ADEPTS是一个新的AI代理能力框架，它提供了六个以用户为中心的设计原则，旨在让AI代理更易于理解、控制和信任，从而加速AI代理的开发和改进。


<details>
  <summary>Details</summary>
Motivation: 目前，关于以人为本的AI代理开发的指导意见分散在各个领域，缺乏一个简洁、面向用户的词汇来指导团队了解AI代理应该具备哪些基本能力。ADEPTS旨在弥合这一差距，提供统一的指导。

Method: ADEPTS是基于六个以人为本的AI代理设计原则，这些原则表达了AI代理为了在日常使用中可理解、可控和可信赖而应具备的最基本的用户界面能力。

Result: ADEPTS框架能够将复杂的AI-UX需求浓缩成一个简洁的框架，为AI研究人员、设计师、工程师和政策审查人员提供可操作的指导。它有潜力加速用户相关代理能力的提升，简化利用这些能力的体验设计，并提供一个共享的语言来跟踪和讨论AI代理开发方面的进展。

Conclusion: ADEPTS是一个能力框架，它定义了一组核心的、面向用户的能力，为AI代理的开发提供统一的指导。该框架基于六个以人为本的AI代理设计原则，这些原则表达了AI代理为了在日常使用中可理解、可控和可信赖而应具备的最基本的用户界面能力。ADEPTS是对现有框架和分类法的补充，它 D E P T S 框架的目的是将复杂的AI-UX需求浓缩成一个简洁的框架，为AI研究人员、设计师、工程师和政策审查人员提供可操作的指导。我们相信ADEPTS有潜力加速用户相关代理能力的提升，简化利用这些能力的体验设计，并提供一个共享的语言来跟踪和讨论AI代理开发方面的进展。

Abstract: Large language models have paved the way to powerful and flexible AI agents,
assisting humans by increasingly integrating into their daily life. This
flexibility, potential, and growing adoption demands a holistic and
cross-disciplinary approach to developing, monitoring and discussing the
capabilities required for agent-driven user experiences. However, current
guidance on human-centered AI agent development is scattered: UX heuristics
focus on interface behaviors, engineering taxonomies describe internal
pipelines, and ethics checklists address high-level governance. There is no
concise, user-facing vocabulary that tells teams what an agent should
fundamentally be able to do. We introduce ADEPTS, a capability framework
defining a set of core user-facing capabilities to provide unified guidance
around the development of AI agents. ADEPTS is based on six principles for
human-centered agent design, that express the minimal, user-facing capabilities
an AI agent should demonstrate to be understandable, controllable and
trustworthy in everyday use. ADEPTS complements existing frameworks and
taxonomies; differently from them, it sits at the interface between technical
and experience development. By presenting ADEPTS, we aim to condense complex
AI-UX requirements into a compact framework that is actionable guidance for AI
researchers, designers, engineers, and policy reviewers alike. We believe
ADEPTS has the potential of accelerating the improvement of user-relevant agent
capabilities, of easing the design of experiences that take advantage of those
capabilities, and of providing a shared language to track and discuss progress
around the development of AI agents.

</details>


### [214] [Integrating Reason-Based Moral Decision-Making in the Reinforcement Learning Architecture](https://arxiv.org/abs/2507.15895)
*Lisa Dargasz*

Main category: cs.AI

TL;DR: 本研究提出了一种名为RBAMA的新型人工智能代理，它通过学习推理理论来做出合乎道德的决策，旨在使其在现实世界中的行为符合道德规范，并已通过初步实验验证了其潜力。


<details>
  <summary>Details</summary>
Motivation: 随着人工智能代理（如人形机器人或自动驾驶汽车）日益强大并接近市场就绪，它们需要在真实环境中安全、合乎道德地运行。因此，开发能够进行合乎道德决策的人工道德代理（AMA）变得至关重要。

Method: 通过在强化学习架构的扩展中，使代理具备学习推理理论的能力，从而能够处理与道德相关的命题并推导出道德义务。代理会调整其行为以确保符合这些义务，同时执行其指定的任务。

Result: RBAMA能够实现基于推理的道德决策，表现出其行为的道德正当性、鲁棒性和可信赖性。

Conclusion: 本研究提出的基于推理的人工道德代理（RBAMA）的扩展架构是一个具体且可部署的框架，能够满足关键的道德要求，并展示了RBAMA在初步实验中的潜力。

Abstract: Reinforcement Learning is a machine learning methodology that has
demonstrated strong performance across a variety of tasks. In particular, it
plays a central role in the development of artificial autonomous agents. As
these agents become increasingly capable, market readiness is rapidly
approaching, which means those agents, for example taking the form of humanoid
robots or autonomous cars, are poised to transition from laboratory prototypes
to autonomous operation in real-world environments. This transition raises
concerns leading to specific requirements for these systems - among them, the
requirement that they are designed to behave ethically. Crucially, research
directed toward building agents that fulfill the requirement to behave
ethically - referred to as artificial moral agents(AMAs) - has to address a
range of challenges at the intersection of computer science and philosophy.
This study explores the development of reason-based artificial moral agents
(RBAMAs). RBAMAs are build on an extension of the reinforcement learning
architecture to enable moral decision-making based on sound normative
reasoning, which is achieved by equipping the agent with the capacity to learn
a reason-theory - a theory which enables it to process morally relevant
propositions to derive moral obligations - through case-based feedback. They
are designed such that they adapt their behavior to ensure conformance to these
obligations while they pursue their designated tasks. These features contribute
to the moral justifiability of the their actions, their moral robustness, and
their moral trustworthiness, which proposes the extended architecture as a
concrete and deployable framework for the development of AMAs that fulfills key
ethical desiderata. This study presents a first implementation of an RBAMA and
demonstrates the potential of RBAMAs in initial experiments.

</details>


### [215] [Does More Inference-Time Compute Really Help Robustness?](https://arxiv.org/abs/2507.15974)
*Tong Wu,Chong Xiang,Jiachen T. Wang,Weichen Yu,Chawin Sitawarin,Vikash Sehwag,Prateek Mittal*

Main category: cs.AI

TL;DR: 在推理时增加计算量可以提高小型开源模型的鲁棒性，但如果中间推理步骤暴露给对手，这种做法反而会降低鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 以往研究表明，增加推理时计算可以提高大型模型的鲁棒性。本研究旨在探讨小型开源模型是否也具有这种特性，并进一步研究中间推理步骤的可见性对模型鲁棒性的影响。

Method: 首先，证明了通过预算强制策略可以扩展小型开源模型（如DeepSeek R1、Qwen3、Phi-reasoning）的推理计算以提高鲁棒性。其次，通过放松中间推理步骤对对手隐藏的假设，发现了推理时计算与模型鲁棒性之间的反向缩放规律，即增加计算量反而会降低鲁棒性。最后，讨论了推理链隐藏的模型在实际场景中仍然容易受到攻击的情况。

Result: 小型开源模型也能从推理时计算的扩展中受益。然而，当中间推理步骤暴露给对手时，推理时计算的增加反而会降低模型的鲁棒性。研究还发现，即使推理链被隐藏，模型也可能容易受到特定攻击，例如涉及工具集成的推理以及高级推理提取攻击。

Conclusion: 通过放松“中间推理步骤对对手来说是隐藏的”这一隐含假设，研究人员发现了一个重要的安全风险，即推理时计算的增加会降低模型的鲁棒性，这是一种与以往研究相反的现象。研究结果表明，推理时计算的鲁棒性优势很大程度上取决于对抗性设置和部署环境，并建议在安全敏感的实际应用中部署时应仔细权衡。

Abstract: Recently, Zaremba et al. demonstrated that increasing inference-time
computation improves robustness in large proprietary reasoning LLMs. In this
paper, we first show that smaller-scale, open-source models (e.g., DeepSeek R1,
Qwen3, Phi-reasoning) can also benefit from inference-time scaling using a
simple budget forcing strategy. More importantly, we reveal and critically
examine an implicit assumption in prior work: intermediate reasoning steps are
hidden from adversaries. By relaxing this assumption, we identify an important
security risk, intuitively motivated and empirically verified as an inverse
scaling law: if intermediate reasoning steps become explicitly accessible,
increased inference-time computation consistently reduces model robustness.
Finally, we discuss practical scenarios where models with hidden reasoning
chains are still vulnerable to attacks, such as models with tool-integrated
reasoning and advanced reasoning extraction attacks. Our findings collectively
demonstrate that the robustness benefits of inference-time scaling depend
heavily on the adversarial setting and deployment context. We urge
practitioners to carefully weigh these subtle trade-offs before applying
inference-time scaling in security-sensitive, real-world applications.

</details>


### [216] [CHIMERA: Compressed Hybrid Intelligence for Twin-Model Enhanced Multi-Agent Deep Reinforcement Learning for Multi-Functional RIS-Assisted Space-Air-Ground Integrated Networks](https://arxiv.org/abs/2507.16204)
*Li-Hsiang Shen,Jyun-Jhe Huang*

Main category: cs.AI

TL;DR: 提出了一种新的空间-天空-地面集成网络 (SAGIN) 架构，集成了多功能可重构智能表面 (MF-RIS) 来解决低地球轨道 (LEO) 卫星的能源短缺问题。通过名为 CHIMERA 的先进强化学习框架优化网络参数以最大化能源效率 (EE)。仿真结果证明该方法优于现有技术。


<details>
  <summary>Details</summary>
Motivation: 旨在通过引入多功能可重构智能表面 (MF-RIS) 来解决低地球轨道 (LEO) 卫星在阴影区域的能源短缺问题，并最大化空间-天空-地面集成网络 (SAGIN) 的长期能源效率 (EE)，同时考虑通信和计算能耗。

Method: 提出了一种名为 CHIMERA 的压缩混合智能框架，该框架集成了语义状态-动作压缩和参数共享，并结合了混合强化学习，以有效探索复杂动作。该框架解决了高度非凸、非线性且包含混合离散-连续参数的优化问题。

Result: 仿真结果表明，所提出的 CHIMERA 方案在能源效率 (EE) 方面显著优于传统基线（包括固定配置或非能量收集的 MF-RIS、传统 RIS 和无 RIS 的情况），以及集中式和多智能体深度强化学习基线。此外，所提出的 SAGIN-MF-RIS 架构由于其互补的覆盖范围，实现了卓越的 EE 性能，与单独的卫星、空中或仅地面部署相比具有显著优势。

Conclusion: 空间-天空-地面集成网络 (SAGIN) 架构通过多功能可重构智能表面 (MF-RIS) 得到增强，MF-RIS 能够同时反射、放大和收集无线能量。该架构旨在解决低地球轨道 (LEO) 卫星在阴影区域的能源短缺问题，同时考虑 SAGIN 节点之间的通信和计算能耗。通过联合优化 MF-RIS 参数（包括信号放大、相移、能量收集比率和活动单元选择）以及 SAGIN 参数（包括波束成形矢量、高空平台站 (HAPS) 部署、用户关联和计算能力），旨在最大化长期能源效率 (EE)。

Abstract: A space-air-ground integrated network (SAGIN) architecture is proposed,
empowered by multi-functional reconfigurable intelligent surfaces (MF-RIS)
capable of simultaneously reflecting, amplifying, and harvesting wireless
energy. The MF-RIS plays a pivotal role in addressing the energy shortages of
low-Earth orbit (LEO) satellites operating in shadowed regions, while
explicitly accounting for both communication and computing energy consumption
across the SAGIN nodes. To maximize the long-term energy efficiency (EE), we
formulate a joint optimization problem over the MF-RIS parameters, including
signal amplification, phase-shifts, energy harvesting ratio, and active element
selection as well as the SAGIN parameters of beamforming vectors, high-altitude
platform station (HAPS) deployment, user association, and computing capability.
The formulated problem is highly non-convex and non-linear and contains mixed
discrete-continuous parameters. To tackle this, we conceive a compressed hybrid
intelligence for twin-model enhanced multi-agent deep reinforcement learning
(CHIMERA) framework, which integrates semantic state-action compression and
parametrized sharing under hybrid reinforcement learning to efficiently explore
suitable complex actions. The simulation results have demonstrated that the
proposed CHIMERA scheme substantially outperforms the conventional benchmarks,
including fixed-configuration or non-harvesting MF-RIS, traditional RIS, and
no-RIS cases, as well as centralized and multi-agent deep reinforcement
learning baselines in terms of the highest EE. Moreover, the proposed
SAGIN-MF-RIS architecture achieves superior EE performance due to its
complementary coverage, offering notable advantages over either standalone
satellite, aerial, or ground-only deployments.

</details>


### [217] [Micromobility Flow Prediction: A Bike Sharing Station-level Study via Multi-level Spatial-Temporal Attention Neural Network](https://arxiv.org/abs/2507.16020)
*Xi Yang,Jiachen Wang,Song Han,Suining He*

Main category: cs.AI

TL;DR: BikeMAN是一种用于预测整个自行车共享系统站点级自行车流量的多级时空注意力神经网络。


<details>
  <summary>Details</summary>
Motivation: 为了解决城市共享单车资源供需不平衡导致的系统维护困难，以及预测整个自行车共享系统站点级交通流量的空间时间复杂性和大规模性挑战。

Method: 提出了一种名为BikeMAN的多级时空注意力神经网络，该网络由编码器和解码器组成，其中一个注意力机制表示系统中自行车站点特征之间的空间相关性，另一个注意力机制描述了自行车站点流量的时间特征。

Result: 通过对纽约市超过700个站点、超过1000万次出行进行实验研究，BikeMAN在预测全市所有站点交通方面显示出高精度。

Conclusion: BikeMAN在预测纽约市自行车共享系统的所有站点交通方面表现出高精度。

Abstract: Efficient use of urban micromobility resources such as bike sharing is
challenging due to the unbalanced station-level demand and supply, which causes
the maintenance of the bike sharing systems painstaking. Prior efforts have
been made on accurate prediction of bike traffics, i.e., demand/pick-up and
return/drop-off, to achieve system efficiency. However, bike station-level
traffic prediction is difficult because of the spatial-temporal complexity of
bike sharing systems. Moreover, such level of prediction over entire bike
sharing systems is also challenging due to the large number of bike stations.
To fill this gap, we propose BikeMAN, a multi-level spatio-temporal attention
neural network to predict station-level bike traffic for entire bike sharing
systems. The proposed network consists of an encoder and a decoder with an
attention mechanism representing the spatial correlation between features of
bike stations in the system and another attention mechanism describing the
temporal characteristic of bike station traffic. Through experimental study on
over 10 millions trips of bike sharing systems (> 700 stations) of New York
City, our network showed high accuracy in predicting the bike station traffic
of all stations in the city.

</details>


### [218] [From Logic to Language: A Trust Index for Problem Solving with LLMs](https://arxiv.org/abs/2507.16028)
*Tehseen Rug,Felix Böhmer,Tessa Pfattheicher*

Main category: cs.AI

TL;DR: LLM擅长处理模糊、动态和主观性强的问题，本文提出一个框架来理解和评估LLM的解决方案，引入了信任指数Q、双语义熵和情感效价等概念。


<details>
  <summary>Details</summary>
Motivation: 经典计算擅长处理有明确规则的问题，但无法触及人类生活中模糊、动态和主观性强的问题。LLM的出现为解决这些问题提供了新的途径，但需要新的框架来理解和评估其能力。

Method: 本文提出一个统一的框架，通过定义和区分形式语言与自然语言可解决的问题空间，并引入向量值信任指数Q来评估自然语言解决方案的连续适宜性。此外，还提出了归一化双语义熵和情感效价两个统计质量维度，以衡量LLM答案的鲁棒性、概念多样性以及主观价值。

Result: 本文引入了一个统一框架，区分了形式语言和自然语言的问题空间。提出向量值信任指数Q来评估自然语言解决方案的连续适宜性，并提出归一化双语义熵和情感效价两个统计质量维度，以更严谨地理解LLM的能力和局限性。

Conclusion: LLM的出现使计算系统能够处理模糊、动态和主观性强的问题，这是经典计算的弱项。本文提出的统一框架通过定义和区分形式语言与自然语言可解决的问题空间，并引入向量值信任指数Q来评估自然语言解决方案的连续适宜性，为理解LLM的优势、局限性和本质提供了更严谨的视角。

Abstract: Classical computation, grounded in formal, logical systems, has been the
engine of technological progress for decades, excelling at problems that can be
described with unambiguous rules. This paradigm, however, leaves a vast ocean
of human problems -- those characterized by ambiguity, dynamic environments,
and subjective context -- largely untouched. The advent of Large Language
Models (LLMs) represents a fundamental shift, enabling computational systems to
engage with this previously inaccessible domain using natural language. This
paper introduces a unified framework to understand and contrast these
problem-solving paradigms. We define and delineate the problem spaces
addressable by formal languages versus natural language. While solutions to the
former problem class can be evaluated using binary quality measures, the latter
requires a much more nuanced definition of approximate solution space taking
into account the vagueness, subjectivity and ambiguity inherent to natural
language. We therefore introduce a vector-valued trust index Q, which reflects
solution quality and distinguishes the binary correctness of formal solutions
from the continuous adequacy spectrum characteristic of natural language
solutions. Within this framework, we propose two statistical quality
dimensions. Normalized bi-semantic entropy measures robustness and conceptual
diversity of LLM answers given semantic variation in problem formulations.
Emotional valence maps subjective valuation of a solution to a quantifiable
metric that can be maximized by invoking statistical measures. The concepts
introduced in this work will provide a more rigorous understanding of the
capabilities, limitations, and inherent nature of problem-solving in the age of
LLMs.

</details>


### [219] [Expert-Guided LLM Reasoning for Battery Discovery: From AI-Driven Hypothesis to Synthesis and Characterization](https://arxiv.org/abs/2507.16110)
*Shengchao Liu,Hannan Xu,Yan Ai,Huanxin Li,Yoshua Bengio,Harry Guo*

Main category: cs.AI

TL;DR: ChatBattery是一个整合了领域知识的新型agentic框架，利用LLM进行材料发现。实验证明，该框架在发现新型电池材料方面取得了显著成效，容量相比现有材料有显著提升，并展示了AI在材料科学领域的应用潜力。


<details>
  <summary>Details</summary>
Motivation: LLM在数学和编码问题中展示了其推理能力，但在电池发现等领域特定应用中的潜力尚未被充分探索。受到推理是引导搜索的启发。

Method: 提出了一种名为ChatBattery的新型agentic框架，该框架整合了领域知识来指导大型语言模型（LLM）在材料设计中进行更有效的推理。

Result: ChatBattery成功识别、合成和表征了三种新型锂离子电池正极材料，其容量分别比NMC811提高了28.8%、25.2%和18.5%。实现了从设计到合成再到表征的完整AI驱动的循环。

Conclusion: ChatBattery成功识别、合成和表征了三种新型锂离子电池正极材料，其容量分别比广泛使用的LiNi0.8Mn0.1Co0.1O2（NMC811）提高了28.8%、25.2%和18.5%。该框架展示了AI驱动的推理在革新材料发现方面的潜力。

Abstract: Large language models (LLMs) leverage chain-of-thought (CoT) techniques to
tackle complex problems, representing a transformative breakthrough in
artificial intelligence (AI). However, their reasoning capabilities have
primarily been demonstrated in solving math and coding problems, leaving their
potential for domain-specific applications-such as battery discovery-largely
unexplored. Inspired by the idea that reasoning mirrors a form of guided
search, we introduce ChatBattery, a novel agentic framework that integrates
domain knowledge to steer LLMs toward more effective reasoning in materials
design. Using ChatBattery, we successfully identify, synthesize, and
characterize three novel lithium-ion battery cathode materials, which achieve
practical capacity improvements of 28.8%, 25.2%, and 18.5%, respectively, over
the widely used cathode material, LiNi0.8Mn0.1Co0.1O2 (NMC811). Beyond this
discovery, ChatBattery paves a new path by showing a successful LLM-driven and
reasoning-based platform for battery materials invention. This complete
AI-driven cycle-from design to synthesis to characterization-demonstrates the
transformative potential of AI-driven reasoning in revolutionizing materials
discovery.

</details>


### [220] [TaxCalcBench: Evaluating Frontier Models on the Tax Calculation Task](https://arxiv.org/abs/2507.16126)
*Michael R. Bock,Kara Molisee,Zachary Ozer,Sumit Shah*

Main category: cs.AI

TL;DR: AI尚不能准确计算美国个人所得税。TaxCalcBench基准测试显示，即使在简化数据集上，现有模型也存在税表误用、计算错误和资格判定失误等问题，表明需要更多基础设施支持AI在此领域的应用。


<details>
  <summary>Details</summary>
Motivation: 计算美国个人所得税需要理解大量英文文本并进行精确计算，旨在评估AI模型在此任务上的能力。

Method: 提出TaxCalcBench基准测试，用于评估模型在给定必要信息下计算美国个人所得税申报的能力。

Result: 在简化的数据集上，最先进的模型计算美国联邦所得税申报的成功率低于三分之一。

Conclusion: AI模型在处理美国个人所得税计算方面仍有很大提升空间，在简化数据集上仍低于30%的成功率，主要问题在于错误使用税表、计算失误以及资格判定不准确。需要进一步的基础设施建设来支持LLM在个人所得税计算任务中的应用。

Abstract: Can AI file your taxes? Not yet. Calculating US personal income taxes is a
task that requires building an understanding of vast amounts of English text
and using that knowledge to carefully compute results. We propose TaxCalcBench,
a benchmark for determining models' abilities to calculate personal income tax
returns given all of the necessary information. Our experiment shows that
state-of-the-art models succeed in calculating less than a third of federal
income tax returns even on this simplified sample set. Our analysis concludes
that models consistently misuse tax tables, make errors in tax calculation, and
incorrectly determine eligibility. Our findings point to the need for
additional infrastructure to apply LLMs to the personal income tax calculation
task.

</details>


### [221] [SpiroLLM: Finetuning Pretrained LLMs to Understand Spirogram Time Series with Clinical Validation in COPD Reporting](https://arxiv.org/abs/2507.16145)
*Shuhao Mei,Yongchao Long,Shan Cao,Xiaobo Han,Shijia Geng,Jinbo Sun,Yuxi Zhou,Shenda Hong*

Main category: cs.AI

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Chronic Obstructive Pulmonary Disease (COPD), a major chronic respiratory
disease with persistent airflow limitation, is a leading global cause of
disability and mortality. Respiratory spirogram time series, routinely
collected during pulmonary function tests (PFTs), play a critical role in the
early detection of repsiratory diseases and in monitoring lung function over
time. However, most current AI models for COPD diagnosis are limited to
outputting classification results without providing a rationale for their
diagnostic process, while current Large Language Models (LLMs) cannot
understand spirograms yet, which severely limits their clinical trust and
adoption. To tackle this challenge, we leverage a cohort of 234,028 individuals
from the UK Biobank (UKB) to propose SpiroLLM, the first multimodal large
language model that can understand spirogram. The model extracts morphological
features from respiratory curves via a SpiroEncoder and aligns them with PFT
numerical values in a unified latent space using a SpiroProjector, ultimately
empowering a large language model to generate a comprehensive diagnostic
report. Experimental results confirm that SpiroLLM achieved a diagnostic AUROC
of 0.8980 (95% CI: 0.8820-0.9132). In a robustness test with missing core data,
it maintained a 100% valid response rate, far surpassing the 13.4% of a
text-only model and showcasing the superiority of its multimodal design. This
work demonstrates the substantial potential of deeply fusing physiological
signals with large language models, establishing a new paradigm for the next
generation of interpretable and reliable clinical decision support tools.

</details>


### [222] [Emergent Cognitive Convergence via Implementation: A Structured Loop Reflecting Four Theories of Mind (A Position Paper)](https://arxiv.org/abs/2507.16184)
*Myung Ho Kim*

Main category: cs.AI

TL;DR: AI代理Agentic Flow在设计中意外融合了四种心智理论的结构，并在实验中显著优于基线LLM代理，证明了实践设计可启发理论发现。


<details>
  <summary>Details</summary>
Motivation: 本文的动机在于探索在设计和实现AI代理（特别是Agentic Flow）的过程中，是否会意外地发现与现有心智理论（如Kahneman的双系统理论、Friston的预测处理、Minsky的社会心智和Clark的扩展心智）在结构上的共鸣。作者希望通过实践设计来揭示理论的潜在联系，而不是从理论出发进行设计。

Method: 本文采用实验方法，将Agentic Flow架构与基线LLM代理进行比较。实验在多步推理任务上进行，以评估Agentic Flow在结构收敛方面的表现。通过量化任务成功率和约束遵守情况来评估性能。

Result: 实验结果显示，Agentic Flow代理在多步推理任务上达到了95.8%的任务成功率，并表现出很强的约束遵守能力。相比之下，基线LLM代理的成功率为62.3%。这些结果表明，Agentic Flow的结构化设计在实际任务中表现出优越性，并支持了理论结构可以通过实践设计出现的观点。

Conclusion: 本文的结论是，通过在Agentic Flow这一AI代理架构的实践设计中，意外地发现了跨越Kahneman、Friston、Minsky和Clark四种有影响力的心智理论的结构性收敛。作者强调，这种收敛并非旨在实现理论统一，而是说明理论结构可以从实际设计选择中涌现，而非自上而下的理论构建。PEACE元架构被提出，用于描述Agentic Flow中观察到的设计层面的规律性，旨在为理解受实际实施需求塑造的架构提供共同的词汇。

Abstract: We report the discovery of a structural convergence across four influential
theories of mind: Kahneman's dual-system theory, Friston's predictive
processing, Minsky's society of mind, and Clark's extended mind-emerging
unintentionally within a practical AI agent architecture called Agentic Flow.
Designed to address limitations in large language models (LLMs), Agentic Flow
comprises five interdependent modules such as Retrieval, Cognition, Control,
Memory, and Action arranged in a recurrent cognitive loop. Although originally
inspired only by Minsky and Clark, the system's structure retrospectively
aligns with computational motifs found in all four theories, including
predictive modeling, associative recall, and error-sensitive control.
  To assess this convergence, we conducted comparative experiments with
baseline LLM agents on multi-step reasoning tasks. The structured agent
achieved 95.8% task success and exhibited strong constraint adherence, while
the baseline system succeeded 62.3% of the time. These results were not aimed
at proving superiority, but at illustrating how theoretical structures may
emerge through practical design choices rather than top-down theory.
  We introduce PEACE as a descriptive meta-architecture that captures
design-level regularities observed in Agentic Flow. Not intended as a new
theory, PEACE provides a shared vocabulary for understanding architectures
shaped by real-world implementation demands. This paper should be read as a
position paper - an exploratory reflection on how implementation can surface
latent structural echoes of cognitive theory, without asserting theoretical
unification.

</details>


### [223] [Distilled Large Language Model in Confidential Computing Environment for System-on-Chip Design](https://arxiv.org/abs/2507.16226)
*Dong Ben,Hui Feng,Qian Wang*

Main category: cs.AI

TL;DR: 在TEE环境中评估了LLMs的性能，发现蒸馏和量化模型表现更优，并且TDX实现对于参数量较少的模型优于CPU版本，证明了其在半导体CAD应用中的潜力。


<details>
  <summary>Details</summary>
Motivation: 为了在电路设计任务中保护机密的大语言模型（LLMs）及其训练数据，并解决现有TEE实现效率低下的问题。

Method: 在TEE（英特尔TDX）、仅CPU和CPU-GPU混合环境中对LLMs进行评估，并根据每秒处理的令牌数评估其性能。

Result: 蒸馏模型（如DeepSeek）因参数量小表现更优；量化模型（如Q4、Q8）相比FP16模型性能提升高达3倍；对于参数量较少的模型（如DeepSeek-r1-1.5B），TDX实现优于CPU版本；通过针对SoC设计的测试台验证了结果。

Conclusion: 轻量级大语言模型（LLMs）有潜力在安全环境中高效部署，适用于半导体CAD应用。

Abstract: Large Language Models (LLMs) are increasingly used in circuit design tasks
and have typically undergone multiple rounds of training. Both the trained
models and their associated training data are considered confidential
intellectual property (IP) and must be protected from exposure. Confidential
Computing offers a promising solution to protect data and models through
Trusted Execution Environments (TEEs). However, existing TEE implementations
are not designed to support the resource-intensive nature of LLMs efficiently.
In this work, we first present a comprehensive evaluation of the LLMs within a
TEE-enabled confidential computing environment, specifically utilizing Intel
Trust Domain Extensions (TDX). We constructed experiments on three
environments: TEE-based, CPU-only, and CPU-GPU hybrid implementations, and
evaluated their performance in terms of tokens per second.
  Our first observation is that distilled models, i.e., DeepSeek, surpass other
models in performance due to their smaller parameters, making them suitable for
resource-constrained devices. Also, in the quantized models such as 4-bit
quantization (Q4) and 8-bit quantization (Q8), we observed a performance gain
of up to 3x compared to FP16 models. Our findings indicate that for fewer
parameter sets, such as DeepSeek-r1-1.5B, the TDX implementation outperforms
the CPU version in executing computations within a secure environment. We
further validate the results using a testbench designed for SoC design tasks.
These validations demonstrate the potential of efficiently deploying
lightweight LLMs on resource-constrained systems for semiconductor CAD
applications.

</details>


### [224] [Voice-based AI Agents: Filling the Economic Gaps in Digital Health Delivery](https://arxiv.org/abs/2507.16229)
*Bo Wen,Chen Wang,Qiwei Han,Raquel Norel,Julia Liu,Thaddeus Stappenbeck,Jeffrey L. Rogers*

Main category: cs.AI

TL;DR: LLM驱动的语音助手有潜力解决医疗保健中的经济和可及性问题，特别是通过Agent PULSE试点研究表明，它们在成本效益、患者接受度和参与度方面具有优势，但仍需解决技术和政策挑战。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLM）驱动的语音助手在加强预防保健和持续患者监护方面的作用，特别是在服务不足的人群中，以弥合数字健康服务的经济和可及性差距。

Method: 本文探讨了大型语言模型（LLM）驱动的语音助手在加强预防保健和持续患者监护方面的作用，特别是关注服务不足的人群。通过分析Agent PULSE（患者理解和联络支持引擎）的开发和试点研究，文中提出了一个经济模型，该模型展示了AI代理如何在人力介入在经济上不可行的情况下提供成本效益高的医疗服务。试点研究包括33名炎症性肠病患者，其中70%的患者接受了AI驱动的监护，37%的患者更倾向于这种方式而非传统方式。此外，文中还分析了包括实时对话AI处理、与医疗系统整合和隐私合规在内的技术挑战，以及围绕监管、偏见缓解和患者自主权的政策考量。

Result: 试点研究表明，70%的炎症性肠病患者接受AI驱动的监护，37%的患者更倾向于AI监护。AI驱动的语音代理能够提高医疗保健的可扩展性和效率，同时改善患者的参与度和可及性。成本效益分析表明，在常规监护任务中具有巨大的潜在节省。

Conclusion: AI驱动的语音代理可以作为公平、可持续的数字医疗解决方案的关键切入点，它们能够提高医疗保健的可扩展性和效率，同时改善患者的参与度和可及性。

Abstract: The integration of voice-based AI agents in healthcare presents a
transformative opportunity to bridge economic and accessibility gaps in digital
health delivery. This paper explores the role of large language model
(LLM)-powered voice assistants in enhancing preventive care and continuous
patient monitoring, particularly in underserved populations. Drawing insights
from the development and pilot study of Agent PULSE (Patient Understanding and
Liaison Support Engine) -- a collaborative initiative between IBM Research,
Cleveland Clinic Foundation, and Morehouse School of Medicine -- we present an
economic model demonstrating how AI agents can provide cost-effective
healthcare services where human intervention is economically unfeasible. Our
pilot study with 33 inflammatory bowel disease patients revealed that 70\%
expressed acceptance of AI-driven monitoring, with 37\% preferring it over
traditional modalities. Technical challenges, including real-time
conversational AI processing, integration with healthcare systems, and privacy
compliance, are analyzed alongside policy considerations surrounding
regulation, bias mitigation, and patient autonomy. Our findings suggest that
AI-driven voice agents not only enhance healthcare scalability and efficiency
but also improve patient engagement and accessibility. For healthcare
executives, our cost-utility analysis demonstrates huge potential savings for
routine monitoring tasks, while technologists can leverage our framework to
prioritize improvements yielding the highest patient impact. By addressing
current limitations and aligning AI development with ethical and regulatory
frameworks, voice-based AI agents can serve as a critical entry point for
equitable, sustainable digital healthcare solutions.

</details>


### [225] [ResearcherBench: Evaluating Deep AI Research Systems on the Frontiers of Scientific Inquiry](https://arxiv.org/abs/2507.16280)
*Tianze Xu,Pengrui Lu,Lyumanshan Ye,Xiangkun Hu,Pengfei Liu*

Main category: cs.AI

TL;DR: 我们提出了 ResearcherBench，这是一个评估深度人工智能研究系统（DARS）在科学研究前沿问题上的能力的基准。我们评估了现有的 DARS 系统，发现 OpenAI Deep Research 和 Gemini Deep Research 的表现优于其他系统。我们希望 ResearcherBench 的开源能够促进下一代 AI 研究助手的开发。


<details>
  <summary>Details</summary>
Motivation: 现有的基准主要将这些系统评估为网络检索和报告生成的代理，忽略了它们在科学研究前沿发现新见解的潜力。

Method: 我们引入了 ResearcherBench，这是第一个专注于评估这些先进的、自主的系统（我们称之为深度人工智能研究系统（DARS））在人工智能前沿科学问题上的能力的基准。我们编译了一个包含 65 个研究问题的语料库，这些问题是从现实世界的科学场景（如实验室讨论和面试）中精心挑选出来的，涵盖了 35 个不同的人工智能学科，并分为三类：技术细节、文献回顾和开放式咨询。我们的双重评估框架结合了基于评分卡的评估（使用专家设计的标准来评估见解质量）和基于事实的评估（衡量引用准确性和覆盖范围）。

Result: OpenAI Deep Research 和 Gemini Deep Research 的表现明显优于其他系统，尤其在开放式咨询问题方面。

Conclusion: OpenAI Deep Research and Gemini Deep Research 在开放式咨询问题方面表现出色，在 AI 自我改进和 ASI 愿景方面迈出了有意义的一步。ResearcherBench 的开源将促进下一代 AI 研究助手的开发。

Abstract: The emergence of deep research systems presents significant capabilities in
problem-solving, extending from basic queries to sophisticated research tasks.
However, existing benchmarks primarily evaluate these systems as agents for web
retrieval and report generation, overlooking their potential to discover novel
insights on the frontiers of scientific research. To address this gap, we
introduce ResearcherBench, the first benchmark focused on evaluating the
capabilities of these advanced, agentic systems - which we refer to as Deep AI
Research Systems (DARS) - on frontier AI scientific questions. We compiled a
dataset of 65 research questions expertly selected from real-world scientific
scenarios such as laboratory discussions and interviews, spanning 35 different
AI subjects and categorized into three types: technical details, literature
review, and open consulting. Our dual evaluation framework combines rubric
assessment, which uses expert-designed criteria to evaluate insight quality,
with factual assessment, which measures citation accuracy (faithfulness) and
coverage (groundedness). We evaluated several leading commercial DARS and
baseline systems. Results show that OpenAI Deep Research and Gemini Deep
Research significantly outperform other systems, with particular strength in
open-ended consulting questions. Such capabilities represent a meaningful step
toward AI self-improvement, aligning with the vision of ASI for AI. We
open-source ResearcherBench to provide a standardized platform for promoting
the development of next-generation AI research assistants, hoping to foster a
new perspective in AI research evaluation for a novel pattern of scientific
collaboration: https://github.com/GAIR-NLP/ResearcherBench.

</details>


### [226] [Cross-Modal Distillation For Widely Differing Modalities](https://arxiv.org/abs/2507.16296)
*Cairong Zhao,Yufeng Jin,Zifan Song,Haonan Chen,Duoqian Miao,Guosheng Hu*

Main category: cs.AI

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Deep learning achieved great progress recently, however, it is not easy or
efficient to further improve its performance by increasing the size of the
model. Multi-modal learning can mitigate this challenge by introducing richer
and more discriminative information as input. To solve the problem of limited
access to multi-modal data at the time of use, we conduct multi-modal learning
by introducing a teacher model to transfer discriminative knowledge to a
student model during training. However, this knowledge transfer via
distillation is not trivial because the big domain gap between the widely
differing modalities can easily lead to overfitting. In this work, we introduce
a cross-modal distillation framework. Specifically, we find hard constrained
loss, e.g. l2 loss forcing the student being exact the same as the teacher, can
easily lead to overfitting in cross-modality distillation. To address this, we
propose two soft constrained knowledge distillation strategies at the feature
level and classifier level respectively. In addition, we propose a
quality-based adaptive weights module to weigh input samples via quantified
data quality, leading to robust model training. We conducted experiments on
speaker recognition and image classification tasks, and the results show that
our approach is able to effectively achieve knowledge transfer between the
commonly used and widely differing modalities of image, text, and speech.

</details>


### [227] [Mind the Gap: Evaluating the Representativeness of Quantitative Medical Language Reasoning LLM Benchmarks for African Disease Burdens](https://arxiv.org/abs/2507.16322)
*Fred Mutisya,Shikoh Gitau,Christine Syovata,Diana Oigara,Ibrahim Matende,Muna Aden,Munira Ali,Ryan Nyotu,Diana Marion,Job Nyangena,Nasubo Ongoma,Keith Mbae,Elizabeth Wamicha,Eric Mibuari,Jean Philbert Nsengemana,Talkmore Chidede*

Main category: cs.AI

TL;DR: 现有医疗语言模型基准未能充分反映非洲的疾病负担和监管环境，可能导致错误的性能声明。需要像Alama Health QA这样基于指南、经过区域性策展的资源，以及扩展的特定疾病数据集，以确保在非洲卫生系统中文献模型进行安全、公平的评估和部署。


<details>
  <summary>Details</summary>
Motivation: 现有的医疗语言模型基准在非洲部署的有效性存在疑问，因为它们未能充分反映非洲的疾病负担和护理背景。

Method: 通过对2019年1月至2025年5月的31篇定量语言模型评估论文进行系统性回顾，识别出19个英语医学QA基准。使用基于肯尼亚临床实践指南的检索增强生成框架开发了Alama Health QA。对六个广泛使用的评估集（AfriMedQA、MMLUMedical、PubMedQA、MedMCQA、MedQAUSMLE和Alama Health QA）进行了语义分析（NTD比例、时效性、可读性、词汇多样性指标）和盲法专家评分，评估维度包括临床相关性、指南一致性、清晰度、干扰项合理性以及语言/文化契合度。

Result: Alama Health QA在所有NTD提及中占有超过40%的比例，并且在疟疾（7.7%）、艾滋病毒（4.1%）和结核病（5.2%）的提及频率上最高；AfriMedQA排名第二，但缺乏正式的指南链接。尽管规模庞大，但全球基准的代表性却很低（例如，三个评估集中没有包含镰状细胞病）。在定性评估中，Alama在相关性和指南一致性方面得分最高；PubMedQA在临床效用方面得分最低。

Conclusion: 现有的医疗语言模型基准主要反映了高收入国家的考试教学大纲和疾病谱，这对其在非洲的部署有效性提出了质疑，因为非洲的医疗负担主要由疟疾、艾滋病毒、结核病、镰状细胞病和其他被忽视的热带病（NTDs）主导，并且国家指南指导着护理。

Abstract: Introduction: Existing medical LLM benchmarks largely reflect examination
syllabi and disease profiles from high income settings, raising questions about
their validity for African deployment where malaria, HIV, TB, sickle cell
disease and other neglected tropical diseases (NTDs) dominate burden and
national guidelines drive care. Methodology: We systematically reviewed 31
quantitative LLM evaluation papers (Jan 2019 May 2025) identifying 19 English
medical QA benchmarks. Alama Health QA was developed using a retrieval
augmented generation framework anchored on the Kenyan Clinical Practice
Guidelines. Six widely used sets (AfriMedQA, MMLUMedical, PubMedQA, MedMCQA,
MedQAUSMLE, and guideline grounded Alama Health QA) underwent harmonized
semantic profiling (NTD proportion, recency, readability, lexical diversity
metrics) and blinded expert rating across five dimensions: clinical relevance,
guideline alignment, clarity, distractor plausibility, and language/cultural
fit. Results: Alama Health QA captured >40% of all NTD mentions across corpora
and the highest within set frequencies for malaria (7.7%), HIV (4.1%), and TB
(5.2%); AfriMedQA ranked second but lacked formal guideline linkage. Global
benchmarks showed minimal representation (e.g., sickle cell disease absent in
three sets) despite large scale. Qualitatively, Alama scored highest for
relevance and guideline alignment; PubMedQA lowest for clinical utility.
Discussion: Quantitative medical LLM benchmarks widely used in the literature
underrepresent African disease burdens and regulatory contexts, risking
misleading performance claims. Guideline anchored, regionally curated resources
such as Alama Health QA and expanded disease specific derivatives are essential
for safe, equitable model evaluation and deployment across African health
systems.

</details>


### [228] [Higher Gauge Flow Models](https://arxiv.org/abs/2507.16334)
*Alexander Strunk,Roland Assam*

Main category: cs.AI

TL;DR: Higher Gauge Flow Models extend traditional flow models using L$_{\infty}$-algebra for improved performance, as shown in experiments.


<details>
  <summary>Details</summary>
Motivation: The motivation is to extend the framework of Generative Flow Models by incorporating higher geometry and higher symmetries associated with higher groups, leading to improved performance.

Method: This paper introduces Higher Gauge Flow Models, which extend ordinary Gauge Flow Models by utilizing an L$_{\infty}$-algebra, thereby integrating higher geometry and higher symmetries of higher groups into Generative Flow Models.

Result: Experimental evaluation on a Gaussian Mixture Model dataset demonstrated substantial performance improvements of Higher Gauge Flow Models compared to traditional Flow Models.

Conclusion: Higher Gauge Flow Models, building upon ordinary Gauge Flow Models, extend the framework of Generative Flow Models by leveraging an L$_{\infty}$-algebra to incorporate higher geometry and higher symmetries associated with higher groups. Experimental evaluations show substantial performance improvements compared to traditional Flow Models.

Abstract: This paper introduces Higher Gauge Flow Models, a novel class of Generative
Flow Models. Building upon ordinary Gauge Flow Models (arXiv:2507.13414), these
Higher Gauge Flow Models leverage an L$_{\infty}$-algebra, effectively
extending the Lie Algebra. This expansion allows for the integration of the
higher geometry and higher symmetries associated with higher groups into the
framework of Generative Flow Models. Experimental evaluation on a Gaussian
Mixture Model dataset revealed substantial performance improvements compared to
traditional Flow Models.

</details>


### [229] [Learning to Call: A Field Trial of a Collaborative Bandit Algorithm for Improved Message Delivery in Mobile Maternal Health](https://arxiv.org/abs/2507.16356)
*Arpan Dasgupta,Mizhaan Maniyar,Awadhesh Srivastava,Sanat Kumar,Amrita Mahale,Aparna Hedge,Arun Suggala,Karthikeyan Shanmugam,Aparna Taneja,Milind Tambe*

Main category: cs.AI

TL;DR: 本研究通过使用机器学习优化通话时间，显著提高了印度Kilkari项目的孕产妇健康信息传递效率。


<details>
  <summary>Details</summary>
Motivation: 印度Kilkari项目通过每周语音通话向数百万母亲传递重要的孕产妇健康信息，但随机通话调度导致漏接和信息传递效率低下，因此需要优化通话调度以提高信息传递效果。

Method: 本研究采用协作多臂老虎机算法，通过学习个体用户偏好来优化移动健康语音通话的调度时间，并与随机通话调度方法进行了对比。

Result: 在试点研究中，与随机通话调度相比，协作多臂老虎机算法将通话接通率提高了20%，证明了其在提高信息传递和扩大服务规模方面的潜力。

Conclusion: 本研究结果表明，通过个性化调度优化移动健康干预措施的通话时间，可以显著提高信息传递的效率，并为大规模改善孕产妇健康提供支持。

Abstract: Mobile health (mHealth) programs utilize automated voice messages to deliver
health information, particularly targeting underserved communities,
demonstrating the effectiveness of using mobile technology to disseminate
crucial health information to these populations, improving health outcomes
through increased awareness and behavioral change. India's Kilkari program
delivers vital maternal health information via weekly voice calls to millions
of mothers. However, the current random call scheduling often results in missed
calls and reduced message delivery. This study presents a field trial of a
collaborative bandit algorithm designed to optimize call timing by learning
individual mothers' preferred call times. We deployed the algorithm with around
$6500$ Kilkari participants as a pilot study, comparing its performance to the
baseline random calling approach. Our results demonstrate a statistically
significant improvement in call pick-up rates with the bandit algorithm,
indicating its potential to enhance message delivery and impact millions of
mothers across India. This research highlights the efficacy of personalized
scheduling in mobile health interventions and underscores the potential of
machine learning to improve maternal health outreach at scale.

</details>


### [230] [Canonical Representations of Markovian Structural Causal Models: A Framework for Counterfactual Reasoning](https://arxiv.org/abs/2507.16370)
*Lucas de Lara*

Main category: cs.AI

TL;DR: 提出了一种新的表示和实现反事实概念的方法，与结构因果模型相比，它在不改变因果约束的情况下提供了更大的灵活性，并且反事实层的内容不需要估计。


<details>
  <summary>Details</summary>
Motivation: 反事实推理旨在回答与事实相反的问题，并且是因果关系中最精细的层次。然而，许多反事实陈述甚至无法通过随机实验来证伪，但它们支撑着像个体公平性这样的基本概念。因此，提供形式化和实现反事实信念的模型仍然是一个根本性的科学问题。

Method: 提出了一种替代结构因果模型的方法来表示与给定因果图模型兼容的反事实，引入了反事实模型（也称为结构因果模型的规范表示），并提出了一个归一化过程来描述和实现各种反事实概念。

Result: 与结构因果模型相比，该方法允许在不改变观察到的和干预的约束的情况下指定许多反事实概念，并且反事实层的内容不需要被估计，只需要做出选择。最后，通过理论和数值示例说明了反事实在因果关系中的特定作用以及该方法的优点。

Conclusion: 该研究提出了一种新的表示和实现反事实概念的方法，它不改变观察到的和干预的约束，并且反事实层的内容不需要被估计，只需要做出选择。

Abstract: Counterfactual reasoning aims at answering contrary-to-fact questions like
''Would have Alice recovered had she taken aspirin?'' and corresponds to the
most fine-grained layer of causation. Critically, while many counterfactual
statements cannot be falsified -- even by randomized experiments -- they
underpin fundamental concepts like individual-wise fairness. Therefore,
providing models to formalize and implement counterfactual beliefs remains a
fundamental scientific problem. In the Markovian setting of Pearl's causal
framework, we propose an alternative approach to structural causal models to
represent counterfactuals compatible with a given causal graphical model. More
precisely, we introduce counterfactual models, also called canonical
representations of structural causal models. They enable analysts to choose a
counterfactual conception via random-process probability distributions with
preassigned marginals and characterize the counterfactual equivalence class of
structural causal models. Then, we present a normalization procedure to
describe and implement various counterfactual conceptions. Compared to
structural causal models, it allows to specify many counterfactual conceptions
without altering the observational and interventional constraints. Moreover,
the content of the model corresponding to the counterfactual layer does not
need to be estimated; only to make a choice. Finally, we illustrate the
specific role of counterfactuals in causality and the benefits of our approach
on theoretical and numerical examples.

</details>


### [231] [LLM-Driven Collaborative Model for Untangling Commits via Explicit and Implicit Dependency Reasoning](https://arxiv.org/abs/2507.16395)
*Bo Hou,Xin Tan,Kai Zheng,Fang Liu,Yinghao Zhu,Li Zhang*

Main category: cs.AI

TL;DR: ColaUntangle通过LLM智能体协作，利用多版本程序依赖图区分显式和隐式依赖，有效解决了代码提交混淆问题，并在实验中显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 由于实际约束或不明确的边界，开发人员经常会创建混淆提交（tangled commits），即将不相关的更改混合在一起，这会对代码审查和维护产生负面影响。现有的提交拆分方法虽然取得了一定的进展，但往往依赖于浅层信号，并且难以区分显式依赖和隐式依赖。

Method: ColaUntangle提出了一种新的协作式咨询框架，该框架利用LLM驱动的智能体来识别和分离显式（如控制/数据流）和隐式（如语义/概念）依赖关系。它通过构建多版本程序依赖图（delta-PDG）来捕获上下文信息，并使用一个专门的审查智能体来综合不同智能体的意见，以实现迭代式咨询和优化。

Result: ColaUntangle在C#数据集上实现了44%的改进，在Java数据集上实现了100%的改进，性能优于现有的最佳基线方法。

Conclusion: ColaUntangle通过整合LLM驱动的智能体，并在多智能体架构中结合显式和隐式依赖关系，有效解决了代码提交混淆问题，并在C#和Java数据集上取得了显著的性能提升，证明了基于LLM的协作框架在自动化提交拆分任务中的潜力。

Abstract: Atomic commits, each of which addresses a single development concern, are a
best practice in software development. However, developers frequently produce
tangled commits that mix unrelated changes due to practical constraints or
unclear boundaries, negatively impacting code review and maintenance. Although
prior commit untangling approaches: rule-based, feature-based, or graph-based,
have made progress, they often rely on shallow signals and fail to distinguish
between explicit dependencies (e.g., control/data flow) and implicit ones
(e.g., semantic or conceptual relationships). In this paper, we propose
ColaUntangle, a new collaborative consultation framework for commit untangling
that models both explicit and implicit dependencies among code changes.
ColaUntangle integrates Large Language Model (LLM)-driven agents in a
multi-agent architecture: one agent specializes in explicit dependencies,
another in implicit ones, and a reviewer agent synthesizes their perspectives
through iterative consultation. To capture explicit and implicit contextual
information, we construct multi-version Program Dependency Graphs (delta-PDG),
enabling agents to reason over code relationships with both symbolic and
semantic depth. We evaluate ColaUntangle on two widely-used datasets (1,612 C#
and 14k Java tangled commits). Experimental results show that ColaUntangle
outperforms the best-performing baseline, achieving an improvement of 44% on
the C# dataset and 100% on the Java dataset. These findings highlight the
potential of LLM-based collaborative frameworks for advancing automated commit
untangling tasks.

</details>


### [232] [Self-Supervised Inductive Logic Programming](https://arxiv.org/abs/2507.16405)
*Stassa Patsantzis*

Main category: cs.AI

TL;DR: The paper introduces a new Self-Supervised ILP setting and a MIL algorithm (Poker) that learns from labeled and unlabeled examples, automatically generating and labeling new examples. Poker outperforms the state-of-the-art system Louise when negative examples are unavailable, demonstrating the effectiveness of automatically generated examples and a general second-order background theory (SONF).


<details>
  <summary>Details</summary>
Motivation: The paper addresses the challenge of learning recursive logic programs with invented predicates when a problem-specific background theory or negative examples are unavailable, formalizing this as a new setting for Self-Supervised ILP.

Method: A new MIL algorithm that learns in the new setting from some positive labelled, and zero or more unlabelled examples, and automatically generates, and labels, new positive and negative examples during learning. We implement this algorithm in Prolog in a new MIL system, called Poker. We introduce a new approach for the principled selection of a second-order background theory as a Second Order Definite Normal Form (SONF), sufficiently general to learn all programs in a class, thus removing the need for a backgound theory tailored to a learning task.

Result: Poker's performance improves with increasing numbers of automatically generated examples, while Louise, bereft of negative examples, over-generalises.

Conclusion: Poker

Abstract: Inductive Logic Programming (ILP) approaches like Meta \-/ Interpretive
Learning (MIL) can learn, from few examples, recursive logic programs with
invented predicates that generalise well to unseen instances. This ability
relies on a background theory and negative examples, both carefully selected
with expert knowledge of a learning problem and its solutions. But what if such
a problem-specific background theory or negative examples are not available? We
formalise this question as a new setting for Self-Supervised ILP and present a
new MIL algorithm that learns in the new setting from some positive labelled,
and zero or more unlabelled examples, and automatically generates, and labels,
new positive and negative examples during learning. We implement this algorithm
in Prolog in a new MIL system, called Poker. We compare Poker to
state-of-the-art MIL system Louise on experiments learning grammars for
Context-Free and L-System languages from labelled, positive example strings, no
negative examples, and just the terminal vocabulary of a language, seen in
examples, as a first-order background theory. We introduce a new approach for
the principled selection of a second-order background theory as a Second Order
Definite Normal Form (SONF), sufficiently general to learn all programs in a
class, thus removing the need for a backgound theory tailored to a learning
task. We find that Poker's performance improves with increasing numbers of
automatically generated examples while Louise, bereft of negative examples,
over-generalises.

</details>


### [233] [Identifying Pre-training Data in LLMs: A Neuron Activation-Based Detection Framework](https://arxiv.org/abs/2507.16414)
*Hongyi Tang,Zhihao Zhu,Yi Yang*

Main category: cs.AI

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: The performance of large language models (LLMs) is closely tied to their
training data, which can include copyrighted material or private information,
raising legal and ethical concerns. Additionally, LLMs face criticism for
dataset contamination and internalizing biases. To address these issues, the
Pre-Training Data Detection (PDD) task was proposed to identify if specific
data was included in an LLM's pre-training corpus. However, existing PDD
methods often rely on superficial features like prediction confidence and loss,
resulting in mediocre performance. To improve this, we introduce NA-PDD, a
novel algorithm analyzing differential neuron activation patterns between
training and non-training data in LLMs. This is based on the observation that
these data types activate different neurons during LLM inference. We also
introduce CCNewsPDD, a temporally unbiased benchmark employing rigorous data
transformations to ensure consistent time distributions between training and
non-training data. Our experiments demonstrate that NA-PDD significantly
outperforms existing methods across three benchmarks and multiple LLMs.

</details>


### [234] [From model-based learning to model-free behaviour with Meta-Interpretive Learning](https://arxiv.org/abs/2507.16434)
*Stassa Patsantzis*

Main category: cs.AI

TL;DR: Meta-Interpretive Learning trains a model-free agent to match a model-based agent's planning skills in navigation tasks, showing both approaches are equivalent.


<details>
  <summary>Details</summary>
Motivation: An autonomous agent capable of independent action in novel environments requires a combination of model-based and model-free capabilities. This research addresses the challenge of creating such an agent.

Method: The study employs Meta-Interpretive Learning to train a model-free Controller using a model-based Solver, enabling the agent to learn planning strategies.

Result: The model-free Controller successfully solves the same planning problems as the model-based Solver in both randomly generated mazes and lake maps, demonstrating equivalence in problem-solving ability.

Conclusion: The model-based solver and the model-free controller demonstrate equivalent problem-solving abilities in grid navigation tasks across different environments, indicating successful integration of model-based and model-free approaches.

Abstract: A "model" is a theory that describes the state of an environment and the
effects of an agent's decisions on the environment. A model-based agent can use
its model to predict the effects of its future actions and so plan ahead, but
must know the state of the environment. A model-free agent cannot plan, but can
act without a model and without completely observing the environment. An
autonomous agent capable of acting independently in novel environments must
combine both sets of capabilities. We show how to create such an agent with
Meta-Interpretive Learning used to learn a model-based Solver used to train a
model-free Controller that can solve the same planning problems as the Solver.
We demonstrate the equivalence in problem-solving ability of the two agents on
grid navigation problems in two kinds of environment: randomly generated mazes,
and lake maps with wide open areas. We find that all navigation problems solved
by the Solver are also solved by the Controller, indicating the two are
equivalent.

</details>


### [235] [Learning Temporal Abstractions via Variational Homomorphisms in Option-Induced Abstract MDPs](https://arxiv.org/abs/2507.16473)
*Chang Li,Yaren Zhang,Haoran Lv,Qiong Cao,Chao Xue,Xiaodong He*

Main category: cs.AI

TL;DR: 通过分层强化学习和变分推理，提出了一种在潜在空间中进行隐式推理的框架，用于LLMs，以克服显式CoT提示的计算成本高和速度慢的问题，并在推理和控制任务中取得了成功。


<details>
  <summary>Details</summary>
Motivation: 为解决大型语言模型（LLMs）在进行链式思考（CoT）推理时计算成本高、速度慢的问题，提出了一种高效的隐式推理框架，使模型能在潜在空间中进行思考，而无需生成显式文本。

Method: 本文提出了一种高效的隐式推理框架，利用分层强化学习和变分贝叶斯方法，将潜在思维建模为分层马尔可夫决策过程（H-MDP）中的选项。引入了变分马尔可夫选项评论（VMOC）算法来学习选项库，并通过推广到连续马尔可夫链的同态理论为抽象推理空间提供了理论基础。此外，还提出了一种利用监督微调（SFT）数据进行冷启动的程序。

Result: 实验证明，该方法在复杂的逻辑推理基准和运动控制任务上均取得了优异的性能，证明了其作为一种原则性学习抽象技能的方法的有效性。

Conclusion: 该框架为语言和控制学习抽象技能提供了一种原则性的方法，在大规模语言模型（LLMs）的复杂推理和控制任务中取得了显著成果。

Abstract: Large Language Models (LLMs) have shown remarkable reasoning ability through
explicit Chain-of-Thought (CoT) prompting, but generating these step-by-step
textual explanations is computationally expensive and slow. To overcome this,
we aim to develop a framework for efficient, implicit reasoning, where the
model "thinks" in a latent space without generating explicit text for every
step. We propose that these latent thoughts can be modeled as
temporally-extended abstract actions, or options, within a hierarchical
reinforcement learning framework. To effectively learn a diverse library of
options as latent embeddings, we first introduce the Variational Markovian
Option Critic (VMOC), an off-policy algorithm that uses variational inference
within the HiT-MDP framework. To provide a rigorous foundation for using these
options as an abstract reasoning space, we extend the theory of continuous MDP
homomorphisms. This proves that learning a policy in the simplified, abstract
latent space, for which VMOC is suited, preserves the optimality of the
solution to the original, complex problem. Finally, we propose a cold-start
procedure that leverages supervised fine-tuning (SFT) data to distill human
reasoning demonstrations into this latent option space, providing a rich
initialization for the model's reasoning capabilities. Extensive experiments
demonstrate that our approach achieves strong performance on complex logical
reasoning benchmarks and challenging locomotion tasks, validating our framework
as a principled method for learning abstract skills for both language and
control.

</details>


### [236] [ACT: Bridging the Gap in Code Translation through Synthetic Data Generation & Adaptive Training](https://arxiv.org/abs/2507.16478)
*Shreya Saxena,Siva Prasad,Zishan Ahmad,Vishal Vaddina*

Main category: cs.AI

TL;DR: ACT是一个创新的框架，通过内部微调开源大型语言模型来改进代码翻译。它使用合成数据和单元测试来提高性能，并通过其控制器模块智能地管理训练过程，为企业提供安全可靠的代码翻译解决方案，并加速了行业迁移项目。


<details>
  <summary>Details</summary>
Motivation: 传统的代码翻译方法依赖于手工规则，缺乏灵活性和可扩展性。先进的语言模型虽然有前景，但受限于专有的、基于API的实现，引发了数据安全和依赖性问题。因此，需要一种能够提升代码翻译能力并解决这些限制的创新框架。

Method: ACT框架通过自动化流水线、合成数据生成模块（包含单元测试以确保准确性和多样性）以及一个能够动态调整超参数、协调迭代数据生成和基于实时评估进行微调的控制器模块，实现了开源大型语言模型的内部微调。

Result: ACT成功地提升了开源模型的代码翻译性能，缩小了开源可及性与闭源解决方案高性能之间的差距。通过执行级别的检查来评估翻译质量，并已在行业规模迁移项目中实现，显著提高了开发人员的加速效果。

Conclusion: ACT提供了一个安全可靠的替代方案，可显著提升开源模型的代码翻译能力，并加速了行业规模迁移项目中的开发人员效率。

Abstract: Code translation is a crucial process in software development and migration
projects, enabling interoperability between different programming languages and
enhancing software adaptability and thus longevity. Traditional automated
translation methods rely heavily on handcrafted transformation rules, which
often lack flexibility and scalability. Meanwhile, advanced language models
present promising alternatives but are often limited by proprietary, API-based
implementations that raise concerns over data security and reliance. In this
paper, we present Auto-Train for Code Translation (ACT), an innovative
framework that aims to improve code translation capabilities by enabling
in-house finetuning of open-source Large Language Models (LLMs). ACT's
automated pipeline significantly boosts the performance of these models,
narrowing the gap between open-source accessibility and the high performance of
closed-source solutions. Central to ACT is its synthetic data generation
module, which builds extensive, high-quality datasets from initial code
samples, incorporating unit tests to ensure functional accuracy and diversity.
ACT's evaluation framework incorporates execution-level checks, offering a
comprehensive assessment of translation quality. A key feature in ACT is its
controller module, which manages the entire pipeline by dynamically adjusting
hyperparameters, orchestrating iterative data generation, and finetuning based
on real-time evaluations. This enables ACT to intelligently optimize when to
continue training, generate additional targeted training data, or stop the
process. Our results demonstrate that ACT consistently enhances the
effectiveness of open-source models, offering businesses and developers a
secure and reliable alternative. Additionally, applying our data generation
pipeline to industry-scale migration projects has led to a notable increase in
developer acceleration.

</details>


### [237] [Agentic RAG with Knowledge Graphs for Complex Multi-Hop Reasoning in Real-World Applications](https://arxiv.org/abs/2507.16507)
*Jean Lelong,Adnane Errazine,Annabelle Blangero*

Main category: cs.AI

TL;DR: INRAExplorer is an agentic RAG system that uses a multi-tool architecture and knowledge graph to overcome limitations of conventional RAG systems in complex queries and data retrieval for scientific domains.


<details>
  <summary>Details</summary>
Motivation: Conventional RAG systems fall short on complex queries, delivering limited, extractive answers and struggling with multiple targeted retrievals or navigating intricate entity relationships, which is a critical gap in knowledge-intensive domains.

Method: INRAExplorer employs an LLM-based agent with a multi-tool architecture to dynamically engage a rich knowledge base, through a comprehensive knowledge graph derived from open access INRAE publications. This design empowers INRAExplorer to conduct iterative, targeted queries, retrieve exhaustive datasets, perform multi-hop reasoning, and deliver structured, comprehensive answers.

Result: INRAExplorer empowers users to conduct iterative, targeted queries, retrieve exhaustive datasets, perform multi-hop reasoning, and deliver structured, comprehensive answers, serving as a concrete illustration of enhancing knowledge interaction in specialized fields.

Conclusion: INRAExplorer is a successful agentic RAG system that enhances knowledge interaction in specialized fields like agriculture by utilizing a multi-tool architecture and a knowledge graph.

Abstract: Conventional Retrieval-Augmented Generation (RAG) systems enhance Large
Language Models (LLMs) but often fall short on complex queries, delivering
limited, extractive answers and struggling with multiple targeted retrievals or
navigating intricate entity relationships. This is a critical gap in
knowledge-intensive domains. We introduce INRAExplorer, an agentic RAG system
for exploring the scientific data of INRAE (France's National Research
Institute for Agriculture, Food and Environment). INRAExplorer employs an
LLM-based agent with a multi-tool architecture to dynamically engage a rich
knowledge base, through a comprehensive knowledge graph derived from open
access INRAE publications. This design empowers INRAExplorer to conduct
iterative, targeted queries, retrieve exhaustive datasets (e.g., all
publications by an author), perform multi-hop reasoning, and deliver
structured, comprehensive answers. INRAExplorer serves as a concrete
illustration of enhancing knowledge interaction in specialized fields.

</details>


### [238] [Frontier AI Risk Management Framework in Practice: A Risk Analysis Technical Report](https://arxiv.org/abs/2507.16534)
*Shanghai AI Lab,:,Xiaoyang Chen,Yunhao Chen,Zeren Chen,Zhiyun Chen,Hanyun Cui,Yawen Duan,Jiaxuan Guo,Qi Guo,Xuhao Hu,Hong Huang,Lige Huang,Chunxiao Li,Juncheng Li,Qihao Lin,Dongrui Liu,Xinmin Liu,Zicheng Liu,Chaochao Lu,Xiaoya Lu,Jingjing Qu,Qibing Ren,Jing Shao,Jingwei Shi,Jingwei Sun,Peng Wang,Weibing Wang,Jia Xu,Lewen Yan,Xiao Yu,Yi Yu,Boxuan Zhang,Jie Zhang,Weichen Zhang,Zhijie Zheng,Tianyi Zhou,Bowen Zhou*

Main category: cs.AI

TL;DR: 本报告评估了AI模型的前沿风险，并根据E-T-C分析和“AI-45°定律”将风险分为绿色、黄色和红色区域。结果显示，所有模型均未触及红线，但部分模型在说服操纵、生物化学风险等方面已进入黄色区域，需要加强风险管理。


<details>
  <summary>Details</summary>
Motivation: 为了解和识别快速发展的人工智能（AI）模型带来的前所未有的风险。

Method: 该报告采用了E-T-C分析（部署环境、威胁源、赋能能力）和“AI-45°定律”，通过“红线”（不可容忍阈值）和“黄线”（早期预警指标）来评估网络攻击、生物和化学风险、说服和操纵、失控的自主AI研发、战略欺骗和策划、自我复制以及共谋等七个领域的风险。

Result: 实验结果表明，所有近期前沿AI模型均处于绿色和黄色区域，未触及红线。具体来说，在网络攻击或失控的AI研发风险方面，没有模型触及黄线。在自我复制、战略欺骗和策划方面，大多数模型仍处于绿色区域，但某些推理模型已进入黄色区域。在说服和操纵方面，由于其对人类的有效影响，大多数模型均处于黄色区域。在生物和化学风险方面，尚无法排除大多数模型处于黄色区域的可能性，但需要详细的威胁建模和深入评估才能做出进一步判断。

Conclusion: 该报告对人工智能（AI）模型的前沿风险进行了全面评估，并提出了应对这些风险的建议。

Abstract: To understand and identify the unprecedented risks posed by rapidly advancing
artificial intelligence (AI) models, this report presents a comprehensive
assessment of their frontier risks. Drawing on the E-T-C analysis (deployment
environment, threat source, enabling capability) from the Frontier AI Risk
Management Framework (v1.0) (SafeWork-F1-Framework), we identify critical risks
in seven areas: cyber offense, biological and chemical risks, persuasion and
manipulation, uncontrolled autonomous AI R\&D, strategic deception and
scheming, self-replication, and collusion. Guided by the "AI-$45^\circ$ Law,"
we evaluate these risks using "red lines" (intolerable thresholds) and "yellow
lines" (early warning indicators) to define risk zones: green (manageable risk
for routine deployment and continuous monitoring), yellow (requiring
strengthened mitigations and controlled deployment), and red (necessitating
suspension of development and/or deployment). Experimental results show that
all recent frontier AI models reside in green and yellow zones, without
crossing red lines. Specifically, no evaluated models cross the yellow line for
cyber offense or uncontrolled AI R\&D risks. For self-replication, and
strategic deception and scheming, most models remain in the green zone, except
for certain reasoning models in the yellow zone. In persuasion and
manipulation, most models are in the yellow zone due to their effective
influence on humans. For biological and chemical risks, we are unable to rule
out the possibility of most models residing in the yellow zone, although
detailed threat modeling and in-depth assessment are required to make further
claims. This work reflects our current understanding of AI frontier risks and
urges collective action to mitigate these challenges.

</details>


### [239] [Novel Multi-Agent Action Masked Deep Reinforcement Learning for General Industrial Assembly Lines Balancing Problems](https://arxiv.org/abs/2507.16635)
*Ali Mohamed Ali,Luca Tirel,Hashim A. Hashim*

Main category: cs.AI

TL;DR: This paper introduces a DRL framework using MDP, action-masking, and multi-agent systems to optimize industrial assembly lines, showing faster convergence than traditional methods.


<details>
  <summary>Details</summary>
Motivation: Efficient planning of activities in industrial assembly lines is crucial for meeting manufacturing standards, avoiding constraint violations, and achieving cost-effectiveness. Existing methods like Integer Programming (IP) can be computationally infeasible for large-scale scenarios, while heuristic methods like Genetic Algorithms may yield suboptimal solutions. This work aims to address these limitations by proposing a more robust and efficient planning approach.

Method: A novel mathematical model of a generic industrial assembly line formulated as a Markov Decision Process (MDP) is proposed. This model is used to create a virtual environment for training Deep Reinforcement Learning (DRL) agents. Two tools are introduced to enhance training efficiency: an action-masking technique to ensure feasible actions and a multi-agent approach where each workstation is managed by an individual agent. A centralized training with decentralized execution framework is adopted.

Result: Numerical simulations demonstrate that the proposed scheme significantly improves convergence speed to the optimal solution when compared to a comparable model-based approach, validating the effectiveness of the DRL framework with action-masking and multi-agent strategies.

Conclusion: The proposed Deep Reinforcement Learning (DRL) framework, incorporating action-masking and a multi-agent approach with centralized training and decentralized execution, offers a scalable and efficient solution for optimizing industrial assembly lines. Numerical simulations validate its effectiveness, showing significantly faster convergence to optimal solutions compared to model-based methods.

Abstract: Efficient planning of activities is essential for modern industrial assembly
lines to uphold manufacturing standards, prevent project constraint violations,
and achieve cost-effective operations. While exact solutions to such challenges
can be obtained through Integer Programming (IP), the dependence of the search
space on input parameters often makes IP computationally infeasible for
large-scale scenarios. Heuristic methods, such as Genetic Algorithms, can also
be applied, but they frequently produce suboptimal solutions in extensive
cases. This paper introduces a novel mathematical model of a generic industrial
assembly line formulated as a Markov Decision Process (MDP), without imposing
assumptions on the type of assembly line a notable distinction from most
existing models. The proposed model is employed to create a virtual environment
for training Deep Reinforcement Learning (DRL) agents to optimize task and
resource scheduling. To enhance the efficiency of agent training, the paper
proposes two innovative tools. The first is an action-masking technique, which
ensures the agent selects only feasible actions, thereby reducing training
time. The second is a multi-agent approach, where each workstation is managed
by an individual agent, as a result, the state and action spaces were reduced.
A centralized training framework with decentralized execution is adopted,
offering a scalable learning architecture for optimizing industrial assembly
lines. This framework allows the agents to learn offline and subsequently
provide real-time solutions during operations by leveraging a neural network
that maps the current factory state to the optimal action. The effectiveness of
the proposed scheme is validated through numerical simulations, demonstrating
significantly faster convergence to the optimal solution compared to a
comparable model-based approach.

</details>


### [240] [Adaptive Inventory Strategies using Deep Reinforcement Learning for Dynamic Agri-Food Supply Chains](https://arxiv.org/abs/2507.16670)
*Amandeep Kaur,Gyan Prakash*

Main category: cs.AI

TL;DR: 通过结合价值和策略的DRL方法，提出了一种新的库存管理算法，用于优化农产品供应链，考虑不确定性和保质期，以最大化利润并促进协作。


<details>
  <summary>Details</summary>
Motivation: 为了解决农产品季节性波动导致的库存管理挑战，以及现有文献中供应链各方协调的缺失问题，本研究旨在优化农产品库存管理。

Method: 提出了一种结合了基于价值和基于策略的DRL方法的深度强化学习算法，用于优化农产品库存管理，并考虑了不确定性、保质期和供应链各方协作。

Result: 实验结果证实了所提出的库存补充策略在随机需求和提前期场景下的优越性能，有效解决了库存优化挑战，并具有管理启示。

Conclusion: 该研究提出了一种新颖的深度强化学习（DRL）算法，用于优化农产品供应链中的库存管理，考虑了不确定性、保质期和多方协作。实验结果表明，该算法在随机需求和提前期场景下表现优于传统方法，并具有实际管理意义。

Abstract: Agricultural products are often subject to seasonal fluctuations in
production and demand. Predicting and managing inventory levels in response to
these variations can be challenging, leading to either excess inventory or
stockouts. Additionally, the coordination among stakeholders at various level
of food supply chain is not considered in the existing body of literature. To
bridge these research gaps, this study focuses on inventory management of
agri-food products under demand and lead time uncertainties. By implementing
effective inventory replenishment policy results in maximize the overall profit
throughout the supply chain. However, the complexity of the problem increases
due to these uncertainties and shelf-life of the product, that makes
challenging to implement traditional approaches to generate optimal set of
solutions. Thus, the current study propose a novel Deep Reinforcement Learning
(DRL) algorithm that combines the benefits of both value- and policy-based DRL
approaches for inventory optimization under uncertainties. The proposed
algorithm can incentivize collaboration among stakeholders by aligning their
interests and objectives through shared optimization goal of maximizing
profitability along the agri-food supply chain while considering perishability,
and uncertainty simultaneously. By selecting optimal order quantities with
continuous action space, the proposed algorithm effectively addresses the
inventory optimization challenges. To rigorously evaluate this algorithm, the
empirical data from fresh agricultural products supply chain inventory is
considered. Experimental results corroborate the improved performance of the
proposed inventory replenishment policy under stochastic demand patterns and
lead time scenarios. The research findings hold managerial implications for
policymakers to manage the inventory of agricultural products more effectively
under uncertainty.

</details>


### [241] [Deliberative Searcher: Improving LLM Reliability via Reinforcement Learning with constraints](https://arxiv.org/abs/2507.16727)
*Zhenyun Yin,Shujie Wang,Xuhong Wang,Xingjun Ma,Yinchun Wang*

Main category: cs.AI

TL;DR: Deliberative Searcher is a framework that integrates certainty calibration with retrieval-based search for open-domain question answering, improving LLM reliability and trustworthiness.


<details>
  <summary>Details</summary>
Motivation: Improving the reliability of large language models (LLMs) is critical for deploying them in real-world scenarios.

Method: The agent performs multi-step reflection and verification over Wikipedia data and is trained with a reinforcement learning algorithm that optimizes for accuracy under a soft reliability constraint.

Result: Empirical results show that proposed method improves alignment between model confidence and correctness, leading to more trustworthy outputs.

Conclusion: Proposed method improves alignment between model confidence and correctness, leading to more trustworthy outputs.

Abstract: Improving the reliability of large language models (LLMs) is critical for
deploying them in real-world scenarios. In this paper, we propose
\textbf{Deliberative Searcher}, the first framework to integrate certainty
calibration with retrieval-based search for open-domain question answering. The
agent performs multi-step reflection and verification over Wikipedia data and
is trained with a reinforcement learning algorithm that optimizes for accuracy
under a soft reliability constraint. Empirical results show that proposed
method improves alignment between model confidence and correctness, leading to
more trustworthy outputs. This paper will be continuously updated.

</details>


### [242] [WGRAMMAR: Leverage Prior Knowledge to Accelerate Structured Decoding](https://arxiv.org/abs/2507.16768)
*Ran Wang,Xiaoxuan Liu,Hao Ren,Gang Chen,Fanchao Qi,Maosong Sun*

Main category: cs.AI

TL;DR: wgrammar是一种新的轻量级解码引擎，通过约束分解和算子组合提高了结构化解码的效率，速度提升高达250倍。


<details>
  <summary>Details</summary>
Motivation: 现有结构化解码方法存在效率瓶颈，如语法编译、状态跟踪和掩码创建。本研究旨在利用现实世界任务中存在的强先验知识来提高结构化解码的效率。

Method: 提出了一种将约束分解为静态和动态组件的方法，预编译静态结构，并在运行时使用语法片段实例化动态参数。使用一组组合算子来模拟常规格式，而不是依赖于下推自动机。

Result: wgrammar引擎实现了高达250倍于现有系统的速度提升。

Conclusion: wgrammar引擎通过结合领域感知简化、约束分解和掩码缓存，在效率上实现了显著提升，比现有系统快250倍。

Abstract: Structured decoding enables large language models (LLMs) to generate outputs
in formats required by downstream systems, such as HTML or JSON. However,
existing methods suffer from efficiency bottlenecks due to grammar compilation,
state tracking, and mask creation. We observe that many real-world tasks embed
strong prior knowledge about output structure. Leveraging this, we propose a
decomposition of constraints into static and dynamic components -- precompiling
static structures offline and instantiating dynamic arguments at runtime using
grammar snippets. Instead of relying on pushdown automata, we employ a
compositional set of operators to model regular formats, achieving lower
transition latency. We introduce wgrammar, a lightweight decoding engine that
integrates domain-aware simplification, constraint decomposition, and mask
caching, achieving up to 250x speedup over existing systems. wgrammar's source
code is publicly available at https://github.com/wrran/wgrammar.

</details>


### [243] [ChatChecker: A Framework for Dialogue System Testing and Evaluation Through Non-cooperative User Simulation](https://arxiv.org/abs/2507.16792)
*Roman Mayr,Michel Schimpf,Thomas Bohné*

Main category: cs.AI

TL;DR: ChatChecker是一个用于评估复杂对话系统的框架，它使用LLM模拟用户交互并检测对话中断。与以往的方法相比，它更易于设置、更通用，并且通过错误分类和新颖的用户模拟器提高了性能，有助于加速鲁棒对话系统的开发。


<details>
  <summary>Details</summary>
Motivation: 现有对话系统评估方法主要关注回合层面的分析，而忽略了对话层面的质量保证。然而，现代对话系统集成多个LLM、外部工具和数据库，因此需要对整个系统进行评估，而不是单独评估其底层的LLM。

Method: ChatChecker框架通过利用LLM模拟用户交互，并包含一个错误分类体系来改进中断检测性能。此外，它引入了一种基于挑战性角色的新颖的非合作用户模拟器，以更有效地发现目标对话系统的弱点。

Result: ChatChecker框架在减少设置工作量和提高通用性方面优于先前的方法，因为它不需要参考对话，并且与目标对话系统的实现无关。通过加入错误分类体系，其中断检测性能有所提升，并且新提出的非合作用户模拟器比先前基于LLM的方法更有效地揭示了目标对话系统的弱点。

Conclusion: ChatChecker框架能够对复杂的对话系统进行全面的、可扩展的评估和测试，通过模拟多样化的用户交互、识别对话中断并评估质量，从而加速鲁棒对话系统的开发。

Abstract: While modern dialogue systems heavily rely on large language models (LLMs),
their implementation often goes beyond pure LLM interaction. Developers
integrate multiple LLMs, external tools, and databases. Therefore, assessment
of the underlying LLM alone does not suffice, and the dialogue systems must be
tested and evaluated as a whole. However, this remains a major challenge. With
most previous work focusing on turn-level analysis, less attention has been
paid to integrated dialogue-level quality assurance. To address this, we
present ChatChecker, a framework for automated evaluation and testing of
complex dialogue systems. ChatChecker uses LLMs to simulate diverse user
interactions, identify dialogue breakdowns, and evaluate quality. Compared to
previous approaches, our design reduces setup effort and is generalizable, as
it does not require reference dialogues and is decoupled from the
implementation of the target dialogue system. We improve breakdown detection
performance over a prior LLM-based approach by including an error taxonomy in
the prompt. Additionally, we propose a novel non-cooperative user simulator
based on challenging personas that uncovers weaknesses in target dialogue
systems more effectively. Through this, ChatChecker contributes to thorough and
scalable testing. This enables both researchers and practitioners to accelerate
the development of robust dialogue systems.

</details>


### [244] [Uncertainty-Aware Knowledge Transformers for Peer-to-Peer Energy Trading with Multi-Agent Reinforcement Learning](https://arxiv.org/abs/2507.16796)
*Mian Ibad Ali Shah,Enda Barrett,Karl Mason*

Main category: cs.AI

TL;DR: 本研究提出了一种新的P2P能源交易框架，结合了能预测不确定性的KTU模型和MARL。实验证明，该框架能有效降低成本、增加收入并减少电网峰值需求，尤其是在P2P交易中效果更佳。


<details>
  <summary>Details</summary>
Motivation: 当前P2P能源交易研究的不足之处在于，现有的方法大多依赖于确定性预测，未能充分考虑能源交易环境中固有的不确定性。这种不确定性对交易决策的稳健性至关重要。因此，本研究旨在提出一种能够明确量化预测不确定性的方法，并将其应用于P2P能源交易，以实现更优化的交易策略和风险管理。

Method: 本研究提出了一个结合了不确定性感知预测和多智能体强化学习（MARL）的P2P能源交易新框架。其中，不确定性感知预测部分采用了基于异方差概率Transformer的模型KTU（Knowledge Transformer with Uncertainty），该模型能够量化预测的不确定性。KTU模型利用领域特定特征，并通过自定义损失函数进行训练，以确保提供可靠的概率预测和置信区间。随后，将这些不确定性感知预测整合到MARL框架中，使智能体能够考虑风险和变异性进行交易策略的优化。

Result: 实验结果表明，采用不确定性感知深度Q网络（DQN）的交易策略，在不进行P2P交易的情况下，能源购买成本降低了高达5.7%，在进行P2P交易时降低了3.2%。同时，电力销售收入分别增加了6.4%和44.7%。此外，峰值时段的电网需求分别减少了38.8%（无P2P）和45.6%（有P2P）。这些改进在启用P2P交易时更为显著，证明了先进预测技术与P2P市场机制协同作用的优势。

Conclusion: 本研究提出的不确定性感知预测与多智能体强化学习（MARL）相结合的P2P能源交易框架，在实际应用中显著降低了能源成本并增加了收入，同时有效减少了峰值时段的电网需求，尤其在启用P2P交易时效果更为显著，证明了其在构建弹性、经济高效的能源社区方面的潜力。

Abstract: This paper presents a novel framework for Peer-to-Peer (P2P) energy trading
that integrates uncertainty-aware prediction with multi-agent reinforcement
learning (MARL), addressing a critical gap in current literature. In contrast
to previous works relying on deterministic forecasts, the proposed approach
employs a heteroscedastic probabilistic transformer-based prediction model
called Knowledge Transformer with Uncertainty (KTU) to explicitly quantify
prediction uncertainty, which is essential for robust decision-making in the
stochastic environment of P2P energy trading. The KTU model leverages
domain-specific features and is trained with a custom loss function that
ensures reliable probabilistic forecasts and confidence intervals for each
prediction. Integrating these uncertainty-aware forecasts into the MARL
framework enables agents to optimize trading strategies with a clear
understanding of risk and variability. Experimental results show that the
uncertainty-aware Deep Q-Network (DQN) reduces energy purchase costs by up to
5.7% without P2P trading and 3.2% with P2P trading, while increasing
electricity sales revenue by 6.4% and 44.7%, respectively. Additionally, peak
hour grid demand is reduced by 38.8% without P2P and 45.6% with P2P. These
improvements are even more pronounced when P2P trading is enabled, highlighting
the synergy between advanced forecasting and market mechanisms for resilient,
economically efficient energy communities.

</details>


<div id='cs.GT'></div>

# cs.GT [[Back]](#toc)

### [245] [Best-of-Both-Worlds Guarantees with Fairer Endings](https://arxiv.org/abs/2507.16209)
*Telikepalli Kavitha,Surya Panchapakesan,Rohit Vaish,Vignesh Viswanathan,Jatin Yadav*

Main category: cs.GT

TL;DR: 本研究旨在解决公平分配不可分割物品的问题，重点在于提高分配的公平性。研究针对不同类型的偏好（字典序、单调、次可加）提出了相应的分配策略和保证，包括但不限于实现事后 EFX 和预前 EF，并对预前和事后公平性之间的权衡进行了深入分析。


<details>
  <summary>Details</summary>
Motivation: 本研究的动机在于寻求更强的公平分配保证，特别是事后 envy-freeness up to any good (EFX) 以及有意义的预前保证。现有研究在随机分配和确定性分配之间取得了一定的平衡，但未能充分满足对更强公平性的需求。

Method: 本研究采用了多种方法来处理公平分配问题。首先，对于字典序偏好，研究通过证明预前 sd-EF 和事后 EFX 的不兼容性，然后提出了一种结合了依赖性舍入和 EFX/PO 分配结构特性的新算法。其次，对于单调估值，研究分析了 EFX-with-charity 的性质。最后，对于次可加估值，研究通过调整分配策略来增强事后保证并放宽预前保证。

Result: 研究取得了以下成果：1) 证明了在字典序偏好下，预前sd-EF与事后EFX的基本不兼容性；提出了一种多项式时间算法，该算法实现了事后 EFX 和 PO，以及预前 9/10-EF。2) 对于单调估值，研究证明了事后 EFX-with-charity 可以与预前 0.5-EF 并存。3) 对于次可加估值，研究将事后保证增强到 EFX-with-bounded-charity，并相应地将预前保证放宽到 0.5-proportionality。

Conclusion: 该研究在公平分配不可分割物品的问题上取得了重要进展。对于字典序偏好，研究证明了预前stochastic-dominance envy-free (sd-EF)与事后 envy-free up to one good (EFX) 的不兼容性，并提出了一种同时实现事后 EFX 和 PO 以及预前 9/10-EF 的多项式时间算法。对于单调估值，研究实现了事后 EFX-with-charity 与预前 0.5-EF。对于次可加估值，研究将事后保证增强到 EFX-with-bounded-charity，同时将预前保证放宽到 0.5-proportionality。

Abstract: Fair allocation of indivisible goods is a fundamental problem at the
interface of economics and computer science. Traditional approaches focus
either on randomized allocations that are fair in expectation or deterministic
allocations that are approximately fair. Recent work reconciles both these
approaches via best-of-both-worlds guarantees, wherein one seeks randomized
allocations that are fair in expectation (ex-ante fair) while being supported
on approximately fair allocations (ex-post fair). Prior work has shown that
under additive valuations, there always exists a randomized allocation that is
ex-ante stochastic-dominance envy-free (sd-EF) and ex-post envy-free up to one
good (EF1).
  Our work is motivated by the goal of achieving stronger ex-post fairness
guarantees such as envy-freeness up to any good (EFX) along with meaningful
ex-ante guarantees. We make the following contributions:
  1) We first consider lexicographic preferences, a subdomain of additive
valuations where ex-post EFX allocations always exist and can be computed
efficiently. On the negative side, we show that ex-ante sd-EF is fundamentally
incompatible with ex-post EFX, prompting a relaxation of the ex-ante benchmark.
We then present a poly. time algorithm that achieves ex-post EFX and PO
together with ex-ante 9/10-EF. Our algorithm uses dependent rounding and
leverages structural properties of EFX and PO allocations.
  2)For monotone valuations, we study EFX-with-charity: a relaxation of EFX
where some goods remain unallocated, with no agent envying the unallocated
pool. We show that ex-post EFX-with-charity can be achieved alongside ex-ante
0.5-EF.
  3)Finally, for subadditive valuations, we strengthen our previous ex-post
guarantee to EFX-with-bounded-charity, where at most n-1 goods (n= no. of
agents) remain unallocated, at the price of weakening the ex-ante guarantee to
0.5-proportionality.

</details>


<div id='cs.GR'></div>

# cs.GR [[Back]](#toc)

### [246] [Dream, Lift, Animate: From Single Images to Animatable Gaussian Avatars](https://arxiv.org/abs/2507.15979)
*Marcel C. Bühler,Ye Yuan,Xueting Li,Yangyi Huang,Koki Nagano,Umar Iqbal*

Main category: cs.GR

TL;DR: DLA框架使用视频扩散模型和3D高斯技术，从单张图像重建可动画的3D人类化身，实现了高质量、实时渲染和编辑。


<details>
  <summary>Details</summary>
Motivation: 从单张图像重建可动画的3D人类化身，旨在捕捉丰富的几何和外观细节，并实现高效渲染和直观编辑。

Method: DLA框架通过多视图生成、3D高斯提升和3D高斯的姿态感知UV空间映射来实现。首先利用视频扩散模型生成多视图，然后将这些视图提升为非结构化3D高斯。接着，通过基于Transformer的编码器将高斯投影到与参数化身体模型UV空间对齐的结构化潜在表示中，该潜在代码可解码为UV空间高斯，并通过身体驱动的变形进行动画处理，并根据姿态和视角进行渲染。

Result: DLA能够在不经过后处理的情况下实现实时渲染和直观编辑，并且在ActorsHQ和4D-Dress数据集上，无论是在感知质量还是光度准确性方面，都优于现有技术。

Conclusion: DLA通过结合视频扩散模型的生成能力和姿态感知UV空间高斯映射，实现了从单张图像到高保真、可动画化3D人类化身的重建，填补了非结构化3D表示与高质量、可动画化身之间的空白。

Abstract: We introduce Dream, Lift, Animate (DLA), a novel framework that reconstructs
animatable 3D human avatars from a single image. This is achieved by leveraging
multi-view generation, 3D Gaussian lifting, and pose-aware UV-space mapping of
3D Gaussians. Given an image, we first dream plausible multi-views using a
video diffusion model, capturing rich geometric and appearance details. These
views are then lifted into unstructured 3D Gaussians. To enable animation, we
propose a transformer-based encoder that models global spatial relationships
and projects these Gaussians into a structured latent representation aligned
with the UV space of a parametric body model. This latent code is decoded into
UV-space Gaussians that can be animated via body-driven deformation and
rendered conditioned on pose and viewpoint. By anchoring Gaussians to the UV
manifold, our method ensures consistency during animation while preserving fine
visual details. DLA enables real-time rendering and intuitive editing without
requiring post-processing. Our method outperforms state-of-the-art approaches
on ActorsHQ and 4D-Dress datasets in both perceptual quality and photometric
accuracy. By combining the generative strengths of video diffusion models with
a pose-aware UV-space Gaussian mapping, DLA bridges the gap between
unstructured 3D representations and high-fidelity, animation-ready avatars.

</details>


### [247] [MMS Player: an open source software for parametric data-driven animation of Sign Language avatars](https://arxiv.org/abs/2507.16463)
*Fabrizio Nunnari,Shailesh Mishra,Patrick Gebhard*

Main category: cs.GR

TL;DR: MMS-Player是一个开源的Blender插件，用于从MMS格式合成手语动画，支持多种输出格式。


<details>
  <summary>Details</summary>
Motivation: MMS格式通过添加并行执行、时序和屈折信息来增强基于词条的手语表示。

Method: 通过Python脚本在Blender 3D创作工具中实现，可通过命令行或HTTP API调用。

Result: 生成的动画可以渲染为视频或导出为其他流行的3D动画交换格式。

Conclusion: MMS-Player是一个开源软件，能够从MMS（MultiModal Signstream）这一新的手语表示格式合成手语动画。

Abstract: This paper describes the MMS-Player, an open source software able to
synthesise sign language animations from a novel sign language representation
format called MMS (MultiModal Signstream). The MMS enhances gloss-based
representations by adding information on parallel execution of signs, timing,
and inflections. The implementation consists of Python scripts for the popular
Blender 3D authoring tool and can be invoked via command line or HTTP API.
Animations can be rendered as videos or exported in other popular 3D animation
exchange formats. The software is freely available under GPL-3.0 license at
https://github.com/DFKI-SignLanguage/MMS-Player.

</details>


<div id='cond-mat.mes-hall'></div>

# cond-mat.mes-hall [[Back]](#toc)

### [248] [Trimer superfluidity of antiparallel dipolar excitons in a bilayer heterostructure](https://arxiv.org/abs/2507.15938)
*Pradyumna P. Belgaonkar,Michal Zimmerman,Snir Gazit,Dror Orgad*

Main category: cond-mat.mes-hall

TL;DR: 量子蒙特卡洛模拟研究了具有1:2密度比的具有反平行偶极子二层结构的激子相图。该系统支持三聚物的形成，即由一层中的单个偶极子和第二层中的两个偶极子组成的三激子束缚态。在足够低的温度和密度下，这些三聚物凝结成三聚物超流相。增加激子密度会引起量子相变，进入两个层中都存在独立偶极子凝结物的相，与三聚物平行。还研究了这些相的热跃迁，发现在三聚物超流相和两超流相中，热无序过程涉及一个中间态，该中间态要么是三聚物超流相，要么是较密集层中的单激子凝结物。


<details>
  <summary>Details</summary>
Motivation: 研究具有1:2密度比的具有反平行偶极子二层结构的激子相图。

Method: 使用量子蒙特卡洛模拟研究了具有1:2密度比的具有反平行偶极子二层结构的激子相图，该相图是温度和密度的函数。

Result: 在足够低的温度和密度下，这些三聚物凝结成三聚物超流相。增加激子密度会引起量子相变，进入两个层中都存在独立偶极子凝结物的相，与三聚物平行。研究了这些相的热跃迁，发现在三聚物超流相和两超流相中，热无序过程涉及一个中间态，该中间态要么是三聚物超流相，要么是较密集层中的单激子凝结物。

Conclusion: 该系统支持三聚物的形成，即由一层中的单个偶极子和第二层中的两个偶极子组成的三激子束缚态。在足够低的温度和密度下，这些三聚物凝结成三聚物超流相。增加激子密度会引起量子相变，进入两个层中都存在独立偶极子凝结物的相，与三聚物平行。研究了这些相的热跃迁，发现在三聚物超流相和两超流相中，热无序过程涉及一个中间态，该中间态要么是三聚物超流相，要么是较密集层中的单激子凝结物。

Abstract: We study the phase diagram of a bilayer of antiparallel dipolar excitons with
a 1:2 density ratio between the layers, as a function of temperature and
density. Using quantum Monte Carlo simulations, we show that such a system
supports the formation of trimers, namely, three-exciton bound states
consisting of a single dipole in one layer and two dipoles in the second layer.
At sufficiently low temperatures and densities, these trimers condense into a
trimer superfluid phase. Increasing the excitonic density induces a quantum
phase transition into a phase in which condensates of independent dipoles exist
in both layers, in parallel to the trimers. We also study the thermal
transitions out of these phases, and find that while the normal state is
reached directly from the trimer superfluid, the thermal disordering of the
two-superfluid phase involves an intermediate state which is either a trimer
superfluid or a single excitonic condensate in the denser layer. A potential
experimental realization using transition metal dichalcogenide heterostructures
is discussed.

</details>


### [249] [Scanning Tunneling Microscope Tip-Induced Formation of Bi Bilayers on Bi$_2$Te$_3$](https://arxiv.org/abs/2507.16081)
*Duy Nguyen,Jay A. Gupta*

Main category: cond-mat.mes-hall

TL;DR: STM电压脉冲可在Bi2Te3表面形成Bi双层岛和陨石坑。


<details>
  <summary>Details</summary>
Motivation: 研究电压脉冲如何影响Bi2Te3表面，并解释所观察到的现象。

Method: 使用扫描隧道显微镜（STM）施加电压脉冲。

Result: 电压脉冲（>+3V）在Bi2Te3表面产生陨石坑，并析出Bi双层岛，岛的大小随着离脉冲点的距离增加而减小。

Conclusion: 电压脉冲诱导的Bi(111)双层岛和陨石坑结构在Bi2Te3(111)表面形成，这表明了场蒸发和隧穿电流引起焦耳加热的相互作用机制。

Abstract: We report the formation of Bi(111) bilayer (BL) islands and crater structures
on Bi$_2$Te$_3$(111) surfaces induced by voltage pulses from an STM tip. Pulses
above a threshold voltage ($+3$ V) produce craters $\sim 0.5$ microns in
diameter, similar to the size of the tip. Redeposited material self-assembles
into a network of atomically ordered islands with a lattice constant identical
to the underlying Bi$_2$Te$_3$ surface. The island size monotonically decreases
over several microns from the pulse site, until the pristine Bi$_2$Te$_3$
surface is recovered. We assign these islands to Bi BL based on atomic
resolution images, analysis of step heights, and tunneling spectroscopy. The
dependence of bilayer formation on bias polarity and the evidence for defect
diffusion together suggest a mechanism driven by the interplay of field
evaporation and tunneling-current-induced Joule heating.

</details>


### [250] [Spatial filtering of interlayer exciton ground state in WSe2/MoS2 heterobilayer](https://arxiv.org/abs/2507.16180)
*Disheng Chen,Kevin Dini,Abdullah Rasmita,Zumeng Huang,Qinghai Tan,Hongbing Cai,Ruihua He,Yansong Miao,Timothy C. H. Liew,Wei-bo Gao*

Main category: cond-mat.mes-hall

TL;DR: 通过空间分布特征分离 WSe2/MoS2 异质双层中的 IX 基态，为实现高温关联态提供了新工具。


<details>
  <summary>Details</summary>
Motivation: 长寿命的 IXs 在 TMD 异质结构中是实现高温激子凝聚的关键，而分离 IX 基态对于实现高温激子凝聚和研究激子莫特绝缘体等关联激子态的动力学至关重要。

Method: 利用 WSe2/MoS2 异质双层中的空间分布特征，并通过与速率扩散模型进行比对，实现 IX 基态与其他 IX 态（不同能量和空间分布）的分离。

Result: 成功地通过空间分布特征将 WSe2/MoS2 异质双层中的 IX 基态与其他 IX 态区分开来，并发现不同 IX 模式的空间分布和能量不同，且符合速率扩散模型。

Conclusion: 本研究表明，WSe2/MoS2 异质双层中的 IX 基态模式可以通过空间滤波来分离，这为在较高温度下实现关联态提供了新的方法。

Abstract: Long-life interlayer excitons (IXs) in transition metal dichalcogenide (TMD)
heterostructure are promising for realizing excitonic condensates at high
temperatures. Critical to this objective is to separate the IX ground state
(the lowest energy of IX state) emission from other states emissions. Filtering
the IX ground state is also essential in uncovering the dynamics of correlated
excitonic states, such as the excitonic Mott insulator. Here, we show that the
IX ground state in WSe2/MoS2 heterobilayer can be separated from other states
by its spatial profile. The emissions from different moire IX modes are
identified by their different energies and spatial distributions, which fits
well with the rate-diffusion model for cascading emission. Our results show
spatial filtering of the ground state mode and enrich the toolbox to realize
correlated states at elevated temperatures.

</details>


### [251] [Long-lived Photoluminescence of Photostable One-dimensional Picoperovskites](https://arxiv.org/abs/2507.16352)
*Maximilian Tomoscheit,Julian Schröer,Jaskaran Singh Virdee,Rico Schwartz,Christopher E. Patrick,Reza J. Kashtiban,Tobias Korn*

Main category: cond-mat.mes-hall

TL;DR: 太长不看：研究发现，封装在纳米管中的一维钙钛矿比块状钙钛矿发光更持久，且发射波长更红。


<details>
  <summary>Details</summary>
Motivation: 动机：研究封装在单壁纳米管中的一维金属卤化物钙钛矿晶体（皮秒钙钛矿）的光学特性，并与块状钙钛矿进行比较。

Method: 方法：使用光学光谱，包括偏振微光致发光（PL）和温度/时间分辨微PL，研究了封装在单壁纳米管中的一维金属卤化物钙钛矿晶体（皮秒钙钛矿）。

Result: 结果：观察到皮秒钙钛矿的明亮发射，具有沿着束轴的清晰线性偏振。与使用相同成分的块状钙钛矿样品相比，其发射发生了红移。此外，在低温下，皮秒钙钛矿的光致发光寿命异常长，达到数百纳秒，比块状钙钛矿长两个数量级。

Conclusion: 总结：一维金属卤化物钙钛矿（皮秒钙钛矿）在单壁纳米管中表现出比块状钙钛矿更长的光致发光寿命和红移发射。

Abstract: We study one-dimensional metal halide perovskite crystals encapsulated in
single-wall nanotubes, so-called picoperovskites, using optical spectroscopy.
Polarized micro-photoluminescence (PL) reveals bright emission from aligned
bundles of picoperovskites with clear linear polarization along the bundle
axis. This emission is red-shifted with respect to bulk perovskite samples
using the same constituents. Temperature-dependent, time-resolved micro-PL
shows extraordinarily long PL lifetimes of the picoperovskites at low
temperatures, reaching several hundred nanoseconds and exceeding those of bulk
perovskites by two orders of magnitude.

</details>


### [252] [A sublattice Stokes polarimeter for bipartite photonic lattices](https://arxiv.org/abs/2507.16446)
*Martin Guillot,Cédric Blanchard,Nicolas Pernet,Martina Morassi,Aristide Lemaître,Luc Le Gratiet,Abdelmounaim Harouri,Isabelle Sagnes,Jacqueline Bloch,Sylvain Ravets*

Main category: cond-mat.mes-hall

TL;DR: 研究人员开发了一种新型斯托克斯极化计，用于测量光子晶格中的亚晶格极化，能够精确重构布洛赫模并获得系统哈密顿量，为研究更复杂的拓扑现象提供了新方法。


<details>
  <summary>Details</summary>
Motivation: 将斯托克斯极化测量推广到其他赝自旋自由度是一个重要挑战，因为赝自旋可以看作是斯托克斯矢量在庞加莱球上的映射，而斯托克斯极化计在测量光偏振方面有广泛应用。

Method: 该方法利用k空间光致发光强度测量，并在每个子晶格上应用受控的相位移动和衰减，实现了亚晶格极化的斯托克斯极化计。

Result: 在作为光子石墨烯和六方氮化硼类似物的蜂窝状耦合微腔阵列中，成功实现了亚晶格极化计，并重构了布里渊区布洛赫模的幅度和相位，在确定本征能量时达到了亚线宽精度。

Conclusion: 该方法能够精确重构布里渊区布洛赫模的幅度和相位，并在确定本征能量时达到亚线宽精度，特别是靠近能带接触点附近。这使得能够完全获取系统的布洛赫哈密顿量和量子几何张量。此外，该方法易于扩展到具有附加内部自由度的更复杂系统，为研究三角翘曲、陈绝缘体相以及多重带隙系统中的欧拉类拓扑提供了实验途径。

Abstract: The concept of pseudo-spin provides a general framework for describing
physical systems featuring two-component spinors, including light polarization,
sublattice degrees of freedom in bipartite lattices, and valley polarization in
2D materials. In all cases, the pseudo-spin can be mapped to a Stokes vector on
the Poincar\'e sphere. Stokes polarimeters for measuring the polarization of
light are a powerful tool with a wide range of applications both in classical
and quantum science. Generalizing Stokes polarimetry to other spinor degrees of
freedom is thus a challenge of prime importance. Here, we introduce and
demonstrate a Stokes polarimeter for the sublattice polarization in a bipartite
photonic lattice. Our method relies on k-space photoluminescence intensity
measurements under controlled phase shifts and attenuations applied
independently to each sublattice. We implement our method using honeycomb
arrays of coupled microcavities realizing photonic analogs of graphene and
hexagonal boron nitride. Using our sublattice polarimeter, we reconstruct the
Bloch modes in amplitude and phase across the Brillouin zone, achieving
sub-linewidth precision in the determination of their eigenenergies, including
near band touching points. This enables full access to the system Bloch
Hamiltonian and quantum geometric tensor. Our approach can readily be extended
to more complex systems with additional internal degrees of freedom, enabling
experimental investigations of trigonal warping, Chern insulating phases, and
Euler-class topology in multigap systems.

</details>


### [253] [Flat-band thermodynamics reveals enhanced performance across Otto, Carnot, and Stirling cycles](https://arxiv.org/abs/2507.16525)
*Hadi Mohammed Soufy,Colin Benjamin*

Main category: cond-mat.mes-hall

TL;DR: 本研究使用连续八能带模型分析了魔角扭曲双层石墨烯（MATBG）在三种量子热力学循环（QOC、QCC、QSC）下的性能。结果表明，MATBG在QSC中作为热机表现最佳，在QOC中效率高但功输出较低。作为制冷机，其在QCC中的性能有显著提升。此外，在严格绝热条件下，MATBG在QSC和QOC中均展现出高度可逆的焦耳泵模式。


<details>
  <summary>Details</summary>
Motivation: 研究MATBG在三种不同的量子热力学循环（QOC、QCC、QSC）下的运行相图，并评估其在不同运行模式下的热力学性能，同时与其他石墨烯材料进行比较。

Method: 采用连续八能带模型，对MATBG在量子奥托循环（QOC）、量子卡诺循环（QCC）和量子斯特林循环（QSC）三种不同的量子热力学循环下的性能进行了全面分析，并评估了其在热机、制冷机、冷泵和焦耳泵等多种运行模式下的表现。

Result: MATBG在QSC中作为热机的性能最优，在QOC中效率高但功输出较低。作为制冷机，其在QCC中的表现优于QOC和QSC。在绝热条件下，QSC和QOC中的MATBG表现出高度可逆的焦耳泵模式。

Conclusion: MATBG在QSC中表现出卓越的热机性能，在QOC中效率高但功输出减少。尽管MATBG作为QOC和QSC中的冷泵或制冷机的性能适中，但在QCC中作为制冷机的性能显著提高。此外，在严格绝热条件下，QSC和QOC中的MATBG均表现出高度可逆的焦耳泵模式，凸显了其独特的 खेळThermodynamic行为。

Abstract: Magic-angle twisted bilayer graphene (MATBG) exhibits remarkable electronic
properties under external magnetic fields, notably the emergence of flat Landau
levels. In this study, we present a comprehensive analysis of MATBG's
operational phase diagram under three distinct quantum thermodynamic cycles,
i.e., Quantum Otto Cycle (QOC), Quantum Carnot Cycle (QCC), and Quantum
Stirling Cycle (QSC). Employing the continuum eight-band model, we evaluate the
thermodynamic performance of MATBG across multiple operational modes: heat
engine, refrigerator, cold pump, and Joule pump, and benchmark it against other
graphene systems such as monolayer graphene, AB-Bernal stacked bilayer
graphene, and non-magic-angle twisted bilayer graphene. Our findings reveal
that MATBG demonstrates superior heat engine performance in QSC, while
achieving high efficiency albeit with reduced work output in QOC. Even though
the performance of MATBG as a cold pump or refrigerator is modest in QOC and
QSC, it shows notable improvement as a refrigerator in QCC. Additionally, we
identify a highly reversible Joule pump mode in both QSC and QOC under strict
adiabaticity, underscoring the unique thermodynamic behavior of MATBG.

</details>


### [254] [Asymmetric trions in monolayer transition metal dichalcogenides](https://arxiv.org/abs/2507.16643)
*Arthur Christianen,Atac Imamoglu*

Main category: cond-mat.mes-hall

TL;DR: Exciton-trion peak splitting in 2D semiconductors is influenced by dark excitons, not just trion binding energy. This finding helps explain MoSe2 and WSe2 spectra.


<details>
  <summary>Details</summary>
Motivation: To provide a more complete understanding of exciton and trion peak splitting in the optical spectra of two-dimensional semiconductors.

Method: Theoretical modeling to demonstrate that the commonly interpreted trion binding energy is incomplete due to the influence of dark excitons.

Result: The theoretical model quantitatively explains measured trion energies in MoSe2 and WSe2, highlighting the significance of the exciton's internal structure.

Conclusion: The splitting between exciton and trion peaks is not solely the trion binding energy but also includes the difference between bright and dark exciton binding energies, which is crucial for interpreting optical responses in transition metal dichalcogenides.

Abstract: Exciton spectroscopy serves as a sensitive probe of electronic states in
two-dimensional semiconductors. A prominent feature in optical spectra is the
trion peak arising from the binding of a charge carrier to an exciton. The
splitting between the exciton and trion peaks is usually interpreted as the
trion binding energy, but we theoretically show that this view is incomplete.
Since dark excitons are more strongly bound than the bright exciton, the trion
wave function is asymmetric and a large contribution to the measured splitting
is the difference between the bright and dark exciton binding energies. Our
model quantitatively explains the measured trion energies in MoSe2 and WSe2,
demonstrating the importance of the internal structure of the exciton for the
interpretation of the optical response of transition metal dichalcogenides.

</details>


### [255] [Enhancing far-field thermal radiation by Floquet engineering](https://arxiv.org/abs/2507.16688)
*Huimin Zhu,Yuhua Ren,Hui Pan,Gaomin Tang,Lei Zhang,Jian-Sheng Wang*

Main category: cond-mat.mes-hall

TL;DR: 通过周期性时间调制SiC薄膜，可以实现超越静态材料限制的热辐射，有效桥接近场和远场，实现主动热辐射控制。


<details>
  <summary>Details</summary>
Motivation: 时间调制为超越静态材料限制的定制热辐射提供了一个动态自由度。

Method: 在Floquet非平衡格林函数框架下，研究周期性时间调制SiC薄膜的远场热辐射。

Result: 时间调制能够实现超越平衡热涨落限制的辐射能量传输到远场。这种增强源于调制引起的倏逝表面声子极化激元与传播模式之间的耦合，通过频率转换有效地桥接了能量和动量失配。即使在零温度下，薄膜也会由于调制产生的非平衡光子占据而发出有限的辐射热通量。辐射输出随调制强度的增加而增长，凸显了外部功在驱动远场发射中的作用。

Conclusion: 时间调制为超越静态材料限制的定制热辐射提供了一个动态自由度。研究表明，时间调制能够实现超越平衡热涨落限制的辐射能量传输到远场。这种增强源于调制引起的倏逝表面声子极化激元与传播模式之间的耦合，通过频率转换有效地桥接了能量和动量失配。即使在零温度下，薄膜也会由于调制产生的非平衡光子占据而发出有限的辐射热通量。辐射输出随调制强度的增加而增长，凸显了外部功在驱动远场发射中的作用。这些结果确立了时间调制作为连接近场和远场区域的有效机制，为主动热辐射控制开辟了新途径。

Abstract: Time modulation introduces a dynamic degree of freedom for tailoring thermal
radiation beyond the limits of static materials. Here we investigate far-field
thermal radiation from a periodically time-modulated SiC film under the Floquet
nonequilibrium Green's function framework. We show that time modulation enables
radiative energy transfer into the far field that surpasses the limit imposed
by the equilibrium thermal fluctuations. This enhancement originates from the
modulation-induced coupling between evanescent surface phonon polaritons and
propagating modes, effectively bridging the energy and momentum mismatch
through frequency conversion. Notably, even at zero temperature, the film emits
a finite radiative heat flux due to nonequilibrium photon occupation generated
by the modulation. The radiative output grows with increasing modulation
strength, highlighting the role of external work in driving far-field emission.
These results establish time modulation as an effective mechanism for bridging
near-field and far-field regimes, opening new pathways for active thermal
radiation control.

</details>


### [256] [Dwell-Time Model Simulation Assistance for Advancing Iron 3D Nano-Printing of Via Focused Electron Beam Induced Deposition](https://arxiv.org/abs/2507.16709)
*Sameh Okasha,Stephen McVitie,Trevor P. Almeida*

Main category: cond-mat.mes-hall

TL;DR: 通过改进的FEBID技术，实现了对三维铁纳米结构的精确控制和高效生长，解决了铁基材料生长难题。


<details>
  <summary>Details</summary>
Motivation: FEBID技术在纳米技术领域，特别是向三维结构发展方面日益重要，但铁基FEBID因电子束反应控制困难、生长效率低等问题发展受限。本研究旨在解决这些挑战，推动铁基FEBID在纳米磁性、自旋电子学等领域的应用。

Method: 通过量化蒙特卡洛模拟与实验生长剖面，结合空间驻留时间分辨率图，优化电子束与铁前驱体的反应，实现对复杂三维铁纳米结构的受控电子束诱导沉积（FEBID）。

Result: 成功实现了对复杂三维铁纳米结构的受控FEBID，提高了形状保真度，并通过预测性调整模型参数，实现了跨多个复杂结构的同时生长，这是以往铁基FEBID无法达到的。

Conclusion: 本研究通过量化蒙特卡洛模拟与实验生长剖面，并结合空间驻留时间分辨率图，实现了对复杂三维铁纳米结构的受控电子束诱导沉积（FEBID），提高了铁的生长保真度和多结构生长能力，解决了以往铁基FEBID生长效率低的问题，为纳米磁性、自旋电子学等领域提供了新的技术手段。

Abstract: Focused electron-beam induced deposition (FEBID) has emerged as a powerful
technique for shifting from direct-write fabrication of two- to
three-dimensional nanostructures, which reflects a broader movement across
nanotechnology as a whole. Fields such as nanoelectronics, nanophotonics, and
energy storage and harvesting are poised to benefit from a new generation of
greener, more versatile, and multifunctional technologies enabled by this
transition to 3D structures. The availability of numerous precursors enables
the deposition of a wide range of materials, including metallic, organic,
semiconducting, magnetic, and superconductors. While materials fabricated using
FEBID typically contain significant amounts of impurities, several strategies
have been developed to achieve high purity. These include the synthesis of new
precursors, optimizing growth conditions, introducing reactive gases during the
growth process, and post-deposition purification techniques.Although iron
(Fe)-based deposits are gaining particular interest due to their potential
applications in nanomagnetism and spintronics, FEBID of Fe has not developed
significantly due to several challenges, mainly controlling the e-beam reaction
with Fe precursors which often results in low yield growth due to a slow
dissociation reaction. This work advances the controlled FEBID of complex 3D Fe
nanostructures by further refining the spatial dwell-time resolution map to
print complex structures within nm feature accuracy, through quantitatively
calibrating Monte Carlo simulations with the measured experimental growth
profiles. The methodology, visualized in 3D graphs, enables high shape fidelity
in Fe growth and maintains the ongoing growth across multiple complex
structures through predictive tuning of model parameters based on input
geometry, an outcome that was previously unachievable for Fe.

</details>


<div id='cs.MA'></div>

# cs.MA [[Back]](#toc)

### [257] [COMPASS: Cooperative Multi-Agent Persistent Monitoring using Spatio-Temporal Attention Network](https://arxiv.org/abs/2507.16306)
*Xingjian Zhang,Yizhuo Wang,Guillaume Sartoretti*

Main category: cs.MA

TL;DR: COMPASS是一个多智能体强化学习框架，用于在不确定性下持续监控多个动态目标。


<details>
  <summary>Details</summary>
Motivation: 为了应对在灾难响应、环境传感和野生动物保护等实际应用中，移动智能体需要在不确定性下持续收集动态目标信息的需求。

Method: 提出了一种名为COMPASS的多智能体强化学习（MARL）框架，利用图模型表示环境，并设计了一个共享的时空注意力网络，用于整合历史观测和空间背景。目标动态使用高斯过程（GPs）进行建模，并采用中心化价值估计和去中心化策略执行进行训练。

Result: 所提出的COMPASS框架能够实现去中心化智能体对多个移动目标的高效持续监控。

Conclusion: COMPASS框架在动态多目标场景下，在不确定性降低、目标覆盖率和协调效率方面一致优于强基线。

Abstract: Persistent monitoring of dynamic targets is essential in real-world
applications such as disaster response, environmental sensing, and wildlife
conservation, where mobile agents must continuously gather information under
uncertainty. We propose COMPASS, a multi-agent reinforcement learning (MARL)
framework that enables decentralized agents to persistently monitor multiple
moving targets efficiently. We model the environment as a graph, where nodes
represent spatial locations and edges capture topological proximity, allowing
agents to reason over structured layouts and revisit informative regions as
needed. Each agent independently selects actions based on a shared
spatio-temporal attention network that we design to integrate historical
observations and spatial context. We model target dynamics using Gaussian
Processes (GPs), which support principled belief updates and enable
uncertainty-aware planning. We train COMPASS using centralized value estimation
and decentralized policy execution under an adaptive reward setting. Our
extensive experiments demonstrate that COMPASS consistently outperforms strong
baselines in uncertainty reduction, target coverage, and coordination
efficiency across dynamic multi-target scenarios.

</details>


### [258] [Smooth Games of Configuration in the Linear-Quadratic Setting](https://arxiv.org/abs/2507.16611)
*Jesse Milzman,Jeffrey Mao,Giuseppe Loianno*

Main category: cs.MA

TL;DR: 本研究提出了一种“配置博弈”的概念，用于战略性地调整差分博弈的参数。研究者定义了一个两阶段博弈模型，其中玩家首先选择配置参数，然后根据这些参数进行博弈。文中还提供了一种计算成本梯度和寻找最优配置的方法，并在示例系统中验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 动态博弈论在多主体场景中提供了分析和解决合作与非合作策略的工具，但其最优配置问题尚未得到充分研究。现有文献虽然涉及动态博弈的参数化，但很少从战略角度探讨，即每个代理的配置选择会受到其他代理决策的影响。

Method: 提出了一种配置博弈的概念，将其定义为有限时间、仿射二次（AQ）差分博弈中的一个两阶段博弈。在第一阶段，玩家选择相应的配置参数，这会影响他们在第二阶段的动态和成本。文中给出了子博弈完美解的概念，以及计算配置博弈中第一阶段成本梯度的算法。此外，还提出了一种基于梯度的搜索局部解的方法，并为均衡配置提供了必要条件。

Result: 文中提出了一种用于配置博弈的子博弈完美解概念，以及计算配置博弈成本梯度的算法，并提出了一种基于梯度的搜索方法来寻找局部最优解。此外，还提供了关于其下游（第二阶段）轨迹的均衡配置的必要条件。

Conclusion: 本研究通过在示例AQ系统中演示其有效性，为差分博弈的战略精细调整提供了一个框架。

Abstract: Dynamic game theory offers a toolbox for formalizing and solving for both
cooperative and non-cooperative strategies in multi-agent scenarios. However,
the optimal configuration of such games remains largely unexplored. While there
is existing literature on the parametrization of dynamic games, little research
examines this parametrization from a strategic perspective where each agent's
configuration choice is influenced by the decisions of others. In this work, we
introduce the concept of a game of configuration, providing a framework for the
strategic fine-tuning of differential games. We define a game of configuration
as a two-stage game within the setting of finite-horizon, affine-quadratic, AQ,
differential games. In the first stage, each player chooses their corresponding
configuration parameter, which will impact their dynamics and costs in the
second stage. We provide the subgame perfect solution concept and a method for
computing first stage cost gradients over the configuration space. This then
allows us to formulate a gradient-based method for searching for local
solutions to the configuration game, as well as provide necessary conditions
for equilibrium configurations over their downstream (second stage)
trajectories. We conclude by demonstrating the effectiveness of our approach in
example AQ systems, both zero-sum and general-sum.

</details>


<div id='cond-mat.mtrl-sci'></div>

# cond-mat.mtrl-sci [[Back]](#toc)

### [259] [Electronic structure of SLSiN under charge density modulation](https://arxiv.org/abs/2507.15883)
*Ashkan Shekaari*

Main category: cond-mat.mtrl-sci

TL;DR: 本研究利用第一性原理密度泛函理论计算，研究了单层Si3N4（SLSiN）的电子行为。结果表明，精确控制电荷密度可以驱动SLSiN从绝缘体转变为金属。


<details>
  <summary>Details</summary>
Motivation: 本研究的动机是评估单位晶胞充电如何改变单层Si3N4（SLSiN）的电子行为。

Method: 本研究利用第一性原理密度泛函理论计算，评估了单位晶胞充电如何改变单层Si3N4（SLSiN）的电子行为。系统地调整了每个晶胞的净电荷，范围从n=0（中性/参考构型）到n=±1, ±2, ±3个基本电荷。对于每种带电构型，在PBE水平上评估了能带结构和态密度。

Result: 在中性状态下，SLSiN表现出零电负性，表明其对额外的电子密度不敏感，并且在整合到异质结构中时具有固有的稳定性。研究结果表明，精确控制电荷密度可以驱动SLSiN完成从绝缘体到金属的转变。

Conclusion: 精确控制SLSiN的电荷密度可以驱动其完成从绝缘体到金属的相变。

Abstract: First-principles density-functional theory calculations were carried out to
assess how incremental unit-cell charging alters the electronic behavior of
SLSiN (single-layer Si$_3$N$_4$). The net charge per cell was systematically
tuned from $n\,=\,0$ (the neutral/reference configuration) to
$n\,=\,\pm\,1,\pm\,2$, and $\pm\,3$ elementary charges, and for each charged
configuration the band structure and density of states were evaluated at the
PBE level. In its neutral state, SLSiN exhibits zero electronegativity,
signifying both its indifference to additional electron density and its
intrinsic stability when integrated into heterostructures. Altogether, these
results reveal that precise control of the charge density can drive SLSiN
across an insulator-to-metal transition.

</details>


### [260] [AutoMAT: A Hierarchical Framework for Autonomous Alloy Discovery](https://arxiv.org/abs/2507.16005)
*Penghui Yang,Chendong Zhao,Bijun Tang,Zhonghan Zhang,Xinrun Wang,Yanchen Deng,Yuhao Lu,Cuntai Guan,Zheng Liu,Bo An*

Main category: cond-mat.mtrl-sci

TL;DR: AutoMAT是一个AI驱动的框架，通过整合大型语言模型、自动化模拟和AI搜索，可以快速发现高性能合金，并已在钛合金和高熵合金的研发中取得显著成果。


<details>
  <summary>Details</summary>
Motivation: 为了克服成分设计空间巨大和验证成本高昂的挑战，加速合金设计。

Method: AutoMAT框架整合了大型语言模型、自动化的CALPHAD模拟和AI驱动的搜索，实现了从构思到验证的整个流程的自动化。

Result: AutoMAT发现的钛合金密度降低了8.1%，屈服强度相当，比最先进的参考合金具有更高的比强度。在高熵合金案例中，AutoMAT将屈服强度提高了28.2%。

Conclusion: AutoMAT是一个可扩展且通用的下一代合金设计平台，能在几周内完成通常需要数年的发现时间，在两个案例研究中分别发现了具有高比强度的钛合金和高屈服强度的高熵合金。

Abstract: Alloy discovery is central to advancing modern industry but remains hindered
by the vastness of compositional design space and the costly validation. Here,
we present AutoMAT, a hierarchical and autonomous framework grounded in and
validated by experiments, which integrates large language models, automated
CALPHAD-based simulations, and AI-driven search to accelerate alloy design.
Spanning the entire pipeline from ideation to validation, AutoMAT achieves high
efficiency, accuracy, and interpretability without the need for manually
curated large datasets. In a case study targeting a lightweight, high-strength
alloy, AutoMAT identifies a titanium alloy with 8.1% lower density and
comparable yield strength relative to the state-of-the-art reference, achieving
the highest specific strength among all comparisons. In a second case targeting
high-yield-strength high-entropy alloys, AutoMAT achieves a 28.2% improvement
in yield strength over the base alloy. In both cases, AutoMAT reduces the
discovery timeline from years to weeks, illustrating its potential as a
scalable and versatile platform for next-generation alloy design.

</details>


### [261] [External magnetic field suppression of carbon diffusion in iron](https://arxiv.org/abs/2507.16090)
*Luke J. Wirth,Dallas R. Trinkle*

Main category: cond-mat.mtrl-sci

TL;DR: 磁场通过影响电子态密度和笼形变来降低铁中碳的扩散率。


<details>
  <summary>Details</summary>
Motivation: 解释外部磁场降低 BCC 铁中碳扩散率的物理机制。

Method: 使用包含磁矩的 DFT 计算，并从海森堡模型中采样，计算了高温和磁场下铁中碳的扩散率。

Result: 该模型能够重现实验测得的磁场对扩散率的抑制效应。研究发现，与铁磁情况相比，增加磁性无序会使电子态密度变平，扭曲碳周围的八面体笼，降低扩散激活势垒；而外加磁场则会逆转这些趋势。

Conclusion: 施加磁场可以降低 BCC 铁中碳的扩散率，这是由于磁性无序引起的电子态密度变化，进而影响了围绕碳的八面体笼的畸变，从而降低了扩散激活势垒。施加的磁场可以逆转这些趋势。

Abstract: External magnetic fields reduce diffusion of carbon in BCC iron, but the
physical mechanism is not understood. Using DFT calculations with magnetic
moments sampled from a Heisenberg model, we calculate diffusivities of carbon
in iron at high temperatures and with field. Our model reproduces the measured
suppression of diffusivity from field. We find that increasing magnetic
disorder flattens the electron density of states compared with the
ferromagnetic case, which distorts the octahedral cages around carbon, lowering
the activation barrier to diffusion; an applied field reverses these trends.

</details>


### [262] [Optically Reconfigurable Electrodes for Dielectric Elastomer Actuators](https://arxiv.org/abs/2507.16091)
*Gino Domel,Ehsan Hajiesmaili,David R. Clarke*

Main category: cond-mat.mtrl-sci

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: An optically addressable and configurable electrode architecture for
dielectric elastomer actuators and arrays is described. It is based on
embedding photoconductive, zinc oxide (ZnO) nanowires in the DEA to create
electrodes. Normally, a network of ZnO nanowires is electrically insulating but
it becomes conductive in the presence of UV light with a photon energy above
the optical bandgap. Taking advantage of this characteristic optical induced
switching behavior, we create an optically addressable electrode design, and
create new, localized capacitor structures. As the ZnO nanowires are only
conductive where, and when, illuminated the effective electrode structure is
not fixed, as is the case with CNT and carbon-black electrodes currently used
in DEAs. This provides greater, previously unattainable, freedom in the design
of dielectric elastomer actuators for soft robotics and devices.

</details>


### [263] [Observation of a phase transition in KTaO$_3$ induced by residual niobium impurities](https://arxiv.org/abs/2507.16093)
*Zijun C. Zhao,Jeremy F. Bourhill,Maxim Goryachev,Aleksey Sadekov,Michael E. Tobar*

Main category: cond-mat.mtrl-sci

TL;DR: KTaO3晶体在低温（约134 K）下因铌杂质（约7%）发生了顺电-铁电相变，表现为介电常数的变化。该发现对可调谐器件设计具有实际意义。


<details>
  <summary>Details</summary>
Motivation: 研究KTaO3晶体在低温下的相变行为，并探究引起该相变的因素及其对可调谐器件设计的影响。

Method: 通过将KTaO3晶体置于铜腔内形成介电加载微波腔，并使用激光烧蚀电感耦合等离子体质谱法（LA-ICPMS）进行杂质分析，观察并研究了近134 K处的介电常数变化和相变行为。

Result: 观察到KTaO3晶体在约134 K时发生由顺电向铁电的相变。该相变由约7%的铌杂质驱动，导致介电常数在相变温度附近发生变化。铌含量较低（<2%）的类似晶体未发生相变，但在该温度下表现出损耗峰。

Conclusion: KTaO3晶体中观察到的相变是由铌杂质引起的，这表明了杂质对铁电性质的影响，并对可调谐器件的设计具有实际意义。

Abstract: We report the observation of a phase transition in a KTaO$_3$ crystal,
corresponding to a paraelectric-to-ferroelectric transition. The crystal was
placed inside a copper cavity to form a dielectric-loaded microwave cavity, and
the transition was observed to occur near 134 K. As the cavity was cooled, the
frequencies of both transverse electric and transverse magnetic resonant modes
decreased (corresponding to an increase in permittivity). The mode frequencies
converge at the transition temperature (near 134 K) and, below this point,
reverse their tuning direction, increasing their frequency with decreasing
temperature. This behaviour corresponds to a decrease in dielectric
permittivity and is atypical for pure KTaO$_3$. To investigate further, we
conducted impurity analysis using Laser Ablation inductively coupled mass
spectrometry (LA-ICPMS), revealing a significant concentration ($\sim$ 7\%) of
niobium (Nb) in the crystal. This suggests that the observed phase transition
is driven by residual Nb impurities, which induce ferroelectricity in an
otherwise paraelectric host. Similar crystals with a lower concentration ($<$
2\%) did not undergo a phase transition but exhibited a loss peak at this
temperature. These findings have practical implications for the design of
tunable devices, for example, resonator-based dark matter detectors, where
low-loss material phase stability and tunability are crucial.

</details>


### [264] [Unveiling two-dimensional electron systems on ultra-wide bandgap semiconductor $\mathrmβ$-Ga$_2$O$_3$](https://arxiv.org/abs/2507.16137)
*Ryu Yukawa,Hiroshi Mizuseki,Suryo Santoso Putro,Yé-Jin L. Lee,Yuuki Masutake,Hinako Telengut,Boxuan Li,Hajime Yamamoto,Tadashi Abukawa,Junya Yoshida,Vladimir V. Kochurikhin,Taketoshi Tomida,Masanori Kitahara,Takahiko Horiai,Akira Yoshikawa,Nobuhiko Sarukura,Noriko Chikumoto,Toshihiko Shimizu,Marilou Cadatal-Raduban,Yoshiyuki Kawazoe,Ryuhei Kohno,Hiroshi Kumigashira,Takuto Nakamura,Tatsuhiko Kanda,Akira Yasui,Miho Kitamura,Hideaki Iwasawa,Koji Horiba,Kenichi Ozawa*

Main category: cond-mat.mtrl-sci

TL;DR: 该研究首次通过ARPES观测了$eta$-Ga$_2$O$_3$的二维电子系统，揭示了其独特的电子结构和载流子密度相关的有效质量反常增加现象，为UWBG材料在量子和电力器件中的应用提供了新思路。


<details>
  <summary>Details</summary>
Motivation: 超宽带隙（UWBG）半导体在电力电子领域具有巨大潜力，但对其界面电子结构的理解因缺乏直接的实验观测而受阻。

Method: 利用高纯度$eta$-Ga$_2$O$_3$单晶的角分辨光电子能谱（ARPES）进行首次动量分辨的超宽带隙（UWBG）材料二维电子系统观测。

Result: 首次实现了在UWBG材料上的动量分辨观测，通过碱金属诱导电子掺杂形成了各向同性的圆形费米面，载流子密度最高达$1.0	imes10^{14}$ $\mathrm{cm}^{-2}$。计算表明电子被限制在表面1.2 nm范围内，内部电场高达$18$ MV $\mathrm{cm}^{-1}$。随着载流子密度增加，有效质量异常地增加近一倍，达到0.48 $\textit{m}_{\mathrm{e}}$，这与其他氧化物半导体报道的趋势相反。

Conclusion: 研究为$eta$-Ga$_2$O$_3$建立了界面电子结构，并证明了超宽带隙材料为探索载流子密度驱动的电子现象提供了肥沃的土壤，为未来的量子和电力器件开辟了新途径。

Abstract: Ultra-wide bandgap (UWBG) semiconductors promise to revolutionize power
electronics, yet a fundamental understanding of their interfacial electronic
structure has been hindered by the absence of direct experimental observation.
Here, we report the first momentum-resolved observation of two-dimensional
electron systems on a UWBG material, enabled by angle resolved photoemission
spectroscopy (ARPES) on high-purity $\beta$-Ga$_2$O$_3$ single crystals.
Alkaline-metal-induced electron doping forms an isotropic circular Fermi
surface, achieving a sheet carrier density of up to $1.0\times10^{14}$
$\mathrm{cm}^{-2}$. Self-consistent Poisson-Schr\"odinger calculations show
that the electrons are confined within 1.2 nm of the surface and reveal an
internal electric field of $18$ MV cm$^{-1}$. Crucially, our measurements
reveal a pronounced renormalization of the electronic band structure: a series
of carrier-density-dependent ARPES measurements shows that as the carrier
density increases from $2\times10^{13}$ to $1.0\times10^{14}$
$\mathrm{cm}^{-2}$, the effective mass anomalously increases, nearly doubling
to a final value of 0.48 $\textit{m}_{\mathrm{e}}$. This trend is notably
opposite to that reported for other oxide semiconductors, pointing towards a
unique renormalization mechanism in $\beta$-Ga$_2$O$_3$. Our findings establish
the interfacial electronic structure of $\beta$-Ga$_2$O$_3$ and demonstrate
that UWBG materials provide fertile ground for exploring carrier-density-driven
electronic phenomena, opening new avenues for future quantum and power devices.

</details>


### [265] [Nd3+ Doping-induced Leakage Currents Suppression in High-temperature 0.7BiFeO3-0.3BaTiO3 Lead-free Piezoceramics](https://arxiv.org/abs/2507.16156)
*Jinming Liu,Mingtong Chen,Zhengbao Yang*

Main category: cond-mat.mtrl-sci

TL;DR: 通过掺杂Nd3+成功解决了BiFeO3-BaTiO3压电陶瓷的高温漏电流问题，显著提高了其高温下的稳定性和压电性能，有望在高温度传感器和执行器领域得到应用。


<details>
  <summary>Details</summary>
Motivation: BiFeO3（铋铁氧体）作为一种潜在的无铅压电材料，因其高居维温度和自发极化而备受关注，但其固有的高漏电流限制了其实际应用。

Method: 制备了0.7BiFeO3-0.3BaTiO3（BF-BT）体系的无铅压电陶瓷，并通过引入Nd3+来调节其微观结构和高温电学性能。

Result: 与未掺杂的陶瓷相比，Nd3+掺杂样品在75°C以上能够显著抑制漏电流（降低超过99%），漏电流密度低至10^-5 Acm^-2，同时提高了高温和强电场下的电阻率，展现出更好的热稳定性。此外，Nd3+掺杂样品在室温下获得了高达172 pC N^-1的压电系数，并在高温下仍保持了较高的介电和压电响应。

Conclusion: 研究结果表明，适量掺杂Nd3+可以改善BiFeO3-BaTiO3陶瓷的压电性能，特别是在高温下的稳定性和漏电流问题，为开发无铅压电材料在高温度传感器和执行器方面的应用提供了新的策略。

Abstract: BiFeO3 has attracted much attention as a potential candidate for replacing
conventional, lead based piezoelectric materials due to its remarkable
spontaneous polarization and high Curie temperature. However, its inherent high
leakage currents, which lead to low piezoelectric response and poor temperature
stability, have severely limited its practical applications. In this study,
lead free piezoelectric ceramics of the 0.7BiFeO3-0.3BaTiO3 (BF-BT) system were
prepared, and their microstructures along with high-temperature electrical
performance were modulated by introducing Nd3+. The results indicate that
moderate Nd doping improves lattice symmetry and reduces oxygen vacancy-related
defect dipoles, thereby effectively suppressing leakage currents at
temperatures above 75{\deg}C. The Nddoped samples exhibit significantly lower
leakage current densities, reduced by over 99% compared to the undoped
ceramics, reaching values as low as 10-5Acm-2. They also show higher
resistivity under elevated temperatures and electric fields, offering notable
improvements in thermal stability over the undoped counterparts. In addition,
the Nd-doped samples achieved piezoelectric coefficients as high as 172 pC N -1
at room temperature while still maintaining high dielectric and piezoelectric
responses at elevated temperatures. This work not only provides an effective
way to solve the leakage current problem of BF-BT ceramics in high temperature
applications but also indicates a new design strategy for optimizing the high
temperature stability of lead free piezoelectric materials, which shows a broad
application prospect in the field of high-temperature sensors and actuators.

</details>


### [266] [Origin of Suppressed Ferroelectricity in k-Ga$_2$O$_3$: Interplay Between Polarization and Lattice Domain Walls](https://arxiv.org/abs/2507.16167)
*Yonghao Zhu,Zhi Wang,Junwei Luo,Lin-Wang Wang*

Main category: cond-mat.mtrl-sci

TL;DR: 机器学习用于研究k相氧化镓(Ga2O3)铁电材料，发现畴壁相互作用机制可解释实验与理论的差异，为调控铁电响应提供了新思路。


<details>
  <summary>Details</summary>
Motivation: 为了解决宽禁带铁电材料实验与理论预测的残留极化和矫顽场存在巨大差异，限制其应用的问题。

Method: 利用基于第一性原理分子动力学数据的机器学习势能，研究了k相氧化镓(Ga2O3)中的极化畴壁(PDW)与晶格畴壁(LDW)的相互作用机制。

Result: 研究发现，k相氧化镓(Ga2O3)中面外极化反转是通过Ga-O子层的面内滑动和剪切实现的，这导致了PDW传播的强各向异性，并使得PDW能够跨越120度LDW。由此产生的稳定畴壁网络抑制了迟滞反转和矫顽场。

Conclusion: 本研究揭示了k相氧化镓(Ga2O3)铁电材料中极化畴壁(PDW)与晶格畴壁(LDW)相互作用的新机制，通过机器学习势能解释了实验与理论预测之间的差异，并指出了通过晶格畴工程调控铁电响应的潜力。

Abstract: The large discrepancy between experimental and theoretical remanent
polarization and coercive field limits the applications of wide-band-gap
ferroelectric materials. Here, using a machine-learning potential trained on
ab-initio molecular dynamics data, we identify a new mechanism of the interplay
between polarization domain wall (PDW) and lattice domain wall (LDW) in
ferroelectric k-phase gallium oxide (Ga2O3), which reconciles predictions with
experimental observations. Our results reveal that the reversal of out-of-plane
polarization is achieved through in-plane sliding and shear of the Ga-O
sublayers. This pathway creates strong anisotropy in PDW propagation, and
crucially leads to topologically forbidden PDW propagation across the 120
degree LDWs observed in synthesized samples. The resulting stable network of
residual domain walls bypasses slow nucleation and suppresses the observable
polarization and coercive field. These insights highlight the potential for
tailoring the ferroelectric response in k-Ga2O3 from lattice-domain
engineering.

</details>


### [267] [Stability by Design: Atomistic Insights into Hydrolysis-Driven MOF Degradation](https://arxiv.org/abs/2507.16197)
*Ashok Yacham,Tarak K. Patra,Jithin John Varghese,Richa Sharma*

Main category: cond-mat.mtrl-sci

TL;DR: 本研究使用反应分子动力学评估了七种常见锌基金属有机框架（MOFs）在潮湿条件下的稳定性，发现沸石咪唑酸盐框架（ZIFs）比异质金属有机框架（IRMOFs）更稳定，稳定性与连接体的尺寸和化学性质有关。


<details>
  <summary>Details</summary>
Motivation: 金属有机框架（MOFs）因其高比表面积和可调的孔隙率，在CO2捕获方面显示出巨大潜力。然而，其在潮湿条件下的稳定性和有效性尚不完全清楚，这限制了它们的商业化应用。因此，本研究旨在探究MOFs在含水环境中的稳定性，以期为开发更稳定的碳捕获材料提供指导。

Method: 本研究采用反应分子动力学（MD）结合元动力学采样方法，评估了七种常见的锌基金属有机框架（MOFs）在模拟的低浓度水分条件下的水解稳定性，并计算了其水合自由能面（FESs）。此外，还尝试将水合能垒与MOFs的理化描述符进行关联分析。

Result: 研究结果显示，MOFs的水稳定性与其连接体的尺寸和化学性质密切相关。沸石咪唑酸盐框架（ZIFs）相比于异质金属有机框架（IRMOFs）表现出更高的水稳定性。研究还初步建立了水合能垒与MOFs理化描述符之间的关联。

Conclusion: 本研究通过反应分子动力学和元动力学采样，评估了七种常见的锌基金属有机框架（MOFs）在模拟的低浓度水分条件下的水解稳定性，并试图将水解能垒与MOFs的理化描述符相关联。研究结果表明，沸石咪唑酸盐框架（ZIFs）比异质金属有机框架（IRMOFs）具有更高的水稳定性，且稳定性与连接体的尺寸和化学性质密切相关。这些发现为了开发更稳定的用于碳捕获技术的吸附材料提供了重要的基础性见解。

Abstract: Metal-organic frameworks (MOFs) are porous materials formed by interconnected
metal atoms via organic linkers, resulting in high surface area and tuneable
porosity, making them exceptional candidates for CO2 capture. However, their
stability and efficacy in humid conditions are not fully understood, often
limiting their commercial applications. Here, we estimate the stability of
seven common Zn-based MOFs using reactive molecular dynamics (MD) along with
metadynamics sampling to determine hydrolysis energetics at conditions
representative of low water concentration limit. The reactions' free energy
surfaces (FESs) showed that water stability strongly depends on its linker size
and chemistry. Our findings indicate zeolitic imidazolate frameworks (ZIFs), a
subclass of MOFs, exhibit higher water stability than iso-reticular
metal-organic frameworks (IRMOFs). We further attempt to correlate hydrolysis
energy barrier with the physicochemical descriptors of these MOFs. This study
provides insights into the critical factors and fundamental implications for
developing stable porous materials for carbon capture technologies.

</details>


### [268] [Elucidating the impact of point defects on the structural, electronic, and mechanical behaviour of chromium nitride](https://arxiv.org/abs/2507.16312)
*Barsha Bhattacharjee,Emilia Olsson*

Main category: cond-mat.mtrl-sci

TL;DR: CrN2因含有缺陷而性能下降，而CrN则能很好地屏蔽缺陷，但氢会使其性能下降，氧则会提高其硬度。


<details>
  <summary>Details</summary>
Motivation: 过渡金属氮化物，如CrN，因其机械弹性而被广泛使用，但其富氮类似物CrN2的理解仍然不足，特别是在原子尺度上。本研究旨在解决这一问题。

Method: 本研究采用密度泛函理论研究了CrN2的固有缺陷（空位、间隙原子和反位原子）以及外在杂质（氢和氧）对CrN2结构、电子、磁和机械响应的影响，并与研究更多的CrN进行了比较。

Result: CrN2具有方向性的N-N键合和半导体特性，对缺陷的掺入高度敏感。CrN具有金属特性，能够有效屏蔽缺陷。

Conclusion: CrN2对缺陷的掺入高度敏感，导致局部自旋极化、能隙态和机械软化，而CrN的金属特性使其能够有效屏蔽类似的缺陷，保持其结构、磁性、电子和机械完整性。然而，氢会引起CrN的各向异性畸变和机械退化，而氧则会提高硬度。这些发现揭示了缺陷化学和键合各向异性如何控制机械性能，并对涂层设计中的纳米级控制具有启示意义。

Abstract: Defect engineering offers an important route to property tuning of
nanostructured coatings for advanced applications. Transition metal nitrides,
such as CrN, are widely used for their mechanical resilience, but their
nitrogen-rich analogue CrN2 remains poorly understood, especially at the atomic
scale. This study employs density functional theory to investigate the
energetics as well as how intrinsic defects (vacancies, interstitials, and
anti-sites) and extrinsic impurities (hydrogen and oxygen) influence the
structural, electronic, magnetic, and mechanical response of CrN2, in
comparison to the more commonly studied CrN. With directional N-N bonding and
semiconducting character, CrN2 shows high sensitivity to defect incorporation,
including local spin polarisation, gap states, and mechanical softening. In
contrast, CrN's metallic character enables effective screening of similar
defects, preserving its structural, magnetic, electronic and mechanical
integrity. However, hydrogen induces anisotropic distortions and mechanical
degradation in CrN, while oxygen enhances hardness. These findings reveal how
defect chemistry and bonding anisotropy govern mechanical performance, with
implications for nanoscale control in coatings design.

</details>


### [269] [Constructing material network representations for intelligent amorphous alloys design](https://arxiv.org/abs/2507.16336)
*S. -Y. Zhang,J. Tian,S. -L. Liu,H. -M. Zhang,H. -Y. Bai,Y. -C. Hu,W. -H. Wang*

Main category: cond-mat.mtrl-sci

TL;DR: 通过构建材料网络来加速非晶态合金的发现，并展示了其在指导新合金设计方面的潜力。


<details>
  <summary>Details</summary>
Motivation: 设计高性能非晶态合金过程依赖于经验法则和无限尝试，成本高、效率低，阻碍了在巨大的材料空间中进行有效采样。

Method: 提出材料网络来加速二元和三元非晶态合金的发现。通过审查不同年份合成的非晶态合金，构建动态材料网络来追踪合金发现的历史。

Result: 网络拓扑揭示了隐藏的材料候选物；动态材料网络追踪合金发现的历史，并发现过去设计的一些创新材料被编码在网络中，展示了其在指导新合金设计方面的预测能力。这些材料网络与现实世界中的一些网络显示出物理相似性。 

Conclusion: 该研究提出的材料网络为智能材料设计，特别是复杂合金的设计开辟了新途径。

Abstract: Designing high-performance amorphous alloys is demanding for various
applications. But this process intensively relies on empirical laws and
unlimited attempts. The high-cost and low-efficiency nature of the traditional
strategies prevents effective sampling in the enormous material space. Here, we
propose material networks to accelerate the discovery of binary and ternary
amorphous alloys. The network topologies reveal hidden material candidates that
were obscured by traditional tabular data representations. By scrutinizing the
amorphous alloys synthesized in different years, we construct dynamical
material networks to track the history of the alloy discovery. We find that
some innovative materials designed in the past were encoded in the networks,
demonstrating their predictive power in guiding new alloy design. These
material networks show physical similarities with several real-world networks
in our daily lives. Our findings pave a new way for intelligent materials
design, especially for complex alloys.

</details>


### [270] [Interstitially bridged van der Waals interface enabling stacking-fault-free, layer-by-layer epitaxy](https://arxiv.org/abs/2507.16361)
*GunWoo Yoo,TaeJoon Mo,Yong-Sung Kim,Chang-Won Choi,Gunho Moon,Sumin Lee,Chan-Cuk Hwang,Woo-Ju Lee,Min-Yeong Choi,Jongyun Choi,Si-Young Choi,Moon-Ho Jo,Cheol-Joo Kim*

Main category: cond-mat.mtrl-sci

TL;DR: 通过引入Mo间隙物，我们成功外延生长了稳定的单晶六方双层MoS2，解决了vdW晶体的层间错配问题。


<details>
  <summary>Details</summary>
Motivation: 为了解决范德华力（vdW）晶体（如MoS2）因层间相互作用弱而易发生扭曲、滑动和屈曲的问题，以及在合成无堆垛层错的多层结构时面临的挑战。

Method: 通过在层层沉积过程中引入Mo间隙物，促进了MoS2的择优外延生长，并利用原子分辨率分析和密度泛函理论计算验证了Mo间隙物在稳定晶格结构和促进六方双层相形成中的作用。

Result: 成功外延生长了单晶六方双层MoS2，其结构具有优异的稳定性，即使在转移后也能保持晶体完整性，并抑制了层间旋转和翻译错配。Mo间隙物位于六方晶格的单一亚晶格位点，与上下两层MoS2形成四面体键，从而锚定了层间配位，并作为成核中心促进了六方双层相的选择性形成。

Conclusion: 本研究提出了一种通过在层间引入Mo间隙物来外延生长单晶六方双层MoS2的方法，有效解决了vdW晶体中堆垛层错和层间错配的问题，并增强了层间耦合，为精确控制堆垛顺序和生长多层vdW晶体提供了稳健的策略。

Abstract: Van der Waals (vdW) crystals are prone to twisting, sliding, and buckling due
to inherently weak interlayer interactions. While thickness-controlled vdW
structures have attracted considerable attention as ultrathin semiconducting
channels, the deterministic synthesis of stacking-fault-free multilayers
remains a persistent challenge. Here, we report the epitaxial growth of
single-crystalline hexagonal bilayer MoS<sub>2</sub>, enabled by the
incorporation of Mo interstitials between layers during layer-by-layer
deposition. The resulting bilayers exhibit exceptional structural robustness,
maintaining their crystallinity and suppressing both rotational and
translational interlayer misalignments even after transfer processes.
Atomic-resolution analysis reveals that the Mo interstitials are located at a
single sublattice site within the hexagonal lattice, where they form
tetrahedral bonds with sulfur atoms from both MoS<sub>2</sub> layers,
effectively anchoring the interlayer registry. Density functional theory
calculations further indicate that these Mo atoms act as nucleation centers,
promoting the selective formation of the hexagonal bilayer phase. This approach
offers a robust strategy for the deterministic growth of multilayer vdW
crystals with precisely controlled stacking order and enhanced interlayer
coupling.

</details>


### [271] [Giant magneto-cubic in-plane Hall effect in a nonmagnetic material](https://arxiv.org/abs/2507.16544)
*Jie Chen,Jin Cao,Yue Lu,Hang Li,Xiaodong Zhou,Xuekui Xi,Orest Pavlosiuk,Piotr Wiśniewski,Dariusz Kaczorowski,Yong-Chang Lau,Cong Xiao,Yue Li,Yong Jiang,Wenhong Wang,Shengyuan A. Yang*

Main category: cond-mat.mtrl-sci

TL;DR: 在非磁性材料 LuAuSn 中发现了具有里程碑意义的巨大平面霍尔效应，这得益于杂质和声子散射，为实际应用开辟了道路。


<details>
  <summary>Details</summary>
Motivation: 填补在非磁性材料中观察到巨大平面霍尔效应的空白，并验证了长期存在的关于磁立方平面霍尔效应的理论预测。

Method: 通过实验和第一性原理计算，研究了非磁性半赫斯勒化合物 LuAuSn 中的平面霍尔效应。重点关注了由杂质和声子散射引起的外部侧跳和偏斜散射过程。

Result: 在非磁性半赫斯勒化合物 LuAuSn 中观察到巨大的平面霍尔效应，其幅度超过了所有先前报道的值。观察到了平面霍尔效应的 π 周期性以及与磁场呈立方关系的依赖性，从而在一种意想不到的材料中实现了在三重旋转对称性下的磁立方平面霍尔效应的理论预测。通过标度律分析和第一性原理计算表明，由杂质和声子散射引起的外部侧跳和偏斜散射过程是观察到的效应的主要原因。

Conclusion: 该研究揭示了一种新型磁非线性平面霍尔效应，其特点是具有前所未有的巨大效应和宽温度范围运行，有望实现平面霍尔效应的实际应用。

Abstract: In-plane Hall effect (IPHE) triggered by an external magnetic field applied
in the transport plane has attracted significant experimental attentions in
recent few years 1-6. However, most experiments focus on magnetic materials,
where the existence of magnetic ordering may complicate understanding the
physics behind, and the relatively small signal magnitudes limit the
application of the effect. Here, we report a giant IPHE in a nonmagnetic
half-Heusler compound LuAuSn, with a magnitude exceeding all the previously
reported values. A -period of IPHE and the consistent cubic dependence on the
magnetic field are observed, realizing the long-sought theoretical prediction
of magneto-cubic IPHE under threefold rotational symmetry7-9 in an unexpected
material. The scaling law analysis and first-principles calculations indicate
that extrinsic side jump and skew scattering processes from both impurity and
phonon scatterings dominate the observed effect. These findings unravel a new
type of magneto-nonlinear IPHE, and its large magnitude and wide-temperature
operation may open the door to practical applications of IPHE.

</details>


### [272] [Microstructure of Silicon Anodes in Solid-State Batteries -- From Crystalline to Amorphous](https://arxiv.org/abs/2507.16561)
*Shamail Ahmed,Federico Rossi,Hanyu Huo,Johannes Haust,Franziska Hueppe,Juergen Belz,Andreas Beyer,Juergen Janek,Kerstin Volz*

Main category: cond-mat.mtrl-sci

TL;DR: 硅负极材料在锂离子电池中虽有潜力，但体积膨胀易导致开裂。本研究利用低温STEM技术揭示了微晶硅电极在循环过程中的微观结构演变，发现其微观结构在多次循环后趋于稳定。为改善电极性能，需仔细选择起始材料并优化电极结构以稳定微观结构。


<details>
  <summary>Details</summary>
Motivation: 为了解决硅负极材料在锂化过程中体积膨胀严重（约300%）导致脱锂时开裂的问题，从而实现其在全固态锂离子电池中的实际应用。

Method: 本研究采用低温扫描透射电子显微镜（STEM）在无固体电解质的环境下，对微晶硅电极在电化学循环过程中的微观结构演变进行了研究。

Result: 研究发现，首次锂化后，电极呈现出结晶态Li15Si4、各种无定形态LixSi相和残留结晶硅的混合物。脱锂后，结构主要变为无定形态，并出现线状特征，结晶度极低。经过10次脱锂后，微观结构更加均匀，线状区域主要存在于晶界。研究结果揭示，从结晶相开始，体硅仅在几次循环后才出现稳定的微观结构。

Conclusion: 本研究表明，通过仔细选择起始材料和优化电极结构，可以稳定硅基负极材料的微观结构，从而控制电极行为并减少开裂，使其在全固态锂离子电池中得到实际应用。

Abstract: Silicon offers great promise as a potential anode active material and the
optimum alternative to lithium metal in all-solid-state lithium-ion batteries.
However, its practical application is limited by severe volume expansion
(~300%) during lithiation, leading to cracking upon delithiation. In this
study, we investigated the microstructural evolution of microcrystalline
silicon electrodes in a solid-electrolyte-free environment using cryogenic
scanning transmission electron microscopy (STEM) during electrochemical
cycling. A controlled workflow prevents ambient exposure, and cryo-TEM ensures
structural integrity. After the first lithiation, the electrode shows a
heterogeneous mix of crystalline Li15Si4, various amorphous LixSi phases, and
residual crystalline silicon. After delithiation, the structure becomes
predominantly amorphous with thread-like features and minimal remaining
crystallinity. By the 10th delithiation, the microstructure is more uniform,
with thread-like regions mainly at grain boundaries. Our results reveal that
starting from a crystalline phase, a stationary microstructure emerges in bulk
silicon only after several cycles. Thus, to have a more controlled behavior of
the electrode and minimize cracking, the starting material should be carefully
chosen along with an optimized electrode architecture to help stabilize the
microstructure throughout cycling.

</details>


### [273] [Wrinkle Mediated Phase Transitions in In$_2$Se$_3$](https://arxiv.org/abs/2507.16706)
*Joseph L. Spellberg,Lina Kodaimati,Atreyie Ghosh,Prakriti P. Joshi,Sarah B. King*

Main category: cond-mat.mtrl-sci

TL;DR: 通过激光诱导起皱和热退火，实现了室温下二维硒化铟（In$_{2}$Se$_{3}$）的可控相变和铁性状态操纵，为铁性器件和相变内存技术提供了新途径。


<details>
  <summary>Details</summary>
Motivation: 二维材料中的晶体相变在电子和铁性应用中具有吸引力，但可靠地在不同相之间进行可逆切换仍然具有挑战性。

Method: 通过激光诱导的起皱来实现二维硒化铟（In$_{2}$Se$_{3}$）的$eta^{'}ightarrow	ext{ 2}$相变，结合热退火进行相恢复，无需低温步骤或机械扰动。

Result: 成功实现了二维硒化铟（In$_{2}$Se$_{3}$）在室温下通过激光诱导起皱进行$eta^{'}ightarrow	ext{ 2}$相变，并结合热退火进行相恢复，从而操纵铁性状态，并生成多相异质结构和进行畴重组。

Conclusion: 这项研究表明，通过激光诱导的起皱，可以在二维硒化铟（In$_{2}$Se$_{3}$）中实现可控的$eta^{

Abstract: Crystalline phase transitions in two-dimensional materials enable precise
control over electronic and ferroic properties, making them attractive
materials for memory and energy storage applications. In$_2$Se$_3$ is
particularly promising because its $\alpha$ and $\beta'$ phases are both stable
at room temperature but exhibit distinct ferroic behaviors. However, achieving
reliable reversible switching between these states remains challenging. Here,
we show that controlled $\beta'\rightarrow\alpha$ phase transitions in 2D
In$_2$Se$_3$ become accessible through laser-induced wrinkling, establishing a
room-temperature approach for manipulating ferroic states in In$_2$Se$_3$ thin
films. Combined with thermal annealing for phase recovery, this approach
eliminates cryogenic steps and mechanical perturbation while harnessing
accumulated internal strain to generate multiphase heterostructures and direct
domain reorganization. This pathway for phase transitions in In$_2$Se$_3$ opens
the door for further development in ferroic device architectures and
phase-change memory technologies.

</details>


### [274] [Chemical Treatment-Induced Indirect-to-Direct Bandgap Transition in MoS2: Impact on Optical Properties](https://arxiv.org/abs/2507.16574)
*Yusuf Kerem Bostan,Elanur Hut,Cem Sanga,Nadire Nayir,Ayse Erol,Yue Wang,Fahrettin Sarcan*

Main category: cond-mat.mtrl-sci

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: The unique electrical and optical properties of emerging two-dimensional
transition metal dichal-cogenides (TMDs) present compelling advantages over
conventional semiconductors, including Si, Ge, and GaAs. Nevertheless,
realising the full potential of TMDs in electronic and optoelectronic devices,
such as transistors, light-emitting diodes (LEDs), and photodetectors, is
con-strained by high contact resistance. This limitation arises from their low
intrinsic carrier concen-trations and the current insufficiency of doping
strategies for atomically thin materials. Notably, chemical treatment with
1,2-dichloroethane (DCE) has been demonstrated as an effective post-growth
method to enhance the n-type electrical conductivity of TMDs. Despite the
well-documented electrical improvements post-DCE treatment, its effects on
optical properties, specifically the retention of optical characteristics and
excitonic behaviour, are not yet clearly under-stood. Here, we systematically
investigate the layer- and time-dependent optical effects of DCE on molybdenum
disulfide (MoS2) using photoluminescence (PL) spectroscopy and Density
Functional Theory (DFT) simulations. Our PL results reveal a rapid reduction in
the indirect bandgap transition, with the direct transition remaining
unaffected. DFT confirms that chlorine (Cl) atoms bind to sulphur vacancies,
creating mid-gap states that facilitate non-radiative recom-bination,
explaining the observed indirect PL suppression. This work demonstrates DCE's
utility not only for n-type doping but also for optical band structure
engineering in MoS2 by selec-tively suppressing indirect transitions,
potentially opening new avenues for 2D optoelectronic device design.

</details>


### [275] [Thermodynamic modeling of binaries in Cr-Fe-Mo-Nb-Ni supported by first-principles calculations](https://arxiv.org/abs/2507.16627)
*Hui Sun,Shun-Li Shang,Shuang Lin,Jingjing Li,Allison M. Beese,Zi-Kui Liu*

Main category: cond-mat.mtrl-sci

TL;DR: 改进了Cr-Fe-Mo-Nb-Ni系统中二元系统的热力学描述，特别是TCP相，以支持材料设计。


<details>
  <summary>Details</summary>
Motivation: 提供Cr-Fe-Mo-Nb-Ni系统中所有二元系统的热力学描述，特别是改进TCP相的描述，以支持CALPHAD建模和材料设计。

Method: 对Cr-Fe-Mo-Nb-Ni系统中的所有二元系统进行了热力学描述，并在必要时进行了重新建模。特别是，使用基于其Wyckoff位置的﹑sigma和mu等拓扑密排（TCP）相的综合亚晶格模型，对Cr-Fe和Fe-Mo系统进行了重新建模。这些改进得到了基于密度泛函理论（DFT）的从头算计算以及文献中可用实验数据的支持。

Result: 所得到的模型提高了描述TCP相的准确性。例如，Cr-Fe中sigma相的预测位Occupancy与实验观察结果高度一致。

Conclusion: 该工作为CALPHAD建模和设计复杂多组分材料（特别是基于Fe和Ni的合金）提供了坚实的基础。

Abstract: Thermodynamic descriptions of all binaries within the Cr-Fe-Mo-Nb-Ni system
have been complied and, where necessary, remodeled. Notably, the Cr-Fe and
Fe-Mo systems have been remodeled using comprehensive sublattice models for the
topologically close-packed (TCP) phases of Laves_C14, sigma, and mu according
to their Wyckoff positions. These refinements are supported by first-principles
calculations based on density functional theory (DFT), in conjunction with
available experimental data in the literature. The resulting models offer
improved accuracy in describing the TCP phases. For instance, the predicted
site occupancies of sigma in Cr-Fe show excellent agreement with experimental
observations. The present work provides a robust foundation for CALPHAD
modeling and the design of complex, multi-component materials, particularly
those based on Fe-based and Ni-based alloys.

</details>


### [276] [Ultrafast X-ray sonography reveals the spatial heterogeneity of the laser-induced magneto-structural phase transition in FeRh](https://arxiv.org/abs/2507.16638)
*Maximilian Mattern,Angel Rodriguez-Fernandez,Roman Shayduk,Jon Ander Arregi,Vojtěch Uhlíř,Ulrike Boesenberg,Jörg Hallmann,Wonhyuk Jo,Aliaksandr Leonau,Rustam Rysov,James Wrigley,Alexey Zozulya,Stefan Eisebitt,Anders Madsen,Daniel Schick,Jan-Etienne Pudell*

Main category: cond-mat.mtrl-sci

TL;DR: 提出了一种新的超快X射线声学技术，用于在高时空分辨率下研究相变。该技术已成功应用于 FeRh 的磁结构相变，揭示了其形核和生长机制。


<details>
  <summary>Details</summary>
Motivation: 尽管超快技术可以在飞秒时间尺度上跟踪相变，但这些过程的空间复杂性和随机性通常仍然难以捉摸。

Method: 通过将超快硬X射线衍射与传播应变脉冲相结合，提出了一种超快X射线声学方法，该方法能够以高时空分辨率解析相特异性应变响应，从而捕获相变的时空异质性。

Result: 成功捕获了 FeRh 的反铁磁到铁磁磁结构相变的时空相异质性，并确定铁磁相在表面形核为直径约 30 nm 的狭窄柱状域。

Conclusion: 该方法为研究相变提供了一个多功能平台，可用于研究伴随结构变化的各种相变，并解决了 FeRh 文献中各种实验结果的矛盾。

Abstract: Phase transitions are governed by both intrinsic and extrinsic
heterogeneities, yet capturing their spatio-temporal dynamics remains a
challenge. While ultrafast techniques track phase changes on femtosecond
timescales, the spatial complexity and stochastic nature of the processes often
remain hidden. Here, we present an experimental approach that combines
well-established ultrafast hard-X-ray diffraction with a propagating strain
pulse as a universal and non-invasive probe. This ultrafast X-ray sonography
can capture the spatio-temporal phase heterogeneity in great detail by
resolving the phase-specific strain response. We apply this approach to the
antiferromagnetic-to-ferromagnetic magneto-structural phase transition in FeRh
and identify the ferromagnetic phase to nucleate at the surface as narrow
columnar domains of approximately $30\,\text{nm}$ diameter. Besides reconciling
the diverse experimental results in the literature on FeRh, X-ray sonography
offers a versatile platform for investigating a wide range of phase transitions
accompanied by structural changes.

</details>


### [277] [Large anisotropic magnetoresistance in $α$-MnTe induced by strain](https://arxiv.org/abs/2507.16738)
*Bao-Feng Chen,Jie-Xiang Yu,Gen Yin*

Main category: cond-mat.mtrl-sci

TL;DR: 通过应变可以大幅调控α-MnTe的输运特性，特别是平面霍尔效应和各向异性磁阻。


<details>
  <summary>Details</summary>
Motivation: α-MnTe是一种p型半导体交替磁体，其N'eel温度接近300K。由于强的自旋-轨道耦合和交替磁对称性，在价带最大值沿Γ-K线和A点的Kramers简并被解除，但能量差很小，这使得输运行为对光谱的微小移动非常敏感。

Method: 通过对单位晶胞的[0001]轴施加约±0.5%的应变调制来研究α-MnTe的输运特性。

Result: 应变调制可以显著改变输运信号，并在价带的两个区域之间切换其热学窗口。平面霍尔效应和各向异性磁阻可以被调制一个数量级，最大可达约30%。

Conclusion: 研究表明，通过对单位晶胞的[0001]轴进行约±0.5%的应变调制，可以显著改变α-MnTe的输运特性，并在价带的两个区域之间切换其热学窗口。当Γ-K线占主导地位时，平面霍尔效应和各向异性磁阻可以被调制一个数量级，最大可达约30%。

Abstract: $\alpha\textrm{-MnTe}$ is a p-type semiconducting altermagnet with a N\'eel
temperature near 300K. Due to the strong spin-orbit coupling and the
altermagnetic symmetry, Kramers degeneracy is lifted in the valence band maxima
along the $\Gamma$-K line and the A point. However, the energy difference is
found to be small, and any small shift in the spectrum can dramatically change
the overall transport behavior. Here we show that a strain modulating the
[0001] axis of the unit cell by $\sim\pm0.5\%$ can significantly change the
transport signature, switching the thermal window between the two regions of
the valence band. When the $\Gamma$-K line is dominating, the planar Hall
effect and the anisotropic magnetoresistance can be modulated by an order of
magnitude, with the maximum up to $\sim30\%$.

</details>


<div id='eess.SP'></div>

# eess.SP [[Back]](#toc)

### [278] [MSGM: A Multi-Scale Spatiotemporal Graph Mamba for EEG Emotion Recognition](https://arxiv.org/abs/2507.15914)
*Hanwen Liu,Yifeng Gong,Zuwei Yan,Zeheng Zhuang,Jiaxuan Lu*

Main category: eess.SP

TL;DR: MSGM框架通过多尺度时空图和Mamba模型，提高了EEG情绪识别的准确性和效率，在多个数据集上超越了现有方法，并实现了快速推理。


<details>
  <summary>Details</summary>
Motivation: 现有的基于脑电图（EEG）的情绪识别方法在捕获多尺度时空动态和保证实时应用中的计算效率方面存在不足。这些方法常常过度简化时间粒度和空间层级，从而限制了识别的准确性。

Method: 提出了一种名为多尺度时空图Mamba（MSGM）的新型框架。该框架集成了多窗口时间分割、双模态空间图建模，并利用Mamba架构实现高效融合。具体方法包括：1. 多尺度时间分割：将EEG信号分割成不同的时间尺度。2. 双模态空间图建模：构建包含全局和局部信息的空间图，并结合神经解剖先验。3. 高效融合：利用多深度图卷积网络（GCN）和token嵌入融合模块，结合Mamba的状态空间模型，实现动态时空交互，并保持线性复杂度。

Result: MSGM框架仅使用一个MSST-Mamba层，在SEED、THU-EP和FACED数据集上均超越了现有领先方法。在被试独立情绪分类任务中，其性能优于基线方法。此外，MSGM在NVIDIA Jetson Xavier NX上实现了毫秒级的推理速度，展现了其鲁棒的准确性和高效性。

Conclusion: MSGM框架通过整合多窗口时间分割、双模态空间图建模和Mamba架构的高效融合，成功克服了脑电图（EEG）情绪识别在捕获多尺度时空动态和保证计算效率方面的挑战。该方法通过在不同时间尺度上分割EEG信号并构建具有神经解剖先验的全局-局部图，有效捕捉了细粒度的情绪波动和分层的大脑连通性。

Abstract: EEG-based emotion recognition struggles with capturing multi-scale
spatiotemporal dynamics and ensuring computational efficiency for real-time
applications. Existing methods often oversimplify temporal granularity and
spatial hierarchies, limiting accuracy. To overcome these challenges, we
propose the Multi-Scale Spatiotemporal Graph Mamba (MSGM), a novel framework
integrating multi-window temporal segmentation, bimodal spatial graph modeling,
and efficient fusion via the Mamba architecture. By segmenting EEG signals
across diverse temporal scales and constructing global-local graphs with
neuroanatomical priors, MSGM effectively captures fine-grained emotional
fluctuations and hierarchical brain connectivity. A multi-depth Graph
Convolutional Network (GCN) and token embedding fusion module, paired with
Mamba's state-space modeling, enable dynamic spatiotemporal interaction at
linear complexity. Notably, with just one MSST-Mamba layer, MSGM surpasses
leading methods in the field on the SEED, THU-EP, and FACED datasets,
outperforming baselines in subject-independent emotion classification while
achieving robust accuracy and millisecond-level inference on the NVIDIA Jetson
Xavier NX.

</details>


### [279] [Modeling and Analysis of Land-to-Ship Maritime Wireless Channels at 5.8 GHz](https://arxiv.org/abs/2507.15969)
*Shu Sun,Yulu Guo,Meixia Tao,Wei Feng,Jun Chen,Ruifeng Gao,Ye Li,Jue Wang,Theodore S. Rappaport*

Main category: eess.SP

TL;DR: 本研究针对 5.8 GHz 陆地到船舶的无线通信，进行了详细的海上信道建模研究。提出了新的路径损耗模型和 SWIFT 衰落模拟模型，并分析了不同衰落模型和小尺度衰落的适用性。研究结果为海上无线通信系统的设计提供了重要的参考依据。


<details>
  <summary>Details</summary>
Motivation: 海上信道建模对于设计能够应对海浪和风等影响信号传播因素的鲁棒通信系统至关重要。

Method: 通过广泛的测量活动，研究了 5.8 GHz 频率下陆地到船舶的海上无线信道特性，并同步收集了水文和气象信息。提出了一个具有物理基础和高精度的用于动态海洋环境的新型大尺度路径损耗模型。引入了海浪引起的固定点（SWIFT）衰落的概念，并提出了一个增强的双射线模型来模拟 SWIFT 衰落。研究了小尺度衰落，并利用了包括双波漫散射功率（TWDP）和非对称拉普拉斯分布在内的多种模型。通过基尼系数和莱斯 K 因子检验了海上信道的稀疏性，并表征了时间色散。

Result: 提出了一个用于动态海洋环境的新型大尺度路径损耗模型。提出了一个增强的双射线模型来模拟海浪引起的固定点（SWIFT）衰落，并显示与测量数据具有良好的一致性。研究了小尺度衰落，发现非对称拉普拉斯分布在大多数情况下表现良好，而 TWDP 模型能更好地捕捉恶劣海况下的双峰衰落。研究了海上信道的稀疏性和时间色散。

Conclusion: 该研究提出的信道模型和参数特征为海上无线系统的设计和部署提供了宝贵的见解。

Abstract: Maritime channel modeling is crucial for designing robust communication
systems in marine environments, where factors like waves and wind impact signal
propagation. This article investigates land-to-ship maritime wireless channel
characteristics at 5.8 GHz based upon an extensive measurement campaign, with
concurrent hydrological and meteorological information collection. First, a
novel large-scale path loss model with physical foundation and high accuracy is
proposed for dynamic marine environments. Then, we introduce the concept of
sea-wave-induced fixed-point (SWIFT) fading, a peculiar phenomenon in maritime
scenarios that captures the impact of sea surface fluctuations on received
power. An enhanced two-ray model incorporating vessel rotational motion is
propounded to simulate the SWIFT fading, showing good alignment with measured
data, particularly for modest antenna movements. Next, the small-scale fading
is studied by leveraging a variety of models including the two-wave with
diffuse power (TWDP) and asymmetric Laplace distributions, with the latter
performing well in most cases, while TWDP better captures bimodal fading in
rough seas. Furthermore, maritime channel sparsity is examined via the Gini
index and Rician $K$ factor, and temporal dispersion is characterized. The
resulting channel models and parameter characteristics offer valuable insights
for maritime wireless system design and deployment.

</details>


### [280] [Meta-Reinforcement Learning Optimization for Movable Antenna-aided Full-Duplex CF-DFRC Systems with Carrier Frequency Offset](https://arxiv.org/abs/2507.16132)
*Yue Xiu,Wanting Lyu,You Li,Ran Yang,Phee Lep Yeoh,Wei Zhang,Guangyi Liu,Ning Wei*

Main category: eess.SP

TL;DR: 该研究提出了一种基于MRL和可移动天线的CF-DFRC系统，通过优化天线位置和波束形成来解决宽带CFO问题，提升了通信和感知性能。


<details>
  <summary>Details</summary>
Motivation: 为了解决宽带场景下载波频率偏移（CFO）引起的同步误差对通信容量和感知精度降低的问题，将可移动天线（MA）集成到CF-DFRC框架中，以利用其空间灵活性和自适应波束形成来动态缓解CFO引起的损伤。

Method: 提出了一种基于元强化学习（MRL）的两阶段交替优化策略，包括流形优化（MO）和惩罚对偶分解（PDD）来解决CFO鲁棒性最坏情况子问题，并采用数据驱动的方式联合优化MA位置和波束形成向量。

Result: 仿真结果表明，所提出的MRL方法在通信和感知性能方面显著优于传统的DRL方案。

Conclusion: 所提出的MRL方法在通信和感知性能方面显著优于传统的DRL方案，并且MA辅助的CF-DFRC系统相比于固定位置天线（FPA）具有优势。

Abstract: By enabling spectrum sharing between radar and communication operations, the
cell-free dual-functional radar-communication (CF-DFRC) system is a promising
candidate to significantly improve spectrum efficiency in future
sixth-generation (6G) wireless networks. However, in wideband scenarios,
synchronization errors caused by carrier frequency offset (CFO) can severely
reduce both communication capacity and sensing accuracy. To address this
challenge, this paper integrates movable antennas (MAs) into the CF-DFRC
framework, leveraging their spatial flexibility and adaptive beamforming to
dynamically mitigate CFO-induced impairments. To fully exploit the advantages
of MAs in wideband scenarios with CFO, we aim to maximize the worst-case
sum-rate of communication and sensing by jointly optimizing MA positions,
{beamforming}, and CFO parameters, subject to transmit power and MA positioning
constraints. Due to the non-convex nature of the problem, we propose a robust
meta reinforcement learning (MRL)-based two-stage alternating optimization
strategy. In the first stage, we employ manifold optimization (MO) with penalty
dual decomposition (PDD) to solve the CFO-robust worst-case subproblem. In the
second stage, we adopt to jointly optimize {the MA positions and beamforming
vectors} in a data-driven manner {for dynamic wireless environments}.
Simulation results show that the proposed MRL approach significantly
outperforms conventional deep reinforcement learning (DRL) schemes in both
communication and sensing performance under CFO impairments. Furthermore,
compared to fixed-position antennas (FPAs), the MA-aided CF-DFRC system
exhibits

</details>


### [281] [Joint Active and Passive Beamforming for Energy-Efficient STARS with Quantization and Element Selection in ISAC Systems](https://arxiv.org/abs/2507.16210)
*Li-Hsiang Shen,Yi-Hsuan Chiu*

Main category: eess.SP

TL;DR: This paper proposes an AQUES scheme for STARS-ISAC systems to maximize energy efficiency (EE) by optimizing BS beamforming and STARS configurations. The proposed scheme outperforms existing methods and demonstrates the superior EE performance of coupled STARS due to reduced hardware complexity.


<details>
  <summary>Details</summary>
Motivation: This paper investigates a simultaneously transmitting and reflecting reconfigurable intelligent surface (STARS)-aided integrated sensing and communication (ISAC) systems in support of full-space energy-efficient data transmissions and target sensing. We formulate an energy efficiency (EE) maximization problem jointly optimizing dual-functional radar-communication (DFRC)-empowered base station (BS) ISAC beamforming and STARS configurations of amplitudes, phase-shifts, quantization levels as well as element selection. Furthermore, relaxed/independent/coupled STARS are considered to examine architectural flexibility.

Method: We propose a joint active-passive beamforming, quantization and element selection (AQUES) scheme based on alternating optimization: Lagrangian dual and Dinkelbach's transformation deals with fractions, whereas successive convex approximation (SCA) convexifies the problem; Penalty dual decomposition (PDD) framework and penalty-based convex-concave programming (PCCP) procedure solves amplitude and phase-shifts; Heuristic search decides the quantization level; Integer relaxation deals with the element selection.

Result: Simulation results demonstrate that STARS-ISAC with the proposed AQUES scheme significantly enhances EE while meeting communication rates and sensing quality requirements.

Conclusion: STARS-ISAC with the proposed AQUES scheme significantly enhances EE while meeting communication rates and sensing quality requirements. The coupled STARS further highlights its superior EE performance over independent and relaxed STARS thanks to its reduced hardware complexity. Moreover, AQUES outperforms existing configurations and benchmark methods in the open literature across various network parameters and deployment scenarios.

Abstract: This paper investigates a simultaneously transmitting and reflecting
reconfigurable intelligent surface (STARS)-aided integrated sensing and
communication (ISAC) systems in support of full-space energy-efficient data
transmissions and target sensing. We formulate an energy efficiency (EE)
maximization problem jointly optimizing dual-functional radar-communication
(DFRC)-empowered base station (BS) ISAC beamforming and STARS configurations of
amplitudes, phase-shifts, quantization levels as well as element selection.
Furthermore, relaxed/independent/coupled STARS are considered to examine
architectural flexibility. To tackle the non-convex and mixed-integer problem,
we propose a joint active-passive beamforming, quantization and element
selection (AQUES) scheme based on alternating optimization: Lagrangian dual and
Dinkelbach's transformation deals with fractions, whereas successive convex
approximation (SCA) convexifies the problem; Penalty dual decomposition (PDD)
framework and penalty-based convex-concave programming (PCCP) procedure solves
amplitude and phase-shifts; Heuristic search decides the quantization level;
Integer relaxation deals with the element selection. Simulation results
demonstrate that STARS-ISAC with the proposed AQUES scheme significantly
enhances EE while meeting communication rates and sensing quality requirements.
The coupled STARS further highlights its superior EE performance over
independent and relaxed STARS thanks to its reduced hardware complexity.
Moreover, AQUES outperforms existing configurations and benchmark methods in
the open literature across various network parameters and deployment scenarios.

</details>


### [282] [Liquid Intelligent Metasurface for Fluid Antennas-Assisted Networks](https://arxiv.org/abs/2507.16211)
*Li-Hsiang Shen*

Main category: eess.SP

TL;DR: 该论文提出了一种新的液态智能超表面（LIM）辅助通信系统（FAS-LIM），通过动态调整天线和超表面的位置来优化通信性能，并在仿真中显示出优于传统方法的性能。


<details>
  <summary>Details</summary>
Motivation: 提出一种新颖的液态智能超表面（LIM）辅助下行多用户多输入单输出（MISO）系统，该系统通过允许流体天线（FA）和LIM动态调整其小尺度位置，以及波束成形和相移控制，实现电磁和空间联合可重构，以克服传统固定几何超表面系统的局限性。

Method: 通过交替优化、引入辅助变量、连续凸近似（SCA）和罚惩金蝉（PCCP）来解决联合优化波束成形、相移和流体天线/液体元件位置的非凸问题。

Result: 仿真结果表明，与采用固定超表面和固定天线阵列的基准方法相比，所提出的FAS-LIM架构在各种参数设置下均表现出显著的性能提升。

Conclusion: 文章提出的FAS-LIM架构在sum-rate最大化方面显著优于采用传统固定超表面和固定天线阵列的基准方法。

Abstract: This paper proposes a novel liquid intelligent metasurface (LIM)-assisted
downlink multi-user multiple-input single-output (MISO) system, wherein both
the base station (BS) and the metasurface are respectively equipped with fluid
antennas (FA) and liquid elements. Unlike conventional reconfigurable
metasurface-assisted systems with static geometries, the proposed architecture
enables joint electromagnetic and spatial reconfigurability by allowing both
the FA-empowered BS (FAS) and LIM to dynamically adjust their small-scale
positions in addition to beamforming and phase-shift controls. We formulate a
sum-rate maximization problem that jointly optimizes the BS beamforming, LIM
phase-shifts, and the positions of fluid antennas and liquid elements. The
problem is highly non-convex due to coupling between variables, fractional
expressions, unit-modulus constraints as well as spatial correlation functions.
To address these challenges, we adopt alternating optimization and introduce
auxiliary variables and employ successive convex approximation (SCA) as well as
the penalty convex-concave procedure (PCCP) to solve the respective
subproblems. Simulation results have demonstrated that the proposed FAS-LIM
architecture significantly outperforms benchmark methods employing conventional
fixed metasurface and fixed antenna arrays in terms of various parameter
settings.

</details>


### [283] [Latency Minimization Oriented Radio and Computation Resource Allocations for 6G V2X Networks with ISCC](https://arxiv.org/abs/2507.16375)
*Peng Liu,Xinyi Wang,Zesong Fei,Yuan Wu,Jie Xu,Arumugam Nallanathan*

Main category: eess.SP

TL;DR: 本文研究了支持ISCC的车联网系统，提出了一种联合优化无线和计算资源的算法，以最小化车辆的感知完成延迟。仿真结果证明了该方法的有效性，并揭示了系统性能与资源利用率之间的权衡。


<details>
  <summary>Details</summary>
Motivation: ISCC（集成感知、通信和计算）技术在6G网络中具有重要应用前景，特别是在车联网（V2X）领域。车辆可以利用ISAC（集成感知和通信）技术感知周围环境，同时将感知数据卸载到路侧基站进行处理。本文旨在解决此类系统中感知完成延迟最小化问题，同时满足检测概率约束。

Method: 本文提出了一种交替优化算法来解决所提出的混合整数非线性规划（MINLP）问题。具体来说，利用分支定界法确定子带分配，利用连续凸近似（SCA）优化功率控制，并根据广义瑞利熵和公平性准则闭式推导出基站的接收波束成形和计算资源分配。

Result: 仿真结果表明，所提出的联合资源分配方案能够显著降低所有车辆的最大任务完成延迟。此外，研究还揭示了系统性能与资源利用率之间的多种有趣权衡。

Conclusion: 所提出的联合资源分配方案可显著降低所有车辆之间的最大任务完成延迟，并揭示了系统性能与资源利用率之间的权衡。

Abstract: Incorporating mobile edge computing (MEC) and integrated sensing and
communication (ISAC) has emerged as a promising technology to enable integrated
sensing, communication, and computing (ISCC) in the sixth generation (6G)
networks. ISCC is particularly attractive for vehicle-to-everything (V2X)
applications, where vehicles perform ISAC to sense the environment and
simultaneously offload the sensing data to roadside base stations (BSs) for
remote processing. In this paper, we investigate a particular ISCC-enabled V2X
system consisting of multiple multi-antenna BSs serving a set of single-antenna
vehicles, in which the vehicles perform their respective ISAC operations (for
simultaneous sensing and offloading to the associated BS) over orthogonal
sub-bands. With the focus on fairly minimizing the sensing completion latency
for vehicles while ensuring the detection probability constraints, we jointly
optimize the allocations of radio resources (i.e., the sub-band allocation,
transmit power control at vehicles, and receive beamforming at BSs) as well as
computation resources at BS MEC servers. To solve the formulated complex
mixed-integer nonlinear programming (MINLP) problem, we propose an alternating
optimization algorithm. In this algorithm, we determine the sub-band allocation
via the branch-and-bound method, optimize the transmit power control via
successive convex approximation (SCA), and derive the receive beamforming and
computation resource allocation at BSs in closed form based on generalized
Rayleigh entropy and fairness criteria, respectively. Simulation results
demonstrate that the proposed joint resource allocation design significantly
reduces the maximum task completion latency among all vehicles. Furthermore, we
also demonstrate several interesting trade-offs between the system performance
and resource utilizations.

</details>


### [284] [Hybrid RISs for Simultaneous Tunable Reflections and Sensing](https://arxiv.org/abs/2507.16550)
*George C. Alexandropoulos,Nir Shlezinger,Ioannis Gavras,Haiyang Zhang*

Main category: eess.SP

TL;DR: HRIS是一种新型RIS，可以反射和传感信号，解决了现有RIS的信道估计难题，并能用于通信、传感和多用户信道估计。


<details>
  <summary>Details</summary>
Motivation: 解决现有纯反射RIS在网络编排（如信道估计）方面遇到的挑战。

Method: 介绍HRIS的实现细节和数学模型，并通过两个应用场景（通信与传感，以及多用户上行信道估计）进行性能评估。

Result: HRIS能够有效地进行传感和集成传感与通信，并在多用户场景下实现个体信道的估计。

Conclusion: 混合反射和传感RIS（HRIS）通过同时反射和传感信号，克服了纯反射RIS带来的信道估计等网络编排挑战，并能实现计算自主和自配置。

Abstract: The concept of smart wireless environments envisions dynamic programmable
propagation of information-bearing signals through the deployment of
Reconfigurable Intelligent Surfaces (RISs). Typical RIS implementations include
metasurfaces with passive unit elements capable to reflect their incident waves
in controllable ways. However, this solely reflective operation induces
significant challenges in the RIS orchestration from the wireless network. For
example, channel estimation, which is essential for coherent RIS-empowered
wireless communications, is quite challenging with the available solely
reflecting RIS designs. This chapter reviews the emerging concept of Hybrid
Reflecting and Sensing RISs (HRISs), which enables metasurfaces to reflect the
impinging signal in a controllable manner, while simultaneously sensing a
portion of it. The sensing capability of HRISs facilitates various network
management functionalities, including channel parameter estimation and
localization, while, most importantly, giving rise to computationally
autonomous and self-configuring RISs. The implementation details of HRISs are
first presented, which are then followed by a convenient mathematical model for
characterizing their dual functionality. Then, two indicative applications of
HRISs are discussed, one for simultaneous communications and sensing and
another that showcases their usefulness for estimating the individual channels
in the uplink of a multi-user HRIS-empowered communication system. For both of
these applications, performance evaluation results are included validating the
role of HRISs for sensing as well as integrated sensing and communications.

</details>


### [285] [Generative Diffusion Models for Wireless Networks: Fundamental, Architecture, and State-of-the-Art](https://arxiv.org/abs/2507.16733)
*Dayu Fan,Rui Meng,Xiaodong Xu,Yiming Liu,Guoshun Nan,Chenyuan Feng,Shujun Han,Song Gao,Bingxuan Xu,Dusit Niyato,Tony Q. S. Quek,Ping Zhang*

Main category: eess.SP

TL;DR: This paper reviews Generative Diffusion Models (GDMs) for wireless networks, covering their tech evolution, applications in a proposed multi-layer architecture, and current schemes. It also discusses challenges and future research.


<details>
  <summary>Details</summary>
Motivation: To address the lack of comprehensive reviews on the technological evolution and application of GDMs in wireless networks, despite their growing potential.

Method: Systematic review and analysis of GDMs in wireless networks, including mathematical principles, representative models, a proposed multi-layer architecture, and a review of existing GDM-based schemes.

Result: A structured overview of GDMs in wireless networks, detailing their advantages, mechanisms across network layers, analysis of existing applications, and identification of key challenges and potential solutions.

Conclusion: This paper provides a comprehensive review of Generative Diffusion Models (GDMs) in wireless networks, analyzing their evolution, applications across different network layers, and existing schemes. It also identifies challenges and suggests future research directions.

Abstract: With the rapid development of Generative Artificial Intelligence (GAI)
technology, Generative Diffusion Models (GDMs) have shown significant
empowerment potential in the field of wireless networks due to advantages, such
as noise resistance, training stability, controllability, and multimodal
generation. Although there have been multiple studies focusing on GDMs for
wireless networks, there is still a lack of comprehensive reviews on their
technological evolution. Motivated by this, we systematically explore the
application of GDMs in wireless networks. Firstly, starting from mathematical
principles, we analyze technical advantages of GDMs and present six
representative models. Furthermore, we propose the multi-layer wireless network
architecture including sensing layer, transmission layer, application layer,
and security plane. We also introduce the core mechanisms of GDM at each of the
layers. Subsequently, we conduct a rigorous review on existing GDM-based
schemes, with a focus on analyzing their innovative points, the role of GDMs,
strengths, and weaknesses. Ultimately, we extract key challenges and provide
potential solutions, with the aim of providing directional guidance for future
research in this field.

</details>


<div id='cs.AR'></div>

# cs.AR [[Back]](#toc)

### [286] [A Sparsity-Aware Autonomous Path Planning Accelerator with HW/SW Co-Design and Multi-Level Dataflow Optimization](https://arxiv.org/abs/2507.16177)
*Yifan Zhang,Xiaoyu Niu,Hongzheng Tian,Yanjun Zhang,Bo Yu,Shaoshan Liu,Sitao Huang*

Main category: cs.AR

TL;DR: 针对自动驾驶路径规划的计算密集性问题，提出了一种基于FPGA的端到端加速框架，采用ADMM和PCG方法，并通过多级数据流优化，显著提升了性能和能效。


<details>
  <summary>Details</summary>
Motivation: 路径规划对于自动驾驶至关重要，但其计算密集性给资源受限的自动驾驶硬件带来了重大挑战。

Method: 提出了一种端到端的、基于FPGA的加速框架，针对二次规划（QP）求解，这是基于优化的路径规划的核心。采用硬件友好的ADMM方法求解QP，并采用可并行化的预处理共轭梯度（PCG）方法求解线性系统。通过分析稀疏矩阵模式，提出定制化的存储方案和高效的稀疏矩阵乘法单元，以减少资源使用和加速矩阵运算。多级数据流优化策略包括算子内并行和流水线、算子间细粒度流水线以及CPU-FPGA系统级任务映射。

Result: 在AMD ZCU102平台上实现的框架，在延迟和能效方面达到了最先进水平，性能和吞吐量均优于现有设计和CPU/GPU解决方案。

Conclusion: 该框架在AMD ZCU102平台上实现了最先进的延迟和能效，在性能上比最佳的FPGA设计快1.48倍，比Intel i7-11800H CPU快2.89倍，比ARM Cortex-A57嵌入式CPU快5.62倍，比最先进的GPU解决方案快1.56倍，同时吞吐量比现有的基于FPGA的设计提高了2.05倍。

Abstract: Path planning is critical for autonomous driving, generating smooth,
collision-free, feasible paths based on perception and localization inputs.
However, its computationally intensive nature poses significant challenges for
resource-constrained autonomous driving hardware. This paper presents an
end-to-end FPGA-based acceleration framework targeting the quadratic
programming (QP), core of optimization-based path planning. We employ a
hardware-friendly alternating direction method of multipliers (ADMM) for QP
solving and a parallelizable preconditioned conjugate gradient (PCG) method for
linear systems. By analyzing sparse matrix patterns, we propose customized
storage schemes and efficient sparse matrix multiplication units, significantly
reducing resource usage and accelerating matrix operations. Our multi-level
dataflow optimization strategy incorporates intra-operator parallelization and
pipelining, inter-operator fine-grained pipelining, and CPU-FPGA system-level
task mapping. Implemented on the AMD ZCU102 platform, our framework achieves
state-of-the-art latency and energy efficiency, including 1.48x faster
performance than the best FPGA-based design, 2.89x over an Intel i7-11800H CPU,
5.62x over an ARM Cortex-A57 embedded CPU, and 1.56x over a state-of-the-art
GPU solution, along with a 2.05x throughput improvement over existing
FPGA-based designs.

</details>


### [287] [Hourglass Sorting: A novel parallel sorting algorithm and its implementation](https://arxiv.org/abs/2507.16326)
*Daniel Bascones,Borja Morcillo*

Main category: cs.AR

TL;DR: 该研究提出了一种新颖的并行排序器，用于输入并行但输出串行的情况，并在 FPGA 上进行了实现和验证，实现了 n+log n 的总排序时间，并且资源会随着输入大小线性扩展。


<details>
  <summary>Details</summary>
Motivation: 排序是计算机科学中的一个基本问题，虽然并行化可以降低排序时间，但会增加实现成本和数据移动的瓶颈。本研究旨在解决这些问题，特别是在输入并行但输出串行的情况下。

Method: 提出了一种新颖的并行排序器，该排序器实现了 n+log n 的总排序时间，并且与输入大小成线性比例扩展资源。

Result: 在 FPGA 上实现的并行排序器在量子 LDPC 解码器的上下文中得到了验证，实现了 log n 的第一元素输出延迟，以及 n+log n 的总排序时间。与其他的并行排序方法不同，时钟速度不会随着 n 的增加而降低，并且资源会随着输入大小线性扩展。

Conclusion: 该研究提出了一种新颖的并行排序器，用于输入并行但输出串行的情况，并在 FPGA 上进行了实现和验证。

Abstract: Sorting is one of the fundamental problems in computer science. Playing a
role in many processes, it has a lower complexity bound imposed by
$\mathcal{O}(n\log{n})$ when executing on a sequential machine. This limit can
be brought down to sub-linear times thanks to parallelization techniques that
increase the number of comparisons done in parallel. This, however, increases
the cost of implementation, which limits the application of such techniques.
Moreover, as the size of the arrays increases, a bottleneck arises in moving
the vast quantities of data required at the input, and generated at the output
of such sorter. This might impose time requirements much stricter than those of
the sorting itself. In this paper, a novel parallel sorter is proposed for the
specific case where the input is parallel, but the output is serial. The design
is then implemented and verified on an FPGA within the context of a quantum
LDPC decoder. A latency of $\log{n}$ is achieved for the output of the first
element, after which the rest stream out for a total sorting time of
$n+\log{n}$. Contrary to other parallel sorting methods, clock speed does not
degrade with $n$, and resources scale linearly with input size.

</details>


### [288] [ApproxGNN: A Pretrained GNN for Parameter Prediction in Design Space Exploration for Approximate Computing](https://arxiv.org/abs/2507.16379)
*Ondrej Vlcek,Vojtech Mrazek*

Main category: cs.AR

TL;DR: ApproxGNN 是一种图神经网络，可提高近似计算的预测准确性，并在图像卷积滤波器上展示了显著的性能提升。


<details>
  <summary>Details</summary>
Motivation: 在近似计算中，在不执行完整综合的情况下预测由近似组件组成的电路的准确性是一个挑战。现有的机器学习方法需要针对每个新的电路配置进行重新训练，这既耗时又耗费计算资源。

Method: ApproxGNN 是一种图神经网络模型，它使用新颖的基于学习的嵌入作为特征来预测近似加速器的质量和硬件成本，而不是传统的错误指标。

Result: ApproxGNN 的实验结果表明，与传统方法相比，其嵌入可将预测准确性（均方误差）提高 50%，并且比统计机器学习方法（未进行微调）的整体预测准确性高 30%，比经过微调的方法高 54%。

Conclusion: ApproxGNN 通过使用基于学习的嵌入作为特征，提高了近似计算中预测准确性的准确性和可转移性，在图像卷积滤波器上将预测准确性提高了 50%，并优于其他方法。

Abstract: Approximate computing offers promising energy efficiency benefits for
error-tolerant applications, but discovering optimal approximations requires
extensive design space exploration (DSE). Predicting the accuracy of circuits
composed of approximate components without performing complete synthesis
remains a challenging problem. Current machine learning approaches used to
automate this task require retraining for each new circuit configuration,
making them computationally expensive and time-consuming. This paper presents
ApproxGNN, a construction methodology for a pre-trained graph neural network
model predicting QoR and HW cost of approximate accelerators employing
approximate adders from a library. This approach is applicable in DSE for
assignment of approximate components to operations in accelerator. Our approach
introduces novel component feature extraction based on learned embeddings
rather than traditional error metrics, enabling improved transferability to
unseen circuits. ApproxGNN models can be trained with a small number of
approximate components, supports transfer to multiple prediction tasks,
utilizes precomputed embeddings for efficiency, and significantly improves
accuracy of the prediction of approximation error. On a set of image
convolutional filters, our experimental results demonstrate that the proposed
embeddings improve prediction accuracy (mean square error) by 50% compared to
conventional methods. Furthermore, the overall prediction accuracy is 30%
better than statistical machine learning approaches without fine-tuning and 54%
better with fast finetuning.

</details>


### [289] [Ironman: Accelerating Oblivious Transfer Extension for Privacy-Preserving AI with Near-Memory Processing](https://arxiv.org/abs/2507.16391)
*Chenqi Lin,Kang Yang,Tianshi Xu,Ling Liang,Yufei Wang,Zhaohui Chen,Runsheng Wang,Mingyu Gao,Meng Li*

Main category: cs.AR

TL;DR: 本研究提出 Ironman 加速器，透過硬體優化 OT 計算，解決 PPML 的延遲瓶頸，顯著提升效率。


<details>
  <summary>Details</summary>
Motivation: 為了應對機器學習 (ML) 應用中日益增長的用戶數據隱私擔憂，PPML 被提出作為一種在加密數據上直接計算 ML 模型以提供正式隱私保證的解決方案。然而，現有的 PPML 框架過度依賴 OT 原語來計算非線性函數，而 OT 在通用 CPU 上的計算效率低下，成為現代 PPML 框架的延遲瓶頸。

Method: 本研究提出了一個名為 Ironman 的新型 OT 加速器，針對 SPCOT 計算提出了一個硬體友善的演算法和客製化加速器，以提高計算吞吐量；針對 LPN 的記憶體頻寬瓶頸，則採用近記憶體處理 (NMP) 架構，並結合記憶體側快取和索引排序技術，以提升有效記憶體頻寬。

Result: Ironman 加速器在 OT 吞吐量方面，相較於 CPU 實現，在不同的 NMP 配置下，實現了 39.2-237.4 倍的提升。在不同的 PPML 框架應用中，對於 CNN 和 Transformer 模型，Ironman 將端到端延遲降低了 2.1-3.4 倍。

Conclusion: 該研究提出了一個名為 Ironman 的新型 OT 加速器，透過硬體加速 SPCOT 和 LPN 計算，顯著提高了 PPML 框架的效率和 OT 吞吐量，並在 CNN 和 Transformer 模型上實現了端到端延遲的降低。

Abstract: With the wide application of machine learning (ML), privacy concerns arise
with user data as they may contain sensitive information. Privacy-preserving ML
(PPML) based on cryptographic primitives has emerged as a promising solution in
which an ML model is directly computed on the encrypted data to provide a
formal privacy guarantee. However, PPML frameworks heavily rely on the
oblivious transfer (OT) primitive to compute nonlinear functions. OT mainly
involves the computation of single-point correlated OT (SPCOT) and learning
parity with noise (LPN) operations. As OT is still computed extensively on
general-purpose CPUs, it becomes the latency bottleneck of modern PPML
frameworks.
  In this paper, we propose a novel OT accelerator, dubbed Ironman, to
significantly increase the efficiency of OT and the overall PPML framework. We
observe that SPCOT is computation-bounded, and thus propose a hardware-friendly
SPCOT algorithm with a customized accelerator to improve SPCOT computation
throughput. In contrast, LPN is memory-bandwidth-bounded due to irregular
memory access patterns. Hence, we further leverage the near-memory processing
(NMP) architecture equipped with memory-side cache and index sorting to improve
effective memory bandwidth. With extensive experiments, we demonstrate Ironman
achieves a 39.2-237.4 times improvement in OT throughput across different NMP
configurations compared to the full-thread CPU implementation. For different
PPML frameworks, Ironman demonstrates a 2.1-3.4 times reduction in end-to-end
latency for both CNN and Transformer models.

</details>


### [290] [Augmenting Von Neumann's Architecture for an Intelligent Future](https://arxiv.org/abs/2507.16628)
*Rajpreet Singh,Vidhi Kothari*

Main category: cs.AR

TL;DR: 提出了一种扩展冯·诺依曼模型的新型计算机体系结构，增加了推理单元（RU），以实现原生的通用人工智能（AGI）能力。该架构支持符号推理、多智能体协调和混合符号-神经计算，并将推理、学习和适应作为内在执行属性，有望实现通用智能机器。


<details>
  <summary>Details</summary>
Motivation: 为了使自主代理能够在系统规模上直接在计算基板内执行目标导向的规划、动态知识操作和内省推理。

Method: 提出了一种新颖的计算机体系结构，该体系结构通过专用的推理单元（RU）扩展了冯·诺依曼模型，实现了原生的通用人工智能能力。RU 作为一种专门的协处理器，将符号推理、多智能体协调和混合符号-神经计算作为基本的体系结构原语。

Result: 该架构通过系统性的硬件、操作系统和代理运行时层面的协同设计，实现了在系统规模上将推理、学习和适应作为内在执行属性，而非软件抽象，从而实现通用人工智能。

Conclusion: 该架构通过将推理、学习和适应作为内在执行属性，为通用智能机器的发展奠定了计算基础。

Abstract: This work presents a novel computer architecture that extends the Von Neumann
model with a dedicated Reasoning Unit (RU) to enable native artificial general
intelligence capabilities. The RU functions as a specialized co-processor that
executes symbolic inference, multi-agent coordination, and hybrid
symbolic-neural computation as fundamental architectural primitives. This
hardware-embedded approach allows autonomous agents to perform goal-directed
planning, dynamic knowledge manipulation, and introspective reasoning directly
within the computational substrate at system scale. The architecture
incorporates a reasoning-specific instruction set architecture, parallel
symbolic processing pipelines, agent-aware kernel abstractions, and a unified
memory hierarchy that seamlessly integrates cognitive and numerical workloads.
Through systematic co-design across hardware, operating system, and agent
runtime layers, this architecture establishes a computational foundation where
reasoning, learning, and adaptation emerge as intrinsic execution properties
rather than software abstractions, potentially enabling the development of
general-purpose intelligent machines.

</details>


### [291] [MTU: The Multifunction Tree Unit in zkSpeed for Accelerating HyperPlonk](https://arxiv.org/abs/2507.16793)
*Jianqiao Mo,Alhad Daftardar,Joey Ah-kiow,Kaiyue Guo,Benedikt Bünz,Siddharth Garg,Brandon Reagen*

Main category: cs.AR

TL;DR: 本研究聚焦于零知识证明（ZKP）中基于树的内核的硬件加速。通过评估不同的遍历策略，并引入一种名为混合遍历（Hybrid Traversal）的新方法，显著提高了CPU和专用硬件（MTU）的性能。MTU相比CPU实现了高达1478倍的加速，混合遍历方法则提供了高达3倍的性能提升，为ZKP硬件加速提供了宝贵的见解。


<details>
  <summary>Details</summary>
Motivation: 许多零知识证明（ZKPs）依赖于像SumCheck协议和Merkle Tree承诺这样的内核，这些内核具有平衡二叉树计算模式，便于硬件加速。虽然已有研究探索了将这些内核作为整体ZKP协议的一部分进行加速，但针对如何最佳利用底层的树模式来提高硬件效率的研究仍然有限。

Method: 通过系统评估基于树的工作负载在不同遍历策略下的性能，并在多线程CPU和多功能树单元（MTU）硬件加速器上进行分析。引入了一种名为混合遍历（Hybrid Traversal）的硬件友好型方法，以提高并行性和可扩展性，同时显著减少硬件上的内存流量。

Result: MTU在DDR级带宽上实现了比CPU高1478倍的加速，并且所提出的混合遍历方法作为独立方法，性能提升高达3倍。

Conclusion: 该研究为具有二叉树结构的的零知识证明（ZKP）工作负载设计高效硬件加速器提供了实际指导。

Abstract: Zero-Knowledge Proofs (ZKPs) are critical for privacy preservation and
verifiable computation. Many ZKPs rely on kernels such as the SumCheck protocol
and Merkle Tree commitments, which enable their security properties. These
kernels exhibit balanced binary tree computational patterns, which enable
efficient hardware acceleration. Prior work has investigated accelerating these
kernels as part of an overarching ZKP protocol; however, a focused study of how
to best exploit the underlying tree pattern for hardware efficiency remains
limited. We conduct a systematic evaluation of these tree-based workloads under
different traversal strategies, analyzing performance on multi-threaded CPUs
and a hardware accelerator, the Multifunction Tree Unit (MTU). We introduce a
hardware-friendly Hybrid Traversal for binary tree that improves parallelism
and scalability while significantly reducing memory traffic on hardware. Our
results show that MTU achieves up to 1478$\times$ speedup over CPU at DDR-level
bandwidth and that our hybrid traversal outperforms as standalone approach by
up to 3$\times$. These findings offer practical guidance for designing
efficient hardware accelerators for ZKP workloads with binary tree structures.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [292] [Fast Task Planning with Neuro-Symbolic Relaxation](https://arxiv.org/abs/2507.15975)
*Qiwei Du,Bowen Li,Yi Du,Shaoshu Su,Taimeng Fu,Zitong Zhan,Zhipeng Zhao,Chen Wang*

Main category: cs.RO

TL;DR: Flax 是一种新的神经符号（NeSy）规划策略，通过结合神经网络预测实体重要性与符号规划，并利用规则松弛和实体重整合来优化规划过程，能在复杂环境中实现更快速、更可靠的任务规划。


<details>
  <summary>Details</summary>
Motivation: 传统的符号规划器在处理现实世界任务规划时，由于实体关系和属性复杂，搜索空间会发生组合爆炸。现有方法通过神经预测简化任务以剪枝搜索空间，但可能遗漏关键实体或在无解的简化任务上浪费资源。因此，需要一种能够快速、可靠规划的方法。

Method: Flax 采用一种神经符号（NeSy）松弛策略，首先学习图神经网络预测实体重要性以创建简化任务并用符号规划器求解；然后，求解规则松弛任务以获得初步计划，并将所有引用的实体重新整合到简化任务中以恢复被忽略但重要的元素；最后，应用互补规则来优化更新后的任务，使其保持可靠和紧凑。

Result: 在合成和现实世界的迷宫导航基准测试中，Flax 的平均成功率提高了 20.82%，平均规划时间减少了 17.65%，相比于最先进的 NeSy 基线。

Conclusion: Flax 通过结合神经重要性预测和符号扩展，能够提高规划成功率并减少规划时间，为复杂环境中的快速、可扩展、长远任务规划提供了一条实用的途径。

Abstract: Real-world task planning requires long-horizon reasoning over large sets of
entities with complex relationships and attributes, leading to a combinatorial
explosion for classical symbolic planners. To prune the search space, recent
methods prioritize searching on a simplified task only containing a few
"important" entities predicted by a neural network. However, such a simple
neuro-symbolic (NeSy) integration risks omitting critical entities and wasting
resources on unsolvable simplified tasks. To enable Fast and reliable planning,
we introduce a NeSy relaxation strategy (Flax), combining neural importance
prediction with symbolic expansion. Specifically, we first learn a graph neural
network to predict entity importance to create a simplified task and solve it
with a symbolic planner. Then, we solve a rule-relaxed task to obtain a quick
rough plan, and reintegrate all referenced entities into the simplified task to
recover any overlooked but essential elements. Finally, we apply complementary
rules to refine the updated task, keeping it both reliable and compact.
Extensive experiments are conducted on both synthetic and real-world maze
navigation benchmarks where a robot must traverse through a maze and interact
with movable objects. The results show that Flax boosts the average success
rate by 20.82% and cuts mean wall-clock planning time by 17.65% compared with
the state-of-the-art NeSy baseline. We expect that Flax offers a practical path
toward fast, scalable, long-horizon task planning in complex environments.

</details>


### [293] [Compositional Coordination for Multi-Robot Teams with Large Language Models](https://arxiv.org/abs/2507.16068)
*Zhehui Huang,Guangyao Shi,Yuwei Wu,Vijay Kumar,Gaurav S. Sukhatme*

Main category: cs.RO

TL;DR: LAN2CB是一个利用大型语言模型将自然语言任务描述转换为机器人控制代码的新框架，可用于多机器人协同。


<details>
  <summary>Details</summary>
Motivation: 传统的机器人协同依赖于专家手动将自然语言任务描述转换为数学公式、算法设计和可执行代码，这种方式耗时耗力、非专业人士难以使用，并且在任务需求变更时不够灵活。本文提出的LAN2CB框架旨在通过利用大型语言模型（LLMs）来简化和泛化多机器人协同流程。

Method: LAN2CB框架通过任务分解（将任务解析为具有依赖关系的依赖图）和代码生成（利用任务依赖图和结构化知识库生成可部署的机器人控制代码）两个关键组件，将自然语言任务描述直接转换为多机器人系统的可执行Python代码。

Result: 实验结果表明，LAN2CB在模拟和真实世界环境中均能有效实现多机器人协同，并且能够支持跨任务类型的泛化。

Conclusion: LAN2CB框架能够有效地和灵活地实现多机器人协同，仅通过自然语言即可显著减少手动工程需求，并支持跨任务类型的泛化。

Abstract: Multi-robot coordination has traditionally relied on a task-specific and
expert-driven pipeline, where natural language mission descriptions are
manually translated by domain experts into mathematical formulation, algorithm
design, and executable code. This conventional process is labor-intensive,
inaccessible to non-experts, and inflexible to changes in mission requirements.
Here, we propose LAN2CB (Language to Collective Behavior), a novel framework
that leverages large language models (LLMs) to streamline and generalize the
multi-robot coordination pipeline. LAN2CB directly converts natural language
mission descriptions into executable Python code for multi-robot systems
through two key components: (1) Mission Decomposition for Task Representation,
which parses the mission into a task graph with dependencies, and (2) Code
Generation, which uses the task graph and a structured knowledge base to
generate deployable robot control code. We further introduce a dataset of
natural language mission specifications to support development and
benchmarking. Experimental results in both simulation and real-world settings
show that LAN2CB enables effective and flexible multi-robot coordination from
natural language, significantly reducing the need for manual engineering while
supporting generalization across mission types. Website:
https://sites.google.com/view/lan2cb.

</details>


### [294] [Designing for Difference: How Human Characteristics Shape Perceptions of Collaborative Robots](https://arxiv.org/abs/2507.16480)
*Sabrina Livanec,Laura Londoño,Michael Gorki,Adrian Röfer,Abhinav Valada,Andrea Kiesel*

Main category: cs.RO

TL;DR: 本研究通过在线实验和认知情感映射（CAM）练习，探讨了机器人行为、人类特征（特别是老年人）和协作类型（如物体交接）对评估结果的影响。结果显示，反社会机器人行为评分最低，老年人协作场景评估更敏感，物体交接场景更受欢迎。研究强调了亲社会设计和反思方法在机器人开发中的重要性。


<details>
  <summary>Details</summary>
Motivation: 由于参与者在现实生活中接触先进的家用机器人的经验有限，目前关于参与者如何评估不同机器人行为与多样化人类需求相结合的研究仍然稀少。本研究旨在通过使用能够让参与者评估机器人行为的方法以及支持有意义反思的方法来解决这一研究缺口。

Method: 本研究采用在线实验方法，让112名参与者（包括实验组和对照组）评估了28种不同人机协作类型中的7个视频。实验组在提供评分前完成了认知情感映射（CAM）练习。

Result: 认知情感映射（CAM）反思并未显著影响总体评分，但能对某些机器人行为和人类状况的组合产生更显著的评估。最重要的是，人机协作的类型会影响评估结果。反社会机器人行为的评分始终最低，而与老年人协作的场景则引发了更敏感的评估。涉及物体交接的场景比不涉及的场景更受好评。

Conclusion: 研究结果表明，人类特征和交互模式都会影响协作机器人的可接受性，强调了亲社会设计的 M 要性。此外，研究还凸显了认知情感映射（CAM）等反思方法在引发细致反馈方面的潜力，有助于为不同人群量身定制以用户为中心且对社会负责的机器人系统。

Abstract: The development of assistive robots for social collaboration raises critical
questions about responsible and inclusive design, especially when interacting
with individuals from protected groups such as those with disabilities or
advanced age. Currently, research is scarce on how participants assess varying
robot behaviors in combination with diverse human needs, likely since
participants have limited real-world experience with advanced domestic robots.
In the current study, we aim to address this gap while using methods that
enable participants to assess robot behavior, as well as methods that support
meaningful reflection despite limited experience. In an online study, 112
participants (from both experimental and control groups) evaluated 7 videos
from a total of 28 variations of human-robot collaboration types. The
experimental group first completed a cognitive-affective mapping (CAM) exercise
on human-robot collaboration before providing their ratings. Although CAM
reflection did not significantly affect overall ratings, it led to more
pronounced assessments for certain combinations of robot behavior and human
condition. Most importantly, the type of human-robot collaboration influences
the assessment. Antisocial robot behavior was consistently rated as the lowest,
while collaboration with aged individuals elicited more sensitive evaluations.
Scenarios involving object handovers were viewed more positively than those
without them. These findings suggest that both human characteristics and
interaction paradigms influence the perceived acceptability of collaborative
robots, underscoring the importance of prosocial design. They also highlight
the potential of reflective methods, such as CAM, to elicit nuanced feedback,
supporting the development of user-centered and socially responsible robotic
systems tailored to diverse populations.

</details>


### [295] [A Comprehensive Evaluation of LiDAR Odometry Techniques](https://arxiv.org/abs/2507.16000)
*Easton Potokar,Michael Kaess*

Main category: cs.RO

TL;DR: This paper analyzes and compares different components of LiDAR Odometry pipelines across various datasets and conditions to recommend the best design choices for accuracy and reliability.


<details>
  <summary>Details</summary>
Motivation: There has been significant work on LiDAR-based state estimation, leading to an explosion of possible technique combinations in LiDAR Odometry (LO) pipelines. However, little work has performed thorough ablation studies to compare the individual building blocks of these pipelines.

Method: The paper summarizes various techniques that constitute a LO pipeline and empirically evaluates these components on a wide range of datasets, considering different environments, LiDAR types, and vehicle motions.

Result: The paper empirically evaluates LO components across diverse datasets and makes recommendations for future LO pipeline design.

Conclusion: The paper provides empirically-backed recommendations for designing future LiDAR Odometry (LO) pipelines to achieve the most accurate and reliable performance.

Abstract: Light Detection and Ranging (LiDAR) sensors have become the sensor of choice
for many robotic state estimation tasks. Because of this, in recent years there
has been significant work done to fine the most accurate method to perform
state estimation using these sensors. In each of these prior works, an
explosion of possible technique combinations has occurred, with each work
comparing LiDAR Odometry (LO) "pipelines" to prior "pipelines". Unfortunately,
little work up to this point has performed the significant amount of ablation
studies comparing the various building-blocks of a LO pipeline. In this work,
we summarize the various techniques that go into defining a LO pipeline and
empirically evaluate these LO components on an expansive number of datasets
across environments, LiDAR types, and vehicle motions. Finally, we make
empirically-backed recommendations for the design of future LO pipelines to
provide the most accurate and reliable performance.

</details>


### [296] [Improved Semantic Segmentation from Ultra-Low-Resolution RGB Images Applied to Privacy-Preserving Object-Goal Navigation](https://arxiv.org/abs/2507.16034)
*Xuying Huang,Sicong Pan,Olga Zatsarynna,Juergen Gall,Maren Bennewitz*

Main category: cs.RO

TL;DR: 提出了一种新的联合学习方法，用于在超低分辨率图像中进行语义分割，以实现隐私保护的机器人导航，并在真实世界场景中取得了更好的分割和导航性能。


<details>
  <summary>Details</summary>
Motivation: 为了在用户隐私和机器人任务性能之间取得平衡，研究了在超低分辨率设置下的机器人导航，以保护视觉隐私。

Method: 提出了一种新颖的、基于语义的、全联合学习的方法，该方法集成了聚集特征提取器和感知分割的判别器，以解决超低分辨率语义分割问题。

Result: 开发了一种新的联合学习方法，用于超低分辨率语义分割，从而实现支持隐私的语义对象目标导航。

Conclusion: 该方法在超低分辨率语义分割方面优于各种基线方法，并且改进的分割结果提高了在真实世界隐私受限场景中语义对象目标导航的成功率。

Abstract: User privacy in mobile robotics has become a critical concern. Existing
methods typically prioritize either the performance of downstream robotic tasks
or privacy protection, with the latter often constraining the effectiveness of
task execution. To jointly address both objectives, we study semantic-based
robot navigation in an ultra-low-resolution setting to preserve visual privacy.
A key challenge in such scenarios is recovering semantic segmentation from
ultra-low-resolution RGB images. In this work, we introduce a novel fully
joint-learning method that integrates an agglomerative feature extractor and a
segmentation-aware discriminator to solve ultra-low-resolution semantic
segmentation, thereby enabling privacy-preserving, semantic object-goal
navigation. Our method outperforms different baselines on ultra-low-resolution
semantic segmentation and our improved segmentation results increase the
success rate of the semantic object-goal navigation in a real-world
privacy-constrained scenario.

</details>


### [297] [Therapist-Exoskeleton-Patient Interaction: An Immersive Gait Therapy](https://arxiv.org/abs/2507.16059)
*Emek Barış Küçüktabak,Matthew R. Short,Lorenzo Vianello,Daniel Ludvig,Levi Hargrove,Kevin Lynch,Jose Pons*

Main category: cs.RO

TL;DR: pHRHI是一种新颖的康复方法，利用连接人与治疗师的外骨骼，相比传统方法能更好地帮助中风患者恢复步态。


<details>
  <summary>Details</summary>
Motivation: 中风后，患者常出现运动和平衡障碍，传统的康复训练方法（如高强度治疗师指导训练）存在体力要求高、难以同时与多个关节交互等局限性。机器人外骨骼虽然能提供多关节支撑，但现有控制策略限制了治疗师的参与和适应性。

Method: 提出了一种新颖的基于物理人机-人交互（pHRHI）的步态康复范式，其中治疗师和中风患者都穿着通过髋关节和膝关节处的弹簧-阻尼器元件虚拟连接的下肢外骨骼。

Result: 与传统的治疗师引导的跑步机行走相比，pHRHI训练提高了关节活动度、步态指标、肌肉激活和患者积极性。

Conclusion: pHRHI结合了机器人的精确性和治疗师的直观性，有望改善康复效果。

Abstract: Following a stroke, individuals often experience mobility and balance
impairments due to lower-limb weakness and loss of independent joint control.
Gait recovery is a key goal of rehabilitation, traditionally achieved through
high-intensity therapist-led training. However, manual assistance can be
physically demanding and limits the therapist's ability to interact with
multiple joints simultaneously. Robotic exoskeletons offer multi-joint support,
reduce therapist strain, and provide objective feedback, but current control
strategies often limit therapist involvement and adaptability.
  We present a novel gait rehabilitation paradigm based on physical
Human-Robot-Human Interaction (pHRHI), where both the therapist and the
post-stroke individual wear lower-limb exoskeletons virtually connected at the
hips and knees via spring-damper elements. This enables bidirectional
interaction, allowing the therapist to guide movement and receive haptic
feedback. In a study with eight chronic stroke patients, pHRHI training
outperformed conventional therapist-guided treadmill walking, leading to
increased joint range of motion, step metrics, muscle activation, and
motivation. These results highlight pHRHI's potential to combine robotic
precision with therapist intuition for improved rehabilitation outcomes.

</details>


### [298] [FTIN: Frequency-Time Integration Network for Inertial Odometry](https://arxiv.org/abs/2507.16120)
*Shanshan Zhang,Qi Zhang,Siyue Wang,Tianshui Wen,Ziheng Zhou,Lingxiang Zheng,Yu Yang*

Main category: cs.RO

TL;DR: 通过融合频率域和时间域信息来改进惯性里程计的定位精度。


<details>
  <summary>Details</summary>
Motivation: 现有主要依赖CNN的时间域惯性里程计方法难以捕捉惯性测量单元数据的长期依赖性，限制了定位精度的提升潜力。

Method: 提出了一种结合频率域和时间域信息的新型网络架构，利用频率域学习的长时依赖性和能量聚集特性，并引入了Scalar LSTM来捕捉时间域的序列依赖性，以实现跨域信息融合。

Result: 在RIDI、RoNIN、OxIOD、RNIN、TLIO和IMUNet等多个公开数据集上进行了实验评估，证明了所提出的频率-时间域融合策略的有效性。与RoNIN ResNet相比，在RoNIN数据集上，绝对轨迹误差减少了43.0%，相对轨迹误差减少了13.1%。

Conclusion: 该方法通过融合频率域和时间域信息，在多个公开数据集上验证了其有效性，并在RoNIN数据集上显著降低了绝对轨迹误差和相对轨迹误差。

Abstract: In recent years, machine learning has achieved significant advancements in
inertial odometry. However, most existing inertial odometry methods primarily
rely on CNNs in the time domain. These methods often struggle to capture
long-term dependency in inertial measurement unit data, thereby constraining
the potential for further improvements in localization accuracy. To address
these issues, we propose a novel network architecture that integrates both
frequency-domain and time-domain information. Specifically, we leverage the
global view and energy compaction properties of frequency-domain learning to
effectively model long-term dependency and reduce redundancy in IMU data.
Additionally, we introduce a Scalar LSTM to capture sequential dependencies in
the time domain, enabling cross-domain information fusion and providing a
stable and reliable reference for localization. Experimental evaluations on
multiple public datasets (e.g., RIDI, RoNIN, OxIOD, RNIN, TLIO, and IMUNet)
demonstrate the effectiveness of the proposed frequency-time domain fusion
strategy. Notably, on the RoNIN dataset, our method achieves a 43.0% reduction
in absolute trajectory error and a 13.1% reduction in relative trajectory error
compared to RoNIN ResNet.

</details>


### [299] [DWSFormer: A Lightweight Inertial Odometry Network for Complex Motion Modeling](https://arxiv.org/abs/2507.16121)
*Shanshan Zhang,Qi Zhang,Siyue Wang,Tianshui Wen,Ziheng Zhou,Lingxiang Zheng,Yu Yang*

Main category: cs.RO

TL;DR: 一种新的轻量级惯性里程计框架，利用星象算子、协同注意机制和多尺度门控卷积来提高在复杂运动中的定位精度。


<details>
  <summary>Details</summary>
Motivation: 现有的惯性里程计方法在处理转弯等复杂运动模式时，会受到由漂移误差引起的精度下降问题，这严重影响了惯性里程计系统在现实世界场景中的应用。

Method: 提出了一种轻量级的惯性里程计框架，该框架将惯性数据投影到使用星象算子方法的高维隐式非线性特征空间，以提取通常被忽略的复杂运动特征。此外，还引入了一种协同注意机制，对通道和时间维度上的全局运动动力学进行联合建模，并设计了多尺度门控卷积单元来捕获运动过程中细粒度的动态变化，从而增强模型学习丰富且富有表现力的运动表征的能力。

Result: 与基线模型相比，所提出的方法在RoNIN数据集上的ATE减少了2.26%到65.78%，确立了该领域的新基准。

Conclusion: 所提出的轻量级惯性里程计框架在六个广泛使用的惯性数据集上进行了广泛的实验，并且一致优于最先进的基线，在RoNIN数据集上的ATE减少了2.26%到65.78%，为该领域树立了新的基准。

Abstract: Inertial odometry (IO) directly estimates the position of a carrier from
inertial sensor measurements and serves as a core technology for the widespread
deployment of consumer grade localization systems. While existing IO methods
can accurately reconstruct simple and near linear motion trajectories, they
often fail to account for drift errors caused by complex motion patterns such
as turning. This limitation significantly degrades localization accuracy and
restricts the applicability of IO systems in real world scenarios. To address
these challenges, we propose a lightweight IO framework. Specifically, inertial
data is projected into a high dimensional implicit nonlinear feature space
using the Star Operation method, enabling the extraction of complex motion
features that are typically overlooked. We further introduce a collaborative
attention mechanism that jointly models global motion dynamics across both
channel and temporal dimensions. In addition, we design Multi Scale Gated
Convolution Units to capture fine grained dynamic variations throughout the
motion process, thereby enhancing the model's ability to learn rich and
expressive motion representations. Extensive experiments demonstrate that our
proposed method consistently outperforms SOTA baselines across six widely used
inertial datasets. Compared to baseline models on the RoNIN dataset, it
achieves reductions in ATE ranging from 2.26% to 65.78%, thereby establishing a
new benchmark in the field.

</details>


### [300] [Benchmarking LLM Privacy Recognition for Social Robot Decision Making](https://arxiv.org/abs/2507.16124)
*Dakota Sullivan,Shirley Zhang,Jennica Li,Heather Kirkorian,Bilge Mutlu,Kassem Fawaz*

Main category: cs.RO

TL;DR: LLM在家庭社交机器人隐私保护方面需改进，与用户隐私偏好存在差距，但通过优化提示策略有提升潜力。


<details>
  <summary>Details</summary>
Motivation: 随着大型语言模型（LLM）的快速发展，其在增强社交机器人与人类交互方面的潜力日益凸显。然而，社交机器人在家庭环境中收集的个人数据（如音频、图像、视频和位置信息）引发了对隐私的担忧。本研究旨在评估当前LLM在处理此类敏感数据时的隐私保护能力，以解决效用与隐私风险之间的矛盾。

Method: 本研究首先通过调查（N = 450）收集用户对居家社交机器人行为的隐私偏好，并分析其隐私导向如何影响行为选择。随后，研究将相同的场景和问题提供给十个最先进的LLM（N = 10），评估LLM与人类用户在隐私偏好上的一致性。最后，研究实施了四种不同的提示策略，以进一步探究LLM作为潜在隐私控制器的能力。

Result: 研究发现，开箱即用的LLM在隐私偏好方面与人类用户的协议率较低。通过实施四种提示策略，研究为增强LLM的隐私控制能力提供了初步的解决方案，但具体效果有待进一步比较和分析。

Conclusion: 本研究探讨了LLM在家庭社交机器人隐私保护方面的潜力，发现目前开箱即用的LLM在隐私意识方面表现不佳，且与人类用户的隐私偏好存在显著差异。通过引入四种提示策略，本研究为提升LLM在人机交互中的隐私控制能力提供了方向，并强调了在AI隐私意识方面进行深入研究的重要性。

Abstract: Social robots are embodied agents that interact with people while following
human communication norms. These robots interact using verbal and non-verbal
cues, and share the physical environments of people. While social robots have
previously utilized rule-based systems or probabilistic models for user
interaction, the rapid evolution of large language models (LLMs) presents new
opportunities to develop LLM-empowered social robots for enhanced human-robot
interaction. To fully realize these capabilities, however, robots need to
collect data such as audio, fine-grained images, video, and locations. As a
result, LLMs often process sensitive personal information, particularly within
home environments. Given the tension between utility and privacy risks,
evaluating how current LLMs manage sensitive data is critical. Specifically, we
aim to explore the extent to which out-of-the-box LLMs are privacy-aware in the
context of household social robots. In this study, we present a set of
privacy-relevant scenarios crafted through the lens of Contextual Integrity
(CI). We first survey users' privacy preferences regarding in-home social robot
behaviors and then examine how their privacy orientation affects their choices
of these behaviors (N = 450). We then provide the same set of scenarios and
questions to state-of-the-art LLMs (N = 10) and find that the agreement between
humans and LLMs is low. To further investigate the capabilities of LLMs as a
potential privacy controller, we implement four additional prompting strategies
and compare their results. Finally, we discuss the implications and potential
of AI privacy awareness in human-robot interaction.

</details>


### [301] [Equivariant Goal Conditioned Contrastive Reinforcement Learning](https://arxiv.org/abs/2507.16139)
*Arsh Tangri,Nichols Crawford Taylor,Haojie Huang,Robert Platt*

Main category: cs.RO

TL;DR: ECRL通过利用对称性来提高对比强化学习的样本效率和泛化能力，并在机器人操作任务中表现出色。


<details>
  <summary>Details</summary>
Motivation: 对比强化学习（CRL）是一个有前途的框架，可用于从无标签交互中提取有用的结构化表示。通过拉近状态-动作对及其对应的未来状态，同时推开负面对，CRL能够在没有手动设计的奖励的情况下学习非平凡策略。

Method: 提出ECRL（Equivariant CRL），利用了由对比强化学习（CRL）驱动的内隐结构，并通过引入组合不变性或等方差约束来进一步约束内隐表示。具体来说，通过为目标条件组不变马尔可夫决策过程（Goal-Conditioned Group-Invariant MDPs）提供正式定义，以表征对称性，并引入了新颖的旋转不变批评者表示和旋转等方差行动者。

Result: ECRL通过利用目标条件操作任务中的内禀对称性，提高了样本效率和空间泛化能力。

Conclusion: ECRL在模拟任务中，无论是在基于状态还是基于图像的设置中，始终优于强大的基线。此外，研究还将该方法扩展到离线强化学习设置，并展示了其在多项任务中的有效性。

Abstract: Contrastive Reinforcement Learning (CRL) provides a promising framework for
extracting useful structured representations from unlabeled interactions. By
pulling together state-action pairs and their corresponding future states,
while pushing apart negative pairs, CRL enables learning nontrivial policies
without manually designed rewards. In this work, we propose Equivariant CRL
(ECRL), which further structures the latent space using equivariant
constraints. By leveraging inherent symmetries in goal-conditioned manipulation
tasks, our method improves both sample efficiency and spatial generalization.
Specifically, we formally define Goal-Conditioned Group-Invariant MDPs to
characterize rotation-symmetric robotic manipulation tasks, and build on this
by introducing a novel rotation-invariant critic representation paired with a
rotation-equivariant actor for Contrastive RL. Our approach consistently
outperforms strong baselines across a range of simulated tasks in both
state-based and image-based settings. Finally, we extend our method to the
offline RL setting, demonstrating its effectiveness across multiple tasks.

</details>


### [302] [Scanning Bot: Efficient Scan Planning using Panoramic Cameras](https://arxiv.org/abs/2507.16175)
*Euijeong Lee,Kyung Min Han,Young J. Kim*

Main category: cs.RO

TL;DR: 提出了一种全自主扫描规划方法，用于全景RGB-D相机，以提高3D场景重建的效率和质量。


<details>
  <summary>Details</summary>
Motivation: 全景RGB-D相机虽然能生成高质量的3D场景重建，但手动选择视角和移动相机既耗时又费力，特别是对于空间限制和确保视角帧之间有足够的特征重叠，这对新手来说很困难。

Method: 提出了一种全自主扫描规划方法，能够为环境扫描生成有效的路径规划，确保无碰撞导航和路径点之间有足够的重叠。

Result: 实验证明，该方法在真实世界实验中达到了 99% 的平均扫描覆盖率，并且比最先进的规划器快了 3 倍。

Conclusion: 该方法在合成和真实世界环境中进行了广泛的实验验证，与最先进的视图规划器相比，显示出优越的性能，平均扫描覆盖率为 99%，扫描时间快了 3 倍。

Abstract: Panoramic RGB-D cameras are known for their ability to produce high quality
3D scene reconstructions. However, operating these cameras involves manually
selecting viewpoints and physically transporting the camera, making the
generation of a 3D model time consuming and tedious. Additionally, the process
can be challenging for novice users due to spatial constraints, such as
ensuring sufficient feature overlap between viewpoint frames. To address these
challenges, we propose a fully autonomous scan planning that generates an
efficient tour plan for environment scanning, ensuring collision-free
navigation and adequate overlap between viewpoints within the plan. Extensive
experiments conducted in both synthetic and real-world environments validate
the performance of our planner against state-of-the-art view planners. In
particular, our method achieved an average scan coverage of 99 percent in the
real-world experiment, with our approach being up to 3 times faster than
state-of-the-art planners in total scan time.

</details>


### [303] [Adaptive Relative Pose Estimation Framework with Dual Noise Tuning for Safe Approaching Maneuvers](https://arxiv.org/abs/2507.16214)
*Batu Candan,Simone Servadio*

Main category: cs.RO

TL;DR: 提出了一种结合CNN和自适应UKF的鲁棒相对姿态估计方法，用于主动碎片移除任务，通过双重自适应提高了精度和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 为了应对像ESA的ENVISAT这样的翻滚废弃卫星的主动碎片移除（ADR）任务所带来的挑战，需要精确且鲁棒的相对姿态估计能力，以实现安全近距离操作。

Method: 提出了一种集成先进计算机视觉技术（包括CNN和相机建模）与自适应非线性滤波（UKF）的完整流程。该方法通过动态调整UKF中的测量噪声协方差来补偿CNN测量不确定性的变化，并通过利用测量残差分析来适应未建模的动力学或机动，从而实现了双重自适应。

Result: 通过使用高保真仿真和真实的ENVISAT模型，并与地面真实值进行比较，在包括测量中断在内的各种条件下，评估了所提出的自适应集成系统的性能。结果表明，该方法在鲁棒性方面得到了增强。

Conclusion: 该方法通过集成计算机视觉技术和自适应非线性滤波，为空间碎片移除任务中的相对姿态估计提供了增强的鲁棒性解决方案，显著提高了安全近距离操作的能力。

Abstract: Accurate and robust relative pose estimation is crucial for enabling
challenging Active Debris Removal (ADR) missions targeting tumbling derelict
satellites such as ESA's ENVISAT. This work presents a complete pipeline
integrating advanced computer vision techniques with adaptive nonlinear
filtering to address this challenge. A Convolutional Neural Network (CNN),
enhanced with image preprocessing, detects structural markers (corners) from
chaser imagery, whose 2D coordinates are converted to 3D measurements using
camera modeling. These measurements are fused within an Unscented Kalman Filter
(UKF) framework, selected for its ability to handle nonlinear relative
dynamics, to estimate the full relative pose. Key contributions include the
integrated system architecture and a dual adaptive strategy within the UKF:
dynamic tuning of the measurement noise covariance compensates for varying CNN
measurement uncertainty, while adaptive tuning of the process noise covariance,
utilizing measurement residual analysis, accounts for unmodeled dynamics or
maneuvers online. This dual adaptation enhances robustness against both
measurement imperfections and dynamic model uncertainties. The performance of
the proposed adaptive integrated system is evaluated through high-fidelity
simulations using a realistic ENVISAT model, comparing estimates against ground
truth under various conditions, including measurement outages. This
comprehensive approach offers an enhanced solution for robust onboard relative
navigation, significantly advancing the capabilities required for safe
proximity operations during ADR missions.

</details>


### [304] [GFM-Planner: Perception-Aware Trajectory Planning with Geometric Feature Metric](https://arxiv.org/abs/2507.16233)
*Yue Lin,Xiaoxuan Zhang,Yang Liu,Dong Wang,Huchuan Lu*

Main category: cs.RO

TL;DR: 提出 GFM-Planner 框架，通过基于几何特征度量（GFM）的感知感知轨迹规划，引导机器人避开退化区域，提高 LiDAR 定位精度。


<details>
  <summary>Details</summary>
Motivation: 自主机器人的精确定位依赖于特征丰富的环境，就像人类依赖地标进行导航一样。

Method: 提出了一种基于几何特征度量（GFM）的感知感知轨迹规划框架。首先，从基础 LiDAR 定位问题推导出 GFM。然后，设计了一个基于 2D 网格的度量编码图（MEM）来有效地存储环境中的 GFM 值，并提出了一种恒定时间解码算法来检索任意位姿的 GFM 值。最后，开发了一种感知感知轨迹规划算法。

Result: 通过模拟和真实世界实验证明，该方法能够让机器人主动选择显著提高 LiDAR 定位精度的轨迹。

Conclusion: GFM-Planner 框架通过引导机器人选择经过特征丰富区域的轨迹，显著提高了 LiDAR 定位精度。

Abstract: Like humans who rely on landmarks for orientation, autonomous robots depend
on feature-rich environments for accurate localization. In this paper, we
propose the GFM-Planner, a perception-aware trajectory planning framework based
on the geometric feature metric, which enhances LiDAR localization accuracy by
guiding the robot to avoid degraded areas. First, we derive the Geometric
Feature Metric (GFM) from the fundamental LiDAR localization problem. Next, we
design a 2D grid-based Metric Encoding Map (MEM) to efficiently store GFM
values across the environment. A constant-time decoding algorithm is further
proposed to retrieve GFM values for arbitrary poses from the MEM. Finally, we
develop a perception-aware trajectory planning algorithm that improves LiDAR
localization capabilities by guiding the robot in selecting trajectories
through feature-rich areas. Both simulation and real-world experiments
demonstrate that our approach enables the robot to actively select trajectories
that significantly enhance LiDAR localization accuracy.

</details>


### [305] [Distributed Oscillatory Guidance for Formation Flight of Fixed-Wing Drones](https://arxiv.org/abs/2507.16458)
*Yang Xu,Jesús Bautista,José Hinojosa,Héctor García de Marina*

Main category: cs.RO

TL;DR: 提出了一种新算法，通过在路径上叠加振荡来控制无人机编队，无需控制速度。


<details>
  <summary>Details</summary>
Motivation: 固定翼无人机的自主编队飞行由于需要对其速度进行协调，而其速度受到严格限制且主要设计为以标称空速飞行，因此难以实现。

Method: 提出了一种通过在引导向量场中叠加振荡行为来控制无人机沿特定路径（如平行直线）的平均速度的算法。无人机通过与邻近的代理进行通信，以闭环方式分布式地调整其振荡幅度，并引入了一种利用非负、非对称饱和函数的新型共识算法。

Result: 该算法通过数值模拟和真实世界编队飞行验证，证明了其在固定翼无人机编队飞行中的有效性，无需对其速度进行任何控制。

Conclusion: 该算法通过在引导向量场中叠加振荡行为来实现固定翼无人机的编队飞行，无需对其速度进行任何控制。通过调整振荡幅度，无人机能够分布式地协调其沿路径的平均速度，从而实现编队。

Abstract: The autonomous formation flight of fixed-wing drones is hard when the
coordination requires the actuation over their speeds since they are critically
bounded and aircraft are mostly designed to fly at a nominal airspeed. This
paper proposes an algorithm to achieve formation flights of fixed-wing drones
without requiring any actuation over their speed. In particular, we guide all
the drones to travel over specific paths, e.g., parallel straight lines, and we
superpose an oscillatory behavior onto the guiding vector field that drives the
drones to the paths. This oscillation enables control over the average velocity
along the path, thereby facilitating inter-drone coordination. Each drone
adjusts its oscillation amplitude distributively in a closed-loop manner by
communicating with neighboring agents in an undirected and connected graph. A
novel consensus algorithm is introduced, leveraging a non-negative, asymmetric
saturation function. This unconventional saturation is justified since negative
amplitudes do not make drones travel backward or have a negative velocity along
the path. Rigorous theoretical analysis of the algorithm is complemented by
validation through numerical simulations and a real-world formation flight.

</details>


### [306] [Trajectory Planning of a Curtain Wall Installation Robot Based on Biomimetic Mechanisms](https://arxiv.org/abs/2507.16305)
*Xiao Liu,Weijun Wang,Tianlun Huang,Zhiyong Wang,Wei Feng*

Main category: cs.RO

TL;DR: 通过模仿人类上肢负重运动，提出了一种用于施工机器人的生物启发式轨迹规划方法，使用PSO算法优化动力学负载分配，将能耗降低了48.4%。


<details>
  <summary>Details</summary>
Motivation: 为了解决建筑机器人（特别是施工机器人）在快速发展的机器人市场中面临的能源消耗关键问题及其应用限制，本研究从人类上肢负重运动的力学中汲取灵感，提出了一种包含人类能量转换原理的生物启发式轨迹规划框架。

Method: 本研究提出了一种生物启发式轨迹规划框架，通过收集人类在上肢负重运动（如哑铃弯举）中的运动轨迹和肌电信号（EMG），构建了集成人类发力和能耗模式的人体运动学轨迹规划。利用粒子群优化（PSO）算法，实现了基于类人运动特征的机器人手臂轨迹规划动力学负载分配。

Result: 通过将生物启发式运动特性应用于幕墙安装任务，验证了所提出的轨迹规划方法的正确性和优越性。仿真结果表明，通过动能和势能之间的智能转换，能耗降低了48.4%。

Conclusion: 本研究提出的生物启发式轨迹规划框架，通过整合人类能量转换原理和动力学负载分配，成功应用于幕墙安装机器人，实现了48.4%的能耗降低，为机器人节能优化提供了新的见解和理论支持。

Abstract: As the robotics market rapidly evolves, energy consumption has become a
critical issue, particularly restricting the application of construction
robots. To tackle this challenge, our study innovatively draws inspiration from
the mechanics of human upper limb movements during weight lifting, proposing a
bio-inspired trajectory planning framework that incorporates human energy
conversion principles. By collecting motion trajectories and electromyography
(EMG) signals during dumbbell curls, we construct an anthropomorphic trajectory
planning that integrates human force exertion patterns and energy consumption
patterns. Utilizing the Particle Swarm Optimization (PSO) algorithm, we achieve
dynamic load distribution for robotic arm trajectory planning based on
human-like movement features. In practical application, these bio-inspired
movement characteristics are applied to curtain wall installation tasks,
validating the correctness and superiority of our trajectory planning method.
Simulation results demonstrate a 48.4% reduction in energy consumption through
intelligent conversion between kinetic and potential energy. This approach
provides new insights and theoretical support for optimizing energy use in
curtain wall installation robots during actual handling tasks.

</details>


### [307] [Design and Dimensional Optimization of Legged Structures for Construction Robots](https://arxiv.org/abs/2507.16328)
*Xiao Liu,Xianlong Yang,Weijun Wang,Wei Feng*

Main category: cs.RO

TL;DR: 受蚂蚁启发，提出一种用于建筑机器人的腿部构型设计与优化方法，以提高其在复杂地形中的自主移动能力，并通过仿真优化了腿部结构。


<details>
  <summary>Details</summary>
Motivation: 为了应对轮式和履带式机器人在复杂非结构化施工环境下的地形适应性和灵活性限制，提升建筑机器人的自主移动能力。

Method: 通过运动学建模、多维度工作空间分析、引入“改进工作空间”和“平均操作性”的概念，并结合ADAMS虚拟原型仿真，优化了腿部构型设计。

Result: 获得了具有最佳综合运动性能的腿部结构比例。

Conclusion: 该研究提出了首个针对建筑环境的腿部运动性能多维度量化评估框架，为解决足式建筑机器人在复杂地形中自主移动的结构设计奠定了基础。

Abstract: Faced with complex and unstructured construction environments, wheeled and
tracked robots exhibit significant limitations in terrain adaptability and
flexibility, making it difficult to meet the requirements of autonomous
operation. Inspired by ants in nature, this paper proposes a leg configuration
design and optimization method tailored for construction scenarios, aiming to
enhance the autonomous mobility of construction robots. This paper analyzes the
full operational motion performance of the leg during both swing and stance
phases. First, based on kinematic modeling and multi-dimensional workspace
analysis, the concept of an "improved workspace" is introduced, and graphical
methods are used to optimize the leg dimensions during the swing phase.
Furthermore, a new concept of "average manipulability" is introduced based on
the velocity Jacobian matrix, and numerical solutions are applied to obtain the
leg segment ratio that maximizes manipulability. To overcome the difficulties
associated with traditional analytical methods, virtual prototype simulations
are conducted in ADAMS to explore the relationship between the robot body's
optimal flexibility and leg segment proportions. In summary, the leg segment
proportions with the best comprehensive motion performance are obtained. This
study presents the first multi-dimensional quantitative evaluation framework
for leg motion performance tailored for construction environments, providing a
structural design foundation for legged construction robots to achieve
autonomous mobility in complex terrains.

</details>


### [308] [Guided Reinforcement Learning for Omnidirectional 3D Jumping in Quadruped Robots](https://arxiv.org/abs/2507.16481)
*Riccardo Bussola,Michele Focchi,Giulio Turrisi,Claudio Semini,Luigi Palopoli*

Main category: cs.RO

TL;DR: 提出一种新的引导式强化学习方法，结合贝塞尔曲线和UARM模型，用于机器人高效、可解释、安全的跳跃控制。


<details>
  <summary>Details</summary>
Motivation: 现有机器人跳跃控制方法（如优化方法）耗时且需要详细的机器人和地形参数，鲁棒性差；而传统的端到端强化学习方法样本复杂度高，难以保证安全性和可预测性。

Method: 提出了一种结合贝塞尔曲线和匀加速直线运动（UARM）模型的引导式强化学习方法。

Result: 仿真和实验结果表明，所提出的方法在效率、可解释性和安全性方面优于现有方法。

Conclusion: 本文提出的结合贝塞尔曲线和匀加速直线运动（UARM）模型的引导式强化学习方法，在效率、可解释性和安全性方面优于现有方法，并在仿真和实验中得到了验证。

Abstract: Jumping poses a significant challenge for quadruped robots, despite being
crucial for many operational scenarios. While optimisation methods exist for
controlling such motions, they are often time-consuming and demand extensive
knowledge of robot and terrain parameters, making them less robust in
real-world scenarios. Reinforcement learning (RL) is emerging as a viable
alternative, yet conventional end-to-end approaches lack efficiency in terms of
sample complexity, requiring extensive training in simulations, and
predictability of the final motion, which makes it difficult to certify the
safety of the final motion. To overcome these limitations, this paper
introduces a novel guided reinforcement learning approach that leverages
physical intuition for efficient and explainable jumping, by combining B\'ezier
curves with a Uniformly Accelerated Rectilinear Motion (UARM) model. Extensive
simulation and experimental results clearly demonstrate the advantages of our
approach over existing alternatives.

</details>


### [309] [Topology Optimization of Leg Structures for Construction Robots Based on Variable Density Method](https://arxiv.org/abs/2507.16335)
*Xiao Liu,Xianlong Yang,Weijun Wang,Wei Feng*

Main category: cs.RO

TL;DR: 通过SIMP拓扑优化和结构再设计，成功实现了建筑机器人腿部轻量化，在减重的同时仍满足性能要求。


<details>
  <summary>Details</summary>
Motivation: 在复杂地形的施工环境中，机器人需要同时满足高负载能力和高移动灵活性的要求，而作为关键的承重部件，机器腿结构的优化尤为重要。

Method: 本文提出了一种基于SIMP（Solid Isotropic Microstructures with Penalization）变密度法的拓扑优化策略，并结合了结构再设计方法，对建筑机器人腿部结构进行了优化。

Result: 通过拓扑优化和结构再设计，研究成功将机器腿股骨部分的质量减小了19.45%，整体腿部质量也降低了7.92%，同时满足了结构性能要求，验证了轻量化设计的可行性。

Conclusion: 该研究为建筑机器人的轻量化设计提供了有力的理论和技术支持，并为其在复杂施工环境中的高效运行奠定了基础。

Abstract: In complex terrain construction environments, there are high demands for
robots to achieve both high payload capacity and mobility flexibility. As the
key load-bearing component, the optimization of robotic leg structures is of
particular importance. Therefore, this study focuses on the optimization of leg
structures for construction robots, proposing a topology optimization strategy
based on the SIMP (Solid Isotropic Microstructures with Penalization) variable
density method along with a structural re-design approach. The design
performance is comprehensively validated through finite element analysis using
ANSYS. First, static and modal analyses are conducted to evaluate the
rationality of the initial design. Then, topology optimization using the
SIMP-based variable density method is applied to the femur section, which
accounts for the largest proportion of the leg's weight. Based on iterative
calculations, the femur undergoes secondary structural reconstruction. After
optimization, the mass of the femur is reduced by 19.45\%, and the overall leg
mass decreases by 7.92\%, achieving the goal of lightweight design. Finally,
static and modal analyses are conducted on the reconstructed leg. The results
demonstrate that the optimized leg still meets structural performance
requirements, validating the feasibility of lightweight design. This research
provides robust theoretical and technical support for lightweight construction
robot design and lays a foundation for their efficient operation in complex
construction environments.

</details>


### [310] [Humanoid Robot Whole-body Geometric Calibration with Embedded Sensors and a Single Plane](https://arxiv.org/abs/2507.16369)
*Thanh D V Nguyen,Vincent Bonnet,Pierre Fernbach,David Daney,Florent Lamiraux*

Main category: cs.RO

TL;DR: 通过一种无需人工干预的新方法和IROC算法，成功简化了一中人形机器人的全身校准过程，并将误差减小了2.3倍。


<details>
  <summary>Details</summary>
Motivation: 传统的人形机器人全身几何校准方法耗时且实验负担重，在机器人社群中常被忽视，但它对精确控制和仿真至关重要。

Method: 提出了一种利用单平面、嵌入式力传感器和导纳控制器来校准人形机器人全身运动学的新颖实用方法。提出了一种名为IROC的新算法，用于从候选姿势中选择最优校准姿势。

Result: 所提出的方法在TALOS人形机器人上进行了实验验证，仅使用31个最优姿势和机器人夹爪在桌子上进行3点接触，就完成了整个全身运动学链的校准。与制造商的模型相比，在交叉验证实验中，平均均方根（RMS）误差减小了2.3倍。

Conclusion: 该研究提出了一种利用单平面、嵌入式力传感器和导纳控制器来校准人形机器人全身运动学的新颖实用方法，无需人工干预。此外，还提出了一种名为IROC的新算法，用于选择最优校准姿势。

Abstract: Whole-body geometric calibration of humanoid robots using classical robot
calibration methods is a timeconsuming and experimentally burdensome task.
However, despite its significance for accurate control and simulation, it is
often overlooked in the humanoid robotics community. To address this issue, we
propose a novel practical method that utilizes a single plane, embedded force
sensors, and an admittance controller to calibrate the whole-body kinematics of
humanoids without requiring manual intervention. Given the complexity of
humanoid robots, it is crucial to generate and determine a minimal set of
optimal calibration postures. To do so, we propose a new algorithm called IROC
(Information Ranking algorithm for selecting Optimal Calibration postures).
IROC requires a pool of feasible candidate postures to build a normalized
weighted information matrix for each posture. Then, contrary to other
algorithms from the literature, IROC will determine the minimal number of
optimal postures that are to be played onto a robot for its calibration. Both
IROC and the single-plane calibration method were experimentally validated on a
TALOS humanoid robot. The total whole-body kinematics chain was calibrated
using solely 31 optimal postures with 3-point contacts on a table by the robot
gripper. In a cross-validation experiment, the average root-mean-square (RMS)
error was reduced by a factor of 2.3 compared to the manufacturer's model.

</details>


### [311] [Application of LLM Guided Reinforcement Learning in Formation Control with Collision Avoidance](https://arxiv.org/abs/2507.16382)
*Chenhao Yao,Zike Yuan,Xiaoxu Liu,Chi Zhu*

Main category: cs.RO

TL;DR: 通过LLM动态生成奖励函数，提升了多智能体系统在编队控制和避障方面的效率。


<details>
  <summary>Details</summary>
Motivation: 在多智能体强化学习（MARL）中，为具有挑战性的编队控制和碰撞避免（FCCA）任务设计有效的奖励函数，以实现策略网络的快速收敛是一个关键挑战。

Method: 提出了一种新颖的框架，利用大型语言模型根据评估结果动态调整奖励函数，以优化多智能体强化学习中的任务。

Result: 所提出的框架能够使多智能体系统（MAS）在动态环境中同时实现编队控制和避障，并以更高的效率和更少的迭代次数达到更优的性能。

Conclusion: 该框架通过使用大型语言模型生成动态调整的奖励函数，实现了高效的协同控制和避障，并在仿真和现实世界中得到了验证。

Abstract: Multi-Agent Systems (MAS) excel at accomplishing complex objectives through
the collaborative efforts of individual agents. Among the methodologies
employed in MAS, Multi-Agent Reinforcement Learning (MARL) stands out as one of
the most efficacious algorithms. However, when confronted with the complex
objective of Formation Control with Collision Avoidance (FCCA): designing an
effective reward function that facilitates swift convergence of the policy
network to an optimal solution. In this paper, we introduce a novel framework
that aims to overcome this challenge. By giving large language models (LLMs) on
the prioritization of tasks and the observable information available to each
agent, our framework generates reward functions that can be dynamically
adjusted online based on evaluation outcomes by employing more advanced
evaluation metrics rather than the rewards themselves. This mechanism enables
the MAS to simultaneously achieve formation control and obstacle avoidance in
dynamic environments with enhanced efficiency, requiring fewer iterations to
reach superior performance levels. Our empirical studies, conducted in both
simulation and real-world settings, validate the practicality and effectiveness
of our proposed approach.

</details>


### [312] [AI or Human? Understanding Perceptions of Embodied Robots with LLMs](https://arxiv.org/abs/2507.16398)
*Lavinia Hriscu,Alberto Sanfeliu,Anais Garrell*

Main category: cs.RO

TL;DR: 本研究在机器人平台上进行图灵测试，发现参与者无法区分AI和人类控制的机器人，为设计未来交互式机器人提供了见解。


<details>
  <summary>Details</summary>
Motivation: 尽管图灵测试被引入作为评估系统智能的手段，但其在人机交互中的相关性和应用仍未得到充分探索。

Method: 通过在机器人平台上进行图灵测试来研究具身机器人的智能感知，让34名参与者在信息检索和包裹交接任务中区分AI和人类操作的机器人。

Result: 参与者无法可靠地区分AI和人类控制的机器人，超出随机水平。分析参与者对机器人感知和导航能力的评估。

Conclusion: 参与者无法可靠地区分人工智能和人类控制的机器人，超出随机水平。分析揭示了影响感知人工智能与人类智能的关键因素。

Abstract: The pursuit of artificial intelligence has long been associated to the the
challenge of effectively measuring intelligence. Even if the Turing Test was
introduced as a means of assessing a system intelligence, its relevance and
application within the field of human-robot interaction remain largely
underexplored. This study investigates the perception of intelligence in
embodied robots by performing a Turing Test within a robotic platform. A total
of 34 participants were tasked with distinguishing between AI- and
human-operated robots while engaging in two interactive tasks: an information
retrieval and a package handover. These tasks assessed the robot perception and
navigation abilities under both static and dynamic conditions. Results indicate
that participants were unable to reliably differentiate between AI- and
human-controlled robots beyond chance levels. Furthermore, analysis of
participant responses reveals key factors influencing the perception of
artificial versus human intelligence in embodied robotic systems. These
findings provide insights into the design of future interactive robots and
contribute to the ongoing discourse on intelligence assessment in AI-driven
systems.

</details>


### [313] [A Target-based Multi-LiDAR Multi-Camera Extrinsic Calibration System](https://arxiv.org/abs/2507.16621)
*Lorenzo Gentilini,Pierpaolo Serio,Valentina Donzella,Lorenzo Pollini*

Main category: cs.RO

TL;DR: 提出一种基于ChArUco板和非线性优化的多激光雷达-摄像头外参标定方法，并在真实世界数据中验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 现代传感器系统收集不同类型的数据，使得数据对齐更加困难。为了解决这个问题，我们提出了一种针对多激光雷达和多摄像机传感器套件的基于目标的外部标定系统。

Method: 使用定制的ChArUco板和定制的非线性优化方法，进行基于目标的激光雷达-摄像头交叉标定。

Result: 在仓库的真实世界数据中测试了该系统，结果证明了所提出方法的有效性，并突显了为各种传感器量身定制的独特管线的可行性。

Conclusion: 提出的基于目标的标定系统可实现激光雷达和摄像头之间的交叉标定，且仅需有限的先验知识，并采用定制的ChArUco板和非线性优化方法。该方法在仓库的真实世界数据中得到了测试，结果证明了其有效性，并突显了为多种传感器量身定制的独特管线的可行性。

Abstract: Extrinsic Calibration represents the cornerstone of autonomous driving. Its
accuracy plays a crucial role in the perception pipeline, as any errors can
have implications for the safety of the vehicle. Modern sensor systems collect
different types of data from the environment, making it harder to align the
data. To this end, we propose a target-based extrinsic calibration system
tailored for a multi-LiDAR and multi-camera sensor suite. This system enables
cross-calibration between LiDARs and cameras with limited prior knowledge using
a custom ChArUco board and a tailored nonlinear optimization method. We test
the system with real-world data gathered in a warehouse. Results demonstrated
the effectiveness of the proposed method, highlighting the feasibility of a
unique pipeline tailored for various types of sensors.

</details>


### [314] [Morpheus: A Neural-driven Animatronic Face with Hybrid Actuation and Diverse Emotion Control](https://arxiv.org/abs/2507.16645)
*Zongzheng Zhang,Jiawen Yang,Ziqiao Peng,Meng Yang,Jianzhu Ma,Lin Cheng,Huazhe Xu,Hang Zhao,Hao Zhao*

Main category: cs.RO

TL;DR: 本研究通过混合驱动硬件和自建模网络算法，克服了动画面部表达情绪的局限性，实现了从语音到逼真、细致面部表情的自动生成。


<details>
  <summary>Details</summary>
Motivation: 解决先前动画面部在硬件和软件方面的限制，这些限制导致它们难以有效表达情绪。先前的刚性驱动器控制精度高但难以小型化，而绳索驱动器虽然节省空间但控制困难。算法方面，需要一种方法来自动建立运动控制与面部表情之间的联系，并能根据语音生成逼真的面部表情。

Method: 提出了一种混合驱动方法，将刚性驱动和绳索驱动结合起来，用于控制面部特征，其中眼睛和嘴巴等关键区域采用刚性驱动，而鼻子和脸颊等传递细微面部微表情的区域采用绳索驱动。算法上，引入了自建模网络，将运动动作映射到面部地标，通过梯度反向传播自动建立混合形状系数与相应的运动控制信号之间的关系。最后，训练了一个神经网络，将语音输入映射到相应的混合形状控制。

Result: 成功构建了一个紧凑且多功能的硬件平台，能够表达多种情绪。通过自建模网络和语音到表情的神经网络，实现了从任意句子生成喜悦、恐惧、厌恶和愤怒等独特情绪表达，并具有细致、特定于情绪的控制信号。

Conclusion: 本研究提出的混合驱动方法结合了刚性驱动和绳索驱动的优点，能够构建出紧凑且多功能的硬件平台，并能有效表达多种情绪。算法方面，通过自建模网络将语音输入映射到面部表情控制，实现了从任意句子生成喜悦、恐惧、厌恶和愤怒等独特情绪表达，并具有细致、特定于情绪的控制信号，这是先前系统所未能实现的。

Abstract: Previous animatronic faces struggle to express emotions effectively due to
hardware and software limitations. On the hardware side, earlier approaches
either use rigid-driven mechanisms, which provide precise control but are
difficult to design within constrained spaces, or tendon-driven mechanisms,
which are more space-efficient but challenging to control. In contrast, we
propose a hybrid actuation approach that combines the best of both worlds. The
eyes and mouth-key areas for emotional expression-are controlled using rigid
mechanisms for precise movement, while the nose and cheek, which convey subtle
facial microexpressions, are driven by strings. This design allows us to build
a compact yet versatile hardware platform capable of expressing a wide range of
emotions. On the algorithmic side, our method introduces a self-modeling
network that maps motor actions to facial landmarks, allowing us to
automatically establish the relationship between blendshape coefficients for
different facial expressions and the corresponding motor control signals
through gradient backpropagation. We then train a neural network to map speech
input to corresponding blendshape controls. With our method, we can generate
distinct emotional expressions such as happiness, fear, disgust, and anger,
from any given sentence, each with nuanced, emotion-specific control signals-a
feature that has not been demonstrated in earlier systems. We release the
hardware design and code at https://github.com/ZZongzheng0918/Morpheus-Hardware
and https://github.com/ZZongzheng0918/Morpheus-Software.

</details>


### [315] [Experience is the Best Teacher: Grounding VLMs for Robotics through Self-Generated Memory](https://arxiv.org/abs/2507.16713)
*Guowei Lan,Kaixian Qu,René Zurbrügg,Changan Chen,Christopher E. Mower,Haitham Bou-Ammar,Marco Hutter*

Main category: cs.RO

TL;DR: ExpTeach通过自生成记忆和检索增强生成（RAG）来解决机器人视觉语言模型（VLM）的接地问题，显著提高了成功率和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 将为互联网数据训练的视觉语言模型（VLMs）有效应用于多样化的真实世界机器人是一个持续存在的挑战。因此，需要一个框架来解决VLM与物理机器人之间的接地问题。

Method: ExpTeach框架通过闭环的方式，让VLM自主规划动作、验证结果、反思失败并调整机器人行为。在此过程中，框架会生成自我经验，并将其总结成长期的记忆，通过检索增强生成（RAG）来指导未来的任务。此外，ExpTeach还包含一个按需图像注释模块，用于增强VLMs的空间理解能力。

Result: ExpTeach框架在四个具有挑战性的机器人任务中，通过反思机制将成功率从36%提高到84%，并观察到智能物体交互（包括创造性工具使用）的出现。在12个真实世界场景（包括8个未见过场景）的广泛测试中，使用长期记忆进行接地将单次试验成功率从22%提高到80%，证明了ExpTeach的有效性和泛化能力。

Conclusion: ExpTeach框架通过自生成真实世界经验的长期记忆，有效解决了视觉语言模型（VLMs）在物理机器人上的接地问题。实验证明，该框架显著提高了机器人在各种任务中的成功率，并展现了智能交互能力，包括创造性工具使用。通过检索增强生成（RAG）和按需图像注释模块，ExpTeach能够检索学习到的知识以指导未来的任务，并增强VLMs的空间理解能力，证明了其在机器人应用中的有效性和泛化性。

Abstract: Vision-language models (VLMs) have been widely adopted in robotics to enable
autonomous planning. However, grounding VLMs, originally trained on internet
data, to diverse real-world robots remains a challenge. This paper presents
ExpTeach, a framework that grounds VLMs to physical robots by building a
self-generated memory of real-world experiences. In ExpTeach, the VLM
autonomously plans actions, verifies outcomes, reflects on failures, and adapts
robot behaviors in a closed loop. The self-generated experiences during this
process are then summarized into a long-term memory, enabling retrieval of
learned knowledge to guide future tasks via retrieval-augmented generation
(RAG). Additionally, ExpTeach enhances the spatial understanding of VLMs with
an on-demand image annotation module. In experiments, we show that reflection
improves success rates from 36% to 84% on four challenging robotic tasks and
observe the emergence of intelligent object interactions, including creative
tool use. Across extensive tests on 12 real-world scenarios (including eight
unseen ones), we find that grounding with long-term memory boosts single-trial
success rates from 22% to 80%, demonstrating the effectiveness and
generalizability of ExpTeach.

</details>


<div id='cs.DC'></div>

# cs.DC [[Back]](#toc)

### [316] [Parallel Ray Tracing of Black Hole Images Using the Schwarzschild Metric](https://arxiv.org/abs/2507.16165)
*Liam Naddell,Marcelo Ponce*

Main category: cs.DC

TL;DR: 该研究实现了一个开源程序，用于在黑洞几何体存在的情况下进行光线追踪渲染，结合了多种并行计算技术。


<details>
  <summary>Details</summary>
Motivation: 为了在黑洞几何体存在的情况下进行光线追踪图像渲染，并且该技术也广泛应用于计算机图形学领域。

Method: 通过结合数学近似、科学计算库的使用、共享内存和分布式内存并行性等技术来实现。

Result: 实现了一个可以进行光线追踪的开源程序。

Conclusion: 该程序将用于科学和天体物理可视化领域

Abstract: Rendering images of black holes by utilizing ray tracing techniques is a
common methodology employed in many aspects of scientific and astrophysical
visualizations. Similarly, general ray tracing techniques are widely used in
areas related to computer graphics. In this work we describe the implementation
of a parallel open-source program that can ray trace images in the presence of
a black hole geometry. We do this by combining a couple of different techniques
usually present in parallel scientific computing, such as, mathematical
approximations, utilization of scientific libraries, shared-memory and
distributed-memory parallelism.

</details>


### [317] [Resilience Evaluation of Kubernetes in Cloud-Edge Environments via Failure Injection](https://arxiv.org/abs/2507.16109)
*Zihao Chen,Mohammad Goudarzi,Adel Nadjaran Toosi*

Main category: cs.DC

TL;DR: 本研究提出了一个框架，用于评估Kubernetes在云和边缘环境中的弹性，并创建了一个包含超11,000个故障场景的数据集。结果显示，云-边缘部署在网络中断时更稳定，而云部署在带宽受限时更具弹性。


<details>
  <summary>Details</summary>
Motivation: 随着Kubernetes在关键任务微服务中的应用日益广泛，在真实的故障条件下评估其系统弹性至关重要。然而，目前对混合云-边缘环境中Kubernetes的系统性弹性评估研究有限。

Method: 研究人员提出并实现了一个集成了主流故障注入工具（Chaos Mesh、Gremlin、ChaosBlade）和自动化工作负载生成的新型弹性评估框架，用于对云-边缘Kubernetes进行全面的测试。该框架能够自动编排复杂的故障场景，包括节点级、Pod级和网络故障。

Result: 研究人员创建了首个混合云-边缘Kubernetes部署的全面弹性数据集，包含来自11,965个故障注入场景的30GB以上性能数据，如响应时间、故障率和错误模式。实验结果表明，云-边缘部署在网络延迟和分区条件下响应稳定性提高了80%，而云部署在带宽限制下弹性提高了47%。

Conclusion: Kubernetes在混合云-边缘环境中的弹性评估已完成。云-边缘部署在网络延迟和分区条件下表现出更稳定的响应（提高80%），而云部署在带宽限制下具有更好的弹性（提高47%），为云-边缘部署的架构决策提供了量化指导。

Abstract: Kubernetes has emerged as an essential platform for deploying containerised
applications across cloud and edge infrastructures. As Kubernetes gains
increasing adoption for mission-critical microservices, evaluating system
resilience under realistic fault conditions becomes crucial. However,
systematic resilience assessments of Kubernetes in hybrid cloud-edge
environments are currently limited in research. To address this gap, a novel
resilience evaluation framework integrates mainstream fault injection tools
with automated workload generation for comprehensive cloud-edge Kubernetes
testing. Multiple fault injection platforms, including Chaos Mesh, Gremlin, and
ChaosBlade are combined with realistic traffic simulation tools, enabling
automated orchestration of complex failure scenarios. Through this framework,
comprehensive experiments are conducted that systematically target node-level,
pod-level, and network failures across cloud and cloud-edge environments. The
first comprehensive resilience dataset for hybrid cloud-edge Kubernetes
deployments is created, comprising over 30 GB of performance data from 11,965
fault injection scenarios including response times, failure rates, and error
patterns. Analysis reveals that cloud-edge deployments demonstrate 80% superior
response stability under network delay and partition conditions, while cloud
deployments exhibit 47% better resilience under bandwidth limitations,
providing quantitative guidance for architectural decision-making in cloud-edge
deployments.

</details>


### [318] [Autonomous Dominant Resource Fairness for Blockchain Ecosystems](https://arxiv.org/abs/2507.16350)
*Serdar Metin*

Main category: cs.DC

TL;DR: 该研究提出了一种名为自主支配资源的智能合约算法，用于解决区块链中多资源分配问题。该算法能有效管理多种资源，且汽油成本低。


<details>
  <summary>Details</summary>
Motivation: 解决在资源管理中，特别是区块链环境中，如何分配多种资源类型给具有不同资源需求的任务的问题，现有方法通常将多资源问题简化为单资源问题或标准化资源包分配。

Method: 提出了一种名为自主支配资源公平（Autonomous Dominant Resource Fairness）的智能合约算法，该算法是支配资源公平（Dominant Resource Fairness）算法的适应版本，通过避免循环迭代来逼近支配资源公平。

Result: 结果表明，自主支配资源公平算法是一种汽油成本效益高的算法，能够管理多种资源类型（达数百种）和无限数量的用户。

Conclusion: 该研究提出了一种名为自主支配资源公平（Autonomous Dominant Resource Fairness）的智能合约算法，用于解决异构资源需求任务的多资源类型分配问题。该算法是支配资源公平（Dominant Resource Fairness）算法的智能合约适应版本，通过避免循环迭代来逼近支配资源公平，这在区块链环境中具有优势，因为它能克服区块汽油限制。

Abstract: Blockchain systems have been a part of mainstream academic research, and a
hot topic at that. It has spread to almost every subfield in the computer
science literature, as well as economics and finance. Especially in a world
where digital trust is much sought for, blockchains offer a rich variety of
desired properties, such as immutability, public auditing, decentralised record
keeping, among others. Not only has it been a research topic of its own, the
integration of blockchains into other systems has been proposed as solutions in
many areas, ranging from grid computing, cloud and fog computing, to internet
of things, self driving vehicles , and smart cities. In many cases the primary
function attributed to blockchains in these contexts is resource management.
Although much attention is paid to this topic, the focus is on single resource
allocation scenarios. Even the cases where multiple resource types are to be
allocated, are treated as single resource type scenarios, and problems are
formulated as allocating standardised bundles consisting of a fixed amount of
each of them, such as virtual machines. The present study addresses the problem
of allocating multiple resource types among tasks with heterogeneous resource
demands with a smart contract adaptation of Precomputed Dominant Resource
Fairness; an algorithm that approximates Dominant Resource Fairness, without
loop iterations, which makes it preferable in the blockchain context because of
the block gas limit. We present the resulting algorithm, Autonomous Dominant
Resource Fairness, along with the empirical data collected from the tests run
on the algorithm. The results show that Autonomous Dominant Resource Fairness
is a gas-cost efficient algorithm, which can be used to manage hundreds of
resource types for unlimited number of users.

</details>


### [319] [FOGNITE: Federated Learning-Enhanced Fog-Cloud Architecture](https://arxiv.org/abs/2507.16668)
*Somayeh Sobati-M*

Main category: cs.DC

TL;DR: FOGNITE是一个基于雾计算的网格智能框架，通过联邦学习、强化学习和数字孪生来提高分布式能源系统的自主性、弹性和效率。


<details>
  <summary>Details</summary>
Motivation: 现代智能电网需要在边缘进行快速、智能和能源感知的计算，以管理实时波动并确保可靠运行。

Method: FOGNITE结合了联邦学习、强化学习和数字孪生验证三个核心组件。每个雾节点在私有能耗数据上训练本地CNN LSTM模型，通过联邦聚合实现预测智能并保护数据隐私。强化学习代理根据当前系统负载和能源状况动态调度任务，以在不确定性下优化性能。为了防止不安全或低效的决策，分层数字孪生层在部署前模拟潜在操作，显著减少了执行错误和能源浪费。

Result: 在真实世界的树莓派设备测试平台上对FOGNITE进行了评估，与传统架构相比，FOGNITE在负载均衡准确性方面提高了93.7%，在能源浪费方面降低了63.2%。

Conclusion: FOGNITE通过将智能电网控制从被动纠正转向主动优化，代表着迈向更智能、更具适应性和可持续性的能源基础设施的一步。

Abstract: Modern smart grids demand fast, intelligent, and energy-aware computing at
the edge to manage real time fluctuations and ensure reliable operation. This
paper introduces FOGNITE Fog-based Grid In intelligence with Neural Integration
and Twin based Execution a next-generation fog cloud framework designed to
enhance autonomy, resilience, and efficiency in distributed energy systems.
FOGNITE combines three core components: federated learning, reinforcement
learning, and digital twin validation. Each fog node trains a local CNN LSTM
model on private energy consumption data, enabling predictive intelligence
while preserving data privacy through federated aggregation. A reinforcement
learning agent dynamically schedules tasks based on current system load and
energy conditions, optimizing for performance under uncertainty.
  To prevent unsafe or inefficient decisions, a hierarchical digital twin layer
simulates potential actions before deployment, significantly reducing execution
errors and energy waste. We evaluate FOGNITE on a real world testbed of
Raspberry Pi devices, showing up to a 93.7% improvement in load balancing
accuracy and a 63.2% reduction in energy waste compared to conventional
architectures. By shifting smart grid control from reactive correction to
proactive optimization, FOGNITE represents a step toward more intelligent,
adaptive, and sustainable energy infrastructures

</details>


### [320] [AcceleratedKernels.jl: Cross-Architecture Parallel Algorithms from a Unified, Transpiled Codebase](https://arxiv.org/abs/2507.16710)
*Andrei-Leonard Nicusan,Dominik Werner,Simon Branford,Simon Hartley,Andrew J. Morris,Kit Windows-Yule*

Main category: cs.DC

TL;DR: AcceleratedKernels.jl is a Julia library for parallel computing on various accelerators. It offers CPU-like performance, enables CPU-GPU co-processing, and achieves high sorting throughputs on GPUs, especially with NVLink interconnects, making GPU computing cost-effective for communication-heavy tasks.


<details>
  <summary>Details</summary>
Motivation: To provide a productive and efficient parallel computing library in Julia that can leverage diverse hardware accelerators with minimized complexity, enabling high performance and composability.

Method: Introduces AcceleratedKernels.jl, a backend-agnostic library for parallel computing in Julia that targets various accelerators through a transpilation architecture. It utilizes a unified codebase for productive parallel programming and enables CPU-GPU co-processing.

Result: Benchmarks show AcceleratedKernels.jl achieves performance comparable to C and OpenMP-multithreaded CPU implementations, with improved numerical consistency. It demonstrates world-class sorting throughputs on NVIDIA A100 GPUs (538-855 GB/s) and shows significant speedups (4.93x) when using NVLink GPU-to-GPU interconnects, making communication-heavy HPC tasks economically viable on GPUs.

Conclusion: AcceleratedKernels.jl achieves world-class sorting throughputs on HPC clusters, demonstrating the viability of GPU computing for communication-heavy tasks when utilizing direct interconnects like NVLink. It also shows competitive performance with CPU implementations and highlights exceptional composability through CPU-GPU co-processing.

Abstract: AcceleratedKernels.jl is introduced as a backend-agnostic library for
parallel computing in Julia, natively targeting NVIDIA, AMD, Intel, and Apple
accelerators via a unique transpilation architecture. Written in a unified,
compact codebase, it enables productive parallel programming with minimised
implementation and usage complexities. Benchmarks of arithmetic-heavy kernels
show performance on par with C and OpenMP-multithreaded CPU implementations,
with Julia sometimes offering more consistent and predictable numerical
performance than conventional C compilers. Exceptional composability is
highlighted as simultaneous CPU-GPU co-processing is achievable - such as
CPU-GPU co-sorting - with transparent use of hardware-specialised MPI
implementations. Tests on the Baskerville Tier 2 UK HPC cluster achieved
world-class sorting throughputs of 538-855 GB/s using 200 NVIDIA A100 GPUs,
comparable to the highest literature-reported figure of 900 GB/s achieved on
262,144 CPU cores. The use of direct NVLink GPU-to-GPU interconnects resulted
in a 4.93x speedup on average; normalised by a combined capital, running and
environmental cost, communication-heavy HPC tasks only become economically
viable on GPUs if GPUDirect interconnects are employed.

</details>


### [321] [Collaborative Inference and Learning between Edge SLMs and Cloud LLMs: A Survey of Algorithms, Execution, and Open Challenges](https://arxiv.org/abs/2507.16731)
*Senyao Li,Haozhao Wang,Wenchao Xu,Rui Zhang,Song Guo,Jingling Yuan,Xian Zhong,Tianwei Zhang,Ruixuan Li*

Main category: cs.DC

TL;DR: 本调查探讨了云端LLM和边缘端SLM在推理和训练中的协作范式，为实现高效、可扩展和值得信赖的边缘-云智能奠定了基础。


<details>
  <summary>Details</summary>
Motivation: 随着大型语言模型（LLM）的发展，仅在云端部署或为边缘设备压缩它们已变得不充分，这主要是由于对延迟、隐私、成本和个性化的担忧。

Method: 本文对LLM和SLM在云端和边缘端的协作进行了全面的调查，涵盖了推理和训练两个方面。在推理方面，将方法分为任务分配、任务划分和基于混合的协作，并细分为任务和令牌粒度，包括自适应调度、资源感知卸载、投机解码和模块化路由。在训练方面，回顾了参数对齐、剪枝、双向蒸馏和小模型引导优化等分布式适应技术。此外，还总结了数据集、基准测试和部署案例，并强调了隐私保护方法和垂直应用。

Result: 该调查为LLM-SLM协作提供了第一个系统性基础，弥合了系统和算法的协同设计，以实现高效、可扩展且值得信赖的边缘-云智能。

Conclusion: LLM-SLM协作提供了高效、可扩展且值得信赖的边缘-云智能的基础。

Abstract: As large language models (LLMs) evolve, deploying them solely in the cloud or
compressing them for edge devices has become inadequate due to concerns about
latency, privacy, cost, and personalization. This survey explores a
collaborative paradigm in which cloud-based LLMs and edge-deployed small
language models (SLMs) cooperate across both inference and training. We present
a unified taxonomy of edge-cloud collaboration strategies. For inference, we
categorize approaches into task assignment, task division, and mixture-based
collaboration at both task and token granularity, encompassing adaptive
scheduling, resource-aware offloading, speculative decoding, and modular
routing. For training, we review distributed adaptation techniques, including
parameter alignment, pruning, bidirectional distillation, and
small-model-guided optimization. We further summarize datasets, benchmarks, and
deployment cases, and highlight privacy-preserving methods and vertical
applications. This survey provides the first systematic foundation for LLM-SLM
collaboration, bridging system and algorithm co-design to enable efficient,
scalable, and trustworthy edge-cloud intelligence.

</details>


### [322] [Cooling Matters: Benchmarking Large Language Models and Vision-Language Models on Liquid-Cooled Versus Air-Cooled H100 GPU Systems](https://arxiv.org/abs/2507.16781)
*Imran Latif,Muhammad Ali Shafique,Hayat Ullah,Alex C. Newkirk,Xi Yu,Arslan Munir*

Main category: cs.DC

TL;DR: 液冷比风冷在AI工作负载下性能更好，能效更高。


<details>
  <summary>Details</summary>
Motivation: AI工作负载（特别是LLM和VLM）的增长导致数据中心对电力和散热的需求增加，需要评估不同的冷却技术。

Method: 使用GPU Burn、Weights and Biases和IPMItool在配备NVIDIA H100 GPU的HGX节点上对LLM和VLM进行基准测试，并收集热、功耗和计算数据，对比液冷和风冷系统。

Result: 液冷系统的GPU温度保持在41-50摄氏度，而风冷系统在负载下为54-72摄氏度。液冷系统性能高出17%（每GPU 54 TFLOPs vs 46 TFLOPs），能效更高，能耗更低。

Conclusion: 液冷系统在AI工作负载下表现出更高的性能、能效和系统效率，为超大规模数据中心提供可持续的解决方案。

Abstract: The unprecedented growth in artificial intelligence (AI) workloads, recently
dominated by large language models (LLMs) and vision-language models (VLMs),
has intensified power and cooling demands in data centers. This study
benchmarks LLMs and VLMs on two HGX nodes, each with 8x NVIDIA H100 graphics
processing units (GPUs), using liquid and air cooling. Leveraging GPU Burn,
Weights and Biases, and IPMItool, we collect detailed thermal, power, and
computation data. Results show that the liquid-cooled systems maintain GPU
temperatures between 41-50 degrees Celsius, while the air-cooled counterparts
fluctuate between 54-72 degrees Celsius under load. This thermal stability of
liquid-cooled systems yields 17 percent higher performance (54 TFLOPs per GPU
vs. 46 TFLOPs per GPU), improved performance per watt, reduced energy overhead,
and greater system efficiency than the air-cooled counterparts. These findings
underscore the energy and sustainability benefits of liquid cooling, offering a
compelling path forward for hyperscale data centers s

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [323] [Quantifying Holistic Review: A Multi-Modal Approach to College Admissions Prediction](https://arxiv.org/abs/2507.15862)
*Jun-Wei Zeng,Jerry Shen*

Main category: cs.LG

TL;DR: 提出CAPS框架，使用多模态方法（SAS, EQI, EIS）和Transformer、LLM、XGBoost来量化和解释大学招生评估，提高透明度和公平性，并在模拟数据上取得了良好效果。


<details>
  <summary>Details</summary>
Motivation: 传统的高等教育招生评估过程（特别是整体评估）存在不透明、不一致以及给申请者带来焦虑等关键问题。本研究旨在通过量化和解释的方式来改进这种评估。

Method: 提出了一种名为CAPS（Comprehensive Applicant Profile Score）的新型多模态框架，将申请者画像分解为学术成绩（SAS）、文书质量（EQI）和课外活动（EIS）三个可解释的组成部分。该框架利用了基于Transformer的语义嵌入、大型语言模型（LLM）评分和XGBoost回归技术。

Result: 在合成但真实的模拟数据集上进行实验，CAPS框架在EQI预测上达到了0.80的R^2值，分类准确率超过75%，宏观F1分数达到0.69，加权F1分数达到0.74。

Conclusion: CAPS框架为大学招生提供了一个透明、可解释且数据驱动的解决方案，解决了传统录取流程中的不透明、不一致和焦虑问题，有望实现更公平的招生实践。

Abstract: This paper introduces the Comprehensive Applicant Profile Score (CAPS), a
novel multi-modal framework designed to quantitatively model and interpret
holistic college admissions evaluations. CAPS decomposes applicant profiles
into three interpretable components: academic performance (Standardized
Academic Score, SAS), essay quality (Essay Quality Index, EQI), and
extracurricular engagement (Extracurricular Impact Score, EIS). Leveraging
transformer-based semantic embeddings, LLM scoring, and XGBoost regression,
CAPS provides transparent and explainable evaluations aligned with human
judgment. Experiments on a synthetic but realistic dataset demonstrate strong
performance, achieving an EQI prediction R^2 of 0.80, classification accuracy
over 75%, a macro F1 score of 0.69, and a weighted F1 score of 0.74. CAPS
addresses key limitations in traditional holistic review -- particularly the
opacity, inconsistency, and anxiety faced by applicants -- thus paving the way
for more equitable and data-informed admissions practices.

</details>


### [324] [Fast-VAT: Accelerating Cluster Tendency Visualization using Cython and Numba](https://arxiv.org/abs/2507.15904)
*MSR Avinash,Ismael Lachheb*

Main category: cs.LG

TL;DR: Fast-VAT is a high-performance reimplementation of the VAT algorithm that significantly improves speed and memory efficiency while maintaining output fidelity.


<details>
  <summary>Details</summary>
Motivation: The standard implementation of Visual Assessment of Cluster Tendency (VAT) suffers from significant performance limitations due to its O(n^2) time complexity and inefficient memory usage.

Method: Reimplementation of the VAT algorithm in Python using Numba

Result: Fast-VAT achieves up to 50x speedup over the baseline implementation. The method was validated on real and synthetic datasets and cluster tendency was verified using Hopkins statistics, PCA, and t-SNE. VAT

Conclusion: Fast-VAT preserves the output fidelity of the original VAT method while achieving up to 50x speedup.

Abstract: Visual Assessment of Cluster Tendency (VAT) is a widely used unsupervised
technique to assess the presence of cluster structure in unlabeled datasets.
However, its standard implementation suffers from significant performance
limitations due to its O(n^2) time complexity and inefficient memory usage. In
this work, we present Fast-VAT, a high-performance reimplementation of the VAT
algorithm in Python, augmented with Numba's Just-In-Time (JIT) compilation and
Cython's static typing and low-level memory optimizations. Our approach
achieves up to 50x speedup over the baseline implementation, while preserving
the output fidelity of the original method. We validate Fast-VAT on a suite of
real and synthetic datasets -- including Iris, Mall Customers, and Spotify
subsets -- and verify cluster tendency using Hopkins statistics, PCA, and
t-SNE. Additionally, we compare VAT's structural insights with clustering
results from DBSCAN and K-Means to confirm its reliability.

</details>


### [325] [RDMA: Cost Effective Agent-Driven Rare Disease Discovery within Electronic Health Record Systems](https://arxiv.org/abs/2507.15867)
*John Wu,Adam Cross,Jimeng Sun*

Main category: cs.LG

TL;DR: RDMA框架通过模仿医学专家的方法，解决了电子健康记录中罕见病信息编码不全的问题，在提高性能和降低成本的同时保护了隐私。


<details>
  <summary>Details</summary>
Motivation: 标准ICD编码系统无法充分捕捉电子健康记录中的罕见病信息，现有方法存在处理缩写、隐含提及、隐私和临床推理等方面的缺陷。

Method: RDMA框架，通过模仿医学专家识别罕见病模式的方式，连接电子健康记录中的零散临床观察，并能处理缩写、识别隐含提及、进行本地推理，从而降低隐私风险。

Result: RDMA框架将F1性能提高了30%以上，并将推理成本降低了10倍，同时减少了使用云服务的隐私风险。

Conclusion: RDMA框架通过连接零散的临床观察来识别罕见病模式，解决了现有方法在处理缩写、隐含提及、隐私和临床推理方面的不足，在提高F1性能的同时降低了推理成本，并减少了隐私风险。

Abstract: Rare diseases affect 1 in 10 Americans, yet standard ICD coding systems fail
to capture these conditions in electronic health records (EHR), leaving crucial
information buried in clinical notes. Current approaches struggle with medical
abbreviations, miss implicit disease mentions, raise privacy concerns with
cloud processing, and lack clinical reasoning abilities. We present Rare
Disease Mining Agents (RDMA), a framework that mirrors how medical experts
identify rare disease patterns in EHR. RDMA connects scattered clinical
observations that together suggest specific rare conditions. By handling
clinical abbreviations, recognizing implicit disease patterns, and applying
contextual reasoning locally on standard hardware, RDMA reduces privacy risks
while improving F1 performance by upwards of 30\% and decreasing inferences
costs 10-fold. This approach helps clinicians avoid the privacy risk of using
cloud services while accessing key rare disease information from EHR systems,
supporting earlier diagnosis for rare disease patients. Available at
https://github.com/jhnwu3/RDMA.

</details>


### [326] [An open dataset of neural networks for hypernetwork research](https://arxiv.org/abs/2507.15869)
*David Kurtenbach,Lior Shamir*

Main category: cs.LG

TL;DR: 我们构建了一个包含10,000个LeNet-5神经网络的数据集，用于支持超网络研究。该数据集可用于区分不同的神经网络，初步分类准确率为72.0%。


<details>
  <summary>Details</summary>
Motivation: 尽管人工智能具有变革潜力，但能够通过生成模型权重（超网络）来产生其他神经网络的神经网络概念在很大程度上未被充分研究。研究资源匮乏是可能的原因之一。因此，我们描述了一个专为超网络研究设计的数据集。

Method: 构建了一个包含10,000个LeNet-5神经网络的数据集，每个网络都针对ImageNette V2数据集的一个二元图像分类任务进行了训练，并且每个类别的1,000个网络都能从所有其他类中识别出特定的ImageNette V2类别。数据集的生成使用了超过10,000个核心的计算集群。

Result: 所提出的神经网络可以被分类，准确率为72.0%，这表明可以通过监督机器学习算法识别神经网络之间的差异。

Conclusion: 该数据集旨在促进超网络研究，并已公开提供。未来研究可以利用此数据集来探索超网络的潜力。

Abstract: Despite the transformative potential of AI, the concept of neural networks
that can produce other neural networks by generating model weights
(hypernetworks) has been largely understudied. One of the possible reasons is
the lack of available research resources that can be used for the purpose of
hypernetwork research. Here we describe a dataset of neural networks, designed
for the purpose of hypernetworks research. The dataset includes $10^4$ LeNet-5
neural networks trained for binary image classification separated into 10
classes, such that each class contains 1,000 different neural networks that can
identify a certain ImageNette V2 class from all other classes. A computing
cluster of over $10^4$ cores was used to generate the dataset. Basic
classification results show that the neural networks can be classified with
accuracy of 72.0%, indicating that the differences between the neural networks
can be identified by supervised machine learning algorithms. The ultimate
purpose of the dataset is to enable hypernetworks research. The dataset and the
code that generates it are open and accessible to the public.

</details>


### [327] [Prompt Smart, Pay Less: Cost-Aware APO for Real-World Applications](https://arxiv.org/abs/2507.15884)
*Jayesh Choudhari,Piyush Kumar Singh,Douglas McIlwraith,Snehal Nair*

Main category: cs.LG

TL;DR: 本研究提出了一种名为APE-OPRO的自动提示优化框架，它在商业多分类任务中比现有方法更具成本效益，并在性能、效率和可扩展性方面取得了良好的平衡。


<details>
  <summary>Details</summary>
Motivation: 现有研究主要在基准分类任务上验证APO框架，缺乏在真实、高风险的商业多分类场景中的全面评估。本研究旨在填补这一空白，并提供关于如何在商业应用中实施APO的实用见解。

Method: 提出了一种名为APE-OPRO的新型混合框架，该框架结合了APE和OPRO的优点，并与现有方法（包括梯度自由的APE、OPRO以及基于梯度的ProTeGi）在约2500个标记产品的真实商业数据集上进行了基准测试。进行了关于深度和广度超参数的消融研究，并分析了标签格式的影响。

Result: APE-OPRO框架相比OPRO提高了约18%的成本效益，且性能相当。ProTeGi在较低API成本下表现出最强的绝对性能，但计算时间更长。APE-OPRO在性能、API效率和可扩展性之间取得了良好的平衡。研究还发现LLM的行为对标签格式敏感。

Conclusion: 该研究首次全面评估了自动提示优化（APO）方法在真实、高风险的商业多分类场景中的应用，并提出了一种名为APE-OPRO的新型混合框架，该框架结合了APE和OPRO的优点，在不牺牲性能的情况下提高了约18%的成本效益。研究结果表明，与基于梯度的方法（如ProTeGi）相比，APE-OPRO在性能、API效率和可扩展性之间取得了更好的平衡。此外，消融研究揭示了超参数和标签格式对LLM行为的敏感性。

Abstract: Prompt design is a critical factor in the effectiveness of Large Language
Models (LLMs), yet remains largely heuristic, manual, and difficult to scale.
This paper presents the first comprehensive evaluation of Automatic Prompt
Optimization (APO) methods for real-world, high-stakes multiclass
classification in a commercial setting, addressing a critical gap in the
existing literature where most of the APO frameworks have been validated only
on benchmark classification tasks of limited complexity.
  We introduce APE-OPRO, a novel hybrid framework that combines the
complementary strengths of APE and OPRO, achieving notably better
cost-efficiency, around $18\%$ improvement over OPRO, without sacrificing
performance. We benchmark APE-OPRO alongside both gradient-free (APE, OPRO) and
gradient-based (ProTeGi) methods on a dataset of ~2,500 labeled products.
  Our results highlight key trade-offs: ProTeGi offers the strongest absolute
performance at lower API cost but higher computational time as noted
in~\cite{protegi}, while APE-OPRO strikes a compelling balance between
performance, API efficiency, and scalability. We further conduct ablation
studies on depth and breadth hyperparameters, and reveal notable sensitivity to
label formatting, indicating implicit sensitivity in LLM behavior. These
findings provide actionable insights for implementing APO in commercial
applications and establish a foundation for future research in multi-label,
vision, and multimodal prompt optimization scenarios.

</details>


### [328] [A Comprehensive Data-centric Overview of Federated Graph Learning](https://arxiv.org/abs/2507.16541)
*Zhengyu Wu,Xunkai Li,Yinlin Zhu,Zekai Chen,Guochen Yan,Yanyu Yan,Hao Zhang,Yuming Ai,Xinmo Jin,Rong-Hua Li,Guoren Wang*

Main category: cs.LG

TL;DR: 这是一项关于联邦图学习（FGL）的调查，它提出了一个数据驱动的分类法，以解决现有研究中缺乏数据中心视角的问题，并探讨了FGL与大模型的融合以及其应用前景。


<details>
  <summary>Details</summary>
Motivation: 现有的联邦图学习调查主要侧重于联邦学习和图机器学习的整合，并且缺乏以数据为中心来系统地审查联邦图学习方法，而这对于评估联邦图学习方法如何处理数据驱动的约束以提高模型性能至关重要。

Method: 提出一个两层数据驱动的分类法：数据特征（根据联邦图学习中使用的数据集的结构和分布特性进行分类）和数据利用（分析用于克服关键数据驱动约束的训练程序和技术）。

Result: 该调查提出了一个数据驱动的分类法，用于系统地审查联邦图学习方法，并分析了联邦图学习与预训练大模型的融合、实际应用和未来方向。

Conclusion: 未来研究应关注联邦图学习与预训练大模型的融合、实际应用案例的展示以及新兴的图机器学习趋势。

Abstract: In the era of big data applications, Federated Graph Learning (FGL) has
emerged as a prominent solution that reconcile the tradeoff between optimizing
the collective intelligence between decentralized datasets holders and
preserving sensitive information to maximum. Existing FGL surveys have
contributed meaningfully but largely focus on integrating Federated Learning
(FL) and Graph Machine Learning (GML), resulting in early stage taxonomies that
emphasis on methodology and simulated scenarios. Notably, a data centric
perspective, which systematically examines FGL methods through the lens of data
properties and usage, remains unadapted to reorganize FGL research, yet it is
critical to assess how FGL studies manage to tackle data centric constraints to
enhance model performances. This survey propose a two-level data centric
taxonomy: Data Characteristics, which categorizes studies based on the
structural and distributional properties of datasets used in FGL, and Data
Utilization, which analyzes the training procedures and techniques employed to
overcome key data centric challenges. Each taxonomy level is defined by three
orthogonal criteria, each representing a distinct data centric configuration.
Beyond taxonomy, this survey examines FGL integration with Pretrained Large
Models, showcases realistic applications, and highlights future direction
aligned with emerging trends in GML.

</details>


### [329] [ReDi: Rectified Discrete Flow](https://arxiv.org/abs/2507.15897)
*Jaehoon Yoo,Wonjung Kim,Seunghoon Hong*

Main category: cs.LG

TL;DR: ReDi通过修正耦合来减少离散流模型中的因子化误差，从而实现快速生成，并可用于训练单步模型。


<details>
  <summary>Details</summary>
Motivation: 离散流模型（DFMs）虽然是强大的生成模型，但通常因依赖于迭代解码过程而存在采样速度慢的问题。这种多步过程源于DFM为处理高维数据而必需的因子化近似。

Method: 提出了一种名为ReDi的新型迭代方法，通过修正源分布和目标分布之间的耦合来减少因子化误差，从而实现高效的几步生成。

Result: ReDi显著降低了条件互信息（Conditional TC），并实现了高效的几步生成。此外，研究表明ReDi修正的耦合非常适合训练高效的单步图像生成模型。

Conclusion: ReDi是一种简单且有理论依据的方法，用于解决离散数据合成中的少步生成挑战，并为高效离散数据合成提供了新的视角。

Abstract: Discrete Flow-based Models (DFMs) are powerful generative models for
high-quality discrete data but typically suffer from slow sampling speeds due
to their reliance on iterative decoding processes. This reliance on a
multi-step process originates from the factorization approximation of DFMs,
which is necessary for handling high-dimensional data. In this paper, we
rigorously characterize the approximation error from factorization using
Conditional Total Correlation (TC), which depends on the coupling. To reduce
the Conditional TC and enable efficient few-step generation, we propose
Rectified Discrete Flow (ReDi), a novel iterative method that reduces
factorization error by rectifying the coupling between source and target
distributions. We theoretically prove that each ReDi step guarantees a
monotonic decreasing Conditional TC, ensuring its convergence. Empirically,
ReDi significantly reduces Conditional TC and enables few-step generation.
Moreover, we demonstrate that the rectified couplings are well-suited for
training efficient one-step models on image generation. ReDi offers a simple
and theoretically grounded approach for tackling the few-step challenge,
providing a new perspective on efficient discrete data synthesis. Code is
available at https://github.com/Ugness/ReDi_discrete

</details>


### [330] [Improving the Generation of VAEs with High Dimensional Latent Spaces by the use of Hyperspherical Coordinates](https://arxiv.org/abs/2507.15900)
*Alejandro Ascarate,Leo Lebrat,Rodrigo Santa Cruz,Clinton Fookes,Olivier Salvado*

Main category: cs.LG

TL;DR: VAE 的潜在空间维度过高时，生成的数据无意义。我们提出使用超球面坐标，将潜在向量压缩到一个区域，以减少稀疏性，提高生成能力。


<details>
  <summary>Details</summary>
Motivation: 标准的 VAE 在潜在空间维度较高时（超过十几维），从先验中解码随机潜在向量通常不会产生有意义的数据。本研究旨在解决此问题。

Method: 我们提出了一种新的潜在空间参数化方法，使用超球面坐标，将潜在向量压缩到超球体上的一个区域，从而减少潜在稀疏性。

Result: 我们表明，我们的方法通过压缩潜在向量和减少潜在稀疏性，可以提高 VAE 的生成能力。

Conclusion: 通过使用超球面坐标参数化潜在空间，我们证明了可以压缩潜在向量，减少潜在稀疏性，并提高 VAE 的生成能力。

Abstract: Variational autoencoders (VAE) encode data into lower-dimensional latent
vectors before decoding those vectors back to data. Once trained, decoding a
random latent vector from the prior usually does not produce meaningful data,
at least when the latent space has more than a dozen dimensions. In this paper,
we investigate this issue by drawing insight from high dimensional statistics:
in these regimes, the latent vectors of a standard VAE are by construction
distributed uniformly on a hypersphere. We propose to formulate the latent
variables of a VAE using hyperspherical coordinates, which allows compressing
the latent vectors towards an island on the hypersphere, thereby reducing the
latent sparsity and we show that this improves the generation ability of the
VAE. We propose a new parameterization of the latent space with limited
computational overhead.

</details>


### [331] [RealBench: Benchmarking Verilog Generation Models with Real-World IP Designs](https://arxiv.org/abs/2507.16200)
*Pengwei Jin,Di Huang,Chongxiao Li,Shuyao Cheng,Yang Zhao,Xinyao Zheng,Jiaguo Zhu,Shuyi Xing,Bohan Dou,Rui Zhang,Zidong Du,Qi Guo,Xing Hu*

Main category: cs.LG

TL;DR: RealBench是首个用于评估LLM在真实世界IP级Verilog生成任务的基准，包含复杂设计和严格验证，但现有LLM表现仍有很大提升空间。


<details>
  <summary>Details</summary>
Motivation: 现有针对LLM生成Verilog的基准未能充分复现真实世界的设计流程，因其设计过于简单、规范不充分且验证环境不够严谨。

Method: 提出RealBench基准，包含复杂的IP设计、多模态规范和严格的验证环境，支持模块级和系统级任务。

Result: 评估显示，即使是表现最好的LLM（o1-preview）在模块级任务上的pass@1也仅为13.3%，系统级任务为0%。

Conclusion: 现有的Verilog生成评测基准在复现真实世界设 计流程方面存在不足，RealBench旨在解决此问题，它包含复杂的IP设计、多模态设 计规范和严格的验证环境，支持模块级和系统级任务。评估显示，即使是表现最好的 LLM（o1-preview）在模块级任务上的pass@1也仅为13.3%，系统级任务为0%， 表明未来需要更强大的Verilog生成模型。

Abstract: The automatic generation of Verilog code using Large Language Models (LLMs)
has garnered significant interest in hardware design automation. However,
existing benchmarks for evaluating LLMs in Verilog generation fall short in
replicating real-world design workflows due to their designs' simplicity,
inadequate design specifications, and less rigorous verification environments.
To address these limitations, we present RealBench, the first benchmark aiming
at real-world IP-level Verilog generation tasks. RealBench features complex,
structured, real-world open-source IP designs, multi-modal and formatted design
specifications, and rigorous verification environments, including 100% line
coverage testbenches and a formal checker. It supports both module-level and
system-level tasks, enabling comprehensive assessments of LLM capabilities.
Evaluations on various LLMs and agents reveal that even one of the
best-performing LLMs, o1-preview, achieves only a 13.3% pass@1 on module-level
tasks and 0% on system-level tasks, highlighting the need for stronger Verilog
generation models in the future. The benchmark is open-sourced at
https://github.com/IPRC-DIP/RealBench.

</details>


### [332] [The Cost of Compression: Tight Quadratic Black-Box Attacks on Sketches for $\ell_2$ Norm Estimation](https://arxiv.org/abs/2507.16345)
*Sara Ahmadian,Edith Cohen,Uri Stemmer*

Main category: cs.LG

TL;DR: 本研究提出了一种针对线性降维技术的黑盒对抗性攻击方法，该方法通用且高效，查询次数接近理论最优，并揭示了压缩表示的基本脆弱性。


<details>
  <summary>Details</summary>
Motivation: 线性降维技术在处理高维数据时非常有效，但容易受到对抗性输入的攻击。本研究旨在解决在黑盒设置下，即降维矩阵未知且不可控的情况下，如何对这种降维技术进行有效的对抗性攻击。

Method: 研究提出了一种通用的、非自适应的攻击方法，该方法不依赖于已知的降维矩阵或估计器，仅通过 O(k^2) 次查询即可实现对黑盒对抗性设置下线性降维的攻击。

Result: 该攻击方法能够有效地识别出导致降维估计失败的对抗性输入，并且在查询次数上（~O(k^2)）与已知的最优估计器上界相匹配。此外，研究还揭示了降维技术在对抗性攻击方面与图像分类领域存在的结构性相似性。

Conclusion: 该研究提出了一个通用的、非自适应的攻击方法，能够有效地针对线性降维技术中的对抗性输入进行攻击，并在查询次数上达到了理论最优。

Abstract: Dimensionality reduction via linear sketching is a powerful and widely used
technique, but it is known to be vulnerable to adversarial inputs. We study the
black-box adversarial setting, where a fixed, hidden sketching matrix A in
$R^{k X n}$ maps high-dimensional vectors v $\in R^n$ to lower-dimensional
sketches A v in $R^k$, and an adversary can query the system to obtain
approximate ell2-norm estimates that are computed from the sketch.
  We present a universal, nonadaptive attack that, using tilde(O)($k^2$)
queries, either causes a failure in norm estimation or constructs an
adversarial input on which the optimal estimator for the query distribution
(used by the attack) fails. The attack is completely agnostic to the sketching
matrix and to the estimator: It applies to any linear sketch and any query
responder, including those that are randomized, adaptive, or tailored to the
query distribution.
  Our lower bound construction tightly matches the known upper bounds of
tilde(Omega)($k^2$), achieved by specialized estimators for Johnson
Lindenstrauss transforms and AMS sketches. Beyond sketching, our results
uncover structural parallels to adversarial attacks in image classification,
highlighting fundamental vulnerabilities of compressed representations.

</details>


### [333] [Multi-Agent Reinforcement Learning for Sample-Efficient Deep Neural Network Mapping](https://arxiv.org/abs/2507.16249)
*Srivatsan Krishnan,Jason Jabbour,Dan Zhang,Natasha Jaques,Aleksandra Faust,Shayegan Omidshafiei,Vijay Janapa Reddi*

Main category: cs.LG

TL;DR: 本研究提出了一种基于多智能体强化学习（MARL）和智能体聚类的框架，用于优化DNN的硬件映射，显著提高了样本效率和模型性能。


<details>
  <summary>Details</summary>
Motivation: 为了克服深度神经网络（DNN）硬件映射中强化学习（RL）样本效率低下的问题，本研究提出了一种新的MARL框架。

Method: 本研究提出了一种去中心化的多智能体强化学习（MARL）框架，并结合了基于相关性分析的智能体聚类算法，以提高样本效率和加速探索。

Result: 实验结果表明，与标准的单智能体RL相比，本研究的MARL方法将样本效率提高了30-300倍，在相同样本条件下，延迟降低了高达32.61倍，能耗延迟积（EDP）降低了16.45倍。

Conclusion: 本研究提出的MARL框架在DNN硬件映射方面显著提高了样本效率，并在延迟和EDP方面取得了优越性能。

Abstract: Mapping deep neural networks (DNNs) to hardware is critical for optimizing
latency, energy consumption, and resource utilization, making it a cornerstone
of high-performance accelerator design. Due to the vast and complex mapping
space, reinforcement learning (RL) has emerged as a promising approach-but its
effectiveness is often limited by sample inefficiency. We present a
decentralized multi-agent reinforcement learning (MARL) framework designed to
overcome this challenge. By distributing the search across multiple agents, our
framework accelerates exploration. To avoid inefficiencies from training
multiple agents in parallel, we introduce an agent clustering algorithm that
assigns similar mapping parameters to the same agents based on correlation
analysis. This enables a decentralized, parallelized learning process that
significantly improves sample efficiency. Experimental results show our MARL
approach improves sample efficiency by 30-300x over standard single-agent RL,
achieving up to 32.61x latency reduction and 16.45x energy-delay product (EDP)
reduction under iso-sample conditions.

</details>


### [334] [Towards Mitigation of Hallucination for LLM-empowered Agents: Progressive Generalization Bound Exploration and Watchdog Monitor](https://arxiv.org/abs/2507.15903)
*Siyuan Liu,Wenjing Liu,Zhiwei Xu,Xin Wang,Bo Chen,Tao Li*

Main category: cs.LG

TL;DR: HalMit 是一个黑盒框架，可检测 LLM 智能体中的幻觉。


<details>
  <summary>Details</summary>
Motivation: LLM 驱动的智能体在与开放环境交互方面已成为一种流行的范例，但 LLM 产生的幻觉（输出与事实不一致）对其可信度构成了重大挑战。为了确保智能体的可靠性，必须有效检测和缓解幻觉。然而，现有方法要么依赖于 LLM 的白盒访问，要么无法准确识别幻觉。

Method: 提出了一种名为 HalMit 的新颖黑盒监控框架，该框架通过概率分形采样技术来模拟 LLM 驱动的智能体的泛化界，以并行生成足够多的查询来触发不可信的响应，从而有效地识别目标智能体的泛化界。

Result: 实验评估表明，HalMit 在幻觉监测方面显著优于现有方法。

Conclusion: HalMit 框架通过对 LLM 驱动的智能体的泛化界进行建模，能够有效地检测幻觉，并且不需要 LLM 的内部知识。实验评估表明，HalMit 在幻觉监测方面显著优于现有方法。其黑盒性质和卓越的性能使 HalMit 成为增强 LLM 驱动的系统可靠性的有希望的解决方案。

Abstract: Empowered by large language models (LLMs), intelligent agents have become a
popular paradigm for interacting with open environments to facilitate AI
deployment. However, hallucinations generated by LLMs-where outputs are
inconsistent with facts-pose a significant challenge, undermining the
credibility of intelligent agents. Only if hallucinations can be mitigated, the
intelligent agents can be used in real-world without any catastrophic risk.
Therefore, effective detection and mitigation of hallucinations are crucial to
ensure the dependability of agents. Unfortunately, the related approaches
either depend on white-box access to LLMs or fail to accurately identify
hallucinations. To address the challenge posed by hallucinations of intelligent
agents, we present HalMit, a novel black-box watchdog framework that models the
generalization bound of LLM-empowered agents and thus detect hallucinations
without requiring internal knowledge of the LLM's architecture. Specifically, a
probabilistic fractal sampling technique is proposed to generate a sufficient
number of queries to trigger the incredible responses in parallel, efficiently
identifying the generalization bound of the target agent. Experimental
evaluations demonstrate that HalMit significantly outperforms existing
approaches in hallucination monitoring. Its black-box nature and superior
performance make HalMit a promising solution for enhancing the dependability of
LLM-powered systems.

</details>


### [335] [Custom Algorithm-based Fault Tolerance for Attention Layers in Transformers](https://arxiv.org/abs/2507.16676)
*Vasileios Titopoulos,Kosmas Alexandridis,Giorgos Dimitrakopoulos*

Main category: cs.LG

TL;DR: Flash-ABFT 是一种新的容错技术，通过一次性校验和计算 Transformer 注意力机制中的 Q, K, V 矩阵乘积（含 Softmax），降低了硬件开销和能耗，提高了错误检测效率。


<details>
  <summary>Details</summary>
Motivation: Transformer 和 LLM 的兴起需要专门的硬件加速器，而这些加速器在高效检测随机硬件故障错误方面面临挑战。传统的 ABFT 技术无法处理整个注意力机制，特别是 Softmax 归一化。

Method: Flash-ABFT 提出了一种新颖的方法，通过在注意力层的 Q, K, V 矩阵乘积（包含 Softmax 操作）上进行一次性校验和计算来实现容错。

Result: 实验结果表明，Flash-ABFT 仅带来 5.3% 的硬件面积开销和低于 1.9% 的能耗开销，是一种经济高效且鲁棒的解决方案。

Conclusion: Flash-ABFT 通过在查询、键和值矩阵的整个三矩阵乘积上计算在线校验和，包括 Softmax 操作，并进行单次检查，来提高注意力加速器中错误检测的效率。该方法显著降低了开销，同时保持了高故障检测精度。

Abstract: Transformers and large language models (LLMs), powered by the attention
mechanism, have transformed numerous AI applications, driving the need for
specialized hardware accelerators. A major challenge in these accelerators is
efficiently detecting errors caused by random hardware faults. Traditional
algorithm-based fault tolerance (ABFT) techniques verify individual matrix
multiplications but fall short in handling the full attention mechanism,
particularly due to intermediate softmax normalization. This work proposes
Flash-ABFT, a novel method that computes an online checksum across the entire
three-matrix product of query, key and value matrices, of an attention layer,
including the softmax operation, with a single check. This approach
significantly reduces overhead by eliminating redundant checks while
maintaining high fault-detection accuracy. Experimental results demonstrate
that Flash-ABFT incurs only 5.3% hardware area overhead and less than 1.9%
energy overhead, making it a cost-effective and robust solution for error
detection in attention accelerators.

</details>


### [336] [Foundation Models and Transformers for Anomaly Detection: A Survey](https://arxiv.org/abs/2507.15905)
*Mouïn Ben Ammar,Arturo Mendoza,Nacim Belkhir,Antoine Manzanera,Gianni Franchi*

Main category: cs.LG

TL;DR: Deep learning, especially Transformers and foundation models, is revolutionizing visual anomaly detection by improving handling of long-range dependencies and data scarcity, leading to more robust and scalable methods.


<details>
  <summary>Details</summary>
Motivation: The survey aims to examine the transformative role of Transformers and foundation models in advancing visual anomaly detection (VAD), addressing challenges such as long-range dependency modeling, contextual modeling, and data scarcity.

Method: This survey categorizes VAD methods into reconstruction-based, feature-based, and zero/few-shot approaches, and examines how Transformer and foundation model architectures are integrated into these categories.

Result: The survey provides a comprehensive review of state-of-the-art techniques in VAD that utilize Transformers and foundation models, highlighting their strengths, limitations, and emerging trends.

Conclusion: Transformers and foundation models represent a significant advancement in visual anomaly detection (VAD), offering more robust, interpretable, and scalable solutions by addressing challenges like long-range dependencies, contextual modeling, and data scarcity through attention mechanisms and large-scale pre-training.

Abstract: In line with the development of deep learning, this survey examines the
transformative role of Transformers and foundation models in advancing visual
anomaly detection (VAD). We explore how these architectures, with their global
receptive fields and adaptability, address challenges such as long-range
dependency modeling, contextual modeling and data scarcity. The survey
categorizes VAD methods into reconstruction-based, feature-based and
zero/few-shot approaches, highlighting the paradigm shift brought about by
foundation models. By integrating attention mechanisms and leveraging
large-scale pre-training, Transformers and foundation models enable more
robust, interpretable, and scalable anomaly detection solutions. This work
provides a comprehensive review of state-of-the-art techniques, their
strengths, limitations, and emerging trends in leveraging these architectures
for VAD.

</details>


### [337] [Neural Probabilistic Shaping: Joint Distribution Learning for Optical Fiber Communications](https://arxiv.org/abs/2507.16012)
*Mohammad Taha Askari,Lutz Lampe,Amirhossein Ghazisaeidi*

Main category: cs.LG

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: We present an autoregressive end-to-end learning approach for probabilistic
shaping on nonlinear fiber channels. Our proposed scheme learns the joint
symbol distribution and provides a 0.3-bits/2D achievable information rate gain
over an optimized marginal distribution for dual-polarized 64-QAM transmission
over a single-span 205 km link.

</details>


### [338] [Towards Reliable, Uncertainty-Aware Alignment](https://arxiv.org/abs/2507.15906)
*Debangshu Banerjee,Kintan Saha,Aditya Gopalan*

Main category: cs.LG

TL;DR: 语言模型对齐中的奖励模型不稳定可能导致性能下降。本文提出了一种方差感知策略优化方法，通过加入奖励模型方差估计作为正则化项，提高了对齐的稳定性和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有的语言模型对齐方法通常依赖于在偏好数据上训练奖励模型，然后针对该奖励模型进行策略优化。然而，仅仅依赖单一奖励模型估计会使策略优化过程容易受到奖励模型不准确性的影响。通过对开源基准的实证研究发现，在相同偏好数据集上独立训练的奖励模型可能存在显著分歧，这凸显了当前对齐策略的不稳定性。理论模型分析表明，奖励模型估计的变异性可能导致过拟合，进而带来性能下降的风险。

Method: 本文提出了一种方差感知策略优化框架，该框架包含一个新的策略正则化项，该正则化项能够整合奖励模型的方差估计。

Result: 实验结果证实，所提出的方差感知策略优化框架能够提供比标准方法更稳定、更鲁棒的对齐效果，有效降低了输出策略劣于默认策略的风险。

Conclusion: 本文提出了一种方差感知策略优化框架，通过引入奖励模型方差估计作为新的策略正则化项，以解决标准对齐方法中奖励模型不准确导致的过拟合和性能下降风险。实验结果表明，该方法在多种语言模型和奖励模型配置下，比标准的（不考虑方差的）方法能实现更稳定、更鲁棒的对齐。

Abstract: Alignment of large language models (LLMs) typically involves training a
reward model on preference data, followed by policy optimization with respect
to the reward model. However, optimizing policies with respect to a single
reward model estimate can render it vulnerable to inaccuracies in the reward
model. We empirically study the variability of reward model training on
open-source benchmarks. We observe that independently trained reward models on
the same preference dataset can exhibit substantial disagreement, highlighting
the instability of current alignment strategies. Employing a theoretical model,
we demonstrate that variability in reward model estimation can cause
overfitting, leading to the risk of performance degradation. To mitigate this
risk, we propose a variance-aware policy optimization framework for
preference-based alignment. The key ingredient of the framework is a new policy
regularizer that incorporates reward model variance estimates. We show that
variance-aware policy optimization provably reduces the risk of outputting a
worse policy than the default. Experiments across diverse LLM and reward model
configurations confirm that our approach yields more stable and robust
alignment than the standard (variance-unaware) pipeline.

</details>


### [339] [Dual Turing Test: A Framework for Detecting and Mitigating Undetectable AI](https://arxiv.org/abs/2507.15907)
*Alberto Messina*

Main category: cs.LG

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: In this short note, we propose a unified framework that bridges three areas:
(1) a flipped perspective on the Turing Test, the "dual Turing test", in which
a human judge's goal is to identify an AI rather than reward a machine for
deception; (2) a formal adversarial classification game with explicit quality
constraints and worst-case guarantees; and (3) a reinforcement learning (RL)
alignment pipeline that uses an undetectability detector and a set of quality
related components in its reward model. We review historical precedents, from
inverted and meta-Turing variants to modern supervised reverse-Turing
classifiers, and highlight the novelty of combining quality thresholds, phased
difficulty levels, and minimax bounds. We then formalize the dual test: define
the judge's task over N independent rounds with fresh prompts drawn from a
prompt space Q, introduce a quality function Q and parameters tau and delta,
and cast the interaction as a two-player zero-sum game over the adversary's
feasible strategy set M. Next, we map this minimax game onto an RL-HF style
alignment loop, in which an undetectability detector D provides negative reward
for stealthy outputs, balanced by a quality proxy that preserves fluency.
Throughout, we include detailed explanations of each component notation, the
meaning of inner minimization over sequences, phased tests, and iterative
adversarial training and conclude with a suggestion for a couple of immediate
actions.

</details>


### [340] [Reducing GPU Memory Fragmentation via Spatio-Temporal Planning for Efficient Large-Scale Model Training](https://arxiv.org/abs/2507.16274)
*Zixiao Huang,Junhao Hu,Hao Lin,Chunyang Zhu,Yueran Tang,Quanlu Zhang,Zhen Guo,Zhenhua Li,Shengen Yan,Zhenhua Zhu,Guohao Dai,Yu Wang*

Main category: cs.LG

TL;DR: STWeaver是一种新的GPU内存分配器，通过离线规划和在线分配相结合，利用时空规律性，显著减少了内存碎片，提高了训练效率和性能。


<details>
  <summary>Details</summary>
Motivation: 默认的GPU内存分配器（如PyTorch）采用在线策略，不了解张量生命周期，可能浪费高达43%的内存并导致内存不足错误，使得优化技术失效。STWeaver旨在解决这个问题。

Method: STWeaver采用了一种新颖的范式，结合了离线规划和在线分配。离线规划利用时空规律性生成近乎最优的分配计划，而在线分配则处理诸如混合专家（MoE）之类复杂和动态的模型。

Result: STWeaver减少了79.2%的碎片率，同时开销可忽略，并将性能提高了32.5%。

Conclusion: STWeaver通过利用训练工作负载中内存分配行为的时空规律性，显著减少了GPU内存碎片，平均减少了79.2%，在某些情况下甚至达到了100%，同时仅带来可忽略的开销。这使得更高效、高吞吐量的训练成为可能，并将性能提高了32.5%。

Abstract: The rapid scaling of large language models (LLMs) has significantly increased
GPU memory pressure, which is further aggravated by training optimization
techniques such as virtual pipeline and recomputation that disrupt tensor
lifespans and introduce considerable memory fragmentation. Default GPU memory
allocators of popular deep learning frameworks like PyTorch use online
strategies without knowledge of tensor lifespans, which can waste up to 43\% of
memory and cause out-of-memory errors, rendering optimization techniques
ineffective or even unusable.
  To address this, we introduce STWeaver, a GPU memory allocator for deep
learning frameworks that reduces fragmentation by exploiting the spatial and
temporal regularity in memory allocation behaviors of training workloads.
STWeaver introduces a novel paradigm that combines offline planning with online
allocation. The offline planning leverages spatio-temporal regularities to
generate a near-optimal allocation plan, while the online allocation handles
complex and dynamic models such as Mixture-of-Experts (MoE). Built as a
pluggable PyTorch allocator, STWeaver reduces fragmentation ratio on average by
79.2\% (up to 100\%) across both dense and sparse models, with negligible
overhead. This enables more efficient, high-throughput training configurations
and improves performance by up to 32.5\%.

</details>


### [341] [HyDRA: A Hybrid-Driven Reasoning Architecture for Verifiable Knowledge Graphs](https://arxiv.org/abs/2507.15917)
*Adrian Kaiser,Claudiu Leoveanu-Condrei,Ryan Gold,Marius-Constantin Dinu,Markus Hofmarcher*

Main category: cs.LG

TL;DR: HyDRA是一个混合驱动的推理架构，用于自动化知识图谱的构建。它利用协作智能体和可验证契约来提高生成知识图谱的可靠性和一致性，并通过SymbolicAI框架进行评估。


<details>
  <summary>Details</summary>
Motivation: 为了解决自动化知识图谱构建中输出可靠性、一致性和可验证性方面的挑战，例如生成图谱中的结构不一致、数据孤岛或抽象类与具体实例的错误混淆等问题。

Method: HyDRA首先通过协作神经符号智能体构建本体，然后利用本体图指导从文档中提取三元组来生成知识图谱。该方法借鉴了契约式设计（DbC）的原则，使用可验证的契约作为主要的控制机制来指导大型语言模型（LLM）的生成过程。

Result: HyDRA提出了一种混合驱动的推理架构，用于可验证的知识图谱自动化。该方法通过协作智能体定义能力问题（CQs），然后构建本体图来指导知识图谱的生成，并提出了一种包含符号验证的评估框架来衡量生成知识图谱的功能正确性。

Conclusion: HyDRA通过利用可验证的契约来指导大型语言模型（LLM）的生成过程，并提出了一种名为SymbolicAI的框架来评估生成知识图谱的功能正确性，从而提高了自动化知识图谱构建的可靠性，并探索了衡量其输出功能完整性的评估方法。

Abstract: The synergy between symbolic knowledge, often represented by Knowledge Graphs
(KGs), and the generative capabilities of neural networks is central to
advancing neurosymbolic AI. A primary bottleneck in realizing this potential is
the difficulty of automating KG construction, which faces challenges related to
output reliability, consistency, and verifiability. These issues can manifest
as structural inconsistencies within the generated graphs, such as the
formation of disconnected $\textit{isolated islands}$ of data or the inaccurate
conflation of abstract classes with specific instances. To address these
challenges, we propose HyDRA, a $\textbf{Hy}$brid-$\textbf{D}$riven
$\textbf{R}$easoning $\textbf{A}$rchitecture designed for verifiable KG
automation. Given a domain or an initial set of documents, HyDRA first
constructs an ontology via a panel of collaborative neurosymbolic agents. These
agents collaboratively agree on a set of competency questions (CQs) that define
the scope and requirements the ontology must be able to answer. Given these
CQs, we build an ontology graph that subsequently guides the automated
extraction of triplets for KG generation from arbitrary documents. Inspired by
design-by-contracts (DbC) principles, our method leverages verifiable contracts
as the primary control mechanism to steer the generative process of Large
Language Models (LLMs). To verify the output of our approach, we extend beyond
standard benchmarks and propose an evaluation framework that assesses the
functional correctness of the resulting KG by leveraging symbolic verifications
as described by the neurosymbolic AI framework, $\textit{SymbolicAI}$. This
work contributes a hybrid-driven architecture for improving the reliability of
automated KG construction and the exploration of evaluation methods for
measuring the functional integrity of its output. The code is publicly
available.

</details>


### [342] [On the transferability of Sparse Autoencoders for interpreting compressed models](https://arxiv.org/abs/2507.15977)
*Suchit Gupte,Vishnu Kabir Chhabra,Mohammad Mahdi Khalili*

Main category: cs.LG

TL;DR: 大型语言模型压缩技术对模型可解释性的影响尚不明确。本研究发现，在原始模型上训练的稀疏自编码器（SAE）可以解释压缩后的模型，直接剪枝原始SAE也能获得与在压缩模型上训练新SAE相当的性能，从而降低了SAE的训练成本。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）的推理效率因其规模而面临挑战，虽然已有多种压缩方法（如剪枝和量化），但压缩对模型可解释性的影响尚不明确。稀疏自编码器（SAEs）在模型解释方面已被证明是有效的，本研究旨在探索压缩对SAEs的影响，并寻找降低SAE训练成本的方法。

Method: 本研究通过比较在原始模型和压缩模型上训练的稀疏自编码器（SAE），探索压缩对模型可解释性的影响。研究发现，在原始模型上训练的SAE可以解释压缩后的模型，并且直接剪枝原始SAE可以获得与在压缩模型上训练新SAE相当的性能。

Result: 在原始模型上训练的SAE可以解释压缩后的模型，但性能略有下降。直接剪枝原始SAE的性能与在压缩模型上训练新SAE相当。

Conclusion: 本研究表明，在原始模型上训练的SAE可以解释压缩后的模型，尽管性能略有下降。此外，直接剪枝原始SAE可以获得与在压缩模型上训练新SAE相当的性能，这有助于降低SAE的训练成本。

Abstract: Modern LLMs face inference efficiency challenges due to their scale. To
address this, many compression methods have been proposed, such as pruning and
quantization. However, the effect of compression on a model's interpretability
remains elusive. While several model interpretation approaches exist, such as
circuit discovery, Sparse Autoencoders (SAEs) have proven particularly
effective in decomposing a model's activation space into its feature basis. In
this work, we explore the differences in SAEs for the original and compressed
models. We find that SAEs trained on the original model can interpret the
compressed model albeit with slight performance degradation compared to the
trained SAE on the compressed model. Furthermore, simply pruning the original
SAE itself achieves performance comparable to training a new SAE on the pruned
model. This finding enables us to mitigate the extensive training costs of
SAEs.

</details>


### [343] [RIS-aided Latent Space Alignment for Semantic Channel Equalization](https://arxiv.org/abs/2507.16450)
*Tomás Hüttebräucker,Mario Edoardo Pandolfo,Simone Fiorellino,Emilio Calvanese Strinati,Paolo Di Lorenzo*

Main category: cs.LG

TL;DR: 在多用户通信中，AI 设备可能因潜在表示不同而产生语义不匹配。本研究提出了一个联合物理和语义信道均衡框架，并利用了 RIS，以解决 MIMO 信道中的语义不匹配问题。该框架包括发送端的预均衡、通过 RIS 信道的传播以及接收端的后均衡。通过优化 MMSE 并提出线性和非线性（基于 DNN）均衡器，并在潜在空间中进行语义压缩并遵守功率约束，证明了所提出的方法优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 在多用户设置中，独立训练的智能体可能导致 AI 原生设备之间产生不同的潜在表示，即使没有传统的传输错误，也会导致语义不匹配，从而阻碍相互理解。这项工作解决了 MIMO 信道中的语义不匹配问题。

Method: 提出了一种联合物理和语义信道均衡框架，该框架利用了可重构智能表面（RIS）。语义均衡被实施为一系列变换：(i) 发送端的预均衡阶段；(ii) 通过 RIS 辅助信道的传播；(iii) 接收端的后均衡阶段。问题被表述为约束最小均方误差（MMSE）优化，并提出了两种解决方案：(i) 线性语义均衡链；(ii) 非线性基于 DNN 的语义均衡器。这两种方法都在潜在空间中操作，并遵守发射功率约束。

Result: 通过广泛的评估，表明所提出的联合均衡策略在各种场景和无线信道条件下，性能优于传统的、分离的物理和语义信道均衡方法。

Conclusion: 提出的联合均衡策略在各种场景和无线信道条件下始终优于传统的、分离的物理和语义信道均衡方法。

Abstract: Semantic communication systems introduce a new paradigm in wireless
communications, focusing on transmitting the intended meaning rather than
ensuring strict bit-level accuracy. These systems often rely on Deep Neural
Networks (DNNs) to learn and encode meaning directly from data, enabling more
efficient communication. However, in multi-user settings where interacting
agents are trained independently-without shared context or joint
optimization-divergent latent representations across AI-native devices can lead
to semantic mismatches, impeding mutual understanding even in the absence of
traditional transmission errors. In this work, we address semantic mismatch in
Multiple-Input Multiple-Output (MIMO) channels by proposing a joint physical
and semantic channel equalization framework that leverages the presence of
Reconfigurable Intelligent Surfaces (RIS). The semantic equalization is
implemented as a sequence of transformations: (i) a pre-equalization stage at
the transmitter; (ii) propagation through the RIS-aided channel; and (iii) a
post-equalization stage at the receiver. We formulate the problem as a
constrained Minimum Mean Squared Error (MMSE) optimization and propose two
solutions: (i) a linear semantic equalization chain, and (ii) a non-linear
DNN-based semantic equalizer. Both methods are designed to operate under
semantic compression in the latent space and adhere to transmit power
constraints. Through extensive evaluations, we show that the proposed joint
equalization strategies consistently outperform conventional, disjoint
approaches to physical and semantic channel equalization across a broad range
of scenarios and wireless channel conditions.

</details>


### [344] [Semantic-Aware Gaussian Process Calibration with Structured Layerwise Kernels for Deep Neural Networks](https://arxiv.org/abs/2507.15987)
*Kyung-hwan Lee,Kyung-tae Kim*

Main category: cs.LG

TL;DR: SAL-GP是一种新颖的逐层校准方法，它通过模仿神经网络的层级结构来改进置信度校准。


<details>
  <summary>Details</summary>
Motivation: 传统的GP校准方法难以捕捉深度神经网络的内部层级结构，限制了其可解释性和评估预测可靠性的有效性。

Method: 提出了一种名为SAL-GP（Semantic-Aware Layer-wise Gaussian Process）的框架，该框架采用多层高斯过程模型，并将神经网络的特征表示映射到局部校准校正。通过结构化的多层核函数实现层间耦合，并对所有层进行联合边际化。

Result: SAL-GP框架能够捕捉局部语义依赖和全局校准一致性，同时在整个网络中一致地传播预测不确定性，从而提高可解释性并实现对深度模型置信度一致性和不确定性量化的原则性评估。

Conclusion: SAL-GP框架通过模仿目标神经网络的层级结构，利用多层GP模型捕捉局部语义依赖和全局校准一致性，从而实现逐层校准。该框架提高了模型的可解释性，并能对深度模型中的置信度一致性和不确定性量化进行原则性评估。

Abstract: Calibrating the confidence of neural network classifiers is essential for
quantifying the reliability of their predictions during inference. However,
conventional Gaussian Process (GP) calibration methods often fail to capture
the internal hierarchical structure of deep neural networks, limiting both
interpretability and effectiveness for assessing predictive reliability. We
propose a Semantic-Aware Layer-wise Gaussian Process (SAL-GP) framework that
mirrors the layered architecture of the target neural network. Instead of
applying a single global GP correction, SAL-GP employs a multi-layer GP model,
where each layer's feature representation is mapped to a local calibration
correction. These layerwise GPs are coupled through a structured multi-layer
kernel, enabling joint marginalization across all layers. This design allows
SAL-GP to capture both local semantic dependencies and global calibration
coherence, while consistently propagating predictive uncertainty through the
network. The resulting framework enhances interpretability aligned with the
network architecture and enables principled evaluation of confidence
consistency and uncertainty quantification in deep models.

</details>


### [345] [Enhancing Stability of Physics-Informed Neural Network Training Through Saddle-Point Reformulation](https://arxiv.org/abs/2507.16008)
*Dmitry Bylinkin,Mikhail Aleksandrov,Savelii Chezhegov,Aleksandr Beznosikov*

Main category: cs.LG

TL;DR: PINN 训练被重新表述为一个非凸强凹鞍点问题，以解决其不稳定的性能。所提出的方法在各种任务和架构的广泛实验研究中被评估，并被证明优于当前最先进的技术。


<details>
  <summary>Details</summary>
Motivation: 为了解决 PINN 训练中因损失函数的复杂景观而导致的性能不稳定问题。

Method: 将 PINN 训练重新表述为非凸强凹鞍点问题。

Result: 所提出的方法在各种任务和架构的广泛实验研究中被评估，并被证明是有效的。

Conclusion: 所提出的方法优于当前最先进的技术。

Abstract: Physics-informed neural networks (PINNs) have gained prominence in recent
years and are now effectively used in a number of applications. However, their
performance remains unstable due to the complex landscape of the loss function.
To address this issue, we reformulate PINN training as a nonconvex-strongly
concave saddle-point problem. After establishing the theoretical foundation for
this approach, we conduct an extensive experimental study, evaluating its
effectiveness across various tasks and architectures. Our results demonstrate
that the proposed method outperforms the current state-of-the-art techniques.

</details>


### [346] [Reactivation: Empirical NTK Dynamics Under Task Shifts](https://arxiv.org/abs/2507.16039)
*Yuzhi Liu,Zixuan Chen,Zirui Zhang,Yufei Liu,Giulia Lanzillotta*

Main category: cs.LG

TL;DR: NTK动力学在持续学习中很有趣，但静态内核近似可能不适用于理论分析。


<details>
  <summary>Details</summary>
Motivation: 在持续学习场景下，研究NTK的动态演变，以挑战静态内核近似的有效性。

Method: 对NTK动力学在持续学习中的动态进行了全面的经验分析。

Result: NTK动力学在持续学习中十分丰富，但静态内核近似在理论分析中可能无效。

Conclusion: 应持续学习的静态内核近似在理论分析中可能无效，即使在大规模情况下。

Abstract: The Neural Tangent Kernel (NTK) offers a powerful tool to study the
functional dynamics of neural networks. In the so-called lazy, or kernel
regime, the NTK remains static during training and the network function is
linear in the static neural tangents feature space. The evolution of the NTK
during training is necessary for feature learning, a key driver of deep
learning success. The study of the NTK dynamics has led to several critical
discoveries in recent years, in generalization and scaling behaviours. However,
this body of work has been limited to the single task setting, where the data
distribution is assumed constant over time. In this work, we present a
comprehensive empirical analysis of NTK dynamics in continual learning, where
the data distribution shifts over time. Our findings highlight continual
learning as a rich and underutilized testbed for probing the dynamics of neural
training. At the same time, they challenge the validity of static-kernel
approximations in theoretical treatments of continual learning, even at large
scale.

</details>


### [347] [A Lower Bound for the Number of Linear Regions of Ternary ReLU Regression Neural Networks](https://arxiv.org/abs/2507.16079)
*Yuta Nakahara,Manabu Kobayashi,Toshiyasu Matsushima*

Main category: cs.LG

TL;DR: 本文分析了三元神经网络的理论表达能力。研究表明，三元神经网络的线性区域数量与网络宽度和深度之间的关系与标准神经网络相似。通过增加宽度或深度，三元神经网络可以达到与通用神经网络相当的性能。


<details>
  <summary>Details</summary>
Motivation: 深度学习的进步使得降低计算复杂度和内存消耗成为一项关键挑战，而参数限制在{-1, 0, +1}的三元神经网络（NNs）作为一种有前途的方法吸引了人们的关注。

Method: 本文从线性区域数量的角度对三元神经网络（NNs）的表达能力进行了理论分析。具体来说，我们评估了具有ReLU激活函数的三元回归NNs的线性区域数量，并证明了其线性区域数量与网络宽度呈多项式增长，与网络深度呈指数增长，与标准NNs类似。此外，我们证明了三元NNs的宽度加倍或深度加倍足以达到与通用ReLU回归NNs相当的最大线性区域数量的下界。

Result: 我们证明了三元NNs的宽度加倍或深度加倍足以达到与通用ReLU回归NNs相当的最大线性区域数量的下界。这在某种程度上为三元NNs的实际成功提供了理论解释。

Conclusion: 三元神经网络（NNs）在图像识别和自然语言处理等实际应用中表现出色，但其理论理解仍然不足。本文从线性区域数量的角度对三元NNs的表达能力进行了理论分析，并证明了其线性区域数量与网络宽度呈多项式增长，与网络深度呈指数增长，这在某种程度上为三元NNs的实际成功提供了理论解释。

Abstract: With the advancement of deep learning, reducing computational complexity and
memory consumption has become a critical challenge, and ternary neural networks
(NNs) that restrict parameters to $\{-1, 0, +1\}$ have attracted attention as a
promising approach. While ternary NNs demonstrate excellent performance in
practical applications such as image recognition and natural language
processing, their theoretical understanding remains insufficient. In this
paper, we theoretically analyze the expressivity of ternary NNs from the
perspective of the number of linear regions. Specifically, we evaluate the
number of linear regions of ternary regression NNs with Rectified Linear Unit
(ReLU) for activation functions and prove that the number of linear regions
increases polynomially with respect to network width and exponentially with
respect to depth, similar to standard NNs. Moreover, we show that it suffices
to either square the width or double the depth of ternary NNs to achieve a
lower bound on the maximum number of linear regions comparable to that of
general ReLU regression NNs. This provides a theoretical explanation, in some
sense, for the practical success of ternary NNs.

</details>


### [348] [TorchAO: PyTorch-Native Training-to-Serving Model Optimization](https://arxiv.org/abs/2507.16099)
*Andrew Or,Apurva Jain,Daniel Vega-Myhre,Jesse Cai,Charles David Hernandez,Zhenrui Zheng,Driss Guessous,Vasiliy Kuznetsov,Christian Puhrsch,Mark Saroufim,Supriya Rao,Thien Tran,Aleksandar Samardžić*

Main category: cs.LG

TL;DR: TorchAO是一个PyTorch原生模型优化框架，通过量化和稀疏性技术，提供从训练到服务的端到端工作流，并已成功应用于Llama等模型的优化。


<details>
  <summary>Details</summary>
Motivation: 为了解决AI模型优化中存在的工具链碎片化问题，提供一个统一的、端到端的、从训练到服务的模型优化框架。

Method: TorchAO利用量化和稀疏性技术，通过新颖的张量子类抽象来支持多种低精度数据类型（INT4、INT8、FP8、MXFP4、MXFP6、MXFP8），并与TorchTitan、TorchTune、Axolotl、HuggingFace、vLLM、SGLang、ExecuTorch等现有工具集成，提供端到端的模型优化工作流。

Result: TorchAO成功支持了Llama 3.2 1B/3B和LlamaGuard3-8B等模型的量化发布，证明了其在模型优化方面的有效性。

Conclusion: TorchAO是一个PyTorch原生模型优化框架，支持多种优化技术，如FP8量化训练、感知量化训练(QAT)、训练后量化(PTQ)和2:4稀疏性。它通过新颖的张量子类抽象支持多种低精度数据类型，并与PyTorch生态系统紧密集成，实现了从预训练到微调再到推理的端到端工作流。TorchAO已成功应用于Llama 3.2 1B/3B和LlamaGuard3-8B模型的量化发布，并已开源。

Abstract: We present TorchAO, a PyTorch-native model optimization framework leveraging
quantization and sparsity to provide an end-to-end, training-to-serving
workflow for AI models. TorchAO supports a variety of popular model
optimization techniques, including FP8 quantized training, quantization-aware
training (QAT), post-training quantization (PTQ), and 2:4 sparsity, and
leverages a novel tensor subclass abstraction to represent a variety of
widely-used, backend agnostic low precision data types, including INT4, INT8,
FP8, MXFP4, MXFP6, and MXFP8. TorchAO integrates closely with the broader
ecosystem at each step of the model optimization pipeline, from pre-training
(TorchTitan) to fine-tuning (TorchTune, Axolotl) to serving (HuggingFace, vLLM,
SGLang, ExecuTorch), connecting an otherwise fragmented space in a single,
unified workflow. TorchAO has enabled recent launches of the quantized Llama
3.2 1B/3B and LlamaGuard3-8B models and is open-source at
https://github.com/pytorch/ao/.

</details>


### [349] [Learning Patient-Specific Spatial Biomarker Dynamics via Operator Learning for Alzheimer's Disease Progression](https://arxiv.org/abs/2507.16148)
*Jindong Wang,Yutong Mao,Xiao Liu,Wenrui Hao*

Main category: cs.LG

TL;DR: AD 进展的个性化预测：一种基于算子学习和数字孪生的新方法，准确率超 90%.


<details>
  <summary>Details</summary>
Motivation: 尽管在阿尔茨海默病治疗方面取得了进展，但能够准确预测个体疾病轨迹的预测模型仍然有限。本研究旨在解决这一问题，提供一种新的个性化建模方法。

Method: 本研究提出了一种基于机器学习的算子学习框架，用于阿尔茨海默病（AD）进展的个性化建模。该框架整合了纵向多模态成像、生物标志物和临床数据，并利用拉普拉斯特征函数基构建了能够捕捉复杂大脑动态的几何感知神经网络算子。该框架嵌入数字孪生范式中，实现了个体化预测、治疗干预模拟和计算临床试验。

Result: 该方法在阿尔茨海默病临床数据上实现了超过90%的多种生物标志物预测准确性，显著优于现有方法。

Conclusion: 该工作提供了一个可扩展、可解释的平台，用于神经退行性疾病的精确建模和个性化治疗优化。

Abstract: Alzheimer's disease (AD) is a complex, multifactorial neurodegenerative
disorder with substantial heterogeneity in progression and treatment response.
Despite recent therapeutic advances, predictive models capable of accurately
forecasting individualized disease trajectories remain limited. Here, we
present a machine learning-based operator learning framework for personalized
modeling of AD progression, integrating longitudinal multimodal imaging,
biomarker, and clinical data. Unlike conventional models with prespecified
dynamics, our approach directly learns patient-specific disease operators
governing the spatiotemporal evolution of amyloid, tau, and neurodegeneration
biomarkers. Using Laplacian eigenfunction bases, we construct geometry-aware
neural operators capable of capturing complex brain dynamics. Embedded within a
digital twin paradigm, the framework enables individualized predictions,
simulation of therapeutic interventions, and in silico clinical trials. Applied
to AD clinical data, our method achieves high prediction accuracy exceeding 90%
across multiple biomarkers, substantially outperforming existing approaches.
This work offers a scalable, interpretable platform for precision modeling and
personalized therapeutic optimization in neurodegenerative diseases.

</details>


### [350] [Perovskite-R1: A Domain-Specialized LLM for Intelligent Discovery of Precursor Additives and Experimental Design](https://arxiv.org/abs/2507.16307)
*Xin-De Wang,Zhi-Rui Chen,Peng-Jie Guo,Ze-Feng Gao,Cheng Mu,Zhong-Yi Lu*

Main category: cs.LG

TL;DR: Perovskite-R1是一个针对钙钛矿太阳能电池前体添加剂设计的专用大语言模型，它通过分析大量文献和材料数据，能够提出有效的解决方案，并通过实验验证了其在提高材料稳定性和性能方面的潜力，为加速材料发现提供了新方法。


<details>
  <summary>Details</summary>
Motivation: 钙钛矿太阳能电池（PSCs）虽然效率高，但长期稳定性、环境可持续性和规模化生产等挑战阻碍了其商业化。科学文献的爆炸式增长和材料、工艺、器件结构的复杂相互作用，使得研究人员难以有效获取、组织和利用该领域的知识。为了解决这个差距，需要一个专门用于钙钛矿PSC前体添加剂发现和设计的语言模型。

Method: 通过系统地挖掘和整理1,232篇高质量的科学出版物，并整合33,269个候选材料的综合库，构建了一个领域特定的指令调优数据集，使用了自动化问答生成和链式思考推理。使用该数据集对QwQ-32B模型进行了微调，从而得到了Perovskite-R1。

Result: Perovskite-R1模型能够智能地综合文献见解，并为缺陷钝化和前体添加剂的选择生成创新且实用的解决方案。对几个模型提出的策略进行的实验验证，证实了它们在提高材料稳定性和性能方面的有效性。

Conclusion: 该研究展示了领域适应的大语言模型在加速材料发现方面的潜力，并为钙钛矿光伏研究中的智能、数据驱动的进步提供了闭环框架。

Abstract: Perovskite solar cells (PSCs) have rapidly emerged as a leading contender in
next-generation photovoltaic technologies, owing to their exceptional power
conversion efficiencies and advantageous material properties. Despite these
advances, challenges such as long-term stability, environmental sustainability,
and scalable manufacturing continue to hinder their commercialization.
Precursor additive engineering has shown promise in addressing these issues by
enhancing both the performance and durability of PSCs. However, the explosive
growth of scientific literature and the complex interplay of materials,
processes, and device architectures make it increasingly difficult for
researchers to efficiently access, organize, and utilize domain knowledge in
this rapidly evolving field. To address this gap, we introduce Perovskite-R1, a
specialized large language model (LLM) with advanced reasoning capabilities
tailored for the discovery and design of PSC precursor additives. By
systematically mining and curating 1,232 high-quality scientific publications
and integrating a comprehensive library of 33,269 candidate materials, we
constructed a domain-specific instruction-tuning dataset using automated
question-answer generation and chain-of-thought reasoning. Fine-tuning the
QwQ-32B model on this dataset resulted in Perovskite-R1, which can
intelligently synthesize literature insights and generate innovative and
practical solutions for defect passivation and the selection of precursor
additives. Experimental validation of several model-proposed strategies
confirms their effectiveness in improving material stability and performance.
Our work demonstrates the potential of domain-adapted LLMs in accelerating
materials discovery and provides a closed-loop framework for intelligent,
data-driven advancements in perovskite photovoltaic research.

</details>


### [351] [LLM Data Selection and Utilization via Dynamic Bi-level Optimization](https://arxiv.org/abs/2507.16178)
*Yang Yu,Kai Han,Hang Zhou,Yehui Tang,Kaiqi Huang,Yunhe Wang,Dacheng Tao*

Main category: cs.LG

TL;DR: 提出了一种新的数据加权模型（DWM），通过双层优化框架动态调整 LLM 训练数据的权重，提高了模型性能，并具有良好的迁移性。


<details>
  <summary>Details</summary>
Motivation: 当前数据选择方法依赖于静态、与训练无关的标准，未能考虑模型训练和数据之间动态的相互作用。因此，需要一种能够动态调整数据权重以提高训练效率和降低成本的方法。

Method: 提出了一种数据加权模型（DWM），并采用双层优化框架来更新权重模型，以捕捉训练过程中模型动态的数据偏好。

Result: DWM 增强了使用随机选择数据训练的模型的性能。学习到的权重模型可以迁移以增强其他数据选择方法和不同大小的模型。研究还分析了模型数据偏好在训练过程中的演变。

Conclusion: 该研究提出的数据加权模型（DWM）能够动态调整批次内数据的权重，以实现 LLM 训练过程中的动态数据利用。实验证明，DWM 能够提升随机选择数据的模型性能，并且学习到的权重模型可以迁移应用于其他数据选择方法和不同大小的模型。此外，研究还分析了模型数据偏好在训练过程中的演变，为理解模型训练期间的数据偏好提供了新的见解。

Abstract: While large-scale training data is fundamental for developing capable large
language models (LLMs), strategically selecting high-quality data has emerged
as a critical approach to enhance training efficiency and reduce computational
costs. Current data selection methodologies predominantly rely on static,
training-agnostic criteria, failing to account for the dynamic model training
and data interactions. In this paper, we propose a new Data Weighting Model
(DWM) to adjust the weight of selected data within each batch to achieve a
dynamic data utilization during LLM training. Specially, to better capture the
dynamic data preference of the trained model, a bi-level optimization framework
is implemented to update the weighting model. Our experiments demonstrate that
DWM enhances the performance of models trained with randomly-selected data, and
the learned weighting model can be transferred to enhance other data selection
methods and models of different sizes. Moreover, we further analyze how a
model's data preferences evolve throughout training, providing new insights
into the data preference of the model during training.

</details>


### [352] [EBaReT: Expert-guided Bag Reward Transformer for Auto Bidding](https://arxiv.org/abs/2507.16186)
*Kaiyuan Li,Pengyu Wang,Yunshan Peng,Pengjia Yuan,Yanxiang Zeng,Rui Xiang,Yanhua Cheng,Xialong Liu,Peng Jiang*

Main category: cs.LG

TL;DR: 针对自动化投标中的数据质量和奖励不确定性问题，提出了一种名为EBaReT的新模型，该模型结合了专家轨迹、PU学习和新颖的奖励函数，并通过实验证明其性能优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 鉴于传统的基于马尔可夫决策过程（MDP）的自动化投标方法存在长期依赖性问题，并且近期研究探索的生成式强化学习方法依赖于监督学习，容易受到次优出价和低点击率/转化率导致的低概率奖励带来的低数据质量问题的影响，而现有研究很少关注这些挑战。

Method: 提出了一种新颖的专家引导袋奖励Transformer（EBaReT）模型，以解决数据质量和奖励不确定性问题。具体来说，为了解决数据质量问题，生成了一组专家轨迹作为训练过程的补充数据，并采用基于正例-无例（PU）学习的判别器来识别专家转换。为了确保决策达到专家水平，还设计了一种新颖的专家引导推理策略。此外，为了减轻奖励的不确定性，将一定时期内的转换视为一个“袋子”，并精心设计了一个能够带来更平滑奖励获取的奖励函数。

Result: 通过大量的实验证明，我们提出的模型在自动化投标方面取得了优于现有最先进方法的性能。

Conclusion: 本研究提出的EBaReT模型在真实数据集上的实验结果表明，其在自动化投标方面优于现有的最先进方法。

Abstract: Reinforcement learning has been widely applied in automated bidding.
Traditional approaches model bidding as a Markov Decision Process (MDP).
Recently, some studies have explored using generative reinforcement learning
methods to address long-term dependency issues in bidding environments.
Although effective, these methods typically rely on supervised learning
approaches, which are vulnerable to low data quality due to the amount of
sub-optimal bids and low probability rewards resulting from the low click and
conversion rates. Unfortunately, few studies have addressed these challenges.
  In this paper, we formalize the automated bidding as a sequence
decision-making problem and propose a novel Expert-guided Bag Reward
Transformer (EBaReT) to address concerns related to data quality and
uncertainty rewards. Specifically, to tackle data quality issues, we generate a
set of expert trajectories to serve as supplementary data in the training
process and employ a Positive-Unlabeled (PU) learning-based discriminator to
identify expert transitions. To ensure the decision also meets the expert
level, we further design a novel expert-guided inference strategy. Moreover, to
mitigate the uncertainty of rewards, we consider the transitions within a
certain period as a "bag" and carefully design a reward function that leads to
a smoother acquisition of rewards. Extensive experiments demonstrate that our
model achieves superior performance compared to state-of-the-art bidding
methods.

</details>


### [353] [METER: Multi-modal Evidence-based Thinking and Explainable Reasoning -- Algorithm and Benchmark](https://arxiv.org/abs/2507.16206)
*Xu Yang,Qi Zhang,Shuming Jiang,Yaowen Xu,Zhaofan Zou,Hao Sun,Xuelong Li*

Main category: cs.LG

TL;DR: METER是一个多模态、可解释的伪造检测基准，旨在解决现有方法的局限性，并通过创新的训练策略提升检测性能。


<details>
  <summary>Details</summary>
Motivation: 现有的伪造检测方法主要侧重于二元分类，缺乏对伪造细节和来源的解释，且通常独立处理不同模态，缺乏跨模态的统一基准和可解释性。

Method: 提出了一种名为METER的多模态基准，包含图像、视频、音频和视听内容，并提供四种检测任务，要求不仅进行真伪分类，还要提供基于证据链的解释，如时空定位、文本理由和伪造类型追踪。此外，还提出了一种结合SFT、DPO和一种整合了人类对齐评估器与CoT推理的新GRPO阶段的人类对齐三阶段CoT训练策略。

Result: METER基准相比于现有基准具有更广泛的模态覆盖和更丰富的可解释性指标，如空间/时间IoU、多类别追踪和证据一致性。

Conclusion: METER的提出为生成式媒体中的可解释、可泛化伪造检测提供了一个标准化的基础，有望推动相关领域的研究进展。

Abstract: With the rapid advancement of generative AI, synthetic content across images,
videos, and audio has become increasingly realistic, amplifying the risk of
misinformation. Existing detection approaches predominantly focus on binary
classification while lacking detailed and interpretable explanations of
forgeries, which limits their applicability in safety-critical scenarios.
Moreover, current methods often treat each modality separately, without a
unified benchmark for cross-modal forgery detection and interpretation. To
address these challenges, we introduce METER, a unified, multi-modal benchmark
for interpretable forgery detection spanning images, videos, audio, and
audio-visual content. Our dataset comprises four tracks, each requiring not
only real-vs-fake classification but also evidence-chain-based explanations,
including spatio-temporal localization, textual rationales, and forgery type
tracing. Compared to prior benchmarks, METER offers broader modality coverage
and richer interpretability metrics such as spatial/temporal IoU, multi-class
tracing, and evidence consistency. We further propose a human-aligned,
three-stage Chain-of-Thought (CoT) training strategy combining SFT, DPO, and a
novel GRPO stage that integrates a human-aligned evaluator with CoT reasoning.
We hope METER will serve as a standardized foundation for advancing
generalizable and interpretable forgery detection in the era of generative
media.

</details>


### [354] [Aligned Manifold Property and Topology Point Clouds for Learning Molecular Properties](https://arxiv.org/abs/2507.16223)
*Alexander Mihalcea*

Main category: cs.LG

TL;DR: AMPTCR通过结合量子标量场和拓扑描述符，创建了一种新的分子表面表示方法，能够用更少的计算资源在分子属性预测任务中取得优异的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的机器学习模型在分子属性预测方面，往往忽略了驱动分子间行为的表面局部现象，或者在处理三维信息时存在计算成本高昂或损失细节的问题。

Method: AMPTCR（Aligned Manifold Property and Topology Cloud Representation）是一种分子表面表示方法，它将局部量子标量场和自定义拓扑描述符结合在对齐的点云格式中。每个表面点包含一个化学标量、测地拓扑向量和转换到标准参考系的坐标，以便使用传统的SE(3)-敏感架构进行有效学习。

Result: 在分子量预测任务中，AMPTCR的验证R^2达到了0.87，证实了其编码物理信息的有效性。在细菌生长抑制任务中，AMPTCR能够通过杜尔富基函数（Dual Fukui functions）作为电子描述符，并结合摩根指纹（Morgan Fingerprints）作为辅助数据，实现分类和直接回归。在分类任务中，ROC AUC达到了0.912；在回归任务中，R^2达到了0.54。

Conclusion: AMPTCR是一种紧凑、表达能力强且架构无关的分子表面性质表示方法，能够有效地模拟与表面相关的分子性质。

Abstract: Machine learning models for molecular property prediction generally rely on
representations -- such as SMILES strings and molecular graphs -- that overlook
the surface-local phenomena driving intermolecular behavior. 3D-based
approaches often reduce surface detail or require computationally expensive
SE(3)-equivariant architectures to manage spatial variance. To overcome these
limitations, this work introduces AMPTCR (Aligned Manifold Property and
Topology Cloud Representation), a molecular surface representation that
combines local quantum-derived scalar fields and custom topological descriptors
within an aligned point cloud format. Each surface point includes a chemically
meaningful scalar, geodesically derived topology vectors, and coordinates
transformed into a canonical reference frame, enabling efficient learning with
conventional SE(3)-sensitive architectures. AMPTCR is evaluated using a DGCNN
framework on two tasks: molecular weight and bacterial growth inhibition. For
molecular weight, results confirm that AMPTCR encodes physically meaningful
data, with a validation R^2 of 0.87. In the bacterial inhibition task, AMPTCR
enables both classification and direct regression of E. coli inhibition values
using Dual Fukui functions as the electronic descriptor and Morgan Fingerprints
as auxiliary data, achieving an ROC AUC of 0.912 on the classification task,
and an R^2 of 0.54 on the regression task. These results help demonstrate that
AMPTCR offers a compact, expressive, and architecture-agnostic representation
for modeling surface-mediated molecular properties.

</details>


### [355] [Understanding Generalization, Robustness, and Interpretability in Low-Capacity Neural Networks](https://arxiv.org/abs/2507.16278)
*Yash Kumar*

Main category: cs.LG

TL;DR: 本文研究了低容量神经网络的容量、稀疏性和鲁棒性。实验发现，模型容量需求随任务复杂度增加，网络在高度稀疏时仍能保持高性能，并且过参数化有助于提高模型对抗扰动的能力。稀疏子网络保留了原始模型的推理过程。


<details>
  <summary>Details</summary>
Motivation: 尽管深度学习模型通常是过参数化的，但研究低容量网络中的容量、稀疏性和鲁棒性之间的基本相互作用仍然是一个重要的研究领域。

Method: 通过创建一系列不同视觉难度的MNIST二分类任务（例如0和1 vs 4和9），建立了一个可控框架来研究低容量网络中的容量、稀疏性和鲁棒性之间的相互作用。

Result: 实验揭示了三个核心发现：1. 成功泛化所需的最小模型容量与任务复杂度直接相关。2. 训练好的网络对极端幅度剪枝（高达95%稀疏度）具有鲁棒性，存在稀疏的高性能子网络。3. 过参数化能显著提高模型对抗输入扰动的鲁棒性。通过显著性图进行的解释性分析证实了稀疏子网络保留了原始密集模型的推理过程。

Conclusion: 研究表明，最小模型容量与任务复杂度直接相关，训练好的网络在极端剪枝下依然表现稳健，并且过参数化能显著提高模型对抗输入扰动的鲁棒性。稀疏子网络保留了原始密集模型的推理过程。

Abstract: Although modern deep learning often relies on massive over-parameterized
models, the fundamental interplay between capacity, sparsity, and robustness in
low-capacity networks remains a vital area of study. We introduce a controlled
framework to investigate these properties by creating a suite of binary
classification tasks from the MNIST dataset with increasing visual difficulty
(e.g., 0 and 1 vs. 4 and 9). Our experiments reveal three core findings. First,
the minimum model capacity required for successful generalization scales
directly with task complexity. Second, these trained networks are robust to
extreme magnitude pruning (up to 95% sparsity), revealing the existence of
sparse, high-performing subnetworks. Third, we show that over-parameterization
provides a significant advantage in robustness against input corruption.
Interpretability analysis via saliency maps further confirms that these
identified sparse subnetworks preserve the core reasoning process of the
original dense models. This work provides a clear, empirical demonstration of
the foundational trade-offs governing simple neural networks.

</details>


### [356] [Towards Resilient Safety-driven Unlearning for Diffusion Models against Downstream Fine-tuning](https://arxiv.org/abs/2507.16302)
*Boheng Li,Renjie Gu,Junjie Wang,Leyi Qi,Yiming Li,Run Wang,Zhan Qin,Tianwei Zhang*

Main category: cs.LG

TL;DR: 本文提出ResAlign框架，解决了文本到图像扩散模型在下游微调后安全遗忘方法效果不佳的问题。ResAlign通过Moreau包络和元学习策略，提高了遗忘的安全性和泛化能力，并在实验中表现优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有的文本到图像（T2I）扩散模型在生成图像方面表现出色，但常常继承预训练数据中的有害行为，引发了安全担忧。虽然近期的安全驱动遗忘方法在抑制模型毒性方面取得了一定进展，但这些方法在下游微调后效果不佳。本文旨在解决这一问题，提出ResAlign框架以增强遗忘方法在下游微调后的鲁棒性。

Method: 本文提出了一种名为ResAlign的安全驱动遗忘框架，该框架通过对下游微调过程进行建模，并利用Moreau包络进行重构，实现了高效的梯度估计，以最小化有害行为的恢复。此外，还提出了一种元学习策略，用于模拟多样化的微调场景，以增强模型的泛化能力。

Result: ResAlign框架在各种数据集、微调方法和配置下进行了广泛的实验，结果表明，与现有遗忘方法相比，ResAlign在下游微调后能更有效地保持模型的安全性，并且在保持良性生成能力方面表现良好。

Conclusion: ResAlign框架通过对下游微调进行建模并采用Moreau包络重构，可以有效地最小化有害行为的恢复。元学习策略的引入有助于模拟不同的微调场景，从而提高模型的泛化能力。实验证明，ResAlign在保留下游微调后模型安全性的同时，能够很好地保持良性生成能力，优于以往的遗忘方法。

Abstract: Text-to-image (T2I) diffusion models have achieved impressive image
generation quality and are increasingly fine-tuned for personalized
applications. However, these models often inherit unsafe behaviors from toxic
pretraining data, raising growing safety concerns. While recent safety-driven
unlearning methods have made promising progress in suppressing model toxicity,
they are identified to be fragile to downstream fine-tuning, where we reveal
that state-of-the-art methods largely fail to retain their effectiveness even
when fine-tuned on entirely benign datasets. To mitigate this problem, in this
paper, we propose ResAlign, a safety-driven unlearning framework with enhanced
resilience against downstream fine-tuning. By modeling downstream fine-tuning
as an implicit optimization problem with a Moreau Envelope-based reformulation,
ResAlign enables efficient gradient estimation to minimize the recovery of
harmful behaviors. Additionally, a meta-learning strategy is proposed to
simulate a diverse distribution of fine-tuning scenarios to improve
generalization. Extensive experiments across a wide range of datasets,
fine-tuning methods, and configurations demonstrate that ResAlign consistently
outperforms prior unlearning approaches in retaining safety after downstream
fine-tuning while preserving benign generation capability well.

</details>


### [357] [Leveraging Personalized PageRank and Higher-Order Topological Structures for Heterophily Mitigation in Graph Neural Networks](https://arxiv.org/abs/2507.16347)
*Yumeng Wang,Zengyi Wo,Wenjun Wang,Xingcheng Fu,Minglai Shao*

Main category: cs.LG

TL;DR: HPGNN通过整合高阶PageRank和GNN来解决异质图中的多尺度信息和噪声问题，并在实验中表现出色。


<details>
  <summary>Details</summary>
Motivation: 现有的异质图模型主要依赖于成对关系，忽略了高阶结构带来的多尺度信息，导致在存在噪声（节点间冲突类别信息）的情况下性能不佳。

Method: HPGNN通过整合高阶个性化PageRank和图神经网络，利用高阶个性化PageRank的高阶近似来捕获长距离和多尺度节点交互，并将其嵌入到卷积网络中，从而有效解决了异质图中存在的挑战。

Result: 在异质图的基准数据集上的广泛实验表明，HPGNN的性能优于七种最先进方法中的五种，并且在同质图上保持了竞争力。

Conclusion: HPGNN

Abstract: Graph Neural Networks (GNNs) excel in node classification tasks but often
assume homophily, where connected nodes share similar labels. This assumption
does not hold in many real-world heterophilic graphs. Existing models for
heterophilic graphs primarily rely on pairwise relationships, overlooking
multi-scale information from higher-order structures. This leads to suboptimal
performance, particularly under noise from conflicting class information across
nodes. To address these challenges, we propose HPGNN, a novel model integrating
Higher-order Personalized PageRank with Graph Neural Networks. HPGNN introduces
an efficient high-order approximation of Personalized PageRank (PPR) to capture
long-range and multi-scale node interactions. This approach reduces
computational complexity and mitigates noise from surrounding information. By
embedding higher-order structural information into convolutional networks,
HPGNN effectively models key interactions across diverse graph dimensions.
Extensive experiments on benchmark datasets demonstrate HPGNN's effectiveness.
The model achieves better performance than five out of seven state-of-the-art
methods on heterophilic graphs in downstream tasks while maintaining
competitive performance on homophilic graphs. HPGNN's ability to balance
multi-scale information and robustness to noise makes it a versatile solution
for real-world graph learning challenges. Codes are available at
https://github.com/streetcorner/HPGNN.

</details>


### [358] [Bipartite Patient-Modality Graph Learning with Event-Conditional Modelling of Censoring for Cancer Survival Prediction](https://arxiv.org/abs/2507.16363)
*Hailin Yue,Hulin Kuang,Jin Liu,Junjian Li,Lanlan Wang,Mengshen He,Jianxin Wang*

Main category: cs.LG

TL;DR: CenSurv通过二分图学习和事件条件删失建模，提高了癌症生存预测的准确性和鲁棒性，尤其在处理模态缺失和删失数据方面表现出色。


<details>
  <summary>Details</summary>
Motivation: 准确预测癌症患者的生存期对于个性化治疗至关重要。然而，现有研究仅关注具有已知生存风险的样本之间的关系，未能充分利用删失样本的价值。此外，这些研究在模态缺失场景下可能出现性能下降，甚至在推理过程中也存在困难。

Method: 该研究提出了一种用于癌症生存预测的二分图患者-模态学习与事件条件删失建模（CenSurv）。首先，利用图结构对多模态数据进行建模并获得表示。然后，为了缓解模态缺失场景下的性能下降，设计了一个二分图来模拟各种模态缺失场景下的患者-模态关系，并利用完整-不完整对齐策略来探索模态无关特征。最后，设计了一个即插即用的事件条件删失建模（ECMC）模块，该模块使用动态动量累积置信度来选择可靠的删失数据，为这些删失数据分配更准确的生存时间，并将它们作为未删失数据纳入训练。

Result: CenSurv在5个公开癌症数据集上的综合评估显示，其在平均C指数方面优于最先进的方法3.1%，并且在各种模态缺失场景下表现出优异的鲁棒性。此外，使用即插即用的ECMC模块，8个基线的平均C指数在5个数据集上增加了1.3%。

Conclusion: CenSurv在5个公开癌症数据集上的综合评估显示，其在平均C指数方面优于最先进的方法3.1%，并且在各种模态缺失场景下表现出优异的鲁棒性。此外，使用即插即用的ECMC模块，8个基线的平均C指数在5个数据集上增加了1.3%。

Abstract: Accurately predicting the survival of cancer patients is crucial for
personalized treatment. However, existing studies focus solely on the
relationships between samples with known survival risks, without fully
leveraging the value of censored samples. Furthermore, these studies may suffer
performance degradation in modality-missing scenarios and even struggle during
the inference process. In this study, we propose a bipartite patient-modality
graph learning with event-conditional modelling of censoring for cancer
survival prediction (CenSurv). Specifically, we first use graph structure to
model multimodal data and obtain representation. Then, to alleviate performance
degradation in modality-missing scenarios, we design a bipartite graph to
simulate the patient-modality relationship in various modality-missing
scenarios and leverage a complete-incomplete alignment strategy to explore
modality-agnostic features. Finally, we design a plug-and-play
event-conditional modeling of censoring (ECMC) that selects reliable censored
data using dynamic momentum accumulation confidences, assigns more accurate
survival times to these censored data, and incorporates them as uncensored data
into training. Comprehensive evaluations on 5 publicly cancer datasets showcase
the superiority of CenSurv over the best state-of-the-art by 3.1% in terms of
the mean C-index, while also exhibiting excellent robustness under various
modality-missing scenarios. In addition, using the plug-and-play ECMC module,
the mean C-index of 8 baselines increased by 1.3% across 5 datasets. Code of
CenSurv is available at https://github.com/yuehailin/CenSurv.

</details>


### [359] [Optimization and generalization analysis for two-layer physics-informed neural networks without over-parametrization](https://arxiv.org/abs/2507.16380)
*Zhihan Zeng,Yiqi Gu*

Main category: cs.LG

TL;DR: 研究了随机梯度下降（SGD）在训练两层物理信息神经网络（PINNs）时的优化和泛化行为，提出了一种避免过度参数化的新理论，并证明了在特定条件下，增加网络宽度可以有效降低损失。


<details>
  <summary>Details</summary>
Motivation: 为了解决现有关于在过度参数化条件下 SGD 训练 PINNs 的理论可能导致高昂计算成本且不切实际的问题，提出新的分析方法。

Method: 通过对两层 PINNs 的训练过程进行新的优化和泛化分析，并在特定假设下避免过度参数化，来研究随机梯度下降（SGD）的行为。

Result: 在特定条件下，证明了当网络宽度超过仅依赖于 ε 和问题的阈值时，训练损失和期望损失可以降低到 O(ε)。

Conclusion: 所提出的理论在避免过度参数化的情况下，对训练两层物理信息神经网络（PINNs）的随机梯度下降（SGD）进行了新的优化和泛化分析，表明当网络宽度超过特定阈值时，训练损失和期望损失可以降低到 O(ε)。

Abstract: This work focuses on the behavior of stochastic gradient descent (SGD) in
solving least-squares regression with physics-informed neural networks (PINNs).
Past work on this topic has been based on the over-parameterization regime,
whose convergence may require the network width to increase vastly with the
number of training samples. So, the theory derived from over-parameterization
may incur prohibitive computational costs and is far from practical
experiments. We perform new optimization and generalization analysis for SGD in
training two-layer PINNs, making certain assumptions about the target function
to avoid over-parameterization. Given $\epsilon>0$, we show that if the network
width exceeds a threshold that depends only on $\epsilon$ and the problem, then
the training loss and expected loss will decrease below $O(\epsilon)$.

</details>


### [360] [Improving Predictions on Highly Unbalanced Data Using Open Source Synthetic Data Upsampling](https://arxiv.org/abs/2507.16419)
*Ivona Krchova,Michael Platzer,Paul Tiwald*

Main category: cs.LG

TL;DR: AI合成数据可显著提升不平衡表格数据预测精度，尤其在少数样本稀少时。


<details>
  <summary>Details</summary>
Motivation: 不平衡表格数据集在预测建模和数据分析中带来了严峻挑战，因为少数类别的样本量远小于多数类别，导致传统机器学习算法倾向于多数类，模型产生偏差，难以准确表示少数类。合成数据通过生成新的、多样化且高度真实的样本，为解决少数类别代表性不足的问题提供了希望。

Method: 该研究通过一个基准研究，评估了使用AI生成的合成数据进行过采样（upsampling）处理高度不平衡表格数据集的有效性。研究采用了MOSTLY AI的Synthetic Data SDK，并将其与标准的过采样方法（如naive oversampling和SMOTE-NC）进行了比较，分析了在不同数据集上训练的预测模型的性能。

Result: 研究结果表明，合成数据可以通过生成多样化的数据点来填补特征空间稀疏区域的空白，从而提高少数群体的预测准确性。使用合成数据进行过采样的训练数据集能够持续产生性能优异的预测模型，尤其是在处理包含极少量少数样本的混合类型数据集时。

Conclusion: 该研究表明，人工智能生成的合成数据在处理高度不平衡的表格数据集方面具有显著优势，能够提高少数类别的预测准确性，特别是在混合类型和少数样本极少的情况下。

Abstract: Unbalanced tabular data sets present significant challenges for predictive
modeling and data analysis across a wide range of applications. In many
real-world scenarios, such as fraud detection, medical diagnosis, and rare
event prediction, minority classes are vastly underrepresented, making it
difficult for traditional machine learning algorithms to achieve high accuracy.
These algorithms tend to favor the majority class, leading to biased models
that struggle to accurately represent minority classes. Synthetic data holds
promise for addressing the under-representation of minority classes by
providing new, diverse, and highly realistic samples. This paper presents a
benchmark study on the use of AI-generated synthetic data for upsampling highly
unbalanced tabular data sets.
  We evaluate the effectiveness of an open-source solution, the Synthetic Data
SDK by MOSTLY AI, which provides a flexible and user-friendly approach to
synthetic upsampling for mixed-type data. We compare predictive models trained
on data sets upsampled with synthetic records to those using standard methods,
such as naive oversampling and SMOTE-NC. Our results demonstrate that synthetic
data can improve predictive accuracy for minority groups by generating diverse
data points that fill gaps in sparse regions of the feature space. We show that
upsampled synthetic training data consistently results in top-performing
predictive models, particularly for mixed-type data sets containing very few
minority samples.

</details>


### [361] [Canonical Correlation Patterns for Validating Clustering of Multivariate Time Series](https://arxiv.org/abs/2507.16497)
*Isabella Degen,Zahraa S Abdallah,Kate Robson Brown,Henry W J Reeve*

Main category: cs.LG

TL;DR: 相关性聚类在各种应用中很有用，但验证其结果是一个挑战。本研究引入了规范相关模式作为验证目标，并提出了一种新的验证方法，该方法在合成数据集上表现优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有聚类验证指标在相关性模式上的有效性未经系统评估，且缺乏适用于相关性模式的验证目标，本研究旨在解决这一验证差距。

Method: 提出了一种新的聚类验证方法，通过引入规范相关模式将无限的相关空间离散化为有限、可解释的参考模式，并使用L1范数进行映射，L5范数用于轮廓宽度准则和Davies-Bouldin指数。

Result: 使用具有完美地面真实值的合成数据集，证明了规范模式提供了可靠的验证目标，并且所提出的方法在分布变化下表现稳健，能够有效检测相关性结构退化，为实际应用提供了指导方针。

Conclusion: 本研究通过引入规范相关模式，为基于相关性的聚类提供了数学上定义的验证目标，弥合了验证差距，使聚类结果能够被严谨地评估。

Abstract: Clustering of multivariate time series using correlation-based methods
reveals regime changes in relationships between variables across health,
finance, and industrial applications. However, validating whether discovered
clusters represent distinct relationships rather than arbitrary groupings
remains a fundamental challenge. Existing clustering validity indices were
developed for Euclidean data, and their effectiveness for correlation patterns
has not been systematically evaluated. Unlike Euclidean clustering, where
geometric shapes provide discrete reference targets, correlations exist in
continuous space without equivalent reference patterns. We address this
validation gap by introducing canonical correlation patterns as mathematically
defined validation targets that discretise the infinite correlation space into
finite, interpretable reference patterns. Using synthetic datasets with perfect
ground truth across controlled conditions, we demonstrate that canonical
patterns provide reliable validation targets, with L1 norm for mapping and L5
norm for silhouette width criterion and Davies-Bouldin index showing superior
performance. These methods are robust to distribution shifts and appropriately
detect correlation structure degradation, enabling practical implementation
guidelines. This work establishes a methodological foundation for rigorous
correlation-based clustering validation in high-stakes domains.

</details>


### [362] [Analogy making as amortised model construction](https://arxiv.org/abs/2507.16511)
*David G. Nagy,Tingke Shen,Hanqi Zhou,Charley M. Wu,Peter Dayan*

Main category: cs.LG

TL;DR: 类比通过重用先前经验中的结构来帮助智能体构建和规划内部模型，从而在模型保真度和计算成本之间取得平衡。


<details>
  <summary>Details</summary>
Motivation: 为了在计算成本和模型保真度之间取得平衡，类比在通过重用旧经验来构建和规划内部模型方面发挥着关键作用。

Method: 将类比形式化为马尔可夫决策过程之间的偏同态关系，并提出了一个框架，其中来自先前解释的抽象模块可作为可组合的构建块，用于新的解释。

Result: 模块化重用支持跨具有共享结构本质的域灵活适应策略和表示。

Conclusion: 类比通过在马尔可夫决策过程之间建立偏同态关系，使智能体能够重用先前经验中的相关结构，并摊销模型构建和规划的计算成本。

Abstract: Humans flexibly construct internal models to navigate novel situations. To be
useful, these internal models must be sufficiently faithful to the environment
that resource-limited planning leads to adequate outcomes; equally, they must
be tractable to construct in the first place. We argue that analogy plays a
central role in these processes, enabling agents to reuse solution-relevant
structure from past experiences and amortise the computational costs of both
model construction (construal) and planning. Formalising analogies as partial
homomorphisms between Markov decision processes, we sketch a framework in which
abstract modules, derived from previous construals, serve as composable
building blocks for new ones. This modular reuse allows for flexible adaptation
of policies and representations across domains with shared structural essence.

</details>


### [363] [confopt: A Library for Implementation and Evaluation of Gradient-based One-Shot NAS Methods](https://arxiv.org/abs/2507.16533)
*Abhash Kumar Jha,Shakiba Moradian,Arjun Krishnakumar,Martin Rapp,Frank Hutter*

Main category: cs.LG

TL;DR: Confopt库用于改进和评估梯度下降单次NAS方法，解决了现有基准测试和代码实现分散的问题，并发现当前评估方法的缺陷。


<details>
  <summary>Details</summary>
Motivation: 当前梯度下降单次NAS方法过度依赖DARTS基准测试，导致研究饱和；且实现方法分散在不同代码库，不利于公平比较和进一步发展。

Method: 提出名为Configurable Optimizer (confopt) 的可扩展库，该库提供最小化的API，便于用户集成新的搜索空间并分解NAS优化器。基于此框架创建了一系列新的DARTS基准测试。

Result: Confopt库简化了梯度下降单次NAS方法的开发和评估。新的基准测试和评估协议揭示了当前评估方法中存在的关键缺陷。

Conclusion: 该论文通过引入Confopt库，并提出新的评估协议，揭示了梯度下降单次神经网络结构搜索（NAS）方法评估中存在的关键缺陷。

Abstract: Gradient-based one-shot neural architecture search (NAS) has significantly
reduced the cost of exploring architectural spaces with discrete design
choices, such as selecting operations within a model. However, the field faces
two major challenges. First, evaluations of gradient-based NAS methods heavily
rely on the DARTS benchmark, despite the existence of other available
benchmarks. This overreliance has led to saturation, with reported improvements
often falling within the margin of noise. Second, implementations of
gradient-based one-shot NAS methods are fragmented across disparate
repositories, complicating fair and reproducible comparisons and further
development. In this paper, we introduce Configurable Optimizer (confopt), an
extensible library designed to streamline the development and evaluation of
gradient-based one-shot NAS methods. Confopt provides a minimal API that makes
it easy for users to integrate new search spaces, while also supporting the
decomposition of NAS optimizers into their core components. We use this
framework to create a suite of new DARTS-based benchmarks, and combine them
with a novel evaluation protocol to reveal a critical flaw in how
gradient-based one-shot NAS methods are currently assessed. The code can be
found at https://github.com/automl/ConfigurableOptimizer.

</details>


### [364] [Symbolic Graph Intelligence: Hypervector Message Passing for Learning Graph-Level Patterns with Tsetlin Machines](https://arxiv.org/abs/2507.16537)
*Christian D. Blakely*

Main category: cs.LG

TL;DR: 一种利用稀疏二元高维向量和Tsetlin机进行图分类的多层符号框架，具有局部可解释性。


<details>
  <summary>Details</summary>
Motivation: 为了实现一般图分类，并提供一种具有局部可解释性的方法。

Method: 提出了一种多层符号框架，用于利用稀疏二元高维向量和Tsetlin机进行一般图分类。通过结构化消息传递对每个图进行编码，其中节点、边和属性信息被绑定并捆绑成一个符号高维向量。此过程通过从节点属性到边关系再到结构角色的分层绑定来保留图的层次语义，从而产生紧凑、离散的表示。还提出了一种局部可解释性框架，这是该方法的一个关键优势。

Result: 在TUDataset基准测试上进行了验证，结果表明该方法具有竞争力，并且与神经图模型相比具有强大的符号透明度。

Conclusion: 该方法在TUDataset基准测试中展示了具有竞争力的准确性，并与神经图模型相比具有强大的符号透明度。

Abstract: We propose a multilayered symbolic framework for general graph classification
that leverages sparse binary hypervectors and Tsetlin Machines. Each graph is
encoded through structured message passing, where node, edge, and attribute
information are bound and bundled into a symbolic hypervector. This process
preserves the hierarchical semantics of the graph through layered binding from
node attributes to edge relations to structural roles resulting in a compact,
discrete representation. We also formulate a local interpretability framework
which lends itself to a key advantage of our approach being locally
interpretable. We validate our method on TUDataset benchmarks, demonstrating
competitive accuracy with strong symbolic transparency compared to neural graph
models.

</details>


### [365] [Families of Optimal Transport Kernels for Cell Complexes](https://arxiv.org/abs/2507.16569)
*Rahul Khorana*

Main category: cs.LG

TL;DR: 本文提出了一种新的机器学习方法，用于在CW复形上进行学习，解决了现有方法的不足。


<details>
  <summary>Details</summary>
Motivation: 为了解决目前缺乏适用于CW复形学习的机器学习方法的问题，本文提出了一种新的学习表示方法。

Method: 本文推导了细胞复形信号分布之间的Wasserstein距离的显式表达式，并将Fused Gromov-Wasserstein距离扩展到CW复形，最后引入了基于最优传输对偶理论的CW复形上概率测量的核。

Result: 本文提出的方法能够同时包含特征和结构信息，并为CW复形上的概率测量引入了新的核。

Conclusion: 本文基于Hodge-Laplacian矩阵推导了细胞复形信号分布之间的Wasserstein距离的显式表达式，并扩展了Fused Gromov-Wasserstein距离来处理CW复形，最后引入了基于最优传输对偶理论的CW复形上概率测量的核。

Abstract: Recent advances have discussed cell complexes as ideal learning
representations. However, there is a lack of available machine learning methods
suitable for learning on CW complexes. In this paper, we derive an explicit
expression for the Wasserstein distance between cell complex signal
distributions in terms of a Hodge-Laplacian matrix. This leads to a
structurally meaningful measure to compare CW complexes and define the optimal
transportation map. In order to simultaneously include both feature and
structure information, we extend the Fused Gromov-Wasserstein distance to CW
complexes. Finally, we introduce novel kernels over the space of probability
measures on CW complexes based on the dual formulation of optimal transport.

</details>


### [366] [Scaling Linear Attention with Sparse State Expansion](https://arxiv.org/abs/2507.16577)
*Yuqi Pan,Yongqi An,Zheng Li,Yuhong Chou,Ruijie Zhu,Xiaohui Wang,Mingxuan Wang,Jinqiao Wang,Guoqi Li*

Main category: cs.LG

TL;DR: Transformer在处理长文本时效率低下，现有解决方案会降低性能。本文提出的SSE通过稀疏更新和状态分区来改进Transformer的注意力机制，有效解决了效率和性能问题，并在数学推理等任务上取得了优异成果。


<details>
  <summary>Details</summary>
Motivation: Transformer在长上下文场景中存在二次计算和线性内存的效率问题，现有的线性注意力变体虽然解决了效率问题，但牺牲了性能。为解决此局限性并实现更有效的上下文压缩，提出SSE。

Method: 提出了一种名为稀疏状态扩展（SSE）的新框架，该框架通过行稀疏更新和状态分区来改进Transformer的线性注意力机制，以实现更有效的上下文压缩。

Result: SSE及其混合版本（SSE-H）在语言建模、上下文检索和数学推理基准测试中表现出色。SSE在检索任务中表现出强大的性能，并且能够有效地随着状态大小进行扩展。经过强化学习（RL）训练后，SSE-H模型在数学推理任务上取得了最先进的性能。

Conclusion: SSE是一种有前景且高效的长上下文建模架构。

Abstract: The Transformer architecture, despite its widespread success, struggles with
long-context scenarios due to quadratic computation and linear memory growth.
While various linear attention variants mitigate these efficiency constraints
by compressing context into fixed-size states, they often degrade performance
in tasks such as in-context retrieval and reasoning. To address this limitation
and achieve more effective context compression, we propose two key innovations.
First, we introduce a row-sparse update formulation for linear attention by
conceptualizing state updating as information classification. This enables
sparse state updates via softmax-based top-$k$ hard classification, thereby
extending receptive fields and reducing inter-class interference. Second, we
present Sparse State Expansion (SSE) within the sparse framework, which expands
the contextual state into multiple partitions, effectively decoupling parameter
size from state capacity while maintaining the sparse classification paradigm.
Our design, supported by efficient parallelized implementations, yields
effective classification and discriminative state representations. We
extensively validate SSE in both pure linear and hybrid (SSE-H) architectures
across language modeling, in-context retrieval, and mathematical reasoning
benchmarks. SSE demonstrates strong retrieval performance and scales favorably
with state size. Moreover, after reinforcement learning (RL) training, our 2B
SSE-H model achieves state-of-the-art mathematical reasoning performance among
small reasoning models, scoring 64.7 on AIME24 and 51.3 on AIME25,
significantly outperforming similarly sized open-source Transformers. These
results highlight SSE as a promising and efficient architecture for
long-context modeling.

</details>


### [367] [Meta-Learning for Cold-Start Personalization in Prompt-Tuned LLMs](https://arxiv.org/abs/2507.16672)
*Yushang Zhao,Huijie Shen,Dannier Li,Lu Chang,Chengrui Zhou,Yinuo Yang*

Main category: cs.LG

TL;DR: 提出一种元学习框架，通过参数高效的提示调整，解决大语言模型推荐系统冷启动问题，实现快速个性化，并在推荐和金融风险分析领域取得优于基线的效果，同时保持实时运行能力。


<details>
  <summary>Details</summary>
Motivation: 现有的基于大语言模型的推荐系统在处理冷启动用户（交互历史很少）时适应性差，且基于监督微调和协同过滤的解决方案维护成本高昂。因此，需要一种能够快速适应冷启动用户并高效个性化推荐系统的方法。

Method: 该研究提出了一种基于元学习的框架，用于参数高效的提示调整，以个性化大语言模型推荐系统。具体方法包括：1. 将每个用户视为一个独立的任务。2. 使用一阶（Reptile）和二阶（MAML）优化算法来学习软提示嵌入，这些嵌入作为输入令牌的增强，代表用户行为先验。3. 通过经验采样、内循环适应和外循环泛化来对提示进行元优化。4. 在MovieLens-1M、Amazon Reviews和Recbole数据集上进行评估，并与基线模型进行比较。

Result: 该元学习框架在MovieLens-1M、Amazon Reviews和Recbole数据集上，在NDCG@10、HR@10和MRR指标上均优于强大的基线模型。此外，该模型能在消费级GPU上实现实时运行（低于300毫秒），并且能够支持零历史记录的用户个性化，适应时间仅为275毫秒。这一特性还被成功应用于金融领域，通过缩短检测延迟和提高支付网络稳定性，实现了实时的风险分析。

Conclusion: 该研究提出了一种新颖的元学习框架，通过参数高效的提示调整，能够有效地个性化基于大语言模型的推荐系统，尤其是在用户数据稀疏的冷启动场景下。该框架通过将用户视为任务，利用一阶和二阶优化学习软提示嵌入，并在多个数据集上证明了其优越的性能和实时适应能力。此外，该框架还能应用于金融领域，通过实时风险分析提高支付网络的稳定性和国家金融基础设施的韧性。

Abstract: Generative, explainable, and flexible recommender systems, derived using
Large Language Models (LLM) are promising and poorly adapted to the cold-start
user situation, where there is little to no history of interaction. The current
solutions i.e. supervised fine-tuning and collaborative filtering are
dense-user-item focused and would be expensive to maintain and update. This
paper introduces a meta-learning framework, that can be used to perform
parameter-efficient prompt-tuning, to effectively personalize LLM-based
recommender systems quickly at cold-start. The model learns soft prompt
embeddings with first-order (Reptile) and second-order (MAML) optimization by
treating each of the users as the tasks. As augmentations to the input tokens,
these learnable vectors are the differentiable control variables that represent
user behavioral priors. The prompts are meta-optimized through episodic
sampling, inner-loop adaptation, and outer-loop generalization. On
MovieLens-1M, Amazon Reviews, and Recbole, we can see that our adaptive model
outperforms strong baselines in NDCG@10, HR@10, and MRR, and it runs in
real-time (i.e., below 300 ms) on consumer GPUs. Zero-history personalization
is also supported by this scalable solution, and its 275 ms rate of adaptation
allows successful real-time risk profiling of financial systems by shortening
detection latency and improving payment network stability. Crucially, the 275
ms adaptation capability can enable real-time risk profiling for financial
institutions, reducing systemic vulnerability detection latency significantly
versus traditional compliance checks. By preventing contagion in payment
networks (e.g., Fedwire), the framework strengthens national financial
infrastructure resilience.

</details>


### [368] [GASPnet: Global Agreement to Synchronize Phases](https://arxiv.org/abs/2507.16674)
*Andrea Alamiaa,Sabine Muzellec,Thomas Serre,Rufin VanRullen*

Main category: cs.LG

TL;DR: 受神经科学的同步绑定理论启发，本文将角度相位引入卷积网络，以增强相似相位神经元间的交互，并抑制相反相位神经元间的交互。实验证明，该方法在准确性、抗噪性和泛化能力上优于标准卷积神经网络，有效解决了视觉绑定问题。


<details>
  <summary>Details</summary>
Motivation: Transformer 架构虽然在人工智能领域取得了巨大成功，但其注意力机制在处理多分类任务时存在局限性。上一项工作提出的“全局路由”机制虽然提高了网络的噪声鲁棒性，但仍不足以应对多分类任务。因此，本研究旨在通过结合 Transformer 的注意力机制和神经科学中的同步绑定理论来改进现有模型，以解决视觉绑定问题并提升模型性能。

Method: 本文提出了一种新颖的机制，将 Transformer 的注意力操作与神经科学中的同步绑定理论相结合。该机制在卷积网络的各层引入了角度相位，并通过 Kuramoto 动力学实现相位对齐，从而增强相位相似神经元之间的操作并抑制相位相反的神经元。

Result: 在包含数字对的数据集和包含 MNIST 数字叠加在 CIFAR-10 图像的数据集上的实验结果表明，该机制相比于传统的卷积神经网络，在准确性、噪声鲁棒性和泛化能力方面均表现更优。

Conclusion: 这项工作提出了一种利用神经科学原理（特别是同步绑定）来解决神经网络中视觉绑定问题的创新机制，并在两个数据集上展示了优于卷积神经网络的性能，包括更好的抗噪性和泛化能力。

Abstract: In recent years, Transformer architectures have revolutionized most fields of
artificial intelligence, relying on an attentional mechanism based on the
agreement between keys and queries to select and route information in the
network. In previous work, we introduced a novel, brain-inspired architecture
that leverages a similar implementation to achieve a global 'routing by
agreement' mechanism. Such a system modulates the network's activity by
matching each neuron's key with a single global query, pooled across the entire
network. Acting as a global attentional system, this mechanism improves noise
robustness over baseline levels but is insufficient for multi-classification
tasks. Here, we improve on this work by proposing a novel mechanism that
combines aspects of the Transformer attentional operations with a compelling
neuroscience theory, namely, binding by synchrony. This theory proposes that
the brain binds together features by synchronizing the temporal activity of
neurons encoding those features. This allows the binding of features from the
same object while efficiently disentangling those from distinct objects. We
drew inspiration from this theory and incorporated angular phases into all
layers of a convolutional network. After achieving phase alignment via Kuramoto
dynamics, we use this approach to enhance operations between neurons with
similar phases and suppresses those with opposite phases. We test the benefits
of this mechanism on two datasets: one composed of pairs of digits and one
composed of a combination of an MNIST item superimposed on a CIFAR-10 image.
Our results reveal better accuracy than CNN networks, proving more robust to
noise and with better generalization abilities. Overall, we propose a novel
mechanism that addresses the visual binding problem in neural networks by
leveraging the synergy between neuroscience and machine learning.

</details>


### [369] [Latent Space Alignment for AI-Native MIMO Semantic Communications](https://arxiv.org/abs/2507.16680)
*Mario Edoardo Pandolfo,Simone Fiorellino,Emilio Calvanese Strinati,Paolo Di Lorenzo*

Main category: cs.LG

TL;DR: 本研究提出了一种利用MIMO通信来解决语义通信中潜在空间不对齐的新方法，通过学习MIMO预编码/解码器对来联合执行潜在空间压缩和语义信道均衡，从而缓解语义不匹配和物理信道损伤。研究提出了线性模型和神经网络模型两种解决方案，并在面向目标的语义通信场景中验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 在语义通信中，当设备依赖不同的语言、逻辑或内部表示时，可能会发生语义不匹配，从而阻碍相互理解。本研究旨在解决这一问题。

Method: 本研究提出了两种解决方案：(i)一种通过交替方向乘子法（ADMM）解决双凸优化问题的线性模型；(ii)一种在传输功率预算和复杂性约束下学习语义MIMO预编码/解码器的基于神经网络的模型。

Result: 数值结果证明了该方法在面向目标的语义通信场景中的有效性，并说明了准确性、通信负担和解决方案复杂性之间的主要权衡。

Conclusion: 该研究提出了一种利用MIMO通信来解决语义通信中潜在空间不对齐的新方法，通过学习MIMO预编码/解码器对来联合执行潜在空间压缩和语义信道均衡，从而缓解语义不匹配和物理信道损伤。

Abstract: Semantic communications focus on prioritizing the understanding of the
meaning behind transmitted data and ensuring the successful completion of tasks
that motivate the exchange of information. However, when devices rely on
different languages, logic, or internal representations, semantic mismatches
may occur, potentially hindering mutual understanding. This paper introduces a
novel approach to addressing latent space misalignment in semantic
communications, exploiting multiple-input multiple-output (MIMO)
communications. Specifically, our method learns a MIMO precoder/decoder pair
that jointly performs latent space compression and semantic channel
equalization, mitigating both semantic mismatches and physical channel
impairments. We explore two solutions: (i) a linear model, optimized by solving
a biconvex optimization problem via the alternating direction method of
multipliers (ADMM); (ii) a neural network-based model, which learns semantic
MIMO precoder/decoder under transmission power budget and complexity
constraints. Numerical results demonstrate the effectiveness of the proposed
approach in a goal-oriented semantic communication scenario, illustrating the
main trade-offs between accuracy, communication burden, and complexity of the
solutions.

</details>


### [370] [FISHER: A Foundation Model for Multi-Modal Industrial Signal Comprehensive Representation](https://arxiv.org/abs/2507.16696)
*Pingyi Fan,Anbai Jiang,Shuwei Zhang,Zhiqiang Lv,Bing Han,Xinhu Zheng,Wenrui Liang,Junjie Li,Wei-Qiang Zhang,Yanmin Qian,Xie Chen,Cheng Lu,Jia Liu*

Main category: cs.LG

TL;DR: FISHER是一个用于多模态工业信号综合表示的基础模型，它能够统一处理M5信号，并在工业异常检测和健康管理任务中表现出色。


<details>
  <summary>Details</summary>
Motivation: 为了有效分析工业信号和检测异常状态，解决SCADA系统中存在的信号异构性（M5问题），并利用跨模态协同效应和强大的扩展定律。

Method: FISHER模型采用STFT子带作为建模单元，并利用了教师-学生SSL框架进行预训练，以支持任意采样率，通过将采样率的增加视为子带信息的拼接。

Result: FISHER模型在RMIS基准测试中，相比于顶尖的SSL模型，展现了通用且出色的能力，实现了高达5.03%的性能提升，并且扩展曲线更优。

Conclusion: FISHER模型在多模态工业信号表示方面展现了通用且出色的能力，在多个健康管理任务上实现了高达5.03%的性能提升，并且具有更高效的扩展曲线。研究还探讨了下游任务的扩展规律，并为未来的工作提供了潜在方向。

Abstract: With the rapid deployment of SCADA systems, how to effectively analyze
industrial signals and detect abnormal states is an urgent need for the
industry. Due to the significant heterogeneity of these signals, which we
summarize as the M5 problem, previous works only focus on small sub-problems
and employ specialized models, failing to utilize the synergies between
modalities and the powerful scaling law. However, we argue that the M5 signals
can be modeled in a unified manner due to the intrinsic similarity. As a
result, we propose FISHER, a Foundation model for multi-modal Industrial Signal
compreHEnsive Representation. To support arbitrary sampling rates, FISHER
considers the increment of sampling rate as the concatenation of sub-band
information. Specifically, FISHER takes the STFT sub-band as the modeling unit
and adopts a teacher student SSL framework for pre-training. We also develop
the RMIS benchmark, which evaluates the representations of M5 industrial
signals on multiple health management tasks. Compared with top SSL models,
FISHER showcases versatile and outstanding capabilities with a general
performance gain up to 5.03%, along with much more efficient scaling curves. We
also investigate the scaling law on downstream tasks and derive potential
avenues for future works. FISHER is now open-sourced on
https://github.com/jianganbai/FISHER

</details>


### [371] [Screen2AX: Vision-Based Approach for Automatic macOS Accessibility Generation](https://arxiv.org/abs/2507.16704)
*Viktor Muryn,Marta Sumyk,Mariya Hirna,Sofiya Garkot,Maksym Shamrai*

Main category: cs.LG

TL;DR: Screen2AX 是一个创新的框架，它能通过分析截图自动生成桌面应用程序的辅助功能元数据，极大地改善了 AI 代理对桌面界面的理解和交互能力。


<details>
  <summary>Details</summary>
Motivation: 为了解决许多应用程序因缺乏或不完整的辅助功能元数据而导致的可访问性问题，并弥补现有研究在捕捉桌面界面复杂性方面的不足，本研究提出了 Screen2AX。

Method: Screen2AX 框架利用视觉-语言和对象检测模型来检测、描述和组织 UI 元素，并模仿 macOS 的系统级辅助功能结构来构建层次化信息。此外，研究人员还创建了三个数据集，用于训练和评估模型。

Result: Screen2AX 在重建辅助功能树方面达到了 77% 的 F1 分数，并能在 Screen2AX-Task 基准测试中提供 2.2 倍于原生辅助功能表示的性能提升，超越了 OmniParser V2 系统。

Conclusion: Screen2AX 框架能够为 macOS 桌面应用程序自动创建实时、树状结构的辅助功能元数据，提高了屏幕内容的解析能力，并显著提升了自主代理在桌面环境中的任务执行性能。

Abstract: Desktop accessibility metadata enables AI agents to interpret screens and
supports users who depend on tools like screen readers. Yet, many applications
remain largely inaccessible due to incomplete or missing metadata provided by
developers - our investigation shows that only 33% of applications on macOS
offer full accessibility support. While recent work on structured screen
representation has primarily addressed specific challenges, such as UI element
detection or captioning, none has attempted to capture the full complexity of
desktop interfaces by replicating their entire hierarchical structure. To
bridge this gap, we introduce Screen2AX, the first framework to automatically
create real-time, tree-structured accessibility metadata from a single
screenshot. Our method uses vision-language and object detection models to
detect, describe, and organize UI elements hierarchically, mirroring macOS's
system-level accessibility structure. To tackle the limited availability of
data for macOS desktop applications, we compiled and publicly released three
datasets encompassing 112 macOS applications, each annotated for UI element
detection, grouping, and hierarchical accessibility metadata alongside
corresponding screenshots. Screen2AX accurately infers hierarchy trees,
achieving a 77% F1 score in reconstructing a complete accessibility tree.
Crucially, these hierarchy trees improve the ability of autonomous agents to
interpret and interact with complex desktop interfaces. We introduce
Screen2AX-Task, a benchmark specifically designed for evaluating autonomous
agent task execution in macOS desktop environments. Using this benchmark, we
demonstrate that Screen2AX delivers a 2.2x performance improvement over native
accessibility representations and surpasses the state-of-the-art OmniParser V2
system on the ScreenSpot benchmark.

</details>


### [372] [Improving Model Classification by Optimizing the Training Dataset](https://arxiv.org/abs/2507.16729)
*Morad Tukan,Loay Mualem,Eitan Netzer,Liran Sigalat*

Main category: cs.LG

TL;DR: This paper presents a framework for tuning coreset generation to improve downstream classification performance, outperforming vanilla coresets and full dataset training.


<details>
  <summary>Details</summary>
Motivation: Conventional sensitivity-based coreset construction often falls short in optimizing for classification performance metrics, e.g., F1 score, focusing instead on loss approximation.

Method: Our method introduces new tunable parameters--including deterministic sampling, class-wise allocation, and refinement via active sampling, beyond traditional sensitivity scores.

Result: Through extensive experiments on diverse datasets and classifiers, we demonstrate that tuned coresets can significantly outperform both vanilla coresets and full dataset training on key classification metrics.

Conclusion: We demonstrate that tuned coresets can significantly outperform both vanilla coresets and full dataset training on key classification metrics, offering an effective path towards better and more efficient model training.

Abstract: In the era of data-centric AI, the ability to curate high-quality training
data is as crucial as model design. Coresets offer a principled approach to
data reduction, enabling efficient learning on large datasets through
importance sampling. However, conventional sensitivity-based coreset
construction often falls short in optimizing for classification performance
metrics, e.g., $F1$ score, focusing instead on loss approximation. In this
work, we present a systematic framework for tuning the coreset generation
process to enhance downstream classification quality. Our method introduces new
tunable parameters--including deterministic sampling, class-wise allocation,
and refinement via active sampling, beyond traditional sensitivity scores.
Through extensive experiments on diverse datasets and classifiers, we
demonstrate that tuned coresets can significantly outperform both vanilla
coresets and full dataset training on key classification metrics, offering an
effective path towards better and more efficient model training.

</details>


### [373] [A Partitioned Sparse Variational Gaussian Process for Fast, Distributed Spatial Modeling](https://arxiv.org/abs/2507.16771)
*Michael Grosskopf,Kellin Rumsey,Ayan Biswas,Earl Lawrence*

Main category: cs.LG

TL;DR: PSVGP通过分区间的通信解决了独立SVGP的边界不连续问题，实现了更平滑、更准确的原位机器学习。


<details>
  <summary>Details</summary>
Motivation: 为了满足未来Exascale（百亿亿次）超级计算机在原位（in situ）训练机器学习算法的需求，特别是处理大量分布式数据时，需要开发可扩展、内存高效且能处理跨节点分布式数据的算法。现有的独立SVGP方法虽然可扩展且准确，但在邻近分区边界处会产生不连续的响应面。

Method: 提出了一种分区SVGP（PSVGP）方法，允许邻近空间分区之间进行少量通信，以改善局部模型的对齐，从而实现更平滑的空间预测。

Result: 所提出的PSVGP方法在保持高度可扩展性和最小计算开销（无内存开销）的同时，改善了空间预测的平滑度，并提高了整体拟合度。

Conclusion: 该研究提出了一种分区SVGP（PSVGP）方法，通过允许邻近空间分区之间进行少量通信，来解决独立SVGP模型产生的非连续响应面问题，从而实现更平滑的空间预测和更好的整体拟合。

Abstract: The next generation of Department of Energy supercomputers will be capable of
exascale computation. For these machines, far more computation will be possible
than that which can be saved to disk. As a result, users will be unable to rely
on post-hoc access to data for uncertainty quantification and other statistical
analyses and there will be an urgent need for sophisticated machine learning
algorithms which can be trained in situ. Algorithms deployed in this setting
must be highly scalable, memory efficient and capable of handling data which is
distributed across nodes as spatially contiguous partitions. One suitable
approach involves fitting a sparse variational Gaussian process (SVGP) model
independently and in parallel to each spatial partition. The resulting model is
scalable, efficient and generally accurate, but produces the undesirable effect
of constructing discontinuous response surfaces due to the disagreement between
neighboring models at their shared boundary. In this paper, we extend this idea
by allowing for a small amount of communication between neighboring spatial
partitions which encourages better alignment of the local models, leading to
smoother spatial predictions and a better fit in general. Due to our
decentralized communication scheme, the proposed extension remains highly
scalable and adds very little overhead in terms of computation (and none, in
terms of memory). We demonstrate this Partitioned SVGP (PSVGP) approach for the
Energy Exascale Earth System Model (E3SM) and compare the results to the
independent SVGP case.

</details>


### [374] [Steering Out-of-Distribution Generalization with Concept Ablation Fine-Tuning](https://arxiv.org/abs/2507.16795)
*Helena Casademunt,Caden Juang,Adam Karvonen,Samuel Marks,Senthooran Rajamanoharan,Neel Nanda*

Main category: cs.LG

TL;DR: CAFT 是一种无需修改训练数据即可控制 LLM 微调泛化问题的新技术，通过消除不良概念来引导模型行为。


<details>
  <summary>Details</summary>
Motivation: 标准方法依赖于修改训练数据，但这并不总是可行。本研究提出了一种无需修改训练数据即可控制 LLM 微调泛化行为的新技术。

Method: CAFT 利用可解释性工具，在微调过程中通过线性投影来消除不良概念，从而引导模型避免不必要的泛化。该技术不需要修改训练数据或使用目标分布中的数据。

Result: CAFT 成功应用于三个微调任务，包括“新兴错位”现象，并将错误的回答减少了 10 倍，同时没有降低在训练分布上的性能。

Conclusion: CAFT 是一种新颖的方法，可以在不修改训练数据的情况下引导 LLM 的泛化。

Abstract: Fine-tuning large language models (LLMs) can lead to unintended
out-of-distribution generalization. Standard approaches to this problem rely on
modifying training data, for example by adding data that better specify the
intended generalization. However, this is not always practical. We introduce
Concept Ablation Fine-Tuning (CAFT), a technique that leverages
interpretability tools to control how LLMs generalize from fine-tuning, without
needing to modify the training data or otherwise use data from the target
distribution. Given a set of directions in an LLM's latent space corresponding
to undesired concepts, CAFT works by ablating these concepts with linear
projections during fine-tuning, steering the model away from unintended
generalizations. We successfully apply CAFT to three fine-tuning tasks,
including emergent misalignment, a phenomenon where LLMs fine-tuned on a narrow
task generalize to give egregiously misaligned responses to general questions.
Without any changes to the fine-tuning data, CAFT reduces misaligned responses
by 10x without degrading performance on the training distribution. Overall,
CAFT represents a novel approach for steering LLM generalization without
modifying training data.

</details>


### [375] [Beyond Binary Rewards: Training LMs to Reason About Their Uncertainty](https://arxiv.org/abs/2507.16806)
*Mehul Damani,Isha Puri,Stewart Slocum,Idan Shenfeld,Leshem Choshen,Yoon Kim,Jacob Andreas*

Main category: cs.LG

TL;DR: RLCR通过结合Brier分数来优化奖励函数，提高了语言模型在推理任务中的准确性和置信度校准能力，并优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有的用于推理的RL方法通常使用二元奖励函数，该函数仅评估LM输出的正确性。这种方法会惩罚猜測或低置信度的输出，导致校准能力下降，并增加LM在其他问题域中产生不正确响应（“幻觉”）的比率。因此，需要一种新的方法来提高准确性和校准估计的置信度。

Method: RLCR（Reinforcement Learning with Calibration Rewards）是一种训练推理模型的方法，它通过引入Brier分数来优化奖励函数，该函数结合了二元正确性分数和用于置信度估计的Brier分数，以激励校准预测。

Result: RLCR在各种数据集上显著提高了校准能力，并且在准确性上没有损失，包括在域内和域外评估中。RLCR的表现优于普通RL训练和事后置信度评分方法。此外，通过置信度加权缩放方法，RLCR在测试时可以进一步提高准确性和校准。

Conclusion: RLCR通过引入Brier分数来优化奖励函数，可以同时提高准确性和校准估计的置信度，并在各种数据集上表现优于普通RL训练和事后置信度评分方法。RLCR还可以通过置信度加权缩放方法在测试时提高准确性和校准，从而生成更可靠的推理模型。

Abstract: When language models (LMs) are trained via reinforcement learning (RL) to
generate natural language "reasoning chains", their performance improves on a
variety of difficult question answering tasks. Today, almost all successful
applications of RL for reasoning use binary reward functions that evaluate the
correctness of LM outputs. Because such reward functions do not penalize
guessing or low-confidence outputs, they often have the unintended side-effect
of degrading calibration and increasing the rate at which LMs generate
incorrect responses (or "hallucinate") in other problem domains. This paper
describes RLCR (Reinforcement Learning with Calibration Rewards), an approach
to training reasoning models that jointly improves accuracy and calibrated
confidence estimation. During RLCR, LMs generate both predictions and numerical
confidence estimates after reasoning. They are trained to optimize a reward
function that augments a binary correctness score with a Brier score -- a
scoring rule for confidence estimates that incentivizes calibrated prediction.
We first prove that this reward function (or any analogous reward function that
uses a bounded, proper scoring rule) yields models whose predictions are both
accurate and well-calibrated. We next show that across diverse datasets, RLCR
substantially improves calibration with no loss in accuracy, on both in-domain
and out-of-domain evaluations -- outperforming both ordinary RL training and
classifiers trained to assign post-hoc confidence scores. While ordinary RL
hurts calibration, RLCR improves it. Finally, we demonstrate that verbalized
confidence can be leveraged at test time to improve accuracy and calibration
via confidence-weighted scaling methods. Our results show that explicitly
optimizing for calibration can produce more generally reliable reasoning
models.

</details>


### [376] [Semi-off-Policy Reinforcement Learning for Vision-Language Slow-thinking Reasoning](https://arxiv.org/abs/2507.16814)
*Junhao Shen,Haiteng Zhao,Yuzhe Gu,Songyang Gao,Kuikun Liu,Haian Huang,Jianfei Gao,Dahua Lin,Wenwei Zhang,Kai Chen*

Main category: cs.LG

TL;DR: SOPHIA 是一种半 off-policy 强化学习方法，通过结合 LVLM 的视觉理解和语言模型的慢思考推理，提升了 LVLM 在复杂多模态任务中的推理能力，并在多个基准测试中取得了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 为了解决大型视觉语言模型（LVLM）在解决复杂多模态任务时，由于主要以视觉-语言对齐进行训练，难以采用 on-policy 强化学习（RL）来发展慢思考能力，因为 rollout 空间受到其初始能力的限制。直接从外部模型蒸馏轨迹可能由于模型间不匹配的视觉感知能力而导致视觉幻觉。

Method: SOPHIA 是一种半 off-policy 强化学习方法，它结合了来自可训练 LVLM 的 on-policy 视觉理解和来自语言模型的 off-policy 慢思考推理。它为推理分配基于结果的奖励，并将视觉奖励反向传播，然后使用反向传播的奖励通过 off-policy RL 算法训练 LVLM 学习慢思考推理能力。

Result: SOPHIA 显著提高了 InternVL3.0-38B 模型的性能，平均提高了 8.50%，在多个多模态推理基准上达到了开源 LVLM 的最先进水平，并且在 MathVision 和 OlympiadBench 等挑战性任务上超过了一些闭源模型（如 GPT-4.1），分别达到了 49.08% 和 49.95% 的 pass@1 准确率。分析表明 SOPHIA 优于监督微调和直接 on-policy RL 方法，为进一步的 on-policy 训练提供了更好的策略初始化。

Conclusion: SOPHIA 通过结合可训练 LVLM 的 on-policy 视觉理解和语言模型的 off-policy 慢思考推理，构建了一个半 off-policy 行为模型，并将基于结果的奖励分配给推理，然后反向传播视觉奖励。该方法在 InternVL2.5 和 InternVL3.0 模型上进行了广泛的实验，证明了其有效性，显著提高了模型在多模态推理基准上的性能，甚至在某些具有挑战性的任务上超过了闭源模型。

Abstract: Enhancing large vision-language models (LVLMs) with visual slow-thinking
reasoning is crucial for solving complex multimodal tasks. However, since LVLMs
are mainly trained with vision-language alignment, it is difficult to adopt
on-policy reinforcement learning (RL) to develop the slow thinking ability
because the rollout space is restricted by its initial abilities. Off-policy RL
offers a way to go beyond the current policy, but directly distilling
trajectories from external models may cause visual hallucinations due to
mismatched visual perception abilities across models. To address these issues,
this paper proposes SOPHIA, a simple and scalable Semi-Off-Policy RL for
vision-language slow-tHInking reAsoning. SOPHIA builds a semi-off-policy
behavior model by combining on-policy visual understanding from a trainable
LVLM with off-policy slow-thinking reasoning from a language model, assigns
outcome-based rewards to reasoning, and propagates visual rewards backward.
Then LVLM learns slow-thinking reasoning ability from the obtained reasoning
trajectories using propagated rewards via off-policy RL algorithms. Extensive
experiments with InternVL2.5 and InternVL3.0 with 8B and 38B sizes show the
effectiveness of SOPHIA. Notably, SOPHIA improves InternVL3.0-38B by 8.50% in
average, reaching state-of-the-art performance among open-source LVLMs on
multiple multimodal reasoning benchmarks, and even outperforms some
closed-source models (e.g., GPT-4.1) on the challenging MathVision and
OlympiadBench, achieving 49.08% and 49.95% pass@1 accuracy, respectively.
Analysis shows SOPHIA outperforms supervised fine-tuning and direct on-policy
RL methods, offering a better policy initialization for further on-policy
training.

</details>


<div id='cs.SI'></div>

# cs.SI [[Back]](#toc)

### [377] [Belief Alignment vs Opinion Leadership: Understanding Cross-linguistic Digital Activism in K-pop and BLM Communities](https://arxiv.org/abs/2507.16046)
*Yuheun Kim,Joshua Introne*

Main category: cs.SI

TL;DR: 本研究发现，在数字活动中，人们对共同信念的认同是跨国界互动的关键驱动力，而意见领袖的直接作用不大。


<details>
  <summary>Details</summary>
Motivation: 本研究旨在探讨跨国界活动的根本驱动因素，尽管已有大量关于社交媒体和互联网在跨国界活动中作用的研究。研究人员提出了两种可能的解释：一是受有影响力的在线意见领袖驱动，二是源于个体对新出现的信念、价值观和规范产生共鸣。

Method: 本研究采用案例研究的方法，重点分析了乔治·弗洛伊德被谋杀后，K-pop 粉丝与“黑人的命也是命”（BLM）运动在 Twitter 上的互动情况。

Result: 研究结果有力地证明，信念的一致性（即人们对共同信念产生共鸣）是数字活动中跨国界互动的主要驱动力。研究还表明，虽然意见领袖（在此案例中为 K-pop 艺人）的行动可能会扩大活动的影响力，并获得粉丝更多的喜爱和崇拜，但这似乎并不是活动的直接原因。最后，研究还初步显示，BLM 与 K-pop 之间的互动可能略微增加了他们整体的信念相似度。

Conclusion: 本研究的结论是，在数字活动中，人们普遍认同的信念是跨国界互动的主要驱动力。虽然有影响力的在线意见领袖（如 K-pop 艺人）可能会促进活动，但他们似乎并不是活动的直接原因。此外，本研究还发现 BLM 和 K-pop 粉丝之间的互动可能略微增加了他们整体的信念相似度。

Abstract: The internet has transformed activism, giving rise to more organic, diverse,
and dynamic social movements that transcend geo-political boundaries. Despite
extensive research on the role of social media and the internet in
cross-cultural activism, the fundamental motivations driving these global
movements remain poorly understood. This study examines two plausible
explanations for cross-cultural activism: first, that it is driven by
influential online opinion leaders, and second, that it results from
individuals resonating with emergent sets of beliefs, values, and norms. We
conduct a case study of the interaction between K-pop fans and the Black Lives
Matter (BLM) movement on Twitter following the murder of George Floyd. Our
findings provide strong evidence that belief alignment, where people resonate
with common beliefs, is a primary driver of cross-cultural interactions in
digital activism. We also demonstrate that while the actions of potential
opinion leaders--in this case, K-pop entertainers--may amplify activism and
lead to further expressions of love and admiration from fans, they do not
appear to be a direct cause of activism. Finally, we report some initial
evidence that the interaction between BLM and K-pop led to slight increases in
their overall belief similarity.

</details>


### [378] [WhatsApp Tiplines and Multilingual Claims in the 2021 Indian Assembly Elections](https://arxiv.org/abs/2507.16298)
*Gautam Kishore Shahi,Scot A. Hale*

Main category: cs.SI

TL;DR: 本研究分析了2021年印度议会选举期间WhatsApp举报数据，发现不同语言的举报内容相似，但用户倾向于只向一个事实核查组织举报。事实核查过程通常需要几天时间。研究为选举期间使用举报功能提供了建议。


<details>
  <summary>Details</summary>
Motivation: 为了在2021年印度议会选举期间，分析WhatsApp举报功能在打击虚假信息方面的作用，并为未来选举提供实践建议。

Method: 本研究采用混合方法，分析了2021年印度议会选举期间，来自451名用户的580个独特举报（包括高资源语言英语、印地语和低资源语言泰卢固语）。通过频繁词分析和神经网络句子嵌入聚类来比较内容相似性，并调查了跨语言和跨事实核查组织的用户重叠情况。同时，评估了核查举报内容并通知用户所需的平均时间。

Result: 不同语言的举报内容存在相似性；部分用户会向同一事实核查组织提交多种语言的举报；事实核查组织通常需要几天时间来核查并回复举报内容；没有用户向多个事实核查组织提交举报，表明每个组织都有其独特的用户群体。

Conclusion: 研究结果显示，不同语言的举报内容存在相似性，部分用户会向同一事实核查组织提交多种语言的举报。事实核查组织通常需要几天时间来核查并回复举报内容。没有用户向多个事实核查组织提交举报，这表明每个组织都有其独特的用户群体。本研究为在选举期间使用WhatsApp举报功能提供了实用的建议，并考虑了用户的隐私。

Abstract: WhatsApp tiplines, first launched in 2019 to combat misinformation, enable
users to interact with fact-checkers to verify misleading content. This study
analyzes 580 unique claims (tips) from 451 users, covering both high-resource
languages (English, Hindi) and a low-resource language (Telugu) during the 2021
Indian assembly elections using a mixed-method approach. We categorize the
claims into three categories, election, COVID-19, and others, and observe
variations across languages. We compare content similarity through frequent
word analysis and clustering of neural sentence embeddings. We also investigate
user overlap across languages and fact-checking organizations. We measure the
average time required to debunk claims and inform tipline users. Results reveal
similarities in claims across languages, with some users submitting tips in
multiple languages to the same fact-checkers. Fact-checkers generally require a
couple of days to debunk a new claim and share the results with users. Notably,
no user submits claims to multiple fact-checking organizations, indicating that
each organization maintains a unique audience. We provide practical
recommendations for using tiplines during elections with ethical consideration
of users' information.

</details>


### [379] [SASH: Decoding Community Structure in Graphs](https://arxiv.org/abs/2507.16583)
*Allison Beemer,Jessalyn Bolkema*

Main category: cs.SI

TL;DR: 提出了一种编码社区结构的方法，并开发了一种名为SASH的新算法来检测图中的社区。SASH在模拟和真实数据集上都表现良好。


<details>
  <summary>Details</summary>
Motivation: 图的社区检测在识别密集连接的顶点簇方面具有重要应用和丰富的文献。该问题先前已被置于纠错码的领域，将图视为假设的潜在社区的噪声版本。

Method: 提出了一种编码社区结构及其相应码参数的方法，并提出了一种新的解码算法SASH。

Result: SASH算法是一种用于从观测数据集中解码估计社区的新颖算法。

Conclusion: SASH算法在模拟的分类种植分区模型和Zachary Karate Club数据集上进行了性能验证。

Abstract: Detection of communities in a graph entails identifying clusters of densely
connected vertices; the area has a variety of important applications and a rich
literature. The problem has previously been situated in the realm of error
correcting codes by viewing a graph as a noisy version of the assumed
underlying communities. In this paper, we introduce an encoding of community
structure along with the resulting code's parameters. We then present a novel
algorithm, SASH, to decode to estimated communities given an observed dataset.
We demonstrate the performance of SASH via simulations on an assortative
planted partition model and on the Zachary's Karate Club dataset.

</details>
