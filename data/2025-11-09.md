<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 63]
- [cs.CL](#cs.CL) [Total: 44]
- [physics.app-ph](#physics.app-ph) [Total: 3]
- [cs.DS](#cs.DS) [Total: 9]
- [eess.IV](#eess.IV) [Total: 2]
- [eess.SY](#eess.SY) [Total: 24]
- [cond-mat.mtrl-sci](#cond-mat.mtrl-sci) [Total: 15]
- [cs.GR](#cs.GR) [Total: 1]
- [cs.MA](#cs.MA) [Total: 3]
- [cs.GT](#cs.GT) [Total: 4]
- [cs.RO](#cs.RO) [Total: 21]
- [cs.LO](#cs.LO) [Total: 3]
- [cs.DC](#cs.DC) [Total: 6]
- [cs.LG](#cs.LG) [Total: 76]
- [quant-ph](#quant-ph) [Total: 52]
- [cond-mat.mes-hall](#cond-mat.mes-hall) [Total: 12]
- [eess.SP](#eess.SP) [Total: 13]
- [cs.AR](#cs.AR) [Total: 5]
- [cs.AI](#cs.AI) [Total: 32]
- [cs.ET](#cs.ET) [Total: 2]
- [cs.NE](#cs.NE) [Total: 3]
- [cs.SI](#cs.SI) [Total: 2]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [LoRA-Edge: Tensor-Train-Assisted LoRA for Practical CNN Fine-Tuning on Edge Devices](https://arxiv.org/abs/2511.03765)
*Hyunseok Kwak,Kyeongwon Lee,Jae-Jin Lee,Woojoo Lee*

Main category: cs.CV

TL;DR: LoRA-Edge是一种参数高效的微调方法，通过低秩适应（LoRA）和张量分解（TT-SVD）技术，在保持推理成本不变的情况下，显著减少了卷积神经网络（CNN）的可训练参数数量，实现了在资源受限的边缘设备上进行有效的模型微调，尤其在人体活动识别（HAR）任务中表现出色。


<details>
  <summary>Details</summary>
Motivation: 为了在内存、计算和能源预算严格的边缘应用（如人体活动识别）中应对域漂移问题，需要对卷积神经网络（CNN）进行设备端微调，但完全微调在这些条件下不可行。

Method: LoRA-Edge方法结合了低秩适应（LoRA）和张量分解（TT-SVD）技术。首先，它对预训练的卷积层应用TT-SVD，然后仅选择性地更新输出端的核心部分，并使用零初始化来确保辅助路径在开始时保持非活动状态。最后，将更新融合回密集卷积核，从而不改变推理成本。

Result: LoRA-Edge将可训练参数数量减少了高达两个数量级，同时在各种HAR数据集和CNN骨干网络上，其准确度与完全微调的差距在4.7%以内，并且可训练参数比例不超过1.49%。该方法在相似的预算下持续优于现有的参数高效基线。在Jetson Orin Nano平台上，TT-SVD初始化和选择性核心训练将收敛到目标F1分数的速度提高了1.4-3.8倍。

Conclusion: LoRA-Edge使得结构对齐、参数高效的设备端CNN适应在边缘平台上变得实用，为资源受限的设备上的模型优化提供了有效的解决方案。

Abstract: On-device fine-tuning of CNNs is essential to withstand domain shift in edge
applications such as Human Activity Recognition (HAR), yet full fine-tuning is
infeasible under strict memory, compute, and energy budgets. We present
LoRA-Edge, a parameter-efficient fine-tuning (PEFT) method that builds on
Low-Rank Adaptation (LoRA) with tensor-train assistance. LoRA-Edge (i) applies
Tensor-Train Singular Value Decomposition (TT-SVD) to pre-trained convolutional
layers, (ii) selectively updates only the output-side core with
zero-initialization to keep the auxiliary path inactive at the start, and (iii)
fuses the update back into dense kernels, leaving inference cost unchanged.
This design preserves convolutional structure and reduces the number of
trainable parameters by up to two orders of magnitude compared to full
fine-tuning. Across diverse HAR datasets and CNN backbones, LoRA-Edge achieves
accuracy within 4.7% of full fine-tuning while updating at most 1.49% of
parameters, consistently outperforming prior parameter-efficient baselines
under similar budgets. On a Jetson Orin Nano, TT-SVD initialization and
selective-core training yield 1.4-3.8x faster convergence to target F1.
LoRA-Edge thus makes structure-aligned, parameter-efficient on-device CNN
adaptation practical for edge platforms.

</details>


### [2] [Near-Lossless 3D Voxel Representation Free from Iso-surface](https://arxiv.org/abs/2511.04029)
*Yihao Luo,Xianglong He,Chuanyu Pan,Yiwen Chen,Jiaqi Wu,Yangguang Li,Wanli Ouyang,Yuanming Hu,Guang Yang,ChoonHwai Yap*

Main category: cs.CV

TL;DR: Faithful Contouring是一种新的稀疏体素化表示方法，可以高保真地表示任意3D网格，无需进行网格修复或渲染优化，并且支持2048+的分辨率。该方法在表示精度和效率上都优于现有方法，并且在形状重建方面也有显著提升。


<details>
  <summary>Details</summary>
Motivation: 现有基于等值面的体素化表示方法在保真度方面存在不足，需要水密性处理或渲染优化，容易丢失几何细节。因此，需要一种能够高保真地表示任意3D网格，且无需进行额外优化的新表示方法。

Method: 提出了一种名为Faithful Contouring的稀疏体素化表示方法，支持2048+分辨率，能够处理任意网格，无需转换为场函数或进行等值面提取。此外，还设计了一种双模态自动编码器用于Faithful Contouring的形状重建。

Result: Faithful Contouring 在直接表示方面达到了 $10^{-5}$ 级别的距离误差；在网格重建方面，相比于现有方法，Chamfer Distance 降低了93%，F-score 提高了35%，证明了其在3D学习任务中作为表示方法的优越性。

Conclusion: Faithful Contouring 是一种高保真、高效率的3D网格稀疏体素化表示方法，能够克服现有方法的局限性，并在网格表示和重建方面取得了显著成果，为3D学习任务提供了更好的基础。

Abstract: Accurate and efficient voxelized representations of 3D meshes are the
foundation of 3D reconstruction and generation. However, existing
representations based on iso-surface heavily rely on water-tightening or
rendering optimization, which inevitably compromise geometric fidelity. We
propose Faithful Contouring, a sparse voxelized representation that supports
2048+ resolutions for arbitrary meshes, requiring neither converting meshes to
field functions nor extracting the isosurface during remeshing. It achieves
near-lossless fidelity by preserving sharpness and internal structures, even
for challenging cases with complex geometry and topology. The proposed method
also shows flexibility for texturing, manipulation, and editing. Beyond
representation, we design a dual-mode autoencoder for Faithful Contouring,
enabling scalable and detail-preserving shape reconstruction. Extensive
experiments show that Faithful Contouring surpasses existing methods in
accuracy and efficiency for both representation and reconstruction. For direct
representation, it achieves distance errors at the $10^{-5}$ level; for mesh
reconstruction, it yields a 93\% reduction in Chamfer Distance and a 35\%
improvement in F-score over strong baselines, confirming superior fidelity as a
representation for 3D learning tasks.

</details>


### [3] [SILVI: Simple Interface for Labeling Video Interactions](https://arxiv.org/abs/2511.03819)
*Ozan Kanbertay,Richard Vogg,Elif Karakoc,Peter M. Kappeler,Claudia Fichtel,Alexander S. Ecker*

Main category: cs.CV

TL;DR: SILVI是一款开源标注软件，整合了个体行为和交互的标注功能，弥合了现有工具的不足，可用于训练和验证计算机视觉模型，并可能广泛应用于人类互动视频分析。


<details>
  <summary>Details</summary>
Motivation: 现有开源标注工具要么不支持个体定位，要么不支持交互标注，无法满足对动物行为进行精细化分析的需求。

Method: 提出SILVI，一款整合了行为标注和个体定位功能的开源标注软件。

Result: SILVI能够直接在视频数据中标注行为和交互，并生成用于训练和验证计算机视觉模型的结构化输出。

Conclusion: SILVI为自动化精细行为分析提供了支持，并且不仅限于动物行为分析，也可用于其他需要提取动态场景图的视频分析。

Abstract: Computer vision methods are increasingly used for the automated analysis of
large volumes of video data collected through camera traps, drones, or direct
observations of animals in the wild. While recent advances have focused
primarily on detecting individual actions, much less work has addressed the
detection and annotation of interactions -- a crucial aspect for understanding
social and individualized animal behavior. Existing open-source annotation
tools support either behavioral labeling without localization of individuals,
or localization without the capacity to capture interactions. To bridge this
gap, we present SILVI, an open-source labeling software that integrates both
functionalities. SILVI enables researchers to annotate behaviors and
interactions directly within video data, generating structured outputs suitable
for training and validating computer vision models. By linking behavioral
ecology with computer vision, SILVI facilitates the development of automated
approaches for fine-grained behavioral analyses. Although developed primarily
in the context of animal behavior, SILVI could be useful more broadly to
annotate human interactions in other videos that require extracting dynamic
scene graphs. The software, along with documentation and download instructions,
is available at: https://gitlab.gwdg.de/kanbertay/interaction-labelling-app.

</details>


### [4] [Noise Injection: Improving Out-of-Distribution Generalization for Limited Size Datasets](https://arxiv.org/abs/2511.03855)
*Duong Mai,Lawrence Hall*

Main category: cs.CV

TL;DR: 通过在训练期间注入噪声来提高 COVID-19 CXR 检测模型的泛化能力，显著缩小了同分布 (ID) 和异分布 (OOD) 数据之间的性能差距。


<details>
  <summary>Details</summary>
Motivation: 深度学习模型在图像识别（尤其是 COVID-19 CXR 检测）中存在泛化能力不足的问题，因为它们会学习利用特定于来源的伪影（捷径）而非真正的生物标记物，导致在新的、分布外 (OOD) 数据上表现不佳。

Method: 研究人员在训练期间采用了四种基本的噪声注入技术（高斯噪声、斑点噪声、泊松噪声和盐椒噪声），以提高模型对分布变化的鲁棒性。

Result: 实验结果表明，与未加噪的训练相比，噪声注入技术可将 ID 和 OOD 评估之间的性能差距从 0.10-0.20 显著降低到 0.01-0.06。该结果基于十个随机种子在 AUC、F1、准确率、召回率和特异性等关键指标上的平均值。

Conclusion: 在训练期间应用噪声注入技术是一种有效的方法，可以提高 COVID-19 CXR 检测模型在不同临床来源的 OOD 数据上的泛化能力，从而解决由于学习捷径而导致的分布外性能下降问题。

Abstract: Deep learned (DL) models for image recognition have been shown to fail to
generalize to data from different devices, populations, etc. COVID-19 detection
from Chest X-rays (CXRs), in particular, has been shown to fail to generalize
to out-of-distribution (OOD) data from new clinical sources not covered in the
training set. This occurs because models learn to exploit shortcuts -
source-specific artifacts that do not translate to new distributions - rather
than reasonable biomarkers to maximize performance on in-distribution (ID)
data. Rendering the models more robust to distribution shifts, our study
investigates the use of fundamental noise injection techniques (Gaussian,
Speckle, Poisson, and Salt and Pepper) during training. Our empirical results
demonstrate that this technique can significantly reduce the performance gap
between ID and OOD evaluation from 0.10-0.20 to 0.01-0.06, based on results
averaged over ten random seeds across key metrics such as AUC, F1, accuracy,
recall and specificity. Our source code is publicly available at
https://github.com/Duongmai127/Noisy-ood

</details>


### [5] [Investigating Robot Control Policy Learning for Autonomous X-ray-guided Spine Procedures](https://arxiv.org/abs/2511.03882)
*Florence Klitzner,Blanca Inigo,Benjamin D. Killeen,Lalithkumar Seenivasan,Michelle Song,Axel Krieger,Mathias Unberath*

Main category: cs.CV

TL;DR: 基于模仿学习的机器人控制策略在X射线引导下椎弓根螺钉置入术中具有应用潜力，但需要在入口点精度和闭环控制方面进行改进。


<details>
  <summary>Details</summary>
Motivation: 评估模仿学习策略在X射线引导下椎弓根螺钉置入术中的可行性，克服多视角X射线图像解释的复杂性。

Method: 开发了一个用于X射线引导脊柱手术的体外仿真环境，并收集了正确的轨迹和相应的X射线图像序列。训练模仿学习策略用于规划和开环控制，仅基于视觉信息进行操作。

Result: 在68.5%的情况下，模仿学习策略在首次尝试时成功，并在不同椎体水平上保持了安全的椎弓根内轨迹。该策略能够泛化到包括骨折在内的复杂解剖结构，并对不同的初始化保持鲁棒性。在真实X射线图像上的测试表明，模型可以生成合理的轨迹。

Conclusion: 模仿学习策略在X射线引导下椎弓根螺钉置入术中显示出初步的希望，但在入口点精度和闭环控制方面存在局限性。未来的工作需要更强的先验知识和领域知识，以开发更轻量级、无需CT的机器人术中脊柱导航系统。

Abstract: Imitation learning-based robot control policies are enjoying renewed interest
in video-based robotics. However, it remains unclear whether this approach
applies to X-ray-guided procedures, such as spine instrumentation. This is
because interpretation of multi-view X-rays is complex. We examine
opportunities and challenges for imitation policy learning in bi-plane-guided
cannula insertion. We develop an in silico sandbox for scalable, automated
simulation of X-ray-guided spine procedures with a high degree of realism. We
curate a dataset of correct trajectories and corresponding bi-planar X-ray
sequences that emulate the stepwise alignment of providers. We then train
imitation learning policies for planning and open-loop control that iteratively
align a cannula solely based on visual information. This precisely controlled
setup offers insights into limitations and capabilities of this method. Our
policy succeeded on the first attempt in 68.5% of cases, maintaining safe
intra-pedicular trajectories across diverse vertebral levels. The policy
generalized to complex anatomy, including fractures, and remained robust to
varied initializations. Rollouts on real bi-planar X-rays further suggest that
the model can produce plausible trajectories, despite training exclusively in
simulation. While these preliminary results are promising, we also identify
limitations, especially in entry point precision. Full closed-look control will
require additional considerations around how to provide sufficiently frequent
feedback. With more robust priors and domain knowledge, such models may provide
a foundation for future efforts toward lightweight and CT-free robotic
intra-operative spinal navigation.

</details>


### [6] [Desert Waste Detection and Classification Using Data-Based and Model-Based Enhanced YOLOv12 DL Model](https://arxiv.org/abs/2511.03888)
*Abdulmumin Sa'ad,Sulaimon Oyeniyi Adebayo,Abdul Jabbar Siddiqui*

Main category: cs.CV

TL;DR: 本文提出了一种基于轻量级YOLOv12并结合自对抗训练（SAT）和特殊数据增强策略的增强型实时目标检测框架，用于沙漠环境下的垃圾检测，取得了更高的精度和效率。


<details>
  <summary>Details</summary>
Motivation: 传统垃圾收集方法在偏远或恶劣环境中效率低下且危险，而现有计算机视觉研究主要集中在城市和可回收垃圾，忽略了有机、危险垃圾以及沙漠等地形。

Method: 提出了一种基于剪枝的轻量级YOLOv12，并集成了自对抗训练（SAT）和专门的数据增强策略，使用DroneTrashNet数据集进行训练和评估。

Result: 该模型在DroneTrashNet数据集上显著提高了精度、召回率和平均精度（mAP），同时实现了低延迟和紧凑的模型尺寸，适合资源受限的航空无人机部署。与最先进的轻量级YOLO变体相比，该模型在准确性和效率之间取得了最佳平衡。

Conclusion: 结合以数据为中心和以模型为中心的增强方法，可以有效地实现沙漠环境中鲁棒、实时的垃圾检测。

Abstract: The global waste crisis is escalating, with solid waste generation expected
to increase by 70% by 2050. Traditional waste collection methods, particularly
in remote or harsh environments like deserts, are labor-intensive, inefficient,
and often hazardous. Recent advances in computer vision and deep learning have
opened the door to automated waste detection systems, yet most research focuses
on urban environments and recyclable materials, overlooking organic and
hazardous waste and underexplored terrains such as deserts. In this work, we
propose an enhanced real-time object detection framework based on a pruned,
lightweight version of YOLOv12 integrated with Self-Adversarial Training (SAT)
and specialized data augmentation strategies. Using the DroneTrashNet dataset,
we demonstrate significant improvements in precision, recall, and mean average
precision (mAP), while achieving low latency and compact model size suitable
for deployment on resource-constrained aerial drones. Benchmarking our model
against state-of-the-art lightweight YOLO variants further highlights its
optimal balance of accuracy and efficiency. Our results validate the
effectiveness of combining data-centric and model-centric enhancements for
robust, real-time waste detection in desert environments.

</details>


### [7] [Improving Diagnostic Performance on Small and Imbalanced Datasets Using Class-Based Input Image Composition](https://arxiv.org/abs/2511.03891)
*Hlali Azzeddine,Majid Ben Yakhlef,Soulaiman El Hazzat*

Main category: cs.CV

TL;DR: 该研究提出了一种名为“类别图像合成”的新方法，通过融合同一类别的多张图像来创建复合输入图像（CoImg），以提高深度学习模型在处理小型、不平衡和低质量数据集时的性能。


<details>
  <summary>Details</summary>
Motivation: 深度学习模型在处理小型、不平衡数据集和低质量输入图像时，容易出现高假阳性预测率。

Method: 提出“类别图像合成”方法，将同一类别的多张图像融合为复合输入图像（CoImg），以增强类内方差和信息密度，提高模型区分细微病变模式的能力。实验在OCTDL数据集上进行，创建了一个平衡版本Co-OCTDL，并将CoImg方法与原始数据集在VGG16模型上进行了比较。

Result: 与在原始数据集上训练的基线模型相比，使用CoImg方法（在Co-OCTDL数据集上）将诊断准确率提高到99.6%，F1分数达到0.995，AUC达到0.9996，同时显著降低了假阳性率。

Conclusion: 类别图像合成方法能够有效提高模型在处理类别不平衡或样本量小等挑战性数据集时的预测质量。

Abstract: Small, imbalanced datasets and poor input image quality can lead to high
false predictions rates with deep learning models. This paper introduces
Class-Based Image Composition, an approach that allows us to reformulate
training inputs through a fusion of multiple images of the same class into
combined visual composites, named Composite Input Images (CoImg). That enhances
the intra-class variance and improves the valuable information density per
training sample and increases the ability of the model to distinguish between
subtle disease patterns. Our method was evaluated on the Optical Coherence
Tomography Dataset for Image-Based Deep Learning Methods (OCTDL) (Kulyabin et
al., 2024), which contains 2,064 high-resolution optical coherence tomography
(OCT) scans of the human retina, representing seven distinct diseases with a
significant class imbalance. We constructed a perfectly class-balanced version
of this dataset, named Co-OCTDL, where each scan is resented as a 3x1 layout
composite image. To assess the effectiveness of this new representation, we
conducted a comparative analysis between the original dataset and its variant
using a VGG16 model. A fair comparison was ensured by utilizing the identical
model architecture and hyperparameters for all experiments. The proposed
approach markedly improved diagnostic results.The enhanced Dataset achieved
near-perfect accuracy (99.6%) with F1-score (0.995) and AUC (0.9996), compared
to a baseline model trained on raw dataset. The false prediction rate was also
significantly lower, this demonstrates that the method can producehigh-quality
predictions even for weak datasets affected by class imbalance or small sample
size.

</details>


### [8] [I Detect What I Don't Know: Incremental Anomaly Learning with Stochastic Weight Averaging-Gaussian for Oracle-Free Medical Imaging](https://arxiv.org/abs/2511.03912)
*Nand Kumar Yadav,Rodrigue Rizk,William CW Chen,KC Santosh*

Main category: cs.CV

TL;DR: 本研究提出了一种无监督、无需专家标注的医学影像异常检测框架，通过增量扩展正常样本集来提高检测性能。


<details>
  <summary>Details</summary>
Motivation: 医学影像中已知异常样本稀少且标注成本高，使得未知异常检测成为一大挑战。

Method: 该框架使用轻量级适配器更新和基于不确定性的样本筛选来逐步扩展正常的样本集。通过冻结预训练的视觉主干网络，并添加微小的卷积适配器，实现了快速的领域自适应和低计算开销。提取的嵌入被存储在一个紧凑的核心集中，用于高效的k近邻（k-NN）异常评分。通过概率门控机制，只有当样本与核心集的距离在校准的z分数阈值内，并且其基于SWAG的认知不确定性低于阈值时，才被接纳，从而防止漂移和错误包含，且无需生成式重建或回放缓冲区。

Result: 该框架能够随着无标签数据的到来持续优化正常性定义，显著优于基线方法。在COVID-CXR数据集上，ROC-AUC从0.9489提升至0.9982（F1值从0.8048提升至0.9746）；在Pneumonia CXR数据集上，ROC-AUC从0.6834提升至0.8968；在Brain MRI ND-5数据集上，ROC-AUC从0.6041提升至0.7269，PR-AUC从0.7539提升至0.8211。

Conclusion: 该框架在真实世界、标注稀缺的医学影像应用中，展现了其有效性和高效性。

Abstract: Unknown anomaly detection in medical imaging remains a fundamental challenge
due to the scarcity of labeled anomalies and the high cost of expert
supervision. We introduce an unsupervised, oracle-free framework that
incrementally expands a trusted set of normal samples without any anomaly
labels. Starting from a small, verified seed of normal images, our method
alternates between lightweight adapter updates and uncertainty-gated sample
admission. A frozen pretrained vision backbone is augmented with tiny
convolutional adapters, ensuring rapid domain adaptation with negligible
computational overhead. Extracted embeddings are stored in a compact coreset
enabling efficient k-nearest neighbor anomaly (k-NN) scoring. Safety during
incremental expansion is enforced by dual probabilistic gates, a sample is
admitted into the normal memory only if its distance to the existing coreset
lies within a calibrated z-score threshold, and its SWAG-based epistemic
uncertainty remains below a seed-calibrated bound. This mechanism prevents
drift and false inclusions without relying on generative reconstruction or
replay buffers. Empirically, our system steadily refines the notion of
normality as unlabeled data arrive, producing substantial gains over baselines.
On COVID-CXR, ROC-AUC improves from 0.9489 to 0.9982 (F1: 0.8048 to 0.9746); on
Pneumonia CXR, ROC-AUC rises from 0.6834 to 0.8968; and on Brain MRI ND-5,
ROC-AUC increases from 0.6041 to 0.7269 and PR-AUC from 0.7539 to 0.8211. These
results highlight the effectiveness and efficiency of the proposed framework
for real-world, label-scarce medical imaging applications.

</details>


### [9] [Adaptive Temporal Refinement: Continuous Depth Allocation and Distance Regression for Efficient Action Localization](https://arxiv.org/abs/2511.03943)
*Ibne Farabi Shihab,Sanjeda Akter,Anuj Sharma*

Main category: cs.CV

TL;DR: BDR和ATR提高了动作定位的精度和效率，BDR通过距离回归优化边界检测，ATR通过自适应计算分配提高效率。


<details>
  <summary>Details</summary>
Motivation: 现有方法在动作定位时计算量分配不均，无法适应不同边界检测的难度差异。

Method: 提出边界距离回归（BDR）和自适应时间细化（ATR）两种方法。BDR使用符号距离回归代替分类，ATR通过连续深度选择τ分配计算量。

Result: BDR提高了边界检测的精度，mAP@0.7提升1.8%-3.1%。ATR在THUMOS14上以更少的计算量（162G FLOPs）实现了更高的mAP@0.7（56.5%），比均匀计算（198G FLOPs，53.6%）高出2.9%。该方法在短动作上效果尤为显著，提升4.2%。

Conclusion: BDR和ATR是有效且高效的动作定位方法，能够显著提升精度并降低计算成本。

Abstract: Temporal action localization requires precise boundary detection; however,
current methods apply uniform computation despite significant variations in
difficulty across boundaries. We present two complementary contributions.
First, Boundary Distance Regression (BDR) provides information-theoretically
optimal localization through signed-distance regression rather than
classification, achieving 43\% sharper boundary peaks. BDR retrofits to
existing methods with approximately 50 lines of code, yielding consistent 1.8
to 3.1\% mAP@0.7 improvements across diverse architectures. Second, Adaptive
Temporal Refinement (ATR) allocates computation via continuous depth selection
$\tau \in [0,1]$, enabling end-to-end differentiable optimization without
reinforcement learning. On THUMOS14, ATR achieves 56.5\% mAP@0.7 at 162G FLOPs,
compared to 53.6\% at 198G for uniform processing, providing a 2.9\%
improvement with 18\% less compute. Gains scale with boundary heterogeneity,
showing 4.2\% improvement on short actions. Training cost is mitigated via
knowledge distillation, with lightweight students retaining 99\% performance at
baseline cost. Results are validated across four benchmarks with rigorous
statistical testing.

</details>


### [10] [Improving Multi-View Reconstruction via Texture-Guided Gaussian-Mesh Joint Optimization](https://arxiv.org/abs/2511.03950)
*Zhejia Cai,Puhua Jiang,Shiwei Mao,Hongkun Cao,Ruqi Huang*

Main category: cs.CV

TL;DR: 本研究提出了一种联合优化高斯-网格的框架，以同时实现几何和外观的精确重建，解决了现有方法在几何和外观优化上的分离问题，从而更好地支持下游编辑任务。


<details>
  <summary>Details</summary>
Motivation: 现有方法在多视角三维重建中，通常将几何精度（如多视图立体）和照片级真实感渲染（如新视角合成）分开处理，这种分离阻碍了后续的三维编辑操作。因此，需要一种能够统一处理几何和外观优化的方法。

Method: 提出了一种新颖的框架，利用高斯引导的可微分渲染技术，同时优化网格的几何（顶点位置和面）和顶点颜色。该方法结合了输入图像的光度一致性以及法线和深度图提供的几何正则化约束。

Result: 实现了高质量的三维重建，能够同时保证几何准确性和逼真的外观，并且可以用于重光照和形状变形等下游编辑任务。

Conclusion: 通过无缝的高斯-网格联合优化，本研究成功地统一了几何和外观的重建过程，为下游的三维编辑应用提供了更高质量、更易于编辑的三维模型。

Abstract: Reconstructing real-world objects from multi-view images is essential for
applications in 3D editing, AR/VR, and digital content creation. Existing
methods typically prioritize either geometric accuracy (Multi-View Stereo) or
photorealistic rendering (Novel View Synthesis), often decoupling geometry and
appearance optimization, which hinders downstream editing tasks. This paper
advocates an unified treatment on geometry and appearance optimization for
seamless Gaussian-mesh joint optimization. More specifically, we propose a
novel framework that simultaneously optimizes mesh geometry (vertex positions
and faces) and vertex colors via Gaussian-guided mesh differentiable rendering,
leveraging photometric consistency from input images and geometric
regularization from normal and depth maps. The obtained high-quality 3D
reconstruction can be further exploit in down-stream editing tasks, such as
relighting and shape deformation. The code will be publicly available upon
acceptance.

</details>


### [11] [A Linear Fractional Transformation Model and Calibration Method for Light Field Camera](https://arxiv.org/abs/2511.03962)
*Zhong Chen,Changfeng Chen*

Main category: cs.CV

TL;DR: 该研究提出了一种新的线性分数变换(LFT)参数α来解耦光场相机中的主透镜和微透镜阵列(MLA)，以实现准确的内参标定，并提供了一种基于最小二乘法的解析解和非线性精炼方法，同时介绍了特征检测方法，实验结果验证了该方法的有效性，并加速了原始光场图像的模拟，有利于数据驱动的深度学习方法。


<details>
  <summary>Details</summary>
Motivation: 准确标定内参是使用光场相机进行3D重建的关键前提，但具有挑战性。

Method: 提出使用线性分数变换(LFT)参数α来解耦主透镜和微透镜阵列(MLA)。方法包括基于最小二乘法的解析解和非线性精炼。此外，还引入了从原始图像检测特征的方法。

Result: 在物理和模拟数据上的实验结果验证了该方法的性能。基于提出的模型，原始光场图像的模拟速度更快。

Conclusion: 提出的LFT参数α能有效解耦主透镜和MLA，实现光场相机的内参标定，并且该模型加速了光场图像模拟，对数据驱动的深度学习方法有益。

Abstract: Accurate calibration of internal parameters is a crucial yet challenging
prerequisite for 3D reconstruction using light field cameras. In this paper, we
propose a linear fractional transformation(LFT) parameter $\alpha$ to decoupled
the main lens and micro lens array (MLA). The proposed method includes an
analytical solution based on least squares, followed by nonlinear refinement.
The method for detecting features from the raw images is also introduced.
Experimental results on both physical and simulated data have verified the
performance of proposed method. Based on proposed model, the simulation of raw
light field images becomes faster, which is crucial for data-driven deep
learning methods. The corresponding code can be obtained from the author's
website.

</details>


### [12] [Room Envelopes: A Synthetic Dataset for Indoor Layout Reconstruction from Images](https://arxiv.org/abs/2511.03970)
*Sam Bahrami,Dylan Campbell*

Main category: cs.CV

TL;DR: 本研究提出了一个名为Room Envelopes的合成数据集，用于改进场景重建方法，特别是针对房间的结构元素（墙壁、地板、天花板）的重建。


<details>
  <summary>Details</summary>
Motivation: 现有场景重建方法无法恢复被遮挡的表面，尤其是在场景结构元素方面。本研究认为场景结构元素（如墙壁、地板、天花板）由于其平面、重复和简单的特性，可以采用更高效的方法进行预测。

Method: 提出了一个名为Room Envelopes的合成数据集，包含RGB图像及其对应的点图（可见表面和移除固定装置后的第一表面）。该数据集可用于监督前馈单目几何估计器，以同时预测可见表面和结构布局表面。

Result: 通过Room Envelopes数据集，可以训练出能够理解场景范围以及物体形状和位置的几何估计器。

Conclusion: Room Envelopes数据集的提出将促进单目几何估计在场景结构恢复方面的研究，从而实现更完整的场景理解。

Abstract: Modern scene reconstruction methods are able to accurately recover 3D
surfaces that are visible in one or more images. However, this leads to
incomplete reconstructions, missing all occluded surfaces. While much progress
has been made on reconstructing entire objects given partial observations using
generative models, the structural elements of a scene, like the walls, floors
and ceilings, have received less attention. We argue that these scene elements
should be relatively easy to predict, since they are typically planar,
repetitive and simple, and so less costly approaches may be suitable. In this
work, we present a synthetic dataset -- Room Envelopes -- that facilitates
progress on this task by providing a set of RGB images and two associated
pointmaps for each image: one capturing the visible surface and one capturing
the first surface once fittings and fixtures are removed, that is, the
structural layout. As we show, this enables direct supervision for feed-forward
monocular geometry estimators that predict both the first visible surface and
the first layout surface. This confers an understanding of the scene's extent,
as well as the shape and location of its objects.

</details>


### [13] [Simple 3D Pose Features Support Human and Machine Social Scene Understanding](https://arxiv.org/abs/2511.03988)
*Wenshuo Qin,Leyla Isik*

Main category: cs.CV

TL;DR: 人类通过3D视觉空间姿态信息来理解社会互动，而现有的AI模型在这方面表现不佳。通过提取3D关节位置并结合精炼的3D社会姿态特征，可以显著提升AI模型对社会互动的识别能力。


<details>
  <summary>Details</summary>
Motivation: 尽管人类能够轻松地从视觉输入中提取关于他人社会互动的信息，但支持这些能力但计算机制尚不清楚，并且社会互动识别仍然是AI视觉系统面临的挑战。本研究旨在探索人类是否依赖于目前大多数AI视觉模型所缺乏的3D视觉空间姿态信息来进行社会互动判断。

Method: 本研究结合了最先进的姿态和深度估计算法，提取了描绘日常人类动作的短视频片段中人物的3D关节位置。然后，将这些3D关节位置预测人类社会互动判断的能力与现有的AI视觉模型进行了比较。此外，研究还提取了一组精炼的3D社会姿态特征（仅描述面部在视频中的3D位置和方向），并评估了这些特征对AI模型性能的提升作用。

Result: 提取的3D关节位置在预测人类社会互动判断方面表现优于大多数现有的AI视觉模型，表明关键的社会信息存在于显式的身体姿态中，而非大多数视觉模型学习到的特征中。一组精炼的3D社会姿态特征（仅描述面部在视频中的3D位置和方向）在预测能力上与完整的3D关节集相当，并且与现成的AI视觉模型的嵌入相结合时，能够显著提升其性能。此外，现成AI视觉模型对3D社会姿态特征的表征程度，能够预测该模型在匹配人类社会判断方面的能力。

Conclusion: 人类社会场景的理解依赖于对3D姿态的显式表征，并且可以通过简单、结构化的视觉空间原语来支持。本研究强调了在AI模型中整合3D姿态信息对于提升社会互动理解能力的重要性。

Abstract: Humans can quickly and effortlessly extract a variety of information about
others' social interactions from visual input, ranging from visuospatial cues
like whether two people are facing each other to higher-level information. Yet,
the computations supporting these abilities remain poorly understood, and
social interaction recognition continues to challenge even the most advanced AI
vision systems. Here, we hypothesized that humans rely on 3D visuospatial pose
information to make social interaction judgments, which is absent in most AI
vision models. To test this, we combined state-of-the-art pose and depth
estimation algorithms to extract 3D joint positions of people in short video
clips depicting everyday human actions and compared their ability to predict
human social interaction judgments with current AI vision models. Strikingly,
3D joint positions outperformed most current AI vision models, revealing that
key social information is available in explicit body position but not in the
learned features of most vision models, including even the layer-wise
embeddings of the pose models used to extract joint positions. To uncover the
critical pose features humans use to make social judgments, we derived a
compact set of 3D social pose features describing only the 3D position and
direction of faces in the videos. We found that these minimal descriptors
matched the predictive strength of the full set of 3D joints and significantly
improved the performance of off-the-shelf AI vision models when combined with
their embeddings. Moreover, the degree to which 3D social pose features were
represented in each off-the-shelf AI vision model predicted the model's ability
to match human social judgments. Together, our findings provide strong evidence
that human social scene understanding relies on explicit representations of 3D
pose and can be supported by simple, structured visuospatial primitives.

</details>


### [14] [CaRF: Enhancing Multi-View Consistency in Referring 3D Gaussian Splatting Segmentation](https://arxiv.org/abs/2511.03992)
*Yuwen Tao,Kanglei Zhou,Xin Tan,Yuan Xie*

Main category: cs.CV

TL;DR: R3DGS通过直接在3D高斯空间中操作并利用相机感知信息来解决现有方法的视点不一致问题，实现了多视点一致的3D高斯分割。


<details>
  <summary>Details</summary>
Motivation: 现有3D高斯分割方法在跨视图一致性方面存在不足，因为它们依赖于2D渲染的伪监督和特定视角的特征学习。

Method: 提出了一种名为CaRF（Camera Aware Referring Field）的框架，它直接在3D高斯空间中操作，并引入了高斯场相机编码（GFCE）和训练配对视图监督（ITPVS）来增强跨视图一致性。

Result: 在Ref LERF、LERF OVS和3D OVS数据集上，CaRF的mIoU平均提升了16.8%、4.3%和2.0%，超过了现有最先进的方法。

Conclusion: CaRF通过直接在3D高斯空间中操作并明确建模视图依赖性，实现了可靠且视图一致的3D场景理解，对机器人AI、AR/VR交互和自动驾驶感知等领域具有潜在应用价值。

Abstract: Referring 3D Gaussian Splatting Segmentation (R3DGS) aims to interpret
free-form language expressions and localize the corresponding 3D regions in
Gaussian fields. While recent advances have introduced cross-modal alignment
between language and 3D geometry, existing pipelines still struggle with
cross-view consistency due to their reliance on 2D rendered pseudo supervision
and view specific feature learning. In this work, we present Camera Aware
Referring Field (CaRF), a fully differentiable framework that operates directly
in the 3D Gaussian space and achieves multi view consistency. Specifically,
CaRF introduces Gaussian Field Camera Encoding (GFCE), which incorporates
camera geometry into Gaussian text interactions to explicitly model view
dependent variations and enhance geometric reasoning. Building on this, In
Training Paired View Supervision (ITPVS) is proposed to align per Gaussian
logits across calibrated views during training, effectively mitigating single
view overfitting and exposing inter view discrepancies for optimization.
Extensive experiments on three representative benchmarks demonstrate that CaRF
achieves average improvements of 16.8%, 4.3%, and 2.0% in mIoU over state of
the art methods on the Ref LERF, LERF OVS, and 3D OVS datasets, respectively.
Moreover, this work promotes more reliable and view consistent 3D scene
understanding, with potential benefits for embodied AI, AR/VR interaction, and
autonomous perception.

</details>


### [15] [PhysCorr: Dual-Reward DPO for Physics-Constrained Text-to-Video Generation with Automated Preference Selection](https://arxiv.org/abs/2511.03997)
*Peiyao Wang,Weining Wang,Qi Li*

Main category: cs.CV

TL;DR: PhysCorr是一个统一框架，用于改进文本到视频生成中的物理一致性，通过PhysicsRM奖励模型和PhyDPO优化管道，显著提高物理真实性，同时保持视觉保真度和语义对齐。


<details>
  <summary>Details</summary>
Motivation: 当前的文本到视频生成模型生成的视频内容经常违反基本的物理规律，例如不真实的物体动力学、不连贯的交互和不现实的运动模式，这阻碍了它们在具身人工智能、机器人和模拟密集型领域的应用。因此，需要一个能够建模、评估和优化物理一致性的框架。

Method: 提出PhysCorr统一框架，包含PhysicsRM（一个量化物体稳定性和交互的双维度奖励模型）和PhyDPO（一个利用对比反馈和物理感知重新加权的直接偏好优化管道），以指导生成过程产生物理上连贯的输出。该方法模型无关且可扩展。

Result: 在多个基准测试的大量实验表明，PhysCorr在提高物理真实性方面取得了显著的改进，同时保持了视觉保真度和语义对齐。

Conclusion: PhysCorr在实现物理上合理且可信赖的视频生成方面迈出了关键一步，解决了现有模型在物理一致性方面的不足。

Abstract: Recent advances in text-to-video generation have achieved impressive
perceptual quality, yet generated content often violates fundamental principles
of physical plausibility - manifesting as implausible object dynamics,
incoherent interactions, and unrealistic motion patterns. Such failures hinder
the deployment of video generation models in embodied AI, robotics, and
simulation-intensive domains. To bridge this gap, we propose PhysCorr, a
unified framework for modeling, evaluating, and optimizing physical consistency
in video generation. Specifically, we introduce PhysicsRM, the first
dual-dimensional reward model that quantifies both intra-object stability and
inter-object interactions. On this foundation, we develop PhyDPO, a novel
direct preference optimization pipeline that leverages contrastive feedback and
physics-aware reweighting to guide generation toward physically coherent
outputs. Our approach is model-agnostic and scalable, enabling seamless
integration into a wide range of video diffusion and transformer-based
backbones. Extensive experiments across multiple benchmarks demonstrate that
PhysCorr achieves significant improvements in physical realism while preserving
visual fidelity and semantic alignment. This work takes a critical step toward
physically grounded and trustworthy video generation.

</details>


### [16] [GNN-MoE: Context-Aware Patch Routing using GNNs for Parameter-Efficient Domain Generalization](https://arxiv.org/abs/2511.04008)
*Mahmoud Soliman,Omar Abdelaziz,Ahmed Radwan,Anand,Mohamed Shehata*

Main category: cs.CV

TL;DR: GNN-MoE通过引入基于图神经网络（GNN）的路由机制，实现了高效的领域泛化（DG）参数高效微调（PEFT），在不牺牲泛化能力的前提下，显著提高了ViT在未见领域上的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 标准的微调方法在领域泛化（DG）任务中，由于成本高昂且可能损害泛化能力，无法有效地适应预训练的Vision Transformer（ViT）。

Method: 提出了一种名为GNN-MoE的解决方案，该方案在参数高效微调（PEFT）框架的基础上，结合了混合专家（MoE）模型和高效的克罗内克适配器。与传统的基于令牌的路由方式不同，GNN-MoE采用了一种新颖的图神经网络（GNN）路由机制（包括GCN、GAT、SAGE），在图像块（patch）之间构建图，并根据块间的关系动态地将图像块分配给专门的专家，从而实现上下文感知的路由。

Result: GNN-MoE在领域泛化（DG）基准测试中取得了最先进或具有竞争力的性能，同时保持了高参数效率。

Conclusion: 基于图的上下文感知路由对于实现鲁棒且轻量级的领域泛化（DG）非常有效，证明了GNN-MoE的实用性。

Abstract: Domain generalization (DG) seeks robust Vision Transformer (ViT) performance
on unseen domains. Efficiently adapting pretrained ViTs for DG is challenging;
standard fine-tuning is costly and can impair generalization. We propose
GNN-MoE, enhancing Parameter-Efficient Fine-Tuning (PEFT) for DG with a
Mixture-of-Experts (MoE) framework using efficient Kronecker adapters. Instead
of token-based routing, a novel Graph Neural Network (GNN) router (GCN, GAT,
SAGE) operates on inter-patch graphs to dynamically assign patches to
specialized experts. This context-aware GNN routing leverages inter-patch
relationships for better adaptation to domain shifts. GNN-MoE achieves
state-of-the-art or competitive DG benchmark performance with high parameter
efficiency, highlighting the utility of graph-based contextual routing for
robust, lightweight DG.

</details>


### [17] [A Hybrid Deep Learning Model for Robust Biometric Authentication from Low-Frame-Rate PPG Signals](https://arxiv.org/abs/2511.04037)
*Arfina Rahman,Mahesh Banavar*

Main category: cs.CV

TL;DR: 该研究提出了一种基于PPG信号的轻量级、高效率的生物特征认证框架，通过结合CVT、ConvMixer和LSTM的混合深度学习模型，在CFIHSR数据集上实现了98%的认证准确率，有效解决了运动伪影和跨个体变异性等挑战，适用于移动和嵌入式设备。


<details>
  <summary>Details</summary>
Motivation: PPG信号因其无创、活体检测和低成本等优点在生物特征认证领域受到关注，但其信号质量易受运动伪影、光照变化和个体生理差异的影响，因此需要鲁棒的特征提取和分类方法。

Method: 本研究提出了一种基于PPG信号的轻量级认证框架。首先，对从低帧率指尖视频中提取的原始PPG信号进行预处理，包括去除基线漂移、使用PCA抑制运动伪影、带通滤波、基于傅里叶变换的重采样和幅度归一化。然后，利用连续小波变换（CWT）将一维PPG信号转换为二维时频散点图。最后，设计了一个混合深度学习模型CVT-ConvMixer-LSTM，结合了卷积视觉变换器（CVT）和ConvMixer的的空间特征提取能力以及长短期记忆网络（LSTM）的时间序列建模能力。

Result: 在包含46名受试者的CFIHSR数据集上，所提出的CVT-ConvMixer-LSTM模型实现了98%的认证准确率，证明了其对噪声和跨个体变异性的鲁棒性。

Conclusion: 该研究提出的基于PPG信号的混合深度学习模型（CVT-ConvMixer-LSTM）具有高效率、可扩展性以及固有的活体检测能力，能够有效克服PPG信号的挑战，为移动和嵌入式生物特征认证应用提供了一种有前景的解决方案。

Abstract: Photoplethysmography (PPG) signals, which measure changes in blood volume in
the skin using light, have recently gained attention in biometric
authentication because of their non-invasive acquisition, inherent liveness
detection, and suitability for low-cost wearable devices. However, PPG signal
quality is challenged by motion artifacts, illumination changes, and
inter-subject physiological variability, making robust feature extraction and
classification crucial. This study proposes a lightweight and cost-effective
biometric authentication framework based on PPG signals extracted from
low-frame-rate fingertip videos. The CFIHSR dataset, comprising PPG recordings
from 46 subjects at a sampling rate of 14 Hz, is employed for evaluation. The
raw PPG signals undergo a standard preprocessing pipeline involving baseline
drift removal, motion artifact suppression using Principal Component Analysis
(PCA), bandpass filtering, Fourier-based resampling, and amplitude
normalization. To generate robust representations, each one-dimensional PPG
segment is converted into a two-dimensional time-frequency scalogram via the
Continuous Wavelet Transform (CWT), effectively capturing transient
cardiovascular dynamics. We developed a hybrid deep learning model, termed
CVT-ConvMixer-LSTM, by combining spatial features from the Convolutional Vision
Transformer (CVT) and ConvMixer branches with temporal features from a Long
Short-Term Memory network (LSTM). The experimental results on 46 subjects
demonstrate an authentication accuracy of 98%, validating the robustness of the
model to noise and variability between subjects. Due to its efficiency,
scalability, and inherent liveness detection capability, the proposed system is
well-suited for real-world mobile and embedded biometric security applications.

</details>


### [18] [MedDChest: A Content-Aware Multimodal Foundational Vision Model for Thoracic Imaging](https://arxiv.org/abs/2511.04016)
*Mahmoud Soliman,Islam Osman,Mohamed S. Shehata,Rasika Rajapakshe*

Main category: cs.CV

TL;DR: MedDChest是一个为胸部影像设计的新的基础视觉Transformer模型，通过在大规模、多模态的胸部影像数据集上进行预训练，并采用新颖的内容感知数据增强策略，显著优于在ImageNet上预训练的模型，为胸部影像诊断任务提供了一个更优的起点。


<details>
  <summary>Details</summary>
Motivation: 现有的医学影像视觉模型常采用在非相关的自然图像上预训练的骨干网络进行微调，这导致了显著的领域差距，从而影响了模型的性能。

Method: 提出了MedDChest，一个专门为胸部影像优化的基础视觉Transformer模型。该模型在一个包含超过120万张图像（涵盖X光和CT等多种模态）的海量、精选、多模态数据集上从头开始预训练。提出了一种名为“引导式随机调整裁剪”的新颖内容感知数据增强策略，该策略偏向于采样解剖学相关区域，克服了标准裁剪方法在医学扫描上的低效率。通过在多种下游诊断任务上进行微调来验证模型的有效性。

Result: 在多个下游诊断任务上的实验表明，MedDChest显著优于强大的、公开的、在ImageNet上预训练的模型。MedDChest作为一个强大的、鲁棒的特征提取器，为各种胸部诊断任务提供了一个显著更好的起点。

Conclusion: 大规模、同域预训练结合领域特定的数据增强策略（如MedDChest及其引导式随机调整裁剪）比使用在ImageNet上预训练的模型在医学影像任务上表现更优。MedDChest模型的权重将公开提供，以促进未来的研究和应用。

Abstract: The performance of vision models in medical imaging is often hindered by the
prevailing paradigm of fine-tuning backbones pre-trained on out-of-domain
natural images. To address this fundamental domain gap, we propose MedDChest, a
new foundational Vision Transformer (ViT) model optimized specifically for
thoracic imaging. We pre-trained MedDChest from scratch on a massive, curated,
multimodal dataset of over 1.2 million images, encompassing different
modalities including Chest X-ray and Computed Tomography (CT) compiled from 10
public sources. A core technical contribution of our work is Guided Random
Resized Crops, a novel content-aware data augmentation strategy that biases
sampling towards anatomically relevant regions, overcoming the inefficiency of
standard cropping techniques on medical scans. We validate our model's
effectiveness by fine-tuning it on a diverse set of downstream diagnostic
tasks. Comprehensive experiments empirically demonstrate that MedDChest
significantly outperforms strong, publicly available ImageNet-pretrained
models. By establishing the superiority of large-scale, in-domain pre-training
combined with domain-specific data augmentation, MedDChest provides a powerful
and robust feature extractor that serves as a significantly better starting
point for a wide array of thoracic diagnostic tasks. The model weights will be
made publicly available to foster future research and applications.

</details>


### [19] [Unveiling Deep Semantic Uncertainty Perception for Language-Anchored Multi-modal Vision-Brain Alignment](https://arxiv.org/abs/2511.04078)
*Zehui Feng,Chenqi Zhang,Mingru Wang,Minuo Wei,Shiwei Cheng,Cuntai Guan,Ting Han*

Main category: cs.CV

TL;DR: Bratrix是一个创新的端到端框架，通过语言锚定实现多模态的视觉-大脑对齐，它将视觉刺激分解为语义成分，并将视觉和大脑表征投影到共享的潜在空间，以生成对齐的视觉-语言和大脑-语言嵌入。该框架引入了一个新颖的不确定性感知模块来处理神经信号中的噪声，并通过语言锚定语义矩阵和两阶段训练策略来提高对齐精度。实验证明Bratrix在EEG、MEG和fMRI基准测试中显著优于现有方法，特别是在EEG检索任务中提升了14.3%。


<details>
  <summary>Details</summary>
Motivation: 现有方法将神经活动直接与视觉嵌入对齐，但仅有视觉的表征往往无法捕捉潜在的语义维度，这限制了模型的可解释性和鲁棒性。因此，需要一种新的方法来解决这个问题。

Method: Bratrix框架将视觉刺激分解为分层的视觉和语言语义成分，并将视觉和大脑表征投影到共享的潜在空间，以形成对齐的视觉-语言和大脑-语言嵌入。它还包含一个不确定性感知模块，在对齐过程中应用不确定性感知加权，以处理噪声神经信号。此外，通过利用可学习的语言锚定语义矩阵增强跨模态相关性，并采用单模态预训练和多模态微调的两阶段训练策略。

Result: 在EEG、MEG和fMRI基准测试上的广泛实验表明，Bratrix在检索、重建和标题生成方面优于最先进的方法，特别是在200路EEG检索任务中超越了14.3%。

Conclusion: Bratrix是第一个实现多模态语言锚定视觉-大脑对齐的端到端框架，它通过解耦视觉刺激、利用不确定性感知和语言锚定语义矩阵，显著提高了视觉语义解码的性能。

Abstract: Unveiling visual semantics from neural signals such as EEG, MEG, and fMRI
remains a fundamental challenge due to subject variability and the entangled
nature of visual features. Existing approaches primarily align neural activity
directly with visual embeddings, but visual-only representations often fail to
capture latent semantic dimensions, limiting interpretability and deep
robustness. To address these limitations, we propose Bratrix, the first
end-to-end framework to achieve multimodal Language-Anchored Vision-Brain
alignment. Bratrix decouples visual stimuli into hierarchical visual and
linguistic semantic components, and projects both visual and brain
representations into a shared latent space, enabling the formation of aligned
visual-language and brain-language embeddings. To emulate human-like perceptual
reliability and handle noisy neural signals, Bratrix incorporates a novel
uncertainty perception module that applies uncertainty-aware weighting during
alignment. By leveraging learnable language-anchored semantic matrices to
enhance cross-modal correlations and employing a two-stage training strategy of
single-modality pretraining followed by multimodal fine-tuning, Bratrix-M
improves alignment precision. Extensive experiments on EEG, MEG, and fMRI
benchmarks demonstrate that Bratrix improves retrieval, reconstruction, and
captioning performance compared to state-of-the-art methods, specifically
surpassing 14.3% in 200-way EEG retrieval task. Code and model are available.

</details>


### [20] [Adversarial and Score-Based CT Denoising: CycleGAN vs Noise2Score](https://arxiv.org/abs/2511.04083)
*Abu Hanif Muhammad Syarubany*

Main category: cs.CV

TL;DR: CycleGAN在CT图像去噪方面表现最佳，Noise2Score是有效的无需配对的替代方案。


<details>
  <summary>Details</summary>
Motivation: 在非配对和自监督条件下研究CT图像去噪，评估CycleGAN和Noise2Score两种方法。

Method: 使用CycleGAN（U-Net骨干）和Noise2Score（N2S）进行去噪。通过参数调整找到CycleGAN的最佳配置（lambda_cycle = 30, lambda_iden = 2, ngf = ndf = 64），并进行充分训练。

Result: CycleGAN将PSNR从34.66 dB / 0.9234 SSIM提升到38.913 dB / 0.971 SSIM，得分1.9441（训练集）/ 1.9343（测试集）。Noise2Score虽然PSNR/SSIM略低，但在极度噪声的输入下表现出色。

Conclusion: CycleGAN在最终图像质量上最优，而Noise2Score在无需配对的情况下提供了具有竞争力的性能。

Abstract: We study CT image denoising in the unpaired and self-supervised regimes by
evaluating two strong, training-data-efficient paradigms: a CycleGAN-based
residual translator and a Noise2Score (N2S) score-matching denoiser. Under a
common evaluation protocol, a configuration sweep identifies a simple standard
U-Net backbone within CycleGAN (lambda_cycle = 30, lambda_iden = 2, ngf = ndf =
64) as the most reliable setting; we then train it to convergence with a longer
schedule. The selected CycleGAN improves the noisy input from 34.66 dB / 0.9234
SSIM to 38.913 dB / 0.971 SSIM and attains an estimated score of 1.9441 and an
unseen-set (Kaggle leaderboard) score of 1.9343. Noise2Score, while slightly
behind in absolute PSNR / SSIM, achieves large gains over very noisy inputs,
highlighting its utility when clean pairs are unavailable. Overall, CycleGAN
offers the strongest final image quality, whereas Noise2Score provides a robust
pair-free alternative with competitive performance. Source code is available at
https://github.com/hanifsyarubany/CT-Scan-Image-Denoising-using-CycleGAN-and-Noise2Score.

</details>


### [21] [When Swin Transformer Meets KANs: An Improved Transformer Architecture for Medical Image Segmentation](https://arxiv.org/abs/2511.04084)
*Nishchal Sapkota,Haoyan Shi,Yejia Zhang,Xianshi Ma,Bofang Zheng,Danny Z. Chen*

Main category: cs.CV

TL;DR: UKAST是一种结合了Kolmogorov-Arnold网络(KAN)的U-Net类架构，用于医学图像分割，在数据稀疏的情况下表现出色。


<details>
  <summary>Details</summary>
Motivation: 解决医学图像分割中存在的复杂解剖结构、标注数据有限、CNN难以捕捉长距离依赖以及Transformer数据需求大和计算成本高的问题。

Method: 将基于有理函数的KAN集成到Swin Transformer编码器中，利用KAT中的Group Rational KAN(GR-KAN)来提高表达能力和数据效率，并减少计算量。

Result: UKAST在四个不同的2D和3D医学图像分割基准测试中取得了最先进的性能，优于CNN和Transformer基线方法，尤其是在数据稀疏的情况下。

Conclusion: KAN增强的Transformer在推动数据高效的医学图像分割方面具有巨大潜力。

Abstract: Medical image segmentation is critical for accurate diagnostics and treatment
planning, but remains challenging due to complex anatomical structures and
limited annotated training data. CNN-based segmentation methods excel at local
feature extraction, but struggle with modeling long-range dependencies.
Transformers, on the other hand, capture global context more effectively, but
are inherently data-hungry and computationally expensive. In this work, we
introduce UKAST, a U-Net like architecture that integrates rational-function
based Kolmogorov-Arnold Networks (KANs) into Swin Transformer encoders. By
leveraging rational base functions and Group Rational KANs (GR-KANs) from the
Kolmogorov-Arnold Transformer (KAT), our architecture addresses the
inefficiencies of vanilla spline-based KANs, yielding a more expressive and
data-efficient framework with reduced FLOPs and only a very small increase in
parameter count compared to SwinUNETR. UKAST achieves state-of-the-art
performance on four diverse 2D and 3D medical image segmentation benchmarks,
consistently surpassing both CNN- and Transformer-based baselines. Notably, it
attains superior accuracy in data-scarce settings, alleviating the data-hungry
limitations of standard Vision Transformers. These results show the potential
of KAN-enhanced Transformers to advance data-efficient medical image
segmentation. Code is available at: https://github.com/nsapkota417/UKAST

</details>


### [22] [SpatialLock: Precise Spatial Control in Text-to-Image Synthesis](https://arxiv.org/abs/2511.04112)
*Biao Liu,Yuanzhi Liang*

Main category: cs.CV

TL;DR: SpatialLock框架通过整合感知信号和地面信息，实现了对文本到图像生成中物体空间位置的精确控制，显著提高了物体定位的准确性和图像质量。


<details>
  <summary>Details</summary>
Motivation: 现有文本到图像合成方法在物体精确定位方面存在挑战，未能充分利用位置信息，导致对物体空间布局的理解不足。

Method: 提出SpatialLock框架，包含两个组件：1. 位置引导注入（PoI），通过注意力层直接整合空间信息，增强模型对地面信息的学习。2. 位置引导学习（PoG），采用基于感知的监督来优化物体定位。

Result: SpatialLock在物体精确定位方面设定了新的最优水平，在多个数据集上实现了超过0.9的IOU分数，并提高了生成图像的视觉质量。

Conclusion: SpatialLock框架能够生成具有精确空间排列的物体，并提升图像质量，解决了现有方法在物体精确定位方面的不足。

Abstract: Text-to-Image (T2I) synthesis has made significant advancements in recent
years, driving applications such as generating datasets automatically. However,
precise control over object localization in generated images remains a
challenge. Existing methods fail to fully utilize positional information,
leading to an inadequate understanding of object spatial layouts. To address
this issue, we propose SpatialLock, a novel framework that leverages perception
signals and grounding information to jointly control the generation of spatial
locations. SpatialLock incorporates two components: Position-Engaged Injection
(PoI) and Position-Guided Learning (PoG). PoI directly integrates spatial
information through an attention layer, encouraging the model to learn the
grounding information effectively. PoG employs perception-based supervision to
further refine object localization. Together, these components enable the model
to generate objects with precise spatial arrangements and improve the visual
quality of the generated images. Experiments show that SpatialLock sets a new
state-of-the-art for precise object positioning, achieving IOU scores above 0.9
across multiple datasets.

</details>


### [23] [BoRe-Depth: Self-supervised Monocular Depth Estimation with Boundary Refinement for Embedded Systems](https://arxiv.org/abs/2511.04388)
*Chang Liu,Juan Li,Sheng Zhang,Chang Liu,Jie Li,Xu Zhang*

Main category: cs.CV

TL;DR: BoRe-Depth是一个参数量仅为8.7M的新型单目深度估计模型，能够提升嵌入式系统上的深度估计性能和物体边界质量。


<details>
  <summary>Details</summary>
Motivation: 现有单目深度估计方法在嵌入式系统上面临深度估计性能差和物体边界模糊的挑战。

Method: 提出了一种名为BoRe-Depth的新型单目深度估计模型，包含一个增强特征自适应融合模块（EFAF）来增强边界细节，并集成语义知识到编码器以提升物体识别和边界感知能力。

Result: BoRe-Depth模型在NVIDIA Jetson Orin上高效运行，达到50.7 FPS，并在多个挑战性数据集上显著优于之前的轻量级模型。

Conclusion: BoRe-Depth模型能够准确地估计深度图，并显著提高边界质量，在嵌入式系统上表现优异。

Abstract: Depth estimation is one of the key technologies for realizing 3D perception
in unmanned systems. Monocular depth estimation has been widely researched
because of its low-cost advantage, but the existing methods face the challenges
of poor depth estimation performance and blurred object boundaries on embedded
systems. In this paper, we propose a novel monocular depth estimation model,
BoRe-Depth, which contains only 8.7M parameters. It can accurately estimate
depth maps on embedded systems and significantly improves boundary quality.
Firstly, we design an Enhanced Feature Adaptive Fusion Module (EFAF) which
adaptively fuses depth features to enhance boundary detail representation.
Secondly, we integrate semantic knowledge into the encoder to improve the
object recognition and boundary perception capabilities. Finally, BoRe-Depth is
deployed on NVIDIA Jetson Orin, and runs efficiently at 50.7 FPS. We
demonstrate that the proposed model significantly outperforms previous
lightweight models on multiple challenging datasets, and we provide detailed
ablation studies for the proposed methods. The code is available at
https://github.com/liangxiansheng093/BoRe-Depth.

</details>


### [24] [Tortoise and Hare Guidance: Accelerating Diffusion Model Inference with Multirate Integration](https://arxiv.org/abs/2511.04117)
*Yunghee Lee,Byeonghyun Pak,Junwha Hong,Hoseong Kim*

Main category: cs.CV

TL;DR: THG是一种无需训练的策略，通过将CFG ODE重构为多速率ODE系统，加速扩散采样同时保持高保真度。它通过在粗粒度时间步长上计算额外的引导项来显著减少计算量，并将NFE减少高达30%，同时几乎没有生成保真度损失。


<details>
  <summary>Details</summary>
Motivation: 分类器自由引导（CFG）的ODE在数值上对时间步长的选择很敏感，而引导项对时间步长的选择不那么敏感，这表明存在冗余，可以用来加速采样。

Method: THG将CFG ODE重构为多速率ODE系统，其中噪声估计在细粒度时间步长上进行积分，而额外的引导项在粗粒度时间步长上进行积分。该方法还包括一个感知误差边界的时间步长采样器和一个引导尺度调度器。

Result: THG将函数评估次数（NFE）减少了高达30%，同时几乎没有损失生成保真度（ΔImageReward≤0.032），并且在相同的计算预算下优于最先进的基于CFG的无需训练的加速器。

Conclusion: 多速率方法在扩散求解器中有巨大的潜力，可以实现无需重新训练模型的实时高质量图像合成。

Abstract: In this paper, we propose Tortoise and Hare Guidance (THG), a training-free
strategy that accelerates diffusion sampling while maintaining high-fidelity
generation. We demonstrate that the noise estimate and the additional guidance
term exhibit markedly different sensitivity to numerical error by reformulating
the classifier-free guidance (CFG) ODE as a multirate system of ODEs. Our
error-bound analysis shows that the additional guidance branch is more robust
to approximation, revealing substantial redundancy that conventional solvers
fail to exploit. Building on this insight, THG significantly reduces the
computation of the additional guidance: the noise estimate is integrated with
the tortoise equation on the original, fine-grained timestep grid, while the
additional guidance is integrated with the hare equation only on a coarse grid.
We also introduce (i) an error-bound-aware timestep sampler that adaptively
selects step sizes and (ii) a guidance-scale scheduler that stabilizes large
extrapolation spans. THG reduces the number of function evaluations (NFE) by up
to 30% with virtually no loss in generation fidelity ($\Delta$ImageReward
$\leq$ 0.032) and outperforms state-of-the-art CFG-based training-free
accelerators under identical computation budgets. Our findings highlight the
potential of multirate formulations for diffusion solvers, paving the way for
real-time high-quality image synthesis without any model retraining. The source
code is available at https://github.com/yhlee-add/THG.

</details>


### [25] [Text to Sketch Generation with Multi-Styles](https://arxiv.org/abs/2511.04123)
*Tengjie Li,Shikui Tu,Lei Xu*

Main category: cs.CV

TL;DR: 该研究提出了一种基于扩散模型的训练免费框架，用于通过文本提示和参考风格草图进行精确的草图风格控制，解决了现有方法在风格控制方面的不足。


<details>
  <summary>Details</summary>
Motivation: 现有草图生成方法主要关注通用合成，缺乏精确的风格控制机制，而本研究旨在实现显式的风格引导。

Method: 提出了一种基于扩散模型的训练免费框架，通过将参考特征作为辅助信息并结合线性平滑以及风格-内容引导机制，实现了显式的风格控制。该框架还扩展支持通过集成多个参考草图的特征，并利用联合AdaIN模块，进行可控的多风格生成。

Result: 实验证明，该方法能够生成高质量的草图，实现精确的风格对齐，并提高了风格控制的灵活性，尤其是在参考和目标草图结构相似度较低的情况下，能有效减少内容泄露，提升合成质量。

Conclusion: 本研究提出的框架能够实现高质量、高风格准确度的草图生成，并提供了更灵活的风格控制能力。

Abstract: Recent advances in vision-language models have facilitated progress in sketch
generation. However, existing specialized methods primarily focus on generic
synthesis and lack mechanisms for precise control over sketch styles. In this
work, we propose a training-free framework based on diffusion models that
enables explicit style guidance via textual prompts and referenced style
sketches. Unlike previous style transfer methods that overwrite key and value
matrices in self-attention, we incorporate the reference features as auxiliary
information with linear smoothing and leverage a style-content guidance
mechanism. This design effectively reduces content leakage from reference
sketches and enhances synthesis quality, especially in cases with low
structural similarity between reference and target sketches. Furthermore, we
extend our framework to support controllable multi-style generation by
integrating features from multiple reference sketches, coordinated via a joint
AdaIN module. Extensive experiments demonstrate that our approach achieves
high-quality sketch generation with accurate style alignment and improved
flexibility in style control. The official implementation of M3S is available
at https://github.com/CMACH508/M3S.

</details>


### [26] [Automated Tennis Player and Ball Tracking with Court Keypoints Detection (Hawk Eye System)](https://arxiv.org/abs/2511.04126)
*Venkata Manikanta Desu,Syed Fawaz Ali*

Main category: cs.CV

TL;DR: 本研究提出一个全自动网球比赛分析流程，结合多种深度学习模型实现球员、网球的实时检测与追踪，并识别球场关键点进行空间定位。


<details>
  <summary>Details</summary>
Motivation: 开发一个能提供详细比赛分析数据的全自动网球比赛分析系统，为教练、转播商和球员提供可操作的见解。

Method: 利用YOLOv8进行球员检测，定制训练的YOLOv5模型进行球的追踪，以及基于ResNet50的架构进行球场关键点检测，构建了一个集成的深度学习框架。

Result: 该系统在不同场地条件和比赛场景下均表现出强大的性能，并能输出标注视频及详细的性能指标，包括球员移动模式、球速、击球准确性和反应时间等。

Conclusion: 该自动化分析流程能够准确有效地提取网球比赛中的关键信息，为比赛分析提供有价值的数据支持。

Abstract: This study presents a complete pipeline for automated tennis match analysis.
Our framework integrates multiple deep learning models to detect and track
players and the tennis ball in real time, while also identifying court
keypoints for spatial reference. Using YOLOv8 for player detection, a
custom-trained YOLOv5 model for ball tracking, and a ResNet50-based
architecture for court keypoint detection, our system provides detailed
analytics including player movement patterns, ball speed, shot accuracy, and
player reaction times. The experimental results demonstrate robust performance
in varying court conditions and match scenarios. The model outputs an annotated
video along with detailed performance metrics, enabling coaches, broadcasters,
and players to gain actionable insights into the dynamics of the game.

</details>


### [27] [DMSORT: An efficient parallel maritime multi-object tracking architecture for unmanned vessel platforms](https://arxiv.org/abs/2511.04128)
*Shengyu Tang,Zeyuan Lu,Jiazhi Dong,Changdong Yu,Xiaoyu Wang,Yaohui Lyu,Weihao Xia*

Main category: cs.CV

TL;DR: DMSORT是一种用于海上多目标跟踪的高效双分支方法，通过仿射补偿和运动估计来解决复杂海洋环境中的挑战，实现了最先进的性能和最快的运行速度。


<details>
  <summary>Details</summary>
Motivation: 为了解决复杂海洋环境中相机运动和视觉退化对多目标跟踪（MOT）造成的挑战，确保船舶导航安全和有效监控。

Method: 提出了一种名为DMSORT的高效双分支方法，其核心是一个并行的跟踪器，包含一个目标检测和重识别（ReID）分支，以及一个用于动态相机运动估计的分支。该方法集成了可逆柱状检测网络（RCDN）和轻量级Transformer外观提取器（Li-TAE），并通过构建投影变换来解耦平台运动和目标运动，在卡尔曼滤波器中应用平台运动补偿，并利用聚类优化的特征融合模块结合运动和外观线索。

Result: 在新加坡海事数据集上进行了广泛评估，DMSORT在保持高身份一致性和对抖动、遮挡鲁棒性的同时，实现了最快的运行速度，优于现有的基于ReID的MOT框架。

Conclusion: DMSORT在海上MOT任务中取得了最先进的性能，特别是在处理相机运动和视觉退化方面，同时保持了高效的运行速度和鲁棒性。

Abstract: Accurate perception of the marine environment through robust multi-object
tracking (MOT) is essential for ensuring safe vessel navigation and effective
maritime surveillance. However, the complicated maritime environment often
causes camera motion and subsequent visual degradation, posing significant
challenges to MOT. To address this challenge, we propose an efficient
Dual-branch Maritime SORT (DMSORT) method for maritime MOT. The core of the
framework is a parallel tracker with affine compensation, which incorporates an
object detection and re-identification (ReID) branch, along with a dedicated
branch for dynamic camera motion estimation. Specifically, a Reversible
Columnar Detection Network (RCDN) is integrated into the detection module to
leverage multi-level visual features for robust object detection. Furthermore,
a lightweight Transformer-based appearance extractor (Li-TAE) is designed to
capture global contextual information and generate robust appearance features.
Another branch decouples platform-induced and target-intrinsic motion by
constructing a projective transformation, applying platform-motion compensation
within the Kalman filter, and thereby stabilizing true object trajectories.
Finally, a clustering-optimized feature fusion module effectively combines
motion and appearance cues to ensure identity consistency under noise,
occlusion, and drift. Extensive evaluations on the Singapore Maritime Dataset
demonstrate that DMSORT achieves state-of-the-art performance. Notably, DMSORT
attains the fastest runtime among existing ReID-based MOT frameworks while
maintaining high identity consistency and robustness to jitter and occlusion.
Code is available at:
https://github.com/BiscuitsLzy/DMSORT-An-efficient-parallel-maritime-multi-object-tracking-architecture-.

</details>


### [28] [Learning from Online Videos at Inference Time for Computer-Use Agents](https://arxiv.org/abs/2511.04137)
*Yujian Liu,Ze Wang,Hao Chen,Ximeng Sun,Xiaodong Yu,Jialian Wu,Jiang Liu,Emad Barsoum,Zicheng Liu,Shiyu Chang*

Main category: cs.CV

TL;DR: 研究如何让计算机使用代理在推理时从在线视频中有效学习，提出了一个框架，该框架检索和过滤教程视频，将它们转换为结构化的演示轨迹，并在执行过程中动态选择轨迹作为上下文指南。


<details>
  <summary>Details</summary>
Motivation: 目前的计算机使用代理在处理需要特定应用程序、平台和多步工作流的领域特定程序知识的任务时，仍然落后于人类用户。人类可以通过观看视频教程来弥补这一差距，通过搜索、浏览和选择性地模仿与当前子目标匹配的短片段。

Method: 提出一个框架，使用视觉语言模型（VLM）来推断UI操作，将视频分割成短的动作子序列，并为每个子序列分配一个文本目标。在推理时，一个两阶段的选择机制动态地为每个步骤选择一个轨迹作为上下文，将代理的注意力集中在最有利的本地指导上。

Result: 在两个广泛使用的基准上进行的实验表明，该框架持续优于强大的基础代理以及仅使用文本教程或文字记录的变体。

Conclusion: 在线视频可以被系统地提炼成可行的指导，从而在推理时改进计算机使用代理。分析突出了轨迹分割和选择、动作过滤和视觉信息的重要性。

Abstract: Computer-use agents can operate computers and automate laborious tasks, but
despite recent rapid progress, they still lag behind human users, especially
when tasks require domain-specific procedural knowledge about particular
applications, platforms, and multi-step workflows. Humans can bridge this gap
by watching video tutorials: we search, skim, and selectively imitate short
segments that match our current subgoal. In this paper, we study how to enable
computer-use agents to learn from online videos at inference time effectively.
We propose a framework that retrieves and filters tutorial videos, converts
them into structured demonstration trajectories, and dynamically selects
trajectories as in-context guidance during execution. Particularly, using a
VLM, we infer UI actions, segment videos into short subsequences of actions,
and assign each subsequence a textual objective. At inference time, a two-stage
selection mechanism dynamically chooses a single trajectory to add in context
at each step, focusing the agent on the most helpful local guidance for its
next decision. Experiments on two widely used benchmarks show that our
framework consistently outperforms strong base agents and variants that use
only textual tutorials or transcripts. Analyses highlight the importance of
trajectory segmentation and selection, action filtering, and visual
information, suggesting that abundant online videos can be systematically
distilled into actionable guidance that improves computer-use agents at
inference time. Our code is available at
https://github.com/UCSB-NLP-Chang/video_demo.

</details>


### [29] [Seeing Straight: Document Orientation Detection for Efficient OCR](https://arxiv.org/abs/2511.04161)
*Suranjan Goswami,Abhinav Ravi,Raja Kolla,Ali Faraz,Shaharukh Khan,Akash,Chandra Khatri,Shubham Agarwal*

Main category: cs.CV

TL;DR: 文档方向识别是OCR预处理的关键一步，本文提出了一个名为OCR-Rotation-Bench（ORB）的基准和基于Phi-3.5-Vision的模型，用于提高OCR在旋转图像上的性能。


<details>
  <summary>Details</summary>
Motivation: 在实际应用中，扫描或拍摄的文档方向可能不正确，这会影响OCR等下游任务的性能。因此，准确的旋转校正至关重要。

Method: 本文提出了OCR-Rotation-Bench（ORB）基准，包含ORB-En（英文）和ORB-Indic（11种印度语言）两个部分。并基于Phi-3.5-Vision模型的视觉编码器，构建了一个快速、鲁棒且轻量级的旋转分类流水线，采用动态图像裁剪，并针对4类旋转任务进行了微调。

Result: 该方法在ORB-En和ORB-Indic数据集上分别达到了96%和92%的准确率。此外，该方法显著提升了闭源模型（最高提升14%）和开源模型（最高提升4倍）在模拟真实场景下的OCR性能。

Conclusion: 本文提出的旋转分类模块能有效提高OCR在旋转图像上的性能，尤其是在模拟真实场景下，对于提升OCR鲁棒性具有重要意义。

Abstract: Despite significant advances in document understanding, determining the
correct orientation of scanned or photographed documents remains a critical
pre-processing step in the real world settings. Accurate rotation correction is
essential for enhancing the performance of downstream tasks such as Optical
Character Recognition (OCR) where misalignment commonly arises due to user
errors, particularly incorrect base orientations of the camera during capture.
In this study, we first introduce OCR-Rotation-Bench (ORB), a new benchmark for
evaluating OCR robustness to image rotations, comprising (i) ORB-En, built from
rotation-transformed structured and free-form English OCR datasets, and (ii)
ORB-Indic, a novel multilingual set spanning 11 Indic mid to low-resource
languages. We also present a fast, robust and lightweight rotation
classification pipeline built on the vision encoder of Phi-3.5-Vision model
with dynamic image cropping, fine-tuned specifically for 4-class rotation task
in a standalone fashion. Our method achieves near-perfect 96% and 92% accuracy
on identifying the rotations respectively on both the datasets. Beyond
classification, we demonstrate the critical role of our module in boosting OCR
performance: closed-source (up to 14%) and open-weights models (up to 4x) in
the simulated real-world setting.

</details>


### [30] [Systematic Evaluation of Preprocessing Techniques for Accurate Image Registration in Digital Pathology](https://arxiv.org/abs/2511.04171)
*Fatemehzahra Darzi,Rodrigo Escobar Diaz Guerrero,Thomas Bocklitz*

Main category: cs.CV

TL;DR: 在数字病理学中，研究了不同颜色变换技术对HE染色图像和非线性多模态图像之间配准的影响，发现CycleGAN颜色变换在配准中误差最低。


<details>
  <summary>Details</summary>
Motivation: 数字病理学中，需要精确配准不同染色或成像方式的图像，以支持生物标志物分析和组织重建等应用。

Method: 研究了20个组织样本对，在进行颜色变换（CycleGAN、Macenko、Reinhard、Vahadane）、反转、对比度调整、强度归一化和去噪等预处理步骤后，使用VALIS配准方法（刚性配准+两步非刚性配准）进行图像配准，并通过相对靶标配准误差（rTRE）评估配准性能。

Result: 在两种场景（原始多模态图像和反转多模态图像）下，CycleGAN颜色变换均实现了最低的配准误差（MMrTRE和AMrTRE），而其他方法误差较高。自定义的基于点的评估也支持了这一结论。

Conclusion: 在配准前应用颜色变换可以改善不同模态图像的对齐，从而在数字病理学中支持更可靠的分析。

Abstract: Image registration refers to the process of spatially aligning two or more
images by mapping them into a common coordinate system, so that corresponding
anatomical or tissue structures are matched across images. In digital
pathology, registration enables direct comparison and integration of
information from different stains or imaging modalities, sup-porting
applications such as biomarker analysis and tissue reconstruction. Accurate
registration of images from different modalities is an essential step in
digital pathology. In this study, we investigated how various color
transformation techniques affect image registration between hematoxylin and
eosin (H&E) stained images and non-linear multimodal images. We used a dataset
of 20 tissue sample pairs, with each pair undergoing several preprocessing
steps, including different color transformation (CycleGAN, Macenko, Reinhard,
Vahadane), inversion, contrast adjustment, intensity normalization, and
denoising. All images were registered using the VALIS registration method,
which first applies rigid registration and then performs non-rigid registration
in two steps on both low and high-resolution images. Registration performance
was evaluated using the relative Target Registration Error (rTRE). We reported
the median of median rTRE values (MMrTRE) and the average of median rTRE values
(AMrTRE) for each method. In addition, we performed a custom point-based
evaluation using ten manually selected key points. Registration was done
separately for two scenarios, using either the original or inverted multimodal
images. In both scenarios, CycleGAN color transformation achieved the lowest
registration errors, while the other methods showed higher errors. These
findings show that applying color transformation before registration improves
alignment between images from different modalities and supports more reliable
analysis in digital pathology.

</details>


### [31] [Covariance Descriptors Meet General Vision Encoders: Riemannian Deep Learning for Medical Image Classification](https://arxiv.org/abs/2511.04190)
*Josef Mayr,Anna Reithmeir,Maxime Di Folco,Julia A. Schnabel*

Main category: cs.CV

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Covariance descriptors capture second-order statistics of image features.
They have shown strong performance in general computer vision tasks, but remain
underexplored in medical imaging. We investigate their effectiveness for both
conventional and learning-based medical image classification, with a particular
focus on SPDNet, a classification network specifically designed for symmetric
positive definite (SPD) matrices. We propose constructing covariance
descriptors from features extracted by pre-trained general vision encoders
(GVEs) and comparing them with handcrafted descriptors. Two GVEs - DINOv2 and
MedSAM - are evaluated across eleven binary and multi-class datasets from the
MedMNSIT benchmark. Our results show that covariance descriptors derived from
GVE features consistently outperform those derived from handcrafted features.
Moreover, SPDNet yields superior performance to state-of-the-art methods when
combined with DINOv2 features. Our findings highlight the potential of
combining covariance descriptors with powerful pretrained vision encoders for
medical image analysis.

</details>


### [32] [AStF: Motion Style Transfer via Adaptive Statistics Fusor](https://arxiv.org/abs/2511.04192)
*Hanmo Chen,Chenghao Xu,Jiexi Yan,Cheng Deng*

Main category: cs.CV

TL;DR: 该研究提出了一种新的自适应统计融合器（AStF），通过引入偏度和峰度来更全面地捕捉运动数据的时空统计模式，从而提高运动风格迁移的性能。


<details>
  <summary>Details</summary>
Motivation: 传统运动风格迁移方法（基于均值和方差）不足以捕捉运动数据的复杂动态模式和时空连贯性，需要更全面的统计特征来处理图像和运动之间的根本差异。

Method: 提出了一种新的自适应统计融合器（AStF），包含风格解耦模块（SDM）和高阶多统计注意力（HOS-Attn），并结合运动一致性正则化（MCR）判别器进行训练。

Result: 实验结果表明，AStF在运动风格迁移方面优于现有技术，能够更全面地建模动态风格所固有的时空统计模式。

Conclusion: AStF通过引入偏度和峰度等高阶统计量，能够更全面地捕捉运动数据的时空统计模式，从而在运动风格迁移任务上取得优于现有技术的性能。

Abstract: Human motion style transfer allows characters to appear less rigidity and
more realism with specific style. Traditional arbitrary image style transfer
typically process mean and variance which is proved effective. Meanwhile,
similar methods have been adapted for motion style transfer. However, due to
the fundamental differences between images and motion, relying on mean and
variance is insufficient to fully capture the complex dynamic patterns and
spatiotemporal coherence properties of motion data. Building upon this, our key
insight is to bring two more coefficient, skewness and kurtosis, into the
analysis of motion style. Specifically, we propose a novel Adaptive Statistics
Fusor (AStF) which consists of Style Disentanglement Module (SDM) and
High-Order Multi-Statistics Attention (HOS-Attn). We trained our AStF in
conjunction with a Motion Consistency Regularization (MCR) discriminator.
Experimental results show that, by providing a more comprehensive model of the
spatiotemporal statistical patterns inherent in dynamic styles, our proposed
AStF shows proficiency superiority in motion style transfers over
state-of-the-arts. Our code and model are available at
https://github.com/CHMimilanlan/AStF.

</details>


### [33] [MedSapiens: Taking a Pose to Rethink Medical Imaging Landmark Detection](https://arxiv.org/abs/2511.04255)
*Marawan Elbatel,Anbang Wang,Keyuan Liu,Kaouther Mouheb,Enrique Almar-Munoz,Lizhuo Lin,Yanqi Yang,Karim Lekadir,Xiaomeng Li*

Main category: cs.CV

TL;DR: 本研究提出MedSapiens，一种适应人类中心基础模型（Sapiens）以进行医学影像解剖标志点检测的方法，并在多个数据集上达到了新的SOTA。


<details>
  <summary>Details</summary>
Motivation: 传统解剖标志点检测依赖领域特定模型，但大规模预训练视觉模型（如Sapiens）的出现提供了新的机会，本研究旨在探索和验证人类中心基础模型在医学影像解剖标志点检测上的潜力。

Method: 将为姿态估计设计的人类中心基础模型Sapiens通过多数据集预训练，调整其以适应医学影像解剖标志点检测任务，并提出MedSapiens模型。

Result: MedSapiens在多个医学影像解剖标志点检测数据集上取得了新的SOTA，在平均成功检测率（SDR）上，相较于通用模型提高了5.26%，相较于领域特定模型提高了21.81%。在少样本设置下，MedSapiens相较于少样本SOTA提高了2.69%的SDR。

Conclusion: 人类中心基础模型（如Sapiens）具有强大的空间姿态定位能力，可以作为医学影像解剖标志点检测的有力先验，这一潜力此前未被充分挖掘。MedSapiens证明了其有效性。

Abstract: This paper does not introduce a novel architecture; instead, it revisits a
fundamental yet overlooked baseline: adapting human-centric foundation models
for anatomical landmark detection in medical imaging. While landmark detection
has traditionally relied on domain-specific models, the emergence of
large-scale pre-trained vision models presents new opportunities. In this
study, we investigate the adaptation of Sapiens, a human-centric foundation
model designed for pose estimation, to medical imaging through multi-dataset
pretraining, establishing a new state of the art across multiple datasets. Our
proposed model, MedSapiens, demonstrates that human-centric foundation models,
inherently optimized for spatial pose localization, provide strong priors for
anatomical landmark detection, yet this potential has remained largely
untapped. We benchmark MedSapiens against existing state-of-the-art models,
achieving up to 5.26% improvement over generalist models and up to 21.81%
improvement over specialist models in the average success detection rate (SDR).
To further assess MedSapiens adaptability to novel downstream tasks with few
annotations, we evaluate its performance in limited-data settings, achieving
2.69% improvement over the few-shot state of the art in SDR. Code and model
weights are available at https://github.com/xmed-lab/MedSapiens .

</details>


### [34] [Proto-LeakNet: Towards Signal-Leak Aware Attribution in Synthetic Human Face Imagery](https://arxiv.org/abs/2511.04260)
*Claudio Giusti,Luca Guarnera,Sebastiano Battiato*

Main category: cs.CV

TL;DR: 该研究提出Proto-LeakNet，一种用于识别AI生成图像来源的网络，它利用扩散模型中残留的统计线索，即使在图像经过后处理后也能保持高精度，并且能够识别未知的生成器。


<details>
  <summary>Details</summary>
Motivation: 随着AI生成图像和Deepfake技术的日益成熟，对图像来源进行追踪和验证变得至关重要。现有方法面临挑战，而扩散模型输出中存在的“信号泄露”为解决此问题提供了新的途径。

Method: Proto-LeakNet在扩散模型的潜在空间中进行操作，通过模拟部分前向扩散过程来暴露生成器特有的线索。利用时间注意力编码器聚合多步潜在特征，并通过特征加权原型头构建嵌入空间，实现可解释的溯源。该模型采用闭集分类与基于密度的开集评估相结合的方式。

Result: Proto-LeakNet在仅使用闭集数据训练的情况下，达到了98.13%的宏观AUC。它学习到的潜在几何结构在经过后处理后依然稳健，超越了现有最先进的方法，并且在区分已知和未知生成器方面表现出色。

Conclusion: 通过对潜在空间中的信号泄露偏差进行建模，可以实现可靠且可解释的AI生成图像和Deepfake取证。Proto-LeakNet证明了这种方法的有效性。

Abstract: The growing sophistication of synthetic image and deepfake generation models
has turned source attribution and authenticity verification into a critical
challenge for modern computer vision systems. Recent studies suggest that
diffusion pipelines unintentionally imprint persistent statistical traces,
known as signal leaks, within their outputs, particularly in latent
representations. Building on this observation, we propose Proto-LeakNet, a
signal-leak-aware and interpretable attribution framework that integrates
closed-set classification with a density-based open-set evaluation on the
learned embeddings, enabling analysis of unseen generators without retraining.
Operating in the latent domain of diffusion models, our method re-simulates
partial forward diffusion to expose residual generator-specific cues. A
temporal attention encoder aggregates multi-step latent features, while a
feature-weighted prototype head structures the embedding space and enables
transparent attribution. Trained solely on closed data and achieving a Macro
AUC of 98.13%, Proto-LeakNet learns a latent geometry that remains robust under
post-processing, surpassing state-of-the-art methods, and achieves strong
separability between known and unseen generators. These results demonstrate
that modeling signal-leak bias in latent space enables reliable and
interpretable AI-image and deepfake forensics. The code for the whole work will
be available upon submission.

</details>


### [35] [DINOv2 Driven Gait Representation Learning for Video-Based Visible-Infrared Person Re-identification](https://arxiv.org/abs/2511.04281)
*Yujie Yang,Shuang Li,Jun Ye,Neng Dong,Fan Li,Huafeng Li*

Main category: cs.CV

TL;DR: 提出了一种名为 DinoGRL 的框架，通过结合 DINOv2 的视觉先验知识来学习步态特征，以解决视频可见光-红外行人重识别（VVI-ReID）问题，该方法通过 SASGL 和 PBMGE 模块，有效提升了跨模态视频匹配的准确性。


<details>
  <summary>Details</summary>
Motivation: 现有方法主要关注模态不变的视觉特征，但忽略了步态特征，而步态特征不仅模态不变且富含时间动态信息，因此限制了它们在跨模态视频匹配中对时空一致性的建模能力。

Method: 提出 DINOv2 驱动的步态表示学习（DinoGRL）框架，包括语义感知轮廓与步态学习（SASGL）模型和渐进式双向多粒度增强（PBMGE）模块。SASGL 利用 DINOv2 的语义先验生成和增强轮廓表示，并与 ReID 目标联合优化。PBMGE 通过步态和外观流之间的多粒度双向交互，逐步优化特征表示。

Result: 在 HITSZ-VCM 和 BUPT 数据集上的大量实验证明了该方法的优越性，显著优于现有的最先进方法。

Conclusion: 所提出的 DinoGRL 框架通过有效学习步态特征并结合外观线索，能够更好地进行跨模态视频匹配，为 VVI-ReID 任务提供了更优的解决方案。

Abstract: Video-based Visible-Infrared person re-identification (VVI-ReID) aims to
retrieve the same pedestrian across visible and infrared modalities from video
sequences. Existing methods tend to exploit modality-invariant visual features
but largely overlook gait features, which are not only modality-invariant but
also rich in temporal dynamics, thus limiting their ability to model the
spatiotemporal consistency essential for cross-modal video matching. To address
these challenges, we propose a DINOv2-Driven Gait Representation Learning
(DinoGRL) framework that leverages the rich visual priors of DINOv2 to learn
gait features complementary to appearance cues, facilitating robust
sequence-level representations for cross-modal retrieval. Specifically, we
introduce a Semantic-Aware Silhouette and Gait Learning (SASGL) model, which
generates and enhances silhouette representations with general-purpose semantic
priors from DINOv2 and jointly optimizes them with the ReID objective to
achieve semantically enriched and task-adaptive gait feature learning.
Furthermore, we develop a Progressive Bidirectional Multi-Granularity
Enhancement (PBMGE) module, which progressively refines feature representations
by enabling bidirectional interactions between gait and appearance streams
across multiple spatial granularities, fully leveraging their complementarity
to enhance global representations with rich local details and produce highly
discriminative features. Extensive experiments on HITSZ-VCM and BUPT datasets
demonstrate the superiority of our approach, significantly outperforming
existing state-of-the-art methods.

</details>


### [36] [FastGS: Training 3D Gaussian Splatting in 100 Seconds](https://arxiv.org/abs/2511.04283)
*Shiwei Ren,Tianci Wen,Yongchun Fang,Biao Lu*

Main category: cs.CV

TL;DR: FastGS是一种新的3D高斯泼溅加速框架，通过基于多视图一致性的高斯核密度估计和剪枝策略，解决了现有方法中高斯数量控制不当的问题，从而在保证渲染质量的同时显著缩短了训练时间。


<details>
  <summary>Details</summary>
Motivation: 现有的3D高斯泼溅（3DGS）加速方法在训练过程中未能有效控制高斯数量，导致计算时间浪费。

Method: 提出了一种名为FastGS的新型、简单且通用的加速框架，该框架基于多视图一致性来评估每个高斯的重要性，并设计了一种创新的、不依赖预算机制的、基于多视图一致性的高斯核密度估计和剪枝策略，以解决训练时间和渲染质量之间的权衡问题。

Result: 在Mip-NeRF 360、Tanks & Temples和Deep Blending数据集上的大量实验表明，FastGS在训练速度上显著优于现有最先进的方法。在Mip-NeRF 360数据集上，与DashGaussian相比，训练速度提高了3.32倍，渲染质量相当；在Deep Blending数据集上，与原始3DGS相比，训练速度提高了15.45倍。FastGS在动态场景重建、表面重建、稀疏视图重建、大规模重建和同步定位与建图等多种任务中均实现了2-7倍的训练加速，展现了其强大的通用性。

Conclusion: FastGS通过其创新的高斯核密度估计和剪枝策略，有效解决了3D高斯泼溅训练中的效率问题，并在多种场景下实现了显著的训练加速，同时保持了可比的渲染质量，证明了其在3D内容创作领域的潜力。

Abstract: The dominant 3D Gaussian splatting (3DGS) acceleration methods fail to
properly regulate the number of Gaussians during training, causing redundant
computational time overhead. In this paper, we propose FastGS, a novel, simple,
and general acceleration framework that fully considers the importance of each
Gaussian based on multi-view consistency, efficiently solving the trade-off
between training time and rendering quality. We innovatively design a
densification and pruning strategy based on multi-view consistency, dispensing
with the budgeting mechanism. Extensive experiments on Mip-NeRF 360, Tanks &
Temples, and Deep Blending datasets demonstrate that our method significantly
outperforms the state-of-the-art methods in training speed, achieving a
3.32$\times$ training acceleration and comparable rendering quality compared
with DashGaussian on the Mip-NeRF 360 dataset and a 15.45$\times$ acceleration
compared with vanilla 3DGS on the Deep Blending dataset. We demonstrate that
FastGS exhibits strong generality, delivering 2-7$\times$ training acceleration
across various tasks, including dynamic scene reconstruction, surface
reconstruction, sparse-view reconstruction, large-scale reconstruction, and
simultaneous localization and mapping. The project page is available at
https://fastgs.github.io/

</details>


### [37] [Vision Foundation Models in Agriculture: Toward Domain-Specific Adaptation for Weed Herbicide Trials Assessment](https://arxiv.org/abs/2511.04288)
*Leire Benito-Del-Valle,Artzai Picón,Daniel Mugica,Manuel Ramos,Eva Portillo,Javier Romero,Carlos Javier Jimenez,Ramón Navarra-Mestre*

Main category: cs.CV

TL;DR: 针对除草剂试验的特性分析，我们调整了一个通用的视觉基础模型。通过在大型农业数据集上使用自监督学习进行训练，该模型学习到了针对除草剂试验图像的丰富且可转移的表示，并在物种识别和损伤分类方面显著优于通用模型，尤其是在未见过的情况下和领域转移场景下表现更佳。此外，领域特定的预训练还能提高分割精度，并且在标注样本较少的情况下，能以更少的标注样本达到更高的F1分数。


<details>
  <summary>Details</summary>
Motivation: 传统的除草剂田间试验在不同环境下需要准确识别植物物种和评估除草剂造成的损害，而通用的视觉基础模型在农业这一细粒度区分至关重要的领域表现有限。

Method: 我们采用自监督学习方法，在一个大型、精选的农业数据集上，对一个通用的视觉基础模型进行训练和调整，使其适应除草剂试验的图像特征。

Result: 在物种识别方面，F1分数从0.91提升至0.94；在损伤分类方面，F1分数从0.26提升至0.33。在未见过的情况下，物种识别F1分数从0.56提升至0.66，损伤分类F1分数从0.17提升至0.27。在领域转移场景下（如无人机图像），物种识别F1分数从0.49提升至0.60。领域特定的预训练还提高了分割精度，在标注样本少的情况下，使用80%的标注样本即可达到比通用模型高5.4%的F1分数。

Conclusion: 领域特定的基础模型具有良好的泛化能力，能够显著减少手动标注工作量，为除草剂试验分析提供了一种可扩展且自动化的解决方案。

Abstract: Herbicide field trials require accurate identification of plant species and
assessment of herbicide-induced damage across diverse environments. While
general-purpose vision foundation models have shown promising results in
complex visual domains, their performance can be limited in agriculture, where
fine-grained distinctions between species and damage types are critical.
  In this work, we adapt a general-purpose vision foundation model to herbicide
trial characterization. Trained using a self-supervised learning approach on a
large, curated agricultural dataset, the model learns rich and transferable
representations optimized for herbicide trials images.
  Our domain-specific model significantly outperforms the best general-purpose
foundation model in both species identification (F1 score improvement from 0.91
to 0.94) and damage classification (from 0.26 to 0.33). Under unseen conditions
(new locations and other time), it achieves even greater gains (species
identification from 0.56 to 0.66; damage classification from 0.17 to 0.27). In
domain-shift scenarios, such as drone imagery, it maintains strong performance
(species classification from 0.49 to 0.60).
  Additionally, we show that domain-specific pretraining enhances segmentation
accuracy, particularly in low-annotation regimes. An annotation-efficiency
analysis reveals that, under unseen conditions, the domain-specific model
achieves 5.4% higher F1 score than the general-purpose model, while using 80%
fewer labeled samples.
  These results demonstrate the generalization capabilities of domain-specific
foundation models and their potential to significantly reduce manual annotation
efforts, offering a scalable and automated solution for herbicide trial
analysis.

</details>


### [38] [Deep learning-based object detection of offshore platforms on Sentinel-1 Imagery and the impact of synthetic training data](https://arxiv.org/abs/2511.04304)
*Robin Spanier,Thorsten Hoeser,Claudia Kuenzer*

Main category: cs.CV

TL;DR: 研究利用合成数据训练YOLOv10模型以提高海上基础设施检测的性能和地理迁移能力。


<details>
  <summary>Details</summary>
Motivation: 海上基础设施（如海上风电场、石油和天然气平台等）的扩张需要有效的监测系统，但现有模型在处理样本稀疏（尤其是在代表性不足的类别、形状和尺寸方面）时表现不佳。

Method: 结合使用合成和真实Sentinel-1卫星图像（2023年第四季度，四个区域：里海、南海、几内亚湾和巴西海岸）训练YOLOv10目标检测模型。

Result: 在三个未见的区域（墨西哥湾、北海、波斯湾）应用模型进行检测，成功检测到3,529个海上平台（北海411个，墨西哥湾1,519个，波斯湾1,593个）。未加入合成数据时F1得分为0.85，加入后提升至0.90。

Conclusion: 合成数据能有效解决遥感中类别不平衡和模型泛化能力不足的问题，是实现可扩展、全球化海上基础设施监测的有效策略，并展示了深度学习在此领域的潜力。

Abstract: The recent and ongoing expansion of marine infrastructure, including offshore
wind farms, oil and gas platforms, artificial islands, and aquaculture
facilities, highlights the need for effective monitoring systems. The
development of robust models for offshore infrastructure detection relies on
comprehensive, balanced datasets, but falls short when samples are scarce,
particularly for underrepresented object classes, shapes, and sizes. By
training deep learning-based YOLOv10 object detection models with a combination
of synthetic and real Sentinel-1 satellite imagery acquired in the fourth
quarter of 2023 from four regions (Caspian Sea, South China Sea, Gulf of
Guinea, and Coast of Brazil), this study investigates the use of synthetic
training data to enhance model performance. We evaluated this approach by
applying the model to detect offshore platforms in three unseen regions (Gulf
of Mexico, North Sea, Persian Gulf) and thereby assess geographic
transferability. This region-holdout evaluation demonstrated that the model
generalises beyond the training areas. In total, 3,529 offshore platforms were
detected, including 411 in the North Sea, 1,519 in the Gulf of Mexico, and
1,593 in the Persian Gulf. The model achieved an F1 score of 0.85, which
improved to 0.90 upon incorporating synthetic data. We analysed how synthetic
data enhances the representation of unbalanced classes and overall model
performance, taking a first step toward globally transferable detection of
offshore infrastructure. This study underscores the importance of balanced
datasets and highlights synthetic data generation as an effective strategy to
address common challenges in remote sensing, demonstrating the potential of
deep learning for scalable, global offshore infrastructure monitoring.

</details>


### [39] [RISE-T2V: Rephrasing and Injecting Semantics with LLM for Expansive Text-to-Video Generation](https://arxiv.org/abs/2511.04317)
*Xiangjun Zhang,Litong Gong,Yinglin Zheng,Yansong Liu,Wentao Jiang,Mingyi Xu,Biao Wang,Tiezheng Ge,Ming Zeng*

Main category: cs.CV

TL;DR: RISE-T2V通过引入“改写适配器”模块，将提示词改写和语义特征提取整合为一步，解决了现有文本到视频模型在处理简洁提示词时视频质量下降和语义理解有限的问题，提升了模型的可扩展性和可用性。


<details>
  <summary>Details</summary>
Motivation: 现有文本到视频（T2V）模型依赖预训练的文本编码器，但在处理简洁提示词时常出现视频质量下降和语义理解有限的问题，且文本编码器无法在线改写提示词，限制了模型的扩展性和可用性。

Method: 提出RISE-T2V框架，将提示词改写和语义特征提取整合为一步。引入“改写适配器”模块，使视频生成模型能利用语言模型（LLM）的文本隐藏状态作为视频生成的条件，通过隐式改写提示词生成更符合用户意图的视频。RISE-T2V框架可应用于多种预训练LLM和视频扩散模型（VDM）。

Result: RISE-T2V框架可应用于不同的视频扩散模型架构，显著提升了T2V模型生成与用户意图高度一致的高质量视频的能力。

Conclusion: RISE-T2V是一个通用的框架，通过整合提示词改写和语义特征提取，有效解决了现有T2V模型的局限性，提高了视频生成质量和用户意图的对齐度。

Abstract: Most text-to-video(T2V) diffusion models depend on pre-trained text encoders
for semantic alignment, yet they often fail to maintain video quality when
provided with concise prompts rather than well-designed ones. The primary issue
lies in their limited textual semantics understanding. Moreover, these text
encoders cannot rephrase prompts online to better align with user intentions,
which limits both the scalability and usability of the models, To address these
challenges, we introduce RISE-T2V, which uniquely integrates the processes of
prompt rephrasing and semantic feature extraction into a single and seamless
step instead of two separate steps. RISE-T2V is universal and can be applied to
various pre-trained LLMs and video diffusion models(VDMs), significantly
enhancing their capabilities for T2V tasks. We propose an innovative module
called the Rephrasing Adapter, enabling diffusion models to utilize text hidden
states during the next token prediction of the LLM as a condition for video
generation. By employing a Rephrasing Adapter, the video generation model can
implicitly rephrase basic prompts into more comprehensive representations that
better match the user's intent. Furthermore, we leverage the powerful
capabilities of LLMs to enable video generation models to accomplish a broader
range of T2V tasks. Extensive experiments demonstrate that RISE-T2V is a
versatile framework applicable to different video diffusion model
architectures, significantly enhancing the ability of T2V models to generate
high-quality videos that align with user intent. Visual results are available
on the webpage at https://rise-t2v.github.io.

</details>


### [40] [Submanifold Sparse Convolutional Networks for Automated 3D Segmentation of Kidneys and Kidney Tumours in Computed Tomography](https://arxiv.org/abs/2511.04334)
*Saúl Alonso-Monsalve,Leigh H. Whitehead,Adam Aurisano,Lorena Escudero Sanchez*

Main category: cs.CV

TL;DR: 提出一种新的体素稀疏化和子流形稀疏卷积网络两阶段方法，用于在医学图像（特别是CT扫描）中自动分割肿瘤，该方法在高分辨率输入和原生3D模型架构下实现了最先进的准确性，同时显著减少了计算资源消耗。


<details>
  <summary>Details</summary>
Motivation: 自动分割肿瘤对于临床应用至关重要，因为手动分割耗时且存在瓶颈。现有方法在处理3D扫描时面临计算挑战，通常需要降采样或使用图像块。

Method: 采用两阶段方法：1. 体素稀疏化；2. 子流形稀疏卷积网络，以在高分辨率输入和原生3D模型架构下进行分割。

Result: 在KiTS23挑战赛的肾癌CT图像上，肾脏+肿块的Dice相似系数为95.8%，肿瘤+囊肿为85.7%，仅肿瘤为80.3%。与等效的密集架构相比，推理时间减少了60%，VRAM使用量减少了75%。

Conclusion: 所提出的方法在高分辨率3D医学图像肿瘤分割方面取得了有竞争力的结果，并且在计算效率方面具有显著优势。

Abstract: The accurate delineation of tumours in radiological images like Computed
Tomography is a very specialised and time-consuming task, and currently a
bottleneck preventing quantitative analyses to be performed routinely in the
clinical setting. For this reason, developing methods for the automated
segmentation of tumours in medical imaging is of the utmost importance and has
driven significant efforts in recent years. However, challenges regarding the
impracticality of 3D scans, given the large amount of voxels to be analysed,
usually requires the downsampling of such images or using patches thereof when
applying traditional convolutional neural networks. To overcome this problem,
in this paper we propose a new methodology that uses, divided into two stages,
voxel sparsification and submanifold sparse convolutional networks. This method
allows segmentations to be performed with high-resolution inputs and a native
3D model architecture, obtaining state-of-the-art accuracies while
significantly reducing the computational resources needed in terms of GPU
memory and time. We studied the deployment of this methodology in the context
of Computed Tomography images of renal cancer patients from the KiTS23
challenge, and our method achieved results competitive with the challenge
winners, with Dice similarity coefficients of 95.8% for kidneys + masses, 85.7%
for tumours + cysts, and 80.3% for tumours alone. Crucially, our method also
offers significant computational improvements, achieving up to a 60% reduction
in inference time and up to a 75\% reduction in VRAM usage compared to an
equivalent dense architecture, across both CPU and various GPU cards tested.

</details>


### [41] [Comparative Study of CNN Architectures for Binary Classification of Horses and Motorcycles in the VOC 2008 Dataset](https://arxiv.org/abs/2511.04344)
*Muhammad Annas Shaikh,Hamza Zaman,Arbaz Asif*

Main category: cs.CV

TL;DR: 本研究评估了九种卷积神经网络架构在VOC 2008数据集上对马匹和摩托车进行二元分类的性能，并解决了类别不平衡问题。


<details>
  <summary>Details</summary>
Motivation: 解决VOC 2008数据集中马匹和摩托车二元分类任务中的类别不平衡问题，并评估不同卷积神经网络架构的性能。

Method: 使用包括ResNet-50、ConvNeXt-Tiny、DenseNet-121和Vision Transformer在内的九种现代架构，并通过实施少数类增强技术来处理类别不平衡问题。在多个性能指标上进行比较。

Result: ConvNeXt-Tiny在马匹检测方面取得了最高的平均精度（AP），为95.53%，在摩托车检测方面为89.12%。数据增强显著提高了少数类检测性能，特别是对更深层次的架构。

Conclusion: ConvNeXt-Tiny在所评估的架构中表现最好。数据增强是缓解目标检测中类别不平衡问题的有效策略，尤其有利于更深层次的架构。本研究为在类别不平衡的情况下进行目标检测的任务提供了架构选择方面的见解。

Abstract: This paper presents a comprehensive evaluation of nine convolutional neural
network architectures for binary classification of horses and motorcycles in
the VOC 2008 dataset. We address the significant class imbalance problem by
implementing minority-class augmentation techniques. Our experiments compare
modern architectures including ResNet-50, ConvNeXt-Tiny, DenseNet-121, and
Vision Transformer across multiple performance metrics. Results demonstrate
substantial performance variations, with ConvNeXt-Tiny achieving the highest
Average Precision (AP) of 95.53% for horse detection and 89.12% for motorcycle
detection. We observe that data augmentation significantly improves minority
class detection, particularly benefiting deeper architectures. This study
provides insights into architecture selection for imbalanced binary
classification tasks and quantifies the impact of data augmentation strategies
in mitigating class imbalance issues in object detection.

</details>


### [42] [Evaluating the Impact of Weather-Induced Sensor Occlusion on BEVFusion for 3D Object Detection](https://arxiv.org/abs/2511.04347)
*Sanjay Kumar,Tim Brophy,Eoin Martino Grua,Ganesh Sistu,Valentina Donzella,Ciaran Eising*

Main category: cs.CV

TL;DR: BEVFusion在自动驾驶3D目标检测中，摄像头和激光雷达在遮挡情况下的表现不同，融合模型更依赖激光雷达。


<details>
  <summary>Details</summary>
Motivation: 探究传感器遮挡对基于BEV表示的3D目标检测模型（以BEVFusion为例）的影响。

Method: 在nuScenes数据集上，评估了单独使用摄像头、单独使用激光雷达以及融合模型在不同程度遮挡情况下的3D目标检测性能，使用mAP和NDS作为评估指标。

Result: 中度遮挡导致仅基于摄像头的检测mAP下降41.3%。仅激光雷达在重度遮挡下mAP下降47.3%。融合模型中，遮挡摄像头导致mAP下降4.1%，遮挡激光雷达导致mAP下降26.8%，表明模型更依赖激光雷达。

Conclusion: 需要开发能应对传感器遮挡或退化的3D目标检测评估方法和传感器融合技术。

Abstract: Accurate 3D object detection is essential for automated vehicles to navigate
safely in complex real-world environments. Bird's Eye View (BEV)
representations, which project multi-sensor data into a top-down spatial
format, have emerged as a powerful approach for robust perception. Although
BEV-based fusion architectures have demonstrated strong performance through
multimodal integration, the effects of sensor occlusions, caused by
environmental conditions such as fog, haze, or physical obstructions, on 3D
detection accuracy remain underexplored. In this work, we investigate the
impact of occlusions on both camera and Light Detection and Ranging (LiDAR)
outputs using the BEVFusion architecture, evaluated on the nuScenes dataset.
Detection performance is measured using mean Average Precision (mAP) and the
nuScenes Detection Score (NDS). Our results show that moderate camera
occlusions lead to a 41.3% drop in mAP (from 35.6% to 20.9%) when detection is
based only on the camera. On the other hand, LiDAR sharply drops in performance
only under heavy occlusion, with mAP falling by 47.3% (from 64.7% to 34.1%),
with a severe impact on long-range detection. In fused settings, the effect
depends on which sensor is occluded: occluding the camera leads to a minor 4.1%
drop (from 68.5% to 65.7%), while occluding LiDAR results in a larger 26.8%
drop (to 50.1%), revealing the model's stronger reliance on LiDAR for the task
of 3D object detection. Our results highlight the need for future research into
occlusion-aware evaluation methods and improved sensor fusion techniques that
can maintain detection accuracy in the presence of partial sensor failure or
degradation due to adverse environmental conditions.

</details>


### [43] [A MATLAB tutorial on deep feature extraction combined with chemometrics for analytical applications](https://arxiv.org/abs/2511.04349)
*Puneet Mishra,Martijntje Vollebregt,Yizhou Ma,Maria Font-i-Furnols*

Main category: cs.CV

TL;DR: 本教程提供一个分步指南，介绍如何将深度学习方法应用于从成像数据中提取空间信息，并将其与光谱信息等其他数据源集成。重点在于使用现有的开源模型提取深度特征，而不是训练新模型。


<details>
  <summary>Details</summary>
Motivation: 分析化学中，虽然成像技术（如彩色相机、高光谱相机和显微镜）可以捕捉材料的空间信息，但使用传统的化学计量学方法提取和分析这些信息以进行探索性和预测性分析仍然是一个挑战。深度学习在图像处理方面有很大潜力，但分析化学领域对其应用有限，因为缺乏结构化的指导。

Method: 本教程旨在弥合这一差距，提供一个分步指南，介绍如何应用深度学习方法来提取成像数据中的空间信息，并将其与光谱信息等其他数据源集成。重点是使用现有的开源模型提取深度特征，而不是训练模型。

Result: 本教程提供了 MATLAB 代码演示，展示了如何处理分析化学中常见的各种成像模式的成像数据。代码可供读者在自己的数据集上运行。

Conclusion: 本教程通过提供实际的 MATLAB 代码和分步指南，解决了分析化学中利用深度学习提取成像数据空间信息的挑战，促进了该领域对先进图像处理技术的应用。

Abstract: Background In analytical chemistry, spatial information about materials is
commonly captured through imaging techniques, such as traditional color cameras
or with advanced hyperspectral cameras and microscopes. However, efficiently
extracting and analyzing this spatial information for exploratory and
predictive purposes remains a challenge, especially when using traditional
chemometric methods. Recent advances in deep learning and artificial
intelligence have significantly enhanced image processing capabilities,
enabling the extraction of multiscale deep features that are otherwise
challenging to capture with conventional image processing techniques. Despite
the wide availability of open-source deep learning models, adoption in
analytical chemistry remains limited because of the absence of structured,
step-by-step guidance for implementing these models.
  Results This tutorial aims to bridge this gap by providing a step-by-step
guide for applying deep learning approaches to extract spatial information from
imaging data and integrating it with other data sources, such as spectral
information. Importantly, the focus of this work is not on training deep
learning models for image processing but on using existing open source models
to extract deep features from imaging data.
  Significance The tutorial provides MATLAB code tutorial demonstrations,
showcasing the processing of imaging data from various imaging modalities
commonly encountered in analytical chemistry. Readers must run the tutorial
steps on their own datasets using the codes presented in this tutorial.

</details>


### [44] [Multi-Task Learning for Visually Grounded Reasoning in Gastrointestinal VQA](https://arxiv.org/abs/2511.04384)
*Itbaan Safwan,Muhammad Annas Shaikh,Muhammad Haaris,Ramail Khan,Muhammad Atif Tahir*

Main category: cs.CV

TL;DR: 使用 LoRA 调优的 Florence-2 模型进行医学 VQA 的多任务框架，结合视觉问答、解释生成和视觉定位。


<details>
  <summary>Details</summary>
Motivation: 为 MediaEval Medico 2025 挑战开发一个能够同时处理视觉问答、生成解释和进行视觉定位的多任务框架。

Method: 使用 LoRA 调优 Florence-2 模型，并整合 Kvasir-VQA-x1 数据集、结构化医学推理的合成解释数据集以及文本到区域对。

Result: 与单任务基线相比，在答案准确性和视觉定位方面取得了显著改进。

Conclusion: 基于视觉定位的多任务学习方法能有效提升医学 VQA 应用的性能。

Abstract: We present a multi-task framework for the MediaEval Medico 2025 challenge,
leveraging a LoRA-tuned Florence-2 model for simultaneous visual question
answering (VQA), explanation generation, and visual grounding. The proposed
system integrates three curated datasets: (1) Kvasir-VQA-x1 for question-answer
learning, (2) a synthetically enriched explanation dataset offering structured
medical reasoning, and (3) text-to-region pairs linking visual features with
segmentation masks. This multi-task setup enables the model to jointly learn
visual grounding, reasoning, and interpretation, producing responses that are
both accurate and interpretable. Extensive evaluation demonstrates that our
approach substantially improves over single-task baselines in both answer
accuracy and visual localization, highlighting the effectiveness of grounded
multi-task learning for medical VQA applications.

</details>


### [45] [DORAEMON: A Unified Library for Visual Object Modeling and Representation Learning at Scale](https://arxiv.org/abs/2511.04394)
*Ke Du,Yimin Peng,Chao Gao,Fan Zhou,Siqiao Xue*

Main category: cs.CV

TL;DR: DORAEMON是一个开源PyTorch库，统一了视觉对象建模和表示学习，提供了一个YAML驱动的工作流，支持分类、检索和度量学习，并提供超过1000个预训练骨干模型、模块化损失函数、增强和分布式训练工具。


<details>
  <summary>Details</summary>
Motivation: DORAEMON的目标是统一视觉对象建模和表示学习，简化跨不同尺度的模型开发和训练过程，并促进研究成果向实际应用的转化。

Method: DORAEMON使用一个YAML驱动的工作流来统一分类、检索和度量学习任务。它提供了超过1000个预训练骨干模型（通过timm兼容接口）、模块化损失函数、数据增强工具和分布式训练实用程序。该库支持在ImageNet-1K、MS-Celeb-1M和Stanford online products等数据集上进行复现性实验，并将模型导出为ONNX或HuggingFace格式。

Result: DORAEMON在ImageNet-1K、MS-Celeb-1M和Stanford online products数据集上取得了与参考结果相当或更优的性能。

Conclusion: DORAEMON通过整合数据集、模型和训练技术，为视觉识别和表示学习的快速实验提供了一个可扩展的基础，从而能够有效地将研究进展转化为实际应用。

Abstract: DORAEMON is an open-source PyTorch library that unifies visual object
modeling and representation learning across diverse scales. A single
YAML-driven workflow covers classification, retrieval and metric learning; more
than 1000 pretrained backbones are exposed through a timm-compatible interface,
together with modular losses, augmentations and distributed-training utilities.
Reproducible recipes match or exceed reference results on ImageNet-1K,
MS-Celeb-1M and Stanford online products, while one-command export to ONNX or
HuggingFace bridges research and deployment. By consolidating datasets, models,
and training techniques into one platform, DORAEMON offers a scalable
foundation for rapid experimentation in visual recognition and representation
learning, enabling efficient transfer of research advances to real-world
applications. The repository is available at https://github.com/wuji3/DORAEMON.

</details>


### [46] [HideAndSeg: an AI-based tool with automated prompting for octopus segmentation in natural habitats](https://arxiv.org/abs/2511.04426)
*Alan de Aguiar,Michaella Pereira Andrade,Charles Morphy D. Santos,João Paulo Gois*

Main category: cs.CV

TL;DR: HideAndSeg是一个新颖的、经过最少监督的人工智能工具，用于分割视频中的章鱼，它建立了一个该任务的定量基准。HideAndSeg 集成了 SAM2 和自定义训练的 YOLOv11 对象检测器，并引入了两个无监督指标来评估分割质量。


<details>
  <summary>Details</summary>
Motivation: 分析处于自然栖息地的章鱼具有挑战性，因为它们具有伪装能力、皮肤纹理和颜色快速变化、非刚体变形以及频繁的遮挡，所有这些都因可变的水下照明和浊度而加剧。为了解决缺乏大规模带注释数据集的问题，本论文介绍了 HideAndSeg。

Method: HideAndSeg 集成了 SAM2 和自定义训练的 YOLOv11 对象检测器。用户提供点坐标以使用 SAM2 生成初始分割掩码，这些掩码用作 YOLO 模型的训练数据。然后，该方法通过向 SAM2 提供边界框提示来完全自动化该流程，无需进一步的手动干预。引入了两个无监督指标（时间一致性 DICE_t 和新组件计数 NC_t）来定量评估分割质量并指导掩码优化。

Result: HideAndSeg 实现了令人满意的性能，与手动提示的方法相比，分割噪声有所减少。该方法即使在完全遮挡一段时间后也能在自然环境中重新识别和分割章鱼，而手动提示的模型在此场景下会失败。

Conclusion: HideAndSeg 通过减少真实场景中手动分析的需要，提供了一个实用的工具，为更有效的野生头足类动物行为研究铺平了道路。

Abstract: Analyzing octopuses in their natural habitats is challenging due to their
camouflage capability, rapid changes in skin texture and color, non-rigid body
deformations, and frequent occlusions, all of which are compounded by variable
underwater lighting and turbidity. Addressing the lack of large-scale annotated
datasets, this paper introduces HideAndSeg, a novel, minimally supervised
AI-based tool for segmenting videos of octopuses. It establishes a quantitative
baseline for this task. HideAndSeg integrates SAM2 with a custom-trained
YOLOv11 object detector. First, the user provides point coordinates to generate
the initial segmentation masks with SAM2. These masks serve as training data
for the YOLO model. After that, our approach fully automates the pipeline by
providing a bounding box prompt to SAM2, eliminating the need for further
manual intervention. We introduce two unsupervised metrics - temporal
consistency $DICE_t$ and new component count $NC_t$ - to quantitatively
evaluate segmentation quality and guide mask refinement in the absence of
ground-truth data, i.e., real-world information that serves to train, validate,
and test AI models. Results show that HideAndSeg achieves satisfactory
performance, reducing segmentation noise compared to the manually prompted
approach. Our method can re-identify and segment the octopus even after periods
of complete occlusion in natural environments, a scenario in which the manually
prompted model fails. By reducing the need for manual analysis in real-world
scenarios, this work provides a practical tool that paves the way for more
efficient behavioral studies of wild cephalopods.

</details>


### [47] [Solving Convex Partition Visual Jigsaw Puzzles](https://arxiv.org/abs/2511.04450)
*Yaniv Ohayon,Ofir Itzhak Shahar,Ohad Ben-Shahar*

Main category: cs.CV

TL;DR: 本文介绍了针对凸多边形拼图的自动求解方法，并构建了相关数据集。


<details>
  <summary>Details</summary>
Motivation: 现有的拼图求解器大多只关注方形拼图，实用性受限。本研究旨在扩展拼图求解器的应用范围，处理更广泛的凸多边形拼图。

Method: 结合几何和图像信息，提出了一种贪心算法来求解凸多边形拼图问题。

Result: 开发了首个凸多边形拼图数据集，并报告了求解器的性能。

Conclusion: 提出的方法能够有效处理凸多边形拼图，并为该领域的研究提供了新的数据集和评估基准。

Abstract: Jigsaw puzzle solving requires the rearrangement of unordered pieces into
their original pose in order to reconstruct a coherent whole, often an image,
and is known to be an intractable problem. While the possible impact of
automatic puzzle solvers can be disruptive in various application domains, most
of the literature has focused on developing solvers for square jigsaw puzzles,
severely limiting their practical use. In this work, we significantly expand
the types of puzzles handled computationally, focusing on what is known as
Convex Partitions, a major subset of polygonal puzzles whose pieces are convex.
We utilize both geometrical and pictorial compatibilities, introduce a greedy
solver, and report several performance measures next to the first benchmark
dataset of such puzzles.

</details>


### [48] [V-Thinker: Interactive Thinking with Images](https://arxiv.org/abs/2511.04460)
*Runqi Qiao,Qiuna Tan,Minghan Yang,Guanting Dong,Peiqing Yang,Shiqiang Lang,Enhui Wan,Xiaowan Wang,Yida Xu,Lan Yang,Chong Sun,Chen Li,Honggang Zhang*

Main category: cs.CV

TL;DR: V-Thinker是一个通用的多模态推理助手，通过端到端的强化学习实现交互式、以视觉为中心的思考，解决了现有LMM在图像交互和长时推理方面的局限性。


<details>
  <summary>Details</summary>
Motivation: 当前的LMM在深度集成图像交互和长时推理能力方面存在挑战，现有方法在视觉工具和任务工作流设计上存在限制。

Method: V-Thinker包含一个数据进化飞轮（自动合成、进化和验证交互式推理数据集）和一个视觉渐进式训练课程（通过点级监督对齐感知，然后通过两阶段强化学习框架整合交互式推理）。此外，还引入了VTBench基准测试。

Result: V-Thinker在通用和交互式推理场景中始终优于强大的基于LMM的基线模型。

Conclusion: V-Thinker在推动图像交互式推理应用方面提供了有价值的见解，并展示了其在通用和交互式推理方面的优越性。

Abstract: Empowering Large Multimodal Models (LMMs) to deeply integrate image
interaction with long-horizon reasoning capabilities remains a long-standing
challenge in this field. Recent advances in vision-centric reasoning explore a
promising "Thinking with Images" paradigm for LMMs, marking a shift from
image-assisted reasoning to image-interactive thinking. While this milestone
enables models to focus on fine-grained image regions, progress remains
constrained by limited visual tool spaces and task-specific workflow designs.
To bridge this gap, we present V-Thinker, a general-purpose multimodal
reasoning assistant that enables interactive, vision-centric thinking through
end-to-end reinforcement learning. V-Thinker comprises two key components: (1)
a Data Evolution Flywheel that automatically synthesizes, evolves, and verifies
interactive reasoning datasets across three dimensions-diversity, quality, and
difficulty; and (2) a Visual Progressive Training Curriculum that first aligns
perception via point-level supervision, then integrates interactive reasoning
through a two-stage reinforcement learning framework. Furthermore, we introduce
VTBench, an expert-verified benchmark targeting vision-centric interactive
reasoning tasks. Extensive experiments demonstrate that V-Thinker consistently
outperforms strong LMM-based baselines in both general and interactive
reasoning scenarios, providing valuable insights for advancing
image-interactive reasoning applications.

</details>


### [49] [Landslide Hazard Mapping with Geospatial Foundation Models: Geographical Generalizability, Data Scarcity, and Band Adaptability](https://arxiv.org/abs/2511.04474)
*Wenwen Li,Sizhe Wang,Hyunho Lee,Chenyan Lu,Sujit Roy,Rahul Ramachandran,Chia-Yu Hsu*

Main category: cs.CV

TL;DR: GeoFMs在滑坡绘图方面表现优于传统模型，尤其是在传感器、标签和领域适应性方面。通过全局预训练、自监督学习和适应性微调，Prithvi-EO-2.0在各种条件下都显示出鲁棒性和准确性，尽管计算成本和数据可用性仍是挑战。


<details>
  <summary>Details</summary>
Motivation: 滑坡造成的严重破坏使得准确及时的滑坡绘图对于灾难准备和响应至关重要。然而，传统的深度学习模型在跨不同传感器、区域或数据量有限的情况下应用时，往往表现不佳。

Method: 提出一个传感器、标签和领域的三轴分析框架，用于适应地理空间基础模型（GeoFMs），重点是用于滑坡绘图的Prithvi-EO-2.0。该模型建立在全局预训练、自监督学习和适应性微调的基础上。

Result: Prithvi-EO-2.0在滑坡绘图任务中持续优于任务特定的CNN（U-Net, U-Net++）、视觉Transformer（Segformer, SwinV2-B）和其他GeoFMs（TerraMind, SatMAE）。该模型在光谱变化、标签稀缺和跨不同数据集及地理环境的泛化能力方面表现出鲁棒性。

Conclusion: GeoFMs为滑坡风险减少和环境监测提供了更鲁棒和可扩展的方法。尽管存在计算成本和数据可用性等挑战，但GeoFMs的优势表明了其在这一领域的重要作用。

Abstract: Landslides cause severe damage to lives, infrastructure, and the environment,
making accurate and timely mapping essential for disaster preparedness and
response. However, conventional deep learning models often struggle when
applied across different sensors, regions, or under conditions of limited
training data. To address these challenges, we present a three-axis analytical
framework of sensor, label, and domain for adapting geospatial foundation
models (GeoFMs), focusing on Prithvi-EO-2.0 for landslide mapping. Through a
series of experiments, we show that it consistently outperforms task-specific
CNNs (U-Net, U-Net++), vision transformers (Segformer, SwinV2-B), and other
GeoFMs (TerraMind, SatMAE). The model, built on global pretraining,
self-supervision, and adaptable fine-tuning, proved resilient to spectral
variation, maintained accuracy under label scarcity, and generalized more
reliably across diverse datasets and geographic settings. Alongside these
strengths, we also highlight remaining challenges such as computational cost
and the limited availability of reusable AI-ready training data for landslide
research. Overall, our study positions GeoFMs as a step toward more robust and
scalable approaches for landslide risk reduction and environmental monitoring.

</details>


### [50] [THEval. Evaluation Framework for Talking Head Video Generation](https://arxiv.org/abs/2511.04520)
*Nabyl Quignon,Baptiste Chopin,Yaohui Wang,Antitza Dantcheva*

Main category: cs.CV

TL;DR: 提出一个包含8个指标的新的评估框架，用于评估生成模型的性能，并公开数据集和代码。


<details>
  <summary>Details</summary>
Motivation: 目前的视频生成评估方法（包括通用视频质量、唇同步和用户研究）存在局限性，无法跟上生成技术的快速发展。

Method: 提出一个包含8个指标的新的评估框架，涵盖质量、自然度和同步性三个维度，并关注效率和与人类偏好的对齐。该框架通过分析头部、嘴部和眉毛的精细动态以及面部质量来评估。

Result: 在85,000个视频上进行的大规模实验表明，尽管许多模型在唇同步方面表现良好，但在生成表情和无伪影细节方面仍面临挑战。通过一个新整理的数据集进行评估，以减少训练数据偏差。

Conclusion: 提出的基准评估框架旨在评估生成方法的改进，并将公开代码、数据集和排行榜以反映该领域的进展。

Abstract: Video generation has achieved remarkable progress, with generated videos
increasingly resembling real ones. However, the rapid advance in generation has
outpaced the development of adequate evaluation metrics. Currently, the
assessment of talking head generation primarily relies on limited metrics,
evaluating general video quality, lip synchronization, and on conducting user
studies. Motivated by this, we propose a new evaluation framework comprising 8
metrics related to three dimensions (i) quality, (ii) naturalness, and (iii)
synchronization. In selecting the metrics, we place emphasis on efficiency, as
well as alignment with human preferences. Based on this considerations, we
streamline to analyze fine-grained dynamics of head, mouth, and eyebrows, as
well as face quality. Our extensive experiments on 85,000 videos generated by
17 state-of-the-art models suggest that while many algorithms excel in lip
synchronization, they face challenges with generating expressiveness and
artifact-free details. These videos were generated based on a novel real
dataset, that we have curated, in order to mitigate bias of training data. Our
proposed benchmark framework is aimed at evaluating the improvement of
generative methods. Original code, dataset and leaderboards will be publicly
released and regularly updated with new methods, in order to reflect progress
in the field.

</details>


### [51] [Learning from Single Timestamps: Complexity Estimation in Laparoscopic Cholecystectomy](https://arxiv.org/abs/2511.04525)
*Dimitrios Anastasiou,Santiago Barbarisi,Lucy Culshaw,Jayna Patel,Evangelos B. Mazomenos,Imanol Luengo,Danail Stoyanov*

Main category: cs.CV

TL;DR: STC-Net是一个用于分析完整腹腔镜胆囊切除术视频的新框架，可以自动评估手术复杂性，准确率达到62.11%，优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 腹腔镜胆囊切除术（LC）的手术复杂性评估至关重要，尤其是在炎症严重的情况下。虽然Parkland分级量表（PGS）是一个经过验证的框架，但其在完整手术视频中的自动化应用仍有待探索。

Method: 提出了一种名为STC-Net的新框架，该框架采用单一时间点进行LC复杂性评估，并能在弱时间监督下运行。STC-Net直接处理完整视频，通过定位、窗口提议和分级模块来同时进行时间定位和分级。该方法采用了一种结合硬、软定位目标和背景感知分级监督的新损失函数。

Result: 在包含1859个LC视频的私有数据集上，STC-Net的准确率为62.11%，F1分数为61.42%，在两个指标上均优于非定位基线10%以上，证明了弱监督在手术复杂性评估中的有效性。

Conclusion: STC-Net提供了一种可扩展且有效的方法，可从完整的LC视频中自动估算基于PGS的手术复杂性，在术后分析和手术培训方面具有应用前景。

Abstract: Purpose: Accurate assessment of surgical complexity is essential in
Laparoscopic Cholecystectomy (LC), where severe inflammation is associated with
longer operative times and increased risk of postoperative complications. The
Parkland Grading Scale (PGS) provides a clinically validated framework for
stratifying inflammation severity; however, its automation in surgical videos
remains largely unexplored, particularly in realistic scenarios where complete
videos must be analyzed without prior manual curation. Methods: In this work,
we introduce STC-Net, a novel framework for SingleTimestamp-based Complexity
estimation in LC via the PGS, designed to operate under weak temporal
supervision. Unlike prior methods limited to static images or manually trimmed
clips, STC-Net operates directly on full videos. It jointly performs temporal
localization and grading through a localization, window proposal, and grading
module. We introduce a novel loss formulation combining hard and soft
localization objectives and background-aware grading supervision. Results:
Evaluated on a private dataset of 1,859 LC videos, STC-Net achieves an accuracy
of 62.11% and an F1-score of 61.42%, outperforming non-localized baselines by
over 10% in both metrics and highlighting the effectiveness of weak supervision
for surgical complexity assessment. Conclusion: STC-Net demonstrates a scalable
and effective approach for automated PGS-based surgical complexity estimation
from full LC videos, making it promising for post-operative analysis and
surgical training.

</details>


### [52] [Thinking with Video: Video Generation as a Promising Multimodal Reasoning Paradigm](https://arxiv.org/abs/2511.04570)
*Jingqi Tong,Yurong Mou,Hangcheng Li,Mingzhe Li,Yongzhuo Yang,Ming Zhang,Qiguang Chen,Tianyi Liang,Xiaomeng Hu,Yining Zheng,Xinchi Chen,Jun Zhao,Xuanjing Huang,Xipeng Qiu*

Main category: cs.CV

TL;DR: 


<details>
  <summary>Details</summary>
Motivation: 现有的“以文本思考”和“以图像思考”范式在提升大语言模型（LLM）和视觉语言模型（VLM）的推理能力方面取得了显著成效，但存在局限性：图像无法捕捉动态过程或连续变化，且文本与视觉的分离阻碍了统一的多模态理解与生成。

Method: 提出“以视频思考”新范式，利用Sora-2等视频生成模型，在统一的时间框架内融合视觉与文本推理。开发了包含视觉中心任务（如Eyeballing Puzzles）和文本中心任务（如GSM8K、MMMU子集）的VideoThinkBench基准。系统分析了模型能力来源，并探索了自洽性和上下文学习的改进效果。

Result: Sora-2在视觉中心任务上表现与SOTA VLM相当，在Eyeballing Games等任务上甚至超越了VLM。在文本中心任务上，Sora-2在MATH上达到92%的准确率，在MMMU上达到75.53%的准确率。自洽性和上下文学习能进一步提升Sora-2的性能。

Conclusion: 视频生成模型有潜力成为统一的多模态理解与生成模型，“以视频思考”可作为统一的多模态推理范式。

Abstract: "Thinking with Text" and "Thinking with Images" paradigm significantly
improve the reasoning ability of large language models (LLMs) and Vision
Language Models (VLMs). However, these paradigms have inherent limitations. (1)
Images capture only single moments and fail to represent dynamic processes or
continuous changes, and (2) The separation of text and vision as distinct
modalities, hindering unified multimodal understanding and generation. To
overcome these limitations, we introduce "Thinking with Video", a new paradigm
that leverages video generation models, such as Sora-2, to bridge visual and
textual reasoning in a unified temporal framework. To support this exploration,
we developed the Video Thinking Benchmark (VideoThinkBench). VideoThinkBench
encompasses two task categories: (1) vision-centric tasks (e.g., Eyeballing
Puzzles), and (2) text-centric tasks (e.g., subsets of GSM8K, MMMU). Our
evaluation establishes Sora-2 as a capable reasoner. On vision-centric tasks,
Sora-2 is generally comparable to state-of-the-art (SOTA) VLMs, and even
surpasses VLMs on several tasks, such as Eyeballing Games. On text-centric
tasks, Sora-2 achieves 92% accuracy on MATH, and 75.53% accuracy on MMMU.
Furthermore, we systematically analyse the source of these abilities. We also
find that self-consistency and in-context learning can improve Sora-2's
performance. In summary, our findings demonstrate that the video generation
model is the potential unified multimodal understanding and generation model,
positions "thinking with video" as a unified multimodal reasoning paradigm.

</details>


### [53] [UniSplat: Unified Spatio-Temporal Fusion via 3D Latent Scaffolds for Dynamic Driving Scene Reconstruction](https://arxiv.org/abs/2511.04595)
*Chen Shi,Shaoshuai Shi,Xiaoyang Lyu,Chunyang Liu,Kehua Sheng,Bo Zhang,Li Jiang*

Main category: cs.CV

TL;DR: UniSplat是一个通用的前馈框架，通过统一的潜在时空融合学习动态场景重建，解决了稀疏、不重叠的摄像机视图和复杂场景动态性的挑战。


<details>
  <summary>Details</summary>
Motivation: 现有方法在处理稀疏、不重叠的摄像机视图和复杂的场景动态性方面存在困难。

Method: UniSplat构建了一个3D潜在支架，利用预训练的基础模型捕捉几何和语义场景上下文。通过在3D支架内进行高效的融合机制，将空间视图和时间帧的信息进行整合。设计了一个双分支解码器，通过结合点锚定细化和基于体素的生成，从融合的支架生成动态感知的高斯，并维护静态高斯的持久内存，以实现超出当前摄像机覆盖范围的流式场景完成。

Result: UniSplat在真实世界数据集上实现了最先进的新视角合成性能，即使对于原始摄像机覆盖范围之外的视点，也能提供鲁棒且高质量的渲染。

Conclusion: UniSplat能够实现高质量的动态场景重建，并能处理超出摄像机覆盖范围的场景。

Abstract: Feed-forward 3D reconstruction for autonomous driving has advanced rapidly,
yet existing methods struggle with the joint challenges of sparse,
non-overlapping camera views and complex scene dynamics. We present UniSplat, a
general feed-forward framework that learns robust dynamic scene reconstruction
through unified latent spatio-temporal fusion. UniSplat constructs a 3D latent
scaffold, a structured representation that captures geometric and semantic
scene context by leveraging pretrained foundation models. To effectively
integrate information across spatial views and temporal frames, we introduce an
efficient fusion mechanism that operates directly within the 3D scaffold,
enabling consistent spatio-temporal alignment. To ensure complete and detailed
reconstructions, we design a dual-branch decoder that generates dynamic-aware
Gaussians from the fused scaffold by combining point-anchored refinement with
voxel-based generation, and maintain a persistent memory of static Gaussians to
enable streaming scene completion beyond current camera coverage. Extensive
experiments on real-world datasets demonstrate that UniSplat achieves
state-of-the-art performance in novel view synthesis, while providing robust
and high-quality renderings even for viewpoints outside the original camera
coverage.

</details>


### [54] [PixCLIP: Achieving Fine-grained Visual Language Understanding via Any-granularity Pixel-Text Alignment Learning](https://arxiv.org/abs/2511.04601)
*Yicheng Xiao,Yu Chen,Haoxuan Ma,Jiale Hong,Caorui Li,Lingxiang Wu,Haiyun Guo,Jinqiao Wang*

Main category: cs.CV

TL;DR: PixCLIP是一个结合视觉提示和长文本描述的新框架，旨在提升图像-文本的细粒度对齐能力，并在像素级交互和长文本处理方面取得了SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 增强CLIP模型在细粒度图像-文本对齐方面的能力，并解决其文本编码器在处理长文本时的局限性。

Method: 1. 构建了一个自动标注流程，生成像素级定位的长文本描述，并创建了包含近150万个样本的数据集LongGRIT。2. 使用LLM替换CLIP的文本编码器，并提出了一个三分支像素-文本对齐学习框架。

Result: PixCLIP在像素级交互和长文本处理方面取得了突破，达到了SOTA性能。

Conclusion: PixCLIP通过结合视觉提示和长文本处理能力，显著提升了细粒度图像-文本对齐的性能。

Abstract: While the Contrastive Language-Image Pretraining(CLIP) model has achieved
remarkable success in a variety of downstream vison language understanding
tasks, enhancing its capability for fine-grained image-text alignment remains
an active research focus. To this end, most existing works adopt the strategy
of explicitly increasing the granularity of visual information processing,
e.g., incorporating visual prompts to guide the model focus on specific local
regions within the image. Meanwhile, researches on Multimodal Large Language
Models(MLLMs) have demonstrated that training with long and detailed textual
descriptions can effectively improve the model's fine-grained vision-language
alignment. However, the inherent token length limitation of CLIP's text encoder
fundamentally limits CLIP to process more granular textual information embedded
in long text sequences. To synergistically leverage the advantages of enhancing
both visual and textual content processing granularity, we propose PixCLIP, a
novel framework designed to concurrently accommodate visual prompt inputs and
process lengthy textual descriptions. Specifically, we first establish an
automated annotation pipeline capable of generating pixel-level localized,
long-form textual descriptions for images. Utilizing this pipeline, we
construct LongGRIT, a high-quality dataset comprising nearly 1.5 million
samples. Secondly, we replace CLIP's original text encoder with the LLM and
propose a three-branch pixel-text alignment learning framework, facilitating
fine-grained alignment between image regions and corresponding textual
descriptions at arbitrary granularity. Experiments demonstrate that PixCLIP
showcases breakthroughs in pixel-level interaction and handling long-form
texts, achieving state-of-the-art performance.

</details>


### [55] [Building Trust in Virtual Immunohistochemistry: Automated Assessment of Image Quality](https://arxiv.org/abs/2511.04615)
*Tushar Kataria,Shikha Dubey,Mary Bronner,Jolanta Jedrzkiewicz,Ben J. Brintz,Shireen Y. Elhabian,Beatrice S. Knudsen*

Main category: cs.CV

TL;DR: 生成虚拟IHC染色图像的框架，评估标准超越传统保真度指标，并强调WSI级评估的重要性。


<details>
  <summary>Details</summary>
Motivation: 现有评估虚拟IHC染色图像质量的方法（基于纹理和分布）无法准确量化IHC染色的准确性，而研究者需要一种能够直接评估染色准确性的方法。

Method: 提出一个自动化的、基于准确性的框架，利用颜色反卷积生成IHC阳性（棕色）像素的掩码，并计算分割掩码与真实IHC图像之间的各项指标（Dice, IoU, Hausdorff距离），以评估像素级标记的准确性。

Result: 研究发现，传统的图像保真度指标（FID, PSNR, SSIM）与实际染色准确性相关性很差。成对模型（如PyramidPix2Pix和AdaptiveNCE）在染色准确性方面表现最佳，而非成对的扩散模型和GAN模型则效果较差。在整张幻灯片（WSI）图像层面评估时，模型性能下降，这在基于图像块的评估中是看不见的。

Conclusion: 该框架提供了一种可重复的方法来评估虚拟IHC模型的质量，这对加速虚拟IHC模型在病理学日常应用至关重要。

Abstract: Deep learning models can generate virtual immunohistochemistry (IHC) stains
from hematoxylin and eosin (H&E) images, offering a scalable and low-cost
alternative to laboratory IHC. However, reliable evaluation of image quality
remains a challenge as current texture- and distribution-based metrics quantify
image fidelity rather than the accuracy of IHC staining. Here, we introduce an
automated and accuracy grounded framework to determine image quality across
sixteen paired or unpaired image translation models. Using color deconvolution,
we generate masks of pixels stained brown (i.e., IHC-positive) as predicted by
each virtual IHC model. We use the segmented masks of real and virtual IHC to
compute stain accuracy metrics (Dice, IoU, Hausdorff distance) that directly
quantify correct pixel - level labeling without needing expert manual
annotations. Our results demonstrate that conventional image fidelity metrics,
including Frechet Inception Distance (FID), peak signal-to-noise ratio (PSNR),
and structural similarity (SSIM), correlate poorly with stain accuracy and
pathologist assessment. Paired models such as PyramidPix2Pix and AdaptiveNCE
achieve the highest stain accuracy, whereas unpaired diffusion- and GAN-based
models are less reliable in providing accurate IHC positive pixel labels.
Moreover, whole-slide images (WSI) reveal performance declines that are
invisible in patch-based evaluations, emphasizing the need for WSI-level
benchmarks. Together, this framework defines a reproducible approach for
assessing the quality of virtual IHC models, a critical step to accelerate
translation towards routine use by pathologists.

</details>


### [56] [NovisVQ: A Streaming Convolutional Neural Network for No-Reference Opinion-Unaware Frame Quality Assessment](https://arxiv.org/abs/2511.04628)
*Kylie Cancilla,Alexander Moore,Amar Saini,Carmen Carrano*

Main category: cs.CV

TL;DR: 本研究提出了一种无需参考视频且不依赖人类评分标签的可扩展、流式视频质量评估（VQA）模型，该模型利用合成退化数据和时间感知卷积架构，直接从退化视频预测全参考（FR）指标，并优于基于图像的方法和现有的无参考（NR）方法。


<details>
  <summary>Details</summary>
Motivation: 现有的视频质量评估（VQA）方法存在局限性：全参考（FR）指标需要参考视频，而大多数无参考（NR）模型依赖昂贵的人类评分标签。此外，许多不考虑评分的NR方法是基于图像的，忽略了对视频对象检测至关重要的时间上下文。

Method: 利用合成退化的大卫数据集（DAVIS dataset），训练了一个时间感知的卷积架构，在推理时无需参考即可直接从退化视频预测FR指标（LPIPS, PSNR, SSIM）。

Result: 该流式方法在泛化到各种退化方面优于基于图像的基线，证明了时间建模对于可扩展VQA的价值。此外，与广泛使用的基于评分的图像质量评估基线BRISQUE相比，该模型与FR指标的相关性更高。

Conclusion: 所提出的时间感知、不考虑评分的VQA模型能够有效且可扩展地评估视频质量，无需参考视频或人类评分，在实际视觉系统中具有广泛的应用前景。

Abstract: Video quality assessment (VQA) is vital for computer vision tasks, but
existing approaches face major limitations: full-reference (FR) metrics require
clean reference videos, and most no-reference (NR) models depend on training on
costly human opinion labels. Moreover, most opinion-unaware NR methods are
image-based, ignoring temporal context critical for video object detection. In
this work, we present a scalable, streaming-based VQA model that is both
no-reference and opinion-unaware. Our model leverages synthetic degradations of
the DAVIS dataset, training a temporal-aware convolutional architecture to
predict FR metrics (LPIPS , PSNR, SSIM) directly from degraded video, without
references at inference. We show that our streaming approach outperforms our
own image-based baseline by generalizing across diverse degradations,
underscoring the value of temporal modeling for scalable VQA in real-world
vision systems. Additionally, we demonstrate that our model achieves higher
correlation with full-reference metrics compared to BRISQUE, a widely-used
opinion-aware image quality assessment baseline, validating the effectiveness
of our temporal, opinion-unaware approach.

</details>


### [57] [Polarization-resolved imaging improves eye tracking](https://arxiv.org/abs/2511.04652)
*Mantas Žurauskas,Tom Bu,Sanaz Alali,Beyza Kalkanli,Derek Shi,Fernando Alamos,Gauresh Pandit,Christopher Mei,Ali Behrooz,Ramin Mirjalili,Dave Stronks,Alexander Fix,Dmitri Model*

Main category: cs.CV

TL;DR: 通过偏振成像技术，可以增强眼球追踪的对比度，并能在眼睑遮挡、眼部移位和瞳孔大小变化等情况下提高追踪精度。


<details>
  <summary>Details</summary>
Motivation: 为了在眼球追踪中引入新的光学对比度机制，利用偏振态来测量眼部组织的反射光。

Method: 使用偏振滤光片阵列相机和线偏振近红外照明器，结合卷积神经网络进行机器学习训练，以实现偏振眼球追踪（PET）。

Result: 与仅使用强度信息的基线相比，PET系统将中值95%绝对注视误差降低了10-16%，并且在有遮挡、眼部移位和瞳孔大小变化的情况下仍然有效。

Conclusion: 偏振成像技术在眼球追踪中具有实际应用价值，可以提高人机交互的性能，并有望成为未来可穿戴设备的一种简单、鲁棒的传感方式。

Abstract: Polarization-resolved near-infrared imaging adds a useful optical contrast
mechanism to eye tracking by measuring the polarization state of light
reflected by ocular tissues in addition to its intensity. In this paper we
demonstrate how this contrast can be used to enable eye tracking. Specifically,
we demonstrate that a polarization-enabled eye tracking (PET) system composed
of a polarization--filter--array camera paired with a linearly polarized
near-infrared illuminator can reveal trackable features across the sclera and
gaze-informative patterns on the cornea, largely absent in intensity-only
images. Across a cohort of 346 participants, convolutional neural network based
machine learning models trained on data from PET reduced the median
95th-percentile absolute gaze error by 10--16\% relative to capacity-matched
intensity baselines under nominal conditions and in the presence of eyelid
occlusions, eye-relief changes, and pupil-size variation. These results link
light--tissue polarization effects to practical gains in human--computer
interaction and position PET as a simple, robust sensing modality for future
wearable devices.

</details>


### [58] [Benchmark Designers Should "Train on the Test Set" to Expose Exploitable Non-Visual Shortcuts](https://arxiv.org/abs/2511.04655)
*Ellis Brown,Jihan Yang,Shusheng Yang,Rob Fergus,Saining Xie*

Main category: cs.CV

TL;DR: 模型可以通过利用偏差、语言先验和表面模式在多模态基准测试中取得好成绩，而不是依靠真正的视觉理解。本研究提出了一种诊断原则，用于设计能够识别和减轻非视觉偏差的基准测试。


<details>
  <summary>Details</summary>
Motivation: 现有基准测试未能有效评估多模态大型语言模型（MLLMs）的真实视觉理解能力，模型可以通过利用偏差、语言先验和表面模式来“欺骗”测试。

Method: 提出了一种诊断原则，通过“测试集压力测试”（TsT）方法诊断基准测试的偏差，并使用“迭代偏差修剪”（IBP）程序来消除偏差。TsT包括使用k折交叉验证在仅包含非视觉文本输入的测试集上微调大型语言模型，以揭示捷径性能并为每个样本分配偏差分数。还使用基于随机森林的诊断工具进行审计。IBP通过过滤高偏差样本来消除偏差。

Result: 在四个基准测试（VSI-Bench、CV-Bench、MMMU和VideoMME）上发现了普遍存在的非视觉偏差。通过应用该框架创建了VSI-Bench-Debiased，该基准测试的非视觉可解性降低，并且视觉-盲性能差距比原始基准测试更大。

Conclusion: 现有的多模态基准测试存在普遍的非视觉偏差，这使得模型能够在没有真正视觉理解的情况下取得好成绩。提出的诊断和去偏方法可以有效地识别和减轻这些偏差，从而创建更可靠的基准测试。

Abstract: Robust benchmarks are crucial for evaluating Multimodal Large Language Models
(MLLMs). Yet we find that models can ace many multimodal benchmarks without
strong visual understanding, instead exploiting biases, linguistic priors, and
superficial patterns. This is especially problematic for vision-centric
benchmarks that are meant to require visual inputs. We adopt a diagnostic
principle for benchmark design: if a benchmark can be gamed, it will be.
Designers should therefore try to ``game'' their own benchmarks first, using
diagnostic and debiasing procedures to systematically identify and mitigate
non-visual biases. Effective diagnosis requires directly ``training on the test
set'' -- probing the released test set for its intrinsic, exploitable patterns.
  We operationalize this standard with two components. First, we diagnose
benchmark susceptibility using a ``Test-set Stress-Test'' (TsT) methodology.
Our primary diagnostic tool involves fine-tuning a powerful Large Language
Model via $k$-fold cross-validation on exclusively the non-visual, textual
inputs of the test set to reveal shortcut performance and assign each sample a
bias score $s(x)$. We complement this with a lightweight Random Forest-based
diagnostic operating on hand-crafted features for fast, interpretable auditing.
Second, we debias benchmarks by filtering high-bias samples using an
``Iterative Bias Pruning'' (IBP) procedure. Applying this framework to four
benchmarks -- VSI-Bench, CV-Bench, MMMU, and VideoMME -- we uncover pervasive
non-visual biases. As a case study, we apply our full framework to create
VSI-Bench-Debiased, demonstrating reduced non-visual solvability and a wider
vision-blind performance gap than the original.

</details>


### [59] [SIMS-V: Simulated Instruction-Tuning for Spatial Video Understanding](https://arxiv.org/abs/2511.04668)
*Ellis Brown,Arijit Ray,Ranjay Krishna,Ross Girshick,Rob Fergus,Saining Xie*

Main category: cs.CV

TL;DR: SIMS-V是一个数据生成框架，利用3D模拟器生成用于多模态语言模型的空间视频训练数据，通过系统消融研究，确定了三种最有效的空间推理问题类型（度量测量、视角依赖推理和时间跟踪），并证明了其在真实世界空间推理任务上的有效性。


<details>
  <summary>Details</summary>
Motivation: 当前多模态语言模型在视频的空间推理方面存在不足，而真实世界的视频数据获取困难且标注成本高。

Method: 提出SIMS-V数据生成框架，利用3D模拟器的特权信息生成空间丰富的视频训练数据，并通过系统消融研究（问题类型、组合和规模）来分析模拟数据特性对真实世界迁移的有效性。

Result: 识别出度量测量、视角依赖推理和时间跟踪这三种问题类型对于培养可迁移的空间智能最为有效，并且在仅使用25K模拟样本的情况下，通过微调的7B参数视频语言模型在真实世界空间推理基准上取得了优于72B基线模型和与专有模型相当的性能。

Conclusion: SIMS-V框架能够高效地训练出在真实世界空间推理任务上表现优越且泛化能力强的模型，为解决多模态语言模型在空间理解方面的挑战提供了新的途径。

Abstract: Despite impressive high-level video comprehension, multimodal language models
struggle with spatial reasoning across time and space. While current spatial
training approaches rely on real-world video data, obtaining diverse footage
with precise spatial annotations remains a bottleneck. To alleviate this
bottleneck, we present SIMS-V -- a systematic data-generation framework that
leverages the privileged information of 3D simulators to create spatially-rich
video training data for multimodal language models. Using this framework, we
investigate which properties of simulated data drive effective real-world
transfer through systematic ablations of question types, mixes, and scales. We
identify a minimal set of three question categories (metric measurement,
perspective-dependent reasoning, and temporal tracking) that prove most
effective for developing transferable spatial intelligence, outperforming
comprehensive coverage despite using fewer question types. These insights
enable highly efficient training: our 7B-parameter video LLM fine-tuned on just
25K simulated examples outperforms the larger 72B baseline and achieves
competitive performance with proprietary models on rigorous real-world spatial
reasoning benchmarks. Our approach demonstrates robust generalization,
maintaining performance on general video understanding while showing
substantial improvements on embodied and real-world spatial tasks.

</details>


### [60] [Cambrian-S: Towards Spatial Supersensing in Video](https://arxiv.org/abs/2511.04670)
*Shusheng Yang,Jihan Yang,Pinzhi Huang,Ellis Brown,Zihao Yang,Yue Yu,Shengbang Tong,Zihan Zheng,Yifan Xu,Muhan Wang,Daohan Lu,Rob Fergus,Yann LeCun,Li Fei-Fei,Saining Xie*

Main category: cs.CV

TL;DR: 本篇论文认为，要实现真正的多模态智能，需要从被动的、任务驱动的系统和蛮力的长上下文转向更广泛的超级感知范式，特别是空间超级感知，并提出了VSI-SUPER基准和一种名为预测感知的新方法。


<details>
  <summary>Details</summary>
Motivation: 当前的多模态智能研究主要集中在反应式、任务驱动的系统和长上下文处理上，而忽略了更广泛的超级感知能力，特别是在空间理解方面，这阻碍了真正多模态智能的发展。

Method: 提出了空间超级感知的四个阶段：语义感知、流式事件认知、隐式3D空间认知和预测世界模型。设计了VSI-SUPER基准，包括VSR（长视域视觉空间回忆）和VSC（持续视觉空间计数）两个任务。通过Curating VSI-590K和训练Cambrian-S模型来测试数据缩放的极限。提出了一种预测感知的方法，利用自监督的下一潜在帧预测器和惊喜（预测误差）来驱动记忆和事件分割。

Result: Cambrian-S模型在VSI-Bench上取得了+30%的绝对提升，但VSI-SUPER上的表现仍然有限，表明仅靠规模不足以实现空间超级感知。预测感知方法在VSI-SUPER上显著优于领先的专有基线。

Conclusion: 真正的空间超级感知不仅需要模型能够观察，还需要它们能够预测、选择和组织经验。预测感知是一种有前景的解决方向，能够推动多模态智能的发展。

Abstract: We argue that progress in true multimodal intelligence calls for a shift from
reactive, task-driven systems and brute-force long context towards a broader
paradigm of supersensing. We frame spatial supersensing as four stages beyond
linguistic-only understanding: semantic perception (naming what is seen),
streaming event cognition (maintaining memory across continuous experiences),
implicit 3D spatial cognition (inferring the world behind pixels), and
predictive world modeling (creating internal models that filter and organize
information). Current benchmarks largely test only the early stages, offering
narrow coverage of spatial cognition and rarely challenging models in ways that
require true world modeling. To drive progress in spatial supersensing, we
present VSI-SUPER, a two-part benchmark: VSR (long-horizon visual spatial
recall) and VSC (continual visual spatial counting). These tasks require
arbitrarily long video inputs yet are resistant to brute-force context
expansion. We then test data scaling limits by curating VSI-590K and training
Cambrian-S, achieving +30% absolute improvement on VSI-Bench without
sacrificing general capabilities. Yet performance on VSI-SUPER remains limited,
indicating that scale alone is insufficient for spatial supersensing. We
propose predictive sensing as a path forward, presenting a proof-of-concept in
which a self-supervised next-latent-frame predictor leverages surprise
(prediction error) to drive memory and event segmentation. On VSI-SUPER, this
approach substantially outperforms leading proprietary baselines, showing that
spatial supersensing requires models that not only see but also anticipate,
select, and organize experience.

</details>


### [61] [InfinityStar: Unified Spacetime AutoRegressive Modeling for Visual Generation](https://arxiv.org/abs/2511.04675)
*Jinlai Liu,Jian Han,Bin Yan,Hui Wu,Fengda Zhu,Xing Wang,Yi Jiang,Bingyue Peng,Zehuan Yuan*

Main category: cs.CV

TL;DR: InfinityStar是一个统一的时空自回归框架，用于高分辨率图像和动态视频合成。它能够通过单一架构同时处理空间和时间依赖性，支持文本到图像、文本到视频、图像到视频以及长交互式视频合成等多种生成任务。该模型在VBench上得分83.74，优于其他自回归模型，并能与部分扩散模型竞争。此外，InfinityStar在生成5秒720p视频时速度比领先的扩散模型快10倍，并且是首个能够生成工业级720p视频的离散自回归视频生成器。


<details>
  <summary>Details</summary>
Motivation: 在视觉和语言领域自回归建模取得成功的背景下，需要一个统一的框架来处理高分辨率图像和动态视频合成，并能高效地捕捉时空依赖性。

Method: 提出了一种名为InfinityStar的统一时空自回归框架，该框架采用纯离散方法，在单一架构内联合捕捉空间和时间依赖性，通过直接的时间自回归支持多种生成任务。

Result: InfinityStar在VBench上获得83.74分，超越了所有自回归模型，并优于HunyuanVideo等扩散模型。在没有额外优化的情况下，生成5秒720p视频的速度比领先的扩散模型快约10倍。

Conclusion: InfinityStar是首个能够生成工业级720p视频的离散自回归视频生成器，证明了其在高效、高质量视频生成方面的潜力，并计划公开所有代码和模型以促进该领域的研究。

Abstract: We introduce InfinityStar, a unified spacetime autoregressive framework for
high-resolution image and dynamic video synthesis. Building on the recent
success of autoregressive modeling in both vision and language, our purely
discrete approach jointly captures spatial and temporal dependencies within a
single architecture. This unified design naturally supports a variety of
generation tasks such as text-to-image, text-to-video, image-to-video, and long
interactive video synthesis via straightforward temporal autoregression.
Extensive experiments demonstrate that InfinityStar scores 83.74 on VBench,
outperforming all autoregressive models by large margins, even surpassing some
diffusion competitors like HunyuanVideo. Without extra optimizations, our model
generates a 5s, 720p video approximately 10x faster than leading
diffusion-based methods. To our knowledge, InfinityStar is the first discrete
autoregressive video generator capable of producing industrial level 720p
videos. We release all code and models to foster further research in efficient,
high-quality video generation.

</details>


### [62] [Tracking and Understanding Object Transformations](https://arxiv.org/abs/2511.04678)
*Yihong Sun,Xinyu Yang,Jennifer J. Sun,Bharath Hariharan*

Main category: cs.CV

TL;DR: 该论文介绍了Track Any State (TAS)任务，旨在解决目标在经历状态变换后外观发生显著变化导致跟踪失败的问题。为此，作者提出了TubeletGraph系统，该系统能够检测和描述状态变化，并在变换后恢复丢失的目标，同时构建描述状态演变的图谱。


<details>
  <summary>Details</summary>
Motivation: 现有跟踪方法在目标经历外观的显著变化（如物体被切割、蝴蝶破茧而出）后，常常会丢失目标，无法实现对其状态变化的跟踪。

Method: 提出TubeletGraph零样本系统，识别被忽略的跟踪，并基于语义和邻近性先验判断是否整合；然后对添加的跟踪进行推理，生成描述状态演变的图谱，以解决目标在变换后丢失的问题。

Result: TubeletGraph在经历状态变换的情况下达到了最先进的跟踪性能，并展示了对物体状态变换的更深层次的理解，以及在时间定位和语义推理方面的潜力。

Conclusion: TubeletGraph作为一个零样本系统，能够有效地跟踪经历状态变换的目标，并理解和描述其状态演变过程，为解决复杂物体变换的跟踪问题提供了新的方法和数据集。

Abstract: Real-world objects frequently undergo state transformations. From an apple
being cut into pieces to a butterfly emerging from its cocoon, tracking through
these changes is important for understanding real-world objects and dynamics.
However, existing methods often lose track of the target object after
transformation, due to significant changes in object appearance. To address
this limitation, we introduce the task of Track Any State: tracking objects
through transformations while detecting and describing state changes,
accompanied by a new benchmark dataset, VOST-TAS. To tackle this problem, we
present TubeletGraph, a zero-shot system that recovers missing objects after
transformation and maps out how object states are evolving over time.
TubeletGraph first identifies potentially overlooked tracks, and determines
whether they should be integrated based on semantic and proximity priors. Then,
it reasons about the added tracks and generates a state graph describing each
observed transformation. TubeletGraph achieves state-of-the-art tracking
performance under transformations, while demonstrating deeper understanding of
object transformations and promising capabilities in temporal grounding and
semantic reasoning for complex object transformations. Code, additional
results, and the benchmark dataset are available at
https://tubelet-graph.github.io.

</details>


### [63] [Carousel: A High-Resolution Dataset for Multi-Target Automatic Image Cropping](https://arxiv.org/abs/2511.04680)
*Rafe Loya,Andrew Hamara,Benjamin Estell,Benjamin Kilpatrick,Andrew C. Freeman*

Main category: cs.CV

TL;DR: 本文提出了一种自动图像裁剪方法，旨在生成多个具有美学吸引力的不同裁剪区域，以满足现代社交媒体应用的需求。


<details>
  <summary>Details</summary>
Motivation: 现代社交媒体应用需要生成多个、具有美学吸引力的不同图像裁剪区域，而现有技术主要集中在生成单一裁剪区域。

Method: 本研究引入了一个包含277张图像和人工标注的数据集，并评估了将图像分割算法作为预处理步骤，应用于几个单一裁剪模型的效果。

Result: 实验评估了在单一裁剪模型应用图像分割算法作为预处理步骤的效果。

Conclusion: 本文的研究为解决生成多个、具有美学吸引力的不同图像裁剪区域的问题提供了新的数据集和评估方法。

Abstract: Automatic image cropping is a method for maximizing the human-perceived
quality of cropped regions in photographs. Although several works have proposed
techniques for producing singular crops, little work has addressed the problem
of producing multiple, distinct crops with aesthetic appeal. In this paper, we
motivate the problem with a discussion on modern social media applications,
introduce a dataset of 277 relevant images and human labels, and evaluate the
efficacy of several single-crop models with an image partitioning algorithm as
a pre-processing step. The dataset is available at
https://github.com/RafeLoya/carousel.

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [64] [Activation-Space Personality Steering: Hybrid Layer Selection for Stable Trait Control in LLMs](https://arxiv.org/abs/2511.03738)
*Pranav Bhandari,Nicolas Fay,Sanjeevan Selvaganapathy,Amitava Datta,Usman Naseem,Mehwish Nasim*

Main category: cs.CL

TL;DR: LLMs具有隐式个性，但难以控制。本文提出一种新方法，通过提取Transformer层的隐藏状态激活，利用大五人格特质来识别和控制LLMs的个性。


<details>
  <summary>Details</summary>
Motivation: 目前缺乏有效的方法来控制和对齐大型语言模型（LLM）的生成行为，以满足特定需求。理解心理特质在LLM中的表征及其应用对于实现这一目标至关重要。

Method: 提出一种新颖的流程，使用大五人格特质（开放性、尽责性、外向性、宜人性、神经质）从Transformer层提取隐藏状态激活，应用低秩子空间发现方法，并识别跨不同模型架构的特定于特质的最优层进行注入。然后，通过灵活的控制框架和动态层选择来实现个性对齐的方向，从而精确控制LLM输出中的特质表达。

Result: 研究发现，人格特质占据低秩共享子空间，并且可以通过仔细的扰动将这些潜在结构转化为可操作的机制，从而实现有效的控制，同时不影响LLM的流畅性、方差和通用能力。

Conclusion: 本文提出的方法能够有效地控制LLM的个性表达，弥合心理学理论与实际模型对齐之间的差距。

Abstract: Large Language Models exhibit implicit personalities in their generation, but
reliably controlling or aligning these traits to meet specific needs remains an
open challenge. The need for effective mechanisms for behavioural manipulation
of the model during generation is a critical gap in the literature that needs
to be fulfilled. Personality-aware LLMs hold a promising direction towards this
objective. However, the relationship between these psychological constructs and
their representations within LLMs remains underexplored and requires further
investigation. Moreover, it is intriguing to understand and study the use of
these representations to steer the models' behaviour. We propose a novel
pipeline that extracts hidden state activations from transformer layers using
the Big Five Personality Traits (Openness, Conscientiousness, Extraversion,
Agreeableness and Neuroticism), which is a comprehensive and empirically
validated framework to model human personality applies low-rank subspace
discovery methods, and identifies trait-specific optimal layers across
different model architectures for robust injection. The resulting
personality-aligned directions are then operationalised through a flexible
steering framework with dynamic layer selection, enabling precise control of
trait expression in LLM outputs. Our findings reveal that personality traits
occupy a low-rank shared subspace, and that these latent structures can be
transformed into actionable mechanisms for effective steering through careful
perturbations without impacting the fluency, variance and general capabilities,
helping to bridge the gap between psychological theory and practical model
alignment.

</details>


### [65] [TextualVerifier: Verify TextGrad Step-by-Step](https://arxiv.org/abs/2511.03739)
*Eugenius Mario Situmorang,Adila Alfa Krisnadhi,Ari Wibisono*

Main category: cs.CL

TL;DR: TextualVerifier是一个用于TextGrad的LLM驱动的自验证框架，通过链式思考和多数投票来提高文本推理的准确性，并在多个基准测试中取得了显著的改进。


<details>
  <summary>Details</summary>
Motivation: 现有的TextGrad方法缺乏确保文本推理有效性的自验证机制。

Method: TextualVerifier框架采用链式思考分解、变体生成、多数投票和共识聚合的工作流程，并能非侵入性地集成到TextGrad中。

Result: TextualVerifier在PRM800K基准测试中独立使用时，将推理步骤的有效性提高了29%。与TextGrad集成后，在GPQA-Diamond、MMLU-ML和MMLU-CP基准测试中，准确率得到了2.2个百分点的提升，同时LLM调用开销适中。单独的TextualVerifier版本在GPQA、MMLU-ML和MMLU-CP上分别带来了8.08%、10.71%和3.92%的准确率提升。

Conclusion: TextualVerifier是首个用于TextGrad的、不依赖于数值梯度且基于LLM的自验证框架，提高了文本推理的可靠性，并为文本优化领域的验证开辟了新方向。

Abstract: TextGrad is a novel approach to text-based automatic differentiation that
enables composite AI systems to perform optimization without explicit numerical
equations. However, it currently lacks self-verification mechanisms that ensure
reasoning validity in text-based decision making. This research introduces
TextualVerifier, a verification framework that leverages chain-of-thought
reasoning and majority voting with large language models to address this
verification gap. TextualVerifier implements a four-stage workflow:
chain-of-thought decomposition, variant generation, majority voting, and
consensus aggregation. It integrates non-invasively with TextGrad at both the
loss function and optimization result verification stages. Experimental
evaluation using the Gemini 1.5 Pro model is conducted in two phases: (1)
standalone evaluation on PRM800K, and (2) integrated evaluation with TextGrad
on GPQA-Diamond, MMLU-ML, and MMLU-CP benchmarks. Results show statistically
significant improvements (p < 0.001). In phase one, TextualVerifier improves
the validity of reasoning steps by 29 percent. In phase two, integration into
TextGrad loss function yields a 2.2 percentage point gain from 68.2 to 70.4
percent with a moderate overhead of 5.9 LLM calls on average. Further
evaluations of TextualVerifier versioning yield 8.08, 10.71, and 3.92
percentage point improvements on GPQA, MMLU-ML, and MMLU-CP respectively.
TextualVerifier thus presents the first self-verification framework for
TextGrad through LLM-based techniques without requiring numerical gradients,
enabling more reliable reasoning and opening new directions for verification in
text-based optimization.

</details>


### [66] [Computational Turing Test Reveals Systematic Differences Between Human and AI Language](https://arxiv.org/abs/2511.04195)
*Nicolò Pagan,Petter Törnberg,Christopher A. Bail,Anikó Hannák,Christopher Barrie*

Main category: cs.CL

TL;DR: LLMs在社会科学中的应用仍需验证，现有评估方法存在缺陷。本文提出计算图灵测试框架，并对比测试了九种LLM在真实社交数据上的表现，发现其输出与人类文本仍有显著差异，尤其在情感表达方面。优化人类相似性可能牺牲语义保真度。


<details>
  <summary>Details</summary>
Motivation: 现有LLM在社会科学中模拟人类行为的假设未经充分检验，依赖人类判断的评估方法不准确，导致缺乏可靠的评估工具和校准模型的方法。

Method: 提出一个计算图灵测试框架，结合BERT可探测性、语义相似性、风格标记和主题模式等指标，评估LLM的文本接近人类语言的程度。对比测试了九种开源LLM在X、Bluesky和Reddit上的五种校准策略。

Result: 即使经过校准，LLM的输出在情感语气和表达方面与人类文本仍有显著区别。指令微调模型表现不如基础模型，模型规模增大不一定能提升人类相似性。优化人类相似性会牺牲语义保真度，反之亦然。

Conclusion: 本文提出的可扩展验证和校准框架有助于LLM模拟研究，但其在捕捉人类沟通方面仍存在局限性，应谨慎使用。

Abstract: Large language models (LLMs) are increasingly used in the social sciences to
simulate human behavior, based on the assumption that they can generate
realistic, human-like text. Yet this assumption remains largely untested.
Existing validation efforts rely heavily on human-judgment-based evaluations --
testing whether humans can distinguish AI from human output -- despite evidence
that such judgments are blunt and unreliable. As a result, the field lacks
robust tools for assessing the realism of LLM-generated text or for calibrating
models to real-world data. This paper makes two contributions. First, we
introduce a computational Turing test: a validation framework that integrates
aggregate metrics (BERT-based detectability and semantic similarity) with
interpretable linguistic features (stylistic markers and topical patterns) to
assess how closely LLMs approximate human language within a given dataset.
Second, we systematically compare nine open-weight LLMs across five calibration
strategies -- including fine-tuning, stylistic prompting, and context retrieval
-- benchmarking their ability to reproduce user interactions on X (formerly
Twitter), Bluesky, and Reddit. Our findings challenge core assumptions in the
literature. Even after calibration, LLM outputs remain clearly distinguishable
from human text, particularly in affective tone and emotional expression.
Instruction-tuned models underperform their base counterparts, and scaling up
model size does not enhance human-likeness. Crucially, we identify a trade-off:
optimizing for human-likeness often comes at the cost of semantic fidelity, and
vice versa. These results provide a much-needed scalable framework for
validation and calibration in LLM simulations -- and offer a cautionary note
about their current limitations in capturing human communication.

</details>


### [67] [GRDD+: An Extended Greek Dialectal Dataset with Cross-Architecture Fine-tuning Evaluation](https://arxiv.org/abs/2511.03772)
*Stergios Chatzikyriakidis,Dimitris Papadakis,Sevasti-Ioanna Papaioannou,Erofili Psaltaki*

Main category: cs.CL

TL;DR: 提出了一个扩展的希腊方言数据集（GRDD+），包含了更多来自克里特、塞浦路斯、本都和北希腊的数据，并新增了六种方言：希腊-科西嘉、格里科（南意大利希腊）、马尼奥特、海普塔尼西亚、察科尼亚和卡塔雷武萨希腊。该数据集包含10种方言，总词汇量达6,374,939个词，是目前为止规模和多样性最大的此类数据集。通过对三种模型架构（Llama-3-8B、Llama-3.1-8B、Krikri-8B）进行微调实验，评估了高质量方言数据对大型语言模型的影响，并与现有模型（Claude-3.7-Sonnet、Gemini-2.5、ChatGPT-5）进行了比较。


<details>
  <summary>Details</summary>
Motivation: 现有的希腊方言数据集GRDD规模有限，为了更全面地研究希腊方言的多样性及其对大型语言模型的影响，需要构建一个更大、更多样化的数据集。

Method: 收集并整合了来自克里特、塞浦路斯、本都、北希腊的现有数据，并新增了希腊-科西嘉、格里科、马尼奥特、海普塔尼西亚、察科尼亚和卡塔雷武萨希腊六种新的希腊方言数据，构建了GRDD+数据集。随后，使用GRDD+数据集对Llama-3-8B、Llama-3.1-8B和Krikri-8B三种模型架构进行了微调，并与Claude-3.7-Sonnet、Gemini-2.5和ChatGPT-5等前沿模型进行了性能比较。

Result: 构建了一个包含10种希腊方言、总计6,374,939个词的GRDD+数据集。实验表明，高质量的方言数据能够有效提升大型语言模型的性能，具体提升效果在不同模型架构上有所差异。

Conclusion: GRDD+数据集的构建为希腊方言研究和相关模型的开发提供了重要的资源。高质量的方言数据对提升大型语言模型处理和理解多样化语言变体的能力至关重要。

Abstract: We present an extended Greek Dialectal Dataset (GRDD+) 1that complements the
existing GRDD dataset with more data from Cretan, Cypriot, Pontic and Northern
Greek, while we add six new varieties: Greco-Corsican, Griko (Southern Italian
Greek), Maniot, Heptanesian, Tsakonian, and Katharevusa Greek. The result is a
dataset with total size 6,374,939 words and 10 varieties. This is the first
dataset with such variation and size to date. We conduct a number of
fine-tuning experiments to see the effect of good quality dialectal data on a
number of LLMs. We fine-tune three model architectures (Llama-3-8B,
Llama-3.1-8B, Krikri-8B) and compare the results to frontier models
(Claude-3.7-Sonnet, Gemini-2.5, ChatGPT-5).

</details>


### [68] [PLLuM: A Family of Polish Large Language Models](https://arxiv.org/abs/2511.03823)
*Jan Kocoń,Maciej Piasecki,Arkadiusz Janz,Teddy Ferdinan,Łukasz Radliński,Bartłomiej Koptyra,Marcin Oleksy,Stanisław Woźniak,Paweł Walkowiak,Konrad Wojtasik,Julia Moska,Tomasz Naskręt,Bartosz Walkowiak,Mateusz Gniewkowski,Kamil Szyc,Dawid Motyka,Dawid Banach,Jonatan Dalasiński,Ewa Rudnicka,Bartłomiej Alberski,Tomasz Walkowiak,Aleksander Szczęsny,Maciej Markiewicz,Tomasz Bernaś,Hubert Mazur,Kamil Żyta,Mateusz Tykierko,Grzegorz Chodak,Tomasz Kajdanowicz,Przemysław Kazienko,Agnieszka Karlińska,Karolina Seweryn,Anna Kołos,Maciej Chrabąszcz,Katarzyna Lorenc,Aleksandra Krasnodębska,Artur Wilczek,Katarzyna Dziewulska,Paula Betscher,Zofia Cieślińska,Katarzyna Kowol,Daria Mikoś,Maciej Trzciński,Dawid Krutul,Marek Kozłowski,Sławomir Dadas,Rafał Poświata,Michał Perełkiewicz,Małgorzata Grębowiec,Maciej Kazuła,Marcin Białas,Roman Roszko,Danuta Roszko,Jurgita Vaičenonienė,Andrius Utka,Paweł Levchuk,Paweł Kowalski,Irena Prawdzic-Jankowska,Maciej Ogrodniczuk,Monika Borys,Anna Bulińska,Wiktoria Gumienna,Witold Kieraś,Dorota Komosińska,Katarzyna Krasnowska-Kieraś,Łukasz Kobyliński,Martyna Lewandowska,Marek Łaziński,Mikołaj Łątkowski,Dawid Mastalerz,Beata Milewicz,Agnieszka Anna Mykowiecka,Angelika Peljak-Łapińska,Sandra Penno,Zuzanna Przybysz,Michał Rudolf,Piotr Rybak,Karolina Saputa,Aleksandra Tomaszewska,Aleksander Wawer,Marcin Woliński,Joanna Wołoszyn,Alina Wróblewska,Bartosz Żuk,Filip Żarnecki,Konrad Kaczyński,Anna Cichosz,Zuzanna Deckert,Monika Garnys,Izabela Grabarczyk,Wojciech Janowski,Sylwia Karasińska,Aleksandra Kujawiak,Piotr Misztela,Maria Szymańska,Karolina Walkusz,Igor Siek,Jakub Kwiatkowski,Piotr Pęzik*

Main category: cs.CL

TL;DR: PLLuM是最大的开源波兰语大型语言模型系列，旨在解决英语中心化问题，包含一个1400亿token的语料库、77k指令和100k偏好优化数据集，并强调负责任的AI框架，以促进开放研究和主权AI技术。


<details>
  <summary>Details</summary>
Motivation: 由于LLM主要关注英语，导致其他语言支持有限，因此需要开发专门针对波兰语的高质量、透明且文化相关的语言模型。

Method: 开发了一个包含1400亿token的波兰语预训练语料库，一个77k的自定义指令数据集，以及一个100k的偏好优化数据集。同时，实施了负责任的AI框架，包括严格的数据治理和用于输出纠正及安全过滤的混合模块。

Result: PLLuM成功构建了基础模型和指令调优变体，并在公共行政领域的下游任务中展示了其实用性。

Conclusion: 通过公开发布PLLuM模型，旨在促进开放研究，并加强波兰的主权AI技术，为波兰语提供一个超越英语中心化商业格局的解决方案。

Abstract: Large Language Models (LLMs) play a central role in modern artificial
intelligence, yet their development has been primarily focused on English,
resulting in limited support for other languages. We present PLLuM (Polish
Large Language Model), the largest open-source family of foundation models
tailored specifically for the Polish language. Developed by a consortium of
major Polish research institutions, PLLuM addresses the need for high-quality,
transparent, and culturally relevant language models beyond the English-centric
commercial landscape. We describe the development process, including the
construction of a new 140-billion-token Polish text corpus for pre-training, a
77k custom instructions dataset, and a 100k preference optimization dataset. A
key component is a Responsible AI framework that incorporates strict data
governance and a hybrid module for output correction and safety filtering. We
detail the models' architecture, training procedures, and alignment techniques
for both base and instruction-tuned variants, and demonstrate their utility in
a downstream task within public administration. By releasing these models
publicly, PLLuM aims to foster open research and strengthen sovereign AI
technologies in Poland.

</details>


### [69] [STARS: Segment-level Token Alignment with Rejection Sampling in Large Language Models](https://arxiv.org/abs/2511.03827)
*Mohammad Atif Quamar,Mohammad Areeb,Mikhail Kuznetsov,Muslum Ozgur Ozmen,Z. Berkay Celik*

Main category: cs.CL

TL;DR: STARS是一种解码时算法，通过采样、评分和拒绝/接受短的、固定大小的 token 单元来指导模型生成，以在计算效率和对齐质量方面优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 对齐大型语言模型与人类价值观对于其安全部署至关重要，但现有方法（如微调）计算成本高且效果不佳，而像 Best-of-N 这样的推理时方法需要大量的计算才能实现最佳对齐。

Method: STARS（Segment-level Token Alignment with Rejection Sampling）是一种解码时算法，通过迭代地采样、评分和拒绝/接受短的、固定大小的 token 单元来指导模型生成，从而实现早期纠正生成路径。

Result: 在六种大型语言模型上，STARS 在胜率方面比监督微调（SFT）高出 14.9 个百分点，比直接偏好优化（DPO）高出 4.3 个百分点，并且与强大的 Best-of-N 基线相比仍具有竞争力。

Conclusion: STARS 提出了一种细粒度的、由奖励引导的采样方法，作为对齐大型语言模型的传统微调和全序列排序方法的通用、稳健且高效的替代方案。

Abstract: Aligning large language models with human values is crucial for their safe
deployment; however, existing methods, such as fine-tuning, are computationally
expensive and suboptimal. In contrast, inference-time approaches like Best-of-N
sampling require practically infeasible computation to achieve optimal
alignment. We propose STARS: Segment-level Token Alignment with Rejection
Sampling, a decoding-time algorithm that steers model generation by iteratively
sampling, scoring, and rejecting/accepting short, fixed-size token segments.
This allows for early correction of the generation path, significantly
improving computational efficiency and boosting alignment quality. Across a
suite of six LLMs, we show that STARS outperforms Supervised Fine-Tuning (SFT)
by up to 14.9 percentage points and Direct Preference Optimization (DPO) by up
to 4.3 percentage points on win-rates, while remaining highly competitive with
strong Best-of-N baselines. Our work establishes granular, reward-guided
sampling as a generalizable, robust, and efficient alternative to traditional
fine-tuning and full-sequence ranking methods for aligning LLMs.

</details>


### [70] [BAPPA: Benchmarking Agents, Plans, and Pipelines for Automated Text-to-SQL Generation](https://arxiv.org/abs/2511.04153)
*Fahim Ahmed,Md Mubtasim Ahasan,Jahir Sadik Monon,Muntasir Wahed,M Ashraful Amin,A K M Mahbubur Rahman,Amin Ahsan Ali*

Main category: cs.CL

TL;DR: 本研究探讨了三种多智能体LLM管道，以提高Text-to-SQL系统处理复杂数据库查询的能力，并对不同规模的开源模型进行了基准测试。


<details>
  <summary>Details</summary>
Motivation: 现有的LLM在处理大型数据库模式和复杂推理的SQL生成方面存在困难，而先前的工作主要集中于使用旗舰模型，忽略了小型高效模型。

Method: 研究了三种多智能体LLM管道：1. 多智能体讨论管道（迭代改进SQL查询）；2. 规划-编码管道（规划模型生成计划，编码模型生成查询）；3. 编码-聚合管道（多个编码器独立生成查询，推理代理选择最佳查询）。

Result: 在Bird-Bench Mini-Dev数据集上的实验表明，多智能体讨论可以提高小型模型的性能（Qwen2.5-7b-Instruct的执行准确率提高了10.6%）。规划-编码管道效果最佳，DeepSeek-R1-32B和QwQ-32B规划器将Gemma 3 27B IT的准确率从52.4%提升至56.4%。

Conclusion: 多智能体方法，特别是规划-编码管道，能够显著提高Text-to-SQL系统的性能，即使是规模较小的模型也能取得优异成绩。

Abstract: Text-to-SQL systems provide a natural language interface that can enable even
laymen to access information stored in databases. However, existing Large
Language Models (LLM) struggle with SQL generation from natural instructions
due to large schema sizes and complex reasoning. Prior work often focuses on
complex, somewhat impractical pipelines using flagship models, while smaller,
efficient models remain overlooked. In this work, we explore three multi-agent
LLM pipelines, with systematic performance benchmarking across a range of small
to large open-source models: (1) Multi-agent discussion pipeline, where agents
iteratively critique and refine SQL queries, and a judge synthesizes the final
answer; (2) Planner-Coder pipeline, where a thinking model planner generates
stepwise SQL generation plans and a coder synthesizes queries; and (3)
Coder-Aggregator pipeline, where multiple coders independently generate SQL
queries, and a reasoning agent selects the best query. Experiments on the
Bird-Bench Mini-Dev set reveal that Multi-Agent discussion can improve small
model performance, with up to 10.6% increase in Execution Accuracy for
Qwen2.5-7b-Instruct seen after three rounds of discussion. Among the pipelines,
the LLM Reasoner-Coder pipeline yields the best results, with DeepSeek-R1-32B
and QwQ-32B planners boosting Gemma 3 27B IT accuracy from 52.4% to the highest
score of 56.4%. Codes are available at
https://github.com/treeDweller98/bappa-sql.

</details>


### [71] [Divide, Cache, Conquer: Dichotomic Prompting for Efficient Multi-Label LLM-Based Classification](https://arxiv.org/abs/2511.03830)
*Mikołaj Langner,Jan Eliasz,Ewa Rudnicka,Jan Kocoń*

Main category: cs.CL

TL;DR: 该研究提出了一种通过将多标签文本分类任务重构为一系列二分决策（是/否）来提高大型语言模型（LLM）效率的方法，并使用蒸馏技术在情感分析任务上进行了验证。


<details>
  <summary>Details</summary>
Motivation: 为解决大型语言模型（LLM）在多标签文本分类任务中的效率问题，提出一种新的方法。

Method: 将多标签分类任务重构为一系列二分决策（是/否）问题，并结合前缀缓存机制提高推理效率。利用LLM-to-SLM蒸馏技术，以DeepSeek-V3作为教师模型，对HerBERT-Large、CLARIN-1B、PLLuM-8B、Gemma3-1B等小型模型进行微调，用于情感分析任务（包括24个维度）。

Result: 微调后的模型在情感分析任务上显著优于零样本基线模型，尤其在训练过的维度上表现更佳。

Conclusion: 将多标签分类分解为二分查询、结合蒸馏和缓存感知推理，为基于LLM的分类提供了一个可扩展且有效的方法框架，该方法不仅适用于情感分析，也适用于其他领域。

Abstract: We introduce a method for efficient multi-label text classification with
large language models (LLMs), built on reformulating classification tasks as
sequences of dichotomic (yes/no) decisions. Instead of generating all labels in
a single structured response, each target dimension is queried independently,
which, combined with a prefix caching mechanism, yields substantial efficiency
gains for short-text inference without loss of accuracy. To demonstrate the
approach, we focus on affective text analysis, covering 24 dimensions including
emotions and sentiment. Using LLM-to-SLM distillation, a powerful annotator
model (DeepSeek-V3) provides multiple annotations per text, which are
aggregated to fine-tune smaller models (HerBERT-Large, CLARIN-1B, PLLuM-8B,
Gemma3-1B). The fine-tuned models show significant improvements over zero-shot
baselines, particularly on the dimensions seen during training. Our findings
suggest that decomposing multi-label classification into dichotomic queries,
combined with distillation and cache-aware inference, offers a scalable and
effective framework for LLM-based classification. While we validate the method
on affective states, the approach is general and applicable across domains.

</details>


### [72] [Evaluating Machine Translation Datasets for Low-Web Data Languages: A Gendered Lens](https://arxiv.org/abs/2511.03880)
*Hellina Hailu Nigatu,Bethelhem Yemane Mamo,Bontu Fufa Balcha,Debora Taye Tesfaye,Elbethel Daniel Zewdie,Ikram Behiru Nesiru,Jitu Ewnetu Hailu,Senait Mengesha Yayo*

Main category: cs.CL

TL;DR: 低资源语言的机器翻译数据集在性别代表方面存在质量问题，存在有害内容。


<details>
  <summary>Details</summary>
Motivation: 随着低资源语言越来越多地被纳入自然语言处理研究，人们越来越重视收集大规模数据集。然而，在优先考虑数量而非质量的情况下，我们可能会面临两个风险：1) 为这些语言构建性能较差的语言技术；2) 产生延续社会偏见的有害内容。因此，有必要调查低资源语言机器翻译数据集的质量，特别是性别代表方面。

Method: 本研究调查了三种低资源语言——阿法尔奥罗莫语、阿姆哈拉语和提格利尼亚语——的机器翻译（MT）数据集的质量，重点关注性别代表情况。

Result: 研究结果表明，虽然训练数据在政治和宗教领域文本方面具有很大的代表性，但基准数据集主要关注新闻、健康和体育领域。此外，研究还发现数据在姓名、动词的语法性别以及数据中的刻板印象方面存在明显的性别倾斜（偏向男性）。更令人担忧的是，研究发现了针对女性的有害和有毒描述，这种情况在数据量最大的语言中更为突出，这表明数量并不保证质量。

Conclusion: 本研究强调了低资源语言机器翻译数据集在性别代表和内容质量方面存在的问题，并希望我们的工作能激发对所收集数据集的进一步探究，并促使及早消除有害内容。

Abstract: As low-resourced languages are increasingly incorporated into NLP research,
there is an emphasis on collecting large-scale datasets. But in prioritizing
quantity over quality, we risk 1) building language technologies that perform
poorly for these languages and 2) producing harmful content that perpetuates
societal biases. In this paper, we investigate the quality of Machine
Translation (MT) datasets for three low-resourced languages--Afan Oromo,
Amharic, and Tigrinya, with a focus on the gender representation in the
datasets. Our findings demonstrate that while training data has a large
representation of political and religious domain text, benchmark datasets are
focused on news, health, and sports. We also found a large skew towards the
male gender--in names of persons, the grammatical gender of verbs, and in
stereotypical depictions in the datasets. Further, we found harmful and toxic
depictions against women, which were more prominent for the language with the
largest amount of data, underscoring that quantity does not guarantee quality.
We hope that our work inspires further inquiry into the datasets collected for
low-resourced languages and prompts early mitigation of harmful content.
WARNING: This paper contains discussion of NSFW content that some may find
disturbing.

</details>


### [73] [GRAD: Graph-Retrieved Adaptive Decoding for Hallucination Mitigation](https://arxiv.org/abs/2511.03900)
*Manh Nguyen,Sunil Gupta,Dai Do,Hung Le*

Main category: cs.CL

TL;DR: GRAD是一种在解码时无需重新训练即可减轻LLM幻觉的方法，它通过构建稀疏的token转移图并将其与模型logits融合来 grounding 生成。


<details>
  <summary>Details</summary>
Motivation: 现有的LLM幻觉缓解方法通常依赖外部知识源，但基于提示的方法不稳定且对领域敏感，而符号知识集成成本高昂。因此，需要一种无需重新训练即可在解码时缓解幻觉的方法。

Method: GRAD通过构建稀疏的token转移图来累积小规模检索语料库中的下一个token logits，然后在解码时将图检索logits与模型logits自适应融合，以偏向高证据的续写同时保持流畅性。

Result: 在三个模型和一系列涵盖内在、外在幻觉和事实性任务的问答基准上，GRAD始终优于基线，内在准确率最高可提高9.7%，幻觉率最低可降低8.6%，正确率最高可提高6.9%，并且在所有方法中获得了最高的真实性-信息性乘积得分。

Conclusion: GRAD是一种轻量级的、即插即用的方法，可以替代对比解码和知识图谱增强，证明了语料库级别token转移的统计证据可以有效地引导生成，产生更真实、可验证的输出。

Abstract: Hallucination mitigation remains a persistent challenge for large language
models (LLMs), even as model scales grow. Existing approaches often rely on
external knowledge sources, such as structured databases or knowledge graphs,
accessed through prompting or retrieval. However, prompt-based grounding is
fragile and domain-sensitive, while symbolic knowledge integration incurs heavy
retrieval and formatting costs. Motivated by knowledge graphs, we introduce
Graph-Retrieved Adaptive Decoding (GRAD), a decoding-time method that grounds
generation in corpus-derived evidence without retraining. GRAD constructs a
sparse token transition graph by accumulating next-token logits across a small
retrieved corpus in a single forward pass. During decoding, graph-retrieved
logits are max-normalized and adaptively fused with model logits to favor
high-evidence continuations while preserving fluency. Across three models and a
range of question-answering benchmarks spanning intrinsic, extrinsic
hallucination, and factuality tasks, GRAD consistently surpasses baselines,
achieving up to 9.7$\%$ higher intrinsic accuracy, 8.6$\%$ lower hallucination
rates, and 6.9$\%$ greater correctness compared to greedy decoding, while
attaining the highest truth--informativeness product score among all methods.
GRAD offers a lightweight, plug-and-play alternative to contrastive decoding
and knowledge graph augmentation, demonstrating that statistical evidence from
corpus-level token transitions can effectively steer generation toward more
truthful and verifiable outputs.

</details>


### [74] [Context informs pragmatic interpretation in vision-language models](https://arxiv.org/abs/2511.03908)
*Alvin Wei Ming Tan,Ben Prystawski,Veronica Boyce,Michael C. Frank*

Main category: cs.CL

TL;DR: 在迭代参照博弈中，语言模型在有相关上下文时表现显著提升，但仍落后于人类，尤其是在处理抽象指代物时。


<details>
  <summary>Details</summary>
Motivation: 评估语言模型在多轮对话环境中进行上下文敏感的语用推理的能力，以迭代参照博弈为测试案例。

Method: 在迭代参照博弈的试验中，通过改变上下文的数量、顺序和相关性来测试人类和视觉-语言模型。

Result: 在缺乏相关上下文时，模型表现优于机会水平但显著逊于人类。然而，当提供相关上下文时，模型的表现随试验进行显著提高。

Conclusion: 对于机器学习模型来说，包含抽象指代物的少样本迭代参照博弈仍然是一项困难的任务。

Abstract: Iterated reference games - in which players repeatedly pick out novel
referents using language - present a test case for agents' ability to perform
context-sensitive pragmatic reasoning in multi-turn linguistic environments. We
tested humans and vision-language models on trials from iterated reference
games, varying the given context in terms of amount, order, and relevance.
Without relevant context, models were above chance but substantially worse than
humans. However, with relevant context, model performance increased
dramatically over trials. Few-shot reference games with abstract referents
remain a difficult task for machine learning models.

</details>


### [75] [A Characterization of List Language Identification in the Limit](https://arxiv.org/abs/2511.04103)
*Moses Charikar,Chirag Pabbaraju,Ambuj Tewari*

Main category: cs.CL

TL;DR: 该论文研究了语言识别问题，并引入了k-列表识别的概念，给出了可k-列表识别语言集合的精确刻画，并建立了相关识别速率。


<details>
  <summary>Details</summary>
Motivation: 受到语言生成问题近期研究的启发，重新审视了语言识别问题，并引入了k-列表识别的概念。

Method: 通过对Angluin的字符化进行递归，给出了语言集合可k-列表识别的精确刻画，并进一步将其分解为k个可单列表识别的语言集合。

Result: 得到了语言集合可k-列表识别的充要条件，并在此基础上建立了统计学习设置下的识别速率，证明了指数速率是可达到的最优速率。

Conclusion: 该研究为k-列表识别问题提供了理论基础，并确定了其最优识别速率。

Abstract: We study the problem of language identification in the limit, where given a
sequence of examples from a target language, the goal of the learner is to
output a sequence of guesses for the target language such that all the guesses
beyond some finite time are correct. Classical results of Gold showed that
language identification in the limit is impossible for essentially any
interesting collection of languages. Later, Angluin gave a precise
characterization of language collections for which this task is possible.
Motivated by recent positive results for the related problem of language
generation, we revisit the classic language identification problem in the
setting where the learner is given the additional power of producing a list of
$k$ guesses at each time step. The goal is to ensure that beyond some finite
time, one of the guesses is correct at each time step.
  We give an exact characterization of collections of languages that can be
$k$-list identified in the limit, based on a recursive version of Angluin's
characterization (for language identification with a list of size $1$). This
further leads to a conceptually appealing characterization: A language
collection can be $k$-list identified in the limit if and only if the
collection can be decomposed into $k$ collections of languages, each of which
can be identified in the limit (with a list of size $1$). We also use our
characterization to establish rates for list identification in the statistical
setting where the input is drawn as an i.i.d. stream from a distribution
supported on some language in the collection. Our results show that if a
collection is $k$-list identifiable in the limit, then the collection can be
$k$-list identified at an exponential rate, and this is best possible. On the
other hand, if a collection is not $k$-list identifiable in the limit, then it
cannot be $k$-list identified at any rate that goes to zero.

</details>


### [76] [The Human Flourishing Geographic Index: A County-Level Dataset for the United States, 2013--2023](https://arxiv.org/abs/2511.03915)
*Stefano M. Iacus,Devika Jain,Andrea Nasuto,Giuseppe Porro,Marcello Carammia,Andrea Vezzulli*

Main category: cs.CL

TL;DR: 该研究介绍了人类繁荣地理指数（HFGI），一个基于26亿条美国推文数据的指数，用于在精细的时空尺度上量化人类繁荣度。


<details>
  <summary>Details</summary>
Motivation: 现有的社会福祉衡量标准缺乏精细的时空分辨率，因此需要开发新的指标来超越单一的经济指标。

Method: 利用经过微调的大型语言模型分析2013-2023年约26亿条地理定位的美国推文，将推文内容分类到与哈佛大学全球繁荣研究框架相符的48个指标，并纳入对移民的态度和腐败的感知。

Result: 该研究生成了包含每月和每年县级及州级指标的数据集，这些指标与人类繁荣相关的讨论相关，并经过验证，能够准确代表相关构建因素，并与既有指标呈现预期相关性。

Conclusion: HFGI为多学科分析福祉、不平等和社会变革提供了前所未有的分辨率，有助于深入了解社交媒体讨论中反映的人类繁荣动态。

Abstract: Quantifying human flourishing, a multidimensional construct including
happiness, health, purpose, virtue, relationships, and financial stability, is
critical for understanding societal well-being beyond economic indicators.
Existing measures often lack fine spatial and temporal resolution. Here we
introduce the Human Flourishing Geographic Index (HFGI), derived from analyzing
approximately 2.6 billion geolocated U.S. tweets (2013-2023) using fine-tuned
large language models to classify expressions across 48 indicators aligned with
Harvard's Global Flourishing Study framework plus attitudes towards migration
and perception of corruption. The dataset offers monthly and yearly county- and
state-level indicators of flourishing-related discourse, validated to confirm
that the measures accurately represent the underlying constructs and show
expected correlations with established indicators. This resource enables
multidisciplinary analyses of well-being, inequality, and social change at
unprecedented resolution, offering insights into the dynamics of human
flourishing as reflected in social media discourse across the United States
over the past decade.

</details>


### [77] [Direct Semantic Communication Between Large Language Models via Vector Translation](https://arxiv.org/abs/2511.03945)
*Fu-Chun Yang,Jason Eshraghian*

Main category: cs.CL

TL;DR: 在多智能体环境中，通过向量翻译建立的潜在桥梁实现了不同大型语言模型间的语义交换，平均余弦相似度达到0.538，并验证了跨模型潜在通信的可行性。


<details>
  <summary>Details</summary>
Motivation: 现有的大型语言模型（LLMs）在多智能体交互中以明文形式传递信息，丢失了大部分潜在语义，导致信息传输受限且增加了计算开销。

Method: 通过训练一个偶编码器翻译器，在Llama-2-7B和Mistral-7B-Instruct之间进行向量翻译，实现表示空间之间的直接语义交换。并将翻译后的向量以30%的混合强度注入目标模型。

Result: 偶编码器翻译器实现了0.538的平均余弦对齐度。注入翻译向量在不破坏logits的情况下引导了目标模型的生成。双向评估显示了2.01:1的传输不对称性，表明通用模型比指令微调模型产生更可转移的表示。

Conclusion: 保守的向量注入方式在保持计算稳定性的同时，证明了跨模型潜在通信是可行的，为构建共享意义而非令牌的协作式人工智能系统铺平了道路。

Abstract: In multi-agent settings, such as debate, reflection, or tool-calling, large
language models (LLMs) pass messages as plain tokens, discarding most latent
semantics. This constrains information transfer and adds unnecessary
computational overhead. We form a latent bridge via vector translations, which
use learned mappings that enable direct semantic exchange between
representation spaces. A dual-encoder translator trained between Llama-2-7B and
Mistral-7B-Instruct attains an average cosine alignment of 0.538. Injecting the
translated vectors at 30 percent blending strength steers the target model's
generation without destabilizing logits. Bidirectional evaluation shows a
2.01:1 transfer asymmetry, indicating that general-purpose models yield more
transferable representations than instruction-tuned variants. This conservative
injection preserves computational stability while demonstrating that
cross-model latent communication is feasible, enabling collaborative AI systems
that share meaning rather than tokens.

</details>


### [78] [Abductive Inference in Retrieval-Augmented Language Models: Generating and Validating Missing Premises](https://arxiv.org/abs/2511.04020)
*Shiyin Lin*

Main category: cs.CL

TL;DR: 检索增强生成（RAG）模型在处理不完整检索信息时存在不足，本文提出引入溯因推理来弥补信息缺口，通过生成、验证候选前提来提高 RAG 系统的准确性和可解释性。


<details>
  <summary>Details</summary>
Motivation: RAG 模型在检索到的证据不完整、存在推理断层时，常难以取得良好性能。

Method: 提出一个将溯因推理集成到 RAG 框架中的方法，该方法能检测信息不足、生成候选缺失前提，并通过一致性和合理性检查来验证这些前提。

Result: 在溯因推理和多跳问答基准测试中，该方法提高了答案的准确性和推理的忠实度。

Conclusion: 溯因推理是增强 RAG 系统鲁棒性和可解释性的一个有前景的方向。

Abstract: Large Language Models (LLMs) enhanced with retrieval -- commonly referred to
as Retrieval-Augmented Generation (RAG) -- have demonstrated strong performance
in knowledge-intensive tasks. However, RAG pipelines often fail when retrieved
evidence is incomplete, leaving gaps in the reasoning process. In such cases,
\emph{abductive inference} -- the process of generating plausible missing
premises to explain observations -- offers a principled approach to bridge
these gaps. In this paper, we propose a framework that integrates abductive
inference into retrieval-augmented LLMs. Our method detects insufficient
evidence, generates candidate missing premises, and validates them through
consistency and plausibility checks. Experimental results on abductive
reasoning and multi-hop QA benchmarks show that our approach improves both
answer accuracy and reasoning faithfulness. This work highlights abductive
inference as a promising direction for enhancing the robustness and
explainability of RAG systems.

</details>


### [79] [WST: Weakly Supervised Transducer for Automatic Speech Recognition](https://arxiv.org/abs/2511.04035)
*Dongji Gao,Chenda Liao,Changliang Liu,Matthew Wiesner,Leibny Paola Garcia,Daniel Povey,Sanjeev Khudanpur,Jian Wu*

Main category: cs.CL

TL;DR: 提出了一种弱监督语音识别模型WST，可以处理高达70%的转录错误，并且优于现有的基于CTC的弱监督方法。


<details>
  <summary>Details</summary>
Motivation: 现有的端到端语音识别模型（如RNN-T）高度依赖大规模、高质量的标注数据，而这些数据难以获取。本研究旨在减少对数据的依赖。

Method: 提出了一种弱监督转换器（WST）模型，该模型采用灵活的训练图，能够稳健地处理转录错误，无需额外的置信度估计或预训练模型。

Result: 在合成和工业数据集上的实验表明，WST在高达70%的转录错误率下仍能有效保持性能，并且优于现有的基于CTC的弱监督方法（如BTC和OTC）。

Conclusion: WST在实际语音识别场景中具有实用性和鲁棒性，能够有效处理带错误的转录数据，并将在公开场合提供实现。

Abstract: The Recurrent Neural Network-Transducer (RNN-T) is widely adopted in
end-to-end (E2E) automatic speech recognition (ASR) tasks but depends heavily
on large-scale, high-quality annotated data, which are often costly and
difficult to obtain. To mitigate this reliance, we propose a Weakly Supervised
Transducer (WST), which integrates a flexible training graph designed to
robustly handle errors in the transcripts without requiring additional
confidence estimation or auxiliary pre-trained models. Empirical evaluations on
synthetic and industrial datasets reveal that WST effectively maintains
performance even with transcription error rates of up to 70%, consistently
outperforming existing Connectionist Temporal Classification (CTC)-based weakly
supervised approaches, such as Bypass Temporal Classification (BTC) and
Omni-Temporal Classification (OTC). These results demonstrate the practical
utility and robustness of WST in realistic ASR settings. The implementation
will be publicly available.

</details>


### [80] [T-FIX: Text-Based Explanations with Features Interpretable to eXperts](https://arxiv.org/abs/2511.04070)
*Shreya Havaldar,Helen Jin,Chaehyeon Kim,Anton Xue,Weiqiu You,Marco Gatti,Bhuvnesh Jain,Helen Qu,Daniel A Hashimoto,Amin Madani,Rajat Deo,Sameed Ahmed M. Khatana,Gary E. Weissman,Lyle Ungar,Eric Wong*

Main category: cs.CL

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: As LLMs are deployed in knowledge-intensive settings (e.g., surgery,
astronomy, therapy), users expect not just answers, but also meaningful
explanations for those answers. In these settings, users are often domain
experts (e.g., doctors, astrophysicists, psychologists) who require
explanations that reflect expert-level reasoning. However, current evaluation
schemes primarily emphasize plausibility or internal faithfulness of the
explanation, which fail to capture whether the content of the explanation truly
aligns with expert intuition. We formalize expert alignment as a criterion for
evaluating explanations with T-FIX, a benchmark spanning seven
knowledge-intensive domains. In collaboration with domain experts, we develop
novel metrics to measure the alignment of LLM explanations with expert
judgment.

</details>


### [81] [Plan of Knowledge: Retrieval-Augmented Large Language Models for Temporal Knowledge Graph Question Answering](https://arxiv.org/abs/2511.04072)
*Xinying Qian,Ying Zhang,Yu Zhao,Baohang Zhou,Xuhui Sui,Xiaojie Yuan*

Main category: cs.CL

TL;DR: LLMs在回答时事问题时存在时间推理能力有限、幻觉和知识缺乏等问题。本文提出了PoK框架，通过将复杂问题分解为子目标序列，并结合对比时间检索器从TKG中检索事实，来增强LLM在TKGQA任务中的解释性和事实一致性。实验表明，PoK显著提高了LLM的检索精度和推理准确性。


<details>
  <summary>Details</summary>
Motivation: 以往的TKGQA方法未能充分理解时间约束的复杂语义信息，而LLMs虽然语义理解能力强，但时间推理能力有限，且存在幻觉和知识缺乏的问题。

Method: 提出PoK框架，包括“知识规划”模块和“对比时间检索器”。“知识规划”将复杂时间问题分解为一系列子目标，利用预定义工具作为推理指导。对比时间检索器构建TKS，用于从TKG中检索语义和时间上对齐的事实。

Result: PoK显著提高了LLM的检索精度和推理准确性，在四个TKGQA基准数据集上，相比现有最先进方法，性能最多提升了56.0%。

Conclusion: PoK框架通过结合结构化规划和时间知识检索，有效提升了时间推理的可解释性和事实一致性，显著优于现有TKGQA方法。

Abstract: Temporal Knowledge Graph Question Answering (TKGQA) aims to answer
time-sensitive questions by leveraging factual information from Temporal
Knowledge Graphs (TKGs). While previous studies have employed pre-trained TKG
embeddings or graph neural networks to inject temporal knowledge, they fail to
fully understand the complex semantic information of time constraints.
Recently, Large Language Models (LLMs) have shown remarkable progress,
benefiting from their strong semantic understanding and reasoning
generalization capabilities. However, their temporal reasoning ability remains
limited. LLMs frequently suffer from hallucination and a lack of knowledge. To
address these limitations, we propose the Plan of Knowledge framework with a
contrastive temporal retriever, which is named PoK. Specifically, the proposed
Plan of Knowledge module decomposes a complex temporal question into a sequence
of sub-objectives from the pre-defined tools, serving as intermediate guidance
for reasoning exploration. In parallel, we construct a Temporal Knowledge Store
(TKS) with a contrastive retrieval framework, enabling the model to selectively
retrieve semantically and temporally aligned facts from TKGs. By combining
structured planning with temporal knowledge retrieval, PoK effectively enhances
the interpretability and factual consistency of temporal reasoning. Extensive
experiments on four benchmark TKGQA datasets demonstrate that PoK significantly
improves the retrieval precision and reasoning accuracy of LLMs, surpassing the
performance of the state-of-the-art TKGQA methods by 56.0% at most.

</details>


### [82] [The truth is no diaper: Human and AI-generated associations to emotional words](https://arxiv.org/abs/2511.04077)
*Špela Vintar,Jan Jona Javoršek*

Main category: cs.CL

TL;DR: 人类和大型语言模型（LLM）在词语联想方面存在中等程度的重叠，但LLM的联想更易受情感影响且缺乏创造性。


<details>
  <summary>Details</summary>
Motivation: 探索大型语言模型（LLM）在词语联想方面与人类的相似之处，特别是针对情感词汇，以了解LLM生成联想的方式。

Method: 比较人类和大型语言模型对情感词汇的联想行为。

Result: LLM与人类的联想重叠度中等。LLM的联想放大了刺激物的潜在情感负荷，并且比人类的联想更可预测、更缺乏创造性。

Conclusion: 虽然LLM在词语联想方面与人类存在一定程度的相似性，但它们在处理情感词汇时表现出放大情感、可预测性强和创造性不足的特点。

Abstract: Human word associations are a well-known method of gaining insight into the
internal mental lexicon, but the responses spontaneously offered by human
participants to word cues are not always predictable as they may be influenced
by personal experience, emotions or individual cognitive styles. The ability to
form associative links between seemingly unrelated concepts can be the driving
mechanisms of creativity. We perform a comparison of the associative behaviour
of humans compared to large language models. More specifically, we explore
associations to emotionally loaded words and try to determine whether large
language models generate associations in a similar way to humans. We find that
the overlap between humans and LLMs is moderate, but also that the associations
of LLMs tend to amplify the underlying emotional load of the stimulus, and that
they tend to be more predictable and less creative than human ones.

</details>


### [83] [Improving the Performance of Radiology Report De-identification with Large-Scale Training and Benchmarking Against Cloud Vendor Methods](https://arxiv.org/abs/2511.04079)
*Eva Prakash,Maayane Attias,Pierre Chambon,Justin Xu,Steven Truong,Jean-Benoit Delbrouck,Tessa Cook,Curtis Langlotz*

Main category: cs.CL

TL;DR: 研究训练了一个基于transformer的去标识模型，在放射学报告中识别受保护的健康信息（PHI），其表现优于现有的学术和商业系统。


<details>
  <summary>Details</summary>
Motivation: 为了提高放射学报告自动去标识的准确性，并将其与商业云供应商的系统进行比较。

Method: 研究人员在一个先进的、基于transformer的PHI去标识流程基础上，使用了两个大型标注的斯坦福大学放射学语料库进行微调，并引入了“年龄”这一新的PHI类别。模型在斯坦福大学和宾夕法尼亚大学（Penn）的测试集上进行了评估，并与商业系统进行了比较。

Result: 该模型在Penn数据集上达到了0.973的F1分数，在斯坦福数据集上达到了0.996的F1分数，表现优于或持平了之前的最先进模型。此外，在合成PHI报告的测试中，该模型也显著优于所有供应商系统。

Conclusion: 一个在多样化的放射学数据集上训练的基于transformer的去标识模型，在PHI检测方面优于之前的学术和商业系统，并为安全的临床文本处理树立了新的基准。

Abstract: Objective: To enhance automated de-identification of radiology reports by
scaling transformer-based models through extensive training datasets and
benchmarking performance against commercial cloud vendor systems for protected
health information (PHI) detection. Materials and Methods: In this
retrospective study, we built upon a state-of-the-art, transformer-based, PHI
de-identification pipeline by fine-tuning on two large annotated radiology
corpora from Stanford University, encompassing chest X-ray, chest CT,
abdomen/pelvis CT, and brain MR reports and introducing an additional PHI
category (AGE) into the architecture. Model performance was evaluated on test
sets from Stanford and the University of Pennsylvania (Penn) for token-level
PHI detection. We further assessed (1) the stability of synthetic PHI
generation using a "hide-in-plain-sight" method and (2) performance against
commercial systems. Precision, recall, and F1 scores were computed across all
PHI categories. Results: Our model achieved overall F1 scores of 0.973 on the
Penn dataset and 0.996 on the Stanford dataset, outperforming or maintaining
the previous state-of-the-art model performance. Synthetic PHI evaluation
showed consistent detectability (overall F1: 0.959 [0.958-0.960]) across 50
independently de-identified Penn datasets. Our model outperformed all vendor
systems on synthetic Penn reports (overall F1: 0.960 vs. 0.632-0.754).
Discussion: Large-scale, multimodal training improved cross-institutional
generalization and robustness. Synthetic PHI generation preserved data utility
while ensuring privacy. Conclusion: A transformer-based de-identification model
trained on diverse radiology datasets outperforms prior academic and commercial
systems in PHI detection and establishes a new benchmark for secure clinical
text processing.

</details>


### [84] [Batch Prompting Suppresses Overthinking Reasoning Under Constraint: How Batch Prompting Suppresses Overthinking in Reasoning Models](https://arxiv.org/abs/2511.04108)
*Wenmo Qiu,Saurabh Srivastava*

Main category: cs.CL

TL;DR: 通过对13个基准进行实验，我们发现批处理可以提高大型推理模型的准确性，同时将推理令牌使用量减少3-5倍。批处理通过抑制过度思考、减少犹豫不决的语言来使模型行为正则化，并产生集体的涌现效应，使模型能够将从简单示例中学习到的模式推广到更难的示例。


<details>
  <summary>Details</summary>
Motivation: 批处理作为一种分摊大型语言模型（LLM）推理成本的策略已被广泛研究。然而，本研究旨在探讨批处理在多步推理过程中对大型推理模型（LRM）行为的正则化作用，这是一种被忽视的额外好处。

Method: 对13个多样化的基准进行了全面的研究，并进行了详细的行为分析，以评估批处理对模型准确性、推理代币使用以及模型行为（如过度思考、犹豫不决的语言和决策能力）的影响。还观察了批处理推理中出现的集体效应。

Result: 批处理在13个基准测试中提高了准确性，并将推理代币使用量大幅减少了3-5倍。行为分析表明，批处理可以抑制过度思考，减少犹豫不决的语言，并鼓励更果断的答案。此外，还观察到批处理推理中的涌现集体效应，模型能够将早期示例中的模式推广到同一批次中更难的示例。

Conclusion: 批处理不仅是一种吞吐量优化技术，而且还是一种强大的推理时正则化器，可以提高LLM推理的效率和可靠性。

Abstract: Recent work has explored batch prompting as a strategy to amortize inference
cost in large language models (LLMs). In this paper, we show that batching
offers an additional, underappreciated benefit: it regularizes model behavior
during multi-step reasoning for Large Reasoning Models (LRMs). We conduct a
comprehensive study across 13 diverse benchmarks and observe that batching
improves accuracy while substantially reducing reasoning token usage, often by
3x-5x. Through detailed behavioral analysis, we find that batching suppresses
overthinking, reduces hedging language (e.g., repetitive self-corrections), and
encourages more decisive answers. Surprisingly, we also observe emergent
collective effects in batched inference: models often generalize patterns from
earlier examples to solve harder ones in the same batch. These findings
position batching not just as a throughput optimization, but as a powerful
inference-time regularizer for more efficient and reliable LLM reasoning.

</details>


### [85] [RIDE: Difficulty Evolving Perturbation with Item Response Theory for Mathematical Reasoning](https://arxiv.org/abs/2511.04120)
*Xinyuan Li,Murong Xu,Wenbiao Tao,Hanlun Zhu,Yike Zhao,Jipeng Zhang,Yunshi Lan*

Main category: cs.CL

TL;DR: LLM在数学推理方面表现出色，但可能存在数据泄露或模式匹配问题。提出RIDE框架，利用项目反应理论（IRT）生成更难、更合理的问题变体，以评估LLM的真实数学推理能力。实验表明，RIDE生成的扰动问题能显著降低LLM在数学竞赛基准测试上的表现。


<details>
  <summary>Details</summary>
Motivation: 现有基于规则的扰动方法生成的数学问题可能不恰当，并且难以系统地评估问题难度和改进基准测试。因此，需要一种新的评估方法来衡量LLM真正的数学推理能力。

Method: 提出RIDE框架，利用项目反应理论（IRT）来评估问题难度并生成更具挑战性、更合理的问题变体。使用35个LLM模拟学生，构建难度排序器，并利用强化学习指导问题改写模型。将RIDE应用于数学竞赛基准测试。

Result: RIDE生成的扰动版本的问题显著降低了先进LLM的性能，平均性能下降21.73%（在26个模型上），揭示了LLM在数学推理方面的鲁棒性有限。

Conclusion: RIDE框架能够有效生成更具挑战性、更合理的问题变体，从而更准确地评估LLM的数学推理能力，并验证了该评估方法的有效性。

Abstract: Large language models (LLMs) achieve high performance on mathematical
reasoning, but these results can be inflated by training data leakage or
superficial pattern matching rather than genuine reasoning. To this end, an
adversarial perturbation-based evaluation is needed to measure true
mathematical reasoning ability. Current rule-based perturbation methods often
generate ill-posed questions and impede the systematic evaluation of question
difficulty and the evolution of benchmarks. To bridge this gap, we propose
RIDE, a novel adversarial question-rewriting framework that leverages Item
Response Theory (IRT) to rigorously measure question difficulty and to generate
intrinsically more challenging, well-posed variations of mathematical problems.
We employ 35 LLMs to simulate students and build a difficulty ranker from their
responses. This ranker provides a reward signal during reinforcement learning
and guides a question-rewriting model to reformulate existing questions across
difficulty levels. Applying RIDE to competition-level mathematical benchmarks
yields perturbed versions that degrade advanced LLM performance, with
experiments showing an average 21.73% drop across 26 models, thereby exposing
limited robustness in mathematical reasoning and confirming the validity of our
evaluation approach.

</details>


### [86] [CantoASR: Prosody-Aware ASR-LALM Collaboration for Low-Resource Cantonese](https://arxiv.org/abs/2511.04139)
*Dazhong Chen,Yi-Cheng Lin,Yuchen Huang,Ziwei Gong,Di Jiang,Zeying Xie,Yi R.,Fung*

Main category: cs.CL

TL;DR: CantoASR是一个结合了强制对齐、LoRA微调的Whisper和指令微调的Qwen-Audio的协作ASR-LALM错误修正框架，用于解决低资源粤语识别的挑战，并在自发粤语数据上取得了显著的词错误率（CER）提升。


<details>
  <summary>Details</summary>
Motivation: 低资源粤语由于数据有限、存在六个词汇声调、声调联络和口音变异等因素，导致现有的自动语音识别（ASR）模型（如Whisper）的词错误率较高。大型音频语言模型（LALM）虽然可以利用更广泛的上下文推理，但仍需要明确的声调和韵律声学线索。

Method: 提出CantoASR，一个协作ASR-LALM错误修正框架，该框架集成了用于声学特征提取的强制对齐，用于改进声调辨别的LoRA微调Whisper，以及用于韵律感知修正的指令微调Qwen-Audio。

Result: 在自发粤语数据上的评估显示，与Whisper-Large-V3相比，CantoASR在词错误率（CER）方面取得了显著的进步。

Conclusion: 将声学线索与LALM推理相结合，为低资源声调和方言ASR提供了一种可扩展的策略。

Abstract: Automatic speech recognition (ASR) is critical for language accessibility,
yet low-resource Cantonese remains challenging due to limited annotated data,
six lexical tones, tone sandhi, and accent variation. Existing ASR models, such
as Whisper, often suffer from high word error rates. Large audio-language
models (LALMs), in contrast, can leverage broader contextual reasoning but
still require explicit tonal and prosodic acoustic cues. We introduce CantoASR,
a collaborative ASR-LALM error correction framework that integrates forced
alignment for acoustic feature extraction, a LoRA-finetuned Whisper for
improved tone discrimination, and an instruction-tuned Qwen-Audio for
prosody-aware correction. Evaluations on spontaneous Cantonese data show
substantial CER gains over Whisper-Large-V3. These findings suggest that
integrating acoustic cues with LALM reasoning provides a scalable strategy for
low-resource tonal and dialectal ASR.

</details>


### [87] [Trustworthy LLM-Mediated Communication: Evaluating Information Fidelity in LLM as a Communicator (LAAC) Framework in Multiple Application Domains](https://arxiv.org/abs/2511.04184)
*Mohammed Musthafa Rafi,Adarsh Krishnamurthy,Aditya Balu*

Main category: cs.CL

TL;DR: AI生成内容泛滥导致沟通失真，提出LAAC模型作为沟通中介，并通过信息捕获保真度、可复现性和查询响应完整性三个维度评估其可信度。


<details>
  <summary>Details</summary>
Motivation: AI生成内容的泛滥导致沟通中的信息冗余和失真，传统的“AI生成-AI压缩”模式阻碍了真实的知识交流。LAAC旨在通过将LLM定位为智能沟通中介，来解决这一问题，促进跨领域（如学术论文、提案、邮件等）的真实沟通。

Method: 通过设计多智能体架构，并在不同沟通场景下进行实验，从三个维度系统评估LAAC的可信度：1. 信息捕获保真度（从对话中准确提取意图）；2. 可复现性（结构化知识在多次交互中的一致性）；3. 查询响应完整性（确保回复无幻觉、不混淆来源、无捏造）。

Result: 初步实验结果显示，在将LAAC应用于高风险沟通场景之前，存在可衡量的信任差距，需要进一步解决。

Conclusion: LAAC模型在真实沟通方面展现了潜力，但其在信息捕获保真度、可复现性和查询响应完整性方面仍存在信任差距，在高风险应用前需要解决这些问题。

Abstract: The proliferation of AI-generated content has created an absurd communication
theater where senders use LLMs to inflate simple ideas into verbose content,
recipients use LLMs to compress them back into summaries, and as a consequence
neither party engage with authentic content. LAAC (LLM as a Communicator)
proposes a paradigm shift - positioning LLMs as intelligent communication
intermediaries that capture the sender's intent through structured dialogue and
facilitate genuine knowledge exchange with recipients. Rather than perpetuating
cycles of AI-generated inflation and compression, LAAC enables authentic
communication across diverse contexts including academic papers, proposals,
professional emails, and cross-platform content generation. However, deploying
LLMs as trusted communication intermediaries raises critical questions about
information fidelity, consistency, and reliability. This position paper
systematically evaluates the trustworthiness requirements for LAAC's deployment
across multiple communication domains. We investigate three fundamental
dimensions: (1) Information Capture Fidelity - accuracy of intent extraction
during sender interviews across different communication types, (2)
Reproducibility - consistency of structured knowledge across multiple
interaction instances, and (3) Query Response Integrity - reliability of
recipient-facing responses without hallucination, source conflation, or
fabrication. Through controlled experiments spanning multiple LAAC use cases,
we assess these trust dimensions using LAAC's multi-agent architecture.
Preliminary findings reveal measurable trust gaps that must be addressed before
LAAC can be reliably deployed in high-stakes communication scenarios.

</details>


### [88] [LLM-as-a-Judge is Bad, Based on AI Attempting the Exam Qualifying for the Member of the Polish National Board of Appeal](https://arxiv.org/abs/2511.04205)
*Michał Karp,Anna Kubaszewska,Magdalena Król,Robert Król,Aleksander Smywiński-Pohl,Mateusz Szymański,Witold Wydmański*

Main category: cs.CL

TL;DR: 大型语言模型在波兰国家申诉委员会考试中表现不佳，尤其是在实践写作部分。


<details>
  <summary>Details</summary>
Motivation: 评估当前大型语言模型（LLMs）能否通过波兰国家申诉委员会（Krajowa Izba Odwoławcza）的官方资格考试。

Method: 对两种LLM的应用方式进行了研究：一是将其作为实际的考生，二是采用‘LLM-as-a-judge’的方法，即由其他模型自动评估LLM生成的答案。研究描述了考试的结构（包括公共采购法知识测试和判决书写作），并提出了用于支持模型的混合信息检索和提取流程。测试了包括GPT-4.1、Claude 4 Sonnet和Bielik-11B-v2.6在内的多种LLM在闭卷和不同检索增强生成（Retrieval-Augmented Generation）设置下的表现。

Result: 尽管模型在知识测试中取得了满意的分数，但在实践写作部分均未达到及格线。‘LLM-as-a-judge’的评估结果与官方委员会的判断存在显著差异。

Conclusion: 尽管技术进步迅速，但目前的大型语言模型在波兰公共采购诉讼中尚不能取代人类法官或独立考官。研究强调了LLM的局限性，包括易出现幻觉、法律条文引用错误、逻辑论证薄弱，以及法律专家与技术团队紧密协作的必要性。

Abstract: This study provides an empirical assessment of whether current large language
models (LLMs) can pass the official qualifying examination for membership in
Poland's National Appeal Chamber (Krajowa Izba Odwo{\l}awcza). The authors
examine two related ideas: using LLM as actual exam candidates and applying the
'LLM-as-a-judge' approach, in which model-generated answers are automatically
evaluated by other models. The paper describes the structure of the exam, which
includes a multiple-choice knowledge test on public procurement law and a
written judgment, and presents the hybrid information recovery and extraction
pipeline built to support the models. Several LLMs (including GPT-4.1, Claude 4
Sonnet and Bielik-11B-v2.6) were tested in closed-book and various
Retrieval-Augmented Generation settings. The results show that although the
models achieved satisfactory scores in the knowledge test, none met the passing
threshold in the practical written part, and the evaluations of the
'LLM-as-a-judge' often diverged from the judgments of the official examining
committee. The authors highlight key limitations: susceptibility to
hallucinations, incorrect citation of legal provisions, weaknesses in logical
argumentation, and the need for close collaboration between legal experts and
technical teams. The findings indicate that, despite rapid technological
progress, current LLMs cannot yet replace human judges or independent examiners
in Polish public procurement adjudication.

</details>


### [89] [REMIND: Input Loss Landscapes Reveal Residual Memorization in Post-Unlearning LLMs](https://arxiv.org/abs/2511.04228)
*Liran Cohen,Yaniv Nemcovesky,Avi Mendelson*

Main category: cs.CL

TL;DR: 机器学习遗忘旨在无需完全重新训练即可从模型中移除特定训练数据的影响，但现有评估方法可能无法检测到语义相似样本中残留的影响。本文提出REMIND（Residual Memorization In Neighborhood Dynamics）新评估方法，通过分析模型在微小输入变化上的损失，检测遗忘数据的残留影响，并判断数据是否已有效遗忘。REMIND表明，已遗忘数据会导致更平坦的损失曲线，而保留或无关数据则表现出更陡峭、更不稳定的模式。REMIND仅需查询访问，优于现有方法，且在不同模型、数据集和释义输入上表现稳健，适用于实际部署。


<details>
  <summary>Details</summary>
Motivation: 现有机器学习遗忘的评估方法仅评估单个输入，可能忽略语义相似样本中残留的影响，从而导致隐私泄露。因此，需要一种新的评估方法来检测这种细微的残留影响。

Method: REMIND通过分析模型在输入微小变化下的损失函数来评估遗忘效果。它通过观察损失景观的平坦度来区分已遗忘数据和未遗忘数据。

Result: REMIND能够检测到现有方法忽略的残留影响，并能区分已遗忘、保留或无关的数据。该方法在不同模型、数据集和释义输入下均表现出稳健性。

Conclusion: REMIND是一种新颖、敏感且可解释的机器学习遗忘评估方法，它通过分析损失景观来检测细微的残留影响，并能有效评估遗忘效果，为语言模型遗忘提供了一个可靠的评估框架。

Abstract: Machine unlearning aims to remove the influence of specific training data
from a model without requiring full retraining. This capability is crucial for
ensuring privacy, safety, and regulatory compliance. Therefore, verifying
whether a model has truly forgotten target data is essential for maintaining
reliability and trustworthiness. However, existing evaluation methods often
assess forgetting at the level of individual inputs. This approach may overlook
residual influence present in semantically similar examples. Such influence can
compromise privacy and lead to indirect information leakage. We propose REMIND
(Residual Memorization In Neighborhood Dynamics), a novel evaluation method
aiming to detect the subtle remaining influence of unlearned data and classify
whether the data has been effectively forgotten. REMIND analyzes the model's
loss over small input variations and reveals patterns unnoticed by single-point
evaluations. We show that unlearned data yield flatter, less steep loss
landscapes, while retained or unrelated data exhibit sharper, more volatile
patterns. REMIND requires only query-based access, outperforms existing methods
under similar constraints, and demonstrates robustness across different models,
datasets, and paraphrased inputs, making it practical for real-world
deployment. By providing a more sensitive and interpretable measure of
unlearning effectiveness, REMIND provides a reliable framework to assess
unlearning in language models. As a result, REMIND offers a novel perspective
on memorization and unlearning.

</details>


### [90] [Reusing Pre-Training Data at Test Time is a Compute Multiplier](https://arxiv.org/abs/2511.04234)
*Alex Fang,Thomas Voice,Ruoming Pang,Ludwig Schmidt,Tom Gunter*

Main category: cs.CL

TL;DR: 预训练方法未能充分利用数据集中的信息，检索增强生成和测试时计算可提高模型性能。


<details>
  <summary>Details</summary>
Motivation: 了解预训练模型从数据中提取知识和信息的效率，以及这种效率如何随模型规模变化。

Method: 使用检索增强生成（RAG）和测试时计算来量化预训练过程中数据集价值的流失，并分析其随模型规模的变化。

Result: 在MMLU、Math-500和SimpleQA数据集上，预训练后进行检索能显著提高准确性。对于MMLU，检索的计算效益约是单独预训练的5倍。通过测试时解析检索到的上下文，LLaMA 3.1 8B模型在MMLU上的性能提升了10个百分点。

Conclusion: 当前的预训练方法未能充分利用现有预训练数据集中的信息，这为进一步的研究和改进留下了巨大的空间。

Abstract: Large language models learn from their vast pre-training corpora, gaining the
ability to solve an ever increasing variety of tasks; yet although researchers
work to improve these datasets, there is little effort to understand how
efficient the pre-training apparatus is at extracting ideas and knowledge from
the data. In this work, we use retrieval augmented generation along with
test-time compute as a way to quantify how much dataset value was left behind
by the process of pre-training, and how this changes across scale. We
demonstrate that pre-training then retrieving from standard and largely
open-sourced datasets results in significant accuracy gains in MMLU, Math-500,
and SimpleQA, which persist through decontamination. For MMLU we observe that
retrieval acts as a ~5x compute multiplier versus pre-training alone. We show
that these results can be further improved by leveraging additional compute at
test time to parse the retrieved context, demonstrating a 10 percentage point
improvement on MMLU for the public LLaMA 3.1 8B model. Overall, our results
suggest that today's pre-training methods do not make full use of the
information in existing pre-training datasets, leaving significant room for
progress.

</details>


### [91] [Efficient Topic Extraction via Graph-Based Labeling: A Lightweight Alternative to Deep Models](https://arxiv.org/abs/2511.04248)
*Salma Mekaoui,Hiba Sofyan,Imane Amaaz,Imane Benchrif,Arsalane Zarghili,Ilham Chaker,Nikola S. Nikolov*

Main category: cs.CL

TL;DR: 本研究提出一种计算资源需求更少、更具可解释性的主题词标注方法。


<details>
  <summary>Details</summary>
Motivation: 现有主题提取方法计算成本高，且主题可解释性差。本研究旨在通过概率统计方法（如主题模型）寻找计算资源需求更少且可解释性更强的主题词标注方法。

Method: 提出一种无监督、基于图的方法，通过分析主题词之间的关系来为主题分配有意义的标签，并与现有基准（包括ChatGPT-3.5）进行了比较。

Result: 在两个不同的数据集上，本研究提出的方法在BERTScore和余弦相似度方面优于传统基准，并且在计算效率方面与ChatGPT-3.5相当。

Conclusion: 本研究提出的基于图的方法在计算效率和标注准确性方面均表现良好，为主题标注领域提供了有前景的方向。

Abstract: Extracting topics from text has become an essential task, especially with the
rapid growth of unstructured textual data. Most existing works rely on highly
computational methods to address this challenge. In this paper, we argue that
probabilistic and statistical approaches, such as topic modeling (TM), can
offer effective alternatives that require fewer computational resources. TM is
a statistical method that automatically discovers topics in large collections
of unlabeled text; however, it produces topics as distributions of
representative words, which often lack clear interpretability. Our objective is
to perform topic labeling by assigning meaningful labels to these sets of
words. To achieve this without relying on computationally expensive models, we
propose a graph-based approach that not only enriches topic words with
semantically related terms but also explores the relationships among them. By
analyzing these connections within the graph, we derive suitable labels that
accurately capture each topic's meaning. We present a comparative study between
our proposed method and several benchmarks, including ChatGPT-3.5, across two
different datasets. Our method achieved consistently better results than
traditional benchmarks in terms of BERTScore and cosine similarity and produced
results comparable to ChatGPT-3.5, while remaining computationally efficient.
Finally, we discuss future directions for topic labeling and highlight
potential research avenues for enhancing interpretability and automation.

</details>


### [92] [SSPO: Subsentence-level Policy Optimization](https://arxiv.org/abs/2511.04256)
*Kun Yang,Zikang chen,Yanmeng Wang,Zhigen Li*

Main category: cs.CL

TL;DR: SSPO通过引入句子级重要性比率，平衡了GRPO和GSPO的优缺点，解决了训练不稳定和数据利用率低的问题，并在多个数据集上取得了领先的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的RLVR算法如GRPO和GSPO存在策略更新不稳定和采样数据利用率低的问题。GRPO的token级重要性比率易受异常值影响导致训练崩溃；GSPO的响应级重要性比率虽然解决了高方差问题，但容易因极端值导致整个响应被错误丢弃，降低了数据利用率。

Method: 提出SSPO算法，采用句子级重要性比率，以平衡GRPO和GSPO。SSPO结合了PPO-CLIP和句子熵，用于稳定调整裁剪边界，鼓励高熵token进行探索，并缩小低熵token的裁剪范围。

Result: SSPO在五个数据集上的平均得分达到46.57，超过了GRPO（43.01）和GSPO（44.42），并在三个数据集上取得了最先进的性能。

Conclusion: SSPO有效地利用了生成的数据，借鉴了GSPO的优点并克服了其缺点，在提高LLM推理能力方面表现出色。

Abstract: As a significant part of post-training of the Large Language Models (LLMs),
Reinforcement Learning from Verifiable Reward (RLVR) has greatly improved LLMs'
reasoning skills. However, some RLVR algorithms, such as GRPO (Group Relative
Policy Optimization) and GSPO (Group Sequence Policy Optimization), are
observed to suffer from unstable policy updates and low usage of sampling data,
respectively. The importance ratio of GRPO is calculated at the token level,
which focuses more on optimizing a single token. This will be easily affected
by outliers, leading to model training collapse. GSPO proposed the calculation
of the response level importance ratio, which solves the problem of high
variance and training noise accumulation in the calculation of the GRPO
importance ratio. However, since all the response tokens share a common
importance ratio, extreme values can easily raise or lower the overall mean,
leading to the entire response being mistakenly discarded, resulting in a
decrease in the utilization of sampled data. This paper introduces SSPO, which
applies sentence-level importance ratio, taking the balance between GRPO and
GSPO. SSPO not only avoids training collapse and high variance, but also
prevents the whole response tokens from being abandoned by the clipping
mechanism. Furthermore, we apply sentence entropy to PPO-CLIP to steadily
adjust the clipping bounds, encouraging high-entropy tokens to explore and
narrow the clipping range of low-entropy tokens. In particular, SSPO achieves
an average score of 46.57 across five datasets, surpassing GRPO (43.01) and
GSPO (44.42), and wins state-of-the-art performance on three datasets. These
results highlight SSPO's effectiveness in leveraging generated data by taking
the essence of GSPO but rejecting its shortcomings.

</details>


### [93] [Dynamic Jointly Batch Selection for Data Efficient Machine Translation Fine-Tuning](https://arxiv.org/abs/2511.04406)
*Mohammad Amin Ghanizadeh,Mohammad Javad Dousti*

Main category: cs.CL

TL;DR: 该研究提出了一种用于微调机器翻译模型的数据选择方法，通过学习能力得分和批次选择策略来提高数据效率和翻译性能。


<details>
  <summary>Details</summary>
Motivation: 数据质量和有效选择是提高机器翻译模型性能的基础，对于构建鲁棒可靠的翻译系统至关重要。

Method: 提出了一种数据选择方法，利用学习者模型和预训练参考模型之间的协同作用，通过定义学习能力得分来评估数据点的效用，并采用考虑数据点之间相互依赖性的批次选择策略。

Result: 在英译波斯及其他语言对的mBART模型上进行了实验，发现在CCMatrix数据集上进行微调时，该方法相比iid基线在数据效率上最多可提高五倍。使用缓存嵌入时，计算效率提高了24倍，并能获得优于随机选择方法的翻译性能。

Conclusion: 所提出的数据选择方法能够显著提高机器翻译模型的训练效率和翻译性能，同时降低计算成本。

Abstract: Data quality and its effective selection are fundamental to improving the
performance of machine translation models, serving as cornerstones for
achieving robust and reliable translation systems. This paper presents a data
selection methodology specifically designed for fine-tuning machine translation
systems, which leverages the synergy between a learner model and a pre-trained
reference model to enhance overall training effectiveness. By defining a
learnability score, our approach systematically evaluates the utility of data
points for training, ensuring that only the most relevant and impactful
examples contribute to the fine-tuning process. Furthermore, our method employs
a batch selection strategy which considers interdependencies among data points,
optimizing the efficiency of the training process while maintaining a focus on
data relevance. Experiments on English to Persian and several other language
pairs using an mBART model fine-tuned on the CCMatrix dataset demonstrate that
our method can achieve up to a fivefold improvement in data efficiency compared
to an iid baseline. Experimental results indicate that our approach improves
computational efficiency by 24 when utilizing cached embeddings, as it requires
fewer training data points. Additionally, it enhances generalization, resulting
in superior translation performance compared to random selection method.

</details>


### [94] [If I Could Turn Back Time: Temporal Reframing as a Historical Reasoning Task for LLMs](https://arxiv.org/abs/2511.04432)
*Lars Bungum,Charles Yijia Huang,Abeer Kashar*

Main category: cs.CL

TL;DR: LLMs在1940年的挪威书籍背景下进行时间推理，英文提示优于挪威文提示，更大的模型效果更好。


<details>
  <summary>Details</summary>
Motivation: 评估大型语言模型（LLMs）在特定历史背景下进行时间推理的能力。

Method: 使用一本1940年的挪威书籍中的琐事问题，要求LLMs扮演1940年的角色回答问题，并进行英文和挪威文的提示测试。使用LLM作为裁判进行评分，并由母语者进行抽样检查。

Result: 英文提示比挪威文提示效果更好，这出乎意料。更大的LLMs在任务中表现更好。测试了DeepSeek-R1、Gemma3、Qwen3和Llama3.1模型系列，以及一个专门为挪威语设计的最大可用LLM。

Conclusion: 在特定历史背景下，LLMs的时间推理能力可以通过调整提示语言（英文优于挪威文）和模型规模（更大模型效果更好）来提升。

Abstract: In this study, we experiment with the ability of LLMs to do temporal
reasoning. Using a Norwegian book from 1940 containing trivia questions, we
prompt the LLMs to answer the questions as if it were 1940. We also pose the
questions in both English and Norwegian. Correct answers are often presented as
sentences, and grading is done by means of LLM-as-judge, with sampled checks by
a native speaker. Prompting in English consistently gave better results than in
Norwegian, an unexpected result. In contrast, using larger LLMs improved
results. We tested the DeepSeek-R1, Gemma3, Qwen3, and Llama3.1 model families,
and also the largest available LLM especially crafted for Norwegian.

</details>


### [95] [Probabilistic Textual Time Series Depression Detection](https://arxiv.org/abs/2511.04476)
*Fabian Schmidt,Seyedehmoniba Ravan,Vladimir Vlassov*

Main category: cs.CL

TL;DR: PTTSD是一个概率性文本时间序列抑郁检测框架，可以从临床访谈中预测PHQ-8分数，同时对时间进行不确定性建模，并在E-DAIC和DAIC-WOZ数据集上实现了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 临床决策支持需要准确且可解释的抑郁严重程度预测，但现有模型往往缺乏不确定性估计和时间建模能力。

Method: PTTSD框架包含序列到序列和序列到一的变体，结合了双向LSTM、自注意力、残差连接以及高斯或学生t输出头，并通过负对数似然进行训练。

Result: PTTSD在E-DAIC和DAIC-WOZ数据集上取得了最先进的文本唯一系统性能（例如，E-DAIC上的MAE为3.85，DAIC上的MAE为3.55），并产生了预测区间良好的校准。

Conclusion: 消融研究证实了注意力和概率建模的价值，与MentalBERT的比较确立了其通用性，而三部分校准分析和案例研究进一步强调了不确定性感知预测的可解释性和临床相关性。

Abstract: Accurate and interpretable predictions of depression severity are essential
for clinical decision support, yet existing models often lack uncertainty
estimates and temporal modeling. We propose PTTSD, a Probabilistic Textual Time
Series Depression Detection framework that predicts PHQ-8 scores from
utterance-level clinical interviews while modeling uncertainty over time. PTTSD
includes sequence-to-sequence and sequence-to-one variants, both combining
bidirectional LSTMs, self-attention, and residual connections with Gaussian or
Student-t output heads trained via negative log-likelihood. Evaluated on E-DAIC
and DAIC-WOZ, PTTSD achieves state-of-the-art performance among text-only
systems (e.g., MAE = 3.85 on E-DAIC, 3.55 on DAIC) and produces well-calibrated
prediction intervals. Ablations confirm the value of attention and
probabilistic modeling, while comparisons with MentalBERT establish generality.
A three-part calibration analysis and qualitative case studies further
highlight the interpretability and clinical relevance of uncertainty-aware
forecasting.

</details>


### [96] [ThaiOCRBench: A Task-Diverse Benchmark for Vision-Language Understanding in Thai](https://arxiv.org/abs/2511.04479)
*Surapon Nonesung,Teetouch Jaknamon,Sirinya Chaiophat,Natapong Nitarach,Chanakan Wittayasakpan,Warit Sirichotedumrong,Adisai Na-Thalang,Kunat Pipatanakul*

Main category: cs.CL

TL;DR: ThaiOCRBench 是第一个针对泰语文本密集型视觉理解任务的综合基准，评估了各种视觉语言模型（VLM），并指出了专有模型优于开源模型的性能差距，特别是在细粒度文本识别和手写内容提取方面。


<details>
  <summary>Details</summary>
Motivation: 现有的视觉语言模型基准主要集中在高资源语言上，而泰语（一种脚本复杂的语言）在包括文档结构理解在内的任务中代表性不足。

Method: 创建了一个包含 2,808 个样本、跨越 13 个任务类别的多样化、人工标注的数据集（ThaiOCRBench），并在零样本设置下评估了各种最先进的视觉语言模型（包括专有和开源模型）。

Result: 在零样本设置下，专有模型（如 Gemini 2.5 Pro）的性能显著优于开源模型。开源模型在细粒度文本识别和手写内容提取方面表现出最大的性能下降。通过错误分析，确定了语言偏见、结构不匹配和内容幻觉等挑战。

Conclusion: ThaiOCRBench 为评估低资源、脚本复杂环境中的视觉语言模型提供了一个标准化的框架，并为改进泰语文档理解提供了可操作的见解。

Abstract: We present ThaiOCRBench, the first comprehensive benchmark for evaluating
vision-language models (VLMs) on Thai text-rich visual understanding tasks.
Despite recent progress in multimodal modeling, existing benchmarks
predominantly focus on high-resource languages, leaving Thai underrepresented,
especially in tasks requiring document structure understanding. ThaiOCRBench
addresses this gap by offering a diverse, human-annotated dataset comprising
2,808 samples across 13 task categories. We evaluate a wide range of
state-of-the-art VLMs in a zero-shot setting, spanning both proprietary and
open-source systems. Results show a significant performance gap, with
proprietary models (e.g., Gemini 2.5 Pro) outperforming open-source
counterparts. Notably, fine-grained text recognition and handwritten content
extraction exhibit the steepest performance drops among open-source models.
Through detailed error analysis, we identify key challenges such as language
bias, structural mismatch, and hallucinated content. ThaiOCRBench provides a
standardized framework for assessing VLMs in low-resource, script-complex
settings, and provides actionable insights for improving Thai-language document
understanding.

</details>


### [97] [RUST-BENCH: Benchmarking LLM Reasoning on Unstructured Text within Structured Tables](https://arxiv.org/abs/2511.04491)
*Nikhil Abhyankar,Purvi Chaurasia,Sanchit Kabra,Ananya Srivastava,Vivek Gupta,Chandan K. Reddy*

Main category: cs.CL

TL;DR: RUST-BENCH是一个包含7966个问题和2031个真实世界表格的新基准，用于评估大型语言模型（LLM）在处理复杂、异构表格数据时的推理能力，发现LLM在处理异构模式和复杂多跳推理方面存在不足。


<details>
  <summary>Details</summary>
Motivation: 现有表格推理基准无法充分反映真实世界数据的复杂性，例如长表格、异构模式、领域特定性和多跳推理需求，因此需要新的基准来更全面地评估大型语言模型（LLM）的推理能力。

Method: 创建了一个名为RUST-BENCH的新基准，其中包含来自RB-Science（NSF资助记录）和RB-Sports（NBA统计）两个领域的2031个真实世界表格中的7966个问题。该基准评估LLM在规模、异构性、领域特异性和推理复杂性方面的综合能力。

Result: 在RUST-BENCH基准上的实验表明，无论是开源还是专有的大型语言模型（LLM）在处理异构模式和复杂的、多跳推理方面都面临挑战，这暴露了当前模型架构和提示策略的持续不足。

Conclusion: RUST-BENCH提供了一个具有挑战性的新测试平台，用于推动表格推理研究的进展，并突显了在处理真实世界表格数据时LLM所面临的现有局限性。

Abstract: Existing tabular reasoning benchmarks mostly test models on small, uniform
tables, underrepresenting the complexity of real-world data and giving an
incomplete view of Large Language Models' (LLMs) reasoning abilities. Real
tables are long, heterogeneous, and domain-specific, mixing structured fields
with free text and requiring multi-hop reasoning across thousands of tokens. To
address this gap, we introduce RUST-BENCH, a benchmark of 7966 questions from
2031 real-world tables spanning two domains: i) RB-Science (NSF grant records)
and ii) RB-Sports (NBA statistics). Unlike prior work, RUST-BENCH evaluates
LLMs jointly across scale, heterogeneity, domain specificity, and reasoning
complexity. Experiments with open-source and proprietary models show that LLMs
struggle with heterogeneous schemas and complex multi-hop inference, revealing
persistent weaknesses in current architectures and prompting strategies.
RUST-BENCH establishes a challenging new testbed for advancing tabular
reasoning research.

</details>


### [98] [OUNLP at TSAR 2025 Shared Task: Multi-Round Text Simplifier via Code Generation](https://arxiv.org/abs/2511.04495)
*Cuong Huynh,Jie Cao*

Main category: cs.CL

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: This paper describes the OUNLP system submitted to the TSAR-2025 Shared Task
(Alva-Manchego et al., 2025), designed for readability-controlled text
simplification using LLM-prompting-based generation. Based on the analysis of
prompt-based text simplification methods, we discovered an interesting finding
that text simplification performance is highly related to the gap between the
source CEFR (Arase et al., 2022) level and the target CEFR level. Inspired by
this finding, we propose two multi-round simplification methods and generate
them via GPT-4o: rule-based simplification (MRS-Rule) and jointly rule-based
LLM simplification (MRS-Joint). Our submitted systems ranked 7 out of 20 teams.
Later improvements with MRS-Joint show that taking the LLM simplified
candidates as the starting point could further boost the multi-round
simplification performance.

</details>


### [99] [Decoding Emergent Big Five Traits in Large Language Models: Temperature-Dependent Expression and Architectural Clustering](https://arxiv.org/abs/2511.04499)
*Christos-Nikolaos Zacharopoulos,Revekka Kyriakoglou*

Main category: cs.CL

TL;DR: LLM的研究表明，它们在四个维度上表现出显著的个性差异，其中神经质和外向性受温度调整影响，并且模型架构可能影响其个性特征的稳定性。


<details>
  <summary>Details</summary>
Motivation: 为了负责任地开发和部署LLM，理解其类似人格的行为变得越来越重要。

Method: 使用大五人格量表-2（BFI-2）框架评估六个LLM在不同采样温度下的特质表达，并通过分层聚类揭示模型集群。

Result: 研究发现，LLM在四个主要人格维度上存在显著差异，神经质和外向性受温度影响，并且不同的模型架构导致了稳定的特质分布。

Conclusion: LLM中出现的类似人格的模式为模型调整、选择和AI系统的伦理治理提供了新的视角。

Abstract: As Large Language Models (LLMs) become integral to human-centered
applications, understanding their personality-like behaviors is increasingly
important for responsible development and deployment. This paper systematically
evaluates six LLMs, applying the Big Five Inventory-2 (BFI-2) framework, to
assess trait expressions under varying sampling temperatures. We find
significant differences across four of the five personality dimensions, with
Neuroticism and Extraversion susceptible to temperature adjustments. Further,
hierarchical clustering reveals distinct model clusters, suggesting that
architectural features may predispose certain models toward stable trait
profiles. Taken together, these results offer new insights into the emergence
of personality-like patterns in LLMs and provide a new perspective on model
tuning, selection, and the ethical governance of AI systems. We share the data
and code for this analysis here:
https://osf.io/bsvzc/?view_only=6672219bede24b4e875097426dc3fac1

</details>


### [100] [RAGalyst: Automated Human-Aligned Agentic Evaluation for Domain-Specific RAG](https://arxiv.org/abs/2511.04502)
*Joshua Gao,Quoc Huy Pham,Subin Varghese,Silwal Saurav,Vedhus Hoskere*

Main category: cs.CL

TL;DR: RAGalyst是一个自动化的、与人类对齐的智能框架，用于领域特定检索增强生成（RAG）系统的严格评估，通过生成合成数据集和优化LLM-as-a-Judge指标来解决现有评估方法的不足。


<details>
  <summary>Details</summary>
Motivation: 现有RAG评估方法在专业、安全关键领域存在挑战，依赖启发式指标或未经人类判断验证的LLM-as-a-Judge方法。

Method: RAGalyst构建了一个智能流水线，用于从源文档生成高质量的合成问答（QA）数据集，并包含一个智能过滤步骤以确保数据保真度。该框架通过提示优化改进了两个关键的LLM-as-a-Judge指标——答案正确性（Answer Correctness）和可回答性（Answerability），以使其与人类标注高度相关。

Result: 在军事行动、网络安全和桥梁工程三个不同领域应用RAGalyst评估各种RAG组件后，发现性能高度依赖于上下文，没有单一的嵌入模型、LLM或超参数配置是普遍最优的。此外，还分析了RAG中导致答案正确性低的最常见原因。

Conclusion: RAGalyst等系统性评估框架是必要的，它使实践者能够揭示领域特定的权衡，并为构建可靠有效的RAG系统做出明智的设计选择。

Abstract: Retrieval-Augmented Generation (RAG) is a critical technique for grounding
Large Language Models (LLMs) in factual evidence, yet evaluating RAG systems in
specialized, safety-critical domains remains a significant challenge. Existing
evaluation frameworks often rely on heuristic-based metrics that fail to
capture domain-specific nuances and other works utilize LLM-as-a-Judge
approaches that lack validated alignment with human judgment. This paper
introduces RAGalyst, an automated, human-aligned agentic framework designed for
the rigorous evaluation of domain-specific RAG systems. RAGalyst features an
agentic pipeline that generates high-quality, synthetic question-answering (QA)
datasets from source documents, incorporating an agentic filtering step to
ensure data fidelity. The framework refines two key LLM-as-a-Judge
metrics-Answer Correctness and Answerability-using prompt optimization to
achieve a strong correlation with human annotations. Applying this framework to
evaluate various RAG components across three distinct domains (military
operations, cybersecurity, and bridge engineering), we find that performance is
highly context-dependent. No single embedding model, LLM, or hyperparameter
configuration proves universally optimal. Additionally, we provide an analysis
on the most common low Answer Correctness reasons in RAG. These findings
highlight the necessity of a systematic evaluation framework like RAGalyst,
which empowers practitioners to uncover domain-specific trade-offs and make
informed design choices for building reliable and effective RAG systems.
RAGalyst is available on our Github.

</details>


### [101] [Modeling Clinical Uncertainty in Radiology Reports: from Explicit Uncertainty Markers to Implicit Reasoning Pathways](https://arxiv.org/abs/2511.04506)
*Paloma Rabaey,Jong Hak Moon,Jung-Oh Lee,Min Gwan Kim,Hangyul Yoon,Thomas Demeester,Edward Choi*

Main category: cs.CL

TL;DR: 该研究提出了一种处理放射学报告中显式和隐式不确定性的框架，并发布了一个名为 Lunguage++ 的扩展数据集，以支持不确定性感知和诊断推理。


<details>
  <summary>Details</summary>
Motivation: 放射学报告在临床决策中至关重要，但其中包含的不确定性（显式和隐式）阻碍了其自动化分析。本研究旨在解决这一挑战。

Method: 该研究提出了一个两部分框架：1. 通过专家验证的、基于 LLM 的参考排名来量化显式不确定性，并将每个发现映射到基于此参考的概率值。2. 通过一个扩展框架来模拟隐式不确定性，该框架系统地添加了专家定义的 14 种常见诊断的特征子发现。

Result: 发布了一个名为 Lunguage++ 的数据集，这是 Lunguage 基准测试的一个扩展版本，不确定性更高，并且可以进行细粒度的结构化放射学报告。该数据集支持不确定性感知图像分类、忠实的诊断推理以及对诊断不确定性临床影响的新研究。

Conclusion: 所提出的框架和 Lunguage++ 数据集能够更好地处理放射学报告中的不确定性，从而提高自动化分析的准确性和临床相关性。

Abstract: Radiology reports are invaluable for clinical decision-making and hold great
potential for automated analysis when structured into machine-readable formats.
These reports often contain uncertainty, which we categorize into two distinct
types: (i) Explicit uncertainty reflects doubt about the presence or absence of
findings, conveyed through hedging phrases. These vary in meaning depending on
the context, making rule-based systems insufficient to quantify the level of
uncertainty for specific findings; (ii) Implicit uncertainty arises when
radiologists omit parts of their reasoning, recording only key findings or
diagnoses. Here, it is often unclear whether omitted findings are truly absent
or simply unmentioned for brevity. We address these challenges with a two-part
framework. We quantify explicit uncertainty by creating an expert-validated,
LLM-based reference ranking of common hedging phrases, and mapping each finding
to a probability value based on this reference. In addition, we model implicit
uncertainty through an expansion framework that systematically adds
characteristic sub-findings derived from expert-defined diagnostic pathways for
14 common diagnoses. Using these methods, we release Lunguage++, an expanded,
uncertainty-aware version of the Lunguage benchmark of fine-grained structured
radiology reports. This enriched resource enables uncertainty-aware image
classification, faithful diagnostic reasoning, and new investigations into the
clinical impact of diagnostic uncertainty.

</details>


### [102] [Are language models aware of the road not taken? Token-level uncertainty and hidden state dynamics](https://arxiv.org/abs/2511.04527)
*Amir Zur,Atticus Geiger,Ekdeep Singh Lubana,Eric Bigelow*

Main category: cs.CL

TL;DR: 语言模型在生成文本时，单个词元的选择可能导致不同的推理路径，从而难以量化不确定性。本研究旨在探讨推理语言模型是否能表示其在生成过程中可能采取的替代路径。通过使用隐藏激活来控制和预测模型在链式思考推理中的不确定性，我们发现模型在不同词元处的不确定性与其激活易控性之间存在明显相关性。这表明，当模型有多种可用路径时，即尚未确定最终答案时，激活干预最为有效。此外，隐藏激活能够预测模型未来的输出分布，证明了模型内隐地表示了各种可能路径的空间。


<details>
  <summary>Details</summary>
Motivation: 本研究的动机是解决语言模型在生成文本时，由于单个词元选择导致推理路径分化，从而难以量化不确定性的问题。研究旨在检验推理语言模型是否能表示其可能采取的替代推理路径。

Method: 本研究通过使用隐藏激活来控制和预测语言模型在进行链式思考推理（chain-of-thought reasoning）过程中的不确定性，以此来检验模型是否会表示其可能采取的替代路径。

Result: 实验发现，模型在不同词元处的不确定性与其激活易控性之间存在明显相关性。这表明，当模型存在多种可能的推理路径（即尚未确定最终答案）时，通过控制激活来进行干预最为有效。此外，研究还发现隐藏激活能够预测模型未来的输出分布，证明了模型内隐地表示了其可能采取的各种推理路径。

Conclusion: 研究结论是，语言模型在生成过程中确实会内隐地表示其可能采取的各种推理路径。隐藏激活的变化与模型的不确定性及可控性相关，并且能够预测模型未来的输出分布，这证明了模型并非沿着单一路径进行推理，而是存在一个潜在的路径空间。

Abstract: When a language model generates text, the selection of individual tokens
might lead it down very different reasoning paths, making uncertainty difficult
to quantify. In this work, we consider whether reasoning language models
represent the alternate paths that they could take during generation. To test
this hypothesis, we use hidden activations to control and predict a language
model's uncertainty during chain-of-thought reasoning. In our experiments, we
find a clear correlation between how uncertain a model is at different tokens,
and how easily the model can be steered by controlling its activations. This
suggests that activation interventions are most effective when there are
alternate paths available to the model -- in other words, when it has not yet
committed to a particular final answer. We also find that hidden activations
can predict a model's future outcome distribution, demonstrating that models
implicitly represent the space of possible paths.

</details>


### [103] [IntelliProof: An Argumentation Network-based Conversational Helper for Organized Reflection](https://arxiv.org/abs/2511.04528)
*Kaveh Eskandari Miandoab,Katharine Kowalyshyn,Kabir Pamnani,Anesu Gavhera,Vasanth Sarathy,Matthias Scheutz*

Main category: cs.CL

TL;DR: IntelliProof是一个交互式系统，利用大型语言模型（LLM）来分析论证性散文。它将散文构建为论证图，其中节点代表论点，节点属性代表支持证据，边表示支持或攻击关系。该系统侧重于用户体验，由LLM对关系进行分类和评分，并进行可视化。它还提供分类依据和文章连贯性的量化指标，并提供自然语言工具来帮助用户理解文章及其论证图。


<details>
  <summary>Details</summary>
Motivation: 现有的自动论文评分系统未能充分满足用户对论证性散文分析的需求，而IntelliProof旨在通过提供一个强调用户体验的交互式系统来解决这一问题。

Method: IntelliProof将散文构建为论证图，其中论点是节点，证据是节点属性，边表示关系。使用LLM对关系进行分类和评分，然后进行可视化。提供分类依据和文章连贯性的量化指标。提供自然语言工具来帮助用户理解文章及其论证图。

Result: 该系统能够快速探索论证质量，同时保留人工监督。它弥合了论证性散文的结构语义与用户对给定文本的理解之间的差距。

Conclusion: IntelliProof通过提供一个交互式、可视化的论证图，并结合LLM的分析能力和用户监督，为分析论证性散文提供了一个创新的方法，从而提高了对文章论证结构和连贯性的理解。

Abstract: We present IntelliProof, an interactive system for analyzing argumentative
essays through LLMs. IntelliProof structures an essay as an argumentation
graph, where claims are represented as nodes, supporting evidence is attached
as node properties, and edges encode supporting or attacking relations. Unlike
existing automated essay scoring systems, IntelliProof emphasizes the user
experience: each relation is initially classified and scored by an LLM, then
visualized for enhanced understanding. The system provides justifications for
classifications and produces quantitative measures for essay coherence. It
enables rapid exploration of argumentative quality while retaining human
oversight. In addition, IntelliProof provides a set of tools for a better
understanding of an argumentative essay and its corresponding graph in natural
language, bridging the gap between the structural semantics of argumentative
essays and the user's understanding of a given text. A live demo and the system
are available here to try: \textbf{https://intelliproof.vercel.app}

</details>


### [104] [From Model to Breach: Towards Actionable LLM-Generated Vulnerabilities Reporting](https://arxiv.org/abs/2511.04538)
*Cyril Vallez,Alexander Sternfeld,Andrei Kucharavy,Ljiljana Dolamic*

Main category: cs.CL

TL;DR: 最新的开源代码大模型在代码生成中仍然存在最早报告的漏洞，


<details>
  <summary>Details</summary>
Motivation: LLM代码助手在软件开发中越来越重要，但它们生成的bug对网络安全构成威胁。尽管已有LLM代码安全基准和改进方法，但对广泛使用的大模型影响尚不清楚。

Method: 提出一个新的评估指标——提示暴露度（PE），用于衡量LLM生成漏洞的风险，考虑了漏洞严重性、生成概率和提示的诱导性。在此基础上，定义了模型暴露度（ME）分数，以量化模型生成漏洞的严重性和普遍性。

Result: 即使是最新开源模型在早期报告的漏洞场景中也易受攻击，表明安全与功能性的权衡阻碍了漏洞的有效修复。

Conclusion: LLM生成的漏洞对网络安全构成挑战，需要新的评估指标（如PE和ME）来衡量和减轻这些风险，以推动模型开发者修复最严重和最普遍的漏洞。

Abstract: As the role of Large Language Models (LLM)-based coding assistants in
software development becomes more critical, so does the role of the bugs they
generate in the overall cybersecurity landscape. While a number of LLM code
security benchmarks have been proposed alongside approaches to improve the
security of generated code, it remains unclear to what extent they have
impacted widely used coding LLMs. Here, we show that even the latest
open-weight models are vulnerable in the earliest reported vulnerability
scenarios in a realistic use setting, suggesting that the safety-functionality
trade-off has until now prevented effective patching of vulnerabilities. To
help address this issue, we introduce a new severity metric that reflects the
risk posed by an LLM-generated vulnerability, accounting for vulnerability
severity, generation chance, and the formulation of the prompt that induces
vulnerable code generation - Prompt Exposure (PE). To encourage the mitigation
of the most serious and prevalent vulnerabilities, we use PE to define the
Model Exposure (ME) score, which indicates the severity and prevalence of
vulnerabilities a model generates.

</details>


### [105] [BanglaMedQA and BanglaMMedBench: Evaluating Retrieval-Augmented Generation Strategies for Bangla Biomedical Question Answering](https://arxiv.org/abs/2511.04560)
*Sadia Sultana,Saiyma Sittul Muna,Mosammat Zannatul Samarukh,Ajwad Abrar,Tareque Mohmud Chowdhury*

Main category: cs.CL

TL;DR: 本研究发布了首个孟加拉语生物医学多选题数据集BanglaMedQA和BanglaMMedBench，并评估了多种检索增强生成(RAG)策略，其中Agentic RAG结合OCR和文本检索，在openai/gpt-oss-120b模型上取得了89.54%的准确率，证明了RAG在提升孟加拉语医疗问答可靠性和可及性方面的潜力。


<details>
  <summary>Details</summary>
Motivation: 在孟加拉语等低资源语言中开发准确的生物医学问答系统具有挑战性，这限制了对可靠医疗知识的公平获取。

Method: 研究发布了BanglaMedQA和BanglaMMedBench数据集，并评估了传统的、零样本后备的、Agentic的、迭代反馈的和聚合的RAG策略，结合了基于教科书和网络的检索以及生成推理。关键创新在于通过OCR集成孟加拉语医学教科书语料库，并实施了一个Agentic RAG流程，该流程动态地在检索和推理策略之间进行选择。

Result: Agentic RAG策略在使用openai/gpt-oss-120b模型时达到了最高的89.54%的准确率，优于其他配置，并展现出卓越的推理质量。

Conclusion: RAG方法有潜力提高孟加拉语医疗问答的可靠性和可及性，为多语言医疗人工智能的未来研究奠定了基础。

Abstract: Developing accurate biomedical Question Answering (QA) systems in
low-resource languages remains a major challenge, limiting equitable access to
reliable medical knowledge. This paper introduces BanglaMedQA and
BanglaMMedBench, the first large-scale Bangla biomedical Multiple Choice
Question (MCQ) datasets designed to evaluate reasoning and retrieval in medical
artificial intelligence (AI). The study applies and benchmarks several
Retrieval-Augmented Generation (RAG) strategies, including Traditional,
Zero-Shot Fallback, Agentic, Iterative Feedback, and Aggregate RAG, combining
textbook-based and web retrieval with generative reasoning to improve factual
accuracy. A key novelty lies in integrating a Bangla medical textbook corpus
through Optical Character Recognition (OCR) and implementing an Agentic RAG
pipeline that dynamically selects between retrieval and reasoning strategies.
Experimental results show that the Agentic RAG achieved the highest accuracy
89.54% with openai/gpt-oss-120b, outperforming other configurations and
demonstrating superior rationale quality. These findings highlight the
potential of RAG-based methods to enhance the reliability and accessibility of
Bangla medical QA, establishing a foundation for future research in
multilingual medical artificial intelligence.

</details>


### [106] [When retrieval outperforms generation: Dense evidence retrieval for scalable fake news detection](https://arxiv.org/abs/2511.04643)
*Alamgir Munir Qazi,John P. McCrae,Jamal Abdul Nasir*

Main category: cs.CL

TL;DR: DeReC是一个轻量级的框架，使用文本嵌入替代LLM来验证事实，效率更高，准确性相当。


<details>
  <summary>Details</summary>
Motivation: 当前事实验证系统因LLM的计算障碍和幻觉风险而面临挑战，需要更高效、可靠的系统。

Method: 提出DeReC框架，结合密集检索和分类，使用通用文本嵌入替代自回归LLM。

Result: DeReC在RAWFC和LIAR-RAW数据集上显著提高了效率（分别减少95%和92%的运行时长），并在RAWFC数据集上获得了比SOTA方法L-Defense更高的F1分数（65.58% vs 61.20%）。

Conclusion: 精心设计的检索系统可以在专业任务上媲美甚至超越LLM的性能，并且更适用于实际部署。

Abstract: The proliferation of misinformation necessitates robust yet computationally
efficient fact verification systems. While current state-of-the-art approaches
leverage Large Language Models (LLMs) for generating explanatory rationales,
these methods face significant computational barriers and hallucination risks
in real-world deployments. We present DeReC (Dense Retrieval Classification), a
lightweight framework that demonstrates how general-purpose text embeddings can
effectively replace autoregressive LLM-based approaches in fact verification
tasks. By combining dense retrieval with specialized classification, our system
achieves better accuracy while being significantly more efficient. DeReC
outperforms explanation-generating LLMs in efficiency, reducing runtime by 95%
on RAWFC (23 minutes 36 seconds compared to 454 minutes 12 seconds) and by 92%
on LIAR-RAW (134 minutes 14 seconds compared to 1692 minutes 23 seconds),
showcasing its effectiveness across varying dataset sizes. On the RAWFC
dataset, DeReC achieves an F1 score of 65.58%, surpassing the state-of-the-art
method L-Defense (61.20%). Our results demonstrate that carefully engineered
retrieval-based systems can match or exceed LLM performance in specialized
tasks while being significantly more practical for real-world deployment.

</details>


### [107] [Logit-Entropy Adaptive Stopping Heuristic for Efficient Chain-of-Thought Reasoning](https://arxiv.org/abs/2511.04654)
*Mohammad Atif Quamar,Mohammad Areeb*

Main category: cs.CL

TL;DR: LEASH是一种训练免费的解码算法，通过监控logit熵斜率和top-logit边际改进来适应性地停止Rationale生成，从而减少token使用和延迟，同时对准确性有很小的影响。


<details>
  <summary>Details</summary>
Motivation: 生成固定的、长Rationale在计算上是浪费的，会增加token使用量和延迟。

Method: LEASH通过监控token级熵的斜率和top-logit边际的改进来适应性地停止Rationale的生成，一旦这两个信号趋于平稳就终止生成。

Result: 与CoT相比，LEASH将平均token生成量减少了30-35%，延迟减少了27%，准确性下降了10个百分点。

Conclusion: LEASH是一种模型无关且无需额外训练或监督的简单有效的CoT解码替代方案。

Abstract: Chain-of-Thought (CoT) prompting is a key technique for enabling complex
reasoning in large language models. However, generating full, fixed-length
rationales is computationally wasteful, inflating both token usage and latency.
We introduce LEASH: Logit-Entropy Adaptive Stopping Heuristic, a training-free
decoding algorithm that adaptively halts rationale generation. LEASH monitors
two intrinsic signals: the slope of token-level entropy and the improvement in
the top-logit margin. It terminates the generation once both signals plateau,
indicating the model has reached a stable reasoning state. Across four
instruction-tuned models on the GSM8K and AQuA-RAT benchmarks, LEASH reduces
average token generation by 30--35% and latency by 27%, while incurring a 10
p.p. accuracy drop relative to CoT. LEASH is model-agnostic and requires no
additional training or supervision, offering a simple and efficient alternative
to CoT decoding.

</details>


<div id='physics.app-ph'></div>

# physics.app-ph [[Back]](#toc)

### [108] [Accurate humidity and pH synchronized measurement with temperature compensation based on polarization maintaining fiber](https://arxiv.org/abs/2511.04203)
*Jia Liu,Jiawen Zhang,Xiyu Liu,Qi Meng,Riming Xu,Jin Wang*

Main category: physics.app-ph

TL;DR: 该研究提出了一种利用改性偏振保持光纤（PMF）实现高精度、实时、多参数（湿度、pH、温度）测量的光纤传感方法。


<details>
  <summary>Details</summary>
Motivation: 现有湿度和pH测量方法存在灵敏度低、信号串扰、系统复杂、无法实时监测等局限性，亟需开发更优的测量技术。

Method: 通过在PMF表面构建复合湿度敏感聚合物（PVA/CNs）薄膜和pH敏感纳米薄膜（PAH/PAA），并结合温度补偿的PMF和多波长矩阵，实现了对湿度、pH和温度的同时实时监测。

Result: 成功制备了集湿度和pH传感功能于一体的光纤传感器，实现了对这两种参数的实时、高精度测量，并有效解决了温度交叉干扰问题。

Conclusion: 所提出的基于PMF的光纤传感方法为实现多参数（湿度、pH、温度）的同时实时监测提供了一种有效途径，并为构建通用的光纤多参数测量平台奠定了基础。

Abstract: Real-time and accurate monitoring of humidity and pH is of great significance
in daily life and industrial production. Existing humidity and pH measurement
suffer from limitations such as low sensitivity, signal crosstalk, complex
system structures, and inability to achieve real-time monitoring. In this work,
the surface of a polarization maintaining fiber (PMF) was functionalized with a
composite humidity-sensitive polymer composed of polyvinyl alcohol (PVA) and
carbon nanosheets (CNs). A humidity-sensitive film with a microporous structure
was prepared on the PMF cladding through high-temperature rapid film formation
and laser processing, enhancing humidity sensitivity and stability. To enable
pH sensing, poly(allylamine hydrochloride) (PAH) and poly (acrylic acid) (PAA)
were successively adsorbed onto the PMF surface via electrostatic
self-assembly, forming a pH-sensitive nanofilm structure. By connecting a
temperature-compensated PMF within the same Sagnac loop and combining it with a
multi-wavelength matrix, simultaneous real-time monitoring of humidity, pH, and
temperature was achieved, effectively solving the issue of temperature
crosstalk and extending toward a universal optical fiber multi-parameter
measurement platform.

</details>


### [109] [Matching frequency response measurements and reduced order models for the inverse identification of viscoelastic properties](https://arxiv.org/abs/2511.04395)
*Linus Taenzer,Paolo Tiso,Bart Van Damme*

Main category: physics.app-ph

TL;DR: 该研究提出了一种结合降阶模型和粒子群优化算法的逆材料表征方法，用于识别聚甲醛（POM）和增材制造烧结陶瓷的粘弹性材料参数，并通过实验数据验证了该方法的有效性及其在处理实际测量数据（如边界条件和噪声）时的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 为了在有限元模拟中精确预测3D打印材料（如陶瓷和聚合物）的机械性能，准确表征其频率依赖性和阻尼行为至关重要，但现有研究对逆材料表征方法的实际验证和应用讨论不足。

Method: 采用结合降阶模型和约束粒子群优化算法的方法，拟合激光多普勒测振仪获得的点测量频率响应函数，以识别聚甲醛（POM）和增材制造烧结陶瓷的粘弹性材料参数（基于粘弹性分数阶导数模型）。

Result: 成功识别了两种材料（POM和烧结陶瓷）的粘弹性分数阶导数模型的参数及其不确定性，并通过动态力学分析（DMA）实验数据验证了方法的有效性，证明了该方法在存在边界条件和噪声等实际实验困难时仍具有适用性。

Conclusion: 所提出的逆材料识别方法能够高质量地识别粘弹性分数阶导数模型的参数及其不确定性，并且该方法适用于处理包含实验数据固有困难（如边界条件和噪声）的情况。

Abstract: 3D-printed materials are used in many different industries (automotive,
aviation, medicine, etc.). Most of these 3D-printed materials are based on
ceramics or polymers whose mechanical properties vary with frequency. For
numerical modeling, it is crucial to characterize this frequency dependency
accurately to enable realistic finite-element simulations. At the same time,
the damping behavior plays a key role in product development, since it governs
a component's response at resonance and thus impacts both performance and
longevity. In current research, inverse material characterization methods are
getting more and more popular. However, their practical validation and
applicability on real measurement data have not yet been discussed widely. In
this work, we show the identification of two different materials, POM and
additively manufactured sintered ceramics, and validate it with experimental
data of a well-established measurement technique (dynamic mechanical analysis).
The material identification process considers state-of-the-art reduced-order
modeling and constrained particle swarm optimization, which are used to fit the
frequency response functions of point measurements obtained by a laser Doppler
vibrometer. This work shows the quality of the method in identifying the
parameters defining the viscoelastic fractional derivative model, including
their uncertainty. It also illustrates the applicability of this identification
method in the presence of practical difficulties that come along with
experimental data such as boundary conditions and noise.

</details>


### [110] [Self-mixing-based photoacoustic sensing](https://arxiv.org/abs/2511.04532)
*Tecla Gabbrielli,Jacopo Pelini,Chenhong Zhang,Francesco Cappelli,Mario Siciliani de Cumis,Stefano Dello Russo,Maria Concetta Canino,Alberto Roncaglia,Paolo De Natale,Simone Borri*

Main category: physics.app-ph

TL;DR: The paper proposes a novel trace-gas sensor that combines photoacoustic spectroscopy and feedback interferometry with a self-mixing readout. This sensor is ultracompact, easy-to-handle, and highly sensitive, achieving performance comparable to state-of-the-art bulky systems while offering advantages in size, baseline, and tailorability.


<details>
  <summary>Details</summary>
Motivation: There is a need for versatile, ultracompact, easy-to-handle, and high-sensitivity sensors for in situ applications like medical diagnostics, security, and environmental monitoring.

Method: The proposed sensor combines photoacoustic spectroscopy and feedback interferometry with a novel self-mixing readout scheme.

Result: The self-mixing readout achieves sensitivity comparable to bulkier state-of-the-art balanced Michelson-interferometric schemes, with similar spectroscopic performance (SNR and MDL). It also offers reduced size, lower baseline, and potential for downsizing and integration, leading to higher detectability for lower gas concentrations. The wavelength independence of both techniques allows for tailorability to any spectral range.

Conclusion: The novel trace-gas sensor with a self-mixing readout is a promising development, offering comparable performance to existing systems in a more compact and versatile package, paving the way for future integrated and highly sensitive gas sensing applications.

Abstract: Versatile, ultracompact, easy-to-handle, high-sensitivity sensors are
compelling tools for in situ pivotal applications, such as medical diagnostics,
security and safety assessments, and environmental control. In this work, we
combine photoacoustic spectroscopy and feedback interferometry, proposing a
novel trace-gas sensor equipped with a self-mixing readout. This scheme
demonstrates a readout sensitivity comparable to that of bulkier
state-of-the-art balanced Michelson-interferometric schemes, achieving the same
spectroscopic performance in terms of signal-to-noise ratio (SNR) and minimum
detection limit (MDL). At the same time, the self-mixing readout benefits from
a reduced size and a lower baseline, paving the way for future system
downsizing and integration while offering a higher detectability for lower gas
concentrations. Moreover, the intrinsic wavelength independence of both
self-mixing and photoacoustic techniques allows the applicability and
tailorability of the sensor to any desired spectral range.

</details>


<div id='cs.DS'></div>

# cs.DS [[Back]](#toc)

### [111] [Attractors Is All You Need: Parity Games In Polynomial Time](https://arxiv.org/abs/2511.03752)
*Rick van der Heijden*

Main category: cs.DS

TL;DR: 本文提出了一种多项式时间算法，可以在 O(n^2 * (n + m)) 时间内解决奇偶游戏，从而结束了数十年的研究。与之前基于吸引子的算法不同，该算法仅移除具有确定获胜者的区域。本文介绍了一种新型吸引子，能够保证找到奇偶游戏的最小优势区域。该吸引子可以在多项式时间内运行，并能将图完全剥离。


<details>
  <summary>Details</summary>
Motivation: 本文旨在解决奇偶游戏问题，并提出一种高效的多项式时间算法，以结束该领域数十年的研究。

Method: 本文提出了一种新颖的算法，该算法不同于以往基于吸引子的方法，它仅移除具有确定获胜者的区域。此外，算法还引入了一种新型吸引子，可以保证找到奇偶游戏的最小优势区域，并能在多项式时间内运行，最终将图完全剥离。

Result: 本文提出了一种可以在 O(n^2 * (n + m)) 时间内解决奇偶游戏的多项式时间算法。

Conclusion: 本文提出的算法在解决奇偶游戏方面取得了突破性进展，其效率和新颖性为该领域的研究提供了新的方向。

Abstract: This paper provides a polynomial-time algorithm for solving parity games that
runs in $\mathcal{O}(n^{2}\cdot(n + m))$ time-ending a search that has taken
decades. Unlike previous attractor-based algorithms, the presented algorithm
only removes regions with a determined winner. The paper introduces a new type
of attractor that can guarantee finding the minimal dominion of a parity game.
The attractor runs in polynomial time and can peel the graph empty.

</details>


### [112] [Multi-Pass Streaming Lower Bounds for Uniformity Testing](https://arxiv.org/abs/2511.03960)
*Qian Li,Xin Lyu*

Main category: cs.DS

TL;DR: 该论文证明了在大小为 $2m$ 的域上进行多轮流式处理的统一性测试的下界，其结果为 $snoldsymbol{	au}=	ilde{oldsymbol{	heta}}(m/oldsymbol{	heta}^2)$。


<details>
  <summary>Details</summary>
Motivation: 区分均匀分布和一种特定的种植分布（其中相邻元素的概率会发生偏差）。

Method: 采用基于 Dinur (2020) 的混合论证方法，将流式处理问题转化为双向通信问题，并提出了一个新的视角，将困难度的根源归因于偏差方向的不确定性而非碰撞位置。

Result: 证明了任何使用 $s$ 空间和 $oldsymbol{	au}$ 轮的流式算法，只要能获得恒定的区分度，就必须满足 $snoldsymbol{	au}=	ilde{oldsymbol{	heta}}(m/oldsymbol{	heta}^2)$ 的权衡关系。

Conclusion: 该研究将单轮流式下界推广到了多轮，并为其他涉及随机输入的流式处理问题提供了新的技术思路。

Abstract: We prove multi-pass streaming lower bounds for uniformity testing over a
domain of size $2m$. The tester receives a stream of $n$ i.i.d. samples and
must distinguish (i) the uniform distribution on $[2m]$ from (ii) a
Paninski-style planted distribution in which, for each pair $(2i-1,2i)$, the
probabilities are biased left or right by $\epsilon/2m$. We show that any
$\ell$-pass streaming algorithm using space $s$ and achieving constant
advantage must satisfy the tradeoff $sn\ell=\tilde{\Omega}(m/\epsilon^2)$. This
extends the one-pass lower bound of Diakonikolas, Gouleakis, Kane, and Rao
(2019) to multiple passes.
  Our proof has two components. First, we develop a hybrid argument, inspired
by Dinur (2020), that reduces streaming to two-player communication problems.
This reduction relies on a new perspective on hardness: we identify the source
of hardness as uncertainty in the bias directions, rather than the collision
locations. Second, we prove a strong lower bound for a basic two-player
communication task, in which Alice and Bob must decide whether two random sign
vectors $Y^a,Y^b\in\{\pm 1\}^m$ are independent or identical, yet they cannot
observe the signs directly--only noisy local views of each coordinate. Our
techniques may be of independent use for other streaming problems with
stochastic inputs.

</details>


### [113] [HART: A Hybrid Addressing Scheme for Self-Balancing Binary Search Trees in Phase Change Memory (PCM)](https://arxiv.org/abs/2511.03994)
*Mahek Desai,Apoorva Rumale,Marjan Asadinia*

Main category: cs.DS

TL;DR: 本研究提出了一种名为HART的新型混合寻址方案，用于优化基于相变内存（PCM）的自平衡二叉搜索树（BST），以解决PCM的耐久性限制和写入不对称性问题，并在大数据应用中取得了显著的性能提升。


<details>
  <summary>Details</summary>
Motivation: 现有的自平衡二叉搜索树算法在设计时并未考虑PCM内存的耐久性限制（10^6至10^8次写入）和写入不对称性，可能导致性能下降。

Method: HART方案结合了用于深层节点的DFAT Gray码寻址和用于浅层节点的线性寻址，旨在减少频繁旋转时的比特翻转，同时保持浅层节点的计算简洁性。

Result: 在PCM感知的AVL树上的实验结果显示，HART方案显著提高了性能，减少了比特翻转，从而增强了耐用性、延长了寿命，并降低了写入能量和延迟。

Conclusion: HART方案是一种高效的解决方案，能够优化PCM内存的特性，为大数据应用带来了显著的性能改进和耐用性提升，且计算开销可忽略不计。

Abstract: As DRAM and other transistor-based memory technologies approach their
scalability limits, alternative storage solutions like Phase-Change Memory
(PCM) are gaining attention for their scalability, fast access times, and zero
leakage power. However, current memory-intensive algorithms, especially those
used in big data systems, often overlook PCM's endurance limitations (10^6 to
10^8 writes before degradation) and write asymmetry. Self-balancing binary
search trees (BSTs), which are widely used for large-scale data management,
were developed without considering PCM's unique properties, leading to
potential performance degradation. This paper introduces HART, a novel hybrid
addressing scheme for self-balancing BSTs, designed to optimize PCM's
characteristics. By combining DFATGray code addressing for deeper nodes with
linear addressing for shallower nodes, HART balances reduced bit flips during
frequent rotations at deeper levels with computational simplicity at shallow
levels. Experimental results on PCM-aware AVL trees demonstrate significant
improvements in performance, with a reduction in bit flips leading to enhanced
endurance, increased lifetime, and lower write energy and latency. Notably,
these benefits are achieved without imposing substantial computational
overhead, making HART an efficient solution for big data applications.

</details>


### [114] [Depth-13 Sorting Networks for 28 Channels](https://arxiv.org/abs/2511.04107)
*Chengu Wang*

Main category: cs.DS

TL;DR: 我们为 27 和 28 通道的排序网络建立了新的深度上限，将之前的最佳上限 14 提高到 13。我们的 28 通道网络通过组合 16 和 12 通道网络的高质量前缀，每次贪婪地增加一个比较器，并使用 SAT 求解器完成剩余层来构建，具有反射对称性。


<details>
  <summary>Details</summary>
Motivation: 改进排序网络的深度上限，特别是为 27 和 28 通道提供新的最优解。

Method: 结合高质量的 16 和 12 通道网络前缀，通过贪婪地添加比较器并使用 SAT 求解器完成，以构建具有反射对称性的 28 通道网络。

Result: 为 27 和 28 通道的排序网络建立了新的深度上限，分别为 13，优于之前的 14。

Conclusion: 通过结合现有网络前缀和 SAT 求解器的方法，成功地为 27 和 28 通道的排序网络找到了更优的深度上限。

Abstract: We establish new depth upper bounds for sorting networks on 27 and 28
channels, improving the previous best bound of 14 to 13. Our 28-channel network
is constructed with reflectional symmetry by combining high-quality prefixes of
16- and 12-channel networks, extending them greedily one comparator at a time,
and using a SAT solver to complete the remaining layers.

</details>


### [115] [Counting Patterns in Degenerate Graphs in Constant Space](https://arxiv.org/abs/2511.04258)
*Balagopal Komarath,Anant Kumar,Akash Pareek*

Main category: cs.DS

TL;DR: 该论文研究了在n-顶点、d-退化图上计数同态、子图同构和诱导子图同构的算法复杂度，引入了新的图参数DAG树深度，并提出了使用该参数的常数空间算法。同时，也改进了基于DAG树宽的算法，并获得了针对特定大小模式图的更优时间复杂度。


<details>
  <summary>Details</summary>
Motivation: 研究在n-顶点、d-退化图上计数同态、子图同构和诱导子图同构的算法复杂度，旨在开发比现有算法（基于DAG树宽）更高效、空间占用更小的算法。

Method: 引入新的图参数DAG树深度，并基于此提出常数空间的分治算法。同时，改进了基于DAG树宽的算法，并针对特定大小的模式图获得了更优的时间复杂度。

Result: 提出了使用DAG树深度的常数空间算法，可用于计数稀疏模式图的子图同构。推导了DAG树深度不超过两的图的诱导骨架刻画。对于至多九个顶点的模式图，能在O(n^3)时间和常数空间内计数诱导子图。提出了一个计数诱导子图的算法，在运行时间上与Bressan的算法相当，但只使用常数空间。改进了DAG树宽的算法，可以更快地计数同态、子图同构和诱导子图同构。对于至多11个顶点的所有模式图，能在二次时间内计数诱导子图。

Conclusion: DAG树深度为计数同态、子图同构和诱导子图同构问题提供了一种新的、空间效率更高的算法设计方法。改进的DAG树宽算法以及针对小规模模式图的更优时间复杂度也为该领域带来了进展。

Abstract: For an arbitrary, fixed graph (pattern graph), we study the algorithmic
complexity of counting homomorphisms, subgraph isomorphisms, and induced
subgraph isomorphisms from the pattern graph to $n$-vertex, $d$-degenerate
graphs as input. Recent work by Bressan (Algorithmica, 2021) has shown that
this problem has efficient dynamic programming algorithms using a graph
parameter called DAG treewidth. Bressan used DAG treewidth to design a fast
algorithm for counting homomorphisms, subgraph isomorphisms, and induced
subgraph isomorphisms that use polynomial space. Bera, Gishboliner, Levanzov,
Seshadhri, and Shapira (SODA, 2021) provided a characterization of graphs with
DAG treewidth one.
  In this paper, we introduce a new graph parameter called DAG treedepth and
show that it yields efficient divide and conquer algorithms that use only
constant space (in the unit-cost RAM model). Specifically, we show:
  An algorithm for counting subgraphs isomorphic to sparse pattern graphs using
only constant space.
  We derive an induced minor-based characterization for graphs of DAG treedepth
up to two.
  For pattern graphs upto nine vertices, the induced subgraphs can be counted
in $O(n^3)$ time using constant space.
  An algorithm for counting induced subgraphs that matches the running time
given by Bressan but only uses constant space.
  Apart from the DAG treedepth result, we also focus on DAG treewidth. For DAG
treewidth, we show that we can count homomorphisms, subgraph isomorphisms, and
induced subgraph isomorphisms faster than Bressan's algorithm (2021). We
further show that for all pattern graphs up to 11 vertices, we can count
induced subgraphs in quadratic time.

</details>


### [116] [Estimating Hitting Times Locally At Scale](https://arxiv.org/abs/2511.04343)
*Themistoklis Haris,Fabian Spaeh,Spyros Dragazis,Charalampos Tsourakakis*

Main category: cs.DS

TL;DR: 该工作提出局部算法估计随机游走中节点对之间的命中时间，克服了全局方法的扩展性问题。


<details>
  <summary>Details</summary>
Motivation: 命中时间是随机过程中的基本距离度量，在网络中心性分析、排名和推荐系统以及流行病学等领域有广泛应用。然而，现有全局方法存在扩展性问题。

Method: 提出两种局部算法来估计命中时间：1. 基于两个独立随机游走在相遇时间处截断命中时间计算。2. 扩展Peng等人[KDD 2021]的工作，采用新颖的谱截断技术来处理命中时间的不对称性。

Result: 提供了算法的理论上限和下限，揭示了命中时间估计与分布测试的联系，并在真实和合成数据集上进行了实验验证。

Conclusion: 提出的局部算法能够有效估计命中时间，克服了传统全局方法的局限性，并在实际应用中具有潜力。

Abstract: Hitting times provide a fundamental measure of distance in random processes,
quantifying the expected number of steps for a random walk starting at node $u$
to reach node $v$. They have broad applications across domains such as network
centrality analysis, ranking and recommendation systems, and epidemiology. In
this work, we develop local algorithms for estimating hitting times between a
pair of vertices $u,v$ without accessing the full graph, overcoming scalability
issues of prior global methods. Our first algorithm uses the key insight that
hitting time computations can be truncated at the meeting time of two
independent random walks from $u$ and $v$. This leads to an efficient estimator
analyzed via the Kronecker product graph and Markov Chain Chernoff bounds. We
also present an algorithm extending the work of [Peng et al.; KDD 2021], that
introduces a novel adaptation of the spectral cutoff technique to account for
the asymmetry of hitting times. This adaptation captures the directionality of
the underlying random walk and requires non-trivial modifications to ensure
accuracy and efficiency. In addition to the algorithmic upper bounds, we also
provide tight asymptotic lower bounds. We also reveal a connection between
hitting time estimation and distribution testing, and validate our algorithms
using experiments on both real and synthetic data.

</details>


### [117] [A Polynomial-Time Algorithm for the Next-to-Shortest Path Problem on Positively Weighted Directed Graphs](https://arxiv.org/abs/2511.04345)
*Kuowen Chen,Nicole Wein,Yiran Zhang*

Main category: cs.DS

TL;DR: 该论文为具有正权重的有向图的次短路径问题提供了一种多项式时间算法，解决了近 30 年来的悬而未决的问题。


<details>
  <summary>Details</summary>
Motivation: “次短路径问题”旨在找到图中两个指定节点间“次短”的路径，即比最短路径稍长的路径。对于具有非负权重的边的有向图，此问题已被证明是 NP 完全的，但对于具有正权重的边的情况，一直悬而未决。

Method: 本文提出了一种适用于具有正权重的边的有向图的次短路径问题的算法。

Result: 该算法解决了近 30 年来关于具有正权重的边的有向图的次短路径问题的开放性问题。

Conclusion: 本文成功解决了一个长期存在的图论难题，为具有正权重的边的有向图提供了次短路径问题的有效算法。

Abstract: Given a graph and a pair of terminals $s$, $t$, the next-to-shortest path
problem asks for an $s\!\to \!t$ (simple) path that is shortest among all not
shortest $s\!\to \!t$ paths (if one exists). This problem was introduced in
1996, and soon after was shown to be NP-complete for directed graphs with
non-negative edge weights, leaving open the case of positive edge weights.
Subsequent work investigated this open question, and developed polynomial-time
algorithms for the cases of undirected graphs and planar directed graphs. In
this work, we resolve this nearly 30-year-old open problem by providing an
algorithm for the next-to-shortest path problem on directed graphs with
positive edge weights.

</details>


### [118] [Free-order secretary for two-sided independence systems](https://arxiv.org/abs/2511.04390)
*Kristóf Bérczi,Vasilis Livanos,José A. Soto,Victor Verdugo*

Main category: cs.DS

TL;DR: 本文提出了一个统一的二分图框架来解决多种在线优化问题，特别是 the Matroid Secretary Problem 及其推广形式，并设计了在不同模型（自由排序、边缘到达、代理到达）下具有竞争力的算法。


<details>
  <summary>Details</summary>
Motivation: 在线优化和组合约束下的序贯决策是核心问题，需要统一和扩展现有模型来解决更广泛的场景。

Method: 提出一个二分图框架，统一了多种已知模型。在自由排序设置下，利用核心引理设计了 $\Omega(1/k^2)$-竞争算法。引入 k-growth 系统并推广核心引理。研究代理到达模型，扩展核心引理并获得 $\Omega(\beta/k^2)$-竞争算法。最后，将结果扩展到多物品选择问题。

Result: 在自由排序设置下，对于 k-matroid 交集问题，设计了一个 $\Omega(1/k^2)$-竞争算法。对于 k-growth 系统，通过推广的核心引理，也得到了 $\Omega(1/k^2)$-竞争算法。在代理到达模型下，得到了 $\Omega(\beta/k^2)$-竞争算法。在多物品选择问题中，对于 partition matroids 和 k-matching 约束等基本情况，获得了常数竞争力的算法。

Conclusion: 本文提出的二分图框架和基于 k-growth 系统的分析方法，成功地统一和扩展了 Matroid Secretary Problem 的研究，并在不同的在线模型下设计了具有竞争力的算法，为在线优化领域提供了新的见解和工具。

Abstract: The Matroid Secretary Problem is a central question in online optimization,
modeling sequential decision-making under combinatorial constraints. We
introduce a bipartite graph framework that unifies and extends several known
formulations, including the bipartite matching, matroid intersection, and
random-order matroid secretary problems. In this model, elements form a
bipartite graph between agents and items, and the objective is to select a
matching that satisfies feasibility constraints on both sides, given by two
independence systems.
  We study the free-order setting, where the algorithm may adaptively choose
the next element to reveal. For $k$-matroid intersection, we leverage a core
lemma by (Feldman, Svensson and Zenklusen, 2022) to design an
$\Omega(1/k^2)$-competitive algorithm, extending known results for single
matroids. Building on this, we identify the structural property underlying our
approach and introduce $k$-growth systems. We establish a generalized core
lemma for $k$-growth systems, showing that a suitably defined set of critical
elements retains a $\Omega(1/k^2)$ fraction of the optimal weight. Using this
lemma, we extend our $\Omega(1/k^2)$-competitive algorithm to $k$-growth
systems for the edge-arrival model.
  We then study the agent-arrival model, which presents unique challenges to
our framework. We extend the core lemma to this model and then apply it to
obtain an $\Omega(\beta/k^2)$-competitive algorithm for $k$-growth systems,
where $\beta$ denotes the competitiveness of a special type of order-oblivious
algorithm for the item-side constraint. Finally, we relax the matching
assumption and extend our results to the case of multiple item selection, where
agents have individual independence systems coupled by a global item-side
constraint. We obtain constant-competitive algorithms for fundamental cases
such as partition matroids and $k$-matching constraints.

</details>


### [119] [Online Algorithms for Repeated Optimal Stopping: Achieving Both Competitive Ratio and Regret Bounds](https://arxiv.org/abs/2511.04484)
*Tsubasa Harada,Yasushi Kawase,Hanna Sumita*

Main category: cs.DS

TL;DR: 本文提出了一种通用的算法框架，用于解决重复最优停时问题，该框架在每轮都能保证竞争比，并且在所有轮次中实现了次线性遗憾。


<details>
  <summary>Details</summary>
Motivation: 解决经典最优停时问题的扩展，即在未知分布下重复进行相同问题的求解，目标是设计在每轮都能保证竞争比，并在所有轮次中实现次线性遗憾的算法。

Method: 设计了一个通用的算法框架，该框架动态选择两种候选算法之一：基于历史观察的经验最优算法，或具有竞争比保证的基于样本的算法。

Result: 所提出的算法在每一轮的表现不劣于基准样本算法，并且总遗憾有$	ilde{O}(\sqrt{T})$的界限。该框架成功应用于重复预言机不等式和秘书问题等经典问题，并在重复预言机不等式问题中实现了从第二轮开始的$1/2$竞争比和$	ilde{O}(\sqrt{T})$的遗憾。

Conclusion: 该算法框架能够同时实现每轮竞争比和次线性遗憾，并且在重复预言机不等式问题上的表现接近最优。此外，即使在i.i.d.模型下，也证明了$\Omega(\sqrt{T})$的遗憾下界，表明所提出算法的性能几乎是最优的。

Abstract: We study the repeated optimal stopping problem, which generalizes the
classical optimal stopping problem with an unknown distribution to a setting
where the same problem is solved repeatedly over $T$ rounds. In this framework,
we aim to design algorithms that guarantee a competitive ratio in each round
while also achieving sublinear regret across all rounds.
  Our primary contribution is a general algorithmic framework that achieves
these objectives simultaneously for a wide array of repeated optimal stopping
problems. The core idea is to dynamically select an algorithm for each round,
choosing between two candidates: (1) an empirically optimal algorithm derived
from the history of observations, and (2) a sample-based algorithm with a
proven competitive ratio guarantee. Based on this approach, we design an
algorithm that performs no worse than the baseline sample-based algorithm in
every round, while ensuring that the total regret is bounded by
$\tilde{O}(\sqrt{T})$.
  We demonstrate the broad applicability of our framework to canonical
problems, including the prophet inequality, the secretary problem, and their
variants under adversarial, random, and i.i.d. input models. For example, for
the repeated prophet inequality problem, our method achieves a
$1/2$-competitive ratio from the second round on and an $\tilde{O}(\sqrt{T})$
regret. Furthermore, we establish a regret lower bound of $\Omega(\sqrt{T})$
even in the i.i.d. model, confirming that our algorithm's performance is almost
optimal with respect to the number of rounds.

</details>


<div id='eess.IV'></div>

# eess.IV [[Back]](#toc)

### [120] [Pediatric Appendicitis Detection from Ultrasound Images](https://arxiv.org/abs/2511.04069)
*Fatemeh Hosseinabadi,Seyedhassan Sharifi*

Main category: eess.IV

TL;DR: 该研究提出了一种基于ResNet的深度学习模型，用于通过超声图像自动检测儿童阑尾炎。


<details>
  <summary>Details</summary>
Motivation: 儿童阑尾炎的诊断因症状重叠和影像质量不一而充满挑战，本研究旨在开发一种深度学习模型来提高诊断的准确性。

Method: 研究使用Regensburg儿科阑尾炎数据集，对预训练的ResNet模型进行微调，以区分阑尾炎和非阑尾炎病例。对图像进行了预处理，包括标准化、调整大小和增强，以提高泛化能力。

Result: 所提出的ResNet模型在准确率（93.44%）、精确率（91.53%）和召回率（89.8%）方面表现出色，有效克服了儿科影像中低对比度、斑点噪声和解剖结构变异等挑战。

Conclusion: 该深度学习模型在自动检测儿童阑尾炎方面显示出强大的潜力，有望辅助临床诊断。

Abstract: Pediatric appendicitis remains one of the most common causes of acute
abdominal pain in children, and its diagnosis continues to challenge clinicians
due to overlapping symptoms and variable imaging quality. This study aims to
develop and evaluate a deep learning model based on a pretrained ResNet
architecture for automated detection of appendicitis from ultrasound images. We
used the Regensburg Pediatric Appendicitis Dataset, which includes ultrasound
scans, laboratory data, and clinical scores from pediatric patients admitted
with abdominal pain to Children Hospital. Hedwig in Regensburg, Germany. Each
subject had 1 to 15 ultrasound views covering the right lower quadrant,
appendix, lymph nodes, and related structures. For the image based
classification task, ResNet was fine tuned to distinguish appendicitis from
non-appendicitis cases. Images were preprocessed by normalization, resizing,
and augmentation to enhance generalization. The proposed ResNet model achieved
an overall accuracy of 93.44, precision of 91.53, and recall of 89.8,
demonstrating strong performance in identifying appendicitis across
heterogeneous ultrasound views. The model effectively learned discriminative
spatial features, overcoming challenges posed by low contrast, speckle noise,
and anatomical variability in pediatric imaging.

</details>


### [121] [Left Atrial Segmentation with nnU-Net Using MRI](https://arxiv.org/abs/2511.04071)
*Fatemeh Hosseinabadi,Seyedhassan Sharifi*

Main category: eess.IV

TL;DR: nnU-Net框架在左心房分割任务中表现出色，平均Dice系数达到93.5，优于传统方法，并能稳健泛化。


<details>
  <summary>Details</summary>
Motivation: 手动分割左心房耗时且依赖观察者，不适用于大规模或时间敏感的临床工作流程，因此需要更有效的方法。

Method: 应用nnU-Net框架（一种自动化的、自配置的深度学习分割架构）处理左心房分割挑战赛2013年的数据集，该数据集包含30个体层析成像扫描及其专家标注的掩模。

Result: nnU-Net模型在左心房分割任务中取得了93.5的平均Dice相似系数，表明其分割结果与专家标注高度重叠，并且优于先前研究报道的几种传统分割方法。

Conclusion: nnU-Net框架能够自动适应MRI数据的特性，在左心房分割任务中表现出强大的性能和鲁棒性，能够准确分割心房体和近端肺静脉，适用于临床应用。

Abstract: Accurate segmentation of the left atrium (LA) from cardiac MRI is critical
for guiding atrial fibrillation (AF) ablation and constructing biophysical
cardiac models. Manual delineation is time-consuming, observer-dependent, and
impractical for large-scale or time-sensitive clinical workflows. Deep learning
methods, particularly convolutional architectures, have recently demonstrated
superior performance in medical image segmentation tasks. In this study, we
applied the nnU-Net framework, an automated, self-configuring deep learning
segmentation architecture, to the Left Atrial Segmentation Challenge 2013
dataset. The dataset consists of thirty MRI scans with corresponding
expert-annotated masks. The nnU-Net model automatically adapted its
preprocessing, network configuration, and training pipeline to the
characteristics of the MRI data. Model performance was quantitatively evaluated
using the Dice similarity coefficient (DSC), and qualitative results were
compared against expert segmentations. The proposed nnUNet model achieved a
mean Dice score of 93.5, demonstrating high overlap with expert annotations and
outperforming several traditional segmentation approaches reported in previous
studies. The network exhibited robust generalization across variations in left
atrial shape, contrast, and image quality, accurately delineating both the
atrial body and proximal pulmonary veins.

</details>


<div id='eess.SY'></div>

# eess.SY [[Back]](#toc)

### [122] [On excitation of control-affine systems and its use for data-driven Koopman approximants](https://arxiv.org/abs/2511.03734)
*Philipp Schmitz,Lea Bold,Friedrich M. Philipp,Mario Rosenfelder,Peter Eberhard,Henrik Ebel,Karl Worthmann*

Main category: eess.SY

TL;DR: 本研究提出一种数据拟合框架，用于提高控制仿射系统的辨识鲁棒性，从而实现更可靠的 EDMD 模型，并通过非完整机器人进行验证。


<details>
  <summary>Details</summary>
Motivation: 控制仿射系统的辨识和 EDMD 模型应用中存在数据需求高、难以处理的问题。

Method: 提出一种数据拟合框架，并推导出基于子空间角度的输入选择准则，以确保最小奇异值的阈值；推导出最大化最小奇异值的最优性条件。

Result: 提出的框架提高了数据拟合的鲁棒性，使得 EDMD 模型更加可靠。

Conclusion: 所提出的方法能够有效地处理控制仿射系统的辨识问题，并通过非完整机器人控制的实例验证了其有效性。

Abstract: The Koopman operator and extended dynamic mode decomposition (EDMD) as a
data-driven technique for its approximation have attracted considerable
attention as a key tool for modeling, analysis, and control of complex
dynamical systems. However, extensions towards control-affine systems resulting
in bilinear surrogate models are prone to demanding data requirements rendering
their applicability intricate. In this paper, we propose a framework for
data-fitting of control-affine mappings to increase the robustness margin in
the associated system identification problem and, thus, to provide more
reliable bilinear EDMD schemes. In particular, guidelines for input selection
based on subspace angles are deduced such that a desired threshold with respect
to the minimal singular value is ensured. Moreover, we derive necessary and
sufficient conditions of optimality for maximizing the minimal singular value.
Further, we demonstrate the usefulness of the proposed approach using bilinear
EDMD with control for non-holonomic robots.

</details>


### [123] [Hybrid ILM-NILM Smart Plug System](https://arxiv.org/abs/2511.03737)
*Dániel István Németh,Kálmán Tornai*

Main category: eess.SY

TL;DR: 通过在智能插头上连接多个负载，可以降低安装成本，但会牺牲部分控制粒度。该混合方法解决了在文献中很少被考虑的家庭常见场景。


<details>
  <summary>Details</summary>
Motivation: 当前电器负荷分类方法分为侵入式和非侵入式，各有优缺点。非侵入式无法控制电器，但成本低；侵入式能控制电器，但成本高。很少有方法能结合两者。

Method: 提出一种混合负荷分类解决方案，该方案通过在智能插头上使用延长线连接多个电器，以降低系统安装成本，并处理文献中很少考虑的家庭常见场景。

Result: 在智能插头上连接多个负载可以降低安装成本，但会牺牲控制粒度。

Conclusion: 通过在智能插头上连接多个负载可以降低安装成本，同时该混合方法也能处理家庭常见场景。

Abstract: Electrical load classification is generally divided into intrusive and
non-intrusive approaches, both having their limitations and advantages. With
the non-intrusive approach, controlling appliances is not possible, but the
installation cost of a single measurement device is cheap. In comparison,
intrusive, smart plug-based solutions offer individual appliance control, but
the installation cost is much higher. There have been very few approaches
aiming to combine these methods. In this paper we show that extending a smart
plug-based solution to multiple loads per plug can reduce control granularity
in favor of lowering the system's installation costs. Connecting various loads
to a Smart Plug through an extension cord is seldom considered in the
literature, even though it is common in households. This scenario is also
handled by the hybrid load classification solution presented in this paper.

</details>


### [124] [Kalman-Bucy Filtering with Randomized Sensing: Fundamental Limits and Sensor Network Design for Field Estimation](https://arxiv.org/abs/2511.03740)
*Xinyi Wang,Devansh R. Agrawal,Dimitra Panagou*

Main category: eess.SY

TL;DR: 该研究提出了一个处理卡尔曼滤波器中测量值随机丢失问题的通用连续时间框架，推导了预期估计协方差的闭式上界，并将其应用于时空场估计，通过“清晰度”指标揭示了传感器网络设计的根本性能限制。


<details>
  <summary>Details</summary>
Motivation: 在测量值随机丢失的条件下，对卡尔曼滤波器的稳定性进行稳定性分析，并将其推广到更通用的连续时间框架，同时考虑了传感位置的变化性。

Method: 在测量矩阵和噪声协方差作为随机过程演变的连续时间框架内，推导了连续时间卡尔曼滤波的预期估计协方差的闭式上界。然后，将此框架应用于时空场估计，利用“清晰度”指标（一种随机变量微分熵的重标度形式）建立了空间平均预期清晰度的无网格下界。

Result: 推导了预期估计协方差的闭式上界，并揭示了捕捉传感器数量、噪声水平和测量频率综合影响的时空场估计的性能极限。通过模拟验证了所提出边界的紧密性，该边界在测量速率降低时接近离散时间卡尔曼滤波器的性能，同时避免了离散时间方法的递归计算。

Conclusion: 提出的理论框架和边界为传感器网络的设计提供了原则性且高效的指导，可以在部署前用于解决传感器网络设计问题。

Abstract: Stability analysis of the Kalman filter under randomly lost measurements has
been widely studied. We revisit this problem in a general continuous-time
framework, where both the measurement matrix and noise covariance evolve as
random processes, capturing variability in sensing locations. Within this
setting, we derive a closed-form upper bound on the expected estimation
covariance for continuous-time Kalman filtering. We then apply this framework
to spatiotemporal field estimation, where the field is modeled as a Gaussian
process observed by randomly located, noisy sensors. Using clarity, introduced
in our earlier work as a rescaled form of the differential entropy of a random
variable, we establish a grid-independent lower bound on the spatially averaged
expected clarity. This result exposes fundamental performance limits through a
composite sensing parameter that jointly captures the effects of the number of
sensors, noise level, and measurement frequency. Simulations confirm that the
proposed bound is tight for the discrete-time Kalman filter, approaching it as
the measurement rate decreases, while avoiding the recursive computations
required in the discrete-time formulation. Most importantly, the derived limits
provide principled and efficient guidelines for sensor network design problem
prior to deployment.

</details>


### [125] [Electric Vehicle Charging Load Modeling: A Survey, Trends, Challenges and Opportunities](https://arxiv.org/abs/2511.03741)
*Xiachong Lin,Arian Prabowo,Imran Razzak,Hao Xue,Matthew Amos,Sam Behrens,Flora D. Salim*

Main category: eess.SY

TL;DR: 本论文全面回顾了过去五年电动汽车充电负荷模型的研究，将其分为统计、仿真和数据驱动三类，并分析了信息融合在其中的应用。


<details>
  <summary>Details</summary>
Motivation: 准确预测电动汽车充电行为对于基础设施规划至关重要，但现有研究缺乏对信息融合建模方法的系统性分析。

Method: 对过去五年电动汽车充电负荷模型进行文献综述，将其归类为统计、仿真和数据驱动方法，并分析信息融合在其中的应用。

Result: 对各类模型的优缺点以及信息融合在模型中的应用进行了分析。

Conclusion: 讨论了该领域的挑战与机遇，为未来研究提供了方向。

Abstract: The evolution of electric vehicles (EVs) is reshaping the automotive
industry, advocating for more sustainable transportation practices. Accurately
predicting EV charging behavior is essential for effective infrastructure
planning and optimization. However, the charging load of EVs is significantly
influenced by uncertainties and randomness, posing challenges for accurate
estimation. Furthermore, existing literature reviews lack a systematic analysis
of modeling approaches focused on information fusion. This paper
comprehensively reviews EV charging load models from the past five years. We
categorize state-of-the-art modeling methods into statistical, simulated, and
data-driven approaches, examining the advantages and drawbacks of each.
Additionally, we analyze the three bottom-up level operations of information
fusion in existing models. We conclude by discussing the challenges and
opportunities in the field, offering guidance for future research endeavors to
advance our understanding and explore practical research directions.

</details>


### [126] [A Model-Based Approach to Automated Digital Twin Generation in Manufacturing](https://arxiv.org/abs/2511.03742)
*Angelos Alexopoulos,Agorakis Bompotas,Nikitas Rigas Kalogeropoulos,Panagiotis Kechagias,Athanasios P. Kalogeras,Christos Alexakos*

Main category: eess.SY

TL;DR: 本论文提出了一种利用AutomationML工厂计划自动生成和部署数字孪生（DT）的平台，并通过生成式人工智能（GAI）驱动的模拟场景生成器和自动物理生产线重构来提高制造效率和适应性。


<details>
  <summary>Details</summary>
Motivation: 现代制造业需要高灵活性和可重构性以适应动态生产需求。虽然模型基础工程（MBE）支持快速生产线设计，但最终的重构需要模拟和验证。数字孪生（DT）通过实时监控、模拟和重构简化了这一过程。

Method: 提出一个自动化平台，利用基于AutomationML的工厂计划自动生成和部署数字孪生（DT），并结合生成式人工智能（GAI）驱动的模拟场景生成器和自动物理生产线重构。

Result: 该平台能够实现数字孪生（DT）的自动生成和部署，并通过GAI驱动的模拟场景生成器和自动物理生产线重构来提高制造效率和适应性。

Conclusion: 所提出的平台通过自动化数字孪生（DT）的创建和部署，以及利用GAI进行模拟和物理重构，显著提高了制造过程的效率和适应性。

Abstract: Modern manufacturing demands high flexibility and reconfigurability to adapt
to dynamic production needs. Model-based Engineering (MBE) supports rapid
production line design, but final reconfiguration requires simulations and
validation. Digital Twins (DTs) streamline this process by enabling real-time
monitoring, simulation, and reconfiguration. This paper presents a novel
platform that automates DT generation and deployment using AutomationML-based
factory plans. The platform closes the loop with a GAI-powered simulation
scenario generator and automatic physical line reconfiguration, enhancing
efficiency and adaptability in manufacturing.

</details>


### [127] [A convolutional neural network deep learning method for model class selection](https://arxiv.org/abs/2511.03743)
*Marios Impraimakis*

Main category: eess.SY

TL;DR: 一种新的深度卷积神经网络方法被提出，用于仅通过系统响应信号来选择模型类别，无需输入信息或进行全系统识别。该方法还可通过卡尔曼滤波器进行增强，并成功应用于识别线性/非线性动态系统和3D建筑有限元模型中的细微信号变化，在结构健康监测方面具有潜力。


<details>
  <summary>Details</summary>
Motivation: 评估一种新颖的深度卷积神经网络方法在仅利用响应信号的情况下进行模型类别选择的能力。

Method: 利用独特自由度产生的响应及其类别信息来训练和验证一维卷积神经网络，以实现模型类别选择。同时，提出了一种可选的基于物理的算法增强方法，使用卡尔曼滤波器融合系统响应信号，并利用加速度和位移数据的运动学约束。

Result: 该方法能够识别具有细微信号变化的系统，这些变化归因于线性/非线性动态系统以及3D建筑有限元模型中的阻尼行为或迟滞行为。

Conclusion: 所提出的方法是一种强大的结构健康监测工具，能够仅凭系统响应信号就能识别模型类别，并且能够检测到系统中的细微变化。

Abstract: The response-only model class selection capability of a novel deep
convolutional neural network method is examined herein in a simple, yet
effective, manner. Specifically, the responses from a unique degree of freedom
along with their class information train and validate a one-dimensional
convolutional neural network. In doing so, the network selects the model class
of new and unlabeled signals without the need of the system input information,
or full system identification. An optional physics-based algorithm enhancement
is also examined using the Kalman filter to fuse the system response signals
using the kinematics constraints of the acceleration and displacement data.
Importantly, the method is shown to select the model class in slight signal
variations attributed to the damping behavior or hysteresis behavior on both
linear and nonlinear dynamic systems, as well as on a 3D building finite
element model, providing a powerful tool for structural health monitoring
applications.

</details>


### [128] [Predictive Compensation in Finite-Horizon LQ Games under Gauss-Markov Deviations](https://arxiv.org/abs/2511.03744)
*Navid Mojahed,Mahdis Rabbani,Shima Nazari*

Main category: eess.SY

TL;DR: 该论文提出了一种预测性补偿框架，用于处理高斯-马尔可夫偏差下的有限时间离散线性二次动态博弈。


<details>
  <summary>Details</summary>
Motivation: 该研究的动机是解决在存在高斯-马尔可夫偏差的情况下，有限时间离散线性二次动态博弈的预测性补偿问题。

Method: 研究方法是利用一阶自回归过程对一个玩家的噪声进行建模，并设计一个能够预测未来相关性影响的补偿策略，同时推导出均值和协方差传播的闭式递推关系。

Result: 研究结果通过预期成本的敏感性分析，量化了预测性补偿策略带来的性能提升。

Conclusion: 该论文成功地开发了一种预测性补偿框架，该框架能够有效处理动态博弈中的高斯-马尔可夫偏差，并通过分析性能改进证明了其有效性。

Abstract: This paper presents a predictive compensation framework for finite-horizon
discrete-time linear quadratic dynamic games in the presence of Gauss-Markov
deviations from feedback Nash strategies. One player experiences correlated
stochastic deviations, modeled via a first-order autoregressive process, while
the other compensates using a predictive strategy that anticipates the effect
of future correlation. Closed-form recursions for mean and covariance
propagation are derived, and the resulting performance improvement is analyzed
through the sensitivity of expected cost.

</details>


### [129] [InvSim algorithm for pre-computing airplane flight controls in limited-range autonomous missions, and demonstration via double-roll maneuver of Mirage III fighters](https://arxiv.org/abs/2511.03745)
*Osama A. Marzouk*

Main category: eess.SY

TL;DR: 本文提出了一个用于固定翼飞机六自由度运动方程（EOM）的通用数学框架，并进行了逆向模拟以预测实现目标飞行轨迹所需的控制量。


<details>
  <summary>Details</summary>
Motivation: 为了解决在给定目标飞行轨迹的情况下，预测实现该轨迹所需的飞行控制量这一问题。

Method: 通过推导适用于逆向模拟的定制化运动方程，并采用符号数学、四阶龙格-库塔（RK4）和有限差分法（FDM）进行数值积分，计算出实现目标轨迹所需的四种控制变量（发动机推力、副翼、升降舵和方向舵的角度）。

Result: 计算得到了实现目标轨迹所需的离散控制值，并通过数值过程进行了演示。

Conclusion: 所提出的飞行力学逆向模拟（InvSim）数值程序能够成功计算出固定翼飞机在特定飞行轨迹下的控制变量。

Abstract: In this work, we start with a generic mathematical framework for the
equations of motion (EOM) in flight mechanics with six degrees of freedom
(6-DOF) for a general (not necessarily symmetric) fixed-wing aircraft. This
mathematical framework incorporates (1) body axes (fixed in the airplane at its
center of gravity), (2) inertial axes (fixed in the earth/ground at the
take-off point), wind axes (aligned with the flight path/course), (3) spherical
flight path angles (azimuth angle measured clockwise from the geographic north,
and elevation angle measured above the horizon plane), and (4) spherical flight
angles (angle of attack and sideslip angle). We then manipulate these equations
of motion to derive a customized version suitable for inverse simulation flight
mechanics, where a target flight trajectory is specified while a set of
corresponding necessary flight controls to achieve that maneuver are predicted.
We then present a numerical procedure for integrating the developed inverse
simulation (InvSim) system in time; utilizing (1) symbolic mathematics, (2)
explicit fourth-order Runge-Kutta (RK4) numerical integration technique, and
(3) expressions based on the finite difference method (FDM); such that the four
necessary control variables (engine thrust force, ailerons' deflection angle,
elevators' deflection angle, and rudder's deflection angle) are computed as
discrete values over the entire maneuver time, and these calculated control
values enable the airplane to achieve the desired flight trajectory, which is
specified by three inertial Cartesian coordinates of the airplane, in addition
to the Euler's roll angle. We finally demonstrate the proposed numerical
procedure of flight mechanics inverse simulation (InvSim).

</details>


### [130] [A Dynamic Recurrent Adjacency Memory Network for Mixed-Generation Power System Stability Forecasting](https://arxiv.org/abs/2511.03746)
*Guang An Ooi,Otavio Bertozzi,Mohd Asim Aftab,Charalambos Konstantinou,Shehab Ahmed*

Main category: eess.SY

TL;DR: 该研究提出了一种名为DRAMN的动态递归邻域记忆网络，结合了物理信息分析和深度学习，用于实时电力系统稳定性预测，解决了传统方法在现代高渗透率电力系统中的局限性。


<details>
  <summary>Details</summary>
Motivation: 现代电力系统由于逆变器电源的高渗透率，表现出复杂的动态行为，对传统稳定性评估方法的扩展性和通用性提出了挑战。

Method: 提出了一种动态递归邻域记忆网络（DRAMN），结合了物理信息分析和深度学习。使用滑动窗口动态模态分解构建时变多层邻域矩阵，并集成图卷积操作于递归门控机制中，以同时建模动态演变和时间依赖性。

Result: 在修改后的IEEE 9总线、39总线和多端高压直流网络上进行了广泛验证，平均准确率分别达到99.85%、99.90%和99.69%，超过了所有基准。该框架还能识别测量值的最优组合，在不降低性能的情况下将特征维度降低82%。

Conclusion: DRAMN实现了最先进的准确率，同时为电力系统操作员提供了更强的可解释性，适合在现代控制中心进行实时部署。

Abstract: Modern power systems with high penetration of inverter-based resources
exhibit complex dynamic behaviors that challenge the scalability and
generalizability of traditional stability assessment methods. This paper
presents a dynamic recurrent adjacency memory network (DRAMN) that combines
physics-informed analysis with deep learning for real-time power system
stability forecasting. The framework employs sliding-window dynamic mode
decomposition to construct time-varying, multi-layer adjacency matrices from
phasor measurement unit and sensor data to capture system dynamics such as
modal participation factors, coupling strengths, phase relationships, and
spectral energy distributions. As opposed to processing spatial and temporal
dependencies separately, DRAMN integrates graph convolution operations directly
within recurrent gating mechanisms, enabling simultaneous modeling of evolving
dynamics and temporal dependencies. Extensive validations on modified IEEE
9-bus, 39-bus, and a multi-terminal HVDC network demonstrate high performance,
achieving 99.85\%, 99.90\%, and 99.69\% average accuracies, respectively,
surpassing all tested benchmarks, including classical machine learning
algorithms and recent graph-based models. The framework identifies optimal
combinations of measurements that reduce feature dimensionality by 82\% without
performance degradation. Correlation analysis between dominant measurements for
small-signal and transient stability events validates generalizability across
different stability phenomena. DRAMN achieves state-of-the-art accuracy while
providing enhanced interpretability for power system operators, making it
suitable for real-time deployment in modern control centers.

</details>


### [131] [Analytical modelling of a stop-less modular bus service with an application to charging strategies comparison](https://arxiv.org/abs/2511.03754)
*Haoran Zhao,Neema Nassir,Andres Fielbaum*

Main category: eess.SY

TL;DR: SLAM公交服务通过动态调整容量和V2V充电技术，优化了低需求到高需求下的运营策略，解决了传统公交效率低下和电动公交充电约束问题。


<details>
  <summary>Details</summary>
Motivation: 提高公交服务效率，解决传统公交停靠时间长和电动公交充电约束问题。

Method: 开发了SLAM公交服务的分析优化模型，并集成了V2V充电技术，比较了不同充电策略下的最优设计和可行性。

Result: 识别出了一系列运营阶段：低需求下的空闲运力、满载小公交、满载大公交以及频率上限模式。在移动充电策略下，增加了能源限制模式，最终在高需求下可能导致不可行。

Conclusion: 该研究为公交运营商提供了优化服务、提高效率的策略，特别是在应对不同客流量和充电需求方面。

Abstract: Buses are a vital component of metropolitan public transport, yet
conventional bus services often struggle with inefficiencies including extended
dwelling time, which increases in-vehicle travel time for non-alighting
passengers. A stop-less autonomous modular (SLAM) bus service has emerged as a
solution, enabling dynamic capacity to reduce dwelling time. Meanwhile, the
electrification of buses is advancing as a strategy to mitigate greenhouse gas
emissions and reduces operators' costs, but introduces new operational
constraints due to charging requirements. This study develops analytical
optimization models for SLAM bus service that integrates vehicle-to-vehicle
(V2V) charging technology. By comparing the optimal designs and their
feasibility across non-charging case and charging strategies, we identify a
sequence of operational stages as ridership grows: from idle capacity under low
demand, to full small buses, full large buses, and a proposed frequency-capped
regime where only bus capacity expands. Under the mobile charging strategy,
this progression further includes an energy-limited regime, in which frequency
declines, and ultimately infeasibility under high demand. These findings enable
operators to deliver more efficient services.

</details>


### [132] [Removing Time-Scale Separation in Feedback-Based Optimization via Estimators](https://arxiv.org/abs/2511.03903)
*Niloufar Yousefi,John W. Simpson-Porco*

Main category: eess.SY

TL;DR: FBO 通过利用动态系统模型信息来改进反馈优化，从而在不要求控制器运行时间尺度比受控系统慢的情况下，实现与受控系统相当的收敛速率。


<details>
  <summary>Details</summary>
Motivation: 传统 FBO 在控制稳定动态系统以解决受约束优化问题时，需要控制器运行的时间尺度比受控系统慢，这在一定程度上限制了闭环性能。

Method: 提出了一种基于估计器的 FBO 修改方法，该方法利用动态系统模型信息来消除传统 FBO 的时间尺度分离要求，从而将收敛速率限制为仅由开环系统的特征值决定。

Result: 该方法已扩展到仅基于近似系统模型的情况，并成功应用于基于逆变器的快速电力系统频率控制。

Conclusion: 基于估计器的 FBO 修改方法克服了传统 FBO 的时间尺度限制，提高了闭环性能，并且可以应用于具有近似模型的情况。

Abstract: Feedback-based optimization (FBO) provides a simple control framework for
regulating a stable dynamical system to the solution of a constrained
optimization problem in the presence of exogenous disturbances, and does so
without full knowledge of the plant dynamics. However, closed-loop stability
requires the controller to operate on a sufficiently slower timescale than the
plant, significantly constraining achievable closed-loop performance. Motivated
by this trade-off, we propose an estimator-based modification of FBO which
leverages dynamic plant model information to eliminate the time-scale
separation requirement of traditional FBO. Under this design, the convergence
rate of the closed-loop system is limited only by the dominant eigenvalue of
the open-loop system. We extend the approach to the case of design based on
only an approximate plant model when the original system is singularly
perturbed. The results are illustrated via an application to fast power system
frequency control using inverter-based resources.

</details>


### [133] [A Co-simulation Framework for Quadrotor Control System Design using ROS 2 and MATLAB/Simulink](https://arxiv.org/abs/2511.03969)
*Hangyu Teng*

Main category: eess.SY

TL;DR: 本论文提出一个整合ROS 2和MATLAB/Simulink的共模拟框架，用于四旋翼无人机控制系统设计与验证，实现了高效的无人机控制算法原型制作和软件在环（SIL）验证。


<details>
  <summary>Details</summary>
Motivation: 共模拟是设计和分析复杂网络物理系统的关键方法，可提高开发效率并降低成本。

Method: 提出一个整合ROS 2和MATLAB/Simulink的共模拟框架。首先，基于牛顿-欧拉方程推导了六自由度非线性动态模型。其次，设计并实现了一个分层控制架构：使用LQR控制器进行姿态控制以获得最优调节性能，并使用PID控制器进行位置控制以确保鲁棒性和实际适用性。最后，阐述了框架架构，包括跨平台数据交换机制的实现细节。

Result: 仿真结果证明了该框架的有效性，能够为无人机控制算法的快速原型制作和软件在环（SIL）验证提供高效且标准化的解决方案。

Conclusion: 该框架能够为无人机控制算法的快速原型制作和软件在环（SIL）验证提供高效且标准化的解决方案。

Abstract: Co-simulation is a critical approach for the design and analysis of complex
cyber-physical systems. It will enhance development efficiency and reduce
costs. This paper presents a co-simulation framework integrating ROS 2 and
MATLAB/Simulink for quadrotor unmanned aerial vehicle (UAV) control system
design and verification. First, a six-degree-of-freedom nonlinear dynamic model
of the quadrotor is derived accurately that based on Newton-Euler equations.
Second, within the proposed framework, a hierarchical control architecture was
designed and implemented: LQR controller for attitude control to achieve
optimal regulation performance, and PID controller for position control to
ensure robustness and practical applicability. Third, elaborated the
architecture of the framework, including the implementation details of the
cross-platform data exchange mechanism. Simulation results demonstrate the
effectiveness of the framework, highlighting its capability to provide an
efficient and standardized solution for rapid prototyping and
Software-in-the-Loop (SIL) validation of UAV control algorithms.

</details>


### [134] [Necessary and Sufficient Conditions for the Optimization-Based Concurrent Execution of Learned Robotic Tasks](https://arxiv.org/abs/2511.04054)
*Sheikh A. Tahmid,Gennaro Notomista*

Main category: eess.SY

TL;DR: 本论文研究如何在一个基于优化的框架中执行由强化学习（RL）学习到的多个值函数编码的任务，并解决了现有研究中未回答的关于何时可以并发执行这些值函数的问题。


<details>
  <summary>Details</summary>
Motivation: 现有研究提出的基于优化的框架在并发执行学习到的值函数方面存在不足，未能回答何时可以并发执行的问题。

Method: 提出定理，为在状态空间子集中使用最小范数控制器并发执行学习到的任务集提供了必要和充分的条件。

Result: 通过提出的定理，深入了解了何时可以使学习到的控制任务并发执行，何时它们本身就已具备并发可执行性，以及何时使用先前提出的方法根本无法实现任务的并发可执行性。

Conclusion: 本研究提出的定理为理解和实现多任务并发执行提供了理论基础，并扩展了优化框架以支持带有折扣因子的值函数，使其更符合标准的强化学习实践。

Abstract: In this work, we consider the problem of executing multiple tasks encoded by
value functions, each learned through Reinforcement Learning, using an
optimization-based framework. Prior works develop such a framework, but left
unanswered a fundamental question of when learned value functions can be
concurrently executed. The main contribution of this work is to present
theorems which provide necessary and sufficient conditions to concurrently
execute sets of learned tasks within subsets of the state space, using a
previously proposed min-norm controller. These theorems provide insight into
when learned control tasks are possible to be made concurrently executable,
when they might already inherently be concurrently executable and when it is
not possible at all to make a set of learned tasks concurrently executable
using the previously proposed methods. Additional contributions of this work
include extending the optimization-based framework to execute multiple tasks
encoded by value functions to also account for value functions trained with a
discount factor, making the overall framework more compatible with standard RL
practices.

</details>


### [135] [Differential Flatness of Quasi-Static Slider-Pusher Models with Applications in Control](https://arxiv.org/abs/2511.04246)
*Sander De Witte,Tom Lefebvre,Thomas Neve,Andras Retzler,Guillaume Crevecoeur*

Main category: eess.SY

TL;DR: 该论文研究了平面滑块-推动器系统作为操作任务中的运动原语的动态特性。


<details>
  <summary>Details</summary>
Motivation: 研究平面滑块-推动器系统的动态特性，以其作为操作任务中的运动原语。

Method: 在准静态假设和可忽略接触摩擦的条件下，构建了基于极限曲面法的微分运动学模型，该模型适用于通用的滑块形状和圆柱形推动器，并推导了系统的微分运动学表示。在此基础上，分析了滑块-推动器系统的固有属性——微分平坦性，并提出了一种控制策略，用于轨迹跟踪，包括准静态反馈策略和动态反馈线性化方法。

Result: 滑块-推动器系统（具有多边形滑块和圆形推动器）具有微分平坦性，并将质心确定为平坦输出。提出的两种控制策略（准静态反馈和动态反馈线性化）通过闭环仿真（包含扰动模型和输入噪声）和使用具有类似手指的推动器和基于视觉的状态检测的物理设置进行了验证。

Conclusion: 仿真和实验结果证实了所提出方法的有效性，证明了这些方法在实际应用中的潜力。

Abstract: This paper investigates the dynamic properties of planar slider-pusher
systems as a motion primitive in manipulation tasks. To that end, we construct
a differential kinematic model deriving from the limit surface approach under
the quasi-static assumption and with negligible contact friction. The
quasi-static model applies to generic slider shapes and circular pusher
geometries, enabling a differential kinematic representation of the system.
From this model, we analyze differential flatness - a property advantageous for
control synthesis and planning - and find that slider-pusher systems with
polygon sliders and circular pushers exhibit flatness with the centre of mass
as a flat output. Leveraging this property, we propose two control strategies
for trajectory tracking: a cascaded quasi-static feedback strategy and a
dynamic feedback linearization approach. We validate these strategies through
closed-loop simulations incorporating perturbed models and input noise, as well
as experimental results using a physical setup with a finger-like pusher and
vision-based state detection. The real-world experiments confirm the
applicability of the simulation gains, highlighting the potential of the
proposed methods for

</details>


### [136] [ComEMS4Build: Comfort-Oriented Energy Management System for Residential Buildings using Hydrogen for Seasonal Storage](https://arxiv.org/abs/2511.04293)
*Jovana Kovačević,Felix Langner,Erfan Tajalli-Ardekani,Marvin Dorn,Simon Waczowicz,Ralf Mikut,Jörg Matthes,Hüseyin K. Çakmak,Veit Hagenmeyer*

Main category: eess.SY

TL;DR: 该研究提出了一种面向舒适度的建筑能源管理系统（ComEMS4Build），该系统集成了光伏、电池储能和氢储能，并辅以燃料电池和热泵，旨在优化冬季德国家庭用户的能源使用。


<details>
  <summary>Details</summary>
Motivation: 为了解决住宅部门整合柔性负荷和储能系统以匹配波动的可再生能源发电与需求的问题，并提出利用氢储能系统实现季节性能源转移，同时通过耦合燃料电池和热泵来降低氢储能系统的初始成本。

Method: 开发并使用一种基于模糊逻辑的面向舒适度的建筑能源管理系统（ComEMS4Build），该系统包含光伏、电池储能和氢储能，并以燃料电池和热泵作为补充技术。使用半合成建模方法，在德国一个家庭住宅建筑中对该系统进行了为期12周的冬季模拟评估，并与基于规则的控制（RBC）和模型预测控制（MPC）进行了比较。

Result: ComEMS4Build 在 12 周中的 10 周内均未违反热舒适性要求，表现与 MPC 相当，而 RBC 的中位数不适度为 0.68 Kh。ComEMS4Build 相比 MPC 增加了 12.06 欧元的周用电成本，而 RBC 则增加了 30.14 欧元。ComEMS4Build 提高了混合储能系统（HESS）的利用率和与电网的能源交换，优于 RBC。然而，在燃料电池运行方面，RBC 减少了 3.48% 的切换次数和 7.59% 的工作时间，优于 MPC。

Conclusion: ComEMS4Build 在满足热舒适性、提高储能利用率和能源交换方面表现良好，但增加了额外的电力成本。RBC 在燃料电池运行方面更具优势。未来的研究可以进一步优化成本效益和燃料电池的运行策略。

Abstract: Integrating flexible loads and storage systems into the residential sector
contributes to the alignment of volatile renewable generation with demand.
Besides batteries serving as a short-term storage solution, residential
buildings can benefit from a Hydrogen (H2) storage system, allowing seasonal
shifting of renewable energy. However, as the initial costs of H2 systems are
high, coupling a Fuel Cell (FC) with a Heat Pump (HP) can contribute to the
size reduction of the H2 system. The present study develops a Comfort-Oriented
Energy Management System for Residential Buildings (ComEMS4Build) comprising
Photovoltaics (PV), Battery Energy Storage System (BESS), and H2 storage, where
FC and HP are envisioned as complementary technologies. The fuzzy-logic-based
ComEMS4Build is designed and evaluated over a period of 12 weeks in winter for
a family household building in Germany using a semi-synthetic modeling
approach. The Rule-Based Control (RBC), which serves as a lower benchmark, is a
scheduler designed to require minimal inputs for operation. The Model
Predictive Control (MPC) is intended as a cost-optimal benchmark with an ideal
forecast. The results show that ComEMS4Build, similar to MPC, does not violate
the thermal comfort of occupants in 10 out of 12 weeks, while RBC has a
slightly higher median discomfort of 0.68 Kh. The ComEMS4Build increases the
weekly electricity costs by 12.06 EUR compared to MPC, while RBC increases the
weekly costs by 30.14 EUR. The ComEMS4Build improves the Hybrid Energy Storage
System (HESS) utilization and energy exchange with the main grid compared to
the RBC. However, when it comes to the FC operation, the RBC has an advantage,
as it reduces the toggling counts by 3.48% and working hours by 7.59% compared
to MPC...

</details>


### [137] [Data-Driven Modeling of Photosynthesis Regulation Under Oscillating Light Condition - Part I: In-Silico Exploration](https://arxiv.org/abs/2511.04330)
*Christian Portilla,Arviandy G Aribowo,Ramachandran Anantharaman,César A Gómez-Pérez,Leyla Özkan*

Main category: eess.SY

TL;DR: 该研究使用数据驱动的系统辨识技术，在频域内获得了光照振荡条件下光合作用调控的简化、面向控制的模型。


<details>
  <summary>Details</summary>
Motivation: 在振荡光照条件下，获得光合作用调控的简化、面向控制的模型。

Method: 使用基于物理的DREAM模型（BDM）仿真的数据，通过最佳线性逼近（BLA）方法估计二阶线性时不变（LTI）传递函数模型，并构建了线性参数时变（LPV）表示。

Result: 在不同的直流偏置和调制频率下，估计了二阶LTI传递函数模型，并构建了由直流光强值定义的调度参数的LPV表示。

Conclusion: 数据驱动的频域系统辨识技术可以成功地获得光合作用调控的简化模型，可用于控制目的。

Abstract: This paper explores the application of data-driven system identification
techniques in the frequency domain to obtain simplified, control-oriented
models of photosynthesis regulation under oscillating light conditions.
In-silico datasets are generated using simulations of the physics-based Basic
DREAM Model (BDM) Funete et al.[2024], with light intensity signals --
comprising DC (static) and AC (modulated) components as input and chlorophyll
fluorescence (ChlF) as output. Using these data, the Best Linear Approximation
(BLA) method is employed to estimate second-order linear time-invariant (LTI)
transfer function models across different operating conditions defined by DC
levels and modulation frequencies of light intensity. Building on these local
models, a Linear Parameter-Varying (LPV) representation is constructed, in
which the scheduling parameter is defined by the DC values of the light
intensity, providing a compact state-space representation of the system
dynamics.

</details>


### [138] [Overview and Performance Evaluation of Supervisory Controller Synthesis with Eclipse ESCET v4.0](https://arxiv.org/abs/2511.04370)
*Dennis Hendriks,Michel Reniers,Wan Fokkink,Wytse Oortwijn*

Main category: eess.SY

TL;DR: 本论文介绍了CIF（控制意图形式化）建模语言和工具，重点在于其在监控器综合方面的应用，并通过基准模型评估了近期性能改进和多层综合方法。


<details>
  <summary>Details</summary>
Motivation: 旨在自动化监控器设计和实现，解决实际应用中被忽略但重要的方面，如运行时错误预防、处理不同类型的需求以及支持输入变量。

Method: 描述了CIF的符号化监控器综合算法，包括处理运行时错误、不同类型的需求和输入变量。同时，引入并描述了CIF的基准模型库，并评估了ESCET工具集近期版本（v0.8至v4.0）在综合性能上的改进，以及多层综合方法的效果。

Result: CIF的算法能够处理实际应用中的复杂问题，基准模型库提供了多样化的测试案例，近期性能改进在一定程度上提升了综合效率，但对于复杂模型仍有提升空间。多层综合方法在特定情况下能提升性能。

Conclusion: CIF在监控器综合方面取得了显著进展，尤其是在处理实际应用问题和提供基准测试方面。虽然性能有所提升，但对于复杂模型的综合仍需进一步优化。多层综合方法是一种有前景的方向，但需要进一步研究以实现更广泛的应用。

Abstract: Supervisory controllers control cyber-physical systems to ensure their
correct and safe operation. Synthesis-based engineering (SBE) is an approach to
largely automate their design and implementation. SBE combines model-based
engineering with computer-aided design, allowing engineers to focus on 'what'
the system should do (the requirements) rather than 'how' it should do it
(design and implementation). In the Eclipse Supervisory Control Engineering
Toolkit (ESCET) open-source project, a community of users, researchers, and
tool vendors jointly develop a toolkit to support the entire SBE process,
particularly through the CIF modeling language and tools. In this paper, we
first provide a description of CIF's symbolic supervisory controller synthesis
algorithm, and thereby include aspects that are often omitted in the
literature, but are of great practical relevance, such as the prevention of
runtime errors, handling different types of requirements, and supporting input
variables (to connect to external inputs). Secondly, we introduce and describe
CIF's benchmark models, a collection of 23 freely available industrial and
academic models of various sizes and complexities. Thirdly, we describe recent
improvements between ESCET versions v0.8 (December 2022) and v4.0 (June 2024)
that affect synthesis performance, evaluate them on our benchmark models, and
show the current practical synthesis performance of CIF. Fourthly, we briefly
look at multi-level synthesis, a non-monolithic synthesis approach, evaluate
its gains, and show that while it can help to further improve synthesis
performance, further performance improvements are still needed to synthesize
complex models.

</details>


### [139] [Deep Koopman Economic Model Predictive Control of a Pasteurisation Unit](https://arxiv.org/abs/2511.04437)
*Patrik Valábek,Michaela Horváthová,Martin Klaučo*

Main category: eess.SY

TL;DR: 本研究提出了一种基于深度Koopman的经济模型预测控制（EMPC）方法，用于实验室规模巴氏杀菌单元（PU）的高效运行。该方法利用Koopman算子理论将非线性系统动力学线性化，并使用神经网络从实验数据中学习线性动力学，提高了预测精度。将此模型应用于包含能源消耗、物料损失和执行器磨损等经济成本的EMPC，并通过拉格朗日乘子法保证了可行性。在多变量PU非线性模型上进行了数值验证，考虑了外部干扰。结果表明，基于深度Koopman的EMPC相比于传统的N4SID方法，总经济成本降低了32%，主要得益于物料损失和能源消耗的减少。此外，稳态运行下电气能源消耗减少了10.2%。研究强调了深度Koopman表示与经济优化结合在实现节能控制方面的实际优势。


<details>
  <summary>Details</summary>
Motivation: 本研究旨在为实验室规模巴氏杀菌单元（PU）提供一种高效的运行控制方法，通过深度Koopman模型和经济模型预测控制（EMPC）相结合，以解决传统方法在处理复杂非线性系统和优化经济成本方面的不足。

Method: 本研究提出了一种基于深度Koopman算子理论的EMPC方法。首先，利用Koopman算子理论将PU的复杂非线性动力学转化为线性表示，并使用神经网络（深度Koopman模型）从实验数据中学习该线性动力学。然后，将此模型集成到EMPC框架中，该框架考虑了能源消耗、物料损失和执行器磨损等经济成本。通过引入拉格朗日乘子法保证了控制的可行性。最后，在PU的非线性模型上进行了数值验证，并与基于N4SID子空间辨识的EMPC进行了比较。

Result: 深度Koopman模型在预测精度上比N4SID方法提高了45%。基于深度Koopman的EMPC在面对外部干扰时，与N4SID EMPC相比，总经济成本降低了32%，主要体现在物料损失和能源消耗的减少。此外，基于Koopman的EMPC在稳态运行时，电气能源消耗减少了10.2%。

Conclusion: 本研究成功地将深度Koopman表示与经济模型预测控制相结合，为巴氏杀菌单元等热密集型设备的资源高效控制提供了一种有效的解决方案。该方法不仅提高了预测精度，还显著降低了运行的经济成本和能源消耗，显示出实际应用价值。

Abstract: This paper presents a deep Koopman-based Economic Model Predictive Control
(EMPC) for efficient operation of a laboratory-scale pasteurization unit (PU).
The method uses Koopman operator theory to transform the complex, nonlinear
system dynamics into a linear representation, enabling the application of
convex optimization while representing the complex PU accurately. The deep
Koopman model utilizes neural networks to learn the linear dynamics from
experimental data, achieving a 45% improvement in open-loop prediction accuracy
over conventional N4SID subspace identification. Both analyzed models were
employed in the EMPC formulation that includes interpretable economic costs,
such as energy consumption, material losses due to inadequate pasteurization,
and actuator wear. The feasibility of EMPC is ensured using slack variables.
The deep Koopman EMPC and N4SID EMPC are numerically validated on a nonlinear
model of multivariable PU under external disturbance. The disturbances include
feed pump fail-to-close scenario and the introduction of a cold batch to be
pastuerized. These results demonstrate that the deep Koopmand EMPC achieves a
32% reduction in total economic cost compared to the N4SID baseline. This
improvement is mainly due to the reductions in material losses and energy
consumption. Furthermore, the steady-state operation via Koopman-based EMPC
requires 10.2% less electrical energy. The results highlight the practical
advantages of integrating deep Koopman representations with economic
optimization to achieve resource-efficient control of thermal-intensive plants.

</details>


### [140] [Deep Dictionary-Free Method for Identifying Linear Model of Nonlinear System with Input Delay](https://arxiv.org/abs/2511.04451)
*Patrik Valábek,Marek Wadinger,Michal Kvasnica,Martin Klaučo*

Main category: eess.SY

TL;DR: 本文提出了一种基于LSTM的深度koopman模型，用于处理具有时滞的非线性动力学系统，能够在线性空间中近似koopman算子，实现对带时滞系统的预测、估计和控制。


<details>
  <summary>Details</summary>
Motivation: 由于非线性动力学系统固有的复杂性以及时滞对系统行为的影响，其预测、估计和控制面临巨大挑战。传统的线性控制技术在这种情况下往往失效，需要创新的方法。

Method: 利用LSTM（长短期记忆）层来捕捉历史依赖关系，并将带时滞的系统动力学有效地编码到潜在空间中，从而实现koopman 算子的近似。该模型是无字典的，解决了传统eDMD方法中需要预定义字典和已知系统动力学的问题。

Result: 在模拟系统上与扩展eDMD进行量化比较，证明了在真实非线性动力学未知的情况下，预测精度方面具有显著的性能提升，并且在系统动力学已知的情况下，取得了与eDMD相当的结果。

Conclusion: 所提出的LSTM增强深度koopman模型能够有效地处理具有时滞的非线性动力学系统，并在预测精度方面优于传统方法，尤其是在系统动力学未知的情况下。

Abstract: Nonlinear dynamical systems with input delays pose significant challenges for
prediction, estimation, and control due to their inherent complexity and the
impact of delays on system behavior. Traditional linear control techniques
often fail in these contexts, necessitating innovative approaches. This paper
introduces a novel approach to approximate the Koopman operator using an
LSTM-enhanced Deep Koopman model, enabling linear representations of nonlinear
systems with time delays. By incorporating Long Short-Term Memory (LSTM)
layers, the proposed framework captures historical dependencies and efficiently
encodes time-delayed system dynamics into a latent space. Unlike traditional
extended Dynamic Mode Decomposition (eDMD) approaches that rely on predefined
dictionaries, the LSTM-enhanced Deep Koopman model is dictionary-free, which
mitigates the problems with the underlying dynamics being known and
incorporated into the dictionary. Quantitative comparisons with extended eDMD
on a simulated system demonstrate highly significant performance gains in
prediction accuracy in cases where the true nonlinear dynamics are unknown and
achieve comparable results to eDMD with known dynamics of a system.

</details>


### [141] [Data-driven uncertainty-aware seakeeping prediction of the Delft 372 catamaran using ensemble Hankel dynamic mode decomposition](https://arxiv.org/abs/2511.04461)
*Giorgio Palma,Andrea Serani,Matteo Diez*

Main category: eess.SY

TL;DR: 该研究提出并验证了一种基于集成学习的 Hankel 动态模式分解与控制（HDMDc）方法，用于高速双体船（Delft 372 模型）的不确定性感知耐波性预测。通过在波浪水槽中进行实验，收集了不同海况下的船体运动和阻力数据。HDMDc 通过增加时间延迟的状态和输入来构建无方程的线性降阶模型，以捕捉非线性和记忆效应。研究比较了两种集成策略：贝叶斯 HDMDc（BHDMDc）和频率 HDMDc（FHDMDc）。结果表明，FHDMDc 提高了预测精度并提供了不确定性估计，而 BHDMDc 在此案例中未显示出优势。FHDMDc 预测的运动概率密度函数与实验数据和 URANS 结果吻合良好，证明了其在设计和运营支持方面具有可靠且计算高效的潜力。


<details>
  <summary>Details</summary>
Motivation: 为了对高速双体船的耐波性进行不确定性感知的预测，提出并验证了一种集成学习的 Hankel 动态模式分解与控制（HDMDc）方法。

Method: HDMDc 通过增加状态和输入的时间延迟年来构建无方程的线性降阶模型，以捕捉非线性和记忆效应。研究中比较了两种集成策略：贝叶斯 HDMDc（BHDMDc）和频率 HDMDc（FHDMDc）。

Result: FHDMDc 提高了预测精度并提供了不确定性估计，而 BHDMDc 在此案例中未显示出优势。FHDMDc 预测的运动概率密度函数与实验数据和 URANS 结果吻合良好。

Conclusion: FHDMDc 是一种可靠且计算高效的耐波性预测方法，可用于设计和运营支持。

Abstract: In this study, we present and validate an ensemble-based Hankel Dynamic Mode
Decomposition with control (HDMDc) for uncertainty-aware seakeeping predictions
of a high-speed catamaran, namely the Delft 372 model. Experimental
measurements (time histories) of wave elevation at the longitudinal center of
gravity, heave, pitch, notional flight-deck velocity, notional bridge
acceleration, and total resistance were collected from irregular wave basin
tests on a 1:33.3 scale replica of the Delft 372 model under sea state 5
conditions at Fr = 0.425, and organized into training, validation, and test
sets. The HDMDc algorithm constructs an equation-free linear reduced-order
model of the seakeeping vessel by augmenting states and inputs with their
time-lagged copies to capture nonlinear and memory effects. Two ensembling
strategies, namely Bayesian HDMDc (BHDMDc), which samples hyperparameters
considered stochastic variables with prior distribution to produce posterior
mean forecasts with confidence intervals, and Frequentist HDMDc (FHDMDc), which
aggregates multiple model obtained over data subsets, are compared in providing
seakeeping prediction and uncertainty quantification. The FHDMDc approach is
found to improve the accuracy of the predictions compared to the deterministic
counterpart, also providing robust uncertainty estimation; whereas the
application of BHDMDc to the present test case is not found beneficial in
comparison to the deterministic model. FHDMDc-derived probability density
functions for the motions closely match both experimental data and URANS
results, demonstrating reliable and computationally efficient seakeeping
prediction for design and operational support.

</details>


### [142] [AI-Driven Phase-Shifted Carrier Optimization for Cascaded Bridge Converters, Modular Multilevel Converters, and Reconfigurable Batteries](https://arxiv.org/abs/2511.04470)
*Amin Hashemi-Zadeh,Nima Tashakor,Sandun Hettiarachchi,Stefan Goetz*

Main category: eess.SY

TL;DR: PSC-PWM在级联桥式转换器、模块化多电平转换器和可重构电池中存在脉冲宽度不均匀、纹波电流大和输出电压失真等问题。本文提出一种神经网络来优化相位偏移，以解决这些问题。


<details>
  <summary>Details</summary>
Motivation: 传统的PSC-PWM方法存在脉冲宽度不均匀、纹波电流大和输出电压失真等问题，而相位偏移的优化计算量大，超出了简单嵌入式控制器的能力。

Method: 提出一种神经网络来模拟瞬时优化器的行为，以降低计算负担，并提出一种简单的缩放策略，允许重用为较少模块训练的神经网络。

Result: 该方法可以实时将电流纹波和加权总谐波失真平均降低高达50%，并且比传统优化器快100到50万倍。

Conclusion: 所提出的神经网络方法通过优化相位偏移，解决了PSC-PWM的纹波电流和输出电压失真问题，并且计算效率高，适用于在线应用。

Abstract: Phase-shifted carrier pulse-width modulation (PSC-PWM) is a widely adopted
scheduling algorithm in cascaded bridge converters, modular multilevel
converters, and reconfigurable batteries. However, non-uniformed pulse widths
for the modules with fixed phase shift angles lead to significant ripple
current and output-voltage distortion. Voltage uniformity instead would require
optimization of the phase shifts of the individual carriers. However, the
computational burden for such optimization is beyond the capabilities of any
simple embedded controller. This paper proposes a neural network that emulates
the behavior of an instantaneous optimizer with significantly reduced
computational burden. The proposed method has the advantages of stable
performance in predicting the optimum phase-shift angles under balanced battery
modules with non-identical modulation indices without requiring extensive
lookup tables, slow numerical optimization, or complex controller tuning. With
only one (re)training session for any specified number of modules, the proposed
method is readily adaptable to different system sizes. Furthermore, the
proposed framework also includes a simple scaling strategy that allows a neural
network trained for fewer modules to be reused for larger systems by grouping
modules and adjusting their phase shifts. The scaling strategy eliminates the
need for retraining. Large-scale assessment, simulations, and experiments
demonstrate that, on average, the proposed approach can reduce the current
ripple and the weighted total harmonic distortion by up to 50 % in real time
and is 100 to 500 thousand times faster than a conventional optimizer (e.g.,
genetic algorithms), making it the only solution for an online application.

</details>


### [143] [Synchronous Observer Design for Landmark-Inertial SLAM with Almost-Global Convergence](https://arxiv.org/abs/2511.04531)
*Arkadeep Saha,Pieter van Goor,Antonio Franchi,Ravi Banavar*

Main category: eess.SY

TL;DR: 该论文提出了一种用于车辆定位与地图绘制（SLAM）的非线性观测器。


<details>
  <summary>Details</summary>
Motivation: 在车辆定位与地图绘制（SLAM）的背景下，提出一种用于处理包含地标位置测量和惯性测量单元（IMU）测量数据的非线性观测器。

Method: 提出一种连续时间非线性观测器，并在编码了LI-SLAM所有可观状态的基空间中对该观测器进行分析。

Result: 证明了在基空间中的误差动力学的局部指数稳定性和几乎全局渐近稳定性，并通过仿真进行了验证。

Conclusion: 所提出的非线性观测器在理论上和仿真上都证明了其在LI-SLAM问题上的有效性。

Abstract: Landmark Inertial Simultaneous Localisation and Mapping (LI-SLAM) is the
problem of estimating the locations of landmarks in the environment and the
robot's pose relative to those landmarks using landmark position measurements
and measurements from Inertial Measurement Unit (IMU). This paper proposes a
nonlinear observer for LI-SLAM posed in continuous time and analyses the
observer in a base space that encodes all the observable states of LI-SLAM. The
local exponential stability and almost-global asymptotic stability of the error
dynamics in base space is established in the proof section and validated using
simulations.

</details>


### [144] [Funnel-Based Online Recovery Control for Nonlinear Systems With Unknown Dynamics](https://arxiv.org/abs/2511.04626)
*Zihao Song,Shirantha Welikala,Panos J. Antsaklis,Hai Lin*

Main category: eess.SY

TL;DR: 本篇论文提出了一种用于非线性系统从攻击或故障中恢复的控制方法，利用循环均衡网络（RENs）学习未知动态并结合漏斗控制实现状态恢复。


<details>
  <summary>Details</summary>
Motivation: 解决非线性系统从攻击或故障中恢复时，学习未知动态（具有形式保证）和寻找不变集（确保状态偏差在名义轨迹允许范围内）的挑战。

Method: 应用循环均衡网络（RENs）学习未知动态，并利用增量积分二次约束（IQC）保证其输入输出特性。然后，提出一种基于漏斗的控制方法，通过推导名义轨迹稳定化的充分条件和不变漏斗来实现系统从偏差状态恢复。

Result: 通过直流微电网控制应用的仿真示例，展示了所提出控制方法的有效性。

Conclusion: 所提出的方法能够有效地从攻击或故障中恢复非线性系统，并通过仿真得到验证。

Abstract: In this paper, we focus on recovery control of nonlinear systems from attacks
or failures. The main challenges of this problem lie in (1) learning the
unknown dynamics caused by attacks or failures with formal guarantees, and (2)
finding the invariant set of states to formally ensure the state deviations
allowed from the nominal trajectory. To solve this problem, we propose to apply
the Recurrent Equilibrium Networks (RENs) to learn the unknown dynamics using
the data from the real-time system states. The input-output property of this
REN model is guaranteed by incremental integral quadratic constraints (IQCs).
Then, we propose a funnel-based control method to achieve system recovery from
the deviated states. In particular, a sufficient condition for nominal
trajectory stabilization is derived together with the invariant funnels along
the nominal trajectory. Eventually, the effectiveness of our proposed control
method is illustrated by a simulation example of a DC microgrid control
application.

</details>


### [145] [Control Affine Hybrid Power Plant Subsystem Modeling for Supervisory Control Design](https://arxiv.org/abs/2511.04644)
*Stephen Ampleman,Himanshu Sharma,Sayak Mukherjee,Sonja Glavaski*

Main category: eess.SY

TL;DR: 该论文提出了一种混合动力发电厂（HPP）的建模和控制设计框架，该HPP包括风电场、太阳能电站和电池储能。


<details>
  <summary>Details</summary>
Motivation: 为了支持发电不足和满足电网需求，需要一种能够结合多种发电（常规/可变）和储能能力的混合动力发电厂（HPP）。

Method: 本研究将风电场、太阳能电站和电池模型整合成控制仿射形式，适用于监督层面的控制设计。针对风力和电池模型，利用非线性控制和控制屏障函数技术开发了发电机扭矩和电池电流控制律，以跟踪来自监督控制律的指令，同时保持安全稳定的运行。

Result: 通过一个测试案例，使用公用事业需求信号进行跟踪，以及时变风能和辐照度数据，并采用基于规则的监督控制律，说明了该建模和控制框架的实用性。

Conclusion: 所提出的框架能够对混合动力发电厂进行建模和控制，确保安全稳定运行并满足电网需求。

Abstract: Hybrid power plants (HPPs) combine multiple power generators
(conventional/variable) and energy storage capabilities to support generation
inadequacy and grid demands. This paper introduces a modeling and control
design framework for hybrid power plants (HPPs) consisting of a wind farm,
solar plant, and battery storage. Specifically, this work adapts established
modeling paradigms for wind farms, solar plants and battery models into a
control affine form suitable for control design at the supervisory level. In
the case of wind and battery models, generator torque and cell current control
laws are developed using nonlinear control and control barrier function
techniques to track a command from a supervisory control law while maintaining
safe and stable operation. The utility of this modeling and control framework
is illustrated through a test case using a utility demand signal for tracking,
time varying wind and irradiance data, and a rule-based supervisory control
law.

</details>


<div id='cond-mat.mtrl-sci'></div>

# cond-mat.mtrl-sci [[Back]](#toc)

### [146] [A data-driven quest for room-temperature bulk plastically deformable ceramics](https://arxiv.org/abs/2511.03815)
*Iwo Słodczyk,Alexander Frisch,Xufei Fang,Inna Gitman,Fengxian Liu*

Main category: cond-mat.mtrl-sci

TL;DR: 该研究采用数据驱动方法，识别出影响陶瓷室温下塑性的关键参数，包括泊松比、Pugh比、Burgers向量、晶体结构、熔化温度和Bader电荷，并建立了多尺度描述符空间，为理解和设计延性陶瓷奠定基础。


<details>
  <summary>Details</summary>
Motivation: 陶瓷材料室温下塑性的研究日益受到关注，需要识别影响塑性的关键参数。

Method: 整合包含55种陶瓷材料（38种塑性，17种脆性）的数据集，采用数据驱动方法识别预测塑性的关键参数。

Result: 研究识别出泊松比、Pugh比、Burgers向量、晶体结构、熔化温度和Bader电荷是预测陶瓷室温塑性的关键参数，并构建了多尺度描述符空间。

Conclusion: 本研究首次系统性地、数据驱动地绘制了陶瓷塑性的控制因素图谱，为统一实验和计算研究提供了基础，有助于理解和设计本征延性陶瓷。

Abstract: The growing number of ceramics exhibiting bulk plasticity at room temperature
has renewed interest in revisiting plastic deformation and dislocation-mediated
mechanical and functional properties in these materials. In this work, a
data-driven approach is employed to identify the key parameters governing
room-temperature bulk plasticity in ceramics. The model integrates an existing
dataset of 55 ceramic materials, 38 plastically deformable and 17 brittle, and
achieves accurate classification of bulk plasticity. The analysis reveals
several key parameters essential for predicting bulk plasticity: i) Poisson's
ratio and Pugh's ratio as macroscopic indicators reflecting the balance between
shear and volumetric deformation resistance, and ii) Burgers vector, crystal
structure and melting temperature as crystallographic descriptors associated
with lattice geometry, slip resistance and thermal stability, and iii) Bader
charge as a microscopic measure of bonding character. Together, these
parameters define a multiscale descriptor space linking intrinsic materials
properties to bulk room-temperature plasticity in ceramics, bridging the gap
between empirical ductility criteria and atomistic mechanisms of
dislocation-mediated plasticity. While preliminary, this study provides the
first systematic, data-driven mapping of the governing factors of ceramic
plasticity. The resulting framework establishes a foundation for unifying
experimental and computational studies through shared datasets and descriptors,
fostering collective progress toward understanding and designing intrinsically
ductile ceramics.

</details>


### [147] [Crystallization Behavior of ZBLAN Glass Under Combined Thermal and Vibrational Effects: Part II - COMSOL Simulation and Apparatus Redesign](https://arxiv.org/abs/2511.03821)
*Ayush Subedi,Anthony Torres,Jeff Ganley*

Main category: cond-mat.mtrl-sci

TL;DR: 振动辅助热处理ZBLAN玻璃时，接触电阻会导致非均匀加热，通过倾斜样品和有限元模拟解决了这个问题，研究了不同振动参数下的结晶行为，并提出了适用于地基和微重力环境的预测模型。


<details>
  <summary>Details</summary>
Motivation: 研究振动辅助热处理ZBLAN玻璃时，由于接触电阻导致的热传导效率降低和非均匀加热问题，并探索优化工艺参数以实现均匀结晶。

Method: 采用COMSOL Multiphysics进行有限元模拟，分析传导、辐射和接触电阻对传热的影响。通过在实验装置中引入四度倾斜来维持样品与石英管之间的稳定接触。利用显微镜、SEM、EDS和AFM等手段分析了不同振动频率和幅度下ZBLAN的结晶行为。

Result: 有限元模拟证实了接触电阻对传热效率的负面影响。倾斜样品设计成功消除了接触不稳定问题，实现了均匀加热和一致的结晶。研究发现，即使在低至约50 Hz的振动下，ZBLAN也能在360°C左右形成良好的晶体结构。在更高振动频率下，结晶起始温度降低，并且振动会加速成核、提高传热效率，从而将有效拉丝温度窗口大约降低30°C。长时间在330°C以上振动会导致不希望的相变。

Conclusion: 振动辅助热处理ZBLAN玻璃需要精确控制热量和振动。该研究提出的预测模型为在不同重力环境下优化ZBLAN玻璃的加工工艺提供了指导。

Abstract: In Part I of this study, vibration assisted heat treatments of ZBLAN glass
revealed irregular crystallization at higher vibration levels, attributed to
intermittent loss of thermal contact between the sample and the inner silica
ampoule wall. The present work (Part II) investigates this mechanism through
finite element modeling (FEM) and experimental validation.COMSOL Multiphysics
simulations incorporating conduction, radiation, and contact resistance confirm
that intermittent contact markedly reduces heat transfer efficiency, lowering
the sampletemperature. To mitigate this effect, the experimental setup was
redesigned with a four-degree inclination to maintain stable contact during
vibration. Subsequent experiments at vibration levels H3-H5 demonstrated
uniform heating and consistent crystallization behavior.Comprehensive
microscopic, Scanning Electron Microscopy (SEM), Energy Dispersive X-ray
Spectroscopy (EDS), and Atomic Force Microscopy (AFM) analyses revealed that
even at subtle vibration levels (~50 Hz), partially crystallized ZBLAN
transformed into well-developed crystalline structures near 360C. With
increasing vibration amplitude, amorphous ZBLAN began forming incipient
crystalline phases around 330C, and at higher frequencies (~100 Hz), partial
crystallization initiated at approximately 350C. These results indicate that
higher vibration frequencies accelerate nucleation, enhance heat transfer, and
reduce the effective fiber-drawing temperature window by about 30C. Prolonged
exposure above 330C under vibration promotes unwanted phase transitions,
emphasizing the need for precise thermal and vibrational control. This study
establishes a predictive framework for vibration-resistant ZBLAN processing
applicable to both terrestrial and microgravity environments.

</details>


### [148] [Scalable Autoregressive Deep Surrogates for Dendritic Microstructure Dynamics](https://arxiv.org/abs/2511.03884)
*Kaihua Ji,Luning Sun,Shusen Liu,Fei Zhou,Tae Wook Heo*

Main category: cond-mat.mtrl-sci

TL;DR: 使用基于短轨迹的深度学习模型，在有限空间域中加速了材料凝固过程的模拟，实现了两个数量级以上的加速。


<details>
  <summary>Details</summary>
Motivation: 材料和能源系统中广泛存在的枝晶生长等微观结构形成，对材料性能有显著影响。然而，相场法计算成本高，限制了其在材料设计中的应用。

Method: 在有限空间域中，利用定量相场模拟的短轨迹训练了基于自回归深度代理的模型。

Result: 该模型在可扩展的长度和时间尺度上准确预测了枝晶演化，速度比相场法快两个数量级以上。在等温生长和定向凝固实验中，模型能够预测微观结构演化，并在枝晶尖端选择常数、形态对称性和初级间距演化方面与相场基准进行了定量比较，结果吻合良好。

Conclusion: 所提出的机器学习框架能够准确预测枝晶演化，显著提高了计算效率，有望应用于实际材料设计。

Abstract: Microstructural pattern formation, such as dendrite growth, occurs widely in
materials and energy systems, significantly influencing material properties and
functional performance. While the phase-field method has emerged as a powerful
computational tool for modeling microstructure dynamics, its high computational
cost limits its integration into practical materials design workflows. Here, we
introduce a machine-learning framework using autoregressive deep surrogates
trained on short trajectories from quantitative phase-field simulations of
alloy solidification in limited spatial domains. Once trained, these surrogates
accurately predict dendritic evolution at scalable length and time scales,
achieving a speed-up of more than two orders of magnitude. Demonstrations in
isothermal growth and in directional solidification of a dilute Al-Cu alloy
validate their ability to predict microstructure evolution. Quantitative
comparisons with phase-field benchmarks further show excellent agreement in the
tip-selection constant, morphological symmetry, and primary spacing evolution.

</details>


### [149] [Learning to shine: Neuroevolution enables optical control of phase transitions](https://arxiv.org/abs/2511.03895)
*Sraddha Agrawal,Stephen Whitelam,Pierre Darancet*

Main category: cond-mat.mtrl-sci

TL;DR: 利用基于强化学习的梯度无关方法，通过优化时变电场来主动控制固体中的结构相变，实现了非热结构相的稳定，并为控制非平衡动力学和稳定量子材料中的隐藏相提供了实用途径。


<details>
  <summary>Details</summary>
Motivation: 本文旨在解决主动光学操控固体结构相变的问题，并探索利用现有强化学习方法来优化时变电场以稳定非热结构相的可能性。

Method: 采用基于强化学习的方法，结合傅里叶神经网络作为时变电场模型，并利用实验可提取的相空间演化指标进行优化。该方法不依赖梯度，可以直接基于实验数据进行优化。

Result: 成功地利用该方法在有耗散的条件下，通过瞬时拉曼散射稳定了铋中的对称相，证明了该方法在连续和脉冲光源下的有效性。

Conclusion: 该框架提供了一种实用的光控非平衡结构动力学方法，为稳定量子材料中隐藏和亚稳态相开辟了新途径。

Abstract: We address the problem of active optical steering of structural phase
transitions in solids. We demonstrate that existing reinforcement learning
approaches can derive optimal time-dependent electric fields in
optically-driven dissipative classical systems far beyond the harmonic regime,
enabling the stabilization of non-thermal structural phases. Our approach
relies on experimentally extractable metrics of the phase-space evolution and
physically-interpretable Fourier Neural Network surrogates of the
time-dependent electric field. Using first-principles simulations, we
demonstrate the stabilization of a symmetric phase in bismuth through impulsive
Raman scattering under continuous and pulsed light sources in the presence of
dissipation. Importantly, the method is gradient-free, which enables
optimization loops based solely on experimental data, such as the measures of
half-periods of oscillations in transient spectroscopy. Our framework thus
provides a practical route for controlling non-equilibrium structural dynamics
with light, opening pathways to stabilize hidden and metastable phases in
quantum materials.

</details>


### [150] [Unconventional cross sections in zinc phosphide nanowires grown using exclusively earth-abundant components](https://arxiv.org/abs/2511.03906)
*Simon Escobar Steinvall,Hampus Thulin,Nico Kawashima,Francesco Salutari,Jonas Johansson,Aidas Urbonavicius,Sebastian Lehmann,Maria Chiara Spadaro,Jordi Arbiol,Silvana Botti,Kimberly A. Dick*

Main category: cond-mat.mtrl-sci

TL;DR: 采用地球上丰富的材料 Zn3P2，通过 Sn 催化和 Si 衬底外延生长出 Zn3P2 纳米线，并观察到纳米线在不同温度和生长条件下呈现三角形、伪五边形和六边形等横截面形态，其中六边形形态是由于 Sn 掺杂形成了四方结构的异质孪晶，这为可持续太阳能电池和纳米线内量子阱的制备提供了新的途径。


<details>
  <summary>Details</summary>
Motivation: 为了实现轻质柔性太阳能电池应用，必须开发直接带隙吸收材料，并利用地球上丰富且易于获取的元素来提高技术的可持续性影响。

Method: 使用 Sn 作为催化剂和 Si (111) 作为衬底，外延生长 Zn3P2 纳米线。

Result: 在不同温度和生长条件下，观察到 Zn3P2 纳米线呈现三角形（低温）、伪五边形（中温）和六边形（高温，高 V/II 比）的横截面形态。其中，六边形形态是通过 Sn 掺杂在四方结构中形成异质孪晶实现的。

Conclusion: Zn3P2 纳米线是一种有潜力用于可持续太阳能收集的材料，并且可以通过在纳米线内制造异质孪晶来制备量子阱。

Abstract: To enable lightweight and flexible solar cell applications it is imperative
to develop direct bandgap absorber materials. Moreover, to enhance the
potential sustainability impact of the technologies there is a drive to base
the devices on earth-abundant and readily available elements. Herein, we report
on the epitaxial growth of Zn3P2 nanowires using exclusively earth-abundant
components, using Sn as the nanowire catalyst and Si (111) as the substrate. We
observe that the nanowires exhibit a triangular cross section at lower
temperatures, a pseudo-pentagonal cross section at intermediate temperatures,
and a hexagonal cross section in a twin plane superlattice configuration at
high temperatures and high V/II ratios. At low temperatures, the surface facets
are constricted into a metastable configuration, yielding the triangular
morphology due to the symmetry of the substrate, while intermediate
temperatures facilitate the formation of a pseudo-pentagonal morphology with
lower surface to volume ratio. The twin plane superlattice structure can only
be observed at conditions that facilitate the incorporation of Sn into Zn3P2,
which is needed to form heterotwins in the tetragonal structure, namely at high
temperatures and high phosphine partial pressures. These findings show a clear
pathway to use Zn3P2 nanowires in sustainable solar energy harvesting using
exclusively earth-abundant components, as well as opening up a novel route of
fabricating quantum wells inside nanowires using heterotwins.

</details>


### [151] [All-optical magnetization reversal via x-ray magnetic circular dichroism](https://arxiv.org/abs/2511.03965)
*Kihiro T. Yamada,Akira Izumi,Tetsuya Ikebuchi,Sumiyuki Okabe,Masaki Kubo,Ryusei Obata,Rei Kobayashi,Yuya Kubota,Takuo Ohkochi,Naomi Kawamura,Kotaro Higashi,Yoichi Shiota,Takahiro Moriyama,Teruo Ono,Iwao Matsuda,Tadashi Togashi,Yoshihito Tanaka,Motohiro Suzuki*

Main category: cond-mat.mtrl-sci

TL;DR: 使用圆偏振X射线脉冲实现了铁磁材料Pt/Co/Pt多层膜的磁化翻转。


<details>
  <summary>Details</summary>
Motivation: 探究X射线光子及其圆偏振在控制凝聚态物质（特别是磁性现象）序参量方面的潜力，并追踪超快动力学。

Method: 利用圆偏振的X射线自由电子激光脉冲照射铁磁Pt/Co/Pt多层膜，观察并分析磁化翻转现象。

Result: 实现了仅通过辐照圆偏振的X射线脉冲即可进行确定性的磁化翻转，且该现象依赖于入射X射线的圆偏度和在Pt $L_3$边的能量共振。

Conclusion: X射线磁性圆二色性（XMCD）效应，特别是Pt的2$p_{3/2}$核心能级到交换分裂的5d价态的跃迁，是导致这一全光学磁化翻转的原因。这标志着在X射线区域研究光与物质相互作用的新方向。

Abstract: Light polarization is one of the most fundamental features, equivalent to
energy and coherence. Magnetism changes light polarization, and vice versa. The
irradiation of intense circularly polarized femtosecond pules to magnetic
materials can alter the magnetic orders and elementary excitations,
particularly in the visible to infrared spectral regions. Furthermore, the
recent development of x-ray free-electron laser enables the element-specific
trace of the ultrafast dynamics with high time and spatial resolution. However,
the light helicity of x-ray photons has not yet been used to control order
parameters in condensed matter materials, not limited to such magnetic
phenomenon. Here, we demonstrate the deterministic magnetization reversal of a
ferromagnetic Pt/Co/Pt multilayer solely by irradiating femtosecond pulses of
circularly polarized hard x-rays. The observed all-optical magnetization
switching depends on the helicity of incident x-ray pulses and is strongly
resonant with the photon energy at the Pt $L_3$ edge. These results originate
in the x-ray magnetic circular dichroism of Pt, involving helicity-dependent
excitation from the 2$p_{3/2}$ core level to the exchange-split 5$d$ valence
states owing to the magnetic proximity effect with Co. These findings mark a
new frontier for examining interactions between light and matter in the x-ray
region.

</details>


### [152] [KAN-Enhanced Contrastive Learning Accelerating Crystal Structure Identification from XRD Patterns](https://arxiv.org/abs/2511.04055)
*Chenlei Xu,Tianhao Su,Jie Xiong,Yue Wu,Shuya Dong,Tian Jiang,Mengwei He,Shuai Chen,Tong-Yi Zhang*

Main category: cond-mat.mtrl-sci

TL;DR: XCCP是一个结合物理学知识的对比学习框架，用于分析粉末X射线衍射数据，能够高效地进行结构检索和对称性识别，并实现高通量筛选和自主实验室集成。


<details>
  <summary>Details</summary>
Motivation: 现有的粉末X射线衍射分析方法依赖专家知识和缓慢的迭代拟合，限制了其在高通量和自主设置下的可扩展性。本研究旨在开发一种更高效、可扩展的分析方法。

Method: 提出一种名为XCCP的物理引导对比学习框架，该框架将粉末衍射图谱与候选晶体结构对齐在一个共享的嵌入空间中。XCCP的XRD编码器采用双专家设计，结合了Kolmogorov-Arnold网络投影头，一个分支关注低角度反射以反映长程有序性，另一个分支捕捉由对称性决定的密集高角度峰。结合晶体图编码器，进行对比预训练以获得基于物理的表征。

Result: XCCP在结构检索任务上达到了0.89的性能，在空间群识别任务上达到了0.93的准确率。该框架还能泛化到成分相似的多主元合金，并实现了对实验数据的零样本迁移。

Conclusion: XCCP是一种强大、可解释且可扩展的方法，为X射线衍theta分析提供了新的范式。它可以促进高通量筛选、快速结构验证以及集成到自主实验室中。

Abstract: Accurate determination of crystal structures is central to materials science,
underpinning the understanding of composition-structure-property relationships
and the discovery of new materials. Powder X-ray diffraction is a key technique
in this pursuit due to its versatility and reliability. However, current
analysis pipelines still rely heavily on expert knowledge and slow iterative
fitting, limiting their scalability in high-throughput and autonomous settings.
Here, we introduce a physics-guided contrastive learning framework termed as
XCCP. It aligns powder diffraction patterns with candidate crystal structures
in a shared embedding space to enable efficient structure retrieval and
symmetry recognition. The XRD encoder employs a dual-expert design with a
Kolmogorov-Arnold Network projection head, one branch emphasizes low angle
reflections reflecting long-range order, while the other captures dense high
angle peaks shaped by symmetry. Coupled with a crystal graph encoder,
contrastive pretraining yields physically grounded representations. XCCP
demonstrates strong performance across tasks, with structure retrieval reaching
0.89 and space group identification attains 0.93 accuracy. The framework
further generalizes to compositionally similar multi principal element alloys
and demonstrates zero-shot transfer to experimental patterns. These results
establish XCCP as a robust, interpretable, and scalable approach that offers a
new paradigm for X-ray diffraction analysis. XCCP facilitates high-throughput
screening, rapid structural validation and integration into autonomous
laboratories.

</details>


### [153] [TXL Fusion: A Hybrid Machine Learning Framework Integrating Chemical Heuristics and Large Language Models for Topological Materials Discovery](https://arxiv.org/abs/2511.04068)
*Arif Ullah,Rajibul Islam,Ghulam Hussain,Zahir Muhammad,Xiaoguang Li,Ming Yang*

Main category: cond-mat.mtrl-sci

TL;DR: TXL Fusion是一个结合了化学启发、物理描述符和大型语言模型（LLM）的混合机器学习框架，用于加速拓扑材料的发现。


<details>
  <summary>Details</summary>
Motivation: 发现拓扑材料（包括绝缘体和半金属）对量子技术至关重要，但受限于第一性原理计算的高计算成本以及实验合成的缓慢和资源密集性。

Method: 该框架整合了化学启发、工程化的物理描述符以及大型语言模型（LLM）的嵌入，并纳入了空间群对称性、价电子构型和成分衍生指标等特征，以对材料进行分类。

Result: TXL Fusion在分类无聊、TSM和TI类别方面比传统方法具有更高的准确性和泛化能力。通过密度泛化理论（DFT）验证的案例确认了其预测的稳健性，并发现了新的候选材料。

Conclusion: TXL Fusion结合了数据驱动的学习和化学直觉，能够快速、可解释地探索复杂的材料空间，为智能发现下一代拓扑和量子材料提供了可扩展的范例。

Abstract: Topological materials--including insulators (TIs) and semimetals (TSMs)--hold
immense promise for quantum technologies, yet their discovery remains
constrained by the high computational cost of first-principles calculations and
the slow, resource-intensive nature of experimental synthesis. Here, we
introduce TXL Fusion, a hybrid machine learning framework that integrates
chemical heuristics, engineered physical descriptors, and large language model
(LLM) embeddings to accelerate the discovery of topological materials. By
incorporating features such as space group symmetry, valence electron
configurations, and composition-derived metrics, TXL Fusion classifies
materials across trivial, TSM, and TI categories with improved accuracy and
generalization compared to conventional approaches. The framework successfully
identified new candidates, with representative cases further validated through
density functional theory (DFT), confirming its predictive robustness. By
uniting data-driven learning with chemical intuition, TXL Fusion enables rapid
and interpretable exploration of complex materials spaces, establishing a
scalable paradigm for the intelligent discovery of next-generation topological
and quantum materials.

</details>


### [154] [Unconventional Thermal Expansion in quasi-one-dimensional monoclinic BaIrO$_3$](https://arxiv.org/abs/2511.04149)
*Jeong Jinwon,Chang Bin,Noh Han-Jin,Lee Seongsu*

Main category: cond-mat.mtrl-sci

TL;DR: BaIrO3晶体结构在低温下表现出非传统的热膨胀行为，与磁转变温度相关。


<details>
  <summary>Details</summary>
Motivation: 研究准一维单斜BaIrO3的晶体结构对温度的依赖性，并解释其异常热膨胀行为。

Method: 使用X射线衍射测量了13 K至300 K温度范围内BaIrO3的衍射图样，并通过Rietveld精炼提取晶格参数。

Result: 晶胞体积显示出与Debye模型预测的晶格热容存在显著偏差，特别是在接近Debye温度的范围内。偏差起始于弱铁磁转变温度附近，表明其与电子和磁结构变化密切相关。

Conclusion: BaIrO3表现出类似invar的非传统热膨胀行为，这与电子和磁结构的转变密切相关，并不能用传统的Debye模型完全解释。

Abstract: We have investigated the temperature dependence of the crystal structure of
quasi-one-dimensional monoclinic BaIrO$_3$ using X-ray diffraction. Diffraction
patterns were measured across a temperature range from 13 K to 300 K, with
5-degree steps, and Rietveld refinements were performed to extract the relevant
lattice parameters. The resulting cell volumes exhibit a significant deviation
from the Debye model predictions for lattice-specific heat within a reasonable
range of the Debye temperature, Gr{\"u}neisen parameter, and bulk modulus. This
suggests an invar-like, unconventional thermal expansion behavior. The
deviation begins near the weak ferromagnetic transition temperature, indicating
a strong correlation with changes in the electronic and magnetic structure of
monoclinic BaIrO$_3$.

</details>


### [155] [Revealing the innate sub-nanometer porous structure of carbon nanomembranes with molecular dynamics simulations and highly charged ion spectroscopy](https://arxiv.org/abs/2511.04266)
*Filip Vuković,Anna Niggas,Levin Mihlan,Zhen Yao,Armin Gölzhäuser,Louise Fréville,Vladislav Stroganov,Andrey Turchanin,Jürgen Schnack,Nigel A. Marks,Richard A. Wilhelm*

Main category: cond-mat.mtrl-sci

TL;DR: 碳纳米膜（CNM）是一种适用于从能量产生和储存到水过滤的各种应用的纳米级薄无序碳材料。由于自由支撑膜的辐射敏感性，使用传统实验表征技术研究这些纳米膜的结构-性质关系具有挑战性。高电荷离子光谱是一种新颖的表征方法，能够在不担心诱导损伤影响测量的情况下推断碳纳米膜的结构细节。在此，我们采用分子动力学模拟来生产基于对苯二酚的 CNM 的候选结构模型，并具有不同程度的纳米孔隙度，并将预测的离子电荷交换数据和拉伸模量与实验进行比较。结果表明，真空中的 CNM 组成很可能包括很大一部分配位不足的碳，并具有开放的亚纳米孔隙结构。这种碳网络在大气中会是反应性的，并在大气条件下可能由氢和氧基团稳定。


<details>
  <summary>Details</summary>
Motivation: 由于辐射敏感性，传统技术难以研究碳纳米膜的结构-性质关系。

Method: 使用分子动力学模拟生成具有不同孔隙度的对苯二酚基 CNM 的结构模型，并将预测的离子电荷交换数据和拉伸模量与实验进行比较。

Result: 结果表明，真空中的 CNM 组成很可能包括很大一部分配位不足的碳，并具有开放的亚纳米孔隙结构。这种碳网络在大气中会是反应性的，并在大气条件下可能由氢和氧基团稳定。

Conclusion: 高电荷离子光谱是一种有前景的碳纳米膜表征技术，结合分子动力学模拟可以揭示其结构特性。

Abstract: Carbon nanomembranes (CNMs) are nanometer-thin disordered carbon materials
that are suitable for a range of applications, from energy generation and
storage, through to water filtration. The structure-property relationships of
these nanomembranes are challenging to study using traditional experimental
characterization techniques, primarily due to the radiation-sensitivity of the
free-standing membrane. Highly charged ion spectroscopy is a novel
characterization method that is able to infer structural details of the carbon
nanomembrane without concern of induced damage affecting the measurements. Here
we employ molecular dynamics simulations to produce candidate structural models
of terphenylthiol-based CNMs with varying degrees of nanoscale porosity, and
compare predicted ion charge exchange data and tensile moduli to experiment.
The results suggest that the in-vacuum CNM composition likely comprises a
significant fraction of under-coordinated carbon, with an open sub-nanometer
porous structure. Such a carbon network would be reactive in atmosphere and
would be presumably stabilized by hydrogen and oxygen groups under atmospheric
conditions.

</details>


### [156] [The Moving Beam Diffraction Geometry: the DIAD Application of a Diffraction Scanning-Probe](https://arxiv.org/abs/2511.04463)
*Alberto Leonardi,Andrew James,Christina Reinhard,Michael Drakopoulos,Ben Williams,Hans Dehyle,Jacob Filik,Liam Perera,Sharif Ahmed*

Main category: cond-mat.mtrl-sci

TL;DR: DIAD beamline enables quasi-simultaneous X-ray CT and diffraction with a novel moving beam geometry for studying material behavior. Calibration and data reduction routines show high accuracy and reliability.


<details>
  <summary>Details</summary>
Motivation: Quantifying correlations between microstructure, strain, phase, and material behavior is challenging due to the need for multiple instruments separated in space and time.

Method: The DIAD beamline uses two independent beams at one sample position for quasi-simultaneous X-ray Computed Tomography and X-ray Powder Diffraction. A novel moving beam diffraction geometry scans a micron-sized diffraction beam over the imaging field of view without moving the specimen.

Result: The moving beam diffraction geometry shows high sensitivity for the detector position downstream normal to the incident beam. The moving beam probe experiences rigid translation without affecting the incident beam path angle. Nearest-neighbor calibration achieves accuracy comparable to self-calibration for small sample region distances. The absolute error of the moving beam diffraction geometry is below 0.0001.

Conclusion: The DIAD beamline's novel moving beam diffraction geometry is reliable and accurate, enabling the study of fast-evolving and motion-susceptible processes and samples with high precision.

Abstract: Understanding the interactions between microstructure, strain, phase, and
material behavior is crucial in many scientific fields. However, quantifying
these correlations is challenging, as it requires the use of multiple
instruments and techniques, often separated by space and time. The Dual Imaging
And Diffraction (DIAD) beamline at Diamond is designed to address this
challenge. DIAD allows its users to visualize internal structures, identify
compositional/phase changes, and measure strain. DIAD provides two independent
beams combined at one sample position, allowing quasi-simultaneous X-ray
Computed Tomography and X-ray Powder Diffraction. A unique functionality of the
DIAD configuration is the ability to perform image-guided diffraction, where
the micron-sized diffraction beam is scanned over the complete area of the
imaging field of view without moving the specimen. This moving beam diffraction
geometry enables the study of fast-evolving and motion-susceptible processes
and samples. Here, we discuss the novel moving beam diffraction geometry
presenting the latest findings on the reliability of both geometry calibration
and data reduction routines used. Our measures confirm diffraction is most
sensitive to the moving geometry for the detector position downstream normal to
the incident beam. The observed data confirm that the motion of the KB mirror
coupled with a fixed aperture slit results in a rigid translation of the beam
probe, without affecting the angle of the incident beam path to the sample. Our
measures demonstrate a nearest-neighbour calibration can achieve the same
accuracy as a self-calibrated geometry when the distance between calibrated and
probed sample region is smaller or equal to the beam spot size. We show the
absolute error of the moving beam diffraction geometry remains below 0.0001,
which is the accuracy we observe for the beamline with stable beam operation.

</details>


### [157] [Machine learning-driven elasticity prediction in advanced inorganic materials via convolutional neural networks](https://arxiv.org/abs/2511.04468)
*Yujie Liu,Zhenyu Wang,Hang Lei,Guoyu Zhang,Jiawei Xian,Zhibin Gao,Jun Sun,Haifeng Song,Xiangdong Ding*

Main category: cond-mat.mtrl-sci

TL;DR: 利用晶体图卷积神经网络 (CGCNN) 预测了 80664 种无机晶体的剪切模量和体积模量，并公开了预测数据集，为材料设计提供了支持。


<details>
  <summary>Details</summary>
Motivation: 为了克服传统实验测量成本高、效率低的缺点，并利用机器学习预测材料的物理性质，特别是弹性性质（剪切模量、体积模量），这些性质对于预测材料的电导率、热导率和机械性能至关重要。

Method: 训练了两个 CGCNN 模型，使用 Matbench v0.1 数据集中 10987 种材料的剪切模量和体积模量数据。对材料进行了筛选，保留了带隙在 0.1-3.0 eV 之间的材料，并排除了含放射性元素的化合物。最终预测了来自 Materials Project 数据库的 54359 种晶体结构和 Merchant 等人发现的 26305 种晶体结构。

Result: 训练好的 CGCNN 模型在预测剪切模量和体积模量方面表现出高精度（平均绝对误差 <13，决定系数 R 平方接近 1）和良好的泛化能力。最终预测了 80664 种无机晶体的剪切模量和体积模量，并将所有数据公开。

Conclusion: 这项工作完成了对 80664 种无机晶体剪切模量和体积模量的预测，丰富了现有的材料弹性数据资源，并为材料设计提供了强大的支持。所有数据均公开可用。

Abstract: Inorganic crystal materials have broad application potential due to excellent
physical and chemical properties, with elastic properties (shear modulus, bulk
modulus) crucial for predicting materials' electrical conductivity, thermal
conductivity and mechanical properties. Traditional experimental measurement
suffers from high cost and low efficiency, while theoretical simulation and
graph neural network-based machine learning methods--especially crystal graph
convolutional neural networks (CGCNNs)--have become effective alternatives,
achieving remarkable results in predicting material elastic properties. This
study trained two CGCNN models using shear modulus and bulk modulus data of
10987 materials from the Matbench v0.1 dataset, which exhibit high accuracy
(mean absolute error <13, coefficient of determination R-squared close to 1)
and good generalization ability. Materials were screened to retain those with
band gaps between 0.1-3.0 eV and exclude radioactive element-containing
compounds. The final predicted dataset comprises two parts: 54359 crystal
structures from the Materials Project database and 26305 crystal structures
discovered by Merchant et al. (2023 Nature 624 80). Ultimately, this study
completed the prediction of shear modulus and bulk modulus for 80664 inorganic
crystals. This work enriches existing material elastic data resources and
provides robust support for material design, with all data openly available at
https://doi.org/10.57760/sciencedb.j00213.00104.

</details>


### [158] [A copper sulfide-hydroxypropyl $β$-Cyclodextrin-reduced graphene oxide composite for highly sensitive electrochemical detection of 5-hydroxytryptamine in biological samples](https://arxiv.org/abs/2511.04493)
*Aravindan Santhan,Kuo Yuan Hwa,Slava V. Rotkin,Cheng-Han Wang,Chun-Wei Ou*

Main category: cond-mat.mtrl-sci

TL;DR: 该研究提出了一种基于Cu2S/Hβcd-rGO复合材料的电化学传感器，用于高灵敏度和选择性地检测血清素（SR）。


<details>
  <summary>Details</summary>
Motivation: 精确识别神经递质对于理解大脑功能、诊断神经系统疾病和制定治疗方案至关重要。本研究旨在开发一种用于检测血清素的电化学传感器。

Method: 研究人员将Cu2S纳米材料与Hβcd-rGO（一种具有出色催化活性和电荷转移能力的复合材料）进行复合，利用范德华力和静电相互作用稳定结构，减少Cu2S的聚集，提高导电性。将该复合材料修饰在玻碳电极（GCE）上，用于血清素的电化学检测。

Result: 所开发的Cu2S/Hβcd-rGO/GCE传感器对血清素在0.019-0.299 μM和4.28-403.14 μM的浓度范围内表现出灵敏的响应，检测限（LOD）低至1.2 nM (0.0012 μM)，灵敏度为15.9 μA μM⁻¹ cm⁻²。该传感器对常见的干扰物（如氨基酚、多巴胺、肾上腺素、氢醌、褪黑素和氯）表现出优异的选择性。在生物样品中的实际应用也显示出良好的回收率。

Conclusion: Cu2S/Hβcd-rGO复合材料是一种有前景的电催化剂，易于制备且成本效益高，可用于开发高效、灵敏且选择性好的血清素电化学传感器。

Abstract: The precise identification of neurotransmitters is essential for
comprehending cerebral function, detecting neurological conditions, and
formulating successful therapeutic approaches. The present work investigates
the electrochemical detection of serotonin with the excellent hybrid
electrocatalyst $Cu_2S/H{\beta}cd-rGO$. $Cu_2S$, with its significant features
as improved catalytic activity and enhanced charge transfer when combined with
$H{\beta}cd-rGO$, will enhance the performance. The integration of $Cu_2S$ with
$H{\beta}cd-rGO$, regulated by the van der Waals force and the electrostatic
interaction, makes it a stable catalyst without disrupting the composite
structure. Also, the aggregation of the $Cu_2S/H{\beta}cd$ with the layered
sheets of rGO can be highly reduced and resulting in the improvement of the
conductivity. Thus, the above features resulted in the improved oxidation
response current when fabricated over the glassy carbon electrode (GCE). The SR
showed sensitive response at a broad linear range of 0.019 to 0.299 $\mu$M and
4.28 to 403.14 $\mu$M, resulting in a lower limit of detection (LOD) of 1.2 nM
or 0.0012 $\mu$M and a sensitivity of about 15.9 $\mu$A ${\mu}M^{-1}$
$cm^{-2}$. The sensor demonstrated excellent selectivity against common
interferents, including aminophenol, dopamine, epinephrine, hydroquinone,
melatonin, and chlorine. The real sample studies in the biological samples show
good recovery values, showing the effectiveness of the as-fabricated sensor.
Thus, the cost-efficient and straightforward integration of
$Cu_2S/H{\beta}cd-rGO$ will be an outstanding electrocatalyst for detecting SR.

</details>


### [159] [Band Alignment Tuning from Charge Transfer in Epitaxial SrIrO$_3$/SrCoO$_3$ Superlattices](https://arxiv.org/abs/2511.04513)
*Jibril Ahammad,Brian B. Opatosky,Tanzila Tasnim,John W. Freeland,Gabriel Calderon Ortiz,Jinwoo Hwang,Gaurab Rimal,Boris Kiefer,Ryan B. Comes*

Main category: cond-mat.mtrl-sci

TL;DR: SrIrO3/SrCoO3超晶格中的界面电荷转移


<details>
  <summary>Details</summary>
Motivation: 理解氧化物界面的电荷转移对于设计具有新兴电子和磁性的材料至关重要，特别是在强电子关联和自旋-轨道耦合共存的系统中。

Method: 利用密度泛函理论（DFT）和X射线吸收光谱（XAS）研究SrIrO3/SrCoO3（SIO/SCO）超晶格的电子结构和电荷转移。

Result: DFT计算和XAS实验均证实了从Ir到Co的电子转移，以及由此产生的轨道各向异性、价态变化和带隙移动。这些效应有助于稳定SCO相并调整SIO的电子结构。

Conclusion: 该研究为通过界面工程设计具有定制磁性和电子特性的氧化物异质结构提供了途径。

Abstract: Understanding charge transfer at oxide interfaces is crucial for designing
materials with emergent electronic and magnetic properties, especially in
systems where strong electron correlations and spin-orbit coupling coexist.
SrIrO$_3$/SrCoO$_3$ (SIO/SCO) superlattices offer a unique platform to explore
these effects due to their contrasting electronic structures and magnetic
behaviors. Building on past theory based on continuity of O 2p band alignment,
we employ density functional theory (DFT) to model electron transfer from Ir to
Co across the SIO/SCO interface. To characterize these effects, we synthesized
epitaxial SIO/SCO superlattices via molecular beam epitaxy. Structural and
transport measurements confirmed high crystallinity, metallic behavior, and
suppression of Kondo scattering that has been reported in uniform SIO films.
Further characterization via X-ray absorption spectroscopy (XAS) revealed
orbital anisotropy and valence changes consistent with interfacial charge
transfer. Co K- and L$_{2,3}$-edge and Ir L$_2$-edge spectra verified electron
donation from Ir to Co, stabilizing the perovskite SCO phase and tuning the
electronic structure of SIO via hole-doping. O K-edge XAS showed band alignment
shifts in the SIO layer consistent with DFT predictions. Our work here provides
a pathway for engineering oxide heterostructures with tailored magnetic and
electronic properties.

</details>


### [160] [The phase-field model of fracture incorporating Mohr-Coulomb, Mogi-Coulomb, and Hoek-Brown strength surfaces](https://arxiv.org/abs/2511.04627)
*S Chockalingam,Adrian Buganza Tepole,Aditya Kumar*

Main category: cond-mat.mtrl-sci

TL;DR: 该研究实现了将材料的屈服面（strength surface）纳入经典断裂相场理论，并提出了一种新的驱动力表达式，以同时描述含裂纹和无裂纹材料的断裂行为。


<details>
  <summary>Details</summary>
Motivation: 现有经典断裂相场理论在模拟含裂纹材料的韧性断裂扩展方面表现良好，但在无裂纹材料的断裂形核方面存在不足，无法考虑材料的屈服面。Kumar等人（2020）的研究为在相场理论中引入屈服面提供了基础，但仍需进一步的实现和验证。因此，本研究旨在实现并验证一种能够同时考虑韧性断裂和屈服面的通用断裂相场模型。

Method: 本研究在现有的相场理论框架下，实现了Chockalingam（2025）提出的通用驱动力表达式。该表达式能够纳入任意形状的屈服面。研究中具体实现了Mohr--Coulomb、3D Hoek--Brown和Mogi--Coulomb等多种具有代表性的屈服面模型。并通过有限元方法对这些模型在均匀应力下的形核、大裂纹扩展以及强度和韧性共同控制下的断裂等经典断裂问题进行了模拟和验证。

Result: 通过对不同断裂问题的模拟，验证了该模型在多种断裂模式下的有效性，能够准确捕捉材料在不同应力状态下是先形核还是先扩展。研究结果表明，该模型能够同时考虑材料的强度和韧性对断裂过程的影响，并且在模拟结果与理论预期一致。

Conclusion: 本研究成功地将多种屈服面模型集成到相场断裂理论中，并通过有限元方法进行了验证。该方法具有通用性和鲁棒性，能够为受任意屈服面控制的材料提供准确的断裂模拟，为研究更广泛的材料断裂行为提供了新的工具。

Abstract: Classical phase-field theories of brittle fracture capture
toughness-controlled crack propagation but do not account for the material's
strength surface, which governs fracture nucleation in the absence of cracks.
The phase-field formulation of Kumar et al. (2020) proposed a blueprint for
incorporating the strength surface while preserving toughness-controlled
propagation by introducing a nucleation driving force and presented results for
the Drucker--Prager surface. Following this blueprint, Chockalingam (2025)
recently derived a general driving-force expression that incorporates arbitrary
strength surfaces. The present work implements this driving force within a
finite-element framework and incorporates representative strength surfaces that
span diverse mathematical and physical characteristics -- the Mohr--Coulomb, 3D
Hoek--Brown, and Mogi--Coulomb surfaces. Through simulations of canonical
fracture problems, the formulation is comprehensively validated across fracture
regimes, capturing (i) nucleation under uniform stress, (ii) crack growth from
large pre-existing flaws, and (iii) fracture governed jointly by strength and
toughness. While the strength surfaces examined here already encompass a broad
range of brittle materials, the results demonstrate the generality and
robustness of the proposed driving-force construction for materials governed by
arbitrary strength surfaces.

</details>


<div id='cs.GR'></div>

# cs.GR [[Back]](#toc)

### [161] [Shellular Metamaterial Design via Compact Electric Potential Parametrization](https://arxiv.org/abs/2511.04025)
*Chang Liu,Bohan Wang*

Main category: cs.GR

TL;DR: 使用简化的设计空间和高效的GPU加速同质化流程，实现了对具有广泛机械响应的细胞超材料的广泛探索和逆向设计，并验证了其在工程应用中的可行性。


<details>
  <summary>Details</summary>
Motivation: 提出一种紧凑但具有高度表达能力的设计空间，用于构建细胞超材料，能够生成从简单平面结构到复杂三周期最小曲面的各种几何形状。

Method: 利用少数自由度来定义设计空间，并开发了一个高效的GPU加速同质化流程，能在20毫秒内评估结构，并在0.5秒内计算有效的弹性张量。这种快速评估支持设计空间的详尽探索和逆向设计。

Result: 该方法能够生成具有几何多样性和广泛机械响应的细胞超材料，其性能可达到理论上限的91.86%，可与现有先进的细胞超材料相媲美。通过增材制造制作的原型验证了设计的可制造性。

Conclusion: 所提出的设计空间和评估流程为细胞超材料的设计和制造提供了一个高效且可行的途径，具有广泛的工程应用潜力。

Abstract: We introduce a compact yet highly expressive design space for shellular
metamaterials. By employing only a few dozen degrees of freedom, this design
space represents geometries ranging from simple planar configurations to
complex triply periodic minimal surfaces. Coupled with this representation, we
develop an efficient GPU-based homogenization pipeline that evaluates the
structure in under 20 ms and computes the corresponding effective elastic
tensor in near-real-time (0.5 s). The high speed of this evaluation facilitates
an exhaustive exploration of the design space and supports an inverse-design
scheme that tailors the shellular structure to specific macroscopic target
property. Structures derived through this approach exhibit not only geometric
diversity but also a wide spectrum of mechanical responses, covering a broad
range of material properties. Moreover, they achieve up to 91.86% of
theoretical upper bounds, a level of performance comparable to state-of-the-art
shellular structures with low solid volume. Finally, our prototypes, fabricated
via additive manufacturing, confirm the practical manufacturability of these
designs, underscoring their potential for real-world engineering applications.

</details>


<div id='cs.MA'></div>

# cs.MA [[Back]](#toc)

### [162] [OptiMA: A Transaction-Based Framework with Throughput Optimization for Very Complex Multi-Agent Systems](https://arxiv.org/abs/2511.03761)
*Umut Çalıkyılmaz,Nitin Nayak,Jinghua Groppe,Sven Groppe*

Main category: cs.MA

TL;DR: 提出一个基于事务的框架（VCMAS）来设计复杂多代理系统，并集成事务调度来解决性能瓶颈问题，实验证明该框架能支持百个以上代理的系统，并提高16%的性能。


<details>
  <summary>Details</summary>
Motivation: 随着多代理系统研究的深入，需要探索更大、更复杂的模型来完成复杂的任务，但这可能导致易受故障和性能瓶颈的影响。

Method: 提出一个基于事务的框架（VCMAS）来设计复杂多代理系统，并集成事务调度来解决性能瓶颈问题。

Result: 实现了OptiMA框架，能够支持百个以上代理的系统，并提高16%的性能。对事务调度问题进行了理论分析，并提供了实际工具。

Conclusion: 基于事务的框架和事务调度能够有效地设计和优化复杂的多代理系统。

Abstract: In recent years, the research of multi-agent systems has taken a direction to
explore larger and more complex models to fulfill sophisticated tasks. We point
out two possible pitfalls that might be caused by increasing complexity;
susceptibilities to faults, and performance bottlenecks. To prevent the former
threat, we propose a transaction-based framework to design very complex
multi-agent systems (VCMAS). To address the second threat, we offer to
integrate transaction scheduling into the proposed framework. We implemented
both of these ideas to develop the OptiMA framework and show that it is able to
facilitate the execution of VCMAS with more than a hundred agents. We also
demonstrate the effect of transaction scheduling on such a system by showing
improvements up to more than 16\%. Furthermore, we also performed a theoretical
analysis on the transaction scheduling problem and provided practical tools
that can be used for future research on it.

</details>


### [163] [ASAP: an Agentic Solution to Auto-optimize Performance of Large-Scale LLM Training](https://arxiv.org/abs/2511.03844)
*Yuran Ding,Xinwei Chen,Xiaofan Zhang,Zongwei Zhou*

Main category: cs.MA

TL;DR: ASAP是一个多智能体系统，利用LLM推理和性能分析工具来自动优化大规模LLM训练的性能，实验显示可减少28%的训练时间并提高1.43倍吞吐量。


<details>
  <summary>Details</summary>
Motivation: 现有LLM训练优化方法依赖手动调整或黑盒搜索，效率低下且资源消耗大，无法跟上LLM领域快速发展的步伐。

Method: ASAP是一个多智能体系统，包含协调者、分析器和建议者智能体，整合了LLM推理、性能分析工具（如roofline分析）以及包含专家知识和过往成功案例的知识库，以自动诊断性能瓶颈并推荐优化的分片配置。

Result: ASAP生成的配置可将训练步长时间减少高达28%，吞吐量提高1.43倍。与人工优化结合，吞吐量可进一步提高至2.58倍。

Conclusion: ASAP为大规模LLM训练提供了一种可扩展、可解释的AI辅助性能工程方法，有效提高了分布式LLM训练的效率。

Abstract: Optimizing large-language model (LLM) training on distributed domain-specific
accelerator systems presents significant challenges due to its complex
optimization space. Existing optimization methods, however, rely on
time-consuming manual tuning or resource-intensive black-box searches, which
struggle to keep pace with the rapidly evolving LLM domain, leading to slow
development and underutilized resources. To address this, we introduce ASAP, an
Agentic Solution to Auto-optimize Performance of Large-Scale LLM Training. It
is a multi-agent system, featuring Coordinator, Analyzer, and Proposal agents,
which integrates LLM reasoning with insights from performance profiling tools,
roofline analysis, and a knowledge base of best practices and successful past
optimizations from human experts. Our proposed design can automate the
diagnosis of performance bottlenecks and recommend optimized sharding
configurations with reasoning, thus effectively improving the efficiency of
distributed LLM training. Experiments have shown that the ASAP-generated
sharding configurations can contribute up to 28% training step time reduction
and 1.43 times throughput improvement. When combined with additional
optimization from human experts, throughput can be further increased to 2.58
times. The proposed ASAP promises to provide a scalable and explainable
methodology for AI-assisted performance engineering in large-scale LLM
training.

</details>


### [164] [Multi-Agent Collaborative Framework For Math Problem Generation](https://arxiv.org/abs/2511.03958)
*Kia Karbasi,Kevin Hong,Mohammad Amin Samadi,Gregory Pottie*

Main category: cs.MA

TL;DR: 使用多智能体协作框架生成数学问题，以更好地控制问题的复杂性和认知需求。


<details>
  <summary>Details</summary>
Motivation: 现有的自动问题生成（AQG）方法在控制数学教育中问题的复杂性和认知需求方面存在不足。

Method: 提出一个协作式多智能体框架，该框架在生成时进行计算，并迭代地优化问题-答案对，以平衡复杂性和认知需求。

Result: 评估指标包括相关性、重要性、清晰度、难度匹配和可回答性。初步结果表明，该框架提高了生成内容的质量，实现了认知挑战和清晰度之间的细致平衡。

Conclusion: 协作式多智能体工作流可以生成更受控、更具教学价值的内容，从而推动自动教育内容生成和自适应学习环境的发展。

Abstract: Automatic question generation (AQG) for mathematics education remains an
elusive goal for Intelligent Tutoring Systems and educators. While pre-trained
transformer-based language models have significantly advanced natural language
generation, they often struggle to precisely control problem complexity and
cognitive demands. In this paper, we introduce a collaborative multi-agent
framework as a novel method of incorporating inference-time computation into
AQG. This approach leverages multiple agents that iteratively refine generated
question-answer pairs to better balance complexity and cognitive demand. We
evaluate the generated questions on five meta-evaluation criteria: relevance,
importance, clarity, difficulty matching, answerability, to assess the system's
ability to control the required complexity and quality of the questions.
Preliminary evaluations show that this collaborative multi-agent framework
elevates the quality of generated educational content by fostering a more
nuanced balance between cognitive challenge and clarity. These promising
outcomes suggest that integrating collaborative multi-agent workflows can yield
more controlled, pedagogically valuable content that can help advance automated
educational content generation and adaptive learning environments.

</details>


<div id='cs.GT'></div>

# cs.GT [[Back]](#toc)

### [165] [On the Existence of Fair Allocations for Goods and Chores under Dissimilar Preferences](https://arxiv.org/abs/2511.03810)
*Egor Gagushin,Marios Mertzanidis,Alexandros Psomas*

Main category: cs.GT

TL;DR: 本文解决了公平分配不可分割物品给多个代理组的核心问题，为任意数量的代理组和物品类型提供了明确的嫉妒自由分配的上界。


<details>
  <summary>Details</summary>
Motivation: 解决Gorantla等人[GMV23]提出的一个主要未解决问题，即为任意数量的代理组和物品类型导出嫉妒自由分配的明确上界。

Method: 引入一种更简单但强大的技术，该技术不仅为不可分割物品提供了建设性的保证，而且可以自然地扩展到分配“麻烦”（chores）和连续域，从而在分蛋糕等相关公平分配设置中获得新结果。

Result: 推导出了适用于任意数量代理组和物品类型的嫉妒自由分配的明确上界。

Conclusion: 本文提出的技术不仅解决了[GMV23]中的一个关键开放性问题，而且为公平分配领域带来了新的见解和应用。

Abstract: We study the fundamental problem of fairly allocating a multiset
$\mathcal{M}$ of $t$ types of indivisible items among $d$ groups of agents,
where all agents within a group have identical additive valuations. Gorantla et
al. [GMV23] showed that for every such instance, there exists a finite number
$\mu$ such that, if each item type appears at least $\mu$ times, an envy-free
allocation exists. Their proof is non-constructive and only provides explicit
upper bounds on $\mu$ for the cases of two groups ($d=2$) or two item types
($t=2$).
  In this work, we resolve one of the main open questions posed by Gorantla et
al. [GMV23] by deriving explicit upper bounds on $\mu$ that hold for arbitrary
numbers of groups and item types. We introduce a significantly simpler, yet
powerful technique that not only yields constructive guarantees for indivisible
goods but also extends naturally to chores and continuous domains, leading to
new results in related fair division settings such as cake cutting.

</details>


### [166] [The Complexity of Equilibrium Refinements in Potential Games](https://arxiv.org/abs/2511.03968)
*Ioannis Anagnostides,Maria-Florina Balcan,Kiriaki Fragkia,Tuomas Sandholm,Emanuel Tewolde,Brian Hu Zhang*

Main category: cs.GT

TL;DR: 本文解决了算法博弈论中计算均衡精炼的计算复杂性问题，特别是在势博弈领域。


<details>
  <summary>Details</summary>
Motivation: 研究计算均衡精炼的复杂性，尤其是在势博弈中的开放性问题。

Method: 研究了不同博弈表示下的纯策略完美均衡的计算复杂性（PLS-complete），并提出了在扩展博弈中有效计算扰动（proper）最佳响应的方法，以及在多项式潜在博弈和对称网络拥塞博弈中的均衡计算。最后，研究了混合策略均衡的计算复杂性。

Result: 在扩展博弈中，纯策略完美均衡是PLS-complete的。在对称网络拥塞和对称 matroid 拥塞博弈中，可以在多项式时间内计算完美纯策略均衡。在多项式潜在博弈中，完美均衡和纳什均衡的最优响应路径长度存在指数级分离。在三元势博弈中，计算接近完美均衡的点需要双指数级扰动。在多项式矩阵势博弈中，均衡精炼属于CLS复杂度类。

Conclusion: 本文在计算势博弈的均衡精炼方面取得了重要进展，包括其计算复杂性和有效算法，并揭示了不同类型均衡之间的计算差异。

Abstract: The complexity of computing equilibrium refinements has been at the forefront
of algorithmic game theory research, but it has remained open in the seminal
class of potential games; we close this fundamental gap in this paper.
  We first establish that computing a pure-strategy perfect equilibrium is
$\mathsf{PLS}$-complete under different game representations -- including
extensive-form games and general polytope games, thereby being polynomial-time
equivalent to pure Nash equilibria. For normal-form proper equilibria, our main
result is that a perturbed (proper) best response can be computed efficiently
in extensive-form games. As a byproduct, we establish
$\mathsf{FIXP}_a$-completeness of normal-form proper equilibria in
extensive-form games, resolving a long-standing open problem. In stark
contrast, we show that computing a normal-form proper equilibrium in polytope
potential games is both $\mathsf{NP}$-hard and $\mathsf{coNP}$-hard.
  We next turn to more structured classes of games, namely symmetric network
congestion and symmetric matroid congestion games. For both classes, we show
that a perfect pure-strategy equilibrium can be computed in polynomial time,
strengthening the existing results for pure Nash equilibria. On the other hand,
we establish that, for a certain class of potential games, there is an
exponential separation in the length of the best-response path between perfect
and Nash equilibria.
  Finally, for mixed strategies, we prove that computing a point geometrically
near a perfect equilibrium requires a doubly exponentially small perturbation
even in $3$-player potential games in normal form. On the flip side, in the
special case of polymatrix potential games, we show that equilibrium
refinements are amenable to perturbed gradient descent dynamics, thereby
belonging to the complexity class $\mathsf{CLS}$.

</details>


### [167] [Fraud-Proof Revenue Division on Subscription Platforms](https://arxiv.org/abs/2511.04465)
*Abheek Ghosh,Tzeh Yuan Neoh,Nicholas Teh,Giannis Tyrovolas*

Main category: cs.GT

TL;DR: 平台通过订阅费和创作者分成模式，研究了如何通过收入分配机制来防止欺诈行为，并提出了一种名为ScaledUserProp的新机制。


<details>
  <summary>Details</summary>
Motivation: 现有欺诈检测方法依赖机器学习，面临与欺诈者持续的军备竞赛。本研究旨在探索具有内在抗操纵性的收入分配机制。

Method: 形式化了三种抗操纵性公理，并检查了现有规则的满足情况。提出了一种新的规则ScaledUserProp。

Result: 发现流媒体平台广泛使用的现有机制不仅未能防止欺诈，还使欺诈检测在计算上变得不可行。ScaledUserProp满足所有三种抗操纵性公理。实验表明，与现有规则相比，ScaledUserProp在真实和合成流媒体数据上都更公平。

Conclusion: ScaledUserProp是一种更公平的替代现有机制的解决方案，能够抵抗欺诈和操纵。

Abstract: We study a model of subscription-based platforms where users pay a fixed fee
for unlimited access to content, and creators receive a share of the revenue.
Existing approaches to detecting fraud predominantly rely on machine learning
methods, engaging in an ongoing arms race with bad actors. We explore revenue
division mechanisms that inherently disincentivize manipulation. We formalize
three types of manipulation-resistance axioms and examine which existing rules
satisfy these. We show that a mechanism widely used by streaming platforms, not
only fails to prevent fraud, but also makes detecting manipulation
computationally intractable. We also introduce a novel rule, ScaledUserProp,
that satisfies all three manipulation-resistance axioms. Finally, experiments
with both real-world and synthetic streaming data support ScaledUserProp as a
fairer alternative compared to existing rules.

</details>


### [168] [Fisher Meets Lindahl: A Unified Duality Framework for Market Equilibrium](https://arxiv.org/abs/2511.04572)
*Yixin Tao,Weiqiang Zheng*

Main category: cs.GT

TL;DR: 本文提出了一种统一的对偶框架，将公共产品的Lindahl均衡与私有产品的Fisher均衡联系起来，并以此为基础，在福利分析、市场动态和带有“麻烦”的市场等方面取得了新进展。


<details>
  <summary>Details</summary>
Motivation: 尽管Fisher市场均衡得到了充分研究，但Lindahl均衡的理论基础仍不完善，本文旨在通过建立两者之间的对偶关系来弥合这一差距。

Method: 本文构建了一个统一的对偶框架，将Lindahl均衡与Fisher均衡联系起来，通过交换分配和价格的角色，并利用这一框架来分析福利性质和市场动态，以及应用于带有“麻烦”的市场。

Result: 研究表明，在特定条件下，Lindahl均衡可以最大化Nash社会福利（NSW）或实现近似最优NSW。此外，本文还提出了新的市场动态，并扩展了PRD到具有总互补效用的市场，以及提出了一个用于私有“麻烦”的市场程序。

Conclusion: 通过建立Fisher均衡和Lindahl均衡的对偶关系，本文不仅填补了Lindahl均衡理论的空白，还在福利最大化、市场动态分析以及处理带有“麻烦”的市场问题上取得了重要进展。

Abstract: The Fisher market equilibrium for private goods and the Lindahl equilibrium
for public goods are classic and fundamental solution concepts for market
equilibria. While Fisher market equilibria have been well-studied, the
theoretical foundations for Lindahl equilibria remain substantially
underdeveloped.
  In this work, we propose a unified duality framework for market equilibria.
We show that Lindahl equilibria of a public goods market correspond to Fisher
market equilibria in a dual Fisher market with dual utilities, and vice versa.
The dual utility is based on the indirect utility, and the correspondence
between the two equilibria works by exchanging the roles of allocations and
prices.
  Using the duality framework, we address the gaps concerning the computation
and dynamics for Lindahl equilibria and obtain new insights and developments
for Fisher market equilibria. First, we leverage this duality to analyze
welfare properties of Lindahl equilibria. For concave homogeneous utilities, we
prove that a Lindahl equilibrium maximizes Nash Social Welfare (NSW). For
concave non-homogeneous utilities, we show that a Lindahl equilibrium achieves
$(1/e)^{1/e}$ approximation to the optimal NSW, and the approximation ratio is
tight. Second, we apply the duality framework to market dynamics, including
proportional response dynamics (PRD) and t\^atonnement. We obtain new market
dynamics for the Lindahl equilibria from market dynamics in the dual Fisher
market. We also use duality to extend PRD to markets with total complements
utilities, the dual class of gross substitutes utilities. Finally, we apply the
duality framework to markets with chores. We propose a program for private
chores for general convex homogeneous disutilities that avoids the "poles"
issue, whose KKT points correspond to Fisher market equilibria. We also
initiate the study of the Lindahl equilibrium for public chores.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [169] [Dynamic Shape Control of Soft Robots Enabled by Data-Driven Model Reduction](https://arxiv.org/abs/2511.03931)
*Iman Adibnazari,Harsh Sharma,Myungsun Park,Jacobo Cervera-Torralba,Boris Kramer,Michael T. Tolley*

Main category: cs.RO

TL;DR: 该研究比较了三种数据驱动的模型降维技术（特征系统实现算法、带控制的动态模式分解和拉格朗日算子推理法）在软体机器人动态形状控制中的应用。


<details>
  <summary>Details</summary>
Motivation: 软体机器人虽然在动态控制方面有巨大潜力，但其高维动力学特性给控制器设计带来挑战，且缺乏通用的建模工具。

Method: 研究人员比较了三种数据驱动的模型降维技术：特征系统实现算法、带控制的动态模式分解和拉格朗日算子推理法。他们使用这些技术生成的线性模型，来设计模型预测控制策略，并在一只模拟的鳗鱼状软体机器人上进行了三组实验，以评估其动态形状控制效果。

Result: 在所有实验中，基于拉格朗日算子推理法的控制策略都比其他模型生成的策略具有更低的跟踪误差。

Conclusion: 拉格朗日算子推理法在生成用于软体机器人动态形状控制的线性模型方面，比特征系统实现算法和带控制的动态模式分解更有效。

Abstract: Soft robots have shown immense promise in settings where they can leverage
dynamic control of their entire bodies. However, effective dynamic shape
control requires a controller that accounts for the robot's high-dimensional
dynamics--a challenge exacerbated by a lack of general-purpose tools for
modeling soft robots amenably for control. In this work, we conduct a
comparative study of data-driven model reduction techniques for generating
linear models amendable to dynamic shape control. We focus on three
methods--the eigensystem realization algorithm, dynamic mode decomposition with
control, and the Lagrangian operator inference (LOpInf) method. Using each
class of model, we explored their efficacy in model predictive control policies
for the dynamic shape control of a simulated eel-inspired soft robot in three
experiments: 1) tracking simulated reference trajectories guaranteed to be
feasible, 2) tracking reference trajectories generated from a biological model
of eel kinematics, and 3) tracking reference trajectories generated by a
reduced-scale physical analog. In all experiments, the LOpInf-based policies
generated lower tracking errors than policies based on other models.

</details>


### [170] [Learning Vision-Driven Reactive Soccer Skills for Humanoid Robots](https://arxiv.org/abs/2511.03996)
*Yushi Wang,Changsheng Luo,Penghui Chen,Jianran Liu,Weijian Sun,Tong Guo,Kechang Yang,Biao Hu,Yangang Zhang,Mingguo Zhao*

Main category: cs.RO

TL;DR: 本研究提出了一个统一的强化学习控制器，用于人形机器人学习基于视觉的足球技能。


<details>
  <summary>Details</summary>
Motivation: 现有的人形足球系统模块化且响应延迟，无法应对动态环境和真实世界的感知限制。本研究旨在解决这些问题，实现更紧密的感知-动作耦合。

Method: 提出了一种结合了ADVERSARIAL MOTION PRIORS、编码器-解码器架构和虚拟感知系统的强化学习方法，以实现从不完美的视觉观测中恢复状态并进行动态控制。

Result: 所提出的控制器在各种场景（包括真实的RoboCup比赛）中表现出强大的反应能力，能够执行连贯且鲁棒的足球行为。

Conclusion: 统一的强化学习控制器能够有效地将视觉感知与运动控制相结合，使人形机器人能够掌握对动态环境具有高度适应性的足球技能。

Abstract: Humanoid soccer poses a representative challenge for embodied intelligence,
requiring robots to operate within a tightly coupled perception-action loop.
However, existing systems typically rely on decoupled modules, resulting in
delayed responses and incoherent behaviors in dynamic environments, while
real-world perceptual limitations further exacerbate these issues. In this
work, we present a unified reinforcement learning-based controller that enables
humanoid robots to acquire reactive soccer skills through the direct
integration of visual perception and motion control. Our approach extends
Adversarial Motion Priors to perceptual settings in real-world dynamic
environments, bridging motion imitation and visually grounded dynamic control.
We introduce an encoder-decoder architecture combined with a virtual perception
system that models real-world visual characteristics, allowing the policy to
recover privileged states from imperfect observations and establish active
coordination between perception and action. The resulting controller
demonstrates strong reactivity, consistently executing coherent and robust
soccer behaviors across various scenarios, including real RoboCup matches.

</details>


### [171] [Integrating Ergonomics and Manipulability for Upper Limb Postural Optimization in Bimanual Human-Robot Collaboration](https://arxiv.org/abs/2511.04009)
*Chenzui Li,Yiming Chen,Xi Wu,Giacinto Barresi,Fei Chen*

Main category: cs.RO

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: This paper introduces an upper limb postural optimization method for
enhancing physical ergonomics and force manipulability during bimanual
human-robot co-carrying tasks. Existing research typically emphasizes human
safety or manipulative efficiency, whereas our proposed method uniquely
integrates both aspects to strengthen collaboration across diverse conditions
(e.g., different grasping postures of humans, and different shapes of objects).
Specifically, the joint angles of a simplified human skeleton model are
optimized by minimizing the cost function to prioritize safety and manipulative
capability. To guide humans towards the optimized posture, the reference
end-effector poses of the robot are generated through a transformation module.
A bimanual model predictive impedance controller (MPIC) is proposed for our
human-like robot, CURI, to recalibrate the end effector poses through planned
trajectories. The proposed method has been validated through various subjects
and objects during human-human collaboration (HHC) and human-robot
collaboration (HRC). The experimental results demonstrate significant
improvement in muscle conditions by comparing the activation of target muscles
before and after optimization.

</details>


### [172] [An LLM-based Framework for Human-Swarm Teaming Cognition in Disaster Search and Rescue](https://arxiv.org/abs/2511.04042)
*Kailun Ji,Xiaoyu Hu,Xinyu Zhang,Jun Chen*

Main category: cs.RO

TL;DR: 该研究提出了一种新颖的LLM-CRF系统，利用大型语言模型（LLMs）来增强人机协作在大型灾难搜救（SAR）任务中的作用，通过理解操作员意图并将其转化为无人机蜂群的指令，显著提高了任务效率和成功率，同时降低了操作员的认知负荷。


<details>
  <summary>Details</summary>
Motivation: 大型灾难搜救（SAR）任务面临地形复杂和通信中断的挑战，而无人机蜂群虽然有潜力，但其协调给操作员带来巨大的认知负担，即“意图-行动差距”。

Method: 提出LLM-CRF系统，利用LLMs处理操作员的多模态输入（语音或图形标注），理解其意图，进行任务分解和规划，实现人与无人机蜂群的闭环协作，无人机可主动反馈，减少人工监控。

Result: 在模拟SAR场景中，与传统界面相比，LLM驱动的方法将任务完成时间缩短了约64.2%，任务成功率提高了7%，NASA-TLX认知负荷评分降低了42.9%。

Conclusion: LLMs在提高高风险场景下人机协作的直观性和有效性方面具有巨大潜力，能够使无人机蜂群成为更积极的合作伙伴。

Abstract: Large-scale disaster Search And Rescue (SAR) operations are persistently
challenged by complex terrain and disrupted communications. While Unmanned
Aerial Vehicle (UAV) swarms offer a promising solution for tasks like wide-area
search and supply delivery, yet their effective coordination places a
significant cognitive burden on human operators. The core human-machine
collaboration bottleneck lies in the ``intention-to-action gap'', which is an
error-prone process of translating a high-level rescue objective into a
low-level swarm command under high intensity and pressure. To bridge this gap,
this study proposes a novel LLM-CRF system that leverages Large Language Models
(LLMs) to model and augment human-swarm teaming cognition. The proposed
framework initially captures the operator's intention through natural and
multi-modal interactions with the device via voice or graphical annotations. It
then employs the LLM as a cognitive engine to perform intention comprehension,
hierarchical task decomposition, and mission planning for the UAV swarm. This
closed-loop framework enables the swarm to act as a proactive partner,
providing active feedback in real-time while reducing the need for manual
monitoring and control, which considerably advances the efficacy of the SAR
task. We evaluate the proposed framework in a simulated SAR scenario.
Experimental results demonstrate that, compared to traditional order and
command-based interfaces, the proposed LLM-driven approach reduced task
completion time by approximately $64.2\%$ and improved task success rate by
$7\%$. It also leads to a considerable reduction in subjective cognitive
workload, with NASA-TLX scores dropping by $42.9\%$. This work establishes the
potential of LLMs to create more intuitive and effective human-swarm
collaborations in high-stakes scenarios.

</details>


### [173] [Enhancing Fault-Tolerant Space Computing: Guidance Navigation and Control (GNC) and Landing Vision System (LVS) Implementations on Next-Gen Multi-Core Processors](https://arxiv.org/abs/2511.04052)
*Kyongsik Yun,David Bayard,Gerik Kubiak,Austin Owens,Andrew Johnson,Ryan Johnson,Dan Scharf,Thomas Lu*

Main category: cs.RO

TL;DR: 未来的行星探索任务需要高性能、容错计算来实现自主导航、制导与控制 (GNC) 和着陆器视觉系统 (LVS) 在进入、下降和着陆 (EDL) 期间的运行。本文评估了在新一代多核处理器（HPSC、Snapdragon VOXL2 和 AMD Xilinx Versal）上部署 GNC 和 LVS 算法的情况，与传统航天硬件相比，LVS 图像处理速度提高了 15 倍，燃料最优大偏转 (GFOLD) 轨迹优化速度提高了 250 多倍。为确保计算可靠性，我们提出了 ARBITER（用于可信执行和恢复的异步冗余行为检查），这是一种多核投票 (MV) 机制，可在冗余核之间执行实时故障检测和纠正。ARBITER 在静态优化任务 (GFOLD) 和动态闭环控制 (姿态控制系统) 中都得到了验证。故障注入研究进一步确定 GFOLD 中的梯度计算阶段最容易受到比特级错误的影响，这促使采用选择性保护策略和基于向量的仲裁。这项工作为火星样本返回、恩塞拉多斯轨道着陆器和谷神星样本返回等未来任务建立了一个可扩展且节能的架构，在这些任务中，机载自主性、低延迟和故障弹性至关重要。


<details>
  <summary>Details</summary>
Motivation: 未来的行星探索任务，特别是涉及火星样本返回、恩塞拉多斯轨道着陆器和谷神星样本返回的任务，需要高度自主和容错的计算能力来实现自主导航、制导与控制 (GNC) 和着陆器视觉系统 (LVS) 在进入、下降和着陆 (EDL) 过程中的操作。

Method: 该研究评估了在新一代多核处理器（HPSC、Snapdragon VOXL2 和 AMD Xilinx Versal）上部署 GNC 和 LVS 算法的性能。为了确保计算的可靠性，提出并实现了一种名为 ARBITER 的多核投票 (MV) 机制，用于实时故障检测和纠正。通过故障注入研究来识别 GFOLD 中的关键脆弱点，并提出相应的保护策略。

Result: 与传统航天硬件相比，在新一代多核处理器上部署 GNC 和 LVS 算法，LVS 图像处理速度提高了 15 倍，GFOLD 轨迹优化速度提高了 250 多倍。ARBITER 机制在 GFOLD 和姿态控制系统上得到了验证。故障注入研究发现 GFOLD 的梯度计算阶段最容易出错，这为选择性保护策略提供了依据。

Conclusion: 该研究成功地展示了一种可扩展且节能的计算架构，适用于未来需要高自主性、低延迟和容错能力（如火星样本返回、恩塞拉多斯轨道着陆器和谷神星样本返回任务）的行星探索任务。ARBITER 机制为实现这些任务所需的计算可靠性提供了解决方案。

Abstract: Future planetary exploration missions demand high-performance, fault-tolerant
computing to enable autonomous Guidance, Navigation, and Control (GNC) and
Lander Vision System (LVS) operations during Entry, Descent, and Landing (EDL).
This paper evaluates the deployment of GNC and LVS algorithms on
next-generation multi-core processors--HPSC, Snapdragon VOXL2, and AMD Xilinx
Versal--demonstrating up to 15x speedup for LVS image processing and over 250x
speedup for Guidance for Fuel-Optimal Large Divert (GFOLD) trajectory
optimization compared to legacy spaceflight hardware. To ensure computational
reliability, we present ARBITER (Asynchronous Redundant Behavior Inspection for
Trusted Execution and Recovery), a Multi-Core Voting (MV) mechanism that
performs real-time fault detection and correction across redundant cores.
ARBITER is validated in both static optimization tasks (GFOLD) and dynamic
closed-loop control (Attitude Control System). A fault injection study further
identifies the gradient computation stage in GFOLD as the most sensitive to
bit-level errors, motivating selective protection strategies and vector-based
output arbitration. This work establishes a scalable and energy-efficient
architecture for future missions, including Mars Sample Return, Enceladus
Orbilander, and Ceres Sample Return, where onboard autonomy, low latency, and
fault resilience are critical.

</details>


### [174] [CBMC-V3: A CNS-inspired Control Framework Towards Manipulation Agility with SNN](https://arxiv.org/abs/2511.04109)
*Yanbo Pang,Qingkai Li,Mingguo Zhao*

Main category: cs.RO

TL;DR: 该研究提出了一种受人脑启发的、基于脉冲神经网络（SNN）的双足控制框架，用于在复杂动态环境中实现敏捷控制，并在仿真和真实机器人平台上取得了优于工业级位置控制的性能。


<details>
  <summary>Details</summary>
Motivation: 现有机器人控制算法难以满足医疗、服务和日常生活等复杂动态环境对机器人敏捷操作的需求。

Method: 提出了一种仿生控制框架，该框架基于脉冲神经网络（SNN），并模仿了人类中枢神经系统（CNS）的结构，包含五个控制模块（大脑皮层、小脑、丘脑、脑干、脊髓），三个分层控制级别（一阶、二阶、三阶）和两条信息路径（上行、下行）。所有模块均使用SNN实现。脊髓模块采用脉冲编码和LIF神经元进行反馈控制；脑干模块通过强化学习动态调整脊髓参数；丘脑模块调整小脑的力矩输出；小脑模块使用循环SNN通过回归学习机器人动力学并提供前馈重力补偿力矩。

Result: 在仿真和真实机器人平台上进行了验证，结果表明该方法在操纵敏捷性方面优于工业级的运动控制。

Conclusion: 所提出的基于SNN的仿生控制框架能够有效地实现机器人手臂在复杂动态环境下的敏捷控制，并在各项性能指标上超越了现有的工业级控制方法。

Abstract: As robotic arm applications extend beyond industrial settings into
healthcare, service, and daily life, existing control algorithms struggle to
achieve the agile manipulation required for complex environments with dynamic
trajectories, unpredictable interactions, and diverse objects. This paper
presents a biomimetic control framework based on Spiking Neural Networks (SNN),
inspired by the human Central Nervous System (CNS), to achieve agile control in
such environments. The proposed framework features five control modules
(cerebral cortex, cerebellum, thalamus, brainstem, spinal cord), three
hierarchical control levels (first-order, second-order, third-order), and two
information pathways (ascending, descending). Each module is fully implemented
using SNN. The spinal cord module uses spike encoding and Leaky
Integrate-and-Fire (LIF) neurons for feedback control. The brainstem module
employs a network of LIF and non-spiking LIF neurons to dynamically adjust
spinal cord parameters via reinforcement learning. The thalamus module
similarly adjusts the cerebellum's torque outputs. The cerebellum module uses a
recurrent SNN to learn the robotic arm's dynamics through regression, providing
feedforward gravity compensation torques. The framework is validated both in
simulation and on real-world robotic arm platform under various loads and
trajectories. Results demonstrate that our method outperforms the
industrial-grade position control in manipulation agility.

</details>


### [175] [BFM-Zero: A Promptable Behavioral Foundation Model for Humanoid Control Using Unsupervised Reinforcement Learning](https://arxiv.org/abs/2511.04131)
*Yitang Li,Zhengyi Luo,Tonghe Zhang,Cunxi Dai,Anssi Kanervisto,Andrea Tirinzoni,Haoyang Weng,Kris Kitani,Mateusz Guzek,Ahmed Touati,Alessandro Lazaric,Matteo Pirotta,Guanya Shi*

Main category: cs.RO

TL;DR: BFM-Zero 是一个框架，可以学习通用的潜在表征，使单个策略能够适应多种下游任务，从而实现通用人形机器人控制。


<details>
  <summary>Details</summary>
Motivation: 现有的人形机器人控制方法要么仅限于模拟，要么专门针对特定任务。BFM-Zero 旨在通过创建一个可提示的通用策略来统一各种控制任务。

Method: BFM-Zero 学习一个共享的潜在表征，将运动、目标和奖励嵌入到通用空间中。它利用无监督强化学习和正反向模型，并通过奖励塑形、域随机化和依赖历史的不对称学习来弥合模拟与现实之间的差距。

Result: BFM-Zero 在 Unitree G1 人形机器人上实现了通用的、鲁棒的全身技能，能够进行零样本运动跟踪、目标到达和奖励优化，以及基于少样本的优化适应。

Conclusion: BFM-Zero 是首个用于全身人形控制的可扩展、可提示行为基础模型，为该领域树立了新标杆。

Abstract: Building Behavioral Foundation Models (BFMs) for humanoid robots has the
potential to unify diverse control tasks under a single, promptable generalist
policy. However, existing approaches are either exclusively deployed on
simulated humanoid characters, or specialized to specific tasks such as
tracking. We propose BFM-Zero, a framework that learns an effective shared
latent representation that embeds motions, goals, and rewards into a common
space, enabling a single policy to be prompted for multiple downstream tasks
without retraining. This well-structured latent space in BFM-Zero enables
versatile and robust whole-body skills on a Unitree G1 humanoid in the real
world, via diverse inference methods, including zero-shot motion tracking, goal
reaching, and reward optimization, and few-shot optimization-based adaptation.
Unlike prior on-policy reinforcement learning (RL) frameworks, BFM-Zero builds
upon recent advancements in unsupervised RL and Forward-Backward (FB) models,
which offer an objective-centric, explainable, and smooth latent representation
of whole-body motions. We further extend BFM-Zero with critical reward shaping,
domain randomization, and history-dependent asymmetric learning to bridge the
sim-to-real gap. Those key design choices are quantitatively ablated in
simulation. A first-of-its-kind model, BFM-Zero establishes a step toward
scalable, promptable behavioral foundation models for whole-body humanoid
control.

</details>


### [176] [PUL-SLAM: Path-Uncertainty Co-Optimization with Lightweight Stagnation Detection for Efficient Robotic Exploration](https://arxiv.org/abs/2511.04180)
*Yizhen Yin,Dapeng Feng,Hongbo Chen,Yuhua Qi*

Main category: cs.RO

TL;DR: 该研究提出了一种结合路径不确定性协同优化深度强化学习和轻量化停滞检测的混合框架，以解决现有主动SLAM探索速度慢和路径次优的问题。


<details>
  <summary>Details</summary>
Motivation: 现有主动SLAM方法在探索速度和路径优化方面存在不足。

Method: 提出了一种结合路径不确定性协同优化深度强化学习（通过双目标奖励函数平衡探索和利用）和轻量化停滞检测（通过激光雷达静态异常检测和地图更新停滞检测减少冗余探索）的混合框架。

Result: 与基于边界和RRT的方法相比，该方法将探索时间缩短了高达65%，路径距离缩短了高达42%，显著提高了复杂环境下的探索效率，并保持了可靠的地图完整性。消融研究表明，协同机制加速了训练收敛。物理机器人平台上的实证验证证明了该算法的实际适用性及其从模拟到真实世界的成功迁移能力。

Conclusion: 所提出的混合框架能有效提高主动SLAM的探索效率和路径优化性能，并具有良好的泛化能力和实际应用潜力。

Abstract: Existing Active SLAM methodologies face issues such as slow exploration speed
and suboptimal paths. To address these limitations, we propose a hybrid
framework combining a Path-Uncertainty Co-Optimization Deep Reinforcement
Learning framework and a Lightweight Stagnation Detection mechanism. The
Path-Uncertainty Co-Optimization framework jointly optimizes travel distance
and map uncertainty through a dual-objective reward function, balancing
exploration and exploitation. The Lightweight Stagnation Detection reduces
redundant exploration through Lidar Static Anomaly Detection and Map Update
Stagnation Detection, terminating episodes on low expansion rates. Experimental
results show that compared with the frontier-based method and RRT method, our
approach shortens exploration time by up to 65% and reduces path distance by up
to 42%, significantly improving exploration efficiency in complex environments
while maintaining reliable map completeness. Ablation studies confirm that the
collaborative mechanism accelerates training convergence. Empirical validation
on a physical robotic platform demonstrates the algorithm's practical
applicability and its successful transferability from simulation to real-world
environments.

</details>


### [177] [GraspView: Active Perception Scoring and Best-View Optimization for Robotic Grasping in Cluttered Environments](https://arxiv.org/abs/2511.04199)
*Shenglin Wang,Mingtong Dai,Jingxuan Su,Lingbo Liu,Chunjie Chen,Xinyu Wu,Liang Lin*

Main category: cs.RO

TL;DR: GraspView是一个仅使用RGB的机器人抓取框架，无需深度传感器，即可在杂乱环境中实现精确抓取，其性能优于RGB-D方法，尤其是在遮挡、近距离感知和透明物体等具有挑战性的场景中。


<details>
  <summary>Details</summary>
Motivation: 在杂乱环境中，由于遮挡、低质量感知和不一致的3D重建，机器人抓取仍然面临巨大挑战。传统的RGB-D方法在透明或有光泽的物体上表现不佳，并且在近距离时性能会下降。

Method: GraspView框架整合了三个关键组件：（1）全局感知场景重建：从单个RGB视图提供局部一致的、按比例缩放的几何信息，并将多视图投影融合为连贯的全局3D场景。（2）渲染和评分的主动感知策略：动态选择最佳的下一个视图以揭示被遮挡的区域。（3）在线度量对齐模块：将VGGT预测与机器人运动学进行校准，以确保物理尺度的一致性。GraspView在此基础上进行全局抓取，融合多视图重建并利用GraspNet进行鲁棒执行。

Result: 在各种桌面物体上的实验表明，GraspView的性能显著优于RGB-D和单视图RGB基线，尤其是在重度遮挡、近距离感知和透明物体的情况下。

Conclusion: GraspView为RGB-D抓取管线提供了一种实用且通用的替代方案，能够在非结构化的真实环境中实现可靠的抓取。

Abstract: Robotic grasping is a fundamental capability for autonomous manipulation, yet
remains highly challenging in cluttered environments where occlusion, poor
perception quality, and inconsistent 3D reconstructions often lead to unstable
or failed grasps. Conventional pipelines have widely relied on RGB-D cameras to
provide geometric information, which fail on transparent or glossy objects and
degrade at close range. We present GraspView, an RGB-only robotic grasping
pipeline that achieves accurate manipulation in cluttered environments without
depth sensors. Our framework integrates three key components: (i) global
perception scene reconstruction, which provides locally consistent, up-to-scale
geometry from a single RGB view and fuses multi-view projections into a
coherent global 3D scene; (ii) a render-and-score active perception strategy,
which dynamically selects next-best-views to reveal occluded regions; and (iii)
an online metric alignment module that calibrates VGGT predictions against
robot kinematics to ensure physical scale consistency. Building on these
tailor-designed modules, GraspView performs best-view global grasping, fusing
multi-view reconstructions and leveraging GraspNet for robust execution.
Experiments on diverse tabletop objects demonstrate that GraspView
significantly outperforms both RGB-D and single-view RGB baselines, especially
under heavy occlusion, near-field sensing, and with transparent objects. These
results highlight GraspView as a practical and versatile alternative to RGB-D
pipelines, enabling reliable grasping in unstructured real-world environments.

</details>


### [178] [Can Context Bridge the Reality Gap? Sim-to-Real Transfer of Context-Aware Policies](https://arxiv.org/abs/2511.04249)
*Marco Iannotta,Yuxuan Yang,Johannes A. Stork,Erik Schaffernicht,Todor Stoyanov*

Main category: cs.RO

TL;DR: Sim-to-real transfer in RL for robotics is challenging due to simulation-reality discrepancies. This paper improves it by conditioning policies on estimated dynamics parameters (context), outperforming context-agnostic methods.


<details>
  <summary>Details</summary>
Motivation: Sim-to-real transfer in reinforcement learning for robotics faces challenges because policies trained in simulation often fail to generalize to the real world due to differences in environment dynamics. Domain Randomization (DR) helps but can reduce performance. This paper explores improving sim-to-real transfer by making policies aware of environment dynamics.

Method: The study integrates a context estimation module into a DR-based RL framework to create context-aware policies. These policies are conditioned on estimated dynamics parameters. Different state-of-the-art supervision strategies for context estimation are compared.

Result: Context-aware policies demonstrated superior performance compared to context-agnostic baselines in both a standard control benchmark and a real-world robotic manipulation task (pushing with a Franka Emika Panda robot). The effectiveness of different supervision strategies varied depending on the specific task.

Conclusion: Conditioning reinforcement learning policies on estimated dynamics parameters (context) improves sim-to-real transfer performance in robotics. While this approach is effective, the optimal method for estimating this context is task-dependent.

Abstract: Sim-to-real transfer remains a major challenge in reinforcement learning (RL)
for robotics, as policies trained in simulation often fail to generalize to the
real world due to discrepancies in environment dynamics. Domain Randomization
(DR) mitigates this issue by exposing the policy to a wide range of randomized
dynamics during training, yet leading to a reduction in performance. While
standard approaches typically train policies agnostic to these variations, we
investigate whether sim-to-real transfer can be improved by conditioning the
policy on an estimate of the dynamics parameters -- referred to as context. To
this end, we integrate a context estimation module into a DR-based RL framework
and systematically compare SOTA supervision strategies. We evaluate the
resulting context-aware policies in both a canonical control benchmark and a
real-world pushing task using a Franka Emika Panda robot. Results show that
context-aware policies outperform the context-agnostic baseline across all
settings, although the best supervision strategy depends on the task.

</details>


### [179] [Design and Control of a Coaxial Dual-rotor Reconfigurable Tailsitter UAV Based on Swashplateless Mechanism](https://arxiv.org/abs/2511.04251)
*Jinfeng Liang,Haocheng Guo,Ximin Lyu*

Main category: cs.RO

TL;DR: 本文提出一种采用可重构机翼设计的尾座式垂直起降无人机，以解决其在多旋翼模式下易受风力干扰的问题。该无人机还采用了同轴异质双旋翼构型以提高电源效率，并使用改进的无十字盘机构来简化结构并减轻结构重量。通过添加拍动铰链优化了无十字盘机构的结构，以减少振动。最后，通过全面的过渡飞行测试验证了无人机在整个飞行包线内的稳定性。


<details>
  <summary>Details</summary>
Motivation: 尾座式垂直起降（VTOL）无人机因其较低的净重和无需倾斜执行器及机构而得到广泛应用。然而，尾座式无人机在多旋翼模式下容易受到风力干扰，因为其暴露了较大的正面机身面积。

Method: 本文提出一种采用可重构机翼设计的尾座式无人机，机翼可以在多旋翼模式下收回，在固定翼模式下伸展。为了考虑电源效率，采用了一种同轴异质双旋翼构型，大大降低了总功耗。为了减轻结构重量和简化结构复杂度，采用了一种改进的无十字盘机构来控制多旋翼模式下的俯仰和横滚。通过添加拍动铰链对无十字盘机构的结构进行了优化，以减少了在周期性加速和减速期间的振动。

Result: 完成了全面的过渡飞行测试，以验证尾座式无人机在整个飞行包线内的稳定飞行性能。

Conclusion: 所提出的尾座式无人机通过采用可重构机翼、同轴异质双旋翼构型和改进的无十字盘机构，成功解决了尾座式无人机在多旋翼模式下的风力干扰问题，并提高了电源效率和结构简化性，同时通过了全面的飞行测试验证了其稳定性。

Abstract: The tailsitter vertical takeoff and landing (VTOL) UAV is widely used due to
its lower dead weight, which eliminates the actuators and mechanisms for
tilting. However, the tailsitter UAV is susceptible to wind disturbances in
multi-rotor mode, as it exposes a large frontal fuselage area. To address this
issue, our tailsitter UAV features a reconfigurable wing design, allowing wings
to retract in multi-rotor mode and extend in fixed- wing mode. Considering
power efficiency, we design a coaxial heterogeneous dual-rotor configuration,
which significantly re- duces the total power consumption. To reduce structural
weight and simplify structural complexity, we employ a swashplateless mechanism
with an improved design to control pitch and roll in multi-rotor mode. We
optimize the structure of the swashplateless mechanism by adding flapping
hinges, which reduces vibration during cyclic acceleration and deceleration.
Finally, we perform comprehensive transition flight tests to validate stable
flight performance across the entire flight envelope of the tailsitter UAV.

</details>


### [180] [MacroNav: Multi-Task Context Representation Learning Enables Efficient Navigation in Unknown Environments](https://arxiv.org/abs/2511.04320)
*Kuankuan Sima,Longbin Tang,Haozhe Ma,Lin Zhao*

Main category: cs.RO

TL;DR: MacroNav是一个学习驱动的导航框架，通过轻量级上下文编码器和基于图的推理，实现了高效的空间理解和导航。


<details>
  <summary>Details</summary>
Motivation: 在未知环境中进行自主导航需要紧凑但富有表现力的空间理解，以支持高级决策制定。现有方法在平衡丰富的上下文表示和导航效率方面存在困难。

Method: MacroNav框架包含两个关键组件：1. 通过多任务自监督学习训练的轻量级上下文编码器，以捕获多尺度、面向导航的空间表示；2. 强化学习策略，将这些表示与基于图的推理相结合，以实现高效的动作选择。

Result: 实验表明，上下文编码器能够实现高效且鲁棒的环境理解。在真实世界部署中，MacroNav在成功率（SR）和成功率加权路径长度（SPL）方面均显著优于最先进的导航方法，同时保持了低计算成本。

Conclusion: MacroNav通过有效的空间理解和高效的决策制定，显著提高了自主导航的能力，并在复杂环境中表现出色。

Abstract: Autonomous navigation in unknown environments requires compact yet expressive
spatial understanding under partial observability to support high-level
decision making. Existing approaches struggle to balance rich contextual
representation with navigation efficiency. We present MacroNav, a
learning-based navigation framework featuring two key components: (1) a
lightweight context encoder trained via multi-task self-supervised learning to
capture multi-scale, navigation-centric spatial representations; and (2) a
reinforcement learning policy that seamlessly integrates these representations
with graph-based reasoning for efficient action selection. Extensive
experiments demonstrate the context encoder's efficient and robust
environmental understanding. Real-world deployments further validate MacroNav's
effectiveness, yielding significant gains over state-of-the-art navigation
methods in both Success Rate (SR) and Success weighted by Path Length (SPL),
while maintaining low computational cost. Code will be released upon
acceptance.

</details>


### [181] [GraSP-VLA: Graph-based Symbolic Action Representation for Long-Horizon Planning with VLA Policies](https://arxiv.org/abs/2511.04357)
*Maëlic Neau,Zoe Falomir,Paulo E. Santos,Anne-Gwenn Bosser,Cédric Buche*

Main category: cs.RO

TL;DR: 该研究提出了一种名为 GraSP-VLA 的新神经符号方法，通过使用连续场景图（Continuous Scene Graph）来生成人类演示的符号表示，解决了现有模仿学习方法在长期任务和泛化能力方面的局限性。


<details>
  <summary>Details</summary>
Motivation: 现有模仿学习方法，如基于视觉-语言-动作（VLA）模型的端到端学习和基于动作模型学习（AML）的符号方法，在处理长期任务和泛化能力方面存在不足。VLA模型缺乏高层符号规划能力，而AML方法泛化性和可扩展性差。

Method: 提出了一种名为 GraSP-VLA 的神经符号框架，使用连续场景图（Continuous Scene Graph）来表示人类演示，并生成新的规划域，同时作为低层VLA策略的协调器，以实现更长的连续动作序列。

Result: GraSP-VLA 在从观测中自动生成规划域方面是有效的，并且在现实世界的实验中，其连续场景图表示在长期任务中协调低层VLA策略方面展现了潜力。

Conclusion: GraSP-VLA 通过结合符号规划和低层模仿学习，有效解决了现有方法的局限性，并在自动规划域生成和长期机器人任务执行方面取得了积极成果。

Abstract: Deploying autonomous robots that can learn new skills from demonstrations is
an important challenge of modern robotics. Existing solutions often apply
end-to-end imitation learning with Vision-Language Action (VLA) models or
symbolic approaches with Action Model Learning (AML). On the one hand, current
VLA models are limited by the lack of high-level symbolic planning, which
hinders their abilities in long-horizon tasks. On the other hand, symbolic
approaches in AML lack generalization and scalability perspectives. In this
paper we present a new neuro-symbolic approach, GraSP-VLA, a framework that
uses a Continuous Scene Graph representation to generate a symbolic
representation of human demonstrations. This representation is used to generate
new planning domains during inference and serves as an orchestrator for
low-level VLA policies, scaling up the number of actions that can be reproduced
in a row. Our results show that GraSP-VLA is effective for modeling symbolic
representations on the task of automatic planning domain generation from
observations. In addition, results on real-world experiments show the potential
of our Continuous Scene Graph representation to orchestrate low-level VLA
policies in long-horizon tasks.

</details>


### [182] [Studying the Effect of Explicit Interaction Representations on Learning Scene-level Distributions of Human Trajectories](https://arxiv.org/abs/2511.04375)
*Anna Mészáros,Javier Alonso-Mora,Jens Kober*

Main category: cs.RO

TL;DR: 现有的多智能体场景联合分布预测模型在处理智能体间交互方面存在局限。本文研究了在同一网络结构中描述交互的不同方法，并分析了它们对学习到的联合分布的影响。实验结果表明，隐式学习交互通常会损害性能，而明确定义交互（例如，在交叉路口谁先通过）可以显著提高性能。


<details>
  <summary>Details</summary>
Motivation: 现有模型在学习多智能体场景交互方面存在不足，需要研究更有效的交互表示方法来提高联合分布预测的准确性。

Method: 在同一网络结构中研究和比较多种交互描述方式，分析它们对最终学习到的联合分布的影响。

Result: 研究发现，隐式学习交互通常会损害性能，而明确定义的交互（例如，在交叉路口谁先通过）可以显著提高预测性能。

Conclusion: 明确定义的交互方式比隐式学习的交互方式更能有效地提高多智能体场景联合分布预测的准确性。

Abstract: Effectively capturing the joint distribution of all agents in a scene is
relevant for predicting the true evolution of the scene and in turn providing
more accurate information to the decision processes of autonomous vehicles.
While new models have been developed for this purpose in recent years, it
remains unclear how to best represent the joint distributions particularly from
the perspective of the interactions between agents. Thus far there is no clear
consensus on how best to represent interactions between agents; whether they
should be learned implicitly from data by neural networks, or explicitly
modeled using the spatial and temporal relations that are more grounded in
human decision-making. This paper aims to study various means of describing
interactions within the same network structure and their effect on the final
learned joint distributions. Our findings show that more often than not, simply
allowing a network to establish interactive connections between agents based on
data has a detrimental effect on performance. Instead, having well defined
interactions (such as which agent of an agent pair passes first at an
intersection) can often bring about a clear boost in performance.

</details>


### [183] [ForeRobo: Unlocking Infinite Simulation Data for 3D Goal-driven Robotic Manipulation](https://arxiv.org/abs/2511.04381)
*Dexin wang,Faliang Chang,Chunsheng Liu*

Main category: cs.RO

TL;DR: ForeRobo是一个生成式机器人代理，通过生成式模拟自主学习抓取技能，它结合了生成式方法和经典控制，通过'提议-生成-学习-驱动'的循环来学习，并在多种抓取任务上展示了优越的性能和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 高效利用模拟来获取高级操作技能具有挑战性但意义重大。

Method: ForeRobo代理采用'提议-生成-学习-驱动'的循环。首先，它提议要获取的技能并构建相应的模拟环境；然后，它配置对象以生成与技能一致的目标状态（ForeGen）；接着，利用ForeGen产生的无限数据训练状态生成模型（ForeFormer），该模型根据场景状态和任务指令预测当前状态下每个点的3D目标位置；最后，利用经典控制算法驱动机器人在真实环境中执行动作。

Result: ForeFormer在刚体和铰接对象操作任务上的平均性能比最先进的状态生成模型提高了56.32%，显示出强大的通用性。在真实世界的20多项机器人任务评估中，ForeRobo实现了零次学习的模拟到现实迁移，平均成功率为79.28%。

Conclusion: ForeRobo通过结合生成式模拟和经典控制，能够自主学习操作技能，并实现高效的零次学习模拟到现实迁移和优越的泛化能力，优于端到端的策略学习方法。

Abstract: Efficiently leveraging simulation to acquire advanced manipulation skills is
both challenging and highly significant. We introduce \textit{ForeRobo}, a
generative robotic agent that utilizes generative simulations to autonomously
acquire manipulation skills driven by envisioned goal states. Instead of
directly learning low-level policies, we advocate integrating generative
paradigms with classical control. Our approach equips a robotic agent with a
self-guided \textit{propose-generate-learn-actuate} cycle. The agent first
proposes the skills to be acquired and constructs the corresponding simulation
environments; it then configures objects into appropriate arrangements to
generate skill-consistent goal states (\textit{ForeGen}). Subsequently, the
virtually infinite data produced by ForeGen are used to train the proposed
state generation model (\textit{ForeFormer}), which establishes point-wise
correspondences by predicting the 3D goal position of every point in the
current state, based on the scene state and task instructions. Finally,
classical control algorithms are employed to drive the robot in real-world
environments to execute actions based on the envisioned goal states. Compared
with end-to-end policy learning methods, ForeFormer offers superior
interpretability and execution efficiency. We train and benchmark ForeFormer
across a variety of rigid-body and articulated-object manipulation tasks, and
observe an average improvement of 56.32\% over the state-of-the-art state
generation models, demonstrating strong generality across different
manipulation patterns. Moreover, in real-world evaluations involving more than
20 robotic tasks, ForeRobo achieves zero-shot sim-to-real transfer and exhibits
remarkable generalization capabilities, attaining an average success rate of
79.28\%.

</details>


### [184] [Temporal Action Selection for Action Chunking](https://arxiv.org/abs/2511.04421)
*Yueyang Weng,Xiaopeng Zhang,Yongjin Mu,Yingcong Zhu,Yanjie Li,Qi Liu*

Main category: cs.RO

TL;DR: 通过引入时间动作选择器（TAS），在保持决策一致性的同时提高了动作识别的响应速度，从而提升了成功率。


<details>
  <summary>Details</summary>
Motivation: 现有动作切块方法在提高决策一致性的同时，牺牲了响应速度，限制了对近期观测的利用，导致在传感器噪声和动态环境变化下适应性不足。

Method: 提出时间动作选择器（TAS），通过缓存多个时间步长的预测动作块，并使用轻量级选择器网络动态选择最优动作，以平衡响应速度、决策一致性和运动连贯性。

Result: TAS在多个任务中显著提高了成功率，最高提升了73.3%。将TAS作为基础策略与残差强化学习（RL）相结合，能够显著提高训练效率并提升性能。

Conclusion: TAS算法能够有效平衡响应速度、决策一致性和运动连贯性，在多种任务和基础策略下均能显著提升成功率，并能与RL结合以提高训练效率和性能。

Abstract: Action chunking is a widely adopted approach in Learning from Demonstration
(LfD). By modeling multi-step action chunks rather than single-step actions,
action chunking significantly enhances modeling capabilities for human expert
policies. However, the reduced decision frequency restricts the utilization of
recent observations, degrading reactivity - particularly evident in the
inadequate adaptation to sensor noise and dynamic environmental changes.
Existing efforts to address this issue have primarily resorted to trading off
reactivity against decision consistency, without achieving both. To address
this limitation, we propose a novel algorithm, Temporal Action Selector (TAS),
which caches predicted action chunks from multiple timesteps and dynamically
selects the optimal action through a lightweight selector network. TAS achieves
balanced optimization across three critical dimensions: reactivity, decision
consistency, and motion coherence. Experiments across multiple tasks with
diverse base policies show that TAS significantly improves success rates -
yielding an absolute gain of up to 73.3%. Furthermore, integrating TAS as a
base policy with residual reinforcement learning (RL) substantially enhances
training efficiency and elevates the performance plateau. Experiments in both
simulation and physical robots confirm the method's efficacy.

</details>


### [185] [Evo-1: Lightweight Vision-Language-Action Model with Preserved Semantic Alignment](https://arxiv.org/abs/2511.04555)
*Tao Lin,Yilei Zhong,Yuxin Du,Jingjing Zhang,Jiting Liu,Yinxinyu Chen,Encheng Gu,Ziyan Liu,Hongyi Cai,Yanwen Zou,Lixing Zou,Zhaoye Zhou,Gen Li,Bo Zhao*

Main category: cs.RO

TL;DR: Evo-1是一个轻量级的视觉-语言-动作（VLA）模型，通过新颖的跨调制扩散变换器和优化的集成模块，实现了高效的计算和部署，无需机器人数据预训练，并在多个基准测试中取得了最先进的成果。


<details>
  <summary>Details</summary>
Motivation: 现有VLA模型参数量大、计算成本高、部署困难，且预训练会损害感知表示，导致泛化能力差。

Method: 提出轻量级VLA模型Evo-1，采用原生多模态视觉-语言模型（VLM），结合交叉调制扩散变换器和优化集成模块。采用两阶段训练范式，逐步对齐动作与感知，保留VLM表示。

Result: Evo-1在Meta-World和RoboTwin测试中分别超越先前最佳模型12.4%和6.9%，在LIBERO上达到94.8%。实际评估中，成功率达78%，推理频率高，内存开销低。

Conclusion: Evo-1在保持强大性能的同时，显著降低了计算复杂度和部署要求，为开发轻量级高效VLA模型提供了新途径。

Abstract: Vision-Language-Action (VLA) models have emerged as a powerful framework that
unifies perception, language, and control, enabling robots to perform diverse
tasks through multimodal understanding. However, current VLA models typically
contain massive parameters and rely heavily on large-scale robot data
pretraining, leading to high computational costs during training, as well as
limited deployability for real-time inference. Moreover, most training
paradigms often degrade the perceptual representations of the vision-language
backbone, resulting in overfitting and poor generalization to downstream tasks.
In this work, we present Evo-1, a lightweight VLA model that reduces
computation and improves deployment efficiency, while maintaining strong
performance without pretraining on robot data. Evo-1 builds on a native
multimodal Vision-Language model (VLM), incorporating a novel cross-modulated
diffusion transformer along with an optimized integration module, together
forming an effective architecture. We further introduce a two-stage training
paradigm that progressively aligns action with perception, preserving the
representations of the VLM. Notably, with only 0.77 billion parameters, Evo-1
achieves state-of-the-art results on the Meta-World and RoboTwin suite,
surpassing the previous best models by 12.4% and 6.9%, respectively, and also
attains a competitive result of 94.8% on LIBERO. In real-world evaluations,
Evo-1 attains a 78% success rate with high inference frequency and low memory
overhead, outperforming all baseline methods. We release code, data, and model
weights to facilitate future research on lightweight and efficient VLA models.

</details>


### [186] [SAFe-Copilot: Unified Shared Autonomy Framework](https://arxiv.org/abs/2511.04664)
*Phat Nguyen,Erfan Aasi,Shiva Sreeram,Guy Rosman,Andrew Silva,Sertac Karaman,Daniela Rus*

Main category: cs.RO

TL;DR: 共享自主框架通过整合高层语义和人类意图来提高自动驾驶的鲁棒性，特别是在罕见和模糊的场景下。


<details>
  <summary>Details</summary>
Motivation: 现有的共享自主方法主要在低层轨迹层面进行仲裁，无法保留人类的驾驶意图，导致在罕见、模糊或分布外场景下自动驾驶系统表现脆弱，而人类驾驶员能通过情境推理成功应对。

Method: 提出一个统一的共享自主框架，该框架利用视觉语言模型（VLMs）从包括驾驶员行为和环境背景在内的多模态线索推断驾驶员意图，并生成连贯的策略来协调人类和自主控制。该框架在模拟人类环境中进行了研究，并在Bench2Drive基准上进行了评估。

Result: 在模拟人类环境中，该框架实现了完美的召回率以及高准确率和精确率。人类受试者调查显示，92%的受试者同意仲裁结果。在Bench2Drive基准上的评估表明，与纯自主系统相比，碰撞率显著降低，整体性能有所提高。

Conclusion: 在语义和基于语言的表示层面进行仲裁是共享自主设计的一个原则，它能够使系统运用常识推理并与人类意图保持一致，从而提升自动驾驶的鲁棒性。

Abstract: Autonomous driving systems remain brittle in rare, ambiguous, and
out-of-distribution scenarios, where human driver succeed through contextual
reasoning. Shared autonomy has emerged as a promising approach to mitigate such
failures by incorporating human input when autonomy is uncertain. However, most
existing methods restrict arbitration to low-level trajectories, which
represent only geometric paths and therefore fail to preserve the underlying
driving intent. We propose a unified shared autonomy framework that integrates
human input and autonomous planners at a higher level of abstraction. Our
method leverages Vision Language Models (VLMs) to infer driver intent from
multi-modal cues -- such as driver actions and environmental context -- and to
synthesize coherent strategies that mediate between human and autonomous
control. We first study the framework in a mock-human setting, where it
achieves perfect recall alongside high accuracy and precision. A human-subject
survey further shows strong alignment, with participants agreeing with
arbitration outcomes in 92% of cases. Finally, evaluation on the Bench2Drive
benchmark demonstrates a substantial reduction in collision rate and
improvement in overall performance compared to pure autonomy. Arbitration at
the level of semantic, language-based representations emerges as a design
principle for shared autonomy, enabling systems to exercise common-sense
reasoning and maintain continuity with human intent.

</details>


### [187] [Real-to-Sim Robot Policy Evaluation with Gaussian Splatting Simulation of Soft-Body Interactions](https://arxiv.org/abs/2511.04665)
*Kaifeng Zhang,Shuo Sha,Hanxiao Jiang,Matthew Loper,Hyunjong Song,Guangyan Cai,Zhuo Xu,Xiaochen Hu,Changxi Zheng,Yunzhu Li*

Main category: cs.RO

TL;DR: 该研究提出了一个名为real-to-sim的框架，用于通过结合物理重建和3D高斯溅射渲染，从现实世界视频构建软体对象的数字孪生，以在模拟环境中准确、可扩展且可复现地评估机器人操作策略，尤其是在处理易变形物体时。


<details>
  <summary>Details</summary>
Motivation: 现实世界中机器人操作策略的评估成本高、耗时长且难以复现，特别是在处理易变形物体时。现有的模拟器在捕捉软体交互的视觉和物理复杂性方面存在不足。

Method: 使用3D高斯溅射技术，从真实世界的视频构建软体对象的数字孪生，并以照片级保真度渲染机器人、物体和环境。该框架结合了物理信息重建和高质量渲染。

Result: 在毛绒玩具打包、绳索布线和T形块推动等代表性易变形操作任务上进行了验证，结果表明模拟运行与现实世界执行性能高度相关，并揭示了学习策略的关键行为模式。

Conclusion: 结合物理信息重建和高质量渲染技术，可以实现机器人操作策略的可复现、可扩展和准确的评估。

Abstract: Robotic manipulation policies are advancing rapidly, but their direct
evaluation in the real world remains costly, time-consuming, and difficult to
reproduce, particularly for tasks involving deformable objects. Simulation
provides a scalable and systematic alternative, yet existing simulators often
fail to capture the coupled visual and physical complexity of soft-body
interactions. We present a real-to-sim policy evaluation framework that
constructs soft-body digital twins from real-world videos and renders robots,
objects, and environments with photorealistic fidelity using 3D Gaussian
Splatting. We validate our approach on representative deformable manipulation
tasks, including plush toy packing, rope routing, and T-block pushing,
demonstrating that simulated rollouts correlate strongly with real-world
execution performance and reveal key behavioral patterns of learned policies.
Our results suggest that combining physics-informed reconstruction with
high-quality rendering enables reproducible, scalable, and accurate evaluation
of robotic manipulation policies. Website: https://real2sim-eval.github.io/

</details>


### [188] [X-Diffusion: Training Diffusion Policies on Cross-Embodiment Human Demonstrations](https://arxiv.org/abs/2511.04671)
*Maximus A. Pace,Prithwish Dan,Chuanruo Ning,Atiksh Bhardwaj,Audrey Du,Edward W. Duan,Wei-Chiu Ma,Kushal Kedia*

Main category: cs.RO

TL;DR: X-Diffusion框架利用人类视频数据训练机器人学习，通过在动作中加入噪声来解决人类与机器人本体的差异，保留高层任务指导，提高机器人学习的成功率。


<details>
  <summary>Details</summary>
Motivation: 人类视频数据易于获取，但人类与机器人本体的差异导致动作执行不匹配，直接使用可能产生机器人无法完成的动作。

Method: X-Diffusion框架首先训练一个分类器来区分被噪声干扰的人类或机器人动作，然后只在加入足够噪声、分类器无法区分其来源时才将人类动作纳入策略训练。低噪声水平下，机器人动作指导精细去噪；高噪声水平下，人类动作提供粗略指导。

Result: X-Diffusion在五个操作任务中，相比于基线方法，平均成功率提高了16%。

Conclusion: X-Diffusion框架能够有效利用人类数据进行机器人学习，避免学习不可行的动作，并显著提高任务成功率。

Abstract: Human videos can be recorded quickly and at scale, making them an appealing
source of training data for robot learning. However, humans and robots differ
fundamentally in embodiment, resulting in mismatched action execution. Direct
kinematic retargeting of human hand motion can therefore produce actions that
are physically infeasible for robots. Despite these low-level differences,
human demonstrations provide valuable motion cues about how to manipulate and
interact with objects. Our key idea is to exploit the forward diffusion
process: as noise is added to actions, low-level execution differences fade
while high-level task guidance is preserved. We present X-Diffusion, a
principled framework for training diffusion policies that maximally leverages
human data without learning dynamically infeasible motions. X-Diffusion first
trains a classifier to predict whether a noisy action is executed by a human or
robot. Then, a human action is incorporated into policy training only after
adding sufficient noise such that the classifier cannot discern its embodiment.
Actions consistent with robot execution supervise fine-grained denoising at low
noise levels, while mismatched human actions provide only coarse guidance at
higher noise levels. Our experiments show that naive co-training under
execution mismatches degrades policy performance, while X-Diffusion
consistently improves it. Across five manipulation tasks, X-Diffusion achieves
a 16% higher average success rate than the best baseline. The project website
is available at https://portal-cornell.github.io/X-Diffusion/.

</details>


### [189] [GentleHumanoid: Learning Upper-body Compliance for Contact-rich Human and Object Interaction](https://arxiv.org/abs/2511.04679)
*Qingzhou Lu,Yao Feng,Baiyu Shi,Michael Piseno,Zhenan Bao,C. Karen Liu*

Main category: cs.RO

TL;DR: 该研究提出了一种名为 GentleHumanoid 的框架，通过将阻抗控制整合到全身运动跟踪策略中，实现了人形机器人的上身顺应性，从而能在与人交互时提供安全、自然的物理交互。


<details>
  <summary>Details</summary>
Motivation: 现有强化学习（RL）策略在处理物理交互时存在不足，通常侧重于刚性跟踪并抑制外部力，而阻抗增强方法则受限于特定部位控制且主要用于抵抗而非实现顺应性。因此，需要一种能实现全身顺应性的方法来提升人形机器人在人居环境中的安全性与交互自然性。

Method: 提出 GentleHumanoid 框架，该框架的核心是一个统一的基于弹簧的力学模型，能够同时处理接触响应（如抵御表面推力）和引导性接触（如根据人类运动数据进行推拉）。该模型确保了肩部、肘部和腕部之间力学的协调一致，并允许策略在多样的交互场景中进行学习。此外，通过任务可调的力阈值来增强安全性。

Result: 在模拟和 Unitree G1 型号机器人上进行的评估表明，GentleHumanoid 框架在执行拥抱、辅助站立和安全操作物体等需要不同程度顺应性的任务时，能够有效降低峰值接触力，同时保持任务成功率，实现了更平滑、更自然的交互。

Conclusion: GentleHumanoid 框架通过整合全身阻抗控制，显著提升了人形机器人在与人交互和物体操作方面的安全性和自然性，是实现能安全有效协作并操作物体的人形机器人的重要一步。

Abstract: Humanoid robots are expected to operate in human-centered environments where
safe and natural physical interaction is essential. However, most recent
reinforcement learning (RL) policies emphasize rigid tracking and suppress
external forces. Existing impedance-augmented approaches are typically
restricted to base or end-effector control and focus on resisting extreme
forces rather than enabling compliance. We introduce GentleHumanoid, a
framework that integrates impedance control into a whole-body motion tracking
policy to achieve upper-body compliance. At its core is a unified spring-based
formulation that models both resistive contacts (restoring forces when pressing
against surfaces) and guiding contacts (pushes or pulls sampled from human
motion data). This formulation ensures kinematically consistent forces across
the shoulder, elbow, and wrist, while exposing the policy to diverse
interaction scenarios. Safety is further supported through task-adjustable
force thresholds. We evaluate our approach in both simulation and on the
Unitree G1 humanoid across tasks requiring different levels of compliance,
including gentle hugging, sit-to-stand assistance, and safe object
manipulation. Compared to baselines, our policy consistently reduces peak
contact forces while maintaining task success, resulting in smoother and more
natural interactions. These results highlight a step toward humanoid robots
that can safely and effectively collaborate with humans and handle objects in
real-world environments.

</details>


<div id='cs.LO'></div>

# cs.LO [[Back]](#toc)

### [190] [An Automated Theorem Generator with Theoretical Foundation Based on Rectangular Standard Contradiction](https://arxiv.org/abs/2511.04092)
*Yang Xu,Peiyao Liu,Shuwei Chen,Jun Liu*

Main category: cs.LO

TL;DR: 本文提出了一种新颖的自动定理生成理论和工具，基于“矩形标准矛盾”结构，实现了从机器“验证者”到“发现者”的转变。


<details>
  <summary>Details</summary>
Motivation: 当前缺乏系统生成非平凡且逻辑上有效的定理的严格理论体系。

Method: 提出了一种名为“矩形标准矛盾”的新型逻辑结构，并基于此构建了完整的自动定理生成（ATG）理论。该理论利用了矩形标准矛盾的两个核心性质：必然不可满足性（标准矛盾）和非冗余性。通过将矩形标准矛盾划分为前提子集A和其补集的否定H，形成有效的定理A ⊢ ¬H，并证明了所有此类定理都逻辑等价。为实现该理论，设计了一种高效的基于模板的ATG算法，并开发了“矩形自动定理生成器”。

Result: 通过理论证明，明确了矩形标准矛盾的两个核心性质：1. 它是标准矛盾（必然不可满足）；2. 具有非冗余性（移除任何子句后剩余子句集均可满足）。提出的ATG理论能够生成所有逻辑等价的有效定理。

Conclusion: 该研究使得机器能够从“验证者”转变为“发现者”，为逻辑和人工智能领域的根本性研究开辟了新途径。

Abstract: Currently, there is a lack of rigorous theoretical system for systematically
generating non-trivial and logically valid theorems. Addressing this critical
gap, this paper conducts research to propose a novel automated theorem
generation theory and tool. Based on the concept of standard contradiction
which possesses unique deductive advantages, this paper defines and proves, for
the first time, a new logical structure known as rectangular standard
contradiction. Centered on this structure, a complete Automated Theorem
Generation (ATG) theory is put forward. Theoretical proofs clarify two core
properties of rectangular standard contradiction: first, it is a standard
contradiction (necessarily unsatisfiable); second, it exhibits non-redundancy
(the remaining clause set becomes satisfiable after removing any clause).
Leveraging these properties, this paper proves that partitioning a rectangular
standard contradiction into a premise subset $A$ and negation of its complement
$H$, a valid theorem $A \vdash \neg H$ can be formed, and all such theorems are
logically equivalent. To implement this theory, an efficient template-based ATG
algorithm is designed, and a Rectangular Automated Theorem Generator is
developed. This research enables machines to transition from "verifiers" to
"discoverers", opening up new avenues for fundamental research in the fields of
logic and artificial intelligence.

</details>


### [191] [Compact Quantitative Theories of Convex Algebras](https://arxiv.org/abs/2511.04201)
*Matteo Mio*

Main category: cs.LO

TL;DR: 定量方程理论在代数中的应用


<details>
  <summary>Details</summary>
Motivation: 介绍紧凑型定量方程理论的概念，并将其应用于代数。

Method: 证明了Mardare等人提出的插值重合（也称为凸）定量代数的理论是紧凑的。

Result: 该理论是紧凑的，可用于获取其他凸代数的紧凑型定量方程理论。

Conclusion: 该研究为距离和概率分布的量化提供了一个新的理论框架。

Abstract: We introduce the concept of compact quantitative equational theory. A
quantitative equational theory is defined to be compact if all its consequences
are derivable by means of finite proofs. We prove that the theory of
interpolative barycentric (also known as convex) quantitative algebras of
Mardare et. al. is compact. This serves as a paradigmatic example, used to
obtain other compact quantitative equational theories of convex algebras, each
axiomatizing some distance on finitely supported probability distributions.

</details>


### [192] [The Size of Interpolants in Modal Logics](https://arxiv.org/abs/2511.04577)
*Balder ten Cate,Louwe Kuijer,Frank Wolter*

Main category: cs.LO

TL;DR: 为（准）模态逻辑的 Craig 插值式、均匀插值式和最强隐含式的尺寸进行了系统研究。主要上界表明，对于表格模态逻辑，最强隐含式的计算可以在多项式时间内还原为经典命题逻辑中的均匀插值式计算，因此当且仅当 NP $\subseteq$ P$_{/\text{poly}}$ 时，它们的 dag 尺寸是多项式的。如果表格模态逻辑具有 Craig 插值性质，则该还原也适用于 Craig 插值式和均匀插值式。主要下界显示，对于几乎所有非表格标准模态逻辑，Craig 插值式和最强隐含式的尺寸存在无条件的指数下界。对于包含或被 S4 或 GL 包含的模态逻辑，我们得到了以下二分法：表格逻辑具有“命题尺寸”的插值式，而非表格逻辑则存在无条件的指数下界。


<details>
  <summary>Details</summary>
Motivation: 研究（准）模态逻辑中 Craig 插值式、均匀插值式和最强隐含式的尺寸问题，并提供上下界。

Method: 通过将最强隐含式的计算还原为经典命题逻辑中的均匀插值式计算，并利用 Craig 插值性质进行推导。

Result: 对于表格模态逻辑，最强隐含式的计算可以在多项式时间内还原为经典命题逻辑中的均匀插值式计算，并且当且仅当 NP $\subseteq$ P$_{/\text{poly}}$ 时，它们的 dag 尺寸是多项式的。对于包含或被 S4 或 GL 包含的模态逻辑，提出了一个二分法：表格逻辑具有“命题尺寸”的插值式，而非表格逻辑则存在无条件的指数下界。

Conclusion: （准）模态逻辑的 Craig 插值式、均匀插值式和最强隐含式的尺寸可以通过上界和下界进行刻画，并且与 NP 问题的复杂度以及逻辑系统的性质（表格或非表格）相关。

Abstract: We start a systematic investigation of the size of Craig interpolants,
uniform interpolants, and strongest implicates for (quasi-)normal modal logics.
Our main upper bound states that for tabular modal logics, the computation of
strongest implicates can be reduced in polynomial time to uniform interpolant
computation in classical propositional logic. Hence they are of polynomial
dag-size iff NP $\subseteq$ P$_{/\text{poly}}$. The reduction also holds for
Craig interpolants and uniform interpolants if the tabular modal logic has the
Craig interpolation property. Our main lower bound shows an unconditional
exponential lower bound on the size of Craig interpolants and strongest
implicates covering almost all non-tabular standard normal modal logics. For
normal modal logics contained in or containing S4 or GL we obtain the following
dichotomy: tabular logics have ``propositionally sized'' interpolants while for
non-tabular logics an unconditional exponential lower bound holds.

</details>


<div id='cs.DC'></div>

# cs.DC [[Back]](#toc)

### [193] [OMPILOT: Harnessing Transformer Models for Auto Parallelization to Shared Memory Computing Paradigms](https://arxiv.org/abs/2511.03866)
*Arijit Bhattacharjee,Ali TehraniJamsaz,Le Chen,Niranjan Hasabnis,Mihai Capota,Nesreen Ahmed,Ali Jannesari*

Main category: cs.DC

TL;DR: LLMs在代码翻译领域取得显著进展，尤其是在C++到OpenMP的翻译方面。本文提出了OMPILOT模型，它是一种专门针对C++到OpenMP翻译的领域特定模型，能够实现有效的共享内存并行化。OMPILOT通过自定义的预训练目标来学习并行结构语义，并结合无监督和有监督学习策略来提高翻译的鲁棒性。与以往仅关注循环级别转换的研究不同，OMPILOT在函数级别进行操作，以捕捉更广泛的语义上下文。为了评估OMPILOT的性能，本文还提出了OMPBLEU，一个专门用于评估OpenMP并行结构正确性和质量的新型复合指标。


<details>
  <summary>Details</summary>
Motivation: LLMs在代码翻译领域的进步为跨语言转换带来了更高的准确性和效率。然而，传统的代码翻译方法在处理特定领域的并行化方面存在局限性。本文旨在解决C++代码到OpenMP的翻译问题，以实现有效的共享内存并行化。

Method: 本文提出了OMPILOT，一个专门为C++到OpenMP翻译设计的领域特定编码器-解码器Transformer模型。OMPILOT采用了自定义的预训练目标，融入了并行结构的语义信息，并结合了无监督和有监督学习策略来增强翻译的鲁棒性。与以往的研究不同，OMPILOT在函数级别进行操作，以获取更广泛的语义上下文。

Result: OMPILOT在C++到OpenMP的代码翻译任务上表现出色，能够有效地实现共享内存并行化。此外，本文还提出了OMPBLEU指标，能够更准确地评估OpenMP并行代码的质量和正确性。

Conclusion: OMPILOT模型为C++代码到OpenMP的翻译提供了一种新颖且有效的方法，能够实现更广泛的语义上下文捕捉和更鲁棒的翻译。OMPBLEU指标的提出也为评估OpenMP并行代码的质量提供了新的标准。

Abstract: Recent advances in large language models (LLMs) have significantly
accelerated progress in code translation, enabling more accurate and efficient
transformation across programming languages. While originally developed for
natural language processing, LLMs have shown strong capabilities in modeling
programming language syntax and semantics, outperforming traditional rule-based
systems in both accuracy and flexibility. These models have streamlined
cross-language conversion, reduced development overhead, and accelerated legacy
code migration. In this paper, we introduce OMPILOT, a novel domain-specific
encoder-decoder transformer tailored for translating C++ code into OpenMP,
enabling effective shared-memory parallelization. OMPILOT leverages custom
pre-training objectives that incorporate the semantics of parallel constructs
and combines both unsupervised and supervised learning strategies to improve
code translation robustness. Unlike previous work that focused primarily on
loop-level transformations, OMPILOT operates at the function level to capture a
wider semantic context. To evaluate our approach, we propose OMPBLEU, a novel
composite metric specifically crafted to assess the correctness and quality of
OpenMP parallel constructs, addressing limitations in conventional translation
metrics.

</details>


### [194] [Stochastic Modeling for Energy-Efficient Edge Infrastructure](https://arxiv.org/abs/2511.03941)
*Fabio Diniz Rossi*

Main category: cs.DC

TL;DR: Edge computing 依赖 AI 预测性功耗扩展来提高能源效率。


<details>
  <summary>Details</summary>
Motivation: Edge Computing 的分布式性质和有限的能源资源带来了能源管理方面的挑战。

Method: 提出了一种使用马尔可夫链进行随机建模的方法，以分析 Edge Computing 中的功耗状态转换。

Result: AI 驱动的预测性功耗扩展比传统的反应式方法具有优势。模型由蒙特卡洛模拟验证，并进行了敏感性分析。

Conclusion: AI 驱动的功耗管理策略通过预期工作负载需求和优化状态转换，显著提高了能源效率。实验结果表明，AI 驱动的功耗管理优化了跨异构边缘节点的功耗分配，并提高了多节点环境中的整体效率和自适应功耗协调。

Abstract: Edge Computing enables low-latency processing for real-time applications but
introduces challenges in power management due to the distributed nature of edge
devices and their limited energy resources. This paper proposes a stochastic
modeling approach using Markov Chains to analyze power state transitions in
Edge Computing. By deriving steady-state probabilities and evaluating energy
consumption, we demonstrate the benefits of AI-driven predictive power scaling
over conventional reactive methods. Monte Carlo simulations validate the model,
showing strong alignment between theoretical and empirical results. Sensitivity
analysis highlights how varying transition probabilities affect power
efficiency, confirming that predictive scaling minimizes unnecessary
transitions and improves overall system responsiveness. Our findings suggest
that AI-based power management strategies significantly enhance energy
efficiency by anticipating workload demands and optimizing state transitions.
Experimental results indicate that AI-based power management optimizes workload
distribution across heterogeneous edge nodes, reducing energy consumption
disparities between devices, improving overall efficiency, and enhancing
adaptive power coordination in multi-node environments.

</details>


### [195] [Parallel Spawning Strategies for Dynamic-Aware MPI Applications](https://arxiv.org/abs/2511.04268)
*Iker Martín-Álvarez,José I. Aliaga,Maribel Castillo,Sergio Iserte*

Main category: cs.DC

TL;DR: 动态资源管理和可塑性对于高性能计算很重要，但可塑性会带来高昂的重配置成本。本研究提出了一种新的并行生成策略，以降低这些成本。


<details>
  <summary>Details</summary>
Motivation: 动态资源管理对于高性能计算系统至关重要，它能够让作业在运行时调整资源分配，从而减少作业的完成时间和提高系统利用率。可塑性是指应用程序在执行期间适应新资源分配的能力。然而，可塑性会带来显著的重配置成本，因此降低这些成本是一个重要的研究课题。

Method: 提出了一种新的并行生成策略，其中所有进程在重分布之前进行协作生成，从而减少执行时间。此外，该策略还消除了收缩限制，能够更好地使并行系统适应工作负载并缩短其完成时间。

Result: 与现有方法相比，该策略在扩展时保持了具有最高 1.25 倍开销的竞争力，同时实现了快速收缩操作，成本降低了至少 20 倍。

Conclusion: 所提出的并行生成策略通过在重分布前进行进程协作生成，有效降低了重配置成本，同时提高了收缩操作的效率，从而克服了现有方法的局限性。该策略在同构和异构系统上都得到了验证，并能在共享资源环境中应用。

Abstract: Dynamic resource management is an increasingly important capability of High
Performance Computing systems, as it enables jobs to adjust their resource
allocation at runtime. This capability has been shown to reduce workload
makespan, substantially decrease job waiting times and improve overall system
utilization. In this context, malleability refers to the ability of
applications to adapt to new resource allocations during execution. Although
beneficial, malleability incurs significant reconfiguration costs, making the
reduction of these costs an important research topic.
  Some existing methods for MPI applications respawn the entire application,
which is an expensive solution that avoids the reuse of original processes.
Other MPI methods reuse them, but fail to fully release unneeded processes when
shrinking, since some ranks within the same communicator remain active across
nodes, preventing the application from returning those nodes to the system.
This work overcomes both limitations by proposing a novel parallel spawning
strategy, in which all processes cooperate in spawning before redistribution,
thereby reducing execution time. Additionally, it removes shrinkage
limitations, allowing better adaptation of parallel systems to workload and
reducing their makespan. As a result, it preserves competitive expansion times
with at most a $1.25\times$ overhead, while enabling fast shrink operations
that reduce their cost by at least $20\times$. This strategy has been validated
on both homogeneous and heterogeneous systems and can also be applied in
shared-resource environments.

</details>


### [196] [Enabling Dynamic Sparsity in Quantized LLM Inference](https://arxiv.org/abs/2511.04477)
*Rongxiang Wang,Kangyuan Shu,Felix Xiaozhu Lin*

Main category: cs.DC

TL;DR: 通过结构化稀疏性和低比特量化技术，在商品GPU上实现高效的LLM稀疏推理，速度提升高达1.55倍，同时保持精度。


<details>
  <summary>Details</summary>
Motivation: 在终端设备上部署LLM因其响应速度、隐私性和成本效益而备受关注，但设备有限的计算和内存能力阻碍了LLM的高效运行。现有的LLM激活动态稀疏性与主流的群组量化方法存在冲突，限制了模型在资源受限硬件上的性能。

Method: (1) 采用锯齿状量化布局，使权重组织方式与激活稀疏性兼容，并优化GPU内存局部性。(2) 设计了针对该布局的专用GEMV内核，以充分利用并行计算单元。(3) 引入紧凑的运行时机制，以最小的开销收集稀疏索引。

Result: 在不同模型规模和硬件配置下，该方法实现了高达1.55倍的解码吞吐量提升，同时保持了与密集量化推理相当的准确性。

Conclusion: 结构化稀疏性与量化技术可以有效地共存于商品GPU上，为在资源受限设备上部署LLM提供了有效解决方案。

Abstract: Deploying large language models (LLMs) on end-user devices is gaining
importance due to benefits in responsiveness, privacy, and operational cost.
Yet the limited memory and compute capability of mobile and desktop GPUs make
efficient execution difficult. Recent observations suggest that the internal
activations of LLMs are often dynamically sparse, meaning that for each input,
only part of the network contributes significantly to the output. Such sparsity
could reduce computation, but it interacts poorly with group-wise quantization,
which remains the dominant approach for fitting LLMs onto resource-constrained
hardware. To reconcile these two properties, this study proposes a set of
techniques that realize dynamic sparse inference under low-bit quantization.
The method features: (1) a zigzag-patterned quantization layout that organizes
weights in a way consistent with activation sparsity and improves GPU memory
locality; (2) a specialized GEMV kernel designed for this layout to fully
utilize parallel compute units; and (3) a compact runtime mechanism that
gathers sparse indices with minimal overhead. Across several model scales and
hardware configurations, the approach achieves up to 1.55x faster decoding
throughput while maintaining accuracy comparable to dense quantized inference,
showing that structured sparsity and quantization can effectively coexist on
commodity GPUs.

</details>


### [197] [A New Probabilistic Mobile Byzantine Failure Model for Self-Protecting Systems](https://arxiv.org/abs/2511.04523)
*Silvia Bonomi,Giovanni Farina,Roy Friedman,Eviatar B. Procaccia,Sebastien Tixeuil*

Main category: cs.DC

TL;DR: 本文提出了一种新的概率性移动拜占庭故障（MBF）模型，用于增强分布式系统的自保护能力，以应对不断演变的攻击。


<details>
  <summary>Details</summary>
Motivation: 现代分布式系统面临日益严峻的安全威胁，需要更强的容错和自保护能力来应对攻击。

Method: 提出了一种新的概率性移动拜占庭故障（MBF）模型，并将其集成到基于MAPE-K架构的自保护分布式系统的分析组件中，以捕捉不断演变的攻击动态。

Result: 对MBF模型进行了数学分析，研究了拜占庭节点数量达到阈值的时间以及系统自恢复到安全状态所需的时间，并提供了仿真结果。

Conclusion: 所提出的MBF模型能够驱动自保护和重新配置策略，以应对动态变化的攻击，提高分布式系统的弹性和安全性。

Abstract: Modern distributed systems face growing security threats, as attackers
continuously enhance their skills and vulnerabilities span across the entire
system stack, from hardware to the application layer. In the system design
phase, fault tolerance techniques can be employed to safeguard systems. From a
theoretical perspective, an attacker attempting to compromise a system can be
abstracted by considering the presence of Byzantine processes in the system.
Although this approach enhances the resilience of the distributed system, it
introduces certain limitations regarding the accuracy of the model in
reflecting real-world scenarios. In this paper, we consider a self-protecting
distributed system based on the \emph{Monitoring-Analyse-Plan-Execute over a
shared Knowledge} (MAPE-K) architecture, and we propose a new probabilistic
Mobile Byzantine Failure (MBF) that can be plugged into the Analysis component.
Our new model captures the dynamics of evolving attacks and can be used to
drive the self-protection and reconfiguration strategy. We analyze
mathematically the time that it takes until the number of Byzantine nodes
crosses given thresholds, or for the system to self-recover back into a safe
state, depending on the rates of Byzantine infection spreading \emph{vs.} the
rate of self-recovery. We also provide simulation results that illustrate the
behavior of the system under such assumptions.

</details>


### [198] [Resolving Conflicts with Grace: Dynamically Concurrent Universality](https://arxiv.org/abs/2511.04631)
*Petr Kuznetsov,Nathan Josia Schrodt*

Main category: cs.DC

TL;DR: 并发操作在共享数据上遇到冲突时会进行同步，并且在某些罕见的states下，两个并发操作才会发生冲突。本文提出了一种动态并发，其中操作仅在必须与并发操作仲裁时才使用强同步原语，并提出了一个动态并发的通用构造。


<details>
  <summary>Details</summary>
Motivation: 同步是分布式计算中可伸缩性的主要障碍。

Method: 提出了一种动态并发的概念，其中操作仅在必须与并发操作进行仲裁时才使用强同步原语，并提出了一个动态并发的通用构造。

Result: 实现了一个动态并发的通用构造。

Conclusion: 动态并发的概念允许操作仅在必要时使用强同步原语，从而提高可伸缩性。

Abstract: Synchronization is the major obstacle to scalability in distributed
computing. Concurrent operations on the shared data engage in synchronization
when they encounter a \emph{conflict}, i.e., their effects depend on the order
in which they are applied. Ideally, one would like to detect conflicts in a
\emph{dynamic} manner, i.e., adjusting to the current system state. Indeed, it
is very common that two concurrent operations conflict only in some rarely
occurring states. In this paper, we define the notion of \emph{dynamic
concurrency}: an operation employs strong synchronization primitives only if it
\emph{has} to arbitrate with concurrent operations, given the current system
state. We then present a dynamically concurrent universal construction.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [199] [Applying Time Series Deep Learning Models to Forecast the Growth of Perennial Ryegrass in Ireland](https://arxiv.org/abs/2511.03749)
*Oluwadurotimi Onibonoje,Vuong M. Ngo,Andrew McCarre,Elodie Ruelle,Bernadette O-Briend,Mark Roantree*

Main category: cs.LG

TL;DR: 爱尔兰的经济支柱之一的乳制品行业正面临盈利能力和可持续性方面的挑战。为了解决这个问题，本研究提出了一种利用深度学习模型来预测黑麦草生长状况的方法，以期提供比现有机械模型更具成本效益的替代方案。


<details>
  <summary>Details</summary>
Motivation: 爱尔兰的乳制品行业是经济的重要组成部分，但面临着盈利能力和可持续性的挑战。目前，草地产量预测依赖于不切实际的机械模型。

Method: 提出并验证了一种用于预测黑麦草生长状况的深度学习模型（特别是时间卷积网络），并使用RMSE为2.74，MAE为3.46的性能指标。

Result: 提出的时间卷积网络在预测爱尔兰科克地区的黑麦草生长方面表现出高水平的性能，并且在跨越34年的1757周的综合数据集上进行了验证。

Conclusion: 本研究通过加深对模型行为的理解，提高了草地产量预测的可靠性，为可持续的乳制品农业实践做出了贡献。

Abstract: Grasslands, constituting the world's second-largest terrestrial carbon sink,
play a crucial role in biodiversity and the regulation of the carbon cycle.
Currently, the Irish dairy sector, a significant economic contributor, grapples
with challenges related to profitability and sustainability. Presently, grass
growth forecasting relies on impractical mechanistic models. In response, we
propose deep learning models tailored for univariate datasets, presenting
cost-effective alternatives. Notably, a temporal convolutional network designed
for forecasting Perennial Ryegrass growth in Cork exhibits high performance,
leveraging historical grass height data with RMSE of 2.74 and MAE of 3.46.
Validation across a comprehensive dataset spanning 1,757 weeks over 34 years
provides insights into optimal model configurations. This study enhances our
understanding of model behavior, thereby improving reliability in grass growth
forecasting and contributing to the advancement of sustainable dairy farming
practices.

</details>


### [200] [Federated Learning with Gramian Angular Fields for Privacy-Preserving ECG Classification on Heterogeneous IoT Devices](https://arxiv.org/abs/2511.03753)
*Youssef Elmir,Yassine Himeur,Abbes Amira*

Main category: cs.LG

TL;DR: 该研究提出了一种用于物联网医疗环境的联邦学习（FL）框架，通过将一维心电图（ECG）信号转换为二维Gramian Angular Field（GAF）图像，并利用卷积神经网络（CNN）进行特征提取，实现了隐私保护的心电图分类。


<details>
  <summary>Details</summary>
Motivation: 在物联网医疗环境中，保护敏感心电图数据的隐私并实现高效分类是一个关键挑战。

Method: 该研究提出了一种联邦学习（FL）框架，将一维心电图（ECG）信号转换为二维Gramian Angular Field（GAF）图像，并使用卷积神经网络（CNN）进行特征提取，同时确保数据在本地设备上处理。该框架在服务器、笔记本电脑和树莓派4等异构物联网设备上进行了实验验证。

Result: 在多客户端设置中，FL-GAF模型实现了95.18%的高分类准确率，在准确性和训练时间上均显著优于单客户端基线。尽管GAF转换增加了计算复杂性，但该框架仍保持了高效的资源利用和通信开销。

Conclusion: 研究结果表明，轻量级、隐私保护的人工智能在基于物联网的医疗监测方面具有巨大潜力，支持智慧健康系统中可扩展且安全的边缘部署。

Abstract: This study presents a federated learning (FL) framework for
privacy-preserving electrocardiogram (ECG) classification in Internet of Things
(IoT) healthcare environments. By transforming 1D ECG signals into 2D Gramian
Angular Field (GAF) images, the proposed approach enables efficient feature
extraction through Convolutional Neural Networks (CNNs) while ensuring that
sensitive medical data remain local to each device. This work is among the
first to experimentally validate GAF-based federated ECG classification across
heterogeneous IoT devices, quantifying both performance and communication
efficiency. To evaluate feasibility in realistic IoT settings, we deployed the
framework across a server, a laptop, and a resource-constrained Raspberry Pi 4,
reflecting edge-cloud integration in IoT ecosystems. Experimental results
demonstrate that the FL-GAF model achieves a high classification accuracy of
95.18% in a multi-client setup, significantly outperforming a single-client
baseline in both accuracy and training time. Despite the added computational
complexity of GAF transformations, the framework maintains efficient resource
utilization and communication overhead. These findings highlight the potential
of lightweight, privacy-preserving AI for IoT-based healthcare monitoring,
supporting scalable and secure edge deployments in smart health systems.

</details>


### [201] [Laugh, Relate, Engage: Stylized Comment Generation for Short Videos](https://arxiv.org/abs/2511.03757)
*Xuan Ouyang,Senan Wang,Bouzhou Wang,Siyuan Xiahou,Jinrong Zhou,Yuekang Li*

Main category: cs.LG

TL;DR: LOLGORITHM是一个多智能体系统（MAS），用于生成符合平台规范、风格多样且有上下文感知能力的短视频评论。


<details>
  <summary>Details</summary>
Motivation: 现有短视频评论生成面临合规性、风格多样性和上下文感知方面的挑战。

Method: LOLGORITHM整合了视频分割、上下文和情感分析以及风格感知提示构建，利用多模态大语言模型（MLLM）直接处理视频输入，并通过明确的提示标记和少样本示例实现细粒度的风格控制，支持包括双关语、押韵、模仿、讽刺、幽默和内容提取在内的六种评论风格。

Result: LOLGORITHM在中文（抖音）和英文（YouTube）数据集上进行了评估，覆盖五个热门视频类型。自动化指标和大规模人类偏好研究（40个视频，105名参与者）表明，LOLGORITHM在抖音上的偏好率超过90%，在YouTube上的偏好率达到87.55%，显著优于基线模型。

Conclusion: LOLGORITHM提供了一个可扩展且具有文化适应性的短视频平台风格化评论生成框架，有望增强用户参与度和创意互动。

Abstract: Short-video platforms have become a central medium in the modern Internet
landscape, where efficient information delivery and strong interactivity are
reshaping user engagement and cultural dissemination. Among the various forms
of user interaction, comments play a vital role in fostering community
participation and enabling content re-creation. However, generating comments
that are both compliant with platform guidelines and capable of exhibiting
stylistic diversity and contextual awareness remains a significant challenge.
We introduce LOLGORITHM, a modular multi-agent system (MAS) designed for
controllable short-video comment generation. The system integrates video
segmentation, contextual and affective analysis, and style-aware prompt
construction. It supports six distinct comment styles: puns (homophones),
rhyming, meme application, sarcasm (irony), plain humor, and content
extraction. Powered by a multimodal large language model (MLLM), LOLGORITHM
directly processes video inputs and achieves fine-grained style control through
explicit prompt markers and few-shot examples. To support development and
evaluation, we construct a bilingual dataset using official APIs from Douyin
(Chinese) and YouTube (English), covering five popular video genres: comedy
skits, daily life jokes, funny animal clips, humorous commentary, and talk
shows. Evaluation combines automated metrics originality, relevance, and style
conformity with a large-scale human preference study involving 40 videos and
105 participants. Results show that LOLGORITHM significantly outperforms
baseline models, achieving preference rates of over 90% on Douyin and 87.55% on
YouTube. This work presents a scalable and culturally adaptive framework for
stylized comment generation on short-video platforms, offering a promising path
to enhance user engagement and creative interaction.

</details>


### [202] [Comparing EPGP Surrogates and Finite Elements Under Degree-of-Freedom Parity](https://arxiv.org/abs/2511.04518)
*Obed Amo,Samit Ghosh,Markus Lange-Hegermann,Bogdan Raiţă,Michael Pokojovy*

Main category: cs.LG

TL;DR: B-EPGP在解决二维波动方程时，精度比CN-FEM高两个数量级。


<details>
  <summary>Details</summary>
Motivation: 比较B-EPGP和CN-FEM在求解二维波动方程时的性能。

Method: B-EPGP利用指数-多项式基来精确满足PDE和边界条件，并使用惩罚最小二乘法估计系数。CN-FEM采用有限元方法和Crank-Nicolson时间步进。通过DoF匹配协议确保公平比较。

Result: 在匹配DoF的情况下，B-EPGP在时空L2误差和最大时间L2空间误差方面均优于CN-FEM。

Conclusion: B-EPGP在求解具有齐次狄利克雷边界条件的二维波动方程方面，比CN-FEM更准确。

Abstract: We present a new benchmarking study comparing a boundary-constrained
Ehrenpreis--Palamodov Gaussian Process (B-EPGP) surrogate with a classical
finite element method combined with Crank--Nicolson time stepping (CN-FEM) for
solving the two-dimensional wave equation with homogeneous Dirichlet boundary
conditions. The B-EPGP construction leverages exponential-polynomial bases
derived from the characteristic variety to enforce the PDE and boundary
conditions exactly and employs penalized least squares to estimate the
coefficients. To ensure fairness across paradigms, we introduce a
degrees-of-freedom (DoF) matching protocol. Under matched DoF, B-EPGP
consistently attains lower space-time $L^2$-error and maximum-in-time
$L^{2}$-error in space than CN-FEM, improving accuracy by roughly two orders of
magnitude.

</details>


### [203] [Multiscale Astrocyte Network Calcium Dynamics for Biologically Plausible Intelligence in Anomaly Detection](https://arxiv.org/abs/2511.03993)
*Berk Iskar,Michael Taynnan Barros*

Main category: cs.LG

TL;DR: 使用受钙离子信号启发的框架，通过模拟细胞和深度神经网络的结合来改进网络异常检测，从而克服概念漂移并提高对新威胁的检测能力。


<details>
  <summary>Details</summary>
Motivation: 传统网络异常检测系统在离线训练后容易受到概念漂移和零日攻击或多态攻击等新威胁的影响。本研究旨在解决这一局限性。

Method: 提出一种受星形胶质细胞钙离子信号启发的钙离子调制学习框架，结合了多细胞星形胶质细胞动力学模拟器和深度神经网络（DNN）。模拟器通过IP3介导的钙离子释放、SERCA泵摄取和细胞间间隙连接的电导感知扩散来模拟星形胶质细胞的钙离子动力学。

Result: 在CTU-13（Neris）网络流量数据集上进行的评估表明，该方法比匹配的基线DNN具有优越的性能，在多个训练/测试分割中实现了高达约98%的准确率，并减少了误报和漏报，同时运行时间开销可忽略不计。

Conclusion: 所提出的钙离子调制学习框架为需要对不断变化的数据模式进行快速、符合生物学原理的适应的流式检测任务提供了一个通用的解决方案，其有效性已在网络安全应用中得到证明。

Abstract: Network anomaly detection systems encounter several challenges with
traditional detectors trained offline. They become susceptible to concept drift
and new threats such as zero-day or polymorphic attacks. To address this
limitation, we propose a Ca$^{2+}$-modulated learning framework that draws
inspiration from astrocytic Ca$^{2+}$ signaling in the brain, where rapid,
context-sensitive adaptation enables robust information processing. Our
approach couples a multicellular astrocyte dynamics simulator with a deep
neural network (DNN). The simulator models astrocytic Ca$^{2+}$ dynamics
through three key mechanisms: IP$_3$-mediated Ca$^{2+}$ release, SERCA pump
uptake, and conductance-aware diffusion through gap junctions between cells.
Evaluation of our proposed network on CTU-13 (Neris) network traffic data
demonstrates the effectiveness of our biologically plausible approach. The
Ca$^{2+}$-gated model outperforms a matched baseline DNN, achieving up to
$\sim$98\% accuracy with reduced false positives and negatives across multiple
train/test splits. Importantly, this improved performance comes with negligible
runtime overhead once Ca$^{2+}$ trajectories are precomputed. While
demonstrated here for cybersecurity applications, this Ca$^{2+}$-modulated
learning framework offers a generic solution for streaming detection tasks that
require rapid, biologically grounded adaptation to evolving data patterns.

</details>


### [204] [What's in Common? Multimodal Models Hallucinate When Reasoning Across Scenes](https://arxiv.org/abs/2511.03768)
*Candace Ross,Florian Bordes,Adina Williams,Polina Kirichenko,Mark Ibrahim*

Main category: cs.LG

TL;DR: 现有模型在处理真实世界场景时仍存在幻觉问题，尽管它们在现有感知基准上表现良好。为了解决这个问题，我们构建了一个名为 Common-O 的新颖基准，用于评估跨场景推理能力。结果表明，即使是领先的模型，在跨场景推理方面也面临巨大挑战，并且幻觉问题在场景中存在相似物体时更为严重。模型规模和多图像训练可以带来一些改进，但距离解决问题仍有差距。


<details>
  <summary>Details</summary>
Motivation: 现有模型在处理真实世界场景时，尽管在感知基准上表现出色，但仍会出现幻觉问题，这表明在感知和真实世界推理之间存在差距。

Method: 构建了一个名为 Common-O 的新颖基准，包含超过 10.5k 的示例，使用未在网络训练数据中出现的新图像，旨在评估跨场景推理能力，通过询问“什么东西是共同的？”来探测推理。

Result: 大多数模型可以识别单张图像中的物体，但跨场景推理非常困难，即使是领先的模型也只在 Common-O 上达到 35% 的准确率，在更复杂的 Common-O Complex 上更是只有 1%。模型在存在相似物体时更容易产生幻觉。模型规模可以带来适度改进，而经过多图像训练的模型表现更好。

Conclusion: 跨场景推理是多模态语言模型面临的重大挑战，现有模型在处理真实世界场景时仍存在幻觉问题。虽然模型规模和多图像训练可以带来一些改进，但距离解决问题仍有差距。建议未来的研究应关注解决跨场景推理中的幻觉问题，并公开了 Common-O 基准以促进相关研究。

Abstract: Multimodal language models possess a remarkable ability to handle an
open-vocabulary's worth of objects. Yet the best models still suffer from
hallucinations when reasoning about scenes in the real world, revealing a gap
between their seemingly strong performance on existing perception benchmarks
that are saturating and their reasoning in the real world. To address this gap,
we build a novel benchmark of in-the-wild scenes that we call Common-O. With
more than 10.5k examples using exclusively new images not found in web training
data to avoid contamination, Common-O goes beyond just perception, inspired by
cognitive tests for humans, to probe reasoning across scenes by asking "what's
in common?". We evaluate leading multimodal language models, including models
specifically trained to perform chain-of-thought reasoning. We find that
perceiving objects in single images is tractable for most models, yet reasoning
across scenes is very challenging even for the best models, including reasoning
models. Despite saturating many leaderboards focusing on perception, the best
performing model only achieves 35% on Common-O -- and on Common-O Complex,
consisting of more complex scenes, the best model achieves only 1%. Curiously,
we find models are more prone to hallucinate when similar objects are present
in the scene, suggesting models may be relying on object co-occurrence seen
during training. Among the models we evaluated, we found scale can provide
modest improvements while models explicitly trained with multi-image inputs
show bigger improvements, suggesting scaled multi-image training may offer
promise. We make our benchmark publicly available to spur research into the
challenge of hallucination when reasoning across scenes.

</details>


### [205] [Enhancing Multimodal Protein Function Prediction Through Dual-Branch Dynamic Selection with Reconstructive Pre-Training](https://arxiv.org/abs/2511.04040)
*Xiaoling Luo,Peng Chen,Chengliang Liu,Xiaopeng Jin,Jie Wen,Yumeng Liu,Junsong Wang*

Main category: cs.LG

TL;DR: DSRPGO通过动态选择和重建预训练机制进行多模态蛋白质功能预测，在BPO、MFO和CCO方面表现优于基准模型。


<details>
  <summary>Details</summary>
Motivation: 多模态蛋白质特征对于蛋白质功能预测至关重要，但其复杂的相互联系难以解析。

Method: 提出一种利用动态选择和重建预训练机制的多模态蛋白质功能预测方法（DSRPGO）。引入重建预训练来挖掘更细粒度的低语义信息。提出双向交互模块（BInM）促进多模态特征间的交互学习。设计动态选择模块（DSM）来选择最有利于当前蛋白质功能预测的特征表示，以应对分层多标签分类的挑战。

Result: DSRPGO模型在人数据集的BPO、MFO和CCO方面取得了显著改进，超越了其他基准模型。

Conclusion: DSRPGO模型在多模态蛋白质功能预测任务上表现出色，尤其是在处理复杂特征和分层多标签分类方面。

Abstract: Multimodal protein features play a crucial role in protein function
prediction. However, these features encompass a wide range of information,
ranging from structural data and sequence features to protein attributes and
interaction networks, making it challenging to decipher their complex
interconnections. In this work, we propose a multimodal protein function
prediction method (DSRPGO) by utilizing dynamic selection and reconstructive
pre-training mechanisms. To acquire complex protein information, we introduce
reconstructive pre-training to mine more fine-grained information with low
semantic levels. Moreover, we put forward the Bidirectional Interaction Module
(BInM) to facilitate interactive learning among multimodal features.
Additionally, to address the difficulty of hierarchical multi-label
classification in this task, a Dynamic Selection Module (DSM) is designed to
select the feature representation that is most conducive to current protein
function prediction. Our proposed DSRPGO model improves significantly in BPO,
MFO, and CCO on human datasets, thereby outperforming other benchmark models.

</details>


### [206] [Contamination Detection for VLMs using Multi-Modal Semantic Perturbation](https://arxiv.org/abs/2511.03774)
*Jaden Park,Mu Cai,Feng Yao,Jingbo Shang,Soochahn Lee,Yong Jae Lee*

Main category: cs.LG

TL;DR: 该研究提出了一种检测受污染的视觉语言模型（VLM）的新方法，通过引入多模态语义扰动来识别因训练数据泄露而性能膨胀的模型。


<details>
  <summary>Details</summary>
Motivation: 现有方法未能有效检测因训练数据泄露而性能膨胀的视觉语言模型（VLM），需要新的检测方法。

Method: 通过在公开的VLM上进行污染实验，评估现有检测方法的局限性，并提出一种基于多模态语义扰动的新检测方法，测试模型在受控扰动下的泛化能力。

Result: 现有的检测方法效果不佳或行为不一致。提出的新方法能够有效检测受污染的VLM，证明了其鲁棒性和有效性。

Conclusion: 提出的基于多模态语义扰动的方法能够有效检测受污染的VLM，解决了现有方法的不足。

Abstract: Recent advances in Vision-Language Models (VLMs) have achieved
state-of-the-art performance on numerous benchmark tasks. However, the use of
internet-scale, often proprietary, pretraining corpora raises a critical
concern for both practitioners and users: inflated performance due to test-set
leakage. While prior works have proposed mitigation strategies such as
decontamination of pretraining data and benchmark redesign for LLMs, the
complementary direction of developing detection methods for contaminated VLMs
remains underexplored. To address this gap, we deliberately contaminate
open-source VLMs on popular benchmarks and show that existing detection
approaches either fail outright or exhibit inconsistent behavior. We then
propose a novel simple yet effective detection method based on multi-modal
semantic perturbation, demonstrating that contaminated models fail to
generalize under controlled perturbations. Finally, we validate our approach
across multiple realistic contamination strategies, confirming its robustness
and effectiveness. The code and perturbed dataset will be released publicly.

</details>


### [207] [FusionDP: Foundation Model-Assisted Differentially Private Learning for Partially Sensitive Features](https://arxiv.org/abs/2511.03806)
*Linghui Zeng,Ruixuan Liu,Atiquer Rahman Sarkar,Xiaoqian Jiang,Joyce C. Ho,Li Xiong*

Main category: cs.LG

TL;DR: FusionDP通过利用大型基础模型进行敏感特征填补，并结合修改后的DP-SGD算法，在保持特征级差分隐私的同时，显著提高了模型在ICU数据和临床笔记分类任务上的效用。


<details>
  <summary>Details</summary>
Motivation: 在隐私保护机器学习中，确保敏感训练数据的隐私至关重要。然而，在实际场景中，可能只需要对部分特征进行隐私保护。例如，在ICU数据中，年龄和性别等人口统计学特征由于其重新识别的可能性而具有较高的隐私风险，而原始的实验室结果通常不那么敏感。传统的DP-SGD在单个样本的所有特征上强制执行隐私保护，会导致过度的噪声注入和显著的效用下降。

Method: FusionDP是一个两步框架，用于在特征级差分隐私下提高模型效用。首先，FusionDP利用大型基础模型，根据非敏感特征推断敏感特征，将它们视为外部先验，在模型训练期间无需访问真实值即可提供高质量的敏感属性估计。其次，引入了一种修改后的DP-SGD算法，该算法在原始和推断的特征上训练模型，同时正式保护原始敏感特征的隐私。

Result: 在PhysioNet的表格数据上的脓毒症预测任务和MIMIC-III的临床笔记分类任务这两种模式下评估了FusionDP。与隐私保护基线相比，结果表明FusionDP在保持严格的特征级隐私的同时，显著提高了模型性能。

Conclusion: FusionDP通过利用大型基础模型进行敏感特征推断，并结合修改后的DP-SGD算法，在保持特征级差分隐私的同时，显著提高了模型在ICU数据和临床笔记分类任务上的效用，展示了基础模型驱动的推断在改善各种模式的隐私-效用权衡方面的潜力。

Abstract: Ensuring the privacy of sensitive training data is crucial in
privacy-preserving machine learning. However, in practical scenarios, privacy
protection may be required for only a subset of features. For instance, in ICU
data, demographic attributes like age and gender pose higher privacy risks due
to their re-identification potential, whereas raw lab results are generally
less sensitive. Traditional DP-SGD enforces privacy protection on all features
in one sample, leading to excessive noise injection and significant utility
degradation. We propose FusionDP, a two-step framework that enhances model
utility under feature-level differential privacy. First, FusionDP leverages
large foundation models to impute sensitive features given non-sensitive
features, treating them as external priors that provide high-quality estimates
of sensitive attributes without accessing the true values during model
training. Second, we introduce a modified DP-SGD algorithm that trains models
on both original and imputed features while formally preserving the privacy of
the original sensitive features. We evaluate FusionDP on two modalities: a
sepsis prediction task on tabular data from PhysioNet and a clinical note
classification task from MIMIC-III. By comparing against privacy-preserving
baselines, our results show that FusionDP significantly improves model
performance while maintaining rigorous feature-level privacy, demonstrating the
potential of foundation model-driven imputation to enhance the privacy-utility
trade-off for various modalities.

</details>


### [208] [Fair and Explainable Credit-Scoring under Concept Drift: Adaptive Explanation Frameworks for Evolving Populations](https://arxiv.org/abs/2511.03807)
*Shivogo John*

Main category: cs.LG

TL;DR: 本研究提出自适应可解释性框架，以解决概念漂移对信用评分模型可解释性和公平性的影响。


<details>
  <summary>Details</summary>
Motivation: 传统的SHAP等可解释性技术假设数据分布固定，在概念漂移发生时会导致解释不稳定甚至不公平。本研究旨在开发自适应解释框架，以动态调整信用模型的可解释性和公平性。

Method: 研究人员整合了XGBoost预测模型和三种自适应SHAP变体：(A) 按切片重加权解释以适应特征分布变化，(B) 使用滑动窗口背景样本进行漂移感知SHAP重基线化，(C) 使用增量岭回归进行在线代理校准。

Result: 与静态SHAP解释相比，自适应方法（特别是重基线化和基于代理的方法）在不损害预测准确性的情况下，显著提高了时间稳定性和跨人口群体的公平性。稳健性测试也证实了自适应解释在真实世界漂移条件下的韧性。

Conclusion: 研究结果表明，自适应可解释性是维持数据驱动的信用系统（以及任何随人口变化而演变的决策模型领域）的透明度、问责制和伦理可靠性的实用机制。

Abstract: Evolving borrower behaviors, shifting economic conditions, and changing
regulatory landscapes continuously reshape the data distributions underlying
modern credit-scoring systems. Conventional explainability techniques, such as
SHAP, assume static data and fixed background distributions, making their
explanations unstable and potentially unfair when concept drift occurs. This
study addresses that challenge by developing adaptive explanation frameworks
that recalibrate interpretability and fairness in dynamically evolving credit
models. Using a multi-year credit dataset, we integrate predictive modeling via
XGBoost with three adaptive SHAP variants: (A) per-slice explanation
reweighting that adjusts for feature distribution shifts, (B) drift-aware SHAP
rebaselining with sliding-window background samples, and (C) online surrogate
calibration using incremental Ridge regression. Each method is benchmarked
against static SHAP explanations using metrics of predictive performance (AUC,
F1), directional and rank stability (cosine, Kendall tau), and fairness
(demographic parity and recalibration). Results show that adaptive methods,
particularly rebaselined and surrogate-based explanations, substantially
improve temporal stability and reduce disparate impact across demographic
groups without degrading predictive accuracy. Robustness tests, including
counterfactual perturbations, background sensitivity analysis, and
proxy-variable detection, confirm the resilience of adaptive explanations under
real-world drift conditions. These findings establish adaptive explainability
as a practical mechanism for sustaining transparency, accountability, and
ethical reliability in data-driven credit systems, and more broadly, in any
domain where decision models evolve with population change.

</details>


### [209] [Optimizing Reasoning Efficiency through Prompt Difficulty Prediction](https://arxiv.org/abs/2511.03808)
*Bo Zhao,Berkcan Kapusuzoglu,Kartik Balasubramaniam,Sambit Sahu,Supriyo Chakraborty,Genta Indra Winata*

Main category: cs.LG

TL;DR: 通过路由方法为每个问题分配最合适的模型来降低大型语言模型的部署成本，同时保持准确性。


<details>
  <summary>Details</summary>
Motivation: 现有的大型语言模型在处理复杂任务时表现出色，但其巨大的模型尺寸和冗长的推理过程导致部署成本高昂。

Method: 提出一种路由方法，利用中间表示训练预测器来评估问题难度或模型正确性，从而将问题分配给最有可能解决它的最小模型。

Result: 在多个数学基准测试中，该路由方法在提高效率方面优于随机分配，并且在显著降低计算量的同时，其性能与s1.1-32B相当。

Conclusion: 面向难度感知的路由方法能够有效地降低推理模型的部署成本。

Abstract: Reasoning language models perform well on complex tasks but are costly to
deploy due to their size and long reasoning traces. We propose a routing
approach that assigns each problem to the smallest model likely to solve it,
reducing compute without sacrificing accuracy. Using intermediate
representations from s1.1-32B, we train lightweight predictors of problem
difficulty or model correctness to guide routing across a pool of reasoning
models. On diverse math benchmarks, routing improves efficiency over random
assignment and matches s1.1-32B's performance while using significantly less
compute. Our results demonstrate that difficulty-aware routing is effective for
cost-efficient deployment of reasoning models.

</details>


### [210] [One Size Does Not Fit All: Architecture-Aware Adaptive Batch Scheduling with DEBA](https://arxiv.org/abs/2511.03809)
*François Belias,Naser Ezzati-Jivan,Foutse Khomh*

Main category: cs.LG

TL;DR: DEBA是一种动态自适应批次大小调度器，通过监控梯度方差、梯度范数变化和损失变化来指导批次大小的调整，从而加速神经网络训练。与现有方法不同，DEBA认识到批次大小调整的有效性因网络架构而异，并提出了一个基于梯度稳定性指标的基线特征框架来预测哪些架构将受益于自适应调度。


<details>
  <summary>Details</summary>
Motivation: 现有自适应批次大小方法在所有架构上采用相同的调整策略，但这种“一刀切”的方法并未考虑到不同网络架构的特性。本文旨在开发一种能够根据不同架构动态调整批次大小的方法，以加速训练并提高准确性。

Method: DEBA（Dynamic Efficient Batch Adaptation）通过监控梯度方差、梯度范数变化和损失变化来指导批次大小的调整。研究人员在六种不同的网络架构（ResNet-18/50、DenseNet-121、EfficientNet-B0、MobileNet-V3、ViT-B16）和两个数据集（CIFAR-10和CIFAR-100）上进行了系统性评估，并使用了五种不同的随机种子。此外，还引入了一个基于梯度稳定性指标（稳定性得分、梯度范数变化）的基线特征框架，用于预测哪些架构可以从自适应调度中受益。消融研究也用于确定关键的设计选择，例如滑动窗口统计和足够的冷冻期。

Result: 研究结果表明，批次大小调整的有效性很大程度上取决于网络架构。轻量级和中等深度架构（MobileNet-V3、DenseNet-121、EfficientNet-B0）实现了45-62%的训练加速，同时准确性提高了1-7%。浅层残差网络（ResNet-18）的准确性提高了2.4-4.0%，速度提高了36-43%。然而，深层残差网络（ResNet-50）表现出高方差，有时甚至准确性下降。对于优化已经很稳定的架构（ViT-B16），DEBA仅实现了6%的加速，准确性保持不变。消融研究表明，使用滑动窗口统计和在调整之间设置至少5个epoch的冷冻期对于DEBA的成功至关重要。

Conclusion: DEBA证明了自适应批次大小调整策略需要根据不同的网络架构进行定制，而不是采用通用的方法。研究结果强调了架构感知设计在自适应批次大小调整中的重要性，并为未来在这方面的研究提供了指导。

Abstract: Adaptive batch size methods aim to accelerate neural network training, but
existing approaches apply identical adaptation strategies across all
architectures, assuming a one-size-fits-all solution. We introduce DEBA
(Dynamic Efficient Batch Adaptation), an adaptive batch scheduler that monitors
gradient variance, gradient norm variation and loss variation to guide batch
size adaptations. Through systematic evaluation across six architectures
(ResNet-18/50, DenseNet-121, EfficientNet-B0, MobileNet-V3, ViT-B16) on
CIFAR-10 and CIFAR-100, with five random seeds per configuration, we
demonstrate that the architecture fundamentally determines adaptation efficacy.
Our findings reveal that: (1) lightweight and medium-depth architectures
(MobileNet-V3, DenseNet-121, EfficientNet-B0) achieve a 45-62% training speedup
with simultaneous accuracy improvements of 1-7%; (2) shallow residual networks
(ResNet-18) show consistent gains of +2.4 - 4.0% in accuracy, 36 - 43% in
speedup, while deep residual networks (ResNet-50) exhibit high variance and
occasional degradation; (3) already-stable architectures (ViT-B16) show minimal
speedup (6%) despite maintaining accuracy, indicating that adaptation benefits
vary with baseline optimization characteristics. We introduce a baseline
characterization framework using gradient stability metrics (stability score,
gradient norm variation) that predicts which architectures will benefit from
adaptive scheduling. Our ablation studies reveal critical design choices often
overlooked in prior work: sliding window statistics (vs. full history) and
sufficient cooldown periods (5+ epochs) between adaptations are essential for
success. This work challenges the prevailing assumption that adaptive methods
generalize across architectures and provides the first systematic evidence that
batch size adaptation requires an architecture-aware design.

</details>


### [211] [Regret Lower Bounds for Decentralized Multi-Agent Stochastic Shortest Path Problems](https://arxiv.org/abs/2511.04594)
*Utkarsh U. Chavan,Prashant Trivedi,Nandyala Hemachandra*

Main category: cs.LG

TL;DR: MAS在需要去中心化协调的应用中很重要，但去中心化多智能体随机最短路径（Dec-MASSP）问题的学习仍然是一个挑战。本研究首次提出了Dec-MASSP的遗憾下界，并揭示了其固有的学习难度。


<details>
  <summary>Details</summary>
Motivation: 去中心化多智能体随机最短路径（Dec-MASSP）问题的学习在单智能体环境中虽有广泛研究，但在多智能体环境中却鲜有探索，本研究旨在解决这一差距。

Method: 研究了具有线性函数逼近的Dec-MASSP问题，利用新颖的基于对称性的论证来识别最优策略的结构，并构建了学习实例的困难度。

Result: 得出了针对任意数量智能体n的遗憾下界为$\\\Omega(\\){\\){\\)sqrt(K)}(\\)），其中K为学习的轮数。

Conclusion: 本研究提出的遗憾下界为Dec-MASSP问题提供了关于学习复杂性的见解，并为设计高效的多智能体学习算法提供了指导。

Abstract: Multi-agent systems (MAS) are central to applications such as swarm robotics
and traffic routing, where agents must coordinate in a decentralized manner to
achieve a common objective. Stochastic Shortest Path (SSP) problems provide a
natural framework for modeling decentralized control in such settings. While
the problem of learning in SSP has been extensively studied in single-agent
settings, the decentralized multi-agent variant remains largely unexplored. In
this work, we take a step towards addressing that gap. We study decentralized
multi-agent SSPs (Dec-MASSPs) under linear function approximation, where the
transition dynamics and costs are represented using linear models. Applying
novel symmetry-based arguments, we identify the structure of optimal policies.
Our main contribution is the first regret lower bound for this setting based on
the construction of hard-to-learn instances for any number of agents, $n$. Our
regret lower bound of $\Omega(\sqrt{K})$, over $K$ episodes, highlights the
inherent learning difficulty in Dec-MASSPs. These insights clarify the learning
complexity of decentralized control and can further guide the design of
efficient learning algorithms in multi-agent systems.

</details>


### [212] [Sketch-Augmented Features Improve Learning Long-Range Dependencies in Graph Neural Networks](https://arxiv.org/abs/2511.03824)
*Ryien Hosseini,Filippo Simini,Venkatram Vishwanath,Rebecca Willett,Henry Hoffmann*

Main category: cs.LG

TL;DR: 通过引入随机全局嵌入（Sketched Random Features）来增强图神经网络（GNNs）处理长距离依赖、过平滑和表达能力受限的问题，并在真实数据集上验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 图神经网络（GNNs）在处理图结构数据时，虽然利用局部信息聚合，但也面临长距离信息压缩、节点表示过平滑以及表达能力有限等挑战。

Method: 提出并引入了一种名为“Sketched Random Features”的随机全局嵌入，并将其融入标准的GNNs中，以有效捕捉长距离依赖关系。该嵌入具有独特性、对距离敏感且与拓扑无关的特性。

Result: 实验结果表明，在真实世界的图学习任务中，这种策略相比基线GNNs能够持续提升性能，既可以作为独立解决方案，也可以作为图位置编码等现有技术的补充。

Conclusion: 引入Sketched Random Features能够有效缓解GNNs在处理长距离依赖、过平滑和表达能力方面的问题，并提升其在各种图学习任务上的性能。

Abstract: Graph Neural Networks learn on graph-structured data by iteratively
aggregating local neighborhood information. While this local message passing
paradigm imparts a powerful inductive bias and exploits graph sparsity, it also
yields three key challenges: (i) oversquashing of long-range information, (ii)
oversmoothing of node representations, and (iii) limited expressive power. In
this work we inject randomized global embeddings of node features, which we
term \textit{Sketched Random Features}, into standard GNNs, enabling them to
efficiently capture long-range dependencies. The embeddings are unique,
distance-sensitive, and topology-agnostic -- properties which we analytically
and empirically show alleviate the aforementioned limitations when injected
into GNNs. Experimental results on real-world graph learning tasks confirm that
this strategy consistently improves performance over baseline GNNs, offering
both a standalone solution and a complementary enhancement to existing
techniques such as graph positional encodings. Our source code is available at
\href{https://github.com/ryienh/sketched-random-features}{https://github.com/ryienh/sketched-random-features}.

</details>


### [213] [From Static to Dynamic: Enhancing Offline-to-Online Reinforcement Learning via Energy-Guided Diffusion Stratification](https://arxiv.org/abs/2511.03828)
*Lipeng Zu,Hansong Zhou,Xiaonan Zhang*

Main category: cs.LG

TL;DR: 该研究提出了一种名为StratDiff的新方法，用于解决离线到在线强化学习中的分布偏移问题。StratDiff利用扩散模型和能量函数从离线数据中学习先验知识，并通过计算KL散度将训练批次划分为“离线类”和“在线类”样本，分别采用不同的学习策略进行更新，从而实现更平滑的策略迁移和更稳定的性能。


<details>
  <summary>Details</summary>
Motivation: 离线到在线强化学习（RL）在从固定的行为策略数据集过渡到在线学习策略时，面临着由分布偏移引起的核心挑战。然而，现有方法很少能显式地评估或利用离线数据本身的分布结构，这导致在根据不同样本类型调整学习策略方面存在研究空白。

Method: StratDiff方法首先部署一个扩散模型来学习离线数据集的先验知识，然后通过能量函数来优化这些知识，以改进策略模仿并在在线微调过程中生成类似离线数据的动作。接着，计算生成动作与相应采样动作之间的KL散度，用于将训练批次划分为“离线类”和“在线类”子集。对于“离线类”样本，采用离线目标进行更新；对于“在线类”样本，则遵循在线学习策略。

Result: 通过将StratDiff与现有的Cal-QL和IQL方法相结合，并在D4RL基准上进行广泛的实证评估，结果表明StratDiff显著优于现有方法，在各种RL设置中展现出增强的适应性和更稳定的性能。

Conclusion: StratDiff通过一种新颖的基于扩散和能量模型的方法，有效地解决了离线到在线强化学习中的分布偏移问题，通过样本分层和差异化学习策略，实现了更优的性能和稳定性。

Abstract: Transitioning from offline to online reinforcement learning (RL) poses
critical challenges due to distributional shifts between the fixed behavior
policy in the offline dataset and the evolving policy during online learning.
Although this issue is widely recognized, few methods attempt to explicitly
assess or utilize the distributional structure of the offline data itself,
leaving a research gap in adapting learning strategies to different types of
samples. To address this challenge, we propose an innovative method,
Energy-Guided Diffusion Stratification (StratDiff), which facilitates smoother
transitions in offline-to-online RL. StratDiff deploys a diffusion model to
learn prior knowledge from the offline dataset. It then refines this knowledge
through energy-based functions to improve policy imitation and generate
offline-like actions during online fine-tuning. The KL divergence between the
generated action and the corresponding sampled action is computed for each
sample and used to stratify the training batch into offline-like and
online-like subsets. Offline-like samples are updated using offline objectives,
while online-like samples follow online learning strategies. We demonstrate the
effectiveness of StratDiff by integrating it with off-the-shelf methods Cal-QL
and IQL. Extensive empirical evaluations on D4RL benchmarks show that StratDiff
significantly outperforms existing methods, achieving enhanced adaptability and
more stable performance across diverse RL settings.

</details>


### [214] [Higher-Order Causal Structure Learning with Additive Models](https://arxiv.org/abs/2511.03831)
*James Enouen,Yujia Zheng,Ignavier Ng,Yan Liu,Kun Zhang*

Main category: cs.LG

TL;DR: 本研究将因果发现从传统的因果关系扩展到更高阶的交互作用，引入了因果有向无环超图（DAG）的概念，并提供了处理新结构和识别结果的理论工具，同时通过扩展现有算法在合成实验中证明了其有效性。


<details>
  <summary>Details</summary>
Motivation: 现有的因果结构学习方法主要关注成对的因果关系，但现实世界中许多过程包含更高阶的交互作用，这方面的研究却很少受到关注。

Method: 将因果模型（CAM）扩展到包含更高阶交互作用的加性模型，使用因果有向无环超图（DAG）来表示这种新的结构，并开发了贪婪算法的扩展来处理更复杂的超图搜索空间。

Result: 提出了处理因果有向无环超图（DAG）的理论工具和识别结果，并推导了与马尔可夫等价类相关的概念。研究表明，更强的假设（如CAM）可以简化超图学习，并可能带来更好的有限样本复杂性。

Conclusion: 本研究成功地将因果发现领域扩展到更高阶的交互作用，通过引入因果有向无环超图（DAG）和相应的理论工具，为处理更复杂的因果关系提供了新的视角和方法，并在实验中验证了其有效性。

Abstract: Causal structure learning has long been the central task of inferring causal
insights from data. Despite the abundance of real-world processes exhibiting
higher-order mechanisms, however, an explicit treatment of interactions in
causal discovery has received little attention. In this work, we focus on
extending the causal additive model (CAM) to additive models with higher-order
interactions. This second level of modularity we introduce to the structure
learning problem is most easily represented by a directed acyclic hypergraph
which extends the DAG. We introduce the necessary definitions and theoretical
tools to handle the novel structure we introduce and then provide
identifiability results for the hyper DAG, extending the typical Markov
equivalence classes. We next provide insights into why learning the more
complex hypergraph structure may actually lead to better empirical results. In
particular, more restrictive assumptions like CAM correspond to easier-to-learn
hyper DAGs and better finite sample complexity. We finally develop an extension
of the greedy CAM algorithm which can handle the more complex hyper DAG search
space and demonstrate its empirical usefulness in synthetic experiments.

</details>


### [215] [Enhancing Q-Value Updates in Deep Q-Learning via Successor-State Prediction](https://arxiv.org/abs/2511.03836)
*Lipeng Zu,Hansong Zhou,Xiaonan Zhang*

Main category: cs.LG

TL;DR: SADQ通过学习环境动态和后继状态分布来改进DQN，以实现更稳定、更高效的强化学习。


<details>
  <summary>Details</summary>
Motivation: DQN的目标更新依赖于过去次优策略产生的状态，这会导致高方差和学习信号不足。当采样转移与当前策略不一致时，问题会更加严重。

Method: SADQ通过建立随机转移模型来显式地学习环境动态，并将后继状态分布整合到Q值估计中，同时采用更高效的动作选择策略。

Result: SADQ在标准强化学习基准和现实世界的矢量控制任务上，相比DQN变体在稳定性和学习效率上都表现更好。

Conclusion: SADQ通过整合后继状态分布和环境动态模型，实现了无偏估计和更低的训练方差，从而提高了强化学习的稳定性和效率。

Abstract: Deep Q-Networks (DQNs) estimate future returns by learning from transitions
sampled from a replay buffer. However, the target updates in DQN often rely on
next states generated by actions from past, potentially suboptimal, policy. As
a result, these states may not provide informative learning signals, causing
high variance into the update process. This issue is exacerbated when the
sampled transitions are poorly aligned with the agent's current policy. To
address this limitation, we propose the Successor-state Aggregation Deep
Q-Network (SADQ), which explicitly models environment dynamics using a
stochastic transition model. SADQ integrates successor-state distributions into
the Q-value estimation process, enabling more stable and policy-aligned value
updates. Additionally, it explores a more efficient action selection strategy
with the modeled transition structure. We provide theoretical guarantees that
SADQ maintains unbiased value estimates while reducing training variance. Our
extensive empirical results across standard RL benchmarks and real-world
vector-based control tasks demonstrate that SADQ consistently outperforms DQN
variants in both stability and learning efficiency.

</details>


### [216] [Benchmark Datasets for Lead-Lag Forecasting on Social Platforms](https://arxiv.org/abs/2511.03877)
*Kimia Kazemian,Zhenzhen Liu,Yangfanyu Yang,Katie Z Luo,Shuhan Gu,Audrey Du,Xinyu Yang,Jack Jansons,Kilian Q Weinberger,John Thickstun,Yian Yin,Sarah Dean*

Main category: cs.LG

TL;DR: 本研究提出了领先滞后预测（LLF）这一新范式，用于预测社交和协作平台中早期互动（如浏览、点赞）与后期高影响力结果（如引用、销售）之间的关系。研究人员发布了两个大规模基准数据集（arXiv 和 GitHub），以促进 LLF 的研究，并对各种基线模型进行了评估。


<details>
  <summary>Details</summary>
Motivation: 现有时间序列研究未能充分解决早期用户行为与后期高影响力结果之间的长期预测问题，缺乏标准化数据集阻碍了该领域的研究。本研究旨在通过提出领先滞后预测（LLF）新范式并提供标准化数据集来解决这一问题。

Method: 构建了两个大规模数据集（arXiv 和 GitHub），包含了早期互动和后期影响力的信息，涵盖了多年的数据。通过统计和分类测试验证了领先滞后动态的存在性，并对参数和非参数回归基线模型进行了基准测试。

Result: 成功构建了包含 arXiv 和 GitHub 数据的两个大规模基准数据集，并验证了其中存在的领先滞后动态。对多种基线模型的性能进行了评估，为后续研究奠定了基础。

Conclusion: 领先滞后预测（LLF）被确立为一个新的时间序列预测范式，尤其适用于分析社交和协作平台中的数据。本研究提供的数据集和基线评估为该领域的进一步系统性探索奠定了实证基础。

Abstract: Social and collaborative platforms emit multivariate time-series traces in
which early interactions-such as views, likes, or downloads-are followed,
sometimes months or years later, by higher impact like citations, sales, or
reviews. We formalize this setting as Lead-Lag Forecasting (LLF): given an
early usage channel (the lead), predict a correlated but temporally shifted
outcome channel (the lag). Despite the ubiquity of such patterns, LLF has not
been treated as a unified forecasting problem within the time-series community,
largely due to the absence of standardized datasets. To anchor research in LLF,
here we present two high-volume benchmark datasets-arXiv (accesses -> citations
of 2.3M papers) and GitHub (pushes/stars -> forks of 3M repositories)-and
outline additional domains with analogous lead-lag dynamics, including
Wikipedia (page views -> edits), Spotify (streams -> concert attendance),
e-commerce (click-throughs -> purchases), and LinkedIn profile (views ->
messages). Our datasets provide ideal testbeds for lead-lag forecasting, by
capturing long-horizon dynamics across years, spanning the full spectrum of
outcomes, and avoiding survivorship bias in sampling. We documented all
technical details of data curation and cleaning, verified the presence of
lead-lag dynamics through statistical and classification tests, and benchmarked
parametric and non-parametric baselines for regression. Our study establishes
LLF as a novel forecasting paradigm and lays an empirical foundation for its
systematic exploration in social and usage data. Our data portal with downloads
and documentation is available at https://lead-lag-forecasting.github.io/.

</details>


### [217] [Conditional Score Learning for Quickest Change Detection in Markov Transition Kernels](https://arxiv.org/abs/2511.03953)
*Wuxia Chen,Taposh Banerjee,Vahid Tarokh*

Main category: cs.LG

TL;DR: 本研究提出一种基于评分函数变化的马尔可夫过程最快变化检测方法，能够直接从样本对中学习转移动力学，并证明了理论和实践的保证。


<details>
  <summary>Details</summary>
Motivation: 在马尔可夫过程的转移核未知的情况下，最快地检测变化。

Method: 直接从样本对 $(\mathbf{x},\mathbf{y})$ 学习条件评分 $\nabla_{\mathbf{y}} \log p(\mathbf{y}|\mathbf{x})$，并基于此开发了一种基于评分的 CUSUM 程序，使用条件 Hyvarinen 评分差异来检测转移核中的变化。为了确保递增有界，提出了一种该统计量的截断版本。

Result: 证明了在均匀遍历马尔可夫过程上，平均虚警时间的指数下界，以及检测延迟的渐近上界。

Conclusion: 所提出的基于评分的检测方法在理论上具有保证，并且在实践中是可行的，适用于高维马尔可夫模型。

Abstract: We address the problem of quickest change detection in Markov processes with
unknown transition kernels. The key idea is to learn the conditional score
$\nabla_{\mathbf{y}} \log p(\mathbf{y}|\mathbf{x})$ directly from sample pairs
$( \mathbf{x},\mathbf{y})$, where both $\mathbf{x}$ and $\mathbf{y}$ are
high-dimensional data generated by the same transition kernel. In this way, we
avoid explicit likelihood evaluation and provide a practical way to learn the
transition dynamics. Based on this estimation, we develop a score-based CUSUM
procedure that uses conditional Hyvarinen score differences to detect changes
in the kernel. To ensure bounded increments, we propose a truncated version of
the statistic. With Hoeffding's inequality for uniformly ergodic Markov
processes, we prove exponential lower bounds on the mean time to false alarm.
We also prove asymptotic upper bounds on detection delay. These results give
both theoretical guarantees and practical feasibility for score-based detection
in high-dimensional Markov models.

</details>


### [218] [DecoHD: Decomposed Hyperdimensional Classification under Extreme Memory Budgets](https://arxiv.org/abs/2511.03911)
*Sanggeon Yun,Hyunwoo Oh,Ryozo Masukawa,Mohsen Imani*

Main category: cs.LG

TL;DR: DecoHD 通过学习分解后的超维度计算（HDC）参数化来压缩 HDC 模型，实现了显著的内存节省和能耗/速度提升，同时保持了准确性和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有的 HDC 模型压缩方法通常会牺牲精度和鲁棒性，并且不适用于压缩学习到的类别原型。

Method: DecoHD 学习分解后的 HDC 参数化，使用小型、共享的每层通道，通过乘法绑定跨层，并在最后进行捆绑，从而从紧凑的因子中获得大的表示空间。它通过轻量级的捆绑头沿着类别轴进行压缩，同时保留了原生的绑定-捆绑-评分机制。

Result: DecoHD 在内存节省方面表现出色，准确率仅有微小下降。与未压缩的 HDC 基线相比，准确率平均仅下降 0.1-0.15%（最差情况 5.7%）。它还提高了对随机比特翻转噪声的鲁棒性，并显著减少了可训练参数数量。在硬件方面，与 CPU 和 GPU 相比，DecoHD 实现了巨大的能耗和速度提升，并且优于基线 HDC ASIC。

Conclusion: DecoHD 是一种有效的 HDC 模型压缩方法，可以在保持准确性和鲁棒性的同时，实现显著的内存、能耗和速度优势。

Abstract: Decomposition is a proven way to shrink deep networks without changing I/O.
We bring this idea to hyperdimensional computing (HDC), where footprint cuts
usually shrink the feature axis and erode concentration and robustness. Prior
HDC decompositions decode via fixed atomic hypervectors, which are ill-suited
for compressing learned class prototypes. We introduce DecoHD, which learns
directly in a decomposed HDC parameterization: a small, shared set of per-layer
channels with multiplicative binding across layers and bundling at the end,
yielding a large representational space from compact factors. DecoHD compresses
along the class axis via a lightweight bundling head while preserving native
bind-bundle-score; training is end-to-end, and inference remains pure HDC,
aligning with in/near-memory accelerators. In evaluation, DecoHD attains
extreme memory savings with only minor accuracy degradation under tight
deployment budgets. On average it stays within about 0.1-0.15% of a strong
non-reduced HDC baseline (worst case 5.7%), is more robust to random bit-flip
noise, reaches its accuracy plateau with up to ~97% fewer trainable parameters,
and -- in hardware -- delivers roughly 277x/35x energy/speed gains over a CPU
(AMD Ryzen 9 9950X), 13.5x/3.7x over a GPU (NVIDIA RTX 4090), and 2.0x/2.4x
over a baseline HDC ASIC.

</details>


### [219] [On Predicting Sociodemographics from Mobility Signals](https://arxiv.org/abs/2511.03924)
*Ekin Uğurel,Cynthia Chen,Brian H. Y. Lee,Filipe Rodrigues*

Main category: cs.LG

TL;DR: 通过引入基于行为的移动图描述符、不确定性度量和多任务学习框架，改进了从移动数据推断社会人口属性的准确性、可解释性和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 解决从移动数据推断社会人口属性时存在的预测不准确、可解释性差以及跨上下文泛化能力有限的问题。

Method: 1. 引入基于定向移动图的行为学高级移动描述符，以提高预测准确性和可解释性。 2. 提出评估模型置信度和准确性之间均衡性的度量和可视化诊断工具，以量化不确定性。 3. 开发多任务学习框架，通过共享表征联合预测多个社会人口属性，以提高泛化能力和样本效率。

Result: 行为学高级移动描述符显著提高了对年龄、性别、收入和家庭结构的预测能力。多任务学习框架在训练数据有限或跨时间段应用模型时，优于单任务模型。

Conclusion: 所提出的方法在准确性、可解释性和泛化能力方面均优于现有方法，为交通规划者提供了更有效的工具来利用移动数据。

Abstract: Inferring sociodemographic attributes from mobility data could help
transportation planners better leverage passively collected datasets, but this
task remains difficult due to weak and inconsistent relationships between
mobility patterns and sociodemographic traits, as well as limited
generalization across contexts. We address these challenges from three angles.
First, to improve predictive accuracy while retaining interpretability, we
introduce a behaviorally grounded set of higher-order mobility descriptors
based on directed mobility graphs. These features capture structured patterns
in trip sequences, travel modes, and social co-travel, and significantly
improve prediction of age, gender, income, and household structure over
baselines features. Second, we introduce metrics and visual diagnostic tools
that encourage evenness between model confidence and accuracy, enabling
planners to quantify uncertainty. Third, to improve generalization and sample
efficiency, we develop a multitask learning framework that jointly predicts
multiple sociodemographic attributes from a shared representation. This
approach outperforms single-task models, particularly when training data are
limited or when applying models across different time periods (i.e., when the
test set distribution differs from the training set).

</details>


### [220] [SynQuE: Estimating Synthetic Dataset Quality Without Annotations](https://arxiv.org/abs/2511.03928)
*Arthur Chen,Victor Zhong*

Main category: cs.LG

TL;DR: 该研究提出了合成数据集质量估计（SynQuE）问题，旨在仅用有限的未标注真实数据来对合成数据集按预期的真实世界任务性能进行排序。


<details>
  <summary>Details</summary>
Motivation: 在数据收集成本高昂或存在隐私限制导致数据稀缺的情况下，解决合成数据集选择的挑战。

Method: 提出了首个SynQuE问题基准，并评估了用于选择训练数据的代理指标。通过嵌入模型调整了基于分布和多样性的距离度量，并提出了一种利用大型语言模型推理能力的新型代理LENS，以应对复杂规划任务的不足。

Result: SynQuE代理指标在包括情感分析、Text2SQL、网页导航和图像分类在内的各种任务上与真实任务性能相关。LENS在复杂任务上表现优于其他代理，能捕捉细微特性。例如，在Text2SQL任务上，使用SynQuE代理选择的前3个合成数据集，平均准确率可从30.4%提升至38.4%（+8.1%）。

Conclusion: SynQuE为在真实数据稀缺情况下选择合成数据提供了一个实用的框架，并鼓励未来在基于基础模型的数据表征和细粒度数据选择方面的研究。

Abstract: We introduce and formalize the Synthetic Dataset Quality Estimation (SynQuE)
problem: ranking synthetic datasets by their expected real-world task
performance using only limited unannotated real data. This addresses a critical
and open challenge where data is scarce due to collection costs or privacy
constraints. We establish the first comprehensive benchmarks for this problem
by introducing and evaluating proxy metrics that choose synthetic data for
training to maximize task performance on real data. We introduce the first
proxy metrics for SynQuE by adapting distribution and diversity-based distance
measures to our context via embedding models. To address the shortcomings of
these metrics on complex planning tasks, we propose LENS, a novel proxy that
leverages large language model reasoning. Our results show that SynQuE proxies
correlate with real task performance across diverse tasks, including sentiment
analysis, Text2SQL, web navigation, and image classification, with LENS
consistently outperforming others on complex tasks by capturing nuanced
characteristics. For instance, on text-to-SQL parsing, training on the top-3
synthetic datasets selected via SynQuE proxies can raise accuracy from 30.4% to
38.4 (+8.1)% on average compared to selecting data indiscriminately. This work
establishes SynQuE as a practical framework for synthetic data selection under
real-data scarcity and motivates future research on foundation model-based data
characterization and fine-grained data selection.

</details>


### [221] [NVIDIA Nemotron Nano V2 VL](https://arxiv.org/abs/2511.03929)
*NVIDIA,:,Amala Sanjay Deshmukh,Kateryna Chumachenko,Tuomas Rintamaki,Matthieu Le,Tyler Poon,Danial Mohseni Taheri,Ilia Karmanov,Guilin Liu,Jarno Seppanen,Guo Chen,Karan Sapra,Zhiding Yu,Adi Renduchintala,Charles Wang,Peter Jin,Arushi Goel,Mike Ranzinger,Lukas Voegtle,Philipp Fischer,Timo Roman,Wei Ping,Boxin Wang,Zhuolin Yang,Nayeon Lee,Shaokun Zhang,Fuxiao Liu,Zhiqi Li,Di Zhang,Greg Heinrich,Hongxu,Yin,Song Han,Pavlo Molchanov,Parth Mannan,Yao Xu,Jane Polak Scowcroft,Tom Balough,Subhashree Radhakrishnan,Paris Zhang,Sean Cha,Ratnesh Kumar,Zaid Pervaiz Bhat,Jian Zhang,Darragh Hanley,Pritam Biswas,Jesse Oliver,Kevin Vasques,Roger Waleffe,Duncan Riach,Oluwatobi Olabiyi,Ameya Sunil Mahabaleshwarkar,Bilal Kartal,Pritam Gundecha,Khanh Nguyen,Alexandre Milesi,Eugene Khvedchenia,Ran Zilberstein,Ofri Masad,Natan Bagrov,Nave Assaf,Tomer Asida,Daniel Afrimi,Amit Zuker,Netanel Haber,Zhiyu Cheng,Jingyu,Xin,Di,Wu,Nik Spirin,Maryam Moosaei,Roman Ageev,Vanshil Atul Shah,Yuting Wu,Daniel Korzekwa,Unnikrishnan Kizhakkemadam Sreekumar,Wanli Jiang,Padmavathy Subramanian,Alejandra Rico,Sandip Bhaskar,Saeid Motiian,Kedi Wu,Annie Surla,Chia-Chih Chen,Hayden Wolff,Matthew Feinberg,Melissa Corpuz,Marek Wawrzos,Eileen Long,Aastha Jhunjhunwala,Paul Hendricks,Farzan Memarian,Benika Hall,Xin-Yu Wang,David Mosallanezhad,Soumye Singhal,Luis Vega,Katherine Cheung,Krzysztof Pawelec,Michael Evans,Katherine Luna,Jie Lou,Erick Galinkin,Akshay Hazare,Kaustubh Purandare,Ann Guan,Anna Warno,Chen Cui,Yoshi Suhara,Shibani Likhite,Seph Mard,Meredith Price,Laya Sleiman,Saori Kaji,Udi Karpas,Kari Briski,Joey Conway,Michael Lightstone,Jan Kautz,Mohammad Shoeybi,Mostofa Patwary,Jonathen Cohen,Oleksii Kuchaiev,Andrew Tao,Bryan Catanzaro*

Main category: cs.LG

TL;DR: Nemotron Nano V2 VL是Nemotron视觉-语言系列的最新模型，在文档理解、视频理解和推理方面有显著提升，采用了Mamba-Transformer混合模型和创新的token削减技术，并提供多种格式的模型检查点和部分数据集、代码。


<details>
  <summary>Details</summary>
Motivation: Nemotron Nano V2 VL旨在实现强大的现实世界文档理解、长视频理解和推理能力，并改进其前代模型Llama-3.1-Nemotron-Nano-VL-8B。

Method: Nemotron Nano V2 VL基于Nemotron Nano V2（一种混合Mamba-Transformer LLM）构建，并采用了创新的token削减技术，以在长文档和视频场景中实现更高的推理吞吐量。

Result: Nemotron Nano V2 VL在所有视觉和文本领域都比前代模型有了显著的改进。

Conclusion: Nemotron Nano V2 VL在现实世界文档理解、长视频理解和推理方面取得了显著进展，并通过多种格式的模型检查点、数据集、代码的发布，促进了相关领域的研究。

Abstract: We introduce Nemotron Nano V2 VL, the latest model of the Nemotron
vision-language series designed for strong real-world document understanding,
long video comprehension, and reasoning tasks. Nemotron Nano V2 VL delivers
significant improvements over our previous model,
Llama-3.1-Nemotron-Nano-VL-8B, across all vision and text domains through major
enhancements in model architecture, datasets, and training recipes. Nemotron
Nano V2 VL builds on Nemotron Nano V2, a hybrid Mamba-Transformer LLM, and
innovative token reduction techniques to achieve higher inference throughput in
long document and video scenarios. We are releasing model checkpoints in BF16,
FP8, and FP4 formats and sharing large parts of our datasets, recipes and
training code.

</details>


### [222] [LogHD: Robust Compression of Hyperdimensional Classifiers via Logarithmic Class-Axis Reduction](https://arxiv.org/abs/2511.03938)
*Sanggeon Yun,Hyunwoo Oh,Ryozo Masukawa,Pietro Mercati,Nathaniel D. Bastian,Mohsen Imani*

Main category: cs.LG

TL;DR: LogHD通过将每个类别的原型替换为对数数量的捆绑超向量，显著减少了内存占用，同时保持了准确性和鲁棒性，并在ASIC实现中实现了更高的能效和速度。


<details>
  <summary>Details</summary>
Motivation: 标准的“每个类一个原型”的超维度计算（HDC）设计需要大量的内存（O(CD)），并且特征轴压缩虽然能减少内存，但会削弱鲁棒性。需要一种新的方法来减少内存占用，同时保持甚至提高鲁棒性。

Method: LogHD提出了一种对数类轴缩减方法，用n≈⌈logk C⌉个捆绑超向量（字母表大小k）替换C个每个类别的原型。它在一个n维激活空间中进行解码，并通过使用容量感知码本和基于配置文件的解码来进一步优化。LogHD还可以与特征轴稀疏化结合使用。

Result: LogHD在多个数据集上实现了具有竞争力的准确性，内存占用更小。与特征轴压缩相比，在同等内存占用下，LogHD在更高的比特翻转率下仍能维持目标准确性。ASIC实现比CPU和GPU快得多，并且比特征轴HDC ASIC基线更节能、更快。

Conclusion: LogHD是一种有效的内存压缩技术，适用于内存、能量和可靠性受限的系统。它通过对数类轴缩减显著减少了内存占用，同时保持了准确性和鲁棒性，并在ASIC实现中取得了优越的性能。

Abstract: Hyperdimensional computing (HDC) suits memory, energy, and
reliability-constrained systems, yet the standard "one prototype per class"
design requires $O(CD)$ memory (with $C$ classes and dimensionality $D$). Prior
compaction reduces $D$ (feature axis), improving storage/compute but weakening
robustness. We introduce LogHD, a logarithmic class-axis reduction that
replaces the $C$ per-class prototypes with $n\!\approx\!\lceil\log_k C\rceil$
bundle hypervectors (alphabet size $k$) and decodes in an $n$-dimensional
activation space, cutting memory to $O(D\log_k C)$ while preserving $D$. LogHD
uses a capacity-aware codebook and profile-based decoding, and composes with
feature-axis sparsification. Across datasets and injected bit flips, LogHD
attains competitive accuracy with smaller models and higher resilience at
matched memory. Under equal memory, it sustains target accuracy at roughly
$2.5$-$3.0\times$ higher bit-flip rates than feature-axis compression; an ASIC
instantiation delivers $498\times$ energy efficiency and $62.6\times$ speedup
over an AMD Ryzen 9 9950X and $24.3\times$/$6.58\times$ over an NVIDIA RTX
4090, and is $4.06\times$ more energy-efficient and $2.19\times$ faster than a
feature-axis HDC ASIC baseline.

</details>


### [223] [RLHF: A comprehensive Survey for Cultural, Multimodal and Low Latency Alignment Methods](https://arxiv.org/abs/2511.03939)
*Raghav Sharma,Manan Mehta,Sai Tiger Raina*

Main category: cs.LG

TL;DR: RLHF是用于对齐LLM的标准方法，但研究已超越文本，本文综述了多模态对齐、文化公平性和低延迟优化等新领域的研究进展，并讨论了PPO、DPO和GRPO等算法以及最新创新，最后提出了开放性挑战。


<details>
  <summary>Details</summary>
Motivation: RLHF是目前对齐LLM的标准方法，但近期研究已超越传统的基于文本的方法，因此需要对多模态对齐、文化公平性和低延迟优化等新领域的研究进行综述，以弥补关键的研究空白。

Method: 首先回顾了PPO、DPO和GRPO等基础算法，然后对最新的创新进行了详细分析，并对这些技术进行了比较综合。

Result: 本文对多模态对齐、文化公平性和低延迟优化等新领域的研究进展进行了综述，并对相关算法和最新创新进行了分析和比较。

Conclusion: 本文为研究人员构建更健壮、更高效、更公平的AI系统提供了重要的路线图，总结了相关的基础算法和最新创新，并指出了未来开放性挑战。

Abstract: Reinforcement Learning from Human Feedback (RLHF) is the standard for
aligning Large Language Models (LLMs), yet recent progress has moved beyond
canonical text-based methods. This survey synthesizes the new frontier of
alignment research by addressing critical gaps in multi-modal alignment,
cultural fairness, and low-latency optimization. To systematically explore
these domains, we first review foundational algo- rithms, including PPO, DPO,
and GRPO, before presenting a detailed analysis of the latest innovations. By
providing a comparative synthesis of these techniques and outlining open
challenges, this work serves as an essential roadmap for researchers building
more robust, efficient, and equitable AI systems.

</details>


### [224] [PrivacyCD: Hierarchical Unlearning for Protecting Student Privacy in Cognitive Diagnosis](https://arxiv.org/abs/2511.03966)
*Mingliang Hou,Yinuo Wang,Teng Guo,Zitao Liu,Wenzhou Dou,Jiaqi Zheng,Renqiang Luo,Mi Tian,Weiqi Luo*

Main category: cs.LG

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: The need to remove specific student data from cognitive diagnosis (CD) models
has become a pressing requirement, driven by users' growing assertion of their
"right to be forgotten". However, existing CD models are largely designed
without privacy considerations and lack effective data unlearning mechanisms.
Directly applying general purpose unlearning algorithms is suboptimal, as they
struggle to balance unlearning completeness, model utility, and efficiency when
confronted with the unique heterogeneous structure of CD models. To address
this, our paper presents the first systematic study of the data unlearning
problem for CD models, proposing a novel and efficient algorithm: hierarchical
importanceguided forgetting (HIF). Our key insight is that parameter importance
in CD models exhibits distinct layer wise characteristics. HIF leverages this
via an innovative smoothing mechanism that combines individual and layer, level
importance, enabling a more precise distinction of parameters associated with
the data to be unlearned. Experiments on three real world datasets show that
HIF significantly outperforms baselines on key metrics, offering the first
effective solution for CD models to respond to user data removal requests and
for deploying high-performance, privacy preserving AI systems

</details>


### [225] [Non-Asymptotic Optimization and Generalization Bounds for Stochastic Gauss-Newton in Overparameterized Models](https://arxiv.org/abs/2511.03972)
*Semih Cayci*

Main category: cs.LG

TL;DR: 分析了用于训练深度神经网络的随机高斯-牛顿（SGN）方法的泛化影响，并提供了理论分析。


<details>
  <summary>Details</summary>
Motivation: 研究高阶优化方法对深度学习泛化能力的影响。

Method: 使用具有Levenberg-Marquardt阻尼和mini-batch采样的方法，通过参数空间中的可变度量分析来建立有限时间收敛界，并通过均匀稳定性在过参数化情况下推导出非渐近泛化界。

Result: 推导了明确依赖于批大小、网络宽度和深度的收敛界；推导了描述曲率、批大小和过参数化对泛化性能影响的泛化界。

Conclusion: 在特定条件下，更大的高斯-牛顿矩阵最小特征值有利于SGN方法的泛化。

Abstract: An important question in deep learning is how higher-order optimization
methods affect generalization. In this work, we analyze a stochastic
Gauss-Newton (SGN) method with Levenberg-Marquardt damping and mini-batch
sampling for training overparameterized deep neural networks with smooth
activations in a regression setting. Our theoretical contributions are twofold.
First, we establish finite-time convergence bounds via a variable-metric
analysis in parameter space, with explicit dependencies on the batch size,
network width and depth. Second, we derive non-asymptotic generalization bounds
for SGN using uniform stability in the overparameterized regime, characterizing
the impact of curvature, batch size, and overparameterization on generalization
performance. Our theoretical results identify a favorable generalization regime
for SGN in which a larger minimum eigenvalue of the Gauss-Newton matrix along
the optimization path yields tighter stability bounds.

</details>


### [226] [PETRA: Pretrained Evolutionary Transformer for SARS-CoV-2 Mutation Prediction](https://arxiv.org/abs/2511.03976)
*Xu Zou*

Main category: cs.LG

TL;DR: PETRA是一个基于进化轨迹的新型Transformer模型，用于预测新冠病毒的变异，相比现有方法能显著提高预测准确性。


<details>
  <summary>Details</summary>
Motivation: 新冠病毒的快速变异给公共卫生和疫苗研发带来了持续挑战，需要更有效的预测方法。

Method: PETRA利用系统发育树推导出的进化轨迹而非原始RNA序列，并采用加权训练框架处理数据不平衡问题，以缓解测序噪声并捕捉病毒进化的层级结构。

Result: PETRA在预测核苷酸变异和刺突蛋白氨基酸变异方面，加权召回率（recall@1）分别达到9.45%和17.10%，远超基线模型的0.49%和6.64%，并能实时预测如24F(XEC)和25A(LP.8.1)等主要分支的变异。

Conclusion: PETRA通过考虑进化轨迹和处理数据不平衡，能够有效预测新冠病毒的未来变异，为应对病毒变异提供了新的工具。

Abstract: Since its emergence, SARS-CoV-2 has demonstrated a rapid and unpredictable
evolutionary trajectory, characterized by the continual emergence of
immune-evasive variants. This poses persistent challenges to public health and
vaccine development.
  While large-scale generative pre-trained transformers (GPTs) have
revolutionized the modeling of sequential data, their direct applications to
noisy viral genomic sequences are limited. In this paper, we introduce
PETRA(Pretrained Evolutionary TRAnsformer), a novel transformer approach based
on evolutionary trajectories derived from phylogenetic trees rather than raw
RNA sequences. This method effectively mitigates sequencing noise and captures
the hierarchical structure of viral evolution.
  With a weighted training framework to address substantial geographical and
temporal imbalances in global sequence data, PETRA excels in predicting future
SARS-CoV-2 mutations, achieving a weighted recall@1 of 9.45% for nucleotide
mutations and 17.10\% for spike amino-acid mutations, compared to 0.49% and
6.64% respectively for the best baseline. PETRA also demonstrates its ability
to aid in the real-time mutation prediction of major clades like 24F(XEC) and
25A(LP.8.1). The code is open sourced on https://github.com/xz-keg/PETra

</details>


### [227] [Structural Priors and Modular Adapters in the Composable Fine-Tuning Algorithm of Large-Scale Models](https://arxiv.org/abs/2511.03981)
*Yuxiao Wang,Di Wu,Feng Liu,Zhimin Qiu,Chenrui Hu*

Main category: cs.LG

TL;DR: 该方法提出了一种可组合的微调方法，将图结构先验与模块化适配器相结合，以解决大规模预训练模型在多任务适应中面临的高计算成本和结构不稳定性问题。


<details>
  <summary>Details</summary>
Motivation: 解决大规模预训练模型在多任务适应中面临的高计算成本和结构不稳定性问题。

Method: 提出了一种可组合的微调方法，通过引入关系矩阵对任务依赖性进行建模，将图结构先验统一应用于适配器权重分配和路径选择。通过低秩映射和可插拔机制将模块化适配器嵌入不同层，实现高效的跨任务组合和复用。

Result: 实验表明，该框架显著提高了任务预测准确性、适配器权重分配精度和整体计算效率，同时保持了模型的轻量化设计，验证了图先验和模块化机制在可组合微调中的协同优势。

Conclusion: 图结构先验与模块化机制的结合在可组合微调方面展现出协同优势，能够有效提高效率和性能。

Abstract: This paper proposes a composable fine-tuning method that integrates graph
structural priors with modular adapters to address the high computational cost
and structural instability faced by large-scale pre-trained models in
multi-task adaptation. The method introduces a relation matrix to model
dependencies among tasks, explicitly encoding correlations between nodes and
paths into graph structural priors, which provide unified structural
constraints for adapter weight allocation and path selection. Modular adapters
are embedded into different layers through low-rank mapping and a pluggable
mechanism, enabling efficient cross-task composition and reuse under prior
guidance. This mechanism not only improves parameter efficiency and training
stability but also alleviates path conflicts and redundant computation in
multi-task scenarios. Furthermore, experiments on hyperparameter sensitivity,
environmental sensitivity, and data sensitivity are conducted to systematically
analyze key factors such as routing temperature, gating thresholds, and
relation matrix regularization strength, verifying the consistency and superior
performance of the method under structural constraints. The results demonstrate
that the proposed framework significantly enhances task prediction accuracy,
adapter weight allocation precision, and overall computational efficiency while
maintaining model lightweight design, highlighting the synergistic advantages
of graph priors and modular mechanisms in composable fine-tuning.

</details>


### [228] [TwIST: Rigging the Lottery in Transformers with Independent Subnetwork Training](https://arxiv.org/abs/2511.03983)
*Michael Menezes,Barbara Su,Xinze Feng,Yehya Farhat,Hamza Shili,Anastasios Kyrillidis*

Main category: cs.LG

TL;DR: TwIST是一个分布式训练框架，用于高效地对大型语言模型（LLM）进行稀疏化，通过并行训练多个子网络、周期性聚合参数和重新采样子网络来识别高质量子网络，从而在部署时实现零成本剪枝，并在高稀疏度下表现优于现有方法，同时生成易于在商品硬件上加速的结构化稀疏模型。


<details>
  <summary>Details</summary>
Motivation: 现有的LLM稀疏化方法通常需要在训练后进行额外的校准或恢复步骤，这增加了部署的复杂性和成本。此外，非结构化稀疏性难以在不支持稀疏计算的硬件上实现实际的推理加速。

Method: TwIST通过并行训练多个子网络，并周期性地聚合它们的参数，然后重新采样新的子网络来学习高质量的稀疏子网络。这种方法能够在训练过程中直接识别出“黄金机票”子网络，避免了训练后的额外操作。

Result: TwIST在高稀疏度（例如50%以上）下，能够实现比现有方法（例如，PPL为23.14，而先前最佳方法为31.64）更低的困惑度（PPL）。此外，TwIST生成的模型是结构化的，并且参数是密集的，这使得它能够在不支持稀疏计算的商品硬件（例如CPU）上实现实际的推理加速和内存减少。

Conclusion: TwIST提供了一种在训练时实现可部署的稀疏LLM的高效途径，无需额外的微调或恢复开销，特别是在追求高稀疏度时，其性能优势更加显著，并且生成的模型结构有利于实际部署。

Abstract: We introduce TwIST, a distributed training framework for efficient large
language model (LLM) sparsification. TwIST trains multiple subnetworks in
parallel, periodically aggregates their parameters, and resamples new
subnetworks during training. This process identifies high-quality subnetworks
("golden tickets") without requiring post-training procedures such as
calibration or Hessian-based recovery. As a result, TwIST enables zero-cost
pruning at deployment time while achieving perplexity competitive with
state-of-the-art post-training sparsification methods. The benefits are most
pronounced under aggressive sparsity (e.g., 50%+), where TwIST significantly
outperforms baseline methods; for example, reaching 23.14 PPL compared to 31.64
for the closest prior approach. Unlike unstructured pruning, TwIST produces
structured, dense matrices that offer practical inference speedups and memory
reductions on commodity hardware (e.g., CPUs) that do not support efficient
sparse computation. TwIST provides an efficient training-time path to
deployable sparse LLMs without additional fine-tuning or recovery overhead.

</details>


### [229] [Use of Continuous Glucose Monitoring with Machine Learning to Identify Metabolic Subphenotypes and Inform Precision Lifestyle Changes](https://arxiv.org/abs/2511.03986)
*Ahmed A. Metwally,Heyjun Park,Yue Wu,Tracey McLaughlin,Michael P. Snyder*

Main category: cs.LG

TL;DR: 连续血糖监测和机器学习有望实现糖尿病的精准分型与干预。


<details>
  <summary>Details</summary>
Motivation: 静态血糖阈值分类掩盖了糖尿病和前驱糖尿病的病理生理异质性，而连续血糖监测和可穿戴技术可以实现动态代谢表型分析，用于预测胰岛素抵抗和β细胞功能等指标，从而实现精准的饮食、睡眠和体育锻炼干预。

Method: 利用连续血糖监测（CGM）和机器学习模型，分析家庭口服葡萄糖耐量试验的高分辨率血糖数据，预测肌肉胰岛素抵抗和β细胞功能的标准指标。同时，整合可穿戴设备数据，分析饮食、睡眠和体育锻炼模式与代谢紊乱的关系，并评估饮食干预的效果。

Result: 研究表明，机器学习模型能够根据高分辨率血糖数据准确预测胰岛素抵抗和β细胞功能。个体对标准化餐食（如土豆与葡萄）的独特餐后血糖反应（PPGR）可以作为代谢亚型的生物标志物。此外，饮食、睡眠和体育锻炼模式（尤其是时间）与特定的代谢功能障碍相关。饮食干预在减弱PPGR方面的效果也取决于代谢表型。

Conclusion: 连续血糖监测能够将早期血糖异常的复杂性分解为不同的、可操作的亚型，从而超越单纯的血糖控制，为针对个体核心代谢缺陷的精准营养、行为和药物策略开辟新途径，推动糖尿病精准预防的新时代。

Abstract: The classification of diabetes and prediabetes by static glucose thresholds
obscures the pathophysiological dysglycemia heterogeneity, primarily driven by
insulin resistance (IR), beta-cell dysfunction, and incretin deficiency. This
review demonstrates that continuous glucose monitoring and wearable
technologies enable a paradigm shift towards non-invasive, dynamic metabolic
phenotyping. We show evidence that machine learning models can leverage
high-resolution glucose data from at-home, CGM-enabled oral glucose tolerance
tests to accurately predict gold-standard measures of muscle IR and beta-cell
function. This personalized characterization extends to real-world nutrition,
where an individual's unique postprandial glycemic response (PPGR) to
standardized meals, such as the relative glucose spike to potatoes versus
grapes, could serve as a biomarker for their metabolic subtype. Moreover,
integrating wearable data reveals that habitual diet, sleep, and physical
activity patterns, particularly their timing, are uniquely associated with
specific metabolic dysfunctions, informing precision lifestyle interventions.
The efficacy of dietary mitigators in attenuating PPGR is also shown to be
phenotype-dependent. Collectively, this evidence demonstrates that CGM can
deconstruct the complexity of early dysglycemia into distinct, actionable
subphenotypes. This approach moves beyond simple glycemic control, paving the
way for targeted nutritional, behavioral, and pharmacological strategies
tailored to an individual's core metabolic defects, thereby paving the way for
a new era of precision diabetes prevention.

</details>


### [230] [Towards Scalable Meta-Learning of near-optimal Interpretable Models via Synthetic Model Generations](https://arxiv.org/abs/2511.04000)
*Kyaw Hpone Myint,Zhe Wu,Alexandre G. R. Day,Giri Iyengar*

Main category: cs.LG

TL;DR: 本文提出了一种高效、可扩展的方法，用于生成合成数据以实现决策树的元学习。该方法通过合成采样近乎最优的决策树来创建大规模、真实的数据集，并在MetaTree transformer架构上进行了验证，证明其性能可与在真实世界数据或计算成本高昂的最优决策树上进行预训练相媲美，同时显著降低了计算成本并提高了数据生成的灵活性。


<details>
  <summary>Details</summary>
Motivation: 决策树因其可解释性而被广泛应用于金融和医疗等高风险领域，但其元学习的效率和可扩展性有待提高。

Method: 生成合成数据以实现决策树的元学习，具体方法是合成采样近乎最优的决策树，创建大规模、真实的数据集，并采用MetaTree transformer架构。

Result: 与在真实世界数据或计算成本高昂的最优决策树上进行预训练相比，所提出的方法达到了相当的性能。

Conclusion: 该策略显著降低了计算成本，增强了数据生成的灵活性，为可扩展、高效的可解释决策树模型的元学习铺平了道路。

Abstract: Decision trees are widely used in high-stakes fields like finance and
healthcare due to their interpretability. This work introduces an efficient,
scalable method for generating synthetic pre-training data to enable
meta-learning of decision trees. Our approach samples near-optimal decision
trees synthetically, creating large-scale, realistic datasets. Using the
MetaTree transformer architecture, we demonstrate that this method achieves
performance comparable to pre-training on real-world data or with
computationally expensive optimal decision trees. This strategy significantly
reduces computational costs, enhances data generation flexibility, and paves
the way for scalable and efficient meta-learning of interpretable decision tree
models.

</details>


### [231] [Accelerating scientific discovery with the common task framework](https://arxiv.org/abs/2511.04001)
*J. Nathan Kutz,Peter Battaglia,Michael Brenner,Kevin Carlberg,Aric Hagberg,Shirley Ho,Stephan Hoyer,Henning Lange,Hod Lipson,Michael W. Mahoney,Frank Noe,Max Welling,Laure Zanna,Francis Zhu,Steven L. Brunton*

Main category: cs.LG

TL;DR: 文章提出了一个通用的科学与工程任务框架（CTF），旨在为机器学习和人工智能算法提供一套标准的评价指标，以应对动态系统分析中的挑战，特别是在数据有限和测量噪声大的情况下。


<details>
  <summary>Details</summary>
Motivation: 当前科学和工程领域在评估机器学习和人工智能算法时缺乏统一的标准和数据集，尤其是在动态系统分析、预测、状态重建、泛化和控制等任务中，并且在数据有限和测量噪声大的情况下尤为明显。

Method: 引入了一个通用的科学与工程任务框架（CTF），该框架包含一系列具有挑战性的数据集和常见的科学与工程目标，为评估和比较不同的机器学习和人工智能算法提供了一个标准化的平台。

Result: CTF框架能够为科学和工程领域中快速发展的机器学习和人工智能算法提供客观的评价指标，促进这些算法在语音识别、语言处理和计算机视觉等传统领域的应用。

Conclusion: 为了促进机器学习和人工智能算法在科学与工程领域的进一步发展和应用，迫切需要一个客观的评价体系，而CTF框架正是为了满足这一需求而设计的。

Abstract: Machine learning (ML) and artificial intelligence (AI) algorithms are
transforming and empowering the characterization and control of dynamic systems
in the engineering, physical, and biological sciences. These emerging modeling
paradigms require comparative metrics to evaluate a diverse set of scientific
objectives, including forecasting, state reconstruction, generalization, and
control, while also considering limited data scenarios and noisy measurements.
We introduce a common task framework (CTF) for science and engineering, which
features a growing collection of challenge data sets with a diverse set of
practical and common objectives. The CTF is a critically enabling technology
that has contributed to the rapid advance of ML/AI algorithms in traditional
applications such as speech recognition, language processing, and computer
vision. There is a critical need for the objective metrics of a CTF to compare
the diverse algorithms being rapidly developed and deployed in practice today
across science and engineering.

</details>


### [232] [Memory- and Latency-Constrained Inference of Large Language Models via Adaptive Split Computing](https://arxiv.org/abs/2511.04002)
*Mingyu Sung,Vikas Palakonda,Suhwan Im,Sunghwan Moon,Il-Min Kim,Sangseok Yun,Jae-Mo Kang*

Main category: cs.LG

TL;DR: 该研究提出了首个面向物联网设备的、专门为大语言模型（LLM）设计的自回归感知式（autoregressive-aware）拆分计算框架，以解决LLM在资源受限的物联网设备上部署的挑战。


<details>
  <summary>Details</summary>
Motivation: 现有的拆分计算方法未能解决自回归推理的独特挑战，特别是其迭代式生成过程和不断增长的键值（KV）缓存需求，这使得LLM在资源受限的物联网设备上的部署不切实际。

Method: 该框架包括三个主要组成部分：1. 一点拆分压缩（OPSC），一种混合精度量化方案，通过将模型划分为不同精度级别的前后端来实现。2. 一个两阶段的中间压缩流水线，结合了阈值拆分（TS）和逐令牌自适应比特量化（TAB-Q），以减少通信开销。3. 一个统一的优化框架，用于联合选择拆分点、量化设置和序列长度，以满足内存和延迟限制。

Result: 在多种LLM和硬件平台上进行的广泛评估表明，与SmoothQuant、OmniQuant和Atom等现有量化方法相比，该框架在推理速度上实现了1.49倍的加速，显著降低了通信开销，同时保持或提高了模型精度。

Conclusion: 该研究提出的自回归感知式拆分计算框架成功解决了LLM在物联网设备部署中的内存和延迟挑战，实现了显著的性能提升和通信开销减少，同时保持了模型精度。

Abstract: Large language models (LLMs) have achieved near-human performance across
diverse reasoning tasks, yet their deployment on resource-constrained
Internet-of-Things (IoT) devices remains impractical due to massive parameter
footprints and memory-intensive autoregressive decoding. While split computing
offers a promising solution by partitioning model execution between edge
devices and cloud servers, existing approaches fail to address the unique
challenges of autoregressive inference, particularly the iterative token
generation process and expanding key-value (KV) cache requirements. This work
introduces the first autoregressive-aware split computing framework designed
explicitly for LLM deployment on edge devices. Our approach makes three key
contributions. First, we develop one-point split compression (OPSC), a
mixed-precision quantization scheme that prevents out-of-memory failures by
strategically partitioning models into front-end and back-end segments with
different precision levels. Second, we propose a two-stage intermediate
compression pipeline that combines threshold splitting (TS) and token-wise
adaptive bit quantization (TAB-Q) to preserve accuracy-critical activations
while dramatically reducing communication overhead. Third, we formulate a
unified optimization framework that jointly selects optimal split points,
quantization settings, and sequence lengths to satisfy strict memory and
latency constraints. Extensive evaluations across diverse LLMs and hardware
platforms demonstrate superior performance compared to state-of-the-art
quantization methods, including SmoothQuant, OmniQuant, and Atom. The framework
achieves a 1.49 inference speedup and significant communication overhead
reduction while maintaining or improving model accuracy.

</details>


### [233] [DartQuant: Efficient Rotational Distribution Calibration for LLM Quantization](https://arxiv.org/abs/2511.04063)
*Yuantian Shao,Yuanteng Chen,Peisong Wang,Jianlin Yu,Jing Lin,Yiwu Yao,Zhihui Wei,Jian Cheng*

Main category: cs.LG

TL;DR: DartQuant是一种高效的、考虑分布的旋转校准方法，通过约束旋转后激活值的分布来降低旋转优化的复杂性，并引入QR-Orth优化方案以提高效率，显著加速了大型模型的推理过程，并节省了内存，使得在资源受限的环境下对大型语言模型进行量化成为可能。


<details>
  <summary>Details</summary>
Motivation: 现有的旋转优化算法在进行端到端微调时计算成本高昂且容易过拟合，旨在解决此问题。

Method: 提出了一种名为DartQuant的高效分布感知旋转校准方法，通过约束旋转后激活值的分布来降低旋转优化的复杂性，并引入了QR-Orth优化方案来替代昂贵的交替优化。

Result: DartQuant在多种模型量化实验中表现出卓越的性能，与现有方法相比，在70B模型上实现了47倍的加速和10倍的内存节省，并且首次在单个3090 GPU上成功完成了70B模型的旋转校准。

Conclusion: DartQuant通过降低旋转优化的复杂性和计算成本，并减少对特定任务损失的依赖，有效解决了现有方法的局限性，使得在资源受限的情况下对大型语言模型进行量化成为可能。

Abstract: Quantization plays a crucial role in accelerating the inference of
large-scale models, and rotational matrices have been shown to effectively
improve quantization performance by smoothing outliers. However, end-to-end
fine-tuning of rotational optimization algorithms incurs high computational
costs and is prone to overfitting. To address this challenge, we propose an
efficient distribution-aware rotational calibration method, DartQuant, which
reduces the complexity of rotational optimization by constraining the
distribution of the activations after rotation. This approach also effectively
reduces reliance on task-specific losses, thereby mitigating the risk of
overfitting. Additionally, we introduce the QR-Orth optimization scheme, which
replaces expensive alternating optimization with a more efficient solution. In
a variety of model quantization experiments, DartQuant demonstrates superior
performance. Compared to existing methods, it achieves 47$\times$ acceleration
and 10$\times$ memory savings for rotational optimization on a 70B model.
Furthermore, it is the first to successfully complete rotational calibration
for a 70B model on a single 3090 GPU, making quantization of large language
models feasible in resource-constrained environments. Code is available at
https://github.com/CAS-CLab/DartQuant.git.

</details>


### [234] [Learning Filter-Aware Distance Metrics for Nearest Neighbor Search with Multiple Filters](https://arxiv.org/abs/2511.04073)
*Ananya Sutradhar,Suryansh Gupta,Ravishankar Krishnaswamy,Haiyang Xu,Aseem Rastogi,Gopal Srinivasa*

Main category: cs.LG

TL;DR: 提出了一种新的过滤式近似最近邻搜索方法，通过学习数据中的最优权衡来替代固定的惩罚机制，提高了搜索精度。


<details>
  <summary>Details</summary>
Motivation: 现有的基于图的过滤式近似最近邻搜索方法在处理不同标签和向量分布的数据集时泛化能力不足，因为它们依赖于固定的、与数据无关的惩罚机制。

Method: 将过滤式近似最近邻搜索问题表述为一个约束线性优化问题，并从中推导出最优权重。这些权重被用于指导搜索过程和索引构建，从而生成更能有效捕捉底层过滤分布和过滤语义的图结构。

Result: 实验结果表明，通过自适应距离函数，过滤式近似最近邻搜索的准确性比固定惩罚方法提高了5-10%。

Conclusion: 提出的方法通过直接从数据中学习最优权衡，为过滤式近似最近邻搜索问题提供了一个更灵活、更通用的框架，显著提高了搜索准确性。

Abstract: Filtered Approximate Nearest Neighbor (ANN) search retrieves the closest
vectors for a query vector from a dataset. It enforces that a specified set of
discrete labels $S$ for the query must be included in the labels of each
retrieved vector. Existing graph-based methods typically incorporate filter
awareness by assigning fixed penalties or prioritizing nodes based on filter
satisfaction. However, since these methods use fixed, data in- dependent
penalties, they often fail to generalize across datasets with diverse label and
vector distributions. In this work, we propose a principled alternative that
learns the optimal trade-off between vector distance and filter match directly
from the data, rather than relying on fixed penalties. We formulate this as a
constrained linear optimization problem, deriving weights that better reflect
the underlying filter distribution and more effectively address the filtered
ANN search problem. These learned weights guide both the search process and
index construction, leading to graph structures that more effectively capture
the underlying filter distribution and filter semantics. Our experiments
demonstrate that adapting the distance function to the data significantly im-
proves accuracy by 5-10% over fixed-penalty methods, providing a more flexible
and generalizable framework for the filtered ANN search problem.

</details>


### [235] [DeNoise: Learning Robust Graph Representations for Unsupervised Graph-Level Anomaly Detection](https://arxiv.org/abs/2511.04086)
*Qingfeng Chen,Haojin Zeng,Jingyi Jie,Shichao Zhang,Debo Cheng*

Main category: cs.LG

TL;DR: DeNoise是一个用于包含噪声的图的无监督图级别异常检测框架，通过联合优化编码器、解码器和对比学习来提高鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有的无监督图级别异常检测（UGAD）方法假设训练数据是干净的，但实际情况并非如此，异常图的存在会降低模型性能。

Method: DeNoise联合优化图级别编码器、属性解码器和结构解码器，并通过对抗性目标学习抗噪声嵌入。它还引入了一个编码器锚点对齐去噪机制，将来自正常图的高信息节点嵌入融合到所有图嵌入中，并利用对比学习来压缩正常图嵌入并排斥异常图嵌入。

Result: 在八个真实世界数据集上的广泛实验表明，DeNoise在不同噪声强度下始终能学习到可靠的图级别表示，并且显著优于最先进的UGAD基线。

Conclusion: DeNoise是一个鲁棒的UGAD框架，能够处理被污染的训练数据，并在各种噪声水平下保持高性能。

Abstract: With the rapid growth of graph-structured data in critical domains,
unsupervised graph-level anomaly detection (UGAD) has become a pivotal task.
UGAD seeks to identify entire graphs that deviate from normal behavioral
patterns. However, most Graph Neural Network (GNN) approaches implicitly assume
that the training set is clean, containing only normal graphs, which is rarely
true in practice. Even modest contamination by anomalous graphs can distort
learned representations and sharply degrade performance. To address this
challenge, we propose DeNoise, a robust UGAD framework explicitly designed for
contaminated training data. It jointly optimizes a graph-level encoder, an
attribute decoder, and a structure decoder via an adversarial objective to
learn noise-resistant embeddings. Further, DeNoise introduces an encoder
anchor-alignment denoising mechanism that fuses high-information node
embeddings from normal graphs into all graph embeddings, improving
representation quality while suppressing anomaly interference. A contrastive
learning component then compacts normal graph embeddings and repels anomalous
ones in the latent space. Extensive experiments on eight real-world datasets
demonstrate that DeNoise consistently learns reliable graph-level
representations under varying noise intensities and significantly outperforms
state-of-the-art UGAD baselines.

</details>


### [236] [KoTaP: A Panel Dataset for Corporate Tax Avoidance, Performance, and Governance in Korea](https://arxiv.org/abs/2511.04094)
*Hyungjong Na,Wonho Song,Seungyong Han,Donghyeon Jo,Sejin Myung,Hyungjoon Kim*

Main category: cs.LG

TL;DR: 本文介绍了一个名为KoTaP的韩国公司避税数据库，涵盖了2011年至2024年间在KOSPI和KOSDAQ上市的非金融公司。


<details>
  <summary>Details</summary>
Motivation: 建立一个全面的数据库（KoTaP），用于研究公司避税行为作为预测变量，并将其与收益管理、盈利能力、稳定性、增长和治理等多个领域联系起来。

Method: 通过排除金融公司、非12月财年末公司、资本减值和税前亏损公司，最终构建了包含1754家公司、12653个公司年度观测值的KoTaP数据库。利用现金有效税率、GAAP有效税率和税收账簿差异等指标衡量避税行为，并进行标准化处理，使其与国际文献保持一致，同时体现了韩国公司的制度特色。

Result: KoTaP数据库具有平衡面板结构、标准化变量、国际可比性，并反映了韩国公司特有的制度特征（如集中持股、高外国持股比例、高流动性比率）。

Conclusion: KoTaP数据库为经济计量学和深度学习模型、外部有效性检验、可解释人工智能分析、政策评估、审计规划和投资分析等提供了关键的开放资源，支持会计、金融和跨学科研究。

Abstract: This study introduces the Korean Tax Avoidance Panel (KoTaP), a long-term
panel dataset of non-financial firms listed on KOSPI and KOSDAQ between 2011
and 2024. After excluding financial firms, firms with non-December fiscal year
ends, capital impairment, and negative pre-tax income, the final dataset
consists of 12,653 firm-year observations from 1,754 firms. KoTaP is designed
to treat corporate tax avoidance as a predictor variable and link it to
multiple domains, including earnings management (accrual- and activity-based),
profitability (ROA, ROE, CFO, LOSS), stability (LEV, CUR, SIZE, PPE, AGE,
INVREC), growth (GRW, MB, TQ), and governance (BIG4, FORN, OWN). Tax avoidance
itself is measured using complementary indicators cash effective tax rate
(CETR), GAAP effective tax rate (GETR), and book-tax difference measures (TSTA,
TSDA) with adjustments to ensure interpretability. A key strength of KoTaP is
its balanced panel structure with standardized variables and its consistency
with international literature on the distribution and correlation of core
indicators. At the same time, it reflects distinctive institutional features of
Korean firms, such as concentrated ownership, high foreign shareholding, and
elevated liquidity ratios, providing both international comparability and
contextual uniqueness. KoTaP enables applications in benchmarking econometric
and deep learning models, external validity checks, and explainable AI
analyses. It further supports policy evaluation, audit planning, and investment
analysis, making it a critical open resource for accounting, finance, and
interdisciplinary research.

</details>


### [237] [Decomposable Neuro Symbolic Regression](https://arxiv.org/abs/2511.04124)
*Giorgio Morales,John W. Sheppard*

Main category: cs.LG

TL;DR: 本研究提出一种可分解的符号回归（SR）方法，利用Transformer、遗传算法（GA）和遗传编程（GP）生成可解释的多变量数学表达式。


<details>
  <summary>Details</summary>
Motivation: 现有的SR方法倾向于优化预测误差，导致生成的表达式过于复杂或不准确。本方法旨在生成可解释的、结构准确的数学表达式。

Method: 1. 使用Multi-Set Transformer生成描述变量影响的单变量符号骨架。
2. 使用GA筛选高质量的骨架。
3. 使用GP逐步合并骨架，保持其结构。
4. 使用GA优化最终多变量骨架的系数。

Result: 在含噪声数据上，本方法在插值和外推误差方面表现优于或媲美现有多种SR方法，并能学习到与原始数学结构匹配的表达式。

Conclusion: 本研究提出的可分解SR方法能够生成结构准确且可解释的多变量数学表达式，并在性能上达到或超过现有方法。

Abstract: Symbolic regression (SR) models complex systems by discovering mathematical
expressions that capture underlying relationships in observed data. However,
most SR methods prioritize minimizing prediction error over identifying the
governing equations, often producing overly complex or inaccurate expressions.
To address this, we present a decomposable SR method that generates
interpretable multivariate expressions leveraging transformer models, genetic
algorithms (GAs), and genetic programming (GP). In particular, our explainable
SR method distills a trained ``opaque'' regression model into mathematical
expressions that serve as explanations of its computed function. Our method
employs a Multi-Set Transformer to generate multiple univariate symbolic
skeletons that characterize how each variable influences the opaque model's
response. We then evaluate the generated skeletons' performance using a
GA-based approach to select a subset of high-quality candidates before
incrementally merging them via a GP-based cascade procedure that preserves
their original skeleton structure. The final multivariate skeletons undergo
coefficient optimization via a GA. We evaluated our method on problems with
controlled and varying degrees of noise, demonstrating lower or comparable
interpolation and extrapolation errors compared to two GP-based methods, three
neural SR methods, and a hybrid approach. Unlike them, our approach
consistently learned expressions that matched the original mathematical
structure.

</details>


### [238] [Exploring the Feasibility of End-to-End Large Language Model as a Compiler](https://arxiv.org/abs/2511.04132)
*Hongbin Zhang,Shihao Gao,Yang Liu,Mingjie Xing,Yanjun Wu,Chen Zhao*

Main category: cs.LG

TL;DR: LLM在编译器领域潜力巨大，但目前成功率有待提高，未来发展可期。


<details>
  <summary>Details</summary>
Motivation: 探索大语言模型（LLM）作为端到端编译器的可行性及其未来发展方向。

Method: 设计了CompilerEval数据集和框架，用于评估LLM在代码理解和汇编代码生成方面的能力，并进行了错误分析、代码优化和跨平台编译评估。

Result: 实验表明，LLM具备基础的编译器能力，但编译成功率较低。通过优化提示、扩大模型规模和引入推理方法，可以显著提高LLM生成汇编代码的质量。

Conclusion: LLM作为编译器（LaaC）具有巨大潜力，通过针对性训练、知识引导的提示和专业基础设施，有望生成高质量汇编代码，并可能引发编译领域的范式转变。

Abstract: In recent years, end-to-end Large Language Model (LLM) technology has shown
substantial advantages across various domains. As critical system software and
infrastructure, compilers are responsible for transforming source code into
target code. While LLMs have been leveraged to assist in compiler development
and maintenance, their potential as an end-to-end compiler remains largely
unexplored. This paper explores the feasibility of LLM as a Compiler (LaaC) and
its future directions. We designed the CompilerEval dataset and framework
specifically to evaluate the capabilities of mainstream LLMs in source code
comprehension and assembly code generation. In the evaluation, we analyzed
various errors, explored multiple methods to improve LLM-generated code, and
evaluated cross-platform compilation capabilities. Experimental results
demonstrate that LLMs exhibit basic capabilities as compilers but currently
achieve low compilation success rates. By optimizing prompts, scaling up the
model, and incorporating reasoning methods, the quality of assembly code
generated by LLMs can be significantly enhanced. Based on these findings, we
maintain an optimistic outlook for LaaC and propose practical architectural
designs and future research directions. We believe that with targeted training,
knowledge-rich prompts, and specialized infrastructure, LaaC has the potential
to generate high-quality assembly code and drive a paradigm shift in the field
of compilation.

</details>


### [239] [Exchange Policy Optimization Algorithm for Semi-Infinite Safe Reinforcement Learning](https://arxiv.org/abs/2511.04147)
*Jiaming Zhang,Yujie Yang,Haoning Wang,Liping Zhang,Shengbo Eben Li*

Main category: cs.LG

TL;DR: 该研究提出了一种名为EPO（交换策略优化）的算法框架，用于解决具有无限数量约束的半无限安全强化学习（SI-safe RL）问题。


<details>
  <summary>Details</summary>
Motivation: 在许多实际应用中，安全强化学习需要满足无限数量的约束条件，例如在所有空间位置都必须满足资源分配的安全性要求。

Method: EPO通过迭代地解决具有有限约束集的安全强化学习子问题，并自适应地调整约束集来实现。在每次迭代中，会添加违反预定义容差的约束，并移除拉格朗日乘子为零的约束。

Result: 通过理论分析，证明了该算法在温和假设下，可以获得接近最优的策略性能，并且全局约束违反严格保持在预定边界内。

Conclusion: EPO是一种有效的算法框架，能够解决半无限安全强化学习问题，同时保证性能和安全性。

Abstract: Safe reinforcement learning (safe RL) aims to respect safety requirements
while optimizing long-term performance. In many practical applications,
however, the problem involves an infinite number of constraints, known as
semi-infinite safe RL (SI-safe RL). Such constraints typically appear when
safety conditions must be enforced across an entire continuous parameter space,
such as ensuring adequate resource distribution at every spatial location. In
this paper, we propose exchange policy optimization (EPO), an algorithmic
framework that achieves optimal policy performance and deterministic bounded
safety. EPO works by iteratively solving safe RL subproblems with finite
constraint sets and adaptively adjusting the active set through constraint
expansion and deletion. At each iteration, constraints with violations
exceeding the predefined tolerance are added to refine the policy, while those
with zero Lagrange multipliers are removed after the policy update. This
exchange rule prevents uncontrolled growth of the working set and supports
effective policy training. Our theoretical analysis demonstrates that, under
mild assumptions, strategies trained via EPO achieve performance comparable to
optimal solutions with global constraint violations strictly remaining within a
prescribed bound.

</details>


### [240] [Learning to Land Anywhere: Transferable Generative Models for Aircraft Trajectories](https://arxiv.org/abs/2511.04155)
*Olav Finne Praesteng Larsen,Massimiliano Ruocco,Michail Spitieris,Abdulmajid Murad,Martina Ragosta*

Main category: cs.LG

TL;DR: 通过迁移学习，可以有效解决机场空域数据稀疏的问题，提高机器学习在航空交通管理中的应用。


<details>
  <summary>Details</summary>
Motivation: 许多次要和区域机场在轨迹数据方面存在稀疏性，这限制了机器学习方法、大规模模拟和“假设”分析的应用。因此，需要研究如何有效利用现有数据来解决数据稀疏问题。

Method: 研究人员将最先进的基于扩散和流匹配的生成模型架构应用于航空领域，并在苏黎世（源）和都柏林（目标）着陆轨迹数据集之间评估其迁移能力。通过在苏黎世预训练模型，然后在都柏林使用不同比例（0%至100%）的本地数据进行微调，来评估模型的性能。

Result: 研究结果表明，基于扩散的模型在仅使用5%的都柏林本地数据时就能达到具有竞争力的性能，并在使用20%的数据时达到基线水平的性能。这些模型在各种指标和视觉检查方面持续优于从头开始训练的模型。虽然潜流匹配和潜在扩散模型也受益于预训练，但效果变化较大，而流匹配模型的泛化能力较弱。

Conclusion: 尽管在捕捉罕见的轨迹模式方面存在挑战，但研究结果证明了迁移学习在减少航空交通管理中轨迹生成所需数据量方面的潜力，即使在历史记录有限的环境中也能生成逼真的合成数据。

Abstract: Access to trajectory data is a key requirement for developing and validating
Air Traffic Management (ATM) solutions, yet many secondary and regional
airports face severe data scarcity. This limits the applicability of machine
learning methods and the ability to perform large-scale simulations or
"what-if" analyses. In this paper, we investigate whether generative models
trained on data-rich airports can be efficiently adapted to data-scarce
airports using transfer learning. We adapt state-of-the-art diffusion- and
flow-matching-based architectures to the aviation domain and evaluate their
transferability between Zurich (source) and Dublin (target) landing trajectory
datasets. Models are pretrained on Zurich and fine-tuned on Dublin with varying
amounts of local data, ranging from 0% to 100%. Results show that
diffusion-based models achieve competitive performance with as little as 5% of
the Dublin data and reach baseline-level performance around 20%, consistently
outperforming models trained from scratch across metrics and visual
inspections. Latent flow matching and latent diffusion models also benefit from
pretraining, though with more variable gains, while flow matching models show
weaker generalization. Despite challenges in capturing rare trajectory
patterns, these findings demonstrate the potential of transfer learning to
substantially reduce data requirements for trajectory generation in ATM,
enabling realistic synthetic data generation even in environments with limited
historical records.

</details>


### [241] [Deep Learning Approach for Clinical Risk Identification Using Transformer Modeling of Heterogeneous EHR Data](https://arxiv.org/abs/2511.04158)
*Anzhuo Xie,Wei-Chen Chang*

Main category: cs.LG

TL;DR: 该研究提出一种基于Transformer的纵向建模方法，用于处理电子健康记录（EHR）数据中的临床风险分类挑战。


<details>
  <summary>Details</summary>
Motivation: 解决临床风险分类中电子健康记录（EHR）数据所面临的异构性、不规则时间模式、模态差异大以及语义结构复杂等挑战。

Method: 提出一种基于Transformer的纵向建模方法，该方法利用特征嵌入层统一表示结构化和非结构化数据，引入可学习的时间编码机制处理不均匀采样，采用多头自注意力机制进行全局依赖建模，并通过语义加权池化模块增强语义表示，最终通过线性映射层生成个体风险评分。

Result: 所提出的模型在准确率、召回率、精确率和F1分数方面优于传统的机器学习和时间深度学习模型。

Conclusion: 在多源异构EHR环境中，该模型实现了稳定且精确的风险识别，为临床智能决策提供了一个高效且可靠的框架。

Abstract: This study proposes a Transformer-based longitudinal modeling method to
address challenges in clinical risk classification with heterogeneous
Electronic Health Record (EHR) data, including irregular temporal patterns,
large modality differences, and complex semantic structures. The method takes
multi-source medical features as input and employs a feature embedding layer to
achieve a unified representation of structured and unstructured data. A
learnable temporal encoding mechanism is introduced to capture dynamic
evolution under uneven sampling intervals. The core model adopts a multi-head
self-attention structure to perform global dependency modeling on longitudinal
sequences, enabling the aggregation of long-term trends and short-term
fluctuations across different temporal scales. To enhance semantic
representation, a semantic-weighted pooling module is designed to assign
adaptive importance to key medical events, improving the discriminative ability
of risk-related features. Finally, a linear mapping layer generates
individual-level risk scores. Experimental results show that the proposed model
outperforms traditional machine learning and temporal deep learning models in
accuracy, recall, precision, and F1-Score, achieving stable and precise risk
identification in multi-source heterogeneous EHR environments and providing an
efficient and reliable framework for clinical intelligent decision-making.

</details>


### [242] [On Joint Regularization and Calibration in Deep Ensembles](https://arxiv.org/abs/2511.04160)
*Laurits Fredsgaard,Mikkel N. Schmidt*

Main category: cs.LG

TL;DR: 联合调优深度集成模型在不同任务和指标上表现各异，但通常能匹配或提升性能，部分重叠的留出策略是实用的解决方案。


<details>
  <summary>Details</summary>
Motivation: 研究联合调优深度集成模型（包括权重衰减、温度缩放和提前停止）对预测性能和不确定性量化的影响，并提出一种部分重叠的留出策略。

Method: 通过实验评估联合调优对深度集成模型性能和不确定性量化的影响，并提出并验证部分重叠的留出策略。

Result: 联合调优通常能匹配或提升模型性能，但效果因任务和指标而异；部分重叠的留出策略在允许联合评估和最大化训练数据使用之间取得了良好平衡。

Conclusion: 联合调优深度集成模型通常是有益的，但效果存在差异；部分重叠的留出策略为深度集成模型优化提供了实用的解决方案和有价值的见解。

Abstract: Deep ensembles are a powerful tool in machine learning, improving both model
performance and uncertainty calibration. While ensembles are typically formed
by training and tuning models individually, evidence suggests that jointly
tuning the ensemble can lead to better performance. This paper investigates the
impact of jointly tuning weight decay, temperature scaling, and early stopping
on both predictive performance and uncertainty quantification. Additionally, we
propose a partially overlapping holdout strategy as a practical compromise
between enabling joint evaluation and maximizing the use of data for training.
Our results demonstrate that jointly tuning the ensemble generally matches or
improves performance, with significant variation in effect size across
different tasks and metrics. We highlight the trade-offs between individual and
joint optimization in deep ensemble training, with the overlapping holdout
strategy offering an attractive practical solution. We believe our findings
provide valuable insights and guidance for practitioners looking to optimize
deep ensemble models. Code is available at:
https://github.com/lauritsf/ensemble-optimality-gap

</details>


### [243] [ScaleDL: Towards Scalable and Efficient Runtime Prediction for Distributed Deep Learning Workloads](https://arxiv.org/abs/2511.04162)
*Xiaokai Wang,Shaoyuan Huang,Yuting Li,Xiaofei Wang*

Main category: cs.LG

TL;DR: ScaleDL是一个新的深度神经网络运行时预测框架，通过结合非线性层建模和图神经网络（GNN）来实现准确的预测，并能跨不同网络架构进行泛化，同时利用D-optimal方法降低数据收集成本。


<details>
  <summary>Details</summary>
Motivation: 现有的深度神经网络（DNN）运行时预测方法在准确性、泛化能力和数据收集成本之间难以平衡，而DNN在现代AI服务中至关重要，其训练和推理任务对计算资源的需求日益增长。

Method: ScaleDL框架结合了非线性层级建模和基于图神经网络（GNN）的跨层交互机制，并采用D-optimal方法来降低数据收集成本。

Result: 在五个流行的DNN模型工作负载上的实验表明，ScaleDL的运行时预测准确性和泛化能力得到了提升，与基线模型相比，MRE降低了6倍，RMSE降低了5倍。

Conclusion: ScaleDL通过其新颖的框架，在准确性、泛化能力和数据收集成本方面取得了良好的平衡，有效解决了DNN运行时预测的挑战。

Abstract: Deep neural networks (DNNs) form the cornerstone of modern AI services,
supporting a wide range of applications, including autonomous driving,
chatbots, and recommendation systems. As models increase in size and
complexity, DNN workloads like training and inference tasks impose
unprecedented demands on distributed computing resources, making the accurate
prediction of runtime essential for optimizing development and resource
allocation. Traditional methods rely on additive computational unit models,
limiting their accuracy and generalizability. In contrast, graph-enhanced
modeling improves performance but significantly increases data collection
costs. Therefore, there is a critical need for a method that strikes a balance
between accuracy, generalizability, and the costs of data collection. To
address these challenges, we propose ScaleDL, a novel runtime prediction
framework that combines nonlinear layer-wise modeling with graph neural network
(GNN)-based cross-layer interaction mechanism, enabling accurate DNN runtime
prediction and hierarchical generalizability across different network
architectures. Additionally, we employ the D-optimal method to reduce data
collection costs. Experiments on the workloads of five popular DNN models prove
that ScaleDL enhances runtime prediction accuracy and generalizability,
achieving 6$\times$ lower MRE and 5$\times$ lower RMSE compared to baseline
models.

</details>


### [244] [Block Rotation is All You Need for MXFP4 Quantization](https://arxiv.org/abs/2511.04214)
*Yuantian Shao,Peisong Wang,Yuanteng Chen,Chang Xu,Zhihui Wei,Jian Cheng*

Main category: cs.LG

TL;DR: 本研究针对MXFP4格式下的模型量化精度问题，提出了一种新的块旋转策略，显著提升了量化LLM的准确性。


<details>
  <summary>Details</summary>
Motivation: 现有模型量化技术在MXFP4格式下存在兼容性问题，导致精度下降，需要新的解决方案。

Method: 通过广泛的基准测试，发现现有旋转方法与MXFP4的PoT块缩放不兼容。提出了一种块旋转策略来解决此问题。

Result: 所提出的块旋转策略在多种LLM上实现了显著的精度提升，解决了旋转方法与MXFP4的冲突。

Conclusion: 本研究提出的块旋转策略有效解决了MXFP4格式下的量化精度问题，为低精度格式下的PTQ研究奠定了基础。

Abstract: Large language models (LLMs) have achieved remarkable success, but their
rapidly growing scale imposes prohibitive costs in memory, computation, and
energy. Post-training quantization (PTQ) is a promising solution for efficient
deployment, yet achieving accurate W4A4 quantization remains an open challenge.
While most existing methods are designed for INT4 formats, the emergence of
MXFP4 -- a new FP4 format with various hardware support (NVIDIA, AMD, Intel)--
raises questions about the applicability of current techniques. In this work,
we establish a comprehensive benchmark of PTQ methods under the MXFP4 format.
Through systematic evaluation, we find that methods like GPTQ consistently
deliver strong performance, whereas rotation-based approaches, which are almost
used by all state-of-the-art approaches, suffer from severe incompatibility
with MXFP4. We further provide the first in-depth analysis of this conflict,
tracing its root to a fundamental mismatch between MXFP4's PoT (power-of-two)
block scaling and the redistribution of outlier energy via global rotation.
Building on this insight, we propose a simple yet effective block rotation
strategy that adapts rotation-based methods to MXFP4, leading to substantial
accuracy improvements across diverse LLMs. Our findings not only offer clear
guidance for practitioners but also set a foundation for advancing PTQ research
under emerging low-precision formats.

</details>


### [245] [The Strong Lottery Ticket Hypothesis for Multi-Head Attention Mechanisms](https://arxiv.org/abs/2511.04217)
*Hikari Otsuka,Daiki Chijiwa,Yasuyuki Okoshi,Daichi Fujiki,Susumu Takeuchi,Masato Motomura*

Main category: cs.LG

TL;DR: 随机初始化的Transformer模型（特别是其多头注意力机制）中存在表现优异的子网络（强彩票），并且可以通过理论分析和实验验证。


<details>
  <summary>Details</summary>
Motivation: 当前SLTH理论缺乏对Transformer模型，特别是其多头注意力（MHA）机制的解释，需要填补这一理论空白。

Method: 对MHA中的SLT存在性进行理论分析，并基于此将SLTH扩展到不含归一化层的Transformer模型。通过实验验证理论发现。

Result: 证明了具有特定隐藏维度（$O(d	ext{log}(Hd^{3/2}))$）的随机初始化的MHA包含一个SLT，可以高概率地近似任意MHA。实验结果显示，源模型（MHA和Transformer）与其目标模型的近似误差随隐藏维度的增加呈指数级下降。

Conclusion: 为Transformer模型中的SLTH提供了理论基础，并提出了改进Transformer性能的新视角。

Abstract: The strong lottery ticket hypothesis (SLTH) conjectures that high-performing
subnetworks, called strong lottery tickets (SLTs), are hidden in randomly
initialized neural networks. Although recent theoretical studies have
established the SLTH across various neural architectures, the SLTH for
transformer architectures still lacks theoretical understanding. In particular,
the current theory of the SLTH does not yet account for the multi-head
attention (MHA) mechanism, a core component of transformers. To address this
gap, we introduce a theoretical analysis of the existence of SLTs within MHAs.
We prove that, if a randomly initialized MHA of $H$ heads and input dimension
$d$ has the hidden dimension $O(d\log(Hd^{3/2}))$ for the key and value, it
contains an SLT that approximates an arbitrary MHA with the same input
dimension with high probability. Furthermore, by leveraging this theory for
MHAs, we extend the SLTH to transformers without normalization layers. We
empirically validate our theoretical findings, demonstrating that the
approximation error between the SLT within a source model (MHA and transformer)
and an approximate target counterpart decreases exponentially by increasing the
hidden dimension of the source model.

</details>


### [246] [seqme: a Python library for evaluating biological sequence design](https://arxiv.org/abs/2511.04239)
*Rasmus Møller-Larsen,Adam Izdebski,Jan Olszewski,Pankhil Gawade,Michal Kmicikiewicz,Wojciech Zarzecki,Ewa Szczurek*

Main category: cs.LG

TL;DR: seqme是一个开源Python库，用于评估生物序列设计方法的性能，提供序列、嵌入和属性指标，支持多种序列类型和设计方法。


<details>
  <summary>Details</summary>
Motivation: 目前缺乏一个集成的软件库来实现用于评估生物序列设计方法的性能指标。

Method: 介绍seqme库，一个模块化、可扩展的开源Python库。该库包含模型无关的指标，用于评估计算生物序列设计方法。seqme包含三类指标：基于序列、基于嵌入和基于属性。它适用于小分子、DNA、ncRNA、mRNA、肽和蛋白质等多种生物序列。该库还提供嵌入和属性模型以及诊断和可视化功能。seqme可用于评估单次和迭代的计算设计方法。

Result: seqme库的实现，包含多种序列、嵌入和属性指标，以及用于检查结果的诊断和可视化功能。

Conclusion: seqme为评估生物序列设计方法提供了一个全面的、模块化的解决方案。

Abstract: Recent advances in computational methods for designing biological sequences
have sparked the development of metrics to evaluate these methods performance
in terms of the fidelity of the designed sequences to a target distribution and
their attainment of desired properties. However, a single software library
implementing these metrics was lacking. In this work we introduce seqme, a
modular and highly extendable open-source Python library, containing
model-agnostic metrics for evaluating computational methods for biological
sequence design. seqme considers three groups of metrics: sequence-based,
embedding-based, and property-based, and is applicable to a wide range of
biological sequences: small molecules, DNA, ncRNA, mRNA, peptides and proteins.
The library offers a number of embedding and property models for biological
sequences, as well as diagnostics and visualization functions to inspect the
results. seqme can be used to evaluate both one-shot and iterative
computational design methods.

</details>


### [247] [Guided by Stars: Interpretable Concept Learning Over Time Series via Temporal Logic Semantics](https://arxiv.org/abs/2511.04244)
*Irene Ferfoglia,Simone Silvetti,Gaia Saveri,Laura Nenzi,Luca Bortolussi*

Main category: cs.LG

TL;DR: STELLE是一个新的神经符号框架，它将时间序列分类与可解释性相结合，通过将时间序列嵌入到时间逻辑概念空间中来实现。它提供了本地和全局解释，并在各种基准测试中取得了具有竞争力的准确性。


<details>
  <summary>Details</summary>
Motivation: 现有的时间序列分类方法大多依赖于难以解释的深度学习黑盒模型，这使得理解其预测背后的原因变得困难，尤其是在安全关键应用中。为了解决这个问题，需要一种能够同时提供准确分类和清晰解释的方法。

Method: STELLE通过将原始时间序列映射到预定义的STL（信号时序逻辑）公式的对齐方式，引入了一种新颖的STL启发式核。通过直接将轨迹嵌入到时间逻辑概念空间中，该模型能够联合优化准确性和可解释性。

Result: STELLE在各种真实世界基准测试中实现了具有竞争力的准确性，并提供了人类可读的STL条件作为本地解释，以及表征类别的公式作为全局解释。这些解释在逻辑上是忠实的。

Conclusion: STELLE成功地将时间序列分类与可解释性相结合，通过神经符号方法实现了这一目标。它提供了本地和全局解释，并且在准确性和解释的忠实度方面都表现出色，证明了其在实际应用中的有效性。

Abstract: Time series classification is a task of paramount importance, as this kind of
data often arises in safety-critical applications. However, it is typically
tackled with black-box deep learning methods, making it hard for humans to
understand the rationale behind their output. To take on this challenge, we
propose a novel approach, STELLE (Signal Temporal logic Embedding for
Logically-grounded Learning and Explanation), a neuro-symbolic framework that
unifies classification and explanation through direct embedding of trajectories
into a space of temporal logic concepts. By introducing a novel STL-inspired
kernel that maps raw time series to their alignment with predefined STL
formulae, our model jointly optimises accuracy and interpretability, as each
prediction is accompanied by the most relevant logical concepts that
characterise it. This yields (i) local explanations as human-readable STL
conditions justifying individual predictions, and (ii) global explanations as
class-characterising formulae. Experiments demonstrate that STELLE achieves
competitive accuracy while providing logically faithful explanations, validated
on diverse real-world benchmarks.

</details>


### [248] [Efficient Reinforcement Learning from Human Feedback via Bayesian Preference Inference](https://arxiv.org/abs/2511.04286)
*Matteo Cercola,Valeria Capretti,Simone Formentin*

Main category: cs.LG

TL;DR: 通过集成主动学习模块到RLHF流程中，提出了一种结合RLHF可扩展性和PBO查询效率的混合框架，以实现更高效、样本更优的偏好数据收集，并在高维偏好优化和LLM微调任务中验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 收集人类偏好数据成本高昂且耗时，因此需要更高效的学习方法，而RLHF和PBO各有利弊，需要一种结合两者优点的方法。

Method: 提出了一种混合框架，将主动学习模块集成到RLHF流程中，以结合RLHF的可扩展性和PBO的查询效率。

Result: 实验结果表明，该混合框架在高维偏好优化和LLM微调任务中，在样本效率和总体性能方面均取得了一致性提升。

Conclusion: 所提出的混合框架能够有效提高偏好数据收集的效率和模型性能。

Abstract: Learning from human preferences is a cornerstone of aligning machine learning
models with subjective human judgments. Yet, collecting such preference data is
often costly and time-consuming, motivating the need for more efficient
learning paradigms. Two established approaches offer complementary advantages:
RLHF scales effectively to high-dimensional tasks such as LLM fine-tuning,
while PBO achieves greater sample efficiency through active querying. We
propose a hybrid framework that unifies RLHF's scalability with PBO's query
efficiency by integrating an acquisition-driven module into the RLHF pipeline,
thereby enabling active and sample-efficient preference gathering. We validate
the proposed approach on two representative domains: (i) high-dimensional
preference optimization and (ii) LLM fine-tuning. Experimental results
demonstrate consistent improvements in both sample efficiency and overall
performance across these tasks.

</details>


### [249] [Differentially Private In-Context Learning with Nearest Neighbor Search](https://arxiv.org/abs/2511.04332)
*Antti Koskela,Tejas Kulkarni,Laith Zumot*

Main category: cs.LG

TL;DR: 为ICL引入了一种新的差分隐私框架，该框架将最近邻搜索整合到隐私感知的方式中，并在文本分类和文档问答方面取得了更好的隐私-效用权衡。


<details>
  <summary>Details</summary>
Motivation: 现有的差分私有上下文学习（DP-ICL）方法忽略了现代大型语言模型（LLM）管道中的一个关键组件：用于检索相关上下文数据的相似性搜索。

Method: 通过从上下文数据的数据库中检索最近邻，并结合一个跟踪所选样本累积隐私成本的隐私过滤器，以确保遵守中央差分隐私预算。

Result: 在文本分类和文档问答方面，与现有基线相比，该方法具有明显优势，并且在所有评估的基准测试中都取得了更好的隐私-效用权衡。

Conclusion: 所提出的方法在上下文学习中集成了最近邻搜索，可以以隐私感知的方式进行，从而在保持高数据效用的同时实现差分隐私。

Abstract: Differentially private in-context learning (DP-ICL) has recently become an
active research topic due to the inherent privacy risks of in-context learning.
However, existing approaches overlook a critical component of modern large
language model (LLM) pipelines: the similarity search used to retrieve relevant
context data. In this work, we introduce a DP framework for in-context learning
that integrates nearest neighbor search of relevant examples in a privacy-aware
manner. Our method outperforms existing baselines by a substantial margin
across all evaluated benchmarks, achieving more favorable privacy-utility
trade-offs. To achieve this, we employ nearest neighbor retrieval from a
database of context data, combined with a privacy filter that tracks the
cumulative privacy cost of selected samples to ensure adherence to a central
differential privacy budget. Experimental results on text classification and
document question answering show a clear advantage of the proposed method over
existing baselines.

</details>


### [250] [LUME-DBN: Full Bayesian Learning of DBNs from Incomplete data in Intensive Care](https://arxiv.org/abs/2511.04333)
*Federico Pirola,Fabio Stella,Marco Grzegorczyk*

Main category: cs.LG

TL;DR: 该研究提出了一种新的基于吉布斯采样的动态贝叶斯网络（DBN）学习方法，用于处理纵向临床数据中的缺失值，并能在模拟和真实ICU数据上实现更优的重建精度和收敛性。


<details>
  <summary>Details</summary>
Motivation: 现有处理纵向临床数据缺失值的方法未能充分考虑时间动态性，限制了DBN在医疗保健领域的应用，尤其是在重症监护等需要理解时间动态性的场景中。

Method: 提出了一种新的基于吉布斯采样的DBN学习方法，将缺失值视为高斯分布的未知参数，并在每次迭代中从其完全条件分布中采样，从而实现基于原则的插补和不确定性估计。

Result: 与标准的模型无关技术（如MICE）相比，所提出的贝叶斯方法在模拟数据集和真实重症监护数据上均表现出更优越的重建精度和收敛性。

Conclusion: 该方法通过整合全贝叶斯推断到时间模型中，提供了更可靠的插补和对模型行为更深入的洞察，支持更安全、更明智的临床决策，尤其是在缺失值频繁且可能产生重大影响的场景中。

Abstract: Dynamic Bayesian networks (DBNs) are increasingly used in healthcare due to
their ability to model complex temporal relationships in patient data while
maintaining interpretability, an essential feature for clinical
decision-making. However, existing approaches to handling missing data in
longitudinal clinical datasets are largely derived from static Bayesian
networks literature, failing to properly account for the temporal nature of the
data. This gap limits the ability to quantify uncertainty over time, which is
particularly critical in settings such as intensive care, where understanding
the temporal dynamics is fundamental for model trustworthiness and
applicability across diverse patient groups. Despite the potential of DBNs, a
full Bayesian framework that integrates missing data handling remains
underdeveloped. In this work, we propose a novel Gibbs sampling-based method
for learning DBNs from incomplete data. Our method treats each missing value as
an unknown parameter following a Gaussian distribution. At each iteration, the
unobserved values are sampled from their full conditional distributions,
allowing for principled imputation and uncertainty estimation. We evaluate our
method on both simulated datasets and real-world intensive care data from
critically ill patients. Compared to standard model-agnostic techniques such as
MICE, our Bayesian approach demonstrates superior reconstruction accuracy and
convergence properties. These results highlight the clinical relevance of
incorporating full Bayesian inference in temporal models, providing more
reliable imputations and offering deeper insight into model behavior. Our
approach supports safer and more informed clinical decision-making,
particularly in settings where missing data are frequent and potentially
impactful.

</details>


### [251] [The Illusion of Certainty: Uncertainty quantification for LLMs fails under ambiguity](https://arxiv.org/abs/2511.04418)
*Tim Tomov,Dominik Fuchsgruber,Tom Wollschläger,Stephan Günnemann*

Main category: cs.LG

TL;DR: 现有LLM的UQ方法在处理歧义性数据时表现不佳，需要新的方法来解决这一问题。


<details>
  <summary>Details</summary>
Motivation: 为了在现实世界中可靠地部署LLM，量化其不确定性至关重要，但现有方法在处理固有的语言歧义性时表现不佳。

Method: 引入了首个具有真实答案分布的歧义性问答数据集MAQA*和AmbigQA*，并评估了当前主流的UQ方法在这些数据集上的表现。

Result: 结果显示，现有UQ方法在有歧义的数据上表现急剧下降，接近随机水平，包括基于预测分布、内部表征和模型集成的方法。

Conclusion: 现有UQ方法在处理歧义性数据时存在根本性缺陷，需要重新考虑当前的建模范式。

Abstract: Accurate uncertainty quantification (UQ) in Large Language Models (LLMs) is
critical for trustworthy deployment. While real-world language is inherently
ambiguous, reflecting aleatoric uncertainty, existing UQ methods are typically
benchmarked against tasks with no ambiguity. In this work, we demonstrate that
while current uncertainty estimators perform well under the restrictive
assumption of no ambiguity, they degrade to close-to-random performance on
ambiguous data. To this end, we introduce MAQA* and AmbigQA*, the first
ambiguous question-answering (QA) datasets equipped with ground-truth answer
distributions estimated from factual co-occurrence. We find this performance
deterioration to be consistent across different estimation paradigms: using the
predictive distribution itself, internal representations throughout the model,
and an ensemble of models. We show that this phenomenon can be theoretically
explained, revealing that predictive-distribution and ensemble-based estimators
are fundamentally limited under ambiguity. Overall, our study reveals a key
shortcoming of current UQ methods for LLMs and motivates a rethinking of
current modeling paradigms.

</details>


### [252] [Spurious Correlation-Aware Embedding Regularization for Worst-Group Robustness](https://arxiv.org/abs/2511.04401)
*Subeen Park,Joowang Kim,Hakyung Lee,Sunjae Yoo,Kyungwoo Song*

Main category: cs.LG

TL;DR: 深度学习模型在不同领域表现出色，但易受分布变化影响，尤其是在代表性不足的子群体上。现有方法虽有进展但受限，缺乏连接嵌入空间表示和最差群体误差的理论框架。本文提出 SCER（Spurious Correlation-Aware Embedding Regularization for Worst-Group Robustness），一种直接正则化特征表示以抑制虚假线索的新方法。理论上，最差群体误差受分类器对虚假线索和核心线索依赖程度的影响，而这可以通过群体-域均值嵌入的差异来识别。SCER 在嵌入层面施加理论约束，鼓励模型关注核心特征，减少对虚假模式的敏感性。在多个视觉和语言任务上的评估表明，SCER 在最差群体准确性方面优于现有最先进方法。


<details>
  <summary>Details</summary>
Motivation: 现有深度学习方法在处理分布变化（尤其是在子群体分布变化）时存在不足，缺乏连接嵌入空间表示和最差群体误差的理论基础。

Method: 提出 SCER（Spurious Correlation-Aware Embedding Regularization for Worst-Group Robustness）方法，通过在嵌入层面施加理论约束，直接正则化特征表示以抑制虚假线索，鼓励模型关注核心特征。

Result: SCER 在多个视觉和语言任务上的评估显示，其在最差群体准确性方面优于现有最先进方法。

Conclusion: SCER 通过理论指导的嵌入正则化，有效提高了深度学习模型在子群体分布变化下的鲁棒性，尤其是在最差群体准确性方面。

Abstract: Deep learning models achieve strong performance across various domains but
often rely on spurious correlations, making them vulnerable to distribution
shifts. This issue is particularly severe in subpopulation shift scenarios,
where models struggle in underrepresented groups. While existing methods have
made progress in mitigating this issue, their performance gains are still
constrained. They lack a rigorous theoretical framework connecting the
embedding space representations with worst-group error. To address this
limitation, we propose Spurious Correlation-Aware Embedding Regularization for
Worst-Group Robustness (SCER), a novel approach that directly regularizes
feature representations to suppress spurious cues. We show theoretically that
worst-group error is influenced by how strongly the classifier relies on
spurious versus core directions, identified from differences in group-wise mean
embeddings across domains and classes. By imposing theoretical constraints at
the embedding level, SCER encourages models to focus on core features while
reducing sensitivity to spurious patterns. Through systematic evaluation on
multiple vision and language, we show that SCER outperforms prior
state-of-the-art studies in worst-group accuracy. Our code is available at
\href{https://github.com/MLAI-Yonsei/SCER}{https://github.com/MLAI-Yonsei/SCER}.

</details>


### [253] [Ground-Truth Subgraphs for Better Training and Evaluation of Knowledge Graph Augmented LLMs](https://arxiv.org/abs/2511.04473)
*Alberto Cattaneo,Carlo Luschi,Daniel Justus*

Main category: cs.LG

TL;DR: 该论文提出了SynthKGQA框架，用于从知识图谱生成高质量的合成问答数据集，以解决现有数据集的不足，并用于评估和训练知识图谱检索模型。


<details>
  <summary>Details</summary>
Motivation: 现有知识图谱问答数据集的缺乏阻碍了对不同检索方法的比较和评估，尤其是在LLM事实性提升方面。

Method: 提出SynthKGQA框架，该框架能够从任何知识图谱生成合成问答数据集，并提供完整的事实三元组作为推理依据。将该框架应用于Wikidata生成GTSQA数据集，以测试知识图谱检索模型在零样本泛化能力方面的表现。

Result: SynthKGQA框架不仅能够生成用于基准测试的数据集，还能用于训练性能更优的模型。通过在GTSQA数据集上评估现有模型，揭示了当前知识图谱检索方法的局限性。

Conclusion: SynthKGQA框架为知识图谱问答数据集的生成提供了一种有效的方法，能够促进对知识图谱检索技术的研究和发展，并为训练更强大的知识图谱增强语言模型提供了可能。

Abstract: Retrieval of information from graph-structured knowledge bases represents a
promising direction for improving the factuality of LLMs. While various
solutions have been proposed, a comparison of methods is difficult due to the
lack of challenging QA datasets with ground-truth targets for graph retrieval.
We present SynthKGQA, a framework for generating high-quality synthetic
Knowledge Graph Question Answering datasets from any Knowledge Graph, providing
the full set of ground-truth facts in the KG to reason over each question. We
show how, in addition to enabling more informative benchmarking of KG
retrievers, the data produced with SynthKGQA also allows us to train better
models. We apply SynthKGQA to Wikidata to generate GTSQA, a new dataset
designed to test zero-shot generalization abilities of KG retrievers with
respect to unseen graph structures and relation types, and benchmark popular
solutions for KG-augmented LLMs on it.

</details>


### [254] [On the Equivalence of Regression and Classification](https://arxiv.org/abs/2511.04422)
*Jayadeva,Naman Dwivedi,Hari Krishnan,N. M. Anoop Krishnan*

Main category: cs.LG

TL;DR: 文章建立了回归与分类之间的正式联系，通过将回归问题转化为分类问题，提出了新的回归方法，并引入了“回归度”来衡量数据集回归的难度。


<details>
  <summary>Details</summary>
Motivation: 支持向量回归中使用的边际最大化项“||w||”的理论基础不明确，作者旨在建立回归与分类之间的正式联系，并提出新的回归方法。

Method: 将具有 M 个样本且位于超平面上的回归问题，转化为具有 2M 个样本的线性分类任务。通过在等价的分类任务上进行边际最大化，推导出了不同于传统方法的回归公式。利用该等价关系，提出“回归度”来评估数据集回归的难度，并训练神经网络学习线性化映射。

Result: 文章证明了回归问题与分类问题之间的一一对应关系，提出了新的回归方法，并引入了“回归度”这一新指标。

Conclusion: 通过将回归问题转化为分类问题，可以导出新的回归方法，并且“回归度”可以作为衡量回归难度的有效指标。此外，神经网络可以学习线性化映射，从而解决线性回归问题。

Abstract: A formal link between regression and classification has been tenuous. Even
though the margin maximization term $\|w\|$ is used in support vector
regression, it has at best been justified as a regularizer. We show that a
regression problem with $M$ samples lying on a hyperplane has a one-to-one
equivalence with a linearly separable classification task with $2M$ samples. We
show that margin maximization on the equivalent classification task leads to a
different regression formulation than traditionally used. Using the
equivalence, we demonstrate a ``regressability'' measure, that can be used to
estimate the difficulty of regressing a dataset, without needing to first learn
a model for it. We use the equivalence to train neural networks to learn a
linearizing map, that transforms input variables into a space where a linear
regressor is adequate.

</details>


### [255] [ForecastGAN: A Decomposition-Based Adversarial Framework for Multi-Horizon Time Series Forecasting](https://arxiv.org/abs/2511.04445)
*Syeda Sitara Wishal Fatima,Afshin Rahimi*

Main category: cs.LG

TL;DR: ForecastGAN是一个创新的基于分解的对抗性框架，用于多步时间序列预测，能有效融合数值和分类特征，并在短期预测中超越现有模型。


<details>
  <summary>Details</summary>
Motivation: 现有时间序列预测方法在短期预测和融合分类特征方面存在局限性。

Method: ForecastGAN包含三个模块：分解模块（提取季节性和趋势）、模型选择模块（根据预测范围选择最优模型）和对抗性训练模块（使用条件生成对抗网络增强鲁棒性）。

Result: 在11个基准多元时间序列数据集上，ForecastGAN在短期预测中表现优于最先进的Transformer模型，并在长期预测中保持竞争力。

Conclusion: ForecastGAN提供了一种更具通用性的时间序列预测方法，能够适应特定场景并保持跨数据集的强劲性能，且无需大量超参数调整。

Abstract: Time series forecasting is essential across domains from finance to supply
chain management. This paper introduces ForecastGAN, a novel decomposition
based adversarial framework addressing limitations in existing approaches for
multi-horizon predictions. Although transformer models excel in long-term
forecasting, they often underperform in short-term scenarios and typically
ignore categorical features. ForecastGAN operates through three integrated
modules: a Decomposition Module that extracts seasonality and trend components;
a Model Selection Module that identifies optimal neural network configurations
based on forecasting horizon; and an Adversarial Training Module that enhances
prediction robustness through Conditional Generative Adversarial Network
training. Unlike conventional approaches, ForecastGAN effectively integrates
both numerical and categorical features. We validate our framework on eleven
benchmark multivariate time series datasets that span various forecasting
horizons. The results show that ForecastGAN consistently outperforms
state-of-the-art transformer models for short-term forecasting while remaining
competitive for long-term horizons. This research establishes a more
generalizable approach to time series forecasting that adapts to specific
contexts while maintaining strong performance across diverse data
characteristics without extensive hyperparameter tuning.

</details>


### [256] [Federated Stochastic Minimax Optimization under Heavy-Tailed Noises](https://arxiv.org/abs/2511.04456)
*Xinwen Zhang,Hongchang Gao*

Main category: cs.LG

TL;DR: 本论文研究在重尾梯度噪声下的联邦非凸-PL最小极大优化问题，并提出了两种新算法Fed-NSGDA-M和FedMuon-DA，它们在更温和的条件下能有效处理重尾噪声，并达到了O(1/(TNp)^((s-1)/(2s)))的收敛率，为该领域提供了首个具有严格理论保证的算法，并通过实验验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 重尾噪声在非凸随机优化中越来越受到关注，因为它比标准的有界方差假设更能反映实际情况。本研究旨在解决联邦学习中重尾梯度噪声下的非凸-PL最小极大优化问题。

Method: 提出两种新算法：Fed-NSGDA-M（结合归一化梯度）和FedMuon-DA（利用Muon优化器进行局部更新）。

Result: 理论上证明两种算法的收敛速率为O(1/(TNp)^((s-1)/(2s)))。

Conclusion: Fed-NSGDA-M和FedMuon-DA是首个在重尾噪声下具有严格理论保证的联邦最小极大优化算法，并通过大量实验证明了其有效性。

Abstract: Heavy-tailed noise has attracted growing attention in nonconvex stochastic
optimization, as numerous empirical studies suggest it offers a more realistic
assumption than standard bounded variance assumption. In this work, we
investigate nonconvex-PL minimax optimization under heavy-tailed gradient noise
in federated learning. We propose two novel algorithms: Fed-NSGDA-M, which
integrates normalized gradients, and FedMuon-DA, which leverages the Muon
optimizer for local updates. Both algorithms are designed to effectively
address heavy-tailed noise in federated minimax optimization, under a milder
condition. We theoretically establish that both algorithms achieve a
convergence rate of $O({1}/{(TNp)^{\frac{s-1}{2s}}})$. To the best of our
knowledge, these are the first federated minimax optimization algorithms with
rigorous theoretical guarantees under heavy-tailed noise. Extensive experiments
further validate their effectiveness.

</details>


### [257] [Towards Causal Market Simulators](https://arxiv.org/abs/2511.04469)
*Dennis Thumm,Luis Ontaneda Mijares*

Main category: cs.LG

TL;DR: We propose TNCM-VAE, a novel model that combines VAEs with structural causal models to generate counterfactual financial time series, preserving temporal and causal relationships. Our model outperforms existing approaches in counterfactual probability estimation and enables applications like financial stress testing.


<details>
  <summary>Details</summary>
Motivation: Existing market generators lack causal reasoning for counterfactual analysis and risk assessment. Our method addresses this by incorporating causal constraints.

Method: We develop a Time-series Neural Causal Model VAE (TNCM-VAE) that combines variational autoencoders with structural causal models. Causal constraints are enforced through directed acyclic graphs in the decoder, and training uses causal Wasserstein distance.

Result: Our method demonstrates superior performance in counterfactual probability estimation, achieving L1 distances as low as 0.03-0.10 compared to ground truth on synthetic autoregressive models.

Conclusion: The TNCM-VAE model can generate plausible counterfactual market trajectories that respect underlying causal mechanisms, enabling applications such as financial stress testing, scenario analysis, and enhanced backtesting.

Abstract: Market generators using deep generative models have shown promise for
synthetic financial data generation, but existing approaches lack causal
reasoning capabilities essential for counterfactual analysis and risk
assessment. We propose a Time-series Neural Causal Model VAE (TNCM-VAE) that
combines variational autoencoders with structural causal models to generate
counterfactual financial time series while preserving both temporal
dependencies and causal relationships. Our approach enforces causal constraints
through directed acyclic graphs in the decoder architecture and employs the
causal Wasserstein distance for training. We validate our method on synthetic
autoregressive models inspired by the Ornstein-Uhlenbeck process, demonstrating
superior performance in counterfactual probability estimation with L1 distances
as low as 0.03-0.10 compared to ground truth. The model enables financial
stress testing, scenario analysis, and enhanced backtesting by generating
plausible counterfactual market trajectories that respect underlying causal
mechanisms.

</details>


### [258] [Q3R: Quadratic Reweighted Rank Regularizer for Effective Low-Rank Training](https://arxiv.org/abs/2511.04485)
*Ipsita Ghosh,Ethan Nguyen,Christian Kümmerle*

Main category: cs.LG

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Parameter-efficient training, based on low-rank optimization, has become a
highly successful tool for fine-tuning large deep-learning models. However,
these methods fail at low-rank pre-training tasks where maintaining the
low-rank structure and the objective remains a challenging task. We propose the
Quadratic Reweighted Rank Regularizer dubbed Q3R, which leads to a novel
low-rank inducing training strategy inspired by the iteratively reweighted
least squares (IRLS) framework. Q3R is based on a quadratic regularizer term
which majorizes a smoothed log determinant serving as rank surrogate objective.
Unlike other low-rank training techniques, Q3R is able to train weight matrices
with prescribed, low target ranks of models that achieve comparable predictive
performance as dense models, with small computational overhead, while remaining
fully compatible with existing architectures. For example, we demonstrated one
experiment where we are able to truncate $60\%$ and $80\%$ of the parameters of
a ViT-Tiny model with $~1.3\%$ and $~4\%$ accuracy drop in CIFAR-10 performance
respectively. The efficacy of Q3R is confirmed on Transformers across both
image and language tasks, including for low-rank fine-tuning.

</details>


### [259] [Distribution-Aware Tensor Decomposition for Compression of Convolutional Neural Networks](https://arxiv.org/abs/2511.04494)
*Alper Kalle,Theo Rudkiewicz,Mohamed-Oumar Ouerfelli,Mohamed Tamaazousti*

Main category: cs.LG

TL;DR: 本文提出了一种新颖的基于数据信息范数（而非传统的Frobenius范数）的张量化和低秩表示方法，用于压缩神经网络的权重。该方法通过最小化层输出分布的变化来优化压缩过程，并提出了新的交替最小二乘算法来处理Tucker-2和CPD分解。实验结果表明，该方法无需微调即可达到有竞争力的准确性，并且具有良好的跨数据集迁移能力。


<details>
  <summary>Details</summary>
Motivation: 传统的神经网络压缩方法（如张量化和低秩表示）通常使用Frobenius范数等各向同性范数来寻找低秩近似，但这种方法在函数空间中的误差度量不够精确。因此，需要一种更有效、更能反映实际性能的压缩方法。

Method: 本文提出了一种基于数据信息范数的方法来压缩神经网络权重。具体来说，它通过最小化层输出分布的变化来度量压缩误差，该误差可以表示为 $\lVert (W - \widetilde{W}) \Sigma^{1/2}\rVert_F$，其中 $\Sigma^{1/2}$ 是层输入协方差矩阵的平方根，$W$ 和 $\widetilde{W}$ 分别是原始和压缩后的权重。为了直接优化这个新的范数，作者提出了用于Tucker-2和CPD张量分解的交替最小二乘算法。

Result: 实验结果表明，所提出的数据信息驱动的压缩方法，即使在没有微调的情况下，也常常能达到具有竞争力的准确性。此外，该方法具有良好的跨数据集迁移能力，即在原始训练数据集不可用的情况下，仍能通过将协方差矩阵迁移到新数据集上进行压缩，且准确性仅有轻微下降。该方法在多种CNN架构（ResNet-18/50，GoogLeNet）和数据集（ImageNet，FGVC-Aircraft，Cifar10，Cifar100）上进行了验证，并证实了其优越性。

Conclusion: 本文提出了一种新的、基于数据信息范数的神经网络压缩方法，通过直接优化函数空间中的误差来提高压缩效率和效果。该方法无需微调即可获得良好的性能，并具有跨数据集迁移的能力，为神经网络压缩领域提供了新的视角和有效的解决方案。

Abstract: Neural networks are widely used for image-related tasks but typically demand
considerable computing power. Once a network has been trained, however, its
memory- and compute-footprint can be reduced by compression. In this work, we
focus on compression through tensorization and low-rank representations.
Whereas classical approaches search for a low-rank approximation by minimizing
an isotropic norm such as the Frobenius norm in weight-space, we use
data-informed norms that measure the error in function space. Concretely, we
minimize the change in the layer's output distribution, which can be expressed
as $\lVert (W - \widetilde{W}) \Sigma^{1/2}\rVert_F$ where $\Sigma^{1/2}$ is
the square root of the covariance matrix of the layer's input and $W$,
$\widetilde{W}$ are the original and compressed weights. We propose new
alternating least square algorithms for the two most common tensor
decompositions (Tucker-2 and CPD) that directly optimize the new norm. Unlike
conventional compression pipelines, which almost always require
post-compression fine-tuning, our data-informed approach often achieves
competitive accuracy without any fine-tuning. We further show that the same
covariance-based norm can be transferred from one dataset to another with only
a minor accuracy drop, enabling compression even when the original training
dataset is unavailable. Experiments on several CNN architectures (ResNet-18/50,
and GoogLeNet) and datasets (ImageNet, FGVC-Aircraft, Cifar10, and Cifar100)
confirm the advantages of the proposed method.

</details>


### [260] [Alternative Fairness and Accuracy Optimization in Criminal Justice](https://arxiv.org/abs/2511.04505)
*Shaolong Wu,James Blume,Geshi Yeung*

Main category: cs.LG

TL;DR: 该研究在算法公平性领域，特别是在刑事司法背景下，提出了一个修改后的群体公平性方法，通过最小化加权误差损失并在误报率差异保持在小容差范围内，来解决现有概念的不确定性，同时考虑了数据偏见、潜在的积极行动和子群体约束等批评，并最终提供了一个包含需求驱动决策、透明度问责以及狭义定义和解决方案三支柱的实用部署框架，旨在将技术设计与合法性联系起来，为风险评估工具的使用提供指导。


<details>
  <summary>Details</summary>
Motivation: 算法公平性，特别是刑事司法领域的概念尚不明确，现有方法存在局限性。

Method: 提出一种修改的标准群体公平性方法，通过最小化加权误差损失并限制假阴性率的差异来解决问题。并考虑了数据偏见、潜在的积极行动和子群体约束等批评。最后，提供了一个包含需求驱动决策、透明度问责以及狭义定义和解决方案三支柱的实用部署框架。

Result: 修改后的方法更容易找到解决方案，可以提高预测准确性，并突出了错误成本的伦理选择。提出的框架将技术设计与合法性联系起来，为公共决策系统提供了可操作的指导。

Conclusion: 提出的修改后的群体公平性方法和实用部署框架能够为刑事司法等领域的算法公平性提供更实际、更合法的解决方案，并能提高预测准确性。

Abstract: Algorithmic fairness has grown rapidly as a research area, yet key concepts
remain unsettled, especially in criminal justice. We review group, individual,
and process fairness and map the conditions under which they conflict. We then
develop a simple modification to standard group fairness. Rather than exact
parity across protected groups, we minimize a weighted error loss while keeping
differences in false negative rates within a small tolerance. This makes
solutions easier to find, can raise predictive accuracy, and surfaces the
ethical choice of error costs. We situate this proposal within three classes of
critique: biased and incomplete data, latent affirmative action, and the
explosion of subgroup constraints. Finally, we offer a practical framework for
deployment in public decision systems built on three pillars: need-based
decisions, Transparency and accountability, and narrowly tailored definitions
and solutions. Together, these elements link technical design to legitimacy and
provide actionable guidance for agencies that use risk assessment and related
tools.

</details>


### [261] [Linear Mode Connectivity under Data Shifts for Deep Ensembles of Image Classifiers](https://arxiv.org/abs/2511.04514)
*C. Hepburn,T. Zielke,A. P. Raulf*

Main category: cs.LG

TL;DR: 线性模式连通性（LMC）在数据迁移下会受到影响，但可以通过减小学习率和增大批次大小来缓解。LMC有助于在训练效率和模型多样性之间取得平衡。


<details>
  <summary>Details</summary>
Motivation: 研究数据迁移对深度学习中线性模式连通性（LMC）的影响，并找出缓解这些影响的条件。

Method: 将数据迁移视为梯度噪声的来源，并研究小学习率和大批次大小如何影响模型的收敛和损失 landscape 的平滑度。

Result: 数据迁移会影响LMC，但可以通过小学习率和大批次大小来缓解。这些参数影响模型是收敛到相同的局部最小值还是不同的、具有不同平滑度和泛化能力的区域。LMC 采样的模型倾向于犯相同的错误，但 LMC 的好处在于平衡训练效率和获得更大、更多样化集成的好处。

Conclusion: LMC 在数据迁移下仍有价值，因为它能在训练效率和模型多样性之间取得平衡。

Abstract: The phenomenon of linear mode connectivity (LMC) links several aspects of
deep learning, including training stability under noisy stochastic gradients,
the smoothness and generalization of local minima (basins), the similarity and
functional diversity of sampled models, and architectural effects on data
processing. In this work, we experimentally study LMC under data shifts and
identify conditions that mitigate their impact. We interpret data shifts as an
additional source of stochastic gradient noise, which can be reduced through
small learning rates and large batch sizes. These parameters influence whether
models converge to the same local minimum or to regions of the loss landscape
with varying smoothness and generalization. Although models sampled via LMC
tend to make similar errors more frequently than those converging to different
basins, the benefit of LMC lies in balancing training efficiency against the
gains achieved from larger, more diverse ensembles. Code and supplementary
materials will be made publicly available at https://github.com/DLR-KI/LMC in
due course.

</details>


### [262] [End-to-End Reinforcement Learning of Koopman Models for eNMPC of an Air Separation Unit](https://arxiv.org/abs/2511.04522)
*Daniel Mayfrank,Kayra Dernek,Laura Lang,Alexander Mitsos,Manuel Dahmen*

Main category: cs.LG

TL;DR: 该研究将一种基于强化学习的Koopman模型训练方法应用于大规模化工过程（氮气空气分离装置）的需求响应控制问题，并取得了与传统方法相当的经济效益，同时避免了约束违规。


<details>
  <summary>Details</summary>
Motivation: 验证所提出的基于强化学习的Koopman模型训练方法能够很好地扩展到大规模非线性模型预测控制（eNMPC）应用，并解决实际中的约束问题。

Method: 将基于强化学习的Koopman模型训练方法应用于一个大规模的氮气空气分离装置的需求响应案例研究，并与纯粹基于系统辨识的Koopman eNMPC方法进行比较，同时只假设少量可测量变量。

Result: 所提出的方法在保持与纯粹基于系统辨识的Koopman eNMPC相当的经济效益的同时，成功避免了约束违规。纯粹基于系统辨识的方法虽然也能带来一定的经济效益，但频繁出现约束违规。

Conclusion: 基于强化学习的Koopman模型训练方法能够有效地应用于大规模化工过程的eNMPC，并且在经济效益和约束满足方面都表现出色。

Abstract: With our recently proposed method based on reinforcement learning (Mayfrank
et al. (2024), Comput. Chem. Eng. 190), Koopman surrogate models can be trained
for optimal performance in specific (economic) nonlinear model predictive
control ((e)NMPC) applications. So far, our method has exclusively been
demonstrated on a small-scale case study. Herein, we show that our method
scales well to a more challenging demand response case study built on a
large-scale model of a single-product (nitrogen) air separation unit. Across
all numerical experiments, we assume observability of only a few realistically
measurable plant variables. Compared to a purely system identification-based
Koopman eNMPC, which generates small economic savings but frequently violates
constraints, our method delivers similar economic performance while avoiding
constraint violations.

</details>


### [263] [Uncertainty Quantification for Reduced-Order Surrogate Models Applied to Cloud Microphysics](https://arxiv.org/abs/2511.04534)
*Jonas E. Katona,Emily K. de Jong,Nipun Gunawardena*

Main category: cs.LG

TL;DR: 我们提出了一种模型无关的后处理框架，使用共形预测来量化潜空间降阶模型（ROM）中的预测不确定性，该框架可以应用于潜空间动力学、重构和端到端预测。


<details>
  <summary>Details</summary>
Motivation: 现有的降阶模型（ROM）缺乏鲁棒的不确定性量化方法，并且经常受限于特定的架构或训练过程。

Method: 使用共形预测，作为一种后处理、模型无关的框架，来估计ROM管道中潜空间动力学、重构和端到端预测的统计预测区间。

Result: 该方法在云微物理潜空间动力学模型上得到了验证，能够准确预测液滴尺寸分布的演变，并量化了整个ROM管道中的不确定性。

Conclusion: 所提出的方法可以有效地量化潜空间降阶模型中的预测不确定性，而无需修改底层架构或训练过程。

Abstract: Reduced-order models (ROMs) can efficiently simulate high-dimensional
physical systems, but lack robust uncertainty quantification methods. Existing
approaches are frequently architecture- or training-specific, which limits
flexibility and generalization. We introduce a post hoc, model-agnostic
framework for predictive uncertainty quantification in latent space ROMs that
requires no modification to the underlying architecture or training procedure.
Using conformal prediction, our approach estimates statistical prediction
intervals for multiple components of the ROM pipeline: latent dynamics,
reconstruction, and end-to-end predictions. We demonstrate the method on a
latent space dynamical model for cloud microphysics, where it accurately
predicts the evolution of droplet-size distributions and quantifies uncertainty
across the ROM pipeline.

</details>


### [264] [Integrating Temporal and Structural Context in Graph Transformers for Relational Deep Learning](https://arxiv.org/abs/2511.04557)
*Divyansha Lachi,Mahmoud Mohammadi,Joe Meyer,Vinam Arora,Tom Palczewski,Eva L. Dyer*

Main category: cs.LG

TL;DR: 本研究提出了关系图感知器（RGP），一种新的图转换器架构，用于整合时空依赖关系和多种预测任务，并在多个数据集上取得了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的图模型在处理关系数据时，主要关注空间结构，忽略了时间信息，并且通常只支持单一预测任务。本研究旨在解决这些不足，以整合长期的空间和时间依赖关系，并支持多任务预测。

Method: 研究提出了一个时间子图采样器来捕捉时间相关的关系，并引入了关系图感知器（RGP），一种利用跨注意力机制的图转换器架构，来整合结构和时间信息。RGP还包含一个灵活的跨注意力解码器，支持在单个模型中进行多任务联合学习。

Result: 在RelBench、SALT和CTU数据集上的实验表明，RGP取得了最先进的性能。

Conclusion: RGP为关系深度学习提供了一个通用且可扩展的解决方案，能够有效整合时空依赖关系并支持多种预测任务。

Abstract: In domains such as healthcare, finance, and e-commerce, the temporal dynamics
of relational data emerge from complex interactions-such as those between
patients and providers, or users and products across diverse categories. To be
broadly useful, models operating on these data must integrate long-range
spatial and temporal dependencies across diverse types of entities, while also
supporting multiple predictive tasks. However, existing graph models for
relational data primarily focus on spatial structure, treating temporal
information merely as a filtering constraint to exclude future events rather
than a modeling signal, and are typically designed for single-task prediction.
To address these gaps, we introduce a temporal subgraph sampler that enhances
global context by retrieving nodes beyond the immediate neighborhood to capture
temporally relevant relationships. In addition, we propose the Relational Graph
Perceiver (RGP), a graph transformer architecture for relational deep learning
that leverages a cross-attention-based latent bottleneck to efficiently
integrate information from both structural and temporal contexts. This latent
bottleneck integrates signals from different node and edge types into a common
latent space, enabling the model to build global context across the entire
relational system. RGP also incorporates a flexible cross-attention decoder
that supports joint learning across tasks with disjoint label spaces within a
single model. Experiments on RelBench, SALT, and CTU show that RGP delivers
state-of-the-art performance, offering a general and scalable solution for
relational deep learning with support for diverse predictive tasks.

</details>


### [265] [ARETE: an R package for Automated REtrieval from TExt with large language models](https://arxiv.org/abs/2511.04573)
*Vasco V. Branco,Jandó Benedek,Lidia Pivovarova,Luís Correia,Pedro Cardoso*

Main category: cs.LG

TL;DR: 该研究提出了一种名为ARETE的R包，利用大型语言模型（如ChatGPT API）自动化提取物种分布数据，解决了关键物种数据缺失和数据处理速度慢的问题。


<details>
  <summary>Details</summary>
Motivation: 关键物种数据（尤其是分布数据）的缺失是实施严格保护措施的主要障碍，而人类活动又加速了数据收集和处理的需求。现有文献中的数据往往难以被机器读取，需要大量人工处理。

Method: 开发了一个名为ARETE的R包，集成了从光学字符识别到异常值检测和表格输出的整个数据提取和验证流程。该方法利用大型语言模型（如ChatGPT API）来自动化提取物种分布数据。

Result: 通过将ARETE提取的数据与人类标注者进行系统比较来验证其有效性。将ARETE提取的100种蜘蛛数据与GBIF数据生成的分布图进行比较，结果显示自动提取的数据显著扩展了已知的物种分布范围（平均扩展三个数量级），发现了新的物种分布区域。

Conclusion: ARETE能够更快地获取以往无法获取的物种分布数据，这对于需要此类数据的项目来说可能是一个重要的改变。研究人员可以更有效地分配资源，手动验证选定的物种，同时自动化处理大部分数据提取工作。该工作流程还可以预测项目规划中可用的文献数据。

Abstract: 1. A hard stop for the implementation of rigorous conservation initiatives is
our lack of key species data, especially occurrence data. Furthermore,
researchers have to contend with an accelerated speed at which new information
must be collected and processed due to anthropogenic activity. Publications
ranging from scientific papers to gray literature contain this crucial
information but their data are often not machine-readable, requiring extensive
human work to be retrieved. 2. We present the ARETE R package, an open-source
software aiming to automate data extraction of species occurrences powered by
large language models, namely using the chatGPT Application Programming
Interface. This R package integrates all steps of the data extraction and
validation process, from Optical Character Recognition to detection of outliers
and output in tabular format. Furthermore, we validate ARETE through systematic
comparison between what is modelled and the work of human annotators. 3. We
demonstrate the usefulness of the approach by comparing range maps produced
using GBIF data and with those automatically extracted for 100 species of
spiders. Newly extracted data allowed to expand the known Extent of Occurrence
by a mean three orders of magnitude, revealing new areas where the species were
found in the past, which mayhave important implications for spatial
conservation planning and extinction risk assessments. 4. ARETE allows faster
access to hitherto untapped occurrence data, a potential game changer in
projects requiring such data. Researchers will be able to better prioritize
resources, manually verifying selected species while maintaining automated
extraction for the majority. This workflow also allows predicting available
bibliographic data during project planning.

</details>


### [266] [Complexity as Advantage: A Regret-Based Perspective on Emergent Structure](https://arxiv.org/abs/2511.04590)
*Oshri Naparstek*

Main category: cs.LG

TL;DR: 该研究提出了复杂性即优势（CAA）框架，该框架将系统的复杂性定义为相对于一组观察者的属性。


<details>
  <summary>Details</summary>
Motivation: CAA框架旨在量化复杂性，将复杂性定义为系统为不同观察者造成的预测性遗憾，而不是其内在属性。

Method: 该框架通过量化不同观察者在尝试模拟系统时产生的预测性遗憾来评估系统的复杂性。

Result: 研究表明，CAA框架统一了涌现行为的多种概念，如多尺度熵和预测信息，并表明“有趣的”系统能够为不同观察者带来差异化的遗憾。

Conclusion: 复杂性可以被视为一种优势，因为它可以为不同观察者创造信息优势，这为复杂性在学习、进化和人工智能中的功能价值提供了量化基础。

Abstract: We introduce Complexity as Advantage (CAA), a framework that defines the
complexity of a system relative to a family of observers. Instead of measuring
complexity as an intrinsic property, we evaluate how much predictive regret a
system induces for different observers attempting to model it. A system is
complex when it is easy for some observers and hard for others, creating an
information advantage. We show that this formulation unifies several notions of
emergent behavior, including multiscale entropy, predictive information, and
observer-dependent structure. The framework suggests that "interesting" systems
are those positioned to create differentiated regret across observers,
providing a quantitative grounding for why complexity can be functionally
valuable. We demonstrate the idea through simple dynamical models and discuss
implications for learning, evolution, and artificial agents.

</details>


### [267] [Environment Agnostic Goal-Conditioning, A Study of Reward-Free Autonomous Learning](https://arxiv.org/abs/2511.04598)
*Hampus Åström,Elin Anna Topp,Jacek Malec*

Main category: cs.LG

TL;DR: 通过将奖励塑造成目标，实现自主无监督强化学习。


<details>
  <summary>Details</summary>
Motivation: 研究如何将常规强化学习环境转化为目标条件环境，使智能体能够自主且无奖励地解决任务。

Method: 将环境转化为目标条件环境，使智能体能够自主选择目标。该方法独立于底层离策略学习算法，并且是环境不可知。

Result: 智能体可以在与外部引导的强化学习相当的训练时间内学会解决任务。虽然单个目标性能存在不稳定性，但平均目标成功率有所提高并趋于稳定。

Conclusion: 所提出的方法可以指导智能体寻求环境中进行的任何观察，从而实现通用智能体训练，以适应特定用例。

Abstract: In this paper we study how transforming regular reinforcement learning
environments into goal-conditioned environments can let agents learn to solve
tasks autonomously and reward-free. We show that an agent can learn to solve
tasks by selecting its own goals in an environment-agnostic way, at training
times comparable to externally guided reinforcement learning. Our method is
independent of the underlying off-policy learning algorithm. Since our method
is environment-agnostic, the agent does not value any goals higher than others,
leading to instability in performance for individual goals. However, in our
experiments, we show that the average goal success rate improves and
stabilizes. An agent trained with this method can be instructed to seek any
observations made in the environment, enabling generic training of agents prior
to specific use cases.

</details>


### [268] [Addressing divergent representations from causal interventions on neural networks](https://arxiv.org/abs/2511.04638)
*Satchel Grant,Simon Jerome Han,Alexa Tartaglini,Christopher Potts*

Main category: cs.LG

TL;DR: 干预措施可能会导致模型内部表征发生分布外偏移，从而影响解释的忠实度。研究提出了区分‘无害’和‘有害’偏移的方法，并改进了CL损失函数以减少有害偏移，从而提高解释方法的可靠性。


<details>
  <summary>Details</summary>
Motivation: 探究模型表征的因果干预是否会产生分布外（发散）表征，以及这是否会影响解释的忠实度。

Method: 首先，通过实证证明常见的因果干预技术确实会使内部表征偏离目标模型的自然分布。然后，对两种发散进行了理论分析：发生在权重零空间和行为决策边界协方差内的‘无害’发散；激活隐藏网络通路并导致行为改变的‘有害’发散。最后，通过改进CL损失函数来减少有害发散。

Result: 发现常见的因果干预技术确实会使内部表征偏离目标模型的自然分布。区分了‘无害’和‘有害’发散。改进的CL损失函数能够减少有害发散的可能性，同时保留干预的解释力。

Conclusion: 干预措施可能导致模型表征的分布外偏移，但通过区分不同类型的偏移并改进干预技术，可以提高模型解释的可靠性。

Abstract: A common approach to mechanistic interpretability is to causally manipulate
model representations via targeted interventions in order to understand what
those representations encode. Here we ask whether such interventions create
out-of-distribution (divergent) representations, and whether this raises
concerns about how faithful their resulting explanations are to the target
model in its natural state. First, we demonstrate empirically that common
causal intervention techniques often do shift internal representations away
from the natural distribution of the target model. Then, we provide a
theoretical analysis of two classes of such divergences: `harmless' divergences
that occur in the null-space of the weights and from covariance within
behavioral decision boundaries, and `pernicious' divergences that activate
hidden network pathways and cause dormant behavioral changes. Finally, in an
effort to mitigate the pernicious cases, we modify the Counterfactual Latent
(CL) loss from Grant (2025) that regularizes interventions to remain closer to
the natural distributions, reducing the likelihood of harmful divergences while
preserving the interpretive power of interventions. Together, these results
highlight a path towards more reliable interpretability methods.

</details>


### [269] [Efficient probabilistic surrogate modeling techniques for partially-observed large-scale dynamical systems](https://arxiv.org/abs/2511.04641)
*Hans Harder,Abhijeet Vishwasrao,Luca Guastoni,Ricardo Vinuesa,Sebastian Peitz*

Main category: cs.LG

TL;DR: 该论文研究了用于预测偏微分方程（如 Navier-Stokes 方程）描述的动力学系统的概率技术，并比较了减少采样步骤的流匹配范例的各种扩展，包括直接蒸馏、渐进蒸馏、对抗性扩散蒸馏、Wasserstein GAN 和修正流。


<details>
  <summary>Details</summary>
Motivation: 该论文旨在研究和比较用于预测偏微分方程描述的动力学系统的流匹配范例的各种扩展，以减少采样步骤。

Method: 比较了直接蒸馏、渐进蒸馏、对抗性扩散蒸馏、Wasserstein GAN 和修正流等流匹配范例的扩展。

Result: 在具有挑战性的系统上进行了实验，并解决了直接预测大型 3D 模拟的 2D 切片的问题。

Conclusion: 该研究为高效的流入生成求解器铺平了道路。

Abstract: This paper is concerned with probabilistic techniques for forecasting
dynamical systems described by partial differential equations (such as, for
example, the Navier-Stokes equations). In particular, it is investigating and
comparing various extensions to the flow matching paradigm that reduce the
number of sampling steps. In this regard, it compares direct distillation,
progressive distillation, adversarial diffusion distillation, Wasserstein GANs
and rectified flows. Moreover, experiments are conducted on a set of
challenging systems. In particular, we also address the challenge of directly
predicting 2D slices of large-scale 3D simulations, paving the way for
efficient inflow generation for solvers.

</details>


### [270] [Optimal Inference Schedules for Masked Diffusion Models](https://arxiv.org/abs/2511.04647)
*Sitan Chen,Kevin Cong,Jerry Li*

Main category: cs.LG

TL;DR: MDM模型在并行采样方面存在理论理解不足的问题，本文提供了新的理论界限和采样方法。


<details>
  <summary>Details</summary>
Motivation: 现有MDM模型在并行采样能力方面缺乏严格的理论分析，导致对采样性能下降的界限不明确。

Method: 通过连接到单变量函数逼近理论，精确表征了真实分布与采样分布之间的期望散度，并据此推导了新的上下界。

Result: 在某些自然分布情况下，可以通过信息论性质（如总相关和对偶总相关）实现O(log n)步采样，而不会显著降低性能。

Conclusion: 虽然理论上存在最优解，但在实际应用中，要达到最优解需要对分布有很强的先验知识。但新的采样方法和理论界限在某些情况下可以实现高效采样。

Abstract: A major bottleneck of standard auto-regressive large language models is that
their inference process is inherently sequential, resulting in very long and
costly inference times. To circumvent this, practitioners proposed a class of
language models called diffusion language models, of which the masked diffusion
model (MDM) is the most successful. The MDM is able to sample tokens
out-of-order and, ostensibly, many tokens at once and in parallel. However,
there is very limited rigorous understanding of how much parallel sampling
these models can perform without noticeable degradation in their sampling
performance. Prior work of Li and Cai obtained some preliminary bounds, but
these are not tight for many natural classes of distributions. In this work, we
give a new, exact characterization of the expected divergence between the true
distribution and the sampled distribution, for any distribution and any
unmasking schedule for the sampler, showing an elegant connection to the theory
of univariate function approximation.
  By leveraging this connection, we then attain a number of novel lower and
upper bounds for this problem. While the connection to function approximation
in principle gives the optimal unmasking schedule for any distribution, we show
that it is in general impossible to compete with it without strong a priori
knowledge of the distribution, even in seemingly benign settings. However, we
also demonstrate new upper bounds and new sampling schedules in terms of
well-studied information-theoretic properties of the base distribution, namely,
its total correlation and dual total correlation, which show that in some
natural settings, one can sample in $O(log n)$ steps without any visible loss
in performance, where $n$ is the total sequence length.

</details>


### [271] [TT-Prune: Joint Model Pruning and Resource Allocation for Communication-efficient Time-triggered Federated Learning](https://arxiv.org/abs/2511.04653)
*Xinlu Zhang,Yansha Deng,Toktam Mahmoodi*

Main category: cs.LG

TL;DR: TT-Fed 通过引入自适应模型剪枝来解决无线通信中的模型剪枝和带宽分配问题，从而降低通信成本并保持模型性能。


<details>
  <summary>Details</summary>
Motivation: 随着用户设备数量的增加和无线带宽的限制，传统的联邦学习（FL）网络面临着“慢启动”和通信开销过大的问题。TT-Fed 提出了一种基于时间触发的联邦学习方法，但仍需解决通信成本和学习延迟的问题。

Method: 本文将自适应模型剪枝引入无线 TT-Fed 系统，并联合优化剪枝率和带宽分配，以最小化训练损失并确保学习延迟。通过对 TT-Fed 模型梯度 L2 范数进行收敛性分析，并利用 KKT 条件推导出无线带宽和剪枝率的闭式解。

Result: 模拟结果表明，模型剪枝可以将通信成本降低 40%，同时保持模型性能不变。

Conclusion: 通过联合优化剪枝率和带宽分配，TT-Fed 系统在保持模型性能的同时，显著降低了通信成本和学习延迟。

Abstract: Federated learning (FL) offers new opportunities in machine learning,
particularly in addressing data privacy concerns. In contrast to conventional
event-based federated learning, time-triggered federated learning (TT-Fed), as
a general form of both asynchronous and synchronous FL, clusters users into
different tiers based on fixed time intervals. However, the FL network consists
of a growing number of user devices with limited wireless bandwidth,
consequently magnifying issues such as stragglers and communication overhead.
In this paper, we introduce adaptive model pruning to wireless TT-Fed systems
and study the problem of jointly optimizing the pruning ratio and bandwidth
allocation to minimize the training loss while ensuring minimal learning
latency. To answer this question, we perform convergence analysis on the
gradient l_2 norm of the TT-Fed model based on model pruning. Based on the
obtained convergence upper bound, a joint optimization problem of pruning ratio
and wireless bandwidth is formulated to minimize the model training loss under
a given delay threshold. Then, we derive closed-form solutions for wireless
bandwidth and pruning ratio using Karush-Kuhn-Tucker(KKT) conditions. The
simulation results show that model pruning could reduce the communication cost
by 40% while maintaining the model performance at the same level.

</details>


### [272] [Nowcast3D: Reliable precipitation nowcasting via gray-box learning](https://arxiv.org/abs/2511.04659)
*Huaguan Chen,Wei Han,Haofei Sun,Ning Lin,Xingtao Song,Yunfan Yang,Jie Tian,Yang Liu,Ji-Rong Wen,Xiaoye Zhang,Xueshun Shen,Hao Sun*

Main category: cs.LG

TL;DR: 该研究提出了一种三维雷达数据驱动的极端降水临近预报模型，通过结合物理约束和数据驱动的方法，提高了预报的准确性和领先时间。


<details>
  <summary>Details</summary>
Motivation: 现有的临近预报方法在时空精度和预报领先时间方面存在局限性，无法满足对快速演变对流的准确预报需求。

Method: 提出了一种灰盒模型，直接处理三维雷达反射率数据，并结合了物理约束的神经算子和数据驱动学习。模型学习垂直变化的平流场，参数化空间变化的扩散，并引入随机项来表示未解析的运动。残差分支捕捉小尺度对流和微物理变异性，不确定性通过基于扩散的随机模块估计。

Result: 该框架在长达三小时的预报时间内，在不同降水情景下均取得了更准确的预报，并在盲测中获得气象学家的广泛认可，在57%的情况下排名第一。

Conclusion: 通过恢复具有物理一致性的全三维动力学，该框架为实现高技能和可靠的极端降水临近预报提供了一条可扩展且稳健的途径。

Abstract: Extreme precipitation nowcasting demands high spatiotemporal fidelity and
extended lead times, yet existing approaches remain limited. Numerical Weather
Prediction (NWP) and its deep-learning emulations are too slow and coarse for
rapidly evolving convection, while extrapolation and purely data-driven models
suffer from error accumulation and excessive smoothing. Hybrid 2D radar-based
methods discard crucial vertical information, preventing accurate
reconstruction of height-dependent dynamics. We introduce a gray-box, fully
three-dimensional nowcasting framework that directly processes volumetric radar
reflectivity and couples physically constrained neural operators with
datadriven learning. The model learns vertically varying 3D advection fields
under a conservative advection operator, parameterizes spatially varying
diffusion, and introduces a Brownian-motion--inspired stochastic term to
represent unresolved motions. A residual branch captures small-scale convective
initiation and microphysical variability, while a diffusion-based stochastic
module estimates uncertainty. The framework achieves more accurate forecasts up
to three-hour lead time across precipitation regimes and ranked first in 57\%
of cases in a blind evaluation by 160 meteorologists. By restoring full 3D
dynamics with physical consistency, it offers a scalable and robust pathway for
skillful and reliable nowcasting of extreme precipitation.

</details>


### [273] [Forgetting is Everywhere](https://arxiv.org/abs/2511.04666)
*Ben Sanati,Thomas L. Lee,Trevor McInroe,Aidan Scannell,Nikolay Malkin,David Abel,Amos Storkey*

Main category: cs.LG

TL;DR: 该理论提出了一种算法无关的理论，将遗忘定义为学习者预测分布的自我不一致性，从而产生了一种衡量遗忘倾向的通用度量方法。


<details>
  <summary>Details</summary>
Motivation: 为了应对通用学习算法在适应新数据时容易遗忘过去知识的挑战，需要对遗忘有原则性的理解，但目前缺乏统一的定义。

Method: 提出了一种算法无关的理论，将遗忘定义为学习者预测分布的自我不一致性，表现为预测信息量的损失，并由此推导出衡量遗忘倾向的通用度量方法。

Result: 通过在分类、回归、生成模型和强化学习等多个领域进行的大规模实验，验证了该理论。实验表明，遗忘存在于所有学习设置中，并显著影响学习效率。

Conclusion: 该理论为理解遗忘提供了原则性的基础，并为分析和改进通用学习算法的信息保留能力奠定了基础。

Abstract: A fundamental challenge in developing general learning algorithms is their
tendency to forget past knowledge when adapting to new data. Addressing this
problem requires a principled understanding of forgetting; yet, despite decades
of study, no unified definition has emerged that provides insights into the
underlying dynamics of learning. We propose an algorithm- and task-agnostic
theory that characterises forgetting as a lack of self-consistency in a
learner's predictive distribution over future experiences, manifesting as a
loss of predictive information. Our theory naturally yields a general measure
of an algorithm's propensity to forget. To validate the theory, we design a
comprehensive set of experiments that span classification, regression,
generative modelling, and reinforcement learning. We empirically demonstrate
how forgetting is present across all learning settings and plays a significant
role in determining learning efficiency. Together, these results establish a
principled understanding of forgetting and lay the foundation for analysing and
improving the information retention capabilities of general learning
algorithms.

</details>


### [274] [Multi-Method Analysis of Mathematics Placement Assessments: Classical, Machine Learning, and Clustering Approaches](https://arxiv.org/abs/2511.04667)
*Julian D. Allagan,Dasia A. Singleton,Shanae N. Perry,Gabrielle C. Morgan,Essence A. Morgan*

Main category: cs.LG

TL;DR: 本研究使用经典测试理论、机器学习和无监督聚类相结合的多方法框架，评估了一个包含40个问题的数学分班考试，该考试对198名学生进行了测试。经典测试理论分析显示，55%的题目区分度优良（D≥0.40），而30%的题目区分度较差（D<0.20），需要更换。问题6（图表解读）成为考试中最具区分度的题目，其区分度（D=1.000）、ANOVA F统计量（F=4609.1）和随机森林特征重要性（0.206）均达到最高，占预测能力的20.6%。机器学习算法表现卓越，随机森林和梯度提升的交叉验证准确率分别为97.5%和96.0%。K-means聚类识别出自然的二元能力结构，边界设在42.5%，这与机构设定的55%的阈值不同，表明可能存在过度分级到补习类别的问题。两簇解表现出极高的稳定性（bootstrap ARI = 0.855），且较低簇的纯度完美。跨方法的一致性证据支持具体的改进建议：更换区分度差的题目、实施两阶段评估以及将随机森林预测与透明度机制相结合。这些发现表明，多方法集成为了基于证据的数学分班优化提供了坚实的实证基础。


<details>
  <summary>Details</summary>
Motivation: 本研究的动机在于通过结合经典测试理论、机器学习和无监督聚类方法，对一项数学分班考试进行全面评估，以优化学生分班的准确性和效率。

Method: 本研究采用了多方法框架，结合了经典测试理论（CTT）、机器学习（如随机森林、梯度提升）和无监督聚类（K-means）来分析一个40题的数学分班考试数据。CTT用于评估题目质量和区分度；机器学习算法用于预测学生表现；K-means聚类用于识别学生能力结构。最后，整合跨方法的结果以提出改进建议。

Result: 本研究通过经典测试理论分析发现，55%的题目区分度良好，但30%的题目区分度较差。问题6（图表解读）是区分度最高的题目。机器学习模型（随机森林和梯度提升）的交叉验证准确率分别达到97.5%和96.0%。K-means聚类识别出学生能力存在一个42.5%的二元结构边界，与机构的55%阈值不同，暗示可能存在过度分级。两簇解的稳定性极高（bootstrap ARI = 0.855）。

Conclusion: 本研究通过整合经典测试理论、机器学习和聚类分析，为优化数学分班考试提供了强有力的实证支持。研究结果表明，应更换区分度低的题目，实施两阶段评估，并考虑结合随机森林预测结果，以提高分班的准确性和效率，避免不必要的补习分级。

Abstract: This study evaluates a 40-item mathematics placement examination administered
to 198 students using a multi-method framework combining Classical Test Theory,
machine learning, and unsupervised clustering. Classical Test Theory analysis
reveals that 55\% of items achieve excellent discrimination ($D \geq 0.40$)
while 30\% demonstrate poor discrimination ($D < 0.20$) requiring replacement.
Question 6 (Graph Interpretation) emerges as the examination's most powerful
discriminator, achieving perfect discrimination ($D = 1.000$), highest ANOVA
F-statistic ($F = 4609.1$), and maximum Random Forest feature importance
(0.206), accounting for 20.6\% of predictive power. Machine learning algorithms
demonstrate exceptional performance, with Random Forest and Gradient Boosting
achieving 97.5\% and 96.0\% cross-validation accuracy. K-means clustering
identifies a natural binary competency structure with a boundary at 42.5\%,
diverging from the institutional threshold of 55\% and suggesting potential
overclassification into remedial categories. The two-cluster solution exhibits
exceptional stability (bootstrap ARI = 0.855) with perfect lower-cluster
purity. Convergent evidence across methods supports specific refinements:
replace poorly discriminating items, implement a two-stage assessment, and
integrate Random Forest predictions with transparency mechanisms. These
findings demonstrate that multi-method integration provides a robust empirical
foundation for evidence-based mathematics placement optimization.

</details>


<div id='quant-ph'></div>

# quant-ph [[Back]](#toc)

### [275] [Boltzmann Sampling of Frustrated J1 - J2 Ising Models with Programmable Quantum Annealers](https://arxiv.org/abs/2511.03796)
*Elijah Pelofske*

Main category: quant-ph

TL;DR: D-Wave量子退火器在模拟伊辛模型（ANNNI模型）的玻尔兹曼分布方面表现出高精度，特别是在存在磁挫动的区域，这表明了其在热力学采样应用中的潜力。


<details>
  <summary>Details</summary>
Motivation: 研究D-Wave量子退火器从经典哈密顿量定义的玻尔兹曼或吉布斯分布中采样的能力，特别是针对具有竞争性磁挫动的ANNNI模型。

Method: 通过在两种不同的D-Wave量子退火处理器上，使用从5纳秒到2000微秒的标准线性斜坡退火，量化ANNNI模型的玻尔兹曼采样误差率。

Result: 在ANNNI模型的磁相图中，发现在某些模拟硬件参数下，D-Wave量子退火器能够以非常高的精度（TVD低至0.0003）和低温（β高达32.2）进行采样，尤其是在存在磁挫动的区域。

Conclusion: 该研究结果支持了当前模拟量子计算机在高度磁挫动自旋系统的热力学采样应用方面的可行性。

Abstract: One of the surprising, and potentially very useful, capabilities of analog
quantum computers, such as D-Wave quantum annealers, is sampling from the
Boltzmann, or Gibbs, distribution defined by a classical Hamiltonian. In this
study, we thoroughly examine the ability of D-Wave quantum annealers to sample
from the Boltzmann distribution defined of a canonical type of competing
magnetic frustration $J_1$-$J_2$ model; the ANNNI (axial next-nearest-neighbor
Ising) model. Boltzmann sampling error rate is quantified for standard
linear-ramp anneals ranging from $5$ nanosecond annealing times up to $2000$
microseconds on two different D-Wave quantum annealing processors.
Interestingly, we find some analog hardware parameters which result in a very
high accuracy (down to a TVD of $0.0003$) and low temperature sampling (down to
$\beta=32.2$) in a frustrated region of the ANNNI model magnetic phase diagram.
This bolsters the viability of current analog quantum computers for
thermodynamic sampling applications of highly frustrated magnetic spin systems.

</details>


### [276] [Temporal entanglement transition in chaotic quantum many-body dynamics](https://arxiv.org/abs/2511.03846)
*Ilya Vilkoviskiy,Michael Sonner,Qi Camm Huang,Wen Wei Ho,Alessio Lerose,Dmitry A. Abanin*

Main category: quant-ph

TL;DR: 时间纠缠（TE）是衡量多体系统局域可观测量模拟动力学复杂性的指标。本研究探讨了TE、非马尔可夫性和局域时间相关性之间的关系，发现TE在特定条件下服从面积定律，表明局域可观测量动力学可由面积定律的IM完全捕获。


<details>
  <summary>Details</summary>
Motivation: 文章旨在调和影响矩阵（IM）的时间纠缠（TE）与局域可观测量快速热化之间的矛盾，并研究TE、非马尔可夫性和局域时间相关性在混沌量子浴中的关系。

Method: 通过精确求解随机酉浴模型，并界定未来和过去自由度之间的可蒸馏纠缠，来研究TE、非马尔可夫性和局域时间相关性。此外，还通过分析踢摆伊辛模型在对偶酉点附近的解析方法和数值方法，来展示TE转变的普适性。

Result: 研究表明，TE在足够低的浴增长率下是广泛的，并反映了真实的非马尔可夫性。然而，这种记忆效应完全包含在复杂的时间相关性中，对少数几个时间相关量的影响可以忽略不计。通过对IM进行粗粒化处理，TE的标度从体积定律转变为面积定律。最终，研究表明面积定律的IM可以完全描述局域可观测量动力学，并且紧凑IM MPS能够准确描述局域演化。

Conclusion: 文章证明了TE从体积定律到面积定律的转变是普适的，并表明面积定律的IM可以完全捕捉局域可观测量动力学。

Abstract: Temporal entanglement (TE) of an influence matrix (IM) has been proposed as a
measure of complexity of simulating dynamics of local observables in a
many-body system. Foligno et al. [Phys. Rev. X 13, 041008 (2023)] recently
argued that the TE in chaotic 1d quantum circuits obeys linear (volume-law)
scaling with evolution time. To reconcile this apparent high complexity of IM
with the rapid thermalization of local observables, here we study the relation
between TE, non-Markovianity, and local temporal correlations for chaotic
quantum baths. By exactly solving a random-unitary bath model, and bounding
distillable entanglement between future and past degrees of freedom, we argue
that TE is extensive for low enough bath growth rate, and it reflects genuine
non-Markovianity. This memory, however, is entirely contained in highly complex
temporal correlations, and its effect on few-point temporal correlators is
negligible. An IM coarse-graining procedure, reducing the allowed frequency of
measurements of the probe system, results in a transition from volume- to
area-law TE scaling. We demonstrate the generality of this TE transition in 1d
circuits by analyzing the kicked Ising model analytically at dual-unitary
points, as well as numerically away from them. This finding indicates that
dynamics of local observables are fully captured by an area-law IM. We provide
evidence that the compact IM MPS obtained via standard compression algorithms
accurately describes local evolution.

</details>


### [277] [Self-correcting High-speed Opto-electronic Probabilistic Computer](https://arxiv.org/abs/2511.04300)
*Ramy Aboushelbaya,Annika Moslein,Hadi Azar,Hamid Tanhaei,Marko von der Leyen*

Main category: quant-ph

TL;DR: 提出了一种新颖的、自纠错、高速光电子概率计算机架构，该架构利用源设备无关（SDI）的量子光子p比特和强大的电子控制。


<details>
  <summary>Details</summary>
Motivation: 结合量子光子的内在随机性和高带宽与经典电子的可编程性和可扩展性，实现高效灵活的概率计算。

Method: 设计并实现了一个基于光子集成电路和FPGA控制的原型系统，能够实现和操控64000个逻辑p比特。

Result: 实验结果表明，该架构实现了2.7 x 10^9 flips/s的翻转率，能耗为4.9 nJ/flip，与最先进的基于磁隧道结（MTJ）的系统相比，在速度和能效方面提高了近三个数量级。SDI协议实现了实时自认证和纠错，确保了在广泛条件下的可靠运行，并解决了p比特数量扩展时的硬件可变性问题。

Conclusion: 量子光子p比特作为可扩展、高性能概率计算的有前景的平台，对组合优化、机器学习和复杂系统建模具有重要意义。

Abstract: We present a novel self-correcting, high-speed optoelectronic probabilistic
computer architecture that leverages source-device independent (SDI) quantum
photonic p-bits integrated with robust electronic control. Our approach
combines the intrinsic randomness and high bandwidth of quantum photonics with
the programmability and scal- ability of classical electronics, enabling
efficient and flexible probabilistic computation. We detail the design and
implementation of a prototype system based on photonic integrated circuits and
FPGA-based control, capable of implementing and manipulating 64000 logical
p-bits. Experimental results demonstrate that our architecture achieves a flip
rate of 2.7 x 10^9 flips/s with an energy consumption of 4.9 nJ/flip,
representing nearly three orders of magnitude improvement in speed and energy
efficiency compared to state-of-the-art magnetic tunnel junc- tion (MTJ) based
systems. Furthermore, the SDI protocol enables real-time self-certification and
error correction, ensuring reliable operation across a wide range of conditions
and solving the problem of hardware variability as the number of p-bits scale.
Our results establish quantum photonic p-bits as a promising platform for
scalable, high-performance probabilistic computing, with significant
implications for combinatorial optimization, machine learning, and complex
system modeling.

</details>


### [278] [On universality of hardware-efficient ansatzes](https://arxiv.org/abs/2511.03870)
*Hokuto Iwakiri,Keita Kanno*

Main category: quant-ph

TL;DR: HEA 模拟是 BQP-complete。


<details>
  <summary>Details</summary>
Motivation: 研究 HEA 的模拟复杂性。

Method: 将任意量子电路表示为 HEA 电路。

Result: 证明某些 HEA 类的模拟是 BQP-complete。

Conclusion: HEA 在模拟方面可能很复杂。

Abstract: The hardware-efficient ansatz (HEA) is one of the most important class of
parametrized quantum circuits for near-term applications of quantum computing.
We show that the problem of simulating some major classes of the HEA is
BQP-complete by explicitly demonstrating that any relevant quantum circuit can
be efficiently represented as an HEA circuit of those classes.

</details>


### [279] [Realistic GKP stabilizer states enable universal quantum computation](https://arxiv.org/abs/2511.03874)
*Fariba Hosseinynejad,Pavithran Iyer,Guillaume Dauphinais,David L. Feder*

Main category: quant-ph

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Physical Gottesman-Kitaev-Preskill (GKP) states are inherently noisy as ideal
ones would require infinite energy. While this is typically considered as a
deficiency to be actively corrected, this work demonstrates that imperfect GKP
stabilizer states can be leveraged in order to apply non-Clifford gates using
only linear optical elements. In particular, Gaussian operations on
normalizable GKP states, combined with homodyne measurements, permit two key
primitives: clean projection onto Pauli eigenstates in the normalizable GKP
codespace, thereby implementing Clifford gates with high fidelity; and
probabilistic projection of unmeasured modes onto non-Pauli eigenstates. These
results demonstrate that normalizable GKP stabilizer states combined with
Gaussian operations provide a practical framework for computational
universality within the measurement-based model of quantum computation in a
realistic continuous-variable setting.

</details>


### [280] [Controlled growth of rare-earth-doped TiO$_{2}$ thin films on III-V semiconductors for hybrid quantum photonic interfaces](https://arxiv.org/abs/2511.03918)
*Henry C. Hammer,Caleb Whittier,Nathan A. Helvy,Christopher Rouleau,Nabil D. Bassim,Ravitej Uppu*

Main category: quant-ph

TL;DR: 通过低温脉冲激光沉积技术在III-V半导体上生长了掺铒钛氧化物薄膜，实现了稀土量子记忆与半导体单光子源的集成。


<details>
  <summary>Details</summary>
Motivation: 量子光子网络需要单光子源和量子存储器，但III-V量子点和稀土离子因晶格失配和生长条件不兼容而难以直接集成。

Method: 采用低温脉冲激光沉积技术，结合砷封盖和缺氧缓冲层，在GaAs和GaSb衬底上外延生长了掺铒钛氧化物薄膜，并使用MCIA模型解释了取向选择性生长。

Result: 成功制备了外延的锐钛矿TiO2(001)薄膜，表面粗糙度小于300pm，并验证了Er3+的光学激活。该方法避免了界面退化，并保留了III-V量子点功能。

Conclusion: 该材料平台为稀土量子记忆与半导体单光子源的单片集成提供了可能，有助于构建可扩展的混合量子光子芯片。

Abstract: Quantum photonic networks require two distinct functionalities: bright
single-photon sources and long-lived quantum memories. III-V semiconductor
quantum dots excel as deterministic and coherent photon emitters, while
rare-earth ions such as erbium (Er$^{3+}$) in crystalline oxides offer
exceptional spin and optical coherence at telecom wavelengths. Combining these
systems and their functionalities via direct epitaxy is challenging due to
lattice mismatch and incompatible growth conditions. Here we demonstrate
low-temperature pulsed laser deposition of Er$^{3+}$-doped TiO$_{2}$ thin films
directly on GaAs and GaSb substrates. Controlled surface preparation with an
arsenic cap and an oxygen-deficient buffer layer enables the growth of
epitaxial anatase TiO$_{2}$ (001) at 390$^{o}$C with sub-300 pm surface
roughness, while avoiding interface degradation. In contrast, high-temperature
oxide desorption or growth temperatures drive the transition to rough,
polycrystalline rutile film, as confirmed by transmission electron microscopy.
Minimal coincident interface area (MCIA) modeling explains the
orientation-selective growth on GaAs and GaSb. Raman and cryogenic
photoluminescence excitation spectroscopy verify the crystal phase and optical
activation of Er$^{3+}$ ions. This multi-parameter growth strategy helps
preserve III-V quantum dot functionality and yields smooth surfaces suitable
for low-loss nanophotonic structures. Our results establish a materials
platform for monolithically integrating rare-earth quantum memories with
semiconductor photon sources, paving the way toward scalable hybrid quantum
photonic chips.

</details>


### [281] [Novel Encodings of Homology, Cohomology, and Characteristic Classes](https://arxiv.org/abs/2511.03920)
*Itai Maimon*

Main category: quant-ph

TL;DR: We construct a novel topological quantum error-correcting code that encodes obstruction classes of fiber bundles, such as Chern and Pontryagin classes, by extending toric codes and analyzing their error structures. An example encoding the Euler class of S^2 is explicitly constructed.


<details>
  <summary>Details</summary>
Motivation: The motivation is to encode topological invariants, specifically obstruction classes of fiber bundles (like Chern or Euler classes), which have not been directly encoded in existing topological quantum error-correcting codes (QECCs).

Method: The method involves constructing and analyzing extensions of toric codes. The topological structure of their errors is analyzed, and these errors are then used to construct a novel code that encodes the obstruction class to a fiber bundle. This process allows for the encoding of characteristic classes like Chern and Pontryagin classes.

Result: The paper constructs and analyzes extensions of toric codes, examines their error topologies, and develops a new QECC that encodes the obstruction class to a fiber bundle. This new code successfully encodes characteristic classes such as the Chern and Pontryagin classes.

Conclusion: The paper successfully constructs a novel topological QECC that encodes characteristic classes, specifically obstruction classes of fiber bundles, by extending toric codes and analyzing their error structures. An explicit example of encoding the Euler class of S^2 is provided, demonstrating the effectiveness of the proposed method.

Abstract: Topological quantum error-correcting codes (QECC) encode a variety of
topological invariants in their code space. A classic structure that has not
been encoded directly is that of obstruction classes of a fiber bundle, such as
the Chern or Euler class. Here, we construct and analyze extensions of toric
codes. We then analyze the topological structure of their errors and finally
construct a novel code using these errors to encode the obstruction class to a
fiber bundle. In so doing, we construct an encoding of characteristic classes
such as the Chern and Pontryagin class in topological QECC. An example of the
Euler class of $S^2$ is constructed explicitly.

</details>


### [282] [Quantum Optical Techniques for Biomedical Imaging](https://arxiv.org/abs/2511.03935)
*Vahid Salari,Yingwen Zhang,Sepideh Ahmadi,Dilip Paneru,Duncan England,Shabir Barzanjeh,Robert Boyd,Ebrahim Karimi,Christoph Simon,Daniel Oblak*

Main category: quant-ph

TL;DR: 量子成像利用光的非经典性质（如纠缠、压缩和量子关联）来克服传统成像技术的局限性，为生物医学应用带来变革，有望提高空间分辨率、信噪比、相位灵敏度并降低辐射剂量。


<details>
  <summary>Details</summary>
Motivation: 量子成像作为一种新兴的生物医学应用方法，旨在利用光的非经典性质来克服传统成像技术的根本限制。

Method: 文章概述了量子光学生物医学成像技术和量子启发成像方法，包括量子光学相干层析成像、量子光学显微镜、鬼成像、多参数量子成像以及量子级相机成像。

Result: 文章描述了每种方法的运行原理、生物医学应用和独特优势，以及它们在实际应用中面临的具体挑战。

Conclusion: 本文旨在指导未来的研究，推动量子成像从实验演示走向具有影响力的生物医学工具。

Abstract: Quantum imaging is emerging as a transformative approach for biomedical
applications, applying nonclassical properties of light, such as entanglement,
squeezing, and quantum correlations, to overcome fundamental limits of
conventional techniques. These methods promise superior spatial resolution,
enhanced signal-to-noise ratios, improved phase sensitivity, and reduced
radiation dose, for potentially safer and more precise imaging for delicate
biological samples. Here, we present an overview of quantum optical biomedical
imaging technologies as well as quantum-inspired imaging methods, including
quantum optical coherence tomography, quantum optical microscopy, ghost
imaging, multi-parameter quantum imaging, and imaging with quantum-grade
cameras. We describe the operating principles, biomedical applications, and
unique advantages of each approach, along with the specific challenges for
their translation into real-life practice. This review aims to guide future
research toward advancing quantum imaging from experimental demonstrations to
impactful biomedical tools.

</details>


### [283] [Non-invertible Kramers-Wannier duality-symmetry in the trotterized critical Ising chain](https://arxiv.org/abs/2511.03947)
*Akash Sinha,Pramod Padmanabhan,Vladimir Korepin*

Main category: quant-ph

TL;DR: 文章提出一种可积的Trotter分解方法，可用于离散时间演化可积多体系统，并保持其守恒量。该方法应用于临界反场链模型，并研究了其Kramers-Wannier对偶对称性。


<details>
  <summary>Details</summary>
Motivation: 研究可积Trotter分解在离散时间演化可积多体系统中的应用，并分析其对称性。

Method: 利用量子逆散射方法构建包含时空离散化的不均匀转移矩阵，得到离散时间守恒量。

Result: 证明了一阶Trotter分解是可积的，并发现对偶算符的数量加倍，可以映射不同阶数的Trotter分解。

Conclusion: 该研究不仅扩展了Trotter分解的结果，还为有限时间下的Floquet演化提供了Kramers-Wannier对偶对称性的分析。

Abstract: Integrable trotterization provides a method to evolve a continuous time
integrable many-body system in discrete time, such that it retains its
conserved quantities. Here we explicitly show that the first order
trotterization of the critical transverse field Ising model is integrable. The
discrete time conserved quantities are obtained from an inhomogeneous transfer
matrix constructed using the quantum inverse scattering method. The
inhomogeneity parameter determines the discrete time step. We then focus on the
non-invertible Kramers-Wannier duality-symmetry for the trotterized evolution.
We find that the discretization of both space and time leads to a doubling of
these duality operators. They account for discrete translations in both space
and time. As an interesting application, we find that these operators also
provide maps between trotterizations of different orders. This helps us extend
our results beyond the trotterization scheme and investigate the
Kramers-Wannier duality-symmetry for finite time Floquet evolution of the
critical transverse field Ising chain.

</details>


### [284] [Multi-Directional Periodic Driving of a Two-Level System beyond Floquet Formalism](https://arxiv.org/abs/2511.03977)
*Michael Warnock,David A. Hague,Vesna F. Mitrovic*

Main category: quant-ph

TL;DR: 该手稿提出了一个精确的解析表达式，用于描述半经典两能级量子系统在任意周期性驱动下的响应，解决了传统数值方法（如Floquet理论）因截断无穷矩阵而可能丢失关键干涉信息的问题，为量子传感和量子控制提供了新的分析工具。


<details>
  <summary>Details</summary>
Motivation: 现有数值方法（如Floquet理论）在处理周期性驱动的两能级系统时，需要截断无穷矩阵，这可能导致丢失重要的干涉信息，影响量子传感器的性能或在量子控制中引入伪影。

Method: 使用$\star$-解析核方法和路径和定理，推导出薛定谔方程的精确级数解，从而得到精确的跃迁概率。该级数解由包含周期性驱动信息的紧凑核表达式生成，并以非谐傅里叶级数基展开，其系数是广义贝塞尔函数的乘积。

Result: 得出了包含所有周期性驱动信息的紧凑核表达式，并将其展开为非谐傅里叶级数基，系数为广义贝塞尔函数的乘积，从而得到精确的跃迁概率。

Conclusion: 该方法提供了一种分析方法，可用于量子传感和量子控制应用，解决了现有数值方法中的精度和信息丢失问题。

Abstract: In this manuscript, we introduce an exact expression for the response of a
semi-classical two-level quantum system subject to arbitrary periodic driving.
Determining the transition probabilities of a two-level system driven by an
arbitrary periodic waveform necessitates numerical calculations through methods
such as Floquet theory, requiring the truncation of an infinite matrix.
However, such truncation can lead to a loss of significant interference
information, hindering quantum sensors or introducing artifacts in quantum
control. To alleviate this issue, we use the $\star$-resolvent formalism with
the path-sum theorem to determine the exact series solution to Schr\"odinger's
equation, therefore providing the exact transition probability. The resulting
series solution is generated from a compact kernel expression containing all of
the information of the periodic drive and then expanded in a non-harmonic
Fourier series basis given by the divided difference of complex exponentials
with coefficients corresponding to products of generalized Bessel functions.
The present method provides an analytical formulation for quantum sensors and
control applications.

</details>


### [285] [Quantum error correction for multiparameter metrology](https://arxiv.org/abs/2511.04018)
*Mauricio Gutiérrez,Chiranjib Mukhopadhyay,Victor Montenegro,Abolfazl Bayat*

Main category: quant-ph

TL;DR: 利用量子纠错技术，通过将除一个未知参数外的所有参数视为噪声来处理，实现了多参数传感中GHZ探测器的量子增强精度，并恢复了可分离且固定的测量策略。


<details>
  <summary>Details</summary>
Motivation: 在多参数传感中，单个GHZ探测器不仅无法实现量子优势，其相应的最优测量也变得复杂且依赖于未知参数。本研究旨在解决这一问题。

Method: 提出了一种利用量子纠错技术的多参数传感方案，将除一个未知参数外的所有参数视为噪声并进行纠错。该方案为每个GHZ探测器提供一个独立的辅助量子比特，并利用多个互补的GHZ探测器来恢复海森堡缩放。

Result: 该策略恢复了单参数GHZ量子传感的核心优势，即在所有未知参数值下都能达到最优的量子增强精度，同时保持测量分离且固定。虽然对于单个GHZ探测器，这种最优精度受到散粒噪声的限制，但通过使用多个互补的GHZ探测器，成功恢复了海森堡缩放。

Conclusion: 所提出的方案有效地实现了多参数传感中GHZ探测器的量子增强精度，并通过量子纠错技术克服了测量复杂性和参数依赖性的挑战，为量子传感领域提供了新的途径。

Abstract: For single-parameter sensing, Greenberger-Horne-Zeilinger (GHZ) probes
achieve optimal quantum-enhanced precision across the unknown parameter range,
solely relying on parameter-independent separable measurement strategies for
all values of the unknown parameter. However, in the multiparameter setting, a
single GHZ probe not only fails to achieve quantum advantage but also the
corresponding optimal measurement becomes complex and dependent on the unknown
parameters. Here, we provide a recipe for multiparameter sensing with GHZ
probes using quantum error correction techniques by treating all but one
unknown parameters as noise, whose effects can be corrected. This strategy
restores the core advantage of single parameter GHZ-based quantum sensing,
namely reaching optimally quantum-enhanced precision for all unknown parameter
values while keeping the measurements separable and fixed. Specifically, given
one shielded ancilla qubit per GHZ probe, our protocol extracts optimal
possible precision for any probe size. While this optimal precision is
shot-noise limited for a single GHZ probe, we recover the Heisenberg scaling
through use of multiple complementary GHZ probes. We demonstrate the
effectiveness of the protocol with Bayesian estimation.

</details>


### [286] [Anomalous heat flow and quantum Otto cycle with indefinite causal order](https://arxiv.org/abs/2511.04028)
*Qing-Feng Xue,Qi Zhang,Xu-Cai Zhuang,Yun-Jie Xia,Enrico Russo,Giulio Chiribella,Rosario Lo Franco,Zhong-Xiao Man*

Main category: quant-ph

TL;DR: 热量通常从高温流向低温，但在交互顺序不确定时，会出现反常热流，允许热量从低温流向高温。利用这一现象，我们设计了一个具有不确定因果顺序的量子奥托循环，可以制冷并产生功。该理论已在光学量子系统中得到实验验证。


<details>
  <summary>Details</summary>
Motivation: 经典热力学认为热量自发地从高温流向低温，且与相互作用顺序无关。然而，当相互作用顺序不确定时，会出现反常热流，即热量可能从低温流向高温。

Method: 设计了一个具有不确定因果顺序的量子奥托循环，并利用反常热流实现了制冷和功的产生。通过光学量子系统对该循环进行了实验模拟。

Result: 成功设计并模拟了一个量子奥托循环，该循环利用反常热流实现了制冷和功的产生，证明了热量在相互作用顺序不确定时可以从低温流向高温。

Conclusion: 当相互作用顺序不确定时，会出现反常热流，这为设计新的量子热力学循环（如量子奥托循环）提供了可能，并能在制冷的同时产生功。该理论已通过光学量子系统得到实验验证。

Abstract: The principle that heat spontaneously flows from higher temperature to lower
temperature is a cornerstone of classical thermodynamics, often assumed to be
independent of the sequence of interactions. While this holds true for
macroscopic systems at equilibrium, here we show that, when the order of
interactions between two identical thermalization channels is indefinite, an
anomalous heat flow emerges, whereby heat can sometime flow from a colder
entity to a hotter one. Taking advantage of this anomalous heat flow, we design
a quantum Otto cycle with indefinite causal order, which not only achieves
refrigeration but also generates work. The anomalous heat flow and the quantum
Otto cycle are experimentally simulated in a photonic quantum setup, which
provides a proof-of-principle demonstration of the theory.

</details>


### [287] [Unifying contextual advantages in state discrimination](https://arxiv.org/abs/2511.04100)
*Kieran Flatt,Joonwoo Bae*

Main category: quant-ph

TL;DR: 量子态辨识可用于检验广义非局域性，本文推导了各类猜测策略下，考虑结论性和非结论性结果的非局域性不等式，并统一了所有态辨识方案和评价指标下的非局域性优势。


<details>
  <summary>Details</summary>
Motivation: 量子态辨识可用于检验广义非局域性，但需要对不同辨识方案和评价指标下的非局域性优势进行深入研究。

Method: 本文针对最小错误辨识、无歧义辨识和最大置信度辨识三种方案，以及置信度、平均猜测概率和非结论性结果率等评价指标，推导了相应的非局域性不等式。

Result: 研究发现，在最小错误辨识和无歧义辨识下，非局域性优势体现在个体结果的置信度和平均猜测概率上；在最大置信度辨识下，非局域性优势不仅体现在置信度和平均猜测概率上，还体现在非结论性结果率上。

Conclusion: 本文的研究结果统一了不同量子态辨识方案和评价指标下的非局域性优势，并提出量子信息应用可能在非局域性理论上获得优势，为相关领域的研究提供了理论基础和新的视角。

Abstract: Quantum state discrimination, alongside its other applications, has recently
found use as a tool for witnessing generalised contextuality. In this article,
we derive noncontextuality inequalities for both conclusive and inconclusive
outcomes across various guessing strategies. For minimum- error discrimination,
the advantage is in terms of the confidences of individual outcomes, while for
unambiguous state discrimination, it is in terms of the average guessing
probability. For maximum- confidence discrimination, we show that contextual
advantages occur not only for the confidence but also their average, the
guessing probability, as well as the inconclusive outcome rate. Our results
unify the contextual advantages across all state discrimination schemes and
figures of merit. We envisage that various quantum information applications
based on state discrimination may offer advantages over non-contextual
theories.

</details>


### [288] [Controllable Non-Hermitianity in Continuous-Variable Qubits](https://arxiv.org/abs/2511.04110)
*Ke-Xiong Yan,Zhi-Cheng Shi,Ye-Hong Chen,Yan Xia*

Main category: quant-ph

TL;DR: 纯粹退相干会引起光量子比特的非对称泄露，这种泄露可以通过非厄米哈密顿量来描述，从而将光量子比特转变为可控的增益和损耗平台，用于研究非厄米物理学。通过调节幅度，可以控制单量子比特的宇称-时间对称性相变，并且通过耦合两个量子比特，可以实现由卓越点引起的纠缠相变。


<details>
  <summary>Details</summary>
Motivation: 传统观点认为退相干是有害的噪声，但本文揭示了纯粹退相干诱导光量子比特的非对称泄露，这使得光量子比特可以作为研究非厄米物理学的平台。

Method: 使用非厄米哈密顿量描述光量子比特的非对称泄露，并通过调节幅度控制单量子比特的宇称-时间对称性相变，以及通过耦合两个量子比特实现由卓越点引起的纠缠相变。

Result: 构建了一个可控的非厄米系统模拟器，实现了对宇称-时间对称性相变和纠缠相变的控制。

Conclusion: 退相干可以被视为一种可控的增益和损耗机制，为研究非厄米物理学提供了一个新的平台。

Abstract: Pure dephasing is the dominant leak mechanism in photonic cat qubits because
its phase errors disrupt the parity protection, rendering the qubit vulnerable
to energy relaxation. In this manuscript, we reveal that this dephasing
mechanism conceals an interesting physical phenomenon: it induces
\textit{asymmetric leakage} from the cat-state subspace, where even- and
odd-parity cat states decay at different rates. This leak asymmetry enables the
dynamics of the system to be described by a non-Hermitian Hamiltonian, thereby
transforming the cat qubit into a platform with controllable gain and loss for
probing non-Hermitian physics. Within this platform, we demonstrate the
possibility to control the parity-time symmetry phase transition in a single
cat qubit by adjusting its amplitude. Moreover, we couple two cat qubits to
realize an entanglement phase transition induced by the exceptional point. Our
work constructs a controllable non-Hermitian system simulator, overturning the
conventional paradigm that treats dephasing as harmful noise.

</details>


### [289] [Non-relativistic Quantum Mechanics on a Twisted Cylindrical Surface](https://arxiv.org/abs/2511.04371)
*G. M. Delgado,J. E. G. Silva*

Main category: quant-ph

TL;DR: 研究了电子在扭曲圆柱体表面上的量子行为，重点关注了几何诱导的量子势对薛定谔方程的影响，并分析了两种散射问题，以了解几何和应变如何影响类似未扭曲系统。


<details>
  <summary>Details</summary>
Motivation: 研究扭曲圆柱体表面上电子的量子行为，以了解几何和应变如何影响类似未扭曲系统。

Method: 计算应变张量得到诱导表面度量，然后采用da Costa形式主义推导出几何诱导的量子势，进而求解薛定谔方程以确定束缚态和能量特征值，并分析了两种散射问题。

Result: 发现线性扭曲和非线性扭曲都会在波函数中产生几何相位，而da Costa势保持不变，束缚态能量谱与扭曲无关。在两种散射问题中，透射概率对扭曲不敏感，但会受到粒子角动量和圆柱体半径的显著影响，并表现出独特的振荡行为。

Conclusion: 几何形状和应变会影响量子系统的特性，特别是扭曲会产生几何相位，但能量谱和透射概率对扭曲不敏感。粒子的角动量和圆柱体的半径对透射概率有显著影响。这些发现对设计基于可控曲率和扭曲材料的量子器件具有重要意义。

Abstract: Twisted cylindrical tubes are important model systems for nanostructures,
heterostructures, and curved quantum devices. In this work, we investigate the
quantum behavior of an electron confined to a twisted cylindrical surface. By
first calculating the strain tensor to obtain the induced surface metric, we
employ da Costa's formalism to derive the geometry-induced quantum potential.
This potential modifies the Schr\"odinger equation even in the absence of
external forces, allowing us to determine the bound states and energy
eigenvalues. This was made in the linear and non-linear torsion regime.
Furthermore, we analyze two distinct scattering problems: (i) scattering within
an infinite cylinder containing a twisted section, and (ii) scattering of a
free particle incident upon a finite twisted cylinder. Our goal is to
understand how geometry and strain influence the properties of analogous
untwisted systems. It turns out that both the linear and non-linear twists
yield to a geometric phase into the wave function, while the da Costa potential
is kept unchanged. Consequently, the system supports bound states whose energie
spectrum is twist independent. For both scattering problems, we find that the
transmission probability is insensitive to torsion, whereas it is significantly
affected by the particle angular momentum and the cylinder's radius, exhibiting
distinct oscillatory behavior. These findings suggest relevant implications for
engineering quantum devices based on materials with controlled curvature and
twist.

</details>


### [290] [Expectation-Realization Interpretation of Quantum Superposition](https://arxiv.org/abs/2511.04154)
*Yanting Wang*

Main category: quant-ph

TL;DR: This paper proposes an 


<details>
  <summary>Details</summary>
Motivation: This paper aims to provide a new interpretation of quantum superposition by comparing it with its classical counterpart, aiming to simplify the understanding of quantum mechanics.

Method: The paper analyzes quantum superposition by comparing it with classical concepts, using Schrödinger's cat as an example. It proposes an 'expectation-realization' interpretation where quantum systems randomly realize into eigenstates weighted by probabilities. This interpretation is extended to quantum pathways and reframes Bell's inequality tests.

Result: The interpretation suggests that quantum systems exist as an expectation over possible eigenstates, and upon measurement, they are randomly realized into one of these states. This view makes concepts like wavefunction collapse, many worlds, and decoherence unnecessary, and reinterprets Bell's inequality tests as validation of wave-like probability without invoking non-locality.

Conclusion: The expectation-realization interpretation offers a unified and simplified understanding of quantum superposition, quantum pathways, and Bell's inequality tests by integrating probability theory with wave mechanics and demystifying concepts like wavefunction collapse and spooky action at a distance.

Abstract: By comparing Schr\"odinger's cat with its classical counterpart, I show that
a quantum superposition should be understood as an expectation over possible
eigenstates weighted by wave-like probabilities. Upon the occurrence of a
certain event, the quantum system is randomly realized into one of the possible
eigenstates due to its intrinsic stochasticity. While the randomness of a
single realization cannot be controlled or predicted, the overall distribution
can be regulated via experimental setup and converges as the number of events
increases. A measurement is indeed an activity employing a certain event to
convert a quantum effect into a macroscopic outcome. Consequently, the puzzling
concepts of wavefunction collapse, many worlds, and decoherence become
unnecessary for understanding quantum superposition. This
expectation-realization interpretation, which integrates probability theory
with wave mechanics, can also be extended to quantum pathways. Moreover, it
reframes tests of Bell's inequalities as validating the wave-like probability
nature of quantum mechanics, with no need to invoke the mysterious notions of
quantum non-locality and "spooky action at a distance".

</details>


### [291] [Two-exponential decay of Acridine Orange](https://arxiv.org/abs/2511.04185)
*Francesco Giacosa,Anna Kolbus,Krzysztof Kyziol,Magdalena Plodowska,Milena Piotrowska,Karol Szary,Arthur Vereijken*

Main category: quant-ph

TL;DR: 在长时程下，荧光衰减符合指数衰减定律，实验结果与量子力学预测的幂律行为不符。


<details>
  <summary>Details</summary>
Motivation: 验证量子力学和量子场论预测的长时程幂律行为是否存在。

Method: 使用两种不同的光子探测器，实验性地研究吖啶橙的荧光衰减。

Result: 实验数据用两个指数函数（寿命分别为 1.7331 ± 0.001 ns 和 5.948 ± 0.012 ns）能很好地描述，与文献报道的值一致。未观察到偏离指数衰减定律的现象。

Conclusion: 实验未观察到预期的幂律行为，但验证了实验装置的准确性，并精确测定了样品的荧光寿命。

Abstract: In this work, we experimentally study the fluorescence decay of Acridine
Orange at late times, in order to test whether a late-time power-law behaviour
emerges, a feature expected to be very small but consistent with quantum
mechanical and quantum field theoretical predictions. Using two distinct photon
detectors, we find that the data are well described by a sum of two exponential
functions with lifetimes $\tau_1 = 1.7331 \pm 0.001$ ns and $\tau_2 = 5.948 \pm
0.012$ ns, in agreement with values reported in the literature. While no
deviation from the exponential decay law is observed, this study serves as a
reliable test for the experimental setup and enables a precise determination of
the sample lifetimes.

</details>


### [292] [Quantum Key Distribution via Charge Teleportation](https://arxiv.org/abs/2511.04188)
*Amir Yona,Yaron Oz*

Main category: quant-ph

TL;DR: 基于电荷 the paper proposes a quantum key distribution (QKD) primitive using charge teleportation, which is more robust to noise than energy teleportation schemes and compatible with near-term platforms.


<details>
  <summary>Details</summary>
Motivation: The motivation is to develop a practical and robust quantum key distribution (QKD) primitive suitable for near-term platforms, addressing limitations of existing energy teleportation schemes.

Method: The paper introduces a QKD primitive based on charge teleportation. Alice's one-bit choice, through Local Operations and Classical Communication (LOCC) on an entangled many-body ground state, influences a local charge shift at Bob, encoding the key bit. The protocol is instantiated on transverse-field Ising models (star-coupled and 1D chain), with closed-form results for two qubits and simulations (exact diagonalization, circuit-level) for larger systems. Resilience to bit flips and local quantum noise is quantified.

Result: Closed-form results for two qubits were obtained. For larger systems, performance was confirmed via exact diagonalization, circuit-level simulations, and a proof-of-principle hardware run. Resilience to classical bit flips and local quantum noise was quantified, identifying regimes where key correctness is preserved.

Conclusion: Charge teleportation serves as a practical, low-rate QKD primitive that is compatible with near-term quantum computing platforms, offering advantages in robustness against noise compared to energy teleportation schemes.

Abstract: We introduce a quantum key distribution (QKD) primitive based on charge
teleportation: by Local Operations and Classical Communication (LOCC) on an
entangled many-body ground state, Alice's one-bit choice steers the sign of a
local charge shift at Bob, which directly encodes the key bit. Relative to
energy teleportation schemes, the charge signal is bit-symmetric, measured in a
single basis, and markedly more robust to realistic noise and model
imperfections. We instantiate the protocol on transverse-field Ising models,
star-coupled and one-dimensional chain, obtain closed-form results for two
qubits, and for larger systems confirm performance via exact diagonalization,
circuit-level simulations, and a proof-of-principle hardware run. We quantify
resilience to classical bit flips and local quantum noise, identifying regimes
where sign integrity, and hence key correctness, is preserved. These results
position charge teleportation as a practical, low-rate QKD primitive compatible
with near-term platforms.

</details>


### [293] [Quantum Chip Co-Design for Fidelity and Entanglement Preservation](https://arxiv.org/abs/2511.04194)
*Ahmad Salmanogli,Hesam Zandi*

Main category: quant-ph

TL;DR: 提出一种混合多量子比特架构，通过内部和外部量子比特组以及耦合的中心可调谐量子比特和分布式谐振器网络，解决了量子比特耦合和测量保真度之间的权衡问题。


<details>
  <summary>Details</summary>
Motivation: 解决可扩展量子硬件开发中的关键权衡问题，即量子比特耦合增强纠缠但可能导致串扰和降低测量保真度。

Method: 提出一种混合多量子比特（九个超导比特）配置，分为内部和外部组，并通过可调谐量子比特和分布式谐振器网络连接。通过求解哈密顿量和主方程来模拟系统动力学，评估光谱特征和保真度。

Result: 模拟结果表明，该设计在保持强纠缠（通过避免交叉区域）的同时，在实际噪声条件下将测量保真度维持在 0.995 左右。

Conclusion: 该架构可在单个可重构架构中优化纠缠强度和读出保真度，为实现高性能、可扩展的超导量子处理器提供了可行途径。

Abstract: This study introduces a superconducting quantum chip architecture designed to
simultaneously preserve entanglement and readout fidelity, addressing one of
the key trade-offs in the development of scalable quantum hardware. In
conventional quantum circuits, strong qubit qubit coupling enhances
entanglement but often leads to undesired crosstalk, dephasing, and reduced
measurement fidelity. To mitigate these effects, we propose a hybrid multiqubit
configuration consisting of nine transmon qubits organized into interior and
exterior groups, interconnected via a flux tunable qubit and a network of
distributed resonators. The interior qubits along with tunable qubit form an
entanglement core, while the exterior qubits operate in the dispersive regime
under large detuning to enable readout. The degree of entanglement can be
dynamically tuned by adjusting the coupling between the central tunable qubit
and the interior qubits. The total Hamiltonian includes all significant
coupling contributions, encompassing effective exchange interactions among
interior and exterior qubits, as well as their mediated couplings through
interface resonators. By numerically solving the complete Hamiltonian alongside
the Lindblad master equation, the system dynamics are characterized, allowing
evaluation of both spectroscopic features and separation fidelity. Simulation
results demonstrate that the proposed design maintains strong entanglement by
creating the avoided-crossing region while sustaining measurement fidelity
around 0.995 under realistic noise conditions. These findings confirm that
entanglement strength and readout fidelity can be co-optimized within a single,
reconfigurable architecture, establishing a viable route toward
high-performance and scalable superconducting quantum processors.

</details>


### [294] [Engineered Robustness for Nonadiabatic Geometric Quantum Gates](https://arxiv.org/abs/2511.04225)
*Xuan Zhang,XIao-le Li,Jingjing Niu,Tongxing Yan,Yuanzhen Chen*

Main category: quant-ph

TL;DR: 本论文提出了一种简化的非绝热几何量子门（NGQG）框架，通过引入额外的辅助约束来抑制动力学污染，实现超鲁棒性能。该框架还允许使用非环路路径设计NGQG，增加了设计的灵活性。


<details>
  <summary>Details</summary>
Motivation: 为了实现对控制错误的内在鲁棒性，但实际鲁棒性尚未得到保证。

Method: 提出了一种简化的非绝热几何量子门（NGQG）框架，并使用非环路路径设计NGQG。在超导传输量子比特上实现了高保真度的单量子比特门，并分析了两比特NGQG在参数驱动下的表现。

Result: 在超导传输量子比特上实现的单量子比特门，其失真度随Rabi振幅误差$\	ildel{\\epsilon}$的增长比例为$\	ildel{\\mathcal{O}}(\	ildel{\\epsilon}^{\	ildel{4}})$，相比之下，传统动力学门的增长比例为$\	ildel{\\mathcal{O}}(\	ildel{\\epsilon}^{\	ildel{2}})$。分析了两比特NGQG在参数驱动下的表现，并发现了影响其性能的因素，如相位补偿和波形校准。

Conclusion: 所提出的超鲁棒NGQG方案简单通用，适用于多种量子计算平台。

Abstract: While geometric quantum gates are often theorized to possess intrinsic
resilience to control errors by exploiting the global properties of evolution
paths, this promise has not consistently translated into practical robustness.
We present a streamlined framework for nonadiabatic geometric quantum gates
(NGQGs) that incorporates additional auxiliary constraints to suppress
dynamical contamination and achieve super-robust performance. Within this
framework, we also design NGQGs using noncyclic paths, offering enhanced design
flexibility. Implemented on superconducting transmon qubits, our scheme
realizes high-fidelity single-qubit gates that are robust against Rabi
amplitude error $\epsilon$, with infidelity scaling as
$\mathcal{O}(\epsilon^4)$, in contrast to the $\mathcal{O}(\epsilon^2)$
behavior of conventional dynamical gates. We further analyze two-qubit NGQGs
under parametric driving. Our results identify subtle limitations that
compromise performance in two-qubit scenarios, underscoring the importance of
phase compensation and waveform calibration. The demonstrated simplicity and
generality of our super-robust NGQG scheme make it applicable across diverse
quantum platforms.

</details>


### [295] [Local quantum coherence with intersource interactions at nonzero temperature](https://arxiv.org/abs/2511.04242)
*Yehor Hudenko,Michal Kolář,Radim Filip,Artem Ryabov*

Main category: quant-ph

TL;DR: 自主产生的局域量子相干性可以通过环境中的相互作用得到增强，其温度依赖性可能包含量子相变的特征。


<details>
  <summary>Details</summary>
Motivation: 探索环境内部的相互作用在生成自主局域量子相干性中的作用。

Method: 分析一个包含目标两能级系统（TLS）和N个相互作用的源TLS（代表环境）的精确可解模型，整个系统处于热平衡状态。

Result: 局域相干性不仅可以持续，而且与没有源间相互作用的情况相比，在有限温度下可以得到增强。相干性的温度依赖性带有量子相变的特征。

Conclusion: 自主产生的量子相干性具有普遍性质，并指出了在非零温度下观测相干性的可行途径。

Abstract: Local quantum coherence in a two-level system (TLS) is typically generated
via time-dependent driving. However, it can also emerge autonomously from
symmetry-breaking interactions between the TLS and its surrounding environment
at a low temperature. Although such environments often consist of interacting
atoms or spins, the role of interactions within the environment in generating
the autonomous local coherence has remained unexplored. Here, we address this
gap by analyzing an exactly solvable model, which comprises a target TLS
coupled to $N$ interacting source TLSs that represent the environment, with the
whole system being in thermal equilibrium. We show that the local coherence not
only persists but can be enhanced at finite temperatures of the environment
compared to the case of no inter-source interactions. The temperature
dependence of the coherence bears signatures of a quantum phase transition, and
our analytical results suggest strategies for its optimization. Our findings
reveal generic properties of the autonomously generated quantum coherence and
point to viable routes for observing the coherence at nonzero temperatures.

</details>


### [296] [Twirlator: A Pipeline for Analyzing Subgroup Symmetry Effects in Quantum Machine Learning Ansatzes](https://arxiv.org/abs/2511.04243)
*Valter Uotila,Väinö Mehtola,Ilmo Salmenperä,Bo Zhao*

Main category: quant-ph

TL;DR: 自动化流水线测量量子机器学习ansatzes关于对称性的特征，发现对称性增加会降低电路的可表达性，但通常会增加纠缠能力。


<details>
  <summary>Details</summary>
Motivation: 已有的量子机器学习中的对称化方法，其在实践中的开销（如额外的门、降低的表达能力等）尚不清楚。

Method: 开发自动化流水线测量量子机器学习ansatzes关于对称性的特征，定义学习问题的对称度为子群的大小，并基于生成元的差异范数、电路特性、表达能力和纠缠能力等三个类别计算度量指标。

Result: 结果表明，在19个常见的ansatzes中，对称化引入了不同的门开销；对称性增加确实降低了电路的表达能力；在大多数情况下，对称性增加会提高纠缠能力。

Conclusion: 这些结果有助于为几何量子机器学习应用选择具有足够表达能力和计算效率的ansatz模式。

Abstract: Leveraging data symmetries has been a key driver of performance gains in
geometric deep learning and geometric and equivariant quantum machine learning.
While symmetrization appears to be a promising method, its practical overhead,
such as additional gates, reduced expressibility, and other factors, is not
well understood in quantum machine learning. In this work, we develop an
automated pipeline to measure various characteristics of quantum machine
learning ansatzes with respect to symmetries that can appear in the learning
task. We define the degree of symmetry in the learning problem as the size of
the subgroup it admits. Subgroups define partial symmetries, which have not
been extensively studied in previous research, which has focused on symmetries
defined by whole groups. Symmetrizing the 19 common ansatzes with respect to
these varying-sized subgroup representations, we compute three classes of
metrics that describe how the common ansatz structures behave under varying
amounts of symmetries. The first metric is based on the norm of the difference
between the original and symmetrized generators, while the second metric counts
depth, size, and other characteristics from the symmetrized circuits. The third
class of metrics includes expressibility and entangling capability. The results
demonstrate varying gate overhead across the studied ansatzes and confirm that
increased symmetry reduces expressibility of the circuits. In most cases,
increased symmetry increases entanglement capability. These results help select
sufficiently expressible and computationally efficient ansatze patterns for
geometric quantum machine learning applications.

</details>


### [297] [Space-Bounded Communication Complexity of Unitaries](https://arxiv.org/abs/2511.04250)
*Longcheng Li,Xiaoming Sun,Jialin Zhang,Jiadong Zhu*

Main category: quant-ph

TL;DR: 本文研究了分布式量子处理器中空间受限通信的酉实现问题，对每个处理器上的量子比特数量进行了限制。通过使用具有非局域双量子比特门的分布式量子电路对处理器进行建模，将酉实现的通信复杂度定义为实现其所需的最小非局域门数量。


<details>
  <summary>Details</summary>
Motivation: 为了确保实际可行性和技术上的非平凡性，研究了分布式量子处理器中空间受限通信的酉实现问题，并对每个处理器上的量子比特数量进行了限制。

Method: 通过使用具有非局域双量子比特门的分布式量子电路对分布式量子处理器进行建模，并定义了酉实现的通信复杂度为实现其所需的最小非局域门数量。我们推导了n比特酉实现通信复杂度的上界，并将其扩展到近似模型和一般网络拓扑。同时，我们还研究了量子傅里叶变换（QFT）和Clifford电路在精确和近似模型下的通信复杂度。

Result: 对于一般的n比特酉，通信复杂度上界由O(max{4^((1-1/k)n-m), n})给出，当m=0且k=2时，复杂度为O(2^n)。对于量子傅里叶变换（QFT）和Clifford电路，在精确模型下通信复杂度具有线性上界，优于之前的二次界限。在近似模型下，QFT的通信复杂度从线性降低到对数级别，而Clifford电路的通信复杂度仍然是线性的。

Conclusion: 本文为优化分布式量子酉实现中的通信提供了基本见解，提高了大规模分布式量子计算（DQC）系统的可行性。

Abstract: We study space-bounded communication complexity for unitary implementation in
distributed quantum processors, where we restrict the number of qubits per
processor to ensure practical relevance and technical non-triviality. We model
distributed quantum processors using distributed quantum circuits with nonlocal
two-qubit gates, defining the communication complexity of a unitary as the
minimum number of such nonlocal gates required for its realization.
  Our contributions are twofold. First, for general $n$-qubit unitaries, we
improve upon the trivial $O(4^n)$ communication bound. Considering $k$
pairwise-connected processors (each with $n/k$ data qubits and $m$ ancillas),
we prove the communication complexity satisfies $O\left(\max\{4^{(1-1/k)n - m},
n\}\right)$--for example, $O(2^n)$ when $m=0$ and $k=2$--and establish the
tightness of this upper bound. We further extend the analysis to approximation
models and general network topologies. Second, for special unitaries, we show
that both the Quantum Fourier Transform (QFT) and Clifford circuits admit
linear upper bounds on communication complexity in the exact model,
outperforming the trivial quadratic bounds applicable to these cases. In the
approximation model, QFT's communication complexity reduces drastically from
linear to logarithmic, while Clifford circuits retain a linear lower bound.
These results offer fundamental insights for optimizing communication in
distributed quantum unitary implementation, advancing the feasibility of
large-scale distributed quantum computing (DQC) systems.

</details>


### [298] [Quantum time-marching algorithms for solving linear transport problems including boundary conditions](https://arxiv.org/abs/2511.04271)
*Sergio Bengoechea,Paul Over,Thomas Rung*

Main category: quant-ph

TL;DR: 该研究提出了一种新的量子时间推进算法，用于模拟多维线性传输现象，并实现了任意边界条件下的高成功率和线性时间复杂度。


<details>
  <summary>Details</summary>
Motivation: 模拟多维线性传输现象，尤其是在具有任意边界条件下，是该研究的主要动机。

Method: 该方法将线性组合酉算法应用于块编码扩散动力学，并使用镜像法或直接编码离散时间推进算子的酉分解来处理任意边界条件。

Result: 研究表明，所提出的算法具有最优的成功率和线性时间复杂度，并通过模拟带有不同边界条件的热方程进行了验证。

Conclusion: 该量子时间推进算法在处理多维线性传输现象方面是实用且高效的，为在容错量子计算机上进行此类模拟提供了可能。

Abstract: This article presents the first complete application of a quantum
time-marching algorithm for simulating multidimensional linear transport
phenomena with arbitrary boundaries, whereby the success probabilities are
problem intrinsic. The method adapts the linear combination of unitaries
algorithm to block encode the diffusive dynamics, while arbitrary boundary
conditions are enforced by the method of images only at the cost of one
additional qubit per spatial dimension. As an alternative to the non-periodic
reflection, the direct encoding of Neumann conditions by the unitary
decomposition of the discrete time-marching operator is proposed. All presented
algorithms indicate optimal success probabilities while maintaining linear time
complexity, thereby securing the practical applicability of the quantum
algorithm on fault-tolerant quantum computers. The proposed time-marching
method is demonstrated through state-vector simulations of the heat equation in
combination with Neumann, Dirichlet, and mixed boundary conditions.

</details>


### [299] [Random access Bell game by sequentially measuring the control of the quantum SWITCH](https://arxiv.org/abs/2511.04272)
*Gaurang Agrawal,Saptarshi Roy*

Main category: quant-ph

TL;DR: 该研究提出了一种名为随机接入贝尔博弈（RABG）的新任务，用于在噪声环境中测试贝尔不等式的违反情况。研究人员探索了使用量子开关（SWITCH）来控制噪声信道顺序以减轻噪声影响的策略，但发现其在标准设置下无效。最终，他们开发了一种利用初始纠缠和顺序测量来控制量子开关的协议，该协议能够在任意多的信道应用后保证贝尔不等式的违反，并允许在任意选定的回合实现近乎最大化的贝尔违反，同时确保所有先前回合的违反。该协议被证明对广义 GHZ 态有效，但对 W 类态无效，从而提供了一种区分这两种多方纠缠类型的方法。


<details>
  <summary>Details</summary>
Motivation: 在有噪声的环境中保持量子关联（如贝尔非局域性）对于量子技术至关重要，而这是一个基本挑战。

Method: 引入了随机接入贝尔博弈（RABG），其中纠缠粒子经过一系列相同的噪声块，并在随机选择的时间点（接入节点）测试违反贝尔不等式的能力。研究了该博弈在由两个完整擦除信道组成的噪声块配置下的性能，并尝试通过相干地控制噪声中信道的顺序来减轻噪声的影响。开发了一种利用目标和控制之间的初始纠缠以及对控制系统进行顺序、不尖锐测量的协议。

Result: 在随机接入贝尔博弈的配置中，标准的量子开关在控制中使用相干态未能提供任何优势。然而，所提出的协议能够保证在任意数量的信道应用后违反贝尔不等式，并能在任意回合实现近乎最大化的贝尔违反，同时确保所有先前回合的违反。该协议对广义 GHZ 态有效，但对 W 类态无效。

Conclusion: 所提出的协议能够通过利用目标和控制之间的初始纠缠以及顺序、不尖锐的测量，在噪声环境中保持贝尔不等式的违反，尤其是在广义 GHZ 态的情况下。这不仅克服了噪声的挑战，还为区分 GHZ 态和 W 类态提供了操作方法。

Abstract: Preserving quantum correlations such as Bell nonlocality in noisy
environments remains a fundamental challenge for quantum technologies. We
introduce the Random Access Bell Game (RABG), a task where an entangled
particle propagates through a sequence of identical noisy blocks, and the
ability to violate a Bell inequality is tested at a randomly chosen point
(access node). We consider a scenario where each noisy block is composed of two
complete erasure channels, an extreme entanglement-breaking channel with
vanishing quantum and classical capacities. We investigate the performance of
the Random Access Bell Game in this configuration and attempt to mitigate the
effect of noise by coherently controlling the order of each channel in the
noise using the quantum {\tt SWITCH}. However, the quantum {\tt SWITCH} in its
canonical setup with a coherent state in the control fails to provide any
advantage in the Random Access Bell Game. Our main contribution is a protocol
that leverages initial entanglement between the target and control of the
quantum {\tt SWITCH} and employs sequential, unsharp measurements on the
control system, showing that it is possible to guarantee a Bell violation after
an arbitrarily large number of channel applications. Furthermore, our protocol
allows for a near-maximal (Tsirelson bound) Bell violation to be achieved at
any desired round, while still ensuring violations in all preceding rounds. We
prove that this advantage is specific to generalized
Greenberger-Horne-Zeilinger (GHZ) states, as the protocol fails for W-class
states, thus providing an operational way to distinguish between these two
fundamental classes of multipartite entanglement.

</details>


### [300] [Quasiprobabilities from incomplete and overcomplete measurements](https://arxiv.org/abs/2511.04274)
*Jan Sperling,Laura Ares,Elizabeth Agudelo*

Main category: quant-ph

TL;DR: 本文讨论了如何从通用测量（包括噪声测量）中（重新）构建拟概率表示，并提出了相应的非经典性概念。


<details>
  <summary>Details</summary>
Motivation: 拟概率表示在量子信息领域，特别是在量子光学中，扮演着重要角色，但其从实验测量中构建，尤其是在存在噪声或信息不完整的情况下，仍面临挑战。本文旨在提供一个通用的框架来解决这些问题。

Method: 本文提出了一种基于测量操作的通用框架，用于从（可能带有噪声的）通用测量中重建拟概率分布。该方法推广了诸如 Kirkwood-Dirac 拟概率和量子光学中的 s 参量拟概率等概念。通过单量子比特系统，对不同的测量方案及其产生的拟概率分布和非经典态集合进行了比较和例证。

Result: 研究表明，信息不完整或过完备的测量场景会显著影响对经典态的判断。单量子比特系统的例子展示了不同测量方案如何影响拟概率分布的重建以及哪些态被认为是“非经典”的。

Conclusion: 本文提供了一个通用的框架，用于从各种测量（包括噪声和信息不完整/过完备的测量）中构建拟概率表示，并推广了现有的拟概率概念。这有助于更准确地评估量子态的非经典性。

Abstract: We discuss the (re-)construction of quasiprobability representations from
generic measurements, including noisy ones. Based on the measurement under
study, quasiprobabilities and the associated concept of nonclassicality are
introduced. A practical concern that we address is the treatment of
informationally incomplete and overcomplete measurement scenarios, which can
significantly alter the assessment of which states are deemed classical.
Notions, such as Kirkwood-Dirac quasiprobabilities and s-parametrized
quasiprobabilities in quantum optics, are generalized by our approach.
Single-qubit systems are used to exemplify and to compare different measurement
schemes, together with the resulting quasiprobabilities and set of nonclassical
states.

</details>


### [301] [Cluster States Generation with a Quantum Metasurface](https://arxiv.org/abs/2511.04297)
*Yehonatan Levin,Uri Israeli,Rivka Bekenstein*

Main category: quant-ph

TL;DR: 使用量子超表面实现光子簇状态生成协议。


<details>
  <summary>Details</summary>
Motivation: 过去的簇状态生成协议在物理实现中存在损耗问题，限制了效率和最大量子比特数。

Method: 利用量子超表面（由亚波长原子阵列组成）实现光子簇状态生成，包括二维簇状态和树簇状态。通过量子超表面实现两比特量子逻辑门（CNOT, CZ, E），保真度超过0.9，并分析了热涨落等实际条件对保真度的影响。

Result: 实现了保真度超过0.9的两比特量子逻辑门，并分析了实际条件下的保真度。

Conclusion: 量子超表面为实现高效率、低损耗的光子簇状态生成提供了可行方案，并在量子计算和通信领域具有广泛应用前景。

Abstract: We investigate the implementation of photonic cluster state generation
protocols using quantum metasurfaces comprising sub-wavelength atomic arrays
which enables quantum-controlled reflectivity. These cluster states are
generated using fundamental quantum logic gates and enable wide-ranging
applications in quantum computation and communication. In the past few years,
certain protocols have been developed, but their physical realizations induces
natural losses on the system mainly originated from coupling the photonic
structures, setting a limit on the efficiency and maximal qubit number. In this
paper, we examine a physical implementation of two specific protocols for
generating distinct cluster states: a two-dimensional cluster state and a tree
cluster state. Our approach leverages the unique properties of a quantum
metasurface and its free space settings to implement two-qubit quantum-logic
gates, namely CNOT, CZ, and E gates, with practical fidelities exceeding 0.9,
and potential speed-up due to parallelism. In addition, we analyze these
protocols fidelities for practical conditions of potential implementation
experiments, such as thermal fluctuation of trapped atoms.

</details>


### [302] [Synchronization effects in a periodically driven two-level system](https://arxiv.org/abs/2511.04339)
*Federico Settimo,Bassano Vacchini*

Main category: quant-ph

TL;DR: 驱动两能级系统在非马尔可夫环境中表现出鲁棒的相位同步，当驱动幅度与频率之比满足特定条件时，同步度迅速达到一个有限值。


<details>
  <summary>Details</summary>
Motivation: 研究了驱动两能级系统与非马尔可夫环境耦合时的相位同步现象。

Method: 采用数值精确的层级方程模拟，不依赖旋转波近似处理系统-浴耦合和相干驱动。

Result: 观察到鲁棒的相位锁定现象，且当驱动幅度与频率之比等于贝塞尔函数J0的零点时（共振比条件），同步度迅速达到有限值。

Conclusion: 通过周期驱动哈密顿量的傅里叶分析得到的静态近似，解释了观察到的相位同步现象。

Abstract: We study phase-synchronization in a driven two-level system coupled to a
non-Markovian bosonic reservoir. The dynamics is described by treating the
system-bath coupling and the coherent drive without invoking the rotating-wave
approximation, and simulated using the numerically exact hierarchical equations
of motion. We observe that a robust phase-locking develops and that the
corresponding synchronization measure rapidly acquires a finite value when the
system is tuned to what we identify as a resonant-ratio condition, namely when
the ratio between the drive amplitude and its frequency coincides with a zero
of the Bessel function $J_0$. We provide an explanation for this phenomenon by
means of a static approximation derived from a Fourier analysis of the
periodically driven Hamiltonian.

</details>


### [303] [A General Strategy for Realizing Mpemba Effects in Open Quantum Systems](https://arxiv.org/abs/2511.04354)
*Yaru Liu,Yucheng Wang*

Main category: quant-ph

TL;DR: Mpemba效应在经典和量子系统中都存在，但量子Mpemba效应通常只在特定初始状态下才出现。本研究提出了一种通用的、实验上可行的策略，通过暂时的键-耗散猝灭来选择性地抑制或增强慢速弛豫模式，从而独立于系统和初始状态来重塑弛豫路径，实现量子Mpemba效应和反向量子Mpemba效应。该机制在具有退相干和边界耗散的系统中得到验证，并提出了冷原子实现方案。


<details>
  <summary>Details</summary>
Motivation: Mpemba效应在经典和量子系统中都存在，但量子Mpemba效应（QME）通常只在特定的初始状态下才出现，这限制了其普遍性。本研究旨在提出一种通用且实验上可行的策略，以实现QME和反向QME。

Method: 通过应用暂时的键-耗散猝灭（temporary bond-dissipation quench），选择性地抑制或增强慢速弛豫模式，从而独立于系统和初始状态来重塑弛豫路径。

Result: 在具有退相干和边界耗散的系统中演示了该机制，并概述了可行的冷原子实现方案。该方法能够实现量子Mpemba效应和反向量子Mpemba效应。

Conclusion: 可控耗散是一种通用的量子控制、加速弛豫和有效非平衡协议的工具。

Abstract: The Mpemba effect, where a state farther from equilibrium relaxes faster than
one closer to it, is a striking phenomenon in both classical and quantum
systems. In open quantum systems, however, the quantum Mpemba effect (QME)
typically occurs only for specifically chosen initial states, which limits its
universality. Here we present a general and experimentally feasible strategy to
realize both QME and anti-QME. By applying a temporary bond-dissipation quench,
we selectively suppresses or enhances slow relaxation modes, thereby reshaping
relaxation pathways independently of both the system and the initial state. We
demonstrate this mechanism in systems with dephasing and boundary dissipation,
and outline feasible cold-atom implementations. Our results establish
controllable dissipation as a versatile tool for quantum control, accelerated
relaxation, and efficient nonequilibrium protocols.

</details>


### [304] [Neutral-atom quantum computation using multi-qubit geometric gates via adiabatic passage](https://arxiv.org/abs/2511.04359)
*Sinchan Snigdha Rej,Bimalendu Deb*

Main category: quant-ph

TL;DR: 通过一种新的双STIRAP脉冲序列，在保持高保真度的同时，实现了对环境噪声更具鲁棒性的两比特和多比特量子门，并成功应用于Grover搜索算法。


<details>
  <summary>Details</summary>
Motivation: 传统的基于里德堡阻塞的相位门依赖于动力学相位累积，容易受到环境涨落的影响。本文提出了一种基于绝热几何相位的方法，以提高量子门的鲁棒性。

Method: 利用双STIRAP（双激发拉曼绝热通道）脉冲序列，在可单独寻址的中性原子系统中实现可控的几何相位，从而构建两比特和多比特量子门。

Result: 在0.6微秒的操作时间内，实现了98%到99%的门保真度。通过误差分析表明，该方法对拉比频率涨落、有限阻塞强度和原子位置变化具有很强的抵抗力。对Grover搜索算法的模拟显示出高成功率。

Conclusion: 所提出的绝热几何相位门方法在物理上是可行的，并且具有可扩展性，为实现容错中性原子量子计算提供了一条有希望的途径。

Abstract: Adiabatic geometric phase gates offer enhanced robustness against
fluctuations compared to con- ventional Rydberg blockade-based phase gates that
rely on dynamical phase accumulation. We theoretically demonstrate two- and
multi-qubit phase gates in a neutral atom architecture, relying on a double
stimulated Raman adiabatic passage (double-STIRAP) pulse sequence that imprints
a controllable geometric phase on the qubit systems. The system is designed in
such a way that every atom is individually addressable, and moreover, no extra
laser is required to be applied on the target atom while scaling up the system
from two- to multi-qubit quantum gates. The gate fidelity has been numerically
analyzed by changing the gate operation time, and we find that 98% to 99%
fidelity can be achieved for gate time $\simeq$ 0.6 $\mu$s. We perform a
systematic error analysis, which re- veals that our proposed gates can exhibit
strong resilience against fluctuations in Rabi frequencies, finite blockade
strength, and atomic position variations. These results establish our approach
as a physically feasible and scalable pathway toward fault-tolerant quantum
computation with neutral atoms. We simulate Grover's search algorithm for two-,
three-, and four-qubit systems with high success probability and thereby
demonstrate the utility and scalability of our proposed gates for quantum
computation.

</details>


### [305] [Minimum measurements quantum protocol for band structure calculation](https://arxiv.org/abs/2511.04389)
*Michal Krejčí,Lucie Krejčí,Ijaz Ahamed Mohammad,Martin Plesch,Martin Friák*

Main category: quant-ph

TL;DR: 提出了一种量子测量协议，将测量设置减少到三个，不随量子比特数量扩展，适用于电子结构计算。


<details>
  <summary>Details</summary>
Motivation: 量子测量协议是量子计算的关键组成部分，但不同的可观测量通常需要不同的测量基，导致测量配置数量随量子比特数增加而增加，成为一个瓶颈。

Method: 从晶格系统中紧束缚（TB）哈密顿量的对称性推导出测量协议，并将其集成到变分量子奇异（VQD）算法中。

Result: 在二维CuO₂方格（3量子比特）和双层石墨烯（4量子比特）系统上演示了该协议的性能。

Conclusion: 该协议可推广到具有高对称性的复杂多体哈密顿量，有望实现量子优越性。

Abstract: Protocols for quantum measurement are an essential part of quantum computing.
Measurements are no longer confined to the final step of computation but are
increasingly embedded within quantum circuits as integral components of
noise-resilient algorithms. However, each observable typically requires a
distinct measurement basis, often demanding a different circuit configuration.
As the number of such configurations typically grows with the number of qubits,
different measurement configurations constitute a major bottleneck. Focusing on
electronic structure calculations in crystalline systems, we propose a
measurement protocol that maximally reduces the number of measurement settings
to just three, independent of the number of qubits. This makes it one of the
few known protocols that do not scale with qubit number. In particular, we
derive the measurement protocol from the symmetries of tight-binding (TB)
Hamiltonians and implement it within the Variational Quantum Deflation (VQD)
algorithm. We demonstrate its performance on two systems, namely a
two-dimensional CuO$_2$ square lattice (3 qubits) and bilayer graphene (4
qubits). The protocol can be generalized to more complex many-body Hamiltonians
with high symmetry, providing a potential path toward future demonstrations of
quantum advantage.

</details>


### [306] [Microwave Output Stabilization of a Qubit Controller via Device-Level Temperature Control](https://arxiv.org/abs/2511.04397)
*Yoshinori Kurimoto,Dongjun Lee,Koichiro Ban,Shinichi Morisaka,Toshi Sumida,Hidehisa Shiomi,Yosuke Ito,Yuuya Sugita,Makoto Negoro,Ryutaro Ohira,Takefumi Miyoshi*

Main category: quant-ph

TL;DR: QuEL-1 SE是一个为超导量子比特设计的多通道量子比特控制器，通过主动热稳定关键模拟集成电路来抑制长期幅度和相位漂移，并在24小时内稳定监测15个微波输出通道，结果显示幅度标准偏差为0.09%-0.22%，相位偏差为0.35°-0.44°，这表明其稳定性足以支持需要容错的长期量子运算。


<details>
  <summary>Details</summary>
Motivation: 为了抑制超导量子比特控制中的长期幅度和相位漂移，需要一种能够提供高稳定性的多通道量子比特控制器。

Method: 设计并实现了一个名为QuEL-1 SE的多通道量子比特控制器，该控制器集成了对锁相环、放大器和混频器等关键模拟集成电路的主动热稳定功能。使用通用的模数转换器，同时监测15个微波输出通道24小时，以评估幅度和相位的稳定性。进一步评估了这些偏差对量子门操作的影响，特别是对Xπ/2门平均保真度的影响。

Result: 对15个微波输出通道进行了24小时的监测，结果显示归一化的幅度标准偏差在0.09%到0.22%之间（平均值为0.15%），相位偏差在0.35°到0.44°之间（平均值为0.39°）。计算得出，幅度误差导致的门保真度损失为2×10⁻⁶，相位误差为2×10⁻⁵，这些数值远低于表面码等容错方案的阈值。

Conclusion: QuEL-1 SE系统具有出色的幅度和相位稳定性，能够支持可靠的长期量子运算，证明了其作为可扩展的超导量子比特（及其他量子比特模式）控制平台的实用性。

Abstract: We present the design and performance of QuEL-1 SE, which is a multichannel
qubit controller developed for superconducting qubits. The system incorporates
the active thermal stabilization of critical analog integrated circuits, such
as phase-locked loops, amplifiers, and mixers, to suppress the long-term
amplitude and phase drift. To evaluate the amplitude and phase stability, we
simultaneously monitor 15 microwave output channels over 24 h using a common
analog-to-digital converter. Across the channels, the normalized amplitude
exhibits standard deviations of 0.09\%--0.22\% (mean: 0.15\%), and the phase
deviations are 0.35$^\circ$--0.44$^\circ$ (mean: 0.39$^\circ$). We further
assess the impact of these deviations on quantum gate operations by estimating
the average fidelity of an $X_{\pi/2}$ gate under the coherent errors
corresponding to the deviations. The resulting gate infidelities are $2\times
10^{-6}$ for amplitude errors and $2\times 10^{-5}$ for phase errors, which are
significantly lower than typical fault-tolerance thresholds such as those of
the surface code. These results demonstrate that the amplitude and phase
stability of QuEL-1 SE enables reliable long-duration quantum operations, thus
highlighting its utility as a scalable control platform for superconducting and
other qubit modalities.

</details>


### [307] [Tight Analysis of a Grover-based Quantum Secret Sharing Scheme](https://arxiv.org/abs/2511.04399)
*Santanu Majhi,Debajyoti Bera*

Main category: quant-ph

TL;DR: 该研究提出了一个基于量子搜索的秘密共享框架，旨在通过公共信道进行安全通信，无需多轮检测窃听。研究对其进行了完整表征，改进了协议的抗窃听能力，但证明了完全的安全性在此框架下不可行。


<details>
  <summary>Details</summary>
Motivation: 现有的量子秘密共享协议通常需要安全通信通道或多轮统计分析来检测窃听者。本研究旨在分析和改进一个可在公共信道上运行、无需多轮检测的量子搜索秘密共享框架。

Method: 对Hsu（2003）提出的量子搜索秘密共享框架进行了完整的正确性和安全性分析，并在此基础上改进了协议，以增强其抗窃听能力。

Result: 通过对Hsu（2003）的框架进行分析，发现了其安全性和正确性，并改进了协议。然而，证明了该框架无法实现完全抵抗窃听者的安全。

Conclusion: 虽然对Hsu（2003）的量子搜索秘密共享框架进行了改进，提高了其抗窃听能力，但最终证明完全抵抗窃听者在该框架下是不可能的。

Abstract: Secret-sharing schemes allow a dealer to split a secret into multiple
"shares" and distribute them individually among many parties while mandating
certain constraints on its reconstruction. Such protocols are usually executed
over a secure communication channel since an eavesdropper, after intercepting
all the shares, is expected to be able to reconstruct the secret. Leveraging
the unique properties of quantum channels, several quantum protocols have been
designed for secret sharing. However, almost all of them detect the presence of
an eavesdropper by statistical analysis of the outcome of multiple rounds, or
simply require a secure channel of communication.
  We present a complete characterisation of the correctness and security
properties of a quantum-search based secret-sharing framework proposed by Hsu
(2003). The scheme was designed to work over public channels without requiring
multiple rounds to detect eavesdropping. Our characterisation allowed us to
improve the original protocol to be more resistant towards eavesdropping.
However, we prove that complete security against an eavesdropper is not
possible in this framework.

</details>


### [308] [Mixed-State Measurement-Induced Phase Transitions in Imaginary-Time Dynamics](https://arxiv.org/abs/2511.04402)
*Yi-Ming Ding,Zenan Liu,Xu Tian,Zhe Wang,Yanzhang Zhu,Zheng Yan*

Main category: quant-ph

TL;DR: MDITE是一种新的框架，用于探索混合态量子相和退相干驱动的临界性。它通过交替进行虚时演化和测量来产生相干恢复动力学和退相干诱导事件之间的竞争，从而产生一类新的混合态相变。


<details>
  <summary>Details</summary>
Motivation: 探索非平衡量子物质和量子信息中的混合态相变。

Method: 提出了一种名为测量- the imaginary-time evolution (MDITE) 的新框架，该框架结合了虚时演化和投影测量。

Result: 在一维横向场伊辛模型和二维二聚化海森堡模型中，MDITE 产生了新的混合态相变。还提供了一种用于有效研究 MDITE 的图示表示。

Conclusion: MDITE 是研究非幺正动力学和退相干在多体量子系统中作用的强大范例。

Abstract: Mixed-state phase transitions have recently attracted growing attention as a
new frontier in nonequilibrium quantum matter and quantum information. In this
work, we introduce the measurement-dressed imaginary-time evolution (MDITE) as
a novel framework to explore mixed-state quantum phases and decoherence-driven
criticality. In this setup, alternating imaginary-time evolution and projective
measurements generate a competition between coherence-restoring dynamics and
decoherence-inducing events. While reminiscent of monitored unitary circuits,
MDITE fundamentally differs in that the physics is encoded in decoherent mixed
states rather than in quantum trajectories. We demonstrate that this interplay
gives rise to a new class of mixed-state phase transitions, using numerical
simulations of the one-dimensional transverse-field Ising model and the
two-dimensional dimerized Heisenberg model. Furthermore, we provide a
diagrammatic representation of the evolving state, which naturally enables
efficient studies of MDITE with quantum Monte Carlo and other many-body
numerical methods, thereby extending investigations of mixed-state phase
transitions to large-scale and higher-dimensional Hamiltonians. Our results
highlight MDITE as a powerful paradigm for investigating non-unitary dynamics
and the fundamental role of decoherence in many-body quantum systems.

</details>


### [309] [Robustness of quantum data hiding against entangled catalysts and memory](https://arxiv.org/abs/2511.04408)
*Aby Philip,Alexander Streltsov*

Main category: quant-ph

TL;DR: 量子数据隐藏技术在可分量子态下具有鲁棒性，但对于某些纠缠态，量子记忆可以增强信息提取。


<details>
  <summary>Details</summary>
Motivation: 研究在有额外量子资源辅助的情况下，是否能克服量子数据隐藏的局限性，即信息在量子态中虽然原则上可区分，但在没有量子信道的情况下却几乎无法区分。

Method: 开发了一个通用的状态判别框架，统一了催化和记忆辅助的局部判别协议，并分析了它们揭示隐藏信息的能力。证明了当隐藏态是可分态时，无论是纠缠催化剂还是量子记忆都无法提高最佳判别概率。对于某些纠缠态，可复用的量子记忆可以将局部不可区分的状态转变为几乎可以完美区分的状态。

Result: 可分数据隐藏方案具有鲁棒性；对于某些纠缠态，量子记忆可以显著提高状态的可区分度。

Conclusion: 划定了催化和记忆辅助状态判别的基本极限，并确定可分编码是量子数据隐藏的一种鲁棒策略。

Abstract: Quantum data hiding stores classical information in bipartite quantum states
that are, in principle, perfectly distinguishable, yet remain almost
indistinguishable without access to a quantum communication channel. Here, we
investigate whether this limitation can be overcome when the communicating
parties are assisted by additional quantum resources. We develop a general
framework for state discrimination that unifies catalytic and memory-assisted
local discrimination protocols and analyze their power to reveal hidden
information. We prove that when the hiding states are separable, neither
entangled catalysts nor quantum memory can increase the optimal discrimination
probability, establishing the robustness of separable data-hiding schemes. In
contrast, for some entangled states, a reusable quantum memory turns locally
indistinguishable states into ones that can be discriminated almost perfectly.
Our results delineate the fundamental limits of catalytic and memory-assisted
state discrimination and identify separable encodings as a robust strategy for
quantum data hiding.

</details>


### [310] [Quantum doubles in symmetric blockade structures](https://arxiv.org/abs/2511.04414)
*Hans Peter Büchler,Tobias F. Maier,Simon Fell,Nicolai Lang*

Main category: quant-ph

TL;DR: 我们利用基于里德堡原子的相互作用，通过设计哈密顿量来解决反问题，从而在具有实验现实的相互作用的微观系统中实现所需的拓扑相。


<details>
  <summary>Details</summary>
Motivation: 旨在解决量子多体物理中的“逆问题”，即如何设计一个哈密顿量，在具有实验现实的两体相互作用的微观系统中实现期望的拓扑相。

Method: 在基于里德堡原子的平台上，利用两体阻塞相互作用构建哈密顿量，以实现非阿贝尔量子双模型描述的拓扑序。

Result: 分析了所构建哈密顿量在基态中实现拓扑序的存在性，并提出了制备这些状态的高效方案，以及用于探测任意子统计的受控绝热编织协议。

Conclusion: 提出的构造方法是通用的，适用于任意有限群G的量子双模型D(G)，并以D(S3)为例进行了编织演示。

Abstract: Exactly solvable models of topologically ordered phases with non-abelian
anyons typically require complicated many-body interactions which do not
naturally appear in nature. This motivates the "inverse problem" of quantum
many-body physics: given microscopic systems with experimentally realistic
two-body interactions, how to design a Hamiltonian that realizes a desired
topological phase? Here we solve this problem on a platform motivated by
Rydberg atoms, where elementary two-level systems couple via simple blockade
interactions. Within this framework, we construct Hamiltonians that realize
topological orders described by non-abelian quantum double models. We
analytically prove the existence of topological order in the ground state, and
present efficient schemes to prepare these states. We also introduce protocols
for the controlled adiabatic braiding of anyonic excitations to probe their
non-abelian statistics. Our construction is generic and applies to quantum
doubles $\mathcal{D}(G)$ for arbitrary finite groups $G$. We illustrate
braiding for the simplest non-abelian quantum double $\mathcal{D}(S_3)$.

</details>


### [311] [Estimating ground-state properties in quantum simulators with global control](https://arxiv.org/abs/2511.04434)
*Cristian Tabares,Dominik S. Wild,J. Ignacio Cirac,Peter Zoller,Alejandro González-Tudela,Daniel González-Cuadra*

Main category: quant-ph

TL;DR: 该研究提出了一种新的量子算法，利用全局时间演化来估计量子多体系统的基态能量，避免了传统量子相位估计算法所需的受控操作，并扩展了其在模拟器上的应用。


<details>
  <summary>Details</summary>
Motivation: 精确确定量子多体系统的基态性质是量子模拟面临的主要挑战之一。

Method: 提出了一种利用全局时间演化和测量洛施密特回声来估计基态能量的协议，并结合直接能量测量来求解方程以推断本征能量。

Result: 在自由费米子系统上，该协议的精度比直接能量测量提高了几个数量级，并且随着初始状态保真度的提高而迅速提高。该方法还成功应用于二维伊辛模型和费米-哈伯德模型，并可扩展到其他可观测量。此外，研究还分析了实验误差的影响并提出了误差缓解策略。

Conclusion: 该研究为使用全局控制的量子模拟器以高精度计算物理相关量提供了一条实用的途径。

Abstract: Accurately determining ground-state properties of quantum many-body systems
remains one of the major challenges of quantum simulation. In this work, we
present a protocol for estimating the ground-state energy using only global
time evolution under a target Hamiltonian. This avoids the need for controlled
operations that are typically required in conventional quantum phase estimation
and extends the algorithm applicability to analog simulators. Our method
extracts energy differences from measurements of the Loschmidt echo over an
initial ground-state approximation, combines them with direct energy
measurements, and solves a set of equations to infer the individual
eigenenergies. We benchmark this protocol on free-fermion systems, showing
orders-of-magnitude precision gains over direct energy measurements on the
initial state, with accuracy improving rapidly with initial-state fidelity and
persisting for hundreds of modes. We further demonstrate applicability to the
2D Ising and Fermi-Hubbard models and show that the approach extends naturally
to other observables such as order parameters. Finally, we analyze the effect
of experimental imperfections and propose error-mitigation strategies. These
results establish a practical route to compute physically relevant quantities
with high precision using globally controlled quantum simulators.

</details>


### [312] [Limiting one-way distillable secret key via privacy testing of extendible states](https://arxiv.org/abs/2511.04438)
*Vishal Singh,Karol Horodecki,Aby Philip,Mark M. Wilde*

Main category: quant-ph

TL;DR: 该论文确定了可扩展状态通过隐私测试的最大概率，并证明其等于可扩展状态与标准最大纠缠状态之间的最大保真度。


<details>
  <summary>Details</summary>
Motivation: 本研究旨在确定任意 k-可扩展状态通过隐私测试的最大概率，并将其与标准最大纠缠状态之间的最大保真度进行关联，以促进量子信息理论和安全通信领域的发展。

Method: 通过确定任意 k-可扩展状态通过隐私测试的最大概率，并证明该概率等于任意 k-可扩展状态与标准最大纠缠状态之间的最大保真度。

Result: 我们证明了可扩展状态通过隐私测试的最大概率等于其与标准最大纠缠状态之间的最大保真度。此发现提供了一种计算 k-可扩展状态通过隐私测试概率的方法，并为理解量子信息理论中的安全通信限制提供了新的见解。

Conclusion: 本研究在量子信息理论中引入了隐私测试和 k-可扩展状态的概念，并确定了它们之间的量化关系。我们提出的界限为单次和多次量子通信场景下的可蒸馏密钥和纠缠提供了有效的计算方法，并在某些情况下显著优于现有界限。

Abstract: The notions of privacy tests and $k$-extendible states have both been
instrumental in quantum information theory, particularly in understanding the
limits of secure communication. In this paper, we determine the maximum
probability with which an arbitrary $k$-extendible state can pass a privacy
test, and we prove that it is equal to the maximum fidelity between an
arbitrary $k$-extendible state and the standard maximally entangled state. Our
findings, coupled with the resource theory of $k$-unextendibility, lead to an
efficiently computable upper bound on the one-shot, one-way distillable key of
a bipartite state, and we prove that it is equal to the best-known efficiently
computable upper bound on the one-shot, one-way distillable entanglement. We
also establish efficiently computable upper bounds on the one-shot,
forward-assisted private capacity of channels. Extending our formalism to the
independent and identically distributed setting, we obtain single-letter
efficiently computable bounds on the $n$-shot, one-way distillable key of a
state and the $n$-shot, forward-assisted private capacity of a channel. For
some key examples of interest, our bounds are significantly tighter than other
known efficiently computable bounds.

</details>


### [313] [Robust certification of non-projective measurements: theory and experiment](https://arxiv.org/abs/2511.04446)
*Raphael Brinster,Peter Tirler,Shishir Khandelwal,Michael Meth,Hermann Kampermann,Dagmar Bruß,Rainer Blatt,Martin Ringbauer,Armin Tavakoli,Nikolai Wyderka*

Main category: quant-ph

TL;DR: POVMs 的不可模拟性可以通过半定规划层级来证明，并在量子处理器上进行了实验验证。


<details>
  <summary>Details</summary>
Motivation: 确定正算子值测量（POVM）在什么条件下优于投影测量是一个悬而未决的问题，特别是对于可投影模拟的POVM，它们不提供任何优势。因此，表征可模拟与不可模拟POVM之间的界限非常重要。

Method: 提出并演示了一种通过引入半定规划层级来认证POVM不可模拟性的通用方法，并为任意POVM的关键可见性不可模拟性度量提供了上限。

Result: 该方法在许多情况下是精确的，并且优于以前的标准。通过使用囚禁离子量子处理器，对二维和三维POVM的不可模拟性进行了实验认证，并提出了一个改进框架以应对状态制备误差。

Conclusion: 所提出的半定规划层级为认证POVM的不可模拟性提供了一个强大而通用的工具，并通过实验得到了验证，还扩展到了具有额外辅助系统的场景。

Abstract: Determining the conditions under which positive operator-valued measures
(POVMs), the most general class of quantum measurements, outperform projective
measurements remains a challenging and largely unresolved problem. Of
particular interest are projectively simulable POVMs, which can be realized
through probabilistic mixtures of projective measurements, and therefore offer
no advantage over projective schemes. Characterizing the boundary between
simulable and non-simulable POVMs is, however, a difficult task, and existing
tools either fail to scale efficiently, provide limited experimental
feasibility or work only for specific POVMs. Here, we introduce and demonstrate
a general method to certify non-simulability of a POVM by introducing a
hierarchy of semidefinite programs. It provides upper bounds on the
non-simulability measure of critical visibility of arbitrary POVMs which are
tight in many cases and outperform previously known criteria. We experimentally
certify the non-simulability of two- and three-dimensional POVMs using a
trapped-ion qudit quantum processor by constructing non-simulability witnesses
and introduce a modification of our framework that makes them robust against
state preparation errors. Finally, we extend our results to the setting where
an additional ancilla system is available.

</details>


### [314] [Hybrid Single-Ion Atomic-Ensemble Node for High-Rate Remote Entanglement Generation](https://arxiv.org/abs/2511.04488)
*Benedikt Tissot,Soubhadra Maiti,Emil R. Hellebek,Anders Søndberg Sørensen*

Main category: quant-ph

TL;DR: 通过结合离子阱节点和基于稀土离子系综的单原子系统，我们开发了一种混合量子网络架构，通过匹配不同带宽的光子来加速离子-离子纠缠的生成。


<details>
  <summary>Details</summary>
Motivation: 量子网络需要在生成纠缠的同时处理信息，但现有的量子系统（如系综量子存储器和单原子系统）各有优缺点。

Method: 提出一种混合架构，结合离子阱和基于稀土离子系综的单原子系统，并解决其光子带宽不匹配的问题，以实现并行任务执行。

Result: 该方法可以显著加速跨越数百公里的量子网络中的离子-离子纠缠生成。

Conclusion: 所提出的混合量子网络架构能够有效结合不同量子系统的优势，显著提高量子网络的纠缠生成速率和处理能力。

Abstract: Different quantum systems possess different favorable qualities. On the one
hand, ensemble-based quantum memories are suited for fast multiplexed
long-range entanglement generation. On the other hand, single-atomic systems
provide access to gates for processing of information. Both of those can
provide advantages for high-rate entanglement generation within quantum
networks. We develop a hybrid architecture that takes advantage of these
properties by combining trapped-ion nodes and nodes comprised of spontaneous
parametric down conversion photon pair sources and absorptive memories based on
rare-earth ion ensembles. To this end, we solve the central challenge of
matching the different bandwidths of photons emitted by those systems in an
initial entanglement-generation step. This enables the parallel execution of
multiple probabilistic tasks in the initial stage. We show that our approach
can lead to a significant speed-up for the fundamental task of creating ion-ion
entanglement over hundreds of kilometers in a quantum network.

</details>


### [315] [Continuous matrix product operators for quantum fields](https://arxiv.org/abs/2511.04545)
*Erickson Tjoa,J. Ignacio Cirac*

Main category: quant-ph

TL;DR: 本文提出了一种用于量子场论的连续矩阵乘积算子ansatz，该ansatz可以在不参考任何晶格参数的情况下以有限数量的矩阵值函数形式表示，并且能够直接在连续统中保持纠缠面积定律。


<details>
  <summary>Details</summary>
Motivation: 本文的动机是为量子场论提供一种新的算符表示方法，并探索其在处理纠缠和构建新酉算符方面的应用。

Method: 本文提出了一种连续矩阵乘积算子ansatz，并展示了它如何表示为有限数量的矩阵值函数，如何通过矩阵乘积算符的连续极限得到，以及如何保持纠缠面积定律，并将连续矩阵乘积状态映射到另一个连续矩阵乘积状态。

Result: 通过该ansatz，研究人员能够构建超出量子细胞自动机范围的几类连续矩阵乘积酉算符。

Conclusion: 本文提出的连续矩阵乘积算子ansatz为量子场论提供了一种有效的工具，可用于处理纠缠问题并构建新的酉算符。

Abstract: In this work we introduce an ansatz for continuous matrix product operators
for quantum field theory. We show that (i) they admit a closed-form expression
in terms of finite number of matrix-valued functions without reference to any
lattice parameter; (ii) they are obtained as a suitable continuum limit of
matrix product operators; (iii) they preserve the entanglement area law
directly in the continuum, and in particular they map continuous matrix product
states (cMPS) to another cMPS. As an application, we use this ansatz to
construct several families of continuous matrix product unitaries beyond
quantum cellular automata.

</details>


### [316] [Scaling advantage with quantum-enhanced memetic tabu search for LABS](https://arxiv.org/abs/2511.04553)
*Alejandro Gomez Cadavid,Pranav Chandarana,Sebastián V. Romero,Jan Trautmann,Enrique Solano,Taylor Lee Patti,Narendra N. Hegade*

Main category: quant-ph

TL;DR: QE-MTS是一种混合算法，通过结合量子优化和经典算法，在低自相关二元序列（LABS）问题上取得了优于现有经典算法和量子近似优化算法的性能，并显著降低了运行时间。


<details>
  <summary>Details</summary>
Motivation: 解决低自相关二元序列（LABS）问题，并寻求一种能够超越现有经典算法和量子近似优化算法的优化方法，以提高计算效率和可扩展性。

Method: 将量子优化（DCQO）生成的高质量初始状态用于初始化经典的MTS算法，形成QE-MTS混合算法，并进行两阶段引导分析以确认其性能。

Result: QE-MTS在LABS问题上实现了$\	ext{O}(1.24^N)$的时间复杂度，优于经典算法的$\	ext{O}(1.34^N)$和量子近似优化算法的$\	ext{O}(1.46^N)$，且电路深度减少了6倍。

Conclusion: 量子增强可以直接提高经典优化算法在LABS等典型问题上的性能，QE-MTS在$N \	ext{>} 47$时将优于其经典对应算法。

Abstract: We introduce quantum-enhanced memetic tabu search (QE-MTS), a non-variational
hybrid algorithm that achieves state-of-the-art scaling for the
low-autocorrelation binary sequence (LABS) problem. By seeding the classical
MTS with high-quality initial states from digitized counterdiabatic quantum
optimization (DCQO), our method suppresses the empirical time-to-solution
scaling to $\mathcal{O}(1.24^N)$ for sequence length $N \in [27,37]$. This
scaling surpasses the best-known classical heuristic $\mathcal{O}(1.34^N)$ and
improves upon the $\mathcal{O}(1.46^N)$ of the quantum approximate optimization
algorithm, achieving superior performance with a $6\times$ reduction in circuit
depth. A two-stage bootstrap analysis confirms the scaling advantage and
projects a crossover point at $N \gtrsim 47$, beyond which QE-MTS outperforms
its classical counterpart. These results provide evidence that quantum
enhancement can directly improve the scaling of classical optimization
algorithms for the paradigmatic LABS problem.

</details>


### [317] [Preferred Basis in Coupled Electron-Nuclear Dynamics](https://arxiv.org/abs/2511.04559)
*Junhyeok Bang*

Main category: quant-ph

TL;DR: 提出一个电子-核动力学的自然高效表征，并在此基础上重新审视了混合量子-经典（MQC）方法。


<details>
  <summary>Details</summary>
Motivation: 当前对强耦合系统（特别是电子-核动力学）的非绝热动力学理解有限，并且现有表征方法在物理解释和模拟精度上存在不足。

Method: 借鉴退相干理论中的指针态和优选态概念，构建电子-核动力学的一个优选表征。在此框架下，分析了混合量子-经典（MQC）方法所利用的独立动力学与纠缠的关系，以及绝热玻恩-奥本海默态作为近似优选表征的条件。

Result: 1) 混合量子-经典（MQC）方法中的独立动力学可以被理解为在优选表征下的一种纠缠表现，而非退相干的直接结果。2) 绝热玻恩-奥本海默态满足近似优选表征的条件。通过优选态的视角，阐明了MQC方法的适用性并指明了改进方向。

Conclusion: 提出的优选表征方法能够调和现有近似方法与更基本的量子理论结构，为开发更可靠的MQC方法提供了系统性途径。

Abstract: Beyond the adiabatic regime, our understanding of quantum dynamics in coupled
systems remains limited, and the choice of representation continues to obscure
physical interpretation and simulation accuracy. Here we propose a natural and
efficient basis for electron nuclear dynamics by drawing on the concepts of
pointer and preferred states from decoherence theory, adapted to systems where
electrons and nuclei interact strongly. Within this framework, we show that 1)
the independent dynamics exploited by mixed quantum classical (MQC) methods is
best understood as a manifestation of entanglement viewed in a preferred basis,
rather than a consequence of decoherence, and 2) the adiabatic Born Oppenheimer
states satisfy the conditions of an approximate preferred basis. This
perspective reconciles widely used approximations with a more fundamental
structure of the theory and provides a systematic route to more reliable MQC
strategies. In effect, we revisit MQC methods through the lens of preferred
states, clarifying when they succeed and how they can be improved.

</details>


### [318] [QEF: Reproducible and Exploratory Quantum Software Experiments](https://arxiv.org/abs/2511.04563)
*Vincent Gierisch,Wolfgang Mauerer*

Main category: quant-ph

TL;DR: QEF是一个轻量级框架，用于系统地、有根据地研究量子算法，强调迭代探索，而非对固定算法进行详尽的经验评估。


<details>
  <summary>Details</summary>
Motivation: 许多工具隐藏了配置或需要临时脚本，阻碍了量子算法的系统研究。

Method: QEF通过简洁的规范捕获量子软件和算法实验的关键方面，该规范可扩展为笛卡尔积以进行大规模参数扫描，支持参数重用以缩短运行时间，并将所有指标和元数据收集到方便探索的格式中。

Result: QEF实现了可重复性和可扩展性，并能方便地与标准统计和可视化软件集成。

Conclusion: QEF旨在降低量子算法（包括针对NISQ设备和未来纠错量子系统）实证研究的实际障碍。

Abstract: Commercially available Noisy Intermediate-Scale Quantum (NISQ) devices now
make small hybrid quantum-classical experiments practical, but many tools hide
configuration or demand ad-hoc scripting.
  We introduce the Quantum Experiment Framework (QEF): A lightweight framework
designed to support the systematic, hypothesis-driven study of quantum
algorithms. Unlike many existing approaches, QEF emphasises iterative,
exploratory analysis of evolving experimental strategies rather than exhaustive
empirical evaluation of fixed algorithms using predefined quality metrics. The
framework's design is informed by a comprehensive review of the literature,
identifying principal parameters and measurement practices currently reported
in the field.
  QEF captures all key aspects of quantum software and algorithm experiments
through a concise specification that expands into a Cartesian product of
variants for controlled large-scale parameter sweeps. This design enables
rigorous and systematic evaluation, as well as precise reproducibility. Large
sweeps are automatically partitioned into asynchronous jobs across simulators
or cloud hardware, and ascertain full hyper-parameter traceability. QEF
supports parameter reuse to improve overall experiment runtimes, and collects
all metrics and metadata into a form that can be conveniently explored with
standard statistical and visualisation software.
  By combining reproducibility and scalability while avoiding the complexities
of full workflow engines, QEF seeks to lower the practical barriers to
empirical research on quantum algorithms, whether these are designed for
current NISQ devices or future error-corrected quantum systems.

</details>


### [319] [Homodyne detection for pulse-by-pulse squeezing measurements](https://arxiv.org/abs/2511.04578)
*Tiphaine Kouadou,Elie Gozlan,Loïc Garcia,David Polizzi,David Fainsin,Iris Paparelle,R. L. Rincón Celis,Bastien Oriot,Anthony Abi Aad,Peter Namdar,Ganaël Roland,Nicolas Treps,Bérengère Argence,Valentina Parigi*

Main category: quant-ph

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Homodyne detection is a phase-sensitive measurement technique, essential for
the characterization of continuous-variable (CV)-encoded quantum states of
light. It is a key component to the implementation of CV quantum-information
protocols and benefits from operating, by design, at room temperature. However,
performing high-speed quantum information processing remains a major challenge,
as conventional homodyne detectors often fail to sustain pulsed operation at
high repetition rates due to electronic limitations. We present wideband
homodyne detectors operating at near-infrared (NIR) and telecom wavelengths,
with optimized performance at repetition rates up to 150 MHz. We demonstrate
their performance by resolving the pulse-by-pulse structure of squeezed states
of light at telecom wavelengths while preserving their spectral multimode
properties.

</details>


### [320] [Controlling Hong-Ou-Mandel antibunching via parity governed spectral shaping of biphoton states](https://arxiv.org/abs/2511.04604)
*Mikhail Guselnikov,Alexei D. Kiselev,Andrei Gaidash,George Miroshnichenko,Anton Kozubov*

Main category: quant-ph

TL;DR: 该研究通过对称度参数Ds表征了Hong-Ou-Mandel（HOM）的聚束和反聚束行为，并发现Ds的符号主要由光谱函数φ12的奇偶性质决定。通过实验可调控的光谱相位调制，可以实现聚束和反聚束状态之间的切换，并计算了 संबंध参数与调制参数的关系，发现了与HOM反聚束对应的对称度参数的窄峰。


<details>
  <summary>Details</summary>
Motivation: 研究HOM聚束和反聚束行为，并探索实现这两种状态切换的实验方法。

Method: 利用对称度参数Ds表征HOM聚束和反聚束，Ds由双光子联合谱振幅（JSA）的对称和反对称部分贡献决定。对于特定类型的JSA，Ds的符号主要由光谱函数φ12的奇偶性质决定。研究了通过光谱相位调制产生的调制双光子态，并计算了 संबंध数与调制参数的关系。

Result: Ds的符号主要由光谱函数φ12的奇偶性质决定，其中偶数部分贡献正值，奇数部分贡献负值。通过调节光谱相位，可以实现HOM聚束和反聚束状态的切换。 संबंध数与调制参数之间存在强相关的窄共振峰和窄谷，其中窄谷对应HOM反聚束。

Conclusion: 通过实验可调控的光谱相位调制可以有效地控制HOM聚束和反聚束状态。 संबंध数和对称度参数Ds之间的关系揭示了HOM反聚束现象的细节。

Abstract: We investigate into experimentally detectable effects such as the
Hong-Ou-Mandel (HOM) bunching and antibunching. These regimes can be
characterized using the symmetry degree parameter $D_S$ that enters the
two-photon coincidence probability $P_{2c}=(1-D_S)/2$. In the case of HOM
bunching (antibunching), $D_S$ is positive (negative). Though the symmetry
degree can generally be expressed in terms of the difference between the
contributions coming from the symmetric and antisymmetric parts of the biphoton
joint spectral amplitude (JSA), $\psi(\omega_1,\omega_2)$, for a certain
physically realizable class of the JSA, where $\psi(\omega_1,\omega_2)$ is
proportional to the product of amplitudes
$\varphi_1(\omega_1)\varphi_2(\omega_2)$ multiplied by a Gaussian shaped
entangling factor, we find the sign of $D_S$ is primarily governed by the
parity properties of the spectral function,
$\varphi_{12}(\omega)=\varphi_1(\omega)\varphi_2^*(\omega)$. It is the even
(odd) part of $\varphi_{12}=\varphi_{12}^{(+)}+\varphi_{12}^{(-)}$ that meets
the parity condition
$\varphi_{12}^{(+)}(\omega-\Omega)=\varphi_{12}^{(+)}(\Omega-\omega)$
($\varphi_{12}^{(-)}(\omega-\Omega)=- \varphi_{12}^{(-)}(\Omega-\omega)$) to
yield the positive (negative) contribution, $D_S^{(+)}$ ($-D_S^{(-)}$), to the
symmetry degree parameter: $D_S=D_S^{(+)}-D_S^{(-)}$. We have shown that
switching between the bunching and antibunching regimes can be realized using
the experimentally accessible family of modulated biphoton states produced
using the spectral phase modulation fine-tuned via the sub-nanometer scale
variation of the path length. For this class of modulated states, the Schmidt
number has been computed as a function of the modulation parameter. This
dependence reveals the structure of narrow resonance peaks strongly correlated
with the corresponding narrow dips of the symmetry degree where the HOM
antibunching occurs.

</details>


### [321] [Qubit Mapping and Routing tailored to Advanced Quantum ISAs: Not as Costly as You Think](https://arxiv.org/abs/2511.04608)
*Zhaohui Yang,Kai Zhang,Xinyang Tian,Xiangyu Ren,Yingjian Liu,Yunfeng Li,Jianxin Chen,Dawei Ding,Yuanx Xie*

Main category: quant-ph

TL;DR: Canopus是一个统一的量子比特映射/路由框架，适用于多种量子指令集架构（ISA），通过在路由阶段进行深度协同优化来降低路由开销。


<details>
  <summary>Details</summary>
Motivation: 现有量子比特映射/路由方法效率低下，因为它们依赖于忽略物理设备原生门特性的抽象路由模型。虽然先进的ISA（如包含 √iSWAP 和 ZZ(θ) 门的ISA）提供了更好的电路综合能力，但缺乏针对这些ISA的编译器优化策略。

Method: Canopus框架基于双量子比特门的标准表示，专注于通过ISA感知的方法进行量子比特路由，以实现深度协同优化。该框架利用双量子比特标准表示和单复多面体来模拟路由阶段更智能的SWAP插入的综合成本。此外，它通过标准形式将双量子比特门之间的交换关系形式化，为基于交换的优化提供了一种通用方法。

Result: Canopus在不同ISA和拓扑结构上，与最先进的方法相比，持续将路由开销降低了15%-35%。

Conclusion: Canopus提出了一种新颖的量子比特映射/路由框架，能够适应不同的量子ISA，并通过深度协同优化显著降低了路由开销。该研究还为程序模式、量子ISA和硬件拓扑的协同探索提供了一种连贯的方法。

Abstract: Qubit mapping/routing is a critical stage in compilation for both near-term
and fault-tolerant quantum computers, yet existing scalable methods typically
impose several times the routing overhead in terms of circuit depth or
duration. This inefficiency stems from a fundamental disconnect: compilers rely
on an abstract routing model (e.g., three-$ \mathrm{CX} $-unrolled SWAP
insertion) that completely ignores the idiosyncrasies of native gates supported
by physical devices.
  Recent hardware breakthroughs have enabled high-precision implementations of
diverse instruction set architectures (ISAs) beyond standard
$\mathrm{CX}$-based gates. Advanced ISAs involving gates such as
$\mathrm{\sqrt{iSWAP}}$ and $\mathrm{ZZ}(\theta)$ gates offer superior circuit
synthesis capabilities and can be realized with higher fidelities. However,
systematic compiler optimization strategies tailored to these advanced ISAs are
lacking.
  To address this, we propose Canopus, a unified qubit mapping/routing
framework applicable to diverse quantum ISAs. Built upon the canonical
representation of two-qubit gates, Canopus centers on qubit routing to perform
deep co-optimization in an ISA-aware approach. Canopus leverages the two-qubit
canonical representation and the monodromy polytope to model the synthesis cost
for more intelligent $ \mathrm{SWAP} $ insertion during the routing stage. We
also formalize the commutation relations between two-qubit gates through the
canonical form, providing a generalized approach to commutativity-based
optimizations. Experiments show that Canopus consistently reduces routing
overhead by 15\%-35\% compared to state-of-the-art methods across different
ISAs and topologies. Our work also presents a coherent method for
co-exploration of program patterns, quantum ISAs, and hardware topologies.

</details>


### [322] [Unclonable Cryptography in Linear Quantum Memory](https://arxiv.org/abs/2511.04633)
*Omri Shmueli,Mark Zhandry*

Main category: quant-ph

TL;DR: 本工作旨在减小量子安全签名方案（尤其是单次签名 OSS）所需的量子密钥存储大小。通过开发基于 coset 状态的新型证明技术，在某些情况下实现了渐进最优的密钥大小。


<details>
  <summary>Details</summary>
Motivation: 量子密码学利用量子信息实现经典方法无法完成的任务，其中量子态常被用作密钥以防止被复制。然而，量子态的退相干特性使得长期量子存储成为量子计算的挑战。因此，在量子协议中最小化长期量子存储的需求日益增加。特别是，单次签名（OSS）等量子签名代币虽然是重要的不可克隆原语，但其所需的量子存储较大。

Method: 本工作提出并应用了使用 coset 状态的新型技术来证明密码系统的安全性。Coset 状态是不可克隆密码学中的关键工具。

Result: 通过应用上述技术，本工作显著减小了量子安全签名方案（包括 OSS）所需的量子密钥存储大小，在某些情况下达到了渐进最优。

Conclusion: 本工作通过开发基于 coset 状态的新型证明技术，有效解决了现有量子签名方案中量子存储过大的问题，实现了量子密钥存储的显著减小，并在某些情况下达到了最优，为量子密码学的发展做出了贡献。

Abstract: Quantum cryptography is a rapidly-developing area which leverages quantum
information to accomplish classically-impossible tasks. In many of these
protocols, quantum states are used as long-term cryptographic keys. Typically,
this is to ensure the keys cannot be copied by an adversary, owing to the
quantum no-cloning theorem. Unfortunately, due to quantum state's tendency to
decohere, persistent quantum memory will likely be one of the most challenging
resources for quantum computers. As such, it will be important to minimize
persistent memory in quantum protocols.
  In this work, we consider the case of one-shot signatures (OSS), and more
general quantum signing tokens. These are important unclonable primitives,
where quantum signing keys allow for signing a single message but not two.
Naturally, these quantum signing keys would require storage in long-term
quantum memory. Very recently, the first OSS was constructed in a classical
oracle model and also in the standard model, but we observe that the quantum
memory required for these protocols is quite large. In this work, we
significantly decrease the quantum secret key size, in some cases achieving
asymptotically optimal size. To do so, we develop novel techniques for proving
the security of cryptosystems using coset states, which are one of the main
tools used in unclonable cryptography.

</details>


### [323] [Random Construction of Quantum LDPC Codes](https://arxiv.org/abs/2511.04634)
*Koki Okada,Kenta Kasai*

Main category: quant-ph

TL;DR: 提出了一种修改正交稀疏矩阵对的方法，该方法在保留矩阵行和列权重分布的同时，引入了真正的结构随机性，可用于构建可扩展的随机化量子LDPC码。


<details>
  <summary>Details</summary>
Motivation: 在CSS码中，矩阵的行和列权重分布对置信传播解码的性能至关重要。需要一种在不改变这些分布的情况下修改正交稀疏矩阵对的方法。

Method: 通过小的2x2交叉交换操作引入局部修改，然后进行基于整数线性规划的局部修复以恢复正交性。重复进行此过程以构建代码。

Result: 该方法可以生成随机化量子LDPC码的集合。每次修复的计算复杂度与矩阵大小无关，具有良好的可扩展性。

Conclusion: 所提出的局部修改方法能够生成结构随机的矩阵，同时保持关键的权重分布，并能有效扩展到大型代码块，为构建高性能量子LDPC码提供了一种有前途的途径。

Abstract: We propose a method for modifying orthogonal sparse matrix pairs used in CSS
codes while preserving their matrix row and column weight distributions, which
play a crucial role in determining the performance of belief-propagation
decoding. Unlike simple row or column permutations that merely reorder existing
elements, the proposed local modification introduces genuine structural
randomness through small $2\times2$ cross-swap operations followed by
integer-linear-program-based local repairs that restore orthogonality. By
applying this procedure repeatedly in a random manner, ensembles of randomized
quantum LDPC codes can be constructed. The computational complexity of each
repair depends only on the maximum row and column weights and is independent of
the overall matrix size, ensuring scalability to large code blocks.

</details>


### [324] [Automated Discovery of Non-local Photonic Gates](https://arxiv.org/abs/2511.04648)
*Sören Arlt,Mario Krenn,Xuemei Gu*

Main category: quant-ph

TL;DR: AI发现了一种利用光子不可区分性实现非局域多光子量子门的新方法，可用于分布式量子信息处理。


<details>
  <summary>Details</summary>
Motivation: 为了在光子系统中实现实用的量子门，需要克服光子间相互作用弱的挑战，并实现非局域相互作用。

Method: 利用量子不可区分性（通过光子路径同一性）在空间分离的光子之间实现非局域多光子量子门，不依赖于预共享的纠缠或贝尔态测量。

Result: 提出了几种非局域多光子量子门（包括量子比特和高维量子比特系统）的实验方案，并发现了一种模拟量子隐形传态的新机制。

Conclusion: 光子路径不可区分性是一种可行的分布式量子信息处理资源，并且自动化发现系统能够为物理学带来新的见解和技术。

Abstract: Interactions between quantum systems enable quantum gates, the building
blocks of quantum information processing. In photonics, direct photon-photon
interactions are too weak to be practically useful, so effective interactions
are engineered with linear optics and measurement. A central challenge is to
realize such interactions non-locally, i.e., between photons that remain
spatially separated. We present experimental proposals for several essential
non-local multiphoton quantum gates that act on spatially separated photons, in
both qubit and high-dimensional qudit systems. All solutions were discovered by
the AI-driven discovery system called PyTheus. Rather than using pre-shared
entanglement or Bell state measurements, our gates use as a resource quantum
indistinguishability by path identity - a technique that exploits coherent
superpositions of the photon pair origins. While analyzing these solutions, we
uncovered a new mechanism that mimics much of the properties of quantum
teleportation, without shared entanglement or Bell state measurements.
Technically, our results establish path indistinguishability as a practical
resource for distributed quantum information processing; conceptually, they
demonstrate how automated discovery systems can contribute new ideas and
techniques in physics.

</details>


### [325] [Photodetection of Squeezed Light: a Whittaker-Shannon Analysis](https://arxiv.org/abs/2511.04657)
*Jasper Kranias,Christian Drago,Colin Vendromin,J. E. Sipe*

Main category: quant-ph

TL;DR: 该论文利用 Whittaker-Shannon 分解来描述压缩光，并基于瞬时光子对数量定义压缩强度。


<details>
  <summary>Details</summary>
Motivation: 为 CW 极限下的压缩光提供时间局部化描述，并引入新的压缩强度定义。

Method: 应用 Whittaker-Shannon 分解，计算了零𝓱探测方案中的正交方差、连续波极限下的符合探测概率，并分析了强压缩光下的 Hong-Ou-Mandel 效应。

Result: 研究发现，强压缩下正交不确定度低于散粒噪声极限，而弱压缩下光子对之间的相关性效应更为显著。

Conclusion: Whittaker-Shannon 分解为理解压缩光和光子对的时间特性提供了有力的工具，并扩展了现有理论至更一般的场景。

Abstract: The Whittaker-Shannon decomposition provides a temporally localized
description of squeezed light, making it applicable in the CW limit and leading
to a definition of squeezing strength based on the number of photon pairs at a
time. We show examples of its usefulness by calculating quadrature variance in
a homodyne detection scheme, coincidence detection probabilities in the
continuous-wave limit, and analyzing the Hong-Ou-Mandel effect for strongly
squeezed light. Quadrature uncertainty falls farther below the shot noise limit
when squeezing is strong, but effects due to correlations between photon pairs
are most significant with weak squeezing. Our analysis extends previous results
to more general scenarios, and we leverage the Whittaker-Shannon formalism to
interpret them based on the temporal properties of photon pairs.

</details>


### [326] [Quantum Search With Generalized Wildcards](https://arxiv.org/abs/2511.04669)
*Arjan Cornelissen,Nikhil S. Mande,Subhasree Patro,Nithish Raja,Swagato Sanyal*

Main category: quant-ph

TL;DR: 本研究提出了一种学习未知比特串x的新方法，该方法通过对特定子集Q的测试来学习x。研究表明，当Q为有界大小集合、连续块、前缀或仅包含全集时，可以获得接近最优的界限。


<details>
  <summary>Details</summary>
Motivation: 解决搜索问题中的通配符问题，并将其推广到更一般的查询模型，以获得更广泛的应用。

Method: 开发了一个新的框架，该框架利用任务的对称性，将学习x的量子查询复杂度与一个优化问题联系起来。该优化问题旨在最大化一个奇函数的最大值与其在子立方体上的标准差之比，其中子立方体的自由变量恰好是Q中的一个元素。

Result: 当Q为有界大小集合、连续块、前缀和仅全集时，得到了学习x的量子查询复杂度的接近最优界限。

Conclusion: 本研究提出的框架和方法为解决更一般的量子查询问题提供了新的思路，特别是利用了负权对偶界（primal version of the negative-weight adversary bound）的对偶形式来证明量子查询的上限，而无需诉诸于半定规划对偶。

Abstract: In the search with wildcards problem [Ambainis, Montanaro, Quantum
Inf.~Comput.'14], one's goal is to learn an unknown bit-string $x \in
\{-1,1\}^n$. An algorithm may, at unit cost, test equality of any subset of the
hidden string with a string of its choice. Ambainis and Montanaro showed a
quantum algorithm of cost $O(\sqrt{n} \log n)$ and a near-matching lower bound
of $\Omega(\sqrt{n})$. Belovs [Comput.~Comp.'15] subsequently showed a tight
$O(\sqrt{n})$ upper bound.
  We consider a natural generalization of this problem, parametrized by a
subset $\cal{Q} \subseteq 2^{[n]}$, where an algorithm may test whether $x_S =
b$ for an arbitrary $S \in \cal{Q}$ and $b \in \{-1,1\}^S$ of its choice, at
unit cost. We show near-tight bounds when $\cal{Q}$ is any of the following
collections: bounded-size sets, contiguous blocks, prefixes, and only the full
set.
  All of these results are derived using a framework that we develop. Using
symmetries of the task at hand we show that the quantum query complexity of
learning $x$ is characterized, up to a constant factor, by an optimization
program, which is succinctly described as follows: `maximize over all odd
functions $f : \{-1,1\}^n \to \mathbb{R}$ the ratio of the maximum value of $f$
to the maximum (over $T \in \cal{Q}$) standard deviation of $f$ on a subcube
whose free variables are exactly $T$.'
  To the best of our knowledge, ours is the first work to use the primal
version of the negative-weight adversary bound (which is a maximization program
typically used to show lower bounds) to show new quantum query upper bounds
without explicitly resorting to SDP duality.

</details>


<div id='cond-mat.mes-hall'></div>

# cond-mat.mes-hall [[Back]](#toc)

### [327] [Dynamics of Josephson junctions beyond the tunneling limit](https://arxiv.org/abs/2511.03811)
*Jacob F. Steiner,Larissa Melischek,Felix von Oppen*

Main category: cond-mat.mes-hall

TL;DR: We present a generalized RCSJ model for Josephson junctions that accounts for nonlinear dissipation and arbitrary supercurrents, going beyond the traditional tunneling limit. This is achieved using a generalized fluctuation-dissipation theorem, motivated by recent work on the Josephson diode effect.


<details>
  <summary>Details</summary>
Motivation: The paper is motivated by the need to generalize the Resistively and Capacitively Shunted Josephson junction (RCSJ) model to include nonlinear current-voltage characteristics of dissipative currents and arbitrary current-phase relations for supercurrents. This generalization is particularly relevant for phenomena like the Josephson diode effect, which are not adequately described by the traditional RCSJ model in the tunneling limit.

Method: The paper presents a derivation of a generalized RCSJ model. This involves using a generalized fluctuation-dissipation theorem, deduced from fluctuation theorems for mesoscopic conductors, to describe the Langevin current. This allows for the incorporation of dissipative currents with nonlinear current-voltage characteristics and supercurrents with arbitrary current-phase relations.

Result: The paper successfully derives a generalized version of the RCSJ model. This model accommodates nonlinear dissipative currents and supercurrents with arbitrary current-phase relations, thereby extending the applicability of the RCSJ model beyond the conventional tunneling limit.

Conclusion: The developed generalized RCSJ model provides a more comprehensive framework for describing the dynamics of superconducting phase differences in Josephson junctions, particularly for systems exhibiting nonlinear dissipation and non-trivial supercurrent behaviors, as exemplified by the Josephson diode effect.

Abstract: The dynamics of the superconducting phase difference across a Josephson
junction can be described within the resistively and capacitively shunted
Josephson junction (RCSJ) model. Microscopic derivations of this model
traditionally rely on the tunneling limit. Here, we present a derivation of a
generalized version of the RCSJ model, which accounts for dissipative currents
with nonlinear current-voltage characteristics as well as supercurrents with
arbitrary current-phase relations. This requires a generalized
fluctuation-dissipation theorem to describe the Langevin current, which we
deduce along the lines of fluctuation theorems for mesoscopic conductors. Our
work is motivated in particular by recent theories of the Josephson diode
effect, which is not captured within the RCSJ model in the tunneling limit.

</details>


### [328] [Unconventional quantization of 2D plasmons in cavities formed by gate slots](https://arxiv.org/abs/2511.03829)
*Ilia Moiseenko,Olga Polischuk,Viacheslav Muravev,Dmitry Svintsov*

Main category: cond-mat.mes-hall

TL;DR: The slot between parallel metal gates above a 2D electron system acts as a plasmonic cavity with unusual mode quantization, where the slot width is L = λ/8 + nλ/2, due to a -π/4 phase shift upon reflection. This leads to strong absorption and field enhancement.


<details>
  <summary>Details</summary>
Motivation: Investigate the plasmonic properties of the slot between parallel metal gates above a 2D electron system and understand the unconventional mode quantization observed.

Method: Excite resonant plasmon modes in the slot and analyze the condition for mode quantization (L = λ/8 + nλ/2). Study the decay rate of these modes and the absorption cross-section.

Result: Observed unconventional mode quantization with the lowest resonance at L = λ/8. Determined that the decay rate is proportional to the square root of the gate-2DES separation. Achieved absorption cross-section up to 50% of the dipole limit due to field enhancement at the gate edges.

Conclusion: The slot between metal gates functions as a plasmonic cavity with unique quantization rules stemming from a -π/4 reflection phase shift, enabling efficient absorption and field enhancement without impedance matching.

Abstract: We demonstrate that the slot between parallel metal gates placed above
two-dimensional electron system (2DES) forms a plasmonic cavity with
unconventional mode quantization. The resonant plasmon modes are excited when
the slot width $L$ and the plasmon wavelength $\lambda$ satisfy the condition
$L = \lambda/8 +n \times \lambda/2$, where $n=0, 1, 2 \ldots$. The lowest
resonance occurs at a surprisingly small cavity size, specifically one eighth
of the plasmon wavelength, which contrasts with the conventional
half-wavelength Fabry-Perot cavities in optics. This unique quantization rule
arises from a non-trivial phase shift of $-\pi/4$ acquired by the 2D plasmon
upon reflection from the edge of the gate. The slot plasmon modes exhibit weak
decay into the gated 2DES region, with the decay rate being proportional to the
square root of the separation between the gate and the 2DES. Absorption
cross-section by such slots reaches $\sim 50$ % of the fundamental dipole limit
without any matching strategies, and is facilitated by field enhancement at the
metal edges.

</details>


### [329] [Modeling Memristor-Based Neural Networks with Manhattan Update: Trade-offs in Learning Performance and Energy Consumption](https://arxiv.org/abs/2511.03858)
*Walter Quiñonez,María José Sánchez,Diego Rubi*

Main category: cond-mat.mes-hall

TL;DR:  memristor神经网络采用硬件友好的曼哈顿更新规则进行训练，研究了学习性能与能耗之间的权衡。研究了非线性、电导范围和可访问级别数对单感知器和深度神经网络的影响，并提出了减少能耗的策略。


<details>
  <summary>Details</summary>
Motivation: 研究 memristor 神经网络在采用硬件友好曼哈顿更新规则训练时的学习性能与能耗之间的权衡。

Method: 使用真实世界的 P/D 曲线模型，评估非线性度、电导范围和可访问级别数对单感知器和 MNIST 数据集上训练的深度神经网络的影响。提出了一种固定差分对之一的 memristor 的策略。

Result: 单感知器可容忍高达 0.01 的 P/D 非线性度，而深度神经网络需要 0.001 的严格条件才能保持准确性。增加离散电导状态的数量可改善收敛性。所提出的固定策略可将深度神经网络的训练能耗降低近 50%，而准确性几乎没有损失。

Conclusion: 设备-算法协同设计对于实现可扩展、低功耗的神经形态硬件以实现边缘人工智能应用至关重要。

Abstract: We present a systematic study of memristor based neural networks trained with
the hardware-friendly Manhattan update rule, focusing on the trade offs between
learning performance and energy consumption. Using realistic models of
potentiation/depression (P/D) curves, we evaluate the impact of nonlinearity
(NLI), conductance range, and number of accessible levels on both a single
perceptron (SP) and a deep neural network (DNN) trained on the MNIST dataset.
Our results show that SPs tolerate P/D nonlinearity up to NLI $\leq 0.01$,
while DNNs require stricter conditions of NLI $\leq$ 0.001 to preserve
accuracy. Increasing the number of discrete conductance states improves
convergence, effectively acting as a finer learning rate. We further propose a
strategy where one memristor of each differential pair is fixed, reducing
redundant memristor conductance updates. This approach lowers training energy
by nearly 50% in DNN with little to no loss in accuracy. Our findings highlight
the importance of device algorithm codesign in enabling scalable, low power
neuromorphic hardware for edge AI applications.

</details>


### [330] [Measuring non-Abelian quantum geometry and topology in a multi-gap photonic lattice](https://arxiv.org/abs/2511.03894)
*Martin Guillot,Cédric Blanchard,Martina Morassi,Aristide Lemaître,Luc Le Gratiet,Abdelmounaim Harouri,Isabelle Sagnes,Robert-Jan Slager,F. Nur Ünal,Jacqueline Bloch,Sylvain Ravets*

Main category: cond-mat.mes-hall

TL;DR: 本研究首次直接测量了非阿贝尔量子几何张量（QGT），为探索具有非阿贝尔特性的多带隙系统开辟了新途径。


<details>
  <summary>Details</summary>
Motivation: 探索具有非阿贝尔特性的多带隙系统的拓扑相，需要新的实验方法来表征其几何响应。

Method: 提出并实现了一种新颖的轨道分辨偏振技术，用于测量二维合成晶格中的非阿贝尔量子几何张量。

Result: 成功测量了非阿贝尔四元数电荷、欧拉曲率和所有能带的非阿贝尔量子度量。

Conclusion: 该研究为实验探索多带隙系统中的拓扑、几何和非阿贝尔物理现象提供了新的工具和视角。

Abstract: Recent discoveries in semi-metallic multi-gap systems featuring band
singularities have galvanized enormous interest in particular due to the
emergence of non-Abelian braiding properties of band nodes. This previously
uncharted set of topological phases necessitates novel approaches to probe them
in laboratories, a pursuit that intricately relates to evaluating non-Abelian
generalizations of the Abelian quantum geometric tensor (QGT) that
characterizes geometric responses. Here, we pioneer the direct measurement of
the non-Abelian QGT. We achieve this by implementing a novel orbital-resolved
polarimetry technique to probe the full Bloch Hamiltonian of a six-band
two-dimensional (2D) synthetic lattice, which grants direct experimental access
to non-Abelian quaternion charges, the Euler curvature, and the non-Abelian
quantum metric associated with all bands. Quantum geometry has been highlighted
to play a key role on macroscopic phenomena ranging from superconductivity in
flat-bands, to optical responses, transport, metrology, and quantum Hall
physics. Therefore, our work unlocks the experimental probing of a wide
phenomenology of multi-gap systems, at the confluence of topology, geometry and
non-Abelian physics.

</details>


### [331] [Description of the orbital Hall effect from orbital magnetic moments of Bloch states: the role of a new correction term in bilayer systems](https://arxiv.org/abs/2511.03901)
*Tarik P. Cysne,Ivo Souza,Tatiana G. Rappoport*

Main category: cond-mat.mes-hall

TL;DR: 推导了布洛赫态轨道磁矩（OMM）的矩阵元，并考虑了先前工作中省略的贝里连接项。


<details>
  <summary>Details</summary>
Motivation: 在先前的工作中省略了贝里连接项，因此需要推导包含该项的OMM矩阵元的精确公式，并研究其对电子传输的影响。

Method: 通过引入贝里连接项，推导了适用于任何非简并布洛赫态的OMM矩阵元公式。利用该公式，研究了其在2H过渡金属二卤化物双层和有偏双层石墨烯中的轨道霍尔效应。

Result: 新的OMM矩阵元公式包含两个新贡献：一个恢复了规范协方差，另一个则在量级上可能产生显著修正。在所研究的两个双层系统中，这些新项都降低了轨道霍尔电导率平台，表明多层范德华材料可能特别容易受到OMM修正的影响。

Conclusion: 提出的OMM矩阵元计算方法是准确的，并且对理解轨道磁矩输运和发展轨道电子学具有重要意义。

Abstract: We present a rigorous derivation of the matrix elements of the orbital
magnetic moment (OMM) of Bloch states. Our calculations include the Berry
connection term in the k-derivatives of Bloch states, which was omitted in
previous works. The resulting formula for the OMM matrix elements applies to
any non-degenerate Bloch states within Hilbert space. We identify two new
contributions: the first restores gauge covariance for non-degenerate states,
while the second, being itself gauge covariant, can provide significant
quantitative corrections depending on the system under study. We examine their
impact on the orbital Hall effect in two bilayer systems: a 2H transition metal
dichalcogenide bilayer and a biased bilayer graphene. In both cases, these new
terms reduce the orbital Hall conductivity plateau compared with results that
neglect them, suggesting that multi-layered van der Waals materials may be
particularly susceptible to the derived OMM corrections. Our findings may
contribute to the formal understanding of electronic OMM transport and to the
conceptual foundations of the emerging field of orbitronics.

</details>


### [332] [Thermal hot-carrier breakdown in metasurface structures based on coplanar arrays of graphene microribbons connected with wide-gap bridges](https://arxiv.org/abs/2511.03975)
*V. Ryzhii,M. Ryzhii,M. S. Shur,T. Otsuji,C. Tang*

Main category: cond-mat.mes-hall

TL;DR: 石墨烯微带线(GMR)与纳米桥(NB)组成的光栅结构具有正反馈机制，可实现阈值行为，可用作开关、传感器和热源。


<details>
  <summary>Details</summary>
Motivation: 研究由石墨烯微带线(GMR)和纳米桥(NB)组成的超表面结构的热电特性，探索其作为开关、传感器和热源等器件的潜力。

Method: 分析了由石墨烯微带线(GMR)和连接它们的纳米桥(NB)组成的超表面结构。纳米桥可以由石墨烯纳米带(GNRs)、单壁半导体碳纳米管(CNTs)或黑砷磷(b-AsP)纳米结构实现。通过在相邻GMR之间施加偏置电压，在GMR中诱导出电子和空穴二维系统，并产生流经连接NB的热离子电流。研究了由此产生的自热效应如何通过载流子有效温度和注入电流之间的正反馈来增强热离子电流，这可能导致热击穿，从而实现具有S形特性的电流-电压特性的阈值行为。

Result: GMR/GNR、GMR/CNT和GMR/AsP超表面结构器件可用于开发快速电压控制的电流开关、传感器、热太赫兹和红外辐射源等。

Conclusion: 石墨烯微带线(GMR)与纳米桥(NB)组成的光栅结构具有自热效应产生正反馈，可实现阈值行为，有望应用于多种电子器件。

Abstract: We analyze the thermal and electrical characteristics of the metasurface
consisting of
  the coplanar interdigital array of the graphene microribbons (GMRs) connected
by nanobridges (NBs). These nanobridges could be implemented using graphene
nanoribbons (GNRs), single-wall semiconducting carbon nanotubes (CNTs), or
black-arsenic-phosphorus (b-AsP) nanostructures. The bias voltage applied
between neighboring GMRs indices electron and hole two-dimensional systems in
the GMRs and induces thermionic currents flowing through connecting NBs. The
resulting self-heating increases thermionic currents providing an effective
positive feadback between the carrier effective temperature and the injected
currents. This mechanism may lead to thermal breakdown enabling threshold
behavior of current-voltage characteristics and resulting in the S-shape of
these characteristics. The devices based on the GMR/GNR, GMR/CNT, and GMR/AsP
metasurface structures can be used as fast voltage-controlled current switches,
sensors, thermal terahertz and infrared sources, and other devices.

</details>


### [333] [Polariton XY-simulators revisited](https://arxiv.org/abs/2511.04223)
*Junhui Cao,Denis Novokreschenov,Alexey Kavokin*

Main category: cond-mat.mes-hall

TL;DR: The paper presents an analytical model for exciton-polariton condensate arrays simulating XY models, showing that the system can reach phase-locked states quickly, with a size-independent convergence rate. The favored state depends on pump power, targeting either the minimum or maximum eigenvalue of the effective XY Hamiltonian.


<details>
  <summary>Details</summary>
Motivation: To investigate whether arrays of bosonic condensates of exciton-polaritons, which can simulate classical XY models and reach phase-locked states, genuinely minimize the corresponding XY Hamiltonian and how the convergence time scales with system size.

Method: Developed an analytical model for an array of N condensates. Analyzed the stability of phase configurations and how the system selectively amplifies specific configurations based on pump power. Investigated the formation rate of phase-locked states.

Result: An array of N condensates has N stable phase configurations. The system favors the state with the smallest eigenvalue of the effective XY Hamiltonian at low pump power and the state with the largest eigenvalue at high pump power. At intermediate powers, all eigenstates are visited. The formation rate of phase-locked states is consistently around 100 ps, regardless of array size.

Conclusion: Polariton-based XY simulators exhibit exceptional speed and scalability, with a phase-locked state formation rate that is independent of system size, making them a powerful platform for simulating classical XY models.

Abstract: Arrays of bosonic condensates of exciton-polaritons have emerged as a
promising platform for simulating classical XY models, capable of rapidly
reaching phase-locked states that may be mapped to arrays of two-dimensional
classical spins. However, it remains unclear whether these states genuinely
minimize the corresponding XY Hamiltonian and how the convergence time scales
with the system size. Here, we develop an analytical model revealing that an
array of $N$ condensates possesses $N$ stable phase configurations. The system
selectively amplifies a specific configuration dependent on the pump power: at
low power, the state with the smallest eigenvalue of an effective XY
Hamiltonian is favored, while at high power, the state with the largest
eigenvalue prevails. At intermediate pump powers, the system visits all
eigenstates of the Hamiltonian. Crucially, the formation rate for any of these
phase-locked states remains on the order of 100 ps, independent of the size of
the array, demonstrating the exceptional speed and scalability of
polariton-based XY simulators.

</details>


### [334] [Revealing the impact of ambient molecular contamination on scanning tunneling microscopy and spectroscopy of layered materials](https://arxiv.org/abs/2511.04257)
*György Kálvin,Péter Vancsó,Márton Szendrő,Konrád Kandrai,András Pálinkás,Levente Tapasztó,Péter Nemes-Incze*

Main category: cond-mat.mes-hall

TL;DR: 表面沾染物（正构烷烃）影响石墨的STM测量，抑制了声子诱导的近费米能隙，并改变了电流-距离特征，提供了一种检测表面沾染物的方法。


<details>
  <summary>Details</summary>
Motivation: 在二维材料表面科学测量中，碳氢化合物污染是一个需要考虑的因素。然而，这种污染对扫描隧道显微镜（STM）和扫描隧道光谱学（STS）测量结果的影响尚不完全清楚，特别是在石墨表面，长期存在的声子诱导近费米能隙的实验结果不一致。

Method: 比较了清洁石墨表面和暴露于环境的沾有正构烷烃的石墨表面的STM和STS测量结果。分析了表面污染层对电流-距离（I(z)）特性的影响。

Result: 环境烷烃层抑制了声子诱导的近费米能隙，解决了STM研究中该特征常缺失的长期不一致问题。表面污染层将电流-距离（I(z)）特性的指数衰减因子改变了1.5到5倍。这种改变是由于当探针穿透污染物覆盖层时，通过烷烃层和隧道结产生了额外的电导通道。

Conclusion: 基于I(z)特性，提供了一个在STM测量中检测表面污染的实用指南。

Abstract: Hydrocarbon contamination is an ever-present factor to consider in surface
science measurements. In the case of van der Waals material surfaces, the
structure of this contamination has become known in recent years as a
self-assembled layer of normal-alkanes, resulting from a few days' exposure to
ambient air. Knowledge of its composition and structure enables systematic
investigation of its influence on surface properties. Here, we investigate the
effect of this contamination on scanning tunneling microscopy (STM) and
spectroscopy measurements by comparing clean and ambient alkane-contaminated
surfaces of graphite. Our results reveal that the ambient alkane layer
suppresses the well-known phonon-induced gap near the Fermi energy, resolving a
long-standing inconsistency in STM studies, where this feature is often absent.
Furthermore, we show that the presence of the contamination layer alters the
current-distance ($I(z)$) characteristics, flattening its exponential decay by
a factor of 1.5 to 5 compared to the clean surface. This change arises from
extra conductance channels through the alkane layer alongside the tunnel
junction, as the tip penetrates the contaminant overlayer. Finally, based on
the $I(z)$ characteristics, we provide a practical guide to detect the presence
of surface contamination in STM measurements.

</details>


### [335] [High luminescence efficiency of multi-valley excitonic complexes in heavily doped WSe2 monolayer](https://arxiv.org/abs/2511.04306)
*Sébastien Roux,Tilly Guyot,Abraao Cefas Torres-Dias,Delphine Lagarde,Laurent Lombez,Dinh Van Tuan,Junghwan Kim,Kenji Watanabe,Xavier Marie,Takashi Taniguchi,Hanan Dery,Cedric Robert*

Main category: cond-mat.mes-hall

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Monolayers of group-VI transition-metal dichalcogenides (TMDs) are
two-dimensional semiconductors that exhibit exceptionally strong light-matter
coupling yet typically suffer from low emission quantum yields. In this letter,
we investigate the heavily n-doped regime of a WSe$_2$ monolayer and show that
multi-particle excitonic complexes produce photoluminescence signals up to two
orders of magnitude stronger than in the neutral state. Time-resolved
photoluminescence and differential reflectivity measurements reveal that the
quantum yield rises with carrier density and exceeds 50% for electron
concentrations above 10$^{13}$ cm$^{-2}$. These findings establish TMD
monolayers as a platform for exploring excitonic complexes in high-density
electron gases and point toward new opportunities for efficient, atomically
thin light emitters.

</details>


### [336] [Many-body interferometry with semiconductor spins](https://arxiv.org/abs/2511.04310)
*Daniel Jirovec,Stefano Reale,Pablo Cova-Fariña,Christian Ventura-Meinersen,Minh T. P. Nguyen,Xin Zhang,Stefan D. Oosterhout,Giordano Scappucci,Menno Veldhorst,Maximilian Rimbach-Russ,Stefano Bosco,Lieven M. K. Vandersypen*

Main category: cond-mat.mes-hall

TL;DR: 研究人员使用包含2x4锗量子点的器件，通过改进的量子点器件和新的光谱协议，实现了对多达八个相互作用的量子自旋的精确控制和测量，观察到了从局域化到混沌相的转变，为研究量子多体现象奠定了基础。


<details>
  <summary>Details</summary>
Motivation: 半导体量子点器件在量子模拟领域具有精确电控和可扩展性优势，但其在多体现象研究方面受到纳米加工和多重相互作用同时控制的挑战限制。

Method: 使用基于Ramsey干涉测量和绝热映射多体绝热态到单体自旋绝热态的光谱协议，对2x4阵列的门定义锗量子点中的八个相互作用自旋进行了光谱分析。

Result: 成功实现了对多达八个相互作用自旋的光谱分析，并能够完全重建其能量谱。当相互作用强度超过磁性无序时，观察到了从局域化到混沌相的转变的迹象。

Conclusion: 该研究展示了在量子点系统中实现对多个相互作用自旋的精确控制和光谱分析的能力，并观察到了标志着迈向多体现象观测的关键转变，为未来在量子点系统中深入研究多体现象铺平了道路。

Abstract: Quantum simulators enable studies of many-body phenomena which are
intractable with classical hardware. Spins in devices based on semiconductor
quantum dots promise precise electrical control and scalability advantages, but
accessing many-body phenomena has so far been restricted by challenges in
nanofabrication and simultaneous control of multiple interactions. Here, we
perform spectroscopy of up to eight interacting spins using a 2x4 array of
gate-defined germanium quantum dots. The spectroscopy protocol is based on
Ramsey interferometry and adiabatic mapping of many-body eigenstates to
single-spin eigenstates, enabling a complete energy spectrum reconstruction. As
the interaction strength exceeds magnetic disorder, we observe signatures of
the crossover from localization to a chaotic phase marking a step towards the
observation of many-body phenomena in quantum dot systems.

</details>


### [337] [Quantum dot thermal machines - a guide to engineering](https://arxiv.org/abs/2511.04324)
*Eugenia Pyurbeeva,Ronnie Kosloff*

Main category: cond-mat.mes-hall

TL;DR: 文章介绍了量子点热机在能量转换效率方面取得的进展，并指出了实际应用中需要关注的最大功率、最大功率下的效率和噪声等问题。文章通过分析量子点内部微观动力学对其作为热机性能的影响，提出了通过调控量子电导和三种动力学不对称性来优化量子点热机的性能。


<details>
  <summary>Details</summary>
Motivation: 实际应用中的量子点热机需要关注最大功率、最大功率下的效率和噪声等参数，而不仅仅是效率。

Method: 分析量子点内部微观动力学对其作为热机性能的影响，提出通过调控量子电导和三种动力学不对称性来优化性能。

Result: 量子点热机的性能取决于量子电导和三种动力学不对称性。通过优化这些参数，可以提升量子点热机的性能。

Conclusion: 通过调控量子电导和三种动力学不对称性，可以优化量子点热机的性能，使其在实际应用中表现更优。

Abstract: Continuous particle exchange thermal machines require no time-dependent
driving, can be realised in solid-state electronic devices, and miniaturised to
nanometre scale. Quantum dots, providing a narrow energy filter and allowing to
manipulate particle flow between the hot and cold reservoirs are at the heart
of such devices. It has been theoretically shown that by mitigating passive
heat flow, Carnot efficiency can be approached arbitrarily closely in a quantum
dot heat engine, and experimentally, values of 0.7{\eta}C have been reached.
However, for practical applications, other parameters of a thermal machine,
such as maximum power, efficiency at maximum power, and noise - stability of
the power output or heat extraction - take precedence over maximising
efficiency. We explore the effect of internal microscopic dynamics of a quantum
dot on these quantities and demonstrate that its performance as a thermal
machine depends on few parameters - the overall conductance and three inherent
asymmetries of the dynamics. These parameters will act as a guide to
engineering the quantum states of the quantum dot, allowing to optimise its
performance beyond that of the simplest case of a two-fold spin-degenerate
transmission level.

</details>


### [338] [Automatic tuning of a donor in a silicon quantum device using machine learning](https://arxiv.org/abs/2511.04543)
*Brandon Severin,Tim Botzem,Federico Fedele,Xi Yu,Benjamin Wilhelm,Holly G. Stemp,Irene Fernández de Fuentes,Daniel Schwienbacher,Danielle Holmes,Fay E. Hudson,Andrew S. Dzurak,Alexander M. Jakob,David N. Jamieson,Andrea Morello,Natalia Ares*

Main category: cond-mat.mes-hall

TL;DR: 基于机器学习的硅基捐赠者自旋量子比特自动调谐


<details>
  <summary>Details</summary>
Motivation: 开发大规模硅基量子处理器，实现复杂器件的自动调谐和操作

Method: 提出首个机器学习算法，可自动定位离子注入捐赠者的电荷跃迁，调谐单次电荷读出，并识别隧穿率相等的门电压参数

Result: 在几分钟内完成器件的自动表征和调谐，速度超过人工调谐

Conclusion: 机器学习算法能够快速自动地表征和调谐硅基捐赠者量子比特器件

Abstract: Donor spin qubits in silicon offer one- and two-qubit gates with fidelities
beyond 99%, coherence times exceeding 30 seconds, and compatibility with
industrial manufacturing methods. This motivates the development of large-scale
quantum processors using this platform, and the ability to automatically tune
and operate such complex devices. In this work, we present the first machine
learning algorithm with the ability to automatically locate the charge
transitions of an ion-implanted donor in a silicon device, tune single-shot
charge readout, and identify the gate voltage parameters where tunnelling rates
in and out the donor site are the same. The entire tuning pipeline is completed
on the order of minutes. Our results enable both automatic characterisation and
tuning of a donor in silicon devices faster than human experts.

</details>


<div id='eess.SP'></div>

# eess.SP [[Back]](#toc)

### [339] [Correlation and Temporal Consistency Analysis of Mono-static and Bi-static ISAC Channels](https://arxiv.org/abs/2511.03837)
*Saúl Fenollosa,Narcis Cardona,Wenfei Yang,Jian Li*

Main category: eess.SP

TL;DR: ISAC需要更完善的信道模型，本文通过在城市微小区环境中进行实测，发现单站和双站感知信道虽然瞬时相关性低，但具有统一的时间一致性，可为ISAC系统设计提供参考。


<details>
  <summary>Details</summary>
Motivation: 现有ISAC信道模型未能充分表征ISAC特有的动态，特别是单站和双站感知配置之间的关系，而这对于6G等未来无线网络至关重要。

Method: 在动态城市微小区（UMi）环境中使用79 GHz FMCW信道探测仪进行实证测量，并在包含移动目标/收发器的七种真实场景中进行验证。

Result: 1. 单站和双站信道由于传播几何形状不同，表现出持续的低瞬时相关性；
2. 尽管瞬时相关性低，但单站和双站信道共享统一的时间一致性，并根据环境运动学可预测地演变。

Conclusion: 实测结果揭示了单站和双站ISAC信道的特性，为鲁棒的ISAC系统设计和未来标准化提供了重要见解。

Abstract: Integrated Sensing and Communication (ISAC) is critical for efficient
spectrum and hardware utilization in future wireless networks like 6G. However,
existing channel models lack comprehensive characterization of ISAC-specific
dynamics, particularly the relationship between mono-static (co-located Tx/Rx)
and bi-static (separated Tx/Rx) sensing configurations. Empirical measurements
in dynamic urban microcell (UMi) environments using a 79-GHz FMCW channel
sounder help bridge this gap. Two key findings are demonstrated: (1)
mono-static and bi-static channels exhibit consistently low instantaneous
correlation due to divergent propagation geometries; (2) despite low
instantaneous correlation, both channels share unified temporal consistency,
evolving predictably under environmental kinematics. These insights, validated
across seven real-world scenarios with moving targets/transceivers, inform
robust ISAC system design and future standardization.

</details>


### [340] [Adaptive Phase Shift Information Compression for IRS Systems: A Prompt Conditioned Variable Rate Framework](https://arxiv.org/abs/2511.03923)
*Xianhua Yu,Dong Li,Bowen Gu,Liuqing Yang,Sumei Sun,George K. Karagiannidis*

Main category: eess.SP

TL;DR: 本研究提出一种结合提示学习的智能反射面（IRS）相位转换信息（PSI）压缩系统，以解决现有深度学习方法存在的译码器复杂度高、对动态信道适应性不足和压缩率静态等问题。


<details>
  <summary>Details</summary>
Motivation: 现有深度学习方法在IRS的PSI压缩中存在译码器复杂度高、对动态信道适应性不足和压缩率静态等问题，阻碍了IRS技术的实际应用。

Method: 提出一种提示条件PSI压缩系统，将提示学习与软提示连接和特征维度线性调制（FiLM）相结合，以适应不同的信噪比、衰落类型和压缩率；通过潜在掩码将压缩率纳入提示嵌入，实现可变比特率；采用轻量化的深度卷积门控（DWCG）译码器以降低复杂度。

Result: 所提出的框架在降低NMSE方面显著优于传统自动编码器基线，同时保持了在各种信道条件下的鲁棒性，并能在单个模型中处理可变的压缩率。

Conclusion: 该框架为下一代无线网络中的实时IRS控制提供了一种可扩展且高效的解决方案。

Abstract: Intelligent reflecting surfaces (IRSs) have become a vital technology for
improving the spectrum and energy efficiency of forthcoming wireless networks.
Nevertheless, practical implementation is obstructed by the excessive overhead
associated with the frequent transmission of phase shift information (PSI) over
bandwidth-constrained control lines. Current deep learning-based compression
methods mitigate this problem but are constrained by elevated decoder
complexity, inadequate flexibility to dynamic channels, and static compression
ratios. This research presents a prompt-conditioned PSI compression system that
integrates prompt learning inspired by large models into the PSI compression
process to address these difficulties. A hybrid prompt technique that
integrates soft prompt concatenation with feature-wise linear modulation (FiLM)
facilitates adaptive encoding across diverse signal-to-noise ratios (SNRs),
fading kinds, and compression ratios. Furthermore, a variable rate technique
incorporates the compression ratio into the prompt embeddings through latent
masking, enabling a singular model to adeptly balance reconstruction accuracy.
Additionally, a lightweight depthwise convolutional gating (DWCG) decoder
facilitates precise feature reconstruction with minimal complexity.
Comprehensive simulations indicate that the proposed framework significantly
reduces NMSE compared to traditional autoencoder baselines, while ensuring
robustness across various channel circumstances and accommodating variable
compression ratios within a single model. These findings underscore the
framework's promise as a scalable and efficient solution for real-time IRS
control in next-generation wireless networks.

</details>


### [341] [Score-Based Quickest Change Detection and Fault Identification for Multi-Stream Signals](https://arxiv.org/abs/2511.03967)
*Wuxia Chen,Sean Moushegian,Vahid Tarokh,Taposh Banerjee*

Main category: eess.SP

TL;DR: 该研究提出了一种名为min-SCUSUM的新方法，用于在复杂模型中进行快速变化检测和故障隔离，通过使用评分函数替代似然比来克服计算难题。


<details>
  <summary>Details</summary>
Motivation: 传统的最优算法在快速变化检测中需要预先估计和事后估计的分布，这对于高维数据来说计算成本很高，并且对于复杂的机器学习模型来说甚至不可行。

Method: 提出了一种基于Hyvarinen评分函数的方法（min-SCUSUM），它使用评分函数的差值来代替对数似然比，从而解决了计算复杂性问题。

Result: 对所提出的算法进行了延迟和虚警分析，并证明了其渐近性能与预变化和事后变化分布之间的Fisher散度有关。此外，还为区分受影响的流和未受影响的流的故障误识别概率设定了上限。

Conclusion: min-SCUSUM算法能够有效地处理多流最快变化检测和故障隔离问题，尤其是在处理未归一化和基于评分的统计模型时，并且具有良好的理论性能保证。

Abstract: This paper introduces an approach to multi-stream quickest change detection
and fault isolation for unnormalized and score-based statistical models.
Traditional optimal algorithms in the quickest change detection literature
require explicit pre-change and post-change distributions to calculate the
likelihood ratio of the observations, which can be computationally expensive
for higher-dimensional data and sometimes even infeasible for complex machine
learning models. To address these challenges, we propose the min-SCUSUM method,
a Hyvarinen score-based algorithm that computes the difference of score
functions in place of log-likelihood ratios. We provide a delay and false alarm
analysis of the proposed algorithm, showing that its asymptotic performance
depends on the Fisher divergence between the pre- and post-change
distributions. Furthermore, we establish an upper bound on the probability of
fault misidentification in distinguishing the affected stream from the
unaffected ones.

</details>


### [342] [Joint Beamforming and Position Design for Movable Antenna Assisted LEO ISAC Systems](https://arxiv.org/abs/2511.03984)
*Hanfu Zhang,Erwu Liu*

Main category: eess.SP

TL;DR: 本文研究了低地球轨道（LEO）卫星辅助的集成传感与通信（ISAC）系统，提出了一种利用可移动天线（MA）来克服信号衰减和传输功率限制的方法。通过联合优化波束成形和MA位置，旨在最小化传感平方位置误差界（SPEB），同时满足通信信噪比（SINR）和其他约束。


<details>
  <summary>Details</summary>
Motivation: 低地球轨道（LEO）卫星辅助的集成传感与通信（ISAC）系统虽然旨在实现普遍连接，但面临信号衰减和传输功率受限的问题，影响了ISAC性能。

Method: 推导了通信SINR和传感SPEB用于评估ISAC性能。提出了一种交替优化（AO）算法，将复杂问题分解为两个子问题，并使用半定松弛（SDR）进行简化和求解。

Result: 通过仿真验证了所提出算法的收敛性和有效性，与基准方法相比，在通信和传感性能之间取得了更好的权衡，传感性能提升了至少25%。

Conclusion: 所提出的MA辅助LEO ISAC系统能有效提升传感性能，并在通信和传感之间取得良好平衡。

Abstract: Low earth orbit (LEO) satellite-assisted integrated sensing and
communications (ISAC) systems have been extensively studied to achieve
ubiquitous connectivity. However, the severe signal attenuation and limited
transmit power at LEO satellites can degrade ISAC performance. To address this
issue, this paper investigated movable antenna (MA)-assisted LEO ISAC systems.
We derive the communication signal-to-interference-plus-noise ratio (SINR) and
the sensing squared position error bound (SPEB) for evaluating the ISAC
performance. Then, we jointly optimize the transmit beamforming and the MA
positions to minimize the SPEB under the SINR constraints, total transmit power
constraint, and several inherent physical constraints of the MA array. We first
simplify the complex problem using the semidefinite relaxation (SDR). Then, we
present a novel alternating optimization (AO)-based algorithm to decouple the
original problem into two subproblems, consequently convexified and solved.
Simulations demonstrate the convergence and effectiveness of the proposed
algorithm. Better trade-off between communication and sensing performance, and
at least 25% gain in sensing performance are achieved, compared to the
benchmarks.

</details>


### [343] [Optimal RIS Placement in a Multi-User MISO System with User Randomness](https://arxiv.org/abs/2511.03998)
*Abhishek Rajasekaran,Mehdi Karbalayghareh,Xiaoyan Ma,David J. Love,Christopher G. Brinton*

Main category: eess.SP

TL;DR: 该论文提出了一种新的方法来优化RIS（可重构智能表面）在RIS辅助系统中的放置位置，以最大化预期的最小信噪比（SINR），同时考虑用户分布的随机性。


<details>
  <summary>Details</summary>
Motivation: 现有RIS放置优化方法假设RIS、基站和用户的位置是已知的，这在实际中不适用。实际情况是，通常只知道用户密度和障碍物的空间分布。因此，需要一种新的方法来优化RIS的放置位置，以应对用户位置的随机性。

Method: 提出了一种递归的、由粗到精的方法。首先，根据障碍物配置构建候选RIS位置集，并通过对用户分布的多次实例化进行评估。然后在每个阶段确定的最优区域内进行递归细化搜索，以找到最终的最优RIS部署区域。

Result: 通过数值结果证明了所提出方法的有效性。

Conclusion: 所提出的递归粗略到精细的方法能够有效地优化RIS在RIS辅助系统中的放置位置，以最大化预期的最小SINR，并能处理用户位置的随机性。

Abstract: It is well established that the performance of reconfigurable intelligent
surface (RIS)-assisted systems critically depends on the optimal placement of
the RIS. Previous works consider either simple coverage maximization or
simultaneous optimization of the placement of the RIS along with the
beamforming and reflection coefficients, most of which assume that the location
of the RIS, base station (BS), and users are known. However, in practice, only
the spatial variation of user density and obstacle configuration are likely to
be known prior to deployment of the system. Thus, we formulate a non-convex
problem that optimizes the position of the RIS over the expected minimum
signal-to-interference-plus-noise ratio (SINR) of the system with user
randomness, assuming that the system employs joint beamforming after
deployment. To solve this problem, we propose a recursive coarse-to-fine
methodology that constructs a set of candidate locations for RIS placement
based on the obstacle configuration and evaluates them over multiple
instantiations from the user distribution. The search is recursively refined
within the optimal region identified in each stage to determine the final
optimal region for RIS deployment. Numerical results are presented to
corroborate our findings.

</details>


### [344] [A Survey on Noise-Based Communication](https://arxiv.org/abs/2511.04011)
*Higo T. P. Da Silva,Hugerles S. Silva,Felipe A. P. Figueiredo,Andre A. Dos Anjos,Rausley A. A. Souza*

Main category: eess.SP

TL;DR: 噪声通信利用噪声的统计特性编码信息，满足6G和海量物联网对超低功耗、安全和隐蔽通信的需求。


<details>
  <summary>Details</summary>
Motivation: 6G网络和海量物联网的兴起需要超低功耗、安全、隐蔽的无线通信技术。

Method: 该调查全面探讨了噪声通信的根本原理和关键方法，包括热噪声调制（TherMod）、噪声调制（NoiseMod）及其变体，以及基尔霍夫定律约翰逊噪声（KLJN）安全密钥交换。同时，也讨论了信道估计和硬件实现等实际挑战。

Result: 噪声通信系统在能效和隐蔽性方面具有无与伦比的优势。

Conclusion: 噪声通信技术在实现下一代自主和安全无线网络方面具有巨大潜力，未来的研究方向包括进一步优化和应用。

Abstract: The proliferation of sixth-generation (6G) networks and the massive Internet
of Things (IoT) demand wireless communication technologies that are
ultra-low-power, secure, and covert. Noise-based communication has emerged as a
transformative paradigm that meets these demands by encoding information
directly into the statistical properties of noise, rather than using
traditional deterministic carriers. This survey provides a comprehensive
synthesis of this field, systematically exploring its fundamental principles
and key methodologies, including thermal noise modulation (TherMod), noise
modulation (NoiseMod) and its variants, and the Kirchhoff-law-Johnson-noise
(KLJN) secure key exchange. We address critical practical challenges such as
channel estimation and hardware implementation, and highlight emerging
applications in simultaneous wireless information and power transfer (SWIPT)
and non-orthogonal multiple access (NOMA). Our analysis confirms that
noise-based systems offer unparalleled advantages in energy efficiency and
covertness, and we conclude by outlining future research directions to realize
their potential for enabling the next generation of autonomous and secure
wireless networks.

</details>


### [345] [Tiny-WiFo: A Lightweight Wireless Foundation Model for Channel Prediction via Multi-Component Adaptive Knowledge Distillation](https://arxiv.org/abs/2511.04015)
*Haotian Zhang,Shijian Gao,Xiang Cheng*

Main category: eess.SP

TL;DR: 本文提出了一种新颖的多组分自适应知识蒸馏（MCAKD）框架，用于解决无线基础模型（FM）在边缘设备上实时部署的挑战。


<details>
  <summary>Details</summary>
Motivation: 无线基础模型（FM）规模庞大，难以在边缘设备上实时部署。

Method: 提出了一种新颖的多组分自适应知识蒸馏（MCAKD）框架，包括基于交叉注意力机制的知识选择（CA-KS）模块，用于识别教师模型中的关键特征，以及自主学习-被动学习（AL-PL）策略，用于平衡知识迁移和独立学习，以实现高训练效率和可控的计算成本。

Result: 将MCAKD应用于WiFo FM，蒸馏出的Tiny-WiFo模型参数量仅为5.5M，在边缘硬件上的推理时间仅为1.6毫秒，同时保留了Wifo 98%以上的性能及其关键的零样本泛化能力。

Conclusion: 该方法使得实时部署FM成为可能。

Abstract: The massive scale of Wireless Foundation Models (FMs) hinders their real-time
deployment on edge devices. This letter moves beyond standard knowledge
distillation by introducing a novel Multi-Component Adaptive Knowledge
Distillation (MCAKD) framework. Key innovations include a Cross-Attention-Based
Knowledge Selection (CA-KS) module that selectively identifies critical
features from the teacher model, and an Autonomous Learning-Passive Learning
(AL-PL) strategy that balances knowledge transfer with independent learning to
achieve high training efficiency at a manageable computational cost. When
applied to the WiFo FM, the distilled Tiny-WiFo model, with only 5.5M
parameters, achieves a 1.6 ms inference time on edge hardware while retaining
over 98% of WiFo's performance and its crucial zero-shot generalization
capability, making real-time FM deployment viable.

</details>


### [346] [Ambiguity Function Analysis of AFDM Under Pulse-Shaped Random ISAC Signaling](https://arxiv.org/abs/2511.04200)
*Yuanhan Ni,Fan Liu,Haoran Yin,Yanqun Tang,Zulin Wang*

Main category: eess.SP

TL;DR: 该论文推导了用于集成传感与通信（ISAC）的新兴仿射频分复用（AFDM）波形在脉冲成形下的模糊函数（AF），并提出了一种新的AFDM参数设计方法以减轻强目标对弱目标的干扰。


<details>
  <summary>Details</summary>
Motivation: 为了解决AFDM波形在ISAC信号中，由于其模糊函数（AF）旁瓣的规律性凹陷对弱目标检测和估计造成性能损失的问题，以及强目标对弱目标的潜在干扰。

Method: 首先推导了AFDM波形在无脉冲成形下的平均平方离散周期模糊函数（DPAF）的闭式表达式。其次，对AFDM、OFDM和OCDM三种波形的AF进行了综合分析。然后，提出了一种利用AFDM参数$c_1$来控制凹陷位置的设计方法。最后，推导了脉冲成形的AFDM波形的平均平方DPAF的闭式表达式。

Result: AFDM波形的AF旁瓣存在规律性凹陷，与OFDM和OCDM波形类似。AFDM可以通过参数$c_1$灵活控制凹陷的位置。脉冲成形滤波器在时延轴上形成成形主瓣，在多普勒轴上形成快速滚降的旁瓣。

Conclusion: AFDM波形通过调整参数$c_1$可以控制其AF的凹陷位置，从而有望缓解强目标对弱目标的干扰。所提出的AFDM参数设计方法和理论分析得到了数值结果的验证。

Abstract: This paper investigates the ambiguity function (AF) of the emerging affine
frequency division multiplexing (AFDM) waveform for Integrated Sensing and
Communication (ISAC) signaling under a pulse shaping regime. Specifically, we
first derive the closed-form expression of the average squared discrete period
AF (DPAF) for AFDM waveform without pulse shaping, revealing that the AF
depends on the parameter $c_1$ and the kurtosis of random communication data,
while being independent of the parameter $c_2$. As a step further, we conduct a
comprehensive analysis on the AFs of various waveforms, including AFDM,
orthogonal frequency division multiplexing (OFDM) and orthogonal chirp-division
multiplexing (OCDM). Our results indicate that all three waveforms exhibit the
same number of regular depressions in the sidelobes of their AFs, which incurs
performance loss for detecting and estimating weak targets. However, the AFDM
waveform can flexibly control the positions of depressions by adjusting the
parameter $c_1$, which motivates a novel design approach of the AFDM parameters
to mitigate the adverse impact of depressions of the strong target on the weak
target. Furthermore, a closed-form expression of the average squared DPAF for
pulse-shaped random AFDM waveform is derived, which demonstrates that the pulse
shaping filter generates the shaped mainlobe along the delay axis and the rapid
roll-off sidelobes along the Doppler axis. Numerical results verify the
effectiveness of our theoretical analysis and proposed design methodology for
the AFDM modulation.

</details>


### [347] [BTTDA: Block-Term Tensor Discriminant Analysis for Brain-Computer Interfacing](https://arxiv.org/abs/2511.04292)
*Arne Van Den Kerchove,Hakim Si-Mohammed,François Cabestaing,Marc M. Van Hulle*

Main category: eess.SP

TL;DR: 该研究提出了一种名为块项张量判别分析（BTTDA）的新型张量分解方法，用于提取脑机接口（BCI）中脑电图（EEG）信号的特征，以提高分类精度。


<details>
  <summary>Details</summary>
Motivation: 现有的基于张量的方法（如Tucker和PARAFAC分解）在处理EEG数据的复杂性方面灵活性不足，而BTTDA旨在通过灵活的多线性降维来提高分类准确性。

Method: BTTDA是一种新的、基于张量的、监督特征提取方法，它扩展了高阶判别分析（HODA），并使用一种新颖且可解释的前向模型和一种迭代提取判别块项的泄放方案。

Result: 在事件相关电位（ERP）数据集上，BTTDA和PARAFACDA的表现显著优于传统HODA方法，达到了91.25%的ROC-AUC。在运动想象（MI）数据集上，虽然所有方法的表现均不理想，但BTTDA（64.52%）仍显著优于HODA（61.00%）。

Conclusion: BTTDA通过其块项结构实现了可解释且更高效的降维，同时不损害判别能力，为BCI和更广泛的神经影像学应用提供了有前景且适应性强的方法。

Abstract: Brain-computer interfaces (BCIs) allow direct communication between the brain
and external devices, frequently using electroencephalography (EEG) to record
neural activity. Dimensionality reduction and structured regularization are
essential for effectively classifying task-related brain signals, including
event-related potentials (ERPs) and motor imagery (MI) rhythms. Current
tensor-based approaches, such as Tucker and PARAFAC decompositions, often lack
the flexibility needed to fully capture the complexity of EEG data. This study
introduces Block-Term Tensor Discriminant Analysis (BTTDA): a novel
tensor-based and supervised feature extraction method designed to enhance
classification accuracy by providing flexible multilinear dimensionality
reduction. Extending Higher Order Discriminant Analysis (HODA), BTTDA uses a
novel and interpretable forward model for HODA combined with a deflation scheme
to iteratively extract discriminant block terms, improving feature
representation for classification. BTTDA and a sum-of-rank-1-terms variant
PARAFACDA were evaluated on publicly available ERP (second-order tensors) and
MI (third-order tensors) EEG datasets from the MOABB benchmarking framework.
Benchmarking revealed that BTTDA and PARAFACDA significantly outperform the
traditional HODA method in ERP decoding, resulting in state-of-the art
performance (ROC-AUC = 91.25%). For MI, decoding results of HODA, BTTDA and
PARAFACDA were subpar, but BTTDA still significantly outperformed HODA (64.52%
> 61.00%). The block-term structure of BTTDA enables interpretable and more
efficient dimensionality reduction without compromising discriminative power.
This offers a promising and adaptable approach for feature extraction in BCI
and broader neuroimaging applications.

</details>


### [348] [RCMCL: A Unified Contrastive Learning Framework for Robust Multi-Modal (RGB-D, Skeleton, Point Cloud) Action Understanding](https://arxiv.org/abs/2511.04351)
*Hasan Akgul,Mari Eplik,Javier Rojas,Akira Yamamoto,Rajesh Kumar,Maya Singh*

Main category: eess.SP

TL;DR: RCMCL是一个自监督框架，通过跨模态对比学习来学习不变表征，并在传感器失效或有噪声时保持可靠性。


<details>
  <summary>Details</summary>
Motivation: 现有的多模态人类动作识别方法虽然准确率高，但依赖大型标注数据集，并且在传感器失效或有噪声时性能会急剧下降。

Method: RCMCL框架结合了三种优化目标：(i)跨模态对比学习，对齐异构数据流；(ii)模态内自蒸馏，增强视图不变性并减少冗余；(iii)退化模拟，训练模型从被掩盖或损坏的输入中恢复。在推理时，自适应模态门控（AMG）网络为每个模态分配数据驱动的可靠性权重，以实现鲁棒融合。

Result: 在NTU RGB+D 120 (CS/CV)和UWA3D-II数据集上，RCMCL在标准设置下达到了最先进的准确率，并且在鲁棒性方面表现出色。在严重双模态退出情况下，其性能仅下降11.5%，显著优于强监督融合基线。

Conclusion: 自监督跨模态对齐、显式退化建模和自适应融合是实现可部署的多模态人类动作识别的关键。

Abstract: Human action recognition (HAR) with multi-modal inputs (RGB-D, skeleton,
point cloud) can achieve high accuracy but typically relies on large labeled
datasets and degrades sharply when sensors fail or are noisy. We present Robust
Cross-Modal Contrastive Learning (RCMCL), a self-supervised framework that
learns modality-invariant representations and remains reliable under modality
dropout and corruption. RCMCL jointly optimizes (i) a cross-modal contrastive
objective that aligns heterogeneous streams, (ii) an intra-modal
self-distillation objective that improves view-invariance and reduces
redundancy, and (iii) a degradation simulation objective that explicitly trains
models to recover from masked or corrupted inputs. At inference, an Adaptive
Modality Gating (AMG) network assigns data-driven reliability weights to each
modality for robust fusion. On NTU RGB+D 120 (CS/CV) and UWA3D-II, RCMCL
attains state-of-the-art accuracy in standard settings and exhibits markedly
better robustness: under severe dual-modality dropout it shows only an 11.5%
degradation, significantly outperforming strong supervised fusion baselines.
These results indicate that self-supervised cross-modal alignment, coupled with
explicit degradation modeling and adaptive fusion, is key to deployable
multi-modal HAR.

</details>


### [349] [High-Resolution Forest Mapping from L-Band Interferometric SAR Time Series using Deep Learning over Northern Spain](https://arxiv.org/abs/2511.04362)
*Chiara Telli,Oleg Antropov,Anne Lönnqvist,Marco Lavalle*

Main category: eess.SP

TL;DR: 利用 L波段干涉时间序列和深度学习进行高分辨率森林测绘，并取得了显著成果。


<details>
  <summary>Details</summary>
Motivation: 本研究旨在探索利用 L 波段干涉时间序列数据集和深度学习模型实现高分辨率森林测绘的潜力。

Method: 研究使用了 9 张 ALOS-2 PALSAR-2 探波雷达影像，结合了 UNet 系列的多种深度学习模型（Vanilla UNet、SeU-Net、嵌套 UNet），并纳入了极化和干涉特征，包括模型反演的干涉测量特征和相干性层。

Result: 结果表明，加入模型反演的干涉测量特征或相干性层能提高反演精度。注意力机制和嵌套连接融合比 Vanilla UNet 或传统机器学习方法能提供更好的预测效果。在 20 米分辨率下，仅使用强度数据的森林高度反演精度在 3.1-3.8 米之间（R2 = 0.45-0.55），而加入强度和干涉相干性特征后，精度提高到 2.8 米以下。在 40 米和 60 米分辨率下，反演性能进一步提高，其中在 60 米分辨率下，使用所有特征的最佳 RMSE 达到 1.95 米。

Conclusion: 研究推荐这种混合方法用于 L 波段 SAR 反演，并且适用于 NISAR 和未来的 ROSE-L 任务。

Abstract: In this study, we examine the potential of high-resolution forest mapping
using L-band interferometric time series datasets and deep learning modeling.
Our SAR data are represented by a time series of nine ALOS-2 PALSAR-2 dual-pol
SAR images acquired at near-zero spatial baseline over a study site in
Asturias, Northern Spain. Reference data are collected using airborne laser
scanning. We examine the performance of several candidate deep learning models
from UNet-family with various combinations of input polarimetric and
interferometric features. In addition to basic Vanilla UNet, attention
reinforced UNet model with squeeze-excitation blocks (SeU-Net) and advanced
UNet model with nested structure and skip pathways are used. Studied features
include dual pol interferometric observables additionally incorporating
model-based derived measures. Results show that adding model-based inverted
InSAR features or InSAR coherence layers improves retrieval accuracy compared
to using backscatter intensity only. Use of attention mechanisms and nested
connection fusion provides better predictions than using Vanilla UNet or
traditional machine learning methods. Forest height retrieval accuracies range
between 3.1-3.8 m (R2 = 0.45--0.55) at 20 m resolution when only intensity data
are used, and improve to less than 2.8 m when both intensity and
interferometric coherence features are included. At 40 m and 60 m resolution,
retrieval performance further improves, primarily due to higher SNR in both the
intensity and interferometric layers. When using intensity at 60 m resolution,
best achieved RMSE is 2.2 m, while when using all suitable input features the
achieved error is 1.95 m. We recommend this hybrid approach for L-band SAR
retrievals also suitable for NISAR and future ROSE-L missions.

</details>


### [350] [A Lightweight Framework for Integrated Sensing and Communications with RIS](https://arxiv.org/abs/2511.04448)
*Chu Li,Kevin Weinberger,Aydin Sezgin*

Main category: eess.SP

TL;DR: Reconfigurable Intelligent Surfaces (RIS) can improve integrated sensing and communication (ISAC) systems, but existing optimization methods are complex or suboptimal. This paper proposes a lightweight RIS phase design with a closed-form solution that balances communication and sensing by partitioning the RIS configuration. The method achieves performance comparable to complex methods with much lower computational complexity.


<details>
  <summary>Details</summary>
Motivation: Existing RIS optimization methods for ISAC, such as SDR and iterative algorithms, have drawbacks like high computational complexity, limited scalability, and suboptimal solutions. There is a need for a more efficient and effective RIS design approach.

Method: The paper proposes a lightweight RIS phase design framework. It partitions the RIS configuration into two parts: one part maximizes communication performance, and the other part introduces small perturbations to create multiple beams for multi-target sensing. This approach yields a closed-form solution and explicitly addresses the trade-off between communication and sensing, as well as proportional beam gain distribution.

Result: Simulation results show that the proposed RIS phase design approach is effective. It achieves performance comparable to SDR-based methods but with significantly lower computational complexity.

Conclusion: The proposed lightweight RIS phase design framework offers an efficient and effective solution for enhancing ISAC systems by optimizing RIS configurations. It provides a closed-form solution that balances communication and sensing performance with reduced computational cost.

Abstract: Reconfigurable Intelligent Surfaces (RIS) have been recognized as a promising
technology to enhance both communication and sensing performance in integrated
sensing and communication (ISAC) systems for future 6G networks. However,
existing RIS optimization methods for improving ISAC performance are mainly
based on semidefinite relaxation (SDR) or iterative algorithms. The former
suffers from high computational complexity and limited scalability, especially
when the number of RIS elements becomes large, while the latter yields
suboptimal solutions whose performance depends on initialization. In this work,
we introduce a lightweight RIS phase design framework that provides a
closed-form solution and explicitly accounts for the trade-off between
communication and sensing, as well as proportional beam gain distribution
toward multiple sensing targets. The key idea is to partition the RIS
configuration into two parts: the first part is designed to maximize the
communication performance, while the second introduces small perturbations to
generate multiple beams for multi-target sensing. Simulation results validate
the effectiveness of the proposed approach and demonstrate that it achieves
performance comparable to SDR but with significantly lower computational
complexity.

</details>


### [351] [An Area-Efficient 20-100-GHz Phase-Invariant Switch-Type Attenuator Achieving 0.1-dB Tuning Step in 65-nm CMOS](https://arxiv.org/abs/2511.04635)
*Qingbin Li,Jian Pang*

Main category: eess.SP

TL;DR: 该论文介绍了一种在20至100 GHz范围内工作的开关式衰减器，该衰减器采用电容补偿技术来减少相位误差，并使用金属线实现小电阻以减小寄生电容，从而在宽频率范围内最小化幅度和相位误差。同时，采用连续可调衰减单元以提高衰减精度。该衰减器采用标准65nm CMOS工艺设计和制造，测量结果显示在20-100 GHz频带内具有7.5 dB的相对衰减范围和连续可调的步长，插入损耗为1.6-3.8 dB，回波损耗优于11.5 dB，均方根幅度和相位误差低于0.15 dB和1.6度。


<details>
  <summary>Details</summary>
Motivation: 该研究的动机是开发一种在20至100 GHz宽频率范围内工作，并且具有高幅度和相位精度，同时占用芯片面积小的开关式衰减器。

Method: 该研究提出了一种基于电容补偿技术和使用金属线实现小电阻的开关式衰减器设计。通过采用电容补偿技术来减少相位误差，并利用金属线实现小电阻以减小寄生电容，从而在宽频率范围内最小化幅度和相位误差，并减小芯片面积。此外，还采用了一个连续可调的衰减单元来提高整体衰减精度。最后，使用标准的65nm CMOS工艺进行了设计和制造。

Result: 测量结果显示，该衰减器在20-100 GHz的频带内实现了7.5 dB的相对衰减范围，并且衰减步长是连续可调的。在此频带内，插入损耗在1.6-3.8 dB之间，所有状态下的回波损耗均优于11.5 dB。此外，均方根幅度和相位误差分别低于0.15 dB和1.6度。

Conclusion: 该研究成功设计并制造了一种高性能的开关式衰减器，该衰减器在20-100 GHz的宽频率范围内具有良好的幅度和相位精度，并且尺寸小。所提出的电容补偿技术和金属线电阻实现有效地减小了幅度和相位误差，同时降低了芯片面积。连续可调衰减单元的引入进一步提高了衰减精度。

Abstract: This paper presents a switch-type attenuator working from 20 to 100 GHz. The
attenuator adopts a capacitive compensation technique to reduce phase error.
The small resistors in this work are implemented with metal lines to reduce the
intrinsic parasitic capacitance, which helps minimize the amplitude and phase
errors over a wide frequency range. Moreover, the utilization of metal lines
also reduces the chip area. In addition, a continuous tuning attenuation unit
is employed to improve the overall attenuation accuracy of the attenuator. The
passive attenuator is designed and fabricated in a standard 65nm CMOS. The
measurement results reveal a relative attenuation range of 7.5 dB with a
continuous tuning step within 20-100 GHz. The insertion loss is 1.6-3.8 dB
within the operation band, while the return losses of all states are better
than 11.5 dB. The RMS amplitude and phase errors are below 0.15 dB and
1.6{\deg}, respectively.

</details>


<div id='cs.AR'></div>

# cs.AR [[Back]](#toc)

### [352] [From Minutes to Seconds: Redefining the Five-Minute Rule for AI-Era Memory Hierarchies](https://arxiv.org/abs/2511.03944)
*Tong Zhang,Vikram Sharma Mailthody,Fei Sun,Linsen Ma,Chris J. Newburn,Teresa Zhang,Yang Liu,Jiangpeng Li,Hao Zhong,Wen-Mei Hwu*

Main category: cs.AR

TL;DR: The five-minute rule for data caching in DRAM is outdated for modern AI platforms, especially those with GPU-centric hosts and high-IOPS SSDs. The caching threshold collapses to a few seconds, reframing NAND flash as an active data tier and opening new research areas. A new framework and simulator (MQSim-Next) are introduced to provide actionable guidance and facilitate future research.


<details>
  <summary>Details</summary>
Motivation: The original five-minute rule, based solely on storage-memory economics, did not account for host costs, feasibility limits, and workload behavior. This paper aims to update the rule by integrating these factors for modern AI platforms.

Method: This paper revisits the five-minute rule by incorporating host costs, DRAM bandwidth/capacity, and physics-grounded models of SSD performance and cost. It embeds these elements into a constraint- and workload-aware framework. A calibrated SSD simulator, MQSim-Next, is introduced for validation and sensitivity analysis. Two case studies are presented to showcase the implications of the revised rule.

Result: For modern AI platforms, particularly GPU-centric hosts with ultra-high-IOPS SSDs, the DRAM-to-flash caching threshold has decreased from minutes to a few seconds. This shift positions NAND flash as an active data tier and reveals significant research opportunities across the hardware-software stack.

Conclusion: The classical five-minute rule has been transformed into a feasible, constraint-aware analysis and provisioning framework tailored for the AI era. This updated approach sets the foundation for future research into memory hierarchies optimized for AI workloads and highlights the evolving role of NAND flash memory.

Abstract: In 1987, Jim Gray and Gianfranco Putzolu introduced the five-minute rule, a
simple, storage-memory-economics-based heuristic for deciding when data should
live in DRAM rather than on storage. Subsequent revisits to the rule largely
retained that economics-only view, leaving host costs, feasibility limits, and
workload behavior out of scope. This paper revisits the rule from first
principles, integrating host costs, DRAM bandwidth/capacity, and
physics-grounded models of SSD performance and cost, and then embedding these
elements in a constraint- and workload-aware framework that yields actionable
provisioning guidance. We show that, for modern AI platforms, especially
GPU-centric hosts paired with ultra-high-IOPS SSDs engineered for fine-grained
random access, the DRAM-to-flash caching threshold collapses from minutes to a
few seconds. This shift reframes NAND flash memory as an active data tier and
exposes a broad research space across the hardware-software stack. We further
introduce MQSim-Next, a calibrated SSD simulator that supports validation and
sensitivity analysis and facilitates future architectural and system research.
Finally, we present two concrete case studies that showcase the software system
design space opened by such memory hierarchy paradigm shift. Overall, we turn a
classical heuristic into an actionable, feasibility-aware analysis and
provisioning framework and set the stage for further research on AI-era memory
hierarchy.

</details>


### [353] [PICNIC: Silicon Photonic Interconnected Chiplets with Computational Network and In-memory Computing for LLM Inference Acceleration](https://arxiv.org/abs/2511.04036)
*Yue Jiet Chong,Yimin Wang,Zhen Wu,Xuanyao Fong*

Main category: cs.AR

TL;DR: 本文提出了一个基于3D堆叠小芯片的大语言模型（LLM）推理加速器，该加速器包含非易失性内存计算处理单元（PE）和PE间计算网络（IPCN），并通过硅光子互连以有效解决通信瓶颈。


<details>
  <summary>Details</summary>
Motivation: 为了解决大语言模型推理中的通信瓶颈问题，本文设计了一个基于3D堆叠小芯片的推理加速器。

Method: 该加速器采用了非易失性内存计算处理单元（PE）和PE间计算网络（IPCN），并通过硅光子互连。同时，开发了一种LLM映射方案来优化硬件调度和工作负载映射。

Result: 在没有芯片集群和功率门控（CCPG）的情况下，相比英伟达A100，实现了3.95倍的加速和30倍的效率提升。通过实施CCPG，进一步提高了可扩展性和效率，在相似吞吐量下，相比英伟达H100实现了57倍的效率提升。

Conclusion: 所提出的3D堆叠小芯片LLM推理加速器在通信瓶颈、加速和能效方面取得了显著改进，并且通过CCPG方案实现了良好的可扩展性。

Abstract: This paper presents a 3D-stacked chiplets based large language model (LLM)
inference accelerator, consisting of non-volatile in-memory-computing
processing elements (PEs) and Inter-PE Computational Network (IPCN),
interconnected via silicon photonic to effectively address the communication
bottlenecks. A LLM mapping scheme was developed to optimize hardware scheduling
and workload mapping. Simulation results show it achieves $3.95\times$ speedup
and $30\times$ efficiency improvement over the Nvidia A100 before chiplet
clustering and power gating scheme (CCPG). Additionally, the system achieves
further scalability and efficiency improvement with the implementation of CCPG
to accommodate larger models, attaining $57\times$ efficiency improvement over
Nvidia H100 at similar throughput.

</details>


### [354] [Disaggregated Architectures and the Redesign of Data Center Ecosystems: Scheduling, Pooling, and Infrastructure Trade-offs](https://arxiv.org/abs/2511.04104)
*Chao Guo,Jiahe Xu,Moshe Zukerman*

Main category: cs.AR

TL;DR: 硬件解耦旨在将数据中心资源从传统服务器集群转变为统一的资源池，尽管存在挑战，但已有显著进展。本文概述了硬件解耦的动机、最新进展、研究挑战与机遇，并进行数值研究以说明关键问题。


<details>
  <summary>Details</summary>
Motivation: 硬件解耦旨在将数据中心（DC）的资源从传统的服务器集群转变为统一的资源池。

Method: 本文进行了数值研究以说明关键问题，并讨论了与解耦架构相关的研究挑战与机遇。

Result: 硬件解耦有潜力重塑整个数据中心生态系统，影响应用设计、资源调度、硬件配置、冷却和供电系统优化。

Conclusion: 尽管存在挑战，但硬件解耦已取得显著进展，并有潜力重塑数据中心生态系统。

Abstract: Hardware disaggregation seeks to transform Data Center (DC) resources from
traditional server fleets into unified resource pools. Despite existing
challenges that may hinder its full realization, significant progress has been
made in both industry and academia. In this article, we provide an overview of
the motivations and recent advancements in hardware disaggregation. We further
discuss the research challenges and opportunities associated with disaggregated
architectures, focusing on aspects that have received limited attention. We
argue that hardware disaggregation has the potential to reshape the entire DC
ecosystem, impacting application design, resource scheduling, hardware
configuration, cooling, and power system optimization. Additionally, we present
a numerical study to illustrate several key aspects of these challenges.

</details>


### [355] [AIM: Software and Hardware Co-design for Architecture-level IR-drop Mitigation in High-performance PIM](https://arxiv.org/abs/2511.04321)
*Yuanpeng Zhang,Xing Hu,Xi Chen,Zhihang Yuan,Cong Li,Jingchen Zhu,Zhao Wang,Chenguang Zhang,Xin Si,Wei Gao,Qiang Wu,Runsheng Wang,Guangyu Sun*

Main category: cs.AR

TL;DR: SRAM PIM的IR-drop问题通过软硬件协同设计AIM得到缓解，实现了性能和能效的提升。


<details>
  <summary>Details</summary>
Motivation: SRAM PIM在高密度、高能效和高精度方面表现出色，但高频率带来了IR-drop问题，影响性能和可靠性，传统方法成本高昂。

Method: 提出AIM软硬件协同设计，包括Rtog和HR建立IR-drop与PIM工作负载的关联，LHR和WDS进行架构层面的IR-drop缓解，IR-Booster动态调整V-f曲线，以及HR感知任务映射。

Result: 在7nm 256-TOPS PIM芯片上进行后布局仿真，AIM实现了高达69.2%的IR-drop缓解，能效提升2.29倍，速度提升1.152倍。

Conclusion: AIM成功地解决了SRAM PIM中的IR-drop问题，通过软硬件协同设计显著提升了性能和能效。

Abstract: SRAM Processing-in-Memory (PIM) has emerged as the most promising
implementation for high-performance PIM, delivering superior computing density,
energy efficiency, and computational precision. However, the pursuit of higher
performance necessitates more complex circuit designs and increased operating
frequencies, which exacerbate IR-drop issues. Severe IR-drop can significantly
degrade chip performance and even threaten reliability. Conventional
circuit-level IR-drop mitigation methods, such as back-end optimizations, are
resource-intensive and often compromise power, performance, and area (PPA). To
address these challenges, we propose AIM, comprehensive software and hardware
co-design for architecture-level IR-drop mitigation in high-performance PIM.
Initially, leveraging the bit-serial and in-situ dataflow processing properties
of PIM, we introduce Rtog and HR, which establish a direct correlation between
PIM workloads and IR-drop. Building on this foundation, we propose LHR and WDS,
enabling extensive exploration of architecture-level IR-drop mitigation while
maintaining computational accuracy through software optimization. Subsequently,
we develop IR-Booster, a dynamic adjustment mechanism that integrates
software-level HR information with hardware-based IR-drop monitoring to adapt
the V-f pairs of the PIM macro, achieving enhanced energy efficiency and
performance. Finally, we propose the HR-aware task mapping method, bridging
software and hardware designs to achieve optimal improvement. Post-layout
simulation results on a 7nm 256-TOPS PIM chip demonstrate that AIM achieves up
to 69.2% IR-drop mitigation, resulting in 2.29x energy efficiency improvement
and 1.152x speedup.

</details>


### [356] [Scalable and Efficient Intra- and Inter-node Interconnection Networks for Post-Exascale Supercomputers and Data centers](https://arxiv.org/abs/2511.04677)
*Joaquin Tarraga-Moreno,Daniel Barley,Francisco J. Andujar Munoz,Jesus Escudero-Sahuquillo,Holger Froning,Pedro Javier Garcia,Francisco J. Quiles,Jose Duato*

Main category: cs.AR

TL;DR: 现代计算系统因数据密集型应用而变得异构且集成度更高，但节点内外的通信瓶颈，尤其是在网络资源共享时，仍然是一个挑战。


<details>
  <summary>Details</summary>
Motivation: 数据密集型应用（如生成式AI、科学模拟、大规模分析）的快速发展，推动现代超级计算机和数据中心向日益异构和紧密集成的架构发展，以减少数据移动和提高计算效率。

Method: 随着每个节点上的加速器数量的增加，会出现节点内和节点间的通信瓶颈，特别是在网络资源被异构组件共享时。

Result: 现代计算系统正朝着异构和紧密集成的方向发展，以应对数据密集型应用的增长。

Conclusion: 尽管采用了新的架构，但通信瓶颈，特别是在共享网络资源的情况下，仍然是现代计算系统面临的挑战。

Abstract: The rapid growth of data-intensive applications such as generative AI,
scientific simulations, and large-scale analytics is driving modern
supercomputers and data centers toward increasingly heterogeneous and tightly
integrated architectures. These systems combine powerful CPUs and accelerators
with emerging high-bandwidth memory and storage technologies to reduce data
movement and improve computational efficiency. However, as the number of
accelerators per node increases, communication bottlenecks emerge both within
and between nodes, particularly when network resources are shared among
heterogeneous components.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [357] [Scaling Agent Learning via Experience Synthesis](https://arxiv.org/abs/2511.03773)
*Zhaorun Chen,Zhuokai Zhao,Kai Zhang,Bo Liu,Qi Qi,Yifan Wu,Tarun Kalluri,Sara Cao,Yuanhao Xiong,Haibo Tong,Huaxiu Yao,Hengduo Li,Jiacheng Zhu,Xian Li,Dawn Song,Bo Li,Jason Weston,Dat Huynh*

Main category: cs.AI

TL;DR: DreamGym是一个用于LLM自主代理的在线强化学习框架，通过合成经验、改进转换稳定性和自适应任务生成来解决RL训练中的挑战，并在各种环境中实现了显著的性能提升。


<details>
  <summary>Details</summary>
Motivation: 现有的强化学习（RL）方法在为大型语言模型（LLM）代理提供自我改进能力时面临挑战，因为实际应用中存在成本高昂的试验、任务多样性有限、奖励信号不可靠以及基础设施复杂性等问题，这些都阻碍了可扩展经验数据的收集。

Method: DreamGym通过将环境动态提炼为基于推理的经验模型，并利用初始化的离线数据和持续交互来丰富经验回放缓冲区，以及自适应地生成新任务来支持代理训练，从而在保持可扩展性的同时合成多样化的经验。

Result: 在完全合成的环境和实际-到模拟迁移场景中，DreamGym在各种环境中都显著改善了RL训练。在WebArena等非RL就绪任务上，DreamGym的性能比所有基线高出30%以上。在RL就绪但成本高昂的环境中，它仅使用合成交互就达到了GRPO和PPO的性能水平。将纯粹在合成经验上训练的策略迁移到实际环境RL时，DreamGym在需要更少实际世界交互的情况下实现了显著的额外性能提升。

Conclusion: DreamGym通过提供一种可扩展的预热策略，为通用RL代理提供了有效的在线RL训练方法，解决了在LLM代理中采用RL的挑战。

Abstract: While reinforcement learning (RL) can empower large language model (LLM)
agents by enabling self-improvement through interaction, its practical adoption
remains challenging due to costly rollouts, limited task diversity, unreliable
reward signals, and infrastructure complexity, all of which obstruct the
collection of scalable experience data. To address these challenges, we
introduce DreamGym, the first unified framework designed to synthesize diverse
experiences with scalability in mind to enable effective online RL training for
autonomous agents. Rather than relying on expensive real-environment rollouts,
DreamGym distills environment dynamics into a reasoning-based experience model
that derives consistent state transitions and feedback signals through
step-by-step reasoning, enabling scalable agent rollout collection for RL. To
improve the stability and quality of transitions, DreamGym leverages an
experience replay buffer initialized with offline real-world data and
continuously enriched with fresh interactions to actively support agent
training. To improve knowledge acquisition, DreamGym adaptively generates new
tasks that challenge the current agent policy, enabling more effective online
curriculum learning. Experiments across diverse environments and agent
backbones demonstrate that DreamGym substantially improves RL training, both in
fully synthetic settings and in sim-to-real transfer scenarios. On non-RL-ready
tasks like WebArena, DreamGym outperforms all baselines by over 30%. And in
RL-ready but costly settings, it matches GRPO and PPO performance using only
synthetic interactions. When transferring a policy trained purely on synthetic
experiences to real-environment RL, DreamGym yields significant additional
performance gains while requiring far fewer real-world interactions, providing
a scalable warm-start strategy for general-purpose RL.

</details>


### [358] [How Different Tokenization Algorithms Impact LLMs and Transformer Models for Binary Code Analysis](https://arxiv.org/abs/2511.03825)
*Ahmed Mostafa,Raisul Arefin Nahid,Samuel Mulder*

Main category: cs.AI

TL;DR: 本研究评估了NLP分词模型在汇编代码分析中的应用，探讨了不同分词策略和模型（如LLM、BERT、BART）对下游任务（如函数签名预测）的影响，并分析了内在指标与外在评估结果之间的关系。


<details>
  <summary>Details</summary>
Motivation: 汇编代码分词是代码分析的基础，但该领域研究不足。本研究旨在评估NLP分词模型及其参数（如词汇量）在汇编代码分析中的内在特性，并探索预处理定制选项和针对性规则，以解决这一研究空白。

Method: 本研究系统地评估了多种分词模型在汇编指令编码和语义捕捉方面的效率。通过内在评估，比较了分词效率、词汇压缩和表示保真度。研究使用了先进的预训练模型，如Llama 3.2、BERT和BART，并评估了它们在多个性能指标上的表现。

Result: 初步研究表明，分词器的选择显著影响下游任务的性能。内在指标只能部分预测外在评估结果，显示了内在分词特性与实际汇编代码任务效用之间复杂的权衡关系。

Conclusion: 本研究为优化低级代码分析的分词模型提供了宝贵的见解，有助于提高基于NLM的二进制分析工作流程的鲁棒性和可扩展性。

Abstract: Tokenization is fundamental in assembly code analysis, impacting intrinsic
characteristics like vocabulary size, semantic coverage, and extrinsic
performance in downstream tasks. Despite its significance, tokenization in the
context of assembly code remains an underexplored area. This study aims to
address this gap by evaluating the intrinsic properties of Natural Language
Processing (NLP) tokenization models and parameter choices, such as vocabulary
size. We explore preprocessing customization options and pre-tokenization rules
tailored to the unique characteristics of assembly code. Additionally, we
assess their impact on downstream tasks like function signature prediction -- a
critical problem in binary code analysis.
  To this end, we conduct a thorough study on various tokenization models,
systematically analyzing their efficiency in encoding assembly instructions and
capturing semantic nuances. Through intrinsic evaluations, we compare
tokenizers based on tokenization efficiency, vocabulary compression, and
representational fidelity for assembly code. Using state-of-the-art pre-trained
models such as the decoder-only Large Language Model (LLM) Llama 3.2, the
encoder-only transformer BERT, and the encoder-decoder model BART, we evaluate
the effectiveness of these tokenizers across multiple performance metrics.
Preliminary findings indicate that tokenizer choice significantly influences
downstream performance, with intrinsic metrics providing partial but incomplete
predictability of extrinsic evaluation outcomes. These results reveal complex
trade-offs between intrinsic tokenizer properties and their utility in
practical assembly code tasks. Ultimately, this study provides valuable
insights into optimizing tokenization models for low-level code analysis,
contributing to the robustness and scalability of Natural Language Model
(NLM)-based binary analysis workflows.

</details>


### [359] [To See or To Read: User Behavior Reasoning in Multimodal LLMs](https://arxiv.org/abs/2511.03845)
*Tianning Dong,Luyi Ma,Varun Vasudevan,Jason Cho,Sushant Kumar,Kannan Achan*

Main category: cs.AI

TL;DR: 图像表示比文本表示更能提高MLLM在用户行为序列分析中的性能。


<details>
  <summary>Details</summary>
Motivation: 探索文本或图像表示的用户行为数据哪种更能有效提高MLLM性能，以优化基于用户行为数据的现代智能系统。

Method: 提出BehaviorLens基准测试框架，使用文本段落、散点图和流程图三种方式表示交易数据，并在六种MLLM上进行评估，比较不同模态表示下的模型性能。

Result: 与文本表示相比，当使用图像（散点图和流程图）表示交易数据时，MLLM的下一购买预测准确率提高了87.5%，且没有额外的计算成本。

Conclusion: 图像表示（特别是散点图和流程图）在用户行为序列分析任务中比文本表示更能有效地提升MLLM的性能。

Abstract: Multimodal Large Language Models (MLLMs) are reshaping how modern agentic
systems reason over sequential user-behavior data. However, whether textual or
image representations of user behavior data are more effective for maximizing
MLLM performance remains underexplored. We present \texttt{BehaviorLens}, a
systematic benchmarking framework for assessing modality trade-offs in
user-behavior reasoning across six MLLMs by representing transaction data as
(1) a text paragraph, (2) a scatter plot, and (3) a flowchart. Using a
real-world purchase-sequence dataset, we find that when data is represented as
images, MLLMs next-purchase prediction accuracy is improved by 87.5% compared
with an equivalent textual representation without any additional computational
cost.

</details>


### [360] [KnowThyself: An Agentic Assistant for LLM Interpretability](https://arxiv.org/abs/2511.03878)
*Suraj Prasai,Mengnan Du,Ying Zhang,Fan Yang*

Main category: cs.AI

TL;DR: KnowThyself是一个基于聊天的LLM解释性工具，它整合了现有工具的功能，并通过自然语言交互降低了技术门槛。


<details>
  <summary>Details</summary>
Motivation: 现有LLM解释性工具零散且需要大量编码，用户难以使用。

Method: KnowThyself使用一个由LLM驱动的协调器来改写用户查询，并由一个代理路由器将其路由到专门的模块。最后，输出被整合为连贯的解释，并通过交互式可视化呈现。

Result: KnowThyself提供了一个统一的、易于使用的平台，用于LLM的解释性，降低了技术门槛，并为LLM的检查奠定了坚实的基础。

Conclusion: KnowThyself通过提供一个集成的、对话式的界面，大大提高了LLM解释性的可访问性。

Abstract: We develop KnowThyself, an agentic assistant that advances large language
model (LLM) interpretability. Existing tools provide useful insights but remain
fragmented and code-intensive. KnowThyself consolidates these capabilities into
a chat-based interface, where users can upload models, pose natural language
questions, and obtain interactive visualizations with guided explanations. At
its core, an orchestrator LLM first reformulates user queries, an agent router
further directs them to specialized modules, and the outputs are finally
contextualized into coherent explanations. This design lowers technical
barriers and provides an extensible platform for LLM inspection. By embedding
the whole process into a conversational workflow, KnowThyself offers a robust
foundation for accessible LLM interpretability.

</details>


### [361] [Extracting Causal Relations in Deep Knowledge Tracing](https://arxiv.org/abs/2511.03948)
*Kevin Hong,Kia Karbasi,Gregory Pottie*

Main category: cs.AI

TL;DR: DKT 通过模拟因果关系而非双向关系来改进知识追踪。


<details>
  <summary>Details</summary>
Motivation: 挑战 DKT 性能提升源于模拟双向关系的普遍观点，提出其优势在于模拟因果结构。

Method: 通过将练习关系图剪枝为有向无环图（DAGs）并在数据集的因果子集上训练 DKT 来检验 DKT 的预测能力，并提出一种使用 DKT 学习表示来提取练习关系 DAG 的新方法。

Result: DKT 的预测能力与因果结构高度一致，并且提出的新方法得到了实证支持。

Conclusion: DKT 的有效性主要源于其近似因果依赖关系的能力，而非简单的关系映射。

Abstract: A longstanding goal in computational educational research is to develop
explainable knowledge tracing (KT) models. Deep Knowledge Tracing (DKT), which
leverages a Recurrent Neural Network (RNN) to predict student knowledge and
performance on exercises, has been proposed as a major advancement over
traditional KT methods. Several studies suggest that its performance gains stem
from its ability to model bidirectional relationships between different
knowledge components (KCs) within a course, enabling the inference of a
student's understanding of one KC from their performance on others. In this
paper, we challenge this prevailing explanation and demonstrate that DKT's
strength lies in its implicit ability to model prerequisite relationships as a
causal structure, rather than bidirectional relationships. By pruning exercise
relation graphs into Directed Acyclic Graphs (DAGs) and training DKT on causal
subsets of the Assistments dataset, we show that DKT's predictive capabilities
align strongly with these causal structures. Furthermore, we propose an
alternative method for extracting exercise relation DAGs using DKT's learned
representations and provide empirical evidence supporting our claim. Our
findings suggest that DKT's effectiveness is largely driven by its capacity to
approximate causal dependencies between KCs rather than simple relational
mappings.

</details>


### [362] [Large language models replicate and predict human cooperation across experiments in game theory](https://arxiv.org/abs/2511.04500)
*Andrea Cera Palatsi,Samuel Martin-Gutierrez,Ana S. Cardenal,Max Pellert*

Main category: cs.AI

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Large language models (LLMs) are increasingly used both to make decisions in
domains such as health, education and law, and to simulate human behavior. Yet
how closely LLMs mirror actual human decision-making remains poorly understood.
This gap is critical: misalignment could produce harmful outcomes in practical
applications, while failure to replicate human behavior renders LLMs
ineffective for social simulations. Here, we address this gap by developing a
digital twin of game-theoretic experiments and introducing a systematic
prompting and probing framework for machine-behavioral evaluation. Testing
three open-source models (Llama, Mistral and Qwen), we find that Llama
reproduces human cooperation patterns with high fidelity, capturing human
deviations from rational choice theory, while Qwen aligns closely with Nash
equilibrium predictions. Notably, we achieved population-level behavioral
replication without persona-based prompting, simplifying the simulation
process. Extending beyond the original human-tested games, we generate and
preregister testable hypotheses for novel game configurations outside the
original parameter grid. Our findings demonstrate that appropriately calibrated
LLMs can replicate aggregate human behavioral patterns and enable systematic
exploration of unexplored experimental spaces, offering a complementary
approach to traditional research in the social and behavioral sciences that
generates new empirical predictions about human social decision-making.

</details>


### [363] [LLMs and Cultural Values: the Impact of Prompt Language and Explicit Cultural Framing](https://arxiv.org/abs/2511.03980)
*Bram Bulté,Ayla Rigouts Terryn*

Main category: cs.AI

TL;DR: 大型语言模型（LLM）在跨语言和跨文化方面存在固有的偏见，即使在有针对性的提示下，也难以完全捕捉到不同国家或地区的用户价值观。


<details>
  <summary>Details</summary>
Motivation: 研究LLM在处理不同语言和文化背景的提示时，其响应如何受到文化价值观的影响，以及模型是否能够充分代表其用户的文化多样性。

Method: 使用Hofstede价值观调查模块和世界价值观调查中的63个项目，将其翻译成11种语言，并以带有或不带有不同文化视角的提示形式，对10个LLM进行探测。

Result: 研究证实，提示语言和文化视角都会导致LLM输出的变化。有针对性的提示可以在一定程度上引导LLM响应朝着与国家主流价值观一致的方向发展，但无法克服模型对特定国家（荷兰、德国、美国、日本）价值观的系统性偏见。所有模型都表现出相似的模式：在大多数主题上产生中性响应，但在社会宽容等问题上则表现出选择性的进步立场。与仅使用提示语言相比，明确的文化视角更能提高与人类受众文化价值观的一致性。然而，结合使用这两种方法的效果，并不比仅使用英文提示和文化框架更优。

Conclusion: LLM对提示的变化足够敏感，可以产生不同的输出，但由于其模型本身锚定于特定文化默认值，因此在充分代表文化多样性方面存在局限性。

Abstract: Large Language Models (LLMs) are rapidly being adopted by users across the
globe, who interact with them in a diverse range of languages. At the same
time, there are well-documented imbalances in the training data and
optimisation objectives of this technology, raising doubts as to whether LLMs
can represent the cultural diversity of their broad user base. In this study,
we look at LLMs and cultural values and examine how prompt language and
cultural framing influence model responses and their alignment with human
values in different countries. We probe 10 LLMs with 63 items from the Hofstede
Values Survey Module and World Values Survey, translated into 11 languages, and
formulated as prompts with and without different explicit cultural
perspectives. Our study confirms that both prompt language and cultural
perspective produce variation in LLM outputs, but with an important caveat:
While targeted prompting can, to a certain extent, steer LLM responses in the
direction of the predominant values of the corresponding countries, it does not
overcome the models' systematic bias toward the values associated with a
restricted set of countries in our dataset: the Netherlands, Germany, the US,
and Japan. All tested models, regardless of their origin, exhibit remarkably
similar patterns: They produce fairly neutral responses on most topics, with
selective progressive stances on issues such as social tolerance. Alignment
with cultural values of human respondents is improved more with an explicit
cultural perspective than with a targeted prompt language. Unexpectedly,
combining both approaches is no more effective than cultural framing with an
English prompt. These findings reveal that LLMs occupy an uncomfortable middle
ground: They are responsive enough to changes in prompts to produce variation,
but too firmly anchored to specific cultural defaults to adequately represent
cultural diversity.

</details>


### [364] [When Empowerment Disempowers](https://arxiv.org/abs/2511.04177)
*Claire Yang,Maya Cakmak,Max Kleiman-Weiner*

Main category: cs.AI

TL;DR: 在多人类环境中，以单一人类的赋权为目标的AI代理可能会剥夺另一个人类的环境控制权，导致“去赋权”现象。


<details>
  <summary>Details</summary>
Motivation: 以往的赋权研究主要关注AI代理如何在一个单一的人类环境中提供协助，但忽视了在多人类环境中可能出现的复杂交互。本研究旨在探讨当AI代理优化一个人类的赋权时，对另一个人类可能产生的负面影响，即“去赋权”现象。

Method: 提出并使用了一个名为Disempower-Grid的开源多人类网格世界测试套件，来模拟和评估AI代理在多人类环境中的行为。通过实验，分析了AI代理优化单一用户赋权时对另一用户赋权的影响，并研究了联合赋权策略在缓解去赋权现象方面的效果及其对用户奖励的影响。

Result: 实验表明，当AI代理专注于提升一个用户的赋权时，会显著降低另一个用户的环境影响和奖励，即产生“去赋权”现象。研究还刻画了“去赋权”发生的条件，并发现联合赋权虽然能缓解“去赋权”，但会牺牲用户的部分奖励。

Conclusion: 在多人类环境中，以赋权为目标的AI代理可能会导致意想不到的负面后果（去赋权）。这揭示了在多智能体背景下，单一智能体设置下看似一致的目标（如赋权）可能变得不一致，对AI对齐社区提出了新的挑战。

Abstract: Empowerment, a measure of an agent's ability to control its environment, has
been proposed as a universal goal-agnostic objective for motivating assistive
behavior in AI agents. While multi-human settings like homes and hospitals are
promising for AI assistance, prior work on empowerment-based assistance assumes
that the agent assists one human in isolation. We introduce an open source
multi-human gridworld test suite Disempower-Grid. Using Disempower-Grid, we
empirically show that assistive RL agents optimizing for one human's
empowerment can significantly reduce another human's environmental influence
and rewards - a phenomenon we formalize as disempowerment. We characterize when
disempowerment occurs in these environments and show that joint empowerment
mitigates disempowerment at the cost of the user's reward. Our work reveals a
broader challenge for the AI alignment community: goal-agnostic objectives that
seem aligned in single-agent settings can become misaligned in multi-agent
contexts.

</details>


### [365] [ArchPilot: A Proxy-Guided Multi-Agent Approach for Machine Learning Engineering](https://arxiv.org/abs/2511.03985)
*Zhuowen Yuan,Tao Liu,Yang Yang,Yang Wang,Feng Qi,Kaushik Rangadurai,Bo Li,Shuang Yang*

Main category: cs.AI

TL;DR: ArchPilot是一个多智能体系统，通过结合架构生成、代理评估和自适应搜索来解决基于LLM的代理在自动机器学习工程中的计算开销和可扩展性问题。


<details>
  <summary>Details</summary>
Motivation: 当前的基于LLM的代理在自动机器学习工程方面表现出色，但它们依赖于重复的完整训练运行来评估候选解决方案，导致计算开销大、可扩展性差以及迭代周期慢。

Method: ArchPilot由三个专业智能体组成：一个协调搜索过程的编排智能体（使用受MCTS启发的算法并包含重启机制和内存管理），一个迭代生成、改进和调试候选架构的生成智能体，以及一个执行代理训练运行、生成和优化代理函数以及将代理分数聚合为保真度感知性能指标的评估智能体。

Result: 实验表明，ArchPilot在MLE-Bench上优于AIDE和ML-Master等SOTA基线。

Conclusion: ArchPilot通过优先考虑高潜力候选者并最大限度地减少对昂贵完整训练运行的依赖，实现了高效的机器学习工程，尤其是在预算有限的情况下。

Abstract: Recent LLM-based agents have demonstrated strong capabilities in automated ML
engineering. However, they heavily rely on repeated full training runs to
evaluate candidate solutions, resulting in significant computational overhead,
limited scalability to large search spaces, and slow iteration cycles. To
address these challenges, we introduce ArchPilot, a multi-agent system that
integrates architecture generation, proxy-based evaluation, and adaptive search
into a unified framework. ArchPilot consists of three specialized agents: an
orchestration agent that coordinates the search process using a Monte Carlo
Tree Search (MCTS)-inspired novel algorithm with a restart mechanism and
manages memory of previous candidates; a generation agent that iteratively
generates, improves, and debugs candidate architectures; and an evaluation
agent that executes proxy training runs, generates and optimizes proxy
functions, and aggregates the proxy scores into a fidelity-aware performance
metric. This multi-agent collaboration allows ArchPilot to prioritize
high-potential candidates with minimal reliance on expensive full training
runs, facilitating efficient ML engineering under limited budgets. Experiments
on MLE-Bench demonstrate that ArchPilot outperforms SOTA baselines such as AIDE
and ML-Master, validating the effectiveness of our multi-agent system.

</details>


### [366] [Detecting Silent Failures in Multi-Agentic AI Trajectories](https://arxiv.org/abs/2511.04032)
*Divya Pathak,Harshit Kumar,Anuska Roy,Felix George,Mudit Verma,Pratibha Moogi*

Main category: cs.AI

TL;DR: 本研究介绍了多智能体AI系统中异常检测任务，并提供了一个数据集和基准测试，以解决LLM驱动的多智能体系统固有的非确定性和易发生静默故障的问题。


<details>
  <summary>Details</summary>
Motivation: 多智能体AI系统（由LLM驱动）存在固有的非确定性，容易出现漂移、循环和细节缺失等难以检测的静默故障。

Method: 研究引入了在智能体轨迹中进行异常检测的任务，并提出了一个数据集创建流程，该流程能够捕捉用户行为、智能体非确定性和LLM的变化。利用该流程，研究者创建并标注了两个基准数据集，分别包含4,275和894个来自多智能体AI系统的轨迹。对这些数据集上的异常检测方法进行了基准测试。

Result: 在基准测试中，监督学习（XGBoost）和半监督学习（SVDD）方法表现相当，准确率分别高达98%和96%。

Conclusion: 本研究为多智能体AI系统中的异常检测提供了首个系统性研究，包括数据集、基准测试和见解，为未来的研究提供了指导。

Abstract: Multi-Agentic AI systems, powered by large language models (LLMs), are
inherently non-deterministic and prone to silent failures such as drift,
cycles, and missing details in outputs, which are difficult to detect. We
introduce the task of anomaly detection in agentic trajectories to identify
these failures and present a dataset curation pipeline that captures user
behavior, agent non-determinism, and LLM variation. Using this pipeline, we
curate and label two benchmark datasets comprising \textbf{4,275 and 894}
trajectories from Multi-Agentic AI systems. Benchmarking anomaly detection
methods on these datasets, we show that supervised (XGBoost) and
semi-supervised (SVDD) approaches perform comparably, achieving accuracies up
to 98% and 96%, respectively. This work provides the first systematic study of
anomaly detection in Multi-Agentic AI systems, offering datasets, benchmarks,
and insights to guide future research.

</details>


### [367] [Interpreting Multi-Attribute Confounding through Numerical Attributes in Large Language Models](https://arxiv.org/abs/2511.04053)
*Hirohane Takagi,Gouki Minegishi,Shota Kizawa,Issey Sukeda,Hitomi Yanaka*

Main category: cs.AI

TL;DR: LLMs在数值推理中存在错误，其内部的数值表示机制尚不清楚。研究发现LLMs会编码并放大现实世界的数值相关性，并且不相关的数值上下文会对其表示和输出产生一致的干扰，这种干扰效果因模型大小而异。


<details>
  <summary>Details</summary>
Motivation: 尽管行为研究已记录了大型语言模型（LLMs）在数值推理中的错误，但其潜在的表示机制仍不清楚。本研究旨在探究LLMs如何整合单一实体的多个数值属性，以及不相关的数值上下文如何干扰这些表示及其下游输出。

Method: 结合线性探测、偏相关分析和基于提示的易受攻击性测试，跨越不同大小的模型进行研究。

Result: 研究结果表明，LLMs能够编码现实世界的数值相关性，但有系统性放大的倾向。此外，不相关的上下文会导致数量表示发生一致性偏移，且这种偏移对下游的影响因模型大小而异。

Conclusion: 这些发现揭示了LLMs决策中的一个漏洞，并为在多属性纠缠下实现更公平、更具表示意识的控制奠定了基础。

Abstract: Although behavioral studies have documented numerical reasoning errors in
large language models (LLMs), the underlying representational mechanisms remain
unclear. We hypothesize that numerical attributes occupy shared latent
subspaces and investigate two questions:(1) How do LLMs internally integrate
multiple numerical attributes of a single entity? (2)How does irrelevant
numerical context perturb these representations and their downstream outputs?
To address these questions, we combine linear probing with partial correlation
analysis and prompt-based vulnerability tests across models of varying sizes.
Our results show that LLMs encode real-world numerical correlations but tend to
systematically amplify them. Moreover, irrelevant context induces consistent
shifts in magnitude representations, with downstream effects that vary by model
size. These findings reveal a vulnerability in LLM decision-making and lay the
groundwork for fairer, representation-aware control under multi-attribute
entanglement.

</details>


### [368] [Agentmandering: A Game-Theoretic Framework for Fair Redistricting via Large Language Model Agents](https://arxiv.org/abs/2511.04076)
*Hao Li,Haotian Chen,Ruoyuan Gong,Juanjuan Wang,Hao Jiang*

Main category: cs.AI

TL;DR: 该研究提出了一种名为Agentmandering的新型重新划分选区框架，该框架将重新划分过程视为两个代表敌对政治利益的智能体之间的回合制博弈，以解决现有计算方法忽视战略动态的问题。


<details>
  <summary>Details</summary>
Motivation: 现有计算方法在生成合法的选区划分方案时，往往忽略了选择过程中的战略动态，这使得党派能够选择在技术上合规但在政治上有利的地图。仅仅满足正式约束并不能保证公平，因为选择过程本身可能被操纵。

Method: Agentmandering框架将重新划分视为两个代表敌对政治利益的智能体之间的回合制博弈。该方法借鉴了博弈论中的‘选择与冻结’协议，利用大型语言模型（LLM）智能体嵌入战略互动。智能体在候选地图集中交替选择和冻结选区，通过受约束且可解释的选择逐步划分州。

Result: 在2020年后美国人口普查数据 across all states 的评估显示，Agentmandering显著减少了党派偏见和不公平性，并且方差比标准基线低2到3个数量级，在摇摆州情景下表现出公平性和稳定性。

Conclusion: Agentmandering通过将战略互动嵌入重新划分过程，有效解决了现有方法的不足，在减少党派偏见和提高选区划分稳定性方面取得了显著成效。

Abstract: Redistricting plays a central role in shaping how votes are translated into
political power. While existing computational methods primarily aim to generate
large ensembles of legally valid districting plans, they often neglect the
strategic dynamics involved in the selection process. This oversight creates
opportunities for partisan actors to cherry-pick maps that, while technically
compliant, are politically advantageous. Simply satisfying formal constraints
does not ensure fairness when the selection process itself can be manipulated.
We propose \textbf{Agentmandering}, a framework that reimagines redistricting
as a turn-based negotiation between two agents representing opposing political
interests. Drawing inspiration from game-theoretic ideas, particularly the
\textit{Choose-and-Freeze} protocol, our method embeds strategic interaction
into the redistricting process via large language model (LLM) agents. Agents
alternate between selecting and freezing districts from a small set of
candidate maps, gradually partitioning the state through constrained and
interpretable choices. Evaluation on post-2020 U.S. Census data across all
states shows that Agentmandering significantly reduces partisan bias and
unfairness, while achieving 2 to 3 orders of magnitude lower variance than
standard baselines. These results demonstrate both fairness and stability,
especially in swing-state scenarios. Our code is available at
https://github.com/Lihaogx/AgentMandering.

</details>


### [369] [DR. WELL: Dynamic Reasoning and Learning with Symbolic World Model for Embodied LLM-Based Multi-Agent Collaboration](https://arxiv.org/abs/2511.04646)
*Narjes Nourzad,Hanqing Yang,Shiyu Chen,Carlee Joe-Wong*

Main category: cs.AI

TL;DR: DR. WELL是一个去中心化的神经符号框架，用于多智能体协作规划。它通过一个两阶段的谈判协议来实现协作：首先，智能体提出带有推理过程的候选角色，然后在共识和环境约束下提交联合分配。之后，每个智能体独立生成并执行其角色的符号计划，而无需暴露详细的轨迹。通过在符号计划上进行推理，而不是原始轨迹，DR. WELL 避免了脆弱的步进式对齐，并实现了可重用、可同步和可解释的更高级别操作。实验表明，DR. WELL 能够适应不同回合，并且动态世界模型能够捕获可重用的模式，从而提高任务完成率和效率。


<details>
  <summary>Details</summary>
Motivation: 传统的协作式多智能体规划在轨迹层面容易因微小的偏差而导致冲突，因此需要一种更高级别的抽象方法。DR. WELL 旨在解决这一挑战，通过符号规划来提高抽象级别，并提供一个最小化的动作词汇表，以实现同步和集体进展。

Method: DR. WELL 采用一个去中心化的神经符号框架，包含一个两阶段的谈判协议：1. 智能体提出候选角色及其推理过程。2. 在共识和环境约束下，智能体承诺一个联合角色分配。 之后，每个智能体独立生成符号计划，并通过共享的、可更新的世界模型来联系执行结果。该框架通过推理符号计划而非原始轨迹来避免对齐问题。

Result: 实验表明，在协作式方块推动任务中，DR. WELL 框架能够使智能体适应不同的回合。动态世界模型捕获了可重用的模式，提高了任务完成率和效率。与仅依赖轨迹的传统方法相比，DR. WELL 通过谈判和自我完善，虽然增加了时间开销，但实现了更高效的协作策略。

Conclusion: DR. WELL 通过其去中心化的神经符号方法，利用谈判协议和动态世界模型，有效地解决了多智能体协作规划中的挑战。该框架通过符号推理提高了规划的鲁棒性、可重用性和可解释性，并在实验中证明了其在提高任务完成率和效率方面的有效性。

Abstract: Cooperative multi-agent planning requires agents to make joint decisions with
partial information and limited communication. Coordination at the trajectory
level often fails, as small deviations in timing or movement cascade into
conflicts. Symbolic planning mitigates this challenge by raising the level of
abstraction and providing a minimal vocabulary of actions that enable
synchronization and collective progress. We present DR. WELL, a decentralized
neurosymbolic framework for cooperative multi-agent planning. Cooperation
unfolds through a two-phase negotiation protocol: agents first propose
candidate roles with reasoning and then commit to a joint allocation under
consensus and environment constraints. After commitment, each agent
independently generates and executes a symbolic plan for its role without
revealing detailed trajectories. Plans are grounded in execution outcomes via a
shared world model that encodes the current state and is updated as agents act.
By reasoning over symbolic plans rather than raw trajectories, DR. WELL avoids
brittle step-level alignment and enables higher-level operations that are
reusable, synchronizable, and interpretable. Experiments on cooperative
block-push tasks show that agents adapt across episodes, with the dynamic world
model capturing reusable patterns and improving task completion rates and
efficiency. Experiments on cooperative block-push tasks show that our dynamic
world model improves task completion and efficiency through negotiation and
self-refinement, trading a time overhead for evolving, more efficient
collaboration strategies.

</details>


### [370] [KGFR: A Foundation Retriever for Generalized Knowledge Graph Question Answering](https://arxiv.org/abs/2511.04093)
*Yuanning Cui,Zequn Sun,Wei Hu,Zhangjie Fu*

Main category: cs.AI

TL;DR: LLM-KGFR框架利用LLM和知识图谱检索器（KGFR）协同工作，通过LLM生成的描述和基于角色初始化的实体实现对未见图谱的零样本泛化，并采用非对称渐进传播（APP）高效处理大型图谱，实现可控推理循环，在KG增强推理方面表现出强大的性能、可扩展性和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有方法在处理知识密集型问题时，由于LLM的上下文和参数知识有限，以及基于GNN的检索器在数据集特定调优和大规模/未见图谱上的可扩展性受限，因此需要一种新的方法。

Method: 提出LLM-KGFR协作框架，其中KGFR编码关系并基于角色初始化实体以实现零样本泛化。采用非对称渐进传播（APP）来高效处理大型图谱。LLM通过节点、边和路径级别的接口迭代地请求候选答案、支持事实和推理路径，形成一个可控的推理循环。

Result: LLM-KGFR框架在保持可扩展性和泛化能力的同时，在KG增强推理任务上实现了强大的性能。

Conclusion: LLM-KGFR框架为知识图谱增强推理提供了一个实用且高效的解决方案，能够克服现有方法的局限性。

Abstract: Large language models (LLMs) excel at reasoning but struggle with
knowledge-intensive questions due to limited context and parametric knowledge.
However, existing methods that rely on finetuned LLMs or GNN retrievers are
limited by dataset-specific tuning and scalability on large or unseen graphs.
We propose the LLM-KGFR collaborative framework, where an LLM works with a
structured retriever, the Knowledge Graph Foundation Retriever (KGFR). KGFR
encodes relations using LLM-generated descriptions and initializes entities
based on their roles in the question, enabling zero-shot generalization to
unseen KGs. To handle large graphs efficiently, it employs Asymmetric
Progressive Propagation (APP)- a stepwise expansion that selectively limits
high-degree nodes while retaining informative paths. Through node-, edge-, and
path-level interfaces, the LLM iteratively requests candidate answers,
supporting facts, and reasoning paths, forming a controllable reasoning loop.
Experiments demonstrate that LLM-KGFR achieves strong performance while
maintaining scalability and generalization, providing a practical solution for
KG-augmented reasoning.

</details>


### [371] [Testing the Testers: Human-Driven Quality Assessment of Voice AI Testing Platforms](https://arxiv.org/abs/2511.04133)
*Miguel E. Andres,Vadim Fedorov,Rida Sadek,Enric Spagnolo-Arrizabalaga,Nadescha Trudel*

Main category: cs.AI

TL;DR: Voice AI 领域的测试可靠性方法仍不完善，本文提出了一个以人为中心、可复现的基准测试框架，用于评估语音 AI 测试质量，并已验证该框架的有效性。


<details>
  <summary>Details</summary>
Motivation: 语音 AI 代理的生产部署日益增多，但目前缺乏系统性的方法来保证测试的可靠性，这导致了一个关键的测量缺口，无法客观评估现有测试方法（内部工具或外部平台）的有效性。

Method: 本文提出了一种系统性框架，通过结合成对比较、Elo 评分、 bootstrap置信区间和置换检验等心理测量技术，并进行严格的统计验证，以解决测试平台在生成真实测试对话（模拟质量）和准确评估代理响应（评估质量）方面的双重挑战。

Result: 对三个主流的商用语音 AI 测试平台进行了全面的实证评估，结果显示，使用该框架可以区分出统计上显著的性能差异。在评估质量方面，表现最佳的 Evalion 平台达到了 0.92 的 F1 分数，而其他平台为 0.73。在模拟质量方面，Evalion 的得分系统（包括平局）为 0.61，而其他平台为 0.43。

Conclusion: 该框架能够让研究人员和组织对其测试能力进行实证验证，为语音 AI 的大规模部署提供必要的测量基础，以确保部署的信心。

Abstract: Voice AI agents are rapidly transitioning to production deployments, yet
systematic methods for ensuring testing reliability remain underdeveloped.
Organizations cannot objectively assess whether their testing approaches
(internal tools or external platforms) actually work, creating a critical
measurement gap as voice AI scales to billions of daily interactions.
  We present the first systematic framework for evaluating voice AI testing
quality through human-centered benchmarking. Our methodology addresses the
fundamental dual challenge of testing platforms: generating realistic test
conversations (simulation quality) and accurately evaluating agent responses
(evaluation quality). The framework combines established psychometric
techniques (pairwise comparisons yielding Elo ratings, bootstrap confidence
intervals, and permutation tests) with rigorous statistical validation to
provide reproducible metrics applicable to any testing approach.
  To validate the framework and demonstrate its utility, we conducted
comprehensive empirical evaluation of three leading commercial platforms
focused on Voice AI Testing using 21,600 human judgments across 45 simulations
and ground truth validation on 60 conversations. Results reveal statistically
significant performance differences with the proposed framework, with the
top-performing platform, Evalion, achieving 0.92 evaluation quality measured as
f1-score versus 0.73 for others, and 0.61 simulation quality using a league
based scoring system (including ties) vs 0.43 for other platforms.
  This framework enables researchers and organizations to empirically validate
the testing capabilities of any platform, providing essential measurement
foundations for confident voice AI deployment at scale. Supporting materials
are made available to facilitate reproducibility and adoption.

</details>


### [372] [Opus: A Quantitative Framework for Workflow Evaluation](https://arxiv.org/abs/2511.04220)
*Alan Seroul,Théo Fagnoni,Inès Adnani,Dana O. Mohamed,Phillip Kingston*

Main category: cs.AI

TL;DR: 该框架通过结合奖励和惩罚机制，为工作流质量和效率提供了一个量化的评估方法。


<details>
  <summary>Details</summary>
Motivation: 提出一个量化工作流质量和效率的框架，以支持工作流的比较、评分和优化。

Method: 结合了Opus工作流奖励（一种概率函数，用于估计成功可能性、资源使用和输出增益）和Opus工作流规范化惩罚（一组可衡量的函数，用于捕捉内聚性、耦合性、可观察性和信息卫生等结构和信息质量）。

Result: 该框架支持在现代自动化系统中（如Opus）自动进行工作流评估、排名和优化，并可集成到强化学习中以指导工作流的发现和改进。

Conclusion: 提出了一种统一的优化公式，用于在奖励-惩罚权衡下识别和排名最优工作流。

Abstract: This paper introduces the Opus Workflow Evaluation Framework, a
probabilistic-normative formulation for quantifying Workflow quality and
efficiency. It integrates notions of correctness, reliability, and cost into a
coherent mathematical model that enables direct comparison, scoring, and
optimization of Workflows. The framework combines the Opus Workflow Reward, a
probabilistic function estimating expected performance through success
likelihood, resource usage, and output gain, with the Opus Workflow Normative
Penalties, a set of measurable functions capturing structural and informational
quality across Cohesion, Coupling, Observability, and Information Hygiene. It
supports automated Workflow assessment, ranking, and optimization within modern
automation systems such as Opus and can be integrated into Reinforcement
Learning loops to guide Workflow discovery and refinement. In this paper, we
introduce the Opus Workflow Reward model that formalizes Workflow success as a
probabilistic expectation over costs and outcomes. We define measurable Opus
Workflow Normative Penalties capturing structural, semantic, and signal-related
properties of Workflows. Finally, we propose a unified optimization formulation
for identifying and ranking optimal Workflows under joint Reward-Penalty
trade-offs.

</details>


### [373] [Shared Spatial Memory Through Predictive Coding](https://arxiv.org/abs/2511.04235)
*Zhengru Fang,Yu Guo,Jingjing Wang,Yuang Zhang,Haonan An,Yinhai Wang,Yuguang Fang*

Main category: cs.AI

TL;DR: 该研究提出了一个多智能体预测编码框架，通过最小化智能体间的相互不确定性来解决多智能体系统中的空间记忆共享和重建问题，并在此基础上实现了高效的通信和协作。


<details>
  <summary>Details</summary>
Motivation: 在多智能体系统中，部分可观测性和有限带宽常常导致协调失败。本研究旨在解决共享和重建一致性空间记忆的挑战。

Method: 提出了一种多智能体预测编码框架，将协调视为最小化智能体间相互不确定性的过程。该框架通过信息瓶颈目标，使智能体学会何时、何地以及如何进行通信。其基础是类似网格细胞的度量，用于自我定位，并通过自我监督运动预测自发产生。在此基础上，智能体发展出一种带宽高效的通信机制和专门的神经元群体，用于编码伙伴的位置（类似海马体社会位置细胞）。最后，通过分层强化学习策略来降低联合不确定性。

Result: 在Memory-Maze基准测试中，该方法在带宽限制下表现出极强的鲁棒性。当带宽从128 bits/step减少到4 bits/step时，成功率仅从73.5%下降到64.4%，而全广播基线则从67.6%骤降至28.6%。

Conclusion: 本研究为复杂社会表征如何从统一的预测驱动中涌现提供了理论上合理且生物学上可行的基础，从而实现了社会集体智能。

Abstract: Sharing and reconstructing a consistent spatial memory is a critical
challenge in multi-agent systems, where partial observability and limited
bandwidth often lead to catastrophic failures in coordination. We introduce a
multi-agent predictive coding framework that formulate coordination as the
minimization of mutual uncertainty among agents. Instantiated as an information
bottleneck objective, it prompts agents to learn not only who and what to
communicate but also when. At the foundation of this framework lies a
grid-cell-like metric as internal spatial coding for self-localization,
emerging spontaneously from self-supervised motion prediction. Building upon
this internal spatial code, agents gradually develop a bandwidth-efficient
communication mechanism and specialized neural populations that encode
partners' locations: an artificial analogue of hippocampal social place cells
(SPCs). These social representations are further enacted by a hierarchical
reinforcement learning policy that actively explores to reduce joint
uncertainty. On the Memory-Maze benchmark, our approach shows exceptional
resilience to bandwidth constraints: success degrades gracefully from 73.5% to
64.4% as bandwidth shrinks from 128 to 4 bits/step, whereas a full-broadcast
baseline collapses from 67.6% to 28.6%. Our findings establish a theoretically
principled and biologically plausible basis for how complex social
representations emerge from a unified predictive drive, leading to social
collective intelligence.

</details>


### [374] [RLoop: An Self-Improving Framework for Reinforcement Learning with Iterative Policy Initialization](https://arxiv.org/abs/2511.04285)
*Zeng Zhiyuan,Jiashuo Liu,Zhangyue Yin,Ge Zhang,Wenhao Huang,Xipeng Qiu*

Main category: cs.AI

TL;DR: RLOop通过迭代策略初始化来解决RLVR中的过拟合问题，通过探索、过滤和精炼，提高模型的泛化能力。


<details>
  <summary>Details</summary>
Motivation: RLVR在训练大型推理模型方面功能强大，但存在RL过拟合的挑战，即模型获得训练奖励但失去泛化能力。这是由策略过度专业化和训练过程中产生的多样化解决方案的灾难性遗忘驱动的。

Method: RLoop是一个基于迭代策略初始化的自改进框架。它使用RL探索给定策略的解决方案空间，然后过滤成功轨迹以创建专家数据集。该数据集通过拒绝采样微调（RFT）来精炼初始策略，为下一次迭代提供一个更优的起点。

Result: 实验表明，RLoop可以缓解遗忘问题，并显著提高泛化能力，与标准RL相比，平均准确率提高了9%，pass@32提高了15%以上。

Conclusion: RLoop通过将瞬态策略变体转化为稳健的性能提升，有效地解决了RLVR中的过拟合问题，并提高了模型的泛化能力。

Abstract: While Reinforcement Learning for Verifiable Rewards (RLVR) is powerful for
training large reasoning models, its training dynamics harbor a critical
challenge: RL overfitting, where models gain training rewards but lose
generalization. Our analysis reveals this is driven by policy
over-specialization and catastrophic forgetting of diverse solutions generated
during training. Standard optimization discards this valuable inter-step policy
diversity. To address this, we introduce RLoop, a self-improving framework
built on iterative policy initialization. RLoop transforms the standard
training process into a virtuous cycle: it first uses RL to explore the
solution space from a given policy, then filters the successful trajectories to
create an expert dataset. This dataset is used via Rejection-sampling
Fine-Tuning (RFT) to refine the initial policy, creating a superior starting
point for the next iteration. This loop of exploration and exploitation via
iterative re-initialization effectively converts transient policy variations
into robust performance gains. Our experiments show RLoop mitigates forgetting
and substantially improves generalization, boosting average accuracy by 9% and
pass@32 by over 15% compared to vanilla RL.

</details>


### [375] [GUI-360: A Comprehensive Dataset and Benchmark for Computer-Using Agents](https://arxiv.org/abs/2511.04307)
*Jian Mu,Chaoyun Zhang,Chiming Ni,Lu Wang,Bo Qiao,Kartik Mathur,Qianhui Wu,Yuhang Xie,Xiaojun Ma,Mengyu Zhou,Si Qin,Liqun Li,Yu Kang,Minghua Ma,Qingwei Lin,Saravan Rajmohan,Dongmei Zhang*

Main category: cs.AI

TL;DR: 本论文提出了GUI-360°，一个大规模、全面的数据集和基准套件，旨在推进计算机使用代理（CUAs）。GUI-360°通过一个LLM增强的、自动化程度很高的流水线来解决CUAs面临的现实世界任务稀缺、多模态轨迹缺乏自动化收集和注释以及缺乏统一基准评估GUI基础、屏幕解析和动作预测等挑战。该数据集包含超过120万个动作步骤，涵盖了数千个跨越主流Windows办公应用的轨迹，并提供了高分辨率截图、辅助功能元数据、实例化目标、中间推理痕迹以及成功和失败的动作轨迹。它支持GUI基础、屏幕解析和动作预测三个经典任务，并采用反映现代代理设计的混合GUI+API动作空间。通过在GUI-360°上对最先进的视觉-语言模型进行基准测试，揭示了它们在基础和动作预测方面存在显著的不足，尽管通过监督微调和强化学习可以获得显著提升，但仍无法达到人类水平的可靠性。研究者公开了GUI-360°及其配套代码，以促进可重复的研究并加速开发健壮的桌面CUAs。


<details>
  <summary>Details</summary>
Motivation: 计算机使用代理（CUAs）面临着现实世界任务稀缺、多模态轨迹缺乏自动化收集和注释以及缺乏统一基准评估GUI基础、屏幕解析和动作预测等挑战。

Method: 提出GUI-360°数据集和基准套件，使用LLM增强的自动化流水线进行查询来源、环境模板构建、任务实例化、批量执行和LLM驱动的质量过滤。

Result: GUI-360°包含超过120万个动作步骤，涵盖了数千个跨越主流Windows办公应用的轨迹，并提供了高分辨率截图、辅助功能元数据、实例化目标、中间推理痕迹以及成功和失败的动作轨迹。最先进的视觉-语言模型在GUI基础和动作预测方面表现出显著不足，但通过监督微调和强化学习有所改善。

Conclusion: GUI-360°数据集和基准套件旨在加速开发健壮的桌面CUAs，但现有模型在某些任务上仍有提升空间。研究者已公开数据集和代码以促进研究。

Abstract: We introduce GUI-360$^\circ$, a large-scale, comprehensive dataset and
benchmark suite designed to advance computer-using agents (CUAs). CUAs present
unique challenges and is constrained by three persistent gaps: a scarcity of
real-world CUA tasks, the lack of automated collection-and-annotation pipelines
for multi-modal trajectories, and the absence of a unified benchmark that
jointly evaluates GUI grounding, screen parsing, and action prediction.
  GUI-360$^\circ$ addresses these gaps with an LLM-augmented, largely automated
pipeline for query sourcing, environment-template construction, task
instantiation, batched execution, and LLM-driven quality filtering. The
released corpus contains over 1.2M executed action steps across thousands of
trajectories in popular Windows office applications, and includes
full-resolution screenshots, accessibility metadata when available,
instantiated goals, intermediate reasoning traces, and both successful and
failed action trajectories. The dataset supports three canonical tasks, GUI
grounding, screen parsing, and action prediction, and a hybrid GUI+API action
space that reflects modern agent designs. Benchmarking state-of-the-art
vision--language models on GUI-360$^\circ$ reveals substantial out-of-the-box
shortcomings in grounding and action prediction; supervised fine-tuning and
reinforcement learning yield significant gains but do not close the gap to
human-level reliability. We release GUI-360$^\circ$ and accompanying code to
facilitate reproducible research and accelerate progress on robust desktop
CUAs.
  The full dataset has been made public on
https://huggingface.co/datasets/vyokky/GUI-360.

</details>


### [376] [Probing the Probes: Methods and Metrics for Concept Alignment](https://arxiv.org/abs/2511.04312)
*Jacob Lysnæs-Larsen,Marte Eggen,Inga Strümke*

Main category: cs.AI

TL;DR: 准确率并不代表概念对齐的可靠指标，需要新的方法和评估指标。


<details>
  <summary>Details</summary>
Motivation: 现有的基于准确率的方法在衡量概念对齐性方面存在不可靠性，因为探测器更容易捕捉到虚假相关性，而非真正对齐的概念。

Method: 提出一种新的基于空间线性归因的概念定位方法，并引入了三种新的定量评估指标：硬准确率、分割分数和增强鲁棒性。通过实验证明，具有平移不变性和空间对齐性的探测器能够提升概念对齐性。

Result: 实验证明，通过操纵虚假相关性构建的探测器也能达到很高的准确率，说明单独的准确率指标不可靠。新的方法和评估指标能够更准确地衡量概念对齐性。

Conclusion: 概念对齐性的评估应侧重于对齐性指标而非准确率，并且探测器的设计应考虑模型架构和概念本身的特性。

Abstract: In explainable AI, Concept Activation Vectors (CAVs) are typically obtained
by training linear classifier probes to detect human-understandable concepts as
directions in the activation space of deep neural networks. It is widely
assumed that a high probe accuracy indicates a CAV faithfully representing its
target concept. However, we show that the probe's classification accuracy alone
is an unreliable measure of concept alignment, i.e., the degree to which a CAV
captures the intended concept. In fact, we argue that probes are more likely to
capture spurious correlations than they are to represent only the intended
concept. As part of our analysis, we demonstrate that deliberately misaligned
probes constructed to exploit spurious correlations, achieve an accuracy close
to that of standard probes. To address this severe problem, we introduce a
novel concept localization method based on spatial linear attribution, and
provide a comprehensive comparison of it to existing feature visualization
techniques for detecting and mitigating concept misalignment. We further
propose three classes of metrics for quantitatively assessing concept
alignment: hard accuracy, segmentation scores, and augmentation robustness. Our
analysis shows that probes with translation invariance and spatial alignment
consistently increase concept alignment. These findings highlight the need for
alignment-based evaluation metrics rather than probe accuracy, and the
importance of tailoring probes to both the model architecture and the nature of
the target concept.

</details>


### [377] [AdversariaLLM: A Unified and Modular Toolbox for LLM Robustness Research](https://arxiv.org/abs/2511.04316)
*Tim Beyer,Jonas Dornbusch,Jakob Steimle,Moritz Ladenburger,Leo Schwinn,Stephan Günnemann*

Main category: cs.AI

TL;DR: LLM安全和鲁棒性研究的碎片化阻碍了进展，AdversariaLLM工具箱通过提供可复现、可比较的评估框架来解决这个问题。


<details>
  <summary>Details</summary>
Motivation: LLM安全和鲁棒性研究的碎片化、不一致的实现、数据集和评估方法阻碍了可复现性和跨研究的可比性，从而阻碍了有意义的进展。

Method: AdversariaLLM是一个用于LLM越狱鲁棒性研究的工具箱，其设计以可复现性、正确性和可扩展性为中心。该框架实现了十二种对抗性攻击算法，集成了七个涵盖有害性、过度拒绝和效用评估的基准数据集，并通过Hugging Face提供了对多种开放权重LLM的访问。实现包括计算资源跟踪、确定性结果和分布评估技术等高级功能，以提高可比性和可复现性。它还通过伴随包JudgeZoo集成进行判断。

Result: AdversariaLLM提供了一个集成的框架，用于评估LLM在面对越狱攻击时的鲁棒性，集成了多种攻击、数据集和模型，并支持可复现和可比较的评估。

Conclusion: AdversariaLLM旨在通过提供一个透明、可比较和可复现的研究基础，来解决LLM安全领域碎片化的问题，从而促进该领域的研究进展。

Abstract: The rapid expansion of research on Large Language Model (LLM) safety and
robustness has produced a fragmented and oftentimes buggy ecosystem of
implementations, datasets, and evaluation methods. This fragmentation makes
reproducibility and comparability across studies challenging, hindering
meaningful progress. To address these issues, we introduce AdversariaLLM, a
toolbox for conducting LLM jailbreak robustness research. Its design centers on
reproducibility, correctness, and extensibility. The framework implements
twelve adversarial attack algorithms, integrates seven benchmark datasets
spanning harmfulness, over-refusal, and utility evaluation, and provides access
to a wide range of open-weight LLMs via Hugging Face. The implementation
includes advanced features for comparability and reproducibility such as
compute-resource tracking, deterministic results, and distributional evaluation
techniques. \name also integrates judging through the companion package
JudgeZoo, which can also be used independently. Together, these components aim
to establish a robust foundation for transparent, comparable, and reproducible
research in LLM safety.

</details>


### [378] [RxSafeBench: Identifying Medication Safety Issues of Large Language Models in Simulated Consultation](https://arxiv.org/abs/2511.04328)
*Jiahao Zhao,Luxin Xu,Minghuan Tan,Lichao Zhang,Ahmadreza Argha,Hamid Alinejad-Rokny,Min Yang*

Main category: cs.AI

TL;DR: LLMs在医疗领域的应用取得进展，但药物安全性评估受限。本文提出模拟临床咨询的框架和RxSafeBench基准，评估LLMs的药物安全性。结果显示，LLMs在整合药物禁忌和相互作用知识方面存在挑战，尤其是在风险隐含时。RxSafeBench为LLMs药物安全性评估提供了首个全面基准。


<details>
  <summary>Details</summary>
Motivation: 现有LLMs在医疗领域进展显著，但药物安全性评估研究有限，缺乏真实世界数据集且临床评估不足。

Method: 提出模拟临床咨询的框架，生成包含药物风险的诊断对话，构建RxRisk DB数据库（包含禁忌、药物相互作用、适应症-药物对），并开发RxSafeBench基准（包含2,443个高质量咨询场景），采用结构化选择题评估LLMs的药物推荐能力。

Result: 当前LLMs在整合药物禁忌和相互作用知识方面存在困难，尤其是在风险隐含的情况下。LLMs在模拟患者场景下推荐安全药物的能力有待提高。

Conclusion: LLMs在药物安全性方面面临挑战，需要通过改进提示和任务调整来提高可靠性。RxSafeBench是首个用于评估LLMs药物安全性的全面基准，有助于推动更安全、更可信赖的AI临床决策支持。

Abstract: Numerous medical systems powered by Large Language Models (LLMs) have
achieved remarkable progress in diverse healthcare tasks. However, research on
their medication safety remains limited due to the lack of real world datasets,
constrained by privacy and accessibility issues. Moreover, evaluation of LLMs
in realistic clinical consultation settings, particularly regarding medication
safety, is still underexplored. To address these gaps, we propose a framework
that simulates and evaluates clinical consultations to systematically assess
the medication safety capabilities of LLMs. Within this framework, we generate
inquiry diagnosis dialogues with embedded medication risks and construct a
dedicated medication safety database, RxRisk DB, containing 6,725
contraindications, 28,781 drug interactions, and 14,906 indication-drug pairs.
A two-stage filtering strategy ensures clinical realism and professional
quality, resulting in the benchmark RxSafeBench with 2,443 high-quality
consultation scenarios. We evaluate leading open-source and proprietary LLMs
using structured multiple choice questions that test their ability to recommend
safe medications under simulated patient contexts. Results show that current
LLMs struggle to integrate contraindication and interaction knowledge,
especially when risks are implied rather than explicit. Our findings highlight
key challenges in ensuring medication safety in LLM-based systems and provide
insights into improving reliability through better prompting and task-specific
tuning. RxSafeBench offers the first comprehensive benchmark for evaluating
medication safety in LLMs, advancing safer and more trustworthy AI-driven
clinical decision support.

</details>


### [379] [Monitor-Generate-Verify (MGV):Formalising Metacognitive Theory for Language Model Reasoning](https://arxiv.org/abs/2511.04341)
*Nick Oh,Fernand Gobet*

Main category: cs.AI

TL;DR: 该研究提出了一种名为“监控-生成-验证”(MGV)的框架，旨在解决现有“生成-验证”模型在推理过程中过早承诺次优路径的问题，并通过引入显式监控机制来提高模型的适应性和恢复能力。


<details>
  <summary>Details</summary>
Motivation: 现有测试时推理架构（如生成-验证范式）在生成和验证方面表现出色，但忽略了监控推理何时以及如何开始的过程，这可能导致模型陷入“前缀支配陷阱”，过早地承诺次优推理路径，并难以恢复，从而导致约20%的准确率损失。

Method: 该研究将Flavell以及Nelson和Narens的元认知理论形式化为计算规范，并提出了监控-生成-验证(MGV)框架。该框架在生成-验证范式的基础上增加了显式的监控机制，该机制在生成开始之前捕获元认知体验（如难度评估和置信度判断），并通过验证反馈来优化未来的监控。

Result: 尽管没有进行实证验证，但该研究首次将基础元认知理论系统地转化为计算模型，为理解推理系统的失败提供了一个原则性的词汇，并为未来的测试时推理设计提供了具体的架构干预建议。

Conclusion: 该研究提出了MGV框架，通过引入显式的元认知监控来解决现有测试时推理架构的局限性，有望为提高模型的推理能力和鲁棒性提供新的方向。

Abstract: Test-time reasoning architectures such as those following the Generate-Verify
paradigm -- where a model iteratively refines or verifies its own generated
outputs -- prioritise generation and verification but exclude the monitoring
processes that determine when and how reasoning should begin. This omission may
contribute to the prefix dominance trap, in which models commit early to
suboptimal reasoning paths and seldom recover, yielding roughly 20% accuracy
loss. We address this architectural gap by formalising Flavell's and Nelson and
Narens' metacognitive theories into computational specifications, proposing the
Monitor-Generate-Verify (MGV) framework. MGV extends the Generate-Verify
paradigm by adding explicit monitoring that captures metacognitive experiences
(from difficulty assessments to confidence judgements) before generation begins
and refines future monitoring through verification feedback. Though we present
no empirical validation, this work provides the first systematic computational
translation of foundational metacognitive theories, offering a principled
vocabulary for understanding reasoning system failures and suggesting specific
architectural interventions for future test-time reasoning designs.

</details>


### [380] [Post-Training LLMs as Better Decision-Making Agents: A Regret-Minimization Approach](https://arxiv.org/abs/2511.04393)
*Chanwoo Park,Ziyang Chen,Asuman Ozdaglar,Kaiqing Zhang*

Main category: cs.AI

TL;DR: LLMs在决策制定方面表现不佳，提出Iterative RMFT方法通过迭代蒸馏低风险决策轨迹来改进LLMs的决策能力，并在多种模型和任务上验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: LLMs作为决策制定“代理”在动态环境中存在决策能力不足、无法有效平衡探索与利用的问题。

Method: Iterative RMFT通过迭代地将低风险决策轨迹“蒸馏”回基础模型。在每次迭代中，模型生成多个决策轨迹，选择风险最低的k个，并在这些轨迹上进行微调。

Result: Iterative RMFT在包括Transformer、开放权重LLM和GPT-4o mini在内的多种模型上，显著提升了LLMs在不同任务（如不同时间范围、动作空间、奖励过程和自然语言环境）下的决策制定表现，并展现出良好的泛化能力。

Conclusion: Iterative RMFT是一种原则性的、通用的模型后训练框架，能够增强LLMs的决策制定能力。

Abstract: Large language models (LLMs) are increasingly deployed as "agents" for
decision-making (DM) in interactive and dynamic environments. Yet, since they
were not originally designed for DM, recent studies show that LLMs can struggle
even in basic online DM problems, failing to achieve low regret or an effective
exploration-exploitation tradeoff. To address this, we introduce Iterative
Regret-Minimization Fine-Tuning (Iterative RMFT), a post-training procedure
that repeatedly distills low-regret decision trajectories back into the base
model. At each iteration, the model rolls out multiple decision trajectories,
selects the k-lowest regret ones, and fine-tunes itself on them. Unlike prior
methods that (a) distill action sequences from known DM algorithms or (b) rely
on manually crafted chain-of-thought templates, our approach leverages the
regret metric to elicit the model's own DM ability and reasoning rationales.
This reliance on model-generated reasoning avoids rigid output engineering and
provides more flexible, natural-language training signals. Empirical results
show that Iterative RMFT improves LLMs' DM performance across diverse models -
from Transformers with numerical input/output, to open-weight LLMs, and
advanced closed-weight models like GPT-4o mini. Its flexibility in output and
reasoning formats enables generalization across tasks with varying horizons,
action spaces, reward processes, and natural-language contexts. Finally, we
provide theoretical insight showing that a single-layer Transformer under this
paradigm can act as a no-regret learner in a simplified setting. Overall,
Iterative RMFT offers a principled and general post-training framework for
enhancing LLMs' decision-making capabilities.

</details>


### [381] [The Peril of Preference: Why GRPO fails on Ordinal Rewards](https://arxiv.org/abs/2511.04439)
*Anisha Garg,Ganesh Venkatesh*

Main category: cs.AI

TL;DR: GRPO在处理非二元奖励时存在缺陷，CoRPO通过引入自适应基线解决了这个问题，并在代码验证任务上表现出更稳定的收敛性和更好的泛化能力。


<details>
  <summary>Details</summary>
Motivation: GRPO在处理非二元奖励时存在缺陷，容易错误地强化不正确的行为。

Method: 提出CoRPO，一种使用自适应基线的新公式，该基线首先强制执行最低质量阈值，然后切换到相对偏好模式。

Result: CoRPO在代码验证任务上表现出更稳定的收敛性和更好的泛化能力。

Conclusion: CoRPO解决了GRPO在处理多维度反馈时的缺陷，是使LLM能够通过强化学习获得新能力的下一步。

Abstract: Group-relative Policy Optimization's (GRPO) simplicity makes it highly
desirable for adapting LLMs to become experts at specific tasks. But this
simplicity also makes it ill-specified as we seek to enhance RL training with
richer, non-binary feedback. When using ordinal rewards to give partial credit,
GRPO's simplicity starts to hurt, as its group-average baseline often assigns a
positive advantage to failed trajectories and reinforces incorrect behavior.
  We introduce Correctness Relative Policy Optimization (CoRPO), a new
formulation that solves this flaw. CoRPO uses an adaptive baseline that
enforces a minimum quality threshold, ensuring failed solutions are never
positively reinforced. Once the policy consistently meets this threshold, the
baseline automatically transitions to a relative preference mode, pushing the
model to find optimal solutions rather than just "acceptable" ones. We
empirically validate CoRPO on a code verification task, where it demonstrates
more stable convergence and better out-of-domain generalization.
  This work represents a critical step in our broader research program to
enable LLMs to learn genuinely new capabilities through reinforcement learning.
We achieve this by enabling LLMs to learn from rich, multi-dimensional feedback
- progressing from binary to ordinal rewards in this work, and onward to
denser, per-step supervision.

</details>


### [382] [Beyond Shortest Path: Agentic Vehicular Routing with Semantic Context](https://arxiv.org/abs/2511.04464)
*Carnot Braun,Rafael O. Jarczewski,Gabriel U. Talasso,Leandro A. Villas,Allan M. de Souza*

Main category: cs.AI

TL;DR: PAVe是一个结合了传统路径查找算法和LLM的混合智能体系统，能够理解并整合人类驾驶员的复杂、动态和语义化情境，实现个性化、自适应的城市出行优化。


<details>
  <summary>Details</summary>
Motivation: 传统的车辆路径系统在优化单一指标（如时间或距离）方面效率很高，但在考虑多个指标时需要额外的处理。然而，它们缺乏理解和整合人类驾驶员复杂的、语义化的和动态的情境（如多步骤任务、情境约束或紧急需求）的能力。

Method: PAVe采用一个大型语言模型（LLM）智能体，该智能体对由多目标（时间、CO2）Dijkstra算法生成的候选路线集进行操作。该智能体利用预先处理的城市兴趣点（POIs）地理空间缓存，根据用户提供的任务、偏好和回避规则来评估这些选项。

Result: 在现实城市环境的基准测试中，PAVe成功地将复杂的raquinone意图转化为合适的路线修改，在使用本地模型进行初始路线选择时，准确率超过88%。

Conclusion: 将经典路由算法与基于LLM的语义推理层相结合，是创建个性化、自适应和可扩展的城市出行优化解决方案的健壮有效方法。

Abstract: Traditional vehicle routing systems efficiently optimize singular metrics
like time or distance, and when considering multiple metrics, they need more
processes to optimize . However, they lack the capability to interpret and
integrate the complex, semantic, and dynamic contexts of human drivers, such as
multi-step tasks, situational constraints, or urgent needs. This paper
introduces and evaluates PAVe (Personalized Agentic Vehicular Routing), a
hybrid agentic assistant designed to augment classical pathfinding algorithms
with contextual reasoning. Our approach employs a Large Language Model (LLM)
agent that operates on a candidate set of routes generated by a multi-objective
(time, CO2) Dijkstra algorithm. The agent evaluates these options against
user-provided tasks, preferences, and avoidance rules by leveraging a
pre-processed geospatial cache of urban Points of Interest (POIs). In a
benchmark of realistic urban scenarios, PAVe successfully used complex user
intent into appropriate route modifications, achieving over 88% accuracy in its
initial route selections with a local model. We conclude that combining
classical routing algorithms with an LLM-based semantic reasoning layer is a
robust and effective approach for creating personalized, adaptive, and scalable
solutions for urban mobility optimization.

</details>


### [383] [Promoting Sustainable Web Agents: Benchmarking and Estimating Energy Consumption through Empirical and Theoretical Analysis](https://arxiv.org/abs/2511.04481)
*Lars Krupp,Daniel Geißler,Vishal Banwari,Paul Lukowicz,Jakob Karolus*

Main category: cs.AI

TL;DR: Web agents are powerful but have unexplored sustainability issues. This paper estimates and benchmarks their energy and CO2 costs, showing significant variation based on design choices. It calls for transparency and energy consumption metrics in web agent evaluation.


<details>
  <summary>Details</summary>
Motivation: To address the largely unexplored sustainability issues (energy and CO2 costs) associated with powerful web agents that interact with the internet.

Method: Both theoretical (estimation) and empirical (benchmarking) approaches were used to explore the energy and CO2 costs of web agents.

Result: Different web agent design philosophies lead to significant variations in energy consumption. Higher energy consumption does not necessarily correlate with better results. Lack of transparency in model parameters and processes hinders energy consumption estimation.

Conclusion: There is a need to change how web agents are evaluated by incorporating dedicated metrics for energy consumption in benchmarks, promoting transparency in model parameters and processes.

Abstract: Web agents, like OpenAI's Operator and Google's Project Mariner, are powerful
agentic systems pushing the boundaries of Large Language Models (LLM). They can
autonomously interact with the internet at the user's behest, such as
navigating websites, filling search masks, and comparing price lists. Though
web agent research is thriving, induced sustainability issues remain largely
unexplored. To highlight the urgency of this issue, we provide an initial
exploration of the energy and $CO_2$ cost associated with web agents from both
a theoretical -via estimation- and an empirical perspective -by benchmarking.
Our results show how different philosophies in web agent creation can severely
impact the associated expended energy, and that more energy consumed does not
necessarily equate to better results. We highlight a lack of transparency
regarding disclosing model parameters and processes used for some web agents as
a limiting factor when estimating energy consumption. Our work contributes
towards a change in thinking of how we evaluate web agents, advocating for
dedicated metrics measuring energy consumption in benchmarks.

</details>


### [384] [Optimizing Sensor Placement in Urban Storm Sewers: A Data-Driven Sparse Sensing Approach](https://arxiv.org/abs/2511.04556)
*Zihang Ding,Kun Zhang*

Main category: cs.AI

TL;DR: 本研究提出了一种数据驱动的稀疏传感（DSS）框架，结合EPA-SWMM模型，用于优化城市排水管网的传感器布局并重建峰值流量，以应对资源限制下的洪水监测和预警挑战。


<details>
  <summary>Details</summary>
Motivation: 城市地表水淹没日益频繁，但时间和预算等实际约束阻碍了高时空分辨率的洪水监测和预警。如何用有限的资源监测城市排水管网和预测流况是一个重大挑战。

Method: 利用SWMM模型生成训练数据集，然后应用DSS框架（包括奇异值分解和QR分解）来优化传感器节点选择，并与SWMM模拟结果进行对比验证。

Result: 研究结果表明，在77个节点中优选3个传感器节点，可以实现0.92-0.95的纳什效率系数（NSE），重建峰值流量。该模型对测量不确定性具有良好的鲁棒性，并且传感器故障的影响与位置和数量有关。

Conclusion: DSS框架在计算效率和物理可解释性之间取得了良好平衡，能够用最少的传感器实现高精度的流量重建，并可进一步集成预测模型，在传感和监测资源有限的情况下实现洪水预警和实时控制。

Abstract: Urban surface water flooding, triggered by intense rainfall overwhelming
drainage systems, is increasingly frequent and widespread. While flood
prediction and monitoring in high spatial-temporal resolution are desired,
practical constraints in time, budget, and technology hinder its full
implementation. How to monitor urban drainage networks and predict flow
conditions under constrained resource is a major challenge. This study presents
a data-driven sparse sensing (DSS) framework, integrated with EPA-SWMM, to
optimize sensor placement and reconstruct peak flowrates in a stormwater
system, using the Woodland Avenue catchment in Duluth, Minnesota, as a case
study. We utilized a SWMM model to generate a training dataset of peak flowrate
profiles across the stormwater network. Furthermore, we applied DSS -
leveraging singular value decomposition for dimensionality reduction and QR
factorization for sensor allocation - to identify the optimal monitoring nodes
based on the simulated training dataset. We then validated the
representativeness of these identified monitoring nodes by comparing the
DSS-reconstructed peak flowrate profiles with those obtained from SWMM. Three
optimally placed sensors among 77 nodes achieved satisfactory reconstruction
performance with Nash-Sutcliffe Efficiency (NSE) values of 0.92-0.95 (25th to
75th percentiles). In addition, the model showed good robustness to uncertainty
in measurements. Its robustness to sensor failures is location-dependent and
improves with the number of sensors deployed. The framework balances
computational efficiency and physical interpretability, enabling high-accuracy
flow reconstruction with minimal sensors. This DSS framework can be further
integrated with predictive models to realize flood early warning and real-time
control under limited sensing and monitoring resource.

</details>


### [385] [Jr. AI Scientist and Its Risk Report: Autonomous Scientific Exploration from a Baseline Paper](https://arxiv.org/abs/2511.04583)
*Atsuyuki Miyai,Mashiro Toyooka,Takashi Otonari,Zaiying Zhao,Kiyoharu Aizawa*

Main category: cs.AI

TL;DR: Jr. AI Scientist是一个AI科学家系统，可以模仿学生研究员的流程：分析局限性、提出假设、进行实验并撰写论文。它在自动化评估中表现优于现有系统，但也暴露了AI科学家系统的风险和挑战。


<details>
  <summary>Details</summary>
Motivation: 理解AI科学家系统的能力和风险对于确保可信赖和可持续的AI科学进步至关重要，同时也要保护学术生态系统的完整性。

Method: 开发了Jr. AI Scientist系统，该系统模仿了学生研究员的核心研究流程：给定基线论文，分析其局限性，提出新的改进假设，通过严格的实验进行验证，并撰写结果论文。该系统利用现代编码代理来处理复杂的多文件实现。

Result: Jr. AI Scientist生成的论文在自动化评估中获得了比现有全自动化系统更高的评分。然而，作者评估和Agents4Science的评审也指出了重要的局限性。

Conclusion: Jr. AI Scientist在生成科学上有价值的贡献方面显示出潜力，但其局限性表明了当前AI科学家系统的潜在风险以及未来研究的关键挑战。报告了开发过程中发现的各种风险，以加深对AI科学家开发进展和风险的理解。

Abstract: Understanding the current capabilities and risks of AI Scientist systems is
essential for ensuring trustworthy and sustainable AI-driven scientific
progress while preserving the integrity of the academic ecosystem. To this end,
we develop Jr. AI Scientist, a state-of-the-art autonomous AI scientist system
that mimics the core research workflow of a novice student researcher: Given
the baseline paper from the human mentor, it analyzes its limitations,
formulates novel hypotheses for improvement, validates them through rigorous
experimentation, and writes a paper with the results. Unlike previous
approaches that assume full automation or operate on small-scale code, Jr. AI
Scientist follows a well-defined research workflow and leverages modern coding
agents to handle complex, multi-file implementations, leading to scientifically
valuable contributions. For evaluation, we conducted automated assessments
using AI Reviewers, author-led evaluations, and submissions to Agents4Science,
a venue dedicated to AI-driven scientific contributions. The findings
demonstrate that Jr. AI Scientist generates papers receiving higher review
scores than existing fully automated systems. Nevertheless, we identify
important limitations from both the author evaluation and the Agents4Science
reviews, indicating the potential risks of directly applying current AI
Scientist systems and key challenges for future research. Finally, we
comprehensively report various risks identified during development. We hope
these insights will deepen understanding of current progress and risks in AI
Scientist development.

</details>


### [386] [Are We Asking the Right Questions? On Ambiguity in Natural Language Queries for Tabular Data Analysis](https://arxiv.org/abs/2511.04584)
*Daniel Gomm,Cornelius Wolff,Madelon Hulsebos*

Main category: cs.AI

TL;DR: 自然语言接口在处理表格数据时，应将歧义视为一种合作交互的特性，由用户和系统共同分担查询规范的责任。本研究提出了一个区分合作查询和非合作查询的框架，并通过分析15个流行数据集中的查询，揭示了现有评估方法的不足。该框架鼓励在解决查询时拥抱合作，为自然语言接口的设计和评估提供了新的视角和未来研究方向。


<details>
  <summary>Details</summary>
Motivation: 现有的自然语言接口在处理表格数据时，需要应对查询中的固有歧义。然而，传统的做法是将歧义视为一种缺陷。本研究旨在将歧义重新定义为一种合作交互的特性，并提出一个框架来区分合作查询和非合作查询，从而为更有效的接口设计和评估提供理论依据。

Method: 提出一个原则性框架，区分可解析的合作查询和无法解析的非合作查询。将此框架应用于15个流行的表格问答和分析数据集，分析其中的查询类型，并评估现有评估方法的适宜性。

Result: 分析发现，现有表格问答和分析数据集中的查询类型混合不当，既不适合评估系统的执行准确性，也不适合评估其解释能力。这表明需要一种新的评估方法。

Conclusion: 本研究提出的合作查询框架和对现有数据集的分析，改变了人们对歧义的看法，从试图消除歧义转向拥抱合作来解决歧义。这有助于更明智地设计和评估自然语言表格数据接口，并为未来的研究指明了方向。

Abstract: Natural language interfaces to tabular data must handle ambiguities inherent
to queries. Instead of treating ambiguity as a deficiency, we reframe it as a
feature of cooperative interaction, where the responsibility of query
specification is shared among the user and the system. We develop a principled
framework distinguishing cooperative queries, i.e., queries that yield a
resolvable interpretation, from uncooperative queries that cannot be resolved.
Applying the framework to evaluations for tabular question answering and
analysis, we analyze the queries in 15 popular datasets, and observe an
uncontrolled mixing of query types neither adequate for evaluating a system's
execution accuracy nor for evaluating interpretation capabilities. Our
framework and analysis of queries shifts the perspective from fixing ambiguity
to embracing cooperation in resolving queries. This reflection enables more
informed design and evaluation for natural language interfaces for tabular
data, for which we outline implications and directions for future research.

</details>


### [387] [Question the Questions: Auditing Representation in Online Deliberative Processes](https://arxiv.org/abs/2511.04588)
*Soham De,Lodewijk Gelauff,Ashish Goel,Smitha Milli,Ariel Procaccia,Alice Siu*

Main category: cs.AI

TL;DR: 本研究提出了一种基于社会选择理论中“正当代表性”概念的审计框架，用于评估在公民审议中，专家提问环节所选问题的代表性水平。研究实现了首个用于在通用效用设置下审计正当代表性的算法，其中最高效算法的运行时间为 O(mn log n)。该框架被应用于历史审议案例，比较了实际提问、整数线性规划选择提问以及大型语言模型（LLM）生成的摘要提问这三种方式的代表性。研究结果揭示了LLM在支持审议过程中的潜力和局限性，并将该审计方法整合到在线审议平台中，以帮助实践者改进未来的审议。 


<details>
  <summary>Details</summary>
Motivation: 在公民审议（如公民议会、审议式民意调查）中，参与者与专家直接互动是一个核心特征。然而，由于时间限制，并非所有参与者提出的问题都能被选出，因此如何选取能够最大程度代表所有参与者利益的一小组问题，成为了一个挑战。

Method: 提出了一种基于社会选择理论中“正当代表性”（JR）概念的审计框架，用于衡量一组问题所能达到的代表性水平。开发了首个在通用效用设置下审计JR的算法，其中最优算法的时间复杂度为O(mn log n)，n为参与者数量，m为问题数量。将该审计方法应用于历史审议数据，并与以下几种方式进行比较：1) 主持人实际选择的问题；2) 通过整数线性规划选出的参与者问题；3) 由大型语言模型（LLM）生成的摘要问题。

Result: 将开发的审计方法应用于历史审议案例，并对实际提问、整数线性规划选出的问题以及LLM生成的摘要问题进行了代表性比较。结果表明，LLM在支持审议方面既有潜力也存在局限性。

Conclusion: 本研究提出的审计框架能够评估和改进公民审议中专家提问环节的问题选择的代表性。研究结果对LLM在审议过程中的应用提供了见解，并将该方法整合到在线审议平台中，便于实践者使用。

Abstract: A central feature of many deliberative processes, such as citizens'
assemblies and deliberative polls, is the opportunity for participants to
engage directly with experts. While participants are typically invited to
propose questions for expert panels, only a limited number can be selected due
to time constraints. This raises the challenge of how to choose a small set of
questions that best represent the interests of all participants. We introduce
an auditing framework for measuring the level of representation provided by a
slate of questions, based on the social choice concept known as justified
representation (JR). We present the first algorithms for auditing JR in the
general utility setting, with our most efficient algorithm achieving a runtime
of $O(mn\log n)$, where $n$ is the number of participants and $m$ is the number
of proposed questions. We apply our auditing methods to historical
deliberations, comparing the representativeness of (a) the actual questions
posed to the expert panel (chosen by a moderator), (b) participants' questions
chosen via integer linear programming, (c) summary questions generated by large
language models (LLMs). Our results highlight both the promise and current
limitations of LLMs in supporting deliberative processes. By integrating our
methods into an online deliberation platform that has been used for over
hundreds of deliberations across more than 50 countries, we make it easy for
practitioners to audit and improve representation in future deliberations.

</details>


### [388] [VeriCoT: Neuro-symbolic Chain-of-Thought Validation via Logical Consistency Checks](https://arxiv.org/abs/2511.04662)
*Yu Feng,Nathaniel Weir,Kaj Bostrom,Sam Bayless,Darion Cassel,Sapana Chaudhary,Benjamin Kiesl-Reiter,Huzefa Rangwala*

Main category: cs.AI

TL;DR: VeriCoT是一种神经符号方法，用于从大语言模型的链式思考（CoT）推理中提取和验证形式逻辑论证，以解决其自身逻辑验证不可靠的问题。


<details>
  <summary>Details</summary>
Motivation: 大语言模型（LLM）虽然可以通过链式思考（CoT）进行多步推理，但无法可靠地验证其自身的逻辑，这在高风险场景中会削弱人们对它们的信任。

Method: VeriCoT将每个CoT推理步骤形式化为一阶逻辑，并识别将论证依据于源上下文、常识知识或先前推理步骤的假设。这种符号表示使得自动求解器能够验证逻辑有效性，而自然语言假设则允许人类和系统识别无依据或错误的推理步骤。

Result: 在ProofWriter、LegalBench和BioASQ数据集上的实验表明，VeriCoT能有效识别错误的推理，并且是最终答案正确性的有力预测指标。此外，通过利用VeriCoT的验证信号进行推理时自我反思、在VeriCoT蒸馏数据集上进行监督微调（SFT）以及使用基于验证的成对奖励通过直接偏好优化（DPO）进行偏好微调（PFT），可以进一步提高推理的有效性和准确性。

Conclusion: VeriCoT通过提取和验证形式逻辑论证，提高了大语言模型在多步推理中的可靠性和可信度，并通过多种微调策略进一步增强了其推理能力。

Abstract: LLMs can perform multi-step reasoning through Chain-of-Thought (CoT), but
they cannot reliably verify their own logic. Even when they reach correct
answers, the underlying reasoning may be flawed, undermining trust in
high-stakes scenarios. To mitigate this issue, we introduce VeriCoT, a
neuro-symbolic method that extracts and verifies formal logical arguments from
CoT reasoning. VeriCoT formalizes each CoT reasoning step into first-order
logic and identifies premises that ground the argument in source context,
commonsense knowledge, or prior reasoning steps. The symbolic representation
enables automated solvers to verify logical validity while the NL premises
allow humans and systems to identify ungrounded or fallacious reasoning steps.
Experiments on the ProofWriter, LegalBench, and BioASQ datasets show VeriCoT
effectively identifies flawed reasoning, and serves as a strong predictor of
final answer correctness. We also leverage VeriCoT's verification signal for
(1) inference-time self-reflection, (2) supervised fine-tuning (SFT) on
VeriCoT-distilled datasets and (3) preference fine-tuning (PFT) with direct
preference optimization (DPO) using verification-based pairwise rewards,
further improving reasoning validity and accuracy.

</details>


<div id='cs.ET'></div>

# cs.ET [[Back]](#toc)

### [389] [OpenMENA: An Open-Source Memristor Interfacing and Compute Board for Neuromorphic Edge-AI Applications](https://arxiv.org/abs/2511.03747)
*Ali Safa,Farida Mohsen,Zainab Ali,Bo Wang,Amine Bermak*

Main category: cs.ET

TL;DR: Open-MENA是一个完全开源的忆阻器内存加速器系统，用于实现节能的边缘AI，包括硬件接口、固件-软件栈以及用于权重编程和片上微调的VIPI方法。


<details>
  <summary>Details</summary>
Motivation: 为了实现节能的边缘AI，利用忆阻器交叉阵列实现内存内乘加运算和局部可塑性学习。

Method: 构建了一个包含可复现硬件接口、固件-软件栈和VIPI编程方法的忆阻器内存加速器系统（Open-MENA），并进行了数字识别和机器人避障任务的验证。

Result: 在数字识别任务中实现了从权重传输到片上自适应的完整流程，并在机器人避障任务中成功将定位输入映射到电机指令。

Conclusion: Open-MENA作为首个完全开源的忆阻器接口系统，能够实现忆阻器驱动的边缘AI，并已成功应用于实际任务，为忆阻器相关研究提供了开源平台。

Abstract: Memristive crossbars enable in-memory multiply-accumulate and local
plasticity learning, offering a path to energy-efficient edge AI. To this end,
we present Open-MENA (Open Memristor-in-Memory Accelerator), which, to our
knowledge, is the first fully open memristor interfacing system integrating (i)
a reproducible hardware interface for memristor crossbars with mixed-signal
read-program-verify loops; (ii) a firmware-software stack with high-level APIs
for inference and on-device learning; and (iii) a Voltage-Incremental
Proportional-Integral (VIPI) method to program pre-trained weights into analog
conductances, followed by chip-in-the-loop fine-tuning to mitigate device
non-idealities. OpenMENA is validated on digit recognition, demonstrating the
flow from weight transfer to on-device adaptation, and on a real-world robot
obstacle-avoidance task, where the memristor-based model learns to map
localization inputs to motor commands. OpenMENA is released as open source to
democratize memristor-enabled edge-AI research.

</details>


### [390] [Implementation of transformer-based LLMs with large-scale optoelectronic neurons on a CMOS image sensor platform](https://arxiv.org/abs/2511.04136)
*Neil Na,Chih-Hao Cheng,Shou-Chen Hsu,Che-Fu Liang,Chung-Chih Lin,Nathaniel Y. Na,Andrew I. Shieh,Erik Chen,Haisheng Rong,Richard A. Soref*

Main category: cs.ET

TL;DR: 该论文提出并分析了在商用CMOS图像传感器（CIS）平台上，使用新型大规模光电器件（OENs）实现Transformer模型（现代LLM的核心）。


<details>
  <summary>Details</summary>
Motivation: 云端部署LLM和AI应用将导致能源消耗呈指数级增长，需要更节能的解决方案。

Method: 利用CMOS图像传感器平台构建大规模光电器件（OENs），并集成到尺寸为2cm x 3cm的芯片上，用于实现Transformer模型推理。

Result: 在40nm CMOS工艺下，实现了1750亿参数GPT-3模型的推理，速度达到12.6 POPS，能效高达74 TOPS/W，面积效率为19 TOPS/mm²，均超越现有数字电子器件约两个数量级。同时，研究了量化格式和硬件误差的影响，结果表明影响很小。

Conclusion: 提出了一个实用且新颖的光电模拟神经网络处理单元（NPU）的实现路径，可作为现有数字处理单元的补充。

Abstract: The recent rapid deployment of datacenter infrastructures for performing
large language models (LLMs) and related artificial intelligence (AI)
applications in the clouds is predicted to incur an exponentially growing
energy consumption in the near-term future. In this paper, we propose and
analyze the implementation of the transformer model, which is the cornerstone
of the modern LLMs, with novel large-scale optoelectronic neurons (OENs)
constructed over the commercially available complementary
metal-oxide-semiconductor (CMOS) image sensor (CIS) platform. With all of the
required optoelectronic devices and electronic circuits integrated in a chiplet
only about 2 cm by 3 cm in size, 175 billon parameters in the case of GPT-3 are
shown to perform inference at an unprecedented speed of 12.6 POPS using only a
40 nm CMOS process node, along with a high power efficiency of 74 TOPS/W and a
high area efficiency of 19 TOPS/mm2, both surpassing the related digital
electronics by roughly two orders of magnitude. The influence of the
quantization formats and the hardware induced errors are numerically
investigated, and are shown to have a minimal impact. Our study presents a new
yet practical path toward analog neural processing units (NPUs) to complement
existing digital processing units.

</details>


<div id='cs.NE'></div>

# cs.NE [[Back]](#toc)

### [391] [Evolutionary Optimization Trumps Adam Optimization on Embedding Space Exploration](https://arxiv.org/abs/2511.03913)
*Domício Pereira Neto,João Correia,Penousal Machado*

Main category: cs.NE

TL;DR: 本研究探讨了使用进化优化方法sep-CMA-ES来优化Stable Diffusion XL Turbo的提示嵌入向量，并与Adam优化器进行了比较，发现在美学和提示对齐方面sep-CMA-ES表现更优。


<details>
  <summary>Details</summary>
Motivation: 为了解决深度生成模型（尤其是扩散模型）难以控制和优化以实现特定目标的问题，本研究旨在研究进化优化方法在嵌入空间探索方面的性能。

Method: 本研究将一种名为分离协方差矩阵自适应进化策略（sep-CMA-ES）的进化优化方法应用于Stable Diffusion XL Turbo的提示嵌入向量，并将其与广泛使用的自适应矩估计（Adam）优化器进行比较。使用LAION Aesthetic Predictor V2和CLIPScore的加权组合作为适应度函数来评估生成图像的质量，该函数允许在视觉吸引力和提示遵循度之间进行灵活的权衡。

Result: 在Parti Prompts (P2) 数据集的子集上进行实验，结果表明sep-CMA-ES在美学和对齐指标上持续优于Adam。

Conclusion: 进化方法sep-CMA-ES为扩散模型提供了一种高效、无梯度的优化方式，在无需进行微调的情况下提高了可控性。本研究强调了进化方法在深度生成模型嵌入空间探索中的潜力，并指出了未来的研究方向。

Abstract: Deep generative models, especially diffusion architectures, have transformed
image generation; however, they are challenging to control and optimize for
specific goals without expensive retraining. Embedding Space Exploration,
especially with Evolutionary Algorithms (EAs), has been shown to be a promising
method for optimizing image generation, particularly within Diffusion Models.
Therefore, in this work, we study the performance of an evolutionary
optimization method, namely Separable Covariance Matrix Adaptation Evolution
Strategy (sep-CMA-ES), against the widely adopted Adaptive Moment Estimation
(Adam), applied to Stable Diffusion XL Turbo's prompt embedding vector. The
evaluation of images combines the LAION Aesthetic Predictor V2 with CLIPScore
into a weighted fitness function, allowing flexible trade-offs between visual
appeal and adherence to prompts. Experiments on a subset of the Parti Prompts
(P2) dataset showcase that sep-CMA-ES consistently yields superior improvements
in aesthetic and alignment metrics in comparison to Adam. Results indicate that
the evolutionary method provides efficient, gradient-free optimization for
diffusion models, enhancing controllability without the need for fine-tuning.
This study emphasizes the potential of evolutionary methods for embedding space
exploration of deep generative models and outlines future research directions.

</details>


### [392] [A Reinforced Evolution-Based Approach to Multi-Resource Load Balancing](https://arxiv.org/abs/2511.04183)
*Leszek Sliwko*

Main category: cs.NE

TL;DR: 该研究提出了一种改进的遗传算法来解决 d-资源系统优化问题，以克服传统遗传算法在严格可行性约束下的局限性。


<details>
  <summary>Details</summary>
Motivation: 经典的进化策略在这种情况下并不奏效，因为所研究的问题具有非常严格的可行性函数。因此，需要一种改进的策略来处理这种复杂性。

Method: 提出了一种增强的遗传方法，并对标准遗传例程进行了一些修改和调整，例如引入了一个类似于生物随机遗传漂移的迁移算子。

Result: 该方法通过引入迁移算子等修改，成功地优化了 d-资源系统。

Conclusion: 增强的遗传方法，特别是通过引入模拟遗传漂移的迁移算子，可以有效地解决具有严格可行性约束的 d-资源系统优化问题。

Abstract: This paper presents a reinforced genetic approach to a defined d-resource
system optimization problem. The classical evolution schema was ineffective due
to a very strict feasibility function in the studied problem. Hence, the
presented strategy has introduced several modifications and adaptations to
standard genetic routines, e.g.: a migration operator which is an analogy to
the biological random genetic drift.

</details>


### [393] [Neural Computation Without Slots: Steps Towards Biologically Plausible Memory and Attention in Natural and Artificial Intelligence](https://arxiv.org/abs/2511.04593)
*Shaunak Bhandarkar,James L. McClelland*

Main category: cs.NE

TL;DR: 大脑可能没有存储模式的专用“槽”，但可以通过基于神经元连接权重存储信息来模仿基于槽的计算。


<details>
  <summary>Details</summary>
Motivation: 探索生物学上合理的大脑记忆机制，并借鉴现代语言模型中基于槽的计算的成功。

Method: 提出了一种称为 K-winner MHN 的方法，该方法使用稀疏神经元集合的重叠权重来存储记忆，并扩展了现代 Hopfield 网络（MHN）以支持长序列处理。

Result: K-winner MHN 在持续学习中比标准 MHN 表现出更好的旧记忆保留能力。此外，MHN 的扩展能够处理长序列并进行反向错误传播，从而在功能上与基于槽的计算相媲美。

Conclusion: 提出的模型为理解生物学上合理机制如何实现类似人类的计算能力提供了基础，而这些能力是之前的模型所无法实现的。

Abstract: Many models used in artificial intelligence and cognitive science rely on
multi-element patterns stored in "slots" - dedicated storage locations - in a
digital computer. As biological brains likely lack slots, we consider how they
might achieve similar functional outcomes without them by building on the
neurally-inspired modern Hopfield network (MHN; Krotov & Hopfield, 2021), which
stores patterns in the connection weights of an individual neuron. We propose
extensions of this approach to increase its biological plausibility as a model
of memory and to capture an important advantage of slot-based computation in
contemporary language models. For memory, neuroscience research suggests that
the weights of overlapping sparse ensembles of neurons, rather than a dedicated
individual neuron, are used to store a memory. We introduce the K-winner MHN,
extending the approach to ensembles, and find that within a continual learning
regime, the ensemble-based MHN exhibits greater retention of older memories, as
measured by the graded sensitivity measure d', than a standard (one-neuron)
MHN. Next, we consider the powerful use of slot-based memory in contemporary
language models. These models use slots to store long sequences of past inputs
and their learned encodings, supporting later predictions and allowing error
signals to be transported backward in time to adjust weights underlying the
learned encodings of these past inputs. Inspired by these models' successes, we
show how the MHN can be extended to capture both of these important functional
outcomes. Collectively, our modeling approaches constitute steps towards
understanding how biologically plausible mechanisms can support computations
that have enabled AI systems to capture human-like abilities that no prior
models have been able to achieve.

</details>


<div id='cs.SI'></div>

# cs.SI [[Back]](#toc)

### [394] [Advancing Equitable AI: Evaluating Cultural Expressiveness in LLMs for Latin American Contexts](https://arxiv.org/abs/2511.04090)
*Brigitte A. Mora-Reyes,Jennifer A. Drewyor,Abel A. Reyes-Angulo*

Main category: cs.SI

TL;DR: AI系统在拉丁美洲的代表性存在偏见，部分原因是数据集中缺乏当地的语言和文化背景。本研究提出了一种新的数据集和评估方法，以解决这一问题。


<details>
  <summary>Details</summary>
Motivation: 现有AI系统的数据集和语言偏向于经济发达地区，导致对拉丁美洲等经济欠发达地区的代表性不足。这加剧了AI的偏见，并将拉丁美洲的观点置于西方视角之下。

Method: 创建了一个包含拉丁美洲历史和社会政治背景的文化意识数据集。使用新提出的“文化表现力”指标，结合统计检验和语言分析，评估了六个语言模型在测试文化背景意识方面的表现。

Result: 研究发现，一些语言模型能更好地捕捉拉丁美洲的观点，而另一些模型则存在显著的情感不匹配（p < 0.001）。使用新数据集对Mistral-7B模型进行微调后，其文化表现力提高了42.9%。

Conclusion: 为了实现公平的AI发展，应优先考虑包含拉丁美洲历史、本土知识和多元语言的数据集，并采用以社区为中心的方法来放大边缘化的声音。

Abstract: Artificial intelligence (AI) systems often reflect biases from economically
advanced regions, marginalizing contexts in economically developing regions
like Latin America due to imbalanced datasets. This paper examines AI
representations of diverse Latin American contexts, revealing disparities
between data from economically advanced and developing regions. We highlight
how the dominance of English over Spanish, Portuguese, and indigenous languages
such as Quechua and Nahuatl perpetuates biases, framing Latin American
perspectives through a Western lens. To address this, we introduce a culturally
aware dataset rooted in Latin American history and socio-political contexts,
challenging Eurocentric models. We evaluate six language models on questions
testing cultural context awareness, using a novel Cultural Expressiveness
metric, statistical tests, and linguistic analyses. Our findings show that some
models better capture Latin American perspectives, while others exhibit
significant sentiment misalignment (p < 0.001). Fine-tuning Mistral-7B with our
dataset improves its cultural expressiveness by 42.9%, advancing equitable AI
development. We advocate for equitable AI by prioritizing datasets that reflect
Latin American history, indigenous knowledge, and diverse languages, while
emphasizing community-centered approaches to amplify marginalized voices.

</details>


### [395] [Launch-Day Diffusion: Tracking Hacker News Impact on GitHub Stars for AI Tools](https://arxiv.org/abs/2511.04453)
*Obada Kraishan*

Main category: cs.SI

TL;DR: HN 曝光显著推动 AI/LLM 工具在 GitHub 上的星标增长，发布时间是关键因素。


<details>
  <summary>Details</summary>
Motivation: 量化像 Hacker News (HN) 这样的社交新闻平台对开源项目（尤其是 AI 和 LLM 工具）的即时影响仍然是一个挑战。

Method: 构建了一个可复现的演示系统，使用公开 API 分析了 2024-2025 年 138 个存储库的发布数据，并利用 Elastic Net 和 Gradient Boosting 等机器学习模型来识别病毒式增长的关键预测因子。

Result: 在 HN 曝光后的 24 小时、48 小时和一周内，存储库平均分别增加 121、189 和 289 个星标。发布时间被确定为关键因素，而“Show HN”标签在控制其他因素后并未显示出统计学优势。

Conclusion: 该系统可在标准硬件上快速运行，并提供可操作的见解，以了解发布动态，并且可以轻松扩展到其他平台。

Abstract: Social news platforms have become key launch outlets for open-source
projects, especially Hacker News (HN), though quantifying their immediate
impact remains challenging. This paper presents a reproducible demonstration
system that tracks how HN exposure translates into GitHub star growth for AI
and LLM tools. Built entirely on public APIs, our pipeline analyzes 138
repository launches from 2024-2025 and reveals substantial launch effects:
repositories gain an average of 121 stars within 24 hours, 189 stars within 48
hours, and 289 stars within a week of HN exposure. Through machine learning
models (Elastic Net) and non-linear approaches (Gradient Boosting), we identify
key predictors of viral growth. Posting timing appears as key factor--launching
at optimal hours can mean hundreds of additional stars--while the "Show HN" tag
shows no statistical advantage after controlling for other factors. The
demonstration completes in under five minutes on standard hardware,
automatically collecting data, training models, and generating visualizations
through single-file scripts. This makes our findings immediately reproducible
and the framework easily be extended to other platforms, providing both
researchers and developers with actionable insights into launch dynamics.

</details>
