<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 124]
- [cs.CL](#cs.CL) [Total: 60]
- [cond-mat.mes-hall](#cond-mat.mes-hall) [Total: 7]
- [physics.app-ph](#physics.app-ph) [Total: 1]
- [cs.LG](#cs.LG) [Total: 125]
- [cs.GT](#cs.GT) [Total: 5]
- [cs.DS](#cs.DS) [Total: 4]
- [eess.SY](#eess.SY) [Total: 22]
- [cs.GR](#cs.GR) [Total: 4]
- [cs.NE](#cs.NE) [Total: 1]
- [cs.ET](#cs.ET) [Total: 5]
- [cs.DC](#cs.DC) [Total: 8]
- [cs.SI](#cs.SI) [Total: 4]
- [cs.AI](#cs.AI) [Total: 48]
- [quant-ph](#quant-ph) [Total: 43]
- [cs.LO](#cs.LO) [Total: 2]
- [eess.SP](#eess.SP) [Total: 17]
- [cond-mat.mtrl-sci](#cond-mat.mtrl-sci) [Total: 32]
- [cs.RO](#cs.RO) [Total: 55]
- [cs.AR](#cs.AR) [Total: 2]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [PolypSeg-GradCAM: Towards Explainable Computer-Aided Gastrointestinal Disease Detection Using U-Net Based Segmentation and Grad-CAM Visualization on the Kvasir Dataset](https://arxiv.org/abs/2509.18159)
*Akwasi Asare,Ulas Bagci*

Main category: cs.CV

TL;DR: 该研究提出了一个名为PolypSeg-GradCAM的可解释深度学习框架，用于结肠镜图像中的息肉分割，结合了U-Net和Grad-CAM技术，实现了高分割精度（IoU为0.9257）和良好的可解释性，有助于提高AI辅助结肠镜检查的可靠性和信任度。


<details>
  <summary>Details</summary>
Motivation: 手动分割结直肠息肉耗时且易出错，而现有的深度学习方法可解释性不足，限制了其临床应用。因此，需要一种既能准确分割息肉又能提供可解释性的方法。

Method: 提出PolypSeg-GradCAM框架，将U-Net架构与Grad-CAM技术相结合，用于透明的息肉分割。在Kvasir-SEG数据集上进行训练和评估。

Result: 在Kvasir-SEG测试集上实现了0.9257的平均交并比（IoU），训练和验证集的Dice系数（F-score）均超过0.96。Grad-CAM可视化证明模型预测关注于临床相关区域。

Conclusion: PolypSeg-GradCAM通过结合高分割精度和可解释性，为开发可靠、可信的AI辅助结肠镜检查和改善结直肠癌早期预防提供了方向。

Abstract: Colorectal cancer (CRC) remains one of the leading causes of cancer-related
morbidity and mortality worldwide, with gastrointestinal (GI) polyps serving as
critical precursors according to the World Health Organization (WHO). Early and
accurate segmentation of polyps during colonoscopy is essential for reducing
CRC progression, yet manual delineation is labor-intensive and prone to
observer variability. Deep learning methods have demonstrated strong potential
for automated polyp analysis, but their limited interpretability remains a
barrier to clinical adoption. In this study, we present PolypSeg-GradCAM, an
explainable deep learning framework that integrates the U-Net architecture with
Gradient-weighted Class Activation Mapping (Grad-CAM) for transparent polyp
segmentation. The model was trained and evaluated on the Kvasir-SEG dataset of
1000 annotated endoscopic images. Experimental results demonstrate robust
segmentation performance, achieving a mean Intersection over Union (IoU) of
0.9257 on the test set and consistently high Dice coefficients (F-score > 0.96)
on training and validation sets. Grad-CAM visualizations further confirmed that
predictions were guided by clinically relevant regions, enhancing transparency
and trust in the model's decisions. By coupling high segmentation accuracy with
interpretability, PolypSeg-GradCAM represents a step toward reliable,
trustworthy AI-assisted colonoscopy and improved early colorectal cancer
prevention.

</details>


### [2] [PerceptronCARE: A Deep Learning-Based Intelligent Teleopthalmology Application for Diabetic Retinopathy Diagnosis](https://arxiv.org/abs/2509.18160)
*Akwasi Asare,Isaac Baffour Senkyire,Emmanuel Freeman,Simon Hilary Ayinedenaba Aluze-Ele,Kelvin Kwao*

Main category: cs.CV

TL;DR: PerceptronCARE是一个基于深度学习的远程眼科应用程序，使用视网膜图像自动检测糖尿病视网膜病变，准确率为85.4%，可用于实时筛查。


<details>
  <summary>Details</summary>
Motivation: 糖尿病视网膜病变是导致成年人失明的主要原因，并且是全球性的健康挑战，尤其是在服务欠缺的地区。本研究旨在开发一种能够自动检测糖尿病视网膜病变的远程眼科应用程序，以解决这一问题。

Method: 研究中使用了包括ResNet-18、EfficientNet-B0和SqueezeNet在内的多种卷积神经网络，以确定准确性和计算效率之间的最佳平衡。最终模型被用于疾病严重程度的分类。

Result: 最终模型在糖尿病视网膜病变检测中的准确率为85.4%，能够支持临床和远程医疗环境中的实时筛查。PerceptronCARE集成了云可扩展性、安全的数据管理和多用户框架。

Conclusion: 本研究强调了人工智能驱动的远程医疗解决方案在扩大糖尿病视网膜病变筛查范围方面的潜力，特别是在资源受限和偏远地区，有助于早期诊断、改善医患互动并降低医疗成本。

Abstract: Diabetic retinopathy is a leading cause of vision loss among adults and a
major global health challenge, particularly in underserved regions. This study
presents PerceptronCARE, a deep learning-based teleophthalmology application
designed for automated diabetic retinopathy detection using retinal images. The
system was developed and evaluated using multiple convolutional neural
networks, including ResNet-18, EfficientNet-B0, and SqueezeNet, to determine
the optimal balance between accuracy and computational efficiency. The final
model classifies disease severity with an accuracy of 85.4%, enabling real-time
screening in clinical and telemedicine settings. PerceptronCARE integrates
cloud-based scalability, secure patient data management, and a multi-user
framework, facilitating early diagnosis, improving doctor-patient interactions,
and reducing healthcare costs. This study highlights the potential of AI-driven
telemedicine solutions in expanding access to diabetic retinopathy screening,
particularly in remote and resource-constrained environments.

</details>


### [3] [Self Identity Mapping](https://arxiv.org/abs/2509.18165)
*Xiuding Cai,Yaoyao Zhu,Linjie Fu,Dong Miao,Yu Yao*

Main category: cs.CV

TL;DR: SIM是一种数据内在正则化框架，通过逆映射机制增强表示学习，减少信息损失，促进梯度流动。其计算效率版本$ho$SIM通过特征采样和投影实现，可即插即用，并能与其他正则化方法协同增效，在多种视觉和非视觉任务中均有提升。


<details>
  <summary>Details</summary>
Motivation: 深度学习中的正则化对于提高泛化能力和减少过拟合至关重要，但现有方法多依赖启发式，在不同场景下效果不稳定。

Method: 提出自身份映射（SIM）框架，利用逆映射机制（将输入从其变换后的输出中重建）来增强表示学习。计算效率版本$ho$SIM通过引入块级特征采样和基于投影的方法来降低复杂性。

Result: $ho$SIM在图像分类、少样本提示学习和域泛化任务上均取得了一致性提升，优于基线方法，并能与其他正则化方法协同增效。该方法在密集到密集任务（如语义分割、图像翻译）以及非视觉域（如音频分类、时间序列异常检测）中均有效。

Conclusion: SIM是一种有效且通用的正则化框架，通过重建输入来改善表示学习。其计算效率版本$ho$SIM易于集成，并能在多种任务中提升性能，同时保持语义信息。

Abstract: Regularization is essential in deep learning to enhance generalization and
mitigate overfitting. However, conventional techniques often rely on
heuristics, making them less reliable or effective across diverse settings. We
propose Self Identity Mapping (SIM), a simple yet effective, data-intrinsic
regularization framework that leverages an inverse mapping mechanism to enhance
representation learning. By reconstructing the input from its transformed
output, SIM reduces information loss during forward propagation and facilitates
smoother gradient flow. To address computational inefficiencies, We instantiate
SIM as $ \rho\text{SIM} $ by incorporating patch-level feature sampling and
projection-based method to reconstruct latent features, effectively lowering
complexity. As a model-agnostic, task-agnostic regularizer, SIM can be
seamlessly integrated as a plug-and-play module, making it applicable to
different network architectures and tasks.
  We extensively evaluate $\rho\text{SIM}$ across three tasks: image
classification, few-shot prompt learning, and domain generalization.
Experimental results show consistent improvements over baseline methods,
highlighting $\rho\text{SIM}$'s ability to enhance representation learning
across various tasks. We also demonstrate that $\rho\text{SIM}$ is orthogonal
to existing regularization methods, boosting their effectiveness. Moreover, our
results confirm that $\rho\text{SIM}$ effectively preserves semantic
information and enhances performance in dense-to-dense tasks, such as semantic
segmentation and image translation, as well as in non-visual domains including
audio classification and time series anomaly detection. The code is publicly
available at https://github.com/XiudingCai/SIM-pytorch.

</details>


### [4] [MAGIA: Sensing Per-Image Signals from Single-Round Averaged Gradients for Label-Inference-Free Gradient Inversion](https://arxiv.org/abs/2509.18170)
*Zhanting Zhou,Jinbo Wang,Zeqin Wu,Fengli Zhang*

Main category: cs.CV

TL;DR: MAGIA是一种新颖的、无需标签推理的基于动量的自适应梯度反演攻击方法，在单轮平均梯度SAG模型下，能够实现高保真多图像重建，克服了现有方法的局限性。


<details>
  <summary>Details</summary>
Motivation: 研究单轮平均梯度SAG模型下的梯度反演问题，解决单个样本线索纠缠在单一批量平均梯度中的挑战。

Method: 提出MAGIA框架，利用基于动量的自适应校正来反演梯度。MAGIA包含两个核心创新：1）闭式组合重缩放，以获得更优的优化界限；2）基于动量的批量损失和子集损失混合，以确保重建的鲁棒性。该方法通过探测随机数据子集来感知潜在的每张图像信号，且无需标签推理。

Result: 在大型批量场景下，MAGIA显著优于现有先进方法，实现了高保真多图像重建，而现有方法在此场景下失效。MAGIA的计算开销与标准求解器相当，并且不需要任何辅助信息。

Conclusion: MAGIA在单轮平均梯度SAG模型下，通过其创新的方法，能够有效地进行梯度反演，实现高保真多图像重建，且计算效率高，无需额外信息。

Abstract: We study gradient inversion in the challenging single round averaged gradient
SAG regime where per sample cues are entangled within a single batch mean
gradient. We introduce MAGIA a momentum based adaptive correction on gradient
inversion attack a novel label inference free framework that senses latent per
image signals by probing random data subsets. MAGIA objective integrates two
core innovations 1 a closed form combinatorial rescaling that creates a
provably tighter optimization bound and 2 a momentum based mixing of whole
batch and subset losses to ensure reconstruction robustness. Extensive
experiments demonstrate that MAGIA significantly outperforms advanced methods
achieving high fidelity multi image reconstruction in large batch scenarios
where prior works fail. This is all accomplished with a computational footprint
comparable to standard solvers and without requiring any auxiliary information.

</details>


### [5] [Baseer: A Vision-Language Model for Arabic Document-to-Markdown OCR](https://arxiv.org/abs/2509.18174)
*Khalil Hennara,Muhammad Hreden,Mohamed Motasim Hamed,Ahmad Bastati,Zeina Aldallal,Sara Chrouf,Safwan AlModhayan*

Main category: cs.CV

TL;DR: Baseer是一个针对阿拉伯文档OCR优化的视觉-语言模型，在Misraj-DocOCR基准上取得了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 阿拉伯文档OCR由于其连字脚本、多样化的字体、发音符号和从右到左的书写方向而具有挑战性。现有的多模态大语言模型（MLLM）在阿拉伯语上的表现有限。

Method: 利用包含合成和真实文档的大规模数据集，采用仅解码器的微调策略，对预训练的MLLM进行微调，并提出了Misraj-DocOCR基准。使用WER作为评估指标。

Result: Baseer显著优于现有的开源和商业解决方案，WER为0.25，在阿拉伯文档OCR领域创下新纪录。

Conclusion: 针对特定领域（如阿拉伯语）的通用MLLM进行适应性调整，可以为形态丰富的语言实现高精度OCR，并为该领域建立了一个强大的基准。

Abstract: Arabic document OCR remains a challenging task due to the language's cursive
script, diverse fonts, diacritics, and right-to-left orientation. While modern
Multimodal Large Language Models (MLLMs) have advanced document understanding
for high-resource languages, their performance on Arabic remains limited. In
this work, we introduce Baseer, a vision-language model fine- tuned
specifically for Arabic document OCR. Leveraging a large-scale dataset
combining synthetic and real-world documents, Baseer is trained using a
decoder-only fine-tuning strategy to adapt a pre-trained MLLM while preserving
general visual features. We also present Misraj-DocOCR, a high-quality,
expert-verified benchmark designed for rigorous evaluation of Arabic OCR
systems. Our experiments show that Baseer significantly outperforms existing
open-source and commercial solutions, achieving a WER of 0.25 and establishing
a new state-of-the-art in the domain of Arabic document OCR. Our results
highlight the benefits of domain-specific adaptation of general-purpose MLLMs
and establish a strong baseline for high-accuracy OCR on morphologically rich
languages like Arabic.

</details>


### [6] [Lyra: Generative 3D Scene Reconstruction via Video Diffusion Model Self-Distillation](https://arxiv.org/abs/2509.19296)
*Sherwin Bahmani,Tianchang Shen,Jiawei Ren,Jiahui Huang,Yifeng Jiang,Haithem Turki,Andrea Tagliasacchi,David B. Lindell,Zan Gojcic,Sanja Fidler,Huan Ling,Jun Gao,Xuanchi Ren*

Main category: cs.CV

TL;DR: 本文提出了一种自蒸馏框架，利用视频扩散模型生成3D高斯泼溅（3DGS）表示，无需多视图训练数据，可从文本或单图像生成静态和动态3D场景。


<details>
  <summary>Details</summary>
Motivation: 当前基于学习的3D重建方法需要大量真实世界的多视图数据，而视频扩散模型虽有强大的生成能力但仅限于2D，限制了其在需要导航和交互的AI领域（如机器人、自动驾驶）的应用。

Method: 提出一个自蒸馏框架，将视频扩散模型中的隐式3D知识蒸馏到显式3D高斯泼溅（3DGS）表示中。该框架在典型的RGB解码器基础上增加了一个3DGS解码器，并由RGB解码器的输出来监督，从而可以使用视频扩散模型生成的合成数据进行训练。

Result: 实验结果表明，该框架在静态和动态3D场景生成方面达到了最先进的性能，能够从文本提示或单张图像实时渲染3D场景，并能从单目视频生成动态3D场景。

Conclusion: 该自蒸馏框架成功地将视频扩散模型的3D知识提取到3DGS表示中，解决了多视图数据依赖问题，并实现了高质量的静态和动态3D场景生成，具有广泛的应用前景。

Abstract: The ability to generate virtual environments is crucial for applications
ranging from gaming to physical AI domains such as robotics, autonomous
driving, and industrial AI. Current learning-based 3D reconstruction methods
rely on the availability of captured real-world multi-view data, which is not
always readily available. Recent advancements in video diffusion models have
shown remarkable imagination capabilities, yet their 2D nature limits the
applications to simulation where a robot needs to navigate and interact with
the environment. In this paper, we propose a self-distillation framework that
aims to distill the implicit 3D knowledge in the video diffusion models into an
explicit 3D Gaussian Splatting (3DGS) representation, eliminating the need for
multi-view training data. Specifically, we augment the typical RGB decoder with
a 3DGS decoder, which is supervised by the output of the RGB decoder. In this
approach, the 3DGS decoder can be purely trained with synthetic data generated
by video diffusion models. At inference time, our model can synthesize 3D
scenes from either a text prompt or a single image for real-time rendering. Our
framework further extends to dynamic 3D scene generation from a monocular input
video. Experimental results show that our framework achieves state-of-the-art
performance in static and dynamic 3D scene generation.

</details>


### [7] [A Deep Learning Approach for Spatio-Temporal Forecasting of InSAR Ground Deformation in Eastern Ireland](https://arxiv.org/abs/2509.18176)
*Wendong Yao,Saeed Azadnejad,Binhua Huang,Shane Donohue,Soumyabrata Dev*

Main category: cs.CV

TL;DR: 提出了一种新的深度学习框架，将稀疏的InSAR测量数据转换为密集时空张量，并使用CNN-LSTM模型进行地面沉降预测，取得了比现有方法更好的效果。


<details>
  <summary>Details</summary>
Motivation: 城市基础设施稳定和地质灾害减缓需要监测地面沉降，但从稀疏的InSAR时间序列数据预测未来变形是一个重大挑战。

Method: 将稀疏的InSAR测量数据转换为密集时空张量，并设计和实现了一个混合卷积神经网络（CNN）和长短期记忆（LSTM）模型来学习空间模式和时间依赖性。

Result: 该模型在Sentinel-1数据上进行了测试，与Light Gradient Boosting Machine和LASSO回归等基线模型相比，提供了更准确、空间上更连贯的预测，并设立了新的性能基准。

Conclusion: 研究结果证实了时空深度学习在提供高分辨率变形预测方面的有效性和潜力。

Abstract: Monitoring ground displacement is crucial for urban infrastructure stability
and mitigating geological hazards. However, forecasting future deformation from
sparse Interferometric Synthetic Aperture Radar (InSAR) time-series data
remains a significant challenge. This paper introduces a novel deep learning
framework that transforms these sparse point measurements into a dense
spatio-temporal tensor. This methodological shift allows, for the first time,
the direct application of advanced computer vision architectures to this
forecasting problem. We design and implement a hybrid Convolutional Neural
Network and Long-Short Term Memory (CNN-LSTM) model, specifically engineered to
simultaneously learn spatial patterns and temporal dependencies from the
generated data tensor. The model's performance is benchmarked against powerful
machine learning baselines, Light Gradient Boosting Machine and LASSO
regression, using Sentinel-1 data from eastern Ireland. Results demonstrate
that the proposed architecture provides significantly more accurate and
spatially coherent forecasts, establishing a new performance benchmark for this
task. Furthermore, an interpretability analysis reveals that baseline models
often default to simplistic persistence patterns, highlighting the necessity of
our integrated spatio-temporal approach to capture the complex dynamics of
ground deformation. Our findings confirm the efficacy and potential of
spatio-temporal deep learning for high-resolution deformation forecasting.

</details>


### [8] [A Framework for Generating Artificial Datasets to Validate Absolute and Relative Position Concepts](https://arxiv.org/abs/2509.18177)
*George Corrêa de Araújo,Helena de Almeida Maia,Helio Pedrini*

Main category: cs.CV

TL;DR: Scrapbook框架生成数据集以探测AI模型对基本概念的理解，发现模型在物体识别方面表现良好，但在位置理解和约束问题方面存在挑战。


<details>
  <summary>Details</summary>
Motivation: 为了生成用于探测AI模型所学概念的大规模数据集，特别是针对物体识别、绝对/相对位置和属性识别等基本概念。

Method: 提出Scrapbook框架，该框架通过生成大量关于单个概念的问题，并采用广泛的语言变异性来生成数据集。

Result: 实验表明，当代模型在物体识别和枚举方面表现出熟练度，但在理解位置信息和处理附加约束的问题方面遇到挑战。MobileVLM-V2模型在答案一致性和合理错误答案方面表现出显著问题，其他模型则倾向于肯定性答案，并难以处理涉及几何形状和位置信息的问题。

Conclusion: Scrapbook框架为生成多样化、全面的数据集提供了一个有价值的工具，有助于系统地评估和提高AI模型的性能。

Abstract: In this paper, we present the Scrapbook framework, a novel methodology
designed to generate extensive datasets for probing the learned concepts of
artificial intelligence (AI) models. The framework focuses on fundamental
concepts such as object recognition, absolute and relative positions, and
attribute identification. By generating datasets with a large number of
questions about individual concepts and a wide linguistic variation, the
Scrapbook framework aims to validate the model's understanding of these basic
elements before tackling more complex tasks. Our experimental findings reveal
that, while contemporary models demonstrate proficiency in recognizing and
enumerating objects, they encounter challenges in comprehending positional
information and addressing inquiries with additional constraints. Specifically,
the MobileVLM-V2 model showed significant answer disagreements and plausible
wrong answers, while other models exhibited a bias toward affirmative answers
and struggled with questions involving geometric shapes and positional
information, indicating areas for improvement in understanding and consistency.
The proposed framework offers a valuable instrument for generating diverse and
comprehensive datasets, which can be utilized to systematically assess and
enhance the performance of AI models.

</details>


### [9] [The Describe-Then-Generate Bottleneck: How VLM Descriptions Alter Image Generation Outcomes](https://arxiv.org/abs/2509.18179)
*Sai Varun Kodathala,Rakesh Vunnam*

Main category: cs.CV

TL;DR: 视觉内容经过文本信息传递时会损失大量信息，影响多模态AI在创意工作流中的应用。


<details>
  <summary>Details</summary>
Motivation: 理解视觉-语言-视觉（vision-language-vision）管道中的信息损失对于评估多模态AI系统的局限性至关重要，但目前对视觉内容经过文本信息传递时的退化现象量化不足。

Method: 通过"描述-生成"（describe-then-generate）管道生成150对图像，并使用LPIPS、SSIM和颜色距离等现有指标，从感知、结构和色彩等维度衡量信息保留情况。

Result: 99.3%的样本出现明显感知退化，91.5%的样本出现显著结构信息损失。

Conclusion: "描述-生成"瓶颈是当前多模态系统中一个可衡量且持续存在的局限性。

Abstract: With the increasing integration of multimodal AI systems in creative
workflows, understanding information loss in vision-language-vision pipelines
has become important for evaluating system limitations. However, the
degradation that occurs when visual content passes through textual
intermediation remains poorly quantified. In this work, we provide empirical
analysis of the describe-then-generate bottleneck, where natural language
serves as an intermediate representation for visual information. We generated
150 image pairs through the describe-then-generate pipeline and applied
existing metrics (LPIPS, SSIM, and color distance) to measure information
preservation across perceptual, structural, and chromatic dimensions. Our
evaluation reveals that 99.3% of samples exhibit substantial perceptual
degradation and 91.5% demonstrate significant structural information loss,
providing empirical evidence that the describe-then-generate bottleneck
represents a measurable and consistent limitation in contemporary multimodal
systems.

</details>


### [10] [AI-Derived Structural Building Intelligence for Urban Resilience: An Application in Saint Vincent and the Grenadines](https://arxiv.org/abs/2509.18182)
*Isabelle Tingzon,Yoji Toriumi,Caroline Gevaert*

Main category: cs.CV

TL;DR: 该研究提出了一种利用人工智能从高分辨率卫星图像中自动推断屋顶属性（如屋顶坡度和屋顶材料）的工作流程，以解决小岛屿发展中国家（SIDS）缺乏详细建筑结构信息的问题，并以圣文森特和格林纳丁斯为案例研究。


<details>
  <summary>Details</summary>
Motivation: 小岛屿发展中国家（SIDS）缺乏详细的建筑结构信息，这阻碍了城市韧性规划和灾害风险减少。本研究旨在解决这一数据缺口。

Method: 研究人员比较了地理空间基础模型结合浅层分类器与微调深度学习模型在屋顶分类方面的效用，并评估了整合邻近SIDS的额外训练数据对模型性能的影响。

Result: 最佳模型在屋顶坡度和屋顶材料分类方面分别达到了0.88和0.83的F1分数。

Conclusion: 该工作旨在为SIDS提供新的能力，利用人工智能和地球观测（EO）数据，实现更高效、循证的城市治理，并结合当地能力建设。

Abstract: Detailed structural building information is used to estimate potential damage
from hazard events like cyclones, floods, and landslides, making them critical
for urban resilience planning and disaster risk reduction. However, such
information is often unavailable in many small island developing states (SIDS)
in climate-vulnerable regions like the Caribbean. To address this data gap, we
present an AI-driven workflow to automatically infer rooftop attributes from
high-resolution satellite imagery, with Saint Vincent and the Grenadines as our
case study. Here, we compare the utility of geospatial foundation models
combined with shallow classifiers against fine-tuned deep learning models for
rooftop classification. Furthermore, we assess the impact of incorporating
additional training data from neighboring SIDS to improve model performance.
Our best models achieve F1 scores of 0.88 and 0.83 for roof pitch and roof
material classification, respectively. Combined with local capacity building,
our work aims to provide SIDS with novel capabilities to harness AI and Earth
Observation (EO) data to enable more efficient, evidence-based urban
governance.

</details>


### [11] [VLA-LPAF: Lightweight Perspective-Adaptive Fusion for Vision-Language-Action to Enable More Unconstrained Robotic Manipulation](https://arxiv.org/abs/2509.18183)
*Jinyue Bian,Zhaoxing Zhang,Zhengyu Liang,Shiwei Zheng,Shengtao Zhang,Rong Shen,Chen Yang,Anzhou Hou*

Main category: cs.CV

TL;DR: VLA模型存在视角不一致的问题，提出VLA-LPAF模块，通过单视角微调并融合多视角信息，提升模型泛化能力，并在多个基准测试中取得显著效果。


<details>
  <summary>Details</summary>
Motivation: 现有VLA模型因视角不一致导致泛化能力受限。

Method: 提出轻量级模块VLA-LPAF，采用2D数据，通过单视角微调并融合多视角信息来解决视角不一致问题。

Result: 在CALVIN、LIBERO和自定义模拟基准上分别平均提高了8%、15%和30%的任务成功率，并在真实世界任务中展示了视图适应性。

Conclusion: VLA-LPAF模块能有效提升VLA模型的视角适应性和泛化能力。

Abstract: The Visual-Language-Action (VLA) models can follow text instructions
according to visual observations of the surrounding environment. This ability
to map multimodal inputs to actions is derived from the training of the VLA
model on extensive standard demonstrations. These visual observations captured
by third-personal global and in-wrist local cameras are inevitably varied in
number and perspective across different environments, resulting in significant
differences in the visual features. This perspective heterogeneity constrains
the generality of VLA models. In light of this, we first propose the
lightweight module VLA-LPAF to foster the perspective adaptivity of VLA models
using only 2D data. VLA-LPAF is finetuned using images from a single view and
fuses other multiview observations in the latent space, which effectively and
efficiently bridge the gap caused by perspective inconsistency. We instantiate
our VLA-LPAF framework with the VLA model RoboFlamingo to construct
RoboFlamingo-LPAF. Experiments show that RoboFlamingo-LPAF averagely achieves
around 8% task success rate improvement on CALVIN, 15% on LIBERO, and 30% on a
customized simulation benchmark. We also demonstrate the developed viewadaptive
characteristics of the proposed RoboFlamingo-LPAF through real-world tasks.

</details>


### [12] [URNet: Uncertainty-aware Refinement Network for Event-based Stereo Depth Estimation](https://arxiv.org/abs/2509.18184)
*Yifeng Cheng,Alois Knoll,Hu Cao*

Main category: cs.CV

TL;DR: URNet是一个用于事件立体测距的不确定性感知细化网络，通过局部-全局细化模块和基于KL散度的不确定性建模，在DSEC数据集上实现了优于现有技术的性能。


<details>
  <summary>Details</summary>
Motivation: 事件相机相比传统帧式相机具有高时间分辨率、高动态范围和低延迟等优势，因此需要开发适用于事件数据的深度估计方法。

Method: 提出了一种名为URNet的不确定性感知细化网络，该网络包含一个局部-全局细化模块，用于捕捉局部细节和全局上下文，并引入了基于KL散度的不确定性建模方法。

Result: URNet在DSEC数据集上进行了广泛的实验评估，在定性和定量评估中均表现出优于现有最先进方法的性能。

Conclusion: URNet通过其独特的局部-全局细化和不确定性建模方法，成功地提升了事件立体测距的精度和可靠性。

Abstract: Event cameras provide high temporal resolution, high dynamic range, and low
latency, offering significant advantages over conventional frame-based cameras.
In this work, we introduce an uncertainty-aware refinement network called URNet
for event-based stereo depth estimation. Our approach features a local-global
refinement module that effectively captures fine-grained local details and
long-range global context. Additionally, we introduce a Kullback-Leibler (KL)
divergence-based uncertainty modeling method to enhance prediction reliability.
Extensive experiments on the DSEC dataset demonstrate that URNet consistently
outperforms state-of-the-art (SOTA) methods in both qualitative and
quantitative evaluations.

</details>


### [13] [Visionerves: Automatic and Reproducible Hybrid AI for Peripheral Nervous System Recognition Applied to Endometriosis Cases](https://arxiv.org/abs/2509.18185)
*Giammarco La Barbera,Enzo Bonnot,Thomas Isla,Juan Pablo de la Plata,Joy-Rose Dunoyer de Segonzac,Jennifer Attali,Cécile Lozach,Alexandre Bellucci,Louis Marcellin,Laure Fournier,Sabine Sarnacki,Pietro Gori,Isabelle Bloch*

Main category: cs.CV

TL;DR: Visionerves是一个新的混合人工智能框架，用于从多梯度DWI和形态学MRI数据中识别周围神经系统，以解决内膜异位症中神经成像的挑战。


<details>
  <summary>Details</summary>
Motivation: 内膜异位症常常导致慢性盆腔疼痛和潜在的神经损伤，而对周围神经进行成像仍然是一个挑战。

Method: Visionerves采用混合人工智能框架，结合了深度学习模型进行自动解剖结构分割和符号空间推理进行神经束成像和识别。它通过模糊空间关系编码解剖知识，无需手动选择感兴趣区域（ROI）。

Result: 在10名患有（已确认或疑似）内膜异位症的女性的腰骶丛中，Visionerves相较于标准神经束成像技术，在Dice分数上提高了25%，空间误差减小到5毫米以内。

Conclusion: Visionerves提供了一种自动且可重复的方法，可以对神经进行详细分析，为内膜异位症相关神经病变以及其他涉及神经的病症的非侵入性诊断开辟了道路。

Abstract: Endometriosis often leads to chronic pelvic pain and possible nerve
involvement, yet imaging the peripheral nerves remains a challenge. We
introduce Visionerves, a novel hybrid AI framework for peripheral nervous
system recognition from multi-gradient DWI and morphological MRI data. Unlike
conventional tractography, Visionerves encodes anatomical knowledge through
fuzzy spatial relationships, removing the need for selection of manual ROIs.
The pipeline comprises two phases: (A) automatic segmentation of anatomical
structures using a deep learning model, and (B) tractography and nerve
recognition by symbolic spatial reasoning. Applied to the lumbosacral plexus in
10 women with (confirmed or suspected) endometriosis, Visionerves demonstrated
substantial improvements over standard tractography, with Dice score
improvements of up to 25% and spatial errors reduced to less than 5 mm. This
automatic and reproducible approach enables detailed nerve analysis and paves
the way for non-invasive diagnosis of endometriosis-related neuropathy, as well
as other conditions with nerve involvement.

</details>


### [14] [V-SenseDrive: A Privacy-Preserving Road Video and In-Vehicle Sensor Fusion Framework for Road Safety & Driver Behaviour Modelling](https://arxiv.org/abs/2509.18187)
*Muhammad Naveed,Nazia Perwaiz,Sidra Sultana,Mohaira Ahmad,Muhammad Moazam Fraz*

Main category: cs.CV

TL;DR: 该研究提出了V-SenseDrive数据集，这是第一个在巴基斯坦驾驶环境中收集的、注重隐私的多模态驾驶行为数据集，旨在解决现有数据集在代表性和隐私保护方面的不足。


<details>
  <summary>Details</summary>
Motivation: 目前缺乏能代表新兴经济体驾驶行为多样性且注重隐私的数据集，尤其是在巴基斯坦这样的国家，复杂的道路条件和驾驶习惯使得可靠的驾驶行为检测尤为重要，这对于提升道路安全、开发高级驾驶辅助系统（ADAS）以及支持保险和车队管理的数据驱动决策至关重要。

Method: V-SenseDrive数据集收集了结合智能手机传感器（惯性测量单元和GPS）数据以及道路视频数据，记录了正常、激进和危险三种驾驶行为。数据通过自定义的Android应用程序采集，包含高频率的加速度计、陀螺仪和GPS流以及连续视频，所有数据源精确同步。研究重点在于数据采集过程，包括参与者选择、驾驶场景、环境考虑和传感器视频同步技术。数据集分为原始、处理和语义三个层次。

Result: V-SenseDrive数据集提供了多模态的驾驶行为数据，包括传感器数据和视频，覆盖了不同类型的道路（城市主干道、次干道和高速公路），记录了三种驾驶行为（正常、激进和危险）。数据集结构化分层，便于未来研究。

Conclusion: V-SenseDrive数据集填补了全球驾驶行为数据集在代表巴基斯坦真实驾驶环境方面的空白，为开发情境感知和智能交通解决方案奠定了基础，有助于提升道路安全和ADAS的开发。

Abstract: Road traffic accidents remain a major public health challenge, particularly
in countries with heterogeneous road conditions, mixed traffic flow, and
variable driving discipline, such as Pakistan. Reliable detection of unsafe
driving behaviours is a prerequisite for improving road safety, enabling
advanced driver assistance systems (ADAS), and supporting data driven decisions
in insurance and fleet management. Most of existing datasets originate from the
developed countries with limited representation of the behavioural diversity
observed in emerging economies and the driver's face recording voilates the
privacy preservation. We present V-SenseDrive, the first privacy-preserving
multimodal driver behaviour dataset collected entirely within the Pakistani
driving environment. V-SenseDrive combines smartphone based inertial and GPS
sensor data with synchronized road facing video to record three target driving
behaviours (normal, aggressive, and risky) on multiple types of roads,
including urban arterials, secondary roads, and motorways. Data was gathered
using a custom Android application designed to capture high frequency
accelerometer, gyroscope, and GPS streams alongside continuous video, with all
sources precisely time aligned to enable multimodal analysis. The focus of this
work is on the data acquisition process, covering participant selection,
driving scenarios, environmental considerations, and sensor video
synchronization techniques. The dataset is structured into raw, processed, and
semantic layers, ensuring adaptability for future research in driver behaviour
classification, traffic safety analysis, and ADAS development. By representing
real world driving in Pakistan, V-SenseDrive fills a critical gap in the global
landscape of driver behaviour datasets and lays the groundwork for context
aware intelligent transportation solutions.

</details>


### [15] [Qianfan-VL: Domain-Enhanced Universal Vision-Language Models](https://arxiv.org/abs/2509.18189)
*Daxiang Dong,Mingming Zheng,Dong Xu,Bairong Zhuang,Wenyu Zhang,Chunhua Luo,Haoran Wang,Zijian Zhao,Jie Li,Yuxuan Li,Hanjun Zhong,Mengyue Liu,Jieting Chen,Shupeng Li,Lun Tian,Yaping Feng,Xin Li,Donggang Jiang,Yong Chen,Yehua Xu,Duohao Qin,Chen Feng,Dan Wang,Henghua Zhang,Jingjing Ha,Jinhui He,Yanfeng Zhai,Chengxin Zheng,Jiayi Mao,Jiacheng Chen,Ruchang Yao,Ziye Yuan,Jianmin Wu,Guangjun Xie,Dou Shen*

Main category: cs.CV

TL;DR: Qianfan-VL是一系列多模态大语言模型，参数量从3B到70B不等，通过创新的领域增强技术在多个基准测试中取得了最先进的性能，尤其在OCR和文档理解方面表现突出，并验证了百度AI基础设施的扩展效率。


<details>
  <summary>Details</summary>
Motivation: 开发能够增强领域特定能力并保持强大通用性能的多模态大语言模型，以满足多样化的企业部署场景。

Method: 采用多阶段渐进式训练和高精度数据合成流水线，并引入长链思维（long chain-of-thought）能力，在百度的昆仑800芯片上进行端到端训练。

Result: Qianfan-VL在通用基准测试上取得了与领先的开源模型相当的结果，在CCBench, SEEDBench IMG, ScienceQA和MMStar等基准测试上达到了最先进的性能。在OCR和文档理解方面，Qianfan-VL在OCRBench和DocVQA上获得了显著优势。其长链思维变体在数学推理（MathVista 78.6%）和逻辑推理任务上表现优异。同时，在5000颗芯片上训练单个任务实现了超过90%的扩展效率。

Conclusion: Qianfan-VL系列模型展示了一种有效的方法来开发领域增强的多模态模型，这些模型在通用和特定领域任务上均表现出色，并证明了大规模AI基础设施在训练SOTA多模态模型方面的能力和效率。

Abstract: We present Qianfan-VL, a series of multimodal large language models ranging
from 3B to 70B parameters, achieving state-of-the-art performance through
innovative domain enhancement techniques. Our approach employs multi-stage
progressive training and high-precision data synthesis pipelines, which prove
to be critical technologies for enhancing domain-specific capabilities while
maintaining strong general performance. Qianfan-VL achieves comparable results
to leading open-source models on general benchmarks, with state-of-the-art
performance on benchmarks such as CCBench, SEEDBench IMG, ScienceQA, and
MMStar. The domain enhancement strategy delivers significant advantages in OCR
and document understanding, validated on both public benchmarks (OCRBench 873,
DocVQA 94.75%) and in-house evaluations. Notably, Qianfan-VL-8B and 70B
variants incorporate long chain-of-thought capabilities, demonstrating superior
performance on mathematical reasoning (MathVista 78.6%) and logical inference
tasks. All models are trained entirely on Baidu's Kunlun P800 chips, validating
the capability of large-scale AI infrastructure to train SOTA-level multimodal
models with over 90% scaling efficiency on 5000 chips for a single task. This
work establishes an effective methodology for developing domain-enhanced
multimodal models suitable for diverse enterprise deployment scenarios.

</details>


### [16] [HazeFlow: Revisit Haze Physical Model as ODE and Non-Homogeneous Haze Generation for Real-World Dehazing](https://arxiv.org/abs/2509.18190)
*Junseong Shin,Seungwoo Chung,Yunjeong Yang,Tae Hyun Kim*

Main category: cs.CV

TL;DR: HazeFlow是一个基于ODE的框架，通过模拟大气散射模型来去除图像中的雾霾，并使用MCBM生成非均匀雾霾数据，以提高在真实世界场景中的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的深度学习去雾方法缺乏真实世界的配对训练数据，并且在处理真实世界的复杂性和多样化的雾霾模式方面存在不足。

Method: 提出了一种新颖的ODE（常微分方程）方法，将大气散射模型（ASM）重新表述为ODE。通过学习一个最优的ODE轨迹，将有雾图像映射到清晰图像。引入了一种使用马尔可夫链布朗运动（MCBM）的非均匀雾霾生成方法来解决配对真实世界数据稀缺的问题。

Result: HazeFlow在各种真实世界的去雾基准数据集上实现了最先进的性能。

Conclusion: HazeFlow通过将ASM重新表述为ODE并结合MCBM生成技术，有效解决了现有去雾方法的局限性，并在真实世界去雾任务中取得了显著的成果。

Abstract: Dehazing involves removing haze or fog from images to restore clarity and
improve visibility by estimating atmospheric scattering effects. While deep
learning methods show promise, the lack of paired real-world training data and
the resulting domain gap hinder generalization to real-world scenarios. In this
context, physics-grounded learning becomes crucial; however, traditional
methods based on the Atmospheric Scattering Model (ASM) often fall short in
handling real-world complexities and diverse haze patterns. To solve this
problem, we propose HazeFlow, a novel ODE-based framework that reformulates ASM
as an ordinary differential equation (ODE). Inspired by Rectified Flow (RF),
HazeFlow learns an optimal ODE trajectory to map hazy images to clean ones,
enhancing real-world dehazing performance with only a single inference step.
Additionally, we introduce a non-homogeneous haze generation method using
Markov Chain Brownian Motion (MCBM) to address the scarcity of paired
real-world data. By simulating realistic haze patterns through MCBM, we enhance
the adaptability of HazeFlow to diverse real-world scenarios. Through extensive
experiments, we demonstrate that HazeFlow achieves state-of-the-art performance
across various real-world dehazing benchmark datasets.

</details>


### [17] [TinyEcoWeedNet: Edge Efficient Real-Time Aerial Agricultural Weed Detection](https://arxiv.org/abs/2509.18193)
*Omar H. Khater,Abdul Jabbar Siddiqui,Aiman El-Maleh,M. Shamim Hossain*

Main category: cs.CV

TL;DR: 该论文提出了一种压缩的 EcoWeedNet 模型，用于在资源受限的边缘设备上进行农业应用，通过结构化通道剪枝、量化感知训练和 TensorRT 加速，显著减小了模型尺寸和计算量，同时提高了推理速度，并在 CottonWeedDet12 数据集上取得了优于其他模型的性能。


<details>
  <summary>Details</summary>
Motivation: 在农业领域部署深度学习模型面临边缘设备资源有限的挑战。

Method: 使用结构化通道剪枝、量化感知训练（QAT）和 NVIDIA 的 TensorRT 在 Jetson Orin Nano 上加速压缩 EcoWeedNet 模型。解决了剪枝复杂网络结构（具有残差捷径、注意力机制、连接和 CSP 块）的挑战。

Result: 模型尺寸减小高达 68.5%，计算量减少 3.2 GFLOPs，FP16 推理速度达到 184 FPS，比基线快 28.7%。在 CottonWeedDet12 数据集上，剪枝后的 EcoWeedNet（剪枝率为 39.5%）在精度、召回率和 mAP50 方面优于 YOLO11n 和 YOLO12n（剪枝率仅为 20%），分别达到 83.7%、77.5% 和 85.9%。

Conclusion: 压缩后的 EcoWeedNet 在精度和效率方面都表现出色，适用于精准农业。

Abstract: Deploying deep learning models in agriculture is difficult because edge
devices have limited resources, but this work presents a compressed version of
EcoWeedNet using structured channel pruning, quantization-aware training (QAT),
and acceleration with NVIDIA's TensorRT on the Jetson Orin Nano. Despite the
challenges of pruning complex architectures with residual shortcuts, attention
mechanisms, concatenations, and CSP blocks, the model size was reduced by up to
68.5% and computations by 3.2 GFLOPs, while inference speed reached 184 FPS at
FP16, 28.7% faster than the baseline. On the CottonWeedDet12 dataset, the
pruned EcoWeedNet with a 39.5% pruning ratio outperformed YOLO11n and YOLO12n
(with only 20% pruning), achieving 83.7% precision, 77.5% recall, and 85.9%
mAP50, proving it to be both efficient and effective for precision agriculture.

</details>


### [18] [Learning Contrastive Multimodal Fusion with Improved Modality Dropout for Disease Detection and Prediction](https://arxiv.org/abs/2509.18284)
*Yi Gu,Kuniaki Saito,Jiaxin Ma*

Main category: cs.CV

TL;DR: 本研究提出了一种新颖的多模态学习框架，通过结合增强的模态丢弃和对比学习来解决模态不平衡和缺失的问题，并在疾病检测和预测任务中取得了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 随着医学诊断越来越多地利用多模态数据，机器学习模型需要在保持对缺失模态的鲁棒性的同时，有效地融合异构信息。现有方法在处理模态不平衡和缺失等实际限制时面临挑战。

Method: 提出了一种新颖的多模态学习框架，该框架集成了增强的模态丢弃和对比学习。引入了可学习的模态令牌以改进缺失感知模态融合，并通过融合的多模态表示来增强传统的单模态对比目标。对包含视觉和表格模态的大规模临床数据集进行了验证。

Result: 在疾病检测和预测任务中取得了最先进的性能，尤其是在仅可用单一模态的挑战性和实际场景中。该方法还成功集成到最近的CT基础模型中，证明了其适应性。

Conclusion: 该方法在多模态学习方面具有有效性、效率和泛化性，为现实世界的临床应用提供了一个可扩展、低成本的解决方案。

Abstract: As medical diagnoses increasingly leverage multimodal data, machine learning
models are expected to effectively fuse heterogeneous information while
remaining robust to missing modalities. In this work, we propose a novel
multimodal learning framework that integrates enhanced modalities dropout and
contrastive learning to address real-world limitations such as modality
imbalance and missingness. Our approach introduces learnable modality tokens
for improving missingness-aware fusion of modalities and augments conventional
unimodal contrastive objectives with fused multimodal representations. We
validate our framework on large-scale clinical datasets for disease detection
and prediction tasks, encompassing both visual and tabular modalities.
Experimental results demonstrate that our method achieves state-of-the-art
performance, particularly in challenging and practical scenarios where only a
single modality is available. Furthermore, we show its adaptability through
successful integration with a recent CT foundation model. Our findings
highlight the effectiveness, efficiency, and generalizability of our approach
for multimodal learning, offering a scalable, low-cost solution with
significant potential for real-world clinical applications. The code is
available at https://github.com/omron-sinicx/medical-modality-dropout.

</details>


### [19] [Rethinking Pulmonary Embolism Segmentation: A Study of Current Approaches and Challenges with an Open Weight Model](https://arxiv.org/abs/2509.18308)
*Yixin Zhang,Ryan Chamberlain,Lawrance Ngo,Kevin Kramer,Maciej A. Mazurowski*

Main category: cs.CV

TL;DR: 本研究在一个包含490个CTPA扫描的内部数据集中，评估了九种广泛使用的CNN和ViT分割架构。研究发现3D U-Net表现最佳，3D模型和CNN模型比ViT模型更适合此任务。预训练可能损害分割性能，而远端栓子分割仍具挑战性。最佳模型达到了0.7131的Dice分数，并在公共数据集上进行了验证。


<details>
  <summary>Details</summary>
Motivation: 本研究旨在系统地评估和比较不同的分割模型（CNN和ViT家族）在肺栓塞（PE）分割任务上的性能，以找出最适合该任务的模型，并深入了解影响模型性能的因素。

Method: 研究人员在一个包含490个CTPA扫描的内部数据集中，对九种广泛使用的CNN和ViT分割架构（使用预训练或随机权重初始化）进行了统一的测试框架下的性能评估。

Result: 研究发现3D U-Net（带有ResNet编码器）在PE分割方面表现出色，3D模型比ViT模型更适合该任务。预训练（即使在大型PE数据集上）有时会损害分割性能，而CNN模型通常优于ViT模型。模型性能模式在相同数据训练下表现一致。中央和大型栓子分割准确率尚可，但远端栓子分割仍具挑战性。最佳模型实现了0.7131的平均Dice分数，并在60个内部测试扫描中检测到181个栓子，同时在公共数据集上验证了其泛化能力。

Conclusion: 3D U-Net是PE分割的有效架构，3D模型和CNN模型在该任务上表现优于ViT模型。预训练策略需要谨慎，并且远端栓子的分割仍然是一个难题，需要更高质量和更大规模的数据集。

Abstract: In this study, we curated a densely annotated in-house dataset comprising 490
CTPA scans. Using this dataset, we systematically evaluated nine widely used
segmentation architectures from both the CNN and Vision Transformer (ViT)
families, initialized with either pretrained or random weights, under a unified
testing framework as a performance audit. Our study leads to several important
observations: (1) 3D U-Net with a ResNet encoder remains a highly effective
architecture for PE segmentation; (2) 3D models are particularly well-suited to
this task given the morphological characteristics of emboli; (3) CNN-based
models generally yield superior performance compared to their ViT-based
counterparts in PE segmentation; (4) classification-based pretraining, even on
large PE datasets, can adversely impact segmentation performance compared to
training from scratch, suggesting that PE classification and segmentation may
rely on different sets of discriminative features; (5) different model
architectures show a highly consistent pattern of segmentation performance when
trained on the same data; and (6) while central and large emboli can be
segmented with satisfactory accuracy, distal emboli remain challenging due to
both task complexity and the scarcity of high-quality datasets. Besides these
findings, our best-performing model achieves a mean Dice score of 0.7131 for
segmentation. It detects 181 emboli with 49 false positives and 28 false
negatives from 60 in-house testing scans. Its generalizability is further
validated on public datasets.

</details>


### [20] [Improving Handshape Representations for Sign Language Processing: A Graph Neural Network Approach](https://arxiv.org/abs/2509.18309)
*Alessa Carbo,Eric Nalisnick*

Main category: cs.CV

TL;DR: 引入了一种新的图神经网络，通过分离手语中的时间动态和静态手形配置来解决手形识别的挑战，并建立了第一个结构化手形识别的基准。


<details>
  <summary>Details</summary>
Motivation: 目前大多数计算方法很少明确地对模型进行手形建模，这在一定程度上限制了识别精度和语言学分析的准确性。

Method: 本文介绍了一种新的图神经网络，将解剖学知识融入图结构，并结合对比学习方法，以应对手形识别中的关键挑战，包括细微的类间区分和时间变化。

Result: 本文提出的方法在37个手形类别上实现了46%的准确率，而基线方法的准确率为25%，建立了第一个结构化手形识别的基准。

Conclusion: 所提出的方法在手形识别方面取得了显著的成果，展示了其在处理细微的类间区分和时间变化方面的有效性，并为未来的研究奠定了基础。

Abstract: Handshapes serve a fundamental phonological role in signed languages, with
American Sign Language employing approximately 50 distinct shapes.
However,computational approaches rarely model handshapes explicitly, limiting
both recognition accuracy and linguistic analysis.We introduce a novel graph
neural network that separates temporal dynamics from static handshape
configurations. Our approach combines anatomically-informed graph structures
with contrastive learning to address key challenges in handshape recognition,
including subtle interclass distinctions and temporal variations. We establish
the first benchmark for structured handshape recognition in signing sequences,
achieving 46% accuracy across 37 handshape classes (with baseline methods
achieving 25%).

</details>


### [21] [Influence of Classification Task and Distribution Shift Type on OOD Detection in Fetal Ultrasound](https://arxiv.org/abs/2509.18326)
*Chun Kit Wong,Anders N. Christensen,Cosmin I. Bercea,Julia A. Schnabel,Martin G. Tolsgaard,Aasa Feragen*

Main category: cs.CV

TL;DR: 本研究通过实验发现，在胎儿超声图像的 OOD 检测任务中，分类任务的选择对模型的不确定性估计和 OOD 检测性能有显著影响，并且最佳任务选择取决于 OOD 样本的具体原因（图像特征或解剖特征偏移）。研究还强调，优秀的 OOD 检测能力并不直接等同于最优的弃权预测，因此在实际应用中需要根据具体需求来选择合适的分类任务和不确定性策略。


<details>
  <summary>Details</summary>
Motivation: 在胎儿超声图像分析中，可靠的 OOD 检测对于模型的安全部署至关重要，因为该领域面临图像异质性和不同临床环境的挑战。OOD 检测依赖于对分类模型不确定性的估计，而模型应在面对 OOD 样本时表现出更高的不确定性。

Method: 本研究通过在四种不同的分类任务上应用八种不确定性量化方法，来实验性地探究分类任务本身对 OOD 检测性能的影响。

Result: 实验结果表明，OOD 检测的性能在很大程度上取决于所选择的分类任务，并且最佳任务的选择与 ID-OOD 的定义标准（即 OOD 样本是由于图像特征偏移还是解剖特征偏移）相关。此外，研究发现，更好的 OOD 检测性能并不一定能保证最优的弃权预测。

Conclusion: 分类任务的选择对胎儿超声 OOD 检测的性能有重要影响，并且最佳任务的选择取决于 OOD 样本的类型。此外，OOD 检测性能与弃权预测性能之间可能存在不匹配，因此在医学图像分析等下游应用中，需要根据具体需求仔细选择分类任务和不确定性策略，以实现最佳的整体模型表现。

Abstract: Reliable out-of-distribution (OOD) detection is important for safe deployment
of deep learning models in fetal ultrasound amidst heterogeneous image
characteristics and clinical settings. OOD detection relies on estimating a
classification model's uncertainty, which should increase for OOD samples.
While existing research has largely focused on uncertainty quantification
methods, this work investigates the impact of the classification task itself.
Through experiments with eight uncertainty quantification methods across four
classification tasks, we demonstrate that OOD detection performance
significantly varies with the task, and that the best task depends on the
defined ID-OOD criteria; specifically, whether the OOD sample is due to: i) an
image characteristic shift or ii) an anatomical feature shift. Furthermore, we
reveal that superior OOD detection does not guarantee optimal abstained
prediction, underscoring the necessity to align task selection and uncertainty
strategies with the specific downstream application in medical image analysis.

</details>


### [22] [WaveletGaussian: Wavelet-domain Diffusion for Sparse-view 3D Gaussian Object Reconstruction](https://arxiv.org/abs/2509.19073)
*Hung Nguyen,Runfa Li,An Le,Truong Nguyen*

Main category: cs.CV

TL;DR: WaveletGaussian通过在小波域进行扩散，并结合轻量级网络和在线随机遮蔽策略，实现了高效的稀疏视图3D高斯重建，同时保持了竞争力的渲染质量并显著减少了训练时间。


<details>
  <summary>Details</summary>
Motivation: 现有的3D高斯泼溅方法在稀疏视图下性能下降，而通过扩散模型修复渲染图的方法计算成本高昂。

Method: 将扩散过程转移到小波域，仅在低频LL子带上进行扩散，高频子带则用轻量级网络优化；提出在线随机遮蔽策略来选择扩散微调的训练对。

Result: WaveletGaussian在Mip-NeRF 360和OmniObject3D数据集上实现了具有竞争力的渲染质量，同时大大缩短了训练时间。

Conclusion: WaveletGaussian是一种更有效的稀疏视图3D高斯对象重建框架，通过小波域扩散和优化的训练策略解决了现有方法的局限性。

Abstract: 3D Gaussian Splatting (3DGS) has become a powerful representation for
image-based object reconstruction, yet its performance drops sharply in
sparse-view settings. Prior works address this limitation by employing
diffusion models to repair corrupted renders, subsequently using them as pseudo
ground truths for later optimization. While effective, such approaches incur
heavy computation from the diffusion fine-tuning and repair steps. We present
WaveletGaussian, a framework for more efficient sparse-view 3D Gaussian object
reconstruction. Our key idea is to shift diffusion into the wavelet domain:
diffusion is applied only to the low-resolution LL subband, while
high-frequency subbands are refined with a lightweight network. We further
propose an efficient online random masking strategy to curate training pairs
for diffusion fine-tuning, replacing the commonly used, but inefficient,
leave-one-out strategy. Experiments across two benchmark datasets, Mip-NeRF 360
and OmniObject3D, show WaveletGaussian achieves competitive rendering quality
while substantially reducing training time.

</details>


### [23] [OrthoLoC: UAV 6-DoF Localization and Calibration Using Orthographic Geodata](https://arxiv.org/abs/2509.18350)
*Oussema Dhaouadi,Riccardo Marin,Johannes Meier,Jacques Kaiser,Daniel Cremers*

Main category: cs.CV

TL;DR: 本文提出了OrthoLoC数据集和AdHoP改进技术，用于在有限资源下进行高精度视觉定位。


<details>
  <summary>Details</summary>
Motivation: 现有的视觉定位系统在资源受限（无网络、无GPS）且需要高精度定位时，难以处理大型数据库或3D模型。现有的研究很少关注利用轻量级且易于获取的正射地理数据。

Method: 提出OrthoLoC数据集，包含来自德国和美国的16,425张UAV图像，解决了UAV图像与地理空间数据之间的域转移问题，并允许独立评估定位和校准性能。提出AdHoP技术，用于改进特征匹配。

Result: 通过全面评估，研究了域转移、数据分辨率和共同可见性对定位精度的影响。AdHoP技术可将匹配率提高95%，并将平移误差降低63%。

Conclusion: OrthoLoC数据集和AdHoP技术为在资源受限条件下进行高精度视觉定位提供了一个新的解决方案，并为该领域的研究提供了基准。

Abstract: Accurate visual localization from aerial views is a fundamental problem with
applications in mapping, large-area inspection, and search-and-rescue
operations. In many scenarios, these systems require high-precision
localization while operating with limited resources (e.g., no internet
connection or GNSS/GPS support), making large image databases or heavy 3D
models impractical. Surprisingly, little attention has been given to leveraging
orthographic geodata as an alternative paradigm, which is lightweight and
increasingly available through free releases by governmental authorities (e.g.,
the European Union). To fill this gap, we propose OrthoLoC, the first
large-scale dataset comprising 16,425 UAV images from Germany and the United
States with multiple modalities. The dataset addresses domain shifts between
UAV imagery and geospatial data. Its paired structure enables fair benchmarking
of existing solutions by decoupling image retrieval from feature matching,
allowing isolated evaluation of localization and calibration performance.
Through comprehensive evaluation, we examine the impact of domain shifts, data
resolutions, and covisibility on localization accuracy. Finally, we introduce a
refinement technique called AdHoP, which can be integrated with any feature
matcher, improving matching by up to 95% and reducing translation error by up
to 63%. The dataset and code are available at:
https://deepscenario.github.io/OrthoLoC.

</details>


### [24] [A Single Image Is All You Need: Zero-Shot Anomaly Localization Without Training Data](https://arxiv.org/abs/2509.18354)
*Mehrdad Moradi,Shengzhe Chen,Hao Yan,Kamran Paynabar*

Main category: cs.CV

TL;DR: 该方法提出了一种名为SSDnet的单张图像异常检测方法，利用卷积神经网络的归纳偏置，在无训练数据的情况下进行异常定位。


<details>
  <summary>Details</summary>
Motivation: 在许多真实场景中，图像异常检测缺乏训练数据或参考样本，因此需要一种仅依赖测试图像本身的单张图像异常定位方法。

Method: SSDnet利用卷积神经网络的归纳偏置，通过基于块的训练框架直接将输入图像输入网络进行自重构，并采用掩码、块打乱和高斯噪声来避免恒等映射，同时使用基于内积相似度的感知损失来捕捉结构信息。

Result: SSDnet在MVTec-AD数据集上实现了0.99的AUROC和0.60的AUPRC，在fabric数据集上实现了0.98的AUROC和0.67的AUPRC，优于现有方法。

Conclusion: SSDnet是一种无需外部训练数据、标签或参考，且鲁棒性强的单张图像异常定位方法。

Abstract: Anomaly detection in images is typically addressed by learning from
collections of training data or relying on reference samples. In many
real-world scenarios, however, such training data may be unavailable, and only
the test image itself is provided. We address this zero-shot setting by
proposing a single-image anomaly localization method that leverages the
inductive bias of convolutional neural networks, inspired by Deep Image Prior
(DIP). Our method is named Single Shot Decomposition Network (SSDnet). Our key
assumption is that natural images often exhibit unified textures and patterns,
and that anomalies manifest as localized deviations from these repetitive or
stochastic patterns. To learn the deep image prior, we design a patch-based
training framework where the input image is fed directly into the network for
self-reconstruction, rather than mapping random noise to the image as done in
DIP. To avoid the model simply learning an identity mapping, we apply masking,
patch shuffling, and small Gaussian noise. In addition, we use a perceptual
loss based on inner-product similarity to capture structure beyond pixel
fidelity. Our approach needs no external training data, labels, or references,
and remains robust in the presence of noise or missing pixels. SSDnet achieves
0.99 AUROC and 0.60 AUPRC on MVTec-AD and 0.98 AUROC and 0.67 AUPRC on the
fabric dataset, outperforming state-of-the-art methods. The implementation code
will be released at https://github.com/mehrdadmoradi124/SSDnet

</details>


### [25] [Align Where the Words Look: Cross-Attention-Guided Patch Alignment with Contrastive and Transport Regularization for Bengali Captioning](https://arxiv.org/abs/2509.18369)
*Riad Ahmed Anonto,Sardar Md. Saffat Zabin,M. Saifur Rahman*

Main category: cs.CV

TL;DR: 在低资源语言中，视觉-语言模型常常会生成与图像内容不符的文本，这是由于数据稀疏、翻译枢纽破坏对齐以及以英语为中心的预训练忽略了目标语言语义所致。我们提出了一个计算感知的孟加拉语图像描述生成流程，在 LaBSE 验证的英孟配对数据和 110k 双语提示合成图像上进行训练。


<details>
  <summary>Details</summary>
Motivation: 低资源语言的视觉-语言模型在图像描述方面存在对齐问题。

Method: 我们提出了一种包含 Patch-Alignment Loss (PAL)、InfoNCE 和 Sinkhorn-based OT 的三重损失目标函数，以对齐真实和合成图像的斑块描述符，并确保细粒度的斑块对应关系。模型使用冻结的 MaxViT 提取视觉特征，孟加拉语的 mBART-50 进行解码，并用一个轻量级桥梁连接视觉和语言模态。

Result: 该模型在 Flickr30k-1k 和 MSCOCO-1k 数据集上取得了显著的改进，BLEU-4 分数分别为 12.29 和 12.00，METEOR 分数分别为 27.98 和 28.14，BERTScore-F1 分数分别为 71.20 和 75.40，优于强基线模型，并将真实-合成质心距离缩小了 41%。

Conclusion: 我们提出的 PAL+InfoNCE+OT 协同方法有效解决了低资源语言的视觉-语言模型在图像描述中的对齐问题，提高了模型的性能。

Abstract: Grounding vision--language models in low-resource languages remains
challenging, as they often produce fluent text about the wrong objects. This
stems from scarce paired data, translation pivots that break alignment, and
English-centric pretraining that ignores target-language semantics. We address
this with a compute-aware Bengali captioning pipeline trained on LaBSE-verified
EN--BN pairs and 110k bilingual-prompted synthetic images. A frozen MaxViT
yields stable visual patches, a Bengali-native mBART-50 decodes, and a
lightweight bridge links the modalities. Our core novelty is a tri-loss
objective: Patch-Alignment Loss (PAL) aligns real and synthetic patch
descriptors using decoder cross-attention, InfoNCE enforces global
real--synthetic separation, and Sinkhorn-based OT ensures balanced fine-grained
patch correspondence. This PAL+InfoNCE+OT synergy improves grounding, reduces
spurious matches, and drives strong gains on Flickr30k-1k (BLEU-4 12.29, METEOR
27.98, BERTScore-F1 71.20) and MSCOCO-1k (BLEU-4 12.00, METEOR 28.14,
BERTScore-F1 75.40), outperforming strong CE baselines and narrowing the
real--synthetic centroid gap by 41%.

</details>


### [26] [TinyBEV: Cross Modal Knowledge Distillation for Efficient Multi Task Bird's Eye View Perception and Planning](https://arxiv.org/abs/2509.18372)
*Reeshad Khan,John Gauch*

Main category: cs.CV

TL;DR: TinyBEV是一个统一的、仅摄像头的BEV框架，能将大型教师模型的完整功能压缩到一个紧凑的、实时的学生模型中，参数量减少78%，速度提升5倍，同时仅需摄像头输入。


<details>
  <summary>Details</summary>
Motivation: 本研究旨在将大型、多模态的感知-规划模型的完整自动驾驶能力迁移到一个资源受限环境下的轻量级模型中，实现实时自主运行。

Method: 提出了一种模型无关的多阶段蒸馏策略，结合了特征级、输出级和自适应区域感知监督，将高容量的多模态知识有效迁移到轻量级BEV表示中。

Result: 在nuScenes数据集上，Tiny-BEV在检测任务上达到了39.0 mAP，在运动预测任务上达到了1.08 minADE，碰撞率为0.32，同时实现了11 FPS的实时运行速度，比UniAD快5倍。

Conclusion: TinyBEV证明了在资源受限的情况下，仍然可以保留完整的全栈驾驶智能，有效弥合了大型多模态感知-规划模型与可部署的实时自主系统之间的差距。

Abstract: We present TinyBEV, a unified, camera only Bird's Eye View (BEV) framework
that distills the full-stack capabilities of a large planning-oriented teacher
(UniAD [19]) into a compact, real-time student model. Unlike prior efficient
camera only baselines such as VAD[23] and VADv2[7], TinyBEV supports the
complete autonomy stack 3D detection, HD-map segmentation, motion forecasting,
occupancy prediction, and goal-directed planning within a streamlined
28M-parameter backbone, achieving a 78% reduction in parameters over UniAD
[19]. Our model-agnostic, multi-stage distillation strategy combines
feature-level, output-level, and adaptive region-aware supervision to
effectively transfer high-capacity multi-modal knowledge to a lightweight BEV
representation. On nuScenes[4], Tiny-BEV achieves 39.0 mAP for detection, 1.08
minADE for motion forecasting, and a 0.32 collision rate, while running 5x
faster (11 FPS) and requiring only camera input. These results demonstrate that
full-stack driving intelligence can be retained in resource-constrained
settings, bridging the gap between large-scale, multi-modal perception-planning
models and deployment-ready real-time autonomy.

</details>


### [27] [BlurBall: Joint Ball and Motion Blur Estimation for Table Tennis Ball Tracking](https://arxiv.org/abs/2509.18387)
*Thomas Gossard,Filip Radovic,Andreas Ziegler,Andrea Zell*

Main category: cs.CV

TL;DR: 本研究提出了一种新的运动模糊球类标注方法，并将标注中心置于模糊条纹的中心，同时显式标注模糊属性，并发布了一个新的乒乓球检测数据集，在多个模型上验证了该标注方法的有效性，并提出了一个名为BlurBall的模型，通过引入注意力机制等方法，在球类检测和轨迹预测方面取得了最先进的成果。


<details>
  <summary>Details</summary>
Motivation: 现有的运动模糊球类标注方法将标注点置于模糊条纹的前缘，忽略了与速度相关的运动线索，并引入了不对称性。

Method: 提出了一种新的标注策略，将球置于模糊条纹的中心，并显式标注模糊属性。基于此，发布了一个新的乒乓球检测数据集。提出了名为BlurBall的模型，该模型能够联合估计球的位置和运动模糊属性，并利用了跨帧输入的Squeeze-and-Excitation等注意力机制。

Result: 所提出的标注方法在各种模型上持续提高了检测性能。BlurBall模型取得了最先进的球类检测结果，并能实现更可靠的轨迹预测。

Conclusion: 利用运动模糊信息不仅可以提高检测精度，还能实现更可靠的轨迹预测，从而促进实时体育分析。

Abstract: Motion blur reduces the clarity of fast-moving objects, posing challenges for
detection systems, especially in racket sports, where balls often appear as
streaks rather than distinct points. Existing labeling conventions mark the
ball at the leading edge of the blur, introducing asymmetry and ignoring
valuable motion cues correlated with velocity. This paper introduces a new
labeling strategy that places the ball at the center of the blur streak and
explicitly annotates blur attributes. Using this convention, we release a new
table tennis ball detection dataset. We demonstrate that this labeling approach
consistently enhances detection performance across various models. Furthermore,
we introduce BlurBall, a model that jointly estimates ball position and motion
blur attributes. By incorporating attention mechanisms such as
Squeeze-and-Excitation over multi-frame inputs, we achieve state-of-the-art
results in ball detection. Leveraging blur not only improves detection accuracy
but also enables more reliable trajectory prediction, benefiting real-time
sports analytics.

</details>


### [28] [MVP: Motion Vector Propagation for Zero-Shot Video Object Detection](https://arxiv.org/abs/2509.18388)
*Binhua Huang,Ni Wang,Wendong Yao,Soumyabrata Dev*

Main category: cs.CV

TL;DR: 该研究提出了一种名为MVP的训练无关型视频目标检测流水线，通过在关键帧上调用OWLv2，并利用压缩域运动矢量在中间帧传播检测框，以降低计算成本，同时保持开放词汇检测能力。


<details>
  <summary>Details</summary>
Motivation: 在视频上运行开放词汇检测器虽然准确但计算成本高昂，因此需要一种更高效的方法。

Method: MVP流水线在固定间隔的关键帧上调用OWLv2，并利用压缩域运动矢量（MV）将检测框传播到中间帧。通过3x3网格聚合运动矢量进行平移和尺度更新，并辅以面积增长检查和可选的单类别切换。该方法不需要标签或微调，并可用于所有开放词汇检测器。

Result: 在ILSVRC2015-VID验证集上，MVP达到了mAP@0.5=0.609和mAP@[0.5:0.95]=0.316。在较低的IoU阈值下，其性能接近逐帧OWLv2-Large，表明粗略定位得到保留。与基于跟踪器的传播方法（MOSSE, KCF, CSRT）相比，MVP在mAP@0.5上表现更优。与需要标签训练的YOLOv12x相比，MVP在保持开放词汇和无标签特性的同时，取得了接近的性能。

Conclusion: 压缩域传播是一种实用的方法，可以在降低检测器调用频率的同时，在视频中保持强大的零样本检测能力。

Abstract: Running a large open-vocabulary (Open-vocab) detector on every video frame is
accurate but expensive. We introduce a training-free pipeline that invokes
OWLv2 only on fixed-interval keyframes and propagates detections to
intermediate frames using compressed-domain motion vectors (MV). A simple 3x3
grid aggregation of motion vectors provides translation and uniform-scale
updates, augmented with an area-growth check and an optional single-class
switch. The method requires no labels, no fine-tuning, and uses the same prompt
list for all open-vocabulary methods. On ILSVRC2015-VID (validation dataset),
our approach (MVP) attains mAP@0.5=0.609 and mAP@[0.5:0.95]=0.316. At loose
intersection-over-union (IoU) thresholds it remains close to framewise
OWLv2-Large (0.747/0.721 at 0.2/0.3 versus 0.784/0.780), reflecting that coarse
localization is largely preserved. Under the same keyframe schedule, MVP
outperforms tracker-based propagation (MOSSE, KCF, CSRT) at mAP@0.5. A
supervised reference (YOLOv12x) reaches 0.631 at mAP@0.5 but requires labeled
training, whereas our method remains label-free and open-vocabulary. These
results indicate that compressed-domain propagation is a practical way to
reduce detector invocations while keeping strong zero-shot coverage in videos.
Our code and models are available at https://github.com/microa/MVP.

</details>


### [29] [Improving the color accuracy of lighting estimation models](https://arxiv.org/abs/2509.18390)
*Zitian Zhang,Joshua Urban Davis,Jeanne Phuong Anh Vu,Jiangtao Kuang,Jean-François Lalonde*

Main category: cs.CV

TL;DR: 通过白平衡预处理提升单张图像HDR照明估计的颜色鲁棒性，无需重新训练现有模型。


<details>
  <summary>Details</summary>
Motivation: 为了实现增强现实（AR）应用中虚拟对象的逼真渲染和合成，需要从单张图像预测复杂的照明环境。然而，颜色鲁棒性是实现视觉逼真的关键且常被忽视的因素。

Method: 本研究不提出新的照明估计算法，而是探索简单的适应技术是否能增强现有模型的颜色准确性。使用包含多样化照明颜色的新型HDR数据集，系统地评估了几种适应策略，特别是基于预训练白平衡网络的输入图像预处理方法。

Result: 结果表明，使用预训练的白平衡网络对输入图像进行预处理，能够提高颜色鲁棒性，并且在所有测试场景中优于其他策略。此方法无需重新训练照明估计模型。

Conclusion: 使用预训练的白平衡网络对输入图像进行预处理是提升单张图像HDR照明估计颜色鲁棒性的一种有效且通用的方法，能够显著提高颜色准确性，且不影响现有模型的性能。

Abstract: Advances in high dynamic range (HDR) lighting estimation from a single image
have opened new possibilities for augmented reality (AR) applications.
Predicting complex lighting environments from a single input image allows for
the realistic rendering and compositing of virtual objects. In this work, we
investigate the color robustness of such methods -- an often overlooked yet
critical factor for achieving visual realism. While most evaluations conflate
color with other lighting attributes (e.g., intensity, direction), we isolate
color as the primary variable of interest. Rather than introducing a new
lighting estimation algorithm, we explore whether simple adaptation techniques
can enhance the color accuracy of existing models. Using a novel HDR dataset
featuring diverse lighting colors, we systematically evaluate several
adaptation strategies. Our results show that preprocessing the input image with
a pre-trained white balance network improves color robustness, outperforming
other strategies across all tested scenarios. Notably, this approach requires
no retraining of the lighting estimation model. We further validate the
generality of this finding by applying the technique to three state-of-the-art
lighting estimation methods from recent literature.

</details>


### [30] [Check Field Detection Agent (CFD-Agent) using Multimodal Large Language and Vision Language Models](https://arxiv.org/abs/2509.18405)
*Sourav Halder,Jinjun Tong,Xinyu Wu*

Main category: cs.CV

TL;DR: 本研究提出了一种创新的、无需训练的支票关键字段自动检测框架，利用视觉语言模型（VLM）和多模态大语言模型（MLLM）实现零样本检测，解决了传统方法对大规模标注数据的依赖问题，并为生成高质量标注数据提供了可能。


<details>
  <summary>Details</summary>
Motivation: 传统支票欺诈检测系统依赖于对签名、MICR行、金额、收款人、付款人等关键字段的准确识别，而这些字段的提取通常需要大量标注数据，但由于专有和隐私问题，此类数据难以获取。因此，需要一种无需大量标注数据即可进行支票关键字段检测的方法。

Method: 提出了一种新的、无需训练的框架，该框架结合了视觉语言模型（VLM）和多模态大语言模型（MLLM），实现了对支票关键字段的零样本（zero-shot）检测。

Result: 在包含110张不同格式和布局的支票的手工数据集上进行了定量评估，证明了该模型具有强大的性能和泛化能力。此外，该框架还可以作为生成高质量标注数据集的启动机制，从而为开发满足特定机构需求的专用实时对象检测模型奠定基础。

Conclusion: 本研究提出的无需训练的框架能够有效地实现支票关键字段的零样本检测，降低了在金融环境中部署此类系统的门槛，并为后续的专业模型开发提供了数据支持。

Abstract: Checks remain a foundational instrument in the financial ecosystem,
facilitating substantial transaction volumes across institutions. However,
their continued use also renders them a persistent target for fraud,
underscoring the importance of robust check fraud detection mechanisms. At the
core of such systems lies the accurate identification and localization of
critical fields, such as the signature, magnetic ink character recognition
(MICR) line, courtesy amount, legal amount, payee, and payer, which are
essential for subsequent verification against reference checks belonging to the
same customer. This field-level detection is traditionally dependent on object
detection models trained on large, diverse, and meticulously labeled datasets,
a resource that is scarce due to proprietary and privacy concerns. In this
paper, we introduce a novel, training-free framework for automated check field
detection, leveraging the power of a vision language model (VLM) in conjunction
with a multimodal large language model (MLLM). Our approach enables zero-shot
detection of check components, significantly lowering the barrier to deployment
in real-world financial settings. Quantitative evaluation of our model on a
hand-curated dataset of 110 checks spanning multiple formats and layouts
demonstrates strong performance and generalization capability. Furthermore,
this framework can serve as a bootstrap mechanism for generating high-quality
labeled datasets, enabling the development of specialized real-time object
detection models tailored to institutional needs.

</details>


### [31] [Losing the Plot: How VLM responses degrade on imperfect charts](https://arxiv.org/abs/2509.18425)
*Philip Wootaek Shin,Jack Sampson,Vijaykrishnan Narayanan,Andres Marquez,Mahantesh Halappanavar*

Main category: cs.CV

TL;DR: 现有图表理解基准假设图表清晰且问题基于事实，但现实世界图表常有扭曲且需要超越简单匹配的推理。本研究评估了 ChatGPT 4o、Claude Sonnet 4 和 Gemini 2.5 Pro 在受损或遮挡情况下的表现，发现性能显著下降，并出现价值虚构、趋势误解和实体混淆等幻觉。模型在恶劣环境下仍表现出过度自信。为解决此问题，研究提出了 CHART NOISe 数据集，包含图表损坏、遮挡和考试风格的多项选择题，并引入了提示反向不一致性。研究贡献包括：(1) 基准测试现有视觉语言模型，揭示其在图表推理方面的系统性漏洞；(2) 发布 CHART NOISe 数据集；(3) 提出质量过滤和遮挡检测等基线缓解策略。


<details>
  <summary>Details</summary>
Motivation: 现实世界图表常包含扭曲和遮挡，并且需要超越简单匹配的推理能力，而现有基准未能充分反映这些挑战。然而，视觉语言模型（VLMs）在处理此类数据时表现出性能下降和幻觉等问题。

Method: 在包含图表损坏、遮挡和考试风格选择题的 CHART NOISe 数据集上，评估了 ChatGPT 4o、Claude Sonnet 4 和 Gemini 2.5 Pro。引入了提示反向不一致性（prompt reverse inconsistency）作为一种评估方法。此外，还提出了质量过滤和遮挡检测等缓解策略。

Result: ChatGPT 4o、Claude Sonnet 4 和 Gemini 2.5 Pro 在处理受损或遮挡的图表时，性能出现显著下降，幻觉（如价值虚构、趋势误解、实体混淆）更加频繁。模型在这些恶劣设置下仍然过度自信，生成看似合理但无依据的解释。

Conclusion: 本研究通过基准测试现有 VLM，揭示了其在图表推理方面的系统性漏洞，并发布了首个包含损坏、遮挡和反向不一致性的 CHART NOISe 数据集。提出的缓解策略为提高图表理解的鲁棒性和可靠性提供了一个严格的测试平台。

Abstract: Vision language models (VLMs) show strong results on chart understanding, yet
existing benchmarks assume clean figures and fact based queries. Real world
charts often contain distortions and demand reasoning beyond simple matching.
We evaluate ChatGPT 4o, Claude Sonnet 4, and Gemini 2.5 Pro, finding sharp
performance drops under corruption or occlusion, with hallucinations such as
value fabrication, trend misinterpretation, and entity confusion becoming more
frequent. Models remain overconfident in degraded settings, generating
plausible but unsupported explanations.
  To address this gap, we introduce CHART NOISe(Chart Hallucinations, Answers,
and Reasoning Testing on Noisy and Occluded Input Selections), a dataset
combining chart corruptions, occlusions, and exam style multiple choice
questions inspired by Korea's CSAT English section. A key innovation is prompt
reverse inconsistency, where models contradict themselves when asked to confirm
versus deny the same statement. Our contributions are threefold: (1)
benchmarking state of the art VLMs, exposing systematic vulnerabilities in
chart reasoning; (2) releasing CHART NOISe, the first dataset unifying
corruption, occlusion, and reverse inconsistency; and (3) proposing baseline
mitigation strategies such as quality filtering and occlusion detection.
Together, these efforts establish a rigorous testbed for advancing robustness
and reliability in chart understanding.

</details>


### [32] [CPT-4DMR: Continuous sPatial-Temporal Representation for 4D-MRI Reconstruction](https://arxiv.org/abs/2509.18427)
*Xinyang Wu,Muheng Li,Xia Li,Orso Pusterla,Sairos Safai,Philippe C. Cattin,Antony J. Lomax,Ye Zhang*

Main category: cs.CV

TL;DR: 该研究提出了一种新的基于神经网络的四维MRI（4D-MRI）重建方法，用于放射治疗计划。该方法将呼吸运动视为由一维信号驱动的连续变形，取代了传统的离散分相方法，提高了效率并能准确捕捉不规则呼吸模式。


<details>
  <summary>Details</summary>
Motivation: 传统的4D-MRI重建方法在捕捉呼吸运动的时间变异性、工作流程复杂性和计算负荷方面存在挑战，因此需要一种更有效、更准确的方法。

Method: 提出了一种新的神经网络框架，包括空间解剖网络（SAN）和时间运动网络（TMN）。SAN编码连续的三维解剖表示，TMN在Transformer衍生的呼吸信号的指导下产生时间一致的形变场，以捕捉呼吸运动。

Result: 该方法在19名志愿者的数据集上进行了评估，证明了其能够准确捕捉规则和不规则的呼吸模式，同时保持血管和支气管的连续性，并具有高解剖保真度。与传统方法相比，总处理时间从约五小时缩短到15分钟的训练时间，并且每个三维体积的推理时间不到一秒。

Conclusion: 该框架能够以高效率和高保真度重建任意呼吸状态下的三维图像，在4D放射治疗计划和实时自适应治疗方面具有巨大潜力。

Abstract: Four-dimensional MRI (4D-MRI) is an promising technique for capturing
respiratory-induced motion in radiation therapy planning and delivery.
Conventional 4D reconstruction methods, which typically rely on phase binning
or separate template scans, struggle to capture temporal variability,
complicate workflows, and impose heavy computational loads. We introduce a
neural representation framework that considers respiratory motion as a smooth,
continuous deformation steered by a 1D surrogate signal, completely replacing
the conventional discrete sorting approach. The new method fuses motion
modeling with image reconstruction through two synergistic networks: the
Spatial Anatomy Network (SAN) encodes a continuous 3D anatomical
representation, while a Temporal Motion Network (TMN), guided by
Transformer-derived respiratory signals, produces temporally consistent
deformation fields. Evaluation using a free-breathing dataset of 19 volunteers
demonstrates that our template- and phase-free method accurately captures both
regular and irregular respiratory patterns, while preserving vessel and
bronchial continuity with high anatomical fidelity. The proposed method
significantly improves efficiency, reducing the total processing time from
approximately five hours required by conventional discrete sorting methods to
just 15 minutes of training. Furthermore, it enables inference of each 3D
volume in under one second. The framework accurately reconstructs 3D images at
any respiratory state, achieves superior performance compared to conventional
methods, and demonstrates strong potential for application in 4D radiation
therapy planning and real-time adaptive treatment.

</details>


### [33] [An Analysis of Kalman Filter based Object Tracking Methods for Fast-Moving Tiny Objects](https://arxiv.org/abs/2509.18451)
*Prithvi Raj Singh,Raju Gottumukkala,Anthony Maida*

Main category: cs.CV

TL;DR: 本文评估了五种先进的卡尔曼滤波器追踪方法（OCSORT、DeepOCSORT、ByteTrack、BoTSORT、StrongSORT）在壁球追踪任务上的性能，发现现有方法在处理快速移动、运动模式不可预测的小型物体时存在显著局限性。


<details>
  <summary>Details</summary>
Motivation: 精确追踪壁球等快速移动的小型物体是计算机视觉和体育机器人领域的一个挑战，现有卡尔曼滤波器方法在处理此类场景时性能下降，需要评估和改进。

Method: 使用包含10,000帧壁球图像的自定义数据集，评估了五种先进的卡尔曼滤波器追踪方法（OCSORT、DeepOCSORT、ByteTrack、BoTSORT、StrongSORT）在推理速度和每图像更新频率方面的性能，并分析了这些因素对追踪准确性和可靠性的影响。

Result: DeepOCSORT的平均轨迹漂移距离（ADE）最低（31.15像素），而ByteTrack的平均推理时间最短（26.6毫秒）。然而，所有方法都存在显著的追踪漂移（3-11厘米），表明现有方法在处理壁球这类快速移动、运动模式不可预测的物体时存在根本性限制，错误率比标准物体追踪基准高3-4倍。

Conclusion: 当前的卡尔曼滤波器追踪方法在处理快速移动、运动模式不可预测的小型物体（如壁球）方面存在显著局限性，需要开发专门的方法来改进性能。

Abstract: Unpredictable movement patterns and small visual mark make precise tracking
of fast-moving tiny objects like a racquetball one of the challenging problems
in computer vision. This challenge is particularly relevant for sport robotics
applications, where lightweight and accurate tracking systems can improve robot
perception and planning capabilities. While Kalman filter-based tracking
methods have shown success in general object tracking scenarios, their
performance degrades substantially when dealing with rapidly moving objects
that exhibit irregular bouncing behavior. In this study, we evaluate the
performance of five state-of-the-art Kalman filter-based tracking
methods-OCSORT, DeepOCSORT, ByteTrack, BoTSORT, and StrongSORT-using a custom
dataset containing 10,000 annotated racquetball frames captured at 720p-1280p
resolution. We focus our analysis on two critical performance factors:
inference speed and update frequency per image, examining how these parameters
affect tracking accuracy and reliability for fast-moving tiny objects. Our
experimental evaluation across four distinct scenarios reveals that DeepOCSORT
achieves the lowest tracking error with an average ADE of 31.15 pixels compared
to ByteTrack's 114.3 pixels, while ByteTrack demonstrates the fastest
processing at 26.6ms average inference time versus DeepOCSORT's 26.8ms.
However, our results show that all Kalman filter-based trackers exhibit
significant tracking drift with spatial errors ranging from 3-11cm (ADE values:
31-114 pixels), indicating fundamental limitations in handling the
unpredictable motion patterns of fast-moving tiny objects like racquetballs.
Our analysis demonstrates that current tracking approaches require substantial
improvements, with error rates 3-4x higher than standard object tracking
benchmarks, highlighting the need for specialized methodologies for fast-moving
tiny object tracking applications.

</details>


### [34] [MoCrop: Training Free Motion Guided Cropping for Efficient Video Action Recognition](https://arxiv.org/abs/2509.18473)
*Binhua Huang,Wendong Yao,Shaowu Chen,Guoxin Wang,Qingyuan Wang,Soumyabrata Dev*

Main category: cs.CV

TL;DR: MoCrop是一个运动感知的自适应裁剪模块，用于在压缩域中高效地进行视频动作识别。它利用H.264视频中的运动矢量来定位运动密集区域，并生成一个应用于所有I帧的单裁剪。该模块无需训练，不增加参数，可插入各种骨干网络。


<details>
  <summary>Details</summary>
Motivation: 提高视频动作识别在压缩域中的效率，减少计算量并/或提高准确率。

Method: 利用H.264视频中的运动矢量来定位运动密集区域，生成一个应用于所有I帧的单裁剪。该方法包括去噪与合并（DM）、蒙特卡洛采样（MCS）和通过运动密度子矩阵搜索进行自适应裁剪（AC）。

Result: 在UCF101数据集上，MoCrop使用ResNet-50骨干网络，在FLOPs相同的情况下提高了+3.5%的Top-1准确率（注意力设置），或者在FLOPs减少26.5%的情况下提高了+2.4%的Top-1准确率（效率设置）。在CoViAR数据集上，MoCrop达到了89.2%的Top-1准确率（原始成本），或在计算量从11.6 GFLOPs减少到8.5 GFLOPs的情况下达到了88.5%的Top-1准确率。在MobileNet-V3、EfficientNet-B1和Swin-B上也取得了持续的性能提升。

Conclusion: MoCrop是一个无需训练、无参数、通用性强的运动感知自适应裁剪模块，能够有效应用于压缩域视频动作识别，并能在提高准确率或减少计算量方面带来显著收益，适合实时部署。

Abstract: We introduce MoCrop, a motion-aware adaptive cropping module for efficient
video action recognition in the compressed domain. MoCrop uses motion vectors
that are available in H.264 video to locate motion-dense regions and produces a
single clip-level crop that is applied to all I-frames at inference. The module
is training free, adds no parameters, and can be plugged into diverse
backbones. A lightweight pipeline that includes denoising & merge (DM), Monte
Carlo sampling (MCS), and adaptive cropping (AC) via a motion-density submatrix
search yields robust crops with negligible overhead. On UCF101, MoCrop improves
accuracy or reduces compute. With ResNet-50, it delivers +3.5% Top-1 accuracy
at equal FLOPs (attention setting), or +2.4% Top-1 accuracy with 26.5% fewer
FLOPs (efficiency setting). Applied to CoViAR, it reaches 89.2% Top-1 accuracy
at the original cost and 88.5% Top-1 accuracy while reducing compute from 11.6
to 8.5 GFLOPs. Consistent gains on MobileNet-V3, EfficientNet-B1, and Swin-B
indicate strong generality and make MoCrop practical for real-time deployment
in the compressed domain. Our code and models are available at
https://github.com/microa/MoCrop.

</details>


### [35] [Codebook-Based Adaptive Feature Compression With Semantic Enhancement for Edge-Cloud Systems](https://arxiv.org/abs/2509.18481)
*Xinyu Wang,Zikun Zhou,Yingjian Li,Xin An,Hongpeng Wang*

Main category: cs.CV

TL;DR: CAFC-SE 通过向量量化 (VQ) 将连续视觉特征映射到离散索引，并在低比特率条件下保留更多信息性视觉模式，从而在速率和准确性方面优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有的图像编码方法在低比特率条件下表现不佳，因为它们会保留冗余细节或学习过度集中的符号分布。

Method: 提出了一种基于码本的自适应特征压缩框架，并进行了语义增强（CAFC-SE）。该框架在边缘通过向量量化（VQ）将连续视觉特征映射到离散索引，并选择性地将它们传输到云端。VQ 操作将特征向量投影到最近的视觉原语上。

Result: CAFC-SE 在低比特率条件下不太容易受到影响，并在速率和准确性方面表现出优越性。

Conclusion: CAFC-SE 是一种有效的图像编码方法，特别是在低比特率条件下，能够通过 VQ 映射保留更多信息性视觉模式。

Abstract: Coding images for machines with minimal bitrate and strong analysis
performance is key to effective edge-cloud systems. Several approaches deploy
an image codec and perform analysis on the reconstructed image. Other methods
compress intermediate features using entropy models and subsequently perform
analysis on the decoded features. Nevertheless, these methods both perform
poorly under low-bitrate conditions, as they retain many redundant details or
learn over-concentrated symbol distributions. In this paper, we propose a
Codebook-based Adaptive Feature Compression framework with Semantic
Enhancement, named CAFC-SE. It maps continuous visual features to discrete
indices with a codebook at the edge via Vector Quantization (VQ) and
selectively transmits them to the cloud. The VQ operation that projects feature
vectors onto the nearest visual primitives enables us to preserve more
informative visual patterns under low-bitrate conditions. Hence, CAFC-SE is
less vulnerable to low-bitrate conditions. Extensive experiments demonstrate
the superiority of our method in terms of rate and accuracy.

</details>


### [36] [MK-UNet: Multi-kernel Lightweight CNN for Medical Image Segmentation](https://arxiv.org/abs/2509.18493)
*Md Mostafijur Rahman,Radu Marculescu*

Main category: cs.CV

TL;DR: MK-UNet是一种超轻量级、多核U型CNN，用于医学图像分割，参数量少、计算效率高，并在多个基准测试中超越了SOTA方法。


<details>
  <summary>Details</summary>
Motivation: 开发一种超轻量级、计算效率高且分割精度优于现有方法的CNN模型，以满足资源受限环境（如即时诊断设备）下的医学图像分割需求。

Method: 设计了一种包含多核深度卷积（MKDC）和多种注意力机制（通道、空间、分组门控注意力）的MK-UNet网络，该网络能够处理多尺度空间关系并提取图像显著特征。

Result: MK-UNet在六个二元医学成像基准测试中，以极少的参数量（0.316M）和计算量（0.314G FLOPs），在分割精度上超越了TransUNet、UNeXt、MedT、CMUNeXt、EGE-UNet和Rolling-UNet等SOTA方法，特别是相对于TransUNet，参数量和计算量分别减少了333倍和123倍；相对于UNeXt，分割精度（DICE分数）提高了6.7%，参数量减少了4.7倍。

Conclusion: MK-UNet通过其轻量化的设计和优越的分割性能，为资源受限环境下的实时、高保真医学诊断提供了一个无与伦比的解决方案。

Abstract: In this paper, we introduce MK-UNet, a paradigm shift towards
ultra-lightweight, multi-kernel U-shaped CNNs tailored for medical image
segmentation. Central to MK-UNet is the multi-kernel depth-wise convolution
block (MKDC) we design to adeptly process images through multiple kernels,
while capturing complex multi-resolution spatial relationships. MK-UNet also
emphasizes the images salient features through sophisticated attention
mechanisms, including channel, spatial, and grouped gated attention. Our
MK-UNet network, with a modest computational footprint of only 0.316M
parameters and 0.314G FLOPs, represents not only a remarkably lightweight, but
also significantly improved segmentation solution that provides higher accuracy
over state-of-the-art (SOTA) methods across six binary medical imaging
benchmarks. Specifically, MK-UNet outperforms TransUNet in DICE score with
nearly 333$\times$ and 123$\times$ fewer parameters and FLOPs, respectively.
Similarly, when compared against UNeXt, MK-UNet exhibits superior segmentation
performance, improving the DICE score up to 6.7% margins while operating with
4.7$\times$ fewer #Params. Our MK-UNet also outperforms other recent
lightweight networks, such as MedT, CMUNeXt, EGE-UNet, and Rolling-UNet, with
much lower computational resources. This leap in performance, coupled with
drastic computational gains, positions MK-UNet as an unparalleled solution for
real-time, high-fidelity medical diagnostics in resource-limited settings, such
as point-of-care devices. Our implementation is available at
https://github.com/SLDGroup/MK-UNet.

</details>


### [37] [BridgeSplat: Bidirectionally Coupled CT and Non-Rigid Gaussian Splatting for Deformable Intraoperative Surgical Navigation](https://arxiv.org/abs/2509.18501)
*Maximilian Fehrentz,Alexander Winkler,Thomas Heiliger,Nazim Haouchine,Christian Heiliger,Nassir Navab*

Main category: cs.CV

TL;DR: BridgeSplat是一种新颖的可变形手术导航方法，通过将术中3D重建与术前CT数据相结合，以连接手术视频和患者体积数据。


<details>
  <summary>Details</summary>
Motivation: 将术中3D重建与术前CT数据相结合，以实现可变形手术导航，弥合手术视频和患者体积数据之间的差距。

Method: 通过光度监督联合优化3D高斯参数和网格变形。通过将每个高斯相对于其父网格三角形进行参数化，实现高斯与网格的对齐，并将变形传播回更新CT。

Result: 在内脏猪手术和模拟人类肝脏的合成数据上证明了BridgeSplat的有效性，并在单目RGB数据上实现了术前CT的合理变形。

Conclusion: BridgeSplat能够有效地实现可变形手术导航，并通过将术中3D重建与术前CT数据相结合，对术前CT进行合理变形。

Abstract: We introduce BridgeSplat, a novel approach for deformable surgical navigation
that couples intraoperative 3D reconstruction with preoperative CT data to
bridge the gap between surgical video and volumetric patient data. Our method
rigs 3D Gaussians to a CT mesh, enabling joint optimization of Gaussian
parameters and mesh deformation through photometric supervision. By
parametrizing each Gaussian relative to its parent mesh triangle, we enforce
alignment between Gaussians and mesh and obtain deformations that can be
propagated back to update the CT. We demonstrate BridgeSplat's effectiveness on
visceral pig surgeries and synthetic data of a human liver under simulation,
showing sensible deformations of the preoperative CT on monocular RGB data.
Code, data, and additional resources can be found at
https://maxfehrentz.github.io/ct-informed-splatting/ .

</details>


### [38] [Source-Free Domain Adaptive Semantic Segmentation of Remote Sensing Images with Diffusion-Guided Label Enrichment](https://arxiv.org/abs/2509.18502)
*Wenjie Liu,Hongmin Liu,Lixin Zhang,Bin Fan*

Main category: cs.CV

TL;DR: 研究了源域不可访问的图像语义分割中的无监督域适应（SFDA）问题，提出了一种名为 DGLE 的伪标签优化框架，利用扩散模型从少量高质量伪标签出发，生成高质量的完整伪标签集，以提升模型在目标域的性能。


<details>
  <summary>Details</summary>
Motivation: 现有源域无监督域适应（SFDA）研究有限，特别是利用自训练方法时，如何处理包含大量噪声的伪标签集以获得高质量伪标签是关键挑战。

Method: 提出了一种名为 Diffusion-Guided Label Enrichment (DGLE) 的伪标签优化框架。首先，通过置信度过滤和超分辨率增强实现伪标签融合，获得少量高质量的初始伪标签。然后，利用扩散模型的去噪和分布建模能力，将这些初始伪标签传播为完整高质量的伪标签集。

Result: DGLE 框架有效避免了直接优化整个伪标签集的困难，显著提高了伪标签的质量，从而增强了模型在目标域的性能。

Conclusion: DGLE 框架通过结合置信度过滤、超分辨率增强和扩散模型，有效地解决了 SFDA 中的伪标签质量问题，为自训练方法提供了更优的伪标签生成途径，并最终提升了模型在目标域的分割性能。

Abstract: Research on unsupervised domain adaptation (UDA) for semantic segmentation of
remote sensing images has been extensively conducted. However, research on how
to achieve domain adaptation in practical scenarios where source domain data is
inaccessible namely, source-free domain adaptation (SFDA) remains limited.
Self-training has been widely used in SFDA, which requires obtaining as many
high-quality pseudo-labels as possible to train models on target domain data.
Most existing methods optimize the entire pseudo-label set to obtain more
supervisory information. However, as pseudo-label sets often contain
substantial noise, simultaneously optimizing all labels is challenging. This
limitation undermines the effectiveness of optimization approaches and thus
restricts the performance of self-training. To address this, we propose a novel
pseudo-label optimization framework called Diffusion-Guided Label Enrichment
(DGLE), which starts from a few easily obtained high-quality pseudo-labels and
propagates them to a complete set of pseudo-labels while ensuring the quality
of newly generated labels. Firstly, a pseudo-label fusion method based on
confidence filtering and super-resolution enhancement is proposed, which
utilizes cross-validation of details and contextual information to obtain a
small number of high-quality pseudo-labels as initial seeds. Then, we leverage
the diffusion model to propagate incomplete seed pseudo-labels with irregular
distributions due to its strong denoising capability for randomly distributed
noise and powerful modeling capacity for complex distributions, thereby
generating complete and high-quality pseudo-labels. This method effectively
avoids the difficulty of directly optimizing the complete set of pseudo-labels,
significantly improves the quality of pseudo-labels, and thus enhances the
model's performance in the target domain.

</details>


### [39] [Hyperbolic Coarse-to-Fine Few-Shot Class-Incremental Learning](https://arxiv.org/abs/2509.18504)
*Jiaxin Dai,Xiang Xiang*

Main category: cs.CV

TL;DR: 提出将特征提取器嵌入双曲空间以提升少样本类增量学习的性能。


<details>
  <summary>Details</summary>
Motivation: 双曲空间在表示层级数据方面优于欧几里得空间，而现有方法在少样本类增量学习（C2FSCIL）任务中存在不足。

Method: 在C2FSCIL任务中，提出将特征提取器嵌入双曲空间（特别是庞加莱球模型），并结合双曲对比损失、双曲全连接层以及双曲空间中的最大熵分布来生成增强特征，以解决样本量有限导致的过拟合问题。

Result: 实验结果表明，该方法能够有效提升粗粒度和细粒度类别的准确率。

Conclusion: 将特征提取器嵌入双曲空间，并结合相应的双曲优化和数据增强技术，能够有效提升C2FSCIL任务的性能。

Abstract: In the field of machine learning, hyperbolic space demonstrates superior
representation capabilities for hierarchical data compared to conventional
Euclidean space. This work focuses on the Coarse-To-Fine Few-Shot
Class-Incremental Learning (C2FSCIL) task. Our study follows the Knowe
approach, which contrastively learns coarse class labels and subsequently
normalizes and freezes the classifier weights of learned fine classes in the
embedding space. To better interpret the "coarse-to-fine" paradigm, we propose
embedding the feature extractor into hyperbolic space. Specifically, we employ
the Poincar\'e ball model of hyperbolic space, enabling the feature extractor
to transform input images into feature vectors within the Poincar\'e ball
instead of Euclidean space. We further introduce hyperbolic contrastive loss
and hyperbolic fully-connected layers to facilitate model optimization and
classification in hyperbolic space. Additionally, to enhance performance under
few-shot conditions, we implement maximum entropy distribution in hyperbolic
space to estimate the probability distribution of fine-class feature vectors.
This allows generation of augmented features from the distribution to mitigate
overfitting during training with limited samples. Experiments on C2FSCIL
benchmarks show that our method effectively improves both coarse and fine class
accuracies.

</details>


### [40] [GeoRemover: Removing Objects and Their Causal Visual Artifacts](https://arxiv.org/abs/2509.18538)
*Zixin Zhu,Haoxiang Li,Xuelu Feng,He Wu,Chunming Qiao,Junsong Yuan*

Main category: cs.CV

TL;DR: 本研究提出了一种几何感知对象移除方法，通过解耦几何移除和外观渲染两个阶段，解决了现有方法无法有效去除阴影、反射等视觉线索，以及过度擦除等问题。


<details>
  <summary>Details</summary>
Motivation: 现有图像编辑方法在移除对象及其视觉线索（如阴影、反射）时存在不足，要么因严格的掩码对齐而无法去除未被掩码的视觉线索，要么因松散的掩码对齐而缺乏可控性并可能误删其他对象。这主要是由于忽略了对象几何与其视觉线索之间的因果关系。

Method: 提出了一种几何感知的两阶段框架：1. 几何移除：利用严格掩码对齐的监督，直接从几何信息（如深度图）中移除对象，实现具有强几何约束的结构感知编辑。2. 外观渲染：根据更新后的几何信息渲染逼真的RGB图像，将视觉线索的移除作为修改3D几何的内隐结果。引入了基于正负样本对的偏好驱动目标，以指导几何移除阶段的学习。

Result: 在两个流行基准测试中，该方法在移除对象及其相关视觉线索方面取得了最先进的性能。

Conclusion: 提出的几何感知两阶段框架能够有效且可控地移除对象及其因果视觉线索，解决了现有方法的局限性。

Abstract: Towards intelligent image editing, object removal should eliminate both the
target object and its causal visual artifacts, such as shadows and reflections.
However, existing image appearance-based methods either follow strictly
mask-aligned training and fail to remove these causal effects which are not
explicitly masked, or adopt loosely mask-aligned strategies that lack
controllability and may unintentionally over-erase other objects. We identify
that these limitations stem from ignoring the causal relationship between an
object's geometry presence and its visual effects. To address this limitation,
we propose a geometry-aware two-stage framework that decouples object removal
into (1) geometry removal and (2) appearance rendering. In the first stage, we
remove the object directly from the geometry (e.g., depth) using strictly
mask-aligned supervision, enabling structure-aware editing with strong
geometric constraints. In the second stage, we render a photorealistic RGB
image conditioned on the updated geometry, where causal visual effects are
considered implicitly as a result of the modified 3D geometry. To guide
learning in the geometry removal stage, we introduce a preference-driven
objective based on positive and negative sample pairs, encouraging the model to
remove objects as well as their causal visual artifacts while avoiding new
structural insertions. Extensive experiments demonstrate that our method
achieves state-of-the-art performance in removing both objects and their
associated artifacts on two popular benchmarks. The code is available at
https://github.com/buxiangzhiren/GeoRemover.

</details>


### [41] [SEGA: A Transferable Signed Ensemble Gaussian Black-Box Attack against No-Reference Image Quality Assessment Models](https://arxiv.org/abs/2509.18546)
*Yujia Liu,Dingquan Li,Tiejun Huang*

Main category: cs.CV

TL;DR: 本文提出了一种名为SEGA的可迁移高斯黑盒攻击方法，用于解决现有针对图像质量评价（NR-IQA）模型的黑盒攻击中存在的迁移性差的问题，并通过实验验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 现有针对NR-IQA模型的黑盒攻击方法存在迁移性差的问题，难以攻击未知的目标模型，因此需要提出一种可迁移性强的攻击方法。

Method: 提出了一种可迁移的符号集成高斯黑盒攻击（SEGA）方法。该方法通过对源模型的梯度进行高斯平滑并集成其平滑梯度来近似目标模型的梯度，并设计了一个特殊的扰动滤波器来去除不适宜的扰动，以保证对抗性扰动的不可感知性。

Result: 在CLIVE数据集上的实验结果表明，SEGA具有优越的可迁移性，能够成功实现基于迁移的黑盒攻击NR-IQA模型。

Conclusion: SEGA是一种有效且可迁移的黑盒攻击方法，能够成功攻击NR-IQA模型，并为设计更鲁棒的NR-IQA系统提供了指导。

Abstract: No-Reference Image Quality Assessment (NR-IQA) models play an important role
in various real-world applications. Recently, adversarial attacks against
NR-IQA models have attracted increasing attention, as they provide valuable
insights for revealing model vulnerabilities and guiding robust system design.
Some effective attacks have been proposed against NR-IQA models in white-box
settings, where the attacker has full access to the target model. However,
these attacks often suffer from poor transferability to unknown target models
in more realistic black-box scenarios, where the target model is inaccessible.
This work makes the first attempt to address the challenge of low
transferability in attacking NR-IQA models by proposing a transferable Signed
Ensemble Gaussian black-box Attack (SEGA). The main idea is to approximate the
gradient of the target model by applying Gaussian smoothing to source models
and ensembling their smoothed gradients. To ensure the imperceptibility of
adversarial perturbations, SEGA further removes inappropriate perturbations
using a specially designed perturbation filter mask. Experimental results on
the CLIVE dataset demonstrate the superior transferability of SEGA, validating
its effectiveness in enabling successful transfer-based black-box attacks
against NR-IQA models.

</details>


### [42] [HadaSmileNet: Hadamard fusion of handcrafted and deep-learning features for enhancing facial emotion recognition of genuine smiles](https://arxiv.org/abs/2509.18550)
*Mohammad Junayed Hasan,Nabeel Mohammed,Shafin Rahman,Philipp Koehn*

Main category: cs.CV

TL;DR: HadaSmileNet是一个新颖的特征融合框架，通过参数无关的乘法交互将基于Transformer的表征与生理学D-Markers直接集成，实现了计算效率和性能的最优。


<details>
  <summary>Details</summary>
Motivation: 区分真实和假笑表情具有重要的应用价值，但现有的多任务学习框架存在计算效率低的问题。

Method: 提出HadaSmileNet框架，通过参数无关的乘法交互（特别是Hadamard乘积）直接融合Transformer表征和D-Markers。

Result: 在四个基准数据集上取得了新的最先进结果（UvA-NEMO, MMI, SPOS, BBC），参数减少26%，训练简化，并增强了判别能力。

Conclusion: HadaSmileNet在效率和有效性方面表现出色，适合需要实时情感计算的多媒体数据挖掘应用。

Abstract: The distinction between genuine and posed emotions represents a fundamental
pattern recognition challenge with significant implications for data mining
applications in social sciences, healthcare, and human-computer interaction.
While recent multi-task learning frameworks have shown promise in combining
deep learning architectures with handcrafted D-Marker features for smile facial
emotion recognition, these approaches exhibit computational inefficiencies due
to auxiliary task supervision and complex loss balancing requirements. This
paper introduces HadaSmileNet, a novel feature fusion framework that directly
integrates transformer-based representations with physiologically grounded
D-Markers through parameter-free multiplicative interactions. Through
systematic evaluation of 15 fusion strategies, we demonstrate that Hadamard
multiplicative fusion achieves optimal performance by enabling direct feature
interactions while maintaining computational efficiency. The proposed approach
establishes new state-of-the-art results for deep learning methods across four
benchmark datasets: UvA-NEMO (88.7 percent, +0.8), MMI (99.7 percent), SPOS
(98.5 percent, +0.7), and BBC (100 percent, +5.0). Comprehensive computational
analysis reveals 26 percent parameter reduction and simplified training
compared to multi-task alternatives, while feature visualization demonstrates
enhanced discriminative power through direct domain knowledge integration. The
framework's efficiency and effectiveness make it particularly suitable for
practical deployment in multimedia data mining applications that require
real-time affective computing capabilities.

</details>


### [43] [Event-guided 3D Gaussian Splatting for Dynamic Human and Scene Reconstruction](https://arxiv.org/abs/2509.18566)
*Xiaoting Yin,Hao Shi,Kailun Yang,Jiajun Zhai,Shangwei Guo,Lin Wang,Kaiwei Wang*

Main category: cs.CV

TL;DR: 提出了一种新颖的事件引导式人景重建框架，利用3D高斯泼溅技术，仅用一个单目事件相机即可同时重建动态人类和静态场景。


<details>
  <summary>Details</summary>
Motivation: 现有的从单目视频中重建动态人类和静态场景的方法，特别是在快速运动的情况下，由于RGB帧的运动模糊而存在困难。事件相机具有微秒级的时间分辨率，在动态人类重建方面具有优势。

Method: 提出一个统一的3D高斯集合，该集合包含可学习的语义属性。只有被归类为人类的高斯点才进行变形以实现动画，而场景高斯点保持静态。为了对抗模糊，提出了一种事件引导损失，将连续渲染过程中模拟的亮度变化与事件流进行匹配，以提高快速移动区域的局部保真度。该方法无需外部人类掩码，并简化了对独立高斯集合的管理。

Result: 在ZJU-MoCap-Blur和MMHPSD-Blur两个基准数据集上，实现了最先进的人景重建效果，在PSNR/SSIM方面相较于强大的基线模型有显著提升，LPIPS降低，尤其在高速运动主体方面效果更佳。

Conclusion: 所提出的事件引导式人景重建框架，利用3D高斯泼溅技术，能够有效地解决单目事件相机在高速运动下的人类和场景重建问题，并在多个评估指标上取得了优于现有方法的性能。

Abstract: Reconstructing dynamic humans together with static scenes from monocular
videos remains difficult, especially under fast motion, where RGB frames suffer
from motion blur. Event cameras exhibit distinct advantages, e.g., microsecond
temporal resolution, making them a superior sensing choice for dynamic human
reconstruction. Accordingly, we present a novel event-guided human-scene
reconstruction framework that jointly models human and scene from a single
monocular event camera via 3D Gaussian Splatting. Specifically, a unified set
of 3D Gaussians carries a learnable semantic attribute; only Gaussians
classified as human undergo deformation for animation, while scene Gaussians
stay static. To combat blur, we propose an event-guided loss that matches
simulated brightness changes between consecutive renderings with the event
stream, improving local fidelity in fast-moving regions. Our approach removes
the need for external human masks and simplifies managing separate Gaussian
sets. On two benchmark datasets, ZJU-MoCap-Blur and MMHPSD-Blur, it delivers
state-of-the-art human-scene reconstruction, with notable gains over strong
baselines in PSNR/SSIM and reduced LPIPS, especially for high-speed subjects.

</details>


### [44] [Live-E2T: Real-time Threat Monitoring in Video via Deduplicated Event Reasoning and Chain-of-Thought](https://arxiv.org/abs/2509.18571)
*Yuhan Wang,Cheng Liu,Zihan Zhao,Weichao Wu*

Main category: cs.CV

TL;DR: Live-E2T框架通过结构化语义元组、在线事件去重和优化的大型语言模型，实现了实时威胁检测和可解释性。


<details>
  <summary>Details</summary>
Motivation: 现有的威胁监控方法在实时性和决策可解释性方面存在不足。

Method: 提出Live-E2T框架，包含三个机制：1. 将视频帧分解为结构化的人-物-交互-地点语义元组；2. 设计高效的在线事件去重和更新机制；3. 使用思维链策略微调大型语言模型，以进行事件序列推理和生成威胁评估报告。

Result: 在XD-Violence和UCF-Crime数据集上，Live-E2T在威胁检测准确性、实时效率和可解释性方面显著优于现有方法。

Conclusion: Live-E2T框架成功地解决了实时威胁监控中的实时性和可解释性挑战。

Abstract: Real-time threat monitoring identifies threatening behaviors in video streams
and provides reasoning and assessment of threat events through explanatory
text. However, prevailing methodologies, whether based on supervised learning
or generative models, struggle to concurrently satisfy the demanding
requirements of real-time performance and decision explainability. To bridge
this gap, we introduce Live-E2T, a novel framework that unifies these two
objectives through three synergistic mechanisms. First, we deconstruct video
frames into structured Human-Object-Interaction-Place semantic tuples. This
approach creates a compact, semantically focused representation, circumventing
the information degradation common in conventional feature compression. Second,
an efficient online event deduplication and updating mechanism is proposed to
filter spatio-temporal redundancies, ensuring the system's real time
responsiveness. Finally, we fine-tune a Large Language Model using a
Chain-of-Thought strategy, endow it with the capability for transparent and
logical reasoning over event sequences to produce coherent threat assessment
reports. Extensive experiments on benchmark datasets, including XD-Violence and
UCF-Crime, demonstrate that Live-E2T significantly outperforms state-of-the-art
methods in terms of threat detection accuracy, real-time efficiency, and the
crucial dimension of explainability.

</details>


### [45] [The Photographer Eye: Teaching Multimodal Large Language Models to See and Critique like Photographers](https://arxiv.org/abs/2509.18582)
*Daiqing Qi,Handong Zhao,Jing Shi,Simon Jenni,Yifei Fan,Franck Dernoncourt,Scott Cohen,Sheng Li*

Main category: cs.CV

TL;DR: 该研究提出了PhotoCritique数据集、PhotoEye模型和PhotoBench基准，以提升多模态大语言模型对图像美学的理解能力，解决了现有模型在处理需要专业摄影知识的真实世界场景时的局限性。


<details>
  <summary>Details</summary>
Motivation: 现有模型在理解图像美学方面存在不足，尤其是在需要摄影技术、后期处理知识等专业知识的真实世界场景中，它们常常无法提供深入的分析和描述，这与区分图像中的事实元素（如天空）和美学组成部分（如蓝色色块）的能力有关。

Method: 研究者提出了一个名为PhotoCritique的新数据集，该数据集来源于专业摄影师和爱好者的广泛讨论，具有规模大、专业性强和多样性高的特点。在此基础上，他们还提出了一个名为PhotoEye的新模型，该模型采用语言引导的多视图视觉融合机制来从多个角度理解图像美学。最后，他们提出了PhotoBench，一个全面且专业的视觉美学理解基准。

Result: 研究结果表明，在现有基准和新提出的PhotoBench基准上，PhotoEye模型相比于其他模型表现出了明显的优势，证明了其在图像美学理解方面的有效性。

Conclusion: 该研究通过引入新的数据集、模型和基准，显著提升了多模态大语言模型在图像美学理解方面的能力，尤其是在需要专业知识的场景中，为该领域的研究提供了新的方向和工具。

Abstract: While editing directly from life, photographers have found it too difficult
to see simultaneously both the blue and the sky. Photographer and curator,
Szarkowski insightfully revealed one of the notable gaps between general and
aesthetic visual understanding: while the former focuses on identifying the
factual element in an image (sky), the latter transcends such object
identification, viewing it instead as an aesthetic component--a pure color
block (blue). Such fundamental distinctions between general (detection,
localization, etc.) and aesthetic (color, lighting, composition, etc.) visual
understanding present a significant challenge for Multimodal Large Language
Models (MLLMs). Although some recent works have made initial explorations, they
are often limited to general and basic aesthetic commonsense. As a result, they
frequently fall short in real-world scenarios (Fig. 1), which require extensive
expertise--including photographic techniques, photo pre/post-processing
knowledge, and more, to provide a detailed analysis and description. To
fundamentally enhance the aesthetics understanding of MLLMs, we first introduce
a novel dataset, PhotoCritique, derived from extensive discussions among
professional photographers and enthusiasts, and characterized by the large
scale, expertise, and diversity. Then, to better learn visual aesthetics from
PhotoCritique, we furthur propose a novel model, PhotoEye, featuring a
languageguided multi-view vision fusion mechanism to understand image
aesthetics from multiple perspectives. Finally, we present a novel benchmark,
PhotoBench, a comprehensive and professional benchmark for aesthetic visual
understanding. On existing benchmarks and PhotoBench, our model demonstrates
clear advantages over existing models.

</details>


### [46] [Enhancing Video Object Segmentation in TrackRAD Using XMem Memory Network](https://arxiv.org/abs/2509.18591)
*Pengchao Deng,Shengqi Chen*

Main category: cs.CV

TL;DR: 该研究提出了一个用于实时MRI引导放疗的先进肿瘤分割框架，该框架利用XMem模型来处理长序列的cine-MRI数据，以实现高精度和实时性。虽然具体的实验数据丢失，但初步结果显示其分割性能合理，满足临床实时性要求。


<details>
  <summary>Details</summary>
Motivation: 为TrackRAD2025挑战提供一个先进的、能够实时分割肿瘤的MRI引导放疗框架，以提高癌症治疗的精确性和安全性。

Method: 利用XMem模型，一个带有记忆机制的架构，对长序列的cine-MRI数据进行肿瘤分割，并实时跟踪肿瘤运动。

Result: 由于实验记录丢失，无法提供精确的量化结果。但初步印象表明，基于XMem的框架分割性能合理，满足实时性要求。

Conclusion: 该框架有助于提高MRI引导放疗中肿瘤跟踪的精度，为癌症治疗的精确性和安全性做出贡献。

Abstract: This paper presents an advanced tumor segmentation framework for real-time
MRI-guided radiotherapy, designed for the TrackRAD2025 challenge. Our method
leverages the XMem model, a memory-augmented architecture, to segment tumors
across long cine-MRI sequences. The proposed system efficiently integrates
memory mechanisms to track tumor motion in real-time, achieving high
segmentation accuracy even under challenging conditions with limited annotated
data. Unfortunately, the detailed experimental records have been lost,
preventing us from reporting precise quantitative results at this stage.
Nevertheless, From our preliminary impressions during development, the
XMem-based framework demonstrated reasonable segmentation performance and
satisfied the clinical real-time requirement. Our work contributes to improving
the precision of tumor tracking during MRI-guided radiotherapy, which is
crucial for enhancing the accuracy and safety of cancer treatments.

</details>


### [47] [SSCM: A Spatial-Semantic Consistent Model for Multi-Contrast MRI Super-Resolution](https://arxiv.org/abs/2509.18593)
*Xiaoman Wu,Lubin Gan,Siying Wu,Jing Zhang,Yunwei Ou,Xiaoyan Sun*

Main category: cs.CV

TL;DR: MC-MRI SR旨在通过利用高分辨率参考图像来增强低分辨率图像的对比度，以缩短成像时间并提高成像效率，同时保留解剖细节。主要挑战在于维持空间-语义一致性，确保解剖结构在目标图像和参考图像之间存在结构差异和运动的情况下保持对齐和连贯。传统方法未能充分模拟空间-语义一致性，并且低估了频域信息的使用，导致粗粒度对齐不佳和高频细节恢复不足。在本文中，我们提出了一种空间-语义一致性模型（SSCM），它集成了动态空间变形模块用于对比度间空间对齐，语义感知令牌聚合块用于长距离语义一致性，以及空间-频率融合块用于精细结构恢复。在公共和私有数据集上的实验表明，SSCM在确保空间和语义上的一致性重建的同时，用更少的参数实现了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: MC-MRI SR 旨在提高成像效率并保留解剖细节，但传统方法在空间-语义一致性和频域信息利用方面存在不足。

Method: 提出了一种名为SSC（Spatial-Semantic Consistent Model）的模型，该模型包含三个关键模块：动态空间变形模块（用于对比度间空间对齐）、语义感知令牌聚合块（用于长距离语义一致性）和空间-频率融合块（用于精细结构恢复）。

Result: SSCM 在公共和私有数据集上实现了最先进的性能，参数更少，并确保了空间和语义上的一致性重建。

Conclusion: SSCM 能够有效解决 MC-MRI SR 中的空间-语义一致性挑战，并比传统方法具有更好的性能。

Abstract: Multi-contrast Magnetic Resonance Imaging super-resolution (MC-MRI SR) aims
to enhance low-resolution (LR) contrasts leveraging high-resolution (HR)
references, shortening acquisition time and improving imaging efficiency while
preserving anatomical details. The main challenge lies in maintaining
spatial-semantic consistency, ensuring anatomical structures remain
well-aligned and coherent despite structural discrepancies and motion between
the target and reference images. Conventional methods insufficiently model
spatial-semantic consistency and underuse frequency-domain information, which
leads to poor fine-grained alignment and inadequate recovery of high-frequency
details. In this paper, we propose the Spatial-Semantic Consistent Model
(SSCM), which integrates a Dynamic Spatial Warping Module for inter-contrast
spatial alignment, a Semantic-Aware Token Aggregation Block for long-range
semantic consistency, and a Spatial-Frequency Fusion Block for fine structure
restoration. Experiments on public and private datasets show that SSCM achieves
state-of-the-art performance with fewer parameters while ensuring spatially and
semantically consistent reconstructions.

</details>


### [48] [OraPO: Oracle-educated Reinforcement Learning for Data-efficient and Factual Radiology Report Generation](https://arxiv.org/abs/2509.18600)
*Zhuoxiao Chen,Hongyang Yu,Ying Xu,Yadan Luo,Long Duong,Yuan-Fang Li*

Main category: cs.CV

TL;DR: 该研究提出了一种名为OraPO的框架，结合FactS作为奖励，用于放射科报告生成（RRG），在数据和计算资源受限的情况下，实现了单阶段、仅强化学习的训练，并取得了新的SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 现有的放射科报告生成（RRG）方法通常需要多阶段训练和庞大的数据集及模型，训练成本高昂。本研究旨在提出一种在预算受限的情况下，能够高效解决RRG任务的框架。

Method: 提出OraPO框架，利用基于FactS的奖励。OraPO通过轻量级的oracle步骤，将强化学习（RL）探索中失败的案例转化为直接偏好监督，实现了单阶段、仅RL的训练。FactS通过提取原子临床事实并与地面真实标签进行推理检查，提供密集的、可解释的句子级奖励。

Result: OraPO和FactS框架显著提高了在临床上具有挑战性的病例的学习效率，在CheXpert Plus数据集上取得了新的SOTA性能（F1得分为0.341），同时训练数据量减少了2-3个数量级，使用的模型为小型基础视觉语言模型（VLM），硬件要求适中。

Conclusion: OraPO和FactS框架提供了一个紧凑且强大的解决方案，能够显著提高RRG任务的学习效率，尤其是在数据和计算资源有限的情况下，并在CheXpert Plus数据集上取得了领先的性能。

Abstract: Radiology report generation (RRG) aims to automatically produce clinically
faithful reports from chest X-ray images. Prevailing work typically follows a
scale-driven paradigm, by multi-stage training over large paired corpora and
oversized backbones, making pipelines highly data- and compute-intensive. In
this paper, we propose Oracle-educated GRPO {OraPO) with a FactScore-based
reward (FactS) to tackle the RRG task under constrained budgets. OraPO enables
single-stage, RL-only training by converting failed GRPO explorations on rare
or difficult studies into direct preference supervision via a lightweight
oracle step. FactS grounds learning in diagnostic evidence by extracting atomic
clinical facts and checking entailment against ground-truth labels, yielding
dense, interpretable sentence-level rewards. Together, OraPO and FactS create a
compact and powerful framework that significantly improves learning efficiency
on clinically challenging cases, setting the new SOTA performance on the
CheXpert Plus dataset (0.341 in F1) with 2--3 orders of magnitude less training
data using a small base VLM on modest hardware.

</details>


### [49] [Training-Free Multi-Style Fusion Through Reference-Based Adaptive Modulation](https://arxiv.org/abs/2509.18602)
*Xu Liu,Yibo Lu,Xinxian Wang,Xinyu Wu*

Main category: cs.CV

TL;DR: AMSF是一个创新的无训练框架，能够融合多种参考风格到扩散模型中，解决了现有方法只能接受单一风格和难以平衡多种风格影响的局限性。


<details>
  <summary>Details</summary>
Motivation: 现有基于参考图的方法在处理单一风格时存在局限，无法实现混合美学和扩展到更多风格，并且缺乏平衡多种风格影响的机制。

Method: AMSF通过一个语义令牌分解模块来编码所有风格图像和文本提示，该模块自适应地注入到冻结的扩散模型的每个交叉注意力层。一个相似度感知重加权模块在每个去噪步骤中重新校准分配给每个风格组件的注意力，从而实现无需微调或外部适配器的、平衡且用户可控的风格融合。

Result: AMSF在定性和定量评估中均表现出色，其多风格融合结果持续优于现有技术，并且其融合设计能够无缝扩展到两种或更多风格。

Conclusion: AMSF通过其新颖的融合设计，为扩散模型中的表达性多风格生成提供了实用的解决方案，能够生成平衡且用户可控的多风格融合图像。

Abstract: We propose Adaptive Multi-Style Fusion (AMSF), a reference-based
training-free framework that enables controllable fusion of multiple reference
styles in diffusion models. Most of the existing reference-based methods are
limited by (a) acceptance of only one style image, thus prohibiting hybrid
aesthetics and scalability to more styles, and (b) lack of a principled
mechanism to balance several stylistic influences. AMSF mitigates these
challenges by encoding all style images and textual hints with a semantic token
decomposition module that is adaptively injected into every cross-attention
layer of an frozen diffusion model. A similarity-aware re-weighting module then
recalibrates, at each denoising step, the attention allocated to every style
component, yielding balanced and user-controllable blends without any
fine-tuning or external adapters. Both qualitative and quantitative evaluations
show that AMSF produces multi-style fusion results that consistently outperform
the state-of-the-art approaches, while its fusion design scales seamlessly to
two or more styles. These capabilities position AMSF as a practical step toward
expressive multi-style generation in diffusion models.

</details>


### [50] [MLF-4DRCNet: Multi-Level Fusion with 4D Radar and Camera for 3D Object Detection in Autonomous Driving](https://arxiv.org/abs/2509.18613)
*Yuzhi Wu,Li Xiao,Jun Liu,Guangfeng Jiang,XiangGen Xia*

Main category: cs.CV

TL;DR: 该研究提出了MLF-4DRCNet，一种新颖的多层次融合4D毫米波雷达和摄像头图像的两阶段框架，用于3D目标检测，解决了现有方法忽略雷达点云稀疏性和几何不完整性的问题。


<details>
  <summary>Details</summary>
Motivation: 为了解决4D毫米波雷达点云稀疏、噪声大以及现有雷达-摄像头融合方法忽视雷达固有缺陷（如稀疏几何和仅限于粗略的场景级集成）的问题，本研究提出了一种新的融合方法。

Method: 提出了一种名为MLF-4DRCNet的新型两阶段框架，通过多层次融合4D雷达和摄像头图像来进行3D目标检测。该框架包含三个关键组件：增强雷达点编码器（ERPE）、分层场景融合池化（HSFP）和提案级融合增强（PLFE）。ERPE在点级别处理，通过提出的三注意力体素特征编码器将雷达点云与2D图像实例融合并编码为体素。HSFP在场景级别动态融合多尺度体素特征与2D图像特征，并对融合后的特征进行池化。PLFE在提案级别通过融合图像特征来优化区域提案，并与HSFP的池化特征进行集成。

Result: 在View-of-Delft (VoD) 和 TJ4DRadSet 数据集上的实验结果表明，MLF-4DRCNet 达到了最先进的性能，并且在VoD数据集上的性能与基于LiDAR的模型相当。

Conclusion: MLF-4DRCNet通过多层次融合（点、场景、提案级别）有效解决了4D毫米波雷达在3D目标检测中的挑战，并在标准数据集上取得了优异的性能，证明了其在自动驾驶感知领域的潜力。

Abstract: The emerging 4D millimeter-wave radar, measuring the range, azimuth,
elevation, and Doppler velocity of objects, is recognized for its
cost-effectiveness and robustness in autonomous driving. Nevertheless, its
point clouds exhibit significant sparsity and noise, restricting its standalone
application in 3D object detection. Recent 4D radar-camera fusion methods have
provided effective perception. Most existing approaches, however, adopt
explicit Bird's-Eye-View fusion paradigms originally designed for LiDAR-camera
fusion, neglecting radar's inherent drawbacks. Specifically, they overlook the
sparse and incomplete geometry of radar point clouds and restrict fusion to
coarse scene-level integration. To address these problems, we propose
MLF-4DRCNet, a novel two-stage framework for 3D object detection via
multi-level fusion of 4D radar and camera images. Our model incorporates the
point-, scene-, and proposal-level multi-modal information, enabling
comprehensive feature representation. It comprises three crucial components:
the Enhanced Radar Point Encoder (ERPE) module, the Hierarchical Scene Fusion
Pooling (HSFP) module, and the Proposal-Level Fusion Enhancement (PLFE) module.
Operating at the point-level, ERPE densities radar point clouds with 2D image
instances and encodes them into voxels via the proposed Triple-Attention Voxel
Feature Encoder. HSFP dynamically integrates multi-scale voxel features with 2D
image features using deformable attention to capture scene context and adopts
pooling to the fused features. PLFE refines region proposals by fusing image
features, and further integrates with the pooled features from HSFP.
Experimental results on the View-of-Delft (VoD) and TJ4DRadSet datasets
demonstrate that MLF-4DRCNet achieves the state-of-the-art performance.
Notably, it attains performance comparable to LiDAR-based models on the VoD
dataset.

</details>


### [51] [Prompt-Guided Dual Latent Steering for Inversion Problems](https://arxiv.org/abs/2509.18619)
*Yichen Wu,Xu Liu,Chenxuan Zhao,Xinyu Wu*

Main category: cs.CV

TL;DR: PDLS通过引入两个互补的“结构路径”和“语义路径”来解决扩散模型图像恢复中的结构保真度和语义准确性之间的平衡问题，通过最优控制理论和线性二次调节器（LQR）实现，无需昂贵的每图像优化，并在各种图像恢复任务中优于单隐变量基线。


<details>
  <summary>Details</summary>
Motivation: 现有方法在将损坏图像映射到扩散模型潜在空间时，难以平衡结构保真度和语义准确性，导致重建图像出现语义漂移、细节模糊或属性错误等问题。

Method: 提出一种名为“提示引导双重潜在向量引导”（PDLS）的框架，该框架基于具有稳定逆转路径的Rectified Flow模型，并将逆转过程分解为两条互补的路径：一条结构路径用于保留原始图像的完整性，一条由提示引导的语义路径。该框架将双重引导表述为最优控制问题，并通过线性二次调节器（LQR）推导出闭式解，该调节器在每一步动态地引导生成轨迹，以防止语义漂移并确保细节的保留。

Result: 在FFHQ-1K和ImageNet-1K数据集上，PDLS在各种图像恢复任务（包括高斯去模糊、运动去模糊、超分辨率和自由形式修复）中，与单隐变量基线相比，能够生成更保真于原始图像且与语义信息更一致的重建图像。

Conclusion: PDLS是一种新颖的、无需训练的框架，通过结合结构和语义引导，有效解决了扩散模型中图像逆转的挑战，在保持图像细节的同时提高了语义准确性，并且无需进行昂贵的每图像优化。

Abstract: Inverting corrupted images into the latent space of diffusion models is
challenging. Current methods, which encode an image into a single latent
vector, struggle to balance structural fidelity with semantic accuracy, leading
to reconstructions with semantic drift, such as blurred details or incorrect
attributes. To overcome this, we introduce Prompt-Guided Dual Latent Steering
(PDLS), a novel, training-free framework built upon Rectified Flow models for
their stable inversion paths. PDLS decomposes the inversion process into two
complementary streams: a structural path to preserve source integrity and a
semantic path guided by a prompt. We formulate this dual guidance as an optimal
control problem and derive a closed-form solution via a Linear Quadratic
Regulator (LQR). This controller dynamically steers the generative trajectory
at each step, preventing semantic drift while ensuring the preservation of fine
detail without costly, per-image optimization. Extensive experiments on FFHQ-1K
and ImageNet-1K under various inversion tasks, including Gaussian deblurring,
motion deblurring, super-resolution and freeform inpainting, demonstrate that
PDLS produces reconstructions that are both more faithful to the original image
and better aligned with the semantic information than single-latent baselines.

</details>


### [52] [Learning neuroimaging models from health system-scale data](https://arxiv.org/abs/2509.18638)
*Yiwei Lyu,Samir Harake,Asadur Chowdury,Soumyanil Banerjee,Rachel Gologorsky,Shixuan Liu,Anna-Katharina Meissner,Akshay Rao,Chenhui Zhao,Akhil Kondepudi,Cheng Jiang,Xinhai Hou,Rushikesh S. Joshi,Volker Neuschmelting,Ashok Srinivasan,Dawn Kleindorfer,Brian Athey,Vikas Gulani,Aditya Pandey,Honglak Lee,Todd Hollon*

Main category: cs.CV

TL;DR: Prima是首个用于神经影像的视觉语言模型（VLM），在超过22万份MRI研究的训练下，平均诊断ROC曲线下面积达到92.0，优于其他最先进的AI模型，并能提供可解释的鉴别诊断、工作列表优先级和临床转诊建议，同时展现出算法公平性，有望缓解医疗系统中的效率低下问题，尤其是在低资源人群中。


<details>
  <summary>Details</summary>
Motivation: 全球对MRI研究的需求不断增长，给医疗系统带来巨大压力，延长了周转时间，加剧了医生的职业倦怠，尤其影响低资源和农村地区的患者。

Method: 利用一个大型学术医疗系统作为数据引擎，开发了Prima，一个基于视觉语言模型（VLM）的AI基础模型，用于临床MRI研究，该模型在一个包含30,000份MRI研究的为期一年的健康系统范围内研究中进行了测试。

Result: Prima在52种放射学诊断中取得了92.0的平均诊断ROC曲线下面积，优于其他最先进的通用和医学AI模型，并能提供可解释的鉴别诊断、工作列表优先级和临床转诊建议，同时在不同人群和MRI系统之间展现出算法公平性。

Conclusion: Prima在医疗系统规模的VLM方面展现了变革潜力，并在推进AI驱动的医疗保健方面发挥着关键作用，有望通过提供可解释的诊断、工作列表优先级和临床转诊建议，以及通过算法公平性来缓解医疗系统中的效率低下问题，尤其是在低资源人群中。

Abstract: Neuroimaging is a ubiquitous tool for evaluating patients with neurological
diseases. The global demand for magnetic resonance imaging (MRI) studies has
risen steadily, placing significant strain on health systems, prolonging
turnaround times, and intensifying physician burnout \cite{Chen2017-bt,
Rula2024-qp-1}. These challenges disproportionately impact patients in
low-resource and rural settings. Here, we utilized a large academic health
system as a data engine to develop Prima, the first vision language model (VLM)
serving as an AI foundation for neuroimaging that supports real-world, clinical
MRI studies as input. Trained on over 220,000 MRI studies, Prima uses a
hierarchical vision architecture that provides general and transferable MRI
features. Prima was tested in a 1-year health system-wide study that included
30K MRI studies. Across 52 radiologic diagnoses from the major neurologic
disorders, including neoplastic, inflammatory, infectious, and developmental
lesions, Prima achieved a mean diagnostic area under the ROC curve of 92.0,
outperforming other state-of-the-art general and medical AI models. Prima
offers explainable differential diagnoses, worklist priority for radiologists,
and clinical referral recommendations across diverse patient demographics and
MRI systems. Prima demonstrates algorithmic fairness across sensitive groups
and can help mitigate health system biases, such as prolonged turnaround times
for low-resource populations. These findings highlight the transformative
potential of health system-scale VLMs and Prima's role in advancing AI-driven
healthcare.

</details>


### [53] [Understanding-in-Generation: Reinforcing Generative Capability of Unified Model via Infusing Understanding into Generation](https://arxiv.org/abs/2509.18639)
*Yuanhuiyi Lyu,Chi Kit Wong,Chenfei Liao,Lutao Jiang,Xu Zheng,Zexin Lu,Linfeng Zhang,Xuming Hu*

Main category: cs.CV

TL;DR: UiG框架通过在生成过程中整合强大的理解能力来增强统一模型进行文本到图像生成的能力，并在TIIF基准测试中取得了显著的性能提升。


<details>
  <summary>Details</summary>
Motivation: 现有的CoT方法将理解和生成过程分开，限制了它们在弥补生成能力方面的不足。UiG框架旨在通过利用统一模型的强大理解能力来增强其图像生成性能。

Method: UiG框架通过“图像编辑”作为桥梁，将理解能力融入生成过程。首先，验证生成的图像，并将统一模型的理解融入编辑指令，然后逐步增强图像。

Result: UiG框架在文本到图像生成方面显著优于现有的文本到图像推理方法，例如，在TIIF基准的长提示设置上提高了3.92%。

Conclusion: UiG框架通过在生成过程中整合理解能力，有效提升了统一模型的文本到图像生成性能。

Abstract: Recent works have made notable advancements in enhancing unified models for
text-to-image generation through the Chain-of-Thought (CoT). However, these
reasoning methods separate the processes of understanding and generation, which
limits their ability to guide the reasoning of unified models in addressing the
deficiencies of their generative capabilities. To this end, we propose a novel
reasoning framework for unified models, Understanding-in-Generation (UiG),
which harnesses the robust understanding capabilities of unified models to
reinforce their performance in image generation. The core insight of our UiG is
to integrate generative guidance by the strong understanding capabilities
during the reasoning process, thereby mitigating the limitations of generative
abilities. To achieve this, we introduce "Image Editing" as a bridge to infuse
understanding into the generation process. Initially, we verify the generated
image and incorporate the understanding of unified models into the editing
instructions. Subsequently, we enhance the generated image step by step,
gradually infusing the understanding into the generation process. Our UiG
framework demonstrates a significant performance improvement in text-to-image
generation over existing text-to-image reasoning methods, e.g., a 3.92% gain on
the long prompt setting of the TIIF benchmark. The project code:
https://github.com/QC-LY/UiG

</details>


### [54] [Zero-shot Monocular Metric Depth for Endoscopic Images](https://arxiv.org/abs/2509.18642)
*Nicolas Toussaint,Emanuele Colleoni,Ricardo Sanchez-Matilla,Joshua Sutcliffe,Vanessa Thompson,Muhammad Asad,Imanol Luengo,Danail Stoyanov*

Main category: cs.CV

TL;DR: 本论文提出了一个针对内窥镜图像的深度估计的基准测试和新的合成数据集EndoSynth，并通过在该数据集上微调模型来提升模型在真实未见内窥镜图像上的性能。


<details>
  <summary>Details</summary>
Motivation: 现有内窥镜图像的深度估计缺乏鲁棒的基准测试和高质量的数据集，限制了该领域的发展和应用。

Method: 1.构建了一个包含多种最先进深度估计模型（包括度量和相对深度估计）在真实、未见内窥镜图像上的评估基准。 2.提出了一个名为EndoSynth的新型合成数据集，其中包含内窥镜手术器械及其对应的真实度量深度和分割掩码。 3.通过在EndoSynth数据集上微调现有的深度估计基础模型，并在真实内窥镜图像上进行评估，验证了该方法的有效性。

Result: 在真实、未见的内窥镜图像上，对现有深度估计模型的泛化能力和性能进行了关键的分析。通过在EndoSynth数据集上微调后，深度估计基础模型在大多数未见真实数据上的准确性有了显著提升。

Conclusion: 本研究通过提供一个基准测试和一个合成数据集，推动了内窥镜图像深度估计领域的发展，并为未来的研究提供了重要的资源。

Abstract: Monocular relative and metric depth estimation has seen a tremendous boost in
the last few years due to the sharp advancements in foundation models and in
particular transformer based networks. As we start to see applications to the
domain of endoscopic images, there is still a lack of robust benchmarks and
high-quality datasets in that area. This paper addresses these limitations by
presenting a comprehensive benchmark of state-of-the-art (metric and relative)
depth estimation models evaluated on real, unseen endoscopic images, providing
critical insights into their generalisation and performance in clinical
scenarios. Additionally, we introduce and publish a novel synthetic dataset
(EndoSynth) of endoscopic surgical instruments paired with ground truth metric
depth and segmentation masks, designed to bridge the gap between synthetic and
real-world data. We demonstrate that fine-tuning depth foundation models using
our synthetic dataset boosts accuracy on most unseen real data by a significant
margin. By providing both a benchmark and a synthetic dataset, this work
advances the field of depth estimation for endoscopic images and serves as an
important resource for future research. Project page, EndoSynth dataset and
trained weights are available at https://github.com/TouchSurgery/EndoSynth.

</details>


### [55] [LEAF-Mamba: Local Emphatic and Adaptive Fusion State Space Model for RGB-D Salient Object Detection](https://arxiv.org/abs/2509.18683)
*Lanhu Wu,Zilin Gao,Hao Fei,Mong-Li Lee,Wynne Hsu*

Main category: cs.CV

TL;DR: 提出LEAF-Mamba模型，用于RGB-D显著性目标检测，通过引入局部渗流和自适应融合机制，解决了现有CNN和Transformer模型在感受野和计算复杂度上的限制，并在RGB-D和RGB-T SOD任务上取得了优于现有方法的性能。


<details>
  <summary>Details</summary>
Motivation: 现有RGB-D显著性目标检测方法（主要基于CNN或Transformer）在处理长程依赖、平衡性能与计算效率方面存在挑战。

Method: 提出LEAF-Mamba模型，包含局部渗流状态空间模块（LE-SSM）来捕捉多尺度局部依赖，以及基于状态空间模型的自适应融合模块（AFM）来进行跨模态交互和融合。

Result: LEAF-Mamba在RGB-D SOD任务上超越了16种现有最先进方法，在RGB-T SOD任务上也表现出强大的泛化能力。

Conclusion: LEAF-Mamba在RGB-D显著性目标检测方面表现出优越的性能和效率，并具有良好的泛化能力。

Abstract: RGB-D salient object detection (SOD) aims to identify the most conspicuous
objects in a scene with the incorporation of depth cues. Existing methods
mainly rely on CNNs, limited by the local receptive fields, or Vision
Transformers that suffer from the cost of quadratic complexity, posing a
challenge in balancing performance and computational efficiency. Recently,
state space models (SSM), Mamba, have shown great potential for modeling
long-range dependency with linear complexity. However, directly applying SSM to
RGB-D SOD may lead to deficient local semantics as well as the inadequate
cross-modality fusion. To address these issues, we propose a Local Emphatic and
Adaptive Fusion state space model (LEAF-Mamba) that contains two novel
components: 1) a local emphatic state space module (LE-SSM) to capture
multi-scale local dependencies for both modalities. 2) an SSM-based adaptive
fusion module (AFM) for complementary cross-modality interaction and reliable
cross-modality integration. Extensive experiments demonstrate that the
LEAF-Mamba consistently outperforms 16 state-of-the-art RGB-D SOD methods in
both efficacy and efficiency. Moreover, our method can achieve excellent
performance on the RGB-T SOD task, proving a powerful generalization ability.

</details>


### [56] [Lightweight Vision Transformer with Window and Spatial Attention for Food Image Classification](https://arxiv.org/abs/2509.18692)
*Xinle Gao,Linghui Ye,Zhiyong Xiao*

Main category: cs.CV

TL;DR: 提出了一种轻量级的食物图像分类算法，通过结合窗口多头注意力机制（WMHAM）和空间注意力机制（SAM），在保证高精度的同时显著降低了模型参数量和计算复杂度，适用于资源受限的环境。


<details>
  <summary>Details</summary>
Motivation: 食物图像分类在自动化质检、食品安全监管和智能农业生产中至关重要，但现有的Vision Transformer模型存在参数量大、计算复杂度高的问题。

Method: 提出了一种轻量级食物图像分类算法，该算法集成了窗口多头注意力机制（WMHAM）和空间注意力机制（SAM）。WMHAM通过窗口划分来捕捉局部和全局上下文特征，降低计算成本；SAM自适应地强调关键空间区域，以增强区分性特征表示。

Result: 在Food-101和Vireo Food-172数据集上，该模型分别达到了95.24%和94.33%的准确率，同时显著减少了参数量和FLOPs。

Conclusion: 该模型在计算效率和分类性能之间取得了有效的平衡，适合在资源受限的环境中部署。

Abstract: With the rapid development of society and continuous advances in science and
technology, the food industry increasingly demands higher production quality
and efficiency. Food image classification plays a vital role in enabling
automated quality control on production lines, supporting food safety
supervision, and promoting intelligent agricultural production. However, this
task faces challenges due to the large number of parameters and high
computational complexity of Vision Transformer models. To address these issues,
we propose a lightweight food image classification algorithm that integrates a
Window Multi-Head Attention Mechanism (WMHAM) and a Spatial Attention Mechanism
(SAM). The WMHAM reduces computational cost by capturing local and global
contextual features through efficient window partitioning, while the SAM
adaptively emphasizes key spatial regions to improve discriminative feature
representation. Experiments conducted on the Food-101 and Vireo Food-172
datasets demonstrate that our model achieves accuracies of 95.24% and 94.33%,
respectively, while significantly reducing parameters and FLOPs compared with
baseline methods. These results confirm that the proposed approach achieves an
effective balance between computational efficiency and classification
performance, making it well-suited for deployment in resource-constrained
environments.

</details>


### [57] [OSDA: A Framework for Open-Set Discovery and Automatic Interpretation of Land-cover in Remote Sensing Imagery](https://arxiv.org/abs/2509.18693)
*Siyi Chen,Kai Wang,Weicong Pang,Ruiming Yang,Ziru Chen,Renjun Gao,Alexis Kai Hon Lau,Dasa Gu,Chenchen Zhang,Cheng Li*

Main category: cs.CV

TL;DR: 本研究提出了OSDA框架，用于无标注的开放集陆表分析，结合了SAM进行精确分割和MLLM进行语义描述，实现了像素级精度和高层语义理解的结合，为动态陆表监测和地球观测分析提供了可扩展、可解释的解决方案。


<details>
  <summary>Details</summary>
Motivation: 开放集遥感陆表分析需要细粒度的空间定位和开放的语义分类能力，包括检测、分割新物体并赋予其可解释的语义标签。

Method: 提出OSDA三阶段框架：(1) 使用SAM进行精确发现和掩码提取；(2) 使用两阶段微调的MLLM进行语义归因和上下文描述；(3) 使用LLM-as-judge进行评估。

Result: OSDA结合了像素级精度和高层语义理解，解决了开放世界遥感解释的关键挑战，能够进行无标注的开放集陆表发现、分割和描述。

Conclusion: OSDA提供了一个无需手动标注、支持跨多种卫星图像的鲁棒评估的框架，为动态陆表监测、自动化地图更新和大规模地球观测分析提供了可扩展且可解释的解决方案。

Abstract: Open-set land-cover analysis in remote sensing requires the ability to
achieve fine-grained spatial localization and semantically open categorization.
This involves not only detecting and segmenting novel objects without
categorical supervision but also assigning them interpretable semantic labels
through multimodal reasoning. In this study, we introduce OSDA, an integrated
three-stage framework for annotation-free open-set land-cover discovery,
segmentation, and description. The pipeline consists of: (1) precise discovery
and mask extraction with a promptable fine-tuned segmentation model (SAM), (2)
semantic attribution and contextual description via a two-phase fine-tuned
multimodal large language model (MLLM), and (3) LLM-as-judge and manual scoring
of the MLLMs evaluation. By combining pixel-level accuracy with high-level
semantic understanding, OSDA addresses key challenges in open-world remote
sensing interpretation. Designed to be architecture-agnostic and label-free,
the framework supports robust evaluation across diverse satellite imagery
without requiring manual annotation. Our work provides a scalable and
interpretable solution for dynamic land-cover monitoring, showing strong
potential for automated cartographic updating and large-scale earth observation
analysis.

</details>


### [58] [Overview of PlantCLEF 2021: cross-domain plant identification](https://arxiv.org/abs/2509.18697)
*Herve Goeau,Pierre Bonnet,Alexis Joly*

Main category: cs.CV

TL;DR: 尽管深度学习和可用数据有所改进，但植物识别仍面临数据稀疏区域（如热带地区）的挑战。LifeCLEF 2021 植物识别挑战赛旨在利用标本馆藏品（主要来自几内亚湾地区）来改善数据稀疏区域的植物自动识别。该比赛使用包含标本照片和少量野外照片的训练集，以及仅包含野外照片的测试集，以解决跨域分类问题。


<details>
  <summary>Details</summary>
Motivation: 利用标本馆藏品来改善数据稀疏区域（如热带地区）的植物自动识别，解决现有模型主要关注北美和西欧而忽视生物多样性丰富的地区的问题。

Method: 将几种方法的组合应用于挑战赛的训练集，训练集包含数万张标本照片和几千张野外照片，以学习两个域之间的对应关系。模型还会利用每个物种的 5 种形态和功能性状值以及地理位置、日期、作者和分类单元等元数据。

Result: 评估了参与研究小组的方法和系统，并分析了主要结果。

Conclusion: LifeCLEF 2021 植物识别挑战赛成功评估了利用标本馆藏品改善热带地区植物自动识别的可能性，并展示了各种方法的性能。

Abstract: Automated plant identification has improved considerably thanks to recent
advances in deep learning and the availability of training data with more and
more field photos. However, this profusion of data concerns only a few tens of
thousands of species, mainly located in North America and Western Europe, much
less in the richest regions in terms of biodiversity such as tropical
countries. On the other hand, for several centuries, botanists have
systematically collected, catalogued and stored plant specimens in herbaria,
especially in tropical regions, and recent efforts by the biodiversity
informatics community have made it possible to put millions of digitised
records online. The LifeCLEF 2021 plant identification challenge (or "PlantCLEF
2021") was designed to assess the extent to which automated identification of
flora in data-poor regions can be improved by using herbarium collections. It
is based on a dataset of about 1,000 species mainly focused on the Guiana
Shield of South America, a region known to have one of the highest plant
diversities in the world. The challenge was evaluated as a cross-domain
classification task where the training set consisted of several hundred
thousand herbarium sheets and a few thousand photos to allow learning a
correspondence between the two domains. In addition to the usual metadata
(location, date, author, taxonomy), the training data also includes the values
of 5 morphological and functional traits for each species. The test set
consisted exclusively of photos taken in the field. This article presents the
resources and evaluations of the assessment carried out, summarises the
approaches and systems used by the participating research groups and provides
an analysis of the main results.

</details>


### [59] [AGSwap: Overcoming Category Boundaries in Object Fusion via Adaptive Group Swapping](https://arxiv.org/abs/2509.18699)
*Zedong Zhang,Ying Tai,Jianjun Qian,Jian Yang,Jun Li*

Main category: cs.CV

TL;DR: AGSwap是一种用于跨类别对象融合的文本到图像生成方法，通过分组嵌入交换和自适应分组更新实现，并引入了COF数据集进行训练和评估。


<details>
  <summary>Details</summary>
Motivation: 现有文本到图像生成方法在融合跨类别对象时存在偏见、混乱或不一致的问题，且缺乏综合性基准数据集。

Method: 提出AGSwap方法，包含分组嵌入交换（通过特征操作融合不同概念的语义属性）和自适应分组更新（通过平衡评估分数动态优化以保证合成一致性）。同时，引入COF数据集（基于ImageNet-1K和WordNet构建，包含95个超类和10个子类，提供451,250个融合对）。

Result: AGSwap在广泛的实验中表现优于现有的组合文本到图像生成方法，包括使用简单和复杂提示的GPT-Image-1。

Conclusion: AGSwap在跨类别对象融合任务上取得了显著的成功，并且引入的COF数据集为该领域的研究提供了重要资源。

Abstract: Fusing cross-category objects to a single coherent object has gained
increasing attention in text-to-image (T2I) generation due to its broad
applications in virtual reality, digital media, film, and gaming. However,
existing methods often produce biased, visually chaotic, or semantically
inconsistent results due to overlapping artifacts and poor integration.
Moreover, progress in this field has been limited by the absence of a
comprehensive benchmark dataset. To address these problems, we propose
\textbf{Adaptive Group Swapping (AGSwap)}, a simple yet highly effective
approach comprising two key components: (1) Group-wise Embedding Swapping,
which fuses semantic attributes from different concepts through feature
manipulation, and (2) Adaptive Group Updating, a dynamic optimization mechanism
guided by a balance evaluation score to ensure coherent synthesis.
Additionally, we introduce \textbf{Cross-category Object Fusion (COF)}, a
large-scale, hierarchically structured dataset built upon ImageNet-1K and
WordNet. COF includes 95 superclasses, each with 10 subclasses, enabling
451,250 unique fusion pairs. Extensive experiments demonstrate that AGSwap
outperforms state-of-the-art compositional T2I methods, including GPT-Image-1
using simple and complex prompts.

</details>


### [60] [Overview of LifeCLEF Plant Identification task 2019: diving into data deficient tropical countries](https://arxiv.org/abs/2509.18705)
*Herve Goeau,Pierre Bonnet,Alexis Joly*

Main category: cs.CV

TL;DR: 该论文介绍了LifeCLEF 2019植物识别挑战赛，该比赛旨在评估在数据匮乏地区对植物进行自动识别的能力。


<details>
  <summary>Details</summary>
Motivation: 现有的植物自动识别技术虽然在深度学习和数据可用性方面取得了进展，但训练数据仅涵盖了少量物种，无法满足全球近36.9万物种的识别需求。因此，本次挑战赛关注数据匮乏地区（如圭亚那地盾和北亚马逊雨林）的植物识别，以推动该领域的发展。

Method: 本次挑战赛基于圭亚那地盾和北亚马逊雨林的10K物种数据集，评估自动识别系统的性能。并与顶尖的热带植物专家进行了性能比较。

Result: 比赛评估了参赛研究小组采用的方法和系统，并对主要成果进行了分析。

Conclusion: 本次挑战赛总结了资源、评估方法、参赛系统的特点以及主要结果，为未来在数据匮乏地区进行植物自动识别的研究提供了参考。

Abstract: Automated identification of plants has improved considerably thanks to the
recent progress in deep learning and the availability of training data.
However, this profusion of data only concerns a few tens of thousands of
species, while the planet has nearly 369K. The LifeCLEF 2019 Plant
Identification challenge (or "PlantCLEF 2019") was designed to evaluate
automated identification on the flora of data deficient regions. It is based on
a dataset of 10K species mainly focused on the Guiana shield and the Northern
Amazon rainforest, an area known to have one of the greatest diversity of
plants and animals in the world. As in the previous edition, a comparison of
the performance of the systems evaluated with the best tropical flora experts
was carried out. This paper presents the resources and assessments of the
challenge, summarizes the approaches and systems employed by the participating
research groups, and provides an analysis of the main outcomes.

</details>


### [61] [RSVG-ZeroOV: Exploring a Training-Free Framework for Zero-Shot Open-Vocabulary Visual Grounding in Remote Sensing Images](https://arxiv.org/abs/2509.18711)
*Ke Li,Di Wang,Ting Wang,Fuyu Dong,Yiming Zhang,Luyao Zhang,Xiangyu Wang,Shaofeng Li,Quan Wang*

Main category: cs.CV

TL;DR: 提出RSVG-ZeroOV框架，通过冻结的通用基础模型实现零样本开放词汇的遥感图像视觉定位，无需训练。


<details>
  <summary>Details</summary>
Motivation: 现有方法受限于闭集词汇，泛化能力差；利用基础模型的方法依赖昂贵数据集和耗时微调。本研究旨在无需训练即可探索冻结通用基础模型在零样本开放词汇遥感图像视觉定位方面的潜力。

Method: RSVG-ZeroOV框架包含三个阶段：(i) 利用视觉-语言模型（VLM）获取文本查询和视觉区域之间的交叉注意力图；(ii) 利用扩散模型（DM）的细粒度建模先验，补充VLM忽略的物体结构和形状信息；(iii) 引入注意力演化模块，抑制不相关激活，生成纯净的分割掩码。

Result: 在没有任何繁琐的特定任务训练的情况下，RSVG-ZeroOV提供了一种高效且可扩展的解决方案。广泛的实验表明，该框架的性能持续优于现有的弱监督和零样本方法。

Conclusion: RSVG-ZeroOV框架能够无需训练，利用冻结的通用基础模型，在零样本开放词汇的遥感图像视觉定位任务上取得优异表现，并有效解决了现有方法的局限性。

Abstract: Remote sensing visual grounding (RSVG) aims to localize objects in remote
sensing images based on free-form natural language expressions. Existing
approaches are typically constrained to closed-set vocabularies, limiting their
applicability in open-world scenarios. While recent attempts to leverage
generic foundation models for open-vocabulary RSVG, they overly rely on
expensive high-quality datasets and time-consuming fine-tuning. To address
these limitations, we propose \textbf{RSVG-ZeroOV}, a training-free framework
that aims to explore the potential of frozen generic foundation models for
zero-shot open-vocabulary RSVG. Specifically, RSVG-ZeroOV comprises three key
stages: (i) Overview: We utilize a vision-language model (VLM) to obtain
cross-attention\footnote[1]{In this paper, although decoder-only VLMs use
self-attention over all tokens, we refer to the image-text interaction part as
cross-attention to distinguish it from pure visual self-attention.}maps that
capture semantic correlations between text queries and visual regions. (ii)
Focus: By leveraging the fine-grained modeling priors of a diffusion model
(DM), we fill in gaps in structural and shape information of objects, which are
often overlooked by VLM. (iii) Evolve: A simple yet effective attention
evolution module is introduced to suppress irrelevant activations, yielding
purified segmentation masks over the referred objects. Without cumbersome
task-specific training, RSVG-ZeroOV offers an efficient and scalable solution.
Extensive experiments demonstrate that the proposed framework consistently
outperforms existing weakly-supervised and zero-shot methods.

</details>


### [62] [What Makes You Unique? Attribute Prompt Composition for Object Re-Identification](https://arxiv.org/abs/2509.18715)
*Yingquan Wang,Pingping Zhang,Chong Sun,Dong Wang,Huchuan Lu*

Main category: cs.CV

TL;DR: 该研究提出了一种名为属性提示组合（APC）的框架，用于解决目标重识别（ReID）中的单域和跨域限制问题，通过利用文本语义增强识别能力和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有ReID模型在单域或跨域场景下存在局限性，单域模型易过拟合，跨域模型可能抑制辨别性线索。

Method: 提出属性提示组合（APC）框架，包括属性提示生成器（APG），其中包含语义属性字典（SAD）和提示组合模块（PCM）。SAD提供丰富的语义描述，PCM自适应地组合相关属性以生成辨别性特征。此外，采用快慢训练策略（FSTS）来平衡ReID的辨别性和泛化性，包括快速更新流（FUS）和慢速更新流（SUS）。

Result: 在标准和域泛化（DG）ReID数据集上的实验表明，APC框架在辨别性和泛化性方面均优于现有最先进的方法。

Conclusion: APC框架通过结合文本语义和创新的训练策略，有效解决了ReID模型的局限性，并在各种数据集上取得了领先的性能。

Abstract: Object Re-IDentification (ReID) aims to recognize individuals across
non-overlapping camera views. While recent advances have achieved remarkable
progress, most existing models are constrained to either single-domain or
cross-domain scenarios, limiting their real-world applicability. Single-domain
models tend to overfit to domain-specific features, whereas cross-domain models
often rely on diverse normalization strategies that may inadvertently suppress
identity-specific discriminative cues. To address these limitations, we propose
an Attribute Prompt Composition (APC) framework, which exploits textual
semantics to jointly enhance discrimination and generalization. Specifically,
we design an Attribute Prompt Generator (APG) consisting of a Semantic
Attribute Dictionary (SAD) and a Prompt Composition Module (PCM). SAD is an
over-complete attribute dictionary to provide rich semantic descriptions, while
PCM adaptively composes relevant attributes from SAD to generate discriminative
attribute-aware features. In addition, motivated by the strong generalization
ability of Vision-Language Models (VLM), we propose a Fast-Slow Training
Strategy (FSTS) to balance ReID-specific discrimination and generalizable
representation learning. Specifically, FSTS adopts a Fast Update Stream (FUS)
to rapidly acquire ReID-specific discriminative knowledge and a Slow Update
Stream (SUS) to retain the generalizable knowledge inherited from the
pre-trained VLM. Through a mutual interaction, the framework effectively
focuses on ReID-relevant features while mitigating overfitting. Extensive
experiments on both conventional and Domain Generalized (DG) ReID datasets
demonstrate that our framework surpasses state-of-the-art methods, exhibiting
superior performances in terms of both discrimination and generalization. The
source code is available at https://github.com/AWangYQ/APC.

</details>


### [63] [Pre-training CLIP against Data Poisoning with Optimal Transport-based Matching and Alignment](https://arxiv.org/abs/2509.18717)
*Tong Zhang,Kuofeng Gao,Jiawang Bai,Leo Yu Zhang,Xin Yin,Zonghui Wang,Shouling Ji,Wenzhi Chen*

Main category: cs.CV

TL;DR: OTCCLIP通过使用基于最优传输的距离度量来重建图像-标题对，以防御针对CLIP模型的数据中毒和后门攻击。


<details>
  <summary>Details</summary>
Motivation: 现有的CLIP模型易受数据中毒和后门攻击，而现有的防御方法仅依赖于全局表示，可能引入错误的图像-标题对并损害CLIP预训练。

Method: 提出了一种基于最优传输的框架OTCCLIP，该框架通过计算细粒度视觉和文本特征集之间的最优传输距离来重建图像-标题对，并重新分配标题。此外，还采用基于最优传输的目标函数来增强跨模态和模态内的细粒度对齐。

Result: OTCCLIP能够成功降低中毒攻击的成功率，并显著提高在中毒数据集上训练的CLIP模型的零样本和线性探测性能。

Conclusion: OTCCLIP是一种有效的方法，可以防御针对CLIP模型的यीडेटा中毒和后门攻击，同时提高模型的性能。

Abstract: Recent studies have shown that Contrastive Language-Image Pre-training (CLIP)
models are threatened by targeted data poisoning and backdoor attacks due to
massive training image-caption pairs crawled from the Internet. Previous
defense methods correct poisoned image-caption pairs by matching a new caption
for each image. However, the matching process relies solely on the global
representations of images and captions, overlooking fine-grained features of
visual and textual features. It may introduce incorrect image-caption pairs and
harm the CLIP pre-training. To address their limitations, we propose an Optimal
Transport-based framework to reconstruct image-caption pairs, named OTCCLIP. We
propose a new optimal transport-based distance measure between fine-grained
visual and textual feature sets and re-assign new captions based on the
proposed optimal transport distance. Additionally, to further reduce the
negative impact of mismatched pairs, we encourage the inter- and intra-modality
fine-grained alignment by employing optimal transport-based objective
functions. Our experiments demonstrate that OTCCLIP can successfully decrease
the attack success rates of poisoning attacks. Also, compared to previous
methods, OTCCLIP significantly improves CLIP's zero-shot and linear probing
performance trained on poisoned datasets.

</details>


### [64] [Knowledge Transfer from Interaction Learning](https://arxiv.org/abs/2509.18733)
*Yilin Gao,Kangyi Chen,Zhongxing Peng,Hengjie Lu,Shugong Xu*

Main category: cs.CV

TL;DR: 现有视觉基础模型（VFMs）在知识迁移方面存在局限性，而视觉语言模型（VLMs）擅长跨模态交互。本文提出的学习交互（LFI）框架通过显式建模视觉理解作为交互过程，并利用交互查询和基于交互的监督，实现了更有效的知识迁移，并在多个基准测试中取得了显著改进，尤其在跨域设置和语义一致性方面表现突出。


<details>
  <summary>Details</summary>
Motivation: 当前视觉基础模型（VFMs）在从视觉语言模型（VLMs）迁移知识方面存在根本性限制，因为现有的VFMs主要采用忽视交互过程的面向结果的范式，而VLMs擅长通过统一的表示空间来模拟跨模态交互。这种表示上的差异阻碍了有效的知识迁移，并限制了在不同视觉任务中的泛化能力。

Method: 提出了一种名为“学习交互”（LFI）的认知启发式框架，该框架通过显式地将视觉理解建模为一个交互过程来解决上述差距。其核心在于，捕捉预训练VLMs中编码的动态交互模式，可以实现更准确、更高效的知识迁移到VFMs。该方法侧重于两项技术创新：交互查询（Interaction Queries），它在网络层之间保持持久的关系结构；以及基于交互的监督（interaction-based supervision），它源自VLMs的跨模态注意力机制。

Result: 通过全面的实验证明，LFI框架在多个基准测试中实现了持续的改进，在TinyImageNet分类任务上提升了3.3个绝对mAP点，在COCO检测/分割任务上提升了1.6个mAP点/2.4个AP点，同时参数开销和收敛速度保持在较低水平。该框架在跨域设置下表现尤为出色，在PACS和VLCS数据集上实现了2.4和9.3个百分点的零样本（zero-shot）提升。此外，人类评估进一步证实了其认知对齐能力，在语义一致性指标上，其表现比面向结果的方法高出2.7倍。

Conclusion: LFI框架通过模拟交互过程，有效解决了视觉基础模型在知识迁移和泛化能力方面的挑战，并在各项任务和评估中取得了显著的性能提升，证明了其在视觉理解和跨模态学习领域的潜力。

Abstract: Current visual foundation models (VFMs) face a fundamental limitation in
transferring knowledge from vision language models (VLMs), while VLMs excel at
modeling cross-modal interactions through unified representation spaces,
existing VFMs predominantly adopt result-oriented paradigms that neglect the
underlying interaction processes. This representational discrepancy hinders
effective knowledge transfer and limits generalization across diverse vision
tasks. We propose Learning from Interactions (LFI), a cognitive-inspired
framework that addresses this gap by explicitly modeling visual understanding
as an interactive process. Our key insight is that capturing the dynamic
interaction patterns encoded in pre-trained VLMs enables more faithful and
efficient knowledge transfer to VFMs. The approach centers on two technical
innovations, Interaction Queries, which maintain persistent relational
structures across network layers, and interaction-based supervision, derived
from the cross-modal attention mechanisms of VLMs. Comprehensive experiments
demonstrate consistent improvements across multiple benchmarks, achieving 3.3
and 1.6mAP/2.4AP absolute gains on TinyImageNet classification and COCO
detection/segmentation respectively, with minimal parameter overhead and faster
convergence. The framework particularly excels in cross-domain settings,
delivering 2.4 and 9.3 zero-shot improvements on PACS and VLCS. Human
evaluations further confirm its cognitive alignment, outperforming
result-oriented methods by 2.7 times in semantic consistency metrics.

</details>


### [65] [HyPSAM: Hybrid Prompt-driven Segment Anything Model for RGB-Thermal Salient Object Detection](https://arxiv.org/abs/2509.18738)
*Ruichao Hou,Xingyuan Li,Tongwei Ren,Dongming Zhou,Gangshan Wu,Jinde Cao*

Main category: cs.CV

TL;DR: 提出了一种名为HyPSAM的新型混合提示驱动分割任何模型，用于RGB-T显着目标检测，通过动态融合网络（DFNet）生成初始显着图作为提示，并通过即插即用精炼网络（P2RNet）利用文本、掩码和边界框提示来优化分割结果，在三个公开数据集上取得了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: RGB-T显着目标检测（RGB-T SOD）旨在通过融合RGB和热力学模态来识别显著物体，但由于特征融合不足和数据稀缺性，精确边界和完整物体的学习仍然具有挑战性。

Method: 提出了一种名为HyPSAM的新型混合提示驱动分割任何模型（HyPSAM），利用分割任何模型（SAM）的零样本泛化能力。首先提出一个动态融合网络（DFNet）生成高质量的初始显着图作为视觉提示，DFNet采用动态卷积和多分支解码。然后提出一个即插即用精炼网络（P2RNet），利用混合提示（文本提示、掩码提示和边界框提示）来指导SAM精炼显着图。

Result: 在三个公开数据集上进行了广泛的实验，证明了该方法取得了最先进的性能。HyPSAM具有出色的多功能性，可以与不同的RGB-T SOD方法无缝集成，实现显著的性能提升。

Conclusion: HyPSAM通过混合提示工程实现了RGB-T显着目标检测的最先进性能，并展示了其在該领域的潜力。

Abstract: RGB-thermal salient object detection (RGB-T SOD) aims to identify prominent
objects by integrating complementary information from RGB and thermal
modalities. However, learning the precise boundaries and complete objects
remains challenging due to the intrinsic insufficient feature fusion and the
extrinsic limitations of data scarcity. In this paper, we propose a novel
hybrid prompt-driven segment anything model (HyPSAM), which leverages the
zero-shot generalization capabilities of the segment anything model (SAM) for
RGB-T SOD. Specifically, we first propose a dynamic fusion network (DFNet) that
generates high-quality initial saliency maps as visual prompts. DFNet employs
dynamic convolution and multi-branch decoding to facilitate adaptive
cross-modality interaction, overcoming the limitations of fixed-parameter
kernels and enhancing multi-modal feature representation. Moreover, we propose
a plug-and-play refinement network (P2RNet), which serves as a general
optimization strategy to guide SAM in refining saliency maps by using hybrid
prompts. The text prompt ensures reliable modality input, while the mask and
box prompts enable precise salient object localization. Extensive experiments
on three public datasets demonstrate that our method achieves state-of-the-art
performance. Notably, HyPSAM has remarkable versatility, seamlessly integrating
with different RGB-T SOD methods to achieve significant performance gains,
thereby highlighting the potential of prompt engineering in this field. The
code and results of our method are available at:
https://github.com/milotic233/HyPSAM.

</details>


### [66] [TriFusion-AE: Language-Guided Depth and LiDAR Fusion for Robust Point Cloud Processing](https://arxiv.org/abs/2509.18743)
*Susmit Neogi*

Main category: cs.CV

TL;DR: TriFusion-AE是一个多模态自编码器，结合了文本、深度图和LiDAR点云，提高了对噪声和对抗性扰动的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有的基于LiDAR的感知方法容易受到噪声、遮挡和对抗性破坏的影响，而传统的自编码器在现实世界的挑战性条件下性能会下降。

Method: 提出了一种名为TriFusion-AE的多模态交叉注意力自编码器，该模型集成了文本先验、来自多视图图像的单目深度图和LiDAR点云，通过对齐语义线索、几何特征和空间结构来学习对扰动具有弹性的表示。

Result: 在强对抗性攻击和重噪声条件下，TriFusion-AE实现了比基于CNN的自编码器更鲁棒的重建，但在轻度扰动下效果提升有限。在nuScenes-mini数据集上进行了评估。

Conclusion: TriFusion-AE通过融合多模态信息显著提高了LiDAR感知对噪声和对抗性攻击的鲁棒性，并且该框架可以与任何基于CNN的点云自编码器集成。

Abstract: LiDAR-based perception is central to autonomous driving and robotics, yet raw
point clouds remain highly vulnerable to noise, occlusion, and adversarial
corruptions. Autoencoders offer a natural framework for denoising and
reconstruction, but their performance degrades under challenging real-world
conditions. In this work, we propose TriFusion-AE, a multimodal cross-attention
autoencoder that integrates textual priors, monocular depth maps from
multi-view images, and LiDAR point clouds to improve robustness. By aligning
semantic cues from text, geometric (depth) features from images, and spatial
structure from LiDAR, TriFusion-AE learns representations that are resilient to
stochastic noise and adversarial perturbations. Interestingly, while showing
limited gains under mild perturbations, our model achieves significantly more
robust reconstruction under strong adversarial attacks and heavy noise, where
CNN-based autoencoders collapse. We evaluate on the nuScenes-mini dataset to
reflect realistic low-data deployment scenarios. Our multimodal fusion
framework is designed to be model-agnostic, enabling seamless integration with
any CNN-based point cloud autoencoder for joint representation learning.

</details>


### [67] [COLT: Enhancing Video Large Language Models with Continual Tool Usage](https://arxiv.org/abs/2509.18754)
*Yuyang Liu,Xinyuan Shi,Bang Yang,Peilin Zhou,Jiahua Dong,Long Chen,Ian Reid,Xiaondan Liang*

Main category: cs.CV

TL;DR: COLT是一个持续学习框架，用于增强开源视频大语言模型（LLMs）的工具使用能力，使其能够处理不断变化的工具流，同时避免遗忘已学知识。


<details>
  <summary>Details</summary>
Motivation: 现有视频理解方法在工具使用方面存在局限性，它们依赖固定的工具库，难以适应现实世界中不断变化的工具数据流。为解决此问题，需要一种能够持续学习新工具并保留旧工具能力的方法。

Method: COLT框架引入了一个可学习的工具代码库作为内存系统，用于存储和检索工具。该系统能够根据用户指令与工具特征的相似度动态选择相关工具，并通过持续学习机制不断更新和扩展工具使用能力，同时防止‘灾难性遗忘’。

Result: 在现有视频大语言模型基准和专门的视频工具使用指令调优数据集VideoToolBench上的大量实验表明，COLT框架在视频LLM的工具使用能力上达到了最先进的性能。

Conclusion: COLT通过引入持续学习机制和工具代码库，有效解决了视频大语言模型在动态工具环境下的工具使用泛化能力问题，显著提升了其处理和利用不断更新的工具的能力。

Abstract: The success of Large Language Models (LLMs) has significantly propelled the
research of video understanding. To harvest the benefits of well-trained expert
models (i.e., tools), video LLMs prioritize the exploration of tool usage
capabilities. Existing methods either prompt closed-source LLMs or employ the
instruction tuning paradigm for tool-use fine-tuning. These methods, however,
assume an established repository of fixed tools and struggle to generalize to
real-world environments where tool data is perpetually evolving and streaming
in. To this end, we propose to enhance open-source video LLMs with COntinuaL
Tool usage (termed COLT), which automatically acquires tool-use ability in a
successive tool stream without suffering 'catastrophic forgetting' of the past
learned tools. Specifically, our COLT incorporates a learnable tool codebook as
a tool-specific memory system. Then relevant tools are dynamically selected
based on the similarity between user instruction and tool features within the
codebook. To unleash the tool usage potential of video LLMs, we collect a
video-centric tool-use instruction tuning dataset VideoToolBench. Extensive
experiments on both previous video LLM benchmarks and the tool-use-specific
VideoToolBench dataset demonstrate the state-of-the-art performance of our
proposed COLT.

</details>


### [68] [FixingGS: Enhancing 3D Gaussian Splatting via Training-Free Score Distillation](https://arxiv.org/abs/2509.18759)
*Zhaorui Wang,Yi Gu,Deming Zhou,Renjing Xu*

Main category: cs.CV

TL;DR: FixingGS是一种无需训练的方法，利用扩散模型增强稀疏视角的3D高斯泼溅重建，通过蒸馏和自适应的渐进式增强来消除伪影和修复缺失内容，实现了更高质量的重建。


<details>
  <summary>Details</summary>
Motivation: 现有的3D高斯泼溅方法在稀疏视角重建时存在伪影，而引入生成式先验的方法又会牺牲多视角一致性，导致结构模糊和细节不可靠。

Method: 提出了一种名为FixingGS的训练无关方法，其核心是利用扩散模型进行稀疏视角3D高斯泼溅重建的增强。该方法包括一个蒸馏方法，以提供更准确、跨视角一致的扩散先验，从而有效消除伪影和进行修复。此外，还提出了一个自适应的渐进式增强方案，以进一步优化在约束不足区域的重建。

Result: 实验结果表明，FixingGS在视觉质量和重建性能上均优于现有的最先进方法。

Conclusion: FixingGS通过利用扩散模型和创新的蒸馏及增强策略，成功解决了稀疏视角3D高斯泼溅重建中的伪影和多视角不一致性问题，取得了显著的成果。

Abstract: Recently, 3D Gaussian Splatting (3DGS) has demonstrated remarkable success in
3D reconstruction and novel view synthesis. However, reconstructing 3D scenes
from sparse viewpoints remains highly challenging due to insufficient visual
information, which results in noticeable artifacts persisting across the 3D
representation. To address this limitation, recent methods have resorted to
generative priors to remove artifacts and complete missing content in
under-constrained areas. Despite their effectiveness, these approaches struggle
to ensure multi-view consistency, resulting in blurred structures and
implausible details. In this work, we propose FixingGS, a training-free method
that fully exploits the capabilities of the existing diffusion model for
sparse-view 3DGS reconstruction enhancement. At the core of FixingGS is our
distillation approach, which delivers more accurate and cross-view coherent
diffusion priors, thereby enabling effective artifact removal and inpainting.
In addition, we propose an adaptive progressive enhancement scheme that further
refines reconstructions in under-constrained regions. Extensive experiments
demonstrate that FixingGS surpasses existing state-of-the-art methods with
superior visual quality and reconstruction performance. Our code will be
released publicly.

</details>


### [69] [Bi-VLM: Pushing Ultra-Low Precision Post-Training Quantization Boundaries in Vision-Language Models](https://arxiv.org/abs/2509.18763)
*Xijun Wang,Junyun Huang,Rayyan Abdalla,Chengyuan Zhang,Ruiqi Xian,Dinesh Manocha*

Main category: cs.CV

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: We address the critical gap between the computational demands of
vision-language models and the possible ultra-low-bit weight precision
(bitwidth $\leq2$ bits) we can use for higher efficiency. Our work is motivated
by the substantial computational cost and memory requirements of VLMs, which
restrict their applicability in hardware-constrained environments. We propose
Bi-VLM, which separates model weights non-uniformly based on the Gaussian
quantiles. Our formulation groups the model weights into outlier (salient) and
multiple inlier (unsalient) subsets, ensuring that each subset contains a
proportion of weights corresponding to its quantile in the distribution. We
propose a saliency-aware hybrid quantization algorithm and use it to quantize
weights by imposing different constraints on the scaler and binary matrices
based on the saliency metric and compression objective. We have evaluated our
approach on different VLMs. For the language model part of the VLM, our Bi-VLM
outperforms the SOTA by 3%-47% on the visual question answering task in terms
of four different benchmarks and three different models. For the overall VLM,
our Bi-VLM outperforms the SOTA by 4%-45%. We also perform token pruning on the
quantized models and observe that there is redundancy of image tokens 90% - 99%
in the quantized models. This helps us to further prune the visual tokens to
improve efficiency.

</details>


### [70] [DiSSECT: Structuring Transfer-Ready Medical Image Representations through Discrete Self-Supervision](https://arxiv.org/abs/2509.18765)
*Azad Singh,Deepak Mishra*

Main category: cs.CV

TL;DR: DiSSECT是一种基于离散表示的自监督学习框架，通过多尺度向量量化来学习医学图像的可复现、结构感知特征，以提高表示的可迁移性，并在各种下游任务中表现出色。


<details>
  <summary>Details</summary>
Motivation: 现有的自监督学习方法在医学图像处理中虽然强大，但常依赖复杂架构、解剖学先验或大量调优的增强方法，这限制了其可扩展性和泛化能力。更严重的是，这些模型容易出现“捷径学习”，尤其是在解剖结构相似而病变细微的胸部X光等影像中。

Method: 提出了一种名为DiSSECT（离散自监督学习用于高效临床可迁移表示）的框架，该框架将多尺度向量量化集成到自监督学习流程中，以强制实现离散表示瓶颈。这限制了模型学习可重复的、结构感知的特征，同时抑制了特定于视图或低效用的模式，从而提高了表示在不同任务和领域之间的迁移能力。

Result: DiSSECT在分类和分割任务上均取得了优异的性能，且只需进行少量或无需微调。在低标签数据情况下，其标签效率尤为突出。在多个公共医学影像数据集上的验证表明，DiSSECT比现有的最先进方法具有更强的鲁棒性和泛化能力。

Conclusion: DiSSECT通过引入离散表示瓶颈，成功地解决了现有自监督学习方法在医学图像处理中的局限性，提高了特征的可重复性、结构感知能力和跨任务/域的迁移能力，并在多种医学影像数据集上展示了其优越性能。

Abstract: Self-supervised learning (SSL) has emerged as a powerful paradigm for medical
image representation learning, particularly in settings with limited labeled
data. However, existing SSL methods often rely on complex architectures,
anatomy-specific priors, or heavily tuned augmentations, which limit their
scalability and generalizability. More critically, these models are prone to
shortcut learning, especially in modalities like chest X-rays, where anatomical
similarity is high and pathology is subtle. In this work, we introduce DiSSECT
-- Discrete Self-Supervision for Efficient Clinical Transferable
Representations, a framework that integrates multi-scale vector quantization
into the SSL pipeline to impose a discrete representational bottleneck. This
constrains the model to learn repeatable, structure-aware features while
suppressing view-specific or low-utility patterns, improving representation
transfer across tasks and domains. DiSSECT achieves strong performance on both
classification and segmentation tasks, requiring minimal or no fine-tuning, and
shows particularly high label efficiency in low-label regimes. We validate
DiSSECT across multiple public medical imaging datasets, demonstrating its
robustness and generalizability compared to existing state-of-the-art
approaches.

</details>


### [71] [Real-time Deer Detection and Warning in Connected Vehicles via Thermal Sensing and Deep Learning](https://arxiv.org/abs/2509.18779)
*Hemanth Puppala,Wayne Sarasua,Srinivas Biyaguda,Farhad Farzinpour,Mashrur Chowdhury*

Main category: cs.CV

TL;DR: 该研究提出了一种结合热成像、深度学习和车联网（CV2X）技术的实时鹿碰撞预警系统，以减少美国每年近210万起鹿车碰撞事件造成的经济损失和人员伤亡。


<details>
  <summary>Details</summary>
Motivation: 由于鹿车碰撞在美国造成严重的经济损失、人员伤亡并威胁鹿种群，因此需要一种有效的碰撞缓解系统。

Method: 该系统使用热成像技术捕捉鹿的热信号，并利用深度学习模型进行实时检测。当检测到高概率碰撞风险时，通过CV2X技术向周边车辆和路侧单元发送预警信息，最终实现从检测到预警的端到端延迟低于100毫秒。

Result: 该系统在自定义数据集上实现了98.84%的平均精度，95.44%的精确率和95.96%的召回率。在实际场地测试中，该系统在各种天气条件下均表现稳健，热成像技术的检测准确率在88%-92%之间，远高于可见光相机（低于60%）。

Conclusion: 该研究验证了结合热成像和车联网技术是减少鹿车碰撞的可行途径。

Abstract: Deer-vehicle collisions represent a critical safety challenge in the United
States, causing nearly 2.1 million incidents annually and resulting in
approximately 440 fatalities, 59,000 injuries, and 10 billion USD in economic
damages. These collisions also contribute significantly to declining deer
populations. This paper presents a real-time detection and driver warning
system that integrates thermal imaging, deep learning, and
vehicle-to-everything communication to help mitigate deer-vehicle collisions.
Our system was trained and validated on a custom dataset of over 12,000 thermal
deer images collected in Mars Hill, North Carolina. Experimental evaluation
demonstrates exceptional performance with 98.84 percent mean average precision,
95.44 percent precision, and 95.96 percent recall. The system was field tested
during a follow-up visit to Mars Hill and readily sensed deer providing the
driver with advanced warning. Field testing validates robust operation across
diverse weather conditions, with thermal imaging maintaining between 88 and 92
percent detection accuracy in challenging scenarios where conventional visible
light based cameras achieve less than 60 percent effectiveness. When a high
probability threshold is reached sensor data sharing messages are broadcast to
surrounding vehicles and roadside units via cellular vehicle to everything
(CV2X) communication devices. Overall, our system achieves end to end latency
consistently under 100 milliseconds from detection to driver alert. This
research establishes a viable technological pathway for reducing deer-vehicle
collisions through thermal imaging and connected vehicles.

</details>


### [72] [Failure Makes the Agent Stronger: Enhancing Accuracy through Structured Reflection for Reliable Tool Interactions](https://arxiv.org/abs/2509.18847)
*Junhao Su,Yuanliang Wan,Junwei Yang,Hengyu Shi,Tianyang Han,Junfeng Luo,Yurui Qiu*

Main category: cs.CV

TL;DR: 提出一种名为“结构化反思”的新方法，通过明确诊断和修复错误来提高工具增强型大语言模型的可靠性，并在 Tool-Reflection-Bench 这一新基准上进行了验证。


<details>
  <summary>Details</summary>
Motivation: 当前工具增强型大语言模型在多轮交互中容易重复犯错，因为它们依赖于启发式提示或单向推理，缺乏有效的错误诊断和修复机制。

Method: 提出“结构化反思”方法，将从错误到修复的过程视为一个明确、可控且可训练的动作。该方法包括诊断失败（使用先前步骤的证据）并提出正确、可执行的后续调用。训练结合了 DAPO 和 GSPO 目标以及针对工具使用的奖励机制，优化了“反思，然后调用，然后最终确定”的步骤策略。创建了一个名为 Tool-Reflection-Bench 的基准来评估模型。

Result: 在 BFCL v3 和 Tool-Reflection-Bench 上的实验表明，该方法显著提高了多轮工具调用成功率和错误恢复能力，并减少了冗余调用。

Conclusion: 使反思明确化并直接对其进行优化，可以提高工具交互的可靠性，并为智能体从失败中学习提供可复现的途径。

Abstract: Tool-augmented large language models (LLMs) are usually trained with
supervised imitation or coarse-grained reinforcement learning that optimizes
single tool calls. Current self-reflection practices rely on heuristic prompts
or one-way reasoning: the model is urged to 'think more' instead of learning
error diagnosis and repair. This is fragile in multi-turn interactions; after a
failure the model often repeats the same mistake. We propose structured
reflection, which turns the path from error to repair into an explicit,
controllable, and trainable action. The agent produces a short yet precise
reflection: it diagnoses the failure using evidence from the previous step and
then proposes a correct, executable follow-up call. For training we combine
DAPO and GSPO objectives with a reward scheme tailored to tool use, optimizing
the stepwise strategy Reflect, then Call, then Final. To evaluate, we introduce
Tool-Reflection-Bench, a lightweight benchmark that programmatically checks
structural validity, executability, parameter correctness, and result
consistency. Tasks are built as mini trajectories of erroneous call,
reflection, and corrected call, with disjoint train and test splits.
Experiments on BFCL v3 and Tool-Reflection-Bench show large gains in multi-turn
tool-call success and error recovery, and a reduction of redundant calls. These
results indicate that making reflection explicit and optimizing it directly
improves the reliability of tool interaction and offers a reproducible path for
agents to learn from failure.

</details>


### [73] [Towards Application Aligned Synthetic Surgical Image Synthesis](https://arxiv.org/abs/2509.18796)
*Danush Kumar Venkatesh,Stefanie Speidel*

Main category: cs.CV

TL;DR: SAADi框架通过使生成模型与下游模型的偏好保持一致，解决了合成数据的质量问题，从而提高了手术影像分析的性能。


<details>
  <summary>Details</summary>
Motivation: 标注手术数据稀缺，阻碍了计算机辅助介入手术的深度学习系统发展。现有扩散模型虽然能生成逼真图像，但存在数据记忆、样本不一致或多样性不足的问题，可能影响下游任务的性能。

Method: 提出SAADi框架，使扩散模型生成的样本与下游模型偏好对齐。通过构建“偏好”与“非偏好”合成图像对，并对扩散模型进行轻量级微调，使图像生成过程显式地与下游目标对齐。进一步通过迭代优化合成样本来提升性能。

Result: 在三个手术数据集上的实验表明，SAADi在分类任务上提升了7-9%，在分割任务上提升了2-10%，尤其在代表性不足的类别上改善显著。迭代优化使性能进一步提升4-10%。

Conclusion: SAADi克服了样本退化问题，确立了任务感知对齐原则，是解决数据稀缺和推进手术视觉应用的关键方法。

Abstract: The scarcity of annotated surgical data poses a significant challenge for
developing deep learning systems in computer-assisted interventions. While
diffusion models can synthesize realistic images, they often suffer from data
memorization, resulting in inconsistent or non-diverse samples that may fail to
improve, or even harm, downstream performance. We introduce \emph{Surgical
Application-Aligned Diffusion} (SAADi), a new framework that aligns diffusion
models with samples preferred by downstream models. Our method constructs pairs
of \emph{preferred} and \emph{non-preferred} synthetic images and employs
lightweight fine-tuning of diffusion models to align the image generation
process with downstream objectives explicitly. Experiments on three surgical
datasets demonstrate consistent gains of $7$--$9\%$ in classification and
$2$--$10\%$ in segmentation tasks, with the considerable improvements observed
for underrepresented classes. Iterative refinement of synthetic samples further
boosts performance by $4$--$10\%$. Unlike baseline approaches, our method
overcomes sample degradation and establishes task-aware alignment as a key
principle for mitigating data scarcity and advancing surgical vision
applications.

</details>


### [74] [VIR-Bench: Evaluating Geospatial and Temporal Understanding of MLLMs via Travel Video Itinerary Reconstruction](https://arxiv.org/abs/2509.19002)
*Hao Wang,Eiki Murata,Lingfang Zhang,Ayako Sato,So Fukuda,Ziqi Yin,Wentao Hu,Keisuke Nakao,Yusuke Nakamura,Sebastian Zwirner,Yi-Chia Chen,Hiroyuki Otomo,Hiroki Ouchi,Daisuke Kawahara*

Main category: cs.CV

TL;DR: VIR-Bench是一个新的基准，用于评估和改进多模态大语言模型（MLLMs）在长距离旅行视频理解方面的能力，它通过路线重建任务来衡量模型在地理空间和时间上的智能，并已成功应用于改进旅行规划代理。 


<details>
  <summary>Details</summary>
Motivation: 现有的视频基准主要关注室内场景或短距离户外活动，未能充分探索长距离旅行带来的挑战，而掌握长期的地理空间-时间轨迹对于下一代MLLMs在具身AI规划和导航等实际任务中至关重要。

Method: 提出VIR-Bench，一个包含200个旅行视频的新基准，并将路线重建作为一项具有挑战性的任务，旨在评估和推动MLLMs的地理空间-时间智能。

Result: 最先进的MLLMs（包括专有模型）在VIR-Bench上得分普遍不高，表明处理跨越广阔空间和时间尺度的视频具有相当大的难度。此外，通过一个案例研究，开发了一个利用VIR-Bench见解的旅行规划代理，该代理在路线推荐方面表现出显著的改进。

Conclusion: VIR-Bench不仅能有效评估模型性能，还能切实提升面向用户的应用程序的表现，如旅行规划代理。

Abstract: Recent advances in multimodal large language models (MLLMs) have
significantly enhanced video understanding capabilities, opening new
possibilities for practical applications. Yet current video benchmarks focus
largely on indoor scenes or short-range outdoor activities, leaving the
challenges associated with long-distance travel largely unexplored. Mastering
extended geospatial-temporal trajectories is critical for next-generation
MLLMs, underpinning real-world tasks such as embodied-AI planning and
navigation. To bridge this gap, we present VIR-Bench, a novel benchmark
consisting of 200 travel videos that frames itinerary reconstruction as a
challenging task designed to evaluate and push forward MLLMs'
geospatial-temporal intelligence. Experimental results reveal that
state-of-the-art MLLMs, including proprietary ones, struggle to achieve high
scores, underscoring the difficulty of handling videos that span extended
spatial and temporal scales. Moreover, we conduct an in-depth case study in
which we develop a prototype travel-planning agent that leverages the insights
gained from VIR-Bench. The agent's markedly improved itinerary recommendations
verify that our evaluation protocol not only benchmarks models effectively but
also translates into concrete performance gains in user-facing applications.

</details>


### [75] [A Kernel Space-based Multidimensional Sparse Model for Dynamic PET Image Denoising](https://arxiv.org/abs/2509.18801)
*Kuang Xiaodong,Li Bingxuan,Li Yuan,Rao Fan,Ma Gege,Xie Qingguo,Mok Greta S P,Liu Huafeng,Zhu Wentao*

Main category: cs.CV

TL;DR: 该研究提出了一种基于深度学习的动态PET图像去噪新方法，名为 neural KMDS-Net。


<details>
  <summary>Details</summary>
Motivation: 动态PET成像在帧数较少时，由于统计量有限，图像质量难以保证，尤其是在提高时间和空间分辨率方面存在挑战。

Method: 提出了一种模型驱动的神经网络，结合了核空间稀疏模型（KMDS）和端到端的神经网络，以自适应地优化参数并实现去噪。

Result: 模拟和真实数据实验结果表明，neural KMDS-Net在动态PET图像去噪方面表现优于现有方法。

Conclusion: 所提出的neural KMDS-Net能够有效提高动态PET图像的时间和空间分辨率，具有良好的去噪性能。

Abstract: Achieving high image quality for temporal frames in dynamic positron emission
tomography (PET) is challenging due to the limited statistic especially for the
short frames. Recent studies have shown that deep learning (DL) is useful in a
wide range of medical image denoising tasks. In this paper, we propose a
model-based neural network for dynamic PET image denoising. The inter-frame
spatial correlation and intra-frame structural consistency in dynamic PET are
used to establish the kernel space-based multidimensional sparse (KMDS) model.
We then substitute the inherent forms of the parameter estimation with neural
networks to enable adaptive parameters optimization, forming the end-to-end
neural KMDS-Net. Extensive experimental results from simulated and real data
demonstrate that the neural KMDS-Net exhibits strong denoising performance for
dynamic PET, outperforming previous baseline methods. The proposed method may
be used to effectively achieve high temporal and spatial resolution for dynamic
PET. Our source code is available at
https://github.com/Kuangxd/Neural-KMDS-Net/tree/main.

</details>


### [76] [ColorBlindnessEval: Can Vision-Language Models Pass Color Blindness Tests?](https://arxiv.org/abs/2509.19070)
*Zijian Ling,Han Zhang,Yazhuo Zhou,Jiahao Cui*

Main category: cs.CV

TL;DR: ColorBlindnessEval是一个评估视觉语言模型(VLMs)在模拟色盲测试的视觉对抗性场景下鲁棒性的新基准。该数据集包含500张模拟的石原测试图像， VLMs在识别嵌入在复杂视觉模式中的数字信息方面存在局限性，并且存在普遍的幻觉问题。


<details>
  <summary>Details</summary>
Motivation: 评估视觉语言模型(VLMs)在模拟色盲测试的视觉对抗性场景下的鲁棒性，并识别其局限性，特别是幻觉问题。

Method: 创建了一个包含500张模拟石原测试图像的数据集，其中嵌入了0到99的数字，并使用了是/否和开放式提示来评估9个VLMs的表现，并与人类参与者进行了比较。

Result: 实验表明，VLMs在理解对抗性环境中的数字方面存在局限性，并且存在普遍的幻觉问题。

Conclusion: 现有的VLMs在复杂视觉环境中鲁棒性不足，需要改进。ColorBlindnessEval数据集有助于基准测试和提高VLMs在现实世界应用中的可靠性。

Abstract: This paper presents ColorBlindnessEval, a novel benchmark designed to
evaluate the robustness of Vision-Language Models (VLMs) in visually
adversarial scenarios inspired by the Ishihara color blindness test. Our
dataset comprises 500 Ishihara-like images featuring numbers from 0 to 99 with
varying color combinations, challenging VLMs to accurately recognize numerical
information embedded in complex visual patterns. We assess 9 VLMs using Yes/No
and open-ended prompts and compare their performance with human participants.
Our experiments reveal limitations in the models' ability to interpret numbers
in adversarial contexts, highlighting prevalent hallucination issues. These
findings underscore the need to improve the robustness of VLMs in complex
visual environments. ColorBlindnessEval serves as a valuable tool for
benchmarking and improving the reliability of VLMs in real-world applications
where accuracy is critical.

</details>


### [77] [Surgical Video Understanding with Label Interpolation](https://arxiv.org/abs/2509.18802)
*Garam Kim,Tae Kyeong Jeong,Juyoun Park*

Main category: cs.CV

TL;DR: 本研究提出了一种结合光流引导的分割标签插值和多任务学习的新框架，以解决机器人辅助手术（RAS）视觉数据理解中的挑战，特别是数据稀疏性和时空不平衡问题。


<details>
  <summary>Details</summary>
Motivation: 机器人辅助手术（RAS）的潜力尚未完全发挥，因为需要精确理解手术视觉数据，而以往的单任务方法和数据标注的不足（特别是像素级分割数据缺乏以及时空信息不平衡）限制了这一点。

Method: 提出了一种结合光流引导的分割标签插值和多任务学习的新框架。利用从标注的关键帧估计的光流，将标签传播到未标注的相邻帧，从而丰富稀疏的空间监督，平衡训练的时空信息。

Result: 该框架通过传播标签丰富了稀疏的空间监督，平衡了时空信息，提高了手术场景理解的准确性和效率，从而增强了RAS的效用。

Conclusion: 所提出的框架通过结合光流插值和多任务学习，有效解决了机器人辅助手术视觉数据理解中的关键挑战，提高了手术场景理解的准确性和效率，最终将促进RAS的应用。

Abstract: Robot-assisted surgery (RAS) has become a critical paradigm in modern
surgery, promoting patient recovery and reducing the burden on surgeons through
minimally invasive approaches. To fully realize its potential, however, a
precise understanding of the visual data generated during surgical procedures
is essential. Previous studies have predominantly focused on single-task
approaches, but real surgical scenes involve complex temporal dynamics and
diverse instrument interactions that limit comprehensive understanding.
Moreover, the effective application of multi-task learning (MTL) requires
sufficient pixel-level segmentation data, which are difficult to obtain due to
the high cost and expertise required for annotation. In particular, long-term
annotations such as phases and steps are available for every frame, whereas
short-term annotations such as surgical instrument segmentation and action
detection are provided only for key frames, resulting in a significant
temporal-spatial imbalance. To address these challenges, we propose a novel
framework that combines optical flow-based segmentation label interpolation
with multi-task learning. optical flow estimated from annotated key frames is
used to propagate labels to adjacent unlabeled frames, thereby enriching sparse
spatial supervision and balancing temporal and spatial information for
training. This integration improves both the accuracy and efficiency of
surgical scene understanding and, in turn, enhances the utility of RAS.

</details>


### [78] [Citrus-V: Advancing Medical Foundation Models with Unified Medical Image Grounding for Clinical Reasoning](https://arxiv.org/abs/2509.19090)
*Guoxin Wang,Jun Zhao,Xinyi Liu,Yanbo Liu,Xuyang Cao,Chao Li,Zhuoyun Liu,Qintian Sun,Fangru Zhou,Haoqiang Xing,Zhenhong Yang*

Main category: cs.CV

TL;DR: Citrus-V是一个多模态医学基础模型，整合了图像分析和文本推理，实现了像素级病灶定位、结构化报告生成和医生般的诊断推理。


<details>
  <summary>Details</summary>
Motivation: 现有医学成像模型过于狭窄，需要多个专用网络，限制了泛化能力。现实世界的临床应用需要精确的视觉基础、多模态集成和链式思考推理。

Method: Citrus-V模型集成了检测、分割和多模态链式思考推理，并提出了一种新颖的多模态训练方法，发布了一个包含推理、检测、分割和文档理解任务的开源数据集。

Result: Citrus-V在多个基准测试中表现优于现有的开源医学模型和专家级成像系统。

Conclusion: Citrus-V提供了一个从视觉基础到临床推理的统一流程，支持精确的病灶量化、自动化报告和可靠的第二意见。

Abstract: Medical imaging provides critical evidence for clinical diagnosis, treatment
planning, and surgical decisions, yet most existing imaging models are narrowly
focused and require multiple specialized networks, limiting their
generalization. Although large-scale language and multimodal models exhibit
strong reasoning and multi-task capabilities, real-world clinical applications
demand precise visual grounding, multimodal integration, and chain-of-thought
reasoning. We introduce Citrus-V, a multimodal medical foundation model that
combines image analysis with textual reasoning. The model integrates detection,
segmentation, and multimodal chain-of-thought reasoning, enabling pixel-level
lesion localization, structured report generation, and physician-like
diagnostic inference in a single framework. We propose a novel multimodal
training approach and release a curated open-source data suite covering
reasoning, detection, segmentation, and document understanding tasks.
Evaluations demonstrate that Citrus-V outperforms existing open-source medical
models and expert-level imaging systems across multiple benchmarks, delivering
a unified pipeline from visual grounding to clinical reasoning and supporting
precise lesion quantification, automated reporting, and reliable second
opinions.

</details>


### [79] [Hyper-Bagel: A Unified Acceleration Framework for Multimodal Understanding and Generation](https://arxiv.org/abs/2509.18824)
*Yanzuo Lu,Xin Xia,Manlin Zhang,Huafeng Kuang,Jianbin Zheng,Yuxi Ren,Xuefeng Xiao*

Main category: cs.CV

TL;DR: Hyper-Bagel 通过推测性解码和多阶段蒸馏加速多模态理解和生成任务，在多模态理解、文生图和图编辑方面实现了显著的加速，同时保持了高质量的输出。


<details>
  <summary>Details</summary>
Motivation: 现有的统一多模态模型在处理大量交织的多模态令牌时，存在扩散去噪和自回归解码带来的巨大计算开销。

Method: 提出 Hyper-Bagel 框架，采用“分而治之”策略，结合推测性解码（用于预测下一个令牌）和多阶段蒸馏（用于扩散去噪），以加速多模态理解和生成。

Result: Hyper-Bagel 在多模态理解任务上实现了超过 2 倍的加速。在生成任务方面，无损 6-NFE 模型在文生图方面实现了 16.67 倍的加速，在图编辑方面实现了 22 倍的加速，同时保持了原始模型的输出质量。此外，还开发了一个高效的 1-NFE 模型，实现了近乎实时的交互式编辑和生成，并通过对抗性蒸馏和人类反馈学习实现了高成本效益和响应速度。

Conclusion: Hyper-Bagel 框架有效解决了统一多模态模型面临的计算开销问题，通过创新的加速策略实现了在理解和生成任务上的显著性能提升，并能保持高质量的输出，为实现无缝、即时的多模态交互提供了解决方案。

Abstract: Unified multimodal models have recently attracted considerable attention for
their remarkable abilities in jointly understanding and generating diverse
content. However, as contexts integrate increasingly numerous interleaved
multimodal tokens, the iterative processes of diffusion denoising and
autoregressive decoding impose significant computational overhead. To address
this, we propose Hyper-Bagel, a unified acceleration framework designed to
simultaneously speed up both multimodal understanding and generation tasks. Our
approach uses a divide-and-conquer strategy, employing speculative decoding for
next-token prediction and a multi-stage distillation process for diffusion
denoising. The framework delivers substantial performance gains, achieving over
a 2x speedup in multimodal understanding. For generative tasks, our resulting
lossless 6-NFE model yields a 16.67x speedup in text-to-image generation and a
22x speedup in image editing, all while preserving the high-quality output of
the original model. We further develop a highly efficient 1-NFE model that
enables near real-time interactive editing and generation. By combining
advanced adversarial distillation with human feedback learning, this model
achieves ultimate cost-effectiveness and responsiveness, making complex
multimodal interactions seamless and instantaneous.

</details>


### [80] [Benchmarking Vision-Language and Multimodal Large Language Models in Zero-shot and Few-shot Scenarios: A study on Christian Iconography](https://arxiv.org/abs/2509.18839)
*Gianmarco Spinaci,Lukas Klic,Giovanni Colavizza*

Main category: cs.CV

TL;DR: 本研究评估了多模态大语言模型（LLM）和视觉语言模型（VLM）在基督教圣像学单标签分类任务中的能力，并与传统监督分类器进行比较。研究发现，Gemini-2.5 Pro和GPT-4o在部分数据集上优于ResNet50基线模型，但模型对数据集（如Wikidata）和输入信息（如类描述或少量样本）敏感。最终结论是，通用多模态LLM可用于文化遗产领域的图像分类，并可作为数字人文工作流中的元数据策展工具。


<details>
  <summary>Details</summary>
Motivation: 评估通用多模态LLM（如GPT-4o、Gemini 2.5）和VLM（如CLIP、SigLIP）在基督教圣像学单标签图像分类任务上的能力，并与传统监督分类器（ResNet50）进行性能比较。

Method: 使用ArtDL、ICONCLASS和Wikidata三个数据集，包含前10个最常见类别。在三种条件下测试模型：1）使用类别标签进行分类；2）提供Iconclass描述；3）进行包含五个样本的少样本学习。将结果与在相同数据集上微调的ResNet50基线进行比较。

Result: Gemini-2.5 Pro和GPT-4o在部分数据集上表现优于ResNet50基线。Wikidata数据集上的准确率显著下降，但Siglip在该数据集上达到最高准确率。在提示中添加类别描述通常能提高零样本性能，而少样本学习效果不佳。多模态LLM能够处理视觉复杂的文化遗产领域的分类任务。

Conclusion: 通用多模态LLM能够胜任视觉复杂文化遗产领域的图像分类任务，并可作为数字人文工作流中的元数据策展工具。未来的研究应集中于优化提示和探索其他分类策略及模型。

Abstract: This study evaluates the capabilities of Multimodal Large Language Models
(LLMs) and Vision Language Models (VLMs) in the task of single-label
classification of Christian Iconography. The goal was to assess whether
general-purpose VLMs (CLIP and SigLIP) and LLMs, such as GPT-4o and Gemini 2.5,
can interpret the Iconography, typically addressed by supervised classifiers,
and evaluate their performance. Two research questions guided the analysis:
(RQ1) How do multimodal LLMs perform on image classification of Christian
saints? And (RQ2), how does performance vary when enriching input with
contextual information or few-shot exemplars? We conducted a benchmarking study
using three datasets supporting Iconclass natively: ArtDL, ICONCLASS, and
Wikidata, filtered to include the top 10 most frequent classes. Models were
tested under three conditions: (1) classification using class labels, (2)
classification with Iconclass descriptions, and (3) few-shot learning with five
exemplars. Results were compared against ResNet50 baselines fine-tuned on the
same datasets. The findings show that Gemini-2.5 Pro and GPT-4o outperformed
the ResNet50 baselines. Accuracy dropped significantly on the Wikidata dataset,
where Siglip reached the highest accuracy score, suggesting model sensitivity
to image size and metadata alignment. Enriching prompts with class descriptions
generally improved zero-shot performance, while few-shot learning produced
lower results, with only occasional and minimal increments in accuracy. We
conclude that general-purpose multimodal LLMs are capable of classification in
visually complex cultural heritage domains. These results support the
application of LLMs as metadata curation tools in digital humanities workflows,
suggesting future research on prompt optimization and the expansion of the
study to other classification strategies and models.

</details>


### [81] [ViG-LRGC: Vision Graph Neural Networks with Learnable Reparameterized Graph Construction](https://arxiv.org/abs/2509.18840)
*Ismael Elsharkawi,Hossam Sharara,Ahmed Rafea*

Main category: cs.CV

TL;DR: ViG-LRGC是一种用于图像的新型图神经网络，它通过可学习的参数自动构建图结构，解决了现有方法的局限性，并在ImageNet-1k上取得了先进的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的视觉图神经网络（ViG）在构建节点图时依赖于非参数化、不可学习的统计方法，可能无法选择最佳邻域，并且需要超参数搜索。

Method: 提出了一种可学习的重参数化图构建（LRGC）方法，通过键查询注意力机制计算节点间的关系，并使用软阈值重参数化进行边选择，实现了可微分的、无超参数的图构建。

Result: 在ImageNet-1k数据集上，提出的ViG-LRGC模型在相似模型尺寸下，性能优于现有的ViG模型。

Conclusion: LRGC提供了一种新颖的、可学习的、无超参数的图构建方法，能够为ViG模型带来性能提升，并解决了现有方法的局限性。

Abstract: Image Representation Learning is an important problem in Computer Vision.
Traditionally, images were processed as grids, using Convolutional Neural
Networks or as a sequence of visual tokens, using Vision Transformers.
Recently, Vision Graph Neural Networks (ViG) have proposed the treatment of
images as a graph of nodes; which provides a more intuitive image
representation. The challenge is to construct a graph of nodes in each layer
that best represents the relations between nodes and does not need a
hyper-parameter search. ViG models in the literature depend on
non-parameterized and non-learnable statistical methods that operate on the
latent features of nodes to create a graph. This might not select the best
neighborhood for each node. Starting from k-NN graph construction to HyperGraph
Construction and Similarity-Thresholded graph construction, these methods lack
the ability to provide a learnable hyper-parameter-free graph construction
method. To overcome those challenges, we present the Learnable Reparameterized
Graph Construction (LRGC) for Vision Graph Neural Networks. LRGC applies
key-query attention between every pair of nodes; then uses soft-threshold
reparameterization for edge selection, which allows the use of a differentiable
mathematical model for training. Using learnable parameters to select the
neighborhood removes the bias that is induced by any clustering or thresholding
methods previously introduced in the literature. In addition, LRGC allows
tuning the threshold in each layer to the training data since the thresholds
are learnable through training and are not provided as hyper-parameters to the
model. We demonstrate that the proposed ViG-LRGC approach outperforms
state-of-the-art ViG models of similar sizes on the ImageNet-1k benchmark
dataset.

</details>


### [82] [Attack for Defense: Adversarial Agents for Point Prompt Optimization Empowering Segment Anything Model](https://arxiv.org/abs/2509.18891)
*Xueyu Liu,Xiaoyi Zhang,Guangze Shi,Meilin Liu,Yexin Lai,Yongfei Wu,Mingqiang Wei*

Main category: cs.CV

TL;DR: Point Prompt Defender是一个对抗性强化学习框架，通过自动优化点提示来提高SAM模型的分割性能和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有SAM模型依赖于启发式或手动设计的提示，限制了可扩展性和泛化能力。

Method: 该框架构建了一个无任务的点提示环境，将图像块表示为双空间图中的节点，并使用对抗性强化学习训练攻击者和防御者代理来优化提示。攻击者代理旨在最大化降低SAM的分割性能，而防御者代理则学习抑制这些破坏性提示并恢复准确性。

Result: 实验表明，Point Prompt Defender能有效提高SAM在各种任务上的分割性能、鲁棒性和泛化能力，且无需重新训练模型。

Conclusion: Point Prompt Defender是一个灵活、可解释且即插即用的框架，用于基于提示的分割。

Abstract: Prompt quality plays a critical role in the performance of the Segment
Anything Model (SAM), yet existing approaches often rely on heuristic or
manually crafted prompts, limiting scalability and generalization. In this
paper, we propose Point Prompt Defender, an adversarial reinforcement learning
framework that adopts an attack-for-defense paradigm to automatically optimize
point prompts. We construct a task-agnostic point prompt environment by
representing image patches as nodes in a dual-space graph, where edges encode
both physical and semantic distances. Within this environment, an attacker
agent learns to activate a subset of prompts that maximally degrade SAM's
segmentation performance, while a defender agent learns to suppress these
disruptive prompts and restore accuracy. Both agents are trained using Deep
Q-Networks with a reward signal based on segmentation quality variation. During
inference, only the defender is deployed to refine arbitrary coarse prompt
sets, enabling enhanced SAM segmentation performance across diverse tasks
without retraining. Extensive experiments show that Point Prompt Defender
effectively improves SAM's robustness and generalization, establishing a
flexible, interpretable, and plug-and-play framework for prompt-based
segmentation.

</details>


### [83] [SmartWilds: Multimodal Wildlife Monitoring Dataset](https://arxiv.org/abs/2509.18894)
*Jenna Kline,Anirudh Potlapally,Bharath Pillai,Tanishka Wani,Rugved Katole,Vedant Patil,Penelope Covey,Hari Subramoni,Tanya Berger-Wolf,Christopher Stewart*

Main category: cs.CV

TL;DR: SmartWilds 是一个包含无人机影像、相机陷阱照片和视频以及生物声学记录的多模态野生动物监测数据集，支持多模态人工智能研究，以应对濒危物种研究、保护生态学和栖息地管理的关键需求。


<details>
  <summary>Details</summary>
Motivation: 支持多模态人工智能研究，以应对濒危物种研究、保护生态学和栖息地管理的关键需求。

Method: 收集了2025年夏季在俄亥俄州野生动物保护区的同步多模态数据（无人机影像、相机陷阱照片和视频、生物声学记录），并对传感器模态性能进行了比较分析。

Result: 展示了传感器模态在土地利用模式、物种检测、行为分析和栖息地监测方面的互补优势。

Conclusion: 建立了可重复的多模态野生动物监测协议，并贡献了开放数据集，以推进保护计算机视觉研究。

Abstract: We present the first release of SmartWilds, a multimodal wildlife monitoring
dataset. SmartWilds is a synchronized collection of drone imagery, camera trap
photographs and videos, and bioacoustic recordings collected during summer 2025
at The Wilds safari park in Ohio. This dataset supports multimodal AI research
for comprehensive environmental monitoring, addressing critical needs in
endangered species research, conservation ecology, and habitat management. Our
pilot deployment captured four days of synchronized monitoring across three
modalities in a 220-acre pasture containing Pere David's deer, Sichuan takin,
Przewalski's horses, as well as species native to Ohio, including bald eagles,
white-tailed deer, and coyotes. We provide a comparative analysis of sensor
modality performance, demonstrating complementary strengths for landuse
patterns, species detection, behavioral analysis, and habitat monitoring. This
work establishes reproducible protocols for multimodal wildlife monitoring
while contributing open datasets to advance conservation computer vision
research. Future releases will include synchronized GPS tracking data from
tagged individuals, citizen science data, and expanded temporal coverage across
multiple seasons.

</details>


### [84] [RS3DBench: A Comprehensive Benchmark for 3D Spatial Perception in Remote Sensing](https://arxiv.org/abs/2509.18897)
*Jiayu Wang,Ruizhi Wang,Jie Song,Haofei Zhang,Mingli Song,Zunlei Feng,Li Sun*

Main category: cs.CV

TL;DR: 该论文提出了一个名为RS3DBench的新型基准，用于推动遥感图像通用大模型3D视觉的发展。该基准包含54,951对遥感图像及其像素级对齐的深度图和文本描述，解决了现有数据集深度信息不全或对齐不精确的问题。此外，论文还介绍了一个基于stable diffusion的遥感深度估计模型，并在该基准上取得了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的遥感数据集在深度信息或深度图与遥感图像的精确对齐方面存在不足，阻碍了通用大模型3D视觉的发展。

Method: 构建了一个包含54,951对遥感图像、像素级对齐的深度图和文本描述的大规模数据集RS3DBench。并提出了一个基于stable diffusion的遥感深度估计模型。

Result: 所提出的RS3DBench数据集为3D视觉感知模型在遥感图像空间理解任务上的训练和评估提供了工具。基于stable diffusion的模型在RS3DBench上达到了最先进的性能。

Conclusion: RS3DBench数据集和提出的模型将为遥感领域的3D视觉感知模型发展和地理智能的进步做出贡献。

Abstract: In this paper, we introduce a novel benchmark designed to propel the
advancement of general-purpose, large-scale 3D vision models for remote sensing
imagery. While several datasets have been proposed within the realm of remote
sensing, many existing collections either lack comprehensive depth information
or fail to establish precise alignment between depth data and remote sensing
images. To address this deficiency, we present a visual Benchmark for 3D
understanding of Remotely Sensed images, dubbed RS3DBench. This dataset
encompasses 54,951 pairs of remote sensing images and pixel-level aligned depth
maps, accompanied by corresponding textual descriptions, spanning a broad array
of geographical contexts. It serves as a tool for training and assessing 3D
visual perception models within remote sensing image spatial understanding
tasks. Furthermore, we introduce a remotely sensed depth estimation model
derived from stable diffusion, harnessing its multimodal fusion capabilities,
thereby delivering state-of-the-art performance on our dataset. Our endeavor
seeks to make a profound contribution to the evolution of 3D visual perception
models and the advancement of geographic artificial intelligence within the
remote sensing domain. The dataset, models and code will be accessed on the
https://rs3dbench.github.io.

</details>


### [85] [DeblurSplat: SfM-free 3D Gaussian Splatting with Event Camera for Robust Deblurring](https://arxiv.org/abs/2509.18898)
*Pengteng Li,Yunfan Lu,Pinhao Song,Weiyu Guo,Huizai Yao,F. Richard Yu,Hui Xiong*

Main category: cs.CV

TL;DR: DeblurSplat是一种创新的、无需运动恢复结构（SfM）的三维高斯泼溅（3D Gaussian Splatting）方法，它利用事件相机来解决运动模糊问题。


<details>
  <summary>Details</summary>
Motivation: 解决运动模糊问题，并避免传统SfM方法中累积的误差。

Method: 1. 利用预训练的密集立体匹配模块（DUSt3R）直接从模糊图像中获取初始点云，绕过中间的相机姿态估计。2. 引入事件流（event stream）的高动态敏感性，从事件流和模糊图像中解码出潜在的清晰图像，为场景重建优化提供精细的监督信号。

Result: DeblurSplat 在生成高保真新视角方面表现出色，并显著提高了渲染效率。

Conclusion: DeblurSplat 是一种有效的无SfM运动去模糊三维高斯泼溅方法，在生成质量和效率方面均优于现有技术。

Abstract: In this paper, we propose the first Structure-from-Motion (SfM)-free
deblurring 3D Gaussian Splatting method via event camera, dubbed DeblurSplat.
We address the motion-deblurring problem in two ways. First, we leverage the
pretrained capability of the dense stereo module (DUSt3R) to directly obtain
accurate initial point clouds from blurred images. Without calculating camera
poses as an intermediate result, we avoid the cumulative errors transfer from
inaccurate camera poses to the initial point clouds' positions. Second, we
introduce the event stream into the deblur pipeline for its high sensitivity to
dynamic change. By decoding the latent sharp images from the event stream and
blurred images, we can provide a fine-grained supervision signal for scene
reconstruction optimization. Extensive experiments across a range of scenes
demonstrate that DeblurSplat not only excels in generating high-fidelity novel
views but also achieves significant rendering efficiency compared to the SOTAs
in deblur 3D-GS.

</details>


### [86] [MoiréNet: A Compact Dual-Domain Network for Image Demoiréing](https://arxiv.org/abs/2509.18910)
*Shuwei Guo,Simin Luan,Yan Ke,Zeyd Boukhers,John See,Cong Yang*

Main category: cs.CV

TL;DR: MoiréNet是一个基于U-Net的框架，通过集成频率和空间域特征来去除Moiré图案，并在参数效率方面取得了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: Moiré图案由显示像素点阵和相机传感器网格之间的频谱混叠引起，表现为各向异性、多尺度伪影，给数字图像去Moiré带来巨大挑战。

Method: MoiréNet框架整合了方向性频率-空间编码器（DFSE）和频率-空间自适应选择器（FSAS），DFSE通过方向性差分卷积识别Moiré方向，FSAS实现精确、特征自适应的抑制。

Result: 实验证明，MoiréNet在公开和实际使用的数据集上都达到了最先进的性能，并且参数效率高，拥有5.513M参数，比ESDNet-L减少了48%。

Conclusion: MoiréNet结合了卓越的恢复质量和参数效率，非常适合智能手机摄影、工业成像和增强现实等资源受限的应用。

Abstract: Moir\'e patterns arise from spectral aliasing between display pixel lattices
and camera sensor grids, manifesting as anisotropic, multi-scale artifacts that
pose significant challenges for digital image demoir\'eing. We propose
Moir\'eNet, a convolutional neural U-Net-based framework that synergistically
integrates frequency and spatial domain features for effective artifact
removal. Moir\'eNet introduces two key components: a Directional
Frequency-Spatial Encoder (DFSE) that discerns moir\'e orientation via
directional difference convolution, and a Frequency-Spatial Adaptive Selector
(FSAS) that enables precise, feature-adaptive suppression. Extensive
experiments demonstrate that Moir\'eNet achieves state-of-the-art performance
on public and actively used datasets while being highly parameter-efficient.
With only 5.513M parameters, representing a 48% reduction compared to ESDNet-L,
Moir\'eNet combines superior restoration quality with parameter efficiency,
making it well-suited for resource-constrained applications including
smartphone photography, industrial imaging, and augmented reality.

</details>


### [87] [Frequency-Domain Decomposition and Recomposition for Robust Audio-Visual Segmentation](https://arxiv.org/abs/2509.18912)
*Yunzhe Shen,Kai Peng,Leiye Liu,Wei Ji,Jingjing Li,Miao Zhang,Yongri Piao,Huchuan Lu*

Main category: cs.CV

TL;DR: 本论文提出了一种新颖的音频-视觉分割（AVS）框架FAVS，通过在频域中进行分解和重构来解决音频和视觉模态之间固有的频域矛盾，取得了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的AVS方法忽略了音频高频信号中的噪声和视觉高频信号中的结构细节之间的固有频域矛盾，可能导致性能不佳。

Method: 提出了一种名为FAVS的新颖框架，包含两个关键模块：频域增强分解器（FDED）和协同跨模态一致性（SCMC）模块。FDED使用基于残差的迭代频域分解来区分特定于模态的语义和结构特征，SCMC利用混合专家架构通过动态专家路由来增强语义一致性和特定于模态的特征保持。

Result: FAVS框架在三个基准数据集上实现了最先进的性能，并且大量的可视化结果进一步验证了所提出的FDED和SCMC模块的有效性。

Conclusion: 所提出的FAVS框架通过在频域中进行分解和重构，有效解决了音频-视觉分割中的模态矛盾，并在实验中取得了优越的性能。

Abstract: Audio-visual segmentation (AVS) plays a critical role in multimodal machine
learning by effectively integrating audio and visual cues to precisely segment
objects or regions within visual scenes. Recent AVS methods have demonstrated
significant improvements. However, they overlook the inherent frequency-domain
contradictions between audio and visual modalities--the pervasively interfering
noise in audio high-frequency signals vs. the structurally rich details in
visual high-frequency signals. Ignoring these differences can result in
suboptimal performance. In this paper, we rethink the AVS task from a deeper
perspective by reformulating AVS task as a frequency-domain decomposition and
recomposition problem. To this end, we introduce a novel Frequency-Aware
Audio-Visual Segmentation (FAVS) framework consisting of two key modules:
Frequency-Domain Enhanced Decomposer (FDED) module and Synergistic Cross-Modal
Consistency (SCMC) module. FDED module employs a residual-based iterative
frequency decomposition to discriminate modality-specific semantics and
structural features, and SCMC module leverages a mixture-of-experts
architecture to reinforce semantic consistency and modality-specific feature
preservation through dynamic expert routing. Extensive experiments demonstrate
that our FAVS framework achieves state-of-the-art performance on three
benchmark datasets, and abundant qualitative visualizations further verify the
effectiveness of the proposed FDED and SCMC modules. The code will be released
as open source upon acceptance of the paper.

</details>


### [88] [xAI-CV: An Overview of Explainable Artificial Intelligence in Computer Vision](https://arxiv.org/abs/2509.18913)
*Nguyen Van Tu,Pham Nguyen Hai Long,Vo Hoai Viet*

Main category: cs.CV

TL;DR: 深度学习在图像分析中表现优异，但常被视为“黑箱”模型，引发可靠性担忧。可解释人工智能（xAI）应运而生，旨在揭示AI的决策过程。本文综述了xAI在视觉感知任务中的四种代表性方法：显著图、概念瓶颈模型（CBM）、原型方法和混合方法。文章分析了它们的作用机制、优缺点及评估指标，为未来的研究和应用提供指导。


<details>
  <summary>Details</summary>
Motivation: 深度学习模型在图像分析任务中表现出色，但其“黑箱”性质引发了对可靠性的担忧，尤其是在关键应用领域。为了让人们能够理解AI模型的处理和决策过程，可解释人工智能（xAI）领域应运而生。

Method: 本文综述了xAI在视觉感知任务中的四种代表性方法，包括：(i) 显著图，(ii) 概念瓶颈模型（CBM），(iii) 基于原型的模型，以及(iv) 混合方法。文章将分析这些方法的内在机制、优点和局限性，以及评估指标。

Result: 本文对xAI在视觉感知任务中的四种代表性方法进行了综述，分析了它们的作用机制、优缺点和评估指标。

Conclusion: 本文旨在为xAI在视觉感知领域的未来研究和应用提供一个全面的概述和指导。

Abstract: Deep learning has become the de facto standard and dominant paradigm in image
analysis tasks, achieving state-of-the-art performance. However, this approach
often results in "black-box" models, whose decision-making processes are
difficult to interpret, raising concerns about reliability in critical
applications. To address this challenge and provide human a method to
understand how AI model process and make decision, the field of xAI has
emerged. This paper surveys four representative approaches in xAI for visual
perception tasks: (i) Saliency Maps, (ii) Concept Bottleneck Models (CBM),
(iii) Prototype-based methods, and (iv) Hybrid approaches. We analyze their
underlying mechanisms, strengths and limitations, as well as evaluation
metrics, thereby providing a comprehensive overview to guide future research
and applications.

</details>


### [89] [LiDAR Point Cloud Image-based Generation Using Denoising Diffusion Probabilistic Models](https://arxiv.org/abs/2509.18917)
*Amirhesam Aghanouri,Cristina Olaverri-Monreal*

Main category: cs.CV

TL;DR: DDPM被用于生成合成的激光雷达点云数据，以增强自动驾驶汽车的感知能力。


<details>
  <summary>Details</summary>
Motivation: 自动驾驶汽车的成功依赖于有效的3D视觉系统，但真实的激光雷达数据收集耗时且存在噪声和稀疏性问题。因此，需要合成数据来增强模型性能。

Method: 提出了一种改进的DDPM模型，采用新的噪声调度和时间步嵌入技术来生成高质量的合成激光雷达点云数据。

Result: 在IAMCV和KITTI-360数据集上进行了广泛评估，结果表明所提出的方法在点云生成质量和下游感知任务性能上优于现有基线，并能有效缓解噪声和稀疏数据的影响。

Conclusion: 所提出的改进DDPM方法能够生成高质量、多样化的合成激光雷达点云数据，有助于提升自动驾驶汽车的感知能力，特别是在处理噪声和稀疏数据时。

Abstract: Autonomous vehicles (AVs) are expected to revolutionize transportation by
improving efficiency and safety. Their success relies on 3D vision systems that
effectively sense the environment and detect traffic agents. Among sensors AVs
use to create a comprehensive view of surroundings, LiDAR provides
high-resolution depth data enabling accurate object detection, safe navigation,
and collision avoidance. However, collecting real-world LiDAR data is
time-consuming and often affected by noise and sparsity due to adverse weather
or sensor limitations. This work applies a denoising diffusion probabilistic
model (DDPM), enhanced with novel noise scheduling and time-step embedding
techniques to generate high-quality synthetic data for augmentation, thereby
improving performance across a range of computer vision tasks, particularly in
AV perception. These modifications impact the denoising process and the model's
temporal awareness, allowing it to produce more realistic point clouds based on
the projection. The proposed method was extensively evaluated under various
configurations using the IAMCV and KITTI-360 datasets, with four performance
metrics compared against state-of-the-art (SOTA) methods. The results
demonstrate the model's superior performance over most existing baselines and
its effectiveness in mitigating the effects of noisy and sparse LiDAR data,
producing diverse point clouds with rich spatial relationships and structural
detail.

</details>


### [90] [Advancing Metallic Surface Defect Detection via Anomaly-Guided Pretraining on a Large Industrial Dataset](https://arxiv.org/abs/2509.18919)
*Chuni Liu,Hongjie Li,Jiaqi Du,Yangyang Hou,Qian Sun,Lei Jin,Ke Xu*

Main category: cs.CV

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: The pretraining-finetuning paradigm is a crucial strategy in metallic surface
defect detection for mitigating the challenges posed by data scarcity. However,
its implementation presents a critical dilemma. Pretraining on natural image
datasets such as ImageNet, faces a significant domain gap. Meanwhile, naive
self-supervised pretraining on in-domain industrial data is often ineffective
due to the inability of existing learning objectives to distinguish subtle
defect patterns from complex background noise and textures. To resolve this, we
introduce Anomaly-Guided Self-Supervised Pretraining (AGSSP), a novel paradigm
that explicitly guides representation learning through anomaly priors. AGSSP
employs a two-stage framework: (1) it first pretrains the model's backbone by
distilling knowledge from anomaly maps, encouraging the network to capture
defect-salient features; (2) it then pretrains the detector using pseudo-defect
boxes derived from these maps, aligning it with localization tasks. To enable
this, we develop a knowledge-enhanced method to generate high-quality anomaly
maps and collect a large-scale industrial dataset of 120,000 images.
Additionally, we present two small-scale, pixel-level labeled metallic surface
defect datasets for validation. Extensive experiments demonstrate that AGSSP
consistently enhances performance across various settings, achieving up to a
10\% improvement in mAP@0.5 and 11.4\% in mAP@0.5:0.95 compared to
ImageNet-based models. All code, pretrained models, and datasets are publicly
available at https://clovermini.github.io/AGSSP-Dev/.

</details>


### [91] [Audio-Driven Universal Gaussian Head Avatars](https://arxiv.org/abs/2509.18924)
*Kartik Teotia,Helge Rhodin,Mohit Mendiratta,Hyeongwoo Kim,Marc Habermann,Christian Theobalt*

Main category: cs.CV

TL;DR: 该研究提出了首个能够驱动真实感人像的通用面部模型，能够生成包含精细表情和动作的逼真头像，并且在唇语同步、图像质量和感知真实度方面优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 以往的面部生成方法主要关注几何变形，忽略了与语音相关的外观变化。本研究旨在解决这一问题，提出一种能够同时处理几何和外观变化的音频驱动人像合成方法。

Method: 提出了一种新颖的通用面部模型（UHAP），该模型能够将语音特征映射到包含几何和外观变化的潜在空间。该模型使用多视角视频进行训练，并结合了中性扫描数据以捕捉身份细节。此外，研究还采用了一种单目编码器来实现轻量级的个性化，使模型能够专注于捕捉目标对象的全局外观和几何特征。

Result: 该方法能够生成具有精确唇语同步、细微表情（如眉毛运动、眼神转移）以及逼真口部内部外观和运动的逼真头像。

Conclusion: 本研究提出的方法是首个能够实现详细外观建模和渲染的通用音频驱动头像模型，并在唇语同步、图像质量和感知真实度等指标上优于现有方法。

Abstract: We introduce the first method for audio-driven universal photorealistic
avatar synthesis, combining a person-agnostic speech model with our novel
Universal Head Avatar Prior (UHAP). UHAP is trained on cross-identity
multi-view videos. In particular, our UHAP is supervised with neutral scan
data, enabling it to capture the identity-specific details at high fidelity. In
contrast to previous approaches, which predominantly map audio features to
geometric deformations only while ignoring audio-dependent appearance
variations, our universal speech model directly maps raw audio inputs into the
UHAP latent expression space. This expression space inherently encodes, both,
geometric and appearance variations. For efficient personalization to new
subjects, we employ a monocular encoder, which enables lightweight regression
of dynamic expression variations across video frames. By accounting for these
expression-dependent changes, it enables the subsequent model fine-tuning stage
to focus exclusively on capturing the subject's global appearance and geometry.
Decoding these audio-driven expression codes via UHAP generates highly
realistic avatars with precise lip synchronization and nuanced expressive
details, such as eyebrow movement, gaze shifts, and realistic mouth interior
appearance as well as motion. Extensive evaluations demonstrate that our method
is not only the first generalizable audio-driven avatar model that can account
for detailed appearance modeling and rendering, but it also outperforms
competing (geometry-only) methods across metrics measuring lip-sync accuracy,
quantitative image quality, and perceptual realism.

</details>


### [92] [SynapFlow: A Modular Framework Towards Large-Scale Analysis of Dendritic Spines](https://arxiv.org/abs/2509.18926)
*Pamela Osuna-Vargas,Altug Kamacioglu,Dominik F. Aschauer,Petros E. Vlachos,Sercan Alipek,Jochen Triesch,Simon Rumpel,Matthias Kaschube*

Main category: cs.CV

TL;DR: 本研究提出了一种基于机器学习的自动化分析树突棘结构动力学的方法，解决了大规模分析中的挑战。


<details>
  <summary>Details</summary>
Motivation: 树突棘的大小与突触效率相关，因此在学习和记忆研究中，对其进行检测和追踪至关重要。然而，目前对3D+时间显微镜数据进行大规模树突棘结构动力学分析仍然困难且耗时。

Method: 研究人员开发了一个模块化的机器学习流程，包括基于Transformer的目标检测模块、整合了空间特征的深度追踪组件、利用空间一致性关联3D棘突的时序追踪模块，以及量化棘突生物学特性的特征提取单元。

Result: 该方法在开源标记棘突数据以及两项补充数据集（一项用于检测和深度追踪，一项用于时序追踪）上进行了验证，并且是第一个提供时序追踪数据集的研究。

Conclusion: 研究人员发布了数据、代码和预训练权重，为可扩展的、端到端的树突棘动力学分析奠定了基础。

Abstract: Dendritic spines are key structural components of excitatory synapses in the
brain. Given the size of dendritic spines provides a proxy for synaptic
efficacy, their detection and tracking across time is important for studies of
the neural basis of learning and memory. Despite their relevance, large-scale
analyses of the structural dynamics of dendritic spines in 3D+time microscopy
data remain challenging and labor-intense. Here, we present a modular machine
learning-based pipeline designed to automate the detection, time-tracking, and
feature extraction of dendritic spines in volumes chronically recorded with
two-photon microscopy. Our approach tackles the challenges posed by biological
data by combining a transformer-based detection module, a depth-tracking
component that integrates spatial features, a time-tracking module to associate
3D spines across time by leveraging spatial consistency, and a feature
extraction unit that quantifies biologically relevant spine properties. We
validate our method on open-source labeled spine data, and on two complementary
annotated datasets that we publish alongside this work: one for detection and
depth-tracking, and one for time-tracking, which, to the best of our knowledge,
is the first data of this kind. To encourage future research, we release our
data, code, and pre-trained weights at
https://github.com/pamelaosuna/SynapFlow, establishing a baseline for scalable,
end-to-end analysis of dendritic spine dynamics.

</details>


### [93] [No Labels Needed: Zero-Shot Image Classification with Collaborative Self-Learning](https://arxiv.org/abs/2509.18938)
*Matheus Vinícius Todescato,Joel Luís Carbonera*

Main category: cs.CV

TL;DR: 该研究提出了一种新颖的零样本图像分类框架，结合了视觉语言模型（VLM）和预训练视觉模型，在没有标注数据的情况下，通过自学习周期和置信度伪标签策略直接在测试数据上训练轻量级分类器，实现了动态适应，并在十个多样化数据集上取得了优于基线零样本方法的结果。


<details>
  <summary>Details</summary>
Motivation: 深度学习模型（如CNNs和ViTs）在分类任务上表现出色，但通常需要大量标注数据，这在数据稀缺的实际场景中是一个主要障碍。视觉语言模型（VLMs）和带有预训练视觉模型的迁移学习是解决此问题的有希望的技术。

Method: 提出了一种结合VLM和预训练视觉模型的新颖零样本图像分类框架。该框架利用置信度伪标签策略，在仅有类别名称且无标注训练数据的情况下，直接在测试数据上训练一个轻量级分类器，以实现动态适应。VLM识别高置信度样本，预训练视觉模型增强其视觉表示，然后这些增强的特征迭代地训练分类器，从而在无监督的情况下捕获互补的语义和视觉线索。该方法避免了VLM微调和大型语言模型的使用，通过依赖纯视觉模型来减少对语义表示的依赖。

Result: 在十个多样化的数据集上的实验评估表明，该方法优于基线的零样本方法。

Conclusion: 所提出的零样本图像分类框架能够有效地在没有标注数据的情况下进行学习和动态适应，并且在多个数据集上展现出优越的性能。

Abstract: While deep learning, including Convolutional Neural Networks (CNNs) and
Vision Transformers (ViTs), has significantly advanced classification
performance, its typical reliance on extensive annotated datasets presents a
major obstacle in many practical scenarios where such data is scarce.
Vision-language models (VLMs) and transfer learning with pre-trained visual
models appear as promising techniques to deal with this problem. This paper
proposes a novel zero-shot image classification framework that combines a VLM
and a pre-trained visual model within a self-learning cycle. Requiring only the
set of class names and no labeled training data, our method utilizes a
confidence-based pseudo-labeling strategy to train a lightweight classifier
directly on the test data, enabling dynamic adaptation. The VLM identifies
high-confidence samples, and the pre-trained visual model enhances their visual
representations. These enhanced features then iteratively train the classifier,
allowing the system to capture complementary semantic and visual cues without
supervision. Notably, our approach avoids VLM fine-tuning and the use of large
language models, relying on the visual-only model to reduce the dependence on
semantic representation. Experimental evaluations on ten diverse datasets
demonstrate that our approach outperforms the baseline zero-shot method.

</details>


### [94] [Seeing Through Reflections: Advancing 3D Scene Reconstruction in Mirror-Containing Environments with Gaussian Splatting](https://arxiv.org/abs/2509.18956)
*Zijing Guo,Yunyang Zhao,Lin Wang*

Main category: cs.CV

TL;DR: MirrorScene3D数据集和ReflectiveGS方法提升了在包含镜子的复杂三维场景重建的性能。


<details>
  <summary>Details</summary>
Motivation: 现有三维重建方法在处理镜子表面时存在不足，未能有效利用镜面反射的丰富信息，导致重建质量下降。本研究旨在解决这一问题，并提出新的数据集和方法来改进镜子环境中三维重建的性能。

Method: 提出名为ReflectiveGS的扩展方法，该方法将3D高斯泼溅（3DGS）进行扩展，将镜面反射视为补充视角而非简单的对称伪影，以此来增强场景几何和恢复缺失细节。同时，构建了一个名为MirrorScene3D的数据集，包含多样化的室内场景、高质量图像和标注的镜子蒙版，用于评估反射环境下的重建方法。

Result: 在MirrorScene3D数据集上的实验表明，ReflectiveGaussian在SSIM、PSNR、LPIPS和训练速度方面均优于现有方法，为镜子丰富的三维重建设定了新的基准。

Conclusion: ReflectiveGS方法能够有效地利用镜面反射信息，显著提高了在包含镜子复杂场景下的三维重建质量和效率，并在MirrorScene3D数据集上取得了领先性能。

Abstract: Mirror-containing environments pose unique challenges for 3D reconstruction
and novel view synthesis (NVS), as reflective surfaces introduce view-dependent
distortions and inconsistencies. While cutting-edge methods such as Neural
Radiance Fields (NeRF) and 3D Gaussian Splatting (3DGS) excel in typical
scenes, their performance deteriorates in the presence of mirrors. Existing
solutions mainly focus on handling mirror surfaces through symmetry mapping but
often overlook the rich information carried by mirror reflections. These
reflections offer complementary perspectives that can fill in absent details
and significantly enhance reconstruction quality. To advance 3D reconstruction
in mirror-rich environments, we present MirrorScene3D, a comprehensive dataset
featuring diverse indoor scenes, 1256 high-quality images, and annotated mirror
masks, providing a benchmark for evaluating reconstruction methods in
reflective settings. Building on this, we propose ReflectiveGS, an extension of
3D Gaussian Splatting that utilizes mirror reflections as complementary
viewpoints rather than simple symmetry artifacts, enhancing scene geometry and
recovering absent details. Experiments on MirrorScene3D show that
ReflectiveGaussian outperforms existing methods in SSIM, PSNR, LPIPS, and
training speed, setting a new benchmark for 3D reconstruction in mirror-rich
environments.

</details>


### [95] [Generative data augmentation for biliary tract detection on intraoperative images](https://arxiv.org/abs/2509.18958)
*Cristina Iacono,Mariarosaria Meola,Federica Conte,Laura Mecozzi,Umberto Bracale,Pietro Falco,Fanny Ficuciello*

Main category: cs.CV

TL;DR: 深度学习被用于腹腔镜胆囊切除术中胆管的可视化，以降低胆管损伤的风险。


<details>
  <summary>Details</summary>
Motivation: 为了降低胆囊切除术中胆管损伤的风险，需要提高术中胆管的可视化水平。

Method: 利用深度学习（Yolo检测算法）和生成对抗网络（GAN）来训练模型，以从白光图像中定位胆道。

Result: 实验结果已讨论。

Conclusion: 通过深度学习提高胆管可视化水平，有望降低胆管损伤风险。

Abstract: Cholecystectomy is one of the most frequently performed procedures in
gastrointestinal surgery, and the laparoscopic approach is the gold standard
for symptomatic cholecystolithiasis and acute cholecystitis. In addition to the
advantages of a significantly faster recovery and better cosmetic results, the
laparoscopic approach bears a higher risk of bile duct injury, which has a
significant impact on quality of life and survival. To avoid bile duct injury,
it is essential to improve the intraoperative visualization of the bile duct.
This work aims to address this problem by leveraging a deep-learning approach
for the localization of the biliary tract from white-light images acquired
during the surgical procedures. To this end, the construction and annotation of
an image database to train the Yolo detection algorithm has been employed.
Besides classical data augmentation techniques, the paper proposes Generative
Adversarial Network (GAN) for the generation of a synthetic portion of the
training dataset. Experimental results have been discussed along with ethical
considerations.

</details>


### [96] [Prompt-DAS: Annotation-Efficient Prompt Learning for Domain Adaptive Semantic Segmentation of Electron Microscopy Images](https://arxiv.org/abs/2509.18973)
*Jiabao Chen,Shan Xiong,Jialin Peng*

Main category: cs.CV

TL;DR: Prompt-DAS是一个可提示的多任务框架，用于对大规模电子显微镜图像中的细胞器实例进行域自适应分割，能够处理不同数量的提示，并支持无监督域自适应（UDA）、弱监督域自适应（WDA）和交互式分割。


<details>
  <summary>Details</summary>
Motivation: 大规模电子显微镜图像的细胞器实例分割的域自适应分割（DAS）是一种实现高效标注学习的有前景的方法。

Method: 提出了一种名为Prompt-DAS的可提示多任务框架，该框架在自适应训练和测试阶段都可以灵活地使用任意数量的点提示。通过引入辅助中心点检测任务，Prompt-DAS可以处理全点、稀疏点甚至无点的情况。此外，还提出了一种新颖的提示引导对比学习方法来增强区分性特征学习。

Result: 在具有挑战性的基准测试上进行了全面的实验，结果表明所提出的方法在现有的UDA、WDA和基于SAM的方法上都更有效。

Conclusion: Prompt-DAS通过其灵活性和新颖的组件，在电子显微镜图像的细胞器实例分割方面取得了优于现有方法的性能。

Abstract: Domain adaptive segmentation (DAS) of numerous organelle instances from
large-scale electron microscopy (EM) is a promising way to enable
annotation-efficient learning. Inspired by SAM, we propose a promptable
multitask framework, namely Prompt-DAS, which is flexible enough to utilize any
number of point prompts during the adaptation training stage and testing stage.
Thus, with varying prompt configurations, Prompt-DAS can perform unsupervised
domain adaptation (UDA) and weakly supervised domain adaptation (WDA), as well
as interactive segmentation during testing. Unlike the foundation model SAM,
which necessitates a prompt for each individual object instance, Prompt-DAS is
only trained on a small dataset and can utilize full points on all instances,
sparse points on partial instances, or even no points at all, facilitated by
the incorporation of an auxiliary center-point detection task. Moreover, a
novel prompt-guided contrastive learning is proposed to enhance discriminative
feature learning. Comprehensive experiments conducted on challenging benchmarks
demonstrate the effectiveness of the proposed approach over existing UDA, WDA,
and SAM-based approaches.

</details>


### [97] [Unveiling Chain of Step Reasoning for Vision-Language Models with Fine-grained Rewards](https://arxiv.org/abs/2509.19003)
*Honghao Chen,Xingzhou Lou,Xiaokun Feng,Kaiqi Huang,Xinlong Wang*

Main category: cs.CV

TL;DR: Chain of thought reasoning is adapted for vision-language models with a focus on step-by-step reasoning and fine-grained rewards, leading to improved performance and insights into scaling.


<details>
  <summary>Details</summary>
Motivation: Existing coarse-grained chain of thought reasoning struggles with fine-grained vision-language tasks and evaluation. This work aims to enable accurate assessment of reasoning step quality for effective reinforcement learning and inference-time scaling.

Method: The paper introduces a framework for step-level reasoning in vision-language models, including data, a process reward model (PRM), and reinforcement learning training, to facilitate fine-grained rewards and accurate step quality assessment.

Result: The proposed methods establish strong baselines with consistent improvements on challenging vision-language benchmarks, supported by thorough empirical analysis and ablation studies.

Conclusion: This work provides a baseline for vision-language models using step-level reasoning and offers insights into multimodal reasoning and inference-time scaling. The dataset, PRM, and code will be made available.

Abstract: Chain of thought reasoning has demonstrated remarkable success in large
language models, yet its adaptation to vision-language reasoning remains an
open challenge with unclear best practices. Existing attempts typically employ
reasoning chains at a coarse-grained level, which struggles to perform
fine-grained structured reasoning and, more importantly, are difficult to
evaluate the reward and quality of intermediate reasoning. In this work, we
delve into chain of step reasoning for vision-language models, enabling
assessing reasoning step quality accurately and leading to effective
reinforcement learning and inference-time scaling with fine-grained rewards. We
present a simple, effective, and fully transparent framework, including the
step-level reasoning data, process reward model (PRM), and reinforcement
learning training. With the proposed approaches, our models set strong
baselines with consistent improvements on challenging vision-language
benchmarks. More importantly, we conduct a thorough empirical analysis and
ablation study, unveiling the impact of each component and several intriguing
properties of inference-time scaling. We believe this paper serves as a
baseline for vision-language models and offers insights into more complex
multimodal reasoning. Our dataset, PRM, and code will be available at
https://github.com/baaivision/CoS.

</details>


### [98] [Weakly Supervised Food Image Segmentation using Vision Transformers and Segment Anything Model](https://arxiv.org/abs/2509.19028)
*Ioannis Sarafis,Alexandros Papadopoulos,Anastasios Delopoulos*

Main category: cs.CV

TL;DR: 提出了一种利用SAM和ViT的弱监督食物图像语义分割方法，仅使用图像级标注，通过CAM生成SAM的提示，在FoodSeg103数据集上取得了0.54的mIoU。


<details>
  <summary>Details</summary>
Motivation: 利用SAM的零样本能力和ViT的注意力机制，解决食物图像语义分割中像素级标注成本高的问题。

Method: 使用ViT（Swin Transformer）的类别激活图（CAM）为SAM生成提示，并结合图像预处理、单掩模和多掩模策略来优化SAM生成的分割掩模。

Result: 在FoodSeg103数据集上，多掩模情况下平均每个图像生成2.4个（不包括背景）掩模，mIoU达到0.54。

Conclusion: 该方法可作为加速食物图像标注任务的工具，或集成到食物和营养追踪应用中。

Abstract: In this paper, we propose a weakly supervised semantic segmentation approach
for food images which takes advantage of the zero-shot capabilities and
promptability of the Segment Anything Model (SAM) along with the attention
mechanisms of Vision Transformers (ViTs). Specifically, we use class activation
maps (CAMs) from ViTs to generate prompts for SAM, resulting in masks suitable
for food image segmentation. The ViT model, a Swin Transformer, is trained
exclusively using image-level annotations, eliminating the need for pixel-level
annotations during training. Additionally, to enhance the quality of the
SAM-generated masks, we examine the use of image preprocessing techniques in
combination with single-mask and multi-mask SAM generation strategies. The
methodology is evaluated on the FoodSeg103 dataset, generating an average of
2.4 masks per image (excluding background), and achieving an mIoU of 0.54 for
the multi-mask scenario. We envision the proposed approach as a tool to
accelerate food image annotation tasks or as an integrated component in food
and nutrition tracking applications.

</details>


### [99] [A DyL-Unet framework based on dynamic learning for Temporally Consistent Echocardiographic Segmentation](https://arxiv.org/abs/2509.19052)
*Jierui Qu,Jianchun Zhao*

Main category: cs.CV

TL;DR: DyL-UNet是一种基于动态学习的U-Net分割模型，通过构建回声动力学图（EDG）并引入心腔相位动力学注意力（CPDA）来提高超声心动图分割的时间稳定性和准确性，在CAMUS和EchoNet-Dynamic数据集上验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 超声心动图的变形和斑点噪声会导致逐帧分割不准确，影响功能估计和临床解释。现有方法在单帧分割准确性高的情况下，时间不稳定性仍然是一个问题。

Method: 提出DyL-UNet模型，包含基于Swin-Transformer的编码器-解码器分支，并通过动态学习构建回声动力学图（EDG）提取动态信息。在跳跃连接处引入心腔相位动力学注意力（CPDA），利用EDG和心腔相位信息强制执行时间一致性。

Result: DyL-UNet在CAMUS和EchoNet-Dynamic数据集上实现了与现有方法相当的分割准确性，同时显著提高了时间一致性。

Conclusion: DyL-UNet提供了一种可靠的解决方案，可用于自动化临床超声心动图分析，解决了现有方法在时间稳定性和准确性方面存在的问题。

Abstract: Accurate segmentation of cardiac anatomy in echocardiography is essential for
cardiovascular diagnosis and treatment. Yet echocardiography is prone to
deformation and speckle noise, causing frame-to-frame segmentation jitter. Even
with high accuracy in single-frame segmentation, temporal instability can
weaken functional estimates and impair clinical interpretability. To address
these issues, we propose DyL-UNet, a dynamic learning-based temporal
consistency U-Net segmentation architecture designed to achieve temporally
stable and precise echocardiographic segmentation. The framework constructs an
Echo-Dynamics Graph (EDG) through dynamic learning to extract dynamic
information from videos. DyL-UNet incorporates multiple Swin-Transformer-based
encoder-decoder branches for processing single-frame images. It further
introduces Cardiac Phase-Dynamics Attention (CPDA) at the skip connections,
which uses EDG-encoded dynamic features and cardiac-phase cues to enforce
temporal consistency during segmentation. Extensive experiments on the CAMUS
and EchoNet-Dynamic datasets demonstrate that DyL-UNet maintains segmentation
accuracy comparable to existing methods while achieving superior temporal
consistency, providing a reliable solution for automated clinical
echocardiography.

</details>


### [100] [3rd Place Report of LSVOS 2025 MeViS Track: Sa2VA-i: Improving Sa2VA Results with Consistent Training and Inference](https://arxiv.org/abs/2509.19082)
*Alexey Nekrasov,Ali Athar,Daan de Geus,Alexander Hermans,Bastian Leibe*

Main category: cs.CV

TL;DR: Sa2VA-i通过解决Sa2VA在训练和推理过程中的不一致性问题，改进了其在视频对象分割任务上的表现，并在多个基准测试中取得了新的最先进成果。


<details>
  <summary>Details</summary>
Motivation: Sa2VA模型在语言引导的密集图像和视频基础方面取得了最先进的成果，但在指代视频对象分割任务上未能发挥其全部潜力。

Method: 通过识别并解决Sa2VA在训练和推理过程中的不一致性问题，提出了改进版本Sa2VA-i。

Result: Sa2VA-i在MeViS、Ref-YT-VOS、Ref-DAVIS和ReVOS等多个视频基准测试中取得了显著的性能提升，最高可达+11.6 J&F。Sa2VA-i-1B模型在MeViS基准测试上的表现与原始Sa2VA-26B模型相当。

Conclusion: 这项工作强调了看似微小的实现细节的重要性，并为指代视频分割领域提供了有价值的见解。

Abstract: Sa2VA is a recent model for language-guided dense grounding in images and
video that achieves state-of-the-art results on multiple segmentation
benchmarks and that has become widely popular. However, we found that Sa2VA
does not perform according to its full potential for referring video object
segmentation tasks. We identify inconsistencies between training and inference
procedures as the key factor holding it back. To mitigate this issue, we
propose an improved version of Sa2VA, Sa2VA-i, that rectifies these issues and
improves the results. In fact, Sa2VA-i sets a new state of the art for multiple
video benchmarks and achieves improvements of up to +11.6 J&F on MeViS, +1.4 on
Ref-YT-VOS, +3.3 on Ref-DAVIS and +4.1 on ReVOS using the same Sa2VA
checkpoints. With our fixes, the Sa2VA-i-1B model even performs on par with the
original Sa2VA-26B model on the MeViS benchmark. We hope that this work will
show the importance of seemingly trivial implementation details and that it
will provide valuable insights for the referring video segmentation field. We
provide the code and updated models at https://github.com/kumuji/sa2va-i

</details>


### [101] [Zero-Shot Multi-Spectral Learning: Reimagining a Generalist Multimodal Gemini 2.5 Model for Remote Sensing Applications](https://arxiv.org/abs/2509.19087)
*Ganesh Mallya,Yotam Gigi,Dahun Kim,Maxim Neumann,Genady Beryozkin,Tomer Shekel,Anelia Angelova*

Main category: cs.CV

TL;DR: 该研究提出了一种训练无关的方法，将多光谱数据作为零样本输入，用于通用的多模态模型，以解决遥感领域中多光谱数据分析的挑战。


<details>
  <summary>Details</summary>
Motivation: 目前，多光谱数据的自动分析主要依赖于专门为多光谱输入训练的机器学习模型，这些模型的训练和支持成本高昂。此外，强大的通用多模态大模型无法理解专业的多光谱信号，限制了其在遥感领域的应用。

Method: 提出了一种训练无关的方法，将多光谱数据以仅零样本模式作为输入，用于在仅RGB输入上训练的通用多模态模型。该方法利用多模态模型对视觉空间的理解，并将领域特定的信息作为指令注入模型。

Result: 在陆地覆盖和土地利用分类等流行的遥感基准测试中，使用Gemini2.5模型在零样本性能上取得了显著的提升，并展示了Gemini2.5模型轻松适应新输入的特性。

Conclusion: 该研究强调了处理非标准专业输入的地理空间专业人员，能够轻松利用Gemini2.5等强大的多模态模型来加速工作，并受益于其丰富的推理和基于专业传感器数据的上下文能力。

Abstract: Multi-spectral imagery plays a crucial role in diverse Remote Sensing
applications including land-use classification, environmental monitoring and
urban planning. These images are widely adopted because their additional
spectral bands correlate strongly with physical materials on the ground, such
as ice, water, and vegetation. This allows for more accurate identification,
and their public availability from missions, such as Sentinel-2 and Landsat,
only adds to their value. Currently, the automatic analysis of such data is
predominantly managed through machine learning models specifically trained for
multi-spectral input, which are costly to train and support. Furthermore,
although providing a lot of utility for Remote Sensing, such additional inputs
cannot be used with powerful generalist large multimodal models, which are
capable of solving many visual problems, but are not able to understand
specialized multi-spectral signals.
  To address this, we propose a training-free approach which introduces new
multi-spectral data in a Zero-Shot-only mode, as inputs to generalist
multimodal models, trained on RGB-only inputs. Our approach leverages the
multimodal models' understanding of the visual space, and proposes to adapt to
inputs to that space, and to inject domain-specific information as instructions
into the model. We exemplify this idea with the Gemini2.5 model and observe
strong Zero-Shot performance gains of the approach on popular Remote Sensing
benchmarks for land cover and land use classification and demonstrate the easy
adaptability of Gemini2.5 to new inputs. These results highlight the potential
for geospatial professionals, working with non-standard specialized inputs, to
easily leverage powerful multimodal models, such as Gemini2.5, to accelerate
their work, benefiting from their rich reasoning and contextual capabilities,
grounded in the specialized sensor data.

</details>


### [102] [Investigating Traffic Accident Detection Using Multimodal Large Language Models](https://arxiv.org/abs/2509.19096)
*Ilhan Skender,Kailin Tong,Selim Solmaz,Daniel Watzenig*

Main category: cs.CV

TL;DR: 该研究评估了多模态大语言模型（MLLMs）在交通摄像头图像中零样本检测和描述交通事故的能力，并结合了YOLO、Deep SORT和SAM等视觉分析技术来提高准确性和可解释性。


<details>
  <summary>Details</summary>
Motivation: 交通安全至关重要，需要及时准确的事故检测以减少危害和加快应急响应。基于基础设施的视觉传感器能够提供可扩展、高效的解决方案，用于持续的实时监控和自动化的事故检测。本研究旨在探索大型语言模型的零样本能力，以应对真实世界中交通摄像头数据缺乏多样性和标注的挑战。

Method: 研究人员在CARLA模拟的DeepAccident数据集上评估了MLLMs在交通事故检测和描述方面的零样本能力。他们比较了Gemini 1.5、Gemini 2.0、Gemma 3和Pixtral这几个模型在没有进行任何微调的情况下进行事故识别和描述的表现。此外，他们还结合了YOLO（对象检测）、Deep SORT（多对象跟踪）和SAM（实例分割）等先进的视觉分析技术，通过增强提示来提高模型的准确性和可解释性。

Result: 在零样本设置下，Pixtral表现最佳，F1分数达到0.71，召回率为83%。通过增强提示，Gemini模型在精确度方面有所提高（例如Gemini 1.5精确度达到90%），但F1分数和召回率却显著下降。Gemma 3在各项指标上表现均衡，波动最小。

Conclusion: 研究表明，将MLLMs与先进的视觉分析技术（如YOLO、Deep SORT和SAM）相结合，在提升交通摄像头图像事故检测和描述的准确性、可解释性方面具有巨大潜力，能够有效应对真实世界应用中的数据稀疏性和多样性挑战。

Abstract: Traffic safety remains a critical global concern, with timely and accurate
accident detection essential for hazard reduction and rapid emergency response.
Infrastructure-based vision sensors offer scalable and efficient solutions for
continuous real-time monitoring, facilitating automated detection of acci-
dents directly from captured images. This research investigates the zero-shot
capabilities of multimodal large language models (MLLMs) for detecting and
describing traffic accidents using images from infrastructure cameras, thus
minimizing reliance on extensive labeled datasets. Main contributions include:
(1) Evaluation of MLLMs using the simulated DeepAccident dataset from CARLA,
explicitly addressing the scarcity of diverse, realistic, infrastructure-based
accident data through controlled simulations; (2) Comparative performance
analysis between Gemini 1.5 and 2.0, Gemma 3 and Pixtral models in acci- dent
identification and descriptive capabilities without prior fine-tuning; and (3)
Integration of advanced visual analytics, specifically YOLO for object
detection, Deep SORT for multi- object tracking, and Segment Anything (SAM) for
instance segmentation, into enhanced prompts to improve model accuracy and
explainability. Key numerical results show Pixtral as the top performer with an
F1-score of 0.71 and 83% recall, while Gemini models gained precision with
enhanced prompts (e.g., Gemini 1.5 rose to 90%) but suffered notable F1 and
recall losses. Gemma 3 offered the most balanced performance with minimal
metric fluctuation. These findings demonstrate the substantial potential of
integrating MLLMs with advanced visual analytics techniques, enhancing their
applicability in real-world automated traffic monitoring systems.

</details>


### [103] [Track-On2: Enhancing Online Point Tracking with Memory](https://arxiv.org/abs/2509.19115)
*Görkay Aydemir,Weidi Xie,Fatma Güney*

Main category: cs.CV

TL;DR: Track-On2是一个基于Transformer的在线长时点跟踪模型，通过架构改进、内存优化和合成训练策略提升了性能和效率。它采用因果处理和内存机制来处理漂移和遮挡，无需未来帧信息。在推理时，模型先进行粗粒度的块级分类，再进行精炼。实验证明，Track-On2在五个合成和真实世界基准测试中取得了最先进的成果。


<details>
  <summary>Details</summary>
Motivation: 解决在视频帧之间进行点位点的一致性识别问题，特别是在外观变化、运动和遮挡显著的情况下，并针对在线设置（逐帧跟踪）进行了优化，以适应实时和流式应用。

Method: 提出Track-On2模型，对Track-On模型进行了扩展，这是一个基于Transformer的简单而高效的在线长时跟踪模型。该模型通过架构改进、更有效的内存使用和改进的合成训练策略来提高性能和效率。它采用因果处理和内存机制来维持时间连贯性，从而在不使用未来帧的情况下处理漂移和遮挡。推理时，先进行粗粒度的块级分类，然后进行精炼。

Result: Track-On2在五个合成和真实世界基准测试中取得了最先进的成果，其性能超过了之前的在线跟踪器，甚至优于利用双向上下文的离线方法。

Conclusion: 因果、基于内存的架构，并且仅使用合成数据进行训练，是可扩展的、用于真实世界点位跟踪的有效解决方案。

Abstract: In this paper, we consider the problem of long-term point tracking, which
requires consistent identification of points across video frames under
significant appearance changes, motion, and occlusion. We target the online
setting, i.e. tracking points frame-by-frame, making it suitable for real-time
and streaming applications. We extend our prior model Track-On into Track-On2,
a simple and efficient transformer-based model for online long-term tracking.
Track-On2 improves both performance and efficiency through architectural
refinements, more effective use of memory, and improved synthetic training
strategies. Unlike prior approaches that rely on full-sequence access or
iterative updates, our model processes frames causally and maintains temporal
coherence via a memory mechanism, which is key to handling drift and occlusions
without requiring future frames. At inference, we perform coarse patch-level
classification followed by refinement. Beyond architecture, we systematically
study synthetic training setups and their impact on memory behavior, showing
how they shape temporal robustness over long sequences. Through comprehensive
experiments, Track-On2 achieves state-of-the-art results across five synthetic
and real-world benchmarks, surpassing prior online trackers and even strong
offline methods that exploit bidirectional context. These results highlight the
effectiveness of causal, memory-based architectures trained purely on synthetic
data as scalable solutions for real-world point tracking. Project page:
https://kuis-ai.github.io/track_on2

</details>


### [104] [KAMERA: Enhancing Aerial Surveys of Ice-associated Seals in Arctic Environments](https://arxiv.org/abs/2509.19129)
*Adam Romlein,Benjamin X. Hou,Yuval Boss,Cynthia L. Christman,Stacie Koslovsky,Erin E. Moreland,Jason Parham,Anthony Hoogs*

Main category: cs.CV

TL;DR: KAMERA系统通过多摄像头、多光谱同步和实时检测，将海豹和北极熊的空中调查数据集处理时间缩短了80%，并对所有数据进行了元数据标注，方便后续引用。该系统还将所有图像和检测到的动物映射到世界平面上，以准确估算调查区域并快速评估调查结果。


<details>
  <summary>Details</summary>
Motivation: 介绍KAMERA系统，一个用于多摄像头、多光谱同步以及对海豹和北极熊进行实时检测的综合系统，旨在提高冰封海域海洋哺乳动物空中调查的效率。

Method: KAMERA系统利用多摄像头、多光谱同步和标定，结合专门的软件和模型，实现对海豹和北极熊的实时检测。所有收集的数据都带有元数据，并被映射到世界平面上，以进行区域估算和结果评估。

Result: KAMERA系统在应用于阿拉斯加附近海域的冰封海豹空中调查时，与传统方法相比，数据集处理时间最多可减少80%。

Conclusion: KAMERA系统通过其多摄像头、多光谱同步和实时检测能力，显著提高了空中调查的效率和数据处理速度，并且通过将数据映射到世界平面和提供全面的元数据，便于后续的分析和评估。该系统是完全开源的，有望推动科学界的类似项目的发展。

Abstract: We introduce KAMERA: a comprehensive system for multi-camera, multi-spectral
synchronization and real-time detection of seals and polar bears. Utilized in
aerial surveys for ice-associated seals in the Bering, Chukchi, and Beaufort
seas around Alaska, KAMERA provides up to an 80% reduction in dataset
processing time over previous methods. Our rigorous calibration and hardware
synchronization enable using multiple spectra for object detection. All
collected data are annotated with metadata so they can be easily referenced
later. All imagery and animal detections from a survey are mapped onto a world
plane for accurate surveyed area estimates and quick assessment of survey
results. We hope KAMERA will inspire other mapping and detection efforts in the
scientific community, with all software, models, and schematics fully
open-sourced.

</details>


### [105] [NeuCODEX: Edge-Cloud Co-Inference with Spike-Driven Compression and Dynamic Early-Exit](https://arxiv.org/abs/2509.19156)
*Maurf Hassan,Steven Davy,Muhammad Zawish,Owais Bin Zuber,Nouman Ashraf*

Main category: cs.CV

TL;DR: NeuCODEX是一种神经形态协同推理架构，通过学习到的脉冲驱动的压缩模块和动态的早期退出机制，实现了边缘-云协同推理，显著降低了数据传输、边缘能耗和端到端延迟，同时保持了可忽略的准确性损失，使得在资源受限环境中部署SNN成为可能。


<details>
  <summary>Details</summary>
Motivation: 为了解决边缘SNN推理的延迟和能量限制以及边缘-云协同推理的高延迟和特征传输成本问题。

Method: 提出NeuCODEX神经形态协同推理架构，采用学习到的脉冲驱动压缩模块减少数据传输，并使用动态早期退出机制根据输出置信度自适应地终止推理。

Result: 在CIFAR10、Caltech、CIFAR10-DVS和N-Caltech数据集上进行评估，在ResNet-18和VGG-16骨干网络上进行原型设计。结果显示，与仅在边缘进行推理相比，NeuCODEX将数据传输减少了高达2048倍，边缘能耗降低了90%以上，端到端延迟减少了高达3倍，准确性损失不到2%。

Conclusion: NeuCODEX使得在资源受限的环境中实际部署高性能SNN成为可能。

Abstract: Spiking Neural Networks (SNNs) offer significant potential for enabling
energy-efficient intelligence at the edge. However, performing full SNN
inference at the edge can be challenging due to the latency and energy
constraints arising from fixed and high timestep overheads. Edge-cloud
co-inference systems present a promising solution, but their deployment is
often hindered by high latency and feature transmission costs. To address these
issues, we introduce NeuCODEX, a neuromorphic co-inference architecture that
jointly optimizes both spatial and temporal redundancy. NeuCODEX incorporates a
learned spike-driven compression module to reduce data transmission and employs
a dynamic early-exit mechanism to adaptively terminate inference based on
output confidence. We evaluated NeuCODEX on both static images (CIFAR10 and
Caltech) and neuromorphic event streams (CIFAR10-DVS and N-Caltech). To
demonstrate practicality, we prototyped NeuCODEX on ResNet-18 and VGG-16
backbones in a real edge-to-cloud testbed. Our proposed system reduces data
transfer by up to 2048x and edge energy consumption by over 90%, while reducing
end-to-end latency by up to 3x compared to edge-only inference, all with a
negligible accuracy drop of less than 2%. In doing so, NeuCODEX enables
practical, high-performance SNN deployment in resource-constrained
environments.

</details>


### [106] [RoSe: Robust Self-supervised Stereo Matching under Adverse Weather Conditions](https://arxiv.org/abs/2509.19165)
*Yun Wang,Junjie Hu,Junhui Hou,Chenghao Zhang,Renwei Yang,Dapeng Oliver Wu*

Main category: cs.CV

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Recent self-supervised stereo matching methods have made significant
progress, but their performance significantly degrades under adverse weather
conditions such as night, rain, and fog. We identify two primary weaknesses
contributing to this performance degradation. First, adverse weather introduces
noise and reduces visibility, making CNN-based feature extractors struggle with
degraded regions like reflective and textureless areas. Second, these degraded
regions can disrupt accurate pixel correspondences, leading to ineffective
supervision based on the photometric consistency assumption. To address these
challenges, we propose injecting robust priors derived from the visual
foundation model into the CNN-based feature extractor to improve feature
representation under adverse weather conditions. We then introduce scene
correspondence priors to construct robust supervisory signals rather than
relying solely on the photometric consistency assumption. Specifically, we
create synthetic stereo datasets with realistic weather degradations. These
datasets feature clear and adverse image pairs that maintain the same semantic
context and disparity, preserving the scene correspondence property. With this
knowledge, we propose a robust self-supervised training paradigm, consisting of
two key steps: robust self-supervised scene correspondence learning and adverse
weather distillation. Both steps aim to align underlying scene results from
clean and adverse image pairs, thus improving model disparity estimation under
adverse weather effects. Extensive experiments demonstrate the effectiveness
and versatility of our proposed solution, which outperforms existing
state-of-the-art self-supervised methods. Codes are available at
\textcolor{blue}{https://github.com/cocowy1/RoSe-Robust-Self-supervised-Stereo-Matching-under-Adverse-Weather-Conditions}.

</details>


### [107] [YOLO-LAN: Precise Polyp Detection via Optimized Loss, Augmentations and Negatives](https://arxiv.org/abs/2509.19166)
*Siddharth Gupta,Jitin Singla*

Main category: cs.CV

TL;DR: 本研究提出了一种基于YOLO的结直肠息肉检测流程YOLO-LAN，通过使用M2IoU损失、多样的数采增强和负数采来模拟真实临床情况，并在Kvasir-seg和BKAI-IGH NeoPolyp数据集上取得了优于现有方法的结果，尤其在mAP$_{50:95}$得分上显著提高，证明了其在AI辅助结直肠癌筛查中的临床相关性。


<details>
  <summary>Details</summary>
Motivation: 结直肠癌（CRC）是一种致命性疾病，其早期阶段表现为结直肠息肉。手动进行结肠镜检查以检测息肉可能不一致且容易出错。因此，基于深度学习的目标检测为在结肠镜检查期间进行更准确、实时的诊断提供了一个有前景的解决方案。

Method: 提出了一种名为YOLO-LAN的基于YOLO的息肉检测流程。该流程采用了M2IoU损失函数、多样化的数据增强技术以及负样本数据，以模拟真实的临床环境。研究人员在Kvasir-seg和BKAI-IGH NeoPolyp数据集上对该流程进行了训练和评估。

Result: 所提出的YOLO-LAN流程在Kvasir-seg和BKAI-IGH NeoPolyp数据集上表现优于现有方法。具体而言，在使用YOLOv12时，在Kvasir-seg数据集上达到了0.9619的mAP$_{50}$和0.8599的mAP$_{50:95}$；在使用YOLOv8时，则达到了0.9540的mAP$_{50}$和0.8487的mAP$_{50:95}$。mAP$_{50:95}$得分的显著提高表明了息肉检测的精确度。此外，研究证明了该方法在检测不同大小息肉和精确定位方面的鲁棒性。

Conclusion: YOLO-LAN在结直肠息肉检测方面表现出高精度和鲁棒性，特别是在mAP$_{50:95}$得分上的提升尤为显著。其在不同大小息肉检测和精确定位方面的能力，使其在AI辅助结直肠癌筛查中具有重要的临床应用价值。

Abstract: Colorectal cancer (CRC), a lethal disease, begins with the growth of abnormal
mucosal cell proliferation called polyps in the inner wall of the colon. When
left undetected, polyps can become malignant tumors. Colonoscopy is the
standard procedure for detecting polyps, as it enables direct visualization and
removal of suspicious lesions. Manual detection by colonoscopy can be
inconsistent and is subject to oversight. Therefore, object detection based on
deep learning offers a better solution for a more accurate and real-time
diagnosis during colonoscopy. In this work, we propose YOLO-LAN, a YOLO-based
polyp detection pipeline, trained using M2IoU loss, versatile data
augmentations and negative data to replicate real clinical situations. Our
pipeline outperformed existing methods for the Kvasir-seg and BKAI-IGH NeoPolyp
datasets, achieving mAP$_{50}$ of 0.9619, mAP$_{50:95}$ of 0.8599 with YOLOv12
and mAP$_{50}$ of 0.9540, mAP$_{50:95}$ of 0.8487 with YOLOv8 on the Kvasir-seg
dataset. The significant increase is achieved in mAP$_{50:95}$ score, showing
the precision of polyp detection. We show robustness based on polyp size and
precise location detection, making it clinically relevant in AI-assisted
colorectal screening.

</details>


### [108] [The 1st Solution for MOSEv2 Challenge 2025: Long-term and Concept-aware Video Segmentation via SeC](https://arxiv.org/abs/2509.19183)
*Mingqi Gao,Jingkun Chen,Yunqi Miao,Gengshen Wu,Zhijin Qin,Jungong Han*

Main category: cs.CV

TL;DR: 本项目为MOSEv2赛道提供了基于SeC增强SAM-2框架的解决方案，实现了39.89%的JF分数，并解决了遮挡、重现和干扰物等核心挑战。


<details>
  <summary>Details</summary>
Motivation: 解决复杂视频对象分割中的长期记忆和概念感知记忆问题，以应对遮挡、重现和干扰物等挑战。

Method: 分析并改编了SeC（一个增强的SAM-2框架），并研究了其长期记忆和概念感知记忆的特性。

Result: 在MOSEv2测试集上取得了39.89%的JF分数，在LSVOS挑战赛的MOSEv2赛道上排名第一。

Conclusion: 该研究表明，长期记忆和概念感知记忆共同作用，能够有效解决视频对象分割中的关键挑战，并取得了优异的竞赛成绩。

Abstract: This technical report explores the MOSEv2 track of the LSVOS Challenge, which
targets complex semi-supervised video object segmentation. By analysing and
adapting SeC, an enhanced SAM-2 framework, we conduct a detailed study of its
long-term memory and concept-aware memory, showing that long-term memory
preserves temporal continuity under occlusion and reappearance, while
concept-aware memory supplies semantic priors that suppress distractors;
together, these traits directly benefit several MOSEv2's core challenges. Our
solution achieves a JF score of 39.89% on the test set, ranking 1st in the
MOSEv2 track of the LSVOS Challenge.

</details>


### [109] [Reading Images Like Texts: Sequential Image Understanding in Vision-Language Models](https://arxiv.org/abs/2509.19191)
*Yueyan Li,Chenggong Zhao,Zeyuan Zang,Caixia Yuan,Xiaojie Wang*

Main category: cs.CV

TL;DR: 该研究受到人类视觉双流假说的启发，将视觉-语言模型（VLM）的视觉处理分解为物体识别和空间感知，以分别进行研究。


<details>
  <summary>Details</summary>
Motivation: 现有VLM的图像处理方式（串行化）与人类视觉（并行化）存在显著差异，且其不透明的内部机制阻碍了深入理解和架构创新。

Method: 将图像转换为文本标记图，分析物体识别的“内容-属性-语义”两阶段过程；理论推导并验证了VLM中位置表示的几何结构，以研究空间感知。基于这些发现，提出了一种基于即插即用视觉解码器的指令无关标记压缩算法，并采用RoPE缩放技术来提高解码效率和空间推理能力。

Result: 通过严格的实验验证了上述分析，加深了对VLM内部机制的理解，并为未来设计更强大的VLM架构提供了明确的原则。

Conclusion: 该研究通过解构VLM的视觉处理机制，提出了改进解码效率和空间推理的方法，并为VLM的未来发展提供了理论指导和实践依据。

Abstract: Vision-Language Models (VLMs) have demonstrated remarkable performance across
a variety of real-world tasks. However, existing VLMs typically process visual
information by serializing images, a method that diverges significantly from
the parallel nature of human vision. Moreover, their opaque internal mechanisms
hinder both deeper understanding and architectural innovation. Inspired by the
dual-stream hypothesis of human vision, which distinguishes the "what" and
"where" pathways, we deconstruct the visual processing in VLMs into object
recognition and spatial perception for separate study. For object recognition,
we convert images into text token maps and find that the model's perception of
image content unfolds as a two-stage process from shallow to deep layers,
beginning with attribute recognition and culminating in semantic
disambiguation. For spatial perception, we theoretically derive and empirically
verify the geometric structure underlying the positional representation in
VLMs. Based on these findings, we introduce an instruction-agnostic token
compression algorithm based on a plug-and-play visual decoder to improve
decoding efficiency, and a RoPE scaling technique to enhance spatial reasoning.
Through rigorous experiments, our work validates these analyses, offering a
deeper understanding of VLM internals and providing clear principles for
designing more capable future architectures.

</details>


### [110] [Vision-Free Retrieval: Rethinking Multimodal Search with Textual Scene Descriptions](https://arxiv.org/abs/2509.19203)
*Ioanna Ntinou,Alexandros Xenos,Yassine Ouali,Adrian Bulat,Georgios Tzimiropoulos*

Main category: cs.CV

TL;DR: 我们提出了一个不需要视觉编码器的、仅基于文本的图像检索方法，使用大型语言模型生成的图像描述，以解决现有方法理解能力浅、模态间隙大、计算成本高和隐私问题。


<details>
  <summary>Details</summary>
Motivation: 现有的对比学习视觉语言模型（VLMs）虽然在学习区分性视觉-语言表示方面表现出色，但存在语言理解肤浅、模态间隙大、训练成本高和隐私问题。

Method: 我们提出了一种仅依赖文本的、单一编码器的检索流程，利用大型语言模型生成的结构化图像描述，将检索任务从传统的“文本到图像”转变为“文本到文本”。

Result: 该方法显著减小了模态间隙，提高了组合性，在短文本和长文本查询方面均表现更优，且训练成本低。在 Flickr30k 和 COCO 数据集上创建的 subFlickr 和 subCOCO 两个基准测试中，我们的方法在检索和组合性方面取得了最先进的零样本性能，即使是参数量仅为 0.3B 的小型模型也能做到。

Conclusion: 我们证明了仅基于文本的检索方法在效率、性能和隐私方面优于传统的多模态方法，并且在各种基准测试中取得了最先进的零样本结果。

Abstract: Contrastively-trained Vision-Language Models (VLMs), such as CLIP, have
become the standard approach for learning discriminative vision-language
representations. However, these models often exhibit shallow language
understanding, manifesting bag-of-words behaviour. These limitations are
reinforced by their dual-encoder design, which induces a modality gap.
Additionally, the reliance on vast web-collected data corpora for training
makes the process computationally expensive and introduces significant privacy
concerns. To address these limitations, in this work, we challenge the
necessity of vision encoders for retrieval tasks by introducing a vision-free,
single-encoder retrieval pipeline. Departing from the traditional text-to-image
retrieval paradigm, we migrate to a text-to-text paradigm with the assistance
of VLLM-generated structured image descriptions. We demonstrate that this
paradigm shift has significant advantages, including a substantial reduction of
the modality gap, improved compositionality, and better performance on short
and long caption queries, all attainable with only a few hours of calibration
on two GPUs. Additionally, substituting raw images with textual descriptions
introduces a more privacy-friendly alternative for retrieval. To further assess
generalisation and address some of the shortcomings of prior compositionality
benchmarks, we release two benchmarks derived from Flickr30k and COCO,
containing diverse compositional queries made of short captions, which we coin
subFlickr and subCOCO. Our vision-free retriever matches and often surpasses
traditional multimodal models. Importantly, our approach achieves
state-of-the-art zero-shot performance on multiple retrieval and
compositionality benchmarks, with models as small as 0.3B parameters. Code is
available at: https://github.com/IoannaNti/LexiCLIP

</details>


### [111] [Long Story Short: Disentangling Compositionality and Long-Caption Understanding in VLMs](https://arxiv.org/abs/2509.19207)
*Israfel Salazar,Desmond Elliott,Yova Kementchedjhieva*

Main category: cs.CV

TL;DR: 对比学习视觉语言模型（VLM）在结合视觉和文本信息方面取得了显著进展，但理解长而密集的标题仍然是一个挑战。本文研究了组合性（理解对象-属性绑定和对象间关系的能力）与长标题理解之间的关系，并提出组合性是理解长标题的关键。通过训练和评估针对这两项能力的模型，研究发现组合性训练可以提高长标题检索性能，而长标题训练也能促进组合性。然而，这些提升对数据质量和模型设计很敏感。研究还发现，在结构不良的标题上训练或参数更新有限，无法支持泛化。同样，旨在保留通用对齐的策略（如冻结位置嵌入）也无法提高组合性理解能力。总的来说，组合性理解和长标题理解是相互交织的能力，可以通过在密集的、有根据的描述上进行训练来共同学习。尽管存在这些挑战，但通过在高、长标题数据上进行训练，模型可以在两项任务上都取得优异表现，为提高 VLM 泛化能力提供了实际指导。


<details>
  <summary>Details</summary>
Motivation: 对比学习视觉语言模型（VLM）在结合视觉和文本信息方面取得了显著进展，但理解长而密集的标题仍然是一个挑战。本文研究了组合性（理解对象-属性绑定和对象间关系的能力）与长标题理解之间的关系，并提出组合性是理解长标题的关键。

Method: 通过训练和评估针对组合性和长标题理解能力的一系列模型。

Result: 组合性训练可以提高长标题检索性能，而长标题训练也能促进组合性。然而，这些提升对数据质量和模型设计很敏感。在结构不良的标题上训练或参数更新有限，无法支持泛化。旨在保留通用对齐的策略（如冻结位置嵌入）也无法提高组合性理解能力。

Conclusion: 组合性理解和长标题理解是相互交织的能力，可以通过在密集的、有根据的描述上进行训练来共同学习。通过在高、长标题数据上进行训练，模型可以在两项任务上都取得优异表现，为提高 VLM 泛化能力提供了实际指导。

Abstract: Contrastive vision-language models (VLMs) have made significant progress in
binding visual and textual information, but understanding long, dense captions
remains an open challenge. We hypothesize that compositionality, the capacity
to reason about object-attribute bindings and inter-object relationships, is
key to understanding longer captions. In this paper, we investigate the
interaction between compositionality and long-caption understanding, asking
whether training for one property enhances the other. We train and evaluate a
range of models that target each of these capabilities. Our results reveal a
bidirectional relationship: compositional training improves performance on
long-caption retrieval, and training on long captions promotes
compositionality. However, these gains are sensitive to data quality and model
design. We find that training on poorly structured captions, or with limited
parameter updates, fails to support generalization. Likewise, strategies that
aim at retaining general alignment, such as freezing positional embeddings, do
not improve compositional understanding. Overall, we find that compositional
understanding and long-caption understanding are intertwined capabilities that
can be jointly learned through training on dense, grounded descriptions.
Despite these challenges, we show that models trained on high-quality,
long-caption data can achieve strong performance in both tasks, offering
practical guidance for improving VLM generalization.

</details>


### [112] [Enabling Plant Phenotyping in Weedy Environments using Multi-Modal Imagery via Synthetic and Generated Training Data](https://arxiv.org/abs/2509.19208)
*Earl Ranario,Ismael Mayanja,Heesup Yun,Brian N. Bailey,J. Mason Earles*

Main category: cs.CV

TL;DR: 利用生成对抗网络（GAN）和合成数据提高热成像中植物分割的准确性。


<details>
  <summary>Details</summary>
Motivation: 在户外环境中，低对比度和频繁的遮挡使得在热成像中准确分割植物成为高通量田间表型分析的一大挑战。

Method: 提出了一种结合合成RGB图像、少量真实标注数据和基于GAN的跨模态对齐的框架，用于增强热成像中的语义分割。利用CycleGAN-turbo将RGB图像转换为热成像，实现了无需校准的鲁棒模板匹配。

Result: 在合成数据和少量真实标注数据（包括5张真实图像）的结合下，相比仅使用真实数据的基线模型，杂草分割精度相对提高了22%，植物分割精度相对提高了17%。

Conclusion: 将合成数据、有限的手动标注和生成模型的跨域翻译相结合，能够显著提高在复杂田间环境中进行多模态图像分割的性能。

Abstract: Accurate plant segmentation in thermal imagery remains a significant
challenge for high throughput field phenotyping, particularly in outdoor
environments where low contrast between plants and weeds and frequent
occlusions hinder performance. To address this, we present a framework that
leverages synthetic RGB imagery, a limited set of real annotations, and
GAN-based cross-modality alignment to enhance semantic segmentation in thermal
images. We trained models on 1,128 synthetic images containing complex mixtures
of crop and weed plants in order to generate image segmentation masks for crop
and weed plants. We additionally evaluated the benefit of integrating as few as
five real, manually segmented field images within the training process using
various sampling strategies. When combining all the synthetic images with a few
labeled real images, we observed a maximum relative improvement of 22% for the
weed class and 17% for the plant class compared to the full real-data baseline.
Cross-modal alignment was enabled by translating RGB to thermal using
CycleGAN-turbo, allowing robust template matching without calibration. Results
demonstrated that combining synthetic data with limited manual annotations and
cross-domain translation via generative models can significantly boost
segmentation performance in complex field environments for multi-model imagery.

</details>


### [113] [HyKid: An Open MRI Dataset with Expert-Annotated Multi-Structure and Choroid Plexus in Pediatric Hydrocephalus](https://arxiv.org/abs/2509.19218)
*Yunzhi Xu,Yushuang Ding,Hu Sun,Hongxi Zhang,Li Zhao*

Main category: cs.CV

TL;DR: HyKid是一个公开的数据集，包含48名患有脑积水的儿童的3D MRI数据，并提供了详细的脑组织和脉络丛分割，以及从临床报告中提取的结构化数据。该数据集有助于脑积水评估，特别是脉络丛体积与总脑脊液体积的相关性，可作为预测模型中的潜在生物标志物。


<details>
  <summary>Details</summary>
Motivation: 现有的脑积水研究因缺乏公开的、专家标注的数据集（尤其是带有脉络丛分割的数据集）而受到限制。

Method: 创建了一个包含48名脑积水患儿的3D MRI数据集（HyKid），并由经验丰富的神经科医生对手动校正的脑组织（包括白质、灰质、侧脑室、外部脑脊液和脉络丛）进行了分割。使用检索增强生成框架从临床放射学报告中提取结构化数据。

Result: 脉络丛体积与总脑脊液体积之间存在强相关性，可作为脑积水评估的潜在生物标志物，预测模型表现优异（AUC = 0.87）。

Conclusion: 提出的HyKid数据集为神经影像算法开发提供了高质量的基准，并揭示了脉络丛相关的特征在脑积水评估中的作用。

Abstract: Evaluation of hydrocephalus in children is challenging, and the related
research is limited by a lack of publicly available, expert-annotated datasets,
particularly those with segmentation of the choroid plexus. To address this, we
present HyKid, an open-source dataset from 48 pediatric patients with
hydrocephalus. 3D MRIs were provided with 1mm isotropic resolution, which was
reconstructed from routine low-resolution images using a slice-to-volume
algorithm. Manually corrected segmentations of brain tissues, including white
matter, grey matter, lateral ventricle, external CSF, and the choroid plexus,
were provided by an experienced neurologist. Additionally, structured data was
extracted from clinical radiology reports using a Retrieval-Augmented
Generation framework. The strong correlation between choroid plexus volume and
total CSF volume provided a potential biomarker for hydrocephalus evaluation,
achieving excellent performance in a predictive model (AUC = 0.87). The
proposed HyKid dataset provided a high-quality benchmark for neuroimaging
algorithms development, and it revealed the choroid plexus-related features in
hydrocephalus assessments. Our datasets are publicly available at
https://www.synapse.org/Synapse:syn68544889.

</details>


### [114] [MsFIN: Multi-scale Feature Interaction Network for Traffic Accident Anticipation](https://arxiv.org/abs/2509.19227)
*Tongshuai Wu,Chao Lu,Ze Song,Yunlong Lin,Sizhe Fan,Xuemei Chen*

Main category: cs.CV

TL;DR: 本篇论文提出了一种名为MsFIN的多尺度特征交互网络，用于从行车记录仪视频中提前预测交通事故，解决了现有模型在处理遮挡、多时间尺度行为线索方面的不足。


<details>
  <summary>Details</summary>
Motivation: 为了应对行车记录仪广泛部署和计算机视觉技术进步的背景下，从行车记录仪视角预测事故以实现主动安全干预的关键需求，同时解决现有方法在建模交通参与者特征交互（常被遮挡）和捕捉事故前复杂、异步的多时序行为线索方面的两大挑战。

Method: 提出了一种名为MsFIN（Multi-scale Feature Interaction Network）的网络，该网络包含三个层次：多尺度特征聚合、时序特征处理和多尺度特征后融合。其中，多尺度模块提取短期、中期和长期时间尺度的场景表示，并利用Transformer促进特征交互；时序特征处理在因果约束下捕捉场景和物体特征的序列演化；最后，在多尺度特征后融合阶段，融合跨多个时间尺度的场景和物体特征，生成全面的风险表示。

Result: 在DAD和DADA数据集上的实验结果表明，MsFIN在预测正确性和提前性方面显著优于采用单一尺度特征提取的现有最先进模型。消融研究验证了MsFIN各模块的有效性，证明了该网络通过多尺度特征融合和上下文交互建模实现了卓越的性能。

Conclusion: MsFIN通过其创新的多尺度特征提取、时序信息处理和跨尺度融合机制，有效解决了行车记录仪视频交通事故预测中的关键挑战，显著提升了预测的准确性和提前性。

Abstract: With the widespread deployment of dashcams and advancements in computer
vision, developing accident prediction models from the dashcam perspective has
become critical for proactive safety interventions. However, two key challenges
persist: modeling feature-level interactions among traffic participants (often
occluded in dashcam views) and capturing complex, asynchronous multi-temporal
behavioral cues preceding accidents. To deal with these two challenges, a
Multi-scale Feature Interaction Network (MsFIN) is proposed for early-stage
accident anticipation from dashcam videos. MsFIN has three layers for
multi-scale feature aggregation, temporal feature processing and multi-scale
feature post fusion, respectively. For multi-scale feature aggregation, a
Multi-scale Module is designed to extract scene representations at short-term,
mid-term and long-term temporal scales. Meanwhile, the Transformer architecture
is leveraged to facilitate comprehensive feature interactions. Temporal feature
processing captures the sequential evolution of scene and object features under
causal constraints. In the multi-scale feature post fusion stage, the network
fuses scene and object features across multiple temporal scales to generate a
comprehensive risk representation. Experiments on DAD and DADA datasets show
that MsFIN significantly outperforms state-of-the-art models with single-scale
feature extraction in both prediction correctness and earliness. Ablation
studies validate the effectiveness of each module in MsFIN, highlighting how
the network achieves superior performance through multi-scale feature fusion
and contextual interaction modeling.

</details>


### [115] [DevFD: Developmental Face Forgery Detection by Learning Shared and Orthogonal LoRA Subspaces](https://arxiv.org/abs/2509.19230)
*Tianshuo Zhang,Li Gao,Siran Peng,Xiangyu Zhu,Zhen Lei*

Main category: cs.CV

TL;DR: 数字人脸生成与操纵的社会风险日益增加，现有检测模型难以跟上技术演进。本文提出一种持续学习方法，通过开发性混合专家（MoE）架构，利用LoRA模型作为专家，结合Real-LoRA学习真实人脸，以及多个Fake-LoRA捕捉新型伪造人脸，并采用正交梯度和损失函数防止灾难性遗忘和梯度干扰，实验证明了该方法的有效性。


<details>
  <summary>Details</summary>
Motivation: 现有的人脸伪造检测模型难以应对快速演进的生成技术，需要一种能够快速适应新域、少量数据、避免遗忘旧类型的方法。

Method: 采用开发性混合专家（MoE）架构，以LoRA模型作为专家。将LoRA分为两组：Real-LoRA（学习真实人脸）和多个Fake-LoRA（学习不同伪造类型）。为防止灾难性遗忘，确保Fake-LoRA的学习方向与已有子空间正交，并集成正交梯度到Fake-LoRA的正交损失中，以防止训练过程中的梯度干扰。

Result: 在数据集和操纵类型增量协议下，实验结果证明了该方法的有效性。

Conclusion: 所提出的基于开发性混合专家（MoE）和LoRA的持续学习方法，能够有效应对不断变化的人脸伪造技术，并在防止灾难性遗忘方面表现出色。

Abstract: The rise of realistic digital face generation and manipulation poses
significant social risks. The primary challenge lies in the rapid and diverse
evolution of generation techniques, which often outstrip the detection
capabilities of existing models. To defend against the ever-evolving new types
of forgery, we need to enable our model to quickly adapt to new domains with
limited computation and data while avoiding forgetting previously learned
forgery types. In this work, we posit that genuine facial samples are abundant
and relatively stable in acquisition methods, while forgery faces continuously
evolve with the iteration of manipulation techniques. Given the practical
infeasibility of exhaustively collecting all forgery variants, we frame face
forgery detection as a continual learning problem and allow the model to
develop as new forgery types emerge. Specifically, we employ a Developmental
Mixture of Experts (MoE) architecture that uses LoRA models as its individual
experts. These experts are organized into two groups: a Real-LoRA to learn and
refine knowledge of real faces, and multiple Fake-LoRAs to capture incremental
information from different forgery types. To prevent catastrophic forgetting,
we ensure that the learning direction of Fake-LoRAs is orthogonal to the
established subspace. Moreover, we integrate orthogonal gradients into the
orthogonal loss of Fake-LoRAs, preventing gradient interference throughout the
training process of each task. Experimental results under both the datasets and
manipulation types incremental protocols demonstrate the effectiveness of our
method.

</details>


### [116] [Lavida-O: Elastic Masked Diffusion Models for Unified Multimodal Understanding and Generation](https://arxiv.org/abs/2509.19244)
*Shufan Li,Jiuxiang Gu,Kangning Liu,Zhe Lin,Zijun Wei,Aditya Grover,Jason Kuen*

Main category: cs.CV

TL;DR: Lavida-O是一个统一的多模态掩码扩散模型（MDM），能够执行图像理解和生成任务，并在物体识别、图像编辑和高分辨率图像合成方面表现出色。


<details>
  <summary>Details</summary>
Motivation: 现有模型在多模态理解和图像生成方面存在局限性，Lavida-O旨在通过统一的MDM解决这些问题，并实现更高级的功能。

Method: Lavida-O采用了一种新颖的弹性混合Transformer架构，并结合了通用文本条件和分层采样等技术，以实现高效的训练和采样。

Result: Lavida-O在物体识别、文本到图像生成和图像编辑等多个基准测试中取得了最先进的性能，超越了现有的自回归和连续扩散模型，并且在推理速度上也有显著提升。

Conclusion: Lavida-O是一个强大的统一多模态扩散模型，通过其独特的架构和技术，在图像理解和生成任务上取得了显著的进展，并为未来的研究提供了新的方向。

Abstract: We proposed Lavida-O, a unified multi-modal Masked Diffusion Model (MDM)
capable of image understanding and generation tasks. Unlike existing multimodal
diffsion language models such as MMaDa and Muddit which only support simple
image-level understanding tasks and low-resolution image generation, Lavida-O
exhibits many new capabilities such as object grounding, image-editing, and
high-resolution (1024px) image synthesis. It is also the first unified MDM that
uses its understanding capabilities to improve image generation and editing
results through planning and iterative self-reflection. To allow effective and
efficient training and sampling, Lavida-O ntroduces many novel techniques such
as Elastic Mixture-of-Transformer architecture, universal text conditioning,
and stratified sampling. \ours~achieves state-of-the-art performance on a wide
range of benchmarks such as RefCOCO object grounding, GenEval text-to-image
generation, and ImgEdit image editing, outperforming existing autoregressive
and continuous diffusion models such as Qwen2.5-VL and FluxKontext-dev, while
offering considerable speedup at inference.

</details>


### [117] [ConViS-Bench: Estimating Video Similarity Through Semantic Concepts](https://arxiv.org/abs/2509.19245)
*Benedetta Liberatori,Alessandro Conti,Lorenzo Vaquero,Yiming Wang,Elisa Ricci,Paolo Rota*

Main category: cs.CV

TL;DR: ConViS是一个新的任务，通过计算预定义概念的语义相似度得分来比较视频对，并引入了ConViS-Bench基准来支持该任务。


<details>
  <summary>Details</summary>
Motivation: 目前的视频相似度评估依赖于全局相似度得分，忽略了人类在比较视频时会考虑不同方面（如动作、地点）的能力。需要一种能够进行类人推理的视频相似度评估方法。

Method: 提出了一种名为ConViS（Concept-based Video Similarity）的新任务，该任务通过计算预定义关键语义概念的解释性相似度得分来比较视频对。同时，发布了ConViS-Bench基准，其中包含经过仔细标注的视频对，涵盖多个领域，并提供概念级相似度得分以及差异和相似之处的文本描述。在ConViS-Bench上对几种最先进的模型进行了基准测试。

Result: 在ConViS任务上，不同模型的表现存在显著差异，表明某些概念在视频相似度评估方面更具挑战性。

Conclusion: ConViS任务和ConViS-Bench基准能够促进语言驱动的视频理解研究，实现类人推理的视频相似度评估，并支持新的应用，如概念条件视频检索。

Abstract: What does it mean for two videos to be similar? Videos may appear similar
when judged by the actions they depict, yet entirely different if evaluated
based on the locations where they were filmed. While humans naturally compare
videos by taking different aspects into account, this ability has not been
thoroughly studied and presents a challenge for models that often depend on
broad global similarity scores. Large Multimodal Models (LMMs) with video
understanding capabilities open new opportunities for leveraging natural
language in comparative video tasks. We introduce Concept-based Video
Similarity estimation (ConViS), a novel task that compares pairs of videos by
computing interpretable similarity scores across a predefined set of key
semantic concepts. ConViS allows for human-like reasoning about video
similarity and enables new applications such as concept-conditioned video
retrieval. To support this task, we also introduce ConViS-Bench, a new
benchmark comprising carefully annotated video pairs spanning multiple domains.
Each pair comes with concept-level similarity scores and textual descriptions
of both differences and similarities. Additionally, we benchmark several
state-of-the-art models on ConViS, providing insights into their alignment with
human judgments. Our results reveal significant performance differences on
ConViS, indicating that some concepts present greater challenges for estimating
video similarity. We believe that ConViS-Bench will serve as a valuable
resource for advancing research in language-driven video understanding.

</details>


### [118] [Adversarially-Refined VQ-GAN with Dense Motion Tokenization for Spatio-Temporal Heatmaps](https://arxiv.org/abs/2509.19252)
*Gabriel Maldonado,Narges Rashvand,Armin Danesh Pazho,Ghazal Alinezhad Noghre,Vinit Katariya,Hamed Tabkhi*

Main category: cs.CV

TL;DR: 一种结合了密集运动标记化和对抗性精炼的 VQ-GAN 框架，用于压缩时空热图，同时保留精细的人体运动轨迹。


<details>
  <summary>Details</summary>
Motivation: 解决连续人类运动理解中的高维度和固有冗余挑战，实现高效压缩和表征。

Method: 提出一种融合密集运动标记化和对抗性精炼的 VQ-GAN 框架，以压缩时空热图并保留精细的人体运动轨迹。

Result: 在 CMU Panoptic 数据集上，该方法 SSIM 指标优于 dVAE 基线 9.31%，并减少了 37.1% 的时间不稳定性。此外，研究发现 2D 运动可以用 128 个标记的词汇表表示，而 3D 运动需要 1024 个标记的码本才能进行保真重建。

Conclusion: 该方法在压缩时空热图和保留人体运动细节方面表现出色，并为分析运动复杂度提供了新颖的视角，证明了其在各种运动分析应用中的实际部署可行性。

Abstract: Continuous human motion understanding remains a core challenge in computer
vision due to its high dimensionality and inherent redundancy. Efficient
compression and representation are crucial for analyzing complex motion
dynamics. In this work, we introduce an adversarially-refined VQ-GAN framework
with dense motion tokenization for compressing spatio-temporal heatmaps while
preserving the fine-grained traces of human motion. Our approach combines dense
motion tokenization with adversarial refinement, which eliminates
reconstruction artifacts like motion smearing and temporal misalignment
observed in non-adversarial baselines. Our experiments on the CMU Panoptic
dataset provide conclusive evidence of our method's superiority, outperforming
the dVAE baseline by 9.31% SSIM and reducing temporal instability by 37.1%.
Furthermore, our dense tokenization strategy enables a novel analysis of motion
complexity, revealing that 2D motion can be optimally represented with a
compact 128-token vocabulary, while 3D motion's complexity demands a much
larger 1024-token codebook for faithful reconstruction. These results establish
practical deployment feasibility across diverse motion analysis applications.
The code base for this work is available at
https://github.com/TeCSAR-UNCC/Pose-Quantization.

</details>


### [119] [Graph-Radiomic Learning (GrRAiL) Descriptor to Characterize Imaging Heterogeneity in Confounding Tumor Pathologies](https://arxiv.org/abs/2509.19258)
*Dheerendranath Battalapalli,Apoorva Safai,Maria Jaramillo,Hyemin Um,Gustavo Adalfo Pineda Ortiz,Ulas Bagci,Manmeet Singh Ahluwalia,Marwa Ismail,Pallavi Tiwari*

Main category: cs.CV

TL;DR: GrRAiL通过识别子区域集群并量化它们之间的空间关系来表征肿瘤内异质性（ILH），在区分肿瘤复发和坏死、以及IPMN风险分层方面优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 在常规影像学中，可靠地区分实体瘤中的混淆病理学和恶性肿瘤是一个重大挑战。现有的放射组学方法在聚合特征时会忽略区域内复杂的空间关系。

Method: 提出了一种新的图放射组学学习（GrRAiL）描述符，通过识别像素级放射组学测量的子区域集群，然后计算图论指标来量化集群间的空间关联，从而捕捉ILH并区分混淆病理学和恶性肿瘤。

Result: 在胶质母细胞瘤（GBM）、脑转移瘤和胰腺导管内乳头状黏液瘤（IPMN）的三个案例研究中，GrRAiL在区分复发/坏死和IPMN风险分层方面，在交叉验证和测试准确性上均优于GNN、纹理放射组学和强度图分析等基线方法，提高了10%以上。

Conclusion: GrRAiL在多机构设置中能够可靠地捕捉ILH，并能区分混淆病理学和恶性肿瘤，在临床可行性方面表现出色。

Abstract: A significant challenge in solid tumors is reliably distinguishing
confounding pathologies from malignant neoplasms on routine imaging. While
radiomics methods seek surrogate markers of lesion heterogeneity on CT/MRI,
many aggregate features across the region of interest (ROI) and miss complex
spatial relationships among varying intensity compositions. We present a new
Graph-Radiomic Learning (GrRAiL) descriptor for characterizing intralesional
heterogeneity (ILH) on clinical MRI scans. GrRAiL (1) identifies clusters of
sub-regions using per-voxel radiomic measurements, then (2) computes
graph-theoretic metrics to quantify spatial associations among clusters. The
resulting weighted graphs encode higher-order spatial relationships within the
ROI, aiming to reliably capture ILH and disambiguate confounding pathologies
from malignancy. To assess efficacy and clinical feasibility, GrRAiL was
evaluated in n=947 subjects spanning three use cases: differentiating tumor
recurrence from radiation effects in glioblastoma (GBM; n=106) and brain
metastasis (n=233), and stratifying pancreatic intraductal papillary mucinous
neoplasms (IPMNs) into no+low vs high risk (n=608). In a multi-institutional
setting, GrRAiL consistently outperformed state-of-the-art baselines - Graph
Neural Networks (GNNs), textural radiomics, and intensity-graph analysis. In
GBM, cross-validation (CV) and test accuracies for recurrence vs
pseudo-progression were 89% and 78% with >10% test-accuracy gains over
comparators. In brain metastasis, CV and test accuracies for recurrence vs
radiation necrosis were 84% and 74% (>13% improvement). For IPMN risk
stratification, CV and test accuracies were 84% and 75%, showing >10%
improvement.

</details>


### [120] [Moving by Looking: Towards Vision-Driven Avatar Motion Generation](https://arxiv.org/abs/2509.19259)
*Markos Diomataris,Berat Mert Albaba,Giorgio Becherini,Partha Ghosh,Omid Taheri,Michael J. Black*

Main category: cs.CV

TL;DR: 该研究提出了CLOPS，一个利用自我中心视觉进行导航和感知的首个虚拟人模型，解决了现有方法忽视人类感知与运动相互依赖性的问题。


<details>
  <summary>Details</summary>
Motivation: 现有的人体运动生成方法忽视了人类感知与运动之间的相互依赖性，并且使用了与人类截然不同且特定于任务的“感知”方式。为了生成类似人类的虚拟人行为，需要模拟人类的感知方式。因此，本研究旨在通过利用自我中心视觉来解决这一问题。

Method: 该研究首先在一个大型动作捕捉数据集上训练了一个运动先验模型，然后使用Q学习训练了一个策略，将自我中心视觉输入映射到运动先验的高层控制指令。这种方法将低层运动技能的学习与高层视觉控制的学习分离开来。

Result: 实验证明，使用自我中心视觉可以使虚拟人的运动特征更像人类，例如，虚拟人能够避开视野中的障碍物。

Conclusion: 将类似人类的传感器，特别是自我中心视觉，应用于虚拟人，有望实现更像人类行为的虚拟人训练。

Abstract: The way we perceive the world fundamentally shapes how we move, whether it is
how we navigate in a room or how we interact with other humans. Current human
motion generation methods, neglect this interdependency and use task-specific
``perception'' that differs radically from that of humans. We argue that the
generation of human-like avatar behavior requires human-like perception.
Consequently, in this work we present CLOPS, the first human avatar that solely
uses egocentric vision to perceive its surroundings and navigate. Using vision
as the primary driver of motion however, gives rise to a significant challenge
for training avatars: existing datasets have either isolated human motion,
without the context of a scene, or lack scale. We overcome this challenge by
decoupling the learning of low-level motion skills from learning of high-level
control that maps visual input to motion. First, we train a motion prior model
on a large motion capture dataset. Then, a policy is trained using Q-learning
to map egocentric visual inputs to high-level control commands for the motion
prior. Our experiments empirically demonstrate that egocentric vision can give
rise to human-like motion characteristics in our avatars. For example, the
avatars walk such that they avoid obstacles present in their visual field.
These findings suggest that equipping avatars with human-like sensors,
particularly egocentric vision, holds promise for training avatars that behave
like humans.

</details>


### [121] [OverLayBench: A Benchmark for Layout-to-Image Generation with Dense Overlaps](https://arxiv.org/abs/2509.19282)
*Bingnan Li,Chen-Yu Wang,Haiyang Xu,Xiang Zhang,Ethan Armand,Divyansh Srivastava,Xiaojun Shan,Zeyuan Chen,Jianwen Xie,Zhuowen Tu*

Main category: cs.CV

TL;DR: 现有方法在处理包含大量重叠边界框的布局时存在困难，我们提出了 OverLayScore 来量化重叠的复杂性，并引入 OverLayBench 基准来评估模型性能，同时提出 CreatiLayout-AM 模型以提高生成质量。


<details>
  <summary>Details</summary>
Motivation: 现有布局到图像生成方法在处理边界框重叠时效果不佳，特别是在重叠区域大或重叠实例语义区分度低的情况下，这导致了生成质量的下降。因此，需要新的评估方法和基准来系统地评估和改进模型在复杂重叠场景下的性能。

Method: 提出了 OverLayScore 指标来量化边界框重叠的复杂性，并据此构建了一个新的基准 OverLayBench，该基准包含了不同重叠复杂度的案例。此外，还提出了 CreatiLayout-AM 模型，该模型在氨掩码数据集上进行了微调，以应对复杂的重叠情况。

Result: 通过 OverLayScore 和 OverLayBench 分析发现，现有基准测试偏向于简单的重叠情况。CreatiLayout-AM 模型在处理复杂重叠方面展现出改进的潜力。

Conclusion: 现有布局到图像生成方法在处理边界框重叠方面仍有局限性。提出的 OverLayScore 和 OverLayBench 为评估和改进模型在复杂重叠场景下的性能提供了新的工具和方向。CreatiLayout-AM 是朝着提高模型在现实复杂场景下生成能力迈出的初步尝试。

Abstract: Despite steady progress in layout-to-image generation, current methods still
struggle with layouts containing significant overlap between bounding boxes. We
identify two primary challenges: (1) large overlapping regions and (2)
overlapping instances with minimal semantic distinction. Through both
qualitative examples and quantitative analysis, we demonstrate how these
factors degrade generation quality. To systematically assess this issue, we
introduce OverLayScore, a novel metric that quantifies the complexity of
overlapping bounding boxes. Our analysis reveals that existing benchmarks are
biased toward simpler cases with low OverLayScore values, limiting their
effectiveness in evaluating model performance under more challenging
conditions. To bridge this gap, we present OverLayBench, a new benchmark
featuring high-quality annotations and a balanced distribution across different
levels of OverLayScore. As an initial step toward improving performance on
complex overlaps, we also propose CreatiLayout-AM, a model fine-tuned on a
curated amodal mask dataset. Together, our contributions lay the groundwork for
more robust layout-to-image generation under realistic and challenging
scenarios. Project link: https://mlpc-ucsd.github.io/OverLayBench.

</details>


### [122] [VolSplat: Rethinking Feed-Forward 3D Gaussian Splatting with Voxel-Aligned Prediction](https://arxiv.org/abs/2509.19297)
*Weijie Wang,Yeqing Chen,Zeyu Zhang,Hengyu Liu,Haoxiao Wang,Zhiyuan Feng,Wenkang Qin,Zheng Zhu,Donny Y. Chen,Bohan Zhuang*

Main category: cs.CV

TL;DR: 3DGS的像素对齐范式存在局限性，提出了一种新的基于体素对齐的高斯 वापरा方法VolSplat，提高了重建质量和视图一致性。


<details>
  <summary>Details</summary>
Motivation: 现有3DGS方法依赖像素对齐，存在视图依赖、密度偏差和对遮挡/低纹理敏感等问题。

Method: 提出VolSplat，用体素对齐的高斯代替像素对齐，直接从预测的3D体素网格预测高斯，实现自适应密度控制。

Result: VolSplat在RealEstate10K和ScanNet数据集上实现了最先进的性能，生成的模型更合理、视图更一致。

Conclusion: VolSplat克服了现有方法的局限性，提供了更具可扩展性、更密集、更鲁棒的3D重建框架。

Abstract: Feed-forward 3D Gaussian Splatting (3DGS) has emerged as a highly effective
solution for novel view synthesis. Existing methods predominantly rely on a
pixel-aligned Gaussian prediction paradigm, where each 2D pixel is mapped to a
3D Gaussian. We rethink this widely adopted formulation and identify several
inherent limitations: it renders the reconstructed 3D models heavily dependent
on the number of input views, leads to view-biased density distributions, and
introduces alignment errors, particularly when source views contain occlusions
or low texture. To address these challenges, we introduce VolSplat, a new
multi-view feed-forward paradigm that replaces pixel alignment with
voxel-aligned Gaussians. By directly predicting Gaussians from a predicted 3D
voxel grid, it overcomes pixel alignment's reliance on error-prone 2D feature
matching, ensuring robust multi-view consistency. Furthermore, it enables
adaptive control over Gaussian density based on 3D scene complexity, yielding
more faithful Gaussian point clouds, improved geometric consistency, and
enhanced novel-view rendering quality. Experiments on widely used benchmarks
including RealEstate10K and ScanNet demonstrate that VolSplat achieves
state-of-the-art performance while producing more plausible and view-consistent
Gaussian reconstructions. In addition to superior results, our approach
establishes a more scalable framework for feed-forward 3D reconstruction with
denser and more robust representations, paving the way for further research in
wider communities. The video results, code and trained models are available on
our project page: https://lhmd.top/volsplat.

</details>


### [123] [CAR-Flow: Condition-Aware Reparameterization Aligns Source and Target for Better Flow Matching](https://arxiv.org/abs/2509.19300)
*Chen Chen,Pengsheng Guo,Liangchen Song,Jiasen Lu,Rui Qian,Xinze Wang,Tsu-Jui Fu,Wei Liu,Yinfei Yang,Alex Schwing*

Main category: cs.CV

TL;DR: CAR-Flow 是一种轻量级、可学习的移位方法，用于条件生成建模，通过调整源、目标或两个分布来缩短模型必须学习的概率路径，从而加快训练速度。


<details>
  <summary>Details</summary>
Motivation: 现有的基于流和扩散的条件生成模型需要学习从高斯噪声到条件数据分布的传输，这既包括质量传输，也包括条件注入，对模型提出了很高的要求。

Method: 提出了一种名为 CAR-Flow 的条件感知重参数化方法，它通过学习一个轻量级的移位来调整源、目标或两个分布，以缩短模型必须学习的概率路径。

Result: 在低维合成数据上，CAR 的效果得到了可视化和量化。在 ImageNet-256 数据集上，使用 CAR-Flow 改进的 SiT-XL/2 模型将 FID 从 2.07 降低到 1.68，同时仅增加了不到 0.6% 的参数。

Conclusion: CAR-Flow 是一种有效的方法，可以加快条件生成模型的训练速度，并提高其性能，同时对模型参数的增加量很小。

Abstract: Conditional generative modeling aims to learn a conditional data distribution
from samples containing data-condition pairs. For this, diffusion and
flow-based methods have attained compelling results. These methods use a
learned (flow) model to transport an initial standard Gaussian noise that
ignores the condition to the conditional data distribution. The model is hence
required to learn both mass transport and conditional injection. To ease the
demand on the model, we propose Condition-Aware Reparameterization for Flow
Matching (CAR-Flow) -- a lightweight, learned shift that conditions the source,
the target, or both distributions. By relocating these distributions, CAR-Flow
shortens the probability path the model must learn, leading to faster training
in practice. On low-dimensional synthetic data, we visualize and quantify the
effects of CAR. On higher-dimensional natural image data (ImageNet-256),
equipping SiT-XL/2 with CAR-Flow reduces FID from 2.07 to 1.68, while
introducing less than 0.6% additional parameters.

</details>


### [124] [Leveraging Geometric Visual Illusions as Perceptual Inductive Biases for Vision Models](https://arxiv.org/abs/2509.15156)
*Haobo Yang,Minghao Guo,Dequan Yang,Wenyu Wang*

Main category: cs.CV

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Contemporary deep learning models have achieved impressive performance in
image classification by primarily leveraging statistical regularities within
large datasets, but they rarely incorporate structured insights drawn directly
from perceptual psychology. To explore the potential of perceptually motivated
inductive biases, we propose integrating classic geometric visual illusions
well-studied phenomena from human perception into standard image-classification
training pipelines. Specifically, we introduce a synthetic, parametric
geometric-illusion dataset and evaluate three multi-source learning strategies
that combine illusion recognition tasks with ImageNet classification
objectives. Our experiments reveal two key conceptual insights: (i)
incorporating geometric illusions as auxiliary supervision systematically
improves generalization, especially in visually challenging cases involving
intricate contours and fine textures; and (ii) perceptually driven inductive
biases, even when derived from synthetic stimuli traditionally considered
unrelated to natural image recognition, can enhance the structural sensitivity
of both CNN and transformer-based architectures. These results demonstrate a
novel integration of perceptual science and machine learning and suggest new
directions for embedding perceptual priors into vision model design.

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [125] [Dynamic Prompt Fusion for Multi-Task and Cross-Domain Adaptation in LLMs](https://arxiv.org/abs/2509.18113)
*Xin Hu,Yue Kang,Guanzi Yao,Tianze Kang,Mengjie Wang,Heyao Liu*

Main category: cs.CL

TL;DR: 本研究提出了一种包含动态提示调度机制的统一多任务学习框架，以解决大型语言模型在多任务和跨域设置下的泛化能力限制问题。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在多任务和跨域设置下存在泛化能力限制。

Method: 提出了一种统一的多任务学习框架，包含一个提示池和一个任务感知调度策略，能够动态地组合和对齐不同任务的提示。通过使用任务嵌入和门控机制来融合提示，并采用联合多任务学习的优化目标，该框架能够缓解任务干扰和负迁移。

Result: 该框架在多项语言理解和知识推理任务上显著提高了性能，并表现出良好的模型稳定性和迁移能力。

Conclusion: 所提出的提示调度方法在统一多任务建模和跨域适应方面具有很高的适用性和有效性。

Abstract: This study addresses the generalization limitations commonly observed in
large language models under multi-task and cross-domain settings. Unlike prior
methods such as SPoT, which depends on fixed prompt templates, our study
introduces a unified multi-task learning framework with dynamic prompt
scheduling mechanism. By introducing a prompt pool and a task-aware scheduling
strategy, the method dynamically combines and aligns prompts for different
tasks. This enhances the model's ability to capture semantic differences across
tasks. During prompt fusion, the model uses task embeddings and a gating
mechanism to finely control the prompt signals. This ensures alignment between
prompt content and task-specific demands. At the same time, it builds flexible
sharing pathways across tasks. In addition, the proposed optimization objective
centers on joint multi-task learning. It incorporates an automatic learning
strategy for scheduling weights, which effectively mitigates task interference
and negative transfer. To evaluate the effectiveness of the method, a series of
sensitivity experiments were conducted. These experiments examined the impact
of prompt temperature parameters and task number variation. The results confirm
the advantages of the proposed mechanism in maintaining model stability and
enhancing transferability. Experimental findings show that the prompt
scheduling method significantly improves performance on a range of language
understanding and knowledge reasoning tasks. These results fully demonstrate
its applicability and effectiveness in unified multi-task modeling and
cross-domain adaptation.

</details>


### [126] [GAUSS: Benchmarking Structured Mathematical Skills for Large Language Models](https://arxiv.org/abs/2509.18122)
*Yue Zhang,Jiaxin Zhang,Qiuyu Ren,Tahsin Saffat,Xiaoxuan Liu,Zitong Yang,Banghua Zhu,Yi Ma*

Main category: cs.CL

TL;DR: GAUSS是一个评估LLM数学能力的基准，涵盖十二项核心技能维度，分为知识理解、问题解决与沟通、元技能与创造力三个领域。它通过对问题按认知技能分类和设计隔离特定能力的任务，为模型构建全面、细致且可解释的数学能力画像，真实反映其潜在的数学智能。通过示例，展示了如何使用GAUSS基准分析GPT-5-thinking的技能画像，揭示了其优劣势以及与o4-mini-high的差异，强调了多维度、基于技能的评估价值。


<details>
  <summary>Details</summary>
Motivation: 评估大型语言模型（LLM）在数学方面的能力，并提供一个全面、细致且可解释的评估框架。

Method: 构建了一个名为GAUSS（General Assessment of Underlying Structured Skills in Mathematics）的基准，该基准涵盖十二项核心技能维度，分为知识和理解、问题解决和沟通、元技能和创造力三个领域。通过对问题进行认知技能分类和设计隔离特定能力的任务来构建评估框架。

Result: 得出了GPT-5-thinking的技能画像，并揭示了其相对于o4-mini-high的优势和劣势。

Conclusion: GAUSS基准能够提供多维度、基于技能的评估，能够真实反映LLM的潜在数学智能，并有助于理解模型在不同数学能力上的表现差异。

Abstract: We introduce \textbf{GAUSS} (\textbf{G}eneral \textbf{A}ssessment of
\textbf{U}nderlying \textbf{S}tructured \textbf{S}kills in Mathematics), a
benchmark that evaluates LLMs' mathematical abilities across twelve core skill
dimensions, grouped into three domains: knowledge and understanding, problem
solving and communication, and meta-skills and creativity. By categorizing
problems according to cognitive skills and designing tasks that isolate
specific abilities, GAUSS constructs comprehensive, fine-grained, and
interpretable profiles of models' mathematical abilities. These profiles
faithfully represent their underlying mathematical intelligence. To exemplify
how to use the \textsc{GAUSS} benchmark, we have derived the skill profile of
\textsc{GPT-5-thinking}, revealing its strengths and weaknesses as well as its
differences relative to \textsc{o4-mini-high}, thereby underscoring the value
of multidimensional, skill-based evaluation.

</details>


### [127] [Event Causality Identification with Synthetic Control](https://arxiv.org/abs/2509.18156)
*Haoyu Wang,Fengze Liu,Jiayao Zhang,Dan Roth,Kyle Richardson*

Main category: cs.CL

TL;DR: 本研究提出了一种基于鲁宾因果模型和合成控制法来识别事件因果关系的新方法，以解决传统方法易受语言误用和图推理谬误影响的问题。


<details>
  <summary>Details</summary>
Motivation: 传统事件因果关系抽取方法在区分因果和相关性时存在不足，容易受到语言非正式使用和图推理谬误的影响，因此需要更鲁棒的方法。

Method: 本研究将鲁宾因果模型应用于事件因果关系识别，将时间上先发生的事件视为“处理”，后发生的事件视为“结果”。为了在文本域模拟处理的干预，研究人员提出寻找与主人公经历相似但接受了干预的“双胞胎”案例，并采用文本嵌入合成与反演技术，利用合成控制法来生成这种“双胞胎”。

Result: 在COPES-hard基准测试中，所提出的方法比包括GPT-4在内的现有方法更有效地识别了因果关系。

Conclusion: 基于鲁宾因果模型和合成控制法的方法能够更可靠地识别事件因果关系，克服了传统方法的局限性。

Abstract: Event causality identification (ECI), a process that extracts causal
relations between events from text, is crucial for distinguishing causation
from correlation. Traditional approaches to ECI have primarily utilized
linguistic patterns and multi-hop relational inference, risking false causality
identification due to informal usage of causality and specious graphical
inference. In this paper, we adopt the Rubin Causal Model to identify event
causality: given two temporally ordered events, we see the first event as the
treatment and the second one as the observed outcome. Determining their
causality involves manipulating the treatment and estimating the resultant
change in the likelihood of the outcome. Given that it is only possible to
implement manipulation conceptually in the text domain, as a work-around, we
try to find a twin for the protagonist from existing corpora. This twin should
have identical life experiences with the protagonist before the treatment but
undergoes an intervention of treatment. However, the practical difficulty of
locating such a match limits its feasibility. Addressing this issue, we use the
synthetic control method to generate such a twin' from relevant historical
data, leveraging text embedding synthesis and inversion techniques. This
approach allows us to identify causal relations more robustly than previous
methods, including GPT-4, which is demonstrated on a causality benchmark,
COPES-hard.

</details>


### [128] [ZERA: Zero-init Instruction Evolving Refinement Agent - From Zero Instructions to Structured Prompts via Principle-based Optimization](https://arxiv.org/abs/2509.18158)
*Seungyoun Yi,Minsoo Khang,Sungrae Park*

Main category: cs.CL

TL;DR: ZERA是一个创新的框架，通过联合优化系统和用户提示来改进大型语言模型（LLM）在特定任务上的表现，克服了现有自动提示优化（APO）方法的局限性。


<details>
  <summary>Details</summary>
Motivation: 现有APO方法主要关注用户提示，依赖非结构化反馈，且需要大量样本和长时间迭代，导致成本高昂且不够稳定。ZERA旨在通过低开销的精炼方法，联合优化系统和用户提示，以更高效、更稳定的方式提升LLM性能。

Method: ZERA使用八个可泛化的标准来评估提示，并自动推断权重，然后根据这些结构化的评估来修改提示。这种方法能够快速收敛到高质量的提示，仅需少量样本和短迭代周期。

Result: 在五个LLM和九个涵盖推理、摘要和代码生成的不同数据集上进行的评估显示，ZERA在各项任务上均能实现相比强有力基线的持续改进。消融研究也进一步证明了ZERA各组成部分在有效构建提示方面的贡献。

Conclusion: ZERA通过联合优化系统和用户提示，并采用基于结构化评估的低开销精炼方法，能够高效、稳定地提升LLM在多种任务上的表现，相比现有方法具有明显优势。

Abstract: Automatic Prompt Optimization (APO) improves large language model (LLM)
performance by refining prompts for specific tasks. However, prior APO methods
typically focus only on user prompts, rely on unstructured feedback, and
require large sample sizes and long iteration cycles-making them costly and
brittle. We propose ZERA (Zero-init Instruction Evolving Refinement Agent), a
novel framework that jointly optimizes both system and user prompts through
principled, low-overhead refinement. ZERA scores prompts using eight
generalizable criteria with automatically inferred weights, and revises prompts
based on these structured critiques. This enables fast convergence to
high-quality prompts using minimal examples and short iteration cycles. We
evaluate ZERA across five LLMs and nine diverse datasets spanning reasoning,
summarization, and code generation tasks. Experimental results demonstrate
consistent improvements over strong baselines. Further ablation studies
highlight the contribution of each component to more effective prompt
construction. Our implementation including all prompts is publicly available at
https://github.com/younatics/zera-agent.

</details>


### [129] [Thinking in a Crowd: How Auxiliary Information Shapes LLM Reasoning](https://arxiv.org/abs/2509.18163)
*Haodong Zhao,Chenyan Zhao,Yansi Li,Zhuosheng Zhang,Gongshen Liu*

Main category: cs.CL

TL;DR: LLM在有外部信息辅助时，其


<details>
  <summary>Details</summary>
Motivation: LLM在有外部信息辅助时，其推理能力至关重要，但外部信息可能是有害的，本研究旨在探究这种信息对LLM推理过程的因果影响。

Method: 创建了一个名为SciAux的新数据集，该数据集源自ScienceQA，用于系统地测试模型在面对有益、无关或误导性信息时的鲁棒性。

Result: 模型的“思考模式”是一把双刃剑：有益信息能提高准确性，但误导信息会导致性能灾难性下降，且该效应被思考过程放大。模型并未因此获得鲁棒性，反而可能因思考而加剧错误。

Conclusion: 关键挑战在于不仅要让模型“思考”，还要使其具备评估推理所依据信息真伪的能力。

Abstract: The capacity of Large Language Models (LLMs) to reason is fundamental to
their application in complex, knowledge-intensive domains. In real-world
scenarios, LLMs are often augmented with external information that can be
helpful, irrelevant, or even misleading. This paper investigates the causal
impact of such auxiliary information on the reasoning process of LLMs with
explicit step-by-step thinking capabilities. We introduce SciAux, a new dataset
derived from ScienceQA, to systematically test the robustness of the model
against these types of information. Our findings reveal a critical
vulnerability: the model's deliberative "thinking mode" is a double-edged
sword. While helpful context improves accuracy, misleading information causes a
catastrophic drop in performance, which is amplified by the thinking process.
Instead of conferring robustness, thinking reinforces the degree of error when
provided with misinformation. This highlights that the challenge is not merely
to make models "think", but to endow them with the critical faculty to evaluate
the information upon which their reasoning is based. The SciAux dataset is
available at https://huggingface.co/datasets/billhdzhao/SciAux.

</details>


### [130] [SIRAG: Towards Stable and Interpretable RAG with A Process-Supervised Multi-Agent Framework](https://arxiv.org/abs/2509.18167)
*Junlin Wang,Zehao Wu,Shaowei Lu,Yanlan Li,Xinghao Huang*

Main category: cs.CL

TL;DR: 提出了一种多代理框架，通过引入决策者和知识选择器代理来改进检索增强生成（RAG）模型，并使用 LLM-as-a-Judge 进行过程监督和 PPO 进行训练，以提高检索和生成组件之间的协调性。


<details>
  <summary>Details</summary>
Motivation: 检索增强生成（RAG）的有效性依赖于检索器和生成器之间的协调，但由于它们是独立开发的，这种交互通常不是最优的，导致检索到的文档不相关或冗余，或者生成器未能充分利用检索到的证据。

Method: 引入了一个由决策者（决定何时继续检索或停止生成）和知识选择器（过滤检索到的文档以保留最相关的证据）组成的双代理框架。使用 LLM-as-a-Judge 对每个中间动作进行过程级别奖励的细粒度监督。采用树状滚动策略探索推理路径，并使用 PPO 算法对两个代理进行端到端训练。

Result: 在单跳和多跳问答基准测试中，该方法与标准的 RAG 基线相比，在准确性、收敛稳定性和推理轨迹可解释性方面均表现更优。

Conclusion: 所提出的多代理框架能够有效弥合检索器和生成器之间的差距，提高 RAG 模型的性能，并且由于其模块化和即插即用特性，易于在实际 RAG 应用中推广使用。

Abstract: Retrieval-Augmented Generation (RAG) enables large language models (LLMs) to
access external knowledge sources, but the effectiveness of RAG relies on the
coordination between the retriever and the generator. Since these components
are developed independently, their interaction is often suboptimal: the
retriever may return irrelevant or redundant documents, while the generator may
fail to fully leverage retrieved evidence. In this work, we propose a
process-supervised multi-agent framework to bridge the gap between retriever
and generator. The framework introduces two lightweight agents: a Decision
Maker, which determines when to continue retrieval or stop for answer
generation, and a Knowledge Selector, which filters retrieved documents to
retain only the most useful evidence. To provide fine-grained supervision, we
employ an LLM-as-a-Judge that evaluates each intermediate action with
process-level rewards, ensuring more accurate credit assignment than relying
solely on final answer correctness. We further adopt a tree-structured rollout
strategy to explore diverse reasoning paths, and train both agents with
Proximal Policy Optimization (PPO) in an end-to-end manner. Experiments on
single-hop and multi-hop question answering benchmarks show that our approach
achieves higher accuracy, more stable convergence, and produces more
interpretable reasoning trajectories compared with standard RAG baselines.
Importantly, the proposed framework is modular and plug-and-play, requiring no
modification to the retriever or generator, making it practical for real-world
RAG applications.

</details>


### [131] [ERFC: Happy Customers with Emotion Recognition and Forecasting in Conversation in Call Centers](https://arxiv.org/abs/2509.18175)
*Aditi Debsharma,Bhushan Jagyasi,Surajit Sen,Priyanka Pandey,Devicharith Dovari,Yuvaraj V. C,Rosalin Parida,Gopali Contractor*

Main category: cs.CL

TL;DR: 通过 ERFC 架构预测对话中的未来情绪，以提高客户满意度。


<details>
  <summary>Details</summary>
Motivation: 情绪识别在呼叫中心等行业有广泛应用，尤其是在客服场景中，客服需要安抚客户以提供更好的客户体验。了解客户的未来情绪有助于客服提供更及时的解决方案。

Method: 提出了一种名为 ERFC 的新架构，该架构能够考虑多模态、不同的情绪属性、上下文以及说话者之间的依赖关系，来预测对话中未来话语的情绪。

Result: 在 IEMOCAP 数据集上进行了广泛的实验，证明了 ERFC 架构的可行性。

Conclusion: ERFC 架构在呼叫中心等注重客户满意度的应用中具有巨大的商业价值。

Abstract: Emotion Recognition in Conversation has been seen to be widely applicable in
call center analytics, opinion mining, finance, retail, healthcare, and other
industries. In a call center scenario, the role of the call center agent is not
just confined to receiving calls but to also provide good customer experience
by pacifying the frustration or anger of the customers. This can be achieved by
maintaining neutral and positive emotion from the agent. As in any
conversation, the emotion of one speaker is usually dependent on the emotion of
other speaker. Hence the positive emotion of an agent, accompanied with the
right resolution will help in enhancing customer experience. This can change an
unhappy customer to a happy one. Imparting the right resolution at right time
becomes easier if the agent has the insight of the emotion of future
utterances. To predict the emotions of the future utterances we propose a novel
architecture, Emotion Recognition and Forecasting in Conversation. Our proposed
ERFC architecture considers multi modalities, different attributes of emotion,
context and the interdependencies of the utterances of the speakers in the
conversation. Our intensive experiments on the IEMOCAP dataset have shown the
feasibility of the proposed ERFC. This approach can provide a tremendous
business value for the applications like call center, where the happiness of
customer is utmost important.

</details>


### [132] [Evaluating Large Language Models for Detecting Antisemitism](https://arxiv.org/abs/2509.18293)
*Jay Patel,Hrudayangam Mehta,Jeremy Blackburn*

Main category: cs.CL

TL;DR: 本研究评估了八种开源大型语言模型（LLMs）在检测反犹内容方面的能力，并提出了一种名为Guided-CoT的新提示技术，该技术通过在上下文中提供定义作为策略指南，提高了所有评估模型的性能。研究还分析了LLM的错误，并量化了模型生成解释中的语义差异，揭示了不同LLM在效用、可解释性和可靠性方面的差异。


<details>
  <summary>Details</summary>
Motivation: 自动检测社交媒体上的仇恨内容是一个重要但充满挑战的问题，需要模型不断适应不断变化的仇恨言论模式。本研究的动机是评估和改进开源大型语言模型（LLMs）在检测特定类型的仇恨内容（反犹内容）方面的能力。

Method: 本研究评估了八种开源LLMs检测反犹内容的表现，重点使用了上下文定义作为策略指南。研究探索了不同的提示技术，并设计了一种名为Guided-CoT的新提示方法，该方法在处理上下文策略时表现良好。此外，研究还检查了LLM的错误，并引入了量化模型生成解释中语义差异的新指标。

Result: Guided-CoT提示方法提高了所有评估模型的性能，并且不受解码配置、模型大小或推理能力的影响。Llama 3.1 70B模型的表现优于微调的GPT-3.5模型。研究还发现了不同LLM在效用、可解释性和可靠性方面存在显著差异，并通过量化语义差异的指标揭示了模型行为的差异和矛盾之处。

Conclusion: 本研究表明，通过使用上下文定义和Guided-CoT等提示技术，可以有效提升开源LLMs检测反犹内容的性能。研究结果强调了不同LLM在准确性、可解释性和可靠性方面的差异，为未来开发更有效的仇恨内容检测工具提供了见解。

Abstract: Detecting hateful content is a challenging and important problem. Automated
tools, like machine-learning models, can help, but they require continuous
training to adapt to the ever-changing landscape of social media. In this work,
we evaluate eight open-source LLMs' capability to detect antisemitic content,
specifically leveraging in-context definition as a policy guideline. We explore
various prompting techniques and design a new CoT-like prompt, Guided-CoT.
Guided-CoT handles the in-context policy well, increasing performance across
all evaluated models, regardless of decoding configuration, model sizes, or
reasoning capability. Notably, Llama 3.1 70B outperforms fine-tuned GPT-3.5.
Additionally, we examine LLM errors and introduce metrics to quantify semantic
divergence in model-generated rationales, revealing notable differences and
paradoxical behaviors among LLMs. Our experiments highlight the differences
observed across LLMs' utility, explainability, and reliability.

</details>


### [133] [Exploiting Tree Structure for Credit Assignment in RL Training of LLMs](https://arxiv.org/abs/2509.18314)
*Hieu Tran,Zonghai Yao,Hong Yu*

Main category: cs.CL

TL;DR: 该研究提出了一种名为TEMPO的无评论员算法，用于优化语言模型（LLM）的推理能力，特别是在奖励稀疏和延迟的情况下。TEMPO通过将多个响应转换为前缀树，并利用非参数前缀值来解决代币级信用分配问题，从而在数学和医学问答等领域取得了优于PPO和GRPO的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的强化学习方法（如PPO和GRPO）在处理长序列和稀疏奖励时存在瓶颈，如代币级信用分配困难、训练复杂、泛化性差或奖励信号分配不精确等问题。本研究旨在解决这些挑战，特别是在可验证奖励的设置下，为LLM推理提供更有效的优化方法。

Method: 本研究提出了Prefix-to-Tree (P2T) 方法，将一组响应转换为前缀树，并计算非参数前缀值。在此基础上，提出了一种名为TEMPO（Tree-Estimated Mean Prefix Value for Policy Optimization）的无评论员算法。TEMPO通过利用前缀树结构，在分支代币处进行分支门控时间差分校正，以提供精确的代币级信用，同时在非分支代币处退化为GRPO。

Result: 在Qwen3-1.7B/4B模型上，TEMPO在MATH、MedQA（分布内）和GSM-HARD、AMC23、MedMCQA、MMLU-Medical（分布外）等基准测试中，均取得了优于PPO和GRPO的性能，并在相似的训练时间内达到了更高的验证准确率。

Conclusion: TEMPO是一种简单而有效的无评论员算法，能够解决LLM推理中的代币级信用分配问题，特别是在可验证奖励和长序列场景下。它通过P2T方法和分支门控时间差分校正，在多个推理基准测试中展现出优越的性能，并具有良好的泛化能力。

Abstract: Reinforcement learning improves LLM reasoning, yet sparse delayed reward over
long sequences makes token-level credit assignment the key bottleneck. We study
the verifiable-reward setting, where the final answer is checkable and multiple
responses can be drawn per prompt. Reasoning tasks in math and medical QA align
with this setup, where only a few decision tokens significantly impact the
outcome. PPO offers token-level advantages with a learned value model, but it
is complex to train both the actor and critic models simultaneously, and it is
not easily generalizable, as the token-level values from the critic model can
make training prone to overfitting. GRPO is critic-free and supports verifiable
rewards, but spreads a single sequence-level return across tokens and ignores
branching. We introduce \textbf{Prefix-to-Tree (P2T)}, a simple procedure that
converts a group of responses into a prefix tree and computes
\emph{nonparametric} prefix values \(V(s)\) by aggregating descendant outcomes.
Built on P2T, we propose \textbf{TEMPO} (\emph{\textbf{T}ree-\textbf{E}stimated
\textbf{M}ean Prefix Value for \textbf{P}olicy \textbf{O}ptimization}), a
critic-free algorithm that augments the group-relative outcome signal of GRPO
with \emph{branch-gated} temporal-difference corrections derived from the tree.
At non-branch tokens, the temporal-difference (TD) term is zero, so TEMPO
reduces to GRPO; at branching tokens, it supplies precise token-level credit
without a learned value network or extra judges/teachers. On Qwen3-1.7B/4B,
TEMPO outperforms PPO and GRPO on in-distribution (MATH, MedQA) and
out-of-distribution (GSM-HARD, AMC23, MedMCQA, MMLU-Medical) benchmarks, and
reaches higher validation accuracy with roughly the same wall-clock time.

</details>


### [134] [Brittleness and Promise: Knowledge Graph Based Reward Modeling for Diagnostic Reasoning](https://arxiv.org/abs/2509.18316)
*Saksham Khatwani,He Cheng,Majid Afshar,Dmitriy Dligach,Yanjun Gao*

Main category: cs.CL

TL;DR: LLMs在诊断推理方面显示出潜力，但缺乏可靠的知识支持。本文提出将LLM作为知识图谱（KG）推理路径的奖励模型，以判断候选路径是否能正确诊断患者，而非直接生成。研究评估了五种任务制定和八种训练范式，并测试了其在诊断总结和医学问答等下游任务上的泛化能力。结果表明，虽然特定奖励优化和蒸馏能提高路径判断性能，但迁移到下游任务的效果有限。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLM）在诊断推理方面有潜力，但缺乏可靠的、基于知识的推理能力。知识图谱（KG）提供了结构化的生物医学知识，可以支持可信赖的推理。以往的方法通常通过检索增强生成或微调来集成KG，但未能实现结构化推理。因此，探索一种新的范式，将LLM作为KG推理路径的奖励模型，以提高其推理能力。

Method: 提出将LLM视为知识图谱（KG）推理路径的奖励模型，让模型学习判断候选路径是否能正确诊断患者。该方法受近期利用奖励训练增强模型推理能力的工作启发，并借鉴了计算理论中验证解通常比从头生成解更容易的观点。实验中，系统评估了五种用于知识路径判断的任务制定和八种训练范式，并测试了这些判断能力在诊断总结和医学问答等下游任务上的泛化性。

Result: 通过对三个开源指令微调LLM的实验，研究发现，虽然特定的奖励优化和蒸馏方法带来了强大的路径判断性能，但这些能力在迁移到下游诊断任务（如诊断总结和医学问答）时表现不佳，泛化能力较弱。

Conclusion: 本研究首次系统评估了在临床知识图谱上进行“奖励模型风格”推理，并探讨了结构化、基于奖励的监督如何影响生成式人工智能医疗系统的诊断推理能力。研究结果揭示了该方法的潜力和局限性，为未来在医疗领域应用LLM和KG提供了见解。

Abstract: Large language models (LLMs) show promise for diagnostic reasoning but often
lack reliable, knowledge grounded inference. Knowledge graphs (KGs), such as
the Unified Medical Language System (UMLS), offer structured biomedical
knowledge that can support trustworthy reasoning. Prior approaches typically
integrate KGs via retrieval augmented generation or fine tuning, inserting KG
content into prompts rather than enabling structured reasoning. We explore an
alternative paradigm: treating the LLM as a reward model of KG reasoning paths,
where the model learns to judge whether a candidate path leads to correct
diagnosis for a given patient input. This approach is inspired by recent work
that leverages reward training to enhance model reasoning abilities, and
grounded in computational theory, which suggests that verifying a solution is
often easier than generating one from scratch. It also parallels physicians'
diagnostic assessment, where they judge which sequences of findings and
intermediate conditions most plausibly support a diagnosis. We first
systematically evaluate five task formulation for knowledge path judging and
eight training paradigm. Second, we test whether the path judging abilities
generalize to downstream diagnostic tasks, including diagnosis summarization
and medical question answering. Experiments with three open source
instruct-tuned LLMs reveal both promise and brittleness: while specific reward
optimization and distillation lead to strong path-judging performance, the
transferability to downstream tasks remain weak. Our finding provides the first
systematic assessment of "reward model style" reasoning over clinical KGs,
offering insights into how structured, reward-based supervision influences
diagnostic reasoning in GenAI systems for healthcare.

</details>


### [135] [Speculate Deep and Accurate: Lossless and Training-Free Acceleration for Offloaded LLMs via Substitute Speculative Decoding](https://arxiv.org/abs/2509.18344)
*Pei-Shuo Wang,Jian-Jia Chen,Chun-Che Yang,Chi-Chih Chang,Ning-Chi Huang,Mohamed S. Abdelfattah,Kai-Chiang Wu*

Main category: cs.CL

TL;DR: SubSpec是一种无损、无需训练的即插即用方法，通过生成低比特量化的替代层来加速参数卸载，可显著提高LLM的推理速度，特别是在内存受限的情况下。


<details>
  <summary>Details</summary>
Motivation: LLMs的巨大模型尺寸给内存有限的消费级GPU带来了部署挑战。模型压缩会降低质量，而参数卸载会带来缓慢的推理速度。现有的加速方法通常需要额外的训练来适应定制模型，或者产生的加速效果有限。

Method: SubSpec通过生成目标LLM部分低比特量化的替代层来构建高度匹配的草稿模型。此外，该方法共享GPU上剩余的层和KV缓存，以进一步降低内存开销并增强匹配度。

Result: SubSpec实现了很高的平均接受长度，在MT-Bench（8GB显存限制）上对Qwen2.5 7B实现了9.1倍的加速，在流行的生成基准测试（24GB显存限制）上对Qwen2.5 32B实现了平均12.5倍的加速。

Conclusion: SubSpec能够有效解决内存限制问题，并在不损失模型质量的情况下显著提高LLM的推理速度。

Abstract: The immense model sizes of large language models (LLMs) challenge deployment
on memory-limited consumer GPUs. Although model compression and parameter
offloading are common strategies to address memory limitations, compression can
degrade quality, and offloading maintains quality but suffers from slow
inference. Speculative decoding presents a promising avenue to accelerate
parameter offloading, utilizing a fast draft model to propose multiple draft
tokens, which are then verified by the target LLM in parallel with a single
forward pass. This method reduces the time-consuming data transfers in forward
passes that involve offloaded weight transfers. Existing methods often rely on
pretrained weights of the same family, but require additional training to align
with custom-trained models. Moreover, approaches that involve draft model
training usually yield only modest speedups. This limitation arises from
insufficient alignment with the target model, preventing higher token
acceptance lengths. To address these challenges and achieve greater speedups,
we propose SubSpec, a plug-and-play method to accelerate parameter offloading
that is lossless and training-free. SubSpec constructs a highly aligned draft
model by generating low-bit quantized substitute layers from offloaded target
LLM portions. Additionally, our method shares the remaining GPU-resident layers
and the KV-Cache, further reducing memory overhead and enhance alignment.
SubSpec achieves a high average acceptance length, delivering 9.1x speedup for
Qwen2.5 7B on MT-Bench (8GB VRAM limit) and an average of 12.5x speedup for
Qwen2.5 32B on popular generation benchmarks (24GB VRAM limit).

</details>


### [136] [Speech Vecalign: an Embedding-based Method for Aligning Parallel Speech Documents](https://arxiv.org/abs/2509.18360)
*Chutong Meng,Philipp Koehn*

Main category: cs.CL

TL;DR: Speech Vecalign是一种新的语音-语音对齐方法，无需文本即可实现单调对齐，并且比现有方法更鲁棒。


<details>
  <summary>Details</summary>
Motivation: 现有语音对齐方法依赖文本或不够鲁棒，限制了语音翻译模型的训练。

Method: Speech Vecalign是一种并行语音文档对齐方法，对语音段嵌入进行单调对齐，不依赖文本。

Result: 在3000小时的未标记英语-德语并行语音数据上，Speech Vecalign产生了约1000小时的高质量对齐。基于此数据训练的语音翻译模型在En-De和De-En方向上比基线方法Global Mining的ASR-BLEU分别提高了0.37和0.18。同时，该模型在使用的原始语音文档数量是SpeechMatrix的1/8的情况下，性能相当或更优。

Conclusion: Speech Vecalign是一种有效的语音-语音对齐方法，可以显著提高语音翻译模型的性能，并且在数据效率方面具有优势。

Abstract: We present Speech Vecalign, a parallel speech document alignment method that
monotonically aligns speech segment embeddings and does not depend on text
transcriptions. Compared to the baseline method Global Mining, a variant of
speech mining, Speech Vecalign produces longer speech-to-speech alignments. It
also demonstrates greater robustness than Local Mining, another speech mining
variant, as it produces less noise. We applied Speech Vecalign to 3,000 hours
of unlabeled parallel English-German (En-De) speech documents from VoxPopuli,
yielding about 1,000 hours of high-quality alignments. We then trained En-De
speech-to-speech translation models on the aligned data. Speech Vecalign
improves the En-to-De and De-to-En performance over Global Mining by 0.37 and
0.18 ASR-BLEU, respectively. Moreover, our models match or outperform
SpeechMatrix model performance, despite using 8 times fewer raw speech
documents.

</details>


### [137] [Interactive Real-Time Speaker Diarization Correction with Human Feedback](https://arxiv.org/abs/2509.18377)
*Xinlu He,Yiwen Guan,Badrivishal Paurana,Zilin Dai,Jacob Whitehill*

Main category: cs.CL

TL;DR: 该研究提出了一种由大型语言模型（LLM）辅助的说话人日志纠错系统，利用用户实时反馈来提高语音处理系统的准确性。


<details>
  <summary>Details</summary>
Motivation: 现有自动语音处理系统在缺乏用户反馈的情况下运行，而引入用户反馈有望提高准确性。

Method: 系统结合了流式自动语音识别（ASR）和说话人日志，利用LLM生成简洁的摘要供用户审查，并接受用户的简短语音反馈。该系统还引入了“分割后合并”（SWM）技术来修正多说话人片段的错误归属，并通过在线说话人注册来收集用户纠错信息，以预防未来错误。

Result: 在AMI测试集上的LLM驱动模拟显示，该系统将说话人日志错误率（DER）显著降低了9.92%，将说话人混淆错误降低了44.23%。研究还分析了不同设置（如摘要与完整文本显示、在线注册数量限制、纠错频率）对纠错效果的影响。

Conclusion: 所提出的LLM辅助的说话人日志纠错系统能有效提高语音处理的准确性，通过用户实时反馈和创新的技术手段解决了现有系统的局限性。

Abstract: Most automatic speech processing systems operate in "open loop" mode without
user feedback about who said what; yet, human-in-the-loop workflows can
potentially enable higher accuracy. We propose an LLM-assisted speaker
diarization correction system that lets users fix speaker attribution errors in
real time. The pipeline performs streaming ASR and diarization, uses an LLM to
deliver concise summaries to the users, and accepts brief verbal feedback that
is immediately incorporated without disrupting interactions. Moreover, we
develop techniques to make the workflow more effective: First, a
split-when-merged (SWM) technique detects and splits multi-speaker segments
that the ASR erroneously attributes to just a single speaker. Second, online
speaker enrollments are collected based on users' diarization corrections, thus
helping to prevent speaker diarization errors from occurring in the future.
LLM-driven simulations on the AMI test set indicate that our system
substantially reduces DER by 9.92% and speaker confusion error by 44.23%. We
further analyze correction efficacy under different settings, including summary
vs full transcript display, the number of online enrollments limitation, and
correction frequency.

</details>


### [138] [NormGenesis: Multicultural Dialogue Generation via Exemplar-Guided Social Norm Modeling and Violation Recovery](https://arxiv.org/abs/2509.18395)
*Minki Hong,Jangho Choi,Jihie Kim*

Main category: cs.CL

TL;DR: NormGenesis是一个多文化框架，用于生成和标注跨英语、中文和韩语的社会化对话。它通过引入新颖的对话类型“违规到解决”（V2R）来模拟社会互动动态，并采用基于示例的迭代细化方法来提高非代表性语言的语用一致性。该框架构建了一个包含10,800个多轮对话的数据集，并在对话合规性、说话者意图和情感反应方面进行了标注。


<details>
  <summary>Details</summary>
Motivation: 为了在对话系统中生成不仅连贯而且在社会可接受的响应，需要对社会规范进行建模，以指导符合文化适当行为的交流。

Method: 提出了一种新颖的对话类型“违规到解决”（V2R），以模拟遵循规范违规的对话进展，通过识别和适当的社会修复。在对话合成过程早期实现基于示例的迭代细化，以提高非代表性语言的语用一致性。构建了一个包含10,800个多轮对话的数据集，并在每个回合中对规范合规性、说话者意图和情感反应进行标注。

Result: 使用NormGenesis框架构建的数据集，在对话质量、自然度和泛化性能方面显著优于现有数据集。在V2R增强数据上训练的模型在涉及伦理敏感性的情境中表现出更强的语用能力。

Conclusion: NormGenesis为文化适应性对话建模设立了新的基准，并为跨语言和文化多样性的规范感知生成提供了一种可扩展的方法。

Abstract: Social norms govern culturally appropriate behavior in communication,
enabling dialogue systems to produce responses that are not only coherent but
also socially acceptable. We present NormGenesis, a multicultural framework for
generating and annotating socially grounded dialogues across English, Chinese,
and Korean. To model the dynamics of social interaction beyond static norm
classification, we propose a novel dialogue type, Violation-to-Resolution
(V2R), which models the progression of conversations following norm violations
through recognition and socially appropriate repair. To improve pragmatic
consistency in underrepresented languages, we implement an exemplar-based
iterative refinement early in the dialogue synthesis process. This design
introduces alignment with linguistic, emotional, and sociocultural expectations
before full dialogue generation begins. Using this framework, we construct a
dataset of 10,800 multi-turn dialogues annotated at the turn level for norm
adherence, speaker intent, and emotional response. Human and LLM-based
evaluations demonstrate that NormGenesis significantly outperforms existing
datasets in refinement quality, dialogue naturalness, and generalization
performance. We show that models trained on our V2R-augmented data exhibit
improved pragmatic competence in ethically sensitive contexts. Our work
establishes a new benchmark for culturally adaptive dialogue modeling and
provides a scalable methodology for norm-aware generation across linguistically
and culturally diverse languages.

</details>


### [139] [Evaluating the Creativity of LLMs in Persian Literary Text Generation](https://arxiv.org/abs/2509.18401)
*Armin Tourajmehr,Mohammad Reza Modarres,Yadollah Yaghoobzadeh*

Main category: cs.CL

TL;DR: LLMs在生成波斯文学文本方面展现了潜力，但仍需改进，并且研究提出了一种结合人类判断和LLM的评估方法。


<details>
  <summary>Details</summary>
Motivation: 评估LLMs生成具有文化相关表达的波斯文学文本的能力，并解决现有研究主要集中在英语和缺乏标准化创造力评估方法的不足。

Method: 构建了一个包含20个不同主题的用户生成波斯文学数据集。采用改编的Torrance创造性思维测试来评估模型输出的原创性、流畅性、灵活性和精细度。为了降低成本，使用LLM作为自动评分的裁判，并通过组内相关系数验证其与人类判断的一致性。同时，分析了模型理解和运用四种核心文学手法（明喻、隐喻、夸张、对立）的能力。

Result: LLMs在波斯文学文本生成方面既有优势也有局限性。LLM作为评估裁判与人类判断高度一致，表明其作为评估工具的可靠性。

Conclusion: LLMs在生成波斯文学文本方面取得了进展，但其能力仍有待提高，需要进一步的优化和研究。

Abstract: Large language models (LLMs) have demonstrated notable creative abilities in
generating literary texts, including poetry and short stories. However, prior
research has primarily centered on English, with limited exploration of
non-English literary traditions and without standardized methods for assessing
creativity. In this paper, we evaluate the capacity of LLMs to generate Persian
literary text enriched with culturally relevant expressions. We build a dataset
of user-generated Persian literary spanning 20 diverse topics and assess model
outputs along four creativity dimensions-originality, fluency, flexibility, and
elaboration-by adapting the Torrance Tests of Creative Thinking. To reduce
evaluation costs, we adopt an LLM as a judge for automated scoring and validate
its reliability against human judgments using intraclass correlation
coefficients, observing strong agreement. In addition, we analyze the models'
ability to understand and employ four core literary devices: simile, metaphor,
hyperbole, and antithesis. Our results highlight both the strengths and
limitations of LLMs in Persian literary text generation, underscoring the need
for further refinement.

</details>


### [140] [Developing an AI framework to automatically detect shared decision-making in patient-doctor conversations](https://arxiv.org/abs/2509.18439)
*Oscar J. Ponce-Ponte,David Toro-Tobon,Luis F. Figueroa,Michael Gionfriddo,Megan Branda,Victor M. Montori,Saturnino Luz,Juan P. Brito*

Main category: cs.CL

TL;DR: 本研究提出了一种自动测量患者-医生共享决策（SDM）的方法，利用语言模型和对话一致性（CA）得分来评估SDM。


<details>
  <summary>Details</summary>
Motivation: 目前缺乏自动测量SDM的方法，而SDM对于实现以患者为中心至关重要。

Method: 通过对157个患者-医生对话进行转录和分段，利用深度学习（DL）模型和微调的BERT模型（通过下一个句子预测任务）来训练模型，并计算四种CA得分。然后，使用随机效应模型评估CA得分与SDM结果（DCS和OPTION12得分）之间的关联。

Result: BERTbase模型达到了最高的召回率@1（0.640）。部分CA得分与OPTION12和DCS得分相关，表明所提出的方法可以衡量SDM。

Conclusion: 本研究成功开发了一种自动化、可扩展的方法，通过可解释的CA得分来测量患者-医生对话中的SDM，有潜力大规模评估SDM策略。

Abstract: Shared decision-making (SDM) is necessary to achieve patient-centred care.
Currently no methodology exists to automatically measure SDM at scale. This
study aimed to develop an automated approach to measure SDM by using language
modelling and the conversational alignment (CA) score. A total of 157
video-recorded patient-doctor conversations from a randomized multi-centre
trial evaluating SDM decision aids for anticoagulation in atrial fibrillations
were transcribed and segmented into 42,559 sentences. Context-response pairs
and negative sampling were employed to train deep learning (DL) models and
fine-tuned BERT models via the next sentence prediction (NSP) task. Each
top-performing model was used to calculate four types of CA scores. A
random-effects analysis by clinician, adjusting for age, sex, race, and trial
arm, assessed the association between CA scores and SDM outcomes: the
Decisional Conflict Scale (DCS) and the Observing Patient Involvement in
Decision-Making 12 (OPTION12) scores. p-values were corrected for multiple
comparisons with the Benjamini-Hochberg method. Among 157 patients (34% female,
mean age 70 SD 10.8), clinicians on average spoke more words than patients
(1911 vs 773). The DL model without the stylebook strategy achieved a recall@1
of 0.227, while the fine-tuned BERTbase (110M) achieved the highest recall@1
with 0.640. The AbsMax (18.36 SE7.74 p=0.025) and Max CA (21.02 SE7.63 p=0.012)
scores generated with the DL without stylebook were associated with OPTION12.
The Max CA score generated with the fine-tuned BERTbase (110M) was associated
with the DCS score (-27.61 SE12.63 p=0.037). BERT model sizes did not have an
impact the association between CA scores and SDM. This study introduces an
automated, scalable methodology to measure SDM in patient-doctor conversations
through explainable CA scores, with potential to evaluate SDM strategies at
scale.

</details>


### [141] [CogniLoad: A Synthetic Natural Language Reasoning Benchmark With Tunable Length, Intrinsic Difficulty, and Distractor Density](https://arxiv.org/abs/2509.18458)
*Daniel Kaiser,Arnoldo Frigessi,Ali Ramezani-Kebrya,Benjamin Ricaud*

Main category: cs.CL

TL;DR: CogniLoad是一个新的基准测试，用于评估LLM在长上下文推理方面的能力，通过控制内在难度、干扰和任务长度来更精确地分析LLM的局限性。


<details>
  <summary>Details</summary>
Motivation: 当前的LLM长上下文推理基准测试未能有效地区分任务复杂性、干扰和任务长度等关键因素，阻碍了精确的失败分析。因此，需要一个能够独立控制这些因素的基准测试。

Method: CogniLoad使用认知负荷理论（CLT）生成自然语言逻辑谜题，并通过三个参数独立控制：内在难度（d）控制内在负荷，干扰与信号之比（ρ）调节外在负荷，任务长度（N）作为对需要内在负荷的条件的代理。对22个SotA推理LLM进行了评估。

Result: 评估结果显示，不同的LLM在CogniLoad上的表现存在差异，其中任务长度是主要的性能限制因素。此外，研究还发现了LLM对内在复杂性的不同敏感度以及对干扰比例的U型反应模式。

Conclusion: CogniLoad通过对认知负荷维度进行系统性、阶梯式控制，提供了一个可复现、可扩展且诊断性强的工具，能够深入剖析LLM的推理局限性，并为未来的模型开发提供指导。

Abstract: Current benchmarks for long-context reasoning in Large Language Models (LLMs)
often blur critical factors like intrinsic task complexity, distractor
interference, and task length. To enable more precise failure analysis, we
introduce CogniLoad, a novel synthetic benchmark grounded in Cognitive Load
Theory (CLT). CogniLoad generates natural-language logic puzzles with
independently tunable parameters that reflect CLT's core dimensions: intrinsic
difficulty ($d$) controls intrinsic load; distractor-to-signal ratio ($\rho$)
regulates extraneous load; and task length ($N$) serves as an operational proxy
for conditions demanding germane load. Evaluating 22 SotA reasoning LLMs,
CogniLoad reveals distinct performance sensitivities, identifying task length
as a dominant constraint and uncovering varied tolerances to intrinsic
complexity and U-shaped responses to distractor ratios. By offering systematic,
factorial control over these cognitive load dimensions, CogniLoad provides a
reproducible, scalable, and diagnostically rich tool for dissecting LLM
reasoning limitations and guiding future model development.

</details>


### [142] [Trace Is In Sentences: Unbiased Lightweight ChatGPT-Generated Text Detector](https://arxiv.org/abs/2509.18535)
*Mo Mu,Dianqiao Lei,Chang Li*

Main category: cs.CL

TL;DR: 检测AI生成文本的挑战在于其易被改写和模型本身的偏见，本研究提出一种基于文本内部结构不变性的轻量级检测框架，通过编码句子嵌入、注意力机制、对比学习和因果图来解决这些问题，并在两个数据集上验证了方法的有效性。


<details>
  <summary>Details</summary>
Motivation: 现有AI生成文本检测器容易受到改写或简单提示的影响，存在模型偏见、训练数据内容偏见、对修改文本的鲁棒性差以及需要大型模型或在线交互等问题。

Method: 提出一种新颖的检测任务，并设计了一个轻量级框架，该框架基于文本的内部结构进行分类，这种结构在词语层面修改下保持不变。具体方法包括：1. 使用预训练语言模型编码句子嵌入。2. 利用注意力机制对句子嵌入之间的关系进行建模。3. 采用对比学习减轻自回归生成引起的嵌入偏见。4. 结合因果图和反事实方法，将结构特征与主题偏见分离开。

Result: 在两个精心策划的数据集（包括摘要比较和修改后的生活FAQ）上进行了实验，验证了所提出方法的有效性。

Conclusion: 本研究提出的基于内部结构分析的检测框架能够有效检测原始和经过改写的AI生成文本，并能克服现有方法的局限性。

Abstract: The widespread adoption of ChatGPT has raised concerns about its misuse,
highlighting the need for robust detection of AI-generated text. Current
word-level detectors are vulnerable to paraphrasing or simple prompts (PSP),
suffer from biases induced by ChatGPT's word-level patterns (CWP) and training
data content, degrade on modified text, and often require large models or
online LLM interaction. To tackle these issues, we introduce a novel task to
detect both original and PSP-modified AI-generated texts, and propose a
lightweight framework that classifies texts based on their internal structure,
which remains invariant under word-level changes. Our approach encodes sentence
embeddings from pre-trained language models and models their relationships via
attention. We employ contrastive learning to mitigate embedding biases from
autoregressive generation and incorporate a causal graph with counterfactual
methods to isolate structural features from topic-related biases. Experiments
on two curated datasets, including abstract comparisons and revised life FAQs,
validate the effectiveness of our method.

</details>


### [143] [LAWCAT: Efficient Distillation from Quadratic to Linear Attention with Convolution across Tokens for Long Context Modeling](https://arxiv.org/abs/2509.18467)
*Zeyu Liu,Souvik Kundu,Lianghao Jiang,Anni Li,Srikanth Ronanki,Sravan Bodapati,Gourav Datta,Peter A. Beerel*

Main category: cs.CL

TL;DR: LAWCAT是一个新的框架，可以将预训练Transformer的能力转移到高效的线性注意力模型中，解决了Transformer的长序列计算瓶颈问题。


<details>
  <summary>Details</summary>
Motivation: Transformer模型在处理长序列时存在二次计算复杂度的问题，限制了其在长上下文应用中的性能，而现有的线性复杂度模型训练成本高。

Method: LAWCAT框架结合了因果Conv1D层来建模局部依赖关系，并使用归一化的门控线性注意力来提高跨不同上下文长度的泛化能力。

Result: LAWCAT在长上下文任务中表现出色，例如Mistral-7B模型在仅使用1K序列进行蒸馏后，在22K长度的序列上仍能达到90%以上的passkey检索准确率。同时，Llama3.2-1B LAWCAT变体在S-NIAH和BABILong基准测试中表现出竞争力，且预训练计算量远低于现有模型。此外，LAWCAT在长序列（超过8K）上的预填充速度优于FlashAttention-2。

Conclusion: LAWCAT为构建高性能、长上下文的线性模型提供了一条有效途径，适用于边缘部署，并减少了对长序列训练数据和计算资源的需求。

Abstract: Although transformer architectures have achieved state-of-the-art performance
across diverse domains, their quadratic computational complexity with respect
to sequence length remains a significant bottleneck, particularly for
latency-sensitive long-context applications. While recent linear-complexity
alternatives are increasingly powerful, effectively training them from scratch
is still resource-intensive. To overcome these limitations, we propose LAWCAT
(Linear Attention with Convolution Across Time), a novel linearization
framework designed to efficiently transfer the capabilities of pre-trained
transformers into a performant linear attention architecture. LAWCAT integrates
causal Conv1D layers to enhance local dependency modeling and employs
normalized gated linear attention to improve generalization across varying
context lengths. Our comprehensive evaluations demonstrate that, distilling
Mistral-7B with only 1K-length sequences yields over 90\% passkey retrieval
accuracy up to 22K tokens, significantly extending its effective context
window. Similarly, Llama3.2-1B LAWCAT variant achieves competitive performance
on S-NIAH 1\&2\&3 tasks (1K-8K context length) and BABILong benchmark
(QA2\&QA3, 0K-16K context length), requiring less than 0.1\% pre-training
tokens compared with pre-training models. Furthermore, LAWCAT exhibits faster
prefill speeds than FlashAttention-2 for sequences exceeding 8K tokens. LAWCAT
thus provides an efficient pathway to high-performance, long-context linear
models suitable for edge deployment, reducing reliance on extensive
long-sequence training data and computational resources.

</details>


### [144] [Actions Speak Louder than Prompts: A Large-Scale Study of LLMs for Graph Inference](https://arxiv.org/abs/2509.18487)
*Ben Finkelshtein,Silviu Cucerzan,Sujay Kumar Jauhar,Ryen White*

Main category: cs.CL

TL;DR: LLM在图机器学习任务中表现出潜力，但对其能力缺乏系统性理解。本文通过大规模、受控的评估，探索了LLM与图数据交互的多种模式（提示、工具使用、代码生成）、数据集类型、结构模式、特征特征和模型配置，并分析了其对输入类型的依赖性。


<details>
  <summary>Details</summary>
Motivation: 评估LLM在文本图机器学习任务中的能力，系统性地理解其优势和劣势。

Method: 通过大规模、受控的实验，评估了LLM在图机器学习中的多种交互模式（提示、工具使用、代码生成）、数据集类型、结构模式、特征特征和模型配置，并分析了其对输入类型的依赖性。

Result: 1. LLM作为代码生成器在图数据上表现最佳，尤其是在长文本或高度图上。2. 所有交互策略在异质图上均有效。3. 代码生成可以灵活地在结构、特征或标签之间切换依赖。4. 评估了LLM对输入类型的依赖性。

Conclusion: LLM在图机器学习任务中具有潜力，代码生成模式表现最佳。研究结果为未来的LLM-图交互方法提供了关键的设计原则。

Abstract: Large language models (LLMs) are increasingly used for text-rich graph
machine learning tasks such as node classification in high-impact domains like
fraud detection and recommendation systems. Yet, despite a surge of interest,
the field lacks a principled understanding of the capabilities of LLMs in their
interaction with graph data. In this work, we conduct a large-scale, controlled
evaluation across several key axes of variability to systematically assess the
strengths and weaknesses of LLM-based graph reasoning methods in text-based
applications. The axes include the LLM-graph interaction mode, comparing
prompting, tool-use, and code generation; dataset domains, spanning citation,
web-link, e-commerce, and social networks; structural regimes contrasting
homophilic and heterophilic graphs; feature characteristics involving both
short- and long-text node attributes; and model configurations with varying LLM
sizes and reasoning capabilities. We further analyze dependencies by
methodically truncating features, deleting edges, and removing labels to
quantify reliance on input types. Our findings provide practical and actionable
guidance. (1) LLMs as code generators achieve the strongest overall performance
on graph data, with especially large gains on long-text or high-degree graphs
where prompting quickly exceeds the token budget. (2) All interaction
strategies remain effective on heterophilic graphs, challenging the assumption
that LLM-based methods collapse under low homophily. (3) Code generation is
able to flexibly adapt its reliance between structure, features, or labels to
leverage the most informative input type. Together, these findings provide a
comprehensive view of the strengths and limitations of current LLM-graph
interaction modes and highlight key design principles for future approaches.

</details>


### [145] [A Rhythm-Aware Phrase Insertion for Classical Arabic Poetry Composition](https://arxiv.org/abs/2509.18514)
*Mohamad Elzohbi,Richard Zhao*

Main category: cs.CL

TL;DR: We present a method using ByT5 to insert Arabic poem phrases for specific rhythm, employing a rule-based rhythm extraction, conditional denoising, and curriculum learning. The model shows high rhythmic alignment and semantic coherence, with potential for co-creative poetry composition.


<details>
  <summary>Details</summary>
Motivation: The motivation is to develop a method for inserting phrases into Arabic poems to ensure they conform to a specific rhythm, aiding in the composition of classical Arabic poetry.

Method: The methodology involves using ByT5, a byte-level multilingual transformer, and a rule-based grapheme-to-beat transformation to extract rhythm from Arabic script. The ByT5 model is fine-tuned using a conditional denoising objective where it reconstructs masked words to match a target rhythm. A curriculum learning strategy is used, involving pre-training on a general Arabic dataset and then fine-tuning on a poetic dataset. Cross-lingual transfer from English to Arabic is also explored.

Result: Experimental results show that the proposed models achieve high rhythmic alignment with the target rhythm while preserving the semantic coherence of the poem phrases.

Conclusion: The proposed model demonstrates the capability to generate Arabic poem phrases that adhere to a specific rhythm and maintain semantic coherence, indicating its potential utility in co-creative applications for composing classical Arabic poetry.

Abstract: This paper presents a methodology for inserting phrases in Arabic poems to
conform to a specific rhythm using ByT5, a byte-level multilingual
transformer-based model. Our work discusses a rule-based grapheme-to-beat
transformation tailored for extracting the rhythm from fully diacritized Arabic
script. Our approach employs a conditional denoising objective to fine-tune
ByT5, where the model reconstructs masked words to match a target rhythm. We
adopt a curriculum learning strategy, pre-training on a general Arabic dataset
before fine-tuning on poetic dataset, and explore cross-lingual transfer from
English to Arabic. Experimental results demonstrate that our models achieve
high rhythmic alignment while maintaining semantic coherence. The proposed
model has the potential to be used in co-creative applications in the process
of composing classical Arabic poems.

</details>


### [146] [CCQA: Generating Question from Solution Can Improve Inference-Time Reasoning in SLMs](https://arxiv.org/abs/2509.18536)
*Jin Young Kim,Ji Won Yoon*

Main category: cs.CL

TL;DR: CCQA是一种新颖的推理方法，通过生成问题-答案对并评估其与原始问题的相似度来提高小型语言模型（SLM）的准确性。它使用一个轻量级的Flan-T5模型来生成问题，并在数学和常识推理基准测试中超越了现有的SOTA方法，为SLMs建立了新的高效推理基线。


<details>
  <summary>Details</summary>
Motivation: 尽管推理时间推理策略提高了大型语言模型的准确性，但它们在小型模型上的效果尚不清楚。传统方法在此背景下通常无法提高性能。

Method: CCQA方法生成每个推理路径和答案的问题，评估其与原始问题的相似度，并选择相似度得分最高的候选解决方案作为最终响应。为支持问题生成，采用了轻量级Flan-T5模型。

Result: 实验结果表明，CCQA在数学和常识推理基准测试的八个模型上持续优于现有的SOTA方法，并为SLMs建立了新的实用高效推理基线。

Conclusion: CCQA是一种有效的方法，可以提高小型语言模型在推理任务中的准确性，并为未来的研究设定了新的基准。

Abstract: Recently, inference-time reasoning strategies have further improved the
accuracy of large language models (LLMs), but their effectiveness on smaller
models remains unclear. Based on the observation that conventional approaches
often fail to improve performance in this context, we propose
\textbf{C}ycle-\textbf{C}onsistency in \textbf{Q}uestion \textbf{A}nswering
(CCQA), a novel reasoning method that can be effectively applied to SLMs.
Inspired by cycle consistency, CCQA generates a question from each reasoning
path and answer, evaluates each by its similarity to the original question, and
then selects the candidate solution with the highest similarity score as the
final response. Since conventional SLMs struggle to generate accurate questions
from their own reasoning paths and answers, we employ a lightweight Flan-T5
model specialized for question generation to support this process efficiently.
From the experimental results, it is verified that CCQA consistently
outperforms existing state-of-the-art (SOTA) methods across eight models on
mathematical and commonsense reasoning benchmarks. Furthermore, our method
establishes a new practical baseline for efficient reasoning in SLMs. Source
code can be found at https://github.com/scai-research/ccqa_official.

</details>


### [147] [Prior-based Noisy Text Data Filtering: Fast and Strong Alternative For Perplexity](https://arxiv.org/abs/2509.18577)
*Yeongbin Seo,Gayoung Kim,Jaehyung Kim,Jinyoung Yeo*

Main category: cs.CL

TL;DR: 提出一种基于 token 先验的文本过滤方法，通过计算词频统计来估计 token 先验，以此替代 PPL 过滤，能显著降低成本并提高性能。


<details>
  <summary>Details</summary>
Motivation: PPL 过滤方法存在耗时和不可靠的问题，需要更优的过滤方法。

Method: 通过计算 token 的先验概率（基于语料库的词频统计），并根据 token 先验的均值和标准差来过滤文档。

Result: 所提出的方法在 20 个下游基准测试中取得了最佳的平均性能，并将时间成本降低了 1000 倍以上。该方法还适用于代码和数学等符号语言，并能动态适应多语言语料库。

Conclusion: 基于 token 先验的过滤方法是一种简单、快速且有效的替代 PPL 过滤的方法，具有广泛的应用前景。

Abstract: As large language models (LLMs) are pretrained on massive web corpora,
careful selection of data becomes essential to ensure effective and efficient
learning. While perplexity (PPL)-based filtering has shown strong performance,
it suffers from drawbacks: substantial time costs and inherent unreliability of
the model when handling noisy or out-of-distribution samples. In this work, we
propose a simple yet powerful alternative: a prior-based data filtering method
that estimates token priors using corpus-level term frequency statistics,
inspired by linguistic insights on word roles and lexical density. Our approach
filters documents based on the mean and standard deviation of token priors,
serving as a fast proxy to PPL while requiring no model inference. Despite its
simplicity, the prior-based filter achieves the highest average performance
across 20 downstream benchmarks, while reducing time cost by over 1000x
compared to PPL-based filtering. We further demonstrate its applicability to
symbolic languages such as code and math, and its dynamic adaptability to
multilingual corpora without supervision

</details>


### [148] [TsqLoRA: Towards Sensitivity and Quality Low-Rank Adaptation for Efficient Fine-Tuning](https://arxiv.org/abs/2509.18585)
*Yu Chen,Yifei Han,Long Zhang,Yue Du,Bin Li*

Main category: cs.CL

TL;DR: TsqLoRA通过整合数据质量驱动的选择和敏感度感知的低秩适配，在保持甚至提高性能的同时，提高了模型微调的效率。


<details>
  <summary>Details</summary>
Motivation: 完全微调大型预训练模型计算成本高，内存占用大，尤其是在资源受限的环境中。现有的参数高效微调方法忽略了不同模型层对训练数据的敏感性差异和重要性。

Method: TsqLoRA包含两个主要组件：一个质量感知采样机制，用于选择信息量最大的训练数据；一个动态秩分配模块，根据每层对参数更新的敏感度来调整其秩。

Result: 实验结果表明，TsqLoRA在多种NLP任务上提高了微调效率，同时保持或提高了性能。

Conclusion: TsqLoRA是一种新颖的参数高效微调方法，通过考虑数据质量和模型层敏感度，在计算和性能之间取得了良好的平衡。

Abstract: Fine-tuning large pre-trained models for downstream tasks has become a
fundamental approach in natural language processing. Fully fine-tuning all
model parameters is computationally expensive and memory-intensive, especially
in resource-constrained environments. Existing parameter-efficient fine-tuning
methods reduce the number of trainable parameters but typically overlook the
varying sensitivity of different model layers and the importance of training
data. In this work, we propose TsqLoRA, a novel method that integrates
data-quality-driven selection with sensitivity-aware low-rank adaptation,
consisted of two main components: a quality-aware sampling mechanism for
selecting the most informative training data, and a dynamic rank allocation
module that adjusts the rank of each layer based on its sensitivity to
parameter updates. The experimental results demonstrate that TsqLoRA improves
fine-tuning efficiency while maintaining or even improving performance on a
variety of NLP tasks. Our code will be available at
https://github.com/Benjamin-Ricky/TsqLoRA.

</details>


### [149] [UniECG: Understanding and Generating ECG in One Unified Model](https://arxiv.org/abs/2509.18588)
*Jiarui Jin,Haoyu Wang,Xiang Lan,Jun Li,Gaofeng Cheng,Hongyan Li,Shenda Hong*

Main category: cs.CL

TL;DR: UniECG是首个能够同时进行循证心电图解释和文本条件心电图生成的统一模型。


<details>
  <summary>Details</summary>
Motivation: 现有的统一模型在理解心电图信号和生成心电图方面存在局限性，无法提供准确的医学诊断。

Method: UniECG采用解耦的两阶段训练方法：首先学习循证解释（心电图到文本），然后通过潜在空间对齐注入心电图生成能力（文本到心电图）。

Result: UniECG能够根据用户输入自主选择解释或生成心电图，扩展了当前心电图模型的能力边界。

Conclusion: UniECG在心电图解释和生成方面取得了突破，为心电图分析和应用开辟了新的可能性。

Abstract: Recent unified models such as GPT-5 have achieved encouraging progress on
vision-language tasks. However, these unified models typically fail to
correctly understand ECG signals and provide accurate medical diagnoses, nor
can they correctly generate ECG signals. To address these limitations, we
propose UniECG, the first unified model for ECG capable of concurrently
performing evidence-based ECG interpretation and text-conditioned ECG
generation tasks. Through a decoupled two-stage training approach, the model
first learns evidence-based interpretation skills (ECG-to-Text), and then
injects ECG generation capabilities (Text-to-ECG) via latent space alignment.
UniECG can autonomously choose to interpret or generate an ECG based on user
input, significantly extending the capability boundaries of current ECG models.
Our code and checkpoints will be made publicly available at
https://github.com/PKUDigitalHealth/UniECG upon acceptance.

</details>


### [150] [A Good Plan is Hard to Find: Aligning Models with Preferences is Misaligned with What Helps Users](https://arxiv.org/abs/2509.18632)
*Nishant Balepur,Matthew Shu,Yoo Yeon Sung,Seraphina Goldfarb-Tarrant,Shi Feng,Fumeng Yang,Rachel Rudinger,Jordan Lee Boyd-Graber*

Main category: cs.CL

TL;DR: 用户偏好与LLM计划的实际帮助性不符，需要真实的用户交互反馈来实现对齐。


<details>
  <summary>Details</summary>
Motivation: 目前的LLM对齐方法（如RLHF和Chatbot Arena）假设用户偏好能反映计划的有效性，但这种假设未经检验。

Method: 通过名为Planorama的界面，让126名用户回答300个多步骤问题，并使用LLM生成的计划。收集了4388个计划执行和5584个比较数据，以衡量计划的有效性（问答成功率）和用户偏好。同时，在模拟环境中复现了该设置，以评估代理和奖励模型是否能模拟或偏好用户真正需要的计划。

Result: 1. 用户偏好、模型偏好和代理成功率不能准确预测哪些计划对用户有帮助，表明常见的对齐反馈可能与实际帮助性产生偏差。 2. 这种偏差并非源于用户个体偏好，因为用户在使用他们偏好或不偏好的计划时，成功率没有显著差异。 3. 表面线索（如简洁性、问题相似性）与用户偏好高度相关，但这些线索不能预测计划的实际帮助性。

Conclusion: 为了实现有帮助的LLM，需要依赖真实用户交互的反馈，而不是仅仅依赖那些看起来有帮助的偏好。文章最后讨论了NLP研究者可以采取的解决此问题的方法。

Abstract: To assist users in complex tasks, LLMs generate plans: step-by-step
instructions towards a goal. While alignment methods aim to ensure LLM plans
are helpful, they train (RLHF) or evaluate (ChatbotArena) on what users prefer,
assuming this reflects what helps them. We test this with Planorama: an
interface where 126 users answer 300 multi-step questions with LLM plans. We
get 4388 plan executions and 5584 comparisons to measure plan helpfulness (QA
success) and user preferences on plans, and recreate the setup in agents and
reward models to see if they simulate or prefer what helps users. We expose: 1)
user/model preferences and agent success do not accurately predict which plans
help users, so common alignment feedback can misalign with helpfulness; 2) this
gap is not due to user-specific preferences, as users are similarly successful
when using plans they prefer/disprefer; 3) surface-level cues like brevity and
question similarity strongly link to preferences, but such biases fail to
predict helpfulness. In all, we argue aligning helpful LLMs needs feedback from
real user interactions, not just preferences of what looks helpful, so we
discuss the plan NLP researchers can execute to solve this problem.

</details>


### [151] [Consistency-Aware Parameter-Preserving Knowledge Editing Framework for Multi-Hop Question Answering](https://arxiv.org/abs/2509.18655)
*Lingwen Deng,Yifei Han,Long Zhang,Yue Du,Bin Li*

Main category: cs.CL

TL;DR: CAPE-KG是一个一致性感知框架，用于在多跳问答（MHQA）上进行参数保留知识编辑（PPKE），通过确保知识图谱（KG）的构建、更新和检索与MHQA任务的要求保持一致，来解决现有PPKE方法中的不一致性问题，提高了PPKE在MHQA上的性能。


<details>
  <summary>Details</summary>
Motivation: 现有基于知识图谱（KG）的参数保留知识编辑（PPKE）方法在多跳问答（MHQA）任务中存在不一致性问题，导致知识污染、更新不稳定以及检索行为与预期不符，从而削弱了PPKE在多跳推理中的可靠性。

Method: 提出CAPE-KG（Consistency-Aware Parameter-Preserving Editing with Knowledge Graphs）框架，该框架通过确保知识图谱（KG）的构建、更新和检索与MHQA任务的要求保持一致，来维护编辑后知识和未编辑知识的一致性推理。

Result: 在MQuAKE基准测试上的广泛实验表明，CAPE-KG在MHQA的PPKE性能方面有所提高，证明了解决PPKE一致性问题的有效性。

Conclusion: 解决PPKE在多跳问答中的一致性问题可以显著提高其性能。

Abstract: Parameter-Preserving Knowledge Editing (PPKE) enables updating models with
new or corrected information without retraining or parameter adjustment. Recent
PPKE approaches based on knowledge graphs (KG) to extend knowledge editing (KE)
capabilities to multi-hop question answering (MHQA). However, these methods
often lack consistency, leading to knowledge contamination, unstable updates,
and retrieval behaviors that fail to reflect the intended edits. Such
inconsistencies undermine the reliability of PPKE in multi- hop reasoning. We
present CAPE-KG, Consistency-Aware Parameter-Preserving Editing with Knowledge
Graphs, a novel consistency-aware framework for PPKE on MHQA. CAPE-KG ensures
KG construction, update, and retrieval are always aligned with the requirements
of the MHQA task, maintaining coherent reasoning over both unedited and edited
knowledge. Extensive experiments on the MQuAKE benchmark show accuracy
improvements in PPKE performance for MHQA, demonstrating the effectiveness of
addressing consistency in PPKE.

</details>


### [152] [Analyzing Uncertainty of LLM-as-a-Judge: Interval Evaluations with Conformal Prediction](https://arxiv.org/abs/2509.18658)
*Huanxin Sheng,Xinyi Liu,Hangfeng He,Jieyu Zhao,Jian Kang*

Main category: cs.CL

TL;DR: LLM-as-a-judge 评估的不可靠性限制了其应用。本研究提出首个基于共形预测的框架来分析 LLM 评估的不确定性，通过提供 LLM 评分的预测区间来解决此问题。此外，还提出了区间中点作为一种低偏差的替代方案，并探索了其在判断中的应用。


<details>
  <summary>Details</summary>
Motivation: LLM-as-a-judge 作为一种新兴的 NLG 评估范式，其评估结果的不确定性问题尚未得到充分研究，这限制了其在实际应用中的可靠性。

Method: 本研究提出了一个利用共形预测来分析 LLM 评估不确定性的框架。具体来说，它为 LLM 评分生成预测区间，并为离散评分任务设计了边界调整方法。此外，还提出了一个基于区间中点的评分作为一种低偏差的替代方案。

Result: 实验结果表明，共形预测能够提供具有覆盖率保证的有效预测区间。同时，研究还探讨了区间中点和提示词调整对于提升评估质量的有效性。

Conclusion: 本研究为 LLM-as-a-judge 评估引入了共形预测，解决了其不确定性问题，提供了具有理论保障的预测区间，并提出了改进评估质量的方法。

Abstract: LLM-as-a-judge has become a promising paradigm for using large language
models (LLMs) to evaluate natural language generation (NLG), but the
uncertainty of its evaluation remains underexplored. This lack of reliability
may limit its deployment in many applications. This work presents the first
framework to analyze the uncertainty by offering a prediction interval of
LLM-based scoring via conformal prediction. Conformal prediction constructs
continuous prediction intervals from a single evaluation run, and we design an
ordinal boundary adjustment for discrete rating tasks. We also suggest a
midpoint-based score within the interval as a low-bias alternative to raw model
score and weighted average. We perform extensive experiments and analysis,
which show that conformal prediction can provide valid prediction interval with
coverage guarantees. We also explore the usefulness of interval midpoint and
judge reprompting for better judgment.

</details>


### [153] [MemOrb: A Plug-and-Play Verbal-Reinforcement Memory Layer for E-Commerce Customer Service](https://arxiv.org/abs/2509.18713)
*Yizhe Huang,Yang Liu,Ruiyu Zhao,Xiaolong Zhong,Xingming Yue,Ling Jiang*

Main category: cs.CL

TL;DR: MemOrb是一个用于LLM客服代理的记忆层，通过提炼多轮交互的策略反思来提高任务成功率和一致性，无需微调。


<details>
  <summary>Details</summary>
Motivation: 现有的LLM客服代理在多轮交互中存在遗忘、重复错误和缺乏持续自我改进机制的问题，导致在动态环境中不可靠。

Method: 提出MemOrb，一个轻量级的、即插即用的口头强化记忆层，将多轮交互提炼成紧凑的策略反思，并存储在共享记忆库中以指导决策，无需微调。

Result: MemOrb显著提高了任务成功率和稳定性，在多轮任务成功率方面提升高达63个百分点，并在重复试验中表现出更一致的性能。

Conclusion: 结构化反思是提升客服场景中冷冻LLM代理长期可靠性的有效机制。

Abstract: Large Language Model-based agents(LLM-based agents) are increasingly deployed
in customer service, yet they often forget across sessions, repeat errors, and
lack mechanisms for continual self-improvement. This makes them unreliable in
dynamic settings where stability and consistency are critical. To better
evaluate these properties, we emphasize two indicators: task success rate as a
measure of overall effectiveness, and consistency metrics such as Pass$^k$ to
capture reliability across multiple trials. To address the limitations of
existing approaches, we propose MemOrb, a lightweight and plug-and-play verbal
reinforcement memory layer that distills multi-turn interactions into compact
strategy reflections. These reflections are stored in a shared memory bank and
retrieved to guide decision-making, without requiring any fine-tuning.
Experiments show that MemOrb significantly improves both success rate and
stability, achieving up to a 63 percentage-point gain in multi-turn success
rate and delivering more consistent performance across repeated trials. Our
results demonstrate that structured reflection is a powerful mechanism for
enhancing long-term reliability of frozen LLM agents in customer service
scenarios.

</details>


### [154] [LOTUSDIS: A Thai far-field meeting corpus for robust conversational ASR](https://arxiv.org/abs/2509.18722)
*Pattara Tipaksorn,Sumonmas Thatphithakkul,Vataya Chunwijitra,Kwanchiva Thangthai*

Main category: cs.CL

TL;DR: LOTUSDIS是一个包含114小时泰语远场对话数据的语料库，旨在改进远场对话语音识别。该数据集包含三个参与者的自发对话，记录了真实混响、噪声和设备影响，无需麦克风阵列。研究人员对多种Whisper模型进行了评估，发现在未进行微调的情况下，模型性能随距离增加而显著下降。通过在LOTUSDIS数据集上进行微调，显著提高了模型的鲁棒性，其中泰语Whisper基线模型的总体词错误率（WER）从64.3%降至38.3%，远场WER从81.6%降至49.5%，尤其是在最远距离的麦克风上。实验结果强调了包含距离多样化训练数据对于构建鲁棒的ASR系统的重要性。该语料库遵循CC-BY-SA 4.0协议发布，同时提供了训练和评估脚本以促进可复现的研究。


<details>
  <summary>Details</summary>
Motivation: 为了推进远场对话自动语音识别（ASR）技术，需要一个能够反映真实世界录音条件的泰语数据集。现有的数据集可能无法充分捕捉远场录音中常见的混响、噪声和设备差异等挑战。

Method: 创建了一个包含114小时泰语对话的LOTUSDIS数据集，其中包含三个参与者在不同距离（0.12米至10米）使用九个独立单通道设备录制的自然对话。同时，他们评估了不同Whisper模型的零样本和微调性能，并计算了总体词错误率（WER）和远场WER。

Result: 在LOTUSDIS数据集上，未微调的Whisper模型在远场录音中表现出显著的性能下降。然而，通过在LOTUSDIS数据集上进行微调，模型的鲁棒性得到了显著提升。具体来说，泰语Whisper基线模型的总体WER从64.3%降低到38.3%，远场WER从81.6%降低到49.5%，在距离最远的麦克风上改进尤为明显。

Conclusion: 距离多样化的训练数据对于提高远场对话ASR系统的鲁棒性至关重要。LOTUSDIS数据集和基线系统的发布将有助于推动该领域的可复现研究。

Abstract: We present LOTUSDIS, a publicly available Thai meeting corpus designed to
advance far-field conversational ASR. The dataset comprises 114 hours of
spontaneous, unscripted dialogue collected in 15-20 minute sessions with three
participants, where overlapping speech is frequent and natural. Speech was
recorded simultaneously by nine independent single-channel devices spanning six
microphone types at distances from 0.12 m to 10 m, preserving the authentic
effects of reverberation, noise, and device coloration without relying on
microphone arrays. We provide standard train, dev, test splits and release a
reproducible baseline system. We benchmarked several Whisper variants under
zero-shot and fine-tuned conditions. Off-the-shelf models showed strong
degradation with distance, confirming a mismatch between pre-training data and
Thai far-field speech. Fine-tuning on LOTUSDIS dramatically improved
robustness: a Thai Whisper baseline reduced overall WER from 64.3 to 38.3 and
far-field WER from 81.6 to 49.5, with especially large gains on the most
distant microphones. These results underscore the importance of
distance-diverse training data for robust ASR. The corpus is available under
CC-BY-SA 4.0. We also release training and evaluation scripts as a baseline
system to promote reproducible research in this field.

</details>


### [155] [Global-Recent Semantic Reasoning on Dynamic Text-Attributed Graphs with Large Language Models](https://arxiv.org/abs/2509.18742)
*Yunan Wang,Jianxin Li,Ziwei Zhang*

Main category: cs.CL

TL;DR: DyTAGs, which have time-evolving interactions and text attributes, are challenging for existing GNNs and LLMs due to their neglect of recent-global temporal semantics and LLMs' efficiency issues. The proposed DyGRASP method uses LLMs and temporal GNNs to address these challenges by capturing recent semantics with implicit reasoning and a sliding window, and global semantics with explicit reasoning and an RNN-like structure, then integrating them with dynamic graph information.


<details>
  <summary>Details</summary>
Motivation: Existing methods for Dynamic Text-Attribute Graphs (DyTAGs) struggle with capturing both recent and global temporal semantics, and applying LLMs to DyTAGs faces efficiency challenges.

Method: DyGRASP utilizes LLMs and temporal GNNs. It captures recent semantics via node-centric implicit reasoning and a sliding window. Global semantics are captured through explicit reasoning with tailored prompts and an RNN-like structure. Recent and global semantics, along with graph structure, are integrated using updating and merging layers.

Result: DyGRASP achieves superior performance on DyTAG benchmarks, with up to a 34% improvement in Hit@10 for destination node retrieval. It also shows strong generalization across different temporal GNNs and LLMs.

Conclusion: DyGRASP effectively and efficiently processes DyTAGs by integrating recent and global temporal semantics with dynamic graph structures, outperforming existing methods.

Abstract: Dynamic Text-Attribute Graphs (DyTAGs), characterized by time-evolving graph
interactions and associated text attributes, are prevalent in real-world
applications. Existing methods, such as Graph Neural Networks (GNNs) and Large
Language Models (LLMs), mostly focus on static TAGs. Extending these existing
methods to DyTAGs is challenging as they largely neglect the recent-global
temporal semantics: the recent semantic dependencies among interaction texts
and the global semantic evolution of nodes over time. Furthermore, applying
LLMs to the abundant and evolving text in DyTAGs faces efficiency issues. To
tackle these challenges, we propose Dynamic Global-Recent Adaptive Semantic
Processing (DyGRASP), a novel method that leverages LLMs and temporal GNNs to
efficiently and effectively reason on DyTAGs. Specifically, we first design a
node-centric implicit reasoning method together with a sliding window mechanism
to efficiently capture recent temporal semantics. In addition, to capture
global semantic dynamics of nodes, we leverage explicit reasoning with tailored
prompts and an RNN-like chain structure to infer long-term semantics. Lastly,
we intricately integrate the recent and global temporal semantics as well as
the dynamic graph structural information using updating and merging layers.
Extensive experiments on DyTAG benchmarks demonstrate DyGRASP's superiority,
achieving up to 34% improvement in Hit@10 for destination node retrieval task.
Besides, DyGRASP exhibits strong generalization across different temporal GNNs
and LLMs.

</details>


### [156] [False Friends Are Not Foes: Investigating Vocabulary Overlap in Multilingual Language Models](https://arxiv.org/abs/2509.18750)
*Julie Kallini,Dan Jurafsky,Christopher Potts,Martijn Bartelds*

Main category: cs.CL

TL;DR: Subword tokenizers with overlapping tokens improve cross-lingual transfer in multilingual models, outperforming disjoint vocabularies and showing performance gains as overlap increases.


<details>
  <summary>Details</summary>
Motivation: To investigate whether overlapping tokens in multilingual subword tokenizers facilitate cross-lingual transfer or cause interference, addressing mixed evidence from prior work due to varied experimental setups and confounders.

Method: Devised a controlled experiment training bilingual autoregressive models on multiple language pairs with systematically varied vocabulary overlap settings, including a new dimension of semantic similarity of shared tokens.

Result: Overlap, regardless of type, created embedding spaces capturing cross-lingual semantic relationships, a weaker effect in models with disjoint vocabularies. Models with overlap outperformed those with disjoint vocabularies on XNLI and XQuAD, with transfer performance generally improving as overlap increased.

Conclusion: Token overlap offers advantages in multilingual models, and a substantial shared vocabulary is a beneficial design choice for multilingual tokenizers.

Abstract: Subword tokenizers trained on multilingual corpora naturally produce
overlapping tokens across languages. Does token overlap facilitate
cross-lingual transfer or instead introduce interference between languages?
Prior work offers mixed evidence, partly due to varied setups and confounders,
such as token frequency or subword segmentation granularity. To address this
question, we devise a controlled experiment where we train bilingual
autoregressive models on multiple language pairs under systematically varied
vocabulary overlap settings. Crucially, we explore a new dimension to
understanding how overlap affects transfer: the semantic similarity of tokens
shared across languages. We first analyze our models' hidden representations
and find that overlap of any kind creates embedding spaces that capture
cross-lingual semantic relationships, while this effect is much weaker in
models with disjoint vocabularies. On XNLI and XQuAD, we find that models with
overlap outperform models with disjoint vocabularies, and that transfer
performance generally improves as overlap increases. Overall, our findings
highlight the advantages of token overlap in multilingual models and show that
substantial shared vocabulary remains a beneficial design choice for
multilingual tokenizers.

</details>


### [157] [When Long Helps Short: How Context Length in Supervised Fine-tuning Affects Behavior of Large Language Models](https://arxiv.org/abs/2509.18762)
*Yingming Zheng,Hanqi Li,Kai Yu,Lu Chen*

Main category: cs.CL

TL;DR: 长上下文监督微调（SFT）可以改善短上下文任务的性能，这与长上下文预训练的普遍观察到的性能下降相反。


<details>
  <summary>Details</summary>
Motivation: 研究长上下文SFT数据长度对LLM短上下文任务行为的影响。

Method: 通过分析多头注意（MHA）和前馈网络（FFN）这两个关键组成部分，并研究它们之间的相互作用，揭示知识偏好偏差。

Result: 长上下文SFT可以独立地改善MHA和FFN的性能。长上下文SFT倾向于上下文知识，而短上下文SFT倾向于参数知识。混合训练可以减轻这种偏差。

Conclusion: 混合训练可以作为一种可解释的指导，用于微调LLM。

Abstract: Large language models (LLMs) have achieved impressive performance across
natural language processing (NLP) tasks. As real-world applications
increasingly demand longer context windows, continued pretraining and
supervised fine-tuning (SFT) on long-context data has become a common approach.
While the effects of data length in continued pretraining have been extensively
studied, their implications for SFT remain unclear. In this work, we
systematically investigate how SFT data length influences LLM behavior on
short-context tasks. Counterintuitively, we find that long-context SFT improves
short-context performance, contrary to the commonly observed degradation from
long-context pretraining. To uncover the underlying mechanisms of this
phenomenon, we first decouple and analyze two key components, Multi-Head
Attention (MHA) and Feed-Forward Network (FFN), and show that both
independently benefit from long-context SFT. We further study their interaction
and reveal a knowledge preference bias: long-context SFT promotes contextual
knowledge, while short-context SFT favors parametric knowledge, making
exclusive reliance on long-context SFT suboptimal. Finally, we demonstrate that
hybrid training mitigates this bias, offering explainable guidance for
fine-tuning LLMs.

</details>


### [158] [Financial Risk Relation Identification through Dual-view Adaptation](https://arxiv.org/abs/2509.18775)
*Wei-Ning Chiu,Yu-Hsiang Wang,Andy Hsiao,Yu-Shiang Huang,Chuan-Ju Wang*

Main category: cs.CL

TL;DR: 本研究提出一种利用10-K文件和自然语言处理技术，通过无监督微调识别企业间风险关联的系统性方法，并引入量化风险关联得分，在实验中表现优于基线方法。


<details>
  <summary>Details</summary>
Motivation: 识别企业间风险关联对于投资组合管理和投资策略至关重要，但传统方法主观、劳动密集且难以扩展。

Method: 利用10-K文件作为数据源，通过无监督微调，基于文件的时间和词汇模式，捕捉隐含的抽象风险联系，开发领域特定的金融编码器。

Result: 提出的方法在多种评估设置中表现优于强基线方法。

Conclusion: 该方法能够系统地提取企业间风险关系，并提供量化风险关系得分，具有透明度和可解释性。

Abstract: A multitude of interconnected risk events -- ranging from regulatory changes
to geopolitical tensions -- can trigger ripple effects across firms.
Identifying inter-firm risk relations is thus crucial for applications like
portfolio management and investment strategy. Traditionally, such assessments
rely on expert judgment and manual analysis, which are, however, subjective,
labor-intensive, and difficult to scale. To address this, we propose a
systematic method for extracting inter-firm risk relations using Form 10-K
filings -- authoritative, standardized financial documents -- as our data
source. Leveraging recent advances in natural language processing, our approach
captures implicit and abstract risk connections through unsupervised
fine-tuning based on chronological and lexical patterns in the filings. This
enables the development of a domain-specific financial encoder with a deeper
contextual understanding and introduces a quantitative risk relation score for
transparency, interpretable analysis. Extensive experiments demonstrate that
our method outperforms strong baselines across multiple evaluation settings.

</details>


### [159] [AECBench: A Hierarchical Benchmark for Knowledge Evaluation of Large Language Models in the AEC Field](https://arxiv.org/abs/2509.18776)
*Chen Liang,Zhaoqi Huang,Haofen Wang,Fu Chai,Chunying Yu,Huanhuan Wei,Zhengjie Liu,Yanpeng Li,Hongjun Wang,Ruifeng Luo,Xianzhong Zhao*

Main category: cs.CL

TL;DR: 该论文提出了AECBench，一个用于评估大型语言模型(LLMs)在建筑、工程和施工(AEC)领域能力的基准测试。


<details>
  <summary>Details</summary>
Motivation: 评估LLMs在AEC领域的鲁棒性和可靠性，因为该领域专业性强且涉及安全关键问题。

Method: 设计了一个包含23个任务的五级认知评估框架（知识记忆、理解、推理、计算、应用），创建了包含4800个问题的多样化数据集，并采用LLM-as-a-Judge方法进行评估。

Result: 评估了九个LLMs，发现它们在知识记忆和理解层面表现尚可，但在从表格中解读建筑规范知识、执行复杂推理和计算以及生成领域特定文档方面存在显著性能缺陷。

Conclusion: 该研究为未来将LLMs可靠地集成到安全关键的工程实践中奠定了基础。

Abstract: Large language models (LLMs), as a novel information technology, are seeing
increasing adoption in the Architecture, Engineering, and Construction (AEC)
field. They have shown their potential to streamline processes throughout the
building lifecycle. However, the robustness and reliability of LLMs in such a
specialized and safety-critical domain remain to be evaluated. To address this
challenge, this paper establishes AECBench, a comprehensive benchmark designed
to quantify the strengths and limitations of current LLMs in the AEC domain.
The benchmark defines 23 representative tasks within a five-level
cognition-oriented evaluation framework encompassing Knowledge Memorization,
Understanding, Reasoning, Calculation, and Application. These tasks were
derived from authentic AEC practice, with scope ranging from codes retrieval to
specialized documents generation. Subsequently, a 4,800-question dataset
encompassing diverse formats, including open-ended questions, was crafted
primarily by engineers and validated through a two-round expert review.
Furthermore, an LLM-as-a-Judge approach was introduced to provide a scalable
and consistent methodology for evaluating complex, long-form responses
leveraging expert-derived rubrics. Through the evaluation of nine LLMs, a clear
performance decline across five cognitive levels was revealed. Despite
demonstrating proficiency in foundational tasks at the Knowledge Memorization
and Understanding levels, the models showed significant performance deficits,
particularly in interpreting knowledge from tables in building codes, executing
complex reasoning and calculation, and generating domain-specific documents.
Consequently, this study lays the groundwork for future research and
development aimed at the robust and reliable integration of LLMs into
safety-critical engineering practices.

</details>


### [160] [Beyond the Leaderboard: Understanding Performance Disparities in Large Language Models via Model Diffing](https://arxiv.org/abs/2509.18792)
*Sabri Boughorbel,Fahim Dalvi,Nadir Durrani,Majd Hawasly*

Main category: cs.CL

TL;DR: 本研究使用模型差异化方法分析了 Gemma-2-9b-it 和 SimPO 增强变体之间的能力差异，发现了 SimPO 主要增强了模型的安全性、多语言能力和指令遵循能力，同时降低了模型自我指涉和幻觉管理方面的倾向。


<details>
  <summary>Details</summary>
Motivation: 随着微调成为优化大型语言模型 (LLM) 的主流范式，理解微调过程中的具体变化变得至关重要。传统的基准测试往往无法解释模型之间性能差异的原因。

Method: 采用模型差异化（一种机制可解释性方法）来分析 Gemma-2-9b-it 和 SimPO 增强变体之间的具体能力差异。利用交叉编码器识别和分类区分这两个模型的潜在表征。

Result: SimPO 获得的潜在概念主要增强了安全机制（+32.8%）、多语言能力（+43.8%）和指令遵循能力（+151.7%）。同时，其额外的训练也降低了模型自我指涉（-44.1%）和幻觉管理（-68.5%）的侧重点。

Conclusion: 模型差异化方法能够提供超越排行榜指标的细粒度见解，将性能差距归因于具体的机制能力。该方法为比较大型语言模型提供了一个透明且有针对性的框架。

Abstract: As fine-tuning becomes the dominant paradigm for improving large language
models (LLMs), understanding what changes during this process is increasingly
important. Traditional benchmarking often fails to explain why one model
outperforms another. In this work, we use model diffing, a mechanistic
interpretability approach, to analyze the specific capability differences
between Gemma-2-9b-it and a SimPO-enhanced variant. Using crosscoders, we
identify and categorize latent representations that differentiate the two
models. We find that SimPO acquired latent concepts predominantly enhance
safety mechanisms (+32.8%), multilingual capabilities (+43.8%), and
instruction-following (+151.7%), while its additional training also reduces
emphasis on model self-reference (-44.1%) and hallucination management
(-68.5%). Our analysis shows that model diffing can yield fine-grained insights
beyond leaderboard metrics, attributing performance gaps to concrete
mechanistic capabilities. This approach offers a transparent and targeted
framework for comparing LLMs.

</details>


### [161] [MAPEX: A Multi-Agent Pipeline for Keyphrase Extraction](https://arxiv.org/abs/2509.18813)
*Liting Zhang,Shiwan Zhao,Aobo Kong,Qicheng Li*

Main category: cs.CL

TL;DR: MAPEX是一个新提出的多智能体协作框架，用于无监督关键词提取，通过动态适应文档长度和利用LLM能力来提高性能。


<details>
  <summary>Details</summary>
Motivation: 现有的无监督提示词方法在处理不同文档长度和LLM骨干时存在不足，未能充分发挥LLM的潜力。

Method: MAPEX引入了多智能体协作，包括专家招募、候选提取、主题引导、知识增强和后处理模块。采用双路径策略，根据文档长度选择知识驱动提取（短文本）或主题引导提取（长文本）。

Result: 在六个基准数据集和三种不同的LLM上进行了广泛的实验，MAPEX的泛化性和通用性表现出色，在F1@5指标上平均优于最先进的无监督方法2.44%，优于标准的LLM基线4.01%。

Conclusion: MAPEX通过引入多智能体协作和动态适应文档长度的双路径策略，有效解决了现有无监督关键词提取方法的局限性，并在实验中取得了显著的性能提升。

Abstract: Keyphrase extraction is a fundamental task in natural language processing.
However, existing unsupervised prompt-based methods for Large Language Models
(LLMs) often rely on single-stage inference pipelines with uniform prompting,
regardless of document length or LLM backbone. Such one-size-fits-all designs
hinder the full exploitation of LLMs' reasoning and generation capabilities,
especially given the complexity of keyphrase extraction across diverse
scenarios. To address these challenges, we propose MAPEX, the first framework
that introduces multi-agent collaboration into keyphrase extraction. MAPEX
coordinates LLM-based agents through modules for expert recruitment, candidate
extraction, topic guidance, knowledge augmentation, and post-processing. A
dual-path strategy dynamically adapts to document length: knowledge-driven
extraction for short texts and topic-guided extraction for long texts.
Extensive experiments on six benchmark datasets across three different LLMs
demonstrate its strong generalization and universality, outperforming the
state-of-the-art unsupervised method by 2.44\% and standard LLM baselines by
4.01\% in F1@5 on average. Code is available at
https://github.com/NKU-LITI/MAPEX.

</details>


### [162] [Are Smaller Open-Weight LLMs Closing the Gap to Proprietary Models for Biomedical Question Answering?](https://arxiv.org/abs/2509.18843)
*Damian Stachura,Joanna Konieczna,Artur Nowak*

Main category: cs.CL

TL;DR: 小型开源大语言模型在生物医学问答任务上表现出色，甚至优于闭源模型。


<details>
  <summary>Details</summary>
Motivation: 评估小型开源大语言模型在生物医学问答领域的替代能力，并与闭源模型进行比较。

Method: 在BioASQ挑战赛中使用检索增强、上下文学习和集成等技术，对比了多个开源模型和GPT-4o、Claude 3.5/3.7等闭源模型。

Result: 开源模型在生物医学问答任务上与闭源模型相当，集成策略下甚至表现更优。

Conclusion: 小型开源大语言模型足以胜任生物医学问答任务，并且在特定策略下能超越闭源模型。

Abstract: Open-weight versions of large language models (LLMs) are rapidly advancing,
with state-of-the-art models like DeepSeek-V3 now performing comparably to
proprietary LLMs. This progression raises the question of whether small
open-weight LLMs are capable of effectively replacing larger closed-source
models. We are particularly interested in the context of biomedical
question-answering, a domain we explored by participating in Task 13B Phase B
of the BioASQ challenge. In this work, we compare several open-weight models
against top-performing systems such as GPT-4o, GPT-4.1, Claude 3.5 Sonnet, and
Claude 3.7 Sonnet. To enhance question answering capabilities, we use various
techniques including retrieving the most relevant snippets based on embedding
distance, in-context learning, and structured outputs. For certain submissions,
we utilize ensemble approaches to leverage the diverse outputs generated by
different models for exact-answer questions. Our results demonstrate that
open-weight LLMs are comparable to proprietary ones. In some instances,
open-weight LLMs even surpassed their closed counterparts, particularly when
ensembling strategies were applied. All code is publicly available at
https://github.com/evidenceprime/BioASQ-13b.

</details>


### [163] [Multi-Hierarchical Feature Detection for Large Language Model Generated Text](https://arxiv.org/abs/2509.18862)
*Luyan Zhang,Xinyu Xie*

Main category: cs.CL

TL;DR: 多特征融合在AI文本检测中提升有限，并增加计算开销。


<details>
  <summary>Details</summary>
Motivation: 探究多特征融合方法能否显著提升AI文本检测能力，超越单一模型。

Method: 实现了一个名为MHFD（Multi-Hierarchical Feature Detection）的方法，融合了基于DeBERTa的语义分析、句法分析和统计概率特征，并使用了自适应融合技术。

Result: 实验表明，多特征融合仅带来0.4-0.5%的性能提升，但计算开销却增加了4.2倍。MHFD在领域内检测准确率为89.7%，跨领域检测稳定性能为84.2%，相较于现有方法仅提升0.4-2.6%。

Conclusion: 多特征融合对现代LLM生成文本的AI检测提升有限，且计算成本高昂，表明现有的神经语言模型可能已经高效地捕捉了大部分相关检测信号。

Abstract: With the rapid advancement of large language model technology, there is
growing interest in whether multi-feature approaches can significantly improve
AI text detection beyond what single neural models achieve. While intuition
suggests that combining semantic, syntactic, and statistical features should
provide complementary signals, this assumption has not been rigorously tested
with modern LLM-generated text. This paper provides a systematic empirical
investigation of multi-hierarchical feature integration for AI text detection,
specifically testing whether the computational overhead of combining multiple
feature types is justified by performance gains. We implement MHFD
(Multi-Hierarchical Feature Detection), integrating DeBERTa-based semantic
analysis, syntactic parsing, and statistical probability features through
adaptive fusion. Our investigation reveals important negative results: despite
theoretical expectations, multi-feature integration provides minimal benefits
(0.4-0.5% improvement) while incurring substantial computational costs (4.2x
overhead), suggesting that modern neural language models may already capture
most relevant detection signals efficiently. Experimental results on multiple
benchmark datasets demonstrate that the MHFD method achieves 89.7% accuracy in
in-domain detection and maintains 84.2% stable performance in cross-domain
detection, showing modest improvements of 0.4-2.6% over existing methods.

</details>


### [164] [Diversity Boosts AI-Generated Text Detection](https://arxiv.org/abs/2509.18880)
*Advik Raj Basani,Pin-Yu Chen*

Main category: cs.CL

TL;DR: DivEye是一个新颖的AI生成文本检测框架，通过分析文本中惊奇度（surprisal）特征的波动来识别AI生成内容，相比现有方法，它在准确性和可解释性方面表现更优，并且对释义和对抗性攻击具有鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 为了应对AI生成文本在教育、商业、新闻和社交媒体等领域被滥用的问题，需要开发比以往更可靠、更具可解释性的检测器，以对抗高质量的AI生成内容。

Method: 提出了一种名为DivEye的新型检测框架，该框架利用基于惊奇度（surprisal）的特征来捕捉文本中不可预测性的波动。具体来说，它通过一系列可解释的统计特征来捕捉人类写作中比LLM输出更丰富的词汇和结构上的不可预测性变化。

Result: DivEye在多个基准测试中，其零样本检测性能比现有方法提高了33.2%，并达到了与微调基线相当的性能。该方法对释义和对抗性攻击具有鲁棒性，能够跨领域和跨模型泛化，并且作为辅助信号时，能将现有检测器的性能提升高达18.7%。

Conclusion: DivEye框架通过利用文本中节奏性不可预测性这一强大且未被充分探索的信号，不仅在检测AI生成文本方面表现出色，还提供了可解释的洞察，指出了文本被标记的原因。

Abstract: Detecting AI-generated text is an increasing necessity to combat misuse of
LLMs in education, business compliance, journalism, and social media, where
synthetic fluency can mask misinformation or deception. While prior detectors
often rely on token-level likelihoods or opaque black-box classifiers, these
approaches struggle against high-quality generations and offer little
interpretability. In this work, we propose DivEye, a novel detection framework
that captures how unpredictability fluctuates across a text using
surprisal-based features. Motivated by the observation that human-authored text
exhibits richer variability in lexical and structural unpredictability than LLM
outputs, DivEye captures this signal through a set of interpretable statistical
features. Our method outperforms existing zero-shot detectors by up to 33.2%
and achieves competitive performance with fine-tuned baselines across multiple
benchmarks. DivEye is robust to paraphrasing and adversarial attacks,
generalizes well across domains and models, and improves the performance of
existing detectors by up to 18.7% when used as an auxiliary signal. Beyond
detection, DivEye provides interpretable insights into why a text is flagged,
pointing to rhythmic unpredictability as a powerful and underexplored signal
for LLM detection.

</details>


### [165] [Extractive Fact Decomposition for Interpretable Natural Language Inference in one Forward Pass](https://arxiv.org/abs/2509.18901)
*Nicholas Popovič,Michael Färber*

Main category: cs.CL

TL;DR: JEDI是一个仅编码器模型，可以进行原子事实分解和可解释推理，无需生成模型，并且在NLI任务中表现出鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有的NLI和事实核查方法依赖于资源密集型的生成式LLM来进行事实分解，JEDI旨在通过仅编码器模型解决此问题。

Method: JEDI模型进行原子事实分解和可解释推理，无需生成模型。使用包含多个NLI基准的合成语料库进行训练。

Result: JEDI在分布内准确率方面具有竞争力，在分布外和对抗性设置中显著提高了鲁棒性。

Conclusion: JEDI证明了仅编码器模型和合成语料库可以实现NLI的可解释性和鲁棒性泛化。

Abstract: Recent works in Natural Language Inference (NLI) and related tasks, such as
automated fact-checking, employ atomic fact decomposition to enhance
interpretability and robustness. For this, existing methods rely on
resource-intensive generative large language models (LLMs) to perform
decomposition. We propose JEDI, an encoder-only architecture that jointly
performs extractive atomic fact decomposition and interpretable inference
without requiring generative models during inference. To facilitate training,
we produce a large corpus of synthetic rationales covering multiple NLI
benchmarks. Experimental results demonstrate that JEDI achieves competitive
accuracy in distribution and significantly improves robustness out of
distribution and in adversarial settings over models based solely on extractive
rationale supervision. Our findings show that interpretability and robust
generalization in NLI can be realized using encoder-only architectures and
synthetic rationales. Code and data available at https://jedi.nicpopovic.com

</details>


### [166] [DTW-Align: Bridging the Modality Gap in End-to-End Speech Translation with Dynamic Time Warping Alignment](https://arxiv.org/abs/2509.18987)
*Abderrahmane Issam,Yusuf Can Semerci,Jan Scholtes,Gerasimos Spanakis*

Main category: cs.CL

TL;DR: 本研究提出一种新的端到端语音翻译（E2E-ST）方法，使用动态时间规整（DTW）来对齐语音和文本嵌入，以解决模态鸿沟问题。


<details>
  <summary>Details</summary>
Motivation: 由于语音和文本模态之间的表示差异，需要弥合模态鸿沟。现有的方法依赖于单词或令牌级别的对齐，但这需要一个并非所有语言都可用的对齐工具。使用最近邻相似性搜索的对齐方法不够准确。

Method: 将动态时间规整（DTW）应用于训练期间的语音和文本嵌入对齐。

Result: 与现有方法相比，本研究的方法能够更准确地对齐语音和文本嵌入，达到相当的E2E-ST性能，同时速度更快。在6个语言方向中的5个上，该方法在低资源环境下表现优于现有方法。

Conclusion: 所提出的DTW对齐方法有效弥合了E2E-ST中的模态鸿沟，在准确性和效率方面均优于现有方法，尤其是在低资源场景下。

Abstract: End-to-End Speech Translation (E2E-ST) is the task of translating source
speech directly into target text bypassing the intermediate transcription step.
The representation discrepancy between the speech and text modalities has
motivated research on what is known as bridging the modality gap.
State-of-the-art methods addressed this by aligning speech and text
representations on the word or token level. Unfortunately, this requires an
alignment tool that is not available for all languages. Although this issue has
been addressed by aligning speech and text embeddings using nearest-neighbor
similarity search, it does not lead to accurate alignments. In this work, we
adapt Dynamic Time Warping (DTW) for aligning speech and text embeddings during
training. Our experiments demonstrate the effectiveness of our method in
bridging the modality gap in E2E-ST. Compared to previous work, our method
produces more accurate alignments and achieves comparable E2E-ST results while
being significantly faster. Furthermore, our method outperforms previous work
in low resource settings on 5 out of 6 language directions.

</details>


### [167] [Investigating Test-Time Scaling with Reranking for Machine Translation](https://arxiv.org/abs/2509.19020)
*Shaomu Tan,Ryosuke Mitani,Ritvik Choudhary,Toshiyuki Sekiya*

Main category: cs.CL

TL;DR: 通过在推理时生成多个候选并选择最佳的测试时扩展（TTS）方法，可以提高机器翻译（MT）的性能，尤其是在高资源语言对上。然而，在低资源语言对上，TTS可能会因指标的局限性而降低翻译质量。


<details>
  <summary>Details</summary>
Motivation: 提高自然语言处理（NLP）系统的性能，同时降低计算成本，特别是在机器翻译（MT）领域，并系统地研究测试时扩展（TTS）在该领域的应用。

Method: 提出了一种简单实用的‘N中选优’（best-of-N）框架，并在WMT24基准测试中进行了实验。研究范围涵盖了六种高资源和一种低资源语言对，五种不同模型尺寸（3B-72B），以及不同的TTS计算预算（N高达1024）。

Result: 在高资源语言对上，TTS普遍提高了翻译质量，并通过人工评估得到证实。通过增加N值，可以使较小的模型达到甚至超过较大的模型（N=1）的性能，但计算成本更高。在固定计算预算下，较大的模型通常更有效率。在低资源语言对上，TTS可能因指标的局限性而降低翻译质量。

Conclusion: TTS是一种有前景的方法，可以提高机器翻译的质量，尤其是在高资源语言对上。然而，其在低资源语言对上的有效性需要进一步研究，并且需要在性能提升和计算成本之间进行权衡。

Abstract: Scaling model parameters has become the de facto strategy for improving NLP
systems, but it comes with substantial computational costs. Test-Time Scaling
(TTS) offers an alternative by allocating more computation at inference:
generating multiple candidates and selecting the best. While effective in tasks
such as mathematical reasoning, TTS has not been systematically explored for
machine translation (MT). In this paper, we present the first systematic study
of TTS for MT, investigating a simple but practical best-of-N framework on
WMT24 benchmarks. Our experiments cover six high-resource and one low-resource
language pairs, five model sizes (3B-72B), and various TTS compute budget (N up
to 1024). Our results show that a) For high-resource languages, TTS generally
improves translation quality according to multiple neural MT evaluation
metrics, and our human evaluation confirms these gains; b) Augmenting smaller
models with large $N$ can match or surpass larger models at $N{=}1$ with more
compute cost; c) Under fixed compute budgets, larger models are typically more
efficient, and TTS can degrade quality due to metric blind spots in
low-resource cases.

</details>


### [168] [Charting a Decade of Computational Linguistics in Italy: The CLiC-it Corpus](https://arxiv.org/abs/2509.19033)
*Chiara Alzetta,Serena Auriemma,Alessandro Bondielli,Luca Dini,Chiara Fazzone,Alessio Miaschi,Martina Miliani,Marta Sartor*

Main category: cs.CL

TL;DR: 该研究分析了意大利计算语言学（CL）和自然语言处理（NLP）领域在CLiC-it会议（2014-2024）上的研究趋势，重点关注技术发展、作者信息和研究主题，旨在为社区提供见解。


<details>
  <summary>Details</summary>
Motivation: 追踪意大利计算语言学（CL）和自然语言处理（NLP）领域的研究趋势，特别是Transformer 기반 대규모 언어 모델(LLM)出现后的变化，为意大利和国际研究界提供见解，支持未来在该领域的决策和发展。

Method: 分析了2014年至2024年CLiC-it会议（意大利CL和NLP领域的主要会议）的10年论文集，构建了CLiC-it语料库，并对其元数据（作者来源、性别、隶属关系等）和论文内容（研究主题）进行了全面分析。

Result: 分析了CLiC-it语料库的元数据和论文内容，揭示了意大利CL和NLP领域随时间变化的研究趋势和关键发展。

Conclusion: 该研究为意大利和国际研究界提供了关于CL和NLP领域新兴趋势和关键发展的宝贵见解，有助于支持该领域的明智决策和未来方向。

Abstract: Over the past decade, Computational Linguistics (CL) and Natural Language
Processing (NLP) have evolved rapidly, especially with the advent of
Transformer-based Large Language Models (LLMs). This shift has transformed
research goals and priorities, from Lexical and Semantic Resources to Language
Modelling and Multimodality. In this study, we track the research trends of the
Italian CL and NLP community through an analysis of the contributions to
CLiC-it, arguably the leading Italian conference in the field. We compile the
proceedings from the first 10 editions of the CLiC-it conference (from 2014 to
2024) into the CLiC-it Corpus, providing a comprehensive analysis of both its
metadata, including author provenance, gender, affiliations, and more, as well
as the content of the papers themselves, which address various topics. Our goal
is to provide the Italian and international research communities with valuable
insights into emerging trends and key developments over time, supporting
informed decisions and future directions in the field.

</details>


### [169] [Pathways of Thoughts: Multi-Directional Thinking for Long-form Personalized Question Answering](https://arxiv.org/abs/2509.19094)
*Alireza Salemi,Cheng Li,Mingyang Zhang,Qiaozhu Mei,Zhuowan Li,Spurthi Amba Hombaiah,Weize Kong,Tao Chen,Hamed Zamani,Michael Bendersky*

Main category: cs.CL

TL;DR: PoT是一种无需微调即可个性化问答系统的推理方法，通过探索多重推理路径并根据用户偏好聚合答案，显著提升了准确性和用户满意度。


<details>
  <summary>Details</summary>
Motivation: 个性化问答系统对于满足用户特定信息需求至关重要，但现有系统在处理长、嘈杂、隐式上下文信息以及生成满足用户期望的答案方面面临挑战。

Method: PoT将LLM的推理过程建模为迭代决策过程，动态选择推理、修正、个性化和澄清等认知操作，生成多样化的候选答案，并根据用户偏好进行聚合和加权。

Result: 在LaMP-QA基准测试中，PoT相比竞争基线取得了高达13.1%的相对改进。人类评估也显示，66%的情况下评估者更喜欢PoT的输出。

Conclusion: PoT能够有效解决个性化问答中的挑战，通过探索不同推理路径并结合用户偏好，生成更优的个性化答案。

Abstract: Personalization is essential for adapting question answering (QA) systems to
user-specific information needs, thereby improving both accuracy and user
satisfaction. However, personalized QA remains relatively underexplored due to
challenges such as inferring preferences from long, noisy, and implicit
contexts, and generating responses that are simultaneously correct,
contextually appropriate, and aligned with user expectations and background
knowledge. To address these challenges, we propose Pathways of Thoughts (PoT),
an inference-stage method that applies to any large language model (LLM)
without requiring task-specific fine-tuning. The approach models the reasoning
of an LLM as an iterative decision process, where the model dynamically selects
among cognitive operations such as reasoning, revision, personalization, and
clarification. This enables exploration of multiple reasoning trajectories,
producing diverse candidate responses that capture different perspectives. PoT
then aggregates and reweights these candidates according to inferred user
preferences, yielding a final personalized response that benefits from the
complementary strengths of diverse reasoning paths. Experiments on the LaMP-QA
benchmark for personalized QA show that PoT consistently outperforms
competitive baselines, achieving up to a 13.1% relative improvement. Human
evaluation corroborates these results, with annotators preferring outputs from
PoT in 66% of cases and reporting ties in only 15% of cases.

</details>


### [170] [Are most sentences unique? An empirical examination of Chomskyan claims](https://arxiv.org/abs/2509.19108)
*Hiram Ring*

Main category: cs.CL

TL;DR: 大多数语言都是独一无二的。


<details>
  <summary>Details</summary>
Motivation: 大多数语言都是独一无二的，这可以通过使用大型语料库进行实证调查来解决。

Method: 使用 NLTK Python 库解析不同类型的语料库，并计算每个语料库中的精确字符串匹配。

Result: 虽然完全独特的句子通常是语料库的大多数，但这在很大程度上受语体限制，并且重复的句子在任何单个语料库中都占有重要的一部分。

Conclusion: 大多数语言都是独一无二的，但这在很大程度上受语体限制，并且重复的句子在任何单个语料库中都占有重要的一部分。

Abstract: A repeated claim in linguistics is that the majority of linguistic utterances
are unique. For example, Pinker (1994: 10), summarizing an argument by Noam
Chomsky, states that "virtually every sentence that a person utters or
understands is a brand-new combination of words, appearing for the first time
in the history of the universe." With the increased availability of large
corpora, this is a claim that can be empirically investigated. The current
paper addresses the question by using the NLTK Python library to parse corpora
of different genres, providing counts of exact string matches in each. Results
show that while completely unique sentences are often the majority of corpora,
this is highly constrained by genre, and that duplicate sentences are not an
insignificant part of any individual corpus.

</details>


### [171] [Human-Annotated NER Dataset for the Kyrgyz Language](https://arxiv.org/abs/2509.19109)
*Timur Turatali,Anton Alekseev,Gulira Jumalieva,Gulnara Kabaeva,Sergey Nikolenko*

Main category: cs.CL

TL;DR: 本文介绍了 KyrgyzNER，这是首个为吉尔吉斯语手动标注的命名实体识别数据集。该数据集包含 1,499 篇新闻文章，共 10,900 句，39,075 个实体提及，涵盖 27 类命名实体。研究展示了标注方案，讨论了标注过程中的挑战，并呈现了描述性统计。


<details>
  <summary>Details</summary>
Motivation: 现有吉尔吉斯语命名实体识别资源匮乏，需要构建数据集来推动该领域的研究和应用。

Method: 构建了一个包含 1,499 篇新闻文章的命名实体识别数据集（KyrgyzNER），包含 10,900 句和 39,075 个实体提及，涵盖 27 个命名实体类别。评估了条件随机场和多语言 Transformer 模型（如 RoBERTa 变体）在数据集上的性能。

Result: 多语言 RoBERTa 模型在 precision 和 recall 之间取得了良好的平衡，尽管所有模型在处理稀有实体类别时都存在困难。其他多语言模型也取得了可比的结果。

Conclusion: 多语言预训练模型在处理吉尔吉斯语等资源有限的语言方面既充满挑战也充满机遇。未来的工作可以探索更细粒度的标注方案，以提供更深入的见解。

Abstract: We introduce KyrgyzNER, the first manually annotated named entity recognition
dataset for the Kyrgyz language. Comprising 1,499 news articles from the 24.KG
news portal, the dataset contains 10,900 sentences and 39,075 entity mentions
across 27 named entity classes. We show our annotation scheme, discuss the
challenges encountered in the annotation process, and present the descriptive
statistics. We also evaluate several named entity recognition models, including
traditional sequence labeling approaches based on conditional random fields and
state-of-the-art multilingual transformer-based models fine-tuned on our
dataset. While all models show difficulties with rare entity categories, models
such as the multilingual RoBERTa variant pretrained on a large corpus across
many languages achieve a promising balance between precision and recall. These
findings emphasize both the challenges and opportunities of using multilingual
pretrained models for processing languages with limited resources. Although the
multilingual RoBERTa model performed best, other multilingual models yielded
comparable results. This suggests that future work exploring more granular
annotation schemes may offer deeper insights for Kyrgyz language processing
pipelines evaluation.

</details>


### [172] [Context-Aware Hierarchical Taxonomy Generation for Scientific Papers via LLM-Guided Multi-Aspect Clustering](https://arxiv.org/abs/2509.19125)
*Kun Zhu,Lizi Liao,Yuxuan Gu,Lei Huang,Xiaocheng Feng,Bing Qin*

Main category: cs.CL

TL;DR: 提出一个结合LLM和动态聚类的上下文感知分层分类法生成框架，用于组织和综合科学文献，并在新的评估基准上取得了优于现有方法的性能。


<details>
  <summary>Details</summary>
Motivation: 科学文献的快速增长需要有效的组织和综合研究发现的方法，而现有的方法缺乏连贯性和粒度。

Method: 利用LLM识别论文的关键方面（如方法、数据集、评估），生成特定方面的论文摘要，然后对这些摘要进行编码和聚类，以形成连贯的层次结构。

Result: 提出的方法显著优于现有方法，在分类法的连贯性、粒度和可解释性方面取得了最先进的性能。

Conclusion: 该框架能够有效地生成连贯、细致且可解释的科学文献分类法，为该领域提供了新的解决方案和评估标准。

Abstract: The rapid growth of scientific literature demands efficient methods to
organize and synthesize research findings. Existing taxonomy construction
methods, leveraging unsupervised clustering or direct prompting of large
language models (LLMs), often lack coherence and granularity. We propose a
novel context-aware hierarchical taxonomy generation framework that integrates
LLM-guided multi-aspect encoding with dynamic clustering. Our method leverages
LLMs to identify key aspects of each paper (e.g., methodology, dataset,
evaluation) and generates aspect-specific paper summaries, which are then
encoded and clustered along each aspect to form a coherent hierarchy. In
addition, we introduce a new evaluation benchmark of 156 expert-crafted
taxonomies encompassing 11.6k papers, providing the first naturally annotated
dataset for this task. Experimental results demonstrate that our method
significantly outperforms prior approaches, achieving state-of-the-art
performance in taxonomy coherence, granularity, and interpretability.

</details>


### [173] [Anecdoctoring: Automated Red-Teaming Across Language and Place](https://arxiv.org/abs/2509.19143)
*Alejandro Cuevas,Saloni Dash,Bharat Kumar Nayak,Dan Vann,Madeleine I. G. Daepp*

Main category: cs.CL

TL;DR: 我们提出了一种名为 anecdoctoring 的新型红队测试方法，该方法可以跨语言和文化自动生成对抗性提示，以应对生成式人工智能的虚假信息风险。


<details>
  <summary>Details</summary>
Motivation: 生成式人工智能的全球普及需要稳健的红队测试评估，但现有的红队测试数据集主要集中在美国和英语，未能满足全球多样化的需求。

Method: 收集了三种语言（英语、西班牙语和印地语）和两个地区（美国和印度）的虚假信息声明，将它们聚类成更广泛的叙述，并使用知识图谱来表征这些叙述，然后将这些知识图谱增强给攻击性语言模型（LLM）。

Result: 与少样本提示相比，该方法在攻击成功率方面表现更优，并提供了可解释性优势。

Conclusion: 这项研究结果强调了应对全球范围内虚假信息风险的必要性，需要能够大规模应对并基于现实世界中的恶意使用情况的缓解措施。

Abstract: Disinformation is among the top risks of generative artificial intelligence
(AI) misuse. Global adoption of generative AI necessitates red-teaming
evaluations (i.e., systematic adversarial probing) that are robust across
diverse languages and cultures, but red-teaming datasets are commonly US- and
English-centric. To address this gap, we propose "anecdoctoring", a novel
red-teaming approach that automatically generates adversarial prompts across
languages and cultures. We collect misinformation claims from fact-checking
websites in three languages (English, Spanish, and Hindi) and two geographies
(US and India). We then cluster individual claims into broader narratives and
characterize the resulting clusters with knowledge graphs, with which we
augment an attacker LLM. Our method produces higher attack success rates and
offers interpretability benefits relative to few-shot prompting. Results
underscore the need for disinformation mitigations that scale globally and are
grounded in real-world adversarial misuse.

</details>


### [174] [Measuring AI "Slop" in Text](https://arxiv.org/abs/2509.19163)
*Chantal Shaib,Tuhin Chakrabarty,Diego Garcia-Olano,Byron C. Wallace*

Main category: cs.CL

TL;DR: AI生成内容的“slop”缺乏明确定义和衡量标准，本研究通过专家访谈构建了“slop”分类体系，并提出可解释的评估维度，发现“slop”判断存在主观性但与潜在维度相关，该框架可用于评估AI生成文本的检测和偏好任务。


<details>
  <summary>Details</summary>
Motivation: 目前缺乏对AI生成“slop”（低质量AI文本）的明确定义和衡量方法。

Method: 通过对NLP、写作和哲学专家的访谈，开发了一个“slop”的分类体系，并提出了一套可解释的维度来评估文本中的“slop”。通过跨度级别的标注，分析“slop”判断的主观性及其与潜在维度（如连贯性和相关性）的关系。

Result: 研究发现，“slop”的二元判断具有一定的主观性，但这种判断与连贯性和相关性等潜在维度相关。所提出的框架可用于AI生成文本的检测和二元偏好任务的评估。

Conclusion: 本研究提出的“slop”评估框架有助于量化AI生成文本的质量，并可能揭示影响质量判断的语言和风格因素。

Abstract: AI "slop" is an increasingly popular term used to describe low-quality
AI-generated text, but there is currently no agreed upon definition of this
term nor a means to measure its occurrence. In this work, we develop a taxonomy
of "slop" through interviews with experts in NLP, writing, and philosophy, and
propose a set of interpretable dimensions for its assessment in text. Through
span-level annotation, we find that binary "slop" judgments are (somewhat)
subjective, but such determinations nonetheless correlate with latent
dimensions such as coherence and relevance. Our framework can be used to
evaluate AI-generated text in both detection and binary preference tasks,
potentially offering new insights into the linguistic and stylistic factors
that contribute to quality judgments.

</details>


### [175] [Soft Tokens, Hard Truths](https://arxiv.org/abs/2509.19170)
*Natasha Butt,Ariel Kwiatkowski,Ismail Labiad,Julia Kempe,Yann Ollivier*

Main category: cs.CL

TL;DR: 本研究提出了一种可扩展的强化学习方法来学习连续思维链（CoT），解决了先前连续令牌训练困难的问题，并在数学推理基准上取得了有竞争力的结果，同时提高了 CoT 的多样性并更好地保留了基础模型的预测。


<details>
  <summary>Details</summary>
Motivation: 先前关于连续令牌的研究表明其具有更高的表达能力，但实际应用受限于训练困难。本研究旨在提出一种可扩展的、无需从离散 CoT 蒸馏的连续 CoT 学习方法。

Method: 本研究提出了一种利用强化学习（RL）来学习连续 CoT 的方法，通过使用“软”令牌（令牌的混合）和在输入嵌入上添加噪声来实现 RL 探索，从而解决了训练困难的问题，并且计算开销极小，可以学习包含数百个令牌的连续 CoT。

Result: 在数学推理基准上，使用 Llama 和 Qwen 模型（高达 8B）进行训练，结果显示：1. 连续 CoT 在 pass@1 指标上与离散令牌 CoT 相当。2. 连续 CoT 在 pass@32 指标上超越了离散令牌 CoT，表明其具有更高的 CoT 多样性。3. 最佳训练策略是使用连续 CoT 令牌进行训练，然后使用离散令牌进行推理。4. 连续 CoT 强化学习训练能更好地保留基础模型在非领域外任务上的预测。

Conclusion: 本研究首次提出了一种可扩展的、无需从参考离散 CoT 蒸馏的连续 CoT 学习方法，并通过强化学习实现了这一目标。该方法在保持计算效率的同时，提高了 CoT 的多样性，并能在实际部署中（使用离散令牌进行推理）取得有竞争力的结果，同时还能更好地保留基础模型的预测能力。

Abstract: The use of continuous instead of discrete tokens during the Chain-of-Thought
(CoT) phase of reasoning LLMs has garnered attention recently, based on the
intuition that a continuous mixture of discrete tokens could simulate a
superposition of several reasoning paths simultaneously. Theoretical results
have formally proven that continuous tokens have much greater expressivity and
can solve specific problems more efficiently. However, practical use of
continuous tokens has been limited by strong training difficulties: previous
works either just use continuous tokens at inference time on a pre-trained
discrete-token model, or must distill the continuous CoT from ground-truth
discrete CoTs and face computational costs that limit the CoT to very few
tokens.
  This is the first work introducing a scalable method to learn continuous CoTs
via reinforcement learning (RL), without distilling from reference discrete
CoTs. We use "soft" tokens: mixtures of tokens together with noise on the input
embedding to provide RL exploration. Computational overhead is minimal,
enabling us to learn continuous CoTs with hundreds of tokens. On math reasoning
benchmarks with Llama and Qwen models up to 8B, training with continuous CoTs
match discrete-token CoTs for pass@1 and surpass them for pass@32, showing
greater CoT diversity. In systematic comparisons, the best-performing scenario
is to train with continuous CoT tokens then use discrete tokens for inference,
meaning the "soft" models can be deployed in a standard way. Finally, we show
continuous CoT RL training better preserves the predictions of the base model
on out-of-domain tasks, thus providing a softer touch to the base model.

</details>


### [176] [Online Process Reward Leanring for Agentic Reinforcement Learning](https://arxiv.org/abs/2509.19199)
*Xiaoqian Liu,Ke Wang,Yuchuan Wu,Fei Huang,Yongbin Li,Junge Zhang,Jianbin Jiao*

Main category: cs.CL

TL;DR: LLM 在交互环境中进行长期推理和行动时，由于奖励稀疏且难以验证，时间信用分配面临挑战。本文提出了在线过程奖励学习（OPRL），一种集成了标准策略学习的信用分配策略，通过隐式过程奖励模型（PRM）将轨迹偏好转化为隐式步奖励，并与结果奖励相结合进行策略更新，从而实现自我强化学习。


<details>
  <summary>Details</summary>
Motivation: 在 LLM 作为自主智能体进行长期推理和行动时，稀疏且难以验证的奖励使得时间信用分配变得极其困难。现有的过程监督方法存在标注偏差、奖励破解、信号过于精细导致高方差以及状态重叠稀疏时失效等问题。

Method: OPRL 是一种信用分配策略，它将轨迹偏好转化为隐式步奖励。具体来说，它交替优化一个隐式过程奖励模型（PRM）和智能体的策略，通过基于轨迹的 DPO 目标将轨迹偏好转化为隐式步奖励。然后，这些步奖励与来自结果奖励的片段级优势相结合，用于策略更新，形成一个自我强化的循环。该方法无需额外的 rollout 或显式的步标签。

Result: OPRL 在 WebShop、VisualSokoban 和 SOTOPIA 的开放式社交互动等三个不同的智能体基准测试中表现优于前沿 LLM 和强大的 RL 基线，在样本效率和训练方差方面取得了最先进的结果。此外，OPRL 通过更少的动作实现了更有效的探索。

Conclusion: OPRL 是一种通用的信用分配策略，可以与标准策略学习算法无缝集成，解决了 LLM 在具有稀疏或不可验证奖励的交互环境中学习时面临的时间信用分配挑战。理论上，OPRL 保证了学习到的步奖励与轨迹偏好一致，并且充当了潜在的塑造奖励，提供了有界梯度以稳定训练。实验结果表明 OPRL 在样本效率、训练稳定性以及探索效率方面优于现有方法，在现实世界的智能体学习中具有潜力。

Abstract: Large language models (LLMs) are increasingly trained with reinforcement
learning (RL) as autonomous agents that reason and act over long horizons in
interactive environments.
  However, sparse and sometimes unverifiable rewards make temporal credit
assignment extremely challenging.
  Recent work attempts to integrate process supervision into agent learning but
suffers from biased annotation, reward hacking, high-variance from overly
fine-grained signals or failtures when state overlap is rare.
  We therefore introduce Online Process Reward Learning (OPRL), a general
credit-assignment strategy for agentic RL that integrates seamlessly with
standard on-policy algorithms without relying on additional rollouts or
explicit step labels.
  In OPRL, we optimize an implicit process reward model (PRM) alternately with
the agent's policy to transform trajectory preferences into implicit step
rewards through a trajectory-based DPO objective.
  These step rewards are then used to compute step-level advantages, which are
combined with episode-level advantages from outcome rewards for policy update,
creating a self-reinforcing loop.
  Theoretical findings guarantee that the learned step rewards are consistent
with trajectory preferences and act as potential-based shaping rewards,
providing bounded gradients to stabilize training.
  Empirically, we evaluate OPRL on three distinct agent benmarks, including
WebShop and VisualSokoban, as well as open-ended social interactions with
unverfiable rewards in SOTOPIA.
  Crucially, OPRL shows superior performance over frontier LLMs and strong RL
baselines across domains, achieving state-of-the-art results with higher
sample-efficiency and lower variance during training.
  Further analysis also demonstrates the efficient exploration by OPRL using
fewer actions, underscoring its potential for agentic learning in real-world
scenarios.

</details>


### [177] [Steering Multimodal Large Language Models Decoding for Context-Aware Safety](https://arxiv.org/abs/2509.19212)
*Zheyuan Liu,Zhangchen Xu,Guangyao Dou,Xiangchi Yuan,Zhaoxuan Tan,Radha Poovendran,Meng Jiang*

Main category: cs.CL

TL;DR: MLLMs在安全决策方面存在不足，SafeCoDe通过对比解码和全局感知来解决过/欠敏感问题，并在实验中证明了其有效性。


<details>
  <summary>Details</summary>
Motivation: 现有MLLMs在进行安全决策时，在区分良性和有害查询方面存在不足，导致了过度敏感或检测遗漏的问题。

Method: 提出了一种名为SafeCoDe的轻量级、模型无关的解码框架，该框架包括：1.对比解码机制，通过对比真实图像和高斯噪声图像来识别对视觉上下文敏感的token；2.全局感知token调制策略，结合场景级推理和token级调整，以适应预测的安全判决。

Result: SafeCoDe在多种MLLMs架构和安全基准测试中，能够提升模型对视觉上下文敏感的拒绝能力，同时不损害模型的整体效用。

Conclusion: SafeCoDe是一种有效的框架，可以提高MLLMs在安全决策方面的能力，解决了现有方法在过度敏感和检测遗漏方面的问题。

Abstract: Multimodal Large Language Models (MLLMs) are increasingly deployed in
real-world applications, yet their ability to make context-aware safety
decisions remains limited. Existing methods often fail to balance
oversensitivity (unjustified refusals of benign queries) and undersensitivity
(missed detection of visually grounded risks), leaving a persistent gap in
safety alignment. To address this issue, we introduce Safety-aware Contrastive
Decoding (SafeCoDe), a lightweight and model-agnostic decoding framework that
dynamically adjusts token generation based on multimodal context. SafeCoDe
operates in two stages: (1) a contrastive decoding mechanism that highlights
tokens sensitive to visual context by contrasting real and Gaussian-noised
images, and (2) a global-aware token modulation strategy that integrates
scene-level reasoning with token-level adjustment to adapt refusals according
to the predicted safety verdict. Extensive experiments across diverse MLLM
architectures and safety benchmarks, covering undersensitivity,
oversensitivity, and general safety evaluations, show that SafeCoDe
consistently improves context-sensitive refusal behaviors while preserving
model helpfulness.

</details>


### [178] [Systematic Comparative Analysis of Large Pretrained Language Models on Contextualized Medication Event Extraction](https://arxiv.org/abs/2509.19224)
*Tariq Abdul-Quddoos,Xishuang Dong,Lijun Qian*

Main category: cs.CL

TL;DR: 基于 BERT 的模型在临床笔记的 NLP 任务中表现出色，但预训练数据领域影响模型性能：临床数据预训练模型在事件检测上更优，而通用数据预训练模型在事件上下文分类上更优。


<details>
  <summary>Details</summary>
Motivation: 比较不同预训练的注意力模型在电子健康记录（EHR）信息提取任务上的表现，特别是区分在临床数据和通用数据上预训练的模型。

Method: 将 Bert Base、BioBert、两种 Clinical Bert 变体、RoBerta 和 Clinical Longformer 在 CMED 数据集上进行微调，以执行药物提取、医疗事件检测和多维度药物事件上下文分类任务，并详细说明了 EHR 的处理方法。

Result: 临床数据预训练模型在药物和医疗事件检测方面更有效；而在药物事件上下文分类方面，通用数据预训练的 Bert Base 模型效果最好。

Conclusion: 预训练数据的领域对于模型在 EHR 信息提取任务中的性能至关重要。

Abstract: Attention-based models have become the leading approach in modeling medical
language for Natural Language Processing (NLP) in clinical notes. These models
outperform traditional techniques by effectively capturing contextual rep-
resentations of language. In this research a comparative analysis is done
amongst pre- trained attention based models namely Bert Base, BioBert, two
variations of Bio+Clinical Bert, RoBerta, and Clinical Long- former on task
related to Electronic Health Record (EHR) information extraction. The tasks
from Track 1 of Harvard Medical School's 2022 National Clinical NLP Challenges
(n2c2) are considered for this comparison, with the Contextualized Medication
Event Dataset (CMED) given for these task. CMED is a dataset of unstructured
EHRs and annotated notes that contain task relevant information about the EHRs.
The goal of the challenge is to develop effective solutions for extracting
contextual information related to patient medication events from EHRs using
data driven methods. Each pre-trained model is fine-tuned and applied on CMED
to perform medication extraction, medical event detection, and
multi-dimensional medication event context classification. Pro- cessing methods
are also detailed for breaking down EHRs for compatibility with the applied
models. Performance analysis has been carried out using a script based on
constructing medical terms from the evaluation portion of CMED with metrics
including recall, precision, and F1-Score. The results demonstrate that models
pre-trained on clinical data are more effective in detecting medication and
medication events, but Bert Base, pre- trained on general domain data showed to
be the most effective for classifying the context of events related to
medications.

</details>


### [179] [CompLLM: Compression for Long Context Q&A](https://arxiv.org/abs/2509.19228)
*Gabriele Berton,Jayakrishnan Unnikrishnan,Son Tran,Mubarak Shah*

Main category: cs.CL

TL;DR: LLMs处理长文本时面临二次计算复杂度的问题。本文提出的CompLLM通过将长文本分段压缩，实现了线性复杂度、可扩展性和可重用性，显著提高了TTFT速度并减小了KV缓存大小，同时保持了与未压缩上下文相当甚至更好的性能。


<details>
  <summary>Details</summary>
Motivation: 现有软上下文压缩方法存在二次压缩复杂度、无法跨查询重用计算等问题，限制了其实际应用。

Method: CompLLM将长上下文划分为独立的片段进行压缩，实现了线性扩展、模型泛化能力和压缩片段的缓存重用。

Result: 在2倍压缩率下，CompLLM在长上下文场景下将TTFT速度提升高达4倍，KV缓存大小减少50%，并且在长序列上性能表现优于未压缩上下文。

Conclusion: CompLLM是一种高效、可扩展且可重用的软上下文压缩技术，能够有效解决LLMs处理长文本的计算挑战，并具有实际应用价值。

Abstract: Large Language Models (LLMs) face significant computational challenges when
processing long contexts due to the quadratic complexity of self-attention.
While soft context compression methods, which map input text to smaller latent
representations, have shown promise, their real-world adoption is limited.
Existing techniques typically compress the context as a single unit, which
leads to quadratic compression complexity and an inability to reuse
computations across queries with overlapping contexts. In this work, we
introduce CompLLM, a soft compression technique designed for practical
deployment. Instead of processing the context holistically, CompLLM divides it
into segments and compresses each one independently. This simple design choice
yields three critical properties: efficiency, as the compression step scales
linearly with the context length; scalability, enabling models trained on short
sequences (e.g., 1k tokens) to generalize to contexts of 100k tokens; and
reusability, allowing compressed segments to be cached and reused across
different queries. Our experiments show that with a 2x compression rate, at
high context lengths CompLLM speeds up Time To First Token (TTFT) by up to 4x
and reduces the KV cache size by 50%. Furthermore, CompLLM achieves performance
comparable to that obtained with the uncompressed context, and even surpasses
it on very long sequences, demonstrating its effectiveness and practical
utility.

</details>


### [180] [Reinforcement Learning on Pre-Training Data](https://arxiv.org/abs/2509.19249)
*Siheng Li,Kejiao Li,Zenan Xu,Guanhua Huang,Evander Yang,Kun Li,Haoyuan Wu,Jiajia Wu,Zihao Zheng,Chenchen Zhang,Kun Shi,Kyrierl Deng,Qi Yi,Ruibin Xiong,Tingqiang Xu,Yuhao Jiang,Jianfeng Yan,Yuyuan Zeng,Guanghui Xu,Jinbao Xue,Zhijiang Xu,Zheng Fang,Shuai Li,Qibin Liu,Xiaoxue Li,Zhuoyu Li,Yangyu Tao,Fei Gao,Cheng Jiang,Bo Chao Wang,Kai Liu,Jianchen Zhu,Wai Lam,Wayyt Wang,Bo Zhou,Di Wang*

Main category: cs.CL

TL;DR: RLPT是一种新的LLM训练范式，它通过在预训练数据上使用强化学习来优化LLM，从而克服了计算资源和高质量文本数据增长不匹配的问题。与依赖人类反馈的RLHF和RLVR不同，RLPT直接从预训练数据中提取奖励信号，并通过下一段预测任务来训练模型，从而提高了模型的泛化推理能力。实验证明RLPT在多个基准测试中有效，并具有良好的扩展性。


<details>
  <summary>Details</summary>
Motivation: 计算资源呈指数级增长，而高质量文本数据增长有限，这限制了传统LLM的扩展方法。因此，需要一种新的方法来优化LLM的训练。

Method: RLPT（Reinforcement Learning on Pre-Training data）是一种新的训练范式，它在预训练数据上应用强化学习。通过采用‘下一段预测’（next-segment prediction）的目标，模型可以根据前面的上下文准确地预测后续文本片段，并从中获得奖励信号。这种方法使强化学习能够扩展到预训练数据上，鼓励模型探索更丰富的轨迹和更广泛的上下文，从而培养更强的泛化推理能力。

Result: 在通用领域和数学推理基准测试上的大量实验证明了RLPT的有效性。例如，将RLPT应用于Qwen3-4B-Base模型后，在MMLU、MMLU-Pro、GPQA-Diamond、KOR-Bench、AIME24和AIME25上的提升分别为3.0、5.1、8.1、6.0、6.6和5.3。这些结果表明RLPT具有良好的扩展性，并有进一步提升的潜力。

Conclusion: RLPT是一种有效的LLM训练范式，它通过在预训练数据上利用强化学习来优化模型，解决了计算资源与数据增长不匹配的问题。该方法通过下一段预测任务直接从预训练数据中提取奖励信号，从而提高了模型的泛化推理能力，并为LLM的推理边界和RLVR性能的提升奠定了基础。其良好的扩展性预示着未来计算能力的提升将带来更大的性能增益。

Abstract: The growing disparity between the exponential scaling of computational
resources and the finite growth of high-quality text data now constrains
conventional scaling approaches for large language models (LLMs). To address
this challenge, we introduce Reinforcement Learning on Pre-Training data
(RLPT), a new training-time scaling paradigm for optimizing LLMs. In contrast
to prior approaches that scale training primarily through supervised learning,
RLPT enables the policy to autonomously explore meaningful trajectories to
learn from pre-training data and improve its capability through reinforcement
learning (RL). While existing RL strategies such as reinforcement learning from
human feedback (RLHF) and reinforcement learning with verifiable rewards (RLVR)
rely on human annotation for reward construction, RLPT eliminates this
dependency by deriving reward signals directly from pre-training data.
Specifically, it adopts a next-segment reasoning objective, rewarding the
policy for accurately predicting subsequent text segments conditioned on the
preceding context. This formulation allows RL to be scaled on pre-training
data, encouraging the exploration of richer trajectories across broader
contexts and thereby fostering more generalizable reasoning skills. Extensive
experiments on both general-domain and mathematical reasoning benchmarks across
multiple models validate the effectiveness of RLPT. For example, when applied
to Qwen3-4B-Base, RLPT yields absolute improvements of $3.0$, $5.1$, $8.1$,
$6.0$, $6.6$, and $5.3$ on MMLU, MMLU-Pro, GPQA-Diamond, KOR-Bench, AIME24, and
AIME25, respectively. The results further demonstrate favorable scaling
behavior, suggesting strong potential for continued gains with more compute. In
addition, RLPT provides a solid foundation, extending the reasoning boundaries
of LLMs and enhancing RLVR performance.

</details>


### [181] [Extracting Conceptual Spaces from LLMs Using Prototype Embeddings](https://arxiv.org/abs/2509.19269)
*Nitesh Kumar,Usashi Chatterjee,Steven Schockaert*

Main category: cs.CL

TL;DR: LLMs可以学习概念空间，但需要专门的方法来提取它们。本文提出了一种通过嵌入原型描述并微调LLM来提取概念空间的方法。


<details>
  <summary>Details</summary>
Motivation: 概念空间在认知科学中很有用，并且有潜力用于可解释的AI，但很难学习。虽然LLM可以捕获必要的感知特征，但缺乏提取概念空间的实用方法。

Method: 提出了一种通过嵌入原型（如“非常甜的食物”）的描述来编码特征（如“甜度”）的策略，并通过微调LLM来使原型嵌入与概念空间维度对齐。

Result: 所提出的方法在经验上被证明是非常有效的。

Conclusion: 所提出的方法可以有效地从LLM中提取概念空间，并有望在可解释的AI中发挥作用。

Abstract: Conceptual spaces represent entities and concepts using cognitively
meaningful dimensions, typically referring to perceptual features. Such
representations are widely used in cognitive science and have the potential to
serve as a cornerstone for explainable AI. Unfortunately, they have proven
notoriously difficult to learn, although recent LLMs appear to capture the
required perceptual features to a remarkable extent. Nonetheless, practical
methods for extracting the corresponding conceptual spaces are currently still
lacking. While various methods exist for extracting embeddings from LLMs,
extracting conceptual spaces also requires us to encode the underlying
features. In this paper, we propose a strategy in which features (e.g.
sweetness) are encoded by embedding the description of a corresponding
prototype (e.g. a very sweet food). To improve this strategy, we fine-tune the
LLM to align the prototype embeddings with the corresponding conceptual space
dimensions. Our empirical analysis finds this approach to be highly effective.

</details>


### [182] [SloPalSpeech: A 2,8000-Hour Slovak Speech Corpus from Parliamentary Data](https://arxiv.org/abs/2509.19270)
*Erik Božík,Marek Šuppa*

Main category: cs.CL

TL;DR: 为斯洛伐克语等低资源语言开发自动语音识别（ASR）的大规模数据集SloPalSpeech，并展示了使用该数据集微调Whisper模型的显著效果。


<details>
  <summary>Details</summary>
Motivation: 低资源语言（如斯洛伐克语）的自动语音识别（ASR）面临训练数据稀缺的挑战。

Method: 创建了一个包含2806小时国会演讲录音的斯洛伐克语ASR数据集SloPalSpeech，并开发了处理流程以生成适合模型训练的30秒音频-文本对。使用该数据集微调了OpenAI Whisper的多个模型（small, medium, large-v3, large-v3-turbo）。

Result: 在Common Voice和FLEURS等基准测试中，微调后的Whisper模型错误率（WER）显著降低，其中Whisper-small模型的WER降低高达70%，接近了更大的Whisper-large-v3模型的基线性能。

Conclusion: 公开SloPalSpeech数据集、分段转录文本（6000万词）和微调后的模型，以促进低资源语音识别领域的研究。

Abstract: Automatic Speech Recognition (ASR) for low-resource languages like Slovak is
hindered by the scarcity of training data. To address this, we introduce
SloPalSpeech, a new, large-scale Slovak ASR dataset containing 2,806 hours of
speech from parliamentary proceedings. We developed a robust processing
pipeline to align and segment long-form recordings into clean, 30-second
audio-transcript pairs suitable for model training. We use this dataset to
fine-tune several OpenAI Whisper models (small, medium, large-v3, and
large-v3-turbo), achieving significant Word Error Rate (WER) reductions on
standard Slovak benchmarks like Common Voice and FLEURS. For instance, the
fine-tuned Whisper-small model's WER dropped by up to 70\%, approaching the
baseline performance of the much larger Whisper-large-v3 model. To foster
future research in low-resource speech recognition, we publicly release the
complete SloPalSpeech dataset, the fully segmented transcripts (60 million
words), and all our fine-tuned models.

</details>


### [183] [WolBanking77: Wolof Banking Speech Intent Classification Dataset](https://arxiv.org/abs/2509.19271)
*Abdou Karim Kandji,Frédéric Precioso,Cheikh Ba,Samba Ndiaye,Augustin Ndione*

Main category: cs.CL

TL;DR: 发布了一个用于银行领域的沃尔语意图分类数据集（WolBanking77），其中包含文本和语音数据，并在各种基线上进行了实验，结果很有希望。


<details>
  <summary>Details</summary>
Motivation: 解决低资源语言和文盲率高导致意图分类模型在这些语言上表现不佳的问题，特别是像塞内加尔的沃尔语这样的语言。

Method: 发布了一个包含9,791个文本句子和4小时以上口语数据的沃尔语意图分类数据集（WolBanking77），并在该数据集上进行了包括文本和语音在内的各种基线模型实验。

Result: 在WolBanking77数据集上，NLP和ASR模型的基线F1分数和词错误率指标都很有希望，并且对模型进行了比较分析。

Conclusion: 发布WolBanking77数据集为沃尔语的意图分类研究提供了资源，并在该数据集上进行的初步实验结果令人鼓舞，为未来的研究和开发奠定了基础。

Abstract: Intent classification models have made a lot of progress in recent years.
However, previous studies primarily focus on high-resource languages datasets,
which results in a gap for low-resource languages and for regions with a high
rate of illiterate people where languages are more spoken than read or written.
This is the case in Senegal, for example, where Wolof is spoken by around 90\%
of the population, with an illiteracy rate of 42\% for the country. Wolof is
actually spoken by more than 10 million people in West African region. To
tackle such limitations, we release a Wolof Intent Classification Dataset
(WolBanking77), for academic research in intent classification. WolBanking77
currently contains 9,791 text sentences in the banking domain and more than 4
hours of spoken sentences. Experiments on various baselines are conducted in
this work, including text and voice state-of-the-art models. The results are
very promising on this current dataset. This paper also provides detailed
analyses of the contents of the data. We report baseline f1-score and word
error rate metrics respectively on NLP and ASR models trained on WolBanking77
dataset and also comparisons between models. We plan to share and conduct
dataset maintenance, updates and to release open-source code.

</details>


### [184] [DRISHTIKON: A Multimodal Multilingual Benchmark for Testing Language Models' Understanding on Indian Culture](https://arxiv.org/abs/2509.19274)
*Arijit Maji,Raghvendra Kumar,Akash Ghosh,Anushka,Nemil Shah,Abhilekh Borah,Vanshika Shah,Nishant Mishra,Sriparna Saha*

Main category: cs.CL

TL;DR: DRISHTIKON是一个针对印度文化的、多模态、多语言的基准测试，用于评估生成式AI的文化理解能力。它涵盖了15种语言，包括了印度所有邦和联邦属地，拥有超过64,000个文本-图像对，聚焦于节日、服饰、美食、艺术和历史遗产等丰富的文化主题。研究评估了多种视觉语言模型（VLMs），揭示了当前模型在理解文化相关的多模态输入方面的局限性，特别是在低资源语言和鲜为人知的传统方面。DRISHTIKON填补了包容性AI研究的空白，为推动文化意识和多模态能力的语言技术提供了测试平台。


<details>
  <summary>Details</summary>
Motivation: 现有的基准测试通常范围通用或全球化，缺乏对特定文化（尤其是印度文化）的深入、细粒度覆盖。DRISHTIKON旨在解决这一问题，通过创建一个专门针对印度文化的、多模态、多语言的基准测试，以评估和提升生成式AI系统对印度文化的理解能力，促进包容性AI研究。

Method: 创建了一个名为DRISHTIKON的基准测试，该测试是多模态和多语言的，专门针对印度文化。它包含了15种语言，覆盖了印度所有地区，并收集了超过64,000个文本-图像对。该基准测试涵盖了节日、服饰、美食、艺术和历史遗产等文化主题。研究人员使用该基准测试评估了多种视觉语言模型（VLMs），包括开源模型、专有模型、推理专用模型和专注于印度语言的模型，并在零样本（zero-shot）和思维链（chain-of-thought）设置下进行了测试。

Result: 评估结果表明，当前的视觉语言模型在理解和推理与印度文化相关的多模态输入方面存在显著局限性，尤其是在处理低资源语言和不太为人所知的文化传统时。

Conclusion: DRISHTIKON基准测试对于填补包容性AI研究中的关键空白至关重要。它提供了一个强大的测试平台，有助于推动开发更具文化意识、在多模态方面更具能力和更包容的语言技术。

Abstract: We introduce DRISHTIKON, a first-of-its-kind multimodal and multilingual
benchmark centered exclusively on Indian culture, designed to evaluate the
cultural understanding of generative AI systems. Unlike existing benchmarks
with a generic or global scope, DRISHTIKON offers deep, fine-grained coverage
across India's diverse regions, spanning 15 languages, covering all states and
union territories, and incorporating over 64,000 aligned text-image pairs. The
dataset captures rich cultural themes including festivals, attire, cuisines,
art forms, and historical heritage amongst many more. We evaluate a wide range
of vision-language models (VLMs), including open-source small and large models,
proprietary systems, reasoning-specialized VLMs, and Indic-focused models,
across zero-shot and chain-of-thought settings. Our results expose key
limitations in current models' ability to reason over culturally grounded,
multimodal inputs, particularly for low-resource languages and less-documented
traditions. DRISHTIKON fills a vital gap in inclusive AI research, offering a
robust testbed to advance culturally aware, multimodally competent language
technologies.

</details>


<div id='cond-mat.mes-hall'></div>

# cond-mat.mes-hall [[Back]](#toc)

### [185] [Interplay of Rashba and valley-Zeeman splittings in weak localization of spin-orbit coupled graphene](https://arxiv.org/abs/2509.18332)
*L. E. Golub*

Main category: cond-mat.mes-hall

TL;DR: 对于具有大Rashba和能谷-Zeeman自旋分裂的石墨烯异质结构，发展了弱局域化理论，并计算了低场下的反常磁阻。


<details>
  <summary>Details</summary>
Motivation: 研究具有大Rashba和能谷-Zeeman自旋分裂的石墨烯异质结构中的弱局域化理论及其对磁阻的影响。

Method: 发展弱局域化理论，计算反常磁阻，得到任意参数关系下的解析表达式。

Result: 发现能谷-Zeeman分裂在无Rashba分裂时对弱局域化无影响，但在存在Rashba耦合时会改变磁电导符号。 the valley-Zeeman splitting has no effect on weak localization in the absence of Rashba splitting but it results in the change of the magnetoconductivity sign in the Rashba-coupled graphene. 谷间散射也会导致量子修正符号反转。

Conclusion: 能谷-Zeeman分裂和谷间散射会影响石墨烯异质结构中的弱局域化和磁电导符号，可以通过理论计算得到任意参数下的解析表达式。

Abstract: Weak localization theory is developed for graphene heterostructures with
transition metal dichalcogenides and topological insulators where the Rashba
and valey-Zeeman spin-splittings of the energy spectrum are large enough. The
anomalous magnetoresistance in low fields caused by weak localization is
calculated. It is shown that the valley-Zeeman splitting has no effect on weak
localization in the absence of Rashba splitting but it results in the change of
the magnetoconductivity sign in the Rashba-coupled graphene. Inter-valley
scattering also affects the quantum correction to the conductivity resulting in
its sign reversal. Analytical expressions are obtained for the anomalous
magnetoconductivity at arbitrary relations between the Rashba and valley-Zeeman
splittings as well as the inter-valley scattering rates.

</details>


### [186] [Spin currents in crystals with spin-orbit coupling: multi-band effects in an effective Hamiltonian formalism](https://arxiv.org/abs/2509.18363)
*K. V. Samokhin,M. Sigrist,M. H. Fischer*

Main category: cond-mat.mes-hall

TL;DR: 通过迭代消除远程带的贡献，我们推导了仅限于一个或多个基本带的自旋流算符，并表明其修正表达式可以主导平衡自旋流。


<details>
  <summary>Details</summary>
Motivation: 忽略从远程带积分中得出的贡献可能导致定性错误的结果，因此需要分析带间混合效应。

Method: 从形式上精确的微观表达式出发，通过迭代消除远程带的贡献，推导出仅限于一个或多个基本带的自旋流算符。

Result: 标准自旋流算符的定义无法用微观理论证明，修正后的算符包含额外的、可以主导平衡自旋流的项，并且其幅度可以显著超过标准定义得到的自旋流。

Conclusion: 必须调整算符以适应所选的基本带，并且必须考虑带间混合效应以获得准确的自旋流计算。

Abstract: When focusing on a few essential bands in an effective description of a
material to calculate observable quantities, the respective operators have to
be adjusted accordingly. Ignoring contributions arising from integrating out
remote bands can lead to qualitatively wrong results. We present a detailed
analysis of the interband mixing effects on spin currents. Specifically, we
calculate the intrinsic spin current in a time-reversal invariant
noncentrosymmetric crystal in the presence of electron-lattice spin-orbit
coupling. Starting from formally exact microscopic expressions, we derive the
spin current operator restricted to one or more essential bands by iterative
elimination of the contributions from distant bands. We show that the standard
definition of the spin current operator in terms of the group velocity obtained
from an effective band Hamiltonian cannot be justified using a microscopic
theory. The modified expression for the spin current operator contains
additional terms, which dominate the equilibrium spin current in a uniform
crystal. We show that the magnitude of these additional terms can considerably
exceed the spin current obtained using the standard definition.

</details>


### [187] [Generation of pure, spin polarized, and unpolarized charge currents at the few cycle limit of circularly polarized light](https://arxiv.org/abs/2509.18432)
*Deepika Gill,Sangeeta Sharma,Sam Shallcross*

Main category: cond-mat.mes-hall

TL;DR: 短脉冲激光可用于在 WSe2 中生成纯净的自旋电流。


<details>
  <summary>Details</summary>
Motivation: 探索过渡金属二卤代物 (TMDC) 在少数周期极限下对圆偏振光脉冲的响应，特别是研究自旋密度和自旋流的产生。

Method: 使用 WSe2 作为模型系统，通过调节~5飞秒的紫外-可见光脉冲的幅度来研究纯自旋流、100% 自旋极化电流和电荷流。

Result: 发现少数周期脉冲不仅产生自旋密度激发，还产生自旋流激发。通过调谐脉冲幅度，可以控制纯净自旋流、100% 自旋极化电流和电荷流。

Conclusion: 少数周期激光脉冲可用于在 TMDC 中实现纯净自旋流的全光生成，这归因于对称性从 C3 变为 C2，从而在激发中产生了净流。

Abstract: In certain members of the transition metal dichalcogenide (TMDC) family,
laser pulses of oppositely circularly polarized light excite electrons of
opposite spin. Here we show that in the few cycle limit such pulses generate
not only a spin density excitation, but also a spin current excitation.
Employing the example of the TMDC WSe$_2$ we show that pure spin currents, the
flow of spin in the absence of net charge flow, 100% spin polarized currents,
and charge currents are all accessible and controllable by tuning the amplitude
of ~ 5 femtosecond gap tuned light pulses. Underpinning this physics is a
symmetry lowering of the valley charge excitation from C3 at long duration to
C2 in the few cycle limit, imbuing the excitation with net current. Our results
both highlight the emergence of a rich light-spin current coupling at ultrafast
times in the TMDC family, as well presenting a route to the all-optical
generation of pure spin currents.

</details>


### [188] [Strain-Tuned Optical Properties of a Two-Dimensional Hexagonal Lattice: Exploiting Saddle Degrees of Freedom and Saddle Filtering Effects](https://arxiv.org/abs/2509.18539)
*Phusit Nualpijit,Bumned Soodchomshom*

Main category: cond-mat.mes-hall

TL;DR: 六方晶格的形变可以通过应变电子学实现，本研究利用紧束缚模型研究了应变对电子谱、导电性、透光率和吸光率的影响，发现应变可以被用来操控这些性质，并提出了一种基于光学测量的应变传感方法。通过分析电子带间跃迁和范霍夫奇点，揭示了形变诱导的类似谷极化的鞍点极化现象，并展示了线偏振光诱导的高效鞍点滤波效应，为设计应变可调的光电器件提供了可能。


<details>
  <summary>Details</summary>
Motivation: 六方晶格因在应变电子学中的应用前景而受到关注，需要研究其形变对其电子和光学性质的影响。

Method: 采用紧束缚模型研究变形六方晶格的各向异性谱、纵向电导率、透光率和吸光率，并分析了电子带间跃迁和范霍夫奇点。

Result: 发现电子输运性质、透光率和吸光率随形变程度呈各向异性变化，其中一方向增强，另一方向被抑制；提出了通过测量透光率和吸光率来确定应变方向和大小的方法；观察到近M点鞍点电子跃迁引起的强吸光现象，并与范霍夫奇点相关；发现了形变诱导的鞍点极化现象，类似于K点和K'点的谷极化；展示了线偏振光诱导的高效鞍点滤波效应。

Conclusion: 研究结果表明，变形六方晶格的光学性质可以通过应变进行调控，为设计应变可编程的光电器件（如偏振选择性光电探测器、可调谐吸收器和超薄光学滤波器）开辟了新途径。

Abstract: The deformation of hexagonal lattices has attracted considerable attention
due to its promising applications in straintronics. This study employs the
tight-binding model to investigate the anisotropic spectrum, where electronic
transport can be manipulated by the degree of deformation. The longitudinal
conductivities, light transmittance, and absorbance are analyzed, revealing
enhancement along one direction and suppression along the other. The findings
indicate that the direction and magnitude of strain can be determined by
measuring transmittance and absorbance, showing significant deviations from the
unstrained condition. Furthermore, a strong absorbance is observed due to the
interband transition of electrons near the M-point saddles, linked to van Hove
singularities for specific values of nearest and next-nearest hoping energy.
The unexpected characteristics of saddle polarization-analogous to valley
polarization at K- and K'-become particularly prominent when strain affects the
selection of M-point saddle. Notably, the demonstration indicates that a highly
efficient M-point saddle filtering effect takes place, induced by linearly
polarized light. This model paves the way for exploring the optical properties
of anisotropic hexagonal lattices, such as black phosphorus and borophene
oxide. These results also open a pathway to strain-programmable optoelectronic
devices, such as polarization-selective photodetectors, tunable absorbers, and
ultrathin optical filters.

</details>


### [189] [Complex Frequency Fingerprint: Interacting Driven Non-Hermitian Skin Effect](https://arxiv.org/abs/2509.18828)
*Zhesen Yang,Zihan Wang,Juntao Huang,Zijian Zheng,Jiangping Hu*

Main category: cond-mat.mes-hall

TL;DR: The paper introduces the concept of a 


<details>
  <summary>Details</summary>
Motivation: quantum many-body systems

Method: complex frequency fingerprint derived from response functions to demonstrate interaction-induced non-Hermitian phenomena like point-gap topology and skin effect, and a complex-frequency density of states to distinguish skin and edge modes.

Result: Interactions alone can cause point-gap topology and the non-Hermitian skin effect, which is frequency-dependent, unlike dissipation-induced effects. A complex-frequency density of states can differentiate non-Hermitian skin modes from topological edge modes.

Conclusion: The complex frequency fingerprint provides a new perspective for understanding excitation properties and non-Hermitian phenomena in quantum many-body systems.

Abstract: The excitation properties of quantum many-body systems are encoded in their
response functions. These functions define an associated response Hamiltonian,
which is intrinsically non-Hermitian due to the dissipative nature of retarded
responses, even in closed systems. By analyzing its eigenvalues and
eigenstates, one obtains a unique characterization of the system, referred to
as the complex frequency fingerprint. Using this framework, we demonstrate that
interactions alone can give rise to both point-gap topology and the
non-Hermitian skin effect. Unlike the dissipation-induced skin effect, this
interaction-driven phenomenon exhibits pronounced frequency dependence. We
further introduce a complex-frequency density of states framework that
distinctly separates non-Hermitian skin modes from topological edge modes.

</details>


### [190] [Intrinsic-perturbation induced anomalous higher-order boundary states in non-Hermitian systems](https://arxiv.org/abs/2509.18952)
*Hui-Qiang Liang,Zuxuan Ou,Linhu Li,Guo-Fu Xu*

Main category: cond-mat.mes-hall

TL;DR: 非厄米系统中的高阶边界态行为难以捉摸，因此寻找这些态背后的机制至关重要且意义重大。本文揭示了一种诱导异常高阶边界态的新机制，该机制源于非正常边界哈密顿量对内在扰动的敏感性（内在扰动指体块对拓扑边界的影响）。在此机制基础上，研究揭示了一种新型相变，即混合边界态与无标度边界态之间的相变。研究还发现，无标度边界态表现出尺寸依赖的谱，影响高阶拓扑边界态的存在。与传统的混合边界态或高阶非厄米边界效应不同，上述两种异常高阶边界态均表现出尺寸依赖的特性。本研究为调控非厄米系统中的高阶边界态和拓扑特性开辟了新方向。


<details>
  <summary>Details</summary>
Motivation: 非厄米系统中高阶边界态的行为难以捉摸，因此找到这些态背后的机制具有重要意义。

Method: 通过分析非正常边界哈密顿量对内在扰动的敏感性来揭示新机制。

Result: 揭示了混合边界态与无标度边界态之间的一种新型相变，并发现无标度边界态具有尺寸依赖的谱，影响高阶拓扑边界态的存在。这些异常高阶边界态表现出尺寸依赖的特性。

Conclusion: 提出了一种新的诱导异常高阶边界态的机制，并发现了与传统边界态不同的尺寸依赖特性，为调控非厄米系统中的高阶边界态和拓扑特性提供了新思路。

Abstract: The behavior of higher-order boundary states in non-Hermitian systems is
elusive and thereby finding the mechanism behind these states is both essential
and significant. Here, we uncover a novel mechanism that induces anomalous
higher-order boundary states. The mechanism originates from the sensitivity of
the non-normal boundary Hamiltonian to intrinsic perturbations, where intrinsic
perturbations here refer to the influence of the bulk on the topological
boundaries. Based on the mechanism, we reveal a new kind of phase transition,
i.e., the transition between hybrid skin-topological states and scale-free
topological boundary states. We also find that scale-free topological boundary
states exhibit size-dependent spectra, influencing the existence of
higher-order topological boundary states. Unlike conventional hybrid
skin-topological states or higher-order non-Hermitian skin effect, the above
two kinds of anomalous higher-order boundary states exhibit size-dependent
characteristics. Our work opens a new horizon for the control of higher-order
boundary states and topological properties of non-Hermitian systems.

</details>


### [191] [Quantum oscillations between excitonic and quantum spin Hall insulators in moiré WSe2](https://arxiv.org/abs/2509.19287)
*Zhongdong Han,Yiyu Xia,Kenji Watanabe,Takashi Taniguchi,Kin Fai Mak,Jie Shan*

Main category: cond-mat.mes-hall

TL;DR: 扭曲双层WSe2 (tWSe2) 中的量子自旋霍尔绝缘体 (QSHI) 和激子绝缘体 (EI) 之间的可调拓扑相变。


<details>
  <summary>Details</summary>
Motivation: 实验上实现QSHI和EI之间的拓扑相变，因为目前缺乏可用于实现这种转变的可调材料。

Method: 利用tWSe2中相互作用增强的g因子和扁平莫尔带，在垂直磁场下实现tWSe2的两个相反谷中的电子型和空穴型朗道能级 (LL)。

Result: 在半填充状态下，观察到QSHI（对于全填充LL）和EI（对于半填充LL）之间的周期性振荡。QSHI具有多达四对螺旋边缘态。通过电场调谐莫尔带结构，分析了费米面嵌套对EI稳定性的影响。

Conclusion: 首次演示了QSHI到EI的拓扑相变，并全面理解了tWSe2的费米面特性。

Abstract: Quantum spin Hall insulators (QSHIs) and excitonic insulators (EIs) are
prototypical topological and correlated states of matter, respectively. The
topological phase transition between the two has attracted much theoretical
interest but experimental studies have been hindered by the availability of
tunable materials that can access such a transition. Here, by utilizing the
interaction-enhanced g-factor and the flat moir\'e bands in twisted bilayer
WSe2 (tWSe2), we realize tunable electron-like and hole-like Landau levels
(LLs) in the opposite valleys of tWSe2 under a perpendicular magnetic field. At
half-band-filling, which corresponds to electron-hole charge neutrality,
periodic oscillations between QSHIs (for fully filled LLs) and EIs (for
half-filled LLs) are observed due to the interplay between the cyclotron energy
and the intervalley correlation; QSHIs with up to four pairs of helical edge
states can be resolved. We further analyze the effect of Fermi surface nesting
on the stability of EIs via electric field-tuning of the moir\'e band
structure. Our results demonstrate a novel QSHI-to-EI topological phase
transition and provide a comprehensive understanding of the fermiology of
tWSe2.

</details>


<div id='physics.app-ph'></div>

# physics.app-ph [[Back]](#toc)

### [192] [Sodium-Decorated Ennea-Graphene: A Novel 2D Carbon Allotrope for High-Capacity Hydrogen Storage](https://arxiv.org/abs/2509.19060)
*Bill D. Aparicio Huacarpuma,José A. S. Laranjeira,Nicolas F. Martins,Julio R. Sambrano,Fábio L. Lopes de Mendonça,Alexandre C. Dias,Luiz A. Ribeiro Junior*

Main category: physics.app-ph

TL;DR: Ennea-Graphene是一种新型二维碳同素异形体，通过DFT计算得到，具有良好的机械和动力学稳定性。其钠修饰形式在储氢方面表现出色，可逆吸附高达每Na原子4个H2分子（8.8 wt% H2），超过了美国能源部2025年的目标。


<details>
  <summary>Details</summary>
Motivation: 开发安全、高效、可逆的储氢材料对于推进氢基能源技术和实现碳中和目标至关重要。

Method: 利用密度泛函理论（DFT）计算，并通过声子色散和从头分子动力学模拟验证了Ennea-Graphene的稳定性和储氢性能。

Result: 计算表明Ennea-Graphene具有良好的机械和动力学稳定性，表现出类金属的电子特性，并具有高面内刚度（杨氏模量为255 N/m）。钠吸附在非九元环中心处具有能量优势（结合能约为-1.56 eV），形成Na@Ennea-Graphene复合物。该复合物可逆吸附高达每Na原子4个H2分子（8.8 wt% H2），超过了美国能源部2025年的目标。吸附的H2保持分子状态，并在接近环境的条件下可释放。

Conclusion: 钠修饰的Ennea-Graphene是一种有前途的纳米材料，可用于下一代储氢技术。

Abstract: The development of safe, efficient, and reversible hydrogen storage materials
is critical for advancing hydrogen-based energy technologies and achieving
carbon-neutral goals. Ennea-Graphene, a new 2D carbon allotrope made of 4-, 5-,
6-, and mainly 9-membered carbon rings (nonagons), is introduced via Density
Functional Theory (DFT) calculations. Phonon dispersion and ab initio molecular
dynamics demonstrate that the monolayer is mechanically and dynamically stable
at 300 K, as no imaginary modes are detected. The pristine system further
exhibits metallic-like electronic behavior. The material exhibits high in-plane
stiffness (Young modulus of 255 N/m). Sodium adsorption at the centers of the
nonagonal rings is energetically favorable, with a binding energy of
approximately -1.56 eV, leading to the formation of the Na@Ennea-Graphene
complex. The calculated H2 adsorption energies range from -0.15 eV to -0.18 eV.
The Na-decorated structure demonstrates excellent hydrogen storage performance,
reversibly adsorbing up to four H2 molecules per Na atom (8.8 wt\% H2). This
capacity surpasses the U.S. Department of Energy's 2025 target for onboard
hydrogen storage materials. The adsorbed H2 remains molecular (H-H bond of
0.76~\AA) and can be released under near-ambient conditions, as verified by 300
K ab initio molecular dynamics simulations. These findings position
sodium-decorated Ennea-Graphene as a promising nanomaterial for next-generation
hydrogen storage technologies.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [193] [Fast Linear Solvers via AI-Tuned Markov Chain Monte Carlo-based Matrix Inversion](https://arxiv.org/abs/2509.18452)
*Anton Lebedev,Won Kyung Lee,Soumyadip Ghosh,Olha I. Yaman,Vassilis Kalantzis,Yingdong Lu,Tomasz Nowicki,Shashanka Ubaru,Lior Horesh,Vassil Alexandrov*

Main category: cs.LG

TL;DR: AI框架通过图神经网络和贝叶斯优化来选择马尔可夫链蒙特卡洛（MCMC）参数，以加速求解大型稀疏线性系统，并在搜索预算减少50%的情况下提高了预处理效果，减少了10%的收敛迭代次数。


<details>
  <summary>Details</summary>
Motivation: 现有的Krylov子空间求解器在处理病态矩阵时收敛速度慢，需要预处理。基于马尔可夫链蒙特卡洛（MCMC）的矩阵求逆可以生成预处理器，但其有效性依赖于参数，手动调整成本高。

Method: 提出一个AI驱动的框架，使用图神经网络作为代理模型来预测MCMC参数对预处理速度的影响，并结合贝叶斯获取函数来选择最有可能减少迭代次数的参数集。

Result: 在先前未见过的病态线性系统上，该框架在搜索预算减少50%的情况下，实现了比传统方法更好的预处理效果，收敛迭代次数减少了约10%。

Conclusion: 该研究为将MCMC预处理方法集成到大规模系统中提供了一条途径。

Abstract: Large, sparse linear systems are pervasive in modern science and engineering,
and Krylov subspace solvers are an established means of solving them. Yet
convergence can be slow for ill-conditioned matrices, so practical deployments
usually require preconditioners. Markov chain Monte Carlo (MCMC)-based matrix
inversion can generate such preconditioners and accelerate Krylov iterations,
but its effectiveness depends on parameters whose optima vary across matrices;
manual or grid search is costly. We present an AI-driven framework recommending
MCMC parameters for a given linear system. A graph neural surrogate predicts
preconditioning speed from $A$ and MCMC parameters. A Bayesian acquisition
function then chooses the parameter sets most likely to minimise iterations. On
a previously unseen ill-conditioned system, the framework achieves better
preconditioning with 50\% of the search budget of conventional methods,
yielding about a 10\% reduction in iterations to convergence. These results
suggest a route for incorporating MCMC-based preconditioners into large-scale
systems.

</details>


### [194] [Machine Learnability as a Measure of Order in Aperiodic Sequences](https://arxiv.org/abs/2509.18103)
*Jennifer Dodgson,Michael Joedhitya,Adith Ramdas,Surender Suresh Kumar,Adarsh Singh Chauhan,Akira Rafhael,Wang Mingshu,Nordine Lotfi*

Main category: cs.LG

TL;DR: 本研究利用图像机器学习模型分析Ulam螺旋图中素数分布的规律性，发现在较大的数域（约500m附近）的素数分布比小数域（约25m以下）更易于学习和识别。


<details>
  <summary>Details</summary>
Motivation: 素数分布具有确定性定义的内在特征，同时也表现出类似随机过程的统计行为。本研究旨在探索使用图像机器学习模型来量化素数分布在特定区域的规律性，并验证机器学习是否可作为数论研究的新型实验工具。

Method: 使用图像机器学习模型，对Ulam螺旋图中不同区域（约500m附近和小于25m）的素数分布图像块进行训练和测试，通过比较模型的准确率、精确率和召回率来评估不同区域素数分布的规律性。

Result: 在纯准确率方面，在约500m区域训练的模型优于在小于25m区域训练的模型，表明前者区域的素数分布更易于学习。精确率和召回率的分数表明，模型在不同区域采用不同的分类策略：在小数域侧重于识别素数模式，在较大数域侧重于排除合数。这与高数量级下素数分布噪声减小、平均性质（密度、等分分佈）占主导地位的数论猜想一致。

Conclusion: 机器学习模型能够有效衡量Ulam螺旋图中不同区域素数分布的规律性差异，大数域的素数分布规律性更强。机器学习有望成为数论研究的新型实验工具，并可能应用于强素数和弱素数的模式识别，服务于密码学研究。

Abstract: Research on the distribution of prime numbers has revealed a dual character:
deterministic in definition yet exhibiting statistical behavior reminiscent of
random processes. In this paper we show that it is possible to use an
image-focused machine learning model to measure the comparative regularity of
prime number fields at specific regions of an Ulam spiral. Specifically, we
demonstrate that in pure accuracy terms, models trained on blocks extracted
from regions of the spiral in the vicinity of 500m outperform models trained on
blocks extracted from the region representing integers lower than 25m. This
implies existence of more easily learnable order in the former region than in
the latter. Moreover, a detailed breakdown of precision and recall scores seem
to imply that the model is favouring a different approach to classification in
different regions of the spiral, focusing more on identifying prime patterns at
lower numbers and more on eliminating composites at higher numbers. This aligns
with number theory conjectures suggesting that at higher orders of magnitude we
should see diminishing noise in prime number distributions, with averages
(density, AP equidistribution) coming to dominate, while local randomness
regularises after scaling by log x. Taken together, these findings point toward
an interesting possibility: that machine learning can serve as a new
experimental instrument for number theory. Notably, the method shows potential
1 for investigating the patterns in strong and weak primes for cryptographic
purposes.

</details>


### [195] [Data Valuation and Selection in a Federated Model Marketplace](https://arxiv.org/abs/2509.18104)
*Wenqian Li,Youjia Yang,Ruoxi Jia,Yan Pang*

Main category: cs.LG

TL;DR: 该研究提出了一个基于Wasserstein距离的联邦学习（FL）框架，用于在数据市场中评估和选择数据源，以提高模型性能和数据隐私性。


<details>
  <summary>Details</summary>
Motivation: 在AI时代，数据市场和模型交易对于促进数据共享和可追溯性至关重要。联邦学习（FL）在保护隐私方面有优势，但如何有效评估和选择异构数据源仍是挑战。

Method: 提出一个基于Wasserstein距离的估计器，用于预测模型在不同数据组合下的性能，并揭示数据异构性与FL聚合算法的兼容性。通过分布式方法在不访问原始数据的情况下近似Wasserstein距离。利用神经缩放定律推断模型性能，实现无需完全训练的数据选择。

Result: 在包含标签倾斜、错误标签和无标签数据源的多种场景下，该框架能可靠地识别出高性能的数据组合。

Conclusion: 该研究提出的框架能够有效应对FL中的数据评估和选择挑战，为构建更可靠的基于FL的模型市场提供了解决方案。

Abstract: In the era of Artificial Intelligence (AI), marketplaces have become
essential platforms for facilitating the exchange of data products to foster
data sharing. Model transactions provide economic solutions in data
marketplaces that enhance data reusability and ensure the traceability of data
ownership. To establish trustworthy data marketplaces, Federated Learning (FL)
has emerged as a promising paradigm to enable collaborative learning across
siloed datasets while safeguarding data privacy. However, effective data
valuation and selection from heterogeneous sources in the FL setup remain key
challenges. This paper introduces a comprehensive framework centered on a
Wasserstein-based estimator tailored for FL. The estimator not only predicts
model performance across unseen data combinations but also reveals the
compatibility between data heterogeneity and FL aggregation algorithms. To
ensure privacy, we propose a distributed method to approximate Wasserstein
distance without requiring access to raw data. Furthermore, we demonstrate that
model performance can be reliably extrapolated under the neural scaling law,
enabling effective data selection without full-scale training. Extensive
experiments across diverse scenarios, such as label skew, mislabeled, and
unlabeled sources, show that our approach consistently identifies
high-performing data combinations, paving the way for more reliable FL-based
model marketplaces.

</details>


### [196] [MeshODENet: A Graph-Informed Neural Ordinary Differential Equation Neural Network for Simulating Mesh-Based Physical Systems](https://arxiv.org/abs/2509.18445)
*Kangzheng Liu,Leixin Ma*

Main category: cs.LG

TL;DR: GNNs结合神经ODE，提出MeshODENet框架，用于加速复杂物理系统的模拟，尤其在结构力学领域，能显著提升长期预测的准确性和稳定性。


<details>
  <summary>Details</summary>
Motivation: 传统的数值求解器在模拟复杂物理系统时计算成本高昂，不适用于多查询任务。尽管GNNs可用于处理网格数据，但其在长期预测方面存在误差累积和不稳定性问题。

Method: 提出MeshODENet框架，结合了GNN的空间推理能力和神经ODE的连续时间建模能力。

Result: 在处理一维和二维弹性体大变形等结构力学问题时，MeshODENet在长期预测的准确性和稳定性方面显著优于基线模型，并大幅缩短了计算时间。

Conclusion: MeshODENet提供了一种强大且通用的数据驱动方法，可加速复杂结构系统的分析和建模。

Abstract: The simulation of complex physical systems using a discretized mesh is a
cornerstone of applied mechanics, but traditional numerical solvers are often
computationally prohibitive for many-query tasks. While Graph Neural Networks
(GNNs) have emerged as powerful surrogate models for mesh-based data, their
standard autoregressive application for long-term prediction is often plagued
by error accumulation and instability. To address this, we introduce
MeshODENet, a general framework that synergizes the spatial reasoning of GNNs
with the continuous-time modeling of Neural Ordinary Differential Equations. We
demonstrate the framework's effectiveness and versatility on a series of
challenging structural mechanics problems, including one- and two-dimensional
elastic bodies undergoing large, non-linear deformations. The results
demonstrate that our approach significantly outperforms baseline models in
long-term predictive accuracy and stability, while achieving substantial
computational speed-ups over traditional solvers. This work presents a powerful
and generalizable approach for developing data-driven surrogates to accelerate
the analysis and modeling of complex structural systems.

</details>


### [197] [Decentor-V: Lightweight ML Training on Low-Power RISC-V Edge Devices](https://arxiv.org/abs/2509.18118)
*Marcelo Ribeiro,Diogo Costa,Gonçalo Moreira,Sandro Pinto,Tiago Gomes*

Main category: cs.LG

TL;DR: 本文将 L-SGD 优化算法扩展到 RISC-V MCU，并提出了一种 8 位量化版本，以提高内存使用率和训练速度，同时保持可忽略的准确性损失。


<details>
  <summary>Details</summary>
Motivation: 由于大多数物联网设备缺乏 GPU，传统的基于云的机器学习训练方法存在隐私和连接性问题。虽然联邦学习 (FL) 提出了一个去中心化的解决方案，但它需要高效的优化算法。L-SGD 已证明可以在 Arm MCU 上进行训练，但需要将其扩展到新兴的 RISC-V 架构。

Method: 将 L-SGD 算法扩展到 RISC-V MCU，并针对 RISC-V 平台上缺乏 FPU 的情况，开发了一种 8 位量化版本的 L-SGD。

Result: 在 Arm 和 RISC-V 平台上评估了 L-SGD。8 位量化 L-SGD 在 RISC-V 上实现了内存使用量减少 4 倍，训练速度提高 2.2 倍，且准确性损失可忽略。

Conclusion: L-SGD 的扩展和量化版本有效地解决了 RISC-V MCU 上设备端训练的挑战，在内存和速度方面取得了显著改进，为在资源受限的设备上进行 FL 铺平了道路。

Abstract: Modern IoT devices increasingly rely on machine learning solutions to process
data locally. However, the lack of graphics processing units (GPUs) or
dedicated accelerators on most platforms makes on-device training largely
infeasible, often requiring cloud-based services to perform this task. This
procedure often raises privacy-related concerns, and creates dependency on
reliable and always-on connectivity. Federated Learning (FL) is a new trend
that addresses these issues by enabling decentralized and collaborative
training directly on devices, but it requires highly efficient optimization
algorithms. L-SGD, a lightweight variant of stochastic gradient descent, has
enabled neural network training on Arm Cortex-M Microcontroller Units (MCUs).
This work extends L-SGD to RISC-V-based MCUs, an open and emerging architecture
that still lacks robust support for on-device training. L-SGD was evaluated on
both Arm and RISC-V platforms using 32-bit floating-point arithmetic,
highlighting the performance impact of the absence of Floating-Point Units
(FPUs) in RISC-V MCUs. To mitigate these limitations, we introduce an 8-bit
quantized version of L-SGD for RISC-V, which achieves nearly 4x reduction in
memory usage and a 2.2x speedup in training time, with negligible accuracy
degradation.

</details>


### [198] [BULL-ODE: Bullwhip Learning with Neural ODEs and Universal Differential Equations under Stochastic Demand](https://arxiv.org/abs/2509.18105)
*Nachiket N. Naik,Prathamesh Dinesh Joshi,Raj Abhijit Dandekar,Rajat Dandekar,Sreedath Panat*

Main category: cs.LG

TL;DR: 当需求服从轻尾或时间相关噪声时，强制执行结构；当极端事件占主导地位时，放宽结构。


<details>
  <summary>Details</summary>
Motivation: 在随机需求下学习连续时间库存动态，并量化结构何时有助于或阻碍牛鞭效应的预测。

Method: 比较了完全学习的神经网络ODE（NODE）和保留守恒和订单到结构但学习一小部分残差策略项的物理信息通用微分方程（UDE）。

Result: 在AR(1)和高斯需求下，UDE在库存RMSE方面优于NODE。然而，在重尾对数正态冲击下，NODE的灵活性更好，而UDE在预测时会滞后。

Conclusion: 在某些情况下，结构偏差有助于预测，但在其他情况下，它可能会受到损害。当噪声为轻尾或时间相关时，应强制执行结构；当极端事件占主导地位时，应放宽结构。

Abstract: We study learning of continuous-time inventory dynamics under stochastic
demand and quantify when structure helps or hurts forecasting of the bullwhip
effect. BULL-ODE compares a fully learned Neural ODE (NODE) that models the
entire right-hand side against a physics-informed Universal Differential
Equation (UDE) that preserves conservation and order-up-to structure while
learning a small residual policy term. Classical supply chain models explain
the bullwhip through control/forecasting choices and information sharing, while
recent physics-informed and neural differential equation methods blend domain
constraints with learned components. It is unclear whether structural bias
helps or hinders forecasting under different demand regimes. We address this by
using a single-echelon testbed with three demand regimes - AR(1)
(autocorrelated), i.i.d. Gaussian, and heavy-tailed lognormal. Training is done
on varying fractions of each trajectory, followed by evaluation of multi-step
forecasts for inventory I, order rate O, and demand D. Across the structured
regimes, UDE consistently generalizes better: with 90% of the training horizon,
inventory RMSE drops from 4.92 (NODE) to 0.26 (UDE) under AR(1) and from 5.96
to 0.95 under Gaussian demand. Under heavy-tailed lognormal shocks, the
flexibility of NODE is better. These trends persist as train18 ing data
shrinks, with NODE exhibiting phase drift in extrapolation while UDE remains
stable but underreacts to rare spikes. Our results provide concrete guidance:
enforce structure when noise is light-tailed or temporally correlated; relax
structure when extreme events dominate. Beyond inventory control, the results
offer guidance for hybrid modeling in scientific and engineering systems:
enforce known structure when conservation laws and modest noise dominate, and
relax structure to capture extremes in settings where rare events drive
dynamics.

</details>


### [199] [Model-Based Transfer Learning for Real-Time Damage Assessment of Bridge Networks](https://arxiv.org/abs/2509.18106)
*Elisa Tomassini,Enrique García-Macías,Filippo Ubertini*

Main category: cs.LG

TL;DR: 该研究提出了一种基于模型迁移学习的方法，利用神经网络代理模型，将一个桥梁的监测模型迁移到另一个相似的桥梁上，以应对大规模桥梁网络结构监测中的可扩展性挑战。


<details>
  <summary>Details</summary>
Motivation: 随着永久监测系统在大型桥梁网络中的广泛应用，数据可获得性增加，但同时也带来了可扩展性挑战，需要高效地跟踪和比较长期行为，因此，在相似结构之间进行知识转移变得至关重要。

Method: 提出一种基于模型迁移学习的方法，利用神经网络代理模型，将一个桥梁的监测模型适应到另一个具有相似特征的桥梁上，这些模型能够捕捉共享的损伤机制。

Result: 通过迁移学习和贝叶斯推断，实现了对结构损伤的位置、严重程度和范围的高度敏感性，并集成了用于基于监测数据的模态特征的连续损伤评估。

Conclusion: 该方法通过跨结构知识转移，增强了实时监测能力，支持了智能监测策略和网络层面的弹性提升。

Abstract: The growing use of permanent monitoring systems has increased data
availability, offering new opportunities for structural assessment but also
posing scalability challenges, especially across large bridge networks.
Managing multiple structures requires tracking and comparing long-term
behaviour efficiently. To address this, knowledge transfer between similar
structures becomes essential. This study proposes a model-based transfer
learning approach using neural network surrogate models, enabling a model
trained on one bridge to be adapted to another with similar characteristics.
These models capture shared damage mechanisms, supporting a scalable and
generalizable monitoring framework. The method was validated using real data
from two bridges. The transferred model was integrated into a Bayesian
inference framework for continuous damage assessment based on modal features
from monitoring data. Results showed high sensitivity to damage location,
severity, and extent. This approach enhances real-time monitoring and enables
cross-structure knowledge transfer, promoting smart monitoring strategies and
improved resilience at the network level.

</details>


### [200] [GnnXemplar: Exemplars to Explanations - Natural Language Rules for Global GNN Interpretability](https://arxiv.org/abs/2509.18376)
*Burouj Armgaan,Eshan Jain,Harsh Pandey,Mahesh Chandran,Sayan Ranu*

Main category: cs.LG

TL;DR: GnnXemplar是一种新的全局图神经网络解释器，它利用认知科学中的典型理论，通过识别嵌入空间中的代表性节点（典型节点）并根据它们的邻域推导出自然语言规则来解释整个类别的预测。该方法在真实世界的基准测试中表现优于现有方法，并在保真度、可扩展性和可解释性方面得到了用户研究的验证。


<details>
  <summary>Details</summary>
Motivation: 现有图神经网络（GNNs）的全局解释方法在处理大型真实世界数据集时存在局限性，因为它们依赖于在小图上发现的模式，而这些模式在大规模图上很少重复，并且难以处理高维属性和复杂的结构-属性交互。因此，需要一种能够有效解释整个类别的预测，并且适用于大规模真实世界场景的全局解释方法。

Method: GnnXemplar利用认知科学中的典型理论，首先通过最大化覆盖反向k近邻的方式选择嵌入空间中的代表性节点（典型节点）。然后，利用大型语言模型（LLMs）和一种自优化提示策略，根据这些典型节点的邻域信息生成可解释的自然语言规则，从而解释GNN对整个类别的预测。

Result: GnnXemplar在各种基准测试中，在解释的保真度、可扩展性和人类可解释性方面显著优于现有方法。一项包含60名参与者的用户研究验证了其可解释性。

Conclusion: GnnXemplar是一种有效的全局图神经网络解释方法，通过借鉴典型理论，并结合大型语言模型，能够生成可信、可扩展且易于人类理解的解释，解决了现有方法在处理大规模真实世界图数据时的不足。

Abstract: Graph Neural Networks (GNNs) are widely used for node classification, yet
their opaque decision-making limits trust and adoption. While local
explanations offer insights into individual predictions, global explanation
methods, those that characterize an entire class, remain underdeveloped.
Existing global explainers rely on motif discovery in small graphs, an approach
that breaks down in large, real-world settings where subgraph repetition is
rare, node attributes are high-dimensional, and predictions arise from complex
structure-attribute interactions. We propose GnnXemplar, a novel global
explainer inspired from Exemplar Theory from cognitive science. GnnXemplar
identifies representative nodes in the GNN embedding space, exemplars, and
explains predictions using natural language rules derived from their
neighborhoods. Exemplar selection is framed as a coverage maximization problem
over reverse k-nearest neighbors, for which we provide an efficient greedy
approximation. To derive interpretable rules, we employ a self-refining prompt
strategy using large language models (LLMs). Experiments across diverse
benchmarks show that GnnXemplar significantly outperforms existing methods in
fidelity, scalability, and human interpretability, as validated by a user study
with 60 participants.

</details>


### [201] [AdaMixT: Adaptive Weighted Mixture of Multi-Scale Expert Transformers for Time Series Forecasting](https://arxiv.org/abs/2509.18107)
*Huanyao Zhang,Jiaye Lin,Wentao Zhang,Haitao Yuan,Guoliang Li*

Main category: cs.LG

TL;DR: AdaMixT通过自适应加权融合多尺度专家Transformer来提升多元时间序列预测性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法在捕捉多尺度特征和融合方面存在局限，导致泛化能力受限。

Method: 提出AdaMixT架构，利用不同尺度的patches，结合通用预训练模型（GPM）和领域特定模型（DSM）进行多尺度特征提取，并通过门控网络动态分配权重以实现自适应融合。

Result: 在八个基准数据集（包括Weather, Traffic, Electricity, ILI和四个ETT数据集）上进行的大量实验证明了AdaMixT在真实世界场景中的有效性。

Conclusion: AdaMixT通过自适应多尺度融合有效解决了现有方法在多元时间序列预测中的挑战。

Abstract: Multivariate time series forecasting involves predicting future values based
on historical observations. However, existing approaches primarily rely on
predefined single-scale patches or lack effective mechanisms for multi-scale
feature fusion. These limitations hinder them from fully capturing the complex
patterns inherent in time series, leading to constrained performance and
insufficient generalizability. To address these challenges, we propose a novel
architecture named Adaptive Weighted Mixture of Multi-Scale Expert Transformers
(AdaMixT). Specifically, AdaMixT introduces various patches and leverages both
General Pre-trained Models (GPM) and Domain-specific Models (DSM) for
multi-scale feature extraction. To accommodate the heterogeneity of temporal
features, AdaMixT incorporates a gating network that dynamically allocates
weights among different experts, enabling more accurate predictions through
adaptive multi-scale fusion. Comprehensive experiments on eight widely used
benchmarks, including Weather, Traffic, Electricity, ILI, and four ETT
datasets, consistently demonstrate the effectiveness of AdaMixT in real-world
scenarios.

</details>


### [202] [A Coopetitive-Compatible Data Generation Framework for Cross-silo Federated Learning](https://arxiv.org/abs/2509.18120)
*Thanh Linh Nguyen,Quoc-Viet Pham*

Main category: cs.LG

TL;DR: CoCoGen是一个利用生成式AI和博弈论的联邦学习框架，用于解决跨组织联邦学习中的统计异质性和经济竞争问题。


<details>
  <summary>Details</summary>
Motivation: 现有的跨组织联邦学习（CFL）主要关注统计异质性，但忽视了组织间的经济竞争。组织可能因为担心效用损失（净收益降低）而不愿参与联合训练。此外，统计异质性和组织间竞争对组织行为和系统整体社会福利的影响也未得到充分研究。

Method: 提出CoCoGen框架，利用生成式AI（GenAI）和潜在博弈论来模拟、分析和优化在异质和竞争环境下的协同学习。CoCoGen通过基于学习性能和效用的公式来刻画竞争和统计异质性，并将每个训练轮次建模为一个加权潜在博弈。进而推导出最大化社会福利的GenAI数据生成策略。

Result: 在Fashion-MNIST数据集上的实验结果表明，不同的异质性和竞争水平会影响组织行为，并且CoCoGen的表现优于基线方法。

Conclusion: CoCoGen成功地解决了跨组织联邦学习中的经济竞争和统计异质性问题，并通过实验证明了其有效性。

Abstract: Cross-silo federated learning (CFL) enables organizations (e.g., hospitals or
banks) to collaboratively train artificial intelligence (AI) models while
preserving data privacy by keeping data local. While prior work has primarily
addressed statistical heterogeneity across organizations, a critical challenge
arises from economic competition, where organizations may act as market rivals,
making them hesitant to participate in joint training due to potential utility
loss (i.e., reduced net benefit). Furthermore, the combined effects of
statistical heterogeneity and inter-organizational competition on
organizational behavior and system-wide social welfare remain underexplored. In
this paper, we propose CoCoGen, a coopetitive-compatible data generation
framework, leveraging generative AI (GenAI) and potential game theory to model,
analyze, and optimize collaborative learning under heterogeneous and
competitive settings. Specifically, CoCoGen characterizes competition and
statistical heterogeneity through learning performance and utility-based
formulations and models each training round as a weighted potential game. We
then derive GenAI-based data generation strategies that maximize social
welfare. Experimental results on the Fashion-MNIST dataset reveal how varying
heterogeneity and competition levels affect organizational behavior and
demonstrate that CoCoGen consistently outperforms baseline methods.

</details>


### [203] [Solve it with EASE](https://arxiv.org/abs/2509.18108)
*Adam Viktorin,Tomas Kadavy,Jozef Kovac,Michal Pluhacek,Roman Senkerik*

Main category: cs.LG

TL;DR: EASE是一个开源的、完全模块化的框架，利用大型语言模型（LLMs）进行迭代算法解决方案的生成，集成了生成、测试、分析和评估，用户可以完全控制错误处理、分析和质量评估，并支持多个LLM协同工作，简化了提示设计和模型管理，为研究人员和从业者提供了一个透明且可扩展的平台。


<details>
  <summary>Details</summary>
Motivation: 该论文的动机是为迭代算法解决方案的生成提供一个开放源码、完全模块化的框架，利用大型语言模型（LLMs）的功能。

Method: 该方法提出了一种名为EASE（Effortless Algorithmic Solution Evolution）的框架，该框架集成了生成、测试、分析和评估，形成一个可重复的反馈循环，并支持多个LLM在生成器、分析器和评估器等互补角色中进行编排。

Result: EASE框架通过抽象化提示设计和模型管理的复杂性，为研究人员和从业者提供了一个透明且可扩展的平台，以便在不同领域共同设计算法和其他生成式解决方案。

Conclusion: EASE框架通过提供一个集成的、可控的、可扩展的平台，简化了利用LLM进行算法解决方案的迭代生成过程。

Abstract: This paper presents EASE (Effortless Algorithmic Solution Evolution), an
open-source and fully modular framework for iterative algorithmic solution
generation leveraging large language models (LLMs). EASE integrates generation,
testing, analysis, and evaluation into a reproducible feedback loop, giving
users full control over error handling, analysis, and quality assessment. Its
architecture supports the orchestration of multiple LLMs in complementary
roles-such as generator, analyst, and evaluator. By abstracting the complexity
of prompt design and model management, EASE provides a transparent and
extensible platform for researchers and practitioners to co-design algorithms
and other generative solutions across diverse domains.

</details>


### [204] [Machine Learning-Based Classification of Vessel Types in Straits Using AIS Tracks](https://arxiv.org/abs/2509.18109)
*Jonatan Katz Nielsen*

Main category: cs.LG

TL;DR: 该研究提出了一种基于AIS数据的船舶类型识别方法，利用机器学习模型对航行轨迹进行分类，实现了高效准确的船舶类型识别。


<details>
  <summary>Details</summary>
Motivation: 为了提高海上安全和打击非法、未报告和未规范（IUU）活动，需要准确识别自动识别系统（AIS）轨迹中的船舶类型。

Method: 该方法使用8天的AIS历史数据，经过数据预处理（填充、去噪、分段），提取了31个轨迹级别特征（运动学、时间、地理空间、船体形状），并采用随机森林模型进行分类，通过5折交叉验证和按MMSI分组的训练/测试分割来避免数据泄露。

Result: 随机森林模型结合SMOTE算法在测试集上达到了92.15%的准确率，最大化ROC-AUC达到0.9897。研究发现，桥位比和最大船速是区分船舶类型的关键特征，而货船和油船之间最容易混淆。

Conclusion: 轻量级特征提取和基于AIS轨迹的机器学习模型能够实时准确地对海峡中的船舶类型进行分类，并具有进一步改进的空间。

Abstract: Accurate recognition of vessel types from Automatic Identification System
(AIS) tracks is essential for safety oversight and combating illegal,
unreported, and unregulated (IUU) activity. This paper presents a strait-scale,
machine-learning pipeline that classifies moving vessels using only AIS data.
We analyze eight days of historical AIS from the Danish Maritime Authority
covering the Bornholm Strait in the Baltic Sea (January 22-30, 2025). After
forward/backward filling voyage records, removing kinematic and geospatial
outliers, and segmenting per-MMSI tracks while excluding stationary periods
($\ge 1$ h), we derive 31 trajectory-level features spanning kinematics (e.g.,
SOG statistics), temporal, geospatial (Haversine distances, spans), and
ship-shape attributes computed from AIS A/B/C/D reference points (length,
width, aspect ratio, bridge-position ratio). To avoid leakage, we perform
grouped train/test splits by MMSI and use stratified 5-fold cross-validation.
Across five classes (cargo, tanker, passenger, high-speed craft, fishing;
N=1{,}910 trajectories; test=382), tree-based models dominate: a Random Forest
with SMOTE attains 92.15% accuracy (macro-precision 94.11%, macro-recall
92.51%, macro-F1 93.27%) on the held-out test set, while a tuned RF reaches
one-vs-rest ROC-AUC up to 0.9897. Feature-importance analysis highlights the
bridge-position ratio and maximum SOG as the most discriminative signals;
principal errors occur between cargo and tanker, reflecting similar transit
behavior. We demonstrate operational value by backfilling missing ship types on
unseen data and discuss improvements such as DBSCAN based trip segmentation and
gradient-boosted ensembles to handle frequent-stop ferries and further lift
performance. The results show that lightweight features over AIS trajectories
enable real-time vessel type classification in straits.

</details>


### [205] [Localized PCA-Net Neural Operators for Scalable Solution Reconstruction of Elliptic PDEs](https://arxiv.org/abs/2509.18110)
*Mrigank Dhingra,Romit Maulik,Adil Rasheed,Omer San*

Main category: cs.LG

TL;DR: 提出一种基于块的PCA-Net框架，将高维求解场分解为小块，在每个块内应用PCA，并在降维后的PCA空间中训练神经网络算子，以解决数据驱动的偏微分方程（PDE）求解问题，并分析了两种块状方法的计算效率和重构精度之间的权衡。


<details>
  <summary>Details</summary>
Motivation: 高维求解场中的主成分分析（PCA）会带来显著的计算开销，而神经算子学习是求解偏微分方程（PDE）的有效方法。

Method: 提出一种块状PCA-Net框架，将求解场分解为小块，在每个块内应用PCA，并在降维的PCA空间中训练神经网络算子。研究了两种块状方法：局部到全局块PCA和局部到局部块PCA，并对计算成本和精度进行了分析。对计算效率最高的方法进行了两种改进：使用重叠块和卷积神经网络（CNN）进行平滑滤波和两步法。

Result: 块状PCA显著降低了计算复杂度，同时保持了高精度，与全局PCA相比，端到端管道处理时间减少了3.7至4倍。

Conclusion: 块状PCA-Net框架是一种用于PDE系统的高效算子学习技术，能够显著降低计算复杂性并保持高精度。

Abstract: Neural operator learning has emerged as a powerful approach for solving
partial differential equations (PDEs) in a data-driven manner. However,
applying principal component analysis (PCA) to high-dimensional solution fields
incurs significant computational overhead. To address this, we propose a
patch-based PCA-Net framework that decomposes the solution fields into smaller
patches, applies PCA within each patch, and trains a neural operator in the
reduced PCA space. We investigate two different patch-based approaches that
balance computational efficiency and reconstruction accuracy: (1)
local-to-global patch PCA, and (2) local-to-local patch PCA. The trade-off
between computational cost and accuracy is analyzed, highlighting the
advantages and limitations of each approach. Furthermore, within each approach,
we explore two refinements for the most computationally efficient method: (i)
introducing overlapping patches with a smoothing filter and (ii) employing a
two-step process with a convolutional neural network (CNN) for refinement. Our
results demonstrate that patch-based PCA significantly reduces computational
complexity while maintaining high accuracy, reducing end-to-end pipeline
processing time by a factor of 3.7 to 4 times compared to global PCA, thefore
making it a promising technique for efficient operator learning in PDE-based
systems.

</details>


### [206] [Prompt Optimization Meets Subspace Representation Learning for Few-shot Out-of-Distribution Detection](https://arxiv.org/abs/2509.18111)
*Faizul Rakib Sayem,Shahana Ibrahim*

Main category: cs.LG

TL;DR: 现有的基于提示学习的视觉语言模型（VLM）的 out-of-distribution（OOD）检测方法仅依赖 softmax 概率，忽略了 VLM 学到的特征嵌入的潜力。本研究提出了一种新的基于上下文优化（CoOp）的框架，将子空间表示学习与提示调优相结合，通过将 ID 特征投影到由提示向量构成的子空间中，并将 ID 不相关的特征投影到正交补空间中，来提高 ID-OOD 分离度。该框架设计了一个端到端的学习标准，以确保 OOD 检测性能和 ID 分类准确性。


<details>
  <summary>Details</summary>
Motivation: 现有的基于提示学习的 OOD 检测方法仅依赖 softmax 概率，忽略了 VLM 学到的特征嵌入的潜力。

Method: 将子空间表示学习与提示调优相结合，通过将 ID 特征投影到由提示向量构成的子空间中，并将 ID 不相关的特征投影到正交补空间中，来提高 ID-OOD 分离度。设计了一个端到端的学习标准，以确保 OOD 检测性能和 ID 分类准确性。

Result: 在真实世界数据集上进行了实验，证明了该方法的有效性。

Conclusion: 所提出的新颖的上下文优化（CoOp）框架，通过集成子空间表示学习和提示调优，能够有效地提升视觉语言模型在开放世界设置下的 OOD 检测能力。

Abstract: The reliability of artificial intelligence (AI) systems in open-world
settings depends heavily on their ability to flag out-of-distribution (OOD)
inputs unseen during training. Recent advances in large-scale vision-language
models (VLMs) have enabled promising few-shot OOD detection frameworks using
only a handful of in-distribution (ID) samples. However, existing prompt
learning-based OOD methods rely solely on softmax probabilities, overlooking
the rich discriminative potential of the feature embeddings learned by VLMs
trained on millions of samples. To address this limitation, we propose a novel
context optimization (CoOp)-based framework that integrates subspace
representation learning with prompt tuning. Our approach improves ID-OOD
separability by projecting the ID features into a subspace spanned by prompt
vectors, while projecting ID-irrelevant features into an orthogonal null space.
To train such OOD detection framework, we design an easy-to-handle end-to-end
learning criterion that ensures strong OOD detection performance as well as
high ID classification accuracy. Experiments on real-world datasets showcase
the effectiveness of our approach.

</details>


### [207] [Large language models surpass domain-specific architectures for antepartum electronic fetal monitoring analysis](https://arxiv.org/abs/2509.18112)
*Sheng Wong,Ravi Shankar,Beth Albert,Gabriel Davis Jones*

Main category: cs.LG

TL;DR: 本研究首次全面比较了用于产前胎心监护图（CTG）分析的各种人工智能（AI）方法，发现微调后的大语言模型（LLMs）表现优于其他模型，为产前护理中的AI临床应用奠定了基础。


<details>
  <summary>Details</summary>
Motivation: 电子胎儿监护（EFM）/心电图（CTG）分析对于评估胎儿健康至关重要，但目前主要依赖主观的临床解释，导致诊断准确性不一。时间序列基础模型（FMs）和大型语言模型（LLMs）在医疗领域表现出色，但其在CTG分析中的潜力尚未被充分探索。

Method: 本研究系统地比较了时间序列FMs和LLMs与现有的、专门用于CTG的AI架构。评估涵盖了超过500份不同长度的真实临床CTG记录。

Result: 研究结果表明，经过微调的LLMs在性能上优于基础模型和领域特定的方法。

Conclusion: 微调后的LLMs为临床CTG解释提供了一种有前途的替代方案，并为未来产前护理中的临床AI发展奠定了基础。

Abstract: Foundation models (FMs) and large language models (LLMs) demonstrate
remarkable capabilities across diverse domains through training on massive
datasets. These models have demonstrated exceptional performance in healthcare
applications, yet their potential for electronic fetal monitoring
(EFM)/cardiotocography (CTG) analysis, a critical technology for evaluating
fetal well-being, remains largely underexplored. Antepartum CTG interpretation
presents unique challenges due to the complex nature of fetal heart rate (FHR)
patterns and uterine activity, requiring sophisticated analysis of long
time-series data. The assessment of CTG is heavily based on subjective clinical
interpretation, often leading to variability in diagnostic accuracy and
deviation from timely pregnancy care. This study presents the first
comprehensive comparison of state-of-the-art AI approaches for automated
antepartum CTG analysis. We systematically compare time-series FMs and LLMs
against established CTG-specific architectures. Our evaluation encompasses over
500 CTG recordings of varying durations reflecting real-world clinical
recordings, providing robust performance benchmarks across different modelling
paradigms. Our results demonstrate that fine-tuned LLMs achieve superior
performance compared to both foundation models and domain-specific approaches,
offering a promising alternative pathway for clinical CTG interpretation. These
findings provide critical insights into the relative strengths of different AI
methodologies for fetal monitoring applications and establish a foundation for
future clinical AI development in prenatal care.

</details>


### [208] [FedFiTS: Fitness-Selected, Slotted Client Scheduling for Trustworthy Federated Learning in Healthcare AI](https://arxiv.org/abs/2509.19120)
*Ferdinand Kahenga,Antoine Bagula,Sajal K. Das,Patrick Sello*

Main category: cs.LG

TL;DR: FedFiTS是一个结合了适应性选择和分时聚合的联邦学习框架，提高了在医疗等敏感领域的隐私保护、效率和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 解决联邦学习在医疗等敏感领域面临的非IID数据、客户端不可靠和对抗性攻击等挑战。

Method: FedFiTS采用三阶段参与策略（自由竞争、自然选择、分时组队），结合动态客户端评分、自适应阈值和队列调度，以平衡收敛效率和鲁棒性。

Result: 理论分析表明，FedFiTS在凸和非凸目标下都具有收敛性界限，并且通信复杂度低于FedAvg等基线。实验证明，FedFiTS在准确性、达到目标时间以及抵御投毒攻击方面优于FedAvg、FedRand和FedPow。

Conclusion: FedFiTS通过整合信任感知聚合和面向公平性的客户端选择，提升了可扩展和安全的联邦学习能力，适用于现实世界的医疗和跨领域部署。

Abstract: Federated Learning (FL) has emerged as a powerful paradigm for
privacy-preserving model training, yet deployments in sensitive domains such as
healthcare face persistent challenges from non-IID data, client unreliability,
and adversarial manipulation. This paper introduces FedFiTS, a trust and
fairness-aware selective FL framework that advances the FedFaSt line by
combining fitness-based client election with slotted aggregation. FedFiTS
implements a three-phase participation strategy-free-for-all training, natural
selection, and slotted team participation-augmented with dynamic client
scoring, adaptive thresholding, and cohort-based scheduling to balance
convergence efficiency with robustness. A theoretical convergence analysis
establishes bounds for both convex and non-convex objectives under standard
assumptions, while a communication-complexity analysis shows reductions
relative to FedAvg and other baselines. Experiments on diverse datasets-medical
imaging (X-ray pneumonia), vision benchmarks (MNIST, FMNIST), and tabular
agricultural data (Crop Recommendation)-demonstrate that FedFiTS consistently
outperforms FedAvg, FedRand, and FedPow in accuracy, time-to-target, and
resilience to poisoning attacks. By integrating trust-aware aggregation with
fairness-oriented client selection, FedFiTS advances scalable and secure FL,
making it well suited for real-world healthcare and cross-domain deployments.

</details>


### [209] [A Study of Skews, Imbalances, and Pathological Conditions in LLM Inference Deployment on GPU Clusters detectable from DPU](https://arxiv.org/abs/2509.18114)
*Javed I. Khan an Henry Uwabor Moye*

Main category: cs.LG

TL;DR: LLM推理中的负载不平衡问题可以通过DPU进行实时检测和缓解，以提高GPU利用率和降低延迟。


<details>
  <summary>Details</summary>
Motivation: LLM推理中的负载不平衡问题导致GPU利用率低下和延迟增加，影响了运行时效率。

Method: 利用DPU（BlueField-3）实时检测和缓解多节点张量并行推理中的负载不平衡。DPU负责监控GPU遥测数据和节点间通信模式，并将分析结果反馈给推理控制器和调度器。

Result: 提出了一种DPU辅助框架，用于实时检测和缓解LLM推理中的负载不平衡问题。

Conclusion: 研究旨在识别多GPU执行LLM张量计算（训练和推理）中出现的失衡/病理状况，评估其对计算性能的影响，并探讨DPU网络是否能有效跟踪和缓解这些问题。

Abstract: Autoregressive inference in large transformer-based language models (LLMs)
presents significant challenges for runtime efficiency, particularly during the
decode phase where load imbalance across GPU shards can cause throughput
degradation and latency spikes. A DPU-assisted framework leveraged by
BlueField-3 Data Processing Units can enable real-time detection and mitigation
of load imbalance in multi-node tensor-parallel inference. By offloading
monitoring tasks to the DPU and analyzing GPU telemetry and inter-node
communication patterns, the resulting system can provide actionable feedback to
inference controllers and schedulers. The goal of this study is three-fold i)
identify the reported skews/imbalances/pathological conditions that arise in
muti-GPU execution of a) LLM tensor computing (both during training and
inference), b) identify their impact on computational performance, and c) make
a critical assessment if those can be tracked for potential mitigation from a
DPU network.

</details>


### [210] [FedFusion: Federated Learning with Diversity- and Cluster-Aware Encoders for Robust Adaptation under Label Scarcity](https://arxiv.org/abs/2509.19220)
*Ferdinand Kahenga,Antoine Bagula,Patrick Sello,Sajal K. Das*

Main category: cs.LG

TL;DR: FedFusion是一个联邦迁移学习框架，通过统一域自适应和节俭标签，并结合多样性/聚类感知编码器（DivEn, DivEn-mix, DivEn-c），解决了联邦学习中特征空间异构、数据非IID和标签稀疏的问题。该框架利用带标签的教师客户端通过置信度过滤的伪标签和域自适应迁移来指导学习客户端，同时为客户端维护个性化编码器。通过相似性加权分类器耦合（可选聚类平均），FedFusion在异构环境下保持全局一致性，并提高了少数客户端的性能。节俭标签流程结合了自/半监督预训练和选择性微调，在不共享原始数据的情况下减少了标注需求。在各种基准测试中，FedFusion在准确性、鲁棒性和公平性方面均优于现有方法，同时通信和计算成本相当。


<details>
  <summary>Details</summary>
Motivation: 联邦学习在实际应用中面临特征空间异构、数据非IID和标签稀疏等挑战。本研究旨在提出一个联邦迁移学习框架，以解决这些实际问题。

Method: FedFusion框架统一了域自适应和节俭标签，并引入了多样性/聚类感知编码器（DivEn, DivEn-mix, DivEn-c）。带标签的教师客户端通过置信度过滤的伪标签和域自适应迁移指导学习客户端，同时客户端维护个性化编码器。通过相似性加权分类器耦合（可选聚类平均）来保持全局一致性，并采用结合自/半监督预训练和选择性微调的节俭标签流程。

Result: 在表格和图像基准测试中，FedFusion在IID、非IID和标签稀疏的设定下，在准确性、鲁棒性和公平性方面持续优于最先进的方法，同时保持相当的通信和计算预算。

Conclusion: 联邦学习中个性化、域自适应和标签效率的协调是应对现实世界约束下鲁棒联邦学习的有效策略。

Abstract: Federated learning in practice must contend with heterogeneous feature
spaces, severe non-IID data, and scarce labels across clients. We present
FedFusion, a federated transfer-learning framework that unifies domain
adaptation and frugal labelling with diversity-/cluster-aware encoders (DivEn,
DivEn-mix, DivEn-c). Labelled teacher clients guide learner clients via
confidence-filtered pseudo-labels and domain-adaptive transfer, while clients
maintain personalised encoders tailored to local data. To preserve global
coherence under heterogeneity, FedFusion employs similarity-weighted classifier
coupling (with optional cluster-wise averaging), mitigating dominance by
data-rich sites and improving minority-client performance. The frugal-labelling
pipeline combines self-/semi-supervised pretext training with selective
fine-tuning, reducing annotation demands without sharing raw data. Across
tabular and imaging benchmarks under IID, non-IID, and label-scarce regimes,
FedFusion consistently outperforms state-of-the-art baselines in accuracy,
robustness, and fairness while maintaining comparable communication and
computation budgets. These results show that harmonising personalisation,
domain adaptation, and label efficiency is an effective recipe for robust
federated learning under real-world constraints.

</details>


### [211] [Towards Scalable and Structured Spatiotemporal Forecasting](https://arxiv.org/abs/2509.18115)
*Hongyi Chen,Xiucheng Li,Xinyang Chen,Jing Li,Kehai Chen,Liqiang Nie*

Main category: cs.LG

TL;DR: 该研究提出了一种新颖的空间平衡注意力机制（Spatial Balance Attention）来解决时空预测问题，通过将空间图划分为子图并分别应用内部和跨子图注意力机制，平衡了空间邻近性和全局相关性，并开发了一种多尺度的时空预测模型，该模型在真实数据集上展现了优越的性能和效率。


<details>
  <summary>Details</summary>
Motivation: 为了平衡空间邻近性和捕捉全局相关性，以解决时空预测问题。

Method: 提出了一种新颖的空间平衡注意力（Spatial Balance Attention）机制，该机制将空间图划分为子图，并分别应用内部子图注意力和跨子图注意力机制来分别学习局部和全局的空间相关性。在此基础上，构建了一个多尺度的时空预测模型。

Result: 所提出的模型在真实世界的中到大规模时空数据集上进行了评估，实验结果表明，在低运行成本下，性能相较于现有基线方法有高达 7.7% 的提升。

Conclusion: 提出的空间平衡注意力机制能够有效地平衡空间邻近性和全局相关性，从而构建出可扩展、易于实现且性能优越的时空预测模型。

Abstract: In this paper, we propose a novel Spatial Balance Attention block for
spatiotemporal forecasting. To strike a balance between obeying spatial
proximity and capturing global correlation, we partition the spatial graph into
a set of subgraphs and instantiate Intra-subgraph Attention to learn local
spatial correlation within each subgraph; to capture the global spatial
correlation, we further aggregate the nodes to produce subgraph representations
and achieve message passing among the subgraphs via Inter-subgraph Attention.
Building on the proposed Spatial Balance Attention block, we develop a
multiscale spatiotemporal forecasting model by progressively increasing the
subgraph scales. The resulting model is both scalable and able to produce
structured spatial correlation, and meanwhile, it is easy to implement. We
evaluate its efficacy and efficiency against the existing models on real-world
spatiotemporal datasets from medium to large sizes. The experimental results
show that it can achieve performance improvements up to 7.7% over the baseline
methods at low running costs.

</details>


### [212] [Amortized Latent Steering: Low-Cost Alternative to Test-Time Optimization](https://arxiv.org/abs/2509.18116)
*Nathan Egbuna,Saatvik Gaur,Sunishchal Dev,Ashwinee Panda,Maheep Chaudhary*

Main category: cs.LG

TL;DR: ALS 是一种通过离线计算的向量在推理时校准模型隐藏表示的方法，可以在不增加额外推理成本的情况下提高模型效率和准确性。


<details>
  <summary>Details</summary>
Motivation: 现有的测试时优化方法（如迭代优化和多步验证）推理成本高昂，而潜空间测试时优化方法（如 LatentSeek）虽然更直接，但仍需要昂贵的每查询优化循环。

Method: ALS 计算成功与不成功生成之间的隐藏状态的平均差值，然后利用这个方向来校准模型的隐藏表示，将偏离成功流形（success manifold）的激活引导回该流形。

Result: 在 GSM8K 和 MATH-500 基准测试中，ALS 比迭代方法快 2-5 倍，同时在效率-准确性权衡方面取得了高达 101% 的改进，与贪婪的思维链（CoT）和自洽性（Self-Consistency）基线相匹配或超越。

Conclusion: ALS 表明，潜空间优化的许多好处可以在离线完成，使得复杂的推理技术可以投入生产使用。

Abstract: Test-time optimization remains impractical at scale due to prohibitive
inference costs\textemdash techniques like iterative refinement and multi-step
verification can require $10$--$100\times$ more compute per query than standard
decoding. Latent space test-time optimization methods like LatentSeek offer a
more direct approach by steering hidden representations, but still demand
expensive per-query optimization loops with multiple backward passes. We
propose Amortized Latent Steering (ALS), which collapses this iterative
optimization into a single offline-computed vector applied at constant cost
during inference. ALS computes the mean difference between hidden states from
successful versus unsuccessful generations, then uses this direction to
calibrate the model's hidden representations: when decoding drifts away from
the success manifold, ALS nudges activations back toward it. Across GSM8K and
MATH-$500$ benchmarks, ALS achieves $2$--$5\times$ speedup over iterative
methods while matching or surpassing greedy Chain-of-Thought (CoT) and
Self-Consistency baselines, yielding up to 101\% improvement in
efficiency--accuracy trade-off. These results show that much of latent
optimization's benefit can be captured offline, making sophisticated reasoning
techniques viable for production deployment. Code is available
at~\href{https://anonymous.4open.science/r/steering-17F2}{https://anonymous.4open.science/r/steering-17F2}

</details>


### [213] [Robust and continuous machine learning of usage habits to adapt digital interfaces to user needs](https://arxiv.org/abs/2509.18117)
*Eric Petit,Denis Chêne*

Main category: cs.LG

TL;DR: 该方法提出了一种使用贝叶斯统计和在线增量学习的机器学习算法，用于设计能够动态适应不同用户和使用策略的数字界面。


<details>
  <summary>Details</summary>
Motivation: 该研究的动机是开发能够根据用户的个人习惯动态调整界面的系统，以改善用户体验。

Method: 该算法利用贝叶斯统计对用户的浏览行为进行建模，重点关注个人习惯而非群体偏好。它采用在线增量学习方法，即使数据量少或环境变化也能进行可靠预测。该方法生成一个任务模型，以图形方式展示当前用户的使用统计数据。

Result: 仿真结果表明，该方法在静态和非静态环境中都有效。

Conclusion: 该研究为开发能够通过帮助用户更好地导航和操作界面来改善用户体验的自适应系统铺平了道路。

Abstract: The paper presents a machine learning approach to design digital interfaces
that can dynamically adapt to different users and usage strategies. The
algorithm uses Bayesian statistics to model users' browsing behavior, focusing
on their habits rather than group preferences. It is distinguished by its
online incremental learning, allowing reliable predictions even with little
data and in the case of a changing environment. This inference method generates
a task model, providing a graphical representation of navigation with the usage
statistics of the current user. The algorithm learns new tasks while preserving
prior knowledge. The theoretical framework is described, and simulations show
the effectiveness of the approach in stationary and non-stationary
environments. In conclusion, this research paves the way for adaptive systems
that improve the user experience by helping them to better navigate and act on
their interface.

</details>


### [214] [MobileRL: Online Agentic Reinforcement Learning for Mobile GUI Agents](https://arxiv.org/abs/2509.18119)
*Yifan Xu,Xiao Liu,Xinghan Liu,Jiaqi Fu,Hanchen Zhang,Bohao Jing,Shudan Zhang,Yuting Wang,Wenyi Zhao,Yuxiao Dong*

Main category: cs.LG

TL;DR: MOBILERL是一个用于增强移动环境GUI智能体的在线智能强化学习框架，通过ADAGRPO算法（包括难度自适应正向回放和失败课程过滤）以及最短路径奖励调整策略，有效解决了任务难度分布不均和环境采样效率低的问题，从而稳定了训练，提高了样本效率，并在AndroidWorld和AndroidLab上取得了最先进的成果。


<details>
  <summary>Details</summary>
Motivation: 移动GUI智能体在强化学习方面仍面临严峻挑战，主要由于任务难度分布不均和大规模环境采样效率低下。

Method: 提出MOBILERL框架，其核心是ADAGRPO算法。ADAGRPO包含难度自适应正向回放和失败课程过滤，并引入了最短路径奖励调整策略。

Result: 将MOBILERL应用于Qwen2.5-VL-7B-Instruct和GLM-4.1V-9B-Base两个开源模型。MOBILERL-9B在AndroidWorld（75.8%）和AndroidLab（46.8%）上均取得了最先进的成功率。

Conclusion: MOBILERL框架通过创新的算法和策略，有效提升了移动GUI智能体的性能，已成功应用于AutoGLM产品并开源。

Abstract: Building general-purpose graphical user interface (GUI) agents has become
increasingly promising with the progress in vision language models. However,
developing effective mobile GUI agents with reinforcement learning (RL) remains
challenging due to the heavy-tailed distribution of task difficulty and the
inefficiency of large-scale environment sampling. We present an online agentic
reinforcement learning framework MOBILERL to enhance GUI agents in mobile
environments. Its core component is the Difficulty-Adaptive GRPO (ADAGRPO)
algorithm. In ADAGRPO, we design difficulty-adaptive positive replay and
failure curriculum filtering to adapt the model to different task difficulties.
We introduce the shortest path reward adjustment strategy to reshape rewards
concerning the task length in multi-turn agentic tasks. Those strategies
jointly stabilize RL training, improve sample efficiency, and generate strong
performance across diverse mobile apps and tasks. We apply MOBILERL to two open
models (Qwen2.5-VL-7B-Instruct and GLM-4.1V-9B-Base). The resultant MOBILERL-9B
model achieves state-of-the-art results in terms of success rates on both
AndroidWorld (75.8%) and AndroidLab (46.8%). The MOBILERL framework is adopted
in the AutoGLM products, and also open-sourced at
https://github.com/THUDM/MobileRL.

</details>


### [215] [Prediction of Coffee Ratings Based On Influential Attributes Using SelectKBest and Optimal Hyperparameters](https://arxiv.org/abs/2509.18124)
*Edmund Agyemang,Lawrence Agbota,Vincent Agbenyeavu,Peggy Akabuah,Bismark Bimpong,Christopher Attafuah*

Main category: cs.LG

TL;DR: 使用监督机器学习算法预测咖啡评分。


<details>
  <summary>Details</summary>
Motivation: 提取用户评论中的文本和数值属性，找出影响咖啡品质评分的关键因素。

Method: 使用TF-IDF进行特征提取，SelectKBest进行特征选择。训练并评估了六种模型（决策树、K近邻、多层感知器、随机森林、Extra Trees和XGBoost），并优化了超参数。主要使用F1分数、Gmean和AUC指标评估模型性能。

Result: 集成方法（Extra Trees、随机森林和XGBoost）以及多层感知器在F1分数、G-mean和AUC等评估指标上持续优于简单的分类器（决策树和K近邻）。

Conclusion: 严格的特征选择和超参数调整对于构建稳健的预测系统至关重要，可以为传统的咖啡杯测提供数据驱动的补充。

Abstract: This study explores the application of supervised machine learning algorithms
to predict coffee ratings based on a combination of influential textual and
numerical attributes extracted from user reviews. Through careful data
preprocessing including text cleaning, feature extraction using TF-IDF, and
selection with SelectKBest, the study identifies key factors contributing to
coffee quality assessments. Six models (Decision Tree, KNearest Neighbors,
Multi-layer Perceptron, Random Forest, Extra Trees, and XGBoost) were trained
and evaluated using optimized hyperparameters. Model performance was assessed
primarily using F1-score, Gmean, and AUC metrics. Results demonstrate that
ensemble methods (Extra Trees, Random Forest, and XGBoost), as well as
Multi-layer Perceptron, consistently outperform simpler classifiers (Decision
Trees and K-Nearest Neighbors) in terms of evaluation metrics such as F1
scores, G-mean and AUC. The findings highlight the essence of rigorous feature
selection and hyperparameter tuning in building robust predictive systems for
sensory product evaluation, offering a data driven approach to complement
traditional coffee cupping by expertise of trained professionals.

</details>


### [216] [Subspace Clustering of Subspaces: Unifying Canonical Correlation Analysis and Subspace Clustering](https://arxiv.org/abs/2509.18653)
*Paris A. Karakasis,Nicholas D. Sidiropoulos*

Main category: cs.LG

TL;DR: 该论文提出了一种新颖的框架，称为子空间聚类（SCoS），用于基于列空间对稀疏矩阵集合进行聚类。该方法将每个数据样本建模为矩阵，并根据其潜在子空间进行聚类，与传统的向量化数据方法不同。


<details>
  <summary>Details</summary>
Motivation: 传统子空间聚类方法假设数据被向量化，而本研究提出的方法直接将数据样本建模为矩阵，并根据其潜在子空间进行聚类，以解决更通用的情况。

Method: 该方法利用三阶张量分解（Block Term Decomposition, BTD）来同时估计聚类成员和部分共享的子空间。

Result: 实验结果表明，该方法在真实世界的高光谱成像数据集上，尤其是在高噪声和干扰条件下，比现有的子空间聚类技术具有更高的聚类准确性和鲁棒性。

Conclusion: 该框架在挑战性高维应用中具有巨大潜力，特别是在数据结构超越单个数据向量的情况下。

Abstract: We introduce a novel framework for clustering a collection of tall matrices
based on their column spaces, a problem we term Subspace Clustering of
Subspaces (SCoS). Unlike traditional subspace clustering methods that assume
vectorized data, our formulation directly models each data sample as a matrix
and clusters them according to their underlying subspaces. We establish
conceptual links to Subspace Clustering and Generalized Canonical Correlation
Analysis (GCCA), and clarify key differences that arise in this more general
setting. Our approach is based on a Block Term Decomposition (BTD) of a
third-order tensor constructed from the input matrices, enabling joint
estimation of cluster memberships and partially shared subspaces. We provide
the first identifiability results for this formulation and propose scalable
optimization algorithms tailored to large datasets. Experiments on real-world
hyperspectral imaging datasets demonstrate that our method achieves superior
clustering accuracy and robustness, especially under high noise and
interference, compared to existing subspace clustering techniques. These
results highlight the potential of the proposed framework in challenging
high-dimensional applications where structure exists beyond individual data
vectors.

</details>


### [217] [NurseSchedRL: Attention-Guided Reinforcement Learning for Nurse-Patient Assignment](https://arxiv.org/abs/2509.18125)
*Harsha Koduri*

Main category: cs.LG

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Healthcare systems face increasing pressure to allocate limited nursing
resources efficiently while accounting for skill heterogeneity, patient acuity,
staff fatigue, and continuity of care. Traditional optimization and heuristic
scheduling methods struggle to capture these dynamic, multi-constraint
environments. I propose NurseSchedRL, a reinforcement learning framework for
nurse-patient assignment that integrates structured state encoding, constrained
action masking, and attention-based representations of skills, fatigue, and
geographical context. NurseSchedRL uses Proximal Policy Optimization (PPO) with
feasibility masks to ensure assignments respect real-world constraints, while
dynamically adapting to patient arrivals and varying nurse availability. In
simulation with realistic nurse and patient data, NurseSchedRL achieves
improved scheduling efficiency, better alignment of skills to patient needs,
and reduced fatigue compared to baseline heuristic and unconstrained RL
approaches. These results highlight the potential of reinforcement learning for
decision support in complex, high-stakes healthcare workforce management.

</details>


### [218] [Anomaly Detection in Electric Vehicle Charging Stations Using Federated Learning](https://arxiv.org/abs/2509.18126)
*Bishal K C,Amr Hilal,Pawan Thapa*

Main category: cs.LG

TL;DR: 联邦学习（FL）在电动汽车充电站（EVCS）的物联网（IoT）环境中通过FedAvgM在系统和数据异构下实现高效、注重隐私的异常检测。


<details>
  <summary>Details</summary>
Motivation: 随着电动汽车基础设施的快速扩张，保护这些基于物联网的充电站免受网络威胁变得至关重要。传统的集中式入侵检测系统（IDS）因涉及敏感数据而引发隐私担忧，因此需要一种替代方案，如联邦学习。

Method: 评估了FedAvg和FedAvgM在EVCS环境中的异常检测性能，考虑了系统和数据异构性。

Result: 在IID设置下，FedAvg优于集中式模型；然而，在非IID数据和系统异构下，其性能会下降。FedAvgM在异构设置下始终优于FedAvg，表现出更好的收敛性和更高的异常检测准确性。

Conclusion: 联邦学习可以处理物联网EVCS中的异构性，而不会造成显著的性能损失，其中FedAvgM是实现鲁棒、注重隐私的EVCS安全的一个有前途的解决方案。

Abstract: Federated Learning (FL) is a decentralized training framework widely used in
IoT ecosystems that preserves privacy by keeping raw data local, making it
ideal for IoT-enabled cyber-physical systems with sensing and communication
like Smart Grids (SGs), Connected and Automated Vehicles (CAV), and Electric
Vehicle Charging Stations (EVCS). With the rapid expansion of electric vehicle
infrastructure, securing these IoT-based charging stations against cyber
threats has become critical. Centralized Intrusion Detection Systems (IDS)
raise privacy concerns due to sensitive network and user data, making FL a
promising alternative. However, current FL-based IDS evaluations overlook
practical challenges such as system heterogeneity and non-IID data. To address
these challenges, we conducted experiments to evaluate the performance of
federated learning for anomaly detection in EV charging stations under system
and data heterogeneity. We used FedAvg and FedAvgM, widely studied optimization
approaches, to analyze their effectiveness in anomaly detection. Under IID
settings, FedAvg achieves superior performance to centralized models using the
same neural network. However, performance degrades with non-IID data and system
heterogeneity. FedAvgM consistently outperforms FedAvg in heterogeneous
settings, showing better convergence and higher anomaly detection accuracy. Our
results demonstrate that FL can handle heterogeneity in IoT-based EVCS without
significant performance loss, with FedAvgM as a promising solution for robust,
privacy-preserving EVCS security.

</details>


### [219] [Safe-SAIL: Towards a Fine-grained Safety Landscape of Large Language Models via Sparse Autoencoder Interpretation Framework](https://arxiv.org/abs/2509.18127)
*Jiaqi Weng,Han Zheng,Hanyu Zhang,Qinqin He,Jialing Tao,Hui Xue,Zhixuan Chu,Xiting Wang*

Main category: cs.LG

TL;DR: 本研究提出Safe-SAIL框架，用于解释大语言模型（LLMs）中的稀疏自编码器（SAE）特征，以增强对安全领域的机制理解。该框架能识别具有最佳概念特异性可解释性的SAE，解释与安全相关的神经元，并引入了可扩展的解释策略，以应对提取丰富、多样化的安全相关特征所面临的挑战。研究还将发布一个包含SAE检查点和人类可读神经元解释的工具包，以支持对LLM安全风险的实证分析。


<details>
  <summary>Details</summary>
Motivation: 现有LLM安全研究主要关注模型输出或特定安全任务，难以应对更广泛、未定义风险。SAE虽有助于模型可解释性，但以往应用未能精细解释安全概念，对毒性响应或违反安全规定等行为的应对不足。

Method: 提出Safe-SAIL框架，系统地识别具有最佳概念特异性可解释性的SAE，解释安全相关神经元，并引入了有效的策略来扩展解释过程。

Result: 研究旨在提供一种更有效的SAE特征解释方法，以应对提取安全相关特征的挑战，并最终通过发布的工具包支持对LLM安全风险的实证分析。

Conclusion: Safe-SAIL框架通过精细化SAE特征解释，能够更有效地捕捉和理解LLM中的安全风险，为LLM安全研究提供新的机制化视角和实用工具。

Abstract: Increasing deployment of large language models (LLMs) in real-world
applications raises significant safety concerns. Most existing safety research
focuses on evaluating LLM outputs or specific safety tasks, limiting their
ability to ad- dress broader, undefined risks. Sparse Autoencoders (SAEs)
facilitate interpretability research to clarify model behavior by explaining
single-meaning atomic features decomposed from entangled signals. jHowever,
prior applications on SAEs do not interpret features with fine-grained
safety-related con- cepts, thus inadequately addressing safety-critical
behaviors, such as generating toxic responses and violating safety regu-
lations. For rigorous safety analysis, we must extract a rich and diverse set
of safety-relevant features that effectively capture these high-risk behaviors,
yet face two challenges: identifying SAEs with the greatest potential for
generating safety concept-specific neurons, and the prohibitively high cost of
detailed feature explanation. In this paper, we pro- pose Safe-SAIL, a
framework for interpreting SAE features within LLMs to advance mechanistic
understanding in safety domains. Our approach systematically identifies SAE
with best concept-specific interpretability, explains safety-related neurons,
and introduces efficient strategies to scale up the in- terpretation process.
We will release a comprehensive toolkit including SAE checkpoints and
human-readable neuron ex- planations, which supports empirical analysis of
safety risks to promote research on LLM safety.

</details>


### [220] [Stability and Generalization of Adversarial Diffusion Training](https://arxiv.org/abs/2509.19234)
*Hesam Hosseini,Ying Cao,Ali H. Sayed*

Main category: cs.LG

TL;DR: 本篇论文提出了基于算法稳定性的方法来分析去中心化设置下对抗性训练的泛化性能。


<details>
  <summary>Details</summary>
Motivation: 对抗性训练虽然能提高模型的鲁棒性，但会带来鲁棒性过拟合和泛化间隙增大的问题。尽管已有研究证明了对抗性训练在去中心化网络中的收敛性，但其泛化性能仍未得到探索。

Method: 利用基于稳定性的方法，针对具有凸损失函数的扩散策略，对去中心化设置下的对抗性训练进行泛化性能分析。

Result: 推导出的界限表明，泛化误差会随着对抗性扰动强度和训练步数的增加而增大，这与单智能体情况一致，但在去中心化设置下是新的发现。

Conclusion: 理论分析和在逻辑回归上的数值实验结果都证实了该泛化误差界限的有效性。

Abstract: Algorithmic stability is an established tool for analyzing generalization.
While adversarial training enhances model robustness, it often suffers from
robust overfitting and an enlarged generalization gap. Although recent work has
established the convergence of adversarial training in decentralized networks,
its generalization properties remain unexplored. This work presents a
stability-based generalization analysis of adversarial training under the
diffusion strategy for convex losses. We derive a bound showing that the
generalization error grows with both the adversarial perturbation strength and
the number of training steps, a finding consistent with single-agent case but
novel for decentralized settings. Numerical experiments on logistic regression
validate these theoretical predictions.

</details>


### [221] [Accounting for Uncertainty in Machine Learning Surrogates: A Gauss-Hermite Quadrature Approach to Reliability Analysis](https://arxiv.org/abs/2509.18128)
*Amirreza Tootchi,Xiaoping Du*

Main category: cs.LG

TL;DR: 机器学习替代模型会引入额外的模型不确定性，本研究提出了一种高斯-厄米特求积方法来解耦这种不确定性，以提高可靠性分析的准确性。


<details>
  <summary>Details</summary>
Motivation: 机器学习替代模型在物理可靠性分析中广泛应用，但其引入的估算不确定性会与输入参数的不确定性耦合，影响预测精度。

Method: 采用高斯-厄米特求积方法，首先使用一阶和二阶可靠性方法评估条件失效概率，然后对估算不确定性进行积分。

Result: 通过三个算例验证，该方法在保持计算效率的同时，比忽略模型不确定性的传统方法能提供更可靠的预测。

Conclusion: 所提出的解耦不确定性的方法能够更准确地进行可靠性分析。

Abstract: Machine learning surrogates are increasingly employed to replace expensive
computational models for physics-based reliability analysis. However, their use
introduces epistemic uncertainty from model approximation errors, which couples
with aleatory uncertainty in model inputs, potentially compromising the
accuracy of reliability predictions. This study proposes a Gauss-Hermite
quadrature approach to decouple these nested uncertainties and enable more
accurate reliability analysis. The method evaluates conditional failure
probabilities under aleatory uncertainty using First and Second Order
Reliability Methods and then integrates these probabilities across realizations
of epistemic uncertainty. Three examples demonstrate that the proposed approach
maintains computational efficiency while yielding more trustworthy predictions
than traditional methods that ignore model uncertainty.

</details>


### [222] [Research on Metro Transportation Flow Prediction Based on the STL-GRU Combined Model](https://arxiv.org/abs/2509.18130)
*Zijie Zhou,Huichen Ma*

Main category: cs.LG

TL;DR: 该研究提出了一种结合STL和GRU的地铁换乘客流预测模型，通过分解时间序列并利用GRU进行预测，显著提高了预测精度。


<details>
  <summary>Details</summary>
Motivation: 为了优化地铁运营计划和提高交通效率，需要精确预测地铁内部换乘客流。

Method: 1. 使用Keras构建和训练GRU模型。 2. 预处理地铁刷卡数据，利用深度优先搜索算法识别乘客路径，构建换乘客流时间序列。 3. 采用STL时间序列分解算法将序列分解为趋势、周期和残差分量。 4. 利用3σ原则处理残差分量中的异常值。 5. 进行换乘客流预测。

Result: 与LSTM、GRU和STL-LSTM模型相比，STL-GRU模型在工作日（非周五）、周五和休息日的预测准确性均有显著提升，平均绝对百分比误差（MAPE）分别至少降低了2.3%、1.36%和6.42%。

Conclusion: STL-GRU组合预测模型能够有效提高地铁换乘客流预测的准确性，为智能运营决策提供更可靠的支持。

Abstract: In the metro intelligent transportation system, accurate transfer passenger
flow prediction is a key link in optimizing operation plans and improving
transportation efficiency. To further improve the theory of metro internal
transfer passenger flow prediction and provide more reliable support for
intelligent operation decisions, this paper innovatively proposes a metro
transfer passenger flow prediction model that integrates the Seasonal and Trend
decomposition using Loess (STL) method and Gated Recurrent Unit (GRU).In
practical application, the model first relies on the deep learning library
Keras to complete the construction and training of the GRU model, laying the
foundation for subsequent prediction; then preprocesses the original metro card
swiping data, uses the graph-based depth-first search algorithm to identify
passengers' travel paths, and further constructs the transfer passenger flow
time series; subsequently adopts the STL time series decomposition algorithm to
decompose the constructed transfer passenger flow time series into trend
component, periodic component and residual component, and uses the 3{\sigma}
principle to eliminate and fill the outliers in the residual component, and
finally completes the transfer passenger flow prediction.Taking the transfer
passenger flow data of a certain metro station as the research sample, the
validity of the model is verified. The results show that compared with Long
Short-Term Memory (LSTM), Gated Recurrent Unit (GRU), and the combined model of
STL time series decomposition method and Long Short-Term Memory (STL-LSTM), the
STL-GRU combined prediction model significantly improves the prediction
accuracy of transfer passenger flow on weekdays (excluding Fridays), Fridays
and rest days, with the mean absolute percentage error (MAPE) of the prediction
results reduced by at least 2.3, 1.36 and 6.42 percentage points respectively.

</details>


### [223] [Two ways to knowledge?](https://arxiv.org/abs/2509.18131)
*Jean-Michel Tucny,Abhisek Ganguly,Santosh Ansumali,Sauro Succi*

Main category: cs.LG

TL;DR: Transformer模型的权重矩阵与物理问题结构无直接关联，表明机器学习与科学方法可能是独立但互补的知识获取途径，但直接的可解释性难以实现。


<details>
  <summary>Details</summary>
Motivation: 探讨Transformer模型在物理应用中权重矩阵的特性，以及其与物理问题结构的关系，并思考机器学习与科学方法的异同。

Method: 分析Transformer模型在解决两个物理问题时权重矩阵的随机性特征，并尝试将其与路径积分技术进行类比。

Result: Transformer模型的权重矩阵表现出随机性，与物理问题结构无明显联系，但与路径积分技术存在潜在关联。

Conclusion: 机器学习，特别是Transformer模型，可能提供一种与传统科学方法不同的知识获取途径，但其可解释性仍是挑战，需要警惕缺乏洞察力的知识获取方式。

Abstract: It is shown that the weight matrices of transformer-based machine learning
applications to the solution of two representative physical applications show a
random-like character which bears no directly recognizable link to the physical
and mathematical structure of the physical problem under study. This suggests
that machine learning and the scientific method may represent two distinct and
potentially complementary paths to knowledge, even though a strict notion of
explainability in terms of direct correspondence between network parameters and
physical structures may remain out of reach. It is also observed that drawing a
parallel between transformer operation and (generalized) path-integration
techniques may account for the random-like nature of the weights, but still
does not resolve the tension with explainability. We conclude with some general
comments on the hazards of gleaning knowledge without the benefit of Insight.

</details>


### [224] [Self-Evolving LLMs via Continual Instruction Tuning](https://arxiv.org/abs/2509.18133)
*Le Huang,Jiazheng Kang,Cheng Hou,Zhe Zhao,Zhenxiang Yan,Chuan Shi,Ting Bai*

Main category: cs.LG

TL;DR: MoE-CL是一种参数高效的对抗性混合专家框架，用于LLM的工业级、自演化持续指令调优，通过专用的LoRA专家和共享的LoRA专家结合GAN中的判别器，以平衡知识保留和跨任务泛化，成功应用于工业场景并降低了人工审核成本。


<details>
  <summary>Details</summary>
Motivation: 现有的持续学习方法在处理工业级LLM的持续指令调优时，由于灾难性遗忘的问题，往往在新任务上表现良好，但在旧任务上性能下降。

Method: 提出了一种名为MoE-CL的参数高效的对抗性混合专家框架。该框架包含一个专用的LoRA专家用于保留任务特定知识，以及一个共享的LoRA专家用于跨任务迁移。通过结合一个任务感知的判别器和一个GAN，防止噪声信息通过共享路径迁移，并促使共享专家学习泛化表示。

Result: 在MTL5和Tencent3基准测试中，MoE-CL在持续指令调优方面表现出有效性。在腾讯视频平台的内容合规性审查A/B测试中，MoE-CL将人工审核成本降低了15.3%。

Conclusion: MoE-CL在需要持续适应和稳定迁移的大规模工业部署中是实用的，能够有效解决灾难性遗忘问题，并能在实际应用中带来显著的成本效益。

Abstract: In real-world industrial settings, large language models (LLMs) must learn
continually to keep pace with diverse and evolving tasks, requiring
self-evolution to refine knowledge under dynamic data distributions. However,
existing continual learning (CL) approaches, such as replay and parameter
isolation, often suffer from catastrophic forgetting: training on new tasks
degrades performance on earlier ones by overfitting to the new distribution and
weakening generalization.We propose MoE-CL, a parameter-efficient adversarial
mixture-of-experts framework for industrial-scale, self-evolving continual
instruction tuning of LLMs. MoE-CL uses a dual-expert design: (1) a dedicated
LoRA expert per task to preserve task-specific knowledge via parameter
independence, mitigating forgetting; and (2) a shared LoRA expert to enable
cross-task transfer. To prevent transferring task-irrelevant noise through the
shared pathway, we integrate a task-aware discriminator within a GAN. The
discriminator encourages the shared expert to pass only task-aligned
information during sequential training. Through adversarial learning, the
shared expert acquires generalized representations that mimic the
discriminator, while dedicated experts retain task-specific details, balancing
knowledge retention and cross-task generalization and thereby supporting
self-evolution.Extensive experiments on the public MTL5 benchmark and an
industrial Tencent3 benchmark validate the effectiveness of MoE-CL for
continual instruction tuning. In real-world A/B testing for content compliance
review on the Tencent Video platform, MoE-CL reduced manual review costs by
15.3%. These results demonstrate that MoE-CL is practical for large-scale
industrial deployment where continual adaptation and stable transfer are
critical.

</details>


### [225] [A Weighted Gradient Tracking Privacy-Preserving Method for Distributed Optimization](https://arxiv.org/abs/2509.18134)
*Furan Xie,Bing Liu,Li Chai*

Main category: cs.LG

TL;DR: 本论文提出了一种加权梯度跟踪分布式隐私保护算法，通过使用衰减权重因子消除梯度跟踪中的隐私泄露风险，并证明了该算法在时变异构步长下的收敛性。


<details>
  <summary>Details</summary>
Motivation: 在分布式优化问题中，保护代理的私有信息免受潜在攻击者的侵害至关重要。梯度跟踪技术虽然能提高收敛速度，但也存在固有的隐私泄露风险。

Method: 提出了一种加权梯度跟踪分布式隐私保护算法，该算法使用衰减权重因子来消除梯度跟踪中的隐私泄露风险，并分析了该算法在时变异构步长下的收敛性。

Result: 证明了所提出的算法在温和假设下能够精确收敛到最优解。通过在分布式估计问题和卷积神经网络的分布式训练中的数值模拟，验证了该算法的有效性。

Conclusion: 所提出的加权梯度跟踪分布式隐私保护算法能够有效消除梯度跟踪中的隐私泄露风险，并保证算法在时变异构步长下的精确收敛性。数值模拟结果也验证了该算法在实际问题中的有效性。

Abstract: This paper investigates the privacy-preserving distributed optimization
problem, aiming to protect agents' private information from potential attackers
during the optimization process. Gradient tracking, an advanced technique for
improving the convergence rate in distributed optimization, has been applied to
most first-order algorithms in recent years. We first reveal the inherent
privacy leakage risk associated with gradient tracking. Building upon this
insight, we propose a weighted gradient tracking distributed privacy-preserving
algorithm, eliminating the privacy leakage risk in gradient tracking using
decaying weight factors. Then, we characterize the convergence of the proposed
algorithm under time-varying heterogeneous step sizes. We prove the proposed
algorithm converges precisely to the optimal solution under mild assumptions.
Finally, numerical simulations validate the algorithm's effectiveness through a
classical distributed estimation problem and the distributed training of a
convolutional neural network.

</details>


### [226] [SDGF: Fusing Static and Multi-Scale Dynamic Correlations for Multivariate Time Series Forecasting](https://arxiv.org/abs/2509.18135)
*Shaoxun Wang,Xingjun Zhang,Qianyang Li,Jiawei Cao,Zhendong Tan*

Main category: cs.LG

TL;DR: 该研究提出了一种新的静态-动态图融合网络（SDGF），通过双路径图结构学习方法来捕捉多尺度时间序列间的相关性，以提高多元时间序列预测的准确性。


<details>
  <summary>Details</summary>
Motivation: 现有方法在建模多尺度依赖关系方面存在局限，难以捕捉其复杂和不断变化的性质。

Method: SDGF模型使用基于先验知识的静态图来锚定长期稳定的依赖关系，并利用多级小波分解提取多尺度特征来构建自适应学习的动态图，以捕捉不同尺度的关联性。通过注意力门控模块融合这两种信息，并使用多核扩张卷积网络来加深对时间模式的理解。

Result: 在多个广泛使用的真实基准数据集上的综合实验证明了该模型的有效性。

Conclusion: SDGF模型能够有效地捕捉多尺度时间序列间的相关性，提高预测准确性。

Abstract: Inter-series correlations are crucial for accurate multivariate time series
forecasting, yet these relationships often exhibit complex dynamics across
different temporal scales. Existing methods are limited in modeling these
multi-scale dependencies and struggle to capture their intricate and evolving
nature. To address this challenge, this paper proposes a novel Static-Dynamic
Graph Fusion network (SDGF), whose core lies in capturing multi-scale
inter-series correlations through a dual-path graph structure learning
approach. Specifically, the model utilizes a static graph based on prior
knowledge to anchor long-term, stable dependencies, while concurrently
employing Multi-level Wavelet Decomposition to extract multi-scale features for
constructing an adaptively learned dynamic graph to capture associations at
different scales. We design an attention-gated module to fuse these two
complementary sources of information intelligently, and a multi-kernel dilated
convolutional network is then used to deepen the understanding of temporal
patterns. Comprehensive experiments on multiple widely used real-world
benchmark datasets demonstrate the effectiveness of our proposed model.

</details>


### [227] [From Parameters to Performance: A Data-Driven Study on LLM Structure and Development](https://arxiv.org/abs/2509.18136)
*Suqing Wang,Zuchao Li,Luohe Shi,Bo Du,Hai Zhao,Yun Li,Qianren Wang*

Main category: cs.LG

TL;DR: LLM结构对性能的影响尚不清楚，本研究构建了一个包含LLM结构及其性能的大型数据集，并通过数据挖掘和可解释性技术进行了分析，为未来LLM的开发提供指导。


<details>
  <summary>Details</summary>
Motivation: LLM的结构配置如何影响其性能的研究不足，本研究旨在填补这一空白。

Method: 构建了一个包含LLM结构及其在多个基准测试上性能的大型数据集，并利用数据挖掘和机械可解释性技术进行分析。

Result: 发现了LLM结构配置与性能之间的关系，并通过实验进行了量化和验证。

Conclusion: 本研究提供了数据驱动的LLM优化见解，旨在指导未来模型的设计和应用。

Abstract: Large language models (LLMs) have achieved remarkable success across various
domains, driving significant technological advancements and innovations.
Despite the rapid growth in model scale and capability, systematic, data-driven
research on how structural configurations affect performance remains scarce. To
address this gap, we present a large-scale dataset encompassing diverse
open-source LLM structures and their performance across multiple benchmarks.
Leveraging this dataset, we conduct a systematic, data mining-driven analysis
to validate and quantify the relationship between structural configurations and
performance. Our study begins with a review of the historical development of
LLMs and an exploration of potential future trends. We then analyze how various
structural choices impact performance across benchmarks and further corroborate
our findings using mechanistic interpretability techniques. By providing
data-driven insights into LLM optimization, our work aims to guide the targeted
development and application of future models. We will release our dataset at
https://huggingface.co/datasets/DX0369/LLM-Structure-Performance-Dataset

</details>


### [228] [LoRALib: A Standardized Benchmark for Evaluating LoRA-MoE Methods](https://arxiv.org/abs/2509.18137)
*Shaoheng Wang,Yao Lu,Yuqi Li,Yaxin Gao,Jiaqi Nie,Shanqing Yu,Yingli Tian,Qi Xuan*

Main category: cs.LG

TL;DR: LoRA-MoE 在跨任务泛化方面表现最佳，并且优先选择与目标任务相关的 LoRA 可以进一步提高 MoE 的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的 LoRA-MoE 方法在模型、数据集、超参数和评估方法方面缺乏统一的标准，导致难以进行公平的比较。

Method: 提出了一种名为 LoRALib 的统一基准，标准化了来自 40 个下游任务的数据集，并使用相同的超参数进行了微调，获得了 680 个 LoRA 模块，涵盖了 17 种模型架构。在此基础上，使用 OpenCompass 对 3 种代表性的 LoRA-MoE 方法和不同的 LoRA 选择机制进行了大规模实验。

Result: LoRA-MoE 表现最佳，并且优先选择与目标任务相关的 LoRA 可以进一步提高 MoE 的性能。

Conclusion: LoRALib 为 LoRA-MoE 的公平比较提供了统一的标准，并为未来的研究提供了新的发现和方向。

Abstract: As a parameter efficient fine-tuning (PEFT) method, low-rank adaptation
(LoRA) can save significant costs in storage and computing, but its strong
adaptability to a single task is often accompanied by insufficient cross-task
generalization capabilities. To improve this, existing work combines LoRA with
mixture-of-experts (MoE) to enhance the model's adaptability through expert
modules and routing mechanisms. However, existing LoRA-MoE methods lack unified
standards in models, datasets, hyperparameters, and evaluation methods, making
it difficult to conduct fair comparisons between different methods. To this
end, we proposed a unified benchmark named LoRALib. Specifically, we
standardized datasets from $40$ downstream tasks into a unified format,
fine-tuned them using the same hyperparameters and obtained $680$ LoRA modules
across $17$ model architectures. Based on this LoRA library, we conduct
large-scale experiments on $3$ representative LoRA-MoE methods and different
LoRA selection mechanisms using the open-sourced testing tool OpenCompass.
Extensive experiments show that LoRAMoE performs best, and that prioritizing
LoRAs relevant to the target task can further improve the performance of MoE.
We hope these findings will inspire future work. Our datasets and LoRA library
are available at https://huggingface.co/datasets/YaoLuzjut/LoRAOcean_dataset
and https://huggingface.co/YaoLuzjut/models.

</details>


### [229] [Rank-Induced PL Mirror Descent: A Rank-Faithful Second-Order Algorithm for Sleeping Experts](https://arxiv.org/abs/2509.18138)
*Tiantian Zhang*

Main category: cs.LG

TL;DR: RIPLM是一种新的算法，直接在秩诱导Plackett-Luce参数化中进行更新，保持了与秩基准的等价性，并且是第一个在睡眠专家设置中具有秩忠实性和方差适应性的算法。


<details>
  <summary>Details</summary>
Motivation: 本研究旨在提出一种新的算法RIPLM，利用秩基准和分布基准之间的结构等价性，直接在秩诱导Plackett-Luce参数化中进行更新，以解决现有方法不直接在参数化中操作的问题。

Method: RIPLM算法直接在秩诱导Plackett-Luce参数化中进行更新，确保算法在每一轮都能保持在秩诱导分布类别内，从而保持与秩基准的等价性。

Result: RIPLM算法是第一个同时满足秩忠实性和方差适应性的算法，该算法应用于睡眠专家设置。

Conclusion: RIPLM算法通过直接在秩诱导Plackett-Luce参数化中更新，实现了秩忠实性和方差适应性，为睡眠专家设置提供了一种新的解决方案。

Abstract: We introduce a new algorithm, \emph{Rank-Induced Plackett--Luce Mirror
Descent (RIPLM)}, which leverages the structural equivalence between the
\emph{rank benchmark} and the \emph{distributional benchmark} established in
\citet{BergamOzcanHsu2022}. Unlike prior approaches that operate on expert
identities, RIPLM updates directly in the \emph{rank-induced Plackett--Luce
(PL)} parameterization. This ensures that the algorithm's played distributions
remain within the class of rank-induced distributions at every round,
preserving the equivalence with the rank benchmark. To our knowledge, RIPLM is
the first algorithm that is both (i) \emph{rank-faithful} and (ii)
\emph{variance-adaptive} in the sleeping experts setting.

</details>


### [230] [Comparative Analysis of FOLD-SE vs. FOLD-R++ in Binary Classification and XGBoost in Multi-Category Classification](https://arxiv.org/abs/2509.18139)
*Akshay Murthy,Shawn Sebastian,Manil Shangle,Huaduo Wang,Sopam Dasgupta,Gopal Gupta*

Main category: cs.LG

TL;DR: FOLD-SE在二元分类和多类别分类任务中都优于FOLD-R++和XGBoost，平衡了准确性、效率和可解释性。


<details>
  <summary>Details</summary>
Motivation: 随着对机器学习模型准确性、效率和可解释性平衡的需求不断增长，本研究旨在比较FOLD-SE和FOLD-R++在二元分类中的表现，并评估FOLD-SE在多类别分类中与XGBoost的性能。

Method: 研究使用数据集合进行分类，主要性能指标包括准确性、F1分数和处理时间。

Result: 在二元分类任务中，FOLD-SE生成的规则更少，虽然准确性和处理效率略有下降，但优于FOLD-R++。在多类别分类任务中，FOLD-SE比XGBoost更精确、更高效，并生成了可理解的规则集。

Conclusion: FOLD-SE在二元和多类别分类任务中都是更好的选择，表明像FOLD-SE这样的基于规则的方法可以弥合可解释性与性能之间的差距，并作为多种分类任务中黑盒模型的可行替代方案。

Abstract: Recently, the demand for Machine Learning (ML) models that can balance
accuracy, efficiency, and interpreability has grown significantly.
Traditionally, there has been a tradeoff between accuracy and explainability in
predictive models, with models such as Neural Networks achieving high accuracy
on complex datasets while sacrificing internal transparency. As such, new
rule-based algorithms such as FOLD-SE have been developed that provide tangible
justification for predictions in the form of interpretable rule sets. The
primary objective of this study was to compare FOLD-SE and FOLD-R++, both
rule-based classifiers, in binary classification and evaluate how FOLD-SE
performs against XGBoost, a widely used ensemble classifier, when applied to
multi-category classification. We hypothesized that because FOLD-SE can
generate a condensed rule set in a more explainable manner, it would lose
upwards of an average of 3 percent in accuracy and F1 score when compared with
XGBoost and FOLD-R++ in multiclass and binary classification, respectively. The
research used data collections for classification, with accuracy, F1 scores,
and processing time as the primary performance measures. Outcomes show that
FOLD-SE is superior to FOLD-R++ in terms of binary classification by offering
fewer rules but losing a minor percentage of accuracy and efficiency in
processing time; in tasks that involve multi-category classifications, FOLD-SE
is more precise and far more efficient compared to XGBoost, in addition to
generating a comprehensible rule set. The results point out that FOLD-SE is a
better choice for both binary tasks and classifications with multiple
categories. Therefore, these results demonstrate that rule-based approaches
like FOLD-SE can bridge the gap between explainability and performance,
highlighting their potential as viable alternatives to black-box models in
diverse classification tasks.

</details>


### [231] [A Machine Learning Framework for Pathway-Driven Therapeutic Target Discovery in Metabolic Disorders](https://arxiv.org/abs/2509.18140)
*Iram Wajahat,Amritpal Singh,Fazel Keshtkar,Syed Ahmad Chan Bukhari*

Main category: cs.LG

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Metabolic disorders, particularly type 2 diabetes mellitus (T2DM), represent
a significant global health burden, disproportionately impacting genetically
predisposed populations such as the Pima Indians (a Native American tribe from
south central Arizona). This study introduces a novel machine learning (ML)
framework that integrates predictive modeling with gene-agnostic pathway
mapping to identify high-risk individuals and uncover potential therapeutic
targets. Using the Pima Indian dataset, logistic regression and t-tests were
applied to identify key predictors of T2DM, yielding an overall model accuracy
of 78.43%. To bridge predictive analytics with biological relevance, we
developed a pathway mapping strategy that links identified predictors to
critical signaling networks, including insulin signaling, AMPK, and PPAR
pathways. This approach provides mechanistic insights without requiring direct
molecular data. Building upon these connections, we propose therapeutic
strategies such as dual GLP-1/GIP receptor agonists, AMPK activators, SIRT1
modulators, and phytochemical, further validated through pathway enrichment
analyses. Overall, this framework advances precision medicine by offering
interpretable and scalable solutions for early detection and targeted
intervention in metabolic disorders. The key contributions of this work are:
(1) development of an ML framework combining logistic regression and principal
component analysis (PCA) for T2DM risk prediction; (2) introduction of a
gene-agnostic pathway mapping approach to generate mechanistic insights; and
(3) identification of novel therapeutic strategies tailored for high-risk
populations.

</details>


### [232] [KM-GPT: An Automated Pipeline for Reconstructing Individual Patient Data from Kaplan-Meier Plots](https://arxiv.org/abs/2509.18141)
*Yao Zhao,Haoyue Sun,Yantian Ding,Yanxun Xu*

Main category: cs.LG

TL;DR: KM-GPT是一个全自动化的AI工具，用于从Kaplan-Meier图重建个体患者数据（IPD），解决了手动数字化效率低且易出错的问题。


<details>
  <summary>Details</summary>
Motivation: 手动数字化Kaplan-Meier图重建个体患者数据（IPD）存在效率低、易出错和可扩展性差的问题，阻碍了临床研究中的证据合成。

Method: KM-GPT利用先进的图像预处理、GPT-5多模态推理和迭代重建算法，实现了从KM图全自动、高精度地重建IPD，无需人工干预。

Result: KM-GPT在合成和真实世界数据集上均表现出高精度、鲁棒性和可复现性，优于现有方法。

Conclusion: KM-GPT通过自动化IPD重建过程，提供了一个可扩展的、用户友好的解决方案，能够加速临床研究中的证据合成和下游分析，支持循证决策。

Abstract: Reconstructing individual patient data (IPD) from Kaplan-Meier (KM) plots
provides valuable insights for evidence synthesis in clinical research.
However, existing approaches often rely on manual digitization, which is
error-prone and lacks scalability. To address these limitations, we develop
KM-GPT, the first fully automated, AI-powered pipeline for reconstructing IPD
directly from KM plots with high accuracy, robustness, and reproducibility.
KM-GPT integrates advanced image preprocessing, multi-modal reasoning powered
by GPT-5, and iterative reconstruction algorithms to generate high-quality IPD
without manual input or intervention. Its hybrid reasoning architecture
automates the conversion of unstructured information into structured data flows
and validates data extraction from complex KM plots. To improve accessibility,
KM-GPT is equipped with a user-friendly web interface and an integrated AI
assistant, enabling researchers to reconstruct IPD without requiring
programming expertise. KM-GPT was rigorously evaluated on synthetic and
real-world datasets, consistently demonstrating superior accuracy. To
illustrate its utility, we applied KM-GPT to a meta-analysis of gastric cancer
immunotherapy trials, reconstructing IPD to facilitate evidence synthesis and
biomarker-based subgroup analyses. By automating traditionally manual processes
and providing a scalable, web-based solution, KM-GPT transforms clinical
research by leveraging reconstructed IPD to enable more informed downstream
analyses, supporting evidence-based decision-making.

</details>


### [233] [AdaSTI: Conditional Diffusion Models with Adaptive Dependency Modeling for Spatio-Temporal Imputation](https://arxiv.org/abs/2509.18144)
*Yubo Yang,Yichen Zhu,Bo Jiang*

Main category: cs.LG

TL;DR: AdaSTI是一种基于条件扩散模型的新型时空数据插补方法，通过双向S4模型预插补提取条件信息，并利用噪声感知时空网络捕获不同扩散步骤的依赖性，在三个真实世界数据集上均优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 时空数据（如交通和环境监测）常因传感器故障等原因出现缺失值。虽然扩散模型在时空插补方面表现出竞争力，但现有方法在提取时空依赖性作为条件信息时存在误差累积，并忽略了不同扩散步骤下依赖性的变异性。

Method: 提出AdaSTI（Adaptive Dependency Model in Diffusion-based Spatio-Temporal Imputation），包括：1. 基于双向S4模型的BiS4PI网络进行预插补，并将插补结果用于提取条件信息；2. 设计Spatio-Temporal Conditionalizer (STC)网络提取条件信息；3. 提出带门控注意力机制的噪声感知时空（NAST）网络，以捕捉跨扩散步骤的变异依赖性。

Result: 在三个真实世界数据集上的广泛实验表明，AdaSTI在所有设置下均优于现有方法，插补误差最多可降低46.4%。

Conclusion: AdaSTI通过有效处理时空依赖性的变异性，显著提高了时空数据插补的性能。

Abstract: Spatio-temporal data abounds in domain like traffic and environmental
monitoring. However, it often suffers from missing values due to sensor
malfunctions, transmission failures, etc. Recent years have seen continued
efforts to improve spatio-temporal data imputation performance. Recently
diffusion models have outperformed other approaches in various tasks, including
spatio-temporal imputation, showing competitive performance. Extracting and
utilizing spatio-temporal dependencies as conditional information is vital in
diffusion-based methods. However, previous methods introduce error accumulation
in this process and ignore the variability of the dependencies in the noisy
data at different diffusion steps. In this paper, we propose AdaSTI (Adaptive
Dependency Model in Diffusion-based Spatio-Temporal Imputation), a novel
spatio-temporal imputation approach based on conditional diffusion model.
Inside AdaSTI, we propose a BiS4PI network based on a bi-directional S4 model
for pre-imputation with the imputed result used to extract conditional
information by our designed Spatio-Temporal Conditionalizer (STC)network. We
also propose a Noise-Aware Spatio-Temporal (NAST) network with a gated
attention mechanism to capture the variant dependencies across diffusion steps.
Extensive experiments on three real-world datasets show that AdaSTI outperforms
existing methods in all the settings, with up to 46.4% reduction in imputation
error.

</details>


### [234] [Interaction Topological Transformer for Multiscale Learning in Porous Materials](https://arxiv.org/abs/2509.18573)
*Dong Chen,Jian Liu,Chun-Long Chen,Guo-Wei Wei*

Main category: cs.LG

TL;DR: ITT是一个数据高效的框架，利用新颖的相互作用拓扑来捕捉多尺度和多层次的材料信息，包括结构、元素、原子和成对元素组织。


<details>
  <summary>Details</summary>
Motivation: 预测多孔材料的结构-性质关系具有挑战性，因为其多尺度性质、稀疏且分布不均的标记数据限制了跨材料族的泛化能力。

Method: 提出相互作用拓扑Transformer（ITT）框架，提取反映复杂多孔骨架内成分和关系结构的尺度感知特征，并通过内置Transformer架构进行集成，支持跨尺度的联合推理，采用自监督预训练和监督微调的两阶段策略进行训练。

Result: ITT在吸附、传输和稳定性性质方面实现了最先进的、准确的且可转移的预测。

Conclusion: 该框架为结构和化学性质多样化的多孔材料提供了有原则的、可扩展的学习引导发现途径。

Abstract: Porous materials exhibit vast structural diversity and support critical
applications in gas storage, separations, and catalysis. However, predictive
modeling remains challenging due to the multiscale nature of structure-property
relationships, where performance is governed by both local chemical
environments and global pore-network topology. These complexities, combined
with sparse and unevenly distributed labeled data, hinder generalization across
material families. We propose the Interaction Topological Transformer (ITT), a
unified data-efficient framework that leverages novel interaction topology to
capture materials information across multiple scales and multiple levels,
including structural, elemental, atomic, and pairwise-elemental organization.
ITT extracts scale-aware features that reflect both compositional and
relational structure within complex porous frameworks, and integrates them
through a built-in Transformer architecture that supports joint reasoning
across scales. Trained using a two-stage strategy, i.e., self-supervised
pretraining on 0.6 million unlabeled structures followed by supervised
fine-tuning, ITT achieves state-of-the-art, accurate, and transferable
predictions for adsorption, transport, and stability properties. This framework
provides a principled and scalable path for learning-guided discovery in
structurally and chemically diverse porous materials.

</details>


### [235] [Early Prediction of Multi-Label Care Escalation Triggers in the Intensive Care Unit Using Electronic Health Records](https://arxiv.org/abs/2509.18145)
*Syed Ahmad Chan Bukhari,Amritpal Singh,Shifath Hossain,Iram Wajahat*

Main category: cs.LG

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Intensive Care Unit (ICU) patients often present with complex, overlapping
signs of physiological deterioration that require timely escalation of care.
Traditional early warning systems, such as SOFA or MEWS, are limited by their
focus on single outcomes and fail to capture the multi-dimensional nature of
clinical decline. This study proposes a multi-label classification framework to
predict Care Escalation Triggers (CETs), including respiratory failure,
hemodynamic instability, renal compromise, and neurological deterioration,
using the first 24 hours of ICU data. Using the MIMIC-IV database, CETs are
defined through rule-based criteria applied to data from hours 24 to 72 (for
example, oxygen saturation below 90, mean arterial pressure below 65 mmHg,
creatinine increase greater than 0.3 mg/dL, or a drop in Glasgow Coma Scale
score greater than 2). Features are extracted from the first 24 hours and
include vital sign aggregates, laboratory values, and static demographics. We
train and evaluate multiple classification models on a cohort of 85,242 ICU
stays (80 percent training: 68,193; 20 percent testing: 17,049). Evaluation
metrics include per-label precision, recall, F1-score, and Hamming loss.
XGBoost, the best performing model, achieves F1-scores of 0.66 for respiratory,
0.72 for hemodynamic, 0.76 for renal, and 0.62 for neurologic deterioration,
outperforming baseline models. Feature analysis shows that clinically relevant
parameters such as respiratory rate, blood pressure, and creatinine are the
most influential predictors, consistent with the clinical definitions of the
CETs. The proposed framework demonstrates practical potential for early,
interpretable clinical alerts without requiring complex time-series modeling or
natural language processing.

</details>


### [236] [ConceptFlow: Hierarchical and Fine-grained Concept-Based Explanation for Convolutional Neural Networks](https://arxiv.org/abs/2509.18147)
*Xinyu Mu,Hui Dou,Furao Shen,Jian Zhao*

Main category: cs.LG

TL;DR: ConceptFlow 通过关注每个滤波器与高层概念的关联以及概念在层间的传播路径，来模拟和解释卷积神经网络（CNN）的内部推理过程。


<details>
  <summary>Details</summary>
Motivation: 现有基于概念的可解释性方法忽视了单个滤波器和概念跨层动态传播的语义角色，ConceptFlow 旨在解决这些局限性。

Method: ConceptFlow 框架包含两个关键组件：(i) 概念注意力（Concept attentions），将每个滤波器与相关的高层概念关联起来，实现局部语义解释；(ii) 概念通路（Conceptual pathways），源自量化概念如何在滤波器之间传播和转化的概念转移矩阵。

Result: 实验结果表明，ConceptFlow 提供了有意义的语义洞察，验证了概念注意力和概念通路在解释决策行为方面的有效性。

Conclusion: ConceptFlow 通过对分层概念通路进行建模，深入了解 CNN 的内部逻辑，并支持生成更忠实、更符合人类的解释。

Abstract: Concept-based interpretability for Convolutional Neural Networks (CNNs) aims
to align internal model representations with high-level semantic concepts, but
existing approaches largely overlook the semantic roles of individual filters
and the dynamic propagation of concepts across layers. To address these
limitations, we propose ConceptFlow, a concept-based interpretability framework
that simulates the internal "thinking path" of a model by tracing how concepts
emerge and evolve across layers. ConceptFlow comprises two key components: (i)
concept attentions, which associate each filter with relevant high-level
concepts to enable localized semantic interpretation, and (ii) conceptual
pathways, derived from a concept transition matrix that quantifies how concepts
propagate and transform between filters. Together, these components offer a
unified and structured view of internal model reasoning. Experimental results
demonstrate that ConceptFlow yields semantically meaningful insights into model
reasoning, validating the effectiveness of concept attentions and conceptual
pathways in explaining decision behavior. By modeling hierarchical conceptual
pathways, ConceptFlow provides deeper insight into the internal logic of CNNs
and supports the generation of more faithful and human-aligned explanations.

</details>


### [237] [Sparse Training Scheme for Multimodal LLM](https://arxiv.org/abs/2509.18150)
*Kean Shi,Liang Chen,Haozhe Zhao,Baobao Chang*

Main category: cs.LG

TL;DR: MLLMs训练效率低下，提出一种基于稀疏表示的STS框架，包括视觉令牌压缩器和层动态跳过器，以提高训练效率。


<details>
  <summary>Details</summary>
Motivation: 训练MLLMs效率低下，因多模态数据引入长序列和低层间计算利用率。

Method: 提出一种基于稀疏表示的STS框架，包括视觉令牌压缩器（压缩视觉令牌）和层动态跳过器（动态跳过不必要的层）。

Result: 在多个基准上进行了广泛评估，证明了该方法的有效性和效率。

Conclusion: STS框架能有效提高MLLMs的训练效率。

Abstract: Multimodal Large Language Models (MLLMs) have demonstrated outstanding
performance across a variety of domains. However, training MLLMs is often
inefficient due to the significantly longer input sequences introduced by
multimodal data and the low utilization of inter-layer computations. To address
this challenge, we shift the focus to the training process itself and propose a
novel training-efficient framework based on sparse representations, termed the
Sparse Training Scheme (STS). This scheme consists of two key components: the
Visual Token Compressor, which reduces the information load by compressing
visual tokens, and the Layer Dynamic Skipper, which mitigates the computational
overhead by dynamically skipping unnecessary layers in the language model
during both forward and backward passes. Our approach is broadly applicable to
diverse MLLM architectures and has been extensively evaluated on multiple
benchmarks, demonstrating its effectiveness and efficiency.

</details>


### [238] [HyperNAS: Enhancing Architecture Representation for NAS Predictor via Hypernetwork](https://arxiv.org/abs/2509.18151)
*Jindi Lv,Yuhao Zhou,Yuxin Tian,Qing Ye,Wentao Feng,Jiancheng Lv*

Main category: cs.LG

TL;DR: HyperNAS通过全局编码方案和共享超网络来学习架构表示，以提高神经架构搜索中的性能评估效率和泛化能力，并在少样本场景下取得了最先进的成果。


<details>
  <summary>Details</summary>
Motivation: 现有的神经架构搜索（NAS）中的性能评估耗时过长，阻碍了研究进展。虽然神经预测器可以作为代理模型加速评估，但它们由于难以捕捉架构间的复杂关系而泛化能力较差。

Method: 提出了一种名为HyperNAS的新型神经预测器范式，包含全局编码方案（用于捕捉宏观结构信息）和共享超网络（用于增强跨架构模式的学习）。此外，还开发了一种动态自适应多任务损失来稳定训练并实现Pareto前沿的个性化探索。

Result: 在包括ViTs在内的五个代表性搜索空间上进行了广泛的实验。结果表明，HyperNAS在少样本场景下表现出显著优势，在CIFAR-10上达到了97.60%的准确率，在ImageNet上达到了82.4%的准确率，样本量减少了至少5倍。

Conclusion: HyperNAS通过改进架构表示学习，有效地解决了NAS中性能评估的挑战，尤其在数据有限的情况下，能够以更少的样本获得优越的性能。

Abstract: Time-intensive performance evaluations significantly impede progress in
Neural Architecture Search (NAS). To address this, neural predictors leverage
surrogate models trained on proxy datasets, allowing for direct performance
predictions for new architectures. However, these predictors often exhibit poor
generalization due to their limited ability to capture intricate relationships
among various architectures. In this paper, we propose HyperNAS, a novel neural
predictor paradigm for enhancing architecture representation learning. HyperNAS
consists of two primary components: a global encoding scheme and a shared
hypernetwork. The global encoding scheme is devised to capture the
comprehensive macro-structure information, while the shared hypernetwork serves
as an auxiliary task to enhance the investigation of inter-architecture
patterns. To ensure training stability, we further develop a dynamic adaptive
multi-task loss to facilitate personalized exploration on the Pareto front.
Extensive experiments across five representative search spaces, including ViTs,
demonstrate the advantages of HyperNAS, particularly in few-shot scenarios. For
instance, HyperNAS strikes new state-of-the-art results, with 97.60\% top-1
accuracy on CIFAR-10 and 82.4\% top-1 accuracy on ImageNet, using at least
5.0$\times$ fewer samples.

</details>


### [239] [WLFM: A Well-Logs Foundation Model for Multi-Task and Cross-Well Geological Interpretation](https://arxiv.org/abs/2509.18152)
*Zhenyu Qi,Qing Yu,Jichen Wang,Yun-Bo Zhao,Zerui Li,Wenjun Lv*

Main category: cs.LG

TL;DR: WLFM是一个在多曲线测井数据上预训练的基金模型，用于改进地下特征表征。它通过三个阶段：日志分块、自监督预训练和多任务适应，实现了在孔隙度估计和岩性分类上的优于现有方法的性能，并展现出层位意识和可复用词汇等新兴能力。


<details>
  <summary>Details</summary>
Motivation: 测井解释在地下表征中至关重要，但面临工具响应异质性、信号噪声和标签有限的挑战。

Method: WLFM模型包含三个阶段：将测井数据块转换为地质标记（tokenization）、使用掩码标记建模和地层感知对比学习进行自监督预训练，以及通过少样本微调进行多任务适应。

Result: WLFM在孔隙度估计上达到0.0041的均方误差（MSE）和在岩性分类上达到74.13%的准确率，优于现有基线。WLFM-Finetune进一步将MSE提高到0.0038，准确率提高到78.10%。此外，WLFM还表现出层位意识，学习了可复用的地质词汇，并能以合理的保真度重建被掩码的曲线，尽管在浅层和超深层存在系统性偏移。

Conclusion: WLFM是一个可扩展、可解释且可迁移的地质人工智能骨干模型，为整合测井、地震和文本等多模态数据提供了潜力。

Abstract: Well-log interpretation is fundamental for subsurface characterization but
remains challenged by heterogeneous tool responses, noisy signals, and limited
labels. We propose WLFM, a foundation model pretrained on multi-curve logs from
1200 wells, comprising three stages: tokenization of log patches into
geological tokens, self-supervised pretraining with masked-token modeling and
stratigraphy-aware contrastive learning, and multi-task adaptation with
few-shot fine-tuning. WLFM consistently outperforms state-of-the-art baselines,
achieving 0.0041 MSE in porosity estimation and 74.13\% accuracy in lithology
classification, while WLFM-Finetune further improves to 0.0038 MSE and 78.10\%
accuracy. Beyond predictive accuracy, WLFM exhibits emergent layer-awareness,
learns a reusable geological vocabulary, and reconstructs masked curves with
reasonable fidelity, though systematic offsets are observed in shallow and
ultra-deep intervals. Although boundary detection is not explicitly evaluated
here, clustering analyses suggest strong potential for future extension. These
results establish WLFM as a scalable, interpretable, and transferable backbone
for geological AI, with implications for multi-modal integration of logs,
seismic, and textual data.

</details>


### [240] [A deep reinforcement learning platform for antibiotic discovery](https://arxiv.org/abs/2509.18153)
*Hanqun Cao,Marcelo D. T. Torres,Jingjie Zhang,Zijun Gao,Fang Wu,Chunbin Gu,Jure Leskovec,Yejin Choi,Cesar de la Fuente-Nunez,Guangyong Chen,Pheng-Ann Heng*

Main category: cs.LG

TL;DR: ApexAmphion是一个深度学习框架，用于从头设计抗生素，通过结合大型蛋白质语言模型和强化学习，实现了快速、多样化和有效的抗生素发现。


<details>
  <summary>Details</summary>
Motivation: 抗生素耐药性（AMR）预计到2050年将导致每年高达1000万人死亡，因此迫切需要新的抗生素。

Method: 该框架首先在精选的肽数据上进行微调，以捕捉抗菌序列的规律性，然后通过近端策略优化进行优化，结合了学习到的最低抑菌浓度（MIC）分类器的预测和可微分的理化目标。

Result: 在体外对100种设计的肽进行了评估，所有候选肽均显示出低MIC值（某些情况下的纳摩尔范围），命中率为100%。其中99种肽对至少两种临床相关细菌表现出广谱抗菌活性，主要通过靶向细胞质膜来杀灭细菌。

Conclusion: 通过将生成、评分和多目标优化与深度强化学习统一在单个流程中，该方法能在数小时内快速生成多样化、有效的候选药物，为肽类抗生素的发现提供了可扩展的途径，并可用于迭代优化以提高药效和可开发性。

Abstract: Antimicrobial resistance (AMR) is projected to cause up to 10 million deaths
annually by 2050, underscoring the urgent need for new antibiotics. Here we
present ApexAmphion, a deep-learning framework for de novo design of
antibiotics that couples a 6.4-billion-parameter protein language model with
reinforcement learning. The model is first fine-tuned on curated peptide data
to capture antimicrobial sequence regularities, then optimised with proximal
policy optimization against a composite reward that combines predictions from a
learned minimum inhibitory concentration (MIC) classifier with differentiable
physicochemical objectives. In vitro evaluation of 100 designed peptides showed
low MIC values (nanomolar range in some cases) for all candidates (100% hit
rate). Moreover, 99 our of 100 compounds exhibited broad-spectrum antimicrobial
activity against at least two clinically relevant bacteria. The lead molecules
killed bacteria primarily by potently targeting the cytoplasmic membrane. By
unifying generation, scoring and multi-objective optimization with deep
reinforcement learning in a single pipeline, our approach rapidly produces
diverse, potent candidates, offering a scalable route to peptide antibiotics
and a platform for iterative steering toward potency and developability within
hours.

</details>


### [241] [MiniCPM-V 4.5: Cooking Efficient MLLMs via Architecture, Data, and Training Recipe](https://arxiv.org/abs/2509.18154)
*Tianyu Yu,Zefan Wang,Chongyi Wang,Fuwei Huang,Wenshuo Ma,Zhihui He,Tianchi Cai,Weize Chen,Yuxiang Huang,Yuanqian Zhao,Bokai Xu,Junbo Cui,Yingjing Xu,Liqing Ruan,Luoyuan Zhang,Hanyu Liu,Jingkun Tang,Hongyuan Liu,Qining Guo,Wenhao Hu,Bingxiang He,Jie Zhou,Jie Cai,Ji Qi,Zonghao Guo,Chi Chen,Guoyang Zeng,Yuxuan Li,Ganqu Cui,Ning Ding,Xu Han,Yuan Yao,Zhiyuan Liu,Maosong Sun*

Main category: cs.LG

TL;DR: MiniCPM-V 4.5是一个高效且性能强大的80亿参数多模态大模型，通过改进模型架构、数据策略和训练方法，在各种基准测试中超越了同类模型，同时显著降低了计算资源消耗。


<details>
  <summary>Details</summary>
Motivation: 多模态大模型（MLLMs）的训练和推理效率低下是其可访问性和可扩展性的主要瓶颈。

Method: 提出MiniCPM-V 4.5，一个80亿参数的模型，采用了统一的3D-Resampler模型架构、统一的学习范式以及混合强化学习策略。

Result: MiniCPM-V 4.5在OpenCompass评估中表现优于GPT-4o-latest和Qwen2.5-VL 72B等模型。在VideoMME基准测试中，其GPU内存消耗和推理时间仅分别为Qwen2.5-VL 7B的46.7%和8.7%。

Conclusion: MiniCPM-V 4.5在保持强大性能的同时，实现了显著的效率提升，为多模态大模型的发展提供了高效解决方案。

Abstract: Multimodal Large Language Models (MLLMs) are undergoing rapid progress and
represent the frontier of AI development. However, their training and inference
efficiency have emerged as a core bottleneck in making MLLMs more accessible
and scalable. To address the challenges, we present MiniCPM-V 4.5, an 8B
parameter model designed for high efficiency and strong performance. We
introduce three core improvements in model architecture, data strategy and
training method: a unified 3D-Resampler model architecture for highly compact
encoding over images and videos, a unified learning paradigm for document
knowledge and text recognition without heavy data engineering, and a hybrid
reinforcement learning strategy for proficiency in both short and long
reasoning modes. Comprehensive experimental results in OpenCompass evaluation
show that MiniCPM-V 4.5 surpasses widely used proprietary models such as
GPT-4o-latest, and significantly larger open-source models such as Qwen2.5-VL
72B. Notably, the strong performance is achieved with remarkable efficiency.
For example, on the widely adopted VideoMME benchmark, MiniCPM-V 4.5 achieves
state-of-the-art performance among models under 30B size, using just 46.7\% GPU
memory cost and 8.7\% inference time of Qwen2.5-VL 7B.

</details>


### [242] [Developing Training Procedures for Piecewise-linear Spline Activation Functions in Neural Networks](https://arxiv.org/abs/2509.18161)
*William H Patty*

Main category: cs.LG

TL;DR: 通过优化神经网络的激活函数形状，可以提高模型的参数效率和准确性。


<details>
  <summary>Details</summary>
Motivation: 传统的静态激活函数（如ReLU、tanh、sigmoid）是经验性选择的，但通过优化激活函数的形状，可以为神经元分配更优的激活值，从而提高模型性能。

Method: 提出并比较了9种训练方法，探索了参数化线性B样条激活函数的双重优化动态。

Result: 与传统的ReLU模型相比，在全连接网络（FNNs）中实现了高达94%的最终模型误差率降低，在卷积神经网络（CNNs）中实现了51%的误差率降低。

Conclusion: 优化激活函数的形状可以显著提高模型的准确性，但会增加开发和训练的复杂性以及最终模型的延迟。

Abstract: Activation functions in neural networks are typically selected from a set of
empirically validated, commonly used static functions such as ReLU, tanh, or
sigmoid. However, by optimizing the shapes of a network's activation functions,
we can train models that are more parameter-efficient and accurate by assigning
more optimal activations to the neurons. In this paper, I present and compare 9
training methodologies to explore dual-optimization dynamics in neural networks
with parameterized linear B-spline activation functions. The experiments
realize up to 94% lower end model error rates in FNNs and 51% lower rates in
CNNs compared to traditional ReLU-based models. These gains come at the cost of
additional development and training complexity as well as end model latency.

</details>


### [243] [A Simple and Reproducible Hybrid Solver for a Truck-Drone VRP with Recharge](https://arxiv.org/abs/2509.18162)
*Meraryslan Meraliyev,Cemil Turan,Shirali Kadyrov*

Main category: cs.LG

TL;DR: 该研究提出了一种混合强化学习（RL）求解器，用于解决配备电池管理的最后一英里配送问题，其中一辆卡车和一架无人机协同工作。该求解器结合了基于ALNS的卡车路径规划和基于指针/注意力机制的无人机出击调度。


<details>
  <summary>Details</summary>
Motivation: 研究动机是解决最后一英里配送问题，特别是在考虑电池管理、无人机速度、续航里程和充电策略的情况下，优化卡车和无人机的协同配送效率。

Method: 采用混合强化学习（RL）方法，结合了带有2/3-opt和Or-opt的ALNS算法进行卡车路径规划，以及一个指针/注意力策略来调度无人机出击。该策略能够解码发射-服务-会合三元组，并考虑续航和充电的可行性约束。使用精确的时间线模拟器来强制执行发射/回收处理并计算总时间。

Result: 在欧几里得实例（N=50, E=0.7, R=0.1）上，该方法实现的平均总时间为5.203±0.093，相比之下，仅使用ALNS的为5.349±0.038，仅使用NN的为5.208±0.124。RL求解器比ALNS平均快2.73%，并且在接近NN的性能。

Conclusion: RL求解器在每次实验中表现不逊于ALNS，并且在三分之二的实验中表现优于或等于NN。通过对总时间的分解分析，揭示了卡车等待时间和无人机任务时间之间的权衡关系，RL调度器能够有效地平衡这两者以最小化总完成时间。

Abstract: We study last-mile delivery with one truck and one drone under explicit
battery management: the drone flies at twice the truck speed; each sortie must
satisfy an endurance budget; after every delivery the drone recharges on the
truck before the next launch. We introduce a hybrid reinforcement learning (RL)
solver that couples an ALNS-based truck tour (with 2/3-opt and Or-opt) with a
small pointer/attention policy that schedules drone sorties. The policy decodes
launch--serve--rendezvous triplets with hard feasibility masks for endurance
and post-delivery recharge; a fast, exact timeline simulator enforces
launch/recovery handling and computes the true makespan used by masked
greedy/beam decoding. On Euclidean instances with $N{=}50$, $E{=}0.7$, and
$R{=}0.1$, the method achieves an average makespan of \textbf{5.203}$\pm$0.093,
versus \textbf{5.349}$\pm$0.038 for ALNS and \textbf{5.208}$\pm$0.124 for NN --
i.e., \textbf{2.73\%} better than ALNS on average and within \textbf{0.10\%} of
NN. Per-seed, the RL scheduler never underperforms ALNS on the same instance
and ties or beats NN on two of three seeds. A decomposition of the makespan
shows the expected truck--wait trade-off across heuristics; the learned
scheduler balances both to minimize the total completion time. We provide a
config-first implementation with plotting and significance-test utilities to
support replication.

</details>


### [244] [Physics-informed time series analysis with Kolmogorov-Arnold Networks under Ehrenfest constraints](https://arxiv.org/abs/2509.18483)
*Abhijit Sen,Illya V. Lukin,Kurt Jacobs,Lev Kaplan,Andrii G. Sotnikov,Denys I. Bondar*

Main category: cs.LG

TL;DR: KANs结合物理信息损失函数在量子动力学预测方面表现优于传统模型，数据需求更少。


<details>
  <summary>Details</summary>
Motivation: 量子系统的时变行为建模因高维希尔伯特空间而面临计算挑战，现有神经网络方法需要大量数据且易出现伪振荡。

Method: 提出一种新的方法，使用结合物理信息损失函数的Kolmogorov Arnold Networks (KANs)，强制执行Ehrenfest定理，并引入了Chain of KANs架构。

Result: KANs仅需5.4%的训练数据（200个样本）即可达到比Temporal Convolution Networks（3700个样本）更高的精度。

Conclusion: 物理信息KANs在保持数学严谨性和物理一致性的同时，显著降低了数据需求，为量子动力学预测提供了一种有力的替代方案。

Abstract: The prediction of quantum dynamical responses lies at the heart of modern
physics. Yet, modeling these time-dependent behaviors remains a formidable
challenge because quantum systems evolve in high-dimensional Hilbert spaces,
often rendering traditional numerical methods computationally prohibitive.
While large language models have achieved remarkable success in sequential
prediction, quantum dynamics presents a fundamentally different challenge:
forecasting the entire temporal evolution of quantum systems rather than merely
the next element in a sequence. Existing neural architectures such as recurrent
and convolutional networks often require vast training datasets and suffer from
spurious oscillations that compromise physical interpretability. In this work,
we introduce a fundamentally new approach: Kolmogorov Arnold Networks (KANs)
augmented with physics-informed loss functions that enforce the Ehrenfest
theorems. Our method achieves superior accuracy with significantly less
training data: it requires only 5.4 percent of the samples (200) compared to
Temporal Convolution Networks (3,700). We further introduce the Chain of KANs,
a novel architecture that embeds temporal causality directly into the model
design, making it particularly well-suited for time series modeling. Our
results demonstrate that physics-informed KANs offer a compelling advantage
over conventional black-box models, maintaining both mathematical rigor and
physical consistency while dramatically reducing data requirements.

</details>


### [245] [DSFT: Inspiring Diffusion Large Language Models to Comprehend Mathematical and Logical Patterns](https://arxiv.org/abs/2509.18164)
*Ranfei Chen,Ming Chen*

Main category: cs.LG

TL;DR: DSFT是一种通过调整掩码策略和损失函数来增强扩散大语言模型（dLLM）在数学和逻辑任务上表现的策略，能在小规模数据上实现5-10%的数学能力和约2%的逻辑能力提升。


<details>
  <summary>Details</summary>
Motivation: 现有的dLLM训练方法主要关注通用知识和推理能力，但在处理数值敏感的数学和顺序敏感的逻辑任务方面存在挑战。

Method: 提出DSFT（Diffusion SFT）策略，通过调整掩码策略和损失函数来引导模型学习数学和逻辑模式，并可灵活组合其他训练方法。

Result: 在LLaDA和Dream系列模型上验证，DSFT在数学和逻辑问题上分别实现了5-10%和约2%的提升。

Conclusion: DSFT是一种简单有效的策略，能够显著提升dLLM在数学和逻辑任务上的表现，为未来特定模式学习提供了有价值的见解。

Abstract: Diffusion large language models (dLLMs) have emerged as a new architecture
following auto regressive models. Their denoising process offers a powerful
generative advantage, but they present significant challenges in learning and
understanding numerically sensitive mathematical and order-sensitive logical
tasks. Current training methods, including pre-training, fine-tuning, and
reinforcement learning, focus primarily on improving general knowledge
retention and reasoning abilities, but lack a comprehensive understanding of
mathematical and logical patterns. We propose DSFT, a simple yet effective
Diffusion SFT strategy, by adjusting the masking strategy and loss function,
guiding models to understand mathematical and logical patterns. This strategy
can be flexibly combined with pre-training, reinforcement learning, and other
training methods. Validated on models such as LLaDA and Dream series, we prove
that DSFT on small-scale data can achieve improvements of 5-10% and
approximately 2% on mathematical and logical problems, respectively. This
inspiring masking approach offers insights for future learning of specific
patterns, which can be easily and efficiently combined with other training
methods and applied to various dLLMs. Our code is publicly available at
https://anonymous.4open.science/r/DSFT-0FFB/

</details>


### [246] [MobiGPT: A Foundation Model for Mobile Wireless Networks](https://arxiv.org/abs/2509.18166)
*Xiaoqian Qi,Haoye Chai,Yong Li*

Main category: cs.LG

TL;DR: MobiGPT是一个用于移动数据预测的基础模型，能够统一预测基站流量、用户应用使用情况和信道质量。它通过软提示学习和时间掩码机制，在短期预测、长期预测和分布生成方面表现出色，并在真实数据集上实现了比现有模型更高的准确性和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 未来的移动网络需要准确高效的移动数据预测来监控网络状态、协调资源和优化服务质量，但现有方法依赖定制化模型，增加了复杂性和成本。

Method: 设计了一个名为MobiGPT的基础模型，采用统一结构，支持软提示学习以理解不同数据类型特征，并引入时间掩码机制来处理短期预测、长期预测和分布生成任务。

Result: 在包含超过100,000个样本的真实世界数据集上进行评估，MobiGPT在多类型预测方面实现了高精度，相较于现有模型，在三个预测任务上分别提高了27.37%、20.08%和7.27%的准确性。此外，在未见过的场景下，MobiGPT的零/少样本性能也提高了21.51%。

Conclusion: MobiGPT作为一个基础模型，展现了强大的泛化能力和迁移能力，能够准确高效地进行多类型移动数据预测，并优于现有方法。

Abstract: With the rapid development of mobile communication technologies, future
mobile networks will offer vast services and resources for commuting,
production, daily life, and entertainment. Accurate and efficient forecasting
of mobile data (e.g., cell traffic, user behavior, channel quality) helps
operators monitor network state changes, orchestrate wireless resources, and
schedule infrastructure and users, thereby improving supply efficiency and
service quality. However, current forecasting paradigms rely on customized
designs with tailored models for exclusive data types. Such approaches increase
complexity and deployment costs under large-scale, heterogeneous networks
involving base stations, users, and channels. In this paper, we design a
foundation model for mobile data forecasting, MobiGPT, with a unified structure
capable of forecasting three data types: base station traffic, user app usage,
and channel quality. We propose a soft-prompt learning method to help the model
understand features of different data types, and introduce a temporal masking
mechanism to guide the model through three forecasting tasks: short-term
prediction, long-term prediction, and distribution generation, supporting
diverse optimization scenarios. Evaluations on real-world datasets with over
100,000 samples show that MobiGPT achieves accurate multi-type forecasting.
Compared to existing models, it improves forecasting accuracy by 27.37%,
20.08%, and 7.27%, reflecting strong generalization. Moreover, MobiGPT exhibits
superior zero/few-shot performance in unseen scenarios, with over 21.51%
improvement, validating its strong transferability as a foundation model.

</details>


### [247] [PiMoE: Token-Level Routing for Integrating High-Precision Computation and Reasoning](https://arxiv.org/abs/2509.18169)
*Hengbo Xiao,Jingyuan Fan,Xin Tong,Jingzhao Zhang,Chao Lu,Guannan He*

Main category: cs.LG

TL;DR: PiMoE是一种结合计算和推理的新型LLM架构，通过token级别的路由实现迭代式计算，在准确性、响应延迟、token使用量和GPU能耗方面优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有的大型语言模型（LLMs）缺乏整合高精度数值计算的能力，而多智能体方法存在通信开销大、可扩展性有限等问题。因此，需要一种新的架构来融合计算和推理。

Method: 提出PiMoE（Physically-isolated Mixture of Experts）架构，该架构在单独训练experts、文本到计算模块和路由器后，将计算能力内源性地集成到神经网络中。在推理时，路由器在token级别进行计算和推理的路由，实现单次思维链中的迭代交替。

Result: 在两个推理-计算任务上，PiMoE架构的准确性优于直接微调LLM的方法，并且在响应延迟、token使用量和GPU能耗方面显著优于主流的多智能体方法。

Conclusion: PiMoE为下一代科学或工业智能系统提供了一种高效、可解释且可扩展的范式。

Abstract: Complex systems typically rely on high-precision numerical computation to
support decisions, but current large language models (LLMs) cannot yet
incorporate such computations as an intrinsic and interpretable capability with
existing architectures. Mainstream multi-agent approaches can leverage external
experts, but inevitably introduce communication overhead and suffer from
inefficient multimodal emergent capability and limited scalability. To this
end, we propose PiMoE (Physically-isolated Mixture of Experts), a training and
inference architecture for integrating computation and reasoning. Instead of
the workflow paradigm of tool invocation, PiMoE endogenously integrates
computational capabilities into neural networks after separately training
experts, a text-to-computation module, and a router. At inference, the router
directs computation and reasoning at the token level, thereby enabling
iterative alternation within a single chain of thought. We evaluate PiMoE on
two reasoning-computation tasks against LLM finetuning and the multi-agent
system approaches. Results show that the PiMoE architecture achieves not only
higher accuracy than directly finetuning LLMs but also significant improvements
in response latency, token usage, and GPU energy consumption compared with
mainstream multi-agent approaches. PiMoE offers an efficient, interpretable,
and scalable paradigm for next-generation scientific or industrial intelligent
systems.

</details>


### [248] [FedIA: A Plug-and-Play Importance-Aware Gradient Pruning Aggregation Method for Domain-Robust Federated Graph Learning on Node Classification](https://arxiv.org/abs/2509.18171)
*Zhanting Zhou,KaHou Tam,Zeqin Wu,Pengzhao Sun,Jinbo Wang,Fengli Zhang*

Main category: cs.LG

TL;DR: FedIA框架通过在聚合前进行去噪来解决联邦图学习中的域偏移问题，提高了模型表示的兼容性、稳定性和最终准确性。


<details>
  <summary>Details</summary>
Motivation: 在Twitch Gamers和多语言Wikipedia等平台上的联邦图学习（FGL）中，域偏移会导致客户端模型产生不兼容的表示，使得朴素聚合不稳定且无效。

Method: 提出FedIA框架，采用“先投影，后聚合”的策略。具体包括：1. 服务器端使用Top-ρ（约5%）掩码保留最具信息量的坐标；2. 使用轻量级影响正则化动量权重抑制异常值客户端。该框架不增加额外的上行流量，服务器内存开销可忽略。

Result: 在同构（Twitch Gamers）和异构（Wikipedia）图上，FedIA的收敛更平稳、更稳定，并且最终准确性优于九种强基线方法。收敛分析表明，动态投影可以维持最优的O(σ^2/√T)收敛率。

Conclusion: FedIA通过在聚合前对客户端更新进行去噪，有效解决了联邦图学习中的域偏移问题，提高了模型性能和训练稳定性。

Abstract: Federated Graph Learning (FGL) under domain skew -- as observed on platforms
such as \emph{Twitch Gamers} and multilingual \emph{Wikipedia} networks --
drives client models toward incompatible representations, rendering naive
aggregation both unstable and ineffective. We find that the culprit is not the
weighting scheme but the \emph{noisy gradient signal}: empirical analysis of
baseline methods suggests that a vast majority of gradient dimensions can be
dominated by domain-specific variance. We therefore shift focus from
"aggregation-first" to a \emph{projection-first} strategy that denoises client
updates \emph{before} they are combined. The proposed FedIA framework realises
this \underline{I}mportance-\underline{A}ware idea through a two-stage,
plug-and-play pipeline: (i) a server-side top-$\rho$ mask keeps only the most
informative about 5% of coordinates, and (ii) a lightweight
influence-regularised momentum weight suppresses outlier clients. FedIA adds
\emph{no extra uplink traffic and only negligible server memory}, making it
readily deployable. On both homogeneous (Twitch Gamers) and heterogeneous
(Wikipedia) graphs, it yields smoother, more stable convergence and higher
final accuracy than nine strong baselines. A convergence sketch further shows
that dynamic projection maintains the optimal
$\mathcal{O}(\sigma^{2}/\sqrt{T})$ rate.

</details>


### [249] [SBVR: Summation of BitVector Representation for Efficient LLM Quantization](https://arxiv.org/abs/2509.18172)
*Wonjun Bang,Jongseok Park,Hongseung Yu,Kyungmin Bin,Kyunghan Lee*

Main category: cs.LG

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: With the advent of large language models (LLMs), numerous Post-Training
Quantization (PTQ) strategies have been proposed to alleviate deployment
barriers created by their enormous parameter counts. Quantization achieves
compression by limiting the number of representable points in the data.
Therefore, the key to achieving efficient quantization is selecting the optimal
combination of representation points, or codes, for the given data. Existing
PTQ solutions adopt two major approaches to this problem: Round-To-Nearest
(RTN)-based methods and codebook-based methods. RTN-based methods map LLM
weights onto uniformly distributed integer grids, failing to account for the
Gaussian-like weight distribution of LLM weights. Codebook-based methods
mitigate this issue by constructing distribution-aware codebooks; however, they
suffer from random and strided memory access patterns, resulting in degraded
inference speed that is exacerbated by the limited size of GPU L1 cache. To
overcome these limitations, we propose a novel LLM quantization method, SBVR
(Summation of BitVector Representation), that enables Gaussian-like code
representation in a hardware-friendly manner for fast inference. SBVR maps
weight values to non-uniform representation points whose distribution follows
the actual distribution of LLM weights, enabling more accurate compression.
Additionally, we design a custom CUDA kernel that allows matrix-vector
multiplication directly in the SBVR format without decompression, thereby
enabling high-performance execution of SBVR-compressed models. Our evaluations
of SBVR on various models demonstrate state-of-the-art perplexity and accuracy
benchmark performance while delivering a 2.21x- 3.04x end-to-end
token-generation speedup over naive FP16 models in the 4-bit quantization
regime.

</details>


### [250] [TurnBack: A Geospatial Route Cognition Benchmark for Large Language Models through Reverse Route](https://arxiv.org/abs/2509.18173)
*Hongyi Luo,Qing Cheng,Daniel Matos,Hari Krishna Gadi,Yanfeng Zhang,Lu Liu,Yongliang Wang,Niclas Zeller,Daniel Cremers,Liqiu Meng*

Main category: cs.LG

TL;DR: LLMs在地理空间路线理解方面存在局限性，尤其是在路线反转任务上，并且在生成正确路线方面鲁棒性不足。


<details>
  <summary>Details</summary>
Motivation: 现有研究对LLM的地理空间认知能力探索不足，受限于不可量化的指标、有限的评估数据集和不明确的研究层次。

Method: 构建了一个包含36000条路线的大型评估数据集，开发了PathBuilder工具用于自然语言与导航路线之间的转换，并提出了新的评估框架和指标来评估11种最先进的LLM在路线反转任务上的表现。

Result: LLMs在路线反转任务上表现出局限性，大多数反转后的路线未能回到起点或与最优路线相似。此外，LLMs在路线生成方面鲁棒性低，并且对其错误答案的置信度高。

Conclusion: LLMs在处理地理空间路线信息，特别是路线反转任务时，能力有限，需要进一步改进。

Abstract: Humans can interpret geospatial information through natural language, while
the geospatial cognition capabilities of Large Language Models (LLMs) remain
underexplored. Prior research in this domain has been constrained by
non-quantifiable metrics, limited evaluation datasets and unclear research
hierarchies. Therefore, we propose a large-scale benchmark and conduct a
comprehensive evaluation of the geospatial route cognition of LLMs. We create a
large-scale evaluation dataset comprised of 36000 routes from 12 metropolises
worldwide. Then, we introduce PathBuilder, a novel tool for converting natural
language instructions into navigation routes, and vice versa, bridging the gap
between geospatial information and natural language. Finally, we propose a new
evaluation framework and metrics to rigorously assess 11 state-of-the-art
(SOTA) LLMs on the task of route reversal. The benchmark reveals that LLMs
exhibit limitation to reverse routes: most reverse routes neither return to the
starting point nor are similar to the optimal route. Additionally, LLMs face
challenges such as low robustness in route generation and high confidence for
their incorrect answers. Code\ \&\ Data available here:
\href{https://github.com/bghjmn32/EMNLP2025_Turnback}{TurnBack.}

</details>


### [251] [Conversational Orientation Reasoning: Egocentric-to-Allocentric Navigation with Multimodal Chain-of-Thought](https://arxiv.org/abs/2509.18200)
*Yu Ti Huang*

Main category: cs.LG

TL;DR: 本研究提出了一种名为COR的新基准和MCoT框架，用于解决中文对话导航中的单角度到绝对角度空间推理问题，特别是在GPS信号弱和缺乏详细地图的室内环境中。


<details>
  <summary>Details</summary>
Motivation: 在室内或复杂设施中，对话代理需要将单角度表述（例如“在我右边”）转换为绝对方向（东/南/西/北）。然而，在GPS信号弱和缺乏详细地图的环境中，这种单角度到绝对角度的空间推理仍然是一个挑战。虽然思维链（CoT）提示在语言和视觉任务中取得了进展，但其在多模态空间定向方面的应用仍有待探索。

Method: 提出了一种名为COR（Conversational Orientation Reasoning）的新基准，用于处理传统中文对话导航的单角度到绝对角度推理问题。同时，提出了一种多模态思维链（MCoT）框架，该框架通过一个结构化的三步推理过程整合了自动语音识别（ASR）转录的语音和地标坐标：1. 提取空间关系；2. 将坐标映射到绝对方向；3. 推断用户方向。并采用课程学习策略在Taiwan-LLM-13B-v2.0-Chat模型上逐步构建这些能力。

Result: MCoT在干净转录上实现了100%的定向准确率，在ASR转录上达到了98.1%，显著优于单模态和非结构化基线。MCoT在嘈杂的对话条件下（包括ASR识别错误和多语言混合切换）表现出鲁棒性，并在跨领域评估中保持了高准确率，对语言变化、领域转移和指代歧义具有弹性。

Conclusion: 结构化的多模态思维链（MCoT）在空间推理方面具有巨大潜力，为实现可解释且资源高效的具身导航提供了途径。MCoT在处理非英语、ASR转录以及资源受限的情况下，能够有效地进行单角度到绝对角度的空间推理。

Abstract: Conversational agents must translate egocentric utterances (e.g., "on my
right") into allocentric orientations (N/E/S/W). This challenge is particularly
critical in indoor or complex facilities where GPS signals are weak and
detailed maps are unavailable. While chain-of-thought (CoT) prompting has
advanced reasoning in language and vision tasks, its application to multimodal
spatial orientation remains underexplored. We introduce Conversational
Orientation Reasoning (COR), a new benchmark designed for Traditional Chinese
conversational navigation projected from real-world environments, addressing
egocentric-to-allocentric reasoning in non-English and ASR-transcribed
scenarios. We propose a multimodal chain-of-thought (MCoT) framework, which
integrates ASR-transcribed speech with landmark coordinates through a
structured three-step reasoning process: (1) extracting spatial relations, (2)
mapping coordinates to absolute directions, and (3) inferring user orientation.
A curriculum learning strategy progressively builds these capabilities on
Taiwan-LLM-13B-v2.0-Chat, a mid-sized model representative of
resource-constrained settings. Experiments show that MCoT achieves 100%
orientation accuracy on clean transcripts and 98.1% with ASR transcripts,
substantially outperforming unimodal and non-structured baselines. Moreover,
MCoT demonstrates robustness under noisy conversational conditions, including
ASR recognition errors and multilingual code-switching. The model also
maintains high accuracy in cross-domain evaluation and resilience to linguistic
variation, domain shift, and referential ambiguity. These findings highlight
the potential of structured MCoT spatial reasoning as a path toward
interpretable and resource-efficient embodied navigation.

</details>


### [252] [Variational Task Vector Composition](https://arxiv.org/abs/2509.18208)
*Boyuan Zhang,Yingjun Du,Xiantong Zhen,Ling Shao*

Main category: cs.LG

TL;DR: 任务向量的贝叶斯推断和稀疏化方法。


<details>
  <summary>Details</summary>
Motivation: 已有任务向量组合方法在处理多任务时存在局限，需要更有效、可解释的方法。

Method: 提出变分任务向量组合，将组合系数作为潜在变量，并使用Spike-and-Slab先验实现稀疏化，同时引入门控采样机制提高稳定性和可解释性。

Result: 在所有数据集上均优于现有方法，通过选择性利用任务向量中最可靠、最具信息量的成分。

Conclusion: 提出的变分任务向量组合方法在效率和效果上均能满足实际需求，并为任务向量组合设定了新的标准。

Abstract: Task vectors capture how a model changes during fine-tuning by recording the
difference between pre-trained and task-specific weights. The composition of
task vectors, a key operator in task arithmetic, enables models to integrate
knowledge from multiple tasks without incurring additional inference costs. In
this paper, we propose variational task vector composition, where composition
coefficients are taken as latent variables and estimated in a Bayesian
inference framework. Unlike previous methods that operate at the task level,
our framework focuses on sample-specific composition. Motivated by the
observation of structural redundancy in task vectors, we introduce a
Spike-and-Slab prior that promotes sparsity and preserves only the most
informative components. To further address the high variance and sampling
inefficiency in sparse, high-dimensional spaces, we develop a gated sampling
mechanism that constructs a controllable posterior by filtering the composition
coefficients based on both uncertainty and importance. This yields a more
stable and interpretable variational framework by deterministically selecting
reliable task components, reducing sampling variance while improving
transparency and generalization. Experimental results demonstrate that our
method consistently outperforms existing approaches across all datasets by
selectively leveraging the most reliable and informative components in task
vectors. These findings highlight the practical value of our approach,
establishing a new standard for efficient and effective task vector
composition.

</details>


### [253] [MolPILE - large-scale, diverse dataset for molecular representation learning](https://arxiv.org/abs/2509.18353)
*Jakub Adamczyk,Jakub Poziemski,Franciszek Job,Mateusz Król,Maciej Makowski*

Main category: cs.LG

TL;DR: MolPILE是一个包含2.22亿个化合物的大规模、多样化且经过严格筛选的分子数据集，旨在解决现有小型分子数据集在化学信息学中表示学习方面的局限性。


<details>
  <summary>Details</summary>
Motivation: 现有的小分子数据集规模、多样性和质量有限，阻碍了分子表示学习在化学信息学中的应用和基础模型的泛化能力。

Method: 通过一个自动化的处理流程，整合了6个大规模数据库，构建了一个包含2.22亿个化合物的数据集，并对其进行了全面的分析。

Result: 在MolPILE数据集上重新训练现有模型可以提高模型的泛化性能，证明了该数据集的有效性。

Conclusion: MolPILE提供了一个标准化的资源，解决了化学领域对类似ImageNet的大规模数据集的需求，为基础模型的训练提供了支持。

Abstract: The size, diversity, and quality of pretraining datasets critically determine
the generalization ability of foundation models. Despite their growing
importance in chemoinformatics, the effectiveness of molecular representation
learning has been hindered by limitations in existing small molecule datasets.
To address this gap, we present MolPILE, large-scale, diverse, and rigorously
curated collection of 222 million compounds, constructed from 6 large-scale
databases using an automated curation pipeline. We present a comprehensive
analysis of current pretraining datasets, highlighting considerable
shortcomings for training ML models, and demonstrate how retraining existing
models on MolPILE yields improvements in generalization performance. This work
provides a standardized resource for model training, addressing the pressing
need for an ImageNet-like dataset in molecular chemistry.

</details>


### [254] [FastMTP: Accelerating LLM Inference with Enhanced Multi-Token Prediction](https://arxiv.org/abs/2509.18362)
*Yuxuan Cai,Xiaozhuan Liang,Xinghua Wang,Jin Ma,Haijin Liang,Jinwen Luo,Xinyu Zuo,Lisheng Duan,Yuyang Yin,Xi Chen*

Main category: cs.LG

TL;DR: FastMTP通过对MTP头进行微调，使其与推理模式对齐，从而提高多步草稿质量，显著提升了投机解码性能，实现了2.03倍的平均加速，且输出质量无损。


<details>
  <summary>Details</summary>
Motivation: 自回归生成在大型语言模型（LLM）的推理过程中存在吞吐量瓶颈，而多令牌预测（MTP）在提高推理速度方面的潜力尚未得到充分探索。

Method: FastMTP通过对MTP头进行微调，使其与推理模式对齐，并采用位置共享权重在自蒸馏数据上进行训练，以捕捉连续未来令牌之间的依赖关系。此外，还集成了语言感知动态词汇压缩技术来降低计算开销。

Result: FastMTP在七个基准测试中实现了平均2.03倍的加速，输出质量无损，比标准的MTP方法提高了82%。

Conclusion: FastMTP是一种实用且易于部署的解决方案，通过轻量级训练和与现有推理框架的无缝集成，有效解决了LLM推理速度慢的问题。

Abstract: As large language models (LLMs) become increasingly powerful, the sequential
nature of autoregressive generation creates a fundamental throughput bottleneck
that limits the practical deployment. While Multi-Token Prediction (MTP) has
demonstrated remarkable benefits for model training efficiency and performance,
its inherent potential for inference acceleration remains largely unexplored.
This paper introduces FastMTP, a simple yet effective method that improves
multi-step draft quality by aligning MTP training with its inference pattern,
significantly enhancing speculative decoding performance. Our approach
fine-tunes a single MTP head with position-shared weights on self-distilled
data, enabling it to capture dependencies among consecutive future tokens and
maintain high acceptance rates across multiple recursive draft steps. By
integrating language-aware dynamic vocabulary compression into the MTP head, we
further reduce computational overhead in the drafting process. Experimental
results across seven diverse benchmarks demonstrate that FastMTP achieves an
average of 2.03x speedup compared to standard next token prediction with
lossless output quality, outperforming vanilla MTP by 82%. FastMTP requires
only lightweight training and seamlessly integrates with existing inference
frameworks, offering a practical and rapidly deployable solution for
accelerating LLM inference.

</details>


### [255] [Multi-Worker Selection based Distributed Swarm Learning for Edge IoT with Non-i.i.d. Data](https://arxiv.org/abs/2509.18367)
*Zhuoyu Yao,Yue Wang,Songyang Zhang,Yingshu Li,Zhipeng Cai,Zhi Tian*

Main category: cs.LG

TL;DR: 该论文提出了一种名为M-DSL的新算法，用于解决分布式群体学习（DSL）中由非独立同分布（non-i.i.d.）数据引起的数据异质性挑战，并通过理论分析和实验验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 现有的分布式群体学习（DSL）在边缘物联网领域具有潜力，但面临非独立同分布（non-i.i.d.）数据带来的挑战，导致学习性能下降和训练行为不一致。此外，缺乏关于数据异质性如何影响模型训练准确性的理论指导。

Method: 论文首先研究了数据异质性对DSL框架的影响，并提出了一种新的多工作者选择机制，称为M-DSL算法。该算法引入了一个新的非i.i.d.程度度量，用于量化本地数据集之间的统计差异，并将数据异质性的度量与DSL性能评估联系起来。M-DSL通过有效的多工作者选择来更新全局模型，并提供了收敛行为的理论分析。

Result: 实验结果表明，M-DSL算法在不同的异质数据集和非i.i.d.数据设置下，能够有效提高性能，并增强网络智能，优于现有的基准方法。

Conclusion: M-DSL算法通过有效选择对全局模型更新做出贡献的工作者，解决了DSL中数据异质性带来的挑战，并在理论和实验上证明了其在提高模型准确性和网络智能方面的有效性。

Abstract: Recent advances in distributed swarm learning (DSL) offer a promising
paradigm for edge Internet of Things. Such advancements enhance data privacy,
communication efficiency, energy saving, and model scalability. However, the
presence of non-independent and identically distributed (non-i.i.d.) data pose
a significant challenge for multi-access edge computing, degrading learning
performance and diverging training behavior of vanilla DSL. Further, there
still lacks theoretical guidance on how data heterogeneity affects model
training accuracy, which requires thorough investigation. To fill the gap, this
paper first study the data heterogeneity by measuring the impact of non-i.i.d.
datasets under the DSL framework. This then motivates a new multi-worker
selection design for DSL, termed M-DSL algorithm, which works effectively with
distributed heterogeneous data. A new non-i.i.d. degree metric is introduced
and defined in this work to formulate the statistical difference among local
datasets, which builds a connection between the measure of data heterogeneity
and the evaluation of DSL performance. In this way, our M-DSL guides effective
selection of multiple works who make prominent contributions for global model
updates. We also provide theoretical analysis on the convergence behavior of
our M-DSL, followed by extensive experiments on different heterogeneous
datasets and non-i.i.d. data settings. Numerical results verify performance
improvement and network intelligence enhancement provided by our M-DSL beyond
the benchmarks.

</details>


### [256] [Graph Enhanced Trajectory Anomaly Detection](https://arxiv.org/abs/2509.18386)
*Jonathan Kabala Mbuya,Dieter Pfoser,Antonios Anastasopoulos*

Main category: cs.LG

TL;DR: GETAD通过整合路网拓扑、路段语义和历史出行模式，利用图注意力网络和Transformer模型进行轨迹异常检测，并引入CWNLL提高鲁棒性，在真实数据集上表现优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有轨迹异常检测方法仅考虑轨迹的有限方面，忽略了路网等底层网络约束和连通性信息。

Method: GETAD框架整合了路网拓扑、路段语义和历史出行模式。它使用图注意力网络学习路网感知的嵌入，并结合基于图的位置编码。Transformer模型用于模拟序列运动，结合自回归预测和监督链接预测的多目标损失函数。引入了置信加权负对数似然（CWNLL）作为异常评分函数。

Result: GETAD在真实和合成数据集上实现了比现有方法一致的改进，尤其在检测道路约束环境中的细微异常方面表现突出。

Conclusion: 将图结构和上下文语义整合到轨迹建模中有助于实现更精确、更具上下文感知的异常检测。

Abstract: Trajectory anomaly detection is essential for identifying unusual and
unexpected movement patterns in applications ranging from intelligent
transportation systems to urban safety and fraud prevention.
  Existing methods only consider limited aspects of the trajectory nature and
its movement space by treating trajectories as sequences of sampled locations,
with sampling determined by positioning technology, e.g., GPS, or by high-level
abstractions such as staypoints. Trajectories are analyzed in Euclidean space,
neglecting the constraints and connectivity information of the underlying
movement network, e.g., road or transit networks.
  The proposed Graph Enhanced Trajectory Anomaly Detection (GETAD) framework
tightly integrates road network topology, segment semantics, and historical
travel patterns to model trajectory data. GETAD uses a Graph Attention Network
to learn road-aware embeddings that capture both physical attributes and
transition behavior, and augments these with graph-based positional encodings
that reflect the spatial layout of the road network.
  A Transformer-based decoder models sequential movement, while a
multiobjective loss function combining autoregressive prediction and supervised
link prediction ensures realistic and structurally coherent representations.
  To improve the robustness of anomaly detection, we introduce Confidence
Weighted Negative Log Likelihood (CW NLL), an anomaly scoring function that
emphasizes high-confidence deviations.
  Experiments on real-world and synthetic datasets demonstrate that GETAD
achieves consistent improvements over existing methods, particularly in
detecting subtle anomalies in road-constrained environments. These results
highlight the benefits of incorporating graph structure and contextual
semantics into trajectory modeling, enabling more precise and context-aware
anomaly detection.

</details>


### [257] [Towards Provable Emergence of In-Context Reinforcement Learning](https://arxiv.org/abs/2509.18389)
*Jiuqi Wang,Rohan Chandra,Shangtong Zhang*

Main category: cs.LG

TL;DR: RL预训练参数是ICRL现象的关键，本文旨在探讨为何RL预训练能产生支持ICRL的参数，并提出参数是预训练损失的全局最小化器的假设，通过Transformer的案例研究进行初步验证。


<details>
  <summary>Details</summary>
Motivation: 许多ICRL研究使用标准的RL算法进行预训练，但并未解释为何RL预训练能产生支持ICRL的参数，本文旨在解决这一核心问题。

Method: 通过一个案例研究，特别是证明当Transformer为策略评估进行预训练时，预训练损失的全局最小化器之一能够实现上下文中的时序差分学习。

Result: 证明了当Transformer为策略评估进行预训练时，预训练损失的全局最小化器之一能够实现上下文中的时序差分学习。

Conclusion: RL预训练参数之所以能支持ICRL现象，是因为这些参数是预训练损失的全局最小化器。

Abstract: Typically, a modern reinforcement learning (RL) agent solves a task by
updating its neural network parameters to adapt its policy to the task.
Recently, it has been observed that some RL agents can solve a wide range of
new out-of-distribution tasks without parameter updates after pretraining on
some task distribution. When evaluated in a new task, instead of making
parameter updates, the pretrained agent conditions its policy on additional
input called the context, e.g., the agent's interaction history in the new
task. The agent's performance increases as the information in the context
increases, with the agent's parameters fixed. This phenomenon is typically
called in-context RL (ICRL). The pretrained parameters of the agent network
enable the remarkable ICRL phenomenon. However, many ICRL works perform the
pretraining with standard RL algorithms. This raises the central question this
paper aims to address: Why can the RL pretraining algorithm generate network
parameters that enable ICRL? We hypothesize that the parameters capable of ICRL
are minimizers of the pretraining loss. This work provides initial support for
this hypothesis through a case study. In particular, we prove that when a
Transformer is pretrained for policy evaluation, one of the global minimizers
of the pretraining loss can enable in-context temporal difference learning.

</details>


### [258] [Development of Deep Learning Optimizers: Approaches, Concepts, and Update Rules](https://arxiv.org/abs/2509.18396)
*Doğay Altınel*

Main category: cs.LG

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Deep learning optimizers are optimization algorithms that enable deep neural
networks to learn. The effectiveness of learning is highly dependent on the
optimizer employed in the training process. Alongside the rapid advancement of
deep learning, a wide range of optimizers with different approaches have been
developed. This study aims to provide a review of various optimizers that have
been proposed and received attention in the literature. From Stochastic
gradient descent to the most recent ones such as Momentum, AdamW, Sophia, and
Muon in chronological order, optimizers are examined individually, and their
distinctive features are highlighted in the study. The update rule of each
optimizer is presented in detail, with an explanation of the associated
concepts and variables. The techniques applied by these optimizers, their
contributions to the optimization process, and their default hyperparameter
settings are also discussed. In addition, insights are offered into the open
challenges encountered in the optimization of deep learning models. Thus, a
comprehensive resource is provided both for understanding the current state of
optimizers and for identifying potential areas of future development.

</details>


### [259] [Explicit Path CGR: Maintaining Sequence Fidelity in Geometric Representations](https://arxiv.org/abs/2509.18408)
*Sarwan Ali*

Main category: cs.LG

TL;DR: 提出一种名为反向混沌游戏表示（R-CGR）的新信息保持方法，用于生物序列分析，解决了传统CGR丢失序列信息的缺点。


<details>
  <summary>Details</summary>
Motivation: 传统CGR方法在进行几何映射时会丢失序列信息，限制了其在生物序列分析中的应用。

Method: R-CGR方法通过显式路径编码和有理数算术精度控制，实现了完整的序列恢复，能够从存储的几何轨迹中完美重建序列。它通过存储完整的路径信息（包括位置和字符信息）来实现可逆性。

Result: R-CGR在生物序列分类任务上表现出有效性，与传统的基于序列的方法相比，取得了具有竞争力的性能，并能提供可解释的几何可视化。

Conclusion: R-CGR方法通过显式编码保留了完整的序列信息，并生成了适用于深度学习的特征丰富的图像，为生物信息学分析开辟了新的途径，尤其适用于需要准确性和序列可恢复性的场景。

Abstract: We present a novel information-preserving Chaos Game Representation (CGR)
method, also called Reverse-CGR (R-CGR), for biological sequence analysis that
addresses the fundamental limitation of traditional CGR approaches - the loss
of sequence information during geometric mapping. Our method introduces
complete sequence recovery through explicit path encoding combined with
rational arithmetic precision control, enabling perfect sequence reconstruction
from stored geometric traces. Unlike purely geometric approaches, our
reversibility is achieved through comprehensive path storage that maintains
both positional and character information at each step. We demonstrate the
effectiveness of R-CGR on biological sequence classification tasks, achieving
competitive performance compared to traditional sequence-based methods while
providing interpretable geometric visualizations. The approach generates
feature-rich images suitable for deep learning while maintaining complete
sequence information through explicit encoding, opening new avenues for
interpretable bioinformatics analysis where both accuracy and sequence recovery
are essential.

</details>


### [260] [Diffusion Policies with Offline and Inverse Reinforcement Learning for Promoting Physical Activity in Older Adults Using Wearable Sensors](https://arxiv.org/abs/2509.18433)
*Chang Liu,Ladda Thiamwong,Yanjie Fu,Rui Xie*

Main category: cs.LG

TL;DR: KANDI是一种用于医疗保健的离线强化学习方法，它利用Kolmogorov-Arnold网络估计奖励函数，并结合扩散策略进行动作优化，解决了现有方法的挑战，并在临床试验和D4DR基准测试中表现出色。


<details>
  <summary>Details</summary>
Motivation: 现实世界临床数据在医疗保健领域的离线强化学习（RL）应用面临诸多挑战，包括奖励定义困难、逆向强化学习（IRL）难以从专家行为中准确推断奖励函数，以及学习到的策略与人类行为不一致等。本研究旨在解决将离线RL应用于老年人促进体育活动中的问题。

Method: 提出了一种名为KANDI（Kolmogorov-Arnold Networks and Diffusion Policies for Offline Inverse Reinforcement Learning）的新方法。KANDI利用Kolmogorov-Arnold网络的函数逼近能力来估计奖励函数，通过学习低跌倒风险老年人的自由生活环境行为（作为专家）。同时，在Actor-Critic框架内使用基于扩散的策略，为离线RL提供了一种生成式的方法，以实现动作优化和提高效率。

Result: KANDI方法在Physio-feedback Exercise Program (PEER)研究的双臂临床试验中，使用可穿戴活动监测数据进行了评估，证明了其在促进老年人体育活动的跌倒风险干预项目中的实际应用潜力。此外，KANDI在D4RL基准测试中优于最先进的方法。

Conclusion: KANDI在解决离线RL在医疗保健应用中的关键挑战方面显示出巨大潜力，为医疗保健领域的活动促进干预策略提供了一种有效的解决方案。

Abstract: Utilizing offline reinforcement learning (RL) with real-world clinical data
is getting increasing attention in AI for healthcare. However, implementation
poses significant challenges. Defining direct rewards is difficult, and inverse
RL (IRL) struggles to infer accurate reward functions from expert behavior in
complex environments. Offline RL also encounters challenges in aligning learned
policies with observed human behavior in healthcare applications. To address
challenges in applying offline RL to physical activity promotion for older
adults at high risk of falls, based on wearable sensor activity monitoring, we
introduce Kolmogorov-Arnold Networks and Diffusion Policies for Offline Inverse
Reinforcement Learning (KANDI). By leveraging the flexible function
approximation in Kolmogorov-Arnold Networks, we estimate reward functions by
learning free-living environment behavior from low-fall-risk older adults
(experts), while diffusion-based policies within an Actor-Critic framework
provide a generative approach for action refinement and efficiency in offline
RL. We evaluate KANDI using wearable activity monitoring data in a two-arm
clinical trial from our Physio-feedback Exercise Program (PEER) study,
emphasizing its practical application in a fall-risk intervention program to
promote physical activity among older adults. Additionally, KANDI outperforms
state-of-the-art methods on the D4RL benchmark. These results underscore
KANDI's potential to address key challenges in offline RL for healthcare
applications, offering an effective solution for activity promotion
intervention strategies in healthcare.

</details>


### [261] [GluMind: Multimodal Parallel Attention and Knowledge Retention for Robust Cross-Population Blood Glucose Forecasting](https://arxiv.org/abs/2509.18457)
*Ebrahim Farahmand,Reza Rahimi Azghan,Nooshin Taheri Chatrudi,Velarie Yaa Ansu-Baidoo,Eric Kim,Gautham Krishna Gudur,Mohit Malu,Owen Krueger,Edison Thomaz,Giulia Pedrielli,Pavan Turaga,Hassan Ghasemzadeh*

Main category: cs.LG

TL;DR: GluMind是一个基于Transformer的多模态框架，用于持续和长期的血糖预测，通过结合交叉注意力和多尺度注意力机制来整合生理和行为信号，并采用知识保留技术来防止灾难性遗忘，在AIREADI数据集上取得了优于现有模型的性能。


<details>
  <summary>Details</summary>
Motivation: 当前血糖预测模型在处理多源异构数据、捕捉长期依赖性以及持续学习能力方面存在挑战，尤其是在需要整合生理和行为信号进行长期预测的场景下。

Method: 提出了一种名为GluMind的Transformer-based多模态框架，该框架包含两个核心的注意力机制：交叉注意机制（用于整合不同采样率的血糖、活动、压力、心率等信号）和多尺度注意力机制（用于捕捉长期时间依赖性）。此外，还引入了一个知识保留模块来缓解灾难性遗忘，并提升整体预测性能。

Result: 在AIREADI数据集上的实验结果表明，GluMind在血糖预测任务上，与现有最先进的模型相比，均方根误差（RMSE）和平均绝对误差（MAE）分别提高了约15%和9%。模型在引入新的患者队列时，展现了稳定的性能和良好的适应性。

Conclusion: GluMind在持续和长期的血糖预测方面表现出卓越的性能，其多模态融合能力和知识保留机制使其能够有效处理复杂数据并适应持续学习场景，为个性化糖尿病管理提供了有前景的解决方案。

Abstract: This paper proposes GluMind, a transformer-based multimodal framework
designed for continual and long-term blood glucose forecasting. GluMind devises
two attention mechanisms, including cross-attention and multi-scale attention,
which operate in parallel and deliver accurate predictive performance.
Cross-attention effectively integrates blood glucose data with other
physiological and behavioral signals such as activity, stress, and heart rate,
addressing challenges associated with varying sampling rates and their adverse
impacts on robust prediction. Moreover, the multi-scale attention mechanism
captures long-range temporal dependencies. To mitigate catastrophic forgetting,
GluMind incorporates a knowledge retention technique into the transformer-based
forecasting model. The knowledge retention module not only enhances the model's
ability to retain prior knowledge but also boosts its overall forecasting
performance. We evaluate GluMind on the recently released AIREADI dataset,
which contains behavioral and physiological data collected from healthy people,
individuals with prediabetes, and those with type 2 diabetes. We examine the
performance stability and adaptability of GluMind in learning continuously as
new patient cohorts are introduced. Experimental results show that GluMind
consistently outperforms other state-of-the-art forecasting models, achieving
approximately 15% and 9% improvements in root mean squared error (RMSE) and
mean absolute error (MAE), respectively.

</details>


### [262] [Probabilistic Geometric Principal Component Analysis with application to neural data](https://arxiv.org/abs/2509.18469)
*Han-Lin Hsieh,Maryam M. Shanechi*

Main category: cs.LG

TL;DR: PGPCA是一种新的降维算法，适用于存在非线性流形的数据，并且可以结合流形知识，同时考虑流形上和流形外的几何坐标系。


<details>
  <summary>Details</summary>
Motivation: 现有的PPCA和其扩展主要基于线性模型，只能在欧几里得坐标系下描述数据，无法很好地处理神经科学等领域中存在非线性流形分布的数据。

Method: 提出了一种概率几何主成分分析（PGPCA）方法，该方法可以显式地结合已知的非线性流形知识，并从中拟合流形。PGPCA可以导出几何坐标系来捕捉数据偏离流形和噪声，并提供一种数据驱动的EM算法来学习模型参数。

Result: 在模拟和大脑数据分析中，PGPCA能够有效地模拟数据在各种给定流形周围的分布，并且在这些数据上优于PPCA。PGPCA还可以测试几何坐标系是否比欧几里得坐标系更能描述数据，并同时在流形上和流形周围进行降维和数据分布学习。

Conclusion: PGPCA通过结合非线性流形几何，泛化了PPCA，能够更好地描述数据分布，特别适用于存在噪声和分布在非线性流形周围的高维数据分析。

Abstract: Dimensionality reduction is critical across various domains of science
including neuroscience. Probabilistic Principal Component Analysis (PPCA) is a
prominent dimensionality reduction method that provides a probabilistic
approach unlike the deterministic approach of PCA and serves as a connection
between PCA and Factor Analysis (FA). Despite their power, PPCA and its
extensions are mainly based on linear models and can only describe the data in
a Euclidean coordinate system. However, in many neuroscience applications, data
may be distributed around a nonlinear geometry (i.e., manifold) rather than
lying in the Euclidean space. We develop Probabilistic Geometric Principal
Component Analysis (PGPCA) for such datasets as a new dimensionality reduction
algorithm that can explicitly incorporate knowledge about a given nonlinear
manifold that is first fitted from these data. Further, we show how in addition
to the Euclidean coordinate system, a geometric coordinate system can be
derived for the manifold to capture the deviations of data from the manifold
and noise. We also derive a data-driven EM algorithm for learning the PGPCA
model parameters. As such, PGPCA generalizes PPCA to better describe data
distributions by incorporating a nonlinear manifold geometry. In simulations
and brain data analyses, we show that PGPCA can effectively model the data
distribution around various given manifolds and outperforms PPCA for such data.
Moreover, PGPCA provides the capability to test whether the new geometric
coordinate system better describes the data than the Euclidean one. Finally,
PGPCA can perform dimensionality reduction and learn the data distribution both
around and on the manifold. These capabilities make PGPCA valuable for
enhancing the efficacy of dimensionality reduction for analysis of
high-dimensional data that exhibit noise and are distributed around a nonlinear
manifold.

</details>


### [263] [Discrete-time diffusion-like models for speech synthesis](https://arxiv.org/abs/2509.18470)
*Xiaozhou Tan,Minghui Zhao,Mattias Cross,Anton Ragni*

Main category: cs.LG

TL;DR: 离散时间扩散模型在语音生成方面可以达到与连续时间模型相当的质量，同时具有更高效和一致的训练和推理。


<details>
  <summary>Details</summary>
Motivation: 现有的连续时间扩散模型在训练和推理过程中存在不匹配问题，并且可能需要较多的推理步数。

Method: 提出并探索了几种离散时间扩散过程，包括加性高斯噪声、乘性高斯噪声、模糊噪声以及模糊和高斯噪声的混合。

Result: 实验结果表明，离散时间过程在语音生成方面可以达到与连续时间模型相当的主观和客观质量，并且在训练和推理方面更加高效和一致。

Conclusion: 离散时间扩散过程是语音生成的一个有前景的方向，可以克服连续时间模型的局限性，并提供更优的性能。

Abstract: Diffusion models have attracted a lot of attention in recent years. These
models view speech generation as a continuous-time process. For efficient
training, this process is typically restricted to additive Gaussian noising,
which is limiting. For inference, the time is typically discretized, leading to
the mismatch between continuous training and discrete sampling conditions.
Recently proposed discrete-time processes, on the other hand, usually do not
have these limitations, may require substantially fewer inference steps, and
are fully consistent between training/inference conditions. This paper explores
some diffusion-like discrete-time processes and proposes some new variants.
These include processes applying additive Gaussian noise, multiplicative
Gaussian noise, blurring noise and a mixture of blurring and Gaussian noises.
The experimental results suggest that discrete-time processes offer comparable
subjective and objective speech quality to their widely popular continuous
counterpart, with more efficient and consistent training and inference schemas.

</details>


### [264] [Individualized non-uniform quantization for vector search](https://arxiv.org/abs/2509.18471)
*Mariano Tepper,Ted Willke*

Main category: cs.LG

TL;DR: NVQ是一种新的向量压缩技术，通过学习单独的非均匀向量量化器来提高效率和准确性。


<details>
  <summary>Details</summary>
Motivation: 高维向量的巨大尺寸给现代向量搜索技术带来了内存/存储检索成本高和占用空间大的问题。

Method: NVQ的核心是使用新颖的、节省资源且计算高效的非线性方法来构建非均匀向量量化器，并为每个索引向量单独学习这些量化器。

Result: 实验结果表明，NVQ在计算成本很小的情况下，比现有技术具有更高的准确性。

Conclusion: NVQ是一种在计算和空间上都高效的高保真度向量压缩技术。

Abstract: Embedding vectors are widely used for representing unstructured data and
searching through it for semantically similar items. However, the large size of
these vectors, due to their high-dimensionality, creates problems for modern
vector search techniques: retrieving large vectors from memory/storage is
expensive and their footprint is costly. In this work, we present NVQ
(non-uniform vector quantization), a new vector compression technique that is
computationally and spatially efficient in the high-fidelity regime. The core
in NVQ is to use novel parsimonious and computationally efficient
nonlinearities for building non-uniform vector quantizers. Critically, these
quantizers are \emph{individually} learned for each indexed vector. Our
experimental results show that NVQ exhibits improved accuracy compared to the
state of the art with a minimal computational cost.

</details>


### [265] [SimpleFold: Folding Proteins is Simpler than You Think](https://arxiv.org/abs/2509.18480)
*Yuyang Wang,Jiarui Lu,Navdeep Jaitly,Josh Susskind,Miguel Angel Bautista*

Main category: cs.LG

TL;DR: SimpleFold是一个仅使用通用Transformer块的流匹配蛋白质折叠模型，它在不依赖复杂领域特定架构的情况下，在标准基准测试和集成预测方面取得了有竞争力的性能，并且易于部署。


<details>
  <summary>Details</summary>
Motivation: 评估仅使用通用Transformer块和流匹配目标是否能够构建高性能的蛋白质折叠模型，挑战对复杂领域特定架构的依赖。

Method: 使用通用的Transformer块，并结合自适应层和流匹配目标（附加结构项）来训练SimpleFold模型，并将其扩展到30亿参数，在900万个精炼的蛋白质结构和PDB数据上进行训练。

Result: SimpleFold-3B在标准折叠基准测试中取得了与最先进基线相当的性能，在集成预测方面表现出强大的能力，并且在消费级硬件上具有高效的部署和推理能力。

Conclusion: SimpleFold的成功表明，蛋白质折叠模型不一定需要复杂的领域特定架构，为未来的研究开辟了新的设计方向。

Abstract: Protein folding models have achieved groundbreaking results typically via a
combination of integrating domain knowledge into the architectural blocks and
training pipelines. Nonetheless, given the success of generative models across
different but related problems, it is natural to question whether these
architectural designs are a necessary condition to build performant models. In
this paper, we introduce SimpleFold, the first flow-matching based protein
folding model that solely uses general purpose transformer blocks. Protein
folding models typically employ computationally expensive modules involving
triangular updates, explicit pair representations or multiple training
objectives curated for this specific domain. Instead, SimpleFold employs
standard transformer blocks with adaptive layers and is trained via a
generative flow-matching objective with an additional structural term. We scale
SimpleFold to 3B parameters and train it on approximately 9M distilled protein
structures together with experimental PDB data. On standard folding benchmarks,
SimpleFold-3B achieves competitive performance compared to state-of-the-art
baselines, in addition SimpleFold demonstrates strong performance in ensemble
prediction which is typically difficult for models trained via deterministic
reconstruction objectives. Due to its general-purpose architecture, SimpleFold
shows efficiency in deployment and inference on consumer-level hardware.
SimpleFold challenges the reliance on complex domain-specific architectures
designs in protein folding, opening up an alternative design space for future
progress.

</details>


### [266] [Hybrid Data can Enhance the Utility of Synthetic Data for Training Anti-Money Laundering Models](https://arxiv.org/abs/2509.18499)
*Rachel Chung,Pratyush Nidhi Sharma,Mikko Siponen,Rohit Vadodaria,Luke Smith*

Main category: cs.LG

TL;DR: 通过结合公开数据和合成数据来增强反洗钱模型


<details>
  <summary>Details</summary>
Motivation: 缺乏真实世界的反洗钱（AML）训练数据，这是一个关键的全球性问题，因为隐私和保密问题限制了访问。

Method: 提出使用混合数据集，通过结合易于访问的公开数据和合成生成的数据来增强 AML 模型。

Result: 混合数据集在保持隐私的同时提高了模型的效用，证明了其作为一种实用的解决方案。

Conclusion: 混合数据集为金融机构提供了一种实用的方法来改进其反洗钱系统。

Abstract: Money laundering is a critical global issue for financial institutions.
Automated Anti-money laundering (AML) models, like Graph Neural Networks (GNN),
can be trained to identify illicit transactions in real time. A major issue for
developing such models is the lack of access to training data due to privacy
and confidentiality concerns. Synthetically generated data that mimics the
statistical properties of real data but preserves privacy and confidentiality
has been proposed as a solution. However, training AML models on purely
synthetic datasets presents its own set of challenges. This article proposes
the use of hybrid datasets to augment the utility of synthetic datasets by
incorporating publicly available, easily accessible, and real-world features.
These additions demonstrate that hybrid datasets not only preserve privacy but
also improve model utility, offering a practical pathway for financial
institutions to enhance AML systems.

</details>


### [267] [APRIL: Active Partial Rollouts in Reinforcement Learning to tame long-tail generation](https://arxiv.org/abs/2509.18521)
*Yuzhen Zhou,Jiajun Li,Yusheng Su,Gowtham Ramesh,Zilin Zhu,Xiang Long,Chenyang Zhao,Jin Pan,Xiaodong Yu,Ze Wang,Kangrui Du,Jialian Wu,Ximeng Sun,Jiang Liu,Qiaolin Yu,Hao Chen,Zicheng Liu,Emad Barsoum*

Main category: cs.LG

TL;DR: APRIL通过在强化学习（RL）训练中采用主动部分回放策略，解决了因响应长度长尾分布导致的GPU利用率低下和效率瓶颈问题，从而提高了回放吞吐量，加速了收敛，并提升了最终准确率。


<details>
  <summary>Details</summary>
Motivation: 现有的强化学习（RL）框架在训练大型预训练语言模型（LLMs）时，主要依赖推理引擎进行回放生成和训练引擎进行策略更新。然而，RL训练成本高昂，其中回放生成占总运行时间的90%以上。此外，响应长度的长尾分布导致少数长响应拖慢整个批次的处理速度，造成GPU空闲和利用率低下，限制了模型的扩展性。

Method: APRIL（Active Partial Rollouts in Reinforcement Learning）提出了一种主动部分回放策略。在回放阶段，APRIL会超额请求回放，一旦达到目标响应数量就立即终止，并将未完成的响应用于后续步骤的继续处理。这种策略确保了所有回放都能被有效利用，同时显著减少了GPU的空闲时间。

Result: 实验表明，APRIL在常用的RL算法（GRPO, DAPO, GSPO）中，将回放吞吐量提高了44%，加速了收敛过程，并在各项任务中实现了高达8%的最终准确率提升。APRIL还具有框架和硬件无关性，已集成到slime RL框架中，并可在NVIDIA和AMD GPU上运行。

Conclusion: APRIL通过结合系统级和算法级的考量，有效地提高了RL训练的效率，解决了长期存在的长尾响应问题，并为RL系统的进一步优化提供了新的思路。

Abstract: Reinforcement learning (RL) has become a cornerstone in advancing large-scale
pre-trained language models (LLMs). Successive generations, including GPT-o
series, DeepSeek-R1, Kimi-K1.5, Grok 4, and GLM-4.5, have relied on large-scale
RL training to enhance reasoning and coding capabilities. To meet the
community's growing RL needs, numerous RL frameworks have been proposed. Most
of these frameworks primarily rely on inference engines for rollout generation
and training engines for policy updates. However, RL training remains
computationally expensive, with rollout generation accounting for more than 90%
of total runtime. In addition, its efficiency is often constrained by the
long-tail distribution of rollout response lengths, where a few lengthy
responses stall entire batches, leaving GPUs idle and underutilized. As model
and rollout sizes continue to grow, this bottleneck increasingly limits
scalability. To address this challenge, we propose Active Partial Rollouts in
Reinforcement Learning (APRIL), which mitigates long-tail inefficiency. In the
rollout phase, APRIL over-provisions rollout requests, terminates once the
target number of responses is reached, and recycles incomplete responses for
continuation in future steps. This strategy ensures that no rollouts are
discarded while substantially reducing GPU idle time. Experiments show that
APRIL improves rollout throughput by at most 44% across commonly used RL
algorithms (GRPO, DAPO, GSPO), accelerates convergence, and achieves at most 8%
higher final accuracy across tasks. Moreover, APRIL is both framework and
hardware agnostic, already integrated into the slime RL framework, and
deployable on NVIDIA and AMD GPUs alike. Taken together, this work unifies
system-level and algorithmic considerations in proposing APRIL, with the aim of
advancing RL training efficiency and inspiring further optimizations in RL
systems.

</details>


### [268] [Reverse-Complement Consistency for DNA Language Models](https://arxiv.org/abs/2509.18529)
*Mingqian Ma*

Main category: cs.LG

TL;DR: DNA语言模型通常无法理解序列与其反向互补序列的生物学意义相同这一基本属性。本研究提出了一种名为反向互补一致性正则化（RCCR）的微调方法，通过直接惩罚模型对序列及其反向互补序列预测之间的差异来解决这个问题。


<details>
  <summary>Details</summary>
Motivation: 现有的DNA语言模型在处理序列及其反向互补序列时预测不一致，这降低了其可靠性。

Method: 提出了一种名为反向互补一致性正则化（RCCR）的简单、模型无关的微调方法，该方法直接惩罚模型在序列及其反向互补序列上的预测差异。

Result: RCCR在三种不同的模型（Nucleotide Transformer, HyenaDNA, DNABERT-2）和多种基因组任务（序列分类、标量回归、特征预测）上进行了评估，结果表明RCCR显著提高了模型的反向互补鲁棒性，减少了预测错误，并且在保持或提高任务准确性的同时，优于反向互补数据增强和测试时平均等基线方法。

Conclusion: RCCR将关键的生物学先验知识直接融入学习过程，为多种生物学任务提供了一种单一的、内在鲁棒的、计算高效的模型微调方法。

Abstract: A fundamental property of DNA is that the reverse complement (RC) of a
sequence often carries identical biological meaning. However, state-of-the-art
DNA language models frequently fail to capture this symmetry, producing
inconsistent predictions for a sequence and its RC counterpart, which
undermines their reliability. In this work, we introduce Reverse-Complement
Consistency Regularization (RCCR), a simple and model-agnostic fine-tuning
objective that directly penalizes the divergence between a model's prediction
on a sequence and the aligned prediction on its reverse complement. We evaluate
RCCR across three diverse backbones (Nucleotide Transformer, HyenaDNA,
DNABERT-2) on a wide range of genomic tasks, including sequence classification,
scalar regression, and profile prediction. Our experiments show that RCCR
substantially improves RC robustness by dramatically reducing prediction flips
and errors, all while maintaining or improving task accuracy compared to
baselines such as RC data augmentation and test-time averaging. By integrating
a key biological prior directly into the learning process, RCCR produces a
single, intrinsically robust, and computationally efficient model fine-tuning
recipe for diverse biology tasks.

</details>


### [269] [Symphony-MoE: Harmonizing Disparate Pre-trained Models into a Coherent Mixture-of-Experts](https://arxiv.org/abs/2509.18542)
*Qi Wang,Hanyang Peng,Yue Yu*

Main category: cs.LG

TL;DR: 通过融合来自不同预训练模型的专家来构建强大的MoE模型，并使用一种新颖的框架来解决参数不匹配问题，从而在多领域任务和分布外泛化方面取得优于基线的结果。


<details>
  <summary>Details</summary>
Motivation: 现有的MoE模型训练成本高，且通过单一预训练模型进行专家复用会导致专家多样性受限。本研究旨在解决这个问题。

Method: 提出了一种名为Symphony-MoE的两阶段框架。第一阶段在无需训练的情况下，通过层感知融合策略构建共享骨干，并使用基于激活的功能对齐来缓解专家之间的参数不对齐。第二阶段仅需轻量级的路由训练。

Result: 实验证明，该方法能够成功整合来自异构源的专家，构建出在多领域任务和分布外泛化方面显著优于基线模型的MoE模型。

Conclusion: Symphony-MoE框架能够有效地融合来自不同预训练模型的专家，克服参数不对齐的挑战，并提升MoE模型的性能。

Abstract: Mixture-of-Experts (MoE) models enable scalable performance by activating
large parameter sets sparsely, minimizing computational overhead. To circumvent
the prohibitive cost of training MoEs from scratch, recent work employs
upcycling, reusing a single pre-trained dense model by replicating its
feed-forward network (FFN) layers into experts. However, this limits expert
diversity, as all experts originate from a single pre-trained dense model. This
paper addresses this limitation by constructing powerful MoE models using
experts sourced from multiple identically-architected but disparate pre-trained
models (e.g., Llama2-Chat and Code Llama). A key challenge lies in the fact
that these source models occupy disparate, dissonant regions of the parameter
space, making direct upcycling prone to severe performance degradation. To
overcome this, we propose Symphony-MoE, a novel two-stage framework designed to
harmonize these models into a single, coherent expert mixture. First, we
establish this harmony in a training-free manner: we construct a shared
backbone via a layer-aware fusion strategy and, crucially, alleviate parameter
misalignment among experts using activation-based functional alignment.
Subsequently, a single lightweight stage of router training coordinates the
entire architecture. Experiments demonstrate that our method successfully
integrates experts from heterogeneous sources, achieving an MoE model that
significantly surpasses baselines in multi-domain tasks and out-of-distribution
generalization.

</details>


### [270] [Global Minimizers of Sigmoid Contrastive Loss](https://arxiv.org/abs/2509.18552)
*Kiril Bangachev,Guy Bresler,Iliyas Noman,Yury Polyanskiy*

Main category: cs.LG

TL;DR: 该论文通过引入可训练的逆温度和偏置，并结合 Sigmoid 损失函数，为对比预训练中的表示获取和对齐提供了一个新的理论视角，解释了 SigLIP 和 SigLIP2 模型的优势，并提出了一种改进的损失函数。


<details>
  <summary>Details</summary>
Motivation: 解释对比预训练中，在 Sigmoid 损失下，使用可训练的逆温度和偏置的优势，并将其与 SigLIP 和 SigLIP2 模型联系起来。

Method: 理论分析了可训练的逆温度和偏置在 Sigmoid 损失下的行为，引入了 $(\mathsf{m}, \mathsf{b}_{{\mathsf{rel}}})$-Constellations 概念来表征损失函数可以为零的配置，并利用该表征来解释 SigLIP 的成功、模态间隙以及确定高质量表示所需的维度。

Result: 提出了 $(\mathsf{m}, \mathsf{b}_{{\mathsf{rel}}})$-Constellations 这一新组合对象，并用其理论上解释了 SigLIP 在检索任务中的成功、模态间隙现象，以及确定了生成高质量表示所需的维度。此外，提出了一种带有显式相对偏置的 Sigmoid 损失重参数化方法，并在合成数据实验中证明了其能改善训练动态。

Conclusion: 通过引入 $(\mathsf{m}, \mathsf{b}_{{\mathsf{rel}}})$-Constellations 和对 Sigmoid 损失的理论分析，为理解和改进对比预训练模型（如 SigLIP）提供了新的见解，并提出了一种实际可行的改进方法。

Abstract: The meta-task of obtaining and aligning representations through contrastive
pretraining is steadily gaining importance since its introduction in CLIP and
ALIGN. In this paper we theoretically explain the advantages of synchronizing
with trainable inverse temperature and bias under the sigmoid loss, as
implemented in the recent SigLIP and SigLIP2 models of Google DeepMind.
Temperature and bias can drive the loss function to zero for a rich class of
configurations that we call $(\mathsf{m},
\mathsf{b}_{\mathsf{rel}})$-Constellations. $(\mathsf{m},
\mathsf{b}_{\mathsf{rel}})$-Constellations are a novel combinatorial object
related to spherical codes and are parametrized by a margin $\mathsf{m}$ and
relative bias $\mathsf{b}_{\mathsf{rel}}$. We use our characterization of
constellations to theoretically justify the success of SigLIP on retrieval, to
explain the modality gap present in SigLIP, and to identify the necessary
dimension for producing high-quality representations. Finally, we propose a
reparameterization of the sigmoid loss with explicit relative bias, which
improves training dynamics in experiments with synthetic data.

</details>


### [271] [Explainable Graph Neural Networks: Understanding Brain Connectivity and Biomarkers in Dementia](https://arxiv.org/abs/2509.18568)
*Niharika Tewari,Nguyen Linh Dan Le,Mujie Liu,Jing Ren,Ziqi Xu,Tabinda Sarwar,Veeky Baths,Feng Xia*

Main category: cs.LG

TL;DR: 本篇论文全面综述了可解释图神经网络（XGNNs）在痴呆症研究中的应用，重点关注其在阿尔茨海默病、帕金森病等疾病诊断和生物标志物识别方面的潜力，并探讨了该领域的挑战与未来方向。


<details>
  <summary>Details</summary>
Motivation: 痴呆症的异质性给诊断和亚型区分带来挑战。图神经网络（GNNs）在建模大脑连接方面有潜力，但其鲁棒性、数据稀疏性和可解释性不足限制了临床应用。可解释图神经网络（XGNNs）结合了图学习和可解释性，有望克服这些障碍。

Method: 本文全面回顾了XGNNs在痴呆症研究中的应用，涵盖了阿尔茨海默病、帕金森病、轻度认知障碍和多疾病诊断等领域。文章还提出了一个针对痴呆症相关任务的可解释性方法分类，并对现有模型在临床场景中的应用进行了比较。

Result: XGNNs在识别疾病相关生物标志物、分析大脑网络中断以及为临床医生提供透明的见解方面展现了潜力。文章对现有模型在临床场景中的应用进行了比较。

Conclusion: XGNNs在痴呆症研究中具有巨大潜力，但仍面临泛化性有限、未充分探索的领域以及与大语言模型（LLMs）结合以实现早期检测等挑战。本综述旨在指导未来工作，实现XGNNs在痴呆症研究中值得信赖、具有临床意义和可扩展的应用。

Abstract: Dementia is a progressive neurodegenerative disorder with multiple
etiologies, including Alzheimer's disease, Parkinson's disease, frontotemporal
dementia, and vascular dementia. Its clinical and biological heterogeneity
makes diagnosis and subtype differentiation highly challenging. Graph Neural
Networks (GNNs) have recently shown strong potential in modeling brain
connectivity, but their limited robustness, data scarcity, and lack of
interpretability constrain clinical adoption. Explainable Graph Neural Networks
(XGNNs) have emerged to address these barriers by combining graph-based
learning with interpretability, enabling the identification of disease-relevant
biomarkers, analysis of brain network disruptions, and provision of transparent
insights for clinicians. This paper presents the first comprehensive review
dedicated to XGNNs in dementia research. We examine their applications across
Alzheimer's disease, Parkinson's disease, mild cognitive impairment, and
multi-disease diagnosis. A taxonomy of explainability methods tailored for
dementia-related tasks is introduced, alongside comparisons of existing models
in clinical scenarios. We also highlight challenges such as limited
generalizability, underexplored domains, and the integration of Large Language
Models (LLMs) for early detection. By outlining both progress and open
problems, this review aims to guide future work toward trustworthy, clinically
meaningful, and scalable use of XGNNs in dementia research.

</details>


### [272] [DS-Diffusion: Data Style-Guided Diffusion Model for Time-Series Generation](https://arxiv.org/abs/2509.18584)
*Mingchun Sun,Rongqiang Zhao,Jie Liu*

Main category: cs.LG

TL;DR: DS-Diffusion 通过风格引导的核和分层去噪机制解决了现有时间序列生成扩散模型在条件引入、分布偏差和可解释性方面的问题，提高了生成数据的质量和灵活性。


<details>
  <summary>Details</summary>
Motivation: 现有时间序列生成扩散模型在引入特定条件时需要重新训练整个框架，存在生成数据与真实数据之间的分布偏差，并且推理过程不直观，可能导致下游任务中的模型偏差。

Method: 提出了一种基于风格引导核的扩散模型（DS-Diffusion），该模型包含时间信息的分层去噪机制（THD），以避免在特定条件下进行重新训练，并减少生成数据与真实数据之间的分布偏差。

Result: 与 ImagenTime 等最先进的模型相比，DS-Diffusion 的预测分数和判别分数分别降低了 5.56% 和 61.55%，进一步减少了生成数据与真实数据之间的分布偏差，推理过程也更具可解释性。

Conclusion: DS-Diffusion 通过无需重新训练模型，提高了模型在特定条件下的灵活性和适应性，同时解决了现有方法的局限性。

Abstract: Diffusion models are the mainstream approach for time series generation
tasks. However, existing diffusion models for time series generation require
retraining the entire framework to introduce specific conditional guidance.
There also exists a certain degree of distributional bias between the generated
data and the real data, which leads to potential model biases in downstream
tasks. Additionally, the complexity of diffusion models and the latent spaces
leads to an uninterpretable inference process. To address these issues, we
propose the data style-guided diffusion model (DS-Diffusion). In the
DS-Diffusion, a diffusion framework based on style-guided kernels is developed
to avoid retraining for specific conditions. The time-information based
hierarchical denoising mechanism (THD) is developed to reduce the
distributional bias between the generated data and the real data. Furthermore,
the generated samples can clearly indicate the data style from which they
originate. We conduct comprehensive evaluations using multiple public datasets
to validate our approach. Experimental results show that, compared to the
state-of-the-art model such as ImagenTime, the predictive score and the
discriminative score decrease by 5.56% and 61.55%, respectively. The
distributional bias between the generated data and the real data is further
reduced, the inference process is also more interpretable. Moreover, by
eliminating the need to retrain the diffusion model, the flexibility and
adaptability of the model to specific conditions are also enhanced.

</details>


### [273] [Reflect before Act: Proactive Error Correction in Language Models](https://arxiv.org/abs/2509.18607)
*Qiuhai Zeng,Sarvesh Rajkumar,Di Wang,Narendra Gyanchandani,Wenbo Yan*

Main category: cs.LG

TL;DR: REBACT通过引入“先反思后行动”机制，在交互式决策任务中显著提升了大型语言模型的性能，提高了成功率并具有计算效率。


<details>
  <summary>Details</summary>
Motivation: 现有的大型语言模型在交互式决策任务中存在错误累积和缺乏有效的自我纠正机制的问题。

Method: 提出了一种名为“先反思后行动”（REBACT）的新方法，在执行下一步动作之前增加了一个关键的反思步骤，以实现即时纠错、确保动作路径的顺畅以及适应环境反馈。

Result: REBACT在ALFWorld、WebShop和TextCraft三个环境中进行了评估，相比强基线模型，在WebShop上的成功率提高了24%（达到61%），在ALFWorld上提高了6.72%（达到98.51%），在TextCraft上提高了0.5%（达到99.5%），同时仅需少量修改步骤，证明了其计算效率。

Conclusion: REBACT是一种有效的方法，可以提升大型语言模型在交互式决策任务中的表现，通过引入反思步骤来纠正错误并适应环境。

Abstract: Large Language Models (LLMs) have demonstrated remarkable capabilities in
interactive decision-making tasks, but existing methods often struggle with
error accumulation and lack robust self-correction mechanisms. We introduce
"Reflect before Act" (REBACT), a novel approach that enhances LLM-based
decision-making by introducing a critical reflect step prior to taking the next
action. This approach allows for immediate error correction, ensuring smooth
action path and adaptibity to environment feedback. We evaluate REBACT on three
diverse interactive environments: ALFWorld, WebShop, and TextCraft. Our results
demonstrate that REBACT significantly outperforms strong baselines, improving
success rates by up to 24% on WebShop (achieving 61%), 6.72% on ALFWorld
(achieving 98.51%), and 0.5% on TextCraft (achieving 99.5%) using
Claude3.5-sonnet as the underlying LLM. Further analysis reveals that REBACT's
performance improvements are achieved with only a few modification steps,
demonstrating its computational efficiency.

</details>


### [274] [Flow marching for a generative PDE foundation model](https://arxiv.org/abs/2509.18611)
*Zituo Chen,Sili Deng*

Main category: cs.LG

TL;DR: 提出了Flow Marching算法，结合了神经算子学习和流匹配，并构建了基于此的生成式PDE基础模型，以解决现有确定性Transformer架构在科学和工程应用中的生成灵活性不足的问题。该模型通过联合采样噪声水平和物理时间步长，学习统一的速度场，将带噪声的当前状态迁移到其干净的后继状态，从而减少长期预测的漂移并实现可感知不确定性的集合生成。


<details>
  <summary>Details</summary>
Motivation: 现有基于PDE的基金模型大多采用确定性Transformer架构，缺乏生成灵活性，无法满足许多科学和工程应用的需求。

Method: 提出Flow Matching算法，结合神经算子学习和流匹配。引入物理预训练变分自编码器（P2VAE）将物理状态嵌入紧凑的潜在空间。设计了高效的Flow Matching Transformer（FMT），结合了扩散-强制方案和潜在时间金字塔。

Result: 在~2.5M个轨迹的数据集上进行了训练和评估。在未见过的Kolmogorov湍流上进行了少样本适应性测试，展示了比确定性模型更优越的长期预测稳定性，并呈现了不确定性分层的集合结果。

Conclusion: 生成式PDE基础模型对于实际应用至关重要，Flow Matching算法及其相关模型（P2VAE和FMT）在解决长期预测漂移、提高计算效率和实现不确定性感知生成方面取得了显著进展。

Abstract: Pretraining on large-scale collections of PDE-governed spatiotemporal
trajectories has recently shown promise for building generalizable models of
dynamical systems. Yet most existing PDE foundation models rely on
deterministic Transformer architectures, which lack generative flexibility for
many science and engineering applications. We propose Flow Marching, an
algorithm that bridges neural operator learning with flow matching motivated by
an analysis of error accumulation in physical dynamical systems, and we build a
generative PDE foundation model on top of it. By jointly sampling the noise
level and the physical time step between adjacent states, the model learns a
unified velocity field that transports a noisy current state toward its clean
successor, reducing long-term rollout drift while enabling uncertainty-aware
ensemble generations. Alongside this core algorithm, we introduce a
Physics-Pretrained Variational Autoencoder (P2VAE) to embed physical states
into a compact latent space, and an efficient Flow Marching Transformer (FMT)
that combines a diffusion-forcing scheme with latent temporal pyramids,
achieving up to 15x greater computational efficiency than full-length video
diffusion models and thereby enabling large-scale pretraining at substantially
reduced cost. We curate a corpus of ~2.5M trajectories across 12 distinct PDE
families and train suites of P2VAEs and FMTs at multiple scales. On downstream
evaluation, we benchmark on unseen Kolmogorov turbulence with few-shot
adaptation, demonstrate long-term rollout stability over deterministic
counterparts, and present uncertainty-stratified ensemble results, highlighting
the importance of generative PDE foundation models for real-world applications.

</details>


### [275] [HyperAdapt: Simple High-Rank Adaptation](https://arxiv.org/abs/2509.18629)
*Abel Gurung,Joseph Campbell*

Main category: cs.LG

TL;DR: HyperAdapt是一种参数高效微调（PEFT）方法，通过应用对角矩阵进行行和列缩放来调整预训练权重矩阵，从而以更少的参数实现与全微调和现有PEFT方法相当的性能。


<details>
  <summary>Details</summary>
Motivation: 当前的微调方法在适应特定应用时需要大量的内存和计算资源。参数高效微调（PEFT）方法通过只更新一小部分权重来缓解这个问题。

Method: HyperAdapt通过应用行和列的缩放（通过对角矩阵）来调整预训练的权重矩阵，从而在仅需要n+m个可训练参数的情况下，为一个n*m的矩阵引入高秩更新。

Result: 在GLUE、算术推理和常识推理基准测试中，使用高达14B参数的模型进行实验，结果表明HyperAdapt在保持性能的同时，所需的可训练参数比现有方法少几个数量级。

Conclusion: HyperAdapt在参数数量上实现了显著的减少，同时在多项基准测试中与全微调和最先进的PEFT方法相当或接近其性能，证明了其作为一种高效微调方法的有效性。

Abstract: Foundation models excel across diverse tasks, but adapting them to
specialized applications often requires fine-tuning, an approach that is memory
and compute-intensive. Parameter-efficient fine-tuning (PEFT) methods mitigate
this by updating only a small subset of weights. In this paper, we introduce
HyperAdapt, a parameter-efficient fine-tuning method that significantly reduces
the number of trainable parameters compared to state-of-the-art methods like
LoRA. Specifically, HyperAdapt adapts a pre-trained weight matrix by applying
row- and column-wise scaling through diagonal matrices, thereby inducing a
high-rank update while requiring only $n+m$ trainable parameters for an $n
\times m$ matrix. Theoretically, we establish an upper bound on the rank of
HyperAdapt's updates, and empirically, we confirm that it consistently induces
high-rank transformations across model layers. Experiments on GLUE, arithmetic
reasoning, and commonsense reasoning benchmarks with models up to 14B
parameters demonstrate that HyperAdapt matches or nearly matches the
performance of full fine-tuning and state-of-the-art PEFT methods while using
orders of magnitude fewer trainable parameters.

</details>


### [276] [Towards Rational Pesticide Design with Graph Machine Learning Models for Ecotoxicology](https://arxiv.org/abs/2509.18703)
*Jakub Adamczyk*

Main category: cs.LG

TL;DR: 利用图机器学习加速开发更安全、更环保的农药。


<details>
  <summary>Details</summary>
Motivation: 受到药物发现中 in silico 方法的启发，本研究专注于合理设计农药，利用图机器学习加速开发更安全、更环保的农药。

Method: 创建了最大的农药对蜜蜂毒性数据集ApisTox，并广泛评估了分子指纹、图核、GNN和预训练transformer等多种机器学习模型。

Result: 与药物化学中常用的方法相比，机器学习模型在农用化学品上的泛化能力较差，这表明需要特定领域的模型和基准。

Conclusion: 未来的工作将集中于开发一个全面的基准套件，并设计针对农药发现独特挑战的机器学习模型。

Abstract: This research focuses on rational pesticide design, using graph machine
learning to accelerate the development of safer, eco-friendly agrochemicals,
inspired by in silico methods in drug discovery. With an emphasis on
ecotoxicology, the initial contributions include the creation of ApisTox, the
largest curated dataset on pesticide toxicity to honey bees. We conducted a
broad evaluation of machine learning (ML) models for molecular graph
classification, including molecular fingerprints, graph kernels, GNNs, and
pretrained transformers. The results show that methods successful in medicinal
chemistry often fail to generalize to agrochemicals, underscoring the need for
domain-specific models and benchmarks. Future work will focus on developing a
comprehensive benchmarking suite and designing ML models tailored to the unique
challenges of pesticide discovery.

</details>


### [277] [A Generalized Bisimulation Metric of State Similarity between Markov Decision Processes: From Theoretical Propositions to Applications](https://arxiv.org/abs/2509.18714)
*Zhenyu Tao,Wei Xu,Xiaohu You*

Main category: cs.LG

TL;DR: 本文提出了一个通用的马尔可夫决策过程（MDP）之间的度量（GBSM），并证明了其三个基本性质：对称性、三角不等式和相同状态空间上的距离界限。该度量在策略迁移、状态聚合和基于采样估计等方面提供了严格的理论分析和改进的界限，并在数值实验中得到了验证。


<details>
  <summary>Details</summary>
Motivation: 在多MDP场景（如策略迁移）中，现有的双模拟度量（BSM）应用存在挑战，且缺乏严格的数学性质分析，阻碍了理论进展。

Method: 形式化定义了MDP对之间的广义双模拟度量（GBSM），并严格证明了其三个基本性质：对称性、三角不等式和相同状态空间上的距离界限。基于这些性质，对策略迁移、状态聚合和采样估计进行了理论分析。

Result: GBSM在策略迁移、状态聚合和采样估计等方面提供了理论分析和显式界限，这些界限比标准BSM更优。GBSM还提供了估计的封闭式样本复杂度，优于基于BSM的渐近结果。数值结果验证了理论发现。

Conclusion: GBSM为多MDP场景下的理论分析提供了坚实的基础，并在策略迁移、状态聚合和采样估计等方面取得了理论和实践上的改进。

Abstract: The bisimulation metric (BSM) is a powerful tool for computing state
similarities within a Markov decision process (MDP), revealing that states
closer in BSM have more similar optimal value functions. While BSM has been
successfully utilized in reinforcement learning (RL) for tasks like state
representation learning and policy exploration, its application to multiple-MDP
scenarios, such as policy transfer, remains challenging. Prior work has
attempted to generalize BSM to pairs of MDPs, but a lack of rigorous analysis
of its mathematical properties has limited further theoretical progress. In
this work, we formally establish a generalized bisimulation metric (GBSM)
between pairs of MDPs, which is rigorously proven with the three fundamental
properties: GBSM symmetry, inter-MDP triangle inequality, and the distance
bound on identical state spaces. Leveraging these properties, we theoretically
analyse policy transfer, state aggregation, and sampling-based estimation in
MDPs, obtaining explicit bounds that are strictly tighter than those derived
from the standard BSM. Additionally, GBSM provides a closed-form sample
complexity for estimation, improving upon existing asymptotic results based on
BSM. Numerical results validate our theoretical findings and demonstrate the
effectiveness of GBSM in multi-MDP scenarios.

</details>


### [278] [LLM-Enhanced Self-Evolving Reinforcement Learning for Multi-Step E-Commerce Payment Fraud Risk Detection](https://arxiv.org/abs/2509.18719)
*Bo Qu,Zhurong Wang,Daisuke Yagi,Zhen Xu,Yang Zhao,Yinan Shan,Frank Zahradnik*

Main category: cs.LG

TL;DR: 本论文提出了一种结合强化学习（RL）和大型语言模型（LLM）的新型电子商务支付欺诈检测方法。通过将交易风险建模为多步马尔可夫决策过程（MDP），RL能够优化跨多个支付阶段的风险检测。由于奖励函数设计的复杂性和多变性，通常需要大量的人类专业知识来构建有效的奖励函数。LLM凭借其强大的推理和编码能力，能够优化这些奖励函数，从而在欺诈检测方面取得比传统方法更好的效果。实验证明，该方法不仅提高了欺诈检测的准确性，还展现了零样本学习能力。在真实世界数据上的长期评估证实了该LLM增强RL框架的有效性、鲁棒性和韧性，表明LLM在工业RL应用方面具有巨大潜力。


<details>
  <summary>Details</summary>
Motivation: 电子商务支付欺诈检测中的奖励函数设计复杂且需要大量专业知识，而传统的奖励函数设计方法在效果上存在局限性。

Method: 将交易风险建模为多步马尔可在交易风险建模为多步马尔可夫决策过程（MDP），并利用大型语言模型（LLM）来优化强化学习（RL）模型的奖励函数，以提高欺诈检测的准确性和效率。

Result: 通过LLM优化奖励函数，在真实世界数据上实现了更高的欺诈检测准确性，并展现了零样本学习能力。长期评估证明了该框架的有效性、鲁棒性和韧性。

Conclusion: 结合LLM和RL的支付欺诈检测框架能够有效提升检测性能，LLM在优化工业RL应用方面具有巨大潜力。

Abstract: This paper presents a novel approach to e-commerce payment fraud detection by
integrating reinforcement learning (RL) with Large Language Models (LLMs). By
framing transaction risk as a multi-step Markov Decision Process (MDP), RL
optimizes risk detection across multiple payment stages. Crafting effective
reward functions, essential for RL model success, typically requires
significant human expertise due to the complexity and variability in design.
LLMs, with their advanced reasoning and coding capabilities, are well-suited to
refine these functions, offering improvements over traditional methods. Our
approach leverages LLMs to iteratively enhance reward functions, achieving
better fraud detection accuracy and demonstrating zero-shot capability.
Experiments with real-world data confirm the effectiveness, robustness, and
resilience of our LLM-enhanced RL framework through long-term evaluations,
underscoring the potential of LLMs in advancing industrial RL applications.

</details>


### [279] [Theory of periodic convolutional neural network](https://arxiv.org/abs/2509.18744)
*Yuqing Liu*

Main category: cs.LG

TL;DR: 引入了一种新的卷积神经网络结构，称为周期性CNN，它将周期性边界条件融入卷积层，并证明了其逼近d-1维线性变量的脊函数的理论能力，这在低维脊函数设置中是不可能的。


<details>
  <summary>Details</summary>
Motivation: 本文的动机是探索和表征周期性CNN的表达能力，特别是其在处理具有高内在维度脊状结构的数据方面的潜力。

Method: 本文提出了一种新颖的卷积神经网络架构，称为周期性CNN，并将周期性边界条件整合到卷积层中。理论贡献是提供了一个严格的逼近定理，证明了周期性CNN在逼近d-1维线性变量的脊函数方面的能力。

Result: 证明了周期性CNN可以逼近d-1维线性变量的脊函数，而在维度较低的情况下则无法做到，从而为周期性CNN的表达能力提供了精确的刻画。

Conclusion: 周期性CNN在处理具有脊状结构的数据方面具有优势，适用于图像分析、物理信息学习和材料科学等领域，扩展了CNN逼近理论的数学基础，并展示了具有实际应用价值的周期性CNN的潜力。

Abstract: We introduce a novel convolutional neural network architecture, termed the
\emph{periodic CNN}, which incorporates periodic boundary conditions into the
convolutional layers. Our main theoretical contribution is a rigorous
approximation theorem: periodic CNNs can approximate ridge functions depending
on $d-1$ linear variables in a $d$-dimensional input space, while such
approximation is impossible in lower-dimensional ridge settings ($d-2$ or fewer
variables). This result establishes a sharp characterization of the expressive
power of periodic CNNs. Beyond the theory, our findings suggest that periodic
CNNs are particularly well-suited for problems where data naturally admits a
ridge-like structure of high intrinsic dimension, such as image analysis on
wrapped domains, physics-informed learning, and materials science. The work
thus both expands the mathematical foundation of CNN approximation theory and
highlights a class of architectures with surprising and practically relevant
approximation capabilities.

</details>


### [280] [MOMEMTO: Patch-based Memory Gate Model in Time Series Foundation Model](https://arxiv.org/abs/2509.18751)
*Samuel Yoon,Jongwon Kim,Juyoung Ha,Young Myoung Ko*

Main category: cs.LG

TL;DR: MOMEMTO是一种用于时间序列异常检测的时间序列基础模型（TFMs），它通过引入基于块的内存模块来解决现有模型过度泛化的问题，能够在一个模型中跨多个数据集进行联合微调，并在23个数据集的实验中取得了优于基线方法的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的基于重构的深度模型在时间序列异常检测中容易过度泛化，准确地重构未见过的异常。虽然内存架构可以存储正常模式的原型，但训练成本高，且未能与时间序列基础模型（TFMs）有效结合。

Method: 提出了一种名为MOMEMTO的时间序列基础模型（TFM），并增强了一个基于块的内存模块来缓解过度泛化。该内存模块能够捕获来自多个域的代表性正常模式，并通过多域训练策略允许单个模型跨多个数据集进行联合微调。MOMEMTO使用预训练编码器的潜在表示来初始化内存项，将它们组织成块级单元，并通过注意力机制进行更新。

Result: 在23个单变量基准数据集上的实验结果表明，MOMEMTO作为单个模型，在AUC和VUS指标上优于基线方法，并能进一步提升其骨干TFM的性能，尤其是在少样本学习场景下。

Conclusion: MOMEMTO通过其创新的基于块的内存模块，有效解决了时间序列异常检测中的过度泛化问题，并在多域学习和少样本学习场景下展现出优越的性能。

Abstract: Recently reconstruction-based deep models have been widely used for time
series anomaly detection, but as their capacity and representation capability
increase, these models tend to over-generalize, often reconstructing unseen
anomalies accurately. Prior works have attempted to mitigate this by
incorporating a memory architecture that stores prototypes of normal patterns.
Nevertheless, these approaches suffer from high training costs and have yet to
be effectively integrated with time series foundation models (TFMs). To address
these challenges, we propose \textbf{MOMEMTO}, a TFM for anomaly detection,
enhanced with a patch-based memory module to mitigate over-generalization. The
memory module is designed to capture representative normal patterns from
multiple domains and enables a single model to be jointly fine-tuned across
multiple datasets through a multi-domain training strategy. MOMEMTO initializes
memory items with latent representations from a pre-trained encoder, organizes
them into patch-level units, and updates them via an attention mechanism. We
evaluate our method using 23 univariate benchmark datasets. Experimental
results demonstrate that MOMEMTO, as a single model, achieves higher scores on
AUC and VUS metrics compared to baseline methods, and further enhances the
performance of its backbone TFM, particularly in few-shot learning scenarios.

</details>


### [281] [Diagonal Linear Networks and the Lasso Regularization Path](https://arxiv.org/abs/2509.18766)
*Raphaël Berthier*

Main category: cs.LG

TL;DR: 对角线性网络训练轨迹与LASSO正则化路径紧密相关，训练时间扮演反向正则化参数的角色。


<details>
  <summary>Details</summary>
Motivation: 深入分析对角线性网络的训练轨迹，并揭示其与LASSO正则化路径的联系。

Method: 分析对角线性网络在小初始化下的训练过程，并将其与LASSO正则化路径进行比较，提供理论证明和模拟。

Result: 证明了在单调性假设下，对角线性网络的训练轨迹与LASSO正则化路径是精确对应的；在一般情况下，证明了近似对应关系。

Conclusion: 对角线性网络的训练过程可以被视为一种LASSO正则化，训练时间相当于正则化参数，这为理解和分析线性网络的隐式正则化提供了新的视角。

Abstract: Diagonal linear networks are neural networks with linear activation and
diagonal weight matrices. Their theoretical interest is that their implicit
regularization can be rigorously analyzed: from a small initialization, the
training of diagonal linear networks converges to the linear predictor with
minimal 1-norm among minimizers of the training loss. In this paper, we deepen
this analysis showing that the full training trajectory of diagonal linear
networks is closely related to the lasso regularization path. In this
connection, the training time plays the role of an inverse regularization
parameter. Both rigorous results and simulations are provided to illustrate
this conclusion. Under a monotonicity assumption on the lasso regularization
path, the connection is exact while in the general case, we show an approximate
connection.

</details>


### [282] [Probabilistic Machine Learning for Uncertainty-Aware Diagnosis of Industrial Systems](https://arxiv.org/abs/2509.18810)
*Arman Mohammadi,Mattias Krysander,Daniel Jung,Erik Frisk*

Main category: cs.LG

TL;DR: 深度神经网络在故障诊断中有应用，但缺乏对其预测置信度的评估。本研究提出了一种基于集成概率机器学习的诊断框架，通过量化和自动化预测不确定性来改进数据驱动的、基于一致性的诊断。该方法在多个案例研究中进行了评估，并在诊断指标方面显示出一致的改进。


<details>
  <summary>Details</summary>
Motivation: 深度神经网络在故障诊断中有应用，但缺乏对其预测置信度的评估，这在对误报高度敏感的一致性诊断中尤其重要。

Method: 提出了一种基于集成概率机器学习的诊断框架，通过量化和自动化预测不确定性来改进数据驱动的、基于一致性的诊断。

Result: 所提出的方法在多个案例研究中进行了评估，并在诊断指标方面显示出一致的改进。

Conclusion: 该框架通过量化和自动化预测不确定性，改进了数据驱动的、基于一致性的诊断。

Abstract: Deep neural networks has been increasingly applied in fault diagnostics,
where it uses historical data
  to capture systems behavior, bypassing the need for high-fidelity physical
models.
  However, despite their competence in prediction tasks, these models often
struggle with
  the evaluation of their confidence. This matter is particularly
  important in consistency-based diagnosis where decision logic is highly
sensitive to false alarms.
  To address this challenge, this work presents a diagnostic framework that
uses
  ensemble probabilistic machine learning to
  improve diagnostic characteristics of data driven consistency based diagnosis
  by quantifying and automating the prediction uncertainty.
  The proposed method is evaluated across several case studies using both
ablation
  and comparative analyses, showing consistent improvements across a range of
diagnostic metrics.

</details>


### [283] [Training-Free Data Assimilation with GenCast](https://arxiv.org/abs/2509.18811)
*Thomas Savary,François Rozet,Gilles Louppe*

Main category: cs.LG

TL;DR: 提出了使用预训练的扩散模型进行数据同化，无需额外训练，并以GenCast为例。


<details>
  <summary>Details</summary>
Motivation: 数据同化在气象、海洋、机器人等领域被广泛应用于从噪声观测中估计动力系统的状态。现有方法在某些情况下可能存在局限性。

Method: 提出了一种轻量级、通用的数据同化方法，利用为模拟动力系统而预训练的扩散模型。该方法基于粒子滤波器，无需额外训练。

Result: （文中未明确说明具体实验结果，但提到了将该方法应用于GenCast，一个生成式天气预报模型）

Conclusion: （文中未明确给出结论，但表明该方法是一种有前景的数据同化解决方案）

Abstract: Data assimilation is widely used in many disciplines such as meteorology,
oceanography, and robotics to estimate the state of a dynamical system from
noisy observations. In this work, we propose a lightweight and general method
to perform data assimilation using diffusion models pre-trained for emulating
dynamical systems. Our method builds on particle filters, a class of data
assimilation algorithms, and does not require any further training. As a
guiding example throughout this work, we illustrate our methodology on GenCast,
a diffusion-based model that generates global ensemble weather forecasts.

</details>


### [284] [Graph-based Clustering Revisited: A Relaxation of Kernel $k$-Means Perspective](https://arxiv.org/abs/2509.18826)
*Wenlong Lyu,Yuheng Jia,Hui Liu,Junhui Hou*

Main category: cs.LG

TL;DR: 现有的图聚类方法（谱聚类、非负矩阵分解、双随机归一化）被视为核 k-means 的松弛形式，但可能过度松弛约束导致聚类效果不佳。本文提出的 LoRD 模型仅放松了正交约束，并推导了概率聚类结果。理论上证明了在双随机约束下，正交性等价于块对角性。通过引入块对角正则化（最大化 Frobenius 范数），提出了 B-LoRD 模型，进一步提高了聚类性能。通过引入类别概率参数，将非凸的双随机约束转化为线性凸约束。LoRD 和 B-LoRD 具有梯度 Lipschitz 连续性，可采用梯度下降算法优化。实验证明了该方法的有效性。


<details>
  <summary>Details</summary>
Motivation: 现有的图聚类方法（如谱聚类、非负矩阵分解、双随机归一化）可以看作是核 k-means 方法的松弛形式，但它们可能过度松弛了固有的低秩、非负、双随机和正交约束，以确保数值可行性，这可能会限制它们的聚类效果。

Method: 本文提出的 LoRD 模型仅放松正交约束，并推导出概率聚类结果。理论上证明了在双随机约束下，正交性等价于块对角性。通过引入块对角正则化（最大化 Frobenius 范数），提出了 B-LoRD 模型。通过引入类别概率参数，将非凸的双随机约束转化为线性凸约束。由于 LoRD 和 B-LoRD 具有梯度 Lipschitz 连续性，因此可以提出一种全局收敛的投影梯度下降算法来进行优化。

Result: 通过大量的实验验证了所提出方法的有效性。

Conclusion: 本文提出的 LoRD 和 B-LoRD 模型，以及相应的优化算法，在图聚类任务上表现出有效性。

Abstract: The well-known graph-based clustering methods, including spectral clustering,
symmetric non-negative matrix factorization, and doubly stochastic
normalization, can be viewed as relaxations of the kernel $k$-means approach.
However, we posit that these methods excessively relax their inherent low-rank,
nonnegative, doubly stochastic, and orthonormal constraints to ensure numerical
feasibility, potentially limiting their clustering efficacy. In this paper,
guided by our theoretical analyses, we propose \textbf{Lo}w-\textbf{R}ank
\textbf{D}oubly stochastic clustering (\textbf{LoRD}), a model that only
relaxes the orthonormal constraint to derive a probabilistic clustering
results. Furthermore, we theoretically establish the equivalence between
orthogonality and block diagonality under the doubly stochastic constraint. By
integrating \textbf{B}lock diagonal regularization into LoRD, expressed as the
maximization of the Frobenius norm, we propose \textbf{B-LoRD}, which further
enhances the clustering performance. To ensure numerical solvability, we
transform the non-convex doubly stochastic constraint into a linear convex
constraint through the introduction of a class probability parameter. We
further theoretically demonstrate the gradient Lipschitz continuity of our LoRD
and B-LoRD enables the proposal of a globally convergent projected gradient
descent algorithm for their optimization. Extensive experiments validate the
effectiveness of our approaches. The code is publicly available at
https://github.com/lwl-learning/LoRD.

</details>


### [285] [Shared-Weights Extender and Gradient Voting for Neural Network Expansion](https://arxiv.org/abs/2509.18842)
*Nikolas Chatzis,Ioannis Kordonis,Manos Theodosis,Petros Maragos*

Main category: cs.LG

TL;DR: 本文提出了一种名为SWE的新方法，通过将新神经元与现有神经元耦合，防止新神经元在训练中变得不活跃，从而实现神经网络的有效扩展。同时，还提出了一种名为SVoD的梯度优化方法，用于在网络扩展过程中合理分配神经元。


<details>
  <summary>Details</summary>
Motivation: 神经网络在训练过程中扩展容量时，新添加的神经元往往难以融入现有网络而变得不活跃，导致容量增长无效。

Method: 提出了一种名为共享权重扩展器（SWE）的新方法，通过将新神经元与现有神经元耦合来实现平滑集成，以防止新神经元不活跃。同时，引入了一种基于梯度的最陡投票分配器（SVoD）方法，用于在深度网络扩展期间分配神经元到各个层。

Result: 通过在四个数据集上进行广泛的基准测试，结果表明本文提出的方法可以有效地抑制神经元不活跃，并且与其他的扩展方法和基线方法相比，取得了更好的性能。

Conclusion: 本文提出的SWE和SVoD方法能够有效解决神经网络扩展过程中新神经元不活跃的问题，提升模型性能。

Abstract: Expanding neural networks during training is a promising way to augment
capacity without retraining larger models from scratch. However, newly added
neurons often fail to adjust to a trained network and become inactive,
providing no contribution to capacity growth. We propose the Shared-Weights
Extender (SWE), a novel method explicitly designed to prevent inactivity of new
neurons by coupling them with existing ones for smooth integration. In
parallel, we introduce the Steepest Voting Distributor (SVoD), a gradient-based
method for allocating neurons across layers during deep network expansion. Our
extensive benchmarking on four datasets shows that our method can effectively
suppress neuron inactivity and achieve better performance compared to other
expanding methods and baselines.

</details>


### [286] [NGRPO: Negative-enhanced Group Relative Policy Optimization](https://arxiv.org/abs/2509.18851)
*Gongrui Nan,Siye Chen,Jing Huang,Mengyu Lu,Dexun Wang,Chunmei Xie,Weiqi Xiong,Xianzhou Zeng,Qixuan Zhou,Yadong Li,Xingzhong Xu*

Main category: cs.LG

TL;DR: GRPO算法在处理同质化响应时存在学习信号缺失的问题，NGRPO通过引入优势校准和非对称裁剪来解决此问题，并在数学推理任务上取得了显著的性能提升。


<details>
  <summary>Details</summary>
Motivation: GRPO算法在处理全对或全错的同质化响应时，由于优势函数值为零，导致梯度为空，无法有效学习。这在同质化错误响应时尤为严重，会丢失宝贵的学习信号。

Method: NGRPO算法通过引入两个关键机制来解决GRPO的局限性：1. 优势校准（Advantage Calibration）：假设存在一个虚拟的最大奖励样本，在计算优势时改变奖励的均值和方差，确保同质化错误样本的优势值不再为零。2. 非对称裁剪（Asymmetric Clipping）：对正样本的更新幅度进行放宽，对负样本的更新幅度进行更严格的约束，以稳定优势校准带来的探索压力。

Result: 在Qwen2.5-Math-7B模型上进行的大量实验表明，NGRPO在MATH500、AMC23和AIME2025等数学基准测试中，显著优于PPO、GRPO、DAPO和PSR-NSR等基线算法。

Conclusion: NGRPO算法成功地从同质化错误中学习，实现了数学推理能力的稳定且大幅度的提升。

Abstract: RLVR has enhanced the reasoning capabilities of Large Language Models (LLMs)
across various tasks. However, GRPO, a representative RLVR algorithm, suffers
from a critical limitation: when all responses within a group are either
entirely correct or entirely incorrect, the model fails to learn from these
homogeneous responses. This is particularly problematic for homogeneously
incorrect groups, where GRPO's advantage function yields a value of zero,
leading to null gradients and the loss of valuable learning signals. To
overcome this issue, we propose NGRPO (Negative-enhanced Group Relative Policy
Optimization), an algorithm designed to convert homogeneous errors into robust
learning signals. First, NGRPO introduces Advantage Calibration. This mechanism
hypothesizes the existence of a virtual maximum-reward sample during advantage
calculation, thereby altering the mean and variance of rewards within a group
and ensuring that the advantages for homogeneously incorrect samples are no
longer zero. Second, NGRPO employs Asymmetric Clipping, which relaxes the
update magnitude for positive samples while imposing stricter constraints on
that of negative samples. This serves to stabilize the exploration pressure
introduced by the advantage calibration. Our experiments on Qwen2.5-Math-7B
demonstrate that NGRPO significantly outperforms baselines such as PPO, GRPO,
DAPO, and PSR-NSR on mathematical benchmarks including MATH500, AMC23, and
AIME2025. These results validate NGRPO's ability to learn from homogeneous
errors, leading to stable and substantial improvements in mathematical
reasoning. Our code is available at https://github.com/nangongrui-ngr/NGRPO.

</details>


### [287] [Exploring Heterophily in Graph-level Tasks](https://arxiv.org/abs/2509.18893)
*Qinhan Hou,Yilun Zheng,Xichun Zhang,Sitao Luan,Jing Tang*

Main category: cs.LG

TL;DR: 在图级学习任务中，研究异质性对于图神经网络架构设计有重要意义。


<details>
  <summary>Details</summary>
Motivation: 现有研究主要集中在节点级任务的异质性，而对图级任务的影响尚不清楚。

Method: 提出图级标记方案分类法，并聚焦于局部结构标记中的基于图元的任务。利用基于能量的梯度流分析，揭示了与节点级任务的频率主导机制不同，图元检测需要混合频率动态来适应多个光谱成分。实验在合成数据集和真实分子属性预测数据集上进行验证。

Result: 基于图元的任务目标与全局频率主导不一致，需要不同的架构考虑。实验表明，频率自适应模型优于频率主导模型。

Conclusion: 该研究首次分析了图级学习中的异质性，揭示了其在图元检测等任务中的重要作用，并为设计有效的图神经网络架构提供了指导。

Abstract: While heterophily has been widely studied in node-level tasks, its impact on
graph-level tasks remains unclear. We present the first analysis of heterophily
in graph-level learning, combining theoretical insights with empirical
validation. We first introduce a taxonomy of graph-level labeling schemes, and
focus on motif-based tasks within local structure labeling, which is a popular
labeling scheme. Using energy-based gradient flow analysis, we reveal a key
insight: unlike frequency-dominated regimes in node-level tasks, motif
detection requires mixed-frequency dynamics to remain flexible across multiple
spectral components. Our theory shows that motif objectives are inherently
misaligned with global frequency dominance, demanding distinct architectural
considerations. Experiments on synthetic datasets with controlled heterophily
and real-world molecular property prediction support our findings, showing that
frequency-adaptive model outperform frequency-dominated models. This work
establishes a new theoretical understanding of heterophily in graph-level
learning and offers guidance for designing effective GNN architectures.

</details>


### [288] [Enhancing the Effectiveness and Durability of Backdoor Attacks in Federated Learning through Maximizing Task Distinction](https://arxiv.org/abs/2509.18904)
*Zhaoxin Wang,Handing Wang,Cong Tian,Yaochu Jin*

Main category: cs.LG

TL;DR: 该研究提出了一种解耦拜占庭攻击与主任务的方法，通过在min-max框架内动态优化拜占庭触发器，以增强攻击的持久性和隐蔽性。


<details>
  <summary>Details</summary>
Motivation: 现有的拜占庭攻击方法将触发器与主任务耦合，容易被诚实更新稀释，并且在联邦防御下持久性有限。本研究旨在解决这一问题。

Method: 提出一种解耦拜占庭攻击与主任务的方法，通过在min-max框架内动态优化拜占庭触发器。内层最大化中毒和良性样本之间的性能差距，外层将自适应触发器注入局部模型。

Result: 在计算机视觉和自然语言处理任务上进行了评估，并将该方法与六种拜占庭攻击方法和六种防御算法进行了比较。实验结果表明，该方法具有良好的攻击性能，并且易于集成到现有的拜占庭攻击技术中。

Conclusion: 所提出的动态优化触发器的方法能够有效解耦拜占庭任务与主任务，增强了攻击的持久性和隐蔽性，并且易于集成到现有攻击技术中，在多种任务和防御场景下均表现出优越的性能。

Abstract: Federated learning allows multiple participants to collaboratively train a
central model without sharing their private data. However, this distributed
nature also exposes new attack surfaces. In particular, backdoor attacks allow
attackers to implant malicious behaviors into the global model while
maintaining high accuracy on benign inputs. Existing attacks usually rely on
fixed patterns or adversarial perturbations as triggers, which tightly couple
the main and backdoor tasks. This coupling makes them vulnerable to dilution by
honest updates and limits their persistence under federated defenses. In this
work, we propose an approach to decouple the backdoor task from the main task
by dynamically optimizing the backdoor trigger within a min-max framework. The
inner layer maximizes the performance gap between poisoned and benign samples,
ensuring that the contributions of benign users have minimal impact on the
backdoor. The outer process injects the adaptive triggers into the local model.
We evaluate our method on both computer vision and natural language tasks, and
compare it with six backdoor attack methods under six defense algorithms.
Experimental results show that our method achieves good attack performance and
can be easily integrated into existing backdoor attack techniques.

</details>


### [289] [Tackling GNARLy Problems: Graph Neural Algorithmic Reasoning Reimagined through Reinforcement Learning](https://arxiv.org/abs/2509.18930)
*Alex Schutz,Victor-Alexandru Darvariu,Efimia Panagiotaki,Bruno Lacerda,Nick Hawes*

Main category: cs.LG

TL;DR: 通过将学习算法轨迹的问题重塑为马尔可夫决策过程，并引入GNARL框架，我们改进了神经算法推理（NAR）的局限性，使其能够处理NP难问题，并且在没有专家算法的情况下也能适用。


<details>
  <summary>Details</summary>
Motivation: NAR范式在训练神经网络执行经典算法方面取得了成功，但存在一些局限性，包括无法独立构建有效解决方案、无法处理多个正确解决方案、在组合NP难问题上表现不佳以及无法应用于尚无已知有效算法的问题。

Method: 将学习算法轨迹重塑为马尔可夫决策过程，并提出GNARL框架，该框架包含将NAR问题转化为RL问题的方法以及适用于多种基于图的问题的学习架构。

Result: 在几个CLRS-30问题上实现了很高的图准确性，其在NP难问题上的性能与更窄的NAR方法相当或更优，并且即使在没有专家算法的情况下也具有适用性。

Conclusion: GNARL框架通过将NAR问题转化为RL问题，有效地解决了现有NAR方法的局限性，并在各种基于图的问题上展现出优越的性能，包括NP难问题和缺乏专家算法的问题。

Abstract: Neural Algorithmic Reasoning (NAR) is a paradigm that trains neural networks
to execute classic algorithms by supervised learning. Despite its successes,
important limitations remain: inability to construct valid solutions without
post-processing and to reason about multiple correct ones, poor performance on
combinatorial NP-hard problems, and inapplicability to problems for which
strong algorithms are not yet known. To address these limitations, we reframe
the problem of learning algorithm trajectories as a Markov Decision Process,
which imposes structure on the solution construction procedure and unlocks the
powerful tools of imitation and reinforcement learning (RL). We propose the
GNARL framework, encompassing the methodology to translate problem formulations
from NAR to RL and a learning architecture suitable for a wide range of
graph-based problems. We achieve very high graph accuracy results on several
CLRS-30 problems, performance matching or exceeding much narrower NAR
approaches for NP-hard problems and, remarkably, applicability even when
lacking an expert algorithm.

</details>


### [290] [Towards Privacy-Aware Bayesian Networks: A Credal Approach](https://arxiv.org/abs/2509.18949)
*Niccolò Rocchi,Fabio Stella,Cassio de Campos*

Main category: cs.LG

TL;DR: 本论文提出使用Credal Networks（CN）来平衡贝叶斯网络（BN）在隐私保护和模型效用之间的关系，通过掩码（masking）技术降低 추적 공격 (tracing attacks) 的成功率，同时保持模型的推理能力，并通过调整CN的超参数来控制隐私增益。


<details>
  <summary>Details</summary>
Motivation: 现有的贝叶斯网络（BN）在隐私保护方面存在不足， 추적 공격 (tracing attacks) 可以结合公开的BN和辅助数据来识别训练数据中的个体，而现有的隐私保护技术（如向学习到的参数中添加噪声）会显著影响模型的效用（准确性和显著性）。

Method: 提出使用Credal Networks（CN）作为一种新的解决方案来平衡模型的隐私和效用。CN是对BN的掩码（masking）版本，而不是添加噪声的版本。研究了 추적 공격 (tracing attacks) 在CN上的适用性，并证明CN可以降低攻击的成功率。识别出需要隐藏的关键学习信息以防止攻击者恢复底层的BN。通过数值实验分析CN超参数对隐私增益的调节作用。

Result: CN能够提供有意义的推理，同时保护隐私。CN相比于添加噪声的方法，在隐私保护和模型效用之间取得了更好的平衡。

Conclusion: CN为开发隐私感知的概率图模型提供了一种原则性、实用且有效的方法。

Abstract: Bayesian networks (BN) are probabilistic graphical models that enable
efficient knowledge representation and inference. These have proven effective
across diverse domains, including healthcare, bioinformatics and economics. The
structure and parameters of a BN can be obtained by domain experts or directly
learned from available data. However, as privacy concerns escalate, it becomes
increasingly critical for publicly released models to safeguard sensitive
information in training data. Typically, released models do not prioritize
privacy by design. In particular, tracing attacks from adversaries can combine
the released BN with auxiliary data to determine whether specific individuals
belong to the data from which the BN was learned. State-of-the-art protection
tecniques involve introducing noise into the learned parameters. While this
offers robust protection against tracing attacks, it significantly impacts the
model's utility, in terms of both the significance and accuracy of the
resulting inferences. Hence, high privacy may be attained at the cost of
releasing a possibly ineffective model. This paper introduces credal networks
(CN) as a novel solution for balancing the model's privacy and utility. After
adapting the notion of tracing attacks, we demonstrate that a CN enables the
masking of the learned BN, thereby reducing the probability of successful
attacks. As CNs are obfuscated but not noisy versions of BNs, they can achieve
meaningful inferences while safeguarding privacy. Moreover, we identify key
learning information that must be concealed to prevent attackers from
recovering the underlying BN. Finally, we conduct a set of numerical
experiments to analyze how privacy gains can be modulated by tuning the CN
hyperparameters. Our results confirm that CNs provide a principled, practical,
and effective approach towards the development of privacy-aware probabilistic
graphical models.

</details>


### [291] [Lift What You Can: Green Online Learning with Heterogeneous Ensembles](https://arxiv.org/abs/2509.18962)
*Kirsten Köbschall,Sebastian Buschjäger,Raphael Fischer,Lisa Hartung,Stefan Kramer*

Main category: cs.LG

TL;DR: HEROS通过选择资源受限的模型子集进行训练，以在预测能力和可持续性之间取得平衡，并提出了一种新的ζ-策略，可在较低成本下实现接近最优的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的流挖掘集成方法在管理和更新模型以适应数据分布变化时，计算成本高昂，未能充分考虑可持续性，因此需要一种更绿色的在线学习方法。

Method: 提出了一种名为HEROS（异构在线集成）的方法，该方法在训练期间根据资源限制选择模型子集进行训练。使用马尔可夫决策过程来捕捉预测性能和可持续性之间的权衡，并提出了一种新的ζ-策略，以较低的成本训练接近最优的模型。

Result: 在11个基准数据集上的实验表明，HEROS的ζ-策略在准确性方面具有高度竞争力，有时甚至优于现有方法，同时显著降低了资源消耗。

Conclusion: HEROS及其ζ-策略为实现绿色在线学习做出了重要贡献，能够有效地平衡预测性能和可持续性，为流挖掘提供了一种更经济高效的解决方案。

Abstract: Ensemble methods for stream mining necessitate managing multiple models and
updating them as data distributions evolve. Considering the calls for more
sustainability, established methods are however not sufficiently considerate of
ensemble members' computational expenses and instead overly focus on predictive
capabilities. To address these challenges and enable green online learning, we
propose heterogeneous online ensembles (HEROS). For every training step, HEROS
chooses a subset of models from a pool of models initialized with diverse
hyperparameter choices under resource constraints to train. We introduce a
Markov decision process to theoretically capture the trade-offs between
predictive performance and sustainability constraints. Based on this framework,
we present different policies for choosing which models to train on incoming
data. Most notably, we propose the novel $\zeta$-policy, which focuses on
training near-optimal models at reduced costs. Using a stochastic model, we
theoretically prove that our $\zeta$-policy achieves near optimal performance
while using fewer resources compared to the best performing policy. In our
experiments across 11 benchmark datasets, we find empiric evidence that our
$\zeta$-policy is a strong contribution to the state-of-the-art, demonstrating
highly accurate performance, in some cases even outperforming competitors, and
simultaneously being much more resource-friendly.

</details>


### [292] [Central Limit Theorems for Asynchronous Averaged Q-Learning](https://arxiv.org/abs/2509.18964)
*Xingtu Liu*

Main category: cs.LG

TL;DR: 本论文为异步更新下的 Polak-Ruppert 平均 Q-learning 建立了中心极限定理。


<details>
  <summary>Details</summary>
Motivation: 研究 Polak-Ruppert 平均 Q-learning 在异步更新下的统计特性，特别是其收敛性和统计分布。

Method: 推导了关于 Polak-Ruppert 平均 Q-learning 的非渐近中心极限定理和泛函中心极限定理。

Result: 得到了一个收敛率明确反映迭代次数、状态-动作空间大小、折扣因子和探索质量的 Wasserstein 距离的非渐近中心极限定理。此外，还推导了一个泛函中心极限定理，表明部分和过程弱收敛于布朗运动。

Conclusion: 证明了在异步更新下，Polak-Ruppert 平均 Q-learning 具有良好的统计特性，并且其收敛过程可以用中心极限定理来描述，甚至可以收敛到布朗运动。

Abstract: This paper establishes central limit theorems for Polyak-Ruppert averaged
Q-learning under asynchronous updates. We present a non-asymptotic central
limit theorem, where the convergence rate in Wasserstein distance explicitly
reflects the dependence on the number of iterations, state-action space size,
the discount factor, and the quality of exploration. In addition, we derive a
functional central limit theorem, showing that the partial-sum process
converges weakly to a Brownian motion.

</details>


### [293] [Otters: An Energy-Efficient SpikingTransformer via Optical Time-to-First-Spike Encoding](https://arxiv.org/abs/2509.18968)
*Zhanglu Yan,Jiayi Mao,Qianhui Liu,Fanfan Li,Gang Pan,Tao Luo,Bowen Zhu,Weng-Fai Wong*

Main category: cs.LG

TL;DR: 该论文提出了一种名为Otters的新型脉冲神经网络（SNN）硬件-软件协同设计，利用光电器件的自然信号衰减来优化时间-首次脉冲（TTFS）编码，从而实现高能效。


<details>
  <summary>Details</summary>
Motivation: 现有的SNN在实现高能效方面面临挑战，因为脉冲神经网络（SNN）中的时间衰减函数和突触权重乘法等计算成本高昂。

Method: 该论文提出了一种名为Otters的新型硬件-软件协同设计，利用光电器件（特别是氧化铟光电突触）的自然信号衰减来直接实现TTFS编码所需的时间衰减函数。此外，还引入了一种新颖的量化神经网络到SNN的转换算法，以解决复杂模型（如Transformer）的训练稀疏性问题。

Result: Otters在七个GLUE基准数据集上实现了最先进的准确性，并且在能效方面比以前的SNN领先模型提高了1.77倍。该结果是通过在商用22nm工艺上进行能耗测量和全面的计算、数据移动和内存访问成本分析得出的。

Conclusion: 该研究通过将器件的物理特性直接转化为计算原语，为高能效SNN开创了新范式，从而显著提高了性能和能效。

Abstract: Spiking neural networks (SNNs) promise high energy efficiency, particularly
with time-to-first-spike (TTFS) encoding, which maximizes sparsity by emitting
at most one spike per neuron. However, such energy advantage is often
unrealized because inference requires evaluating a temporal decay function and
subsequent multiplication with the synaptic weights. This paper challenges this
costly approach by repurposing a physical hardware `bug', namely, the natural
signal decay in optoelectronic devices, as the core computation of TTFS. We
fabricated a custom indium oxide optoelectronic synapse, showing how its
natural physical decay directly implements the required temporal function. By
treating the device's analog output as the fused product of the synaptic weight
and temporal decay, optoelectronic synaptic TTFS (named Otters) eliminates
these expensive digital operations. To use the Otters paradigm in complex
architectures like the transformer, which are challenging to train directly due
to the sparsity issue, we introduce a novel quantized neural network-to-SNN
conversion algorithm. This complete hardware-software co-design enables our
model to achieve state-of-the-art accuracy across seven GLUE benchmark datasets
and demonstrates a 1.77$\times$ improvement in energy efficiency over previous
leading SNNs, based on a comprehensive analysis of compute, data movement, and
memory access costs using energy measurements from a commercial 22nm process.
Our work thus establishes a new paradigm for energy-efficient SNNs, translating
fundamental device physics directly into powerful computational primitives. All
codes and data are open source.

</details>


### [294] [Learning From Simulators: A Theory of Simulation-Grounded Learning](https://arxiv.org/abs/2509.18990)
*Carson Dudley,Marisa Eisenberg*

Main category: cs.LG

TL;DR: SGNNs 是完全在模拟数据上训练的预测模型，具有理论基础，并能在数据有限的情况下实现科学预测。


<details>
  <summary>Details</summary>
Motivation: SGNNs 在现实世界标签有限或未被观察到的领域取得了最先进的性能，但缺乏正式的基础。本文旨在为模拟基础学习提供理论基础。

Method: 本文提出了模拟基础学习的理论基础，证明 SGNNs 实现了一个模拟先验下的摊销贝叶斯推断，并收敛到贝叶斯最优预测器。推导了模型误设下的泛化界限，并证明了 SGNNs 可以学习经验方法无法学习的不可观察的科学量。此外，还形式化了一种新颖的机械可解释性，通过将预测归因于生成它们的模拟机制，从而获得后验一致的、有科学依据的解释。

Result: 数值实验验证了所有理论预测。SGNNs 恢复了潜在参数，在不匹配的情况下保持鲁棒性，并且优于经典工具：在模型选择任务中，SGNNs 在区分机械动力学方面的误差是 AIC 的一半。

Conclusion: SGNNs 建立了一个有原则且实用的框架，用于在数据有限的情况下进行科学预测。

Abstract: Simulation-Grounded Neural Networks (SGNNs) are predictive models trained
entirely on synthetic data from mechanistic simulations. They have achieved
state-of-the-art performance in domains where real-world labels are limited or
unobserved, but lack a formal underpinning.
  We present the foundational theory of simulation-grounded learning. We show
that SGNNs implement amortized Bayesian inference under a simulation prior and
converge to the Bayes-optimal predictor. We derive generalization bounds under
model misspecification and prove that SGNNs can learn unobservable scientific
quantities that empirical methods provably cannot. We also formalize a novel
form of mechanistic interpretability uniquely enabled by SGNNs: by attributing
predictions to the simulated mechanisms that generated them, SGNNs yield
posterior-consistent, scientifically grounded explanations.
  We provide numerical experiments to validate all theoretical predictions.
SGNNs recover latent parameters, remain robust under mismatch, and outperform
classical tools: in a model selection task, SGNNs achieve half the error of AIC
in distinguishing mechanistic dynamics. These results establish SGNNs as a
principled and practical framework for scientific prediction in data-limited
regimes.

</details>


### [295] [CR-Net: Scaling Parameter-Efficient Training with Cross-Layer Low-Rank Structure](https://arxiv.org/abs/2509.18993)
*Boao Kong,Junzhu Liang,Yuxi Liu,Renjia Deng,Kun Yuan*

Main category: cs.LG

TL;DR: CR-Net是一种新的参数高效框架，通过利用跨层激活残差的低秩特性，在保持模型性能的同时，减少了参数复杂性、计算开销和内存需求，并在各种模型规模的实验中优于现有最先进的低秩方法。


<details>
  <summary>Details</summary>
Motivation: 现有的低秩方法在模型性能、计算开销和激活内存节省方面存在不足，需要更优化的解决方案。

Method: 提出CR-Net框架，采用对偶路径架构，结合前一层输出及其低秩差值来重构层激活，并开发了专门的激活重计算策略以降低内存需求。

Result: 在从60M到7B参数的模型规模的预训练实验中，CR-Net在性能上持续优于最先进的低秩框架，同时需要更少的计算资源和内存。

Conclusion: CR-Net通过利用跨层激活残差的低秩特性，成功解决了现有低秩方法的局限性，并在效率和性能方面取得了显著的改进。

Abstract: Low-rank architectures have become increasingly important for efficient large
language model (LLM) pre-training, providing substantial reductions in both
parameter complexity and memory/computational demands. Despite these
advantages, current low-rank methods face three critical shortcomings: (1)
compromised model performance, (2) considerable computational overhead, and (3)
limited activation memory savings. To address these limitations, we propose
Cross-layer Low-Rank residual Network (CR-Net), an innovative
parameter-efficient framework inspired by our discovery that inter-layer
activation residuals possess low-rank properties. CR-Net implements this
insight through a dual-path architecture that efficiently reconstructs layer
activations by combining previous-layer outputs with their low-rank
differences, thereby maintaining high-rank information with minimal parameters.
We further develop a specialized activation recomputation strategy tailored for
CR-Net that dramatically reduces memory requirements. Extensive pre-training
experiments across model scales from 60M to 7B parameters demonstrate that
CR-Net consistently outperforms state-of-the-art low-rank frameworks while
requiring fewer computational resources and less memory.

</details>


### [296] [Theoretical Foundations of Representation Learning using Unlabeled Data: Statistics and Optimization](https://arxiv.org/abs/2509.18997)
*Pascal Esser,Maximilian Fleissner,Debarghya Ghoshdastidar*

Main category: cs.LG

TL;DR: 深度学习在无监督表征学习方面取得了巨大成功，但其背后的理论基础尚不明确。本文概述了该领域的最新理论进展，并结合了统计学和优化领域的数学工具。


<details>
  <summary>Details</summary>
Motivation: 当前的深度学习模型在无监督表征学习方面采用了新的原理，这些原理难以用经典的统计学理论进行分析。尤其是在视觉基础模型领域，尽管自监督学习和掩码自编码器等技术取得了巨大成功，但我们仍然难以准确描述其学到的表征，也无法解释它们为何能适用于各种预测任务或表现出涌现行为。

Method: 本文旨在结合统计学和优化领域的数学工具，为无监督表征学习提供理论分析基础。论文将概述该领域的最新理论进展，并介绍作者在该方向上的贡献。

Result: 本文对无监督表征学习领域的最新理论进展进行了概述。

Conclusion: 需要结合统计学和优化领域的数学工具来深入理解深度学习模型在无监督表征学习方面的表现。

Abstract: Representation learning from unlabeled data has been extensively studied in
statistics, data science and signal processing with a rich literature on
techniques for dimension reduction, compression, multi-dimensional scaling
among others. However, current deep learning models use new principles for
unsupervised representation learning that cannot be easily analyzed using
classical theories. For example, visual foundation models have found tremendous
success using self-supervision or denoising/masked autoencoders, which
effectively learn representations from massive amounts of unlabeled data.
However, it remains difficult to characterize the representations learned by
these models and to explain why they perform well for diverse prediction tasks
or show emergent behavior. To answer these questions, one needs to combine
mathematical tools from statistics and optimization. This paper provides an
overview of recent theoretical advances in representation learning from
unlabeled data and mentions our contributions in this direction.

</details>


### [297] [Fully Learnable Neural Reward Machines](https://arxiv.org/abs/2509.19017)
*Hazem Dewidar,Elena Umili*

Main category: cs.LG

TL;DR: 可学习的神经奖励机（NRM）可以端到端地学习符号映射（SG）函数和自动机，从而无需先验知识，并且比基于RNN的方法更具可解释性且性能更优。


<details>
  <summary>Details</summary>
Motivation: 解决非马尔可夫强化学习（RL）任务中的挑战，这些任务需要智能体对整个状态-动作对轨迹进行推理才能做出最优决策。

Method: 提出一种完全可学习的神经奖励机（NRM），能够端到端地学习符号映射（SG）函数和自动机，无需任何先验知识。

Result: 与先前基于循环神经网络（RNN）的方法相比，所提出的完全可学习奖励机（FLNRM）与深度强化学习（DRL）的结合可以带来更好的性能。

Conclusion: 所提出的完全可学习奖励机（FLNRM）能够端到端地学习符号映射（SG）函数和自动机，无需任何先验知识，与经典深度强化学习（DRL）方法一样易于应用，并且由于自动机的有限和紧凑的性质而更具可解释性。此外，它在与DRL结合时，其性能优于先前基于循环神经网络（RNN）的方法。

Abstract: Non-Markovian Reinforcement Learning (RL) tasks present significant
challenges, as agents must reason over entire trajectories of state-action
pairs to make optimal decisions. A common strategy to address this is through
symbolic formalisms, such as Linear Temporal Logic (LTL) or automata, which
provide a structured way to express temporally extended objectives. However,
these approaches often rely on restrictive assumptions -- such as the
availability of a predefined Symbol Grounding (SG) function mapping raw
observations to high-level symbolic representations, or prior knowledge of the
temporal task. In this work, we propose a fully learnable version of Neural
Reward Machines (NRM), which can learn both the SG function and the automaton
end-to-end, removing any reliance on prior knowledge. Our approach is therefore
as easily applicable as classic deep RL (DRL) approaches, while being far more
explainable, because of the finite and compact nature of automata. Furthermore,
we show that by integrating Fully Learnable Reward Machines (FLNRM) with DRL,
our method outperforms previous approaches based on Recurrent Neural Networks
(RNNs).

</details>


### [298] [OmniBridge: Unified Multimodal Understanding, Generation, and Retrieval via Latent Space Alignment](https://arxiv.org/abs/2509.19018)
*Teng Xiao,Zuchao Li,Lefei Zhang*

Main category: cs.LG

TL;DR: OmniBridge是一个统一的、模块化的多模态框架，支持视觉-语言理解、生成和检索任务，采用语言中心设计，通过轻量级双向潜在对齐模块和解耦训练策略，实现了跨模态任务的最优性能。


<details>
  <summary>Details</summary>
Motivation: 当前多模态大模型在处理理解、生成和检索任务时存在各自为战、训练成本高、跨模态泛化能力有限等问题。

Method: OmniBridge采用语言中心设计，复用预训练语言模型，并引入轻量级双向潜在对齐模块。通过两阶段解耦训练策略：监督微调和潜在空间对齐，以及语义引导的扩散训练，来统一多模态建模。

Result: 在多个基准测试中，OmniBridge在理解、生成和检索三个任务上均取得了具有竞争力的甚至是最优的性能。

Conclusion: 潜在空间对齐是统一多模态建模、实现共享表示空间的有效方法。

Abstract: Recent advances in multimodal large language models (LLMs) have led to
significant progress in understanding, generation, and retrieval tasks.
However, current solutions often treat these tasks in isolation or require
training LLMs from scratch, resulting in high computational costs and limited
generalization across modalities. In this work, we present OmniBridge, a
unified and modular multimodal framework that supports vision-language
understanding, generation, and retrieval within a unified architecture.
OmniBridge adopts a language-centric design that reuses pretrained LLMs and
introduces a lightweight bidirectional latent alignment module. To address the
challenge of task interference, we propose a two-stage decoupled training
strategy: supervised fine-tuning and latent space alignment for aligning LLM
behavior with multimodal reasoning, and semantic-guided diffusion training to
align cross-modal latent spaces via learnable query embeddings. Extensive
experiments across a wide range of benchmarks demonstrate that OmniBridge
achieves competitive or state-of-the-art performance in all three tasks.
Moreover, our results highlight the effectiveness of latent space alignment for
unifying multimodal modeling under a shared representation space. Code and
models are released at https://github.com/xiao-xt/OmniBridge.

</details>


### [299] [Improving Credit Card Fraud Detection through Transformer-Enhanced GAN Oversampling](https://arxiv.org/abs/2509.19032)
*Kashaf Ul Emaan*

Main category: cs.LG

TL;DR: 该研究提出了一种基于Transformer编码器块的生成对抗网络（GAN），用于生成逼真的欺诈交易样本，以解决信用卡欺诈检测中数据不平衡的问题，并在召回率、F1分数和AUC方面取得了显著的改进。


<details>
  <summary>Details</summary>
Motivation: 信用卡欺诈检测面临着交易数据集高度不平衡的问题，传统的过采样方法（如SMOTE）生成的样本过于简单，难以应对复杂的欺诈模式。现有的CTGAN和TVAE模型在表格合成方面效率更高，但在高维依赖建模方面仍存在问题。

Method: 提出了一种混合方法，结合了生成对抗网络（GAN）和Transformer编码器块，以生成逼真的欺诈交易样本。GAN架构允许训练逼真的生成器，而Transformer通过自注意力机制学习丰富的特征交互。

Result: 在公开的信用卡欺诈检测数据集上进行测试，并与传统的和生成重采样策略以及多种分类器（如逻辑回归、随机森林、极端梯度提升和支持向量机）进行比较。结果表明，所提出的基于Transformer的GAN在召回率、F1分数和AUC方面显示出显著的优势。

Conclusion: 所提出的基于Transformer的GAN在克服欺诈检测任务中固有的严重类别不平衡问题方面是有效的。

Abstract: Detection of credit card fraud is an acute issue of financial security
because transaction datasets are highly lopsided, with fraud cases being only a
drop in the ocean. Balancing datasets using the most popular methods of
traditional oversampling such as the Synthetic Minority Oversampling Technique
(SMOTE) generally create simplistic synthetic samples that are not readily
applicable to complex fraud patterns. Recent industry advances that include
Conditional Tabular Generative Adversarial Networks (CTGAN) and Tabular
Variational Autoencoders (TVAE) have demonstrated increased efficiency in
tabular synthesis, yet all these models still exhibit issues with
high-dimensional dependence modelling. Now we will present our hybrid approach
where we use a Generative Adversarial Network (GAN) with a Transformer encoder
block to produce realistic fraudulent transactions samples. The GAN
architecture allows training realistic generators adversarial, and the
Transformer allows the model to learn rich feature interactions by
self-attention. Such a hybrid strategy overcomes the limitations of SMOTE,
CTGAN, and TVAE by producing a variety of high-quality synthetic minority
classes samples. We test our algorithm on the publicly-available Credit Card
Fraud Detection dataset and compare it to conventional and generative
resampling strategies with a variety of classifiers, such as Logistic
Regression (LR), Random Forest (RF), Extreme Gradient Boosting (XGBoost), and
Support Vector Machine (SVM). Findings indicate that our Transformer-based GAN
shows substantial gains in Recall, F1-score and Area Under the Receiver
Operating Characteristic Curve (AUC), which indicates that it is effective in
overcoming the severe class imbalance inherent in the task of fraud detection.

</details>


### [300] [Latent Danger Zone: Distilling Unified Attention for Cross-Architecture Black-box Attacks](https://arxiv.org/abs/2509.19044)
*Yang Li,Chenyu Wang,Tingrui Wang,Yongwei Wang,Haonan Li,Zhunga Liu,Quan Pan*

Main category: cs.LG

TL;DR: JAD是一个利用潜在扩散模型进行黑盒对抗性攻击的框架，通过融合CNN和ViT的注意力图来生成能够有效跨不同模型迁移的对抗样本，从而提高攻击的泛化性和效率。


<details>
  <summary>Details</summary>
Motivation: 现有的黑盒对抗性攻击方法在模型内部信息获取有限的情况下，往往受限于特定的网络架构或需要大量的查询次数，导致跨架构迁移能力有限且查询成本高。

Method: JAD利用潜在扩散模型，并结合从卷积神经网络（CNN）和视觉Transformer（ViT）模型中提取的注意力图进行指导，生成对抗性样本。通过关注跨架构普遍敏感的图像区域，该方法能够生成在不同模型类型之间有效迁移的对抗性扰动。

Result: 实验表明，与现有方法相比，JAD在攻击泛化性、生成效率和跨架构迁移能力方面表现更优。

Conclusion: JAD通过联合注意力蒸馏策略，实现了模型无关性，并在各种模型上实现了优越的攻击泛化能力。此外，扩散模型的生成特性通过减少对迭代查询的依赖，提高了对抗样本生成的效率，为黑盒对抗性攻击提供了一种有前景且有效的方法。

Abstract: Black-box adversarial attacks remain challenging due to limited access to
model internals. Existing methods often depend on specific network
architectures or require numerous queries, resulting in limited
cross-architecture transferability and high query costs. To address these
limitations, we propose JAD, a latent diffusion model framework for black-box
adversarial attacks. JAD generates adversarial examples by leveraging a latent
diffusion model guided by attention maps distilled from both a convolutional
neural network (CNN) and a Vision Transformer (ViT) models. By focusing on
image regions that are commonly sensitive across architectures, this approach
crafts adversarial perturbations that transfer effectively between different
model types. This joint attention distillation strategy enables JAD to be
architecture-agnostic, achieving superior attack generalization across diverse
models. Moreover, the generative nature of the diffusion framework yields high
adversarial sample generation efficiency by reducing reliance on iterative
queries. Experiments demonstrate that JAD offers improved attack
generalization, generation efficiency, and cross-architecture transferability
compared to existing methods, providing a promising and effective paradigm for
black-box adversarial attacks.

</details>


### [301] [Beyond Backpropagation: Exploring Innovative Algorithms for Energy-Efficient Deep Neural Network Training](https://arxiv.org/abs/2509.19063)
*Przemysław Spyra*

Main category: cs.LG

TL;DR: 该论文研究了三种反向传播（BP）之外的训练方法（前馈-前馈 FF、级联前馈 CaFo 和单前馈 MF），并将其与 BP 训练进行比较。结果显示 MF 在 MLP 上优于 BP 训练，并且在能源消耗和训练时间方面更具优势。


<details>
  <summary>Details</summary>
Motivation: 深度神经网络（DNN）的计算和能源需求日益增长，这主要由反向传播（BP）引起，对可持续人工智能（AI）的发展构成了挑战。

Method: 该研究建立了一个强大的比较框架，在各自的原生架构（MLP 用于 FF 和 MF，CNN 用于 CaFo）上实现了每种算法，并与等效的 BP 训练模型进行了基准测试。使用 Optuna 优化了超参数，并根据验证性能应用了持续的提前停止标准，以确保所有模型在比较前都经过最佳调整。

Result: MF 不仅在 MLP 上可以与 BP 媲美，而且在分类精度上持续超越 BP。其优越的泛化能力源于收敛到验证损失格局中更有利的最小值，这挑战了需要全局优化才能获得最先进结果的假设。MF 将能源消耗和训练时间分别减少了高达 41% 和 34%。

Conclusion: 通过记录从 FF 的概念基础到 MF 的准确性和可持续性的综合，这项工作为未来节能深度学习提供了清晰、数据驱动的路线图。

Abstract: The rising computational and energy demands of deep neural networks (DNNs),
driven largely by backpropagation (BP), challenge sustainable AI development.
This paper rigorously investigates three BP-free training methods: the
Forward-Forward (FF), Cascaded-Forward (CaFo), and Mono-Forward (MF)
algorithms, tracing their progression from foundational concepts to a
demonstrably superior solution.
  A robust comparative framework was established: each algorithm was
implemented on its native architecture (MLPs for FF and MF, a CNN for CaFo) and
benchmarked against an equivalent BP-trained model. Hyperparameters were
optimized with Optuna, and consistent early stopping criteria were applied
based on validation performance, ensuring all models were optimally tuned
before comparison.
  Results show that MF not only competes with but consistently surpasses BP in
classification accuracy on its native MLPs. Its superior generalization stems
from converging to a more favorable minimum in the validation loss landscape,
challenging the assumption that global optimization is required for
state-of-the-art results. Measured at the hardware level using the NVIDIA
Management Library (NVML) API, MF reduces energy consumption by up to 41% and
shortens training time by up to 34%, translating to a measurably smaller carbon
footprint as estimated by CodeCarbon.
  Beyond this primary result, we present a hardware-level analysis that
explains the efficiency gains: exposing FF's architectural inefficiencies,
validating MF's computationally lean design, and challenging the assumption
that all BP-free methods are inherently more memory-efficient. By documenting
the evolution from FF's conceptual groundwork to MF's synthesis of accuracy and
sustainability, this work offers a clear, data-driven roadmap for future
energy-efficient deep learning.

</details>


### [302] [Diffusion Bridge Variational Inference for Deep Gaussian Processes](https://arxiv.org/abs/2509.19078)
*Jian Xu,Qibin Zhao,John Paisley,Delu Zeng*

Main category: cs.LG

TL;DR: DDVI的改进版DBVI，通过学习数据依赖的初始分布来提高深度高斯过程推理的效率和准确性。


<details>
  <summary>Details</summary>
Motivation: 现有的DDVI方法在深度高斯过程的推理中存在收敛慢和效率低的问题，因为其固定的先验分布与真实后验分布差距过大。

Method: 提出了一种称为扩散桥变分推理（DBVI）的改进方法，通过学习一个数据依赖的初始分布来替代DDVI中固定的先验分布。该初始分布由一个自适应神经网络参数化，并利用ELBO目标函数的梯度进行优化，从而减小了后验差距，提高了样本效率。该神经网络被设计为作用于诱导输入，以实现可扩展的摊销。

Result: DBVI在回归、分类和图像重建任务中，在预测精度、收敛速度和后验质量方面均优于DDVI和其他变分基线。

Conclusion: DBVI作为DDVI的原则性扩展，通过引入可学习的、数据依赖的初始分布，能够显著提高深度高斯过程推理的效率和准确性，并且在各种任务中都取得了优于现有方法的性能。

Abstract: Deep Gaussian processes (DGPs) enable expressive hierarchical Bayesian
modeling but pose substantial challenges for posterior inference, especially
over inducing variables. Denoising diffusion variational inference (DDVI)
addresses this by modeling the posterior as a time-reversed diffusion from a
simple Gaussian prior. However, DDVI's fixed unconditional starting
distribution remains far from the complex true posterior, resulting in
inefficient inference trajectories and slow convergence. In this work, we
propose Diffusion Bridge Variational Inference (DBVI), a principled extension
of DDVI that initiates the reverse diffusion from a learnable, data-dependent
initial distribution. This initialization is parameterized via an amortized
neural network and progressively adapted using gradients from the ELBO
objective, reducing the posterior gap and improving sample efficiency. To
enable scalable amortization, we design the network to operate on the inducing
inputs, which serve as structured, low-dimensional summaries of the dataset and
naturally align with the inducing variables' shape. DBVI retains the
mathematical elegance of DDVI, including Girsanov-based ELBOs and reverse-time
SDEs,while reinterpreting the prior via a Doob-bridged diffusion process. We
derive a tractable training objective under this formulation and implement DBVI
for scalable inference in large-scale DGPs. Across regression, classification,
and image reconstruction tasks, DBVI consistently outperforms DDVI and other
variational baselines in predictive accuracy, convergence speed, and posterior
quality.

</details>


### [303] [Graph Neural Networks with Similarity-Navigated Probabilistic Feature Copying](https://arxiv.org/abs/2509.19084)
*Asela Hevapathige*

Main category: cs.LG

TL;DR: AxelGNN是一种受Axelrod文化传播模型启发的新型图神经网络（GNN）架构，通过引入相似性门控概率交互、基于特征的复制机制和全局极化来解决GNN中的特征平滑、异构关系处理和特征向量完整性问题，并在节点分类和影响估计任务上取得了优于或持平的性能。


<details>
  <summary>Details</summary>
Motivation: 现有图神经网络（GNN）在特征平滑、异构关系处理和特征向量的整体性处理方面存在局限性。

Method: 提出了一种名为AxelGNN的新型GNN架构，该架构受Axelrod文化传播模型的启发，通过以下方式解决现有GNN的局限性：1. 引入相似性门控概率交互：该机制根据节点相似性自适应地促进收敛或发散。2. 实现基于特征的复制机制：在片段级别进行细粒度的特征聚合。3. 保持全局极化：在多个表示簇中保持节点的独特性。该模型的双稳态收敛动力学能够在一个架构中同时处理同质和异质图。

Result: 在节点分类和影响估计基准测试中，AxelGNN在各种同质/异质特征的图结构上，持续优于或持平于最先进的GNN方法。

Conclusion: AxelGNN通过其新颖的架构和机制，成功地解决了现有GNN面临的关键挑战，并在多项基准测试中展现出优越的性能。

Abstract: Graph Neural Networks (GNNs) have demonstrated remarkable success across
various graph-based tasks. However, they face some fundamental limitations:
feature oversmoothing can cause node representations to become
indistinguishable in deeper networks, they struggle to effectively manage
heterogeneous relationships where connected nodes differ significantly, and
they process entire feature vectors as indivisible units, which limits
flexibility. We seek to address these limitations. We propose AxelGNN, a novel
GNN architecture inspired by Axelrod's cultural dissemination model that
addresses these limitations through a unified framework. AxelGNN incorporates
similarity-gated probabilistic interactions that adaptively promote convergence
or divergence based on node similarity, implements trait-level copying
mechanisms for fine-grained feature aggregation at the segment level, and
maintains global polarization to preserve node distinctiveness across multiple
representation clusters. The model's bistable convergence dynamics naturally
handle both homophilic and heterophilic graphs within a single architecture.
Extensive experiments on node classification and influence estimation
benchmarks demonstrate that AxelGNN consistently outperforms or matches
state-of-the-art GNN methods across diverse graph structures with varying
homophily-heterophily characteristics.

</details>


### [304] [Asymptotically Optimal Problem-Dependent Bandit Policies for Transfer Learning](https://arxiv.org/abs/2509.19098)
*Adrien Prevost,Timothee Mathieu,Odalric-Ambrym Maillard*

Main category: cs.LG

TL;DR: 该研究提出了KL-UCB-Transfer算法，用于解决迁移学习场景下的非上下文多臂老虎机问题，并在理论和实践上证明了其有效性。


<details>
  <summary>Details</summary>
Motivation: 在迁移学习的设定下，研究非上下文多臂老虎机问题，并考虑源数据和目标数据之间的距离约束。

Method: Derive a problem-dependent asymptotic lower bound on cumulative regret that extends the classical Lai-Robbins result to incorporate the transfer parameters (d_k, L_k, N'_k). Propose KL-UCB-Transfer, a simple index policy that matches this new bound in the Gaussian case.

Result: 推导了考虑迁移参数的累积遗憾的渐近下界，并提出了KL-UCB-Transfer算法，该算法在Gaussian情况下匹配此新界限。

Conclusion: KL-UCB-Transfer算法在源数据和目标数据足够接近时，显著优于无先验基线。

Abstract: We study the non-contextual multi-armed bandit problem in a transfer learning
setting: before any pulls, the learner is given N'_k i.i.d. samples from each
source distribution nu'_k, and the true target distributions nu_k lie within a
known distance bound d_k(nu_k, nu'_k) <= L_k. In this framework, we first
derive a problem-dependent asymptotic lower bound on cumulative regret that
extends the classical Lai-Robbins result to incorporate the transfer parameters
(d_k, L_k, N'_k). We then propose KL-UCB-Transfer, a simple index policy that
matches this new bound in the Gaussian case. Finally, we validate our approach
via simulations, showing that KL-UCB-Transfer significantly outperforms the
no-prior baseline when source and target distributions are sufficiently close.

</details>


### [305] [Algorithms for Adversarially Robust Deep Learning](https://arxiv.org/abs/2509.19100)
*Alexander Robey*

Main category: cs.LG

TL;DR: 深度学习模型在安全关键应用中越来越普及，因此确保其决策能够抵御对抗性攻击至关重要。本论文探讨了旨在提高模型鲁棒性的算法的最新进展。我们首先讨论计算机视觉中的对抗性样本问题，并提出新的技术成果、训练范式和认证算法。然后，我们研究领域泛化问题，即训练神经网络以适应未见过的测试分布。我们提出了在医学成像、分子识别和图像分类等领域达到最先进泛化能力的新算法。最后，我们研究大型语言模型（LLM）的越狱问题，即攻击者试图诱导 LLM 生成不当内容。我们提出了新的攻击和防御方法，以推动基于语言的智能体在鲁棒性方面的发展。


<details>
  <summary>Details</summary>
Motivation: 确保深度学习模型在安全关键应用中的决策能够抵御对抗性攻击，并在计算机视觉、领域泛化（特别是在医学成像、分子识别和图像分类中）以及大型语言模型的越狱问题上实现更强的鲁棒性和泛化能力。

Method: 在计算机视觉领域，提出了新的技术成果、训练范式和认证算法来解决对抗性样本问题。在领域泛化方面，提出了新的算法以提高在医学成像、分子识别和图像分类中的泛化能力。在大型语言模型方面，提出了新的攻击和防御方法来应对越狱问题。

Result: 在计算机视觉领域取得了关于对抗性样本的新技术成果、训练范式和认证算法。在领域泛化方面，提出的新算法在医学成像、分子识别和图像分类中达到了最先进的泛化能力。在大型语言模型方面，提出的新攻击和防御方法代表了在设计鲁棒语言智能体方面的前沿进展。

Conclusion: 本论文在提高深度学习模型（包括计算机视觉模型和大型语言模型）的鲁棒性方面取得了显著进展，并在领域泛化任务中实现了最先进的性能。

Abstract: Given the widespread use of deep learning models in safety-critical
applications, ensuring that the decisions of such models are robust against
adversarial exploitation is of fundamental importance. In this thesis, we
discuss recent progress toward designing algorithms that exhibit desirable
robustness properties. First, we discuss the problem of adversarial examples in
computer vision, for which we introduce new technical results, training
paradigms, and certification algorithms. Next, we consider the problem of
domain generalization, wherein the task is to train neural networks to
generalize from a family of training distributions to unseen test
distributions. We present new algorithms that achieve state-of-the-art
generalization in medical imaging, molecular identification, and image
classification. Finally, we study the setting of jailbreaking large language
models (LLMs), wherein an adversarial user attempts to design prompts that
elicit objectionable content from an LLM. We propose new attacks and defenses,
which represent the frontier of progress toward designing robust language-based
agents.

</details>


### [306] [DRO-REBEL: Distributionally Robust Relative-Reward Regression for Fast and Efficient LLM Alignment](https://arxiv.org/abs/2509.19104)
*Sharan Sahu,Martin T. Wells*

Main category: cs.LG

TL;DR: RLHF 领域的现有离线方法存在过优化问题，会导致模型过拟合奖励错误指定并偏离训练期间观察到的首选行为。本研究提出了 DRO-REBEL，这是一类统一的、基于 Wasserstein、KL 和 χ2 模糊集的鲁棒 REBEL 更新方法。


<details>
  <summary>Details</summary>
Motivation: 解决现有离线 RLHF 方法在模型对奖励的错误指定上过拟合，以及在训练过程中偏离首选行为的问题。

Method: 提出了一种名为 DRO-REBEL 的新方法，该方法包含基于 Wasserstein、KL 和 χ2 模糊集的鲁棒 REBEL 更新。该方法利用 Fenchel 对偶将更新简化为相对奖励回归，避免了 PPO 风格的裁剪或辅助值网络，并具有良好的可扩展性。

Result: 在标准线性奖励和对数线性策略类别以及数据覆盖条件下，证明了该方法具有 O(n^{-1/4}) 的估计界限，优于现有的 DRO-DPO 方法。通过局部 Rademacher 复杂性分析，实现了 O(n^{-1/2}) 的 minimax-optimal 速率。在 Emotion Alignment、ArmoRM 和 HH-Alignment 等基准测试中，该方法在面对未见的偏好混合、模型大小和数据尺度时，表现出强大的最坏情况鲁棒性。

Conclusion: DRO-REBEL 提供了一种统一的、鲁棒的 RLHF 更新方法，在理论和实践上都优于现有方法，并揭示了半径-覆盖率权衡中的“没有免费午餐”现象。

Abstract: Reinforcement learning with human feedback (RLHF) has become crucial for
aligning Large Language Models (LLMs) with human intent. However, existing
offline RLHF approaches suffer from overoptimization, where models overfit to
reward misspecification and drift from preferred behaviors observed during
training. We introduce DRO-REBEL, a unified family of robust REBEL updates with
type-$p$ Wasserstein, KL, and $\chi^2$ ambiguity sets. Using Fenchel duality,
each update reduces to a simple relative-reward regression, preserving
scalability and avoiding PPO-style clipping or auxiliary value networks. Under
standard linear-reward and log-linear policy classes with a data-coverage
condition, we establish $O(n^{-1/4})$ estimation bounds with tighter constants
than prior DRO-DPO approaches, and recover the minimax-optimal $O(n^{-1/2})$
rate via a localized Rademacher complexity analysis. The same analysis closes
the gap for Wasserstein-DPO and KL-DPO, showing both also attain optimal
parametric rates. We derive practical SGD algorithms for all three divergences:
gradient regularization (Wasserstein), importance weighting (KL), and a fast
1-D dual solve ($\chi^2$). Experiments on Emotion Alignment, the large-scale
ArmoRM multi-objective benchmark, and HH-Alignment demonstrate strong
worst-case robustness across unseen preference mixtures, model sizes, and data
scales, with $\chi^2$-REBEL showing consistently strong empirical performance.
A controlled radius--coverage study validates a no-free-lunch trade-off: radii
shrinking faster than empirical divergence concentration rates achieve
minimax-optimal parametric rates but forfeit coverage, while
coverage-guaranteeing radii incur $O(n^{-1/4})$ rates.

</details>


### [307] [Towards Practical Multi-label Causal Discovery in High-Dimensional Event Sequences via One-Shot Graph Aggregation](https://arxiv.org/abs/2509.19112)
*Hugo Math,Rainer Lienhart*

Main category: cs.LG

TL;DR: CARGO是一种用于稀疏、高维事件序列的多标签因果发现方法，它利用预训练的因果Transformer来推断因果图，并通过自适应频率融合进行聚合，以重建标签的全局马尔可夫边界。


<details>
  <summary>Details</summary>
Motivation: 理解事件序列中的因果关系，特别是像疾病或系统故障这样的结果标签，以及像症状或错误代码这样的前置事件，对于医疗保健或车辆诊断等领域至关重要，但仍是一个未解决的挑战。

Method: CARGO利用两个预训练的因果Transformer作为事件序列的领域特定基础模型。它并行推断每个序列的单次因果图，并使用自适应频率融合进行聚合，以重建标签的全局马尔可夫边界。这种两阶段方法能够在规模上进行有效的概率推理，同时避免了对整个数据集进行条件独立性测试的不可行成本。

Result: 在具有超过29,100个唯一事件类型和474个不平衡标签的具有挑战性的真实世界汽车故障预测数据集上，CARGO展示了其执行结构化推理的能力。

Conclusion: CARGO是一种可扩展的多标签因果发现方法，能够处理稀疏、高维事件序列，并在真实世界数据上有效地进行因果推理。

Abstract: Understanding causality in event sequences where outcome labels such as
diseases or system failures arise from preceding events like symptoms or error
codes is critical. Yet remains an unsolved challenge across domains like
healthcare or vehicle diagnostics. We introduce CARGO, a scalable multi-label
causal discovery method for sparse, high-dimensional event sequences comprising
of thousands of unique event types. Using two pretrained causal Transformers as
domain-specific foundation models for event sequences. CARGO infers in
parallel, per sequence one-shot causal graphs and aggregates them using an
adaptive frequency fusion to reconstruct the global Markov boundaries of
labels. This two-stage approach enables efficient probabilistic reasoning at
scale while bypassing the intractable cost of full-dataset conditional
independence testing. Our results on a challenging real-world automotive fault
prediction dataset with over 29,100 unique event types and 474 imbalanced
labels demonstrate CARGO's ability to perform structured reasoning.

</details>


### [308] [Analysis on distribution and clustering of weight](https://arxiv.org/abs/2509.19122)
*Chunming Ye,Wenquan Tian,Yalan Gao,Songzhou Li*

Main category: cs.LG

TL;DR: 本文提出两种向量（标准差向量和聚类向量）来描述大型语言模型权重特征，用于分析模型间的相关性和差异性。


<details>
  <summary>Details</summary>
Motivation: 研究大型语言模型架构和参数特征，特别是权重特征，以分析模型间的相关性和差异性。

Method: 提出两种向量：1. 标准差向量：假设权重服从正态分布，对投影矩阵的标准差值进行归一化得到。2. 聚类向量：提取每个权重投影矩阵的奇异值，并使用K-Means算法进行分组，将同类型矩阵的分组数据合并得到。

Result: 这两种向量能有效区分不同模型，并展示同家族模型的相似性。LoRA微调实验表明，标准差向量受数据集影响，而聚类向量基本不受影响，与预训练模型保持高度一致。

Conclusion: 标准差向量能反映模型权重分布受数据集影响的特征，而聚类向量则能捕捉模型权重间不受微调影响的相关性，两者结合可全面分析模型特征。

Abstract: The study on architecture and parameter characteristics remains the hot topic
in the research of large language models. In this paper we concern with the
characteristics of weight which are used to analyze the correlations and
differences between models. Two kinds of vectors-standard deviation vector and
clustering vector-are proposed to describe features of models. In the first
case, the weights are assumed to follow normal distribution. The standard
deviation values of projection matrices are normalized to form
Standard-Deviation Vector, representing the distribution characteristics of
models. In the second case, the singular values from each weight projection
matrix are extracted and grouped by K-Means algorithm. The grouped data with
the same type matrix are combined as Clustering Vector to represent the
correlation characteristics of models' weights. The study reveals that these
two vectors can effectively distinguish between different models and clearly
show the similarities among models of the same family. Moreover, after
conducting LoRA fine-tuning with different datasets and models, it is found
that the distribution of weights represented by standard deviation vector is
directly influenced by the dataset, but the correlations between different
weights represented by clustering vector remain unaffected and maintain a high
consistency with the pre-trained model.

</details>


### [309] [PipelineRL: Faster On-policy Reinforcement Learning for Long Sequence Generatio](https://arxiv.org/abs/2509.19128)
*Alexandre Piché,Ehsan Kamaloo,Rafael Pardinas,Dzmitry Bahdanau*

Main category: cs.LG

TL;DR: PipelineRL通过在LLM训练中引入


<details>
  <summary>Details</summary>
Motivation: RL方法在提升LLM推理能力方面有潜力，但现有方法面临扩展性挑战，难以在高AI加速器利用率和数据新鲜度之间取得平衡。

Method: PipelineRL提出了一种并发异步数据生成和模型训练的方法，其核心是“in-flight weight updates”机制，允许在生成序列的同时以最小中断更新模型权重，从而提高加速器利用率和数据新鲜度。

Result: 在长篇推理任务的实验中，使用128个H100 GPU，PipelineRL的学习速度约是传统RL基线的两倍，同时保持了高比例的on-policy训练数据。

Conclusion: PipelineRL在LLM训练中实现了硬件效率和数据on-policyness的更优 trade-off，并且开源了一个可扩展的实现版本。

Abstract: Reinforcement Learning (RL) is increasingly utilized to enhance the reasoning
capabilities of Large Language Models (LLMs). However, effectively scaling
these RL methods presents significant challenges, primarily due to the
difficulty in maintaining high AI accelerator utilization without generating
stale, off-policy data that harms common RL algorithms. This paper introduces
PipelineRL, an approach designed to achieve a superior trade-off between
hardware efficiency and data on-policyness for LLM training. PipelineRL employs
concurrent asynchronous data generation and model training, distinguished by
the novel in-flight weight updates. This mechanism allows the LLM generation
engine to receive updated model weights with minimal interruption during the
generation of token sequences, thereby maximizing both the accelerator
utilization and the freshness of training data. Experiments conducted on
long-form reasoning tasks using 128 H100 GPUs demonstrate that PipelineRL
achieves approximately $\sim 2x$ faster learning compared to conventional RL
baselines while maintaining highly on-policy training data. A scalable and
modular open-source implementation of PipelineRL is also released as a key
contribution.

</details>


### [310] [GSTM-HMU: Generative Spatio-Temporal Modeling for Human Mobility Understanding](https://arxiv.org/abs/2509.19135)
*Wenying Luo,Zhiyuan Lin,Wenhao Xu,Minghao Liu,Zhi Li*

Main category: cs.LG

TL;DR: GSTM-HMU是一个生成式时空框架，通过整合地理位置、POI类别语义和周期性时间节奏，并考虑用户意图和生活方式模式，来分析人类移动轨迹，并在多种下游任务中取得了显著的改进。


<details>
  <summary>Details</summary>
Motivation: 分析人类移动轨迹，特别是短期访问模式和长期生活规律，并在此基础上进行预测。重点在于处理地理位置、POI类别语义和时间信息的复杂性。

Method: 提出了一种名为GSTM-HMU的生成式时空框架，包含四个关键创新：1. 时空概念编码器（STCE）将地理位置、POI类别语义和周期性时间节奏整合为统一的向量表示。2. 认知轨迹记忆（CTM）自适应地过滤历史访问记录，强调近期和行为上重要的事件，以更有效地捕捉用户意图。3. 生活方式概念库（LCB）提供结构化的人类偏好线索，如活动类型和生活方式模式，以增强可解释性和个性化。4. 面向任务的生成头将学习到的表示转化为多个下游任务的预测。

Result: 在Gowalla, WeePlace, Brightkite和FourSquare四个真实世界数据集上进行了广泛的实验，并在下一个位置预测、轨迹用户识别和时间估计三个基准任务上进行了评估。结果显示GSTM-HMU在这些任务上相比强大的基线模型取得了持续且显著的改进。

Conclusion: GSTM-HMU在从复杂移动数据中提取语义规律方面是有效的。生成式建模为构建更鲁棒、可解释和可泛化的 
人类移动智能系统奠定了有希望的基础。

Abstract: Human mobility traces, often recorded as sequences of check-ins, provide a
unique window into both short-term visiting patterns and persistent lifestyle
regularities. In this work we introduce GSTM-HMU, a generative spatio-temporal
framework designed to advance mobility analysis by explicitly modeling the
semantic and temporal complexity of human movement. The framework consists of
four key innovations. First, a Spatio-Temporal Concept Encoder (STCE)
integrates geographic location, POI category semantics, and periodic temporal
rhythms into unified vector representations. Second, a Cognitive Trajectory
Memory (CTM) adaptively filters historical visits, emphasizing recent and
behaviorally salient events in order to capture user intent more effectively.
Third, a Lifestyle Concept Bank (LCB) contributes structured human preference
cues, such as activity types and lifestyle patterns, to enhance
interpretability and personalization. Finally, task-oriented generative heads
transform the learned representations into predictions for multiple downstream
tasks. We conduct extensive experiments on four widely used real-world
datasets, including Gowalla, WeePlace, Brightkite, and FourSquare, and evaluate
performance on three benchmark tasks: next-location prediction, trajectory-user
identification, and time estimation. The results demonstrate consistent and
substantial improvements over strong baselines, confirming the effectiveness of
GSTM-HMU in extracting semantic regularities from complex mobility data. Beyond
raw performance gains, our findings also suggest that generative modeling
provides a promising foundation for building more robust, interpretable, and
generalizable systems for human mobility intelligence.

</details>


### [311] [Efficient Reinforcement Learning by Reducing Forgetting with Elephant Activation Functions](https://arxiv.org/abs/2509.19159)
*Qingfeng Lan,Gautham Vasan,A. Rupam Mahmood*

Main category: cs.LG

TL;DR: Catastrophic forgetting in RL is a long-standing problem. This paper investigates the role of activation functions, proposing 'elephant activation functions' that induce sparse outputs and gradients to mitigate forgetting and improve RL efficiency.


<details>
  <summary>Details</summary>
Motivation: Catastrophic forgetting is a major challenge in reinforcement learning (RL). While algorithmic solutions exist, the impact of neural network architecture, specifically activation functions, on this issue is not well understood.

Method: The study analyzes how activation functions affect neural network training dynamics and catastrophic forgetting in RL. It identifies gradient sparsity as crucial and proposes 'elephant activation functions' that create both sparse outputs and gradients.

Result: Replacing standard activation functions with elephant activation functions in value-based RL algorithms significantly reduces catastrophic forgetting, leading to more sample- and memory-efficient RL.

Conclusion: Elephant activation functions, by promoting sparse outputs and gradients, offer a promising architectural solution to mitigate catastrophic forgetting in reinforcement learning, enhancing overall efficiency.

Abstract: Catastrophic forgetting has remained a significant challenge for efficient
reinforcement learning for decades (Ring 1994, Rivest and Precup 2003). While
recent works have proposed effective methods to mitigate this issue, they
mainly focus on the algorithmic side. Meanwhile, we do not fully understand
what architectural properties of neural networks lead to catastrophic
forgetting. This study aims to fill this gap by studying the role of activation
functions in the training dynamics of neural networks and their impact on
catastrophic forgetting in reinforcement learning setup. Our study reveals
that, besides sparse representations, the gradient sparsity of activation
functions also plays an important role in reducing forgetting. Based on this
insight, we propose a new class of activation functions, elephant activation
functions, that can generate both sparse outputs and sparse gradients. We show
that by simply replacing classical activation functions with elephant
activation functions in the neural networks of value-based algorithms, we can
significantly improve the resilience of neural networks to catastrophic
forgetting, thus making reinforcement learning more sample-efficient and
memory-efficient.

</details>


### [312] [Unveiling the Role of Learning Rate Schedules via Functional Scaling Laws](https://arxiv.org/abs/2509.19189)
*Binghui Li,Fengling Chen,Zixun Huang,Lean Wang,Lei Wu*

Main category: cs.LG

TL;DR: 本文提出函数式缩放定律（FSL），研究了学习率策略对大型语言模型（LLM）训练动态的影响，并为LLM预训练中的一些经验实践提供了理论依据。


<details>
  <summary>Details</summary>
Motivation: 现有关于LLM缩放定律的研究主要关注最终损失，忽略了训练过程中的损失动态以及学习率策略的影响。本文旨在填补这一空白。

Method: 通过研究一个教师-学生核回归模型，并利用在线随机梯度下降（SGD）进行训练。借助内在时间视角和SGD的随机微分方程（SDE）模型，提出函数式缩放定律（FSL），该定律能够描述在一般学习率策略下，训练过程中总体风险的演变。学习率策略的影响通过一个显式的卷积型函数项来体现。

Result: FSL能够捕捉学习率策略的影响，并被用于分析三种常用的学习率策略（恒定、指数衰减、预热-稳定-衰减）在数据限制和计算限制两种情况下的表现。研究结果为LLM预训练中的一些经验做法（如高容量模型更高效、学习率衰减可提高训练效率、预热-稳定-衰减策略优于直接衰减策略）提供了理论支持。此外，FSL还被用作一个代理模型，用于拟合、预测和优化LLM预训练中的损失曲线，并在不同模型规模（0.1B到1B参数）上进行了实验验证。

Conclusion: FSL框架能够加深对LLM预训练动态的理解，并为改进大规模模型训练提供见解。

Abstract: Scaling laws have played a cornerstone role in guiding the training of large
language models (LLMs). However, most existing works on scaling laws primarily
focus on the final-step loss, overlooking the loss dynamics during the training
process and, crucially, the impact of learning rate schedule (LRS). In this
paper, we aim to bridge this gap by studying a teacher-student kernel
regression setup trained via online stochastic gradient descent (SGD).
Leveraging a novel intrinsic time viewpoint and stochastic differential
equation (SDE) modeling of SGD, we introduce the Functional Scaling Law (FSL),
which characterizes the evolution of population risk during the training
process for general LRSs. Remarkably, the impact of the LRSs is captured
through an explicit convolution-type functional term, making their effects
fully tractable. To illustrate the utility of FSL, we analyze three widely used
LRSs -- constant, exponential decay, and warmup-stable-decay (WSD) -- under
both data-limited and compute-limited regimes. We provide theoretical
justification for widely adopted empirical practices in LLMs pre-training such
as (i) higher-capacity models are more data- and compute-efficient; (ii)
learning rate decay can improve training efficiency; (iii) WSD-like schedules
can outperform direct-decay schedules. Lastly, we explore the practical
relevance of FSL as a surrogate model for fitting, predicting and optimizing
the loss curves in LLM pre-training, with experiments conducted across model
sizes ranging from 0.1B to 1B parameters. We hope our FSL framework can deepen
the understanding of LLM pre-training dynamics and provide insights for
improving large-scale model training.

</details>


### [313] [A Validation Strategy for Deep Learning Models: Evaluating and Enhancing Robustness](https://arxiv.org/abs/2509.19197)
*Abdul-Rauf Nuhu,Parham Kebria,Vahid Hemmati,Benjamin Lartey,Mahmoud Nabil Mahmoud,Abdollah Homaifar,Edward Tunstel*

Main category: cs.LG

TL;DR: 该研究提出一种从训练数据中提取“弱鲁棒”样本的方法，用于评估和提升深度学习模型的鲁棒性，以应对对抗性和常见扰动。


<details>
  <summary>Details</summary>
Motivation: 现有深度学习模型在干净数据集上表现良好，但在面对对抗性和常见扰动时鲁棒性不足，影响了模型的可靠性。传统的鲁棒性验证方法依赖于扰动测试数据集，而本研究旨在提出一种新的验证方法。

Method: 提出一种通过局部鲁棒性分析从训练数据集中提取“弱鲁棒”样本的验证方法。这些样本最容易受到扰动的影响，可以作为模型脆弱性的早期敏感指标。通过在这些具有挑战性的训练实例上评估模型，可以更深入地理解模型的鲁棒性，并指导有针对性的性能提升。

Result: 在 CIFAR-10、CIFAR-100 和 ImageNet 数据集上训练的模型上证明了该方法的有效性，表明基于弱鲁棒样本的鲁棒性验证可以显著提高模型在对抗性和常见扰动下的可靠性。

Conclusion: 通过从训练数据中提取“弱鲁棒”样本进行分析，可以有效地评估和改进深度学习模型的鲁棒性，从而提高模型在各种扰动下的可靠性。

Abstract: Data-driven models, especially deep learning classifiers often demonstrate
great success on clean datasets. Yet, they remain vulnerable to common data
distortions such as adversarial and common corruption perturbations. These
perturbations can significantly degrade performance, thereby challenging the
overall reliability of the models. Traditional robustness validation typically
relies on perturbed test datasets to assess and improve model performance. In
our framework, however, we propose a validation approach that extracts "weak
robust" samples directly from the training dataset via local robustness
analysis. These samples, being the most susceptible to perturbations, serve as
an early and sensitive indicator of the model's vulnerabilities. By evaluating
models on these challenging training instances, we gain a more nuanced
understanding of its robustness, which informs targeted performance
enhancement. We demonstrate the effectiveness of our approach on models trained
with CIFAR-10, CIFAR-100, and ImageNet, highlighting how robustness validation
guided by weak robust samples can drive meaningful improvements in model
reliability under adversarial and common corruption scenarios.

</details>


### [314] [PPG-Distill: Efficient Photoplethysmography Signals Analysis via Foundation Model Distillation](https://arxiv.org/abs/2509.19215)
*Juntong Ni,Saurabh Kataria,Shengpu Tang,Carl Yang,Xiao Hu,Wei Jin*

Main category: cs.LG

TL;DR: PPG-Distill是一个知识蒸馏框架，通过多层蒸馏（预测、特征、补丁）和专门的形态/节律蒸馏，将大型PPG模型的知识转移到资源受限的设备上，实现了高效的PPG分析。


<details>
  <summary>Details</summary>
Motivation: 由于大型PPG基础模型难以部署在资源受限的设备上，因此需要一种有效的方法来在这些设备上进行PPG分析。

Method: PPG-Distill框架通过预测级、特征级和补丁级蒸馏来传递全局和局部知识。它还结合了形态蒸馏来保留局部波形模式，以及节律蒸馏来捕获补丁间的时间结构。

Result: 在心率估计和房颤检测任务中，PPG-Distill将学生模型的性能提高了21.8%，同时实现了7倍的推理速度提升和19倍的内存使用量减少。

Conclusion: PPG-Distill能够有效地将大型PPG模型的知识转移到资源受限的设备上，从而实现高效的PPG分析，适用于可穿戴设备。

Abstract: Photoplethysmography (PPG) is widely used in wearable health monitoring, yet
large PPG foundation models remain difficult to deploy on resource-limited
devices. We present PPG-Distill, a knowledge distillation framework that
transfers both global and local knowledge through prediction-, feature-, and
patch-level distillation. PPG-Distill incorporates morphology distillation to
preserve local waveform patterns and rhythm distillation to capture inter-patch
temporal structures. On heart rate estimation and atrial fibrillation
detection, PPG-Distill improves student performance by up to 21.8% while
achieving 7X faster inference and reducing memory usage by 19X, enabling
efficient PPG analysis on wearables

</details>


### [315] [Video Killed the Energy Budget: Characterizing the Latency and Power Regimes of Open Text-to-Video Models](https://arxiv.org/abs/2509.19222)
*Julien Delavande,Regis Pierrard,Sasha Luccioni*

Main category: cs.LG

TL;DR: 研究了文本到视频生成模型（T2V）的计算成本和能耗，并提出了一个分析模型来预测其性能。


<details>
  <summary>Details</summary>
Motivation: T2V模型计算成本高昂，但其能源消耗研究不足。

Method: 开发了一个计算密集型分析模型，预测了模型在空间分辨率、时间长度和去噪步数方面的扩展规律，并通过在WAN2.1-T2V上的实验进行了验证，随后将分析扩展到其他六个T2V模型。

Result: T2V模型在空间分辨率和时间长度上呈现二次方增长，在去噪步数上呈现线性增长。

Conclusion: 研究结果为设计和部署更可持续的生成式视频系统提供了基准参考和实践指导。

Abstract: Recent advances in text-to-video (T2V) generation have enabled the creation
of high-fidelity, temporally coherent clips from natural language prompts. Yet
these systems come with significant computational costs, and their energy
demands remain poorly understood. In this paper, we present a systematic study
of the latency and energy consumption of state-of-the-art open-source T2V
models. We first develop a compute-bound analytical model that predicts scaling
laws with respect to spatial resolution, temporal length, and denoising steps.
We then validate these predictions through fine-grained experiments on
WAN2.1-T2V, showing quadratic growth with spatial and temporal dimensions, and
linear scaling with the number of denoising steps. Finally, we extend our
analysis to six diverse T2V models, comparing their runtime and energy profiles
under default settings. Our results provide both a benchmark reference and
practical insights for designing and deploying more sustainable generative
video systems.

</details>


### [316] [Study Design and Demystification of Physics Informed Neural Networks for Power Flow Simulation](https://arxiv.org/abs/2509.19233)
*Milad Leyli-abadi,Antoine Marot,Jérôme Picault*

Main category: cs.LG

TL;DR: 可再生能源整合和跨界电力交换增加，导致电网面临更大不确定性和运行风险。传统物理求解器速度慢，机器学习模型可作为快速替代，但需嵌入物理定律（如基尔霍夫定律）以提高其准确性。本研究通过消融实验，研究了从正则化项或无监督损失中嵌入物理约束，以及从多层感知机到图神经网络的模型架构等混合策略。


<details>
  <summary>Details</summary>
Motivation: 在能源转型背景下，需要解决日益增长的可再生能源整合和跨界电力交换带来的电网不确定性和运行风险问题，而传统物理求解器速度慢，机器学习模型可以作为一种快速的替代方案，但需要保证其物理遵循性。

Method: 通过消融实验，研究不同混合策略（如将物理约束作为正则化项或无监督损失）以及不同模型架构（从多层感知机到图神经网络）对物理信息机器学习模型的影响。使用名为LIPS的基准测试流程，从准确性、物理合规性、工业准备度和分布外泛化能力四个维度评估模型。

Result: 研究结果表明，整合物理知识对模型的准确性、物理合规性、工业准备度和分布外泛化能力等多个维度都产生了影响。

Conclusion: 本研究通过消融实验和基准测试，深入探讨了混合策略对物理信息机器学习模型性能的影响，为提高电网稳定性和运行效率提供了新的见解。

Abstract: In the context of the energy transition, with increasing integration of
renewable sources and cross-border electricity exchanges, power grids are
encountering greater uncertainty and operational risk. Maintaining grid
stability under varying conditions is a complex task, and power flow simulators
are commonly used to support operators by evaluating potential actions before
implementation. However, traditional physical solvers, while accurate, are
often too slow for near real-time use. Machine learning models have emerged as
fast surrogates, and to improve their adherence to physical laws (e.g.,
Kirchhoff's laws), they are often trained with embedded constraints which are
also known as physics-informed or hybrid models. This paper presents an
ablation study to demystify hybridization strategies, ranging from
incorporating physical constraints as regularization terms or unsupervised
losses, and exploring model architectures from simple multilayer perceptrons to
advanced graph-based networks enabling the direct optimization of physics
equations. Using our custom benchmarking pipeline for hybrid models called
LIPS, we evaluate these models across four dimensions: accuracy, physical
compliance, industrial readiness, and out-of-distribution generalization. The
results highlight how integrating physical knowledge impacts performance across
these criteria. All the implementations are reproducible and provided in the
corresponding Github page.

</details>


### [317] [What Characterizes Effective Reasoning? Revisiting Length, Review, and Structure of CoT](https://arxiv.org/abs/2509.19284)
*Yunzhen Feng,Julia Kempe,Cheng Zhang,Parag Jain,Anthony Hartshorn*

Main category: cs.LG

TL;DR: 有效性 CoT 的特点是失败的步骤更少，并且支持结构感知测试时间扩展，而不是无差别地生成长 CoT。


<details>
  <summary>Details</summary>
Motivation:  LRMs 在长 CoT 轨迹上花费大量的测试时间计算，但有效的 CoT 的特征仍然不清楚。虽然之前的工作报告称通过附加的“等待”标记来延长 CoT 和增加审查（重新访问早期步骤）可以带来收益，但最近的研究表明，较短的思考可以优于较长的轨迹。

Method: 引入 CoT 的图视图来提取结构，并识别单个统计数据——失败步骤分数 (FSF)，即被放弃的分支中的步骤的比例——该分数持续优于模型之间的正确性长度和审查比率。

Result: 与“越长越好”的说法相反，我们发现幼稚的 CoT 延长和审查的增加都与准确性降低有关。FSF 在模型之间的正确性长度和审查比率方面持续优于。

Conclusion: 有效 CoT 的特点是失败的次数更少，并支持结构感知测试时间扩展，而不是无差别地生成长 CoT。

Abstract: Large reasoning models (LRMs) spend substantial test-time compute on long
chain-of-thought (CoT) traces, but what *characterizes* an effective CoT
remains unclear. While prior work reports gains from lengthening CoTs and
increasing review (revisiting earlier steps) via appended *wait* tokens, recent
studies suggest that shorter thinking can outperform longer traces. We
therefore conduct a systematic evaluation across ten LRMs on math and
scientific reasoning. Contrary to the "longer-is-better" narrative, we find
that both naive CoT lengthening and increased review are associated with
*lower* accuracy.
  As CoT unfolds step by step, token-level metrics can conflate verbosity with
process quality. We introduce a graph view of CoT to extract structure and
identify a single statistic-the *Failed-Step Fraction (FSF)*, the fraction of
steps in abandoned branches-that consistently outpredicts length and review
ratio for correctness across models. To probe causality, we design two
interventions. First, we rank candidate CoTs by each metric at test time, where
FSF yields the largest pass@1 gains; second, we edit CoTs to remove failed
branches, which significantly improves accuracy, indicating that failed
branches bias subsequent reasoning. Taken together, these results characterize
effective CoTs as those that *fail less* and support *structure-aware*
test-time scaling over indiscriminately generating long CoT.

</details>


<div id='cs.GT'></div>

# cs.GT [[Back]](#toc)

### [318] [On Sybil-proofness in Restaking Networks](https://arxiv.org/abs/2509.18338)
*Tarun Chitra,Paolo Penna,Manvir Schneider*

Main category: cs.GT

TL;DR: Restaking协议的Sybil攻击防御存在根本性限制，无法同时防御两种攻击类型，网络拓扑结构至关重要。


<details>
  <summary>Details</summary>
Motivation: Restaking协议扩展了验证者的职责，但其安全性依赖于对Sybil攻击的抵抗能力。

Method: 提出一个形式化框架来评估Restaking网络中的Sybil攻击防御能力，区分两种攻击类型，并分析了边际和乘法罚款机制。证明了一个不可能定理，即没有罚款机制能够同时阻止两种攻击类型。最后，研究了随机图模型下的网络结构对Sybil攻击的影响。

Result: 分析表明，Erdos-Renyi网络仍然是Sybil攻击的防御性的，而具有最小异质性的两块随机块模型会使Sybil攻击变得有利可图。

Conclusion: Restaking协议的Sybil攻击防御存在根本性限制，无法同时防御两种攻击类型。网络拓扑结构在Sybil攻击防御中起着关键作用。

Abstract: Restaking protocols expand validator responsibilities beyond consensus, but
their security depends on resistance to Sybil attacks. We introduce a formal
framework for Sybil-proofness in restaking networks, distinguishing between two
types of attacks, one in which other Sybil identities are kept out of an attack
and one where multiple Sybil identities attack. We analyze marginal and
multiplicative slashing mechanisms and characterize the conditions under which
each deters Sybil strategies. We then prove an impossibility theorem: no
slashing mechanism can simultaneously prevent both attack types. Finally, we
study the impact of network structure through random graph models: while
Erd\"os-R\'enyi networks remain Sybil-proof, even minimal heterogeneity in a
two-block stochastic block model makes Sybil attacks profitable. These results
reveal fundamental limits of mechanism design for restaking and highlight the
critical role of network topology.

</details>


### [319] [Fair Decisions through Plurality: Results from a Crowdfunding Platform](https://arxiv.org/abs/2509.18343)
*Joel Miller,E. Glen Weyl,Chris Kanich*

Main category: cs.GT

TL;DR: QF 算法存在问题，CO-QF 算法在效率和公平性方面表现更好。


<details>
  <summary>Details</summary>
Motivation: 提高众筹平台的公平性和经济效率。

Method: 提出了一种名为“面向连接的二次方资助”（CO-QF）的新算法，并与之前的“方 QF”算法进行了比较。

Result: CO-QF 算法的采用率为 89%，已分配超过 400 万美元。模拟显示 CO-QF 提供了比 QF 更好的社会福利。

Conclusion: CO-QF 算法是一种比 QF 更有利的众筹平台算法，并且可能是一种通用的公共决策工具。

Abstract: We discuss an algorithmic intervention aimed at increasing equity and
economic efficiency at a crowdfunding platform that gives cash subsidies to
grantees. Through a blend of technical and qualitative methods, we show that
the previous algorithm used by the platform -- Quadratic Funding (QF) --
suffered problems because its design was rooted in a model of individuals as
isolated and selfish. We present an alternative algorithm --
Connection-Oriented Quadratic Funding (CO-QF) -- rooted in a theory of
plurality and prosocial utilities, and show that it qualitatively and
quantitatively performs better than QF. CO-QF has achieved an 89% adoption rate
at the platform and has distributed over $4 Million to date. In simulations we
show that it provides better social welfare than QF. While our design for CO-QF
was responsive to the needs of a specific community, we also extrapolate out of
this context to show that CO-QF is a potentially helpful tool for
general-purpose public decision making.

</details>


### [320] [Group Formation through Game Theory and Agent-Based Modeling: Spatial Cohesion, Heterogeneity, and Resource Pooling](https://arxiv.org/abs/2509.18551)
*Chenlan Wang,Jimin Han,Diana Jue-Rajasingh*

Main category: cs.GT

TL;DR: 研究人员开发了博弈论模型和基于代理的模型来研究由资源整合、空间聚集和异质性驱动的小组形成。跨部门伙伴关系（CSP）涉及公共、私人和非营利组织，它们各自贡献不同的资源。当参与者在竞争环境中根据他人的选择进行战略性优化时，就会形成小组。研究证明了稳定小组均衡的存在性，并模拟了在不同空间和资源条件下的小组形成动态。结果表明，有限的个人资源会导致主要在附近参与者之间形成小组，而丰富的资源则允许小组跨越更远的距离。增加的资源异质性和空间邻近性促进了更大、更多样化的小组的形成。这些发现揭示了影响小组规模和构成的重要权衡，为有效的跨部门合作和多主体系统提供了策略。


<details>
  <summary>Details</summary>
Motivation: 本研究的动机是理解和模拟由资源整合、空间聚集和异质性驱动的跨部门伙伴关系（CSP）中的小组形成过程。研究旨在揭示影响小组规模、构成和形成动态的关键因素，为优化跨部门合作提供见解。

Method: 本研究结合了博弈论模型和基于代理的模型来研究小组形成。参与者（代表公共、私人和非营利组织）根据资源整合、空间邻近性和异质性等因素，在竞争环境中战略性地优化其选择。研究证明了稳定小组均衡的存在性，并通过模拟来探索不同空间和资源条件下的形成动态。

Result: 研究结果表明，有限的个人资源会促使小组主要在空间邻近的参与者之间形成，而充足的资源则允许小组在更广泛的区域内形成。此外，增加的资源异质性和空间邻近性能够促进更大、更多样化的小组的形成。这些发现揭示了影响小组规模和构成的关键权衡。

Conclusion: 本研究的结论是，小组的形成（尤其是在跨部门合作背景下）受到资源可用性、空间因素和参与者异质性的显著影响。有限的资源和较强的空间聚集性倾向于形成规模较小、更集中的合作小组，而丰富的资源和较低的空间限制则允许形成更大、更多样化的合作网络。这些发现为了解和指导有效的跨部门合作以及设计多主体系统提供了重要的理论和实践指导。

Abstract: This paper develops a game-theoretic model and an agent-based model to study
group formation driven by resource pooling, spatial cohesion, and
heterogeneity. We focus on cross-sector partnerships (CSPs) involving public,
private, and nonprofit organizations, each contributing distinct resources.
Group formation occurs as agents strategically optimize their choices in
response to others within a competitive setting. We prove the existence of
stable group equilibria and simulate formation dynamics under varying spatial
and resource conditions. The results show that limited individual resources
lead to groups that form mainly among nearby actors, while abundant resources
allow groups to move across larger distances. Increased resource heterogeneity
and spatial proximity promote the formation of larger and more diverse groups.
These findings reveal key trade-offs shaping group size and composition,
guiding strategies for effective cross-sector collaborations and multi-agent
systems.

</details>


### [321] [Proximately Envy-Free and Efficient Allocation of Mixed Manna](https://arxiv.org/abs/2509.18673)
*Siddharth Barman,Paritosh Verma*

Main category: cs.GT

TL;DR: 在混合人`manna`（物品和`chores`的组合）的公平分配问题中，本研究证明了存在满足


<details>
  <summary>Details</summary>
Motivation: 本研究旨在解决混合`manna`（可分配物品和不可分配`chores`的组合）的公平分配问题，特别是证明存在同时满足

Method: 引入了“内省式”的无嫉妒（物品数量-1）分配（`IEF1`）概念，并证明了对于混合`manna`，存在满足“帕累托最优”（`PO`）和`IEF1`的分配。

Result: 证明了存在同时满足“帕累托最优”（`PO`）和“内省式”的无嫉妒（物品数量-1）分配（`IEF1`）的混合`manna`分配。

Conclusion: 本研究在混合`manna`的公平分配问题上取得了重要进展，证明了存在满足`PO`和`IEF1`的分配，该结果推广了先前在不可分配`chores`分配问题上的研究成果。

Abstract: The existence of fair and efficient allocations of indivisible items is a
central problem in fair division. For indivisible goods, the existence of
Pareto efficient (PO) and envy free up to one item (EF1) allocations was
established by Caragiannis et al. In a recent breakthrough, Mahara established
the existence of PO and EF1 allocations for indivisible chores.
  However, the existence of PO and EF1 allocations of mixed manna remains an
intriguing open problem. In this paper, we make significant progress in this
direction. We establish the existence of allocations that are PO and
introspective envy free up to one item (IEF1) for mixed manna. In an IEF1
allocation, each agent can eliminate its envy towards all the other agents by
either adding an item or removing an item from its own bundle. The notion of
IEF1 coincides with EF1 for indivisible chores, and hence, our existence result
generalizes the aforementioned result of Mahara.

</details>


### [322] [Approximating Electoral Control Problems](https://arxiv.org/abs/2509.19279)
*Huy Vu Bui,Michael C. Chavrimootoo,Trung Kien Le,Son M. Nguyen*

Main category: cs.GT

TL;DR: 本文研究了选举控制问题（一种选举攻击形式）的近似算法，重点关注投票规则中的多选、批准和孔多塞规则。研究结果表明，在 P!=NP 的前提下，对于批准和孔多塞规则，文中所提出的近似算法是最优的。对于多选规则，文中给出了一个 O(m) 的近似算法，并证明了其近似度下界为 Omega(m^{1/4})。


<details>
  <summary>Details</summary>
Motivation: 大多数关于选举控制的研究都集中在计算复杂性方面，而忽略了近似算法。尽管近似算法在研究操纵和贿赂等其他选举攻击形式时得到了广泛应用，但在选举控制领域却鲜有关注。本文旨在填补这一研究空白，为选举控制问题提供近似算法方面的分析。

Method: 本文利用覆盖整数规划（CIP）可以被近似到 O(log n) 的事实，来设计和分析近似算法。具体来说，对于批准和孔多塞投票规则，证明了所给算法的最优性（除非 P=NP）。对于多选投票规则，提出了一种 O(m) 近似算法，并利用最小 k-并集（M k U）问题的已知下界来证明其近似度下界为 Omega(m^{1/4})。此外，还采用公理化方法将 O(m) 近似算法推广到无限多的投票规则。

Result: 对于批准和孔多塞投票规则，证明了在 P!=NP 的前提下，所提出的近似算法是近似最优的。对于多选投票规则，给出了一个 O(m) 的近似算法，并证明了其近似度下界为 Omega(m^{1/4})。研究结果解决了 18 年前提出的一个长期悬而未决的问题。

Conclusion: 本文为选举控制问题（特别是多选、批准和孔多塞规则）提供了近似算法的分析，并取得了最优或接近最优的结果。研究结果不仅填补了该领域的空白，还为未来的研究提供了新的方向，例如将近似算法应用于更广泛的投票规则和选举攻击形式。

Abstract: Much research in electoral control -- one of the most studied form of
electoral attacks, in which an entity running an election alters the structure
of that election to yield a preferred outcome -- has focused on giving decision
complexity results, e.g., membership in P, NP-completeness, or fixed-parameter
tractability. Approximation algorithms on the other hand have received little
attention in electoral control, despite their prevalence in the study of other
forms of electoral attacks, such as manipulation and bribery. Early work
established some preliminary results with respect to popular voting rules such
as plurality, approval, and Condorcet. In this paper, we establish for each of
the ``standard'' control problems under plurality, approval, and Condorcet,
whether they are approximable, and we prove our results in both the weighted
and unweighted voter settings. For each problem we study under either approval
or Condorcet, we show that any approximation algorithm we give is optimal,
unless P=NP. Our approximation algorithms leverage the fact that Covering
Integer Programs (CIPs) can be approximated within a factor of $O(\log n)$.
Under plurality, we give an $O(m)$-approximation algorithm, and give as lower
bound $\Omega(m^{1/4})$, by using a known lower bound on the Minimum $k$-Union
(M$k$U) problem. To our knowledge, this is the first application of M$k$U in
computational social choice. We also generalize our $O(m)$-approximation
algorithm to work with respect to an infinite family of voting rules using an
axiomatic approach. Our work closes a long list of open problems established 18
years ago.

</details>


<div id='cs.DS'></div>

# cs.DS [[Back]](#toc)

### [323] [Precoloring extension with demands on paths](https://arxiv.org/abs/2509.18936)
*Arun Kumar Das,Michal Opler,Tomáš Valla*

Main category: cs.DS

TL;DR: DPED问题在路径上被研究，提出了多项式时间精确算法、近似算法，并证明了其NP-完全性，研究了参数化复杂性，并提出了FPT算法。


<details>
  <summary>Details</summary>
Motivation: DPED问题源于商业广播频道中的节目调度，需要满足内容重复和放置的约束。

Method: 研究DPED在路径上的问题，提出了精确算法、近似算法、NP-完全性证明、参数化复杂性分析和FPT算法。

Result: 提出了DPED在路径上的多项式时间精确算法、近似算法，证明了DPED是NP-完全的，并提出了针对颜色数、距离和预染色顶点数的FPT算法。

Conclusion: DPED问题在路径上的研究取得了多项进展，包括精确算法、近似算法、NP-完全性证明以及FPT算法，为相关调度问题提供了理论基础。

Abstract: Let $G$ be a graph with a set of precolored vertices, and let us be given an
integer distance parameter $d$ and a set of integer demands $d_1,\dots,d_c$.
The Distance Precoloring Extension with Demands (DPED) problem is to compute a
vertex $c$-coloring of $G$ such that the following three conditions hold: (i)
the resulting coloring respects the colors of the precolored vertices, (ii) the
distance of two vertices of the same color is at least $d$, and (iii) the
number of vertices colored by color $i$ is exactly $d_i$. This problem is
motivated by a program scheduling in commercial broadcast channels with
constraints on content repetition and placement, which leads precisely to the
DPED problem for paths.
  In this paper, we study DPED on paths and present a polynomial time exact
algorithm when precolored vertices are restricted to the two ends of the path
and devise an approximation algorithm for DPED with an additive approximation
factor polynomially bounded by $d$ and the number of precolored vertices. Then,
we prove that the Distance Precoloring Extension problem on paths, a less
restrictive version of DPED without the demand constraints, and then DPED
itself, is NP-complete. Motivated by this result, we further study the
parameterized complexity of DPED on paths. We establish that the DPED problem
on paths is $W[1]$-hard when parameterized by the number of colors and the
distance. On the positive side, we devise a fixed parameter tractable (FPT)
algorithm for DPED on paths when the number of colors, the distance, and the
number of precolored vertices are considered as the parameters. Moreover, we
prove that Distance Precoloring Extension is FPT parameterized by the distance.
As a byproduct, we also obtain several results for the Distance List Coloring
problem on paths.

</details>


### [324] [GraphBLAS Mathematical Opportunities: Parallel Hypersparse, Matrix Based Graph Streaming, and Complex-Index Matrices](https://arxiv.org/abs/2509.18984)
*Hayden Jananthan,Jeremy Kepner,Michael Jones,Vijay Gadepally,Michael Houle,Peter Michaleas,Chasen Milner,Alex Pentland*

Main category: cs.DS

TL;DR: GraphBLAS 库标准不仅能用线性代数表达图算法，还能实现新的高性能计算方法，如利用超稀疏矩阵进行并行计算、基于矩阵的图流和复数索引矩阵。本文将对这些概念进行数学形式化，并通过实例展示其潜力。


<details>
  <summary>Details</summary>
Motivation: GraphBLAS 库标准在图算法实现方面提供了超越线性代数表达的能力，激发了新的高性能计算思路，包括利用超稀疏矩阵进行并行计算、基于矩阵的图流处理以及复数索引矩阵等。本文旨在对这些新方法进行数学形式化，并探索其在不同领域的应用潜力。

Method: 本文形式化地发展了并行超稀疏矩阵、基于矩阵的图流和复数索引矩阵的概念。

Result: 文章通过具体示例，展示了并行超稀疏矩阵、基于矩阵的图流和复数索引矩阵等概念的潜在优势。

Conclusion: 本文对 GraphBLAS 库标准带来的新计算范式进行了形式化阐述，并辅以实例，证明了这些新方法在图计算领域的应用前景。

Abstract: The GraphBLAS high performance library standard has yielded capabilities
beyond enabling graph algorithms to be readily expressed in the language of
linear algebra. These GraphBLAS capabilities enable new performant ways of
thinking about algorithms that include leveraging hypersparse matrices for
parallel computation, matrix-based graph streaming, and complex-index matrices.
Formalizing these concepts mathematically provides additional opportunities to
apply GraphBLAS to new areas. This paper formally develops parallel hypersparse
matrices, matrix-based graph streaming, and complex-index matrices and
illustrates these concepts with various examples to demonstrate their potential
merits.

</details>


### [325] [Optimization of Base-n Radix Sort for Skewed Datasets](https://arxiv.org/abs/2509.19021)
*Atharv Pandey,Lakshmanan Kuppusamy*

Main category: cs.DS

TL;DR: BNRS和SLPR是比传统比较排序更快的非比较排序算法，尤其适用于具有大量小值和少量大值的偏斜数据集。


<details>
  <summary>Details</summary>
Motivation: 分析了非比较排序算法Base-n Radix Sort (BNRS)，并引入了其优化变体Stable Logical Partition Radix Sort (SLPR)，旨在为特定整数分布提供比传统比较排序更快的排序解决方案。

Method: 分析了Base-n Radix Sort (BNRS)算法，并提出了一种名为Stable Logical Partition Radix Sort (SLPR)的优化变体，该变体使用原地稳定分区来减小每次传递中的活动问题规模。

Result: 证明了BNRS和SLPR算法在时间复杂度上，当满足k < nlog(n)时，对于某些整数分布比传统比较排序算法更有效。SLPR优化通过原地稳定分区，有效地处理了包含大多数小数和混合少量大数的偏斜数据集。

Conclusion: BNRS和SLPR是非比较排序算法，在k < nlog(n)的条件下，对于某些整数分布，其时间复杂度优于比较排序算法。SLPR的原地稳定分区优化使其在处理偏斜数据集方面表现出色。

Abstract: The importance and applications of sorting is apparent and needs no
explanation. In this paper, we analyse a non-comparison sorting algorithm,
Base-n Radix Sort (BNRS) and introduce an optimized vari- ant of BNRS, namely,
Stable Logical Partition Radix Sort (SLPR). The complexity of these algorithms
is measured by the input size $n$ and the maximum value $k$. We show that with
respect to time complexity, these algorithms are more succinct than traditional
comparison-based sorting algorithms for representing the sorted order of
certain integer distribu- tions, specifically, when $k <nlog_2^n$ is met. We
also show that the SLPR optimization, which uses in-place stable partitioning
to reduce the active problem size in each pass, resulting in highly effective
sorting for skewed datasets that contain a majority of small numbers and mix of
very large numbers.

</details>


### [326] [Linear Regression under Missing or Corrupted Coordinates](https://arxiv.org/abs/2509.19242)
*Ilias Diakonikolas,Jelena Diakonikolas,Daniel M. Kane,Jasper C. H. Lee,Thanasis Pittas*

Main category: cs.DS

TL;DR: 研究在有删失或被对手破坏的多元线性回归模型，并推导了信息论下界，与算法的误差相匹配，并且在删失和破坏设置下最优误差是相同的。


<details>
  <summary>Details</summary>
Motivation: 研究在删失或被对手破坏的多元线性回归模型，并推导了信息论下界，与算法的误差相匹配，并且在删失和破坏设置下最优误差是相同的。

Method: 推导了信息论下界，并与算法的误差进行了比较。

Result: 在删失和破坏设置下，最优误差是相同的。

Conclusion: 在删失和破坏设置下，最优误差是相同的。

Abstract: We study multivariate linear regression under Gaussian covariates in two
settings, where data may be erased or corrupted by an adversary under a
coordinate-wise budget. In the incomplete data setting, an adversary may
inspect the dataset and delete entries in up to an $\eta$-fraction of samples
per coordinate; a strong form of the Missing Not At Random model. In the
corrupted data setting, the adversary instead replaces values arbitrarily, and
the corruption locations are unknown to the learner. Despite substantial work
on missing data, linear regression under such adversarial missingness remains
poorly understood, even information-theoretically. Unlike the clean setting,
where estimation error vanishes with more samples, here the optimal error
remains a positive function of the problem parameters. Our main contribution is
to characterize this error up to constant factors across essentially the entire
parameter range. Specifically, we establish novel information-theoretic lower
bounds on the achievable error that match the error of (computationally
efficient) algorithms. A key implication is that, perhaps surprisingly, the
optimal error in the missing data setting matches that in the corruption
setting-so knowing the corruption locations offers no general advantage.

</details>


<div id='eess.SY'></div>

# eess.SY [[Back]](#toc)

### [327] [Stochastic Economic Dispatch with Battery Energy Storage considering Wind and Load Uncertainty](https://arxiv.org/abs/2509.18100)
*Shishir Lamichhane,Anamika Dubey*

Main category: eess.SY

TL;DR: BESS通过SDED-S框架改善电力系统灵活性和降低成本，特别是在高风能渗透率下。


<details>
  <summary>Details</summary>
Motivation: 在整合风能等可再生能源的电力系统中，管理运营灵活性、可靠性并同时最小化运营成本面临挑战。BESS为解决这些问题提供了有前景的方案。

Method: 提出一个包含储能的随机动态经济调度（SDED-S）框架，捕捉风能和负荷不确定性之间的时间相关性，并使用受分层和重要性采样启发的场景生成方法。

Result: 在改进的IEEE 39总线系统上进行了案例研究，显示BESS部署显著提高了系统灵活性，减少了可再生能源弃置和调度成本。BESS尺寸的增加减少了可再生能源的弃置，在高风能渗透率下，BESS部署带来的成本节约更大。

Conclusion: BESS的战略部署能有效提升电力系统的灵活性，降低成本，并且在高风能渗透率下其重要性更为凸显。

Abstract: With the integration of renewable energy resources in power systems, managing
operational flexibility and reliability while minimizing operational costs has
become increasingly challenging. Battery energy storage system (BESS) offers a
promising solution to address these issues. This paper presents a stochastic
dynamic economic dispatch with storage (SDED-S) framework to assess the impact
of BESS in managing uncertainty. The temporal correlation between wind and load
uncertainties is captured, with scenarios generated using a method inspired by
stratified and importance sampling. The proposed approach is demonstrated on a
modified IEEE 39-bus system, where selected conventional generators are
converted to wind power plants. Case studies show that strategic BESS
deployment significantly improves system flexibility by reducing renewable
curtailments and dispatch costs. Renewable energy curtailments decrease upon
increasing BESS size and approach zero depending on wind penetration level.
Higher wind penetrations result in greater curtailments without storage and
yield larger cost savings when BESS is deployed, highlighting the growing need
for flexibility as renewable energy penetrations increase.

</details>


### [328] [Reversible Kalman Filter for state estimation with Manifold](https://arxiv.org/abs/2509.18224)
*Svyatoslav Covanov,Cedric Pradalier*

Main category: eess.SY

TL;DR: 该研究提出了一种基于卡尔曼滤波的流形上状态估计算法，用于评估现有卡尔曼滤波方法的精度，并提出了一个新的具有良好数值特性的滤波器，以解决以往方法中存在的发散问题。


<details>
  <summary>Details</summary>
Motivation: 评估现有卡尔曼滤波变体在流形上的精度，并解决以往方法中的发散问题。

Method: 提出了一种新的卡尔曼滤波算法，用于流形上的状态估计，该算法具有良好的数值特性，并且不依赖于小速度假设。

Result: 新的滤波器消除了以往方法中的发散问题，精度仅受传感器噪声限制，并提出了适用于水下环境的传感器配置。

Conclusion: 新提出的卡尔曼滤波算法在流形状态估计方面具有优势，特别是在传感器精度要求较高或需要处理非线性运动的场景下，并且可以通过特定的传感器组合扩展到水下等复杂环境。

Abstract: This work introduces an algorithm for state estimation on manifolds within
the framework of the Kalman filter. Its primary objective is to provide a
methodology enabling the evaluation of the precision of existing Kalman filter
variants with arbitrary accuracy on synthetic data, something that, to the best
of our knowledge, has not been addressed in prior work. To this end, we develop
a new filter that exhibits favorable numerical properties, thereby correcting
the divergences observed in previous Kalman filter variants. In this
formulation, the achievable precision is no longer constrained by the
small-velocity assumption and is determined solely by sensor noise. In
addition, this new filter assumes high precision on the sensors, which, in real
scenarios require a detection step that we define heuristically, allowing one
to extend this approach to scenarios, using either a 9-axis IMU or a
combination of odometry, accelerometer, and pressure sensors. The latter
configuration is designed for the reconstruction of trajectories in underwater
environments.

</details>


### [329] [Fully Distributed State Estimation for Multi-agent Systems and its Application in Cooperative Localization](https://arxiv.org/abs/2509.18292)
*Shuaiting Huang,Haodong Jiang,Chengcheng Zhao,Peng Cheng,Junfeng Wu*

Main category: eess.SY

TL;DR: 本研究提出了一种分布式估计算法，用于线性多智能体系统（MAS），其中每个智能体都可以估计整个系统的状态。该方法利用领导-跟随共识规则和 Luenberger 估计器，使智能体能够跟踪其他智能体的状态估计。研究表明，只要通信图是强连通的，估计算法就是可稳定化的。此外，该算法是完全分布式的，并且能够适应智能体的动态添加或删除。该方法还应用于合作定位问题，提出了两种分布式定位算法。仿真结果验证了该方法的有效性。


<details>
  <summary>Details</summary>
Motivation: 提出了一种分布式估计算法，用于解决连续时间线性多智能体系统（MAS）的状态估计问题，使每个智能体能够自主地重构整个系统的状态。

Method: 提出了一种分布式观察器，其中每个智能体 i 通过利用领导-跟随共识规则来跟踪智能体 j 的状态估计，而智能体 j 使用类似 Luenberger 的估计规则来生成自己的状态估计。

Result: 在节点级可观测性和拓扑排序一致性的假设下，证明了当且仅当通信图是强连通的时，估计误差的动态是可稳定化的。此外，还讨论了该观察器的完全分布式设计，即使在智能体数量动态变化的情况下也能确保其正确运行。并将该方法应用于合作定位问题，开发了两种完全分布式的定位算法。

Conclusion: 所提出的分布式观察器在假设通信图强连通的情况下，能够有效地估计多智能体系统的状态，并且该方法具有良好的鲁棒性，能够适应智能体的动态增减，并成功应用于合作定位问题。

Abstract: In this paper, we investigate the distributed state estimation problem for a
continuous-time linear multi-agent system (MAS) composed of $\mathit{m}$ agents
and monitored by the agents themselves. To address this problem, we propose a
distributed observer that enables each agent to reconstruct the state of the
MAS. The main idea is to let each agent $\mathit{i}$ recover the state of agent
$\mathit{j}$ by using leader-follower consensus rules to track agent
$\mathit{j}$'s state estimate, which is generated by agent $\mathit{j}$ itself
using a Luenberger-like estimation rule. Under the assumptions of node-level
observability and topological ordering consistency, we show that the estimation
error dynamics are stabilizable if and only if the communication graph is
strongly connected. Moreover, we discuss the fully distributed design of the
proposed observer, assuming that the agents only know basic MAS configuration
information, such as the homogeneity and the maximum number of allowable
agents. This design ensures that the proposed observer functions correctly when
agents are added or removed. Building on this, we consider cooperative
localization as a distributed estimation problem and develop two fully
distributed localization algorithms that allow agents to track their own and
other agents' positions (and velocities) within the MAS. Finally, we conduct
simulations to demonstrate the effectiveness of our proposed theoretical
results.

</details>


### [330] [On the Dynamics of Acceleration in First order Gradient Methods](https://arxiv.org/abs/2509.18346)
*M Parimi,Rachit Mehra,S. R. Wagh,Amol Yerudkar,Navdeep Singh*

Main category: eess.SY

TL;DR: Nesterov加速算法的加速现象，通过控制理论和几何奇异摄动理论的动力系统视角来揭示其数学原理。


<details>
  <summary>Details</summary>
Motivation: 解释Nesterov加速算法的加速现象的本质，并揭示其背后的数学原理。

Method: 利用控制理论中的Passivity and Immersion方法和几何奇异摄动理论来构建解释加速现象的动力系统模型。

Result: 通过动力系统模型解释了Nesterov加速算法（光滑强凸和凸情况）的加速机制，并为三重动量法和重球法提供了理论依据。

Conclusion: 该动力学系统框架能够解释Nesterov加速算法的加速机制，并为相关算法提供新的视角和理论支持。

Abstract: Ever since the original algorithm by Nesterov (1983), the true nature of the
acceleration phenomenon has remained elusive, with various interpretations of
why the method is actually faster. The diagnosis of the algorithm through the
lens of Ordinary Differential Equations (ODEs) and the corresponding dynamical
system formulation to explain the underlying dynamics has a rich history. In
the literature, the ODEs that explain algorithms are typically derived by
considering the limiting case of the algorithm maps themselves, that is, an ODE
formulation follows the development of an algorithm. This obfuscates the
underlying higher order principles and thus provides little evidence of the
working of the algorithm. Such has been the case with Nesterov algorithm and
the various analogies used to describe the acceleration phenomena, viz,
momentum associated with the rolling of a Heavy-Ball down a slope, Hessian
damping etc. The main focus of our work is to ideate the genesis of the
Nesterov algorithm from the viewpoint of dynamical systems leading to
demystifying the mathematical rigour behind the algorithm. Instead of reverse
engineering ODEs from discrete algorithms, this work explores tools from the
recently developed control paradigm titled Passivity and Immersion approach and
the Geometric Singular Perturbation theory which are applied to arrive at the
formulation of a dynamical system that explains and models the acceleration
phenomena. This perspective helps to gain insights into the various terms
present and the sequence of steps used in Nesterovs accelerated algorithm for
the smooth strongly convex and the convex case. The framework can also be
extended to derive the acceleration achieved using the triple momentum method
and provides justifications for the non-convergence to the optimal solution in
the Heavy-Ball method.

</details>


### [331] [Optimal Service Mode Assignment in a Simple Computation Offloading System: Extended Version](https://arxiv.org/abs/2509.18356)
*Darin Jeff,Eytan Modiano*

Main category: eess.SY

TL;DR: 本研究提出了一种用于最小化计算任务延迟的作业分配策略，该策略区分了云端处理和本地-云端协同处理两种模式。


<details>
  <summary>Details</summary>
Motivation: 设计一种状态相关的策略，以最小化包含云处理和本地-云端协同处理两种模式的计算卸载模型中的系统延迟。

Method: 当云服务器空闲时，将下一个任务分配给云进行处理；当云服务器繁忙时，如果队列长度超过某个阈值，则将任务分配给本地服务器进行预处理，然后发送到云端完成处理。

Result: 推导并证明了在云服务器空闲和繁忙两种情况下，最优策略的结构。证明了当云服务器繁忙时，存在一个阈值，只有当队列长度超过该阈值时，才将任务分配给本地服务器。

Conclusion: 最优策略具有一种阈值结构：当云服务器空闲时，总是将任务卸载到云端；当云服务器繁忙时，仅当队列长度超过某个阈值时，才将任务卸载到本地服务器进行部分处理。该策略通过仿真得到了验证。

Abstract: We consider a simple computation offloading model where jobs can either be
fully processed in the cloud or be partially processed at a local server before
being sent to the cloud to complete processing. Our goal is to design a policy
for assigning jobs to service modes, i.e., full offloading or partial
offloading, based on the state of the system, in order to minimize delay in the
system. We show that when the cloud server is idle, the optimal policy is to
assign the next job in the system queue to the cloud for processing. However,
when the cloud server is busy, we show that, under mild assumptions, the
optimal policy is of a threshold type, that sends the next job in the system
queue to the local server if the queue exceeds a certain threshold. Finally, we
demonstrate this policy structure through simulations.

</details>


### [332] [Policy Gradient with Self-Attention for Model-Free Distributed Nonlinear Multi-Agent Games](https://arxiv.org/abs/2509.18371)
*Eduardo Sebastián,Maitrayee Keskar,Eeman Iqbal,Eduardo Montijano,Carlos Sagüés,Nikolay Atanasov*

Main category: eess.SY

TL;DR: 该研究提出了一种基于策略梯度的模型无关方法，用于解决动态非线性多人博弈问题，并通过自注意力机制处理时变通信结构。


<details>
  <summary>Details</summary>
Motivation: 多人博弈在动态非线性环境下充满挑战，因为代理之间的交互是时变的，且（潜在的）纳什均衡是非平稳的。

Method: 提出了一种策略梯度方法，用于学习分布式策略，该策略遵循多团队博弈中的通信结构，并采用自注意力层参数化非线性反馈增益来处理时变通信拓扑。

Result: 所提出的分布式策略梯度方法在分布式线性与非线性调节、以及模拟和真实多机器人追逐与规避博弈等多种场景中均取得了优异的性能。

Conclusion: 该研究为解决动态非线性多人博弈问题提供了一种有效的分布式策略梯度学习方法。

Abstract: Multi-agent games in dynamic nonlinear settings are challenging due to the
time-varying interactions among the agents and the non-stationarity of the
(potential) Nash equilibria. In this paper we consider model-free games, where
agent transitions and costs are observed without knowledge of the transition
and cost functions that generate them. We propose a policy gradient approach to
learn distributed policies that follow the communication structure in
multi-team games, with multiple agents per team. Our formulation is inspired by
the structure of distributed policies in linear quadratic games, which take the
form of time-varying linear feedback gains. In the nonlinear case, we model the
policies as nonlinear feedback gains, parameterized by self-attention layers to
account for the time-varying multi-agent communication topology. We demonstrate
that our distributed policy gradient approach achieves strong performance in
several settings, including distributed linear and nonlinear regulation, and
simulated and real multi-robot pursuit-and-evasion games.

</details>


### [333] [Compositional System Dynamics: The Higher Mathematics Underlying System Dynamics Diagrams & Practice](https://arxiv.org/abs/2509.18475)
*Xiaoyan Li,Evan Patterson,Patricia L. Mabry,Nathaniel D. Osgood*

Main category: eess.SY

TL;DR: 本文利用范畴论的形式化方法，为系统动力学（SD）建模奠定了坚实的数学基础，实现了模型的可扩展、透明和系统的推理。


<details>
  <summary>Details</summary>
Motivation: 为系统动力学建模提供一个稳健的数学基础，通过范畴论的形式化方法来增强模型表示、分析和组合能力。

Method: 将系统动力学图（如存量-流量图、系统结构图、因果回路图）形式化为范畴构造，使用带属性的C-sets编码图，并利用结构化的共跨、推出、拉回和函子映射等范畴工具来实现模块化组合、分层和语法与语义之间的映射。

Result: 该方法为传统实践提供了坚实的数学结构支撑，能够识别特定路径和反馈回路、检测复杂图中的简单模式、发现图之间的共同结构，以及在不同图类型之间进行结构保持映射。此外，该框架还支持随机转移动力学等替代语义，超越了传统的常微分方程（ODE）表示。

Conclusion: 通过揭示和形式化系统动力学图的隐藏数学结构，该工作使从业者能够以清晰、可扩展和严谨的方式处理复杂系统。

Abstract: This work establishes a robust mathematical foundation for compositional
System Dynamics modeling, leveraging category theory to formalize and enhance
the representation, analysis, and composition of system models. Here, System
Dynamics diagrams, such as stock & flow diagrams, system structure diagrams,
and causal loop diagrams, are formulated as categorical constructs, enabling
scalable, transparent, and systematic reasoning. By encoding these diagrams as
data using attributed C-sets and utilizing advanced categorical tools like
structured cospans, pushouts, pullbacks, and functor mappings, the framework
supports modular composition, stratification, and seamless mapping between
syntax and semantics.
  The approach underwrites traditional practice with firm mathematical
structure, facilitates the identification of certain forms of pathways and
feedback loops, the detection of simple patterns within complex diagrams,
common structure between diagrams, and structure-preserving mappings between
diverse diagram types. Additionally, this framework supports alternative
semantics, such as stochastic transition dynamics, extending beyond traditional
ordinary differential equation (ODE) representations. Applications in
compositional modeling, modularity, and team-based collaboration demonstrate
the practical advantages of this advanced framework.
  Future directions include integrating dimensional annotations, supporting
hybrid and agent-based modeling paradigms, and expanding the framework's
applicability to global and local temporal reasoning through temporal sheaves.
By revealing and formalizing the hidden mathematical structure of System
Dynamics diagrams, this work empowers practitioners to tackle complex systems
with clarity, scalability, and rigor.

</details>


### [334] [Refined Barrier Conditions for Finite-Time Safety and Reach-Avoid Guarantees in Stochastic Systems](https://arxiv.org/abs/2509.18518)
*Bai Xue,Luke Ong,Dominik Wagner,Peixin Wang*

Main category: eess.SY

TL;DR: 本研究提出了改进的障碍函数条件，放宽了对辅助函数的有界性假设，从而在有限时间内为随机系统提供概率安全和可达-避免保证，并扩展了可验证系统的范围。


<details>
  <summary>Details</summary>
Motivation: 现有障碍证书方法在处理随机系统时，通常需要辅助函数具有有界性假设，这限制了其应用范围。本研究旨在克服这一限制，为更广泛的随机系统提供有限时间概率安全和可达-避免保证。

Method: 本研究提出了改进的障碍类条件，放宽了对辅助函数的有界性假设。具体而言，研究在离散时间系统中建立了推导有限时间安全概率上界的条件，在连续时间系统中建立了推导有限时间可达-避免概率下界的条件。

Result: 通过放宽有界性假设，本研究显著扩展了可验证系统的类别，特别是那些具有无界状态空间的系统。此外，该方法还促进了诸如带有多项式函数的半定规划等先进优化技术的应用。通过数值示例验证了该方法的有效性。

Conclusion: 本研究提出的改进障碍类条件能够去除对辅助函数的有界性假设，从而在有限时间内为随机系统提供概率安全和可达-避免保证，并且扩展了可验证系统的范围，能够应用于具有无界状态空间的系统，并促进了先进优化技术的应用。

Abstract: Providing finite-time probabilistic safety and reach-avoid guarantees is
crucial for safety-critical stochastic systems. Existing barrier certificate
methods often rely on a restrictive boundedness assumption for auxiliary
functions, limiting their applicability. This paper presents refined
barrier-like conditions that remove this assumption. Specifically, we establish
conditions for deriving upper bounds on finite-time safety probabilities in
discrete-time systems and lower bounds on finite-time reach-avoid probabilities
in continuous-time systems. This key relaxation significantly expands the class
of verifiable systems, especially those with unbounded state spaces, and
facilitates the application of advanced optimization techniques, such as
semi-definite programming with polynomial functions. The efficacy of our
approach is validated through numerical examples.

</details>


### [335] [AI Agent Access (A\^3) Network: An Embodied, Communication-Aware Multi-Agent Framework for 6G Coverage](https://arxiv.org/abs/2509.18526)
*Han Zeng,Haibo Wang,Luhao Fan,Bingcheng Zhu,Xiaohu You,Zaichen Zhang*

Main category: eess.SY

TL;DR: 6G网络需要自主和有弹性的网络，但现有的多智能体强化学习（MARL）方法在静态部署和集中控制下，在孤立的阶段（如探索、中继形成或接入）进行优化，这限制了其适应性。我们提出了AI Agent Access (A^3) Network，一个统一的、由具身智能驱动的框架，将多智能体网络转变为一个动态的、去中心化的、端到端的系统。与以往的方法不同，A^3 Network将探索、目标用户接入和回传维护整合到单一学习过程中，并支持运行时按需添加代理。其去中心化的策略确保了即使单个代理也能在有限的观测下独立运行，而协调的代理则实现了可扩展、通信优化的覆盖。通过将链路级通信度量嵌入Actor-Critic学习中，A^3 Network将拓扑形成与鲁棒的决策相结合。数值模拟表明，A^3 Network不仅能平衡探索和通信效率，还能提供现有MARL框架所缺乏的系统级适应性，为6G多智能体网络提供了一个新范例。


<details>
  <summary>Details</summary>
Motivation: 现有的多智能体强化学习（MARL）方法在处理6G通信所需的自主和弹性网络方面存在局限性，因为它们通常专注于孤立的网络阶段，并在静态部署和中心化控制下进行优化，这限制了其适应性。

Method: 提出了一种名为AI Agent Access (A^3) Network的框架，该框架利用具身智能，将探索、目标用户接入和回传维护整合到一个统一的学习过程中，并支持运行时动态添加代理。该框架采用去中心化策略，并将链路级通信度量嵌入Actor-Critic学习中，以实现拓扑形成与决策的结合。

Result: 数值模拟结果表明，A^3 Network在平衡探索与通信效率方面表现良好，并展现了现有MARL框架所缺乏的系统级适应性。

Conclusion: A^3 Network为6G多智能体网络提供了一个新的范例，其特点是统一的学习过程、去中心化策略和强大的适应性，能够满足6G通信对自主和弹性网络的需求。

Abstract: The vision of 6G communication demands autonomous and resilient networking in
environments without fixed infrastructure. Yet most multi-agent reinforcement
learning (MARL) approaches focus on isolated stages - exploration, relay
formation, or access - under static deployments and centralized control,
limiting adaptability. We propose the AI Agent Access (A\^3) Network, a
unified, embodied intelligence-driven framework that transforms multi-agent
networking into a dynamic, decentralized, and end-to-end system. Unlike prior
schemes, the A\^3 Network integrates exploration, target user access, and
backhaul maintenance within a single learning process, while supporting
on-demand agent addition during runtime. Its decentralized policies ensure that
even a single agent can operate independently with limited observations, while
coordinated agents achieve scalable, communication-optimized coverage. By
embedding link-level communication metrics into actor-critic learning, the A\^3
Network couples topology formation with robust decision-making. Numerical
simulations demonstrate that the A\^3 Network not only balances exploration and
communication efficiency but also delivers system-level adaptability absent in
existing MARL frameworks, offering a new paradigm for 6G multi-agent networks.

</details>


### [336] [Interaction-aware Lane-Changing Early Warning System in Congested Traffic](https://arxiv.org/abs/2509.18624)
*Yue Zhang,Xinzhi Zhong,Soyoung Ahn,Yajie Zou,Zhengbing He*

Main category: eess.SY

TL;DR: 该研究提出了一个交互感知车道变换预警（LCEW）系统，通过预测多车轨迹来提前发出预警信号，以提高拥堵交通中的安全性。


<details>
  <summary>Details</summary>
Motivation: 拥堵交通中的车道变换（LC）是涉及多车交互的复杂事件，存在显著安全隐患。提前预警能为主驾提供更主动的驾驶辅助和更明智的决策。

Method: 引入了基于互信息的社交时空图卷积神经网络（STGCNN-MI）框架来预测多车轨迹，通过MI为邻接矩阵来提升预测精度并解释车辆交互。然后，使用定向边界框检测来识别由预测轨迹带来的直接和间接碰撞风险。最后，生成预警信号告知LC车辆潜在碰撞的位置。

Result: 在SUMO中进行的交通仿真实验表明，所提出的交互感知LCEW系统能够提升车辆安全和整体交通效率，并促进更自然的驾驶行为适应。

Conclusion: 所提出的交互感知LCEW系统能够通过准确预测多车轨迹和识别潜在风险，有效地提升拥堵交通中车道变换的安全性与交通效率。

Abstract: Lane changes (LCs) in congested traffic are complex, multi-vehicle
interactive events that pose significant safety concerns. Providing early
warnings can enable more proactive driver assistance system and support more
informed decision-making for drivers under LCs. This paper presents an
interaction-aware Lane-Changing Early Warning (LCEW) system designed to issue
reliable early warning signals based on future trajectory predictions. We first
investigate the stochastic nature of LCs, characterized by (i) variable-size
multi-vehicle interactions and (ii) the direct and indirect risks resulting
from these interactions. To model these stochastic interactions, a Social
Spatio-Temporal Graph Convolutional Neural Network framework informed by mutual
information (STGCNN-MI) is introduced to predict multi-vehicle trajectories. By
leveraging a MI-based adjacency matrix, the framework enhances trajectory
prediction accuracy while providing interpretable representations of vehicle
interactions. Then, potential collisions between the LC vehicle and adjacent
vehicles (direct risks) or among the non-adjacent vehicles (indirect risks) are
identified using oriented bounding box detection applied to the predicted
trajectories. Finally, a warning signal is generated to inform the LC driver of
location of potential collisions within the predicted time window. Traffic
simulation experiments conducted in SUMO demonstrate that the proposed
interaction-aware LCEW improves both vehicle-level safety and overall traffic
efficiency, while also promoting more natural behavioral adaptation.

</details>


### [337] [Dual Iterative Learning Control for Multiple-Input Multiple-Output Dynamics with Validation in Robotic Systems](https://arxiv.org/abs/2509.18723)
*Jan-Hendrik Ewering,Alessandro Papa,Simon F. G. Ehlers,Thomas Seel,Michael Meindl*

Main category: eess.SY

TL;DR: 该研究提出了一种名为MIMO双迭代学习控制（DILC）的新型数据驱动方法，用于解决多输入多输出（MIMO）系统的自主运动任务。该方法无需先验知识或手动调参，即可同时实现跟踪控制和模型学习，并在模拟和真实世界的MIMO系统中验证了其快速学习能力。


<details>
  <summary>Details</summary>
Motivation: 解决智能系统在多任务和多系统中的自主运动能力，特别是应对未知动力学和复杂MIMO系统手动调参的挑战。

Method: 提出了一种名为MIMO双迭代学习控制（DILC）的数据驱动迭代学习方案，用于同时进行跟踪控制和模型学习，无需先验系统知识或手动调参。该方案适用于重复性MIMO系统，并能与现有的迭代学习控制方法融合。研究给出了线时不变系统在参考跟踪误差和模型误差上的单调收敛条件。

Result: DILC方案在工业机器人高保真模拟和多个非线性真实世界MIMO系统中，实现了运动任务的快速自主求解，无需模型知识或手动调参。实验表明，许多参考跟踪任务在10-20次试验内完成，复杂运动学习在100次迭代内完成。

Conclusion: DILC因其快速自主学习能力，有潜力成为复杂智能真实世界系统学习框架中的高效构建模块。

Abstract: Solving motion tasks autonomously and accurately is a core ability for
intelligent real-world systems. To achieve genuine autonomy across multiple
systems and tasks, key challenges include coping with unknown dynamics and
overcoming the need for manual parameter tuning, which is especially crucial in
complex Multiple-Input Multiple-Output (MIMO) systems.
  This paper presents MIMO Dual Iterative Learning Control (DILC), a novel
data-driven iterative learning scheme for simultaneous tracking control and
model learning, without requiring any prior system knowledge or manual
parameter tuning. The method is designed for repetitive MIMO systems and
integrates seamlessly with established iterative learning control methods. We
provide monotonic convergence conditions for both reference tracking error and
model error in linear time-invariant systems.
  The DILC scheme -- rapidly and autonomously -- solves various motion tasks in
high-fidelity simulations of an industrial robot and in multiple nonlinear
real-world MIMO systems, without requiring model knowledge or manually tuning
the algorithm. In our experiments, many reference tracking tasks are solved
within 10-20 trials, and even complex motions are learned in less than 100
iterations. We believe that, because of its rapid and autonomous learning
capabilities, DILC has the potential to serve as an efficient building block
within complex learning frameworks for intelligent real-world systems.

</details>


### [338] [An Extended Kalman Filter for Systems with Infinite-Dimensional Measurements](https://arxiv.org/abs/2509.18749)
*Maxwell M. Varley,Timothy L. Molloy,Girish N. Nair*

Main category: eess.SY

TL;DR: 本文研究了具有有限状态和无限维测量的离散时间非线性随机系统的状态估计问题，并开发了一种扩展卡尔曼滤波器（EKF）。


<details>
  <summary>Details</summary>
Motivation: 该研究的动机源于诸如图象制导定位与跟踪等现实世界应用。文中提出的方法为在视觉制导状态估计中应用图像梯度提供了新的系统理论依据。

Method: 开发了一种用于实时状态估计的扩展卡尔曼滤波器（EKF），并将测量噪声建模为无限维随机场。在应用于视觉制导状态估计时，实现EKF所需的测量雅可比矩阵被证明对应于图像梯度。

Result: 在涉及使用下视单目相机视频对无人机进行定位的公开真实世界数据集上，证明了EKF的实用性。EKF在某些情况下优于已建立的视觉-惯性里程计算法VINS-MONO，均方误差降低了10倍。

Conclusion: 所提出的EKF在视觉制导状态估计方面显示出实际应用价值，并优于现有的先进算法。

Abstract: This article examines state estimation in discrete-time nonlinear stochastic
systems with finite-dimensional states and infinite-dimensional measurements,
motivated by real-world applications such as vision-based localization and
tracking. We develop an extended Kalman filter (EKF) for real-time state
estimation, with the measurement noise modeled as an infinite-dimensional
random field. When applied to vision-based state estimation, the measurement
Jacobians required to implement the EKF are shown to correspond to image
gradients. This result provides a novel system-theoretic justification for the
use of image gradients as features for vision-based state estimation,
contrasting with their (often heuristic) introduction in many computer-vision
pipelines. We demonstrate the practical utility of the EKF on a public
real-world dataset involving the localization of an aerial drone using video
from a downward-facing monocular camera. The EKF is shown to outperform
VINS-MONO, an established visual-inertial odometry algorithm, in some cases
achieving mean squared error reductions of up to an order of magnitude.

</details>


### [339] [Integration of Concentrated Solar Power Plants in Renewable-Only VPP with Electrical and Thermal Demands: A Two-Stage Robust Bidding Approach](https://arxiv.org/abs/2509.18769)
*Hadi Nemati,Pedro Sánchez-Martín,Álvaro Ortega,Lukas Sigrist,Luis Rouco*

Main category: eess.SY

TL;DR: 该论文提出将光热发电厂（CSP）整合到仅可再生能源的虚拟电厂（RVPP）中，以参与电力日前和备用市场，并通过热能购买协议交易热能。


<details>
  <summary>Details</summary>
Motivation: 整合 CSP 到 RVPP 以增强其在电力和热能市场的竞争力，并应对多种不确定性。

Method: 提出一种改进的两阶段鲁棒优化方法，考虑了电力价格、可再生能源发电量、CSP 热发电量以及电力和热能需求的不确定性。利用可调方法为 CSP 的储热分配电能和备用容量，以最大化 RVPP 的利润。

Result: 通过仿真案例研究证明了该方法的有效性和计算效率。结果表明，整合 CSP 提高了 RVPP 的灵活性，并增加了其在考虑所有交易选项和不同风险规避水平下的盈利能力。

Conclusion: 整合 CSP 到 RVPP 是提高 RVPP 灵活性和盈利能力的一种有效策略。

Abstract: This paper proposes the integration of Concentrated Solar Power Plant (CSP)
in the Renewable-only virtual power plant (RVPP) for bidding in the electricity
day-ahead and secondary reserve markets, as well as trading thermal energy
through a heat purchase agreement. A reformulated two-stage robust optimization
approach is introduced to account for multiple uncertainties, including
electricity prices, non-dispatchable renewable energy sources electrical
production, CSP thermal production, and uncertainties in electrical and thermal
demand consumption. The provision of energy and reserve by the thermal storage
of CSP is modeled using an adjustable approach, which allocates a share of
energy for up and down reserves based on the profitability of the RVPP.
Simulations are conducted for several case studies to demonstrate the
effectiveness and computational efficiency of the proposed approach under
different RVPP operator decisions against uncertain parameters and various
trading strategies for electricity and thermal energy. The simulation results
show that integrating CSP into RVPP enhances RVPP flexibility for both
electrical and thermal trading. Furthermore, the results indicate that the
profitability of the RVPP increases when all trading options are considered,
across different levels of conservatism adopted by the RVPP operator in
response to uncertain parameters.

</details>


### [340] [Frequency-Varying Optimization: A Control Framework for New Dynamic Frequency Response Services](https://arxiv.org/abs/2509.18935)
*Yiqiao Xu,Quan Wan,Alessandra Parisio*

Main category: eess.SY

TL;DR: 可再生能源发电具有波动性，为了解决这个问题，英国国家电网运营商（NESO）引入了三种新的动态服务，其中资产聚合在其中起着关键作用。本文将聚合响应单元（ARU）的频率响应问题建模为一个频率变化优化（FVO）问题，并提出了一种跟踪最优轨迹（TOT）的算法来解决这个问题，该算法适用于资产动态可忽略和需要考虑资产动态的两种情况。结果表明，ARU可以在固定时间内收敛到最优轨迹，并满足NESO要求的最大交付时间。该框架易于分布式部署，可用于协调大量资产。数值结果验证了所提出控制框架的有效性和可扩展性。


<details>
  <summary>Details</summary>
Motivation: 为了解决可再生能源发电的波动性问题，需要更快速有效的频率响应。英国国家电网运营商（NESO）引入了新的动态服务，其中资产聚合（ARU）是关键。ARU的频率响应需求随电网频率变化，形成频率变化的等式约束。

Method: 将ARU的优化协调问题建模为频率变化优化（FVO）问题。将FVO问题重新制定为跟踪最优轨迹（TOT）问题，并提出了两种算法：一种适用于资产动态可忽略的情况，另一种适用于需要考虑资产动态的情况。

Result: 在合理条件下，ARU可以在固定时间内收敛到最优轨迹，并在NESO要求的最大交付时间内满足要求。该框架可分布式部署，易于协调大量资产。

Conclusion: 所提出的基于TOT的框架能够有效地协调ARU以提供所需的频率响应，并且具有良好的可扩展性，能够满足NESO的要求。

Abstract: To address the variability of renewable generation, initiatives have been
launched globally to provide faster and more effective frequency responses. In
the UK, the National Energy System Operator (NESO) has introduced a suite of
three new dynamic services, where aggregation of assets is expected to play a
key role. For an Aggregated Response Unit (ARU), the required level of
frequency response varies with grid frequency, resulting in a frequency-varying
equality constraint that assets should meet collectively. We show that the
optimal coordination of an ARU constitutes a Frequency-Varying Optimization
(FVO) problem, in which the optimal trajectory for each asset evolves
dynamically. To facilitate online optimization, we reformulate the FVO problem
into Tracking of the Optimal Trajectory (TOT) problems, with algorithms
proposed for two scenarios: one where the asset dynamics are negligible, and
another where they must be accounted for. Under reasonable conditions, the ARU
converges to the optimal trajectory within a fixed time, and within the maximum
delivery time requested by NESO. The proposed framework can be readily
distributed to coordinate a large number of assets. Numerical results verify
the effectiveness and scalability of the proposed control framework.

</details>


### [341] [Adaptive Override Control under High-Relative-Degree Nonovershooting Constraints](https://arxiv.org/abs/2509.18988)
*Ziliang Lyu,Miroslav Krstic,Kaixin Lu,Yiguang Hong,Lihua Xie*

Main category: eess.SY

TL;DR: 本论文提出了一种自适应控制器，用于在存在高相对度非超调约束和参数不确定性的情况下，安全地覆盖不安全动作。


<details>
  <summary>Details</summary>
Motivation: 本研究旨在解决在存在高相对度非超调约束和参数不确定性的情况下，如何自适应地覆盖不安全动作的问题。

Method: 采用模块化设计方法，将控制器和参数估计器分开设计。控制器模块确保由参数不确定性引起 any safety violations 保持有界，前提是参数估计误差及其一阶导数有界或平方可积。估计器模块保证满足参数估计误差的要求。

Result: 理论分析和仿真结果表明，闭环安全违反由初始估计误差的可调函数界定。此外，随着时间的增加，参数估计收敛到真实值，安全违反量相应减少。

Conclusion: 所提出的方法能够有效地处理具有挑战性的安全约束和不确定性，并通过仿真证明了其有效性。

Abstract: This paper considers the problem of adaptively overriding unsafe actions of a
nominal controller in the presence of high-relative-degree nonovershooting
constraints and parametric uncertainties. To prevent the design from being
coupled with high-order derivatives of the parameter estimation error, we adopt
a modular design approach in which the controller and the parameter identifier
are designed separately. The controller module ensures that any safety
violations caused by parametric uncertainties remain bounded, provided that the
parameter estimation error and its first-order derivative are either bounded or
square-integrable. The identifier module, in turn, guarantees that these
requirements on the parameter estimation error are satisfied. Both theoretical
analysis and simulation results demonstrate that the closed-loop safety
violation is bounded by a tunable function of the initial estimation error.
Moreover, as time increases, the parameter estimate converges to the true
value, and the amount of safety violation decreases accordingly.

</details>


### [342] [A Weighted Least Squares Error Hetero-functional Graph State Estimator of the American Multi-modal Energy System](https://arxiv.org/abs/2509.19045)
*Dakota Thompson,Amro M. Farid*

Main category: eess.SY

TL;DR: 该论文提出了一个名为“美国多模式能源系统（AMES）”的框架，用于分析美国能源基础设施（电网、天然气、石油和煤炭）在气候变化背景下的相互依赖性，并开发了一种基于异构图论（HFGT）和加权最小二乘误差（WLSE）的状态估计方法（WLSEHFGSE），以资产级粒度恢复系统中的物质和能量流。


<details>
  <summary>Details</summary>
Motivation: 鉴于 21 世纪全球气候变化带来的严峻挑战，需要对包括电网、天然气、石油和煤炭在内的美国多模式能源系统（AMES）进行根本性变革。为了制定有效的政策，必须理解 AMES 的结构和行为相互依赖性。

Method: 该研究采用异构图论（HFGT）对 AMES 的两个区域进行建模和行为分析。具体而言，论文开发了一种加权最小二乘误差状态估计模型（WLSEHFGSE），该模型结合了数据驱动、基于模型的系统工程方法和 HFGT，旨在优化 AMES 中的物质和能量流。

Result: 该研究首次将状态估计方法与 HFGT 结合，并开发了 WLSEHFGSE 优化程序。实验证明，该方法能够以资产级粒度恢复 AMES 这种复杂系统中的物质和能量流。

Conclusion: 该论文成功地将状态估计方法与异构图论相结合，开发出一种能够精确恢复美国多模式能源系统中物质和能量流的方法，为应对气候变化相关的能源系统挑战提供了新的途径。

Abstract: As one of the most pressing challenges of the 21st century, global climate
change demands a host of changes across at least four critical energy
infrastructures: the electric grid, the natural gas system, the oil system, and
the coal system. In the context of the United States, this paper refers to this
system-of-systems as ``The American Multi-Modal Energy System (AMES)". These
combined changes necessitate an understanding of the AMES interdependencies,
both structurally and behaviorally, to develop and enact effective policies.
This work focuses on behavioral analysis methods to provide examples of how to
analyze system behavior and the critical matter and energy flows through the
system. Building upon past works, two regions of the AMES are modeled, and
their behavior is analyzed using Hetero-functional Graph Theory (HFGT). More
specifically, the work presents a weighted least square error state estimation
model of the AMES. State estimation has played a major role in the operation
and development of the American Electric Power System. This work extends the
state estimation analysis beyond the single-operand electric grid environment
into the heterogeneous environment of the AMES. Employing a data-driven and
model-based systems engineering approach in combination with HFGT, a Weighted
Least Squares Error Hetero-functional Graph State Estimation (WLSEHFGSE)
optimization program is developed to estimate the optimal flows of mass and
energy through the AMES. This work is the first to integrate state estimation
methods with HFGT. Furthermore, it demonstrates how such a WLSEHFGSE recovers
the mass and energy flows in a system-of-systems like the AMES with asset-level
granularity.

</details>


### [343] [MAPPO for Edge Server Monitoring](https://arxiv.org/abs/2509.19079)
*Samuel Chamoun,Christian McDowell,Robin Buchanan,Kevin Chan,Eric Graves,Yin Sun*

Main category: eess.SY

TL;DR: 该论文提出了一种基于MAPPO的算法，通过优化查询调度来解决边缘服务器监控中的通信问题，以平衡吞吐量和通信开销。


<details>
  <summary>Details</summary>
Motivation: 在边缘服务器监控中，准确了解服务器状态对于维持高吞吐量至关重要，但在动态工作负载和部分可观测性下难以实现。

Method: 通过主动状态查询和作业执行反馈两种机制来维护服务器知识，并提出了一种基于多智能体近端策略优化（MAPPO）的算法，采用集中训练分布式执行（CTDE）的方法来学习分布式查询和调度策略。

Result: MAPPO算法在吞吐量-成本权衡方面表现优越，平均比最近的基线提高了30%。

Conclusion: 所提出的MAPPO算法能够有效解决边缘服务器监控中的通信问题，并显著提高系统性能。

Abstract: In this paper, we consider a goal-oriented communication problem for edge
server monitoring, where jobs arrive intermittently at multiple dispatchers and
must be assigned to shared edge servers with finite queues and time-varying
availability. Accurate knowledge of server status is critical for sustaining
high throughput, yet remains challenging under dynamic workloads and partial
observability. To address this challenge, each dispatcher maintains server
knowledge through two complementary mechanisms: (i) active status queries that
provide instantaneous updates at a communication cost, and (ii) job execution
feedback that reveals server conditions opportunistically. We formulate a
cooperative multi-agent distributed decision-making problem in which
dispatchers jointly optimize query scheduling to balance throughput against
communication overhead. To solve this problem, we propose a Multi-Agent
Proximal Policy Optimization (MAPPO)-based algorithm that leverages centralized
training with decentralized execution (CTDE) to learn distributed
query-and-dispatch policies under partial and stale observations. Numerical
evaluations show that MAPPO achieves superior throughput-cost tradeoffs and
significantly outperforms baseline strategies, achieving on average a 30%
improvement over the closest baseline.

</details>


### [344] [AI-Enabled Smart Hygiene System for Real-Time Glucose Detection](https://arxiv.org/abs/2509.19107)
*Khan Masood Parvez,Sk Md Abidar Rahaman,Ali Shiri Sichani,Hadi AliAkbarpour*

Main category: eess.SY

TL;DR: 基于CPW馈电的微带环形天线生物传感器可用于检测尿液样本中的生物标志物。


<details>
  <summary>Details</summary>
Motivation: 开发一种能够实时监测用户泌尿健康状况的智能系统，以实现早期疾病检测和个性化健康管理。

Method: 设计并实现了一种CPW馈电的微带环形天线生物传感器，能够通过测量谐振频率的变化来检测尿液样本的五种不同状况。同时，提出了一种基于CNN-LSTM的AI框架，用于处理重叠的频率响应，提高健康状况检测的准确性。

Result: 天线在暴露于五种特定尿液状况时，其谐振频率相对于基线1.42 GHz发生了明显偏移，证明了其作为微波传感器的有效性。AI框架有望提高检测准确性。

Conclusion: 所提出的智能监测系统，结合了先进的天线设计和AI算法，能够实时、无感地监测用户健康状况，为智能家居和远程医疗提供了新的解决方案。

Abstract: This research presents a smart urinary health monitoring system incorporating
a coplanar waveguide (CPW)-fed slot-loop antenna biosensor designed to analyse
various urine samples. The antenna demonstrates distinct resonant frequency
shifts when exposed to five specific urine conditions, deviating from its
baseline 1.42 GHz operation. These measurable frequency variations enable the
antenna to function as an effective microwave sensor for urinary biomarker
detection. A potential artificial intelligence-based Convolutional Neural
Networks Long Short-Term Memory (CNN-LSTM) framework is also discussed to
overcome the limitations of overlapping frequency responses, aiming to improve
the accuracy of health condition detection. These components contribute to the
development of a smart toilet system that displays real-time health information
on a wall-mounted urinal screen, without requiring any user effort or
behavioural change.

</details>


### [345] [A Fast Initialization Method for Neural Network Controllers: A Case Study of Image-based Visual Servoing Control for the multicopter Interception](https://arxiv.org/abs/2509.19110)
*Chenxu Ke,Congling Tian,Kaichen Xu,Ye Li,Lingcong Bao*

Main category: eess.SY

TL;DR: 该方法提出了一种基于模型和稳定性条件的快速神经网络控制器初始化方法，解决了强化学习训练数据需求大、收敛慢以及基于李雅普诺夫稳定性的方法需要初始稳定策略的问题。


<details>
  <summary>Details</summary>
Motivation: 现有的基于强化学习的控制器设计方法需要大量初始训练数据，且存在随机性强、收敛慢和计算资源需求高的问题。基于李雅普诺夫稳定性的方法虽然能提供稳定性保证，但通常需要一个初始稳定的神经网络控制策略。然而，设计一个初始稳定的控制器需要大量的控制设计知识，这对于日益复杂的控制问题来说是一个挑战。

Method: 提出了一种新的神经网络快速初始化方法，该方法通过构建符合稳定性条件的数据集，并基于系统模型来初始化神经网络控制策略。这种方法可以作为强化学习的初始策略，从而将训练重点放在提高控制器性能上，也可以作为基于学习的李雅普诺夫控制方法的初始状态。

Result: 所提出的方法通过一个多旋翼飞机拦截的图像视觉伺服控制的案例进行了仿真和实验验证。实验结果表明，该方法能够有效地训练控制策略，并实现了最终15米/秒的拦截速度。

Conclusion: 所提出的神经网络快速初始化方法能够有效地解决传统强化学习训练数据需求大、收敛慢以及基于李雅普诺夫方法需要初始稳定策略的缺点，并通过多旋翼飞机拦截实验验证了其有效性和实用性。

Abstract: Reinforcement learning-based controller design methods often require
substantial data in the initial training phase. Moreover, the training process
tends to exhibit strong randomness and slow convergence. It often requires
considerable time or high computational resources. Another class of
learning-based method incorporates Lyapunov stability theory to obtain a
control policy with stability guarantees. However, these methods generally
require an initially stable neural network control policy at the beginning of
training. Evidently, a stable neural network controller can not only serve as
an initial policy for reinforcement learning, allowing the training to focus on
improving controller performance, but also act as an initial state for
learning-based Lyapunov control methods. Although stable controllers can be
designed using traditional control theory, designers still need to have a great
deal of control design knowledge to address increasingly complicated control
problems. The proposed neural network rapid initialization method in this paper
achieves the initial training of the neural network control policy by
constructing datasets that conform to the stability conditions based on the
system model. Furthermore, using the image-based visual servoing control for
multicopter interception as a case study, simulations and experiments were
conducted to validate the effectiveness and practical performance of the
proposed method. In the experiment, the trained control policy attains a final
interception velocity of 15 m/s.

</details>


### [346] [Robust Synchronous Reference Frame Phase-Looked Loop (PLL) with Feed-Forward Frequency Estimation](https://arxiv.org/abs/2509.19111)
*Michael Ruderman,Elia Brescia,Paolo Roberto Massenio,Giuseppe Leonardo Cascella,David Naso*

Main category: eess.SY

TL;DR: 该研究提出了一种改进的同步参考帧锁相环（SRF-PLL）技术，通过引入鲁棒设计和前馈频率估计器，提高了在电力系统中的性能，使其对输入信号的幅值变化不敏感，并能更好地跟踪频率变化。


<details>
  <summary>Details</summary>
Motivation: 传统的SRF-PLL在处理含有噪声和变化的输入信号时，其锁相性能会受到影响。需要改进PLL设计以提高其鲁棒性和动态响应。

Method: 采用比例-积分（PI）控制器，并通过最大化相角裕度和采用归一化方案来设计鲁棒的反馈环路，使其对输入信号的幅值不敏感。此外，引入一个模型无关的前馈频率估计器来改善瞬态响应和频率斜坡跟踪能力。

Result: 提出的改进型SRF-PLL方案在包含变化角速度和负载的永磁同步电机（PMSM）驱动器的三相谐波电流上进行了实验验证，评估了其跟踪角频率和锁相角的能力。

Conclusion: 提出的前馈-反馈SRF-PLL方案能够有效提高锁相环在电力系统应用中的鲁棒性和动态性能，尤其是在处理噪声和变化信号时。

Abstract: Synchronous reference frame phase-looked loop (SRF-PLL) techniques are widely
used for interfacing and control applications in the power systems and energy
conversion at large. Since a PLL system synchronizes its output with an
exogenous harmonic signal, often 3-phases voltage or current, the locking of
the frequency and phase angle depends on the performance of the feedback loop
with at least two integrator terms, and on the distortions of the measured
input quantities. For the conventional SRF-PLL with a proportional-integral
(PI) control in feedback, we are providing a robust design which maximizes the
phase margin and uses the normalization scheme for yielding the loop
insensitive to the input amplitude variations. The main improvement in the
transient behavior and also in tracking of frequency ramps is achieved by using
the robust feed-forward frequency estimator, which is model-free and suitable
for the noisy and time-varying harmonic signals. The proposed
feed-forward-feedback SRF-PLL scheme is experimentally evaluated on the
3-phases harmonic currents from standard PMSM drives with varying angular
speeds and loads. Both, the tracked angular frequency and locked phase angle
are assessed as performance metrics of the robust SRF-PLL scheme with
feedforwarding.

</details>


### [347] [Watts and Drops: Co-Scheduling Power and Water in Desalination Plants](https://arxiv.org/abs/2509.19243)
*Ahmed S. Alahmed,Audun Botterud,Saurabh Amin,Ali T. Al-Awami*

Main category: eess.SY

TL;DR: 该论文提出了一个数学框架，用于联合调度一个以营利为目的的、结合了热能和膜技术的可再生能源协同水处理厂的用水和用电。该工厂将处理后的水以固定价格出售给水务公司，并根据其净用电需求与电网进行双向电力交易。


<details>
  <summary>Details</summary>
Motivation: 开发一个数学框架，用于联合调度可再生能源协同水处理厂的用水和用电，以实现利润最大化。

Method: 提出一个数学框架，调度热能和膜技术协同的水处理厂的用水和用电。

Result: 最优调度策略依赖于工厂的内部可再生能源发电量，并呈现出简单的阈值结构。在该策略下，基于热能的产水随着可再生能源发电量的增加而单调递减，而基于膜的产水则单调递增。

Conclusion: 得出了最优调度策略的阈值结构及其背后的直观原理，并探讨了其关键特性。

Abstract: We develop a mathematical framework to jointly schedule water and electricity
in a profit-maximizing renewable colocated water desalination plant that
integrates both thermal and membrane based technologies. The price-taking
desalination plant sells desalinated water to a water utility at a given price
and engages in bidirectional electricity transactions with the grid, purchasing
or selling power based on its net electricity demand. We show that the optimal
scheduling policy depends on the plant's internal renewable generation and
follows a simple threshold structure. Under the optimal policy, thermal based
water output decreases monotonically with renewable output, while membrane
based water output increases monotonically. We characterize the structure and
intuition behind the threshold policy and examine key special properties.

</details>


### [348] [Policy Gradient Bounds in Multitask LQR](https://arxiv.org/abs/2509.19266)
*Charis Stamouli,Leonardo F. Toso,Anastasios Tsiamis,George J. Pappas,James Anderson*

Main category: eess.SY

TL;DR: 我们提出了一种基于双模仿度量的任务异质性方法，用于多任务线性二次调节（LQR）问题，以改进策略梯度方法的性能保证。


<details>
  <summary>Details</summary>
Motivation: 现有关于多任务 LQR 的分析未能捕捉到闭环任务的相似性，导致性能保证过于保守。因此，需要一种新的方法来衡量任务异质性，并在此基础上改进性能。

Method: 提出基于双模仿度量的任务异质性方法，使用新的双模仿函数来约束在共同稳定控制器下，一对任务之间的闭环成本梯度距离。利用这些度量，推导出多任务最优控制器和渐近策略梯度控制器在每个任务上的次优界。

Result: 在多个随机任务集上，我们提出的基于双模仿度量的任务异质性方法，相比于基线度量，在改进任务异质性方面表现出显著的提升。

Conclusion: 基于双模仿度量的任务异质性方法可以更准确地捕捉多任务 LQR 中的任务相似性，从而为策略梯度方法提供更优的性能保证，并在实践中取得了更好的效果。

Abstract: We analyze the performance of policy gradient in multitask linear quadratic
regulation (LQR), where the system and cost parameters differ across tasks. The
main goal of multitask LQR is to find a controller with satisfactory
performance on every task. Prior analyses on relevant contexts fail to capture
closed-loop task similarities, resulting in conservative performance
guarantees. To account for such similarities, we propose bisimulation-based
measures of task heterogeneity. Our measures employ new bisimulation functions
to bound the cost gradient distance between a pair of tasks in closed loop with
a common stabilizing controller. Employing these measures, we derive
suboptimality bounds for both the multitask optimal controller and the
asymptotic policy gradient controller with respect to each of the tasks. We
further provide conditions under which the policy gradient iterates remain
stabilizing for every system. For multiple random sets of certain tasks, we
observe that our bisimulation-based measures improve upon baseline measures of
task heterogeneity dramatically.

</details>


<div id='cs.GR'></div>

# cs.GR [[Back]](#toc)

### [349] [Zero-Shot Visual Deepfake Detection: Can AI Predict and Prevent Fake Content Before It's Created?](https://arxiv.org/abs/2509.18461)
*Ayan Sar,Sampurna Roy,Tanupriya Choudhury,Ajith Abraham*

Main category: cs.GR

TL;DR: 本研究探讨了零样本深度伪造检测和预防策略，以应对日益增长的深度伪造威胁。


<details>
  <summary>Details</summary>
Motivation: 深度伪造技术（如GANs和扩散模型）的快速发展对数字安全、媒体诚信和公众信任构成了严重威胁，需要新的检测和预防方法。

Method: 研究了自监督学习、基于Transformer的零样本分类器、生成模型指纹识别和元学习技术，并提出了包括对抗性扰动、数字水印、实时AI监控和基于区块链的内容验证在内的AI驱动的预防策略。

Result: 在零样本检测方面，研究探索了多种先进技术，并提出了一系列预防措施。然而，仍面临对抗性攻击、可扩展性、伦理困境和缺乏标准化评估基准等挑战。

Conclusion: 零样本检测和预防仍面临挑战，未来的研究方向包括可解释AI、多模态融合、量子AI和联邦学习。需要一个结合零样本学习和预防机制的综合性数字真实性防御框架，并强调跨学科合作的重要性。

Abstract: Generative adversarial networks (GANs) and diffusion models have dramatically
advanced deepfake technology, and its threats to digital security, media
integrity, and public trust have increased rapidly. This research explored
zero-shot deepfake detection, an emerging method even when the models have
never seen a particular deepfake variation. In this work, we studied
self-supervised learning, transformer-based zero-shot classifier, generative
model fingerprinting, and meta-learning techniques that better adapt to the
ever-evolving deepfake threat. In addition, we suggested AI-driven prevention
strategies that mitigated the underlying generation pipeline of the deepfakes
before they occurred. They consisted of adversarial perturbations for creating
deepfake generators, digital watermarking for content authenticity
verification, real-time AI monitoring for content creation pipelines, and
blockchain-based content verification frameworks. Despite these advancements,
zero-shot detection and prevention faced critical challenges such as
adversarial attacks, scalability constraints, ethical dilemmas, and the absence
of standardized evaluation benchmarks. These limitations were addressed by
discussing future research directions on explainable AI for deepfake detection,
multimodal fusion based on image, audio, and text analysis, quantum AI for
enhanced security, and federated learning for privacy-preserving deepfake
detection. This further highlighted the need for an integrated defense
framework for digital authenticity that utilized zero-shot learning in
combination with preventive deepfake mechanisms. Finally, we highlighted the
important role of interdisciplinary collaboration between AI researchers,
cybersecurity experts, and policymakers to create resilient defenses against
the rising tide of deepfake attacks.

</details>


### [350] [Differentiable Light Transport with Gaussian Surfels via Adapted Radiosity for Efficient Relighting and Geometry Reconstruction](https://arxiv.org/abs/2509.18497)
*Kaiwen Jiang,Jia-Mu Sun,Zilu Li,Dan Wang,Tzu-Mao Li,Ravi Ramamoorthi*

Main category: cs.GR

TL;DR: 高斯表面元结合可微光线传输，实现高效的全局光照渲染，包括镜面反射，并优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有 radiance fields 在材质反射和光照条件建模方面存在不足，导致几何歧义和重光照困难。传统基于物理的渲染计算成本高，简化方法精度不足。

Method: 提出了一种基于高斯表面元和球谐系数空间的可微光线传输框架，扩展了经典辐射度理论，解决了非二元可见性和半透明问题，并推导了高效的梯度优化反向传播。

Result: 实现了视图无关的渲染，每秒帧数可达数百，能够处理包括镜面反射在内的全局光照效果。在几何重建、视图合成和重光照方面，相较于现有基线方法表现更优。

Conclusion: 该框架通过高效的可微光线传输，在保持高渲染效率的同时，显著提升了 radiance fields 在材质和光照建模方面的能力，并在多种评估指标上超越了现有技术。

Abstract: Radiance fields have gained tremendous success with applications ranging from
novel view synthesis to geometry reconstruction, especially with the advent of
Gaussian splatting. However, they sacrifice modeling of material reflective
properties and lighting conditions, leading to significant geometric
ambiguities and the inability to easily perform relighting. One way to address
these limitations is to incorporate physically-based rendering, but it has been
prohibitively expensive to include full global illumination within the inner
loop of the optimization. Therefore, previous works adopt simplifications that
make the whole optimization with global illumination effects efficient but less
accurate. In this work, we adopt Gaussian surfels as the primitives and build
an efficient framework for differentiable light transport, inspired from the
classic radiosity theory. The whole framework operates in the coefficient space
of spherical harmonics, enabling both diffuse and specular materials. We extend
the classic radiosity into non-binary visibility and semi-opaque primitives,
propose novel solvers to efficiently solve the light transport, and derive the
backward pass for gradient optimizations, which is more efficient than
auto-differentiation. During inference, we achieve view-independent rendering
where light transport need not be recomputed under viewpoint changes, enabling
hundreds of FPS for global illumination effects, including view-dependent
reflections using a spherical harmonics representation. Through extensive
qualitative and quantitative experiments, we demonstrate superior geometry
reconstruction, view synthesis and relighting than previous inverse rendering
baselines, or data-driven baselines given relatively sparse datasets with known
or unknown lighting conditions.

</details>


### [351] [Text Slider: Efficient and Plug-and-Play Continuous Concept Control for Image/Video Synthesis via LoRA Adapters](https://arxiv.org/abs/2509.18831)
*Pin-Yen Chiu,I-Sheng Fang,Jun-Cheng Chen*

Main category: cs.GR

TL;DR: Text Slider是一个轻量级、高效且即插即用的框架，通过在预训练的文本编码器中识别低秩方向，实现对视觉概念的连续控制，同时显著减少了训练时间、GPU内存消耗和可训练参数数量。它还支持多概念组合和连续控制，可用于图像和视频合成。


<details>
  <summary>Details</summary>
Motivation: 现有的概念控制方法需要大量的训练时间和GPU内存，并且需要为不同的扩散模型进行重新训练，限制了其可扩展性和适应性。

Method: Text Slider通过识别预训练文本编码器中的低秩方向来实现对视觉概念的连续控制。

Result: Text Slider比Concept Slider快5倍，比Attribute Control快47倍，同时GPU内存使用量分别减少了近2倍和4倍。

Conclusion: Text Slider实现了比现有方法更高效的训练和更低的内存占用，同时保持了对图像和视频合成的精细控制能力。

Abstract: Recent advances in diffusion models have significantly improved image and
video synthesis. In addition, several concept control methods have been
proposed to enable fine-grained, continuous, and flexible control over
free-form text prompts. However, these methods not only require intensive
training time and GPU memory usage to learn the sliders or embeddings but also
need to be retrained for different diffusion backbones, limiting their
scalability and adaptability. To address these limitations, we introduce Text
Slider, a lightweight, efficient and plug-and-play framework that identifies
low-rank directions within a pre-trained text encoder, enabling continuous
control of visual concepts while significantly reducing training time, GPU
memory consumption, and the number of trainable parameters. Furthermore, Text
Slider supports multi-concept composition and continuous control, enabling
fine-grained and flexible manipulation in both image and video synthesis. We
show that Text Slider enables smooth and continuous modulation of specific
attributes while preserving the original spatial layout and structure of the
input. Text Slider achieves significantly better efficiency: 5$\times$ faster
training than Concept Slider and 47$\times$ faster than Attribute Control,
while reducing GPU memory usage by nearly 2$\times$ and 4$\times$,
respectively.

</details>


### [352] [One-shot Embroidery Customization via Contrastive LoRA Modulation](https://arxiv.org/abs/2509.18948)
*Jun Ma,Qian He,Gaofeng He,Huang Chen,Chen Liu,Xiaogang Jin,Huamin Wang*

Main category: cs.GR

TL;DR: 提出了一种新颖的对比学习框架，用于解耦细粒度风格和内容特征，以实现绣花等纺织艺术的定制化。


<details>
  <summary>Details</summary>
Motivation: 现有的风格迁移方法在处理绣花这种具有复杂针法和材质特性的纺织艺术时面临挑战，需要能够进行细粒度视觉特征迁移的技术。

Method: 提出了一种新颖的对比学习框架，利用预训练的扩散模型解耦风格和内容特征。通过构建图像对定义目标风格，并采用基于解耦表示的相似性度量。然后，利用两阶段对比LoRA调制技术捕捉细粒度风格特征，第一阶段更新整个LoRA和选定的风格块以初步分离风格和内容，第二阶段通过自知识蒸馏进一步解耦。最后构建推理流程，仅使用风格块处理图像或文本输入。

Result: 提出的方法在绣花定制化基准测试中超越了现有方法，并在艺术风格迁移、素描着色和外观迁移三个附加领域展现出强大的泛化能力。

Conclusion: 该方法有效实现了细粒度风格迁移，特别是在绣花定制化方面，并具有良好的泛化性，为相关领域的图像处理提供了新的解决方案。

Abstract: Diffusion models have significantly advanced image manipulation techniques,
and their ability to generate photorealistic images is beginning to transform
retail workflows, particularly in presale visualization. Beyond artistic style
transfer, the capability to perform fine-grained visual feature transfer is
becoming increasingly important. Embroidery is a textile art form characterized
by intricate interplay of diverse stitch patterns and material properties,
which poses unique challenges for existing style transfer methods. To explore
the customization for such fine-grained features, we propose a novel
contrastive learning framework that disentangles fine-grained style and content
features with a single reference image, building on the classic concept of
image analogy. We first construct an image pair to define the target style, and
then adopt a similarity metric based on the decoupled representations of
pretrained diffusion models for style-content separation. Subsequently, we
propose a two-stage contrastive LoRA modulation technique to capture
fine-grained style features. In the first stage, we iteratively update the
whole LoRA and the selected style blocks to initially separate style from
content. In the second stage, we design a contrastive learning strategy to
further decouple style and content through self-knowledge distillation.
Finally, we build an inference pipeline to handle image or text inputs with
only the style blocks. To evaluate our method on fine-grained style transfer,
we build a benchmark for embroidery customization. Our approach surpasses prior
methods on this task and further demonstrates strong generalization to three
additional domains: artistic style transfer, sketch colorization, and
appearance transfer.

</details>


<div id='cs.NE'></div>

# cs.NE [[Back]](#toc)

### [353] [Smart Cellular Bricks for Decentralized Shape Classification and Damage Recovery](https://arxiv.org/abs/2509.18659)
*Rodrigo Moreno,Andres Faina,Shyam Sudhakaran,Kathryn Walker,Sebastian Risi*

Main category: cs.NE

TL;DR: 受生物系统去中心化自我识别和形态再生能力的启发，我们提出了一种基于神经网络的3D细胞砖系统，该系统仅通过局部交互即可实现全局形状分类和损伤检测，并具有良好的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 受生物系统中仅依赖局部相互作用的去中心化自我识别和形态再生能力的启发。

Method: 利用神经网络细胞自动机（NCA），一个学习到的、完全去中心化的算法，使每个模块能够独立执行相同的神经网络，而无需访问任何全局状态或定位信息。

Result: 由数百个细胞砖组成的集合能够通过纯粹的局部交互准确地对各种3D形状进行分类，并且对异类形状变化、通信故障和模块故障具有很强的鲁棒性。该框架还可用于检测缺失或损坏的组件，从而实现对结构中断的本地化和恢复过程的指导。

Conclusion: 这项工作提供了大规模、去中心化自我识别和损伤检测的物理实现，推进了鲁棒、自适应和受生物启发的模块化系统的潜力。

Abstract: Biological systems possess remarkable capabilities for self-recognition and
morphological regeneration, often relying solely on local interactions.
Inspired by these decentralized processes, we present a novel system of
physical 3D bricks--simple cubic units equipped with local communication,
processing, and sensing--that are capable of inferring their global shape class
and detecting structural damage. Leveraging Neural Cellular Automata (NCA), a
learned, fully-distributed algorithm, our system enables each module to
independently execute the same neural network without access to any global
state or positioning information. We demonstrate the ability of collections of
hundreds of these cellular bricks to accurately classify a variety of 3D shapes
through purely local interactions. The approach shows strong robustness to
out-of-distribution shape variations and high tolerance to communication faults
and failed modules. In addition to shape inference, the same decentralized
framework is extended to detect missing or damaged components, allowing the
collective to localize structural disruptions and to guide a recovery process.
This work provides a physical realization of large-scale, decentralized
self-recognition and damage detection, advancing the potential of robust,
adaptive, and bio-inspired modular systems.

</details>


<div id='cs.ET'></div>

# cs.ET [[Back]](#toc)

### [354] [Energy-convergence trade off for the training of neural networks on bio-inspired hardware](https://arxiv.org/abs/2509.18121)
*Nikhil Garg,Paul Uriarte Vicandi,Yanming Zhang,Alexandre Baigol,Donato Francesco Falcone,Saketh Ram Mamidala,Bert Jan Offrein,Laura Bégon-Lours*

Main category: cs.ET

TL;DR: 基于HfO2/ZrO2超晶格的铁电突触器件通过短脉冲编程和定制训练实现了高效的片上学习，在保持准确性的同时降低了能耗。


<details>
  <summary>Details</summary>
Motivation: 在极端边缘部署AI处理需要超低功耗，铁电突触器件有潜力通过减少数据传输来加速神经网络训练，但需要在性能和能效之间取得平衡。

Method: 研究基于HfO2/ZrO2超晶格的铁电突触器件，并将实验测量的权重更新输入到硬件感知神经网络模拟中，分析不同脉冲宽度下的能量和准确性，并提出“对称点偏移”技术。

Result: 研究发现，较短的脉冲宽度可以降低单次更新的能耗，但需要更多的训练周期，不过总能耗有所降低且准确性未受影响。与混合精度SGD相比，普通SGD的分类准确性有所下降。提出的“对称点偏移”技术能够恢复准确性。

Conclusion: 在准确性、收敛速度和能耗之间存在权衡。短脉冲编程结合定制训练可以显著提高片上学习的效率。

Abstract: The increasing deployment of wearable sensors and implantable devices is
shifting AI processing demands to the extreme edge, necessitating ultra-low
power for continuous operation. Inspired by the brain, emerging memristive
devices promise to accelerate neural network training by eliminating costly
data transfers between compute and memory. Though, balancing performance and
energy efficiency remains a challenge. We investigate ferroelectric synaptic
devices based on HfO2/ZrO2 superlattices and feed their experimentally measured
weight updates into hardware-aware neural network simulations. Across pulse
widths from 20 ns to 0.2 ms, shorter pulses lower per-update energy but require
more training epochs while still reducing total energy without sacrificing
accuracy. Classification accuracy using plain stochastic gradient descent (SGD)
is diminished compared to mixed-precision SGD. We analyze the causes and
propose a ``symmetry point shifting'' technique, addressing asymmetric updates
and restoring accuracy. These results highlight a trade-off among accuracy,
convergence speed, and energy use, showing that short-pulse programming with
tailored training significantly enhances on-chip learning efficiency.

</details>


### [355] [Weight Mapping Properties of a Dual Tree Single Clock Adiabatic Capacitive Neuron](https://arxiv.org/abs/2509.18143)
*Mike Smart,Sachin Maheshwari,Himadri Singh Raghav,Alexander Serb*

Main category: cs.ET

TL;DR: DTSC ACN电路在ANN计算中具有高能效潜力，但将AN权重映射到ACN电容值仍有待研究。本文探讨了映射的复杂性、挑战和影响，并提出了一种优化方法，可减小芯片尺寸并提高分类准确性。我们使用TensorFlow和Larq训练了三个ANN网络，并将其权重映射到DTSC ACN电容值域，验证了100%的功能等效性。此外，我们还研究了权重量化对ACN性能的影响，并提出了新的IC设计指标。


<details>
  <summary>Details</summary>
Motivation: 将软件训练的ANN中的抽象权重有效映射到物理ACN电容值是一个未被充分研究的领域，具有潜在的挑战和影响，需要解决以实现实际应用。

Method: 研究将AN权重映射到ACN电容值的复杂性、挑战和特性。提出了一种优化的AN到ACN映射方法。使用TensorFlow和Larq训练了三个ANN网络，并将它们的权重映射到DTSC ACN电容值域。引入了与IC设计相关的性能指标，如芯片面积和比较器决策效率。

Result: 成功地将三个ANN网络的权重映射到DTSC ACN电容值域，并验证了100%的功能等效性。提出的优化方法有望减小芯片尺寸并提高分类准确性。研究了权重量化对ACN性能的影响。

Conclusion: 将AN权重映射到ACN电容值具有隐藏的复杂性，但通过优化的映射方法可以克服这些挑战。这种方法可以实现高能效的ANN计算，并为IC设计带来更小的芯片尺寸和更高的准确性。对权重量化对IC设计考虑因素的影响的进一步研究是必要的。

Abstract: Dual Tree Single Clock (DTSC) Adiabatic Capacitive Neuron (ACN) circuits
offer the potential for highly energy-efficient Artificial Neural Network (ANN)
computation in full custom analog IC designs. The efficient mapping of
Artificial Neuron (AN) abstract weights, extracted from the software-trained
ANNs, onto physical ACN capacitance values has, however, yet to be fully
researched. In this paper, we explore the unexpected hidden complexities,
challenges and properties of the mapping, as well as, the ramifications for IC
designers in terms accuracy, design and implementation. We propose an optimal,
AN to ACN methodology, that promotes smaller chip sizes and improved overall
classification accuracy, necessary for successful practical deployment. Using
TensorFlow and Larq software frameworks, we train three different ANN networks
and map their weights into the energy-efficient DTSC ACN capacitance value
domain to demonstrate 100% functional equivalency. Finally, we delve into the
impact of weight quantization on ACN performance using novel metrics related to
practical IC considerations, such as IC floor space and comparator
decision-making efficacy.

</details>


### [356] [Lightweight Targeted Estimation of Layout Noise in a Quantum Computer using Quality Indicator Circuits](https://arxiv.org/abs/2509.18679)
*Shikhar Srivastava,Ritajit Majumdar,Padmanabha Venkatagiri Seshadri,Anupama Ray,Yogesh Simmhan*

Main category: cs.ET

TL;DR: QIC是一种轻量级的实时方法，用于评估量子电路布局质量，以减少噪声并提高性能。


<details>
  <summary>Details</summary>
Motivation: 量子计算中的噪声最小化对于可靠执行量子电路至关重要，而电路到硬件的映射是影响性能的关键因素，现有方法存在局限性。

Method: 提出了一种名为质量指示电路（QIC）的轻量级、实时方法。QIC是小型探测电路，保留用户电路的基本结构，其理想的无噪声结果是已知的，用于评估哪个硬件区域最适合执行目标电路。具体方法包括：1. 基本方法：为每个同构布局执行QIC以选择最佳布局。2. 改进方法：通过合并多个布局的Union QIC方法，以及允许重叠的基于失真阈值的方法，进一步降低开销。

Result: 与Mapomatic相比，QIC在布局选择质量上更优；与JIT相比，硬件开销平均减少79%。

Conclusion: QIC是一种轻量级、可靠的量子设备布局选择技术，适用于近期量子设备。

Abstract: In the current era of quantum computing, minimizing noise is essential for
reliably executing quantum circuits on hardware. A key factor affecting circuit
performance is the mapping of the abstract quantum circuit to the physical
layout of the quantum hardware. This mapping can significantly influence output
quality, especially since hardware noise profiles are non-uniform and dynamic.
Existing solutions such as Mapomatic and Just-In-Time (JIT) Transpilation
attempt to address this issue but are limited either by relying on stale
calibration data or high hardware usage, respectively. In this article, we
propose Quality Indicator Circuits (QICs) as a lightweight, real-time method
for assessing layout quality. A QIC is a small probe circuit that is designed
to retain the basic structure of the user's circuit and whose ideal noiseless
outcome is known. It is used to evaluate which region of the quantum hardware
is best suited for executing the circuit of interest. We first propose a basic
method where a QIC is executed for each isomorphic layout to detect the best
among them. Although this requires several targeted circuit executions, we show
that it still, in most cases, reduces the execution overheads as compared with
JIT. To reduce the overheads further, we propose the union of multiple layouts
with a Union QIC approach that has no overlaps, and a Distortion Threshold
based approach allowing some overlap. Our results show that these outperform
Mapomatic in the quality of layout selection while reducing the hardware
overhead of JIT by 79 percent on average. This makes our proposed method
lightweight and reliable, and a viable technique for layout selection in
near-term quantum devices.

</details>


### [357] [Integrating Stacked Intelligent Metasurfaces and Power Control for Dynamic Edge Inference via Over-The-Air Neural Networks](https://arxiv.org/abs/2509.18906)
*Kyriakos Stylianopoulos,George C. Alexandropoulos*

Main category: cs.ET

TL;DR: 该研究提出了一种利用堆叠智能超表面（SIM）来控制无线信号传播，使信道能够执行空中计算的新型边缘推理（EI）框架，从而无需接收器端的符号估计，显著降低了计算和通信开销。


<details>
  <summary>Details</summary>
Motivation: 传统边缘推理将无线信道视为噪声，而本研究旨在利用SIM控制无线传播，使信道本身实现空中计算，从而消除符号估计的需要，降低计算和通信开销。

Method: 将发射器-信道-接收器系统建模为一个端到端的深度神经网络（DNN），其中SIM单元的响应是可训练参数，并引入一个专门的DNN模块，利用用户位置信息动态调整传输功率以应对信道变化。

Result: 提出的集成超表面的DNN框架，采用深度SIM架构，能够在不同场景下平衡分类准确性和功耗，实现显著的能效提升。

Conclusion: 所提出的方法通过利用SIM控制无线传播实现空中计算，并结合动态功率调整，在保持分类准确性的同时显著提高了能源效率。

Abstract: This paper introduces a novel framework for Edge Inference (EI) that bypasses
the conventional practice of treating the wireless channel as noise. We utilize
Stacked Intelligent Metasurfaces (SIMs) to control wireless propagation,
enabling the channel itself to perform over-the-air computation. This
eliminates the need for symbol estimation at the receiver, significantly
reducing computational and communication overhead. Our approach models the
transmitter-channel-receiver system as an end-to-end Deep Neural Network (DNN)
where the response of the SIM elements are trainable parameters. To address
channel variability, we incorporate a dedicated DNN module responsible for
dynamically adjusting transmission power leveraging user location information.
Our performance evaluations showcase that the proposed metasurfaces-integrated
DNN framework with deep SIM architectures are capable of balancing
classification accuracy and power consumption under diverse scenarios, offering
significant energy efficiency improvements.

</details>


### [358] [A Stateless Transparent Voting Machine](https://arxiv.org/abs/2509.19257)
*Juan E. Gilbert,Jean D. Louis*

Main category: cs.ET

TL;DR: 该论文提出了一种名为“无状态、透明投票机”（STVM）的投票机设计，它通过交互式打印界面让选民在投票时就能核对自己的纸质选票，并利用只读媒体（BD-R）启动，确保了系统的安全性和无状态性。


<details>
  <summary>Details</summary>
Motivation: 提高投票系统的透明度和安全性，解决选票被篡改和系统被攻击的问题。

Method: 实现了一种无状态、透明的投票机（STVM），使用交互式打印界面让选民核对纸质选票，并从只读媒体（BD-R）启动，不使用硬盘。

Result: STVM通过其无状态设计和透明交互式打印界面，提供了高可用性、可访问性和安全性，解决了选票被篡改和系统被攻击的问题。

Conclusion: STVM是一种安全、易用且无障碍的投票机设计，能够有效提升投票系统的安全性和可信度。

Abstract: Transparency and security are essential in our voting system, and voting
machines. This paper describes an implementation of a stateless, transparent
voting machine (STVM). The STVM is a ballot marking device (BMD) that uses a
transparent, interactive printing interface where voters can verify their paper
ballots as they fill out the ballot. The transparent interface turns the paper
ballot into an interactive interface. In this architecture, stateless describes
the machine's boot sequence, where no information is stored or passed forward
between reboots. The machine does not have a hard drive. Instead, it boots and
runs from read-only media. This STVM design utilizes a Blu-ray Disc ROM (BD-R)
to boot the voting software. This system's statelessness and the transparent
interactive printing interface make this design the most secure BMD for voting.
Unlike other voting methods, this system incorporates high usability,
accessibility, and security for all voters. The STVM uses an open-source voting
system that has a universally designed interface, making the system accessible
for all voters independent of their ability or disability. This system can make
voting safer by simultaneously addressing the issue of voters noticing a vote
flip and making it difficult for a hack to persist or go unmitigated.

</details>


<div id='cs.DC'></div>

# cs.DC [[Back]](#toc)

### [359] [Bridging Simulation and Silicon: A Study of RISC-V Hardware and FireSim Simulation](https://arxiv.org/abs/2509.18472)
*Atanu Barai,Kamalavasan Kamalakkannan,Patrick Diehl,Maxim Moraru,Jered Dominguez-Trujillo,Howard Pritchard,Nandakishore Santhi,Farzad Fatollahi-Fard,Galen Shipman*

Main category: cs.DC

TL;DR: 尽管FireSim在RISC-V处理器和HPC领域具有潜力，但其模拟与真实硬件之间的性能预测仍存在差距。


<details>
  <summary>Details</summary>
Motivation: 评估FireSim模拟框架在RISC-V桌面级处理器上的可行性与性能预测准确性，并与物理硬件进行对比。

Method: 在FireSim中建模商用单板计算机和桌面级RISC-V CPU，通过基准测试和LAMMPS分子动力学代码，比较单核和四核配置下的模拟与实际硬件性能。

Result: FireSim能提供架构性能趋势的见解，但在模拟和实际运行时间之间存在差异，这源于模拟环境的局限性和CPU制造商提供的性能规格不完整。

Conclusion: FireSim在RISC-V HPC领域有应用潜力，但要实现精确的性能预测，需要克服模拟环境的局限性并获得更详细的硬件规格。

Abstract: RISC-V ISA-based processors have recently emerged as both powerful and
energy-efficient computing platforms. The release of the MILK-V Pioneer marked
a significant milestone as the first desktop-grade RISC-V system. With
increasing engagement from both academia and industry, such platforms exhibit
strong potential for adoption in high-performance computing (HPC) environments.
  The open-source, FPGA-accelerated FireSim framework has emerged as a flexible
and scalable tool for architectural exploration, enabling simulation of various
system configurations using RISC-V cores. Despite its capabilities, there
remains a lack of systematic evaluation regarding the feasibility and
performance prediction accuracy of FireSim when compared to physical hardware.
  In this study, we address this gap by modeling a commercially available
single-board computer and a desktop-grade RISC-V CPU within FireSim. To ensure
fidelity between simulation and real hardware, we first measure the performance
of a series of benchmarks to compare runtime behavior under single-core and
four-core configurations. Based on the closest matching simulation parameters,
we subsequently evaluate performance using a representative mini-application
and the LAMMPS molecular dynamics code.
  Our findings indicate that while FireSim provides valuable insights into
architectural performance trends, discrepancies remain between simulated and
measured runtimes. These deviations stem from both inherent limitations of the
simulation environment and the restricted availability of detailed performance
specifications from CPU manufacturers, which hinder precise configuration
matching.

</details>


### [360] [6G Twin: Hybrid Gaussian Radio Fields for Channel Estimation and Non-Linear Precoder Design for Radio Access Networks](https://arxiv.org/abs/2509.18735)
*Muhammad Ahmed Mohsin,Muhammad Umer,Ahsan Bilal,Muhammad Ali Jamshed,Dean F. Hougen,John M. Cioffi*

Main category: cs.DC

TL;DR: 6G Twin是一个AI原生的RAN设计，通过GRF、持续信道预测和minPMAC优化了CSI获取、信道预测和预编码，实现了低开销、高精度、低功耗和高数据速率。


<details>
  <summary>Details</summary>
Motivation: 本研究旨在设计一个端到端的AI原生6G无线接入网络（RAN），以解决当前RAN在CSI获取、信道预测和能效方面的挑战。

Method: 本研究提出了一种名为6G Twin的RAN设计，包含三个关键组件：（1）神经高斯无线电场（GRF）用于压缩CSI获取；（2）持续信道预测，具备切换持久性；（3）能量最优的非线性预编码器（minPMAC）。GRF使用稀疏高斯场替代密集导频，将导频开销减少约100倍，并实现毫秒级推理和分钟级训练。（2）提出了一种基于重放的持续学习器，用于在移动和小区切换场景下保持精度，提高了信道归一化均方误差（NMSE）超过10 dB。（3）minPMAC解决了MAC预编码器设计问题，在满足最小速率要求的同时最小化传输能量，实现了4-10倍的低能耗。

Result: GRF将导频开销减少约100倍，推理时间为1.1毫秒，训练时间少于2分钟。持续学习器将NMSE提高了10 dB以上，并额外提高了2-5 dB。minPMAC实现了4-10倍的低能耗，并且随着信噪比的增长，每焦耳比特数单调增加。整体框架实现了实时CSI、动态网络下的鲁棒跟踪以及高效切换，并在3GPP场景下实现了先进的吞吐量-能量权衡。

Conclusion: 6G Twin是一个实用的、GPU就绪的框架，它通过GRF、持续信道预测和minPMAC的协同作用，在CSI获取、动态网络下的鲁棒跟踪以及吞吐量-能量效率方面取得了显著的改进，为6G RAN的设计提供了一个有效的解决方案。

Abstract: This work introduces 6G Twin, the first end-to-end artificial intelligence
(AI)-native radio access network (RAN) design that unifies (i) neural Gaussian
Radio Fields (GRF) for compressed channel state information (CSI) acquisition,
(ii) continual channel prediction with handover persistence, and (iii) an
energy-optimal nonlinear precoder (minPMAC). GRF replaces dense pilots with a
sparse Gaussian field, cutting pilot overhead by about 100x while delivering
1.1 ms inference and less than 2 minutes on-site training, thus enabling
millisecond-scale closed-loop operation. A replay-driven continual learner
sustains accuracy under mobility and cell transitions, improving channel
normalized mean square error (NMSE) by more than 10 dB over frozen predictors
and an additional 2-5 dB over uniform replay, thereby stabilizing performance
across UMi/UMa handovers. Finally, minPMAC solves a convex, order-free MAC
precoder design that recovers the globally optimal order from Broadcast Channel
(BC) duals and minimizes transmit energy subject to minimum-rate guarantees,
achieving 4-10 times lower energy (scenario dependent) with monotonically
increasing bits per joule as SNR grows. This translates to up to 5 times higher
data rate at comparable power or the same rates at substantially lower power.
Together, these components form a practical, GPU-ready framework that attains
real-time CSI, robust tracking in dynamic networks with efficient handovers,
and state-of-the-art throughput-energy tradeoffs under 3GPP-style settings.

</details>


### [361] [On The Reproducibility Limitations of RAG Systems](https://arxiv.org/abs/2509.18869)
*Baiqiang Wang,Dongfang Zhao,Nathan R Tallent,Luanzheng Guo*

Main category: cs.DC

TL;DR: ReproRAG是一个用于评估和量化基于向量的检索系统可复现性的基准测试框架，它通过分析不同组件（如嵌入模型、检索算法、硬件配置等）的不确定性来源，并使用精确匹配率、雅卡尔相似度、肯德尔 τ 等指标来衡量可复现性与性能之间的权衡，旨在提高科学领域中检索增强生成（RAG）的可靠性。


<details>
  <summary>Details</summary>
Motivation: 检索增强生成（RAG）在科学工作流中用于整合不断发展的科学知识，但其检索组件中的不确定性（非确定性）常常影响其可靠性。

Method: ReproRAG框架通过分析嵌入模型、精度、检索算法、硬件配置和分布式执行环境等整个流程中的不确定性来源，并采用精确匹配率、雅卡尔相似度、肯德尔 τ 等一系列指标来量化检索系统的可复现性。

Result: 大规模实证研究表明，不同的嵌入模型对RAG的可复现性有显著影响。ReproRAG框架能够有效地表征可复现性与性能之间的权衡。

Conclusion: ReproRAG框架为研究人员和工程师提供了验证部署、基准测试可复现性以及做出明智设计决策的工具，有助于构建更值得信赖的科学人工智能。

Abstract: Retrieval-Augmented Generation (RAG) is increasingly employed in generative
AI-driven scientific workflows to integrate rapidly evolving scientific
knowledge bases, yet its reliability is frequently compromised by
non-determinism in their retrieval components. This paper introduces ReproRAG,
a comprehensive benchmarking framework designed to systematically measure and
quantify the reproducibility of vector-based retrieval systems. ReproRAG
investigates sources of uncertainty across the entire pipeline, including
different embedding models, precision, retrieval algorithms, hardware
configurations, and distributed execution environments. Utilizing a suite of
metrics, such as Exact Match Rate, Jaccard Similarity, and Kendall's Tau, the
proposed framework effectively characterizes the trade-offs between
reproducibility and performance. Our large-scale empirical study reveals
critical insights; for instance, we observe that different embedding models
have remarkable impact on RAG reproducibility. The open-sourced ReproRAG
framework provides researchers and engineers productive tools to validate
deployments, benchmark reproducibility, and make informed design decisions,
thereby fostering more trustworthy AI for science.

</details>


### [362] [TD3-Sched: Learning to Orchestrate Container-based Cloud-Edge Resources via Distributed Reinforcement Learning](https://arxiv.org/abs/2509.18957)
*Shengye Song,Minxian Xu,Kan Hu,Wenxia Guo,Kejiang Ye*

Main category: cs.DC

TL;DR: TD3-Sched是一个基于TD3的分布式强化学习调度器，用于云边协同环境下的CPU和内存资源分配，能有效降低延迟并提高服务质量。


<details>
  <summary>Details</summary>
Motivation: 云边协同环境中的资源调度面临挑战，尤其是在边缘节点资源受限且对延迟敏感的场景下，现有的集中式调度器可能导致性能瓶颈和用户体验下降。

Method: 提出TD3-Sched，一个基于Twin Delayed Deep Deterministic Policy Gradient (TD3) 的分布式强化学习（DRL）调度器，用于连续控制CPU和内存的分配，以优化动态工作负载下的资源配置。

Result: 在基于SockShop应用和阿里巴巴数据的云边测试台上，TD3-Sched相比于其他强化学习和基于规则的基线方法，在相同负载下延迟降低了17.9%至38.6%，在高负载下降低了16%至31.6%。其服务水平目标（SLO）合规性也表现优异，仅有0.47%的违规。

Conclusion: TD3-Sched在容器化的云边环境中，相比基线方法，能够实现更快的收敛速度、更低的延迟和更稳定的性能，同时保持服务质量。

Abstract: Resource scheduling in cloud-edge systems is challenging as edge nodes run
latency-sensitive workloads under tight resource constraints, while existing
centralized schedulers can suffer from performance bottlenecks and user
experience degradation. To address the issues of distributed decisions in
cloud-edge environments, we present TD3-Sched, a distributed reinforcement
learning (DRL) scheduler based on Twin Delayed Deep Deterministic Policy
Gradient (TD3) for continuous control of CPU and memory allocation, which can
achieve optimized decisions for resource provisioning under dynamic workloads.
On a realistic cloud-edge testbed with SockShop application and Alibaba traces,
TD3-Sched achieves reductions of 17.9% to 38.6% in latency under same loads
compared with other reinforcement-learning and rule-based baselines, and 16% to
31.6% under high loads. TD3-Sched also shows superior Service Level Objective
(SLO) compliance with only 0.47% violations. These results indicate faster
convergence, lower latency, and more stable performance while preserving
service quality in container-based cloud-edge environment compared with the
baselines.

</details>


### [363] [Scheduler-Driven Job Atomization](https://arxiv.org/abs/2509.19086)
*Michal Konopa,Jan Fesl,Ladislav Beránek*

Main category: cs.DC

TL;DR: SJA是一种新的GPU集群调度范式，通过将作业分解为可变大小的子作业来提高GPU利用率。


<details>
  <summary>Details</summary>
Motivation: 现有的GPU集群调度方法由于将作业视为固定大小的块而导致碎片化、利用率低下和作业拒绝。

Method: SJA通过调度器宣告可用执行空间，作业响应并生成适合该空间的子作业，从而实现调度器和作业之间的双向交互。

Result: SJA旨在提高GPU利用率，减少等待时间，并最小化迁移开销，但本文仅提出概念，未进行实验评估。

Conclusion: SJA是一种有前景的GPU集群调度方法，但需要进一步的研究和实验验证。

Abstract: Modern GPU clusters, particularly those built on NVIDIA's Multi-Instance GPU
(MIG) architecture, often suffer from inefficiencies because jobs are treated
as rigid, indivisible blocks that occupy a fixed slice until completion. The
reliance on static peak memory estimates exacerbates fragmentation,
underutilization, and job rejections. We propose Scheduler-Driven Job
Atomization (SJA), a new paradigm that establishes a bidirectional interaction
between scheduler and jobs. In SJA, the scheduler advertises available
execution gaps, and jobs respond by signaling interest if they can potentially
generate a subjob that fits the offered time-capacity window. The scheduler may
collect multiple signals for the same slot and, based on its allocation policy
(e.g., fairness, efficiency, or SLA priorities), selects which job is granted
the slot. Only then does the chosen job materialize a safe, self-contained
subjob tailored to that opportunity. Unlike migration or preemption, SJA
proactively shapes workloads before execution, thereby avoiding costly state
transfers and unpredictable interruptions. It aims to increase GPU utilization,
reduce wait times, and minimize migration overhead by aligning jobs with
opportunities in real time, ensuring that each admitted subjob is correct by
construction. This paper is presented as a concept paper: it introduces the
paradigm, defines its building blocks, and outlines future research directions,
rather than offering a full experimental evaluation.

</details>


### [364] [In-Transit Data Transport Strategies for Coupled AI-Simulation Workflow Patterns](https://arxiv.org/abs/2509.19150)
*Harikrishna Tummalapalli,Riccardo Balin,Christine M. Simpson,Andrew Park,Aymen Alsaadi,Andrew E. Shao,Wesley Brewer,Shantenu Jha*

Main category: cs.DC

TL;DR: SimAI-Bench是一个用于评估和原型化耦合AI-模拟工作流的工具，并在Aurora超级计算机上分析了两种常见数据传输模式的性能。


<details>
  <summary>Details</summary>
Motivation: HPC设施中耦合AI-模拟工作负载的日益复杂，需要新的工具来支持性能分析和模拟工作流的原型设计。

Method: 使用SimAI-Bench在Aurora超级计算机上对两种工作流模式（一对一和多对一）的数据传输性能进行了基准测试。

Result: 在一对一模式下，节点本地和DragonHPC数据暂存策略相比Redis和Lustre文件系统表现出优越的性能。在多对一模式下，随着集合规模的增长，数据传输成为主要的瓶颈，文件系统是最佳选择。

Conclusion: SimAI-Bench能够有效地评估耦合AI-模拟工作流，并为优化这些工作流提供了有价值的见解。

Abstract: Coupled AI-Simulation workflows are becoming the major workloads for HPC
facilities, and their increasing complexity necessitates new tools for
performance analysis and prototyping of new in-situ workflows. We present
SimAI-Bench, a tool designed to both prototype and evaluate these coupled
workflows. In this paper, we use SimAI-Bench to benchmark the data transport
performance of two common patterns on the Aurora supercomputer: a one-to-one
workflow with co-located simulation and AI training instances, and a
many-to-one workflow where a single AI model is trained from an ensemble of
simulations. For the one-to-one pattern, our analysis shows that node-local and
DragonHPC data staging strategies provide excellent performance compared Redis
and Lustre file system. For the many-to-one pattern, we find that data
transport becomes a dominant bottleneck as the ensemble size grows. Our
evaluation reveals that file system is the optimal solution among the tested
strategies for the many-to-one pattern.

</details>


### [365] [Non-Uniform Content-Oblivious Leader Election on Oriented Asynchronous Rings](https://arxiv.org/abs/2509.19187)
*Jérémie Chalopin,Yi-Jun Chang,Lyuting Chen,Giuseppe A. Di Luna,Haoran Zhou*

Main category: cs.DC

TL;DR: 该论文研究了有向环网络中的领导者选举问题，并在内容无关的异步消息传递系统中提出了新的算法和下界。


<details>
  <summary>Details</summary>
Motivation: 现有算法在有向环网络中的领导者选举存在消息复杂度和统一性方面的局限，本文旨在探索更优的解决方案。

Method: 在统一模型下，证明了在发送消息数量受限的情况下无法解决该问题。在非统一模型下，提出了两种算法，分别具有 $O(n 	f{cdot} U 	f{cdot} 	f{ID}_{	f{min}})$ 和 $O(U 	f{cdot} 	f{ID}_{	f{min}})$ 的消息复杂度。在匿名模型下，提出了一个随机化算法。

Result: 在统一模型下，证明了无常数消息发送的统一算法不存在。在非统一模型下，提出了两种算法，消息复杂度优于现有算法，并匹配了 $	f{log} 	f{ID}_{	f{min}}$ 的最优下界。在匿名模型下，提出了一个随机化算法，消息复杂度为 $O(	f{log}^2 U)$。

Conclusion: 本文在内容无关模型下，对环网络领导者选举问题进行了深入研究，分别在统一、非统一和匿名设置下取得了新的理论结果，并对算法的复杂度进行了分析和优化。

Abstract: We study the leader election problem in oriented ring networks under
content-oblivious asynchronous message-passing systems, where an adversary may
arbitrarily corrupt message contents.
  Frei et al. (DISC 2024) presented a uniform terminating leader election
algorithm for oriented rings in this setting, with message complexity $O(n
\cdot \mathsf{ID}_{\max})$ on a ring of size $n$, where $\mathsf{ID}_{\max}$ is
the largest identifier in the system, this result has been recently extended by
Chalopin et al. (DISC 2025) to unoriented rings.
  In this paper, we investigate the message complexity of leader election on
ring networks in the content-oblivious model, showing that no uniform algorithm
can solve the problem if each process is limited to sending a constant number
of messages in one direction.
  Interestingly, this limitation hinges on the uniformity assumption. In the
non-uniform setting, where processes know an upper bound $U \geq n$ on the ring
size, we present an algorithm with message complexity $O(n \cdot U \cdot
\mathsf{ID}_{\min})$, in which each process sends $O(U \cdot
\mathsf{ID}_{\min})$ messages clockwise and only three messages
counter-clockwise. Here, $\mathsf{ID}_{\min}$ is the smallest identifier in the
system. This dependence on the identifiers compares favorably with the
dependence on $\mathsf{ID}_{\max}$ of Frei et al.
  We also show a non-uniform algorithm where each process sends $O(U \cdot
\log\mathsf{ID}_{\min})$ messages in one direction and
$O(\log\mathsf{ID}_{\min})$ in the other. The factor $\log \mathsf{ID}_{\min}$
is optimal, matching the lower bound of Frei et al.
  Finally, in the anonymous setting, where processes do not have identifiers,
we propose a randomized algorithm where each process sends only $O(\log^2 U)$
messages, with a success probability of $1 - U^{-c}$.

</details>


### [366] [Accelerating Gravitational $N$-Body Simulations Using the RISC-V-Based Tenstorrent Wormhole](https://arxiv.org/abs/2509.19294)
*Jenny Lynn Almerol,Elisabetta Boella,Mario Spera,Daniele Gregori*

Main category: cs.DC

TL;DR: RISC-V加速器在科学计算方面表现出色，在天体物理N体模拟中实现了2倍以上的加速和接近2倍的能耗节省。


<details>
  <summary>Details</summary>
Motivation: 展示RISC-V平台在高性能科学计算，特别是天体物理N体模拟方面的潜力。

Method: 在Tenstorrent的Wormhole n300 RISC-V卡上加速了一个天体物理N体代码。

Result: 与高度优化的CPU实现相比，实现了超过2倍的速度提升和约2倍的能耗节省。

Conclusion: RISC-V平台在天体物理模拟方面具有竞争力。

Abstract: Although originally developed primarily for artificial intelligence
workloads, RISC-V-based accelerators are also emerging as attractive platforms
for high-performance scientific computing. In this work, we present our
approach to accelerating an astrophysical $N$-body code on the RISC-V-based
Wormhole n300 card developed by Tenstorrent. Our results show that this
platform can be highly competitive for astrophysical simulations employing this
class of algorithms, delivering more than a $2 \times$ speedup and
approximately $2 \times$ energy savings compared to a highly optimized CPU
implementation of the same code.

</details>


<div id='cs.SI'></div>

# cs.SI [[Back]](#toc)

### [367] [Homophily in Complex Networks: Measures, Models, and Applications](https://arxiv.org/abs/2509.18289)
*Akrati Saxena,Gaurav Kumar,Chandrakala Meena*

Main category: cs.SI

TL;DR: 本教程全面概述了同质性，包括其定义、性质、度量的局限性、高阶网络结构中的同质性、网络生成模型以及实际应用。最后讨论了该领域的开放性挑战、新兴方向和研究机会。


<details>
  <summary>Details</summary>
Motivation: 理解群体内部和跨群体互动对于揭示网络演变动态和结构不平等的出现至关重要。

Method: 本教程将讨论同质性的不同定义、关键性质、常用度量的局限性，并扩展到超图和单纯复形等高阶网络结构。此外，还将讨论能够生成具有可调同质性水平的不同类型同质性网络以及其实际应用的网络生成模型。

Result: 本教程提供了关于同质性的全面概述，包括其定义、性质、度量局限性、高阶网络结构、网络生成模型和实际应用。

Conclusion: 本教程最后讨论了同质性研究领域的开放性挑战、新兴方向和未来研究机会。

Abstract: Homophily, the tendency of individuals to connect with others who share
similar attributes, is a defining feature of social networks. Understanding how
groups interact, both within and across, is crucial for uncovering the dynamics
of network evolution and the emergence of structural inequalities in these
network. This tutorial offers a comprehensive overview of homophily, covering
its various definitions, key properties, and the limitations of widely used
metrics. Extending beyond traditional pairwise interactions, we will discuss
homophily in higher-order network structures such as hypergraphs and simplicial
complexes. We will further discuss network generating models capable of
producing different types of homophilic networks with tunable levels of
homophily and highlight their relevance in real-world contexts. The tutorial
concludes with a discussion of open challenges, emerging directions, and
opportunities for further research in this area.

</details>


### [368] [Identifying Constructive Conflict in Online Discussions through Controversial yet Toxicity Resilient Posts](https://arxiv.org/abs/2509.18303)
*Ozgur Can Seckin,Bao Tran Truong,Alessandro Flammini,Filippo Menczer*

Main category: cs.SI

TL;DR: 算法推荐可以通过考虑建设性冲突来促进社交媒体上不同观点之间的对话。


<details>
  <summary>Details</summary>
Motivation: 社交媒体上的回音室和有毒的交流阻碍了不同观点之间的对话，而算法推荐有可能通过将建设性冲突作为一个基本标准来解决这个问题。

Method: 通过“争议性”和“毒性抵抗力”两个维度来操作化“建设性冲突”这一标准，分别用于识别挑战性对话和尊重性对话。

Result: 研究表明，评估对有毒回应的抵抗力不同于识别低毒性帖子。政治帖子通常更具争议性，并且更容易吸引有毒回应。然而，一些帖子，即使是政治帖子，尽管争议很大，但却能抵抗毒性，并有可能引发公民参与。毒性抵抗性帖子倾向于使用礼貌的线索，例如表示感谢和谨慎用词。

Conclusion: 通过对帖子语气进行调整，有可能鼓励建设性的政治讨论。

Abstract: Bridging content that brings together individuals with opposing viewpoints on
social media remains elusive, overshadowed by echo chambers and toxic
exchanges. We propose that algorithmic curation could surface such content by
considering constructive conflicts as a foundational criterion. We
operationalize this criterion through controversiality to identify challenging
dialogues and toxicity resilience to capture respectful conversations. We
develop high-accuracy models to capture these dimensions. Analyses based on
these models demonstrate that assessing resilience to toxic responses is not
the same as identifying low-toxicity posts. We also find that political posts
are often controversial and tend to attract more toxic responses. However, some
posts, even the political ones, are resilient to toxicity despite being highly
controversial, potentially sparking civil engagement. Toxicity resilient posts
tend to use politeness cues, such as showing gratitude and hedging. These
findings suggest the potential for framing the tone of posts to encourage
constructive political discussions.

</details>


### [369] [A Graph-Neural-Network-Entropy model of vital node identification on network attack and propagation](https://arxiv.org/abs/2509.18325)
*Huaizhi Liao,Tian Qiu,Guang Chen*

Main category: cs.SI

TL;DR: 本研究提出了一种基于图神经网络和信息熵的新方法（GNNE），用于识别复杂网络中的关键节点。


<details>
  <summary>Details</summary>
Motivation: 现有方法未能充分整合节点特征、交互和状态，而关键节点的识别对于网络防护至关重要，尤其是在网络遭受攻击时。

Method: GNNE方法结合了图卷积网络（GCN）和图注意力网络（GAT）。GCN用于学习节点特征，然后将这些特征输入GAT以获得节点的“影响因子”。最后，利用这些影响因子计算节点的熵，以评估节点的重要性。GCN负责提取节点特征，GAT通过注意力机制为不同邻居分配不同权重来聚合邻居特征，而节点熵则量化了节点在网络中的状态。

Result: 在合成的Barabasi-Albert网络上训练，并在六个真实数据集上进行测试。与八种传统的基于拓扑的方法和四种基于图的机器学习方法相比，GNNE在网络攻击和传播方面显示出识别关键节点的优势。

Conclusion: GNNE方法能够有效地识别复杂网络中的关键节点，并在网络攻击和传播场景下优于现有方法。

Abstract: Vital nodes usually play a key role in complex networks. Uncovering these
nodes is an important task in protecting the network, especially when the
network suffers intentional attack. Many existing methods have not fully
integrated the node feature, interaction and state. In this article, we propose
a novel method (GNNE) based on graph neural networks and information entropy.
The method employs a Graph Convolutional Network (GCN) to learn the nodes'
features, which are input into a Graph Attention Network (GAT) to obtain the
influence factor of nodes, and the node influence factors are used to calculate
the nodes' entropy to evaluate the node importance. The GNNE takes advantage of
the GCN and GAT, with the GCN well extracting the nodes' features and the GAT
aggregating the features of the nodes' neighbors by using the attention
mechanism to assign different weights to the neighbors with different
importance, and the nodes' entropy quantifies the nodes' state in the network.
The proposed method is trained on a synthetic Barabasi-Albert network, and
tested on six real datasets. Compared with eight traditional topology-based
methods and four graph-machine-learning-based methods, the GNNE shows an
advantage for the vital node identification in the perspectives of network
attack and propagation.

</details>


### [370] [Simulating Online Social Media Conversations on Controversial Topics Using AI Agents Calibrated on Real-World Data](https://arxiv.org/abs/2509.18985)
*Elisa Composta,Nicolo' Fontana,Francesco Corso,Francesco Pierri*

Main category: cs.SI

TL;DR: LLM 代理在模拟社交网络中表现出连贯性但缺乏多样性。


<details>
  <summary>Details</summary>
Motivation: 利用 LLM 模拟用户在社交网络中的行为，以探索受控场景并提高模拟的真实性。

Method: 在模拟的微博社交网络中，使用根据真实政治对话校准的 LLM 代理，并引入了意见模型。

Result: LLM 代理生成连贯的内容并形成现实的社交网络结构，但在语气和毒性方面不如真实数据多样。LLM 驱动的意见动态与传统模型相似，但参数变化对结果影响不大，表明需要更仔细的认知建模。

Conclusion: LLM 在模拟社交用户行为方面具有潜力，但需要在捕捉多样性和复杂动态方面进行改进。

Abstract: Online social networks offer a valuable lens to analyze both individual and
collective phenomena. Researchers often use simulators to explore controlled
scenarios, and the integration of Large Language Models (LLMs) makes these
simulations more realistic by enabling agents to understand and generate
natural language content. In this work, we investigate the behavior of
LLM-based agents in a simulated microblogging social network. We initialize
agents with realistic profiles calibrated on real-world online conversations
from the 2022 Italian political election and extend an existing simulator by
introducing mechanisms for opinion modeling. We examine how LLM agents simulate
online conversations, interact with others, and evolve their opinions under
different scenarios. Our results show that LLM agents generate coherent
content, form connections, and build a realistic social network structure.
However, their generated content displays less heterogeneity in tone and
toxicity compared to real data. We also find that LLM-based opinion dynamics
evolve over time in ways similar to traditional mathematical models. Varying
parameter configurations produces no significant changes, indicating that
simulations require more careful cognitive modeling at initialization to
replicate human behavior more faithfully. Overall, we demonstrate the potential
of LLMs for simulating user behavior in social environments, while also
identifying key challenges in capturing heterogeneity and complex dynamics.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [371] [MMCD: Multi-Modal Collaborative Decision-Making for Connected Autonomy with Knowledge Distillation](https://arxiv.org/abs/2509.18198)
*Rui Liu,Zikang Wang,Peng Gao,Yu Shen,Pratap Tokekar,Ming Lin*

Main category: cs.AI

TL;DR: 提出了一种名为MMCD的新型框架，用于在存在传感器故障或通信丢失等挑战性条件下，实现多模态和多车辆协同决策。该框架通过跨模态知识蒸馏，使模型能够在数据模态不完整的情况下也能有效运行，并在相关的自动驾驶和空地协同任务中显著提高了行车安全性。


<details>
  <summary>Details</summary>
Motivation: 现有自动驾驶系统在事故多发环境中面临决策鲁棒性挑战，单一车辆的传感器范围有限且视野受阻，增加了事故发生的可能性。虽然多车辆协同和多模态（RGB图像和LiDAR点云）方法提供了解决方案，但它们通常假设训练和测试期间所有数据模态和协同车辆都可用，这在实际中难以实现。

Method: 提出了一种名为MMCD（Multi-Modal Collaborative Decision-making）的新型框架，用于协同自主驾驶。该框架融合了来自本车和协同车辆的多模态观测信息，以增强在挑战性条件下的决策能力。为了确保在测试期间某些数据模态不可用时仍能保持鲁棒性，提出了一种基于跨模态知识蒸馏的方法，采用教师-学生模型结构。教师模型使用多种数据模态进行训练，而学生模型则被设计为能够有效地处理减少后的数据模态。

Result: 在“车辆协同自动驾驶”和“空地协同”的实验中，MMCD框架将行车安全性提高了多达20.7%，在检测潜在事故和做出安全驾驶决策方面优于现有的最佳基线方法。

Conclusion: MMCD框架通过融合多模态信息和利用跨模态知识蒸馏，有效地解决了连接自动驾驶中因数据模态缺失或协同车辆不可用而带来的挑战，显著提高了驾驶安全性。

Abstract: Autonomous systems have advanced significantly, but challenges persist in
accident-prone environments where robust decision-making is crucial. A single
vehicle's limited sensor range and obstructed views increase the likelihood of
accidents. Multi-vehicle connected systems and multi-modal approaches,
leveraging RGB images and LiDAR point clouds, have emerged as promising
solutions. However, existing methods often assume the availability of all data
modalities and connected vehicles during both training and testing, which is
impractical due to potential sensor failures or missing connected vehicles. To
address these challenges, we introduce a novel framework MMCD (Multi-Modal
Collaborative Decision-making) for connected autonomy. Our framework fuses
multi-modal observations from ego and collaborative vehicles to enhance
decision-making under challenging conditions. To ensure robust performance when
certain data modalities are unavailable during testing, we propose an approach
based on cross-modal knowledge distillation with a teacher-student model
structure. The teacher model is trained with multiple data modalities, while
the student model is designed to operate effectively with reduced modalities.
In experiments on $\textit{connected autonomous driving with ground vehicles}$
and $\textit{aerial-ground vehicles collaboration}$, our method improves
driving safety by up to ${\it 20.7}\%$, surpassing the best-existing baseline
in detecting potential accidents and making safe driving decisions. More
information can be found on our website https://ruiiu.github.io/mmcd.

</details>


### [372] [A Cost-Benefit Analysis of On-Premise Large Language Model Deployment: Breaking Even with Commercial LLM Services](https://arxiv.org/abs/2509.18101)
*Guanzhong Pan,Haibo Wang*

Main category: cs.AI

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Large language models (LLMs) are becoming increasingly widespread.
Organizations that want to use AI for productivity now face an important
decision. They can subscribe to commercial LLM services or deploy models on
their own infrastructure. Cloud services from providers such as OpenAI,
Anthropic, and Google are attractive because they provide easy access to
state-of-the-art models and are easy to scale. However, concerns about data
privacy, the difficulty of switching service providers, and long-term operating
costs have driven interest in local deployment of open-source models. This
paper presents a cost-benefit analysis framework to help organizations
determine when on-premise LLM deployment becomes economically viable compared
to commercial subscription services. We consider the hardware requirements,
operational expenses, and performance benchmarks of the latest open-source
models, including Qwen, Llama, Mistral, and etc. Then we compare the total cost
of deploying these models locally with the major cloud providers subscription
fee. Our findings provide an estimated breakeven point based on usage levels
and performance needs. These results give organizations a practical framework
for planning their LLM strategies.

</details>


### [373] [Change in Quantitative Bipolar Argumentation: Sufficient, Necessary, and Counterfactual Explanations](https://arxiv.org/abs/2509.18215)
*Timotheus Kampik,Kristijonas Čyras,José Ruiz Alarcón*

Main category: cs.AI

TL;DR: 本研究提出了一种在定量双极论证框架（QBAF）中解释推理变化的方法，通过追踪论证强度偏序中的不一致性（称为强度不一致），并将其归因于特定论证，从而提供解释。


<details>
  <summary>Details</summary>
Motivation: 在定量双极论证框架（QBAF）中，当进行推理更新并再次推理时，理解推理结果变化的原因是一个挑战。本研究旨在解决这一问题，通过追踪和解释推理变化。

Method: 提出了一种追踪QBAF中强度不一致性的方法，将不一致性归因于特定论证，并识别充分、必要和反事实的解释。此外，还定义了一种基于启发式的搜索方法。

Result: 识别了强度不一致的充分、必要和反事实的解释，并证明了当且仅当更新导致强度不一致时，强度不一致的解释才存在。还实现了一种用于搜索这些解释的启发式方法。

Conclusion: 本研究提供了一种形式化的方法来解释QBAF中推理的变化，通过识别和归因强度不一致性，为理解和调试论证系统提供了有价值的见解。

Abstract: This paper presents a formal approach to explaining change of inference in
Quantitative Bipolar Argumentation Frameworks (QBAFs). When drawing conclusions
from a QBAF and updating the QBAF to then again draw conclusions (and so on),
our approach traces changes -- which we call strength inconsistencies -- in the
partial order over argument strengths that a semantics establishes on some
arguments of interest, called topic arguments. We trace the causes of strength
inconsistencies to specific arguments, which then serve as explanations. We
identify sufficient, necessary, and counterfactual explanations for strength
inconsistencies and show that strength inconsistency explanations exist if and
only if an update leads to strength inconsistency. We define a heuristic-based
approach to facilitate the search for strength inconsistency explanations, for
which we also provide an implementation.

</details>


### [374] [SPADE: A Large Language Model Framework for Soil Moisture Pattern Recognition and Anomaly Detection in Precision Agriculture](https://arxiv.org/abs/2509.18123)
*Yeonju Lee,Rui Qi Chen,Joseph Oboamah,Po Nien Su,Wei-zhen Liang,Yeyin Shi,Lu Gan,Yongsheng Chen,Xin Qiao,Jing Li*

Main category: cs.AI

TL;DR: SPADE是一个利用大语言模型（LLMs）分析土壤湿度时间序列数据的框架，能够进行灌溉模式和异常检测，无需任务特定的标注或微调，并在实际应用中表现出优于现有方法的性能。


<details>
  <summary>Details</summary>
Motivation: 现有土壤湿度时间序列分析方法依赖于阈值规则或数据需求量大的机器学习/深度学习模型，这些模型在适应性和可解释性方面存在局限性。本研究旨在开发一种更具适应性和可解释性的方法。

Method: SPADE框架利用大型语言模型（如ChatGPT-4.1）将时间序列数据转换为文本表示，并设计了领域驱动的提示模板，以实现零样本分析，无需进行任务特定的标注或微调。该框架能够检测灌溉事件、估算净灌溉增益、检测和分类异常，并生成结构化的、可解释的报告。

Result: SPADE在异常检测方面优于现有方法，实现了更高的召回率和F1分数，并能准确分类异常类型。在灌溉事件检测方面，SPADE也取得了很高的精确率和召回率。SPADE生成的报告提供了可解释性和可用性。

Conclusion: 本研究证明了大型语言模型在精准农业领域的潜力，作为可扩展、适应性强的工具，能够整合定性知识和数据驱动的推理，从而为准确的土壤湿度监测和改进灌溉计划提供可行的见解。

Abstract: Accurate interpretation of soil moisture patterns is critical for irrigation
scheduling and crop management, yet existing approaches for soil moisture
time-series analysis either rely on threshold-based rules or data-hungry
machine learning or deep learning models that are limited in adaptability and
interpretability. In this study, we introduce SPADE (Soil moisture Pattern and
Anomaly DEtection), an integrated framework that leverages large language
models (LLMs) to jointly detect irrigation patterns and anomalies in soil
moisture time-series data. SPADE utilizes ChatGPT-4.1 for its advanced
reasoning and instruction-following capabilities, enabling zero-shot analysis
without requiring task-specific annotation or fine-tuning. By converting
time-series data into a textual representation and designing domain-informed
prompt templates, SPADE identifies irrigation events, estimates net irrigation
gains, detects, classifies anomalies, and produces structured, interpretable
reports. Experiments were conducted on real-world soil moisture sensor data
from commercial and experimental farms cultivating multiple crops across the
United States. Results demonstrate that SPADE outperforms the existing method
in anomaly detection, achieving higher recall and F1 scores and accurately
classifying anomaly types. Furthermore, SPADE achieved high precision and
recall in detecting irrigation events, indicating its strong capability to
capture irrigation patterns accurately. SPADE's reports provide
interpretability and usability of soil moisture analytics. This study
highlights the potential of LLMs as scalable, adaptable tools for precision
agriculture, which is capable of integrating qualitative knowledge and
data-driven reasoning to produce actionable insights for accurate soil moisture
monitoring and improved irrigation scheduling from soil moisture time-series
data.

</details>


### [375] [Position Paper: Integrating Explainability and Uncertainty Estimation in Medical AI](https://arxiv.org/abs/2509.18132)
*Xiuyi Fan*

Main category: cs.AI

TL;DR: 本研究提出了一种名为 XUE 的新方法，它结合了可解释性和不确定性量化，旨在提高医疗 AI 的可信度和可用性。


<details>
  <summary>Details</summary>
Motivation: 目前的医疗 AI 系统在量化和沟通不确定性方面存在不足，无法与临床推理保持一致。现有的 XAI 技术侧重于解释模型预测，但未能捕捉预测的置信度或可靠性。而不确定性估计（UE）技术虽然提供了置信度度量，但缺乏直观的解释。这种脱节限制了 AI 在医学领域的应用。

Method: 本研究系统地将医学不确定性映射到 AI 不确定性概念，并确定了实现 XUE 的关键挑战。研究概述了推进 XUE 的技术方向，包括多模态不确定性量化、模型无关的可视化技术以及不确定性感知决策支持系统。最后，提出指导原则以确保 XUE 的有效实现。

Result: 研究分析强调了需要开发不仅能生成可靠预测，还能以临床相关方式阐明置信度水平的 AI 系统。

Conclusion: 本研究通过弥合可解释性和不确定性之间的差距，为开发值得信赖的医疗 AI 做出了贡献，为开发能够应对现实世界临床复杂性的 AI 系统铺平了道路。

Abstract: Uncertainty is a fundamental challenge in medical practice, but current
medical AI systems fail to explicitly quantify or communicate uncertainty in a
way that aligns with clinical reasoning. Existing XAI works focus on
interpreting model predictions but do not capture the confidence or reliability
of these predictions. Conversely, uncertainty estimation (UE) techniques
provide confidence measures but lack intuitive explanations. The disconnect
between these two areas limits AI adoption in medicine. To address this gap, we
propose Explainable Uncertainty Estimation (XUE) that integrates explainability
with uncertainty quantification to enhance trust and usability in medical AI.
We systematically map medical uncertainty to AI uncertainty concepts and
identify key challenges in implementing XUE. We outline technical directions
for advancing XUE, including multimodal uncertainty quantification,
model-agnostic visualization techniques, and uncertainty-aware decision support
systems. Lastly, we propose guiding principles to ensure effective XUE
realisation. Our analysis highlights the need for AI systems that not only
generate reliable predictions but also articulate confidence levels in a
clinically meaningful way. This work contributes to the development of
trustworthy medical AI by bridging explainability and uncertainty, paving the
way for AI systems that are aligned with real-world clinical complexities.

</details>


### [376] [HSGM: Hierarchical Segment-Graph Memory for Scalable Long-Text Semantics](https://arxiv.org/abs/2509.18168)
*Dong Liu,Yanxuan Yu*

Main category: cs.AI

TL;DR: HSGM是一个新的框架，通过将长文档分解为多个段落，并在每个段落上构建局部语义图，再提取摘要节点形成全局图记忆，来解决长文档语义解析的挑战。它支持增量更新和分层查询处理，将复杂度从O(N^2)降低到O(N*k + (N/k)^2)，并实现了2-4倍的推理加速和超过60%的内存减少，同时保持了95%以上的准确率。


<details>
  <summary>Details</summary>
Motivation: 长文档的语义解析存在二次增长的计算和内存需求挑战。

Method: 提出了一种名为分层段图记忆（HSGM）的新框架。该框架将输入文档分解为M个有意义的段落，在每个段落上构建局部语义图，并提取紧凑的摘要节点以形成全局图记忆。HSGM支持增量更新和分层查询处理。

Result: 在AMR解析、语义角色标注和法律事件提取等三个基准测试中，HSGM实现了2-4倍的推理加速，峰值内存减少超过60%，准确率达到基线准确率的95%以上。

Conclusion: HSGM能够对超长文本进行可扩展、准确的语义建模，能够满足实时和资源受限的自然语言处理应用的需求。

Abstract: Semantic parsing of long documents remains challenging due to quadratic
growth in pairwise composition and memory requirements. We introduce
\textbf{Hierarchical Segment-Graph Memory (HSGM)}, a novel framework that
decomposes an input of length $N$ into $M$ meaningful segments, constructs
\emph{Local Semantic Graphs} on each segment, and extracts compact
\emph{summary nodes} to form a \emph{Global Graph Memory}. HSGM supports
\emph{incremental updates} -- only newly arrived segments incur local graph
construction and summary-node integration -- while \emph{Hierarchical Query
Processing} locates relevant segments via top-$K$ retrieval over summary nodes
and then performs fine-grained reasoning within their local graphs.
  Theoretically, HSGM reduces worst-case complexity from $O(N^2)$ to
$O\!\left(N\,k + (N/k)^2\right)$, with segment size $k \ll N$, and we derive
Frobenius-norm bounds on the approximation error introduced by node
summarization and sparsification thresholds. Empirically, on three benchmarks
-- long-document AMR parsing, segment-level semantic role labeling (OntoNotes),
and legal event extraction -- HSGM achieves \emph{2--4$\times$ inference
speedup}, \emph{$>60\%$ reduction} in peak memory, and \emph{$\ge 95\%$} of
baseline accuracy. Our approach unlocks scalable, accurate semantic modeling
for ultra-long texts, enabling real-time and resource-constrained NLP
applications.

</details>


### [377] [Foam-Agent: An End-to-End Composable Multi-Agent Framework for Automating CFD Simulation in OpenFOAM](https://arxiv.org/abs/2509.18178)
*Ling Yue,Nithin Somasekharan,Tingwen Zhang,Yadi Cao,Shaowu Pan*

Main category: cs.AI

TL;DR: Foam-Agent 是一个多智能体框架，可以根据自然语言提示自动完成整个 OpenFOAM 工作流，解决了 CFD 学习曲线陡峭和设置复杂的问题。


<details>
  <summary>Details</summary>
Motivation: CFD 学习曲线陡峭且设置复杂，Foam-Agent 旨在自动化整个 OpenFOAM 工作流，降低 CFD 的入门门槛。

Method: Foam-Agent 采用多智能体框架，通过一个综合性的端到端模拟自动化流程，包括预处理（网格生成）、HPC 脚本生成和后处理（可视化）。它使用模型上下文协议（MCP）将核心功能暴露为可调用的工具，并利用分层多索引 RAG 和依赖感知生成过程来提高配置的准确性。

Result: 在 110 个模拟任务的基准测试中，Foam-Agent 使用 Claude 3.5 Sonnet 取得了 88.2% 的成功率，显著优于现有框架（MetaOpenFOAM 成功率为 55.5%）。

Conclusion: Foam-Agent 极大地降低了 CFD 的专业知识门槛，展示了专业化的多智能体系统如何能够普及复杂科学计算。

Abstract: Computational Fluid Dynamics (CFD) is an essential simulation tool in
engineering, yet its steep learning curve and complex manual setup create
significant barriers. To address these challenges, we introduce Foam-Agent, a
multi-agent framework that automates the entire end-to-end OpenFOAM workflow
from a single natural language prompt. Our key innovations address critical
gaps in existing systems: 1. An Comprehensive End-to-End Simulation Automation:
Foam-Agent is the first system to manage the full simulation pipeline,
including advanced pre-processing with a versatile Meshing Agent capable of
handling external mesh files and generating new geometries via Gmsh, automatic
generation of HPC submission scripts, and post-simulation visualization via
ParaView. 2. Composable Service Architecture: Going beyond a monolithic agent,
the framework uses Model Context Protocol (MCP) to expose its core functions as
discrete, callable tools. This allows for flexible integration and use by other
agentic systems, such as Claude-code, for more exploratory workflows. 3.
High-Fidelity Configuration Generation: We achieve superior accuracy through a
Hierarchical Multi-Index RAG for precise context retrieval and a
dependency-aware generation process that ensures configuration consistency.
Evaluated on a benchmark of 110 simulation tasks, Foam-Agent achieves an 88.2%
success rate with Claude 3.5 Sonnet, significantly outperforming existing
frameworks (55.5% for MetaOpenFOAM). Foam-Agent dramatically lowers the
expertise barrier for CFD, demonstrating how specialized multi-agent systems
can democratize complex scientific computing. The code is public at
https://github.com/csml-rpi/Foam-Agent.

</details>


### [378] [Large Language Models and Operations Research: A Structured Survey](https://arxiv.org/abs/2509.18180)
*Yang Wang,Kai Li*

Main category: cs.AI

TL;DR: LLMs在运筹学（OR）中展现出巨大潜力，可用于自动建模、辅助优化和直接求解，但仍面临挑战，如语义映射不稳定、研究碎片化、泛化能力有限和评估不足。


<details>
  <summary>Details</summary>
Motivation: 传统运筹学方法在处理大规模、动态和多约束问题时面临挑战，而LLMs凭借其语义理解、结构化生成和推理控制能力，有望克服这些限制。

Method: 本论文将LLMs在OR中的应用方法归纳为三个主要方向：自动建模、辅助优化和直接求解。

Result: 论文回顾了LLMs在OR中的最新进展，并讨论了评估基准和特定领域应用。

Conclusion: 尽管LLMs在OR领域取得了显著进展，但仍存在语义到结构的映射不稳定、研究进展碎片化、泛化能力有限以及评估体系不完善等关键问题。未来的研究应致力于解决这些问题，以推动LLMs在OR中的作用。

Abstract: Operations research (OR) provides fundamental methodologies for complex
system decision-making, with established applications in transportation, supply
chain management, and production scheduling. Traditional approaches, which
depend on expert-based modeling and manual parameter adjustment, often face
challenges in handling large-scale, dynamic, and multi-constraint problems.
Recently, large language models (LLMs) have shown potential to address these
limitations through semantic understanding, structured generation, and
reasoning control. LLMs can translate natural language descriptions into
mathematical models or executable code, generate heuristics, evolve algorithms,
and directly tackle optimization tasks. This paper surveys recent progress on
the integration of LLMs into OR, organizing methods into three main directions:
automatic modeling, auxiliary optimization, and direct solving. It further
reviews evaluation benchmarks and domain-specific applications, and summarizes
key open issues such as unstable semantic-to-structure mapping, fragmented
research progress, limited generalization, and insufficient evaluation systems.
Finally, the survey outlines possible research avenues for advancing the role
of LLMs in OR.

</details>


### [379] [Synthesizing Attitudes, Predicting Actions (SAPA): Behavioral Theory-Guided LLMs for Ridesourcing Mode Choice Modeling](https://arxiv.org/abs/2509.18181)
*Mustafa Sameen,Xiaojian Zhang,Xilei Zhao*

Main category: cs.AI

TL;DR: 本研究提出了一种名为SAPA的新框架，利用大型语言模型（LLM）来合成潜在态度，以提高网约车出行方式选择预测的准确性，解决了现有模型因难以捕捉心理因素和类别不平衡而导致的预测精度不足的问题。


<details>
  <summary>Details</summary>
Motivation: 准确的网约车出行模式选择模型对于设计有效的交通管理政策至关重要，以减少拥堵、改善出行和更有效地分配资源。现有模型在这方面存在不足。

Method: SAPA框架首先利用LLM根据原始出行调查数据生成定性出行者画像，然后训练一个倾向得分模型，并结合画像信息来生成个体得分。接着，LLM为潜在变量（如时间和成本敏感性）分配定量分数。最后，一个分类器整合倾向得分、潜在变量得分（及其交互项）以及可观察的出行属性来预测网约车出行方式选择。

Result: 实验结果表明，SAPA显著优于最先进的基线模型，在测试集上的PR-AUC方面，网约车出行选择预测的准确性提高了高达75.9%。

Conclusion: 本研究提供了一个准确预测网约车出行方式选择的强大工具，并提供了一种易于迁移到各种应用的方法。

Abstract: Accurate modeling of ridesourcing mode choices is essential for designing and
implementing effective traffic management policies for reducing congestion,
improving mobility, and allocating resources more efficiently. Existing models
for predicting ridesourcing mode choices often suffer from limited predictive
accuracy due to their inability to capture key psychological factors, and are
further challenged by severe class imbalance, as ridesourcing trips comprise
only a small fraction of individuals' daily travel. To address these
limitations, this paper introduces the Synthesizing Attitudes, Predicting
Actions (SAPA) framework, a hierarchical approach that uses Large Language
Models (LLMs) to synthesize theory-grounded latent attitudes to predict
ridesourcing choices. SAPA first uses an LLM to generate qualitative traveler
personas from raw travel survey data and then trains a propensity-score model
on demographic and behavioral features, enriched by those personas, to produce
an individual-level score. Next, the LLM assigns quantitative scores to
theory-driven latent variables (e.g., time and cost sensitivity), and a final
classifier integrates the propensity score, latent-variable scores (with their
interaction terms), and observable trip attributes to predict ridesourcing mode
choice. Experiments on a large-scale, multi-year travel survey show that SAPA
significantly outperforms state-of-the-art baselines, improving ridesourcing
choice predictions by up to 75.9% in terms of PR-AUC on a held-out test set.
This study provides a powerful tool for accurately predicting ridesourcing mode
choices, and provides a methodology that is readily transferable to various
applications.

</details>


### [380] [An Outcome-Based Educational Recommender System](https://arxiv.org/abs/2509.18186)
*Nursultan Askarbekuly,Timur Fayzrakhmanov,Sladjan Babarogić,Ivan Luković*

Main category: cs.AI

TL;DR: OBER是一个基于结果的教育推荐系统，可以根据学习成果评估推荐算法，并已在真实环境中进行了测试。


<details>
  <summary>Details</summary>
Motivation: 大多数教育推荐系统依赖点击或评分来评估相关性，但其真实的教学效果尚不清楚。

Method: OBER使用基于实体的关系模型、日志驱动的掌握度公式和插件架构。它通过记录学习者的互动和评估来跟踪学习进度，并根据预定义学习成果的掌握情况来评估推荐算法的有效性。

Result: 在为期两周的A/B测试中，虽然协同过滤（CF）在用户留存方面表现最佳，但固定路径的教学方法在学习者掌握度方面取得了最高分。这表明，仅关注用户互动（如点击率）可能无法充分体现教学效果。

Conclusion: OBER通过将学习成果和评估项目直接嵌入数据模式，为教育推荐系统提供了一种新的评估维度，可以衡量其促进的掌握度，而不仅仅是用户互动。该框架具有方法无关性和可扩展性，可用于评估各种推荐算法的教学影响。

Abstract: Most educational recommender systems are tuned and judged on click- or
rating-based relevance, leaving their true pedagogical impact unclear. We
introduce OBER-an Outcome-Based Educational Recommender that embeds learning
outcomes and assessment items directly into the data schema, so any algorithm
can be evaluated on the mastery it fosters. OBER uses a minimalist
entity-relation model, a log-driven mastery formula, and a plug-in
architecture. Integrated into an e-learning system in non-formal domain, it was
evaluated trough a two-week randomized split test with over 5 700 learners
across three methods: fixed expert trajectory, collaborative filtering (CF),
and knowledge-based (KB) filtering. CF maximized retention, but the fixed path
achieved the highest mastery. Because OBER derives business, relevance, and
learning metrics from the same logs, it lets practitioners weigh relevance and
engagement against outcome mastery with no extra testing overhead. The
framework is method-agnostic and readily extensible to future adaptive or
context-aware recommenders.

</details>


### [381] [nDNA -- the Semantic Helix of Artificial Cognition](https://arxiv.org/abs/2509.18216)
*Amitava Das*

Main category: cs.AI

TL;DR: 该研究提出了神经网络DNA（nDNA）作为一种新的语义-基因型表示方法，用于捕捉AI基础模型潜在的内在几何结构，从而揭示其“认知身份”。nDNA通过三个维度（谱曲率、热力学长度和信念向量场）来量化模型的内在几何特征，类似于生物DNA编码了遗传信息，nDNA也记录了模型在训练、微调和演变过程中的“遗传”痕迹。研究者将此开创为一个新领域——神经基因组学，旨在将模型视为具有可追溯认知能力的“数字语义生物”，用于模型比较、风险诊断和演化研究。


<details>
  <summary>Details</summary>
Motivation: 随着AI基础模型能力增强，理解其超越表面行为的内在“认知身份”变得越发重要。现有的基准测试仅能衡量行为，而模型的本质根植于其潜在的几何结构。

Method: 提出了一种名为神经网络DNA（nDNA）的语义-基因型表示方法。nDNA基于三个核心的潜在几何维度：谱曲率（量化概念流动的曲率）、热力学长度（量化表示过渡的语义成本）和信念向量场（描绘引导信念方向的语义扭曲场）。通过分析模型在预训练、微调、对齐、剪枝、蒸馏和合并等过程中的变化，追踪模型的“遗传”和“变异”。

Result: nDNA能够捕捉模型的内在几何特征，作为一种稳定的、坐标无关的“神经网络DNA指纹”，该指纹与模型的输入行为相关联。通过这种指纹，可以追溯模型在不同生命周期阶段（如预训练、微调、对齐等）的“谱系”，测量检查点之间的“遗传”关系，检测因新数据或目标变化引起的“性状漂移”，并研究人工智能认知的演化。

Conclusion: nDNA提供了一种新颖的视角来理解和量化AI基础模型的内在认知结构，将模型视为具有“遗传”和“演化”能力的“数字语义生物”。这为模型比较、风险评估和治理开辟了新的途径，标志着神经基因组学这一新领域的诞生。

Abstract: As AI foundation models grow in capability, a deeper question emerges: What
shapes their internal cognitive identity -- beyond fluency and output?
Benchmarks measure behavior, but the soul of a model resides in its latent
geometry. In this work, we propose Neural DNA (nDNA) as a semantic-genotypic
representation that captures this latent identity through the intrinsic
geometry of belief. At its core, nDNA is synthesized from three principled and
indispensable dimensions of latent geometry: spectral curvature, which reveals
the curvature of conceptual flow across layers; thermodynamic length, which
quantifies the semantic effort required to traverse representational
transitions through layers; and belief vector field, which delineates the
semantic torsion fields that guide a model's belief directional orientations.
Like biological DNA, it encodes ancestry, mutation, and semantic inheritance,
found in finetuning and alignment scars, cultural imprints, and architectural
drift. In naming it, we open a new field: Neural Genomics, where models are not
just tools, but digital semantic organisms with traceable inner cognition.
  Modeling statement. We read AI foundation models as semantic fluid--dynamics:
meaning is transported through layers like fluid in a shaped conduit; nDNA is
the physics-grade readout of that flow -- a geometry-first measure of how
meaning is bent, paid for, and pushed -- yielding a stable, coordinate-free
neural DNA fingerprint tied to on-input behavior; with this fingerprint we
cross into biology: tracing lineages across pretraining, fine-tuning,
alignment, pruning, distillation, and merges; measuring inheritance between
checkpoints; detecting drift as traits shift under new data or objectives; and,
ultimately, studying the evolution of artificial cognition to compare models,
diagnose risks, and govern change over time.

</details>


### [382] [Similarity Field Theory: A Mathematical Framework for Intelligence](https://arxiv.org/abs/2509.18218)
*Kei-Sing Ng*

Main category: cs.AI

TL;DR: 本篇论文提出了相似性场理论（Similarity Field Theory, SFT），一个形式化框架，用于描述动态系统中实体之间相似性关系及其演化规律。理论核心包括相似性场S、系统演化Z_p、概念K及其诱导的纤维F_α(K)，以及生成新实体的生成算子G。基于此，论文提出了智能的生成定义：一个算子G若能基于概念K的纤维中的实体生成新的也属于该纤维的实体，则该算子是智能的。SFT为表征、比较和构建智能系统提供了基础语言。论文证明了两个定理：(i) 不对称性阻止了相互包含；(ii) 稳定性需要锚定坐标或最终限制在f的某个层集内。这些结果确保了相似性场的演化是受约束且可解释的。最后，论文探讨了SFT如何用于解释大型语言模型，并将其用作探索社会认知的实验工具。


<details>
  <summary>Details</summary>
Motivation: 我们认为，持续存在的和转化的相似性关系是任何可理解的动态系统的结构基础。本篇论文旨在提出一个名为“相似性场理论”的数学框架，该框架形式化了实体间相似性值及其演化所遵循的原理。

Method: 本研究定义了以下核心概念：(1) 相似性场 S: U × U → [0,1]，这是一个在实体集合U上定义的场，满足自反性 S(E,E)=1，并且可以是不对称和非传递的。(2) 系统的演化 Z_p = (X_p, S^(p))，其中 p=0,1,2,...。(3) 概念 K，被定义为诱导纤维 F_α(K) = { E ∈ U | S(E,K) ≥ α } 的实体，即一元映射 S_K(E) := S(E,K) 的超水平集。(4) 生成算子 G，用于产生新的实体。在此框架下，研究形式化了智能的生成定义：如果一个算子G能够基于包含概念K的纤维中的实体生成新的也属于该纤维的实体，则称该算子是智能的。此外，还证明了两个定理：(i) 不对称性阻止相互包含；(ii) 稳定性需要锚定坐标或最终被限制在某个层集内。

Result: 本研究证明了两个定理：(i) 不对称性可以阻止实体间的相互包含关系；(ii) 系统的稳定性需要满足两个条件之一：要么存在一个锚定坐标，要么系统最终被限制在某个层集内。这些结果保证了相似性场的演化是受到约束且可解释的。

Conclusion: 相似性场理论为表征、比较和构建智能系统提供了一个基础性的语言。通过证明的定理，该框架确保了相似性场演化的约束性和可解释性。最后，论文将该理论应用于解释大型语言模型，并提出利用它们作为探索社会认知的实验工具。

Abstract: We posit that persisting and transforming similarity relations form the
structural basis of any comprehensible dynamic system. This paper introduces
Similarity Field Theory, a mathematical framework that formalizes the
principles governing similarity values among entities and their evolution. We
define: (1) a similarity field $S: U \times U \to [0,1]$ over a universe of
entities $U$, satisfying reflexivity $S(E,E)=1$ and treated as a directed
relational field (asymmetry and non-transitivity are allowed); (2) the
evolution of a system through a sequence $Z_p = (X_p, S^{(p)})$ indexed by
$p=0,1,2,\ldots$; (3) concepts $K$ as entities that induce fibers
$F_{\alpha}(K) = { E \in U \mid S(E,K) \ge \alpha }$, i.e., superlevel sets of
the unary map $S_K(E) := S(E,K)$; and (4) a generative operator $G$ that
produces new entities. Within this framework, we formalize a generative
definition of intelligence: an operator $G$ is intelligent with respect to a
concept $K$ if, given a system containing entities belonging to the fiber of
$K$, it generates new entities that also belong to that fiber. Similarity Field
Theory thus offers a foundational language for characterizing, comparing, and
constructing intelligent systems. We prove two theorems: (i) asymmetry blocks
mutual inclusion; and (ii) stability requires either an anchor coordinate or
eventual confinement within a level set of $f$. These results ensure that the
evolution of similarity fields is both constrained and interpretable,
culminating in an exploration of how the framework allows us to interpret large
language models and use them as experimental probes into societal cognition.

</details>


### [383] [Multimodal Health Risk Prediction System for Chronic Diseases via Vision-Language Fusion and Large Language Models](https://arxiv.org/abs/2509.18221)
*Dingxin Lu,Shurui Wu,Xinyi Huang*

Main category: cs.AI

TL;DR: VL-RiskFormer是一个包含大型语言模型推理头的分层堆叠视觉-语言多模态Transformer，用于预测个体健康风险。


<details>
  <summary>Details</summary>
Motivation: 随着慢性病负担的增加和临床数据的多模态异构性，迫切需要一个统一的多模态人工智能框架来预测个体健康风险。

Method: VL-RiskFormer在双流架构的基础上进行了四项关键创新：(i) 使用动量更新编码器和去偏置InfoNCE损失对放射图像、眼底图和可穿戴设备照片及其临床叙述进行跨模态比较和细粒度对齐预训练；(ii) 引入时间融合块，通过自适应时间间隔位置编码将不规则的就诊序列整合到因果Transformer解码器中；(iii) 集成疾病本体图适配器，将ICD-10代码注入视觉和文本通道，并借助图注意力机制推断共病模式。

Result: 在MIMIC-IV纵向队列上，VL-RiskFormer实现了0.90的平均AUROC和2.7%的预期校准误差。

Conclusion: VL-RiskFormer在预测个体健康风险方面表现出色，证明了其作为统一多模态AI框架的潜力。

Abstract: With the rising global burden of chronic diseases and the multimodal and
heterogeneous clinical data (medical imaging, free-text recordings, wearable
sensor streams, etc.), there is an urgent need for a unified multimodal AI
framework that can proactively predict individual health risks. We propose
VL-RiskFormer, a hierarchical stacked visual-language multimodal Transformer
with a large language model (LLM) inference head embedded in its top layer. The
system builds on the dual-stream architecture of existing visual-linguistic
models (e.g., PaLM-E, LLaVA) with four key innovations: (i) pre-training with
cross-modal comparison and fine-grained alignment of radiological images,
fundus maps, and wearable device photos with corresponding clinical narratives
using momentum update encoders and debiased InfoNCE losses; (ii) a time fusion
block that integrates irregular visit sequences into the causal Transformer
decoder through adaptive time interval position coding; (iii) a disease
ontology map adapter that injects ICD-10 codes into visual and textual channels
in layers and infers comorbid patterns with the help of a graph attention
mechanism. On the MIMIC-IV longitudinal cohort, VL-RiskFormer achieved an
average AUROC of 0.90 with an expected calibration error of 2.7 percent.

</details>


### [384] [From "What to Eat?" to Perfect Recipe: ChefMind's Chain-of-Exploration for Ambiguous User Intent in Recipe Recommendation](https://arxiv.org/abs/2509.18226)
*Yu Fu,Linyue Cai,Ruoyu Wu,Yong Zhao*

Main category: cs.AI

TL;DR: ChefMind是一个结合了探索链（CoE）、知识图（KG）、检索增强生成（RAG）和大型语言模型（LLM）的混合推荐系统，用于解决个性化菜谱推荐中的模糊用户意图、语义准确性和细节覆盖不足的问题。


<details>
  <summary>Details</summary>
Motivation: 个性化菜谱推荐系统在处理模糊的用户意图、确保语义准确性和提供充足的细节覆盖方面面临挑战。

Method: ChefMind采用混合架构，结合了探索链（CoE）来细化模糊查询、知识图（KG）进行语义推理和解释、检索增强生成（RAG）来补充烹饪细节，以及大型语言模型（LLM）来整合输出并生成连贯的推荐。

Result: 在Xiachufang数据集和手动标注查询上的评估显示，ChefMind的平均得分为8.7，优于仅使用LLM、KG或RAG的模型（得分在6.4-6.7之间），在准确性、相关性、完整性和清晰度方面表现更佳。此外，ChefMind将未处理的查询减少到1.6%，证明了其处理模糊需求的能力。

Conclusion: ChefMind通过整合多种技术，有效解决了个性化菜谱推荐中的挑战，并在准确性、相关性、完整性和清晰度方面取得了显著的性能提升。

Abstract: Personalized recipe recommendation faces challenges in handling fuzzy user
intent, ensuring semantic accuracy, and providing sufficient detail coverage.
We propose ChefMind, a hybrid architecture combining Chain of Exploration
(CoE), Knowledge Graph (KG), Retrieval-Augmented Generation (RAG), and a Large
Language Model (LLM). CoE refines ambiguous queries into structured conditions,
KG offers semantic reasoning and interpretability, RAG supplements contextual
culinary details, and LLM integrates outputs into coherent recommendations. We
evaluate ChefMind on the Xiachufang dataset and manually annotated queries,
comparing it with LLM-only, KG-only, and RAG-only baselines. Results show that
ChefMind achieves superior performance in accuracy, relevance, completeness,
and clarity, with an average score of 8.7 versus 6.4-6.7 for ablation models.
Moreover, it reduces unprocessed queries to 1.6%, demonstrating robustness in
handling fuzzy demands.

</details>


### [385] [An N-Plus-1 GPT Agency for Critical Solution of Mechanical Engineering Analysis Problems](https://arxiv.org/abs/2509.18229)
*Anthony Patera,Rohan Abeyaratne*

Main category: cs.AI

TL;DR: 生成式AI（特别是GPT）虽然能解决机械工程分析问题，但存在不可靠性。本文提出一种“N-Plus-1”GPT代理方法，通过运行N个GPT实例并比较其结果，以提高解决方案的准确性。该方法借鉴了孔多塞陪审定理，在N足够大且单个实例成功率高于1/2的情况下，能够高概率地得到正确解。此外，该方法还能处理不同的问题解释和求解方法，并具有透明度和教学价值。


<details>
  <summary>Details</summary>
Motivation: GPT在解决机械工程分析问题时存在不可靠性，成功率仅为85%，不适合直接用于教育或工程实践。

Method: 提出“N-Plus-1”GPT代理方法，首先运行N个独立的GPT实例（Agent Solve）生成N个解决方案，然后由Agent Compare进行总结和比较，最终推荐一个解决方案。

Result: 该方法借鉴了孔多塞陪审定理，在单个实例成功率大于1/2且N足够大的情况下，能够高概率地得到正确解。Agent Compare还可以整合次优解中的信息，例如不同的数学模型或求解方法。与Grok Heavy相比，该方法在设计和性能上相似，但在透明度和教学价值方面更受重视。

Conclusion: “N-Plus-1”GPT代理方法通过集成多个GPT实例并进行比较，解决了GPT在机械工程分析中的可靠性问题，并具有潜在的教学价值。

Abstract: Generative AI, and specifically GPT, can produce a remarkable solution to a
mechanical engineering analysis problem - but also, on occasion, a flawed
solution. For example, an elementary mechanics problem is solved flawlessly in
one GPT instance and incorrectly in a subsequent GPT instance, with a success
probability of only 85%. This unreliability renders "out-of-the-box" GPT
unsuitable for deployment in education or engineering practice. We introduce an
"N-Plus-1" GPT Agency for Initial (Low-Cost) Analysis of mechanical engineering
Problem Statements. Agency first launches N instantiations of Agent Solve to
yield N independent Proposed Problem Solution Realizations; Agency then invokes
Agent Compare to summarize and compare the N Proposed Problem Solution
Realizations and to provide a Recommended Problem Solution. We argue from
Condorcet's Jury Theorem that, for a Problem Statement characterized by
per-Solve success probability greater than 1/2 (and N sufficiently large), the
Predominant (Agent Compare) Proposed Problem Solution will, with high
probability, correspond to a Correct Proposed Problem Solution. Furthermore,
Agent Compare can also incorporate aspects of Secondary (Agent Compare)
Proposed Problem Solutions, in particular when the latter represent alternative
Problem Statement interpretations - different Mathematical Models - or
alternative Mathematical Solution Procedures. Comparisons to Grok Heavy, a
commercial multi-agent model, show similarities in design and performance, but
also important differences in emphasis: our Agency focuses on transparency and
pedagogical value.

</details>


### [386] [Towards General Computer Control with Hierarchical Agents and Multi-Level Action Spaces](https://arxiv.org/abs/2509.18230)
*Zihan Dong,Xinyu Fan,Zixiang Tang,Yunqing Li*

Main category: cs.AI

TL;DR: ComputerAgent是一个轻量级分层强化学习框架，通过多模态状态编码和元动作与早停机制，实现了高效的桌面应用控制，参数量仅为15M，在真实任务中表现优于大型模型。


<details>
  <summary>Details</summary>
Motivation: 控制桌面应用程序是一个基本但服务不足的问题，现有的多模态大语言模型（MLLMs）存在推理延迟高、样本效率低和设备部署不可行的问题。

Method: ComputerAgent是一个轻量级分层强化学习框架，它将操作系统控制设计为一个两级选项过程（管理器和子策略），采用三模态状态编码器（屏幕截图、任务ID、数值状态）来处理视觉和上下文的多样性，集成元动作和早停机制以减少无效交互，并使用紧凑的视觉骨干网络和小型策略网络来实现设备端推理（15M参数）。

Result: 在135个真实桌面任务的测试中，ComputerAgent在简单任务（<8步）上实现了92.1%的成功率，在困难任务（>=8步）上实现了58.8%的成功率，在简单场景下其表现与200B参数的MLLMs基线相当或更优，同时模型尺寸减小了四个数量级，推理时间缩短了一半。

Conclusion: 分层强化学习为计算机控制提供了一种实用、可扩展的替代方案，能够取代单体MLLM驱动的自动化。

Abstract: Controlling desktop applications via software remains a fundamental yet
under-served problem. Existing multi-modal large language models (MLLMs) ingest
screenshots and task instructions to generate keystrokes and mouse events, but
they suffer from prohibitive inference latency, poor sample efficiency on
long-horizon sparse-reward tasks, and infeasible on-device deployment. We
introduce a lightweight hierarchical reinforcement learning framework,
ComputerAgent, that formulates OS control as a two-level option process
(manager and subpolicy), employs a triple-modal state encoder (screenshot, task
ID, numeric state) to handle visual and contextual diversity, integrates
meta-actions with an early-stop mechanism to reduce wasted interactions, and
uses a compact vision backbone plus small policy networks for on-device
inference (15M parameters). On a suite of 135 real-world desktop tasks,
ComputerAgent attains 92.1% success on simple tasks (<8 steps) and 58.8% on
hard tasks (>=8 steps), matching or exceeding 200B-parameter MLLM baselines on
simple scenarios while reducing model size by over four orders of magnitude and
halving inference time. These results demonstrate that hierarchical RL offers a
practical, scalable alternative to monolithic MLLM-based automation for
computer control.

</details>


### [387] [The Illusion of Readiness: Stress Testing Large Frontier Models on Multimodal Medical Benchmarks](https://arxiv.org/abs/2509.18234)
*Yu Gu,Jingjing Fu,Xiaodong Liu,Jeya Maria Jose Valanarasu,Noel Codella,Reuben Tan,Qianchu Liu,Ying Jin,Sheng Zhang,Jinyu Wang,Rui Wang,Lei Song,Guanghui Qin,Naoto Usuyama,Cliff Wong,Cheng Hao,Hohin Lee,Praneeth Sanapathi,Sarah Hilado,Bian Jiang,Javier Alvarez-Valle,Mu Wei,Jianfeng Gao,Eric Horvitz,Matt Lungren,Hoifung Poon,Paul Vozila*

Main category: cs.AI

TL;DR: 大型语言模型在医学基准测试中表现优异，但在压力测试下暴露出许多问题，例如在缺少关键输入（如图像）的情况下也能猜对，对微小的提示更改反应不一，并且会编造看似合理但有缺陷的推理过程。这表明当前的基准测试可能更侧重于“应试技巧”而非真正的医学理解。


<details>
  <summary>Details</summary>
Motivation: 评估当前领先的AI模型在医学领域的实际能力，揭示在严格测试下它们存在的脆弱性和“走捷径”学习的问题，并指出医学基准测试在衡量真实世界能力方面的局限性。

Method: 对六个主流的大型语言模型在六个常用的医学基准测试上进行压力测试。通过临床医生指导的评分标准评估，分析基准测试实际衡量的内容以及它们被不当互换使用的现象，以暴露模型的失败模式。

Result: 研究发现，尽管模型在基准测试中得分很高，但它们表现出脆弱性和“走捷径”学习的行为。不同的基准测试实际衡量的内容差异很大，但却被当作是等效的，这掩盖了模型的失败模式。

Conclusion: 目前的医学基准测试分数不能直接反映AI在真实医疗环境中的准备程度。为了让AI在医疗领域获得信任，我们需要对其鲁棒性、推理的合理性以及是否符合实际医疗需求有更高的要求，而不仅仅满足于基准测试的领先地位。

Abstract: Large frontier models like GPT-5 now achieve top scores on medical
benchmarks. But our stress tests tell a different story. Leading systems often
guess correctly even when key inputs like images are removed, flip answers
under trivial prompt changes, and fabricate convincing yet flawed reasoning.
These aren't glitches; they expose how today's benchmarks reward test-taking
tricks over medical understanding. We evaluate six flagship models across six
widely used benchmarks and find that high leaderboard scores hide brittleness
and shortcut learning. Through clinician-guided rubric evaluation, we show that
benchmarks vary widely in what they truly measure yet are treated
interchangeably, masking failure modes. We caution that medical benchmark
scores do not directly reflect real-world readiness. If we want AI to earn
trust in healthcare, we must demand more than leaderboard wins and must hold
systems accountable for robustness, sound reasoning, and alignment with real
medical demands.

</details>


### [388] [Evaluating the Safety and Skill Reasoning of Large Reasoning Models Under Compute Constraints](https://arxiv.org/abs/2509.18382)
*Adarsha Balaji,Le Chen,Rajeev Thakur,Franck Cappello,Sandeep Madireddy*

Main category: cs.AI

TL;DR: 通过长度约束和模型量化来减少推理模型的计算需求，同时研究其对安全性的影响。


<details>
  <summary>Details</summary>
Motivation: 现有的测试时计算扩展方法虽然能通过生成更长的链式思考（CoT）序列来提升推理语言模型的性能，但计算成本显著增加。本研究旨在解决此问题。

Method: 研究了两种计算约束策略：（1）推理长度约束：使用基于长度受控策略优化（LCPO）的强化学习方法进行微调，以满足用户定义的CoT推理长度；（2）模型量化：在用户定义的计算约束内，最大化CoT序列的生成。

Result: 探究了计算效率与模型安全性的权衡。

Conclusion: 计算约束策略（长度约束和模型量化）可以降低推理模型的计算需求，并研究了其对模型安全性的影响。

Abstract: Test-time compute scaling has demonstrated the ability to improve the
performance of reasoning language models by generating longer chain-of-thought
(CoT) sequences. However, this increase in performance comes with a significant
increase in computational cost. In this work, we investigate two compute
constraint strategies: (1) reasoning length constraint and (2) model
quantization, as methods to reduce the compute demand of reasoning models and
study their impact on their safety performance. Specifically, we explore two
approaches to apply compute constraints to reasoning models: (1) fine-tuning
reasoning models using a length controlled policy optimization (LCPO) based
reinforcement learning method to satisfy a user-defined CoT reasoning length,
and (2) applying quantization to maximize the generation of CoT sequences
within a user-defined compute constraint. Furthermore, we study the trade-off
between the computational efficiency and the safety of the model.

</details>


### [389] [Gödel Test: Can Large Language Models Solve Easy Conjectures?](https://arxiv.org/abs/2509.18383)
*Moran Feldman,Amin Karbasi*

Main category: cs.AI

TL;DR: GPT-5在组合优化领域的五个猜想上表现出有意义的进展，但在需要交叉论文综合的方面存在局限性。


<details>
  <summary>Details</summary>
Motivation: 评估大型语言模型在解决数学竞赛之外的数学问题，特别是之前未解决的简单猜想方面的能力。

Method: 对GPT-5在五个组合优化猜想上的表现进行研究，为模型提供猜想的来源论文，并评估其推理过程。

Result: GPT-5在三个较容易的问题上给出了近乎正确的解决方案，其中一个问题甚至得出了一个错误的猜想但给出了有效的解决方案。在需要结合两篇论文信息的问题上，GPT-5表现不佳。在最后一个更难的问题上，GPT-5提出了与研究人员相同的算法，但在分析上失败了。

Conclusion: GPT-5在常规推理方面取得了有意义的进展，偶尔表现出原创性，但在需要交叉论文综合时存在明显限制。GPT-5可能是未来能够通过“哥德尔测试”的前沿模型的一个早期代表。

Abstract: Recent announcements from frontier AI model labs have highlighted strong
results on high-school and undergraduate math competitions. Yet it remains
unclear whether large language models can solve new, simple conjectures in more
advanced areas of mathematics. We propose the G\"odel Test: evaluating whether
a model can produce correct proofs for very simple, previously unsolved
conjectures. To this end, we study the performance of GPT-5 on five conjectures
in combinatorial optimization. For each problem, we provided one or two source
papers from which the conjecture arose, withheld our own conjecture, and then
assessed the model's reasoning in detail. On the three easier problems, GPT-5
produced nearly correct solutions; for Problem 2 it even derived a different
approximation guarantee that, upon checking, refuted our conjecture while
providing a valid solution. The model failed on Problem 4, which required
combining results from two papers. On Problem 5, a harder case without a
validated conjecture, GPT-5 proposed the same algorithm we had in mind but
failed in the analysis, suggesting the proof is more challenging than expected.
Although our sample is small, the results point to meaningful progress on
routine reasoning, occasional flashes of originality, and clear limitations
when cross-paper synthesis is required. GPT-5 may represent an early step
toward frontier models eventually passing the G\"odel Test.

</details>


### [390] [ATLAS: Benchmarking and Adapting LLMs for Global Trade via Harmonized Tariff Code Classification](https://arxiv.org/abs/2509.18400)
*Pritish Yuvraj,Siva Devarakonda*

Main category: cs.AI

TL;DR: 该研究首次提出了海关编码分类基准，并引入了经过微调的 Atlas 模型（LLaMA-3.3-70B），在10位和6位分类上均取得了显著的准确率提升，同时成本更低且支持自托管以保护数据隐私。研究旨在推动海关编码分类成为一个新的社区基准任务。


<details>
  <summary>Details</summary>
Motivation: 准确对商品进行海关编码（HTS）分类对于全球贸易至关重要，但此前机器学习领域对此关注不足，错误分类会导致货物运输中断。

Method: 创建了首个源自美国海关裁定在线搜索系统（CROSS）的海关编码（HTS）分类基准，并评估了包括 Atlas（LLaMA-3.3-70B）、GPT-5-Thinking 和 Gemini-2.5-Pro-Thinking 在内的领先大型语言模型。

Result: 经过微调的 Atlas 模型在10位分类上达到了40%的准确率，6位分类上达到了57.5%的准确率，分别比 GPT-5-Thinking 高15个百分点，比 Gemini-2.5-Pro-Thinking 高27.5个百分点。此外，Atlas 的成本比 GPT-5-Thinking 低约五倍，比 Gemini-2.5-Pro-Thinking 低约八倍。

Conclusion: 尽管 Atlas 模型取得了显著进展，但海关编码分类任务仍然充满挑战，10位分类准确率仅为40%。通过发布数据集和模型，研究旨在将海关编码分类确立为一个新的社区基准任务，并鼓励在检索、推理和对齐方面进行未来研究。

Abstract: Accurate classification of products under the Harmonized Tariff Schedule
(HTS) is a critical bottleneck in global trade, yet it has received little
attention from the machine learning community. Misclassification can halt
shipments entirely, with major postal operators suspending deliveries to the
U.S. due to incomplete customs documentation. We introduce the first benchmark
for HTS code classification, derived from the U.S. Customs Rulings Online
Search System (CROSS). Evaluating leading LLMs, we find that our fine-tuned
Atlas model (LLaMA-3.3-70B) achieves 40 percent fully correct 10-digit
classifications and 57.5 percent correct 6-digit classifications, improvements
of 15 points over GPT-5-Thinking and 27.5 points over Gemini-2.5-Pro-Thinking.
Beyond accuracy, Atlas is roughly five times cheaper than GPT-5-Thinking and
eight times cheaper than Gemini-2.5-Pro-Thinking, and can be self-hosted to
guarantee data privacy in high-stakes trade and compliance workflows. While
Atlas sets a strong baseline, the benchmark remains highly challenging, with
only 40 percent 10-digit accuracy. By releasing both dataset and model, we aim
to position HTS classification as a new community benchmark task and invite
future work in retrieval, reasoning, and alignment.

</details>


### [391] [Instruction-Following Evaluation in Function Calling for Large Language Models](https://arxiv.org/abs/2509.18420)
*Nikolai Skripko*

Main category: cs.AI

TL;DR: IFEval-FC 是一个评估大型语言模型函数调用中指令遵循能力的新基准。该基准通过在 JSON schema 中编码可验证的格式来测试模型是否能遵循参数描述中的格式说明。现有模型（包括 GPT-5 和 Claude 4.1 Opus）在遵循基本格式规则方面存在不足，这表明在实际应用中存在局限性。


<details>
  <summary>Details</summary>
Motivation: 现有评估函数调用的基准（如 BFCL、tau^2-Bench、ACEBench）主要关注参数的正确性，但忽略了模型遵循参数描述中嵌入的格式指令的能力，例如值是否用双引号括起来或是否使用 ISO 日期格式。这对于构建可靠的 AI 代理至关重要。

Method: IFEval-FC 基准的设计灵感来源于 IFEval，它将可验证的格式直接嵌入到 JSON schema 描述中，例如指定某个值不应包含标点符号。该基准包含 750 个测试用例，每个用例都包括一个带有格式说明的函数及其对应的用户查询。评估过程完全算法化，以确保客观性、可复现性和可扩展性。

Result: 实验结果表明，即使是像 GPT-5 和 Claude 4.1 Opus 这样最先进的专有模型，也经常无法遵循基本的格式规则。这揭示了在实际的 AI 代理系统中存在一个实际的局限性。

Conclusion: IFEval-FC 基准的引入突显了大型语言模型在严格遵循函数调用格式指令方面存在的不足。现有模型在处理这些格式约束时表现出的挣扎，对需要精确格式化输入的真实世界 AI 代理系统的开发和部署提出了挑战。

Abstract: Function calling is a core capability of large language models, essential for
AI agents. Existing benchmarks such as the Berkeley Function Calling
Leaderboard (BFCL), tau^2-Bench (arXiv:2506.07982), and ACEBench
(arXiv:2501.12851) evaluate argument correctness but do not test adherence to
format instructions embedded in parameter descriptions, such as enclosing
values in double quotes or using ISO date formats.
  We introduce IFEval-FC, a benchmark inspired by IFEval (arXiv:2311.07911)
that assesses precise instruction following in function calling. IFEval-FC
encodes verifiable formats directly within JSON schema descriptions, for
example specifying that a value must not contain punctuation. It includes 750
test cases, each consisting of a function with an embedded format for one of
its input parameters and a corresponding user query. Evaluation is fully
algorithmic, ensuring objectivity, reproducibility, and scalability.
  Our results show that even state-of-the-art proprietary models, including
GPT-5 and Claude 4.1 Opus, frequently fail to follow basic formatting rules,
highlighting a practical limitation for real-world agent systems. The complete
codebase and data are publicly available at
https://github.com/Skripkon/IFEval-FC.

</details>


### [392] [Memory-QA: Answering Recall Questions Based on Multimodal Memories](https://arxiv.org/abs/2509.18436)
*Hongda Jiang,Xinyuan Zhang,Siddhant Garg,Rishab Arora,Shiun-Zu Kuo,Jiayang Xu,Christopher Brossman,Yue Liu,Aaron Colak,Ahmed Aly,Anuj Kumar,Xin Luna Dong*

Main category: cs.AI

TL;DR: Memory-QA是一个新的视觉问答任务，需要从先前的多模态记忆中回答关于视觉内容的问题。Pensieve是一个集成记忆增强、时空感知检索和多记忆问答微调的流水线，旨在解决此任务的挑战。


<details>
  <summary>Details</summary>
Motivation: 现有技术在处理需要从先前存储的多模态记忆中回忆视觉内容的问题时存在不足，该任务具有记忆创建、时空信息利用和多记忆整合等独特挑战。

Method: 提出了一种名为Pensieve的流水线，包括记忆增强、时空感知多信号检索和多记忆问答微调。

Result: 在创建的多模态基准上，Pensieve的性能优于现有技术，QA准确率提高了14%。

Conclusion: 所提出的Memory-QA任务和Pensieve流水线能够有效应对从多模态记忆中进行视觉问答的挑战，并取得了优于现有技术的性能。

Abstract: We introduce Memory-QA, a novel real-world task that involves answering
recall questions about visual content from previously stored multimodal
memories. This task poses unique challenges, including the creation of
task-oriented memories, the effective utilization of temporal and location
information within memories, and the ability to draw upon multiple memories to
answer a recall question. To address these challenges, we propose a
comprehensive pipeline, Pensieve, integrating memory-specific augmentation,
time- and location-aware multi-signal retrieval, and multi-memory QA
fine-tuning. We created a multimodal benchmark to illustrate various real
challenges in this task, and show the superior performance of Pensieve over
state-of-the-art solutions (up to 14% on QA accuracy).

</details>


### [393] [FERA: Foil Fencing Referee Assistant Using Pose-Based Multi-Label Move Recognition and Rule Reasoning](https://arxiv.org/abs/2509.18527)
*Ziwen Chen,Zhong Wang*

Main category: cs.AI

TL;DR: FERA是一个为击剑比赛设计的AI裁判原型，使用基于姿态的多标签动作识别和规则推理来解决主观判罚、错误和可用性问题。


<details>
  <summary>Details</summary>
Motivation: 体育比赛（如击剑）面临裁判中的主观判罚、人为错误、偏见以及练习环境中可用性有限等挑战。

Method: FERA提取视频中的2D关节位置，进行归一化，计算101维运动特征，并使用Transformer进行多标签动作和剑刃分类。为了确定优先权和得分，FERA应用了带有编码的右侧规则的精炼语言模型，为每次攻防提供决策和解释。

Result: 在有限的标注数据下，通过5折交叉验证，平均宏F1得分为0.549，优于TCN、BiLSTM和Transformer等基线模型。

Conclusion: FERA展示了在击剑比赛中实现自动化裁判辅助的潜力，并为AI在击剑领域的应用（如指导）开辟了新的机会。

Abstract: The sport of fencing, like many other sports, faces challenges in refereeing:
subjective calls, human errors, bias, and limited availability in practice
environments. We present FERA (Fencing Referee Assistant), a prototype AI
referee for foil fencing which integrates pose-based multi-label action
recognition and rule-based reasoning. FERA extracts 2D joint positions from
video, normalizes them, computes a 101-dimensional kinematic feature set, and
applies a Transformer for multi-label move and blade classification. To
determine priority and scoring, FERA applies a distilled language model with
encoded right-of-way rules, producing both a decision and an explanation for
each exchange. With limited hand-labeled data, a 5-fold cross-validation
achieves an average macro-F1 score of 0.549, outperforming multiple baselines,
including a Temporal Convolutional Network (TCN), BiLSTM, and a vanilla
Transformer. While not ready for deployment, these results demonstrate a
promising path towards automated referee assistance in foil fencing and new
opportunities for AI applications, such as coaching in the field of fencing.

</details>


### [394] [LLMZ+: Contextual Prompt Whitelist Principles for Agentic LLMs](https://arxiv.org/abs/2509.18557)
*Tom Pawelek,Raj Patel,Charlotte Crowell,Noorbakhsh Amiri,Sudip Mittal,Shahram Rahimi,Andy Perkins*

Main category: cs.AI

TL;DR: Agentic AI's privileged access and nondeterministic behavior pose significant security risks. LLMZ+ offers an alternative defense by using prompt whitelisting to ensure only safe and contextually appropriate messages interact with the LLM, thereby preventing jailbreak attacks without disrupting legitimate communications.


<details>
  <summary>Details</summary>
Motivation: Traditional defense mechanisms for agentic AI focus on detecting malicious intent, but the unique characteristics of agentic LLMs (privileged access, reliance on nondeterministic behavior) introduce substantial security risks that these methods may not fully address. Thus, an alternative approach is needed.

Method: LLMZ+ implements a prompt whitelisting strategy. This approach allows only messages that are contextually appropriate and safe to interact with the agentic LLM, ensuring that all communications adhere to predefined use cases and operational boundaries.

Result: LLMZ+ demonstrates strong resilience against common jailbreak prompts, with no disruption to legitimate business communications. The effectiveness was measured by false positive and false negative rates, which were reduced to 0 in the experimental setting.

Conclusion: LLMZ+ provides a more streamlined, resilient, and resource-efficient security framework for agentic LLMs by employing prompt whitelisting, which effectively mitigates jailbreak risks while preserving normal operations.

Abstract: Compared to traditional models, agentic AI represents a highly valuable
target for potential attackers as they possess privileged access to data
sources and API tools, which are traditionally not incorporated into classical
agents. Unlike a typical software application residing in a Demilitarized Zone
(DMZ), agentic LLMs consciously rely on nondeterministic behavior of the AI
(only defining a final goal, leaving the path selection to LLM). This
characteristic introduces substantial security risk to both operational
security and information security. Most common existing defense mechanism rely
on detection of malicious intent and preventing it from reaching the LLM agent,
thus protecting against jailbreak attacks such as prompt injection. In this
paper, we present an alternative approach, LLMZ+, which moves beyond
traditional detection-based approaches by implementing prompt whitelisting.
Through this method, only contextually appropriate and safe messages are
permitted to interact with the agentic LLM. By leveraging the specificity of
context, LLMZ+ guarantees that all exchanges between external users and the LLM
conform to predefined use cases and operational boundaries. Our approach
streamlines the security framework, enhances its long-term resilience, and
reduces the resources required for sustaining LLM information security. Our
empirical evaluation demonstrates that LLMZ+ provides strong resilience against
the most common jailbreak prompts. At the same time, legitimate business
communications are not disrupted, and authorized traffic flows seamlessly
between users and the agentic LLM. We measure the effectiveness of approach
using false positive and false negative rates, both of which can be reduced to
0 in our experimental setting.

</details>


### [395] [Solving Math Word Problems Using Estimation Verification and Equation Generation](https://arxiv.org/abs/2509.18565)
*Mitchell Piehl,Dillon Wilson,Ananya Kalita,Jugal Kalita*

Main category: cs.AI

TL;DR: LLM 通过生成方程并使用外部求解器来解决数学应用题，并通过估算来验证答案，实现了最先进的结果。


<details>
  <summary>Details</summary>
Motivation: LLM 在解决数学应用题方面存在困难，需要改进的提示方法。

Method: 首先提示 LLM 从问题分解中创建方程，然后使用外部符号方程求解器得到答案。然后，LLM 会第二次解决该问题以估算正确答案，并将其与生成答案进行比较。如果验证失败，则采用迭代校正过程。

Result: 在数值和代数 MWP 数据集上取得了新的最先进成果，平均提高了近 2%。在三角函数 MWP 上取得了令人满意的结果。引入了 SVAMPClean 和 Trig300 两个新数据集。

Conclusion: 所提出的方法在解决数学应用题方面取得了最先进的成果，并为该领域做出了贡献。

Abstract: Large Language Models (LLMs) excel at various tasks, including
problem-solving and question-answering. However, LLMs often find Math Word
Problems (MWPs) challenging because solving them requires a range of reasoning
and mathematical abilities with which LLMs seem to struggle. Recent efforts
have helped LLMs solve more complex MWPs with improved prompts. This study
proposes a novel method that initially prompts an LLM to create equations from
a decomposition of the question, followed by using an external symbolic
equation solver to produce an answer. To ensure the accuracy of the obtained
answer, inspired by an established recommendation of math teachers, the LLM is
instructed to solve the MWP a second time, but this time with the objective of
estimating the correct answer instead of solving it exactly. The estimation is
then compared to the generated answer to verify. If verification fails, an
iterative rectification process is employed to ensure the correct answer is
eventually found. This approach achieves new state-of-the-art results on
datasets used by prior published research on numeric and algebraic MWPs,
improving the previous best results by nearly two percent on average. In
addition, the approach obtains satisfactory results on trigonometric MWPs, a
task not previously attempted to the authors' best knowledge. This study also
introduces two new datasets, SVAMPClean and Trig300, to further advance the
testing of LLMs' reasoning abilities.

</details>


### [396] [Adaptive Learning in Spatial Agent-Based Models for Climate Risk Assessment: A Geospatial Framework with Evolutionary Economic Agents](https://arxiv.org/abs/2509.18633)
*Yara Mohajerani*

Main category: cs.AI

TL;DR: 该研究提出了一个结合了地理空间、基于代理的模型和进化学习的框架，用于评估气候风险对经济系统的影响。


<details>
  <summary>Details</summary>
Motivation: 为了模拟气候风险评估中复杂的空间异质性危害与适应性经济系统之间的相互作用。

Method: 利用 Mesa 框架进行空间建模，结合 CLIMADA 气候影响评估，并引入基于适应性学习和进化选择的经济代理行为，以模拟预算分配、定价、工资和风险适应策略的演变。

Result: 在 RCP8.5 河流洪水情景下，模型显示进化适应使企业能在数十年后恢复到基线生产水平。但研究也揭示了系统性风险，由于供应链中断，即使是未直接暴露于洪水的代理，其商品平均价格也比基线高出 5.6%。

Conclusion: 该研究提出的开源框架能够量化直接和间接的气候风险，并评估具有成本效益的适应策略，为金融机构和企业提供决策支持。

Abstract: Climate risk assessment requires modelling complex interactions between
spatially heterogeneous hazards and adaptive economic systems. We present a
novel geospatial agent-based model that integrates climate hazard data with
evolutionary learning for economic agents. Our framework combines Mesa-based
spatial modelling with CLIMADA climate impact assessment, introducing adaptive
learning behaviours that allow firms to evolve strategies for budget
allocation, pricing, wages, and risk adaptation through fitness-based selection
and mutation. We demonstrate the framework using riverine flood projections
under RCP8.5 until 2100, showing that evolutionary adaptation enables firms to
converge with baseline (no hazard) production levels after decades of
disruption due to climate stress. Our results reveal systemic risks where even
agents that are not directly exposed to floods face impacts through supply
chain disruptions, with the end-of-century average price of goods 5.6% higher
under RCP8.5 compared to the baseline. This open-source framework provides
financial institutions and companies with tools to quantify both direct and
cascading climate risks while evaluating cost-effective adaptation strategies.

</details>


### [397] [TERAG: Token-Efficient Graph-Based Retrieval-Augmented Generation](https://arxiv.org/abs/2509.18667)
*Qiao Xiao,Hong Ting Tsang,Jiaxin Bai*

Main category: cs.AI

TL;DR: TERAG是一个低成本的图构建框架，通过结合个性化PageRank（PPR）和检索，在保证高准确率的同时显著降低了LLM的token消耗。


<details>
  <summary>Details</summary>
Motivation: 现有的图基检索增强生成（RAG）方法在图构建过程中LLM的token消耗成本高，限制了其大规模应用。TERAG旨在以更低的成本构建信息丰富的图。

Method: TERAG框架结合了HippoRAG的思路，在检索阶段引入个性化PageRank（PPR），从而在构建图的过程中降低token消耗。

Result: TERAG能够达到现有图基RAG方法的80%以上的准确率，同时仅消耗3%-11%的输出token。

Conclusion: TERAG是一个在成本效益方面优于现有方法的图基RAG框架，能够有效解决高token消耗的问题。

Abstract: Graph-based Retrieval-augmented generation (RAG) has become a widely studied
approach for improving the reasoning, accuracy, and factuality of Large
Language Models. However, many existing graph-based RAG systems overlook the
high cost associated with LLM token usage during graph construction, hindering
large-scale adoption. To address this, we propose TERAG, a simple yet effective
framework designed to build informative graphs at a significantly lower cost.
Inspired by HippoRAG, we incorporate Personalized PageRank (PPR) during the
retrieval phase, and we achieve at least 80% of the accuracy of widely used
graph-based RAG methods while consuming only 3%-11% of the output tokens.

</details>


### [398] [Implementation of airborne ML models with semantics preservation](https://arxiv.org/abs/2509.18681)
*Nicolas Valot,Louis Fabre,Benjamin Lesage,Ammar Mechouche,Claire Pagetti*

Main category: cs.AI

TL;DR: The paper clarifies the difference between ML models and MLMDs and refines semantics preservation to ensure accurate model replication, applying it to industrial use cases.


<details>
  <summary>Details</summary>
Motivation: The need to guarantee the safe operation of ML-based airborne systems and demonstrate compliance with safety regulations (EASA, ED-324).

Method: Differentiating between ML models and MLMDs, and refining the concept of semantics preservation for accurate model replication.

Result: Demonstration of the contributions applied to industrial use cases, involving the building and comparison of several target models.

Conclusion: The paper's contributions provide a clearer understanding and methodology for ensuring the safety and reliability of ML models in airborne systems.

Abstract: Machine Learning (ML) may offer new capabilities in airborne systems.
However, as any piece of airborne systems, ML-based systems will be required to
guarantee their safe operation. Thus, their development will have to be
demonstrated to be compliant with the adequate guidance. So far, the European
Union Aviation Safety Agency (EASA) has published a concept paper and an
EUROCAE/SAE group is preparing ED-324. Both approaches delineate high-level
objectives to confirm the ML model achieves its intended function and maintains
training performance in the target environment. The paper aims to clarify the
difference between an ML model and its corresponding unambiguous description,
referred to as the Machine Learning Model Description (MLMD). It then refines
the essential notion of semantics preservation to ensure the accurate
replication of the model. We apply our contributions to several industrial use
cases to build and compare several target models.

</details>


### [399] [Advances in Large Language Models for Medicine](https://arxiv.org/abs/2509.18690)
*Zhiyu Kan,Wensheng Gan,Zhenlian Qi,Philip S. Yu*

Main category: cs.AI

TL;DR: AI技术，特别是大型语言模型（LLM），在医疗领域取得了显著进展，本综述对LLM在医疗中的研究进展、训练技术、应用、优缺点、分类及未来方向进行了系统性分析。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLM）在医疗领域的广泛应用和重要性日益凸显，需要对相关研究进展进行系统性回顾和分析。

Method: 对大型语言模型在医疗领域的最新研究进展进行系统性回顾，包括训练技术、在医疗环境中的适应性、相关应用、优缺点。对医疗LLM进行分类（基于训练方法的三种类型和两种评估方法）。提出挑战的解决方案并概述未来研究方向。

Result: 对LLM在医疗领域的训练技术、应用、优缺点进行了分析，并创新性地将医疗LLM分为三类（基于训练方法）和两种评估方法。指出了现有挑战并提出了解决方案和未来研究方向。

Conclusion: 本研究系统性地回顾了LLM在医疗领域的最新研究，强调了发展医疗LLM的必要性，加深了对其发展现状的理解，并为后续研究提供了明确指导。

Abstract: Artificial intelligence (AI) technology has advanced rapidly in recent years,
with large language models (LLMs) emerging as a significant breakthrough. LLMs
are increasingly making an impact across various industries, with the medical
field standing out as the most prominent application area. This paper
systematically reviews the up-to-date research progress of LLMs in the medical
field, providing an in-depth analysis of training techniques for large medical
models, their adaptation in healthcare settings, related applications, as well
as their strengths and limitations. Furthermore, it innovatively categorizes
medical LLMs into three distinct types based on their training methodologies
and classifies their evaluation approaches into two categories. Finally, the
study proposes solutions to existing challenges and outlines future research
directions based on identified issues in the field of medical LLMs. By
systematically reviewing previous and advanced research findings, we aim to
highlight the necessity of developing medical LLMs, provide a deeper
understanding of their current state of development, and offer clear guidance
for subsequent research.

</details>


### [400] [Autonomous Data Agents: A New Opportunity for Smart Data](https://arxiv.org/abs/2509.18710)
*Yanjie Fu,Dongjie Wang,Wangyang Ying,Xiangliang Zhang,Huan Liu,Jian Pei*

Main category: cs.AI

TL;DR: 自主数据代理（DataAgents）通过集成LLM推理和任务分解、动作推理与接地、工具调用，能够自主解释数据任务描述，将其分解为子任务，并执行相应操作，将复杂、非结构化数据转化为连贯、可操作的知识，代表了数据到知识系统的范式转变。


<details>
  <summary>Details</summary>
Motivation: 随着数据规模和复杂性的增长，数据准备、转换和分析过程变得劳动密集、重复且难以扩展。数据与AI的对齐至关重要，但数据往往未针对AI利用进行优化。本研究旨在探索如何通过集约化数据操作在数据中封装更多知识。

Method: 本研究提出了自主数据代理（DataAgents）的概念，该代理集成了LLM推理、任务分解、动作推理与接地以及工具调用。DataAgents能够自主解释数据任务描述，将任务分解为子任务，进行动作推理，将动作接地为Python代码或工具调用，并执行操作。它们能够动态规划工作流，调用强大工具，并适应各种规模的数据任务。

Result: DataAgents能够处理数据的收集、集成、预处理、选择、转换、重新加权、增强、重编程、修复和检索。通过这些能力，DataAgents将复杂、非结构化的数据转化为连贯、可操作的知识。

Conclusion: DataAgents代表了迈向自主数据到知识系统的范式转变。研究者呼吁共同努力，以优化动作工作流，建立开放数据集和基准生态系统，保护隐私，平衡效率与可扩展性，并开发可信赖的DataAgents护栏以防止恶意行为。

Abstract: As data continues to grow in scale and complexity, preparing, transforming,
and analyzing it remains labor-intensive, repetitive, and difficult to scale.
Since data contains knowledge and AI learns knowledge from it, the alignment
between AI and data is essential. However, data is often not structured in ways
that are optimal for AI utilization. Moreover, an important question arises:
how much knowledge can we pack into data through intensive data operations?
Autonomous data agents (DataAgents), which integrate LLM reasoning with task
decomposition, action reasoning and grounding, and tool calling, can
autonomously interpret data task descriptions, decompose tasks into subtasks,
reason over actions, ground actions into python code or tool calling, and
execute operations. Unlike traditional data management and engineering tools,
DataAgents dynamically plan workflows, call powerful tools, and adapt to
diverse data tasks at scale. This report argues that DataAgents represent a
paradigm shift toward autonomous data-to-knowledge systems. DataAgents are
capable of handling collection, integration, preprocessing, selection,
transformation, reweighing, augmentation, reprogramming, repairs, and
retrieval. Through these capabilities, DataAgents transform complex and
unstructured data into coherent and actionable knowledge. We first examine why
the convergence of agentic AI and data-to-knowledge systems has emerged as a
critical trend. We then define the concept of DataAgents and discuss their
architectural design, training strategies, as well as the new skills and
capabilities they enable. Finally, we call for concerted efforts to advance
action workflow optimization, establish open datasets and benchmark ecosystems,
safeguard privacy, balance efficiency with scalability, and develop trustworthy
DataAgent guardrails to prevent malicious actions.

</details>


### [401] [Experience Scaling: Post-Deployment Evolution For Large Language Models](https://arxiv.org/abs/2509.18771)
*Xingkun Yin,Kaibin Huang,Dong In Kim,Hongyang Du*

Main category: cs.AI

TL;DR: 通过持续的与环境交互和经验共享来扩展LLM能力，以克服静态数据的限制。


<details>
  <summary>Details</summary>
Motivation: 现有的LLM扩展方法（如增加模型大小、训练数据和计算能力）正面临瓶颈，因为人类生成文本已趋于枯竭，且收益递减。

Method: 提出了一种名为“经验扩展”的框架，通过自主与环境交互和共享经验来实现LLM的持续后部署演进。该框架能够捕获原始交互、将其提炼成紧凑的、可重用的知识，并定期优化存储的内容以保持相关性和效率。

Result: 在模拟的现实世界场景中，包括泛化到以前未见过但相关的任务、重复查询和过饱和知识库，经验扩展提高了准确性，随着时间的推移维持了性能，并在应用于新情况时保持了收益。

Conclusion: 结构化的后部署学习可以扩展LLM的能力，超越静态人类生成数据的限制，为持续的智能进步提供了一条可扩展的路径。

Abstract: Scaling model size, training data, and compute power have driven advances in
large language models (LLMs), but these approaches are reaching saturation as
human-generated text is exhausted and further gains diminish. We propose
experience scaling, a framework for continuous post-deployment evolution for
LLMs through autonomous interaction with the environment and collaborative
sharing of accumulated experience. The framework captures raw interactions,
distills them into compact, reusable knowledge, and periodically refines stored
content to preserve relevance and efficiency. We validate the framework in
simulated real-world scenarios involving generalization to previously unseen
but related tasks, repetitive queries, and over-saturated knowledge stores.
Across all settings, experience scaling improves accuracy, sustains performance
over time, and maintains gains when applied to novel situations. These results
demonstrate that structured post-deployment learning can extend LLM
capabilities beyond the limits of static human-generated data, offering a
scalable path for continued intelligence progress.

</details>


### [402] [The AGNTCY Agent Directory Service: Architecture and Implementation](https://arxiv.org/abs/2509.18787)
*Luca Muscariello,Vijoy Pandey,Ramiz Polic*

Main category: cs.AI

TL;DR: ADS是一个分布式AI代理发现服务，利用内容寻址存储、分层分类法和加密签名，实现跨异构多代理系统的多维度发现。它基于OASF构建，通过Kademlia DHT实现的两级映射来解耦能力索引和内容位置，并重用了OCI/ORAS基础设施进行 artifact 分发，集成了Sigstore进行溯源，支持面向LLM提示代理、MCP服务器和A2A组件等新兴代理模式的模式驱动扩展。


<details>
  <summary>Details</summary>
Motivation: 为AI代理提供一个高效、可验证、多维度的发现服务，以应对异构多代理系统中代理能力的索引和发现挑战。

Method: ADS基于OASF构建，利用内容寻址存储、分层分类法和加密签名。通过Kademlia DHT实现的两级映射来解耦能力索引和内容位置。重用OCI/ORAS进行artifact分发，集成Sigstore进行溯源，并支持模式驱动的扩展。

Result: ADS能够实现高效、可验证、多维度的代理能力、元数据和溯源的发现，并支持对新兴代理模式的扩展。

Conclusion: ADS为AI代理的注册和互操作性提供了一个强大的基础架构，能够适应不断发展的代理技术。

Abstract: The Agent Directory Service (ADS) is a distributed directory for the
discovery of AI agent capabilities, metadata, and provenance. It leverages
content-addressed storage, hierarchical taxonomies, and cryptographic signing
to enable efficient, verifiable, and multi-dimensional discovery across
heterogeneous Multi-Agent Systems (MAS). Built on the Open Agentic Schema
Framework (OASF), ADS decouples capability indexing from content location
through a two-level mapping realized over a Kademlia-based Distributed Hash
Table (DHT). It reuses mature OCI / ORAS infrastructure for artifact
distribution, integrates Sigstore for provenance, and supports schema-driven
extensibility for emerging agent modalities (LLM prompt agents, MCP servers,
A2A-enabled components). This paper formalizes the architectural model,
describes storage and discovery layers, explains security and performance
properties, and positions ADS within the broader landscape of emerging agent
registry and interoperability initiatives.

</details>


### [403] [Bounded PCTL Model Checking of Large Language Model Outputs](https://arxiv.org/abs/2509.18836)
*Dennis Gross,Helge Spieker,Arnaud Gotlieb*

Main category: cs.AI

TL;DR: LLMCHECKER通过基于模型检查的方法验证LLM文本生成的PCTL属性，通过关注累积概率最高的k个标记来提高效率和准确性。


<details>
  <summary>Details</summary>
Motivation: LLM文本生成过程中，文本质量和偏见等因素的量化对生成过程的验证提出了挑战。传统的验证方法难以处理LLM的概率性和复杂性。

Method: 提出了一种名为LLMCHECKER的基于模型检查的验证方法，用于验证LLM文本生成过程的概率计算树逻辑（PCTL）属性。该方法通过引入$\\alpha$-$k$-有界文本生成策略，将验证过程聚焦于每一步生成过程中累积概率最高的k个标记，并根据阈值$\\alpha$进一步筛选。

Result: 实验表明，LLMCHECKER能够有效地验证Llama、Gemma、Mistral、Genstruct和BERT等多种LLM的PCTL属性，证明了该方法的通用性和有效性。

Conclusion: LLMCHECKER是首次将PCTL模型检查应用于LLM文本生成过程一致性验证的尝试，为LLM的可靠性和安全性提供了新的验证途径。

Abstract: In this paper, we introduce LLMCHECKER, a model-checking-based verification
method to verify the probabilistic computation tree logic (PCTL) properties of
an LLM text generation process. We empirically show that only a limited number
of tokens are typically chosen during text generation, which are not always the
same. This insight drives the creation of $\alpha$-$k$-bounded text generation,
narrowing the focus to the $\alpha$ maximal cumulative probability on the
top-$k$ tokens at every step of the text generation process. Our verification
method considers an initial string and the subsequent top-$k$ tokens while
accommodating diverse text quantification methods, such as evaluating text
quality and biases. The threshold $\alpha$ further reduces the selected tokens,
only choosing those that exceed or meet it in cumulative probability.
LLMCHECKER then allows us to formally verify the PCTL properties of
$\alpha$-$k$-bounded LLMs. We demonstrate the applicability of our method in
several LLMs, including Llama, Gemma, Mistral, Genstruct, and BERT. To our
knowledge, this is the first time PCTL-based model checking has been used to
check the consistency of the LLM text generation process.

</details>


### [404] [Model selection meets clinical semantics: Optimizing ICD-10-CM prediction via LLM-as-Judge evaluation, redundancy-aware sampling, and section-aware fine-tuning](https://arxiv.org/abs/2509.18846)
*Hong-Jie Dai,Zheng-Hao Li,An-Tai Lu,Bo-Tsz Shain,Ming-Ta Li,Tatheer Hussain Mir,Kuang-Te Wang,Min-I Su,Pei-Kang Liu,Ming-Ju Tsai*

Main category: cs.AI

TL;DR: 使用模块化框架和LLM-as-judge评估协议，改进ICD-10-CM编码预测的准确性，解决模型选择、输入上下文和数据冗余的挑战。


<details>
  <summary>Details</summary>
Motivation: 目前的ICD编码任务劳动密集且易出错，尽管LLM有潜力实现自动化，但存在模型选择、输入上下文和数据冗余等挑战。

Method: 提出一个模块化框架，通过合理的模型选择、冗余感知数据采样和结构化输入设计来解决LLM在ICD-10-CM编码预测中的挑战。框架整合了LLM-as-judge评估协议和Plackett-Luce聚合，以评估和排名开源LLM。引入基于嵌入的相似性度量和冗余感知采样策略来去除语义重复的出院小结。利用台湾医院的结构化出院小结来评估上下文效应，并在通用和特定部分的建模范式下检查各部分的包含情况。

Result: 在两个机构数据集上的实验表明，所选的基础模型在经过微调后，在内部和外部评估中始终优于基线LLM。增加临床部分能持续提高预测性能。

Conclusion: 该研究使用开源LLM，建立了一种实用且有原则的ICD-10-CM编码预测方法。所提出的框架通过结合明智的模型选择、高效的数据精炼和上下文感知的提示，为自动化医疗编码系统在现实世界中的部署提供了一个可扩展的、适合机构的解决方案。

Abstract: Accurate International Classification of Diseases (ICD) coding is critical
for clinical documentation, billing, and healthcare analytics, yet it remains a
labour-intensive and error-prone task. Although large language models (LLMs)
show promise in automating ICD coding, their challenges in base model
selection, input contextualization, and training data redundancy limit their
effectiveness. We propose a modular framework for ICD-10 Clinical Modification
(ICD-10-CM) code prediction that addresses these challenges through principled
model selection, redundancy-aware data sampling, and structured input design.
The framework integrates an LLM-as-judge evaluation protocol with Plackett-Luce
aggregation to assess and rank open-source LLMs based on their intrinsic
comprehension of ICD-10-CM code definitions. We introduced embedding-based
similarity measures, a redundancy-aware sampling strategy to remove
semantically duplicated discharge summaries. We leverage structured discharge
summaries from Taiwanese hospitals to evaluate contextual effects and examine
section-wise content inclusion under universal and section-specific modelling
paradigms. Experiments across two institutional datasets demonstrate that the
selected base model after fine-tuning consistently outperforms baseline LLMs in
internal and external evaluations. Incorporating more clinical sections
consistently improves prediction performance. This study uses open-source LLMs
to establish a practical and principled approach to ICD-10-CM code prediction.
The proposed framework provides a scalable, institution-ready solution for
real-world deployment of automated medical coding systems by combining informed
model selection, efficient data refinement, and context-aware prompting.

</details>


### [405] [MAPO: Mixed Advantage Policy Optimization](https://arxiv.org/abs/2509.18849)
*Wenke Huang,Quan Zhang,Yiyang Fang,Jian Liang,Xuankun Rong,Huanjin Yao,Guancheng Wan,Ke Liang,Wenwen He,Mingjun Li,Leszek Rutkowski,Mang Ye,Bo Du,Dacheng Tao*

Main category: cs.AI

TL;DR: GRPO在基础模型推理任务中表现出色，但其优势函数存在优势反转和优势镜像问题。本文提出的MAPO策略通过引入优势百分比偏差和动态重加权来解决这些问题，并已通过实验验证。


<details>
  <summary>Details</summary>
Motivation: GRPO在基础模型推理任务中表现出色，但其优势函数在处理不同查询样本时存在优势反转和优势镜像问题，阻碍了合理的优势分配。因此，需要一种新的策略来解决这些问题。

Method: 提出了一种名为MAPO（Mixed Advantage Policy Optimization）的策略，通过引入优势百分比偏差来处理高确定性轨迹样本，并动态重加权不同轨迹确定性样本的优势函数，从而自适应地考虑样本特性。

Result: MAPO策略通过动态调整优势函数，有效解决了GRPO的优势反转和优势镜像问题，并已通过与现有先进方法进行比较和消融研究进行了验证。

Conclusion: MAPO是一种简单而有效的GRPO策略，通过解决优势函数中的问题，提高了基础模型在推理任务上的性能。

Abstract: Recent advances in reinforcement learning for foundation models, such as
Group Relative Policy Optimization (GRPO), have significantly improved the
performance of foundation models on reasoning tasks. Notably, the advantage
function serves as a central mechanism in GRPO for ranking the trajectory
importance. However, existing explorations encounter both advantage reversion
and advantage mirror problems, which hinder the reasonable advantage allocation
across different query samples. In this work, we propose an easy but effective
GRPO strategy, Mixed Advantage Policy Optimization (MAPO). We reveal that the
trajectory appears with different certainty and propose the advantage percent
deviation for samples with high-certainty trajectories. Furthermore, we
dynamically reweight the advantage function for samples with varying trajectory
certainty, thereby adaptively configuring the advantage function to account for
sample-specific characteristics. Comparison with related state-of-the-art
methods, along with ablation studies on different advantage variants, validates
the effectiveness of our approach.

</details>


### [406] [Conf-Profile: A Confidence-Driven Reasoning Paradigm for Label-Free User Profiling](https://arxiv.org/abs/2509.18864)
*Yingxin Li,Jianbo Zhao,Xueyu Ren,Jie Tang,Wangjie You,Xu Chen,Kan Zhou,Chao Feng,Jiao Ran,Yuan Meng,Zhi Wang*

Main category: cs.AI

TL;DR: 为了解决用户画像技术中缺乏综合基准和标签稀疏的问题，本文提出了ProfileBench基准和Conf-Profile框架。Conf-Profile采用两阶段范式，首先利用带有置信度提示的LLM合成高质量标签，然后通过置信度加权投票和校准来提高准确性和平衡分布。该框架还能通过置信度引导的无监督强化学习进一步增强推理能力，并在Qwen3-8B模型上取得了13.97%的F1提升。


<details>
  <summary>Details</summary>
Motivation: 当前用户画像技术缺乏综合基准，且存在标签稀疏、用户数据异构且噪声大等问题，影响了LLM在用户画像任务上的表现。

Method: 提出ProfileBench基准，并设计了Conf-Profile框架，该框架包含两阶段范式：1. 利用LLM和置信度提示合成高质量标签，并进行置信度加权投票和校准。2. 通过置信度引导的无监督强化学习增强推理能力，包括利用置信度进行难度过滤、准标签投票和奖励加权。

Result: Conf-Profile框架通过两阶段训练，在Qwen3-8B模型上将F1分数提高了13.97%，证明了其有效性。

Conclusion: Conf-Profile框架能够有效解决用户画像中的标签稀疏和数据异构噪声问题，通过置信度学习和强化学习显著提升了用户画像的准确性和可靠性。

Abstract: User profiling, as a core technique for user understanding, aims to infer
structural attributes from user information. Large Language Models (LLMs)
provide a promising avenue for user profiling, yet the progress is hindered by
the lack of comprehensive benchmarks. To bridge this gap, we propose
ProfileBench, an industrial benchmark derived from a real-world video platform,
encompassing heterogeneous user data and a well-structured profiling taxonomy.
However, the profiling task remains challenging due to the difficulty of
collecting large-scale ground-truth labels, and the heterogeneous and noisy
user information can compromise the reliability of LLMs. To approach label-free
and reliable user profiling, we propose a Confidence-driven Profile reasoning
framework Conf-Profile, featuring a two-stage paradigm. We first synthesize
high-quality labels by leveraging advanced LLMs with confidence hints, followed
by confidence-weighted voting for accuracy improvement and confidence
calibration for a balanced distribution. The multiple profile results,
rationales, and confidence scores are aggregated and distilled into a
lightweight LLM. We further enhance the reasoning ability via confidence-guided
unsupervised reinforcement learning, which exploits confidence for difficulty
filtering, quasi-ground truth voting, and reward weighting. Experimental
results demonstrate that Conf-Profile delivers substantial performance through
the two-stage training, improving F1 by 13.97 on Qwen3-8B.

</details>


### [407] [Memory in Large Language Models: Mechanisms, Evaluation and Evolution](https://arxiv.org/abs/2509.18868)
*Dianxing Zhang,Wendong Li,Kani Song,Jiaye Lu,Gang Li,Liuchun Yang,Sheng Li*

Main category: cs.AI

TL;DR: LLM记忆被定义为一种持久状态，并提出了一个四部分分类法（参数、上下文、外部、程序/情景）和一个记忆四元组（位置、持久性、读写路径、可控性）。该框架通过“写入->读取->抑制/更新”链连接机制、评估和治理。为了避免异构设置中的失真比较，采用了三设置协议（仅参数、离线检索、在线检索）。在此基础上，构建了分层评估：参数（封闭式回忆、编辑差异、记忆/隐私）、上下文（位置曲线和中间序列下降）、外部（答案正确性与片段归属/忠实度）以及程序/情景（跨会话一致性和时间线回放，E MARS+）。该框架整合了时间治理和泄露审计（新鲜度命中、过时答案、拒绝切片）以及通过评分者间一致性加配对测试（带有多次比较校正）的不确定性报告。为了更新和遗忘，提出了 DMM Gov：协调 DAPT/TAPT、PEFT、模型编辑（ROME、MEND、MEMIT、SERAC）和 RAG，形成一个可审计的循环，涵盖准入阈值、推出、监控、回滚和变更审计，并对及时性、冲突处理和长期一致性进行了规定。最后，提出了四个可检验的命题：最小可识别性；最小评估卡；因果约束编辑与可验证遗忘；以及检索与小窗口回放何时优于超长上下文阅读。这为研究和部署提供了一个可重现、可比较和可治理的坐标系。


<details>
  <summary>Details</summary>
Motivation: 定义和评估大型语言模型（LLM）的记忆能力，并提出一个治理框架，以实现可重现、可比较和可治理的研究和部署。

Method: 提出一个统一的 LLM 记忆定义，一个四部分分类法和一个记忆四元组。采用三设置协议和分层评估方法（参数、上下文、外部、程序/情景）。提出 DMM Gov 框架用于更新和遗忘，整合了多种技术。提出四个可检验的命题。

Result: 构建了一个 LLM 记忆评估和治理框架，包括 DMM Gov，并提出了四个可检验的命题，旨在实现可重现、可比较和可治理的研究和部署。

Conclusion: 所提出的 LLM 记忆定义、评估框架和治理机制为 LLM 记忆的研究和部署提供了一个系统化的方法，能够实现可重现、可比较和可治理的评估与记忆相关的能力。

Abstract: Under a unified operational definition, we define LLM memory as a persistent
state written during pretraining, finetuning, or inference that can later be
addressed and that stably influences outputs. We propose a four-part taxonomy
(parametric, contextual, external, procedural/episodic) and a memory quadruple
(location, persistence, write/access path, controllability). We link mechanism,
evaluation, and governance via the chain write -> read -> inhibit/update. To
avoid distorted comparisons across heterogeneous setups, we adopt a
three-setting protocol (parametric only, offline retrieval, online retrieval)
that decouples capability from information availability on the same data and
timeline. On this basis we build a layered evaluation: parametric (closed-book
recall, edit differential, memorization/privacy), contextual (position curves
and the mid-sequence drop), external (answer correctness vs snippet
attribution/faithfulness), and procedural/episodic (cross-session consistency
and timeline replay, E MARS+). The framework integrates temporal governance and
leakage auditing (freshness hits, outdated answers, refusal slices) and
uncertainty reporting via inter-rater agreement plus paired tests with
multiple-comparison correction. For updating and forgetting, we present DMM
Gov: coordinating DAPT/TAPT, PEFT, model editing (ROME, MEND, MEMIT, SERAC),
and RAG to form an auditable loop covering admission thresholds, rollout,
monitoring, rollback, and change audits, with specs for timeliness, conflict
handling, and long-horizon consistency. Finally, we give four testable
propositions: minimum identifiability; a minimal evaluation card; causally
constrained editing with verifiable forgetting; and when retrieval with
small-window replay outperforms ultra-long-context reading. This yields a
reproducible, comparable, and governable coordinate system for research and
deployment.

</details>


### [408] [LongCat-Flash-Thinking Technical Report](https://arxiv.org/abs/2509.18883)
*Meituan LongCat Team,Anchun Gui,Bei Li,Bingyang Tao,Bole Zhou,Borun Chen,Chao Zhang,Chao Zhang,Chengcheng Han,Chenhui Yang,Chi Zhang,Chong Peng,Chuyu Zhang,Cong Chen,Fengcun Li,Gang Xu,Guoyuan Lin,Hao Jiang,Hao Liang,Haomin Fu,Haoxiang Ma,Hong Liu,Hongyan Hao,Hongyin Tang,Hongyu Zang,Hongzhi Ni,Hui Su,Jiahao Liu,Jiahuan Li,Jialin Liu,Jianfei Zhang,Jianhao Xu,Jianing Wang,Jiaqi Sun,Jiaqi Zhang,Jiarong Shi,Jiawei Yang,Jingang Wang,Jinrui Ding,Jun Kuang,Jun Xu,Ke He,Kefeng Zhang,Keheng Wang,Keqing He,Li Wei,Liang Shi,Lin Qiu,Lingbin Kong,Lingchuan Liu,Linsen Guo,Longfei An,Mai Xia,Meng Zhou,Mengshen Zhu,Peng Pei,Pengcheng Jia,Qi Gu,Qi Guo,Qiong Huang,Quan Chen,Quanchi Weng,Rongxiang Weng,Ruichen Shao,Rumei Li,Shanglin Lei,Shuai Du,Shuaikang Liu,Shuang Zhou,Shuhao Hu,Siyu Xu,Songshan Gong,Tao Liang,Tianhao Hu,Wei He,Wei Shi,Wei Wang,Wei Wu,Wei Zhuo,Weifeng Tang,Wenjie Shi,Wenlong Zhu,Xi Su,Xiangcheng Liu,Xiangyu Xi,Xiangzhou Huang,Xiao Liu,Xiaochen Jiang,Xiaowei Shi,Xiaowen Shi,Xiaoyu Li,Xin Chen,Xinyue Zhao,Xuan Huang,Xuemiao Zhang,Xuezhi Cao,Xunliang Cai,Yajie Zhang,Yang Chen,Yang Liu,Yang Liu,Yang Zheng,Yaoming Wang,Yaqi Huo,Yerui Sun,Yifan Lu,Yiyang Li,Youshao Xiao,Yuanzhe Lei,Yuchen Xie,Yueqing Sun,Yufei Zhang,Yuhuai Wei,Yulei Qian,Yunke Zhao,Yuqing Ding,Yuwei Jiang,Zhaohua Yang,Zhengyu Chen,Zhijian Liu,Zhikang Xia,Zhongda Su,Ziran Li,Ziwen Wang,Ziyuan Zhuang,Zongyu Wang,Zunyuan Yang*

Main category: cs.AI

TL;DR: LongCat-Flash-Thinking是一个高效的5600亿参数开源MoE推理模型，通过长CoT数据冷启动和大规模RL训练，在复杂推理任务上达到SOTA。


<details>
  <summary>Details</summary>
Motivation: 为了开发一个高效的大规模MoE推理模型，并提升其在形式化和agentic推理方面的能力。

Method: 采用长CoT数据冷启动，结合领域并行训练方案，并通过DORA系统进行大规模RL训练，实现异步训练加速。

Result: 在AIME-25等推理任务上取得SOTA性能，并显著降低了agentic推理的token消耗（平均减少64.5%），同时保持了任务准确性。

Conclusion: LongCat-Flash-Thinking是一个高效且性能优越的开源推理模型，其训练方法和系统具有普适性，旨在推动推理系统和agentic AI的研究。

Abstract: We present LongCat-Flash-Thinking, an efficient 560-billion-parameter
open-source Mixture-of-Experts (MoE) reasoning model. Its advanced capabilities
are cultivated through a meticulously crafted training process, beginning with
long Chain-of-Thought (CoT) data cold-start and culminating in large-scale
Reinforcement Learning (RL). We first employ a well-designed cold-start
training strategy, which significantly enhances the reasoning potential and
equips the model with specialized skills in both formal and agentic reasoning.
Then, a core innovation is our domain-parallel training scheme, which decouples
optimization across distinct domains (e.g., STEM, Code, Agentic) and
subsequently fuses the resulting expert models into a single, nearly
Pareto-optimal model. This entire process is powered by our Dynamic
ORchestration for Asynchronous rollout (DORA) system, a large-scale RL
framework that delivers a greater than threefold training speedup over
synchronous methods on tens of thousands of accelerators. As a result,
LongCat-Flash-Thinking achieves state-of-the-art performance among open-source
models on a suite of complex reasoning tasks. The model exhibits exceptional
efficiency in agentic reasoning, reducing average token consumption by 64.5%
(from 19, 653 to 6, 965) on AIME-25, without degrading task accuracy. We
release LongCat-Flash-Thinking to promote further advances in reasoning systems
and agentic AI research.

</details>


### [409] [How Far are VLMs from Visual Spatial Intelligence? A Benchmark-Driven Perspective](https://arxiv.org/abs/2509.18905)
*Songsong Yu,Yuxin Chen,Hao Ju,Lianjie Jia,Fuxi Zhang,Shaofei Huang,Yuhan Wu,Rundi Cui,Binghao Ran,Zaibin Zhang,Zhedong Zheng,Zhipeng Zhang,Yifan Wang,Lin Song,Lijun Wang,Yanwei Li,Ying Shan,Huchuan Lu*

Main category: cs.AI

TL;DR: 尽管视觉语言模型（VLM）在视觉空间推理（VSR）方面取得了进展，但由于三维空间表示和推理的复杂性，实现人类水平的VSR仍然具有挑战性。本研究对VSR进行了系统性调查，涵盖了输入模态、模型架构、训练策略和推理机制。研究将空间智能分为三个能力级别：基本感知、空间理解和空间规划，并创建了SIBench基准，包含了23个任务设置的近20个开源数据集。实验表明，当前最先进的VLM在感知任务上表现良好，但在理解和规划任务上，尤其是在数值估计、多视图推理、时间动态和空间想象方面，表现不佳。这揭示了实现空间智能的重大挑战，并为该领域未来的研究提供了系统性的路线图和全面的基准。


<details>
  <summary>Details</summary>
Motivation: 视觉空间推理（VSR）是人类核心认知能力，对于发展具身智能和自主系统至关重要。现有视觉语言模型（VLMs）在VSR方面仍有很大提升空间。

Method: 对VSR的现有方法进行了系统性调查，包括输入模态、模型架构、训练策略和推理机制。将空间智能分为三个能力级别（基本感知、空间理解、空间规划），并创建了SIBench基准，整合了近20个开源数据集。

Result: 实验表明，VLM在基本感知任务上表现尚可，但在空间理解和空间规划任务上，尤其是在数值估计、多视图推理、时间动态和空间想象方面，表现出显著的不足，存在感知与推理能力的显著差距。

Conclusion: 实现空间智能仍然面临重大挑战，本研究提出的SIBench基准和系统性调查为未来VSR领域的研究提供了方向和工具。

Abstract: Visual Spatial Reasoning (VSR) is a core human cognitive ability and a
critical requirement for advancing embodied intelligence and autonomous
systems. Despite recent progress in Vision-Language Models (VLMs), achieving
human-level VSR remains highly challenging due to the complexity of
representing and reasoning over three-dimensional space. In this paper, we
present a systematic investigation of VSR in VLMs, encompassing a review of
existing methodologies across input modalities, model architectures, training
strategies, and reasoning mechanisms. Furthermore, we categorize spatial
intelligence into three levels of capability, ie, basic perception, spatial
understanding, spatial planning, and curate SIBench, a spatial intelligence
benchmark encompassing nearly 20 open-source datasets across 23 task settings.
Experiments with state-of-the-art VLMs reveal a pronounced gap between
perception and reasoning, as models show competence in basic perceptual tasks
but consistently underperform in understanding and planning tasks, particularly
in numerical estimation, multi-view reasoning, temporal dynamics, and spatial
imagination. These findings underscore the substantial challenges that remain
in achieving spatial intelligence, while providing both a systematic roadmap
and a comprehensive benchmark to drive future research in the field. The
related resources of this study are accessible at
https://sibench.github.io/Awesome-Visual-Spatial-Reasoning/.

</details>


### [410] [Data Efficient Adaptation in Large Language Models via Continuous Low-Rank Fine-Tuning](https://arxiv.org/abs/2509.18942)
*Xiao Han,Zimo Zhao,Wanyu Wang,Maolin Wang,Zitao Liu,Yi Chang,Xiangyu Zhao*

Main category: cs.AI

TL;DR: DEAL框架结合LoRA和连续微调策略，解决了现有微调方法的灾难性遗忘和数据效率低下问题，在15个数据集上表现优于基线方法，提高了任务准确性和资源效率。


<details>
  <summary>Details</summary>
Motivation: 微调（FT）是将大型语言模型（LLM）适配到特定任务的关键，但现有方法存在灾难性遗忘和数据效率低下的问题。

Method: 提出DEAL框架，结合低秩适配（LoRA）和连续微调策略，并加入知识保留和自适应参数更新模块。

Result: 在15个多样化数据集上的实验表明，DEAL在任务准确性和资源效率方面持续优于基线方法。

Conclusion: DEAL框架能够提升大型语言模型的持续适应能力，同时提高任务性能和资源效率。

Abstract: Recent advancements in Large Language Models (LLMs) have emphasized the
critical role of fine-tuning (FT) techniques in adapting LLMs to specific
tasks, especially when retraining from scratch is computationally infeasible.
Fine-tuning enables LLMs to leverage task- or domain-specific data, producing
models that more effectively meet the requirements of targeted applications.
However, con- ventional FT approaches often suffer from catastrophic forgetting
and suboptimal data efficiency, limiting their real-world applicability. To
address these challenges, this paper proposes DEAL, a novel framework that
integrates Low-Rank Adapta- tion (LoRA) with a continuous fine-tuning strategy.
By incorporating knowledge retention and adaptive parameter update modules, the
framework mitigates the lim- itations of existing FT methods while maintaining
efficiency in privacy-preserving settings. Experiments on 15 diverse datasets
show that DEAL consistently outper- forms baseline methods, yielding
substantial gains in task accuracy and resource efficiency. These findings
demonstrate the potential of our approach to advance continual adaptation in
LLMs by enhancing task performance while improving resource efficiency.

</details>


### [411] [LLM-based Agents Suffer from Hallucinations: A Survey of Taxonomy, Methods, and Directions](https://arxiv.org/abs/2509.18970)
*Xixun Lin,Yucheng Ning,Jingwen Zhang,Yan Dong,Yilong Liu,Yongxuan Wu,Xiaohua Qi,Nan Sun,Yanmin Shang,Pengfei Cao,Lixin Zou,Xu Chen,Chuan Zhou,Jia Wu,Shirui Pan,Bin Wang,Yanan Cao,Kai Chen,Songlin Hu,Li Guo*

Main category: cs.AI

TL;DR: LLM代理在现实世界应用中展现出巨大潜力，但幻觉问题严重影响其可靠性。本文首次全面 survey 了LLM代理中的幻觉问题，提出了新的分类法，分析了幻觉的触发原因，并总结了现有的缓解和检测方法，为未来研究指明了方向。


<details>
  <summary>Details</summary>
Motivation: LLM代理虽然在教育、科研、金融等领域有广泛应用前景，但幻觉问题会导致任务错误，降低系统可靠性。因此，需要系统性地梳理和理解LLM代理的幻觉问题。

Method: 通过分析LLM代理的完整工作流程，提出新的幻觉分类法，识别不同阶段的幻觉类型；深入研究18种幻觉的触发原因；详细回顾现有研究，总结幻觉的缓解和检测方法。

Result: 识别出LLM代理在不同阶段可能出现的幻觉类型，归纳了导致幻觉出现的18种原因，并总结了现有的幻觉缓解和检测技术。

Conclusion: 本文首次全面 survey 了LLM代理中的幻觉问题，提出了新的分类法，分析了幻觉的触发原因，并总结了现有的缓解和检测方法，为未来研究指明了方向，旨在促进更可靠的LLM代理系统的发展。

Abstract: Driven by the rapid advancements of Large Language Models (LLMs), LLM-based
agents have emerged as powerful intelligent systems capable of human-like
cognition, reasoning, and interaction. These agents are increasingly being
deployed across diverse real-world applications, including student education,
scientific research, and financial analysis. However, despite their remarkable
potential, LLM-based agents remain vulnerable to hallucination issues, which
can result in erroneous task execution and undermine the reliability of the
overall system design. Addressing this critical challenge requires a deep
understanding and a systematic consolidation of recent advances on LLM-based
agents. To this end, we present the first comprehensive survey of
hallucinations in LLM-based agents. By carefully analyzing the complete
workflow of agents, we propose a new taxonomy that identifies different types
of agent hallucinations occurring at different stages. Furthermore, we conduct
an in-depth examination of eighteen triggering causes underlying the emergence
of agent hallucinations. Through a detailed review of a large number of
existing studies, we summarize approaches for hallucination mitigation and
detection, and highlight promising directions for future research. We hope this
survey will inspire further efforts toward addressing hallucinations in
LLM-based agents, ultimately contributing to the development of more robust and
reliable agent systems.

</details>


### [412] [From latent factors to language: a user study on LLM-generated explanations for an inherently interpretable matrix-based recommender system](https://arxiv.org/abs/2509.18980)
*Maxime Manderlier,Fabian Lecron,Olivier Vu Thanh,Nicolas Gillis*

Main category: cs.AI

TL;DR: LLMs can generate interpretable recommendation explanations from a constrained matrix factorization model, evaluated through a user study.


<details>
  <summary>Details</summary>
Motivation: To investigate if LLMs can create effective user-facing explanations from a mathematically interpretable recommendation model and to evaluate these explanations using a user-centered approach.

Method: Used a constrained matrix factorization model with explicit user types and interpretable item scores. Translated model insights into natural language explanations via LLM prompts. Conducted a user study with 326 participants to assess explanation quality (transparency, effectiveness, persuasion, trust, satisfaction) and recommendation quality. Generated multiple explanation types by varying LLM inputs.

Result: All generated explanation types were well-received by users, with minor statistical differences between strategies. User comments provided qualitative insights into their reactions to different explanation types.

Conclusion: LLMs can generate effective, user-facing explanations from interpretable recommendation models. A user-centered evaluation approach is crucial for assessing explanation quality, complementing quantitative metrics.

Abstract: We investigate whether large language models (LLMs) can generate effective,
user-facing explanations from a mathematically interpretable recommendation
model. The model is based on constrained matrix factorization, where user types
are explicitly represented and predicted item scores share the same scale as
observed ratings, making the model's internal representations and predicted
scores directly interpretable. This structure is translated into natural
language explanations using carefully designed LLM prompts. Many works in
explainable AI rely on automatic evaluation metrics, which often fail to
capture users' actual needs and perceptions. In contrast, we adopt a
user-centered approach: we conduct a study with 326 participants who assessed
the quality of the explanations across five key dimensions-transparency,
effectiveness, persuasion, trust, and satisfaction-as well as the
recommendations themselves.To evaluate how different explanation strategies are
perceived, we generate multiple explanation types from the same underlying
model, varying the input information provided to the LLM. Our analysis reveals
that all explanation types are generally well received, with moderate
statistical differences between strategies. User comments further underscore
how participants react to each type of explanation, offering complementary
insights beyond the quantitative results.

</details>


### [413] [Remaining Time Prediction in Outbound Warehouse Processes: A Case Study (Short Paper)](https://arxiv.org/abs/2509.18986)
*Erik Penther,Michael Grohs,Jana-Rebecca Rehse*

Main category: cs.AI

TL;DR: We compared four remaining time prediction methods on a real-life logistics dataset. Deep learning models were most accurate, but boosting techniques offered competitive accuracy with lower computational costs.


<details>
  <summary>Details</summary>
Motivation: Predictive process monitoring aims to forecast future process executions, specifically predicting the remaining time until completion. This paper investigates different approaches for this task.

Method: The study compares four different remaining time prediction methods using a novel event log from a real-life outbound warehouse process in the aviation logistics industry. The log contains 169,523 traces and will be made publicly available.

Result: Deep learning models demonstrated the highest accuracy in predicting remaining time. However, shallow methods, such as conventional boosting techniques, achieved comparable accuracy while requiring substantially fewer computational resources.

Conclusion: While deep learning models offer the best accuracy for remaining time prediction, traditional boosting techniques provide a viable alternative with significantly lower computational demands, making them a practical choice for certain applications.

Abstract: Predictive process monitoring is a sub-domain of process mining which aims to
forecast the future of ongoing process executions. One common prediction target
is the remaining time, meaning the time that will elapse until a process
execution is completed. In this paper, we compare four different remaining time
prediction approaches in a real-life outbound warehouse process of a logistics
company in the aviation business. For this process, the company provided us
with a novel and original event log with 169,523 traces, which we can make
publicly available. Unsurprisingly, we find that deep learning models achieve
the highest accuracy, but shallow methods like conventional boosting techniques
achieve competitive accuracy and require significantly fewer computational
resources.

</details>


### [414] [Landmarks, Monuments, and Beacons: Understanding Generative Calls to Action](https://arxiv.org/abs/2509.19030)
*Victoire Hervé,Henrik Warpefelt,Christoph Salge*

Main category: cs.AI

TL;DR: 自动评估程序生成内容（PCG）存在困难，尤其是在处理复合产物时。为解决此问题，本文提出了基于可感知性、唤起性和行动号召的“地标”、“纪念碑”和“信标”等嵌套概念，以玩家为中心，可跨游戏类型通用。这些概念可以通过现有技术进行识别和评估，从而实现PCG的完全自动化分解和重要子组件的评估，连接人文学科与游戏技术研究，并改进PCG评估。


<details>
  <summary>Details</summary>
Motivation: 目前的算法评估方法难以找到与人类体验一致的PCG（程序生成内容）评估指标，特别是在处理复合产物时。因此，需要一种新的方法来自动分解和评估PCG。

Method: 本文借鉴游戏研究和游戏人工智能的研究，引入了“地标”、“纪念碑”和“信标”这三个嵌套的概念。这些概念是基于产物的可感知性、唤起性和行动号召，并从玩家的角度出发。这些术语具有通用性，适用于各种游戏类型。

Result: 这些概念可以通过当前研究和工业界使用的技术来发现和评估。这为PCG的完全自动化分解和关键子组件的评估铺平了道路。

Conclusion: 本文提出的方法旨在连接人文学科和技术游戏研究，并实现更好的计算PCG评估。该方法不仅适用于混合式和组合式PCG，而且具有更广泛的应用前景。

Abstract: Algorithmic evaluation of procedurally generated content struggles to find
metrics that align with human experience, particularly for composite artefacts.
Automatic decomposition as a possible solution requires concepts that meet a
range of properties. To this end, drawing on Games Studies and Game AI
research, we introduce the nested concepts of \textit{Landmarks},
\textit{Monuments}, and \textit{Beacons}. These concepts are based on the
artefact's perceivability, evocativeness, and Call to Action, all from a
player-centric perspective. These terms are generic to games and usable across
genres. We argue that these entities can be found and evaluated with techniques
currently used in both research and industry, opening a path towards a fully
automated decomposition of PCG, and evaluation of the salient sub-components.
Although the work presented here emphasises mixed-initiative PCG and
compositional PCG, we believe it applies beyond those domains. With this
approach, we intend to create a connection between humanities and technical
game research and allow for better computational PCG evaluation

</details>


### [415] [Towards Causal Representation Learning with Observable Sources as Auxiliaries](https://arxiv.org/abs/2509.19058)
*Kwonho Kim,Heejeong Nam,Inwoo Hwang,Sanghack Lee*

Main category: cs.AI

TL;DR: 本研究提出了一种包含可观测源作为辅助变量的因果表征学习框架，可以识别除子空间变换和排列外的整个潜在变量。


<details>
  <summary>Details</summary>
Motivation: 现有因果表征学习方法通常需要对潜在结构或关系做出假设，并且在辅助变量的选择上存在局限性，仅限于混合函数之外的变量。本研究旨在扩展辅助变量的范围，纳入系统中易于观测或提取的潜在因素。

Method: 提出一个包含可观测源作为辅助变量的框架，利用这些辅助变量作为有效的条件变量。研究表明，通过保体积编码器可以识别出潜在变量（在子空间变换和置换下）。当存在多个已知辅助变量时，提出了一种变量选择方案，以最大化潜在因素的可恢复性（在已知潜在因果图的情况下）。

Result: 通过保体积编码器，可以识别整个潜在变量（子空间变换和排列）。提出的变量选择方案能在已知潜在因果图的情况下，选择最优的辅助变量以最大化潜在因素的可恢复性。

Conclusion: 本研究提出的包含可观测源作为辅助变量的因果表征学习框架，有效解决了现有方法的局限性，并通过合成图和图像数据的实验证明了其有效性，扩展了当前方法的边界。

Abstract: Causal representation learning seeks to recover latent factors that generate
observational data through a mixing function. Needing assumptions on latent
structures or relationships to achieve identifiability in general, prior works
often build upon conditional independence given known auxiliary variables.
However, prior frameworks limit the scope of auxiliary variables to be external
to the mixing function. Yet, in some cases, system-driving latent factors can
be easily observed or extracted from data, possibly facilitating
identification. In this paper, we introduce a framework of observable sources
being auxiliaries, serving as effective conditioning variables. Our main
results show that one can identify entire latent variables up to subspace-wise
transformations and permutations using volume-preserving encoders. Moreover,
when multiple known auxiliary variables are available, we offer a
variable-selection scheme to choose those that maximize recoverability of the
latent factors given knowledge of the latent causal graph. Finally, we
demonstrate the effectiveness of our framework through experiments on synthetic
graph and image data, thereby extending the boundaries of current approaches.

</details>


### [416] [Code Driven Planning with Domain-Adaptive Critic](https://arxiv.org/abs/2509.19077)
*Zikang Tian,Shaohui Peng,Du Huang,Jiaming Guo,Ruizhi Chen,Rui Zhang,Xishan Zhang,Yuxuan Guo,Zidong Du,Qi Guo,Ling Li,Yewen Pu,Xing Hu,Yunji Chen*

Main category: cs.AI

TL;DR: CoPiC通过使用LLM生成可执行的规划程序，并利用领域自适应的Critic来评估和选择最符合长期奖励的规划，从而在降低LLM查询成本的同时提高规划性能。


<details>
  <summary>Details</summary>
Motivation: 现有的LLM任务规划方法在处理需要环境特定知识的问题时，由于通用知识与环境要求的差距而导致计划不准确。频繁查询LLM进行迭代优化虽然能解决这个问题，但成本高昂且受限于短期反馈，难以优化长期奖励。

Method: CoPiC提出了一种新的方法，不依赖频繁查询，而是利用LLM生成多样化的、可执行的规划程序。然后，训练一个领域自适应的Critic来评估这些程序生成的候选规划，并选择最符合长期奖励的规划执行。

Result: 在ALFWorld、NetHack和StarCraft II Unit Building等环境中，CoPiC相比于AdaPlanner和Reflexion等现有的LLM基线方法，成功率平均提高了23.33%，同时查询成本降低了91.27%。

Conclusion: CoPiC通过使用LLM生成规划程序，并结合领域自适应Critic进行评估，有效解决了现有LLM规划方法的局限性，实现了在降低成本的同时提高规划效率和效果。

Abstract: Large Language Models (LLMs) have been widely adopted as task planners for AI
agents in sequential decision-making problems, leveraging their extensive world
knowledge. However, the gap between their general knowledge and
environment-specific requirements often leads to inaccurate plans. To address
this, existing approaches rely on frequent LLM queries to iteratively refine
plans based on immediate environmental feedback, which incurs substantial query
costs. However, this refinement is typically guided by short-term environmental
feedback, limiting LLMs from developing plans aligned with long-term rewards.
We propose Code Driven Planning with Domain-Adaptive Critic (CoPiC). Instead of
relying on frequent queries, CoPiC employs LLMs to generate a diverse set of
high-level planning programs, which iteratively produce and refine candidate
plans. A trained domain-adaptive critic then evaluates these candidates and
selects the one most aligned with long-term rewards for execution. Using
high-level planning programs as planner and domain-adaptive critic as
estimator, CoPiC improves planning while significantly reducing query costs.
Results in ALFWorld, NetHack, and StarCraft II Unit Building show that CoPiC
outperforms advanced LLM-based baselines, AdaPlanner and Reflexion, achieving
an average (1) 23.33% improvement in success rate and (2) 91.27% reduction in
query costs.

</details>


### [417] [AgentInit: Initializing LLM-based Multi-Agent Systems via Diversity and Expertise Orchestration for Effective and Efficient Collaboration](https://arxiv.org/abs/2509.19236)
*Chunhao Tian,Yutong Wang,Xuebo Liu,Zhexuan Wang,Liang Ding,Miao Zhang,Min Zhang*

Main category: cs.AI

TL;DR: AgentInit是一种用于优化多智能体系统（MAS）团队结构的新型初始化方法，通过多轮交互、自然语言到格式的转换以及基于Pareto原则的团队选择策略，提高了团队协作效率和任务相关性，实验证明其性能优于现有方法，并具有良好的可迁移性。


<details>
  <summary>Details</summary>
Motivation: 现有MAS初始化方法未能充分考虑生成Agent在后续阶段的协作需求，而AgentInit旨在优化Agent团队的结构以满足这些需求。

Method: AgentInit结合了多轮Agent交互与反思、自然语言到格式的转换机制以及基于Pareto原则的团队选择策略，以实现Agent团队结构的最优化。

Result: AgentInit在各种框架和任务中持续优于最先进的初始化方法和预定义策略，整体性能分别提高了1.2和1.6，同时显著降低了代币消耗。此外，其强大的可迁移性和关键组成部分的有效性也得到了验证。

Conclusion: AgentInit作为一种可靠的MAS初始化方法，通过优化团队结构、促进有效协作和提高整体系统性能，展现了其优越性和适应性。

Abstract: Proper initialization is crucial for any system, particularly in multi-agent
systems (MAS), where it plays a pivotal role in determining both the system's
efficiency and effectiveness. However, existing MAS initialization methods do
not fully account for the collaborative needs of the generated agents in
subsequent stages. Inspired by the principles of effective team composition, we
propose AgentInit, which aims to optimize the structure of agent teams.
Specifically, in addition to multi-round interactions and reflections between
agents during agent generation, AgentInit incorporates a Natural Language to
Format mechanism to ensure consistency and standardization. Balanced team
selection strategies using Pareto principles are subsequently applied to
jointly consider agent team diversity and task relevance to promote effective
and efficient collaboration and enhance overall system performance. Experiments
show that AgentInit consistently outperforms state-of-the-art initialization
methods and pre-defined strategies across various frameworks and tasks,
achieving an overall performance improvement of up to 1.2 and 1.6,
respectively, while also significantly reducing token consumption. Further
analysis confirms its strong transferability to similar tasks and verifies the
effectiveness of its key components, demonstrating its capability and
adaptability as a reliable MAS initialization method. Source code and models
are available at https://github.com/1737423697/AgentInit.

</details>


### [418] [Cross-Cultural Transfer of Commonsense Reasoning in LLMs: Evidence from the Arab World](https://arxiv.org/abs/2509.19265)
*Saeed Almheiri,Rania Hossam,Mena Attia,Chenxi Wang,Preslav Nakov,Timothy Baldwin,Fajri Koto*

Main category: cs.AI

TL;DR: 跨文化迁移在大型语言模型（LLM）的文化适应中具有巨大潜力，本研究通过阿拉伯世界的跨文化常识推理实验进行验证。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLM）常带有西方中心偏见，限制了其在多元文化背景下的有效性。虽然已有研究探索文化适应，但利用一种文化的适应性来改善另一种文化的性能的跨文化迁移潜力仍有待发掘。

Method: 本研究使用涵盖13个阿拉伯国家的、基于文化的常识推理数据集，评估了上下文学习和基于演示的强化（DITTO）等轻量级适应方法，以及监督微调和直接偏好优化等基线方法。

Result: 结果表明，仅使用一个国家的12个特定文化示例，就可以在多语言模型中将其他国家的性能平均提高10%。此外，研究还发现，来自印度尼西亚和美国文化背景的示例在选择题推理方面可以匹配甚至超越本国文化适应，表明常识推理具有跨越阿拉伯世界的文化迁移能力。

Conclusion: 研究证明了高效的跨文化适应是可行的，并为将大型语言模型（LLM）应用于资源匮乏的文化环境提供了一种有前景的方法。

Abstract: Large language models (LLMs) often reflect Western-centric biases, limiting
their effectiveness in diverse cultural contexts. Although some work has
explored cultural alignment, the potential for cross-cultural transfer, using
alignment in one culture to improve performance in others, remains
underexplored. This paper investigates cross-cultural transfer of commonsense
reasoning in the Arab world, where linguistic and historical similarities
coexist with local cultural differences. Using a culturally grounded
commonsense reasoning dataset covering 13 Arab countries, we evaluate
lightweight alignment methods such as in-context learning and
demonstration-based reinforcement (DITTO), alongside baselines like supervised
fine-tuning and direct preference optimization. Our results show that merely 12
culture-specific examples from one country can improve performance in others by
10\% on average, within multilingual models. In addition, we demonstrate that
out-of-culture demonstrations from Indonesia and US contexts can match or
surpass in-culture alignment for MCQ reasoning, highlighting cultural
commonsense transferability beyond the Arab world. These findings demonstrate
that efficient cross-cultural alignment is possible and offer a promising
approach to adapt LLMs to low-resource cultural settings.

</details>


<div id='quant-ph'></div>

# quant-ph [[Back]](#toc)

### [419] [Generalized Gottesman-Kitaev-Preskill States on a Quantum Torus](https://arxiv.org/abs/2509.18204)
*Sijo K. Joseph,Sudhir Singh*

Main category: quant-ph

TL;DR: 我们提出了一种广义GKP（GGKP）态的精确且可实现的量子态，解决了现有GKP态的固有病态问题，并揭示了量子纠错、非交换几何和Theta函数理论之间的联系。


<details>
  <summary>Details</summary>
Motivation: 现有广义GKP态的定义存在能量无限、不可归一化和不相互正交等根本性问题，这限制了其在物理系统中的应用。

Method: 通过考虑耦合量子谐振子等系统固有的紧凑量子相位空间，并应用量子Zak变换（QZT）到压缩相干态，我们得到了GGKP态。这种方法揭示了黎曼Theta函数在量子环相位空间上是这些态的自然表示。

Result: 我们得到了一个精确且可实现的GGKP态，它没有无限能量、不可归一化和不相互正交的问题。此外，我们还发现了量子纠错、非交换几何和广义Theta函数理论之间的深刻联系。

Conclusion: 我们提出的GGKP态的框架不仅提供了一个表现良好的量子态，还为容错光量子计算开辟了新的途径，并揭示了量子纠错、非交换几何和Theta函数理论之间的深刻联系。

Abstract: We introduce a novel formulation of a Generalized Gottesman-Kitaev-Preskill
(GKP) state that resolves all of its foundational pathologies, such as infinite
energy, non-normalizability, and or- thogonality. We demonstrate that these
issues are artifacts of defining the code on an unbounded phase-space. By
considering the compact quantum-phase-space intrinsic to systems like coupled
quantum harmonic oscillators, we have obtained a Generalized GKP (GGKP) state
that is both exact and physically realizable. This is achieved by applying an
obtained Quantum Zak Transform (QZT) to Squeezed Coherent States, which reveals
that Riemann-Theta functions are the natural representation of these states on
the quantum torus phase-space. This framework not only provides a well-behaved
quantum state, but also reveals a deep connection between quantum error correc-
tion, non-commutative geometry, and the theory of generalized Theta functions.
This opens a new avenue for fault-tolerant photonic quantum computing.

</details>


### [420] [Connecting Quantum Computing with Classical Stochastic Simulation](https://arxiv.org/abs/2509.18614)
*Jose Blanchet,Mark S. Squillante,Mario Szegedy,Guanyang Wang*

Main category: quant-ph

TL;DR: 本文介绍量子计算在蒙特卡洛计算中的应用，特别是在计算金融领域。


<details>
  <summary>Details</summary>
Motivation: 介绍量子计算在蒙特卡洛计算中的应用，特别是在计算金融领域。

Method: 从Grover算法入手，介绍幅值估算问题，并应用于计数和蒙特卡洛积分，最后通过Python/Qiskit实现进行演示。

Result: 通过Python/Qiskit实现演示了量子蒙特卡洛计算在金融领域的应用。

Conclusion: 讨论了当前在扩展量子模拟技术方面面临的挑战。

Abstract: This tutorial paper introduces quantum approaches to Monte Carlo computation
with applications in computational finance. We outline the basics of quantum
computing using Grover's algorithm for unstructured search to build intuition.
We then move slowly to amplitude estimation problems and applications to
counting and Monte Carlo integration, again using Grover-type iterations. A
hands-on Python/Qiskit implementation illustrates these concepts applied to
finance. The paper concludes with a discussion on current challenges in scaling
quantum simulation techniques.

</details>


### [421] [Structure-Fair Quantum Circuit Complexity: An Information-Theoretic Lower Bound](https://arxiv.org/abs/2509.18205)
*HongZheng Liu,YiNuo Tian,Zhiyue Wu*

Main category: quant-ph

TL;DR: 量子信息论提出了一种新的量子态复杂度度量方法-参考依赖复杂度（RCC），它能公平地量化具有内在结构（如对称性或编码）的量子态的复杂度，并通过量子相对熵衡量量子态偏离其“结构化真空”的程度，从而只评估非平凡信息的生成成本。该方法在理论上建立了RCC作为通用量子电路复杂度的严格信息论下界，并提出了基于量子假设检验的操作协议，使其可被实验测量。这为量子技术提供了一个结构公平的评价标准，并加深了对计算成本与非平凡信息生成之间内在联系的理解。


<details>
  <summary>Details</summary>
Motivation: Fairly quantifying the complexity of quantum states that possess intrinsic structures (such as symmetries or encodings) is a fundamental challenge for benchmarking quantum technologies.

Method: We introduce the "Reference-Contingent Complexity" (RCC). Its core idea is to utilize the quantum relative entropy to measure the extent to which a state deviates from its "structured vacuum" (the maximum entropy state within its constrained subspace), thereby only pricing the generation of non-trivial information. We establish a central theorem, establishing that the RCC is a rigorous information-theoretic lower bound on universal quantum circuit complexity, a bound that features a linear leading term, a universal logarithmic correction, and a precise physical correction for the non-uniformity of the spectral distribution. Furthermore, we establish an operational protocol based on quantum hypothesis testing, which connects this theoretical lower bound to experimentally accessible observables.

Result: The RCC is a rigorous information-theoretic lower bound on universal quantum circuit complexity, featuring a linear leading term, a universal logarithmic correction, and a precise physical correction. An operational protocol based on quantum hypothesis testing connects this bound to experimentally accessible observables.

Conclusion: This work provides a structurally-fair yardstick for quantum technologies and offers a new perspective for exploring the intrinsic connection between computational cost and the generation of non-trivial information.

Abstract: Fairly quantifying the complexity of quantum states that possess intrinsic
structures (such as symmetries or encodings) is a fundamental challenge for
benchmarking quantum technologies. We introduce the "Reference-Contingent
Complexity" (RCC). Its core idea is to utilize the quantum relative entropy to
measure the extent to which a state deviates from its "structured vacuum" (the
maximum entropy state within its constrained subspace), thereby only pricing
the generation of non-trivial information. We establish a central theorem,
establishing that the RCC is a rigorous information-theoretic lower bound on
universal quantum circuit complexity, a bound that features a linear leading
term, a universal logarithmic correction, and a precise physical correction for
the non-uniformity of the spectral distribution. Furthermore, we establish an
operational protocol based on quantum hypothesis testing, which connects this
theoretical lower bound to experimentally accessible observables. This work
provides a structurally-fair yardstick for quantum technologies and offers a
new perspective for exploring the intrinsic connection between computational
cost and the generation of non-trivial information.

</details>


### [422] [Joint momenta-coordinates states as pointer states in quantum decoherence](https://arxiv.org/abs/2509.18206)
*Nomenjanahary Tanjonirina Manampisoa,Ravo Tokiniaina Ranaivoson,Roland Raboanary,Raoelina Andriambololona,Rivo Herivola Manjakamanana Ravelonjato*

Main category: quant-ph

TL;DR: 联合动量-坐标态被严格证明是量子退相干中的指针态，特别是在欠阻尼情况下，这扩展了先前关于高斯态的研究，并对量子信息有潜在应用。


<details>
  <summary>Details</summary>
Motivation: 量子退相干如何从量子系统中产生经典性，特别是确定哪些量子态可以被视为指针态。

Method: 在兰布拉德框架下，研究了欠阻尼和过阻尼两种情况下的受阻尼谐振子，并应用了 Zurek 的可预测性筛选准则。

Result: 只有在欠阻尼情况下，联合动量-坐标态才能在所有时间内保持纯净和稳健，从而被确定为真正的指针态。

Conclusion: 联合动量-坐标态是量子退相干中的指针态，特别是在欠阻尼情况下，这扩展了先前的研究，并将经典稳健性融入了量子相空间形式主义，对容错量子信息具有潜在应用。

Abstract: Quantum decoherence provides a framework to study the emergence of
classicality from quantum system by showing how interactions with the
environments suppress interferences and select robust states known as pointer
states. Earlier studies have linked Gaussian coherent states with pointer
states. More recently, it was conjectured that more general quantum states
called joint momenta-coordinates states could also be considered as more
suitable candidates to be pointer states. These states are associated to the
concept of quantum phase space and saturate, by definition, generalized
uncertainty relations. In this work, we rigorously prove this conjecture.
Building on the Lindblad framework for the damped harmonic oscillator and
applying Zurek's predictability-sieve criterion, we analyze both underdamped
and overdamped regimes. We show that only in the underdamped case do joint
momenta-coordinates states remain pure and robust for all times, establishing
them as the true pointer states. This extends Isar's earlier underdamped
treatment, generalizes the concept beyond Gaussian approximations, and embeds
classical robustness in the quantum phase space formalism, with potential
applications in error-resilient quantum information.

</details>


### [423] [Order from chaos with adaptive circuits on quantum hardware](https://arxiv.org/abs/2509.18259)
*Bibek Pokharel,Haining Pan,Kemal Aziz,Luke C. G. Govia,Sriram Ganeshan,Thomas Iadecola,Justin H. Wilson,Barbara A. Jones,Abhinav Deshpande,Jedediah H. Pixley,Maika Takita*

Main category: quant-ph

TL;DR: 通过结合中途测量和复位操作，在IBM超导量子处理器上实现了自适应监测的量子电路，用于控制量子混沌动力学，并观察到了量子-经典动力学之间的相变。


<details>
  <summary>Details</summary>
Motivation: 在可编程量子设备上实现自适应监测的量子电路，以控制量子混沌动力学。

Method: 在IBM超导量子处理器上，使用多达100个量子比特，通过局部中途测量和复位操作，结合条件反馈，实现自适应监测量子电路，以控制量子混沌动力学，该动力学模拟了经典上混沌的伯努利映射。

Result: 观察到了量子-经典动力学之间的相变，并利用噪声模拟、矩阵乘积态和统计力学模型进行了理论描述。利用量子计算机上大规模的量子比特数量，高精度地估计了普适临界性质。

Conclusion: 通过成功地在多达100个量子比特的系统上应用近5000个纠缠门和5000个非酉中途操作，该实验为实现容错量子计算指明了方向。

Abstract: Programmable quantum devices provide a platform to control the coherent
dynamics of quantum wavefunctions. Here we experimentally realize adaptive
monitored quantum circuits, which incorporate conditional feedback into
non-unitary evolution, to control quantum chaotic dynamics using a combination
of local mid-circuit measurements and resets. The experiments are performed
with an IBM superconducting quantum processor using up to 100 qubits that
samples a quantum version of the classically chaotic Bernoulli map. This map
scrambles quantum information, while local measurements and feedback attempt to
steer the dynamics toward a state that is a fixed point of the map. This
competition drives a dynamical phase transition between quantum and classical
dynamics that we observe experimentally and describe theoretically using noisy
simulations, matrix product states, and mappings to statistical mechanics
models. Estimates of the universal critical properties are obtained to high
accuracy on the quantum computer thanks to the large number of qubits utilized
in the calculation. By successfully applying up to nearly 5000 entangling gates
and 5000 non-unitary mid-circuit operations on systems up to 100 qubits, this
experiment serves as a signpost on the route towards fault tolerance.

</details>


### [424] [Training the classification capability of large-scale quantum cellular automata](https://arxiv.org/abs/2509.18262)
*Mario Boneberg,Simon Kochsiek,Gabriele Perfetto,Igor Lesanovsky*

Main category: quant-ph

TL;DR: 在相变附近，动力学可能不再是遍历性的，这使得系统能够被归类到几个宏观上可区分的固定点之一。这种机制被应用于量子元胞自动机和量子神经网络，用于状态分类。研究表明，即使在高维状态空间中，也可以通过训练数据有效地学习这种分类能力。文章以一个与Z2对称伊辛模型相关的量子元胞自动机为例，说明了二元分类的可能性，并指出该方法可以推广到更广泛的分类任务，为理解量子机器学习中的涌现多体现象和数据处理能力提供了新的视角。


<details>
  <summary>Details</summary>
Motivation: Ergodicity breaking near a phase transition provides a mechanism for classifying states, which can be leveraged for quantum machine learning tasks like state classification in quantum cellular automata and feed-forward quantum neural networks.

Method: The paper demonstrates that the state classification capability enabled by ergodicity breaking can be efficiently learned from training data, even in high-dimensional state spaces. This is illustrated using a quantum cellular automaton connected to the dynamics of a $\mathbb{Z}_2$-symmetric Ising model with local interactions and dissipation.

Result: The study shows that binary classification can be achieved using the described approach, which is linked to the dynamics of a $\mathbb{Z}_2$-symmetric Ising model. The method is shown to be efficiently learnable from training data even in extremely high-dimensional state spaces.

Conclusion: The proposed approach, leveraging ergodicity breaking near phase transitions, offers a viable and efficiently learnable method for state classification in quantum machine learning. It generalizes beyond binary classification and provides a framework for connecting emergent many-body phenomena with data processing capabilities in quantum systems.

Abstract: In the vicinity of a phase transition ergodicity can be broken. Here,
different initial many-body configurations evolve towards one of several fixed
points, which are macroscopically distinguishable through an order parameter.
This mechanism enables state classification in quantum cellular automata and
feed-forward quantum neural networks. We demonstrate that this capability can
be efficiently learned from training data even in extremely high-dimensional
state spaces. We illustrate this using a quantum cellular automaton that allows
binary classification, which is closely connected to the dynamics of a
$\mathbb{Z}_2$-symmetric Ising model with local interactions and dissipation.
This approach can be generalized beyond binary classification and offers a
natural framework for exploring the link between emergent many-body phenomena
and the interpretation of data processing capabilities in the context of
quantum machine learning.

</details>


### [425] [Not All Qubits are Utilized Equally](https://arxiv.org/abs/2509.19241)
*Jeremie Pope,Swaroop Ghosh*

Main category: quant-ph

TL;DR: 该论文分析了量子计算机硬件的平均量子比特利用率，以识别各种编译器配置如何改变利用率模式，并提出了优化和定价策略。


<details>
  <summary>Details</summary>
Motivation: 随着量子计算机功能的提高和物理量子比特数量的增加，量子程序员通常依赖软件套件将电路转译为目标机器架构兼容的电路。对于具有连接性限制的超导架构，所选的综合、布局和布线算法会极大地改变物理量子比特的平均利用模式。因此，有必要分析平均量子比特利用率，以了解各种编译器配置如何改变利用率模式。

Method: 通过分析量子硬件的平均量子比特利用率，研究各种编译器配置如何改变利用率模式。使用IBM的27量子比特Falcon R4架构和Qiskit平台，对一部分量子比特、门分布和优化配置进行了初步分析。

Result: 分析显示，存在一种持续存在的倾向于微不足道的映射，但可以通过增加优化来解决，前提是架构的整体利用率保持在某个阈值以下。这会导致一些量子比特被过度使用，而另一些量子比特则使用不足。

Conclusion: 研究结果表明，可以通过关注过度使用的量子比特来减少校准开销；通过优化、映射和布线算法来最大化硬件利用率；以及在多租户环境中通过以较低的价格为未使用的量子比特定价来激励使用并提高硬件吞吐量。

Abstract: Improvements to the functionality of modern Noisy Intermediate-Scale Quantum
(NISQ) computers have coincided with an increase in the total number of
physical qubits. Quantum programmers do not commonly design circuits that
directly utilize these qubits; instead, they rely on various software suites to
algorithmically transpile the circuit into one compatible with a target
machine's architecture. For connectivity-constrained superconducting
architectures in particular, the chosen syntheses, layout, and routing
algorithms used to transpile a circuit drastically change the average
utilization patterns of physical qubits. In this paper, we analyze average
qubit utilization of a quantum hardware as a means to identify how various
transpiler configurations change utilization patterns. We present the
preliminary results of this analysis using IBM's 27-qubit Falcon R4
architecture on the Qiskit platform for a subset of qubits, gate distributions,
and optimization configurations. We found a persistent bias towards trivial
mapping, which can be addressed through increased optimization provided that
the overall utilization of an architecture remains below a certain threshold.
As a result, some qubits are overused whereas other remain underused. The
implication of our study are many-fold namely, (a) potential reduction in
calibration overhead by focusing on overused qubits, (b) refining optimization,
mapping and routing algorithms to maximize the hardware utilization and (c)
pricing underused qubits at low rate to motivate their usage and improve
hardware throughput (applicable in multi-tenant environments).

</details>


### [426] [Efficient Quantum Protein Structure Prediction with Problem-Agnostic Ansatzes](https://arxiv.org/abs/2509.18263)
*Hanna Linn,Rui-Hao Li,Alexander Holden,Abdullah Ash Saki,Frank DiFilippo,Tomas Radivoyevitch,Daniel Blankenberg,Laura García-Álvarez,Göran Johansson*

Main category: quant-ph

TL;DR: 提出了一种更有效的量子蛋白结构预测工作流程，通过使用问题无关的ansatz来绕过显式哈密顿量构建的需要，并在经典计算机上高效计算能量成本函数，从而实现可扩展性。


<details>
  <summary>Details</summary>
Motivation: 准确预测氨基酸序列的蛋白质结构是计算生物学中的一个基本挑战，对理解生物功能和基于结构的药物发现具有深远影响。

Method: 我们引入了一种更有效的工作流程，通过使用问题无关的ansatz并最小化可以在经典计算机上高效计算的基于能量的成本函数，从而绕过显式哈密顿量构建的需要。我们在各种晶格上使用包含高达二阶近邻相互作用的26个氨基酸的蛋白质集来测试我们的方法。

Result: 在无噪声模拟器和IBM Kingston量子计算机上评估了该方法，使用了多种指标来评估预测质量，针对比先前研究中通常处理的更长的序列。

Conclusion: 结果证明了该方法的扩展性和多功能性，并指出了改进的领域，为未来的算法开发和硬件进步提供了信息。

Abstract: Accurately predicting protein structures from amino acid sequences remains a
fundamental challenge in computational biology, with profound implications for
understanding biological functions and enabling structure-based drug discovery.
Quantum computing approaches based on coarse-grained lattice models combined
with variational algorithms have been proposed as an initial step towards
predicting protein structures using quantum computers. In this work, we
introduce a more efficient quantum protein structure prediction workflow that
bypasses the need for explicit Hamiltonian construction by employing a
problem-agnostic ansatz. The ansatz is trained to minimize an energy-based cost
function that can be efficiently computed on classical computers, eliminating
the need for ancillary qubits and reducing circuit depth compared to previous
Hamiltonian-based methods. This enables a more scalable approach for larger
proteins and facilitates the inclusion of higher-order interactions, previously
hard to achieve in quantum approaches. We validate our method by benchmarking a
hardware-efficient ansatz on a large set of proteins with up to 26 amino acids,
modeled on the tetrahedral, body-centered cubic, and face-centered cubic
lattices, incorporating up to second-nearest-neighbor interactions. We assess
the performance on both a noise-free simulator and the ibm_kingston quantum
computer using a set of distinct metrics to probe different aspects of the
prediction quality. These experiments push the boundaries of quantum methods
for protein structure prediction, targeting sequences that are longer than
those typically addressed in prior studies. Overall, the results highlight the
scalability and versatility of our approach, while also identifying key areas
for improvement to inform future algorithm development and hardware
advancements.

</details>


### [427] [Transversal STAR architecture for megaquop-scale quantum simulation with neutral atoms](https://arxiv.org/abs/2509.18294)
*Refaat Ismail,I-Chi Chen,Chen Zhao,Ronen Weiss,Fangli Liu,Hengyun Zhou,Sheng-Tao Wang,Andrew Sornborger,Milan Kornjača*

Main category: quant-ph

TL;DR: 提出了一种与中性原子量子硬件共同设计的“横贯STAR”架构，以降低早期容错量子模拟的资源开销。


<details>
  <summary>Details</summary>
Motivation: 现有的基于STAR的量子纠错方法在实现低噪声“魔术资源态”制备时，由于固定的量子比特连接性，导致成本较高。

Method: 提出“横贯STAR”架构，并与中性原子量子硬件进行协同设计，利用电路级模拟推导了基于表面码的横贯STAR小工具的逻辑噪声模型，并验证了其可组合性。

Result: “横贯STAR”架构在逻辑布局、时间和空间开销上实现了显著节省，在极限情况下可模拟局部哈密顿量，模拟总量超600。实现该极限约需10,000个物理量子比特，物理错误率为10^-3，这相当于完全容错计算所需的10^6-10^7 T门。此外，该架构可扩展至高码率量子码。

Conclusion: 协同设计的“横贯STAR”架构有望大幅减少早期容错量子模拟（达到百万量子操作规模）所需的物理资源。

Abstract: Quantum computing experiments have made remarkable progress in demonstrating
key components of quantum error correction, a prerequisite for scalable quantum
computation. While we anticipate the arrival of early fault-tolerant quantum
hardware capable of a million reliable quantum operations, the cost of
preparing low-noise `magic resource states' presents a formidable challenge.
The recently proposed partially-fault-tolerant architecture based on a
space-time efficient analog rotation (STAR) approach attempts to address this
challenge by using post-selection to prepare low-noise, small-angle magic
states. Its proposed physical implementation, however, assumes fixed qubit
connectivity, resulting in implementation costs closer to leading
fully-fault-tolerant approaches. Here, we propose the transversal STAR
architecture and co-design it with neutral-atom quantum hardware, deriving
significant savings in logical layout, time, and space overhead. Through
circuit-level simulations, we derive the logical noise model for
surface-code-based transversal STAR gadgets and verify their composability. At
its limit, the transversal STAR architecture can efficiently simulate local
Hamiltonians with a total simulation volume exceeding 600. Achieving this limit
would require approximately 10,000 physical qubits at a physical error rate of
$10^{-3}$. This is equivalent to a fully-fault-tolerant computation requiring
over $10^6$-$10^7$ $T$ gates. Finally, we extend the transversal STAR
architecture to high-rate quantum codes, demonstrating how a limited set of
highly parallel transversal Clifford gates and generalized small-angle magic
injection can be utilized for effective quantum simulation. We anticipate that
the co-designed transversal STAR architecture could substantially reduce the
physical resources necessary for early-fault-tolerant quantum simulation at the
megaquop scale.

</details>


### [428] [A sharper Magnus expansion bound woven in binary branches](https://arxiv.org/abs/2509.18312)
*Harriet Apel,Toby Cubitt,Emilio Onorati*

Main category: quant-ph

TL;DR: Magnus展开提供了一种指数表示，可用于表示算符族。本研究提出了Magnus展开截断误差的通用上界，并提供了计算和分析方法。


<details>
  <summary>Details</summary>
Motivation: Magnus展开在量子力学等领域中用于表示由含时哈密顿量决定的幺正演化，但其计算复杂度高。本研究旨在为Magnus展开的截断误差提供一个通用的、与生成元无关的上界，以改善其精度和理解其局限性。

Method: 利用Iserles和Norsett引入的二叉树表示，推导出一种递推公式来界定Magnus展开中各项的幅度，从而建立截断误差的上界。

Result: 推导出了Magnus展开截断误差的通用上界，并通过计算前24项的Magnus级数，验证了其数值结果与理论分析的趋势一致。

Conclusion: 本研究为Magnus展开的截断误差提供了理论上界的分析，并辅以数值计算的验证，旨在增进对该技术准确性和局限性的理解，并为近似量子动力学提供更精确的界限。

Abstract: The Magnus expansion provides an exponential representation of one-parameter
operator families, expressed as a series expansion in its generators. This is
useful for example in quantum mechanics for expressing a unitary evolution
determined by a time-dependent Hamiltonian generator of the dynamics. The
solution is constructed as a series expansion in terms of increasingly complex
nested commutators that rapidly become challenging to compute directly. This
work establishes a universal upper bound, agnostic to the generator, on the
error incurred when the Magnus expansion is truncated at an arbitrary given
order. The main technical ingredient of the proof is the binary tree
representation introduced by Iserles and Norsett from which we derive a
recursion formula to delimit the magnitude of any term in the expansion. We
complement our analytic results for the truncation error with explicit
calculation of the first 24 terms in the Magnus series, illustrating that they
follow the scaling behaviour we have derived. With these findings we aim to
contribute to the understanding of the accuracy and limitations of the Magnus
expansion technique, and to provide a sharper bound for approximating quantum
dynamics without requiring assumptions on the structure of their generators.

</details>


### [429] [Overcoming limitations on gate fidelity in noisy static exchange-coupled surface qubits](https://arxiv.org/abs/2509.18737)
*Hoang-Anh Le,Saba Taherpour,Denis Janković,Christoph Wolf*

Main category: quant-ph

TL;DR: 通过开放量子系统模拟和量子最优控制理论，研究了原子尺度量子比特平台的高保真度量子控制问题，并提出了优化实验设计的建议。


<details>
  <summary>Details</summary>
Motivation: 为了解决原子尺度量子比特平台中存在的静态交换耦合、有限的寿命和初始状态极化限制高保真度量子控制的问题。

Method: 采用开放量子系统模拟和量子最优控制理论，特别是Krotov方法，来研究量子比特平台的高保真度操作条件，并与传统的Rabi驱动进行比较。

Result: 证明了在该量子比特平台中实现高保真度操作（保真度大于0.9）的可行性条件，并展示了Krotov方法如何适应特定的噪声源以优于传统的Rabi驱动。

Conclusion: 提出了优化实验设计的建议，以最大化该量子比特平台中的门保真度。

Abstract: Recent experiments demonstrated that the spin state of individual atoms on
surfaces can be quantum-coherently controlled through all-electric electron
spin resonance. By constructing interacting arrays of atoms this results in an
atomic-scale qubit platform. However, the static exchange coupling between
qubits, limited lifetime and polarization of the initial state, impose
significant limits on high-fidelity quantum control. We address this issue
using open quantum systems simulation and quantum optimal control theory. We
demonstrate the conditions under which high-fidelity operations ($\mathcal{F}
\gtrsim 0.9$) are feasible in this qubit platform, and show how the Krotov
method of quantum optimal control theory adapts to specific noise sources to
outperform the conventional Rabi drivings. Finally, we re-examine the
experimental setup used in the initial demonstration of this qubit platform and
propose optimized experimental designs to maximize gate fidelity in this
platform.

</details>


### [430] [Chiral Color Code : Single-shot error correction for exotic topological order](https://arxiv.org/abs/2509.18324)
*Dongjin Lee,Beni Yoshida*

Main category: quant-ph

TL;DR: Chiral color codes are a family of 3D stabilizer codes that realize fermionic and chiral topological orders. They are fault-tolerant and can be used to manipulate fermions and chiral anyons.


<details>
  <summary>Details</summary>
Motivation: The paper presents a new family of 3D stabilizer codes, the chiral color codes, designed to realize fermionic and chiral topological orders.

Method: The chiral color codes are constructed within the gauge color code framework. The paper proves the bulk is short-range entangled by constructing a local quantum channel to prepare the ground state. They also prove that the code has a unique ground state after removing bulk transparent fermions or bosons on closed manifolds.

Result: The codes realize $\mathbb{Z}_d^{(\alpha)}$ anyon theories with anomalous chiral surface topological order. In the qubit case, it realizes the topological phase of a single copy of the fermionic toric code. The codes are fault-tolerant, admitting single-shot error correction and code switching.

Conclusion: The chiral color codes are a promising platform for realizing and manipulating fermions and chiral anyons due to their unique topological properties and fault-tolerant features.

Abstract: We present a family of simple three-dimensional stabilizer codes, called the
chiral color codes, that realize fermionic and chiral topological orders. In
the qubit case, the code realizes the topological phase of a single copy of the
fermionic toric code. For qudit systems with local dimension $d$, the model
features a chiral parameter $\alpha$ and realizes 3D topological phases
characterized by $\mathbb{Z}_d^{(\alpha)}$ anyon theories with anomalous chiral
surface topological order. On closed manifolds, the code has a unique ground
state after removing bulk transparent fermions or bosons. Furthermore, we prove
that the bulk is short-range entangled (for odd $d$, coprime $\alpha$) by
constructing an explicit local quantum channel that prepares the ground state.
The chiral color codes are constructed within the gauge color code, and hence
inherit its fault-tolerant features: they admit single-shot error correction
and allow code switching to other stabilizer color codes. These properties
position the chiral color codes as particularly useful platforms for realizing
and manipulating fermions and chiral anyons.

</details>


### [431] [Uncut Gem - An Open-Source Hackable Quantum Sensor](https://arxiv.org/abs/2509.18329)
*Mark Carney,Victoria Kumaran*

Main category: quant-ph

TL;DR: 一个开源、可定制的基于金刚石NV色心磁力计的量子传感器平台，旨在降低量子传感技术的入门门槛，促进教育、研究和创新。


<details>
  <summary>Details</summary>
Motivation: 为了普及量子传感技术，提供一个全面、模块化且成本效益高的系统。

Method: 利用现成的消费级（COTS）组件，结合新颖的硬件配置和开源的Arduino固件，实现便携性、易定制性和前瞻性。

Result: 成功构建了一个紧凑的平台，可用于教育、研究和量子技术创新。

Conclusion: 该平台体现了开放科学和社区驱动开发的理念，通过降低技术壁垒，使更多人能够接触和使用量子传感技术。

Abstract: This work presents an overview of our fully open-source, hackable quantum
sensor platform based on nitrogen-vacancy (NV) center diamond magnetometry.
This initiative aims to democratize access to quantum sensing by providing a
comprehensive, modular, and cost-effective system. The design leverages
consumer off-the-shelf (COTS) components in a novel hardware configuration,
complemented by open-source firmware written in the Arduino IDE, facilitating
portability, ease of customization, and future-proofing the design. By lowering
the barriers to entry, our sensor serves as a compact platform for education,
research, and innovation in quantum technologies, embodying the ethos of open
science and community-driven development.

</details>


### [432] [Non-equilibrium Dynamics of Two-level Systems directly after Cryogenic Alternating Bias](https://arxiv.org/abs/2509.19223)
*V. Iaia,E. S. Joseph,S. Im,N. Hagopian,S. O'Kelley,C. Kim,N. Materise,S. Patra,V. Lordi,M. A. Eriksson,P. M. Voyles,K. G. Ray,Y. J. Rosen*

Main category: quant-ph

TL;DR: 大型交流电场可逆地改变非晶氧化物中的两级系统动力学，但不会影响LC振荡器的损耗。


<details>
  <summary>Details</summary>
Motivation: 两级系统（TLS）会降低量子比特和谐振器的性能，但之前的研究表明，施加大型交流电场可以改变其性质。

Method: 在低温下，对非晶氧化物平行板电容器中的TLS施加交流电场，并通过光谱学成像来研究TLS。

Result: 交流电场导致TLS稳态光谱消失，并出现持续数分钟的瞬态行为。这种效应在10K以上可通过热循环逆转。LC振荡器的固有损耗因子保持不变。

Conclusion: 交流电场引起的TLS行为改变可能是由脉冲电压引起的应变导致的非平衡能量积累造成的。未来的研究应关注这种非平衡能量及其对TLS动力学的影响。

Abstract: Two-level systems (TLSs) are tunneling states commonly found in amorphous
materials that electrically couple to qubits, resonators, and vibrational modes
in materials, leading to energy loss in those systems. Recent studies suggest
that applying a large alternating electric field changes the oxide structure,
potentially improving the performance of qubits and resonators. In this study,
we probe the effect of alternating bias at cryogenic temperatures on TLS
dynamics within amorphous oxide parallel-plate capacitors operating in the
strongly coupled regime. We bias the TLSs in the capacitors using an electric
field. This allows us to spectroscopically image TLSs and extract their
densities and dipole moments. When an in-situ alternating bias is applied, the
steady-state spectra from the standard TLS model disappear. Post-alternating
bias TLS spectroscopy reveals transient behavior, in which the TLS frequency
fluctuates on the order of minutes. Thermal cycling above 10 K reverses these
effects, restoring the TLS spectrum to its original state, indicating a
reversible mechanism. Importantly, the intrinsic loss tangent of the LC
oscillator remains unchanged before and after the application of the
alternating bias. We propose that the disappearance of the steady-state
spectrum are caused by non-equilibrium energy build up from strain in the oxide
film introduced by the pulsed voltage bias sequence. Understanding this
non-equilibrium energy could inform future models of time-dependent TLS
dynamics.

</details>


### [433] [Optimal scheme for distributed quantum metrology](https://arxiv.org/abs/2509.18334)
*Zhiyao Hu,Allen Zang,Jianwei Wang,Tian Zhong,Haidong Yuan,Liang Jiang,Zain H. Saleem*

Main category: quant-ph

TL;DR: 本研究解决了分布式量子计量学中的最优控制问题，证明了最优控制可以本地实现，从而简化了分布式量子计量学的实施。


<details>
  <summary>Details</summary>
Motivation: 目前最优的量子计量策略主要集中在本地场景，而对于分布式场景，特别是其中最优控制的作用，仍缺乏理解。

Method: 推导出估计N个独立未知参数的线性组合的最优探测态、最优控制协议和测量策略，这些参数与d个网络化传感器耦合。证明了最优控制可以在每个传感器上本地实现。

Result: 最优控制可以在每个传感器上本地实现，无需跨节点的非本地控制操作，大大降低了实施分布式量子计量最优策略的复杂性。

Conclusion: 本研究为分布式量子计量学提供了最优方案，并证明了最优控制可以在每个传感器上本地执行，这对实际应用具有重要意义。

Abstract: Optimal strategies for local quantum metrology -- including the preparation
of optimal probe states, implementation of optimal control and measurement
strategies, are well established. However, for distributed quantum metrology,
where the goal is to estimate global properties of multiple spatially
distributed parameters, the optimal scheme -- particularly the role of optimal
control -- remains poorly understood. In this work, we address this challenge
by developing optimal schemes for distributed quantum metrology that
characterize the ultimate precision limits in distributed systems. We derive
the optimal probe state, optimal control protocols, and measurement strategies
in estimating a linear combination of $N$ independent unknown parameters
coupled to $d$ networked sensors. Crucially, we prove that the optimal control
operations can be implemented locally on each sensor, eliminating the need for
non-local control operations across distant nodes. This result significantly
reduces the complexity of implementing optimal strategies in distributed
quantum metrology. To demonstrate the power of our framework, we apply it to
several key scenarios.

</details>


### [434] [Qubit Instrumentation of Entanglement](https://arxiv.org/abs/2509.18340)
*Mark Carney*

Main category: quant-ph

TL;DR: 该研究通过量化音乐家之间的“音调中心性”，并将其作为参数输入到树莓派 Pico 上的量子模拟中，探索了物理纠缠如何表示和模拟“人类纠缠”。模拟结果被编码回 MIDI 并发送回音乐家的乐器，使得音调越接近，乐器纠缠于 $|oldsymbol{
u}^+angle$ 状态的可能性越大；反之，则越可能纠缠于 $|oldsymbol{
u}^-angle$ 状态。此举旨在创造具有相关性或反相关性的随机参数，为量子音乐表达开辟新途径。


<details>
  <summary>Details</summary>
Motivation: 本研究旨在探索和模拟物理纠缠中的“人类纠缠”，为音乐家提供一种体验和表达量子化音乐的新方式。

Method: 研究通过 MIDI 捕捉音乐家之间的“音调中心性”，将其作为参数输入到树莓派 Pico 上的量子模拟中。模拟结果随后被编码回 MIDI 并发送给音乐家的乐器，以 $|oldsymbol{
u}^+angle$ 和 $|oldsymbol{
u}^-angle$ 状态模拟纠缠。

Result: 实验实现了概念，产生了具有相关性或反相关性的随机参数，为量子音乐表达增加了新的维度，并提供了完整的代码和示例输出。

Conclusion: 本研究为音乐家探索和体验其自身的音乐体验的量子模拟铺平了道路，为“纠缠合奏”的未来带来了新的可能性和细微差别。

Abstract: This chapter and the experiments described within explore how `human
entanglement' might be represented and even emulated by physical entanglement.
To achieve this, a notion of `tonal centrality' between two musicians is
captured via MIDI and passed as a parameter into a quantum simulation taking
place on an embedded device (a Raspberry Pi Pico). The results of these
simulations are then coded back into MIDI and sent to the players' instruments.
The closer the musicians' tonality is, the more their instruments will be
entangled in a $|\Phi^+ \rangle$ state, and the further away they are the more
their instruments will be entangled in a $|\Psi^+ \rangle$ state. The intention
is to create random parameters that are correlative - \emph{i.e.} the same on
both instruments - or anti-correlative - \emph{i.e.} the bit-wise opposite of
each other, influenced by the tonal relationship from the players. These random
parameters sharing these particular properties add a new dimension for
quantum-musical expression. This concept was realised experimentally, and the
full code and sample outputs are provided. This work aims to pave the way for
musicians to explore and experience quantum emulations of their own musical
experiences, adding a new nuance and possibilities for the future of
\emph{entangled ensembles.}

</details>


### [435] [Scalable Steady-State Entanglement with Floquet-Engineered Stabilizer Pumping in Neutral Atom Arrays](https://arxiv.org/abs/2509.18379)
*F. Q. Guo,Shi-Lei Su,Weibin Li,X. Q. Shao*

Main category: quant-ph

TL;DR: 本研究提出了一种在Floquet-Lindblad框架下，通过耗散协议制备中性原子阵列中非平衡稳态纠缠的方法。


<details>
  <summary>Details</summary>
Motivation: 制备非平衡稳态纠缠，为测量基量子计算提供资源状态，并实现被动纠错。

Method: 通过非瞬时诱导的稳定器泵浦，包括共振激光脉冲和失谐的$\	ext{pi}$脉冲，在Floquet-Lindblad框架下实现。

Result: 成功制备了任意多方图态，具有高保真度，且该方案具有可扩展性，对多普勒频移和原子空间涨落具有鲁棒性。

Conclusion: 该耗散方案可扩展且鲁棒，能够高效制备用于量子计算的资源状态，并提供潜在的纠错机制。

Abstract: We propose a dissipative protocol for preparing nonequilibrium steady-state
entanglement in neutral atom arrays within a Floquet-Lindblad framework.
Stabilizer pumping is implemented through noninstantaneous kicks, where each
period consists of a short resonant laser pulse followed by a detuned strong
$\pi$ pulse that couples the atomic ground state to a Rydberg state. This
scheme is intrinsically fast and robust against the Doppler shifts and
interatomic spatial fluctuations, as adiabatic requirements on the laser field
are avoided. As such the engineered dissipation channels induce a fast decay
rate, dramatically accelerating convergence toward the desired steady states.
We show that this approach is inherently scalable and enables high-fidelity
preparation of arbitrary multipartite graph states in the neutral atom array at
zero and finite temperatures. Our study not only facilitates the preparation of
resource states for measurement-based quantum computation but also provides a
passive error-correction mechanism in the undergoing computation.

</details>


### [436] [Observation of synchronization between two quantum van der Pol oscillators in trapped ions](https://arxiv.org/abs/2509.18423)
*Jiarui Liu,Qiming Wu,Joel E. Moore,Hartmut Haeffner,Christopher W. Wächtler*

Main category: quant-ph

TL;DR: 本研究首次在实验中实现了两个量子范德堡振荡器的同步，并探索了其对外部场的响应，为进一步研究量子同步网络奠定了基础。


<details>
  <summary>Details</summary>
Motivation: 在经典系统中，同步现象广泛存在于非线性动力学中，但其在量子极限环振荡器中的实验验证仍有待探索。

Method: 利用囚禁离子实现了两个量子范德堡振荡器的同步，并观察了同步状态下的稳定相对相位，同时个体相位保持不可及。

Result: 成功实现了两个量子范德堡振荡器的同步，并观察到稳定的相对相位。研究了同步系统对外部场的响应。

Conclusion: 本研究首次在量子 regime 下实现了极限环同步，并为探索更大规模量子同步网络中的复杂同步动力学提供了基础，同时保留了量子特性这一开放性问题。

Abstract: Synchronization is a hallmark of nonlinear dynamics. It drives self-organized
behavior across systems ranging from astronomy to chemistry. Among the simplest
systems, the van der Pol oscillator captures the essence of limit-cycle
behavior and forms the basis for diverse physical and biological models. While
mutual synchronization has long been established in classical systems, it has
yet to be experimentally observed in quantum limit-cycle oscillators, despite a
decade of theoretical exploration. Here, we demonstrate synchronization between
two quantum van der Pol oscillators using trapped ions. The synchronized state
manifests itself as a stable relative phase, while the individual oscillator
phases remain inaccessible. In view of potential sensing applications, we
investigate the response of the synchronized system to an external field. Our
results establish limit-cycle synchronization in the quantum regime and pave
the way toward exploring complex synchronized dynamics in larger networks,
where persistence of quantum features remains an open question.

</details>


### [437] [Shift of quantum critical point of discrete time crystal on a noisy quantum simulator](https://arxiv.org/abs/2509.18474)
*Yuta Hirasaki,Toshinari Itoko,Naoki Kanazawa,Eiji Saitoh*

Main category: quant-ph

TL;DR: 本研究使用156量子比特的IBM量子系统，研究了量子比特退相干对量子时间晶体动力学的影响，发现退相干会移动量子相变相关的临界行为的位置，并强调了在近期量子硬件上理解和减轻退相干的重要性。


<details>
  <summary>Details</summary>
Motivation: 近期量子技术在模拟量子多体系统方面取得了进展，但量子模拟器固有的退相干及其对系统动力学（尤其是在量子相变附近）的影响仍未得到充分理解。

Method: 使用156量子比特的IBM量子系统，实验研究了退相干对量子时间晶体动力学的影响。

Result: 退相干会移动与量子相变相关的临界行为的位置，表明有噪声的模拟可能导致相边界识别不准确。

Conclusion: 结果强调了理解和减轻退相干对于在近期量子硬件上可靠地模拟量子多体系统的重要性。

Abstract: Recent advances in quantum technology have enabled the simulation of quantum
many-body systems on real quantum devices. However, such quantum simulators are
inherently subject to decoherence, and its impact on system dynamics -
particularly near quantum phase transitions - remains insufficiently
understood. In this work, we experimentally investigate how decoherence in
quantum devices affects the dynamics of quantum time crystals, using a
156-qubit IBM Quantum system. We find that decoherence shifts the location of
critical behavior associated with the phase transition, suggesting that noisy
simulations can lead to inaccurate identification of phase boundaries. Our
results underscore the importance of understanding and mitigating decoherence
to reliably simulate quantum many-body systems on near-term quantum hardware.

</details>


### [438] [Machine learning approach to single-shot multiparameter estimation for the non-linear Schrödinger equation](https://arxiv.org/abs/2509.18479)
*Louis Rossignol,Tangui Aladjidi,Myrann Baker-Rasooli,Quentin Glorieux*

Main category: quant-ph

TL;DR: 本研究使用卷积神经网络（ConvNeXt）和多元高斯负对数似然损失函数，将参数估计视为逆问题，通过单次测量图像（密度和相位）准确估计非线性薛定谔方程（NLSE）的关键参数（非线性系数 $n_2$、饱和强度 $I_{sat}$ 和线性吸收系数 $\alpha$）。


<details>
  <summary>Details</summary>
Motivation: 从单次测量中准确估计非线性薛定谔方程（NLSE）的参数，这些参数通常是强相关的，仍然是一个重大挑战。

Method: 将参数估计视为逆问题，训练神经网络来反演NLSE映射。结合了快速数值求解器、基于ConvNeXt架构的机器学习方法以及多元高斯负对数似然损失函数。

Result: 在100,000张模拟图像上训练的模型，在12,500个未见过测试样本上实现了3.22%的平均绝对误差，证明了强大的泛化能力和与真实值的高度一致性。

Conclusion: 该方法为表征非线性系统提供了一条有效的途径，并且在考虑实际噪声时，有潜力在理论模型和实验数据之间架起桥梁。

Abstract: The nonlinear Schr\"odinger equation (NLSE) is a fundamental model for wave
dynamics in nonlinear media ranging from optical fibers to Bose-Einstein
condensates. Accurately estimating its parameters, which are often strongly
correlated, from a single measurement remains a significant challenge. We
address this problem by treating parameter estimation as an inverse problem and
training a neural network to invert the NLSE mapping. We combine a fast
numerical solver with a machine learning approach based on the ConvNeXt
architecture and a multivariate Gaussian negative log-likelihood loss function.
From single-shot field (density and phase) images, our model estimates three
key parameters: the nonlinear coefficient $n_2$, the saturation intensity
$I_{sat}$, and the linear absorption coefficient $\alpha$. Trained on 100,000
simulated images, the model achieves a mean absolute error of $3.22\%$ on
12,500 unseen test samples, demonstrating strong generalization and close
agreement with ground-truth values. This approach provides an efficient route
for characterizing nonlinear systems and has the potential to bridge
theoretical modeling and experimental data when realistic noise is
incorporated.

</details>


### [439] [Characterizing Noise in Controlling Superconducting Qubits](https://arxiv.org/abs/2509.18482)
*Yuanzheng Paul Tan,Yung Szen Yap,Long Hoang Nguyen,Rangga P. Budoyo,Patrick Bore,Kun Hee Park,Christoph Hufnagel,Rainer Dumke*

Main category: quant-ph

TL;DR: 量子计算受限于NISQ设备的错误率，提高保真度需要识别错误源。本研究调查了噪声对超导量子比特控制脉冲的影响，并观察到门保真度与信噪比的依赖关系。我们提出了一个模型来描述噪声与量子比特系统的相互作用，并展示了一种表征噪声环境的方法。


<details>
  <summary>Details</summary>
Motivation: 识别NISQ设备中导致量子逻辑门错误的操作，包括背景噪声。

Method: 提出一个模型，研究控制电子学中的噪声与量子比特系统的交互作用。通过调整信号与噪声的比率来观察门保真度的变化。

Result: 门保真度与信噪比的依赖关系。

Conclusion: 本研究提出了一个噪声模型，并展示了一种对量子比特控制噪声环境进行表征的方法。

Abstract: Meaningful quantum computing is currently bottlenecked by the error rates of
current generation Noisy Intermediate Scale Quantum (NISQ) devices. To improve
the fidelity of the quantum logic gates, it is essential to recognize the
contributions of various sources of errors, including background noise. In this
work, we investigate the effects of noise when applied to superconducting qubit
control pulses to observe the dependency of the gate fidelity with the
signal-to-noise ratio (SNR). We propose a model on how the noise of the control
electronics interacts with the qubit system and demonstrate a method for
characterizing the noise environment of the qubit control.

</details>


### [440] [Mitigating Phase Correlations in Quantum Key Distribution Using Path-Selection Modulation](https://arxiv.org/abs/2509.18490)
*Amita Gnanapandithan,Li Qian,Hoi-Kwong Lo*

Main category: quant-ph

TL;DR: 利用“路径选择调制”光源，消除对主动相位调制器和诱导侧信道的需求，以增强量子密钥分发（QKD）的安全性。


<details>
  <summary>Details</summary>
Motivation: 量子密钥分发（QKD）中存在的相位相关性是一个未被充分探索的漏洞，可能危及通信安全。

Method: 提出并实现了一种“路径选择调制”光源，该光源通过在多个路径之间进行随机选择来编码量子态，避免了使用主动相位调制器，从而消除了与之相关的侧信道漏洞。利用增益切换技术实现相位随机化，并在1 GHz的时钟速率下进行了表征。

Result: 该光源成功地在高达1 GHz的重复率下进行了实验和模拟表征，证明了其在消除相位相关性漏洞方面的有效性。

Conclusion: 所提出的“路径选择调制”光源为解决QKD中的相位相关性侧信道问题提供了一种有效的解决方案，有望提高QKD系统的整体安全性。

Abstract: Phase correlations are an under-explored vulnerability in QKD. Here, we
present an experimental and simulated characterization of correlations arising
from electro-optic phase encoding, over repetition rates up to the GHz level.
To mitigate this vulnerability (and all side channels arising from active phase
modulators), we propose a "path-selection modulation" source that eliminates
the need for active phase modulation altogether. Encoding is achieved by
randomly selecting between multiple paths, each path corresponding to one of
the desired encoded states. Phase randomization is achieved using
gain-switching. We characterize this source at a clock rate of 1 GHz.

</details>


### [441] [Re-uploading quantum data: A universal function approximator for quantum inputs](https://arxiv.org/abs/2509.18530)
*Hyunho Cha,Daniel K. Park,Jungwoo Lee*

Main category: quant-ph

TL;DR: 通过量子数据重编码技术，可以仅使用一个辅助量子比特和单量子比特测量来近似任何有界连续函数，为处理量子数据提供了一种高效且富有表现力的方法。


<details>
  <summary>Details</summary>
Motivation: 在量子数据上探索量子数据重编码的潜力，因为量子态中的信息不易以经典形式访问。

Method: 提出并分析了一种量子数据重编码架构，其中一个量子比特与输入状态的新的副本进行顺序交互。通过交替使用纠缠酉变换和输入寄存器的中程重置，可以实现完全正迹保持映射的离散级联。

Result: 该量子数据重编码架构可以近似任何有界连续函数，并且只需要一个辅助量子比特和单量子比特测量。

Conclusion: 该框架提供了一种量子比特效率高且富有表现力的方法，用于设计直接在量子数据上操作的量子机器学习模型。

Abstract: Quantum data re-uploading has proved powerful for classical inputs, where
repeatedly encoding features into a small circuit yields universal function
approximation. Extending this idea to quantum inputs remains underexplored, as
the information contained in a quantum state is not directly accessible in
classical form. We propose and analyze a quantum data re-uploading architecture
in which a qubit interacts sequentially with fresh copies of an arbitrary input
state. The circuit can approximate any bounded continuous function using only
one ancilla qubit and single-qubit measurements. By alternating entangling
unitaries with mid-circuit resets of the input register, the architecture
realizes a discrete cascade of completely positive and trace-preserving maps,
analogous to collision models in open quantum system dynamics. Our framework
provides a qubit-efficient and expressive approach to designing quantum machine
learning models that operate directly on quantum data.

</details>


### [442] [Universality in fidelity-based quantum metrology](https://arxiv.org/abs/2509.18533)
*Luis Aragón-Muñoz,Chryssomalis Chryssomalakos,Ana Gabriela Flores-Delgado,John Martin,Eduardo Serrano-Ensástiga*

Main category: quant-ph

TL;DR: 某些量子自旋态在作为传感器时表现出普适的最优或最差性能，不依赖于所探测的具体变换。


<details>
  <summary>Details</summary>
Motivation: 确定哪些量子自旋态能够最优地作为给定变换的传感器，并考虑所有可能的自旋系统定向。

Method: 使用基于保真度判据的几何方法，该方法适用于幺正变换（如旋转和压缩）和非幺正变换（如洛伦兹变换）。

Result: 发现存在一个零测度子集的状态，这些状态对于某些变换是最佳传感器，而对于其他变换则是最差传感器，并且这个集合与变换本身无关。

Conclusion: 存在一些自旋态，无论它们用于检测什么变换，始终是最佳或最差的传感器。

Abstract: We consider the problem of identifying the quantum spin states that are the
optimal sensors of a given transformation averaged over all possible
orientations of the spin system. Our geometric approach to the problem is based
on a fidelity criterion and is entirely general, encompassing both unitary
transformations (such as rotations and squeezing) and non-unitary
transformations (such as Lorentz boosts). This formalism leads to a
universality result: There exists a zero-measure subset of states that will be
optimal sensors for certain transformations and the worst sensors for others,
and this set does not depend on the transformation under consideration. In
other words, some spin states are simply the best (or worst) sensors,
regardless of what they detect.

</details>


### [443] [Robust quantum communication through lossy microwave links](https://arxiv.org/abs/2509.18547)
*James D. Teoh,Nathanael Cottet,Patrick Winkel,Luke D. Burkhart,Luigi Frunzio,Robert J. Schoelkopf*

Main category: quant-ph

TL;DR: 通过利用微波链路中的驻波模式和局部测量，我们提出了一种新的信号辅助纠缠生成方案，以高保真度（92±1%）在分离的超导比特之间生成贝尔态，即使在光子损耗严重的情况下也能实现，并成功地将此作为资源进行了确定性量子隐形传态，平均保真度达到90±1%。


<details>
  <summary>Details</summary>
Motivation: 为了克服超导量子网络中光子损耗对纠缠保真度的限制，并为分布式量子计算提供支持。

Method: 利用微波链路中的驻波模式和对玻色子编码量子进行局部测量，实现信号辅助纠缠生成，并以此为资源进行确定性量子隐形传态。

Result: 在高达2%的单光子传输效率的条件下，实现了92±1%的贝尔态保真度和90±1%的量子比特传输保真度。

Conclusion: 该方案表明，在高损耗的微波通信中，快速的耦合速率和低损耗链路不再是高保真度量子通信的严格要求，为未来超导量子网络的设计提供了指导。

Abstract: Entanglement generation lies at the heart of many quantum networking
protocols as it enables distributed and modular quantum computing. For
superconducting qubits, entanglement fidelity is typically limited by photon
loss in the links that connect these qubits together. We propose and realize a
new scheme for heralded entanglement generation that almost entirely
circumvents this limit. We produce Bell states with $92\pm1\%$ state fidelity,
including state preparation and measurement (SPAM) errors, between separated
superconducting bosonic qubits in a high-loss regime where direct deterministic
state transfer fails. Our scheme exploits simple but fundamental physics found
in microwave links, specifically the ability to treat our communication channel
as a single standing wave mode. Combining this with local measurements on
bosonically encoded qubits allows us to herald entanglement with success
probabilities approaching the scheme's upper limit of 50% per attempt. We then
use the heralded Bell state as a resource to deterministically teleport a qubit
between modules with an average state transfer fidelity of $90\pm1\%$. This is
achieved despite the link possessing a direct single photon transfer efficiency
of 2%. Our work informs the design of future superconducting quantum networks,
by demonstrating fast coupling rates and low loss links are no longer strict
requirements for high-fidelity quantum communication in the microwave regime.

</details>


### [444] [Compressed Permutation Oracles](https://arxiv.org/abs/2509.18586)
*Joseph Carolan*

Main category: quant-ph

TL;DR: 该论文开发了一种压缩置换预言机，用于分析量子算法在查询随机、可逆置换时的密码学问题，并解决了 Feistel 网络和多种密码学原语的量子安全性证明问题。


<details>
  <summary>Details</summary>
Motivation: 许多现有的密码学技术在应用于随机预言机时会失效或无法推广到随机置换，导致基于置换的密码学结构缺乏量子安全证明。本研究旨在弥补这一差距。

Method: 提出并证明了一种压缩置换预言机的健全性，该预言机具有类似 Zhandry 压缩函数预言机的特性，能够通过少量输入-输出来反映算法对预言机的了解程度。在此基础上，证明了七轮 Feistel 结构是强量子伪随机排列（PRP），并重新证明了 Sponge 和 Davies-Meyer 结构在碰撞和原像抵抗性方面的量子查询下界，以及双向零搜索、稀疏谓词搜索的困难性，并给出了循环查找和 one-more 问题的新下界。

Result: 成功开发了压缩置换预言机，并证明了七轮 Feistel 结构是强量子 PRP。此外，还重新证明了多种密码学原语（如 Sponge、Davies-Meyer）在碰撞和原像抵抗性方面的已知量子查询下界，并为循环查找和 one-more 问题提供了新的下界。

Conclusion: 本研究为解决密码学中量子算法分析的挑战提供了新的框架，并通过应用该框架证明了 Feistel 结构和多种密码学原语的量子安全性。

Abstract: The analysis of quantum algorithms which query random, invertible
permutations has been a long-standing challenge in cryptography. Many
techniques which apply to random oracles fail, or are not known to generalize
to this setting. As a result, foundational cryptographic constructions
involving permutations often lack quantum security proofs. With the aim of
closing this gap, we develop and prove soundness of a compressed permutation
oracle. Our construction shares many of the attractive features of Zhandry's
original compressed function oracle: the purification is a small list of
input-output pairs which meaningfully reflect an algorithm's knowledge of the
oracle.
  We then apply this framework to show that the Feistel construction with seven
rounds is a strong quantum PRP, resolving an open question of (Zhandry, 2012).
We further re-prove essentially all known quantum query lower bounds in the
random permutation model, notably the collision and preimage resistance of both
Sponge and Davies-Meyer, hardness of double-sided zero search and sparse
predicate search, and give new lower bounds for cycle finding and the one-more
problem.

</details>


### [445] [Scalable bayesian shadow tomography for quantum property estimation with set transformers](https://arxiv.org/abs/2509.18674)
*Hyunho Cha,Wonjung Kim,Jungwoo Lee*

Main category: quant-ph

TL;DR: 本研究介绍了一种可扩展的贝叶斯机器学习框架，用于从测量数据中估计未知量子态的标量属性，无需进行完整的密度矩阵重建。


<details>
  <summary>Details</summary>
Motivation: 该框架首次将经典阴影协议与置换不变集Transformer架构相结合，以预测和纠正现有估计器的偏差，从而逼近真实的贝叶斯后验均值。

Method: 测量结果被编码为固定维度的特征向量，网络输出对基线估计器的残差校正。通过输入大小与系统大小和测量次数的依赖性为多项式，确保了对大型量子系统的可扩展性。

Result: 在量子态保真度和二阶Rényi熵估计任务中，使用随机泡利和随机Clifford测量，该贝叶斯估计器在副本数量较少的情况下，均方误差始终低于单独使用经典阴影的方法，降低幅度超过99%。

Conclusion: 该贝叶斯机器学习框架在估计量子态标量属性方面，相比于现有方法具有显著的优势，尤其是在数据量有限的情况下。

Abstract: A scalable Bayesian machine learning framework is introduced for estimating
scalar properties of an unknown quantum state from measurement data, which
bypasses full density matrix reconstruction. This work is the first to
integrate the classical shadows protocol with a permutation-invariant set
transformer architecture, enabling the approach to predict and correct bias in
existing estimators to approximate the true Bayesian posterior mean.
Measurement outcomes are encoded as fixed-dimensional feature vectors, and the
network outputs a residual correction to a baseline estimator. Scalability to
large quantum systems is ensured by the polynomial dependence of input size on
system size and number of measurements. On Greenberger-Horne-Zeilinger state
fidelity and second-order R\'enyi entropy estimation tasks -- using random
Pauli and random Clifford measurements -- this Bayesian estimator always
achieves lower mean squared error than classical shadows alone, with more than
a 99\% reduction in the few copy regime.

</details>


### [446] [Barycentric decompositions for extensive monotone divergences](https://arxiv.org/abs/2509.18725)
*Erkka Haapasalo*

Main category: quant-ph

TL;DR: test spectrum characterizes divergences in a generalized real-algebraic setting, with implications for classical and quantum divergences.


<details>
  <summary>Details</summary>
Motivation: To study sets of divergences/dissimilarity measures in a generalized real-algebraic setting, encompassing classical and quantum multivariate divergences.

Method: Characterization of divergences using the 'test spectrum' through barycenters and extreme points. Full characterization of the test spectrum in the classical case and analysis of its composition in the quantum case.

Result: The test spectrum characterizes all other divergences. Extreme points of relevant convex subsets are within the test spectrum. Classical multivariate divergences are fully characterized. In the quantum case, previously suggested divergences are within the test spectrum and are extreme points, suggesting their independence.

Conclusion: The test spectrum is a key concept for understanding divergences. The findings highlight the real variability and independence of previously suggested quantum divergences.

Abstract: We study sets of divergences or dissimilarity measures in a generalized
real-algebraic setting which includes the cases of classical and quantum
multivariate divergences. We show that a special subset of divergences, the
so-called test spectrum, characterizes the rest of the divergences through
barycentres and that the extreme points of relevant convex subsets of general
divergences are contained within the test spectrum. Only some special parts of
the test spectrum may contain non-extreme elements. We are able to fully
characterize the test spectrum in the case of classical multivariate
divergences. The quantum case is much more varied, and we demonstrate that
essentially all the bivariate and multivariate quantum divergences suggested
previously in literature are within the test spectrum and extreme within the
set of all quantum (multivariate) divergences. This suggests that the
variability of quantum divergences is real since all the previously suggested
divergences are independent of each other.

</details>


### [447] [Bell state measurements in quantum optics: a review of recent progress and open challenges](https://arxiv.org/abs/2509.18756)
*Luca Bianchi,Carlo Marconi,Davide Bacco*

Main category: quant-ph

TL;DR: BMS are crucial for quantum information processing, but difficult to implement with linear optics in photonic platforms. This review examines existing proposals, their limitations, and strategies to overcome them, also surveying advances in high-dimensional systems for scalable quantum networks and high-capacity communication.


<details>
  <summary>Details</summary>
Motivation: BMS are central to quantum information processing tasks like teleportation, entanglement swapping, and fusion-gate quantum computation. Efficient BMS are challenging in photonic platforms using linear optics.

Method: The paper reviews existing proposals for implementing BMS in photonic platforms, discusses their fundamental limitations, and explores strategies to overcome them. It also surveys recent advances in BMS for high-dimensional systems.

Result: The review provides a comprehensive examination of existing proposals for BMS, highlighting their limitations and strategies to overcome them. Recent advances in high-dimensional BMS are also surveyed.

Conclusion: Efficient BMS, especially in high-dimensional systems, are crucial for advancing quantum networks and communication, despite the challenges posed by linear optics in photonic platforms.

Abstract: Bell state measurements, which project bipartite qubit systems onto the
maximally entangled Bell basis, are central to a wide range of quantum
information processing tasks, including quantum teleportation, entanglement
swapping, and fusion-gate quantum computation. In photonic quantum platforms,
where information is encoded in optical degrees of freedom, the realization of
efficient Bell state measurements is particularly challenging, especially when
constrained to linear optical elements. In this review, we provide a
comprehensive examination of existing proposals for implementing Bell state
measurements, highlighting their fundamental limitations and the strategies
developed to overcome them. Additionally, we survey recent advances in Bell
state measurements for high-dimensional systems, an area of growing interest
due to its relevance in scalable quantum networks and high-capacity quantum
communication.

</details>


### [448] [Virtual Quantum Markov Chain of four-qubit systems](https://arxiv.org/abs/2509.18803)
*Zhixing Chen,Lin Chen*

Main category: quant-ph

TL;DR: 将量子马尔可夫链框架扩展到四方子系统，并分析其结构标准，证明了 W 态是 VQMC，而 GHZ 态不是，同时提出了用于测试可恢复性和量化采样开销的 SDP 公式。


<details>
  <summary>Details</summary>
Motivation: 将现有的三方量子马尔可夫链（VQMC）框架扩展到四方子系统，以研究多方量子系统中的相关性和可恢复性。

Method: 分析了 VQMC 的结构标准（如核包含条件），并使用四方 W 态和 GHZ 态的显式示例进行验证。此外，还开发了用于测试可恢复性和量化采样开销的半定规划（SDP）方法，并通过混合状态反例建立了 VQMC 集合的非凸性。

Result: 研究表明，四方 W 态满足 VQMC 的条件，可以恢复，而 GHZ 态则不能。提出了 SDP 公式来测试可恢复性并量化采样开销。通过混合状态反例证明了 VQMC 集合的非凸性。

Conclusion: 对四方 VQMC 的分析提供了理论见解和计算工具，以研究多方量子系统中的相关性和可恢复性。 W 态是 VQMC，而 GHZ 态不是，并且 VQMC 集合是非凸的。

Abstract: We extend the framework of virtual quantum Markov chains (VQMCs) from
tripartite systems to the four-qubit setting. Structural criteria such as the
kernel-inclusion condition are analyzed, showing that they are necessary but
not sufficient for the existence of a valid recovery map. By explicit examples,
we demonstrate that the four-qubit W state admits a recovery channel and thus
qualifies as a VQMC, while the GHZ state does not. We further provide
semidefinite programming (SDP) formulations to test recoverability and quantify
sampling overhead, and establish the non-convexity of the VQMC set through
mixed-state counterexamples. These results supply both theoretical insights and
computational tools for studying correlations and recoverability in
multipartite quantum systems.

</details>


### [449] [Quantum-memory-assisted on-demand microwave-optical transduction](https://arxiv.org/abs/2509.18834)
*Hai-Tao Tu,Kai-Yu Liao,Si-Yuan Qiu,Xiao-Hong Liu,Yi-Qi Guo,Zheng-Qi Du,Yang Xu,Xin-Ding Zhang,Hui Yan,Shi-Liang Zhu*

Main category: quant-ph

TL;DR: 使用Rydberg原子系综实现了内存增强的微波-光学转换，存储效率>90%，带宽2.1MHz，噪声等效温度26K。


<details>
  <summary>Details</summary>
Motivation: 微波-光学转换器和量子存储器是量子中继器的关键组成部分，但两者的集成具有挑战性。

Method: 利用级联电磁诱导透明过程，将微波光子存储在里德堡原子高度激发态，并在检索过程中将其转换为光学光子。

Result: 实现了大于90%的面积归一化存储效率，2.1MHz的带宽，以及26K的低噪声等效温度（无腔体）。

Conclusion: 该研究为基于原子系综的量子中继器在量子信息处理中的实际应用铺平了道路。

Abstract: Microwave-optical transducers and quantum memories are fundamental components
of quantum repeaters, essential for developing a quantum internet in which
solid-state quantum computers serve as nodes interconnected by optical fibers
for data transmission. Although both technologies have made significant
advancements, the integration of microwave-optical conversion and quantum
memory functionalities remains a challenge. Here, we theoretically propose and
experimentally demonstrate a memoryenhanced quantum microwave-optical
transduction using a Rydberg ensemble. By utilizing a cascaded
electromagnetically induced transparency process, we store microwave photons in
a highly excited collective state and subsequently convert them into optical
photons during the retrieval process. Taking advantage of the optical depth
with order of millions for microwave photons in Rydberg ensemble, combined with
a minimal storage dephasing rate at the single-photon level, the transducer
achieves an areanormalized storage efficiency greater than 90%, a bandwidth of
2.1 MHz, and a noise equivalent temperature as low as 26 K, even in cavity-free
conditions. Our findings pave the way for the practical implementation of
quantum repeaters based on atomic ensembles in quantum information processing.

</details>


### [450] [Trading modes against energy](https://arxiv.org/abs/2509.18854)
*Lukas Brenner,Beatriz Dias,Robert Koenig*

Main category: quant-ph

TL;DR: 该研究探讨了在混合量子比特-振荡器模型中，使用酉线路进行弱模拟n量子比特量子电路所需的能量。研究发现，可以通过（1）线性数量的玻色子模式和多项式能量，（2）亚线性数量的模式和亚指数能量，或（3）恒定数量的模式和指数能量来实现高效的近似弱模拟。


<details>
  <summary>Details</summary>
Motivation: 探究在混合量子比特-振荡器模型中，使用酉线路进行弱模拟n量子比特量子电路所需的能量。

Method: 通过将量子比特编码到高维的近似GKP码中，并利用Jaynes-Cummings哈密顿量将玻色子模式耦合到量子比特。

Result: 研究结果表明，可以通过三种不同的资源权衡（模式数量与能量消耗）来实现高效的近似弱模拟：1. 线性数量的模式和多项式能量；2. 亚线性数量的模式和亚指数能量；3. 恒定数量的模式和指数能量。

Conclusion: 该研究揭示了在连续变量设置中，系统规模（模式数量）与执行量子计算所需的能量之间存在权衡关系。

Abstract: We ask how much energy is required to weakly simulate an $n$-qubit quantum
circuit (i.e., produce samples from its output distribution) by a unitary
circuit in a hybrid qubit-oscillator model. The latter consists of a certain
number of bosonic modes coupled to a constant number of qubits by a
Jaynes-Cummings Hamiltonian. We find that efficient approximate weak simulation
of an $n$-qubit quantum circuit of polynomial size with inverse polynomial
error is possible with
  (1) a linear number of bosonic modes and a polynomial amount of energy, or
  (2) a sublinear (polynomial) number of modes and a subexponential amount of
energy, or
  (3) a constant number of modes and an exponential amount of energy. Our
construction encodes qubits into high-dimensional approximate
Gottesman-Kitaev-Preskill (GKP) codes. It provides new insight into the
trade-off between system size (i.e., number of modes) and the amount of energy
required to perform quantum computation in the continuous-variable setting.

</details>


### [451] [Braiding of dynamical eigenvalues of Hermitian bosonic Kitaev chains](https://arxiv.org/abs/2509.18879)
*Heming Wang,Shanhui Fan*

Main category: quant-ph

TL;DR: 量子系统中的动力学特征值可以形成辫子结构，尤其是在有效的增益和损耗区域。


<details>
  <summary>Details</summary>
Motivation: 研究具有多个能带的厄米玻色子Kitaev链中动力学特征值的辫子结构。

Method: 通过分析动力学矩阵的复数特征值及其对称性约束，并利用系统中的卓越点来显式构造辫子结构。

Result: 证明了动力学特征值的对称性约束仍然允许在复平面的有效增益和损耗区域内形成辫子；显式构造了两股和三股辫子。

Conclusion: 在具有多个能带的厄米玻色子Kitaev链中，动力学特征值可以通过卓越点形成辫子结构，这在有效的增益和损耗区域是可能的，并讨论了实现的方案。

Abstract: In quantum mechanics, observables correspond to Hermitian operators, and the
spectra are restricted to be real. However, the dynamics of the underlying
fields may allow complex eigenvalues and therefore create the possibility of
braiding structures. Here we study the braiding of dynamical eigenvalues in
quantum systems by considering Hermitian bosonic Kitaev chains with multiple
bands. The dynamics of the quantum fields in these systems are described by
their dynamic matrices, which have complex eigenvalues. We show that there are
symmetry constraints imposed on these dynamic eigenvalues. Despite these
constraints, braiding is possible for frequencies within the effective gain and
loss regions of the complex plane. We explicitly construct two- and
three-strand braidings using the exceptional points found in the system and
discuss possible implementations.

</details>


### [452] [Diffusive Stochastic Master Equation (SME) with dispersive qubit/cavity coupling](https://arxiv.org/abs/2509.18925)
*Pierre Rouchon*

Main category: quant-ph

TL;DR: 该论文提供了扩散随机主方程（SME）在描述具有色散耦合的量子比特/腔系统方面的详细分析，该分析包含了经典输入/输出信号。研究表明，量子比特/腔密度算符的动力学指数收敛于一个缓慢不变流形，该流形由一个虚构量子比特的密度算符通过一个时变确定性Kraus图参数化。该虚构量子比特受一个包含经典输入/输出信号的SME控制。论文还将其扩展到描述由任意模式和集体输入/输出信号组成的系统的动力学。


<details>
  <summary>Details</summary>
Motivation: 该研究的动机在于提供对具有色散耦合的量子比特/腔系统使用扩散随机主方程（SME）的深入分析，并考虑经典输入/输出信号的影响。

Method: 通过分析扩散随机主方程（SME），展示量子比特/腔密度算符的动力学如何指数收敛到一个由虚构量子比特的密度算符参数化的缓慢不变流形，该流形由一个时变确定性Kraus图表示。虚构量子比特的动力学由一个包含经典输入/输出信号的SME控制。

Result: 研究表明，量子比特/腔密度算符的动力学指数收敛到一个缓慢不变流形，该流形可以通过时变确定性Kraus图表示，并受一个虚构量子比特的SME控制。该方法被成功扩展到更一般的系统。

Conclusion: 该分析为理解和模拟具有色散耦合的量子比特/腔系统（包括经典输入/输出信号）提供了一个有效框架。研究结果表明，系统动力学可以被简化为在缓慢不变流形上的演化，并由一个虚构量子比特的SME控制。

Abstract: A detailed analysis of the diffusive Stochastic Master Equation (SME) for
qubit/cavity systems with dispersive coupling is provided. This analysis
incorporates classical input signals and output signals (measurement outcomes
through homodyne detection). The dynamics of the qubit/cavity density operator
is shown to converge exponentially towards a slow invariant manifold,
parameterized via a time-varying deterministic Kraus map by the density
operator of a fictitious qubit. This fictitious qubit is governed by a SME
incorporating the classical input/output signals. Extension where the qubit is
replaced by any qudit dispersively coupled to an arbitrary set of modes with
collective input/output classical signals.

</details>


### [453] [Quantum Random Synthetic Skyrmion Texture Generation, a Qiskit Simulation](https://arxiv.org/abs/2509.18947)
*Hillol Biswas*

Main category: quant-ph

TL;DR: 该论文研究了利用量子计算合成生成斯 পরিস্থিতির纹理的可能性。


<details>
  <summary>Details</summary>
Motivation: 斯 পরিস্থিতি作为拓扑自旋结构，具有整数绕组数（拓扑荷），能够被用作量子比特（qubits）。本研究的动机在于探索利用量子计算来合成生成斯 परिस्थिती纹理，以期开辟基于量子随机性和其他标准的斯 परिस्थिती研究新方向。

Method: 通过量子计算生成了数百种不同的斯 परिस्थिती纹理，并进行了样本比较。

Result: 成功生成了多种斯 परिस्थिती纹理，并通过样本比较展示了其多样性。

Conclusion: 研究表明，利用量子计算合成生成斯 परिस्थिती纹理是可行的，并为相关研究指明了新方向。

Abstract: An integer winding, i.e., topological charge, is a characteristic of
skyrmions, which are topologically nontrivial spin patterns in magnets. They
emerge when smooth two-dimensional spin configurations are stabilized by
conflicting interactions such as exchange, anisotropy, the
Dzyaloshinskii-Moriya interaction, or geometric frustration. These nanoscale
textures, which are typically a few to tens of nanometers in size, are strong
'particle-like' excitations because they are shielded by energy barriers
connected to their topology. By exploiting their helicity, i.e., spin rotation
angle or associated internal modes, as a two-level system, skyrmions can
function as quantum bits or qubits. Two quantized helicity states of a
nanometer-scale skyrmion encode the logical value states in a 'skyrmion qubit.'
Interestingly, skyrmion qubits are topologically protected and macroscopic,
i.e., they involve a large number of spins; however, external influences can
still affect them. When the texture is tiny and disconnected, the helicity
angle of the skyrmion becomes quantized. A qubit basis is made up of the lowest
two energy eigenstates, i.e., symmetric or antisymmetric superpositions of
opposite helicity, for example. Therefore, Skyrmion textures can provide
valuable insights for different purposes. However, is it possible to
synthetically generate skyrmion textures using quantum computing? This paper
investigates the possibility and generates a few hundred different textures,
producing sample comparisons from various types, which indicate a novel
direction for skyrmion-based research based on quantum randomness and other
criteria.

</details>


### [454] [Quantum Annealing for Minimum Bisection Problem: A Machine Learning-based Approach for Penalty Parameter Tuning](https://arxiv.org/abs/2509.19005)
*Renáta Rusnáková,Martin Chovanec,Juraj Gazda*

Main category: quant-ph

TL;DR: 本研究使用量子退火和机器学习方法解决最小二分问题，并在实验中优于经典算法。


<details>
  <summary>Details</summary>
Motivation: 最小二分问题是组合优化中的一个著名NP困难问题，在并行计算、网络设计和机器学习等领域有实际应用。本研究旨在探索使用D-Wave量子退火求解器解决最小二分问题的潜力。

Method: 将最小二分问题建模为二次无约束二元优化（QUBO）问题，并提出一种基于梯度增强回归器的机器学习方法，用于自适应调整QUBO模型中的惩罚参数。该方法根据输入图的结构属性、节点数和密度来预测合适的惩罚参数值。

Result: 在包含多达4000个节点的随机Erdos-Renyi图的大型数据集上测试了该方法，并与经典的Metis和Kernighan-Lin算法进行了比较。实验结果表明，所提出的自适应调整策略显著提高了量子退火混合求解器的性能，并始终优于所使用的经典方法。

Conclusion: 所提出的基于机器学习的自适应惩罚参数调整方法能够有效提高量子退火求解器在最小二分问题上的性能，并优于Metis和Kernighan-Lin等经典算法，显示了其在图划分问题上的应用潜力。

Abstract: The Minimum Bisection Problem is a well-known NP-hard problem in
combinatorial optimization, with practical applications in areas such as
parallel computing, network design, and machine learning. In this paper, we
examine the potential of using D-Wave Systems' quantum annealing solvers to
solve the Minimum Bisection Problem, which we formulate as a Quadratic
Unconstrained Binary Optimization model. A key challenge in this formulation
lies in choosing an appropriate penalty parameter, as it plays a crucial role
in ensuring both the quality of the solution and the satisfaction of the
problem's constraints. To address this, we introduce a novel machine
learning-based approach for adaptive tuning of the penalty parameter.
Specifically, we use a Gradient Boosting Regressor model trained to predict
suitable penalty parameter values based on structural properties of the input
graph, the number of nodes and the graph's density. This method enables the
penalty parameter to be adjusted dynamically for each specific problem
instance, improving the solver's ability to balance the competing goals of
minimizing the cut size and maintaining equally sized partitions. We test our
approach on a large dataset of randomly generated Erd\H{o}s-R\'enyi graphs with
up to 4,000 nodes, and we compare the results with classical partitioning
algorithms, Metis and Kernighan-Lin. Experimental findings demonstrate that our
adaptive tuning strategy significantly improves the performance of the quantum
annealing hybrid solver and consistently outperforms the classical methods
used, indicating its potential as an alternative for the graph partitioning
problem.

</details>


### [455] [High harmonic generation from a Bose-Einstein condensate](https://arxiv.org/abs/2509.19022)
*Philipp Stammer*

Main category: quant-ph

TL;DR: 利用Bose-Einstein凝聚体进行高次谐波产生，连接了超冷温度下的物质波和超快阿秒时间尺度的辐射爆发。


<details>
  <summary>Details</summary>
Motivation: 本文的动机是将超冷原子研究中的Bose-Einstein凝聚体与高次谐波产生领域联系起来，以前这两个领域是独立研究的。

Method: 通过探索Bose-Einstein凝聚体产生高次谐波。

Result: 实现了超冷温度下的物质波与超快阿秒时间尺度的辐射爆发的连接。

Conclusion: 本文成功地将Bose-Einstein凝聚体作为高次谐波产生的源，实现了超冷物质波与超快辐射的耦合。

Abstract: Lasers provide intense coherent radiation, essential to cool and trap atoms
into a Bose-Einstein condensate or can alternatively drive the non-linear
dynamics of high-order harmonic generation. Yet, these two fundamental
processes remained of independent consideration. Here, we connect matter waves
at ultracold temperatures with radiation bursts on the ultrafast attosecond
timescale. We do this by exploring high harmonic generation from a
Bose-Einstein condensate.

</details>


### [456] [Improving QAOA to find approximate QUBO solutions in O(1) shots](https://arxiv.org/abs/2509.19035)
*A. Yu. Chernyavskiy,D. A. Kulikov,B. I. Bantysh,Yu. I. Bogdanov,A. K. Fedorov,E. O. Kiktenko*

Main category: quant-ph

TL;DR: QAOA在解决组合优化问题方面有巨大潜力，但面临噪声和退火退化等挑战。本文提出了一种改进的固定点QAOA（fpQAOA）方案，结合了概率目标、正弦-余弦编码和系数矩阵重缩放，显著减少了获得近似解所需的量子比特数量，并有望实现O(1)量子比特复杂度，而电路深度保持二次方增长。单独移除这些改进中的任何一个都会导致所需量子比特数量随着问题规模呈指数增长。


<details>
  <summary>Details</summary>
Motivation: QAOA作为解决组合优化问题的强大量子框架，在实际应用中尤其是在二次无约束二元优化（QUBO）问题上，显示出巨大潜力。然而，其混合量子-经典实现面临统计噪声和退火退化等严峻挑战。固定点QAOA（fpQAOA）是一种有前景的解决方案，通过在小问题实例上训练参数并在将其转移到大问题实例来缓解这些问题。

Method: 本文提出了一种改进的fpQAOA方案，其特点包括：(i) 关注获得目标近似比（AR）的概率，而非精确的最优解；(ii) 将层数设置为问题大小，并采用QAOA角度的正弦-余弦编码；(iii) 将问题系数矩阵重缩放到单位弗罗贝尼厄斯范数。

Result: 该组合方法使得获得近似解所需的介数量（median number）随着问题规模的增加而减少，并且对于所考虑的问题类别，AR值与最优值相差仅在百分之几之内。结果外推表明，在保持二次方电路深度的同时，具有O(1)量子比特复杂度。

Conclusion: 本文提出的改进fpQAOA方案通过结合概率目标、正弦-余弦编码和系数矩阵重缩放，有效解决了QAOA实现和可扩展性估计中的关键瓶颈。该方法显著降低了获得近似解所需的量子比特数量，并有望实现O(1)量子比特复杂度，同时保持二次方电路深度。重要的是，省略该方案中的任何一个改进都会导致所需量子比特数量随着问题规模的增加呈指数增长。

Abstract: Quantum Approximate Optimization Algorithm (QAOA) provides one of the most
promising quantum frameworks for addressing discrete optimization problems with
broad real-world applications, particularly quadratic unconstrained binary
optimization (QUBO) problems. However, the widely used hybrid
quantum--classical implementation faces significant challenges due to
statistical noise and barren plateaus. A prominent approach to mitigate these
issues is fixed-point QAOA (fpQAOA), where circuit parameters are trained on
small problem instances and subsequently transferred to larger ones. In this
work, we develop a modified fpQAOA scheme that combines (i) considering the
probability of achieving a target approximation ratio (AR) rather than
requiring the exact optimum, (ii) setting the number of layers equal to the
problem size with the sine--cosine encoding of QAOA angles, and (iii) rescaling
the problem coefficient matrices to unit Frobenius norm. We demonstrate that
this combination leads to a decreasing median number of shots required to
obtain approximate solutions as the problem size increases, with ARs being
within a few percent from the optimum for the considered problem classes.
Extrapolation of these results suggests an $O(1)$ shot complexity while
retaining at most quadratic circuit depth, underscoring the potential of our
approach to overcome key bottlenecks in QAOA implementations and scalability
estimations. Remarkably, omitting even a single one of the modifications
(i)--(iii) results in exponential growth of the number of shots required as the
problem size increases.

</details>


### [457] [Nonadiabatic processes in dynamical controls](https://arxiv.org/abs/2509.19062)
*Yoshiaki Teranishi,Satoshi Morita,Seiji Miyashita*

Main category: quant-ph

TL;DR: 该研究提出了一个计算量子态输运过程中粒子存活概率的理论模型，考虑了初始扰动、最终扰动和绝热隧穿三种机制，并发现该模型能有效预测不同加速协议下的存活概率，无需进行复杂的动力学模拟。


<details>
  <summary>Details</summary>
Motivation: 在量子态的实时操控中，动态控制哈密顿量参数极具挑战性。本研究旨在研究粒子在势阱中被输运过程中，由于量子力学过程（如逃逸）导致的存活概率问题。

Method: 提出一个考虑了初始扰动、绝热隧穿和最终扰动的存活概率计算公式，并对不同加速协议下的输运过程进行定量分析。

Result: 研究发现，在输运过程中，粒子的存活概率衰减行为在很大程度上可以由初始扰动、最终扰动以及贯穿整个过程的绝热隧穿的积分形式所解释。

Conclusion: 一旦确定了扰动因素和绝热隧穿的贡献，就可以在不进行单独动力学模拟的情况下，估算出任何加速协议下的存活概率。该研究还从绝热理论的角度分析了初始和最终点的扰动效应。

Abstract: In the real-time manipulation of quantum states, it is necessary to
dynamically control the parameters of the system's Hamiltonian, which is a
highly nontrivial task. We have studied the survival probability during the
conveyance of a particle by a trapping potential, where the particle may escape
from the potential well due to quantum mechanical processes (Morita et al.,
Phys. Rev. Research 6, 043329 (2024)). We pointed out that the escape
mechanisms can be classified into two categories. One is an initial disturbance
caused by a non-analytic change of parameters at the starting point, the
significance of which had been pointed out earlier by one of the authors
(Morita, J. Phys. Soc. Jpn. 76, 104001 (2007)). The other is adiabatic
tunneling, a phenomenon that occurs due to quantum tunneling during the
acceleration process. We have proposed a formula for the survival probability
as a function of acceleration protocols, taking both mechanisms into account.
In this paper, we quantitatively examine the survival probabilities in
conveyance processes. Surprisingly, we find that the decay behaviors under
different acceleration protocols are almost perfectly explained by the combined
effects of the initial and final disturbances, together with an integral form
of adiabatic tunneling throughout the transport process. Therefore, once these
disturbance factors and the adiabatic tunneling contribution are determined,
the survival probability for any acceleration protocol can be estimated without
performing dynamical simulations for each individual case. We also analyze the
effects of the disturbances at the initial and final points from the
perspective of adiabatic theory.

</details>


### [458] [Quantum Autoencoder: An efficient approach to quantum feature map generation](https://arxiv.org/abs/2509.19157)
*Shengxin Zhuang,Yusen Wu,Xavier F. Cadet,Du Q. Huynh,Wei Liu,Philippe Charton,Cedric Damour,Frederic Cadet,Jingbo B. Wang*

Main category: quant-ph

TL;DR: 量子自编码器可以从大规模数据集中学习有效的量子表征，并在多种肽分类任务中优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 现有的量子机器学习方法依赖于固定的、手工设计的量子编码，可能无法捕捉到最优特征。本研究旨在探索量子自编码器在学习数据驱动的量子表征方面的能力。

Method: 在理论上证明了量子自编码器在整个训练过程中具有样本复杂度优势，并在数值上对300万个肽序列进行了训练，然后将学习到的表征与基于哈密顿演化的基线进行比较，使用了量子核支持向量机。

Result: 量子自编码器学习到的表征在七个数据集上的准确度比哈密顿基线提高了0.4%到8.1%，表明其能够有效地泛化到不同的下游数据集，并且预训练可以实现有效的迁移学习，无需进行特定任务的微调。此外，量子自编码器架构能够从大规模数据集（300万个样本）中学习，并且参数量紧凑（约900个参数），证明了其在实际量子应用中的可行性。

Conclusion: 量子自编码器是一种有效的学习数据驱动量子表征的方法，能够处理大规模数据集，并在多种下游任务中取得优于传统方法的性能。

Abstract: Quantum machine learning methods often rely on fixed, hand-crafted quantum
encodings that may not capture optimal features for downstream tasks. In this
work, we study the power of quantum autoencoders in learning data-driven
quantum representations. We first theoretically demonstrate that the quantum
autoencoder method is efficient in terms of sample complexity throughout the
entire training process. Then we numerically train the quantum autoencoder on 3
million peptide sequences, and evaluate their effectiveness across multiple
peptide classification problems including antihypertensive peptide prediction,
blood-brain barrier-penetration, and cytotoxic activity detection. The learned
representations were compared against Hamiltonian-evolved baselines using a
quantum kernel with support vector machines. Results show that quantum
autoencoder learned representations achieve accuracy improvements ranging from
0.4\% to 8.1\% over Hamiltonian baselines across seven datasets, demonstrating
effective generalization to diverse downstream datasets with pre-training
enabling effective transfer learning without task-specific fine-tuning. This
work establishes that quantum autoencoder architectures can effectively learn
from large-scale datasets (3 million samples) with compact parameterizations
($\sim$900 parameters), demonstrating their viability for practical quantum
applications.

</details>


### [459] [Who Let the Diamonds Out?](https://arxiv.org/abs/2509.19179)
*Vincent Halde,Olivier Bernard,Mathieu Brochu,Laurier Dufresne,Nicolas Fleury,Kayla Johnson,Benjamin Moffet,David Roy-Guay*

Main category: quant-ph

TL;DR: 这是一个手持式金刚石氮-空位（NV）质谱仪，可在地球磁场和恶劣环境下运行，具有出色的传感器性能。


<details>
  <summary>Details</summary>
Motivation: 大多数现有的NV中心磁力计都局限于实验室设置，缺乏在实际应用中实现其全部潜力的便携性和环境鲁棒性。

Method: 开发了一种全便携、手持式NV磁力计，可提供约400pT/sqrt(Hz)的矢量灵敏度、地球磁场中低于5nT的航向误差以及支持现场重新校准和在移动平台上运行的宽信号带宽。该系统已通过环境资格认证（热、振动、辐射和低地球轨道部署相关的其他运行压力），并成功部署在北加拿大、无人机和高空平流层气球的恶劣环境中。

Result: 该设备可在地球磁场和恶劣环境下运行，传感器性能出色。

Conclusion: 这项工作使NV磁力计成为一种强大的、多功能的工具，可为各种现场和自主应用带来量子传感性能。

Abstract: Nitrogen-Vacancy (NV) center magnetometry is a highly promising quantum
sensing technology, with early prototypes demonstrating impressive sensitivity
in compact sensing heads. Yet, most existing implementations remain tied to
laboratory setups, lacking the portability and environmental robustness needed
to unlock their full potential in real-world applications. In this work, we
introduce a fully portable, hand-held NV-based magnetometer that delivers a
vector sensitivity of approximately 400 pT/sqrt(Hz), heading errors below 5 nT
in Earth's field, and a wide signal bandwidth that supports on-field
recalibration and operation on moving platforms. We further demonstrate the
system's technological maturity through environmental qualification such as
thermal, vibration, radiation and other operational stresses related to
deployment in low Earth orbit, and through successful deployments in demanding
scenarios, including northern Canadian weather conditions, drone-mounted
surveys and high-altitude balloon flights. Together, these achievements
establish this NV-based magnetometer as a robust, versatile tool ready to bring
quantum sensing performance to a broad range of field and autonomous
applications.

</details>


### [460] [Quantum Krylov Algorithm for Szegö Quadrature](https://arxiv.org/abs/2509.19195)
*William Kirby,Yizhi Shen,Daan Camps,Anirban Chowdhury,Katherine Klymko,Roel Van Beeumen*

Main category: quant-ph

TL;DR: We present a quantum algorithm for evaluating matrix elements of functions of unitary operators using quantum processor data to construct quadrature rules. This method allows for classical approximation of $\langle\psi_1|f(U)|\psi_0\rangle$ and offers advantages like not requiring direct approximation of $f$ and post-computation flexibility.


<details>
  <summary>Details</summary>
Motivation: The motivation is to develop a quantum algorithm to evaluate matrix elements of functions of unitary operators, enabling applications in estimating Hamiltonian spectra and Gibbs states, and serving as a subroutine in other quantum algorithms.

Method: The algorithm calculates quadrature nodes and weights using data from a quantum processor. Specifically, it computes Szegö quadrature rules, which form a functional for classically approximating $\langle\psi_1|f(U)|\psi_0\rangle$ for any function $f$.

Result: The algorithm computes Szegö quadrature rules that relate the degree of $f$ to the number of quantum circuits required. This functional can be classically applied to any $f$ after construction.

Conclusion: The proposed quantum algorithm provides an efficient method for evaluating matrix elements of functions of unitary operators, with key advantages including avoiding direct approximation of $f$ and offering classical post-computation flexibility for arbitrary functions.

Abstract: We present a quantum algorithm to evaluate matrix elements of functions of
unitary operators. The method is based on calculating quadrature nodes and
weights using data collected from a quantum processor. Given a unitary $U$ and
quantum states $|\psi_0\rangle$, $|\psi_1\rangle$, the resulting quadrature
rules form a functional that can then be used to classically approximate
$\langle\psi_1|f(U)|\psi_0\rangle$ for any function $f$. In particular, the
algorithm calculates Szeg\"o quadrature rules, which, when $f$ is a Laurent
polynomial, have the optimal relation between degree of $f$ and number of
distinct quantum circuits required. The unitary operator $U$ could approximate
a time evolution, opening the door to applications like estimating properties
of Hamiltonian spectra and Gibbs states, but more generally could be any
operator implementable via a quantum circuit. We expect this algorithm to be
useful as a subroutine in other quantum algorithms, much like quantum signal
processing or the quantum eigenvalue transformation of unitaries. Key
advantages of our algorithm are that it does not require approximating $f$
directly, via a series expansion or in any other way, and once the output
functional has been constructed using the quantum algorithm, it can be applied
to any $f$ classically after the fact.

</details>


### [461] [Uniqueness of Complementary Recovery in Holographic Error-Correcting Codes](https://arxiv.org/abs/2509.19299)
*Julia Jones,Jason Pollack*

Main category: quant-ph

TL;DR: 全息码是一种具有几何结构的纠错码，其关键特性是“互补恢复”。该论文指出，之前声称的唯一性定理（即只有最大代数才能满足互补恢复）存在反例。通过使用一个四比特码的一个“非相邻”分区，并引入对擦除的纠错要求（即满足代数Knill-Laflamme条件），论文恢复了唯一性，并重新证明了该定理。最后，论文列出了“原子”全息码中可能违反纠错假设的分区。


<details>
  <summary>Details</summary>
Motivation: 探究全息码的互补恢复特性，并修正之前关于唯一性定理的陈述。

Method: 提出一个四比特码的“非相邻”分区作为反例，并引入对擦除的纠错要求（代数Knill-Laflamme条件），然后重新证明唯一性定理。

Result: 证明了之前全息码唯一性定理的反例，并通过添加纠错要求恢复了唯一性，并重新证明了该定理。最后列出了原子全息码中可能违反纠错假设的分区。

Conclusion: 全息码的互补恢复特性依赖于纠错（特别是对擦除的纠错）要求。在满足此要求下，全息码的代数结构具有唯一性。

Abstract: Holographic codes are a type of error-correcting code with extra geometric
structure ensured by a ``complementary recovery'' property: given a division of
the physical Hilbert space $\mathcal{H}$ into $\mathcal{H}_A$ and
$\mathcal{H}_{\bar A}$, and an algebra of physical operators
$\mathcal{M}\subseteq (\mathcal{L}(\mathcal{H}_A)\otimes I_{\mathcal{H}_{\bar
A}})$, the logical operators in $\mathcal{L}(\mathcal{H}_L)\simeq
\mathcal{L}(P\mathcal{H})$ which can be created by acting in $\mathcal{M}$ are
identical to the logical operators whose expectation values cannot be altered
by acting in the commutant $\mathcal{M}^\prime$, and vice versa. In
arXiv:2110.14691, a uniqueness theorem was stated: the only possible tuple of
(code, bipartition, algebra) which can exhibit complementary recovery is the
maximal one $\mathcal{M}=P(\mathcal{L}(\mathcal{H}_A)\otimes
I_{\mathcal{H}_{\bar A}})P$. We point out a counterexample to this result,
using a ``non-adjacent'' bipartition of a four-qubit code proposed in
arXiv:2110.14691. We show that the failure of uniqueness is due to a failure to
enforce error correction against erasure of $\mathcal{H}_{\bar A}$, which
requires enforcing the algebraic Knill-Laflamme condition $[P E_i^\dagger E_j
P,\mathcal{M}]=0$ for each pair of error operators. When we add the additional
requirement that $\mathcal{M}$ be correctable with respect to this channel,
uniqueness is restored, and we re-prove the theorem of arXiv:2110.14691 with
this added assumption. We present the list of bipartitions of the ``atomic''
holographic codes in arXiv:2110.14691 in which the correctability assumption
can be violated.

</details>


<div id='cs.LO'></div>

# cs.LO [[Back]](#toc)

### [462] [Proceedings Seventh International Conference on Applied Category Theory 2024](https://arxiv.org/abs/2509.18357)
*Michael Johnson,David Jaz Myers*

Main category: cs.LO

TL;DR: ACT 2024会议涵盖了从纯理论到应用研究的广泛主题，涉及科学和工程领域的多个学科。


<details>
  <summary>Details</summary>
Motivation: 介绍ACT 2024会议的广泛性和学科交叉性。

Method: 列举了会议涉及的具体学科领域，如经典力学、量子物理、概率论、语言学、决策论、机器学习、流行病学、热力学、工程学和逻辑学。

Result: 展示了会议内容的丰富性和多样性。

Conclusion: 强调了应用范畴理论在不同科学和工程领域中的广泛应用潜力。

Abstract: Proceedings of the Seventh International Conference on Applied Category
Theory, held at the University of Oxford on 17 - 21 June 2024. The
contributions to ACT 2024 ranged from pure to applied and included
contributions in a wide range of disciplines in science and engineering. ACT
2024 included talks in classical mechanics, quantum physics, probability
theory, linguistics, decision theory, machine learning, epidemiology,
thermodynamics, engineering, and logic.

</details>


### [463] [Singleton algorithms for the Constraint Satisfaction Problem](https://arxiv.org/abs/2509.18434)
*Dmitriy Zhuk*

Main category: cs.LO

TL;DR: 研究了(promise)约束满足问题（CSP）的单例算法，并将其能力与minion同态联系起来。证明了对于有限关系结构，该条件等价于存在具有特定对称性的多态函数（palette block symmetric polymorphisms）。这表明单例BLP+AIP算法可以解决大小不超过7的域上的所有可处理CSP。最后，通过具体CSP模板说明了线性规划的局限性、单例算法的强大以及palette block symmetric polymorphisms的优美性。


<details>
  <summary>Details</summary>
Motivation: 对（promise）约束满足问题（CSP）的标准通用算法进行了自然加强，即其单例版本，旨在理解这种加强对算法能力的影响。

Method: 通过将算法固定到一个约束元组，然后运行算法，如果结果为否定则移除该元组，来研究CSP的单例版本。利用Hales-Jewett定理，将单例版本的能力与minion同态联系起来，并进一步证明了该条件等价于存在具有调色板块对称性的多态函数。

Result: 证明了对于有限关系结构，单例算法的能力等价于存在调色板块对称性多态函数。进一步证明了单例BLP+AIP算法可以解决域大小不超过7的所有可处理CSP。

Conclusion: 单例版本的BLP+AIP算法能够解决域大小不超过7的所有可处理CSP。通过具体CSP模板的例子，说明了线性规划的局限性，以及单例算法和调色板块对称性多态函数的优越性。

Abstract: A natural strengthening of an algorithm for the (promise) constraint
satisfaction problem is its singleton version: we first fix a constraint to
some tuple from the constraint relation, then run the algorithm, and remove the
tuple from the constraint if the answer is negative. We characterize the power
of the singleton versions of standard universal algorithms for the (promise)
CSP over a fixed template in terms of the existence of a minion homomorphism.
Using the Hales-Jewett theorem, we show that for finite relational structures
this minion condition is equivalent to the existence of polymorphisms with
certain symmetries, called palette block symmetric polymorphisms. By proving
the existence of such polymorphisms we establish that the singleton version of
the BLP+AIP algorithm solves all tractable CSPs over domains of size at most 7.
Finally, by providing concrete CSP templates, we illustrate the limitations of
linear programming, the power of the singleton versions, and the elegance of
the palette block symmetric polymorphisms.

</details>


<div id='eess.SP'></div>

# eess.SP [[Back]](#toc)

### [464] [On Multi-entity, Multivariate Quickest Change Point Detection](https://arxiv.org/abs/2509.18310)
*Bahar Kor,Bipin Gaikwad,Abani Patra,Eric L. Miller*

Main category: eess.SP

TL;DR: 我们提出了一个在线变更点检测（CPD）框架，用于处理多实体、多元时间序列数据，解决了在复杂动态环境中检测系统行为变化的挑战。


<details>
  <summary>Details</summary>
Motivation: 在传统传感方法（如视频监控）不可行的情况下，例如在人群监控应用中，检测系统范围的行为转变。

Method: 通过基于重建误差的自编码器计算个体偏离常态（IDfN），并聚合个体偏离以获得系统范围异常得分（SWAS）。对SWAS应用统计偏差指标和累积和（CUSUM）技术来检测变化。

Result: 在合成数据集和专门为群体行为异常检测设计的人群模拟上进行了评估，证明该方法能够准确检测重要的系统级变化。

Conclusion: 该方法为监控复杂的、多智能体的系统提供了一个可扩展的、注重隐私的解决方案，并且我们引入了新的、具有挑战性的多实体多元时间序列数据集来评估CPD。

Abstract: We propose a framework for online Change Point Detection (CPD) from
multi-entity, multivariate time series data, motivated by applications in crowd
monitoring where traditional sensing methods (e.g., video surveillance) may be
infeasible. Our approach addresses the challenge of detecting system-wide
behavioral shifts in complex, dynamic environments where the number and
behavior of individual entities may be uncertain or evolve. We introduce the
concept of Individual Deviation from Normality (IDfN), computed via a
reconstruction-error-based autoencoder trained on normal behavior. We aggregate
these individual deviations using mean, variance, and Kernel Density Estimates
(KDE) to yield a System-Wide Anomaly Score (SWAS). To detect persistent or
abrupt changes, we apply statistical deviation metrics and the Cumulative Sum
(CUSUM) technique to these scores. Our unsupervised approach eliminates the
need for labeled data or feature extraction, enabling real-time operation on
streaming input. Evaluations on both synthetic datasets and crowd simulations,
explicitly designed for anomaly detection in group behaviors, demonstrate that
our method accurately detects significant system-level changes, offering a
scalable and privacy-preserving solution for monitoring complex multi-agent
systems. In addition to this methodological contribution, we introduce new,
challenging multi-entity multivariate time series datasets generated from crowd
simulations in Unity and coupled nonlinear oscillators. To the best of our
knowledge, there is currently no publicly available dataset of this type
designed explicitly to evaluate CPD in complex collective and interactive
systems, highlighting an essential gap that our work addresses.

</details>


### [465] [Multi-Target Detection for Cognitive MIMO Radar Networks](https://arxiv.org/abs/2509.18381)
*Nicholas L. K. Goradia,Harpreet S. Dhillon,R. Michael Buehrer*

Main category: eess.SP

TL;DR: 该研究提出了一种用于认知雷达网络中恒虚警率（CFAR）多目标检测的信号融合技术，并利用强化学习（RL）来优化检测性能。


<details>
  <summary>Details</summary>
Motivation: 在未知的噪声和杂波分布下，为认知雷达网络开发中心化和去中心化的CFAR多目标检测信号融合技术，并探索其性能。

Method: 开发了用于未知噪声和杂波分布下共位单基地MIMO雷达的检测统计量，并推广到认知雷达网络；利用强化学习（RL）使雷达学习目标可能出现的位置；研究了空间域（雷达天线数量）和时间域（时间采样点数）之间的权衡。

Result: 证明了在未知噪声和杂波分布下，CFAR检测在空间域和时间域之间存在基本权衡；展示了中心化和去中心化检测的优势和权衡。

Conclusion: 所提出的信号融合和强化学习方法能够有效提升认知雷达网络在未知噪声和杂波分布下的多目标检测性能，并揭示了空间和时间域的权衡关系。

Abstract: In this work, we develop centralized and decentralized signal fusion
techniques for constant false alarm rate (CFAR) multi-target detection with a
cognitive radar network in unknown noise and clutter distributions. Further, we
first develop a detection statistic for co-located monostatic MIMO radar in
unknown noise and clutter distributions which is asymptotically CFAR as the
number of received pulses over all antennas grows large, and we provide
conditions under which this detection statistic is valid. We leverage
reinforcement learning (RL) for improved multi-target detection performance,
where the radar learns likely target locations in a search area. These results
are then generalized to the setting of cognitive radar networks, where radars
collaborate to learn where targets are likely to appear in a search area. We
show a fundamental tradeoff between the spatial and temporal domain for CFAR
detection in unknown noise and clutter distributions; in other words, we show a
tradeoff between the number of radar antennas and the number of temporal
samples. We show the benefits and tradeoffs with centralized and decentralized
detection with a network of cognitive radars.

</details>


### [466] [Automatic Model Extraction of the Match Standard in Symmetric--Reciprocal--Match Calibration](https://arxiv.org/abs/2509.18426)
*Ziad Hatab,Michael Ernst Gadringer,Arash Arsanjani,Wolfgang Boesch*

Main category: eess.SP

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: This paper addresses the modeling of parasitics of the match standard in the
symmetric-reciprocal-match (SRM) calibration method of vector network analyzers
(VNAs). In the general SRM procedure, the match standard is assumed to be fully
known. Here, we demonstrate that the match can be modeled with an arbitrary
frequency-dependent model using a non-linear global optimization procedure. To
highlight the validity of the suggested approach, numerical tests were
conducted, demonstrating the ability to recover the match standard parasitic
model down to software numerical precision. Additionally, we performed
microstrip line measurements to compare the SRM calibration with match modeling
to the multiline thru-reflect-line (TRL) calibration one, showing that
automatic model extraction can achieve accuracy similar to using a match
standard defined through multiline TRL calibration.

</details>


### [467] [A Secure Affine Frequency Division Multiplexing for Wireless Communication Systems](https://arxiv.org/abs/2509.18555)
*Ping Wang,Zulin Wang,Yuanfang Ma,Xiaosi Tian,Yuanhan Ni*

Main category: eess.SP

TL;DR: 本研究提出了一种安全仿射频分复用（SE-AFDM）技术，通过引入时变参数 c2 来提高无线通信系统的安全性，同时保持良好的比特误码率（BER）性能，尤其是在高移动性场景下。


<details>
  <summary>Details</summary>
Motivation: 为了增强无线通信系统的通信安全性，并解决在双选择性信道下通信可靠性和安全性之间的平衡问题。

Method: 提出了一种安全仿射频分复用（SE-AFDM）技术，利用时变参数 c2 来提高系统安全性。推导了输入输出关系，证明了合法接收者可以消除 c2 引入的非线性影响而不损失 BER 性能。理论证明了窃听者无法分离 c2 和随机信息符号，导致其 BER 性能严重下降。分析了窃听者的有效信噪比（SINR），表明 SINR 随 c2 值域的扩展而减小。

Result: SE-AFDM 能够在双选择性信道下实现通信可靠性。时变参数 c2 能够提高通信系统的安全性，因为窃听者无法分离 c2 和随机信息符号。窃听者的有效 SINR 随着 c2 值域的扩展而减小。数值结果验证了所提出的 SE-AFDM 波形在高移动性场景下具有显著的安全性，同时保持了良好的 BER 性能。

Conclusion: 所提出的 SE-AFDM 技术通过引入可调的时变参数 c2，成功地在提高无线通信系统安全性的同时，保持了与传统系统相当的 BER 性能，特别是在高移动性应用中，为安全通信提供了一种有效的方法。

Abstract: This paper introduces a secure affine frequency division multiplexing
(SE-AFDM) for wireless communication systems to enhance communication security.
Besides configuring the parameter c1 to obtain communication reliability under
doubly selective channels, we also utilize the time-varying parameter c2 to
improve the security of the communications system. The derived input-output
relation shows that the legitimate receiver can eliminate the nonlinear impact
introduced by the time-varying c2 without losing the bit error rate (BER)
performance. Moreover, it is theoretically proved that the eavesdropper cannot
separate the time-varying c2 and random information symbols, such that the BER
performance of the eavesdropper is severely deteriorated. Meanwhile, the
analysis of the effective signal-to-interference-plus-noise ratio (SINR) of the
eavesdropper illustrates that the SINR decreases as the value range of c2
expands. Numerical results verify that the proposed SE-AFDM waveform has
significant security while maintaining good BER performance in high-mobility
scenarios.

</details>


### [468] [Integrated Cellular and LEO-based Positioning and Synchronization under User Mobility](https://arxiv.org/abs/2509.18727)
*Yasaman Ettefagh,Sharief Saleh,Musa Furkan Keskin,Hui Chen,Gonzalo Seco-Granados,Henk Wymeersch*

Main category: eess.SP

TL;DR: 本文研究了在地面和非地面网络（特别是低地球轨道卫星）融合环境下，移动用户设备的定位、同步和速度估计。在仅接收来自一个基站和一个低地球轨道卫星信号的最小配置下，推导了考虑移动性、时钟和频率偏移的通用信号模型，并提出了计算复杂度递减的简化模型。为每个模型开发了估计算法，以实现高效精确的参数恢复。仿真结果验证了所提模型的有效性，并展示了其在不同场景下的适用性。研究结果强调了在用户移动环境下，如何针对不同的部署环境和应用需求优化复杂度与性能的权衡，为6G定位和同步系统提供了有价值的见解。


<details>
  <summary>Details</summary>
Motivation: 在地面和非地面网络（特别是低地球轨道卫星）融合环境下，为移动用户设备（UE）提供定位、同步和速度估计解决方案。

Method: 1. 建立一个包含移动性、时钟和频率偏移的通用信号模型。
2. 提出一系列计算复杂度递减的简化模型。
3. 为每个模型开发估计算法以实现参数恢复。

Result: 仿真结果验证了所提模型的有效性，证明了其在不同场景下的适用性。模型在计算复杂度与性能之间实现了优化，为6G定位和同步系统提供了有价值的见解。

Conclusion: 所提出的模型和估计算法能够有效地在地面和非地面网络融合环境下，为移动用户设备实现定位、同步和速度估计。通过权衡计算复杂度和性能，可以满足不同部署环境和应用需求，为6G系统提供支持。

Abstract: This paper investigates the localization, synchronization, and speed
estimation of a mobile user equipment (UE) leveraging integrated terrestrial
and non-terrestrial networks (NTNs), in particular low Earth orbit (LEO)
satellites. We focus on a minimal setup in which the UE received signal from
only one base station (BS) and one LEO satellite. We derive a generic signal
model accounting for mobility, clock and frequency offsets, based on which a
hierarchy of simplified models are proposed and organized by computational
complexity. Estimation algorithms are developed for each model to facilitate
efficient and accurate parameter recovery. Rigorous simulations validate the
effectiveness of the proposed models, demonstrating their suitability across
diverse scenarios. The findings highlight how the trade-off between complexity
and performance can be optimized for varying deployment environments and
application requirements, offering valuable insights for 6G positioning and
synchronization systems under user mobility.

</details>


### [469] [Detection Capability Comparison Between Intensity Detection and Splitting Detection for Rydberg-Atomic Sensors](https://arxiv.org/abs/2509.18753)
*Hao Wu,Xinyuan Yao,Rui Ni,Chen Gong,Kaibin Huang*

Main category: eess.SP

TL;DR: 里德堡原子量子接收器有两种主要的信号读取方案：基于强度和基于分裂。本文对这两种方案进行了建模和分析，并提出了最大似然估计（MLE）方法和相应的Cramér-Rao下界（CRLB）。研究表明，在最大斜率区域进行数据采集可以提高灵敏度并最小化估计方差，尤其是在分裂检测方案中，这比传统的多项式拟合效果更好。


<details>
  <summary>Details</summary>
Motivation: 里德堡原子量子接收器因其高灵敏度和宽频率范围而在通信接收领域具有吸引力，但其信号读取方案（基于强度和基于分裂）的优化和分析尚不充分。

Method: 对基于强度和基于分裂的信号读取方案进行建模和分类，推导了最大似然估计（MLE）程序和Cramér-Rao下界（CRLB），并提出在最大斜率区域进行数据采集以提高灵敏度和最小化估计方差的策略。

Result: 基于最大似然估计和在最大斜率区域进行数据采集的策略，分裂检测方案的估计方差显著降低，优于传统的多项式拟合。两种方案都通过提出的MLE方法实现了较低的估计方差，提高了精度，并有助于微波校准。

Conclusion: 本文对里德堡原子量子接收器的两种信号读取方案进行了系统分析，提出了改进的信号读取和估计方法，并通过数值结果验证了其在提高灵敏度和降低估计方差方面的有效性，为通信接收和微波校准提供了新的途径。

Abstract: Rydberg atomic quantum receivers have been seen as novel radio frequency
measurements and the high sensitivity to a large range of frequencies makes it
attractive for communications reception. However, their unique physical
characteristics enable two fundamental signal readout schemes: intensity-based
detection and splitting-based detection. The former measures the electric
fields through laser intensity, while the latter utilizes Autler-Townes
splitting. In this work, we systematically categorize and model existing signal
readout methods, classifying them into these two paradigms. Then, we derive the
maximum likelihood estimation procedures and corresponding Cram\'er-Rao lower
bounds (CRLB) for each detection modality. Through the analysis of the CRLB, we
propose strategy for both readout schemes to enhance sensitivity and minimize
estimation variance: acquiring data in regions with maximal slope magnitudes.
While this approach has been implemented in intensity-based detection (e.g.,
superheterodyne schemes), its application to splitting-based detection remains
unexplored. Implementation of non-uniform frequency scanning, with preferential
sampling at regions exhibiting maximum peak slopes combined with our proposed
maximum likelihood splitting estimation method, achieves significantly reduced
estimation variance compared to conventional polynomial fitting. The
comparative analysis reveals the optimal detection performance of the two
detection schemes. This work also contributes to enhancing the accuracy of
microwave calibration. Numerical results reveal that both fundamental signal
readout methods achieve lower estimation variance based on our proposed maximum
likelihood estimation approach.

</details>


### [470] [Highly Parallel Singular Value Decomposition for Low-Latency MIMO Processing](https://arxiv.org/abs/2509.18799)
*Sijia Cheng,Liang Liu,Ove Edfors,Juan Vidal Alegria*

Main category: eess.SP

TL;DR: SVD在无线系统中有广泛应用，但其迭代性质限制了实时性。本文提出一种基于Gram矩阵三对角化的4步并行方法，并通过硬件剖析进行时间复杂度分析，证明了其在海量MIMO场景下的优越时间效率。


<details>
  <summary>Details</summary>
Motivation: SVD在MIMO等无线系统中的广泛应用面临迭代性质带来的高执行时间问题，这对于实时和低延迟应用构成了挑战。

Method: 分析了现有SVD方法的延迟，并提出了一种基于Gram矩阵三对角化的4步高度并行方法。开发了一个包含硬件剖析的时间复杂度分析框架，实现了无需完全实现即可进行可扩展和现实的评估。

Result: 数值结果表明，所选的并行方法在时间效率上具有显著优势，尤其是在海量MIMO场景下。

Conclusion: 基于Gram矩阵三对角化的4步并行SVD方法在处理大规模MIMO系统时，比传统方法具有更优越的时间效率。

Abstract: Singular value decomposition (SVD) is widely used in wireless systems,
including multiple-input multiple-output (MIMO) processing and dimension
reduction in distributed MIMO (D-MIMO). However, the iterative nature of
decomposition methods results in increased execution time as system size grows,
posing challenges for real-time and low-latency applications. To address this,
we analyze the latency of state-of-art SVD methods, and highlight the
efficiency of a 4-step highly parallel method based on Gram matrix
tridiagonalization. Furthermore, we develop a time complexity (processing
latency) analysis framework with hardware profiling, allowing scalable and
realistic evaluation without full implementation. The numerical results
demonstrate the superior time efficiency of the selected parallel method,
particularly in massive MIMO scenarios.

</details>


### [471] [Normal mode parameters estimation by a VLA in single-shooting](https://arxiv.org/abs/2509.18853)
*Xiaolei Li,Pengyu Wang,Wenhua Song,Yangjin Xu,Wei Gao*

Main category: eess.SP

TL;DR: OCMS是一种利用VLA估计模态波数和模态深度函数的新方法，在已知声速剖面的情况下，利用模态深度函数的正交性进行提取。该方法在不同信噪比、VLA孔径、VLA阵元数、VLA倾斜和声速剖面不确定性下表现稳健，并通过SwellEx96实验数据验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 从垂直线性阵列（VLA）数据中估计模态波数和模态深度函数，尤其是在VLA和声源静止且声速剖面已知的情况下。

Method: 提出一种正交约束模态搜索（OCMS）方法，该方法利用不同模态深度函数的正交性来提取模态深度函数及其对应的波数。

Result: OCMS在不同信噪比、VLA孔径、VLA阵元数、VLA倾斜和声速剖面不确定性下表现出稳健性。在SSP不确定性小于1 m/s且VLA倾斜角小于5度时，算法性能可靠。SwellEx96实验数据验证了该方法的有效性，实验数据与Kraken计算结果的模态波数相对误差在10^{-4}级别。

Conclusion: OCMS是一种有效的、稳健的从VLA数据中估计模态波数和模态深度函数的方法，适用于已知声速剖面的情况，并在实际实验数据中得到了验证。

Abstract: This paper proposes an orthogonality-constrained modal search (OCMS) method
for estimating modal wavenumbers and modal depth functions using a vertical
linear array (VLA). Under the assumption of a known sound speed profile, OCMS
leverages the orthogonality of distinct modal depth functions to extract both
the modal depth functions and their corresponding wavenumbers, even when the
VLA and a monochromatic sound source remain stationary.The performance of OCMS
is evaluated through numerical simulations under varying signal-to-noise ratios
(SNRs), different VLA apertures, varying numbers of VLA elements, VLA tilt and
sound speed profile (SSP) uncertainty. The results demonstrate that OCMS is
robust against noise, VLA aperture variations, and changes in the number of VLA
elements, meanwhile, the algorithm maintains reliable performance when SSP
uncertainty < 1 m/s and VLA tilt angle <5{\deg}. Furthermore, the effectiveness
of OCMS is validated using SwellEx96 experimental data. The relative error
between the modal wavenumbers derived from experimental data and those computed
via Kraken is on the order of $10^{-4}$.

</details>


### [472] [Quaternion LMS for Graph Signal Recovery](https://arxiv.org/abs/2509.18918)
*Hamideh-Sadat Fazael-Ardekani,Hadi Zayyani,Hamid Soltanian-Zadeh*

Main category: eess.SP

TL;DR: 本文提出了一种名为四元数图最小均方（QGLMS）的新算法，用于解决图信号处理中的四元数图信号恢复问题。


<details>
  <summary>Details</summary>
Motivation: 将图信号恢复（GSR）问题推广到四元数域，以扩展自适应滤波和图信号处理中的现有方法。

Method: 推导了基于四元数代数的QGLMS基本自适应公式，并进行了均值收敛性和均方收敛性分析。

Result: 通过数学分析得到了QGLMS步长参数的充分条件，并通过仿真结果验证了该算法在图信号重构方面的有效性。

Conclusion: QGLMS算法能够有效地解决四元数域的图信号恢复问题，并为算法参数选择提供了理论指导。

Abstract: This letter generalizes the Graph Signal Recovery (GSR) problem in Graph
Signal Processing (GSP) to the Quaternion domain. It extends the Quaternion
Least Mean Square (QLMS) in adaptive filtering literature, and Graph LMS (GLMS)
algorithm in GSP literature, to an algorithm called Quaternion GLMS (QGLMS).
The basic adaptation formula using Quaternion-based algebra is derived.
Moreover, mean convergence analysis and mean-square convergence analysis are
mathematically performed. Hence, a sufficient condition on the step-size
parameter of QGLMS is suggested. Also, simulation results demonstrate the
effectiveness of the proposed algorithm in graph signal reconstruction.

</details>


### [473] [Bayesian Convolutional Neural Networks for Prior Learning in Graph Signal Recovery](https://arxiv.org/abs/2509.19056)
*Razieh Torkamani,Arash Amini,Hadi Zayyani,Mehdi Korki*

Main category: eess.SP

TL;DR: 该研究提出了一种基于贝叶斯卷积神经网络（BCNN）的图信号恢复（GSR）框架，该框架能够从不完整的观测中准确、稳健地重建图信号，尤其适用于复杂、非高斯信号模型和大规模应用。


<details>
  <summary>Details</summary>
Motivation: 图信号恢复（GSR）面临着底层统计模型未知或过于复杂的挑战。本研究旨在提出一种灵活、数据驱动的框架，直接从训练样本中学习信号的先验知识。

Method: 提出了一种贝叶斯卷积神经网络（BCNN）架构，使用基于切比雪夫多项式的图感知滤波器来建模图信号的先验分布。通过将CNN的隐藏层解释为吉布斯分布并采用高斯混合模型（GMM）非线性，获得了一个闭式且富有表现力的先验。该先验被整合到变分贝叶斯（VB）推断框架中，用于估计信号和噪声精度的后验分布。

Result: 实验结果表明，所提出的BCNN-GSR算法在合成和真实世界的图数据集上，能够针对各种信号分布实现精确且稳健的恢复。

Conclusion: BCNN-GSR算法能够准确、稳健地恢复图信号，能够泛化到复杂、非高斯信号模型，并且计算效率高，适用于实际的大规模图恢复任务。

Abstract: Graph signal recovery (GSR) is a fundamental problem in graph signal
processing, where the goal is to reconstruct a complete signal defined over a
graph from a subset of noisy or missing observations. A central challenge in
GSR is that the underlying statistical model of the graph signal is often
unknown or too complex to specify analytically. To address this, we propose a
flexible, data-driven framework that learns the signal prior directly from
training samples. We develop a Bayesian convolutional neural network (BCNN)
architecture that models the prior distribution of graph signals using
graph-aware filters based on Chebyshev polynomials. By interpreting the hidden
layers of the CNN as Gibbs distributions and employing Gaussian mixture model
(GMM) nonlinearities, we obtain a closed-form and expressive prior. This prior
is integrated into a variational Bayesian (VB) inference framework to estimate
the posterior distribution of the signal and noise precision. Extensive
experiments on synthetic and real-world graph datasets demonstrate that the
proposed BCNN-GSR algorithm achieves accurate and robust recovery across a
variety of signal distributions. The method generalizes well to complex,
non-Gaussian signal models and remains computationally efficient, making it
suitable for practical large-scale graph recovery tasks.

</details>


### [474] [Data-Free Knowledge Distillation for LiDAR-Aided Beam Tracking in MmWave Systems](https://arxiv.org/abs/2509.19092)
*Abolfazl Zakeri,Nhan Thanh Nguyen,Ahmed Alkhateeb,Markku Juntti*

Main category: eess.SP

TL;DR: 提出一个数据无关的知识蒸馏框架，用于高效的激光雷达辅助毫米波波束跟踪，取得了优于教师模型的性能。


<details>
  <summary>Details</summary>
Motivation: 多模态传感虽然能降低训练开销，但受限于机器学习复杂度和数据集需求。现有的方法需要大量数据，而本研究旨在解决这个问题。

Method: 提出一个数据无关的知识蒸馏框架。通过生成器合成激光雷达输入数据，并结合元数据损失、激活损失和熵损失来指导生成器。学生模型通过合成数据和教师模型进行知识蒸馏，同时考虑KL散度和教师-学生模型预测之间的均方误差（MSE）损失。

Result: 所提出的数据无关知识蒸馏（DF-KD）框架在Top-1和Top-5准确率上略优于教师模型。元数据损失对生成器性能有显著贡献，并且MSE损失可以有效替代标准的知识蒸馏损失，同时需要更少的超参数调整。

Conclusion: 该框架能够高效地进行激光雷达辅助的毫米波波束跟踪，并且在不依赖真实数据的情况下，能够取得优于教师模型的性能。元数据损失和MSE损失是提升性能的关键因素。

Abstract: Multimodal sensing reduces beam training overhead but is constrained by
machine learning complexity and dataset demands. To address this, we propose a
data-free (DF) knowledge distillation (KD) framework for efficient LiDAR-aided
mmWave beam tracking, i.e., predicting the best current and future beams.
Specifically, we propose a knowledge inversion framework, where a generator
synthesizes LiDAR input data from random noise, guided by a loss function
defined on the features and outputs of a pre-trained teacher model. The student
model is then trained using the synthetic data and knowledge distilled from the
teacher. The generator loss combines three terms, called metadata loss,
activation loss, and entropy loss. For student training, in addition to the
standard Kullback-Leibler divergence loss, we also consider a mean-squared
error (MSE) loss between the teacher and student logits. Simulation results
show that the proposed DF-KD (slightly) outperforms the teacher in Top-1 and
Top-5 accuracies. Moreover, we observe that the metadata loss contributes
significantly to the generator performance, and that the MSE loss for the
student can effectively replace the standard KD loss while requiring fewer
fine-tuned hyperparameters.

</details>


### [475] [Enabling Drone Detection with SWARM Repeater-Assisted MIMO ISAC](https://arxiv.org/abs/2509.19119)
*Palatip Jopanya,Diana P. M. Osorio*

Main category: eess.SP

TL;DR: 本文研究了在蜂窝网络中部署中继器集群以增强无人机检测的雷达感知能力。


<details>
  <summary>Details</summary>
Motivation: 随着对集成传感和通信（ISAC）的新架构、用例和标准的定义不断出现，基于海量多输入多输出（MIMO）天线技术的蜂窝系统也在经历着新型网络组件集成带来的并行演进。本研究旨在探索一种通过部署中继器集群来实现经济高效的蜂窝网络密集化的新方法，以支持新兴的ISAC用例和服务。

Method: 本文研究了如何利用中继器瞬时重传信号的能力，在由中继器集群辅助的MIMO ISAC系统中增强无人机检测的雷达感知能力。

Result: 通过优化中继器的增益（在足够大的最大放大增益下），结果表明增加中继器的数量可以提高感测性能。

Conclusion: 在无人机检测的MIMO ISAC系统中，通过优化增益和增加中继器数量，可以有效提升感测性能。

Abstract: As definitions about new architectural aspects, use cases, and standards for
integrated sensing and communication (ISAC) continue to appear, cellular
systems based on massive multiple-input multiple-output (MIMO) antenna
technology are also experiencing a parallel evolution through the integration
of novel network components. This evolution should support emerging ISAC use
cases and services. In particular, this paper explores a recent vision for
cost-efficient cellular network densification through the deployment of swarms
of repeaters. Leveraging their ability to retransmit signals instantaneously,
we investigate how these repeaters can enhance radar sensing capabilities for
drone detection in a swarm repeater-assisted MIMO ISAC system. Our results
demonstrate that, by optimizing the gains of repeaters given a sufficient
maximum amplification gain, increasing the number of repeaters can lead to
gains in sensing performance.

</details>


### [476] [Deep Reinforcement Learning for Dynamic Sensing and Communications](https://arxiv.org/abs/2509.19130)
*Abolfazl Zakeri,Nhan Thanh Nguyen,Ahmed Alkhateeb,Markku Juntti*

Main category: eess.SP

TL;DR: 提出一个统一的机器学习框架，用于动态确定何时进行感知以及利用感官数据进行波束预测，以在平均感知预算下最大化平均信噪比。


<details>
  <summary>Details</summary>
Motivation: 在毫米波通信中，环境感知可以帮助波束训练，但需要权衡感知成本。

Method: 使用Lyapunov优化来执行感知约束，并使用深度Q网络来确定感知时隙。然后，使用预训练的深度神经网络将感知数据映射到码本中的最佳波束。

Result: 仿真结果表明，该方法显著降低了感知开销，同时保持了令人满意的通信性能。

Conclusion: 所提出的方法能够有效地平衡感知成本和通信性能。

Abstract: Environmental sensing can significantly enhance mmWave communications by
assisting beam training, yet its benefits must be balanced against the
associated sensing costs. To this end, we propose a unified machine learning
framework that dynamically determines when to sense and leverages sensory data
for beam prediction. Specifically, we formulate a joint sensing and beamforming
problem that maximizes the av- erage signal-to-noise ratio under an average
sensing budget. Lyapunov optimization is employed to enforce the sensing
constraint, while a deep Q-Network determines the sensing slots. A pretrained
deep neural network then maps the sens- ing data to optimal beams in the
codebook. Simulations based on the real-world DeepSense dataset demonstrate
that the pro- posed approach substantially reduces sensing overhead while
maintaining satisfactory communications performance.

</details>


### [477] [On the Performance of THz Wireless Systems over $α$-$\mathcal{F}$ Channels with Beam Misalignment and Mobility](https://arxiv.org/abs/2509.19235)
*Wamberto J. L. Queiroz,Hugerles S. Silva,Higo T. P. Silva,Alexandros-Apostolos A. Boulogeorgos*

Main category: eess.SP

TL;DR: 本论文研究了太赫兹（THz）无线系统在考虑波束不对准和移动性因素下，于 α-F 衰落信道上的性能表现。


<details>
  <summary>Details</summary>
Motivation: 研究太赫兹（THz）无线系统在存在波束不对准和移动性因素下的性能，该因素在 α-F 衰落信道上尤为重要。

Method: 推导了瞬时信噪比的概率密度、累积分布、矩生成函数以及高阶矩的新表达式。基于这些表达式，推导了新的中断概率、符号错误概率和平均信道容量的计算公式，并推导出渐近度量。

Result: 推导了瞬时信噪比的概率密度、累积分布、矩生成函数以及高阶矩的新表达式，并基于这些表达式推导了新的中断概率、符号错误概率和平均信道容量的计算公式，同时推导了渐近度量。

Conclusion: 通过蒙特卡洛模拟验证了所推导的分析框架的有效性。

Abstract: This paper investigates the performance of terahertz~(THz) wireless systems
over the $\alpha$-$\mathcal{F}$ fading channels with beam misalignment and
mobility. New expressions are derived for the probability density, cumulative
distribution, and moment generating functions, as well as higher-order moments
of the instantaneous signal-to-noise ratio. Building upon the aforementioned
expressions, we extract novel formulas for the outage probability, symbol error
probability, and average channel capacity. Asymptotic metrics are also deduced,
which provide useful insights. Monte Carlo simulations results are presented to
support the derived analytical framework.

</details>


### [478] [Faster-Than-Nyquist Signalling - Theoretical Limits on Capacity and Techniques to Approach Capacity](https://arxiv.org/abs/2509.19272)
*Sathwik Chadaga*

Main category: eess.SP

TL;DR: FTN信号是一种非正交传输方案，通过引入符号间干扰（ISI）来提高吞吐量和频谱效率。本论文研究了FTN信号中的ISI问题，并推导了避免ISI的条件。此外，还探讨了FTN系统的容量理论极限，并研究了功率分配和自适应加载技术在减少ISI和提高OFDM-FTN系统吞吐量方面的应用，并进行了仿真验证。


<details>
  <summary>Details</summary>
Motivation: FTN信号能够提供比Nyquist信号更高的吞吐量和频谱效率，但其引入的ISI问题需要被研究和解决。

Method: 推导了避免FTN信号中ISI的脉冲形状和时间加速因子（τ）的条件；研究了FTN系统的容量理论极限；探索了功率分配和自适应加载技术在OFDM-FTN系统中的应用。

Result: 推导了避免ISI的条件；评估了FTN系统的容量；展示了功率分配和自适应加载技术在OFDM-FTN系统中的应用和仿真结果。

Conclusion: 通过选择合适的脉冲形状和时间加速因子，可以完全避免FTN信号中的ISI。此外，功率分配和自适应加载技术可以进一步提高OFDM-FTN系统的性能。

Abstract: Faster-Than-Nyquist (FTN) Signalling is a non-orthogonal transmission scheme
that violates the Nyquist zero-ISI criterion providing higher throughput and
better spectral efficiency than a Nyquist transmission scheme. In this thesis,
the inter symbol interference (ISI) introduced by FTN signalling is studied,
and conditions on pulse shapes and $\tau$ (time acceleration factor) are
derived so that the ISI can be avoided completely. Further, these conditions
are reinforced by investigating the theoretical limits on the capacities of FTN
systems. Finally, the use of power allocation and adaptive loading techniques
are explored in reducing the effect of ISI and increasing the throughput of
orthogonal frequency division multiplexing (OFDM) FTN systems. The
implementation of these techniques and simulation results are also
demonstrated.

</details>


### [479] [A Novel Site-Specific Inference Model for Urban Canyon Channels: From Measurements to Modeling](https://arxiv.org/abs/2509.19275)
*Junzhe Song,Ruisi He,Mi Yang,Zhengyu Zhang,Xinwen Chen,Xiaoying Zhang,Bo Ai*

Main category: eess.SP

TL;DR: 本文提出了一种基于环境几何的场地特定信道推理模型，以解决现有信道模型未能充分捕捉城市峡谷场景下信道特性的问题。该模型利用亚 6GHz 信道测量数据进行参数化，通过聚类分析与几何传播相关的多径分量（MPCs），建立了物理环境与 MPCs 统计特性之间的可解释映射关系。通过与测量数据的二阶统计量对比，验证了该模型在不同城市峡谷场景下具有高精度和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有信道模型未能充分捕捉城市峡谷场景下信道特性的特点，而城市峡谷场景对于智能交通和智慧城市应用中的无线通信系统设计至关重要。

Method: 提出一种基于环境几何的场地特定信道推理模型。该模型使用亚 6GHz 信道测量数据进行参数化，提取并根据几何传播（特别是峡谷宽度）影响对多径分量（MPCs）进行聚类，从而建立物理环境与 MPCs 统计特性之间的映射关系。

Result: 所提出的模型在不同城市峡谷场景下，通过与测量数据的二阶统计量对比，证明了其高精度和鲁棒性。

Conclusion: 该基于环境几何的场地特定信道推理模型能够准确且稳健地捕捉城市峡谷场景下的信道特性。

Abstract: With the rapid development of intelligent transportation and smart city
applications, urban canyon has become a critical scenario for the design and
evaluation of wireless communication systems. Due to its unique environmental
layout, the channel characteristics in urban canyon are strongly a street
geometry and building distribution, thereby exhibiting significant
site-specific channel condition. However, this feature has not been well
captured in existing channel models. In this paper, we propose a site-specific
channel inference model based on environmental geometry, the model is
parameterized using sub-6GHz channel measurements. Multipath components (MPCs)
are extracted and clustered according to geometric propagation, which are
explicitly derived from the influence of canyon width, thereby establishing an
interpretable mapping between the physical environment and statistical
characteristics of MPCs. A step-by-step implementation scheme is presented.
Subsequently, the proposed site-specific channel inference model is validated
by comparing second-order statistics of channels, derived from the model and
measurements. The results show that the proposed model achieves high accuracy
and robustness in different urban canyon scenarios.

</details>


### [480] [STFT-AECNN: An Attention-Enhanced CNN for Efficient Φ-OTDR Event Recognition in IoT-Enabled Distributed Acoustic Sensing](https://arxiv.org/abs/2509.19281)
*Xiyang Lan,Xin Li*

Main category: eess.SP

TL;DR: 提出了一种基于短时傅里叶变换 (STFT) 的注意力增强卷积神经网络 (STFT-AECNN)，用于解决 {\Phi}-OTDR 数据分析中的挑战，实现了高精度和高效率的事件识别，适用于物联网环境。


<details>
  <summary>Details</summary>
Motivation: 现有的深度学习方法在处理 {\Phi}-OTDR 海量数据时，要么破坏信号固有的时空结构，要么计算成本过高，限制了其在资源受限的物联网场景中的应用。

Method: 提出了一种新的 STFT-AECNN 模型，将多通道时间序列数据表示为堆叠的频谱图，以充分利用其时空特征，并实现高效的二维卷积处理。引入了空间高效注意力模块 (SEAM) 来自适应地强调信息量最大的通道，并采用联合交叉熵和三元组损失来增强学习到的特征空间的判别力。

Result: 在公开的 BJTU {\Phi}-OTDR 数据集上的广泛实验表明，STFT-AECNN 实现了 99.94% 的峰值准确率，同时保持了高计算效率。

Conclusion: STFT-AECNN 在物联网 {\Phi}-OTDR 应用中具有实时、可扩展和鲁棒的事件识别潜力，为可靠和智能的物联网传感应用铺平了道路。

Abstract: Phase-sensitive optical time-domain reflectometry ({\Phi}-OTDR) has emerged
as a promising sensing technology in Internet of Things (IoT) infrastructures,
enabling large-scale distributed acoustic sensing (DAS) for smart city
surveillance, industrial pipeline monitoring, and critical infrastructure
protection. However, accurately recognizing events from massive {\Phi}-OTDR
data streams remains challenging, as existing deep learning methods either
disrupt the inherent spatiotemporal structure of signals or incur prohibitive
computational costs, limiting their applicability in resource-constrained IoT
scenarios. To overcome these challenges, we propose a novel STFT-based
Attention-Enhanced Convolutional Neural Network (STFT-AECNN), which represents
multi-channel time-series data as stacked spectrograms to fully exploit their
spatiotemporal characteristics while enabling efficient 2D CNN processing. A
Spatial Efficient Attention Module (SEAM) is further introduced to adaptively
emphasize the most informative channels, and a joint Cross-Entropy and Triplet
loss is adopted to enhance the discriminability of the learned feature space.
Extensive experiments on the public BJTU {\Phi}-OTDR dataset demonstrate that
STFT-AECNN achieves a peak accuracy of 99.94% while maintaining high
computational efficiency. These results highlight its potential for real-time,
scalable, and robust event recognition in IoT-enabled DAS systems, paving the
way for reliable and intelligent IoT sensing applications.

</details>


<div id='cond-mat.mtrl-sci'></div>

# cond-mat.mtrl-sci [[Back]](#toc)

### [481] [Cyclo-Graphyne: A Highly Porous and Semimetallic 2D Carbon Allotrope with Dirac Cones](https://arxiv.org/abs/2509.18299)
*Jhionathan de Lima,Cristiano Francisco Woellner*

Main category: cond-mat.mtrl-sci

TL;DR: Cyclo-graphyne (CGY)是一种具有多孔结构的2D碳同素异形体，具有sp/sp^2杂化的碳原子。研究系统地研究了其结构、能量、动力学、热学、电子、机械、光学和振动特性。结果表明CGY在能量上是可行的，动力学和热学上是稳定的（高达1000K）。它是一种具有超窄带隙和两个狄拉克锥的半金属。CGY具有高度的顺应性和各向同性，杨氏模量比石墨烯低一个数量级。光学光谱显示出强烈的紫外吸收和红外反射，振动光谱则显示出独特的拉曼峰和丰富的红外活性。这些特性使CGY在气体捕获和分离、柔性纳米电子学和光电子学等领域具有应用前景。


<details>
  <summary>Details</summary>
Motivation: 本研究旨在全面表征新兴的2D碳同素异形体——环状炔烃（CGY），并系统研究其各种物理化学性质，以评估其作为潜在应用材料的可行性。

Method: 利用密度泛函理论（DFT）系统研究了CGY的结构、能量、动力学、热学、电子、机械、光学和振动特性，并通过从头算分子动力学模拟进行热稳定性分析。

Result: 计算得到的内聚能和形成能与已合成的石墨炔相当，证实了其能量上的可行性。声子色散计算证实了其动力学稳定性，而从头算分子动力学模拟表明其在至少1000 K的温度下具有热稳定性。电子性质表明CGY是一种具有超窄带隙和两个狄拉克锥的半金属。机械性能显示CGY具有高度的顺应性和各向同性，杨氏模量比石墨烯低一个数量级。光学光谱显示出强烈的紫外吸收和红外反射，以及各向同性的响应。振动光谱则显示出独特的拉曼峰和丰富的红外活性。

Conclusion: CGY是一种具有优异物理化学特性的2D碳同素异形体，包括能量可行性、动力学和热学稳定性、半金属特性、高顺应性和各向同性以及独特的光学和振动响应。这些特性使其在气体捕获与分离、柔性纳米电子学和光电子学等领域具有重要的应用潜力。

Abstract: We present a comprehensive characterization of Cyclo-graphyne (CGY), an
emerging 2D carbon allotrope with a porous structure of sp/sp$^2$-hybridized
carbon atoms. Using density functional theory, we systematically investigate
its structural, energetic, dynamical, thermal, electronic, mechanical, optical,
and vibrational properties. The calculated cohesive and formation energies are
both comparable to those of other synthesized graphynes, confirming its
energetic viability. Phonon dispersion calculations confirm its dynamical
stability, while ab initio molecular dynamics simulations indicate thermal
stability up to at least 1000 K. Electronic results reveal that CGY is a
semimetal with an ultranarrow band gap and features two Dirac cones in its
electronic structure. Mechanically, CGY is highly compliant and isotropic,
exhibiting a Young's modulus an order of magnitude lower than that of graphene.
The optical spectrum reveals strong ultraviolet absorption and infrared
reflectivity with an isotropic response, while the vibrational spectra show
distinct Raman peaks and rich infrared activity. These properties position CGY
as a promising candidate for future applications in areas such as gas capture
and separation, flexible nanoelectronics, and optoelectronics.

</details>


### [482] [All-magnonic neurons for analog artificial neural networks](https://arxiv.org/abs/2509.18321)
*David Breitbach,Moritz Bechberger,Hanadi Mortada,Björn Heinz,Roman Verba,Qi Wang,Carsten Dubs,Mario Carpentieri,Giovanni Finocchio,Davi Rodrigues,Alexandre Abbass Hamadeh,Philipp Pirro*

Main category: cond-mat.mtrl-sci

TL;DR: 提出一种全磁性模拟神经元，利用非线性磁频移实现触发和记忆功能，并可通过传播磁振子实现突触连接，在标准基准测试中表现出高分类精度，有望用于低功耗、可扩展的波基神经形态计算。


<details>
  <summary>Details</summary>
Motivation: 传统数字系统在处理现代神经网络的能耗和可扩展性方面存在挑战，模拟神经形态硬件正受到关注。

Method: 利用镓取代的钇铁石榴石薄膜上的非线性磁频移，实现全磁性模拟神经元，并通过微焦布里渊光散射光谱进行实验验证，包括多神经元触发、级联和多输入集成。

Result: 实验验证了多神经元触发、级联和多输入集成，并在神经网络模拟中实现了高分类精度。

Conclusion: 全磁性神经元作为有潜力的器件，可用于构建低功耗、可扩展的波基神经形态计算系统，并作为未来物理神经网络的构建模块。

Abstract: Analog neuromorphic hardware is gaining traction as conventional digital
systems struggle to keep pace with the growing energy and scalability demands
of modern neural networks. Here, we present analog, fully magnonic, artificial
neurons, which exploit a nonlinear magnon excitation mechanism based on the
nonlinear magnonic frequency shift. This yields a sharp trigger response and
tunable fading memory, as well as synaptic connections to other neurons via
propagating magnons. Using micro-focused Brillouin light scattering
spectroscopy on a Gallium-substituted yttrium iron garnet thin film, we show
multi-neuron triggering, cascadability, and multi-input integration across
interconnected neurons. Finally, we implement the experimentally verified
neuron activation function in a neural network simulation, yielding high
classification accuracy on standard benchmarks. The results establish
all-magnonic neurons as promising devices for scalable, low-power, wave-based
neuromorphic computing, highlighting their potential as building blocks for
future physical neural networks.

</details>


### [483] [Nonthermal magnetization pathways in photoexcited semiconductors](https://arxiv.org/abs/2509.18335)
*Giovanni Marini*

Main category: cond-mat.mtrl-sci

TL;DR: 利用飞秒光脉冲在名义上非磁性的半导体中稳定长程磁序是一个令人兴奋但实验上具有挑战性的目标。理论研究表明，某些非磁性半导体在激子激光激发后会表现出瞬态磁不稳定性，但导致这些状态的动力学途径仍未得到充分探索。本研究提出了最小的实时自旋轨道模型，并确定了实现瞬态磁序涌现的基本微观机制。然后，利用现象学的时间相关 Ginzburg-Landau 模型讨论了这些发现与实际材料的相关性。最后，结合当前结果，分析了用于研究动态诱导的对称性破缺状态的当前第一性原理方法的优缺点。


<details>
  <summary>Details</summary>
Motivation: 旨在探索利用飞秒光脉冲在非磁性半导体中实现瞬态长程磁序的理论和实验挑战，特别是研究导致这些磁态的动力学途径。

Method: 提出了一个最小的实时自旋轨道模型，并利用现象学的时间相关 Ginzburg-Landau 模型来识别微观机制并讨论其在实际材料中的相关性。

Result: 识别了实现瞬态磁序涌现的基本微观机制，并讨论了其在实际材料中的相关性。

Conclusion: 分析了当前第一性原理方法在研究动态诱导的对称性破缺状态方面的优势和局限性。

Abstract: The stabilization of long-range magnetic order in nominally non-magnetic
semi- conductors using femtosecond light pulses is an exciting yet
experimentally challenging goal. Theoretical studies indicate that certain
non-magnetic semi- conductors can exhibit transient magnetic instabilities
following above-gap laser excitation, but the dynamical pathways leading to
these states remain largely unexplored. In this work, I introduce a minimal
real-time spin-orbital model and identify the fundamental microscopic
mechanisms that enable the emergence of a transient magnetic order. I then
discuss the relevance of these findings for real materials employing a
phenomenological time-dependent Ginzburg- Landau model. Finally, I analyze the
strengths and limitations of current first-principles methodologies for
investigating dynamically induced broken- symmetry states in the light of the
present results.

</details>


### [484] [Quaternary crystals CdZnTeSe: Growth via the vertical Bridgman method with different compositions of raw materials](https://arxiv.org/abs/2509.18634)
*S. V. Naydenov,O. K. Kapustnyk,I. M. Pritula,D. S. Sofronov,I. S. Terzin,N. O. Kovalenko*

Main category: cond-mat.mtrl-sci

TL;DR: Indium-doped CdZnTeSe crystals were grown using a new combined vertical Bridgman method with improved homogeneity and electrophysical properties.


<details>
  <summary>Details</summary>
Motivation: To explore a novel method for growing indium-doped CdZnTeSe crystals with enhanced homogeneity and electrophysical properties.

Method: Grew indium-doped CdZnTeSe crystals with various compositions using the vertical Bridgman method under high-pressure argon, employing a combined approach with simple and binary starting components. Theoretically analyzed permissible reactions for multicomponent crystal formation. Studied the homogeneity of atomic composition and electrical resistance (dark and illuminated).

Result: Crystals grown via the new combined method exhibited superior homogeneity in composition and electrophysical properties compared to other methods.

Conclusion: The new combined vertical Bridgman method is effective for growing indium-doped CdZnTeSe crystals with improved homogeneity and electrophysical properties.

Abstract: Indium-doped semiconductor crystals CdZnTeSe with several different
compositions of raw materials were grown via the vertical Bridgman method under
high-pressure argon. For the first time, these crystals were obtained via a
combined method from a mixture of simple and binary starting components. A
theoretical analysis of the permissible reactions for obtaining multicomponent
CdZnTeSe crystals from different compositions of starting materials was
performed. The homogeneity of the distribution of the atomic composition and
electrical resistance (in the dark and under illumination) of the obtained
crystals was studied. Crystals grown via the new combined method presented the
best homogeneity of composition and electrophysical properties.

</details>


### [485] [Quantifying the reactivity of isolated LixSi domains in Si anodes using operando NMR](https://arxiv.org/abs/2509.18352)
*Evelyna Wang,Marco-Tulio F. Rodrigues,Baris Key*

Main category: cond-mat.mtrl-sci

TL;DR: Si负极的日历老化是商业化的障碍，本研究利用原位核磁共振波谱技术研究了Li离子电池的Si负极在日历老化过程中的行为，发现了复杂的 the SEI层生长与溶解，以及锂的硅化物（LixSi）的形成和反应，其中一些LixSi会形成电化学隔离并自放电，且老化结果与硅颗粒类型和表面涂层有关。


<details>
  <summary>Details</summary>
Motivation: Si负极可以显著提高锂离子电池的能量密度，但日历老化是其商业化的主要障碍。

Method: 利用原位核磁共振波谱（NMR）技术，在日历老化过程中检测和量化Si负极中锂的硅化物（LixSi）的形成和反应。

Result: 实验直接证明了Si负极中存在复杂的日历老化现象，包括SEI层的生长与溶解，以及电化学隔离的LixSi的形成（即使在放电后仍有高度锂化的相存在）。研究还发现，这些隔离的LixSi会随着时间自放电。老化结果与硅颗粒的类型密切相关，某些表面涂层可以降低锂的硅化物与电解液的反应性。

Conclusion: Si负极的日历老化是一个复杂的过程，涉及SEI层的动态变化和锂硅化物的形成与自放电。通过控制硅颗粒的类型和使用表面涂层，可以改善Si负极的日历老化性能。

Abstract: The use of Si anodes can greatly improve the energy density of Li-ion
batteries. However, understanding and mitigation of calendar aging remains a
barrier to commercialization. In this short report, we utilize operando Nuclear
Magnetic Resonance (NMR) spectroscopy to detect and quantify lithium silicides
(LixSi) as they form and react within Si anodes in pouch cells during calendar
aging. We provide direct experimental evidence of complex aging phenomena in
the Si anodes, including both SEI growth and dissolution during storage.
Formation of electrochemically isolated LixSi is also observed, as indicated by
the partial persistence of highly lithiated phases after the cell is
discharged. Remarkably, we show that these isolated domains can themselves
self-discharge over time, suggesting that their detection can be challenging in
post-mortem studies. Finally, we show that aging outcomes depend heavily on the
type of silicon particles contained within the electrode, and that certain
surface coatings can help decrease the reactivity between lithium silicides and
the electrolyte.

</details>


### [486] [Atomistic mechanisms of oxidation and chlorine corrosion in Ni-based superalloys: The role of boron and light interstitial segregation](https://arxiv.org/abs/2509.19232)
*Tyler D. Doležal,Rodrigo Freitas,Ju Li*

Main category: cond-mat.mtrl-sci

TL;DR: 光间隙物（如硼和氧）通过重塑合金元素分布和偏析，从根本上改变了多组元镍基合金的界面化学。氧吸附促使硼从晶界迁移到自由表面，并与Cr、Fe、Mo共富集形成BO3三方结构。在无氧条件下，硼偏析至晶界。氯暴露后，氧化表面形成了新的Cl-M结合。高温MD模拟揭示了氯和Nb及BO3结构之间的相互作用。发现了一种新的稳定机制，其中亚表面硼原子锚定上层Cr中心，抑制其迁移，减轻氯驱动的位移。该研究强调了在反应条件下追踪光间隙物串扰和溶质迁移的必要性，为设计耐腐蚀表面化学提供了原子标准。


<details>
  <summary>Details</summary>
Motivation: 研究光间隙物（如硼和氧）在多组元镍基合金中的相互作用，及其对界面化学、元素分布和偏析的影响，并揭示其在不同环境（如氧化和卤素暴露）下的动态行为和稳定机制。

Method: 采用混合蒙特卡洛（HMC）和分子动力学（MD）模拟方法，结合高温MD模拟。

Result: 氧吸附驱动硼从晶界迁移到自由表面，并与Cr、Fe、Mo共富集形成BO3三方结构，同时促进M-O-M链的形成。无氧条件下，硼偏析至晶界。氯暴露后，氧化表面形成Cl-M结合，Cr、Fe、Mo进一步富集。高温MD模拟揭示了氯的向上拉力和Nb/BO3结构的抗变形能力之间的拉锯战，并发现亚表面硼原子锚定Cr中心的新稳定机制。

Conclusion: 硼在合金元素偏析和氧化物网络稳定中起双重作用，铌是增强卤素侵蚀下内聚力的关键元素。该研究强调了在反应条件下追踪光间隙物串扰和溶质迁移的重要性，为设计镍基高温合金的耐腐蚀表面化学提供了原子标准。

Abstract: Hybrid Monte Carlo and molecular dynamics simulations were used to
investigate the interaction of light interstitials in multi-element Ni-based
alloys. We show that light interstitials such as boron and oxygen fundamentally
alter interfacial chemistry by reshaping alloy-element distribution and
segregation. Oxygen adsorption drove boron migration from the grain boundary to
the free surface, where it co-enriched with Cr, Fe, and Mo and formed BO3
trigonal motifs embedded within mixed-metal oxide networks. Oxygen also
promoted M-O-M chain formation, including Nb2O5 clusters at the free surface.
In the absence of oxygen, boron segregated to the grain boundary, altering
local metal chemistry and underscoring a dynamic, environment-sensitive
behavior. Following chlorine exposure, the oxidized surfaces retained strong
O-mediated connectivity while forming new Cl-M associations, particularly with
Nb and Cr, and exhibited further surface enrichment in Cr, Fe, and Mo.
High-temperature MD simulations revealed a dynamic tug-of-war: chlorine exerted
upward pull and disrupted weakly anchored sites, while Nb- and BO3-rich oxide
motifs resisted deformation. A new stabilization mechanism was identified in
which subsurface boron atoms anchored overlying Cr centers, suppressing their
mobility and mitigating chlorine-driven displacement. These results demonstrate
boron's dual role as a modifier of alloy-element segregation and a stabilizer
of oxide networks, and identify Nb as a key element in reinforcing cohesion
under halogen attack. More broadly, this study highlights the need to track
light interstitial cross-talk and solute migration under reactive conditions,
offering atomistic criteria for designing corrosion-resistant surface
chemistries in Ni-based superalloys exposed to halogenated or oxidative
environments.

</details>


### [487] [Er$_\mathrm{Al}$:Al$_2$O$_3$ for Telecom-Band Photonics: Electronic Structure and Optical Properties](https://arxiv.org/abs/2509.18409)
*Mahtab A. Khan,Jayden D. Craft,Hari P. Paudel,Yuhua Duan,Dirk R. Englund,Michael N. Leuenberger*

Main category: cond-mat.mtrl-sci

TL;DR: Er-doped Al2O3是一种有前途的电信波段集成光子学材料。本研究利用从头算和对称性分析来研究Er在Al位点的取代（ErAl）在α-Al2O3中的行为。计算证实了ErAl的结构稳定性，并利用局部三方晶格对称性对Er能级进行了分类，推导了偏振分辨的电偶极选择规则，明确了对称性允许的f-d杂化通道。通过Kubo-Greenwood吸收光谱计算，定量验证了这些对称性预测。此外，还将计算得到的4f内谱线强度与Judd-Ofelt理论联系起来，阐明了4f-5d混合在光学活性中的作用。研究预测了在1.47μm（电信波段）附近的特征吸收，这对于片上放大和发射具有重要意义。该研究首次对Er:Al2O3进行了对称性分辨的第一性原理处理，并结合了Judd-Ofelt理论解释，为在宽带隙氧化物中定制稀土掺杂剂以用于集成光子学提供了一个可迁移的框架。计算的光谱结果与实验数据吻合良好。


<details>
  <summary>Details</summary>
Motivation: 研究Er在Al位点的取代（ErAl）在α-Al2O3中的行为，旨在为电信波段集成光子学提供有前景的材料，并阐明其光学性质的微观机制。

Method: 利用从头算（ab initio calculations）和对称性分析，结合第一性原理弛豫、对称性分类、偏振分辨电偶极选择规则推导、Kubo-Greenwood吸收光谱计算以及Judd-Ofelt理论分析。

Result: 证实了ErAl的结构稳定性；明确了对称性允许的f-d杂化通道；定量验证了对称性预测；阐明了4f-5d混合在光学活性中的作用；预测了在1.47μm（电信波段）附近存在特征吸收；计算的光谱结果与实验数据吻合良好。

Conclusion: Er-doped Al2O3是一种有前途的电信波段集成光子学材料。本研究通过对称性分辨的第一性原理处理和Judd-Ofelt理论解释，为理解和定制稀土掺杂剂在宽带隙氧化物中的应用提供了理论框架，并预测了其在光子器件中的应用潜力。

Abstract: Er-doped Al$_2$O$_3$ is a promising host for telecom-band integrated
photonics. Here we combine ab initio calculations with a symmetry-resolved
analysis to elucidate substitutional Er on the Al site (Er$_\mathrm{Al}$) in
$\alpha$-Al$_2$O$_3$. First-principles relaxations confirm the structural
stability of Er$_\mathrm{Al}$. We then use the local trigonal crystal-field
symmetry to classify the Er-derived impurity levels by irreducible
representations and to derive polarization-resolved electric-dipole selection
rules, explicitly identifying the symmetry-allowed $f$\textendash$d$
hybridization channels. Kubo--Greenwood absorption spectra computed from
Kohn--Sham states quantitatively corroborate these symmetry predictions.
Furthermore, we connect the calculated intra-$4f$ line strengths to Judd--Ofelt
theory, clarifying the role of $4f$\textendash$5d$ admixture in enabling
optical activity. Notably, we predict a characteristic absorption near
$1.47~\mu\mathrm{m}$ (telecom band), relevant for on-chip amplification and
emission. To our knowledge, a symmetry-resolved first-principles treatment of
Er:Al$_2$O$_3$ with an explicit Judd--Ofelt interpretation has not been
reported, providing a transferable framework for tailoring rare-earth dopants
in wide-band-gap oxides for integrated photonics. Our results for the optical
spectra are in good agreement with experimental data.

</details>


### [488] [Zero-field Anomalous Hall Effect in Bulk Single Crystal Mn3Ir](https://arxiv.org/abs/2509.18485)
*Xin Gu,Ruoqi Wang,Bo Zhao,Haofu Wen,Kunquan Hong,Shijun Yuan,Taishi Chen,Jinlan Wang*

Main category: cond-mat.mtrl-sci

TL;DR: Mn_3Ir是零场反常霍尔效应的领先平台，但体单晶生长困难。本文成功生长了化学计量比的Mn_3Ir体单晶，并通过磁化和AHE表征发现A型和B型反铁磁畴共存导致AHE信号微弱。


<details>
  <summary>Details</summary>
Motivation: 体单晶Mn_3Ir的生长和表征对于理解其内在磁性和电子性质至关重要，以推动反铁磁自旋电子学的发展。

Method: 使用高通量通量法生长了(111)-取向的六方Mn_3Ir单晶，并通过磁化和AHE进行了表征。

Result: 生长出了化学计量比的Mn_3Ir体单晶，并检测到微弱的AHE信号，归因于A型和B型反铁磁畴的共存，它们相互抵消了净AHE响应。

Conclusion: 该研究揭示了体Mn_3Ir内在磁性和AHE的关键方面，为开发先进的自旋电子器件提供了一个关键的材料平台。

Abstract: The L1_2-phase non-collinear antiferromagnet (AFM) Mn_3Ir has emerged as a
pioneering platform for realizing the zero-field anomalous Hall effect (AHE),
thereby catalyzing rapid advances in antiferromagnetic spintronics. Despite its
significant potential, experimental investigations of the intrinsic magnetic
and electronic properties of Mn_3Ir have been greatly hindered by the
formidable challenges in growing bulk single crystals. Here, we report the
growth of stoichiometric Mn_3Ir bulk single crystals and their characterization
in terms of magnetization and the AHE. Using a high-throughput flux method, we
obtained (111)-oriented hexagonal Mn_3Ir single crystals. A small AHE signal
was detected, which we attribute to the coexistence of A- and B-type
antiferromagnetic domains that mutually cancel the net AHE response. Our
results reveal key aspects of the intrinsic magnetic properties and AHE in bulk
Mn_3Ir, providing a critical material platform for the development of advanced
spintronic devices.

</details>


### [489] [Optical properties of RCd3P3 (R: Ce or La) compounds: Insulator-metal transition induced by displacement of atoms in the unit cell](https://arxiv.org/abs/2509.18549)
*Jaekyung Jang,Yu-Seong Seo,Jeonghun Lee,Eundeok Mun,Jungseek Hwang*

Main category: cond-mat.mtrl-sci

TL;DR: CeCd3P3 and LaCd3P3 are semiconductors, but atomic displacement can make them metallic. Optical spectroscopy confirms metallic behavior, and changes in phonons suggest a structural phase transition. CeCd3P3 is promising for studying the photoinduced Kondo effect.


<details>
  <summary>Details</summary>
Motivation: Investigate the electronic structures and optical properties of RCd3P3 (R = Ce or La) single crystals to understand their properties and potential applications.

Method: Performed first-principles analysis and optical spectroscopy on CeCd3P3 and LaCd3P3 single crystals.

Result: Both compounds exhibit semiconductor characteristics with narrow energy gaps (0.51 eV for CeCd3P3, 0.70 eV for LaCd3P3) theoretically. Atomic displacement leads to a metallic state. Optical spectroscopy reveals a metallic state with low charge carrier density. Significant modification of infrared-active phonons indicates a structural phase transition. CeCd3P3 has a metallic ground state with limited charge carriers.

Conclusion: The study elucidates the electronic and optical properties of CeCd3P3 and LaCd3P3, highlighting the impact of atomic structure on their electronic states. The compounds show potential for further research, particularly CeCd3P3 for the photoinduced Kondo effect.

Abstract: We examined the electronic structures and optical properties of single
crystals of RCd3P3 (R = Ce or La). Our first-principles analysis indicates that
CeCd3P3 and LaCd3P3 exhibit semiconductor characteristics with narrow energy
gaps of approximately 0.51 and 0.70 eV, respectively. Notably, a slight
displacement of the Cd and P atoms within the unit cell significantly
transforms the electronic structure from insulating to metallic state. Optical
spectroscopy of both compounds reveals a metallic state with a low charge
carrier density, suggesting a finite density of states at the Fermi level. A
comparison between the theoretical electronic structures and experimental
optical properties elucidates the observed metallic behavior. Additionally, the
notable modification of the infrared-active phonons strongly indicates a
structural phase transition in these compounds. Our findings also suggest that
CeCd3P3 serves as a suitable platform for investigating the photoinduced Kondo
effect due to its metallic ground state with limited charge carriers.

</details>


### [490] [Optical properties of popular dielectric substrate materials in a wide spectral range from far-infrared to ultraviolet](https://arxiv.org/abs/2509.18556)
*Minjae Kim,Hong Gu Lee,Jungseek Hwang*

Main category: cond-mat.mtrl-sci

TL;DR: 该研究调查了13种不同介电材料的光学特性，包括反射光谱、光学电导率、介电函数和带隙。


<details>
  <summary>Details</summary>
Motivation: 研究13种不同介电材料的光学特性，以获得其光学电导率、介电函数和带隙，并为生长在这些材料上的薄膜提供光学分析信息。

Method: 使用傅里叶变换红外光谱和单色光谱仪测量了13种不同介电材料（包括13种不同的材料）的单次反射光谱，覆盖了从远红外到紫外（80-50,000 cm-1）的宽光谱范围。利用Kramers-Kronig分析获得光学电导率和介电函数。测量了透射光谱以获得带隙。使用洛伦兹模型拟合反射光谱以获得声子结构。

Result: 每种介电材料都表现出独特的光子结构和光学带隙，这与材料的成分和晶体结构有关。研究结果为生长在这些材料上的薄膜的光学分析提供了有价值的信息。

Conclusion: 所研究的13种介电材料的光学特性（包括声子结构和光学带隙）与它们的成分和晶体结构相关。

Abstract: We investigated the optical properties of 13 different dielectric materials
(slide glass, quartz, Al2O3 (c-cut), DyScO3 (110), KTaO3 (001), LaAlO3 (001),
(LaAlO3)0.3-(Sr2AlTaO6)0.7 (001) (LSAT), MgF2 (100), MgO (100), SiC, SrTiO3
(001), TbScO3 (110), and TiO2). The single-bounce reflectance spectra of the
bulk samples were measured using Fourier transform infrared (FTIR) and
monochromatic spectrometers across a wide spectral range, from far infrared to
ultraviolet (80-50,000 cm-1). Using the Kramers-Kronig analysis, we obtained
the optical conductivity and dielectric function of the dielectric materials
from their measured reflectance spectra. Moreover, we measured the
transmittance spectra of the materials to obtain their bandgaps. We fitted the
measured reflectance spectra using the Lorentz model to obtain phononic
structures. Each dielectric material exhibits unique phononic structures and
optical bandgaps, associated with the composition and crystal structure of the
material. The observed optical properties of these dielectric materials provide
valuable information for the optical analysis of thin films grown on them.

</details>


### [491] [Large Anomalous and Topological Hall Effect and Nernst Effect in a Dirac Kagome Magnet Fe3Ge](https://arxiv.org/abs/2509.18590)
*Chunqiang Xu,Shuvankar Gupta,Hengxin Tan,Hyeonhu Bae,Olajumoke Oluwatobiloba Emmanuel,Mingyu Xu,Yan Wu,Xiaofeng Xu,Pengpeng Zhang,Weiwei Xie,Binghai Yan,Xianglin Ke*

Main category: cond-mat.mtrl-sci

TL;DR: Fe3Ge单晶在磁性、电子和热电性质方面表现出色，具有较大的反常霍尔效应和反常能尔斯特效应，以及由标量自旋手征引起的拓扑霍尔效应和拓扑能尔斯特系数，是室温下横向热电应用的有力候选者。


<details>
  <summary>Details</summary>
Motivation: 寻找具有非常规磁性和电子特性的kagome磁体。在Fe3Ge单晶中研究其磁性、电子和热电性质，特别是其反常霍尔效应、反常能尔斯特效应和拓扑霍尔效应。

Method: 实验测量了Fe3Ge单晶的磁性、电子和热电性质，并进行了第一性原理计算，以揭示其反常霍尔效应和反常能尔斯特效应的内在机制。

Result: Fe3Ge单晶具有大的反常霍尔效应和反常能尔斯特效应，其反常横向热电导率达到4.6 A m^-1 K^-1。此外，还观察到了0.9 microOhm cm的拓扑霍尔电阻率和1.2 microvolt K^-1的拓扑能尔斯特系数。第一性原理计算表明，这些响应主要由动量空间中的贝里曲率驱动，而拓扑效应则归因于标量自旋手征相关的贝里相位。

Conclusion: Fe3Ge单晶结合了动量空间和实空间的贝里相效应，展现出优异的横向热电性质，是室温下横向热电应用的有前景的材料。

Abstract: The search for kagome magnets with unconventional magnetic and electronic
properties has gained significant attention in recent years. We report the
magnetic, electronic, and thermoelectric properties of Fe3Ge single crystals,
where the Fe atoms form a slightly distorted kagome lattice. Fe3Ge exhibits a
large anomalous Hall effect and anomalous Nernst effect. The anomalous
transverse thermoelectric conductivity reaches about 4.6 A m^-1 K^-1, exceeding
values reported for conventional ferromagnets and most topological
ferromagnets. First-principles calculations indicate that these transport
responses are primarily governed by intrinsic mechanisms, highlighting the
dominant role of Berry curvature arising from massive Dirac gaps in momentum
space. In addition, we observe a topological Hall resistivity of about 0.9
microOhm cm and a topological Nernst coefficient of 1.2 microvolt K^-1, which
are attributed to the Berry phase associated with field-induced scalar spin
chirality. These findings demonstrate the combined influence of Berry phases in
both momentum and real space, establishing Fe3Ge as a promising candidate for
room-temperature transverse thermoelectric applications.

</details>


### [492] [First principles band structure of interacting phosphorus and boron/aluminum $δ$-doped layers in silicon](https://arxiv.org/abs/2509.19205)
*Quinn T. Campbell,Andrew D. Baczewski,Shashank Misra,Evan M. Anderson*

Main category: cond-mat.mtrl-sci

TL;DR: 硅中的磷或硼/铝 $\delta$ 层在小距离（<10 Å）会相互重叠并抵消，在较大的距离（>10 Å）会独立工作，形成类 P-N 结，并且在 20 Å 的间距下，磷和硼层之间的隧穿概率会增加。


<details>
  <summary>Details</summary>
Motivation: 研究磷 $\delta$ 层与硼或铝 $\delta$ 层之间的相互作用，以了解它们在不同分离距离下的行为，为设计基于相互作用的 $\delta$ 层的硅基电子器件奠定基础。

Method: 使用密度泛函理论计算磷 $\delta$ 层与硼或铝 $\delta$ 层相互作用的电子结构，并改变 $\delta$ 层之间的距离。

Result: 当 $\delta$ 层之间的距离为 10 Å 或更小时，掺杂剂电位会重叠并相互抵消，电子结构与块状硅非常相似。当距离大于 10 Å 时，两层独立工作，形成一个由本征层取代耗尽层的 P-N 二极管。在 20 Å 的距离下，磷和硼层之间的隧穿概率超过 3%，高于传统结的隧穿率。

Conclusion: $\delta$ 层之间的相互作用会增强较大分离距离下的隧穿效应，这为设计基于相互作用的 $\delta$ 层的硅基电子器件提供了基础。

Abstract: Silicon can be heavily doped with phosphorus in a single atomic layer (a
$\delta$ layer), significantly altering the electronic structure of the
conduction bands within the material. Recent progress has also made it possible
to further dope silicon with acceptor-based $\delta$ layers using either boron
or aluminum, making it feasible to create devices with interacting $\delta$
layers with opposite polarity. It is not known, however, how these $\delta$
layers will interact, particularly at small separation distances. Using Density
Functional Theory, we calculate the electronic structure of a phosphorus-based
$\delta$ layer interacting with a boron or aluminum $\delta$ layer, varying the
distances between the $\delta$ layers. At separations 10 \AA\ and smaller, the
dopant potentials overlap and largely cancel each other out, leading to an
electronic structure closely mimicking bulk silicon. At separations greater
than 10 \AA, the two layers behave independently of one another, forming a p-n
diode with an intrinsic layer taking the place of the depletion region. One
mechanism for charge transfer between $\delta$ layers at larger distances could
be tunneling, where we see a greater than 3\% probability for tunneling between
a phosphorus and boron layer at 20 \AA\ separation. This tunneling rate exceeds
what would be seen for a standard silicon 1.1 eV triangular barrier, indicating
that the interaction between delta layers creates enhanced tunneling at larger
separation distances compared to a traditional junction. These calculations
provide a foundation for the design of silicon-based electronics based on
interacting $\delta$ layers.

</details>


### [493] [A closed-loop AI framework for hypothesis-driven and interpretable materials design](https://arxiv.org/abs/2509.18604)
*Kangyu Ji,Tianran Liu,Fang Sheng,Shaun Tan,Moungi Bawendi,Tonio Buonassisi*

Main category: cond-mat.mtrl-sci

TL;DR: 该研究提出了一个结合了理论驱动的假设生成和数据驱动的假设检验的通用活性学习工作流，用于材料发现。


<details>
  <summary>Details</summary>
Motivation: 当前的材料发现方法在整合概念推理和数据驱动分析方面存在不足，本研究旨在弥合这一差距。

Method: 该工作流结合了由大型语言模型指导的自上而下的理论驱动假设生成，以及通过根源关联研究进行的自下而上的数据驱动假设检验。

Result: 研究成功设计了等摩尔五元阳离子二维钙钛矿，并通过活性学习和关联研究，在探索了极小设计空间（小于0.004%）的情况下，识别出了具有高相纯度的候选材料。同时，关联研究发现了影响相纯度的分子特征。

Conclusion: 该集成方法能够融合概念和统计假设，为等摩尔五元阳离子二维钙钛矿的相纯度提供可推广和理性的设计规则。该框架为复杂设计空间内的优化过程提供了可解释、可推广的设计规则，为理性、可扩展和高效的材料发现奠定了基础。

Abstract: Scientific hypothesis generation is central to materials discovery, yet
current approaches often emphasize either conceptual (idea-to-data) reasoning
or data-driven (data-to-idea) analysis, rarely achieving an effective
integration of both. Here, we present a generalizable active learning workflow
that integrates top-down, theory-driven hypothesis generation, guided by a
large language model. This is complemented by bottom-up, data-driven hypothesis
testing through a root-cause association study. We demonstrate this approach
through the design of equimolar quinary-cation two-dimensional perovskite, a
chemically complex system with over 850,000 possible cation combinations. In
the top-down component, the large language model drives closed-loop
optimization by proposing candidates that are likely to achieve phase purity,
leveraging domain knowledge and chain-of-thought reasoning. With each
iteration, the model identifies an increasing number of near phase-pure
compositions, sampling less than 0.004% of the design space. In parallel, the
bottom-up association study identifies molecular features with statistically
significant influences on phase purity. The integration of these approaches
enables the convergence of conceptual and statistical hypotheses, leading to
generalizable and rational design rules for phase-pure quinary-cation
two-dimensional perovskites. As a proof of concept, we applied the optimized
phase-pure quinary-cation two-dimensional perovskite film as a surface capping
layer in perovskite solar cells, achieving good performance and stability. Our
framework enables the development of interpretable and generalizable design
rules that are applicable to a wide range of optimization processes within
complex design spaces, providing a foundational strategy for rational,
scalable, and efficient materials discovery.

</details>


### [494] [Octahedral dynamics and local symmetry in hybrid perovskite FAPbI3 under thermal excitation](https://arxiv.org/abs/2509.18617)
*H. Joshi,K. C. Bhamu,A. Shankar,Rana Biswas,M. Wlazło*

Main category: cond-mat.mtrl-sci

TL;DR: DFT和AIMD模拟揭示了FAPbI3中PbI6八面体体积随温度变化的动力学行为，并解释了其对带隙的影响。


<details>
  <summary>Details</summary>
Motivation: 研究热激发下FAPbI3中局部结构单元（PbI6八面体）的演变及其对宏观电子性质的影响。

Method: 使用密度泛函理论（DFT）和从头分子动力学（AIMD）模拟研究了FAPbI3在热激发下的结构演变和电子结构。

Result: 随着温度升高，PbI6八面体体积分布变宽，八面体体积和键角减小，表明对称性破坏和局部环境多样化。FA阳离子的动力学行为是导致八面体体积变化和PbI6八面体软化的主要原因。结构变化直接导致带隙变化。

Conclusion: FAPbI3中热诱导的动力学行为是其宏观电子性质（如带隙）变化的原因，PbI6八面体在调节其电子性质方面起着关键作用。

Abstract: Density Functional Theory (DFT) and ab initio molecular dynamics (AIMD)
simulations have been employed to investigate the evolution of local motifs
within the tetragonal phase of FAPbI3 under thermal excitation. Our results
reveal a distinct broadening in the distribution of PbI6 octahedral volumes
with increasing temperature, indicating a gradual breakdown of symmetry and
emergence of diverse local environments. These octahedral volume distortions
are primarily driven by the dynamic behaviour of the FA cation leading to
softening of PbI6 octahedra, evident from calculated mean octahedral volume and
Pb-I-Pb bond angles. The examination of electronic structure confirmed that
this dynamic structural phenomenon is directly responsible for the change in
fundamental band gap value, highlighting the role of PbI6 octahedra in
modifying and modulating the electronic properties in FAPbI3. The results
demonstrate the microscopic origin of thermally induced dynamical behaviour to
the macroscopic electronic properties and underscore the pivotal role of local
motifs in hybrid perovskites.

</details>


### [495] [Beyond Bloch: A Theoretical Blueprint for Conjugated Polymer Optoelectronics](https://arxiv.org/abs/2509.18663)
*Miguel Lagos,Miguel Kiwi,Rodrigo Paredes*

Main category: cond-mat.mtrl-sci

TL;DR: 共轭聚合物在有机电子器件中显示出潜力，但需要新的理论框架来解释其电荷传输。该模型考虑了电子-电子相互作用，并预测了两种新的激发态，这些态遵循玻色-爱因斯坦统计并促进电荷传输。


<details>
  <summary>Details</summary>
Motivation: 需要一个新的理论框架来解释共轭聚合物中与布洛赫理论所描述的无机材料不同的电荷传输机制。

Method: 提出一个包含电子-电子相互作用（包括站内相互作用和交替位点之间的π态相互作用）的模型。

Result: 模型预测了两种新的、遵循玻色-爱因斯坦统计的平带激发态，这两种状态有助于电荷传输。该模型还能精确重现实验测得的紫外-可见吸收和电致发光光谱。

Conclusion: 该模型成功地解释了共轭聚合物的半导体特性和电荷传输机制，并得到了实验数据的支持。

Abstract: Conjugated polymers are experiencing a surge of renewed interest due to their
promising applications in various organic electronic devices. These include
organic light-emitting diodes (OLEDs), field-effect transistors (FETs), and
organic photovoltaic (OPV) devices, among many others. Their appeal stems from
distinct advantages they hold over traditional inorganic semiconductors. Unlike
inorganic semiconductors, where electrons are often considered to be in
delocalized, free, or quasi-free states (as described by Bloch's theory),
electrons in conjugated polymers behave differently. They are strongly coupled
within highly localized $\sigma$ or $\pi$-orbitals and interact significantly
with the ionic cores. This means they are far from the idealized delocalized
states presumed by Bloch's theory approaches. Consequently, after nearly a
century of applying Bloch's theory to the electronic transport properties of
inorganic materials, there is a clear need for a new theoretical framework to
explain efficient charge transport in these organic solids. Our presented model
addresses this need by incorporating crucial electron-electron interactions.
Specifically, it accounts for both intra-site interactions and interactions
between the $\pi$-states located at alternating sites along the polymer chain.
This framework provides a many-body charge conduction mechanism and explains
the semiconducting properties of the undoped material. A significant outcome of
our model is the prediction of two novel flat bands of excited bonding states.
Intriguingly, these states obey Bose--Einstein statistics and facilitate charge
transport. Furthermore, our model accurately reproduces experimental data,
providing an excellent fit for measured UV-Vis absorption and
electroluminescent spectra.

</details>


### [496] [A basis-free, octonionic criterion for Weyl points in solids](https://arxiv.org/abs/2509.18678)
*Christian Tantardini*

Main category: cond-mat.mtrl-sci

TL;DR: 提出了一种基于八元数结构的局部、无基底的Weyl点诊断新方法，消除了传统方法中的算法任意性，并简化了高通量搜索流程。


<details>
  <summary>Details</summary>
Motivation: 传统Weyl点诊断方法（如基于Berry通量和k·p线性化）存在算法任意性问题，依赖于用户选择的参数，不适用于第一性原理计算工作流。需要一种更稳健、内在化的诊断方法。

Method: 利用$\mathbb{R}^7$上的八元数结构，从一个平滑的两带投影算符构建一个单位八元数场及其八元数联络。通过将三个方向导数与G2不变的三形式收缩，得到一个赝标量密度，其符号即为Weyl的चिरैलिटी。通过检查八元数关联子的消失来确定局部问题在关联（四元数）三平面内闭合。

Result: 该方法消除了对封闭曲面和规范缝选择的依赖，并且在与Chern电荷和sgn(det v)的诊断方法等价。证明了该方法与传统诊断方法在某些条件下等价，并提供了一种实用的算法，兼容Wannier紧束缚哈密顿量。

Conclusion: 提出的八元数Weyl点判据是一种局部、无基底的方法，能够消除传统方法的算法任意性，简化高通量搜索，并在存在能带纠缠或接近多重简并点时提供内在的警示信号。

Abstract: Conventional diagnostics of Weyl points -- Berry flux on small spheres and $k
\cdot p$ linearization -- are topologically sound but depend on user choices
(sphere center and radius, gauge smoothing, charting, and local frame
transport) that introduce algorithmic arbitrariness in first-principles
workflows. We propose a \emph{local, basis-free} criterion built from the
octonionic structure on $\mathbb{R}^7$. From a smooth two-band projector we
construct a unit octonion field and its octonionic connection; contracting
three directional derivatives with the $\mathrm{G}_2$--invariant three-form
yields a pseudoscalar density whose sign equals the Weyl chirality. A vanishing
octonionic associator at leading order certifies that the local problem closes
inside an associative (quaternionic) three-plane, while a nonzero density
identifies a Weyl point. The construction is invariant under $\mathrm{SU}(2)$
gauge changes of the two-band subspace and under $\mathrm{G}_2$ rotations of
its completion, and it eliminates enclosing surfaces and gauge-seam choices. In
the linear regime we prove equivalence with the conventional diagnostics (Chern
charge on a small sphere and $\mathrm{sgn}\det v$). We outline a practical
algorithm compatible with Wannier tight-binding Hamiltonians and provide
self-consistency checks based on stencil refinement and the associator norm.
The \emph{octonionic Weyl point criterion} streamlines chirality assignment in
high-throughput searches and offers an intrinsic warning signal in the presence
of band entanglement or proximity to multi-fold touchings.

</details>


### [497] [Spin defects in hexagonal boron nitride as two-dimensional strain sensors](https://arxiv.org/abs/2509.18745)
*Z. Mu,Z. Zhang,J. Fraunié,C. Robert,G. Seine,B. Gil,G. Cassabois,V. Jacques*

Main category: cond-mat.mtrl-sci

TL;DR: V$_	ext{B}^-$ 色心可用于在六方氮化硼 (hBN) 中进行亚微米级应变传感。


<details>
  <summary>Details</summary>
Motivation: 精确测量二维材料的晶格变形对于基础科学和技术应用都很重要。

Method: 利用六方氮化硼 (hBN) 中的硼-空位 (V$_	ext{B}^-$) 色心进行应变传感。

Result: 精确量化了单轴应力下 hBN 薄片中 E$_{m 2g}$ 拉曼模式的应变诱导频移，确立了 V$_	ext{B}^-$ 色心作为范德华异质结构中应变计量的新工具。

Conclusion: V$_	ext{B}^-$ 色心可用于精确应变测量，并具有多功能传感能力，可用于研究应变工程二维材料。

Abstract: Lattice deformation is a powerful way to engineer the properties of
two-dimensional (2D) materials, making their precise measurement an important
challenge for both fundamental science and technological applications. Here, we
demonstrate that boron-vacancy (V$_\text{B}^-$) color centers in hexagonal
boron nitride (hBN) enable quantitative strain sensing with sub-micrometer
spatial resolution. Using this approach, we precisely quantify the
strain-induced shift of the E$_{\rm 2g}$ Raman mode in a hBN flake under
uniaxial stress, establishing V$_\text{B}^-$ centers as a new tool for strain
metrology in van der Waals heterostructures. Beyond strain sensing, our work
also highlights the unique multimodal sensing functionalities offered by
V$_\text{B}^-$ centers, which will be valuable for future studies of
strain-engineered 2D materials.

</details>


### [498] [Asymmetrical Defect Sink Behaviour of HCP/BCC Zr/Nb Multilayer Interfaces: Bubble-Denuded Zones at Nb Layers](https://arxiv.org/abs/2509.18818)
*Nabil. Daghbouj,H. S. Sen,Mohamed BenSalem,Jan. Duchoňc,Bingsheng. Li,Miroslav. Karlík,F. Ge,Vladimir. Krsjak,Petr. Báborh,M. O. Liedke,M. Butterling,Alexandre. Wagner,Bora. Karasulub,Tomas. Polcarak*

Main category: cond-mat.mtrl-sci

TL;DR: ZrNb纳米金属多层膜中的辐射引起的氦气泡形成和缺陷演变。Zr层比Nb层表现出更大的氦气泡和更高的肿胀，而Nb层在界面周围形成无气泡区。这是由于Zr和Nb之间原子传输性质的差异。ZrNb多层膜比单一材料具有更好的抗辐照性能。


<details>
  <summary>Details</summary>
Motivation: 核能系统中材料的结构完整性面临着辐射引起的氦气泡形成的挑战。

Method: 使用80 keV氦离子辐照ZrNb纳米金属多层膜、单晶铌和多晶锆。采用透射电子显微镜、二次离子质谱、扫描透射电子显微镜电子能量损失谱、纳米压痕、多普勒展宽正电子湮没光谱、正电子湮没寿命光谱和原子模拟等方法进行分析。

Result: Zr层显示出更大的氦气泡、更高的肿胀和氦保留，而Nb层在界面附近形成无气泡区。ZrNb多层膜比单一材料表现出较低的辐照硬化和氦保留。DFT计算表明Nb的空位和氦原子迁移势垒较低。

Conclusion: ZrNb纳米多层膜中的接口在驱动不对称辐射损伤方面起着关键作用，并且Nb层在抑制缺陷生长方面是有效的。ZrNb多层膜是比传统材料更能抵抗极端辐照环境的优选材料。

Abstract: Radiation induced helium bubble formation poses a major challenge to the
structural integrity of materials in nuclear energy systems. In this study, we
investigate defect evolution and He behavior in ZrNb nanoscale metallic
multilayers with immiscible BCC and HCP interfaces, irradiated with 80 keV He
ions. For comparison, single crystal Nb and polycrystalline Zr were also
irradiated under identical conditions to serve as reference materials. Using
cross sectional TEM, SIMS, STEM EELS, nanoindentation, Doppler Broadening
Positron Annihilation Spectroscopy, Positron Annihilation Lifetime
Spectroscopy, and atomistic simulations, we reveal a highly asymmetric damage
response across the multilayer interfaces. Zr layers exhibit larger He bubbles,
higher swelling, and greater helium retention while Nb layers develop
bubble-denuded zones exclusively around the interfaces, where bubble nucleation
is strongly suppressed and swelling is limited. This asymmetry arises from
differences in atomic transport properties DFT calculations show lower
migration barriers for vacancies and He atoms in Nb, enabling efficient defect
migration and recombination at interfaces, whereas Zr retains defects due to
higher migration barriers. EELS and DBS PALS measurements confirm bubble
densities and the presence of sub-nanometer open volumes. Compared to
monolithic samples, the ZrNb multilayers exhibit lower irradiation induced
hardening and reduced He retention. These findings highlight the role of
interfaces in driving asymmetric radiation damage and demonstrate the
effectiveness of BCC Nb layers in mitigating defect growth. Overall, ZrNb
multilayers are established as a superior alternative to conventional single
and polycrystalline materials for extreme irradiation environments.

</details>


### [499] [Quantum-to-classical transition and H-theorem in surface diffusion](https://arxiv.org/abs/2509.18844)
*E. E. Torres-Miyares,S. Miret-Artés*

Main category: cond-mat.mtrl-sci

TL;DR: 本文研究了从量子到经典动力学的转变，重点关注表面扩散的开放动力学。


<details>
  <summary>Details</summary>
Motivation: 研究表面扩散的开放动力学如何通过量子-经典转变，从纯量子态平滑过渡到经典态。

Method: 使用 Liouville-von Neumann 方程和 Caldeira-Leggett 形式主义，通过缩放普朗克常数来分析吸附质在平面上的布朗运动，特别关注了弹道和扩散运动这两种极端的时间行为。

Result: 在经典模型中，高斯函数由热速度决定，而在量子模型中，则由波包的初始扩散速度决定。这导致了经典和量子理想气体的概念。此外，还讨论了在 Pt(111) 表面上 H 和 D 扩散的 H 函数，以区分由隧穿和热激活扩散引起的不可逆性。

Conclusion: 本文探讨了量子-经典转变如何影响表面扩散的动力学，并提出了区分量子和经典扩散机制的方法。

Abstract: In this work, surface diffusion is studied with a different perspective by
showing how the corresponding open dynamics is transformed when passing, in a
continuous and smooth way, from a pure quantum regime to a full classical
regime; the so-called quantum-to-classical transition. This continuous process
is carried out from the Liouville-von Neumann equation by scaling Planck's
constant. For this goal, the Brownian motion of an adsorbate on a flat surface
is analyzed in order to show how this transition takes place. In particular,
this open dynamics is studied from the master equation for the reduced density
matrix within the Caldeira-Leggett formalism; in particular, the two extreme
time behaviors, the ballistic and diffusive motions. It is also shown that the
origin of the ballistic motion is different for the quantum and classical
regimes. In this scenario, the corresponding Gaussian function for the
intermediate scattering function is governed by the thermal velocity in the
classical regime versus the initial spreading velocity of the wave packet for
the quantum regime, leading to speak of classical and quantum ideal gas,
respectively. Finally, in the diffusive regime, and starting from the
Chudley-Elliott model, the quantum-to-classical transition is also discussed in
terms of the well-known H-function for three surface temperatures in the
diffusion of H and D on a Pt(111) surface. The main goal in this analysis is if
one can discriminate the irreversibility coming from tunneling and thermal
activation diffusion.

</details>


### [500] [Sub-nanosecond heat-based logic, writing and reset in an antiferromagnetic magnetoresistive memory](https://arxiv.org/abs/2509.18855)
*M. Surynek,A. Farkas,J. Zubac,P. Kubascik,K. Olejnik,F. Krizek,L. Nadvornik,T. Ostatnicky,R. P. Campion,V. Novak,T. Jungwirth,P. Nemec*

Main category: cond-mat.mtrl-sci

TL;DR: 本文研究了基于CuMnAs薄膜的磁热模拟记忆器件，实现了亚纳秒级的热逻辑运算和长时记忆存储，并能通过热脉冲快速重置。


<details>
  <summary>Details</summary>
Motivation: 本文旨在探索基于热脉冲的逻辑运算和记忆存储的实现，为构建热逻辑电路提供一种新的思路。

Method: 通过实验研究了CuMnAs薄膜器件对飞秒激光脉冲产生的热脉冲的响应。当热脉冲超过阈值温度时，器件将短时记忆中的逻辑运算结果转移到基于磁阻效应的长时记忆中，并通过热脉冲实现长时记忆的重置。

Result: 实现了亚纳秒级的in-memory热逻辑运算，并将运算结果以磁阻形式存储在长时记忆中，该存储可由电信号读出。同时，证明了可以通过热脉冲快速重置长时记忆。

Conclusion: 基于CuMnAs薄膜的磁热模拟记忆器件能够在亚纳秒级的时间尺度上执行热逻辑运算和存储，并能快速重置，这使其与GHz频率的电子器件兼容，为开发高速热逻辑电路提供了可能。

Abstract: Thermal logic aims to create thermal counterparts to electronic circuits. In
this work, we investigate experimentally the response of an analog memory
device based on a thin film of an antiferromagnetic metal CuMnAs to bursts of
heat pulses generated by the absorption of femtosecond laser pulses at room
ambient temperature. When a threshold temperature in the heat-based short-term
memory of the device is exceeded, the output of the in-memory logic operations
is transferred within the same device to a long-term memory, where it can be
retrieved at macroscopic times. The long-term memory is based on
magnetoresistive switching from a reference low-resistive uniform magnetic
state to high-resistive metastable nanofragmented magnetic states. The
in-memory heat-based logic operations and the conversion of the outputs into
the electrically-readable long-term magnetoresistive memory were performed at
sub-nanosecond time scales, making them compatible with the GHz frequencies of
standard electronics. Finally, we demonstrate the possibility of rapidly
resetting the long-term memory to the reference low-resistive state by heat
pulses.

</details>


### [501] [Giant optical anisotropy in CrSBr from giant exciton oscillator strength](https://arxiv.org/abs/2509.18866)
*Georgy Ermolaev,Tagir Mazitov,Arslan Mazitov,Adilet Toksumakov,Dmitriy Grudinin,Anton Minnekhanov,Gleb Tselikov,Dmitry Yakubovsky,Gleb Tikhonowski,Nikolay Pak,Umer Ahsan,Aleksandr Slavich,Mikhail Mironov,Alexey Tsapenko,Andrey Vyshnevyy,Ivan Kruglov,Zdenek Sofer,Aleksey Arsenin,Kostya Novoselov,Andrey Katanin,Valentyn Volkov*

Main category: cond-mat.mtrl-sci

TL;DR: CrSBr材料中的准一维激子表现出巨大的振荡器强度，这得益于降低的维度导致的电子-空穴波函数重叠增加，并与自旋涨落相关，从而实现了超紧凑的波片。


<details>
  <summary>Details</summary>
Motivation: 研究范德华材料中维度和电子关联如何影响光-物质相互作用，特别是如何最大化激子振荡器强度。

Method: 通过光学测量和从头计算研究CrSBr中的激子特性。

Result: 发现CrSBr中的准一维激子具有异常高的振荡器强度，并与自旋涨落有关，表现出巨大的双折射和各向异性波导特性，并成功实现了超紧凑的四分之一波片。

Conclusion: 维度工程在磁性范德华材料中对于实现新颖的光-物质耦合和开发超紧凑光子器件具有重要意义。

Abstract: The interplay between dimensionality and electronic correlations in van der
Waals (vdW) materials offers a powerful toolkit for engineering light-matter
interactions at the nanoscale. Excitons, bound electron-hole pairs, are central
to this endeavor, yet maximizing their oscillator strength, which dictates the
interaction cross-section, remains a challenge. Conventional wisdom suggests a
trade-off, where the observable oscillator strength often decreases in strongly
bound systems due to population dynamics. Here, we unveil a colossal oscillator
strength associated with the quasi-one-dimensional (quasi-1D) excitons in the
layered magnetic semiconductor CrSBr, which fundamentally defies this
established scaling law. Through comprehensive optical characterization and ab
initio calculations, we establish that this anomalous enhancement originates
directly from the reduced dimensionality, which enforces an increased
electron-hole wavefunction overlap. Moreover, we find a close connection
between fundamental exciton and local spin fluctuations that contribute to the
opening of the gap in the electronic spectrum. The resulting optical anisotropy
shows a giant in-plane birefringence (Delta_n = 1.45) and profoundly
anisotropic waveguiding, which we directly visualize using nano-optical
imaging. Leveraging this extreme response, we realize a true zero-order
quarter-wave plate with an unprecedented wavelength-to-thickness ratio
(lambda/t) exceeding 3.4, surpassing the limits of current miniaturization
technologies, including state-of-the-art metasurfaces. Our findings underscore
the profound impact of dimensionality engineering in magnetic vdW materials for
realizing novel regimes of light-matter coupling and developing next-generation
ultracompact photonic architectures.

</details>


### [502] [Chemistry and physics of layered oxychalcogenides containing an anti-cuprate type square lattice](https://arxiv.org/abs/2509.18870)
*Nicola Kelly*

Main category: cond-mat.mtrl-sci

TL;DR: 该综述探讨了含有[M2O]方形晶格层的层状固态材料，重点关注了它们与铜酸盐超导体中[CuO2]平面的反型结构关系。研究了M从早期（Ti, V）到晚期（Mn, Co, Fe）过渡金属的各种氧硫属化合物，并分析了这些化合物的结构、物理性质以及[M2O]层对其性质的影响。文章还讨论了软化学改性在合成新型范德华材料和亚稳态化合物中的应用，并展望了这些材料在块体、少层和单层极限下的未来发展方向。


<details>
  <summary>Details</summary>
Motivation: 由于[M2O]层是层状铜酸盐超导体中[CuO2]平面的反型结构，因此近年来对含有[M2O]方形晶格层的层状固态材料引起了广泛关注。

Method: 该综述系统地梳理了所有这些氧硫属化合物的结构和物理性质，并将这些性质与其共有的反型铜酸盐方形晶格[M2O]层联系起来。文章围绕金属离子M的不同氧化态进行组织，以探索M的电子构型对整个化合物物理性质的影响。

Result: 总结了具有[M2O]反铜酸盐层的层状氧硫属化合物的结构和物理性质，并强调了软化学改性在调节这些材料性质和合成新型范德华材料及其他亚稳态化合物中的作用。

Conclusion: 未来的研究方向包括在块体、少层和单层极限下探索这些材料的发展潜力。

Abstract: There has been significant recent interest in layered solid-state materials
containing an [M2O] square lattice layer (M = transition metal), particularly
because [M2O] is the anti-type of the [CuO2] planes in the layered cuprate
superconductors. In addition to the superconducting titanium oxypnictides, the
[M2O] anti-cuprate layer also occurs in a wide range of layered oxychalcogenide
compounds with M spanning early (Ti, V) to later transition metals (Mn, Co,
Fe). The chalcogenide in question - which sandwiches the anti-cuprate layer -
may be S, Se or Te, and in combination with a wide range of intervening
"spacer" layers, many different structural families have been investigated.
This review surveys the structures and physical properties of all these
oxychalcogenide materials and relates these properties to their common
anti-cuprate square lattice [M2O] layer. It is organised around the different
oxidation states of the metal ion M, in order to explore the effects of the
electronic configuration of M on the physical properties of each compound as a
whole. A key part of the review highlights the use of soft-chemical
modifications to alter physical properties of these materials, in the synthesis
of novel van der Waals materials and other metastable compounds. Future avenues
for these materials in the bulk, few- and single-layer limits are discussed.

</details>


### [503] [Nanoscale Strain Evolution and Grain Boundary-Mediated Defect Sink Behavior in Irradiated SiC: Insights from N-PED and DFT](https://arxiv.org/abs/2509.18895)
*Nabil Daghbouj,Ahmed. T. AlMotasem,Jan. Duchoňb,Bingsheng. Li,Mohamed. Bensalem,Frans. Munnik,Xin Ou,Anna. Macková,William. J. Weber,Tomas. Polcara*

Main category: cond-mat.mtrl-sci

TL;DR: 本研究利用纳米束精密电子衍射（N-PED）技术，结合高分辨率X射线衍射（HR-XRD）和密度泛函理论（DFT）计算，在高精度地表征了辐照诱导的碳化硅（SiC）材料中的应变梯度，特别是在多晶SiC的晶界（GB）附近。研究发现，晶界在辐照过程中扮演着缺陷汇的角色，表现出应变放大效应，并且通过原子 तिथे segregation 和点缺陷的结合机制，能够缓解氦（He）诱导的晶界脆化，为提升SiC材料的抗辐照性能提供了理论依据。


<details>
  <summary>Details</summary>
Motivation: 辐照诱导的应变是影响SiC材料抗辐照性能的关键因素，但传统方法难以精确表征多晶SiC中的纳米尺度应变梯度，因此需要开发新的表征技术来理解辐照损伤机制。

Method: 本研究采用了纳米束精密电子衍射（N-PED）技术，对单晶和多晶SiC进行多方向应变测量，并结合高分辨率X射线衍射（HR-XRD）模拟和密度泛函理论（DFT）计算，来分析辐照损伤和材料的应变行为。

Result: N-PED技术能够精确测量SiC材料中的应变梯度。研究发现在He+H辐照的单晶4H-SiC中，N-PED结果与HR-XRD模拟结果吻合良好。在He辐照的多晶α-SiC中，观察到晶界附近的空泡贫化区（BDZ），表明晶界是缺陷的活性汇。N-PED在高粉末SiC的晶界处观测到高达2.5%的应变放大，以及BDZ内的应变弛豫。DFT计算表明，Si、C和He原子有向晶界核心区迁移的趋势，这导致用于容纳He的空位减少，并在晶界附近产生局部应变弛豫。第一性原理拉伸模拟表明，Si和C的间隙原子能够缓解He引起的晶界脆化。

Conclusion: 晶界工程对于提高SiC材料的抗辐照性能至关重要。通过理解辐照诱导的应变机制，并利用Si、C原子间隙对He引起的晶界脆化的缓解作用，可以为核能和空间应用中的SiC材料设计提供指导。

Abstract: Understanding irradiation-induced strain in silicon carbide (SiC) is
essential for designing radiation-tolerant ceramic materials. However,
conventional methods often fail to resolve nanoscale strain gradients,
especially in polycrystalline forms. In this study, we employ nano-beam
precession electron diffraction (N-PED) to perform high-resolution,
multi-directional strain mapping in both single-crystal 4H-SiC and
polycrystalline {\alpha}-SiC subjected to helium and hydrogen ion irradiation.
The high-resolution X-ray diffraction (HR-XRD) simulations of He + H irradiated
single-crystal 4H-SiC closely match the strain profiles obtained from N-PED,
demonstrating the reliability and accuracy of the N-PED method. In
He-irradiated polycrystalline {\alpha}-SiC at high temperatures, a
bubble-depleted zone (BDZ) near the grain boundary (GB) reveals that GBs act as
active sinks for irradiation-induced defects. N-PED further shows strain
amplification localized at the GBs, reaching up to 2.5%, along with strain
relief within the BDZ. To explain this behavior, density functional theory
(DFT) calculations of binding and migration energies indicate a strong tendency
for Si, C, and He atoms to segregate toward the GB core. This segregation
reduces the availability of vacancies to accommodate He atoms and leads to
local strain relaxation near the GB. Furthermore, first-principles tensile
simulations reveal that Si and C interstitials mitigate He-induced GB
embrittlement. Charge density and DOS analyses link this effect to the bonding
characteristics between point defects and neighboring atoms at GB. These
insights underscore the importance of grain boundary engineering in enhancing
radiation tolerance of SiC for nuclear and space applications.

</details>


### [504] [Magnetic Ordering in Moiré Graphene Multilayers from a Continuum Hartree+U Approach](https://arxiv.org/abs/2509.18923)
*Christopher T. S. Cheung,Valerio Vitale,Lennart Klebl,Ammon Fischer,Dante M. Kennes,Arash A. Mostofi,Johannes Lischner,Zachary A. H. Goodwin*

Main category: cond-mat.mtrl-sci

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Recently, symmetry-broken ground states, such as correlated insulating
states, magnetic order and superconductivity, have been discovered in twisted
bilayer graphene (tBLG) and twisted trilayer graphene (tTLG) near the so-called
magic-angle. Understanding the magnetic order in these systems is challenging,
as atomistic methods become extremely expensive near the magic angle and
continuum approaches fail to capture important atomistic details. In this work,
we develop a self-consistent approach based on a continuum model that
incorporates both short-ranged Hubbard interactions and long-ranged Coulomb
interactions, therefore allowing efficient exploration of magnetic order in
moir\'e graphene multilayers. With this approach, we perform a systematic
analysis of the magnetic phase diagram of tBLG as a function of doping level
and twist angle, near the magic angle. We find that the results are consistent
with previous perturbative atomistic Hartree+U calculations. Furthermore, we
predict stable magnetic orders for the tTLG. We found that the magnetic orders
are similar to those in tBLG for small values of on-site repulsion. In the
future, the developed method can be utilized to investigate magnetic ordering
tendencies from short-range exchange interactions in other moir\'e graphene
multilayers as a function of doping, twist angle, screening environment, among
other variables.

</details>


### [505] [A Methodological Study on Data Representation for Machine Learning Modelling of Thermal Conductivity of Rare-Earth Oxides](https://arxiv.org/abs/2509.18951)
*Amiya Chowdhury,Acacio Rincón Romero,Eduardo Aguilar-Bejarano,Halar Memon,Grazziela Figueredo,Tanvir Hussain*

Main category: cond-mat.mtrl-sci

TL;DR: 图神经网络在热障涂层材料的QSAR建模中优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 热障涂层（TBC）材料的QSAR建模可以缩短实验周期，但传统方法受限于数据质量和材料表示。图神经网络可以提供更丰富的材料表示，并可能提高模型性能。

Method: 比较了基于手工描述符的随机森林（RF）和高斯过程（GP）模型与基于图表示（使用晶体图卷积神经网络，CGCNN）的模型在热障涂层材料上的性能。同时探索了两种数据增强方法。

Result: CGCNN模型在QSAR建模中表现显著优于RF和GP模型。

Conclusion: 基于图表示的CGCNN模型在热障涂层材料的QSAR建模中具有巨大潜力，能够显著提升模型性能。

Abstract: Quantitative structure-activity relationship (QSAR) modelling is widely
employed in materials sci- ence to predict properties of interest and extract
useful descriptors for measured properties. In thermal barrier coatings (TBC),
QSAR can significantly shorten the experimental discovery cycle, which can take
years. Although machine learning methods are commonly employed for QSAR, their
performance depends on the data quality and how instances are represented.
Traditional, hand-crafted descriptors based on known material properties are
limited to represent materials that share the same basic crystal structure,
limited the size of the dataset. By contrast, graph neural networks offer a
more expressive representation, encoding atomic positions and bonds in the
crystal lattice. In this study, we compare Random Forest (RF) and Gaussian
Process (GP) models trained on hand-crafted descriptors from the literature
with graph-based representations for high-entropy, rare-earth pyrochlore oxides
using the Crystal Graph Convolutional Neural Network (CGCNN). Two different
types of augmentation methods are also explored to account for the limited data
size, one of which is only applicable to graph-based representations. Our
findings show that the CGCNN model substantially outperforms the RF and GP
models, underscoring the potential of graph-based representations for enhanced
QSAR modelling in TBC research.

</details>


### [506] [Anharmonicity-driven phonon avoided crossing and anomalous thermal transport in nodal-line semimetal ZrSiS](https://arxiv.org/abs/2509.19081)
*Xin Jin,Qingqing Zhang,Dengfeng Li,Zhenxiang Cheng,Jianli Wang,Xuewei Lv,Xiaoyuan Zhou,Rui Wang,Xianyong Ding,Peng Yu,Xiaolong Yang*

Main category: cond-mat.mtrl-sci

TL;DR: ZrSiS材料中，非谐效应显著降低了晶格热导率，且其晶格热导率异常高，不遵循维德曼-弗兰兹定律。同时，其拓扑电子狄拉克态赋予了优异的导电性。


<details>
  <summary>Details</summary>
Motivation: 理解拓扑材料中的热电输运对于推动其在量子技术和能源转换中的应用至关重要。

Method: 利用第一性原理计算系统研究了ZrSiS的声子和电荷输运。

Result: 非谐声子重正化导致载热声子软化，抑制了晶格热导率。非谐效应还削弱了Zr-S相互作用，导致低频光学声子出现避免交叉。这些效应协同作用，在室温下沿c轴使晶格热导率降低了16%。ZrSiS的晶格热导率异常大，甚至超过了电子热导率，导致洛伦兹数显著偏离Sommerfeld值。ZrSiS具有优异的导电性，归因于其拓扑电子狄拉克态。

Conclusion: 该研究深入理解了ZrSiS的电热输运机制，并强调了非谐效应对金属材料晶格动力学和热输运的重要性。

Abstract: Understanding thermal and electrical transport in topological materials is
essential for advancing their applications in quantum technologies and energy
conversion. Herein, we employ first-principles calculations to systematically
investigate phonon and charge transport in the prototypical nodal-line
semimetal ZrSiS. The results unveil that anharmonic phonon renormalization
results in the pronounced softening of heat-carrying phonons and suppressed
lattice thermal conductivity ($\kappa_{\rm L}$). Crucially, anharmonic effects
are found to noticeably weaken Zr-S interactions, triggering avoided-crossing
behavior of low-frequency optical phonons. The combination of phonon softening
and avoided crossing synergistically reduces phonon group velocities, yielding
a 16\% suppression in $\kappa_{\rm L}$ along the $c$-axis at room temperature.
Contrary to conventional metals, we discover that the lattice contribution to
thermal conductivity in ZrSiS is abnormally large, even dominating heat
conduction along the $c$-axis. This unusual behavior results in a substantial
deviation of the Lorenz number from the Sommerfeld value -- exceeding it by up
to threefold -- thereby challenging the validation of standard Wiedemann-Franz
law for thermal conductivity estimation. Moreover, our calculations demonstrate
that ZrSiS exhibits exceptional electrical conductivity, attributed to its
topological electronic Dirac states that accounts for both high Fermi
velocities and weak electron-phonon coupling. This study provides critical
insights into the electrical and thermal transport mechanisms in ZrSiS and
highlights the importance of anharmonic effects in the lattice dynamics and
thermal transport of metallic materials.

</details>


### [507] [Trends in the electronic structure of borophene polymorphs](https://arxiv.org/abs/2509.19106)
*Alam Osorio,Lucia Reining,Francesco Sottile*

Main category: cond-mat.mtrl-sci

TL;DR: Borophene 是一种由纯硼原子组成的二维材料，具有多晶型和独特的电子结构。本研究探讨了不同硼烯变体的电子结构共享特征和模型局限性，揭示了缺陷样态和键合/反键合单层样态的出现。研究还表明，硼烯的褶皱可以作为调谐参数，实现半金属、狄拉克锥和费米面嵌套。


<details>
  <summary>Details</summary>
Motivation: 本研究旨在探索不同硼烯变体的电子结构共享特征，并研究其模型的局限性。

Method: 研究选取了一组代表性的硼烯变体（$m urthermore$, $m urthermore$, $m urthermore$, $m urthermore$, $m urthermore$, $m urthermore$, $m urthermore$-双层）进行了电子结构研究。

Result: 研究揭示了在某些变体中出现与母体刚性电子结构相关的缺陷样态，以及在$m urthermore$-双层中出现的键合/反键合单层样态。此外，研究还表明$m urthermore$和$m urthermore$的褶皱可以作为调谐参数，实现半金属、狄拉克锥和费米面嵌套。

Conclusion: 硼烯的独特电子结构和可调谐特性预示着其在未来具有广泛的应用前景，本研究期望能激发对更大、更复杂硼烯结构的研究兴趣。

Abstract: Borophene is a two-dimensional material made out of boron atoms only. It
exhibits polymorphism and different allotropes can be studied in terms of a
rigid electronic structure, where only the occupation of the states change with
the respect to the number of electrons available in the system (self-doping).
In this work we selected a set of representative borophene polymorphs
($\delta_3$, $\delta_5$, $\delta_6$, $\beta_{12}$ $\alpha_1$, $\alpha'$,
$\alpha'$-Bilayer) and studied the shared features of their electronic
structures and the limitations of this model. Our work revealed the appearance
of defect-like states in some polymorphs when related to a parent rigid
electronic structure, and bonding/antibonding monolayer-like states in the
$\alpha'$-Bilayer. Moreover, we show how the buckling of $\delta_6$ and
$\alpha'$ can act as a tuning parameter, enabling semimetallicity, Dirac cones,
and nesting of the Fermi surface. In light of their promises for exotic but
also useful behavior, we expect our work to foster the interest in larger and
more complex borophene structures.

</details>


### [508] [First principles and scanning tunneling spectroscopical evidences for thermodynamically stable "on-top" sulfur divacancy in monolayer WS$_{2}$](https://arxiv.org/abs/2509.19121)
*Weiru Chen,John C. Thomas,Yihuang Xiong,Zhuohang Yu,Da Zhou,Shalini Kumari,Zhongwei Dai,Joshua A. Robinson,Mauricio Terrones,Archana Raja,Sinéad Griffin,Alexander Weber-Bargioni,Geoffroy Hautier*

Main category: cond-mat.mtrl-sci

TL;DR: WS2单层材料中的硫空位对光电子学、催化和量子信息科学等应用至关重要。本研究使用第一性原理计算，重点研究了WS2单空位和双空位的热力学稳定性和电子结构。


<details>
  <summary>Details</summary>
Motivation: 为了识别和控制WS2单层材料中的硫空位，本研究对其进行了深入探究。

Method: 利用第一性原理计算，研究了WS2单空位和双空位的热力学稳定性和电子结构。

Result: 发现了一个"on-top"的二重空位结构，其结合能为160 meV，是唯一能量上稳定的复合物。该二重空位复合物的电子结构与单空位相比，未占据态移动了140 meV。通过扫描隧道谱技术观测到WS2中一系列空位的电子态移动，为二重空位缺陷的存在提供了光谱学证据。

Conclusion: WS2单层材料中的"on-top"二重空位是能量上稳定的缺陷，其电子结构的改变可以通过扫描隧道谱技术进行观测。

Abstract: Chalcogen vacancies in monolayer transition metal dichalcogenides (TMDs),
such as WS$_{2}$, play a crucial role in various applications ranging from
optoelectronics and catalysis to quantum information science (QIS), making
their identification and control essential. This study focuses on WS$_{2}$
single vacancy and vacancy pairs. Using first principles computations, we
investigate their thermodynamic stabilities and electronic structures. We
identify an "on-top" divacancy configuration where two vacancies sit on top of
each other to be the only energetically stable complex with a binding energy of
160 meV. We compute a small difference in electronic structure with a shift of
the unoccupied state by 140 meV for the divacancy complex and observe
electronic state shift during Scanning Tunneling Spectroscopy of a series of
vacancy in WS$_2$ providing spectroscopical evidence for the presence of this
defect.

</details>


### [509] [Exploring Cation Selection and Disorder within Entropy-Driven $A_{6}B_{2}$O$_{17}$ ($A$=Zr/Hf, $B$=Nb/Ta) Oxides](https://arxiv.org/abs/2509.19132)
*Jacob T. Sivak,R. Jackson Spurling,Jon-Paul Maria,Susan B. Sinnott*

Main category: cond-mat.mtrl-sci

TL;DR: DFT计算研究了A6B2O17（A=Zr/Hf，B=Nb/Ta）氧化物的结构、稳定性和缺陷化学，发现Ta化合物的带隙比Nb化合物大，并且所有成分都倾向于形成氧空位，但与AO2和B2O5相比，它们在焓上不稳定，属于熵稳定材料。


<details>
  <summary>Details</summary>
Motivation: 研究A6B2O17（A=Zr/Hf，B=Nb/Ta）氧化物的局部原子和电子结构、热力学稳定性和缺陷化学，以了解其性质并为未来成分调整提供基础。

Method: 使用第一性原理密度泛函理论（DFT）计算，研究有序和全无序的特殊类随机结构，并与实验结果进行比较。

Result: 结构预测与实验结果一致。电子结构强烈依赖于B阳离子种类：A6Ta2O17的带隙比A6Nb2O17大~30%。缺陷化学相似，氧空位比阳离子缺陷更有利。所有A6B2O17成分相对于AO2和B2O5是焓不稳定的，属于熵稳定材料。无序超晶胞预测与实验测量结果吻合，表明所有A6B2O17成分在所有配位点上都存在显著的阳离子无序。

Conclusion: DFT计算为A6B2O17材料家族提供了基础理解，并建立了未来通过成分调整来设计目标材料特性的框架。

Abstract: We investigate the local atomic and electronic structure, thermodynamic
stability, and defect chemistry of $A_{6}B_{2}$O$_{17}$ ($A$ = Zr/Hf, $B$ =
Nb/Ta) oxides using first-principles density functional theory (DFT)
calculations. We examine both ordered unit cells as well as fully disordered
special quasirandom structures to clearly discern the effects of cation
disorder. Structural predictions align closely with previous experimental
results and follow established ionic radii trends. The electronic structure is
strongly dependent on $B$-cation species: $A_{6}$Ta$_{2}$O$_{17}$ compositions
have ~30% larger band gaps than their $A_{6}$Nb$_{2}$O$_{17}$ counterparts.
Defect chemistry is similar for all compositions, with anion vacancies being
more energetically favorable than corresponding cation defects. All explored
$A_{6}B_{2}$O$_{17}$ compositions are enthalpically unstable with respect to
their $A$O$_{2}$ and $B_{2}$O$_{5}$ competing oxides and are therefore
classified as entropy-stabilized materials, supporting prior experimental
results. The pronounced agreement between our disordered supercell predictions
with experimental measurements indicates all explored $A_{6}B_{2}$O$_{17}$
compositions contain substantial cation disorder across all 6-, 7-, and
8-coordinated sites. Our findings collectively provide a fundamental
understanding of the $A_{6}B_{2}$O$_{17}$ material family through DFT
calculations, establishing a framework for future compositional tuning to
engineer targeted material properties.

</details>


### [510] [Optical probing of charge traps in organic field-effect transistors](https://arxiv.org/abs/2509.19155)
*Dean Kos,Marta Mas-Torrent*

Main category: cond-mat.mtrl-sci

TL;DR: 利用聚焦激光照明对有机场效应晶体管中的电荷陷阱进行空间分辨光学探测，发现陷阱与光照剂量和位置相关，并证实了其负电荷特性，为陷阱工程和器件优化提供了新思路。


<details>
  <summary>Details</summary>
Motivation: 为了研究有机场效应晶体管中的电荷陷阱，并探索其空间分布和影响。

Method: 通过扫描聚焦激光，同时记录器件的传输特性曲线，并结合开尔文探针显微镜技术来探测电荷陷阱。

Result: 观察到器件的开启电压出现持续的、局域化的偏移，且该偏移与光照剂量和位置相关。通过开尔文探针显微镜证实了扫描路径上存在负电荷陷阱。该现象在多种器件几何和有机半导体材料中均可重现。

Conclusion: 所提出的方法能够实现对电荷陷阱分布的直接绘制，并为陷阱工程、阈值电压调谐以及有机光电器件存储器的开发提供了新的策略。

Abstract: We report spatially resolved optical probing of charge traps in organic
field-effect transistors using focussed laser illumination. By scanning a 635
nm laser across the transistor channel and simultaneously acquiring transfer
characteristics, we observe persistent, localised shifts in transistor turn-on
voltage correlated with illumination dose and position, with negligible impact
on field-effect mobility. The effect is strongest 5-10 um from the source
electrode and requires a drain-to-source scan direction with sub-10 um step
size. Kelvin probe force microscopy confirms trapped negative charges along the
scan path, consistent with exciton dissociation and electron trapping near the
semiconductor-dielectric interface. The phenomenon is reproducible across
multiple device geometries and organic semiconductors, including
TMTES-pentacene, TIPS-pentacene, and diF-TES-ADT. These findings enable direct
mapping of trap distributions and suggest new strategies for trap engineering,
threshold voltage tuning, and development of organic optoelectronic memories.

</details>


### [511] [Detachment limited interlayer transport processes during SrTiO3 pulsed laser epitaxy](https://arxiv.org/abs/2509.19181)
*Jeffrey G. Ulbrandt,Xiaozhi Zhang,Randall L. Headrick*

Main category: cond-mat.mtrl-sci

TL;DR: 脉冲激光外延生长导致表面岛的成核，通过X射线反射和动力学蒙特卡罗模拟进行研究。


<details>
  <summary>Details</summary>
Motivation: 研究脉冲激光外延生长中瞬时岛的成核及其演化过程。

Method: 结合使用原位X射线反射和动力学蒙特卡罗（kMC）模拟。通过掠入射X射线反射监测层间传输，通过扩散散射揭示面内尺度演变。

Result: 在激光脉冲后的恢复时间内，初始阶段快于实验时间分辨率，随后恢复需要几秒钟。瞬时岛在稳定岛上形成，然后通过脱附和扩散成熟。kMC模拟表明脱附能垒是恢复时间常数的主要决定因素。

Conclusion: 脉冲激光外延生长过程中，瞬时岛的形成和成熟是影响表面形貌的关键因素，其动力学过程可以通过X射线反射和kMC模拟有效研究。

Abstract: Pulsed laser epitaxial growth is characterized by high instantaneous
deposition rates that leads to the nucleation of transient islands, both on
surface terraces, and on top of stable islands formed during previous
deposition pulses. We report results from combined in-situ X-ray reflectivity
and kinetic Monte Carlo (kMC) simulations. Specular reflectivity monitors
interlayer transport, while diffuse scattering reveals the evolution of
in-plane length scales, both during the recovery time between individual laser
pulses and over multiple deposited layers. The initial stage after each laser
pulse is faster than the temporal resolution of the experiment, while
subsequent recovery occurs over seconds. The results suggest that transient
islands on top of stable two-dimensional islands form immediately after the
deposition pulse, and then ripen via detachment and diffusion, leading to the
slower component. kMC simulations show that the detachment energy barrier plays
a dominant role in determining the recovery time constant.

</details>


### [512] [Molecular Insights into Caprock Integrity of Subsurface Hydrogen Storage: Perspective on Hydrogen-induced Swelling and Mechanical Response](https://arxiv.org/abs/2509.19283)
*Mehdi Ghasemi,Mohamad Ali Ghafari,Masoud Babaei,Valentina Erastova*

Main category: cond-mat.mtrl-sci

TL;DR: 氢气（H_2）的注入会影响钠基蒙脱石（Na+-Mt）的溶胀行为和力学性质，可能影响地下储氢的安全。


<details>
  <summary>Details</summary>
Motivation: 地质储氢需要可靠的长效盖层密封，但H_2与粘土矿物的纳米级相互作用对于储存安全性至关重要，目前仍未得到充分研究。

Method: 本研究使用分子模拟研究了不同水合状态和层间H_2含量的钠基蒙脱石（Mt）的溶胀行为和力学性质。

Result: 结果表明，H_2会加速水合状态的转变，缩小晶体溶胀的稳定性窗口，并在受限层间促进非对称羽流的形成。H_2改变了阳离子和水的配位，从而削弱了Na+-Mt的静电相互作用，并调节了界面和本体中的氢键网络。力学分析表明，Mt在面内刚度方面表现出明显的各向异性，主要受基面间距膨胀控制，而面外刚度则高度依赖于初始水中或H_2的存在，这会削弱层间内聚力。面内拉伸和压缩强度遵循面内刚度趋势，而面外拉伸强度则受Mt-水氢键控制。H_2的存在通过破坏纳米尺度的液桥进一步促进了Mt片的 الآخر。

Conclusion: 研究结果首次提供了原子尺度上的证据，表明插入的H_2会改变Mt的溶胀能量学、弹性各向异性和断裂路径，这凸显了在地下储氢过程中可能损害盖层完整性的关键纳米级机制。

Abstract: The geological storage of hydrogen (H_2) requires reliable long-term caprock
sealing, yet the nanoscale interactions between H_2 and clay minerals remain
critically underexplored despite their importance for storage security. This
lack of understanding has limited the ability to predict mechanical stability
and leakage risks in H_2 storage formations. Using molecular simulations, this
study investigates the swelling behavior and mechanical properties of sodium
montmorillonite (Mt), a common smectite clay, under varying hydration states
and interlayer H_2 contents. Results show that H_2 accelerates hydration-state
transitions, narrows the stability window of crystalline swelling, and promotes
asymmetric plume formation in confined interlayers. H_2 alters cation and water
coordination, thereby weakening Na^+--Mt electrostatic interactions and
modulating H-bond networks at the interface and in the bulk. Mechanical
analysis reveals pronounced anisotropy in Mt. In-plane stiffness is mainly
governed by basal spacing expansion, whereas out-of-plane stiffness is highly
sensitive to the initial presence of water or H_2, which weaken interlayer
cohesion. Tensile and compressive strengths in the in-plane directions follow
in-plane stiffness trends, while the out-of-plane tensile strength is governed
by Mt--water H-bonds. The presence of H_2 further promotes Mt sheets separation
by disrupting nanoscale liquid bridges. Collectively, these results provide the
first atomistic-scale evidence that intercalated H_2 reshapes swelling
energetics, elastic anisotropy, and failure pathways in Mt, highlighting
critical nanoscale mechanisms that may compromise caprock integrity during
underground H_2 storage.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [513] [PEEK: Guiding and Minimal Image Representations for Zero-Shot Generalization of Robot Manipulation Policies](https://arxiv.org/abs/2509.18282)
*Jesse Zhang,Marius Memmel,Kevin Kim,Dieter Fox,Jesse Thomason,Fabio Ramos,Erdem Bıyık,Abhishek Gupta,Anqi Li*

Main category: cs.RO

TL;DR: PEEK通过微调视觉-语言模型（VLM）来提取机器人操作的关键点，从而提高泛化能力，将‘何处’和‘何事’的推理交给VLM，让策略专注于‘如何行动’。


<details>
  <summary>Details</summary>
Motivation: 现有的机器人操作策略泛化能力不足，因为它们需要同时学习关注点、采取的行动以及如何执行。

Method: 提出PEEK（Policy-agnostic Extraction of Essential Keypoints）方法，通过微调VLM来预测统一的点状中间表示：1. 指定行动的末端执行器路径；2. 指示关注点的任务相关掩码。该表示可直接叠加在机器人观测上，实现策略无关性和跨架构可转移性。为实现可扩展训练，引入了自动标注流程，涵盖了20多个跨9种具身机器人的数据集。

Result: 在真实世界评估中，PEEK一致性地提升了零样本泛化能力，包括在仅模拟训练的3D策略上实现了41.4倍的真实世界性能提升，以及在大型VLA和小型操作策略上实现了2-3.5倍的收益。

Conclusion: 通过让VLM吸收语义和视觉复杂性，PEEK为操作策略提供了必需的最少线索——‘何处’、‘何事’和‘如何’，从而提高了泛化能力。

Abstract: Robotic manipulation policies often fail to generalize because they must
simultaneously learn where to attend, what actions to take, and how to execute
them. We argue that high-level reasoning about where and what can be offloaded
to vision-language models (VLMs), leaving policies to specialize in how to act.
We present PEEK (Policy-agnostic Extraction of Essential Keypoints), which
fine-tunes VLMs to predict a unified point-based intermediate representation:
1. end-effector paths specifying what actions to take, and 2. task-relevant
masks indicating where to focus. These annotations are directly overlaid onto
robot observations, making the representation policy-agnostic and transferable
across architectures. To enable scalable training, we introduce an automatic
annotation pipeline, generating labeled data across 20+ robot datasets spanning
9 embodiments. In real-world evaluations, PEEK consistently boosts zero-shot
generalization, including a 41.4x real-world improvement for a 3D policy
trained only in simulation, and 2-3.5x gains for both large VLAs and small
manipulation policies. By letting VLMs absorb semantic and visual complexity,
PEEK equips manipulation policies with the minimal cues they need--where, what,
and how. Website at https://peek-robot.github.io/.

</details>


### [514] [Fine-Tuning Robot Policies While Maintaining User Privacy](https://arxiv.org/abs/2509.18311)
*Benjamin A. Christie,Sagar Parekh,Dylan P. Losey*

Main category: cs.RO

TL;DR: PRoP是一个模型无关的框架，用于个性化和私有机器人策略，它使用唯一的密钥来转换网络权重，以匹配用户的偏好，同时防止外部代理访问这些数据。


<details>
  <summary>Details</summary>
Motivation: 现有的通用机器人策略在个性化时会泄露用户的偏好数据，因此需要一种在个性化机器人动作的同时保持学习私密性的方法。

Method: PRoP框架通过为每个用户配备一个唯一的密钥来转换机器人网络权重。正确的密钥会启用用户偏好的策略，而错误的密钥则使机器人恢复到基线行为。

Result: PRoP框架在模仿学习、强化学习和分类任务中被证明具有广泛的适用性，并且在实践中优于现有的基于编码器的方法。

Conclusion: PRoP框架提供了一种在不泄露用户偏好的情况下实现机器人个性化的有效方法，同时保持了原始策略的架构和行为。

Abstract: Recent works introduce general-purpose robot policies. These policies provide
a strong prior over how robots should behave -- e.g., how a robot arm should
manipulate food items. But in order for robots to match an individual person's
needs, users typically fine-tune these generalized policies -- e.g., showing
the robot arm how to make their own preferred dinners. Importantly, during the
process of personalizing robots, end-users leak data about their preferences,
habits, and styles (e.g., the foods they prefer to eat). Other agents can
simply roll-out the fine-tuned policy and see these personally-trained
behaviors. This leads to a fundamental challenge: how can we develop robots
that personalize actions while keeping learning private from external agents?
We here explore this emerging topic in human-robot interaction and develop
PRoP, a model-agnostic framework for personalized and private robot policies.
Our core idea is to equip each user with a unique key; this key is then used to
mathematically transform the weights of the robot's network. With the correct
key, the robot's policy switches to match that user's preferences -- but with
incorrect keys, the robot reverts to its baseline behaviors. We show the
general applicability of our method across multiple model types in imitation
learning, reinforcement learning, and classification tasks. PRoP is practically
advantageous because it retains the architecture and behaviors of the original
policy, and experimentally outperforms existing encoder-based approaches. See
videos and code here: https://prop-icra26.github.io.

</details>


### [515] [Haptic Communication in Human-Human and Human-Robot Co-Manipulation](https://arxiv.org/abs/2509.18327)
*Katherine H. Allen,Chris Rogers,Elaine S. Short*

Main category: cs.RO

TL;DR: 人类两人一组共同操作一个物体时，需要就各自意图的运动计划进行沟通。其中一部分协作是通过被操纵物体的运动本身来实现的，我们称之为“触觉通信”。本研究捕捉了人类两人一组共同移动一个物体时的运动，其中一名参与者领先执行一项跟随者不知情的运动计划。然后，我们捕捉了同一批参与者在与机器人协作者共同操作同一物体时的运动。通过使用低成本的惯性测量单元（IMU）跟踪共享物体的运动，我们可以直接比较人类之间的共享操作与同一批参与者与机器人交互时的运动。


<details>
  <summary>Details</summary>
Motivation: 研究人类两人一组共同操作物体时的触觉通信，并与人类与机器人协作进行比较，旨在改进机器人执行物理任务的能力。

Method: 捕捉人类两人一组共同操作物体（其中一人领先，另一人跟随）以及人类与机器人协作操作同一物体的运动。使用低成本惯性测量单元（IMU）跟踪共享物体的运动，并收集参与者的问卷反馈。

Result: 研究结果表明，人类之间的协作明显更流畅。IMU 数据分析显示，在运动模式方面，人类协作与人机协作之间存在客观差异。在准确性和流畅性方面，人类协作和人机协作在主客观测量指标上均存在差异。

Conclusion: 人类之间的协作比与机器人的协作更流畅，并且在运动模式上存在客观差异。这些差异表明，未来的机器人助手需要在执行物理任务时，能够发送和接收拟人化的触觉信号，以提高协作效果。

Abstract: When a human dyad jointly manipulates an object, they must communicate about
their intended motion plans. Some of that collaboration is achieved through the
motion of the manipulated object itself, which we call "haptic communication."
In this work, we captured the motion of human-human dyads moving an object
together with one participant leading a motion plan about which the follower is
uninformed. We then captured the same human participants manipulating the same
object with a robot collaborator. By tracking the motion of the shared object
using a low-cost IMU, we can directly compare human-human shared manipulation
to the motion of those same participants interacting with the robot.
Intra-study and post-study questionnaires provided participant feedback on the
collaborations, indicating that the human-human collaborations are
significantly more fluent, and analysis of the IMU data indicates that it
captures objective differences in the motion profiles of the conditions. The
differences in objective and subjective measures of accuracy and fluency
between the human-human and human-robot trials motivate future research into
improving robot assistants for physical tasks by enabling them to send and
receive anthropomorphic haptic signals.

</details>


### [516] [The Landform Contextual Mesh: Automatically Fusing Surface and Orbital Terrain for Mars 2020](https://arxiv.org/abs/2509.18330)
*Marsette Vona*

Main category: cs.RO

TL;DR: 该论文介绍了一种名为Landform contextual mesh的三维地形可视化技术，该技术融合了火星探测器图像和轨道遥感数据，可用于火星任务的规划和公众展示。


<details>
  <summary>Details</summary>
Motivation: 为火星任务的科学规划和公众教育提供交互式三维地形可视化工具。

Method: 通过融合火星探测器图像（2D）和轨道高程/颜色图（3D）数据，自动构建上下文网格，并用于交互式三维地形可视化。

Result: 创建了用于火星任务规划的上下文网格，并部分部署到公众访问网站。

Conclusion: Landform contextual mesh技术为火星探测任务提供了强大的可视化支持，有助于科学规划和公众参与。

Abstract: The Landform contextual mesh fuses 2D and 3D data from up to thousands of
Mars 2020 rover images, along with orbital elevation and color maps from Mars
Reconnaissance Orbiter, into an interactive 3D terrain visualization.
Contextual meshes are built automatically for each rover location during
mission ground data system processing, and are made available to mission
scientists for tactical and strategic planning in the Advanced Science
Targeting Tool for Robotic Operations (ASTTRO). A subset of them are also
deployed to the "Explore with Perseverance" public access website.

</details>


### [517] [Application Management in C-ITS: Orchestrating Demand-Driven Deployments and Reconfigurations](https://arxiv.org/abs/2509.18793)
*Lukas Zanger,Bastian Lampe,Lennart Reiher,Lutz Eckstein*

Main category: cs.RO

TL;DR: 该论文提出了一种基于Kubernetes的按需应用程序管理方法，以应对大规模协作式智能交通系统（C-ITS）中动态环境和资源利用率的挑战。


<details>
  <summary>Details</summary>
Motivation: 随着车辆自动化和互联化程度的提高，C-ITS和离线服务的应用日益广泛，云原生技术在其中扮演着越来越重要的角色。然而，大规模C-ITS中的应用程序编排面临动态环境和资源利用效率的独特挑战。

Method: 提出了一种按需应用程序管理方法，利用Kubernetes来应对这些挑战。该方法考虑了C-ITS内不同实体的需求，实现了微服务部署、重新配置、更新、升级和扩展等流程的自动化。通过按需执行这些流程，可以减少计算资源消耗和网络流量。该方法通过所提出的基于Kubernetes和ROS 2的应用程序管理框架，动态地协调不断变化的需求。

Result: 该框架在C-ITS集体环境感知用例中进行了演示，并公开了原型框架的源代码。

Conclusion: 所提出的按需应用程序管理方法能够有效地应对大规模C-ITS中的挑战，通过自动化和动态协调满足不断变化的需求，从而优化资源利用率。

Abstract: Vehicles are becoming increasingly automated and interconnected, enabling the
formation of cooperative intelligent transport systems (C-ITS) and the use of
offboard services. As a result, cloud-native techniques, such as microservices
and container orchestration, play an increasingly important role in their
operation. However, orchestrating applications in a large-scale C-ITS poses
unique challenges due to the dynamic nature of the environment and the need for
efficient resource utilization. In this paper, we present a demand-driven
application management approach that leverages cloud-native techniques -
specifically Kubernetes - to address these challenges. Taking into account the
demands originating from different entities within the C-ITS, the approach
enables the automation of processes, such as deployment, reconfiguration,
update, upgrade, and scaling of microservices. Executing these processes on
demand can, for example, reduce computing resource consumption and network
traffic. A demand may include a request for provisioning an external supporting
service, such as a collective environment model. The approach handles changing
and new demands by dynamically reconciling them through our proposed
application management framework built on Kubernetes and the Robot Operating
System (ROS 2). We demonstrate the operation of our framework in the C-ITS use
case of collective environment perception and make the source code of the
prototypical framework publicly available at
https://github.com/ika-rwth-aachen/application_manager .

</details>


### [518] [Semantic-Aware Particle Filter for Reliable Vineyard Robot Localisation](https://arxiv.org/abs/2509.18342)
*Rajitha de Silva,Jonathan Cox,James R. Heselden,Marija Popovic,Cesar Cadena,Riccardo Polvara*

Main category: cs.RO

TL;DR: 提出了一种结合了稳定物体级别检测（葡萄藤树干和支撑杆）的语义粒子滤波器，用于解决在葡萄园等结构化户外环境中，基于 LiDAR 的方法因重复的行几何和感知混淆而导致的定位失败问题。


<details>
  <summary>Details</summary>
Motivation: 在结构化户外环境中，移动机器人的精确定位至关重要，但基于 LiDAR 的方法在葡萄园中常因重复的行几何和感知混淆而失败。

Method: 提出了一种语义粒子滤波器，将稳定的物体级别检测（葡萄藤树干和支撑杆）纳入似然估计过程。检测到的地标被投影到鸟瞰图并与 LiDAR 扫描融合，生成语义观测。通过使用连接相邻地标的语义墙来缓解行的混淆，并在语义稀疏的区域引入带有噪声的 GPS 先验以保持全局一致性。

Result: 实验表明，该方法能够将定位保持在正确的行内，并在 AMCL 失败的偏差中恢复，性能优于 RTAB-Map 等视觉 SLAM 方法。

Conclusion: 所提出的语义粒子滤波器能够有效地解决葡萄园等重复几何环境中的定位问题，并通过融合语义信息和利用 GPS 先验来提高定位的鲁棒性和准确性。

Abstract: Accurate localisation is critical for mobile robots in structured outdoor
environments, yet LiDAR-based methods often fail in vineyards due to repetitive
row geometry and perceptual aliasing. We propose a semantic particle filter
that incorporates stable object-level detections, specifically vine trunks and
support poles into the likelihood estimation process. Detected landmarks are
projected into a birds eye view and fused with LiDAR scans to generate semantic
observations. A key innovation is the use of semantic walls, which connect
adjacent landmarks into pseudo-structural constraints that mitigate row
aliasing. To maintain global consistency in headland regions where semantics
are sparse, we introduce a noisy GPS prior that adaptively supports the filter.
Experiments in a real vineyard demonstrate that our approach maintains
localisation within the correct row, recovers from deviations where AMCL fails,
and outperforms vision-based SLAM methods such as RTAB-Map.

</details>


### [519] [Proactive-reactive detection and mitigation of intermittent faults in robot swarms](https://arxiv.org/abs/2509.19246)
*Sinan Oğuz,Emanuele Garone,Marco Dorigo,Mary Katherine Heinrich*

Main category: cs.RO

TL;DR: 现有的机器人群可靠性研究主要关注永久性故障，而忽略了间歇性故障。本文提出了一种在新提出的自组织神经系统（SoNS）方法基础上，针对机器人群间歇性故障的主动-反应策略，利用自组织备份层和多层网络中的分布式共识来检测和缓解间歇性故障。


<details>
  <summary>Details</summary>
Motivation: 现有的机器人群可靠性研究主要关注永久性故障，但忽略了在机器人群中普遍存在且难以检测的间歇性故障。SoNS方法的出现为解决这个问题提供了新的可能性。

Method: 提出了一种主动-反应策略，包括：1. 主动构建动态备份路径以应对网络拓扑和机器人位置的变化。2. 反应式地使用单次似然比检验来检测故障。3. 故障检测后，通信被暂时重路由。4. 利用自组织备份层和多层网络中的分布式共识。

Result: 在有代表性的故障位置数据场景下，验证了该方法在机器人编队控制中的有效性。结果表明，该方法能够有效防止间歇性故障干扰编队收敛，并且具有高故障检测准确率和低误报率。

Conclusion: 本文提出的主动-反应策略能够有效地检测和缓解机器人群中的间歇性故障，确保了编队控制的可靠性。

Abstract: Intermittent faults are transient errors that sporadically appear and
disappear. Although intermittent faults pose substantial challenges to
reliability and coordination, existing studies of fault tolerance in robot
swarms focus instead on permanent faults. One reason for this is that
intermittent faults are prohibitively difficult to detect in the fully
self-organized ad-hoc networks typical of robot swarms, as their network
topologies are transient and often unpredictable. However, in the recently
introduced self-organizing nervous systems (SoNS) approach, robot swarms are
able to self-organize persistent network structures for the first time, easing
the problem of detecting intermittent faults. To address intermittent faults in
robot swarms that have persistent networks, we propose a novel
proactive-reactive strategy to detection and mitigation, based on
self-organized backup layers and distributed consensus in a multiplex network.
Proactively, the robots self-organize dynamic backup paths before faults occur,
adapting to changes in the primary network topology and the robots' relative
positions. Reactively, robots use one-shot likelihood ratio tests to compare
information received along different paths in the multiplex network, enabling
early fault detection. Upon detection, communication is temporarily rerouted in
a self-organized way, until the detected fault resolves. We validate the
approach in representative scenarios of faulty positional data occurring during
formation control, demonstrating that intermittent faults are prevented from
disrupting convergence to desired formations, with high fault detection
accuracy and low rates of false positives.

</details>


### [520] [AD-VF: LLM-Automatic Differentiation Enables Fine-Tuning-Free Robot Planning from Formal Methods Feedback](https://arxiv.org/abs/2509.18384)
*Yunhao Yang,Junyuan Hong,Gabriel Jacob Perin,Zhiwen Fan,Li Yin,Zhangyang Wang,Ufuk Topcu*

Main category: cs.RO

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Large language models (LLMs) can translate natural language instructions into
executable action plans for robotics, autonomous driving, and other domains.
Yet, deploying LLM-driven planning in the physical world demands strict
adherence to safety and regulatory constraints, which current models often
violate due to hallucination or weak alignment. Traditional data-driven
alignment methods, such as Direct Preference Optimization (DPO), require costly
human labeling, while recent formal-feedback approaches still depend on
resource-intensive fine-tuning. In this paper, we propose LAD-VF, a
fine-tuning-free framework that leverages formal verification feedback for
automated prompt engineering. By introducing a formal-verification-informed
text loss integrated with LLM-AutoDiff, LAD-VF iteratively refines prompts
rather than model parameters. This yields three key benefits: (i) scalable
adaptation without fine-tuning; (ii) compatibility with modular LLM
architectures; and (iii) interpretable refinement via auditable prompts.
Experiments in robot navigation and manipulation tasks demonstrate that LAD-VF
substantially enhances specification compliance, improving success rates from
60% to over 90%. Our method thus presents a scalable and interpretable pathway
toward trustworthy, formally-verified LLM-driven control systems.

</details>


### [521] [Assistive Decision-Making for Right of Way Navigation at Uncontrolled Intersections](https://arxiv.org/abs/2509.18407)
*Navya Tiwari,Joseph Vazhaeparampil,Victoria Preston*

Main category: cs.RO

TL;DR: 该研究提出了一种用于无控制交叉路口的驾驶员辅助框架，通过部分可观察马尔可夫决策过程（POMDP）解决路权问题，并在模拟环境中评估了四种决策方法，证明了概率规划器在减少碰撞方面的优越性。


<details>
  <summary>Details</summary>
Motivation: 无控制交叉路口因规则模糊、视野遮挡和不可预测的驾驶行为导致交通事故频发。现有自动驾驶研究虽关注不确定性感知决策，但针对人类驾驶车辆的导航辅助系统却很少。

Method: 将无控制交叉路口的譲路问题构建为部分可观察马尔可在夫决策过程（POMDP）。使用包含随机交通、行人、遮挡和对抗性场景的自定义模拟测试平台，评估了确定性有限状态机（FSM）、QMDP、POMCP和DESPOT这四种决策方法。

Result: 概率规划器优于基于规则的基线方法，在部分可观察性下实现了高达97.5%的无碰撞导航。其中，POMCP优先考虑安全，而DESPOT在效率和运行时间可行性之间取得了平衡。

Conclusion: 不确定性感知规划对于驾驶员辅助至关重要。未来的研究应侧重于融合传感器和环境感知模块，以实现真实的实时交通环境部署。

Abstract: Uncontrolled intersections account for a significant fraction of roadway
crashes due to ambiguous right-of-way rules, occlusions, and unpredictable
driver behavior. While autonomous vehicle research has explored
uncertainty-aware decision making, few systems exist to retrofit human-operated
vehicles with assistive navigation support. We present a driver-assist
framework for right-of-way reasoning at uncontrolled intersections, formulated
as a Partially Observable Markov Decision Process (POMDP). Using a custom
simulation testbed with stochastic traffic agents, pedestrians, occlusions, and
adversarial scenarios, we evaluate four decision-making approaches: a
deterministic finite state machine (FSM), and three probabilistic planners:
QMDP, POMCP, and DESPOT. Results show that probabilistic planners outperform
the rule-based baseline, achieving up to 97.5 percent collision-free navigation
under partial observability, with POMCP prioritizing safety and DESPOT
balancing efficiency and runtime feasibility. Our findings highlight the
importance of uncertainty-aware planning for driver assistance and motivate
future integration of sensor fusion and environment perception modules for
real-time deployment in realistic traffic environments.

</details>


### [522] [Latent Action Pretraining Through World Modeling](https://arxiv.org/abs/2509.18428)
*Bahey Tharwat,Yara Nasser,Ali Abouzeid,Ian Reid*

Main category: cs.RO

TL;DR: LAWM是一个模型无关的自监督预训练框架，用于学习机器人模仿学习模型中的潜在动作表示，通过世界建模从无标签视频数据中学习，并在多个基准测试中表现优于现有方法，同时更高效实用。


<details>
  <summary>Details</summary>
Motivation: 现有的大型视觉-语言-动作（VLA）模型在机器人操作任务中表现良好，但其巨大的模型尺寸给实际部署带来了挑战。虽然一些方法引入了潜在动作表示以实现无监督预训练，但仍有改进空间。

Method: 提出LAWM框架，该框架模型无关，通过世界建模从无标签视频数据（包括机器人录像和人类操作视频）中学习潜在动作表示，用于自监督预训练模仿学习模型。

Result: LAWM在LIBERO基准测试和实际设置中，其性能优于使用真实机器人动作和类似预训练方法训练的模型，并且在实际应用中更高效、更实用。

Conclusion: LAWM是一个有效的模型无关框架，可以通过自监督学习潜在动作表示，为机器人模仿学习提供了一种更高效、更实用的预训练方法，能够跨任务、环境和具身进行迁移。

Abstract: Vision-Language-Action (VLA) models have gained popularity for learning
robotic manipulation tasks that follow language instructions. State-of-the-art
VLAs, such as OpenVLA and $\pi_{0}$, were trained on large-scale, manually
labeled action datasets collected through teleoperation. More recent
approaches, including LAPA and villa-X, introduce latent action representations
that enable unsupervised pretraining on unlabeled datasets by modeling abstract
visual changes between frames. Although these methods have shown strong
results, their large model sizes make deployment in real-world settings
challenging. In this work, we propose LAWM, a model-agnostic framework to
pretrain imitation learning models in a self-supervised way, by learning latent
action representations from unlabeled video data through world modeling. These
videos can be sourced from robot recordings or videos of humans performing
actions with everyday objects. Our framework is designed to be effective for
transferring across tasks, environments, and embodiments. It outperforms models
trained with ground-truth robotics actions and similar pretraining methods on
the LIBERO benchmark and real-world setup, while being significantly more
efficient and practical for real-world settings.

</details>


### [523] [PrioriTouch: Adapting to User Contact Preferences for Whole-Arm Physical Human-Robot Interaction](https://arxiv.org/abs/2509.18447)
*Rishabh Madan,Jiawei Lin,Mahika Goel,Angchen Xie,Xiaoyu Liang,Marcus Lee,Justin Guo,Pranav N. Thakkar,Rohan Banerjee,Jose Barreiros,Kate Tsui,Tom Silver,Tapomayukh Bhattacharjee*

Main category: cs.RO

TL;DR: PrioriTouch是一个用于处理物理人机交互中多接触点不兼容力反馈需求的框架，通过学习排序和分层操作空间控制，能够根据用户偏好进行调整，并在模拟和真实世界实验中验证了其适应性、任务性能、安全性和舒适性。


<details>
  <summary>Details</summary>
Motivation: 在物理人机交互（pHRI）中，机器人需要适应个体接触偏好（如接触位置和力的大小），但多个接触点可能带来不兼容的力反馈需求，尤其是在护理任务中，冲突难以避免。因此，需要一个能够处理多重偏好、进行权衡和优先级排序的系统。

Method: PrioriTouch框架结合了新颖的学习排序方法和分层操作空间控制，并利用了仿真内循环（simulation-in-the-loop）进行数据高效且安全的探索。此外，还结合了用户研究中获得的个性化舒适阈值。

Result: PrioriTouch在模拟和真实世界实验中表现出色，能够适应用户的接触偏好，保持任务性能，并提高安全性和舒适性。

Conclusion: PrioriTouch框架成功地解决了物理人机交互中多接触点不兼容的力反馈需求问题，通过优先级排序和自适应控制，实现了对用户偏好的个性化适应，并在各种应用场景中展现了其有效性。

Abstract: Physical human-robot interaction (pHRI) requires robots to adapt to
individual contact preferences, such as where and how much force is applied.
Identifying preferences is difficult for a single contact; with whole-arm
interaction involving multiple simultaneous contacts between the robot and
human, the challenge is greater because different body parts can impose
incompatible force requirements. In caregiving tasks, where contact is frequent
and varied, such conflicts are unavoidable. With multiple preferences across
multiple contacts, no single solution can satisfy all objectives--trade-offs
are inherent, making prioritization essential. We present PrioriTouch, a
framework for ranking and executing control objectives across multiple
contacts. PrioriTouch can prioritize from a general collection of controllers,
making it applicable not only to caregiving scenarios such as bed bathing and
dressing but also to broader multi-contact settings. Our method combines a
novel learning-to-rank approach with hierarchical operational space control,
leveraging simulation-in-the-loop rollouts for data-efficient and safe
exploration. We conduct a user study on physical assistance preferences, derive
personalized comfort thresholds, and incorporate them into PrioriTouch. We
evaluate PrioriTouch through extensive simulation and real-world experiments,
demonstrating its ability to adapt to user contact preferences, maintain task
performance, and enhance safety and comfort. Website:
https://emprise.cs.cornell.edu/prioritouch.

</details>


### [524] [Learning Geometry-Aware Nonprehensile Pushing and Pulling with Dexterous Hands](https://arxiv.org/abs/2509.18455)
*Yunshuang Li,Yiyang Ling,Gaurav S. Sukhatme,Daniel Seita*

Main category: cs.RO

TL;DR: 该研究提出了一种名为GD2P（Geometry-aware Dexterous Pushing and Pulling）的方法，使用多指灵巧手进行非抓取式操作（如推和拉），以应对几何形状、尺寸或与机器人/环境关系而难以抓取的物体。


<details>
  <summary>Details</summary>
Motivation: 现有非抓取式操作研究多依赖于平行颚夹具或工具，而多指灵巧手虽操作模式丰富，但其动力学建模困难。本研究旨在利用灵巧手的优势，克服建模难题，实现更通用的非抓取式操作。

Method: GD2P方法通过综合和学习预接触的灵巧手姿势来合成有效的操作。具体步骤包括：1. 使用接触引导采样生成多样化的手部姿势；2. 通过物理模拟过滤这些姿势；3. 训练一个以物体几何为条件的扩散模型来预测可行的姿势；4. 在测试时，采样手部姿势并利用标准运动规划器选择和执行推拉动作。

Result: 在Allegro Hand上进行了840次真实世界实验，并将GD2P与基线方法进行了比较，结果表明GD2P为训练灵巧的非抓取式操作策略提供了一条可扩展的途径。该方法还成功应用于LEAP Hand，证明了其对不同手部形态的适用性。

Conclusion: GD2P是一种利用灵巧手进行非抓取式操作（推和拉）的有效方法，通过几何感知和学习预接触姿势，克服了传统方法的局限性。该方法具有可扩展性，并能适应不同的手部形态，为机器人操作领域提供了新的解决方案。研究还开源了预训练模型和数据集，以促进未来研究。

Abstract: Nonprehensile manipulation, such as pushing and pulling, enables robots to
move, align, or reposition objects that may be difficult to grasp due to their
geometry, size, or relationship to the robot or the environment. Much of the
existing work in nonprehensile manipulation relies on parallel-jaw grippers or
tools such as rods and spatulas. In contrast, multi-fingered dexterous hands
offer richer contact modes and versatility for handling diverse objects to
provide stable support over the objects, which compensates for the difficulty
of modeling the dynamics of nonprehensile manipulation. Therefore, we propose
Geometry-aware Dexterous Pushing and Pulling (GD2P) for nonprehensile
manipulation with dexterous robotic hands. We study pushing and pulling by
framing the problem as synthesizing and learning pre-contact dexterous hand
poses that lead to effective manipulation. We generate diverse hand poses via
contact-guided sampling, filter them using physics simulation, and train a
diffusion model conditioned on object geometry to predict viable poses. At test
time, we sample hand poses and use standard motion planners to select and
execute pushing and pulling actions. We perform 840 real-world experiments with
an Allegro Hand, comparing our method to baselines. The results indicate that
GD2P offers a scalable route for training dexterous nonprehensile manipulation
policies. We further demonstrate GD2P on a LEAP Hand, highlighting its
applicability to different hand morphologies. Our pre-trained models and
dataset, including 1.3 million hand poses across 2.3k objects, will be
open-source to facilitate further research. Our project website is available
at: geodex2p.github.io.

</details>


### [525] [A Counterfactual Reasoning Framework for Fault Diagnosis in Robot Perception Systems](https://arxiv.org/abs/2509.18460)
*Haeyoon Han,Mahdi Taheri,Soon-Jo Chung,Fred Y. Hadaegh*

Main category: cs.RO

TL;DR: 本研究提出了一种利用反事实推理进行自动驾驶感知系统故障检测与隔离（FDI）的框架，该框架不依赖物理冗余，而是利用分析冗余和反事实推理来构建感知可靠性测试，并将其视为受系统状态和故障场景影响的因果结果。


<details>
  <summary>Details</summary>
Motivation: 感知系统对自动驾驶系统的决策至关重要，因此准确检测和隔离感知系统中的故障非常重要。感知系统故障的特点是与环境感知上下文相关，并且多级流水线中的错误会跨模块传播。

Method: 提出了一种利用反事实推理的框架，用于感知系统的故障检测与隔离（FDI）。该方法利用分析冗余和反事实推理来构建感知可靠性测试，并将其视为受系统状态和故障场景影响的因果结果。通过反事实推理生成假设故障下的可靠性测试结果，以更新故障假设的置信度。推导了被动和主动FDI方法，其中主动FDI被定义为因果老虎机问题，利用蒙特卡洛树搜索（MCTS）和上限信赖（UCB）来寻找最大化有效信息（EI）的控制输入，EI量化了控制输入对FDI的信息量。

Result: 在机器人探索场景中，通过视觉导航进行操作的太空机器人主动调整其姿态以最大化EI，并成功隔离了由传感器损坏、动态场景和感知退化引起的故障。

Conclusion: 所提出的基于反事实推理的FDI框架能够有效地检测和隔离机器人感知系统中的故障，并且在主动FDI中通过最大化EI可以提高故障诊断的效率。

Abstract: Perception systems provide a rich understanding of the environment for
autonomous systems, shaping decisions in all downstream modules. Hence,
accurate detection and isolation of faults in perception systems is important.
Faults in perception systems pose particular challenges: faults are often tied
to the perceptual context of the environment, and errors in their multi-stage
pipelines can propagate across modules. To address this, we adopt a
counterfactual reasoning approach to propose a framework for fault detection
and isolation (FDI) in perception systems. As opposed to relying on physical
redundancy (i.e., having extra sensors), our approach utilizes analytical
redundancy with counterfactual reasoning to construct perception reliability
tests as causal outcomes influenced by system states and fault scenarios.
Counterfactual reasoning generates reliability test results under hypothesized
faults to update the belief over fault hypotheses. We derive both passive and
active FDI methods. While the passive FDI can be achieved by belief updates,
the active FDI approach is defined as a causal bandit problem, where we utilize
Monte Carlo Tree Search (MCTS) with upper confidence bound (UCB) to find
control inputs that maximize a detection and isolation metric, designated as
Effective Information (EI). The mentioned metric quantifies the informativeness
of control inputs for FDI. We demonstrate the approach in a robot exploration
scenario, where a space robot performing vision-based navigation actively
adjusts its attitude to increase EI and correctly isolate faults caused by
sensor damage, dynamic scenes, and perceptual degradation.

</details>


### [526] [Robotic Skill Diversification via Active Mutation of Reward Functions in Reinforcement Learning During a Liquid Pouring Task](https://arxiv.org/abs/2509.18463)
*Jannick van Buuren,Roberto Giglio,Loris Roveda,Luka Peternel*

Main category: cs.RO

TL;DR: 通过对奖励函数施加高斯噪声来突变权重，以在机器人操作任务中产生多样化的技能。我们使用液体倾倒用例进行了检查，并发现由此产生的策略展示了从执行预期的倾倒任务到清洁容器边缘、混合液体和浇水等新颖技能的广泛行为。


<details>
  <summary>Details</summary>
Motivation: 本研究的动机在于探索如何通过对强化学习中的奖励函数进行刻意突变，从而在机器人操作任务中产生多样化的技能变体。

Method: 本研究的重点是开发一个新颖的奖励函数突变框架，该框架通过对奖励函数中不同项的权重应用高斯噪声来实现。我们受到人类运动控制中成本效益权衡模型的启发，并设计了一个包含准确性、时间和精力这几个关键项的奖励函数。该研究在 NVIDIA Isaac Sim 创建的模拟环境中进行，该环境包含一个弗兰卡·艾米卡熊猫机械臂，它手持一个需要将液体倒入容器的玻璃杯。所使用的强化学习算法基于近端策略优化（PPO）。

Result: 所产生的策略展示了广泛的行为，包括执行预期倾倒任务的变体，以及可用于意外任务的新颖技能，例如容器边缘清洁、液体混合和浇水。

Conclusion: 这项工作为机器人系统执行特定任务的多样化学习提供了有前景的方向，并有可能为未来的任务衍生出有意义的技能。

Abstract: This paper explores how deliberate mutations of reward function in
reinforcement learning can produce diversified skill variations in robotic
manipulation tasks, examined with a liquid pouring use case. To this end, we
developed a new reward function mutation framework that is based on applying
Gaussian noise to the weights of the different terms in the reward function.
Inspired by the cost-benefit tradeoff model from human motor control, we
designed the reward function with the following key terms: accuracy, time, and
effort. The study was performed in a simulation environment created in NVIDIA
Isaac Sim, and the setup included Franka Emika Panda robotic arm holding a
glass with a liquid that needed to be poured into a container. The
reinforcement learning algorithm was based on Proximal Policy Optimization. We
systematically explored how different configurations of mutated weights in the
rewards function would affect the learned policy. The resulting policies
exhibit a wide range of behaviours: from variations in execution of the
originally intended pouring task to novel skills useful for unexpected tasks,
such as container rim cleaning, liquid mixing, and watering. This approach
offers promising directions for robotic systems to perform diversified learning
of specific tasks, while also potentially deriving meaningful skills for future
tasks.

</details>


### [527] [RL-augmented Adaptive Model Predictive Control for Bipedal Locomotion over Challenging Terrain](https://arxiv.org/abs/2509.18466)
*Junnosuke Kamohara,Feiyang Wu,Chinmayee Wamorkar,Seth Hutchinson,Ye Zhao*

Main category: cs.RO

TL;DR: 结合MPC和RL的强化学习增强MPC框架，用于实现人形双足机器人在崎岖湿滑地形上的鲁棒行走。


<details>
  <summary>Details</summary>
Motivation: 传统MPC在崎岖湿滑地形上应用受限，RL缺乏约束满足保证。现有MPC和RL的结合主要用于平坦地形或四足机器人。

Method: 提出一个RL增强的MPC框架，为单刚体动力学MPC的系统动力学、摆动腿控制器和步态频率三个关键组件进行参数化，以适应崎岖湿滑地形的双足行走。

Result: 通过在NVIDIA IsaacLab中对机器人进行模拟，包括楼梯、踏脚石和低摩擦表面等多种地形的测试，验证了该方法的有效性。

Conclusion: RL增强的MPC框架相比于基线MPC和RL，表现出更强的适应性和鲁棒性，能够实现更优的双足行走。

Abstract: Model predictive control (MPC) has demonstrated effectiveness for humanoid
bipedal locomotion; however, its applicability in challenging environments,
such as rough and slippery terrain, is limited by the difficulty of modeling
terrain interactions. In contrast, reinforcement learning (RL) has achieved
notable success in training robust locomotion policies over diverse terrain,
yet it lacks guarantees of constraint satisfaction and often requires
substantial reward shaping. Recent efforts in combining MPC and RL have shown
promise of taking the best of both worlds, but they are primarily restricted to
flat terrain or quadrupedal robots. In this work, we propose an RL-augmented
MPC framework tailored for bipedal locomotion over rough and slippery terrain.
Our method parametrizes three key components of
single-rigid-body-dynamics-based MPC: system dynamics, swing leg controller,
and gait frequency. We validate our approach through bipedal robot simulations
in NVIDIA IsaacLab across various terrains, including stairs, stepping stones,
and low-friction surfaces. Experimental results demonstrate that our
RL-augmented MPC framework produces significantly more adaptive and robust
behaviors compared to baseline MPC and RL.

</details>


### [528] [Spatial Envelope MPC: High Performance Driving without a Reference](https://arxiv.org/abs/2509.18506)
*Siyuan Yu,Congkai Shen,Yufei Xi,James Dallas,Michael Thompson,John Subosits,Hiroshi Yasuda,Tulga Ersal*

Main category: cs.RO

TL;DR: 提出了一种新颖的基于包络线的模型预测控制（MPC）框架，使自动驾驶汽车能够在没有预定义参考的情况下处理各种场景下的高性能驾驶。


<details>
  <summary>Details</summary>
Motivation: 在高性能自动驾驶中，车辆动态极限下的安全运行需要一个实时规划和控制框架，该框架能够在预定义参考轨迹最优或不可行时，考虑关键车辆动力学和环境约束。现有的框架主要是基于参考的，这限制了它们在此类情况下的性能。

Method: 本研究引入了一个计算高效的车辆动力学模型，并提出了一种连续可微的数学公式，用于精确捕捉整个可驾驶包络线。该模型和公式允许将动态可行性和安全约束直接集成到统一的规划和控制框架中，从而无需预定义参考。通过结合强化学习和优化技术来解决包络线规划问题（即最大化逼近安全可驾驶区域）。

Result: 通过仿真和真实世界实验验证了该框架，证明了其在赛车、紧急避撞和越野导航等多种任务中的高性能。

Conclusion: 所提出的框架具有高动态性能，并且能够在没有预定义参考的情况下处理广泛的自动驾驶场景。该框架的有效性通过仿真和真实世界实验得到证明，展示了其跨各种任务的可扩展性和广泛适用性。

Abstract: This paper presents a novel envelope based model predictive control (MPC)
framework designed to enable autonomous vehicles to handle high performance
driving across a wide range of scenarios without a predefined reference. In
high performance autonomous driving, safe operation at the vehicle's dynamic
limits requires a real time planning and control framework capable of
accounting for key vehicle dynamics and environmental constraints when
following a predefined reference trajectory is suboptimal or even infeasible.
State of the art planning and control frameworks, however, are predominantly
reference based, which limits their performance in such situations. To address
this gap, this work first introduces a computationally efficient vehicle
dynamics model tailored for optimization based control and a continuously
differentiable mathematical formulation that accurately captures the entire
drivable envelope. This novel model and formulation allow for the direct
integration of dynamic feasibility and safety constraints into a unified
planning and control framework, thereby removing the necessity for predefined
references. The challenge of envelope planning, which refers to maximally
approximating the safe drivable area, is tackled by combining reinforcement
learning with optimization techniques. The framework is validated through both
simulations and real world experiments, demonstrating its high performance
across a variety of tasks, including racing, emergency collision avoidance and
off road navigation. These results highlight the framework's scalability and
broad applicability across a diverse set of scenarios.

</details>


### [529] [LCMF: Lightweight Cross-Modality Mambaformer for Embodied Robotics VQA](https://arxiv.org/abs/2509.18576)
*Zeyi Kang,Liang He,Yanxin Zhang,Zuheng Ming,Kaixing Zhao*

Main category: cs.RO

TL;DR: 该研究提出了轻量级的LCMF级联注意力框架，通过多级跨模态参数共享机制和Mamba模块，有效融合异构模态数据，并在资源受限环境下提高了计算效率，在VQA和EQA任务中取得了优于现有基线的结果。


<details>
  <summary>Details</summary>
Motivation: 为了解决机器人感知、理解指令和决策时，异构数据融合困难以及资源受限环境下的计算效率问题，本研究提出了LCMF级联注意力框架。

Method: 本研究提出了一种轻量级的LCMF级联注意力框架，该框架将多级跨模态参数共享机制引入Mamba模块，并结合了交叉注意力和选择性参数共享状态空间模型（SSMs）的优点，实现了异构模态的高效融合和语义互补对齐。

Result: LCMF在VQA任务中的准确率为74.29%，优于现有的多模态基线。在EQA视频任务中，其表现与大型语言模型代理（LLM Agents）的分布集群相当。该框架的计算量（FLOPs）比可比基线平均值减少了4.35倍，参数量（图像-文本）为1.6651亿，（视频-文本）为2.19亿。

Conclusion: LCMF框架为资源受限场景下的人机交互（HRI）应用提供了一个高效的解决方案，它在具有强大跨模态决策泛化能力的同时，显著降低了计算复杂度和参数量。

Abstract: Multimodal semantic learning plays a critical role in embodied intelligence,
especially when robots perceive their surroundings, understand human
instructions, and make intelligent decisions. However, the field faces
technical challenges such as effective fusion of heterogeneous data and
computational efficiency in resource-constrained environments. To address these
challenges, this study proposes the lightweight LCMF cascaded attention
framework, introducing a multi-level cross-modal parameter sharing mechanism
into the Mamba module. By integrating the advantages of Cross-Attention and
Selective parameter-sharing State Space Models (SSMs), the framework achieves
efficient fusion of heterogeneous modalities and semantic complementary
alignment. Experimental results show that LCMF surpasses existing multimodal
baselines with an accuracy of 74.29% in VQA tasks and achieves competitive
mid-tier performance within the distribution cluster of Large Language Model
Agents (LLM Agents) in EQA video tasks. Its lightweight design achieves a
4.35-fold reduction in FLOPs relative to the average of comparable baselines
while using only 166.51M parameters (image-text) and 219M parameters
(video-text), providing an efficient solution for Human-Robot Interaction (HRI)
applications in resource-constrained scenarios with strong multimodal decision
generalization capabilities.

</details>


### [530] [VLN-Zero: Rapid Exploration and Cache-Enabled Neurosymbolic Vision-Language Planning for Zero-Shot Transfer in Robot Navigation](https://arxiv.org/abs/2509.18592)
*Neel P. Bhatt,Yunhao Yang,Rohan Siva,Pranay Samineni,Daniel Milan,Zhangyang Wang,Ufuk Topcu*

Main category: cs.RO

TL;DR: VLN-Zero是一个创新的视觉-语言导航框架，通过两阶段方法（探索和部署）实现了高效的零样本导航。它利用视觉-语言模型构建场景图，并结合神经符号规划器进行推理和执行，显著提高了在未知环境中的导航成功率和效率。


<details>
  <summary>Details</summary>
Motivation: 现有导航方法在探索或泛化能力方面存在不足，无法满足现实世界自主性的需求。

Method: VLN-Zero框架包含两个阶段：1. 探索阶段：利用结构化提示引导视觉-语言模型（VLM）进行信息性和多样性的轨迹搜索，生成场景图。2. 部署阶段：神经符号规划器基于场景图和环境观测生成执行计划，同时利用缓存加速执行过程。

Result: VLN-Zero的成功率是现有最先进零样本模型的两倍，并且优于大多数经过微调的模型。它能在更短的时间内到达目标地点，并且VLM调用次数平均减少了55%。

Conclusion: VLN-Zero通过结合快速探索、符号推理和缓存执行，克服了先前视觉-语言导航方法的计算效率低下和泛化能力差的问题，实现了在未知环境中鲁棒且可扩展的决策能力。

Abstract: Rapid adaptation in unseen environments is essential for scalable real-world
autonomy, yet existing approaches rely on exhaustive exploration or rigid
navigation policies that fail to generalize. We present VLN-Zero, a two-phase
vision-language navigation framework that leverages vision-language models to
efficiently construct symbolic scene graphs and enable zero-shot neurosymbolic
navigation. In the exploration phase, structured prompts guide VLM-based search
toward informative and diverse trajectories, yielding compact scene graph
representations. In the deployment phase, a neurosymbolic planner reasons over
the scene graph and environmental observations to generate executable plans,
while a cache-enabled execution module accelerates adaptation by reusing
previously computed task-location trajectories. By combining rapid exploration,
symbolic reasoning, and cache-enabled execution, the proposed framework
overcomes the computational inefficiency and poor generalization of prior
vision-language navigation methods, enabling robust and scalable
decision-making in unseen environments. VLN-Zero achieves 2x higher success
rate compared to state-of-the-art zero-shot models, outperforms most fine-tuned
baselines, and reaches goal locations in half the time with 55% fewer VLM calls
on average compared to state-of-the-art models across diverse environments.
Codebase, datasets, and videos for VLN-Zero are available at:
https://vln-zero.github.io/.

</details>


### [531] [Growing with Your Embodied Agent: A Human-in-the-Loop Lifelong Code Generation Framework for Long-Horizon Manipulation Skills](https://arxiv.org/abs/2509.18597)
*Yuan Meng,Zhenguo Sun,Max Fest,Xukun Li,Zhenshan Bing,Alois Knoll*

Main category: cs.RO

TL;DR: 使用包含外部记忆和检索增强生成（RAG）的可重用技能来改进基于LLM的机器人操作代码生成，解决了现有方法的局限性，如噪声、固定原语、有限上下文和长时任务处理能力不足。


<details>
  <summary>Details</summary>
Motivation: 现有基于LLM的代码生成方法在机器人操作领域存在噪声大、原语固定、上下文窗口有限以及难以处理长时任务的问题。此外，闭环反馈中的知识存储格式不当，限制了泛化能力并可能导致灾难性遗忘，因此需要学习可重用的技能。仅依赖LLM的方法在极长时任务中因其有限的推理能力而常常失败。

Method: 提出一个包含外部记忆和检索增强生成（RAG）的可重用技能框架，并辅以提示机制以实现动态重用。该框架通过人类在循环中进行纠正，并将这些纠正编码成可重用的技能。

Result: 在Ravens, Franka Kitchen和MetaWorld数据集以及真实世界环境中进行了实验，结果表明该框架的成功率为0.93，比基线方法高出27%；纠正轮次的效率提高了42%；能够成功解决如“建造房屋”这类需要超过20个原语规划的极长时任务。

Conclusion: 所提出的框架通过将纠正编码为可重用的技能，并结合外部记忆和RAG，能够有效地解决现有LLM代码生成方法的局限性，在机器人操作任务中取得了显著的性能提升，尤其是在处理复杂和长时任务方面。

Abstract: Large language models (LLMs)-based code generation for robotic manipulation
has recently shown promise by directly translating human instructions into
executable code, but existing methods remain noisy, constrained by fixed
primitives and limited context windows, and struggle with long-horizon tasks.
While closed-loop feedback has been explored, corrected knowledge is often
stored in improper formats, restricting generalization and causing catastrophic
forgetting, which highlights the need for learning reusable skills. Moreover,
approaches that rely solely on LLM guidance frequently fail in extremely
long-horizon scenarios due to LLMs' limited reasoning capability in the robotic
domain, where such issues are often straightforward for humans to identify. To
address these challenges, we propose a human-in-the-loop framework that encodes
corrections into reusable skills, supported by external memory and
Retrieval-Augmented Generation with a hint mechanism for dynamic reuse.
Experiments on Ravens, Franka Kitchen, and MetaWorld, as well as real-world
settings, show that our framework achieves a 0.93 success rate (up to 27%
higher than baselines) and a 42% efficiency improvement in correction rounds.
It can robustly solve extremely long-horizon tasks such as "build a house",
which requires planning over 20 primitives.

</details>


### [532] [End-to-End Crop Row Navigation via LiDAR-Based Deep Reinforcement Learning](https://arxiv.org/abs/2509.18608)
*Ana Luiza Mineiro,Francisco Affonso,Marcelo Becker*

Main category: cs.RO

TL;DR: 提出了一种基于深度强化学习的端到端导航系统，用于解决在遮挡密集、GNSS信号不可靠的农业环境中的导航问题。


<details>
  <summary>Details</summary>
Motivation: 现有农业环境导航方法在GNSS不可靠、行间杂乱、光照变化等因素下存在挑战。

Method: 提出了一种基于体素下采样策略的深度强化学习方法，该方法将3D LiDAR原始数据直接映射到控制指令，输入的LiDAR数据尺寸减少了95.83%，无需标签数据集或手动设计的控制接口，即可在模拟环境中进行训练。

Result: 在模拟环境中，该方法在笔直行走的种植园中实现了100%的成功率，在不同弯曲度（不同正弦频率和幅度）的行中表现出逐步下降的性能。

Conclusion: 该方法通过在模拟环境中训练的端到端学习导航系统，能够有效地处理农业环境中的导航挑战，但性能会随着行弯曲度的增加而下降。

Abstract: Reliable navigation in under-canopy agricultural environments remains a
challenge due to GNSS unreliability, cluttered rows, and variable lighting. To
address these limitations, we present an end-to-end learning-based navigation
system that maps raw 3D LiDAR data directly to control commands using a deep
reinforcement learning policy trained entirely in simulation. Our method
includes a voxel-based downsampling strategy that reduces LiDAR input size by
95.83%, enabling efficient policy learning without relying on labeled datasets
or manually designed control interfaces. The policy was validated in
simulation, achieving a 100% success rate in straight-row plantations and
showing a gradual decline in performance as row curvature increased, tested
across varying sinusoidal frequencies and amplitudes.

</details>


### [533] [PIE: Perception and Interaction Enhanced End-to-End Motion Planning for Autonomous Driving](https://arxiv.org/abs/2509.18609)
*Chengran Yuan,Zijian Lu,Zhanqi Zhang,Yimin Zhao,Zefan Huang,Shuo Sun,Jiawei Sun,Jiahui Li,Christina Dao Wen Lee,Dongen Li,Marcelo H. Ang Jr*

Main category: cs.RO

TL;DR: PIE是一个创新的端到端运动规划框架，通过融合高级感知、推理和意图建模，有效解决了自动驾驶中的场景理解和预测难题，并在NAVSIM基准测试中取得了领先的性能。


<details>
  <summary>Details</summary>
Motivation: 尽管端到端运动规划很有前景，但场景理解和有效的决策制定预测仍然是其大规模部署的重大障碍。

Method: PIE框架集成了双向Mamba融合（处理多模态融合中的数据压缩损失）和一种新颖的增强推理解码器（集成Mamba和Mixture-of-Experts，用于场景兼容的锚点选择和自适应轨迹推理）。此外，它还采用动作-运动交互模块来利用周围代理的状态预测来优化自身规划。

Result: PIE在NAVSIM基准测试中，未使用任何集成或数据增强技术，取得了88.9的PDM分数和85.6的EPDM分数，超越了现有最先进的方法。

Conclusion: 全面的定量和定性分析表明，PIE能够可靠地生成可行且高质量的自我轨迹。

Abstract: End-to-end motion planning is promising for simplifying complex autonomous
driving pipelines. However, challenges such as scene understanding and
effective prediction for decision-making continue to present substantial
obstacles to its large-scale deployment. In this paper, we present PIE, a
pioneering framework that integrates advanced perception, reasoning, and
intention modeling to dynamically capture interactions between the ego vehicle
and surrounding agents. It incorporates a bidirectional Mamba fusion that
addresses data compression losses in multimodal fusion of camera and LiDAR
inputs, alongside a novel reasoning-enhanced decoder integrating Mamba and
Mixture-of-Experts to facilitate scene-compliant anchor selection and optimize
adaptive trajectory inference. PIE adopts an action-motion interaction module
to effectively utilize state predictions of surrounding agents to refine ego
planning. The proposed framework is thoroughly validated on the NAVSIM
benchmark. PIE, without using any ensemble and data augmentation techniques,
achieves an 88.9 PDM score and 85.6 EPDM score, surpassing the performance of
prior state-of-the-art methods. Comprehensive quantitative and qualitative
analyses demonstrate that PIE is capable of reliably generating feasible and
high-quality ego trajectories.

</details>


### [534] [SINGER: An Onboard Generalist Vision-Language Navigation Policy for Drones](https://arxiv.org/abs/2509.18610)
*Maximilian Adang,JunEn Low,Ola Shorinwa,Mac Schwager*

Main category: cs.RO

TL;DR: SINGER是一个语言引导的自主无人机导航系统，利用模拟器、专家演示和轻量级策略，在真实世界中实现了零样本模拟到真实世界的迁移，并在到达率、视野保持和碰撞减少方面优于现有基线。


<details>
  <summary>Details</summary>
Motivation: 现有的大型视觉-语言模型在机器人操作方面取得了成功，但在开放词汇的自主无人机导航方面仍面临挑战，原因是缺乏大规模演示、实时控制需求以及对外部姿态估计模块的依赖。本项目旨在解决这些问题。

Method: SINGER系统包含三个核心组件：（1）一个利用高斯泼溅技术生成逼真且嵌入语言的飞行模拟数据，以最小化模拟到真实的差距；（2）一个受RRT启发的、用于生成无碰撞导航演示的多轨迹生成专家；（3）一个轻量级的端到端视觉运动策略，用于实时闭环控制。

Result: 通过大量的硬件飞行实验，SINGER在零样本模拟到真实世界的迁移方面表现出色，能够成功导航到未曾见过的环境和语言指定的目标。与基线方法相比，SINGER的到达率提高了23.33%，视野保持率提高了16.67%，碰撞次数减少了10%。

Conclusion: SINGER通过结合模拟器、专家演示和轻量级策略，成功实现了语言引导的自主无人机导航，并在真实世界的飞行实验中证明了其优越性，解决了开放词汇无人机导航的挑战。

Abstract: Large vision-language models have driven remarkable progress in
open-vocabulary robot policies, e.g., generalist robot manipulation policies,
that enable robots to complete complex tasks specified in natural language.
Despite these successes, open-vocabulary autonomous drone navigation remains an
unsolved challenge due to the scarcity of large-scale demonstrations, real-time
control demands of drones for stabilization, and lack of reliable external pose
estimation modules. In this work, we present SINGER for language-guided
autonomous drone navigation in the open world using only onboard sensing and
compute. To train robust, open-vocabulary navigation policies, SINGER leverages
three central components: (i) a photorealistic language-embedded flight
simulator with minimal sim-to-real gap using Gaussian Splatting for efficient
data generation, (ii) an RRT-inspired multi-trajectory generation expert for
collision-free navigation demonstrations, and these are used to train (iii) a
lightweight end-to-end visuomotor policy for real-time closed-loop control.
Through extensive hardware flight experiments, we demonstrate superior
zero-shot sim-to-real transfer of our policy to unseen environments and unseen
language-conditioned goal objects. When trained on ~700k-1M observation action
pairs of language conditioned visuomotor data and deployed on hardware, SINGER
outperforms a velocity-controlled semantic guidance baseline by reaching the
query 23.33% more on average, and maintains the query in the field of view
16.67% more on average, with 10% fewer collisions.

</details>


### [535] [The Case for Negative Data: From Crash Reports to Counterfactuals for Reasonable Driving](https://arxiv.org/abs/2509.18626)
*Jay Patrikar,Apoorva Sharma,Sushant Veer,Boyi Li,Sebastian Scherer,Marco Pavone*

Main category: cs.RO

TL;DR: 在自动驾驶系统中，通过将事故报告转化为以自我为中心的语言，并统一日志和事故场景到场景-动作表示，以支持基于检索的决策，从而提高安全性。


<details>
  <summary>Details</summary>
Motivation: 现有自动驾驶系统主要在无事故数据上训练，缺乏在安全-性能边界附近的指导。而真实的事故报告包含了关键的对比证据，但其非结构化、第三人称的叙述方式难以直接利用。

Method: 将事故报告进行规范化，转化为以自我为中心的语言，并将日志和事故报告统一为场景-动作表示。在决策时，通过检索相关先例来仲裁建议的操作，并引入代理反事实扩展来提出可能的替代方案，检索并推理不同结果，最终做出决策。

Result: 在nuScenes基准测试中，先例检索显著提高了模型校准度，将上下文首选操作的召回率从24%提高到53%。反事实变体在保持这些提升的同时，还能优化风险边缘的决策。

Conclusion: 所提出的方法通过利用事故报告的先例检索和反事实推理，能够有效地提高自动驾驶系统的安全性和决策能力。

Abstract: Learning-based autonomous driving systems are trained mostly on incident-free
data, offering little guidance near safety-performance boundaries. Real crash
reports contain precisely the contrastive evidence needed, but they are hard to
use: narratives are unstructured, third-person, and poorly grounded to sensor
views. We address these challenges by normalizing crash narratives to
ego-centric language and converting both logs and crashes into a unified
scene-action representation suitable for retrieval. At decision time, our
system adjudicates proposed actions by retrieving relevant precedents from this
unified index; an agentic counterfactual extension proposes plausible
alternatives, retrieves for each, and reasons across outcomes before deciding.
On a nuScenes benchmark, precedent retrieval substantially improves
calibration, with recall on contextually preferred actions rising from 24% to
53%. The counterfactual variant preserves these gains while sharpening
decisions near risk.

</details>


### [536] [Distributionally Robust Safe Motion Planning with Contextual Information](https://arxiv.org/abs/2509.18666)
*Kaizer Rahaman,Simran Kumari,Ashish R. Hota*

Main category: cs.RO

TL;DR: 提出一种结合上下文信息的分布鲁棒碰撞避免方法，通过在RKHS中嵌入条件轨迹分布，定义歧义集，并将其纳入运动规划。


<details>
  <summary>Details</summary>
Motivation: 为了在避免碰撞的同时考虑环境的动态不确定性，并提高避碰的成功率。

Method: 通过条件核均值嵌入算子在RKHS中嵌入条件轨迹分布，定义包含经验估计值一定距离内的分布的歧义集，并将其形式化为分布鲁棒碰撞避免约束，纳入以递推预测为基础的运动规划。

Result: 相比于未考虑上下文信息和/或分布鲁棒性的方法，该方法在具有挑战性的场景中更成功地避免了碰撞。

Conclusion: 所提出的分布鲁棒方法，通过整合上下文信息和分布鲁棒性，能够更有效地进行碰撞避免。

Abstract: We present a distributionally robust approach for collision avoidance by
incorporating contextual information. Specifically, we embed the conditional
distribution of future trajectory of the obstacle conditioned on the motion of
the ego agent in a reproducing kernel Hilbert space (RKHS) via the conditional
kernel mean embedding operator. Then, we define an ambiguity set containing all
distributions whose embedding in the RKHS is within a certain distance from the
empirical estimate of conditional mean embedding learnt from past data.
Consequently, a distributionally robust collision avoidance constraint is
formulated, and included in the receding horizon based motion planning
formulation of the ego agent. Simulation results show that the proposed
approach is more successful in avoiding collision compared to approaches that
do not include contextual information and/or distributional robustness in their
formulation in several challenging scenarios.

</details>


### [537] [Generalizable Domain Adaptation for Sim-and-Real Policy Co-Training](https://arxiv.org/abs/2509.18631)
*Shuo Cheng,Liqian Ma,Zhenyang Chen,Ajay Mandlekar,Caelan Garrett,Danfei Xu*

Main category: cs.RO

TL;DR: 使用统一的sim-and-real协同训练框架，结合最优传输（OT）损失，利用模拟数据和少量真实世界演示来学习可泛化的机器人操作策略，实现了高达30%的真实世界成功率提升，并能泛化到仅在模拟中 seen 的场景。


<details>
  <summary>Details</summary>
Motivation: 真实世界演示数据获取成本高，而模拟数据虽然可扩展但存在域间差异，阻碍了策略的迁移。本研究旨在提出一种能够主要利用模拟数据并仅需少量真实世界演示的泛化操作策略学习框架。

Method: 提出一个统一的sim-and-real协同训练框架，通过学习领域不变、任务相关的特征空间来弥合模拟与真实世界的差距。关键在于通过最优传输（OT）损失来对齐跨领域的观测和动作的联合分布，并扩展到非均衡OT以处理模拟数据丰富而真实数据有限的问题。

Result: 在具有挑战性的机器人操作任务中验证了该方法，相比仅使用模拟数据或真实数据的方法，能够利用丰富的模拟数据，在真实世界成功率方面提高了30%，并且能够泛化到仅在模拟环境中 seen 的场景。

Conclusion: 本研究提出的统一sim-and-real协同训练框架，结合了OT损失，能够有效地利用模拟数据和少量真实世界演示来学习可泛化的机器人操作策略，显著提高了在真实世界中的性能和泛化能力。

Abstract: Behavior cloning has shown promise for robot manipulation, but real-world
demonstrations are costly to acquire at scale. While simulated data offers a
scalable alternative, particularly with advances in automated demonstration
generation, transferring policies to the real world is hampered by various
simulation and real domain gaps. In this work, we propose a unified
sim-and-real co-training framework for learning generalizable manipulation
policies that primarily leverages simulation and only requires a few real-world
demonstrations. Central to our approach is learning a domain-invariant,
task-relevant feature space. Our key insight is that aligning the joint
distributions of observations and their corresponding actions across domains
provides a richer signal than aligning observations (marginals) alone. We
achieve this by embedding an Optimal Transport (OT)-inspired loss within the
co-training framework, and extend this to an Unbalanced OT framework to handle
the imbalance between abundant simulation data and limited real-world examples.
We validate our method on challenging manipulation tasks, showing it can
leverage abundant simulation data to achieve up to a 30% improvement in the
real-world success rate and even generalize to scenarios seen only in
simulation.

</details>


### [538] [3D Flow Diffusion Policy: Visuomotor Policy Learning via Generating Flow in 3D Space](https://arxiv.org/abs/2509.18676)
*Sangjun Noh,Dongwoo Nam,Kangmin Kim,Geonhyup Lee,Yeonguk Yu,Raeyoung Kang,Kyoobin Lee*

Main category: cs.RO

TL;DR: 3D FDP 使用 3D 流作为中间表示来学习机器人操作策略，在模拟和真实机器人上均取得最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 在机器人操作中学习能够跨不同物体和交互动力学泛化的鲁棒性视觉运动策略仍然是一个挑战，因为现有方法常常忽略精细的局部运动线索。

Method: 提出 3D 流扩散策略 (3D FDP) 框架，该框架利用场景级 3D 流作为结构化中间表示来捕捉精细的局部运动线索。该方法预测采样查询点的时域轨迹，并将动作生成与这些交互感知流进行条件化，这些流在统一的扩散架构中联合实现。

Result: 在 MetaWorld 基准的 50 个任务上实现了最先进的性能，特别是在中等和困难设置下表现出色。在真实机器人上的八个任务中，始终优于先前的方法，尤其是在接触丰富和非抓取场景中。

Conclusion: 3D 流是一种强大的结构化先验，可用于学习可泛化的视觉运动策略，从而促进更鲁棒、更多功能的机器人操作发展。

Abstract: Learning robust visuomotor policies that generalize across diverse objects
and interaction dynamics remains a central challenge in robotic manipulation.
Most existing approaches rely on direct observation-to-action mappings or
compress perceptual inputs into global or object-centric features, which often
overlook localized motion cues critical for precise and contact-rich
manipulation. We present 3D Flow Diffusion Policy (3D FDP), a novel framework
that leverages scene-level 3D flow as a structured intermediate representation
to capture fine-grained local motion cues. Our approach predicts the temporal
trajectories of sampled query points and conditions action generation on these
interaction-aware flows, implemented jointly within a unified diffusion
architecture. This design grounds manipulation in localized dynamics while
enabling the policy to reason about broader scene-level consequences of
actions. Extensive experiments on the MetaWorld benchmark show that 3D FDP
achieves state-of-the-art performance across 50 tasks, particularly excelling
on medium and hard settings. Beyond simulation, we validate our method on eight
real-robot tasks, where it consistently outperforms prior baselines in
contact-rich and non-prehensile scenarios. These results highlight 3D flow as a
powerful structural prior for learning generalizable visuomotor policies,
supporting the development of more robust and versatile robotic manipulation.
Robot demonstrations, additional results, and code can be found at
https://sites.google.com/view/3dfdp/home.

</details>


### [539] [Number Adaptive Formation Flight Planning via Affine Deformable Guidance in Narrow Environments](https://arxiv.org/abs/2509.18636)
*Yuan Zhou,Jialiang Hou,Guangtong Xu,Fei Gao*

Main category: cs.RO

TL;DR: 该论文提出了一种基于可变形虚拟结构（DVS）并结合连续时空变换的编队规划方法，以解决在狭窄环境中无人机数量变化时编队维持和规划收敛性问题。


<details>
  <summary>Details</summary>
Motivation: 在狭窄环境中，无人机数量的变化会阻碍规划收敛到期望的配置，需要一种能够适应这种变化的编队规划方法。

Method: 首先，利用 Lloyd 算法进行均匀划分（Partitioning）和 Hungarian 算法进行分配（Assignment），即 PAAS，来满足无人机间的安全距离和保持编队形状的完整性，特别适用于不规则编队几何。然后，使用基于原语的路径搜索和非线性轨迹优化来规划包含 DVS 的时空轨迹。该 DVS 轨迹能够自适应地处理无人机数量的变化，并通过仿射变换适应狭窄环境。最后，每个无人机在 DVS 提供的期望时空位置的指导下，进行分布式轨迹规划，同时考虑碰撞避免和动态可行性要求。

Result: 所提出的方法能够在模拟中实现高达 15% 的无人机数量加入或离开，并在混乱的环境中快速恢复期望的编队形状。与当前最先进的编队规划方法相比，该方法展现了更快的编队恢复能力和环境适应性。实际实验验证了该方法的有效性和鲁棒性。

Conclusion: 所提出的基于 DVS 的编队规划方法能够有效地处理无人机数量变化和狭窄环境的挑战，实现快速的编队恢复和良好的环境适应性。

Abstract: Formation maintenance with varying number of drones in narrow environments
hinders the convergence of planning to the desired configurations. To address
this challenge, this paper proposes a formation planning method guided by
Deformable Virtual Structures (DVS) with continuous spatiotemporal
transformation. Firstly, to satisfy swarm safety distance and preserve
formation shape filling integrity for irregular formation geometries, we employ
Lloyd algorithm for uniform $\underline{PA}$rtitioning and Hungarian algorithm
for $\underline{AS}$signment (PAAS) in DVS. Subsequently, a spatiotemporal
trajectory involving DVS is planned using primitive-based path search and
nonlinear trajectory optimization. The DVS trajectory achieves adaptive
transitions with respect to a varying number of drones while ensuring
adaptability to narrow environments through affine transformation. Finally,
each agent conducts distributed trajectory planning guided by desired
spatiotemporal positions within the DVS, while incorporating collision
avoidance and dynamic feasibility requirements. Our method enables up to 15\%
of swarm numbers to join or leave in cluttered environments while rapidly
restoring the desired formation shape in simulation. Compared to cutting-edge
formation planning method, we demonstrate rapid formation recovery capacity and
environmental adaptability. Real-world experiments validate the effectiveness
and resilience of our formation planning method.

</details>


### [540] [Do You Need Proprioceptive States in Visuomotor Policies?](https://arxiv.org/abs/2509.18644)
*Juntu Zhao,Wenbo Lu,Di Zhang,Yufeng Liu,Yushen Liang,Tianluo Zhang,Yifeng Cao,Junyuan Xie,Yingdong Hu,Shengjie Wang,Junliang Guo,Dequan Wang,Yang Gao*

Main category: cs.RO

TL;DR: 该研究提出了一种名为“无状态策略”的方法，仅通过视觉输入来训练机器人操作策略，摒弃了传统的本体感觉状态输入，从而提高了空间泛化能力。


<details>
  <summary>Details</summary>
Motivation: 在机器人操作任务中，结合视觉和本体感觉状态的模仿学习策略容易过度依赖本体感觉输入，导致对训练轨迹的过拟合和较差的空间泛化能力。

Method: 提出“无状态策略”，仅使用视觉观测作为输入来预测动作，摒弃了本体感觉状态。该策略在相对末端执行器动作空间中构建，并利用双腕广角摄像头提供的视觉信息。

Result: “无状态策略”在空间泛化能力上显著优于基于状态的策略。在实际的抓取、折叠衬衫和全身操作等任务中，高度泛化成功率从0%提高到85%，水平泛化成功率从6%提高到64%。此外，该策略在数据效率和跨机器人适应性方面也表现出优势。

Conclusion: “无状态策略”通过仅依赖视觉输入，克服了传统方法的局限性，显著提高了机器人在各种操作任务中的空间泛化能力、数据效率和适应性，使其在实际应用中更具实用性。

Abstract: Imitation-learning-based visuomotor policies have been widely used in robot
manipulation, where both visual observations and proprioceptive states are
typically adopted together for precise control. However, in this study, we find
that this common practice makes the policy overly reliant on the proprioceptive
state input, which causes overfitting to the training trajectories and results
in poor spatial generalization. On the contrary, we propose the State-free
Policy, removing the proprioceptive state input and predicting actions only
conditioned on visual observations. The State-free Policy is built in the
relative end-effector action space, and should ensure the full task-relevant
visual observations, here provided by dual wide-angle wrist cameras. Empirical
results demonstrate that the State-free policy achieves significantly stronger
spatial generalization than the state-based policy: in real-world tasks such as
pick-and-place, challenging shirt-folding, and complex whole-body manipulation,
spanning multiple robot embodiments, the average success rate improves from 0\%
to 85\% in height generalization and from 6\% to 64\% in horizontal
generalization. Furthermore, they also show advantages in data efficiency and
cross-embodiment adaptation, enhancing their practicality for real-world
deployment.

</details>


### [541] [SPiDR: A Simple Approach for Zero-Shot Safety in Sim-to-Real Transfer](https://arxiv.org/abs/2509.18648)
*Yarden As,Chengrui Qu,Benjamin Unger,Dongho Kang,Max van der Hart,Laixi Shi,Stelian Coros,Adam Wierman,Andreas Krause*

Main category: cs.RO

TL;DR: SPiDR是一种通过悲观域随机化进行模拟到现实的强化学习算法，该算法具有可证明的安全保证，能够有效弥合模拟到现实的差距，同时保持良好的性能。


<details>
  <summary>Details</summary>
Motivation: 在真实世界应用中部署强化学习（RL）时，安全性仍然是一个主要问题。虽然模拟器提供了安全的训练环境，但不可避免的模拟到现实的差距会带来额外的安全问题。为了解决这个挑战，需要一种既能保证安全又能与可扩展训练流水线兼容的方法。

Method: SPiDR算法通过域随机化将模拟到现实的差距的不确定性纳入安全约束，使其具有通用性并与现有训练流水线高度兼容。

Result: 通过在模拟到模拟基准测试和两个不同的真实世界机器人平台上进行的大量实验，SPiDR被证明能够有效确保安全，同时保持良好的性能。

Conclusion: SPiDR是一种可扩展的算法，具有可证明的安全保证，用于安全的模拟到现实转移。它通过域随机化将模拟到现实的差距的不确定性纳入安全约束，从而解决了安全强化学习中的一个关键挑战。

Abstract: Safety remains a major concern for deploying reinforcement learning (RL) in
real-world applications. Simulators provide safe, scalable training
environments, but the inevitable sim-to-real gap introduces additional safety
concerns, as policies must satisfy constraints in real-world conditions that
differ from simulation. To address this challenge, robust safe RL techniques
offer principled methods, but are often incompatible with standard scalable
training pipelines. In contrast, domain randomization, a simple and popular
sim-to-real technique, stands out as a promising alternative, although it often
results in unsafe behaviors in practice. We present SPiDR, short for
Sim-to-real via Pessimistic Domain Randomization -- a scalable algorithm with
provable guarantees for safe sim-to-real transfer. SPiDR uses domain
randomization to incorporate the uncertainty about the sim-to-real gap into the
safety constraints, making it versatile and highly compatible with existing
training pipelines. Through extensive experiments on sim-to-sim benchmarks and
two distinct real-world robotic platforms, we demonstrate that SPiDR
effectively ensures safety despite the sim-to-real gap while maintaining strong
performance.

</details>


### [542] [N2M: Bridging Navigation and Manipulation by Learning Pose Preference from Rollout](https://arxiv.org/abs/2509.18671)
*Kaixin Chai,Hyunjun Lee,Joseph J. Lim*

Main category: cs.RO

TL;DR: N2M是一个过渡模块，通过将机器人引导至任务区域内更优的初始姿态，显著提高了移动操作任务的成功率，仅依赖于以自我为中心的观察，并且具有出色的数据效率和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 移动操作中的抓取策略通常对初始姿态有特定偏好，但导航模块只关注到达任务区域，忽略了初始姿态对下游操作的影响，导致任务成功率不高。

Method: 提出了一种名为N2M的过渡模块，该模块在机器人到达任务区域后，能够引导其调整到一个更适合下游抓取操作的初始姿态。N2M模块的特点包括：仅依赖于以自我为中心的观察、实时适应环境变化、高视点鲁棒性、跨任务/策略/硬件的广泛适用性、以及出色的数据效率和泛化能力。

Result: 在PnPCounterToCab任务中，N2M将平均成功率从仅有3%的基线提高到54%。在Toybox Handover任务中，N2M即使在仅有15个数据样本的未知环境中也能提供可靠的预测，展示了其高效的数据利用率和泛化能力。

Conclusion: N2M通过解决导航和操作之间初始姿态的错配问题，显著提高了移动操作任务的成功率，并且在数据效率和泛化能力方面表现出色。

Abstract: In mobile manipulation, the manipulation policy has strong preferences for
initial poses where it is executed. However, the navigation module focuses
solely on reaching the task area, without considering which initial pose is
preferable for downstream manipulation. To address this misalignment, we
introduce N2M, a transition module that guides the robot to a preferable
initial pose after reaching the task area, thereby substantially improving task
success rates. N2M features five key advantages: (1) reliance solely on
ego-centric observation without requiring global or historical information; (2)
real-time adaptation to environmental changes; (3) reliable prediction with
high viewpoint robustness; (4) broad applicability across diverse tasks,
manipulation policies, and robot hardware; and (5) remarkable data efficiency
and generalizability. We demonstrate the effectiveness of N2M through extensive
simulation and real-world experiments. In the PnPCounterToCab task, N2M
improves the averaged success rate from 3% with the reachability-based baseline
to 54%. Furthermore, in the Toybox Handover task, N2M provides reliable
predictions even in unseen environments with only 15 data samples, showing
remarkable data efficiency and generalizability.

</details>


### [543] [Query-Centric Diffusion Policy for Generalizable Robotic Assembly](https://arxiv.org/abs/2509.18686)
*Ziyi Xu,Haohong Lin,Shiqi Liu,Ding Zhao*

Main category: cs.RO

TL;DR: QDP是一个新颖的机器人装配框架，通过查询机制连接高层规划和底层控制，提高了装配精度和成功率。


<details>
  <summary>Details</summary>
Motivation: 机器人装配任务因零件交互的复杂性和对噪声的敏感性而具有挑战性。现有的分层策略在技能查询和执行之间存在不匹配的问题。

Method: 提出了一种以查询为中心的扩散策略（QDP）框架，该框架利用包含对象、接触点和技能信息的查询来连接高层规划和底层控制，并利用点云观测来提高策略的鲁棒性。

Result: 在FurnitureBench的模拟和真实世界环境中进行了实验，QDP在技能精度和长时程成功率方面均有所提高，在插入和拧紧任务中的技能成功率比基线提高了50%以上。

Conclusion: QDP框架能够有效解决高层规划和底层控制之间的不匹配问题，提高机器人装配任务的性能。

Abstract: The robotic assembly task poses a key challenge in building generalist robots
due to the intrinsic complexity of part interactions and the sensitivity to
noise perturbations in contact-rich settings. The assembly agent is typically
designed in a hierarchical manner: high-level multi-part reasoning and
low-level precise control. However, implementing such a hierarchical policy is
challenging in practice due to the mismatch between high-level skill queries
and low-level execution. To address this, we propose the Query-centric
Diffusion Policy (QDP), a hierarchical framework that bridges high-level
planning and low-level control by utilizing queries comprising objects, contact
points, and skill information. QDP introduces a query-centric mechanism that
identifies task-relevant components and uses them to guide low-level policies,
leveraging point cloud observations to improve the policy's robustness. We
conduct comprehensive experiments on the FurnitureBench in both simulation and
real-world settings, demonstrating improved performance in skill precision and
long-horizon success rate. In the challenging insertion and screwing tasks, QDP
improves the skill-wise success rate by over 50% compared to baselines without
structured queries.

</details>


### [544] [Learning Obstacle Avoidance using Double DQN for Quadcopter Navigation](https://arxiv.org/abs/2509.18734)
*Nishant Doshi,Amey Sutvani,Sanket Gujar*

Main category: cs.RO

TL;DR: 自主飞行器在城市环境中通过深度相机进行导航的强化学习。


<details>
  <summary>Details</summary>
Motivation: 应对城市环境中自主飞行器导航面临的挑战，如GPS精度下降、狭窄空间和动态障碍物。

Method: 使用深度相机训练一个虚拟四旋翼机器人代理进行导航的强化学习。

Result: 成功在模拟城市环境中实现导航。

Conclusion: 强化学习可用于训练自主飞行器在复杂城市环境中进行导航。

Abstract: One of the challenges faced by Autonomous Aerial Vehicles is reliable
navigation through urban environments. Factors like reduction in precision of
Global Positioning System (GPS), narrow spaces and dynamically moving obstacles
make the path planning of an aerial robot a complicated task. One of the skills
required for the agent to effectively navigate through such an environment is
to develop an ability to avoid collisions using information from onboard depth
sensors. In this paper, we propose Reinforcement Learning of a virtual
quadcopter robot agent equipped with a Depth Camera to navigate through a
simulated urban environment.

</details>


### [545] [MV-UMI: A Scalable Multi-View Interface for Cross-Embodiment Learning](https://arxiv.org/abs/2509.18757)
*Omar Rayyan,John Abanes,Mahmoud Hafez,Anthony Tzes,Fares Abu-Dakka*

Main category: cs.RO

TL;DR: MV-UMI框架整合了第三人称视角和以自我为中心的摄像头，以克服手持抓取器在收集数据时仅依赖第一人称视角所带来的场景上下文信息不足的限制，从而提高了机器人操作策略的性能。


<details>
  <summary>Details</summary>
Motivation: 手持抓取器虽然易于扩展且成本较低，但仅依赖第一人称视角会限制其捕捉足够的场景上下文信息，从而影响机器人操作策略的鲁棒性。

Method: MV-UMI框架整合了第三人称视角和以自我为中心的摄像头，以克服手持抓取器在收集数据时仅依赖第一人称视角所带来的场景上下文信息不足的限制。

Result: MV-UMI框架在需要广泛场景理解的子任务中，性能平均提高了约47%，证明了该方法在扩展手持抓取器系统可学习的操作任务范围方面的有效性，并且没有牺牲其固有的跨设备兼容性。

Conclusion: MV-UMI框架通过整合多视角信息，有效解决了手持抓取器在数据收集中的局限性，提高了机器人操作策略的性能和泛化能力，扩大了可学习的操作任务范围。

Abstract: Recent advances in imitation learning have shown great promise for developing
robust robot manipulation policies from demonstrations. However, this promise
is contingent on the availability of diverse, high-quality datasets, which are
not only challenging and costly to collect but are often constrained to a
specific robot embodiment. Portable handheld grippers have recently emerged as
intuitive and scalable alternatives to traditional robotic teleoperation
methods for data collection. However, their reliance solely on first-person
view wrist-mounted cameras often creates limitations in capturing sufficient
scene contexts. In this paper, we present MV-UMI (Multi-View Universal
Manipulation Interface), a framework that integrates a third-person perspective
with the egocentric camera to overcome this limitation. This integration
mitigates domain shifts between human demonstration and robot deployment,
preserving the cross-embodiment advantages of handheld data-collection devices.
Our experimental results, including an ablation study, demonstrate that our
MV-UMI framework improves performance in sub-tasks requiring broad scene
understanding by approximately 47% across 3 tasks, confirming the effectiveness
of our approach in expanding the range of feasible manipulation tasks that can
be learned using handheld gripper systems, without compromising the
cross-embodiment advantages inherent to such systems.

</details>


### [546] [VGGT-DP: Generalizable Robot Control via Vision Foundation Models](https://arxiv.org/abs/2509.18778)
*Shijia Ge,Yinxin Zhang,Shuzhao Xie,Weixiang Zhang,Mingcai Zhou,Zhi Wang*

Main category: cs.RO

TL;DR: VGGT-DP框架整合了3D感知模型的几何先验和本体感受反馈，用于视觉模仿学习，提高了机器人操控技能的空间理解和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有视觉模仿学习框架主要关注策略设计，忽略了视觉编码器的结构和容量，限制了空间理解和泛化能力。VGGT-DP框架旨在解决此问题。

Method: VGGT-DP框架整合了视觉几何地面化Transformer（VGGT）作为视觉编码器，并引入了由本体感受引导的视觉学习策略，对感知进行校准，以提高空间定位和闭环控制。此外，框架还设计了帧间标记重用机制以降低推理延迟，并应用了随机标记裁剪来增强策略的鲁棒性并减少过拟合。

Result: 在MetaWorld的挑战性任务中，VGGT-DP显著优于DP和DP3等强基线模型，特别是在精度要求高和长时程的场景中表现更佳。

Conclusion: VGGT-DP通过整合几何先验和本体感受反馈，有效提升了视觉模仿学习的性能，尤其在复杂操控任务中展现出优越性。

Abstract: Visual imitation learning frameworks allow robots to learn manipulation
skills from expert demonstrations. While existing approaches mainly focus on
policy design, they often neglect the structure and capacity of visual
encoders, limiting spatial understanding and generalization. Inspired by
biological vision systems, which rely on both visual and proprioceptive cues
for robust control, we propose VGGT-DP, a visuomotor policy framework that
integrates geometric priors from a pretrained 3D perception model with
proprioceptive feedback. We adopt the Visual Geometry Grounded Transformer
(VGGT) as the visual encoder and introduce a proprioception-guided visual
learning strategy to align perception with internal robot states, improving
spatial grounding and closed-loop control. To reduce inference latency, we
design a frame-wise token reuse mechanism that compacts multi-view tokens into
an efficient spatial representation. We further apply random token pruning to
enhance policy robustness and reduce overfitting. Experiments on challenging
MetaWorld tasks show that VGGT-DP significantly outperforms strong baselines
such as DP and DP3, particularly in precision-critical and long-horizon
scenarios.

</details>


### [547] [Human-Interpretable Uncertainty Explanations for Point Cloud Registration](https://arxiv.org/abs/2509.18786)
*Johannes A. Gaus,Loris Schneider,Yitian Shi,Jongseok Lee,Rania Rayyes,Rudolph Triebel*

Main category: cs.RO

TL;DR: GP-CA 是一种新的点云配准方法，可以量化和解释配准不确定性，并在公开数据集和机器人实验中表现优于其他最先进的方法。


<details>
  <summary>Details</summary>
Motivation: 现有的点云配准方法（如 ICP）在传感器噪声、姿态估计误差和遮挡导致的部分重叠等不确定性情况下会失败。GP-CA 旨在解决这个问题。

Method: GP-CA 利用高斯过程概念归因（GP-CA）来量化和解释配准不确定性，并通过查询信息实例来发现新的不确定性来源。它还利用主动学习来提高样本效率。

Result: GP-CA 在三个公开数据集和机器人实验中得到了验证，其性能优于其他最先进的方法，在运行时、样本效率和准确性方面都有所提高。

Conclusion: GP-CA 是一种有效且鲁棒的点云配准方法，可量化和解释不确定性，并通过主动学习实现高样本效率。它在机器人感知中具有实际应用前景，可以实现有效的故障恢复行为。

Abstract: In this paper, we address the point cloud registration problem, where
well-known methods like ICP fail under uncertainty arising from sensor noise,
pose-estimation errors, and partial overlap due to occlusion. We develop a
novel approach, Gaussian Process Concept Attribution (GP-CA), which not only
quantifies registration uncertainty but also explains it by attributing
uncertainty to well-known sources of errors in registration problems. Our
approach leverages active learning to discover new uncertainty sources in the
wild by querying informative instances. We validate GP-CA on three publicly
available datasets and in our real-world robot experiment. Extensive ablations
substantiate our design choices. Our approach outperforms other
state-of-the-art methods in terms of runtime, high sample-efficiency with
active learning, and high accuracy. Our real-world experiment clearly
demonstrates its applicability. Our video also demonstrates that GP-CA enables
effective failure-recovery behaviors, yielding more robust robotic perception.

</details>


### [548] [DexSkin: High-Coverage Conformable Robotic Skin for Learning Contact-Rich Manipulation](https://arxiv.org/abs/2509.18830)
*Suzannah Wistreich,Baiyu Shi,Stephen Tian,Samuel Clarke,Michael Nath,Chengyi Xu,Zhenan Bao,Jiajun Wu*

Main category: cs.RO

TL;DR: DexSkin是一种柔软、可定制的电容式电子皮肤，可用于机器人的精细操作，实现高精度的触觉传感。


<details>
  <summary>Details</summary>
Motivation: 实现灵巧的机器人操作所需的触觉传感能力。

Method: 开发了一种名为DexSkin的柔软、可形变、电容式的电子皮肤，并将其应用于夹爪手指，实现了大面积、高精度的触觉感知，并验证了其在机器人操作学习中的有效性。

Result: DexSkin能够进行灵敏、可定位、可校准的触觉传感，并可适应不同几何形状。在夹爪手指上的实验表明，DexSkin能够支持机器人进行抓取、重定向物体和缠绕橡皮筋等具有挑战性的操作。此外，DexSkin可以校准以实现跨传感器实例的模型迁移，并适用于在线强化学习。

Conclusion: DexSkin在学习现实世界中接触密集型操作方面具有实用性和有效性。

Abstract: Human skin provides a rich tactile sensing stream, localizing intentional and
unintentional contact events over a large and contoured region. Replicating
these tactile sensing capabilities for dexterous robotic manipulation systems
remains a longstanding challenge. In this work, we take a step towards this
goal by introducing DexSkin. DexSkin is a soft, conformable capacitive
electronic skin that enables sensitive, localized, and calibratable tactile
sensing, and can be tailored to varying geometries. We demonstrate its efficacy
for learning downstream robotic manipulation by sensorizing a pair of parallel
jaw gripper fingers, providing tactile coverage across almost the entire finger
surfaces. We empirically evaluate DexSkin's capabilities in learning
challenging manipulation tasks that require sensing coverage across the entire
surface of the fingers, such as reorienting objects in hand and wrapping
elastic bands around boxes, in a learning-from-demonstration framework. We then
show that, critically for data-driven approaches, DexSkin can be calibrated to
enable model transfer across sensor instances, and demonstrate its
applicability to online reinforcement learning on real robots. Our results
highlight DexSkin's suitability and practicality for learning real-world,
contact-rich manipulation. Please see our project webpage for videos and
visualizations: https://dex-skin.github.io/.

</details>


### [549] [Bi-VLA: Bilateral Control-Based Imitation Learning via Vision-Language Fusion for Action Generation](https://arxiv.org/abs/2509.18865)
*Masato Kobayashi,Thanpimon Buamanee*

Main category: cs.RO

TL;DR: Bi-VLA是一个新框架，通过结合视觉和语言指令，解决了传统双边控制方法模型单一任务的局限性，提高了任务成功率和通用性。


<details>
  <summary>Details</summary>
Motivation: 传统双边控制方法需要针对特定任务设计模型，限制了其通用性。本研究旨在扩展双边控制方法，使其能够在一个模型中处理多个任务。

Method: Bi-VLA利用来自领导-跟随双边控制的机器人关节角度、速度和扭矩数据，结合SigLIP和FiLM进行视觉特征与自然语言指令的融合。

Result: 在两种任务类型（一种需要语言提示，另一种仅凭视觉区分）上的实验表明，Bi-VLA能够成功解释视觉-语言组合，并提高了任务成功率。

Conclusion: Bi-VLA克服了先前双边方法单一任务的限制，并通过实验证明视觉和语言的结合显著提高了模型的通用性。

Abstract: We propose Bilateral Control-Based Imitation Learning via Vision-Language
Fusion for Action Generation (Bi-VLA), a novel framework that extends bilateral
control-based imitation learning to handle more than one task within a single
model. Conventional bilateral control methods exploit joint angle, velocity,
torque, and vision for precise manipulation but require task-specific models,
limiting their generality. Bi-VLA overcomes this limitation by utilizing robot
joint angle, velocity, and torque data from leader-follower bilateral control
with visual features and natural language instructions through SigLIP and
FiLM-based fusion. We validated Bi-VLA on two task types: one requiring
supplementary language cues and another distinguishable solely by vision.
Real-robot experiments showed that Bi-VLA successfully interprets
vision-language combinations and improves task success rates compared to
conventional bilateral control-based imitation learning. Our Bi-VLA addresses
the single-task limitation of prior bilateral approaches and provides empirical
evidence that combining vision and language significantly enhances versatility.
Experimental results validate the effectiveness of Bi-VLA in real-world tasks.
For additional material, please visit the website:
https://mertcookimg.github.io/bi-vla/

</details>


### [550] [Lang2Morph: Language-Driven Morphological Design of Robotic Hands](https://arxiv.org/abs/2509.18937)
*Yanyuan Qiao,Kieran Gilday,Yutong Xie,Josie Hughes*

Main category: cs.RO

TL;DR: Lang2Morph是一个利用大型语言模型（LLMs）将自然语言任务描述转化为机器人手部几何结构和参数的流水线，实现了针对特定任务的3D打印手部设计。


<details>
  <summary>Details</summary>
Motivation: 当前机器人手部设计依赖专家经验和手动调整，自动化方法计算成本高且不适用于灵巧手设计。大型语言模型（LLMs）在理解人与物体交互和生成能力方面具有潜力，可以作为机器人手部设计的替代方案。

Method: Lang2Morph流水线包含两个主要部分：1. 形态设计：将任务转化为语义标签、语法结构和OPHand兼容参数。2. 选择与优化：根据语义匹配度和尺寸兼容性评估设计候选，并在需要时进行LLM引导的优化。

Result: Lang2Morph在多种任务上进行了评估，结果表明该方法能够生成多样化且与任务相关的机器人手部形态。

Conclusion: Lang2Morph是首个开发用于任务驱动机器人手部设计的基于LLM的框架，展示了其在生成任务相关手部形态方面的潜力。

Abstract: Designing robotic hand morphologies for diverse manipulation tasks requires
balancing dexterity, manufacturability, and task-specific functionality. While
open-source frameworks and parametric tools support reproducible design, they
still rely on expert heuristics and manual tuning. Automated methods using
optimization are often compute-intensive, simulation-dependent, and rarely
target dexterous hands. Large language models (LLMs), with their broad
knowledge of human-object interactions and strong generative capabilities,
offer a promising alternative for zero-shot design reasoning. In this paper, we
present Lang2Morph, a language-driven pipeline for robotic hand design. It uses
LLMs to translate natural-language task descriptions into symbolic structures
and OPH-compatible parameters, enabling 3D-printable task-specific
morphologies. The pipeline consists of: (i) Morphology Design, which maps tasks
into semantic tags, structural grammars, and OPH-compatible parameters; and
(ii) Selection and Refinement, which evaluates design candidates based on
semantic alignment and size compatibility, and optionally applies LLM-guided
refinement when needed. We evaluate Lang2Morph across varied tasks, and results
show that our approach can generate diverse, task-relevant morphologies. To our
knowledge, this is the first attempt to develop an LLM-based framework for
task-conditioned robotic hand design.

</details>


### [551] [Eva-VLA: Evaluating Vision-Language-Action Models' Robustness Under Real-World Physical Variations](https://arxiv.org/abs/2509.18953)
*Hanqing Liu,Jiahuan Long,Junqi Wu,Jiacheng Hou,Huili Tang,Tingsong Jiang,Weien Zhou,Wen Yao*

Main category: cs.RO

TL;DR: Eva-VLA是一个评估VLA模型鲁棒性的框架，发现现有模型在面对物理变化时存在严重漏洞。


<details>
  <summary>Details</summary>
Motivation: 评估和改进现有VLA模型在现实世界物理变化下的鲁棒性，解决VLA模型在实际应用中可能遇到的挑战。

Method: 将物理变化转化为连续优化问题，通过优化三个关键领域（物体3D变换、光照变化、对抗性补丁）的参数来探索最坏情况。

Result: 现有VLA模型在所有类型的变化下失败率均超过60%，其中物体变换在长序列任务中失败率高达97.8%。

Conclusion: Eva-VLA框架可以系统地评估VLA模型的鲁棒性，并为提高其在现实世界部署中的可靠性提供途径。Eva-VLA的实验结果揭示了当前VLA模型在面对真实世界复杂多变的环境时存在显著的脆弱性。

Abstract: Vision-Language-Action (VLA) models have emerged as promising solutions for
robotic manipulation, yet their robustness to real-world physical variations
remains critically underexplored. To bridge this gap, we propose Eva-VLA, the
first unified framework that systematically evaluates the robustness of VLA
models by transforming discrete physical variations into continuous
optimization problems. However, comprehensively assessing VLA robustness
presents two key challenges: (1) how to systematically characterize diverse
physical variations encountered in real-world deployments while maintaining
evaluation reproducibility, and (2) how to discover worst-case scenarios
without prohibitive real-world data collection costs efficiently. To address
the first challenge, we decompose real-world variations into three critical
domains: object 3D transformations that affect spatial reasoning, illumination
variations that challenge visual perception, and adversarial patches that
disrupt scene understanding. For the second challenge, we introduce a
continuous black-box optimization framework that transforms discrete physical
variations into parameter optimization, enabling systematic exploration of
worst-case scenarios. Extensive experiments on state-of-the-art OpenVLA models
across multiple benchmarks reveal alarming vulnerabilities: all variation types
trigger failure rates exceeding 60%, with object transformations causing up to
97.8% failure in long-horizon tasks. Our findings expose critical gaps between
controlled laboratory success and unpredictable deployment readiness, while the
Eva-VLA framework provides a practical pathway for hardening VLA-based robotic
manipulation models against real-world deployment challenges.

</details>


### [552] [Towards Robust LiDAR Localization: Deep Learning-based Uncertainty Estimation](https://arxiv.org/abs/2509.18954)
*Minoo Dolatabadi,Fardin Ayar,Ehsan Javanmardi,Manabu Tsukada,Mahdi Javanmardi*

Main category: cs.RO

TL;DR: 该研究提出了一种基于深度学习的框架，用于在ICP匹配前预测激光雷达扫描的注册误差协方差，即使在没有参考地图的情况下也能提高定位的准确性和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 传统的基于ICP的激光雷达定位和SLAM方法在特征稀疏或动态环境中容易出现姿态估计不准确的问题，并且准确预测ICP的误差协方差具有挑战性。现有的深度学习方法要么依赖预建地图，要么只提供二元分类，无法充分建模不确定性。

Method: 提出了一种数据驱动的深度学习框架，用于在ICP匹配之前估计ICP的注册误差协方差，即使在没有参考地图的情况下也能进行估计。

Result: 在KITTI数据集上的广泛实验证明了该方法的有效性，该方法能够准确预测协方差，并在使用预建地图进行定位或SLAM时，能显著降低定位误差并提高鲁棒性。

Conclusion: 所提出的框架通过提供可靠的6-DoF误差协方差估计，能够有效地将ICP集成到卡尔曼滤波中，从而提高激光雷达定位的准确性和鲁棒性。

Abstract: LiDAR-based localization and SLAM often rely on iterative matching
algorithms, particularly the Iterative Closest Point (ICP) algorithm, to align
sensor data with pre-existing maps or previous scans. However, ICP is prone to
errors in featureless environments and dynamic scenes, leading to inaccurate
pose estimation. Accurately predicting the uncertainty associated with ICP is
crucial for robust state estimation but remains challenging, as existing
approaches often rely on handcrafted models or simplified assumptions.
Moreover, a few deep learning-based methods for localizability estimation
either depend on a pre-built map, which may not always be available, or provide
a binary classification of localizable versus non-localizable, which fails to
properly model uncertainty. In this work, we propose a data-driven framework
that leverages deep learning to estimate the registration error covariance of
ICP before matching, even in the absence of a reference map. By associating
each LiDAR scan with a reliable 6-DoF error covariance estimate, our method
enables seamless integration of ICP within Kalman filtering, enhancing
localization accuracy and robustness. Extensive experiments on the KITTI
dataset demonstrate the effectiveness of our approach, showing that it
accurately predicts covariance and, when applied to localization using a
pre-built map or SLAM, reduces localization errors and improves robustness.

</details>


### [553] [Category-Level Object Shape and Pose Estimation in Less Than a Millisecond](https://arxiv.org/abs/2509.18979)
*Lorenzo Shaikewitz,Tim Nguyen,Luca Carlone*

Main category: cs.RO

TL;DR: 该论文提出了一种快速的、可获得全局最优性证书的物体三维形状和姿态估计方法，仅需类别级物体先验知识。


<details>
  <summary>Details</summary>
Motivation: 物体三维形状和姿态估计是机器人领域的基础问题，支撑着抓取、场景理解和导航等任务。

Method: 该方法利用学习到的前端检测稀疏的、类别级语义关键点，并使用线性活动形状模型表示物体形状。通过最大后验概率优化问题同时求解位置、方向和形状。该优化问题可以转化为特征值问题，并使用自洽场迭代（self-consistent field iteration）进行高效求解，每次迭代仅需计算一个4x4矩阵并找到其最小特征值-向量对。对应的拉格朗日乘子可以通过求解线性系统得到，为全局最优性提供了简单的证书。

Result: 该方法在合成数据和多种真实世界场景（包括两个公开数据集和一个无人机跟踪场景）上进行了测试。单次迭代耗时约100微秒，能够实现快速的异常值剔除。

Conclusion: 所提出的方法能够高效地估计物体的三维形状和姿态，并提供全局最优性证书，适用于机器人领域的多种任务。

Abstract: Object shape and pose estimation is a foundational robotics problem,
supporting tasks from manipulation to scene understanding and navigation. We
present a fast local solver for shape and pose estimation which requires only
category-level object priors and admits an efficient certificate of global
optimality. Given an RGB-D image of an object, we use a learned front-end to
detect sparse, category-level semantic keypoints on the target object. We
represent the target object's unknown shape using a linear active shape model
and pose a maximum a posteriori optimization problem to solve for position,
orientation, and shape simultaneously. Expressed in unit quaternions, this
problem admits first-order optimality conditions in the form of an eigenvalue
problem with eigenvector nonlinearities. Our primary contribution is to solve
this problem efficiently with self-consistent field iteration, which only
requires computing a 4-by-4 matrix and finding its minimum eigenvalue-vector
pair at each iterate. Solving a linear system for the corresponding Lagrange
multipliers gives a simple global optimality certificate. One iteration of our
solver runs in about 100 microseconds, enabling fast outlier rejection. We test
our method on synthetic data and a variety of real-world settings, including
two public datasets and a drone tracking scenario. Code is released at
https://github.com/MIT-SPARK/Fast-ShapeAndPose.

</details>


### [554] [Pure Vision Language Action (VLA) Models: A Comprehensive Survey](https://arxiv.org/abs/2509.19012)
*Dapeng Zhang,Jin Sun,Chenghui Hu,Xiaoyan Wu,Zhenlong Yuan,Rui Zhou,Fei Shen,Qingguo Zhou*

Main category: cs.RO

TL;DR: VLA模型是机器人领域的一项新范式，可以主动进行操作和决策，而不是传统的基于策略的控制。本篇综述对VLA方法进行了分类，探讨了其动机、策略和实现，并介绍了相关数据集、基准和模拟平台，最后提出了未来的挑战和发展方向。


<details>
  <summary>Details</summary>
Motivation: VLA模型代表了从传统基于策略的控制到通用机器人的范式转变，将视觉语言模型（VLM）从被动的序列生成器转变为复杂、动态环境中操作和决策的主动代理。

Method: 本综述对VLA方法进行了分类，包括自回归、扩散、强化学习、混合和专用方法，并详细检查了它们的动机、核心策略和实现。此外，还介绍了基础数据集、基准和模拟平台。

Result: 本综述对VLA的出现、跨不同场景的应用进行了全面的分析，并对基于自回归、扩散、强化学习、混合和专用方法进行了分类。

Conclusion: 本综述对VLA的研究现状进行了全面的分析，并提出了关键挑战和未来方向的观点，以推动VLA模型和可泛化机器人的研究。

Abstract: The emergence of Vision Language Action (VLA) models marks a paradigm shift
from traditional policy-based control to generalized robotics, reframing Vision
Language Models (VLMs) from passive sequence generators into active agents for
manipulation and decision-making in complex, dynamic environments. This survey
delves into advanced VLA methods, aiming to provide a clear taxonomy and a
systematic, comprehensive review of existing research. It presents a
comprehensive analysis of VLA applications across different scenarios and
classifies VLA approaches into several paradigms: autoregression-based,
diffusion-based, reinforcement-based, hybrid, and specialized methods; while
examining their motivations, core strategies, and implementations in detail. In
addition, foundational datasets, benchmarks, and simulation platforms are
introduced. Building on the current VLA landscape, the review further proposes
perspectives on key challenges and future directions to advance research in VLA
models and generalizable robotics. By synthesizing insights from over three
hundred recent studies, this survey maps the contours of this rapidly evolving
field and highlights the opportunities and challenges that will shape the
development of scalable, general-purpose VLA methods.

</details>


### [555] [Reduced-Order Model-Guided Reinforcement Learning for Demonstration-Free Humanoid Locomotion](https://arxiv.org/abs/2509.19023)
*Shuai Liu,Meng Cheng Lau*

Main category: cs.RO

TL;DR: ROM-GRL是一个两阶段强化学习框架，用于人形机器人行走，无需动作捕捉数据或复杂的奖励塑造。第一阶段训练一个紧凑的4-DOF ROM，生成高效的步态模板。第二阶段使用SAC和对抗性判别器训练一个全身体策略，确保其步态特征分布与ROM的演示匹配。实验表明，ROM-GRL在1米/秒和4米/秒的速度下，比纯奖励基线产生更稳定、对称的步态，并具有更低的跟踪误差。通过将轻量级ROM引导提炼到高维策略中，ROM-GRL在仅奖励和基于模仿的运动方法之间架起了桥梁，实现了无需人类演示的多功能、自然的类人行为。


<details>
  <summary>Details</summary>
Motivation: 该研究旨在开发一种无需动作捕捉数据或复杂奖励塑造即可实现人形机器人高效行走的方法。

Method: 该研究提出了一种名为ROM-GRL的两阶段强化学习框架。第一阶段，通过近端策略优化（PPO）训练一个4自由度（DOF）的降阶模型（ROM），以生成高效的步态模板。第二阶段，利用软Actor-Critic（SAC）算法结合对抗性判别器，训练一个全身体策略，确保其五维步态特征分布与ROM的演示匹配。

Result: 在1米/秒和4米/秒的速度下进行的实验表明，ROM-GRL生成的步态稳定且对称，与纯奖励基线相比，跟踪误差显著降低。

Conclusion: ROM-GRL通过将轻量级ROM的引导提炼到高维策略中，弥合了仅奖励方法和基于模仿的方法之间的差距，实现了无需人类演示即可实现通用、自然的类人行为。

Abstract: We introduce Reduced-Order Model-Guided Reinforcement Learning (ROM-GRL), a
two-stage reinforcement learning framework for humanoid walking that requires
no motion capture data or elaborate reward shaping. In the first stage, a
compact 4-DOF (four-degree-of-freedom) reduced-order model (ROM) is trained via
Proximal Policy Optimization. This generates energy-efficient gait templates.
In the second stage, those dynamically consistent trajectories guide a
full-body policy trained with Soft Actor--Critic augmented by an adversarial
discriminator, ensuring the student's five-dimensional gait feature
distribution matches the ROM's demonstrations. Experiments at 1
meter-per-second and 4 meter-per-second show that ROM-GRL produces stable,
symmetric gaits with substantially lower tracking error than a pure-reward
baseline. By distilling lightweight ROM guidance into high-dimensional
policies, ROM-GRL bridges the gap between reward-only and imitation-based
locomotion methods, enabling versatile, naturalistic humanoid behaviors without
any human demonstrations.

</details>


### [556] [TacEva: A Performance Evaluation Framework For Vision-Based Tactile Sensors](https://arxiv.org/abs/2509.19037)
*Qingzheng Cong,Steven Oh,Wen Fan,Shan Luo,Kaspar Althoefer,Dandan Zhang*

Main category: cs.RO

TL;DR: TacEva是一个用于评估视觉触觉传感器(VBTS)性能的框架，解决了现有传感器性能不一致和缺乏标准化评估指标的问题。


<details>
  <summary>Details</summary>
Motivation: 现有视觉触觉传感器(VBTS)由于传感机制、结构尺寸等参数的差异，导致性能差异显著，难以针对特定任务进行优化，缺乏标准化评估指标。

Method: 提出TacEva框架，定义了一套性能指标，并设计了结构化的实验流程，以实现对VBTS性能的一致性和可重复性量化。

Result: 将TacEva框架应用于多种不同传感机制的VBTS，实验结果表明该框架能够提供详尽的设计评估和各性能维度的量化指标。

Conclusion: TacEva框架能够帮助研究人员根据具体任务预先选择最合适的VBTS，并为优化VBTS设计提供性能指导。

Abstract: Vision-Based Tactile Sensors (VBTSs) are widely used in robotic tasks because
of the high spatial resolution they offer and their relatively low
manufacturing costs. However, variations in their sensing mechanisms,
structural dimension, and other parameters lead to significant performance
disparities between existing VBTSs. This makes it challenging to optimize them
for specific tasks, as both the initial choice and subsequent fine-tuning are
hindered by the lack of standardized metrics. To address this issue, TacEva is
introduced as a comprehensive evaluation framework for the quantitative
analysis of VBTS performance. The framework defines a set of performance
metrics that capture key characteristics in typical application scenarios. For
each metric, a structured experimental pipeline is designed to ensure
consistent and repeatable quantification. The framework is applied to multiple
VBTSs with distinct sensing mechanisms, and the results demonstrate its ability
to provide a thorough evaluation of each design and quantitative indicators for
each performance dimension. This enables researchers to pre-select the most
appropriate VBTS on a task by task basis, while also offering
performance-guided insights into the optimization of VBTS design. A list of
existing VBTS evaluation methods and additional evaluations can be found on our
website: https://stevenoh2003.github.io/TacEva/

</details>


### [557] [ManipForce: Force-Guided Policy Learning with Frequency-Aware Representation for Contact-Rich Manipulation](https://arxiv.org/abs/2509.19047)
*Geonhyup Lee,Yeongjin Lee,Kangmin Kim,Seongju Lee,Sangjun Noh,Seunghyeok Back,Kyoobin Lee*

Main category: cs.RO

TL;DR: ManipForce是一个手持系统，用于捕捉机器人操作过程中的力和扭矩（F/T）及RGB数据。结合该数据，研究者提出了一种名为FMT（Frequency-Aware Multimodal Transformer）的策略，通过编码和融合异步的RGB和F/T信号，以Transformer扩散策略的形式来处理接触式操作任务。在6个现实世界的接触式操作任务中，FMT策略取得了83%的平均成功率，显著优于仅使用RGB数据的基线方法。实验结果表明，高频F/T数据和跨模态融合对于需要高精度和稳定接触的任务尤为重要。


<details>
  <summary>Details</summary>
Motivation: 现有的模仿学习方法主要依赖于视觉演示，难以精确控制接触式操作任务中的交互力，而这类任务（如精密装配）需要精确的力控制。

Method: 提出了一种名为ManipForce的手持系统，用于捕捉自然人演示过程中高频的力和扭矩（F/T）以及RGB数据。在此基础上，提出了一种名为FMT（Frequency-Aware Multimodal Transformer）的策略，该策略使用频率和模态感知的嵌入来编码异步的RGB和F/T信号，并通过双向交叉注意力机制在Transformer扩散策略中融合这些信息。

Result: 在6个现实世界的接触式操作任务（如齿轮组装、翻箱和电池插入）上进行了广泛的实验。FMT策略在ManipForce演示下训练，在所有任务上的平均成功率为83%，显著优于仅RGB数据的基线方法。消融研究和采样频率分析进一步证实，包含高频F/T数据和跨模态集成可以提高策略性能，尤其是在需要高精度和稳定接触的任务中。

Conclusion: 高频的力和扭矩数据对于提高接触式操作任务中的机器人策略性能至关重要，特别是对于需要高精度和稳定接触的任务。ManipForce系统和FMT策略的结合为解决这些挑战提供了一种有效的方法。

Abstract: Contact-rich manipulation tasks such as precision assembly require precise
control of interaction forces, yet existing imitation learning methods rely
mainly on vision-only demonstrations. We propose ManipForce, a handheld system
designed to capture high-frequency force-torque (F/T) and RGB data during
natural human demonstrations for contact-rich manipulation. Building on these
demonstrations, we introduce the Frequency-Aware Multimodal Transformer (FMT).
FMT encodes asynchronous RGB and F/T signals using frequency- and
modality-aware embeddings and fuses them via bi-directional cross-attention
within a transformer diffusion policy. Through extensive experiments on six
real-world contact-rich manipulation tasks - such as gear assembly, box
flipping, and battery insertion - FMT trained on ManipForce demonstrations
achieves robust performance with an average success rate of 83% across all
tasks, substantially outperforming RGB-only baselines. Ablation and
sampling-frequency analyses further confirm that incorporating high-frequency
F/T data and cross-modal integration improves policy performance, especially in
tasks demanding high precision and stable contact.

</details>


### [558] [SlicerROS2: A Research and Development Module for Image-Guided Robotic Interventions](https://arxiv.org/abs/2509.19076)
*Laura Connolly,Aravind S. Kumar,Kapi Ketan Mehta,Lidia Al-Zogbi,Peter Kazanzides,Parvin Mousavi,Gabor Fichtinger,Axel Krieger,Junichi Tokuda,Russell H. Taylor,Simon Leonard,Anton Deguet*

Main category: cs.RO

TL;DR: SlicerROS2是一个结合了3D Slicer和ROS的软件模块，用于标准化医学机器人研究的集成方法。新版本提供了更大的模块化、对低级功能和3D Slicer Python API的访问，以及更好的数据传输协议，并通过四个实际应用展示了其在图像引导机器人场景中的核心功能。


<details>
  <summary>Details</summary>
Motivation: 为了在医学机器人研究中实现标准化的集成方法，需要一个能够结合3D Slicer和ROS的软件模块。

Method: 通过重写和重新设计SlicerROS2模块，提供了更大的模块化、对低级功能和3D Slicer Python API的访问，以及更好的数据传输协议。

Result: 新设计提供了更大的模块化、对低级功能和3D Slicer Python API的访问，以及更好的数据传输协议，并通过四个实际应用展示了其在图像引导机器人场景中的核心功能。

Conclusion: 新设计的SlicerROS2模块通过提供增强的功能和实际应用，进一步推动了医学机器人研究的标准集成。

Abstract: Image-guided robotic interventions involve the use of medical imaging in
tandem with robotics. SlicerROS2 is a software module that combines 3D Slicer
and robot operating system (ROS) in pursuit of a standard integration approach
for medical robotics research. The first release of SlicerROS2 demonstrated the
feasibility of using the C++ API from 3D Slicer and ROS to load and visualize
robots in real time. Since this initial release, we've rewritten and redesigned
the module to offer greater modularity, access to low-level features, access to
3D Slicer's Python API, and better data transfer protocols. In this paper, we
introduce this new design as well as four applications that leverage the core
functionalities of SlicerROS2 in realistic image-guided robotics scenarios.

</details>


### [559] [World4RL: Diffusion World Models for Policy Refinement with Reinforcement Learning for Robotic Manipulation](https://arxiv.org/abs/2509.19080)
*Zhennan Jiang,Kai Liu,Yuxin Qin,Shuai Tian,Yupeng Zheng,Mingcai Zhou,Chao Yu,Haoran Li,Dongbin Zhao*

Main category: cs.RO

TL;DR: 通过使用基于扩散模型的世界模型来优化机器人操纵策略，实现完全在模拟环境中进行，从而提高成功率。


<details>
  <summary>Details</summary>
Motivation: 机器人操纵策略的训练受限于专家数据稀疏和覆盖范围窄的问题，而强化学习在真实机器人上训练成本高且不安全，在模拟器上训练则存在域迁移问题。

Method: 提出了一种名为World4RL的框架，该框架利用基于扩散模型的世界模型作为高保真模拟器，在完全虚构的环境中对预训练的策略进行优化。该框架包含预训练扩散世界模型和在冻结的世界模型中进行策略精炼两个关键部分，并设计了两项创新：一种用于机器人操纵的两热编码方案和采用扩散主干网络以提高建模保真度。

Result: 实验结果表明，World4RL能够提供高保真度的环境建模，并实现一致的策略精炼，与仅模仿学习和其他基线方法相比，成功率显著提高。

Conclusion: 基于扩散模型的世界模型可以有效地用于机器人操纵策略的优化，解决了现有方法的局限性，并在模拟和真实世界实验中取得了优于对比方法的成果。

Abstract: Robotic manipulation policies are commonly initialized through imitation
learning, but their performance is limited by the scarcity and narrow coverage
of expert data. Reinforcement learning can refine polices to alleviate this
limitation, yet real-robot training is costly and unsafe, while training in
simulators suffers from the sim-to-real gap. Recent advances in generative
models have demonstrated remarkable capabilities in real-world simulation, with
diffusion models in particular excelling at generation. This raises the
question of how diffusion model-based world models can be combined to enhance
pre-trained policies in robotic manipulation. In this work, we propose
World4RL, a framework that employs diffusion-based world models as
high-fidelity simulators to refine pre-trained policies entirely in imagined
environments for robotic manipulation. Unlike prior works that primarily employ
world models for planning, our framework enables direct end-to-end policy
optimization. World4RL is designed around two principles: pre-training a
diffusion world model that captures diverse dynamics on multi-task datasets and
refining policies entirely within a frozen world model to avoid online
real-world interactions. We further design a two-hot action encoding scheme
tailored for robotic manipulation and adopt diffusion backbones to improve
modeling fidelity. Extensive simulation and real-world experiments demonstrate
that World4RL provides high-fidelity environment modeling and enables
consistent policy refinement, yielding significantly higher success rates
compared to imitation learning and other baselines. More visualization results
are available at https://world4rl.github.io/.

</details>


### [560] [FUNCanon: Learning Pose-Aware Action Primitives via Functional Object Canonicalization for Generalizable Robotic Manipulation](https://arxiv.org/abs/2509.19102)
*Hongli Xu,Lei Zhang,Xiaoyue Hu,Boyang Zhong,Kaixin Bai,Zoltán-Csaba Márton,Zhenshan Bing,Zhaopeng Chen,Alois Christian Knoll,Jianwei Zhang*

Main category: cs.RO

TL;DR: FunCanon框架通过将长时操作任务分解为由执行者、动词和对象定义的动作块序列，并将物体映射到共享的功能帧中，来提高机器人技能的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 通用机器人技能通常局限于特定任务，泛化能力差。该研究旨在通过一种新框架来解决这一问题。

Method: 提出FunCanon框架，将长时操作任务分解为动作块序列（执行者、动词、对象），并利用视觉语言模型进行功能物体规范化，实现姿态感知和类别泛化。在此基础上训练FuncDiffuser策略。

Result: 实验证明FunCanon在模拟和真实世界基准测试中实现了类别泛化、跨任务行为复用和鲁棒的sim2real部署。

Conclusion: 功能规范化为复杂操作领域的可扩展模仿学习提供了强大的归纳偏见，提高了泛化能力。

Abstract: General-purpose robotic skills from end-to-end demonstrations often leads to
task-specific policies that fail to generalize beyond the training
distribution. Therefore, we introduce FunCanon, a framework that converts
long-horizon manipulation tasks into sequences of action chunks, each defined
by an actor, verb, and object. These chunks focus policy learning on the
actions themselves, rather than isolated tasks, enabling compositionality and
reuse. To make policies pose-aware and category-general, we perform functional
object canonicalization for functional alignment and automatic manipulation
trajectory transfer, mapping objects into shared functional frames using
affordance cues from large vision language models. An object centric and action
centric diffusion policy FuncDiffuser trained on this aligned data naturally
respects object affordances and poses, simplifying learning and improving
generalization ability. Experiments on simulated and real-world benchmarks
demonstrate category-level generalization, cross-task behavior reuse, and
robust sim2real deployment, showing that functional canonicalization provides a
strong inductive bias for scalable imitation learning in complex manipulation
domains. Details of the demo and supplemental material are available on our
project website https://sites.google.com/view/funcanon.

</details>


### [561] [Spectral Signature Mapping from RGB Imagery for Terrain-Aware Navigation](https://arxiv.org/abs/2509.19105)
*Sarvesh Prajapati,Ananya Trivedi,Nathaniel Hanson,Bruce Maxwell,Taskin Padir*

Main category: cs.RO

TL;DR: RS-Net利用RGB图像预测光谱特征，从而推断地形和摩擦系数，并将其应用于轮式和四足机器人的运动规划中，解决了传统方法在区分视觉相似但材质不同的地表时的局限性。


<details>
  <summary>Details</summary>
Motivation: 现有的机器人导航方法依赖几何或语义标签来分类可通行表面，但无法区分视觉相似但材质不同的表面。光谱传感可以推断材质组成，但存在硬件集成、成本和计算处理的挑战。本研究旨在结合RGB传感的易用性和光谱数据的丰富材质信息。

Method: 提出了一种名为RS-Net的深度神经网络，用于从RGB图像块预测光谱特征。然后将预测的光谱特征映射到地形标签和摩擦系数。最后，将地形分类集成到采样基运动规划器中，将摩擦估计集成到基于接触力-MPC的控制器中，用于轮式和四足机器人在户外环境中的导航。

Result: RS-Net能够从RGB图像预测地形分类和摩擦系数，并成功应用于轮式和四足机器人的导航任务，实现了在仅使用RGB传感的情况下进行有效的导航。

Conclusion: 本研究提出了一种框架，通过RS-Net从RGB图像中学习并预测物理属性（如地形和摩擦），解决了传统方法在区分材质方面的不足，并为机器人提供了仅依赖RGB传感即可进行户外导航的能力。

Abstract: Successful navigation in outdoor environments requires accurate prediction of
the physical interactions between the robot and the terrain. To this end,
several methods rely on geometric or semantic labels to classify traversable
surfaces. However, such labels cannot distinguish visually similar surfaces
that differ in material properties. Spectral sensors enable inference of
material composition from surface reflectance measured across multiple
wavelength bands. Although spectral sensing is gaining traction in robotics,
widespread deployment remains constrained by the need for custom hardware
integration, high sensor costs, and compute-intensive processing pipelines. In
this paper, we present RGB Image to Spectral Signature Neural Network (RS-Net),
a deep neural network designed to bridge the gap between the accessibility of
RGB sensing and the rich material information provided by spectral data. RS-Net
predicts spectral signatures from RGB patches, which we map to terrain labels
and friction coefficients. The resulting terrain classifications are integrated
into a sampling-based motion planner for a wheeled robot operating in outdoor
environments. Likewise, the friction estimates are incorporated into a
contact-force-based MPC for a quadruped robot navigating slippery surfaces.
Thus, we introduce a framework that learns the task-relevant physical property
once during training and thereafter relies solely on RGB sensing at test time.
The code is available at https://github.com/prajapatisarvesh/RS-Net.

</details>


### [562] [BiGraspFormer: End-to-End Bimanual Grasp Transformer](https://arxiv.org/abs/2509.19142)
*Kangmin Kim,Seunghyeok Back,Geonhyup Lee,Sangbeom Lee,Sangjun Noh,Kyoobin Lee*

Main category: cs.RO

TL;DR: BiGraspFormer是一个端到端的Transformer框架，可以直接从物体点云生成协调的双臂抓取，解决了现有方法在协调抓取方面的不足。


<details>
  <summary>Details</summary>
Motivation: 现有方法在双臂抓取方面存在协调问题，如碰撞风险和力不平衡，而BiGraspFormer旨在解决这些限制。

Method: BiGraspFormer采用Single-Guided Bimanual (SGB)策略，首先生成多种单臂抓取候选，然后利用注意力机制预测双臂姿态和质量分数。

Result: BiGraspFormer在仿真和真实世界实验中持续优于现有方法，并且推理速度快（<0.05s）。

Conclusion: BiGraspFormer能够有效生成协调的双臂抓取，并且性能优越。

Abstract: Bimanual grasping is essential for robots to handle large and complex
objects. However, existing methods either focus solely on single-arm grasping
or employ separate grasp generation and bimanual evaluation stages, leading to
coordination problems including collision risks and unbalanced force
distribution. To address these limitations, we propose BiGraspFormer, a unified
end-to-end transformer framework that directly generates coordinated bimanual
grasps from object point clouds. Our key idea is the Single-Guided Bimanual
(SGB) strategy, which first generates diverse single grasp candidates using a
transformer decoder, then leverages their learned features through specialized
attention mechanisms to jointly predict bimanual poses and quality scores. This
conditioning strategy reduces the complexity of the 12-DoF search space while
ensuring coordinated bimanual manipulation. Comprehensive simulation
experiments and real-world validation demonstrate that BiGraspFormer
consistently outperforms existing methods while maintaining efficient inference
speed (<0.05s), confirming the effectiveness of our framework. Code and
supplementary materials are available at https://sites.google.com/bigraspformer

</details>


### [563] [A Multimodal Stochastic Planning Approach for Navigation and Multi-Robot Coordination](https://arxiv.org/abs/2509.19168)
*Mark Gonzales,Ethan Oh,Joseph Moore*

Main category: cs.RO

TL;DR: 提出一种基于交叉熵的多模态策略规划方法，用于解决多智能体避障和陷阱环境下的规划问题。


<details>
  <summary>Details</summary>
Motivation: 在多智能体规划中，尤其是在存在局部最优解和需要有效探索解空间的情况下，需要一种能够处理多模态策略分布的方法来提高鲁棒性。

Method: 使用交叉熵方法优化多模态策略分布，并将其应用于多智能体无碰撞规划，允许智能体共享多样化的候选策略以避免死锁，并最小化全局目标。

Result: 该方法在陷阱环境和多智能体避障的数值模拟中显著提高了成功率。硬件实验验证了该方法的实时可行性和实际性能。

Conclusion: 基于交叉熵的多模态策略规划方法能够有效提高多智能体规划的成功率和鲁棒性，并能在保持较低计算复杂度的同时实现分布式优化。

Abstract: In this paper, we present a receding-horizon, sampling-based planner capable
of reasoning over multimodal policy distributions. By using the cross-entropy
method to optimize a multimodal policy under a common cost function, our
approach increases robustness against local minima and promotes effective
exploration of the solution space. We show that our approach naturally extends
to multi-robot collision-free planning, enables agents to share diverse
candidate policies to avoid deadlocks, and allows teams to minimize a global
objective without incurring the computational complexity of centralized
optimization. Numerical simulations demonstrate that employing multiple modes
significantly improves success rates in trap environments and in multi-robot
collision avoidance. Hardware experiments further validate the approach's
real-time feasibility and practical performance.

</details>


### [564] [MagiClaw: A Dual-Use, Vision-Based Soft Gripper for Bridging the Human Demonstration to Robotic Deployment Gap](https://arxiv.org/abs/2509.19169)
*Tianyu Wu,Xudong Han,Haoran Sun,Zishang Zhang,Bangchao Huang,Chaoyang Song,Fang Wan*

Main category: cs.RO

TL;DR: MagiClaw是一个通用的两指末端执行器，它充当了手工工具和机器人末端执行器的角色，以弥合操作技能转移中的“域间隙”。它通过集成的SPN（带摄像头）和iPhone（提供姿态、RGB视频和深度图）来收集多模态数据，以实现机器人操作。


<details>
  <summary>Details</summary>
Motivation: 解决在人类演示到机器人执行的操作技能转移中，“域间隙”带来的挑战，以实现更通用的操作策略。

Method: MagiClaw利用集成的SPN（带摄像头）和iPhone（提供6D姿态、RGB视频和深度图）来收集多模态数据。数据通过自定义iOS应用程序进行同步和流式传输，用于实时遥操作、离线策略学习和混合现实控制。

Result: MagiClaw能够作为手工工具和机器人末端执行器，收集高保真、接触丰富的操作数据集，从而加速通用操作策略的开发。

Conclusion: MagiClaw通过统一的系统架构，降低了收集数据集的门槛，并加速了通用操作策略的开发。

Abstract: The transfer of manipulation skills from human demonstration to robotic
execution is often hindered by a "domain gap" in sensing and morphology. This
paper introduces MagiClaw, a versatile two-finger end-effector designed to
bridge this gap. MagiClaw functions interchangeably as both a handheld tool for
intuitive data collection and a robotic end-effector for policy deployment,
ensuring hardware consistency and reliability. Each finger incorporates a Soft
Polyhedral Network (SPN) with an embedded camera, enabling vision-based
estimation of 6-DoF forces and contact deformation. This proprioceptive data is
fused with exteroceptive environmental sensing from an integrated iPhone, which
provides 6D pose, RGB video, and LiDAR-based depth maps. Through a custom iOS
application, MagiClaw streams synchronized, multi-modal data for real-time
teleoperation, offline policy learning, and immersive control via mixed-reality
interfaces. We demonstrate how this unified system architecture lowers the
barrier to collecting high-fidelity, contact-rich datasets and accelerates the
development of generalizable manipulation policies. Please refer to the iOS app
at https://apps.apple.com/cn/app/magiclaw/id6661033548 for further details.

</details>


### [565] [Imitation-Guided Bimanual Planning for Stable Manipulation under Changing External Forces](https://arxiv.org/abs/2509.19261)
*Kuanqi Cai,Chunfeng Wang,Zeqi Li,Haowen Yao,Weinan Chen,Luis Figueredo,Aude Billard,Arash Ajoudani*

Main category: cs.RO

TL;DR: 提出了一种模仿引导的双臂规划框架，通过集成高效的抓取过渡策略和运动性能优化，来提高机器人操作的稳定性和灵活性。


<details>
  <summary>Details</summary>
Motivation: 现有的抓取过渡策略常常无法考虑不断变化的外部力，也不能有效地优化运动性能，导致在动态环境中机器人操作的稳定性和效率受到限制。

Method: 提出了一种模仿引导的双臂规划框架，该框架包含用于在单臂和双臂抓取之间实现无缝过渡的稳定交集采样策略，以及一个结合了模仿学习的全局路径生成器和二次规划驱动的局部规划器的分层双阶段运动架构。

Result: 通过一系列力密集型任务的评估，证明了该方法在抓取过渡效率和运动性能方面有了显著的改进。

Conclusion: 提出的模仿引导的双臂规划框架能够有效地处理动态环境中的抓取过渡问题，提高了机器人操作的稳定性和灵活性。

Abstract: Robotic manipulation in dynamic environments often requires seamless
transitions between different grasp types to maintain stability and efficiency.
However, achieving smooth and adaptive grasp transitions remains a challenge,
particularly when dealing with external forces and complex motion constraints.
Existing grasp transition strategies often fail to account for varying external
forces and do not optimize motion performance effectively. In this work, we
propose an Imitation-Guided Bimanual Planning Framework that integrates
efficient grasp transition strategies and motion performance optimization to
enhance stability and dexterity in robotic manipulation. Our approach
introduces Strategies for Sampling Stable Intersections in Grasp Manifolds for
seamless transitions between uni-manual and bi-manual grasps, reducing
computational costs and regrasping inefficiencies. Additionally, a Hierarchical
Dual-Stage Motion Architecture combines an Imitation Learning-based Global Path
Generator with a Quadratic Programming-driven Local Planner to ensure real-time
motion feasibility, obstacle avoidance, and superior manipulability. The
proposed method is evaluated through a series of force-intensive tasks,
demonstrating significant improvements in grasp transition efficiency and
motion performance. A video demonstrating our simulation results can be viewed
at
\href{https://youtu.be/3DhbUsv4eDo}{\textcolor{blue}{https://youtu.be/3DhbUsv4eDo}}.

</details>


### [566] [SOE: Sample-Efficient Robot Policy Self-Improvement via On-Manifold Exploration](https://arxiv.org/abs/2509.19292)
*Yang Jin,Jun Lv,Han Xue,Wendi Chen,Chuan Wen,Cewu Lu*

Main category: cs.RO

TL;DR: SOE框架通过在可行动作流形上进行探索，增强了机器人操作策略的探索和改进能力，提高了任务成功率和样本效率，同时保证了安全性和多样性。


<details>
  <summary>Details</summary>
Motivation: 现有机器人策略的探索能力不足，常因动作模式崩溃和随机扰动导致不安全、不稳定的行为。SOE旨在解决这些问题，提高探索的安全性、多样性和有效性。

Method: SOE学习任务相关因素的紧凑潜在表示，并将探索限制在可行动作的流形上，以保证安全、多样和有效。它可以作为插件模块集成到现有策略模型中，增强探索能力而不影响基础策略性能。

Result: SOE在模拟和现实世界的任务中持续优于现有方法，实现了更高的任务成功率、更平稳和更安全的探索，以及更好的样本效率。

Conclusion: SOE将流形探索确立为一种原则性的、样本高效的策略自我改进方法。

Abstract: Intelligent agents progress by continually refining their capabilities
through actively exploring environments. Yet robot policies often lack
sufficient exploration capability due to action mode collapse. Existing methods
that encourage exploration typically rely on random perturbations, which are
unsafe and induce unstable, erratic behaviors, thereby limiting their
effectiveness. We propose Self-Improvement via On-Manifold Exploration (SOE), a
framework that enhances policy exploration and improvement in robotic
manipulation. SOE learns a compact latent representation of task-relevant
factors and constrains exploration to the manifold of valid actions, ensuring
safety, diversity, and effectiveness. It can be seamlessly integrated with
arbitrary policy models as a plug-in module, augmenting exploration without
degrading the base policy performance. Moreover, the structured latent space
enables human-guided exploration, further improving efficiency and
controllability. Extensive experiments in both simulation and real-world tasks
demonstrate that SOE consistently outperforms prior methods, achieving higher
task success rates, smoother and safer exploration, and superior sample
efficiency. These results establish on-manifold exploration as a principled
approach to sample-efficient policy self-improvement. Project website:
https://ericjin2002.github.io/SOE

</details>


### [567] [Residual Off-Policy RL for Finetuning Behavior Cloning Policies](https://arxiv.org/abs/2509.19301)
*Lars Ankile,Zhenyu Jiang,Rocky Duan,Guanya Shi,Pieter Abbeel,Anusha Nagabandi*

Main category: cs.RO

TL;DR: BC and RL can be combined for better robot control, learning from human examples and then refining with reinforcement learning for efficiency and safety, even on complex robots like humanoids.


<details>
  <summary>Details</summary>
Motivation: Traditional behavior cloning (BC) relies on human demonstrations, which are limited by data quality and collection effort. Reinforcement learning (RL) can train agents autonomously but faces challenges in sample efficiency, safety, and sparse rewards, especially for high-degree-of-freedom (DoF) systems in the real world.

Method: A residual learning framework is proposed that uses BC policies as a base and learns lightweight per-step residual corrections through sample-efficient off-policy RL. This method only requires sparse binary rewards.

Result: The approach improves manipulation policies on high-DoF systems in simulation and the real world, demonstrating state-of-the-art performance on vision-based tasks. It achieved the first successful real-world RL training on a humanoid robot with dexterous hands.

Conclusion: The proposed method offers a practical way to deploy RL in the real world by combining the strengths of BC and RL, overcoming limitations of each individually, and achieving strong results on complex robotic manipulation tasks.

Abstract: Recent advances in behavior cloning (BC) have enabled impressive visuomotor
control policies. However, these approaches are limited by the quality of human
demonstrations, the manual effort required for data collection, and the
diminishing returns from increasing offline data. In comparison, reinforcement
learning (RL) trains an agent through autonomous interaction with the
environment and has shown remarkable success in various domains. Still,
training RL policies directly on real-world robots remains challenging due to
sample inefficiency, safety concerns, and the difficulty of learning from
sparse rewards for long-horizon tasks, especially for high-degree-of-freedom
(DoF) systems. We present a recipe that combines the benefits of BC and RL
through a residual learning framework. Our approach leverages BC policies as
black-box bases and learns lightweight per-step residual corrections via
sample-efficient off-policy RL. We demonstrate that our method requires only
sparse binary reward signals and can effectively improve manipulation policies
on high-degree-of-freedom (DoF) systems in both simulation and the real world.
In particular, we demonstrate, to the best of our knowledge, the first
successful real-world RL training on a humanoid robot with dexterous hands. Our
results demonstrate state-of-the-art performance in various vision-based tasks,
pointing towards a practical pathway for deploying RL in the real world.
Project website: https://residual-offpolicy-rl.github.io

</details>


<div id='cs.AR'></div>

# cs.AR [[Back]](#toc)

### [568] [Lightweight Congruence Profiling for Early Design Exploration of Heterogeneous FPGAs](https://arxiv.org/abs/2509.18295)
*Allen Boston,Biruk Seyoum,Luca Carloni,Pierre-Emmanuel Gaillardon*

Main category: cs.AR

TL;DR: FPGA 架构变得复杂，需要新的分析方法来优化设计。


<details>
  <summary>Details</summary>
Motivation: FPGA 架构集成越来越复杂，需要新的方法来优化设计和分析性能。

Method: 提出了一种基于 Roofline 模型的轻量级分析方法，引入了三个一致性分数来识别异构资源、FPGA  fabric 和应用逻辑相关的瓶颈。

Result: 在 Koios 和 VPR 基准套件上使用 Stratix 10 类似 FPGA 进行了评估。

Conclusion: 该方法能够有效地进行异构 FPGA 的架构协同设计，以提高性能。

Abstract: Field-Programmable Gate Arrays (FPGAs) have evolved from uniform logic arrays
into heterogeneous fabrics integrating digital signal processors (DSPs),
memories, and specialized accelerators to support emerging workloads such as
machine learning. While these enhancements improve power, performance, and area
(PPA), they complicate design space exploration and application optimization
due to complex resource interactions.
  To address these challenges, we propose a lightweight profiling methodology
inspired by the Roofline model. It introduces three congruence scores that
quickly identify bottlenecks related to heterogeneous resources, fabric, and
application logic. Evaluated on the Koios and VPR benchmark suites using a
Stratix 10 like FPGA, this approach enables efficient FPGA architecture
co-design to improve heterogeneous FPGA performance.

</details>


### [569] [Chiplet-Based RISC-V SoC with Modular AI Acceleration](https://arxiv.org/abs/2509.18355)
*P. Ramkumar,S. S. Bharadwaj*

Main category: cs.AR

TL;DR: 该论文提出了一种新颖的基于 chiplet 的 RISC-V SoC 架构，通过模块化 AI 加速和智能系统级优化来解决高性能、高能效和成本效益的挑战，并在行业标准基准测试中展示了显著的性能提升。


<details>
  <summary>Details</summary>
Motivation: 在先进的 360 mm^2 工艺节点上，单片 SoC 设计的低良率（低于 16%）阻碍了在保持架构灵活性的同时实现高性能、高能效和成本效益。

Method: 提出了一种包含 4 项关键创新的 chiplet 架构：自适应跨 chiplet 动态电压和频率调整 (DVFS)；支持流控单元和压缩感知传输的 AI 感知通用 chiplet 互联 Express (UCIe) 协议扩展；跨异构 chiplet 的分布式加密安全；以及智能传感器驱动的负载迁移。该架构集成了 7nm RISC-V CPU chiplet、双 5nm AI 加速器（各 15 TOPS INT8）、16GB HBM3 内存堆栈和专用电源管理控制器。

Result: 与之前的 basic chiplet 实现相比，AI 优化配置实现了约 14.7% 的延迟降低、17.3% 的吞吐量提高和 16.2% 的功耗降低，整体效率提高了 40.1%（MobileNetV2 推理约为 3.5 mJ，功耗为 860 mW，吞吐量为 244 images/s），同时在所有实验工作负载中保持了低于 5ms 的实时能力。

Conclusion: 模块化 chiplet 设计可以实现接近单片 SoC 的计算密度，同时提供成本效益、可扩展性和可升级性，这对于下一代边缘 AI 设备应用至关重要。

Abstract: Achieving high performance, energy efficiency, and cost-effectiveness while
maintaining architectural flexibility is a critical challenge in the
development and deployment of edge AI devices. Monolithic SoC designs struggle
with this complex balance mainly due to low manufacturing yields (below 16%) at
advanced 360 mm^2 process nodes. This paper presents a novel chiplet-based
RISC-V SoC architecture that addresses these limitations through modular AI
acceleration and intelligent system level optimization. Our proposed design
integrates 4 different key innovations in a 30mm x 30mm silicon interposer:
adaptive cross-chiplet Dynamic Voltage and Frequency Scaling (DVFS); AI-aware
Universal Chiplet Interconnect Express (UCIe) protocol extensions featuring
streaming flow control units and compression-aware transfers; distributed
cryptographic security across heterogeneous chiplets; and intelligent
sensor-driven load migration. The proposed architecture integrates a 7nm RISC-V
CPU chiplet with dual 5nm AI accelerators (15 TOPS INT8 each), 16GB HBM3 memory
stacks, and dedicated power management controllers. Experimental results across
industry standard benchmarks like MobileNetV2, ResNet-50 and real-time video
processing demonstrate significant performance improvements. The AI-optimized
configuration achieves ~14.7% latency reduction, 17.3% throughput improvement,
and 16.2% power reduction compared to previous basic chiplet implementations.
These improvements collectively translate to a 40.1% efficiency gain
corresponding to ~3.5 mJ per MobileNetV2 inference (860 mW/244 images/s), while
maintaining sub-5ms real-time capability across all experimented workloads.
These performance upgrades demonstrate that modular chiplet designs can achieve
near-monolithic computational density while enabling cost efficiency,
scalability and upgradeability, crucial for next-generation edge AI device
applications.

</details>
